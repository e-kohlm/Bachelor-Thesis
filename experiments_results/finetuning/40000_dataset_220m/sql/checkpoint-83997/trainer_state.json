{
  "best_metric": 0.8678587003924988,
  "best_model_checkpoint": "../saved_models/gpu_sql/checkpoint-83997",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 83997,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00010714668381013607,
      "grad_norm": 122.76207733154297,
      "learning_rate": 1.999978570663238e-05,
      "loss": 0.8478,
      "step": 1
    },
    {
      "epoch": 0.0010714668381013607,
      "grad_norm": 18.675800323486328,
      "learning_rate": 1.9997857066323797e-05,
      "loss": 0.5877,
      "step": 10
    },
    {
      "epoch": 0.0021429336762027215,
      "grad_norm": 24.490690231323242,
      "learning_rate": 1.9995714132647596e-05,
      "loss": 0.9093,
      "step": 20
    },
    {
      "epoch": 0.0032144005143040825,
      "grad_norm": 1.6155726909637451,
      "learning_rate": 1.9993571198971392e-05,
      "loss": 0.3098,
      "step": 30
    },
    {
      "epoch": 0.004285867352405443,
      "grad_norm": 137.00865173339844,
      "learning_rate": 1.999142826529519e-05,
      "loss": 1.4929,
      "step": 40
    },
    {
      "epoch": 0.005357334190506804,
      "grad_norm": 0.06712547689676285,
      "learning_rate": 1.9989285331618987e-05,
      "loss": 0.9807,
      "step": 50
    },
    {
      "epoch": 0.006428801028608165,
      "grad_norm": 85.21296691894531,
      "learning_rate": 1.9987142397942786e-05,
      "loss": 2.1003,
      "step": 60
    },
    {
      "epoch": 0.007500267866709525,
      "grad_norm": 0.9298816323280334,
      "learning_rate": 1.9984999464266585e-05,
      "loss": 0.9966,
      "step": 70
    },
    {
      "epoch": 0.008571734704810886,
      "grad_norm": 1.119080662727356,
      "learning_rate": 1.998285653059038e-05,
      "loss": 0.401,
      "step": 80
    },
    {
      "epoch": 0.009643201542912247,
      "grad_norm": 0.039417948573827744,
      "learning_rate": 1.9980713596914176e-05,
      "loss": 0.5112,
      "step": 90
    },
    {
      "epoch": 0.010714668381013608,
      "grad_norm": 67.4707260131836,
      "learning_rate": 1.9978570663237975e-05,
      "loss": 1.774,
      "step": 100
    },
    {
      "epoch": 0.011786135219114969,
      "grad_norm": 2.4675452709198,
      "learning_rate": 1.997642772956177e-05,
      "loss": 1.5788,
      "step": 110
    },
    {
      "epoch": 0.01285760205721633,
      "grad_norm": 1.0889428853988647,
      "learning_rate": 1.9974284795885567e-05,
      "loss": 0.7435,
      "step": 120
    },
    {
      "epoch": 0.013929068895317689,
      "grad_norm": 60.8398323059082,
      "learning_rate": 1.9972141862209366e-05,
      "loss": 0.4474,
      "step": 130
    },
    {
      "epoch": 0.01500053573341905,
      "grad_norm": 97.80406951904297,
      "learning_rate": 1.9969998928533165e-05,
      "loss": 1.1073,
      "step": 140
    },
    {
      "epoch": 0.016072002571520413,
      "grad_norm": 0.11261966079473495,
      "learning_rate": 1.996785599485696e-05,
      "loss": 0.714,
      "step": 150
    },
    {
      "epoch": 0.017143469409621772,
      "grad_norm": 105.6134033203125,
      "learning_rate": 1.996571306118076e-05,
      "loss": 0.7647,
      "step": 160
    },
    {
      "epoch": 0.018214936247723135,
      "grad_norm": 82.5982666015625,
      "learning_rate": 1.9963570127504555e-05,
      "loss": 0.8096,
      "step": 170
    },
    {
      "epoch": 0.019286403085824494,
      "grad_norm": 2.6925764083862305,
      "learning_rate": 1.9961427193828354e-05,
      "loss": 0.8256,
      "step": 180
    },
    {
      "epoch": 0.020357869923925853,
      "grad_norm": 5.882763862609863,
      "learning_rate": 1.995928426015215e-05,
      "loss": 0.861,
      "step": 190
    },
    {
      "epoch": 0.021429336762027216,
      "grad_norm": 0.7879958748817444,
      "learning_rate": 1.9957141326475945e-05,
      "loss": 1.213,
      "step": 200
    },
    {
      "epoch": 0.022500803600128575,
      "grad_norm": 38.01911163330078,
      "learning_rate": 1.9954998392799744e-05,
      "loss": 1.0264,
      "step": 210
    },
    {
      "epoch": 0.023572270438229938,
      "grad_norm": 56.17198944091797,
      "learning_rate": 1.995285545912354e-05,
      "loss": 1.038,
      "step": 220
    },
    {
      "epoch": 0.024643737276331297,
      "grad_norm": 246.5903778076172,
      "learning_rate": 1.995071252544734e-05,
      "loss": 0.5087,
      "step": 230
    },
    {
      "epoch": 0.02571520411443266,
      "grad_norm": 51.190242767333984,
      "learning_rate": 1.9948569591771135e-05,
      "loss": 0.3579,
      "step": 240
    },
    {
      "epoch": 0.02678667095253402,
      "grad_norm": 48.844482421875,
      "learning_rate": 1.9946426658094934e-05,
      "loss": 0.4875,
      "step": 250
    },
    {
      "epoch": 0.027858137790635378,
      "grad_norm": 0.22702409327030182,
      "learning_rate": 1.9944283724418733e-05,
      "loss": 0.7522,
      "step": 260
    },
    {
      "epoch": 0.02892960462873674,
      "grad_norm": 69.53632354736328,
      "learning_rate": 1.994214079074253e-05,
      "loss": 1.3245,
      "step": 270
    },
    {
      "epoch": 0.0300010714668381,
      "grad_norm": 13.827940940856934,
      "learning_rate": 1.9939997857066324e-05,
      "loss": 0.6803,
      "step": 280
    },
    {
      "epoch": 0.031072538304939463,
      "grad_norm": 1.2184255123138428,
      "learning_rate": 1.9937854923390123e-05,
      "loss": 0.2864,
      "step": 290
    },
    {
      "epoch": 0.032144005143040826,
      "grad_norm": 0.14393702149391174,
      "learning_rate": 1.993571198971392e-05,
      "loss": 1.1709,
      "step": 300
    },
    {
      "epoch": 0.033215471981142185,
      "grad_norm": 1.243528962135315,
      "learning_rate": 1.9933569056037718e-05,
      "loss": 1.3622,
      "step": 310
    },
    {
      "epoch": 0.034286938819243544,
      "grad_norm": 24.22310447692871,
      "learning_rate": 1.9931426122361514e-05,
      "loss": 0.2268,
      "step": 320
    },
    {
      "epoch": 0.0353584056573449,
      "grad_norm": 50.47933578491211,
      "learning_rate": 1.9929283188685313e-05,
      "loss": 0.8175,
      "step": 330
    },
    {
      "epoch": 0.03642987249544627,
      "grad_norm": 61.635597229003906,
      "learning_rate": 1.992714025500911e-05,
      "loss": 0.7784,
      "step": 340
    },
    {
      "epoch": 0.03750133933354763,
      "grad_norm": 44.28676986694336,
      "learning_rate": 1.9924997321332907e-05,
      "loss": 0.6999,
      "step": 350
    },
    {
      "epoch": 0.03857280617164899,
      "grad_norm": 3.378471851348877,
      "learning_rate": 1.9922854387656703e-05,
      "loss": 0.8931,
      "step": 360
    },
    {
      "epoch": 0.03964427300975035,
      "grad_norm": 13.709314346313477,
      "learning_rate": 1.9920711453980502e-05,
      "loss": 0.6983,
      "step": 370
    },
    {
      "epoch": 0.040715739847851706,
      "grad_norm": 10.715008735656738,
      "learning_rate": 1.9918568520304298e-05,
      "loss": 0.4842,
      "step": 380
    },
    {
      "epoch": 0.04178720668595307,
      "grad_norm": 0.9976497292518616,
      "learning_rate": 1.9916425586628097e-05,
      "loss": 0.6143,
      "step": 390
    },
    {
      "epoch": 0.04285867352405443,
      "grad_norm": 0.681986391544342,
      "learning_rate": 1.9914282652951892e-05,
      "loss": 0.8095,
      "step": 400
    },
    {
      "epoch": 0.04393014036215579,
      "grad_norm": 23.88422203063965,
      "learning_rate": 1.9912139719275688e-05,
      "loss": 0.2864,
      "step": 410
    },
    {
      "epoch": 0.04500160720025715,
      "grad_norm": 0.20319904386997223,
      "learning_rate": 1.9909996785599487e-05,
      "loss": 1.0183,
      "step": 420
    },
    {
      "epoch": 0.04607307403835851,
      "grad_norm": 38.20836639404297,
      "learning_rate": 1.9907853851923283e-05,
      "loss": 1.0048,
      "step": 430
    },
    {
      "epoch": 0.047144540876459876,
      "grad_norm": 23.524206161499023,
      "learning_rate": 1.9905710918247082e-05,
      "loss": 0.3764,
      "step": 440
    },
    {
      "epoch": 0.048216007714561235,
      "grad_norm": 39.79494857788086,
      "learning_rate": 1.990356798457088e-05,
      "loss": 0.992,
      "step": 450
    },
    {
      "epoch": 0.049287474552662594,
      "grad_norm": 0.569127082824707,
      "learning_rate": 1.9901425050894677e-05,
      "loss": 0.9424,
      "step": 460
    },
    {
      "epoch": 0.05035894139076395,
      "grad_norm": 24.482158660888672,
      "learning_rate": 1.9899282117218476e-05,
      "loss": 0.4515,
      "step": 470
    },
    {
      "epoch": 0.05143040822886532,
      "grad_norm": 32.15747833251953,
      "learning_rate": 1.989713918354227e-05,
      "loss": 0.9429,
      "step": 480
    },
    {
      "epoch": 0.05250187506696668,
      "grad_norm": 29.45623016357422,
      "learning_rate": 1.9894996249866067e-05,
      "loss": 0.8031,
      "step": 490
    },
    {
      "epoch": 0.05357334190506804,
      "grad_norm": 0.6787106394767761,
      "learning_rate": 1.9892853316189866e-05,
      "loss": 0.5256,
      "step": 500
    },
    {
      "epoch": 0.0546448087431694,
      "grad_norm": 0.8328346610069275,
      "learning_rate": 1.9890710382513662e-05,
      "loss": 1.0428,
      "step": 510
    },
    {
      "epoch": 0.055716275581270756,
      "grad_norm": 24.351980209350586,
      "learning_rate": 1.988856744883746e-05,
      "loss": 0.9837,
      "step": 520
    },
    {
      "epoch": 0.05678774241937212,
      "grad_norm": 30.57132911682129,
      "learning_rate": 1.9886424515161256e-05,
      "loss": 0.9555,
      "step": 530
    },
    {
      "epoch": 0.05785920925747348,
      "grad_norm": 0.539790153503418,
      "learning_rate": 1.9884281581485055e-05,
      "loss": 0.508,
      "step": 540
    },
    {
      "epoch": 0.05893067609557484,
      "grad_norm": 0.2007112354040146,
      "learning_rate": 1.9882138647808855e-05,
      "loss": 0.6095,
      "step": 550
    },
    {
      "epoch": 0.0600021429336762,
      "grad_norm": 0.10219959914684296,
      "learning_rate": 1.987999571413265e-05,
      "loss": 0.5353,
      "step": 560
    },
    {
      "epoch": 0.061073609771777566,
      "grad_norm": 2.2306230068206787,
      "learning_rate": 1.9877852780456446e-05,
      "loss": 0.7573,
      "step": 570
    },
    {
      "epoch": 0.062145076609878926,
      "grad_norm": 33.84129333496094,
      "learning_rate": 1.9875709846780245e-05,
      "loss": 0.7093,
      "step": 580
    },
    {
      "epoch": 0.06321654344798029,
      "grad_norm": 42.94261932373047,
      "learning_rate": 1.987356691310404e-05,
      "loss": 1.073,
      "step": 590
    },
    {
      "epoch": 0.06428801028608165,
      "grad_norm": 0.9644546508789062,
      "learning_rate": 1.9871423979427836e-05,
      "loss": 1.2828,
      "step": 600
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 30.62038230895996,
      "learning_rate": 1.9869281045751635e-05,
      "loss": 0.812,
      "step": 610
    },
    {
      "epoch": 0.06643094396228437,
      "grad_norm": 7.565391540527344,
      "learning_rate": 1.986713811207543e-05,
      "loss": 0.6142,
      "step": 620
    },
    {
      "epoch": 0.06750241080038573,
      "grad_norm": 25.112192153930664,
      "learning_rate": 1.986499517839923e-05,
      "loss": 0.6589,
      "step": 630
    },
    {
      "epoch": 0.06857387763848709,
      "grad_norm": 12.029792785644531,
      "learning_rate": 1.986285224472303e-05,
      "loss": 0.4028,
      "step": 640
    },
    {
      "epoch": 0.06964534447658845,
      "grad_norm": 37.984745025634766,
      "learning_rate": 1.9860709311046825e-05,
      "loss": 0.4769,
      "step": 650
    },
    {
      "epoch": 0.0707168113146898,
      "grad_norm": 25.977697372436523,
      "learning_rate": 1.9858566377370624e-05,
      "loss": 1.0984,
      "step": 660
    },
    {
      "epoch": 0.07178827815279117,
      "grad_norm": 30.03087043762207,
      "learning_rate": 1.985642344369442e-05,
      "loss": 1.0648,
      "step": 670
    },
    {
      "epoch": 0.07285974499089254,
      "grad_norm": 26.061241149902344,
      "learning_rate": 1.9854280510018215e-05,
      "loss": 0.6362,
      "step": 680
    },
    {
      "epoch": 0.0739312118289939,
      "grad_norm": 31.201377868652344,
      "learning_rate": 1.9852137576342014e-05,
      "loss": 1.028,
      "step": 690
    },
    {
      "epoch": 0.07500267866709526,
      "grad_norm": 32.598270416259766,
      "learning_rate": 1.984999464266581e-05,
      "loss": 0.5785,
      "step": 700
    },
    {
      "epoch": 0.07607414550519662,
      "grad_norm": 15.949535369873047,
      "learning_rate": 1.984785170898961e-05,
      "loss": 0.5234,
      "step": 710
    },
    {
      "epoch": 0.07714561234329798,
      "grad_norm": 0.22459755837917328,
      "learning_rate": 1.9845708775313404e-05,
      "loss": 0.0431,
      "step": 720
    },
    {
      "epoch": 0.07821707918139933,
      "grad_norm": 31.492610931396484,
      "learning_rate": 1.9843565841637204e-05,
      "loss": 1.135,
      "step": 730
    },
    {
      "epoch": 0.0792885460195007,
      "grad_norm": 1.6823546886444092,
      "learning_rate": 1.9841422907961003e-05,
      "loss": 0.4811,
      "step": 740
    },
    {
      "epoch": 0.08036001285760205,
      "grad_norm": 8.886484146118164,
      "learning_rate": 1.9839279974284798e-05,
      "loss": 0.3779,
      "step": 750
    },
    {
      "epoch": 0.08143147969570341,
      "grad_norm": 0.0694020539522171,
      "learning_rate": 1.9837137040608594e-05,
      "loss": 0.4043,
      "step": 760
    },
    {
      "epoch": 0.08250294653380477,
      "grad_norm": 19.54446792602539,
      "learning_rate": 1.9834994106932393e-05,
      "loss": 0.829,
      "step": 770
    },
    {
      "epoch": 0.08357441337190614,
      "grad_norm": 12.93506145477295,
      "learning_rate": 1.983285117325619e-05,
      "loss": 0.6471,
      "step": 780
    },
    {
      "epoch": 0.0846458802100075,
      "grad_norm": 0.20939823985099792,
      "learning_rate": 1.9830708239579988e-05,
      "loss": 0.7108,
      "step": 790
    },
    {
      "epoch": 0.08571734704810886,
      "grad_norm": 40.60633850097656,
      "learning_rate": 1.9828565305903783e-05,
      "loss": 1.007,
      "step": 800
    },
    {
      "epoch": 0.08678881388621022,
      "grad_norm": 1.603236198425293,
      "learning_rate": 1.982642237222758e-05,
      "loss": 0.881,
      "step": 810
    },
    {
      "epoch": 0.08786028072431158,
      "grad_norm": 0.20851071178913116,
      "learning_rate": 1.9824279438551378e-05,
      "loss": 0.5729,
      "step": 820
    },
    {
      "epoch": 0.08893174756241294,
      "grad_norm": 0.4474216401576996,
      "learning_rate": 1.9822136504875177e-05,
      "loss": 1.1212,
      "step": 830
    },
    {
      "epoch": 0.0900032144005143,
      "grad_norm": 0.750798225402832,
      "learning_rate": 1.9819993571198973e-05,
      "loss": 0.3869,
      "step": 840
    },
    {
      "epoch": 0.09107468123861566,
      "grad_norm": 5.993780136108398,
      "learning_rate": 1.9817850637522772e-05,
      "loss": 0.6162,
      "step": 850
    },
    {
      "epoch": 0.09214614807671702,
      "grad_norm": 0.42682674527168274,
      "learning_rate": 1.9815707703846567e-05,
      "loss": 0.5139,
      "step": 860
    },
    {
      "epoch": 0.09321761491481839,
      "grad_norm": 0.3968428373336792,
      "learning_rate": 1.9813564770170367e-05,
      "loss": 0.7857,
      "step": 870
    },
    {
      "epoch": 0.09428908175291975,
      "grad_norm": 45.233497619628906,
      "learning_rate": 1.9811421836494162e-05,
      "loss": 1.0177,
      "step": 880
    },
    {
      "epoch": 0.09536054859102111,
      "grad_norm": 2.1403679847717285,
      "learning_rate": 1.9809278902817958e-05,
      "loss": 0.4137,
      "step": 890
    },
    {
      "epoch": 0.09643201542912247,
      "grad_norm": 0.8195986151695251,
      "learning_rate": 1.9807135969141757e-05,
      "loss": 0.7365,
      "step": 900
    },
    {
      "epoch": 0.09750348226722383,
      "grad_norm": 29.4318790435791,
      "learning_rate": 1.9804993035465553e-05,
      "loss": 0.7157,
      "step": 910
    },
    {
      "epoch": 0.09857494910532519,
      "grad_norm": 0.7603296637535095,
      "learning_rate": 1.980285010178935e-05,
      "loss": 0.6598,
      "step": 920
    },
    {
      "epoch": 0.09964641594342655,
      "grad_norm": 18.104501724243164,
      "learning_rate": 1.980070716811315e-05,
      "loss": 0.3191,
      "step": 930
    },
    {
      "epoch": 0.1007178827815279,
      "grad_norm": 32.52066421508789,
      "learning_rate": 1.9798564234436946e-05,
      "loss": 1.1729,
      "step": 940
    },
    {
      "epoch": 0.10178934961962927,
      "grad_norm": 12.61751651763916,
      "learning_rate": 1.9796421300760742e-05,
      "loss": 0.5392,
      "step": 950
    },
    {
      "epoch": 0.10286081645773064,
      "grad_norm": 0.9280394315719604,
      "learning_rate": 1.979427836708454e-05,
      "loss": 0.5008,
      "step": 960
    },
    {
      "epoch": 0.103932283295832,
      "grad_norm": 41.620216369628906,
      "learning_rate": 1.9792135433408337e-05,
      "loss": 0.9201,
      "step": 970
    },
    {
      "epoch": 0.10500375013393336,
      "grad_norm": 0.5429539084434509,
      "learning_rate": 1.9789992499732136e-05,
      "loss": 0.546,
      "step": 980
    },
    {
      "epoch": 0.10607521697203472,
      "grad_norm": 32.25482940673828,
      "learning_rate": 1.978784956605593e-05,
      "loss": 0.6976,
      "step": 990
    },
    {
      "epoch": 0.10714668381013608,
      "grad_norm": 15.14654541015625,
      "learning_rate": 1.9785706632379727e-05,
      "loss": 0.9066,
      "step": 1000
    },
    {
      "epoch": 0.10821815064823744,
      "grad_norm": 5.3031535148620605,
      "learning_rate": 1.9783563698703526e-05,
      "loss": 0.8024,
      "step": 1010
    },
    {
      "epoch": 0.1092896174863388,
      "grad_norm": 23.3075008392334,
      "learning_rate": 1.9781420765027325e-05,
      "loss": 0.7709,
      "step": 1020
    },
    {
      "epoch": 0.11036108432444015,
      "grad_norm": 23.441184997558594,
      "learning_rate": 1.977927783135112e-05,
      "loss": 0.4526,
      "step": 1030
    },
    {
      "epoch": 0.11143255116254151,
      "grad_norm": 37.092796325683594,
      "learning_rate": 1.977713489767492e-05,
      "loss": 0.8406,
      "step": 1040
    },
    {
      "epoch": 0.11250401800064289,
      "grad_norm": 0.21093547344207764,
      "learning_rate": 1.9774991963998716e-05,
      "loss": 0.9271,
      "step": 1050
    },
    {
      "epoch": 0.11357548483874425,
      "grad_norm": 22.77665138244629,
      "learning_rate": 1.9772849030322515e-05,
      "loss": 0.9858,
      "step": 1060
    },
    {
      "epoch": 0.1146469516768456,
      "grad_norm": 26.719959259033203,
      "learning_rate": 1.977070609664631e-05,
      "loss": 0.6783,
      "step": 1070
    },
    {
      "epoch": 0.11571841851494696,
      "grad_norm": 1.5760691165924072,
      "learning_rate": 1.9768563162970106e-05,
      "loss": 0.1806,
      "step": 1080
    },
    {
      "epoch": 0.11678988535304832,
      "grad_norm": 25.177072525024414,
      "learning_rate": 1.9766420229293905e-05,
      "loss": 1.0378,
      "step": 1090
    },
    {
      "epoch": 0.11786135219114968,
      "grad_norm": 23.907848358154297,
      "learning_rate": 1.97642772956177e-05,
      "loss": 0.5057,
      "step": 1100
    },
    {
      "epoch": 0.11893281902925104,
      "grad_norm": 13.558270454406738,
      "learning_rate": 1.97621343619415e-05,
      "loss": 0.7018,
      "step": 1110
    },
    {
      "epoch": 0.1200042858673524,
      "grad_norm": 1.3700672388076782,
      "learning_rate": 1.97599914282653e-05,
      "loss": 0.5489,
      "step": 1120
    },
    {
      "epoch": 0.12107575270545376,
      "grad_norm": 23.91288948059082,
      "learning_rate": 1.9757848494589094e-05,
      "loss": 0.3941,
      "step": 1130
    },
    {
      "epoch": 0.12214721954355513,
      "grad_norm": 18.081748962402344,
      "learning_rate": 1.9755705560912893e-05,
      "loss": 0.4735,
      "step": 1140
    },
    {
      "epoch": 0.12321868638165649,
      "grad_norm": 6.9278669357299805,
      "learning_rate": 1.975356262723669e-05,
      "loss": 0.2318,
      "step": 1150
    },
    {
      "epoch": 0.12429015321975785,
      "grad_norm": 11.584568977355957,
      "learning_rate": 1.9751419693560485e-05,
      "loss": 0.2205,
      "step": 1160
    },
    {
      "epoch": 0.1253616200578592,
      "grad_norm": 0.12871520221233368,
      "learning_rate": 1.9749276759884284e-05,
      "loss": 0.8292,
      "step": 1170
    },
    {
      "epoch": 0.12643308689596058,
      "grad_norm": 34.69547653198242,
      "learning_rate": 1.974713382620808e-05,
      "loss": 1.2719,
      "step": 1180
    },
    {
      "epoch": 0.12750455373406194,
      "grad_norm": 2.322920322418213,
      "learning_rate": 1.9744990892531875e-05,
      "loss": 0.888,
      "step": 1190
    },
    {
      "epoch": 0.1285760205721633,
      "grad_norm": 0.48819229006767273,
      "learning_rate": 1.9742847958855674e-05,
      "loss": 0.516,
      "step": 1200
    },
    {
      "epoch": 0.12964748741026466,
      "grad_norm": 24.581478118896484,
      "learning_rate": 1.9740705025179473e-05,
      "loss": 0.7129,
      "step": 1210
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 28.83682632446289,
      "learning_rate": 1.973856209150327e-05,
      "loss": 1.1586,
      "step": 1220
    },
    {
      "epoch": 0.13179042108646738,
      "grad_norm": 8.00069808959961,
      "learning_rate": 1.9736419157827068e-05,
      "loss": 1.2219,
      "step": 1230
    },
    {
      "epoch": 0.13286188792456874,
      "grad_norm": 6.722685813903809,
      "learning_rate": 1.9734276224150864e-05,
      "loss": 0.4998,
      "step": 1240
    },
    {
      "epoch": 0.1339333547626701,
      "grad_norm": 19.034879684448242,
      "learning_rate": 1.9732133290474663e-05,
      "loss": 0.9404,
      "step": 1250
    },
    {
      "epoch": 0.13500482160077146,
      "grad_norm": 4.886907577514648,
      "learning_rate": 1.9729990356798458e-05,
      "loss": 0.4386,
      "step": 1260
    },
    {
      "epoch": 0.13607628843887282,
      "grad_norm": 40.98508834838867,
      "learning_rate": 1.9727847423122254e-05,
      "loss": 1.1062,
      "step": 1270
    },
    {
      "epoch": 0.13714775527697418,
      "grad_norm": 3.162475824356079,
      "learning_rate": 1.9725704489446053e-05,
      "loss": 1.0024,
      "step": 1280
    },
    {
      "epoch": 0.13821922211507554,
      "grad_norm": 3.3680577278137207,
      "learning_rate": 1.972356155576985e-05,
      "loss": 0.8653,
      "step": 1290
    },
    {
      "epoch": 0.1392906889531769,
      "grad_norm": 1.4224666357040405,
      "learning_rate": 1.9721418622093648e-05,
      "loss": 0.6461,
      "step": 1300
    },
    {
      "epoch": 0.14036215579127825,
      "grad_norm": 17.07760238647461,
      "learning_rate": 1.9719275688417447e-05,
      "loss": 0.6148,
      "step": 1310
    },
    {
      "epoch": 0.1414336226293796,
      "grad_norm": 17.40933609008789,
      "learning_rate": 1.9717132754741242e-05,
      "loss": 1.3418,
      "step": 1320
    },
    {
      "epoch": 0.14250508946748097,
      "grad_norm": 2.8494672775268555,
      "learning_rate": 1.971498982106504e-05,
      "loss": 0.7041,
      "step": 1330
    },
    {
      "epoch": 0.14357655630558233,
      "grad_norm": 9.385058403015137,
      "learning_rate": 1.9712846887388837e-05,
      "loss": 0.674,
      "step": 1340
    },
    {
      "epoch": 0.1446480231436837,
      "grad_norm": 13.724782943725586,
      "learning_rate": 1.9710703953712633e-05,
      "loss": 0.3157,
      "step": 1350
    },
    {
      "epoch": 0.14571948998178508,
      "grad_norm": 0.6436024308204651,
      "learning_rate": 1.9708561020036432e-05,
      "loss": 0.6506,
      "step": 1360
    },
    {
      "epoch": 0.14679095681988644,
      "grad_norm": 0.43401533365249634,
      "learning_rate": 1.9706418086360228e-05,
      "loss": 1.0417,
      "step": 1370
    },
    {
      "epoch": 0.1478624236579878,
      "grad_norm": 0.48097506165504456,
      "learning_rate": 1.9704275152684027e-05,
      "loss": 0.7725,
      "step": 1380
    },
    {
      "epoch": 0.14893389049608916,
      "grad_norm": 17.64723777770996,
      "learning_rate": 1.9702132219007822e-05,
      "loss": 0.6593,
      "step": 1390
    },
    {
      "epoch": 0.15000535733419051,
      "grad_norm": 0.6986045837402344,
      "learning_rate": 1.969998928533162e-05,
      "loss": 0.937,
      "step": 1400
    },
    {
      "epoch": 0.15107682417229187,
      "grad_norm": 0.22952337563037872,
      "learning_rate": 1.9697846351655417e-05,
      "loss": 0.3501,
      "step": 1410
    },
    {
      "epoch": 0.15214829101039323,
      "grad_norm": 10.121223449707031,
      "learning_rate": 1.9695703417979216e-05,
      "loss": 0.4455,
      "step": 1420
    },
    {
      "epoch": 0.1532197578484946,
      "grad_norm": 0.35487961769104004,
      "learning_rate": 1.969356048430301e-05,
      "loss": 0.258,
      "step": 1430
    },
    {
      "epoch": 0.15429122468659595,
      "grad_norm": 0.17933200299739838,
      "learning_rate": 1.969141755062681e-05,
      "loss": 0.7525,
      "step": 1440
    },
    {
      "epoch": 0.1553626915246973,
      "grad_norm": 1.9496550559997559,
      "learning_rate": 1.9689274616950606e-05,
      "loss": 0.9521,
      "step": 1450
    },
    {
      "epoch": 0.15643415836279867,
      "grad_norm": 0.825351357460022,
      "learning_rate": 1.9687131683274405e-05,
      "loss": 1.1015,
      "step": 1460
    },
    {
      "epoch": 0.15750562520090003,
      "grad_norm": 3.52345609664917,
      "learning_rate": 1.96849887495982e-05,
      "loss": 0.4622,
      "step": 1470
    },
    {
      "epoch": 0.1585770920390014,
      "grad_norm": 0.44704410433769226,
      "learning_rate": 1.9682845815921997e-05,
      "loss": 0.9326,
      "step": 1480
    },
    {
      "epoch": 0.15964855887710275,
      "grad_norm": 0.6592519879341125,
      "learning_rate": 1.9680702882245796e-05,
      "loss": 0.7639,
      "step": 1490
    },
    {
      "epoch": 0.1607200257152041,
      "grad_norm": 21.68880844116211,
      "learning_rate": 1.9678559948569595e-05,
      "loss": 0.5572,
      "step": 1500
    },
    {
      "epoch": 0.16179149255330547,
      "grad_norm": 19.854190826416016,
      "learning_rate": 1.967641701489339e-05,
      "loss": 0.6427,
      "step": 1510
    },
    {
      "epoch": 0.16286295939140683,
      "grad_norm": 1.2140716314315796,
      "learning_rate": 1.967427408121719e-05,
      "loss": 0.7545,
      "step": 1520
    },
    {
      "epoch": 0.16393442622950818,
      "grad_norm": 3.4086005687713623,
      "learning_rate": 1.9672131147540985e-05,
      "loss": 0.569,
      "step": 1530
    },
    {
      "epoch": 0.16500589306760954,
      "grad_norm": 21.741119384765625,
      "learning_rate": 1.9669988213864784e-05,
      "loss": 0.7289,
      "step": 1540
    },
    {
      "epoch": 0.16607735990571093,
      "grad_norm": 3.6811327934265137,
      "learning_rate": 1.966784528018858e-05,
      "loss": 0.7087,
      "step": 1550
    },
    {
      "epoch": 0.1671488267438123,
      "grad_norm": 23.508718490600586,
      "learning_rate": 1.9665702346512376e-05,
      "loss": 0.2861,
      "step": 1560
    },
    {
      "epoch": 0.16822029358191365,
      "grad_norm": 16.531639099121094,
      "learning_rate": 1.9663559412836175e-05,
      "loss": 0.5338,
      "step": 1570
    },
    {
      "epoch": 0.169291760420015,
      "grad_norm": 48.72996139526367,
      "learning_rate": 1.966141647915997e-05,
      "loss": 0.8723,
      "step": 1580
    },
    {
      "epoch": 0.17036322725811637,
      "grad_norm": 43.19258117675781,
      "learning_rate": 1.965927354548377e-05,
      "loss": 0.4711,
      "step": 1590
    },
    {
      "epoch": 0.17143469409621773,
      "grad_norm": 3.448606252670288,
      "learning_rate": 1.9657130611807565e-05,
      "loss": 0.8132,
      "step": 1600
    },
    {
      "epoch": 0.17250616093431909,
      "grad_norm": 20.307069778442383,
      "learning_rate": 1.9654987678131364e-05,
      "loss": 0.55,
      "step": 1610
    },
    {
      "epoch": 0.17357762777242045,
      "grad_norm": 1.030131220817566,
      "learning_rate": 1.9652844744455163e-05,
      "loss": 0.1911,
      "step": 1620
    },
    {
      "epoch": 0.1746490946105218,
      "grad_norm": 0.20129860937595367,
      "learning_rate": 1.965070181077896e-05,
      "loss": 0.5844,
      "step": 1630
    },
    {
      "epoch": 0.17572056144862316,
      "grad_norm": 0.34812453389167786,
      "learning_rate": 1.9648558877102754e-05,
      "loss": 0.6909,
      "step": 1640
    },
    {
      "epoch": 0.17679202828672452,
      "grad_norm": 0.3244950473308563,
      "learning_rate": 1.9646415943426553e-05,
      "loss": 0.5067,
      "step": 1650
    },
    {
      "epoch": 0.17786349512482588,
      "grad_norm": 31.754592895507812,
      "learning_rate": 1.964427300975035e-05,
      "loss": 0.8778,
      "step": 1660
    },
    {
      "epoch": 0.17893496196292724,
      "grad_norm": 29.892505645751953,
      "learning_rate": 1.9642130076074145e-05,
      "loss": 1.1296,
      "step": 1670
    },
    {
      "epoch": 0.1800064288010286,
      "grad_norm": 0.707042396068573,
      "learning_rate": 1.9639987142397944e-05,
      "loss": 0.7797,
      "step": 1680
    },
    {
      "epoch": 0.18107789563912996,
      "grad_norm": 2.4251749515533447,
      "learning_rate": 1.9637844208721743e-05,
      "loss": 0.6052,
      "step": 1690
    },
    {
      "epoch": 0.18214936247723132,
      "grad_norm": 1.2826370000839233,
      "learning_rate": 1.963570127504554e-05,
      "loss": 1.0617,
      "step": 1700
    },
    {
      "epoch": 0.18322082931533268,
      "grad_norm": 0.6565564870834351,
      "learning_rate": 1.9633558341369338e-05,
      "loss": 0.6193,
      "step": 1710
    },
    {
      "epoch": 0.18429229615343404,
      "grad_norm": 0.41267454624176025,
      "learning_rate": 1.9631415407693133e-05,
      "loss": 0.6586,
      "step": 1720
    },
    {
      "epoch": 0.18536376299153542,
      "grad_norm": 0.25151169300079346,
      "learning_rate": 1.9629272474016932e-05,
      "loss": 0.2666,
      "step": 1730
    },
    {
      "epoch": 0.18643522982963678,
      "grad_norm": 13.332871437072754,
      "learning_rate": 1.9627129540340728e-05,
      "loss": 0.3902,
      "step": 1740
    },
    {
      "epoch": 0.18750669666773814,
      "grad_norm": 31.50068473815918,
      "learning_rate": 1.9624986606664524e-05,
      "loss": 0.9773,
      "step": 1750
    },
    {
      "epoch": 0.1885781635058395,
      "grad_norm": 0.35789555311203003,
      "learning_rate": 1.9622843672988323e-05,
      "loss": 0.4147,
      "step": 1760
    },
    {
      "epoch": 0.18964963034394086,
      "grad_norm": 15.649949073791504,
      "learning_rate": 1.962070073931212e-05,
      "loss": 0.4307,
      "step": 1770
    },
    {
      "epoch": 0.19072109718204222,
      "grad_norm": 10.317392349243164,
      "learning_rate": 1.9618557805635917e-05,
      "loss": 0.3126,
      "step": 1780
    },
    {
      "epoch": 0.19179256402014358,
      "grad_norm": 22.353281021118164,
      "learning_rate": 1.9616414871959713e-05,
      "loss": 0.3456,
      "step": 1790
    },
    {
      "epoch": 0.19286403085824494,
      "grad_norm": 35.853782653808594,
      "learning_rate": 1.9614271938283512e-05,
      "loss": 0.4675,
      "step": 1800
    },
    {
      "epoch": 0.1939354976963463,
      "grad_norm": 4.450577735900879,
      "learning_rate": 1.961212900460731e-05,
      "loss": 0.5166,
      "step": 1810
    },
    {
      "epoch": 0.19500696453444766,
      "grad_norm": 1.4729059934616089,
      "learning_rate": 1.9609986070931107e-05,
      "loss": 0.4106,
      "step": 1820
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.1718532294034958,
      "learning_rate": 1.9607843137254903e-05,
      "loss": 0.7341,
      "step": 1830
    },
    {
      "epoch": 0.19714989821065038,
      "grad_norm": 18.828542709350586,
      "learning_rate": 1.96057002035787e-05,
      "loss": 1.005,
      "step": 1840
    },
    {
      "epoch": 0.19822136504875174,
      "grad_norm": 32.2855339050293,
      "learning_rate": 1.9603557269902497e-05,
      "loss": 1.0299,
      "step": 1850
    },
    {
      "epoch": 0.1992928318868531,
      "grad_norm": 22.25824737548828,
      "learning_rate": 1.9601414336226293e-05,
      "loss": 0.377,
      "step": 1860
    },
    {
      "epoch": 0.20036429872495445,
      "grad_norm": 1.0066704750061035,
      "learning_rate": 1.9599271402550092e-05,
      "loss": 0.9556,
      "step": 1870
    },
    {
      "epoch": 0.2014357655630558,
      "grad_norm": 1.2428996562957764,
      "learning_rate": 1.959712846887389e-05,
      "loss": 0.4694,
      "step": 1880
    },
    {
      "epoch": 0.20250723240115717,
      "grad_norm": 0.5581093430519104,
      "learning_rate": 1.9594985535197687e-05,
      "loss": 0.6176,
      "step": 1890
    },
    {
      "epoch": 0.20357869923925853,
      "grad_norm": 12.756013870239258,
      "learning_rate": 1.9592842601521486e-05,
      "loss": 0.3072,
      "step": 1900
    },
    {
      "epoch": 0.20465016607735992,
      "grad_norm": 5.040177822113037,
      "learning_rate": 1.959069966784528e-05,
      "loss": 0.3145,
      "step": 1910
    },
    {
      "epoch": 0.20572163291546128,
      "grad_norm": 1.765443205833435,
      "learning_rate": 1.958855673416908e-05,
      "loss": 0.5924,
      "step": 1920
    },
    {
      "epoch": 0.20679309975356264,
      "grad_norm": 0.2523350417613983,
      "learning_rate": 1.9586413800492876e-05,
      "loss": 0.2554,
      "step": 1930
    },
    {
      "epoch": 0.207864566591664,
      "grad_norm": 19.03386878967285,
      "learning_rate": 1.9584270866816672e-05,
      "loss": 1.0218,
      "step": 1940
    },
    {
      "epoch": 0.20893603342976536,
      "grad_norm": 0.2508811950683594,
      "learning_rate": 1.958212793314047e-05,
      "loss": 0.516,
      "step": 1950
    },
    {
      "epoch": 0.21000750026786671,
      "grad_norm": 20.959794998168945,
      "learning_rate": 1.9579984999464266e-05,
      "loss": 0.7241,
      "step": 1960
    },
    {
      "epoch": 0.21107896710596807,
      "grad_norm": 2.977726697921753,
      "learning_rate": 1.9577842065788065e-05,
      "loss": 0.9982,
      "step": 1970
    },
    {
      "epoch": 0.21215043394406943,
      "grad_norm": 14.570174217224121,
      "learning_rate": 1.957569913211186e-05,
      "loss": 0.4561,
      "step": 1980
    },
    {
      "epoch": 0.2132219007821708,
      "grad_norm": 3.4005041122436523,
      "learning_rate": 1.957355619843566e-05,
      "loss": 0.6397,
      "step": 1990
    },
    {
      "epoch": 0.21429336762027215,
      "grad_norm": 15.460675239562988,
      "learning_rate": 1.957141326475946e-05,
      "loss": 0.2765,
      "step": 2000
    },
    {
      "epoch": 0.2153648344583735,
      "grad_norm": 26.21604347229004,
      "learning_rate": 1.9569270331083255e-05,
      "loss": 0.84,
      "step": 2010
    },
    {
      "epoch": 0.21643630129647487,
      "grad_norm": 17.15468406677246,
      "learning_rate": 1.956712739740705e-05,
      "loss": 0.2939,
      "step": 2020
    },
    {
      "epoch": 0.21750776813457623,
      "grad_norm": 0.330513060092926,
      "learning_rate": 1.956498446373085e-05,
      "loss": 0.222,
      "step": 2030
    },
    {
      "epoch": 0.2185792349726776,
      "grad_norm": 15.751435279846191,
      "learning_rate": 1.9562841530054645e-05,
      "loss": 0.6444,
      "step": 2040
    },
    {
      "epoch": 0.21965070181077895,
      "grad_norm": 4.618628978729248,
      "learning_rate": 1.9560698596378444e-05,
      "loss": 0.5942,
      "step": 2050
    },
    {
      "epoch": 0.2207221686488803,
      "grad_norm": 0.2588978409767151,
      "learning_rate": 1.955855566270224e-05,
      "loss": 0.3846,
      "step": 2060
    },
    {
      "epoch": 0.22179363548698167,
      "grad_norm": 4.320155620574951,
      "learning_rate": 1.955641272902604e-05,
      "loss": 0.8131,
      "step": 2070
    },
    {
      "epoch": 0.22286510232508303,
      "grad_norm": 6.722803592681885,
      "learning_rate": 1.9554269795349835e-05,
      "loss": 0.3932,
      "step": 2080
    },
    {
      "epoch": 0.2239365691631844,
      "grad_norm": 21.668128967285156,
      "learning_rate": 1.9552126861673634e-05,
      "loss": 0.8431,
      "step": 2090
    },
    {
      "epoch": 0.22500803600128577,
      "grad_norm": 59.635009765625,
      "learning_rate": 1.954998392799743e-05,
      "loss": 0.7965,
      "step": 2100
    },
    {
      "epoch": 0.22607950283938713,
      "grad_norm": 84.625732421875,
      "learning_rate": 1.954784099432123e-05,
      "loss": 0.7868,
      "step": 2110
    },
    {
      "epoch": 0.2271509696774885,
      "grad_norm": 15.922586441040039,
      "learning_rate": 1.9545698060645024e-05,
      "loss": 0.5108,
      "step": 2120
    },
    {
      "epoch": 0.22822243651558985,
      "grad_norm": 0.9468055963516235,
      "learning_rate": 1.9543555126968823e-05,
      "loss": 0.4211,
      "step": 2130
    },
    {
      "epoch": 0.2292939033536912,
      "grad_norm": 0.26466190814971924,
      "learning_rate": 1.954141219329262e-05,
      "loss": 0.3957,
      "step": 2140
    },
    {
      "epoch": 0.23036537019179257,
      "grad_norm": 0.21797342598438263,
      "learning_rate": 1.9539269259616414e-05,
      "loss": 0.5164,
      "step": 2150
    },
    {
      "epoch": 0.23143683702989393,
      "grad_norm": 0.13610930740833282,
      "learning_rate": 1.9537126325940214e-05,
      "loss": 0.4733,
      "step": 2160
    },
    {
      "epoch": 0.2325083038679953,
      "grad_norm": 21.750633239746094,
      "learning_rate": 1.953498339226401e-05,
      "loss": 0.9104,
      "step": 2170
    },
    {
      "epoch": 0.23357977070609665,
      "grad_norm": 19.7441463470459,
      "learning_rate": 1.9532840458587808e-05,
      "loss": 0.3241,
      "step": 2180
    },
    {
      "epoch": 0.234651237544198,
      "grad_norm": 0.19389189779758453,
      "learning_rate": 1.9530697524911607e-05,
      "loss": 0.3348,
      "step": 2190
    },
    {
      "epoch": 0.23572270438229936,
      "grad_norm": 14.882233619689941,
      "learning_rate": 1.9528554591235403e-05,
      "loss": 0.56,
      "step": 2200
    },
    {
      "epoch": 0.23679417122040072,
      "grad_norm": 20.127445220947266,
      "learning_rate": 1.9526411657559202e-05,
      "loss": 0.2462,
      "step": 2210
    },
    {
      "epoch": 0.23786563805850208,
      "grad_norm": 0.17357629537582397,
      "learning_rate": 1.9524268723882998e-05,
      "loss": 0.5213,
      "step": 2220
    },
    {
      "epoch": 0.23893710489660344,
      "grad_norm": 0.2174246609210968,
      "learning_rate": 1.9522125790206793e-05,
      "loss": 0.4414,
      "step": 2230
    },
    {
      "epoch": 0.2400085717347048,
      "grad_norm": 35.5059928894043,
      "learning_rate": 1.9519982856530592e-05,
      "loss": 0.7829,
      "step": 2240
    },
    {
      "epoch": 0.24108003857280616,
      "grad_norm": 9.236432075500488,
      "learning_rate": 1.9517839922854388e-05,
      "loss": 0.3311,
      "step": 2250
    },
    {
      "epoch": 0.24215150541090752,
      "grad_norm": 0.16307786107063293,
      "learning_rate": 1.9515696989178187e-05,
      "loss": 0.2328,
      "step": 2260
    },
    {
      "epoch": 0.2432229722490089,
      "grad_norm": 0.3826030194759369,
      "learning_rate": 1.9513554055501983e-05,
      "loss": 0.1808,
      "step": 2270
    },
    {
      "epoch": 0.24429443908711027,
      "grad_norm": 0.09932895749807358,
      "learning_rate": 1.9511411121825782e-05,
      "loss": 0.8443,
      "step": 2280
    },
    {
      "epoch": 0.24536590592521162,
      "grad_norm": 0.3945446312427521,
      "learning_rate": 1.950926818814958e-05,
      "loss": 1.101,
      "step": 2290
    },
    {
      "epoch": 0.24643737276331298,
      "grad_norm": 20.678112030029297,
      "learning_rate": 1.9507125254473377e-05,
      "loss": 0.8616,
      "step": 2300
    },
    {
      "epoch": 0.24750883960141434,
      "grad_norm": 17.769208908081055,
      "learning_rate": 1.9504982320797172e-05,
      "loss": 0.7161,
      "step": 2310
    },
    {
      "epoch": 0.2485803064395157,
      "grad_norm": 33.23187255859375,
      "learning_rate": 1.950283938712097e-05,
      "loss": 0.7911,
      "step": 2320
    },
    {
      "epoch": 0.24965177327761706,
      "grad_norm": 25.389062881469727,
      "learning_rate": 1.9500696453444767e-05,
      "loss": 0.8818,
      "step": 2330
    },
    {
      "epoch": 0.2507232401157184,
      "grad_norm": 0.2816806435585022,
      "learning_rate": 1.9498553519768563e-05,
      "loss": 0.1253,
      "step": 2340
    },
    {
      "epoch": 0.2517947069538198,
      "grad_norm": 20.500837326049805,
      "learning_rate": 1.949641058609236e-05,
      "loss": 0.7089,
      "step": 2350
    },
    {
      "epoch": 0.25286617379192117,
      "grad_norm": 1.2603427171707153,
      "learning_rate": 1.9494267652416157e-05,
      "loss": 0.3405,
      "step": 2360
    },
    {
      "epoch": 0.2539376406300225,
      "grad_norm": 2.3359382152557373,
      "learning_rate": 1.9492124718739956e-05,
      "loss": 0.2489,
      "step": 2370
    },
    {
      "epoch": 0.2550091074681239,
      "grad_norm": 15.25706672668457,
      "learning_rate": 1.9489981785063755e-05,
      "loss": 0.8009,
      "step": 2380
    },
    {
      "epoch": 0.2560805743062252,
      "grad_norm": 0.21921636164188385,
      "learning_rate": 1.948783885138755e-05,
      "loss": 0.5613,
      "step": 2390
    },
    {
      "epoch": 0.2571520411443266,
      "grad_norm": 0.27789726853370667,
      "learning_rate": 1.948569591771135e-05,
      "loss": 0.7477,
      "step": 2400
    },
    {
      "epoch": 0.25822350798242794,
      "grad_norm": 19.226783752441406,
      "learning_rate": 1.9483552984035146e-05,
      "loss": 1.0315,
      "step": 2410
    },
    {
      "epoch": 0.2592949748205293,
      "grad_norm": 0.27203378081321716,
      "learning_rate": 1.948141005035894e-05,
      "loss": 0.8817,
      "step": 2420
    },
    {
      "epoch": 0.26036644165863065,
      "grad_norm": 0.23625361919403076,
      "learning_rate": 1.947926711668274e-05,
      "loss": 0.4273,
      "step": 2430
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 25.56903648376465,
      "learning_rate": 1.9477124183006536e-05,
      "loss": 0.6068,
      "step": 2440
    },
    {
      "epoch": 0.2625093753348334,
      "grad_norm": 84.65306854248047,
      "learning_rate": 1.9474981249330335e-05,
      "loss": 0.8957,
      "step": 2450
    },
    {
      "epoch": 0.26358084217293476,
      "grad_norm": 5.894993305206299,
      "learning_rate": 1.947283831565413e-05,
      "loss": 1.0644,
      "step": 2460
    },
    {
      "epoch": 0.2646523090110361,
      "grad_norm": 0.6717324256896973,
      "learning_rate": 1.947069538197793e-05,
      "loss": 0.3395,
      "step": 2470
    },
    {
      "epoch": 0.2657237758491375,
      "grad_norm": 7.487875938415527,
      "learning_rate": 1.946855244830173e-05,
      "loss": 0.1165,
      "step": 2480
    },
    {
      "epoch": 0.2667952426872388,
      "grad_norm": 0.10950997471809387,
      "learning_rate": 1.9466409514625525e-05,
      "loss": 0.5546,
      "step": 2490
    },
    {
      "epoch": 0.2678667095253402,
      "grad_norm": 24.613672256469727,
      "learning_rate": 1.946426658094932e-05,
      "loss": 0.9611,
      "step": 2500
    },
    {
      "epoch": 0.26893817636344153,
      "grad_norm": 0.7459741234779358,
      "learning_rate": 1.946212364727312e-05,
      "loss": 0.5668,
      "step": 2510
    },
    {
      "epoch": 0.2700096432015429,
      "grad_norm": 0.72142094373703,
      "learning_rate": 1.9459980713596915e-05,
      "loss": 0.742,
      "step": 2520
    },
    {
      "epoch": 0.27108111003964425,
      "grad_norm": 0.9998233914375305,
      "learning_rate": 1.9457837779920714e-05,
      "loss": 0.8391,
      "step": 2530
    },
    {
      "epoch": 0.27215257687774563,
      "grad_norm": 30.24400520324707,
      "learning_rate": 1.945569484624451e-05,
      "loss": 0.7565,
      "step": 2540
    },
    {
      "epoch": 0.273224043715847,
      "grad_norm": 3.647763252258301,
      "learning_rate": 1.9453551912568305e-05,
      "loss": 0.6273,
      "step": 2550
    },
    {
      "epoch": 0.27429551055394835,
      "grad_norm": 1.1289899349212646,
      "learning_rate": 1.9451408978892104e-05,
      "loss": 0.6456,
      "step": 2560
    },
    {
      "epoch": 0.27536697739204974,
      "grad_norm": 25.605871200561523,
      "learning_rate": 1.9449266045215903e-05,
      "loss": 0.6124,
      "step": 2570
    },
    {
      "epoch": 0.27643844423015107,
      "grad_norm": 0.5590049028396606,
      "learning_rate": 1.94471231115397e-05,
      "loss": 0.3192,
      "step": 2580
    },
    {
      "epoch": 0.27750991106825246,
      "grad_norm": 19.770414352416992,
      "learning_rate": 1.9444980177863498e-05,
      "loss": 0.7288,
      "step": 2590
    },
    {
      "epoch": 0.2785813779063538,
      "grad_norm": 0.4625825881958008,
      "learning_rate": 1.9442837244187294e-05,
      "loss": 0.3117,
      "step": 2600
    },
    {
      "epoch": 0.2796528447444552,
      "grad_norm": 1.0045793056488037,
      "learning_rate": 1.9440694310511093e-05,
      "loss": 0.637,
      "step": 2610
    },
    {
      "epoch": 0.2807243115825565,
      "grad_norm": 20.857975006103516,
      "learning_rate": 1.943855137683489e-05,
      "loss": 0.5063,
      "step": 2620
    },
    {
      "epoch": 0.2817957784206579,
      "grad_norm": 0.35120680928230286,
      "learning_rate": 1.9436408443158684e-05,
      "loss": 0.6976,
      "step": 2630
    },
    {
      "epoch": 0.2828672452587592,
      "grad_norm": 1.0464773178100586,
      "learning_rate": 1.9434265509482483e-05,
      "loss": 0.2054,
      "step": 2640
    },
    {
      "epoch": 0.2839387120968606,
      "grad_norm": 0.21859249472618103,
      "learning_rate": 1.943212257580628e-05,
      "loss": 0.7698,
      "step": 2650
    },
    {
      "epoch": 0.28501017893496194,
      "grad_norm": 3.170762538909912,
      "learning_rate": 1.9429979642130078e-05,
      "loss": 0.909,
      "step": 2660
    },
    {
      "epoch": 0.28608164577306333,
      "grad_norm": 18.691513061523438,
      "learning_rate": 1.9427836708453877e-05,
      "loss": 0.7451,
      "step": 2670
    },
    {
      "epoch": 0.28715311261116466,
      "grad_norm": 17.085359573364258,
      "learning_rate": 1.9425693774777673e-05,
      "loss": 0.7714,
      "step": 2680
    },
    {
      "epoch": 0.28822457944926605,
      "grad_norm": 0.8205397725105286,
      "learning_rate": 1.9423550841101472e-05,
      "loss": 0.8302,
      "step": 2690
    },
    {
      "epoch": 0.2892960462873674,
      "grad_norm": 0.5334791541099548,
      "learning_rate": 1.9421407907425267e-05,
      "loss": 0.6376,
      "step": 2700
    },
    {
      "epoch": 0.29036751312546877,
      "grad_norm": 0.8245348334312439,
      "learning_rate": 1.9419264973749063e-05,
      "loss": 1.1921,
      "step": 2710
    },
    {
      "epoch": 0.29143897996357016,
      "grad_norm": 1.1283515691757202,
      "learning_rate": 1.9417122040072862e-05,
      "loss": 1.0911,
      "step": 2720
    },
    {
      "epoch": 0.2925104468016715,
      "grad_norm": 18.374589920043945,
      "learning_rate": 1.9414979106396658e-05,
      "loss": 0.4845,
      "step": 2730
    },
    {
      "epoch": 0.2935819136397729,
      "grad_norm": 3.6792972087860107,
      "learning_rate": 1.9412836172720453e-05,
      "loss": 0.5629,
      "step": 2740
    },
    {
      "epoch": 0.2946533804778742,
      "grad_norm": 0.22953739762306213,
      "learning_rate": 1.9410693239044252e-05,
      "loss": 0.4409,
      "step": 2750
    },
    {
      "epoch": 0.2957248473159756,
      "grad_norm": 40.023353576660156,
      "learning_rate": 1.940855030536805e-05,
      "loss": 0.7648,
      "step": 2760
    },
    {
      "epoch": 0.2967963141540769,
      "grad_norm": 0.45851370692253113,
      "learning_rate": 1.9406407371691847e-05,
      "loss": 1.0161,
      "step": 2770
    },
    {
      "epoch": 0.2978677809921783,
      "grad_norm": 0.7208998203277588,
      "learning_rate": 1.9404264438015646e-05,
      "loss": 0.494,
      "step": 2780
    },
    {
      "epoch": 0.29893924783027964,
      "grad_norm": 0.5106820464134216,
      "learning_rate": 1.9402121504339442e-05,
      "loss": 0.6294,
      "step": 2790
    },
    {
      "epoch": 0.30001071466838103,
      "grad_norm": 0.8225467801094055,
      "learning_rate": 1.939997857066324e-05,
      "loss": 0.6638,
      "step": 2800
    },
    {
      "epoch": 0.30108218150648236,
      "grad_norm": 15.660000801086426,
      "learning_rate": 1.9397835636987037e-05,
      "loss": 0.4631,
      "step": 2810
    },
    {
      "epoch": 0.30215364834458375,
      "grad_norm": 0.37813517451286316,
      "learning_rate": 1.9395692703310832e-05,
      "loss": 0.614,
      "step": 2820
    },
    {
      "epoch": 0.3032251151826851,
      "grad_norm": 9.999785423278809,
      "learning_rate": 1.939354976963463e-05,
      "loss": 0.617,
      "step": 2830
    },
    {
      "epoch": 0.30429658202078647,
      "grad_norm": 24.595849990844727,
      "learning_rate": 1.9391406835958427e-05,
      "loss": 0.6636,
      "step": 2840
    },
    {
      "epoch": 0.3053680488588878,
      "grad_norm": 11.998740196228027,
      "learning_rate": 1.9389263902282226e-05,
      "loss": 0.4109,
      "step": 2850
    },
    {
      "epoch": 0.3064395156969892,
      "grad_norm": 0.3738192617893219,
      "learning_rate": 1.9387120968606025e-05,
      "loss": 0.4055,
      "step": 2860
    },
    {
      "epoch": 0.3075109825350905,
      "grad_norm": 0.9218218922615051,
      "learning_rate": 1.938497803492982e-05,
      "loss": 0.7048,
      "step": 2870
    },
    {
      "epoch": 0.3085824493731919,
      "grad_norm": 0.2306479513645172,
      "learning_rate": 1.938283510125362e-05,
      "loss": 0.5162,
      "step": 2880
    },
    {
      "epoch": 0.30965391621129323,
      "grad_norm": 1.6485360860824585,
      "learning_rate": 1.9380692167577415e-05,
      "loss": 0.6741,
      "step": 2890
    },
    {
      "epoch": 0.3107253830493946,
      "grad_norm": 16.27330780029297,
      "learning_rate": 1.937854923390121e-05,
      "loss": 0.6122,
      "step": 2900
    },
    {
      "epoch": 0.311796849887496,
      "grad_norm": 18.940710067749023,
      "learning_rate": 1.937640630022501e-05,
      "loss": 0.5792,
      "step": 2910
    },
    {
      "epoch": 0.31286831672559734,
      "grad_norm": 2.774747133255005,
      "learning_rate": 1.9374263366548806e-05,
      "loss": 0.9004,
      "step": 2920
    },
    {
      "epoch": 0.3139397835636987,
      "grad_norm": 1.5193839073181152,
      "learning_rate": 1.93721204328726e-05,
      "loss": 0.2143,
      "step": 2930
    },
    {
      "epoch": 0.31501125040180006,
      "grad_norm": 0.18728068470954895,
      "learning_rate": 1.93699774991964e-05,
      "loss": 0.9529,
      "step": 2940
    },
    {
      "epoch": 0.31608271723990145,
      "grad_norm": 17.351133346557617,
      "learning_rate": 1.93678345655202e-05,
      "loss": 1.0091,
      "step": 2950
    },
    {
      "epoch": 0.3171541840780028,
      "grad_norm": 3.688192129135132,
      "learning_rate": 1.9365691631843995e-05,
      "loss": 0.2446,
      "step": 2960
    },
    {
      "epoch": 0.31822565091610416,
      "grad_norm": 20.367061614990234,
      "learning_rate": 1.9363548698167794e-05,
      "loss": 0.6074,
      "step": 2970
    },
    {
      "epoch": 0.3192971177542055,
      "grad_norm": 0.3502446413040161,
      "learning_rate": 1.936140576449159e-05,
      "loss": 0.7159,
      "step": 2980
    },
    {
      "epoch": 0.3203685845923069,
      "grad_norm": 52.742557525634766,
      "learning_rate": 1.935926283081539e-05,
      "loss": 0.5212,
      "step": 2990
    },
    {
      "epoch": 0.3214400514304082,
      "grad_norm": 0.17432564496994019,
      "learning_rate": 1.9357119897139185e-05,
      "loss": 0.1316,
      "step": 3000
    },
    {
      "epoch": 0.3225115182685096,
      "grad_norm": 0.7873790860176086,
      "learning_rate": 1.935497696346298e-05,
      "loss": 0.5015,
      "step": 3010
    },
    {
      "epoch": 0.32358298510661093,
      "grad_norm": 30.440832138061523,
      "learning_rate": 1.935283402978678e-05,
      "loss": 1.0395,
      "step": 3020
    },
    {
      "epoch": 0.3246544519447123,
      "grad_norm": 0.4980831742286682,
      "learning_rate": 1.9350691096110575e-05,
      "loss": 1.8805,
      "step": 3030
    },
    {
      "epoch": 0.32572591878281365,
      "grad_norm": 33.41138458251953,
      "learning_rate": 1.9348548162434374e-05,
      "loss": 1.1853,
      "step": 3040
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.8331435918807983,
      "learning_rate": 1.9346405228758173e-05,
      "loss": 0.2782,
      "step": 3050
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 16.735116958618164,
      "learning_rate": 1.934426229508197e-05,
      "loss": 0.5844,
      "step": 3060
    },
    {
      "epoch": 0.32894031929711776,
      "grad_norm": 25.95147705078125,
      "learning_rate": 1.9342119361405768e-05,
      "loss": 0.6378,
      "step": 3070
    },
    {
      "epoch": 0.3300117861352191,
      "grad_norm": 7.14222526550293,
      "learning_rate": 1.9339976427729564e-05,
      "loss": 0.6039,
      "step": 3080
    },
    {
      "epoch": 0.3310832529733205,
      "grad_norm": 0.38107559084892273,
      "learning_rate": 1.933783349405336e-05,
      "loss": 0.257,
      "step": 3090
    },
    {
      "epoch": 0.33215471981142186,
      "grad_norm": 43.25901794433594,
      "learning_rate": 1.9335690560377158e-05,
      "loss": 0.9325,
      "step": 3100
    },
    {
      "epoch": 0.3332261866495232,
      "grad_norm": 24.055131912231445,
      "learning_rate": 1.9333547626700954e-05,
      "loss": 0.7997,
      "step": 3110
    },
    {
      "epoch": 0.3342976534876246,
      "grad_norm": 6.901670932769775,
      "learning_rate": 1.9331404693024753e-05,
      "loss": 0.3893,
      "step": 3120
    },
    {
      "epoch": 0.3353691203257259,
      "grad_norm": 18.49974250793457,
      "learning_rate": 1.932926175934855e-05,
      "loss": 0.7428,
      "step": 3130
    },
    {
      "epoch": 0.3364405871638273,
      "grad_norm": 0.4840051829814911,
      "learning_rate": 1.9327118825672348e-05,
      "loss": 0.4731,
      "step": 3140
    },
    {
      "epoch": 0.33751205400192863,
      "grad_norm": 0.36902835965156555,
      "learning_rate": 1.9324975891996143e-05,
      "loss": 0.5457,
      "step": 3150
    },
    {
      "epoch": 0.33858352084003,
      "grad_norm": 0.21003098785877228,
      "learning_rate": 1.9322832958319942e-05,
      "loss": 0.6768,
      "step": 3160
    },
    {
      "epoch": 0.33965498767813135,
      "grad_norm": 16.552515029907227,
      "learning_rate": 1.9320690024643738e-05,
      "loss": 0.6485,
      "step": 3170
    },
    {
      "epoch": 0.34072645451623274,
      "grad_norm": 0.3814076781272888,
      "learning_rate": 1.9318547090967537e-05,
      "loss": 0.8663,
      "step": 3180
    },
    {
      "epoch": 0.34179792135433407,
      "grad_norm": 33.203311920166016,
      "learning_rate": 1.9316404157291333e-05,
      "loss": 0.6416,
      "step": 3190
    },
    {
      "epoch": 0.34286938819243545,
      "grad_norm": 0.5396640300750732,
      "learning_rate": 1.9314261223615132e-05,
      "loss": 0.2066,
      "step": 3200
    },
    {
      "epoch": 0.3439408550305368,
      "grad_norm": 0.10138972103595734,
      "learning_rate": 1.9312118289938927e-05,
      "loss": 0.4337,
      "step": 3210
    },
    {
      "epoch": 0.34501232186863817,
      "grad_norm": 17.881433486938477,
      "learning_rate": 1.9309975356262723e-05,
      "loss": 1.3257,
      "step": 3220
    },
    {
      "epoch": 0.3460837887067395,
      "grad_norm": 1.0329241752624512,
      "learning_rate": 1.9307832422586522e-05,
      "loss": 0.4653,
      "step": 3230
    },
    {
      "epoch": 0.3471552555448409,
      "grad_norm": 5.797713756561279,
      "learning_rate": 1.930568948891032e-05,
      "loss": 0.6002,
      "step": 3240
    },
    {
      "epoch": 0.3482267223829422,
      "grad_norm": 2.7269883155822754,
      "learning_rate": 1.9303546555234117e-05,
      "loss": 0.7847,
      "step": 3250
    },
    {
      "epoch": 0.3492981892210436,
      "grad_norm": 2.4826624393463135,
      "learning_rate": 1.9301403621557916e-05,
      "loss": 0.3383,
      "step": 3260
    },
    {
      "epoch": 0.350369656059145,
      "grad_norm": 16.663768768310547,
      "learning_rate": 1.929926068788171e-05,
      "loss": 0.2963,
      "step": 3270
    },
    {
      "epoch": 0.3514411228972463,
      "grad_norm": 16.82327651977539,
      "learning_rate": 1.929711775420551e-05,
      "loss": 0.7789,
      "step": 3280
    },
    {
      "epoch": 0.3525125897353477,
      "grad_norm": 42.983543395996094,
      "learning_rate": 1.9294974820529306e-05,
      "loss": 0.5744,
      "step": 3290
    },
    {
      "epoch": 0.35358405657344905,
      "grad_norm": 1.9448041915893555,
      "learning_rate": 1.9292831886853102e-05,
      "loss": 0.2253,
      "step": 3300
    },
    {
      "epoch": 0.35465552341155043,
      "grad_norm": 26.48689842224121,
      "learning_rate": 1.92906889531769e-05,
      "loss": 0.7983,
      "step": 3310
    },
    {
      "epoch": 0.35572699024965176,
      "grad_norm": 24.84064483642578,
      "learning_rate": 1.9288546019500697e-05,
      "loss": 0.4592,
      "step": 3320
    },
    {
      "epoch": 0.35679845708775315,
      "grad_norm": 25.322723388671875,
      "learning_rate": 1.9286403085824496e-05,
      "loss": 0.5728,
      "step": 3330
    },
    {
      "epoch": 0.3578699239258545,
      "grad_norm": 0.10671230405569077,
      "learning_rate": 1.928426015214829e-05,
      "loss": 0.1628,
      "step": 3340
    },
    {
      "epoch": 0.35894139076395587,
      "grad_norm": 0.25432446599006653,
      "learning_rate": 1.928211721847209e-05,
      "loss": 0.7402,
      "step": 3350
    },
    {
      "epoch": 0.3600128576020572,
      "grad_norm": 17.725553512573242,
      "learning_rate": 1.927997428479589e-05,
      "loss": 0.6357,
      "step": 3360
    },
    {
      "epoch": 0.3610843244401586,
      "grad_norm": 11.98232650756836,
      "learning_rate": 1.9277831351119685e-05,
      "loss": 0.5342,
      "step": 3370
    },
    {
      "epoch": 0.3621557912782599,
      "grad_norm": 1.2701671123504639,
      "learning_rate": 1.927568841744348e-05,
      "loss": 0.4436,
      "step": 3380
    },
    {
      "epoch": 0.3632272581163613,
      "grad_norm": 27.053625106811523,
      "learning_rate": 1.927354548376728e-05,
      "loss": 0.5115,
      "step": 3390
    },
    {
      "epoch": 0.36429872495446264,
      "grad_norm": 21.659408569335938,
      "learning_rate": 1.9271402550091076e-05,
      "loss": 0.6955,
      "step": 3400
    },
    {
      "epoch": 0.365370191792564,
      "grad_norm": 1.2624691724777222,
      "learning_rate": 1.926925961641487e-05,
      "loss": 0.539,
      "step": 3410
    },
    {
      "epoch": 0.36644165863066536,
      "grad_norm": 26.318096160888672,
      "learning_rate": 1.926711668273867e-05,
      "loss": 0.2861,
      "step": 3420
    },
    {
      "epoch": 0.36751312546876674,
      "grad_norm": 17.624801635742188,
      "learning_rate": 1.926497374906247e-05,
      "loss": 0.6108,
      "step": 3430
    },
    {
      "epoch": 0.3685845923068681,
      "grad_norm": 33.23411560058594,
      "learning_rate": 1.9262830815386265e-05,
      "loss": 1.2308,
      "step": 3440
    },
    {
      "epoch": 0.36965605914496946,
      "grad_norm": 49.439735412597656,
      "learning_rate": 1.9260687881710064e-05,
      "loss": 0.5091,
      "step": 3450
    },
    {
      "epoch": 0.37072752598307085,
      "grad_norm": 13.362154960632324,
      "learning_rate": 1.925854494803386e-05,
      "loss": 0.2456,
      "step": 3460
    },
    {
      "epoch": 0.3717989928211722,
      "grad_norm": 0.7002329230308533,
      "learning_rate": 1.925640201435766e-05,
      "loss": 0.7198,
      "step": 3470
    },
    {
      "epoch": 0.37287045965927357,
      "grad_norm": 18.282621383666992,
      "learning_rate": 1.9254259080681454e-05,
      "loss": 0.9665,
      "step": 3480
    },
    {
      "epoch": 0.3739419264973749,
      "grad_norm": 0.4000908434391022,
      "learning_rate": 1.925211614700525e-05,
      "loss": 0.6362,
      "step": 3490
    },
    {
      "epoch": 0.3750133933354763,
      "grad_norm": 0.27201545238494873,
      "learning_rate": 1.924997321332905e-05,
      "loss": 0.4763,
      "step": 3500
    },
    {
      "epoch": 0.3760848601735776,
      "grad_norm": 0.5053392052650452,
      "learning_rate": 1.9247830279652845e-05,
      "loss": 0.8605,
      "step": 3510
    },
    {
      "epoch": 0.377156327011679,
      "grad_norm": 29.033174514770508,
      "learning_rate": 1.9245687345976644e-05,
      "loss": 0.9044,
      "step": 3520
    },
    {
      "epoch": 0.37822779384978034,
      "grad_norm": 0.7782020568847656,
      "learning_rate": 1.924354441230044e-05,
      "loss": 0.5359,
      "step": 3530
    },
    {
      "epoch": 0.3792992606878817,
      "grad_norm": 0.3583342432975769,
      "learning_rate": 1.924140147862424e-05,
      "loss": 0.4849,
      "step": 3540
    },
    {
      "epoch": 0.38037072752598305,
      "grad_norm": 7.864875793457031,
      "learning_rate": 1.9239258544948038e-05,
      "loss": 0.0932,
      "step": 3550
    },
    {
      "epoch": 0.38144219436408444,
      "grad_norm": 32.7347526550293,
      "learning_rate": 1.9237115611271833e-05,
      "loss": 0.6675,
      "step": 3560
    },
    {
      "epoch": 0.3825136612021858,
      "grad_norm": 180.19110107421875,
      "learning_rate": 1.923497267759563e-05,
      "loss": 0.6431,
      "step": 3570
    },
    {
      "epoch": 0.38358512804028716,
      "grad_norm": 0.2430318146944046,
      "learning_rate": 1.9232829743919428e-05,
      "loss": 0.864,
      "step": 3580
    },
    {
      "epoch": 0.3846565948783885,
      "grad_norm": 22.2125301361084,
      "learning_rate": 1.9230686810243224e-05,
      "loss": 0.468,
      "step": 3590
    },
    {
      "epoch": 0.3857280617164899,
      "grad_norm": 0.521156370639801,
      "learning_rate": 1.9228543876567023e-05,
      "loss": 0.5767,
      "step": 3600
    },
    {
      "epoch": 0.3867995285545912,
      "grad_norm": 16.9774112701416,
      "learning_rate": 1.9226400942890818e-05,
      "loss": 0.8291,
      "step": 3610
    },
    {
      "epoch": 0.3878709953926926,
      "grad_norm": 0.48023849725723267,
      "learning_rate": 1.9224258009214617e-05,
      "loss": 0.5562,
      "step": 3620
    },
    {
      "epoch": 0.388942462230794,
      "grad_norm": 18.977676391601562,
      "learning_rate": 1.9222115075538413e-05,
      "loss": 0.6814,
      "step": 3630
    },
    {
      "epoch": 0.3900139290688953,
      "grad_norm": 7.255238056182861,
      "learning_rate": 1.9219972141862212e-05,
      "loss": 0.5656,
      "step": 3640
    },
    {
      "epoch": 0.3910853959069967,
      "grad_norm": 56.12782287597656,
      "learning_rate": 1.9217829208186008e-05,
      "loss": 0.6303,
      "step": 3650
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.6915789246559143,
      "learning_rate": 1.9215686274509807e-05,
      "loss": 0.4313,
      "step": 3660
    },
    {
      "epoch": 0.3932283295831994,
      "grad_norm": 0.3381451666355133,
      "learning_rate": 1.9213543340833602e-05,
      "loss": 0.5194,
      "step": 3670
    },
    {
      "epoch": 0.39429979642130075,
      "grad_norm": 0.40942469239234924,
      "learning_rate": 1.9211400407157398e-05,
      "loss": 0.7951,
      "step": 3680
    },
    {
      "epoch": 0.39537126325940214,
      "grad_norm": 0.3399551510810852,
      "learning_rate": 1.9209257473481197e-05,
      "loss": 0.2306,
      "step": 3690
    },
    {
      "epoch": 0.39644273009750347,
      "grad_norm": 0.28850257396698,
      "learning_rate": 1.9207114539804993e-05,
      "loss": 0.378,
      "step": 3700
    },
    {
      "epoch": 0.39751419693560486,
      "grad_norm": 0.584649920463562,
      "learning_rate": 1.9204971606128792e-05,
      "loss": 0.8764,
      "step": 3710
    },
    {
      "epoch": 0.3985856637737062,
      "grad_norm": 19.740877151489258,
      "learning_rate": 1.9202828672452588e-05,
      "loss": 0.8731,
      "step": 3720
    },
    {
      "epoch": 0.3996571306118076,
      "grad_norm": 5.41411018371582,
      "learning_rate": 1.9200685738776387e-05,
      "loss": 0.3814,
      "step": 3730
    },
    {
      "epoch": 0.4007285974499089,
      "grad_norm": 40.016929626464844,
      "learning_rate": 1.9198542805100186e-05,
      "loss": 0.8096,
      "step": 3740
    },
    {
      "epoch": 0.4018000642880103,
      "grad_norm": 44.124874114990234,
      "learning_rate": 1.919639987142398e-05,
      "loss": 0.5586,
      "step": 3750
    },
    {
      "epoch": 0.4028715311261116,
      "grad_norm": 18.462066650390625,
      "learning_rate": 1.9194256937747777e-05,
      "loss": 0.2244,
      "step": 3760
    },
    {
      "epoch": 0.403942997964213,
      "grad_norm": 0.2539020776748657,
      "learning_rate": 1.9192114004071576e-05,
      "loss": 0.7231,
      "step": 3770
    },
    {
      "epoch": 0.40501446480231434,
      "grad_norm": 0.312023401260376,
      "learning_rate": 1.918997107039537e-05,
      "loss": 0.4146,
      "step": 3780
    },
    {
      "epoch": 0.40608593164041573,
      "grad_norm": 18.232336044311523,
      "learning_rate": 1.918782813671917e-05,
      "loss": 0.4919,
      "step": 3790
    },
    {
      "epoch": 0.40715739847851706,
      "grad_norm": 0.627368688583374,
      "learning_rate": 1.9185685203042966e-05,
      "loss": 0.3733,
      "step": 3800
    },
    {
      "epoch": 0.40822886531661845,
      "grad_norm": 0.15852800011634827,
      "learning_rate": 1.9183542269366765e-05,
      "loss": 0.5896,
      "step": 3810
    },
    {
      "epoch": 0.40930033215471984,
      "grad_norm": 18.50898551940918,
      "learning_rate": 1.918139933569056e-05,
      "loss": 0.8534,
      "step": 3820
    },
    {
      "epoch": 0.41037179899282117,
      "grad_norm": 0.6750850081443787,
      "learning_rate": 1.917925640201436e-05,
      "loss": 0.6294,
      "step": 3830
    },
    {
      "epoch": 0.41144326583092256,
      "grad_norm": 50.20058822631836,
      "learning_rate": 1.9177113468338156e-05,
      "loss": 0.3034,
      "step": 3840
    },
    {
      "epoch": 0.4125147326690239,
      "grad_norm": 0.21262502670288086,
      "learning_rate": 1.9174970534661955e-05,
      "loss": 0.4456,
      "step": 3850
    },
    {
      "epoch": 0.4135861995071253,
      "grad_norm": 16.932973861694336,
      "learning_rate": 1.917282760098575e-05,
      "loss": 0.8234,
      "step": 3860
    },
    {
      "epoch": 0.4146576663452266,
      "grad_norm": 0.22709156572818756,
      "learning_rate": 1.917068466730955e-05,
      "loss": 0.0292,
      "step": 3870
    },
    {
      "epoch": 0.415729133183328,
      "grad_norm": 0.19619393348693848,
      "learning_rate": 1.9168541733633345e-05,
      "loss": 0.8234,
      "step": 3880
    },
    {
      "epoch": 0.4168006000214293,
      "grad_norm": 0.1450774222612381,
      "learning_rate": 1.916639879995714e-05,
      "loss": 1.1178,
      "step": 3890
    },
    {
      "epoch": 0.4178720668595307,
      "grad_norm": 17.266502380371094,
      "learning_rate": 1.916425586628094e-05,
      "loss": 0.8168,
      "step": 3900
    },
    {
      "epoch": 0.41894353369763204,
      "grad_norm": 0.4929223954677582,
      "learning_rate": 1.9162112932604736e-05,
      "loss": 0.8954,
      "step": 3910
    },
    {
      "epoch": 0.42001500053573343,
      "grad_norm": 17.183610916137695,
      "learning_rate": 1.9159969998928535e-05,
      "loss": 0.6336,
      "step": 3920
    },
    {
      "epoch": 0.42108646737383476,
      "grad_norm": 0.8096380829811096,
      "learning_rate": 1.9157827065252334e-05,
      "loss": 1.0843,
      "step": 3930
    },
    {
      "epoch": 0.42215793421193615,
      "grad_norm": 1.1875468492507935,
      "learning_rate": 1.915568413157613e-05,
      "loss": 0.4849,
      "step": 3940
    },
    {
      "epoch": 0.4232294010500375,
      "grad_norm": 0.626807689666748,
      "learning_rate": 1.915354119789993e-05,
      "loss": 0.7212,
      "step": 3950
    },
    {
      "epoch": 0.42430086788813887,
      "grad_norm": 635.1914672851562,
      "learning_rate": 1.9151398264223724e-05,
      "loss": 0.515,
      "step": 3960
    },
    {
      "epoch": 0.4253723347262402,
      "grad_norm": 17.45284080505371,
      "learning_rate": 1.914925533054752e-05,
      "loss": 0.7341,
      "step": 3970
    },
    {
      "epoch": 0.4264438015643416,
      "grad_norm": 0.834414541721344,
      "learning_rate": 1.914711239687132e-05,
      "loss": 0.4752,
      "step": 3980
    },
    {
      "epoch": 0.42751526840244297,
      "grad_norm": 19.497238159179688,
      "learning_rate": 1.9144969463195114e-05,
      "loss": 0.4226,
      "step": 3990
    },
    {
      "epoch": 0.4285867352405443,
      "grad_norm": 3.0844781398773193,
      "learning_rate": 1.9142826529518913e-05,
      "loss": 0.5943,
      "step": 4000
    },
    {
      "epoch": 0.4296582020786457,
      "grad_norm": 23.492494583129883,
      "learning_rate": 1.914068359584271e-05,
      "loss": 0.6825,
      "step": 4010
    },
    {
      "epoch": 0.430729668916747,
      "grad_norm": 0.7834962010383606,
      "learning_rate": 1.9138540662166508e-05,
      "loss": 0.1692,
      "step": 4020
    },
    {
      "epoch": 0.4318011357548484,
      "grad_norm": 34.4975471496582,
      "learning_rate": 1.9136397728490307e-05,
      "loss": 0.7886,
      "step": 4030
    },
    {
      "epoch": 0.43287260259294974,
      "grad_norm": 15.092284202575684,
      "learning_rate": 1.9134254794814103e-05,
      "loss": 0.9036,
      "step": 4040
    },
    {
      "epoch": 0.4339440694310511,
      "grad_norm": 20.48930549621582,
      "learning_rate": 1.91321118611379e-05,
      "loss": 0.9348,
      "step": 4050
    },
    {
      "epoch": 0.43501553626915246,
      "grad_norm": 18.15616798400879,
      "learning_rate": 1.9129968927461698e-05,
      "loss": 0.3295,
      "step": 4060
    },
    {
      "epoch": 0.43608700310725385,
      "grad_norm": 0.4495443105697632,
      "learning_rate": 1.9127825993785493e-05,
      "loss": 0.0819,
      "step": 4070
    },
    {
      "epoch": 0.4371584699453552,
      "grad_norm": 0.23937582969665527,
      "learning_rate": 1.912568306010929e-05,
      "loss": 0.3119,
      "step": 4080
    },
    {
      "epoch": 0.43822993678345656,
      "grad_norm": 98.2409439086914,
      "learning_rate": 1.9123540126433088e-05,
      "loss": 0.8359,
      "step": 4090
    },
    {
      "epoch": 0.4393014036215579,
      "grad_norm": 0.264615923166275,
      "learning_rate": 1.9121397192756887e-05,
      "loss": 0.5919,
      "step": 4100
    },
    {
      "epoch": 0.4403728704596593,
      "grad_norm": 18.557453155517578,
      "learning_rate": 1.9119254259080683e-05,
      "loss": 0.5423,
      "step": 4110
    },
    {
      "epoch": 0.4414443372977606,
      "grad_norm": 0.11300168186426163,
      "learning_rate": 1.9117111325404482e-05,
      "loss": 0.4006,
      "step": 4120
    },
    {
      "epoch": 0.442515804135862,
      "grad_norm": 0.11435682326555252,
      "learning_rate": 1.9114968391728277e-05,
      "loss": 0.7124,
      "step": 4130
    },
    {
      "epoch": 0.44358727097396333,
      "grad_norm": 16.420063018798828,
      "learning_rate": 1.9112825458052076e-05,
      "loss": 1.1467,
      "step": 4140
    },
    {
      "epoch": 0.4446587378120647,
      "grad_norm": 4.620307445526123,
      "learning_rate": 1.9110682524375872e-05,
      "loss": 0.9627,
      "step": 4150
    },
    {
      "epoch": 0.44573020465016605,
      "grad_norm": 0.23290623724460602,
      "learning_rate": 1.9108539590699668e-05,
      "loss": 0.2409,
      "step": 4160
    },
    {
      "epoch": 0.44680167148826744,
      "grad_norm": 0.21757632493972778,
      "learning_rate": 1.9106396657023467e-05,
      "loss": 0.5079,
      "step": 4170
    },
    {
      "epoch": 0.4478731383263688,
      "grad_norm": 0.39567577838897705,
      "learning_rate": 1.9104253723347262e-05,
      "loss": 0.3021,
      "step": 4180
    },
    {
      "epoch": 0.44894460516447016,
      "grad_norm": 0.13218872249126434,
      "learning_rate": 1.910211078967106e-05,
      "loss": 0.4178,
      "step": 4190
    },
    {
      "epoch": 0.45001607200257154,
      "grad_norm": 15.684887886047363,
      "learning_rate": 1.9099967855994857e-05,
      "loss": 0.6818,
      "step": 4200
    },
    {
      "epoch": 0.4510875388406729,
      "grad_norm": 51.97127151489258,
      "learning_rate": 1.9097824922318656e-05,
      "loss": 0.27,
      "step": 4210
    },
    {
      "epoch": 0.45215900567877426,
      "grad_norm": 0.18186873197555542,
      "learning_rate": 1.9095681988642455e-05,
      "loss": 0.4433,
      "step": 4220
    },
    {
      "epoch": 0.4532304725168756,
      "grad_norm": 14.634771347045898,
      "learning_rate": 1.909353905496625e-05,
      "loss": 0.3716,
      "step": 4230
    },
    {
      "epoch": 0.454301939354977,
      "grad_norm": 0.17030729353427887,
      "learning_rate": 1.9091396121290047e-05,
      "loss": 0.4062,
      "step": 4240
    },
    {
      "epoch": 0.4553734061930783,
      "grad_norm": 0.44122716784477234,
      "learning_rate": 1.9089253187613846e-05,
      "loss": 0.2381,
      "step": 4250
    },
    {
      "epoch": 0.4564448730311797,
      "grad_norm": 30.241390228271484,
      "learning_rate": 1.908711025393764e-05,
      "loss": 0.6187,
      "step": 4260
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 1.6985992193222046,
      "learning_rate": 1.908496732026144e-05,
      "loss": 0.3725,
      "step": 4270
    },
    {
      "epoch": 0.4585878067073824,
      "grad_norm": 0.06557556986808777,
      "learning_rate": 1.9082824386585236e-05,
      "loss": 0.6874,
      "step": 4280
    },
    {
      "epoch": 0.45965927354548375,
      "grad_norm": 0.11919618397951126,
      "learning_rate": 1.9080681452909035e-05,
      "loss": 0.7417,
      "step": 4290
    },
    {
      "epoch": 0.46073074038358514,
      "grad_norm": 3.197087287902832,
      "learning_rate": 1.907853851923283e-05,
      "loss": 0.6685,
      "step": 4300
    },
    {
      "epoch": 0.46180220722168647,
      "grad_norm": 0.7307232022285461,
      "learning_rate": 1.907639558555663e-05,
      "loss": 0.8647,
      "step": 4310
    },
    {
      "epoch": 0.46287367405978785,
      "grad_norm": 7.552124977111816,
      "learning_rate": 1.9074252651880425e-05,
      "loss": 0.5104,
      "step": 4320
    },
    {
      "epoch": 0.4639451408978892,
      "grad_norm": 1.8944005966186523,
      "learning_rate": 1.9072109718204225e-05,
      "loss": 0.4019,
      "step": 4330
    },
    {
      "epoch": 0.4650166077359906,
      "grad_norm": 0.7286282777786255,
      "learning_rate": 1.906996678452802e-05,
      "loss": 0.2615,
      "step": 4340
    },
    {
      "epoch": 0.46608807457409196,
      "grad_norm": 0.11618503928184509,
      "learning_rate": 1.906782385085182e-05,
      "loss": 0.332,
      "step": 4350
    },
    {
      "epoch": 0.4671595414121933,
      "grad_norm": 0.11598870158195496,
      "learning_rate": 1.9065680917175615e-05,
      "loss": 0.6126,
      "step": 4360
    },
    {
      "epoch": 0.4682310082502947,
      "grad_norm": 18.636280059814453,
      "learning_rate": 1.906353798349941e-05,
      "loss": 0.5442,
      "step": 4370
    },
    {
      "epoch": 0.469302475088396,
      "grad_norm": 3.496091604232788,
      "learning_rate": 1.906139504982321e-05,
      "loss": 0.8653,
      "step": 4380
    },
    {
      "epoch": 0.4703739419264974,
      "grad_norm": 0.23012852668762207,
      "learning_rate": 1.9059252116147005e-05,
      "loss": 0.9498,
      "step": 4390
    },
    {
      "epoch": 0.47144540876459873,
      "grad_norm": 0.7611396312713623,
      "learning_rate": 1.9057109182470804e-05,
      "loss": 0.6553,
      "step": 4400
    },
    {
      "epoch": 0.4725168756027001,
      "grad_norm": 19.66292953491211,
      "learning_rate": 1.9054966248794603e-05,
      "loss": 0.8569,
      "step": 4410
    },
    {
      "epoch": 0.47358834244080145,
      "grad_norm": 17.76478385925293,
      "learning_rate": 1.90528233151184e-05,
      "loss": 0.7516,
      "step": 4420
    },
    {
      "epoch": 0.47465980927890283,
      "grad_norm": 44.347904205322266,
      "learning_rate": 1.9050680381442198e-05,
      "loss": 0.6756,
      "step": 4430
    },
    {
      "epoch": 0.47573127611700416,
      "grad_norm": 22.624982833862305,
      "learning_rate": 1.9048537447765994e-05,
      "loss": 0.6651,
      "step": 4440
    },
    {
      "epoch": 0.47680274295510555,
      "grad_norm": 0.09768473356962204,
      "learning_rate": 1.904639451408979e-05,
      "loss": 0.2246,
      "step": 4450
    },
    {
      "epoch": 0.4778742097932069,
      "grad_norm": 0.15500383079051971,
      "learning_rate": 1.904425158041359e-05,
      "loss": 0.5828,
      "step": 4460
    },
    {
      "epoch": 0.47894567663130827,
      "grad_norm": 20.48565101623535,
      "learning_rate": 1.9042108646737384e-05,
      "loss": 0.5941,
      "step": 4470
    },
    {
      "epoch": 0.4800171434694096,
      "grad_norm": 25.12305450439453,
      "learning_rate": 1.9039965713061183e-05,
      "loss": 0.8528,
      "step": 4480
    },
    {
      "epoch": 0.481088610307511,
      "grad_norm": 0.9640703797340393,
      "learning_rate": 1.903782277938498e-05,
      "loss": 0.5847,
      "step": 4490
    },
    {
      "epoch": 0.4821600771456123,
      "grad_norm": 18.072118759155273,
      "learning_rate": 1.9035679845708778e-05,
      "loss": 0.5905,
      "step": 4500
    },
    {
      "epoch": 0.4832315439837137,
      "grad_norm": 16.256946563720703,
      "learning_rate": 1.9033536912032577e-05,
      "loss": 0.5248,
      "step": 4510
    },
    {
      "epoch": 0.48430301082181504,
      "grad_norm": 31.255945205688477,
      "learning_rate": 1.9031393978356373e-05,
      "loss": 0.7522,
      "step": 4520
    },
    {
      "epoch": 0.4853744776599164,
      "grad_norm": 2.524057388305664,
      "learning_rate": 1.9029251044680168e-05,
      "loss": 0.4052,
      "step": 4530
    },
    {
      "epoch": 0.4864459444980178,
      "grad_norm": 0.4910385310649872,
      "learning_rate": 1.9027108111003967e-05,
      "loss": 0.6659,
      "step": 4540
    },
    {
      "epoch": 0.48751741133611914,
      "grad_norm": 0.36910274624824524,
      "learning_rate": 1.9024965177327763e-05,
      "loss": 0.6354,
      "step": 4550
    },
    {
      "epoch": 0.48858887817422053,
      "grad_norm": 0.28212931752204895,
      "learning_rate": 1.902282224365156e-05,
      "loss": 0.0044,
      "step": 4560
    },
    {
      "epoch": 0.48966034501232186,
      "grad_norm": 0.15724244713783264,
      "learning_rate": 1.9020679309975358e-05,
      "loss": 0.5935,
      "step": 4570
    },
    {
      "epoch": 0.49073181185042325,
      "grad_norm": 21.49443244934082,
      "learning_rate": 1.9018536376299153e-05,
      "loss": 0.642,
      "step": 4580
    },
    {
      "epoch": 0.4918032786885246,
      "grad_norm": 0.4516660273075104,
      "learning_rate": 1.9016393442622952e-05,
      "loss": 0.3172,
      "step": 4590
    },
    {
      "epoch": 0.49287474552662597,
      "grad_norm": 30.728046417236328,
      "learning_rate": 1.901425050894675e-05,
      "loss": 0.3198,
      "step": 4600
    },
    {
      "epoch": 0.4939462123647273,
      "grad_norm": 0.101392462849617,
      "learning_rate": 1.9012107575270547e-05,
      "loss": 0.6551,
      "step": 4610
    },
    {
      "epoch": 0.4950176792028287,
      "grad_norm": 46.71123123168945,
      "learning_rate": 1.9009964641594346e-05,
      "loss": 1.1783,
      "step": 4620
    },
    {
      "epoch": 0.49608914604093,
      "grad_norm": 0.9001041054725647,
      "learning_rate": 1.9007821707918142e-05,
      "loss": 0.8359,
      "step": 4630
    },
    {
      "epoch": 0.4971606128790314,
      "grad_norm": 15.430377006530762,
      "learning_rate": 1.9005678774241937e-05,
      "loss": 0.447,
      "step": 4640
    },
    {
      "epoch": 0.49823207971713274,
      "grad_norm": 28.359424591064453,
      "learning_rate": 1.9003535840565737e-05,
      "loss": 0.54,
      "step": 4650
    },
    {
      "epoch": 0.4993035465552341,
      "grad_norm": 21.156461715698242,
      "learning_rate": 1.9001392906889532e-05,
      "loss": 0.587,
      "step": 4660
    },
    {
      "epoch": 0.5003750133933355,
      "grad_norm": 21.897214889526367,
      "learning_rate": 1.899924997321333e-05,
      "loss": 0.7539,
      "step": 4670
    },
    {
      "epoch": 0.5014464802314368,
      "grad_norm": 16.658702850341797,
      "learning_rate": 1.8997107039537127e-05,
      "loss": 0.7995,
      "step": 4680
    },
    {
      "epoch": 0.5025179470695382,
      "grad_norm": 17.543310165405273,
      "learning_rate": 1.8994964105860926e-05,
      "loss": 0.5805,
      "step": 4690
    },
    {
      "epoch": 0.5035894139076396,
      "grad_norm": 4.555885314941406,
      "learning_rate": 1.8992821172184725e-05,
      "loss": 0.4701,
      "step": 4700
    },
    {
      "epoch": 0.5046608807457409,
      "grad_norm": 15.114516258239746,
      "learning_rate": 1.899067823850852e-05,
      "loss": 0.3877,
      "step": 4710
    },
    {
      "epoch": 0.5057323475838423,
      "grad_norm": 0.3318841755390167,
      "learning_rate": 1.8988535304832316e-05,
      "loss": 0.4826,
      "step": 4720
    },
    {
      "epoch": 0.5068038144219437,
      "grad_norm": 19.4506778717041,
      "learning_rate": 1.8986392371156115e-05,
      "loss": 0.9787,
      "step": 4730
    },
    {
      "epoch": 0.507875281260045,
      "grad_norm": 1.1967979669570923,
      "learning_rate": 1.898424943747991e-05,
      "loss": 0.6528,
      "step": 4740
    },
    {
      "epoch": 0.5089467480981463,
      "grad_norm": 9.129304885864258,
      "learning_rate": 1.8982106503803707e-05,
      "loss": 0.6289,
      "step": 4750
    },
    {
      "epoch": 0.5100182149362478,
      "grad_norm": 0.4986326992511749,
      "learning_rate": 1.8979963570127506e-05,
      "loss": 0.1457,
      "step": 4760
    },
    {
      "epoch": 0.5110896817743491,
      "grad_norm": 0.12559308111667633,
      "learning_rate": 1.89778206364513e-05,
      "loss": 0.3701,
      "step": 4770
    },
    {
      "epoch": 0.5121611486124504,
      "grad_norm": 0.12429472804069519,
      "learning_rate": 1.89756777027751e-05,
      "loss": 0.5973,
      "step": 4780
    },
    {
      "epoch": 0.5132326154505518,
      "grad_norm": 0.11851760745048523,
      "learning_rate": 1.89735347690989e-05,
      "loss": 0.2354,
      "step": 4790
    },
    {
      "epoch": 0.5143040822886532,
      "grad_norm": 0.0776229053735733,
      "learning_rate": 1.8971391835422695e-05,
      "loss": 0.6877,
      "step": 4800
    },
    {
      "epoch": 0.5153755491267545,
      "grad_norm": 16.468547821044922,
      "learning_rate": 1.8969248901746494e-05,
      "loss": 0.8992,
      "step": 4810
    },
    {
      "epoch": 0.5164470159648559,
      "grad_norm": 0.723456621170044,
      "learning_rate": 1.896710596807029e-05,
      "loss": 0.4565,
      "step": 4820
    },
    {
      "epoch": 0.5175184828029572,
      "grad_norm": 18.299331665039062,
      "learning_rate": 1.8964963034394086e-05,
      "loss": 0.3504,
      "step": 4830
    },
    {
      "epoch": 0.5185899496410586,
      "grad_norm": 0.1588297337293625,
      "learning_rate": 1.8962820100717885e-05,
      "loss": 0.4366,
      "step": 4840
    },
    {
      "epoch": 0.51966141647916,
      "grad_norm": 17.8632869720459,
      "learning_rate": 1.896067716704168e-05,
      "loss": 0.8236,
      "step": 4850
    },
    {
      "epoch": 0.5207328833172613,
      "grad_norm": 0.22543387115001678,
      "learning_rate": 1.895853423336548e-05,
      "loss": 0.5711,
      "step": 4860
    },
    {
      "epoch": 0.5218043501553626,
      "grad_norm": 30.374340057373047,
      "learning_rate": 1.8956391299689275e-05,
      "loss": 0.6532,
      "step": 4870
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 22.974943161010742,
      "learning_rate": 1.8954248366013074e-05,
      "loss": 0.9071,
      "step": 4880
    },
    {
      "epoch": 0.5239472838315654,
      "grad_norm": 19.12775993347168,
      "learning_rate": 1.8952105432336873e-05,
      "loss": 0.7558,
      "step": 4890
    },
    {
      "epoch": 0.5250187506696667,
      "grad_norm": 0.24689824879169464,
      "learning_rate": 1.894996249866067e-05,
      "loss": 0.1784,
      "step": 4900
    },
    {
      "epoch": 0.5260902175077682,
      "grad_norm": 15.442098617553711,
      "learning_rate": 1.8947819564984464e-05,
      "loss": 0.3843,
      "step": 4910
    },
    {
      "epoch": 0.5271616843458695,
      "grad_norm": 1.2286518812179565,
      "learning_rate": 1.8945676631308263e-05,
      "loss": 0.4131,
      "step": 4920
    },
    {
      "epoch": 0.5282331511839709,
      "grad_norm": 19.746021270751953,
      "learning_rate": 1.894353369763206e-05,
      "loss": 0.4502,
      "step": 4930
    },
    {
      "epoch": 0.5293046180220722,
      "grad_norm": 27.929718017578125,
      "learning_rate": 1.8941390763955858e-05,
      "loss": 0.5733,
      "step": 4940
    },
    {
      "epoch": 0.5303760848601736,
      "grad_norm": 0.21908606588840485,
      "learning_rate": 1.8939247830279654e-05,
      "loss": 0.3733,
      "step": 4950
    },
    {
      "epoch": 0.531447551698275,
      "grad_norm": 0.6237192153930664,
      "learning_rate": 1.893710489660345e-05,
      "loss": 0.2475,
      "step": 4960
    },
    {
      "epoch": 0.5325190185363763,
      "grad_norm": 100.64107513427734,
      "learning_rate": 1.893496196292725e-05,
      "loss": 0.4886,
      "step": 4970
    },
    {
      "epoch": 0.5335904853744776,
      "grad_norm": 32.05891418457031,
      "learning_rate": 1.8932819029251048e-05,
      "loss": 0.6518,
      "step": 4980
    },
    {
      "epoch": 0.5346619522125791,
      "grad_norm": 3.759110450744629,
      "learning_rate": 1.8930676095574843e-05,
      "loss": 0.5011,
      "step": 4990
    },
    {
      "epoch": 0.5357334190506804,
      "grad_norm": 0.08523107320070267,
      "learning_rate": 1.8928533161898642e-05,
      "loss": 0.3997,
      "step": 5000
    },
    {
      "epoch": 0.5368048858887817,
      "grad_norm": 29.10572624206543,
      "learning_rate": 1.8926390228222438e-05,
      "loss": 0.6964,
      "step": 5010
    },
    {
      "epoch": 0.5378763527268831,
      "grad_norm": 0.2527819871902466,
      "learning_rate": 1.8924247294546237e-05,
      "loss": 0.3586,
      "step": 5020
    },
    {
      "epoch": 0.5389478195649845,
      "grad_norm": 0.20879501104354858,
      "learning_rate": 1.8922104360870033e-05,
      "loss": 0.6717,
      "step": 5030
    },
    {
      "epoch": 0.5400192864030858,
      "grad_norm": 0.2647586762905121,
      "learning_rate": 1.8919961427193828e-05,
      "loss": 0.4983,
      "step": 5040
    },
    {
      "epoch": 0.5410907532411872,
      "grad_norm": 0.16855667531490326,
      "learning_rate": 1.8917818493517627e-05,
      "loss": 0.5851,
      "step": 5050
    },
    {
      "epoch": 0.5421622200792885,
      "grad_norm": 16.423946380615234,
      "learning_rate": 1.8915675559841423e-05,
      "loss": 0.5436,
      "step": 5060
    },
    {
      "epoch": 0.5432336869173899,
      "grad_norm": 21.348007202148438,
      "learning_rate": 1.8913532626165222e-05,
      "loss": 0.2052,
      "step": 5070
    },
    {
      "epoch": 0.5443051537554913,
      "grad_norm": 92.6854476928711,
      "learning_rate": 1.891138969248902e-05,
      "loss": 0.7107,
      "step": 5080
    },
    {
      "epoch": 0.5453766205935926,
      "grad_norm": 21.603635787963867,
      "learning_rate": 1.8909246758812817e-05,
      "loss": 0.8085,
      "step": 5090
    },
    {
      "epoch": 0.546448087431694,
      "grad_norm": 20.871814727783203,
      "learning_rate": 1.8907103825136616e-05,
      "loss": 0.6298,
      "step": 5100
    },
    {
      "epoch": 0.5475195542697954,
      "grad_norm": 8.801783561706543,
      "learning_rate": 1.890496089146041e-05,
      "loss": 0.578,
      "step": 5110
    },
    {
      "epoch": 0.5485910211078967,
      "grad_norm": 1.6202476024627686,
      "learning_rate": 1.8902817957784207e-05,
      "loss": 0.7772,
      "step": 5120
    },
    {
      "epoch": 0.549662487945998,
      "grad_norm": 3.4026036262512207,
      "learning_rate": 1.8900675024108006e-05,
      "loss": 0.6431,
      "step": 5130
    },
    {
      "epoch": 0.5507339547840995,
      "grad_norm": 0.24782942235469818,
      "learning_rate": 1.8898532090431802e-05,
      "loss": 0.7,
      "step": 5140
    },
    {
      "epoch": 0.5518054216222008,
      "grad_norm": 21.317527770996094,
      "learning_rate": 1.8896389156755598e-05,
      "loss": 0.5277,
      "step": 5150
    },
    {
      "epoch": 0.5528768884603021,
      "grad_norm": 0.16386505961418152,
      "learning_rate": 1.8894246223079397e-05,
      "loss": 0.3116,
      "step": 5160
    },
    {
      "epoch": 0.5539483552984035,
      "grad_norm": 18.892784118652344,
      "learning_rate": 1.8892103289403196e-05,
      "loss": 0.6877,
      "step": 5170
    },
    {
      "epoch": 0.5550198221365049,
      "grad_norm": 0.21733208000659943,
      "learning_rate": 1.888996035572699e-05,
      "loss": 0.1867,
      "step": 5180
    },
    {
      "epoch": 0.5560912889746062,
      "grad_norm": 0.1494804322719574,
      "learning_rate": 1.888781742205079e-05,
      "loss": 0.9633,
      "step": 5190
    },
    {
      "epoch": 0.5571627558127076,
      "grad_norm": 29.326343536376953,
      "learning_rate": 1.8885674488374586e-05,
      "loss": 0.9159,
      "step": 5200
    },
    {
      "epoch": 0.5582342226508089,
      "grad_norm": 30.520118713378906,
      "learning_rate": 1.8883531554698385e-05,
      "loss": 0.8501,
      "step": 5210
    },
    {
      "epoch": 0.5593056894889104,
      "grad_norm": 20.24488639831543,
      "learning_rate": 1.888138862102218e-05,
      "loss": 0.5306,
      "step": 5220
    },
    {
      "epoch": 0.5603771563270117,
      "grad_norm": 14.410759925842285,
      "learning_rate": 1.8879245687345976e-05,
      "loss": 0.8662,
      "step": 5230
    },
    {
      "epoch": 0.561448623165113,
      "grad_norm": 16.086698532104492,
      "learning_rate": 1.8877102753669775e-05,
      "loss": 0.7808,
      "step": 5240
    },
    {
      "epoch": 0.5625200900032143,
      "grad_norm": 29.068981170654297,
      "learning_rate": 1.887495981999357e-05,
      "loss": 0.6976,
      "step": 5250
    },
    {
      "epoch": 0.5635915568413158,
      "grad_norm": 16.48798370361328,
      "learning_rate": 1.887281688631737e-05,
      "loss": 0.535,
      "step": 5260
    },
    {
      "epoch": 0.5646630236794171,
      "grad_norm": 16.49225425720215,
      "learning_rate": 1.887067395264117e-05,
      "loss": 0.5738,
      "step": 5270
    },
    {
      "epoch": 0.5657344905175185,
      "grad_norm": 0.39701783657073975,
      "learning_rate": 1.8868531018964965e-05,
      "loss": 0.3587,
      "step": 5280
    },
    {
      "epoch": 0.5668059573556199,
      "grad_norm": 0.5094366073608398,
      "learning_rate": 1.8866388085288764e-05,
      "loss": 0.2747,
      "step": 5290
    },
    {
      "epoch": 0.5678774241937212,
      "grad_norm": 0.16722072660923004,
      "learning_rate": 1.886424515161256e-05,
      "loss": 0.7451,
      "step": 5300
    },
    {
      "epoch": 0.5689488910318226,
      "grad_norm": 31.192584991455078,
      "learning_rate": 1.8862102217936355e-05,
      "loss": 0.6018,
      "step": 5310
    },
    {
      "epoch": 0.5700203578699239,
      "grad_norm": 28.439599990844727,
      "learning_rate": 1.8859959284260154e-05,
      "loss": 0.7174,
      "step": 5320
    },
    {
      "epoch": 0.5710918247080253,
      "grad_norm": 0.7478335499763489,
      "learning_rate": 1.885781635058395e-05,
      "loss": 0.5649,
      "step": 5330
    },
    {
      "epoch": 0.5721632915461267,
      "grad_norm": 3.943293809890747,
      "learning_rate": 1.885567341690775e-05,
      "loss": 0.6799,
      "step": 5340
    },
    {
      "epoch": 0.573234758384228,
      "grad_norm": 0.39195263385772705,
      "learning_rate": 1.8853530483231545e-05,
      "loss": 0.4503,
      "step": 5350
    },
    {
      "epoch": 0.5743062252223293,
      "grad_norm": 39.49835968017578,
      "learning_rate": 1.8851387549555344e-05,
      "loss": 0.4791,
      "step": 5360
    },
    {
      "epoch": 0.5753776920604308,
      "grad_norm": 3.438701868057251,
      "learning_rate": 1.884924461587914e-05,
      "loss": 0.7645,
      "step": 5370
    },
    {
      "epoch": 0.5764491588985321,
      "grad_norm": 0.15152429044246674,
      "learning_rate": 1.884710168220294e-05,
      "loss": 0.378,
      "step": 5380
    },
    {
      "epoch": 0.5775206257366334,
      "grad_norm": 12.58917236328125,
      "learning_rate": 1.8844958748526734e-05,
      "loss": 0.8395,
      "step": 5390
    },
    {
      "epoch": 0.5785920925747348,
      "grad_norm": 57.227760314941406,
      "learning_rate": 1.8842815814850533e-05,
      "loss": 0.8405,
      "step": 5400
    },
    {
      "epoch": 0.5796635594128362,
      "grad_norm": 2.6094260215759277,
      "learning_rate": 1.884067288117433e-05,
      "loss": 0.978,
      "step": 5410
    },
    {
      "epoch": 0.5807350262509375,
      "grad_norm": 19.043088912963867,
      "learning_rate": 1.8838529947498128e-05,
      "loss": 0.5079,
      "step": 5420
    },
    {
      "epoch": 0.5818064930890389,
      "grad_norm": 0.25723111629486084,
      "learning_rate": 1.8836387013821923e-05,
      "loss": 0.5407,
      "step": 5430
    },
    {
      "epoch": 0.5828779599271403,
      "grad_norm": 0.3602105975151062,
      "learning_rate": 1.883424408014572e-05,
      "loss": 0.4139,
      "step": 5440
    },
    {
      "epoch": 0.5839494267652416,
      "grad_norm": 6.167596817016602,
      "learning_rate": 1.8832101146469518e-05,
      "loss": 1.1007,
      "step": 5450
    },
    {
      "epoch": 0.585020893603343,
      "grad_norm": 29.036788940429688,
      "learning_rate": 1.8829958212793317e-05,
      "loss": 0.6665,
      "step": 5460
    },
    {
      "epoch": 0.5860923604414443,
      "grad_norm": 0.32665497064590454,
      "learning_rate": 1.8827815279117113e-05,
      "loss": 0.1219,
      "step": 5470
    },
    {
      "epoch": 0.5871638272795457,
      "grad_norm": 0.3534574806690216,
      "learning_rate": 1.8825672345440912e-05,
      "loss": 0.8455,
      "step": 5480
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 26.897768020629883,
      "learning_rate": 1.8823529411764708e-05,
      "loss": 1.0146,
      "step": 5490
    },
    {
      "epoch": 0.5893067609557484,
      "grad_norm": 17.380990982055664,
      "learning_rate": 1.8821386478088503e-05,
      "loss": 0.9072,
      "step": 5500
    },
    {
      "epoch": 0.5903782277938497,
      "grad_norm": 32.81867218017578,
      "learning_rate": 1.8819243544412302e-05,
      "loss": 0.453,
      "step": 5510
    },
    {
      "epoch": 0.5914496946319512,
      "grad_norm": 3.0329666137695312,
      "learning_rate": 1.8817100610736098e-05,
      "loss": 0.5833,
      "step": 5520
    },
    {
      "epoch": 0.5925211614700525,
      "grad_norm": 25.43694496154785,
      "learning_rate": 1.8814957677059897e-05,
      "loss": 0.3073,
      "step": 5530
    },
    {
      "epoch": 0.5935926283081538,
      "grad_norm": 0.11635664850473404,
      "learning_rate": 1.8812814743383693e-05,
      "loss": 0.2168,
      "step": 5540
    },
    {
      "epoch": 0.5946640951462552,
      "grad_norm": 26.37227439880371,
      "learning_rate": 1.8810671809707492e-05,
      "loss": 0.4951,
      "step": 5550
    },
    {
      "epoch": 0.5957355619843566,
      "grad_norm": 56.739585876464844,
      "learning_rate": 1.8808528876031287e-05,
      "loss": 0.723,
      "step": 5560
    },
    {
      "epoch": 0.596807028822458,
      "grad_norm": 19.545475006103516,
      "learning_rate": 1.8806385942355086e-05,
      "loss": 0.8137,
      "step": 5570
    },
    {
      "epoch": 0.5978784956605593,
      "grad_norm": 0.2535911798477173,
      "learning_rate": 1.8804243008678882e-05,
      "loss": 0.5791,
      "step": 5580
    },
    {
      "epoch": 0.5989499624986606,
      "grad_norm": 24.330472946166992,
      "learning_rate": 1.880210007500268e-05,
      "loss": 0.2713,
      "step": 5590
    },
    {
      "epoch": 0.6000214293367621,
      "grad_norm": 0.22974948585033417,
      "learning_rate": 1.8799957141326477e-05,
      "loss": 0.3629,
      "step": 5600
    },
    {
      "epoch": 0.6010928961748634,
      "grad_norm": 0.4456561207771301,
      "learning_rate": 1.8797814207650276e-05,
      "loss": 0.8759,
      "step": 5610
    },
    {
      "epoch": 0.6021643630129647,
      "grad_norm": 17.74909019470215,
      "learning_rate": 1.879567127397407e-05,
      "loss": 0.5247,
      "step": 5620
    },
    {
      "epoch": 0.6032358298510662,
      "grad_norm": 1.2956947088241577,
      "learning_rate": 1.8793528340297867e-05,
      "loss": 0.1746,
      "step": 5630
    },
    {
      "epoch": 0.6043072966891675,
      "grad_norm": 0.15177756547927856,
      "learning_rate": 1.8791385406621666e-05,
      "loss": 0.3368,
      "step": 5640
    },
    {
      "epoch": 0.6053787635272688,
      "grad_norm": 57.53720474243164,
      "learning_rate": 1.8789242472945465e-05,
      "loss": 0.6129,
      "step": 5650
    },
    {
      "epoch": 0.6064502303653702,
      "grad_norm": 0.40611809492111206,
      "learning_rate": 1.878709953926926e-05,
      "loss": 0.096,
      "step": 5660
    },
    {
      "epoch": 0.6075216972034716,
      "grad_norm": 22.09124183654785,
      "learning_rate": 1.878495660559306e-05,
      "loss": 0.5733,
      "step": 5670
    },
    {
      "epoch": 0.6085931640415729,
      "grad_norm": 0.13403640687465668,
      "learning_rate": 1.8782813671916856e-05,
      "loss": 0.7809,
      "step": 5680
    },
    {
      "epoch": 0.6096646308796743,
      "grad_norm": 22.525266647338867,
      "learning_rate": 1.8780670738240655e-05,
      "loss": 0.2596,
      "step": 5690
    },
    {
      "epoch": 0.6107360977177756,
      "grad_norm": 0.22002598643302917,
      "learning_rate": 1.877852780456445e-05,
      "loss": 0.4535,
      "step": 5700
    },
    {
      "epoch": 0.611807564555877,
      "grad_norm": 53.399173736572266,
      "learning_rate": 1.8776384870888246e-05,
      "loss": 1.2996,
      "step": 5710
    },
    {
      "epoch": 0.6128790313939784,
      "grad_norm": 0.229239821434021,
      "learning_rate": 1.8774241937212045e-05,
      "loss": 0.4906,
      "step": 5720
    },
    {
      "epoch": 0.6139504982320797,
      "grad_norm": 0.48865020275115967,
      "learning_rate": 1.877209900353584e-05,
      "loss": 0.284,
      "step": 5730
    },
    {
      "epoch": 0.615021965070181,
      "grad_norm": 0.2073415070772171,
      "learning_rate": 1.876995606985964e-05,
      "loss": 0.5101,
      "step": 5740
    },
    {
      "epoch": 0.6160934319082825,
      "grad_norm": 21.172956466674805,
      "learning_rate": 1.8767813136183435e-05,
      "loss": 0.3372,
      "step": 5750
    },
    {
      "epoch": 0.6171648987463838,
      "grad_norm": 17.19657325744629,
      "learning_rate": 1.8765670202507235e-05,
      "loss": 0.2086,
      "step": 5760
    },
    {
      "epoch": 0.6182363655844851,
      "grad_norm": 0.14171980321407318,
      "learning_rate": 1.8763527268831034e-05,
      "loss": 0.7457,
      "step": 5770
    },
    {
      "epoch": 0.6193078324225865,
      "grad_norm": 0.23538446426391602,
      "learning_rate": 1.876138433515483e-05,
      "loss": 0.1906,
      "step": 5780
    },
    {
      "epoch": 0.6203792992606879,
      "grad_norm": 0.23980847001075745,
      "learning_rate": 1.8759241401478625e-05,
      "loss": 0.5484,
      "step": 5790
    },
    {
      "epoch": 0.6214507660987892,
      "grad_norm": 0.5661476850509644,
      "learning_rate": 1.8757098467802424e-05,
      "loss": 0.728,
      "step": 5800
    },
    {
      "epoch": 0.6225222329368906,
      "grad_norm": 0.3434000611305237,
      "learning_rate": 1.875495553412622e-05,
      "loss": 0.61,
      "step": 5810
    },
    {
      "epoch": 0.623593699774992,
      "grad_norm": 0.2624340355396271,
      "learning_rate": 1.8752812600450015e-05,
      "loss": 0.5156,
      "step": 5820
    },
    {
      "epoch": 0.6246651666130933,
      "grad_norm": 16.15227508544922,
      "learning_rate": 1.8750669666773814e-05,
      "loss": 0.6403,
      "step": 5830
    },
    {
      "epoch": 0.6257366334511947,
      "grad_norm": 17.755727767944336,
      "learning_rate": 1.8748526733097613e-05,
      "loss": 1.1195,
      "step": 5840
    },
    {
      "epoch": 0.626808100289296,
      "grad_norm": 1.2183647155761719,
      "learning_rate": 1.874638379942141e-05,
      "loss": 0.5,
      "step": 5850
    },
    {
      "epoch": 0.6278795671273975,
      "grad_norm": 0.6381568908691406,
      "learning_rate": 1.8744240865745208e-05,
      "loss": 0.2885,
      "step": 5860
    },
    {
      "epoch": 0.6289510339654988,
      "grad_norm": 0.3082149028778076,
      "learning_rate": 1.8742097932069004e-05,
      "loss": 0.7562,
      "step": 5870
    },
    {
      "epoch": 0.6300225008036001,
      "grad_norm": 17.81059455871582,
      "learning_rate": 1.8739954998392803e-05,
      "loss": 0.5978,
      "step": 5880
    },
    {
      "epoch": 0.6310939676417014,
      "grad_norm": 0.21087561547756195,
      "learning_rate": 1.87378120647166e-05,
      "loss": 0.4766,
      "step": 5890
    },
    {
      "epoch": 0.6321654344798029,
      "grad_norm": 17.196033477783203,
      "learning_rate": 1.8735669131040394e-05,
      "loss": 0.6653,
      "step": 5900
    },
    {
      "epoch": 0.6332369013179042,
      "grad_norm": 0.30771446228027344,
      "learning_rate": 1.8733526197364193e-05,
      "loss": 0.3908,
      "step": 5910
    },
    {
      "epoch": 0.6343083681560056,
      "grad_norm": 0.28487351536750793,
      "learning_rate": 1.873138326368799e-05,
      "loss": 0.4375,
      "step": 5920
    },
    {
      "epoch": 0.6353798349941069,
      "grad_norm": 0.2716200649738312,
      "learning_rate": 1.8729240330011788e-05,
      "loss": 0.5342,
      "step": 5930
    },
    {
      "epoch": 0.6364513018322083,
      "grad_norm": 17.14143180847168,
      "learning_rate": 1.8727097396335584e-05,
      "loss": 0.4535,
      "step": 5940
    },
    {
      "epoch": 0.6375227686703097,
      "grad_norm": 0.4399794936180115,
      "learning_rate": 1.8724954462659383e-05,
      "loss": 0.8772,
      "step": 5950
    },
    {
      "epoch": 0.638594235508411,
      "grad_norm": 0.43941259384155273,
      "learning_rate": 1.872281152898318e-05,
      "loss": 0.0942,
      "step": 5960
    },
    {
      "epoch": 0.6396657023465123,
      "grad_norm": 15.649456024169922,
      "learning_rate": 1.8720668595306977e-05,
      "loss": 0.5342,
      "step": 5970
    },
    {
      "epoch": 0.6407371691846138,
      "grad_norm": 0.2699059545993805,
      "learning_rate": 1.8718525661630773e-05,
      "loss": 0.2839,
      "step": 5980
    },
    {
      "epoch": 0.6418086360227151,
      "grad_norm": 0.12072070688009262,
      "learning_rate": 1.8716382727954572e-05,
      "loss": 0.1581,
      "step": 5990
    },
    {
      "epoch": 0.6428801028608164,
      "grad_norm": 0.10607516020536423,
      "learning_rate": 1.8714239794278368e-05,
      "loss": 0.3353,
      "step": 6000
    },
    {
      "epoch": 0.6439515696989179,
      "grad_norm": 0.10614962130784988,
      "learning_rate": 1.8712096860602167e-05,
      "loss": 0.1463,
      "step": 6010
    },
    {
      "epoch": 0.6450230365370192,
      "grad_norm": 0.07704852521419525,
      "learning_rate": 1.8709953926925962e-05,
      "loss": 0.9063,
      "step": 6020
    },
    {
      "epoch": 0.6460945033751205,
      "grad_norm": 14.723484992980957,
      "learning_rate": 1.870781099324976e-05,
      "loss": 0.6857,
      "step": 6030
    },
    {
      "epoch": 0.6471659702132219,
      "grad_norm": 22.227373123168945,
      "learning_rate": 1.8705668059573557e-05,
      "loss": 0.6817,
      "step": 6040
    },
    {
      "epoch": 0.6482374370513233,
      "grad_norm": 0.2424987256526947,
      "learning_rate": 1.8703525125897356e-05,
      "loss": 0.4771,
      "step": 6050
    },
    {
      "epoch": 0.6493089038894246,
      "grad_norm": 0.2528162896633148,
      "learning_rate": 1.8701382192221152e-05,
      "loss": 0.5583,
      "step": 6060
    },
    {
      "epoch": 0.650380370727526,
      "grad_norm": 7.017599105834961,
      "learning_rate": 1.869923925854495e-05,
      "loss": 0.4987,
      "step": 6070
    },
    {
      "epoch": 0.6514518375656273,
      "grad_norm": 0.7444025874137878,
      "learning_rate": 1.8697096324868747e-05,
      "loss": 0.2441,
      "step": 6080
    },
    {
      "epoch": 0.6525233044037287,
      "grad_norm": 684.1180419921875,
      "learning_rate": 1.8694953391192546e-05,
      "loss": 0.5441,
      "step": 6090
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.4071667194366455,
      "learning_rate": 1.869281045751634e-05,
      "loss": 0.4898,
      "step": 6100
    },
    {
      "epoch": 0.6546662380799314,
      "grad_norm": 16.037967681884766,
      "learning_rate": 1.8690667523840137e-05,
      "loss": 0.7262,
      "step": 6110
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 14.818367004394531,
      "learning_rate": 1.8688524590163936e-05,
      "loss": 0.7934,
      "step": 6120
    },
    {
      "epoch": 0.6568091717561342,
      "grad_norm": 0.2653646171092987,
      "learning_rate": 1.868638165648773e-05,
      "loss": 0.3933,
      "step": 6130
    },
    {
      "epoch": 0.6578806385942355,
      "grad_norm": 0.4857034385204315,
      "learning_rate": 1.868423872281153e-05,
      "loss": 0.5881,
      "step": 6140
    },
    {
      "epoch": 0.6589521054323368,
      "grad_norm": 16.361534118652344,
      "learning_rate": 1.868209578913533e-05,
      "loss": 0.9633,
      "step": 6150
    },
    {
      "epoch": 0.6600235722704382,
      "grad_norm": 1.6618865728378296,
      "learning_rate": 1.8679952855459125e-05,
      "loss": 0.5135,
      "step": 6160
    },
    {
      "epoch": 0.6610950391085396,
      "grad_norm": 0.20992767810821533,
      "learning_rate": 1.8677809921782924e-05,
      "loss": 0.51,
      "step": 6170
    },
    {
      "epoch": 0.662166505946641,
      "grad_norm": 0.149491548538208,
      "learning_rate": 1.867566698810672e-05,
      "loss": 0.5975,
      "step": 6180
    },
    {
      "epoch": 0.6632379727847423,
      "grad_norm": 31.25404930114746,
      "learning_rate": 1.8673524054430516e-05,
      "loss": 0.9423,
      "step": 6190
    },
    {
      "epoch": 0.6643094396228437,
      "grad_norm": 0.7045744061470032,
      "learning_rate": 1.8671381120754315e-05,
      "loss": 0.8008,
      "step": 6200
    },
    {
      "epoch": 0.665380906460945,
      "grad_norm": 21.776016235351562,
      "learning_rate": 1.866923818707811e-05,
      "loss": 0.4645,
      "step": 6210
    },
    {
      "epoch": 0.6664523732990464,
      "grad_norm": 18.311120986938477,
      "learning_rate": 1.866709525340191e-05,
      "loss": 0.505,
      "step": 6220
    },
    {
      "epoch": 0.6675238401371477,
      "grad_norm": 0.936175525188446,
      "learning_rate": 1.8664952319725705e-05,
      "loss": 0.326,
      "step": 6230
    },
    {
      "epoch": 0.6685953069752492,
      "grad_norm": 15.667434692382812,
      "learning_rate": 1.8662809386049504e-05,
      "loss": 0.7511,
      "step": 6240
    },
    {
      "epoch": 0.6696667738133505,
      "grad_norm": 0.34371793270111084,
      "learning_rate": 1.8660666452373303e-05,
      "loss": 0.6486,
      "step": 6250
    },
    {
      "epoch": 0.6707382406514518,
      "grad_norm": 0.8050523996353149,
      "learning_rate": 1.86585235186971e-05,
      "loss": 0.9685,
      "step": 6260
    },
    {
      "epoch": 0.6718097074895532,
      "grad_norm": 0.42646196484565735,
      "learning_rate": 1.8656380585020895e-05,
      "loss": 0.2538,
      "step": 6270
    },
    {
      "epoch": 0.6728811743276546,
      "grad_norm": 41.604244232177734,
      "learning_rate": 1.8654237651344694e-05,
      "loss": 1.0514,
      "step": 6280
    },
    {
      "epoch": 0.6739526411657559,
      "grad_norm": 0.42394810914993286,
      "learning_rate": 1.865209471766849e-05,
      "loss": 0.0191,
      "step": 6290
    },
    {
      "epoch": 0.6750241080038573,
      "grad_norm": 0.26529189944267273,
      "learning_rate": 1.8649951783992285e-05,
      "loss": 0.8051,
      "step": 6300
    },
    {
      "epoch": 0.6760955748419586,
      "grad_norm": 0.4246962070465088,
      "learning_rate": 1.8647808850316084e-05,
      "loss": 0.6498,
      "step": 6310
    },
    {
      "epoch": 0.67716704168006,
      "grad_norm": 17.134838104248047,
      "learning_rate": 1.864566591663988e-05,
      "loss": 0.8635,
      "step": 6320
    },
    {
      "epoch": 0.6782385085181614,
      "grad_norm": 1.474361538887024,
      "learning_rate": 1.864352298296368e-05,
      "loss": 0.2619,
      "step": 6330
    },
    {
      "epoch": 0.6793099753562627,
      "grad_norm": 0.24442042410373688,
      "learning_rate": 1.8641380049287478e-05,
      "loss": 0.2517,
      "step": 6340
    },
    {
      "epoch": 0.6803814421943641,
      "grad_norm": 18.90381622314453,
      "learning_rate": 1.8639237115611273e-05,
      "loss": 0.6366,
      "step": 6350
    },
    {
      "epoch": 0.6814529090324655,
      "grad_norm": 0.7180429100990295,
      "learning_rate": 1.8637094181935072e-05,
      "loss": 0.6967,
      "step": 6360
    },
    {
      "epoch": 0.6825243758705668,
      "grad_norm": 0.34847718477249146,
      "learning_rate": 1.8634951248258868e-05,
      "loss": 0.2468,
      "step": 6370
    },
    {
      "epoch": 0.6835958427086681,
      "grad_norm": 0.6372582316398621,
      "learning_rate": 1.8632808314582664e-05,
      "loss": 0.7214,
      "step": 6380
    },
    {
      "epoch": 0.6846673095467696,
      "grad_norm": 19.534299850463867,
      "learning_rate": 1.8630665380906463e-05,
      "loss": 0.3287,
      "step": 6390
    },
    {
      "epoch": 0.6857387763848709,
      "grad_norm": 0.1037161648273468,
      "learning_rate": 1.862852244723026e-05,
      "loss": 0.3598,
      "step": 6400
    },
    {
      "epoch": 0.6868102432229722,
      "grad_norm": 0.2720131278038025,
      "learning_rate": 1.8626379513554058e-05,
      "loss": 0.7675,
      "step": 6410
    },
    {
      "epoch": 0.6878817100610736,
      "grad_norm": 0.383092999458313,
      "learning_rate": 1.8624236579877853e-05,
      "loss": 0.6145,
      "step": 6420
    },
    {
      "epoch": 0.688953176899175,
      "grad_norm": 12.843362808227539,
      "learning_rate": 1.8622093646201652e-05,
      "loss": 0.7573,
      "step": 6430
    },
    {
      "epoch": 0.6900246437372763,
      "grad_norm": 18.324304580688477,
      "learning_rate": 1.861995071252545e-05,
      "loss": 0.6489,
      "step": 6440
    },
    {
      "epoch": 0.6910961105753777,
      "grad_norm": 11.123763084411621,
      "learning_rate": 1.8617807778849247e-05,
      "loss": 0.3071,
      "step": 6450
    },
    {
      "epoch": 0.692167577413479,
      "grad_norm": 31.77590560913086,
      "learning_rate": 1.8615664845173043e-05,
      "loss": 0.7313,
      "step": 6460
    },
    {
      "epoch": 0.6932390442515804,
      "grad_norm": 0.9852110743522644,
      "learning_rate": 1.8613521911496842e-05,
      "loss": 0.5632,
      "step": 6470
    },
    {
      "epoch": 0.6943105110896818,
      "grad_norm": 0.944405198097229,
      "learning_rate": 1.8611378977820637e-05,
      "loss": 0.9552,
      "step": 6480
    },
    {
      "epoch": 0.6953819779277831,
      "grad_norm": 0.6062742471694946,
      "learning_rate": 1.8609236044144433e-05,
      "loss": 0.3404,
      "step": 6490
    },
    {
      "epoch": 0.6964534447658844,
      "grad_norm": 0.23457442224025726,
      "learning_rate": 1.8607093110468232e-05,
      "loss": 0.6524,
      "step": 6500
    },
    {
      "epoch": 0.6975249116039859,
      "grad_norm": 0.2508716881275177,
      "learning_rate": 1.8604950176792028e-05,
      "loss": 0.4638,
      "step": 6510
    },
    {
      "epoch": 0.6985963784420872,
      "grad_norm": 18.80156707763672,
      "learning_rate": 1.8602807243115827e-05,
      "loss": 0.528,
      "step": 6520
    },
    {
      "epoch": 0.6996678452801885,
      "grad_norm": 0.3542494773864746,
      "learning_rate": 1.8600664309439626e-05,
      "loss": 0.9063,
      "step": 6530
    },
    {
      "epoch": 0.70073931211829,
      "grad_norm": 0.8710092306137085,
      "learning_rate": 1.859852137576342e-05,
      "loss": 0.9186,
      "step": 6540
    },
    {
      "epoch": 0.7018107789563913,
      "grad_norm": 15.030638694763184,
      "learning_rate": 1.859637844208722e-05,
      "loss": 0.533,
      "step": 6550
    },
    {
      "epoch": 0.7028822457944927,
      "grad_norm": 0.34987711906433105,
      "learning_rate": 1.8594235508411016e-05,
      "loss": 0.6039,
      "step": 6560
    },
    {
      "epoch": 0.703953712632594,
      "grad_norm": 16.081205368041992,
      "learning_rate": 1.8592092574734812e-05,
      "loss": 0.2452,
      "step": 6570
    },
    {
      "epoch": 0.7050251794706954,
      "grad_norm": 7.341468811035156,
      "learning_rate": 1.858994964105861e-05,
      "loss": 0.2897,
      "step": 6580
    },
    {
      "epoch": 0.7060966463087968,
      "grad_norm": 18.850046157836914,
      "learning_rate": 1.8587806707382407e-05,
      "loss": 0.8016,
      "step": 6590
    },
    {
      "epoch": 0.7071681131468981,
      "grad_norm": 1.2467780113220215,
      "learning_rate": 1.8585663773706206e-05,
      "loss": 0.2673,
      "step": 6600
    },
    {
      "epoch": 0.7082395799849994,
      "grad_norm": 35.78468322753906,
      "learning_rate": 1.858352084003e-05,
      "loss": 0.6177,
      "step": 6610
    },
    {
      "epoch": 0.7093110468231009,
      "grad_norm": 41.129425048828125,
      "learning_rate": 1.85813779063538e-05,
      "loss": 0.5764,
      "step": 6620
    },
    {
      "epoch": 0.7103825136612022,
      "grad_norm": 26.04238510131836,
      "learning_rate": 1.85792349726776e-05,
      "loss": 0.4232,
      "step": 6630
    },
    {
      "epoch": 0.7114539804993035,
      "grad_norm": 0.20390848815441132,
      "learning_rate": 1.8577092039001395e-05,
      "loss": 1.2822,
      "step": 6640
    },
    {
      "epoch": 0.7125254473374049,
      "grad_norm": 0.3054426908493042,
      "learning_rate": 1.857494910532519e-05,
      "loss": 0.4871,
      "step": 6650
    },
    {
      "epoch": 0.7135969141755063,
      "grad_norm": 0.25566616654396057,
      "learning_rate": 1.857280617164899e-05,
      "loss": 0.5757,
      "step": 6660
    },
    {
      "epoch": 0.7146683810136076,
      "grad_norm": 22.965778350830078,
      "learning_rate": 1.8570663237972785e-05,
      "loss": 0.3478,
      "step": 6670
    },
    {
      "epoch": 0.715739847851709,
      "grad_norm": 24.30101776123047,
      "learning_rate": 1.8568520304296584e-05,
      "loss": 0.5784,
      "step": 6680
    },
    {
      "epoch": 0.7168113146898103,
      "grad_norm": 18.2719669342041,
      "learning_rate": 1.856637737062038e-05,
      "loss": 0.6329,
      "step": 6690
    },
    {
      "epoch": 0.7178827815279117,
      "grad_norm": 21.193218231201172,
      "learning_rate": 1.8564234436944176e-05,
      "loss": 0.5915,
      "step": 6700
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.6410521268844604,
      "learning_rate": 1.8562091503267975e-05,
      "loss": 0.3811,
      "step": 6710
    },
    {
      "epoch": 0.7200257152041144,
      "grad_norm": 53.43918228149414,
      "learning_rate": 1.8559948569591774e-05,
      "loss": 0.8777,
      "step": 6720
    },
    {
      "epoch": 0.7210971820422158,
      "grad_norm": 0.528022050857544,
      "learning_rate": 1.855780563591557e-05,
      "loss": 0.0104,
      "step": 6730
    },
    {
      "epoch": 0.7221686488803172,
      "grad_norm": 0.11143282055854797,
      "learning_rate": 1.855566270223937e-05,
      "loss": 0.3365,
      "step": 6740
    },
    {
      "epoch": 0.7232401157184185,
      "grad_norm": 6.849864482879639,
      "learning_rate": 1.8553519768563164e-05,
      "loss": 1.1229,
      "step": 6750
    },
    {
      "epoch": 0.7243115825565198,
      "grad_norm": 30.835363388061523,
      "learning_rate": 1.8551376834886963e-05,
      "loss": 0.8783,
      "step": 6760
    },
    {
      "epoch": 0.7253830493946213,
      "grad_norm": 1.0217664241790771,
      "learning_rate": 1.854923390121076e-05,
      "loss": 1.089,
      "step": 6770
    },
    {
      "epoch": 0.7264545162327226,
      "grad_norm": 32.1778678894043,
      "learning_rate": 1.8547090967534555e-05,
      "loss": 0.7324,
      "step": 6780
    },
    {
      "epoch": 0.727525983070824,
      "grad_norm": 16.9937744140625,
      "learning_rate": 1.8544948033858354e-05,
      "loss": 0.6477,
      "step": 6790
    },
    {
      "epoch": 0.7285974499089253,
      "grad_norm": 28.805749893188477,
      "learning_rate": 1.854280510018215e-05,
      "loss": 0.4817,
      "step": 6800
    },
    {
      "epoch": 0.7296689167470267,
      "grad_norm": 2.4983339309692383,
      "learning_rate": 1.854066216650595e-05,
      "loss": 0.2667,
      "step": 6810
    },
    {
      "epoch": 0.730740383585128,
      "grad_norm": 53.49114990234375,
      "learning_rate": 1.8538519232829747e-05,
      "loss": 0.2839,
      "step": 6820
    },
    {
      "epoch": 0.7318118504232294,
      "grad_norm": 35.67776107788086,
      "learning_rate": 1.8536376299153543e-05,
      "loss": 0.8145,
      "step": 6830
    },
    {
      "epoch": 0.7328833172613307,
      "grad_norm": 10.777277946472168,
      "learning_rate": 1.8534233365477342e-05,
      "loss": 0.7181,
      "step": 6840
    },
    {
      "epoch": 0.7339547840994322,
      "grad_norm": 1.275355577468872,
      "learning_rate": 1.8532090431801138e-05,
      "loss": 0.4228,
      "step": 6850
    },
    {
      "epoch": 0.7350262509375335,
      "grad_norm": 28.213525772094727,
      "learning_rate": 1.8529947498124934e-05,
      "loss": 0.9991,
      "step": 6860
    },
    {
      "epoch": 0.7360977177756348,
      "grad_norm": 20.499887466430664,
      "learning_rate": 1.8527804564448733e-05,
      "loss": 0.8542,
      "step": 6870
    },
    {
      "epoch": 0.7371691846137362,
      "grad_norm": 1.7717288732528687,
      "learning_rate": 1.8525661630772528e-05,
      "loss": 0.1886,
      "step": 6880
    },
    {
      "epoch": 0.7382406514518376,
      "grad_norm": 17.451345443725586,
      "learning_rate": 1.8523518697096324e-05,
      "loss": 0.5671,
      "step": 6890
    },
    {
      "epoch": 0.7393121182899389,
      "grad_norm": 4.23753547668457,
      "learning_rate": 1.8521375763420123e-05,
      "loss": 0.5239,
      "step": 6900
    },
    {
      "epoch": 0.7403835851280403,
      "grad_norm": 107.09761047363281,
      "learning_rate": 1.8519232829743922e-05,
      "loss": 0.5036,
      "step": 6910
    },
    {
      "epoch": 0.7414550519661417,
      "grad_norm": 0.2883051931858063,
      "learning_rate": 1.8517089896067718e-05,
      "loss": 0.5499,
      "step": 6920
    },
    {
      "epoch": 0.742526518804243,
      "grad_norm": 0.32411086559295654,
      "learning_rate": 1.8514946962391517e-05,
      "loss": 0.5817,
      "step": 6930
    },
    {
      "epoch": 0.7435979856423444,
      "grad_norm": 0.233929842710495,
      "learning_rate": 1.8512804028715312e-05,
      "loss": 0.4866,
      "step": 6940
    },
    {
      "epoch": 0.7446694524804457,
      "grad_norm": 0.34466901421546936,
      "learning_rate": 1.851066109503911e-05,
      "loss": 0.9412,
      "step": 6950
    },
    {
      "epoch": 0.7457409193185471,
      "grad_norm": 0.15940654277801514,
      "learning_rate": 1.8508518161362907e-05,
      "loss": 0.2513,
      "step": 6960
    },
    {
      "epoch": 0.7468123861566485,
      "grad_norm": 0.5374955534934998,
      "learning_rate": 1.8506375227686703e-05,
      "loss": 0.518,
      "step": 6970
    },
    {
      "epoch": 0.7478838529947498,
      "grad_norm": 86.60462188720703,
      "learning_rate": 1.8504232294010502e-05,
      "loss": 0.8868,
      "step": 6980
    },
    {
      "epoch": 0.7489553198328511,
      "grad_norm": 35.39192199707031,
      "learning_rate": 1.8502089360334297e-05,
      "loss": 0.7516,
      "step": 6990
    },
    {
      "epoch": 0.7500267866709526,
      "grad_norm": 0.4559814929962158,
      "learning_rate": 1.8499946426658096e-05,
      "loss": 0.5868,
      "step": 7000
    },
    {
      "epoch": 0.7510982535090539,
      "grad_norm": 0.3728123903274536,
      "learning_rate": 1.8497803492981896e-05,
      "loss": 0.4381,
      "step": 7010
    },
    {
      "epoch": 0.7521697203471552,
      "grad_norm": 0.273483544588089,
      "learning_rate": 1.849566055930569e-05,
      "loss": 1.0453,
      "step": 7020
    },
    {
      "epoch": 0.7532411871852566,
      "grad_norm": 5.2917280197143555,
      "learning_rate": 1.849351762562949e-05,
      "loss": 0.487,
      "step": 7030
    },
    {
      "epoch": 0.754312654023358,
      "grad_norm": 0.4002465009689331,
      "learning_rate": 1.8491374691953286e-05,
      "loss": 0.2845,
      "step": 7040
    },
    {
      "epoch": 0.7553841208614593,
      "grad_norm": 0.347381055355072,
      "learning_rate": 1.848923175827708e-05,
      "loss": 0.5392,
      "step": 7050
    },
    {
      "epoch": 0.7564555876995607,
      "grad_norm": 15.585729598999023,
      "learning_rate": 1.848708882460088e-05,
      "loss": 1.1543,
      "step": 7060
    },
    {
      "epoch": 0.7575270545376621,
      "grad_norm": 17.55763816833496,
      "learning_rate": 1.8484945890924676e-05,
      "loss": 0.3096,
      "step": 7070
    },
    {
      "epoch": 0.7585985213757634,
      "grad_norm": 17.77496910095215,
      "learning_rate": 1.8482802957248475e-05,
      "loss": 0.4602,
      "step": 7080
    },
    {
      "epoch": 0.7596699882138648,
      "grad_norm": 19.058849334716797,
      "learning_rate": 1.848066002357227e-05,
      "loss": 0.2477,
      "step": 7090
    },
    {
      "epoch": 0.7607414550519661,
      "grad_norm": 0.08140210807323456,
      "learning_rate": 1.847851708989607e-05,
      "loss": 0.3905,
      "step": 7100
    },
    {
      "epoch": 0.7618129218900676,
      "grad_norm": 0.2169329822063446,
      "learning_rate": 1.8476374156219866e-05,
      "loss": 0.3394,
      "step": 7110
    },
    {
      "epoch": 0.7628843887281689,
      "grad_norm": 0.29008978605270386,
      "learning_rate": 1.8474231222543665e-05,
      "loss": 0.3585,
      "step": 7120
    },
    {
      "epoch": 0.7639558555662702,
      "grad_norm": 0.09482169896364212,
      "learning_rate": 1.847208828886746e-05,
      "loss": 0.0419,
      "step": 7130
    },
    {
      "epoch": 0.7650273224043715,
      "grad_norm": 0.4117095470428467,
      "learning_rate": 1.846994535519126e-05,
      "loss": 0.7853,
      "step": 7140
    },
    {
      "epoch": 0.766098789242473,
      "grad_norm": 17.926931381225586,
      "learning_rate": 1.8467802421515055e-05,
      "loss": 0.3194,
      "step": 7150
    },
    {
      "epoch": 0.7671702560805743,
      "grad_norm": 19.923843383789062,
      "learning_rate": 1.8465659487838854e-05,
      "loss": 0.8389,
      "step": 7160
    },
    {
      "epoch": 0.7682417229186757,
      "grad_norm": 0.2660011053085327,
      "learning_rate": 1.846351655416265e-05,
      "loss": 0.9415,
      "step": 7170
    },
    {
      "epoch": 0.769313189756777,
      "grad_norm": 30.788311004638672,
      "learning_rate": 1.8461373620486446e-05,
      "loss": 0.6104,
      "step": 7180
    },
    {
      "epoch": 0.7703846565948784,
      "grad_norm": 36.174434661865234,
      "learning_rate": 1.8459230686810245e-05,
      "loss": 0.8621,
      "step": 7190
    },
    {
      "epoch": 0.7714561234329798,
      "grad_norm": 4.175356864929199,
      "learning_rate": 1.8457087753134044e-05,
      "loss": 0.626,
      "step": 7200
    },
    {
      "epoch": 0.7725275902710811,
      "grad_norm": 23.393451690673828,
      "learning_rate": 1.845494481945784e-05,
      "loss": 0.7301,
      "step": 7210
    },
    {
      "epoch": 0.7735990571091824,
      "grad_norm": 0.5367279052734375,
      "learning_rate": 1.845280188578164e-05,
      "loss": 0.1758,
      "step": 7220
    },
    {
      "epoch": 0.7746705239472839,
      "grad_norm": 3.7259140014648438,
      "learning_rate": 1.8450658952105434e-05,
      "loss": 0.6589,
      "step": 7230
    },
    {
      "epoch": 0.7757419907853852,
      "grad_norm": 17.547700881958008,
      "learning_rate": 1.8448516018429233e-05,
      "loss": 0.3175,
      "step": 7240
    },
    {
      "epoch": 0.7768134576234865,
      "grad_norm": 3.985863208770752,
      "learning_rate": 1.844637308475303e-05,
      "loss": 0.3135,
      "step": 7250
    },
    {
      "epoch": 0.777884924461588,
      "grad_norm": 31.50926399230957,
      "learning_rate": 1.8444230151076824e-05,
      "loss": 1.2022,
      "step": 7260
    },
    {
      "epoch": 0.7789563912996893,
      "grad_norm": 56.82743835449219,
      "learning_rate": 1.8442087217400623e-05,
      "loss": 0.2918,
      "step": 7270
    },
    {
      "epoch": 0.7800278581377906,
      "grad_norm": 93.98936462402344,
      "learning_rate": 1.843994428372442e-05,
      "loss": 0.3496,
      "step": 7280
    },
    {
      "epoch": 0.781099324975892,
      "grad_norm": 16.249568939208984,
      "learning_rate": 1.8437801350048218e-05,
      "loss": 0.6309,
      "step": 7290
    },
    {
      "epoch": 0.7821707918139934,
      "grad_norm": 19.548765182495117,
      "learning_rate": 1.8435658416372014e-05,
      "loss": 0.9984,
      "step": 7300
    },
    {
      "epoch": 0.7832422586520947,
      "grad_norm": 1.1761029958724976,
      "learning_rate": 1.8433515482695813e-05,
      "loss": 0.4602,
      "step": 7310
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.5699998736381531,
      "learning_rate": 1.843137254901961e-05,
      "loss": 0.3671,
      "step": 7320
    },
    {
      "epoch": 0.7853851923282974,
      "grad_norm": 18.66112518310547,
      "learning_rate": 1.8429229615343408e-05,
      "loss": 0.6358,
      "step": 7330
    },
    {
      "epoch": 0.7864566591663988,
      "grad_norm": 35.788543701171875,
      "learning_rate": 1.8427086681667203e-05,
      "loss": 0.6637,
      "step": 7340
    },
    {
      "epoch": 0.7875281260045002,
      "grad_norm": 0.23842884600162506,
      "learning_rate": 1.8424943747991002e-05,
      "loss": 0.5099,
      "step": 7350
    },
    {
      "epoch": 0.7885995928426015,
      "grad_norm": 0.282573938369751,
      "learning_rate": 1.8422800814314798e-05,
      "loss": 0.6653,
      "step": 7360
    },
    {
      "epoch": 0.7896710596807028,
      "grad_norm": 0.4284328520298004,
      "learning_rate": 1.8420657880638594e-05,
      "loss": 0.3587,
      "step": 7370
    },
    {
      "epoch": 0.7907425265188043,
      "grad_norm": 0.41129979491233826,
      "learning_rate": 1.8418514946962393e-05,
      "loss": 0.2349,
      "step": 7380
    },
    {
      "epoch": 0.7918139933569056,
      "grad_norm": 20.0228214263916,
      "learning_rate": 1.841637201328619e-05,
      "loss": 0.8925,
      "step": 7390
    },
    {
      "epoch": 0.7928854601950069,
      "grad_norm": 2.368910551071167,
      "learning_rate": 1.8414229079609987e-05,
      "loss": 0.3922,
      "step": 7400
    },
    {
      "epoch": 0.7939569270331083,
      "grad_norm": 1.9019255638122559,
      "learning_rate": 1.8412086145933786e-05,
      "loss": 0.5419,
      "step": 7410
    },
    {
      "epoch": 0.7950283938712097,
      "grad_norm": 32.129886627197266,
      "learning_rate": 1.8409943212257582e-05,
      "loss": 0.3602,
      "step": 7420
    },
    {
      "epoch": 0.796099860709311,
      "grad_norm": 16.5035457611084,
      "learning_rate": 1.840780027858138e-05,
      "loss": 0.8364,
      "step": 7430
    },
    {
      "epoch": 0.7971713275474124,
      "grad_norm": 0.7170996069908142,
      "learning_rate": 1.8405657344905177e-05,
      "loss": 0.095,
      "step": 7440
    },
    {
      "epoch": 0.7982427943855138,
      "grad_norm": 0.7119600772857666,
      "learning_rate": 1.8403514411228972e-05,
      "loss": 0.6076,
      "step": 7450
    },
    {
      "epoch": 0.7993142612236152,
      "grad_norm": 0.5425333976745605,
      "learning_rate": 1.840137147755277e-05,
      "loss": 0.337,
      "step": 7460
    },
    {
      "epoch": 0.8003857280617165,
      "grad_norm": 0.1286511868238449,
      "learning_rate": 1.8399228543876567e-05,
      "loss": 0.4945,
      "step": 7470
    },
    {
      "epoch": 0.8014571948998178,
      "grad_norm": 0.09554129093885422,
      "learning_rate": 1.8397085610200366e-05,
      "loss": 0.1194,
      "step": 7480
    },
    {
      "epoch": 0.8025286617379193,
      "grad_norm": 0.08224385976791382,
      "learning_rate": 1.8394942676524162e-05,
      "loss": 0.2495,
      "step": 7490
    },
    {
      "epoch": 0.8036001285760206,
      "grad_norm": 32.44801712036133,
      "learning_rate": 1.839279974284796e-05,
      "loss": 1.1223,
      "step": 7500
    },
    {
      "epoch": 0.8046715954141219,
      "grad_norm": 0.06461971998214722,
      "learning_rate": 1.839065680917176e-05,
      "loss": 0.7877,
      "step": 7510
    },
    {
      "epoch": 0.8057430622522233,
      "grad_norm": 39.99168395996094,
      "learning_rate": 1.8388513875495556e-05,
      "loss": 1.2835,
      "step": 7520
    },
    {
      "epoch": 0.8068145290903247,
      "grad_norm": 0.1703862100839615,
      "learning_rate": 1.838637094181935e-05,
      "loss": 0.9628,
      "step": 7530
    },
    {
      "epoch": 0.807885995928426,
      "grad_norm": 23.915922164916992,
      "learning_rate": 1.838422800814315e-05,
      "loss": 0.2369,
      "step": 7540
    },
    {
      "epoch": 0.8089574627665274,
      "grad_norm": 0.24087412655353546,
      "learning_rate": 1.8382085074466946e-05,
      "loss": 0.5578,
      "step": 7550
    },
    {
      "epoch": 0.8100289296046287,
      "grad_norm": 23.726795196533203,
      "learning_rate": 1.837994214079074e-05,
      "loss": 0.6261,
      "step": 7560
    },
    {
      "epoch": 0.8111003964427301,
      "grad_norm": 0.10048229992389679,
      "learning_rate": 1.837779920711454e-05,
      "loss": 0.2093,
      "step": 7570
    },
    {
      "epoch": 0.8121718632808315,
      "grad_norm": 16.56543731689453,
      "learning_rate": 1.837565627343834e-05,
      "loss": 0.9787,
      "step": 7580
    },
    {
      "epoch": 0.8132433301189328,
      "grad_norm": 19.82288932800293,
      "learning_rate": 1.8373513339762135e-05,
      "loss": 0.6789,
      "step": 7590
    },
    {
      "epoch": 0.8143147969570341,
      "grad_norm": 35.67387390136719,
      "learning_rate": 1.8371370406085934e-05,
      "loss": 0.6067,
      "step": 7600
    },
    {
      "epoch": 0.8153862637951356,
      "grad_norm": 22.085641860961914,
      "learning_rate": 1.836922747240973e-05,
      "loss": 0.9722,
      "step": 7610
    },
    {
      "epoch": 0.8164577306332369,
      "grad_norm": 0.31669995188713074,
      "learning_rate": 1.836708453873353e-05,
      "loss": 1.0332,
      "step": 7620
    },
    {
      "epoch": 0.8175291974713382,
      "grad_norm": 53.27681350708008,
      "learning_rate": 1.8364941605057325e-05,
      "loss": 0.8197,
      "step": 7630
    },
    {
      "epoch": 0.8186006643094397,
      "grad_norm": 2.5994958877563477,
      "learning_rate": 1.836279867138112e-05,
      "loss": 0.387,
      "step": 7640
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 19.6381778717041,
      "learning_rate": 1.836065573770492e-05,
      "loss": 0.7233,
      "step": 7650
    },
    {
      "epoch": 0.8207435979856423,
      "grad_norm": 2.1087658405303955,
      "learning_rate": 1.8358512804028715e-05,
      "loss": 1.0907,
      "step": 7660
    },
    {
      "epoch": 0.8218150648237437,
      "grad_norm": 0.11681748181581497,
      "learning_rate": 1.8356369870352514e-05,
      "loss": 0.1807,
      "step": 7670
    },
    {
      "epoch": 0.8228865316618451,
      "grad_norm": 19.327369689941406,
      "learning_rate": 1.835422693667631e-05,
      "loss": 0.7608,
      "step": 7680
    },
    {
      "epoch": 0.8239579984999464,
      "grad_norm": 0.2885727286338806,
      "learning_rate": 1.835208400300011e-05,
      "loss": 0.6202,
      "step": 7690
    },
    {
      "epoch": 0.8250294653380478,
      "grad_norm": 17.273731231689453,
      "learning_rate": 1.8349941069323908e-05,
      "loss": 0.6182,
      "step": 7700
    },
    {
      "epoch": 0.8261009321761491,
      "grad_norm": 0.5176274180412292,
      "learning_rate": 1.8347798135647704e-05,
      "loss": 0.503,
      "step": 7710
    },
    {
      "epoch": 0.8271723990142505,
      "grad_norm": 0.2617794871330261,
      "learning_rate": 1.83456552019715e-05,
      "loss": 0.1512,
      "step": 7720
    },
    {
      "epoch": 0.8282438658523519,
      "grad_norm": 0.29140275716781616,
      "learning_rate": 1.83435122682953e-05,
      "loss": 0.6147,
      "step": 7730
    },
    {
      "epoch": 0.8293153326904532,
      "grad_norm": 0.3298412263393402,
      "learning_rate": 1.8341369334619094e-05,
      "loss": 0.714,
      "step": 7740
    },
    {
      "epoch": 0.8303867995285545,
      "grad_norm": 0.18804681301116943,
      "learning_rate": 1.8339226400942893e-05,
      "loss": 0.0065,
      "step": 7750
    },
    {
      "epoch": 0.831458266366656,
      "grad_norm": 0.11507686227560043,
      "learning_rate": 1.833708346726669e-05,
      "loss": 0.0957,
      "step": 7760
    },
    {
      "epoch": 0.8325297332047573,
      "grad_norm": 0.0809653028845787,
      "learning_rate": 1.8334940533590488e-05,
      "loss": 0.9256,
      "step": 7770
    },
    {
      "epoch": 0.8336012000428586,
      "grad_norm": 0.18355689942836761,
      "learning_rate": 1.8332797599914283e-05,
      "loss": 0.5405,
      "step": 7780
    },
    {
      "epoch": 0.83467266688096,
      "grad_norm": 0.38703009486198425,
      "learning_rate": 1.8330654666238083e-05,
      "loss": 0.8585,
      "step": 7790
    },
    {
      "epoch": 0.8357441337190614,
      "grad_norm": 0.47185999155044556,
      "learning_rate": 1.8328511732561878e-05,
      "loss": 0.2877,
      "step": 7800
    },
    {
      "epoch": 0.8368156005571628,
      "grad_norm": 0.4406577944755554,
      "learning_rate": 1.8326368798885677e-05,
      "loss": 0.7281,
      "step": 7810
    },
    {
      "epoch": 0.8378870673952641,
      "grad_norm": 0.32191842794418335,
      "learning_rate": 1.8324225865209473e-05,
      "loss": 0.3017,
      "step": 7820
    },
    {
      "epoch": 0.8389585342333655,
      "grad_norm": 22.499605178833008,
      "learning_rate": 1.8322082931533272e-05,
      "loss": 0.5797,
      "step": 7830
    },
    {
      "epoch": 0.8400300010714669,
      "grad_norm": 0.16204038262367249,
      "learning_rate": 1.8319939997857068e-05,
      "loss": 0.4004,
      "step": 7840
    },
    {
      "epoch": 0.8411014679095682,
      "grad_norm": 10.148449897766113,
      "learning_rate": 1.8317797064180863e-05,
      "loss": 0.0852,
      "step": 7850
    },
    {
      "epoch": 0.8421729347476695,
      "grad_norm": 3.6982574462890625,
      "learning_rate": 1.8315654130504662e-05,
      "loss": 0.4158,
      "step": 7860
    },
    {
      "epoch": 0.843244401585771,
      "grad_norm": 0.18138596415519714,
      "learning_rate": 1.8313511196828458e-05,
      "loss": 0.3511,
      "step": 7870
    },
    {
      "epoch": 0.8443158684238723,
      "grad_norm": 0.1532716304063797,
      "learning_rate": 1.8311368263152257e-05,
      "loss": 0.238,
      "step": 7880
    },
    {
      "epoch": 0.8453873352619736,
      "grad_norm": 0.23897545039653778,
      "learning_rate": 1.8309225329476056e-05,
      "loss": 0.3854,
      "step": 7890
    },
    {
      "epoch": 0.846458802100075,
      "grad_norm": 34.822906494140625,
      "learning_rate": 1.8307082395799852e-05,
      "loss": 0.4842,
      "step": 7900
    },
    {
      "epoch": 0.8475302689381764,
      "grad_norm": 0.04554366320371628,
      "learning_rate": 1.830493946212365e-05,
      "loss": 0.4123,
      "step": 7910
    },
    {
      "epoch": 0.8486017357762777,
      "grad_norm": 33.70558166503906,
      "learning_rate": 1.8302796528447446e-05,
      "loss": 0.2559,
      "step": 7920
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.042781416326761246,
      "learning_rate": 1.8300653594771242e-05,
      "loss": 0.0018,
      "step": 7930
    },
    {
      "epoch": 0.8507446694524804,
      "grad_norm": 0.7846359014511108,
      "learning_rate": 1.829851066109504e-05,
      "loss": 0.6882,
      "step": 7940
    },
    {
      "epoch": 0.8518161362905818,
      "grad_norm": 0.29318031668663025,
      "learning_rate": 1.8296367727418837e-05,
      "loss": 0.2063,
      "step": 7950
    },
    {
      "epoch": 0.8528876031286832,
      "grad_norm": 0.11532963812351227,
      "learning_rate": 1.8294224793742636e-05,
      "loss": 0.6124,
      "step": 7960
    },
    {
      "epoch": 0.8539590699667845,
      "grad_norm": 21.249666213989258,
      "learning_rate": 1.829208186006643e-05,
      "loss": 0.3909,
      "step": 7970
    },
    {
      "epoch": 0.8550305368048859,
      "grad_norm": 0.6842367649078369,
      "learning_rate": 1.828993892639023e-05,
      "loss": 0.8822,
      "step": 7980
    },
    {
      "epoch": 0.8561020036429873,
      "grad_norm": 45.20579147338867,
      "learning_rate": 1.828779599271403e-05,
      "loss": 0.3607,
      "step": 7990
    },
    {
      "epoch": 0.8571734704810886,
      "grad_norm": 0.19736436009407043,
      "learning_rate": 1.8285653059037825e-05,
      "loss": 0.576,
      "step": 8000
    },
    {
      "epoch": 0.8582449373191899,
      "grad_norm": 18.985837936401367,
      "learning_rate": 1.828351012536162e-05,
      "loss": 0.5538,
      "step": 8010
    },
    {
      "epoch": 0.8593164041572914,
      "grad_norm": 41.110801696777344,
      "learning_rate": 1.828136719168542e-05,
      "loss": 0.9747,
      "step": 8020
    },
    {
      "epoch": 0.8603878709953927,
      "grad_norm": 17.538406372070312,
      "learning_rate": 1.8279224258009216e-05,
      "loss": 0.2517,
      "step": 8030
    },
    {
      "epoch": 0.861459337833494,
      "grad_norm": 17.737300872802734,
      "learning_rate": 1.827708132433301e-05,
      "loss": 0.7892,
      "step": 8040
    },
    {
      "epoch": 0.8625308046715954,
      "grad_norm": 2.769436836242676,
      "learning_rate": 1.827493839065681e-05,
      "loss": 0.3583,
      "step": 8050
    },
    {
      "epoch": 0.8636022715096968,
      "grad_norm": 0.27963173389434814,
      "learning_rate": 1.8272795456980606e-05,
      "loss": 0.8255,
      "step": 8060
    },
    {
      "epoch": 0.8646737383477981,
      "grad_norm": 0.22018133103847504,
      "learning_rate": 1.8270652523304405e-05,
      "loss": 0.2886,
      "step": 8070
    },
    {
      "epoch": 0.8657452051858995,
      "grad_norm": 0.13695721328258514,
      "learning_rate": 1.8268509589628204e-05,
      "loss": 0.6303,
      "step": 8080
    },
    {
      "epoch": 0.8668166720240008,
      "grad_norm": 1.1634323596954346,
      "learning_rate": 1.8266366655952e-05,
      "loss": 0.526,
      "step": 8090
    },
    {
      "epoch": 0.8678881388621023,
      "grad_norm": 0.2096734642982483,
      "learning_rate": 1.82642237222758e-05,
      "loss": 0.2909,
      "step": 8100
    },
    {
      "epoch": 0.8689596057002036,
      "grad_norm": 0.4485619366168976,
      "learning_rate": 1.8262080788599595e-05,
      "loss": 0.6263,
      "step": 8110
    },
    {
      "epoch": 0.8700310725383049,
      "grad_norm": 2.2183289527893066,
      "learning_rate": 1.825993785492339e-05,
      "loss": 0.3951,
      "step": 8120
    },
    {
      "epoch": 0.8711025393764062,
      "grad_norm": 0.07213781028985977,
      "learning_rate": 1.825779492124719e-05,
      "loss": 0.355,
      "step": 8130
    },
    {
      "epoch": 0.8721740062145077,
      "grad_norm": 19.160655975341797,
      "learning_rate": 1.8255651987570985e-05,
      "loss": 0.6338,
      "step": 8140
    },
    {
      "epoch": 0.873245473052609,
      "grad_norm": 0.3446411192417145,
      "learning_rate": 1.8253509053894784e-05,
      "loss": 1.0872,
      "step": 8150
    },
    {
      "epoch": 0.8743169398907104,
      "grad_norm": 0.25457149744033813,
      "learning_rate": 1.825136612021858e-05,
      "loss": 0.0733,
      "step": 8160
    },
    {
      "epoch": 0.8753884067288118,
      "grad_norm": 0.2431573122739792,
      "learning_rate": 1.824922318654238e-05,
      "loss": 0.8874,
      "step": 8170
    },
    {
      "epoch": 0.8764598735669131,
      "grad_norm": 17.070228576660156,
      "learning_rate": 1.8247080252866178e-05,
      "loss": 0.8192,
      "step": 8180
    },
    {
      "epoch": 0.8775313404050145,
      "grad_norm": 0.42156070470809937,
      "learning_rate": 1.8244937319189973e-05,
      "loss": 0.4213,
      "step": 8190
    },
    {
      "epoch": 0.8786028072431158,
      "grad_norm": 19.87977409362793,
      "learning_rate": 1.824279438551377e-05,
      "loss": 0.7046,
      "step": 8200
    },
    {
      "epoch": 0.8796742740812172,
      "grad_norm": 16.87286376953125,
      "learning_rate": 1.8240651451837568e-05,
      "loss": 0.642,
      "step": 8210
    },
    {
      "epoch": 0.8807457409193186,
      "grad_norm": 25.20548439025879,
      "learning_rate": 1.8238508518161364e-05,
      "loss": 0.3107,
      "step": 8220
    },
    {
      "epoch": 0.8818172077574199,
      "grad_norm": 0.16279050707817078,
      "learning_rate": 1.823636558448516e-05,
      "loss": 0.1182,
      "step": 8230
    },
    {
      "epoch": 0.8828886745955212,
      "grad_norm": 0.24615462124347687,
      "learning_rate": 1.823422265080896e-05,
      "loss": 0.8564,
      "step": 8240
    },
    {
      "epoch": 0.8839601414336227,
      "grad_norm": 0.29415833950042725,
      "learning_rate": 1.8232079717132754e-05,
      "loss": 0.8859,
      "step": 8250
    },
    {
      "epoch": 0.885031608271724,
      "grad_norm": 90.06294250488281,
      "learning_rate": 1.8229936783456553e-05,
      "loss": 0.8523,
      "step": 8260
    },
    {
      "epoch": 0.8861030751098253,
      "grad_norm": 0.419868141412735,
      "learning_rate": 1.8227793849780352e-05,
      "loss": 0.3423,
      "step": 8270
    },
    {
      "epoch": 0.8871745419479267,
      "grad_norm": 2.3076860904693604,
      "learning_rate": 1.8225650916104148e-05,
      "loss": 0.7485,
      "step": 8280
    },
    {
      "epoch": 0.8882460087860281,
      "grad_norm": 18.456090927124023,
      "learning_rate": 1.8223507982427947e-05,
      "loss": 0.5651,
      "step": 8290
    },
    {
      "epoch": 0.8893174756241294,
      "grad_norm": 0.6169148087501526,
      "learning_rate": 1.8221365048751743e-05,
      "loss": 0.8557,
      "step": 8300
    },
    {
      "epoch": 0.8903889424622308,
      "grad_norm": 27.13976287841797,
      "learning_rate": 1.8219222115075538e-05,
      "loss": 0.7264,
      "step": 8310
    },
    {
      "epoch": 0.8914604093003321,
      "grad_norm": 0.15094880759716034,
      "learning_rate": 1.8217079181399337e-05,
      "loss": 0.1306,
      "step": 8320
    },
    {
      "epoch": 0.8925318761384335,
      "grad_norm": 40.92196273803711,
      "learning_rate": 1.8214936247723133e-05,
      "loss": 0.4664,
      "step": 8330
    },
    {
      "epoch": 0.8936033429765349,
      "grad_norm": 0.1442701816558838,
      "learning_rate": 1.8212793314046932e-05,
      "loss": 0.2496,
      "step": 8340
    },
    {
      "epoch": 0.8946748098146362,
      "grad_norm": 62.25223922729492,
      "learning_rate": 1.8210650380370728e-05,
      "loss": 0.9998,
      "step": 8350
    },
    {
      "epoch": 0.8957462766527376,
      "grad_norm": 5.720655918121338,
      "learning_rate": 1.8208507446694527e-05,
      "loss": 0.3777,
      "step": 8360
    },
    {
      "epoch": 0.896817743490839,
      "grad_norm": 0.19937583804130554,
      "learning_rate": 1.8206364513018326e-05,
      "loss": 0.5425,
      "step": 8370
    },
    {
      "epoch": 0.8978892103289403,
      "grad_norm": 0.34665319323539734,
      "learning_rate": 1.820422157934212e-05,
      "loss": 0.9735,
      "step": 8380
    },
    {
      "epoch": 0.8989606771670416,
      "grad_norm": 64.61163330078125,
      "learning_rate": 1.8202078645665917e-05,
      "loss": 0.5978,
      "step": 8390
    },
    {
      "epoch": 0.9000321440051431,
      "grad_norm": 55.0499382019043,
      "learning_rate": 1.8199935711989716e-05,
      "loss": 0.3163,
      "step": 8400
    },
    {
      "epoch": 0.9011036108432444,
      "grad_norm": 0.7243900299072266,
      "learning_rate": 1.8197792778313512e-05,
      "loss": 0.3012,
      "step": 8410
    },
    {
      "epoch": 0.9021750776813457,
      "grad_norm": 19.537498474121094,
      "learning_rate": 1.819564984463731e-05,
      "loss": 0.1507,
      "step": 8420
    },
    {
      "epoch": 0.9032465445194471,
      "grad_norm": 0.4113257825374603,
      "learning_rate": 1.8193506910961107e-05,
      "loss": 0.3797,
      "step": 8430
    },
    {
      "epoch": 0.9043180113575485,
      "grad_norm": 170.3700714111328,
      "learning_rate": 1.8191363977284902e-05,
      "loss": 0.2205,
      "step": 8440
    },
    {
      "epoch": 0.9053894781956499,
      "grad_norm": 21.292842864990234,
      "learning_rate": 1.81892210436087e-05,
      "loss": 1.0797,
      "step": 8450
    },
    {
      "epoch": 0.9064609450337512,
      "grad_norm": 2.124737501144409,
      "learning_rate": 1.81870781099325e-05,
      "loss": 0.5907,
      "step": 8460
    },
    {
      "epoch": 0.9075324118718525,
      "grad_norm": 20.71270179748535,
      "learning_rate": 1.8184935176256296e-05,
      "loss": 0.6682,
      "step": 8470
    },
    {
      "epoch": 0.908603878709954,
      "grad_norm": 2.047222375869751,
      "learning_rate": 1.8182792242580095e-05,
      "loss": 0.689,
      "step": 8480
    },
    {
      "epoch": 0.9096753455480553,
      "grad_norm": 0.39827844500541687,
      "learning_rate": 1.818064930890389e-05,
      "loss": 0.3033,
      "step": 8490
    },
    {
      "epoch": 0.9107468123861566,
      "grad_norm": 0.2860080897808075,
      "learning_rate": 1.817850637522769e-05,
      "loss": 0.5336,
      "step": 8500
    },
    {
      "epoch": 0.911818279224258,
      "grad_norm": 0.16551072895526886,
      "learning_rate": 1.8176363441551485e-05,
      "loss": 0.417,
      "step": 8510
    },
    {
      "epoch": 0.9128897460623594,
      "grad_norm": 33.5557861328125,
      "learning_rate": 1.817422050787528e-05,
      "loss": 0.4233,
      "step": 8520
    },
    {
      "epoch": 0.9139612129004607,
      "grad_norm": 30.994142532348633,
      "learning_rate": 1.817207757419908e-05,
      "loss": 1.1101,
      "step": 8530
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.35118499398231506,
      "learning_rate": 1.8169934640522876e-05,
      "loss": 0.37,
      "step": 8540
    },
    {
      "epoch": 0.9161041465766635,
      "grad_norm": 91.28555297851562,
      "learning_rate": 1.8167791706846675e-05,
      "loss": 0.3837,
      "step": 8550
    },
    {
      "epoch": 0.9171756134147648,
      "grad_norm": 64.02568054199219,
      "learning_rate": 1.8165648773170474e-05,
      "loss": 0.3553,
      "step": 8560
    },
    {
      "epoch": 0.9182470802528662,
      "grad_norm": 0.1748426854610443,
      "learning_rate": 1.816350583949427e-05,
      "loss": 0.6783,
      "step": 8570
    },
    {
      "epoch": 0.9193185470909675,
      "grad_norm": 16.320354461669922,
      "learning_rate": 1.816136290581807e-05,
      "loss": 0.5191,
      "step": 8580
    },
    {
      "epoch": 0.9203900139290689,
      "grad_norm": 1.974353551864624,
      "learning_rate": 1.8159219972141864e-05,
      "loss": 0.5869,
      "step": 8590
    },
    {
      "epoch": 0.9214614807671703,
      "grad_norm": 17.93482780456543,
      "learning_rate": 1.815707703846566e-05,
      "loss": 1.0497,
      "step": 8600
    },
    {
      "epoch": 0.9225329476052716,
      "grad_norm": 0.5942690968513489,
      "learning_rate": 1.815493410478946e-05,
      "loss": 0.083,
      "step": 8610
    },
    {
      "epoch": 0.9236044144433729,
      "grad_norm": 0.27523159980773926,
      "learning_rate": 1.8152791171113255e-05,
      "loss": 0.3584,
      "step": 8620
    },
    {
      "epoch": 0.9246758812814744,
      "grad_norm": 0.7761865258216858,
      "learning_rate": 1.815064823743705e-05,
      "loss": 0.7643,
      "step": 8630
    },
    {
      "epoch": 0.9257473481195757,
      "grad_norm": 0.8779379725456238,
      "learning_rate": 1.814850530376085e-05,
      "loss": 0.3895,
      "step": 8640
    },
    {
      "epoch": 0.926818814957677,
      "grad_norm": 325.8218688964844,
      "learning_rate": 1.814636237008465e-05,
      "loss": 0.4773,
      "step": 8650
    },
    {
      "epoch": 0.9278902817957784,
      "grad_norm": 0.12238837778568268,
      "learning_rate": 1.8144219436408444e-05,
      "loss": 0.7667,
      "step": 8660
    },
    {
      "epoch": 0.9289617486338798,
      "grad_norm": 30.854928970336914,
      "learning_rate": 1.8142076502732243e-05,
      "loss": 0.6119,
      "step": 8670
    },
    {
      "epoch": 0.9300332154719811,
      "grad_norm": 28.1795597076416,
      "learning_rate": 1.813993356905604e-05,
      "loss": 1.1169,
      "step": 8680
    },
    {
      "epoch": 0.9311046823100825,
      "grad_norm": 0.6056814193725586,
      "learning_rate": 1.8137790635379838e-05,
      "loss": 0.2007,
      "step": 8690
    },
    {
      "epoch": 0.9321761491481839,
      "grad_norm": 20.151500701904297,
      "learning_rate": 1.8135647701703633e-05,
      "loss": 0.7801,
      "step": 8700
    },
    {
      "epoch": 0.9332476159862853,
      "grad_norm": 90.95170593261719,
      "learning_rate": 1.813350476802743e-05,
      "loss": 0.7994,
      "step": 8710
    },
    {
      "epoch": 0.9343190828243866,
      "grad_norm": 16.022567749023438,
      "learning_rate": 1.8131361834351228e-05,
      "loss": 0.5027,
      "step": 8720
    },
    {
      "epoch": 0.9353905496624879,
      "grad_norm": 0.23687532544136047,
      "learning_rate": 1.8129218900675024e-05,
      "loss": 0.6129,
      "step": 8730
    },
    {
      "epoch": 0.9364620165005894,
      "grad_norm": 0.2386358678340912,
      "learning_rate": 1.8127075966998823e-05,
      "loss": 0.2008,
      "step": 8740
    },
    {
      "epoch": 0.9375334833386907,
      "grad_norm": 15.844930648803711,
      "learning_rate": 1.8124933033322622e-05,
      "loss": 0.2119,
      "step": 8750
    },
    {
      "epoch": 0.938604950176792,
      "grad_norm": 27.154720306396484,
      "learning_rate": 1.8122790099646418e-05,
      "loss": 0.6911,
      "step": 8760
    },
    {
      "epoch": 0.9396764170148934,
      "grad_norm": 0.18127304315567017,
      "learning_rate": 1.8120647165970217e-05,
      "loss": 0.595,
      "step": 8770
    },
    {
      "epoch": 0.9407478838529948,
      "grad_norm": 0.28837546706199646,
      "learning_rate": 1.8118504232294012e-05,
      "loss": 0.3274,
      "step": 8780
    },
    {
      "epoch": 0.9418193506910961,
      "grad_norm": 0.2979542016983032,
      "learning_rate": 1.8116361298617808e-05,
      "loss": 0.3329,
      "step": 8790
    },
    {
      "epoch": 0.9428908175291975,
      "grad_norm": 17.408689498901367,
      "learning_rate": 1.8114218364941607e-05,
      "loss": 0.56,
      "step": 8800
    },
    {
      "epoch": 0.9439622843672988,
      "grad_norm": 32.87872314453125,
      "learning_rate": 1.8112075431265403e-05,
      "loss": 0.642,
      "step": 8810
    },
    {
      "epoch": 0.9450337512054002,
      "grad_norm": 0.2900996804237366,
      "learning_rate": 1.81099324975892e-05,
      "loss": 0.1374,
      "step": 8820
    },
    {
      "epoch": 0.9461052180435016,
      "grad_norm": 13.615073204040527,
      "learning_rate": 1.8107789563912997e-05,
      "loss": 0.743,
      "step": 8830
    },
    {
      "epoch": 0.9471766848816029,
      "grad_norm": 0.7469921112060547,
      "learning_rate": 1.8105646630236796e-05,
      "loss": 0.5987,
      "step": 8840
    },
    {
      "epoch": 0.9482481517197042,
      "grad_norm": 32.82543182373047,
      "learning_rate": 1.8103503696560592e-05,
      "loss": 0.474,
      "step": 8850
    },
    {
      "epoch": 0.9493196185578057,
      "grad_norm": 23.95206069946289,
      "learning_rate": 1.810136076288439e-05,
      "loss": 0.3667,
      "step": 8860
    },
    {
      "epoch": 0.950391085395907,
      "grad_norm": 0.11461929976940155,
      "learning_rate": 1.8099217829208187e-05,
      "loss": 0.0092,
      "step": 8870
    },
    {
      "epoch": 0.9514625522340083,
      "grad_norm": 18.098636627197266,
      "learning_rate": 1.8097074895531986e-05,
      "loss": 1.014,
      "step": 8880
    },
    {
      "epoch": 0.9525340190721098,
      "grad_norm": 0.06278667598962784,
      "learning_rate": 1.809493196185578e-05,
      "loss": 0.5455,
      "step": 8890
    },
    {
      "epoch": 0.9536054859102111,
      "grad_norm": 0.10472467541694641,
      "learning_rate": 1.809278902817958e-05,
      "loss": 0.729,
      "step": 8900
    },
    {
      "epoch": 0.9546769527483124,
      "grad_norm": 0.4636676609516144,
      "learning_rate": 1.8090646094503376e-05,
      "loss": 0.7688,
      "step": 8910
    },
    {
      "epoch": 0.9557484195864138,
      "grad_norm": 0.3325985372066498,
      "learning_rate": 1.8088503160827172e-05,
      "loss": 0.5088,
      "step": 8920
    },
    {
      "epoch": 0.9568198864245152,
      "grad_norm": 25.092884063720703,
      "learning_rate": 1.808636022715097e-05,
      "loss": 0.3101,
      "step": 8930
    },
    {
      "epoch": 0.9578913532626165,
      "grad_norm": 0.18349234759807587,
      "learning_rate": 1.808421729347477e-05,
      "loss": 0.4239,
      "step": 8940
    },
    {
      "epoch": 0.9589628201007179,
      "grad_norm": 0.4438632130622864,
      "learning_rate": 1.8082074359798566e-05,
      "loss": 0.4254,
      "step": 8950
    },
    {
      "epoch": 0.9600342869388192,
      "grad_norm": 18.35342788696289,
      "learning_rate": 1.8079931426122365e-05,
      "loss": 0.4291,
      "step": 8960
    },
    {
      "epoch": 0.9611057537769206,
      "grad_norm": 0.18074873089790344,
      "learning_rate": 1.807778849244616e-05,
      "loss": 0.2846,
      "step": 8970
    },
    {
      "epoch": 0.962177220615022,
      "grad_norm": 0.15787100791931152,
      "learning_rate": 1.807564555876996e-05,
      "loss": 0.647,
      "step": 8980
    },
    {
      "epoch": 0.9632486874531233,
      "grad_norm": 1.001586675643921,
      "learning_rate": 1.8073502625093755e-05,
      "loss": 0.1936,
      "step": 8990
    },
    {
      "epoch": 0.9643201542912246,
      "grad_norm": 43.74546432495117,
      "learning_rate": 1.807135969141755e-05,
      "loss": 0.7156,
      "step": 9000
    },
    {
      "epoch": 0.9653916211293261,
      "grad_norm": 28.732280731201172,
      "learning_rate": 1.806921675774135e-05,
      "loss": 1.2659,
      "step": 9010
    },
    {
      "epoch": 0.9664630879674274,
      "grad_norm": 16.523221969604492,
      "learning_rate": 1.8067073824065145e-05,
      "loss": 0.4765,
      "step": 9020
    },
    {
      "epoch": 0.9675345548055287,
      "grad_norm": 19.499380111694336,
      "learning_rate": 1.8064930890388944e-05,
      "loss": 0.6519,
      "step": 9030
    },
    {
      "epoch": 0.9686060216436301,
      "grad_norm": 0.3312181830406189,
      "learning_rate": 1.806278795671274e-05,
      "loss": 0.5186,
      "step": 9040
    },
    {
      "epoch": 0.9696774884817315,
      "grad_norm": 0.3350069522857666,
      "learning_rate": 1.806064502303654e-05,
      "loss": 0.5631,
      "step": 9050
    },
    {
      "epoch": 0.9707489553198329,
      "grad_norm": 1.7704215049743652,
      "learning_rate": 1.8058502089360338e-05,
      "loss": 0.1217,
      "step": 9060
    },
    {
      "epoch": 0.9718204221579342,
      "grad_norm": 45.06884765625,
      "learning_rate": 1.8056359155684134e-05,
      "loss": 0.3713,
      "step": 9070
    },
    {
      "epoch": 0.9728918889960356,
      "grad_norm": 24.740131378173828,
      "learning_rate": 1.805421622200793e-05,
      "loss": 0.3195,
      "step": 9080
    },
    {
      "epoch": 0.973963355834137,
      "grad_norm": 1.4822578430175781,
      "learning_rate": 1.805207328833173e-05,
      "loss": 0.3522,
      "step": 9090
    },
    {
      "epoch": 0.9750348226722383,
      "grad_norm": 0.18602102994918823,
      "learning_rate": 1.8049930354655524e-05,
      "loss": 0.9458,
      "step": 9100
    },
    {
      "epoch": 0.9761062895103396,
      "grad_norm": 0.11200335621833801,
      "learning_rate": 1.804778742097932e-05,
      "loss": 0.0818,
      "step": 9110
    },
    {
      "epoch": 0.9771777563484411,
      "grad_norm": 0.10311983525753021,
      "learning_rate": 1.804564448730312e-05,
      "loss": 0.2215,
      "step": 9120
    },
    {
      "epoch": 0.9782492231865424,
      "grad_norm": 27.222532272338867,
      "learning_rate": 1.8043501553626918e-05,
      "loss": 0.8633,
      "step": 9130
    },
    {
      "epoch": 0.9793206900246437,
      "grad_norm": 2.055668354034424,
      "learning_rate": 1.8041358619950714e-05,
      "loss": 0.3157,
      "step": 9140
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.31495440006256104,
      "learning_rate": 1.8039215686274513e-05,
      "loss": 0.2466,
      "step": 9150
    },
    {
      "epoch": 0.9814636237008465,
      "grad_norm": 20.727256774902344,
      "learning_rate": 1.803707275259831e-05,
      "loss": 0.8217,
      "step": 9160
    },
    {
      "epoch": 0.9825350905389478,
      "grad_norm": 17.595199584960938,
      "learning_rate": 1.8034929818922107e-05,
      "loss": 0.3631,
      "step": 9170
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 0.15331946313381195,
      "learning_rate": 1.8032786885245903e-05,
      "loss": 0.6731,
      "step": 9180
    },
    {
      "epoch": 0.9846780242151505,
      "grad_norm": 0.20207791030406952,
      "learning_rate": 1.80306439515697e-05,
      "loss": 0.1179,
      "step": 9190
    },
    {
      "epoch": 0.9857494910532519,
      "grad_norm": 0.3169669508934021,
      "learning_rate": 1.8028501017893498e-05,
      "loss": 0.2193,
      "step": 9200
    },
    {
      "epoch": 0.9868209578913533,
      "grad_norm": 0.1356709748506546,
      "learning_rate": 1.8026358084217293e-05,
      "loss": 0.8518,
      "step": 9210
    },
    {
      "epoch": 0.9878924247294546,
      "grad_norm": 0.2899869382381439,
      "learning_rate": 1.8024215150541093e-05,
      "loss": 0.1739,
      "step": 9220
    },
    {
      "epoch": 0.9889638915675559,
      "grad_norm": 21.802873611450195,
      "learning_rate": 1.8022072216864888e-05,
      "loss": 0.5663,
      "step": 9230
    },
    {
      "epoch": 0.9900353584056574,
      "grad_norm": 0.30712890625,
      "learning_rate": 1.8019929283188687e-05,
      "loss": 0.1895,
      "step": 9240
    },
    {
      "epoch": 0.9911068252437587,
      "grad_norm": 0.12308339029550552,
      "learning_rate": 1.8017786349512486e-05,
      "loss": 0.7881,
      "step": 9250
    },
    {
      "epoch": 0.99217829208186,
      "grad_norm": 0.31440311670303345,
      "learning_rate": 1.8015643415836282e-05,
      "loss": 0.6497,
      "step": 9260
    },
    {
      "epoch": 0.9932497589199615,
      "grad_norm": 32.138023376464844,
      "learning_rate": 1.8013500482160078e-05,
      "loss": 0.8316,
      "step": 9270
    },
    {
      "epoch": 0.9943212257580628,
      "grad_norm": 0.5118957757949829,
      "learning_rate": 1.8011357548483877e-05,
      "loss": 0.4066,
      "step": 9280
    },
    {
      "epoch": 0.9953926925961641,
      "grad_norm": 18.15261459350586,
      "learning_rate": 1.8009214614807672e-05,
      "loss": 0.5517,
      "step": 9290
    },
    {
      "epoch": 0.9964641594342655,
      "grad_norm": 20.855823516845703,
      "learning_rate": 1.8007071681131468e-05,
      "loss": 0.4859,
      "step": 9300
    },
    {
      "epoch": 0.9975356262723669,
      "grad_norm": 140.7248992919922,
      "learning_rate": 1.8004928747455267e-05,
      "loss": 0.9065,
      "step": 9310
    },
    {
      "epoch": 0.9986070931104682,
      "grad_norm": 22.11412239074707,
      "learning_rate": 1.8002785813779066e-05,
      "loss": 0.8288,
      "step": 9320
    },
    {
      "epoch": 0.9996785599485696,
      "grad_norm": 0.9953076839447021,
      "learning_rate": 1.8000642880102862e-05,
      "loss": 0.0843,
      "step": 9330
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8685,
      "eval_f1": 0.6612279948475741,
      "eval_loss": 0.4785381555557251,
      "eval_precision": 0.6609442060085837,
      "eval_recall": 0.6615120274914089,
      "eval_runtime": 477.8601,
      "eval_samples_per_second": 12.556,
      "eval_steps_per_second": 4.185,
      "step": 9333
    },
    {
      "epoch": 1.000750026786671,
      "grad_norm": 30.854415893554688,
      "learning_rate": 1.799849994642666e-05,
      "loss": 0.6925,
      "step": 9340
    },
    {
      "epoch": 1.0018214936247722,
      "grad_norm": 18.84004783630371,
      "learning_rate": 1.7996357012750456e-05,
      "loss": 0.5922,
      "step": 9350
    },
    {
      "epoch": 1.0028929604628736,
      "grad_norm": 0.03981829434633255,
      "learning_rate": 1.7994214079074256e-05,
      "loss": 0.4763,
      "step": 9360
    },
    {
      "epoch": 1.0039644273009751,
      "grad_norm": 0.5526502728462219,
      "learning_rate": 1.799207114539805e-05,
      "loss": 0.321,
      "step": 9370
    },
    {
      "epoch": 1.0050358941390765,
      "grad_norm": 0.06256645172834396,
      "learning_rate": 1.7989928211721847e-05,
      "loss": 0.428,
      "step": 9380
    },
    {
      "epoch": 1.0061073609771778,
      "grad_norm": 0.053296130150556564,
      "learning_rate": 1.7987785278045646e-05,
      "loss": 0.3978,
      "step": 9390
    },
    {
      "epoch": 1.0071788278152791,
      "grad_norm": 0.01731555350124836,
      "learning_rate": 1.798564234436944e-05,
      "loss": 0.2631,
      "step": 9400
    },
    {
      "epoch": 1.0082502946533805,
      "grad_norm": 1.2372967004776,
      "learning_rate": 1.798349941069324e-05,
      "loss": 0.0177,
      "step": 9410
    },
    {
      "epoch": 1.0093217614914818,
      "grad_norm": 0.3696568012237549,
      "learning_rate": 1.7981356477017036e-05,
      "loss": 0.6162,
      "step": 9420
    },
    {
      "epoch": 1.0103932283295831,
      "grad_norm": 0.07073745876550674,
      "learning_rate": 1.7979213543340835e-05,
      "loss": 0.6747,
      "step": 9430
    },
    {
      "epoch": 1.0114646951676847,
      "grad_norm": 0.4087330102920532,
      "learning_rate": 1.7977070609664634e-05,
      "loss": 0.4844,
      "step": 9440
    },
    {
      "epoch": 1.012536162005786,
      "grad_norm": 0.09123358130455017,
      "learning_rate": 1.797492767598843e-05,
      "loss": 0.0503,
      "step": 9450
    },
    {
      "epoch": 1.0136076288438873,
      "grad_norm": 0.21177667379379272,
      "learning_rate": 1.7972784742312226e-05,
      "loss": 0.2909,
      "step": 9460
    },
    {
      "epoch": 1.0146790956819887,
      "grad_norm": 0.2954001724720001,
      "learning_rate": 1.7970641808636025e-05,
      "loss": 0.3754,
      "step": 9470
    },
    {
      "epoch": 1.01575056252009,
      "grad_norm": 0.14534339308738708,
      "learning_rate": 1.796849887495982e-05,
      "loss": 0.5506,
      "step": 9480
    },
    {
      "epoch": 1.0168220293581913,
      "grad_norm": 0.2781641185283661,
      "learning_rate": 1.796635594128362e-05,
      "loss": 0.5203,
      "step": 9490
    },
    {
      "epoch": 1.0178934961962927,
      "grad_norm": 8.317448616027832,
      "learning_rate": 1.7964213007607415e-05,
      "loss": 0.4076,
      "step": 9500
    },
    {
      "epoch": 1.018964963034394,
      "grad_norm": 12.150290489196777,
      "learning_rate": 1.7962070073931214e-05,
      "loss": 0.6305,
      "step": 9510
    },
    {
      "epoch": 1.0200364298724955,
      "grad_norm": 0.0747707188129425,
      "learning_rate": 1.795992714025501e-05,
      "loss": 0.1884,
      "step": 9520
    },
    {
      "epoch": 1.0211078967105969,
      "grad_norm": 17.362506866455078,
      "learning_rate": 1.795778420657881e-05,
      "loss": 0.6378,
      "step": 9530
    },
    {
      "epoch": 1.0221793635486982,
      "grad_norm": 0.861353874206543,
      "learning_rate": 1.7955641272902605e-05,
      "loss": 0.3493,
      "step": 9540
    },
    {
      "epoch": 1.0232508303867995,
      "grad_norm": 0.2086198627948761,
      "learning_rate": 1.7953498339226404e-05,
      "loss": 0.6568,
      "step": 9550
    },
    {
      "epoch": 1.0243222972249009,
      "grad_norm": 0.2089112251996994,
      "learning_rate": 1.79513554055502e-05,
      "loss": 0.2522,
      "step": 9560
    },
    {
      "epoch": 1.0253937640630022,
      "grad_norm": 0.18577292561531067,
      "learning_rate": 1.7949212471873998e-05,
      "loss": 0.643,
      "step": 9570
    },
    {
      "epoch": 1.0264652309011035,
      "grad_norm": 0.42627766728401184,
      "learning_rate": 1.7947069538197794e-05,
      "loss": 0.295,
      "step": 9580
    },
    {
      "epoch": 1.0275366977392049,
      "grad_norm": 0.2717307209968567,
      "learning_rate": 1.794492660452159e-05,
      "loss": 0.1681,
      "step": 9590
    },
    {
      "epoch": 1.0286081645773064,
      "grad_norm": 0.5579209923744202,
      "learning_rate": 1.794278367084539e-05,
      "loss": 0.4587,
      "step": 9600
    },
    {
      "epoch": 1.0296796314154077,
      "grad_norm": 11.360342979431152,
      "learning_rate": 1.7940640737169184e-05,
      "loss": 0.188,
      "step": 9610
    },
    {
      "epoch": 1.030751098253509,
      "grad_norm": 26.158340454101562,
      "learning_rate": 1.7938497803492983e-05,
      "loss": 0.75,
      "step": 9620
    },
    {
      "epoch": 1.0318225650916104,
      "grad_norm": 21.381948471069336,
      "learning_rate": 1.7936354869816782e-05,
      "loss": 0.646,
      "step": 9630
    },
    {
      "epoch": 1.0328940319297117,
      "grad_norm": 0.059790659695863724,
      "learning_rate": 1.7934211936140578e-05,
      "loss": 0.0733,
      "step": 9640
    },
    {
      "epoch": 1.033965498767813,
      "grad_norm": 0.03576645255088806,
      "learning_rate": 1.7932069002464377e-05,
      "loss": 0.1828,
      "step": 9650
    },
    {
      "epoch": 1.0350369656059144,
      "grad_norm": 0.10963182151317596,
      "learning_rate": 1.7929926068788173e-05,
      "loss": 1.095,
      "step": 9660
    },
    {
      "epoch": 1.036108432444016,
      "grad_norm": 0.04010525718331337,
      "learning_rate": 1.792778313511197e-05,
      "loss": 0.8389,
      "step": 9670
    },
    {
      "epoch": 1.0371798992821173,
      "grad_norm": 20.307767868041992,
      "learning_rate": 1.7925640201435768e-05,
      "loss": 0.6123,
      "step": 9680
    },
    {
      "epoch": 1.0382513661202186,
      "grad_norm": 0.504808247089386,
      "learning_rate": 1.7923497267759563e-05,
      "loss": 0.6203,
      "step": 9690
    },
    {
      "epoch": 1.03932283295832,
      "grad_norm": 14.371186256408691,
      "learning_rate": 1.7921354334083362e-05,
      "loss": 0.4905,
      "step": 9700
    },
    {
      "epoch": 1.0403942997964213,
      "grad_norm": 0.46039167046546936,
      "learning_rate": 1.7919211400407158e-05,
      "loss": 0.5559,
      "step": 9710
    },
    {
      "epoch": 1.0414657666345226,
      "grad_norm": 0.26277291774749756,
      "learning_rate": 1.7917068466730957e-05,
      "loss": 0.1816,
      "step": 9720
    },
    {
      "epoch": 1.042537233472624,
      "grad_norm": 0.07045876234769821,
      "learning_rate": 1.7914925533054756e-05,
      "loss": 0.2742,
      "step": 9730
    },
    {
      "epoch": 1.0436087003107253,
      "grad_norm": 149.40025329589844,
      "learning_rate": 1.791278259937855e-05,
      "loss": 0.238,
      "step": 9740
    },
    {
      "epoch": 1.0446801671488268,
      "grad_norm": 0.02259637415409088,
      "learning_rate": 1.7910639665702347e-05,
      "loss": 0.6402,
      "step": 9750
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.23130996525287628,
      "learning_rate": 1.7908496732026146e-05,
      "loss": 0.4074,
      "step": 9760
    },
    {
      "epoch": 1.0468231008250295,
      "grad_norm": 1.1957356929779053,
      "learning_rate": 1.7906353798349942e-05,
      "loss": 0.1482,
      "step": 9770
    },
    {
      "epoch": 1.0478945676631308,
      "grad_norm": 15.8410062789917,
      "learning_rate": 1.7904210864673738e-05,
      "loss": 0.6663,
      "step": 9780
    },
    {
      "epoch": 1.0489660345012322,
      "grad_norm": 0.20306575298309326,
      "learning_rate": 1.7902067930997537e-05,
      "loss": 0.3295,
      "step": 9790
    },
    {
      "epoch": 1.0500375013393335,
      "grad_norm": 0.1374938040971756,
      "learning_rate": 1.7899924997321332e-05,
      "loss": 0.7889,
      "step": 9800
    },
    {
      "epoch": 1.0511089681774348,
      "grad_norm": 0.23791909217834473,
      "learning_rate": 1.789778206364513e-05,
      "loss": 0.3495,
      "step": 9810
    },
    {
      "epoch": 1.0521804350155364,
      "grad_norm": 0.10709680616855621,
      "learning_rate": 1.789563912996893e-05,
      "loss": 0.1147,
      "step": 9820
    },
    {
      "epoch": 1.0532519018536377,
      "grad_norm": 0.12371545284986496,
      "learning_rate": 1.7893496196292726e-05,
      "loss": 0.1635,
      "step": 9830
    },
    {
      "epoch": 1.054323368691739,
      "grad_norm": 0.8778971433639526,
      "learning_rate": 1.7891353262616525e-05,
      "loss": 0.5869,
      "step": 9840
    },
    {
      "epoch": 1.0553948355298404,
      "grad_norm": 0.13046292960643768,
      "learning_rate": 1.788921032894032e-05,
      "loss": 0.6056,
      "step": 9850
    },
    {
      "epoch": 1.0564663023679417,
      "grad_norm": 0.22748929262161255,
      "learning_rate": 1.7887067395264117e-05,
      "loss": 0.279,
      "step": 9860
    },
    {
      "epoch": 1.057537769206043,
      "grad_norm": 0.1841910034418106,
      "learning_rate": 1.7884924461587916e-05,
      "loss": 0.8738,
      "step": 9870
    },
    {
      "epoch": 1.0586092360441444,
      "grad_norm": 0.19798535108566284,
      "learning_rate": 1.788278152791171e-05,
      "loss": 0.4941,
      "step": 9880
    },
    {
      "epoch": 1.0596807028822457,
      "grad_norm": 17.805152893066406,
      "learning_rate": 1.788063859423551e-05,
      "loss": 0.4744,
      "step": 9890
    },
    {
      "epoch": 1.0607521697203472,
      "grad_norm": 0.1731361746788025,
      "learning_rate": 1.7878495660559306e-05,
      "loss": 0.6191,
      "step": 9900
    },
    {
      "epoch": 1.0618236365584486,
      "grad_norm": 0.05673214793205261,
      "learning_rate": 1.7876352726883105e-05,
      "loss": 0.3968,
      "step": 9910
    },
    {
      "epoch": 1.06289510339655,
      "grad_norm": 16.193065643310547,
      "learning_rate": 1.7874209793206904e-05,
      "loss": 0.4852,
      "step": 9920
    },
    {
      "epoch": 1.0639665702346512,
      "grad_norm": 18.08641815185547,
      "learning_rate": 1.78720668595307e-05,
      "loss": 0.5111,
      "step": 9930
    },
    {
      "epoch": 1.0650380370727526,
      "grad_norm": 0.3501216769218445,
      "learning_rate": 1.7869923925854495e-05,
      "loss": 0.5054,
      "step": 9940
    },
    {
      "epoch": 1.066109503910854,
      "grad_norm": 0.34895870089530945,
      "learning_rate": 1.7867780992178294e-05,
      "loss": 0.6342,
      "step": 9950
    },
    {
      "epoch": 1.0671809707489552,
      "grad_norm": 0.1993485987186432,
      "learning_rate": 1.786563805850209e-05,
      "loss": 0.5785,
      "step": 9960
    },
    {
      "epoch": 1.0682524375870566,
      "grad_norm": 0.5756112337112427,
      "learning_rate": 1.7863495124825886e-05,
      "loss": 0.6642,
      "step": 9970
    },
    {
      "epoch": 1.0693239044251581,
      "grad_norm": 60.08773422241211,
      "learning_rate": 1.7861352191149685e-05,
      "loss": 0.113,
      "step": 9980
    },
    {
      "epoch": 1.0703953712632595,
      "grad_norm": 0.13870869576931,
      "learning_rate": 1.785920925747348e-05,
      "loss": 0.6199,
      "step": 9990
    },
    {
      "epoch": 1.0714668381013608,
      "grad_norm": 0.03464771807193756,
      "learning_rate": 1.785706632379728e-05,
      "loss": 0.4436,
      "step": 10000
    },
    {
      "epoch": 1.0725383049394621,
      "grad_norm": 21.155475616455078,
      "learning_rate": 1.785492339012108e-05,
      "loss": 0.549,
      "step": 10010
    },
    {
      "epoch": 1.0736097717775634,
      "grad_norm": 23.517093658447266,
      "learning_rate": 1.7852780456444874e-05,
      "loss": 0.7163,
      "step": 10020
    },
    {
      "epoch": 1.0746812386156648,
      "grad_norm": 28.623355865478516,
      "learning_rate": 1.7850637522768673e-05,
      "loss": 0.3194,
      "step": 10030
    },
    {
      "epoch": 1.0757527054537661,
      "grad_norm": 0.18242067098617554,
      "learning_rate": 1.784849458909247e-05,
      "loss": 0.344,
      "step": 10040
    },
    {
      "epoch": 1.0768241722918677,
      "grad_norm": 1.1646133661270142,
      "learning_rate": 1.7846351655416265e-05,
      "loss": 0.5853,
      "step": 10050
    },
    {
      "epoch": 1.077895639129969,
      "grad_norm": 21.533449172973633,
      "learning_rate": 1.7844208721740064e-05,
      "loss": 0.3914,
      "step": 10060
    },
    {
      "epoch": 1.0789671059680703,
      "grad_norm": 0.4773079752922058,
      "learning_rate": 1.784206578806386e-05,
      "loss": 0.7411,
      "step": 10070
    },
    {
      "epoch": 1.0800385728061717,
      "grad_norm": 0.540497899055481,
      "learning_rate": 1.783992285438766e-05,
      "loss": 0.5748,
      "step": 10080
    },
    {
      "epoch": 1.081110039644273,
      "grad_norm": 0.5751610398292542,
      "learning_rate": 1.7837779920711454e-05,
      "loss": 0.2906,
      "step": 10090
    },
    {
      "epoch": 1.0821815064823743,
      "grad_norm": 0.4395952820777893,
      "learning_rate": 1.7835636987035253e-05,
      "loss": 0.4202,
      "step": 10100
    },
    {
      "epoch": 1.0832529733204757,
      "grad_norm": 15.944160461425781,
      "learning_rate": 1.7833494053359052e-05,
      "loss": 0.5653,
      "step": 10110
    },
    {
      "epoch": 1.0843244401585772,
      "grad_norm": 0.07678813487291336,
      "learning_rate": 1.7831351119682848e-05,
      "loss": 0.5429,
      "step": 10120
    },
    {
      "epoch": 1.0853959069966785,
      "grad_norm": 0.10790987312793732,
      "learning_rate": 1.7829208186006643e-05,
      "loss": 0.6252,
      "step": 10130
    },
    {
      "epoch": 1.0864673738347799,
      "grad_norm": 0.08369312435388565,
      "learning_rate": 1.7827065252330442e-05,
      "loss": 0.3142,
      "step": 10140
    },
    {
      "epoch": 1.0875388406728812,
      "grad_norm": 28.552562713623047,
      "learning_rate": 1.7824922318654238e-05,
      "loss": 1.3588,
      "step": 10150
    },
    {
      "epoch": 1.0886103075109825,
      "grad_norm": 0.9801430106163025,
      "learning_rate": 1.7822779384978037e-05,
      "loss": 0.2225,
      "step": 10160
    },
    {
      "epoch": 1.0896817743490839,
      "grad_norm": 1.6225621700286865,
      "learning_rate": 1.7820636451301833e-05,
      "loss": 0.3769,
      "step": 10170
    },
    {
      "epoch": 1.0907532411871852,
      "grad_norm": 0.06211472675204277,
      "learning_rate": 1.781849351762563e-05,
      "loss": 0.2347,
      "step": 10180
    },
    {
      "epoch": 1.0918247080252865,
      "grad_norm": 0.05313415080308914,
      "learning_rate": 1.7816350583949428e-05,
      "loss": 0.448,
      "step": 10190
    },
    {
      "epoch": 1.092896174863388,
      "grad_norm": 0.21133148670196533,
      "learning_rate": 1.7814207650273227e-05,
      "loss": 0.5517,
      "step": 10200
    },
    {
      "epoch": 1.0939676417014894,
      "grad_norm": 18.95749282836914,
      "learning_rate": 1.7812064716597022e-05,
      "loss": 0.2116,
      "step": 10210
    },
    {
      "epoch": 1.0950391085395907,
      "grad_norm": 0.08571282029151917,
      "learning_rate": 1.780992178292082e-05,
      "loss": 0.1492,
      "step": 10220
    },
    {
      "epoch": 1.096110575377692,
      "grad_norm": 18.909379959106445,
      "learning_rate": 1.7807778849244617e-05,
      "loss": 0.3661,
      "step": 10230
    },
    {
      "epoch": 1.0971820422157934,
      "grad_norm": 23.387310028076172,
      "learning_rate": 1.7805635915568416e-05,
      "loss": 0.8568,
      "step": 10240
    },
    {
      "epoch": 1.0982535090538947,
      "grad_norm": 0.16841863095760345,
      "learning_rate": 1.7803492981892212e-05,
      "loss": 0.6098,
      "step": 10250
    },
    {
      "epoch": 1.099324975891996,
      "grad_norm": 24.73724365234375,
      "learning_rate": 1.7801350048216007e-05,
      "loss": 0.1999,
      "step": 10260
    },
    {
      "epoch": 1.1003964427300974,
      "grad_norm": 0.07095597684383392,
      "learning_rate": 1.7799207114539806e-05,
      "loss": 0.6114,
      "step": 10270
    },
    {
      "epoch": 1.101467909568199,
      "grad_norm": 0.27678588032722473,
      "learning_rate": 1.7797064180863602e-05,
      "loss": 0.4847,
      "step": 10280
    },
    {
      "epoch": 1.1025393764063003,
      "grad_norm": 23.710201263427734,
      "learning_rate": 1.77949212471874e-05,
      "loss": 0.4016,
      "step": 10290
    },
    {
      "epoch": 1.1036108432444016,
      "grad_norm": 0.2625787854194641,
      "learning_rate": 1.77927783135112e-05,
      "loss": 0.1383,
      "step": 10300
    },
    {
      "epoch": 1.104682310082503,
      "grad_norm": 0.20570108294487,
      "learning_rate": 1.7790635379834996e-05,
      "loss": 0.5525,
      "step": 10310
    },
    {
      "epoch": 1.1057537769206043,
      "grad_norm": 151.3153076171875,
      "learning_rate": 1.7788492446158795e-05,
      "loss": 0.6967,
      "step": 10320
    },
    {
      "epoch": 1.1068252437587056,
      "grad_norm": 0.13009999692440033,
      "learning_rate": 1.778634951248259e-05,
      "loss": 0.3056,
      "step": 10330
    },
    {
      "epoch": 1.107896710596807,
      "grad_norm": 21.13576316833496,
      "learning_rate": 1.7784206578806386e-05,
      "loss": 0.7746,
      "step": 10340
    },
    {
      "epoch": 1.1089681774349085,
      "grad_norm": 0.551275908946991,
      "learning_rate": 1.7782063645130185e-05,
      "loss": 0.2201,
      "step": 10350
    },
    {
      "epoch": 1.1100396442730098,
      "grad_norm": 13.864591598510742,
      "learning_rate": 1.777992071145398e-05,
      "loss": 0.4242,
      "step": 10360
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.408611536026001,
      "learning_rate": 1.7777777777777777e-05,
      "loss": 0.5114,
      "step": 10370
    },
    {
      "epoch": 1.1121825779492125,
      "grad_norm": 39.71931457519531,
      "learning_rate": 1.7775634844101576e-05,
      "loss": 0.9092,
      "step": 10380
    },
    {
      "epoch": 1.1132540447873138,
      "grad_norm": 2.7542552947998047,
      "learning_rate": 1.7773491910425375e-05,
      "loss": 0.4863,
      "step": 10390
    },
    {
      "epoch": 1.1143255116254152,
      "grad_norm": 1.7780349254608154,
      "learning_rate": 1.777134897674917e-05,
      "loss": 0.367,
      "step": 10400
    },
    {
      "epoch": 1.1153969784635165,
      "grad_norm": 0.14869849383831024,
      "learning_rate": 1.776920604307297e-05,
      "loss": 0.0039,
      "step": 10410
    },
    {
      "epoch": 1.1164684453016178,
      "grad_norm": 24.987939834594727,
      "learning_rate": 1.7767063109396765e-05,
      "loss": 0.4337,
      "step": 10420
    },
    {
      "epoch": 1.1175399121397194,
      "grad_norm": 0.28030839562416077,
      "learning_rate": 1.7764920175720564e-05,
      "loss": 0.2109,
      "step": 10430
    },
    {
      "epoch": 1.1186113789778207,
      "grad_norm": 38.43660354614258,
      "learning_rate": 1.776277724204436e-05,
      "loss": 0.7643,
      "step": 10440
    },
    {
      "epoch": 1.119682845815922,
      "grad_norm": 0.34681442379951477,
      "learning_rate": 1.7760634308368155e-05,
      "loss": 0.4756,
      "step": 10450
    },
    {
      "epoch": 1.1207543126540234,
      "grad_norm": 0.4453202784061432,
      "learning_rate": 1.7758491374691954e-05,
      "loss": 0.2325,
      "step": 10460
    },
    {
      "epoch": 1.1218257794921247,
      "grad_norm": 0.14606966078281403,
      "learning_rate": 1.775634844101575e-05,
      "loss": 0.261,
      "step": 10470
    },
    {
      "epoch": 1.122897246330226,
      "grad_norm": 31.56191062927246,
      "learning_rate": 1.775420550733955e-05,
      "loss": 0.5015,
      "step": 10480
    },
    {
      "epoch": 1.1239687131683274,
      "grad_norm": 0.21868985891342163,
      "learning_rate": 1.7752062573663348e-05,
      "loss": 0.6125,
      "step": 10490
    },
    {
      "epoch": 1.1250401800064287,
      "grad_norm": 16.017337799072266,
      "learning_rate": 1.7749919639987144e-05,
      "loss": 0.6609,
      "step": 10500
    },
    {
      "epoch": 1.1261116468445302,
      "grad_norm": 0.08238574117422104,
      "learning_rate": 1.7747776706310943e-05,
      "loss": 0.3415,
      "step": 10510
    },
    {
      "epoch": 1.1271831136826316,
      "grad_norm": 0.1410498321056366,
      "learning_rate": 1.774563377263474e-05,
      "loss": 0.5375,
      "step": 10520
    },
    {
      "epoch": 1.128254580520733,
      "grad_norm": 0.04607277736067772,
      "learning_rate": 1.7743490838958534e-05,
      "loss": 0.312,
      "step": 10530
    },
    {
      "epoch": 1.1293260473588342,
      "grad_norm": 0.07887699455022812,
      "learning_rate": 1.7741347905282333e-05,
      "loss": 0.8584,
      "step": 10540
    },
    {
      "epoch": 1.1303975141969356,
      "grad_norm": 0.2639811635017395,
      "learning_rate": 1.773920497160613e-05,
      "loss": 0.6478,
      "step": 10550
    },
    {
      "epoch": 1.131468981035037,
      "grad_norm": 0.253872811794281,
      "learning_rate": 1.7737062037929928e-05,
      "loss": 0.0728,
      "step": 10560
    },
    {
      "epoch": 1.1325404478731382,
      "grad_norm": 15.272833824157715,
      "learning_rate": 1.7734919104253724e-05,
      "loss": 0.6093,
      "step": 10570
    },
    {
      "epoch": 1.1336119147112398,
      "grad_norm": 0.14220920205116272,
      "learning_rate": 1.7732776170577523e-05,
      "loss": 0.8736,
      "step": 10580
    },
    {
      "epoch": 1.1346833815493411,
      "grad_norm": 0.14073017239570618,
      "learning_rate": 1.773063323690132e-05,
      "loss": 0.6116,
      "step": 10590
    },
    {
      "epoch": 1.1357548483874425,
      "grad_norm": 0.35152196884155273,
      "learning_rate": 1.7728490303225117e-05,
      "loss": 0.0627,
      "step": 10600
    },
    {
      "epoch": 1.1368263152255438,
      "grad_norm": 19.634313583374023,
      "learning_rate": 1.7726347369548913e-05,
      "loss": 0.3854,
      "step": 10610
    },
    {
      "epoch": 1.1378977820636451,
      "grad_norm": 18.255516052246094,
      "learning_rate": 1.7724204435872712e-05,
      "loss": 0.8369,
      "step": 10620
    },
    {
      "epoch": 1.1389692489017464,
      "grad_norm": 37.985565185546875,
      "learning_rate": 1.7722061502196508e-05,
      "loss": 0.343,
      "step": 10630
    },
    {
      "epoch": 1.1400407157398478,
      "grad_norm": 0.2269720584154129,
      "learning_rate": 1.7719918568520307e-05,
      "loss": 0.5532,
      "step": 10640
    },
    {
      "epoch": 1.1411121825779493,
      "grad_norm": 1.990171194076538,
      "learning_rate": 1.7717775634844103e-05,
      "loss": 0.6229,
      "step": 10650
    },
    {
      "epoch": 1.1421836494160507,
      "grad_norm": 0.8450679183006287,
      "learning_rate": 1.7715632701167898e-05,
      "loss": 0.2838,
      "step": 10660
    },
    {
      "epoch": 1.143255116254152,
      "grad_norm": 0.17275987565517426,
      "learning_rate": 1.7713489767491697e-05,
      "loss": 0.4062,
      "step": 10670
    },
    {
      "epoch": 1.1443265830922533,
      "grad_norm": 56.48804473876953,
      "learning_rate": 1.7711346833815496e-05,
      "loss": 0.4349,
      "step": 10680
    },
    {
      "epoch": 1.1453980499303547,
      "grad_norm": 1.0282557010650635,
      "learning_rate": 1.7709203900139292e-05,
      "loss": 0.3513,
      "step": 10690
    },
    {
      "epoch": 1.146469516768456,
      "grad_norm": 0.25638988614082336,
      "learning_rate": 1.770706096646309e-05,
      "loss": 0.3648,
      "step": 10700
    },
    {
      "epoch": 1.1475409836065573,
      "grad_norm": 0.06151591241359711,
      "learning_rate": 1.7704918032786887e-05,
      "loss": 0.1546,
      "step": 10710
    },
    {
      "epoch": 1.1486124504446587,
      "grad_norm": 21.44181251525879,
      "learning_rate": 1.7702775099110686e-05,
      "loss": 0.6042,
      "step": 10720
    },
    {
      "epoch": 1.14968391728276,
      "grad_norm": 0.6955683827400208,
      "learning_rate": 1.770063216543448e-05,
      "loss": 0.2441,
      "step": 10730
    },
    {
      "epoch": 1.1507553841208615,
      "grad_norm": 0.11343463510274887,
      "learning_rate": 1.7698489231758277e-05,
      "loss": 0.1963,
      "step": 10740
    },
    {
      "epoch": 1.1518268509589629,
      "grad_norm": 0.21741007268428802,
      "learning_rate": 1.7696346298082076e-05,
      "loss": 0.6991,
      "step": 10750
    },
    {
      "epoch": 1.1528983177970642,
      "grad_norm": 24.575746536254883,
      "learning_rate": 1.7694203364405872e-05,
      "loss": 0.1271,
      "step": 10760
    },
    {
      "epoch": 1.1539697846351655,
      "grad_norm": 5.837577819824219,
      "learning_rate": 1.769206043072967e-05,
      "loss": 0.2264,
      "step": 10770
    },
    {
      "epoch": 1.1550412514732669,
      "grad_norm": 4.276075839996338,
      "learning_rate": 1.7689917497053466e-05,
      "loss": 0.5822,
      "step": 10780
    },
    {
      "epoch": 1.1561127183113682,
      "grad_norm": 0.08376721292734146,
      "learning_rate": 1.7687774563377266e-05,
      "loss": 0.2973,
      "step": 10790
    },
    {
      "epoch": 1.1571841851494695,
      "grad_norm": 0.11167338490486145,
      "learning_rate": 1.7685631629701065e-05,
      "loss": 0.2002,
      "step": 10800
    },
    {
      "epoch": 1.158255651987571,
      "grad_norm": 0.2280641794204712,
      "learning_rate": 1.768348869602486e-05,
      "loss": 1.0691,
      "step": 10810
    },
    {
      "epoch": 1.1593271188256724,
      "grad_norm": 0.3084421753883362,
      "learning_rate": 1.7681345762348656e-05,
      "loss": 0.8875,
      "step": 10820
    },
    {
      "epoch": 1.1603985856637737,
      "grad_norm": 20.311941146850586,
      "learning_rate": 1.7679202828672455e-05,
      "loss": 0.4318,
      "step": 10830
    },
    {
      "epoch": 1.161470052501875,
      "grad_norm": 0.4338766038417816,
      "learning_rate": 1.767705989499625e-05,
      "loss": 0.2767,
      "step": 10840
    },
    {
      "epoch": 1.1625415193399764,
      "grad_norm": 23.792734146118164,
      "learning_rate": 1.7674916961320046e-05,
      "loss": 0.7033,
      "step": 10850
    },
    {
      "epoch": 1.1636129861780777,
      "grad_norm": 33.5924186706543,
      "learning_rate": 1.7672774027643845e-05,
      "loss": 0.5493,
      "step": 10860
    },
    {
      "epoch": 1.164684453016179,
      "grad_norm": 21.99801254272461,
      "learning_rate": 1.7670631093967644e-05,
      "loss": 0.3693,
      "step": 10870
    },
    {
      "epoch": 1.1657559198542806,
      "grad_norm": 19.350799560546875,
      "learning_rate": 1.766848816029144e-05,
      "loss": 0.5973,
      "step": 10880
    },
    {
      "epoch": 1.166827386692382,
      "grad_norm": 0.06525135040283203,
      "learning_rate": 1.766634522661524e-05,
      "loss": 0.1952,
      "step": 10890
    },
    {
      "epoch": 1.1678988535304833,
      "grad_norm": 0.1380895972251892,
      "learning_rate": 1.7664202292939035e-05,
      "loss": 0.1449,
      "step": 10900
    },
    {
      "epoch": 1.1689703203685846,
      "grad_norm": 0.200051411986351,
      "learning_rate": 1.7662059359262834e-05,
      "loss": 0.529,
      "step": 10910
    },
    {
      "epoch": 1.170041787206686,
      "grad_norm": 0.13794191181659698,
      "learning_rate": 1.765991642558663e-05,
      "loss": 0.1728,
      "step": 10920
    },
    {
      "epoch": 1.1711132540447873,
      "grad_norm": 0.147391676902771,
      "learning_rate": 1.7657773491910425e-05,
      "loss": 0.3575,
      "step": 10930
    },
    {
      "epoch": 1.1721847208828886,
      "grad_norm": 18.34040641784668,
      "learning_rate": 1.7655630558234224e-05,
      "loss": 0.6828,
      "step": 10940
    },
    {
      "epoch": 1.17325618772099,
      "grad_norm": 0.2064039409160614,
      "learning_rate": 1.765348762455802e-05,
      "loss": 0.6677,
      "step": 10950
    },
    {
      "epoch": 1.1743276545590913,
      "grad_norm": 0.3842606246471405,
      "learning_rate": 1.765134469088182e-05,
      "loss": 0.4275,
      "step": 10960
    },
    {
      "epoch": 1.1753991213971928,
      "grad_norm": 0.20802925527095795,
      "learning_rate": 1.7649201757205615e-05,
      "loss": 0.4413,
      "step": 10970
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.3229921758174896,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 0.5538,
      "step": 10980
    },
    {
      "epoch": 1.1775420550733955,
      "grad_norm": 0.3168339431285858,
      "learning_rate": 1.7644915889853213e-05,
      "loss": 0.5812,
      "step": 10990
    },
    {
      "epoch": 1.1786135219114968,
      "grad_norm": 0.3853994607925415,
      "learning_rate": 1.764277295617701e-05,
      "loss": 0.4708,
      "step": 11000
    },
    {
      "epoch": 1.1796849887495982,
      "grad_norm": 18.047409057617188,
      "learning_rate": 1.7640630022500804e-05,
      "loss": 0.4991,
      "step": 11010
    },
    {
      "epoch": 1.1807564555876995,
      "grad_norm": 0.5120272636413574,
      "learning_rate": 1.7638487088824603e-05,
      "loss": 0.4888,
      "step": 11020
    },
    {
      "epoch": 1.1818279224258008,
      "grad_norm": 0.18540453910827637,
      "learning_rate": 1.76363441551484e-05,
      "loss": 0.0082,
      "step": 11030
    },
    {
      "epoch": 1.1828993892639024,
      "grad_norm": 20.44721794128418,
      "learning_rate": 1.7634201221472194e-05,
      "loss": 0.6988,
      "step": 11040
    },
    {
      "epoch": 1.1839708561020037,
      "grad_norm": 0.034783799201250076,
      "learning_rate": 1.7632058287795993e-05,
      "loss": 0.0113,
      "step": 11050
    },
    {
      "epoch": 1.185042322940105,
      "grad_norm": 0.3232516348361969,
      "learning_rate": 1.7629915354119792e-05,
      "loss": 0.9371,
      "step": 11060
    },
    {
      "epoch": 1.1861137897782064,
      "grad_norm": 18.44798469543457,
      "learning_rate": 1.7627772420443588e-05,
      "loss": 0.8393,
      "step": 11070
    },
    {
      "epoch": 1.1871852566163077,
      "grad_norm": 0.16014106571674347,
      "learning_rate": 1.7625629486767387e-05,
      "loss": 0.1954,
      "step": 11080
    },
    {
      "epoch": 1.188256723454409,
      "grad_norm": 0.22209447622299194,
      "learning_rate": 1.7623486553091183e-05,
      "loss": 0.4179,
      "step": 11090
    },
    {
      "epoch": 1.1893281902925104,
      "grad_norm": 26.073986053466797,
      "learning_rate": 1.7621343619414982e-05,
      "loss": 0.8587,
      "step": 11100
    },
    {
      "epoch": 1.190399657130612,
      "grad_norm": 0.36818501353263855,
      "learning_rate": 1.7619200685738778e-05,
      "loss": 0.4934,
      "step": 11110
    },
    {
      "epoch": 1.1914711239687132,
      "grad_norm": 28.091096878051758,
      "learning_rate": 1.7617057752062573e-05,
      "loss": 0.3657,
      "step": 11120
    },
    {
      "epoch": 1.1925425908068146,
      "grad_norm": 23.421022415161133,
      "learning_rate": 1.7614914818386372e-05,
      "loss": 0.4632,
      "step": 11130
    },
    {
      "epoch": 1.193614057644916,
      "grad_norm": 0.08192115277051926,
      "learning_rate": 1.7612771884710168e-05,
      "loss": 0.5494,
      "step": 11140
    },
    {
      "epoch": 1.1946855244830172,
      "grad_norm": 20.16322898864746,
      "learning_rate": 1.7610628951033967e-05,
      "loss": 0.4789,
      "step": 11150
    },
    {
      "epoch": 1.1957569913211186,
      "grad_norm": 0.09062633663415909,
      "learning_rate": 1.7608486017357763e-05,
      "loss": 0.3573,
      "step": 11160
    },
    {
      "epoch": 1.19682845815922,
      "grad_norm": 18.5572566986084,
      "learning_rate": 1.760634308368156e-05,
      "loss": 0.6423,
      "step": 11170
    },
    {
      "epoch": 1.1978999249973215,
      "grad_norm": 0.0863405242562294,
      "learning_rate": 1.760420015000536e-05,
      "loss": 0.3502,
      "step": 11180
    },
    {
      "epoch": 1.1989713918354228,
      "grad_norm": 0.4520246386528015,
      "learning_rate": 1.7602057216329156e-05,
      "loss": 0.3411,
      "step": 11190
    },
    {
      "epoch": 1.2000428586735241,
      "grad_norm": 0.20821185410022736,
      "learning_rate": 1.7599914282652952e-05,
      "loss": 0.103,
      "step": 11200
    },
    {
      "epoch": 1.2011143255116254,
      "grad_norm": 0.15461662411689758,
      "learning_rate": 1.759777134897675e-05,
      "loss": 0.4688,
      "step": 11210
    },
    {
      "epoch": 1.2021857923497268,
      "grad_norm": 22.147045135498047,
      "learning_rate": 1.7595628415300547e-05,
      "loss": 0.9056,
      "step": 11220
    },
    {
      "epoch": 1.203257259187828,
      "grad_norm": 0.10938325524330139,
      "learning_rate": 1.7593485481624346e-05,
      "loss": 0.2834,
      "step": 11230
    },
    {
      "epoch": 1.2043287260259294,
      "grad_norm": 17.83697509765625,
      "learning_rate": 1.759134254794814e-05,
      "loss": 0.7721,
      "step": 11240
    },
    {
      "epoch": 1.2054001928640308,
      "grad_norm": 0.16337840259075165,
      "learning_rate": 1.758919961427194e-05,
      "loss": 0.157,
      "step": 11250
    },
    {
      "epoch": 1.206471659702132,
      "grad_norm": 16.895919799804688,
      "learning_rate": 1.7587056680595736e-05,
      "loss": 1.1812,
      "step": 11260
    },
    {
      "epoch": 1.2075431265402337,
      "grad_norm": 0.9307513236999512,
      "learning_rate": 1.7584913746919535e-05,
      "loss": 0.2368,
      "step": 11270
    },
    {
      "epoch": 1.208614593378335,
      "grad_norm": 0.249794140458107,
      "learning_rate": 1.758277081324333e-05,
      "loss": 0.0437,
      "step": 11280
    },
    {
      "epoch": 1.2096860602164363,
      "grad_norm": 17.544700622558594,
      "learning_rate": 1.758062787956713e-05,
      "loss": 0.5233,
      "step": 11290
    },
    {
      "epoch": 1.2107575270545377,
      "grad_norm": 0.02750002034008503,
      "learning_rate": 1.7578484945890926e-05,
      "loss": 0.1829,
      "step": 11300
    },
    {
      "epoch": 1.211828993892639,
      "grad_norm": 0.2348008006811142,
      "learning_rate": 1.7576342012214725e-05,
      "loss": 0.6511,
      "step": 11310
    },
    {
      "epoch": 1.2129004607307403,
      "grad_norm": 0.20273564755916595,
      "learning_rate": 1.757419907853852e-05,
      "loss": 0.1929,
      "step": 11320
    },
    {
      "epoch": 1.2139719275688416,
      "grad_norm": 34.23038101196289,
      "learning_rate": 1.7572056144862316e-05,
      "loss": 0.7348,
      "step": 11330
    },
    {
      "epoch": 1.2150433944069432,
      "grad_norm": 0.11770322918891907,
      "learning_rate": 1.7569913211186115e-05,
      "loss": 0.0347,
      "step": 11340
    },
    {
      "epoch": 1.2161148612450445,
      "grad_norm": 0.06459140032529831,
      "learning_rate": 1.756777027750991e-05,
      "loss": 0.5292,
      "step": 11350
    },
    {
      "epoch": 1.2171863280831459,
      "grad_norm": 0.2074483186006546,
      "learning_rate": 1.756562734383371e-05,
      "loss": 0.5282,
      "step": 11360
    },
    {
      "epoch": 1.2182577949212472,
      "grad_norm": 18.745573043823242,
      "learning_rate": 1.756348441015751e-05,
      "loss": 0.6333,
      "step": 11370
    },
    {
      "epoch": 1.2193292617593485,
      "grad_norm": 0.4811021387577057,
      "learning_rate": 1.7561341476481304e-05,
      "loss": 0.1769,
      "step": 11380
    },
    {
      "epoch": 1.2204007285974499,
      "grad_norm": 15.860042572021484,
      "learning_rate": 1.7559198542805104e-05,
      "loss": 0.5497,
      "step": 11390
    },
    {
      "epoch": 1.2214721954355512,
      "grad_norm": 0.16740190982818604,
      "learning_rate": 1.75570556091289e-05,
      "loss": 0.3067,
      "step": 11400
    },
    {
      "epoch": 1.2225436622736527,
      "grad_norm": 0.1408522129058838,
      "learning_rate": 1.7554912675452695e-05,
      "loss": 0.3721,
      "step": 11410
    },
    {
      "epoch": 1.223615129111754,
      "grad_norm": 15.125185012817383,
      "learning_rate": 1.7552769741776494e-05,
      "loss": 0.7217,
      "step": 11420
    },
    {
      "epoch": 1.2246865959498554,
      "grad_norm": 0.12674452364444733,
      "learning_rate": 1.755062680810029e-05,
      "loss": 0.3405,
      "step": 11430
    },
    {
      "epoch": 1.2257580627879567,
      "grad_norm": 23.817794799804688,
      "learning_rate": 1.754848387442409e-05,
      "loss": 0.6492,
      "step": 11440
    },
    {
      "epoch": 1.226829529626058,
      "grad_norm": 0.6260896325111389,
      "learning_rate": 1.7546340940747884e-05,
      "loss": 0.4627,
      "step": 11450
    },
    {
      "epoch": 1.2279009964641594,
      "grad_norm": 0.4107353389263153,
      "learning_rate": 1.7544198007071683e-05,
      "loss": 0.3731,
      "step": 11460
    },
    {
      "epoch": 1.2289724633022607,
      "grad_norm": 0.4254209101200104,
      "learning_rate": 1.7542055073395482e-05,
      "loss": 0.4332,
      "step": 11470
    },
    {
      "epoch": 1.230043930140362,
      "grad_norm": 0.04680781066417694,
      "learning_rate": 1.7539912139719278e-05,
      "loss": 0.4505,
      "step": 11480
    },
    {
      "epoch": 1.2311153969784634,
      "grad_norm": 0.6110131740570068,
      "learning_rate": 1.7537769206043074e-05,
      "loss": 0.221,
      "step": 11490
    },
    {
      "epoch": 1.232186863816565,
      "grad_norm": 124.20280456542969,
      "learning_rate": 1.7535626272366873e-05,
      "loss": 0.4376,
      "step": 11500
    },
    {
      "epoch": 1.2332583306546663,
      "grad_norm": 0.01815255545079708,
      "learning_rate": 1.753348333869067e-05,
      "loss": 0.957,
      "step": 11510
    },
    {
      "epoch": 1.2343297974927676,
      "grad_norm": 0.2472638636827469,
      "learning_rate": 1.7531340405014464e-05,
      "loss": 0.4833,
      "step": 11520
    },
    {
      "epoch": 1.235401264330869,
      "grad_norm": 0.3675612211227417,
      "learning_rate": 1.7529197471338263e-05,
      "loss": 0.4941,
      "step": 11530
    },
    {
      "epoch": 1.2364727311689703,
      "grad_norm": 19.408506393432617,
      "learning_rate": 1.752705453766206e-05,
      "loss": 0.6564,
      "step": 11540
    },
    {
      "epoch": 1.2375441980070716,
      "grad_norm": 0.6234679818153381,
      "learning_rate": 1.7524911603985858e-05,
      "loss": 0.6207,
      "step": 11550
    },
    {
      "epoch": 1.238615664845173,
      "grad_norm": 8.712388038635254,
      "learning_rate": 1.7522768670309657e-05,
      "loss": 0.3872,
      "step": 11560
    },
    {
      "epoch": 1.2396871316832745,
      "grad_norm": 0.0984170064330101,
      "learning_rate": 1.7520625736633453e-05,
      "loss": 0.2997,
      "step": 11570
    },
    {
      "epoch": 1.2407585985213758,
      "grad_norm": 0.0912715271115303,
      "learning_rate": 1.751848280295725e-05,
      "loss": 0.1727,
      "step": 11580
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.0624423585832119,
      "learning_rate": 1.7516339869281047e-05,
      "loss": 0.3183,
      "step": 11590
    },
    {
      "epoch": 1.2429015321975785,
      "grad_norm": 18.491348266601562,
      "learning_rate": 1.7514196935604843e-05,
      "loss": 0.4593,
      "step": 11600
    },
    {
      "epoch": 1.2439729990356798,
      "grad_norm": 0.22604748606681824,
      "learning_rate": 1.7512054001928642e-05,
      "loss": 0.6182,
      "step": 11610
    },
    {
      "epoch": 1.2450444658737811,
      "grad_norm": 0.3931790590286255,
      "learning_rate": 1.7509911068252438e-05,
      "loss": 0.6504,
      "step": 11620
    },
    {
      "epoch": 1.2461159327118825,
      "grad_norm": 24.932703018188477,
      "learning_rate": 1.7507768134576237e-05,
      "loss": 0.4116,
      "step": 11630
    },
    {
      "epoch": 1.247187399549984,
      "grad_norm": 26.9097843170166,
      "learning_rate": 1.7505625200900032e-05,
      "loss": 0.5688,
      "step": 11640
    },
    {
      "epoch": 1.2482588663880854,
      "grad_norm": 0.7885314226150513,
      "learning_rate": 1.750348226722383e-05,
      "loss": 0.8216,
      "step": 11650
    },
    {
      "epoch": 1.2493303332261867,
      "grad_norm": 17.19175148010254,
      "learning_rate": 1.750133933354763e-05,
      "loss": 0.8793,
      "step": 11660
    },
    {
      "epoch": 1.250401800064288,
      "grad_norm": 18.827272415161133,
      "learning_rate": 1.7499196399871426e-05,
      "loss": 0.3781,
      "step": 11670
    },
    {
      "epoch": 1.2514732669023894,
      "grad_norm": 1.468136191368103,
      "learning_rate": 1.7497053466195222e-05,
      "loss": 0.6763,
      "step": 11680
    },
    {
      "epoch": 1.2525447337404907,
      "grad_norm": 12.101472854614258,
      "learning_rate": 1.749491053251902e-05,
      "loss": 0.4175,
      "step": 11690
    },
    {
      "epoch": 1.253616200578592,
      "grad_norm": 0.559278666973114,
      "learning_rate": 1.7492767598842816e-05,
      "loss": 0.4618,
      "step": 11700
    },
    {
      "epoch": 1.2546876674166936,
      "grad_norm": 0.4954184889793396,
      "learning_rate": 1.7490624665166615e-05,
      "loss": 0.5293,
      "step": 11710
    },
    {
      "epoch": 1.2557591342547947,
      "grad_norm": 0.2073403000831604,
      "learning_rate": 1.748848173149041e-05,
      "loss": 0.7464,
      "step": 11720
    },
    {
      "epoch": 1.2568306010928962,
      "grad_norm": 3.6052405834198,
      "learning_rate": 1.7486338797814207e-05,
      "loss": 0.2361,
      "step": 11730
    },
    {
      "epoch": 1.2579020679309976,
      "grad_norm": 0.09041312336921692,
      "learning_rate": 1.7484195864138006e-05,
      "loss": 0.2077,
      "step": 11740
    },
    {
      "epoch": 1.258973534769099,
      "grad_norm": 41.58711624145508,
      "learning_rate": 1.7482052930461805e-05,
      "loss": 0.8748,
      "step": 11750
    },
    {
      "epoch": 1.2600450016072002,
      "grad_norm": 1.1983720064163208,
      "learning_rate": 1.74799099967856e-05,
      "loss": 0.2694,
      "step": 11760
    },
    {
      "epoch": 1.2611164684453016,
      "grad_norm": 0.27589544653892517,
      "learning_rate": 1.74777670631094e-05,
      "loss": 0.4173,
      "step": 11770
    },
    {
      "epoch": 1.2621879352834031,
      "grad_norm": 0.04583999514579773,
      "learning_rate": 1.7475624129433195e-05,
      "loss": 0.0138,
      "step": 11780
    },
    {
      "epoch": 1.2632594021215042,
      "grad_norm": 0.5349764823913574,
      "learning_rate": 1.747348119575699e-05,
      "loss": 0.327,
      "step": 11790
    },
    {
      "epoch": 1.2643308689596058,
      "grad_norm": 16.79427146911621,
      "learning_rate": 1.747133826208079e-05,
      "loss": 1.0097,
      "step": 11800
    },
    {
      "epoch": 1.2654023357977071,
      "grad_norm": 0.38713976740837097,
      "learning_rate": 1.7469195328404586e-05,
      "loss": 0.3301,
      "step": 11810
    },
    {
      "epoch": 1.2664738026358084,
      "grad_norm": 0.8300038576126099,
      "learning_rate": 1.7467052394728385e-05,
      "loss": 0.6597,
      "step": 11820
    },
    {
      "epoch": 1.2675452694739098,
      "grad_norm": 31.369861602783203,
      "learning_rate": 1.746490946105218e-05,
      "loss": 0.2934,
      "step": 11830
    },
    {
      "epoch": 1.268616736312011,
      "grad_norm": 27.33624839782715,
      "learning_rate": 1.746276652737598e-05,
      "loss": 0.3788,
      "step": 11840
    },
    {
      "epoch": 1.2696882031501124,
      "grad_norm": 0.23335498571395874,
      "learning_rate": 1.746062359369978e-05,
      "loss": 0.6278,
      "step": 11850
    },
    {
      "epoch": 1.2707596699882138,
      "grad_norm": 17.29500389099121,
      "learning_rate": 1.7458480660023574e-05,
      "loss": 0.384,
      "step": 11860
    },
    {
      "epoch": 1.2718311368263153,
      "grad_norm": 0.1415381133556366,
      "learning_rate": 1.745633772634737e-05,
      "loss": 0.3831,
      "step": 11870
    },
    {
      "epoch": 1.2729026036644167,
      "grad_norm": 0.22182200849056244,
      "learning_rate": 1.745419479267117e-05,
      "loss": 0.3571,
      "step": 11880
    },
    {
      "epoch": 1.273974070502518,
      "grad_norm": 28.718278884887695,
      "learning_rate": 1.7452051858994965e-05,
      "loss": 0.6787,
      "step": 11890
    },
    {
      "epoch": 1.2750455373406193,
      "grad_norm": 20.009092330932617,
      "learning_rate": 1.7449908925318764e-05,
      "loss": 0.7893,
      "step": 11900
    },
    {
      "epoch": 1.2761170041787206,
      "grad_norm": 17.231956481933594,
      "learning_rate": 1.744776599164256e-05,
      "loss": 0.311,
      "step": 11910
    },
    {
      "epoch": 1.277188471016822,
      "grad_norm": 0.5799012184143066,
      "learning_rate": 1.7445623057966355e-05,
      "loss": 0.1632,
      "step": 11920
    },
    {
      "epoch": 1.2782599378549233,
      "grad_norm": 0.1279255598783493,
      "learning_rate": 1.7443480124290154e-05,
      "loss": 0.1526,
      "step": 11930
    },
    {
      "epoch": 1.2793314046930249,
      "grad_norm": 0.07990771532058716,
      "learning_rate": 1.7441337190613953e-05,
      "loss": 0.8775,
      "step": 11940
    },
    {
      "epoch": 1.280402871531126,
      "grad_norm": 0.16497059166431427,
      "learning_rate": 1.743919425693775e-05,
      "loss": 0.0366,
      "step": 11950
    },
    {
      "epoch": 1.2814743383692275,
      "grad_norm": 35.3548469543457,
      "learning_rate": 1.7437051323261548e-05,
      "loss": 0.9199,
      "step": 11960
    },
    {
      "epoch": 1.2825458052073289,
      "grad_norm": 18.722484588623047,
      "learning_rate": 1.7434908389585343e-05,
      "loss": 0.3053,
      "step": 11970
    },
    {
      "epoch": 1.2836172720454302,
      "grad_norm": 0.2670002281665802,
      "learning_rate": 1.7432765455909142e-05,
      "loss": 0.3036,
      "step": 11980
    },
    {
      "epoch": 1.2846887388835315,
      "grad_norm": 0.31436625123023987,
      "learning_rate": 1.7430622522232938e-05,
      "loss": 0.4585,
      "step": 11990
    },
    {
      "epoch": 1.2857602057216329,
      "grad_norm": 0.1734791100025177,
      "learning_rate": 1.7428479588556734e-05,
      "loss": 0.5925,
      "step": 12000
    },
    {
      "epoch": 1.2868316725597344,
      "grad_norm": 16.159910202026367,
      "learning_rate": 1.7426336654880533e-05,
      "loss": 0.8053,
      "step": 12010
    },
    {
      "epoch": 1.2879031393978355,
      "grad_norm": 27.651596069335938,
      "learning_rate": 1.742419372120433e-05,
      "loss": 0.5705,
      "step": 12020
    },
    {
      "epoch": 1.288974606235937,
      "grad_norm": 27.027271270751953,
      "learning_rate": 1.7422050787528127e-05,
      "loss": 1.0488,
      "step": 12030
    },
    {
      "epoch": 1.2900460730740384,
      "grad_norm": 0.4152762293815613,
      "learning_rate": 1.7419907853851927e-05,
      "loss": 0.1217,
      "step": 12040
    },
    {
      "epoch": 1.2911175399121397,
      "grad_norm": 0.7752275466918945,
      "learning_rate": 1.7417764920175722e-05,
      "loss": 0.2103,
      "step": 12050
    },
    {
      "epoch": 1.292189006750241,
      "grad_norm": 0.28272485733032227,
      "learning_rate": 1.741562198649952e-05,
      "loss": 1.0689,
      "step": 12060
    },
    {
      "epoch": 1.2932604735883424,
      "grad_norm": 20.033723831176758,
      "learning_rate": 1.7413479052823317e-05,
      "loss": 0.7982,
      "step": 12070
    },
    {
      "epoch": 1.2943319404264437,
      "grad_norm": 1.0379294157028198,
      "learning_rate": 1.7411336119147113e-05,
      "loss": 0.3266,
      "step": 12080
    },
    {
      "epoch": 1.295403407264545,
      "grad_norm": 0.23929424583911896,
      "learning_rate": 1.740919318547091e-05,
      "loss": 0.565,
      "step": 12090
    },
    {
      "epoch": 1.2964748741026466,
      "grad_norm": 0.5054872035980225,
      "learning_rate": 1.7407050251794707e-05,
      "loss": 0.6583,
      "step": 12100
    },
    {
      "epoch": 1.297546340940748,
      "grad_norm": 0.3498939573764801,
      "learning_rate": 1.7404907318118503e-05,
      "loss": 0.4506,
      "step": 12110
    },
    {
      "epoch": 1.2986178077788493,
      "grad_norm": 0.06716222316026688,
      "learning_rate": 1.7402764384442302e-05,
      "loss": 0.4408,
      "step": 12120
    },
    {
      "epoch": 1.2996892746169506,
      "grad_norm": 0.27206599712371826,
      "learning_rate": 1.74006214507661e-05,
      "loss": 0.3761,
      "step": 12130
    },
    {
      "epoch": 1.300760741455052,
      "grad_norm": 0.4110560417175293,
      "learning_rate": 1.73984785170899e-05,
      "loss": 0.7569,
      "step": 12140
    },
    {
      "epoch": 1.3018322082931533,
      "grad_norm": 0.34498634934425354,
      "learning_rate": 1.7396335583413696e-05,
      "loss": 0.6443,
      "step": 12150
    },
    {
      "epoch": 1.3029036751312546,
      "grad_norm": 7.135685920715332,
      "learning_rate": 1.739419264973749e-05,
      "loss": 0.1193,
      "step": 12160
    },
    {
      "epoch": 1.3039751419693562,
      "grad_norm": 0.09960557520389557,
      "learning_rate": 1.739204971606129e-05,
      "loss": 0.2205,
      "step": 12170
    },
    {
      "epoch": 1.3050466088074575,
      "grad_norm": 0.09721746295690536,
      "learning_rate": 1.7389906782385086e-05,
      "loss": 0.2712,
      "step": 12180
    },
    {
      "epoch": 1.3061180756455588,
      "grad_norm": 73.2905502319336,
      "learning_rate": 1.7387763848708882e-05,
      "loss": 0.1347,
      "step": 12190
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.010560807771980762,
      "learning_rate": 1.738562091503268e-05,
      "loss": 0.1979,
      "step": 12200
    },
    {
      "epoch": 1.3082610093217615,
      "grad_norm": 0.08970412611961365,
      "learning_rate": 1.7383477981356477e-05,
      "loss": 0.2445,
      "step": 12210
    },
    {
      "epoch": 1.3093324761598628,
      "grad_norm": 0.07112854719161987,
      "learning_rate": 1.7381335047680276e-05,
      "loss": 0.8012,
      "step": 12220
    },
    {
      "epoch": 1.3104039429979641,
      "grad_norm": 0.10430882126092911,
      "learning_rate": 1.7379192114004075e-05,
      "loss": 0.1515,
      "step": 12230
    },
    {
      "epoch": 1.3114754098360657,
      "grad_norm": 0.1257563829421997,
      "learning_rate": 1.737704918032787e-05,
      "loss": 0.2021,
      "step": 12240
    },
    {
      "epoch": 1.3125468766741668,
      "grad_norm": 20.856233596801758,
      "learning_rate": 1.737490624665167e-05,
      "loss": 0.3453,
      "step": 12250
    },
    {
      "epoch": 1.3136183435122684,
      "grad_norm": 0.37374627590179443,
      "learning_rate": 1.7372763312975465e-05,
      "loss": 1.0143,
      "step": 12260
    },
    {
      "epoch": 1.3146898103503697,
      "grad_norm": 0.09495068341493607,
      "learning_rate": 1.737062037929926e-05,
      "loss": 0.5699,
      "step": 12270
    },
    {
      "epoch": 1.315761277188471,
      "grad_norm": 22.22884750366211,
      "learning_rate": 1.736847744562306e-05,
      "loss": 0.7162,
      "step": 12280
    },
    {
      "epoch": 1.3168327440265724,
      "grad_norm": 0.8862070441246033,
      "learning_rate": 1.7366334511946855e-05,
      "loss": 0.5791,
      "step": 12290
    },
    {
      "epoch": 1.3179042108646737,
      "grad_norm": 49.59431457519531,
      "learning_rate": 1.7364191578270654e-05,
      "loss": 0.3933,
      "step": 12300
    },
    {
      "epoch": 1.318975677702775,
      "grad_norm": 26.2740535736084,
      "learning_rate": 1.736204864459445e-05,
      "loss": 0.3846,
      "step": 12310
    },
    {
      "epoch": 1.3200471445408763,
      "grad_norm": 0.22339269518852234,
      "learning_rate": 1.735990571091825e-05,
      "loss": 0.3676,
      "step": 12320
    },
    {
      "epoch": 1.321118611378978,
      "grad_norm": 0.22115540504455566,
      "learning_rate": 1.7357762777242048e-05,
      "loss": 0.2374,
      "step": 12330
    },
    {
      "epoch": 1.3221900782170792,
      "grad_norm": 0.4259706735610962,
      "learning_rate": 1.7355619843565844e-05,
      "loss": 0.4984,
      "step": 12340
    },
    {
      "epoch": 1.3232615450551806,
      "grad_norm": 24.56646728515625,
      "learning_rate": 1.735347690988964e-05,
      "loss": 0.4353,
      "step": 12350
    },
    {
      "epoch": 1.324333011893282,
      "grad_norm": 0.4478941857814789,
      "learning_rate": 1.735133397621344e-05,
      "loss": 0.7013,
      "step": 12360
    },
    {
      "epoch": 1.3254044787313832,
      "grad_norm": 0.22173629701137543,
      "learning_rate": 1.7349191042537234e-05,
      "loss": 0.3291,
      "step": 12370
    },
    {
      "epoch": 1.3264759455694846,
      "grad_norm": 2.1868979930877686,
      "learning_rate": 1.7347048108861033e-05,
      "loss": 0.4423,
      "step": 12380
    },
    {
      "epoch": 1.327547412407586,
      "grad_norm": 0.18380767107009888,
      "learning_rate": 1.734490517518483e-05,
      "loss": 0.3406,
      "step": 12390
    },
    {
      "epoch": 1.3286188792456874,
      "grad_norm": 0.23712040483951569,
      "learning_rate": 1.7342762241508625e-05,
      "loss": 0.3129,
      "step": 12400
    },
    {
      "epoch": 1.3296903460837888,
      "grad_norm": 19.57387351989746,
      "learning_rate": 1.7340619307832424e-05,
      "loss": 0.7432,
      "step": 12410
    },
    {
      "epoch": 1.33076181292189,
      "grad_norm": 0.251476913690567,
      "learning_rate": 1.7338476374156223e-05,
      "loss": 0.6375,
      "step": 12420
    },
    {
      "epoch": 1.3318332797599914,
      "grad_norm": 15.928464889526367,
      "learning_rate": 1.733633344048002e-05,
      "loss": 0.3455,
      "step": 12430
    },
    {
      "epoch": 1.3329047465980928,
      "grad_norm": 22.545177459716797,
      "learning_rate": 1.7334190506803817e-05,
      "loss": 0.2675,
      "step": 12440
    },
    {
      "epoch": 1.333976213436194,
      "grad_norm": 0.051527585834264755,
      "learning_rate": 1.7332047573127613e-05,
      "loss": 0.3407,
      "step": 12450
    },
    {
      "epoch": 1.3350476802742954,
      "grad_norm": 18.132837295532227,
      "learning_rate": 1.7329904639451412e-05,
      "loss": 0.3767,
      "step": 12460
    },
    {
      "epoch": 1.336119147112397,
      "grad_norm": 0.1336691826581955,
      "learning_rate": 1.7327761705775208e-05,
      "loss": 0.1244,
      "step": 12470
    },
    {
      "epoch": 1.337190613950498,
      "grad_norm": 145.0780029296875,
      "learning_rate": 1.7325618772099003e-05,
      "loss": 0.4503,
      "step": 12480
    },
    {
      "epoch": 1.3382620807885997,
      "grad_norm": 0.08402679860591888,
      "learning_rate": 1.7323475838422802e-05,
      "loss": 0.4468,
      "step": 12490
    },
    {
      "epoch": 1.339333547626701,
      "grad_norm": 30.253948211669922,
      "learning_rate": 1.7321332904746598e-05,
      "loss": 0.4439,
      "step": 12500
    },
    {
      "epoch": 1.3404050144648023,
      "grad_norm": 22.370956420898438,
      "learning_rate": 1.7319189971070397e-05,
      "loss": 1.0234,
      "step": 12510
    },
    {
      "epoch": 1.3414764813029036,
      "grad_norm": 0.2836075723171234,
      "learning_rate": 1.7317047037394196e-05,
      "loss": 0.6718,
      "step": 12520
    },
    {
      "epoch": 1.342547948141005,
      "grad_norm": 21.810123443603516,
      "learning_rate": 1.7314904103717992e-05,
      "loss": 0.412,
      "step": 12530
    },
    {
      "epoch": 1.3436194149791065,
      "grad_norm": 5.73204231262207,
      "learning_rate": 1.731276117004179e-05,
      "loss": 0.5433,
      "step": 12540
    },
    {
      "epoch": 1.3446908818172076,
      "grad_norm": 0.4026733338832855,
      "learning_rate": 1.7310618236365587e-05,
      "loss": 0.4984,
      "step": 12550
    },
    {
      "epoch": 1.3457623486553092,
      "grad_norm": 23.78718376159668,
      "learning_rate": 1.7308475302689382e-05,
      "loss": 0.6306,
      "step": 12560
    },
    {
      "epoch": 1.3468338154934105,
      "grad_norm": 0.10720627009868622,
      "learning_rate": 1.730633236901318e-05,
      "loss": 0.6361,
      "step": 12570
    },
    {
      "epoch": 1.3479052823315119,
      "grad_norm": 0.2856663167476654,
      "learning_rate": 1.7304189435336977e-05,
      "loss": 0.2372,
      "step": 12580
    },
    {
      "epoch": 1.3489767491696132,
      "grad_norm": 1.814499020576477,
      "learning_rate": 1.7302046501660773e-05,
      "loss": 0.5052,
      "step": 12590
    },
    {
      "epoch": 1.3500482160077145,
      "grad_norm": 0.08930500596761703,
      "learning_rate": 1.7299903567984572e-05,
      "loss": 0.5097,
      "step": 12600
    },
    {
      "epoch": 1.3511196828458159,
      "grad_norm": 15.251800537109375,
      "learning_rate": 1.729776063430837e-05,
      "loss": 0.5355,
      "step": 12610
    },
    {
      "epoch": 1.3521911496839172,
      "grad_norm": 0.3846081495285034,
      "learning_rate": 1.7295617700632166e-05,
      "loss": 0.3819,
      "step": 12620
    },
    {
      "epoch": 1.3532626165220187,
      "grad_norm": 17.1461238861084,
      "learning_rate": 1.7293474766955965e-05,
      "loss": 0.5964,
      "step": 12630
    },
    {
      "epoch": 1.35433408336012,
      "grad_norm": 0.37411561608314514,
      "learning_rate": 1.729133183327976e-05,
      "loss": 1.0221,
      "step": 12640
    },
    {
      "epoch": 1.3554055501982214,
      "grad_norm": 0.45097616314888,
      "learning_rate": 1.728918889960356e-05,
      "loss": 0.1936,
      "step": 12650
    },
    {
      "epoch": 1.3564770170363227,
      "grad_norm": 0.10515578836202621,
      "learning_rate": 1.7287045965927356e-05,
      "loss": 0.1732,
      "step": 12660
    },
    {
      "epoch": 1.357548483874424,
      "grad_norm": 0.07898327708244324,
      "learning_rate": 1.728490303225115e-05,
      "loss": 0.5184,
      "step": 12670
    },
    {
      "epoch": 1.3586199507125254,
      "grad_norm": 23.408964157104492,
      "learning_rate": 1.728276009857495e-05,
      "loss": 0.772,
      "step": 12680
    },
    {
      "epoch": 1.3596914175506267,
      "grad_norm": 48.52250671386719,
      "learning_rate": 1.7280617164898746e-05,
      "loss": 0.4055,
      "step": 12690
    },
    {
      "epoch": 1.3607628843887283,
      "grad_norm": 0.159650057554245,
      "learning_rate": 1.7278474231222545e-05,
      "loss": 0.328,
      "step": 12700
    },
    {
      "epoch": 1.3618343512268296,
      "grad_norm": 15.165288925170898,
      "learning_rate": 1.7276331297546344e-05,
      "loss": 0.6332,
      "step": 12710
    },
    {
      "epoch": 1.362905818064931,
      "grad_norm": 18.932785034179688,
      "learning_rate": 1.727418836387014e-05,
      "loss": 0.3026,
      "step": 12720
    },
    {
      "epoch": 1.3639772849030323,
      "grad_norm": 0.035664014518260956,
      "learning_rate": 1.727204543019394e-05,
      "loss": 0.033,
      "step": 12730
    },
    {
      "epoch": 1.3650487517411336,
      "grad_norm": 0.06642786413431168,
      "learning_rate": 1.7269902496517735e-05,
      "loss": 0.3466,
      "step": 12740
    },
    {
      "epoch": 1.366120218579235,
      "grad_norm": 0.13829703629016876,
      "learning_rate": 1.726775956284153e-05,
      "loss": 0.5758,
      "step": 12750
    },
    {
      "epoch": 1.3671916854173363,
      "grad_norm": 0.2582158148288727,
      "learning_rate": 1.726561662916533e-05,
      "loss": 0.4187,
      "step": 12760
    },
    {
      "epoch": 1.3682631522554378,
      "grad_norm": 0.04625006765127182,
      "learning_rate": 1.7263473695489125e-05,
      "loss": 0.4885,
      "step": 12770
    },
    {
      "epoch": 1.369334619093539,
      "grad_norm": 0.06499364227056503,
      "learning_rate": 1.726133076181292e-05,
      "loss": 0.2734,
      "step": 12780
    },
    {
      "epoch": 1.3704060859316405,
      "grad_norm": 0.3784756660461426,
      "learning_rate": 1.725918782813672e-05,
      "loss": 0.3509,
      "step": 12790
    },
    {
      "epoch": 1.3714775527697418,
      "grad_norm": 20.777908325195312,
      "learning_rate": 1.725704489446052e-05,
      "loss": 0.747,
      "step": 12800
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.25262343883514404,
      "learning_rate": 1.7254901960784314e-05,
      "loss": 0.4874,
      "step": 12810
    },
    {
      "epoch": 1.3736204864459445,
      "grad_norm": 0.11165546625852585,
      "learning_rate": 1.7252759027108114e-05,
      "loss": 0.6596,
      "step": 12820
    },
    {
      "epoch": 1.3746919532840458,
      "grad_norm": 0.3858114778995514,
      "learning_rate": 1.725061609343191e-05,
      "loss": 0.2782,
      "step": 12830
    },
    {
      "epoch": 1.3757634201221471,
      "grad_norm": 18.977937698364258,
      "learning_rate": 1.7248473159755708e-05,
      "loss": 0.2148,
      "step": 12840
    },
    {
      "epoch": 1.3768348869602485,
      "grad_norm": 52.54129409790039,
      "learning_rate": 1.7246330226079504e-05,
      "loss": 0.8605,
      "step": 12850
    },
    {
      "epoch": 1.37790635379835,
      "grad_norm": 0.15607891976833344,
      "learning_rate": 1.72441872924033e-05,
      "loss": 0.2064,
      "step": 12860
    },
    {
      "epoch": 1.3789778206364514,
      "grad_norm": 16.262535095214844,
      "learning_rate": 1.72420443587271e-05,
      "loss": 0.3379,
      "step": 12870
    },
    {
      "epoch": 1.3800492874745527,
      "grad_norm": 0.21699948608875275,
      "learning_rate": 1.7239901425050894e-05,
      "loss": 0.7111,
      "step": 12880
    },
    {
      "epoch": 1.381120754312654,
      "grad_norm": 0.24642914533615112,
      "learning_rate": 1.7237758491374693e-05,
      "loss": 0.501,
      "step": 12890
    },
    {
      "epoch": 1.3821922211507554,
      "grad_norm": 0.21638375520706177,
      "learning_rate": 1.7235615557698492e-05,
      "loss": 0.265,
      "step": 12900
    },
    {
      "epoch": 1.3832636879888567,
      "grad_norm": 0.91000896692276,
      "learning_rate": 1.7233472624022288e-05,
      "loss": 0.9172,
      "step": 12910
    },
    {
      "epoch": 1.384335154826958,
      "grad_norm": 0.7136576175689697,
      "learning_rate": 1.7231329690346087e-05,
      "loss": 0.0149,
      "step": 12920
    },
    {
      "epoch": 1.3854066216650596,
      "grad_norm": 0.16933608055114746,
      "learning_rate": 1.7229186756669883e-05,
      "loss": 0.5892,
      "step": 12930
    },
    {
      "epoch": 1.386478088503161,
      "grad_norm": 23.604589462280273,
      "learning_rate": 1.722704382299368e-05,
      "loss": 0.5179,
      "step": 12940
    },
    {
      "epoch": 1.3875495553412622,
      "grad_norm": 16.256206512451172,
      "learning_rate": 1.7224900889317477e-05,
      "loss": 0.2957,
      "step": 12950
    },
    {
      "epoch": 1.3886210221793636,
      "grad_norm": 0.644402801990509,
      "learning_rate": 1.7222757955641273e-05,
      "loss": 0.6193,
      "step": 12960
    },
    {
      "epoch": 1.389692489017465,
      "grad_norm": 0.42623990774154663,
      "learning_rate": 1.7220615021965072e-05,
      "loss": 0.3828,
      "step": 12970
    },
    {
      "epoch": 1.3907639558555662,
      "grad_norm": 19.61309051513672,
      "learning_rate": 1.7218472088288868e-05,
      "loss": 0.328,
      "step": 12980
    },
    {
      "epoch": 1.3918354226936676,
      "grad_norm": 31.861469268798828,
      "learning_rate": 1.7216329154612667e-05,
      "loss": 1.1385,
      "step": 12990
    },
    {
      "epoch": 1.392906889531769,
      "grad_norm": 0.458848774433136,
      "learning_rate": 1.7214186220936463e-05,
      "loss": 0.6973,
      "step": 13000
    },
    {
      "epoch": 1.3939783563698702,
      "grad_norm": 0.3607963025569916,
      "learning_rate": 1.721204328726026e-05,
      "loss": 0.4201,
      "step": 13010
    },
    {
      "epoch": 1.3950498232079718,
      "grad_norm": 33.57019805908203,
      "learning_rate": 1.7209900353584057e-05,
      "loss": 0.591,
      "step": 13020
    },
    {
      "epoch": 1.396121290046073,
      "grad_norm": 0.7847059965133667,
      "learning_rate": 1.7207757419907856e-05,
      "loss": 0.5051,
      "step": 13030
    },
    {
      "epoch": 1.3971927568841744,
      "grad_norm": 0.24506622552871704,
      "learning_rate": 1.7205614486231652e-05,
      "loss": 0.2772,
      "step": 13040
    },
    {
      "epoch": 1.3982642237222758,
      "grad_norm": 0.05294591188430786,
      "learning_rate": 1.720347155255545e-05,
      "loss": 0.2745,
      "step": 13050
    },
    {
      "epoch": 1.399335690560377,
      "grad_norm": 1.161741852760315,
      "learning_rate": 1.7201328618879247e-05,
      "loss": 0.326,
      "step": 13060
    },
    {
      "epoch": 1.4004071573984787,
      "grad_norm": 0.2773342430591583,
      "learning_rate": 1.7199185685203042e-05,
      "loss": 0.6831,
      "step": 13070
    },
    {
      "epoch": 1.4014786242365798,
      "grad_norm": 0.07563204318284988,
      "learning_rate": 1.719704275152684e-05,
      "loss": 0.7883,
      "step": 13080
    },
    {
      "epoch": 1.4025500910746813,
      "grad_norm": 0.1536399871110916,
      "learning_rate": 1.719489981785064e-05,
      "loss": 0.2057,
      "step": 13090
    },
    {
      "epoch": 1.4036215579127826,
      "grad_norm": 18.569246292114258,
      "learning_rate": 1.7192756884174436e-05,
      "loss": 0.7742,
      "step": 13100
    },
    {
      "epoch": 1.404693024750884,
      "grad_norm": 0.1755412071943283,
      "learning_rate": 1.7190613950498235e-05,
      "loss": 0.5626,
      "step": 13110
    },
    {
      "epoch": 1.4057644915889853,
      "grad_norm": 14.594122886657715,
      "learning_rate": 1.718847101682203e-05,
      "loss": 0.4201,
      "step": 13120
    },
    {
      "epoch": 1.4068359584270866,
      "grad_norm": 0.2972695231437683,
      "learning_rate": 1.718632808314583e-05,
      "loss": 0.2918,
      "step": 13130
    },
    {
      "epoch": 1.407907425265188,
      "grad_norm": 19.660676956176758,
      "learning_rate": 1.7184185149469626e-05,
      "loss": 0.1847,
      "step": 13140
    },
    {
      "epoch": 1.4089788921032893,
      "grad_norm": 0.34897899627685547,
      "learning_rate": 1.718204221579342e-05,
      "loss": 0.1048,
      "step": 13150
    },
    {
      "epoch": 1.4100503589413909,
      "grad_norm": 0.29511454701423645,
      "learning_rate": 1.717989928211722e-05,
      "loss": 0.5971,
      "step": 13160
    },
    {
      "epoch": 1.4111218257794922,
      "grad_norm": 53.247718811035156,
      "learning_rate": 1.7177756348441016e-05,
      "loss": 0.5502,
      "step": 13170
    },
    {
      "epoch": 1.4121932926175935,
      "grad_norm": 0.10764525830745697,
      "learning_rate": 1.7175613414764815e-05,
      "loss": 0.8741,
      "step": 13180
    },
    {
      "epoch": 1.4132647594556949,
      "grad_norm": 0.19767646491527557,
      "learning_rate": 1.717347048108861e-05,
      "loss": 0.3642,
      "step": 13190
    },
    {
      "epoch": 1.4143362262937962,
      "grad_norm": 0.11475511640310287,
      "learning_rate": 1.717132754741241e-05,
      "loss": 0.387,
      "step": 13200
    },
    {
      "epoch": 1.4154076931318975,
      "grad_norm": 0.1804482638835907,
      "learning_rate": 1.716918461373621e-05,
      "loss": 0.4354,
      "step": 13210
    },
    {
      "epoch": 1.4164791599699988,
      "grad_norm": 0.1673414260149002,
      "learning_rate": 1.7167041680060004e-05,
      "loss": 0.3533,
      "step": 13220
    },
    {
      "epoch": 1.4175506268081004,
      "grad_norm": 0.15879669785499573,
      "learning_rate": 1.71648987463838e-05,
      "loss": 0.1376,
      "step": 13230
    },
    {
      "epoch": 1.4186220936462017,
      "grad_norm": 4.595987319946289,
      "learning_rate": 1.71627558127076e-05,
      "loss": 0.4077,
      "step": 13240
    },
    {
      "epoch": 1.419693560484303,
      "grad_norm": 0.08417650312185287,
      "learning_rate": 1.7160612879031395e-05,
      "loss": 0.2278,
      "step": 13250
    },
    {
      "epoch": 1.4207650273224044,
      "grad_norm": 1.0425392389297485,
      "learning_rate": 1.715846994535519e-05,
      "loss": 0.1829,
      "step": 13260
    },
    {
      "epoch": 1.4218364941605057,
      "grad_norm": 0.3081056773662567,
      "learning_rate": 1.715632701167899e-05,
      "loss": 0.8439,
      "step": 13270
    },
    {
      "epoch": 1.422907960998607,
      "grad_norm": 54.9260139465332,
      "learning_rate": 1.715418407800279e-05,
      "loss": 0.7091,
      "step": 13280
    },
    {
      "epoch": 1.4239794278367084,
      "grad_norm": 0.09361262619495392,
      "learning_rate": 1.7152041144326584e-05,
      "loss": 0.3053,
      "step": 13290
    },
    {
      "epoch": 1.42505089467481,
      "grad_norm": 0.6723780632019043,
      "learning_rate": 1.7149898210650383e-05,
      "loss": 0.2354,
      "step": 13300
    },
    {
      "epoch": 1.426122361512911,
      "grad_norm": 20.051753997802734,
      "learning_rate": 1.714775527697418e-05,
      "loss": 0.5307,
      "step": 13310
    },
    {
      "epoch": 1.4271938283510126,
      "grad_norm": 0.03596264123916626,
      "learning_rate": 1.7145612343297978e-05,
      "loss": 0.2401,
      "step": 13320
    },
    {
      "epoch": 1.428265295189114,
      "grad_norm": 0.14321967959403992,
      "learning_rate": 1.7143469409621774e-05,
      "loss": 0.3074,
      "step": 13330
    },
    {
      "epoch": 1.4293367620272153,
      "grad_norm": 11.607504844665527,
      "learning_rate": 1.714132647594557e-05,
      "loss": 0.5959,
      "step": 13340
    },
    {
      "epoch": 1.4304082288653166,
      "grad_norm": 0.06984896957874298,
      "learning_rate": 1.7139183542269368e-05,
      "loss": 0.0754,
      "step": 13350
    },
    {
      "epoch": 1.431479695703418,
      "grad_norm": 0.07059955596923828,
      "learning_rate": 1.7137040608593164e-05,
      "loss": 0.0056,
      "step": 13360
    },
    {
      "epoch": 1.4325511625415193,
      "grad_norm": 0.02300923503935337,
      "learning_rate": 1.7134897674916963e-05,
      "loss": 0.5806,
      "step": 13370
    },
    {
      "epoch": 1.4336226293796206,
      "grad_norm": 0.3450951874256134,
      "learning_rate": 1.713275474124076e-05,
      "loss": 0.5118,
      "step": 13380
    },
    {
      "epoch": 1.4346940962177221,
      "grad_norm": 13.971153259277344,
      "learning_rate": 1.7130611807564558e-05,
      "loss": 0.0165,
      "step": 13390
    },
    {
      "epoch": 1.4357655630558235,
      "grad_norm": 25.957136154174805,
      "learning_rate": 1.7128468873888357e-05,
      "loss": 0.8417,
      "step": 13400
    },
    {
      "epoch": 1.4368370298939248,
      "grad_norm": 0.13237231969833374,
      "learning_rate": 1.7126325940212152e-05,
      "loss": 0.2198,
      "step": 13410
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 17.729820251464844,
      "learning_rate": 1.7124183006535948e-05,
      "loss": 0.3787,
      "step": 13420
    },
    {
      "epoch": 1.4389799635701275,
      "grad_norm": 0.455716073513031,
      "learning_rate": 1.7122040072859747e-05,
      "loss": 0.5759,
      "step": 13430
    },
    {
      "epoch": 1.4400514304082288,
      "grad_norm": 0.04586150497198105,
      "learning_rate": 1.7119897139183543e-05,
      "loss": 0.1536,
      "step": 13440
    },
    {
      "epoch": 1.4411228972463301,
      "grad_norm": 0.21617530286312103,
      "learning_rate": 1.7117754205507342e-05,
      "loss": 0.1911,
      "step": 13450
    },
    {
      "epoch": 1.4421943640844317,
      "grad_norm": 0.30673372745513916,
      "learning_rate": 1.7115611271831138e-05,
      "loss": 0.8945,
      "step": 13460
    },
    {
      "epoch": 1.443265830922533,
      "grad_norm": 0.21259286999702454,
      "learning_rate": 1.7113468338154937e-05,
      "loss": 0.1897,
      "step": 13470
    },
    {
      "epoch": 1.4443372977606344,
      "grad_norm": 0.1836138814687729,
      "learning_rate": 1.7111325404478732e-05,
      "loss": 0.2763,
      "step": 13480
    },
    {
      "epoch": 1.4454087645987357,
      "grad_norm": 20.501108169555664,
      "learning_rate": 1.710918247080253e-05,
      "loss": 1.1071,
      "step": 13490
    },
    {
      "epoch": 1.446480231436837,
      "grad_norm": 0.06228680536150932,
      "learning_rate": 1.7107039537126327e-05,
      "loss": 0.4477,
      "step": 13500
    },
    {
      "epoch": 1.4475516982749383,
      "grad_norm": 20.88201141357422,
      "learning_rate": 1.7104896603450126e-05,
      "loss": 0.6774,
      "step": 13510
    },
    {
      "epoch": 1.4486231651130397,
      "grad_norm": 15.427350997924805,
      "learning_rate": 1.710275366977392e-05,
      "loss": 0.2553,
      "step": 13520
    },
    {
      "epoch": 1.4496946319511412,
      "grad_norm": 15.0585298538208,
      "learning_rate": 1.710061073609772e-05,
      "loss": 0.2027,
      "step": 13530
    },
    {
      "epoch": 1.4507660987892423,
      "grad_norm": 0.06644368916749954,
      "learning_rate": 1.7098467802421516e-05,
      "loss": 0.6753,
      "step": 13540
    },
    {
      "epoch": 1.451837565627344,
      "grad_norm": 0.14917679131031036,
      "learning_rate": 1.7096324868745312e-05,
      "loss": 0.2484,
      "step": 13550
    },
    {
      "epoch": 1.4529090324654452,
      "grad_norm": 0.27039414644241333,
      "learning_rate": 1.709418193506911e-05,
      "loss": 0.3114,
      "step": 13560
    },
    {
      "epoch": 1.4539804993035466,
      "grad_norm": 0.24724245071411133,
      "learning_rate": 1.7092039001392907e-05,
      "loss": 0.8932,
      "step": 13570
    },
    {
      "epoch": 1.455051966141648,
      "grad_norm": 17.194547653198242,
      "learning_rate": 1.7089896067716706e-05,
      "loss": 0.7455,
      "step": 13580
    },
    {
      "epoch": 1.4561234329797492,
      "grad_norm": 0.26894503831863403,
      "learning_rate": 1.7087753134040505e-05,
      "loss": 0.4863,
      "step": 13590
    },
    {
      "epoch": 1.4571948998178508,
      "grad_norm": 0.5054327249526978,
      "learning_rate": 1.70856102003643e-05,
      "loss": 0.2887,
      "step": 13600
    },
    {
      "epoch": 1.4582663666559519,
      "grad_norm": 26.79375457763672,
      "learning_rate": 1.7083467266688096e-05,
      "loss": 0.4761,
      "step": 13610
    },
    {
      "epoch": 1.4593378334940534,
      "grad_norm": 0.17866939306259155,
      "learning_rate": 1.7081324333011895e-05,
      "loss": 0.787,
      "step": 13620
    },
    {
      "epoch": 1.4604093003321548,
      "grad_norm": 6.762291431427002,
      "learning_rate": 1.707918139933569e-05,
      "loss": 0.5406,
      "step": 13630
    },
    {
      "epoch": 1.461480767170256,
      "grad_norm": 0.6891655325889587,
      "learning_rate": 1.707703846565949e-05,
      "loss": 0.4788,
      "step": 13640
    },
    {
      "epoch": 1.4625522340083574,
      "grad_norm": 14.871655464172363,
      "learning_rate": 1.7074895531983286e-05,
      "loss": 0.7412,
      "step": 13650
    },
    {
      "epoch": 1.4636237008464588,
      "grad_norm": 11.109719276428223,
      "learning_rate": 1.7072752598307085e-05,
      "loss": 0.3688,
      "step": 13660
    },
    {
      "epoch": 1.46469516768456,
      "grad_norm": 0.1215188279747963,
      "learning_rate": 1.707060966463088e-05,
      "loss": 0.4571,
      "step": 13670
    },
    {
      "epoch": 1.4657666345226614,
      "grad_norm": 0.18967024981975555,
      "learning_rate": 1.706846673095468e-05,
      "loss": 0.1649,
      "step": 13680
    },
    {
      "epoch": 1.466838101360763,
      "grad_norm": 0.1367654949426651,
      "learning_rate": 1.7066323797278475e-05,
      "loss": 0.2408,
      "step": 13690
    },
    {
      "epoch": 1.4679095681988643,
      "grad_norm": 0.43817654252052307,
      "learning_rate": 1.7064180863602274e-05,
      "loss": 0.3266,
      "step": 13700
    },
    {
      "epoch": 1.4689810350369656,
      "grad_norm": 0.06639424711465836,
      "learning_rate": 1.706203792992607e-05,
      "loss": 0.3742,
      "step": 13710
    },
    {
      "epoch": 1.470052501875067,
      "grad_norm": 0.5583447813987732,
      "learning_rate": 1.705989499624987e-05,
      "loss": 0.5476,
      "step": 13720
    },
    {
      "epoch": 1.4711239687131683,
      "grad_norm": 0.7949199080467224,
      "learning_rate": 1.7057752062573664e-05,
      "loss": 0.5852,
      "step": 13730
    },
    {
      "epoch": 1.4721954355512696,
      "grad_norm": 22.76968002319336,
      "learning_rate": 1.705560912889746e-05,
      "loss": 0.591,
      "step": 13740
    },
    {
      "epoch": 1.473266902389371,
      "grad_norm": 14.880228996276855,
      "learning_rate": 1.705346619522126e-05,
      "loss": 0.5967,
      "step": 13750
    },
    {
      "epoch": 1.4743383692274725,
      "grad_norm": 4.504819393157959,
      "learning_rate": 1.7051323261545055e-05,
      "loss": 0.3835,
      "step": 13760
    },
    {
      "epoch": 1.4754098360655736,
      "grad_norm": 0.04900260642170906,
      "learning_rate": 1.7049180327868854e-05,
      "loss": 0.0047,
      "step": 13770
    },
    {
      "epoch": 1.4764813029036752,
      "grad_norm": 0.8547059893608093,
      "learning_rate": 1.7047037394192653e-05,
      "loss": 0.3511,
      "step": 13780
    },
    {
      "epoch": 1.4775527697417765,
      "grad_norm": 0.12155445665121078,
      "learning_rate": 1.704489446051645e-05,
      "loss": 0.3649,
      "step": 13790
    },
    {
      "epoch": 1.4786242365798778,
      "grad_norm": 40.44089126586914,
      "learning_rate": 1.7042751526840248e-05,
      "loss": 0.2345,
      "step": 13800
    },
    {
      "epoch": 1.4796957034179792,
      "grad_norm": 0.3140738606452942,
      "learning_rate": 1.7040608593164043e-05,
      "loss": 0.3129,
      "step": 13810
    },
    {
      "epoch": 1.4807671702560805,
      "grad_norm": 0.6941346526145935,
      "learning_rate": 1.703846565948784e-05,
      "loss": 0.4409,
      "step": 13820
    },
    {
      "epoch": 1.481838637094182,
      "grad_norm": 0.3508748710155487,
      "learning_rate": 1.7036322725811638e-05,
      "loss": 0.4763,
      "step": 13830
    },
    {
      "epoch": 1.4829101039322832,
      "grad_norm": 0.35559898614883423,
      "learning_rate": 1.7034179792135434e-05,
      "loss": 0.8815,
      "step": 13840
    },
    {
      "epoch": 1.4839815707703847,
      "grad_norm": 0.4610326588153839,
      "learning_rate": 1.7032036858459233e-05,
      "loss": 0.6499,
      "step": 13850
    },
    {
      "epoch": 1.485053037608486,
      "grad_norm": 42.11366271972656,
      "learning_rate": 1.702989392478303e-05,
      "loss": 0.7212,
      "step": 13860
    },
    {
      "epoch": 1.4861245044465874,
      "grad_norm": 16.725677490234375,
      "learning_rate": 1.7027750991106827e-05,
      "loss": 0.9183,
      "step": 13870
    },
    {
      "epoch": 1.4871959712846887,
      "grad_norm": 0.6798633337020874,
      "learning_rate": 1.7025608057430626e-05,
      "loss": 0.3792,
      "step": 13880
    },
    {
      "epoch": 1.48826743812279,
      "grad_norm": 2.881220579147339,
      "learning_rate": 1.7023465123754422e-05,
      "loss": 0.2919,
      "step": 13890
    },
    {
      "epoch": 1.4893389049608914,
      "grad_norm": 0.0911295935511589,
      "learning_rate": 1.7021322190078218e-05,
      "loss": 0.7415,
      "step": 13900
    },
    {
      "epoch": 1.4904103717989927,
      "grad_norm": 19.276290893554688,
      "learning_rate": 1.7019179256402017e-05,
      "loss": 0.1511,
      "step": 13910
    },
    {
      "epoch": 1.4914818386370943,
      "grad_norm": 0.20715764164924622,
      "learning_rate": 1.7017036322725812e-05,
      "loss": 0.0624,
      "step": 13920
    },
    {
      "epoch": 1.4925533054751956,
      "grad_norm": 0.06773437559604645,
      "learning_rate": 1.7014893389049608e-05,
      "loss": 0.5547,
      "step": 13930
    },
    {
      "epoch": 1.493624772313297,
      "grad_norm": 0.1300310343503952,
      "learning_rate": 1.7012750455373407e-05,
      "loss": 0.2978,
      "step": 13940
    },
    {
      "epoch": 1.4946962391513983,
      "grad_norm": 0.2770818769931793,
      "learning_rate": 1.7010607521697203e-05,
      "loss": 0.5259,
      "step": 13950
    },
    {
      "epoch": 1.4957677059894996,
      "grad_norm": 35.096229553222656,
      "learning_rate": 1.7008464588021002e-05,
      "loss": 0.6058,
      "step": 13960
    },
    {
      "epoch": 1.496839172827601,
      "grad_norm": 16.483144760131836,
      "learning_rate": 1.70063216543448e-05,
      "loss": 0.5965,
      "step": 13970
    },
    {
      "epoch": 1.4979106396657023,
      "grad_norm": 78.96798706054688,
      "learning_rate": 1.7004178720668597e-05,
      "loss": 0.7958,
      "step": 13980
    },
    {
      "epoch": 1.4989821065038038,
      "grad_norm": 43.230594635009766,
      "learning_rate": 1.7002035786992396e-05,
      "loss": 0.3293,
      "step": 13990
    },
    {
      "epoch": 1.500053573341905,
      "grad_norm": 17.391000747680664,
      "learning_rate": 1.699989285331619e-05,
      "loss": 0.4869,
      "step": 14000
    },
    {
      "epoch": 1.5011250401800065,
      "grad_norm": 0.5796754360198975,
      "learning_rate": 1.6997749919639987e-05,
      "loss": 0.8242,
      "step": 14010
    },
    {
      "epoch": 1.5021965070181078,
      "grad_norm": 0.6042649745941162,
      "learning_rate": 1.6995606985963786e-05,
      "loss": 0.4427,
      "step": 14020
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.3482726812362671,
      "learning_rate": 1.6993464052287582e-05,
      "loss": 0.1427,
      "step": 14030
    },
    {
      "epoch": 1.5043394406943105,
      "grad_norm": 0.31138134002685547,
      "learning_rate": 1.699132111861138e-05,
      "loss": 0.8348,
      "step": 14040
    },
    {
      "epoch": 1.5054109075324118,
      "grad_norm": 14.461724281311035,
      "learning_rate": 1.6989178184935176e-05,
      "loss": 0.2848,
      "step": 14050
    },
    {
      "epoch": 1.5064823743705134,
      "grad_norm": 0.332384318113327,
      "learning_rate": 1.6987035251258975e-05,
      "loss": 0.1176,
      "step": 14060
    },
    {
      "epoch": 1.5075538412086145,
      "grad_norm": 241.03875732421875,
      "learning_rate": 1.6984892317582775e-05,
      "loss": 0.5059,
      "step": 14070
    },
    {
      "epoch": 1.508625308046716,
      "grad_norm": 0.7421944737434387,
      "learning_rate": 1.698274938390657e-05,
      "loss": 0.7286,
      "step": 14080
    },
    {
      "epoch": 1.5096967748848173,
      "grad_norm": 482.0065612792969,
      "learning_rate": 1.6980606450230366e-05,
      "loss": 0.2641,
      "step": 14090
    },
    {
      "epoch": 1.5107682417229187,
      "grad_norm": 0.06902710348367691,
      "learning_rate": 1.6978463516554165e-05,
      "loss": 0.1741,
      "step": 14100
    },
    {
      "epoch": 1.51183970856102,
      "grad_norm": 0.08131010830402374,
      "learning_rate": 1.697632058287796e-05,
      "loss": 0.2545,
      "step": 14110
    },
    {
      "epoch": 1.5129111753991213,
      "grad_norm": 0.17859125137329102,
      "learning_rate": 1.697417764920176e-05,
      "loss": 1.4406,
      "step": 14120
    },
    {
      "epoch": 1.513982642237223,
      "grad_norm": 15.140324592590332,
      "learning_rate": 1.6972034715525555e-05,
      "loss": 0.3566,
      "step": 14130
    },
    {
      "epoch": 1.515054109075324,
      "grad_norm": 1.2225464582443237,
      "learning_rate": 1.696989178184935e-05,
      "loss": 0.5546,
      "step": 14140
    },
    {
      "epoch": 1.5161255759134256,
      "grad_norm": 17.832246780395508,
      "learning_rate": 1.696774884817315e-05,
      "loss": 0.3606,
      "step": 14150
    },
    {
      "epoch": 1.517197042751527,
      "grad_norm": 16.780494689941406,
      "learning_rate": 1.696560591449695e-05,
      "loss": 0.1809,
      "step": 14160
    },
    {
      "epoch": 1.5182685095896282,
      "grad_norm": 19.917726516723633,
      "learning_rate": 1.6963462980820745e-05,
      "loss": 0.1283,
      "step": 14170
    },
    {
      "epoch": 1.5193399764277296,
      "grad_norm": 24.704959869384766,
      "learning_rate": 1.6961320047144544e-05,
      "loss": 1.003,
      "step": 14180
    },
    {
      "epoch": 1.5204114432658309,
      "grad_norm": 1.036272406578064,
      "learning_rate": 1.695917711346834e-05,
      "loss": 0.1483,
      "step": 14190
    },
    {
      "epoch": 1.5214829101039324,
      "grad_norm": 11.471774101257324,
      "learning_rate": 1.695703417979214e-05,
      "loss": 0.2828,
      "step": 14200
    },
    {
      "epoch": 1.5225543769420335,
      "grad_norm": 0.10616990178823471,
      "learning_rate": 1.6954891246115934e-05,
      "loss": 0.7821,
      "step": 14210
    },
    {
      "epoch": 1.523625843780135,
      "grad_norm": 0.657001256942749,
      "learning_rate": 1.695274831243973e-05,
      "loss": 0.3089,
      "step": 14220
    },
    {
      "epoch": 1.5246973106182362,
      "grad_norm": 0.0918334349989891,
      "learning_rate": 1.695060537876353e-05,
      "loss": 0.3911,
      "step": 14230
    },
    {
      "epoch": 1.5257687774563378,
      "grad_norm": 31.538333892822266,
      "learning_rate": 1.6948462445087324e-05,
      "loss": 0.5471,
      "step": 14240
    },
    {
      "epoch": 1.526840244294439,
      "grad_norm": 0.1267928183078766,
      "learning_rate": 1.6946319511411124e-05,
      "loss": 0.6623,
      "step": 14250
    },
    {
      "epoch": 1.5279117111325404,
      "grad_norm": 21.160690307617188,
      "learning_rate": 1.6944176577734923e-05,
      "loss": 0.4843,
      "step": 14260
    },
    {
      "epoch": 1.5289831779706418,
      "grad_norm": 0.14505712687969208,
      "learning_rate": 1.6942033644058718e-05,
      "loss": 0.4738,
      "step": 14270
    },
    {
      "epoch": 1.530054644808743,
      "grad_norm": 0.12498795241117477,
      "learning_rate": 1.6939890710382517e-05,
      "loss": 0.1119,
      "step": 14280
    },
    {
      "epoch": 1.5311261116468446,
      "grad_norm": 31.26622200012207,
      "learning_rate": 1.6937747776706313e-05,
      "loss": 0.4231,
      "step": 14290
    },
    {
      "epoch": 1.5321975784849458,
      "grad_norm": 14.442279815673828,
      "learning_rate": 1.693560484303011e-05,
      "loss": 0.8786,
      "step": 14300
    },
    {
      "epoch": 1.5332690453230473,
      "grad_norm": 0.09250111132860184,
      "learning_rate": 1.6933461909353908e-05,
      "loss": 0.4788,
      "step": 14310
    },
    {
      "epoch": 1.5343405121611486,
      "grad_norm": 14.081331253051758,
      "learning_rate": 1.6931318975677703e-05,
      "loss": 0.3623,
      "step": 14320
    },
    {
      "epoch": 1.53541197899925,
      "grad_norm": 0.07461477071046829,
      "learning_rate": 1.69291760420015e-05,
      "loss": 0.5576,
      "step": 14330
    },
    {
      "epoch": 1.5364834458373513,
      "grad_norm": 30.662399291992188,
      "learning_rate": 1.6927033108325298e-05,
      "loss": 0.4719,
      "step": 14340
    },
    {
      "epoch": 1.5375549126754526,
      "grad_norm": 12.383749961853027,
      "learning_rate": 1.6924890174649097e-05,
      "loss": 0.4986,
      "step": 14350
    },
    {
      "epoch": 1.5386263795135542,
      "grad_norm": 20.756357192993164,
      "learning_rate": 1.6922747240972893e-05,
      "loss": 0.5086,
      "step": 14360
    },
    {
      "epoch": 1.5396978463516553,
      "grad_norm": 5.950689792633057,
      "learning_rate": 1.6920604307296692e-05,
      "loss": 0.2123,
      "step": 14370
    },
    {
      "epoch": 1.5407693131897569,
      "grad_norm": 0.08239477127790451,
      "learning_rate": 1.6918461373620487e-05,
      "loss": 0.7258,
      "step": 14380
    },
    {
      "epoch": 1.5418407800278582,
      "grad_norm": 0.8662815093994141,
      "learning_rate": 1.6916318439944287e-05,
      "loss": 0.5696,
      "step": 14390
    },
    {
      "epoch": 1.5429122468659595,
      "grad_norm": 0.6748839616775513,
      "learning_rate": 1.6914175506268082e-05,
      "loss": 0.5214,
      "step": 14400
    },
    {
      "epoch": 1.5439837137040608,
      "grad_norm": 76.25404357910156,
      "learning_rate": 1.6912032572591878e-05,
      "loss": 0.6483,
      "step": 14410
    },
    {
      "epoch": 1.5450551805421622,
      "grad_norm": 34.430423736572266,
      "learning_rate": 1.6909889638915677e-05,
      "loss": 0.4541,
      "step": 14420
    },
    {
      "epoch": 1.5461266473802637,
      "grad_norm": 34.1180305480957,
      "learning_rate": 1.6907746705239473e-05,
      "loss": 0.6481,
      "step": 14430
    },
    {
      "epoch": 1.5471981142183648,
      "grad_norm": 27.78306007385254,
      "learning_rate": 1.690560377156327e-05,
      "loss": 0.3585,
      "step": 14440
    },
    {
      "epoch": 1.5482695810564664,
      "grad_norm": 0.10975199192762375,
      "learning_rate": 1.690346083788707e-05,
      "loss": 0.7735,
      "step": 14450
    },
    {
      "epoch": 1.5493410478945675,
      "grad_norm": 20.782785415649414,
      "learning_rate": 1.6901317904210866e-05,
      "loss": 0.162,
      "step": 14460
    },
    {
      "epoch": 1.550412514732669,
      "grad_norm": 394.6351623535156,
      "learning_rate": 1.6899174970534665e-05,
      "loss": 0.4648,
      "step": 14470
    },
    {
      "epoch": 1.5514839815707704,
      "grad_norm": 69.88238525390625,
      "learning_rate": 1.689703203685846e-05,
      "loss": 0.2434,
      "step": 14480
    },
    {
      "epoch": 1.5525554484088717,
      "grad_norm": 0.06355410069227219,
      "learning_rate": 1.6894889103182257e-05,
      "loss": 0.0088,
      "step": 14490
    },
    {
      "epoch": 1.5536269152469733,
      "grad_norm": 0.1571047306060791,
      "learning_rate": 1.6892746169506056e-05,
      "loss": 0.5471,
      "step": 14500
    },
    {
      "epoch": 1.5546983820850744,
      "grad_norm": 21.692947387695312,
      "learning_rate": 1.689060323582985e-05,
      "loss": 0.7327,
      "step": 14510
    },
    {
      "epoch": 1.555769848923176,
      "grad_norm": 20.978797912597656,
      "learning_rate": 1.6888460302153647e-05,
      "loss": 0.664,
      "step": 14520
    },
    {
      "epoch": 1.556841315761277,
      "grad_norm": 135.78932189941406,
      "learning_rate": 1.6886317368477446e-05,
      "loss": 0.8119,
      "step": 14530
    },
    {
      "epoch": 1.5579127825993786,
      "grad_norm": 13.931138038635254,
      "learning_rate": 1.6884174434801245e-05,
      "loss": 0.2761,
      "step": 14540
    },
    {
      "epoch": 1.55898424943748,
      "grad_norm": 0.2681211829185486,
      "learning_rate": 1.688203150112504e-05,
      "loss": 1.1242,
      "step": 14550
    },
    {
      "epoch": 1.5600557162755813,
      "grad_norm": 0.13406264781951904,
      "learning_rate": 1.687988856744884e-05,
      "loss": 0.2424,
      "step": 14560
    },
    {
      "epoch": 1.5611271831136826,
      "grad_norm": 0.7369041442871094,
      "learning_rate": 1.6877745633772636e-05,
      "loss": 0.0773,
      "step": 14570
    },
    {
      "epoch": 1.562198649951784,
      "grad_norm": 0.04381744936108589,
      "learning_rate": 1.6875602700096435e-05,
      "loss": 0.1926,
      "step": 14580
    },
    {
      "epoch": 1.5632701167898855,
      "grad_norm": 0.4797784984111786,
      "learning_rate": 1.687345976642023e-05,
      "loss": 0.7693,
      "step": 14590
    },
    {
      "epoch": 1.5643415836279866,
      "grad_norm": 2.4357895851135254,
      "learning_rate": 1.6871316832744026e-05,
      "loss": 0.3102,
      "step": 14600
    },
    {
      "epoch": 1.5654130504660881,
      "grad_norm": 0.10714641958475113,
      "learning_rate": 1.6869173899067825e-05,
      "loss": 0.1877,
      "step": 14610
    },
    {
      "epoch": 1.5664845173041895,
      "grad_norm": 0.3692033588886261,
      "learning_rate": 1.686703096539162e-05,
      "loss": 0.4072,
      "step": 14620
    },
    {
      "epoch": 1.5675559841422908,
      "grad_norm": 0.13409510254859924,
      "learning_rate": 1.686488803171542e-05,
      "loss": 0.3751,
      "step": 14630
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 36.95043182373047,
      "learning_rate": 1.686274509803922e-05,
      "loss": 0.4632,
      "step": 14640
    },
    {
      "epoch": 1.5696989178184935,
      "grad_norm": 0.5739642977714539,
      "learning_rate": 1.6860602164363014e-05,
      "loss": 0.4021,
      "step": 14650
    },
    {
      "epoch": 1.570770384656595,
      "grad_norm": 18.1009521484375,
      "learning_rate": 1.6858459230686813e-05,
      "loss": 0.5326,
      "step": 14660
    },
    {
      "epoch": 1.5718418514946961,
      "grad_norm": 0.1042313501238823,
      "learning_rate": 1.685631629701061e-05,
      "loss": 0.3287,
      "step": 14670
    },
    {
      "epoch": 1.5729133183327977,
      "grad_norm": 1.365329623222351,
      "learning_rate": 1.6854173363334405e-05,
      "loss": 0.0139,
      "step": 14680
    },
    {
      "epoch": 1.573984785170899,
      "grad_norm": 20.883771896362305,
      "learning_rate": 1.6852030429658204e-05,
      "loss": 0.7272,
      "step": 14690
    },
    {
      "epoch": 1.5750562520090003,
      "grad_norm": 0.20762084424495697,
      "learning_rate": 1.6849887495982e-05,
      "loss": 0.3985,
      "step": 14700
    },
    {
      "epoch": 1.5761277188471017,
      "grad_norm": 87.33610534667969,
      "learning_rate": 1.68477445623058e-05,
      "loss": 0.3863,
      "step": 14710
    },
    {
      "epoch": 1.577199185685203,
      "grad_norm": 20.096885681152344,
      "learning_rate": 1.6845601628629594e-05,
      "loss": 0.1388,
      "step": 14720
    },
    {
      "epoch": 1.5782706525233046,
      "grad_norm": 0.21780481934547424,
      "learning_rate": 1.6843458694953393e-05,
      "loss": 0.2561,
      "step": 14730
    },
    {
      "epoch": 1.5793421193614057,
      "grad_norm": 0.039062123745679855,
      "learning_rate": 1.684131576127719e-05,
      "loss": 0.5249,
      "step": 14740
    },
    {
      "epoch": 1.5804135861995072,
      "grad_norm": 0.08968473225831985,
      "learning_rate": 1.6839172827600988e-05,
      "loss": 0.629,
      "step": 14750
    },
    {
      "epoch": 1.5814850530376083,
      "grad_norm": 0.19172312319278717,
      "learning_rate": 1.6837029893924784e-05,
      "loss": 0.2338,
      "step": 14760
    },
    {
      "epoch": 1.5825565198757099,
      "grad_norm": 0.06868507713079453,
      "learning_rate": 1.6834886960248583e-05,
      "loss": 0.8637,
      "step": 14770
    },
    {
      "epoch": 1.5836279867138112,
      "grad_norm": 1.2686716318130493,
      "learning_rate": 1.683274402657238e-05,
      "loss": 0.3505,
      "step": 14780
    },
    {
      "epoch": 1.5846994535519126,
      "grad_norm": 0.07251971960067749,
      "learning_rate": 1.6830601092896177e-05,
      "loss": 0.3817,
      "step": 14790
    },
    {
      "epoch": 1.5857709203900139,
      "grad_norm": 30.480478286743164,
      "learning_rate": 1.6828458159219973e-05,
      "loss": 0.3575,
      "step": 14800
    },
    {
      "epoch": 1.5868423872281152,
      "grad_norm": 2.552786350250244,
      "learning_rate": 1.682631522554377e-05,
      "loss": 0.2924,
      "step": 14810
    },
    {
      "epoch": 1.5879138540662168,
      "grad_norm": 31.405439376831055,
      "learning_rate": 1.6824172291867568e-05,
      "loss": 0.2354,
      "step": 14820
    },
    {
      "epoch": 1.5889853209043179,
      "grad_norm": 29.34955596923828,
      "learning_rate": 1.6822029358191367e-05,
      "loss": 0.5496,
      "step": 14830
    },
    {
      "epoch": 1.5900567877424194,
      "grad_norm": 0.668769359588623,
      "learning_rate": 1.6819886424515162e-05,
      "loss": 0.5088,
      "step": 14840
    },
    {
      "epoch": 1.5911282545805208,
      "grad_norm": 0.0798153355717659,
      "learning_rate": 1.681774349083896e-05,
      "loss": 0.2528,
      "step": 14850
    },
    {
      "epoch": 1.592199721418622,
      "grad_norm": 0.3716081976890564,
      "learning_rate": 1.6815600557162757e-05,
      "loss": 0.3067,
      "step": 14860
    },
    {
      "epoch": 1.5932711882567234,
      "grad_norm": 18.118846893310547,
      "learning_rate": 1.6813457623486556e-05,
      "loss": 0.5377,
      "step": 14870
    },
    {
      "epoch": 1.5943426550948248,
      "grad_norm": 0.15385933220386505,
      "learning_rate": 1.6811314689810352e-05,
      "loss": 0.6946,
      "step": 14880
    },
    {
      "epoch": 1.5954141219329263,
      "grad_norm": 21.679719924926758,
      "learning_rate": 1.6809171756134148e-05,
      "loss": 0.277,
      "step": 14890
    },
    {
      "epoch": 1.5964855887710274,
      "grad_norm": 0.15798714756965637,
      "learning_rate": 1.6807028822457947e-05,
      "loss": 0.0186,
      "step": 14900
    },
    {
      "epoch": 1.597557055609129,
      "grad_norm": 0.06852570921182632,
      "learning_rate": 1.6804885888781742e-05,
      "loss": 0.2091,
      "step": 14910
    },
    {
      "epoch": 1.5986285224472303,
      "grad_norm": 0.06503508985042572,
      "learning_rate": 1.680274295510554e-05,
      "loss": 0.4881,
      "step": 14920
    },
    {
      "epoch": 1.5996999892853316,
      "grad_norm": 0.06841713935136795,
      "learning_rate": 1.6800600021429337e-05,
      "loss": 0.9924,
      "step": 14930
    },
    {
      "epoch": 1.600771456123433,
      "grad_norm": 0.37109845876693726,
      "learning_rate": 1.6798457087753136e-05,
      "loss": 0.5928,
      "step": 14940
    },
    {
      "epoch": 1.6018429229615343,
      "grad_norm": 17.906953811645508,
      "learning_rate": 1.6796314154076935e-05,
      "loss": 0.4616,
      "step": 14950
    },
    {
      "epoch": 1.6029143897996359,
      "grad_norm": 0.21555782854557037,
      "learning_rate": 1.679417122040073e-05,
      "loss": 0.3329,
      "step": 14960
    },
    {
      "epoch": 1.603985856637737,
      "grad_norm": 42.595542907714844,
      "learning_rate": 1.6792028286724526e-05,
      "loss": 0.3741,
      "step": 14970
    },
    {
      "epoch": 1.6050573234758385,
      "grad_norm": 0.08306792378425598,
      "learning_rate": 1.6789885353048325e-05,
      "loss": 0.5372,
      "step": 14980
    },
    {
      "epoch": 1.6061287903139396,
      "grad_norm": 20.581418991088867,
      "learning_rate": 1.678774241937212e-05,
      "loss": 0.5944,
      "step": 14990
    },
    {
      "epoch": 1.6072002571520412,
      "grad_norm": 0.2733421325683594,
      "learning_rate": 1.6785599485695917e-05,
      "loss": 0.2012,
      "step": 15000
    },
    {
      "epoch": 1.6082717239901425,
      "grad_norm": 6.2588419914245605,
      "learning_rate": 1.6783456552019716e-05,
      "loss": 0.0698,
      "step": 15010
    },
    {
      "epoch": 1.6093431908282438,
      "grad_norm": 40.95817565917969,
      "learning_rate": 1.6781313618343515e-05,
      "loss": 0.7341,
      "step": 15020
    },
    {
      "epoch": 1.6104146576663452,
      "grad_norm": 14.327570915222168,
      "learning_rate": 1.677917068466731e-05,
      "loss": 0.4866,
      "step": 15030
    },
    {
      "epoch": 1.6114861245044465,
      "grad_norm": 0.058227479457855225,
      "learning_rate": 1.677702775099111e-05,
      "loss": 0.2785,
      "step": 15040
    },
    {
      "epoch": 1.612557591342548,
      "grad_norm": 22.03374671936035,
      "learning_rate": 1.6774884817314905e-05,
      "loss": 0.3049,
      "step": 15050
    },
    {
      "epoch": 1.6136290581806492,
      "grad_norm": 0.10060691833496094,
      "learning_rate": 1.6772741883638704e-05,
      "loss": 0.3236,
      "step": 15060
    },
    {
      "epoch": 1.6147005250187507,
      "grad_norm": 0.28854650259017944,
      "learning_rate": 1.67705989499625e-05,
      "loss": 0.3971,
      "step": 15070
    },
    {
      "epoch": 1.615771991856852,
      "grad_norm": 0.1827850043773651,
      "learning_rate": 1.6768456016286296e-05,
      "loss": 0.2099,
      "step": 15080
    },
    {
      "epoch": 1.6168434586949534,
      "grad_norm": 0.1394234001636505,
      "learning_rate": 1.6766313082610095e-05,
      "loss": 0.6748,
      "step": 15090
    },
    {
      "epoch": 1.6179149255330547,
      "grad_norm": 0.11430871486663818,
      "learning_rate": 1.676417014893389e-05,
      "loss": 0.6648,
      "step": 15100
    },
    {
      "epoch": 1.618986392371156,
      "grad_norm": 0.2974347770214081,
      "learning_rate": 1.676202721525769e-05,
      "loss": 0.6445,
      "step": 15110
    },
    {
      "epoch": 1.6200578592092576,
      "grad_norm": 0.15932351350784302,
      "learning_rate": 1.6759884281581485e-05,
      "loss": 0.3409,
      "step": 15120
    },
    {
      "epoch": 1.6211293260473587,
      "grad_norm": 21.51059913635254,
      "learning_rate": 1.6757741347905284e-05,
      "loss": 0.7842,
      "step": 15130
    },
    {
      "epoch": 1.6222007928854603,
      "grad_norm": 0.12329446524381638,
      "learning_rate": 1.6755598414229083e-05,
      "loss": 0.2495,
      "step": 15140
    },
    {
      "epoch": 1.6232722597235616,
      "grad_norm": 0.1542665958404541,
      "learning_rate": 1.675345548055288e-05,
      "loss": 0.5522,
      "step": 15150
    },
    {
      "epoch": 1.624343726561663,
      "grad_norm": 0.24298490583896637,
      "learning_rate": 1.6751312546876674e-05,
      "loss": 0.0053,
      "step": 15160
    },
    {
      "epoch": 1.6254151933997643,
      "grad_norm": 0.07831688225269318,
      "learning_rate": 1.6749169613200474e-05,
      "loss": 0.6172,
      "step": 15170
    },
    {
      "epoch": 1.6264866602378656,
      "grad_norm": 16.467605590820312,
      "learning_rate": 1.674702667952427e-05,
      "loss": 0.2175,
      "step": 15180
    },
    {
      "epoch": 1.6275581270759671,
      "grad_norm": 17.62429428100586,
      "learning_rate": 1.6744883745848068e-05,
      "loss": 0.5667,
      "step": 15190
    },
    {
      "epoch": 1.6286295939140683,
      "grad_norm": 0.44359076023101807,
      "learning_rate": 1.6742740812171864e-05,
      "loss": 1.0216,
      "step": 15200
    },
    {
      "epoch": 1.6297010607521698,
      "grad_norm": 20.056455612182617,
      "learning_rate": 1.6740597878495663e-05,
      "loss": 0.4125,
      "step": 15210
    },
    {
      "epoch": 1.630772527590271,
      "grad_norm": 18.564292907714844,
      "learning_rate": 1.673845494481946e-05,
      "loss": 0.5322,
      "step": 15220
    },
    {
      "epoch": 1.6318439944283725,
      "grad_norm": 16.589258193969727,
      "learning_rate": 1.6736312011143258e-05,
      "loss": 0.4077,
      "step": 15230
    },
    {
      "epoch": 1.6329154612664738,
      "grad_norm": 31.440448760986328,
      "learning_rate": 1.6734169077467053e-05,
      "loss": 0.7873,
      "step": 15240
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.29312369227409363,
      "learning_rate": 1.6732026143790852e-05,
      "loss": 0.1707,
      "step": 15250
    },
    {
      "epoch": 1.6350583949426767,
      "grad_norm": 102.0009994506836,
      "learning_rate": 1.6729883210114648e-05,
      "loss": 0.7511,
      "step": 15260
    },
    {
      "epoch": 1.6361298617807778,
      "grad_norm": 0.4556410610675812,
      "learning_rate": 1.6727740276438447e-05,
      "loss": 0.3334,
      "step": 15270
    },
    {
      "epoch": 1.6372013286188793,
      "grad_norm": 0.08230411261320114,
      "learning_rate": 1.6725597342762243e-05,
      "loss": 0.4863,
      "step": 15280
    },
    {
      "epoch": 1.6382727954569805,
      "grad_norm": 20.19279670715332,
      "learning_rate": 1.672345440908604e-05,
      "loss": 0.3221,
      "step": 15290
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 0.22566358745098114,
      "learning_rate": 1.6721311475409837e-05,
      "loss": 0.554,
      "step": 15300
    },
    {
      "epoch": 1.6404157291331833,
      "grad_norm": 0.05314876511693001,
      "learning_rate": 1.6719168541733633e-05,
      "loss": 0.1746,
      "step": 15310
    },
    {
      "epoch": 1.6414871959712847,
      "grad_norm": 0.5293877124786377,
      "learning_rate": 1.6717025608057432e-05,
      "loss": 0.2298,
      "step": 15320
    },
    {
      "epoch": 1.642558662809386,
      "grad_norm": 0.11493109911680222,
      "learning_rate": 1.671488267438123e-05,
      "loss": 0.4748,
      "step": 15330
    },
    {
      "epoch": 1.6436301296474873,
      "grad_norm": 0.6817823648452759,
      "learning_rate": 1.6712739740705027e-05,
      "loss": 0.4858,
      "step": 15340
    },
    {
      "epoch": 1.644701596485589,
      "grad_norm": 0.12414436042308807,
      "learning_rate": 1.6710596807028826e-05,
      "loss": 0.2543,
      "step": 15350
    },
    {
      "epoch": 1.64577306332369,
      "grad_norm": 17.493555068969727,
      "learning_rate": 1.670845387335262e-05,
      "loss": 0.6361,
      "step": 15360
    },
    {
      "epoch": 1.6468445301617916,
      "grad_norm": 21.923837661743164,
      "learning_rate": 1.6706310939676417e-05,
      "loss": 0.1754,
      "step": 15370
    },
    {
      "epoch": 1.6479159969998929,
      "grad_norm": 15.123726844787598,
      "learning_rate": 1.6704168006000216e-05,
      "loss": 0.4534,
      "step": 15380
    },
    {
      "epoch": 1.6489874638379942,
      "grad_norm": 21.173471450805664,
      "learning_rate": 1.6702025072324012e-05,
      "loss": 0.4393,
      "step": 15390
    },
    {
      "epoch": 1.6500589306760955,
      "grad_norm": 0.08161094784736633,
      "learning_rate": 1.669988213864781e-05,
      "loss": 0.7165,
      "step": 15400
    },
    {
      "epoch": 1.6511303975141969,
      "grad_norm": 0.22032706439495087,
      "learning_rate": 1.6697739204971607e-05,
      "loss": 0.3414,
      "step": 15410
    },
    {
      "epoch": 1.6522018643522984,
      "grad_norm": 0.1527024656534195,
      "learning_rate": 1.6695596271295406e-05,
      "loss": 0.3698,
      "step": 15420
    },
    {
      "epoch": 1.6532733311903995,
      "grad_norm": 1.2993357181549072,
      "learning_rate": 1.66934533376192e-05,
      "loss": 0.8498,
      "step": 15430
    },
    {
      "epoch": 1.654344798028501,
      "grad_norm": 0.2856413424015045,
      "learning_rate": 1.6691310403943e-05,
      "loss": 0.3095,
      "step": 15440
    },
    {
      "epoch": 1.6554162648666024,
      "grad_norm": 117.33875274658203,
      "learning_rate": 1.6689167470266796e-05,
      "loss": 0.4353,
      "step": 15450
    },
    {
      "epoch": 1.6564877317047038,
      "grad_norm": 0.05708598345518112,
      "learning_rate": 1.6687024536590595e-05,
      "loss": 0.2984,
      "step": 15460
    },
    {
      "epoch": 1.657559198542805,
      "grad_norm": 0.14746464788913727,
      "learning_rate": 1.668488160291439e-05,
      "loss": 0.3168,
      "step": 15470
    },
    {
      "epoch": 1.6586306653809064,
      "grad_norm": 0.03430340066552162,
      "learning_rate": 1.6682738669238186e-05,
      "loss": 0.5429,
      "step": 15480
    },
    {
      "epoch": 1.659702132219008,
      "grad_norm": 20.921274185180664,
      "learning_rate": 1.6680595735561985e-05,
      "loss": 0.6502,
      "step": 15490
    },
    {
      "epoch": 1.660773599057109,
      "grad_norm": 0.3470107614994049,
      "learning_rate": 1.667845280188578e-05,
      "loss": 0.5447,
      "step": 15500
    },
    {
      "epoch": 1.6618450658952106,
      "grad_norm": 3.0050747394561768,
      "learning_rate": 1.667630986820958e-05,
      "loss": 0.3619,
      "step": 15510
    },
    {
      "epoch": 1.6629165327333117,
      "grad_norm": 0.9480595588684082,
      "learning_rate": 1.667416693453338e-05,
      "loss": 0.1207,
      "step": 15520
    },
    {
      "epoch": 1.6639879995714133,
      "grad_norm": 0.06677594780921936,
      "learning_rate": 1.6672024000857175e-05,
      "loss": 0.3416,
      "step": 15530
    },
    {
      "epoch": 1.6650594664095146,
      "grad_norm": 0.06843560934066772,
      "learning_rate": 1.6669881067180974e-05,
      "loss": 0.171,
      "step": 15540
    },
    {
      "epoch": 1.666130933247616,
      "grad_norm": 24.916275024414062,
      "learning_rate": 1.666773813350477e-05,
      "loss": 0.8948,
      "step": 15550
    },
    {
      "epoch": 1.6672024000857173,
      "grad_norm": 16.74474334716797,
      "learning_rate": 1.6665595199828565e-05,
      "loss": 0.3221,
      "step": 15560
    },
    {
      "epoch": 1.6682738669238186,
      "grad_norm": 0.03960451856255531,
      "learning_rate": 1.6663452266152364e-05,
      "loss": 0.3096,
      "step": 15570
    },
    {
      "epoch": 1.6693453337619202,
      "grad_norm": 0.07864739745855331,
      "learning_rate": 1.666130933247616e-05,
      "loss": 0.3586,
      "step": 15580
    },
    {
      "epoch": 1.6704168006000213,
      "grad_norm": 14.30150032043457,
      "learning_rate": 1.665916639879996e-05,
      "loss": 0.4939,
      "step": 15590
    },
    {
      "epoch": 1.6714882674381228,
      "grad_norm": 0.5763757824897766,
      "learning_rate": 1.6657023465123755e-05,
      "loss": 0.1974,
      "step": 15600
    },
    {
      "epoch": 1.6725597342762242,
      "grad_norm": 0.15132923424243927,
      "learning_rate": 1.6654880531447554e-05,
      "loss": 0.5373,
      "step": 15610
    },
    {
      "epoch": 1.6736312011143255,
      "grad_norm": 0.15326234698295593,
      "learning_rate": 1.6652737597771353e-05,
      "loss": 0.7871,
      "step": 15620
    },
    {
      "epoch": 1.6747026679524268,
      "grad_norm": 0.13777418434619904,
      "learning_rate": 1.665059466409515e-05,
      "loss": 0.4501,
      "step": 15630
    },
    {
      "epoch": 1.6757741347905282,
      "grad_norm": 0.2439206838607788,
      "learning_rate": 1.6648451730418944e-05,
      "loss": 0.1255,
      "step": 15640
    },
    {
      "epoch": 1.6768456016286297,
      "grad_norm": 0.36285606026649475,
      "learning_rate": 1.6646308796742743e-05,
      "loss": 0.345,
      "step": 15650
    },
    {
      "epoch": 1.6779170684667308,
      "grad_norm": 0.15874305367469788,
      "learning_rate": 1.664416586306654e-05,
      "loss": 0.4817,
      "step": 15660
    },
    {
      "epoch": 1.6789885353048324,
      "grad_norm": 37.68289566040039,
      "learning_rate": 1.6642022929390335e-05,
      "loss": 0.4378,
      "step": 15670
    },
    {
      "epoch": 1.6800600021429337,
      "grad_norm": 0.14283733069896698,
      "learning_rate": 1.6639879995714134e-05,
      "loss": 0.24,
      "step": 15680
    },
    {
      "epoch": 1.681131468981035,
      "grad_norm": 0.05775885283946991,
      "learning_rate": 1.663773706203793e-05,
      "loss": 0.2972,
      "step": 15690
    },
    {
      "epoch": 1.6822029358191364,
      "grad_norm": 0.08677513897418976,
      "learning_rate": 1.6635594128361728e-05,
      "loss": 0.3586,
      "step": 15700
    },
    {
      "epoch": 1.6832744026572377,
      "grad_norm": 0.09965293109416962,
      "learning_rate": 1.6633451194685527e-05,
      "loss": 0.2814,
      "step": 15710
    },
    {
      "epoch": 1.6843458694953393,
      "grad_norm": 0.18893463909626007,
      "learning_rate": 1.6631308261009323e-05,
      "loss": 0.1419,
      "step": 15720
    },
    {
      "epoch": 1.6854173363334404,
      "grad_norm": 0.22710229456424713,
      "learning_rate": 1.6629165327333122e-05,
      "loss": 0.7268,
      "step": 15730
    },
    {
      "epoch": 1.686488803171542,
      "grad_norm": 14.837841033935547,
      "learning_rate": 1.6627022393656918e-05,
      "loss": 0.6526,
      "step": 15740
    },
    {
      "epoch": 1.687560270009643,
      "grad_norm": 0.3739486634731293,
      "learning_rate": 1.6624879459980713e-05,
      "loss": 0.7357,
      "step": 15750
    },
    {
      "epoch": 1.6886317368477446,
      "grad_norm": 1.0224823951721191,
      "learning_rate": 1.6622736526304512e-05,
      "loss": 0.4911,
      "step": 15760
    },
    {
      "epoch": 1.689703203685846,
      "grad_norm": 0.2680346965789795,
      "learning_rate": 1.6620593592628308e-05,
      "loss": 0.5029,
      "step": 15770
    },
    {
      "epoch": 1.6907746705239473,
      "grad_norm": 0.2951349914073944,
      "learning_rate": 1.6618450658952107e-05,
      "loss": 0.5537,
      "step": 15780
    },
    {
      "epoch": 1.6918461373620488,
      "grad_norm": 0.10487440973520279,
      "learning_rate": 1.6616307725275903e-05,
      "loss": 0.2748,
      "step": 15790
    },
    {
      "epoch": 1.69291760420015,
      "grad_norm": 0.4786377549171448,
      "learning_rate": 1.6614164791599702e-05,
      "loss": 0.1836,
      "step": 15800
    },
    {
      "epoch": 1.6939890710382515,
      "grad_norm": 0.12817583978176117,
      "learning_rate": 1.66120218579235e-05,
      "loss": 0.3676,
      "step": 15810
    },
    {
      "epoch": 1.6950605378763526,
      "grad_norm": 243.9555206298828,
      "learning_rate": 1.6609878924247297e-05,
      "loss": 0.3969,
      "step": 15820
    },
    {
      "epoch": 1.6961320047144541,
      "grad_norm": 0.16353805363178253,
      "learning_rate": 1.6607735990571092e-05,
      "loss": 0.3243,
      "step": 15830
    },
    {
      "epoch": 1.6972034715525555,
      "grad_norm": 0.04373849555850029,
      "learning_rate": 1.660559305689489e-05,
      "loss": 0.1248,
      "step": 15840
    },
    {
      "epoch": 1.6982749383906568,
      "grad_norm": 0.16277195513248444,
      "learning_rate": 1.6603450123218687e-05,
      "loss": 0.3202,
      "step": 15850
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.07053495943546295,
      "learning_rate": 1.6601307189542486e-05,
      "loss": 1.0813,
      "step": 15860
    },
    {
      "epoch": 1.7004178720668595,
      "grad_norm": 38.15810012817383,
      "learning_rate": 1.659916425586628e-05,
      "loss": 0.3745,
      "step": 15870
    },
    {
      "epoch": 1.701489338904961,
      "grad_norm": 0.38937026262283325,
      "learning_rate": 1.6597021322190077e-05,
      "loss": 1.0588,
      "step": 15880
    },
    {
      "epoch": 1.7025608057430621,
      "grad_norm": 20.47010612487793,
      "learning_rate": 1.6594878388513876e-05,
      "loss": 0.4336,
      "step": 15890
    },
    {
      "epoch": 1.7036322725811637,
      "grad_norm": 28.930347442626953,
      "learning_rate": 1.6592735454837675e-05,
      "loss": 0.4606,
      "step": 15900
    },
    {
      "epoch": 1.704703739419265,
      "grad_norm": 9.227364540100098,
      "learning_rate": 1.659059252116147e-05,
      "loss": 0.3618,
      "step": 15910
    },
    {
      "epoch": 1.7057752062573663,
      "grad_norm": 20.094125747680664,
      "learning_rate": 1.658844958748527e-05,
      "loss": 0.6459,
      "step": 15920
    },
    {
      "epoch": 1.7068466730954677,
      "grad_norm": 0.4877950847148895,
      "learning_rate": 1.6586306653809066e-05,
      "loss": 0.3465,
      "step": 15930
    },
    {
      "epoch": 1.707918139933569,
      "grad_norm": 95.30609130859375,
      "learning_rate": 1.6584163720132865e-05,
      "loss": 0.4526,
      "step": 15940
    },
    {
      "epoch": 1.7089896067716706,
      "grad_norm": 0.026686573401093483,
      "learning_rate": 1.658202078645666e-05,
      "loss": 0.1629,
      "step": 15950
    },
    {
      "epoch": 1.7100610736097717,
      "grad_norm": 17.80110740661621,
      "learning_rate": 1.6579877852780456e-05,
      "loss": 0.29,
      "step": 15960
    },
    {
      "epoch": 1.7111325404478732,
      "grad_norm": 87.04017639160156,
      "learning_rate": 1.6577734919104255e-05,
      "loss": 0.5228,
      "step": 15970
    },
    {
      "epoch": 1.7122040072859745,
      "grad_norm": 0.8553049564361572,
      "learning_rate": 1.657559198542805e-05,
      "loss": 0.4282,
      "step": 15980
    },
    {
      "epoch": 1.7132754741240759,
      "grad_norm": 0.4101696312427521,
      "learning_rate": 1.657344905175185e-05,
      "loss": 0.2982,
      "step": 15990
    },
    {
      "epoch": 1.7143469409621772,
      "grad_norm": 0.0422096811234951,
      "learning_rate": 1.657130611807565e-05,
      "loss": 0.2825,
      "step": 16000
    },
    {
      "epoch": 1.7154184078002785,
      "grad_norm": 0.016342412680387497,
      "learning_rate": 1.6569163184399445e-05,
      "loss": 0.0089,
      "step": 16010
    },
    {
      "epoch": 1.71648987463838,
      "grad_norm": 0.014138877391815186,
      "learning_rate": 1.6567020250723244e-05,
      "loss": 0.1295,
      "step": 16020
    },
    {
      "epoch": 1.7175613414764812,
      "grad_norm": 28.582048416137695,
      "learning_rate": 1.656487731704704e-05,
      "loss": 0.6078,
      "step": 16030
    },
    {
      "epoch": 1.7186328083145828,
      "grad_norm": 65.4525375366211,
      "learning_rate": 1.6562734383370835e-05,
      "loss": 0.5749,
      "step": 16040
    },
    {
      "epoch": 1.7197042751526839,
      "grad_norm": 35.108856201171875,
      "learning_rate": 1.6560591449694634e-05,
      "loss": 0.563,
      "step": 16050
    },
    {
      "epoch": 1.7207757419907854,
      "grad_norm": 14.604616165161133,
      "learning_rate": 1.655844851601843e-05,
      "loss": 0.8553,
      "step": 16060
    },
    {
      "epoch": 1.7218472088288868,
      "grad_norm": 0.5842198729515076,
      "learning_rate": 1.6556305582342225e-05,
      "loss": 0.0123,
      "step": 16070
    },
    {
      "epoch": 1.722918675666988,
      "grad_norm": 19.839109420776367,
      "learning_rate": 1.6554162648666024e-05,
      "loss": 0.5954,
      "step": 16080
    },
    {
      "epoch": 1.7239901425050894,
      "grad_norm": 0.41803213953971863,
      "learning_rate": 1.6552019714989823e-05,
      "loss": 0.3822,
      "step": 16090
    },
    {
      "epoch": 1.7250616093431907,
      "grad_norm": 31.015316009521484,
      "learning_rate": 1.654987678131362e-05,
      "loss": 0.5123,
      "step": 16100
    },
    {
      "epoch": 1.7261330761812923,
      "grad_norm": 0.3740081191062927,
      "learning_rate": 1.6547733847637418e-05,
      "loss": 0.5045,
      "step": 16110
    },
    {
      "epoch": 1.7272045430193934,
      "grad_norm": 0.15610653162002563,
      "learning_rate": 1.6545590913961214e-05,
      "loss": 0.4402,
      "step": 16120
    },
    {
      "epoch": 1.728276009857495,
      "grad_norm": 23.657211303710938,
      "learning_rate": 1.6543447980285013e-05,
      "loss": 0.5344,
      "step": 16130
    },
    {
      "epoch": 1.7293474766955963,
      "grad_norm": 21.95699119567871,
      "learning_rate": 1.654130504660881e-05,
      "loss": 0.3907,
      "step": 16140
    },
    {
      "epoch": 1.7304189435336976,
      "grad_norm": 0.3560388684272766,
      "learning_rate": 1.6539162112932604e-05,
      "loss": 0.1689,
      "step": 16150
    },
    {
      "epoch": 1.731490410371799,
      "grad_norm": 0.6052768230438232,
      "learning_rate": 1.6537019179256403e-05,
      "loss": 0.2785,
      "step": 16160
    },
    {
      "epoch": 1.7325618772099003,
      "grad_norm": 30.283742904663086,
      "learning_rate": 1.65348762455802e-05,
      "loss": 0.3544,
      "step": 16170
    },
    {
      "epoch": 1.7336333440480018,
      "grad_norm": 3.251636505126953,
      "learning_rate": 1.6532733311903998e-05,
      "loss": 0.7539,
      "step": 16180
    },
    {
      "epoch": 1.734704810886103,
      "grad_norm": 0.20682160556316376,
      "learning_rate": 1.6530590378227797e-05,
      "loss": 0.1887,
      "step": 16190
    },
    {
      "epoch": 1.7357762777242045,
      "grad_norm": 0.17599688470363617,
      "learning_rate": 1.6528447444551593e-05,
      "loss": 0.2914,
      "step": 16200
    },
    {
      "epoch": 1.7368477445623058,
      "grad_norm": 18.01873016357422,
      "learning_rate": 1.6526304510875392e-05,
      "loss": 0.0551,
      "step": 16210
    },
    {
      "epoch": 1.7379192114004072,
      "grad_norm": 0.1538207232952118,
      "learning_rate": 1.6524161577199187e-05,
      "loss": 0.3604,
      "step": 16220
    },
    {
      "epoch": 1.7389906782385085,
      "grad_norm": 21.630945205688477,
      "learning_rate": 1.6522018643522983e-05,
      "loss": 0.7628,
      "step": 16230
    },
    {
      "epoch": 1.7400621450766098,
      "grad_norm": 15.897991180419922,
      "learning_rate": 1.6519875709846782e-05,
      "loss": 0.5164,
      "step": 16240
    },
    {
      "epoch": 1.7411336119147114,
      "grad_norm": 32.49086380004883,
      "learning_rate": 1.6517732776170578e-05,
      "loss": 0.7536,
      "step": 16250
    },
    {
      "epoch": 1.7422050787528125,
      "grad_norm": 0.25490546226501465,
      "learning_rate": 1.6515589842494377e-05,
      "loss": 0.1592,
      "step": 16260
    },
    {
      "epoch": 1.743276545590914,
      "grad_norm": 0.051653459668159485,
      "learning_rate": 1.6513446908818172e-05,
      "loss": 0.6016,
      "step": 16270
    },
    {
      "epoch": 1.7443480124290152,
      "grad_norm": 0.06023173779249191,
      "learning_rate": 1.651130397514197e-05,
      "loss": 0.0027,
      "step": 16280
    },
    {
      "epoch": 1.7454194792671167,
      "grad_norm": 0.2022508680820465,
      "learning_rate": 1.6509161041465767e-05,
      "loss": 0.7472,
      "step": 16290
    },
    {
      "epoch": 1.746490946105218,
      "grad_norm": 0.14482273161411285,
      "learning_rate": 1.6507018107789566e-05,
      "loss": 0.4845,
      "step": 16300
    },
    {
      "epoch": 1.7475624129433194,
      "grad_norm": 18.73541831970215,
      "learning_rate": 1.6504875174113362e-05,
      "loss": 0.1723,
      "step": 16310
    },
    {
      "epoch": 1.748633879781421,
      "grad_norm": 0.3026168644428253,
      "learning_rate": 1.650273224043716e-05,
      "loss": 0.1689,
      "step": 16320
    },
    {
      "epoch": 1.749705346619522,
      "grad_norm": 0.15272007882595062,
      "learning_rate": 1.6500589306760957e-05,
      "loss": 0.2928,
      "step": 16330
    },
    {
      "epoch": 1.7507768134576236,
      "grad_norm": 0.2361261397600174,
      "learning_rate": 1.6498446373084752e-05,
      "loss": 0.6898,
      "step": 16340
    },
    {
      "epoch": 1.7518482802957247,
      "grad_norm": 1.2214019298553467,
      "learning_rate": 1.649630343940855e-05,
      "loss": 0.0065,
      "step": 16350
    },
    {
      "epoch": 1.7529197471338263,
      "grad_norm": 0.013510550372302532,
      "learning_rate": 1.6494160505732347e-05,
      "loss": 0.4704,
      "step": 16360
    },
    {
      "epoch": 1.7539912139719276,
      "grad_norm": 0.34372076392173767,
      "learning_rate": 1.6492017572056146e-05,
      "loss": 0.6391,
      "step": 16370
    },
    {
      "epoch": 1.755062680810029,
      "grad_norm": 0.2555668354034424,
      "learning_rate": 1.6489874638379945e-05,
      "loss": 0.5947,
      "step": 16380
    },
    {
      "epoch": 1.7561341476481303,
      "grad_norm": 0.017666278406977654,
      "learning_rate": 1.648773170470374e-05,
      "loss": 0.5881,
      "step": 16390
    },
    {
      "epoch": 1.7572056144862316,
      "grad_norm": 0.28351232409477234,
      "learning_rate": 1.648558877102754e-05,
      "loss": 0.6995,
      "step": 16400
    },
    {
      "epoch": 1.7582770813243331,
      "grad_norm": 0.07128262519836426,
      "learning_rate": 1.6483445837351335e-05,
      "loss": 0.1642,
      "step": 16410
    },
    {
      "epoch": 1.7593485481624342,
      "grad_norm": 0.39883285760879517,
      "learning_rate": 1.648130290367513e-05,
      "loss": 0.1605,
      "step": 16420
    },
    {
      "epoch": 1.7604200150005358,
      "grad_norm": 0.10813848674297333,
      "learning_rate": 1.647915996999893e-05,
      "loss": 0.1868,
      "step": 16430
    },
    {
      "epoch": 1.7614914818386371,
      "grad_norm": 33.15998458862305,
      "learning_rate": 1.6477017036322726e-05,
      "loss": 0.4962,
      "step": 16440
    },
    {
      "epoch": 1.7625629486767385,
      "grad_norm": 0.1057816594839096,
      "learning_rate": 1.6474874102646525e-05,
      "loss": 0.2538,
      "step": 16450
    },
    {
      "epoch": 1.7636344155148398,
      "grad_norm": 0.32946452498435974,
      "learning_rate": 1.647273116897032e-05,
      "loss": 0.3026,
      "step": 16460
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.056424304842948914,
      "learning_rate": 1.647058823529412e-05,
      "loss": 0.2541,
      "step": 16470
    },
    {
      "epoch": 1.7657773491910427,
      "grad_norm": 0.044603049755096436,
      "learning_rate": 1.6468445301617915e-05,
      "loss": 0.6001,
      "step": 16480
    },
    {
      "epoch": 1.7668488160291438,
      "grad_norm": 17.681306838989258,
      "learning_rate": 1.6466302367941714e-05,
      "loss": 0.6858,
      "step": 16490
    },
    {
      "epoch": 1.7679202828672453,
      "grad_norm": 35.861732482910156,
      "learning_rate": 1.646415943426551e-05,
      "loss": 0.4408,
      "step": 16500
    },
    {
      "epoch": 1.7689917497053467,
      "grad_norm": 0.22691254317760468,
      "learning_rate": 1.646201650058931e-05,
      "loss": 0.4662,
      "step": 16510
    },
    {
      "epoch": 1.770063216543448,
      "grad_norm": 0.25848138332366943,
      "learning_rate": 1.6459873566913105e-05,
      "loss": 0.4522,
      "step": 16520
    },
    {
      "epoch": 1.7711346833815493,
      "grad_norm": 0.19343511760234833,
      "learning_rate": 1.6457730633236904e-05,
      "loss": 0.4459,
      "step": 16530
    },
    {
      "epoch": 1.7722061502196507,
      "grad_norm": 17.300844192504883,
      "learning_rate": 1.64555876995607e-05,
      "loss": 0.4269,
      "step": 16540
    },
    {
      "epoch": 1.7732776170577522,
      "grad_norm": 0.9544672966003418,
      "learning_rate": 1.6453444765884495e-05,
      "loss": 0.4106,
      "step": 16550
    },
    {
      "epoch": 1.7743490838958533,
      "grad_norm": 0.08827870339155197,
      "learning_rate": 1.6451301832208294e-05,
      "loss": 0.2154,
      "step": 16560
    },
    {
      "epoch": 1.7754205507339549,
      "grad_norm": 20.05284881591797,
      "learning_rate": 1.6449158898532093e-05,
      "loss": 0.3763,
      "step": 16570
    },
    {
      "epoch": 1.776492017572056,
      "grad_norm": 0.34060096740722656,
      "learning_rate": 1.644701596485589e-05,
      "loss": 0.4252,
      "step": 16580
    },
    {
      "epoch": 1.7775634844101575,
      "grad_norm": 0.37888476252555847,
      "learning_rate": 1.6444873031179688e-05,
      "loss": 0.6337,
      "step": 16590
    },
    {
      "epoch": 1.7786349512482589,
      "grad_norm": 0.05285168066620827,
      "learning_rate": 1.6442730097503484e-05,
      "loss": 0.2599,
      "step": 16600
    },
    {
      "epoch": 1.7797064180863602,
      "grad_norm": 0.24645346403121948,
      "learning_rate": 1.6440587163827283e-05,
      "loss": 0.3082,
      "step": 16610
    },
    {
      "epoch": 1.7807778849244615,
      "grad_norm": 0.21320119500160217,
      "learning_rate": 1.6438444230151078e-05,
      "loss": 0.1439,
      "step": 16620
    },
    {
      "epoch": 1.7818493517625629,
      "grad_norm": 0.2078152447938919,
      "learning_rate": 1.6436301296474874e-05,
      "loss": 0.1953,
      "step": 16630
    },
    {
      "epoch": 1.7829208186006644,
      "grad_norm": 14.226845741271973,
      "learning_rate": 1.6434158362798673e-05,
      "loss": 0.1924,
      "step": 16640
    },
    {
      "epoch": 1.7839922854387655,
      "grad_norm": 0.06350225955247879,
      "learning_rate": 1.643201542912247e-05,
      "loss": 0.0027,
      "step": 16650
    },
    {
      "epoch": 1.785063752276867,
      "grad_norm": 0.06922737509012222,
      "learning_rate": 1.6429872495446268e-05,
      "loss": 0.7509,
      "step": 16660
    },
    {
      "epoch": 1.7861352191149684,
      "grad_norm": 0.0197118129581213,
      "learning_rate": 1.6427729561770063e-05,
      "loss": 0.703,
      "step": 16670
    },
    {
      "epoch": 1.7872066859530698,
      "grad_norm": 2.1853747367858887,
      "learning_rate": 1.6425586628093862e-05,
      "loss": 0.3388,
      "step": 16680
    },
    {
      "epoch": 1.788278152791171,
      "grad_norm": 0.10730395466089249,
      "learning_rate": 1.642344369441766e-05,
      "loss": 0.3121,
      "step": 16690
    },
    {
      "epoch": 1.7893496196292724,
      "grad_norm": 0.14365725219249725,
      "learning_rate": 1.6421300760741457e-05,
      "loss": 0.3629,
      "step": 16700
    },
    {
      "epoch": 1.790421086467374,
      "grad_norm": 0.039383500814437866,
      "learning_rate": 1.6419157827065253e-05,
      "loss": 0.7283,
      "step": 16710
    },
    {
      "epoch": 1.791492553305475,
      "grad_norm": 0.2980555593967438,
      "learning_rate": 1.6417014893389052e-05,
      "loss": 0.2168,
      "step": 16720
    },
    {
      "epoch": 1.7925640201435766,
      "grad_norm": 272.3472595214844,
      "learning_rate": 1.6414871959712847e-05,
      "loss": 0.8751,
      "step": 16730
    },
    {
      "epoch": 1.793635486981678,
      "grad_norm": 0.1958690583705902,
      "learning_rate": 1.6412729026036643e-05,
      "loss": 0.2245,
      "step": 16740
    },
    {
      "epoch": 1.7947069538197793,
      "grad_norm": 0.31028446555137634,
      "learning_rate": 1.6410586092360442e-05,
      "loss": 0.3426,
      "step": 16750
    },
    {
      "epoch": 1.7957784206578806,
      "grad_norm": 0.1519942283630371,
      "learning_rate": 1.640844315868424e-05,
      "loss": 0.1693,
      "step": 16760
    },
    {
      "epoch": 1.796849887495982,
      "grad_norm": 31.740074157714844,
      "learning_rate": 1.6406300225008037e-05,
      "loss": 0.5328,
      "step": 16770
    },
    {
      "epoch": 1.7979213543340835,
      "grad_norm": 0.06367144733667374,
      "learning_rate": 1.6404157291331836e-05,
      "loss": 0.2262,
      "step": 16780
    },
    {
      "epoch": 1.7989928211721846,
      "grad_norm": 0.07726144045591354,
      "learning_rate": 1.640201435765563e-05,
      "loss": 0.2276,
      "step": 16790
    },
    {
      "epoch": 1.8000642880102862,
      "grad_norm": 0.07252150028944016,
      "learning_rate": 1.639987142397943e-05,
      "loss": 0.5042,
      "step": 16800
    },
    {
      "epoch": 1.8011357548483873,
      "grad_norm": 30.080976486206055,
      "learning_rate": 1.6397728490303226e-05,
      "loss": 0.3928,
      "step": 16810
    },
    {
      "epoch": 1.8022072216864888,
      "grad_norm": 0.4249514937400818,
      "learning_rate": 1.6395585556627022e-05,
      "loss": 0.4009,
      "step": 16820
    },
    {
      "epoch": 1.8032786885245902,
      "grad_norm": 0.6538053750991821,
      "learning_rate": 1.639344262295082e-05,
      "loss": 0.6613,
      "step": 16830
    },
    {
      "epoch": 1.8043501553626915,
      "grad_norm": 0.03858489915728569,
      "learning_rate": 1.6391299689274617e-05,
      "loss": 0.3059,
      "step": 16840
    },
    {
      "epoch": 1.8054216222007928,
      "grad_norm": 0.1869661509990692,
      "learning_rate": 1.6389156755598416e-05,
      "loss": 0.4991,
      "step": 16850
    },
    {
      "epoch": 1.8064930890388942,
      "grad_norm": 0.01899079978466034,
      "learning_rate": 1.638701382192221e-05,
      "loss": 0.0015,
      "step": 16860
    },
    {
      "epoch": 1.8075645558769957,
      "grad_norm": 0.03032659739255905,
      "learning_rate": 1.638487088824601e-05,
      "loss": 0.7813,
      "step": 16870
    },
    {
      "epoch": 1.8086360227150968,
      "grad_norm": 0.2490318864583969,
      "learning_rate": 1.638272795456981e-05,
      "loss": 0.3414,
      "step": 16880
    },
    {
      "epoch": 1.8097074895531984,
      "grad_norm": 0.10232913494110107,
      "learning_rate": 1.6380585020893605e-05,
      "loss": 0.7899,
      "step": 16890
    },
    {
      "epoch": 1.8107789563912997,
      "grad_norm": 56.99252700805664,
      "learning_rate": 1.63784420872174e-05,
      "loss": 0.8614,
      "step": 16900
    },
    {
      "epoch": 1.811850423229401,
      "grad_norm": 2.4860236644744873,
      "learning_rate": 1.63762991535412e-05,
      "loss": 0.531,
      "step": 16910
    },
    {
      "epoch": 1.8129218900675024,
      "grad_norm": 26.304357528686523,
      "learning_rate": 1.6374156219864996e-05,
      "loss": 0.7277,
      "step": 16920
    },
    {
      "epoch": 1.8139933569056037,
      "grad_norm": 0.27050337195396423,
      "learning_rate": 1.6372013286188795e-05,
      "loss": 0.1528,
      "step": 16930
    },
    {
      "epoch": 1.8150648237437053,
      "grad_norm": 0.30696770548820496,
      "learning_rate": 1.636987035251259e-05,
      "loss": 0.7088,
      "step": 16940
    },
    {
      "epoch": 1.8161362905818064,
      "grad_norm": 16.307538986206055,
      "learning_rate": 1.636772741883639e-05,
      "loss": 0.9313,
      "step": 16950
    },
    {
      "epoch": 1.817207757419908,
      "grad_norm": 27.98701286315918,
      "learning_rate": 1.6365584485160185e-05,
      "loss": 0.6613,
      "step": 16960
    },
    {
      "epoch": 1.8182792242580093,
      "grad_norm": 0.04846039414405823,
      "learning_rate": 1.6363441551483984e-05,
      "loss": 0.0136,
      "step": 16970
    },
    {
      "epoch": 1.8193506910961106,
      "grad_norm": 0.8810474872589111,
      "learning_rate": 1.636129861780778e-05,
      "loss": 0.5759,
      "step": 16980
    },
    {
      "epoch": 1.820422157934212,
      "grad_norm": 0.10271517187356949,
      "learning_rate": 1.635915568413158e-05,
      "loss": 0.5682,
      "step": 16990
    },
    {
      "epoch": 1.8214936247723132,
      "grad_norm": 0.3753819167613983,
      "learning_rate": 1.6357012750455374e-05,
      "loss": 0.499,
      "step": 17000
    },
    {
      "epoch": 1.8225650916104148,
      "grad_norm": 96.79674530029297,
      "learning_rate": 1.6354869816779173e-05,
      "loss": 0.3442,
      "step": 17010
    },
    {
      "epoch": 1.823636558448516,
      "grad_norm": 0.17355658113956451,
      "learning_rate": 1.635272688310297e-05,
      "loss": 0.4416,
      "step": 17020
    },
    {
      "epoch": 1.8247080252866175,
      "grad_norm": 25.281387329101562,
      "learning_rate": 1.6350583949426765e-05,
      "loss": 0.6724,
      "step": 17030
    },
    {
      "epoch": 1.8257794921247188,
      "grad_norm": 0.8470081686973572,
      "learning_rate": 1.6348441015750564e-05,
      "loss": 0.1446,
      "step": 17040
    },
    {
      "epoch": 1.8268509589628201,
      "grad_norm": 155.1990203857422,
      "learning_rate": 1.634629808207436e-05,
      "loss": 0.7204,
      "step": 17050
    },
    {
      "epoch": 1.8279224258009215,
      "grad_norm": 0.04391210898756981,
      "learning_rate": 1.634415514839816e-05,
      "loss": 0.3743,
      "step": 17060
    },
    {
      "epoch": 1.8289938926390228,
      "grad_norm": 15.831501960754395,
      "learning_rate": 1.6342012214721958e-05,
      "loss": 0.5277,
      "step": 17070
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 0.8893858790397644,
      "learning_rate": 1.6339869281045753e-05,
      "loss": 0.3841,
      "step": 17080
    },
    {
      "epoch": 1.8311368263152255,
      "grad_norm": 0.023973021656274796,
      "learning_rate": 1.6337726347369552e-05,
      "loss": 0.2667,
      "step": 17090
    },
    {
      "epoch": 1.832208293153327,
      "grad_norm": 0.11204107850790024,
      "learning_rate": 1.6335583413693348e-05,
      "loss": 0.934,
      "step": 17100
    },
    {
      "epoch": 1.8332797599914281,
      "grad_norm": 0.10862860083580017,
      "learning_rate": 1.6333440480017144e-05,
      "loss": 0.2775,
      "step": 17110
    },
    {
      "epoch": 1.8343512268295297,
      "grad_norm": 0.2884475588798523,
      "learning_rate": 1.6331297546340943e-05,
      "loss": 0.3262,
      "step": 17120
    },
    {
      "epoch": 1.835422693667631,
      "grad_norm": 0.4737861752510071,
      "learning_rate": 1.6329154612664738e-05,
      "loss": 0.4787,
      "step": 17130
    },
    {
      "epoch": 1.8364941605057323,
      "grad_norm": 343.0267028808594,
      "learning_rate": 1.6327011678988537e-05,
      "loss": 0.3053,
      "step": 17140
    },
    {
      "epoch": 1.8375656273438337,
      "grad_norm": 19.87706756591797,
      "learning_rate": 1.6324868745312333e-05,
      "loss": 0.3595,
      "step": 17150
    },
    {
      "epoch": 1.838637094181935,
      "grad_norm": 6.517254829406738,
      "learning_rate": 1.6322725811636132e-05,
      "loss": 0.4192,
      "step": 17160
    },
    {
      "epoch": 1.8397085610200365,
      "grad_norm": 32.152530670166016,
      "learning_rate": 1.632058287795993e-05,
      "loss": 0.5421,
      "step": 17170
    },
    {
      "epoch": 1.8407800278581377,
      "grad_norm": 0.15957872569561005,
      "learning_rate": 1.6318439944283727e-05,
      "loss": 0.6216,
      "step": 17180
    },
    {
      "epoch": 1.8418514946962392,
      "grad_norm": 121.79290771484375,
      "learning_rate": 1.6316297010607522e-05,
      "loss": 0.3895,
      "step": 17190
    },
    {
      "epoch": 1.8429229615343405,
      "grad_norm": 4.0128350257873535,
      "learning_rate": 1.631415407693132e-05,
      "loss": 0.3886,
      "step": 17200
    },
    {
      "epoch": 1.8439944283724419,
      "grad_norm": 0.13311338424682617,
      "learning_rate": 1.6312011143255117e-05,
      "loss": 0.3839,
      "step": 17210
    },
    {
      "epoch": 1.8450658952105432,
      "grad_norm": 18.60834503173828,
      "learning_rate": 1.6309868209578913e-05,
      "loss": 0.5022,
      "step": 17220
    },
    {
      "epoch": 1.8461373620486445,
      "grad_norm": 2.2331314086914062,
      "learning_rate": 1.6307725275902712e-05,
      "loss": 0.3245,
      "step": 17230
    },
    {
      "epoch": 1.847208828886746,
      "grad_norm": 158.695068359375,
      "learning_rate": 1.6305582342226508e-05,
      "loss": 0.661,
      "step": 17240
    },
    {
      "epoch": 1.8482802957248472,
      "grad_norm": 0.0926402285695076,
      "learning_rate": 1.6303439408550307e-05,
      "loss": 0.3095,
      "step": 17250
    },
    {
      "epoch": 1.8493517625629488,
      "grad_norm": 112.74463653564453,
      "learning_rate": 1.6301296474874106e-05,
      "loss": 0.5911,
      "step": 17260
    },
    {
      "epoch": 1.85042322940105,
      "grad_norm": 1.4342976808547974,
      "learning_rate": 1.62991535411979e-05,
      "loss": 0.1434,
      "step": 17270
    },
    {
      "epoch": 1.8514946962391514,
      "grad_norm": 0.025534173473715782,
      "learning_rate": 1.62970106075217e-05,
      "loss": 0.2576,
      "step": 17280
    },
    {
      "epoch": 1.8525661630772527,
      "grad_norm": 0.25509920716285706,
      "learning_rate": 1.6294867673845496e-05,
      "loss": 0.4302,
      "step": 17290
    },
    {
      "epoch": 1.853637629915354,
      "grad_norm": 0.010846216231584549,
      "learning_rate": 1.629272474016929e-05,
      "loss": 0.4208,
      "step": 17300
    },
    {
      "epoch": 1.8547090967534556,
      "grad_norm": 20.1806697845459,
      "learning_rate": 1.629058180649309e-05,
      "loss": 0.3944,
      "step": 17310
    },
    {
      "epoch": 1.8557805635915567,
      "grad_norm": 0.02103566564619541,
      "learning_rate": 1.6288438872816886e-05,
      "loss": 0.1983,
      "step": 17320
    },
    {
      "epoch": 1.8568520304296583,
      "grad_norm": 7.7037739753723145,
      "learning_rate": 1.6286295939140685e-05,
      "loss": 0.6128,
      "step": 17330
    },
    {
      "epoch": 1.8579234972677594,
      "grad_norm": 27.947473526000977,
      "learning_rate": 1.628415300546448e-05,
      "loss": 0.6843,
      "step": 17340
    },
    {
      "epoch": 1.858994964105861,
      "grad_norm": 0.08098858594894409,
      "learning_rate": 1.628201007178828e-05,
      "loss": 0.6544,
      "step": 17350
    },
    {
      "epoch": 1.8600664309439623,
      "grad_norm": 19.104759216308594,
      "learning_rate": 1.627986713811208e-05,
      "loss": 0.1885,
      "step": 17360
    },
    {
      "epoch": 1.8611378977820636,
      "grad_norm": 0.26443514227867126,
      "learning_rate": 1.6277724204435875e-05,
      "loss": 0.2806,
      "step": 17370
    },
    {
      "epoch": 1.862209364620165,
      "grad_norm": 0.2136390060186386,
      "learning_rate": 1.627558127075967e-05,
      "loss": 0.7121,
      "step": 17380
    },
    {
      "epoch": 1.8632808314582663,
      "grad_norm": 21.041419982910156,
      "learning_rate": 1.627343833708347e-05,
      "loss": 1.2763,
      "step": 17390
    },
    {
      "epoch": 1.8643522982963678,
      "grad_norm": 0.35041344165802,
      "learning_rate": 1.6271295403407265e-05,
      "loss": 0.3252,
      "step": 17400
    },
    {
      "epoch": 1.865423765134469,
      "grad_norm": 0.7417077422142029,
      "learning_rate": 1.626915246973106e-05,
      "loss": 0.1263,
      "step": 17410
    },
    {
      "epoch": 1.8664952319725705,
      "grad_norm": 0.2514163553714752,
      "learning_rate": 1.626700953605486e-05,
      "loss": 0.5452,
      "step": 17420
    },
    {
      "epoch": 1.8675666988106718,
      "grad_norm": 31.549612045288086,
      "learning_rate": 1.6264866602378656e-05,
      "loss": 0.4763,
      "step": 17430
    },
    {
      "epoch": 1.8686381656487732,
      "grad_norm": 0.3124411106109619,
      "learning_rate": 1.6262723668702455e-05,
      "loss": 0.0066,
      "step": 17440
    },
    {
      "epoch": 1.8697096324868745,
      "grad_norm": 0.06378788501024246,
      "learning_rate": 1.6260580735026254e-05,
      "loss": 0.4997,
      "step": 17450
    },
    {
      "epoch": 1.8707810993249758,
      "grad_norm": 0.1567908227443695,
      "learning_rate": 1.625843780135005e-05,
      "loss": 0.3324,
      "step": 17460
    },
    {
      "epoch": 1.8718525661630774,
      "grad_norm": 0.7577521204948425,
      "learning_rate": 1.625629486767385e-05,
      "loss": 0.3761,
      "step": 17470
    },
    {
      "epoch": 1.8729240330011785,
      "grad_norm": 0.1098281592130661,
      "learning_rate": 1.6254151933997644e-05,
      "loss": 0.6031,
      "step": 17480
    },
    {
      "epoch": 1.87399549983928,
      "grad_norm": 40.236141204833984,
      "learning_rate": 1.625200900032144e-05,
      "loss": 0.7082,
      "step": 17490
    },
    {
      "epoch": 1.8750669666773814,
      "grad_norm": 15.253938674926758,
      "learning_rate": 1.624986606664524e-05,
      "loss": 0.4823,
      "step": 17500
    },
    {
      "epoch": 1.8761384335154827,
      "grad_norm": 0.2857248783111572,
      "learning_rate": 1.6247723132969034e-05,
      "loss": 0.7863,
      "step": 17510
    },
    {
      "epoch": 1.877209900353584,
      "grad_norm": 23.62116813659668,
      "learning_rate": 1.6245580199292833e-05,
      "loss": 0.5778,
      "step": 17520
    },
    {
      "epoch": 1.8782813671916854,
      "grad_norm": 0.5220438838005066,
      "learning_rate": 1.624343726561663e-05,
      "loss": 0.2776,
      "step": 17530
    },
    {
      "epoch": 1.879352834029787,
      "grad_norm": 19.86861228942871,
      "learning_rate": 1.6241294331940428e-05,
      "loss": 0.6298,
      "step": 17540
    },
    {
      "epoch": 1.880424300867888,
      "grad_norm": 30.0562744140625,
      "learning_rate": 1.6239151398264227e-05,
      "loss": 0.5144,
      "step": 17550
    },
    {
      "epoch": 1.8814957677059896,
      "grad_norm": 18.17902946472168,
      "learning_rate": 1.6237008464588023e-05,
      "loss": 0.3829,
      "step": 17560
    },
    {
      "epoch": 1.8825672345440907,
      "grad_norm": 0.7504838705062866,
      "learning_rate": 1.623486553091182e-05,
      "loss": 0.4978,
      "step": 17570
    },
    {
      "epoch": 1.8836387013821922,
      "grad_norm": 28.677248001098633,
      "learning_rate": 1.6232722597235618e-05,
      "loss": 0.8354,
      "step": 17580
    },
    {
      "epoch": 1.8847101682202936,
      "grad_norm": 0.0816914439201355,
      "learning_rate": 1.6230579663559413e-05,
      "loss": 0.0901,
      "step": 17590
    },
    {
      "epoch": 1.885781635058395,
      "grad_norm": 19.684181213378906,
      "learning_rate": 1.6228436729883212e-05,
      "loss": 0.2533,
      "step": 17600
    },
    {
      "epoch": 1.8868531018964965,
      "grad_norm": 0.26540571451187134,
      "learning_rate": 1.6226293796207008e-05,
      "loss": 0.4518,
      "step": 17610
    },
    {
      "epoch": 1.8879245687345976,
      "grad_norm": 0.5974821448326111,
      "learning_rate": 1.6224150862530804e-05,
      "loss": 0.4419,
      "step": 17620
    },
    {
      "epoch": 1.8889960355726991,
      "grad_norm": 0.6321991086006165,
      "learning_rate": 1.6222007928854603e-05,
      "loss": 0.228,
      "step": 17630
    },
    {
      "epoch": 1.8900675024108002,
      "grad_norm": 0.27861183881759644,
      "learning_rate": 1.6219864995178402e-05,
      "loss": 0.2757,
      "step": 17640
    },
    {
      "epoch": 1.8911389692489018,
      "grad_norm": 0.23927827179431915,
      "learning_rate": 1.6217722061502197e-05,
      "loss": 0.426,
      "step": 17650
    },
    {
      "epoch": 1.8922104360870031,
      "grad_norm": 0.010994037613272667,
      "learning_rate": 1.6215579127825996e-05,
      "loss": 0.0014,
      "step": 17660
    },
    {
      "epoch": 1.8932819029251045,
      "grad_norm": 0.02318105660378933,
      "learning_rate": 1.6213436194149792e-05,
      "loss": 0.309,
      "step": 17670
    },
    {
      "epoch": 1.8943533697632058,
      "grad_norm": 0.01378016546368599,
      "learning_rate": 1.621129326047359e-05,
      "loss": 0.5939,
      "step": 17680
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.1540190577507019,
      "learning_rate": 1.6209150326797387e-05,
      "loss": 0.2327,
      "step": 17690
    },
    {
      "epoch": 1.8964963034394087,
      "grad_norm": 0.21860180795192719,
      "learning_rate": 1.6207007393121182e-05,
      "loss": 0.4313,
      "step": 17700
    },
    {
      "epoch": 1.8975677702775098,
      "grad_norm": 153.71633911132812,
      "learning_rate": 1.620486445944498e-05,
      "loss": 0.1421,
      "step": 17710
    },
    {
      "epoch": 1.8986392371156113,
      "grad_norm": 0.04658067971467972,
      "learning_rate": 1.6202721525768777e-05,
      "loss": 0.881,
      "step": 17720
    },
    {
      "epoch": 1.8997107039537127,
      "grad_norm": 0.09981285780668259,
      "learning_rate": 1.6200578592092576e-05,
      "loss": 0.7388,
      "step": 17730
    },
    {
      "epoch": 1.900782170791814,
      "grad_norm": 0.8701941967010498,
      "learning_rate": 1.6198435658416375e-05,
      "loss": 0.1348,
      "step": 17740
    },
    {
      "epoch": 1.9018536376299153,
      "grad_norm": 0.24369923770427704,
      "learning_rate": 1.619629272474017e-05,
      "loss": 0.0589,
      "step": 17750
    },
    {
      "epoch": 1.9029251044680167,
      "grad_norm": 0.01431311760097742,
      "learning_rate": 1.619414979106397e-05,
      "loss": 0.1277,
      "step": 17760
    },
    {
      "epoch": 1.9039965713061182,
      "grad_norm": 0.3289302885532379,
      "learning_rate": 1.6192006857387766e-05,
      "loss": 0.8784,
      "step": 17770
    },
    {
      "epoch": 1.9050680381442193,
      "grad_norm": 0.04398656636476517,
      "learning_rate": 1.618986392371156e-05,
      "loss": 0.3586,
      "step": 17780
    },
    {
      "epoch": 1.9061395049823209,
      "grad_norm": 141.66859436035156,
      "learning_rate": 1.618772099003536e-05,
      "loss": 0.5247,
      "step": 17790
    },
    {
      "epoch": 1.9072109718204222,
      "grad_norm": 0.13639098405838013,
      "learning_rate": 1.6185578056359156e-05,
      "loss": 0.3674,
      "step": 17800
    },
    {
      "epoch": 1.9082824386585235,
      "grad_norm": 0.07415609806776047,
      "learning_rate": 1.6183435122682952e-05,
      "loss": 0.0094,
      "step": 17810
    },
    {
      "epoch": 1.9093539054966249,
      "grad_norm": 0.08710049837827682,
      "learning_rate": 1.618129218900675e-05,
      "loss": 0.48,
      "step": 17820
    },
    {
      "epoch": 1.9104253723347262,
      "grad_norm": 15.400101661682129,
      "learning_rate": 1.617914925533055e-05,
      "loss": 0.6101,
      "step": 17830
    },
    {
      "epoch": 1.9114968391728278,
      "grad_norm": 23.21272850036621,
      "learning_rate": 1.6177006321654345e-05,
      "loss": 0.3195,
      "step": 17840
    },
    {
      "epoch": 1.9125683060109289,
      "grad_norm": 0.09360715001821518,
      "learning_rate": 1.6174863387978145e-05,
      "loss": 0.7769,
      "step": 17850
    },
    {
      "epoch": 1.9136397728490304,
      "grad_norm": 0.017302045598626137,
      "learning_rate": 1.617272045430194e-05,
      "loss": 0.1109,
      "step": 17860
    },
    {
      "epoch": 1.9147112396871315,
      "grad_norm": 54.95853042602539,
      "learning_rate": 1.617057752062574e-05,
      "loss": 0.5816,
      "step": 17870
    },
    {
      "epoch": 1.915782706525233,
      "grad_norm": 0.11231539398431778,
      "learning_rate": 1.6168434586949535e-05,
      "loss": 0.7534,
      "step": 17880
    },
    {
      "epoch": 1.9168541733633344,
      "grad_norm": 18.93407440185547,
      "learning_rate": 1.616629165327333e-05,
      "loss": 0.4944,
      "step": 17890
    },
    {
      "epoch": 1.9179256402014357,
      "grad_norm": 2.683534622192383,
      "learning_rate": 1.616414871959713e-05,
      "loss": 0.1616,
      "step": 17900
    },
    {
      "epoch": 1.918997107039537,
      "grad_norm": 46.89893341064453,
      "learning_rate": 1.6162005785920925e-05,
      "loss": 0.1805,
      "step": 17910
    },
    {
      "epoch": 1.9200685738776384,
      "grad_norm": 0.025342486798763275,
      "learning_rate": 1.6159862852244724e-05,
      "loss": 0.024,
      "step": 17920
    },
    {
      "epoch": 1.92114004071574,
      "grad_norm": 0.12448502331972122,
      "learning_rate": 1.6157719918568523e-05,
      "loss": 0.0026,
      "step": 17930
    },
    {
      "epoch": 1.922211507553841,
      "grad_norm": 23.738204956054688,
      "learning_rate": 1.615557698489232e-05,
      "loss": 0.2969,
      "step": 17940
    },
    {
      "epoch": 1.9232829743919426,
      "grad_norm": 25.33948516845703,
      "learning_rate": 1.6153434051216118e-05,
      "loss": 0.5364,
      "step": 17950
    },
    {
      "epoch": 1.924354441230044,
      "grad_norm": 0.1306692510843277,
      "learning_rate": 1.6151291117539914e-05,
      "loss": 0.9094,
      "step": 17960
    },
    {
      "epoch": 1.9254259080681453,
      "grad_norm": 0.23529262840747833,
      "learning_rate": 1.614914818386371e-05,
      "loss": 0.4495,
      "step": 17970
    },
    {
      "epoch": 1.9264973749062466,
      "grad_norm": 0.12350573390722275,
      "learning_rate": 1.614700525018751e-05,
      "loss": 0.3023,
      "step": 17980
    },
    {
      "epoch": 1.927568841744348,
      "grad_norm": 0.12805862724781036,
      "learning_rate": 1.6144862316511304e-05,
      "loss": 0.3184,
      "step": 17990
    },
    {
      "epoch": 1.9286403085824495,
      "grad_norm": 0.055131807923316956,
      "learning_rate": 1.6142719382835103e-05,
      "loss": 0.002,
      "step": 18000
    },
    {
      "epoch": 1.9297117754205506,
      "grad_norm": 17.097105026245117,
      "learning_rate": 1.61405764491589e-05,
      "loss": 0.5875,
      "step": 18010
    },
    {
      "epoch": 1.9307832422586522,
      "grad_norm": 0.24209481477737427,
      "learning_rate": 1.6138433515482698e-05,
      "loss": 0.3583,
      "step": 18020
    },
    {
      "epoch": 1.9318547090967535,
      "grad_norm": 0.16663947701454163,
      "learning_rate": 1.6136290581806494e-05,
      "loss": 0.1456,
      "step": 18030
    },
    {
      "epoch": 1.9329261759348548,
      "grad_norm": 38.89647674560547,
      "learning_rate": 1.6134147648130293e-05,
      "loss": 0.4574,
      "step": 18040
    },
    {
      "epoch": 1.9339976427729562,
      "grad_norm": 0.07717280089855194,
      "learning_rate": 1.6132004714454088e-05,
      "loss": 0.2268,
      "step": 18050
    },
    {
      "epoch": 1.9350691096110575,
      "grad_norm": 0.11860869824886322,
      "learning_rate": 1.6129861780777887e-05,
      "loss": 0.3663,
      "step": 18060
    },
    {
      "epoch": 1.936140576449159,
      "grad_norm": 24.433042526245117,
      "learning_rate": 1.6127718847101683e-05,
      "loss": 0.8059,
      "step": 18070
    },
    {
      "epoch": 1.9372120432872602,
      "grad_norm": 17.910112380981445,
      "learning_rate": 1.6125575913425482e-05,
      "loss": 0.3996,
      "step": 18080
    },
    {
      "epoch": 1.9382835101253617,
      "grad_norm": 96.86961364746094,
      "learning_rate": 1.6123432979749278e-05,
      "loss": 0.5606,
      "step": 18090
    },
    {
      "epoch": 1.9393549769634628,
      "grad_norm": 47.002647399902344,
      "learning_rate": 1.6121290046073073e-05,
      "loss": 0.2314,
      "step": 18100
    },
    {
      "epoch": 1.9404264438015644,
      "grad_norm": 0.10921982675790787,
      "learning_rate": 1.6119147112396872e-05,
      "loss": 0.7066,
      "step": 18110
    },
    {
      "epoch": 1.9414979106396657,
      "grad_norm": 0.8590556979179382,
      "learning_rate": 1.611700417872067e-05,
      "loss": 0.2599,
      "step": 18120
    },
    {
      "epoch": 1.942569377477767,
      "grad_norm": 354.15106201171875,
      "learning_rate": 1.6114861245044467e-05,
      "loss": 1.0558,
      "step": 18130
    },
    {
      "epoch": 1.9436408443158686,
      "grad_norm": 100.60991668701172,
      "learning_rate": 1.6112718311368266e-05,
      "loss": 0.4381,
      "step": 18140
    },
    {
      "epoch": 1.9447123111539697,
      "grad_norm": 0.24177688360214233,
      "learning_rate": 1.6110575377692062e-05,
      "loss": 0.7698,
      "step": 18150
    },
    {
      "epoch": 1.9457837779920713,
      "grad_norm": 0.22179584205150604,
      "learning_rate": 1.6108432444015857e-05,
      "loss": 0.576,
      "step": 18160
    },
    {
      "epoch": 1.9468552448301724,
      "grad_norm": 0.18211589753627777,
      "learning_rate": 1.6106289510339657e-05,
      "loss": 0.3751,
      "step": 18170
    },
    {
      "epoch": 1.947926711668274,
      "grad_norm": 0.35532739758491516,
      "learning_rate": 1.6104146576663452e-05,
      "loss": 0.3591,
      "step": 18180
    },
    {
      "epoch": 1.9489981785063752,
      "grad_norm": 0.1673641800880432,
      "learning_rate": 1.610200364298725e-05,
      "loss": 0.16,
      "step": 18190
    },
    {
      "epoch": 1.9500696453444766,
      "grad_norm": 0.3684552013874054,
      "learning_rate": 1.6099860709311047e-05,
      "loss": 0.3468,
      "step": 18200
    },
    {
      "epoch": 1.951141112182578,
      "grad_norm": 26.069717407226562,
      "learning_rate": 1.6097717775634846e-05,
      "loss": 0.3652,
      "step": 18210
    },
    {
      "epoch": 1.9522125790206792,
      "grad_norm": 0.06210178881883621,
      "learning_rate": 1.609557484195864e-05,
      "loss": 0.0068,
      "step": 18220
    },
    {
      "epoch": 1.9532840458587808,
      "grad_norm": 1.614970088005066,
      "learning_rate": 1.609343190828244e-05,
      "loss": 0.7377,
      "step": 18230
    },
    {
      "epoch": 1.954355512696882,
      "grad_norm": 2.0329573154449463,
      "learning_rate": 1.6091288974606236e-05,
      "loss": 0.4367,
      "step": 18240
    },
    {
      "epoch": 1.9554269795349835,
      "grad_norm": 32.36526870727539,
      "learning_rate": 1.6089146040930035e-05,
      "loss": 0.3727,
      "step": 18250
    },
    {
      "epoch": 1.9564984463730848,
      "grad_norm": 0.1377773880958557,
      "learning_rate": 1.608700310725383e-05,
      "loss": 0.5288,
      "step": 18260
    },
    {
      "epoch": 1.9575699132111861,
      "grad_norm": 0.24575184285640717,
      "learning_rate": 1.608486017357763e-05,
      "loss": 0.3509,
      "step": 18270
    },
    {
      "epoch": 1.9586413800492875,
      "grad_norm": 0.05419398099184036,
      "learning_rate": 1.6082717239901426e-05,
      "loss": 0.2903,
      "step": 18280
    },
    {
      "epoch": 1.9597128468873888,
      "grad_norm": 5.118562698364258,
      "learning_rate": 1.608057430622522e-05,
      "loss": 0.1766,
      "step": 18290
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.1296611875295639,
      "learning_rate": 1.607843137254902e-05,
      "loss": 0.6733,
      "step": 18300
    },
    {
      "epoch": 1.9618557805635914,
      "grad_norm": 0.15606720745563507,
      "learning_rate": 1.607628843887282e-05,
      "loss": 0.3468,
      "step": 18310
    },
    {
      "epoch": 1.962927247401693,
      "grad_norm": 0.9041483998298645,
      "learning_rate": 1.6074145505196615e-05,
      "loss": 0.5242,
      "step": 18320
    },
    {
      "epoch": 1.9639987142397943,
      "grad_norm": 16.664579391479492,
      "learning_rate": 1.6072002571520414e-05,
      "loss": 0.8957,
      "step": 18330
    },
    {
      "epoch": 1.9650701810778957,
      "grad_norm": 0.0510423518717289,
      "learning_rate": 1.606985963784421e-05,
      "loss": 0.4208,
      "step": 18340
    },
    {
      "epoch": 1.966141647915997,
      "grad_norm": 56.68939208984375,
      "learning_rate": 1.606771670416801e-05,
      "loss": 0.8473,
      "step": 18350
    },
    {
      "epoch": 1.9672131147540983,
      "grad_norm": 15.92322826385498,
      "learning_rate": 1.6065573770491805e-05,
      "loss": 0.1889,
      "step": 18360
    },
    {
      "epoch": 1.9682845815921999,
      "grad_norm": 21.973875045776367,
      "learning_rate": 1.60634308368156e-05,
      "loss": 0.5511,
      "step": 18370
    },
    {
      "epoch": 1.969356048430301,
      "grad_norm": 22.991798400878906,
      "learning_rate": 1.60612879031394e-05,
      "loss": 0.4811,
      "step": 18380
    },
    {
      "epoch": 1.9704275152684025,
      "grad_norm": 20.094738006591797,
      "learning_rate": 1.6059144969463195e-05,
      "loss": 0.6655,
      "step": 18390
    },
    {
      "epoch": 1.9714989821065037,
      "grad_norm": 25.455595016479492,
      "learning_rate": 1.6057002035786994e-05,
      "loss": 0.3442,
      "step": 18400
    },
    {
      "epoch": 1.9725704489446052,
      "grad_norm": 0.15480439364910126,
      "learning_rate": 1.605485910211079e-05,
      "loss": 0.3535,
      "step": 18410
    },
    {
      "epoch": 1.9736419157827065,
      "grad_norm": 0.12624473869800568,
      "learning_rate": 1.605271616843459e-05,
      "loss": 0.3528,
      "step": 18420
    },
    {
      "epoch": 1.9747133826208079,
      "grad_norm": 0.38730406761169434,
      "learning_rate": 1.6050573234758388e-05,
      "loss": 0.4284,
      "step": 18430
    },
    {
      "epoch": 1.9757848494589092,
      "grad_norm": 22.481239318847656,
      "learning_rate": 1.6048430301082183e-05,
      "loss": 0.4843,
      "step": 18440
    },
    {
      "epoch": 1.9768563162970105,
      "grad_norm": 97.1596908569336,
      "learning_rate": 1.604628736740598e-05,
      "loss": 0.7244,
      "step": 18450
    },
    {
      "epoch": 1.977927783135112,
      "grad_norm": 0.3314957916736603,
      "learning_rate": 1.6044144433729778e-05,
      "loss": 0.4716,
      "step": 18460
    },
    {
      "epoch": 1.9789992499732132,
      "grad_norm": 0.2610383927822113,
      "learning_rate": 1.6042001500053574e-05,
      "loss": 0.0116,
      "step": 18470
    },
    {
      "epoch": 1.9800707168113147,
      "grad_norm": 0.24631203711032867,
      "learning_rate": 1.603985856637737e-05,
      "loss": 0.1473,
      "step": 18480
    },
    {
      "epoch": 1.981142183649416,
      "grad_norm": 0.34406179189682007,
      "learning_rate": 1.603771563270117e-05,
      "loss": 0.5501,
      "step": 18490
    },
    {
      "epoch": 1.9822136504875174,
      "grad_norm": 0.22853541374206543,
      "learning_rate": 1.6035572699024968e-05,
      "loss": 0.1792,
      "step": 18500
    },
    {
      "epoch": 1.9832851173256187,
      "grad_norm": 0.2715425491333008,
      "learning_rate": 1.6033429765348763e-05,
      "loss": 0.329,
      "step": 18510
    },
    {
      "epoch": 1.98435658416372,
      "grad_norm": 0.09661170840263367,
      "learning_rate": 1.6031286831672562e-05,
      "loss": 0.2649,
      "step": 18520
    },
    {
      "epoch": 1.9854280510018216,
      "grad_norm": 18.154787063598633,
      "learning_rate": 1.6029143897996358e-05,
      "loss": 0.6178,
      "step": 18530
    },
    {
      "epoch": 1.9864995178399227,
      "grad_norm": 0.18026959896087646,
      "learning_rate": 1.6027000964320157e-05,
      "loss": 0.3972,
      "step": 18540
    },
    {
      "epoch": 1.9875709846780243,
      "grad_norm": 0.019103730097413063,
      "learning_rate": 1.6024858030643953e-05,
      "loss": 0.519,
      "step": 18550
    },
    {
      "epoch": 1.9886424515161256,
      "grad_norm": 0.26245900988578796,
      "learning_rate": 1.602271509696775e-05,
      "loss": 0.4947,
      "step": 18560
    },
    {
      "epoch": 1.989713918354227,
      "grad_norm": 0.18330352008342743,
      "learning_rate": 1.6020572163291547e-05,
      "loss": 0.1681,
      "step": 18570
    },
    {
      "epoch": 1.9907853851923283,
      "grad_norm": 0.5057249665260315,
      "learning_rate": 1.6018429229615343e-05,
      "loss": 0.5303,
      "step": 18580
    },
    {
      "epoch": 1.9918568520304296,
      "grad_norm": 0.263290673494339,
      "learning_rate": 1.6016286295939142e-05,
      "loss": 0.7121,
      "step": 18590
    },
    {
      "epoch": 1.9929283188685312,
      "grad_norm": 0.30941179394721985,
      "learning_rate": 1.6014143362262938e-05,
      "loss": 0.2902,
      "step": 18600
    },
    {
      "epoch": 1.9939997857066323,
      "grad_norm": 50.959228515625,
      "learning_rate": 1.6012000428586737e-05,
      "loss": 0.1872,
      "step": 18610
    },
    {
      "epoch": 1.9950712525447338,
      "grad_norm": 15.177518844604492,
      "learning_rate": 1.6009857494910536e-05,
      "loss": 0.4119,
      "step": 18620
    },
    {
      "epoch": 1.996142719382835,
      "grad_norm": 0.023515963926911354,
      "learning_rate": 1.600771456123433e-05,
      "loss": 0.2438,
      "step": 18630
    },
    {
      "epoch": 1.9972141862209365,
      "grad_norm": 18.848657608032227,
      "learning_rate": 1.6005571627558127e-05,
      "loss": 0.5168,
      "step": 18640
    },
    {
      "epoch": 1.9982856530590378,
      "grad_norm": 46.92603302001953,
      "learning_rate": 1.6003428693881926e-05,
      "loss": 0.4879,
      "step": 18650
    },
    {
      "epoch": 1.9993571198971392,
      "grad_norm": 0.4602448642253876,
      "learning_rate": 1.6001285760205722e-05,
      "loss": 0.5809,
      "step": 18660
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9016666666666666,
      "eval_f1": 0.7421328671328671,
      "eval_loss": 0.42358529567718506,
      "eval_precision": 0.755338078291815,
      "eval_recall": 0.729381443298969,
      "eval_runtime": 510.6665,
      "eval_samples_per_second": 11.749,
      "eval_steps_per_second": 3.916,
      "step": 18666
    },
    {
      "epoch": 2.0004285867352407,
      "grad_norm": 0.08740126341581345,
      "learning_rate": 1.599914282652952e-05,
      "loss": 0.4111,
      "step": 18670
    },
    {
      "epoch": 2.001500053573342,
      "grad_norm": 0.43531906604766846,
      "learning_rate": 1.5996999892853317e-05,
      "loss": 0.2994,
      "step": 18680
    },
    {
      "epoch": 2.0025715204114434,
      "grad_norm": 65.33343505859375,
      "learning_rate": 1.5994856959177116e-05,
      "loss": 0.3843,
      "step": 18690
    },
    {
      "epoch": 2.0036429872495445,
      "grad_norm": 17.123397827148438,
      "learning_rate": 1.599271402550091e-05,
      "loss": 0.2784,
      "step": 18700
    },
    {
      "epoch": 2.004714454087646,
      "grad_norm": 4.182875633239746,
      "learning_rate": 1.599057109182471e-05,
      "loss": 0.1797,
      "step": 18710
    },
    {
      "epoch": 2.005785920925747,
      "grad_norm": 0.3642808496952057,
      "learning_rate": 1.5988428158148506e-05,
      "loss": 0.5001,
      "step": 18720
    },
    {
      "epoch": 2.0068573877638487,
      "grad_norm": 0.1028522178530693,
      "learning_rate": 1.5986285224472305e-05,
      "loss": 0.2382,
      "step": 18730
    },
    {
      "epoch": 2.0079288546019503,
      "grad_norm": 18.22345542907715,
      "learning_rate": 1.59841422907961e-05,
      "loss": 0.2888,
      "step": 18740
    },
    {
      "epoch": 2.0090003214400514,
      "grad_norm": 0.08417528867721558,
      "learning_rate": 1.59819993571199e-05,
      "loss": 0.3519,
      "step": 18750
    },
    {
      "epoch": 2.010071788278153,
      "grad_norm": 29.537242889404297,
      "learning_rate": 1.5979856423443695e-05,
      "loss": 0.2631,
      "step": 18760
    },
    {
      "epoch": 2.011143255116254,
      "grad_norm": 20.37625503540039,
      "learning_rate": 1.597771348976749e-05,
      "loss": 0.7253,
      "step": 18770
    },
    {
      "epoch": 2.0122147219543556,
      "grad_norm": 0.103610560297966,
      "learning_rate": 1.597557055609129e-05,
      "loss": 0.4145,
      "step": 18780
    },
    {
      "epoch": 2.0132861887924567,
      "grad_norm": 0.09144546836614609,
      "learning_rate": 1.5973427622415086e-05,
      "loss": 0.1532,
      "step": 18790
    },
    {
      "epoch": 2.0143576556305582,
      "grad_norm": 0.033619605004787445,
      "learning_rate": 1.5971284688738885e-05,
      "loss": 0.2935,
      "step": 18800
    },
    {
      "epoch": 2.01542912246866,
      "grad_norm": 0.14225496351718903,
      "learning_rate": 1.5969141755062684e-05,
      "loss": 0.2246,
      "step": 18810
    },
    {
      "epoch": 2.016500589306761,
      "grad_norm": 0.21824884414672852,
      "learning_rate": 1.596699882138648e-05,
      "loss": 0.4184,
      "step": 18820
    },
    {
      "epoch": 2.0175720561448625,
      "grad_norm": 0.14267495274543762,
      "learning_rate": 1.596485588771028e-05,
      "loss": 0.103,
      "step": 18830
    },
    {
      "epoch": 2.0186435229829636,
      "grad_norm": 14.854625701904297,
      "learning_rate": 1.5962712954034074e-05,
      "loss": 0.3631,
      "step": 18840
    },
    {
      "epoch": 2.019714989821065,
      "grad_norm": 0.06857776641845703,
      "learning_rate": 1.596057002035787e-05,
      "loss": 0.5858,
      "step": 18850
    },
    {
      "epoch": 2.0207864566591662,
      "grad_norm": 0.22789399325847626,
      "learning_rate": 1.595842708668167e-05,
      "loss": 0.4162,
      "step": 18860
    },
    {
      "epoch": 2.021857923497268,
      "grad_norm": 0.20792032778263092,
      "learning_rate": 1.5956284153005465e-05,
      "loss": 0.0043,
      "step": 18870
    },
    {
      "epoch": 2.0229293903353693,
      "grad_norm": 0.3332042098045349,
      "learning_rate": 1.5954141219329264e-05,
      "loss": 0.1004,
      "step": 18880
    },
    {
      "epoch": 2.0240008571734704,
      "grad_norm": 2.7384579181671143,
      "learning_rate": 1.595199828565306e-05,
      "loss": 0.3873,
      "step": 18890
    },
    {
      "epoch": 2.025072324011572,
      "grad_norm": 0.09754624962806702,
      "learning_rate": 1.594985535197686e-05,
      "loss": 0.2844,
      "step": 18900
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.11890784651041031,
      "learning_rate": 1.5947712418300657e-05,
      "loss": 0.3587,
      "step": 18910
    },
    {
      "epoch": 2.0272152576877747,
      "grad_norm": 0.21783365309238434,
      "learning_rate": 1.5945569484624453e-05,
      "loss": 0.595,
      "step": 18920
    },
    {
      "epoch": 2.0282867245258758,
      "grad_norm": 83.4917221069336,
      "learning_rate": 1.594342655094825e-05,
      "loss": 0.3228,
      "step": 18930
    },
    {
      "epoch": 2.0293581913639773,
      "grad_norm": 0.18640285730361938,
      "learning_rate": 1.5941283617272048e-05,
      "loss": 0.5148,
      "step": 18940
    },
    {
      "epoch": 2.0304296582020784,
      "grad_norm": 0.3376823961734772,
      "learning_rate": 1.5939140683595844e-05,
      "loss": 0.7092,
      "step": 18950
    },
    {
      "epoch": 2.03150112504018,
      "grad_norm": 0.3544623553752899,
      "learning_rate": 1.593699774991964e-05,
      "loss": 0.3159,
      "step": 18960
    },
    {
      "epoch": 2.0325725918782815,
      "grad_norm": 0.08616095781326294,
      "learning_rate": 1.5934854816243438e-05,
      "loss": 0.3133,
      "step": 18970
    },
    {
      "epoch": 2.0336440587163827,
      "grad_norm": 0.36437639594078064,
      "learning_rate": 1.5932711882567234e-05,
      "loss": 0.2934,
      "step": 18980
    },
    {
      "epoch": 2.034715525554484,
      "grad_norm": 0.04754188656806946,
      "learning_rate": 1.5930568948891033e-05,
      "loss": 0.3335,
      "step": 18990
    },
    {
      "epoch": 2.0357869923925853,
      "grad_norm": 10.552738189697266,
      "learning_rate": 1.5928426015214832e-05,
      "loss": 0.8695,
      "step": 19000
    },
    {
      "epoch": 2.036858459230687,
      "grad_norm": 74.05985260009766,
      "learning_rate": 1.5926283081538628e-05,
      "loss": 0.245,
      "step": 19010
    },
    {
      "epoch": 2.037929926068788,
      "grad_norm": 0.18686632812023163,
      "learning_rate": 1.5924140147862427e-05,
      "loss": 0.2246,
      "step": 19020
    },
    {
      "epoch": 2.0390013929068895,
      "grad_norm": 0.27043023705482483,
      "learning_rate": 1.5921997214186222e-05,
      "loss": 0.2994,
      "step": 19030
    },
    {
      "epoch": 2.040072859744991,
      "grad_norm": 0.24759067595005035,
      "learning_rate": 1.5919854280510018e-05,
      "loss": 0.1568,
      "step": 19040
    },
    {
      "epoch": 2.041144326583092,
      "grad_norm": 0.07140026241540909,
      "learning_rate": 1.5917711346833817e-05,
      "loss": 0.2044,
      "step": 19050
    },
    {
      "epoch": 2.0422157934211937,
      "grad_norm": 0.038288015872240067,
      "learning_rate": 1.5915568413157613e-05,
      "loss": 0.137,
      "step": 19060
    },
    {
      "epoch": 2.043287260259295,
      "grad_norm": 0.1426323503255844,
      "learning_rate": 1.5913425479481412e-05,
      "loss": 0.5768,
      "step": 19070
    },
    {
      "epoch": 2.0443587270973964,
      "grad_norm": 15.856420516967773,
      "learning_rate": 1.5911282545805207e-05,
      "loss": 0.3752,
      "step": 19080
    },
    {
      "epoch": 2.0454301939354975,
      "grad_norm": 0.17450593411922455,
      "learning_rate": 1.5909139612129006e-05,
      "loss": 0.5147,
      "step": 19090
    },
    {
      "epoch": 2.046501660773599,
      "grad_norm": 0.4362093210220337,
      "learning_rate": 1.5906996678452806e-05,
      "loss": 0.2621,
      "step": 19100
    },
    {
      "epoch": 2.0475731276117006,
      "grad_norm": 148.1326141357422,
      "learning_rate": 1.59048537447766e-05,
      "loss": 0.2136,
      "step": 19110
    },
    {
      "epoch": 2.0486445944498017,
      "grad_norm": 66.36104583740234,
      "learning_rate": 1.5902710811100397e-05,
      "loss": 0.7233,
      "step": 19120
    },
    {
      "epoch": 2.0497160612879033,
      "grad_norm": 0.05667239800095558,
      "learning_rate": 1.5900567877424196e-05,
      "loss": 0.4318,
      "step": 19130
    },
    {
      "epoch": 2.0507875281260044,
      "grad_norm": 0.05999116227030754,
      "learning_rate": 1.589842494374799e-05,
      "loss": 0.2048,
      "step": 19140
    },
    {
      "epoch": 2.051858994964106,
      "grad_norm": 0.16716159880161285,
      "learning_rate": 1.5896282010071787e-05,
      "loss": 0.1448,
      "step": 19150
    },
    {
      "epoch": 2.052930461802207,
      "grad_norm": 67.77103424072266,
      "learning_rate": 1.5894139076395586e-05,
      "loss": 0.4741,
      "step": 19160
    },
    {
      "epoch": 2.0540019286403086,
      "grad_norm": 0.1388111561536789,
      "learning_rate": 1.5891996142719382e-05,
      "loss": 0.1731,
      "step": 19170
    },
    {
      "epoch": 2.0550733954784097,
      "grad_norm": 32.385498046875,
      "learning_rate": 1.588985320904318e-05,
      "loss": 0.196,
      "step": 19180
    },
    {
      "epoch": 2.0561448623165113,
      "grad_norm": 0.23279863595962524,
      "learning_rate": 1.588771027536698e-05,
      "loss": 0.3869,
      "step": 19190
    },
    {
      "epoch": 2.057216329154613,
      "grad_norm": 0.31427502632141113,
      "learning_rate": 1.5885567341690776e-05,
      "loss": 0.2774,
      "step": 19200
    },
    {
      "epoch": 2.058287795992714,
      "grad_norm": 45.68446731567383,
      "learning_rate": 1.5883424408014575e-05,
      "loss": 0.3438,
      "step": 19210
    },
    {
      "epoch": 2.0593592628308155,
      "grad_norm": 0.053385552018880844,
      "learning_rate": 1.588128147433837e-05,
      "loss": 0.4241,
      "step": 19220
    },
    {
      "epoch": 2.0604307296689166,
      "grad_norm": 0.5081304311752319,
      "learning_rate": 1.5879138540662166e-05,
      "loss": 0.2452,
      "step": 19230
    },
    {
      "epoch": 2.061502196507018,
      "grad_norm": 1.1340209245681763,
      "learning_rate": 1.5876995606985965e-05,
      "loss": 0.1793,
      "step": 19240
    },
    {
      "epoch": 2.0625736633451193,
      "grad_norm": 34.374446868896484,
      "learning_rate": 1.587485267330976e-05,
      "loss": 0.7846,
      "step": 19250
    },
    {
      "epoch": 2.063645130183221,
      "grad_norm": 0.03224371746182442,
      "learning_rate": 1.587270973963356e-05,
      "loss": 0.1469,
      "step": 19260
    },
    {
      "epoch": 2.0647165970213224,
      "grad_norm": 0.016934292390942574,
      "learning_rate": 1.5870566805957356e-05,
      "loss": 0.2829,
      "step": 19270
    },
    {
      "epoch": 2.0657880638594235,
      "grad_norm": 0.030559107661247253,
      "learning_rate": 1.5868423872281155e-05,
      "loss": 0.2301,
      "step": 19280
    },
    {
      "epoch": 2.066859530697525,
      "grad_norm": 17.208736419677734,
      "learning_rate": 1.5866280938604954e-05,
      "loss": 0.5042,
      "step": 19290
    },
    {
      "epoch": 2.067930997535626,
      "grad_norm": 0.10177023708820343,
      "learning_rate": 1.586413800492875e-05,
      "loss": 0.7463,
      "step": 19300
    },
    {
      "epoch": 2.0690024643737277,
      "grad_norm": 0.790134072303772,
      "learning_rate": 1.5861995071252545e-05,
      "loss": 0.4839,
      "step": 19310
    },
    {
      "epoch": 2.070073931211829,
      "grad_norm": 45.58892822265625,
      "learning_rate": 1.5859852137576344e-05,
      "loss": 0.3406,
      "step": 19320
    },
    {
      "epoch": 2.0711453980499304,
      "grad_norm": 0.2469111531972885,
      "learning_rate": 1.585770920390014e-05,
      "loss": 0.397,
      "step": 19330
    },
    {
      "epoch": 2.072216864888032,
      "grad_norm": 15.317033767700195,
      "learning_rate": 1.585556627022394e-05,
      "loss": 0.8533,
      "step": 19340
    },
    {
      "epoch": 2.073288331726133,
      "grad_norm": 0.07211676985025406,
      "learning_rate": 1.5853423336547734e-05,
      "loss": 0.3685,
      "step": 19350
    },
    {
      "epoch": 2.0743597985642346,
      "grad_norm": 0.5642811059951782,
      "learning_rate": 1.585128040287153e-05,
      "loss": 0.0056,
      "step": 19360
    },
    {
      "epoch": 2.0754312654023357,
      "grad_norm": 0.022872723639011383,
      "learning_rate": 1.584913746919533e-05,
      "loss": 0.1897,
      "step": 19370
    },
    {
      "epoch": 2.0765027322404372,
      "grad_norm": 0.2689498960971832,
      "learning_rate": 1.5846994535519128e-05,
      "loss": 0.3307,
      "step": 19380
    },
    {
      "epoch": 2.0775741990785384,
      "grad_norm": 0.013157553039491177,
      "learning_rate": 1.5844851601842924e-05,
      "loss": 0.4025,
      "step": 19390
    },
    {
      "epoch": 2.07864566591664,
      "grad_norm": 5.086189270019531,
      "learning_rate": 1.5842708668166723e-05,
      "loss": 0.6119,
      "step": 19400
    },
    {
      "epoch": 2.079717132754741,
      "grad_norm": 0.1266380101442337,
      "learning_rate": 1.584056573449052e-05,
      "loss": 0.054,
      "step": 19410
    },
    {
      "epoch": 2.0807885995928426,
      "grad_norm": 0.022045627236366272,
      "learning_rate": 1.5838422800814318e-05,
      "loss": 0.1881,
      "step": 19420
    },
    {
      "epoch": 2.081860066430944,
      "grad_norm": 0.06909827142953873,
      "learning_rate": 1.5836279867138113e-05,
      "loss": 0.2044,
      "step": 19430
    },
    {
      "epoch": 2.0829315332690452,
      "grad_norm": 0.016948282718658447,
      "learning_rate": 1.583413693346191e-05,
      "loss": 0.4612,
      "step": 19440
    },
    {
      "epoch": 2.084003000107147,
      "grad_norm": 0.04873088002204895,
      "learning_rate": 1.5831993999785708e-05,
      "loss": 0.5569,
      "step": 19450
    },
    {
      "epoch": 2.085074466945248,
      "grad_norm": 51.50774002075195,
      "learning_rate": 1.5829851066109504e-05,
      "loss": 0.1241,
      "step": 19460
    },
    {
      "epoch": 2.0861459337833494,
      "grad_norm": 0.03460313379764557,
      "learning_rate": 1.5827708132433303e-05,
      "loss": 0.0382,
      "step": 19470
    },
    {
      "epoch": 2.0872174006214506,
      "grad_norm": 23.70499610900879,
      "learning_rate": 1.58255651987571e-05,
      "loss": 0.5045,
      "step": 19480
    },
    {
      "epoch": 2.088288867459552,
      "grad_norm": 0.017638983204960823,
      "learning_rate": 1.5823422265080897e-05,
      "loss": 0.453,
      "step": 19490
    },
    {
      "epoch": 2.0893603342976537,
      "grad_norm": 0.03170868754386902,
      "learning_rate": 1.5821279331404696e-05,
      "loss": 0.4305,
      "step": 19500
    },
    {
      "epoch": 2.0904318011357548,
      "grad_norm": 22.75840187072754,
      "learning_rate": 1.5819136397728492e-05,
      "loss": 0.2905,
      "step": 19510
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 0.23514500260353088,
      "learning_rate": 1.5816993464052288e-05,
      "loss": 0.5399,
      "step": 19520
    },
    {
      "epoch": 2.0925747348119574,
      "grad_norm": 0.27433639764785767,
      "learning_rate": 1.5814850530376087e-05,
      "loss": 0.1931,
      "step": 19530
    },
    {
      "epoch": 2.093646201650059,
      "grad_norm": 0.5371645092964172,
      "learning_rate": 1.5812707596699882e-05,
      "loss": 0.1758,
      "step": 19540
    },
    {
      "epoch": 2.09471766848816,
      "grad_norm": 0.02736855484545231,
      "learning_rate": 1.5810564663023678e-05,
      "loss": 0.4835,
      "step": 19550
    },
    {
      "epoch": 2.0957891353262617,
      "grad_norm": 0.12116328626871109,
      "learning_rate": 1.5808421729347477e-05,
      "loss": 0.3872,
      "step": 19560
    },
    {
      "epoch": 2.096860602164363,
      "grad_norm": 0.22315193712711334,
      "learning_rate": 1.5806278795671276e-05,
      "loss": 0.1853,
      "step": 19570
    },
    {
      "epoch": 2.0979320690024643,
      "grad_norm": 0.026312468573451042,
      "learning_rate": 1.5804135861995075e-05,
      "loss": 0.3953,
      "step": 19580
    },
    {
      "epoch": 2.099003535840566,
      "grad_norm": 0.033503297716379166,
      "learning_rate": 1.580199292831887e-05,
      "loss": 0.1793,
      "step": 19590
    },
    {
      "epoch": 2.100075002678667,
      "grad_norm": 1.2353695631027222,
      "learning_rate": 1.5799849994642667e-05,
      "loss": 0.1173,
      "step": 19600
    },
    {
      "epoch": 2.1011464695167685,
      "grad_norm": 0.04925180599093437,
      "learning_rate": 1.5797707060966466e-05,
      "loss": 0.0054,
      "step": 19610
    },
    {
      "epoch": 2.1022179363548696,
      "grad_norm": 0.018669305369257927,
      "learning_rate": 1.579556412729026e-05,
      "loss": 0.7645,
      "step": 19620
    },
    {
      "epoch": 2.103289403192971,
      "grad_norm": 14.318845748901367,
      "learning_rate": 1.5793421193614057e-05,
      "loss": 0.8296,
      "step": 19630
    },
    {
      "epoch": 2.1043608700310727,
      "grad_norm": 0.2092374861240387,
      "learning_rate": 1.5791278259937856e-05,
      "loss": 0.2821,
      "step": 19640
    },
    {
      "epoch": 2.105432336869174,
      "grad_norm": 1.02601957321167,
      "learning_rate": 1.578913532626165e-05,
      "loss": 0.4164,
      "step": 19650
    },
    {
      "epoch": 2.1065038037072754,
      "grad_norm": 15.008838653564453,
      "learning_rate": 1.578699239258545e-05,
      "loss": 0.3155,
      "step": 19660
    },
    {
      "epoch": 2.1075752705453765,
      "grad_norm": 0.03861929848790169,
      "learning_rate": 1.578484945890925e-05,
      "loss": 0.3554,
      "step": 19670
    },
    {
      "epoch": 2.108646737383478,
      "grad_norm": 59.098148345947266,
      "learning_rate": 1.5782706525233045e-05,
      "loss": 0.4447,
      "step": 19680
    },
    {
      "epoch": 2.109718204221579,
      "grad_norm": 0.19169998168945312,
      "learning_rate": 1.5780563591556844e-05,
      "loss": 0.0026,
      "step": 19690
    },
    {
      "epoch": 2.1107896710596807,
      "grad_norm": 0.01652086153626442,
      "learning_rate": 1.577842065788064e-05,
      "loss": 0.2148,
      "step": 19700
    },
    {
      "epoch": 2.1118611378977823,
      "grad_norm": 0.10827462375164032,
      "learning_rate": 1.5776277724204436e-05,
      "loss": 0.1945,
      "step": 19710
    },
    {
      "epoch": 2.1129326047358834,
      "grad_norm": 14.984652519226074,
      "learning_rate": 1.5774134790528235e-05,
      "loss": 0.3569,
      "step": 19720
    },
    {
      "epoch": 2.114004071573985,
      "grad_norm": 0.11888538300991058,
      "learning_rate": 1.577199185685203e-05,
      "loss": 0.1606,
      "step": 19730
    },
    {
      "epoch": 2.115075538412086,
      "grad_norm": 12.874255180358887,
      "learning_rate": 1.576984892317583e-05,
      "loss": 0.0063,
      "step": 19740
    },
    {
      "epoch": 2.1161470052501876,
      "grad_norm": 0.2041734755039215,
      "learning_rate": 1.5767705989499625e-05,
      "loss": 0.182,
      "step": 19750
    },
    {
      "epoch": 2.1172184720882887,
      "grad_norm": 197.4348907470703,
      "learning_rate": 1.5765563055823424e-05,
      "loss": 0.8297,
      "step": 19760
    },
    {
      "epoch": 2.1182899389263903,
      "grad_norm": 0.04770512133836746,
      "learning_rate": 1.5763420122147223e-05,
      "loss": 0.3141,
      "step": 19770
    },
    {
      "epoch": 2.1193614057644914,
      "grad_norm": 0.1390991061925888,
      "learning_rate": 1.576127718847102e-05,
      "loss": 0.1044,
      "step": 19780
    },
    {
      "epoch": 2.120432872602593,
      "grad_norm": 0.012628812342882156,
      "learning_rate": 1.5759134254794815e-05,
      "loss": 0.6854,
      "step": 19790
    },
    {
      "epoch": 2.1215043394406945,
      "grad_norm": 0.2466580867767334,
      "learning_rate": 1.5756991321118614e-05,
      "loss": 0.1291,
      "step": 19800
    },
    {
      "epoch": 2.1225758062787956,
      "grad_norm": 0.07091183960437775,
      "learning_rate": 1.575484838744241e-05,
      "loss": 0.557,
      "step": 19810
    },
    {
      "epoch": 2.123647273116897,
      "grad_norm": 41.945465087890625,
      "learning_rate": 1.575270545376621e-05,
      "loss": 0.3364,
      "step": 19820
    },
    {
      "epoch": 2.1247187399549983,
      "grad_norm": 0.5047691464424133,
      "learning_rate": 1.5750562520090004e-05,
      "loss": 0.0827,
      "step": 19830
    },
    {
      "epoch": 2.1257902067931,
      "grad_norm": 0.024766238406300545,
      "learning_rate": 1.57484195864138e-05,
      "loss": 0.2232,
      "step": 19840
    },
    {
      "epoch": 2.126861673631201,
      "grad_norm": 0.06688311696052551,
      "learning_rate": 1.57462766527376e-05,
      "loss": 0.5298,
      "step": 19850
    },
    {
      "epoch": 2.1279331404693025,
      "grad_norm": 0.021247444674372673,
      "learning_rate": 1.5744133719061398e-05,
      "loss": 0.2078,
      "step": 19860
    },
    {
      "epoch": 2.129004607307404,
      "grad_norm": 1.6811892986297607,
      "learning_rate": 1.5741990785385193e-05,
      "loss": 0.6162,
      "step": 19870
    },
    {
      "epoch": 2.130076074145505,
      "grad_norm": 0.09384078532457352,
      "learning_rate": 1.5739847851708993e-05,
      "loss": 0.4963,
      "step": 19880
    },
    {
      "epoch": 2.1311475409836067,
      "grad_norm": 0.013470284640789032,
      "learning_rate": 1.5737704918032788e-05,
      "loss": 0.0538,
      "step": 19890
    },
    {
      "epoch": 2.132219007821708,
      "grad_norm": 0.012656020931899548,
      "learning_rate": 1.5735561984356587e-05,
      "loss": 0.2015,
      "step": 19900
    },
    {
      "epoch": 2.1332904746598094,
      "grad_norm": 0.16516034305095673,
      "learning_rate": 1.5733419050680383e-05,
      "loss": 0.668,
      "step": 19910
    },
    {
      "epoch": 2.1343619414979105,
      "grad_norm": 29.50790023803711,
      "learning_rate": 1.573127611700418e-05,
      "loss": 0.3629,
      "step": 19920
    },
    {
      "epoch": 2.135433408336012,
      "grad_norm": 0.17628784477710724,
      "learning_rate": 1.5729133183327978e-05,
      "loss": 0.3514,
      "step": 19930
    },
    {
      "epoch": 2.136504875174113,
      "grad_norm": 0.007424242328852415,
      "learning_rate": 1.5726990249651773e-05,
      "loss": 0.1616,
      "step": 19940
    },
    {
      "epoch": 2.1375763420122147,
      "grad_norm": 0.5054734945297241,
      "learning_rate": 1.5724847315975572e-05,
      "loss": 0.5004,
      "step": 19950
    },
    {
      "epoch": 2.1386478088503162,
      "grad_norm": 53.890811920166016,
      "learning_rate": 1.572270438229937e-05,
      "loss": 0.0267,
      "step": 19960
    },
    {
      "epoch": 2.1397192756884174,
      "grad_norm": 0.08673842996358871,
      "learning_rate": 1.5720561448623167e-05,
      "loss": 0.3006,
      "step": 19970
    },
    {
      "epoch": 2.140790742526519,
      "grad_norm": 0.024731559678912163,
      "learning_rate": 1.5718418514946963e-05,
      "loss": 0.6703,
      "step": 19980
    },
    {
      "epoch": 2.14186220936462,
      "grad_norm": 0.1445723921060562,
      "learning_rate": 1.5716275581270762e-05,
      "loss": 0.3968,
      "step": 19990
    },
    {
      "epoch": 2.1429336762027216,
      "grad_norm": 0.005070088431239128,
      "learning_rate": 1.5714132647594557e-05,
      "loss": 0.0015,
      "step": 20000
    },
    {
      "epoch": 2.1440051430408227,
      "grad_norm": 0.04295549541711807,
      "learning_rate": 1.5711989713918356e-05,
      "loss": 0.5931,
      "step": 20010
    },
    {
      "epoch": 2.1450766098789242,
      "grad_norm": 0.12104926258325577,
      "learning_rate": 1.5709846780242152e-05,
      "loss": 0.2663,
      "step": 20020
    },
    {
      "epoch": 2.146148076717026,
      "grad_norm": 0.7920555472373962,
      "learning_rate": 1.5707703846565948e-05,
      "loss": 0.1668,
      "step": 20030
    },
    {
      "epoch": 2.147219543555127,
      "grad_norm": 0.1061861664056778,
      "learning_rate": 1.5705560912889747e-05,
      "loss": 0.3895,
      "step": 20040
    },
    {
      "epoch": 2.1482910103932285,
      "grad_norm": 0.07509168982505798,
      "learning_rate": 1.5703417979213546e-05,
      "loss": 0.3676,
      "step": 20050
    },
    {
      "epoch": 2.1493624772313296,
      "grad_norm": 0.1646725833415985,
      "learning_rate": 1.570127504553734e-05,
      "loss": 0.013,
      "step": 20060
    },
    {
      "epoch": 2.150433944069431,
      "grad_norm": 0.052872877568006516,
      "learning_rate": 1.569913211186114e-05,
      "loss": 0.491,
      "step": 20070
    },
    {
      "epoch": 2.1515054109075322,
      "grad_norm": 0.032419316470623016,
      "learning_rate": 1.5696989178184936e-05,
      "loss": 0.0022,
      "step": 20080
    },
    {
      "epoch": 2.1525768777456338,
      "grad_norm": 0.20709465444087982,
      "learning_rate": 1.5694846244508735e-05,
      "loss": 0.0028,
      "step": 20090
    },
    {
      "epoch": 2.1536483445837353,
      "grad_norm": 0.02771858498454094,
      "learning_rate": 1.569270331083253e-05,
      "loss": 0.0379,
      "step": 20100
    },
    {
      "epoch": 2.1547198114218364,
      "grad_norm": 0.1020447164773941,
      "learning_rate": 1.5690560377156327e-05,
      "loss": 0.6815,
      "step": 20110
    },
    {
      "epoch": 2.155791278259938,
      "grad_norm": 0.02879757434129715,
      "learning_rate": 1.5688417443480126e-05,
      "loss": 0.5012,
      "step": 20120
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 0.060549188405275345,
      "learning_rate": 1.568627450980392e-05,
      "loss": 0.348,
      "step": 20130
    },
    {
      "epoch": 2.1579342119361407,
      "grad_norm": 0.17707256972789764,
      "learning_rate": 1.568413157612772e-05,
      "loss": 0.1224,
      "step": 20140
    },
    {
      "epoch": 2.1590056787742418,
      "grad_norm": 98.53572845458984,
      "learning_rate": 1.568198864245152e-05,
      "loss": 0.6797,
      "step": 20150
    },
    {
      "epoch": 2.1600771456123433,
      "grad_norm": 0.1869349479675293,
      "learning_rate": 1.5679845708775315e-05,
      "loss": 0.3176,
      "step": 20160
    },
    {
      "epoch": 2.161148612450445,
      "grad_norm": 0.256246417760849,
      "learning_rate": 1.5677702775099114e-05,
      "loss": 0.328,
      "step": 20170
    },
    {
      "epoch": 2.162220079288546,
      "grad_norm": 0.02461760863661766,
      "learning_rate": 1.567555984142291e-05,
      "loss": 0.1917,
      "step": 20180
    },
    {
      "epoch": 2.1632915461266475,
      "grad_norm": 37.00639343261719,
      "learning_rate": 1.5673416907746705e-05,
      "loss": 0.505,
      "step": 20190
    },
    {
      "epoch": 2.1643630129647486,
      "grad_norm": 0.05976393446326256,
      "learning_rate": 1.5671273974070505e-05,
      "loss": 0.2131,
      "step": 20200
    },
    {
      "epoch": 2.16543447980285,
      "grad_norm": 0.18544186651706696,
      "learning_rate": 1.56691310403943e-05,
      "loss": 0.5282,
      "step": 20210
    },
    {
      "epoch": 2.1665059466409513,
      "grad_norm": 0.05211963132023811,
      "learning_rate": 1.5666988106718096e-05,
      "loss": 0.1654,
      "step": 20220
    },
    {
      "epoch": 2.167577413479053,
      "grad_norm": 0.037297818809747696,
      "learning_rate": 1.5664845173041895e-05,
      "loss": 0.2835,
      "step": 20230
    },
    {
      "epoch": 2.1686488803171544,
      "grad_norm": 0.27033916115760803,
      "learning_rate": 1.5662702239365694e-05,
      "loss": 0.1837,
      "step": 20240
    },
    {
      "epoch": 2.1697203471552555,
      "grad_norm": 0.9963961839675903,
      "learning_rate": 1.566055930568949e-05,
      "loss": 0.2956,
      "step": 20250
    },
    {
      "epoch": 2.170791813993357,
      "grad_norm": 0.09156160801649094,
      "learning_rate": 1.565841637201329e-05,
      "loss": 0.6065,
      "step": 20260
    },
    {
      "epoch": 2.171863280831458,
      "grad_norm": 0.08478107303380966,
      "learning_rate": 1.5656273438337084e-05,
      "loss": 0.1359,
      "step": 20270
    },
    {
      "epoch": 2.1729347476695597,
      "grad_norm": 0.11017218977212906,
      "learning_rate": 1.5654130504660883e-05,
      "loss": 0.1778,
      "step": 20280
    },
    {
      "epoch": 2.174006214507661,
      "grad_norm": 0.05772913619875908,
      "learning_rate": 1.565198757098468e-05,
      "loss": 0.5557,
      "step": 20290
    },
    {
      "epoch": 2.1750776813457624,
      "grad_norm": 0.20164823532104492,
      "learning_rate": 1.5649844637308475e-05,
      "loss": 0.1927,
      "step": 20300
    },
    {
      "epoch": 2.1761491481838635,
      "grad_norm": 0.11214867979288101,
      "learning_rate": 1.5647701703632274e-05,
      "loss": 0.3145,
      "step": 20310
    },
    {
      "epoch": 2.177220615021965,
      "grad_norm": 17.322811126708984,
      "learning_rate": 1.564555876995607e-05,
      "loss": 0.6387,
      "step": 20320
    },
    {
      "epoch": 2.1782920818600666,
      "grad_norm": 0.1682136207818985,
      "learning_rate": 1.564341583627987e-05,
      "loss": 0.3106,
      "step": 20330
    },
    {
      "epoch": 2.1793635486981677,
      "grad_norm": 0.17683884501457214,
      "learning_rate": 1.5641272902603667e-05,
      "loss": 0.0038,
      "step": 20340
    },
    {
      "epoch": 2.1804350155362693,
      "grad_norm": 0.021294575184583664,
      "learning_rate": 1.5639129968927463e-05,
      "loss": 0.1792,
      "step": 20350
    },
    {
      "epoch": 2.1815064823743704,
      "grad_norm": 0.06773842126131058,
      "learning_rate": 1.5636987035251262e-05,
      "loss": 0.3217,
      "step": 20360
    },
    {
      "epoch": 2.182577949212472,
      "grad_norm": 0.08961135894060135,
      "learning_rate": 1.5634844101575058e-05,
      "loss": 0.1611,
      "step": 20370
    },
    {
      "epoch": 2.183649416050573,
      "grad_norm": 0.024802647531032562,
      "learning_rate": 1.5632701167898854e-05,
      "loss": 0.2615,
      "step": 20380
    },
    {
      "epoch": 2.1847208828886746,
      "grad_norm": 0.03186427056789398,
      "learning_rate": 1.5630558234222653e-05,
      "loss": 0.1344,
      "step": 20390
    },
    {
      "epoch": 2.185792349726776,
      "grad_norm": 0.029558097943663597,
      "learning_rate": 1.5628415300546448e-05,
      "loss": 0.4265,
      "step": 20400
    },
    {
      "epoch": 2.1868638165648773,
      "grad_norm": 1.7117905616760254,
      "learning_rate": 1.5626272366870247e-05,
      "loss": 0.2332,
      "step": 20410
    },
    {
      "epoch": 2.187935283402979,
      "grad_norm": 1.0427744388580322,
      "learning_rate": 1.5624129433194043e-05,
      "loss": 0.3403,
      "step": 20420
    },
    {
      "epoch": 2.18900675024108,
      "grad_norm": 0.4634488523006439,
      "learning_rate": 1.5621986499517842e-05,
      "loss": 0.8069,
      "step": 20430
    },
    {
      "epoch": 2.1900782170791815,
      "grad_norm": 0.41856807470321655,
      "learning_rate": 1.5619843565841638e-05,
      "loss": 0.2321,
      "step": 20440
    },
    {
      "epoch": 2.1911496839172826,
      "grad_norm": 0.02822796255350113,
      "learning_rate": 1.5617700632165437e-05,
      "loss": 0.1869,
      "step": 20450
    },
    {
      "epoch": 2.192221150755384,
      "grad_norm": 22.123966217041016,
      "learning_rate": 1.5615557698489232e-05,
      "loss": 0.5665,
      "step": 20460
    },
    {
      "epoch": 2.1932926175934853,
      "grad_norm": 0.06776589155197144,
      "learning_rate": 1.561341476481303e-05,
      "loss": 0.6308,
      "step": 20470
    },
    {
      "epoch": 2.194364084431587,
      "grad_norm": 0.06413187086582184,
      "learning_rate": 1.5611271831136827e-05,
      "loss": 0.3865,
      "step": 20480
    },
    {
      "epoch": 2.1954355512696884,
      "grad_norm": 0.061189789324998856,
      "learning_rate": 1.5609128897460626e-05,
      "loss": 0.2652,
      "step": 20490
    },
    {
      "epoch": 2.1965070181077895,
      "grad_norm": 0.0814763754606247,
      "learning_rate": 1.5606985963784422e-05,
      "loss": 0.1058,
      "step": 20500
    },
    {
      "epoch": 2.197578484945891,
      "grad_norm": 0.035367175936698914,
      "learning_rate": 1.5604843030108217e-05,
      "loss": 0.0187,
      "step": 20510
    },
    {
      "epoch": 2.198649951783992,
      "grad_norm": 0.07671872526407242,
      "learning_rate": 1.5602700096432017e-05,
      "loss": 0.1534,
      "step": 20520
    },
    {
      "epoch": 2.1997214186220937,
      "grad_norm": 0.10179590433835983,
      "learning_rate": 1.5600557162755816e-05,
      "loss": 0.3899,
      "step": 20530
    },
    {
      "epoch": 2.200792885460195,
      "grad_norm": 53.89191436767578,
      "learning_rate": 1.559841422907961e-05,
      "loss": 0.5386,
      "step": 20540
    },
    {
      "epoch": 2.2018643522982964,
      "grad_norm": 35.62793731689453,
      "learning_rate": 1.559627129540341e-05,
      "loss": 0.3494,
      "step": 20550
    },
    {
      "epoch": 2.202935819136398,
      "grad_norm": 0.10466910153627396,
      "learning_rate": 1.5594128361727206e-05,
      "loss": 0.8894,
      "step": 20560
    },
    {
      "epoch": 2.204007285974499,
      "grad_norm": 0.07872489839792252,
      "learning_rate": 1.5591985428051005e-05,
      "loss": 0.3434,
      "step": 20570
    },
    {
      "epoch": 2.2050787528126006,
      "grad_norm": 0.5317785143852234,
      "learning_rate": 1.55898424943748e-05,
      "loss": 0.1819,
      "step": 20580
    },
    {
      "epoch": 2.2061502196507017,
      "grad_norm": 0.18232953548431396,
      "learning_rate": 1.5587699560698596e-05,
      "loss": 0.4475,
      "step": 20590
    },
    {
      "epoch": 2.2072216864888032,
      "grad_norm": 13.902555465698242,
      "learning_rate": 1.5585556627022395e-05,
      "loss": 0.371,
      "step": 20600
    },
    {
      "epoch": 2.2082931533269043,
      "grad_norm": 0.02034243755042553,
      "learning_rate": 1.558341369334619e-05,
      "loss": 0.2495,
      "step": 20610
    },
    {
      "epoch": 2.209364620165006,
      "grad_norm": 110.07864379882812,
      "learning_rate": 1.558127075966999e-05,
      "loss": 0.1757,
      "step": 20620
    },
    {
      "epoch": 2.2104360870031075,
      "grad_norm": 0.12214349210262299,
      "learning_rate": 1.5579127825993786e-05,
      "loss": 0.1487,
      "step": 20630
    },
    {
      "epoch": 2.2115075538412086,
      "grad_norm": 0.016019215807318687,
      "learning_rate": 1.5576984892317585e-05,
      "loss": 0.0012,
      "step": 20640
    },
    {
      "epoch": 2.21257902067931,
      "grad_norm": 0.3107476234436035,
      "learning_rate": 1.5574841958641384e-05,
      "loss": 0.6879,
      "step": 20650
    },
    {
      "epoch": 2.2136504875174112,
      "grad_norm": 26.085023880004883,
      "learning_rate": 1.557269902496518e-05,
      "loss": 0.2263,
      "step": 20660
    },
    {
      "epoch": 2.214721954355513,
      "grad_norm": 15.058415412902832,
      "learning_rate": 1.5570556091288975e-05,
      "loss": 0.3393,
      "step": 20670
    },
    {
      "epoch": 2.215793421193614,
      "grad_norm": 0.07256045937538147,
      "learning_rate": 1.5568413157612774e-05,
      "loss": 0.0923,
      "step": 20680
    },
    {
      "epoch": 2.2168648880317154,
      "grad_norm": 0.05711378902196884,
      "learning_rate": 1.556627022393657e-05,
      "loss": 0.6006,
      "step": 20690
    },
    {
      "epoch": 2.217936354869817,
      "grad_norm": 0.11267910152673721,
      "learning_rate": 1.5564127290260366e-05,
      "loss": 0.3792,
      "step": 20700
    },
    {
      "epoch": 2.219007821707918,
      "grad_norm": 19.482620239257812,
      "learning_rate": 1.5561984356584165e-05,
      "loss": 0.3283,
      "step": 20710
    },
    {
      "epoch": 2.2200792885460197,
      "grad_norm": 0.08401147276163101,
      "learning_rate": 1.5559841422907964e-05,
      "loss": 0.3576,
      "step": 20720
    },
    {
      "epoch": 2.2211507553841208,
      "grad_norm": 17.186870574951172,
      "learning_rate": 1.555769848923176e-05,
      "loss": 0.5125,
      "step": 20730
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.22440440952777863,
      "learning_rate": 1.555555555555556e-05,
      "loss": 0.2509,
      "step": 20740
    },
    {
      "epoch": 2.2232936890603234,
      "grad_norm": 0.07656648755073547,
      "learning_rate": 1.5553412621879354e-05,
      "loss": 0.0059,
      "step": 20750
    },
    {
      "epoch": 2.224365155898425,
      "grad_norm": 0.06738395243883133,
      "learning_rate": 1.5551269688203153e-05,
      "loss": 0.4511,
      "step": 20760
    },
    {
      "epoch": 2.2254366227365265,
      "grad_norm": 0.13594958186149597,
      "learning_rate": 1.554912675452695e-05,
      "loss": 0.2769,
      "step": 20770
    },
    {
      "epoch": 2.2265080895746276,
      "grad_norm": 0.08688508719205856,
      "learning_rate": 1.5546983820850744e-05,
      "loss": 0.3165,
      "step": 20780
    },
    {
      "epoch": 2.227579556412729,
      "grad_norm": 0.03573961183428764,
      "learning_rate": 1.5544840887174543e-05,
      "loss": 0.4917,
      "step": 20790
    },
    {
      "epoch": 2.2286510232508303,
      "grad_norm": 15.877544403076172,
      "learning_rate": 1.554269795349834e-05,
      "loss": 1.0009,
      "step": 20800
    },
    {
      "epoch": 2.229722490088932,
      "grad_norm": 0.1371164619922638,
      "learning_rate": 1.5540555019822138e-05,
      "loss": 0.5361,
      "step": 20810
    },
    {
      "epoch": 2.230793956927033,
      "grad_norm": 1.368415355682373,
      "learning_rate": 1.5538412086145934e-05,
      "loss": 0.1509,
      "step": 20820
    },
    {
      "epoch": 2.2318654237651345,
      "grad_norm": 0.26103124022483826,
      "learning_rate": 1.5536269152469733e-05,
      "loss": 0.2298,
      "step": 20830
    },
    {
      "epoch": 2.2329368906032356,
      "grad_norm": 0.2640398144721985,
      "learning_rate": 1.5534126218793532e-05,
      "loss": 0.4641,
      "step": 20840
    },
    {
      "epoch": 2.234008357441337,
      "grad_norm": 0.09319860488176346,
      "learning_rate": 1.5531983285117328e-05,
      "loss": 0.1421,
      "step": 20850
    },
    {
      "epoch": 2.2350798242794387,
      "grad_norm": 0.18430502712726593,
      "learning_rate": 1.5529840351441123e-05,
      "loss": 0.2007,
      "step": 20860
    },
    {
      "epoch": 2.23615129111754,
      "grad_norm": 43.39827346801758,
      "learning_rate": 1.5527697417764922e-05,
      "loss": 0.2966,
      "step": 20870
    },
    {
      "epoch": 2.2372227579556414,
      "grad_norm": 0.7567415237426758,
      "learning_rate": 1.5525554484088718e-05,
      "loss": 0.182,
      "step": 20880
    },
    {
      "epoch": 2.2382942247937425,
      "grad_norm": 14.123292922973633,
      "learning_rate": 1.5523411550412514e-05,
      "loss": 0.7458,
      "step": 20890
    },
    {
      "epoch": 2.239365691631844,
      "grad_norm": 0.08570197224617004,
      "learning_rate": 1.5521268616736313e-05,
      "loss": 0.173,
      "step": 20900
    },
    {
      "epoch": 2.240437158469945,
      "grad_norm": 0.2142074704170227,
      "learning_rate": 1.551912568306011e-05,
      "loss": 0.0735,
      "step": 20910
    },
    {
      "epoch": 2.2415086253080467,
      "grad_norm": 8.339693069458008,
      "learning_rate": 1.5516982749383907e-05,
      "loss": 0.4021,
      "step": 20920
    },
    {
      "epoch": 2.242580092146148,
      "grad_norm": 15.603967666625977,
      "learning_rate": 1.5514839815707706e-05,
      "loss": 0.0092,
      "step": 20930
    },
    {
      "epoch": 2.2436515589842494,
      "grad_norm": 0.13358747959136963,
      "learning_rate": 1.5512696882031502e-05,
      "loss": 0.0031,
      "step": 20940
    },
    {
      "epoch": 2.244723025822351,
      "grad_norm": 24.051807403564453,
      "learning_rate": 1.55105539483553e-05,
      "loss": 0.6996,
      "step": 20950
    },
    {
      "epoch": 2.245794492660452,
      "grad_norm": 0.35536444187164307,
      "learning_rate": 1.5508411014679097e-05,
      "loss": 0.6382,
      "step": 20960
    },
    {
      "epoch": 2.2468659594985536,
      "grad_norm": 0.1813669055700302,
      "learning_rate": 1.5506268081002892e-05,
      "loss": 0.1637,
      "step": 20970
    },
    {
      "epoch": 2.2479374263366547,
      "grad_norm": 0.18504658341407776,
      "learning_rate": 1.550412514732669e-05,
      "loss": 0.5824,
      "step": 20980
    },
    {
      "epoch": 2.2490088931747563,
      "grad_norm": 0.12178422510623932,
      "learning_rate": 1.5501982213650487e-05,
      "loss": 0.1748,
      "step": 20990
    },
    {
      "epoch": 2.2500803600128574,
      "grad_norm": 2.094907760620117,
      "learning_rate": 1.5499839279974286e-05,
      "loss": 0.6579,
      "step": 21000
    },
    {
      "epoch": 2.251151826850959,
      "grad_norm": 48.97674560546875,
      "learning_rate": 1.5497696346298082e-05,
      "loss": 0.1915,
      "step": 21010
    },
    {
      "epoch": 2.2522232936890605,
      "grad_norm": 0.32954487204551697,
      "learning_rate": 1.549555341262188e-05,
      "loss": 0.5041,
      "step": 21020
    },
    {
      "epoch": 2.2532947605271616,
      "grad_norm": 0.036978624761104584,
      "learning_rate": 1.549341047894568e-05,
      "loss": 0.4984,
      "step": 21030
    },
    {
      "epoch": 2.254366227365263,
      "grad_norm": 0.39526334404945374,
      "learning_rate": 1.5491267545269476e-05,
      "loss": 0.1483,
      "step": 21040
    },
    {
      "epoch": 2.2554376942033643,
      "grad_norm": 18.925241470336914,
      "learning_rate": 1.548912461159327e-05,
      "loss": 0.3063,
      "step": 21050
    },
    {
      "epoch": 2.256509161041466,
      "grad_norm": 0.1385413557291031,
      "learning_rate": 1.548698167791707e-05,
      "loss": 0.4083,
      "step": 21060
    },
    {
      "epoch": 2.257580627879567,
      "grad_norm": 58.87723159790039,
      "learning_rate": 1.5484838744240866e-05,
      "loss": 0.3422,
      "step": 21070
    },
    {
      "epoch": 2.2586520947176685,
      "grad_norm": 1.2700196504592896,
      "learning_rate": 1.5482695810564665e-05,
      "loss": 0.4244,
      "step": 21080
    },
    {
      "epoch": 2.25972356155577,
      "grad_norm": 0.039467114955186844,
      "learning_rate": 1.548055287688846e-05,
      "loss": 0.3285,
      "step": 21090
    },
    {
      "epoch": 2.260795028393871,
      "grad_norm": 0.4717271029949188,
      "learning_rate": 1.547840994321226e-05,
      "loss": 0.3119,
      "step": 21100
    },
    {
      "epoch": 2.2618664952319727,
      "grad_norm": 0.2919827699661255,
      "learning_rate": 1.5476267009536055e-05,
      "loss": 0.4687,
      "step": 21110
    },
    {
      "epoch": 2.262937962070074,
      "grad_norm": 0.05437931790947914,
      "learning_rate": 1.5474124075859854e-05,
      "loss": 0.0497,
      "step": 21120
    },
    {
      "epoch": 2.2640094289081754,
      "grad_norm": 0.01718849688768387,
      "learning_rate": 1.547198114218365e-05,
      "loss": 0.3863,
      "step": 21130
    },
    {
      "epoch": 2.2650808957462765,
      "grad_norm": 0.1507483273744583,
      "learning_rate": 1.546983820850745e-05,
      "loss": 0.409,
      "step": 21140
    },
    {
      "epoch": 2.266152362584378,
      "grad_norm": 0.03330468013882637,
      "learning_rate": 1.5467695274831245e-05,
      "loss": 0.1621,
      "step": 21150
    },
    {
      "epoch": 2.2672238294224796,
      "grad_norm": 0.04817026108503342,
      "learning_rate": 1.5465552341155044e-05,
      "loss": 0.3081,
      "step": 21160
    },
    {
      "epoch": 2.2682952962605807,
      "grad_norm": 0.018757546320557594,
      "learning_rate": 1.546340940747884e-05,
      "loss": 0.158,
      "step": 21170
    },
    {
      "epoch": 2.2693667630986822,
      "grad_norm": 0.05257783457636833,
      "learning_rate": 1.5461266473802635e-05,
      "loss": 0.254,
      "step": 21180
    },
    {
      "epoch": 2.2704382299367833,
      "grad_norm": 17.13970184326172,
      "learning_rate": 1.5459123540126434e-05,
      "loss": 0.8148,
      "step": 21190
    },
    {
      "epoch": 2.271509696774885,
      "grad_norm": 0.17574277520179749,
      "learning_rate": 1.545698060645023e-05,
      "loss": 0.3886,
      "step": 21200
    },
    {
      "epoch": 2.272581163612986,
      "grad_norm": 0.2301715761423111,
      "learning_rate": 1.545483767277403e-05,
      "loss": 0.3603,
      "step": 21210
    },
    {
      "epoch": 2.2736526304510876,
      "grad_norm": 0.3101893365383148,
      "learning_rate": 1.5452694739097828e-05,
      "loss": 0.1539,
      "step": 21220
    },
    {
      "epoch": 2.274724097289189,
      "grad_norm": 0.8584333062171936,
      "learning_rate": 1.5450551805421624e-05,
      "loss": 0.2935,
      "step": 21230
    },
    {
      "epoch": 2.2757955641272902,
      "grad_norm": 21.720447540283203,
      "learning_rate": 1.5448408871745423e-05,
      "loss": 0.5373,
      "step": 21240
    },
    {
      "epoch": 2.276867030965392,
      "grad_norm": 0.12667366862297058,
      "learning_rate": 1.544626593806922e-05,
      "loss": 0.3867,
      "step": 21250
    },
    {
      "epoch": 2.277938497803493,
      "grad_norm": 1573.13330078125,
      "learning_rate": 1.5444123004393014e-05,
      "loss": 0.1124,
      "step": 21260
    },
    {
      "epoch": 2.2790099646415944,
      "grad_norm": 0.3829106092453003,
      "learning_rate": 1.5441980070716813e-05,
      "loss": 0.1701,
      "step": 21270
    },
    {
      "epoch": 2.2800814314796956,
      "grad_norm": 0.1627287119626999,
      "learning_rate": 1.543983713704061e-05,
      "loss": 0.1925,
      "step": 21280
    },
    {
      "epoch": 2.281152898317797,
      "grad_norm": 0.43491432070732117,
      "learning_rate": 1.5437694203364408e-05,
      "loss": 1.1642,
      "step": 21290
    },
    {
      "epoch": 2.2822243651558987,
      "grad_norm": 0.01902402751147747,
      "learning_rate": 1.5435551269688203e-05,
      "loss": 0.2465,
      "step": 21300
    },
    {
      "epoch": 2.2832958319939998,
      "grad_norm": 23.20781135559082,
      "learning_rate": 1.5433408336012003e-05,
      "loss": 0.2039,
      "step": 21310
    },
    {
      "epoch": 2.2843672988321013,
      "grad_norm": 0.029186978936195374,
      "learning_rate": 1.54312654023358e-05,
      "loss": 0.13,
      "step": 21320
    },
    {
      "epoch": 2.2854387656702024,
      "grad_norm": 0.1407928317785263,
      "learning_rate": 1.5429122468659597e-05,
      "loss": 0.1325,
      "step": 21330
    },
    {
      "epoch": 2.286510232508304,
      "grad_norm": 20.64651107788086,
      "learning_rate": 1.5426979534983393e-05,
      "loss": 0.5385,
      "step": 21340
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 38.8242301940918,
      "learning_rate": 1.5424836601307192e-05,
      "loss": 0.1401,
      "step": 21350
    },
    {
      "epoch": 2.2886531661845066,
      "grad_norm": 0.04520541429519653,
      "learning_rate": 1.5422693667630988e-05,
      "loss": 0.1858,
      "step": 21360
    },
    {
      "epoch": 2.2897246330226078,
      "grad_norm": 0.014453327283263206,
      "learning_rate": 1.5420550733954783e-05,
      "loss": 0.0037,
      "step": 21370
    },
    {
      "epoch": 2.2907960998607093,
      "grad_norm": 0.10602331161499023,
      "learning_rate": 1.5418407800278582e-05,
      "loss": 0.7029,
      "step": 21380
    },
    {
      "epoch": 2.291867566698811,
      "grad_norm": 0.2725512683391571,
      "learning_rate": 1.5416264866602378e-05,
      "loss": 0.6811,
      "step": 21390
    },
    {
      "epoch": 2.292939033536912,
      "grad_norm": 0.026109328493475914,
      "learning_rate": 1.5414121932926177e-05,
      "loss": 0.1541,
      "step": 21400
    },
    {
      "epoch": 2.2940105003750135,
      "grad_norm": 0.33959993720054626,
      "learning_rate": 1.5411978999249976e-05,
      "loss": 0.2567,
      "step": 21410
    },
    {
      "epoch": 2.2950819672131146,
      "grad_norm": 237.58181762695312,
      "learning_rate": 1.5409836065573772e-05,
      "loss": 0.2599,
      "step": 21420
    },
    {
      "epoch": 2.296153434051216,
      "grad_norm": 0.11820054799318314,
      "learning_rate": 1.540769313189757e-05,
      "loss": 0.373,
      "step": 21430
    },
    {
      "epoch": 2.2972249008893173,
      "grad_norm": 0.21128077805042267,
      "learning_rate": 1.5405550198221366e-05,
      "loss": 0.1589,
      "step": 21440
    },
    {
      "epoch": 2.298296367727419,
      "grad_norm": 14.650090217590332,
      "learning_rate": 1.5403407264545162e-05,
      "loss": 0.2566,
      "step": 21450
    },
    {
      "epoch": 2.29936783456552,
      "grad_norm": 0.1709568351507187,
      "learning_rate": 1.540126433086896e-05,
      "loss": 0.1901,
      "step": 21460
    },
    {
      "epoch": 2.3004393014036215,
      "grad_norm": 0.08858610689640045,
      "learning_rate": 1.5399121397192757e-05,
      "loss": 0.6547,
      "step": 21470
    },
    {
      "epoch": 2.301510768241723,
      "grad_norm": 26.261314392089844,
      "learning_rate": 1.5396978463516556e-05,
      "loss": 0.5519,
      "step": 21480
    },
    {
      "epoch": 2.302582235079824,
      "grad_norm": 0.2437407523393631,
      "learning_rate": 1.539483552984035e-05,
      "loss": 0.5026,
      "step": 21490
    },
    {
      "epoch": 2.3036537019179257,
      "grad_norm": 0.346525102853775,
      "learning_rate": 1.539269259616415e-05,
      "loss": 0.3171,
      "step": 21500
    },
    {
      "epoch": 2.304725168756027,
      "grad_norm": 0.747077465057373,
      "learning_rate": 1.539054966248795e-05,
      "loss": 0.167,
      "step": 21510
    },
    {
      "epoch": 2.3057966355941284,
      "grad_norm": 16.419519424438477,
      "learning_rate": 1.5388406728811745e-05,
      "loss": 0.5477,
      "step": 21520
    },
    {
      "epoch": 2.3068681024322295,
      "grad_norm": 0.08109472692012787,
      "learning_rate": 1.538626379513554e-05,
      "loss": 0.1831,
      "step": 21530
    },
    {
      "epoch": 2.307939569270331,
      "grad_norm": 0.12364707887172699,
      "learning_rate": 1.538412086145934e-05,
      "loss": 0.1087,
      "step": 21540
    },
    {
      "epoch": 2.3090110361084326,
      "grad_norm": 0.03538107872009277,
      "learning_rate": 1.5381977927783136e-05,
      "loss": 0.0034,
      "step": 21550
    },
    {
      "epoch": 2.3100825029465337,
      "grad_norm": 0.03402281180024147,
      "learning_rate": 1.5379834994106935e-05,
      "loss": 0.488,
      "step": 21560
    },
    {
      "epoch": 2.3111539697846353,
      "grad_norm": 15.48098373413086,
      "learning_rate": 1.537769206043073e-05,
      "loss": 0.8083,
      "step": 21570
    },
    {
      "epoch": 2.3122254366227364,
      "grad_norm": 0.05368699133396149,
      "learning_rate": 1.5375549126754526e-05,
      "loss": 0.1004,
      "step": 21580
    },
    {
      "epoch": 2.313296903460838,
      "grad_norm": 0.2501109540462494,
      "learning_rate": 1.5373406193078325e-05,
      "loss": 0.1865,
      "step": 21590
    },
    {
      "epoch": 2.314368370298939,
      "grad_norm": 84.35299682617188,
      "learning_rate": 1.5371263259402124e-05,
      "loss": 0.5763,
      "step": 21600
    },
    {
      "epoch": 2.3154398371370406,
      "grad_norm": 0.05264974758028984,
      "learning_rate": 1.536912032572592e-05,
      "loss": 0.1402,
      "step": 21610
    },
    {
      "epoch": 2.316511303975142,
      "grad_norm": 18.190073013305664,
      "learning_rate": 1.536697739204972e-05,
      "loss": 0.4247,
      "step": 21620
    },
    {
      "epoch": 2.3175827708132433,
      "grad_norm": 0.7898712754249573,
      "learning_rate": 1.5364834458373515e-05,
      "loss": 0.4732,
      "step": 21630
    },
    {
      "epoch": 2.318654237651345,
      "grad_norm": 0.23782366514205933,
      "learning_rate": 1.5362691524697314e-05,
      "loss": 0.0065,
      "step": 21640
    },
    {
      "epoch": 2.319725704489446,
      "grad_norm": 0.07123218476772308,
      "learning_rate": 1.536054859102111e-05,
      "loss": 0.1875,
      "step": 21650
    },
    {
      "epoch": 2.3207971713275475,
      "grad_norm": 0.025945164263248444,
      "learning_rate": 1.5358405657344905e-05,
      "loss": 0.3657,
      "step": 21660
    },
    {
      "epoch": 2.3218686381656486,
      "grad_norm": 17.389175415039062,
      "learning_rate": 1.5356262723668704e-05,
      "loss": 0.613,
      "step": 21670
    },
    {
      "epoch": 2.32294010500375,
      "grad_norm": 0.10576831549406052,
      "learning_rate": 1.53541197899925e-05,
      "loss": 0.5535,
      "step": 21680
    },
    {
      "epoch": 2.3240115718418517,
      "grad_norm": 0.4074512720108032,
      "learning_rate": 1.53519768563163e-05,
      "loss": 0.5163,
      "step": 21690
    },
    {
      "epoch": 2.325083038679953,
      "grad_norm": 0.23240786790847778,
      "learning_rate": 1.5349833922640098e-05,
      "loss": 0.2275,
      "step": 21700
    },
    {
      "epoch": 2.3261545055180544,
      "grad_norm": 19.630693435668945,
      "learning_rate": 1.5347690988963893e-05,
      "loss": 0.4407,
      "step": 21710
    },
    {
      "epoch": 2.3272259723561555,
      "grad_norm": 29.881633758544922,
      "learning_rate": 1.5345548055287692e-05,
      "loss": 0.3322,
      "step": 21720
    },
    {
      "epoch": 2.328297439194257,
      "grad_norm": 45.617271423339844,
      "learning_rate": 1.5343405121611488e-05,
      "loss": 0.5167,
      "step": 21730
    },
    {
      "epoch": 2.329368906032358,
      "grad_norm": 1.5619405508041382,
      "learning_rate": 1.5341262187935284e-05,
      "loss": 0.5187,
      "step": 21740
    },
    {
      "epoch": 2.3304403728704597,
      "grad_norm": 0.04257206246256828,
      "learning_rate": 1.5339119254259083e-05,
      "loss": 0.1386,
      "step": 21750
    },
    {
      "epoch": 2.3315118397085612,
      "grad_norm": 0.02820807322859764,
      "learning_rate": 1.533697632058288e-05,
      "loss": 0.0402,
      "step": 21760
    },
    {
      "epoch": 2.3325833065466623,
      "grad_norm": 0.017559317871928215,
      "learning_rate": 1.5334833386906674e-05,
      "loss": 0.0052,
      "step": 21770
    },
    {
      "epoch": 2.333654773384764,
      "grad_norm": 90.33753204345703,
      "learning_rate": 1.5332690453230473e-05,
      "loss": 0.031,
      "step": 21780
    },
    {
      "epoch": 2.334726240222865,
      "grad_norm": 0.009526235982775688,
      "learning_rate": 1.5330547519554272e-05,
      "loss": 0.1854,
      "step": 21790
    },
    {
      "epoch": 2.3357977070609666,
      "grad_norm": 0.05144451931118965,
      "learning_rate": 1.5328404585878068e-05,
      "loss": 0.5859,
      "step": 21800
    },
    {
      "epoch": 2.3368691738990677,
      "grad_norm": 29.43682289123535,
      "learning_rate": 1.5326261652201867e-05,
      "loss": 1.0217,
      "step": 21810
    },
    {
      "epoch": 2.3379406407371692,
      "grad_norm": 52.18879699707031,
      "learning_rate": 1.5324118718525663e-05,
      "loss": 0.5865,
      "step": 21820
    },
    {
      "epoch": 2.339012107575271,
      "grad_norm": 0.1354793757200241,
      "learning_rate": 1.532197578484946e-05,
      "loss": 0.2045,
      "step": 21830
    },
    {
      "epoch": 2.340083574413372,
      "grad_norm": 0.04177789390087128,
      "learning_rate": 1.5319832851173257e-05,
      "loss": 0.3921,
      "step": 21840
    },
    {
      "epoch": 2.3411550412514734,
      "grad_norm": 0.20408831536769867,
      "learning_rate": 1.5317689917497053e-05,
      "loss": 0.3034,
      "step": 21850
    },
    {
      "epoch": 2.3422265080895746,
      "grad_norm": 0.041204120963811874,
      "learning_rate": 1.5315546983820852e-05,
      "loss": 0.3644,
      "step": 21860
    },
    {
      "epoch": 2.343297974927676,
      "grad_norm": 0.13297583162784576,
      "learning_rate": 1.5313404050144648e-05,
      "loss": 0.4135,
      "step": 21870
    },
    {
      "epoch": 2.344369441765777,
      "grad_norm": 20.497058868408203,
      "learning_rate": 1.5311261116468447e-05,
      "loss": 0.4286,
      "step": 21880
    },
    {
      "epoch": 2.3454409086038788,
      "grad_norm": 0.030833039432764053,
      "learning_rate": 1.5309118182792246e-05,
      "loss": 0.1553,
      "step": 21890
    },
    {
      "epoch": 2.34651237544198,
      "grad_norm": 0.05164428427815437,
      "learning_rate": 1.530697524911604e-05,
      "loss": 0.169,
      "step": 21900
    },
    {
      "epoch": 2.3475838422800814,
      "grad_norm": 281.552490234375,
      "learning_rate": 1.530483231543984e-05,
      "loss": 0.835,
      "step": 21910
    },
    {
      "epoch": 2.3486553091181825,
      "grad_norm": 0.026337245479226112,
      "learning_rate": 1.5302689381763636e-05,
      "loss": 0.2477,
      "step": 21920
    },
    {
      "epoch": 2.349726775956284,
      "grad_norm": 0.019963199272751808,
      "learning_rate": 1.5300546448087432e-05,
      "loss": 0.389,
      "step": 21930
    },
    {
      "epoch": 2.3507982427943857,
      "grad_norm": 0.33173513412475586,
      "learning_rate": 1.529840351441123e-05,
      "loss": 0.4292,
      "step": 21940
    },
    {
      "epoch": 2.3518697096324868,
      "grad_norm": 0.21170596778392792,
      "learning_rate": 1.5296260580735027e-05,
      "loss": 0.5089,
      "step": 21950
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.36268433928489685,
      "learning_rate": 1.5294117647058822e-05,
      "loss": 0.3076,
      "step": 21960
    },
    {
      "epoch": 2.3540126433086894,
      "grad_norm": 0.596039891242981,
      "learning_rate": 1.529197471338262e-05,
      "loss": 0.1204,
      "step": 21970
    },
    {
      "epoch": 2.355084110146791,
      "grad_norm": 24.77988052368164,
      "learning_rate": 1.528983177970642e-05,
      "loss": 0.663,
      "step": 21980
    },
    {
      "epoch": 2.356155576984892,
      "grad_norm": 0.40458282828330994,
      "learning_rate": 1.5287688846030216e-05,
      "loss": 0.5237,
      "step": 21990
    },
    {
      "epoch": 2.3572270438229936,
      "grad_norm": 0.08511440455913544,
      "learning_rate": 1.5285545912354015e-05,
      "loss": 0.2183,
      "step": 22000
    },
    {
      "epoch": 2.358298510661095,
      "grad_norm": 16.969980239868164,
      "learning_rate": 1.528340297867781e-05,
      "loss": 0.5031,
      "step": 22010
    },
    {
      "epoch": 2.3593699774991963,
      "grad_norm": 0.15771903097629547,
      "learning_rate": 1.528126004500161e-05,
      "loss": 0.2376,
      "step": 22020
    },
    {
      "epoch": 2.360441444337298,
      "grad_norm": 1.569582223892212,
      "learning_rate": 1.5279117111325405e-05,
      "loss": 0.446,
      "step": 22030
    },
    {
      "epoch": 2.361512911175399,
      "grad_norm": 53.81184768676758,
      "learning_rate": 1.52769741776492e-05,
      "loss": 0.5334,
      "step": 22040
    },
    {
      "epoch": 2.3625843780135005,
      "grad_norm": 24.498119354248047,
      "learning_rate": 1.5274831243973e-05,
      "loss": 0.2241,
      "step": 22050
    },
    {
      "epoch": 2.3636558448516016,
      "grad_norm": 3.6819345951080322,
      "learning_rate": 1.5272688310296796e-05,
      "loss": 0.312,
      "step": 22060
    },
    {
      "epoch": 2.364727311689703,
      "grad_norm": 0.34743455052375793,
      "learning_rate": 1.5270545376620595e-05,
      "loss": 0.1525,
      "step": 22070
    },
    {
      "epoch": 2.3657987785278047,
      "grad_norm": 0.3444948196411133,
      "learning_rate": 1.5268402442944394e-05,
      "loss": 0.3719,
      "step": 22080
    },
    {
      "epoch": 2.366870245365906,
      "grad_norm": 0.8024466633796692,
      "learning_rate": 1.526625950926819e-05,
      "loss": 0.0034,
      "step": 22090
    },
    {
      "epoch": 2.3679417122040074,
      "grad_norm": 0.030954038724303246,
      "learning_rate": 1.526411657559199e-05,
      "loss": 0.176,
      "step": 22100
    },
    {
      "epoch": 2.3690131790421085,
      "grad_norm": 32.9384765625,
      "learning_rate": 1.5261973641915784e-05,
      "loss": 0.2812,
      "step": 22110
    },
    {
      "epoch": 2.37008464588021,
      "grad_norm": 0.08675561100244522,
      "learning_rate": 1.525983070823958e-05,
      "loss": 0.5095,
      "step": 22120
    },
    {
      "epoch": 2.371156112718311,
      "grad_norm": 0.11241395026445389,
      "learning_rate": 1.5257687774563379e-05,
      "loss": 0.2009,
      "step": 22130
    },
    {
      "epoch": 2.3722275795564127,
      "grad_norm": 0.09405171871185303,
      "learning_rate": 1.5255544840887175e-05,
      "loss": 0.8636,
      "step": 22140
    },
    {
      "epoch": 2.3732990463945143,
      "grad_norm": 0.43234071135520935,
      "learning_rate": 1.5253401907210974e-05,
      "loss": 0.2563,
      "step": 22150
    },
    {
      "epoch": 2.3743705132326154,
      "grad_norm": 13.611801147460938,
      "learning_rate": 1.5251258973534771e-05,
      "loss": 0.8024,
      "step": 22160
    },
    {
      "epoch": 2.375441980070717,
      "grad_norm": 21.49168586730957,
      "learning_rate": 1.5249116039858567e-05,
      "loss": 0.4971,
      "step": 22170
    },
    {
      "epoch": 2.376513446908818,
      "grad_norm": 0.19937537610530853,
      "learning_rate": 1.5246973106182366e-05,
      "loss": 0.1397,
      "step": 22180
    },
    {
      "epoch": 2.3775849137469196,
      "grad_norm": 0.46964600682258606,
      "learning_rate": 1.5244830172506161e-05,
      "loss": 0.3133,
      "step": 22190
    },
    {
      "epoch": 2.3786563805850207,
      "grad_norm": 0.2917442321777344,
      "learning_rate": 1.5242687238829959e-05,
      "loss": 0.3259,
      "step": 22200
    },
    {
      "epoch": 2.3797278474231223,
      "grad_norm": 30.38869285583496,
      "learning_rate": 1.5240544305153758e-05,
      "loss": 0.4882,
      "step": 22210
    },
    {
      "epoch": 2.380799314261224,
      "grad_norm": 0.06784435361623764,
      "learning_rate": 1.5238401371477553e-05,
      "loss": 0.3699,
      "step": 22220
    },
    {
      "epoch": 2.381870781099325,
      "grad_norm": 0.3922598958015442,
      "learning_rate": 1.5236258437801352e-05,
      "loss": 0.4696,
      "step": 22230
    },
    {
      "epoch": 2.3829422479374265,
      "grad_norm": 0.031079662963747978,
      "learning_rate": 1.5234115504125148e-05,
      "loss": 0.215,
      "step": 22240
    },
    {
      "epoch": 2.3840137147755276,
      "grad_norm": 0.4556896984577179,
      "learning_rate": 1.5231972570448946e-05,
      "loss": 0.2421,
      "step": 22250
    },
    {
      "epoch": 2.385085181613629,
      "grad_norm": 0.25577911734580994,
      "learning_rate": 1.5229829636772745e-05,
      "loss": 0.1802,
      "step": 22260
    },
    {
      "epoch": 2.3861566484517303,
      "grad_norm": 0.05799533426761627,
      "learning_rate": 1.522768670309654e-05,
      "loss": 0.162,
      "step": 22270
    },
    {
      "epoch": 2.387228115289832,
      "grad_norm": 0.08773204684257507,
      "learning_rate": 1.5225543769420338e-05,
      "loss": 0.0121,
      "step": 22280
    },
    {
      "epoch": 2.3882995821279334,
      "grad_norm": 0.036952219903469086,
      "learning_rate": 1.5223400835744135e-05,
      "loss": 0.7036,
      "step": 22290
    },
    {
      "epoch": 2.3893710489660345,
      "grad_norm": 0.032503679394721985,
      "learning_rate": 1.5221257902067932e-05,
      "loss": 0.3895,
      "step": 22300
    },
    {
      "epoch": 2.390442515804136,
      "grad_norm": 56.442138671875,
      "learning_rate": 1.5219114968391731e-05,
      "loss": 0.2572,
      "step": 22310
    },
    {
      "epoch": 2.391513982642237,
      "grad_norm": 33.08002471923828,
      "learning_rate": 1.5216972034715527e-05,
      "loss": 0.2102,
      "step": 22320
    },
    {
      "epoch": 2.3925854494803387,
      "grad_norm": 0.016726121306419373,
      "learning_rate": 1.5214829101039323e-05,
      "loss": 0.1382,
      "step": 22330
    },
    {
      "epoch": 2.39365691631844,
      "grad_norm": 116.30316162109375,
      "learning_rate": 1.5212686167363122e-05,
      "loss": 0.1594,
      "step": 22340
    },
    {
      "epoch": 2.3947283831565414,
      "grad_norm": 0.1051967665553093,
      "learning_rate": 1.5210543233686919e-05,
      "loss": 0.3721,
      "step": 22350
    },
    {
      "epoch": 2.395799849994643,
      "grad_norm": 14.036356925964355,
      "learning_rate": 1.5208400300010715e-05,
      "loss": 0.5164,
      "step": 22360
    },
    {
      "epoch": 2.396871316832744,
      "grad_norm": 164.22079467773438,
      "learning_rate": 1.5206257366334514e-05,
      "loss": 0.574,
      "step": 22370
    },
    {
      "epoch": 2.3979427836708456,
      "grad_norm": 0.09447214752435684,
      "learning_rate": 1.520411443265831e-05,
      "loss": 0.1054,
      "step": 22380
    },
    {
      "epoch": 2.3990142505089467,
      "grad_norm": 0.21597382426261902,
      "learning_rate": 1.5201971498982108e-05,
      "loss": 0.3133,
      "step": 22390
    },
    {
      "epoch": 2.4000857173470482,
      "grad_norm": 0.008359858766198158,
      "learning_rate": 1.5199828565305906e-05,
      "loss": 0.3807,
      "step": 22400
    },
    {
      "epoch": 2.4011571841851493,
      "grad_norm": 0.26353150606155396,
      "learning_rate": 1.5197685631629702e-05,
      "loss": 0.0051,
      "step": 22410
    },
    {
      "epoch": 2.402228651023251,
      "grad_norm": 27.467130661010742,
      "learning_rate": 1.51955426979535e-05,
      "loss": 0.3199,
      "step": 22420
    },
    {
      "epoch": 2.403300117861352,
      "grad_norm": 0.158868670463562,
      "learning_rate": 1.5193399764277296e-05,
      "loss": 0.3932,
      "step": 22430
    },
    {
      "epoch": 2.4043715846994536,
      "grad_norm": 16.031673431396484,
      "learning_rate": 1.5191256830601094e-05,
      "loss": 0.4164,
      "step": 22440
    },
    {
      "epoch": 2.4054430515375547,
      "grad_norm": 0.9006251692771912,
      "learning_rate": 1.5189113896924893e-05,
      "loss": 0.8012,
      "step": 22450
    },
    {
      "epoch": 2.406514518375656,
      "grad_norm": 0.09334857016801834,
      "learning_rate": 1.5186970963248688e-05,
      "loss": 0.2181,
      "step": 22460
    },
    {
      "epoch": 2.4075859852137578,
      "grad_norm": 19.145893096923828,
      "learning_rate": 1.5184828029572487e-05,
      "loss": 0.189,
      "step": 22470
    },
    {
      "epoch": 2.408657452051859,
      "grad_norm": 0.006279201712459326,
      "learning_rate": 1.5182685095896283e-05,
      "loss": 0.1625,
      "step": 22480
    },
    {
      "epoch": 2.4097289188899604,
      "grad_norm": 0.03094273991882801,
      "learning_rate": 1.518054216222008e-05,
      "loss": 0.2652,
      "step": 22490
    },
    {
      "epoch": 2.4108003857280615,
      "grad_norm": 36.06532669067383,
      "learning_rate": 1.517839922854388e-05,
      "loss": 0.465,
      "step": 22500
    },
    {
      "epoch": 2.411871852566163,
      "grad_norm": 0.09674263745546341,
      "learning_rate": 1.5176256294867675e-05,
      "loss": 0.3875,
      "step": 22510
    },
    {
      "epoch": 2.412943319404264,
      "grad_norm": 0.1636972278356552,
      "learning_rate": 1.517411336119147e-05,
      "loss": 0.3726,
      "step": 22520
    },
    {
      "epoch": 2.4140147862423658,
      "grad_norm": 0.2940739095211029,
      "learning_rate": 1.517197042751527e-05,
      "loss": 0.8995,
      "step": 22530
    },
    {
      "epoch": 2.4150862530804673,
      "grad_norm": 0.17636661231517792,
      "learning_rate": 1.5169827493839067e-05,
      "loss": 0.286,
      "step": 22540
    },
    {
      "epoch": 2.4161577199185684,
      "grad_norm": 39.57727813720703,
      "learning_rate": 1.5167684560162864e-05,
      "loss": 0.4452,
      "step": 22550
    },
    {
      "epoch": 2.41722918675667,
      "grad_norm": 0.022020934149622917,
      "learning_rate": 1.5165541626486662e-05,
      "loss": 0.0033,
      "step": 22560
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 0.17973212897777557,
      "learning_rate": 1.5163398692810458e-05,
      "loss": 0.5805,
      "step": 22570
    },
    {
      "epoch": 2.4193721204328726,
      "grad_norm": 0.0172012560069561,
      "learning_rate": 1.5161255759134257e-05,
      "loss": 0.392,
      "step": 22580
    },
    {
      "epoch": 2.4204435872709738,
      "grad_norm": 0.08034338057041168,
      "learning_rate": 1.5159112825458054e-05,
      "loss": 0.7695,
      "step": 22590
    },
    {
      "epoch": 2.4215150541090753,
      "grad_norm": 0.26234322786331177,
      "learning_rate": 1.515696989178185e-05,
      "loss": 0.0068,
      "step": 22600
    },
    {
      "epoch": 2.422586520947177,
      "grad_norm": 0.05692605301737785,
      "learning_rate": 1.5154826958105649e-05,
      "loss": 0.1192,
      "step": 22610
    },
    {
      "epoch": 2.423657987785278,
      "grad_norm": 0.04554418474435806,
      "learning_rate": 1.5152684024429444e-05,
      "loss": 0.5987,
      "step": 22620
    },
    {
      "epoch": 2.4247294546233795,
      "grad_norm": 0.2824991047382355,
      "learning_rate": 1.5150541090753243e-05,
      "loss": 0.3125,
      "step": 22630
    },
    {
      "epoch": 2.4258009214614806,
      "grad_norm": 0.3000575304031372,
      "learning_rate": 1.514839815707704e-05,
      "loss": 0.276,
      "step": 22640
    },
    {
      "epoch": 2.426872388299582,
      "grad_norm": 0.1142260953783989,
      "learning_rate": 1.5146255223400836e-05,
      "loss": 0.1979,
      "step": 22650
    },
    {
      "epoch": 2.4279438551376833,
      "grad_norm": 36.50164794921875,
      "learning_rate": 1.5144112289724635e-05,
      "loss": 0.2686,
      "step": 22660
    },
    {
      "epoch": 2.429015321975785,
      "grad_norm": 0.3240524232387543,
      "learning_rate": 1.5141969356048431e-05,
      "loss": 0.2286,
      "step": 22670
    },
    {
      "epoch": 2.4300867888138864,
      "grad_norm": 0.08771604299545288,
      "learning_rate": 1.5139826422372228e-05,
      "loss": 0.1917,
      "step": 22680
    },
    {
      "epoch": 2.4311582556519875,
      "grad_norm": 21.338186264038086,
      "learning_rate": 1.5137683488696027e-05,
      "loss": 0.7556,
      "step": 22690
    },
    {
      "epoch": 2.432229722490089,
      "grad_norm": 1.2876172065734863,
      "learning_rate": 1.5135540555019823e-05,
      "loss": 0.2785,
      "step": 22700
    },
    {
      "epoch": 2.43330118932819,
      "grad_norm": 0.15608268976211548,
      "learning_rate": 1.5133397621343619e-05,
      "loss": 0.3533,
      "step": 22710
    },
    {
      "epoch": 2.4343726561662917,
      "grad_norm": 103.19664764404297,
      "learning_rate": 1.5131254687667418e-05,
      "loss": 0.1644,
      "step": 22720
    },
    {
      "epoch": 2.435444123004393,
      "grad_norm": 0.04707818105816841,
      "learning_rate": 1.5129111753991215e-05,
      "loss": 0.4501,
      "step": 22730
    },
    {
      "epoch": 2.4365155898424944,
      "grad_norm": 0.020947609096765518,
      "learning_rate": 1.5126968820315013e-05,
      "loss": 0.0021,
      "step": 22740
    },
    {
      "epoch": 2.437587056680596,
      "grad_norm": 0.05896536260843277,
      "learning_rate": 1.512482588663881e-05,
      "loss": 0.1358,
      "step": 22750
    },
    {
      "epoch": 2.438658523518697,
      "grad_norm": 0.0376589410007,
      "learning_rate": 1.5122682952962606e-05,
      "loss": 0.1774,
      "step": 22760
    },
    {
      "epoch": 2.4397299903567986,
      "grad_norm": 0.01089438982307911,
      "learning_rate": 1.5120540019286405e-05,
      "loss": 0.1566,
      "step": 22770
    },
    {
      "epoch": 2.4408014571948997,
      "grad_norm": 0.02310945652425289,
      "learning_rate": 1.5118397085610202e-05,
      "loss": 0.1997,
      "step": 22780
    },
    {
      "epoch": 2.4418729240330013,
      "grad_norm": 0.03075689636170864,
      "learning_rate": 1.5116254151933998e-05,
      "loss": 0.2537,
      "step": 22790
    },
    {
      "epoch": 2.4429443908711024,
      "grad_norm": 163.94664001464844,
      "learning_rate": 1.5114111218257797e-05,
      "loss": 0.4907,
      "step": 22800
    },
    {
      "epoch": 2.444015857709204,
      "grad_norm": 0.03198453411459923,
      "learning_rate": 1.5111968284581592e-05,
      "loss": 0.4301,
      "step": 22810
    },
    {
      "epoch": 2.4450873245473055,
      "grad_norm": 0.11076974868774414,
      "learning_rate": 1.5109825350905391e-05,
      "loss": 0.3837,
      "step": 22820
    },
    {
      "epoch": 2.4461587913854066,
      "grad_norm": 0.077415831387043,
      "learning_rate": 1.5107682417229189e-05,
      "loss": 0.4817,
      "step": 22830
    },
    {
      "epoch": 2.447230258223508,
      "grad_norm": 0.158175528049469,
      "learning_rate": 1.5105539483552984e-05,
      "loss": 1.0956,
      "step": 22840
    },
    {
      "epoch": 2.4483017250616093,
      "grad_norm": 0.16898410022258759,
      "learning_rate": 1.5103396549876783e-05,
      "loss": 0.3172,
      "step": 22850
    },
    {
      "epoch": 2.449373191899711,
      "grad_norm": 0.1695019006729126,
      "learning_rate": 1.5101253616200579e-05,
      "loss": 0.1803,
      "step": 22860
    },
    {
      "epoch": 2.450444658737812,
      "grad_norm": 0.16851428151130676,
      "learning_rate": 1.5099110682524376e-05,
      "loss": 0.3794,
      "step": 22870
    },
    {
      "epoch": 2.4515161255759135,
      "grad_norm": 0.11379941552877426,
      "learning_rate": 1.5096967748848176e-05,
      "loss": 0.3777,
      "step": 22880
    },
    {
      "epoch": 2.452587592414015,
      "grad_norm": 0.023026177659630775,
      "learning_rate": 1.5094824815171971e-05,
      "loss": 0.0138,
      "step": 22890
    },
    {
      "epoch": 2.453659059252116,
      "grad_norm": 0.0818953663110733,
      "learning_rate": 1.509268188149577e-05,
      "loss": 0.6635,
      "step": 22900
    },
    {
      "epoch": 2.4547305260902177,
      "grad_norm": 0.08476021140813828,
      "learning_rate": 1.5090538947819566e-05,
      "loss": 0.2153,
      "step": 22910
    },
    {
      "epoch": 2.455801992928319,
      "grad_norm": 0.29890450835227966,
      "learning_rate": 1.5088396014143363e-05,
      "loss": 0.8391,
      "step": 22920
    },
    {
      "epoch": 2.4568734597664204,
      "grad_norm": 0.4285992383956909,
      "learning_rate": 1.508625308046716e-05,
      "loss": 0.1663,
      "step": 22930
    },
    {
      "epoch": 2.4579449266045215,
      "grad_norm": 0.18661870062351227,
      "learning_rate": 1.5084110146790958e-05,
      "loss": 0.5822,
      "step": 22940
    },
    {
      "epoch": 2.459016393442623,
      "grad_norm": 0.06699567288160324,
      "learning_rate": 1.5081967213114754e-05,
      "loss": 0.3157,
      "step": 22950
    },
    {
      "epoch": 2.460087860280724,
      "grad_norm": 0.24473880231380463,
      "learning_rate": 1.5079824279438553e-05,
      "loss": 0.4605,
      "step": 22960
    },
    {
      "epoch": 2.4611593271188257,
      "grad_norm": 0.17801249027252197,
      "learning_rate": 1.507768134576235e-05,
      "loss": 0.181,
      "step": 22970
    },
    {
      "epoch": 2.462230793956927,
      "grad_norm": 0.023927289992570877,
      "learning_rate": 1.5075538412086147e-05,
      "loss": 0.9535,
      "step": 22980
    },
    {
      "epoch": 2.4633022607950283,
      "grad_norm": 0.5296851396560669,
      "learning_rate": 1.5073395478409945e-05,
      "loss": 0.0038,
      "step": 22990
    },
    {
      "epoch": 2.46437372763313,
      "grad_norm": 50.97117233276367,
      "learning_rate": 1.507125254473374e-05,
      "loss": 0.7258,
      "step": 23000
    },
    {
      "epoch": 2.465445194471231,
      "grad_norm": 21.995452880859375,
      "learning_rate": 1.506910961105754e-05,
      "loss": 0.5472,
      "step": 23010
    },
    {
      "epoch": 2.4665166613093326,
      "grad_norm": 0.08075270056724548,
      "learning_rate": 1.5066966677381337e-05,
      "loss": 0.0056,
      "step": 23020
    },
    {
      "epoch": 2.4675881281474337,
      "grad_norm": 91.79756164550781,
      "learning_rate": 1.5064823743705132e-05,
      "loss": 0.2993,
      "step": 23030
    },
    {
      "epoch": 2.468659594985535,
      "grad_norm": 95.81889343261719,
      "learning_rate": 1.5062680810028932e-05,
      "loss": 0.2084,
      "step": 23040
    },
    {
      "epoch": 2.4697310618236363,
      "grad_norm": 0.27545425295829773,
      "learning_rate": 1.5060537876352727e-05,
      "loss": 0.6894,
      "step": 23050
    },
    {
      "epoch": 2.470802528661738,
      "grad_norm": 0.03114488162100315,
      "learning_rate": 1.5058394942676526e-05,
      "loss": 0.3883,
      "step": 23060
    },
    {
      "epoch": 2.4718739954998394,
      "grad_norm": 0.02592400833964348,
      "learning_rate": 1.5056252009000324e-05,
      "loss": 0.1536,
      "step": 23070
    },
    {
      "epoch": 2.4729454623379405,
      "grad_norm": 155.82615661621094,
      "learning_rate": 1.505410907532412e-05,
      "loss": 0.266,
      "step": 23080
    },
    {
      "epoch": 2.474016929176042,
      "grad_norm": 3.8829665184020996,
      "learning_rate": 1.5051966141647918e-05,
      "loss": 0.424,
      "step": 23090
    },
    {
      "epoch": 2.475088396014143,
      "grad_norm": 293.9212646484375,
      "learning_rate": 1.5049823207971714e-05,
      "loss": 0.3744,
      "step": 23100
    },
    {
      "epoch": 2.4761598628522448,
      "grad_norm": 0.06638170033693314,
      "learning_rate": 1.5047680274295511e-05,
      "loss": 0.1952,
      "step": 23110
    },
    {
      "epoch": 2.477231329690346,
      "grad_norm": 0.16411544382572174,
      "learning_rate": 1.5045537340619309e-05,
      "loss": 0.409,
      "step": 23120
    },
    {
      "epoch": 2.4783027965284474,
      "grad_norm": 2.0605058670043945,
      "learning_rate": 1.5043394406943106e-05,
      "loss": 0.0257,
      "step": 23130
    },
    {
      "epoch": 2.479374263366549,
      "grad_norm": 0.02509770169854164,
      "learning_rate": 1.5041251473266905e-05,
      "loss": 0.1453,
      "step": 23140
    },
    {
      "epoch": 2.48044573020465,
      "grad_norm": 0.05553970858454704,
      "learning_rate": 1.50391085395907e-05,
      "loss": 0.3001,
      "step": 23150
    },
    {
      "epoch": 2.4815171970427516,
      "grad_norm": 0.1506640464067459,
      "learning_rate": 1.5036965605914498e-05,
      "loss": 0.6842,
      "step": 23160
    },
    {
      "epoch": 2.4825886638808528,
      "grad_norm": 0.27768588066101074,
      "learning_rate": 1.5034822672238295e-05,
      "loss": 0.2153,
      "step": 23170
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 20.253507614135742,
      "learning_rate": 1.5032679738562093e-05,
      "loss": 0.4606,
      "step": 23180
    },
    {
      "epoch": 2.4847315975570554,
      "grad_norm": 0.024868259206414223,
      "learning_rate": 1.5030536804885888e-05,
      "loss": 0.1572,
      "step": 23190
    },
    {
      "epoch": 2.485803064395157,
      "grad_norm": 0.08766324073076248,
      "learning_rate": 1.5028393871209688e-05,
      "loss": 0.6241,
      "step": 23200
    },
    {
      "epoch": 2.4868745312332585,
      "grad_norm": 0.14685221016407013,
      "learning_rate": 1.5026250937533485e-05,
      "loss": 0.3772,
      "step": 23210
    },
    {
      "epoch": 2.4879459980713596,
      "grad_norm": 6.720083713531494,
      "learning_rate": 1.5024108003857282e-05,
      "loss": 0.2313,
      "step": 23220
    },
    {
      "epoch": 2.489017464909461,
      "grad_norm": 0.27485495805740356,
      "learning_rate": 1.502196507018108e-05,
      "loss": 0.18,
      "step": 23230
    },
    {
      "epoch": 2.4900889317475623,
      "grad_norm": 0.025920189917087555,
      "learning_rate": 1.5019822136504875e-05,
      "loss": 0.3307,
      "step": 23240
    },
    {
      "epoch": 2.491160398585664,
      "grad_norm": 0.07426489144563675,
      "learning_rate": 1.5017679202828674e-05,
      "loss": 0.5,
      "step": 23250
    },
    {
      "epoch": 2.492231865423765,
      "grad_norm": 0.029912294819951057,
      "learning_rate": 1.5015536269152472e-05,
      "loss": 0.2109,
      "step": 23260
    },
    {
      "epoch": 2.4933033322618665,
      "grad_norm": 250.8899383544922,
      "learning_rate": 1.5013393335476267e-05,
      "loss": 0.2349,
      "step": 23270
    },
    {
      "epoch": 2.494374799099968,
      "grad_norm": 77.12452697753906,
      "learning_rate": 1.5011250401800066e-05,
      "loss": 0.7405,
      "step": 23280
    },
    {
      "epoch": 2.495446265938069,
      "grad_norm": 20.509183883666992,
      "learning_rate": 1.5009107468123862e-05,
      "loss": 0.4208,
      "step": 23290
    },
    {
      "epoch": 2.4965177327761707,
      "grad_norm": 0.22391670942306519,
      "learning_rate": 1.5006964534447661e-05,
      "loss": 0.0216,
      "step": 23300
    },
    {
      "epoch": 2.497589199614272,
      "grad_norm": 0.11519964039325714,
      "learning_rate": 1.5004821600771457e-05,
      "loss": 0.1431,
      "step": 23310
    },
    {
      "epoch": 2.4986606664523734,
      "grad_norm": 0.12396179884672165,
      "learning_rate": 1.5002678667095254e-05,
      "loss": 0.1644,
      "step": 23320
    },
    {
      "epoch": 2.4997321332904745,
      "grad_norm": 61.33872604370117,
      "learning_rate": 1.5000535733419053e-05,
      "loss": 0.2316,
      "step": 23330
    },
    {
      "epoch": 2.500803600128576,
      "grad_norm": 0.2698531448841095,
      "learning_rate": 1.4998392799742849e-05,
      "loss": 0.3418,
      "step": 23340
    },
    {
      "epoch": 2.5018750669666776,
      "grad_norm": 0.005771494470536709,
      "learning_rate": 1.4996249866066646e-05,
      "loss": 0.1503,
      "step": 23350
    },
    {
      "epoch": 2.5029465338047787,
      "grad_norm": 0.4602243900299072,
      "learning_rate": 1.4994106932390444e-05,
      "loss": 0.0023,
      "step": 23360
    },
    {
      "epoch": 2.50401800064288,
      "grad_norm": 0.13465963304042816,
      "learning_rate": 1.4991963998714241e-05,
      "loss": 0.5336,
      "step": 23370
    },
    {
      "epoch": 2.5050894674809814,
      "grad_norm": 0.010531074367463589,
      "learning_rate": 1.498982106503804e-05,
      "loss": 0.2721,
      "step": 23380
    },
    {
      "epoch": 2.506160934319083,
      "grad_norm": 0.016980504617094994,
      "learning_rate": 1.4987678131361836e-05,
      "loss": 0.3861,
      "step": 23390
    },
    {
      "epoch": 2.507232401157184,
      "grad_norm": 40.93021011352539,
      "learning_rate": 1.4985535197685633e-05,
      "loss": 0.397,
      "step": 23400
    },
    {
      "epoch": 2.5083038679952856,
      "grad_norm": 0.08171825855970383,
      "learning_rate": 1.498339226400943e-05,
      "loss": 0.0149,
      "step": 23410
    },
    {
      "epoch": 2.509375334833387,
      "grad_norm": 0.05963761731982231,
      "learning_rate": 1.4981249330333228e-05,
      "loss": 0.0027,
      "step": 23420
    },
    {
      "epoch": 2.5104468016714883,
      "grad_norm": 0.04988733306527138,
      "learning_rate": 1.4979106396657023e-05,
      "loss": 0.0194,
      "step": 23430
    },
    {
      "epoch": 2.5115182685095894,
      "grad_norm": 0.00946173258125782,
      "learning_rate": 1.4976963462980822e-05,
      "loss": 0.7253,
      "step": 23440
    },
    {
      "epoch": 2.512589735347691,
      "grad_norm": 31.37281608581543,
      "learning_rate": 1.497482052930462e-05,
      "loss": 0.9942,
      "step": 23450
    },
    {
      "epoch": 2.5136612021857925,
      "grad_norm": 0.0918683409690857,
      "learning_rate": 1.4972677595628417e-05,
      "loss": 0.1225,
      "step": 23460
    },
    {
      "epoch": 2.5147326690238936,
      "grad_norm": 0.1231691911816597,
      "learning_rate": 1.4970534661952214e-05,
      "loss": 0.2366,
      "step": 23470
    },
    {
      "epoch": 2.515804135861995,
      "grad_norm": 18.110097885131836,
      "learning_rate": 1.496839172827601e-05,
      "loss": 0.7759,
      "step": 23480
    },
    {
      "epoch": 2.5168756027000967,
      "grad_norm": 0.07747487723827362,
      "learning_rate": 1.496624879459981e-05,
      "loss": 0.3186,
      "step": 23490
    },
    {
      "epoch": 2.517947069538198,
      "grad_norm": 217.64784240722656,
      "learning_rate": 1.4964105860923605e-05,
      "loss": 0.4354,
      "step": 23500
    },
    {
      "epoch": 2.519018536376299,
      "grad_norm": 0.030962085351347923,
      "learning_rate": 1.4961962927247402e-05,
      "loss": 0.6423,
      "step": 23510
    },
    {
      "epoch": 2.5200900032144005,
      "grad_norm": 0.020830946043133736,
      "learning_rate": 1.4959819993571201e-05,
      "loss": 0.0041,
      "step": 23520
    },
    {
      "epoch": 2.521161470052502,
      "grad_norm": 0.012509025633335114,
      "learning_rate": 1.4957677059894997e-05,
      "loss": 0.0554,
      "step": 23530
    },
    {
      "epoch": 2.522232936890603,
      "grad_norm": 0.07592951506376266,
      "learning_rate": 1.4955534126218796e-05,
      "loss": 0.2308,
      "step": 23540
    },
    {
      "epoch": 2.5233044037287047,
      "grad_norm": 0.16085195541381836,
      "learning_rate": 1.4953391192542592e-05,
      "loss": 0.0615,
      "step": 23550
    },
    {
      "epoch": 2.5243758705668062,
      "grad_norm": 0.020341159775853157,
      "learning_rate": 1.4951248258866389e-05,
      "loss": 0.2116,
      "step": 23560
    },
    {
      "epoch": 2.5254473374049073,
      "grad_norm": 1.4153982400894165,
      "learning_rate": 1.4949105325190188e-05,
      "loss": 0.4154,
      "step": 23570
    },
    {
      "epoch": 2.5265188042430085,
      "grad_norm": 0.009090774692595005,
      "learning_rate": 1.4946962391513984e-05,
      "loss": 0.1312,
      "step": 23580
    },
    {
      "epoch": 2.52759027108111,
      "grad_norm": 0.015536852180957794,
      "learning_rate": 1.4944819457837781e-05,
      "loss": 0.7352,
      "step": 23590
    },
    {
      "epoch": 2.5286617379192116,
      "grad_norm": 0.2891629636287689,
      "learning_rate": 1.4942676524161578e-05,
      "loss": 0.3715,
      "step": 23600
    },
    {
      "epoch": 2.5297332047573127,
      "grad_norm": 0.01592577062547207,
      "learning_rate": 1.4940533590485376e-05,
      "loss": 0.379,
      "step": 23610
    },
    {
      "epoch": 2.5308046715954142,
      "grad_norm": 0.6793321967124939,
      "learning_rate": 1.4938390656809171e-05,
      "loss": 0.6618,
      "step": 23620
    },
    {
      "epoch": 2.5318761384335153,
      "grad_norm": 0.04127703234553337,
      "learning_rate": 1.493624772313297e-05,
      "loss": 0.3118,
      "step": 23630
    },
    {
      "epoch": 2.532947605271617,
      "grad_norm": 0.32844993472099304,
      "learning_rate": 1.4934104789456768e-05,
      "loss": 0.161,
      "step": 23640
    },
    {
      "epoch": 2.534019072109718,
      "grad_norm": 18.1412296295166,
      "learning_rate": 1.4931961855780565e-05,
      "loss": 0.646,
      "step": 23650
    },
    {
      "epoch": 2.5350905389478195,
      "grad_norm": 0.040584057569503784,
      "learning_rate": 1.4929818922104363e-05,
      "loss": 0.0084,
      "step": 23660
    },
    {
      "epoch": 2.536162005785921,
      "grad_norm": 38.18436813354492,
      "learning_rate": 1.4927675988428158e-05,
      "loss": 0.32,
      "step": 23670
    },
    {
      "epoch": 2.537233472624022,
      "grad_norm": 0.4070761799812317,
      "learning_rate": 1.4925533054751957e-05,
      "loss": 0.1951,
      "step": 23680
    },
    {
      "epoch": 2.5383049394621238,
      "grad_norm": 0.12959057092666626,
      "learning_rate": 1.4923390121075753e-05,
      "loss": 0.0035,
      "step": 23690
    },
    {
      "epoch": 2.539376406300225,
      "grad_norm": 0.06464716792106628,
      "learning_rate": 1.492124718739955e-05,
      "loss": 0.3437,
      "step": 23700
    },
    {
      "epoch": 2.5404478731383264,
      "grad_norm": 0.0961407870054245,
      "learning_rate": 1.491910425372335e-05,
      "loss": 0.5592,
      "step": 23710
    },
    {
      "epoch": 2.5415193399764275,
      "grad_norm": 0.07068637758493423,
      "learning_rate": 1.4916961320047145e-05,
      "loss": 0.3593,
      "step": 23720
    },
    {
      "epoch": 2.542590806814529,
      "grad_norm": 0.12454226613044739,
      "learning_rate": 1.4914818386370944e-05,
      "loss": 0.0213,
      "step": 23730
    },
    {
      "epoch": 2.5436622736526306,
      "grad_norm": 0.05064011737704277,
      "learning_rate": 1.491267545269474e-05,
      "loss": 0.1972,
      "step": 23740
    },
    {
      "epoch": 2.5447337404907318,
      "grad_norm": 0.13487587869167328,
      "learning_rate": 1.4910532519018537e-05,
      "loss": 0.5258,
      "step": 23750
    },
    {
      "epoch": 2.5458052073288333,
      "grad_norm": 0.056588780134916306,
      "learning_rate": 1.4908389585342336e-05,
      "loss": 0.5155,
      "step": 23760
    },
    {
      "epoch": 2.5468766741669344,
      "grad_norm": 0.03650756552815437,
      "learning_rate": 1.4906246651666132e-05,
      "loss": 0.3061,
      "step": 23770
    },
    {
      "epoch": 2.547948141005036,
      "grad_norm": 20.62785530090332,
      "learning_rate": 1.4904103717989929e-05,
      "loss": 0.3085,
      "step": 23780
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.7416561245918274,
      "learning_rate": 1.4901960784313726e-05,
      "loss": 0.3465,
      "step": 23790
    },
    {
      "epoch": 2.5500910746812386,
      "grad_norm": 0.018638022243976593,
      "learning_rate": 1.4899817850637524e-05,
      "loss": 0.6113,
      "step": 23800
    },
    {
      "epoch": 2.55116254151934,
      "grad_norm": 0.030438201501965523,
      "learning_rate": 1.4897674916961323e-05,
      "loss": 0.2484,
      "step": 23810
    },
    {
      "epoch": 2.5522340083574413,
      "grad_norm": 85.36489868164062,
      "learning_rate": 1.4895531983285119e-05,
      "loss": 0.583,
      "step": 23820
    },
    {
      "epoch": 2.553305475195543,
      "grad_norm": 0.14593172073364258,
      "learning_rate": 1.4893389049608916e-05,
      "loss": 0.0052,
      "step": 23830
    },
    {
      "epoch": 2.554376942033644,
      "grad_norm": 4.208614826202393,
      "learning_rate": 1.4891246115932713e-05,
      "loss": 0.1608,
      "step": 23840
    },
    {
      "epoch": 2.5554484088717455,
      "grad_norm": 0.12850533425807953,
      "learning_rate": 1.488910318225651e-05,
      "loss": 0.1582,
      "step": 23850
    },
    {
      "epoch": 2.5565198757098466,
      "grad_norm": 0.9987486600875854,
      "learning_rate": 1.4886960248580306e-05,
      "loss": 0.4529,
      "step": 23860
    },
    {
      "epoch": 2.557591342547948,
      "grad_norm": 0.42179322242736816,
      "learning_rate": 1.4884817314904105e-05,
      "loss": 0.3201,
      "step": 23870
    },
    {
      "epoch": 2.5586628093860497,
      "grad_norm": 19.86858367919922,
      "learning_rate": 1.4882674381227901e-05,
      "loss": 0.3909,
      "step": 23880
    },
    {
      "epoch": 2.559734276224151,
      "grad_norm": 0.1015293151140213,
      "learning_rate": 1.48805314475517e-05,
      "loss": 0.3287,
      "step": 23890
    },
    {
      "epoch": 2.560805743062252,
      "grad_norm": 0.4299471974372864,
      "learning_rate": 1.4878388513875497e-05,
      "loss": 0.5023,
      "step": 23900
    },
    {
      "epoch": 2.5618772099003535,
      "grad_norm": 14.271265983581543,
      "learning_rate": 1.4876245580199293e-05,
      "loss": 0.1744,
      "step": 23910
    },
    {
      "epoch": 2.562948676738455,
      "grad_norm": 0.2659546434879303,
      "learning_rate": 1.4874102646523092e-05,
      "loss": 0.3025,
      "step": 23920
    },
    {
      "epoch": 2.564020143576556,
      "grad_norm": 0.737678050994873,
      "learning_rate": 1.4871959712846888e-05,
      "loss": 0.1612,
      "step": 23930
    },
    {
      "epoch": 2.5650916104146577,
      "grad_norm": 0.3679341971874237,
      "learning_rate": 1.4869816779170685e-05,
      "loss": 0.4816,
      "step": 23940
    },
    {
      "epoch": 2.5661630772527593,
      "grad_norm": 0.037609297782182693,
      "learning_rate": 1.4867673845494484e-05,
      "loss": 0.721,
      "step": 23950
    },
    {
      "epoch": 2.5672345440908604,
      "grad_norm": 0.1492164134979248,
      "learning_rate": 1.486553091181828e-05,
      "loss": 0.4489,
      "step": 23960
    },
    {
      "epoch": 2.5683060109289615,
      "grad_norm": 0.6765964031219482,
      "learning_rate": 1.4863387978142079e-05,
      "loss": 0.3768,
      "step": 23970
    },
    {
      "epoch": 2.569377477767063,
      "grad_norm": 0.15177197754383087,
      "learning_rate": 1.4861245044465875e-05,
      "loss": 0.2187,
      "step": 23980
    },
    {
      "epoch": 2.5704489446051646,
      "grad_norm": 0.052846759557724,
      "learning_rate": 1.4859102110789672e-05,
      "loss": 0.0254,
      "step": 23990
    },
    {
      "epoch": 2.5715204114432657,
      "grad_norm": 0.35066598653793335,
      "learning_rate": 1.4856959177113471e-05,
      "loss": 0.0022,
      "step": 24000
    },
    {
      "epoch": 2.5725918782813673,
      "grad_norm": 0.026489995419979095,
      "learning_rate": 1.4854816243437267e-05,
      "loss": 0.0013,
      "step": 24010
    },
    {
      "epoch": 2.573663345119469,
      "grad_norm": 21.94423484802246,
      "learning_rate": 1.4852673309761064e-05,
      "loss": 0.4915,
      "step": 24020
    },
    {
      "epoch": 2.57473481195757,
      "grad_norm": 25.530874252319336,
      "learning_rate": 1.4850530376084861e-05,
      "loss": 0.8382,
      "step": 24030
    },
    {
      "epoch": 2.575806278795671,
      "grad_norm": 0.05103154107928276,
      "learning_rate": 1.4848387442408659e-05,
      "loss": 0.1978,
      "step": 24040
    },
    {
      "epoch": 2.5768777456337726,
      "grad_norm": 0.029307566583156586,
      "learning_rate": 1.4846244508732458e-05,
      "loss": 0.1314,
      "step": 24050
    },
    {
      "epoch": 2.577949212471874,
      "grad_norm": 21.023847579956055,
      "learning_rate": 1.4844101575056253e-05,
      "loss": 0.202,
      "step": 24060
    },
    {
      "epoch": 2.5790206793099753,
      "grad_norm": 15.62808895111084,
      "learning_rate": 1.4841958641380049e-05,
      "loss": 0.4907,
      "step": 24070
    },
    {
      "epoch": 2.580092146148077,
      "grad_norm": 0.1263454109430313,
      "learning_rate": 1.4839815707703848e-05,
      "loss": 0.0387,
      "step": 24080
    },
    {
      "epoch": 2.581163612986178,
      "grad_norm": 0.2087404727935791,
      "learning_rate": 1.4837672774027645e-05,
      "loss": 0.8294,
      "step": 24090
    },
    {
      "epoch": 2.5822350798242795,
      "grad_norm": 0.17333170771598816,
      "learning_rate": 1.4835529840351441e-05,
      "loss": 0.1581,
      "step": 24100
    },
    {
      "epoch": 2.5833065466623806,
      "grad_norm": 0.20043228566646576,
      "learning_rate": 1.483338690667524e-05,
      "loss": 0.1546,
      "step": 24110
    },
    {
      "epoch": 2.584378013500482,
      "grad_norm": 41.69095993041992,
      "learning_rate": 1.4831243972999036e-05,
      "loss": 0.7662,
      "step": 24120
    },
    {
      "epoch": 2.5854494803385837,
      "grad_norm": 17.60670280456543,
      "learning_rate": 1.4829101039322835e-05,
      "loss": 0.3416,
      "step": 24130
    },
    {
      "epoch": 2.586520947176685,
      "grad_norm": 0.18796400725841522,
      "learning_rate": 1.4826958105646632e-05,
      "loss": 0.2751,
      "step": 24140
    },
    {
      "epoch": 2.5875924140147863,
      "grad_norm": 0.022586220875382423,
      "learning_rate": 1.4824815171970428e-05,
      "loss": 0.1248,
      "step": 24150
    },
    {
      "epoch": 2.5886638808528875,
      "grad_norm": 23.33049201965332,
      "learning_rate": 1.4822672238294227e-05,
      "loss": 0.1261,
      "step": 24160
    },
    {
      "epoch": 2.589735347690989,
      "grad_norm": 0.13245871663093567,
      "learning_rate": 1.4820529304618023e-05,
      "loss": 0.2557,
      "step": 24170
    },
    {
      "epoch": 2.59080681452909,
      "grad_norm": 0.24615478515625,
      "learning_rate": 1.481838637094182e-05,
      "loss": 0.4376,
      "step": 24180
    },
    {
      "epoch": 2.5918782813671917,
      "grad_norm": 0.12236502766609192,
      "learning_rate": 1.4816243437265619e-05,
      "loss": 0.3007,
      "step": 24190
    },
    {
      "epoch": 2.5929497482052932,
      "grad_norm": 0.15709979832172394,
      "learning_rate": 1.4814100503589415e-05,
      "loss": 0.6028,
      "step": 24200
    },
    {
      "epoch": 2.5940212150433943,
      "grad_norm": 25.466123580932617,
      "learning_rate": 1.4811957569913214e-05,
      "loss": 0.6385,
      "step": 24210
    },
    {
      "epoch": 2.595092681881496,
      "grad_norm": 13.670904159545898,
      "learning_rate": 1.480981463623701e-05,
      "loss": 0.6849,
      "step": 24220
    },
    {
      "epoch": 2.596164148719597,
      "grad_norm": 106.81522369384766,
      "learning_rate": 1.4807671702560807e-05,
      "loss": 0.7833,
      "step": 24230
    },
    {
      "epoch": 2.5972356155576986,
      "grad_norm": 27.25189781188965,
      "learning_rate": 1.4805528768884606e-05,
      "loss": 0.1867,
      "step": 24240
    },
    {
      "epoch": 2.5983070823957997,
      "grad_norm": 0.3392196297645569,
      "learning_rate": 1.4803385835208401e-05,
      "loss": 0.0121,
      "step": 24250
    },
    {
      "epoch": 2.599378549233901,
      "grad_norm": 0.33421239256858826,
      "learning_rate": 1.4801242901532197e-05,
      "loss": 0.7332,
      "step": 24260
    },
    {
      "epoch": 2.6004500160720028,
      "grad_norm": 15.160416603088379,
      "learning_rate": 1.4799099967855996e-05,
      "loss": 1.0096,
      "step": 24270
    },
    {
      "epoch": 2.601521482910104,
      "grad_norm": 0.7928254008293152,
      "learning_rate": 1.4796957034179793e-05,
      "loss": 0.5857,
      "step": 24280
    },
    {
      "epoch": 2.6025929497482054,
      "grad_norm": 0.722786009311676,
      "learning_rate": 1.479481410050359e-05,
      "loss": 0.0121,
      "step": 24290
    },
    {
      "epoch": 2.6036644165863065,
      "grad_norm": 1.548462986946106,
      "learning_rate": 1.4792671166827388e-05,
      "loss": 0.9228,
      "step": 24300
    },
    {
      "epoch": 2.604735883424408,
      "grad_norm": 32.806270599365234,
      "learning_rate": 1.4790528233151184e-05,
      "loss": 0.8363,
      "step": 24310
    },
    {
      "epoch": 2.605807350262509,
      "grad_norm": 0.44390735030174255,
      "learning_rate": 1.4788385299474983e-05,
      "loss": 0.3779,
      "step": 24320
    },
    {
      "epoch": 2.6068788171006108,
      "grad_norm": 0.4196550250053406,
      "learning_rate": 1.478624236579878e-05,
      "loss": 0.1847,
      "step": 24330
    },
    {
      "epoch": 2.6079502839387123,
      "grad_norm": 15.603128433227539,
      "learning_rate": 1.4784099432122576e-05,
      "loss": 0.1553,
      "step": 24340
    },
    {
      "epoch": 2.6090217507768134,
      "grad_norm": 0.03723539412021637,
      "learning_rate": 1.4781956498446375e-05,
      "loss": 0.2339,
      "step": 24350
    },
    {
      "epoch": 2.610093217614915,
      "grad_norm": 0.052843376994132996,
      "learning_rate": 1.477981356477017e-05,
      "loss": 0.4715,
      "step": 24360
    },
    {
      "epoch": 2.611164684453016,
      "grad_norm": 0.22987936437129974,
      "learning_rate": 1.477767063109397e-05,
      "loss": 0.4835,
      "step": 24370
    },
    {
      "epoch": 2.6122361512911176,
      "grad_norm": 0.016009854152798653,
      "learning_rate": 1.4775527697417767e-05,
      "loss": 0.1861,
      "step": 24380
    },
    {
      "epoch": 2.6133076181292187,
      "grad_norm": 38.15121078491211,
      "learning_rate": 1.4773384763741563e-05,
      "loss": 0.3217,
      "step": 24390
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 0.29631534218788147,
      "learning_rate": 1.4771241830065362e-05,
      "loss": 0.4341,
      "step": 24400
    },
    {
      "epoch": 2.615450551805422,
      "grad_norm": 0.03760933876037598,
      "learning_rate": 1.4769098896389157e-05,
      "loss": 0.2742,
      "step": 24410
    },
    {
      "epoch": 2.616522018643523,
      "grad_norm": 22.313404083251953,
      "learning_rate": 1.4766955962712955e-05,
      "loss": 0.3861,
      "step": 24420
    },
    {
      "epoch": 2.617593485481624,
      "grad_norm": 0.1284731924533844,
      "learning_rate": 1.4764813029036754e-05,
      "loss": 0.191,
      "step": 24430
    },
    {
      "epoch": 2.6186649523197256,
      "grad_norm": 0.022205350920557976,
      "learning_rate": 1.476267009536055e-05,
      "loss": 0.0052,
      "step": 24440
    },
    {
      "epoch": 2.619736419157827,
      "grad_norm": 0.27441683411598206,
      "learning_rate": 1.4760527161684349e-05,
      "loss": 0.3432,
      "step": 24450
    },
    {
      "epoch": 2.6208078859959283,
      "grad_norm": 0.024092059582471848,
      "learning_rate": 1.4758384228008144e-05,
      "loss": 0.0051,
      "step": 24460
    },
    {
      "epoch": 2.62187935283403,
      "grad_norm": 0.1939481943845749,
      "learning_rate": 1.4756241294331942e-05,
      "loss": 0.1646,
      "step": 24470
    },
    {
      "epoch": 2.6229508196721314,
      "grad_norm": 47.02630615234375,
      "learning_rate": 1.4754098360655739e-05,
      "loss": 0.4481,
      "step": 24480
    },
    {
      "epoch": 2.6240222865102325,
      "grad_norm": 0.06318768113851547,
      "learning_rate": 1.4751955426979536e-05,
      "loss": 0.5093,
      "step": 24490
    },
    {
      "epoch": 2.6250937533483336,
      "grad_norm": 40.38471603393555,
      "learning_rate": 1.4749812493303332e-05,
      "loss": 0.6552,
      "step": 24500
    },
    {
      "epoch": 2.626165220186435,
      "grad_norm": 14.142390251159668,
      "learning_rate": 1.4747669559627131e-05,
      "loss": 0.5807,
      "step": 24510
    },
    {
      "epoch": 2.6272366870245367,
      "grad_norm": 0.025119977071881294,
      "learning_rate": 1.4745526625950928e-05,
      "loss": 0.1934,
      "step": 24520
    },
    {
      "epoch": 2.628308153862638,
      "grad_norm": 0.25818905234336853,
      "learning_rate": 1.4743383692274724e-05,
      "loss": 0.6299,
      "step": 24530
    },
    {
      "epoch": 2.6293796207007394,
      "grad_norm": 0.042472898960113525,
      "learning_rate": 1.4741240758598523e-05,
      "loss": 0.0031,
      "step": 24540
    },
    {
      "epoch": 2.630451087538841,
      "grad_norm": 0.17337766289710999,
      "learning_rate": 1.4739097824922319e-05,
      "loss": 0.7446,
      "step": 24550
    },
    {
      "epoch": 2.631522554376942,
      "grad_norm": 0.02676551230251789,
      "learning_rate": 1.4736954891246118e-05,
      "loss": 0.2892,
      "step": 24560
    },
    {
      "epoch": 2.632594021215043,
      "grad_norm": 0.10200629383325577,
      "learning_rate": 1.4734811957569915e-05,
      "loss": 0.1811,
      "step": 24570
    },
    {
      "epoch": 2.6336654880531447,
      "grad_norm": 23.853002548217773,
      "learning_rate": 1.473266902389371e-05,
      "loss": 0.1973,
      "step": 24580
    },
    {
      "epoch": 2.6347369548912463,
      "grad_norm": 0.1841871291399002,
      "learning_rate": 1.473052609021751e-05,
      "loss": 0.32,
      "step": 24590
    },
    {
      "epoch": 2.6358084217293474,
      "grad_norm": 18.985666275024414,
      "learning_rate": 1.4728383156541305e-05,
      "loss": 0.8734,
      "step": 24600
    },
    {
      "epoch": 2.636879888567449,
      "grad_norm": 0.242099791765213,
      "learning_rate": 1.4726240222865103e-05,
      "loss": 1.0392,
      "step": 24610
    },
    {
      "epoch": 2.63795135540555,
      "grad_norm": 0.29029014706611633,
      "learning_rate": 1.4724097289188902e-05,
      "loss": 0.3529,
      "step": 24620
    },
    {
      "epoch": 2.6390228222436516,
      "grad_norm": 0.5217821002006531,
      "learning_rate": 1.4721954355512698e-05,
      "loss": 0.1051,
      "step": 24630
    },
    {
      "epoch": 2.6400942890817527,
      "grad_norm": 27.513532638549805,
      "learning_rate": 1.4719811421836497e-05,
      "loss": 0.5989,
      "step": 24640
    },
    {
      "epoch": 2.6411657559198543,
      "grad_norm": 0.034384556114673615,
      "learning_rate": 1.4717668488160292e-05,
      "loss": 0.3008,
      "step": 24650
    },
    {
      "epoch": 2.642237222757956,
      "grad_norm": 1.0490729808807373,
      "learning_rate": 1.471552555448409e-05,
      "loss": 0.0123,
      "step": 24660
    },
    {
      "epoch": 2.643308689596057,
      "grad_norm": 27.511335372924805,
      "learning_rate": 1.4713382620807887e-05,
      "loss": 0.2439,
      "step": 24670
    },
    {
      "epoch": 2.6443801564341585,
      "grad_norm": 2.762315511703491,
      "learning_rate": 1.4711239687131684e-05,
      "loss": 0.2139,
      "step": 24680
    },
    {
      "epoch": 2.6454516232722596,
      "grad_norm": 0.14635097980499268,
      "learning_rate": 1.470909675345548e-05,
      "loss": 0.4185,
      "step": 24690
    },
    {
      "epoch": 2.646523090110361,
      "grad_norm": 0.061474647372961044,
      "learning_rate": 1.4706953819779279e-05,
      "loss": 0.0012,
      "step": 24700
    },
    {
      "epoch": 2.6475945569484622,
      "grad_norm": 0.16359387338161469,
      "learning_rate": 1.4704810886103076e-05,
      "loss": 0.2506,
      "step": 24710
    },
    {
      "epoch": 2.648666023786564,
      "grad_norm": 0.07007333636283875,
      "learning_rate": 1.4702667952426874e-05,
      "loss": 0.517,
      "step": 24720
    },
    {
      "epoch": 2.6497374906246653,
      "grad_norm": 0.0470285564661026,
      "learning_rate": 1.4700525018750671e-05,
      "loss": 0.0183,
      "step": 24730
    },
    {
      "epoch": 2.6508089574627665,
      "grad_norm": 0.10477793961763382,
      "learning_rate": 1.4698382085074467e-05,
      "loss": 0.0341,
      "step": 24740
    },
    {
      "epoch": 2.651880424300868,
      "grad_norm": 0.08405622839927673,
      "learning_rate": 1.4696239151398266e-05,
      "loss": 0.1516,
      "step": 24750
    },
    {
      "epoch": 2.652951891138969,
      "grad_norm": 0.05725104734301567,
      "learning_rate": 1.4694096217722063e-05,
      "loss": 0.0052,
      "step": 24760
    },
    {
      "epoch": 2.6540233579770707,
      "grad_norm": 0.3779831528663635,
      "learning_rate": 1.4691953284045859e-05,
      "loss": 0.8007,
      "step": 24770
    },
    {
      "epoch": 2.655094824815172,
      "grad_norm": 0.06365904957056046,
      "learning_rate": 1.4689810350369658e-05,
      "loss": 0.0036,
      "step": 24780
    },
    {
      "epoch": 2.6561662916532733,
      "grad_norm": 0.08057670295238495,
      "learning_rate": 1.4687667416693454e-05,
      "loss": 0.1833,
      "step": 24790
    },
    {
      "epoch": 2.657237758491375,
      "grad_norm": 35.14080047607422,
      "learning_rate": 1.4685524483017253e-05,
      "loss": 0.6002,
      "step": 24800
    },
    {
      "epoch": 2.658309225329476,
      "grad_norm": 14.624122619628906,
      "learning_rate": 1.468338154934105e-05,
      "loss": 0.6898,
      "step": 24810
    },
    {
      "epoch": 2.6593806921675776,
      "grad_norm": 0.4737960994243622,
      "learning_rate": 1.4681238615664846e-05,
      "loss": 0.4129,
      "step": 24820
    },
    {
      "epoch": 2.6604521590056787,
      "grad_norm": 0.15282653272151947,
      "learning_rate": 1.4679095681988645e-05,
      "loss": 0.1744,
      "step": 24830
    },
    {
      "epoch": 2.66152362584378,
      "grad_norm": 0.01636449061334133,
      "learning_rate": 1.467695274831244e-05,
      "loss": 0.5675,
      "step": 24840
    },
    {
      "epoch": 2.6625950926818813,
      "grad_norm": 0.1248810663819313,
      "learning_rate": 1.4674809814636238e-05,
      "loss": 0.416,
      "step": 24850
    },
    {
      "epoch": 2.663666559519983,
      "grad_norm": 0.3149724006652832,
      "learning_rate": 1.4672666880960035e-05,
      "loss": 0.3191,
      "step": 24860
    },
    {
      "epoch": 2.6647380263580844,
      "grad_norm": 0.6162080764770508,
      "learning_rate": 1.4670523947283832e-05,
      "loss": 0.3594,
      "step": 24870
    },
    {
      "epoch": 2.6658094931961855,
      "grad_norm": 0.5651021599769592,
      "learning_rate": 1.4668381013607631e-05,
      "loss": 0.1694,
      "step": 24880
    },
    {
      "epoch": 2.666880960034287,
      "grad_norm": 0.014682991430163383,
      "learning_rate": 1.4666238079931427e-05,
      "loss": 0.3325,
      "step": 24890
    },
    {
      "epoch": 2.667952426872388,
      "grad_norm": 0.060853589326143265,
      "learning_rate": 1.4664095146255224e-05,
      "loss": 0.0043,
      "step": 24900
    },
    {
      "epoch": 2.6690238937104898,
      "grad_norm": 0.056667719036340714,
      "learning_rate": 1.4661952212579022e-05,
      "loss": 0.5068,
      "step": 24910
    },
    {
      "epoch": 2.670095360548591,
      "grad_norm": 0.45540720224380493,
      "learning_rate": 1.465980927890282e-05,
      "loss": 0.2147,
      "step": 24920
    },
    {
      "epoch": 2.6711668273866924,
      "grad_norm": 0.1156415045261383,
      "learning_rate": 1.4657666345226615e-05,
      "loss": 0.0407,
      "step": 24930
    },
    {
      "epoch": 2.672238294224794,
      "grad_norm": 0.22121794521808624,
      "learning_rate": 1.4655523411550414e-05,
      "loss": 0.3394,
      "step": 24940
    },
    {
      "epoch": 2.673309761062895,
      "grad_norm": 0.18411238491535187,
      "learning_rate": 1.4653380477874211e-05,
      "loss": 0.2054,
      "step": 24950
    },
    {
      "epoch": 2.674381227900996,
      "grad_norm": 0.3064463436603546,
      "learning_rate": 1.4651237544198009e-05,
      "loss": 0.1782,
      "step": 24960
    },
    {
      "epoch": 2.6754526947390977,
      "grad_norm": 0.01361742801964283,
      "learning_rate": 1.4649094610521806e-05,
      "loss": 0.0897,
      "step": 24970
    },
    {
      "epoch": 2.6765241615771993,
      "grad_norm": 1.791967749595642,
      "learning_rate": 1.4646951676845602e-05,
      "loss": 0.2942,
      "step": 24980
    },
    {
      "epoch": 2.6775956284153004,
      "grad_norm": 14.828144073486328,
      "learning_rate": 1.46448087431694e-05,
      "loss": 0.5056,
      "step": 24990
    },
    {
      "epoch": 2.678667095253402,
      "grad_norm": 0.011266541667282581,
      "learning_rate": 1.4642665809493198e-05,
      "loss": 0.4716,
      "step": 25000
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.18506065011024475,
      "learning_rate": 1.4640522875816994e-05,
      "loss": 0.1652,
      "step": 25010
    },
    {
      "epoch": 2.6808100289296046,
      "grad_norm": 0.10381616652011871,
      "learning_rate": 1.4638379942140793e-05,
      "loss": 0.4074,
      "step": 25020
    },
    {
      "epoch": 2.6818814957677057,
      "grad_norm": 0.003125931369140744,
      "learning_rate": 1.4636237008464588e-05,
      "loss": 0.0007,
      "step": 25030
    },
    {
      "epoch": 2.6829529626058073,
      "grad_norm": 0.17496171593666077,
      "learning_rate": 1.4634094074788387e-05,
      "loss": 0.6426,
      "step": 25040
    },
    {
      "epoch": 2.684024429443909,
      "grad_norm": 0.407949835062027,
      "learning_rate": 1.4631951141112183e-05,
      "loss": 0.4908,
      "step": 25050
    },
    {
      "epoch": 2.68509589628201,
      "grad_norm": 0.38956984877586365,
      "learning_rate": 1.462980820743598e-05,
      "loss": 0.451,
      "step": 25060
    },
    {
      "epoch": 2.6861673631201115,
      "grad_norm": 24.694725036621094,
      "learning_rate": 1.462766527375978e-05,
      "loss": 0.1753,
      "step": 25070
    },
    {
      "epoch": 2.687238829958213,
      "grad_norm": 0.01910455897450447,
      "learning_rate": 1.4625522340083575e-05,
      "loss": 0.1702,
      "step": 25080
    },
    {
      "epoch": 2.688310296796314,
      "grad_norm": 0.18250493705272675,
      "learning_rate": 1.4623379406407373e-05,
      "loss": 0.4221,
      "step": 25090
    },
    {
      "epoch": 2.6893817636344153,
      "grad_norm": 0.013516691513359547,
      "learning_rate": 1.462123647273117e-05,
      "loss": 0.0947,
      "step": 25100
    },
    {
      "epoch": 2.690453230472517,
      "grad_norm": 0.011424949392676353,
      "learning_rate": 1.4619093539054967e-05,
      "loss": 0.0608,
      "step": 25110
    },
    {
      "epoch": 2.6915246973106184,
      "grad_norm": 0.19040508568286896,
      "learning_rate": 1.4616950605378766e-05,
      "loss": 0.5014,
      "step": 25120
    },
    {
      "epoch": 2.6925961641487195,
      "grad_norm": 0.012566791847348213,
      "learning_rate": 1.4614807671702562e-05,
      "loss": 0.0036,
      "step": 25130
    },
    {
      "epoch": 2.693667630986821,
      "grad_norm": 19.31737518310547,
      "learning_rate": 1.461266473802636e-05,
      "loss": 0.1521,
      "step": 25140
    },
    {
      "epoch": 2.694739097824922,
      "grad_norm": 0.09209165722131729,
      "learning_rate": 1.4610521804350157e-05,
      "loss": 0.449,
      "step": 25150
    },
    {
      "epoch": 2.6958105646630237,
      "grad_norm": 0.22742101550102234,
      "learning_rate": 1.4608378870673954e-05,
      "loss": 0.0067,
      "step": 25160
    },
    {
      "epoch": 2.696882031501125,
      "grad_norm": 0.010458232834935188,
      "learning_rate": 1.460623593699775e-05,
      "loss": 0.1615,
      "step": 25170
    },
    {
      "epoch": 2.6979534983392264,
      "grad_norm": 0.005933763459324837,
      "learning_rate": 1.4604093003321549e-05,
      "loss": 0.3289,
      "step": 25180
    },
    {
      "epoch": 2.699024965177328,
      "grad_norm": 20.169384002685547,
      "learning_rate": 1.4601950069645346e-05,
      "loss": 0.3555,
      "step": 25190
    },
    {
      "epoch": 2.700096432015429,
      "grad_norm": 0.2597118616104126,
      "learning_rate": 1.4599807135969143e-05,
      "loss": 0.2606,
      "step": 25200
    },
    {
      "epoch": 2.7011678988535306,
      "grad_norm": 0.14132645726203918,
      "learning_rate": 1.459766420229294e-05,
      "loss": 0.5489,
      "step": 25210
    },
    {
      "epoch": 2.7022393656916317,
      "grad_norm": 9.392616271972656,
      "learning_rate": 1.4595521268616736e-05,
      "loss": 0.3537,
      "step": 25220
    },
    {
      "epoch": 2.7033108325297333,
      "grad_norm": 0.010748358443379402,
      "learning_rate": 1.4593378334940536e-05,
      "loss": 0.0693,
      "step": 25230
    },
    {
      "epoch": 2.7043822993678344,
      "grad_norm": 0.11189905554056168,
      "learning_rate": 1.4591235401264331e-05,
      "loss": 0.345,
      "step": 25240
    },
    {
      "epoch": 2.705453766205936,
      "grad_norm": 0.04917621240019798,
      "learning_rate": 1.4589092467588129e-05,
      "loss": 0.1406,
      "step": 25250
    },
    {
      "epoch": 2.7065252330440375,
      "grad_norm": 0.03625405952334404,
      "learning_rate": 1.4586949533911928e-05,
      "loss": 0.1487,
      "step": 25260
    },
    {
      "epoch": 2.7075966998821386,
      "grad_norm": 0.40597742795944214,
      "learning_rate": 1.4584806600235723e-05,
      "loss": 0.0898,
      "step": 25270
    },
    {
      "epoch": 2.70866816672024,
      "grad_norm": 0.079319529235363,
      "learning_rate": 1.4582663666559522e-05,
      "loss": 0.6368,
      "step": 25280
    },
    {
      "epoch": 2.7097396335583412,
      "grad_norm": 0.5669932961463928,
      "learning_rate": 1.4580520732883318e-05,
      "loss": 0.2224,
      "step": 25290
    },
    {
      "epoch": 2.710811100396443,
      "grad_norm": 0.33384600281715393,
      "learning_rate": 1.4578377799207115e-05,
      "loss": 0.1155,
      "step": 25300
    },
    {
      "epoch": 2.711882567234544,
      "grad_norm": 0.06204337626695633,
      "learning_rate": 1.4576234865530914e-05,
      "loss": 0.0015,
      "step": 25310
    },
    {
      "epoch": 2.7129540340726455,
      "grad_norm": 0.12914609909057617,
      "learning_rate": 1.457409193185471e-05,
      "loss": 0.3836,
      "step": 25320
    },
    {
      "epoch": 2.714025500910747,
      "grad_norm": 0.061093468219041824,
      "learning_rate": 1.4571948998178507e-05,
      "loss": 0.1399,
      "step": 25330
    },
    {
      "epoch": 2.715096967748848,
      "grad_norm": 0.009420674294233322,
      "learning_rate": 1.4569806064502305e-05,
      "loss": 0.382,
      "step": 25340
    },
    {
      "epoch": 2.7161684345869497,
      "grad_norm": 0.010187055915594101,
      "learning_rate": 1.4567663130826102e-05,
      "loss": 0.6755,
      "step": 25350
    },
    {
      "epoch": 2.717239901425051,
      "grad_norm": 0.22368495166301727,
      "learning_rate": 1.4565520197149901e-05,
      "loss": 0.1857,
      "step": 25360
    },
    {
      "epoch": 2.7183113682631523,
      "grad_norm": 0.21259373426437378,
      "learning_rate": 1.4563377263473697e-05,
      "loss": 0.0879,
      "step": 25370
    },
    {
      "epoch": 2.7193828351012534,
      "grad_norm": 0.021971454843878746,
      "learning_rate": 1.4561234329797494e-05,
      "loss": 0.4884,
      "step": 25380
    },
    {
      "epoch": 2.720454301939355,
      "grad_norm": 84.75596618652344,
      "learning_rate": 1.4559091396121292e-05,
      "loss": 0.1116,
      "step": 25390
    },
    {
      "epoch": 2.7215257687774566,
      "grad_norm": 0.05287511646747589,
      "learning_rate": 1.4556948462445089e-05,
      "loss": 0.2341,
      "step": 25400
    },
    {
      "epoch": 2.7225972356155577,
      "grad_norm": 0.1555122286081314,
      "learning_rate": 1.4554805528768885e-05,
      "loss": 0.1984,
      "step": 25410
    },
    {
      "epoch": 2.723668702453659,
      "grad_norm": 0.08571801334619522,
      "learning_rate": 1.4552662595092684e-05,
      "loss": 0.0778,
      "step": 25420
    },
    {
      "epoch": 2.7247401692917603,
      "grad_norm": 0.08788563311100006,
      "learning_rate": 1.4550519661416481e-05,
      "loss": 0.0397,
      "step": 25430
    },
    {
      "epoch": 2.725811636129862,
      "grad_norm": 0.008323756977915764,
      "learning_rate": 1.4548376727740277e-05,
      "loss": 0.4533,
      "step": 25440
    },
    {
      "epoch": 2.726883102967963,
      "grad_norm": 0.022450849413871765,
      "learning_rate": 1.4546233794064076e-05,
      "loss": 0.5099,
      "step": 25450
    },
    {
      "epoch": 2.7279545698060645,
      "grad_norm": 0.047537822276353836,
      "learning_rate": 1.4544090860387871e-05,
      "loss": 0.5619,
      "step": 25460
    },
    {
      "epoch": 2.729026036644166,
      "grad_norm": 0.004869516938924789,
      "learning_rate": 1.454194792671167e-05,
      "loss": 0.0864,
      "step": 25470
    },
    {
      "epoch": 2.730097503482267,
      "grad_norm": 0.05213293060660362,
      "learning_rate": 1.4539804993035466e-05,
      "loss": 0.0971,
      "step": 25480
    },
    {
      "epoch": 2.7311689703203683,
      "grad_norm": 0.9329188466072083,
      "learning_rate": 1.4537662059359263e-05,
      "loss": 0.2344,
      "step": 25490
    },
    {
      "epoch": 2.73224043715847,
      "grad_norm": 83.86034393310547,
      "learning_rate": 1.4535519125683062e-05,
      "loss": 0.0362,
      "step": 25500
    },
    {
      "epoch": 2.7333119039965714,
      "grad_norm": 0.004892841447144747,
      "learning_rate": 1.4533376192006858e-05,
      "loss": 0.2765,
      "step": 25510
    },
    {
      "epoch": 2.7343833708346725,
      "grad_norm": 0.12043801695108414,
      "learning_rate": 1.4531233258330655e-05,
      "loss": 0.2021,
      "step": 25520
    },
    {
      "epoch": 2.735454837672774,
      "grad_norm": 0.30678337812423706,
      "learning_rate": 1.4529090324654453e-05,
      "loss": 0.1481,
      "step": 25530
    },
    {
      "epoch": 2.7365263045108756,
      "grad_norm": 0.07796671241521835,
      "learning_rate": 1.452694739097825e-05,
      "loss": 0.4372,
      "step": 25540
    },
    {
      "epoch": 2.7375977713489767,
      "grad_norm": 0.007424820214509964,
      "learning_rate": 1.452480445730205e-05,
      "loss": 0.6586,
      "step": 25550
    },
    {
      "epoch": 2.738669238187078,
      "grad_norm": 2.8327674865722656,
      "learning_rate": 1.4522661523625845e-05,
      "loss": 0.0053,
      "step": 25560
    },
    {
      "epoch": 2.7397407050251794,
      "grad_norm": 0.09239660203456879,
      "learning_rate": 1.4520518589949642e-05,
      "loss": 0.0154,
      "step": 25570
    },
    {
      "epoch": 2.740812171863281,
      "grad_norm": 0.8823676705360413,
      "learning_rate": 1.451837565627344e-05,
      "loss": 0.3328,
      "step": 25580
    },
    {
      "epoch": 2.741883638701382,
      "grad_norm": 0.0107683464884758,
      "learning_rate": 1.4516232722597237e-05,
      "loss": 0.1828,
      "step": 25590
    },
    {
      "epoch": 2.7429551055394836,
      "grad_norm": 0.0730743482708931,
      "learning_rate": 1.4514089788921033e-05,
      "loss": 0.1644,
      "step": 25600
    },
    {
      "epoch": 2.744026572377585,
      "grad_norm": 0.053622983396053314,
      "learning_rate": 1.4511946855244832e-05,
      "loss": 0.0006,
      "step": 25610
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.04226427897810936,
      "learning_rate": 1.4509803921568629e-05,
      "loss": 0.1728,
      "step": 25620
    },
    {
      "epoch": 2.7461695060537874,
      "grad_norm": 0.15306030213832855,
      "learning_rate": 1.4507660987892426e-05,
      "loss": 0.2492,
      "step": 25630
    },
    {
      "epoch": 2.747240972891889,
      "grad_norm": 0.015002444386482239,
      "learning_rate": 1.4505518054216224e-05,
      "loss": 0.8048,
      "step": 25640
    },
    {
      "epoch": 2.7483124397299905,
      "grad_norm": 0.01448693498969078,
      "learning_rate": 1.450337512054002e-05,
      "loss": 0.1989,
      "step": 25650
    },
    {
      "epoch": 2.7493839065680916,
      "grad_norm": 153.65098571777344,
      "learning_rate": 1.4501232186863818e-05,
      "loss": 0.182,
      "step": 25660
    },
    {
      "epoch": 2.750455373406193,
      "grad_norm": 27.69257164001465,
      "learning_rate": 1.4499089253187614e-05,
      "loss": 0.2449,
      "step": 25670
    },
    {
      "epoch": 2.7515268402442943,
      "grad_norm": 0.136911541223526,
      "learning_rate": 1.4496946319511411e-05,
      "loss": 0.2686,
      "step": 25680
    },
    {
      "epoch": 2.752598307082396,
      "grad_norm": 0.013819369487464428,
      "learning_rate": 1.449480338583521e-05,
      "loss": 0.3969,
      "step": 25690
    },
    {
      "epoch": 2.753669773920497,
      "grad_norm": 0.01967887207865715,
      "learning_rate": 1.4492660452159006e-05,
      "loss": 0.8736,
      "step": 25700
    },
    {
      "epoch": 2.7547412407585985,
      "grad_norm": 0.06397483497858047,
      "learning_rate": 1.4490517518482805e-05,
      "loss": 0.707,
      "step": 25710
    },
    {
      "epoch": 2.7558127075967,
      "grad_norm": 0.0377337746322155,
      "learning_rate": 1.4488374584806601e-05,
      "loss": 0.1638,
      "step": 25720
    },
    {
      "epoch": 2.756884174434801,
      "grad_norm": 22.192806243896484,
      "learning_rate": 1.4486231651130398e-05,
      "loss": 0.2191,
      "step": 25730
    },
    {
      "epoch": 2.7579556412729027,
      "grad_norm": 0.317081093788147,
      "learning_rate": 1.4484088717454197e-05,
      "loss": 0.2505,
      "step": 25740
    },
    {
      "epoch": 2.759027108111004,
      "grad_norm": 37.22414779663086,
      "learning_rate": 1.4481945783777993e-05,
      "loss": 0.6406,
      "step": 25750
    },
    {
      "epoch": 2.7600985749491054,
      "grad_norm": 0.11963292956352234,
      "learning_rate": 1.447980285010179e-05,
      "loss": 0.3486,
      "step": 25760
    },
    {
      "epoch": 2.7611700417872065,
      "grad_norm": 27.283950805664062,
      "learning_rate": 1.4477659916425588e-05,
      "loss": 0.2241,
      "step": 25770
    },
    {
      "epoch": 2.762241508625308,
      "grad_norm": 0.024133697152137756,
      "learning_rate": 1.4475516982749385e-05,
      "loss": 0.7708,
      "step": 25780
    },
    {
      "epoch": 2.7633129754634096,
      "grad_norm": 14.941784858703613,
      "learning_rate": 1.4473374049073184e-05,
      "loss": 0.2039,
      "step": 25790
    },
    {
      "epoch": 2.7643844423015107,
      "grad_norm": 0.06155223026871681,
      "learning_rate": 1.447123111539698e-05,
      "loss": 0.005,
      "step": 25800
    },
    {
      "epoch": 2.7654559091396123,
      "grad_norm": 0.23245063424110413,
      "learning_rate": 1.4469088181720777e-05,
      "loss": 0.639,
      "step": 25810
    },
    {
      "epoch": 2.7665273759777134,
      "grad_norm": 82.1969985961914,
      "learning_rate": 1.4466945248044574e-05,
      "loss": 0.2224,
      "step": 25820
    },
    {
      "epoch": 2.767598842815815,
      "grad_norm": 0.0745013952255249,
      "learning_rate": 1.4464802314368372e-05,
      "loss": 0.0039,
      "step": 25830
    },
    {
      "epoch": 2.768670309653916,
      "grad_norm": 0.10159637033939362,
      "learning_rate": 1.4462659380692167e-05,
      "loss": 0.0535,
      "step": 25840
    },
    {
      "epoch": 2.7697417764920176,
      "grad_norm": 0.3460392951965332,
      "learning_rate": 1.4460516447015966e-05,
      "loss": 0.2379,
      "step": 25850
    },
    {
      "epoch": 2.770813243330119,
      "grad_norm": 0.15980859100818634,
      "learning_rate": 1.4458373513339762e-05,
      "loss": 0.2482,
      "step": 25860
    },
    {
      "epoch": 2.7718847101682202,
      "grad_norm": 23.698795318603516,
      "learning_rate": 1.4456230579663561e-05,
      "loss": 0.8681,
      "step": 25870
    },
    {
      "epoch": 2.772956177006322,
      "grad_norm": 21.319408416748047,
      "learning_rate": 1.4454087645987359e-05,
      "loss": 0.6365,
      "step": 25880
    },
    {
      "epoch": 2.774027643844423,
      "grad_norm": 20.610919952392578,
      "learning_rate": 1.4451944712311154e-05,
      "loss": 0.378,
      "step": 25890
    },
    {
      "epoch": 2.7750991106825245,
      "grad_norm": 0.21986372768878937,
      "learning_rate": 1.4449801778634953e-05,
      "loss": 0.1164,
      "step": 25900
    },
    {
      "epoch": 2.7761705775206256,
      "grad_norm": 0.17701901495456696,
      "learning_rate": 1.4447658844958749e-05,
      "loss": 0.31,
      "step": 25910
    },
    {
      "epoch": 2.777242044358727,
      "grad_norm": 44.881690979003906,
      "learning_rate": 1.4445515911282546e-05,
      "loss": 0.5154,
      "step": 25920
    },
    {
      "epoch": 2.7783135111968287,
      "grad_norm": 18.92255973815918,
      "learning_rate": 1.4443372977606345e-05,
      "loss": 0.7203,
      "step": 25930
    },
    {
      "epoch": 2.77938497803493,
      "grad_norm": 0.10399972647428513,
      "learning_rate": 1.4441230043930141e-05,
      "loss": 0.2692,
      "step": 25940
    },
    {
      "epoch": 2.7804564448730313,
      "grad_norm": 0.11240674555301666,
      "learning_rate": 1.443908711025394e-05,
      "loss": 0.387,
      "step": 25950
    },
    {
      "epoch": 2.7815279117111325,
      "grad_norm": 0.6347366571426392,
      "learning_rate": 1.4436944176577736e-05,
      "loss": 0.5207,
      "step": 25960
    },
    {
      "epoch": 2.782599378549234,
      "grad_norm": 19.7469425201416,
      "learning_rate": 1.4434801242901533e-05,
      "loss": 0.1863,
      "step": 25970
    },
    {
      "epoch": 2.783670845387335,
      "grad_norm": 15.160341262817383,
      "learning_rate": 1.4432658309225332e-05,
      "loss": 0.2155,
      "step": 25980
    },
    {
      "epoch": 2.7847423122254367,
      "grad_norm": 18.5164852142334,
      "learning_rate": 1.4430515375549128e-05,
      "loss": 0.3985,
      "step": 25990
    },
    {
      "epoch": 2.785813779063538,
      "grad_norm": 0.09223878383636475,
      "learning_rate": 1.4428372441872925e-05,
      "loss": 0.0056,
      "step": 26000
    },
    {
      "epoch": 2.7868852459016393,
      "grad_norm": 0.01563536934554577,
      "learning_rate": 1.4426229508196722e-05,
      "loss": 0.1566,
      "step": 26010
    },
    {
      "epoch": 2.7879567127397404,
      "grad_norm": 0.13176250457763672,
      "learning_rate": 1.442408657452052e-05,
      "loss": 0.6118,
      "step": 26020
    },
    {
      "epoch": 2.789028179577842,
      "grad_norm": 0.1348728984594345,
      "learning_rate": 1.4421943640844319e-05,
      "loss": 0.1851,
      "step": 26030
    },
    {
      "epoch": 2.7900996464159435,
      "grad_norm": 63.69657897949219,
      "learning_rate": 1.4419800707168115e-05,
      "loss": 0.4512,
      "step": 26040
    },
    {
      "epoch": 2.7911711132540447,
      "grad_norm": 0.10959501564502716,
      "learning_rate": 1.441765777349191e-05,
      "loss": 0.2531,
      "step": 26050
    },
    {
      "epoch": 2.792242580092146,
      "grad_norm": 0.15859052538871765,
      "learning_rate": 1.441551483981571e-05,
      "loss": 0.5688,
      "step": 26060
    },
    {
      "epoch": 2.7933140469302478,
      "grad_norm": 1.0767948627471924,
      "learning_rate": 1.4413371906139507e-05,
      "loss": 0.32,
      "step": 26070
    },
    {
      "epoch": 2.794385513768349,
      "grad_norm": 28.812091827392578,
      "learning_rate": 1.4411228972463302e-05,
      "loss": 0.3664,
      "step": 26080
    },
    {
      "epoch": 2.79545698060645,
      "grad_norm": 0.0354749858379364,
      "learning_rate": 1.4409086038787101e-05,
      "loss": 0.5131,
      "step": 26090
    },
    {
      "epoch": 2.7965284474445515,
      "grad_norm": 0.09662532061338425,
      "learning_rate": 1.4406943105110897e-05,
      "loss": 0.224,
      "step": 26100
    },
    {
      "epoch": 2.797599914282653,
      "grad_norm": 21.582679748535156,
      "learning_rate": 1.4404800171434696e-05,
      "loss": 0.3938,
      "step": 26110
    },
    {
      "epoch": 2.798671381120754,
      "grad_norm": 7.501326084136963,
      "learning_rate": 1.4402657237758493e-05,
      "loss": 0.2846,
      "step": 26120
    },
    {
      "epoch": 2.7997428479588558,
      "grad_norm": 0.13581053912639618,
      "learning_rate": 1.4400514304082289e-05,
      "loss": 0.1446,
      "step": 26130
    },
    {
      "epoch": 2.8008143147969573,
      "grad_norm": 17.385549545288086,
      "learning_rate": 1.4398371370406088e-05,
      "loss": 0.4992,
      "step": 26140
    },
    {
      "epoch": 2.8018857816350584,
      "grad_norm": 0.037311822175979614,
      "learning_rate": 1.4396228436729884e-05,
      "loss": 0.166,
      "step": 26150
    },
    {
      "epoch": 2.8029572484731595,
      "grad_norm": 0.0331643745303154,
      "learning_rate": 1.4394085503053681e-05,
      "loss": 0.3766,
      "step": 26160
    },
    {
      "epoch": 2.804028715311261,
      "grad_norm": 10.598660469055176,
      "learning_rate": 1.439194256937748e-05,
      "loss": 0.1516,
      "step": 26170
    },
    {
      "epoch": 2.8051001821493626,
      "grad_norm": 0.024425959214568138,
      "learning_rate": 1.4389799635701276e-05,
      "loss": 0.2367,
      "step": 26180
    },
    {
      "epoch": 2.8061716489874637,
      "grad_norm": 18.70882797241211,
      "learning_rate": 1.4387656702025075e-05,
      "loss": 0.5869,
      "step": 26190
    },
    {
      "epoch": 2.8072431158255653,
      "grad_norm": 0.41887572407722473,
      "learning_rate": 1.438551376834887e-05,
      "loss": 0.2445,
      "step": 26200
    },
    {
      "epoch": 2.8083145826636664,
      "grad_norm": 0.0338820219039917,
      "learning_rate": 1.4383370834672668e-05,
      "loss": 0.4022,
      "step": 26210
    },
    {
      "epoch": 2.809386049501768,
      "grad_norm": 0.28688469529151917,
      "learning_rate": 1.4381227900996467e-05,
      "loss": 0.7754,
      "step": 26220
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 0.01775343157351017,
      "learning_rate": 1.4379084967320263e-05,
      "loss": 0.1548,
      "step": 26230
    },
    {
      "epoch": 2.8115289831779706,
      "grad_norm": 0.13883085548877716,
      "learning_rate": 1.4376942033644058e-05,
      "loss": 0.3066,
      "step": 26240
    },
    {
      "epoch": 2.812600450016072,
      "grad_norm": 0.012273312546312809,
      "learning_rate": 1.4374799099967857e-05,
      "loss": 0.3414,
      "step": 26250
    },
    {
      "epoch": 2.8136719168541733,
      "grad_norm": 0.04895113408565521,
      "learning_rate": 1.4372656166291655e-05,
      "loss": 0.1438,
      "step": 26260
    },
    {
      "epoch": 2.814743383692275,
      "grad_norm": 0.04111963510513306,
      "learning_rate": 1.4370513232615452e-05,
      "loss": 0.3348,
      "step": 26270
    },
    {
      "epoch": 2.815814850530376,
      "grad_norm": 0.4719144403934479,
      "learning_rate": 1.436837029893925e-05,
      "loss": 0.0113,
      "step": 26280
    },
    {
      "epoch": 2.8168863173684775,
      "grad_norm": 20.729928970336914,
      "learning_rate": 1.4366227365263045e-05,
      "loss": 0.3535,
      "step": 26290
    },
    {
      "epoch": 2.8179577842065786,
      "grad_norm": 0.023197341710329056,
      "learning_rate": 1.4364084431586844e-05,
      "loss": 0.0475,
      "step": 26300
    },
    {
      "epoch": 2.81902925104468,
      "grad_norm": 17.718421936035156,
      "learning_rate": 1.4361941497910641e-05,
      "loss": 0.3106,
      "step": 26310
    },
    {
      "epoch": 2.8201007178827817,
      "grad_norm": 0.851081371307373,
      "learning_rate": 1.4359798564234437e-05,
      "loss": 0.1202,
      "step": 26320
    },
    {
      "epoch": 2.821172184720883,
      "grad_norm": 4.099935054779053,
      "learning_rate": 1.4357655630558236e-05,
      "loss": 0.5836,
      "step": 26330
    },
    {
      "epoch": 2.8222436515589844,
      "grad_norm": 0.04728638008236885,
      "learning_rate": 1.4355512696882032e-05,
      "loss": 0.2833,
      "step": 26340
    },
    {
      "epoch": 2.8233151183970855,
      "grad_norm": 14.354848861694336,
      "learning_rate": 1.435336976320583e-05,
      "loss": 0.9766,
      "step": 26350
    },
    {
      "epoch": 2.824386585235187,
      "grad_norm": 0.023744968697428703,
      "learning_rate": 1.4351226829529628e-05,
      "loss": 0.2449,
      "step": 26360
    },
    {
      "epoch": 2.825458052073288,
      "grad_norm": 0.16322004795074463,
      "learning_rate": 1.4349083895853424e-05,
      "loss": 0.341,
      "step": 26370
    },
    {
      "epoch": 2.8265295189113897,
      "grad_norm": 73.49589538574219,
      "learning_rate": 1.4346940962177223e-05,
      "loss": 0.6058,
      "step": 26380
    },
    {
      "epoch": 2.8276009857494913,
      "grad_norm": 0.16449221968650818,
      "learning_rate": 1.4344798028501019e-05,
      "loss": 0.4207,
      "step": 26390
    },
    {
      "epoch": 2.8286724525875924,
      "grad_norm": 0.9900598526000977,
      "learning_rate": 1.4342655094824816e-05,
      "loss": 0.1384,
      "step": 26400
    },
    {
      "epoch": 2.829743919425694,
      "grad_norm": 0.7006560564041138,
      "learning_rate": 1.4340512161148615e-05,
      "loss": 0.1053,
      "step": 26410
    },
    {
      "epoch": 2.830815386263795,
      "grad_norm": 23.921306610107422,
      "learning_rate": 1.433836922747241e-05,
      "loss": 0.199,
      "step": 26420
    },
    {
      "epoch": 2.8318868531018966,
      "grad_norm": 0.0415424145758152,
      "learning_rate": 1.4336226293796206e-05,
      "loss": 0.67,
      "step": 26430
    },
    {
      "epoch": 2.8329583199399977,
      "grad_norm": 0.1219567283987999,
      "learning_rate": 1.4334083360120005e-05,
      "loss": 0.1475,
      "step": 26440
    },
    {
      "epoch": 2.8340297867780992,
      "grad_norm": 0.14948952198028564,
      "learning_rate": 1.4331940426443803e-05,
      "loss": 0.4347,
      "step": 26450
    },
    {
      "epoch": 2.835101253616201,
      "grad_norm": 1.5675101280212402,
      "learning_rate": 1.43297974927676e-05,
      "loss": 0.8306,
      "step": 26460
    },
    {
      "epoch": 2.836172720454302,
      "grad_norm": 0.12132153660058975,
      "learning_rate": 1.4327654559091397e-05,
      "loss": 0.5746,
      "step": 26470
    },
    {
      "epoch": 2.8372441872924035,
      "grad_norm": 0.21873976290225983,
      "learning_rate": 1.4325511625415193e-05,
      "loss": 0.314,
      "step": 26480
    },
    {
      "epoch": 2.8383156541305046,
      "grad_norm": 0.39203307032585144,
      "learning_rate": 1.4323368691738992e-05,
      "loss": 0.2389,
      "step": 26490
    },
    {
      "epoch": 2.839387120968606,
      "grad_norm": 0.32461652159690857,
      "learning_rate": 1.432122575806279e-05,
      "loss": 0.4043,
      "step": 26500
    },
    {
      "epoch": 2.8404585878067072,
      "grad_norm": 16.711565017700195,
      "learning_rate": 1.4319082824386585e-05,
      "loss": 0.4775,
      "step": 26510
    },
    {
      "epoch": 2.841530054644809,
      "grad_norm": 0.48654088377952576,
      "learning_rate": 1.4316939890710384e-05,
      "loss": 0.3726,
      "step": 26520
    },
    {
      "epoch": 2.8426015214829103,
      "grad_norm": 0.037617962807416916,
      "learning_rate": 1.431479695703418e-05,
      "loss": 0.4798,
      "step": 26530
    },
    {
      "epoch": 2.8436729883210115,
      "grad_norm": 0.07461600005626678,
      "learning_rate": 1.4312654023357979e-05,
      "loss": 0.2023,
      "step": 26540
    },
    {
      "epoch": 2.8447444551591126,
      "grad_norm": 0.5973905324935913,
      "learning_rate": 1.4310511089681776e-05,
      "loss": 0.1875,
      "step": 26550
    },
    {
      "epoch": 2.845815921997214,
      "grad_norm": 1.8151532411575317,
      "learning_rate": 1.4308368156005572e-05,
      "loss": 0.2755,
      "step": 26560
    },
    {
      "epoch": 2.8468873888353157,
      "grad_norm": 0.10155981034040451,
      "learning_rate": 1.4306225222329371e-05,
      "loss": 0.3015,
      "step": 26570
    },
    {
      "epoch": 2.847958855673417,
      "grad_norm": 14.92169189453125,
      "learning_rate": 1.4304082288653167e-05,
      "loss": 0.6176,
      "step": 26580
    },
    {
      "epoch": 2.8490303225115183,
      "grad_norm": 0.14223149418830872,
      "learning_rate": 1.4301939354976964e-05,
      "loss": 0.6225,
      "step": 26590
    },
    {
      "epoch": 2.85010178934962,
      "grad_norm": 29.692258834838867,
      "learning_rate": 1.4299796421300763e-05,
      "loss": 0.2584,
      "step": 26600
    },
    {
      "epoch": 2.851173256187721,
      "grad_norm": 14.954383850097656,
      "learning_rate": 1.4297653487624559e-05,
      "loss": 0.3674,
      "step": 26610
    },
    {
      "epoch": 2.852244723025822,
      "grad_norm": 1.6961829662322998,
      "learning_rate": 1.4295510553948358e-05,
      "loss": 0.7037,
      "step": 26620
    },
    {
      "epoch": 2.8533161898639237,
      "grad_norm": 20.189645767211914,
      "learning_rate": 1.4293367620272153e-05,
      "loss": 0.2144,
      "step": 26630
    },
    {
      "epoch": 2.854387656702025,
      "grad_norm": 35.2940788269043,
      "learning_rate": 1.429122468659595e-05,
      "loss": 0.2356,
      "step": 26640
    },
    {
      "epoch": 2.8554591235401263,
      "grad_norm": 14.304757118225098,
      "learning_rate": 1.4289081752919748e-05,
      "loss": 0.4785,
      "step": 26650
    },
    {
      "epoch": 2.856530590378228,
      "grad_norm": 0.16246408224105835,
      "learning_rate": 1.4286938819243546e-05,
      "loss": 0.5257,
      "step": 26660
    },
    {
      "epoch": 2.8576020572163294,
      "grad_norm": 0.709362268447876,
      "learning_rate": 1.4284795885567341e-05,
      "loss": 0.0072,
      "step": 26670
    },
    {
      "epoch": 2.8586735240544305,
      "grad_norm": 14.504511833190918,
      "learning_rate": 1.428265295189114e-05,
      "loss": 0.8324,
      "step": 26680
    },
    {
      "epoch": 2.8597449908925316,
      "grad_norm": 0.03370117396116257,
      "learning_rate": 1.4280510018214938e-05,
      "loss": 0.3562,
      "step": 26690
    },
    {
      "epoch": 2.860816457730633,
      "grad_norm": 1.4081257581710815,
      "learning_rate": 1.4278367084538735e-05,
      "loss": 0.5061,
      "step": 26700
    },
    {
      "epoch": 2.8618879245687348,
      "grad_norm": 17.180973052978516,
      "learning_rate": 1.4276224150862532e-05,
      "loss": 0.1767,
      "step": 26710
    },
    {
      "epoch": 2.862959391406836,
      "grad_norm": 0.36273911595344543,
      "learning_rate": 1.4274081217186328e-05,
      "loss": 0.4692,
      "step": 26720
    },
    {
      "epoch": 2.8640308582449374,
      "grad_norm": 28.388973236083984,
      "learning_rate": 1.4271938283510127e-05,
      "loss": 0.5146,
      "step": 26730
    },
    {
      "epoch": 2.8651023250830385,
      "grad_norm": 1.0812368392944336,
      "learning_rate": 1.4269795349833924e-05,
      "loss": 0.1502,
      "step": 26740
    },
    {
      "epoch": 2.86617379192114,
      "grad_norm": 24.00347900390625,
      "learning_rate": 1.426765241615772e-05,
      "loss": 0.3404,
      "step": 26750
    },
    {
      "epoch": 2.867245258759241,
      "grad_norm": 0.11323319375514984,
      "learning_rate": 1.4265509482481519e-05,
      "loss": 0.0062,
      "step": 26760
    },
    {
      "epoch": 2.8683167255973427,
      "grad_norm": 0.05159231647849083,
      "learning_rate": 1.4263366548805315e-05,
      "loss": 0.0055,
      "step": 26770
    },
    {
      "epoch": 2.8693881924354443,
      "grad_norm": 0.0047494820319116116,
      "learning_rate": 1.4261223615129114e-05,
      "loss": 0.0094,
      "step": 26780
    },
    {
      "epoch": 2.8704596592735454,
      "grad_norm": 0.00869062915444374,
      "learning_rate": 1.4259080681452911e-05,
      "loss": 0.3137,
      "step": 26790
    },
    {
      "epoch": 2.871531126111647,
      "grad_norm": 0.03269157186150551,
      "learning_rate": 1.4256937747776707e-05,
      "loss": 0.5524,
      "step": 26800
    },
    {
      "epoch": 2.872602592949748,
      "grad_norm": 0.04099802300333977,
      "learning_rate": 1.4254794814100506e-05,
      "loss": 0.0804,
      "step": 26810
    },
    {
      "epoch": 2.8736740597878496,
      "grad_norm": 14.918508529663086,
      "learning_rate": 1.4252651880424302e-05,
      "loss": 0.1538,
      "step": 26820
    },
    {
      "epoch": 2.8747455266259507,
      "grad_norm": 0.16298435628414154,
      "learning_rate": 1.4250508946748099e-05,
      "loss": 0.745,
      "step": 26830
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 1.8415331840515137,
      "learning_rate": 1.4248366013071896e-05,
      "loss": 0.0324,
      "step": 26840
    },
    {
      "epoch": 2.876888460302154,
      "grad_norm": 0.034786589443683624,
      "learning_rate": 1.4246223079395694e-05,
      "loss": 0.2634,
      "step": 26850
    },
    {
      "epoch": 2.877959927140255,
      "grad_norm": 0.18101449310779572,
      "learning_rate": 1.4244080145719493e-05,
      "loss": 0.1638,
      "step": 26860
    },
    {
      "epoch": 2.8790313939783565,
      "grad_norm": 0.05184096470475197,
      "learning_rate": 1.4241937212043288e-05,
      "loss": 0.0331,
      "step": 26870
    },
    {
      "epoch": 2.8801028608164576,
      "grad_norm": 0.19457243382930756,
      "learning_rate": 1.4239794278367086e-05,
      "loss": 0.6793,
      "step": 26880
    },
    {
      "epoch": 2.881174327654559,
      "grad_norm": 0.012411058880388737,
      "learning_rate": 1.4237651344690883e-05,
      "loss": 0.4959,
      "step": 26890
    },
    {
      "epoch": 2.8822457944926603,
      "grad_norm": 0.06992392987012863,
      "learning_rate": 1.423550841101468e-05,
      "loss": 0.4553,
      "step": 26900
    },
    {
      "epoch": 2.883317261330762,
      "grad_norm": 18.676692962646484,
      "learning_rate": 1.4233365477338476e-05,
      "loss": 1.0739,
      "step": 26910
    },
    {
      "epoch": 2.8843887281688634,
      "grad_norm": 0.08118750154972076,
      "learning_rate": 1.4231222543662275e-05,
      "loss": 0.5072,
      "step": 26920
    },
    {
      "epoch": 2.8854601950069645,
      "grad_norm": 0.09974285960197449,
      "learning_rate": 1.4229079609986072e-05,
      "loss": 0.0065,
      "step": 26930
    },
    {
      "epoch": 2.886531661845066,
      "grad_norm": 0.1962326467037201,
      "learning_rate": 1.422693667630987e-05,
      "loss": 0.1839,
      "step": 26940
    },
    {
      "epoch": 2.887603128683167,
      "grad_norm": 21.412813186645508,
      "learning_rate": 1.4224793742633667e-05,
      "loss": 0.2655,
      "step": 26950
    },
    {
      "epoch": 2.8886745955212687,
      "grad_norm": 62.325923919677734,
      "learning_rate": 1.4222650808957463e-05,
      "loss": 0.9102,
      "step": 26960
    },
    {
      "epoch": 2.88974606235937,
      "grad_norm": 0.06897998601198196,
      "learning_rate": 1.4220507875281262e-05,
      "loss": 0.5405,
      "step": 26970
    },
    {
      "epoch": 2.8908175291974714,
      "grad_norm": 0.2158632129430771,
      "learning_rate": 1.421836494160506e-05,
      "loss": 0.1099,
      "step": 26980
    },
    {
      "epoch": 2.891888996035573,
      "grad_norm": 0.22945748269557953,
      "learning_rate": 1.4216222007928855e-05,
      "loss": 0.623,
      "step": 26990
    },
    {
      "epoch": 2.892960462873674,
      "grad_norm": 12.705214500427246,
      "learning_rate": 1.4214079074252654e-05,
      "loss": 0.1364,
      "step": 27000
    },
    {
      "epoch": 2.8940319297117756,
      "grad_norm": 0.05774057283997536,
      "learning_rate": 1.421193614057645e-05,
      "loss": 0.2565,
      "step": 27010
    },
    {
      "epoch": 2.8951033965498767,
      "grad_norm": 15.584404945373535,
      "learning_rate": 1.4209793206900249e-05,
      "loss": 0.7676,
      "step": 27020
    },
    {
      "epoch": 2.8961748633879782,
      "grad_norm": 0.19611050188541412,
      "learning_rate": 1.4207650273224044e-05,
      "loss": 0.3211,
      "step": 27030
    },
    {
      "epoch": 2.8972463302260794,
      "grad_norm": 14.791254997253418,
      "learning_rate": 1.4205507339547842e-05,
      "loss": 0.1656,
      "step": 27040
    },
    {
      "epoch": 2.898317797064181,
      "grad_norm": 26.140283584594727,
      "learning_rate": 1.420336440587164e-05,
      "loss": 0.4964,
      "step": 27050
    },
    {
      "epoch": 2.8993892639022825,
      "grad_norm": 0.013514754362404346,
      "learning_rate": 1.4201221472195436e-05,
      "loss": 0.1525,
      "step": 27060
    },
    {
      "epoch": 2.9004607307403836,
      "grad_norm": 0.2482527494430542,
      "learning_rate": 1.4199078538519234e-05,
      "loss": 0.1531,
      "step": 27070
    },
    {
      "epoch": 2.9015321975784847,
      "grad_norm": 0.13073097169399261,
      "learning_rate": 1.4196935604843031e-05,
      "loss": 0.639,
      "step": 27080
    },
    {
      "epoch": 2.9026036644165862,
      "grad_norm": 0.08954015374183655,
      "learning_rate": 1.4194792671166828e-05,
      "loss": 0.1928,
      "step": 27090
    },
    {
      "epoch": 2.903675131254688,
      "grad_norm": 0.10747767984867096,
      "learning_rate": 1.4192649737490627e-05,
      "loss": 0.0022,
      "step": 27100
    },
    {
      "epoch": 2.904746598092789,
      "grad_norm": 33.26553726196289,
      "learning_rate": 1.4190506803814423e-05,
      "loss": 0.0104,
      "step": 27110
    },
    {
      "epoch": 2.9058180649308905,
      "grad_norm": 0.025532664731144905,
      "learning_rate": 1.418836387013822e-05,
      "loss": 0.1966,
      "step": 27120
    },
    {
      "epoch": 2.906889531768992,
      "grad_norm": 0.07236011326313019,
      "learning_rate": 1.4186220936462018e-05,
      "loss": 0.2161,
      "step": 27130
    },
    {
      "epoch": 2.907960998607093,
      "grad_norm": 0.1452716588973999,
      "learning_rate": 1.4184078002785815e-05,
      "loss": 0.3289,
      "step": 27140
    },
    {
      "epoch": 2.9090324654451942,
      "grad_norm": 0.19889289140701294,
      "learning_rate": 1.4181935069109611e-05,
      "loss": 0.3198,
      "step": 27150
    },
    {
      "epoch": 2.910103932283296,
      "grad_norm": 0.04276376962661743,
      "learning_rate": 1.417979213543341e-05,
      "loss": 0.195,
      "step": 27160
    },
    {
      "epoch": 2.9111753991213973,
      "grad_norm": 0.08354000747203827,
      "learning_rate": 1.4177649201757207e-05,
      "loss": 0.4218,
      "step": 27170
    },
    {
      "epoch": 2.9122468659594984,
      "grad_norm": 0.12678752839565277,
      "learning_rate": 1.4175506268081005e-05,
      "loss": 0.2617,
      "step": 27180
    },
    {
      "epoch": 2.9133183327976,
      "grad_norm": 0.03744014352560043,
      "learning_rate": 1.4173363334404802e-05,
      "loss": 0.4636,
      "step": 27190
    },
    {
      "epoch": 2.9143897996357016,
      "grad_norm": 0.023257791996002197,
      "learning_rate": 1.4171220400728598e-05,
      "loss": 0.1334,
      "step": 27200
    },
    {
      "epoch": 2.9154612664738027,
      "grad_norm": 15.492168426513672,
      "learning_rate": 1.4169077467052397e-05,
      "loss": 0.272,
      "step": 27210
    },
    {
      "epoch": 2.9165327333119038,
      "grad_norm": 0.13436709344387054,
      "learning_rate": 1.4166934533376192e-05,
      "loss": 0.2356,
      "step": 27220
    },
    {
      "epoch": 2.9176042001500053,
      "grad_norm": 0.036541666835546494,
      "learning_rate": 1.416479159969999e-05,
      "loss": 0.179,
      "step": 27230
    },
    {
      "epoch": 2.918675666988107,
      "grad_norm": 18.574378967285156,
      "learning_rate": 1.4162648666023789e-05,
      "loss": 0.2213,
      "step": 27240
    },
    {
      "epoch": 2.919747133826208,
      "grad_norm": 15.61431884765625,
      "learning_rate": 1.4160505732347584e-05,
      "loss": 0.2853,
      "step": 27250
    },
    {
      "epoch": 2.9208186006643095,
      "grad_norm": 4.055777072906494,
      "learning_rate": 1.4158362798671382e-05,
      "loss": 0.3274,
      "step": 27260
    },
    {
      "epoch": 2.9218900675024106,
      "grad_norm": 0.31985145807266235,
      "learning_rate": 1.415621986499518e-05,
      "loss": 0.2848,
      "step": 27270
    },
    {
      "epoch": 2.922961534340512,
      "grad_norm": 0.3214940130710602,
      "learning_rate": 1.4154076931318977e-05,
      "loss": 0.101,
      "step": 27280
    },
    {
      "epoch": 2.9240330011786133,
      "grad_norm": 0.5870598554611206,
      "learning_rate": 1.4151933997642776e-05,
      "loss": 0.0025,
      "step": 27290
    },
    {
      "epoch": 2.925104468016715,
      "grad_norm": 0.08022858947515488,
      "learning_rate": 1.4149791063966571e-05,
      "loss": 0.4764,
      "step": 27300
    },
    {
      "epoch": 2.9261759348548164,
      "grad_norm": 0.07451114058494568,
      "learning_rate": 1.4147648130290369e-05,
      "loss": 0.1577,
      "step": 27310
    },
    {
      "epoch": 2.9272474016929175,
      "grad_norm": 13.6976957321167,
      "learning_rate": 1.4145505196614166e-05,
      "loss": 0.2941,
      "step": 27320
    },
    {
      "epoch": 2.928318868531019,
      "grad_norm": 0.007686603348702192,
      "learning_rate": 1.4143362262937963e-05,
      "loss": 0.5783,
      "step": 27330
    },
    {
      "epoch": 2.92939033536912,
      "grad_norm": 0.2648268938064575,
      "learning_rate": 1.4141219329261759e-05,
      "loss": 0.1783,
      "step": 27340
    },
    {
      "epoch": 2.9304618022072217,
      "grad_norm": 0.051294952630996704,
      "learning_rate": 1.4139076395585558e-05,
      "loss": 0.3753,
      "step": 27350
    },
    {
      "epoch": 2.931533269045323,
      "grad_norm": 0.023213058710098267,
      "learning_rate": 1.4136933461909355e-05,
      "loss": 0.2736,
      "step": 27360
    },
    {
      "epoch": 2.9326047358834244,
      "grad_norm": 0.05279270187020302,
      "learning_rate": 1.4134790528233153e-05,
      "loss": 0.0035,
      "step": 27370
    },
    {
      "epoch": 2.933676202721526,
      "grad_norm": 0.017847472801804543,
      "learning_rate": 1.413264759455695e-05,
      "loss": 0.3206,
      "step": 27380
    },
    {
      "epoch": 2.934747669559627,
      "grad_norm": 0.06535273045301437,
      "learning_rate": 1.4130504660880746e-05,
      "loss": 0.2911,
      "step": 27390
    },
    {
      "epoch": 2.9358191363977286,
      "grad_norm": 6.418310165405273,
      "learning_rate": 1.4128361727204545e-05,
      "loss": 0.4298,
      "step": 27400
    },
    {
      "epoch": 2.9368906032358297,
      "grad_norm": 0.006609516218304634,
      "learning_rate": 1.412621879352834e-05,
      "loss": 0.0408,
      "step": 27410
    },
    {
      "epoch": 2.9379620700739313,
      "grad_norm": 0.021479977294802666,
      "learning_rate": 1.4124075859852138e-05,
      "loss": 0.1273,
      "step": 27420
    },
    {
      "epoch": 2.9390335369120324,
      "grad_norm": 14.09456729888916,
      "learning_rate": 1.4121932926175937e-05,
      "loss": 0.2882,
      "step": 27430
    },
    {
      "epoch": 2.940105003750134,
      "grad_norm": 42.37127685546875,
      "learning_rate": 1.4119789992499733e-05,
      "loss": 0.7252,
      "step": 27440
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.09954769164323807,
      "learning_rate": 1.4117647058823532e-05,
      "loss": 0.0057,
      "step": 27450
    },
    {
      "epoch": 2.9422479374263366,
      "grad_norm": 0.14573493599891663,
      "learning_rate": 1.4115504125147327e-05,
      "loss": 0.5785,
      "step": 27460
    },
    {
      "epoch": 2.943319404264438,
      "grad_norm": 0.18299436569213867,
      "learning_rate": 1.4113361191471125e-05,
      "loss": 0.2385,
      "step": 27470
    },
    {
      "epoch": 2.9443908711025393,
      "grad_norm": 61.0283088684082,
      "learning_rate": 1.4111218257794924e-05,
      "loss": 0.4094,
      "step": 27480
    },
    {
      "epoch": 2.945462337940641,
      "grad_norm": 64.75737762451172,
      "learning_rate": 1.410907532411872e-05,
      "loss": 0.4182,
      "step": 27490
    },
    {
      "epoch": 2.946533804778742,
      "grad_norm": 0.04307003319263458,
      "learning_rate": 1.4106932390442517e-05,
      "loss": 0.1853,
      "step": 27500
    },
    {
      "epoch": 2.9476052716168435,
      "grad_norm": 0.12686766684055328,
      "learning_rate": 1.4104789456766314e-05,
      "loss": 0.0022,
      "step": 27510
    },
    {
      "epoch": 2.948676738454945,
      "grad_norm": 0.010427896864712238,
      "learning_rate": 1.4102646523090111e-05,
      "loss": 0.4536,
      "step": 27520
    },
    {
      "epoch": 2.949748205293046,
      "grad_norm": 0.9290507435798645,
      "learning_rate": 1.410050358941391e-05,
      "loss": 0.8796,
      "step": 27530
    },
    {
      "epoch": 2.9508196721311473,
      "grad_norm": 0.33167073130607605,
      "learning_rate": 1.4098360655737706e-05,
      "loss": 0.0042,
      "step": 27540
    },
    {
      "epoch": 2.951891138969249,
      "grad_norm": 0.10190491378307343,
      "learning_rate": 1.4096217722061503e-05,
      "loss": 0.1735,
      "step": 27550
    },
    {
      "epoch": 2.9529626058073504,
      "grad_norm": 0.09181629866361618,
      "learning_rate": 1.40940747883853e-05,
      "loss": 0.0024,
      "step": 27560
    },
    {
      "epoch": 2.9540340726454515,
      "grad_norm": 0.022666316479444504,
      "learning_rate": 1.4091931854709098e-05,
      "loss": 0.0602,
      "step": 27570
    },
    {
      "epoch": 2.955105539483553,
      "grad_norm": 0.12157060205936432,
      "learning_rate": 1.4089788921032894e-05,
      "loss": 0.1927,
      "step": 27580
    },
    {
      "epoch": 2.9561770063216546,
      "grad_norm": 0.1753089278936386,
      "learning_rate": 1.4087645987356693e-05,
      "loss": 0.1114,
      "step": 27590
    },
    {
      "epoch": 2.9572484731597557,
      "grad_norm": 0.011662114411592484,
      "learning_rate": 1.4085503053680489e-05,
      "loss": 0.5074,
      "step": 27600
    },
    {
      "epoch": 2.958319939997857,
      "grad_norm": 0.09410210698843002,
      "learning_rate": 1.4083360120004288e-05,
      "loss": 0.6307,
      "step": 27610
    },
    {
      "epoch": 2.9593914068359584,
      "grad_norm": 97.25836181640625,
      "learning_rate": 1.4081217186328085e-05,
      "loss": 0.1589,
      "step": 27620
    },
    {
      "epoch": 2.96046287367406,
      "grad_norm": 0.025255238637328148,
      "learning_rate": 1.407907425265188e-05,
      "loss": 0.2687,
      "step": 27630
    },
    {
      "epoch": 2.961534340512161,
      "grad_norm": 0.11405142396688461,
      "learning_rate": 1.407693131897568e-05,
      "loss": 0.6005,
      "step": 27640
    },
    {
      "epoch": 2.9626058073502626,
      "grad_norm": 0.1225554347038269,
      "learning_rate": 1.4074788385299475e-05,
      "loss": 0.1727,
      "step": 27650
    },
    {
      "epoch": 2.963677274188364,
      "grad_norm": 0.2187056690454483,
      "learning_rate": 1.4072645451623273e-05,
      "loss": 0.3065,
      "step": 27660
    },
    {
      "epoch": 2.9647487410264652,
      "grad_norm": 94.01008605957031,
      "learning_rate": 1.4070502517947072e-05,
      "loss": 0.3586,
      "step": 27670
    },
    {
      "epoch": 2.9658202078645663,
      "grad_norm": 0.17693600058555603,
      "learning_rate": 1.4068359584270867e-05,
      "loss": 0.3066,
      "step": 27680
    },
    {
      "epoch": 2.966891674702668,
      "grad_norm": 13.204804420471191,
      "learning_rate": 1.4066216650594666e-05,
      "loss": 0.9758,
      "step": 27690
    },
    {
      "epoch": 2.9679631415407695,
      "grad_norm": 0.19749704003334045,
      "learning_rate": 1.4064073716918462e-05,
      "loss": 0.3527,
      "step": 27700
    },
    {
      "epoch": 2.9690346083788706,
      "grad_norm": 0.5374606251716614,
      "learning_rate": 1.406193078324226e-05,
      "loss": 0.1902,
      "step": 27710
    },
    {
      "epoch": 2.970106075216972,
      "grad_norm": 0.042110614478588104,
      "learning_rate": 1.4059787849566058e-05,
      "loss": 0.3227,
      "step": 27720
    },
    {
      "epoch": 2.9711775420550737,
      "grad_norm": 7.250805854797363,
      "learning_rate": 1.4057644915889854e-05,
      "loss": 0.0099,
      "step": 27730
    },
    {
      "epoch": 2.972249008893175,
      "grad_norm": 13.622854232788086,
      "learning_rate": 1.4055501982213651e-05,
      "loss": 0.1457,
      "step": 27740
    },
    {
      "epoch": 2.973320475731276,
      "grad_norm": 0.1928538680076599,
      "learning_rate": 1.4053359048537449e-05,
      "loss": 0.2207,
      "step": 27750
    },
    {
      "epoch": 2.9743919425693774,
      "grad_norm": 1.934726357460022,
      "learning_rate": 1.4051216114861246e-05,
      "loss": 0.3903,
      "step": 27760
    },
    {
      "epoch": 2.975463409407479,
      "grad_norm": 70.32998657226562,
      "learning_rate": 1.4049073181185045e-05,
      "loss": 0.071,
      "step": 27770
    },
    {
      "epoch": 2.97653487624558,
      "grad_norm": 0.26007694005966187,
      "learning_rate": 1.4046930247508841e-05,
      "loss": 0.1633,
      "step": 27780
    },
    {
      "epoch": 2.9776063430836817,
      "grad_norm": 0.32367780804634094,
      "learning_rate": 1.4044787313832637e-05,
      "loss": 0.204,
      "step": 27790
    },
    {
      "epoch": 2.9786778099217828,
      "grad_norm": 39.65719223022461,
      "learning_rate": 1.4042644380156436e-05,
      "loss": 0.7304,
      "step": 27800
    },
    {
      "epoch": 2.9797492767598843,
      "grad_norm": 21.449926376342773,
      "learning_rate": 1.4040501446480233e-05,
      "loss": 0.6342,
      "step": 27810
    },
    {
      "epoch": 2.9808207435979854,
      "grad_norm": 0.04362252354621887,
      "learning_rate": 1.4038358512804029e-05,
      "loss": 0.4864,
      "step": 27820
    },
    {
      "epoch": 2.981892210436087,
      "grad_norm": 0.18488465249538422,
      "learning_rate": 1.4036215579127828e-05,
      "loss": 0.1193,
      "step": 27830
    },
    {
      "epoch": 2.9829636772741885,
      "grad_norm": 0.06537365168333054,
      "learning_rate": 1.4034072645451623e-05,
      "loss": 0.3474,
      "step": 27840
    },
    {
      "epoch": 2.9840351441122897,
      "grad_norm": 0.01518284808844328,
      "learning_rate": 1.4031929711775422e-05,
      "loss": 0.2067,
      "step": 27850
    },
    {
      "epoch": 2.985106610950391,
      "grad_norm": 0.28062376379966736,
      "learning_rate": 1.402978677809922e-05,
      "loss": 0.2073,
      "step": 27860
    },
    {
      "epoch": 2.9861780777884923,
      "grad_norm": 0.12075379490852356,
      "learning_rate": 1.4027643844423015e-05,
      "loss": 0.1693,
      "step": 27870
    },
    {
      "epoch": 2.987249544626594,
      "grad_norm": 0.08151305466890335,
      "learning_rate": 1.4025500910746814e-05,
      "loss": 0.0029,
      "step": 27880
    },
    {
      "epoch": 2.988321011464695,
      "grad_norm": 0.013742128387093544,
      "learning_rate": 1.402335797707061e-05,
      "loss": 0.1563,
      "step": 27890
    },
    {
      "epoch": 2.9893924783027965,
      "grad_norm": 0.09522393345832825,
      "learning_rate": 1.4021215043394407e-05,
      "loss": 0.0019,
      "step": 27900
    },
    {
      "epoch": 2.990463945140898,
      "grad_norm": 0.13890190422534943,
      "learning_rate": 1.4019072109718207e-05,
      "loss": 1.368,
      "step": 27910
    },
    {
      "epoch": 2.991535411978999,
      "grad_norm": 21.005191802978516,
      "learning_rate": 1.4016929176042002e-05,
      "loss": 0.2419,
      "step": 27920
    },
    {
      "epoch": 2.9926068788171007,
      "grad_norm": 0.20856578648090363,
      "learning_rate": 1.4014786242365801e-05,
      "loss": 0.3147,
      "step": 27930
    },
    {
      "epoch": 2.993678345655202,
      "grad_norm": 0.015532156452536583,
      "learning_rate": 1.4012643308689597e-05,
      "loss": 0.3759,
      "step": 27940
    },
    {
      "epoch": 2.9947498124933034,
      "grad_norm": 0.12538863718509674,
      "learning_rate": 1.4010500375013394e-05,
      "loss": 0.0427,
      "step": 27950
    },
    {
      "epoch": 2.9958212793314045,
      "grad_norm": 0.1333761215209961,
      "learning_rate": 1.4008357441337193e-05,
      "loss": 0.5475,
      "step": 27960
    },
    {
      "epoch": 2.996892746169506,
      "grad_norm": 0.00752566521987319,
      "learning_rate": 1.4006214507660989e-05,
      "loss": 0.2349,
      "step": 27970
    },
    {
      "epoch": 2.9979642130076076,
      "grad_norm": 0.010881234891712666,
      "learning_rate": 1.4004071573984785e-05,
      "loss": 0.1774,
      "step": 27980
    },
    {
      "epoch": 2.9990356798457087,
      "grad_norm": 0.15458112955093384,
      "learning_rate": 1.4001928640308584e-05,
      "loss": 0.3485,
      "step": 27990
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9263333333333333,
      "eval_f1": 0.8068181818181818,
      "eval_loss": 0.34491556882858276,
      "eval_precision": 0.8211743772241993,
      "eval_recall": 0.7929553264604811,
      "eval_runtime": 698.3567,
      "eval_samples_per_second": 8.592,
      "eval_steps_per_second": 2.864,
      "step": 27999
    },
    {
      "epoch": 3.0001071466838103,
      "grad_norm": 24.42762565612793,
      "learning_rate": 1.3999785706632381e-05,
      "loss": 0.7786,
      "step": 28000
    },
    {
      "epoch": 3.0011786135219114,
      "grad_norm": 0.07332127541303635,
      "learning_rate": 1.3997642772956178e-05,
      "loss": 0.0024,
      "step": 28010
    },
    {
      "epoch": 3.002250080360013,
      "grad_norm": 29.473325729370117,
      "learning_rate": 1.3995499839279976e-05,
      "loss": 0.1556,
      "step": 28020
    },
    {
      "epoch": 3.003321547198114,
      "grad_norm": 0.025294482707977295,
      "learning_rate": 1.3993356905603771e-05,
      "loss": 0.0034,
      "step": 28030
    },
    {
      "epoch": 3.0043930140362156,
      "grad_norm": 0.029303625226020813,
      "learning_rate": 1.399121397192757e-05,
      "loss": 0.1473,
      "step": 28040
    },
    {
      "epoch": 3.0054644808743167,
      "grad_norm": 0.13629956543445587,
      "learning_rate": 1.3989071038251368e-05,
      "loss": 0.213,
      "step": 28050
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 13.859721183776855,
      "learning_rate": 1.3986928104575163e-05,
      "loss": 0.1926,
      "step": 28060
    },
    {
      "epoch": 3.00760741455052,
      "grad_norm": 0.004484734497964382,
      "learning_rate": 1.3984785170898963e-05,
      "loss": 0.0048,
      "step": 28070
    },
    {
      "epoch": 3.008678881388621,
      "grad_norm": 0.30314508080482483,
      "learning_rate": 1.3982642237222758e-05,
      "loss": 0.3887,
      "step": 28080
    },
    {
      "epoch": 3.0097503482267225,
      "grad_norm": 0.23658210039138794,
      "learning_rate": 1.3980499303546556e-05,
      "loss": 0.7607,
      "step": 28090
    },
    {
      "epoch": 3.0108218150648236,
      "grad_norm": 14.609187126159668,
      "learning_rate": 1.3978356369870355e-05,
      "loss": 0.3268,
      "step": 28100
    },
    {
      "epoch": 3.011893281902925,
      "grad_norm": 0.31028440594673157,
      "learning_rate": 1.397621343619415e-05,
      "loss": 0.0034,
      "step": 28110
    },
    {
      "epoch": 3.0129647487410263,
      "grad_norm": 0.017198346555233,
      "learning_rate": 1.397407050251795e-05,
      "loss": 0.4528,
      "step": 28120
    },
    {
      "epoch": 3.014036215579128,
      "grad_norm": 0.26721668243408203,
      "learning_rate": 1.3971927568841745e-05,
      "loss": 0.2503,
      "step": 28130
    },
    {
      "epoch": 3.0151076824172294,
      "grad_norm": 0.24067705869674683,
      "learning_rate": 1.3969784635165542e-05,
      "loss": 0.1483,
      "step": 28140
    },
    {
      "epoch": 3.0161791492553305,
      "grad_norm": 0.13044211268424988,
      "learning_rate": 1.3967641701489341e-05,
      "loss": 0.1754,
      "step": 28150
    },
    {
      "epoch": 3.017250616093432,
      "grad_norm": 0.0053189839236438274,
      "learning_rate": 1.3965498767813137e-05,
      "loss": 0.0045,
      "step": 28160
    },
    {
      "epoch": 3.018322082931533,
      "grad_norm": 0.06481461226940155,
      "learning_rate": 1.3963355834136933e-05,
      "loss": 0.374,
      "step": 28170
    },
    {
      "epoch": 3.0193935497696347,
      "grad_norm": 0.10026448220014572,
      "learning_rate": 1.3961212900460732e-05,
      "loss": 0.2292,
      "step": 28180
    },
    {
      "epoch": 3.020465016607736,
      "grad_norm": 0.14036977291107178,
      "learning_rate": 1.3959069966784529e-05,
      "loss": 0.1087,
      "step": 28190
    },
    {
      "epoch": 3.0215364834458374,
      "grad_norm": 14.020126342773438,
      "learning_rate": 1.3956927033108326e-05,
      "loss": 0.3058,
      "step": 28200
    },
    {
      "epoch": 3.022607950283939,
      "grad_norm": 0.0034784991294145584,
      "learning_rate": 1.3954784099432124e-05,
      "loss": 0.4537,
      "step": 28210
    },
    {
      "epoch": 3.02367941712204,
      "grad_norm": 13.496305465698242,
      "learning_rate": 1.395264116575592e-05,
      "loss": 0.3634,
      "step": 28220
    },
    {
      "epoch": 3.0247508839601416,
      "grad_norm": 0.16481821238994598,
      "learning_rate": 1.3950498232079719e-05,
      "loss": 0.8704,
      "step": 28230
    },
    {
      "epoch": 3.0258223507982427,
      "grad_norm": 0.21083052456378937,
      "learning_rate": 1.3948355298403516e-05,
      "loss": 0.3071,
      "step": 28240
    },
    {
      "epoch": 3.0268938176363442,
      "grad_norm": 0.030987869948148727,
      "learning_rate": 1.3946212364727312e-05,
      "loss": 0.1639,
      "step": 28250
    },
    {
      "epoch": 3.0279652844744454,
      "grad_norm": 0.411310613155365,
      "learning_rate": 1.394406943105111e-05,
      "loss": 0.0204,
      "step": 28260
    },
    {
      "epoch": 3.029036751312547,
      "grad_norm": 26.015884399414062,
      "learning_rate": 1.3941926497374906e-05,
      "loss": 0.501,
      "step": 28270
    },
    {
      "epoch": 3.030108218150648,
      "grad_norm": 0.3652585744857788,
      "learning_rate": 1.3939783563698705e-05,
      "loss": 0.393,
      "step": 28280
    },
    {
      "epoch": 3.0311796849887496,
      "grad_norm": 0.08437037467956543,
      "learning_rate": 1.3937640630022503e-05,
      "loss": 0.18,
      "step": 28290
    },
    {
      "epoch": 3.032251151826851,
      "grad_norm": 0.05941764637827873,
      "learning_rate": 1.3935497696346298e-05,
      "loss": 0.4733,
      "step": 28300
    },
    {
      "epoch": 3.0333226186649522,
      "grad_norm": 0.12373711168766022,
      "learning_rate": 1.3933354762670097e-05,
      "loss": 0.2588,
      "step": 28310
    },
    {
      "epoch": 3.034394085503054,
      "grad_norm": 0.09940597414970398,
      "learning_rate": 1.3931211828993893e-05,
      "loss": 0.1182,
      "step": 28320
    },
    {
      "epoch": 3.035465552341155,
      "grad_norm": 18.721162796020508,
      "learning_rate": 1.392906889531769e-05,
      "loss": 0.3283,
      "step": 28330
    },
    {
      "epoch": 3.0365370191792564,
      "grad_norm": 0.010390081442892551,
      "learning_rate": 1.392692596164149e-05,
      "loss": 0.0039,
      "step": 28340
    },
    {
      "epoch": 3.0376084860173576,
      "grad_norm": 0.3253990113735199,
      "learning_rate": 1.3924783027965285e-05,
      "loss": 0.148,
      "step": 28350
    },
    {
      "epoch": 3.038679952855459,
      "grad_norm": 0.09165848046541214,
      "learning_rate": 1.3922640094289084e-05,
      "loss": 0.0146,
      "step": 28360
    },
    {
      "epoch": 3.0397514196935607,
      "grad_norm": 40.60036087036133,
      "learning_rate": 1.392049716061288e-05,
      "loss": 0.3389,
      "step": 28370
    },
    {
      "epoch": 3.0408228865316618,
      "grad_norm": 15.967642784118652,
      "learning_rate": 1.3918354226936677e-05,
      "loss": 0.1655,
      "step": 28380
    },
    {
      "epoch": 3.0418943533697633,
      "grad_norm": 70.8131332397461,
      "learning_rate": 1.3916211293260475e-05,
      "loss": 0.4524,
      "step": 28390
    },
    {
      "epoch": 3.0429658202078644,
      "grad_norm": 61.16053009033203,
      "learning_rate": 1.3914068359584272e-05,
      "loss": 0.1893,
      "step": 28400
    },
    {
      "epoch": 3.044037287045966,
      "grad_norm": 0.003224694635719061,
      "learning_rate": 1.3911925425908068e-05,
      "loss": 0.1348,
      "step": 28410
    },
    {
      "epoch": 3.045108753884067,
      "grad_norm": 4.577705383300781,
      "learning_rate": 1.3909782492231867e-05,
      "loss": 0.0842,
      "step": 28420
    },
    {
      "epoch": 3.0461802207221687,
      "grad_norm": 0.098808653652668,
      "learning_rate": 1.3907639558555664e-05,
      "loss": 0.1393,
      "step": 28430
    },
    {
      "epoch": 3.04725168756027,
      "grad_norm": 41.64887619018555,
      "learning_rate": 1.3905496624879461e-05,
      "loss": 0.1663,
      "step": 28440
    },
    {
      "epoch": 3.0483231543983713,
      "grad_norm": 0.015527896583080292,
      "learning_rate": 1.3903353691203259e-05,
      "loss": 0.0005,
      "step": 28450
    },
    {
      "epoch": 3.049394621236473,
      "grad_norm": 0.19593991339206696,
      "learning_rate": 1.3901210757527054e-05,
      "loss": 0.3408,
      "step": 28460
    },
    {
      "epoch": 3.050466088074574,
      "grad_norm": 190.95889282226562,
      "learning_rate": 1.3899067823850853e-05,
      "loss": 0.2705,
      "step": 28470
    },
    {
      "epoch": 3.0515375549126755,
      "grad_norm": 0.10469950735569,
      "learning_rate": 1.389692489017465e-05,
      "loss": 0.1657,
      "step": 28480
    },
    {
      "epoch": 3.0526090217507766,
      "grad_norm": 14.17922592163086,
      "learning_rate": 1.3894781956498446e-05,
      "loss": 0.6975,
      "step": 28490
    },
    {
      "epoch": 3.053680488588878,
      "grad_norm": 0.5646740198135376,
      "learning_rate": 1.3892639022822245e-05,
      "loss": 0.3642,
      "step": 28500
    },
    {
      "epoch": 3.0547519554269797,
      "grad_norm": 0.12303601205348969,
      "learning_rate": 1.3890496089146041e-05,
      "loss": 0.0072,
      "step": 28510
    },
    {
      "epoch": 3.055823422265081,
      "grad_norm": 0.218131884932518,
      "learning_rate": 1.388835315546984e-05,
      "loss": 0.2377,
      "step": 28520
    },
    {
      "epoch": 3.0568948891031824,
      "grad_norm": 0.10266504436731339,
      "learning_rate": 1.3886210221793638e-05,
      "loss": 0.1458,
      "step": 28530
    },
    {
      "epoch": 3.0579663559412835,
      "grad_norm": 0.19181357324123383,
      "learning_rate": 1.3884067288117433e-05,
      "loss": 0.2584,
      "step": 28540
    },
    {
      "epoch": 3.059037822779385,
      "grad_norm": 0.0026493356563150883,
      "learning_rate": 1.3881924354441232e-05,
      "loss": 0.389,
      "step": 28550
    },
    {
      "epoch": 3.060109289617486,
      "grad_norm": 0.04326494783163071,
      "learning_rate": 1.3879781420765028e-05,
      "loss": 0.002,
      "step": 28560
    },
    {
      "epoch": 3.0611807564555877,
      "grad_norm": 0.4749000072479248,
      "learning_rate": 1.3877638487088825e-05,
      "loss": 0.119,
      "step": 28570
    },
    {
      "epoch": 3.062252223293689,
      "grad_norm": 17.7807674407959,
      "learning_rate": 1.3875495553412623e-05,
      "loss": 0.1824,
      "step": 28580
    },
    {
      "epoch": 3.0633236901317904,
      "grad_norm": 0.154176726937294,
      "learning_rate": 1.387335261973642e-05,
      "loss": 0.1574,
      "step": 28590
    },
    {
      "epoch": 3.064395156969892,
      "grad_norm": 56.94939422607422,
      "learning_rate": 1.3871209686060219e-05,
      "loss": 0.7409,
      "step": 28600
    },
    {
      "epoch": 3.065466623807993,
      "grad_norm": 0.014964455738663673,
      "learning_rate": 1.3869066752384015e-05,
      "loss": 0.3131,
      "step": 28610
    },
    {
      "epoch": 3.0665380906460946,
      "grad_norm": 0.7579765319824219,
      "learning_rate": 1.3866923818707812e-05,
      "loss": 0.2548,
      "step": 28620
    },
    {
      "epoch": 3.0676095574841957,
      "grad_norm": 0.12107136100530624,
      "learning_rate": 1.386478088503161e-05,
      "loss": 0.1665,
      "step": 28630
    },
    {
      "epoch": 3.0686810243222973,
      "grad_norm": 40.94995880126953,
      "learning_rate": 1.3862637951355407e-05,
      "loss": 0.4649,
      "step": 28640
    },
    {
      "epoch": 3.0697524911603984,
      "grad_norm": 0.00655336445197463,
      "learning_rate": 1.3860495017679202e-05,
      "loss": 0.1797,
      "step": 28650
    },
    {
      "epoch": 3.0708239579985,
      "grad_norm": 0.0942346528172493,
      "learning_rate": 1.3858352084003001e-05,
      "loss": 0.7074,
      "step": 28660
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 0.9520334005355835,
      "learning_rate": 1.3856209150326799e-05,
      "loss": 0.311,
      "step": 28670
    },
    {
      "epoch": 3.0729668916747026,
      "grad_norm": 0.07552701979875565,
      "learning_rate": 1.3854066216650596e-05,
      "loss": 0.1829,
      "step": 28680
    },
    {
      "epoch": 3.074038358512804,
      "grad_norm": 0.04309917986392975,
      "learning_rate": 1.3851923282974394e-05,
      "loss": 0.0027,
      "step": 28690
    },
    {
      "epoch": 3.0751098253509053,
      "grad_norm": 0.020251624286174774,
      "learning_rate": 1.384978034929819e-05,
      "loss": 0.3478,
      "step": 28700
    },
    {
      "epoch": 3.076181292189007,
      "grad_norm": 0.02398846484720707,
      "learning_rate": 1.3847637415621988e-05,
      "loss": 0.5249,
      "step": 28710
    },
    {
      "epoch": 3.077252759027108,
      "grad_norm": 0.03165015950798988,
      "learning_rate": 1.3845494481945786e-05,
      "loss": 0.0008,
      "step": 28720
    },
    {
      "epoch": 3.0783242258652095,
      "grad_norm": 0.10369553416967392,
      "learning_rate": 1.3843351548269581e-05,
      "loss": 0.0019,
      "step": 28730
    },
    {
      "epoch": 3.079395692703311,
      "grad_norm": 0.14360515773296356,
      "learning_rate": 1.384120861459338e-05,
      "loss": 0.5472,
      "step": 28740
    },
    {
      "epoch": 3.080467159541412,
      "grad_norm": 0.03411858156323433,
      "learning_rate": 1.3839065680917176e-05,
      "loss": 0.4786,
      "step": 28750
    },
    {
      "epoch": 3.0815386263795137,
      "grad_norm": 0.053489021956920624,
      "learning_rate": 1.3836922747240975e-05,
      "loss": 0.5305,
      "step": 28760
    },
    {
      "epoch": 3.082610093217615,
      "grad_norm": 0.16458359360694885,
      "learning_rate": 1.383477981356477e-05,
      "loss": 0.005,
      "step": 28770
    },
    {
      "epoch": 3.0836815600557164,
      "grad_norm": 0.11320361495018005,
      "learning_rate": 1.3832636879888568e-05,
      "loss": 0.0224,
      "step": 28780
    },
    {
      "epoch": 3.0847530268938175,
      "grad_norm": 0.024264279752969742,
      "learning_rate": 1.3830493946212367e-05,
      "loss": 0.3036,
      "step": 28790
    },
    {
      "epoch": 3.085824493731919,
      "grad_norm": 0.2840575575828552,
      "learning_rate": 1.3828351012536163e-05,
      "loss": 0.0039,
      "step": 28800
    },
    {
      "epoch": 3.08689596057002,
      "grad_norm": 0.04387146234512329,
      "learning_rate": 1.382620807885996e-05,
      "loss": 0.0077,
      "step": 28810
    },
    {
      "epoch": 3.0879674274081217,
      "grad_norm": 0.0733722448348999,
      "learning_rate": 1.3824065145183757e-05,
      "loss": 0.1011,
      "step": 28820
    },
    {
      "epoch": 3.0890388942462232,
      "grad_norm": 0.09939439594745636,
      "learning_rate": 1.3821922211507555e-05,
      "loss": 0.5256,
      "step": 28830
    },
    {
      "epoch": 3.0901103610843244,
      "grad_norm": 0.056037891656160355,
      "learning_rate": 1.3819779277831354e-05,
      "loss": 0.4247,
      "step": 28840
    },
    {
      "epoch": 3.091181827922426,
      "grad_norm": 27.561323165893555,
      "learning_rate": 1.381763634415515e-05,
      "loss": 0.4617,
      "step": 28850
    },
    {
      "epoch": 3.092253294760527,
      "grad_norm": 0.06652607768774033,
      "learning_rate": 1.3815493410478947e-05,
      "loss": 0.3147,
      "step": 28860
    },
    {
      "epoch": 3.0933247615986286,
      "grad_norm": 0.06685911864042282,
      "learning_rate": 1.3813350476802744e-05,
      "loss": 0.1673,
      "step": 28870
    },
    {
      "epoch": 3.0943962284367297,
      "grad_norm": 37.88145065307617,
      "learning_rate": 1.3811207543126542e-05,
      "loss": 0.367,
      "step": 28880
    },
    {
      "epoch": 3.0954676952748312,
      "grad_norm": 0.11849866062402725,
      "learning_rate": 1.3809064609450337e-05,
      "loss": 0.1528,
      "step": 28890
    },
    {
      "epoch": 3.096539162112933,
      "grad_norm": 0.00684363953769207,
      "learning_rate": 1.3806921675774136e-05,
      "loss": 0.3057,
      "step": 28900
    },
    {
      "epoch": 3.097610628951034,
      "grad_norm": 2.2882988452911377,
      "learning_rate": 1.3804778742097934e-05,
      "loss": 0.3455,
      "step": 28910
    },
    {
      "epoch": 3.0986820957891354,
      "grad_norm": 0.07922319322824478,
      "learning_rate": 1.3802635808421731e-05,
      "loss": 0.2094,
      "step": 28920
    },
    {
      "epoch": 3.0997535626272366,
      "grad_norm": 0.022527625784277916,
      "learning_rate": 1.3800492874745528e-05,
      "loss": 0.3892,
      "step": 28930
    },
    {
      "epoch": 3.100825029465338,
      "grad_norm": 38.959861755371094,
      "learning_rate": 1.3798349941069324e-05,
      "loss": 0.6851,
      "step": 28940
    },
    {
      "epoch": 3.101896496303439,
      "grad_norm": 0.3034279942512512,
      "learning_rate": 1.3796207007393123e-05,
      "loss": 0.0678,
      "step": 28950
    },
    {
      "epoch": 3.1029679631415408,
      "grad_norm": 0.5052496790885925,
      "learning_rate": 1.3794064073716919e-05,
      "loss": 0.0057,
      "step": 28960
    },
    {
      "epoch": 3.1040394299796423,
      "grad_norm": 0.09539734572172165,
      "learning_rate": 1.3791921140040716e-05,
      "loss": 0.0242,
      "step": 28970
    },
    {
      "epoch": 3.1051108968177434,
      "grad_norm": 0.14866675436496735,
      "learning_rate": 1.3789778206364515e-05,
      "loss": 0.0029,
      "step": 28980
    },
    {
      "epoch": 3.106182363655845,
      "grad_norm": 0.18202586472034454,
      "learning_rate": 1.378763527268831e-05,
      "loss": 0.1864,
      "step": 28990
    },
    {
      "epoch": 3.107253830493946,
      "grad_norm": 0.7965970039367676,
      "learning_rate": 1.3785492339012108e-05,
      "loss": 0.243,
      "step": 29000
    },
    {
      "epoch": 3.1083252973320477,
      "grad_norm": 0.010038862936198711,
      "learning_rate": 1.3783349405335906e-05,
      "loss": 0.4764,
      "step": 29010
    },
    {
      "epoch": 3.1093967641701488,
      "grad_norm": 0.33850401639938354,
      "learning_rate": 1.3781206471659703e-05,
      "loss": 0.4,
      "step": 29020
    },
    {
      "epoch": 3.1104682310082503,
      "grad_norm": 0.24765829741954803,
      "learning_rate": 1.3779063537983502e-05,
      "loss": 0.0033,
      "step": 29030
    },
    {
      "epoch": 3.111539697846352,
      "grad_norm": 0.11948933452367783,
      "learning_rate": 1.3776920604307298e-05,
      "loss": 0.4404,
      "step": 29040
    },
    {
      "epoch": 3.112611164684453,
      "grad_norm": 14.928407669067383,
      "learning_rate": 1.3774777670631095e-05,
      "loss": 0.1811,
      "step": 29050
    },
    {
      "epoch": 3.1136826315225545,
      "grad_norm": 0.1807558536529541,
      "learning_rate": 1.3772634736954892e-05,
      "loss": 0.3013,
      "step": 29060
    },
    {
      "epoch": 3.1147540983606556,
      "grad_norm": 0.0036825696006417274,
      "learning_rate": 1.377049180327869e-05,
      "loss": 0.1268,
      "step": 29070
    },
    {
      "epoch": 3.115825565198757,
      "grad_norm": 0.04242313653230667,
      "learning_rate": 1.3768348869602485e-05,
      "loss": 0.3228,
      "step": 29080
    },
    {
      "epoch": 3.1168970320368583,
      "grad_norm": 66.11742401123047,
      "learning_rate": 1.3766205935926284e-05,
      "loss": 0.1468,
      "step": 29090
    },
    {
      "epoch": 3.11796849887496,
      "grad_norm": 5.658865928649902,
      "learning_rate": 1.3764063002250082e-05,
      "loss": 0.0047,
      "step": 29100
    },
    {
      "epoch": 3.119039965713061,
      "grad_norm": 0.007991686463356018,
      "learning_rate": 1.3761920068573879e-05,
      "loss": 0.1847,
      "step": 29110
    },
    {
      "epoch": 3.1201114325511625,
      "grad_norm": 0.0024239704944193363,
      "learning_rate": 1.3759777134897676e-05,
      "loss": 0.0013,
      "step": 29120
    },
    {
      "epoch": 3.121182899389264,
      "grad_norm": 0.05555775389075279,
      "learning_rate": 1.3757634201221472e-05,
      "loss": 0.3113,
      "step": 29130
    },
    {
      "epoch": 3.122254366227365,
      "grad_norm": 0.07053980976343155,
      "learning_rate": 1.3755491267545271e-05,
      "loss": 0.0018,
      "step": 29140
    },
    {
      "epoch": 3.1233258330654667,
      "grad_norm": 1.310497760772705,
      "learning_rate": 1.3753348333869067e-05,
      "loss": 0.0017,
      "step": 29150
    },
    {
      "epoch": 3.124397299903568,
      "grad_norm": 0.16545206308364868,
      "learning_rate": 1.3751205400192864e-05,
      "loss": 0.4456,
      "step": 29160
    },
    {
      "epoch": 3.1254687667416694,
      "grad_norm": 0.005667822435498238,
      "learning_rate": 1.3749062466516663e-05,
      "loss": 0.0029,
      "step": 29170
    },
    {
      "epoch": 3.1265402335797705,
      "grad_norm": 0.05690665915608406,
      "learning_rate": 1.3746919532840459e-05,
      "loss": 0.6698,
      "step": 29180
    },
    {
      "epoch": 3.127611700417872,
      "grad_norm": 0.2571011483669281,
      "learning_rate": 1.3744776599164258e-05,
      "loss": 0.1269,
      "step": 29190
    },
    {
      "epoch": 3.1286831672559736,
      "grad_norm": 0.010353438556194305,
      "learning_rate": 1.3742633665488054e-05,
      "loss": 0.5276,
      "step": 29200
    },
    {
      "epoch": 3.1297546340940747,
      "grad_norm": 14.928888320922852,
      "learning_rate": 1.3740490731811851e-05,
      "loss": 0.2118,
      "step": 29210
    },
    {
      "epoch": 3.1308261009321763,
      "grad_norm": 0.24579548835754395,
      "learning_rate": 1.373834779813565e-05,
      "loss": 0.0929,
      "step": 29220
    },
    {
      "epoch": 3.1318975677702774,
      "grad_norm": 0.16102202236652374,
      "learning_rate": 1.3736204864459446e-05,
      "loss": 0.4389,
      "step": 29230
    },
    {
      "epoch": 3.132969034608379,
      "grad_norm": 0.05312098190188408,
      "learning_rate": 1.3734061930783243e-05,
      "loss": 0.6435,
      "step": 29240
    },
    {
      "epoch": 3.13404050144648,
      "grad_norm": 0.03198925033211708,
      "learning_rate": 1.373191899710704e-05,
      "loss": 0.0017,
      "step": 29250
    },
    {
      "epoch": 3.1351119682845816,
      "grad_norm": 0.37209200859069824,
      "learning_rate": 1.3729776063430838e-05,
      "loss": 0.3475,
      "step": 29260
    },
    {
      "epoch": 3.136183435122683,
      "grad_norm": 0.016018187627196312,
      "learning_rate": 1.3727633129754637e-05,
      "loss": 0.0287,
      "step": 29270
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 0.01327150035649538,
      "learning_rate": 1.3725490196078432e-05,
      "loss": 0.0008,
      "step": 29280
    },
    {
      "epoch": 3.138326368798886,
      "grad_norm": 61.17972946166992,
      "learning_rate": 1.372334726240223e-05,
      "loss": 0.2682,
      "step": 29290
    },
    {
      "epoch": 3.139397835636987,
      "grad_norm": 0.0036715359892696142,
      "learning_rate": 1.3721204328726027e-05,
      "loss": 0.2521,
      "step": 29300
    },
    {
      "epoch": 3.1404693024750885,
      "grad_norm": 0.34734275937080383,
      "learning_rate": 1.3719061395049824e-05,
      "loss": 0.3393,
      "step": 29310
    },
    {
      "epoch": 3.1415407693131896,
      "grad_norm": 0.08130534738302231,
      "learning_rate": 1.371691846137362e-05,
      "loss": 0.492,
      "step": 29320
    },
    {
      "epoch": 3.142612236151291,
      "grad_norm": 0.0636049211025238,
      "learning_rate": 1.371477552769742e-05,
      "loss": 0.1434,
      "step": 29330
    },
    {
      "epoch": 3.1436837029893923,
      "grad_norm": 0.009784119203686714,
      "learning_rate": 1.3712632594021215e-05,
      "loss": 0.2139,
      "step": 29340
    },
    {
      "epoch": 3.144755169827494,
      "grad_norm": 0.0990811288356781,
      "learning_rate": 1.3710489660345014e-05,
      "loss": 0.4631,
      "step": 29350
    },
    {
      "epoch": 3.1458266366655954,
      "grad_norm": 0.27288222312927246,
      "learning_rate": 1.3708346726668811e-05,
      "loss": 0.2097,
      "step": 29360
    },
    {
      "epoch": 3.1468981035036965,
      "grad_norm": 0.00583114568144083,
      "learning_rate": 1.3706203792992607e-05,
      "loss": 0.3282,
      "step": 29370
    },
    {
      "epoch": 3.147969570341798,
      "grad_norm": 0.13746850192546844,
      "learning_rate": 1.3704060859316406e-05,
      "loss": 0.3832,
      "step": 29380
    },
    {
      "epoch": 3.149041037179899,
      "grad_norm": 0.055356331169605255,
      "learning_rate": 1.3701917925640202e-05,
      "loss": 0.2413,
      "step": 29390
    },
    {
      "epoch": 3.1501125040180007,
      "grad_norm": 0.3609202206134796,
      "learning_rate": 1.3699774991963999e-05,
      "loss": 0.177,
      "step": 29400
    },
    {
      "epoch": 3.151183970856102,
      "grad_norm": 0.10855861753225327,
      "learning_rate": 1.3697632058287798e-05,
      "loss": 0.0158,
      "step": 29410
    },
    {
      "epoch": 3.1522554376942034,
      "grad_norm": 0.07198378443717957,
      "learning_rate": 1.3695489124611594e-05,
      "loss": 0.381,
      "step": 29420
    },
    {
      "epoch": 3.153326904532305,
      "grad_norm": 0.06855873018503189,
      "learning_rate": 1.3693346190935393e-05,
      "loss": 0.1178,
      "step": 29430
    },
    {
      "epoch": 3.154398371370406,
      "grad_norm": 14.140266418457031,
      "learning_rate": 1.3691203257259188e-05,
      "loss": 0.4737,
      "step": 29440
    },
    {
      "epoch": 3.1554698382085076,
      "grad_norm": 0.005749616771936417,
      "learning_rate": 1.3689060323582986e-05,
      "loss": 0.3942,
      "step": 29450
    },
    {
      "epoch": 3.1565413050466087,
      "grad_norm": 0.01615091599524021,
      "learning_rate": 1.3686917389906785e-05,
      "loss": 0.468,
      "step": 29460
    },
    {
      "epoch": 3.1576127718847102,
      "grad_norm": 0.00986526533961296,
      "learning_rate": 1.368477445623058e-05,
      "loss": 0.4133,
      "step": 29470
    },
    {
      "epoch": 3.1586842387228113,
      "grad_norm": 0.580370306968689,
      "learning_rate": 1.3682631522554378e-05,
      "loss": 0.0996,
      "step": 29480
    },
    {
      "epoch": 3.159755705560913,
      "grad_norm": 0.008736495859920979,
      "learning_rate": 1.3680488588878175e-05,
      "loss": 0.4578,
      "step": 29490
    },
    {
      "epoch": 3.1608271723990145,
      "grad_norm": 18.42470932006836,
      "learning_rate": 1.3678345655201973e-05,
      "loss": 0.3678,
      "step": 29500
    },
    {
      "epoch": 3.1618986392371156,
      "grad_norm": 0.015620410442352295,
      "learning_rate": 1.3676202721525772e-05,
      "loss": 0.0071,
      "step": 29510
    },
    {
      "epoch": 3.162970106075217,
      "grad_norm": 0.1312238872051239,
      "learning_rate": 1.3674059787849567e-05,
      "loss": 0.1569,
      "step": 29520
    },
    {
      "epoch": 3.1640415729133182,
      "grad_norm": 0.012428640387952328,
      "learning_rate": 1.3671916854173365e-05,
      "loss": 0.0141,
      "step": 29530
    },
    {
      "epoch": 3.1651130397514198,
      "grad_norm": 0.10696196556091309,
      "learning_rate": 1.3669773920497162e-05,
      "loss": 0.1646,
      "step": 29540
    },
    {
      "epoch": 3.166184506589521,
      "grad_norm": 0.08133754134178162,
      "learning_rate": 1.366763098682096e-05,
      "loss": 0.4843,
      "step": 29550
    },
    {
      "epoch": 3.1672559734276224,
      "grad_norm": 0.04489710554480553,
      "learning_rate": 1.3665488053144755e-05,
      "loss": 0.0625,
      "step": 29560
    },
    {
      "epoch": 3.168327440265724,
      "grad_norm": 0.00912658404558897,
      "learning_rate": 1.3663345119468554e-05,
      "loss": 0.0749,
      "step": 29570
    },
    {
      "epoch": 3.169398907103825,
      "grad_norm": 0.007463705725967884,
      "learning_rate": 1.366120218579235e-05,
      "loss": 0.5691,
      "step": 29580
    },
    {
      "epoch": 3.1704703739419267,
      "grad_norm": 61.504207611083984,
      "learning_rate": 1.3659059252116149e-05,
      "loss": 0.0357,
      "step": 29590
    },
    {
      "epoch": 3.1715418407800278,
      "grad_norm": 0.013885223306715488,
      "learning_rate": 1.3656916318439946e-05,
      "loss": 0.0007,
      "step": 29600
    },
    {
      "epoch": 3.1726133076181293,
      "grad_norm": 0.14690256118774414,
      "learning_rate": 1.3654773384763742e-05,
      "loss": 0.1744,
      "step": 29610
    },
    {
      "epoch": 3.1736847744562304,
      "grad_norm": 0.02964642085134983,
      "learning_rate": 1.365263045108754e-05,
      "loss": 0.5812,
      "step": 29620
    },
    {
      "epoch": 3.174756241294332,
      "grad_norm": 0.2715619206428528,
      "learning_rate": 1.3650487517411336e-05,
      "loss": 0.2309,
      "step": 29630
    },
    {
      "epoch": 3.1758277081324335,
      "grad_norm": 0.07740922272205353,
      "learning_rate": 1.3648344583735134e-05,
      "loss": 0.3249,
      "step": 29640
    },
    {
      "epoch": 3.1768991749705346,
      "grad_norm": 0.11469253152608871,
      "learning_rate": 1.3646201650058933e-05,
      "loss": 0.2101,
      "step": 29650
    },
    {
      "epoch": 3.177970641808636,
      "grad_norm": 0.015259256586432457,
      "learning_rate": 1.3644058716382729e-05,
      "loss": 0.184,
      "step": 29660
    },
    {
      "epoch": 3.1790421086467373,
      "grad_norm": 0.5332576632499695,
      "learning_rate": 1.3641915782706528e-05,
      "loss": 0.2419,
      "step": 29670
    },
    {
      "epoch": 3.180113575484839,
      "grad_norm": 0.027464617043733597,
      "learning_rate": 1.3639772849030323e-05,
      "loss": 0.0011,
      "step": 29680
    },
    {
      "epoch": 3.18118504232294,
      "grad_norm": 0.03521594777703285,
      "learning_rate": 1.363762991535412e-05,
      "loss": 0.06,
      "step": 29690
    },
    {
      "epoch": 3.1822565091610415,
      "grad_norm": 0.17149756848812103,
      "learning_rate": 1.363548698167792e-05,
      "loss": 0.0039,
      "step": 29700
    },
    {
      "epoch": 3.1833279759991426,
      "grad_norm": 16.975996017456055,
      "learning_rate": 1.3633344048001715e-05,
      "loss": 0.9217,
      "step": 29710
    },
    {
      "epoch": 3.184399442837244,
      "grad_norm": 0.10099192708730698,
      "learning_rate": 1.3631201114325513e-05,
      "loss": 0.0305,
      "step": 29720
    },
    {
      "epoch": 3.1854709096753457,
      "grad_norm": 0.059801798313856125,
      "learning_rate": 1.362905818064931e-05,
      "loss": 0.3989,
      "step": 29730
    },
    {
      "epoch": 3.186542376513447,
      "grad_norm": 12.386882781982422,
      "learning_rate": 1.3626915246973107e-05,
      "loss": 0.1721,
      "step": 29740
    },
    {
      "epoch": 3.1876138433515484,
      "grad_norm": 0.7579914927482605,
      "learning_rate": 1.3624772313296906e-05,
      "loss": 0.2935,
      "step": 29750
    },
    {
      "epoch": 3.1886853101896495,
      "grad_norm": 0.09952402114868164,
      "learning_rate": 1.3622629379620702e-05,
      "loss": 0.0018,
      "step": 29760
    },
    {
      "epoch": 3.189756777027751,
      "grad_norm": 0.05228776857256889,
      "learning_rate": 1.3620486445944498e-05,
      "loss": 0.1814,
      "step": 29770
    },
    {
      "epoch": 3.190828243865852,
      "grad_norm": 0.050384558737277985,
      "learning_rate": 1.3618343512268297e-05,
      "loss": 0.3105,
      "step": 29780
    },
    {
      "epoch": 3.1918997107039537,
      "grad_norm": 0.14790399372577667,
      "learning_rate": 1.3616200578592094e-05,
      "loss": 0.0023,
      "step": 29790
    },
    {
      "epoch": 3.192971177542055,
      "grad_norm": 47.83246994018555,
      "learning_rate": 1.361405764491589e-05,
      "loss": 0.3009,
      "step": 29800
    },
    {
      "epoch": 3.1940426443801564,
      "grad_norm": 0.007731710560619831,
      "learning_rate": 1.3611914711239689e-05,
      "loss": 0.0016,
      "step": 29810
    },
    {
      "epoch": 3.195114111218258,
      "grad_norm": 0.3815913200378418,
      "learning_rate": 1.3609771777563485e-05,
      "loss": 0.5151,
      "step": 29820
    },
    {
      "epoch": 3.196185578056359,
      "grad_norm": 0.08260291814804077,
      "learning_rate": 1.3607628843887284e-05,
      "loss": 0.0326,
      "step": 29830
    },
    {
      "epoch": 3.1972570448944606,
      "grad_norm": 0.08654295653104782,
      "learning_rate": 1.3605485910211081e-05,
      "loss": 0.0015,
      "step": 29840
    },
    {
      "epoch": 3.1983285117325617,
      "grad_norm": 0.009113850072026253,
      "learning_rate": 1.3603342976534877e-05,
      "loss": 0.2298,
      "step": 29850
    },
    {
      "epoch": 3.1993999785706633,
      "grad_norm": 0.039068374782800674,
      "learning_rate": 1.3601200042858676e-05,
      "loss": 0.2778,
      "step": 29860
    },
    {
      "epoch": 3.2004714454087644,
      "grad_norm": 0.0033288714475929737,
      "learning_rate": 1.3599057109182471e-05,
      "loss": 0.1872,
      "step": 29870
    },
    {
      "epoch": 3.201542912246866,
      "grad_norm": 0.008654830045998096,
      "learning_rate": 1.3596914175506269e-05,
      "loss": 0.4247,
      "step": 29880
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 14.040871620178223,
      "learning_rate": 1.3594771241830068e-05,
      "loss": 0.3916,
      "step": 29890
    },
    {
      "epoch": 3.2036858459230686,
      "grad_norm": 0.02031104825437069,
      "learning_rate": 1.3592628308153863e-05,
      "loss": 0.6854,
      "step": 29900
    },
    {
      "epoch": 3.20475731276117,
      "grad_norm": 0.08642147481441498,
      "learning_rate": 1.359048537447766e-05,
      "loss": 0.4881,
      "step": 29910
    },
    {
      "epoch": 3.2058287795992713,
      "grad_norm": 0.03530179336667061,
      "learning_rate": 1.3588342440801458e-05,
      "loss": 0.0057,
      "step": 29920
    },
    {
      "epoch": 3.206900246437373,
      "grad_norm": 0.07640410959720612,
      "learning_rate": 1.3586199507125255e-05,
      "loss": 0.2077,
      "step": 29930
    },
    {
      "epoch": 3.207971713275474,
      "grad_norm": 0.0365724191069603,
      "learning_rate": 1.3584056573449055e-05,
      "loss": 0.3026,
      "step": 29940
    },
    {
      "epoch": 3.2090431801135755,
      "grad_norm": 0.016133945435285568,
      "learning_rate": 1.358191363977285e-05,
      "loss": 0.3705,
      "step": 29950
    },
    {
      "epoch": 3.210114646951677,
      "grad_norm": 0.026284176856279373,
      "learning_rate": 1.3579770706096646e-05,
      "loss": 0.0228,
      "step": 29960
    },
    {
      "epoch": 3.211186113789778,
      "grad_norm": 0.07508058845996857,
      "learning_rate": 1.3577627772420445e-05,
      "loss": 0.0228,
      "step": 29970
    },
    {
      "epoch": 3.2122575806278797,
      "grad_norm": 0.09686783701181412,
      "learning_rate": 1.3575484838744242e-05,
      "loss": 0.0752,
      "step": 29980
    },
    {
      "epoch": 3.213329047465981,
      "grad_norm": 0.04738554731011391,
      "learning_rate": 1.3573341905068038e-05,
      "loss": 0.3486,
      "step": 29990
    },
    {
      "epoch": 3.2144005143040824,
      "grad_norm": 0.04600108787417412,
      "learning_rate": 1.3571198971391837e-05,
      "loss": 0.0035,
      "step": 30000
    },
    {
      "epoch": 3.2154719811421835,
      "grad_norm": 0.08242727071046829,
      "learning_rate": 1.3569056037715633e-05,
      "loss": 0.0043,
      "step": 30010
    },
    {
      "epoch": 3.216543447980285,
      "grad_norm": 0.007563666440546513,
      "learning_rate": 1.3566913104039432e-05,
      "loss": 0.2844,
      "step": 30020
    },
    {
      "epoch": 3.2176149148183866,
      "grad_norm": 0.008895847015082836,
      "learning_rate": 1.3564770170363229e-05,
      "loss": 0.8268,
      "step": 30030
    },
    {
      "epoch": 3.2186863816564877,
      "grad_norm": 0.016543526202440262,
      "learning_rate": 1.3562627236687025e-05,
      "loss": 0.3486,
      "step": 30040
    },
    {
      "epoch": 3.2197578484945892,
      "grad_norm": 0.07587345689535141,
      "learning_rate": 1.3560484303010824e-05,
      "loss": 0.2026,
      "step": 30050
    },
    {
      "epoch": 3.2208293153326903,
      "grad_norm": 4.755173683166504,
      "learning_rate": 1.355834136933462e-05,
      "loss": 0.1658,
      "step": 30060
    },
    {
      "epoch": 3.221900782170792,
      "grad_norm": 15.617878913879395,
      "learning_rate": 1.3556198435658417e-05,
      "loss": 0.3403,
      "step": 30070
    },
    {
      "epoch": 3.222972249008893,
      "grad_norm": 0.19785109162330627,
      "learning_rate": 1.3554055501982216e-05,
      "loss": 0.0202,
      "step": 30080
    },
    {
      "epoch": 3.2240437158469946,
      "grad_norm": 0.007276381365954876,
      "learning_rate": 1.3551912568306011e-05,
      "loss": 0.0018,
      "step": 30090
    },
    {
      "epoch": 3.225115182685096,
      "grad_norm": 0.018391069024801254,
      "learning_rate": 1.354976963462981e-05,
      "loss": 0.5417,
      "step": 30100
    },
    {
      "epoch": 3.2261866495231972,
      "grad_norm": 0.16642798483371735,
      "learning_rate": 1.3547626700953606e-05,
      "loss": 0.1626,
      "step": 30110
    },
    {
      "epoch": 3.227258116361299,
      "grad_norm": 0.12030286341905594,
      "learning_rate": 1.3545483767277404e-05,
      "loss": 0.001,
      "step": 30120
    },
    {
      "epoch": 3.2283295831994,
      "grad_norm": 0.009657016023993492,
      "learning_rate": 1.3543340833601203e-05,
      "loss": 0.0017,
      "step": 30130
    },
    {
      "epoch": 3.2294010500375014,
      "grad_norm": 0.028405100107192993,
      "learning_rate": 1.3541197899924998e-05,
      "loss": 0.242,
      "step": 30140
    },
    {
      "epoch": 3.2304725168756026,
      "grad_norm": 0.023010622709989548,
      "learning_rate": 1.3539054966248794e-05,
      "loss": 0.2307,
      "step": 30150
    },
    {
      "epoch": 3.231543983713704,
      "grad_norm": 0.03375035524368286,
      "learning_rate": 1.3536912032572593e-05,
      "loss": 0.0016,
      "step": 30160
    },
    {
      "epoch": 3.232615450551805,
      "grad_norm": 0.0053964415565133095,
      "learning_rate": 1.353476909889639e-05,
      "loss": 0.6385,
      "step": 30170
    },
    {
      "epoch": 3.2336869173899068,
      "grad_norm": 0.015618424862623215,
      "learning_rate": 1.3532626165220188e-05,
      "loss": 0.3502,
      "step": 30180
    },
    {
      "epoch": 3.2347583842280083,
      "grad_norm": 0.038333579897880554,
      "learning_rate": 1.3530483231543985e-05,
      "loss": 0.1771,
      "step": 30190
    },
    {
      "epoch": 3.2358298510661094,
      "grad_norm": 0.14184416830539703,
      "learning_rate": 1.352834029786778e-05,
      "loss": 0.271,
      "step": 30200
    },
    {
      "epoch": 3.236901317904211,
      "grad_norm": 0.18258696794509888,
      "learning_rate": 1.352619736419158e-05,
      "loss": 0.4099,
      "step": 30210
    },
    {
      "epoch": 3.237972784742312,
      "grad_norm": 0.005602247081696987,
      "learning_rate": 1.3524054430515377e-05,
      "loss": 0.8484,
      "step": 30220
    },
    {
      "epoch": 3.2390442515804136,
      "grad_norm": 0.2105993777513504,
      "learning_rate": 1.3521911496839173e-05,
      "loss": 0.0639,
      "step": 30230
    },
    {
      "epoch": 3.2401157184185148,
      "grad_norm": 0.05597144737839699,
      "learning_rate": 1.3519768563162972e-05,
      "loss": 0.3667,
      "step": 30240
    },
    {
      "epoch": 3.2411871852566163,
      "grad_norm": 0.3107335865497589,
      "learning_rate": 1.3517625629486767e-05,
      "loss": 0.1118,
      "step": 30250
    },
    {
      "epoch": 3.242258652094718,
      "grad_norm": 0.08934760093688965,
      "learning_rate": 1.3515482695810567e-05,
      "loss": 0.154,
      "step": 30260
    },
    {
      "epoch": 3.243330118932819,
      "grad_norm": 0.04545105993747711,
      "learning_rate": 1.3513339762134364e-05,
      "loss": 0.2207,
      "step": 30270
    },
    {
      "epoch": 3.2444015857709205,
      "grad_norm": 16.989370346069336,
      "learning_rate": 1.351119682845816e-05,
      "loss": 0.4663,
      "step": 30280
    },
    {
      "epoch": 3.2454730526090216,
      "grad_norm": 0.06596428900957108,
      "learning_rate": 1.3509053894781959e-05,
      "loss": 0.002,
      "step": 30290
    },
    {
      "epoch": 3.246544519447123,
      "grad_norm": 0.0809050127863884,
      "learning_rate": 1.3506910961105754e-05,
      "loss": 0.0021,
      "step": 30300
    },
    {
      "epoch": 3.2476159862852243,
      "grad_norm": 0.009713373146951199,
      "learning_rate": 1.3504768027429552e-05,
      "loss": 0.0028,
      "step": 30310
    },
    {
      "epoch": 3.248687453123326,
      "grad_norm": 0.01836727187037468,
      "learning_rate": 1.350262509375335e-05,
      "loss": 0.3208,
      "step": 30320
    },
    {
      "epoch": 3.249758919961427,
      "grad_norm": 0.012179601937532425,
      "learning_rate": 1.3500482160077146e-05,
      "loss": 0.1651,
      "step": 30330
    },
    {
      "epoch": 3.2508303867995285,
      "grad_norm": 0.011265316046774387,
      "learning_rate": 1.3498339226400945e-05,
      "loss": 0.18,
      "step": 30340
    },
    {
      "epoch": 3.25190185363763,
      "grad_norm": 0.013354264199733734,
      "learning_rate": 1.3496196292724741e-05,
      "loss": 0.2485,
      "step": 30350
    },
    {
      "epoch": 3.252973320475731,
      "grad_norm": 0.027005691081285477,
      "learning_rate": 1.3494053359048538e-05,
      "loss": 0.1406,
      "step": 30360
    },
    {
      "epoch": 3.2540447873138327,
      "grad_norm": 0.0027030580677092075,
      "learning_rate": 1.3491910425372336e-05,
      "loss": 0.1851,
      "step": 30370
    },
    {
      "epoch": 3.255116254151934,
      "grad_norm": 0.10910912603139877,
      "learning_rate": 1.3489767491696133e-05,
      "loss": 0.6336,
      "step": 30380
    },
    {
      "epoch": 3.2561877209900354,
      "grad_norm": 0.03923213109374046,
      "learning_rate": 1.3487624558019929e-05,
      "loss": 0.0023,
      "step": 30390
    },
    {
      "epoch": 3.2572591878281365,
      "grad_norm": 31.384687423706055,
      "learning_rate": 1.3485481624343728e-05,
      "loss": 0.5474,
      "step": 30400
    },
    {
      "epoch": 3.258330654666238,
      "grad_norm": 26.758630752563477,
      "learning_rate": 1.3483338690667525e-05,
      "loss": 0.0044,
      "step": 30410
    },
    {
      "epoch": 3.2594021215043396,
      "grad_norm": 111.29107666015625,
      "learning_rate": 1.3481195756991323e-05,
      "loss": 0.2741,
      "step": 30420
    },
    {
      "epoch": 3.2604735883424407,
      "grad_norm": 0.6954191327095032,
      "learning_rate": 1.347905282331512e-05,
      "loss": 0.3628,
      "step": 30430
    },
    {
      "epoch": 3.2615450551805423,
      "grad_norm": 0.03204835206270218,
      "learning_rate": 1.3476909889638916e-05,
      "loss": 0.2681,
      "step": 30440
    },
    {
      "epoch": 3.2626165220186434,
      "grad_norm": 0.1751541644334793,
      "learning_rate": 1.3474766955962715e-05,
      "loss": 0.4516,
      "step": 30450
    },
    {
      "epoch": 3.263687988856745,
      "grad_norm": 0.006690619513392448,
      "learning_rate": 1.3472624022286512e-05,
      "loss": 0.1599,
      "step": 30460
    },
    {
      "epoch": 3.264759455694846,
      "grad_norm": 0.18272249400615692,
      "learning_rate": 1.3470481088610308e-05,
      "loss": 0.1557,
      "step": 30470
    },
    {
      "epoch": 3.2658309225329476,
      "grad_norm": 0.10048186033964157,
      "learning_rate": 1.3468338154934107e-05,
      "loss": 0.0053,
      "step": 30480
    },
    {
      "epoch": 3.266902389371049,
      "grad_norm": 0.13154079020023346,
      "learning_rate": 1.3466195221257902e-05,
      "loss": 0.0062,
      "step": 30490
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 0.008893094025552273,
      "learning_rate": 1.3464052287581701e-05,
      "loss": 0.1306,
      "step": 30500
    },
    {
      "epoch": 3.269045323047252,
      "grad_norm": 0.11507776379585266,
      "learning_rate": 1.3461909353905499e-05,
      "loss": 0.1595,
      "step": 30510
    },
    {
      "epoch": 3.270116789885353,
      "grad_norm": 0.1773705631494522,
      "learning_rate": 1.3459766420229294e-05,
      "loss": 0.1737,
      "step": 30520
    },
    {
      "epoch": 3.2711882567234545,
      "grad_norm": 0.05720910057425499,
      "learning_rate": 1.3457623486553093e-05,
      "loss": 0.3405,
      "step": 30530
    },
    {
      "epoch": 3.2722597235615556,
      "grad_norm": 0.020347673445940018,
      "learning_rate": 1.3455480552876889e-05,
      "loss": 0.3082,
      "step": 30540
    },
    {
      "epoch": 3.273331190399657,
      "grad_norm": 0.26922065019607544,
      "learning_rate": 1.3453337619200686e-05,
      "loss": 0.2728,
      "step": 30550
    },
    {
      "epoch": 3.2744026572377587,
      "grad_norm": 20.784753799438477,
      "learning_rate": 1.3451194685524484e-05,
      "loss": 0.2709,
      "step": 30560
    },
    {
      "epoch": 3.27547412407586,
      "grad_norm": 37.31092071533203,
      "learning_rate": 1.3449051751848281e-05,
      "loss": 0.3379,
      "step": 30570
    },
    {
      "epoch": 3.2765455909139614,
      "grad_norm": 0.04258112609386444,
      "learning_rate": 1.344690881817208e-05,
      "loss": 0.3987,
      "step": 30580
    },
    {
      "epoch": 3.2776170577520625,
      "grad_norm": 0.018866343423724174,
      "learning_rate": 1.3444765884495876e-05,
      "loss": 0.4008,
      "step": 30590
    },
    {
      "epoch": 3.278688524590164,
      "grad_norm": 0.1946491003036499,
      "learning_rate": 1.3442622950819673e-05,
      "loss": 0.2524,
      "step": 30600
    },
    {
      "epoch": 3.279759991428265,
      "grad_norm": 0.07581143081188202,
      "learning_rate": 1.344048001714347e-05,
      "loss": 0.2102,
      "step": 30610
    },
    {
      "epoch": 3.2808314582663667,
      "grad_norm": 0.2563779056072235,
      "learning_rate": 1.3438337083467268e-05,
      "loss": 0.0237,
      "step": 30620
    },
    {
      "epoch": 3.2819029251044682,
      "grad_norm": 0.020843207836151123,
      "learning_rate": 1.3436194149791064e-05,
      "loss": 0.0022,
      "step": 30630
    },
    {
      "epoch": 3.2829743919425693,
      "grad_norm": 0.11445001512765884,
      "learning_rate": 1.3434051216114863e-05,
      "loss": 0.624,
      "step": 30640
    },
    {
      "epoch": 3.284045858780671,
      "grad_norm": 0.05441933870315552,
      "learning_rate": 1.343190828243866e-05,
      "loss": 0.4054,
      "step": 30650
    },
    {
      "epoch": 3.285117325618772,
      "grad_norm": 18.14825439453125,
      "learning_rate": 1.3429765348762457e-05,
      "loss": 0.1876,
      "step": 30660
    },
    {
      "epoch": 3.2861887924568736,
      "grad_norm": 0.04964453727006912,
      "learning_rate": 1.3427622415086255e-05,
      "loss": 0.3303,
      "step": 30670
    },
    {
      "epoch": 3.2872602592949747,
      "grad_norm": 36.481163024902344,
      "learning_rate": 1.342547948141005e-05,
      "loss": 0.381,
      "step": 30680
    },
    {
      "epoch": 3.2883317261330762,
      "grad_norm": 0.2992464601993561,
      "learning_rate": 1.342333654773385e-05,
      "loss": 0.326,
      "step": 30690
    },
    {
      "epoch": 3.289403192971178,
      "grad_norm": 0.2349318116903305,
      "learning_rate": 1.3421193614057647e-05,
      "loss": 0.0023,
      "step": 30700
    },
    {
      "epoch": 3.290474659809279,
      "grad_norm": 0.7307581901550293,
      "learning_rate": 1.3419050680381442e-05,
      "loss": 0.0033,
      "step": 30710
    },
    {
      "epoch": 3.2915461266473804,
      "grad_norm": 1.7846498489379883,
      "learning_rate": 1.3416907746705242e-05,
      "loss": 0.165,
      "step": 30720
    },
    {
      "epoch": 3.2926175934854816,
      "grad_norm": 0.05280977860093117,
      "learning_rate": 1.3414764813029037e-05,
      "loss": 0.1616,
      "step": 30730
    },
    {
      "epoch": 3.293689060323583,
      "grad_norm": 0.01177565660327673,
      "learning_rate": 1.3412621879352836e-05,
      "loss": 0.3606,
      "step": 30740
    },
    {
      "epoch": 3.294760527161684,
      "grad_norm": 1.204703688621521,
      "learning_rate": 1.3410478945676632e-05,
      "loss": 0.1889,
      "step": 30750
    },
    {
      "epoch": 3.2958319939997858,
      "grad_norm": 0.05577642470598221,
      "learning_rate": 1.340833601200043e-05,
      "loss": 0.0042,
      "step": 30760
    },
    {
      "epoch": 3.296903460837887,
      "grad_norm": 15.243354797363281,
      "learning_rate": 1.3406193078324228e-05,
      "loss": 0.5082,
      "step": 30770
    },
    {
      "epoch": 3.2979749276759884,
      "grad_norm": 0.007933957502245903,
      "learning_rate": 1.3404050144648024e-05,
      "loss": 0.1988,
      "step": 30780
    },
    {
      "epoch": 3.2990463945140895,
      "grad_norm": 0.004679006524384022,
      "learning_rate": 1.3401907210971821e-05,
      "loss": 0.0021,
      "step": 30790
    },
    {
      "epoch": 3.300117861352191,
      "grad_norm": 22.472061157226562,
      "learning_rate": 1.3399764277295619e-05,
      "loss": 0.6534,
      "step": 30800
    },
    {
      "epoch": 3.3011893281902926,
      "grad_norm": 14.423086166381836,
      "learning_rate": 1.3397621343619416e-05,
      "loss": 0.5582,
      "step": 30810
    },
    {
      "epoch": 3.3022607950283938,
      "grad_norm": 0.19406479597091675,
      "learning_rate": 1.3395478409943212e-05,
      "loss": 0.3746,
      "step": 30820
    },
    {
      "epoch": 3.3033322618664953,
      "grad_norm": 0.46954119205474854,
      "learning_rate": 1.339333547626701e-05,
      "loss": 0.007,
      "step": 30830
    },
    {
      "epoch": 3.3044037287045964,
      "grad_norm": 48.43052291870117,
      "learning_rate": 1.3391192542590808e-05,
      "loss": 0.4986,
      "step": 30840
    },
    {
      "epoch": 3.305475195542698,
      "grad_norm": 0.46858838200569153,
      "learning_rate": 1.3389049608914605e-05,
      "loss": 0.2274,
      "step": 30850
    },
    {
      "epoch": 3.306546662380799,
      "grad_norm": 0.09302562475204468,
      "learning_rate": 1.3386906675238403e-05,
      "loss": 0.4903,
      "step": 30860
    },
    {
      "epoch": 3.3076181292189006,
      "grad_norm": 0.04448134824633598,
      "learning_rate": 1.3384763741562198e-05,
      "loss": 0.1281,
      "step": 30870
    },
    {
      "epoch": 3.308689596057002,
      "grad_norm": 0.07922102510929108,
      "learning_rate": 1.3382620807885997e-05,
      "loss": 0.3259,
      "step": 30880
    },
    {
      "epoch": 3.3097610628951033,
      "grad_norm": 0.010484747588634491,
      "learning_rate": 1.3380477874209795e-05,
      "loss": 0.0451,
      "step": 30890
    },
    {
      "epoch": 3.310832529733205,
      "grad_norm": 0.05704770237207413,
      "learning_rate": 1.337833494053359e-05,
      "loss": 0.1586,
      "step": 30900
    },
    {
      "epoch": 3.311903996571306,
      "grad_norm": 0.00445671146735549,
      "learning_rate": 1.337619200685739e-05,
      "loss": 0.5045,
      "step": 30910
    },
    {
      "epoch": 3.3129754634094075,
      "grad_norm": 114.21675872802734,
      "learning_rate": 1.3374049073181185e-05,
      "loss": 0.399,
      "step": 30920
    },
    {
      "epoch": 3.3140469302475086,
      "grad_norm": 0.021470937877893448,
      "learning_rate": 1.3371906139504984e-05,
      "loss": 0.3597,
      "step": 30930
    },
    {
      "epoch": 3.31511839708561,
      "grad_norm": 0.10124441981315613,
      "learning_rate": 1.336976320582878e-05,
      "loss": 0.4558,
      "step": 30940
    },
    {
      "epoch": 3.3161898639237117,
      "grad_norm": 0.33655357360839844,
      "learning_rate": 1.3367620272152577e-05,
      "loss": 0.004,
      "step": 30950
    },
    {
      "epoch": 3.317261330761813,
      "grad_norm": 0.0935220792889595,
      "learning_rate": 1.3365477338476376e-05,
      "loss": 0.3442,
      "step": 30960
    },
    {
      "epoch": 3.3183327975999144,
      "grad_norm": 0.0566384419798851,
      "learning_rate": 1.3363334404800172e-05,
      "loss": 0.0025,
      "step": 30970
    },
    {
      "epoch": 3.3194042644380155,
      "grad_norm": 0.14878569543361664,
      "learning_rate": 1.336119147112397e-05,
      "loss": 0.3662,
      "step": 30980
    },
    {
      "epoch": 3.320475731276117,
      "grad_norm": 0.18375661969184875,
      "learning_rate": 1.3359048537447767e-05,
      "loss": 0.3029,
      "step": 30990
    },
    {
      "epoch": 3.321547198114218,
      "grad_norm": 17.926528930664062,
      "learning_rate": 1.3356905603771564e-05,
      "loss": 0.6455,
      "step": 31000
    },
    {
      "epoch": 3.3226186649523197,
      "grad_norm": 0.12961509823799133,
      "learning_rate": 1.3354762670095363e-05,
      "loss": 0.1389,
      "step": 31010
    },
    {
      "epoch": 3.3236901317904213,
      "grad_norm": 0.023088881745934486,
      "learning_rate": 1.3352619736419159e-05,
      "loss": 0.345,
      "step": 31020
    },
    {
      "epoch": 3.3247615986285224,
      "grad_norm": 0.04250471666455269,
      "learning_rate": 1.3350476802742956e-05,
      "loss": 0.2113,
      "step": 31030
    },
    {
      "epoch": 3.325833065466624,
      "grad_norm": 0.024028664454817772,
      "learning_rate": 1.3348333869066753e-05,
      "loss": 0.1166,
      "step": 31040
    },
    {
      "epoch": 3.326904532304725,
      "grad_norm": 0.28310611844062805,
      "learning_rate": 1.3346190935390551e-05,
      "loss": 0.0843,
      "step": 31050
    },
    {
      "epoch": 3.3279759991428266,
      "grad_norm": 0.27228257060050964,
      "learning_rate": 1.3344048001714347e-05,
      "loss": 0.2151,
      "step": 31060
    },
    {
      "epoch": 3.3290474659809277,
      "grad_norm": 1.3775936365127563,
      "learning_rate": 1.3341905068038146e-05,
      "loss": 0.1758,
      "step": 31070
    },
    {
      "epoch": 3.3301189328190293,
      "grad_norm": 92.28944396972656,
      "learning_rate": 1.3339762134361943e-05,
      "loss": 0.5039,
      "step": 31080
    },
    {
      "epoch": 3.331190399657131,
      "grad_norm": 0.019152237102389336,
      "learning_rate": 1.333761920068574e-05,
      "loss": 0.146,
      "step": 31090
    },
    {
      "epoch": 3.332261866495232,
      "grad_norm": 0.07736667990684509,
      "learning_rate": 1.3335476267009538e-05,
      "loss": 0.001,
      "step": 31100
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 19.1196346282959,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.6022,
      "step": 31110
    },
    {
      "epoch": 3.3344048001714346,
      "grad_norm": 0.010257157497107983,
      "learning_rate": 1.3331190399657132e-05,
      "loss": 0.1055,
      "step": 31120
    },
    {
      "epoch": 3.335476267009536,
      "grad_norm": 20.030601501464844,
      "learning_rate": 1.3329047465980928e-05,
      "loss": 0.2599,
      "step": 31130
    },
    {
      "epoch": 3.3365477338476373,
      "grad_norm": 0.008651519194245338,
      "learning_rate": 1.3326904532304725e-05,
      "loss": 0.4787,
      "step": 31140
    },
    {
      "epoch": 3.337619200685739,
      "grad_norm": 0.02765340358018875,
      "learning_rate": 1.3324761598628524e-05,
      "loss": 0.1564,
      "step": 31150
    },
    {
      "epoch": 3.3386906675238404,
      "grad_norm": 0.015005269087851048,
      "learning_rate": 1.332261866495232e-05,
      "loss": 0.1092,
      "step": 31160
    },
    {
      "epoch": 3.3397621343619415,
      "grad_norm": 0.015201420523226261,
      "learning_rate": 1.3320475731276119e-05,
      "loss": 0.0014,
      "step": 31170
    },
    {
      "epoch": 3.340833601200043,
      "grad_norm": 0.4831571578979492,
      "learning_rate": 1.3318332797599915e-05,
      "loss": 1.0023,
      "step": 31180
    },
    {
      "epoch": 3.341905068038144,
      "grad_norm": 0.11278122663497925,
      "learning_rate": 1.3316189863923712e-05,
      "loss": 0.1896,
      "step": 31190
    },
    {
      "epoch": 3.3429765348762457,
      "grad_norm": 14.977974891662598,
      "learning_rate": 1.3314046930247511e-05,
      "loss": 0.2104,
      "step": 31200
    },
    {
      "epoch": 3.344048001714347,
      "grad_norm": 0.10495630651712418,
      "learning_rate": 1.3311903996571307e-05,
      "loss": 0.002,
      "step": 31210
    },
    {
      "epoch": 3.3451194685524483,
      "grad_norm": 0.09715323150157928,
      "learning_rate": 1.3309761062895104e-05,
      "loss": 0.0013,
      "step": 31220
    },
    {
      "epoch": 3.34619093539055,
      "grad_norm": 15.791953086853027,
      "learning_rate": 1.3307618129218902e-05,
      "loss": 0.1841,
      "step": 31230
    },
    {
      "epoch": 3.347262402228651,
      "grad_norm": 0.017253726720809937,
      "learning_rate": 1.3305475195542699e-05,
      "loss": 0.2334,
      "step": 31240
    },
    {
      "epoch": 3.3483338690667526,
      "grad_norm": 0.0679367259144783,
      "learning_rate": 1.3303332261866498e-05,
      "loss": 0.2667,
      "step": 31250
    },
    {
      "epoch": 3.3494053359048537,
      "grad_norm": 113.07617950439453,
      "learning_rate": 1.3301189328190294e-05,
      "loss": 0.8841,
      "step": 31260
    },
    {
      "epoch": 3.3504768027429552,
      "grad_norm": 0.08223000168800354,
      "learning_rate": 1.3299046394514091e-05,
      "loss": 0.8179,
      "step": 31270
    },
    {
      "epoch": 3.3515482695810563,
      "grad_norm": 0.10349871218204498,
      "learning_rate": 1.3296903460837888e-05,
      "loss": 0.0035,
      "step": 31280
    },
    {
      "epoch": 3.352619736419158,
      "grad_norm": 0.1109946146607399,
      "learning_rate": 1.3294760527161686e-05,
      "loss": 0.0018,
      "step": 31290
    },
    {
      "epoch": 3.353691203257259,
      "grad_norm": 37.986228942871094,
      "learning_rate": 1.3292617593485481e-05,
      "loss": 0.1727,
      "step": 31300
    },
    {
      "epoch": 3.3547626700953606,
      "grad_norm": 0.09077440202236176,
      "learning_rate": 1.329047465980928e-05,
      "loss": 0.0019,
      "step": 31310
    },
    {
      "epoch": 3.3558341369334617,
      "grad_norm": 0.029505960643291473,
      "learning_rate": 1.3288331726133076e-05,
      "loss": 0.1763,
      "step": 31320
    },
    {
      "epoch": 3.356905603771563,
      "grad_norm": 0.03638413920998573,
      "learning_rate": 1.3286188792456875e-05,
      "loss": 0.5631,
      "step": 31330
    },
    {
      "epoch": 3.3579770706096648,
      "grad_norm": 0.022772951051592827,
      "learning_rate": 1.3284045858780672e-05,
      "loss": 0.1836,
      "step": 31340
    },
    {
      "epoch": 3.359048537447766,
      "grad_norm": 0.017146093770861626,
      "learning_rate": 1.3281902925104468e-05,
      "loss": 0.269,
      "step": 31350
    },
    {
      "epoch": 3.3601200042858674,
      "grad_norm": 0.32973912358283997,
      "learning_rate": 1.3279759991428267e-05,
      "loss": 0.3432,
      "step": 31360
    },
    {
      "epoch": 3.3611914711239685,
      "grad_norm": 0.08733252435922623,
      "learning_rate": 1.3277617057752063e-05,
      "loss": 0.5245,
      "step": 31370
    },
    {
      "epoch": 3.36226293796207,
      "grad_norm": 0.24644514918327332,
      "learning_rate": 1.327547412407586e-05,
      "loss": 0.3644,
      "step": 31380
    },
    {
      "epoch": 3.363334404800171,
      "grad_norm": 0.17257994413375854,
      "learning_rate": 1.327333119039966e-05,
      "loss": 0.0034,
      "step": 31390
    },
    {
      "epoch": 3.3644058716382728,
      "grad_norm": 0.4977674186229706,
      "learning_rate": 1.3271188256723455e-05,
      "loss": 0.0031,
      "step": 31400
    },
    {
      "epoch": 3.3654773384763743,
      "grad_norm": 0.03558656573295593,
      "learning_rate": 1.3269045323047254e-05,
      "loss": 0.4082,
      "step": 31410
    },
    {
      "epoch": 3.3665488053144754,
      "grad_norm": 0.08055853843688965,
      "learning_rate": 1.326690238937105e-05,
      "loss": 0.2829,
      "step": 31420
    },
    {
      "epoch": 3.367620272152577,
      "grad_norm": 0.16867750883102417,
      "learning_rate": 1.3264759455694847e-05,
      "loss": 0.369,
      "step": 31430
    },
    {
      "epoch": 3.368691738990678,
      "grad_norm": 0.026339340955018997,
      "learning_rate": 1.3262616522018646e-05,
      "loss": 0.098,
      "step": 31440
    },
    {
      "epoch": 3.3697632058287796,
      "grad_norm": 17.545019149780273,
      "learning_rate": 1.3260473588342442e-05,
      "loss": 0.1531,
      "step": 31450
    },
    {
      "epoch": 3.3708346726668807,
      "grad_norm": 0.017154129222035408,
      "learning_rate": 1.3258330654666239e-05,
      "loss": 0.422,
      "step": 31460
    },
    {
      "epoch": 3.3719061395049823,
      "grad_norm": 0.025902843102812767,
      "learning_rate": 1.3256187720990036e-05,
      "loss": 0.0036,
      "step": 31470
    },
    {
      "epoch": 3.372977606343084,
      "grad_norm": 0.16059383749961853,
      "learning_rate": 1.3254044787313834e-05,
      "loss": 0.005,
      "step": 31480
    },
    {
      "epoch": 3.374049073181185,
      "grad_norm": 0.026253387331962585,
      "learning_rate": 1.3251901853637633e-05,
      "loss": 0.1921,
      "step": 31490
    },
    {
      "epoch": 3.3751205400192865,
      "grad_norm": 19.2908935546875,
      "learning_rate": 1.3249758919961428e-05,
      "loss": 0.2053,
      "step": 31500
    },
    {
      "epoch": 3.3761920068573876,
      "grad_norm": 0.025108039379119873,
      "learning_rate": 1.3247615986285224e-05,
      "loss": 0.9781,
      "step": 31510
    },
    {
      "epoch": 3.377263473695489,
      "grad_norm": 0.13834048807621002,
      "learning_rate": 1.3245473052609023e-05,
      "loss": 0.2452,
      "step": 31520
    },
    {
      "epoch": 3.3783349405335903,
      "grad_norm": 0.34529775381088257,
      "learning_rate": 1.324333011893282e-05,
      "loss": 0.1634,
      "step": 31530
    },
    {
      "epoch": 3.379406407371692,
      "grad_norm": 0.11664941906929016,
      "learning_rate": 1.3241187185256616e-05,
      "loss": 0.2967,
      "step": 31540
    },
    {
      "epoch": 3.3804778742097934,
      "grad_norm": 0.15503916144371033,
      "learning_rate": 1.3239044251580415e-05,
      "loss": 0.1747,
      "step": 31550
    },
    {
      "epoch": 3.3815493410478945,
      "grad_norm": 86.36408233642578,
      "learning_rate": 1.3236901317904211e-05,
      "loss": 0.1518,
      "step": 31560
    },
    {
      "epoch": 3.382620807885996,
      "grad_norm": 0.031069714576005936,
      "learning_rate": 1.323475838422801e-05,
      "loss": 0.2124,
      "step": 31570
    },
    {
      "epoch": 3.383692274724097,
      "grad_norm": 0.19308575987815857,
      "learning_rate": 1.3232615450551807e-05,
      "loss": 0.0054,
      "step": 31580
    },
    {
      "epoch": 3.3847637415621987,
      "grad_norm": 0.017060361802577972,
      "learning_rate": 1.3230472516875603e-05,
      "loss": 0.1547,
      "step": 31590
    },
    {
      "epoch": 3.3858352084003,
      "grad_norm": 0.006346830632537603,
      "learning_rate": 1.3228329583199402e-05,
      "loss": 0.4582,
      "step": 31600
    },
    {
      "epoch": 3.3869066752384014,
      "grad_norm": 0.011248073540627956,
      "learning_rate": 1.3226186649523198e-05,
      "loss": 0.0044,
      "step": 31610
    },
    {
      "epoch": 3.387978142076503,
      "grad_norm": 0.23779523372650146,
      "learning_rate": 1.3224043715846995e-05,
      "loss": 0.2239,
      "step": 31620
    },
    {
      "epoch": 3.389049608914604,
      "grad_norm": 0.0942268893122673,
      "learning_rate": 1.3221900782170794e-05,
      "loss": 0.7241,
      "step": 31630
    },
    {
      "epoch": 3.3901210757527056,
      "grad_norm": 0.008260227739810944,
      "learning_rate": 1.321975784849459e-05,
      "loss": 0.2536,
      "step": 31640
    },
    {
      "epoch": 3.3911925425908067,
      "grad_norm": 0.46916961669921875,
      "learning_rate": 1.3217614914818389e-05,
      "loss": 0.087,
      "step": 31650
    },
    {
      "epoch": 3.3922640094289083,
      "grad_norm": 0.006653765682131052,
      "learning_rate": 1.3215471981142184e-05,
      "loss": 0.0288,
      "step": 31660
    },
    {
      "epoch": 3.3933354762670094,
      "grad_norm": 0.17702028155326843,
      "learning_rate": 1.3213329047465982e-05,
      "loss": 0.0047,
      "step": 31670
    },
    {
      "epoch": 3.394406943105111,
      "grad_norm": 0.01556466519832611,
      "learning_rate": 1.3211186113789781e-05,
      "loss": 0.0073,
      "step": 31680
    },
    {
      "epoch": 3.3954784099432125,
      "grad_norm": 2.982388734817505,
      "learning_rate": 1.3209043180113577e-05,
      "loss": 0.003,
      "step": 31690
    },
    {
      "epoch": 3.3965498767813136,
      "grad_norm": 15.647753715515137,
      "learning_rate": 1.3206900246437372e-05,
      "loss": 0.1915,
      "step": 31700
    },
    {
      "epoch": 3.397621343619415,
      "grad_norm": 0.004747925326228142,
      "learning_rate": 1.3204757312761171e-05,
      "loss": 0.2878,
      "step": 31710
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 0.5984273552894592,
      "learning_rate": 1.3202614379084969e-05,
      "loss": 0.5083,
      "step": 31720
    },
    {
      "epoch": 3.399764277295618,
      "grad_norm": 28.20431137084961,
      "learning_rate": 1.3200471445408764e-05,
      "loss": 0.2588,
      "step": 31730
    },
    {
      "epoch": 3.400835744133719,
      "grad_norm": 0.12813827395439148,
      "learning_rate": 1.3198328511732563e-05,
      "loss": 0.2255,
      "step": 31740
    },
    {
      "epoch": 3.4019072109718205,
      "grad_norm": 0.11468122154474258,
      "learning_rate": 1.3196185578056359e-05,
      "loss": 0.1591,
      "step": 31750
    },
    {
      "epoch": 3.402978677809922,
      "grad_norm": 24.320688247680664,
      "learning_rate": 1.3194042644380158e-05,
      "loss": 0.0096,
      "step": 31760
    },
    {
      "epoch": 3.404050144648023,
      "grad_norm": 0.012263651005923748,
      "learning_rate": 1.3191899710703955e-05,
      "loss": 0.2203,
      "step": 31770
    },
    {
      "epoch": 3.4051216114861247,
      "grad_norm": 218.26393127441406,
      "learning_rate": 1.3189756777027751e-05,
      "loss": 0.1676,
      "step": 31780
    },
    {
      "epoch": 3.406193078324226,
      "grad_norm": 26.354337692260742,
      "learning_rate": 1.318761384335155e-05,
      "loss": 0.6867,
      "step": 31790
    },
    {
      "epoch": 3.4072645451623274,
      "grad_norm": 0.02348601259291172,
      "learning_rate": 1.3185470909675346e-05,
      "loss": 0.0018,
      "step": 31800
    },
    {
      "epoch": 3.4083360120004285,
      "grad_norm": 0.15488877892494202,
      "learning_rate": 1.3183327975999143e-05,
      "loss": 0.1666,
      "step": 31810
    },
    {
      "epoch": 3.40940747883853,
      "grad_norm": 0.018907003104686737,
      "learning_rate": 1.3181185042322942e-05,
      "loss": 0.2213,
      "step": 31820
    },
    {
      "epoch": 3.410478945676631,
      "grad_norm": 0.005661810282617807,
      "learning_rate": 1.3179042108646738e-05,
      "loss": 0.1543,
      "step": 31830
    },
    {
      "epoch": 3.4115504125147327,
      "grad_norm": 0.09547320008277893,
      "learning_rate": 1.3176899174970537e-05,
      "loss": 0.4122,
      "step": 31840
    },
    {
      "epoch": 3.412621879352834,
      "grad_norm": 0.008298258297145367,
      "learning_rate": 1.3174756241294333e-05,
      "loss": 0.5794,
      "step": 31850
    },
    {
      "epoch": 3.4136933461909353,
      "grad_norm": 0.004098821431398392,
      "learning_rate": 1.317261330761813e-05,
      "loss": 0.1088,
      "step": 31860
    },
    {
      "epoch": 3.414764813029037,
      "grad_norm": 0.13420262932777405,
      "learning_rate": 1.3170470373941929e-05,
      "loss": 0.1602,
      "step": 31870
    },
    {
      "epoch": 3.415836279867138,
      "grad_norm": 0.030350062996149063,
      "learning_rate": 1.3168327440265725e-05,
      "loss": 0.332,
      "step": 31880
    },
    {
      "epoch": 3.4169077467052396,
      "grad_norm": 0.25722357630729675,
      "learning_rate": 1.316618450658952e-05,
      "loss": 0.0018,
      "step": 31890
    },
    {
      "epoch": 3.4179792135433407,
      "grad_norm": 16.48432159423828,
      "learning_rate": 1.316404157291332e-05,
      "loss": 0.2826,
      "step": 31900
    },
    {
      "epoch": 3.419050680381442,
      "grad_norm": 0.009176425635814667,
      "learning_rate": 1.3161898639237117e-05,
      "loss": 0.5437,
      "step": 31910
    },
    {
      "epoch": 3.4201221472195433,
      "grad_norm": 0.0765647441148758,
      "learning_rate": 1.3159755705560914e-05,
      "loss": 0.3963,
      "step": 31920
    },
    {
      "epoch": 3.421193614057645,
      "grad_norm": 0.04882090538740158,
      "learning_rate": 1.3157612771884711e-05,
      "loss": 0.0119,
      "step": 31930
    },
    {
      "epoch": 3.4222650808957464,
      "grad_norm": 0.07577836513519287,
      "learning_rate": 1.3155469838208507e-05,
      "loss": 0.2546,
      "step": 31940
    },
    {
      "epoch": 3.4233365477338475,
      "grad_norm": 0.24294215440750122,
      "learning_rate": 1.3153326904532306e-05,
      "loss": 0.4909,
      "step": 31950
    },
    {
      "epoch": 3.424408014571949,
      "grad_norm": 0.044174063950777054,
      "learning_rate": 1.3151183970856103e-05,
      "loss": 0.4114,
      "step": 31960
    },
    {
      "epoch": 3.42547948141005,
      "grad_norm": 0.06417180597782135,
      "learning_rate": 1.3149041037179899e-05,
      "loss": 0.018,
      "step": 31970
    },
    {
      "epoch": 3.4265509482481518,
      "grad_norm": 0.09801337867975235,
      "learning_rate": 1.3146898103503698e-05,
      "loss": 0.3013,
      "step": 31980
    },
    {
      "epoch": 3.427622415086253,
      "grad_norm": 0.12412157654762268,
      "learning_rate": 1.3144755169827494e-05,
      "loss": 0.1749,
      "step": 31990
    },
    {
      "epoch": 3.4286938819243544,
      "grad_norm": 0.06367621570825577,
      "learning_rate": 1.3142612236151293e-05,
      "loss": 0.2792,
      "step": 32000
    },
    {
      "epoch": 3.429765348762456,
      "grad_norm": 0.26429447531700134,
      "learning_rate": 1.314046930247509e-05,
      "loss": 0.1669,
      "step": 32010
    },
    {
      "epoch": 3.430836815600557,
      "grad_norm": 0.10685087740421295,
      "learning_rate": 1.3138326368798886e-05,
      "loss": 0.4981,
      "step": 32020
    },
    {
      "epoch": 3.4319082824386586,
      "grad_norm": 0.03628617152571678,
      "learning_rate": 1.3136183435122685e-05,
      "loss": 0.0198,
      "step": 32030
    },
    {
      "epoch": 3.4329797492767598,
      "grad_norm": 0.02334146946668625,
      "learning_rate": 1.313404050144648e-05,
      "loss": 0.177,
      "step": 32040
    },
    {
      "epoch": 3.4340512161148613,
      "grad_norm": 0.00951098557561636,
      "learning_rate": 1.3131897567770278e-05,
      "loss": 0.1873,
      "step": 32050
    },
    {
      "epoch": 3.4351226829529624,
      "grad_norm": 75.75836944580078,
      "learning_rate": 1.3129754634094077e-05,
      "loss": 0.2022,
      "step": 32060
    },
    {
      "epoch": 3.436194149791064,
      "grad_norm": 0.07793264836072922,
      "learning_rate": 1.3127611700417873e-05,
      "loss": 0.3845,
      "step": 32070
    },
    {
      "epoch": 3.4372656166291655,
      "grad_norm": 0.16042126715183258,
      "learning_rate": 1.3125468766741672e-05,
      "loss": 0.0026,
      "step": 32080
    },
    {
      "epoch": 3.4383370834672666,
      "grad_norm": 0.0072001502849161625,
      "learning_rate": 1.3123325833065467e-05,
      "loss": 0.183,
      "step": 32090
    },
    {
      "epoch": 3.439408550305368,
      "grad_norm": 0.024024924263358116,
      "learning_rate": 1.3121182899389265e-05,
      "loss": 0.1781,
      "step": 32100
    },
    {
      "epoch": 3.4404800171434693,
      "grad_norm": 0.13845573365688324,
      "learning_rate": 1.3119039965713062e-05,
      "loss": 0.2054,
      "step": 32110
    },
    {
      "epoch": 3.441551483981571,
      "grad_norm": 0.01174229010939598,
      "learning_rate": 1.311689703203686e-05,
      "loss": 0.221,
      "step": 32120
    },
    {
      "epoch": 3.442622950819672,
      "grad_norm": 1.7102551460266113,
      "learning_rate": 1.3114754098360655e-05,
      "loss": 0.2896,
      "step": 32130
    },
    {
      "epoch": 3.4436944176577735,
      "grad_norm": 0.6939222812652588,
      "learning_rate": 1.3112611164684454e-05,
      "loss": 0.5096,
      "step": 32140
    },
    {
      "epoch": 3.444765884495875,
      "grad_norm": 0.01631852425634861,
      "learning_rate": 1.3110468231008252e-05,
      "loss": 0.0103,
      "step": 32150
    },
    {
      "epoch": 3.445837351333976,
      "grad_norm": 15.447916984558105,
      "learning_rate": 1.3108325297332049e-05,
      "loss": 0.6475,
      "step": 32160
    },
    {
      "epoch": 3.4469088181720777,
      "grad_norm": 0.034956883639097214,
      "learning_rate": 1.3106182363655846e-05,
      "loss": 0.3158,
      "step": 32170
    },
    {
      "epoch": 3.447980285010179,
      "grad_norm": 0.04741236940026283,
      "learning_rate": 1.3104039429979642e-05,
      "loss": 0.1701,
      "step": 32180
    },
    {
      "epoch": 3.4490517518482804,
      "grad_norm": 0.16776518523693085,
      "learning_rate": 1.3101896496303441e-05,
      "loss": 0.5264,
      "step": 32190
    },
    {
      "epoch": 3.4501232186863815,
      "grad_norm": 0.09718181937932968,
      "learning_rate": 1.3099753562627238e-05,
      "loss": 0.0022,
      "step": 32200
    },
    {
      "epoch": 3.451194685524483,
      "grad_norm": 0.01214834488928318,
      "learning_rate": 1.3097610628951034e-05,
      "loss": 0.29,
      "step": 32210
    },
    {
      "epoch": 3.4522661523625846,
      "grad_norm": 0.0072135403752326965,
      "learning_rate": 1.3095467695274833e-05,
      "loss": 0.2265,
      "step": 32220
    },
    {
      "epoch": 3.4533376192006857,
      "grad_norm": 0.007386650890111923,
      "learning_rate": 1.3093324761598629e-05,
      "loss": 0.0258,
      "step": 32230
    },
    {
      "epoch": 3.4544090860387873,
      "grad_norm": 0.06862813979387283,
      "learning_rate": 1.3091181827922428e-05,
      "loss": 0.003,
      "step": 32240
    },
    {
      "epoch": 3.4554805528768884,
      "grad_norm": 21.73281478881836,
      "learning_rate": 1.3089038894246225e-05,
      "loss": 0.2287,
      "step": 32250
    },
    {
      "epoch": 3.45655201971499,
      "grad_norm": 0.03533080592751503,
      "learning_rate": 1.308689596057002e-05,
      "loss": 0.1501,
      "step": 32260
    },
    {
      "epoch": 3.457623486553091,
      "grad_norm": 19.85952377319336,
      "learning_rate": 1.308475302689382e-05,
      "loss": 0.005,
      "step": 32270
    },
    {
      "epoch": 3.4586949533911926,
      "grad_norm": 0.050372496247291565,
      "learning_rate": 1.3082610093217615e-05,
      "loss": 0.2503,
      "step": 32280
    },
    {
      "epoch": 3.459766420229294,
      "grad_norm": 0.02157525345683098,
      "learning_rate": 1.3080467159541413e-05,
      "loss": 0.0009,
      "step": 32290
    },
    {
      "epoch": 3.4608378870673953,
      "grad_norm": 113.6340560913086,
      "learning_rate": 1.307832422586521e-05,
      "loss": 0.409,
      "step": 32300
    },
    {
      "epoch": 3.461909353905497,
      "grad_norm": 0.08813305199146271,
      "learning_rate": 1.3076181292189008e-05,
      "loss": 0.1567,
      "step": 32310
    },
    {
      "epoch": 3.462980820743598,
      "grad_norm": 0.11619977653026581,
      "learning_rate": 1.3074038358512807e-05,
      "loss": 0.0021,
      "step": 32320
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 17.777748107910156,
      "learning_rate": 1.3071895424836602e-05,
      "loss": 0.7396,
      "step": 32330
    },
    {
      "epoch": 3.4651237544198006,
      "grad_norm": 0.010345470160245895,
      "learning_rate": 1.30697524911604e-05,
      "loss": 0.2472,
      "step": 32340
    },
    {
      "epoch": 3.466195221257902,
      "grad_norm": 0.005847457330673933,
      "learning_rate": 1.3067609557484197e-05,
      "loss": 0.0014,
      "step": 32350
    },
    {
      "epoch": 3.4672666880960032,
      "grad_norm": 0.002900532679632306,
      "learning_rate": 1.3065466623807994e-05,
      "loss": 0.0005,
      "step": 32360
    },
    {
      "epoch": 3.468338154934105,
      "grad_norm": 0.32770147919654846,
      "learning_rate": 1.306332369013179e-05,
      "loss": 0.1453,
      "step": 32370
    },
    {
      "epoch": 3.469409621772206,
      "grad_norm": 0.10140419006347656,
      "learning_rate": 1.3061180756455589e-05,
      "loss": 0.0455,
      "step": 32380
    },
    {
      "epoch": 3.4704810886103075,
      "grad_norm": 19.478443145751953,
      "learning_rate": 1.3059037822779386e-05,
      "loss": 0.645,
      "step": 32390
    },
    {
      "epoch": 3.471552555448409,
      "grad_norm": 0.37497392296791077,
      "learning_rate": 1.3056894889103184e-05,
      "loss": 0.67,
      "step": 32400
    },
    {
      "epoch": 3.47262402228651,
      "grad_norm": 0.0039367834106087685,
      "learning_rate": 1.3054751955426981e-05,
      "loss": 0.2085,
      "step": 32410
    },
    {
      "epoch": 3.4736954891246117,
      "grad_norm": 0.06587337702512741,
      "learning_rate": 1.3052609021750777e-05,
      "loss": 0.116,
      "step": 32420
    },
    {
      "epoch": 3.474766955962713,
      "grad_norm": 38.95104217529297,
      "learning_rate": 1.3050466088074576e-05,
      "loss": 0.0127,
      "step": 32430
    },
    {
      "epoch": 3.4758384228008143,
      "grad_norm": 0.006408523768186569,
      "learning_rate": 1.3048323154398373e-05,
      "loss": 0.1826,
      "step": 32440
    },
    {
      "epoch": 3.4769098896389155,
      "grad_norm": 0.11449155956506729,
      "learning_rate": 1.3046180220722169e-05,
      "loss": 0.3332,
      "step": 32450
    },
    {
      "epoch": 3.477981356477017,
      "grad_norm": 0.07904446125030518,
      "learning_rate": 1.3044037287045968e-05,
      "loss": 0.1767,
      "step": 32460
    },
    {
      "epoch": 3.4790528233151186,
      "grad_norm": 0.014542005956172943,
      "learning_rate": 1.3041894353369764e-05,
      "loss": 0.3088,
      "step": 32470
    },
    {
      "epoch": 3.4801242901532197,
      "grad_norm": 0.002928280271589756,
      "learning_rate": 1.3039751419693563e-05,
      "loss": 0.1718,
      "step": 32480
    },
    {
      "epoch": 3.481195756991321,
      "grad_norm": 0.00874030590057373,
      "learning_rate": 1.3037608486017358e-05,
      "loss": 0.0009,
      "step": 32490
    },
    {
      "epoch": 3.4822672238294223,
      "grad_norm": 0.0038896158803254366,
      "learning_rate": 1.3035465552341156e-05,
      "loss": 0.5272,
      "step": 32500
    },
    {
      "epoch": 3.483338690667524,
      "grad_norm": 15.64973258972168,
      "learning_rate": 1.3033322618664955e-05,
      "loss": 0.3954,
      "step": 32510
    },
    {
      "epoch": 3.484410157505625,
      "grad_norm": 0.20522694289684296,
      "learning_rate": 1.303117968498875e-05,
      "loss": 0.4071,
      "step": 32520
    },
    {
      "epoch": 3.4854816243437265,
      "grad_norm": 0.0068887160159647465,
      "learning_rate": 1.3029036751312548e-05,
      "loss": 0.0017,
      "step": 32530
    },
    {
      "epoch": 3.486553091181828,
      "grad_norm": 0.23727886378765106,
      "learning_rate": 1.3026893817636345e-05,
      "loss": 0.0052,
      "step": 32540
    },
    {
      "epoch": 3.487624558019929,
      "grad_norm": 0.27406638860702515,
      "learning_rate": 1.3024750883960142e-05,
      "loss": 0.4041,
      "step": 32550
    },
    {
      "epoch": 3.4886960248580308,
      "grad_norm": 0.13804063200950623,
      "learning_rate": 1.3022607950283941e-05,
      "loss": 0.176,
      "step": 32560
    },
    {
      "epoch": 3.489767491696132,
      "grad_norm": 0.00468867551535368,
      "learning_rate": 1.3020465016607737e-05,
      "loss": 0.1281,
      "step": 32570
    },
    {
      "epoch": 3.4908389585342334,
      "grad_norm": 0.016080809757113457,
      "learning_rate": 1.3018322082931534e-05,
      "loss": 0.3459,
      "step": 32580
    },
    {
      "epoch": 3.4919104253723345,
      "grad_norm": 0.25897592306137085,
      "learning_rate": 1.3016179149255332e-05,
      "loss": 0.0019,
      "step": 32590
    },
    {
      "epoch": 3.492981892210436,
      "grad_norm": 0.006905107758939266,
      "learning_rate": 1.3014036215579129e-05,
      "loss": 0.1204,
      "step": 32600
    },
    {
      "epoch": 3.4940533590485376,
      "grad_norm": 0.08970177173614502,
      "learning_rate": 1.3011893281902925e-05,
      "loss": 0.4934,
      "step": 32610
    },
    {
      "epoch": 3.4951248258866388,
      "grad_norm": 0.137800931930542,
      "learning_rate": 1.3009750348226724e-05,
      "loss": 0.2233,
      "step": 32620
    },
    {
      "epoch": 3.4961962927247403,
      "grad_norm": 17.5216064453125,
      "learning_rate": 1.3007607414550521e-05,
      "loss": 0.1657,
      "step": 32630
    },
    {
      "epoch": 3.4972677595628414,
      "grad_norm": 0.07873900234699249,
      "learning_rate": 1.3005464480874317e-05,
      "loss": 0.4531,
      "step": 32640
    },
    {
      "epoch": 3.498339226400943,
      "grad_norm": 0.22292307019233704,
      "learning_rate": 1.3003321547198116e-05,
      "loss": 0.4246,
      "step": 32650
    },
    {
      "epoch": 3.499410693239044,
      "grad_norm": 0.02635008841753006,
      "learning_rate": 1.3001178613521912e-05,
      "loss": 0.5241,
      "step": 32660
    },
    {
      "epoch": 3.5004821600771456,
      "grad_norm": 0.10222279280424118,
      "learning_rate": 1.299903567984571e-05,
      "loss": 0.0156,
      "step": 32670
    },
    {
      "epoch": 3.501553626915247,
      "grad_norm": 0.03866126760840416,
      "learning_rate": 1.2996892746169506e-05,
      "loss": 0.1564,
      "step": 32680
    },
    {
      "epoch": 3.5026250937533483,
      "grad_norm": 0.0032203965820372105,
      "learning_rate": 1.2994749812493304e-05,
      "loss": 0.0347,
      "step": 32690
    },
    {
      "epoch": 3.50369656059145,
      "grad_norm": 0.06567628681659698,
      "learning_rate": 1.2992606878817103e-05,
      "loss": 0.2268,
      "step": 32700
    },
    {
      "epoch": 3.504768027429551,
      "grad_norm": 0.023357434198260307,
      "learning_rate": 1.2990463945140898e-05,
      "loss": 0.1936,
      "step": 32710
    },
    {
      "epoch": 3.5058394942676525,
      "grad_norm": 170.1279754638672,
      "learning_rate": 1.2988321011464696e-05,
      "loss": 0.3537,
      "step": 32720
    },
    {
      "epoch": 3.5069109611057536,
      "grad_norm": 0.02228039689362049,
      "learning_rate": 1.2986178077788493e-05,
      "loss": 0.164,
      "step": 32730
    },
    {
      "epoch": 3.507982427943855,
      "grad_norm": 0.3358997404575348,
      "learning_rate": 1.298403514411229e-05,
      "loss": 0.0022,
      "step": 32740
    },
    {
      "epoch": 3.5090538947819567,
      "grad_norm": 0.40331676602363586,
      "learning_rate": 1.298189221043609e-05,
      "loss": 0.448,
      "step": 32750
    },
    {
      "epoch": 3.510125361620058,
      "grad_norm": 0.17804643511772156,
      "learning_rate": 1.2979749276759885e-05,
      "loss": 0.6281,
      "step": 32760
    },
    {
      "epoch": 3.511196828458159,
      "grad_norm": 0.3205428123474121,
      "learning_rate": 1.2977606343083682e-05,
      "loss": 0.2659,
      "step": 32770
    },
    {
      "epoch": 3.5122682952962605,
      "grad_norm": 0.13882656395435333,
      "learning_rate": 1.297546340940748e-05,
      "loss": 0.2997,
      "step": 32780
    },
    {
      "epoch": 3.513339762134362,
      "grad_norm": 0.12330803275108337,
      "learning_rate": 1.2973320475731277e-05,
      "loss": 0.7088,
      "step": 32790
    },
    {
      "epoch": 3.514411228972463,
      "grad_norm": 0.265697717666626,
      "learning_rate": 1.2971177542055073e-05,
      "loss": 0.4879,
      "step": 32800
    },
    {
      "epoch": 3.5154826958105647,
      "grad_norm": 21.207027435302734,
      "learning_rate": 1.2969034608378872e-05,
      "loss": 0.1511,
      "step": 32810
    },
    {
      "epoch": 3.5165541626486663,
      "grad_norm": 0.06065680459141731,
      "learning_rate": 1.296689167470267e-05,
      "loss": 0.3641,
      "step": 32820
    },
    {
      "epoch": 3.5176256294867674,
      "grad_norm": 0.09239640831947327,
      "learning_rate": 1.2964748741026467e-05,
      "loss": 0.0603,
      "step": 32830
    },
    {
      "epoch": 3.5186970963248685,
      "grad_norm": 0.04633387178182602,
      "learning_rate": 1.2962605807350264e-05,
      "loss": 0.376,
      "step": 32840
    },
    {
      "epoch": 3.51976856316297,
      "grad_norm": 0.23764511942863464,
      "learning_rate": 1.296046287367406e-05,
      "loss": 0.5067,
      "step": 32850
    },
    {
      "epoch": 3.5208400300010716,
      "grad_norm": 0.41947832703590393,
      "learning_rate": 1.2958319939997859e-05,
      "loss": 0.1784,
      "step": 32860
    },
    {
      "epoch": 3.5219114968391727,
      "grad_norm": 0.14330118894577026,
      "learning_rate": 1.2956177006321654e-05,
      "loss": 0.7224,
      "step": 32870
    },
    {
      "epoch": 3.5229829636772743,
      "grad_norm": 0.10858956724405289,
      "learning_rate": 1.2954034072645452e-05,
      "loss": 0.0045,
      "step": 32880
    },
    {
      "epoch": 3.524054430515376,
      "grad_norm": 0.12689965963363647,
      "learning_rate": 1.295189113896925e-05,
      "loss": 0.3851,
      "step": 32890
    },
    {
      "epoch": 3.525125897353477,
      "grad_norm": 424.60235595703125,
      "learning_rate": 1.2949748205293046e-05,
      "loss": 0.3489,
      "step": 32900
    },
    {
      "epoch": 3.526197364191578,
      "grad_norm": 0.2679167091846466,
      "learning_rate": 1.2947605271616845e-05,
      "loss": 0.0026,
      "step": 32910
    },
    {
      "epoch": 3.5272688310296796,
      "grad_norm": 25.17034912109375,
      "learning_rate": 1.2945462337940641e-05,
      "loss": 0.1369,
      "step": 32920
    },
    {
      "epoch": 3.528340297867781,
      "grad_norm": 0.0740034282207489,
      "learning_rate": 1.2943319404264438e-05,
      "loss": 0.141,
      "step": 32930
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 2.7129619121551514,
      "learning_rate": 1.2941176470588238e-05,
      "loss": 0.0037,
      "step": 32940
    },
    {
      "epoch": 3.530483231543984,
      "grad_norm": 0.08547013998031616,
      "learning_rate": 1.2939033536912033e-05,
      "loss": 0.0851,
      "step": 32950
    },
    {
      "epoch": 3.531554698382085,
      "grad_norm": 0.009970284067094326,
      "learning_rate": 1.293689060323583e-05,
      "loss": 0.0015,
      "step": 32960
    },
    {
      "epoch": 3.5326261652201865,
      "grad_norm": 47.39558410644531,
      "learning_rate": 1.2934747669559628e-05,
      "loss": 0.4552,
      "step": 32970
    },
    {
      "epoch": 3.5336976320582876,
      "grad_norm": 16.84288787841797,
      "learning_rate": 1.2932604735883425e-05,
      "loss": 0.3391,
      "step": 32980
    },
    {
      "epoch": 3.534769098896389,
      "grad_norm": 0.14657655358314514,
      "learning_rate": 1.2930461802207224e-05,
      "loss": 0.0017,
      "step": 32990
    },
    {
      "epoch": 3.5358405657344907,
      "grad_norm": 0.0309300497174263,
      "learning_rate": 1.292831886853102e-05,
      "loss": 0.0008,
      "step": 33000
    },
    {
      "epoch": 3.536912032572592,
      "grad_norm": 0.025149034336209297,
      "learning_rate": 1.2926175934854817e-05,
      "loss": 0.4796,
      "step": 33010
    },
    {
      "epoch": 3.5379834994106933,
      "grad_norm": 0.004740591160953045,
      "learning_rate": 1.2924033001178615e-05,
      "loss": 0.3284,
      "step": 33020
    },
    {
      "epoch": 3.5390549662487945,
      "grad_norm": 0.0038603574503213167,
      "learning_rate": 1.2921890067502412e-05,
      "loss": 0.1766,
      "step": 33030
    },
    {
      "epoch": 3.540126433086896,
      "grad_norm": 0.0749238058924675,
      "learning_rate": 1.2919747133826208e-05,
      "loss": 0.5154,
      "step": 33040
    },
    {
      "epoch": 3.541197899924997,
      "grad_norm": 0.12441664934158325,
      "learning_rate": 1.2917604200150007e-05,
      "loss": 0.1831,
      "step": 33050
    },
    {
      "epoch": 3.5422693667630987,
      "grad_norm": 0.2939460873603821,
      "learning_rate": 1.2915461266473802e-05,
      "loss": 0.3273,
      "step": 33060
    },
    {
      "epoch": 3.5433408336012002,
      "grad_norm": 0.271578311920166,
      "learning_rate": 1.2913318332797601e-05,
      "loss": 0.2849,
      "step": 33070
    },
    {
      "epoch": 3.5444123004393013,
      "grad_norm": 0.10653078556060791,
      "learning_rate": 1.2911175399121399e-05,
      "loss": 0.2018,
      "step": 33080
    },
    {
      "epoch": 3.545483767277403,
      "grad_norm": 0.1695549488067627,
      "learning_rate": 1.2909032465445194e-05,
      "loss": 0.1828,
      "step": 33090
    },
    {
      "epoch": 3.546555234115504,
      "grad_norm": 0.011559553444385529,
      "learning_rate": 1.2906889531768994e-05,
      "loss": 0.162,
      "step": 33100
    },
    {
      "epoch": 3.5476267009536055,
      "grad_norm": 14.405725479125977,
      "learning_rate": 1.290474659809279e-05,
      "loss": 0.7574,
      "step": 33110
    },
    {
      "epoch": 3.5486981677917067,
      "grad_norm": 0.17046277225017548,
      "learning_rate": 1.2902603664416587e-05,
      "loss": 0.1291,
      "step": 33120
    },
    {
      "epoch": 3.549769634629808,
      "grad_norm": 0.08061081171035767,
      "learning_rate": 1.2900460730740386e-05,
      "loss": 0.1389,
      "step": 33130
    },
    {
      "epoch": 3.5508411014679098,
      "grad_norm": 0.08557508140802383,
      "learning_rate": 1.2898317797064181e-05,
      "loss": 0.1265,
      "step": 33140
    },
    {
      "epoch": 3.551912568306011,
      "grad_norm": 0.050043120980262756,
      "learning_rate": 1.289617486338798e-05,
      "loss": 0.0308,
      "step": 33150
    },
    {
      "epoch": 3.5529840351441124,
      "grad_norm": 0.0035564335994422436,
      "learning_rate": 1.2894031929711776e-05,
      "loss": 0.0019,
      "step": 33160
    },
    {
      "epoch": 3.5540555019822135,
      "grad_norm": 0.04758410155773163,
      "learning_rate": 1.2891888996035573e-05,
      "loss": 0.0021,
      "step": 33170
    },
    {
      "epoch": 3.555126968820315,
      "grad_norm": 0.10534365475177765,
      "learning_rate": 1.2889746062359372e-05,
      "loss": 0.6015,
      "step": 33180
    },
    {
      "epoch": 3.556198435658416,
      "grad_norm": 0.05409853905439377,
      "learning_rate": 1.2887603128683168e-05,
      "loss": 0.1776,
      "step": 33190
    },
    {
      "epoch": 3.5572699024965178,
      "grad_norm": 0.047618817538022995,
      "learning_rate": 1.2885460195006965e-05,
      "loss": 0.0012,
      "step": 33200
    },
    {
      "epoch": 3.5583413693346193,
      "grad_norm": 0.0484653003513813,
      "learning_rate": 1.2883317261330763e-05,
      "loss": 0.2249,
      "step": 33210
    },
    {
      "epoch": 3.5594128361727204,
      "grad_norm": 0.028035538271069527,
      "learning_rate": 1.288117432765456e-05,
      "loss": 0.8457,
      "step": 33220
    },
    {
      "epoch": 3.560484303010822,
      "grad_norm": 0.2219463586807251,
      "learning_rate": 1.287903139397836e-05,
      "loss": 0.3877,
      "step": 33230
    },
    {
      "epoch": 3.561555769848923,
      "grad_norm": 0.11876124888658524,
      "learning_rate": 1.2876888460302155e-05,
      "loss": 0.3449,
      "step": 33240
    },
    {
      "epoch": 3.5626272366870246,
      "grad_norm": 0.12049373984336853,
      "learning_rate": 1.287474552662595e-05,
      "loss": 0.3859,
      "step": 33250
    },
    {
      "epoch": 3.5636987035251257,
      "grad_norm": 1.2294262647628784,
      "learning_rate": 1.287260259294975e-05,
      "loss": 0.0162,
      "step": 33260
    },
    {
      "epoch": 3.5647701703632273,
      "grad_norm": 0.04446115717291832,
      "learning_rate": 1.2870459659273547e-05,
      "loss": 0.4732,
      "step": 33270
    },
    {
      "epoch": 3.565841637201329,
      "grad_norm": 0.028274396434426308,
      "learning_rate": 1.2868316725597343e-05,
      "loss": 0.4139,
      "step": 33280
    },
    {
      "epoch": 3.56691310403943,
      "grad_norm": 0.024177229031920433,
      "learning_rate": 1.2866173791921142e-05,
      "loss": 0.2394,
      "step": 33290
    },
    {
      "epoch": 3.567984570877531,
      "grad_norm": 98.16015625,
      "learning_rate": 1.2864030858244937e-05,
      "loss": 0.0368,
      "step": 33300
    },
    {
      "epoch": 3.5690560377156326,
      "grad_norm": 0.2790061831474304,
      "learning_rate": 1.2861887924568736e-05,
      "loss": 0.061,
      "step": 33310
    },
    {
      "epoch": 3.570127504553734,
      "grad_norm": 0.12984302639961243,
      "learning_rate": 1.2859744990892534e-05,
      "loss": 0.0038,
      "step": 33320
    },
    {
      "epoch": 3.5711989713918353,
      "grad_norm": 32.64744567871094,
      "learning_rate": 1.285760205721633e-05,
      "loss": 0.1787,
      "step": 33330
    },
    {
      "epoch": 3.572270438229937,
      "grad_norm": 0.22203262150287628,
      "learning_rate": 1.2855459123540128e-05,
      "loss": 0.0014,
      "step": 33340
    },
    {
      "epoch": 3.5733419050680384,
      "grad_norm": 0.006354487035423517,
      "learning_rate": 1.2853316189863924e-05,
      "loss": 0.091,
      "step": 33350
    },
    {
      "epoch": 3.5744133719061395,
      "grad_norm": 0.010177088901400566,
      "learning_rate": 1.2851173256187721e-05,
      "loss": 0.001,
      "step": 33360
    },
    {
      "epoch": 3.5754848387442406,
      "grad_norm": 0.07071210443973541,
      "learning_rate": 1.284903032251152e-05,
      "loss": 0.3606,
      "step": 33370
    },
    {
      "epoch": 3.576556305582342,
      "grad_norm": 0.00420219823718071,
      "learning_rate": 1.2846887388835316e-05,
      "loss": 0.0746,
      "step": 33380
    },
    {
      "epoch": 3.5776277724204437,
      "grad_norm": 21.601097106933594,
      "learning_rate": 1.2844744455159115e-05,
      "loss": 0.5546,
      "step": 33390
    },
    {
      "epoch": 3.578699239258545,
      "grad_norm": 0.2359006553888321,
      "learning_rate": 1.284260152148291e-05,
      "loss": 0.2098,
      "step": 33400
    },
    {
      "epoch": 3.5797707060966464,
      "grad_norm": 32.546478271484375,
      "learning_rate": 1.2840458587806708e-05,
      "loss": 0.3437,
      "step": 33410
    },
    {
      "epoch": 3.580842172934748,
      "grad_norm": 0.10165611654520035,
      "learning_rate": 1.2838315654130507e-05,
      "loss": 0.0013,
      "step": 33420
    },
    {
      "epoch": 3.581913639772849,
      "grad_norm": 0.003310596803203225,
      "learning_rate": 1.2836172720454303e-05,
      "loss": 0.002,
      "step": 33430
    },
    {
      "epoch": 3.58298510661095,
      "grad_norm": 0.005453310441225767,
      "learning_rate": 1.2834029786778099e-05,
      "loss": 0.262,
      "step": 33440
    },
    {
      "epoch": 3.5840565734490517,
      "grad_norm": 59.12028503417969,
      "learning_rate": 1.2831886853101898e-05,
      "loss": 0.4382,
      "step": 33450
    },
    {
      "epoch": 3.5851280402871533,
      "grad_norm": 0.01675805263221264,
      "learning_rate": 1.2829743919425695e-05,
      "loss": 0.1239,
      "step": 33460
    },
    {
      "epoch": 3.5861995071252544,
      "grad_norm": 0.04991071671247482,
      "learning_rate": 1.2827600985749494e-05,
      "loss": 0.4144,
      "step": 33470
    },
    {
      "epoch": 3.587270973963356,
      "grad_norm": 0.016558630391955376,
      "learning_rate": 1.282545805207329e-05,
      "loss": 0.4436,
      "step": 33480
    },
    {
      "epoch": 3.588342440801457,
      "grad_norm": 131.649169921875,
      "learning_rate": 1.2823315118397085e-05,
      "loss": 0.3856,
      "step": 33490
    },
    {
      "epoch": 3.5894139076395586,
      "grad_norm": 0.77973473072052,
      "learning_rate": 1.2821172184720884e-05,
      "loss": 0.4217,
      "step": 33500
    },
    {
      "epoch": 3.5904853744776597,
      "grad_norm": 0.043197985738515854,
      "learning_rate": 1.2819029251044682e-05,
      "loss": 0.2135,
      "step": 33510
    },
    {
      "epoch": 3.5915568413157613,
      "grad_norm": 0.021257927641272545,
      "learning_rate": 1.2816886317368477e-05,
      "loss": 0.2229,
      "step": 33520
    },
    {
      "epoch": 3.592628308153863,
      "grad_norm": 2.649684429168701,
      "learning_rate": 1.2814743383692276e-05,
      "loss": 0.2867,
      "step": 33530
    },
    {
      "epoch": 3.593699774991964,
      "grad_norm": 29.335988998413086,
      "learning_rate": 1.2812600450016072e-05,
      "loss": 0.4516,
      "step": 33540
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 9.523660659790039,
      "learning_rate": 1.281045751633987e-05,
      "loss": 0.2644,
      "step": 33550
    },
    {
      "epoch": 3.5958427086681666,
      "grad_norm": 1.1858409643173218,
      "learning_rate": 1.2808314582663669e-05,
      "loss": 0.3794,
      "step": 33560
    },
    {
      "epoch": 3.596914175506268,
      "grad_norm": 0.011213407851755619,
      "learning_rate": 1.2806171648987464e-05,
      "loss": 0.0029,
      "step": 33570
    },
    {
      "epoch": 3.5979856423443692,
      "grad_norm": 0.18227148056030273,
      "learning_rate": 1.2804028715311263e-05,
      "loss": 0.1543,
      "step": 33580
    },
    {
      "epoch": 3.599057109182471,
      "grad_norm": 0.19909033179283142,
      "learning_rate": 1.2801885781635059e-05,
      "loss": 0.2138,
      "step": 33590
    },
    {
      "epoch": 3.6001285760205723,
      "grad_norm": 0.015080997720360756,
      "learning_rate": 1.2799742847958856e-05,
      "loss": 0.2609,
      "step": 33600
    },
    {
      "epoch": 3.6012000428586735,
      "grad_norm": 0.03763565421104431,
      "learning_rate": 1.2797599914282655e-05,
      "loss": 0.4826,
      "step": 33610
    },
    {
      "epoch": 3.602271509696775,
      "grad_norm": 0.09753330796957016,
      "learning_rate": 1.2795456980606451e-05,
      "loss": 0.5132,
      "step": 33620
    },
    {
      "epoch": 3.603342976534876,
      "grad_norm": 25.876680374145508,
      "learning_rate": 1.2793314046930248e-05,
      "loss": 0.2698,
      "step": 33630
    },
    {
      "epoch": 3.6044144433729777,
      "grad_norm": 0.10706035792827606,
      "learning_rate": 1.2791171113254046e-05,
      "loss": 0.0033,
      "step": 33640
    },
    {
      "epoch": 3.605485910211079,
      "grad_norm": 15.808445930480957,
      "learning_rate": 1.2789028179577843e-05,
      "loss": 0.1931,
      "step": 33650
    },
    {
      "epoch": 3.6065573770491803,
      "grad_norm": 0.0512077771127224,
      "learning_rate": 1.2786885245901642e-05,
      "loss": 0.2141,
      "step": 33660
    },
    {
      "epoch": 3.607628843887282,
      "grad_norm": 0.055386900901794434,
      "learning_rate": 1.2784742312225438e-05,
      "loss": 0.1986,
      "step": 33670
    },
    {
      "epoch": 3.608700310725383,
      "grad_norm": 0.30316758155822754,
      "learning_rate": 1.2782599378549233e-05,
      "loss": 0.1392,
      "step": 33680
    },
    {
      "epoch": 3.6097717775634846,
      "grad_norm": 0.02447998709976673,
      "learning_rate": 1.2780456444873032e-05,
      "loss": 0.2432,
      "step": 33690
    },
    {
      "epoch": 3.6108432444015857,
      "grad_norm": 0.1486700028181076,
      "learning_rate": 1.277831351119683e-05,
      "loss": 0.7166,
      "step": 33700
    },
    {
      "epoch": 3.611914711239687,
      "grad_norm": 127.72328186035156,
      "learning_rate": 1.2776170577520625e-05,
      "loss": 0.3543,
      "step": 33710
    },
    {
      "epoch": 3.6129861780777883,
      "grad_norm": 0.028988342732191086,
      "learning_rate": 1.2774027643844425e-05,
      "loss": 0.2836,
      "step": 33720
    },
    {
      "epoch": 3.61405764491589,
      "grad_norm": 0.009284423664212227,
      "learning_rate": 1.277188471016822e-05,
      "loss": 0.6635,
      "step": 33730
    },
    {
      "epoch": 3.6151291117539914,
      "grad_norm": 0.08462492376565933,
      "learning_rate": 1.276974177649202e-05,
      "loss": 0.4558,
      "step": 33740
    },
    {
      "epoch": 3.6162005785920925,
      "grad_norm": 19.60613441467285,
      "learning_rate": 1.2767598842815817e-05,
      "loss": 0.5342,
      "step": 33750
    },
    {
      "epoch": 3.617272045430194,
      "grad_norm": 0.3210546672344208,
      "learning_rate": 1.2765455909139612e-05,
      "loss": 0.1033,
      "step": 33760
    },
    {
      "epoch": 3.618343512268295,
      "grad_norm": 0.11948668211698532,
      "learning_rate": 1.2763312975463411e-05,
      "loss": 0.1717,
      "step": 33770
    },
    {
      "epoch": 3.6194149791063968,
      "grad_norm": 0.10736867785453796,
      "learning_rate": 1.2761170041787207e-05,
      "loss": 0.0015,
      "step": 33780
    },
    {
      "epoch": 3.620486445944498,
      "grad_norm": 0.36541232466697693,
      "learning_rate": 1.2759027108111004e-05,
      "loss": 0.1604,
      "step": 33790
    },
    {
      "epoch": 3.6215579127825994,
      "grad_norm": 0.04529377818107605,
      "learning_rate": 1.2756884174434803e-05,
      "loss": 0.2862,
      "step": 33800
    },
    {
      "epoch": 3.622629379620701,
      "grad_norm": 0.011340340599417686,
      "learning_rate": 1.2754741240758599e-05,
      "loss": 0.6964,
      "step": 33810
    },
    {
      "epoch": 3.623700846458802,
      "grad_norm": 0.3823471963405609,
      "learning_rate": 1.2752598307082398e-05,
      "loss": 0.3452,
      "step": 33820
    },
    {
      "epoch": 3.624772313296903,
      "grad_norm": 0.06801200658082962,
      "learning_rate": 1.2750455373406194e-05,
      "loss": 0.0017,
      "step": 33830
    },
    {
      "epoch": 3.6258437801350047,
      "grad_norm": 2.3317043781280518,
      "learning_rate": 1.2748312439729991e-05,
      "loss": 0.1521,
      "step": 33840
    },
    {
      "epoch": 3.6269152469731063,
      "grad_norm": 0.06092628836631775,
      "learning_rate": 1.274616950605379e-05,
      "loss": 0.0297,
      "step": 33850
    },
    {
      "epoch": 3.6279867138112074,
      "grad_norm": 0.0031914045102894306,
      "learning_rate": 1.2744026572377586e-05,
      "loss": 0.1381,
      "step": 33860
    },
    {
      "epoch": 3.629058180649309,
      "grad_norm": 0.00485086627304554,
      "learning_rate": 1.2741883638701381e-05,
      "loss": 0.0959,
      "step": 33870
    },
    {
      "epoch": 3.6301296474874105,
      "grad_norm": 0.043212734162807465,
      "learning_rate": 1.273974070502518e-05,
      "loss": 0.0007,
      "step": 33880
    },
    {
      "epoch": 3.6312011143255116,
      "grad_norm": 0.004636434372514486,
      "learning_rate": 1.2737597771348978e-05,
      "loss": 0.0885,
      "step": 33890
    },
    {
      "epoch": 3.6322725811636127,
      "grad_norm": 0.07506527006626129,
      "learning_rate": 1.2735454837672775e-05,
      "loss": 0.118,
      "step": 33900
    },
    {
      "epoch": 3.6333440480017143,
      "grad_norm": 0.14033058285713196,
      "learning_rate": 1.2733311903996573e-05,
      "loss": 0.0508,
      "step": 33910
    },
    {
      "epoch": 3.634415514839816,
      "grad_norm": 13.79149055480957,
      "learning_rate": 1.2731168970320368e-05,
      "loss": 0.4036,
      "step": 33920
    },
    {
      "epoch": 3.635486981677917,
      "grad_norm": 0.004060419742017984,
      "learning_rate": 1.2729026036644167e-05,
      "loss": 0.1969,
      "step": 33930
    },
    {
      "epoch": 3.6365584485160185,
      "grad_norm": 0.8914320468902588,
      "learning_rate": 1.2726883102967965e-05,
      "loss": 0.1764,
      "step": 33940
    },
    {
      "epoch": 3.63762991535412,
      "grad_norm": 1.0473881959915161,
      "learning_rate": 1.272474016929176e-05,
      "loss": 0.3526,
      "step": 33950
    },
    {
      "epoch": 3.638701382192221,
      "grad_norm": 0.0052813454531133175,
      "learning_rate": 1.272259723561556e-05,
      "loss": 0.0031,
      "step": 33960
    },
    {
      "epoch": 3.6397728490303223,
      "grad_norm": 23.6435489654541,
      "learning_rate": 1.2720454301939355e-05,
      "loss": 0.6462,
      "step": 33970
    },
    {
      "epoch": 3.640844315868424,
      "grad_norm": 0.017848940566182137,
      "learning_rate": 1.2718311368263154e-05,
      "loss": 0.0006,
      "step": 33980
    },
    {
      "epoch": 3.6419157827065254,
      "grad_norm": 0.026819348335266113,
      "learning_rate": 1.2716168434586951e-05,
      "loss": 0.2926,
      "step": 33990
    },
    {
      "epoch": 3.6429872495446265,
      "grad_norm": 0.012296314351260662,
      "learning_rate": 1.2714025500910747e-05,
      "loss": 0.0007,
      "step": 34000
    },
    {
      "epoch": 3.644058716382728,
      "grad_norm": 0.00689260708168149,
      "learning_rate": 1.2711882567234546e-05,
      "loss": 0.2604,
      "step": 34010
    },
    {
      "epoch": 3.645130183220829,
      "grad_norm": 0.06262348592281342,
      "learning_rate": 1.2709739633558342e-05,
      "loss": 0.4349,
      "step": 34020
    },
    {
      "epoch": 3.6462016500589307,
      "grad_norm": 0.13209988176822662,
      "learning_rate": 1.270759669988214e-05,
      "loss": 0.5723,
      "step": 34030
    },
    {
      "epoch": 3.647273116897032,
      "grad_norm": 0.037701789289712906,
      "learning_rate": 1.2705453766205938e-05,
      "loss": 0.4204,
      "step": 34040
    },
    {
      "epoch": 3.6483445837351334,
      "grad_norm": 0.007383686024695635,
      "learning_rate": 1.2703310832529734e-05,
      "loss": 0.2097,
      "step": 34050
    },
    {
      "epoch": 3.649416050573235,
      "grad_norm": 0.14773136377334595,
      "learning_rate": 1.2701167898853533e-05,
      "loss": 0.2054,
      "step": 34060
    },
    {
      "epoch": 3.650487517411336,
      "grad_norm": 0.1061776801943779,
      "learning_rate": 1.2699024965177329e-05,
      "loss": 0.0022,
      "step": 34070
    },
    {
      "epoch": 3.6515589842494376,
      "grad_norm": 0.16112196445465088,
      "learning_rate": 1.2696882031501126e-05,
      "loss": 0.5105,
      "step": 34080
    },
    {
      "epoch": 3.6526304510875387,
      "grad_norm": 0.03714795038104057,
      "learning_rate": 1.2694739097824923e-05,
      "loss": 0.2378,
      "step": 34090
    },
    {
      "epoch": 3.6537019179256403,
      "grad_norm": 17.042253494262695,
      "learning_rate": 1.269259616414872e-05,
      "loss": 0.1968,
      "step": 34100
    },
    {
      "epoch": 3.6547733847637414,
      "grad_norm": 44.24235153198242,
      "learning_rate": 1.2690453230472516e-05,
      "loss": 0.5694,
      "step": 34110
    },
    {
      "epoch": 3.655844851601843,
      "grad_norm": 0.0836661159992218,
      "learning_rate": 1.2688310296796315e-05,
      "loss": 0.3526,
      "step": 34120
    },
    {
      "epoch": 3.6569163184399445,
      "grad_norm": 0.07610294967889786,
      "learning_rate": 1.2686167363120113e-05,
      "loss": 0.0044,
      "step": 34130
    },
    {
      "epoch": 3.6579877852780456,
      "grad_norm": 0.1334812045097351,
      "learning_rate": 1.268402442944391e-05,
      "loss": 0.2317,
      "step": 34140
    },
    {
      "epoch": 3.659059252116147,
      "grad_norm": 0.1556103527545929,
      "learning_rate": 1.2681881495767707e-05,
      "loss": 0.2865,
      "step": 34150
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 18.78805160522461,
      "learning_rate": 1.2679738562091503e-05,
      "loss": 0.2092,
      "step": 34160
    },
    {
      "epoch": 3.66120218579235,
      "grad_norm": 30.994657516479492,
      "learning_rate": 1.2677595628415302e-05,
      "loss": 0.4074,
      "step": 34170
    },
    {
      "epoch": 3.662273652630451,
      "grad_norm": 0.03903855383396149,
      "learning_rate": 1.26754526947391e-05,
      "loss": 0.3098,
      "step": 34180
    },
    {
      "epoch": 3.6633451194685525,
      "grad_norm": 0.02175174094736576,
      "learning_rate": 1.2673309761062895e-05,
      "loss": 0.2049,
      "step": 34190
    },
    {
      "epoch": 3.664416586306654,
      "grad_norm": 0.03144822269678116,
      "learning_rate": 1.2671166827386694e-05,
      "loss": 0.1719,
      "step": 34200
    },
    {
      "epoch": 3.665488053144755,
      "grad_norm": 0.028970137238502502,
      "learning_rate": 1.266902389371049e-05,
      "loss": 0.498,
      "step": 34210
    },
    {
      "epoch": 3.6665595199828567,
      "grad_norm": 0.7925132513046265,
      "learning_rate": 1.2666880960034289e-05,
      "loss": 0.0129,
      "step": 34220
    },
    {
      "epoch": 3.667630986820958,
      "grad_norm": 0.01981181465089321,
      "learning_rate": 1.2664738026358086e-05,
      "loss": 0.0702,
      "step": 34230
    },
    {
      "epoch": 3.6687024536590593,
      "grad_norm": 0.21379448473453522,
      "learning_rate": 1.2662595092681882e-05,
      "loss": 0.23,
      "step": 34240
    },
    {
      "epoch": 3.6697739204971604,
      "grad_norm": 0.0685187503695488,
      "learning_rate": 1.2660452159005681e-05,
      "loss": 0.0009,
      "step": 34250
    },
    {
      "epoch": 3.670845387335262,
      "grad_norm": 0.0746476948261261,
      "learning_rate": 1.2658309225329477e-05,
      "loss": 0.4312,
      "step": 34260
    },
    {
      "epoch": 3.6719168541733636,
      "grad_norm": 1.4385432004928589,
      "learning_rate": 1.2656166291653274e-05,
      "loss": 0.2237,
      "step": 34270
    },
    {
      "epoch": 3.6729883210114647,
      "grad_norm": 0.014305812306702137,
      "learning_rate": 1.2654023357977071e-05,
      "loss": 0.0189,
      "step": 34280
    },
    {
      "epoch": 3.674059787849566,
      "grad_norm": 0.012310788035392761,
      "learning_rate": 1.2651880424300869e-05,
      "loss": 0.3639,
      "step": 34290
    },
    {
      "epoch": 3.6751312546876673,
      "grad_norm": 0.15689480304718018,
      "learning_rate": 1.2649737490624668e-05,
      "loss": 0.0203,
      "step": 34300
    },
    {
      "epoch": 3.676202721525769,
      "grad_norm": 0.050361402332782745,
      "learning_rate": 1.2647594556948463e-05,
      "loss": 0.1882,
      "step": 34310
    },
    {
      "epoch": 3.67727418836387,
      "grad_norm": 0.1949685662984848,
      "learning_rate": 1.264545162327226e-05,
      "loss": 0.4171,
      "step": 34320
    },
    {
      "epoch": 3.6783456552019715,
      "grad_norm": 0.267073392868042,
      "learning_rate": 1.2643308689596058e-05,
      "loss": 0.3631,
      "step": 34330
    },
    {
      "epoch": 3.679417122040073,
      "grad_norm": 0.02284899353981018,
      "learning_rate": 1.2641165755919856e-05,
      "loss": 0.0015,
      "step": 34340
    },
    {
      "epoch": 3.680488588878174,
      "grad_norm": 0.2619933784008026,
      "learning_rate": 1.2639022822243651e-05,
      "loss": 0.0018,
      "step": 34350
    },
    {
      "epoch": 3.6815600557162753,
      "grad_norm": 23.231687545776367,
      "learning_rate": 1.263687988856745e-05,
      "loss": 0.2116,
      "step": 34360
    },
    {
      "epoch": 3.682631522554377,
      "grad_norm": 0.022780993953347206,
      "learning_rate": 1.2634736954891248e-05,
      "loss": 0.4129,
      "step": 34370
    },
    {
      "epoch": 3.6837029893924784,
      "grad_norm": 0.1728672832250595,
      "learning_rate": 1.2632594021215045e-05,
      "loss": 0.2602,
      "step": 34380
    },
    {
      "epoch": 3.6847744562305795,
      "grad_norm": 0.13121797144412994,
      "learning_rate": 1.2630451087538842e-05,
      "loss": 0.1446,
      "step": 34390
    },
    {
      "epoch": 3.685845923068681,
      "grad_norm": 0.05303981155157089,
      "learning_rate": 1.2628308153862638e-05,
      "loss": 0.1861,
      "step": 34400
    },
    {
      "epoch": 3.6869173899067826,
      "grad_norm": 0.028598450124263763,
      "learning_rate": 1.2626165220186437e-05,
      "loss": 0.1041,
      "step": 34410
    },
    {
      "epoch": 3.6879888567448837,
      "grad_norm": 0.031823500990867615,
      "learning_rate": 1.2624022286510234e-05,
      "loss": 0.0684,
      "step": 34420
    },
    {
      "epoch": 3.689060323582985,
      "grad_norm": 0.1031859964132309,
      "learning_rate": 1.262187935283403e-05,
      "loss": 0.3591,
      "step": 34430
    },
    {
      "epoch": 3.6901317904210864,
      "grad_norm": 0.014279107563197613,
      "learning_rate": 1.2619736419157829e-05,
      "loss": 0.3799,
      "step": 34440
    },
    {
      "epoch": 3.691203257259188,
      "grad_norm": 0.05208117142319679,
      "learning_rate": 1.2617593485481625e-05,
      "loss": 0.0541,
      "step": 34450
    },
    {
      "epoch": 3.692274724097289,
      "grad_norm": 0.031881943345069885,
      "learning_rate": 1.2615450551805422e-05,
      "loss": 0.0014,
      "step": 34460
    },
    {
      "epoch": 3.6933461909353906,
      "grad_norm": 0.21229436993598938,
      "learning_rate": 1.261330761812922e-05,
      "loss": 0.3325,
      "step": 34470
    },
    {
      "epoch": 3.694417657773492,
      "grad_norm": 0.007843646220862865,
      "learning_rate": 1.2611164684453017e-05,
      "loss": 0.4158,
      "step": 34480
    },
    {
      "epoch": 3.6954891246115933,
      "grad_norm": 0.11538543552160263,
      "learning_rate": 1.2609021750776816e-05,
      "loss": 0.5643,
      "step": 34490
    },
    {
      "epoch": 3.6965605914496944,
      "grad_norm": 0.07729435712099075,
      "learning_rate": 1.2606878817100612e-05,
      "loss": 0.345,
      "step": 34500
    },
    {
      "epoch": 3.697632058287796,
      "grad_norm": 0.06627841293811798,
      "learning_rate": 1.2604735883424409e-05,
      "loss": 0.2055,
      "step": 34510
    },
    {
      "epoch": 3.6987035251258975,
      "grad_norm": 0.1152203381061554,
      "learning_rate": 1.2602592949748206e-05,
      "loss": 0.6026,
      "step": 34520
    },
    {
      "epoch": 3.6997749919639986,
      "grad_norm": 0.11829186975955963,
      "learning_rate": 1.2600450016072004e-05,
      "loss": 0.1841,
      "step": 34530
    },
    {
      "epoch": 3.7008464588021,
      "grad_norm": 0.05973081663250923,
      "learning_rate": 1.25983070823958e-05,
      "loss": 0.1122,
      "step": 34540
    },
    {
      "epoch": 3.7019179256402013,
      "grad_norm": 0.15768811106681824,
      "learning_rate": 1.2596164148719598e-05,
      "loss": 0.1731,
      "step": 34550
    },
    {
      "epoch": 3.702989392478303,
      "grad_norm": 14.271893501281738,
      "learning_rate": 1.2594021215043396e-05,
      "loss": 0.2207,
      "step": 34560
    },
    {
      "epoch": 3.704060859316404,
      "grad_norm": 1.4557490348815918,
      "learning_rate": 1.2591878281367193e-05,
      "loss": 0.172,
      "step": 34570
    },
    {
      "epoch": 3.7051323261545055,
      "grad_norm": 0.06148763746023178,
      "learning_rate": 1.258973534769099e-05,
      "loss": 0.1554,
      "step": 34580
    },
    {
      "epoch": 3.706203792992607,
      "grad_norm": 0.13092121481895447,
      "learning_rate": 1.2587592414014786e-05,
      "loss": 0.425,
      "step": 34590
    },
    {
      "epoch": 3.707275259830708,
      "grad_norm": 0.006258504930883646,
      "learning_rate": 1.2585449480338585e-05,
      "loss": 0.1808,
      "step": 34600
    },
    {
      "epoch": 3.7083467266688097,
      "grad_norm": 0.004570253659039736,
      "learning_rate": 1.2583306546662382e-05,
      "loss": 0.489,
      "step": 34610
    },
    {
      "epoch": 3.709418193506911,
      "grad_norm": 0.7688549757003784,
      "learning_rate": 1.2581163612986178e-05,
      "loss": 0.1927,
      "step": 34620
    },
    {
      "epoch": 3.7104896603450124,
      "grad_norm": 14.301462173461914,
      "learning_rate": 1.2579020679309977e-05,
      "loss": 0.4772,
      "step": 34630
    },
    {
      "epoch": 3.7115611271831135,
      "grad_norm": 0.116115041077137,
      "learning_rate": 1.2576877745633773e-05,
      "loss": 0.2441,
      "step": 34640
    },
    {
      "epoch": 3.712632594021215,
      "grad_norm": 17.120397567749023,
      "learning_rate": 1.2574734811957572e-05,
      "loss": 0.1668,
      "step": 34650
    },
    {
      "epoch": 3.7137040608593166,
      "grad_norm": 0.1142641007900238,
      "learning_rate": 1.2572591878281368e-05,
      "loss": 0.2592,
      "step": 34660
    },
    {
      "epoch": 3.7147755276974177,
      "grad_norm": 0.05657050758600235,
      "learning_rate": 1.2570448944605165e-05,
      "loss": 0.1573,
      "step": 34670
    },
    {
      "epoch": 3.7158469945355193,
      "grad_norm": 0.08590669184923172,
      "learning_rate": 1.2568306010928964e-05,
      "loss": 0.1419,
      "step": 34680
    },
    {
      "epoch": 3.7169184613736204,
      "grad_norm": 0.20563752949237823,
      "learning_rate": 1.256616307725276e-05,
      "loss": 0.1321,
      "step": 34690
    },
    {
      "epoch": 3.717989928211722,
      "grad_norm": 27.886432647705078,
      "learning_rate": 1.2564020143576557e-05,
      "loss": 0.4675,
      "step": 34700
    },
    {
      "epoch": 3.719061395049823,
      "grad_norm": 0.049681853502988815,
      "learning_rate": 1.2561877209900354e-05,
      "loss": 0.0622,
      "step": 34710
    },
    {
      "epoch": 3.7201328618879246,
      "grad_norm": 0.05631445348262787,
      "learning_rate": 1.2559734276224152e-05,
      "loss": 0.1715,
      "step": 34720
    },
    {
      "epoch": 3.721204328726026,
      "grad_norm": 0.2586556077003479,
      "learning_rate": 1.255759134254795e-05,
      "loss": 0.456,
      "step": 34730
    },
    {
      "epoch": 3.7222757955641272,
      "grad_norm": 15.415125846862793,
      "learning_rate": 1.2555448408871746e-05,
      "loss": 0.5438,
      "step": 34740
    },
    {
      "epoch": 3.723347262402229,
      "grad_norm": 0.11571373045444489,
      "learning_rate": 1.2553305475195544e-05,
      "loss": 0.681,
      "step": 34750
    },
    {
      "epoch": 3.72441872924033,
      "grad_norm": 1.0319186449050903,
      "learning_rate": 1.2551162541519341e-05,
      "loss": 0.6491,
      "step": 34760
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 1.5386263132095337,
      "learning_rate": 1.2549019607843138e-05,
      "loss": 0.0503,
      "step": 34770
    },
    {
      "epoch": 3.7265616629165326,
      "grad_norm": 0.01403087005019188,
      "learning_rate": 1.2546876674166934e-05,
      "loss": 0.0056,
      "step": 34780
    },
    {
      "epoch": 3.727633129754634,
      "grad_norm": 5.690417289733887,
      "learning_rate": 1.2544733740490733e-05,
      "loss": 0.0063,
      "step": 34790
    },
    {
      "epoch": 3.7287045965927357,
      "grad_norm": 0.05168582499027252,
      "learning_rate": 1.254259080681453e-05,
      "loss": 0.1749,
      "step": 34800
    },
    {
      "epoch": 3.729776063430837,
      "grad_norm": 0.12460516393184662,
      "learning_rate": 1.2540447873138328e-05,
      "loss": 0.5476,
      "step": 34810
    },
    {
      "epoch": 3.7308475302689383,
      "grad_norm": 14.039822578430176,
      "learning_rate": 1.2538304939462125e-05,
      "loss": 0.7118,
      "step": 34820
    },
    {
      "epoch": 3.7319189971070394,
      "grad_norm": 0.009874965995550156,
      "learning_rate": 1.2536162005785921e-05,
      "loss": 0.0017,
      "step": 34830
    },
    {
      "epoch": 3.732990463945141,
      "grad_norm": 1.5564152002334595,
      "learning_rate": 1.253401907210972e-05,
      "loss": 0.0075,
      "step": 34840
    },
    {
      "epoch": 3.734061930783242,
      "grad_norm": 0.03163456544280052,
      "learning_rate": 1.2531876138433516e-05,
      "loss": 0.5234,
      "step": 34850
    },
    {
      "epoch": 3.7351333976213437,
      "grad_norm": 0.2254505604505539,
      "learning_rate": 1.2529733204757313e-05,
      "loss": 0.2941,
      "step": 34860
    },
    {
      "epoch": 3.736204864459445,
      "grad_norm": 0.011203735135495663,
      "learning_rate": 1.2527590271081112e-05,
      "loss": 0.2081,
      "step": 34870
    },
    {
      "epoch": 3.7372763312975463,
      "grad_norm": 0.0455625094473362,
      "learning_rate": 1.2525447337404908e-05,
      "loss": 0.2329,
      "step": 34880
    },
    {
      "epoch": 3.7383477981356474,
      "grad_norm": 0.06285320222377777,
      "learning_rate": 1.2523304403728707e-05,
      "loss": 0.2145,
      "step": 34890
    },
    {
      "epoch": 3.739419264973749,
      "grad_norm": 0.11739528179168701,
      "learning_rate": 1.2521161470052502e-05,
      "loss": 0.2048,
      "step": 34900
    },
    {
      "epoch": 3.7404907318118505,
      "grad_norm": 0.0691206306219101,
      "learning_rate": 1.25190185363763e-05,
      "loss": 0.0216,
      "step": 34910
    },
    {
      "epoch": 3.7415621986499517,
      "grad_norm": 0.027890589088201523,
      "learning_rate": 1.2516875602700099e-05,
      "loss": 0.1748,
      "step": 34920
    },
    {
      "epoch": 3.742633665488053,
      "grad_norm": 0.06292365491390228,
      "learning_rate": 1.2514732669023894e-05,
      "loss": 0.8346,
      "step": 34930
    },
    {
      "epoch": 3.7437051323261548,
      "grad_norm": 0.12950624525547028,
      "learning_rate": 1.2512589735347692e-05,
      "loss": 0.1976,
      "step": 34940
    },
    {
      "epoch": 3.744776599164256,
      "grad_norm": 457.7425231933594,
      "learning_rate": 1.2510446801671489e-05,
      "loss": 0.7953,
      "step": 34950
    },
    {
      "epoch": 3.745848066002357,
      "grad_norm": 0.6714069843292236,
      "learning_rate": 1.2508303867995286e-05,
      "loss": 0.2629,
      "step": 34960
    },
    {
      "epoch": 3.7469195328404585,
      "grad_norm": 0.01230233907699585,
      "learning_rate": 1.2506160934319086e-05,
      "loss": 0.1513,
      "step": 34970
    },
    {
      "epoch": 3.74799099967856,
      "grad_norm": 0.044247277081012726,
      "learning_rate": 1.2504018000642881e-05,
      "loss": 0.002,
      "step": 34980
    },
    {
      "epoch": 3.749062466516661,
      "grad_norm": 0.11991465091705322,
      "learning_rate": 1.2501875066966679e-05,
      "loss": 0.4084,
      "step": 34990
    },
    {
      "epoch": 3.7501339333547627,
      "grad_norm": 0.011951896362006664,
      "learning_rate": 1.2499732133290476e-05,
      "loss": 0.5484,
      "step": 35000
    },
    {
      "epoch": 3.7512054001928643,
      "grad_norm": 0.09806609153747559,
      "learning_rate": 1.2497589199614273e-05,
      "loss": 0.4733,
      "step": 35010
    },
    {
      "epoch": 3.7522768670309654,
      "grad_norm": 1.513785719871521,
      "learning_rate": 1.2495446265938069e-05,
      "loss": 0.0263,
      "step": 35020
    },
    {
      "epoch": 3.7533483338690665,
      "grad_norm": 0.09694725275039673,
      "learning_rate": 1.2493303332261868e-05,
      "loss": 0.2191,
      "step": 35030
    },
    {
      "epoch": 3.754419800707168,
      "grad_norm": 0.01736748032271862,
      "learning_rate": 1.2491160398585664e-05,
      "loss": 0.2592,
      "step": 35040
    },
    {
      "epoch": 3.7554912675452696,
      "grad_norm": 26.622915267944336,
      "learning_rate": 1.2489017464909463e-05,
      "loss": 0.2337,
      "step": 35050
    },
    {
      "epoch": 3.7565627343833707,
      "grad_norm": 0.01631377451121807,
      "learning_rate": 1.248687453123326e-05,
      "loss": 0.0007,
      "step": 35060
    },
    {
      "epoch": 3.7576342012214723,
      "grad_norm": 16.84372901916504,
      "learning_rate": 1.2484731597557056e-05,
      "loss": 0.1649,
      "step": 35070
    },
    {
      "epoch": 3.7587056680595734,
      "grad_norm": 0.013302730396389961,
      "learning_rate": 1.2482588663880855e-05,
      "loss": 0.1114,
      "step": 35080
    },
    {
      "epoch": 3.759777134897675,
      "grad_norm": 0.17078828811645508,
      "learning_rate": 1.248044573020465e-05,
      "loss": 0.0088,
      "step": 35090
    },
    {
      "epoch": 3.760848601735776,
      "grad_norm": 26.254127502441406,
      "learning_rate": 1.2478302796528448e-05,
      "loss": 0.1633,
      "step": 35100
    },
    {
      "epoch": 3.7619200685738776,
      "grad_norm": 0.05720316618680954,
      "learning_rate": 1.2476159862852247e-05,
      "loss": 0.1288,
      "step": 35110
    },
    {
      "epoch": 3.762991535411979,
      "grad_norm": 0.007533441297709942,
      "learning_rate": 1.2474016929176042e-05,
      "loss": 0.0015,
      "step": 35120
    },
    {
      "epoch": 3.7640630022500803,
      "grad_norm": 0.027429252862930298,
      "learning_rate": 1.2471873995499842e-05,
      "loss": 0.0008,
      "step": 35130
    },
    {
      "epoch": 3.765134469088182,
      "grad_norm": 0.007035157177597284,
      "learning_rate": 1.2469731061823637e-05,
      "loss": 0.2067,
      "step": 35140
    },
    {
      "epoch": 3.766205935926283,
      "grad_norm": 0.06619659811258316,
      "learning_rate": 1.2467588128147435e-05,
      "loss": 0.415,
      "step": 35150
    },
    {
      "epoch": 3.7672774027643845,
      "grad_norm": 0.005752394907176495,
      "learning_rate": 1.2465445194471234e-05,
      "loss": 0.2243,
      "step": 35160
    },
    {
      "epoch": 3.7683488696024856,
      "grad_norm": 0.1212054118514061,
      "learning_rate": 1.246330226079503e-05,
      "loss": 0.9648,
      "step": 35170
    },
    {
      "epoch": 3.769420336440587,
      "grad_norm": 0.01846209540963173,
      "learning_rate": 1.2461159327118827e-05,
      "loss": 0.254,
      "step": 35180
    },
    {
      "epoch": 3.7704918032786887,
      "grad_norm": 0.07154438644647598,
      "learning_rate": 1.2459016393442624e-05,
      "loss": 0.2858,
      "step": 35190
    },
    {
      "epoch": 3.77156327011679,
      "grad_norm": 23.84006118774414,
      "learning_rate": 1.2456873459766421e-05,
      "loss": 0.1514,
      "step": 35200
    },
    {
      "epoch": 3.7726347369548914,
      "grad_norm": 0.03561878204345703,
      "learning_rate": 1.245473052609022e-05,
      "loss": 0.3152,
      "step": 35210
    },
    {
      "epoch": 3.7737062037929925,
      "grad_norm": 0.031315695494413376,
      "learning_rate": 1.2452587592414016e-05,
      "loss": 0.3035,
      "step": 35220
    },
    {
      "epoch": 3.774777670631094,
      "grad_norm": 0.35222485661506653,
      "learning_rate": 1.2450444658737812e-05,
      "loss": 0.1746,
      "step": 35230
    },
    {
      "epoch": 3.775849137469195,
      "grad_norm": 0.022007862105965614,
      "learning_rate": 1.244830172506161e-05,
      "loss": 0.2748,
      "step": 35240
    },
    {
      "epoch": 3.7769206043072967,
      "grad_norm": 0.018489541485905647,
      "learning_rate": 1.2446158791385408e-05,
      "loss": 0.0035,
      "step": 35250
    },
    {
      "epoch": 3.7779920711453983,
      "grad_norm": 15.225351333618164,
      "learning_rate": 1.2444015857709204e-05,
      "loss": 0.5181,
      "step": 35260
    },
    {
      "epoch": 3.7790635379834994,
      "grad_norm": 0.008132273331284523,
      "learning_rate": 1.2441872924033003e-05,
      "loss": 0.1651,
      "step": 35270
    },
    {
      "epoch": 3.780135004821601,
      "grad_norm": 0.011740036308765411,
      "learning_rate": 1.2439729990356798e-05,
      "loss": 0.3583,
      "step": 35280
    },
    {
      "epoch": 3.781206471659702,
      "grad_norm": 0.013458386063575745,
      "learning_rate": 1.2437587056680598e-05,
      "loss": 0.3332,
      "step": 35290
    },
    {
      "epoch": 3.7822779384978036,
      "grad_norm": 0.011165810748934746,
      "learning_rate": 1.2435444123004395e-05,
      "loss": 0.1652,
      "step": 35300
    },
    {
      "epoch": 3.7833494053359047,
      "grad_norm": 0.01732168160378933,
      "learning_rate": 1.243330118932819e-05,
      "loss": 0.1116,
      "step": 35310
    },
    {
      "epoch": 3.7844208721740062,
      "grad_norm": 15.978935241699219,
      "learning_rate": 1.243115825565199e-05,
      "loss": 0.1733,
      "step": 35320
    },
    {
      "epoch": 3.785492339012108,
      "grad_norm": 0.0936446487903595,
      "learning_rate": 1.2429015321975785e-05,
      "loss": 0.5742,
      "step": 35330
    },
    {
      "epoch": 3.786563805850209,
      "grad_norm": 0.02995200827717781,
      "learning_rate": 1.2426872388299583e-05,
      "loss": 0.1995,
      "step": 35340
    },
    {
      "epoch": 3.7876352726883105,
      "grad_norm": 0.1531323790550232,
      "learning_rate": 1.2424729454623382e-05,
      "loss": 0.1583,
      "step": 35350
    },
    {
      "epoch": 3.7887067395264116,
      "grad_norm": 22.127370834350586,
      "learning_rate": 1.2422586520947177e-05,
      "loss": 0.5202,
      "step": 35360
    },
    {
      "epoch": 3.789778206364513,
      "grad_norm": 0.43934518098831177,
      "learning_rate": 1.2420443587270975e-05,
      "loss": 0.6292,
      "step": 35370
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 0.17450062930583954,
      "learning_rate": 1.2418300653594772e-05,
      "loss": 0.0135,
      "step": 35380
    },
    {
      "epoch": 3.791921140040716,
      "grad_norm": 16.48326873779297,
      "learning_rate": 1.241615771991857e-05,
      "loss": 0.2802,
      "step": 35390
    },
    {
      "epoch": 3.7929926068788173,
      "grad_norm": 0.03103398159146309,
      "learning_rate": 1.2414014786242368e-05,
      "loss": 0.133,
      "step": 35400
    },
    {
      "epoch": 3.7940640737169185,
      "grad_norm": 0.021102972328662872,
      "learning_rate": 1.2411871852566164e-05,
      "loss": 0.2056,
      "step": 35410
    },
    {
      "epoch": 3.7951355405550196,
      "grad_norm": 15.845541954040527,
      "learning_rate": 1.240972891888996e-05,
      "loss": 0.8419,
      "step": 35420
    },
    {
      "epoch": 3.796207007393121,
      "grad_norm": 0.24975870549678802,
      "learning_rate": 1.2407585985213759e-05,
      "loss": 0.1578,
      "step": 35430
    },
    {
      "epoch": 3.7972784742312227,
      "grad_norm": 0.2162223607301712,
      "learning_rate": 1.2405443051537556e-05,
      "loss": 0.0751,
      "step": 35440
    },
    {
      "epoch": 3.7983499410693238,
      "grad_norm": 0.1925431340932846,
      "learning_rate": 1.2403300117861352e-05,
      "loss": 0.2196,
      "step": 35450
    },
    {
      "epoch": 3.7994214079074253,
      "grad_norm": 0.17140546441078186,
      "learning_rate": 1.2401157184185151e-05,
      "loss": 0.3115,
      "step": 35460
    },
    {
      "epoch": 3.800492874745527,
      "grad_norm": 0.04733359441161156,
      "learning_rate": 1.2399014250508947e-05,
      "loss": 0.0035,
      "step": 35470
    },
    {
      "epoch": 3.801564341583628,
      "grad_norm": 0.019304856657981873,
      "learning_rate": 1.2396871316832746e-05,
      "loss": 0.1558,
      "step": 35480
    },
    {
      "epoch": 3.802635808421729,
      "grad_norm": 0.16761831939220428,
      "learning_rate": 1.2394728383156543e-05,
      "loss": 0.0883,
      "step": 35490
    },
    {
      "epoch": 3.8037072752598307,
      "grad_norm": 0.19983342289924622,
      "learning_rate": 1.2392585449480339e-05,
      "loss": 0.0118,
      "step": 35500
    },
    {
      "epoch": 3.804778742097932,
      "grad_norm": 0.08005347102880478,
      "learning_rate": 1.2390442515804138e-05,
      "loss": 0.144,
      "step": 35510
    },
    {
      "epoch": 3.8058502089360333,
      "grad_norm": 0.08435588330030441,
      "learning_rate": 1.2388299582127933e-05,
      "loss": 0.0013,
      "step": 35520
    },
    {
      "epoch": 3.806921675774135,
      "grad_norm": 0.007580597884953022,
      "learning_rate": 1.238615664845173e-05,
      "loss": 0.1647,
      "step": 35530
    },
    {
      "epoch": 3.8079931426122364,
      "grad_norm": 16.373205184936523,
      "learning_rate": 1.238401371477553e-05,
      "loss": 0.2744,
      "step": 35540
    },
    {
      "epoch": 3.8090646094503375,
      "grad_norm": 0.006777328904718161,
      "learning_rate": 1.2381870781099325e-05,
      "loss": 0.001,
      "step": 35550
    },
    {
      "epoch": 3.8101360762884386,
      "grad_norm": 0.0059501174837350845,
      "learning_rate": 1.2379727847423124e-05,
      "loss": 0.1583,
      "step": 35560
    },
    {
      "epoch": 3.81120754312654,
      "grad_norm": 0.005699825473129749,
      "learning_rate": 1.237758491374692e-05,
      "loss": 0.162,
      "step": 35570
    },
    {
      "epoch": 3.8122790099646418,
      "grad_norm": 0.05152342468500137,
      "learning_rate": 1.2375441980070717e-05,
      "loss": 0.488,
      "step": 35580
    },
    {
      "epoch": 3.813350476802743,
      "grad_norm": 0.29902130365371704,
      "learning_rate": 1.2373299046394517e-05,
      "loss": 0.3243,
      "step": 35590
    },
    {
      "epoch": 3.8144219436408444,
      "grad_norm": 0.25235483050346375,
      "learning_rate": 1.2371156112718312e-05,
      "loss": 0.0008,
      "step": 35600
    },
    {
      "epoch": 3.8154934104789455,
      "grad_norm": 0.005281172227114439,
      "learning_rate": 1.2369013179042108e-05,
      "loss": 0.5298,
      "step": 35610
    },
    {
      "epoch": 3.816564877317047,
      "grad_norm": 0.07878062129020691,
      "learning_rate": 1.2366870245365907e-05,
      "loss": 0.4569,
      "step": 35620
    },
    {
      "epoch": 3.817636344155148,
      "grad_norm": 14.56489372253418,
      "learning_rate": 1.2364727311689704e-05,
      "loss": 0.7476,
      "step": 35630
    },
    {
      "epoch": 3.8187078109932497,
      "grad_norm": 0.05358230322599411,
      "learning_rate": 1.2362584378013502e-05,
      "loss": 0.1395,
      "step": 35640
    },
    {
      "epoch": 3.8197792778313513,
      "grad_norm": 0.4154150187969208,
      "learning_rate": 1.2360441444337299e-05,
      "loss": 0.1363,
      "step": 35650
    },
    {
      "epoch": 3.8208507446694524,
      "grad_norm": 0.010735803283751011,
      "learning_rate": 1.2358298510661095e-05,
      "loss": 0.1277,
      "step": 35660
    },
    {
      "epoch": 3.821922211507554,
      "grad_norm": 0.012518451549112797,
      "learning_rate": 1.2356155576984894e-05,
      "loss": 0.0168,
      "step": 35670
    },
    {
      "epoch": 3.822993678345655,
      "grad_norm": 0.1946040689945221,
      "learning_rate": 1.2354012643308691e-05,
      "loss": 0.3223,
      "step": 35680
    },
    {
      "epoch": 3.8240651451837566,
      "grad_norm": 0.10895664244890213,
      "learning_rate": 1.2351869709632487e-05,
      "loss": 0.3267,
      "step": 35690
    },
    {
      "epoch": 3.8251366120218577,
      "grad_norm": 0.040199100971221924,
      "learning_rate": 1.2349726775956286e-05,
      "loss": 0.1798,
      "step": 35700
    },
    {
      "epoch": 3.8262080788599593,
      "grad_norm": 15.729743003845215,
      "learning_rate": 1.2347583842280081e-05,
      "loss": 0.4467,
      "step": 35710
    },
    {
      "epoch": 3.827279545698061,
      "grad_norm": 0.264238178730011,
      "learning_rate": 1.234544090860388e-05,
      "loss": 0.1274,
      "step": 35720
    },
    {
      "epoch": 3.828351012536162,
      "grad_norm": 0.01869179680943489,
      "learning_rate": 1.2343297974927678e-05,
      "loss": 0.5503,
      "step": 35730
    },
    {
      "epoch": 3.8294224793742635,
      "grad_norm": 0.15176476538181305,
      "learning_rate": 1.2341155041251473e-05,
      "loss": 0.38,
      "step": 35740
    },
    {
      "epoch": 3.8304939462123646,
      "grad_norm": 18.23612403869629,
      "learning_rate": 1.2339012107575273e-05,
      "loss": 0.6629,
      "step": 35750
    },
    {
      "epoch": 3.831565413050466,
      "grad_norm": 1.2195733785629272,
      "learning_rate": 1.2336869173899068e-05,
      "loss": 0.2132,
      "step": 35760
    },
    {
      "epoch": 3.8326368798885673,
      "grad_norm": 0.06451887637376785,
      "learning_rate": 1.2334726240222866e-05,
      "loss": 0.2401,
      "step": 35770
    },
    {
      "epoch": 3.833708346726669,
      "grad_norm": 0.973194420337677,
      "learning_rate": 1.2332583306546665e-05,
      "loss": 0.1239,
      "step": 35780
    },
    {
      "epoch": 3.8347798135647704,
      "grad_norm": 0.29773879051208496,
      "learning_rate": 1.233044037287046e-05,
      "loss": 0.0046,
      "step": 35790
    },
    {
      "epoch": 3.8358512804028715,
      "grad_norm": 27.541568756103516,
      "learning_rate": 1.232829743919426e-05,
      "loss": 0.3494,
      "step": 35800
    },
    {
      "epoch": 3.836922747240973,
      "grad_norm": 0.021867254748940468,
      "learning_rate": 1.2326154505518055e-05,
      "loss": 0.378,
      "step": 35810
    },
    {
      "epoch": 3.837994214079074,
      "grad_norm": 8.570976257324219,
      "learning_rate": 1.2324011571841852e-05,
      "loss": 0.237,
      "step": 35820
    },
    {
      "epoch": 3.8390656809171757,
      "grad_norm": 0.10503337532281876,
      "learning_rate": 1.232186863816565e-05,
      "loss": 0.1829,
      "step": 35830
    },
    {
      "epoch": 3.840137147755277,
      "grad_norm": 0.16887153685092926,
      "learning_rate": 1.2319725704489447e-05,
      "loss": 0.0837,
      "step": 35840
    },
    {
      "epoch": 3.8412086145933784,
      "grad_norm": 0.032861143350601196,
      "learning_rate": 1.2317582770813243e-05,
      "loss": 0.2715,
      "step": 35850
    },
    {
      "epoch": 3.84228008143148,
      "grad_norm": 0.03244873881340027,
      "learning_rate": 1.2315439837137042e-05,
      "loss": 0.1838,
      "step": 35860
    },
    {
      "epoch": 3.843351548269581,
      "grad_norm": 0.0831640437245369,
      "learning_rate": 1.2313296903460839e-05,
      "loss": 0.2657,
      "step": 35870
    },
    {
      "epoch": 3.844423015107682,
      "grad_norm": 0.8031781911849976,
      "learning_rate": 1.2311153969784636e-05,
      "loss": 0.4203,
      "step": 35880
    },
    {
      "epoch": 3.8454944819457837,
      "grad_norm": 0.013459008187055588,
      "learning_rate": 1.2309011036108434e-05,
      "loss": 0.131,
      "step": 35890
    },
    {
      "epoch": 3.8465659487838852,
      "grad_norm": 0.10649055987596512,
      "learning_rate": 1.230686810243223e-05,
      "loss": 0.4048,
      "step": 35900
    },
    {
      "epoch": 3.8476374156219864,
      "grad_norm": 0.05144451931118965,
      "learning_rate": 1.2304725168756029e-05,
      "loss": 0.0028,
      "step": 35910
    },
    {
      "epoch": 3.848708882460088,
      "grad_norm": 0.696721613407135,
      "learning_rate": 1.2302582235079826e-05,
      "loss": 0.0932,
      "step": 35920
    },
    {
      "epoch": 3.8497803492981895,
      "grad_norm": 16.932737350463867,
      "learning_rate": 1.2300439301403622e-05,
      "loss": 0.3321,
      "step": 35930
    },
    {
      "epoch": 3.8508518161362906,
      "grad_norm": 0.3760962188243866,
      "learning_rate": 1.229829636772742e-05,
      "loss": 0.2092,
      "step": 35940
    },
    {
      "epoch": 3.8519232829743917,
      "grad_norm": 15.255135536193848,
      "learning_rate": 1.2296153434051216e-05,
      "loss": 0.5228,
      "step": 35950
    },
    {
      "epoch": 3.8529947498124932,
      "grad_norm": 0.22438566386699677,
      "learning_rate": 1.2294010500375015e-05,
      "loss": 0.2563,
      "step": 35960
    },
    {
      "epoch": 3.854066216650595,
      "grad_norm": 0.01712319627404213,
      "learning_rate": 1.2291867566698813e-05,
      "loss": 0.0017,
      "step": 35970
    },
    {
      "epoch": 3.855137683488696,
      "grad_norm": 17.809988021850586,
      "learning_rate": 1.2289724633022608e-05,
      "loss": 0.5984,
      "step": 35980
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 21.122676849365234,
      "learning_rate": 1.2287581699346407e-05,
      "loss": 0.3847,
      "step": 35990
    },
    {
      "epoch": 3.857280617164899,
      "grad_norm": 1.2325851917266846,
      "learning_rate": 1.2285438765670203e-05,
      "loss": 0.2746,
      "step": 36000
    },
    {
      "epoch": 3.858352084003,
      "grad_norm": 15.258111953735352,
      "learning_rate": 1.2283295831994e-05,
      "loss": 0.3728,
      "step": 36010
    },
    {
      "epoch": 3.8594235508411012,
      "grad_norm": 0.13338375091552734,
      "learning_rate": 1.2281152898317798e-05,
      "loss": 0.0041,
      "step": 36020
    },
    {
      "epoch": 3.860495017679203,
      "grad_norm": 0.03852472081780434,
      "learning_rate": 1.2279009964641595e-05,
      "loss": 0.2681,
      "step": 36030
    },
    {
      "epoch": 3.8615664845173043,
      "grad_norm": 0.09394916892051697,
      "learning_rate": 1.2276867030965394e-05,
      "loss": 0.205,
      "step": 36040
    },
    {
      "epoch": 3.8626379513554054,
      "grad_norm": 0.16761700809001923,
      "learning_rate": 1.227472409728919e-05,
      "loss": 0.2216,
      "step": 36050
    },
    {
      "epoch": 3.863709418193507,
      "grad_norm": 0.12914593517780304,
      "learning_rate": 1.2272581163612987e-05,
      "loss": 0.5452,
      "step": 36060
    },
    {
      "epoch": 3.8647808850316085,
      "grad_norm": 16.18560028076172,
      "learning_rate": 1.2270438229936785e-05,
      "loss": 0.597,
      "step": 36070
    },
    {
      "epoch": 3.8658523518697097,
      "grad_norm": 0.1614588499069214,
      "learning_rate": 1.2268295296260582e-05,
      "loss": 0.2466,
      "step": 36080
    },
    {
      "epoch": 3.8669238187078108,
      "grad_norm": 0.08844475448131561,
      "learning_rate": 1.2266152362584378e-05,
      "loss": 0.2205,
      "step": 36090
    },
    {
      "epoch": 3.8679952855459123,
      "grad_norm": 0.8511300086975098,
      "learning_rate": 1.2264009428908177e-05,
      "loss": 0.145,
      "step": 36100
    },
    {
      "epoch": 3.869066752384014,
      "grad_norm": 0.14575481414794922,
      "learning_rate": 1.2261866495231974e-05,
      "loss": 0.0033,
      "step": 36110
    },
    {
      "epoch": 3.870138219222115,
      "grad_norm": 15.440622329711914,
      "learning_rate": 1.2259723561555771e-05,
      "loss": 0.3067,
      "step": 36120
    },
    {
      "epoch": 3.8712096860602165,
      "grad_norm": 0.02649061754345894,
      "learning_rate": 1.2257580627879569e-05,
      "loss": 0.2771,
      "step": 36130
    },
    {
      "epoch": 3.8722811528983176,
      "grad_norm": 0.02382066287100315,
      "learning_rate": 1.2255437694203364e-05,
      "loss": 0.3144,
      "step": 36140
    },
    {
      "epoch": 3.873352619736419,
      "grad_norm": 0.03215102478861809,
      "learning_rate": 1.2253294760527163e-05,
      "loss": 0.2107,
      "step": 36150
    },
    {
      "epoch": 3.8744240865745203,
      "grad_norm": 0.024224378168582916,
      "learning_rate": 1.225115182685096e-05,
      "loss": 0.0116,
      "step": 36160
    },
    {
      "epoch": 3.875495553412622,
      "grad_norm": 0.10575924813747406,
      "learning_rate": 1.2249008893174756e-05,
      "loss": 0.1424,
      "step": 36170
    },
    {
      "epoch": 3.8765670202507234,
      "grad_norm": 0.020211102440953255,
      "learning_rate": 1.2246865959498555e-05,
      "loss": 0.3621,
      "step": 36180
    },
    {
      "epoch": 3.8776384870888245,
      "grad_norm": 0.18392294645309448,
      "learning_rate": 1.2244723025822351e-05,
      "loss": 0.006,
      "step": 36190
    },
    {
      "epoch": 3.878709953926926,
      "grad_norm": 0.06217576190829277,
      "learning_rate": 1.224258009214615e-05,
      "loss": 0.1833,
      "step": 36200
    },
    {
      "epoch": 3.879781420765027,
      "grad_norm": 0.2928096354007721,
      "learning_rate": 1.2240437158469946e-05,
      "loss": 0.0018,
      "step": 36210
    },
    {
      "epoch": 3.8808528876031287,
      "grad_norm": 0.006842292379587889,
      "learning_rate": 1.2238294224793743e-05,
      "loss": 0.0013,
      "step": 36220
    },
    {
      "epoch": 3.88192435444123,
      "grad_norm": 0.09275475889444351,
      "learning_rate": 1.2236151291117542e-05,
      "loss": 0.1621,
      "step": 36230
    },
    {
      "epoch": 3.8829958212793314,
      "grad_norm": 28.998111724853516,
      "learning_rate": 1.2234008357441338e-05,
      "loss": 0.4023,
      "step": 36240
    },
    {
      "epoch": 3.884067288117433,
      "grad_norm": 0.020903604105114937,
      "learning_rate": 1.2231865423765135e-05,
      "loss": 0.1503,
      "step": 36250
    },
    {
      "epoch": 3.885138754955534,
      "grad_norm": 0.21738310158252716,
      "learning_rate": 1.2229722490088933e-05,
      "loss": 0.0017,
      "step": 36260
    },
    {
      "epoch": 3.8862102217936356,
      "grad_norm": 0.10835796594619751,
      "learning_rate": 1.222757955641273e-05,
      "loss": 0.2527,
      "step": 36270
    },
    {
      "epoch": 3.8872816886317367,
      "grad_norm": 0.09341606497764587,
      "learning_rate": 1.2225436622736526e-05,
      "loss": 0.3125,
      "step": 36280
    },
    {
      "epoch": 3.8883531554698383,
      "grad_norm": 0.009210254065692425,
      "learning_rate": 1.2223293689060325e-05,
      "loss": 0.2567,
      "step": 36290
    },
    {
      "epoch": 3.8894246223079394,
      "grad_norm": 0.002769465558230877,
      "learning_rate": 1.2221150755384122e-05,
      "loss": 0.597,
      "step": 36300
    },
    {
      "epoch": 3.890496089146041,
      "grad_norm": 0.0283874049782753,
      "learning_rate": 1.221900782170792e-05,
      "loss": 0.1495,
      "step": 36310
    },
    {
      "epoch": 3.8915675559841425,
      "grad_norm": 0.05580512434244156,
      "learning_rate": 1.2216864888031717e-05,
      "loss": 0.4075,
      "step": 36320
    },
    {
      "epoch": 3.8926390228222436,
      "grad_norm": 22.400039672851562,
      "learning_rate": 1.2214721954355512e-05,
      "loss": 0.3052,
      "step": 36330
    },
    {
      "epoch": 3.893710489660345,
      "grad_norm": 0.04283905401825905,
      "learning_rate": 1.2212579020679311e-05,
      "loss": 0.2768,
      "step": 36340
    },
    {
      "epoch": 3.8947819564984463,
      "grad_norm": 0.018956823274493217,
      "learning_rate": 1.2210436087003109e-05,
      "loss": 0.0266,
      "step": 36350
    },
    {
      "epoch": 3.895853423336548,
      "grad_norm": 0.0797576755285263,
      "learning_rate": 1.2208293153326904e-05,
      "loss": 0.1111,
      "step": 36360
    },
    {
      "epoch": 3.896924890174649,
      "grad_norm": 0.020895907655358315,
      "learning_rate": 1.2206150219650703e-05,
      "loss": 0.3321,
      "step": 36370
    },
    {
      "epoch": 3.8979963570127505,
      "grad_norm": 32.22431945800781,
      "learning_rate": 1.2204007285974499e-05,
      "loss": 0.4881,
      "step": 36380
    },
    {
      "epoch": 3.899067823850852,
      "grad_norm": 0.07018701732158661,
      "learning_rate": 1.2201864352298298e-05,
      "loss": 0.2454,
      "step": 36390
    },
    {
      "epoch": 3.900139290688953,
      "grad_norm": 0.0502605065703392,
      "learning_rate": 1.2199721418622094e-05,
      "loss": 0.35,
      "step": 36400
    },
    {
      "epoch": 3.9012107575270543,
      "grad_norm": 0.06423738598823547,
      "learning_rate": 1.2197578484945891e-05,
      "loss": 0.2568,
      "step": 36410
    },
    {
      "epoch": 3.902282224365156,
      "grad_norm": 0.06918681412935257,
      "learning_rate": 1.219543555126969e-05,
      "loss": 0.0184,
      "step": 36420
    },
    {
      "epoch": 3.9033536912032574,
      "grad_norm": 0.15379801392555237,
      "learning_rate": 1.2193292617593486e-05,
      "loss": 0.2985,
      "step": 36430
    },
    {
      "epoch": 3.9044251580413585,
      "grad_norm": 0.049314964562654495,
      "learning_rate": 1.2191149683917283e-05,
      "loss": 0.0018,
      "step": 36440
    },
    {
      "epoch": 3.90549662487946,
      "grad_norm": 0.19153627753257751,
      "learning_rate": 1.218900675024108e-05,
      "loss": 0.2106,
      "step": 36450
    },
    {
      "epoch": 3.9065680917175616,
      "grad_norm": 0.03275711461901665,
      "learning_rate": 1.2186863816564878e-05,
      "loss": 0.3659,
      "step": 36460
    },
    {
      "epoch": 3.9076395585556627,
      "grad_norm": 19.6320858001709,
      "learning_rate": 1.2184720882888677e-05,
      "loss": 0.1361,
      "step": 36470
    },
    {
      "epoch": 3.908711025393764,
      "grad_norm": 18.40108871459961,
      "learning_rate": 1.2182577949212473e-05,
      "loss": 0.2752,
      "step": 36480
    },
    {
      "epoch": 3.9097824922318654,
      "grad_norm": 0.026920411735773087,
      "learning_rate": 1.218043501553627e-05,
      "loss": 0.5264,
      "step": 36490
    },
    {
      "epoch": 3.910853959069967,
      "grad_norm": 0.0507710762321949,
      "learning_rate": 1.2178292081860067e-05,
      "loss": 0.1711,
      "step": 36500
    },
    {
      "epoch": 3.911925425908068,
      "grad_norm": 0.5382259488105774,
      "learning_rate": 1.2176149148183865e-05,
      "loss": 0.2413,
      "step": 36510
    },
    {
      "epoch": 3.9129968927461696,
      "grad_norm": 0.039577171206474304,
      "learning_rate": 1.217400621450766e-05,
      "loss": 0.492,
      "step": 36520
    },
    {
      "epoch": 3.914068359584271,
      "grad_norm": 0.50283282995224,
      "learning_rate": 1.217186328083146e-05,
      "loss": 0.1103,
      "step": 36530
    },
    {
      "epoch": 3.9151398264223722,
      "grad_norm": 0.882304847240448,
      "learning_rate": 1.2169720347155257e-05,
      "loss": 0.3619,
      "step": 36540
    },
    {
      "epoch": 3.9162112932604733,
      "grad_norm": 0.1423206478357315,
      "learning_rate": 1.2167577413479054e-05,
      "loss": 0.1013,
      "step": 36550
    },
    {
      "epoch": 3.917282760098575,
      "grad_norm": 0.05826301500201225,
      "learning_rate": 1.2165434479802852e-05,
      "loss": 0.3443,
      "step": 36560
    },
    {
      "epoch": 3.9183542269366765,
      "grad_norm": 0.006371461320668459,
      "learning_rate": 1.2163291546126647e-05,
      "loss": 0.0015,
      "step": 36570
    },
    {
      "epoch": 3.9194256937747776,
      "grad_norm": 0.07161381840705872,
      "learning_rate": 1.2161148612450446e-05,
      "loss": 0.0016,
      "step": 36580
    },
    {
      "epoch": 3.920497160612879,
      "grad_norm": 0.00618169317021966,
      "learning_rate": 1.2159005678774242e-05,
      "loss": 0.1536,
      "step": 36590
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 16.510671615600586,
      "learning_rate": 1.215686274509804e-05,
      "loss": 0.5668,
      "step": 36600
    },
    {
      "epoch": 3.922640094289082,
      "grad_norm": 101.31543731689453,
      "learning_rate": 1.2154719811421838e-05,
      "loss": 0.3304,
      "step": 36610
    },
    {
      "epoch": 3.923711561127183,
      "grad_norm": 29.264211654663086,
      "learning_rate": 1.2152576877745634e-05,
      "loss": 0.1571,
      "step": 36620
    },
    {
      "epoch": 3.9247830279652844,
      "grad_norm": 0.05706847831606865,
      "learning_rate": 1.2150433944069433e-05,
      "loss": 0.1262,
      "step": 36630
    },
    {
      "epoch": 3.925854494803386,
      "grad_norm": 0.05046489089727402,
      "learning_rate": 1.2148291010393229e-05,
      "loss": 0.2512,
      "step": 36640
    },
    {
      "epoch": 3.926925961641487,
      "grad_norm": 0.34570661187171936,
      "learning_rate": 1.2146148076717026e-05,
      "loss": 0.2355,
      "step": 36650
    },
    {
      "epoch": 3.9279974284795887,
      "grad_norm": 796.937744140625,
      "learning_rate": 1.2144005143040825e-05,
      "loss": 0.5538,
      "step": 36660
    },
    {
      "epoch": 3.9290688953176898,
      "grad_norm": 30.161962509155273,
      "learning_rate": 1.214186220936462e-05,
      "loss": 0.3466,
      "step": 36670
    },
    {
      "epoch": 3.9301403621557913,
      "grad_norm": 0.006856851279735565,
      "learning_rate": 1.2139719275688418e-05,
      "loss": 0.2218,
      "step": 36680
    },
    {
      "epoch": 3.9312118289938924,
      "grad_norm": 91.58128356933594,
      "learning_rate": 1.2137576342012215e-05,
      "loss": 0.2758,
      "step": 36690
    },
    {
      "epoch": 3.932283295831994,
      "grad_norm": 0.03518175333738327,
      "learning_rate": 1.2135433408336013e-05,
      "loss": 0.2019,
      "step": 36700
    },
    {
      "epoch": 3.9333547626700955,
      "grad_norm": 0.252542644739151,
      "learning_rate": 1.2133290474659812e-05,
      "loss": 0.2177,
      "step": 36710
    },
    {
      "epoch": 3.9344262295081966,
      "grad_norm": 0.0080986637622118,
      "learning_rate": 1.2131147540983608e-05,
      "loss": 0.1388,
      "step": 36720
    },
    {
      "epoch": 3.935497696346298,
      "grad_norm": 0.05493723601102829,
      "learning_rate": 1.2129004607307405e-05,
      "loss": 0.0029,
      "step": 36730
    },
    {
      "epoch": 3.9365691631843993,
      "grad_norm": 0.013993484899401665,
      "learning_rate": 1.2126861673631202e-05,
      "loss": 0.0027,
      "step": 36740
    },
    {
      "epoch": 3.937640630022501,
      "grad_norm": 0.07337060570716858,
      "learning_rate": 1.2124718739955e-05,
      "loss": 0.4011,
      "step": 36750
    },
    {
      "epoch": 3.938712096860602,
      "grad_norm": 0.021078161895275116,
      "learning_rate": 1.2122575806278795e-05,
      "loss": 0.4493,
      "step": 36760
    },
    {
      "epoch": 3.9397835636987035,
      "grad_norm": 0.021870210766792297,
      "learning_rate": 1.2120432872602594e-05,
      "loss": 0.4498,
      "step": 36770
    },
    {
      "epoch": 3.940855030536805,
      "grad_norm": 1.8170820474624634,
      "learning_rate": 1.211828993892639e-05,
      "loss": 0.347,
      "step": 36780
    },
    {
      "epoch": 3.941926497374906,
      "grad_norm": 0.029041718691587448,
      "learning_rate": 1.2116147005250189e-05,
      "loss": 0.3876,
      "step": 36790
    },
    {
      "epoch": 3.9429979642130077,
      "grad_norm": 0.03837919235229492,
      "learning_rate": 1.2114004071573986e-05,
      "loss": 0.1733,
      "step": 36800
    },
    {
      "epoch": 3.944069431051109,
      "grad_norm": 0.08881573379039764,
      "learning_rate": 1.2111861137897782e-05,
      "loss": 0.1537,
      "step": 36810
    },
    {
      "epoch": 3.9451408978892104,
      "grad_norm": 0.16183394193649292,
      "learning_rate": 1.2109718204221581e-05,
      "loss": 0.2013,
      "step": 36820
    },
    {
      "epoch": 3.9462123647273115,
      "grad_norm": 0.6242445111274719,
      "learning_rate": 1.2107575270545377e-05,
      "loss": 0.3231,
      "step": 36830
    },
    {
      "epoch": 3.947283831565413,
      "grad_norm": 0.29035094380378723,
      "learning_rate": 1.2105432336869174e-05,
      "loss": 0.2597,
      "step": 36840
    },
    {
      "epoch": 3.9483552984035146,
      "grad_norm": 0.03694278374314308,
      "learning_rate": 1.2103289403192973e-05,
      "loss": 0.1354,
      "step": 36850
    },
    {
      "epoch": 3.9494267652416157,
      "grad_norm": 0.04972062632441521,
      "learning_rate": 1.2101146469516769e-05,
      "loss": 0.442,
      "step": 36860
    },
    {
      "epoch": 3.9504982320797173,
      "grad_norm": 55.56120300292969,
      "learning_rate": 1.2099003535840568e-05,
      "loss": 0.4917,
      "step": 36870
    },
    {
      "epoch": 3.9515696989178184,
      "grad_norm": 0.9620479941368103,
      "learning_rate": 1.2096860602164364e-05,
      "loss": 0.6053,
      "step": 36880
    },
    {
      "epoch": 3.95264116575592,
      "grad_norm": 0.12449341267347336,
      "learning_rate": 1.2094717668488161e-05,
      "loss": 0.3746,
      "step": 36890
    },
    {
      "epoch": 3.953712632594021,
      "grad_norm": 0.380131334066391,
      "learning_rate": 1.209257473481196e-05,
      "loss": 0.2789,
      "step": 36900
    },
    {
      "epoch": 3.9547840994321226,
      "grad_norm": 14.83117961883545,
      "learning_rate": 1.2090431801135756e-05,
      "loss": 0.4642,
      "step": 36910
    },
    {
      "epoch": 3.955855566270224,
      "grad_norm": 0.04276982322335243,
      "learning_rate": 1.2088288867459553e-05,
      "loss": 0.1653,
      "step": 36920
    },
    {
      "epoch": 3.9569270331083253,
      "grad_norm": 0.005065698176622391,
      "learning_rate": 1.208614593378335e-05,
      "loss": 0.1255,
      "step": 36930
    },
    {
      "epoch": 3.9579984999464264,
      "grad_norm": 0.4433263838291168,
      "learning_rate": 1.2084003000107148e-05,
      "loss": 0.0044,
      "step": 36940
    },
    {
      "epoch": 3.959069966784528,
      "grad_norm": 0.6984719634056091,
      "learning_rate": 1.2081860066430947e-05,
      "loss": 0.3102,
      "step": 36950
    },
    {
      "epoch": 3.9601414336226295,
      "grad_norm": 0.04067240655422211,
      "learning_rate": 1.2079717132754742e-05,
      "loss": 0.153,
      "step": 36960
    },
    {
      "epoch": 3.9612129004607306,
      "grad_norm": 0.05328702926635742,
      "learning_rate": 1.2077574199078538e-05,
      "loss": 0.1847,
      "step": 36970
    },
    {
      "epoch": 3.962284367298832,
      "grad_norm": 20.755617141723633,
      "learning_rate": 1.2075431265402337e-05,
      "loss": 0.2871,
      "step": 36980
    },
    {
      "epoch": 3.9633558341369337,
      "grad_norm": 0.006929188501089811,
      "learning_rate": 1.2073288331726134e-05,
      "loss": 0.1196,
      "step": 36990
    },
    {
      "epoch": 3.964427300975035,
      "grad_norm": 0.0043393829837441444,
      "learning_rate": 1.207114539804993e-05,
      "loss": 0.0017,
      "step": 37000
    },
    {
      "epoch": 3.965498767813136,
      "grad_norm": 0.05072343349456787,
      "learning_rate": 1.206900246437373e-05,
      "loss": 0.3978,
      "step": 37010
    },
    {
      "epoch": 3.9665702346512375,
      "grad_norm": 0.008518638089299202,
      "learning_rate": 1.2066859530697525e-05,
      "loss": 0.2775,
      "step": 37020
    },
    {
      "epoch": 3.967641701489339,
      "grad_norm": 0.11426763236522675,
      "learning_rate": 1.2064716597021324e-05,
      "loss": 0.1619,
      "step": 37030
    },
    {
      "epoch": 3.96871316832744,
      "grad_norm": 0.02135622501373291,
      "learning_rate": 1.2062573663345121e-05,
      "loss": 0.2014,
      "step": 37040
    },
    {
      "epoch": 3.9697846351655417,
      "grad_norm": 0.03290700167417526,
      "learning_rate": 1.2060430729668917e-05,
      "loss": 0.2098,
      "step": 37050
    },
    {
      "epoch": 3.9708561020036433,
      "grad_norm": 0.08238900452852249,
      "learning_rate": 1.2058287795992716e-05,
      "loss": 0.0517,
      "step": 37060
    },
    {
      "epoch": 3.9719275688417444,
      "grad_norm": 0.012933055870234966,
      "learning_rate": 1.2056144862316512e-05,
      "loss": 0.1663,
      "step": 37070
    },
    {
      "epoch": 3.9729990356798455,
      "grad_norm": 0.05529731139540672,
      "learning_rate": 1.2054001928640309e-05,
      "loss": 0.1194,
      "step": 37080
    },
    {
      "epoch": 3.974070502517947,
      "grad_norm": 24.048376083374023,
      "learning_rate": 1.2051858994964108e-05,
      "loss": 0.2202,
      "step": 37090
    },
    {
      "epoch": 3.9751419693560486,
      "grad_norm": 0.021312089636921883,
      "learning_rate": 1.2049716061287904e-05,
      "loss": 0.2808,
      "step": 37100
    },
    {
      "epoch": 3.9762134361941497,
      "grad_norm": 0.005177734885364771,
      "learning_rate": 1.2047573127611703e-05,
      "loss": 0.0008,
      "step": 37110
    },
    {
      "epoch": 3.9772849030322512,
      "grad_norm": 0.004032345488667488,
      "learning_rate": 1.2045430193935498e-05,
      "loss": 0.1207,
      "step": 37120
    },
    {
      "epoch": 3.9783563698703523,
      "grad_norm": 18.78801155090332,
      "learning_rate": 1.2043287260259296e-05,
      "loss": 0.1579,
      "step": 37130
    },
    {
      "epoch": 3.979427836708454,
      "grad_norm": 0.03257860988378525,
      "learning_rate": 1.2041144326583095e-05,
      "loss": 0.1711,
      "step": 37140
    },
    {
      "epoch": 3.980499303546555,
      "grad_norm": 0.07204797863960266,
      "learning_rate": 1.203900139290689e-05,
      "loss": 0.0028,
      "step": 37150
    },
    {
      "epoch": 3.9815707703846566,
      "grad_norm": 0.003241512458771467,
      "learning_rate": 1.2036858459230686e-05,
      "loss": 0.4009,
      "step": 37160
    },
    {
      "epoch": 3.982642237222758,
      "grad_norm": 106.86092376708984,
      "learning_rate": 1.2034715525554485e-05,
      "loss": 0.6479,
      "step": 37170
    },
    {
      "epoch": 3.9837137040608592,
      "grad_norm": 0.01503834780305624,
      "learning_rate": 1.2032572591878283e-05,
      "loss": 0.171,
      "step": 37180
    },
    {
      "epoch": 3.984785170898961,
      "grad_norm": 0.043612536042928696,
      "learning_rate": 1.2030429658202078e-05,
      "loss": 0.318,
      "step": 37190
    },
    {
      "epoch": 3.985856637737062,
      "grad_norm": 0.2914775311946869,
      "learning_rate": 1.2028286724525877e-05,
      "loss": 0.265,
      "step": 37200
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 0.1396273821592331,
      "learning_rate": 1.2026143790849673e-05,
      "loss": 0.0029,
      "step": 37210
    },
    {
      "epoch": 3.9879995714132646,
      "grad_norm": 22.93484878540039,
      "learning_rate": 1.2024000857173472e-05,
      "loss": 0.1841,
      "step": 37220
    },
    {
      "epoch": 3.989071038251366,
      "grad_norm": 0.01065037027001381,
      "learning_rate": 1.202185792349727e-05,
      "loss": 0.0014,
      "step": 37230
    },
    {
      "epoch": 3.9901425050894677,
      "grad_norm": 0.1464281678199768,
      "learning_rate": 1.2019714989821065e-05,
      "loss": 0.3007,
      "step": 37240
    },
    {
      "epoch": 3.9912139719275688,
      "grad_norm": 0.2006167620420456,
      "learning_rate": 1.2017572056144864e-05,
      "loss": 0.3882,
      "step": 37250
    },
    {
      "epoch": 3.9922854387656703,
      "grad_norm": 0.240462988615036,
      "learning_rate": 1.201542912246866e-05,
      "loss": 0.0021,
      "step": 37260
    },
    {
      "epoch": 3.9933569056037714,
      "grad_norm": 0.02437525801360607,
      "learning_rate": 1.2013286188792457e-05,
      "loss": 0.0786,
      "step": 37270
    },
    {
      "epoch": 3.994428372441873,
      "grad_norm": 0.007584476377815008,
      "learning_rate": 1.2011143255116256e-05,
      "loss": 0.1409,
      "step": 37280
    },
    {
      "epoch": 3.995499839279974,
      "grad_norm": 0.004085390828549862,
      "learning_rate": 1.2009000321440052e-05,
      "loss": 0.0014,
      "step": 37290
    },
    {
      "epoch": 3.9965713061180757,
      "grad_norm": 0.018644219264388084,
      "learning_rate": 1.200685738776385e-05,
      "loss": 0.6193,
      "step": 37300
    },
    {
      "epoch": 3.997642772956177,
      "grad_norm": 0.01910710148513317,
      "learning_rate": 1.2004714454087646e-05,
      "loss": 0.2506,
      "step": 37310
    },
    {
      "epoch": 3.9987142397942783,
      "grad_norm": 0.028341123834252357,
      "learning_rate": 1.2002571520411444e-05,
      "loss": 0.2407,
      "step": 37320
    },
    {
      "epoch": 3.99978570663238,
      "grad_norm": 12.944535255432129,
      "learning_rate": 1.2000428586735243e-05,
      "loss": 0.2268,
      "step": 37330
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9371666666666667,
      "eval_f1": 0.8279324509356458,
      "eval_loss": 0.3271414339542389,
      "eval_precision": 0.8831548198636806,
      "eval_recall": 0.7792096219931272,
      "eval_runtime": 486.621,
      "eval_samples_per_second": 12.33,
      "eval_steps_per_second": 4.11,
      "step": 37332
    },
    {
      "epoch": 4.000857173470481,
      "grad_norm": 0.013862557709217072,
      "learning_rate": 1.1998285653059039e-05,
      "loss": 0.1054,
      "step": 37340
    },
    {
      "epoch": 4.0019286403085825,
      "grad_norm": 0.36051344871520996,
      "learning_rate": 1.1996142719382834e-05,
      "loss": 0.0027,
      "step": 37350
    },
    {
      "epoch": 4.003000107146684,
      "grad_norm": 0.010598680935800076,
      "learning_rate": 1.1993999785706633e-05,
      "loss": 0.0014,
      "step": 37360
    },
    {
      "epoch": 4.004071573984785,
      "grad_norm": 0.03555214777588844,
      "learning_rate": 1.199185685203043e-05,
      "loss": 0.0014,
      "step": 37370
    },
    {
      "epoch": 4.005143040822887,
      "grad_norm": 0.03673003986477852,
      "learning_rate": 1.198971391835423e-05,
      "loss": 0.0015,
      "step": 37380
    },
    {
      "epoch": 4.006214507660988,
      "grad_norm": 15.23621654510498,
      "learning_rate": 1.1987570984678025e-05,
      "loss": 0.1691,
      "step": 37390
    },
    {
      "epoch": 4.007285974499089,
      "grad_norm": 0.021009111776947975,
      "learning_rate": 1.1985428051001821e-05,
      "loss": 0.0005,
      "step": 37400
    },
    {
      "epoch": 4.008357441337191,
      "grad_norm": 0.06173126399517059,
      "learning_rate": 1.198328511732562e-05,
      "loss": 0.1447,
      "step": 37410
    },
    {
      "epoch": 4.009428908175292,
      "grad_norm": 0.29213327169418335,
      "learning_rate": 1.1981142183649417e-05,
      "loss": 0.0008,
      "step": 37420
    },
    {
      "epoch": 4.010500375013393,
      "grad_norm": 0.04116416350007057,
      "learning_rate": 1.1978999249973213e-05,
      "loss": 0.3916,
      "step": 37430
    },
    {
      "epoch": 4.011571841851494,
      "grad_norm": 46.21634292602539,
      "learning_rate": 1.1976856316297012e-05,
      "loss": 0.3494,
      "step": 37440
    },
    {
      "epoch": 4.012643308689596,
      "grad_norm": 0.48953577876091003,
      "learning_rate": 1.1974713382620808e-05,
      "loss": 0.2429,
      "step": 37450
    },
    {
      "epoch": 4.013714775527697,
      "grad_norm": 0.48774686455726624,
      "learning_rate": 1.1972570448944607e-05,
      "loss": 0.3563,
      "step": 37460
    },
    {
      "epoch": 4.0147862423657985,
      "grad_norm": 0.13066598773002625,
      "learning_rate": 1.1970427515268404e-05,
      "loss": 0.2179,
      "step": 37470
    },
    {
      "epoch": 4.0158577092039005,
      "grad_norm": 0.268444299697876,
      "learning_rate": 1.19682845815922e-05,
      "loss": 0.0019,
      "step": 37480
    },
    {
      "epoch": 4.016929176042002,
      "grad_norm": 0.036193832755088806,
      "learning_rate": 1.1966141647915999e-05,
      "loss": 0.203,
      "step": 37490
    },
    {
      "epoch": 4.018000642880103,
      "grad_norm": 51.132164001464844,
      "learning_rate": 1.1963998714239795e-05,
      "loss": 0.1678,
      "step": 37500
    },
    {
      "epoch": 4.019072109718204,
      "grad_norm": 0.09631620347499847,
      "learning_rate": 1.1961855780563592e-05,
      "loss": 0.2005,
      "step": 37510
    },
    {
      "epoch": 4.020143576556306,
      "grad_norm": 0.05155452713370323,
      "learning_rate": 1.1959712846887391e-05,
      "loss": 0.1694,
      "step": 37520
    },
    {
      "epoch": 4.021215043394407,
      "grad_norm": 24.28879165649414,
      "learning_rate": 1.1957569913211187e-05,
      "loss": 0.0046,
      "step": 37530
    },
    {
      "epoch": 4.022286510232508,
      "grad_norm": 0.02316969260573387,
      "learning_rate": 1.1955426979534986e-05,
      "loss": 0.2602,
      "step": 37540
    },
    {
      "epoch": 4.02335797707061,
      "grad_norm": 0.047114647924900055,
      "learning_rate": 1.1953284045858781e-05,
      "loss": 0.1353,
      "step": 37550
    },
    {
      "epoch": 4.024429443908711,
      "grad_norm": 0.0789056196808815,
      "learning_rate": 1.1951141112182579e-05,
      "loss": 0.2183,
      "step": 37560
    },
    {
      "epoch": 4.025500910746812,
      "grad_norm": 0.006412831135094166,
      "learning_rate": 1.1948998178506378e-05,
      "loss": 0.5422,
      "step": 37570
    },
    {
      "epoch": 4.026572377584913,
      "grad_norm": 33.15566635131836,
      "learning_rate": 1.1946855244830173e-05,
      "loss": 0.2198,
      "step": 37580
    },
    {
      "epoch": 4.027643844423015,
      "grad_norm": 0.0870840772986412,
      "learning_rate": 1.1944712311153969e-05,
      "loss": 0.0322,
      "step": 37590
    },
    {
      "epoch": 4.0287153112611165,
      "grad_norm": 0.3562050461769104,
      "learning_rate": 1.1942569377477768e-05,
      "loss": 0.2786,
      "step": 37600
    },
    {
      "epoch": 4.029786778099218,
      "grad_norm": 0.05013250559568405,
      "learning_rate": 1.1940426443801565e-05,
      "loss": 0.4423,
      "step": 37610
    },
    {
      "epoch": 4.03085824493732,
      "grad_norm": 0.04708382114768028,
      "learning_rate": 1.1938283510125363e-05,
      "loss": 0.2742,
      "step": 37620
    },
    {
      "epoch": 4.031929711775421,
      "grad_norm": 0.5861403346061707,
      "learning_rate": 1.193614057644916e-05,
      "loss": 0.4314,
      "step": 37630
    },
    {
      "epoch": 4.033001178613522,
      "grad_norm": 60.303279876708984,
      "learning_rate": 1.1933997642772956e-05,
      "loss": 0.1497,
      "step": 37640
    },
    {
      "epoch": 4.034072645451623,
      "grad_norm": 0.11779390275478363,
      "learning_rate": 1.1931854709096755e-05,
      "loss": 0.1049,
      "step": 37650
    },
    {
      "epoch": 4.035144112289725,
      "grad_norm": 0.004982274025678635,
      "learning_rate": 1.1929711775420552e-05,
      "loss": 0.0014,
      "step": 37660
    },
    {
      "epoch": 4.036215579127826,
      "grad_norm": 0.07043654471635818,
      "learning_rate": 1.1927568841744348e-05,
      "loss": 0.2427,
      "step": 37670
    },
    {
      "epoch": 4.037287045965927,
      "grad_norm": 0.021917229518294334,
      "learning_rate": 1.1925425908068147e-05,
      "loss": 0.0008,
      "step": 37680
    },
    {
      "epoch": 4.038358512804029,
      "grad_norm": 0.10377319157123566,
      "learning_rate": 1.1923282974391943e-05,
      "loss": 0.1066,
      "step": 37690
    },
    {
      "epoch": 4.03942997964213,
      "grad_norm": 0.04143987223505974,
      "learning_rate": 1.1921140040715742e-05,
      "loss": 0.0008,
      "step": 37700
    },
    {
      "epoch": 4.040501446480231,
      "grad_norm": 0.03212183713912964,
      "learning_rate": 1.1918997107039539e-05,
      "loss": 0.0008,
      "step": 37710
    },
    {
      "epoch": 4.0415729133183325,
      "grad_norm": 0.0072563206776976585,
      "learning_rate": 1.1916854173363335e-05,
      "loss": 0.2792,
      "step": 37720
    },
    {
      "epoch": 4.0426443801564345,
      "grad_norm": 0.007960383780300617,
      "learning_rate": 1.1914711239687134e-05,
      "loss": 0.1571,
      "step": 37730
    },
    {
      "epoch": 4.043715846994536,
      "grad_norm": 0.013090123422443867,
      "learning_rate": 1.191256830601093e-05,
      "loss": 0.0422,
      "step": 37740
    },
    {
      "epoch": 4.044787313832637,
      "grad_norm": 0.00806655827909708,
      "learning_rate": 1.1910425372334727e-05,
      "loss": 0.223,
      "step": 37750
    },
    {
      "epoch": 4.045858780670739,
      "grad_norm": 0.003564276499673724,
      "learning_rate": 1.1908282438658526e-05,
      "loss": 0.114,
      "step": 37760
    },
    {
      "epoch": 4.04693024750884,
      "grad_norm": 0.010984021238982677,
      "learning_rate": 1.1906139504982321e-05,
      "loss": 0.0004,
      "step": 37770
    },
    {
      "epoch": 4.048001714346941,
      "grad_norm": 0.0255131833255291,
      "learning_rate": 1.190399657130612e-05,
      "loss": 0.2184,
      "step": 37780
    },
    {
      "epoch": 4.049073181185042,
      "grad_norm": 0.03379453346133232,
      "learning_rate": 1.1901853637629916e-05,
      "loss": 0.5604,
      "step": 37790
    },
    {
      "epoch": 4.050144648023144,
      "grad_norm": 0.8316755890846252,
      "learning_rate": 1.1899710703953714e-05,
      "loss": 0.1686,
      "step": 37800
    },
    {
      "epoch": 4.051216114861245,
      "grad_norm": 0.008919995278120041,
      "learning_rate": 1.1897567770277511e-05,
      "loss": 0.2234,
      "step": 37810
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 0.08899810165166855,
      "learning_rate": 1.1895424836601308e-05,
      "loss": 0.3892,
      "step": 37820
    },
    {
      "epoch": 4.053359048537447,
      "grad_norm": 0.0338137224316597,
      "learning_rate": 1.1893281902925104e-05,
      "loss": 0.1421,
      "step": 37830
    },
    {
      "epoch": 4.054430515375549,
      "grad_norm": 0.015395727008581161,
      "learning_rate": 1.1891138969248903e-05,
      "loss": 0.3229,
      "step": 37840
    },
    {
      "epoch": 4.05550198221365,
      "grad_norm": 0.010705221444368362,
      "learning_rate": 1.18889960355727e-05,
      "loss": 0.3209,
      "step": 37850
    },
    {
      "epoch": 4.0565734490517515,
      "grad_norm": 0.01381403487175703,
      "learning_rate": 1.1886853101896498e-05,
      "loss": 0.0051,
      "step": 37860
    },
    {
      "epoch": 4.0576449158898535,
      "grad_norm": 0.0445236898958683,
      "learning_rate": 1.1884710168220295e-05,
      "loss": 0.0009,
      "step": 37870
    },
    {
      "epoch": 4.058716382727955,
      "grad_norm": 0.011004750616848469,
      "learning_rate": 1.188256723454409e-05,
      "loss": 0.0017,
      "step": 37880
    },
    {
      "epoch": 4.059787849566056,
      "grad_norm": 0.4842770993709564,
      "learning_rate": 1.188042430086789e-05,
      "loss": 0.0016,
      "step": 37890
    },
    {
      "epoch": 4.060859316404157,
      "grad_norm": 0.005560725927352905,
      "learning_rate": 1.1878281367191687e-05,
      "loss": 0.0007,
      "step": 37900
    },
    {
      "epoch": 4.061930783242259,
      "grad_norm": 0.004000040702521801,
      "learning_rate": 1.1876138433515483e-05,
      "loss": 0.1537,
      "step": 37910
    },
    {
      "epoch": 4.06300225008036,
      "grad_norm": 0.011876863427460194,
      "learning_rate": 1.1873995499839282e-05,
      "loss": 0.0006,
      "step": 37920
    },
    {
      "epoch": 4.064073716918461,
      "grad_norm": 0.015741223469376564,
      "learning_rate": 1.1871852566163077e-05,
      "loss": 0.2795,
      "step": 37930
    },
    {
      "epoch": 4.065145183756563,
      "grad_norm": 0.010096929036080837,
      "learning_rate": 1.1869709632486876e-05,
      "loss": 0.0133,
      "step": 37940
    },
    {
      "epoch": 4.066216650594664,
      "grad_norm": 0.005737322848290205,
      "learning_rate": 1.1867566698810674e-05,
      "loss": 0.0004,
      "step": 37950
    },
    {
      "epoch": 4.067288117432765,
      "grad_norm": 0.003011934459209442,
      "learning_rate": 1.186542376513447e-05,
      "loss": 0.1576,
      "step": 37960
    },
    {
      "epoch": 4.068359584270866,
      "grad_norm": 0.0017935206415131688,
      "learning_rate": 1.1863280831458269e-05,
      "loss": 0.2972,
      "step": 37970
    },
    {
      "epoch": 4.069431051108968,
      "grad_norm": 0.013519063591957092,
      "learning_rate": 1.1861137897782064e-05,
      "loss": 0.3181,
      "step": 37980
    },
    {
      "epoch": 4.0705025179470695,
      "grad_norm": 0.12446332722902298,
      "learning_rate": 1.1858994964105862e-05,
      "loss": 0.5734,
      "step": 37990
    },
    {
      "epoch": 4.071573984785171,
      "grad_norm": 0.9451936483383179,
      "learning_rate": 1.1856852030429659e-05,
      "loss": 0.2102,
      "step": 38000
    },
    {
      "epoch": 4.072645451623273,
      "grad_norm": 0.07872474938631058,
      "learning_rate": 1.1854709096753456e-05,
      "loss": 0.0419,
      "step": 38010
    },
    {
      "epoch": 4.073716918461374,
      "grad_norm": 0.06348977237939835,
      "learning_rate": 1.1852566163077255e-05,
      "loss": 0.0025,
      "step": 38020
    },
    {
      "epoch": 4.074788385299475,
      "grad_norm": 14.43285083770752,
      "learning_rate": 1.1850423229401051e-05,
      "loss": 0.2579,
      "step": 38030
    },
    {
      "epoch": 4.075859852137576,
      "grad_norm": 0.006593853235244751,
      "learning_rate": 1.1848280295724848e-05,
      "loss": 0.2786,
      "step": 38040
    },
    {
      "epoch": 4.076931318975678,
      "grad_norm": 0.06753263622522354,
      "learning_rate": 1.1846137362048646e-05,
      "loss": 0.6108,
      "step": 38050
    },
    {
      "epoch": 4.078002785813779,
      "grad_norm": 0.04255557805299759,
      "learning_rate": 1.1843994428372443e-05,
      "loss": 0.1552,
      "step": 38060
    },
    {
      "epoch": 4.07907425265188,
      "grad_norm": 15.835609436035156,
      "learning_rate": 1.1841851494696239e-05,
      "loss": 0.3235,
      "step": 38070
    },
    {
      "epoch": 4.080145719489982,
      "grad_norm": 0.011863752268254757,
      "learning_rate": 1.1839708561020038e-05,
      "loss": 0.001,
      "step": 38080
    },
    {
      "epoch": 4.081217186328083,
      "grad_norm": 0.004258254077285528,
      "learning_rate": 1.1837565627343835e-05,
      "loss": 0.1418,
      "step": 38090
    },
    {
      "epoch": 4.082288653166184,
      "grad_norm": 0.12447211891412735,
      "learning_rate": 1.183542269366763e-05,
      "loss": 0.5984,
      "step": 38100
    },
    {
      "epoch": 4.0833601200042855,
      "grad_norm": 0.09369682520627975,
      "learning_rate": 1.183327975999143e-05,
      "loss": 0.1841,
      "step": 38110
    },
    {
      "epoch": 4.0844315868423875,
      "grad_norm": 0.014404605142772198,
      "learning_rate": 1.1831136826315226e-05,
      "loss": 0.3201,
      "step": 38120
    },
    {
      "epoch": 4.085503053680489,
      "grad_norm": 16.55789566040039,
      "learning_rate": 1.1828993892639025e-05,
      "loss": 0.1564,
      "step": 38130
    },
    {
      "epoch": 4.08657452051859,
      "grad_norm": 26.915613174438477,
      "learning_rate": 1.1826850958962822e-05,
      "loss": 0.1269,
      "step": 38140
    },
    {
      "epoch": 4.087645987356692,
      "grad_norm": 0.47350892424583435,
      "learning_rate": 1.1824708025286618e-05,
      "loss": 0.0027,
      "step": 38150
    },
    {
      "epoch": 4.088717454194793,
      "grad_norm": 0.06996484100818634,
      "learning_rate": 1.1822565091610417e-05,
      "loss": 0.0011,
      "step": 38160
    },
    {
      "epoch": 4.089788921032894,
      "grad_norm": 0.004161849617958069,
      "learning_rate": 1.1820422157934212e-05,
      "loss": 0.1331,
      "step": 38170
    },
    {
      "epoch": 4.090860387870995,
      "grad_norm": 0.0020604836754500866,
      "learning_rate": 1.181827922425801e-05,
      "loss": 0.1654,
      "step": 38180
    },
    {
      "epoch": 4.091931854709097,
      "grad_norm": 0.0039052998181432486,
      "learning_rate": 1.1816136290581807e-05,
      "loss": 0.3327,
      "step": 38190
    },
    {
      "epoch": 4.093003321547198,
      "grad_norm": 0.07564500719308853,
      "learning_rate": 1.1813993356905604e-05,
      "loss": 0.314,
      "step": 38200
    },
    {
      "epoch": 4.094074788385299,
      "grad_norm": 0.23720408976078033,
      "learning_rate": 1.1811850423229403e-05,
      "loss": 0.109,
      "step": 38210
    },
    {
      "epoch": 4.095146255223401,
      "grad_norm": 0.07282570004463196,
      "learning_rate": 1.1809707489553199e-05,
      "loss": 0.0126,
      "step": 38220
    },
    {
      "epoch": 4.096217722061502,
      "grad_norm": 0.029038971289992332,
      "learning_rate": 1.1807564555876996e-05,
      "loss": 0.5793,
      "step": 38230
    },
    {
      "epoch": 4.0972891888996035,
      "grad_norm": 24.052013397216797,
      "learning_rate": 1.1805421622200794e-05,
      "loss": 0.2124,
      "step": 38240
    },
    {
      "epoch": 4.098360655737705,
      "grad_norm": 0.00105136982165277,
      "learning_rate": 1.1803278688524591e-05,
      "loss": 0.0017,
      "step": 38250
    },
    {
      "epoch": 4.099432122575807,
      "grad_norm": 0.0024078493006527424,
      "learning_rate": 1.1801135754848387e-05,
      "loss": 0.1607,
      "step": 38260
    },
    {
      "epoch": 4.100503589413908,
      "grad_norm": 0.01267246063798666,
      "learning_rate": 1.1798992821172186e-05,
      "loss": 0.2243,
      "step": 38270
    },
    {
      "epoch": 4.101575056252009,
      "grad_norm": 0.005549267400056124,
      "learning_rate": 1.1796849887495983e-05,
      "loss": 0.0025,
      "step": 38280
    },
    {
      "epoch": 4.102646523090111,
      "grad_norm": 0.0017133256187662482,
      "learning_rate": 1.179470695381978e-05,
      "loss": 0.4919,
      "step": 38290
    },
    {
      "epoch": 4.103717989928212,
      "grad_norm": 0.2644721269607544,
      "learning_rate": 1.1792564020143578e-05,
      "loss": 0.0023,
      "step": 38300
    },
    {
      "epoch": 4.104789456766313,
      "grad_norm": 0.0024917786940932274,
      "learning_rate": 1.1790421086467374e-05,
      "loss": 0.0006,
      "step": 38310
    },
    {
      "epoch": 4.105860923604414,
      "grad_norm": 27.282453536987305,
      "learning_rate": 1.1788278152791173e-05,
      "loss": 0.6147,
      "step": 38320
    },
    {
      "epoch": 4.106932390442516,
      "grad_norm": 0.06453969329595566,
      "learning_rate": 1.178613521911497e-05,
      "loss": 0.1466,
      "step": 38330
    },
    {
      "epoch": 4.108003857280617,
      "grad_norm": 0.01572023704648018,
      "learning_rate": 1.1783992285438766e-05,
      "loss": 0.0409,
      "step": 38340
    },
    {
      "epoch": 4.109075324118718,
      "grad_norm": 0.103032186627388,
      "learning_rate": 1.1781849351762565e-05,
      "loss": 0.0096,
      "step": 38350
    },
    {
      "epoch": 4.1101467909568195,
      "grad_norm": 0.01775406301021576,
      "learning_rate": 1.177970641808636e-05,
      "loss": 0.0009,
      "step": 38360
    },
    {
      "epoch": 4.1112182577949214,
      "grad_norm": 0.0053112260065972805,
      "learning_rate": 1.177756348441016e-05,
      "loss": 0.0017,
      "step": 38370
    },
    {
      "epoch": 4.112289724633023,
      "grad_norm": 17.107542037963867,
      "learning_rate": 1.1775420550733955e-05,
      "loss": 0.5998,
      "step": 38380
    },
    {
      "epoch": 4.113361191471124,
      "grad_norm": 0.004660953301936388,
      "learning_rate": 1.1773277617057752e-05,
      "loss": 0.0018,
      "step": 38390
    },
    {
      "epoch": 4.114432658309226,
      "grad_norm": 0.07534974068403244,
      "learning_rate": 1.1771134683381551e-05,
      "loss": 0.182,
      "step": 38400
    },
    {
      "epoch": 4.115504125147327,
      "grad_norm": 0.008889874443411827,
      "learning_rate": 1.1768991749705347e-05,
      "loss": 0.3949,
      "step": 38410
    },
    {
      "epoch": 4.116575591985428,
      "grad_norm": 40.76283645629883,
      "learning_rate": 1.1766848816029144e-05,
      "loss": 0.3427,
      "step": 38420
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.06697961688041687,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 0.1745,
      "step": 38430
    },
    {
      "epoch": 4.118718525661631,
      "grad_norm": 0.0025952919386327267,
      "learning_rate": 1.176256294867674e-05,
      "loss": 0.4957,
      "step": 38440
    },
    {
      "epoch": 4.119789992499732,
      "grad_norm": 0.012072204612195492,
      "learning_rate": 1.1760420015000538e-05,
      "loss": 0.3323,
      "step": 38450
    },
    {
      "epoch": 4.120861459337833,
      "grad_norm": 0.17958484590053558,
      "learning_rate": 1.1758277081324334e-05,
      "loss": 0.0036,
      "step": 38460
    },
    {
      "epoch": 4.121932926175935,
      "grad_norm": 0.04584425315260887,
      "learning_rate": 1.1756134147648131e-05,
      "loss": 0.1069,
      "step": 38470
    },
    {
      "epoch": 4.123004393014036,
      "grad_norm": 0.03748319298028946,
      "learning_rate": 1.1753991213971929e-05,
      "loss": 0.2022,
      "step": 38480
    },
    {
      "epoch": 4.124075859852137,
      "grad_norm": 0.0019163141259923577,
      "learning_rate": 1.1751848280295726e-05,
      "loss": 0.1816,
      "step": 38490
    },
    {
      "epoch": 4.1251473266902385,
      "grad_norm": 0.14831098914146423,
      "learning_rate": 1.1749705346619522e-05,
      "loss": 0.1569,
      "step": 38500
    },
    {
      "epoch": 4.1262187935283405,
      "grad_norm": 0.035925183445215225,
      "learning_rate": 1.174756241294332e-05,
      "loss": 0.0016,
      "step": 38510
    },
    {
      "epoch": 4.127290260366442,
      "grad_norm": 11.862977027893066,
      "learning_rate": 1.1745419479267118e-05,
      "loss": 0.0065,
      "step": 38520
    },
    {
      "epoch": 4.128361727204543,
      "grad_norm": 0.09187667816877365,
      "learning_rate": 1.1743276545590915e-05,
      "loss": 0.183,
      "step": 38530
    },
    {
      "epoch": 4.129433194042645,
      "grad_norm": 0.002002034103497863,
      "learning_rate": 1.1741133611914713e-05,
      "loss": 0.0914,
      "step": 38540
    },
    {
      "epoch": 4.130504660880746,
      "grad_norm": 0.1807314157485962,
      "learning_rate": 1.1738990678238508e-05,
      "loss": 0.462,
      "step": 38550
    },
    {
      "epoch": 4.131576127718847,
      "grad_norm": 147.71954345703125,
      "learning_rate": 1.1736847744562307e-05,
      "loss": 0.1397,
      "step": 38560
    },
    {
      "epoch": 4.132647594556948,
      "grad_norm": 0.004410926252603531,
      "learning_rate": 1.1734704810886103e-05,
      "loss": 0.0008,
      "step": 38570
    },
    {
      "epoch": 4.13371906139505,
      "grad_norm": 0.01125351618975401,
      "learning_rate": 1.17325618772099e-05,
      "loss": 0.0017,
      "step": 38580
    },
    {
      "epoch": 4.134790528233151,
      "grad_norm": 0.007443497888743877,
      "learning_rate": 1.17304189435337e-05,
      "loss": 0.241,
      "step": 38590
    },
    {
      "epoch": 4.135861995071252,
      "grad_norm": 77.28324127197266,
      "learning_rate": 1.1728276009857495e-05,
      "loss": 0.1669,
      "step": 38600
    },
    {
      "epoch": 4.136933461909354,
      "grad_norm": 0.031643688678741455,
      "learning_rate": 1.1726133076181294e-05,
      "loss": 0.1914,
      "step": 38610
    },
    {
      "epoch": 4.138004928747455,
      "grad_norm": 0.04663047939538956,
      "learning_rate": 1.172399014250509e-05,
      "loss": 0.1938,
      "step": 38620
    },
    {
      "epoch": 4.1390763955855565,
      "grad_norm": 0.046290360391139984,
      "learning_rate": 1.1721847208828887e-05,
      "loss": 0.3342,
      "step": 38630
    },
    {
      "epoch": 4.140147862423658,
      "grad_norm": 30.921585083007812,
      "learning_rate": 1.1719704275152686e-05,
      "loss": 0.3535,
      "step": 38640
    },
    {
      "epoch": 4.14121932926176,
      "grad_norm": 0.026019737124443054,
      "learning_rate": 1.1717561341476482e-05,
      "loss": 0.0023,
      "step": 38650
    },
    {
      "epoch": 4.142290796099861,
      "grad_norm": 0.02743150293827057,
      "learning_rate": 1.171541840780028e-05,
      "loss": 0.0866,
      "step": 38660
    },
    {
      "epoch": 4.143362262937962,
      "grad_norm": 0.02499409392476082,
      "learning_rate": 1.1713275474124077e-05,
      "loss": 0.001,
      "step": 38670
    },
    {
      "epoch": 4.144433729776064,
      "grad_norm": 0.020387256518006325,
      "learning_rate": 1.1711132540447874e-05,
      "loss": 0.6048,
      "step": 38680
    },
    {
      "epoch": 4.145505196614165,
      "grad_norm": 0.05158577486872673,
      "learning_rate": 1.1708989606771673e-05,
      "loss": 0.4,
      "step": 38690
    },
    {
      "epoch": 4.146576663452266,
      "grad_norm": 0.10806119441986084,
      "learning_rate": 1.1706846673095469e-05,
      "loss": 0.1931,
      "step": 38700
    },
    {
      "epoch": 4.147648130290367,
      "grad_norm": 5.25605583190918,
      "learning_rate": 1.1704703739419266e-05,
      "loss": 0.244,
      "step": 38710
    },
    {
      "epoch": 4.148719597128469,
      "grad_norm": 20.13363265991211,
      "learning_rate": 1.1702560805743063e-05,
      "loss": 0.009,
      "step": 38720
    },
    {
      "epoch": 4.14979106396657,
      "grad_norm": 0.13843511044979095,
      "learning_rate": 1.170041787206686e-05,
      "loss": 0.166,
      "step": 38730
    },
    {
      "epoch": 4.150862530804671,
      "grad_norm": 0.06073415279388428,
      "learning_rate": 1.1698274938390656e-05,
      "loss": 0.1588,
      "step": 38740
    },
    {
      "epoch": 4.151933997642773,
      "grad_norm": 0.06223546713590622,
      "learning_rate": 1.1696132004714456e-05,
      "loss": 0.1927,
      "step": 38750
    },
    {
      "epoch": 4.1530054644808745,
      "grad_norm": 0.005518736783415079,
      "learning_rate": 1.1693989071038251e-05,
      "loss": 0.3873,
      "step": 38760
    },
    {
      "epoch": 4.154076931318976,
      "grad_norm": 0.06385286152362823,
      "learning_rate": 1.169184613736205e-05,
      "loss": 0.0019,
      "step": 38770
    },
    {
      "epoch": 4.155148398157077,
      "grad_norm": 0.08529219776391983,
      "learning_rate": 1.1689703203685848e-05,
      "loss": 0.7178,
      "step": 38780
    },
    {
      "epoch": 4.156219864995179,
      "grad_norm": 78.43929290771484,
      "learning_rate": 1.1687560270009643e-05,
      "loss": 0.2154,
      "step": 38790
    },
    {
      "epoch": 4.15729133183328,
      "grad_norm": 0.06882240623235703,
      "learning_rate": 1.1685417336333442e-05,
      "loss": 0.1642,
      "step": 38800
    },
    {
      "epoch": 4.158362798671381,
      "grad_norm": 0.02432047761976719,
      "learning_rate": 1.1683274402657238e-05,
      "loss": 0.1734,
      "step": 38810
    },
    {
      "epoch": 4.159434265509482,
      "grad_norm": 0.06879567354917526,
      "learning_rate": 1.1681131468981035e-05,
      "loss": 0.2123,
      "step": 38820
    },
    {
      "epoch": 4.160505732347584,
      "grad_norm": 0.10794959217309952,
      "learning_rate": 1.1678988535304834e-05,
      "loss": 0.1992,
      "step": 38830
    },
    {
      "epoch": 4.161577199185685,
      "grad_norm": 0.3391965627670288,
      "learning_rate": 1.167684560162863e-05,
      "loss": 0.1974,
      "step": 38840
    },
    {
      "epoch": 4.162648666023786,
      "grad_norm": 0.16661228239536285,
      "learning_rate": 1.1674702667952429e-05,
      "loss": 0.1909,
      "step": 38850
    },
    {
      "epoch": 4.163720132861888,
      "grad_norm": 31.689208984375,
      "learning_rate": 1.1672559734276225e-05,
      "loss": 0.1796,
      "step": 38860
    },
    {
      "epoch": 4.164791599699989,
      "grad_norm": 0.01285874005407095,
      "learning_rate": 1.1670416800600022e-05,
      "loss": 0.0056,
      "step": 38870
    },
    {
      "epoch": 4.1658630665380905,
      "grad_norm": 53.95981979370117,
      "learning_rate": 1.1668273866923821e-05,
      "loss": 0.1492,
      "step": 38880
    },
    {
      "epoch": 4.1669345333761925,
      "grad_norm": 0.03589095175266266,
      "learning_rate": 1.1666130933247617e-05,
      "loss": 0.0019,
      "step": 38890
    },
    {
      "epoch": 4.168006000214294,
      "grad_norm": 0.02454253099858761,
      "learning_rate": 1.1663987999571414e-05,
      "loss": 0.0006,
      "step": 38900
    },
    {
      "epoch": 4.169077467052395,
      "grad_norm": 49.49174499511719,
      "learning_rate": 1.1661845065895212e-05,
      "loss": 0.4785,
      "step": 38910
    },
    {
      "epoch": 4.170148933890496,
      "grad_norm": 82.01060485839844,
      "learning_rate": 1.1659702132219009e-05,
      "loss": 0.113,
      "step": 38920
    },
    {
      "epoch": 4.171220400728598,
      "grad_norm": 0.026192210614681244,
      "learning_rate": 1.1657559198542808e-05,
      "loss": 0.2019,
      "step": 38930
    },
    {
      "epoch": 4.172291867566699,
      "grad_norm": 0.03179115056991577,
      "learning_rate": 1.1655416264866604e-05,
      "loss": 0.3001,
      "step": 38940
    },
    {
      "epoch": 4.1733633344048,
      "grad_norm": 0.04130372777581215,
      "learning_rate": 1.16532733311904e-05,
      "loss": 0.0309,
      "step": 38950
    },
    {
      "epoch": 4.174434801242901,
      "grad_norm": 0.025781851261854172,
      "learning_rate": 1.1651130397514198e-05,
      "loss": 0.2344,
      "step": 38960
    },
    {
      "epoch": 4.175506268081003,
      "grad_norm": 0.030062109231948853,
      "learning_rate": 1.1648987463837996e-05,
      "loss": 0.192,
      "step": 38970
    },
    {
      "epoch": 4.176577734919104,
      "grad_norm": 0.12077764421701431,
      "learning_rate": 1.1646844530161791e-05,
      "loss": 0.1686,
      "step": 38980
    },
    {
      "epoch": 4.177649201757205,
      "grad_norm": 0.08138353377580643,
      "learning_rate": 1.164470159648559e-05,
      "loss": 0.1298,
      "step": 38990
    },
    {
      "epoch": 4.178720668595307,
      "grad_norm": 0.012906117364764214,
      "learning_rate": 1.1642558662809386e-05,
      "loss": 0.4347,
      "step": 39000
    },
    {
      "epoch": 4.179792135433408,
      "grad_norm": 0.01198939885944128,
      "learning_rate": 1.1640415729133183e-05,
      "loss": 0.4978,
      "step": 39010
    },
    {
      "epoch": 4.1808636022715095,
      "grad_norm": 0.02657211944460869,
      "learning_rate": 1.1638272795456982e-05,
      "loss": 0.1831,
      "step": 39020
    },
    {
      "epoch": 4.181935069109611,
      "grad_norm": 0.06539712846279144,
      "learning_rate": 1.1636129861780778e-05,
      "loss": 0.1793,
      "step": 39030
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 0.05057358741760254,
      "learning_rate": 1.1633986928104577e-05,
      "loss": 0.2274,
      "step": 39040
    },
    {
      "epoch": 4.184078002785814,
      "grad_norm": 0.08253894746303558,
      "learning_rate": 1.1631843994428373e-05,
      "loss": 0.2646,
      "step": 39050
    },
    {
      "epoch": 4.185149469623915,
      "grad_norm": 0.03967957943677902,
      "learning_rate": 1.162970106075217e-05,
      "loss": 0.0975,
      "step": 39060
    },
    {
      "epoch": 4.186220936462017,
      "grad_norm": 0.014703710563480854,
      "learning_rate": 1.162755812707597e-05,
      "loss": 0.1453,
      "step": 39070
    },
    {
      "epoch": 4.187292403300118,
      "grad_norm": 0.004769638646394014,
      "learning_rate": 1.1625415193399765e-05,
      "loss": 0.1863,
      "step": 39080
    },
    {
      "epoch": 4.188363870138219,
      "grad_norm": 0.31290170550346375,
      "learning_rate": 1.1623272259723562e-05,
      "loss": 0.0011,
      "step": 39090
    },
    {
      "epoch": 4.18943533697632,
      "grad_norm": 20.635406494140625,
      "learning_rate": 1.162112932604736e-05,
      "loss": 0.7939,
      "step": 39100
    },
    {
      "epoch": 4.190506803814422,
      "grad_norm": 0.07231879979372025,
      "learning_rate": 1.1618986392371157e-05,
      "loss": 0.001,
      "step": 39110
    },
    {
      "epoch": 4.191578270652523,
      "grad_norm": 0.02024858258664608,
      "learning_rate": 1.1616843458694956e-05,
      "loss": 0.0035,
      "step": 39120
    },
    {
      "epoch": 4.192649737490624,
      "grad_norm": 0.03426485136151314,
      "learning_rate": 1.1614700525018752e-05,
      "loss": 0.1072,
      "step": 39130
    },
    {
      "epoch": 4.193721204328726,
      "grad_norm": 0.009989488869905472,
      "learning_rate": 1.1612557591342547e-05,
      "loss": 0.1844,
      "step": 39140
    },
    {
      "epoch": 4.1947926711668275,
      "grad_norm": 0.014962343499064445,
      "learning_rate": 1.1610414657666346e-05,
      "loss": 0.0016,
      "step": 39150
    },
    {
      "epoch": 4.195864138004929,
      "grad_norm": 0.015190533362329006,
      "learning_rate": 1.1608271723990144e-05,
      "loss": 0.1741,
      "step": 39160
    },
    {
      "epoch": 4.19693560484303,
      "grad_norm": 15.445769309997559,
      "learning_rate": 1.160612879031394e-05,
      "loss": 0.2687,
      "step": 39170
    },
    {
      "epoch": 4.198007071681132,
      "grad_norm": 0.0306252334266901,
      "learning_rate": 1.1603985856637738e-05,
      "loss": 0.1908,
      "step": 39180
    },
    {
      "epoch": 4.199078538519233,
      "grad_norm": 21.97549057006836,
      "learning_rate": 1.1601842922961534e-05,
      "loss": 0.3994,
      "step": 39190
    },
    {
      "epoch": 4.200150005357334,
      "grad_norm": 0.04897646978497505,
      "learning_rate": 1.1599699989285333e-05,
      "loss": 0.1697,
      "step": 39200
    },
    {
      "epoch": 4.201221472195436,
      "grad_norm": 0.0037358200643211603,
      "learning_rate": 1.159755705560913e-05,
      "loss": 0.3572,
      "step": 39210
    },
    {
      "epoch": 4.202292939033537,
      "grad_norm": 0.009456872008740902,
      "learning_rate": 1.1595414121932926e-05,
      "loss": 0.3788,
      "step": 39220
    },
    {
      "epoch": 4.203364405871638,
      "grad_norm": 0.07190677523612976,
      "learning_rate": 1.1593271188256725e-05,
      "loss": 0.1634,
      "step": 39230
    },
    {
      "epoch": 4.204435872709739,
      "grad_norm": 0.10084211826324463,
      "learning_rate": 1.1591128254580521e-05,
      "loss": 0.0013,
      "step": 39240
    },
    {
      "epoch": 4.205507339547841,
      "grad_norm": 0.09349364787340164,
      "learning_rate": 1.1588985320904318e-05,
      "loss": 0.0961,
      "step": 39250
    },
    {
      "epoch": 4.206578806385942,
      "grad_norm": 0.053492844104766846,
      "learning_rate": 1.1586842387228117e-05,
      "loss": 0.3549,
      "step": 39260
    },
    {
      "epoch": 4.2076502732240435,
      "grad_norm": 0.16559045016765594,
      "learning_rate": 1.1584699453551913e-05,
      "loss": 0.1185,
      "step": 39270
    },
    {
      "epoch": 4.2087217400621455,
      "grad_norm": 25.625198364257812,
      "learning_rate": 1.1582556519875712e-05,
      "loss": 0.7401,
      "step": 39280
    },
    {
      "epoch": 4.209793206900247,
      "grad_norm": 0.08851722627878189,
      "learning_rate": 1.1580413586199508e-05,
      "loss": 0.3948,
      "step": 39290
    },
    {
      "epoch": 4.210864673738348,
      "grad_norm": 0.233555406332016,
      "learning_rate": 1.1578270652523305e-05,
      "loss": 0.0154,
      "step": 39300
    },
    {
      "epoch": 4.211936140576449,
      "grad_norm": 0.18689221143722534,
      "learning_rate": 1.1576127718847104e-05,
      "loss": 0.1888,
      "step": 39310
    },
    {
      "epoch": 4.213007607414551,
      "grad_norm": 0.10281776636838913,
      "learning_rate": 1.15739847851709e-05,
      "loss": 0.0541,
      "step": 39320
    },
    {
      "epoch": 4.214079074252652,
      "grad_norm": 0.014996582642197609,
      "learning_rate": 1.1571841851494695e-05,
      "loss": 0.2292,
      "step": 39330
    },
    {
      "epoch": 4.215150541090753,
      "grad_norm": 0.08850467950105667,
      "learning_rate": 1.1569698917818494e-05,
      "loss": 0.0027,
      "step": 39340
    },
    {
      "epoch": 4.216222007928854,
      "grad_norm": 0.06815772503614426,
      "learning_rate": 1.1567555984142292e-05,
      "loss": 0.2359,
      "step": 39350
    },
    {
      "epoch": 4.217293474766956,
      "grad_norm": 0.05968722328543663,
      "learning_rate": 1.156541305046609e-05,
      "loss": 0.1726,
      "step": 39360
    },
    {
      "epoch": 4.218364941605057,
      "grad_norm": 0.07854494452476501,
      "learning_rate": 1.1563270116789887e-05,
      "loss": 0.0019,
      "step": 39370
    },
    {
      "epoch": 4.219436408443158,
      "grad_norm": 0.005490228999406099,
      "learning_rate": 1.1561127183113682e-05,
      "loss": 0.8109,
      "step": 39380
    },
    {
      "epoch": 4.22050787528126,
      "grad_norm": 0.07026410847902298,
      "learning_rate": 1.1558984249437481e-05,
      "loss": 0.0012,
      "step": 39390
    },
    {
      "epoch": 4.2215793421193615,
      "grad_norm": 0.02280474081635475,
      "learning_rate": 1.1556841315761279e-05,
      "loss": 0.0015,
      "step": 39400
    },
    {
      "epoch": 4.222650808957463,
      "grad_norm": 0.10635069757699966,
      "learning_rate": 1.1554698382085074e-05,
      "loss": 0.4255,
      "step": 39410
    },
    {
      "epoch": 4.223722275795565,
      "grad_norm": 0.010290248319506645,
      "learning_rate": 1.1552555448408873e-05,
      "loss": 0.1291,
      "step": 39420
    },
    {
      "epoch": 4.224793742633666,
      "grad_norm": 0.06884149461984634,
      "learning_rate": 1.1550412514732669e-05,
      "loss": 0.0016,
      "step": 39430
    },
    {
      "epoch": 4.225865209471767,
      "grad_norm": 19.161603927612305,
      "learning_rate": 1.1548269581056468e-05,
      "loss": 0.2238,
      "step": 39440
    },
    {
      "epoch": 4.226936676309868,
      "grad_norm": 0.10051873326301575,
      "learning_rate": 1.1546126647380265e-05,
      "loss": 0.19,
      "step": 39450
    },
    {
      "epoch": 4.22800814314797,
      "grad_norm": 0.09139424562454224,
      "learning_rate": 1.1543983713704061e-05,
      "loss": 0.1522,
      "step": 39460
    },
    {
      "epoch": 4.229079609986071,
      "grad_norm": 0.09525291621685028,
      "learning_rate": 1.154184078002786e-05,
      "loss": 0.1697,
      "step": 39470
    },
    {
      "epoch": 4.230151076824172,
      "grad_norm": 23.258493423461914,
      "learning_rate": 1.1539697846351656e-05,
      "loss": 0.3068,
      "step": 39480
    },
    {
      "epoch": 4.231222543662273,
      "grad_norm": 0.010830591432750225,
      "learning_rate": 1.1537554912675453e-05,
      "loss": 0.7012,
      "step": 39490
    },
    {
      "epoch": 4.232294010500375,
      "grad_norm": 0.17541974782943726,
      "learning_rate": 1.1535411978999252e-05,
      "loss": 0.0019,
      "step": 39500
    },
    {
      "epoch": 4.233365477338476,
      "grad_norm": 0.07431312650442123,
      "learning_rate": 1.1533269045323048e-05,
      "loss": 0.0019,
      "step": 39510
    },
    {
      "epoch": 4.2344369441765775,
      "grad_norm": 14.782276153564453,
      "learning_rate": 1.1531126111646847e-05,
      "loss": 0.5566,
      "step": 39520
    },
    {
      "epoch": 4.2355084110146795,
      "grad_norm": 0.07461301982402802,
      "learning_rate": 1.1528983177970643e-05,
      "loss": 0.4223,
      "step": 39530
    },
    {
      "epoch": 4.236579877852781,
      "grad_norm": 0.09921667724847794,
      "learning_rate": 1.152684024429444e-05,
      "loss": 0.071,
      "step": 39540
    },
    {
      "epoch": 4.237651344690882,
      "grad_norm": 0.005642111878842115,
      "learning_rate": 1.1524697310618237e-05,
      "loss": 0.2688,
      "step": 39550
    },
    {
      "epoch": 4.238722811528983,
      "grad_norm": 0.15139855444431305,
      "learning_rate": 1.1522554376942035e-05,
      "loss": 0.1725,
      "step": 39560
    },
    {
      "epoch": 4.239794278367085,
      "grad_norm": 0.04168648645281792,
      "learning_rate": 1.152041144326583e-05,
      "loss": 0.2093,
      "step": 39570
    },
    {
      "epoch": 4.240865745205186,
      "grad_norm": 0.0033865259028971195,
      "learning_rate": 1.151826850958963e-05,
      "loss": 0.0048,
      "step": 39580
    },
    {
      "epoch": 4.241937212043287,
      "grad_norm": 20.522525787353516,
      "learning_rate": 1.1516125575913427e-05,
      "loss": 0.4718,
      "step": 39590
    },
    {
      "epoch": 4.243008678881389,
      "grad_norm": 0.003251219168305397,
      "learning_rate": 1.1513982642237224e-05,
      "loss": 0.171,
      "step": 39600
    },
    {
      "epoch": 4.24408014571949,
      "grad_norm": 0.4191543757915497,
      "learning_rate": 1.1511839708561021e-05,
      "loss": 0.0018,
      "step": 39610
    },
    {
      "epoch": 4.245151612557591,
      "grad_norm": 0.11756771802902222,
      "learning_rate": 1.1509696774884817e-05,
      "loss": 0.2848,
      "step": 39620
    },
    {
      "epoch": 4.246223079395692,
      "grad_norm": 0.03958916291594505,
      "learning_rate": 1.1507553841208616e-05,
      "loss": 0.7952,
      "step": 39630
    },
    {
      "epoch": 4.247294546233794,
      "grad_norm": 0.04884294793009758,
      "learning_rate": 1.1505410907532413e-05,
      "loss": 0.0018,
      "step": 39640
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 0.019280891865491867,
      "learning_rate": 1.1503267973856209e-05,
      "loss": 0.1415,
      "step": 39650
    },
    {
      "epoch": 4.2494374799099965,
      "grad_norm": 0.03522796556353569,
      "learning_rate": 1.1501125040180008e-05,
      "loss": 0.5184,
      "step": 39660
    },
    {
      "epoch": 4.2505089467480985,
      "grad_norm": 0.08301854878664017,
      "learning_rate": 1.1498982106503804e-05,
      "loss": 0.1603,
      "step": 39670
    },
    {
      "epoch": 4.2515804135862,
      "grad_norm": 0.07618547230958939,
      "learning_rate": 1.1496839172827603e-05,
      "loss": 0.0053,
      "step": 39680
    },
    {
      "epoch": 4.252651880424301,
      "grad_norm": 0.12236189842224121,
      "learning_rate": 1.14946962391514e-05,
      "loss": 0.3054,
      "step": 39690
    },
    {
      "epoch": 4.253723347262402,
      "grad_norm": 0.08228123933076859,
      "learning_rate": 1.1492553305475196e-05,
      "loss": 0.1704,
      "step": 39700
    },
    {
      "epoch": 4.254794814100504,
      "grad_norm": 0.0020289719104766846,
      "learning_rate": 1.1490410371798995e-05,
      "loss": 0.29,
      "step": 39710
    },
    {
      "epoch": 4.255866280938605,
      "grad_norm": 0.12178955227136612,
      "learning_rate": 1.148826743812279e-05,
      "loss": 0.0011,
      "step": 39720
    },
    {
      "epoch": 4.256937747776706,
      "grad_norm": 0.03694883733987808,
      "learning_rate": 1.1486124504446588e-05,
      "loss": 0.3408,
      "step": 39730
    },
    {
      "epoch": 4.258009214614808,
      "grad_norm": 0.02540723606944084,
      "learning_rate": 1.1483981570770385e-05,
      "loss": 0.383,
      "step": 39740
    },
    {
      "epoch": 4.259080681452909,
      "grad_norm": 0.044632893055677414,
      "learning_rate": 1.1481838637094183e-05,
      "loss": 0.28,
      "step": 39750
    },
    {
      "epoch": 4.26015214829101,
      "grad_norm": 0.19412647187709808,
      "learning_rate": 1.1479695703417982e-05,
      "loss": 0.1307,
      "step": 39760
    },
    {
      "epoch": 4.261223615129111,
      "grad_norm": 0.0031934259459376335,
      "learning_rate": 1.1477552769741777e-05,
      "loss": 0.1181,
      "step": 39770
    },
    {
      "epoch": 4.262295081967213,
      "grad_norm": 0.0041057453490793705,
      "learning_rate": 1.1475409836065575e-05,
      "loss": 0.1594,
      "step": 39780
    },
    {
      "epoch": 4.2633665488053145,
      "grad_norm": 0.16517099738121033,
      "learning_rate": 1.1473266902389372e-05,
      "loss": 0.2013,
      "step": 39790
    },
    {
      "epoch": 4.264438015643416,
      "grad_norm": 0.32859304547309875,
      "learning_rate": 1.147112396871317e-05,
      "loss": 0.0013,
      "step": 39800
    },
    {
      "epoch": 4.265509482481518,
      "grad_norm": 0.8998579382896423,
      "learning_rate": 1.1468981035036965e-05,
      "loss": 0.092,
      "step": 39810
    },
    {
      "epoch": 4.266580949319619,
      "grad_norm": 10.370882034301758,
      "learning_rate": 1.1466838101360764e-05,
      "loss": 0.3074,
      "step": 39820
    },
    {
      "epoch": 4.26765241615772,
      "grad_norm": 0.11698964238166809,
      "learning_rate": 1.1464695167684561e-05,
      "loss": 0.0826,
      "step": 39830
    },
    {
      "epoch": 4.268723882995821,
      "grad_norm": 0.2378634512424469,
      "learning_rate": 1.1462552234008359e-05,
      "loss": 0.1776,
      "step": 39840
    },
    {
      "epoch": 4.269795349833923,
      "grad_norm": 0.0007760753505863249,
      "learning_rate": 1.1460409300332156e-05,
      "loss": 0.1364,
      "step": 39850
    },
    {
      "epoch": 4.270866816672024,
      "grad_norm": 0.2100028395652771,
      "learning_rate": 1.1458266366655952e-05,
      "loss": 0.0011,
      "step": 39860
    },
    {
      "epoch": 4.271938283510125,
      "grad_norm": 0.037883028388023376,
      "learning_rate": 1.1456123432979751e-05,
      "loss": 0.0018,
      "step": 39870
    },
    {
      "epoch": 4.273009750348226,
      "grad_norm": 0.817107617855072,
      "learning_rate": 1.1453980499303548e-05,
      "loss": 0.0006,
      "step": 39880
    },
    {
      "epoch": 4.274081217186328,
      "grad_norm": 0.056215669959783554,
      "learning_rate": 1.1451837565627344e-05,
      "loss": 0.2011,
      "step": 39890
    },
    {
      "epoch": 4.275152684024429,
      "grad_norm": 102.4921646118164,
      "learning_rate": 1.1449694631951143e-05,
      "loss": 0.3462,
      "step": 39900
    },
    {
      "epoch": 4.2762241508625305,
      "grad_norm": 0.04789206385612488,
      "learning_rate": 1.1447551698274939e-05,
      "loss": 0.2345,
      "step": 39910
    },
    {
      "epoch": 4.2772956177006325,
      "grad_norm": 0.0007152135367505252,
      "learning_rate": 1.1445408764598736e-05,
      "loss": 0.0016,
      "step": 39920
    },
    {
      "epoch": 4.278367084538734,
      "grad_norm": 1.324508547782898,
      "learning_rate": 1.1443265830922533e-05,
      "loss": 0.2792,
      "step": 39930
    },
    {
      "epoch": 4.279438551376835,
      "grad_norm": 0.042279962450265884,
      "learning_rate": 1.144112289724633e-05,
      "loss": 0.32,
      "step": 39940
    },
    {
      "epoch": 4.280510018214937,
      "grad_norm": 0.0318579263985157,
      "learning_rate": 1.143897996357013e-05,
      "loss": 0.0021,
      "step": 39950
    },
    {
      "epoch": 4.281581485053038,
      "grad_norm": 0.026361554861068726,
      "learning_rate": 1.1436837029893925e-05,
      "loss": 0.5557,
      "step": 39960
    },
    {
      "epoch": 4.282652951891139,
      "grad_norm": 0.0011364179663360119,
      "learning_rate": 1.1434694096217723e-05,
      "loss": 0.0022,
      "step": 39970
    },
    {
      "epoch": 4.28372441872924,
      "grad_norm": 18.278011322021484,
      "learning_rate": 1.143255116254152e-05,
      "loss": 0.3659,
      "step": 39980
    },
    {
      "epoch": 4.284795885567342,
      "grad_norm": 0.040110114961862564,
      "learning_rate": 1.1430408228865317e-05,
      "loss": 0.0057,
      "step": 39990
    },
    {
      "epoch": 4.285867352405443,
      "grad_norm": 0.0071007609367370605,
      "learning_rate": 1.1428265295189113e-05,
      "loss": 0.1313,
      "step": 40000
    },
    {
      "epoch": 4.286938819243544,
      "grad_norm": 0.06743971258401871,
      "learning_rate": 1.1426122361512912e-05,
      "loss": 0.0933,
      "step": 40010
    },
    {
      "epoch": 4.288010286081645,
      "grad_norm": 0.0014814924215897918,
      "learning_rate": 1.142397942783671e-05,
      "loss": 0.1676,
      "step": 40020
    },
    {
      "epoch": 4.289081752919747,
      "grad_norm": 23.02549934387207,
      "learning_rate": 1.1421836494160507e-05,
      "loss": 0.2952,
      "step": 40030
    },
    {
      "epoch": 4.2901532197578485,
      "grad_norm": 0.014679335057735443,
      "learning_rate": 1.1419693560484304e-05,
      "loss": 0.006,
      "step": 40040
    },
    {
      "epoch": 4.29122468659595,
      "grad_norm": 0.05103716254234314,
      "learning_rate": 1.14175506268081e-05,
      "loss": 0.0025,
      "step": 40050
    },
    {
      "epoch": 4.292296153434052,
      "grad_norm": 0.0451357401907444,
      "learning_rate": 1.1415407693131899e-05,
      "loss": 0.3233,
      "step": 40060
    },
    {
      "epoch": 4.293367620272153,
      "grad_norm": 0.0005978806293569505,
      "learning_rate": 1.1413264759455696e-05,
      "loss": 0.0009,
      "step": 40070
    },
    {
      "epoch": 4.294439087110254,
      "grad_norm": 0.0040410542860627174,
      "learning_rate": 1.1411121825779492e-05,
      "loss": 0.1899,
      "step": 40080
    },
    {
      "epoch": 4.295510553948355,
      "grad_norm": 0.0005166327464394271,
      "learning_rate": 1.1408978892103291e-05,
      "loss": 0.3611,
      "step": 40090
    },
    {
      "epoch": 4.296582020786457,
      "grad_norm": 0.03925316035747528,
      "learning_rate": 1.1406835958427087e-05,
      "loss": 0.0074,
      "step": 40100
    },
    {
      "epoch": 4.297653487624558,
      "grad_norm": 0.040016576647758484,
      "learning_rate": 1.1404693024750886e-05,
      "loss": 0.0119,
      "step": 40110
    },
    {
      "epoch": 4.298724954462659,
      "grad_norm": 0.09032745659351349,
      "learning_rate": 1.1402550091074681e-05,
      "loss": 0.3899,
      "step": 40120
    },
    {
      "epoch": 4.299796421300761,
      "grad_norm": 0.09601325541734695,
      "learning_rate": 1.1400407157398479e-05,
      "loss": 0.3446,
      "step": 40130
    },
    {
      "epoch": 4.300867888138862,
      "grad_norm": 0.3102951943874359,
      "learning_rate": 1.1398264223722278e-05,
      "loss": 0.9025,
      "step": 40140
    },
    {
      "epoch": 4.301939354976963,
      "grad_norm": 0.027901355177164078,
      "learning_rate": 1.1396121290046073e-05,
      "loss": 0.1658,
      "step": 40150
    },
    {
      "epoch": 4.3030108218150644,
      "grad_norm": 2.7976412773132324,
      "learning_rate": 1.139397835636987e-05,
      "loss": 0.1858,
      "step": 40160
    },
    {
      "epoch": 4.304082288653166,
      "grad_norm": 1.2163136005401611,
      "learning_rate": 1.1391835422693668e-05,
      "loss": 0.0014,
      "step": 40170
    },
    {
      "epoch": 4.3051537554912676,
      "grad_norm": 0.15079337358474731,
      "learning_rate": 1.1389692489017466e-05,
      "loss": 0.4966,
      "step": 40180
    },
    {
      "epoch": 4.306225222329369,
      "grad_norm": 0.13681398332118988,
      "learning_rate": 1.1387549555341265e-05,
      "loss": 0.1428,
      "step": 40190
    },
    {
      "epoch": 4.307296689167471,
      "grad_norm": 0.14224715530872345,
      "learning_rate": 1.138540662166506e-05,
      "loss": 0.3824,
      "step": 40200
    },
    {
      "epoch": 4.308368156005572,
      "grad_norm": 0.019573552533984184,
      "learning_rate": 1.1383263687988858e-05,
      "loss": 0.3085,
      "step": 40210
    },
    {
      "epoch": 4.309439622843673,
      "grad_norm": 0.026629965752363205,
      "learning_rate": 1.1381120754312655e-05,
      "loss": 0.0389,
      "step": 40220
    },
    {
      "epoch": 4.310511089681774,
      "grad_norm": 0.045664794743061066,
      "learning_rate": 1.1378977820636452e-05,
      "loss": 0.0031,
      "step": 40230
    },
    {
      "epoch": 4.311582556519876,
      "grad_norm": 0.013391467742621899,
      "learning_rate": 1.1376834886960248e-05,
      "loss": 0.0053,
      "step": 40240
    },
    {
      "epoch": 4.312654023357977,
      "grad_norm": 0.003851803485304117,
      "learning_rate": 1.1374691953284047e-05,
      "loss": 0.1306,
      "step": 40250
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 0.1406455636024475,
      "learning_rate": 1.1372549019607844e-05,
      "loss": 0.0007,
      "step": 40260
    },
    {
      "epoch": 4.31479695703418,
      "grad_norm": 0.14358724653720856,
      "learning_rate": 1.1370406085931642e-05,
      "loss": 0.3852,
      "step": 40270
    },
    {
      "epoch": 4.315868423872281,
      "grad_norm": 0.0017166079487651587,
      "learning_rate": 1.1368263152255439e-05,
      "loss": 0.1957,
      "step": 40280
    },
    {
      "epoch": 4.316939890710382,
      "grad_norm": 0.20842374861240387,
      "learning_rate": 1.1366120218579235e-05,
      "loss": 0.0016,
      "step": 40290
    },
    {
      "epoch": 4.3180113575484835,
      "grad_norm": 21.80834197998047,
      "learning_rate": 1.1363977284903034e-05,
      "loss": 0.1029,
      "step": 40300
    },
    {
      "epoch": 4.3190828243865855,
      "grad_norm": 0.04072519764304161,
      "learning_rate": 1.136183435122683e-05,
      "loss": 0.0193,
      "step": 40310
    },
    {
      "epoch": 4.320154291224687,
      "grad_norm": 0.09962565451860428,
      "learning_rate": 1.1359691417550627e-05,
      "loss": 0.1342,
      "step": 40320
    },
    {
      "epoch": 4.321225758062788,
      "grad_norm": 0.033699508756399155,
      "learning_rate": 1.1357548483874426e-05,
      "loss": 0.2353,
      "step": 40330
    },
    {
      "epoch": 4.32229722490089,
      "grad_norm": 35.552001953125,
      "learning_rate": 1.1355405550198222e-05,
      "loss": 0.1426,
      "step": 40340
    },
    {
      "epoch": 4.323368691738991,
      "grad_norm": 0.05043637380003929,
      "learning_rate": 1.135326261652202e-05,
      "loss": 0.3581,
      "step": 40350
    },
    {
      "epoch": 4.324440158577092,
      "grad_norm": 16.970563888549805,
      "learning_rate": 1.1351119682845816e-05,
      "loss": 0.4236,
      "step": 40360
    },
    {
      "epoch": 4.325511625415193,
      "grad_norm": 29.75166130065918,
      "learning_rate": 1.1348976749169614e-05,
      "loss": 0.0046,
      "step": 40370
    },
    {
      "epoch": 4.326583092253295,
      "grad_norm": 0.09825874119997025,
      "learning_rate": 1.1346833815493413e-05,
      "loss": 0.0016,
      "step": 40380
    },
    {
      "epoch": 4.327654559091396,
      "grad_norm": 0.02025814726948738,
      "learning_rate": 1.1344690881817208e-05,
      "loss": 0.0013,
      "step": 40390
    },
    {
      "epoch": 4.328726025929497,
      "grad_norm": 42.093685150146484,
      "learning_rate": 1.1342547948141006e-05,
      "loss": 0.2072,
      "step": 40400
    },
    {
      "epoch": 4.329797492767598,
      "grad_norm": 0.0012491787783801556,
      "learning_rate": 1.1340405014464803e-05,
      "loss": 0.0007,
      "step": 40410
    },
    {
      "epoch": 4.3308689596057,
      "grad_norm": 0.0012775075156241655,
      "learning_rate": 1.13382620807886e-05,
      "loss": 0.0007,
      "step": 40420
    },
    {
      "epoch": 4.3319404264438015,
      "grad_norm": 0.001042185234837234,
      "learning_rate": 1.13361191471124e-05,
      "loss": 0.5169,
      "step": 40430
    },
    {
      "epoch": 4.333011893281903,
      "grad_norm": 0.009677608497440815,
      "learning_rate": 1.1333976213436195e-05,
      "loss": 0.5957,
      "step": 40440
    },
    {
      "epoch": 4.334083360120005,
      "grad_norm": 29.546785354614258,
      "learning_rate": 1.1331833279759992e-05,
      "loss": 0.1789,
      "step": 40450
    },
    {
      "epoch": 4.335154826958106,
      "grad_norm": 0.030726054683327675,
      "learning_rate": 1.132969034608379e-05,
      "loss": 0.0004,
      "step": 40460
    },
    {
      "epoch": 4.336226293796207,
      "grad_norm": 0.03596881777048111,
      "learning_rate": 1.1327547412407587e-05,
      "loss": 0.0008,
      "step": 40470
    },
    {
      "epoch": 4.337297760634309,
      "grad_norm": 0.007803624030202627,
      "learning_rate": 1.1325404478731383e-05,
      "loss": 0.0011,
      "step": 40480
    },
    {
      "epoch": 4.33836922747241,
      "grad_norm": 0.12361067533493042,
      "learning_rate": 1.1323261545055182e-05,
      "loss": 0.1576,
      "step": 40490
    },
    {
      "epoch": 4.339440694310511,
      "grad_norm": 0.03710617497563362,
      "learning_rate": 1.1321118611378978e-05,
      "loss": 0.0007,
      "step": 40500
    },
    {
      "epoch": 4.340512161148612,
      "grad_norm": 1.6309890747070312,
      "learning_rate": 1.1318975677702777e-05,
      "loss": 0.2261,
      "step": 40510
    },
    {
      "epoch": 4.341583627986714,
      "grad_norm": 0.7933910489082336,
      "learning_rate": 1.1316832744026574e-05,
      "loss": 0.2628,
      "step": 40520
    },
    {
      "epoch": 4.342655094824815,
      "grad_norm": 0.0019417847506701946,
      "learning_rate": 1.131468981035037e-05,
      "loss": 0.2148,
      "step": 40530
    },
    {
      "epoch": 4.343726561662916,
      "grad_norm": 0.10689293593168259,
      "learning_rate": 1.1312546876674169e-05,
      "loss": 0.0009,
      "step": 40540
    },
    {
      "epoch": 4.3447980285010175,
      "grad_norm": 0.06596497446298599,
      "learning_rate": 1.1310403942997964e-05,
      "loss": 0.0005,
      "step": 40550
    },
    {
      "epoch": 4.3458694953391195,
      "grad_norm": 0.03866015002131462,
      "learning_rate": 1.1308261009321762e-05,
      "loss": 0.0015,
      "step": 40560
    },
    {
      "epoch": 4.346940962177221,
      "grad_norm": 0.05643007904291153,
      "learning_rate": 1.130611807564556e-05,
      "loss": 0.1938,
      "step": 40570
    },
    {
      "epoch": 4.348012429015322,
      "grad_norm": 147.96261596679688,
      "learning_rate": 1.1303975141969356e-05,
      "loss": 0.2826,
      "step": 40580
    },
    {
      "epoch": 4.349083895853424,
      "grad_norm": 27.714399337768555,
      "learning_rate": 1.1301832208293155e-05,
      "loss": 0.8397,
      "step": 40590
    },
    {
      "epoch": 4.350155362691525,
      "grad_norm": 0.01948757842183113,
      "learning_rate": 1.1299689274616951e-05,
      "loss": 0.0027,
      "step": 40600
    },
    {
      "epoch": 4.351226829529626,
      "grad_norm": 0.003524237545207143,
      "learning_rate": 1.1297546340940748e-05,
      "loss": 0.4036,
      "step": 40610
    },
    {
      "epoch": 4.352298296367727,
      "grad_norm": 0.04296845197677612,
      "learning_rate": 1.1295403407264548e-05,
      "loss": 0.2033,
      "step": 40620
    },
    {
      "epoch": 4.353369763205829,
      "grad_norm": 0.08475430309772491,
      "learning_rate": 1.1293260473588343e-05,
      "loss": 0.1849,
      "step": 40630
    },
    {
      "epoch": 4.35444123004393,
      "grad_norm": 0.08318465203046799,
      "learning_rate": 1.129111753991214e-05,
      "loss": 0.1946,
      "step": 40640
    },
    {
      "epoch": 4.355512696882031,
      "grad_norm": 0.05813812091946602,
      "learning_rate": 1.1288974606235938e-05,
      "loss": 0.0048,
      "step": 40650
    },
    {
      "epoch": 4.356584163720133,
      "grad_norm": 0.01497067790478468,
      "learning_rate": 1.1286831672559735e-05,
      "loss": 0.0014,
      "step": 40660
    },
    {
      "epoch": 4.357655630558234,
      "grad_norm": 0.06521110981702805,
      "learning_rate": 1.1284688738883534e-05,
      "loss": 0.4443,
      "step": 40670
    },
    {
      "epoch": 4.3587270973963355,
      "grad_norm": 0.12634538114070892,
      "learning_rate": 1.128254580520733e-05,
      "loss": 0.1237,
      "step": 40680
    },
    {
      "epoch": 4.359798564234437,
      "grad_norm": 0.025293400511145592,
      "learning_rate": 1.1280402871531126e-05,
      "loss": 0.1944,
      "step": 40690
    },
    {
      "epoch": 4.360870031072539,
      "grad_norm": 0.003728172043338418,
      "learning_rate": 1.1278259937854925e-05,
      "loss": 0.1542,
      "step": 40700
    },
    {
      "epoch": 4.36194149791064,
      "grad_norm": 0.02337855100631714,
      "learning_rate": 1.1276117004178722e-05,
      "loss": 0.2902,
      "step": 40710
    },
    {
      "epoch": 4.363012964748741,
      "grad_norm": 0.0010765859624370933,
      "learning_rate": 1.1273974070502518e-05,
      "loss": 0.2339,
      "step": 40720
    },
    {
      "epoch": 4.364084431586843,
      "grad_norm": 0.0010501798242330551,
      "learning_rate": 1.1271831136826317e-05,
      "loss": 0.3108,
      "step": 40730
    },
    {
      "epoch": 4.365155898424944,
      "grad_norm": 25.697649002075195,
      "learning_rate": 1.1269688203150112e-05,
      "loss": 0.0067,
      "step": 40740
    },
    {
      "epoch": 4.366227365263045,
      "grad_norm": 0.0019173271721228957,
      "learning_rate": 1.1267545269473911e-05,
      "loss": 0.0018,
      "step": 40750
    },
    {
      "epoch": 4.367298832101146,
      "grad_norm": 0.08269849419593811,
      "learning_rate": 1.1265402335797709e-05,
      "loss": 0.1053,
      "step": 40760
    },
    {
      "epoch": 4.368370298939248,
      "grad_norm": 19.842390060424805,
      "learning_rate": 1.1263259402121504e-05,
      "loss": 0.6357,
      "step": 40770
    },
    {
      "epoch": 4.369441765777349,
      "grad_norm": 0.007976011373102665,
      "learning_rate": 1.1261116468445304e-05,
      "loss": 0.175,
      "step": 40780
    },
    {
      "epoch": 4.37051323261545,
      "grad_norm": 66.32630157470703,
      "learning_rate": 1.12589735347691e-05,
      "loss": 0.1217,
      "step": 40790
    },
    {
      "epoch": 4.371584699453552,
      "grad_norm": 0.06107354164123535,
      "learning_rate": 1.1256830601092897e-05,
      "loss": 0.062,
      "step": 40800
    },
    {
      "epoch": 4.372656166291653,
      "grad_norm": 0.13096489012241364,
      "learning_rate": 1.1254687667416696e-05,
      "loss": 0.4578,
      "step": 40810
    },
    {
      "epoch": 4.3737276331297545,
      "grad_norm": 0.6819050312042236,
      "learning_rate": 1.1252544733740491e-05,
      "loss": 0.0018,
      "step": 40820
    },
    {
      "epoch": 4.374799099967856,
      "grad_norm": 0.1045789122581482,
      "learning_rate": 1.1250401800064289e-05,
      "loss": 0.1682,
      "step": 40830
    },
    {
      "epoch": 4.375870566805958,
      "grad_norm": 0.028765389695763588,
      "learning_rate": 1.1248258866388086e-05,
      "loss": 0.4168,
      "step": 40840
    },
    {
      "epoch": 4.376942033644059,
      "grad_norm": 0.0032827502582222223,
      "learning_rate": 1.1246115932711883e-05,
      "loss": 0.1918,
      "step": 40850
    },
    {
      "epoch": 4.37801350048216,
      "grad_norm": 0.19199684262275696,
      "learning_rate": 1.1243972999035682e-05,
      "loss": 0.0022,
      "step": 40860
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 0.9122486114501953,
      "learning_rate": 1.1241830065359478e-05,
      "loss": 0.4973,
      "step": 40870
    },
    {
      "epoch": 4.380156434158363,
      "grad_norm": 0.09235258400440216,
      "learning_rate": 1.1239687131683274e-05,
      "loss": 0.2057,
      "step": 40880
    },
    {
      "epoch": 4.381227900996464,
      "grad_norm": 0.0335715226829052,
      "learning_rate": 1.1237544198007073e-05,
      "loss": 0.0513,
      "step": 40890
    },
    {
      "epoch": 4.382299367834565,
      "grad_norm": 0.03667965531349182,
      "learning_rate": 1.123540126433087e-05,
      "loss": 0.0104,
      "step": 40900
    },
    {
      "epoch": 4.383370834672667,
      "grad_norm": 21.817790985107422,
      "learning_rate": 1.1233258330654666e-05,
      "loss": 0.1752,
      "step": 40910
    },
    {
      "epoch": 4.384442301510768,
      "grad_norm": 0.06546397507190704,
      "learning_rate": 1.1231115396978465e-05,
      "loss": 0.0008,
      "step": 40920
    },
    {
      "epoch": 4.385513768348869,
      "grad_norm": 0.11543789505958557,
      "learning_rate": 1.122897246330226e-05,
      "loss": 0.0007,
      "step": 40930
    },
    {
      "epoch": 4.3865852351869705,
      "grad_norm": 0.011638355441391468,
      "learning_rate": 1.122682952962606e-05,
      "loss": 0.2876,
      "step": 40940
    },
    {
      "epoch": 4.3876567020250725,
      "grad_norm": 17.759017944335938,
      "learning_rate": 1.1224686595949857e-05,
      "loss": 0.3585,
      "step": 40950
    },
    {
      "epoch": 4.388728168863174,
      "grad_norm": 0.031696900725364685,
      "learning_rate": 1.1222543662273653e-05,
      "loss": 0.2714,
      "step": 40960
    },
    {
      "epoch": 4.389799635701275,
      "grad_norm": 0.011519679799675941,
      "learning_rate": 1.1220400728597452e-05,
      "loss": 0.0007,
      "step": 40970
    },
    {
      "epoch": 4.390871102539377,
      "grad_norm": 0.012020169757306576,
      "learning_rate": 1.1218257794921247e-05,
      "loss": 0.4664,
      "step": 40980
    },
    {
      "epoch": 4.391942569377478,
      "grad_norm": 26.225412368774414,
      "learning_rate": 1.1216114861245045e-05,
      "loss": 0.1465,
      "step": 40990
    },
    {
      "epoch": 4.393014036215579,
      "grad_norm": 0.04716431349515915,
      "learning_rate": 1.1213971927568844e-05,
      "loss": 0.1646,
      "step": 41000
    },
    {
      "epoch": 4.394085503053681,
      "grad_norm": 0.08667007833719254,
      "learning_rate": 1.121182899389264e-05,
      "loss": 0.0012,
      "step": 41010
    },
    {
      "epoch": 4.395156969891782,
      "grad_norm": 0.004331686999648809,
      "learning_rate": 1.1209686060216438e-05,
      "loss": 0.8666,
      "step": 41020
    },
    {
      "epoch": 4.396228436729883,
      "grad_norm": 22.924753189086914,
      "learning_rate": 1.1207543126540234e-05,
      "loss": 0.3608,
      "step": 41030
    },
    {
      "epoch": 4.397299903567984,
      "grad_norm": 0.01790272817015648,
      "learning_rate": 1.1205400192864031e-05,
      "loss": 0.0017,
      "step": 41040
    },
    {
      "epoch": 4.398371370406086,
      "grad_norm": 0.0014535092050209641,
      "learning_rate": 1.120325725918783e-05,
      "loss": 0.3984,
      "step": 41050
    },
    {
      "epoch": 4.399442837244187,
      "grad_norm": 0.09003810584545135,
      "learning_rate": 1.1201114325511626e-05,
      "loss": 0.5689,
      "step": 41060
    },
    {
      "epoch": 4.4005143040822885,
      "grad_norm": 0.1184377446770668,
      "learning_rate": 1.1198971391835422e-05,
      "loss": 0.0031,
      "step": 41070
    },
    {
      "epoch": 4.40158577092039,
      "grad_norm": 0.05490463972091675,
      "learning_rate": 1.119682845815922e-05,
      "loss": 0.1354,
      "step": 41080
    },
    {
      "epoch": 4.402657237758492,
      "grad_norm": 0.0441158264875412,
      "learning_rate": 1.1194685524483018e-05,
      "loss": 0.1693,
      "step": 41090
    },
    {
      "epoch": 4.403728704596593,
      "grad_norm": 0.22808276116847992,
      "learning_rate": 1.1192542590806817e-05,
      "loss": 0.2582,
      "step": 41100
    },
    {
      "epoch": 4.404800171434694,
      "grad_norm": 0.2137605845928192,
      "learning_rate": 1.1190399657130613e-05,
      "loss": 0.832,
      "step": 41110
    },
    {
      "epoch": 4.405871638272796,
      "grad_norm": 0.04154570773243904,
      "learning_rate": 1.1188256723454409e-05,
      "loss": 0.1864,
      "step": 41120
    },
    {
      "epoch": 4.406943105110897,
      "grad_norm": 0.2556178569793701,
      "learning_rate": 1.1186113789778208e-05,
      "loss": 0.0019,
      "step": 41130
    },
    {
      "epoch": 4.408014571948998,
      "grad_norm": 0.12454986572265625,
      "learning_rate": 1.1183970856102005e-05,
      "loss": 0.1417,
      "step": 41140
    },
    {
      "epoch": 4.409086038787099,
      "grad_norm": 0.04449882358312607,
      "learning_rate": 1.11818279224258e-05,
      "loss": 0.0009,
      "step": 41150
    },
    {
      "epoch": 4.410157505625201,
      "grad_norm": 94.02934265136719,
      "learning_rate": 1.11796849887496e-05,
      "loss": 0.3832,
      "step": 41160
    },
    {
      "epoch": 4.411228972463302,
      "grad_norm": 0.003209838178008795,
      "learning_rate": 1.1177542055073395e-05,
      "loss": 0.1635,
      "step": 41170
    },
    {
      "epoch": 4.412300439301403,
      "grad_norm": 0.002191179199144244,
      "learning_rate": 1.1175399121397194e-05,
      "loss": 0.0006,
      "step": 41180
    },
    {
      "epoch": 4.413371906139505,
      "grad_norm": 0.493895947933197,
      "learning_rate": 1.1173256187720992e-05,
      "loss": 0.4051,
      "step": 41190
    },
    {
      "epoch": 4.4144433729776065,
      "grad_norm": 0.003069785423576832,
      "learning_rate": 1.1171113254044787e-05,
      "loss": 0.0025,
      "step": 41200
    },
    {
      "epoch": 4.415514839815708,
      "grad_norm": 0.011052888818085194,
      "learning_rate": 1.1168970320368586e-05,
      "loss": 0.0017,
      "step": 41210
    },
    {
      "epoch": 4.416586306653809,
      "grad_norm": 0.0019756758119910955,
      "learning_rate": 1.1166827386692382e-05,
      "loss": 0.0015,
      "step": 41220
    },
    {
      "epoch": 4.417657773491911,
      "grad_norm": 0.06285984814167023,
      "learning_rate": 1.116468445301618e-05,
      "loss": 0.0006,
      "step": 41230
    },
    {
      "epoch": 4.418729240330012,
      "grad_norm": 22.001985549926758,
      "learning_rate": 1.1162541519339978e-05,
      "loss": 0.1964,
      "step": 41240
    },
    {
      "epoch": 4.419800707168113,
      "grad_norm": 0.010370153933763504,
      "learning_rate": 1.1160398585663774e-05,
      "loss": 0.4093,
      "step": 41250
    },
    {
      "epoch": 4.420872174006215,
      "grad_norm": 0.00880440603941679,
      "learning_rate": 1.1158255651987573e-05,
      "loss": 0.0007,
      "step": 41260
    },
    {
      "epoch": 4.421943640844316,
      "grad_norm": 0.0014785879757255316,
      "learning_rate": 1.1156112718311369e-05,
      "loss": 0.1153,
      "step": 41270
    },
    {
      "epoch": 4.423015107682417,
      "grad_norm": 0.0757070779800415,
      "learning_rate": 1.1153969784635166e-05,
      "loss": 0.0012,
      "step": 41280
    },
    {
      "epoch": 4.424086574520518,
      "grad_norm": 0.005715047940611839,
      "learning_rate": 1.1151826850958965e-05,
      "loss": 0.3707,
      "step": 41290
    },
    {
      "epoch": 4.42515804135862,
      "grad_norm": 27.048070907592773,
      "learning_rate": 1.1149683917282761e-05,
      "loss": 0.1663,
      "step": 41300
    },
    {
      "epoch": 4.426229508196721,
      "grad_norm": 45.569297790527344,
      "learning_rate": 1.1147540983606557e-05,
      "loss": 0.3387,
      "step": 41310
    },
    {
      "epoch": 4.4273009750348225,
      "grad_norm": 0.007737435400485992,
      "learning_rate": 1.1145398049930356e-05,
      "loss": 0.2965,
      "step": 41320
    },
    {
      "epoch": 4.4283724418729244,
      "grad_norm": 0.04181743040680885,
      "learning_rate": 1.1143255116254153e-05,
      "loss": 0.1383,
      "step": 41330
    },
    {
      "epoch": 4.429443908711026,
      "grad_norm": 27.74357795715332,
      "learning_rate": 1.114111218257795e-05,
      "loss": 0.332,
      "step": 41340
    },
    {
      "epoch": 4.430515375549127,
      "grad_norm": 0.015170363709330559,
      "learning_rate": 1.1138969248901748e-05,
      "loss": 0.2081,
      "step": 41350
    },
    {
      "epoch": 4.431586842387228,
      "grad_norm": 0.0014692010590806603,
      "learning_rate": 1.1136826315225543e-05,
      "loss": 0.1566,
      "step": 41360
    },
    {
      "epoch": 4.43265830922533,
      "grad_norm": 0.12208371609449387,
      "learning_rate": 1.1134683381549342e-05,
      "loss": 0.3127,
      "step": 41370
    },
    {
      "epoch": 4.433729776063431,
      "grad_norm": 0.004217511508613825,
      "learning_rate": 1.113254044787314e-05,
      "loss": 0.1614,
      "step": 41380
    },
    {
      "epoch": 4.434801242901532,
      "grad_norm": 0.8105095624923706,
      "learning_rate": 1.1130397514196935e-05,
      "loss": 0.0056,
      "step": 41390
    },
    {
      "epoch": 4.435872709739634,
      "grad_norm": 0.004393649287521839,
      "learning_rate": 1.1128254580520734e-05,
      "loss": 0.0155,
      "step": 41400
    },
    {
      "epoch": 4.436944176577735,
      "grad_norm": 0.003361725015565753,
      "learning_rate": 1.112611164684453e-05,
      "loss": 0.1567,
      "step": 41410
    },
    {
      "epoch": 4.438015643415836,
      "grad_norm": 17.17924690246582,
      "learning_rate": 1.112396871316833e-05,
      "loss": 0.1328,
      "step": 41420
    },
    {
      "epoch": 4.439087110253937,
      "grad_norm": 0.00714637478813529,
      "learning_rate": 1.1121825779492127e-05,
      "loss": 0.001,
      "step": 41430
    },
    {
      "epoch": 4.440158577092039,
      "grad_norm": 0.210779070854187,
      "learning_rate": 1.1119682845815922e-05,
      "loss": 0.3394,
      "step": 41440
    },
    {
      "epoch": 4.44123004393014,
      "grad_norm": 0.004535103682428598,
      "learning_rate": 1.1117539912139721e-05,
      "loss": 0.0007,
      "step": 41450
    },
    {
      "epoch": 4.4423015107682415,
      "grad_norm": 0.3175329267978668,
      "learning_rate": 1.1115396978463517e-05,
      "loss": 0.0008,
      "step": 41460
    },
    {
      "epoch": 4.443372977606343,
      "grad_norm": 0.008882812224328518,
      "learning_rate": 1.1113254044787314e-05,
      "loss": 0.0012,
      "step": 41470
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 0.004738332703709602,
      "learning_rate": 1.1111111111111113e-05,
      "loss": 0.002,
      "step": 41480
    },
    {
      "epoch": 4.445515911282546,
      "grad_norm": 0.0012895796680822968,
      "learning_rate": 1.1108968177434909e-05,
      "loss": 0.0003,
      "step": 41490
    },
    {
      "epoch": 4.446587378120647,
      "grad_norm": 0.008820191025733948,
      "learning_rate": 1.1106825243758708e-05,
      "loss": 0.2625,
      "step": 41500
    },
    {
      "epoch": 4.447658844958749,
      "grad_norm": 0.017079031094908714,
      "learning_rate": 1.1104682310082504e-05,
      "loss": 0.2138,
      "step": 41510
    },
    {
      "epoch": 4.44873031179685,
      "grad_norm": 0.022949934005737305,
      "learning_rate": 1.1102539376406301e-05,
      "loss": 0.1473,
      "step": 41520
    },
    {
      "epoch": 4.449801778634951,
      "grad_norm": 0.13449974358081818,
      "learning_rate": 1.1100396442730098e-05,
      "loss": 0.1285,
      "step": 41530
    },
    {
      "epoch": 4.450873245473053,
      "grad_norm": 0.023580126464366913,
      "learning_rate": 1.1098253509053896e-05,
      "loss": 0.1457,
      "step": 41540
    },
    {
      "epoch": 4.451944712311154,
      "grad_norm": 0.00529683381319046,
      "learning_rate": 1.1096110575377691e-05,
      "loss": 0.1733,
      "step": 41550
    },
    {
      "epoch": 4.453016179149255,
      "grad_norm": 55.25624084472656,
      "learning_rate": 1.109396764170149e-05,
      "loss": 0.2113,
      "step": 41560
    },
    {
      "epoch": 4.454087645987356,
      "grad_norm": 0.006052218843251467,
      "learning_rate": 1.1091824708025288e-05,
      "loss": 0.4473,
      "step": 41570
    },
    {
      "epoch": 4.455159112825458,
      "grad_norm": 0.015312681905925274,
      "learning_rate": 1.1089681774349085e-05,
      "loss": 0.1166,
      "step": 41580
    },
    {
      "epoch": 4.4562305796635595,
      "grad_norm": 0.00463102525100112,
      "learning_rate": 1.1087538840672883e-05,
      "loss": 0.1851,
      "step": 41590
    },
    {
      "epoch": 4.457302046501661,
      "grad_norm": 0.05708110332489014,
      "learning_rate": 1.1085395906996678e-05,
      "loss": 0.0008,
      "step": 41600
    },
    {
      "epoch": 4.458373513339762,
      "grad_norm": 0.016396816819906235,
      "learning_rate": 1.1083252973320477e-05,
      "loss": 0.1758,
      "step": 41610
    },
    {
      "epoch": 4.459444980177864,
      "grad_norm": 0.011343399062752724,
      "learning_rate": 1.1081110039644275e-05,
      "loss": 0.0028,
      "step": 41620
    },
    {
      "epoch": 4.460516447015965,
      "grad_norm": 0.025820476934313774,
      "learning_rate": 1.107896710596807e-05,
      "loss": 0.0004,
      "step": 41630
    },
    {
      "epoch": 4.461587913854066,
      "grad_norm": 177.45567321777344,
      "learning_rate": 1.107682417229187e-05,
      "loss": 0.1327,
      "step": 41640
    },
    {
      "epoch": 4.462659380692168,
      "grad_norm": 0.006794061977416277,
      "learning_rate": 1.1074681238615665e-05,
      "loss": 0.291,
      "step": 41650
    },
    {
      "epoch": 4.463730847530269,
      "grad_norm": 0.021691223606467247,
      "learning_rate": 1.1072538304939464e-05,
      "loss": 0.0007,
      "step": 41660
    },
    {
      "epoch": 4.46480231436837,
      "grad_norm": 0.006669110152870417,
      "learning_rate": 1.1070395371263261e-05,
      "loss": 0.0005,
      "step": 41670
    },
    {
      "epoch": 4.465873781206471,
      "grad_norm": 0.04273165762424469,
      "learning_rate": 1.1068252437587057e-05,
      "loss": 0.0051,
      "step": 41680
    },
    {
      "epoch": 4.466945248044573,
      "grad_norm": 0.024035563692450523,
      "learning_rate": 1.1066109503910856e-05,
      "loss": 0.201,
      "step": 41690
    },
    {
      "epoch": 4.468016714882674,
      "grad_norm": 0.01928449608385563,
      "learning_rate": 1.1063966570234652e-05,
      "loss": 0.2693,
      "step": 41700
    },
    {
      "epoch": 4.4690881817207755,
      "grad_norm": 36.375732421875,
      "learning_rate": 1.1061823636558449e-05,
      "loss": 0.4323,
      "step": 41710
    },
    {
      "epoch": 4.4701596485588775,
      "grad_norm": 0.08743316680192947,
      "learning_rate": 1.1059680702882246e-05,
      "loss": 0.6025,
      "step": 41720
    },
    {
      "epoch": 4.471231115396979,
      "grad_norm": 217.7635955810547,
      "learning_rate": 1.1057537769206044e-05,
      "loss": 0.4224,
      "step": 41730
    },
    {
      "epoch": 4.47230258223508,
      "grad_norm": 0.02656199410557747,
      "learning_rate": 1.105539483552984e-05,
      "loss": 0.0024,
      "step": 41740
    },
    {
      "epoch": 4.473374049073181,
      "grad_norm": 0.04978993907570839,
      "learning_rate": 1.1053251901853639e-05,
      "loss": 0.1419,
      "step": 41750
    },
    {
      "epoch": 4.474445515911283,
      "grad_norm": 0.03156616538763046,
      "learning_rate": 1.1051108968177436e-05,
      "loss": 0.0021,
      "step": 41760
    },
    {
      "epoch": 4.475516982749384,
      "grad_norm": 0.18289391696453094,
      "learning_rate": 1.1048966034501233e-05,
      "loss": 0.139,
      "step": 41770
    },
    {
      "epoch": 4.476588449587485,
      "grad_norm": 1.2058049440383911,
      "learning_rate": 1.104682310082503e-05,
      "loss": 0.0029,
      "step": 41780
    },
    {
      "epoch": 4.477659916425587,
      "grad_norm": 0.012439793907105923,
      "learning_rate": 1.1044680167148826e-05,
      "loss": 0.0275,
      "step": 41790
    },
    {
      "epoch": 4.478731383263688,
      "grad_norm": 0.00551562150940299,
      "learning_rate": 1.1042537233472625e-05,
      "loss": 0.2704,
      "step": 41800
    },
    {
      "epoch": 4.479802850101789,
      "grad_norm": 0.14256620407104492,
      "learning_rate": 1.1040394299796423e-05,
      "loss": 0.0006,
      "step": 41810
    },
    {
      "epoch": 4.48087431693989,
      "grad_norm": 1.702004075050354,
      "learning_rate": 1.1038251366120218e-05,
      "loss": 0.0478,
      "step": 41820
    },
    {
      "epoch": 4.481945783777992,
      "grad_norm": 0.0016173019539564848,
      "learning_rate": 1.1036108432444017e-05,
      "loss": 0.1822,
      "step": 41830
    },
    {
      "epoch": 4.4830172506160935,
      "grad_norm": 0.049542780965566635,
      "learning_rate": 1.1033965498767813e-05,
      "loss": 0.1022,
      "step": 41840
    },
    {
      "epoch": 4.484088717454195,
      "grad_norm": 0.008995238691568375,
      "learning_rate": 1.1031822565091612e-05,
      "loss": 0.0015,
      "step": 41850
    },
    {
      "epoch": 4.485160184292296,
      "grad_norm": 29.371370315551758,
      "learning_rate": 1.102967963141541e-05,
      "loss": 0.6261,
      "step": 41860
    },
    {
      "epoch": 4.486231651130398,
      "grad_norm": 0.01613866724073887,
      "learning_rate": 1.1027536697739205e-05,
      "loss": 0.1667,
      "step": 41870
    },
    {
      "epoch": 4.487303117968499,
      "grad_norm": 0.01885331980884075,
      "learning_rate": 1.1025393764063004e-05,
      "loss": 0.4432,
      "step": 41880
    },
    {
      "epoch": 4.4883745848066,
      "grad_norm": 0.010433107614517212,
      "learning_rate": 1.10232508303868e-05,
      "loss": 0.0017,
      "step": 41890
    },
    {
      "epoch": 4.489446051644702,
      "grad_norm": 0.05057714506983757,
      "learning_rate": 1.1021107896710597e-05,
      "loss": 0.192,
      "step": 41900
    },
    {
      "epoch": 4.490517518482803,
      "grad_norm": 0.040996912866830826,
      "learning_rate": 1.1018964963034395e-05,
      "loss": 0.0009,
      "step": 41910
    },
    {
      "epoch": 4.491588985320904,
      "grad_norm": 0.04314315691590309,
      "learning_rate": 1.1016822029358192e-05,
      "loss": 0.1919,
      "step": 41920
    },
    {
      "epoch": 4.492660452159006,
      "grad_norm": 41.933326721191406,
      "learning_rate": 1.1014679095681991e-05,
      "loss": 0.1588,
      "step": 41930
    },
    {
      "epoch": 4.493731918997107,
      "grad_norm": 0.05298725888133049,
      "learning_rate": 1.1012536162005787e-05,
      "loss": 0.1987,
      "step": 41940
    },
    {
      "epoch": 4.494803385835208,
      "grad_norm": 101.81362915039062,
      "learning_rate": 1.1010393228329584e-05,
      "loss": 0.5562,
      "step": 41950
    },
    {
      "epoch": 4.495874852673309,
      "grad_norm": 0.03012218326330185,
      "learning_rate": 1.1008250294653381e-05,
      "loss": 0.1692,
      "step": 41960
    },
    {
      "epoch": 4.496946319511411,
      "grad_norm": 0.13175998628139496,
      "learning_rate": 1.1006107360977179e-05,
      "loss": 0.4598,
      "step": 41970
    },
    {
      "epoch": 4.4980177863495125,
      "grad_norm": 0.16051167249679565,
      "learning_rate": 1.1003964427300974e-05,
      "loss": 0.164,
      "step": 41980
    },
    {
      "epoch": 4.499089253187614,
      "grad_norm": 42.0570068359375,
      "learning_rate": 1.1001821493624773e-05,
      "loss": 0.1453,
      "step": 41990
    },
    {
      "epoch": 4.500160720025715,
      "grad_norm": 0.122469462454319,
      "learning_rate": 1.099967855994857e-05,
      "loss": 0.0019,
      "step": 42000
    },
    {
      "epoch": 4.501232186863817,
      "grad_norm": 0.11699020862579346,
      "learning_rate": 1.0997535626272368e-05,
      "loss": 0.1791,
      "step": 42010
    },
    {
      "epoch": 4.502303653701918,
      "grad_norm": 0.00390548724681139,
      "learning_rate": 1.0995392692596165e-05,
      "loss": 0.1465,
      "step": 42020
    },
    {
      "epoch": 4.503375120540019,
      "grad_norm": 26.502885818481445,
      "learning_rate": 1.0993249758919961e-05,
      "loss": 0.2381,
      "step": 42030
    },
    {
      "epoch": 4.504446587378121,
      "grad_norm": 0.0023921693209558725,
      "learning_rate": 1.099110682524376e-05,
      "loss": 0.163,
      "step": 42040
    },
    {
      "epoch": 4.505518054216222,
      "grad_norm": 0.012815326452255249,
      "learning_rate": 1.0988963891567558e-05,
      "loss": 0.193,
      "step": 42050
    },
    {
      "epoch": 4.506589521054323,
      "grad_norm": 0.006932966876775026,
      "learning_rate": 1.0986820957891353e-05,
      "loss": 0.0017,
      "step": 42060
    },
    {
      "epoch": 4.507660987892425,
      "grad_norm": 0.021955333650112152,
      "learning_rate": 1.0984678024215152e-05,
      "loss": 0.0469,
      "step": 42070
    },
    {
      "epoch": 4.508732454730526,
      "grad_norm": 32.763729095458984,
      "learning_rate": 1.0982535090538948e-05,
      "loss": 0.0462,
      "step": 42080
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 0.11348185688257217,
      "learning_rate": 1.0980392156862747e-05,
      "loss": 0.0013,
      "step": 42090
    },
    {
      "epoch": 4.5108753884067285,
      "grad_norm": 166.29611206054688,
      "learning_rate": 1.0978249223186543e-05,
      "loss": 0.1922,
      "step": 42100
    },
    {
      "epoch": 4.5119468552448305,
      "grad_norm": 0.0017185087781399488,
      "learning_rate": 1.097610628951034e-05,
      "loss": 0.0011,
      "step": 42110
    },
    {
      "epoch": 4.513018322082932,
      "grad_norm": 0.06881414353847504,
      "learning_rate": 1.0973963355834139e-05,
      "loss": 0.2233,
      "step": 42120
    },
    {
      "epoch": 4.514089788921033,
      "grad_norm": 0.016208194196224213,
      "learning_rate": 1.0971820422157935e-05,
      "loss": 0.1987,
      "step": 42130
    },
    {
      "epoch": 4.515161255759134,
      "grad_norm": 0.0009998169261962175,
      "learning_rate": 1.0969677488481732e-05,
      "loss": 0.0008,
      "step": 42140
    },
    {
      "epoch": 4.516232722597236,
      "grad_norm": 0.021034622564911842,
      "learning_rate": 1.096753455480553e-05,
      "loss": 0.2542,
      "step": 42150
    },
    {
      "epoch": 4.517304189435337,
      "grad_norm": 0.0012376202503219247,
      "learning_rate": 1.0965391621129327e-05,
      "loss": 0.3032,
      "step": 42160
    },
    {
      "epoch": 4.518375656273438,
      "grad_norm": 0.007579261437058449,
      "learning_rate": 1.0963248687453126e-05,
      "loss": 0.3347,
      "step": 42170
    },
    {
      "epoch": 4.51944712311154,
      "grad_norm": 0.35595405101776123,
      "learning_rate": 1.0961105753776921e-05,
      "loss": 0.406,
      "step": 42180
    },
    {
      "epoch": 4.520518589949641,
      "grad_norm": 0.015964185819029808,
      "learning_rate": 1.0958962820100719e-05,
      "loss": 0.4394,
      "step": 42190
    },
    {
      "epoch": 4.521590056787742,
      "grad_norm": 17.813905715942383,
      "learning_rate": 1.0956819886424516e-05,
      "loss": 0.2119,
      "step": 42200
    },
    {
      "epoch": 4.522661523625843,
      "grad_norm": 8.178297996520996,
      "learning_rate": 1.0954676952748314e-05,
      "loss": 0.0052,
      "step": 42210
    },
    {
      "epoch": 4.523732990463945,
      "grad_norm": 0.007999813184142113,
      "learning_rate": 1.095253401907211e-05,
      "loss": 0.1738,
      "step": 42220
    },
    {
      "epoch": 4.5248044573020465,
      "grad_norm": 0.19080950319766998,
      "learning_rate": 1.0950391085395908e-05,
      "loss": 0.3698,
      "step": 42230
    },
    {
      "epoch": 4.525875924140148,
      "grad_norm": 0.012940394692122936,
      "learning_rate": 1.0948248151719706e-05,
      "loss": 0.0011,
      "step": 42240
    },
    {
      "epoch": 4.52694739097825,
      "grad_norm": 0.002301478059962392,
      "learning_rate": 1.0946105218043503e-05,
      "loss": 0.0009,
      "step": 42250
    },
    {
      "epoch": 4.528018857816351,
      "grad_norm": 20.845096588134766,
      "learning_rate": 1.09439622843673e-05,
      "loss": 0.3963,
      "step": 42260
    },
    {
      "epoch": 4.529090324654452,
      "grad_norm": 0.009136880747973919,
      "learning_rate": 1.0941819350691096e-05,
      "loss": 0.0018,
      "step": 42270
    },
    {
      "epoch": 4.530161791492553,
      "grad_norm": 0.07697097212076187,
      "learning_rate": 1.0939676417014895e-05,
      "loss": 0.2951,
      "step": 42280
    },
    {
      "epoch": 4.531233258330655,
      "grad_norm": 0.18405508995056152,
      "learning_rate": 1.093753348333869e-05,
      "loss": 0.0023,
      "step": 42290
    },
    {
      "epoch": 4.532304725168756,
      "grad_norm": 0.006278278771787882,
      "learning_rate": 1.0935390549662488e-05,
      "loss": 0.0021,
      "step": 42300
    },
    {
      "epoch": 4.533376192006857,
      "grad_norm": 0.02391665056347847,
      "learning_rate": 1.0933247615986287e-05,
      "loss": 0.0009,
      "step": 42310
    },
    {
      "epoch": 4.534447658844959,
      "grad_norm": 0.006905549671500921,
      "learning_rate": 1.0931104682310083e-05,
      "loss": 0.4883,
      "step": 42320
    },
    {
      "epoch": 4.53551912568306,
      "grad_norm": 0.06824111193418503,
      "learning_rate": 1.0928961748633882e-05,
      "loss": 0.5598,
      "step": 42330
    },
    {
      "epoch": 4.536590592521161,
      "grad_norm": 0.14672178030014038,
      "learning_rate": 1.0926818814957677e-05,
      "loss": 0.1657,
      "step": 42340
    },
    {
      "epoch": 4.5376620593592625,
      "grad_norm": 0.0481041856110096,
      "learning_rate": 1.0924675881281475e-05,
      "loss": 0.1847,
      "step": 42350
    },
    {
      "epoch": 4.5387335261973645,
      "grad_norm": 0.08283655345439911,
      "learning_rate": 1.0922532947605274e-05,
      "loss": 0.2873,
      "step": 42360
    },
    {
      "epoch": 4.539804993035466,
      "grad_norm": 0.02447856031358242,
      "learning_rate": 1.092039001392907e-05,
      "loss": 0.0024,
      "step": 42370
    },
    {
      "epoch": 4.540876459873567,
      "grad_norm": 0.06013540178537369,
      "learning_rate": 1.0918247080252867e-05,
      "loss": 0.1761,
      "step": 42380
    },
    {
      "epoch": 4.541947926711668,
      "grad_norm": 0.06650747358798981,
      "learning_rate": 1.0916104146576664e-05,
      "loss": 0.0008,
      "step": 42390
    },
    {
      "epoch": 4.54301939354977,
      "grad_norm": 0.03544725850224495,
      "learning_rate": 1.0913961212900462e-05,
      "loss": 0.1537,
      "step": 42400
    },
    {
      "epoch": 4.544090860387871,
      "grad_norm": 0.03293224424123764,
      "learning_rate": 1.091181827922426e-05,
      "loss": 0.1284,
      "step": 42410
    },
    {
      "epoch": 4.545162327225972,
      "grad_norm": 2.1056487560272217,
      "learning_rate": 1.0909675345548056e-05,
      "loss": 0.571,
      "step": 42420
    },
    {
      "epoch": 4.546233794064074,
      "grad_norm": 0.022732039913535118,
      "learning_rate": 1.0907532411871854e-05,
      "loss": 0.4391,
      "step": 42430
    },
    {
      "epoch": 4.547305260902175,
      "grad_norm": 0.011392801068723202,
      "learning_rate": 1.0905389478195651e-05,
      "loss": 0.5317,
      "step": 42440
    },
    {
      "epoch": 4.548376727740276,
      "grad_norm": 0.10371595621109009,
      "learning_rate": 1.0903246544519448e-05,
      "loss": 0.0012,
      "step": 42450
    },
    {
      "epoch": 4.549448194578378,
      "grad_norm": 0.07119692116975784,
      "learning_rate": 1.0901103610843244e-05,
      "loss": 0.3023,
      "step": 42460
    },
    {
      "epoch": 4.550519661416479,
      "grad_norm": 0.8520594835281372,
      "learning_rate": 1.0898960677167043e-05,
      "loss": 0.5685,
      "step": 42470
    },
    {
      "epoch": 4.5515911282545805,
      "grad_norm": 0.9701893925666809,
      "learning_rate": 1.0896817743490839e-05,
      "loss": 0.2894,
      "step": 42480
    },
    {
      "epoch": 4.552662595092682,
      "grad_norm": 0.40821439027786255,
      "learning_rate": 1.0894674809814638e-05,
      "loss": 0.2303,
      "step": 42490
    },
    {
      "epoch": 4.553734061930784,
      "grad_norm": 0.010119383223354816,
      "learning_rate": 1.0892531876138435e-05,
      "loss": 0.1621,
      "step": 42500
    },
    {
      "epoch": 4.554805528768885,
      "grad_norm": 24.51120376586914,
      "learning_rate": 1.089038894246223e-05,
      "loss": 0.1508,
      "step": 42510
    },
    {
      "epoch": 4.555876995606986,
      "grad_norm": 0.02496783435344696,
      "learning_rate": 1.088824600878603e-05,
      "loss": 0.2192,
      "step": 42520
    },
    {
      "epoch": 4.556948462445087,
      "grad_norm": 0.23485633730888367,
      "learning_rate": 1.0886103075109826e-05,
      "loss": 0.0008,
      "step": 42530
    },
    {
      "epoch": 4.558019929283189,
      "grad_norm": 0.051019638776779175,
      "learning_rate": 1.0883960141433623e-05,
      "loss": 0.1528,
      "step": 42540
    },
    {
      "epoch": 4.55909139612129,
      "grad_norm": 356.39105224609375,
      "learning_rate": 1.0881817207757422e-05,
      "loss": 0.2821,
      "step": 42550
    },
    {
      "epoch": 4.560162862959391,
      "grad_norm": 0.18673104047775269,
      "learning_rate": 1.0879674274081218e-05,
      "loss": 0.3752,
      "step": 42560
    },
    {
      "epoch": 4.561234329797493,
      "grad_norm": 0.08546421676874161,
      "learning_rate": 1.0877531340405017e-05,
      "loss": 0.0008,
      "step": 42570
    },
    {
      "epoch": 4.562305796635594,
      "grad_norm": 0.0069135986268520355,
      "learning_rate": 1.0875388406728812e-05,
      "loss": 0.3332,
      "step": 42580
    },
    {
      "epoch": 4.563377263473695,
      "grad_norm": 0.023454269394278526,
      "learning_rate": 1.087324547305261e-05,
      "loss": 0.4709,
      "step": 42590
    },
    {
      "epoch": 4.564448730311797,
      "grad_norm": 0.006999886594712734,
      "learning_rate": 1.0871102539376409e-05,
      "loss": 0.0011,
      "step": 42600
    },
    {
      "epoch": 4.565520197149898,
      "grad_norm": 0.012288182973861694,
      "learning_rate": 1.0868959605700204e-05,
      "loss": 0.3461,
      "step": 42610
    },
    {
      "epoch": 4.5665916639879995,
      "grad_norm": 0.1531154364347458,
      "learning_rate": 1.0866816672024002e-05,
      "loss": 0.0068,
      "step": 42620
    },
    {
      "epoch": 4.567663130826101,
      "grad_norm": 0.0932665690779686,
      "learning_rate": 1.0864673738347799e-05,
      "loss": 0.0017,
      "step": 42630
    },
    {
      "epoch": 4.568734597664203,
      "grad_norm": 0.022308532148599625,
      "learning_rate": 1.0862530804671596e-05,
      "loss": 0.2199,
      "step": 42640
    },
    {
      "epoch": 4.569806064502304,
      "grad_norm": 0.026032842695713043,
      "learning_rate": 1.0860387870995392e-05,
      "loss": 0.1264,
      "step": 42650
    },
    {
      "epoch": 4.570877531340405,
      "grad_norm": 85.6927719116211,
      "learning_rate": 1.0858244937319191e-05,
      "loss": 0.3215,
      "step": 42660
    },
    {
      "epoch": 4.571948998178506,
      "grad_norm": 0.0021109329536557198,
      "learning_rate": 1.0856102003642987e-05,
      "loss": 0.3275,
      "step": 42670
    },
    {
      "epoch": 4.573020465016608,
      "grad_norm": 0.24428586661815643,
      "learning_rate": 1.0853959069966786e-05,
      "loss": 0.3892,
      "step": 42680
    },
    {
      "epoch": 4.574091931854709,
      "grad_norm": 0.005691017489880323,
      "learning_rate": 1.0851816136290583e-05,
      "loss": 0.452,
      "step": 42690
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 0.49872007966041565,
      "learning_rate": 1.0849673202614379e-05,
      "loss": 0.182,
      "step": 42700
    },
    {
      "epoch": 4.576234865530912,
      "grad_norm": 0.052085697650909424,
      "learning_rate": 1.0847530268938178e-05,
      "loss": 0.169,
      "step": 42710
    },
    {
      "epoch": 4.577306332369013,
      "grad_norm": 0.005843005143105984,
      "learning_rate": 1.0845387335261974e-05,
      "loss": 0.015,
      "step": 42720
    },
    {
      "epoch": 4.578377799207114,
      "grad_norm": 18.366201400756836,
      "learning_rate": 1.0843244401585771e-05,
      "loss": 0.5662,
      "step": 42730
    },
    {
      "epoch": 4.5794492660452155,
      "grad_norm": 0.0049547976814210415,
      "learning_rate": 1.084110146790957e-05,
      "loss": 0.1721,
      "step": 42740
    },
    {
      "epoch": 4.5805207328833175,
      "grad_norm": 0.12267915904521942,
      "learning_rate": 1.0838958534233366e-05,
      "loss": 0.2388,
      "step": 42750
    },
    {
      "epoch": 4.581592199721419,
      "grad_norm": 0.017184576019644737,
      "learning_rate": 1.0836815600557165e-05,
      "loss": 0.5103,
      "step": 42760
    },
    {
      "epoch": 4.58266366655952,
      "grad_norm": 6.3166937828063965,
      "learning_rate": 1.083467266688096e-05,
      "loss": 0.0738,
      "step": 42770
    },
    {
      "epoch": 4.583735133397622,
      "grad_norm": 0.19291271269321442,
      "learning_rate": 1.0832529733204758e-05,
      "loss": 0.1584,
      "step": 42780
    },
    {
      "epoch": 4.584806600235723,
      "grad_norm": 0.16164810955524445,
      "learning_rate": 1.0830386799528557e-05,
      "loss": 0.1589,
      "step": 42790
    },
    {
      "epoch": 4.585878067073824,
      "grad_norm": 0.07121188938617706,
      "learning_rate": 1.0828243865852352e-05,
      "loss": 0.0036,
      "step": 42800
    },
    {
      "epoch": 4.586949533911925,
      "grad_norm": 0.11702451854944229,
      "learning_rate": 1.082610093217615e-05,
      "loss": 0.3187,
      "step": 42810
    },
    {
      "epoch": 4.588021000750027,
      "grad_norm": 0.03379720076918602,
      "learning_rate": 1.0823957998499947e-05,
      "loss": 0.0963,
      "step": 42820
    },
    {
      "epoch": 4.589092467588128,
      "grad_norm": 0.09711750596761703,
      "learning_rate": 1.0821815064823745e-05,
      "loss": 0.0012,
      "step": 42830
    },
    {
      "epoch": 4.590163934426229,
      "grad_norm": 0.0029481800738722086,
      "learning_rate": 1.0819672131147544e-05,
      "loss": 0.2785,
      "step": 42840
    },
    {
      "epoch": 4.591235401264331,
      "grad_norm": 0.004622939042747021,
      "learning_rate": 1.081752919747134e-05,
      "loss": 0.3698,
      "step": 42850
    },
    {
      "epoch": 4.592306868102432,
      "grad_norm": 0.012949391268193722,
      "learning_rate": 1.0815386263795135e-05,
      "loss": 0.0012,
      "step": 42860
    },
    {
      "epoch": 4.5933783349405335,
      "grad_norm": 0.003067015204578638,
      "learning_rate": 1.0813243330118934e-05,
      "loss": 0.0007,
      "step": 42870
    },
    {
      "epoch": 4.594449801778635,
      "grad_norm": 0.0028884338680654764,
      "learning_rate": 1.0811100396442731e-05,
      "loss": 0.3362,
      "step": 42880
    },
    {
      "epoch": 4.595521268616737,
      "grad_norm": 0.009532430209219456,
      "learning_rate": 1.0808957462766527e-05,
      "loss": 0.2224,
      "step": 42890
    },
    {
      "epoch": 4.596592735454838,
      "grad_norm": 0.02671780250966549,
      "learning_rate": 1.0806814529090326e-05,
      "loss": 0.145,
      "step": 42900
    },
    {
      "epoch": 4.597664202292939,
      "grad_norm": 0.01549475733190775,
      "learning_rate": 1.0804671595414122e-05,
      "loss": 0.1933,
      "step": 42910
    },
    {
      "epoch": 4.59873566913104,
      "grad_norm": 25.327489852905273,
      "learning_rate": 1.080252866173792e-05,
      "loss": 0.5667,
      "step": 42920
    },
    {
      "epoch": 4.599807135969142,
      "grad_norm": 0.2720308005809784,
      "learning_rate": 1.0800385728061718e-05,
      "loss": 0.1487,
      "step": 42930
    },
    {
      "epoch": 4.600878602807243,
      "grad_norm": 18.945634841918945,
      "learning_rate": 1.0798242794385514e-05,
      "loss": 0.2465,
      "step": 42940
    },
    {
      "epoch": 4.601950069645344,
      "grad_norm": 0.004324088804423809,
      "learning_rate": 1.0796099860709313e-05,
      "loss": 0.26,
      "step": 42950
    },
    {
      "epoch": 4.603021536483446,
      "grad_norm": 0.012955689802765846,
      "learning_rate": 1.0793956927033108e-05,
      "loss": 0.031,
      "step": 42960
    },
    {
      "epoch": 4.604093003321547,
      "grad_norm": 0.0035660152789205313,
      "learning_rate": 1.0791813993356906e-05,
      "loss": 0.1428,
      "step": 42970
    },
    {
      "epoch": 4.605164470159648,
      "grad_norm": 0.0026934861671179533,
      "learning_rate": 1.0789671059680705e-05,
      "loss": 0.4912,
      "step": 42980
    },
    {
      "epoch": 4.60623593699775,
      "grad_norm": 0.516093373298645,
      "learning_rate": 1.07875281260045e-05,
      "loss": 0.0188,
      "step": 42990
    },
    {
      "epoch": 4.6073074038358515,
      "grad_norm": 0.016450054943561554,
      "learning_rate": 1.07853851923283e-05,
      "loss": 0.0017,
      "step": 43000
    },
    {
      "epoch": 4.608378870673953,
      "grad_norm": 0.0018524372717365623,
      "learning_rate": 1.0783242258652095e-05,
      "loss": 0.1698,
      "step": 43010
    },
    {
      "epoch": 4.609450337512054,
      "grad_norm": 0.014556140638887882,
      "learning_rate": 1.0781099324975893e-05,
      "loss": 0.4313,
      "step": 43020
    },
    {
      "epoch": 4.610521804350156,
      "grad_norm": 0.0032672679517418146,
      "learning_rate": 1.0778956391299692e-05,
      "loss": 0.1235,
      "step": 43030
    },
    {
      "epoch": 4.611593271188257,
      "grad_norm": 123.94837188720703,
      "learning_rate": 1.0776813457623487e-05,
      "loss": 0.5322,
      "step": 43040
    },
    {
      "epoch": 4.612664738026358,
      "grad_norm": 0.5105589032173157,
      "learning_rate": 1.0774670523947283e-05,
      "loss": 0.101,
      "step": 43050
    },
    {
      "epoch": 4.613736204864459,
      "grad_norm": 0.02031891979277134,
      "learning_rate": 1.0772527590271082e-05,
      "loss": 0.1646,
      "step": 43060
    },
    {
      "epoch": 4.614807671702561,
      "grad_norm": 0.01148612517863512,
      "learning_rate": 1.077038465659488e-05,
      "loss": 0.1309,
      "step": 43070
    },
    {
      "epoch": 4.615879138540662,
      "grad_norm": 283.5358581542969,
      "learning_rate": 1.0768241722918677e-05,
      "loss": 0.2246,
      "step": 43080
    },
    {
      "epoch": 4.616950605378763,
      "grad_norm": 0.0746343731880188,
      "learning_rate": 1.0766098789242474e-05,
      "loss": 0.0009,
      "step": 43090
    },
    {
      "epoch": 4.618022072216865,
      "grad_norm": 0.023805484175682068,
      "learning_rate": 1.076395585556627e-05,
      "loss": 0.3646,
      "step": 43100
    },
    {
      "epoch": 4.619093539054966,
      "grad_norm": 0.0670614242553711,
      "learning_rate": 1.0761812921890069e-05,
      "loss": 0.002,
      "step": 43110
    },
    {
      "epoch": 4.6201650058930674,
      "grad_norm": 0.0648440420627594,
      "learning_rate": 1.0759669988213866e-05,
      "loss": 0.1863,
      "step": 43120
    },
    {
      "epoch": 4.621236472731169,
      "grad_norm": 0.09485170245170593,
      "learning_rate": 1.0757527054537662e-05,
      "loss": 0.2574,
      "step": 43130
    },
    {
      "epoch": 4.6223079395692706,
      "grad_norm": 24.366832733154297,
      "learning_rate": 1.0755384120861461e-05,
      "loss": 0.2458,
      "step": 43140
    },
    {
      "epoch": 4.623379406407372,
      "grad_norm": 0.05331862345337868,
      "learning_rate": 1.0753241187185257e-05,
      "loss": 0.0035,
      "step": 43150
    },
    {
      "epoch": 4.624450873245473,
      "grad_norm": 0.015509004704654217,
      "learning_rate": 1.0751098253509056e-05,
      "loss": 0.6438,
      "step": 43160
    },
    {
      "epoch": 4.625522340083575,
      "grad_norm": 0.23346395790576935,
      "learning_rate": 1.0748955319832853e-05,
      "loss": 0.1564,
      "step": 43170
    },
    {
      "epoch": 4.626593806921676,
      "grad_norm": 0.022879749536514282,
      "learning_rate": 1.0746812386156649e-05,
      "loss": 0.2361,
      "step": 43180
    },
    {
      "epoch": 4.627665273759777,
      "grad_norm": 0.04714520648121834,
      "learning_rate": 1.0744669452480448e-05,
      "loss": 0.1405,
      "step": 43190
    },
    {
      "epoch": 4.628736740597878,
      "grad_norm": 0.038781918585300446,
      "learning_rate": 1.0742526518804243e-05,
      "loss": 0.33,
      "step": 43200
    },
    {
      "epoch": 4.62980820743598,
      "grad_norm": 0.20383699238300323,
      "learning_rate": 1.074038358512804e-05,
      "loss": 0.0015,
      "step": 43210
    },
    {
      "epoch": 4.630879674274081,
      "grad_norm": 0.023364370688796043,
      "learning_rate": 1.073824065145184e-05,
      "loss": 0.0035,
      "step": 43220
    },
    {
      "epoch": 4.631951141112182,
      "grad_norm": 0.09249114245176315,
      "learning_rate": 1.0736097717775635e-05,
      "loss": 0.202,
      "step": 43230
    },
    {
      "epoch": 4.633022607950284,
      "grad_norm": 0.011956061236560345,
      "learning_rate": 1.0733954784099434e-05,
      "loss": 0.0015,
      "step": 43240
    },
    {
      "epoch": 4.634094074788385,
      "grad_norm": 0.13094891607761383,
      "learning_rate": 1.073181185042323e-05,
      "loss": 0.2165,
      "step": 43250
    },
    {
      "epoch": 4.6351655416264865,
      "grad_norm": 0.44857460260391235,
      "learning_rate": 1.0729668916747027e-05,
      "loss": 0.0012,
      "step": 43260
    },
    {
      "epoch": 4.636237008464588,
      "grad_norm": 0.002751203952357173,
      "learning_rate": 1.0727525983070825e-05,
      "loss": 0.0004,
      "step": 43270
    },
    {
      "epoch": 4.63730847530269,
      "grad_norm": 0.04343092814087868,
      "learning_rate": 1.0725383049394622e-05,
      "loss": 0.291,
      "step": 43280
    },
    {
      "epoch": 4.638379942140791,
      "grad_norm": 0.0021102973259985447,
      "learning_rate": 1.0723240115718418e-05,
      "loss": 0.3539,
      "step": 43290
    },
    {
      "epoch": 4.639451408978892,
      "grad_norm": 0.060090288519859314,
      "learning_rate": 1.0721097182042217e-05,
      "loss": 0.2655,
      "step": 43300
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 0.0034823077730834484,
      "learning_rate": 1.0718954248366014e-05,
      "loss": 0.1943,
      "step": 43310
    },
    {
      "epoch": 4.641594342655095,
      "grad_norm": 0.01057688519358635,
      "learning_rate": 1.0716811314689812e-05,
      "loss": 0.4239,
      "step": 43320
    },
    {
      "epoch": 4.642665809493196,
      "grad_norm": 30.01261329650879,
      "learning_rate": 1.0714668381013609e-05,
      "loss": 0.3163,
      "step": 43330
    },
    {
      "epoch": 4.643737276331297,
      "grad_norm": 0.023489922285079956,
      "learning_rate": 1.0712525447337405e-05,
      "loss": 0.7271,
      "step": 43340
    },
    {
      "epoch": 4.644808743169399,
      "grad_norm": 0.014293023385107517,
      "learning_rate": 1.0710382513661204e-05,
      "loss": 0.6222,
      "step": 43350
    },
    {
      "epoch": 4.6458802100075,
      "grad_norm": 19.466978073120117,
      "learning_rate": 1.0708239579985001e-05,
      "loss": 0.3692,
      "step": 43360
    },
    {
      "epoch": 4.646951676845601,
      "grad_norm": 0.4444716274738312,
      "learning_rate": 1.0706096646308797e-05,
      "loss": 0.1828,
      "step": 43370
    },
    {
      "epoch": 4.648023143683703,
      "grad_norm": 0.08154501020908356,
      "learning_rate": 1.0703953712632596e-05,
      "loss": 0.3519,
      "step": 43380
    },
    {
      "epoch": 4.6490946105218045,
      "grad_norm": 0.0449899323284626,
      "learning_rate": 1.0701810778956391e-05,
      "loss": 0.1061,
      "step": 43390
    },
    {
      "epoch": 4.650166077359906,
      "grad_norm": 23.159496307373047,
      "learning_rate": 1.069966784528019e-05,
      "loss": 0.1952,
      "step": 43400
    },
    {
      "epoch": 4.651237544198007,
      "grad_norm": 0.07226356863975525,
      "learning_rate": 1.0697524911603988e-05,
      "loss": 0.2825,
      "step": 43410
    },
    {
      "epoch": 4.652309011036109,
      "grad_norm": 0.01684790663421154,
      "learning_rate": 1.0695381977927783e-05,
      "loss": 0.002,
      "step": 43420
    },
    {
      "epoch": 4.65338047787421,
      "grad_norm": 0.9251806139945984,
      "learning_rate": 1.0693239044251582e-05,
      "loss": 0.2553,
      "step": 43430
    },
    {
      "epoch": 4.654451944712311,
      "grad_norm": 0.03960632160305977,
      "learning_rate": 1.0691096110575378e-05,
      "loss": 0.0012,
      "step": 43440
    },
    {
      "epoch": 4.655523411550412,
      "grad_norm": 0.21985961496829987,
      "learning_rate": 1.0688953176899175e-05,
      "loss": 0.1563,
      "step": 43450
    },
    {
      "epoch": 4.656594878388514,
      "grad_norm": 0.034890491515398026,
      "learning_rate": 1.0686810243222973e-05,
      "loss": 0.0057,
      "step": 43460
    },
    {
      "epoch": 4.657666345226615,
      "grad_norm": 0.02860490418970585,
      "learning_rate": 1.068466730954677e-05,
      "loss": 0.0006,
      "step": 43470
    },
    {
      "epoch": 4.658737812064716,
      "grad_norm": 0.0034960510674864054,
      "learning_rate": 1.068252437587057e-05,
      "loss": 0.0124,
      "step": 43480
    },
    {
      "epoch": 4.659809278902818,
      "grad_norm": 0.020302664488554,
      "learning_rate": 1.0680381442194365e-05,
      "loss": 0.1399,
      "step": 43490
    },
    {
      "epoch": 4.660880745740919,
      "grad_norm": 0.00260707619599998,
      "learning_rate": 1.0678238508518162e-05,
      "loss": 0.4237,
      "step": 43500
    },
    {
      "epoch": 4.6619522125790205,
      "grad_norm": 0.0671120434999466,
      "learning_rate": 1.067609557484196e-05,
      "loss": 0.0007,
      "step": 43510
    },
    {
      "epoch": 4.6630236794171225,
      "grad_norm": 0.03938635066151619,
      "learning_rate": 1.0673952641165757e-05,
      "loss": 0.2033,
      "step": 43520
    },
    {
      "epoch": 4.664095146255224,
      "grad_norm": 0.01778472773730755,
      "learning_rate": 1.0671809707489553e-05,
      "loss": 0.0017,
      "step": 43530
    },
    {
      "epoch": 4.665166613093325,
      "grad_norm": 0.134633406996727,
      "learning_rate": 1.0669666773813352e-05,
      "loss": 0.3909,
      "step": 43540
    },
    {
      "epoch": 4.666238079931426,
      "grad_norm": 0.03424230217933655,
      "learning_rate": 1.0667523840137149e-05,
      "loss": 0.2296,
      "step": 43550
    },
    {
      "epoch": 4.667309546769528,
      "grad_norm": 0.0566655658185482,
      "learning_rate": 1.0665380906460945e-05,
      "loss": 0.3599,
      "step": 43560
    },
    {
      "epoch": 4.668381013607629,
      "grad_norm": 0.014405684545636177,
      "learning_rate": 1.0663237972784744e-05,
      "loss": 0.0369,
      "step": 43570
    },
    {
      "epoch": 4.66945248044573,
      "grad_norm": 0.0373469702899456,
      "learning_rate": 1.066109503910854e-05,
      "loss": 0.0891,
      "step": 43580
    },
    {
      "epoch": 4.670523947283831,
      "grad_norm": 0.15710380673408508,
      "learning_rate": 1.0658952105432338e-05,
      "loss": 0.0013,
      "step": 43590
    },
    {
      "epoch": 4.671595414121933,
      "grad_norm": 0.021776562556624413,
      "learning_rate": 1.0656809171756136e-05,
      "loss": 0.0131,
      "step": 43600
    },
    {
      "epoch": 4.672666880960034,
      "grad_norm": 0.5326117277145386,
      "learning_rate": 1.0654666238079931e-05,
      "loss": 0.3789,
      "step": 43610
    },
    {
      "epoch": 4.673738347798135,
      "grad_norm": 0.002087785629555583,
      "learning_rate": 1.065252330440373e-05,
      "loss": 0.0054,
      "step": 43620
    },
    {
      "epoch": 4.674809814636237,
      "grad_norm": 94.7665023803711,
      "learning_rate": 1.0650380370727526e-05,
      "loss": 0.5945,
      "step": 43630
    },
    {
      "epoch": 4.6758812814743385,
      "grad_norm": 0.01189444214105606,
      "learning_rate": 1.0648237437051324e-05,
      "loss": 0.1453,
      "step": 43640
    },
    {
      "epoch": 4.67695274831244,
      "grad_norm": 0.16373521089553833,
      "learning_rate": 1.0646094503375121e-05,
      "loss": 0.2427,
      "step": 43650
    },
    {
      "epoch": 4.678024215150542,
      "grad_norm": 0.0388866662979126,
      "learning_rate": 1.0643951569698918e-05,
      "loss": 0.0018,
      "step": 43660
    },
    {
      "epoch": 4.679095681988643,
      "grad_norm": 0.002867923118174076,
      "learning_rate": 1.0641808636022717e-05,
      "loss": 0.0002,
      "step": 43670
    },
    {
      "epoch": 4.680167148826744,
      "grad_norm": 0.00433218851685524,
      "learning_rate": 1.0639665702346513e-05,
      "loss": 0.0013,
      "step": 43680
    },
    {
      "epoch": 4.681238615664845,
      "grad_norm": 0.023036818951368332,
      "learning_rate": 1.063752276867031e-05,
      "loss": 0.6274,
      "step": 43690
    },
    {
      "epoch": 4.682310082502947,
      "grad_norm": 0.010275818407535553,
      "learning_rate": 1.0635379834994108e-05,
      "loss": 0.1059,
      "step": 43700
    },
    {
      "epoch": 4.683381549341048,
      "grad_norm": 0.0876416563987732,
      "learning_rate": 1.0633236901317905e-05,
      "loss": 0.6361,
      "step": 43710
    },
    {
      "epoch": 4.684453016179149,
      "grad_norm": 0.027681035920977592,
      "learning_rate": 1.06310939676417e-05,
      "loss": 0.2401,
      "step": 43720
    },
    {
      "epoch": 4.68552448301725,
      "grad_norm": 0.021325835958123207,
      "learning_rate": 1.06289510339655e-05,
      "loss": 0.2305,
      "step": 43730
    },
    {
      "epoch": 4.686595949855352,
      "grad_norm": 2.429124593734741,
      "learning_rate": 1.0626808100289297e-05,
      "loss": 0.4982,
      "step": 43740
    },
    {
      "epoch": 4.687667416693453,
      "grad_norm": 0.006154042202979326,
      "learning_rate": 1.0624665166613094e-05,
      "loss": 0.0036,
      "step": 43750
    },
    {
      "epoch": 4.688738883531554,
      "grad_norm": 0.024662669748067856,
      "learning_rate": 1.0622522232936892e-05,
      "loss": 0.3108,
      "step": 43760
    },
    {
      "epoch": 4.689810350369656,
      "grad_norm": 0.09221605956554413,
      "learning_rate": 1.0620379299260687e-05,
      "loss": 0.3017,
      "step": 43770
    },
    {
      "epoch": 4.6908818172077575,
      "grad_norm": 0.05234263092279434,
      "learning_rate": 1.0618236365584487e-05,
      "loss": 0.1391,
      "step": 43780
    },
    {
      "epoch": 4.691953284045859,
      "grad_norm": 0.2433239072561264,
      "learning_rate": 1.0616093431908284e-05,
      "loss": 0.0027,
      "step": 43790
    },
    {
      "epoch": 4.69302475088396,
      "grad_norm": 0.03206340968608856,
      "learning_rate": 1.061395049823208e-05,
      "loss": 0.1522,
      "step": 43800
    },
    {
      "epoch": 4.694096217722062,
      "grad_norm": 31.849834442138672,
      "learning_rate": 1.0611807564555879e-05,
      "loss": 0.3674,
      "step": 43810
    },
    {
      "epoch": 4.695167684560163,
      "grad_norm": 129.68341064453125,
      "learning_rate": 1.0609664630879674e-05,
      "loss": 0.0351,
      "step": 43820
    },
    {
      "epoch": 4.696239151398264,
      "grad_norm": 185.7876739501953,
      "learning_rate": 1.0607521697203473e-05,
      "loss": 0.6894,
      "step": 43830
    },
    {
      "epoch": 4.697310618236365,
      "grad_norm": 0.09596741199493408,
      "learning_rate": 1.0605378763527269e-05,
      "loss": 0.0886,
      "step": 43840
    },
    {
      "epoch": 4.698382085074467,
      "grad_norm": 0.015271979384124279,
      "learning_rate": 1.0603235829851066e-05,
      "loss": 0.1105,
      "step": 43850
    },
    {
      "epoch": 4.699453551912568,
      "grad_norm": 0.3291129469871521,
      "learning_rate": 1.0601092896174865e-05,
      "loss": 0.0023,
      "step": 43860
    },
    {
      "epoch": 4.700525018750669,
      "grad_norm": 0.023967677727341652,
      "learning_rate": 1.0598949962498661e-05,
      "loss": 0.0012,
      "step": 43870
    },
    {
      "epoch": 4.701596485588771,
      "grad_norm": 0.03732500225305557,
      "learning_rate": 1.0596807028822458e-05,
      "loss": 0.1393,
      "step": 43880
    },
    {
      "epoch": 4.702667952426872,
      "grad_norm": 0.0009051364031620324,
      "learning_rate": 1.0594664095146256e-05,
      "loss": 0.1904,
      "step": 43890
    },
    {
      "epoch": 4.7037394192649735,
      "grad_norm": 0.03559987619519234,
      "learning_rate": 1.0592521161470053e-05,
      "loss": 0.2877,
      "step": 43900
    },
    {
      "epoch": 4.7048108861030755,
      "grad_norm": 0.006870129611343145,
      "learning_rate": 1.0590378227793852e-05,
      "loss": 0.0002,
      "step": 43910
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.012921352870762348,
      "learning_rate": 1.0588235294117648e-05,
      "loss": 0.0551,
      "step": 43920
    },
    {
      "epoch": 4.706953819779278,
      "grad_norm": 0.05663115903735161,
      "learning_rate": 1.0586092360441445e-05,
      "loss": 0.2179,
      "step": 43930
    },
    {
      "epoch": 4.708025286617379,
      "grad_norm": 3.8282854557037354,
      "learning_rate": 1.0583949426765243e-05,
      "loss": 0.7626,
      "step": 43940
    },
    {
      "epoch": 4.709096753455481,
      "grad_norm": 0.019817117601633072,
      "learning_rate": 1.058180649308904e-05,
      "loss": 0.0008,
      "step": 43950
    },
    {
      "epoch": 4.710168220293582,
      "grad_norm": 0.06120144575834274,
      "learning_rate": 1.0579663559412836e-05,
      "loss": 0.1718,
      "step": 43960
    },
    {
      "epoch": 4.711239687131683,
      "grad_norm": 0.0299205482006073,
      "learning_rate": 1.0577520625736635e-05,
      "loss": 0.0012,
      "step": 43970
    },
    {
      "epoch": 4.712311153969784,
      "grad_norm": 0.0075845797546207905,
      "learning_rate": 1.0575377692060432e-05,
      "loss": 0.001,
      "step": 43980
    },
    {
      "epoch": 4.713382620807886,
      "grad_norm": 0.011033741757273674,
      "learning_rate": 1.057323475838423e-05,
      "loss": 0.2428,
      "step": 43990
    },
    {
      "epoch": 4.714454087645987,
      "grad_norm": 0.04454499110579491,
      "learning_rate": 1.0571091824708027e-05,
      "loss": 0.1397,
      "step": 44000
    },
    {
      "epoch": 4.715525554484088,
      "grad_norm": 0.018354453146457672,
      "learning_rate": 1.0568948891031822e-05,
      "loss": 0.1507,
      "step": 44010
    },
    {
      "epoch": 4.71659702132219,
      "grad_norm": 0.06594789773225784,
      "learning_rate": 1.0566805957355621e-05,
      "loss": 0.2218,
      "step": 44020
    },
    {
      "epoch": 4.7176684881602915,
      "grad_norm": 0.0019373394316062331,
      "learning_rate": 1.0564663023679417e-05,
      "loss": 0.1395,
      "step": 44030
    },
    {
      "epoch": 4.718739954998393,
      "grad_norm": 0.018038619309663773,
      "learning_rate": 1.0562520090003214e-05,
      "loss": 0.3979,
      "step": 44040
    },
    {
      "epoch": 4.719811421836495,
      "grad_norm": 0.6494777798652649,
      "learning_rate": 1.0560377156327013e-05,
      "loss": 0.0373,
      "step": 44050
    },
    {
      "epoch": 4.720882888674596,
      "grad_norm": 0.029183197766542435,
      "learning_rate": 1.0558234222650809e-05,
      "loss": 0.0008,
      "step": 44060
    },
    {
      "epoch": 4.721954355512697,
      "grad_norm": 0.007740827277302742,
      "learning_rate": 1.0556091288974608e-05,
      "loss": 0.4028,
      "step": 44070
    },
    {
      "epoch": 4.723025822350798,
      "grad_norm": 0.061146095395088196,
      "learning_rate": 1.0553948355298404e-05,
      "loss": 0.6396,
      "step": 44080
    },
    {
      "epoch": 4.7240972891889,
      "grad_norm": 0.020437121391296387,
      "learning_rate": 1.0551805421622201e-05,
      "loss": 0.2327,
      "step": 44090
    },
    {
      "epoch": 4.725168756027001,
      "grad_norm": 189.63246154785156,
      "learning_rate": 1.0549662487946e-05,
      "loss": 0.2021,
      "step": 44100
    },
    {
      "epoch": 4.726240222865102,
      "grad_norm": 0.041926972568035126,
      "learning_rate": 1.0547519554269796e-05,
      "loss": 0.1271,
      "step": 44110
    },
    {
      "epoch": 4.727311689703203,
      "grad_norm": 0.033809445798397064,
      "learning_rate": 1.0545376620593593e-05,
      "loss": 0.0669,
      "step": 44120
    },
    {
      "epoch": 4.728383156541305,
      "grad_norm": 0.0011609147768467665,
      "learning_rate": 1.054323368691739e-05,
      "loss": 0.0013,
      "step": 44130
    },
    {
      "epoch": 4.729454623379406,
      "grad_norm": 0.0024469252675771713,
      "learning_rate": 1.0541090753241188e-05,
      "loss": 0.1402,
      "step": 44140
    },
    {
      "epoch": 4.7305260902175075,
      "grad_norm": 0.0783955305814743,
      "learning_rate": 1.0538947819564987e-05,
      "loss": 0.0004,
      "step": 44150
    },
    {
      "epoch": 4.7315975570556095,
      "grad_norm": 0.16454827785491943,
      "learning_rate": 1.0536804885888783e-05,
      "loss": 0.127,
      "step": 44160
    },
    {
      "epoch": 4.732669023893711,
      "grad_norm": 31.809329986572266,
      "learning_rate": 1.053466195221258e-05,
      "loss": 0.691,
      "step": 44170
    },
    {
      "epoch": 4.733740490731812,
      "grad_norm": 0.06157061457633972,
      "learning_rate": 1.0532519018536377e-05,
      "loss": 0.1356,
      "step": 44180
    },
    {
      "epoch": 4.734811957569914,
      "grad_norm": 0.002721349010244012,
      "learning_rate": 1.0530376084860175e-05,
      "loss": 0.1247,
      "step": 44190
    },
    {
      "epoch": 4.735883424408015,
      "grad_norm": 0.00331339449621737,
      "learning_rate": 1.052823315118397e-05,
      "loss": 0.0018,
      "step": 44200
    },
    {
      "epoch": 4.736954891246116,
      "grad_norm": 0.32558098435401917,
      "learning_rate": 1.052609021750777e-05,
      "loss": 0.1083,
      "step": 44210
    },
    {
      "epoch": 4.738026358084217,
      "grad_norm": 0.030552899464964867,
      "learning_rate": 1.0523947283831565e-05,
      "loss": 0.0011,
      "step": 44220
    },
    {
      "epoch": 4.739097824922319,
      "grad_norm": 0.0504533052444458,
      "learning_rate": 1.0521804350155364e-05,
      "loss": 0.0744,
      "step": 44230
    },
    {
      "epoch": 4.74016929176042,
      "grad_norm": 0.004718373529613018,
      "learning_rate": 1.0519661416479162e-05,
      "loss": 0.0001,
      "step": 44240
    },
    {
      "epoch": 4.741240758598521,
      "grad_norm": 0.020965470001101494,
      "learning_rate": 1.0517518482802957e-05,
      "loss": 0.1326,
      "step": 44250
    },
    {
      "epoch": 4.742312225436622,
      "grad_norm": 0.02258165553212166,
      "learning_rate": 1.0515375549126756e-05,
      "loss": 0.0009,
      "step": 44260
    },
    {
      "epoch": 4.743383692274724,
      "grad_norm": 0.019854500889778137,
      "learning_rate": 1.0513232615450552e-05,
      "loss": 0.1477,
      "step": 44270
    },
    {
      "epoch": 4.7444551591128254,
      "grad_norm": 22.76807403564453,
      "learning_rate": 1.051108968177435e-05,
      "loss": 0.3862,
      "step": 44280
    },
    {
      "epoch": 4.745526625950927,
      "grad_norm": 0.08753219991922379,
      "learning_rate": 1.0508946748098148e-05,
      "loss": 0.0731,
      "step": 44290
    },
    {
      "epoch": 4.7465980927890286,
      "grad_norm": 0.14211449027061462,
      "learning_rate": 1.0506803814421944e-05,
      "loss": 0.3451,
      "step": 44300
    },
    {
      "epoch": 4.74766955962713,
      "grad_norm": 0.03300393372774124,
      "learning_rate": 1.0504660880745743e-05,
      "loss": 0.3136,
      "step": 44310
    },
    {
      "epoch": 4.748741026465231,
      "grad_norm": 0.0022591555025428534,
      "learning_rate": 1.0502517947069539e-05,
      "loss": 0.0144,
      "step": 44320
    },
    {
      "epoch": 4.749812493303332,
      "grad_norm": 0.0047462270595133305,
      "learning_rate": 1.0500375013393336e-05,
      "loss": 0.6439,
      "step": 44330
    },
    {
      "epoch": 4.750883960141434,
      "grad_norm": 0.03801799565553665,
      "learning_rate": 1.0498232079717135e-05,
      "loss": 0.0004,
      "step": 44340
    },
    {
      "epoch": 4.751955426979535,
      "grad_norm": 0.04785074666142464,
      "learning_rate": 1.049608914604093e-05,
      "loss": 0.0049,
      "step": 44350
    },
    {
      "epoch": 4.753026893817636,
      "grad_norm": 0.13227328658103943,
      "learning_rate": 1.0493946212364728e-05,
      "loss": 0.0005,
      "step": 44360
    },
    {
      "epoch": 4.754098360655737,
      "grad_norm": 0.020611431449651718,
      "learning_rate": 1.0491803278688525e-05,
      "loss": 0.0962,
      "step": 44370
    },
    {
      "epoch": 4.755169827493839,
      "grad_norm": 0.0018059869762510061,
      "learning_rate": 1.0489660345012323e-05,
      "loss": 0.1939,
      "step": 44380
    },
    {
      "epoch": 4.75624129433194,
      "grad_norm": 0.0024526275228708982,
      "learning_rate": 1.0487517411336122e-05,
      "loss": 0.4897,
      "step": 44390
    },
    {
      "epoch": 4.757312761170041,
      "grad_norm": 0.015329176560044289,
      "learning_rate": 1.0485374477659918e-05,
      "loss": 0.0005,
      "step": 44400
    },
    {
      "epoch": 4.758384228008143,
      "grad_norm": 0.017104897648096085,
      "learning_rate": 1.0483231543983713e-05,
      "loss": 0.1887,
      "step": 44410
    },
    {
      "epoch": 4.7594556948462445,
      "grad_norm": 0.0017498728120699525,
      "learning_rate": 1.0481088610307512e-05,
      "loss": 0.0453,
      "step": 44420
    },
    {
      "epoch": 4.760527161684346,
      "grad_norm": 0.024072973057627678,
      "learning_rate": 1.047894567663131e-05,
      "loss": 0.0023,
      "step": 44430
    },
    {
      "epoch": 4.761598628522448,
      "grad_norm": 0.004071386996656656,
      "learning_rate": 1.0476802742955105e-05,
      "loss": 0.0015,
      "step": 44440
    },
    {
      "epoch": 4.762670095360549,
      "grad_norm": 0.002429866697639227,
      "learning_rate": 1.0474659809278904e-05,
      "loss": 0.1538,
      "step": 44450
    },
    {
      "epoch": 4.76374156219865,
      "grad_norm": 0.027897624298930168,
      "learning_rate": 1.04725168756027e-05,
      "loss": 0.206,
      "step": 44460
    },
    {
      "epoch": 4.764813029036751,
      "grad_norm": 0.1620330810546875,
      "learning_rate": 1.0470373941926497e-05,
      "loss": 0.5387,
      "step": 44470
    },
    {
      "epoch": 4.765884495874853,
      "grad_norm": 0.013346838764846325,
      "learning_rate": 1.0468231008250296e-05,
      "loss": 0.1461,
      "step": 44480
    },
    {
      "epoch": 4.766955962712954,
      "grad_norm": 0.030935073271393776,
      "learning_rate": 1.0466088074574092e-05,
      "loss": 0.0879,
      "step": 44490
    },
    {
      "epoch": 4.768027429551055,
      "grad_norm": 0.019300220534205437,
      "learning_rate": 1.0463945140897891e-05,
      "loss": 0.0993,
      "step": 44500
    },
    {
      "epoch": 4.769098896389156,
      "grad_norm": 0.20769762992858887,
      "learning_rate": 1.0461802207221687e-05,
      "loss": 0.4267,
      "step": 44510
    },
    {
      "epoch": 4.770170363227258,
      "grad_norm": 0.01596969924867153,
      "learning_rate": 1.0459659273545484e-05,
      "loss": 0.1714,
      "step": 44520
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 0.0590212456882,
      "learning_rate": 1.0457516339869283e-05,
      "loss": 0.2377,
      "step": 44530
    },
    {
      "epoch": 4.7723132969034605,
      "grad_norm": 20.227840423583984,
      "learning_rate": 1.0455373406193079e-05,
      "loss": 0.4865,
      "step": 44540
    },
    {
      "epoch": 4.7733847637415625,
      "grad_norm": 0.025012962520122528,
      "learning_rate": 1.0453230472516876e-05,
      "loss": 0.1286,
      "step": 44550
    },
    {
      "epoch": 4.774456230579664,
      "grad_norm": 82.92741394042969,
      "learning_rate": 1.0451087538840674e-05,
      "loss": 0.2035,
      "step": 44560
    },
    {
      "epoch": 4.775527697417765,
      "grad_norm": 17.29181480407715,
      "learning_rate": 1.0448944605164471e-05,
      "loss": 0.1207,
      "step": 44570
    },
    {
      "epoch": 4.776599164255867,
      "grad_norm": 0.007182507775723934,
      "learning_rate": 1.044680167148827e-05,
      "loss": 0.0641,
      "step": 44580
    },
    {
      "epoch": 4.777670631093968,
      "grad_norm": 0.013089634478092194,
      "learning_rate": 1.0444658737812066e-05,
      "loss": 0.0006,
      "step": 44590
    },
    {
      "epoch": 4.778742097932069,
      "grad_norm": 0.005495411343872547,
      "learning_rate": 1.0442515804135861e-05,
      "loss": 0.0007,
      "step": 44600
    },
    {
      "epoch": 4.77981356477017,
      "grad_norm": 0.034853968769311905,
      "learning_rate": 1.044037287045966e-05,
      "loss": 0.2023,
      "step": 44610
    },
    {
      "epoch": 4.780885031608272,
      "grad_norm": 0.00839191023260355,
      "learning_rate": 1.0438229936783458e-05,
      "loss": 0.48,
      "step": 44620
    },
    {
      "epoch": 4.781956498446373,
      "grad_norm": 0.07048553228378296,
      "learning_rate": 1.0436087003107253e-05,
      "loss": 0.3149,
      "step": 44630
    },
    {
      "epoch": 4.783027965284474,
      "grad_norm": 0.48214924335479736,
      "learning_rate": 1.0433944069431052e-05,
      "loss": 0.001,
      "step": 44640
    },
    {
      "epoch": 4.784099432122575,
      "grad_norm": 0.3113507628440857,
      "learning_rate": 1.0431801135754848e-05,
      "loss": 0.002,
      "step": 44650
    },
    {
      "epoch": 4.785170898960677,
      "grad_norm": 106.81082916259766,
      "learning_rate": 1.0429658202078647e-05,
      "loss": 0.4482,
      "step": 44660
    },
    {
      "epoch": 4.7862423657987785,
      "grad_norm": 0.13311269879341125,
      "learning_rate": 1.0427515268402444e-05,
      "loss": 0.1135,
      "step": 44670
    },
    {
      "epoch": 4.78731383263688,
      "grad_norm": 0.04978113994002342,
      "learning_rate": 1.042537233472624e-05,
      "loss": 0.0899,
      "step": 44680
    },
    {
      "epoch": 4.788385299474982,
      "grad_norm": 0.01053526159375906,
      "learning_rate": 1.0423229401050039e-05,
      "loss": 0.0073,
      "step": 44690
    },
    {
      "epoch": 4.789456766313083,
      "grad_norm": 35.080604553222656,
      "learning_rate": 1.0421086467373835e-05,
      "loss": 0.2917,
      "step": 44700
    },
    {
      "epoch": 4.790528233151184,
      "grad_norm": 0.19942112267017365,
      "learning_rate": 1.0418943533697632e-05,
      "loss": 0.0365,
      "step": 44710
    },
    {
      "epoch": 4.791599699989286,
      "grad_norm": 0.028630629181861877,
      "learning_rate": 1.0416800600021431e-05,
      "loss": 0.0123,
      "step": 44720
    },
    {
      "epoch": 4.792671166827387,
      "grad_norm": 1.0280187129974365,
      "learning_rate": 1.0414657666345227e-05,
      "loss": 0.0016,
      "step": 44730
    },
    {
      "epoch": 4.793742633665488,
      "grad_norm": 0.010312378406524658,
      "learning_rate": 1.0412514732669026e-05,
      "loss": 0.0034,
      "step": 44740
    },
    {
      "epoch": 4.794814100503589,
      "grad_norm": 0.0031712003983557224,
      "learning_rate": 1.0410371798992822e-05,
      "loss": 0.3839,
      "step": 44750
    },
    {
      "epoch": 4.795885567341691,
      "grad_norm": 0.01669999025762081,
      "learning_rate": 1.0408228865316619e-05,
      "loss": 0.0021,
      "step": 44760
    },
    {
      "epoch": 4.796957034179792,
      "grad_norm": 18.6126708984375,
      "learning_rate": 1.0406085931640418e-05,
      "loss": 0.3615,
      "step": 44770
    },
    {
      "epoch": 4.798028501017893,
      "grad_norm": 48.457706451416016,
      "learning_rate": 1.0403942997964214e-05,
      "loss": 0.4684,
      "step": 44780
    },
    {
      "epoch": 4.7990999678559945,
      "grad_norm": 0.04000953957438469,
      "learning_rate": 1.040180006428801e-05,
      "loss": 0.2524,
      "step": 44790
    },
    {
      "epoch": 4.8001714346940965,
      "grad_norm": 0.04948709160089493,
      "learning_rate": 1.0399657130611808e-05,
      "loss": 0.3352,
      "step": 44800
    },
    {
      "epoch": 4.801242901532198,
      "grad_norm": 66.3071517944336,
      "learning_rate": 1.0397514196935606e-05,
      "loss": 0.1955,
      "step": 44810
    },
    {
      "epoch": 4.802314368370299,
      "grad_norm": 0.004104185849428177,
      "learning_rate": 1.0395371263259405e-05,
      "loss": 0.3399,
      "step": 44820
    },
    {
      "epoch": 4.803385835208401,
      "grad_norm": 0.011829243041574955,
      "learning_rate": 1.03932283295832e-05,
      "loss": 0.2179,
      "step": 44830
    },
    {
      "epoch": 4.804457302046502,
      "grad_norm": 0.0063362703658640385,
      "learning_rate": 1.0391085395906996e-05,
      "loss": 0.0023,
      "step": 44840
    },
    {
      "epoch": 4.805528768884603,
      "grad_norm": 0.11431726068258286,
      "learning_rate": 1.0388942462230795e-05,
      "loss": 0.175,
      "step": 44850
    },
    {
      "epoch": 4.806600235722704,
      "grad_norm": 0.011153479106724262,
      "learning_rate": 1.0386799528554592e-05,
      "loss": 0.0003,
      "step": 44860
    },
    {
      "epoch": 4.807671702560806,
      "grad_norm": 0.40561652183532715,
      "learning_rate": 1.0384656594878388e-05,
      "loss": 0.0042,
      "step": 44870
    },
    {
      "epoch": 4.808743169398907,
      "grad_norm": 0.044165290892124176,
      "learning_rate": 1.0382513661202187e-05,
      "loss": 0.2185,
      "step": 44880
    },
    {
      "epoch": 4.809814636237008,
      "grad_norm": 0.010662779211997986,
      "learning_rate": 1.0380370727525983e-05,
      "loss": 0.1894,
      "step": 44890
    },
    {
      "epoch": 4.810886103075109,
      "grad_norm": 0.010351251810789108,
      "learning_rate": 1.0378227793849782e-05,
      "loss": 0.0009,
      "step": 44900
    },
    {
      "epoch": 4.811957569913211,
      "grad_norm": 0.006747678853571415,
      "learning_rate": 1.037608486017358e-05,
      "loss": 0.3127,
      "step": 44910
    },
    {
      "epoch": 4.813029036751312,
      "grad_norm": 0.06226920709013939,
      "learning_rate": 1.0373941926497375e-05,
      "loss": 0.0006,
      "step": 44920
    },
    {
      "epoch": 4.8141005035894135,
      "grad_norm": 1.8754993677139282,
      "learning_rate": 1.0371798992821174e-05,
      "loss": 0.3786,
      "step": 44930
    },
    {
      "epoch": 4.8151719704275155,
      "grad_norm": 0.041013024747371674,
      "learning_rate": 1.036965605914497e-05,
      "loss": 0.2632,
      "step": 44940
    },
    {
      "epoch": 4.816243437265617,
      "grad_norm": 0.012456451542675495,
      "learning_rate": 1.0367513125468767e-05,
      "loss": 0.0074,
      "step": 44950
    },
    {
      "epoch": 4.817314904103718,
      "grad_norm": 0.010374248959124088,
      "learning_rate": 1.0365370191792566e-05,
      "loss": 0.1631,
      "step": 44960
    },
    {
      "epoch": 4.81838637094182,
      "grad_norm": 3.5777878761291504,
      "learning_rate": 1.0363227258116362e-05,
      "loss": 0.3851,
      "step": 44970
    },
    {
      "epoch": 4.819457837779921,
      "grad_norm": 0.03238552063703537,
      "learning_rate": 1.036108432444016e-05,
      "loss": 0.2067,
      "step": 44980
    },
    {
      "epoch": 4.820529304618022,
      "grad_norm": 0.002926324727013707,
      "learning_rate": 1.0358941390763956e-05,
      "loss": 0.2618,
      "step": 44990
    },
    {
      "epoch": 4.821600771456123,
      "grad_norm": 156.26739501953125,
      "learning_rate": 1.0356798457087754e-05,
      "loss": 0.3795,
      "step": 45000
    },
    {
      "epoch": 4.822672238294225,
      "grad_norm": 0.0030506295152008533,
      "learning_rate": 1.0354655523411553e-05,
      "loss": 0.1221,
      "step": 45010
    },
    {
      "epoch": 4.823743705132326,
      "grad_norm": 3.217179298400879,
      "learning_rate": 1.0352512589735348e-05,
      "loss": 0.0751,
      "step": 45020
    },
    {
      "epoch": 4.824815171970427,
      "grad_norm": 3.552882194519043,
      "learning_rate": 1.0350369656059144e-05,
      "loss": 0.216,
      "step": 45030
    },
    {
      "epoch": 4.825886638808528,
      "grad_norm": 17.930999755859375,
      "learning_rate": 1.0348226722382943e-05,
      "loss": 0.5104,
      "step": 45040
    },
    {
      "epoch": 4.82695810564663,
      "grad_norm": 0.0034169014543294907,
      "learning_rate": 1.034608378870674e-05,
      "loss": 0.1966,
      "step": 45050
    },
    {
      "epoch": 4.8280295724847315,
      "grad_norm": 93.94178771972656,
      "learning_rate": 1.0343940855030538e-05,
      "loss": 0.237,
      "step": 45060
    },
    {
      "epoch": 4.829101039322833,
      "grad_norm": 0.10292091220617294,
      "learning_rate": 1.0341797921354335e-05,
      "loss": 0.1921,
      "step": 45070
    },
    {
      "epoch": 4.830172506160935,
      "grad_norm": 0.007023644167929888,
      "learning_rate": 1.0339654987678131e-05,
      "loss": 0.0014,
      "step": 45080
    },
    {
      "epoch": 4.831243972999036,
      "grad_norm": 0.058503154665231705,
      "learning_rate": 1.033751205400193e-05,
      "loss": 0.0018,
      "step": 45090
    },
    {
      "epoch": 4.832315439837137,
      "grad_norm": 0.06280606240034103,
      "learning_rate": 1.0335369120325727e-05,
      "loss": 0.1846,
      "step": 45100
    },
    {
      "epoch": 4.833386906675239,
      "grad_norm": 0.011534018442034721,
      "learning_rate": 1.0333226186649523e-05,
      "loss": 0.8858,
      "step": 45110
    },
    {
      "epoch": 4.83445837351334,
      "grad_norm": 0.10092458873987198,
      "learning_rate": 1.0331083252973322e-05,
      "loss": 0.1428,
      "step": 45120
    },
    {
      "epoch": 4.835529840351441,
      "grad_norm": 0.07995881885290146,
      "learning_rate": 1.0328940319297118e-05,
      "loss": 0.002,
      "step": 45130
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 0.009705666452646255,
      "learning_rate": 1.0326797385620917e-05,
      "loss": 0.0016,
      "step": 45140
    },
    {
      "epoch": 4.837672774027644,
      "grad_norm": 0.08095893263816833,
      "learning_rate": 1.0324654451944714e-05,
      "loss": 0.0039,
      "step": 45150
    },
    {
      "epoch": 4.838744240865745,
      "grad_norm": 0.3916994333267212,
      "learning_rate": 1.032251151826851e-05,
      "loss": 0.3326,
      "step": 45160
    },
    {
      "epoch": 4.839815707703846,
      "grad_norm": 0.005831834394484758,
      "learning_rate": 1.0320368584592309e-05,
      "loss": 0.0006,
      "step": 45170
    },
    {
      "epoch": 4.8408871745419475,
      "grad_norm": 0.11121179908514023,
      "learning_rate": 1.0318225650916104e-05,
      "loss": 0.3458,
      "step": 45180
    },
    {
      "epoch": 4.8419586413800495,
      "grad_norm": 12.852767944335938,
      "learning_rate": 1.0316082717239902e-05,
      "loss": 0.003,
      "step": 45190
    },
    {
      "epoch": 4.843030108218151,
      "grad_norm": 0.037911541759967804,
      "learning_rate": 1.0313939783563701e-05,
      "loss": 0.3017,
      "step": 45200
    },
    {
      "epoch": 4.844101575056252,
      "grad_norm": 0.025360791012644768,
      "learning_rate": 1.0311796849887497e-05,
      "loss": 0.0014,
      "step": 45210
    },
    {
      "epoch": 4.845173041894354,
      "grad_norm": 76.54595184326172,
      "learning_rate": 1.0309653916211296e-05,
      "loss": 0.1533,
      "step": 45220
    },
    {
      "epoch": 4.846244508732455,
      "grad_norm": 18.72921371459961,
      "learning_rate": 1.0307510982535091e-05,
      "loss": 0.382,
      "step": 45230
    },
    {
      "epoch": 4.847315975570556,
      "grad_norm": 0.01365579292178154,
      "learning_rate": 1.0305368048858889e-05,
      "loss": 0.0008,
      "step": 45240
    },
    {
      "epoch": 4.848387442408658,
      "grad_norm": 56.351959228515625,
      "learning_rate": 1.0303225115182686e-05,
      "loss": 0.5433,
      "step": 45250
    },
    {
      "epoch": 4.849458909246759,
      "grad_norm": 0.00699667539447546,
      "learning_rate": 1.0301082181506483e-05,
      "loss": 0.0015,
      "step": 45260
    },
    {
      "epoch": 4.85053037608486,
      "grad_norm": 2.142488479614258,
      "learning_rate": 1.0298939247830279e-05,
      "loss": 0.0012,
      "step": 45270
    },
    {
      "epoch": 4.851601842922961,
      "grad_norm": 0.05814050883054733,
      "learning_rate": 1.0296796314154078e-05,
      "loss": 0.0027,
      "step": 45280
    },
    {
      "epoch": 4.852673309761063,
      "grad_norm": 0.012211275286972523,
      "learning_rate": 1.0294653380477875e-05,
      "loss": 0.0011,
      "step": 45290
    },
    {
      "epoch": 4.853744776599164,
      "grad_norm": 0.0035637887194752693,
      "learning_rate": 1.0292510446801673e-05,
      "loss": 0.2439,
      "step": 45300
    },
    {
      "epoch": 4.8548162434372655,
      "grad_norm": 0.04908401891589165,
      "learning_rate": 1.029036751312547e-05,
      "loss": 0.2432,
      "step": 45310
    },
    {
      "epoch": 4.855887710275367,
      "grad_norm": 0.0012798308162018657,
      "learning_rate": 1.0288224579449266e-05,
      "loss": 0.2855,
      "step": 45320
    },
    {
      "epoch": 4.856959177113469,
      "grad_norm": 0.001228355336934328,
      "learning_rate": 1.0286081645773065e-05,
      "loss": 0.0003,
      "step": 45330
    },
    {
      "epoch": 4.85803064395157,
      "grad_norm": 98.7572250366211,
      "learning_rate": 1.0283938712096862e-05,
      "loss": 0.1292,
      "step": 45340
    },
    {
      "epoch": 4.859102110789671,
      "grad_norm": 0.003728092648088932,
      "learning_rate": 1.0281795778420658e-05,
      "loss": 0.3688,
      "step": 45350
    },
    {
      "epoch": 4.860173577627773,
      "grad_norm": 0.0082487091422081,
      "learning_rate": 1.0279652844744457e-05,
      "loss": 0.3757,
      "step": 45360
    },
    {
      "epoch": 4.861245044465874,
      "grad_norm": 0.0137833496555686,
      "learning_rate": 1.0277509911068253e-05,
      "loss": 0.3559,
      "step": 45370
    },
    {
      "epoch": 4.862316511303975,
      "grad_norm": 0.008025798946619034,
      "learning_rate": 1.027536697739205e-05,
      "loss": 0.1824,
      "step": 45380
    },
    {
      "epoch": 4.863387978142076,
      "grad_norm": 270.8814392089844,
      "learning_rate": 1.0273224043715849e-05,
      "loss": 0.4713,
      "step": 45390
    },
    {
      "epoch": 4.864459444980178,
      "grad_norm": 0.0986047238111496,
      "learning_rate": 1.0271081110039645e-05,
      "loss": 0.2259,
      "step": 45400
    },
    {
      "epoch": 4.865530911818279,
      "grad_norm": 0.0011720535112544894,
      "learning_rate": 1.0268938176363444e-05,
      "loss": 0.2101,
      "step": 45410
    },
    {
      "epoch": 4.86660237865638,
      "grad_norm": 0.11727415025234222,
      "learning_rate": 1.026679524268724e-05,
      "loss": 0.1967,
      "step": 45420
    },
    {
      "epoch": 4.8676738454944815,
      "grad_norm": 0.021426985040307045,
      "learning_rate": 1.0264652309011037e-05,
      "loss": 0.0796,
      "step": 45430
    },
    {
      "epoch": 4.8687453123325835,
      "grad_norm": 0.0038199620321393013,
      "learning_rate": 1.0262509375334834e-05,
      "loss": 0.0532,
      "step": 45440
    },
    {
      "epoch": 4.869816779170685,
      "grad_norm": 0.001250238623470068,
      "learning_rate": 1.0260366441658631e-05,
      "loss": 0.0362,
      "step": 45450
    },
    {
      "epoch": 4.870888246008786,
      "grad_norm": 48.298927307128906,
      "learning_rate": 1.0258223507982427e-05,
      "loss": 0.2574,
      "step": 45460
    },
    {
      "epoch": 4.871959712846888,
      "grad_norm": 0.0035346955992281437,
      "learning_rate": 1.0256080574306226e-05,
      "loss": 0.4007,
      "step": 45470
    },
    {
      "epoch": 4.873031179684989,
      "grad_norm": 31.657453536987305,
      "learning_rate": 1.0253937640630023e-05,
      "loss": 0.1884,
      "step": 45480
    },
    {
      "epoch": 4.87410264652309,
      "grad_norm": 0.0547947995364666,
      "learning_rate": 1.025179470695382e-05,
      "loss": 0.2814,
      "step": 45490
    },
    {
      "epoch": 4.875174113361192,
      "grad_norm": 0.14944960176944733,
      "learning_rate": 1.0249651773277618e-05,
      "loss": 0.0025,
      "step": 45500
    },
    {
      "epoch": 4.876245580199293,
      "grad_norm": 0.1757228523492813,
      "learning_rate": 1.0247508839601414e-05,
      "loss": 0.5666,
      "step": 45510
    },
    {
      "epoch": 4.877317047037394,
      "grad_norm": 0.004002975765615702,
      "learning_rate": 1.0245365905925213e-05,
      "loss": 0.5392,
      "step": 45520
    },
    {
      "epoch": 4.878388513875495,
      "grad_norm": 24.156978607177734,
      "learning_rate": 1.024322297224901e-05,
      "loss": 0.1675,
      "step": 45530
    },
    {
      "epoch": 4.879459980713597,
      "grad_norm": 251.941162109375,
      "learning_rate": 1.0241080038572806e-05,
      "loss": 0.2573,
      "step": 45540
    },
    {
      "epoch": 4.880531447551698,
      "grad_norm": 0.026670312508940697,
      "learning_rate": 1.0238937104896605e-05,
      "loss": 0.2452,
      "step": 45550
    },
    {
      "epoch": 4.881602914389799,
      "grad_norm": 0.20596668124198914,
      "learning_rate": 1.02367941712204e-05,
      "loss": 0.2763,
      "step": 45560
    },
    {
      "epoch": 4.8826743812279005,
      "grad_norm": 0.17227156460285187,
      "learning_rate": 1.02346512375442e-05,
      "loss": 0.0012,
      "step": 45570
    },
    {
      "epoch": 4.8837458480660025,
      "grad_norm": 0.10955691337585449,
      "learning_rate": 1.0232508303867997e-05,
      "loss": 0.3331,
      "step": 45580
    },
    {
      "epoch": 4.884817314904104,
      "grad_norm": 0.236770898103714,
      "learning_rate": 1.0230365370191793e-05,
      "loss": 0.0022,
      "step": 45590
    },
    {
      "epoch": 4.885888781742205,
      "grad_norm": 22.63648796081543,
      "learning_rate": 1.0228222436515592e-05,
      "loss": 0.595,
      "step": 45600
    },
    {
      "epoch": 4.886960248580307,
      "grad_norm": 0.494744211435318,
      "learning_rate": 1.0226079502839387e-05,
      "loss": 0.0078,
      "step": 45610
    },
    {
      "epoch": 4.888031715418408,
      "grad_norm": 38.61729049682617,
      "learning_rate": 1.0223936569163185e-05,
      "loss": 0.3908,
      "step": 45620
    },
    {
      "epoch": 4.889103182256509,
      "grad_norm": 0.09415818005800247,
      "learning_rate": 1.0221793635486982e-05,
      "loss": 0.2873,
      "step": 45630
    },
    {
      "epoch": 4.890174649094611,
      "grad_norm": 67.7086181640625,
      "learning_rate": 1.021965070181078e-05,
      "loss": 0.1217,
      "step": 45640
    },
    {
      "epoch": 4.891246115932712,
      "grad_norm": 3.9798407554626465,
      "learning_rate": 1.0217507768134579e-05,
      "loss": 0.0508,
      "step": 45650
    },
    {
      "epoch": 4.892317582770813,
      "grad_norm": 0.022632546722888947,
      "learning_rate": 1.0215364834458374e-05,
      "loss": 0.3114,
      "step": 45660
    },
    {
      "epoch": 4.893389049608914,
      "grad_norm": 0.18918848037719727,
      "learning_rate": 1.0213221900782172e-05,
      "loss": 0.0012,
      "step": 45670
    },
    {
      "epoch": 4.894460516447016,
      "grad_norm": 0.01950576715171337,
      "learning_rate": 1.0211078967105969e-05,
      "loss": 0.0072,
      "step": 45680
    },
    {
      "epoch": 4.895531983285117,
      "grad_norm": 0.0151928486302495,
      "learning_rate": 1.0208936033429766e-05,
      "loss": 0.004,
      "step": 45690
    },
    {
      "epoch": 4.8966034501232185,
      "grad_norm": 0.13775743544101715,
      "learning_rate": 1.0206793099753562e-05,
      "loss": 0.1551,
      "step": 45700
    },
    {
      "epoch": 4.89767491696132,
      "grad_norm": 0.00488751195371151,
      "learning_rate": 1.0204650166077361e-05,
      "loss": 0.3531,
      "step": 45710
    },
    {
      "epoch": 4.898746383799422,
      "grad_norm": 0.13903486728668213,
      "learning_rate": 1.0202507232401158e-05,
      "loss": 0.4363,
      "step": 45720
    },
    {
      "epoch": 4.899817850637523,
      "grad_norm": 7.704527854919434,
      "learning_rate": 1.0200364298724956e-05,
      "loss": 0.169,
      "step": 45730
    },
    {
      "epoch": 4.900889317475624,
      "grad_norm": 0.03361073136329651,
      "learning_rate": 1.0198221365048753e-05,
      "loss": 0.3996,
      "step": 45740
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 0.023716187104582787,
      "learning_rate": 1.0196078431372549e-05,
      "loss": 0.0025,
      "step": 45750
    },
    {
      "epoch": 4.903032251151827,
      "grad_norm": 0.5195066332817078,
      "learning_rate": 1.0193935497696348e-05,
      "loss": 0.1527,
      "step": 45760
    },
    {
      "epoch": 4.904103717989928,
      "grad_norm": 0.003970992285758257,
      "learning_rate": 1.0191792564020145e-05,
      "loss": 0.0003,
      "step": 45770
    },
    {
      "epoch": 4.90517518482803,
      "grad_norm": 0.004282050766050816,
      "learning_rate": 1.018964963034394e-05,
      "loss": 0.0016,
      "step": 45780
    },
    {
      "epoch": 4.906246651666131,
      "grad_norm": 0.008249628357589245,
      "learning_rate": 1.018750669666774e-05,
      "loss": 0.2265,
      "step": 45790
    },
    {
      "epoch": 4.907318118504232,
      "grad_norm": 0.121278777718544,
      "learning_rate": 1.0185363762991535e-05,
      "loss": 0.0009,
      "step": 45800
    },
    {
      "epoch": 4.908389585342333,
      "grad_norm": 0.01759866252541542,
      "learning_rate": 1.0183220829315335e-05,
      "loss": 0.3639,
      "step": 45810
    },
    {
      "epoch": 4.909461052180435,
      "grad_norm": 0.03858821094036102,
      "learning_rate": 1.018107789563913e-05,
      "loss": 0.0384,
      "step": 45820
    },
    {
      "epoch": 4.9105325190185365,
      "grad_norm": 0.08848369866609573,
      "learning_rate": 1.0178934961962928e-05,
      "loss": 0.0014,
      "step": 45830
    },
    {
      "epoch": 4.911603985856638,
      "grad_norm": 0.004079969599843025,
      "learning_rate": 1.0176792028286727e-05,
      "loss": 0.4866,
      "step": 45840
    },
    {
      "epoch": 4.912675452694739,
      "grad_norm": 0.014756524004042149,
      "learning_rate": 1.0174649094610522e-05,
      "loss": 0.3809,
      "step": 45850
    },
    {
      "epoch": 4.913746919532841,
      "grad_norm": 0.010621320456266403,
      "learning_rate": 1.017250616093432e-05,
      "loss": 0.4079,
      "step": 45860
    },
    {
      "epoch": 4.914818386370942,
      "grad_norm": 0.04635641351342201,
      "learning_rate": 1.0170363227258117e-05,
      "loss": 0.2333,
      "step": 45870
    },
    {
      "epoch": 4.915889853209043,
      "grad_norm": 0.04060725122690201,
      "learning_rate": 1.0168220293581914e-05,
      "loss": 0.1607,
      "step": 45880
    },
    {
      "epoch": 4.916961320047145,
      "grad_norm": 0.019485270604491234,
      "learning_rate": 1.0166077359905713e-05,
      "loss": 0.1641,
      "step": 45890
    },
    {
      "epoch": 4.918032786885246,
      "grad_norm": 0.037241123616695404,
      "learning_rate": 1.0163934426229509e-05,
      "loss": 0.0134,
      "step": 45900
    },
    {
      "epoch": 4.919104253723347,
      "grad_norm": 0.1727978140115738,
      "learning_rate": 1.0161791492553306e-05,
      "loss": 0.2756,
      "step": 45910
    },
    {
      "epoch": 4.920175720561448,
      "grad_norm": 0.06838971376419067,
      "learning_rate": 1.0159648558877104e-05,
      "loss": 0.001,
      "step": 45920
    },
    {
      "epoch": 4.92124718739955,
      "grad_norm": 0.08802904933691025,
      "learning_rate": 1.0157505625200901e-05,
      "loss": 0.0006,
      "step": 45930
    },
    {
      "epoch": 4.922318654237651,
      "grad_norm": 30.809362411499023,
      "learning_rate": 1.0155362691524697e-05,
      "loss": 0.2125,
      "step": 45940
    },
    {
      "epoch": 4.9233901210757525,
      "grad_norm": 0.007989887148141861,
      "learning_rate": 1.0153219757848496e-05,
      "loss": 0.001,
      "step": 45950
    },
    {
      "epoch": 4.924461587913854,
      "grad_norm": 0.024151142686605453,
      "learning_rate": 1.0151076824172293e-05,
      "loss": 0.2508,
      "step": 45960
    },
    {
      "epoch": 4.925533054751956,
      "grad_norm": 0.026165910065174103,
      "learning_rate": 1.014893389049609e-05,
      "loss": 0.2033,
      "step": 45970
    },
    {
      "epoch": 4.926604521590057,
      "grad_norm": 0.04984999820590019,
      "learning_rate": 1.0146790956819888e-05,
      "loss": 0.376,
      "step": 45980
    },
    {
      "epoch": 4.927675988428158,
      "grad_norm": 39.30039596557617,
      "learning_rate": 1.0144648023143684e-05,
      "loss": 0.3683,
      "step": 45990
    },
    {
      "epoch": 4.92874745526626,
      "grad_norm": 0.05003136023879051,
      "learning_rate": 1.0142505089467483e-05,
      "loss": 0.0009,
      "step": 46000
    },
    {
      "epoch": 4.929818922104361,
      "grad_norm": 0.013078291900455952,
      "learning_rate": 1.0140362155791278e-05,
      "loss": 0.4293,
      "step": 46010
    },
    {
      "epoch": 4.930890388942462,
      "grad_norm": 0.0805589035153389,
      "learning_rate": 1.0138219222115076e-05,
      "loss": 0.285,
      "step": 46020
    },
    {
      "epoch": 4.931961855780564,
      "grad_norm": 0.27134764194488525,
      "learning_rate": 1.0136076288438875e-05,
      "loss": 0.1063,
      "step": 46030
    },
    {
      "epoch": 4.933033322618665,
      "grad_norm": 0.021354997530579567,
      "learning_rate": 1.013393335476267e-05,
      "loss": 0.3317,
      "step": 46040
    },
    {
      "epoch": 4.934104789456766,
      "grad_norm": 0.040769606828689575,
      "learning_rate": 1.013179042108647e-05,
      "loss": 0.0973,
      "step": 46050
    },
    {
      "epoch": 4.935176256294867,
      "grad_norm": 0.026259474456310272,
      "learning_rate": 1.0129647487410265e-05,
      "loss": 0.1996,
      "step": 46060
    },
    {
      "epoch": 4.936247723132969,
      "grad_norm": 0.026280144229531288,
      "learning_rate": 1.0127504553734062e-05,
      "loss": 0.002,
      "step": 46070
    },
    {
      "epoch": 4.93731918997107,
      "grad_norm": 0.010997556149959564,
      "learning_rate": 1.0125361620057861e-05,
      "loss": 0.335,
      "step": 46080
    },
    {
      "epoch": 4.9383906568091716,
      "grad_norm": 0.004831553902477026,
      "learning_rate": 1.0123218686381657e-05,
      "loss": 0.0694,
      "step": 46090
    },
    {
      "epoch": 4.939462123647273,
      "grad_norm": 0.0074299974367022514,
      "learning_rate": 1.0121075752705454e-05,
      "loss": 0.3946,
      "step": 46100
    },
    {
      "epoch": 4.940533590485375,
      "grad_norm": 0.010739446617662907,
      "learning_rate": 1.0118932819029252e-05,
      "loss": 0.0025,
      "step": 46110
    },
    {
      "epoch": 4.941605057323476,
      "grad_norm": 0.07104780524969101,
      "learning_rate": 1.011678988535305e-05,
      "loss": 0.1839,
      "step": 46120
    },
    {
      "epoch": 4.942676524161577,
      "grad_norm": 1.0876655578613281,
      "learning_rate": 1.0114646951676848e-05,
      "loss": 0.0912,
      "step": 46130
    },
    {
      "epoch": 4.943747990999679,
      "grad_norm": 0.08638268709182739,
      "learning_rate": 1.0112504018000644e-05,
      "loss": 0.3871,
      "step": 46140
    },
    {
      "epoch": 4.94481945783778,
      "grad_norm": 0.31186026334762573,
      "learning_rate": 1.0110361084324441e-05,
      "loss": 0.3965,
      "step": 46150
    },
    {
      "epoch": 4.945890924675881,
      "grad_norm": 0.02759058214724064,
      "learning_rate": 1.0108218150648239e-05,
      "loss": 0.0006,
      "step": 46160
    },
    {
      "epoch": 4.946962391513983,
      "grad_norm": 25.8552303314209,
      "learning_rate": 1.0106075216972036e-05,
      "loss": 0.1795,
      "step": 46170
    },
    {
      "epoch": 4.948033858352084,
      "grad_norm": 0.00497352285310626,
      "learning_rate": 1.0103932283295832e-05,
      "loss": 0.0049,
      "step": 46180
    },
    {
      "epoch": 4.949105325190185,
      "grad_norm": 0.08637960255146027,
      "learning_rate": 1.010178934961963e-05,
      "loss": 0.0005,
      "step": 46190
    },
    {
      "epoch": 4.950176792028286,
      "grad_norm": 0.011205732822418213,
      "learning_rate": 1.0099646415943426e-05,
      "loss": 0.3239,
      "step": 46200
    },
    {
      "epoch": 4.951248258866388,
      "grad_norm": 0.019960889592766762,
      "learning_rate": 1.0097503482267225e-05,
      "loss": 0.3083,
      "step": 46210
    },
    {
      "epoch": 4.9523197257044895,
      "grad_norm": 0.010157403536140919,
      "learning_rate": 1.0095360548591023e-05,
      "loss": 0.3418,
      "step": 46220
    },
    {
      "epoch": 4.953391192542591,
      "grad_norm": 0.07555913925170898,
      "learning_rate": 1.0093217614914818e-05,
      "loss": 0.0031,
      "step": 46230
    },
    {
      "epoch": 4.954462659380692,
      "grad_norm": 44.51063919067383,
      "learning_rate": 1.0091074681238617e-05,
      "loss": 0.737,
      "step": 46240
    },
    {
      "epoch": 4.955534126218794,
      "grad_norm": 0.24084459245204926,
      "learning_rate": 1.0088931747562413e-05,
      "loss": 0.0875,
      "step": 46250
    },
    {
      "epoch": 4.956605593056895,
      "grad_norm": 0.017195576801896095,
      "learning_rate": 1.008678881388621e-05,
      "loss": 0.1463,
      "step": 46260
    },
    {
      "epoch": 4.957677059894996,
      "grad_norm": 0.41568753123283386,
      "learning_rate": 1.008464588021001e-05,
      "loss": 0.2983,
      "step": 46270
    },
    {
      "epoch": 4.958748526733098,
      "grad_norm": 338.3775939941406,
      "learning_rate": 1.0082502946533805e-05,
      "loss": 0.0732,
      "step": 46280
    },
    {
      "epoch": 4.959819993571199,
      "grad_norm": 275.1504211425781,
      "learning_rate": 1.0080360012857603e-05,
      "loss": 0.2668,
      "step": 46290
    },
    {
      "epoch": 4.9608914604093,
      "grad_norm": 4.007608890533447,
      "learning_rate": 1.00782170791814e-05,
      "loss": 0.1938,
      "step": 46300
    },
    {
      "epoch": 4.961962927247402,
      "grad_norm": 0.0021928369533270597,
      "learning_rate": 1.0076074145505197e-05,
      "loss": 0.6112,
      "step": 46310
    },
    {
      "epoch": 4.963034394085503,
      "grad_norm": 25.166015625,
      "learning_rate": 1.0073931211828996e-05,
      "loss": 0.1148,
      "step": 46320
    },
    {
      "epoch": 4.964105860923604,
      "grad_norm": 21.193418502807617,
      "learning_rate": 1.0071788278152792e-05,
      "loss": 0.5198,
      "step": 46330
    },
    {
      "epoch": 4.9651773277617055,
      "grad_norm": 0.029762286692857742,
      "learning_rate": 1.006964534447659e-05,
      "loss": 0.0006,
      "step": 46340
    },
    {
      "epoch": 4.9662487945998075,
      "grad_norm": 0.20448826253414154,
      "learning_rate": 1.0067502410800387e-05,
      "loss": 0.0016,
      "step": 46350
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 0.09116087108850479,
      "learning_rate": 1.0065359477124184e-05,
      "loss": 0.3544,
      "step": 46360
    },
    {
      "epoch": 4.96839172827601,
      "grad_norm": 0.01606668159365654,
      "learning_rate": 1.006321654344798e-05,
      "loss": 0.2096,
      "step": 46370
    },
    {
      "epoch": 4.969463195114111,
      "grad_norm": 0.10295358300209045,
      "learning_rate": 1.0061073609771779e-05,
      "loss": 0.191,
      "step": 46380
    },
    {
      "epoch": 4.970534661952213,
      "grad_norm": 0.06157505512237549,
      "learning_rate": 1.0058930676095574e-05,
      "loss": 0.0015,
      "step": 46390
    },
    {
      "epoch": 4.971606128790314,
      "grad_norm": 0.04897420108318329,
      "learning_rate": 1.0056787742419373e-05,
      "loss": 0.0639,
      "step": 46400
    },
    {
      "epoch": 4.972677595628415,
      "grad_norm": 0.523804783821106,
      "learning_rate": 1.005464480874317e-05,
      "loss": 0.0008,
      "step": 46410
    },
    {
      "epoch": 4.973749062466517,
      "grad_norm": 0.010333363898098469,
      "learning_rate": 1.0052501875066966e-05,
      "loss": 0.0996,
      "step": 46420
    },
    {
      "epoch": 4.974820529304618,
      "grad_norm": 0.20732657611370087,
      "learning_rate": 1.0050358941390765e-05,
      "loss": 0.0004,
      "step": 46430
    },
    {
      "epoch": 4.975891996142719,
      "grad_norm": 0.05289498716592789,
      "learning_rate": 1.0048216007714561e-05,
      "loss": 0.2513,
      "step": 46440
    },
    {
      "epoch": 4.97696346298082,
      "grad_norm": 0.4878893196582794,
      "learning_rate": 1.0046073074038359e-05,
      "loss": 0.425,
      "step": 46450
    },
    {
      "epoch": 4.978034929818922,
      "grad_norm": 0.04276015982031822,
      "learning_rate": 1.0043930140362158e-05,
      "loss": 0.165,
      "step": 46460
    },
    {
      "epoch": 4.9791063966570235,
      "grad_norm": 0.008383307605981827,
      "learning_rate": 1.0041787206685953e-05,
      "loss": 0.001,
      "step": 46470
    },
    {
      "epoch": 4.980177863495125,
      "grad_norm": 0.04259997978806496,
      "learning_rate": 1.0039644273009752e-05,
      "loss": 0.3003,
      "step": 46480
    },
    {
      "epoch": 4.981249330333226,
      "grad_norm": 0.014508928172290325,
      "learning_rate": 1.0037501339333548e-05,
      "loss": 0.0759,
      "step": 46490
    },
    {
      "epoch": 4.982320797171328,
      "grad_norm": 0.043991412967443466,
      "learning_rate": 1.0035358405657345e-05,
      "loss": 0.2055,
      "step": 46500
    },
    {
      "epoch": 4.983392264009429,
      "grad_norm": 0.08354178816080093,
      "learning_rate": 1.0033215471981144e-05,
      "loss": 0.0011,
      "step": 46510
    },
    {
      "epoch": 4.98446373084753,
      "grad_norm": 0.0026867303531616926,
      "learning_rate": 1.003107253830494e-05,
      "loss": 0.3594,
      "step": 46520
    },
    {
      "epoch": 4.985535197685632,
      "grad_norm": 0.012322221882641315,
      "learning_rate": 1.0028929604628737e-05,
      "loss": 0.2008,
      "step": 46530
    },
    {
      "epoch": 4.986606664523733,
      "grad_norm": 0.0014602752635255456,
      "learning_rate": 1.0026786670952535e-05,
      "loss": 0.2027,
      "step": 46540
    },
    {
      "epoch": 4.987678131361834,
      "grad_norm": 0.599165141582489,
      "learning_rate": 1.0024643737276332e-05,
      "loss": 0.1967,
      "step": 46550
    },
    {
      "epoch": 4.988749598199936,
      "grad_norm": 116.58644104003906,
      "learning_rate": 1.0022500803600131e-05,
      "loss": 0.3697,
      "step": 46560
    },
    {
      "epoch": 4.989821065038037,
      "grad_norm": 1.01181960105896,
      "learning_rate": 1.0020357869923927e-05,
      "loss": 0.1244,
      "step": 46570
    },
    {
      "epoch": 4.990892531876138,
      "grad_norm": 0.22319790720939636,
      "learning_rate": 1.0018214936247722e-05,
      "loss": 0.1975,
      "step": 46580
    },
    {
      "epoch": 4.9919639987142395,
      "grad_norm": 0.11874837428331375,
      "learning_rate": 1.0016072002571521e-05,
      "loss": 0.2035,
      "step": 46590
    },
    {
      "epoch": 4.9930354655523415,
      "grad_norm": 0.1565122753381729,
      "learning_rate": 1.0013929068895319e-05,
      "loss": 0.3018,
      "step": 46600
    },
    {
      "epoch": 4.994106932390443,
      "grad_norm": 0.04428020492196083,
      "learning_rate": 1.0011786135219115e-05,
      "loss": 0.0072,
      "step": 46610
    },
    {
      "epoch": 4.995178399228544,
      "grad_norm": 0.05458356812596321,
      "learning_rate": 1.0009643201542914e-05,
      "loss": 0.003,
      "step": 46620
    },
    {
      "epoch": 4.996249866066645,
      "grad_norm": 0.1886262744665146,
      "learning_rate": 1.000750026786671e-05,
      "loss": 0.4763,
      "step": 46630
    },
    {
      "epoch": 4.997321332904747,
      "grad_norm": 0.2504209578037262,
      "learning_rate": 1.0005357334190508e-05,
      "loss": 0.0183,
      "step": 46640
    },
    {
      "epoch": 4.998392799742848,
      "grad_norm": 0.13151544332504272,
      "learning_rate": 1.0003214400514306e-05,
      "loss": 0.1591,
      "step": 46650
    },
    {
      "epoch": 4.999464266580949,
      "grad_norm": 0.0017377490876242518,
      "learning_rate": 1.0001071466838101e-05,
      "loss": 0.2624,
      "step": 46660
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.939,
      "eval_f1": 0.8336363636363636,
      "eval_loss": 0.35382869839668274,
      "eval_precision": 0.8851351351351351,
      "eval_recall": 0.7878006872852233,
      "eval_runtime": 527.5276,
      "eval_samples_per_second": 11.374,
      "eval_steps_per_second": 3.791,
      "step": 46665
    },
    {
      "epoch": 5.000535733419051,
      "grad_norm": 0.0019919713959097862,
      "learning_rate": 9.998928533161899e-06,
      "loss": 0.3594,
      "step": 46670
    },
    {
      "epoch": 5.001607200257152,
      "grad_norm": 0.18623457849025726,
      "learning_rate": 9.996785599485696e-06,
      "loss": 0.4696,
      "step": 46680
    },
    {
      "epoch": 5.002678667095253,
      "grad_norm": 0.18716886639595032,
      "learning_rate": 9.994642665809493e-06,
      "loss": 0.0119,
      "step": 46690
    },
    {
      "epoch": 5.003750133933354,
      "grad_norm": 0.05697723850607872,
      "learning_rate": 9.992499732133292e-06,
      "loss": 0.087,
      "step": 46700
    },
    {
      "epoch": 5.004821600771456,
      "grad_norm": 0.3127168118953705,
      "learning_rate": 9.990356798457088e-06,
      "loss": 0.2518,
      "step": 46710
    },
    {
      "epoch": 5.005893067609557,
      "grad_norm": 0.28012552857398987,
      "learning_rate": 9.988213864780885e-06,
      "loss": 0.0021,
      "step": 46720
    },
    {
      "epoch": 5.0069645344476585,
      "grad_norm": 0.06771192699670792,
      "learning_rate": 9.986070931104683e-06,
      "loss": 0.003,
      "step": 46730
    },
    {
      "epoch": 5.0080360012857605,
      "grad_norm": 0.11368893086910248,
      "learning_rate": 9.98392799742848e-06,
      "loss": 0.0013,
      "step": 46740
    },
    {
      "epoch": 5.009107468123862,
      "grad_norm": 0.0014805077807977796,
      "learning_rate": 9.981785063752277e-06,
      "loss": 0.1694,
      "step": 46750
    },
    {
      "epoch": 5.010178934961963,
      "grad_norm": 0.034801874309778214,
      "learning_rate": 9.979642130076075e-06,
      "loss": 0.0942,
      "step": 46760
    },
    {
      "epoch": 5.011250401800064,
      "grad_norm": 0.27310270071029663,
      "learning_rate": 9.977499196399872e-06,
      "loss": 0.001,
      "step": 46770
    },
    {
      "epoch": 5.012321868638166,
      "grad_norm": 57.51047897338867,
      "learning_rate": 9.97535626272367e-06,
      "loss": 0.0248,
      "step": 46780
    },
    {
      "epoch": 5.013393335476267,
      "grad_norm": 0.05886755883693695,
      "learning_rate": 9.973213329047467e-06,
      "loss": 0.1452,
      "step": 46790
    },
    {
      "epoch": 5.014464802314368,
      "grad_norm": 0.07634267956018448,
      "learning_rate": 9.971070395371264e-06,
      "loss": 0.0102,
      "step": 46800
    },
    {
      "epoch": 5.01553626915247,
      "grad_norm": 0.0009213269222527742,
      "learning_rate": 9.968927461695062e-06,
      "loss": 0.0738,
      "step": 46810
    },
    {
      "epoch": 5.016607735990571,
      "grad_norm": 0.0008657256257720292,
      "learning_rate": 9.966784528018859e-06,
      "loss": 0.0506,
      "step": 46820
    },
    {
      "epoch": 5.017679202828672,
      "grad_norm": 0.028811411932110786,
      "learning_rate": 9.964641594342656e-06,
      "loss": 0.0008,
      "step": 46830
    },
    {
      "epoch": 5.018750669666773,
      "grad_norm": 24.66310691833496,
      "learning_rate": 9.962498660666454e-06,
      "loss": 0.3552,
      "step": 46840
    },
    {
      "epoch": 5.019822136504875,
      "grad_norm": 0.008070012554526329,
      "learning_rate": 9.960355726990251e-06,
      "loss": 0.1847,
      "step": 46850
    },
    {
      "epoch": 5.0208936033429765,
      "grad_norm": 0.0025436044670641422,
      "learning_rate": 9.958212793314048e-06,
      "loss": 0.0014,
      "step": 46860
    },
    {
      "epoch": 5.021965070181078,
      "grad_norm": 0.04722336307168007,
      "learning_rate": 9.956069859637844e-06,
      "loss": 0.1385,
      "step": 46870
    },
    {
      "epoch": 5.02303653701918,
      "grad_norm": 0.028879716992378235,
      "learning_rate": 9.953926925961641e-06,
      "loss": 0.0007,
      "step": 46880
    },
    {
      "epoch": 5.024108003857281,
      "grad_norm": 224.67578125,
      "learning_rate": 9.95178399228544e-06,
      "loss": 0.0857,
      "step": 46890
    },
    {
      "epoch": 5.025179470695382,
      "grad_norm": 29.846954345703125,
      "learning_rate": 9.949641058609238e-06,
      "loss": 0.1769,
      "step": 46900
    },
    {
      "epoch": 5.026250937533483,
      "grad_norm": 0.045492783188819885,
      "learning_rate": 9.947498124933033e-06,
      "loss": 0.0756,
      "step": 46910
    },
    {
      "epoch": 5.027322404371585,
      "grad_norm": 0.0035670807119458914,
      "learning_rate": 9.945355191256831e-06,
      "loss": 0.4464,
      "step": 46920
    },
    {
      "epoch": 5.028393871209686,
      "grad_norm": 0.09837417304515839,
      "learning_rate": 9.943212257580628e-06,
      "loss": 0.4133,
      "step": 46930
    },
    {
      "epoch": 5.029465338047787,
      "grad_norm": 0.09142038971185684,
      "learning_rate": 9.941069323904427e-06,
      "loss": 0.2576,
      "step": 46940
    },
    {
      "epoch": 5.030536804885889,
      "grad_norm": 0.06297216564416885,
      "learning_rate": 9.938926390228223e-06,
      "loss": 0.1298,
      "step": 46950
    },
    {
      "epoch": 5.03160827172399,
      "grad_norm": 0.04438038542866707,
      "learning_rate": 9.93678345655202e-06,
      "loss": 0.105,
      "step": 46960
    },
    {
      "epoch": 5.032679738562091,
      "grad_norm": 0.0023574570659548044,
      "learning_rate": 9.934640522875818e-06,
      "loss": 0.2493,
      "step": 46970
    },
    {
      "epoch": 5.0337512054001925,
      "grad_norm": 0.010739820078015327,
      "learning_rate": 9.932497589199615e-06,
      "loss": 0.1709,
      "step": 46980
    },
    {
      "epoch": 5.0348226722382945,
      "grad_norm": 0.006404956337064505,
      "learning_rate": 9.930354655523412e-06,
      "loss": 0.0632,
      "step": 46990
    },
    {
      "epoch": 5.035894139076396,
      "grad_norm": 0.02693612314760685,
      "learning_rate": 9.92821172184721e-06,
      "loss": 0.0298,
      "step": 47000
    },
    {
      "epoch": 5.036965605914497,
      "grad_norm": 0.08797342330217361,
      "learning_rate": 9.926068788171007e-06,
      "loss": 0.4152,
      "step": 47010
    },
    {
      "epoch": 5.038037072752599,
      "grad_norm": 0.003013781737536192,
      "learning_rate": 9.923925854494804e-06,
      "loss": 0.0013,
      "step": 47020
    },
    {
      "epoch": 5.0391085395907,
      "grad_norm": 0.1113358661532402,
      "learning_rate": 9.921782920818602e-06,
      "loss": 0.0009,
      "step": 47030
    },
    {
      "epoch": 5.040180006428801,
      "grad_norm": 0.0011013548355549574,
      "learning_rate": 9.919639987142399e-06,
      "loss": 0.0013,
      "step": 47040
    },
    {
      "epoch": 5.041251473266902,
      "grad_norm": 0.025453366339206696,
      "learning_rate": 9.917497053466196e-06,
      "loss": 0.001,
      "step": 47050
    },
    {
      "epoch": 5.042322940105004,
      "grad_norm": 0.02801925502717495,
      "learning_rate": 9.915354119789994e-06,
      "loss": 0.0003,
      "step": 47060
    },
    {
      "epoch": 5.043394406943105,
      "grad_norm": 0.042639438062906265,
      "learning_rate": 9.91321118611379e-06,
      "loss": 0.0015,
      "step": 47070
    },
    {
      "epoch": 5.044465873781206,
      "grad_norm": 0.0008621602901257575,
      "learning_rate": 9.911068252437589e-06,
      "loss": 0.001,
      "step": 47080
    },
    {
      "epoch": 5.045537340619308,
      "grad_norm": 11.193626403808594,
      "learning_rate": 9.908925318761386e-06,
      "loss": 0.0059,
      "step": 47090
    },
    {
      "epoch": 5.046608807457409,
      "grad_norm": 0.028859194368124008,
      "learning_rate": 9.906782385085183e-06,
      "loss": 0.1889,
      "step": 47100
    },
    {
      "epoch": 5.0476802742955105,
      "grad_norm": 0.03064093366265297,
      "learning_rate": 9.904639451408979e-06,
      "loss": 0.4203,
      "step": 47110
    },
    {
      "epoch": 5.048751741133612,
      "grad_norm": 0.0007607205188833177,
      "learning_rate": 9.902496517732776e-06,
      "loss": 0.1568,
      "step": 47120
    },
    {
      "epoch": 5.049823207971714,
      "grad_norm": 0.0696815699338913,
      "learning_rate": 9.900353584056575e-06,
      "loss": 0.0012,
      "step": 47130
    },
    {
      "epoch": 5.050894674809815,
      "grad_norm": 0.02167627587914467,
      "learning_rate": 9.898210650380371e-06,
      "loss": 0.0016,
      "step": 47140
    },
    {
      "epoch": 5.051966141647916,
      "grad_norm": 0.0005818399949930608,
      "learning_rate": 9.896067716704168e-06,
      "loss": 0.0003,
      "step": 47150
    },
    {
      "epoch": 5.053037608486018,
      "grad_norm": 0.0005694790161214769,
      "learning_rate": 9.893924783027966e-06,
      "loss": 0.209,
      "step": 47160
    },
    {
      "epoch": 5.054109075324119,
      "grad_norm": 0.04620211943984032,
      "learning_rate": 9.891781849351763e-06,
      "loss": 0.2383,
      "step": 47170
    },
    {
      "epoch": 5.05518054216222,
      "grad_norm": 0.00246100639924407,
      "learning_rate": 9.88963891567556e-06,
      "loss": 0.1839,
      "step": 47180
    },
    {
      "epoch": 5.056252009000321,
      "grad_norm": 0.0005032134940847754,
      "learning_rate": 9.887495981999358e-06,
      "loss": 0.6066,
      "step": 47190
    },
    {
      "epoch": 5.057323475838423,
      "grad_norm": 0.12044939398765564,
      "learning_rate": 9.885353048323155e-06,
      "loss": 0.2045,
      "step": 47200
    },
    {
      "epoch": 5.058394942676524,
      "grad_norm": 0.010284622199833393,
      "learning_rate": 9.883210114646952e-06,
      "loss": 0.0004,
      "step": 47210
    },
    {
      "epoch": 5.059466409514625,
      "grad_norm": 0.04001976549625397,
      "learning_rate": 9.88106718097075e-06,
      "loss": 0.0009,
      "step": 47220
    },
    {
      "epoch": 5.0605378763527264,
      "grad_norm": 0.016040349379181862,
      "learning_rate": 9.878924247294547e-06,
      "loss": 0.0755,
      "step": 47230
    },
    {
      "epoch": 5.0616093431908284,
      "grad_norm": 0.0017240403685718775,
      "learning_rate": 9.876781313618345e-06,
      "loss": 0.0497,
      "step": 47240
    },
    {
      "epoch": 5.06268081002893,
      "grad_norm": 0.0012952795950695872,
      "learning_rate": 9.874638379942142e-06,
      "loss": 0.0003,
      "step": 47250
    },
    {
      "epoch": 5.063752276867031,
      "grad_norm": 0.003819865407422185,
      "learning_rate": 9.872495446265938e-06,
      "loss": 0.2004,
      "step": 47260
    },
    {
      "epoch": 5.064823743705133,
      "grad_norm": 0.00941952783614397,
      "learning_rate": 9.870352512589737e-06,
      "loss": 0.0004,
      "step": 47270
    },
    {
      "epoch": 5.065895210543234,
      "grad_norm": 0.03776802495121956,
      "learning_rate": 9.868209578913534e-06,
      "loss": 0.0175,
      "step": 47280
    },
    {
      "epoch": 5.066966677381335,
      "grad_norm": 105.42111206054688,
      "learning_rate": 9.866066645237331e-06,
      "loss": 0.0879,
      "step": 47290
    },
    {
      "epoch": 5.068038144219436,
      "grad_norm": 0.0010913957376033068,
      "learning_rate": 9.863923711561127e-06,
      "loss": 0.2155,
      "step": 47300
    },
    {
      "epoch": 5.069109611057538,
      "grad_norm": 0.47219035029411316,
      "learning_rate": 9.861780777884924e-06,
      "loss": 0.0027,
      "step": 47310
    },
    {
      "epoch": 5.070181077895639,
      "grad_norm": 0.01448756642639637,
      "learning_rate": 9.859637844208723e-06,
      "loss": 0.0003,
      "step": 47320
    },
    {
      "epoch": 5.07125254473374,
      "grad_norm": 0.002642714884132147,
      "learning_rate": 9.85749491053252e-06,
      "loss": 0.1975,
      "step": 47330
    },
    {
      "epoch": 5.072324011571842,
      "grad_norm": 0.04956569895148277,
      "learning_rate": 9.855351976856316e-06,
      "loss": 0.0012,
      "step": 47340
    },
    {
      "epoch": 5.073395478409943,
      "grad_norm": 0.003911428619176149,
      "learning_rate": 9.853209043180114e-06,
      "loss": 0.2973,
      "step": 47350
    },
    {
      "epoch": 5.074466945248044,
      "grad_norm": 0.0015655014431104064,
      "learning_rate": 9.851066109503911e-06,
      "loss": 0.1978,
      "step": 47360
    },
    {
      "epoch": 5.0755384120861455,
      "grad_norm": 0.082664355635643,
      "learning_rate": 9.848923175827708e-06,
      "loss": 0.1073,
      "step": 47370
    },
    {
      "epoch": 5.0766098789242475,
      "grad_norm": 0.04063016548752785,
      "learning_rate": 9.846780242151506e-06,
      "loss": 0.0366,
      "step": 47380
    },
    {
      "epoch": 5.077681345762349,
      "grad_norm": 0.02755422331392765,
      "learning_rate": 9.844637308475303e-06,
      "loss": 0.3557,
      "step": 47390
    },
    {
      "epoch": 5.07875281260045,
      "grad_norm": 0.20622418820858002,
      "learning_rate": 9.8424943747991e-06,
      "loss": 0.0005,
      "step": 47400
    },
    {
      "epoch": 5.079824279438552,
      "grad_norm": 0.014235561713576317,
      "learning_rate": 9.840351441122898e-06,
      "loss": 0.0005,
      "step": 47410
    },
    {
      "epoch": 5.080895746276653,
      "grad_norm": 0.0013731454964727163,
      "learning_rate": 9.838208507446695e-06,
      "loss": 0.2176,
      "step": 47420
    },
    {
      "epoch": 5.081967213114754,
      "grad_norm": 0.06692788004875183,
      "learning_rate": 9.836065573770493e-06,
      "loss": 0.0003,
      "step": 47430
    },
    {
      "epoch": 5.083038679952855,
      "grad_norm": 0.15433736145496368,
      "learning_rate": 9.83392264009429e-06,
      "loss": 0.0006,
      "step": 47440
    },
    {
      "epoch": 5.084110146790957,
      "grad_norm": 51.58072280883789,
      "learning_rate": 9.831779706418087e-06,
      "loss": 0.4076,
      "step": 47450
    },
    {
      "epoch": 5.085181613629058,
      "grad_norm": 60.04950714111328,
      "learning_rate": 9.829636772741885e-06,
      "loss": 0.167,
      "step": 47460
    },
    {
      "epoch": 5.086253080467159,
      "grad_norm": 0.10701022297143936,
      "learning_rate": 9.827493839065682e-06,
      "loss": 0.1634,
      "step": 47470
    },
    {
      "epoch": 5.087324547305261,
      "grad_norm": 0.019412249326705933,
      "learning_rate": 9.82535090538948e-06,
      "loss": 0.2788,
      "step": 47480
    },
    {
      "epoch": 5.088396014143362,
      "grad_norm": 0.05270400270819664,
      "learning_rate": 9.823207971713277e-06,
      "loss": 0.2279,
      "step": 47490
    },
    {
      "epoch": 5.0894674809814635,
      "grad_norm": 0.0005997882690280676,
      "learning_rate": 9.821065038037072e-06,
      "loss": 0.1737,
      "step": 47500
    },
    {
      "epoch": 5.090538947819565,
      "grad_norm": 0.0006962515180930495,
      "learning_rate": 9.818922104360871e-06,
      "loss": 0.0008,
      "step": 47510
    },
    {
      "epoch": 5.091610414657667,
      "grad_norm": 0.0005582359153777361,
      "learning_rate": 9.816779170684669e-06,
      "loss": 0.0006,
      "step": 47520
    },
    {
      "epoch": 5.092681881495768,
      "grad_norm": 0.039441339671611786,
      "learning_rate": 9.814636237008466e-06,
      "loss": 0.0247,
      "step": 47530
    },
    {
      "epoch": 5.093753348333869,
      "grad_norm": 0.00041329971281811595,
      "learning_rate": 9.812493303332262e-06,
      "loss": 0.2764,
      "step": 47540
    },
    {
      "epoch": 5.094824815171971,
      "grad_norm": 0.08172989636659622,
      "learning_rate": 9.81035036965606e-06,
      "loss": 0.193,
      "step": 47550
    },
    {
      "epoch": 5.095896282010072,
      "grad_norm": 0.10118528455495834,
      "learning_rate": 9.808207435979857e-06,
      "loss": 0.3478,
      "step": 47560
    },
    {
      "epoch": 5.096967748848173,
      "grad_norm": 4.61181116104126,
      "learning_rate": 9.806064502303656e-06,
      "loss": 0.2484,
      "step": 47570
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 0.0012336400104686618,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.4012,
      "step": 47580
    },
    {
      "epoch": 5.099110682524376,
      "grad_norm": 0.11220396310091019,
      "learning_rate": 9.801778634951249e-06,
      "loss": 0.1713,
      "step": 47590
    },
    {
      "epoch": 5.100182149362477,
      "grad_norm": 0.04223727062344551,
      "learning_rate": 9.799635701275046e-06,
      "loss": 0.0008,
      "step": 47600
    },
    {
      "epoch": 5.101253616200578,
      "grad_norm": 0.38908976316452026,
      "learning_rate": 9.797492767598843e-06,
      "loss": 0.0018,
      "step": 47610
    },
    {
      "epoch": 5.10232508303868,
      "grad_norm": 0.0005575923132710159,
      "learning_rate": 9.79534983392264e-06,
      "loss": 0.0004,
      "step": 47620
    },
    {
      "epoch": 5.1033965498767815,
      "grad_norm": 0.04805494099855423,
      "learning_rate": 9.793206900246438e-06,
      "loss": 0.0002,
      "step": 47630
    },
    {
      "epoch": 5.104468016714883,
      "grad_norm": 0.056458692997694016,
      "learning_rate": 9.791063966570235e-06,
      "loss": 0.0003,
      "step": 47640
    },
    {
      "epoch": 5.105539483552984,
      "grad_norm": 0.02411527745425701,
      "learning_rate": 9.788921032894033e-06,
      "loss": 0.2419,
      "step": 47650
    },
    {
      "epoch": 5.106610950391086,
      "grad_norm": 0.0008300766930915415,
      "learning_rate": 9.78677809921783e-06,
      "loss": 0.3425,
      "step": 47660
    },
    {
      "epoch": 5.107682417229187,
      "grad_norm": 23.96576499938965,
      "learning_rate": 9.784635165541627e-06,
      "loss": 0.094,
      "step": 47670
    },
    {
      "epoch": 5.108753884067288,
      "grad_norm": 0.15777073800563812,
      "learning_rate": 9.782492231865425e-06,
      "loss": 0.0148,
      "step": 47680
    },
    {
      "epoch": 5.109825350905389,
      "grad_norm": 0.000653131864964962,
      "learning_rate": 9.780349298189222e-06,
      "loss": 0.0009,
      "step": 47690
    },
    {
      "epoch": 5.110896817743491,
      "grad_norm": 0.0344131700694561,
      "learning_rate": 9.77820636451302e-06,
      "loss": 0.085,
      "step": 47700
    },
    {
      "epoch": 5.111968284581592,
      "grad_norm": 0.026041818782687187,
      "learning_rate": 9.776063430836817e-06,
      "loss": 0.0006,
      "step": 47710
    },
    {
      "epoch": 5.113039751419693,
      "grad_norm": 0.055395204573869705,
      "learning_rate": 9.773920497160614e-06,
      "loss": 0.0014,
      "step": 47720
    },
    {
      "epoch": 5.114111218257795,
      "grad_norm": 0.039065297693014145,
      "learning_rate": 9.771777563484412e-06,
      "loss": 0.4023,
      "step": 47730
    },
    {
      "epoch": 5.115182685095896,
      "grad_norm": 0.0010967041598632932,
      "learning_rate": 9.769634629808207e-06,
      "loss": 0.2809,
      "step": 47740
    },
    {
      "epoch": 5.1162541519339975,
      "grad_norm": 47.620079040527344,
      "learning_rate": 9.767491696132005e-06,
      "loss": 0.2689,
      "step": 47750
    },
    {
      "epoch": 5.117325618772099,
      "grad_norm": 0.28809982538223267,
      "learning_rate": 9.765348762455804e-06,
      "loss": 0.0016,
      "step": 47760
    },
    {
      "epoch": 5.118397085610201,
      "grad_norm": 0.1598631739616394,
      "learning_rate": 9.763205828779601e-06,
      "loss": 0.0108,
      "step": 47770
    },
    {
      "epoch": 5.119468552448302,
      "grad_norm": 0.027511373162269592,
      "learning_rate": 9.761062895103397e-06,
      "loss": 0.0752,
      "step": 47780
    },
    {
      "epoch": 5.120540019286403,
      "grad_norm": 0.0008267326047644019,
      "learning_rate": 9.758919961427194e-06,
      "loss": 0.001,
      "step": 47790
    },
    {
      "epoch": 5.121611486124505,
      "grad_norm": 0.00037751352647319436,
      "learning_rate": 9.756777027750991e-06,
      "loss": 0.2248,
      "step": 47800
    },
    {
      "epoch": 5.122682952962606,
      "grad_norm": 0.014796845614910126,
      "learning_rate": 9.75463409407479e-06,
      "loss": 0.0617,
      "step": 47810
    },
    {
      "epoch": 5.123754419800707,
      "grad_norm": 0.03365565463900566,
      "learning_rate": 9.752491160398586e-06,
      "loss": 0.0005,
      "step": 47820
    },
    {
      "epoch": 5.124825886638808,
      "grad_norm": 13.513690948486328,
      "learning_rate": 9.750348226722383e-06,
      "loss": 0.2355,
      "step": 47830
    },
    {
      "epoch": 5.12589735347691,
      "grad_norm": 0.1683541089296341,
      "learning_rate": 9.74820529304618e-06,
      "loss": 0.0013,
      "step": 47840
    },
    {
      "epoch": 5.126968820315011,
      "grad_norm": 0.03322383016347885,
      "learning_rate": 9.746062359369978e-06,
      "loss": 0.3851,
      "step": 47850
    },
    {
      "epoch": 5.128040287153112,
      "grad_norm": 0.0527813658118248,
      "learning_rate": 9.743919425693776e-06,
      "loss": 0.1082,
      "step": 47860
    },
    {
      "epoch": 5.129111753991214,
      "grad_norm": 0.024197658523917198,
      "learning_rate": 9.741776492017573e-06,
      "loss": 0.2646,
      "step": 47870
    },
    {
      "epoch": 5.130183220829315,
      "grad_norm": 0.0006790767074562609,
      "learning_rate": 9.73963355834137e-06,
      "loss": 0.1466,
      "step": 47880
    },
    {
      "epoch": 5.1312546876674165,
      "grad_norm": 0.0005606845952570438,
      "learning_rate": 9.737490624665168e-06,
      "loss": 0.0004,
      "step": 47890
    },
    {
      "epoch": 5.132326154505518,
      "grad_norm": 0.0008124024607241154,
      "learning_rate": 9.735347690988965e-06,
      "loss": 0.4665,
      "step": 47900
    },
    {
      "epoch": 5.13339762134362,
      "grad_norm": 0.0067495922558009624,
      "learning_rate": 9.733204757312762e-06,
      "loss": 0.001,
      "step": 47910
    },
    {
      "epoch": 5.134469088181721,
      "grad_norm": 0.0011386454571038485,
      "learning_rate": 9.73106182363656e-06,
      "loss": 0.4051,
      "step": 47920
    },
    {
      "epoch": 5.135540555019822,
      "grad_norm": 0.8284512162208557,
      "learning_rate": 9.728918889960357e-06,
      "loss": 0.1329,
      "step": 47930
    },
    {
      "epoch": 5.136612021857924,
      "grad_norm": 0.0360088087618351,
      "learning_rate": 9.726775956284153e-06,
      "loss": 0.4537,
      "step": 47940
    },
    {
      "epoch": 5.137683488696025,
      "grad_norm": 0.024576928466558456,
      "learning_rate": 9.724633022607952e-06,
      "loss": 0.2336,
      "step": 47950
    },
    {
      "epoch": 5.138754955534126,
      "grad_norm": 63.57770538330078,
      "learning_rate": 9.722490088931749e-06,
      "loss": 0.3174,
      "step": 47960
    },
    {
      "epoch": 5.139826422372227,
      "grad_norm": 0.0014372648438438773,
      "learning_rate": 9.720347155255546e-06,
      "loss": 0.0018,
      "step": 47970
    },
    {
      "epoch": 5.140897889210329,
      "grad_norm": 0.0026056626811623573,
      "learning_rate": 9.718204221579342e-06,
      "loss": 0.1082,
      "step": 47980
    },
    {
      "epoch": 5.14196935604843,
      "grad_norm": 0.007486572954803705,
      "learning_rate": 9.71606128790314e-06,
      "loss": 0.0698,
      "step": 47990
    },
    {
      "epoch": 5.143040822886531,
      "grad_norm": 0.027401048690080643,
      "learning_rate": 9.713918354226939e-06,
      "loss": 0.0589,
      "step": 48000
    },
    {
      "epoch": 5.144112289724633,
      "grad_norm": 0.05064328387379646,
      "learning_rate": 9.711775420550736e-06,
      "loss": 0.1593,
      "step": 48010
    },
    {
      "epoch": 5.1451837565627345,
      "grad_norm": 0.00557604618370533,
      "learning_rate": 9.709632486874532e-06,
      "loss": 0.0005,
      "step": 48020
    },
    {
      "epoch": 5.146255223400836,
      "grad_norm": 0.00912737101316452,
      "learning_rate": 9.707489553198329e-06,
      "loss": 0.2294,
      "step": 48030
    },
    {
      "epoch": 5.147326690238937,
      "grad_norm": 16.731285095214844,
      "learning_rate": 9.705346619522126e-06,
      "loss": 0.3875,
      "step": 48040
    },
    {
      "epoch": 5.148398157077039,
      "grad_norm": 0.001893255626782775,
      "learning_rate": 9.703203685845924e-06,
      "loss": 0.0561,
      "step": 48050
    },
    {
      "epoch": 5.14946962391514,
      "grad_norm": 0.34349027276039124,
      "learning_rate": 9.701060752169721e-06,
      "loss": 0.0058,
      "step": 48060
    },
    {
      "epoch": 5.150541090753241,
      "grad_norm": 0.0017162068979814649,
      "learning_rate": 9.698917818493518e-06,
      "loss": 0.1486,
      "step": 48070
    },
    {
      "epoch": 5.151612557591343,
      "grad_norm": 0.13497433066368103,
      "learning_rate": 9.696774884817316e-06,
      "loss": 0.0099,
      "step": 48080
    },
    {
      "epoch": 5.152684024429444,
      "grad_norm": 0.0010460357880219817,
      "learning_rate": 9.694631951141113e-06,
      "loss": 0.0731,
      "step": 48090
    },
    {
      "epoch": 5.153755491267545,
      "grad_norm": 0.0032115629874169827,
      "learning_rate": 9.69248901746491e-06,
      "loss": 0.0003,
      "step": 48100
    },
    {
      "epoch": 5.154826958105646,
      "grad_norm": 0.0010051392018795013,
      "learning_rate": 9.690346083788708e-06,
      "loss": 0.4133,
      "step": 48110
    },
    {
      "epoch": 5.155898424943748,
      "grad_norm": 0.011694272048771381,
      "learning_rate": 9.688203150112505e-06,
      "loss": 0.2671,
      "step": 48120
    },
    {
      "epoch": 5.156969891781849,
      "grad_norm": 0.038570377975702286,
      "learning_rate": 9.6860602164363e-06,
      "loss": 0.0003,
      "step": 48130
    },
    {
      "epoch": 5.1580413586199505,
      "grad_norm": 0.2200702726840973,
      "learning_rate": 9.6839172827601e-06,
      "loss": 0.0049,
      "step": 48140
    },
    {
      "epoch": 5.1591128254580525,
      "grad_norm": 0.0008745471714064479,
      "learning_rate": 9.681774349083897e-06,
      "loss": 0.001,
      "step": 48150
    },
    {
      "epoch": 5.160184292296154,
      "grad_norm": 0.028050055727362633,
      "learning_rate": 9.679631415407694e-06,
      "loss": 0.6248,
      "step": 48160
    },
    {
      "epoch": 5.161255759134255,
      "grad_norm": 0.029438838362693787,
      "learning_rate": 9.67748848173149e-06,
      "loss": 0.2545,
      "step": 48170
    },
    {
      "epoch": 5.162327225972356,
      "grad_norm": 0.04533141106367111,
      "learning_rate": 9.675345548055288e-06,
      "loss": 0.1412,
      "step": 48180
    },
    {
      "epoch": 5.163398692810458,
      "grad_norm": 0.027807116508483887,
      "learning_rate": 9.673202614379087e-06,
      "loss": 0.0024,
      "step": 48190
    },
    {
      "epoch": 5.164470159648559,
      "grad_norm": 0.0010899727931246161,
      "learning_rate": 9.671059680702884e-06,
      "loss": 0.0005,
      "step": 48200
    },
    {
      "epoch": 5.16554162648666,
      "grad_norm": 0.0010635843500494957,
      "learning_rate": 9.66891674702668e-06,
      "loss": 0.0003,
      "step": 48210
    },
    {
      "epoch": 5.166613093324761,
      "grad_norm": 0.08718786388635635,
      "learning_rate": 9.666773813350477e-06,
      "loss": 0.174,
      "step": 48220
    },
    {
      "epoch": 5.167684560162863,
      "grad_norm": 17.565767288208008,
      "learning_rate": 9.664630879674274e-06,
      "loss": 0.2141,
      "step": 48230
    },
    {
      "epoch": 5.168756027000964,
      "grad_norm": 0.0005997862317599356,
      "learning_rate": 9.662487945998072e-06,
      "loss": 0.0008,
      "step": 48240
    },
    {
      "epoch": 5.169827493839065,
      "grad_norm": 0.06333528459072113,
      "learning_rate": 9.660345012321869e-06,
      "loss": 0.0337,
      "step": 48250
    },
    {
      "epoch": 5.170898960677167,
      "grad_norm": 22.660390853881836,
      "learning_rate": 9.658202078645666e-06,
      "loss": 0.238,
      "step": 48260
    },
    {
      "epoch": 5.1719704275152685,
      "grad_norm": 0.000791088561527431,
      "learning_rate": 9.656059144969464e-06,
      "loss": 0.0012,
      "step": 48270
    },
    {
      "epoch": 5.17304189435337,
      "grad_norm": 0.010716012679040432,
      "learning_rate": 9.653916211293261e-06,
      "loss": 0.0917,
      "step": 48280
    },
    {
      "epoch": 5.174113361191471,
      "grad_norm": 0.02126937545835972,
      "learning_rate": 9.651773277617058e-06,
      "loss": 0.1048,
      "step": 48290
    },
    {
      "epoch": 5.175184828029573,
      "grad_norm": 0.5558925271034241,
      "learning_rate": 9.649630343940856e-06,
      "loss": 0.0757,
      "step": 48300
    },
    {
      "epoch": 5.176256294867674,
      "grad_norm": 15.262272834777832,
      "learning_rate": 9.647487410264653e-06,
      "loss": 0.3462,
      "step": 48310
    },
    {
      "epoch": 5.177327761705775,
      "grad_norm": 0.38874882459640503,
      "learning_rate": 9.64534447658845e-06,
      "loss": 0.2548,
      "step": 48320
    },
    {
      "epoch": 5.178399228543877,
      "grad_norm": 22.908859252929688,
      "learning_rate": 9.643201542912248e-06,
      "loss": 0.1836,
      "step": 48330
    },
    {
      "epoch": 5.179470695381978,
      "grad_norm": 0.0021852338686585426,
      "learning_rate": 9.641058609236045e-06,
      "loss": 0.1055,
      "step": 48340
    },
    {
      "epoch": 5.180542162220079,
      "grad_norm": 0.060573793947696686,
      "learning_rate": 9.638915675559843e-06,
      "loss": 0.3406,
      "step": 48350
    },
    {
      "epoch": 5.18161362905818,
      "grad_norm": 0.19135169684886932,
      "learning_rate": 9.63677274188364e-06,
      "loss": 0.0675,
      "step": 48360
    },
    {
      "epoch": 5.182685095896282,
      "grad_norm": 0.03669014573097229,
      "learning_rate": 9.634629808207436e-06,
      "loss": 0.0013,
      "step": 48370
    },
    {
      "epoch": 5.183756562734383,
      "grad_norm": 0.060019172728061676,
      "learning_rate": 9.632486874531235e-06,
      "loss": 0.2834,
      "step": 48380
    },
    {
      "epoch": 5.1848280295724845,
      "grad_norm": 0.0013272673822939396,
      "learning_rate": 9.630343940855032e-06,
      "loss": 0.2258,
      "step": 48390
    },
    {
      "epoch": 5.1858994964105865,
      "grad_norm": 0.022769097238779068,
      "learning_rate": 9.62820100717883e-06,
      "loss": 0.2448,
      "step": 48400
    },
    {
      "epoch": 5.186970963248688,
      "grad_norm": 0.002096387557685375,
      "learning_rate": 9.626058073502625e-06,
      "loss": 0.0431,
      "step": 48410
    },
    {
      "epoch": 5.188042430086789,
      "grad_norm": 0.0019143272656947374,
      "learning_rate": 9.623915139826422e-06,
      "loss": 0.0013,
      "step": 48420
    },
    {
      "epoch": 5.18911389692489,
      "grad_norm": 0.005193106364458799,
      "learning_rate": 9.62177220615022e-06,
      "loss": 0.001,
      "step": 48430
    },
    {
      "epoch": 5.190185363762992,
      "grad_norm": 0.0011026388965547085,
      "learning_rate": 9.619629272474019e-06,
      "loss": 0.0226,
      "step": 48440
    },
    {
      "epoch": 5.191256830601093,
      "grad_norm": 0.02426084503531456,
      "learning_rate": 9.617486338797814e-06,
      "loss": 0.1806,
      "step": 48450
    },
    {
      "epoch": 5.192328297439194,
      "grad_norm": 0.003692848375067115,
      "learning_rate": 9.615343405121612e-06,
      "loss": 0.393,
      "step": 48460
    },
    {
      "epoch": 5.193399764277296,
      "grad_norm": 0.0782606303691864,
      "learning_rate": 9.613200471445409e-06,
      "loss": 0.2188,
      "step": 48470
    },
    {
      "epoch": 5.194471231115397,
      "grad_norm": 0.0017765727825462818,
      "learning_rate": 9.611057537769206e-06,
      "loss": 0.0004,
      "step": 48480
    },
    {
      "epoch": 5.195542697953498,
      "grad_norm": 0.0010630626929923892,
      "learning_rate": 9.608914604093004e-06,
      "loss": 0.0007,
      "step": 48490
    },
    {
      "epoch": 5.196614164791599,
      "grad_norm": 329.8841552734375,
      "learning_rate": 9.606771670416801e-06,
      "loss": 0.2229,
      "step": 48500
    },
    {
      "epoch": 5.197685631629701,
      "grad_norm": 0.019457003101706505,
      "learning_rate": 9.604628736740599e-06,
      "loss": 0.2446,
      "step": 48510
    },
    {
      "epoch": 5.198757098467802,
      "grad_norm": 42.54130172729492,
      "learning_rate": 9.602485803064396e-06,
      "loss": 0.4789,
      "step": 48520
    },
    {
      "epoch": 5.1998285653059035,
      "grad_norm": 0.010102273896336555,
      "learning_rate": 9.600342869388193e-06,
      "loss": 0.6263,
      "step": 48530
    },
    {
      "epoch": 5.2009000321440055,
      "grad_norm": 0.0715559720993042,
      "learning_rate": 9.59819993571199e-06,
      "loss": 0.3329,
      "step": 48540
    },
    {
      "epoch": 5.201971498982107,
      "grad_norm": 0.011629976332187653,
      "learning_rate": 9.596057002035788e-06,
      "loss": 0.2293,
      "step": 48550
    },
    {
      "epoch": 5.203042965820208,
      "grad_norm": 0.09041203558444977,
      "learning_rate": 9.593914068359585e-06,
      "loss": 0.0431,
      "step": 48560
    },
    {
      "epoch": 5.204114432658309,
      "grad_norm": 0.36555108428001404,
      "learning_rate": 9.591771134683383e-06,
      "loss": 0.0083,
      "step": 48570
    },
    {
      "epoch": 5.205185899496411,
      "grad_norm": 0.06934517621994019,
      "learning_rate": 9.58962820100718e-06,
      "loss": 0.3747,
      "step": 48580
    },
    {
      "epoch": 5.206257366334512,
      "grad_norm": 0.032663315534591675,
      "learning_rate": 9.587485267330977e-06,
      "loss": 0.0015,
      "step": 48590
    },
    {
      "epoch": 5.207328833172613,
      "grad_norm": 0.01240536943078041,
      "learning_rate": 9.585342333654775e-06,
      "loss": 0.0028,
      "step": 48600
    },
    {
      "epoch": 5.208400300010715,
      "grad_norm": 0.061909064650535583,
      "learning_rate": 9.58319939997857e-06,
      "loss": 0.0013,
      "step": 48610
    },
    {
      "epoch": 5.209471766848816,
      "grad_norm": 0.08020564168691635,
      "learning_rate": 9.581056466302368e-06,
      "loss": 0.0015,
      "step": 48620
    },
    {
      "epoch": 5.210543233686917,
      "grad_norm": 0.0022191230673342943,
      "learning_rate": 9.578913532626167e-06,
      "loss": 0.5079,
      "step": 48630
    },
    {
      "epoch": 5.211614700525018,
      "grad_norm": 0.0780198946595192,
      "learning_rate": 9.576770598949964e-06,
      "loss": 0.0125,
      "step": 48640
    },
    {
      "epoch": 5.21268616736312,
      "grad_norm": 0.13554440438747406,
      "learning_rate": 9.57462766527376e-06,
      "loss": 0.0496,
      "step": 48650
    },
    {
      "epoch": 5.2137576342012215,
      "grad_norm": 0.0014853999018669128,
      "learning_rate": 9.572484731597557e-06,
      "loss": 0.001,
      "step": 48660
    },
    {
      "epoch": 5.214829101039323,
      "grad_norm": 0.25739726424217224,
      "learning_rate": 9.570341797921355e-06,
      "loss": 0.4907,
      "step": 48670
    },
    {
      "epoch": 5.215900567877425,
      "grad_norm": 16.02358627319336,
      "learning_rate": 9.568198864245154e-06,
      "loss": 0.2222,
      "step": 48680
    },
    {
      "epoch": 5.216972034715526,
      "grad_norm": 0.009517744183540344,
      "learning_rate": 9.56605593056895e-06,
      "loss": 0.0007,
      "step": 48690
    },
    {
      "epoch": 5.218043501553627,
      "grad_norm": 3.296107769012451,
      "learning_rate": 9.563912996892747e-06,
      "loss": 0.2565,
      "step": 48700
    },
    {
      "epoch": 5.219114968391728,
      "grad_norm": 0.010406089015305042,
      "learning_rate": 9.561770063216544e-06,
      "loss": 0.002,
      "step": 48710
    },
    {
      "epoch": 5.22018643522983,
      "grad_norm": 0.03826020658016205,
      "learning_rate": 9.559627129540341e-06,
      "loss": 0.001,
      "step": 48720
    },
    {
      "epoch": 5.221257902067931,
      "grad_norm": 0.013103428296744823,
      "learning_rate": 9.557484195864139e-06,
      "loss": 0.0008,
      "step": 48730
    },
    {
      "epoch": 5.222329368906032,
      "grad_norm": 0.044748470187187195,
      "learning_rate": 9.555341262187936e-06,
      "loss": 0.1616,
      "step": 48740
    },
    {
      "epoch": 5.223400835744133,
      "grad_norm": 0.051971543580293655,
      "learning_rate": 9.553198328511733e-06,
      "loss": 0.0005,
      "step": 48750
    },
    {
      "epoch": 5.224472302582235,
      "grad_norm": 0.003043125383555889,
      "learning_rate": 9.55105539483553e-06,
      "loss": 0.0953,
      "step": 48760
    },
    {
      "epoch": 5.225543769420336,
      "grad_norm": 0.001721735461615026,
      "learning_rate": 9.548912461159328e-06,
      "loss": 0.1813,
      "step": 48770
    },
    {
      "epoch": 5.2266152362584375,
      "grad_norm": 0.02951129898428917,
      "learning_rate": 9.546769527483125e-06,
      "loss": 0.002,
      "step": 48780
    },
    {
      "epoch": 5.2276867030965395,
      "grad_norm": 0.0034997223410755396,
      "learning_rate": 9.544626593806923e-06,
      "loss": 0.1674,
      "step": 48790
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 0.08075764775276184,
      "learning_rate": 9.54248366013072e-06,
      "loss": 0.1875,
      "step": 48800
    },
    {
      "epoch": 5.229829636772742,
      "grad_norm": 0.19267137348651886,
      "learning_rate": 9.540340726454518e-06,
      "loss": 0.6029,
      "step": 48810
    },
    {
      "epoch": 5.230901103610843,
      "grad_norm": 0.07486104220151901,
      "learning_rate": 9.538197792778315e-06,
      "loss": 0.285,
      "step": 48820
    },
    {
      "epoch": 5.231972570448945,
      "grad_norm": 0.00889169704169035,
      "learning_rate": 9.536054859102112e-06,
      "loss": 0.0013,
      "step": 48830
    },
    {
      "epoch": 5.233044037287046,
      "grad_norm": 0.0340069979429245,
      "learning_rate": 9.53391192542591e-06,
      "loss": 0.0013,
      "step": 48840
    },
    {
      "epoch": 5.234115504125147,
      "grad_norm": 30.709457397460938,
      "learning_rate": 9.531768991749705e-06,
      "loss": 0.5089,
      "step": 48850
    },
    {
      "epoch": 5.235186970963249,
      "grad_norm": 1.2319270372390747,
      "learning_rate": 9.529626058073503e-06,
      "loss": 0.1935,
      "step": 48860
    },
    {
      "epoch": 5.23625843780135,
      "grad_norm": 0.023870743811130524,
      "learning_rate": 9.527483124397302e-06,
      "loss": 0.078,
      "step": 48870
    },
    {
      "epoch": 5.237329904639451,
      "grad_norm": 0.16200824081897736,
      "learning_rate": 9.525340190721099e-06,
      "loss": 0.2425,
      "step": 48880
    },
    {
      "epoch": 5.238401371477552,
      "grad_norm": 0.026318974792957306,
      "learning_rate": 9.523197257044895e-06,
      "loss": 0.0007,
      "step": 48890
    },
    {
      "epoch": 5.239472838315654,
      "grad_norm": 20.406343460083008,
      "learning_rate": 9.521054323368692e-06,
      "loss": 0.2191,
      "step": 48900
    },
    {
      "epoch": 5.2405443051537555,
      "grad_norm": 0.030622361227869987,
      "learning_rate": 9.51891138969249e-06,
      "loss": 0.2128,
      "step": 48910
    },
    {
      "epoch": 5.241615771991857,
      "grad_norm": 0.030150843784213066,
      "learning_rate": 9.516768456016288e-06,
      "loss": 0.1477,
      "step": 48920
    },
    {
      "epoch": 5.242687238829959,
      "grad_norm": 0.02307070419192314,
      "learning_rate": 9.514625522340084e-06,
      "loss": 0.1666,
      "step": 48930
    },
    {
      "epoch": 5.24375870566806,
      "grad_norm": 0.05051398277282715,
      "learning_rate": 9.512482588663881e-06,
      "loss": 0.162,
      "step": 48940
    },
    {
      "epoch": 5.244830172506161,
      "grad_norm": 0.06618869304656982,
      "learning_rate": 9.510339654987679e-06,
      "loss": 0.2052,
      "step": 48950
    },
    {
      "epoch": 5.245901639344262,
      "grad_norm": 0.00975651852786541,
      "learning_rate": 9.508196721311476e-06,
      "loss": 0.0026,
      "step": 48960
    },
    {
      "epoch": 5.246973106182364,
      "grad_norm": 0.17975373566150665,
      "learning_rate": 9.506053787635274e-06,
      "loss": 0.4282,
      "step": 48970
    },
    {
      "epoch": 5.248044573020465,
      "grad_norm": 0.029085364192724228,
      "learning_rate": 9.503910853959071e-06,
      "loss": 0.0033,
      "step": 48980
    },
    {
      "epoch": 5.249116039858566,
      "grad_norm": 0.0328473299741745,
      "learning_rate": 9.501767920282868e-06,
      "loss": 0.1409,
      "step": 48990
    },
    {
      "epoch": 5.250187506696668,
      "grad_norm": 9.979774475097656,
      "learning_rate": 9.499624986606666e-06,
      "loss": 0.0035,
      "step": 49000
    },
    {
      "epoch": 5.251258973534769,
      "grad_norm": 0.026097001507878304,
      "learning_rate": 9.497482052930463e-06,
      "loss": 0.0772,
      "step": 49010
    },
    {
      "epoch": 5.25233044037287,
      "grad_norm": 0.009754370898008347,
      "learning_rate": 9.49533911925426e-06,
      "loss": 0.0054,
      "step": 49020
    },
    {
      "epoch": 5.2534019072109714,
      "grad_norm": 0.002759945346042514,
      "learning_rate": 9.493196185578058e-06,
      "loss": 0.2024,
      "step": 49030
    },
    {
      "epoch": 5.254473374049073,
      "grad_norm": 0.27646246552467346,
      "learning_rate": 9.491053251901853e-06,
      "loss": 0.0026,
      "step": 49040
    },
    {
      "epoch": 5.2555448408871746,
      "grad_norm": 0.49707379937171936,
      "learning_rate": 9.48891031822565e-06,
      "loss": 0.0024,
      "step": 49050
    },
    {
      "epoch": 5.256616307725276,
      "grad_norm": 17.03078269958496,
      "learning_rate": 9.48676738454945e-06,
      "loss": 0.4857,
      "step": 49060
    },
    {
      "epoch": 5.257687774563378,
      "grad_norm": 16.823287963867188,
      "learning_rate": 9.484624450873247e-06,
      "loss": 0.2691,
      "step": 49070
    },
    {
      "epoch": 5.258759241401479,
      "grad_norm": 0.005036541726440191,
      "learning_rate": 9.482481517197043e-06,
      "loss": 0.0003,
      "step": 49080
    },
    {
      "epoch": 5.25983070823958,
      "grad_norm": 0.03670794516801834,
      "learning_rate": 9.48033858352084e-06,
      "loss": 0.1524,
      "step": 49090
    },
    {
      "epoch": 5.260902175077681,
      "grad_norm": 0.015956338495016098,
      "learning_rate": 9.478195649844637e-06,
      "loss": 0.0019,
      "step": 49100
    },
    {
      "epoch": 5.261973641915783,
      "grad_norm": 0.18055418133735657,
      "learning_rate": 9.476052716168437e-06,
      "loss": 0.1768,
      "step": 49110
    },
    {
      "epoch": 5.263045108753884,
      "grad_norm": 0.0261620432138443,
      "learning_rate": 9.473909782492232e-06,
      "loss": 0.0043,
      "step": 49120
    },
    {
      "epoch": 5.264116575591985,
      "grad_norm": 0.0026907389983534813,
      "learning_rate": 9.47176684881603e-06,
      "loss": 0.2237,
      "step": 49130
    },
    {
      "epoch": 5.265188042430087,
      "grad_norm": 0.038592878729104996,
      "learning_rate": 9.469623915139827e-06,
      "loss": 0.0002,
      "step": 49140
    },
    {
      "epoch": 5.266259509268188,
      "grad_norm": 0.04520125314593315,
      "learning_rate": 9.467480981463624e-06,
      "loss": 0.5327,
      "step": 49150
    },
    {
      "epoch": 5.267330976106289,
      "grad_norm": 0.021388711407780647,
      "learning_rate": 9.465338047787422e-06,
      "loss": 0.0003,
      "step": 49160
    },
    {
      "epoch": 5.2684024429443905,
      "grad_norm": 0.003719173138961196,
      "learning_rate": 9.463195114111219e-06,
      "loss": 0.1423,
      "step": 49170
    },
    {
      "epoch": 5.2694739097824925,
      "grad_norm": 0.10062611103057861,
      "learning_rate": 9.461052180435016e-06,
      "loss": 0.0006,
      "step": 49180
    },
    {
      "epoch": 5.270545376620594,
      "grad_norm": 247.17605590820312,
      "learning_rate": 9.458909246758814e-06,
      "loss": 0.4165,
      "step": 49190
    },
    {
      "epoch": 5.271616843458695,
      "grad_norm": 0.016103679314255714,
      "learning_rate": 9.456766313082611e-06,
      "loss": 0.1547,
      "step": 49200
    },
    {
      "epoch": 5.272688310296797,
      "grad_norm": 0.009154299274086952,
      "learning_rate": 9.454623379406408e-06,
      "loss": 0.0033,
      "step": 49210
    },
    {
      "epoch": 5.273759777134898,
      "grad_norm": 0.00640200125053525,
      "learning_rate": 9.452480445730206e-06,
      "loss": 0.21,
      "step": 49220
    },
    {
      "epoch": 5.274831243972999,
      "grad_norm": 30.255937576293945,
      "learning_rate": 9.450337512054003e-06,
      "loss": 0.4009,
      "step": 49230
    },
    {
      "epoch": 5.2759027108111,
      "grad_norm": 28.998559951782227,
      "learning_rate": 9.448194578377799e-06,
      "loss": 0.2309,
      "step": 49240
    },
    {
      "epoch": 5.276974177649202,
      "grad_norm": 0.04446827992796898,
      "learning_rate": 9.446051644701598e-06,
      "loss": 0.0072,
      "step": 49250
    },
    {
      "epoch": 5.278045644487303,
      "grad_norm": 0.05795668810606003,
      "learning_rate": 9.443908711025395e-06,
      "loss": 0.2202,
      "step": 49260
    },
    {
      "epoch": 5.279117111325404,
      "grad_norm": 44.245887756347656,
      "learning_rate": 9.441765777349193e-06,
      "loss": 0.1952,
      "step": 49270
    },
    {
      "epoch": 5.280188578163505,
      "grad_norm": 0.04063956066966057,
      "learning_rate": 9.439622843672988e-06,
      "loss": 0.1677,
      "step": 49280
    },
    {
      "epoch": 5.281260045001607,
      "grad_norm": 0.023460181429982185,
      "learning_rate": 9.437479909996786e-06,
      "loss": 0.1803,
      "step": 49290
    },
    {
      "epoch": 5.2823315118397085,
      "grad_norm": 0.038920409977436066,
      "learning_rate": 9.435336976320585e-06,
      "loss": 0.0056,
      "step": 49300
    },
    {
      "epoch": 5.28340297867781,
      "grad_norm": 0.0709381252527237,
      "learning_rate": 9.433194042644382e-06,
      "loss": 0.2047,
      "step": 49310
    },
    {
      "epoch": 5.284474445515912,
      "grad_norm": 0.0614166222512722,
      "learning_rate": 9.431051108968178e-06,
      "loss": 0.1666,
      "step": 49320
    },
    {
      "epoch": 5.285545912354013,
      "grad_norm": 0.04598512873053551,
      "learning_rate": 9.428908175291975e-06,
      "loss": 0.007,
      "step": 49330
    },
    {
      "epoch": 5.286617379192114,
      "grad_norm": 0.004702882841229439,
      "learning_rate": 9.426765241615772e-06,
      "loss": 0.4764,
      "step": 49340
    },
    {
      "epoch": 5.287688846030216,
      "grad_norm": 0.00150941067840904,
      "learning_rate": 9.42462230793957e-06,
      "loss": 0.0033,
      "step": 49350
    },
    {
      "epoch": 5.288760312868317,
      "grad_norm": 28.424747467041016,
      "learning_rate": 9.422479374263367e-06,
      "loss": 0.1347,
      "step": 49360
    },
    {
      "epoch": 5.289831779706418,
      "grad_norm": 0.17976191639900208,
      "learning_rate": 9.420336440587164e-06,
      "loss": 0.3942,
      "step": 49370
    },
    {
      "epoch": 5.290903246544519,
      "grad_norm": 0.12964294850826263,
      "learning_rate": 9.418193506910962e-06,
      "loss": 0.2358,
      "step": 49380
    },
    {
      "epoch": 5.291974713382621,
      "grad_norm": 0.40346309542655945,
      "learning_rate": 9.416050573234759e-06,
      "loss": 0.0259,
      "step": 49390
    },
    {
      "epoch": 5.293046180220722,
      "grad_norm": 0.17237131297588348,
      "learning_rate": 9.413907639558556e-06,
      "loss": 0.3594,
      "step": 49400
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 0.00441100774332881,
      "learning_rate": 9.411764705882354e-06,
      "loss": 0.0012,
      "step": 49410
    },
    {
      "epoch": 5.2951891138969245,
      "grad_norm": 0.06446532160043716,
      "learning_rate": 9.409621772206151e-06,
      "loss": 0.1862,
      "step": 49420
    },
    {
      "epoch": 5.2962605807350265,
      "grad_norm": 0.08921896666288376,
      "learning_rate": 9.407478838529949e-06,
      "loss": 0.0026,
      "step": 49430
    },
    {
      "epoch": 5.297332047573128,
      "grad_norm": 0.08848513662815094,
      "learning_rate": 9.405335904853746e-06,
      "loss": 0.251,
      "step": 49440
    },
    {
      "epoch": 5.298403514411229,
      "grad_norm": 0.04966544732451439,
      "learning_rate": 9.403192971177543e-06,
      "loss": 0.1882,
      "step": 49450
    },
    {
      "epoch": 5.299474981249331,
      "grad_norm": 0.007914500311017036,
      "learning_rate": 9.40105003750134e-06,
      "loss": 0.1105,
      "step": 49460
    },
    {
      "epoch": 5.300546448087432,
      "grad_norm": 0.5111660361289978,
      "learning_rate": 9.398907103825138e-06,
      "loss": 0.2966,
      "step": 49470
    },
    {
      "epoch": 5.301617914925533,
      "grad_norm": 0.099136121571064,
      "learning_rate": 9.396764170148934e-06,
      "loss": 0.0057,
      "step": 49480
    },
    {
      "epoch": 5.302689381763634,
      "grad_norm": 2.801140308380127,
      "learning_rate": 9.394621236472733e-06,
      "loss": 0.1625,
      "step": 49490
    },
    {
      "epoch": 5.303760848601736,
      "grad_norm": 0.006489281076937914,
      "learning_rate": 9.39247830279653e-06,
      "loss": 0.0008,
      "step": 49500
    },
    {
      "epoch": 5.304832315439837,
      "grad_norm": 19.570629119873047,
      "learning_rate": 9.390335369120327e-06,
      "loss": 0.1914,
      "step": 49510
    },
    {
      "epoch": 5.305903782277938,
      "grad_norm": 0.12196500599384308,
      "learning_rate": 9.388192435444123e-06,
      "loss": 0.2295,
      "step": 49520
    },
    {
      "epoch": 5.30697524911604,
      "grad_norm": 0.054128050804138184,
      "learning_rate": 9.38604950176792e-06,
      "loss": 0.0014,
      "step": 49530
    },
    {
      "epoch": 5.308046715954141,
      "grad_norm": 0.015521455556154251,
      "learning_rate": 9.383906568091718e-06,
      "loss": 0.0436,
      "step": 49540
    },
    {
      "epoch": 5.3091181827922425,
      "grad_norm": 0.3339482247829437,
      "learning_rate": 9.381763634415517e-06,
      "loss": 0.0027,
      "step": 49550
    },
    {
      "epoch": 5.310189649630344,
      "grad_norm": 0.03896864131093025,
      "learning_rate": 9.379620700739312e-06,
      "loss": 0.2407,
      "step": 49560
    },
    {
      "epoch": 5.311261116468446,
      "grad_norm": 0.005090050399303436,
      "learning_rate": 9.37747776706311e-06,
      "loss": 0.189,
      "step": 49570
    },
    {
      "epoch": 5.312332583306547,
      "grad_norm": 0.0034031106624752283,
      "learning_rate": 9.375334833386907e-06,
      "loss": 0.2614,
      "step": 49580
    },
    {
      "epoch": 5.313404050144648,
      "grad_norm": 0.2503882050514221,
      "learning_rate": 9.373191899710705e-06,
      "loss": 0.2267,
      "step": 49590
    },
    {
      "epoch": 5.31447551698275,
      "grad_norm": 19.927820205688477,
      "learning_rate": 9.371048966034502e-06,
      "loss": 0.1813,
      "step": 49600
    },
    {
      "epoch": 5.315546983820851,
      "grad_norm": 0.0024404232390224934,
      "learning_rate": 9.3689060323583e-06,
      "loss": 0.4014,
      "step": 49610
    },
    {
      "epoch": 5.316618450658952,
      "grad_norm": 0.2993856966495514,
      "learning_rate": 9.366763098682097e-06,
      "loss": 0.0009,
      "step": 49620
    },
    {
      "epoch": 5.317689917497053,
      "grad_norm": 0.07439035922288895,
      "learning_rate": 9.364620165005894e-06,
      "loss": 0.0009,
      "step": 49630
    },
    {
      "epoch": 5.318761384335155,
      "grad_norm": 0.0030402650590986013,
      "learning_rate": 9.362477231329691e-06,
      "loss": 0.0009,
      "step": 49640
    },
    {
      "epoch": 5.319832851173256,
      "grad_norm": 147.10653686523438,
      "learning_rate": 9.360334297653489e-06,
      "loss": 0.0998,
      "step": 49650
    },
    {
      "epoch": 5.320904318011357,
      "grad_norm": 0.003446598770096898,
      "learning_rate": 9.358191363977286e-06,
      "loss": 0.0198,
      "step": 49660
    },
    {
      "epoch": 5.321975784849459,
      "grad_norm": 0.9887564778327942,
      "learning_rate": 9.356048430301083e-06,
      "loss": 0.2122,
      "step": 49670
    },
    {
      "epoch": 5.32304725168756,
      "grad_norm": 0.05591314285993576,
      "learning_rate": 9.35390549662488e-06,
      "loss": 0.1466,
      "step": 49680
    },
    {
      "epoch": 5.3241187185256615,
      "grad_norm": 16.648536682128906,
      "learning_rate": 9.351762562948678e-06,
      "loss": 0.1646,
      "step": 49690
    },
    {
      "epoch": 5.325190185363763,
      "grad_norm": 0.3016600012779236,
      "learning_rate": 9.349619629272475e-06,
      "loss": 0.2124,
      "step": 49700
    },
    {
      "epoch": 5.326261652201865,
      "grad_norm": 0.29718708992004395,
      "learning_rate": 9.347476695596273e-06,
      "loss": 0.0013,
      "step": 49710
    },
    {
      "epoch": 5.327333119039966,
      "grad_norm": 0.003122679889202118,
      "learning_rate": 9.345333761920068e-06,
      "loss": 0.0002,
      "step": 49720
    },
    {
      "epoch": 5.328404585878067,
      "grad_norm": 0.0009307842119596899,
      "learning_rate": 9.343190828243866e-06,
      "loss": 0.3116,
      "step": 49730
    },
    {
      "epoch": 5.329476052716169,
      "grad_norm": 0.04065372422337532,
      "learning_rate": 9.341047894567665e-06,
      "loss": 0.1798,
      "step": 49740
    },
    {
      "epoch": 5.33054751955427,
      "grad_norm": 0.14567528665065765,
      "learning_rate": 9.338904960891462e-06,
      "loss": 0.1289,
      "step": 49750
    },
    {
      "epoch": 5.331618986392371,
      "grad_norm": 0.0018042393494397402,
      "learning_rate": 9.336762027215258e-06,
      "loss": 0.0004,
      "step": 49760
    },
    {
      "epoch": 5.332690453230472,
      "grad_norm": 0.0009178086766041815,
      "learning_rate": 9.334619093539055e-06,
      "loss": 0.0004,
      "step": 49770
    },
    {
      "epoch": 5.333761920068574,
      "grad_norm": 20.617446899414062,
      "learning_rate": 9.332476159862853e-06,
      "loss": 0.634,
      "step": 49780
    },
    {
      "epoch": 5.334833386906675,
      "grad_norm": 0.009677856229245663,
      "learning_rate": 9.330333226186652e-06,
      "loss": 0.0007,
      "step": 49790
    },
    {
      "epoch": 5.335904853744776,
      "grad_norm": 0.04285584017634392,
      "learning_rate": 9.328190292510447e-06,
      "loss": 0.1154,
      "step": 49800
    },
    {
      "epoch": 5.3369763205828775,
      "grad_norm": 0.011484271846711636,
      "learning_rate": 9.326047358834245e-06,
      "loss": 0.6032,
      "step": 49810
    },
    {
      "epoch": 5.3380477874209795,
      "grad_norm": 21.285917282104492,
      "learning_rate": 9.323904425158042e-06,
      "loss": 0.1606,
      "step": 49820
    },
    {
      "epoch": 5.339119254259081,
      "grad_norm": 0.08339931815862656,
      "learning_rate": 9.32176149148184e-06,
      "loss": 0.0004,
      "step": 49830
    },
    {
      "epoch": 5.340190721097182,
      "grad_norm": 0.009043509140610695,
      "learning_rate": 9.319618557805637e-06,
      "loss": 0.0028,
      "step": 49840
    },
    {
      "epoch": 5.341262187935284,
      "grad_norm": 177.19212341308594,
      "learning_rate": 9.317475624129434e-06,
      "loss": 0.366,
      "step": 49850
    },
    {
      "epoch": 5.342333654773385,
      "grad_norm": 28.387035369873047,
      "learning_rate": 9.315332690453231e-06,
      "loss": 0.0531,
      "step": 49860
    },
    {
      "epoch": 5.343405121611486,
      "grad_norm": 0.04894355311989784,
      "learning_rate": 9.313189756777029e-06,
      "loss": 0.0017,
      "step": 49870
    },
    {
      "epoch": 5.344476588449588,
      "grad_norm": 0.023173794150352478,
      "learning_rate": 9.311046823100826e-06,
      "loss": 0.1327,
      "step": 49880
    },
    {
      "epoch": 5.345548055287689,
      "grad_norm": 0.03445884957909584,
      "learning_rate": 9.308903889424624e-06,
      "loss": 0.0003,
      "step": 49890
    },
    {
      "epoch": 5.34661952212579,
      "grad_norm": 0.020804718136787415,
      "learning_rate": 9.306760955748421e-06,
      "loss": 0.184,
      "step": 49900
    },
    {
      "epoch": 5.347690988963891,
      "grad_norm": 0.0008298508473671973,
      "learning_rate": 9.304618022072217e-06,
      "loss": 0.0006,
      "step": 49910
    },
    {
      "epoch": 5.348762455801993,
      "grad_norm": 0.0014754432486370206,
      "learning_rate": 9.302475088396014e-06,
      "loss": 0.0002,
      "step": 49920
    },
    {
      "epoch": 5.349833922640094,
      "grad_norm": 0.03446493670344353,
      "learning_rate": 9.300332154719813e-06,
      "loss": 0.0004,
      "step": 49930
    },
    {
      "epoch": 5.3509053894781955,
      "grad_norm": 0.03292527794837952,
      "learning_rate": 9.29818922104361e-06,
      "loss": 0.5143,
      "step": 49940
    },
    {
      "epoch": 5.351976856316297,
      "grad_norm": 0.001704976661130786,
      "learning_rate": 9.296046287367406e-06,
      "loss": 0.1632,
      "step": 49950
    },
    {
      "epoch": 5.353048323154399,
      "grad_norm": 63.158329010009766,
      "learning_rate": 9.293903353691203e-06,
      "loss": 0.375,
      "step": 49960
    },
    {
      "epoch": 5.3541197899925,
      "grad_norm": 0.03767632693052292,
      "learning_rate": 9.291760420015e-06,
      "loss": 0.0006,
      "step": 49970
    },
    {
      "epoch": 5.355191256830601,
      "grad_norm": 0.1320873647928238,
      "learning_rate": 9.2896174863388e-06,
      "loss": 0.212,
      "step": 49980
    },
    {
      "epoch": 5.356262723668703,
      "grad_norm": 43.248348236083984,
      "learning_rate": 9.287474552662595e-06,
      "loss": 0.0243,
      "step": 49990
    },
    {
      "epoch": 5.357334190506804,
      "grad_norm": 19.79798698425293,
      "learning_rate": 9.285331618986393e-06,
      "loss": 0.0875,
      "step": 50000
    },
    {
      "epoch": 5.358405657344905,
      "grad_norm": 0.0031043109484016895,
      "learning_rate": 9.28318868531019e-06,
      "loss": 0.1418,
      "step": 50010
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 0.000754806911572814,
      "learning_rate": 9.281045751633987e-06,
      "loss": 0.0003,
      "step": 50020
    },
    {
      "epoch": 5.360548591021108,
      "grad_norm": 0.04356374219059944,
      "learning_rate": 9.278902817957785e-06,
      "loss": 0.0004,
      "step": 50030
    },
    {
      "epoch": 5.361620057859209,
      "grad_norm": 0.01715964265167713,
      "learning_rate": 9.276759884281582e-06,
      "loss": 0.166,
      "step": 50040
    },
    {
      "epoch": 5.36269152469731,
      "grad_norm": 0.11858650296926498,
      "learning_rate": 9.27461695060538e-06,
      "loss": 0.0994,
      "step": 50050
    },
    {
      "epoch": 5.363762991535412,
      "grad_norm": 0.0018245059764012694,
      "learning_rate": 9.272474016929177e-06,
      "loss": 0.1951,
      "step": 50060
    },
    {
      "epoch": 5.3648344583735135,
      "grad_norm": 0.004734009969979525,
      "learning_rate": 9.270331083252974e-06,
      "loss": 0.4284,
      "step": 50070
    },
    {
      "epoch": 5.365905925211615,
      "grad_norm": 0.022639811038970947,
      "learning_rate": 9.268188149576772e-06,
      "loss": 0.1256,
      "step": 50080
    },
    {
      "epoch": 5.366977392049716,
      "grad_norm": 0.02931535243988037,
      "learning_rate": 9.266045215900569e-06,
      "loss": 0.2596,
      "step": 50090
    },
    {
      "epoch": 5.368048858887818,
      "grad_norm": 48.96012878417969,
      "learning_rate": 9.263902282224366e-06,
      "loss": 0.198,
      "step": 50100
    },
    {
      "epoch": 5.369120325725919,
      "grad_norm": 0.01698697730898857,
      "learning_rate": 9.261759348548162e-06,
      "loss": 0.0003,
      "step": 50110
    },
    {
      "epoch": 5.37019179256402,
      "grad_norm": 0.04680672660470009,
      "learning_rate": 9.259616414871961e-06,
      "loss": 0.0064,
      "step": 50120
    },
    {
      "epoch": 5.371263259402122,
      "grad_norm": 0.028663404285907745,
      "learning_rate": 9.257473481195758e-06,
      "loss": 0.0008,
      "step": 50130
    },
    {
      "epoch": 5.372334726240223,
      "grad_norm": 0.06016895920038223,
      "learning_rate": 9.255330547519556e-06,
      "loss": 0.0007,
      "step": 50140
    },
    {
      "epoch": 5.373406193078324,
      "grad_norm": 0.0017480915412306786,
      "learning_rate": 9.253187613843351e-06,
      "loss": 0.0062,
      "step": 50150
    },
    {
      "epoch": 5.374477659916425,
      "grad_norm": 0.012750024907290936,
      "learning_rate": 9.251044680167149e-06,
      "loss": 0.1307,
      "step": 50160
    },
    {
      "epoch": 5.375549126754527,
      "grad_norm": 0.042475368827581406,
      "learning_rate": 9.248901746490948e-06,
      "loss": 0.0006,
      "step": 50170
    },
    {
      "epoch": 5.376620593592628,
      "grad_norm": 0.0017308342503383756,
      "learning_rate": 9.246758812814745e-06,
      "loss": 0.3188,
      "step": 50180
    },
    {
      "epoch": 5.3776920604307294,
      "grad_norm": 0.03540550917387009,
      "learning_rate": 9.24461587913854e-06,
      "loss": 0.0003,
      "step": 50190
    },
    {
      "epoch": 5.3787635272688314,
      "grad_norm": 0.040530797094106674,
      "learning_rate": 9.242472945462338e-06,
      "loss": 0.0018,
      "step": 50200
    },
    {
      "epoch": 5.3798349941069326,
      "grad_norm": 0.0013999477960169315,
      "learning_rate": 9.240330011786135e-06,
      "loss": 0.0003,
      "step": 50210
    },
    {
      "epoch": 5.380906460945034,
      "grad_norm": 0.016576675698161125,
      "learning_rate": 9.238187078109933e-06,
      "loss": 0.011,
      "step": 50220
    },
    {
      "epoch": 5.381977927783135,
      "grad_norm": 0.0010635413927957416,
      "learning_rate": 9.23604414443373e-06,
      "loss": 0.0028,
      "step": 50230
    },
    {
      "epoch": 5.383049394621237,
      "grad_norm": 0.0007397208828479052,
      "learning_rate": 9.233901210757528e-06,
      "loss": 0.0971,
      "step": 50240
    },
    {
      "epoch": 5.384120861459338,
      "grad_norm": 21.761194229125977,
      "learning_rate": 9.231758277081325e-06,
      "loss": 0.3149,
      "step": 50250
    },
    {
      "epoch": 5.385192328297439,
      "grad_norm": 0.009761542081832886,
      "learning_rate": 9.229615343405122e-06,
      "loss": 0.2343,
      "step": 50260
    },
    {
      "epoch": 5.386263795135541,
      "grad_norm": 0.004487088415771723,
      "learning_rate": 9.22747240972892e-06,
      "loss": 0.0003,
      "step": 50270
    },
    {
      "epoch": 5.387335261973642,
      "grad_norm": 38.26836395263672,
      "learning_rate": 9.225329476052717e-06,
      "loss": 0.1477,
      "step": 50280
    },
    {
      "epoch": 5.388406728811743,
      "grad_norm": 0.034699730575084686,
      "learning_rate": 9.223186542376514e-06,
      "loss": 0.0015,
      "step": 50290
    },
    {
      "epoch": 5.389478195649844,
      "grad_norm": 0.0017284919740632176,
      "learning_rate": 9.221043608700312e-06,
      "loss": 0.0001,
      "step": 50300
    },
    {
      "epoch": 5.390549662487946,
      "grad_norm": 24.725643157958984,
      "learning_rate": 9.218900675024109e-06,
      "loss": 0.3621,
      "step": 50310
    },
    {
      "epoch": 5.391621129326047,
      "grad_norm": 0.06724055111408234,
      "learning_rate": 9.216757741347906e-06,
      "loss": 0.3269,
      "step": 50320
    },
    {
      "epoch": 5.3926925961641485,
      "grad_norm": 0.026368683204054832,
      "learning_rate": 9.214614807671704e-06,
      "loss": 0.1421,
      "step": 50330
    },
    {
      "epoch": 5.39376406300225,
      "grad_norm": 0.20683923363685608,
      "learning_rate": 9.212471873995501e-06,
      "loss": 0.0009,
      "step": 50340
    },
    {
      "epoch": 5.394835529840352,
      "grad_norm": 0.003964895382523537,
      "learning_rate": 9.210328940319297e-06,
      "loss": 0.0002,
      "step": 50350
    },
    {
      "epoch": 5.395906996678453,
      "grad_norm": 0.02346251904964447,
      "learning_rate": 9.208186006643096e-06,
      "loss": 0.1661,
      "step": 50360
    },
    {
      "epoch": 5.396978463516554,
      "grad_norm": 0.006395756732672453,
      "learning_rate": 9.206043072966893e-06,
      "loss": 0.1296,
      "step": 50370
    },
    {
      "epoch": 5.398049930354656,
      "grad_norm": 0.001825537532567978,
      "learning_rate": 9.20390013929069e-06,
      "loss": 0.0508,
      "step": 50380
    },
    {
      "epoch": 5.399121397192757,
      "grad_norm": 0.030629834160208702,
      "learning_rate": 9.201757205614486e-06,
      "loss": 0.5929,
      "step": 50390
    },
    {
      "epoch": 5.400192864030858,
      "grad_norm": 0.01986703649163246,
      "learning_rate": 9.199614271938284e-06,
      "loss": 0.1794,
      "step": 50400
    },
    {
      "epoch": 5.40126433086896,
      "grad_norm": 0.1767743080854416,
      "learning_rate": 9.197471338262081e-06,
      "loss": 0.2964,
      "step": 50410
    },
    {
      "epoch": 5.402335797707061,
      "grad_norm": 0.00213390844874084,
      "learning_rate": 9.19532840458588e-06,
      "loss": 0.0009,
      "step": 50420
    },
    {
      "epoch": 5.403407264545162,
      "grad_norm": 0.005548505578190088,
      "learning_rate": 9.193185470909676e-06,
      "loss": 0.1986,
      "step": 50430
    },
    {
      "epoch": 5.404478731383263,
      "grad_norm": 0.028784651309251785,
      "learning_rate": 9.191042537233473e-06,
      "loss": 0.1505,
      "step": 50440
    },
    {
      "epoch": 5.405550198221365,
      "grad_norm": 0.2687869369983673,
      "learning_rate": 9.18889960355727e-06,
      "loss": 0.1457,
      "step": 50450
    },
    {
      "epoch": 5.4066216650594665,
      "grad_norm": 0.06779644638299942,
      "learning_rate": 9.186756669881068e-06,
      "loss": 0.1589,
      "step": 50460
    },
    {
      "epoch": 5.407693131897568,
      "grad_norm": 0.062851183116436,
      "learning_rate": 9.184613736204865e-06,
      "loss": 0.1228,
      "step": 50470
    },
    {
      "epoch": 5.408764598735669,
      "grad_norm": 0.001936593558639288,
      "learning_rate": 9.182470802528662e-06,
      "loss": 0.0016,
      "step": 50480
    },
    {
      "epoch": 5.409836065573771,
      "grad_norm": 0.3363531231880188,
      "learning_rate": 9.18032786885246e-06,
      "loss": 0.0016,
      "step": 50490
    },
    {
      "epoch": 5.410907532411872,
      "grad_norm": 0.008606991730630398,
      "learning_rate": 9.178184935176257e-06,
      "loss": 0.358,
      "step": 50500
    },
    {
      "epoch": 5.411978999249973,
      "grad_norm": 6.312560081481934,
      "learning_rate": 9.176042001500054e-06,
      "loss": 0.2675,
      "step": 50510
    },
    {
      "epoch": 5.413050466088075,
      "grad_norm": 0.018942248076200485,
      "learning_rate": 9.173899067823852e-06,
      "loss": 0.3067,
      "step": 50520
    },
    {
      "epoch": 5.414121932926176,
      "grad_norm": 0.0110520264133811,
      "learning_rate": 9.17175613414765e-06,
      "loss": 0.0011,
      "step": 50530
    },
    {
      "epoch": 5.415193399764277,
      "grad_norm": 20.695432662963867,
      "learning_rate": 9.169613200471447e-06,
      "loss": 0.6189,
      "step": 50540
    },
    {
      "epoch": 5.416264866602378,
      "grad_norm": 0.008395886979997158,
      "learning_rate": 9.167470266795244e-06,
      "loss": 0.0015,
      "step": 50550
    },
    {
      "epoch": 5.41733633344048,
      "grad_norm": 0.026540327817201614,
      "learning_rate": 9.165327333119041e-06,
      "loss": 0.1786,
      "step": 50560
    },
    {
      "epoch": 5.418407800278581,
      "grad_norm": 0.03579296916723251,
      "learning_rate": 9.163184399442839e-06,
      "loss": 0.0952,
      "step": 50570
    },
    {
      "epoch": 5.4194792671166825,
      "grad_norm": 0.0015170191181823611,
      "learning_rate": 9.161041465766636e-06,
      "loss": 0.1813,
      "step": 50580
    },
    {
      "epoch": 5.4205507339547845,
      "grad_norm": 0.13112954795360565,
      "learning_rate": 9.158898532090432e-06,
      "loss": 0.1089,
      "step": 50590
    },
    {
      "epoch": 5.421622200792886,
      "grad_norm": 0.02895250730216503,
      "learning_rate": 9.156755598414229e-06,
      "loss": 0.0236,
      "step": 50600
    },
    {
      "epoch": 5.422693667630987,
      "grad_norm": 0.08573895692825317,
      "learning_rate": 9.154612664738028e-06,
      "loss": 0.0008,
      "step": 50610
    },
    {
      "epoch": 5.423765134469088,
      "grad_norm": 30.60823631286621,
      "learning_rate": 9.152469731061825e-06,
      "loss": 0.439,
      "step": 50620
    },
    {
      "epoch": 5.42483660130719,
      "grad_norm": 0.15203799307346344,
      "learning_rate": 9.150326797385621e-06,
      "loss": 0.0006,
      "step": 50630
    },
    {
      "epoch": 5.425908068145291,
      "grad_norm": 0.03725403919816017,
      "learning_rate": 9.148183863709418e-06,
      "loss": 0.358,
      "step": 50640
    },
    {
      "epoch": 5.426979534983392,
      "grad_norm": 0.4203915297985077,
      "learning_rate": 9.146040930033216e-06,
      "loss": 0.0008,
      "step": 50650
    },
    {
      "epoch": 5.428051001821494,
      "grad_norm": 0.01616644114255905,
      "learning_rate": 9.143897996357015e-06,
      "loss": 0.0011,
      "step": 50660
    },
    {
      "epoch": 5.429122468659595,
      "grad_norm": 0.06627098470926285,
      "learning_rate": 9.14175506268081e-06,
      "loss": 0.1362,
      "step": 50670
    },
    {
      "epoch": 5.430193935497696,
      "grad_norm": 0.017456939443945885,
      "learning_rate": 9.139612129004608e-06,
      "loss": 0.6631,
      "step": 50680
    },
    {
      "epoch": 5.431265402335797,
      "grad_norm": 0.04701673239469528,
      "learning_rate": 9.137469195328405e-06,
      "loss": 0.001,
      "step": 50690
    },
    {
      "epoch": 5.432336869173899,
      "grad_norm": 0.11824915558099747,
      "learning_rate": 9.135326261652203e-06,
      "loss": 0.0741,
      "step": 50700
    },
    {
      "epoch": 5.4334083360120005,
      "grad_norm": 0.7150729894638062,
      "learning_rate": 9.133183327976e-06,
      "loss": 0.002,
      "step": 50710
    },
    {
      "epoch": 5.434479802850102,
      "grad_norm": 0.19396083056926727,
      "learning_rate": 9.131040394299797e-06,
      "loss": 0.2945,
      "step": 50720
    },
    {
      "epoch": 5.435551269688203,
      "grad_norm": 0.005357770249247551,
      "learning_rate": 9.128897460623595e-06,
      "loss": 0.091,
      "step": 50730
    },
    {
      "epoch": 5.436622736526305,
      "grad_norm": 0.03136053308844566,
      "learning_rate": 9.126754526947392e-06,
      "loss": 0.4238,
      "step": 50740
    },
    {
      "epoch": 5.437694203364406,
      "grad_norm": 0.12219636887311935,
      "learning_rate": 9.12461159327119e-06,
      "loss": 0.083,
      "step": 50750
    },
    {
      "epoch": 5.438765670202507,
      "grad_norm": 0.018530426546931267,
      "learning_rate": 9.122468659594987e-06,
      "loss": 0.1114,
      "step": 50760
    },
    {
      "epoch": 5.439837137040609,
      "grad_norm": 0.011937488801777363,
      "learning_rate": 9.120325725918784e-06,
      "loss": 0.3926,
      "step": 50770
    },
    {
      "epoch": 5.44090860387871,
      "grad_norm": 0.016488878056406975,
      "learning_rate": 9.11818279224258e-06,
      "loss": 0.2106,
      "step": 50780
    },
    {
      "epoch": 5.441980070716811,
      "grad_norm": 0.01718803681433201,
      "learning_rate": 9.116039858566377e-06,
      "loss": 0.0383,
      "step": 50790
    },
    {
      "epoch": 5.443051537554913,
      "grad_norm": 0.032598719000816345,
      "learning_rate": 9.113896924890176e-06,
      "loss": 0.0035,
      "step": 50800
    },
    {
      "epoch": 5.444123004393014,
      "grad_norm": 0.0021732253953814507,
      "learning_rate": 9.111753991213973e-06,
      "loss": 0.0027,
      "step": 50810
    },
    {
      "epoch": 5.445194471231115,
      "grad_norm": 0.008172692731022835,
      "learning_rate": 9.109611057537769e-06,
      "loss": 0.0746,
      "step": 50820
    },
    {
      "epoch": 5.446265938069216,
      "grad_norm": 0.009961974807083607,
      "learning_rate": 9.107468123861566e-06,
      "loss": 0.1708,
      "step": 50830
    },
    {
      "epoch": 5.447337404907318,
      "grad_norm": 0.0033928111661225557,
      "learning_rate": 9.105325190185364e-06,
      "loss": 0.006,
      "step": 50840
    },
    {
      "epoch": 5.4484088717454195,
      "grad_norm": 0.017414569854736328,
      "learning_rate": 9.103182256509163e-06,
      "loss": 0.1558,
      "step": 50850
    },
    {
      "epoch": 5.449480338583521,
      "grad_norm": 0.002051793271675706,
      "learning_rate": 9.101039322832959e-06,
      "loss": 0.0003,
      "step": 50860
    },
    {
      "epoch": 5.450551805421622,
      "grad_norm": 0.00977674312889576,
      "learning_rate": 9.098896389156756e-06,
      "loss": 0.0004,
      "step": 50870
    },
    {
      "epoch": 5.451623272259724,
      "grad_norm": 0.36565741896629333,
      "learning_rate": 9.096753455480553e-06,
      "loss": 0.0007,
      "step": 50880
    },
    {
      "epoch": 5.452694739097825,
      "grad_norm": 0.27136847376823425,
      "learning_rate": 9.09461052180435e-06,
      "loss": 0.1931,
      "step": 50890
    },
    {
      "epoch": 5.453766205935926,
      "grad_norm": 0.001747423899360001,
      "learning_rate": 9.092467588128148e-06,
      "loss": 0.0003,
      "step": 50900
    },
    {
      "epoch": 5.454837672774028,
      "grad_norm": 0.03901509940624237,
      "learning_rate": 9.090324654451945e-06,
      "loss": 0.177,
      "step": 50910
    },
    {
      "epoch": 5.455909139612129,
      "grad_norm": 0.019510475918650627,
      "learning_rate": 9.088181720775743e-06,
      "loss": 0.0013,
      "step": 50920
    },
    {
      "epoch": 5.45698060645023,
      "grad_norm": 0.01682739518582821,
      "learning_rate": 9.08603878709954e-06,
      "loss": 0.0019,
      "step": 50930
    },
    {
      "epoch": 5.458052073288332,
      "grad_norm": 0.0010040104389190674,
      "learning_rate": 9.083895853423337e-06,
      "loss": 0.0005,
      "step": 50940
    },
    {
      "epoch": 5.459123540126433,
      "grad_norm": 0.0009787421440705657,
      "learning_rate": 9.081752919747135e-06,
      "loss": 0.1841,
      "step": 50950
    },
    {
      "epoch": 5.460195006964534,
      "grad_norm": 0.006615166086703539,
      "learning_rate": 9.079609986070932e-06,
      "loss": 0.2448,
      "step": 50960
    },
    {
      "epoch": 5.4612664738026355,
      "grad_norm": 0.009339851327240467,
      "learning_rate": 9.07746705239473e-06,
      "loss": 0.2258,
      "step": 50970
    },
    {
      "epoch": 5.4623379406407375,
      "grad_norm": 0.02289372682571411,
      "learning_rate": 9.075324118718525e-06,
      "loss": 0.0012,
      "step": 50980
    },
    {
      "epoch": 5.463409407478839,
      "grad_norm": 0.06013642996549606,
      "learning_rate": 9.073181185042324e-06,
      "loss": 0.0004,
      "step": 50990
    },
    {
      "epoch": 5.46448087431694,
      "grad_norm": 0.0970931351184845,
      "learning_rate": 9.071038251366122e-06,
      "loss": 0.2416,
      "step": 51000
    },
    {
      "epoch": 5.465552341155041,
      "grad_norm": 0.007582685444504023,
      "learning_rate": 9.068895317689919e-06,
      "loss": 0.2087,
      "step": 51010
    },
    {
      "epoch": 5.466623807993143,
      "grad_norm": 0.07154234498739243,
      "learning_rate": 9.066752384013715e-06,
      "loss": 0.0009,
      "step": 51020
    },
    {
      "epoch": 5.467695274831244,
      "grad_norm": 0.022555343806743622,
      "learning_rate": 9.064609450337512e-06,
      "loss": 0.2178,
      "step": 51030
    },
    {
      "epoch": 5.468766741669345,
      "grad_norm": 0.0006750002503395081,
      "learning_rate": 9.062466516661311e-06,
      "loss": 0.0002,
      "step": 51040
    },
    {
      "epoch": 5.469838208507447,
      "grad_norm": 0.021638555452227592,
      "learning_rate": 9.060323582985108e-06,
      "loss": 0.0097,
      "step": 51050
    },
    {
      "epoch": 5.470909675345548,
      "grad_norm": 0.016601456329226494,
      "learning_rate": 9.058180649308904e-06,
      "loss": 0.0015,
      "step": 51060
    },
    {
      "epoch": 5.471981142183649,
      "grad_norm": 0.00625928770750761,
      "learning_rate": 9.056037715632701e-06,
      "loss": 0.0976,
      "step": 51070
    },
    {
      "epoch": 5.47305260902175,
      "grad_norm": 0.0005336860776878893,
      "learning_rate": 9.053894781956499e-06,
      "loss": 0.2027,
      "step": 51080
    },
    {
      "epoch": 5.474124075859852,
      "grad_norm": 0.43142279982566833,
      "learning_rate": 9.051751848280296e-06,
      "loss": 0.1821,
      "step": 51090
    },
    {
      "epoch": 5.4751955426979535,
      "grad_norm": 0.02072843536734581,
      "learning_rate": 9.049608914604093e-06,
      "loss": 0.0005,
      "step": 51100
    },
    {
      "epoch": 5.476267009536055,
      "grad_norm": 18.68663787841797,
      "learning_rate": 9.04746598092789e-06,
      "loss": 0.394,
      "step": 51110
    },
    {
      "epoch": 5.477338476374157,
      "grad_norm": 35.48488998413086,
      "learning_rate": 9.045323047251688e-06,
      "loss": 0.1498,
      "step": 51120
    },
    {
      "epoch": 5.478409943212258,
      "grad_norm": 0.008287841454148293,
      "learning_rate": 9.043180113575485e-06,
      "loss": 0.1831,
      "step": 51130
    },
    {
      "epoch": 5.479481410050359,
      "grad_norm": 0.0011821383377537131,
      "learning_rate": 9.041037179899283e-06,
      "loss": 0.3518,
      "step": 51140
    },
    {
      "epoch": 5.48055287688846,
      "grad_norm": 0.04942493513226509,
      "learning_rate": 9.03889424622308e-06,
      "loss": 0.0035,
      "step": 51150
    },
    {
      "epoch": 5.481624343726562,
      "grad_norm": 0.4517078101634979,
      "learning_rate": 9.036751312546878e-06,
      "loss": 0.4303,
      "step": 51160
    },
    {
      "epoch": 5.482695810564663,
      "grad_norm": 0.18834027647972107,
      "learning_rate": 9.034608378870675e-06,
      "loss": 0.0222,
      "step": 51170
    },
    {
      "epoch": 5.483767277402764,
      "grad_norm": 0.08889559656381607,
      "learning_rate": 9.032465445194472e-06,
      "loss": 0.0004,
      "step": 51180
    },
    {
      "epoch": 5.484838744240866,
      "grad_norm": 0.011024845764040947,
      "learning_rate": 9.03032251151827e-06,
      "loss": 0.3421,
      "step": 51190
    },
    {
      "epoch": 5.485910211078967,
      "grad_norm": 0.01423961203545332,
      "learning_rate": 9.028179577842067e-06,
      "loss": 0.0007,
      "step": 51200
    },
    {
      "epoch": 5.486981677917068,
      "grad_norm": 0.0009942599572241306,
      "learning_rate": 9.026036644165864e-06,
      "loss": 0.199,
      "step": 51210
    },
    {
      "epoch": 5.4880531447551695,
      "grad_norm": 0.028188223019242287,
      "learning_rate": 9.02389371048966e-06,
      "loss": 0.0012,
      "step": 51220
    },
    {
      "epoch": 5.4891246115932715,
      "grad_norm": 0.005340117029845715,
      "learning_rate": 9.021750776813459e-06,
      "loss": 0.1283,
      "step": 51230
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 0.044890038669109344,
      "learning_rate": 9.019607843137256e-06,
      "loss": 0.0072,
      "step": 51240
    },
    {
      "epoch": 5.491267545269474,
      "grad_norm": 0.009395180270075798,
      "learning_rate": 9.017464909461054e-06,
      "loss": 0.0006,
      "step": 51250
    },
    {
      "epoch": 5.492339012107575,
      "grad_norm": 0.00670909509062767,
      "learning_rate": 9.01532197578485e-06,
      "loss": 0.0007,
      "step": 51260
    },
    {
      "epoch": 5.493410478945677,
      "grad_norm": 0.0665726512670517,
      "learning_rate": 9.013179042108647e-06,
      "loss": 0.0005,
      "step": 51270
    },
    {
      "epoch": 5.494481945783778,
      "grad_norm": 0.001447382033802569,
      "learning_rate": 9.011036108432444e-06,
      "loss": 0.0002,
      "step": 51280
    },
    {
      "epoch": 5.495553412621879,
      "grad_norm": 24.386430740356445,
      "learning_rate": 9.008893174756243e-06,
      "loss": 0.6097,
      "step": 51290
    },
    {
      "epoch": 5.496624879459981,
      "grad_norm": 0.001054392196238041,
      "learning_rate": 9.006750241080039e-06,
      "loss": 0.0003,
      "step": 51300
    },
    {
      "epoch": 5.497696346298082,
      "grad_norm": 16.498315811157227,
      "learning_rate": 9.004607307403836e-06,
      "loss": 0.2293,
      "step": 51310
    },
    {
      "epoch": 5.498767813136183,
      "grad_norm": 1.4348090887069702,
      "learning_rate": 9.002464373727634e-06,
      "loss": 0.3717,
      "step": 51320
    },
    {
      "epoch": 5.499839279974285,
      "grad_norm": 0.040777746587991714,
      "learning_rate": 9.000321440051431e-06,
      "loss": 0.0009,
      "step": 51330
    },
    {
      "epoch": 5.500910746812386,
      "grad_norm": 0.7369762659072876,
      "learning_rate": 8.998178506375228e-06,
      "loss": 0.1294,
      "step": 51340
    },
    {
      "epoch": 5.5019822136504875,
      "grad_norm": 0.13027992844581604,
      "learning_rate": 8.996035572699026e-06,
      "loss": 0.0018,
      "step": 51350
    },
    {
      "epoch": 5.503053680488589,
      "grad_norm": 0.05281413346529007,
      "learning_rate": 8.993892639022823e-06,
      "loss": 0.0007,
      "step": 51360
    },
    {
      "epoch": 5.504125147326691,
      "grad_norm": 0.08218495547771454,
      "learning_rate": 8.99174970534662e-06,
      "loss": 0.653,
      "step": 51370
    },
    {
      "epoch": 5.505196614164792,
      "grad_norm": 0.028896288946270943,
      "learning_rate": 8.989606771670418e-06,
      "loss": 0.0011,
      "step": 51380
    },
    {
      "epoch": 5.506268081002893,
      "grad_norm": 29.223474502563477,
      "learning_rate": 8.987463837994215e-06,
      "loss": 0.253,
      "step": 51390
    },
    {
      "epoch": 5.507339547840994,
      "grad_norm": 0.01488407887518406,
      "learning_rate": 8.985320904318012e-06,
      "loss": 0.2949,
      "step": 51400
    },
    {
      "epoch": 5.508411014679096,
      "grad_norm": 0.13326029479503632,
      "learning_rate": 8.98317797064181e-06,
      "loss": 0.5782,
      "step": 51410
    },
    {
      "epoch": 5.509482481517197,
      "grad_norm": 0.026225948706269264,
      "learning_rate": 8.981035036965607e-06,
      "loss": 0.9094,
      "step": 51420
    },
    {
      "epoch": 5.510553948355298,
      "grad_norm": 0.03700513020157814,
      "learning_rate": 8.978892103289404e-06,
      "loss": 0.1787,
      "step": 51430
    },
    {
      "epoch": 5.5116254151934,
      "grad_norm": 0.222678542137146,
      "learning_rate": 8.976749169613202e-06,
      "loss": 0.0023,
      "step": 51440
    },
    {
      "epoch": 5.512696882031501,
      "grad_norm": 0.007304094731807709,
      "learning_rate": 8.974606235936999e-06,
      "loss": 0.015,
      "step": 51450
    },
    {
      "epoch": 5.513768348869602,
      "grad_norm": 0.0052543929778039455,
      "learning_rate": 8.972463302260795e-06,
      "loss": 0.0011,
      "step": 51460
    },
    {
      "epoch": 5.514839815707704,
      "grad_norm": 0.022343814373016357,
      "learning_rate": 8.970320368584592e-06,
      "loss": 0.0012,
      "step": 51470
    },
    {
      "epoch": 5.515911282545805,
      "grad_norm": 0.0057079847902059555,
      "learning_rate": 8.968177434908391e-06,
      "loss": 0.3505,
      "step": 51480
    },
    {
      "epoch": 5.5169827493839065,
      "grad_norm": 0.09310782700777054,
      "learning_rate": 8.966034501232189e-06,
      "loss": 0.1423,
      "step": 51490
    },
    {
      "epoch": 5.518054216222008,
      "grad_norm": 0.003899230156093836,
      "learning_rate": 8.963891567555984e-06,
      "loss": 0.1863,
      "step": 51500
    },
    {
      "epoch": 5.51912568306011,
      "grad_norm": 207.641845703125,
      "learning_rate": 8.961748633879782e-06,
      "loss": 0.3162,
      "step": 51510
    },
    {
      "epoch": 5.520197149898211,
      "grad_norm": 0.0016883470816537738,
      "learning_rate": 8.959605700203579e-06,
      "loss": 0.0009,
      "step": 51520
    },
    {
      "epoch": 5.521268616736312,
      "grad_norm": 0.002366107888519764,
      "learning_rate": 8.957462766527378e-06,
      "loss": 0.1303,
      "step": 51530
    },
    {
      "epoch": 5.522340083574413,
      "grad_norm": 137.8429718017578,
      "learning_rate": 8.955319832851174e-06,
      "loss": 0.2848,
      "step": 51540
    },
    {
      "epoch": 5.523411550412515,
      "grad_norm": 0.022354718297719955,
      "learning_rate": 8.953176899174971e-06,
      "loss": 0.206,
      "step": 51550
    },
    {
      "epoch": 5.524483017250616,
      "grad_norm": 0.01981442980468273,
      "learning_rate": 8.951033965498768e-06,
      "loss": 0.0017,
      "step": 51560
    },
    {
      "epoch": 5.525554484088717,
      "grad_norm": 0.010706298984587193,
      "learning_rate": 8.948891031822566e-06,
      "loss": 0.8564,
      "step": 51570
    },
    {
      "epoch": 5.526625950926819,
      "grad_norm": 0.001511565176770091,
      "learning_rate": 8.946748098146363e-06,
      "loss": 0.1168,
      "step": 51580
    },
    {
      "epoch": 5.52769741776492,
      "grad_norm": 0.06224214658141136,
      "learning_rate": 8.94460516447016e-06,
      "loss": 0.1218,
      "step": 51590
    },
    {
      "epoch": 5.528768884603021,
      "grad_norm": 0.010207525454461575,
      "learning_rate": 8.942462230793958e-06,
      "loss": 0.0915,
      "step": 51600
    },
    {
      "epoch": 5.5298403514411225,
      "grad_norm": 0.00550357811152935,
      "learning_rate": 8.940319297117755e-06,
      "loss": 0.2217,
      "step": 51610
    },
    {
      "epoch": 5.5309118182792245,
      "grad_norm": 0.006262196693569422,
      "learning_rate": 8.938176363441553e-06,
      "loss": 0.2025,
      "step": 51620
    },
    {
      "epoch": 5.531983285117326,
      "grad_norm": 0.0021094265393912792,
      "learning_rate": 8.93603342976535e-06,
      "loss": 0.0001,
      "step": 51630
    },
    {
      "epoch": 5.533054751955427,
      "grad_norm": 0.000831053766887635,
      "learning_rate": 8.933890496089147e-06,
      "loss": 0.1839,
      "step": 51640
    },
    {
      "epoch": 5.534126218793529,
      "grad_norm": 0.009493159130215645,
      "learning_rate": 8.931747562412943e-06,
      "loss": 0.1536,
      "step": 51650
    },
    {
      "epoch": 5.53519768563163,
      "grad_norm": 0.04524831846356392,
      "learning_rate": 8.92960462873674e-06,
      "loss": 0.1638,
      "step": 51660
    },
    {
      "epoch": 5.536269152469731,
      "grad_norm": 23.08260154724121,
      "learning_rate": 8.92746169506054e-06,
      "loss": 0.5125,
      "step": 51670
    },
    {
      "epoch": 5.537340619307832,
      "grad_norm": 28.61742401123047,
      "learning_rate": 8.925318761384337e-06,
      "loss": 0.5648,
      "step": 51680
    },
    {
      "epoch": 5.538412086145934,
      "grad_norm": 0.008767268620431423,
      "learning_rate": 8.923175827708132e-06,
      "loss": 0.0005,
      "step": 51690
    },
    {
      "epoch": 5.539483552984035,
      "grad_norm": 0.0019948335830122232,
      "learning_rate": 8.92103289403193e-06,
      "loss": 0.1813,
      "step": 51700
    },
    {
      "epoch": 5.540555019822136,
      "grad_norm": 0.3628912568092346,
      "learning_rate": 8.918889960355727e-06,
      "loss": 0.0397,
      "step": 51710
    },
    {
      "epoch": 5.541626486660238,
      "grad_norm": 0.008214514702558517,
      "learning_rate": 8.916747026679526e-06,
      "loss": 0.0015,
      "step": 51720
    },
    {
      "epoch": 5.542697953498339,
      "grad_norm": 0.002953615039587021,
      "learning_rate": 8.914604093003322e-06,
      "loss": 0.1395,
      "step": 51730
    },
    {
      "epoch": 5.5437694203364405,
      "grad_norm": 0.13199706375598907,
      "learning_rate": 8.912461159327119e-06,
      "loss": 0.2802,
      "step": 51740
    },
    {
      "epoch": 5.544840887174542,
      "grad_norm": 0.030636385083198547,
      "learning_rate": 8.910318225650916e-06,
      "loss": 0.0071,
      "step": 51750
    },
    {
      "epoch": 5.545912354012644,
      "grad_norm": 0.0028529982082545757,
      "learning_rate": 8.908175291974714e-06,
      "loss": 0.5135,
      "step": 51760
    },
    {
      "epoch": 5.546983820850745,
      "grad_norm": 0.0007945830002427101,
      "learning_rate": 8.906032358298511e-06,
      "loss": 0.0009,
      "step": 51770
    },
    {
      "epoch": 5.548055287688846,
      "grad_norm": 0.0027185212820768356,
      "learning_rate": 8.903889424622309e-06,
      "loss": 0.1484,
      "step": 51780
    },
    {
      "epoch": 5.549126754526947,
      "grad_norm": 0.37251994013786316,
      "learning_rate": 8.901746490946106e-06,
      "loss": 0.0215,
      "step": 51790
    },
    {
      "epoch": 5.550198221365049,
      "grad_norm": 4.027355670928955,
      "learning_rate": 8.899603557269903e-06,
      "loss": 0.0031,
      "step": 51800
    },
    {
      "epoch": 5.55126968820315,
      "grad_norm": 0.09459952265024185,
      "learning_rate": 8.8974606235937e-06,
      "loss": 0.0438,
      "step": 51810
    },
    {
      "epoch": 5.552341155041251,
      "grad_norm": 0.12071488797664642,
      "learning_rate": 8.895317689917498e-06,
      "loss": 0.4707,
      "step": 51820
    },
    {
      "epoch": 5.553412621879353,
      "grad_norm": 0.0009022908634506166,
      "learning_rate": 8.893174756241295e-06,
      "loss": 0.0002,
      "step": 51830
    },
    {
      "epoch": 5.554484088717454,
      "grad_norm": 0.07577105611562729,
      "learning_rate": 8.891031822565093e-06,
      "loss": 0.0003,
      "step": 51840
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 0.010579807683825493,
      "learning_rate": 8.888888888888888e-06,
      "loss": 0.1641,
      "step": 51850
    },
    {
      "epoch": 5.556627022393657,
      "grad_norm": 0.07564321160316467,
      "learning_rate": 8.886745955212687e-06,
      "loss": 0.0014,
      "step": 51860
    },
    {
      "epoch": 5.5576984892317585,
      "grad_norm": 0.022607652470469475,
      "learning_rate": 8.884603021536485e-06,
      "loss": 0.0767,
      "step": 51870
    },
    {
      "epoch": 5.55876995606986,
      "grad_norm": 0.07565314322710037,
      "learning_rate": 8.882460087860282e-06,
      "loss": 0.4364,
      "step": 51880
    },
    {
      "epoch": 5.559841422907961,
      "grad_norm": 0.09890922904014587,
      "learning_rate": 8.880317154184078e-06,
      "loss": 0.1276,
      "step": 51890
    },
    {
      "epoch": 5.560912889746063,
      "grad_norm": 0.05114073306322098,
      "learning_rate": 8.878174220507875e-06,
      "loss": 0.2224,
      "step": 51900
    },
    {
      "epoch": 5.561984356584164,
      "grad_norm": 0.009055009111762047,
      "learning_rate": 8.876031286831674e-06,
      "loss": 0.0006,
      "step": 51910
    },
    {
      "epoch": 5.563055823422265,
      "grad_norm": 0.0007008258253335953,
      "learning_rate": 8.873888353155471e-06,
      "loss": 0.0245,
      "step": 51920
    },
    {
      "epoch": 5.564127290260366,
      "grad_norm": 0.0006454189424403012,
      "learning_rate": 8.871745419479267e-06,
      "loss": 0.3343,
      "step": 51930
    },
    {
      "epoch": 5.565198757098468,
      "grad_norm": 0.19878514111042023,
      "learning_rate": 8.869602485803065e-06,
      "loss": 0.2447,
      "step": 51940
    },
    {
      "epoch": 5.566270223936569,
      "grad_norm": 0.007564885076135397,
      "learning_rate": 8.867459552126862e-06,
      "loss": 0.1684,
      "step": 51950
    },
    {
      "epoch": 5.56734169077467,
      "grad_norm": 0.0015317145735025406,
      "learning_rate": 8.86531661845066e-06,
      "loss": 0.0005,
      "step": 51960
    },
    {
      "epoch": 5.568413157612772,
      "grad_norm": 26.485023498535156,
      "learning_rate": 8.863173684774457e-06,
      "loss": 0.7079,
      "step": 51970
    },
    {
      "epoch": 5.569484624450873,
      "grad_norm": 0.04754503443837166,
      "learning_rate": 8.861030751098254e-06,
      "loss": 0.0008,
      "step": 51980
    },
    {
      "epoch": 5.570556091288974,
      "grad_norm": 0.026051463559269905,
      "learning_rate": 8.858887817422051e-06,
      "loss": 0.3898,
      "step": 51990
    },
    {
      "epoch": 5.571627558127076,
      "grad_norm": 0.12179999053478241,
      "learning_rate": 8.856744883745849e-06,
      "loss": 0.0009,
      "step": 52000
    },
    {
      "epoch": 5.5726990249651775,
      "grad_norm": 0.01623181439936161,
      "learning_rate": 8.854601950069646e-06,
      "loss": 0.3436,
      "step": 52010
    },
    {
      "epoch": 5.573770491803279,
      "grad_norm": 0.005658120382577181,
      "learning_rate": 8.852459016393443e-06,
      "loss": 0.0024,
      "step": 52020
    },
    {
      "epoch": 5.57484195864138,
      "grad_norm": 0.013200563378632069,
      "learning_rate": 8.85031608271724e-06,
      "loss": 0.0022,
      "step": 52030
    },
    {
      "epoch": 5.575913425479482,
      "grad_norm": 141.19374084472656,
      "learning_rate": 8.848173149041038e-06,
      "loss": 0.0251,
      "step": 52040
    },
    {
      "epoch": 5.576984892317583,
      "grad_norm": 0.004781106952577829,
      "learning_rate": 8.846030215364835e-06,
      "loss": 0.0019,
      "step": 52050
    },
    {
      "epoch": 5.578056359155684,
      "grad_norm": 206.64329528808594,
      "learning_rate": 8.843887281688633e-06,
      "loss": 0.5091,
      "step": 52060
    },
    {
      "epoch": 5.579127825993785,
      "grad_norm": 0.007165134884417057,
      "learning_rate": 8.84174434801243e-06,
      "loss": 0.0087,
      "step": 52070
    },
    {
      "epoch": 5.580199292831887,
      "grad_norm": 0.04281449690461159,
      "learning_rate": 8.839601414336227e-06,
      "loss": 0.1129,
      "step": 52080
    },
    {
      "epoch": 5.581270759669988,
      "grad_norm": 0.05186943709850311,
      "learning_rate": 8.837458480660023e-06,
      "loss": 0.2027,
      "step": 52090
    },
    {
      "epoch": 5.582342226508089,
      "grad_norm": 0.01411756407469511,
      "learning_rate": 8.835315546983822e-06,
      "loss": 0.1805,
      "step": 52100
    },
    {
      "epoch": 5.583413693346191,
      "grad_norm": 0.0012334786588326097,
      "learning_rate": 8.83317261330762e-06,
      "loss": 0.002,
      "step": 52110
    },
    {
      "epoch": 5.584485160184292,
      "grad_norm": 0.013395721092820168,
      "learning_rate": 8.831029679631417e-06,
      "loss": 0.0005,
      "step": 52120
    },
    {
      "epoch": 5.5855566270223935,
      "grad_norm": 0.057696714997291565,
      "learning_rate": 8.828886745955213e-06,
      "loss": 0.0012,
      "step": 52130
    },
    {
      "epoch": 5.586628093860495,
      "grad_norm": 0.012448574416339397,
      "learning_rate": 8.82674381227901e-06,
      "loss": 0.0001,
      "step": 52140
    },
    {
      "epoch": 5.587699560698597,
      "grad_norm": 0.06069716811180115,
      "learning_rate": 8.824600878602807e-06,
      "loss": 0.1665,
      "step": 52150
    },
    {
      "epoch": 5.588771027536698,
      "grad_norm": 0.04640395939350128,
      "learning_rate": 8.822457944926606e-06,
      "loss": 0.0003,
      "step": 52160
    },
    {
      "epoch": 5.589842494374799,
      "grad_norm": 0.006288877688348293,
      "learning_rate": 8.820315011250402e-06,
      "loss": 0.0004,
      "step": 52170
    },
    {
      "epoch": 5.5909139612129,
      "grad_norm": 169.660400390625,
      "learning_rate": 8.8181720775742e-06,
      "loss": 0.2418,
      "step": 52180
    },
    {
      "epoch": 5.591985428051002,
      "grad_norm": 0.01615891419351101,
      "learning_rate": 8.816029143897997e-06,
      "loss": 0.0004,
      "step": 52190
    },
    {
      "epoch": 5.593056894889103,
      "grad_norm": 0.02500183694064617,
      "learning_rate": 8.813886210221794e-06,
      "loss": 0.2102,
      "step": 52200
    },
    {
      "epoch": 5.594128361727204,
      "grad_norm": 0.012233695015311241,
      "learning_rate": 8.811743276545591e-06,
      "loss": 0.1872,
      "step": 52210
    },
    {
      "epoch": 5.595199828565306,
      "grad_norm": 0.12041953206062317,
      "learning_rate": 8.809600342869389e-06,
      "loss": 0.3677,
      "step": 52220
    },
    {
      "epoch": 5.596271295403407,
      "grad_norm": 0.01061705220490694,
      "learning_rate": 8.807457409193186e-06,
      "loss": 0.0034,
      "step": 52230
    },
    {
      "epoch": 5.597342762241508,
      "grad_norm": 0.0007206537993624806,
      "learning_rate": 8.805314475516983e-06,
      "loss": 0.021,
      "step": 52240
    },
    {
      "epoch": 5.59841422907961,
      "grad_norm": 0.04687139019370079,
      "learning_rate": 8.80317154184078e-06,
      "loss": 0.1855,
      "step": 52250
    },
    {
      "epoch": 5.5994856959177115,
      "grad_norm": 0.32697737216949463,
      "learning_rate": 8.801028608164578e-06,
      "loss": 0.0127,
      "step": 52260
    },
    {
      "epoch": 5.600557162755813,
      "grad_norm": 0.001135175465606153,
      "learning_rate": 8.798885674488376e-06,
      "loss": 0.0093,
      "step": 52270
    },
    {
      "epoch": 5.601628629593914,
      "grad_norm": 0.0006429672357626259,
      "learning_rate": 8.796742740812173e-06,
      "loss": 0.0006,
      "step": 52280
    },
    {
      "epoch": 5.602700096432016,
      "grad_norm": 0.05910731479525566,
      "learning_rate": 8.79459980713597e-06,
      "loss": 0.1804,
      "step": 52290
    },
    {
      "epoch": 5.603771563270117,
      "grad_norm": 53.958282470703125,
      "learning_rate": 8.792456873459768e-06,
      "loss": 0.1657,
      "step": 52300
    },
    {
      "epoch": 5.604843030108218,
      "grad_norm": 2.1394426822662354,
      "learning_rate": 8.790313939783565e-06,
      "loss": 0.2623,
      "step": 52310
    },
    {
      "epoch": 5.605914496946319,
      "grad_norm": 0.0005305035156197846,
      "learning_rate": 8.788171006107362e-06,
      "loss": 0.0004,
      "step": 52320
    },
    {
      "epoch": 5.606985963784421,
      "grad_norm": 0.016798818483948708,
      "learning_rate": 8.786028072431158e-06,
      "loss": 0.021,
      "step": 52330
    },
    {
      "epoch": 5.608057430622522,
      "grad_norm": 0.0012443633750081062,
      "learning_rate": 8.783885138754955e-06,
      "loss": 0.0006,
      "step": 52340
    },
    {
      "epoch": 5.609128897460623,
      "grad_norm": 0.00552363321185112,
      "learning_rate": 8.781742205078754e-06,
      "loss": 0.1512,
      "step": 52350
    },
    {
      "epoch": 5.610200364298725,
      "grad_norm": 0.07758233696222305,
      "learning_rate": 8.779599271402552e-06,
      "loss": 0.1422,
      "step": 52360
    },
    {
      "epoch": 5.611271831136826,
      "grad_norm": 0.06922639161348343,
      "learning_rate": 8.777456337726347e-06,
      "loss": 0.1526,
      "step": 52370
    },
    {
      "epoch": 5.6123432979749275,
      "grad_norm": 0.0008926091832108796,
      "learning_rate": 8.775313404050145e-06,
      "loss": 0.0007,
      "step": 52380
    },
    {
      "epoch": 5.6134147648130295,
      "grad_norm": 0.002490806393325329,
      "learning_rate": 8.773170470373942e-06,
      "loss": 0.2182,
      "step": 52390
    },
    {
      "epoch": 5.614486231651131,
      "grad_norm": 0.05235821008682251,
      "learning_rate": 8.771027536697741e-06,
      "loss": 0.0008,
      "step": 52400
    },
    {
      "epoch": 5.615557698489232,
      "grad_norm": 0.003380563110113144,
      "learning_rate": 8.768884603021537e-06,
      "loss": 0.0058,
      "step": 52410
    },
    {
      "epoch": 5.616629165327333,
      "grad_norm": 0.0020493397023528814,
      "learning_rate": 8.766741669345334e-06,
      "loss": 0.1319,
      "step": 52420
    },
    {
      "epoch": 5.617700632165435,
      "grad_norm": 0.000783895084168762,
      "learning_rate": 8.764598735669132e-06,
      "loss": 0.1493,
      "step": 52430
    },
    {
      "epoch": 5.618772099003536,
      "grad_norm": 0.059175580739974976,
      "learning_rate": 8.762455801992929e-06,
      "loss": 0.0003,
      "step": 52440
    },
    {
      "epoch": 5.619843565841637,
      "grad_norm": 0.01083153486251831,
      "learning_rate": 8.760312868316726e-06,
      "loss": 0.0002,
      "step": 52450
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 0.00516365934163332,
      "learning_rate": 8.758169934640524e-06,
      "loss": 0.002,
      "step": 52460
    },
    {
      "epoch": 5.62198649951784,
      "grad_norm": 42.44003677368164,
      "learning_rate": 8.756027000964321e-06,
      "loss": 0.2105,
      "step": 52470
    },
    {
      "epoch": 5.623057966355941,
      "grad_norm": 32.12200927734375,
      "learning_rate": 8.753884067288118e-06,
      "loss": 0.1776,
      "step": 52480
    },
    {
      "epoch": 5.624129433194042,
      "grad_norm": 0.08042297512292862,
      "learning_rate": 8.751741133611916e-06,
      "loss": 0.0004,
      "step": 52490
    },
    {
      "epoch": 5.625200900032144,
      "grad_norm": 0.7439382076263428,
      "learning_rate": 8.749598199935713e-06,
      "loss": 0.7115,
      "step": 52500
    },
    {
      "epoch": 5.6262723668702455,
      "grad_norm": 0.042160678654909134,
      "learning_rate": 8.74745526625951e-06,
      "loss": 0.1567,
      "step": 52510
    },
    {
      "epoch": 5.627343833708347,
      "grad_norm": 0.01774393394589424,
      "learning_rate": 8.745312332583308e-06,
      "loss": 0.5047,
      "step": 52520
    },
    {
      "epoch": 5.628415300546449,
      "grad_norm": 0.16257961094379425,
      "learning_rate": 8.743169398907103e-06,
      "loss": 0.001,
      "step": 52530
    },
    {
      "epoch": 5.62948676738455,
      "grad_norm": 0.006493416614830494,
      "learning_rate": 8.741026465230902e-06,
      "loss": 0.0067,
      "step": 52540
    },
    {
      "epoch": 5.630558234222651,
      "grad_norm": 0.006403942126780748,
      "learning_rate": 8.7388835315547e-06,
      "loss": 0.1564,
      "step": 52550
    },
    {
      "epoch": 5.631629701060752,
      "grad_norm": 0.04351096972823143,
      "learning_rate": 8.736740597878495e-06,
      "loss": 0.1603,
      "step": 52560
    },
    {
      "epoch": 5.632701167898854,
      "grad_norm": 0.0033454331569373608,
      "learning_rate": 8.734597664202293e-06,
      "loss": 0.0004,
      "step": 52570
    },
    {
      "epoch": 5.633772634736955,
      "grad_norm": 0.017349211499094963,
      "learning_rate": 8.73245473052609e-06,
      "loss": 0.0012,
      "step": 52580
    },
    {
      "epoch": 5.634844101575056,
      "grad_norm": 1.3442429304122925,
      "learning_rate": 8.73031179684989e-06,
      "loss": 0.0036,
      "step": 52590
    },
    {
      "epoch": 5.635915568413157,
      "grad_norm": 0.0010392589028924704,
      "learning_rate": 8.728168863173685e-06,
      "loss": 0.0063,
      "step": 52600
    },
    {
      "epoch": 5.636987035251259,
      "grad_norm": 62.56006622314453,
      "learning_rate": 8.726025929497482e-06,
      "loss": 0.1213,
      "step": 52610
    },
    {
      "epoch": 5.63805850208936,
      "grad_norm": 0.09615547209978104,
      "learning_rate": 8.72388299582128e-06,
      "loss": 0.1444,
      "step": 52620
    },
    {
      "epoch": 5.639129968927461,
      "grad_norm": 56.061973571777344,
      "learning_rate": 8.721740062145077e-06,
      "loss": 0.206,
      "step": 52630
    },
    {
      "epoch": 5.640201435765563,
      "grad_norm": 0.008202806115150452,
      "learning_rate": 8.719597128468874e-06,
      "loss": 0.0004,
      "step": 52640
    },
    {
      "epoch": 5.6412729026036645,
      "grad_norm": 0.0008416443015448749,
      "learning_rate": 8.717454194792672e-06,
      "loss": 0.0011,
      "step": 52650
    },
    {
      "epoch": 5.642344369441766,
      "grad_norm": 14.633071899414062,
      "learning_rate": 8.715311261116469e-06,
      "loss": 0.1858,
      "step": 52660
    },
    {
      "epoch": 5.643415836279867,
      "grad_norm": 0.06509735435247421,
      "learning_rate": 8.713168327440266e-06,
      "loss": 0.3784,
      "step": 52670
    },
    {
      "epoch": 5.644487303117969,
      "grad_norm": 0.04305640235543251,
      "learning_rate": 8.711025393764064e-06,
      "loss": 0.227,
      "step": 52680
    },
    {
      "epoch": 5.64555876995607,
      "grad_norm": 0.0013207083102315664,
      "learning_rate": 8.708882460087861e-06,
      "loss": 0.3077,
      "step": 52690
    },
    {
      "epoch": 5.646630236794171,
      "grad_norm": 22.382808685302734,
      "learning_rate": 8.706739526411658e-06,
      "loss": 0.2371,
      "step": 52700
    },
    {
      "epoch": 5.647701703632272,
      "grad_norm": 0.030233152210712433,
      "learning_rate": 8.704596592735456e-06,
      "loss": 0.1913,
      "step": 52710
    },
    {
      "epoch": 5.648773170470374,
      "grad_norm": 0.023382561281323433,
      "learning_rate": 8.702453659059251e-06,
      "loss": 0.1846,
      "step": 52720
    },
    {
      "epoch": 5.649844637308475,
      "grad_norm": 0.0028176086489111185,
      "learning_rate": 8.70031072538305e-06,
      "loss": 0.1369,
      "step": 52730
    },
    {
      "epoch": 5.650916104146576,
      "grad_norm": 0.0014959301333874464,
      "learning_rate": 8.698167791706848e-06,
      "loss": 0.2352,
      "step": 52740
    },
    {
      "epoch": 5.651987570984678,
      "grad_norm": 0.31108933687210083,
      "learning_rate": 8.696024858030645e-06,
      "loss": 0.8683,
      "step": 52750
    },
    {
      "epoch": 5.653059037822779,
      "grad_norm": 0.3569830060005188,
      "learning_rate": 8.693881924354441e-06,
      "loss": 0.0013,
      "step": 52760
    },
    {
      "epoch": 5.6541305046608805,
      "grad_norm": 0.1144120842218399,
      "learning_rate": 8.691738990678238e-06,
      "loss": 0.0013,
      "step": 52770
    },
    {
      "epoch": 5.6552019714989825,
      "grad_norm": 0.25716134905815125,
      "learning_rate": 8.689596057002037e-06,
      "loss": 0.1268,
      "step": 52780
    },
    {
      "epoch": 5.656273438337084,
      "grad_norm": 0.014968495815992355,
      "learning_rate": 8.687453123325835e-06,
      "loss": 0.0006,
      "step": 52790
    },
    {
      "epoch": 5.657344905175185,
      "grad_norm": 0.20844580233097076,
      "learning_rate": 8.68531018964963e-06,
      "loss": 0.1799,
      "step": 52800
    },
    {
      "epoch": 5.658416372013286,
      "grad_norm": 1.6610699892044067,
      "learning_rate": 8.683167255973428e-06,
      "loss": 0.0154,
      "step": 52810
    },
    {
      "epoch": 5.659487838851388,
      "grad_norm": 0.01299378927797079,
      "learning_rate": 8.681024322297225e-06,
      "loss": 0.0015,
      "step": 52820
    },
    {
      "epoch": 5.660559305689489,
      "grad_norm": 0.02077706716954708,
      "learning_rate": 8.678881388621024e-06,
      "loss": 0.1574,
      "step": 52830
    },
    {
      "epoch": 5.66163077252759,
      "grad_norm": 0.0021569733507931232,
      "learning_rate": 8.67673845494482e-06,
      "loss": 0.2313,
      "step": 52840
    },
    {
      "epoch": 5.662702239365691,
      "grad_norm": 0.024553891271352768,
      "learning_rate": 8.674595521268617e-06,
      "loss": 0.0003,
      "step": 52850
    },
    {
      "epoch": 5.663773706203793,
      "grad_norm": 0.0773606225848198,
      "learning_rate": 8.672452587592414e-06,
      "loss": 0.001,
      "step": 52860
    },
    {
      "epoch": 5.664845173041894,
      "grad_norm": 0.004536715801805258,
      "learning_rate": 8.670309653916212e-06,
      "loss": 0.1716,
      "step": 52870
    },
    {
      "epoch": 5.665916639879995,
      "grad_norm": 18.953054428100586,
      "learning_rate": 8.66816672024001e-06,
      "loss": 0.17,
      "step": 52880
    },
    {
      "epoch": 5.666988106718097,
      "grad_norm": 0.10743100941181183,
      "learning_rate": 8.666023786563807e-06,
      "loss": 0.0006,
      "step": 52890
    },
    {
      "epoch": 5.6680595735561985,
      "grad_norm": 0.04601501673460007,
      "learning_rate": 8.663880852887604e-06,
      "loss": 0.1757,
      "step": 52900
    },
    {
      "epoch": 5.6691310403943,
      "grad_norm": 0.0158571507781744,
      "learning_rate": 8.661737919211401e-06,
      "loss": 0.0021,
      "step": 52910
    },
    {
      "epoch": 5.670202507232402,
      "grad_norm": 17.490629196166992,
      "learning_rate": 8.659594985535199e-06,
      "loss": 0.2078,
      "step": 52920
    },
    {
      "epoch": 5.671273974070503,
      "grad_norm": 0.05424778535962105,
      "learning_rate": 8.657452051858996e-06,
      "loss": 0.001,
      "step": 52930
    },
    {
      "epoch": 5.672345440908604,
      "grad_norm": 0.1452530473470688,
      "learning_rate": 8.655309118182793e-06,
      "loss": 0.0007,
      "step": 52940
    },
    {
      "epoch": 5.673416907746705,
      "grad_norm": 0.008723154664039612,
      "learning_rate": 8.65316618450659e-06,
      "loss": 0.1995,
      "step": 52950
    },
    {
      "epoch": 5.674488374584807,
      "grad_norm": 0.0012899675639346242,
      "learning_rate": 8.651023250830386e-06,
      "loss": 0.0004,
      "step": 52960
    },
    {
      "epoch": 5.675559841422908,
      "grad_norm": 0.026176461949944496,
      "learning_rate": 8.648880317154185e-06,
      "loss": 0.1766,
      "step": 52970
    },
    {
      "epoch": 5.676631308261009,
      "grad_norm": 0.12674576044082642,
      "learning_rate": 8.646737383477983e-06,
      "loss": 0.001,
      "step": 52980
    },
    {
      "epoch": 5.67770277509911,
      "grad_norm": 14.427610397338867,
      "learning_rate": 8.64459444980178e-06,
      "loss": 0.2025,
      "step": 52990
    },
    {
      "epoch": 5.678774241937212,
      "grad_norm": 0.005881591700017452,
      "learning_rate": 8.642451516125576e-06,
      "loss": 0.0024,
      "step": 53000
    },
    {
      "epoch": 5.679845708775313,
      "grad_norm": 0.09426294267177582,
      "learning_rate": 8.640308582449373e-06,
      "loss": 0.1216,
      "step": 53010
    },
    {
      "epoch": 5.6809171756134145,
      "grad_norm": 0.0014071440091356635,
      "learning_rate": 8.638165648773172e-06,
      "loss": 0.3183,
      "step": 53020
    },
    {
      "epoch": 5.6819886424515165,
      "grad_norm": 0.002647459739819169,
      "learning_rate": 8.63602271509697e-06,
      "loss": 0.0169,
      "step": 53030
    },
    {
      "epoch": 5.683060109289618,
      "grad_norm": 0.003716884646564722,
      "learning_rate": 8.633879781420765e-06,
      "loss": 0.239,
      "step": 53040
    },
    {
      "epoch": 5.684131576127719,
      "grad_norm": 0.011213576421141624,
      "learning_rate": 8.631736847744563e-06,
      "loss": 0.1624,
      "step": 53050
    },
    {
      "epoch": 5.685203042965821,
      "grad_norm": 0.04423286393284798,
      "learning_rate": 8.62959391406836e-06,
      "loss": 0.0013,
      "step": 53060
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 0.0115007059648633,
      "learning_rate": 8.627450980392157e-06,
      "loss": 0.0013,
      "step": 53070
    },
    {
      "epoch": 5.687345976642023,
      "grad_norm": 0.012473524548113346,
      "learning_rate": 8.625308046715955e-06,
      "loss": 0.1666,
      "step": 53080
    },
    {
      "epoch": 5.688417443480124,
      "grad_norm": 0.013323511928319931,
      "learning_rate": 8.623165113039752e-06,
      "loss": 0.1305,
      "step": 53090
    },
    {
      "epoch": 5.689488910318226,
      "grad_norm": 0.0073218210600316525,
      "learning_rate": 8.62102217936355e-06,
      "loss": 0.0016,
      "step": 53100
    },
    {
      "epoch": 5.690560377156327,
      "grad_norm": 0.008338612504303455,
      "learning_rate": 8.618879245687347e-06,
      "loss": 0.3499,
      "step": 53110
    },
    {
      "epoch": 5.691631843994428,
      "grad_norm": 0.011027821339666843,
      "learning_rate": 8.616736312011144e-06,
      "loss": 0.366,
      "step": 53120
    },
    {
      "epoch": 5.692703310832529,
      "grad_norm": 16.925148010253906,
      "learning_rate": 8.614593378334941e-06,
      "loss": 0.3035,
      "step": 53130
    },
    {
      "epoch": 5.693774777670631,
      "grad_norm": 35.72910690307617,
      "learning_rate": 8.612450444658739e-06,
      "loss": 0.2908,
      "step": 53140
    },
    {
      "epoch": 5.6948462445087324,
      "grad_norm": 0.006801097188144922,
      "learning_rate": 8.610307510982536e-06,
      "loss": 0.0082,
      "step": 53150
    },
    {
      "epoch": 5.695917711346834,
      "grad_norm": 0.04390304535627365,
      "learning_rate": 8.608164577306333e-06,
      "loss": 0.1172,
      "step": 53160
    },
    {
      "epoch": 5.6969891781849356,
      "grad_norm": 0.020635316148400307,
      "learning_rate": 8.60602164363013e-06,
      "loss": 0.0007,
      "step": 53170
    },
    {
      "epoch": 5.698060645023037,
      "grad_norm": 0.0033413670025765896,
      "learning_rate": 8.603878709953928e-06,
      "loss": 0.003,
      "step": 53180
    },
    {
      "epoch": 5.699132111861138,
      "grad_norm": 0.017700070515275,
      "learning_rate": 8.601735776277726e-06,
      "loss": 0.0014,
      "step": 53190
    },
    {
      "epoch": 5.700203578699239,
      "grad_norm": 0.0036597251892089844,
      "learning_rate": 8.599592842601521e-06,
      "loss": 0.1409,
      "step": 53200
    },
    {
      "epoch": 5.701275045537341,
      "grad_norm": 0.06690676510334015,
      "learning_rate": 8.59744990892532e-06,
      "loss": 0.0007,
      "step": 53210
    },
    {
      "epoch": 5.702346512375442,
      "grad_norm": 0.05469220504164696,
      "learning_rate": 8.595306975249118e-06,
      "loss": 0.0006,
      "step": 53220
    },
    {
      "epoch": 5.703417979213543,
      "grad_norm": 0.13770078122615814,
      "learning_rate": 8.593164041572915e-06,
      "loss": 0.0027,
      "step": 53230
    },
    {
      "epoch": 5.704489446051644,
      "grad_norm": 0.17863310873508453,
      "learning_rate": 8.59102110789671e-06,
      "loss": 0.2098,
      "step": 53240
    },
    {
      "epoch": 5.705560912889746,
      "grad_norm": 0.001053516403771937,
      "learning_rate": 8.588878174220508e-06,
      "loss": 0.001,
      "step": 53250
    },
    {
      "epoch": 5.706632379727847,
      "grad_norm": 0.004474208690226078,
      "learning_rate": 8.586735240544305e-06,
      "loss": 0.0006,
      "step": 53260
    },
    {
      "epoch": 5.707703846565948,
      "grad_norm": 0.0007031740387901664,
      "learning_rate": 8.584592306868104e-06,
      "loss": 0.1725,
      "step": 53270
    },
    {
      "epoch": 5.70877531340405,
      "grad_norm": 0.03350592777132988,
      "learning_rate": 8.5824493731919e-06,
      "loss": 0.0004,
      "step": 53280
    },
    {
      "epoch": 5.7098467802421515,
      "grad_norm": 0.008063023909926414,
      "learning_rate": 8.580306439515697e-06,
      "loss": 0.0002,
      "step": 53290
    },
    {
      "epoch": 5.710918247080253,
      "grad_norm": 20.33301544189453,
      "learning_rate": 8.578163505839495e-06,
      "loss": 0.004,
      "step": 53300
    },
    {
      "epoch": 5.711989713918355,
      "grad_norm": 0.0020567569881677628,
      "learning_rate": 8.576020572163292e-06,
      "loss": 0.1464,
      "step": 53310
    },
    {
      "epoch": 5.713061180756456,
      "grad_norm": 0.003020143834874034,
      "learning_rate": 8.57387763848709e-06,
      "loss": 0.3702,
      "step": 53320
    },
    {
      "epoch": 5.714132647594557,
      "grad_norm": 54.250545501708984,
      "learning_rate": 8.571734704810887e-06,
      "loss": 0.4872,
      "step": 53330
    },
    {
      "epoch": 5.715204114432658,
      "grad_norm": 0.5077683925628662,
      "learning_rate": 8.569591771134684e-06,
      "loss": 0.001,
      "step": 53340
    },
    {
      "epoch": 5.71627558127076,
      "grad_norm": 0.032927677035331726,
      "learning_rate": 8.567448837458482e-06,
      "loss": 0.2211,
      "step": 53350
    },
    {
      "epoch": 5.717347048108861,
      "grad_norm": 0.42130276560783386,
      "learning_rate": 8.565305903782279e-06,
      "loss": 0.18,
      "step": 53360
    },
    {
      "epoch": 5.718418514946962,
      "grad_norm": 0.029974011704325676,
      "learning_rate": 8.563162970106076e-06,
      "loss": 0.3163,
      "step": 53370
    },
    {
      "epoch": 5.719489981785063,
      "grad_norm": 0.11581900715827942,
      "learning_rate": 8.561020036429874e-06,
      "loss": 0.0429,
      "step": 53380
    },
    {
      "epoch": 5.720561448623165,
      "grad_norm": 0.09841830283403397,
      "learning_rate": 8.558877102753671e-06,
      "loss": 0.0015,
      "step": 53390
    },
    {
      "epoch": 5.721632915461266,
      "grad_norm": 0.06279884278774261,
      "learning_rate": 8.556734169077468e-06,
      "loss": 0.001,
      "step": 53400
    },
    {
      "epoch": 5.7227043822993675,
      "grad_norm": 0.02080761082470417,
      "learning_rate": 8.554591235401266e-06,
      "loss": 0.1741,
      "step": 53410
    },
    {
      "epoch": 5.7237758491374695,
      "grad_norm": 0.0009179603075608611,
      "learning_rate": 8.552448301725063e-06,
      "loss": 0.0022,
      "step": 53420
    },
    {
      "epoch": 5.724847315975571,
      "grad_norm": 0.022012483328580856,
      "learning_rate": 8.55030536804886e-06,
      "loss": 0.0003,
      "step": 53430
    },
    {
      "epoch": 5.725918782813672,
      "grad_norm": 0.006556261796504259,
      "learning_rate": 8.548162434372656e-06,
      "loss": 0.1752,
      "step": 53440
    },
    {
      "epoch": 5.726990249651774,
      "grad_norm": 0.001148795709013939,
      "learning_rate": 8.546019500696453e-06,
      "loss": 0.3937,
      "step": 53450
    },
    {
      "epoch": 5.728061716489875,
      "grad_norm": 0.20114630460739136,
      "learning_rate": 8.543876567020252e-06,
      "loss": 0.0011,
      "step": 53460
    },
    {
      "epoch": 5.729133183327976,
      "grad_norm": 0.004583999048918486,
      "learning_rate": 8.541733633344048e-06,
      "loss": 0.1233,
      "step": 53470
    },
    {
      "epoch": 5.730204650166077,
      "grad_norm": 0.001839561969973147,
      "learning_rate": 8.539590699667845e-06,
      "loss": 0.1788,
      "step": 53480
    },
    {
      "epoch": 5.731276117004179,
      "grad_norm": 0.001215986325405538,
      "learning_rate": 8.537447765991643e-06,
      "loss": 0.1946,
      "step": 53490
    },
    {
      "epoch": 5.73234758384228,
      "grad_norm": 0.0033862986601889133,
      "learning_rate": 8.53530483231544e-06,
      "loss": 0.368,
      "step": 53500
    },
    {
      "epoch": 5.733419050680381,
      "grad_norm": 0.0011926715960726142,
      "learning_rate": 8.533161898639238e-06,
      "loss": 0.0006,
      "step": 53510
    },
    {
      "epoch": 5.734490517518482,
      "grad_norm": 0.0014319808688014746,
      "learning_rate": 8.531018964963035e-06,
      "loss": 0.1823,
      "step": 53520
    },
    {
      "epoch": 5.735561984356584,
      "grad_norm": 0.0008342659566551447,
      "learning_rate": 8.528876031286832e-06,
      "loss": 0.1909,
      "step": 53530
    },
    {
      "epoch": 5.7366334511946855,
      "grad_norm": 0.08929258584976196,
      "learning_rate": 8.52673309761063e-06,
      "loss": 0.6517,
      "step": 53540
    },
    {
      "epoch": 5.737704918032787,
      "grad_norm": 59.800540924072266,
      "learning_rate": 8.524590163934427e-06,
      "loss": 0.2604,
      "step": 53550
    },
    {
      "epoch": 5.738776384870889,
      "grad_norm": 16.9838924407959,
      "learning_rate": 8.522447230258224e-06,
      "loss": 0.1396,
      "step": 53560
    },
    {
      "epoch": 5.73984785170899,
      "grad_norm": 0.26239171624183655,
      "learning_rate": 8.520304296582022e-06,
      "loss": 0.3473,
      "step": 53570
    },
    {
      "epoch": 5.740919318547091,
      "grad_norm": 0.5797224640846252,
      "learning_rate": 8.518161362905819e-06,
      "loss": 0.1694,
      "step": 53580
    },
    {
      "epoch": 5.741990785385193,
      "grad_norm": 0.047125428915023804,
      "learning_rate": 8.516018429229616e-06,
      "loss": 0.0024,
      "step": 53590
    },
    {
      "epoch": 5.743062252223294,
      "grad_norm": 0.014732043258845806,
      "learning_rate": 8.513875495553414e-06,
      "loss": 0.0015,
      "step": 53600
    },
    {
      "epoch": 5.744133719061395,
      "grad_norm": 0.36390167474746704,
      "learning_rate": 8.511732561877211e-06,
      "loss": 0.0014,
      "step": 53610
    },
    {
      "epoch": 5.745205185899496,
      "grad_norm": 0.005238526035100222,
      "learning_rate": 8.509589628201008e-06,
      "loss": 0.0003,
      "step": 53620
    },
    {
      "epoch": 5.746276652737598,
      "grad_norm": 0.03283779323101044,
      "learning_rate": 8.507446694524804e-06,
      "loss": 0.0011,
      "step": 53630
    },
    {
      "epoch": 5.747348119575699,
      "grad_norm": 0.0009679789072833955,
      "learning_rate": 8.505303760848601e-06,
      "loss": 0.0006,
      "step": 53640
    },
    {
      "epoch": 5.7484195864138,
      "grad_norm": 1.0918172597885132,
      "learning_rate": 8.5031608271724e-06,
      "loss": 0.1945,
      "step": 53650
    },
    {
      "epoch": 5.7494910532519015,
      "grad_norm": 0.04144400730729103,
      "learning_rate": 8.501017893496198e-06,
      "loss": 0.0002,
      "step": 53660
    },
    {
      "epoch": 5.7505625200900035,
      "grad_norm": 0.03821571543812752,
      "learning_rate": 8.498874959819994e-06,
      "loss": 0.0005,
      "step": 53670
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 0.051711611449718475,
      "learning_rate": 8.496732026143791e-06,
      "loss": 0.0005,
      "step": 53680
    },
    {
      "epoch": 5.752705453766206,
      "grad_norm": 0.004648095928132534,
      "learning_rate": 8.494589092467588e-06,
      "loss": 0.0005,
      "step": 53690
    },
    {
      "epoch": 5.753776920604308,
      "grad_norm": 27.487239837646484,
      "learning_rate": 8.492446158791387e-06,
      "loss": 0.2363,
      "step": 53700
    },
    {
      "epoch": 5.754848387442409,
      "grad_norm": 0.009882910177111626,
      "learning_rate": 8.490303225115183e-06,
      "loss": 0.4601,
      "step": 53710
    },
    {
      "epoch": 5.75591985428051,
      "grad_norm": 0.027543557807803154,
      "learning_rate": 8.48816029143898e-06,
      "loss": 0.4459,
      "step": 53720
    },
    {
      "epoch": 5.756991321118611,
      "grad_norm": 0.0016247291350737214,
      "learning_rate": 8.486017357762778e-06,
      "loss": 0.1918,
      "step": 53730
    },
    {
      "epoch": 5.758062787956713,
      "grad_norm": 0.03195999562740326,
      "learning_rate": 8.483874424086575e-06,
      "loss": 0.0027,
      "step": 53740
    },
    {
      "epoch": 5.759134254794814,
      "grad_norm": 0.037303026765584946,
      "learning_rate": 8.481731490410372e-06,
      "loss": 0.0005,
      "step": 53750
    },
    {
      "epoch": 5.760205721632915,
      "grad_norm": 0.02882557548582554,
      "learning_rate": 8.47958855673417e-06,
      "loss": 0.0019,
      "step": 53760
    },
    {
      "epoch": 5.761277188471016,
      "grad_norm": 65.34935760498047,
      "learning_rate": 8.477445623057967e-06,
      "loss": 0.2792,
      "step": 53770
    },
    {
      "epoch": 5.762348655309118,
      "grad_norm": 0.003176730126142502,
      "learning_rate": 8.475302689381764e-06,
      "loss": 0.0001,
      "step": 53780
    },
    {
      "epoch": 5.763420122147219,
      "grad_norm": 0.005092521198093891,
      "learning_rate": 8.473159755705562e-06,
      "loss": 0.181,
      "step": 53790
    },
    {
      "epoch": 5.7644915889853205,
      "grad_norm": 0.10573446750640869,
      "learning_rate": 8.471016822029359e-06,
      "loss": 0.0006,
      "step": 53800
    },
    {
      "epoch": 5.7655630558234225,
      "grad_norm": 0.007939726114273071,
      "learning_rate": 8.468873888353156e-06,
      "loss": 0.1398,
      "step": 53810
    },
    {
      "epoch": 5.766634522661524,
      "grad_norm": 38.3178596496582,
      "learning_rate": 8.466730954676954e-06,
      "loss": 0.5293,
      "step": 53820
    },
    {
      "epoch": 5.767705989499625,
      "grad_norm": 0.0011526038870215416,
      "learning_rate": 8.46458802100075e-06,
      "loss": 0.2886,
      "step": 53830
    },
    {
      "epoch": 5.768777456337727,
      "grad_norm": 36.67018127441406,
      "learning_rate": 8.462445087324549e-06,
      "loss": 0.4037,
      "step": 53840
    },
    {
      "epoch": 5.769848923175828,
      "grad_norm": 0.08388356119394302,
      "learning_rate": 8.460302153648346e-06,
      "loss": 0.0011,
      "step": 53850
    },
    {
      "epoch": 5.770920390013929,
      "grad_norm": 0.07471290975809097,
      "learning_rate": 8.458159219972143e-06,
      "loss": 0.6313,
      "step": 53860
    },
    {
      "epoch": 5.77199185685203,
      "grad_norm": 0.0959225594997406,
      "learning_rate": 8.456016286295939e-06,
      "loss": 0.0034,
      "step": 53870
    },
    {
      "epoch": 5.773063323690132,
      "grad_norm": 0.04965541139245033,
      "learning_rate": 8.453873352619736e-06,
      "loss": 0.1517,
      "step": 53880
    },
    {
      "epoch": 5.774134790528233,
      "grad_norm": 0.02427018992602825,
      "learning_rate": 8.451730418943535e-06,
      "loss": 0.0014,
      "step": 53890
    },
    {
      "epoch": 5.775206257366334,
      "grad_norm": 0.11087298393249512,
      "learning_rate": 8.449587485267333e-06,
      "loss": 0.001,
      "step": 53900
    },
    {
      "epoch": 5.776277724204435,
      "grad_norm": 0.018133088946342468,
      "learning_rate": 8.447444551591128e-06,
      "loss": 0.2388,
      "step": 53910
    },
    {
      "epoch": 5.777349191042537,
      "grad_norm": 0.011364216916263103,
      "learning_rate": 8.445301617914926e-06,
      "loss": 0.1629,
      "step": 53920
    },
    {
      "epoch": 5.7784206578806385,
      "grad_norm": 0.0325440838932991,
      "learning_rate": 8.443158684238723e-06,
      "loss": 0.1866,
      "step": 53930
    },
    {
      "epoch": 5.77949212471874,
      "grad_norm": 0.001658427412621677,
      "learning_rate": 8.44101575056252e-06,
      "loss": 0.3741,
      "step": 53940
    },
    {
      "epoch": 5.780563591556842,
      "grad_norm": 0.0035819150507450104,
      "learning_rate": 8.438872816886318e-06,
      "loss": 0.1995,
      "step": 53950
    },
    {
      "epoch": 5.781635058394943,
      "grad_norm": 0.4519706070423126,
      "learning_rate": 8.436729883210115e-06,
      "loss": 0.0014,
      "step": 53960
    },
    {
      "epoch": 5.782706525233044,
      "grad_norm": 0.06570205092430115,
      "learning_rate": 8.434586949533912e-06,
      "loss": 0.0009,
      "step": 53970
    },
    {
      "epoch": 5.783777992071146,
      "grad_norm": 0.004137818235903978,
      "learning_rate": 8.43244401585771e-06,
      "loss": 0.3692,
      "step": 53980
    },
    {
      "epoch": 5.784849458909247,
      "grad_norm": 0.036554012447595596,
      "learning_rate": 8.430301082181507e-06,
      "loss": 0.1805,
      "step": 53990
    },
    {
      "epoch": 5.785920925747348,
      "grad_norm": 0.1742798388004303,
      "learning_rate": 8.428158148505305e-06,
      "loss": 0.1673,
      "step": 54000
    },
    {
      "epoch": 5.786992392585449,
      "grad_norm": 0.005364696495234966,
      "learning_rate": 8.426015214829102e-06,
      "loss": 0.0003,
      "step": 54010
    },
    {
      "epoch": 5.788063859423551,
      "grad_norm": 0.04943755641579628,
      "learning_rate": 8.4238722811529e-06,
      "loss": 0.0021,
      "step": 54020
    },
    {
      "epoch": 5.789135326261652,
      "grad_norm": 0.06817985326051712,
      "learning_rate": 8.421729347476697e-06,
      "loss": 0.2444,
      "step": 54030
    },
    {
      "epoch": 5.790206793099753,
      "grad_norm": 0.0017523069400340319,
      "learning_rate": 8.419586413800494e-06,
      "loss": 0.0005,
      "step": 54040
    },
    {
      "epoch": 5.7912782599378545,
      "grad_norm": 0.0073465206660330296,
      "learning_rate": 8.417443480124291e-06,
      "loss": 0.2185,
      "step": 54050
    },
    {
      "epoch": 5.7923497267759565,
      "grad_norm": 0.0348396897315979,
      "learning_rate": 8.415300546448089e-06,
      "loss": 0.1281,
      "step": 54060
    },
    {
      "epoch": 5.793421193614058,
      "grad_norm": 17.445898056030273,
      "learning_rate": 8.413157612771884e-06,
      "loss": 0.3366,
      "step": 54070
    },
    {
      "epoch": 5.794492660452159,
      "grad_norm": 35.38969802856445,
      "learning_rate": 8.411014679095683e-06,
      "loss": 0.4702,
      "step": 54080
    },
    {
      "epoch": 5.795564127290261,
      "grad_norm": 0.01435832679271698,
      "learning_rate": 8.40887174541948e-06,
      "loss": 0.1615,
      "step": 54090
    },
    {
      "epoch": 5.796635594128362,
      "grad_norm": 0.17237916588783264,
      "learning_rate": 8.406728811743278e-06,
      "loss": 0.0031,
      "step": 54100
    },
    {
      "epoch": 5.797707060966463,
      "grad_norm": 0.0011613513343036175,
      "learning_rate": 8.404585878067074e-06,
      "loss": 0.0008,
      "step": 54110
    },
    {
      "epoch": 5.798778527804565,
      "grad_norm": 0.0016729471972212195,
      "learning_rate": 8.402442944390871e-06,
      "loss": 0.0003,
      "step": 54120
    },
    {
      "epoch": 5.799849994642666,
      "grad_norm": 0.06974001973867416,
      "learning_rate": 8.400300010714668e-06,
      "loss": 0.0034,
      "step": 54130
    },
    {
      "epoch": 5.800921461480767,
      "grad_norm": 0.0029968256130814552,
      "learning_rate": 8.398157077038468e-06,
      "loss": 0.153,
      "step": 54140
    },
    {
      "epoch": 5.801992928318868,
      "grad_norm": 0.0007257818942889571,
      "learning_rate": 8.396014143362263e-06,
      "loss": 0.1274,
      "step": 54150
    },
    {
      "epoch": 5.80306439515697,
      "grad_norm": 23.20133399963379,
      "learning_rate": 8.39387120968606e-06,
      "loss": 0.7418,
      "step": 54160
    },
    {
      "epoch": 5.804135861995071,
      "grad_norm": 0.08039955049753189,
      "learning_rate": 8.391728276009858e-06,
      "loss": 0.5234,
      "step": 54170
    },
    {
      "epoch": 5.8052073288331725,
      "grad_norm": 0.005799111444503069,
      "learning_rate": 8.389585342333655e-06,
      "loss": 0.0011,
      "step": 54180
    },
    {
      "epoch": 5.806278795671274,
      "grad_norm": 0.013038859702646732,
      "learning_rate": 8.387442408657453e-06,
      "loss": 0.0007,
      "step": 54190
    },
    {
      "epoch": 5.807350262509376,
      "grad_norm": 0.02928873710334301,
      "learning_rate": 8.38529947498125e-06,
      "loss": 0.001,
      "step": 54200
    },
    {
      "epoch": 5.808421729347477,
      "grad_norm": 0.010728627443313599,
      "learning_rate": 8.383156541305047e-06,
      "loss": 0.1538,
      "step": 54210
    },
    {
      "epoch": 5.809493196185578,
      "grad_norm": 0.31377971172332764,
      "learning_rate": 8.381013607628845e-06,
      "loss": 0.0122,
      "step": 54220
    },
    {
      "epoch": 5.81056466302368,
      "grad_norm": 43.76121520996094,
      "learning_rate": 8.378870673952642e-06,
      "loss": 0.17,
      "step": 54230
    },
    {
      "epoch": 5.811636129861781,
      "grad_norm": 0.036201294511556625,
      "learning_rate": 8.37672774027644e-06,
      "loss": 0.0011,
      "step": 54240
    },
    {
      "epoch": 5.812707596699882,
      "grad_norm": 0.00355173135176301,
      "learning_rate": 8.374584806600237e-06,
      "loss": 0.0009,
      "step": 54250
    },
    {
      "epoch": 5.813779063537983,
      "grad_norm": 0.001526932930573821,
      "learning_rate": 8.372441872924034e-06,
      "loss": 0.0021,
      "step": 54260
    },
    {
      "epoch": 5.814850530376085,
      "grad_norm": 0.005353323183953762,
      "learning_rate": 8.370298939247831e-06,
      "loss": 0.0005,
      "step": 54270
    },
    {
      "epoch": 5.815921997214186,
      "grad_norm": 0.13670238852500916,
      "learning_rate": 8.368156005571629e-06,
      "loss": 0.2003,
      "step": 54280
    },
    {
      "epoch": 5.816993464052287,
      "grad_norm": 0.0014021963579580188,
      "learning_rate": 8.366013071895426e-06,
      "loss": 0.0007,
      "step": 54290
    },
    {
      "epoch": 5.8180649308903885,
      "grad_norm": 0.05345655232667923,
      "learning_rate": 8.363870138219224e-06,
      "loss": 0.0004,
      "step": 54300
    },
    {
      "epoch": 5.8191363977284905,
      "grad_norm": 0.019041504710912704,
      "learning_rate": 8.36172720454302e-06,
      "loss": 0.2919,
      "step": 54310
    },
    {
      "epoch": 5.820207864566592,
      "grad_norm": 0.03326677531003952,
      "learning_rate": 8.359584270866817e-06,
      "loss": 0.3143,
      "step": 54320
    },
    {
      "epoch": 5.821279331404693,
      "grad_norm": 0.004350776318460703,
      "learning_rate": 8.357441337190616e-06,
      "loss": 0.3842,
      "step": 54330
    },
    {
      "epoch": 5.822350798242795,
      "grad_norm": 0.000997039140202105,
      "learning_rate": 8.355298403514413e-06,
      "loss": 0.1522,
      "step": 54340
    },
    {
      "epoch": 5.823422265080896,
      "grad_norm": 0.004138072021305561,
      "learning_rate": 8.353155469838209e-06,
      "loss": 0.0004,
      "step": 54350
    },
    {
      "epoch": 5.824493731918997,
      "grad_norm": 17.556211471557617,
      "learning_rate": 8.351012536162006e-06,
      "loss": 0.5561,
      "step": 54360
    },
    {
      "epoch": 5.825565198757099,
      "grad_norm": 0.018870152533054352,
      "learning_rate": 8.348869602485803e-06,
      "loss": 0.0013,
      "step": 54370
    },
    {
      "epoch": 5.8266366655952,
      "grad_norm": 0.003968429751694202,
      "learning_rate": 8.3467266688096e-06,
      "loss": 0.2117,
      "step": 54380
    },
    {
      "epoch": 5.827708132433301,
      "grad_norm": 0.07807984948158264,
      "learning_rate": 8.344583735133398e-06,
      "loss": 0.2971,
      "step": 54390
    },
    {
      "epoch": 5.828779599271402,
      "grad_norm": 0.007913959212601185,
      "learning_rate": 8.342440801457195e-06,
      "loss": 0.0021,
      "step": 54400
    },
    {
      "epoch": 5.829851066109504,
      "grad_norm": 0.395110160112381,
      "learning_rate": 8.340297867780993e-06,
      "loss": 0.1832,
      "step": 54410
    },
    {
      "epoch": 5.830922532947605,
      "grad_norm": 0.027954338118433952,
      "learning_rate": 8.33815493410479e-06,
      "loss": 0.0002,
      "step": 54420
    },
    {
      "epoch": 5.831993999785706,
      "grad_norm": 0.15182048082351685,
      "learning_rate": 8.336012000428587e-06,
      "loss": 0.0016,
      "step": 54430
    },
    {
      "epoch": 5.8330654666238075,
      "grad_norm": 0.007316713221371174,
      "learning_rate": 8.333869066752385e-06,
      "loss": 0.001,
      "step": 54440
    },
    {
      "epoch": 5.8341369334619095,
      "grad_norm": 0.10430086404085159,
      "learning_rate": 8.331726133076182e-06,
      "loss": 0.0003,
      "step": 54450
    },
    {
      "epoch": 5.835208400300011,
      "grad_norm": 0.021469492465257645,
      "learning_rate": 8.32958319939998e-06,
      "loss": 0.0006,
      "step": 54460
    },
    {
      "epoch": 5.836279867138112,
      "grad_norm": 0.08810869604349136,
      "learning_rate": 8.327440265723777e-06,
      "loss": 0.1704,
      "step": 54470
    },
    {
      "epoch": 5.837351333976214,
      "grad_norm": 0.061323750764131546,
      "learning_rate": 8.325297332047574e-06,
      "loss": 0.4082,
      "step": 54480
    },
    {
      "epoch": 5.838422800814315,
      "grad_norm": 0.08367224782705307,
      "learning_rate": 8.323154398371372e-06,
      "loss": 0.199,
      "step": 54490
    },
    {
      "epoch": 5.839494267652416,
      "grad_norm": 0.0030933041125535965,
      "learning_rate": 8.321011464695167e-06,
      "loss": 0.0008,
      "step": 54500
    },
    {
      "epoch": 5.840565734490518,
      "grad_norm": 0.008698082529008389,
      "learning_rate": 8.318868531018965e-06,
      "loss": 0.1946,
      "step": 54510
    },
    {
      "epoch": 5.841637201328619,
      "grad_norm": 0.0009785911533981562,
      "learning_rate": 8.316725597342764e-06,
      "loss": 0.1209,
      "step": 54520
    },
    {
      "epoch": 5.84270866816672,
      "grad_norm": 0.00632454315200448,
      "learning_rate": 8.314582663666561e-06,
      "loss": 0.2306,
      "step": 54530
    },
    {
      "epoch": 5.843780135004821,
      "grad_norm": 0.026417771354317665,
      "learning_rate": 8.312439729990357e-06,
      "loss": 0.1932,
      "step": 54540
    },
    {
      "epoch": 5.844851601842923,
      "grad_norm": 0.003651030594483018,
      "learning_rate": 8.310296796314154e-06,
      "loss": 0.1664,
      "step": 54550
    },
    {
      "epoch": 5.845923068681024,
      "grad_norm": 0.003635105909779668,
      "learning_rate": 8.308153862637951e-06,
      "loss": 0.1571,
      "step": 54560
    },
    {
      "epoch": 5.8469945355191255,
      "grad_norm": 0.09778600931167603,
      "learning_rate": 8.30601092896175e-06,
      "loss": 0.0425,
      "step": 54570
    },
    {
      "epoch": 5.848066002357227,
      "grad_norm": 0.001228293520398438,
      "learning_rate": 8.303867995285546e-06,
      "loss": 0.001,
      "step": 54580
    },
    {
      "epoch": 5.849137469195329,
      "grad_norm": 0.03896872326731682,
      "learning_rate": 8.301725061609343e-06,
      "loss": 0.1348,
      "step": 54590
    },
    {
      "epoch": 5.85020893603343,
      "grad_norm": 0.0008535557426512241,
      "learning_rate": 8.29958212793314e-06,
      "loss": 0.0003,
      "step": 54600
    },
    {
      "epoch": 5.851280402871531,
      "grad_norm": 0.009989612735807896,
      "learning_rate": 8.297439194256938e-06,
      "loss": 0.304,
      "step": 54610
    },
    {
      "epoch": 5.852351869709633,
      "grad_norm": 0.08158717304468155,
      "learning_rate": 8.295296260580736e-06,
      "loss": 0.0014,
      "step": 54620
    },
    {
      "epoch": 5.853423336547734,
      "grad_norm": 0.0017362707294523716,
      "learning_rate": 8.293153326904533e-06,
      "loss": 0.1432,
      "step": 54630
    },
    {
      "epoch": 5.854494803385835,
      "grad_norm": 0.27933141589164734,
      "learning_rate": 8.29101039322833e-06,
      "loss": 0.0916,
      "step": 54640
    },
    {
      "epoch": 5.855566270223937,
      "grad_norm": 0.01370066124945879,
      "learning_rate": 8.288867459552128e-06,
      "loss": 0.0004,
      "step": 54650
    },
    {
      "epoch": 5.856637737062038,
      "grad_norm": 0.03579496219754219,
      "learning_rate": 8.286724525875925e-06,
      "loss": 0.0351,
      "step": 54660
    },
    {
      "epoch": 5.857709203900139,
      "grad_norm": 0.0014395095640793443,
      "learning_rate": 8.284581592199722e-06,
      "loss": 0.2236,
      "step": 54670
    },
    {
      "epoch": 5.85878067073824,
      "grad_norm": 0.5338338017463684,
      "learning_rate": 8.28243865852352e-06,
      "loss": 0.2001,
      "step": 54680
    },
    {
      "epoch": 5.859852137576342,
      "grad_norm": 0.004074478521943092,
      "learning_rate": 8.280295724847317e-06,
      "loss": 0.0001,
      "step": 54690
    },
    {
      "epoch": 5.8609236044144435,
      "grad_norm": 0.0003196597390342504,
      "learning_rate": 8.278152791171113e-06,
      "loss": 0.0003,
      "step": 54700
    },
    {
      "epoch": 5.861995071252545,
      "grad_norm": 0.005484788678586483,
      "learning_rate": 8.276009857494912e-06,
      "loss": 0.0,
      "step": 54710
    },
    {
      "epoch": 5.863066538090646,
      "grad_norm": 0.00041828880785033107,
      "learning_rate": 8.273866923818709e-06,
      "loss": 0.2905,
      "step": 54720
    },
    {
      "epoch": 5.864138004928748,
      "grad_norm": 0.019360149279236794,
      "learning_rate": 8.271723990142506e-06,
      "loss": 0.1391,
      "step": 54730
    },
    {
      "epoch": 5.865209471766849,
      "grad_norm": 82.12307739257812,
      "learning_rate": 8.269581056466302e-06,
      "loss": 0.1865,
      "step": 54740
    },
    {
      "epoch": 5.86628093860495,
      "grad_norm": 0.027004409581422806,
      "learning_rate": 8.2674381227901e-06,
      "loss": 0.0005,
      "step": 54750
    },
    {
      "epoch": 5.867352405443052,
      "grad_norm": 0.1281760036945343,
      "learning_rate": 8.265295189113899e-06,
      "loss": 0.1387,
      "step": 54760
    },
    {
      "epoch": 5.868423872281153,
      "grad_norm": 39.638004302978516,
      "learning_rate": 8.263152255437696e-06,
      "loss": 0.3647,
      "step": 54770
    },
    {
      "epoch": 5.869495339119254,
      "grad_norm": 0.012487978674471378,
      "learning_rate": 8.261009321761492e-06,
      "loss": 0.2454,
      "step": 54780
    },
    {
      "epoch": 5.870566805957355,
      "grad_norm": 0.16383928060531616,
      "learning_rate": 8.258866388085289e-06,
      "loss": 0.0006,
      "step": 54790
    },
    {
      "epoch": 5.871638272795457,
      "grad_norm": 0.026932699605822563,
      "learning_rate": 8.256723454409086e-06,
      "loss": 0.2635,
      "step": 54800
    },
    {
      "epoch": 5.872709739633558,
      "grad_norm": 0.00047771364916116,
      "learning_rate": 8.254580520732884e-06,
      "loss": 0.2183,
      "step": 54810
    },
    {
      "epoch": 5.8737812064716595,
      "grad_norm": 0.00044559998787008226,
      "learning_rate": 8.252437587056681e-06,
      "loss": 0.0007,
      "step": 54820
    },
    {
      "epoch": 5.874852673309761,
      "grad_norm": 0.015650225803256035,
      "learning_rate": 8.250294653380478e-06,
      "loss": 0.0004,
      "step": 54830
    },
    {
      "epoch": 5.875924140147863,
      "grad_norm": 0.013915156945586205,
      "learning_rate": 8.248151719704276e-06,
      "loss": 0.0003,
      "step": 54840
    },
    {
      "epoch": 5.876995606985964,
      "grad_norm": 0.00043679092777892947,
      "learning_rate": 8.246008786028073e-06,
      "loss": 0.0826,
      "step": 54850
    },
    {
      "epoch": 5.878067073824065,
      "grad_norm": 0.00031422360916621983,
      "learning_rate": 8.24386585235187e-06,
      "loss": 0.19,
      "step": 54860
    },
    {
      "epoch": 5.879138540662167,
      "grad_norm": 0.0005434973863884807,
      "learning_rate": 8.241722918675668e-06,
      "loss": 0.0007,
      "step": 54870
    },
    {
      "epoch": 5.880210007500268,
      "grad_norm": 0.0006483960314653814,
      "learning_rate": 8.239579984999465e-06,
      "loss": 0.0043,
      "step": 54880
    },
    {
      "epoch": 5.881281474338369,
      "grad_norm": 0.00042132503585889935,
      "learning_rate": 8.237437051323262e-06,
      "loss": 0.1648,
      "step": 54890
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.5492016077041626,
      "learning_rate": 8.23529411764706e-06,
      "loss": 0.0019,
      "step": 54900
    },
    {
      "epoch": 5.883424408014572,
      "grad_norm": 0.0013447942910715938,
      "learning_rate": 8.233151183970857e-06,
      "loss": 0.3802,
      "step": 54910
    },
    {
      "epoch": 5.884495874852673,
      "grad_norm": 0.3388010561466217,
      "learning_rate": 8.231008250294655e-06,
      "loss": 0.1989,
      "step": 54920
    },
    {
      "epoch": 5.885567341690774,
      "grad_norm": 0.00047217265819199383,
      "learning_rate": 8.228865316618452e-06,
      "loss": 0.0009,
      "step": 54930
    },
    {
      "epoch": 5.886638808528876,
      "grad_norm": 0.0011519173858687282,
      "learning_rate": 8.226722382942248e-06,
      "loss": 0.0006,
      "step": 54940
    },
    {
      "epoch": 5.887710275366977,
      "grad_norm": 0.00036544245085678995,
      "learning_rate": 8.224579449266047e-06,
      "loss": 0.0623,
      "step": 54950
    },
    {
      "epoch": 5.8887817422050786,
      "grad_norm": 0.018850792199373245,
      "learning_rate": 8.222436515589844e-06,
      "loss": 0.5746,
      "step": 54960
    },
    {
      "epoch": 5.88985320904318,
      "grad_norm": 0.02561653032898903,
      "learning_rate": 8.220293581913641e-06,
      "loss": 0.1658,
      "step": 54970
    },
    {
      "epoch": 5.890924675881282,
      "grad_norm": 0.0005587412160821259,
      "learning_rate": 8.218150648237437e-06,
      "loss": 0.1829,
      "step": 54980
    },
    {
      "epoch": 5.891996142719383,
      "grad_norm": 0.005756203085184097,
      "learning_rate": 8.216007714561234e-06,
      "loss": 0.1452,
      "step": 54990
    },
    {
      "epoch": 5.893067609557484,
      "grad_norm": 0.056587740778923035,
      "learning_rate": 8.213864780885032e-06,
      "loss": 0.0015,
      "step": 55000
    },
    {
      "epoch": 5.894139076395586,
      "grad_norm": 0.1407676488161087,
      "learning_rate": 8.21172184720883e-06,
      "loss": 0.0005,
      "step": 55010
    },
    {
      "epoch": 5.895210543233687,
      "grad_norm": 0.055582404136657715,
      "learning_rate": 8.209578913532626e-06,
      "loss": 0.0009,
      "step": 55020
    },
    {
      "epoch": 5.896282010071788,
      "grad_norm": 0.11620569974184036,
      "learning_rate": 8.207435979856424e-06,
      "loss": 0.0004,
      "step": 55030
    },
    {
      "epoch": 5.89735347690989,
      "grad_norm": 0.0003970021498389542,
      "learning_rate": 8.205293046180221e-06,
      "loss": 0.408,
      "step": 55040
    },
    {
      "epoch": 5.898424943747991,
      "grad_norm": 0.00035939013469032943,
      "learning_rate": 8.203150112504018e-06,
      "loss": 0.0011,
      "step": 55050
    },
    {
      "epoch": 5.899496410586092,
      "grad_norm": 0.00039216384175233543,
      "learning_rate": 8.201007178827816e-06,
      "loss": 0.0004,
      "step": 55060
    },
    {
      "epoch": 5.900567877424193,
      "grad_norm": 0.06606552004814148,
      "learning_rate": 8.198864245151613e-06,
      "loss": 0.0002,
      "step": 55070
    },
    {
      "epoch": 5.901639344262295,
      "grad_norm": 0.0009640139760449529,
      "learning_rate": 8.19672131147541e-06,
      "loss": 0.4891,
      "step": 55080
    },
    {
      "epoch": 5.9027108111003965,
      "grad_norm": 0.04363461583852768,
      "learning_rate": 8.194578377799208e-06,
      "loss": 0.0001,
      "step": 55090
    },
    {
      "epoch": 5.903782277938498,
      "grad_norm": 0.31806081533432007,
      "learning_rate": 8.192435444123005e-06,
      "loss": 0.0009,
      "step": 55100
    },
    {
      "epoch": 5.904853744776599,
      "grad_norm": 0.12302692234516144,
      "learning_rate": 8.190292510446803e-06,
      "loss": 0.204,
      "step": 55110
    },
    {
      "epoch": 5.905925211614701,
      "grad_norm": 0.0009199666092172265,
      "learning_rate": 8.1881495767706e-06,
      "loss": 0.4758,
      "step": 55120
    },
    {
      "epoch": 5.906996678452802,
      "grad_norm": 51.10495376586914,
      "learning_rate": 8.186006643094397e-06,
      "loss": 0.1995,
      "step": 55130
    },
    {
      "epoch": 5.908068145290903,
      "grad_norm": 0.005221434403210878,
      "learning_rate": 8.183863709418195e-06,
      "loss": 0.0514,
      "step": 55140
    },
    {
      "epoch": 5.909139612129005,
      "grad_norm": 0.016858557239174843,
      "learning_rate": 8.181720775741992e-06,
      "loss": 0.2989,
      "step": 55150
    },
    {
      "epoch": 5.910211078967106,
      "grad_norm": 0.02514922432601452,
      "learning_rate": 8.17957784206579e-06,
      "loss": 0.0005,
      "step": 55160
    },
    {
      "epoch": 5.911282545805207,
      "grad_norm": 0.13204032182693481,
      "learning_rate": 8.177434908389587e-06,
      "loss": 0.0025,
      "step": 55170
    },
    {
      "epoch": 5.912354012643309,
      "grad_norm": 0.04785018414258957,
      "learning_rate": 8.175291974713382e-06,
      "loss": 0.4118,
      "step": 55180
    },
    {
      "epoch": 5.91342547948141,
      "grad_norm": 0.008430195041000843,
      "learning_rate": 8.17314904103718e-06,
      "loss": 0.0019,
      "step": 55190
    },
    {
      "epoch": 5.914496946319511,
      "grad_norm": 0.007427166681736708,
      "learning_rate": 8.171006107360979e-06,
      "loss": 0.0009,
      "step": 55200
    },
    {
      "epoch": 5.9155684131576125,
      "grad_norm": 0.0043946970254182816,
      "learning_rate": 8.168863173684776e-06,
      "loss": 0.0016,
      "step": 55210
    },
    {
      "epoch": 5.9166398799957145,
      "grad_norm": 0.23463401198387146,
      "learning_rate": 8.166720240008572e-06,
      "loss": 0.0013,
      "step": 55220
    },
    {
      "epoch": 5.917711346833816,
      "grad_norm": 0.025284871459007263,
      "learning_rate": 8.164577306332369e-06,
      "loss": 0.5617,
      "step": 55230
    },
    {
      "epoch": 5.918782813671917,
      "grad_norm": 0.09430380165576935,
      "learning_rate": 8.162434372656167e-06,
      "loss": 0.2222,
      "step": 55240
    },
    {
      "epoch": 5.919854280510018,
      "grad_norm": 0.0018694923492148519,
      "learning_rate": 8.160291438979966e-06,
      "loss": 0.0022,
      "step": 55250
    },
    {
      "epoch": 5.92092574734812,
      "grad_norm": 0.01572687365114689,
      "learning_rate": 8.158148505303761e-06,
      "loss": 0.0005,
      "step": 55260
    },
    {
      "epoch": 5.921997214186221,
      "grad_norm": 0.007796100806444883,
      "learning_rate": 8.156005571627559e-06,
      "loss": 0.4506,
      "step": 55270
    },
    {
      "epoch": 5.923068681024322,
      "grad_norm": 168.27061462402344,
      "learning_rate": 8.153862637951356e-06,
      "loss": 0.4389,
      "step": 55280
    },
    {
      "epoch": 5.924140147862424,
      "grad_norm": 0.1313345730304718,
      "learning_rate": 8.151719704275153e-06,
      "loss": 0.1168,
      "step": 55290
    },
    {
      "epoch": 5.925211614700525,
      "grad_norm": 0.14890509843826294,
      "learning_rate": 8.14957677059895e-06,
      "loss": 0.0159,
      "step": 55300
    },
    {
      "epoch": 5.926283081538626,
      "grad_norm": 0.019486814737319946,
      "learning_rate": 8.147433836922748e-06,
      "loss": 0.3763,
      "step": 55310
    },
    {
      "epoch": 5.927354548376727,
      "grad_norm": 0.0032397566828876734,
      "learning_rate": 8.145290903246545e-06,
      "loss": 0.1722,
      "step": 55320
    },
    {
      "epoch": 5.928426015214829,
      "grad_norm": 0.006418622564524412,
      "learning_rate": 8.143147969570343e-06,
      "loss": 0.1661,
      "step": 55330
    },
    {
      "epoch": 5.9294974820529305,
      "grad_norm": 0.0006720960373058915,
      "learning_rate": 8.14100503589414e-06,
      "loss": 0.0015,
      "step": 55340
    },
    {
      "epoch": 5.930568948891032,
      "grad_norm": 0.05852203443646431,
      "learning_rate": 8.138862102217937e-06,
      "loss": 0.0007,
      "step": 55350
    },
    {
      "epoch": 5.931640415729133,
      "grad_norm": 0.0023824796080589294,
      "learning_rate": 8.136719168541735e-06,
      "loss": 0.1277,
      "step": 55360
    },
    {
      "epoch": 5.932711882567235,
      "grad_norm": 0.0021801467519253492,
      "learning_rate": 8.13457623486553e-06,
      "loss": 0.364,
      "step": 55370
    },
    {
      "epoch": 5.933783349405336,
      "grad_norm": 0.09115045517683029,
      "learning_rate": 8.132433301189328e-06,
      "loss": 0.1376,
      "step": 55380
    },
    {
      "epoch": 5.934854816243437,
      "grad_norm": 0.03373701125383377,
      "learning_rate": 8.130290367513127e-06,
      "loss": 0.0015,
      "step": 55390
    },
    {
      "epoch": 5.935926283081539,
      "grad_norm": 0.0012282445095479488,
      "learning_rate": 8.128147433836924e-06,
      "loss": 0.0013,
      "step": 55400
    },
    {
      "epoch": 5.93699774991964,
      "grad_norm": 0.051750946789979935,
      "learning_rate": 8.12600450016072e-06,
      "loss": 0.0002,
      "step": 55410
    },
    {
      "epoch": 5.938069216757741,
      "grad_norm": 0.0022292975336313248,
      "learning_rate": 8.123861566484517e-06,
      "loss": 0.4449,
      "step": 55420
    },
    {
      "epoch": 5.939140683595843,
      "grad_norm": 0.04083912447094917,
      "learning_rate": 8.121718632808315e-06,
      "loss": 0.1134,
      "step": 55430
    },
    {
      "epoch": 5.940212150433944,
      "grad_norm": 50.16473388671875,
      "learning_rate": 8.119575699132114e-06,
      "loss": 0.1675,
      "step": 55440
    },
    {
      "epoch": 5.941283617272045,
      "grad_norm": 0.009136724285781384,
      "learning_rate": 8.11743276545591e-06,
      "loss": 0.0248,
      "step": 55450
    },
    {
      "epoch": 5.9423550841101465,
      "grad_norm": 0.011831113137304783,
      "learning_rate": 8.115289831779707e-06,
      "loss": 0.2709,
      "step": 55460
    },
    {
      "epoch": 5.9434265509482485,
      "grad_norm": 0.02680450864136219,
      "learning_rate": 8.113146898103504e-06,
      "loss": 0.2591,
      "step": 55470
    },
    {
      "epoch": 5.94449801778635,
      "grad_norm": 0.029684308916330338,
      "learning_rate": 8.111003964427301e-06,
      "loss": 0.0008,
      "step": 55480
    },
    {
      "epoch": 5.945569484624451,
      "grad_norm": 0.16370053589344025,
      "learning_rate": 8.108861030751099e-06,
      "loss": 0.0014,
      "step": 55490
    },
    {
      "epoch": 5.946640951462552,
      "grad_norm": 0.04811249300837517,
      "learning_rate": 8.106718097074896e-06,
      "loss": 0.0006,
      "step": 55500
    },
    {
      "epoch": 5.947712418300654,
      "grad_norm": 0.17278483510017395,
      "learning_rate": 8.104575163398693e-06,
      "loss": 0.0007,
      "step": 55510
    },
    {
      "epoch": 5.948783885138755,
      "grad_norm": 0.014567432925105095,
      "learning_rate": 8.10243222972249e-06,
      "loss": 0.0009,
      "step": 55520
    },
    {
      "epoch": 5.949855351976856,
      "grad_norm": 0.007937374524772167,
      "learning_rate": 8.100289296046288e-06,
      "loss": 0.2974,
      "step": 55530
    },
    {
      "epoch": 5.950926818814958,
      "grad_norm": 0.0018453552620485425,
      "learning_rate": 8.098146362370085e-06,
      "loss": 0.0008,
      "step": 55540
    },
    {
      "epoch": 5.951998285653059,
      "grad_norm": 0.34058645367622375,
      "learning_rate": 8.096003428693883e-06,
      "loss": 0.0008,
      "step": 55550
    },
    {
      "epoch": 5.95306975249116,
      "grad_norm": 1.0637571811676025,
      "learning_rate": 8.09386049501768e-06,
      "loss": 0.1531,
      "step": 55560
    },
    {
      "epoch": 5.954141219329262,
      "grad_norm": 0.003045877441763878,
      "learning_rate": 8.091717561341476e-06,
      "loss": 0.0426,
      "step": 55570
    },
    {
      "epoch": 5.955212686167363,
      "grad_norm": 0.0005472236080095172,
      "learning_rate": 8.089574627665275e-06,
      "loss": 0.5653,
      "step": 55580
    },
    {
      "epoch": 5.956284153005464,
      "grad_norm": 23.55277442932129,
      "learning_rate": 8.087431693989072e-06,
      "loss": 0.3705,
      "step": 55590
    },
    {
      "epoch": 5.9573556198435655,
      "grad_norm": 0.1933375597000122,
      "learning_rate": 8.08528876031287e-06,
      "loss": 0.4421,
      "step": 55600
    },
    {
      "epoch": 5.9584270866816675,
      "grad_norm": 0.005542903207242489,
      "learning_rate": 8.083145826636665e-06,
      "loss": 0.0011,
      "step": 55610
    },
    {
      "epoch": 5.959498553519769,
      "grad_norm": 0.06268585473299026,
      "learning_rate": 8.081002892960463e-06,
      "loss": 0.0007,
      "step": 55620
    },
    {
      "epoch": 5.96057002035787,
      "grad_norm": 0.05215325206518173,
      "learning_rate": 8.078859959284262e-06,
      "loss": 0.0006,
      "step": 55630
    },
    {
      "epoch": 5.961641487195971,
      "grad_norm": 0.029909290373325348,
      "learning_rate": 8.076717025608059e-06,
      "loss": 0.0008,
      "step": 55640
    },
    {
      "epoch": 5.962712954034073,
      "grad_norm": 0.00100874830968678,
      "learning_rate": 8.074574091931855e-06,
      "loss": 0.0005,
      "step": 55650
    },
    {
      "epoch": 5.963784420872174,
      "grad_norm": 0.011291283182799816,
      "learning_rate": 8.072431158255652e-06,
      "loss": 0.0008,
      "step": 55660
    },
    {
      "epoch": 5.964855887710275,
      "grad_norm": 0.015794547274708748,
      "learning_rate": 8.07028822457945e-06,
      "loss": 0.0006,
      "step": 55670
    },
    {
      "epoch": 5.965927354548377,
      "grad_norm": 0.0006125125219114125,
      "learning_rate": 8.068145290903247e-06,
      "loss": 0.208,
      "step": 55680
    },
    {
      "epoch": 5.966998821386478,
      "grad_norm": 0.015460368245840073,
      "learning_rate": 8.066002357227044e-06,
      "loss": 0.1504,
      "step": 55690
    },
    {
      "epoch": 5.968070288224579,
      "grad_norm": 0.0010233743814751506,
      "learning_rate": 8.063859423550841e-06,
      "loss": 0.0005,
      "step": 55700
    },
    {
      "epoch": 5.969141755062681,
      "grad_norm": 0.014172086492180824,
      "learning_rate": 8.061716489874639e-06,
      "loss": 0.2926,
      "step": 55710
    },
    {
      "epoch": 5.970213221900782,
      "grad_norm": 0.0098539674654603,
      "learning_rate": 8.059573556198436e-06,
      "loss": 0.187,
      "step": 55720
    },
    {
      "epoch": 5.9712846887388835,
      "grad_norm": 0.005177544429898262,
      "learning_rate": 8.057430622522234e-06,
      "loss": 0.2285,
      "step": 55730
    },
    {
      "epoch": 5.972356155576985,
      "grad_norm": 0.027530068531632423,
      "learning_rate": 8.055287688846031e-06,
      "loss": 0.1676,
      "step": 55740
    },
    {
      "epoch": 5.973427622415087,
      "grad_norm": 0.12216903269290924,
      "learning_rate": 8.053144755169828e-06,
      "loss": 0.2143,
      "step": 55750
    },
    {
      "epoch": 5.974499089253188,
      "grad_norm": 127.71631622314453,
      "learning_rate": 8.051001821493626e-06,
      "loss": 0.0907,
      "step": 55760
    },
    {
      "epoch": 5.975570556091289,
      "grad_norm": 0.0013345647603273392,
      "learning_rate": 8.048858887817423e-06,
      "loss": 0.1487,
      "step": 55770
    },
    {
      "epoch": 5.97664202292939,
      "grad_norm": 0.015689581632614136,
      "learning_rate": 8.04671595414122e-06,
      "loss": 0.3599,
      "step": 55780
    },
    {
      "epoch": 5.977713489767492,
      "grad_norm": 0.6581547856330872,
      "learning_rate": 8.044573020465018e-06,
      "loss": 0.5955,
      "step": 55790
    },
    {
      "epoch": 5.978784956605593,
      "grad_norm": 0.1835906207561493,
      "learning_rate": 8.042430086788815e-06,
      "loss": 0.1924,
      "step": 55800
    },
    {
      "epoch": 5.979856423443694,
      "grad_norm": 0.03097730316221714,
      "learning_rate": 8.04028715311261e-06,
      "loss": 0.0007,
      "step": 55810
    },
    {
      "epoch": 5.980927890281796,
      "grad_norm": 0.1620490849018097,
      "learning_rate": 8.03814421943641e-06,
      "loss": 0.0042,
      "step": 55820
    },
    {
      "epoch": 5.981999357119897,
      "grad_norm": 0.09479299187660217,
      "learning_rate": 8.036001285760207e-06,
      "loss": 0.0011,
      "step": 55830
    },
    {
      "epoch": 5.983070823957998,
      "grad_norm": 0.026881124824285507,
      "learning_rate": 8.033858352084004e-06,
      "loss": 0.0004,
      "step": 55840
    },
    {
      "epoch": 5.9841422907960995,
      "grad_norm": 0.020484352484345436,
      "learning_rate": 8.0317154184078e-06,
      "loss": 0.0005,
      "step": 55850
    },
    {
      "epoch": 5.9852137576342015,
      "grad_norm": 16.76825714111328,
      "learning_rate": 8.029572484731597e-06,
      "loss": 0.1495,
      "step": 55860
    },
    {
      "epoch": 5.986285224472303,
      "grad_norm": 0.008719555102288723,
      "learning_rate": 8.027429551055395e-06,
      "loss": 0.0015,
      "step": 55870
    },
    {
      "epoch": 5.987356691310404,
      "grad_norm": 0.10277319699525833,
      "learning_rate": 8.025286617379194e-06,
      "loss": 0.4356,
      "step": 55880
    },
    {
      "epoch": 5.988428158148505,
      "grad_norm": 0.0024172174744307995,
      "learning_rate": 8.02314368370299e-06,
      "loss": 0.1178,
      "step": 55890
    },
    {
      "epoch": 5.989499624986607,
      "grad_norm": 0.0019226321019232273,
      "learning_rate": 8.021000750026787e-06,
      "loss": 0.1016,
      "step": 55900
    },
    {
      "epoch": 5.990571091824708,
      "grad_norm": 0.21454669535160065,
      "learning_rate": 8.018857816350584e-06,
      "loss": 0.1483,
      "step": 55910
    },
    {
      "epoch": 5.991642558662809,
      "grad_norm": 0.03912303224205971,
      "learning_rate": 8.016714882674382e-06,
      "loss": 0.4213,
      "step": 55920
    },
    {
      "epoch": 5.992714025500911,
      "grad_norm": 0.10004504024982452,
      "learning_rate": 8.014571948998179e-06,
      "loss": 0.3293,
      "step": 55930
    },
    {
      "epoch": 5.993785492339012,
      "grad_norm": 0.06345269083976746,
      "learning_rate": 8.012429015321976e-06,
      "loss": 0.2161,
      "step": 55940
    },
    {
      "epoch": 5.994856959177113,
      "grad_norm": 0.07171107828617096,
      "learning_rate": 8.010286081645774e-06,
      "loss": 0.0015,
      "step": 55950
    },
    {
      "epoch": 5.995928426015215,
      "grad_norm": 0.013833396136760712,
      "learning_rate": 8.008143147969571e-06,
      "loss": 0.0007,
      "step": 55960
    },
    {
      "epoch": 5.996999892853316,
      "grad_norm": 0.03600040823221207,
      "learning_rate": 8.006000214293368e-06,
      "loss": 0.1557,
      "step": 55970
    },
    {
      "epoch": 5.9980713596914175,
      "grad_norm": 0.010296438820660114,
      "learning_rate": 8.003857280617166e-06,
      "loss": 0.001,
      "step": 55980
    },
    {
      "epoch": 5.999142826529519,
      "grad_norm": 0.0010673359502106905,
      "learning_rate": 8.001714346940963e-06,
      "loss": 0.4727,
      "step": 55990
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9436666666666667,
      "eval_f1": 0.85580204778157,
      "eval_loss": 0.30490922927856445,
      "eval_precision": 0.85,
      "eval_recall": 0.8616838487972509,
      "eval_runtime": 482.0791,
      "eval_samples_per_second": 12.446,
      "eval_steps_per_second": 4.149,
      "step": 55998
    },
    {
      "epoch": 6.000214293367621,
      "grad_norm": 0.020088622346520424,
      "learning_rate": 7.99957141326476e-06,
      "loss": 0.0548,
      "step": 56000
    },
    {
      "epoch": 6.001285760205722,
      "grad_norm": 0.02587730623781681,
      "learning_rate": 7.997428479588558e-06,
      "loss": 0.0008,
      "step": 56010
    },
    {
      "epoch": 6.002357227043823,
      "grad_norm": 0.01572524942457676,
      "learning_rate": 7.995285545912355e-06,
      "loss": 0.001,
      "step": 56020
    },
    {
      "epoch": 6.003428693881925,
      "grad_norm": 0.0017254076665267348,
      "learning_rate": 7.993142612236153e-06,
      "loss": 0.1605,
      "step": 56030
    },
    {
      "epoch": 6.004500160720026,
      "grad_norm": 0.28461211919784546,
      "learning_rate": 7.99099967855995e-06,
      "loss": 0.1554,
      "step": 56040
    },
    {
      "epoch": 6.005571627558127,
      "grad_norm": 0.007887219078838825,
      "learning_rate": 7.988856744883746e-06,
      "loss": 0.1607,
      "step": 56050
    },
    {
      "epoch": 6.006643094396228,
      "grad_norm": 0.018653512001037598,
      "learning_rate": 7.986713811207543e-06,
      "loss": 0.047,
      "step": 56060
    },
    {
      "epoch": 6.00771456123433,
      "grad_norm": 0.07146888971328735,
      "learning_rate": 7.984570877531342e-06,
      "loss": 0.0471,
      "step": 56070
    },
    {
      "epoch": 6.008786028072431,
      "grad_norm": 0.0005030847969464958,
      "learning_rate": 7.98242794385514e-06,
      "loss": 0.0941,
      "step": 56080
    },
    {
      "epoch": 6.009857494910532,
      "grad_norm": 0.0006660723011009395,
      "learning_rate": 7.980285010178935e-06,
      "loss": 0.1452,
      "step": 56090
    },
    {
      "epoch": 6.0109289617486334,
      "grad_norm": 0.038660258054733276,
      "learning_rate": 7.978142076502732e-06,
      "loss": 0.0016,
      "step": 56100
    },
    {
      "epoch": 6.0120004285867354,
      "grad_norm": 0.016474198549985886,
      "learning_rate": 7.97599914282653e-06,
      "loss": 0.0019,
      "step": 56110
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 0.031107889488339424,
      "learning_rate": 7.973856209150329e-06,
      "loss": 0.0438,
      "step": 56120
    },
    {
      "epoch": 6.014143362262938,
      "grad_norm": 0.0011582858860492706,
      "learning_rate": 7.971713275474124e-06,
      "loss": 0.4208,
      "step": 56130
    },
    {
      "epoch": 6.01521482910104,
      "grad_norm": 0.0010474997106939554,
      "learning_rate": 7.969570341797922e-06,
      "loss": 0.0421,
      "step": 56140
    },
    {
      "epoch": 6.016286295939141,
      "grad_norm": 0.002107250038534403,
      "learning_rate": 7.967427408121719e-06,
      "loss": 0.0018,
      "step": 56150
    },
    {
      "epoch": 6.017357762777242,
      "grad_norm": 0.0007606337312608957,
      "learning_rate": 7.965284474445516e-06,
      "loss": 0.0004,
      "step": 56160
    },
    {
      "epoch": 6.018429229615343,
      "grad_norm": 0.0009908167412504554,
      "learning_rate": 7.963141540769314e-06,
      "loss": 0.1453,
      "step": 56170
    },
    {
      "epoch": 6.019500696453445,
      "grad_norm": 0.06837358325719833,
      "learning_rate": 7.960998607093111e-06,
      "loss": 0.0003,
      "step": 56180
    },
    {
      "epoch": 6.020572163291546,
      "grad_norm": 0.0008128019981086254,
      "learning_rate": 7.958855673416909e-06,
      "loss": 0.0004,
      "step": 56190
    },
    {
      "epoch": 6.021643630129647,
      "grad_norm": 0.0012732157483696938,
      "learning_rate": 7.956712739740706e-06,
      "loss": 0.001,
      "step": 56200
    },
    {
      "epoch": 6.022715096967749,
      "grad_norm": 0.00028882952756248415,
      "learning_rate": 7.954569806064503e-06,
      "loss": 0.0001,
      "step": 56210
    },
    {
      "epoch": 6.02378656380585,
      "grad_norm": 0.0003116167208645493,
      "learning_rate": 7.9524268723883e-06,
      "loss": 0.0,
      "step": 56220
    },
    {
      "epoch": 6.024858030643951,
      "grad_norm": 0.11957778036594391,
      "learning_rate": 7.950283938712098e-06,
      "loss": 0.0005,
      "step": 56230
    },
    {
      "epoch": 6.0259294974820525,
      "grad_norm": 0.002788344630971551,
      "learning_rate": 7.948141005035894e-06,
      "loss": 0.0016,
      "step": 56240
    },
    {
      "epoch": 6.0270009643201545,
      "grad_norm": 14.352630615234375,
      "learning_rate": 7.945998071359691e-06,
      "loss": 0.2775,
      "step": 56250
    },
    {
      "epoch": 6.028072431158256,
      "grad_norm": 17.060073852539062,
      "learning_rate": 7.94385513768349e-06,
      "loss": 0.1457,
      "step": 56260
    },
    {
      "epoch": 6.029143897996357,
      "grad_norm": 0.02406918630003929,
      "learning_rate": 7.941712204007287e-06,
      "loss": 0.1845,
      "step": 56270
    },
    {
      "epoch": 6.030215364834459,
      "grad_norm": 1.0678852796554565,
      "learning_rate": 7.939569270331083e-06,
      "loss": 0.0004,
      "step": 56280
    },
    {
      "epoch": 6.03128683167256,
      "grad_norm": 0.3907693326473236,
      "learning_rate": 7.93742633665488e-06,
      "loss": 0.263,
      "step": 56290
    },
    {
      "epoch": 6.032358298510661,
      "grad_norm": 0.0004058819031342864,
      "learning_rate": 7.935283402978678e-06,
      "loss": 0.0006,
      "step": 56300
    },
    {
      "epoch": 6.033429765348762,
      "grad_norm": 0.03810688108205795,
      "learning_rate": 7.933140469302477e-06,
      "loss": 0.001,
      "step": 56310
    },
    {
      "epoch": 6.034501232186864,
      "grad_norm": 0.00042878728709183633,
      "learning_rate": 7.930997535626272e-06,
      "loss": 0.0002,
      "step": 56320
    },
    {
      "epoch": 6.035572699024965,
      "grad_norm": 0.0006495226989500225,
      "learning_rate": 7.92885460195007e-06,
      "loss": 0.0004,
      "step": 56330
    },
    {
      "epoch": 6.036644165863066,
      "grad_norm": 0.001278246403671801,
      "learning_rate": 7.926711668273867e-06,
      "loss": 0.2647,
      "step": 56340
    },
    {
      "epoch": 6.037715632701168,
      "grad_norm": 0.007884263060986996,
      "learning_rate": 7.924568734597665e-06,
      "loss": 0.0008,
      "step": 56350
    },
    {
      "epoch": 6.038787099539269,
      "grad_norm": 0.0005645086639560759,
      "learning_rate": 7.922425800921462e-06,
      "loss": 0.201,
      "step": 56360
    },
    {
      "epoch": 6.0398585663773705,
      "grad_norm": 0.0010470933048054576,
      "learning_rate": 7.92028286724526e-06,
      "loss": 0.1896,
      "step": 56370
    },
    {
      "epoch": 6.040930033215472,
      "grad_norm": 0.016574682667851448,
      "learning_rate": 7.918139933569057e-06,
      "loss": 0.0001,
      "step": 56380
    },
    {
      "epoch": 6.042001500053574,
      "grad_norm": 0.01274916809052229,
      "learning_rate": 7.915996999892854e-06,
      "loss": 0.1153,
      "step": 56390
    },
    {
      "epoch": 6.043072966891675,
      "grad_norm": 0.024725008755922318,
      "learning_rate": 7.913854066216651e-06,
      "loss": 0.0004,
      "step": 56400
    },
    {
      "epoch": 6.044144433729776,
      "grad_norm": 0.01822686567902565,
      "learning_rate": 7.911711132540449e-06,
      "loss": 0.1882,
      "step": 56410
    },
    {
      "epoch": 6.045215900567878,
      "grad_norm": 0.21864500641822815,
      "learning_rate": 7.909568198864246e-06,
      "loss": 0.0006,
      "step": 56420
    },
    {
      "epoch": 6.046287367405979,
      "grad_norm": 0.0007514622993767262,
      "learning_rate": 7.907425265188043e-06,
      "loss": 0.0028,
      "step": 56430
    },
    {
      "epoch": 6.04735883424408,
      "grad_norm": 0.0007501912768930197,
      "learning_rate": 7.905282331511839e-06,
      "loss": 0.1986,
      "step": 56440
    },
    {
      "epoch": 6.048430301082181,
      "grad_norm": 0.019086306914687157,
      "learning_rate": 7.903139397835638e-06,
      "loss": 0.0516,
      "step": 56450
    },
    {
      "epoch": 6.049501767920283,
      "grad_norm": 0.00044835711014457047,
      "learning_rate": 7.900996464159435e-06,
      "loss": 0.0642,
      "step": 56460
    },
    {
      "epoch": 6.050573234758384,
      "grad_norm": 0.01625688001513481,
      "learning_rate": 7.898853530483233e-06,
      "loss": 0.1769,
      "step": 56470
    },
    {
      "epoch": 6.051644701596485,
      "grad_norm": 0.11602623015642166,
      "learning_rate": 7.896710596807028e-06,
      "loss": 0.1264,
      "step": 56480
    },
    {
      "epoch": 6.052716168434587,
      "grad_norm": 0.0008266782970167696,
      "learning_rate": 7.894567663130826e-06,
      "loss": 0.3167,
      "step": 56490
    },
    {
      "epoch": 6.0537876352726885,
      "grad_norm": 0.00126657634973526,
      "learning_rate": 7.892424729454625e-06,
      "loss": 0.0012,
      "step": 56500
    },
    {
      "epoch": 6.05485910211079,
      "grad_norm": 0.00036949472269043326,
      "learning_rate": 7.890281795778422e-06,
      "loss": 0.0636,
      "step": 56510
    },
    {
      "epoch": 6.055930568948891,
      "grad_norm": 0.0003445713664405048,
      "learning_rate": 7.888138862102218e-06,
      "loss": 0.0004,
      "step": 56520
    },
    {
      "epoch": 6.057002035786993,
      "grad_norm": 0.0069120959378778934,
      "learning_rate": 7.885995928426015e-06,
      "loss": 0.0003,
      "step": 56530
    },
    {
      "epoch": 6.058073502625094,
      "grad_norm": 0.0005727734533138573,
      "learning_rate": 7.883852994749813e-06,
      "loss": 0.001,
      "step": 56540
    },
    {
      "epoch": 6.059144969463195,
      "grad_norm": 0.013154666870832443,
      "learning_rate": 7.881710061073612e-06,
      "loss": 0.3198,
      "step": 56550
    },
    {
      "epoch": 6.060216436301296,
      "grad_norm": 0.11783391982316971,
      "learning_rate": 7.879567127397407e-06,
      "loss": 0.0006,
      "step": 56560
    },
    {
      "epoch": 6.061287903139398,
      "grad_norm": 0.014595922082662582,
      "learning_rate": 7.877424193721205e-06,
      "loss": 0.1034,
      "step": 56570
    },
    {
      "epoch": 6.062359369977499,
      "grad_norm": 18.101259231567383,
      "learning_rate": 7.875281260045002e-06,
      "loss": 0.1865,
      "step": 56580
    },
    {
      "epoch": 6.0634308368156,
      "grad_norm": 0.006375696510076523,
      "learning_rate": 7.8731383263688e-06,
      "loss": 0.0002,
      "step": 56590
    },
    {
      "epoch": 6.064502303653702,
      "grad_norm": 0.0007637884700670838,
      "learning_rate": 7.870995392692597e-06,
      "loss": 0.1501,
      "step": 56600
    },
    {
      "epoch": 6.065573770491803,
      "grad_norm": 18.633634567260742,
      "learning_rate": 7.868852459016394e-06,
      "loss": 0.1573,
      "step": 56610
    },
    {
      "epoch": 6.0666452373299045,
      "grad_norm": 0.0005344430101104081,
      "learning_rate": 7.866709525340191e-06,
      "loss": 0.192,
      "step": 56620
    },
    {
      "epoch": 6.067716704168006,
      "grad_norm": 0.007346798200160265,
      "learning_rate": 7.864566591663989e-06,
      "loss": 0.363,
      "step": 56630
    },
    {
      "epoch": 6.068788171006108,
      "grad_norm": 0.06525303423404694,
      "learning_rate": 7.862423657987786e-06,
      "loss": 0.0007,
      "step": 56640
    },
    {
      "epoch": 6.069859637844209,
      "grad_norm": 0.004252958111464977,
      "learning_rate": 7.860280724311584e-06,
      "loss": 0.154,
      "step": 56650
    },
    {
      "epoch": 6.07093110468231,
      "grad_norm": 0.00877437461167574,
      "learning_rate": 7.858137790635381e-06,
      "loss": 0.2282,
      "step": 56660
    },
    {
      "epoch": 6.072002571520412,
      "grad_norm": 0.0708981603384018,
      "learning_rate": 7.855994856959178e-06,
      "loss": 0.2533,
      "step": 56670
    },
    {
      "epoch": 6.073074038358513,
      "grad_norm": 0.12563501298427582,
      "learning_rate": 7.853851923282974e-06,
      "loss": 0.1178,
      "step": 56680
    },
    {
      "epoch": 6.074145505196614,
      "grad_norm": 0.02214251086115837,
      "learning_rate": 7.851708989606773e-06,
      "loss": 0.0006,
      "step": 56690
    },
    {
      "epoch": 6.075216972034715,
      "grad_norm": 0.005467732436954975,
      "learning_rate": 7.84956605593057e-06,
      "loss": 0.0014,
      "step": 56700
    },
    {
      "epoch": 6.076288438872817,
      "grad_norm": 0.03493005409836769,
      "learning_rate": 7.847423122254368e-06,
      "loss": 0.1841,
      "step": 56710
    },
    {
      "epoch": 6.077359905710918,
      "grad_norm": 0.004039169754832983,
      "learning_rate": 7.845280188578163e-06,
      "loss": 0.0003,
      "step": 56720
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 0.02012302726507187,
      "learning_rate": 7.84313725490196e-06,
      "loss": 0.2325,
      "step": 56730
    },
    {
      "epoch": 6.079502839387121,
      "grad_norm": 420.960205078125,
      "learning_rate": 7.84099432122576e-06,
      "loss": 0.3115,
      "step": 56740
    },
    {
      "epoch": 6.080574306225222,
      "grad_norm": 0.0007095008622854948,
      "learning_rate": 7.838851387549557e-06,
      "loss": 0.0006,
      "step": 56750
    },
    {
      "epoch": 6.0816457730633235,
      "grad_norm": 0.024194858968257904,
      "learning_rate": 7.836708453873353e-06,
      "loss": 0.001,
      "step": 56760
    },
    {
      "epoch": 6.082717239901425,
      "grad_norm": 0.04005734995007515,
      "learning_rate": 7.83456552019715e-06,
      "loss": 0.0013,
      "step": 56770
    },
    {
      "epoch": 6.083788706739527,
      "grad_norm": 0.011297659948468208,
      "learning_rate": 7.832422586520947e-06,
      "loss": 0.4717,
      "step": 56780
    },
    {
      "epoch": 6.084860173577628,
      "grad_norm": 0.005284955259412527,
      "learning_rate": 7.830279652844745e-06,
      "loss": 0.0034,
      "step": 56790
    },
    {
      "epoch": 6.085931640415729,
      "grad_norm": 0.11242537945508957,
      "learning_rate": 7.828136719168542e-06,
      "loss": 0.1238,
      "step": 56800
    },
    {
      "epoch": 6.087003107253831,
      "grad_norm": 0.024914821609854698,
      "learning_rate": 7.82599378549234e-06,
      "loss": 0.0011,
      "step": 56810
    },
    {
      "epoch": 6.088074574091932,
      "grad_norm": 0.004665793851017952,
      "learning_rate": 7.823850851816137e-06,
      "loss": 0.1024,
      "step": 56820
    },
    {
      "epoch": 6.089146040930033,
      "grad_norm": 0.0004247989854775369,
      "learning_rate": 7.821707918139934e-06,
      "loss": 0.0005,
      "step": 56830
    },
    {
      "epoch": 6.090217507768134,
      "grad_norm": 0.00026297621661797166,
      "learning_rate": 7.819564984463732e-06,
      "loss": 0.198,
      "step": 56840
    },
    {
      "epoch": 6.091288974606236,
      "grad_norm": 0.08635426312685013,
      "learning_rate": 7.817422050787529e-06,
      "loss": 0.0014,
      "step": 56850
    },
    {
      "epoch": 6.092360441444337,
      "grad_norm": 0.0012735238997265697,
      "learning_rate": 7.815279117111326e-06,
      "loss": 0.1435,
      "step": 56860
    },
    {
      "epoch": 6.093431908282438,
      "grad_norm": 0.018966587260365486,
      "learning_rate": 7.813136183435124e-06,
      "loss": 0.1779,
      "step": 56870
    },
    {
      "epoch": 6.09450337512054,
      "grad_norm": 0.00043202287633903325,
      "learning_rate": 7.810993249758921e-06,
      "loss": 0.0006,
      "step": 56880
    },
    {
      "epoch": 6.0955748419586415,
      "grad_norm": 0.010293034836649895,
      "learning_rate": 7.808850316082718e-06,
      "loss": 0.0001,
      "step": 56890
    },
    {
      "epoch": 6.096646308796743,
      "grad_norm": 0.07434176653623581,
      "learning_rate": 7.806707382406516e-06,
      "loss": 0.0038,
      "step": 56900
    },
    {
      "epoch": 6.097717775634844,
      "grad_norm": 0.051976364105939865,
      "learning_rate": 7.804564448730313e-06,
      "loss": 0.0003,
      "step": 56910
    },
    {
      "epoch": 6.098789242472946,
      "grad_norm": 1.5645666122436523,
      "learning_rate": 7.802421515054109e-06,
      "loss": 0.1536,
      "step": 56920
    },
    {
      "epoch": 6.099860709311047,
      "grad_norm": 0.1075609028339386,
      "learning_rate": 7.800278581377908e-06,
      "loss": 0.1627,
      "step": 56930
    },
    {
      "epoch": 6.100932176149148,
      "grad_norm": 0.09109967947006226,
      "learning_rate": 7.798135647701705e-06,
      "loss": 0.1478,
      "step": 56940
    },
    {
      "epoch": 6.10200364298725,
      "grad_norm": 0.00027374865021556616,
      "learning_rate": 7.795992714025502e-06,
      "loss": 0.0005,
      "step": 56950
    },
    {
      "epoch": 6.103075109825351,
      "grad_norm": 0.0002728200051933527,
      "learning_rate": 7.793849780349298e-06,
      "loss": 0.1865,
      "step": 56960
    },
    {
      "epoch": 6.104146576663452,
      "grad_norm": 0.0004388561937958002,
      "learning_rate": 7.791706846673096e-06,
      "loss": 0.2446,
      "step": 56970
    },
    {
      "epoch": 6.105218043501553,
      "grad_norm": 0.008482160978019238,
      "learning_rate": 7.789563912996893e-06,
      "loss": 0.0007,
      "step": 56980
    },
    {
      "epoch": 6.106289510339655,
      "grad_norm": 74.76615905761719,
      "learning_rate": 7.787420979320692e-06,
      "loss": 0.1291,
      "step": 56990
    },
    {
      "epoch": 6.107360977177756,
      "grad_norm": 0.16698597371578217,
      "learning_rate": 7.785278045644488e-06,
      "loss": 0.09,
      "step": 57000
    },
    {
      "epoch": 6.1084324440158575,
      "grad_norm": 0.006184592843055725,
      "learning_rate": 7.783135111968285e-06,
      "loss": 0.0001,
      "step": 57010
    },
    {
      "epoch": 6.1095039108539595,
      "grad_norm": 190.00485229492188,
      "learning_rate": 7.780992178292082e-06,
      "loss": 0.2157,
      "step": 57020
    },
    {
      "epoch": 6.110575377692061,
      "grad_norm": 0.005887981038540602,
      "learning_rate": 7.77884924461588e-06,
      "loss": 0.0011,
      "step": 57030
    },
    {
      "epoch": 6.111646844530162,
      "grad_norm": 0.04459623992443085,
      "learning_rate": 7.776706310939677e-06,
      "loss": 0.1849,
      "step": 57040
    },
    {
      "epoch": 6.112718311368263,
      "grad_norm": 0.004791544750332832,
      "learning_rate": 7.774563377263474e-06,
      "loss": 0.2481,
      "step": 57050
    },
    {
      "epoch": 6.113789778206365,
      "grad_norm": 0.008183080703020096,
      "learning_rate": 7.772420443587272e-06,
      "loss": 0.0004,
      "step": 57060
    },
    {
      "epoch": 6.114861245044466,
      "grad_norm": 0.0002570587967056781,
      "learning_rate": 7.770277509911069e-06,
      "loss": 0.0857,
      "step": 57070
    },
    {
      "epoch": 6.115932711882567,
      "grad_norm": 0.05989278107881546,
      "learning_rate": 7.768134576234866e-06,
      "loss": 0.0008,
      "step": 57080
    },
    {
      "epoch": 6.117004178720668,
      "grad_norm": 0.003942165989428759,
      "learning_rate": 7.765991642558664e-06,
      "loss": 0.0006,
      "step": 57090
    },
    {
      "epoch": 6.11807564555877,
      "grad_norm": 0.00024402039707638323,
      "learning_rate": 7.763848708882461e-06,
      "loss": 0.1753,
      "step": 57100
    },
    {
      "epoch": 6.119147112396871,
      "grad_norm": 0.0002464769349899143,
      "learning_rate": 7.761705775206257e-06,
      "loss": 0.3915,
      "step": 57110
    },
    {
      "epoch": 6.120218579234972,
      "grad_norm": 0.03770335763692856,
      "learning_rate": 7.759562841530056e-06,
      "loss": 0.0017,
      "step": 57120
    },
    {
      "epoch": 6.121290046073074,
      "grad_norm": 0.0045863487757742405,
      "learning_rate": 7.757419907853853e-06,
      "loss": 0.4443,
      "step": 57130
    },
    {
      "epoch": 6.1223615129111755,
      "grad_norm": 0.005666798446327448,
      "learning_rate": 7.75527697417765e-06,
      "loss": 0.1265,
      "step": 57140
    },
    {
      "epoch": 6.123432979749277,
      "grad_norm": 0.013032215647399426,
      "learning_rate": 7.753134040501446e-06,
      "loss": 0.0004,
      "step": 57150
    },
    {
      "epoch": 6.124504446587378,
      "grad_norm": 0.00027496309485286474,
      "learning_rate": 7.750991106825244e-06,
      "loss": 0.1883,
      "step": 57160
    },
    {
      "epoch": 6.12557591342548,
      "grad_norm": 0.12347734719514847,
      "learning_rate": 7.748848173149041e-06,
      "loss": 0.0008,
      "step": 57170
    },
    {
      "epoch": 6.126647380263581,
      "grad_norm": 0.0017157192341983318,
      "learning_rate": 7.74670523947284e-06,
      "loss": 0.0002,
      "step": 57180
    },
    {
      "epoch": 6.127718847101682,
      "grad_norm": 0.007039832416921854,
      "learning_rate": 7.744562305796636e-06,
      "loss": 0.1807,
      "step": 57190
    },
    {
      "epoch": 6.128790313939784,
      "grad_norm": 0.005927568301558495,
      "learning_rate": 7.742419372120433e-06,
      "loss": 0.0005,
      "step": 57200
    },
    {
      "epoch": 6.129861780777885,
      "grad_norm": 0.0050324066542088985,
      "learning_rate": 7.74027643844423e-06,
      "loss": 0.0004,
      "step": 57210
    },
    {
      "epoch": 6.130933247615986,
      "grad_norm": 0.01057626586407423,
      "learning_rate": 7.738133504768028e-06,
      "loss": 0.0007,
      "step": 57220
    },
    {
      "epoch": 6.132004714454087,
      "grad_norm": 0.004680583253502846,
      "learning_rate": 7.735990571091825e-06,
      "loss": 0.2385,
      "step": 57230
    },
    {
      "epoch": 6.133076181292189,
      "grad_norm": 0.0074273752979934216,
      "learning_rate": 7.733847637415622e-06,
      "loss": 0.1443,
      "step": 57240
    },
    {
      "epoch": 6.13414764813029,
      "grad_norm": 0.11852284520864487,
      "learning_rate": 7.73170470373942e-06,
      "loss": 0.1733,
      "step": 57250
    },
    {
      "epoch": 6.1352191149683915,
      "grad_norm": 0.2168007344007492,
      "learning_rate": 7.729561770063217e-06,
      "loss": 0.0012,
      "step": 57260
    },
    {
      "epoch": 6.1362905818064934,
      "grad_norm": 0.006211941130459309,
      "learning_rate": 7.727418836387014e-06,
      "loss": 0.0003,
      "step": 57270
    },
    {
      "epoch": 6.137362048644595,
      "grad_norm": 0.01048181764781475,
      "learning_rate": 7.725275902710812e-06,
      "loss": 0.0017,
      "step": 57280
    },
    {
      "epoch": 6.138433515482696,
      "grad_norm": 0.004714800976216793,
      "learning_rate": 7.72313296903461e-06,
      "loss": 0.0001,
      "step": 57290
    },
    {
      "epoch": 6.139504982320797,
      "grad_norm": 0.0002463329001329839,
      "learning_rate": 7.720990035358407e-06,
      "loss": 0.0001,
      "step": 57300
    },
    {
      "epoch": 6.140576449158899,
      "grad_norm": 0.005345386918634176,
      "learning_rate": 7.718847101682204e-06,
      "loss": 0.0002,
      "step": 57310
    },
    {
      "epoch": 6.141647915997,
      "grad_norm": 0.0002200538438046351,
      "learning_rate": 7.716704168006001e-06,
      "loss": 0.0001,
      "step": 57320
    },
    {
      "epoch": 6.142719382835101,
      "grad_norm": 0.003815524745732546,
      "learning_rate": 7.714561234329799e-06,
      "loss": 0.668,
      "step": 57330
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 0.013701487332582474,
      "learning_rate": 7.712418300653596e-06,
      "loss": 0.0001,
      "step": 57340
    },
    {
      "epoch": 6.144862316511304,
      "grad_norm": 3.1822521686553955,
      "learning_rate": 7.710275366977392e-06,
      "loss": 0.0013,
      "step": 57350
    },
    {
      "epoch": 6.145933783349405,
      "grad_norm": 0.07059046626091003,
      "learning_rate": 7.708132433301189e-06,
      "loss": 0.3182,
      "step": 57360
    },
    {
      "epoch": 6.147005250187506,
      "grad_norm": 0.1404116302728653,
      "learning_rate": 7.705989499624988e-06,
      "loss": 0.001,
      "step": 57370
    },
    {
      "epoch": 6.148076717025608,
      "grad_norm": 0.0034886791836470366,
      "learning_rate": 7.703846565948785e-06,
      "loss": 0.2259,
      "step": 57380
    },
    {
      "epoch": 6.149148183863709,
      "grad_norm": 0.004784358665347099,
      "learning_rate": 7.701703632272581e-06,
      "loss": 0.2028,
      "step": 57390
    },
    {
      "epoch": 6.1502196507018105,
      "grad_norm": 0.0008085811859928071,
      "learning_rate": 7.699560698596378e-06,
      "loss": 0.0011,
      "step": 57400
    },
    {
      "epoch": 6.1512911175399125,
      "grad_norm": 0.1977553367614746,
      "learning_rate": 7.697417764920176e-06,
      "loss": 0.0013,
      "step": 57410
    },
    {
      "epoch": 6.152362584378014,
      "grad_norm": 0.004442564211785793,
      "learning_rate": 7.695274831243975e-06,
      "loss": 0.0005,
      "step": 57420
    },
    {
      "epoch": 6.153434051216115,
      "grad_norm": 52.842369079589844,
      "learning_rate": 7.69313189756777e-06,
      "loss": 0.3575,
      "step": 57430
    },
    {
      "epoch": 6.154505518054216,
      "grad_norm": 0.004785859491676092,
      "learning_rate": 7.690988963891568e-06,
      "loss": 0.0008,
      "step": 57440
    },
    {
      "epoch": 6.155576984892318,
      "grad_norm": 0.011252742260694504,
      "learning_rate": 7.688846030215365e-06,
      "loss": 0.0005,
      "step": 57450
    },
    {
      "epoch": 6.156648451730419,
      "grad_norm": 0.7124325633049011,
      "learning_rate": 7.686703096539163e-06,
      "loss": 0.0005,
      "step": 57460
    },
    {
      "epoch": 6.15771991856852,
      "grad_norm": 0.3506750166416168,
      "learning_rate": 7.68456016286296e-06,
      "loss": 0.0005,
      "step": 57470
    },
    {
      "epoch": 6.158791385406622,
      "grad_norm": 0.024843236431479454,
      "learning_rate": 7.682417229186757e-06,
      "loss": 0.0005,
      "step": 57480
    },
    {
      "epoch": 6.159862852244723,
      "grad_norm": 0.35236120223999023,
      "learning_rate": 7.680274295510555e-06,
      "loss": 0.1634,
      "step": 57490
    },
    {
      "epoch": 6.160934319082824,
      "grad_norm": 0.0007170744938775897,
      "learning_rate": 7.678131361834352e-06,
      "loss": 0.0018,
      "step": 57500
    },
    {
      "epoch": 6.162005785920925,
      "grad_norm": 27.428834915161133,
      "learning_rate": 7.67598842815815e-06,
      "loss": 0.3171,
      "step": 57510
    },
    {
      "epoch": 6.163077252759027,
      "grad_norm": 0.07321309298276901,
      "learning_rate": 7.673845494481947e-06,
      "loss": 0.1513,
      "step": 57520
    },
    {
      "epoch": 6.1641487195971285,
      "grad_norm": 0.006441460456699133,
      "learning_rate": 7.671702560805744e-06,
      "loss": 0.4018,
      "step": 57530
    },
    {
      "epoch": 6.16522018643523,
      "grad_norm": 0.00022307362814899534,
      "learning_rate": 7.669559627129541e-06,
      "loss": 0.1943,
      "step": 57540
    },
    {
      "epoch": 6.166291653273332,
      "grad_norm": 0.006138479337096214,
      "learning_rate": 7.667416693453337e-06,
      "loss": 0.0015,
      "step": 57550
    },
    {
      "epoch": 6.167363120111433,
      "grad_norm": 0.005415268242359161,
      "learning_rate": 7.665273759777136e-06,
      "loss": 0.2057,
      "step": 57560
    },
    {
      "epoch": 6.168434586949534,
      "grad_norm": 0.017298772931098938,
      "learning_rate": 7.663130826100933e-06,
      "loss": 0.0023,
      "step": 57570
    },
    {
      "epoch": 6.169506053787635,
      "grad_norm": 1.9979764223098755,
      "learning_rate": 7.66098789242473e-06,
      "loss": 0.0008,
      "step": 57580
    },
    {
      "epoch": 6.170577520625737,
      "grad_norm": 0.010129313915967941,
      "learning_rate": 7.658844958748526e-06,
      "loss": 0.0077,
      "step": 57590
    },
    {
      "epoch": 6.171648987463838,
      "grad_norm": 0.002662306185811758,
      "learning_rate": 7.656702025072324e-06,
      "loss": 0.0011,
      "step": 57600
    },
    {
      "epoch": 6.172720454301939,
      "grad_norm": 0.00014800635108258575,
      "learning_rate": 7.654559091396123e-06,
      "loss": 0.0004,
      "step": 57610
    },
    {
      "epoch": 6.17379192114004,
      "grad_norm": 0.0002160137810278684,
      "learning_rate": 7.65241615771992e-06,
      "loss": 0.0007,
      "step": 57620
    },
    {
      "epoch": 6.174863387978142,
      "grad_norm": 0.005434130318462849,
      "learning_rate": 7.650273224043716e-06,
      "loss": 0.2122,
      "step": 57630
    },
    {
      "epoch": 6.175934854816243,
      "grad_norm": 0.032876960933208466,
      "learning_rate": 7.648130290367513e-06,
      "loss": 0.2204,
      "step": 57640
    },
    {
      "epoch": 6.1770063216543445,
      "grad_norm": 0.0002222748880740255,
      "learning_rate": 7.64598735669131e-06,
      "loss": 0.0003,
      "step": 57650
    },
    {
      "epoch": 6.1780777884924465,
      "grad_norm": 0.06227556988596916,
      "learning_rate": 7.643844423015108e-06,
      "loss": 0.0001,
      "step": 57660
    },
    {
      "epoch": 6.179149255330548,
      "grad_norm": 0.006511392537504435,
      "learning_rate": 7.641701489338905e-06,
      "loss": 0.0005,
      "step": 57670
    },
    {
      "epoch": 6.180220722168649,
      "grad_norm": 0.00023463444085791707,
      "learning_rate": 7.639558555662703e-06,
      "loss": 0.0009,
      "step": 57680
    },
    {
      "epoch": 6.18129218900675,
      "grad_norm": 0.003959362860769033,
      "learning_rate": 7.6374156219865e-06,
      "loss": 0.0571,
      "step": 57690
    },
    {
      "epoch": 6.182363655844852,
      "grad_norm": 0.0001313054672209546,
      "learning_rate": 7.635272688310297e-06,
      "loss": 0.0004,
      "step": 57700
    },
    {
      "epoch": 6.183435122682953,
      "grad_norm": 0.1269403100013733,
      "learning_rate": 7.633129754634095e-06,
      "loss": 0.1627,
      "step": 57710
    },
    {
      "epoch": 6.184506589521054,
      "grad_norm": 0.0055704303085803986,
      "learning_rate": 7.630986820957892e-06,
      "loss": 0.1692,
      "step": 57720
    },
    {
      "epoch": 6.185578056359156,
      "grad_norm": 0.0001766156783560291,
      "learning_rate": 7.6288438872816895e-06,
      "loss": 0.1267,
      "step": 57730
    },
    {
      "epoch": 6.186649523197257,
      "grad_norm": 0.00019845909264404327,
      "learning_rate": 7.626700953605487e-06,
      "loss": 0.0009,
      "step": 57740
    },
    {
      "epoch": 6.187720990035358,
      "grad_norm": 0.007353358902037144,
      "learning_rate": 7.624558019929283e-06,
      "loss": 0.0002,
      "step": 57750
    },
    {
      "epoch": 6.188792456873459,
      "grad_norm": 0.00015299661026801914,
      "learning_rate": 7.622415086253081e-06,
      "loss": 0.1522,
      "step": 57760
    },
    {
      "epoch": 6.189863923711561,
      "grad_norm": 0.0062048048712313175,
      "learning_rate": 7.620272152576879e-06,
      "loss": 0.0009,
      "step": 57770
    },
    {
      "epoch": 6.1909353905496625,
      "grad_norm": 0.1073155328631401,
      "learning_rate": 7.618129218900676e-06,
      "loss": 0.0003,
      "step": 57780
    },
    {
      "epoch": 6.192006857387764,
      "grad_norm": 0.004768529906868935,
      "learning_rate": 7.615986285224473e-06,
      "loss": 0.0487,
      "step": 57790
    },
    {
      "epoch": 6.193078324225866,
      "grad_norm": 0.00023158866679295897,
      "learning_rate": 7.61384335154827e-06,
      "loss": 0.0001,
      "step": 57800
    },
    {
      "epoch": 6.194149791063967,
      "grad_norm": 0.00020317039161454886,
      "learning_rate": 7.6117004178720675e-06,
      "loss": 0.0,
      "step": 57810
    },
    {
      "epoch": 6.195221257902068,
      "grad_norm": 0.08898431062698364,
      "learning_rate": 7.609557484195866e-06,
      "loss": 0.2329,
      "step": 57820
    },
    {
      "epoch": 6.196292724740169,
      "grad_norm": 0.00012943183537572622,
      "learning_rate": 7.607414550519661e-06,
      "loss": 0.1201,
      "step": 57830
    },
    {
      "epoch": 6.197364191578271,
      "grad_norm": 0.003344058059155941,
      "learning_rate": 7.6052716168434595e-06,
      "loss": 0.0002,
      "step": 57840
    },
    {
      "epoch": 6.198435658416372,
      "grad_norm": 0.0010992728639394045,
      "learning_rate": 7.603128683167257e-06,
      "loss": 0.0001,
      "step": 57850
    },
    {
      "epoch": 6.199507125254473,
      "grad_norm": 0.010807533748447895,
      "learning_rate": 7.600985749491054e-06,
      "loss": 0.0001,
      "step": 57860
    },
    {
      "epoch": 6.200578592092575,
      "grad_norm": 0.00013822794426232576,
      "learning_rate": 7.598842815814851e-06,
      "loss": 0.0062,
      "step": 57870
    },
    {
      "epoch": 6.201650058930676,
      "grad_norm": 0.3596312403678894,
      "learning_rate": 7.596699882138648e-06,
      "loss": 0.001,
      "step": 57880
    },
    {
      "epoch": 6.202721525768777,
      "grad_norm": 2.2921953201293945,
      "learning_rate": 7.594556948462446e-06,
      "loss": 0.001,
      "step": 57890
    },
    {
      "epoch": 6.203792992606878,
      "grad_norm": 0.04761665314435959,
      "learning_rate": 7.592414014786244e-06,
      "loss": 0.1261,
      "step": 57900
    },
    {
      "epoch": 6.20486445944498,
      "grad_norm": 0.0001796162105165422,
      "learning_rate": 7.59027108111004e-06,
      "loss": 0.0002,
      "step": 57910
    },
    {
      "epoch": 6.2059359262830815,
      "grad_norm": 17.97490119934082,
      "learning_rate": 7.5881281474338375e-06,
      "loss": 0.1493,
      "step": 57920
    },
    {
      "epoch": 6.207007393121183,
      "grad_norm": 0.0002246111980639398,
      "learning_rate": 7.585985213757635e-06,
      "loss": 0.1786,
      "step": 57930
    },
    {
      "epoch": 6.208078859959285,
      "grad_norm": 0.012003946118056774,
      "learning_rate": 7.583842280081432e-06,
      "loss": 0.0002,
      "step": 57940
    },
    {
      "epoch": 6.209150326797386,
      "grad_norm": 0.0001881659118225798,
      "learning_rate": 7.581699346405229e-06,
      "loss": 0.1361,
      "step": 57950
    },
    {
      "epoch": 6.210221793635487,
      "grad_norm": 0.001044325646944344,
      "learning_rate": 7.579556412729027e-06,
      "loss": 0.0004,
      "step": 57960
    },
    {
      "epoch": 6.211293260473588,
      "grad_norm": 0.014073302038013935,
      "learning_rate": 7.577413479052824e-06,
      "loss": 0.0007,
      "step": 57970
    },
    {
      "epoch": 6.21236472731169,
      "grad_norm": 0.003165872534736991,
      "learning_rate": 7.575270545376622e-06,
      "loss": 0.2778,
      "step": 57980
    },
    {
      "epoch": 6.213436194149791,
      "grad_norm": 0.0002145210310118273,
      "learning_rate": 7.573127611700418e-06,
      "loss": 0.0001,
      "step": 57990
    },
    {
      "epoch": 6.214507660987892,
      "grad_norm": 0.02901092916727066,
      "learning_rate": 7.5709846780242155e-06,
      "loss": 0.0019,
      "step": 58000
    },
    {
      "epoch": 6.215579127825994,
      "grad_norm": 0.0007588419830426574,
      "learning_rate": 7.568841744348014e-06,
      "loss": 0.0015,
      "step": 58010
    },
    {
      "epoch": 6.216650594664095,
      "grad_norm": 0.00031613220926374197,
      "learning_rate": 7.566698810671809e-06,
      "loss": 0.133,
      "step": 58020
    },
    {
      "epoch": 6.217722061502196,
      "grad_norm": 0.0005418402142822742,
      "learning_rate": 7.564555876995608e-06,
      "loss": 0.0004,
      "step": 58030
    },
    {
      "epoch": 6.2187935283402975,
      "grad_norm": 0.010211959481239319,
      "learning_rate": 7.562412943319405e-06,
      "loss": 0.236,
      "step": 58040
    },
    {
      "epoch": 6.2198649951783995,
      "grad_norm": 13.518289566040039,
      "learning_rate": 7.560270009643202e-06,
      "loss": 0.5699,
      "step": 58050
    },
    {
      "epoch": 6.220936462016501,
      "grad_norm": 0.0026193871162831783,
      "learning_rate": 7.558127075966999e-06,
      "loss": 0.3126,
      "step": 58060
    },
    {
      "epoch": 6.222007928854602,
      "grad_norm": 18.8914737701416,
      "learning_rate": 7.555984142290796e-06,
      "loss": 0.3734,
      "step": 58070
    },
    {
      "epoch": 6.223079395692704,
      "grad_norm": 0.17542317509651184,
      "learning_rate": 7.553841208614594e-06,
      "loss": 0.0645,
      "step": 58080
    },
    {
      "epoch": 6.224150862530805,
      "grad_norm": 0.02074570208787918,
      "learning_rate": 7.551698274938392e-06,
      "loss": 0.0096,
      "step": 58090
    },
    {
      "epoch": 6.225222329368906,
      "grad_norm": 0.03345322981476784,
      "learning_rate": 7.549555341262188e-06,
      "loss": 0.2256,
      "step": 58100
    },
    {
      "epoch": 6.226293796207007,
      "grad_norm": 0.00014867607387714088,
      "learning_rate": 7.547412407585986e-06,
      "loss": 0.0016,
      "step": 58110
    },
    {
      "epoch": 6.227365263045109,
      "grad_norm": 0.00015576228906866163,
      "learning_rate": 7.545269473909783e-06,
      "loss": 0.4768,
      "step": 58120
    },
    {
      "epoch": 6.22843672988321,
      "grad_norm": 0.008130691945552826,
      "learning_rate": 7.54312654023358e-06,
      "loss": 0.4562,
      "step": 58130
    },
    {
      "epoch": 6.229508196721311,
      "grad_norm": 0.389860063791275,
      "learning_rate": 7.540983606557377e-06,
      "loss": 0.1323,
      "step": 58140
    },
    {
      "epoch": 6.230579663559412,
      "grad_norm": 0.00024370869505219162,
      "learning_rate": 7.538840672881175e-06,
      "loss": 0.158,
      "step": 58150
    },
    {
      "epoch": 6.231651130397514,
      "grad_norm": 0.21583695709705353,
      "learning_rate": 7.536697739204972e-06,
      "loss": 0.3189,
      "step": 58160
    },
    {
      "epoch": 6.2327225972356155,
      "grad_norm": 0.006094501353800297,
      "learning_rate": 7.53455480552877e-06,
      "loss": 0.342,
      "step": 58170
    },
    {
      "epoch": 6.233794064073717,
      "grad_norm": 0.00694266427308321,
      "learning_rate": 7.532411871852566e-06,
      "loss": 0.1809,
      "step": 58180
    },
    {
      "epoch": 6.234865530911819,
      "grad_norm": 0.15681621432304382,
      "learning_rate": 7.530268938176364e-06,
      "loss": 0.0007,
      "step": 58190
    },
    {
      "epoch": 6.23593699774992,
      "grad_norm": 0.012828836217522621,
      "learning_rate": 7.528126004500162e-06,
      "loss": 0.2948,
      "step": 58200
    },
    {
      "epoch": 6.237008464588021,
      "grad_norm": 0.003974538296461105,
      "learning_rate": 7.525983070823959e-06,
      "loss": 0.0018,
      "step": 58210
    },
    {
      "epoch": 6.238079931426122,
      "grad_norm": 0.0031529816333204508,
      "learning_rate": 7.523840137147756e-06,
      "loss": 0.0013,
      "step": 58220
    },
    {
      "epoch": 6.239151398264224,
      "grad_norm": 0.0005534426309168339,
      "learning_rate": 7.521697203471553e-06,
      "loss": 0.2248,
      "step": 58230
    },
    {
      "epoch": 6.240222865102325,
      "grad_norm": 0.006899332161992788,
      "learning_rate": 7.51955426979535e-06,
      "loss": 0.1103,
      "step": 58240
    },
    {
      "epoch": 6.241294331940426,
      "grad_norm": 0.0183444544672966,
      "learning_rate": 7.517411336119148e-06,
      "loss": 0.0005,
      "step": 58250
    },
    {
      "epoch": 6.242365798778528,
      "grad_norm": 0.03372064232826233,
      "learning_rate": 7.515268402442944e-06,
      "loss": 0.0006,
      "step": 58260
    },
    {
      "epoch": 6.243437265616629,
      "grad_norm": 0.0003619362832978368,
      "learning_rate": 7.5131254687667424e-06,
      "loss": 0.1736,
      "step": 58270
    },
    {
      "epoch": 6.24450873245473,
      "grad_norm": 0.00029886674019508064,
      "learning_rate": 7.51098253509054e-06,
      "loss": 0.0004,
      "step": 58280
    },
    {
      "epoch": 6.2455801992928315,
      "grad_norm": 0.005931742489337921,
      "learning_rate": 7.508839601414337e-06,
      "loss": 0.0001,
      "step": 58290
    },
    {
      "epoch": 6.2466516661309335,
      "grad_norm": 0.006459755823016167,
      "learning_rate": 7.506696667738134e-06,
      "loss": 0.1248,
      "step": 58300
    },
    {
      "epoch": 6.247723132969035,
      "grad_norm": 0.0003129091637674719,
      "learning_rate": 7.504553734061931e-06,
      "loss": 0.0001,
      "step": 58310
    },
    {
      "epoch": 6.248794599807136,
      "grad_norm": 0.008530492894351482,
      "learning_rate": 7.502410800385728e-06,
      "loss": 0.0034,
      "step": 58320
    },
    {
      "epoch": 6.249866066645238,
      "grad_norm": 0.009094302542507648,
      "learning_rate": 7.500267866709527e-06,
      "loss": 0.1374,
      "step": 58330
    },
    {
      "epoch": 6.250937533483339,
      "grad_norm": 0.0002292283606948331,
      "learning_rate": 7.498124933033323e-06,
      "loss": 0.2673,
      "step": 58340
    },
    {
      "epoch": 6.25200900032144,
      "grad_norm": 0.00100826530251652,
      "learning_rate": 7.4959819993571204e-06,
      "loss": 0.0002,
      "step": 58350
    },
    {
      "epoch": 6.253080467159541,
      "grad_norm": 0.00022792154049966484,
      "learning_rate": 7.493839065680918e-06,
      "loss": 0.001,
      "step": 58360
    },
    {
      "epoch": 6.254151933997643,
      "grad_norm": 0.0011834288015961647,
      "learning_rate": 7.491696132004715e-06,
      "loss": 0.0012,
      "step": 58370
    },
    {
      "epoch": 6.255223400835744,
      "grad_norm": 0.004634274169802666,
      "learning_rate": 7.489553198328512e-06,
      "loss": 0.0002,
      "step": 58380
    },
    {
      "epoch": 6.256294867673845,
      "grad_norm": 0.00019180835806764662,
      "learning_rate": 7.48741026465231e-06,
      "loss": 0.0006,
      "step": 58390
    },
    {
      "epoch": 6.257366334511947,
      "grad_norm": 0.008709282614290714,
      "learning_rate": 7.485267330976107e-06,
      "loss": 0.0002,
      "step": 58400
    },
    {
      "epoch": 6.258437801350048,
      "grad_norm": 20.127243041992188,
      "learning_rate": 7.483124397299905e-06,
      "loss": 0.1521,
      "step": 58410
    },
    {
      "epoch": 6.2595092681881495,
      "grad_norm": 0.00018335079948883504,
      "learning_rate": 7.480981463623701e-06,
      "loss": 0.0001,
      "step": 58420
    },
    {
      "epoch": 6.260580735026251,
      "grad_norm": 0.00024617902818135917,
      "learning_rate": 7.4788385299474984e-06,
      "loss": 0.0002,
      "step": 58430
    },
    {
      "epoch": 6.261652201864353,
      "grad_norm": 0.0020341540221124887,
      "learning_rate": 7.476695596271296e-06,
      "loss": 0.3473,
      "step": 58440
    },
    {
      "epoch": 6.262723668702454,
      "grad_norm": 0.013555255718529224,
      "learning_rate": 7.474552662595094e-06,
      "loss": 0.0383,
      "step": 58450
    },
    {
      "epoch": 6.263795135540555,
      "grad_norm": 19.1744384765625,
      "learning_rate": 7.4724097289188905e-06,
      "loss": 0.1823,
      "step": 58460
    },
    {
      "epoch": 6.264866602378657,
      "grad_norm": 0.038392242044210434,
      "learning_rate": 7.470266795242688e-06,
      "loss": 0.1461,
      "step": 58470
    },
    {
      "epoch": 6.265938069216758,
      "grad_norm": 0.009634516201913357,
      "learning_rate": 7.468123861566485e-06,
      "loss": 0.0001,
      "step": 58480
    },
    {
      "epoch": 6.267009536054859,
      "grad_norm": 0.009759293869137764,
      "learning_rate": 7.465980927890283e-06,
      "loss": 0.0006,
      "step": 58490
    },
    {
      "epoch": 6.26808100289296,
      "grad_norm": 0.00038362876512110233,
      "learning_rate": 7.463837994214079e-06,
      "loss": 0.0003,
      "step": 58500
    },
    {
      "epoch": 6.269152469731062,
      "grad_norm": 0.00468001514673233,
      "learning_rate": 7.4616950605378764e-06,
      "loss": 0.2142,
      "step": 58510
    },
    {
      "epoch": 6.270223936569163,
      "grad_norm": 0.022736433893442154,
      "learning_rate": 7.459552126861675e-06,
      "loss": 0.0003,
      "step": 58520
    },
    {
      "epoch": 6.271295403407264,
      "grad_norm": 0.0006580664776265621,
      "learning_rate": 7.457409193185472e-06,
      "loss": 0.2301,
      "step": 58530
    },
    {
      "epoch": 6.272366870245366,
      "grad_norm": 24.556886672973633,
      "learning_rate": 7.4552662595092685e-06,
      "loss": 0.3508,
      "step": 58540
    },
    {
      "epoch": 6.273438337083467,
      "grad_norm": 0.007087551988661289,
      "learning_rate": 7.453123325833066e-06,
      "loss": 0.0006,
      "step": 58550
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 0.00046728577581234276,
      "learning_rate": 7.450980392156863e-06,
      "loss": 0.0002,
      "step": 58560
    },
    {
      "epoch": 6.27558127075967,
      "grad_norm": 0.00018203907529823482,
      "learning_rate": 7.4488374584806614e-06,
      "loss": 0.001,
      "step": 58570
    },
    {
      "epoch": 6.276652737597772,
      "grad_norm": 0.00021539832232519984,
      "learning_rate": 7.446694524804458e-06,
      "loss": 0.0006,
      "step": 58580
    },
    {
      "epoch": 6.277724204435873,
      "grad_norm": 0.0001892002474050969,
      "learning_rate": 7.444551591128255e-06,
      "loss": 0.1385,
      "step": 58590
    },
    {
      "epoch": 6.278795671273974,
      "grad_norm": 0.06402630358934402,
      "learning_rate": 7.442408657452053e-06,
      "loss": 0.0114,
      "step": 58600
    },
    {
      "epoch": 6.279867138112076,
      "grad_norm": 0.00024397725064773113,
      "learning_rate": 7.44026572377585e-06,
      "loss": 0.2622,
      "step": 58610
    },
    {
      "epoch": 6.280938604950177,
      "grad_norm": 0.008950711227953434,
      "learning_rate": 7.4381227900996465e-06,
      "loss": 0.136,
      "step": 58620
    },
    {
      "epoch": 6.282010071788278,
      "grad_norm": 0.1030917838215828,
      "learning_rate": 7.435979856423444e-06,
      "loss": 0.0893,
      "step": 58630
    },
    {
      "epoch": 6.283081538626379,
      "grad_norm": 0.10194854438304901,
      "learning_rate": 7.433836922747242e-06,
      "loss": 0.1979,
      "step": 58640
    },
    {
      "epoch": 6.284153005464481,
      "grad_norm": 0.004201035480946302,
      "learning_rate": 7.4316939890710394e-06,
      "loss": 0.3317,
      "step": 58650
    },
    {
      "epoch": 6.285224472302582,
      "grad_norm": 0.014160724356770515,
      "learning_rate": 7.429551055394836e-06,
      "loss": 0.0,
      "step": 58660
    },
    {
      "epoch": 6.286295939140683,
      "grad_norm": 0.00494700763374567,
      "learning_rate": 7.427408121718633e-06,
      "loss": 0.0004,
      "step": 58670
    },
    {
      "epoch": 6.2873674059787845,
      "grad_norm": 0.001715735299512744,
      "learning_rate": 7.425265188042431e-06,
      "loss": 0.0009,
      "step": 58680
    },
    {
      "epoch": 6.2884388728168865,
      "grad_norm": 0.0002079716941807419,
      "learning_rate": 7.423122254366229e-06,
      "loss": 0.0009,
      "step": 58690
    },
    {
      "epoch": 6.289510339654988,
      "grad_norm": 0.012124505825340748,
      "learning_rate": 7.4209793206900245e-06,
      "loss": 0.1226,
      "step": 58700
    },
    {
      "epoch": 6.290581806493089,
      "grad_norm": 0.0044543202966451645,
      "learning_rate": 7.418836387013823e-06,
      "loss": 0.0009,
      "step": 58710
    },
    {
      "epoch": 6.291653273331191,
      "grad_norm": 0.0001819039462134242,
      "learning_rate": 7.41669345333762e-06,
      "loss": 0.1614,
      "step": 58720
    },
    {
      "epoch": 6.292724740169292,
      "grad_norm": 0.0036072840448468924,
      "learning_rate": 7.414550519661417e-06,
      "loss": 0.0045,
      "step": 58730
    },
    {
      "epoch": 6.293796207007393,
      "grad_norm": 0.004903044551610947,
      "learning_rate": 7.412407585985214e-06,
      "loss": 0.0405,
      "step": 58740
    },
    {
      "epoch": 6.294867673845495,
      "grad_norm": 0.003721160115674138,
      "learning_rate": 7.410264652309011e-06,
      "loss": 0.0001,
      "step": 58750
    },
    {
      "epoch": 6.295939140683596,
      "grad_norm": 0.00023315908038057387,
      "learning_rate": 7.4081217186328095e-06,
      "loss": 0.6778,
      "step": 58760
    },
    {
      "epoch": 6.297010607521697,
      "grad_norm": 0.004347451962530613,
      "learning_rate": 7.405978784956607e-06,
      "loss": 0.6527,
      "step": 58770
    },
    {
      "epoch": 6.298082074359798,
      "grad_norm": 0.0048476895317435265,
      "learning_rate": 7.403835851280403e-06,
      "loss": 0.0003,
      "step": 58780
    },
    {
      "epoch": 6.2991535411979,
      "grad_norm": 0.0006133926217444241,
      "learning_rate": 7.401692917604201e-06,
      "loss": 0.4444,
      "step": 58790
    },
    {
      "epoch": 6.300225008036001,
      "grad_norm": 0.00043711051694117486,
      "learning_rate": 7.399549983927998e-06,
      "loss": 0.171,
      "step": 58800
    },
    {
      "epoch": 6.3012964748741025,
      "grad_norm": 0.008550907485187054,
      "learning_rate": 7.397407050251795e-06,
      "loss": 0.0005,
      "step": 58810
    },
    {
      "epoch": 6.302367941712204,
      "grad_norm": 0.17975282669067383,
      "learning_rate": 7.395264116575592e-06,
      "loss": 0.2434,
      "step": 58820
    },
    {
      "epoch": 6.303439408550306,
      "grad_norm": 19.665035247802734,
      "learning_rate": 7.39312118289939e-06,
      "loss": 0.1124,
      "step": 58830
    },
    {
      "epoch": 6.304510875388407,
      "grad_norm": 0.002926178276538849,
      "learning_rate": 7.3909782492231875e-06,
      "loss": 0.2222,
      "step": 58840
    },
    {
      "epoch": 6.305582342226508,
      "grad_norm": 0.006736610550433397,
      "learning_rate": 7.388835315546985e-06,
      "loss": 0.0013,
      "step": 58850
    },
    {
      "epoch": 6.30665380906461,
      "grad_norm": 0.0005351625732146204,
      "learning_rate": 7.386692381870781e-06,
      "loss": 0.0004,
      "step": 58860
    },
    {
      "epoch": 6.307725275902711,
      "grad_norm": 36.35038375854492,
      "learning_rate": 7.384549448194579e-06,
      "loss": 0.3183,
      "step": 58870
    },
    {
      "epoch": 6.308796742740812,
      "grad_norm": 0.279493123292923,
      "learning_rate": 7.382406514518377e-06,
      "loss": 0.0014,
      "step": 58880
    },
    {
      "epoch": 6.309868209578913,
      "grad_norm": 0.011995944194495678,
      "learning_rate": 7.380263580842174e-06,
      "loss": 0.1155,
      "step": 58890
    },
    {
      "epoch": 6.310939676417015,
      "grad_norm": 37.5651969909668,
      "learning_rate": 7.378120647165971e-06,
      "loss": 0.1188,
      "step": 58900
    },
    {
      "epoch": 6.312011143255116,
      "grad_norm": 0.015374308452010155,
      "learning_rate": 7.375977713489768e-06,
      "loss": 0.2123,
      "step": 58910
    },
    {
      "epoch": 6.313082610093217,
      "grad_norm": 0.0008129820344038308,
      "learning_rate": 7.3738347798135655e-06,
      "loss": 0.0002,
      "step": 58920
    },
    {
      "epoch": 6.314154076931319,
      "grad_norm": 0.0005822647362947464,
      "learning_rate": 7.371691846137362e-06,
      "loss": 0.0028,
      "step": 58930
    },
    {
      "epoch": 6.3152255437694205,
      "grad_norm": 0.0012064430629834533,
      "learning_rate": 7.369548912461159e-06,
      "loss": 0.0641,
      "step": 58940
    },
    {
      "epoch": 6.316297010607522,
      "grad_norm": 0.0005916050868108869,
      "learning_rate": 7.3674059787849576e-06,
      "loss": 0.0005,
      "step": 58950
    },
    {
      "epoch": 6.317368477445623,
      "grad_norm": 0.0005529400077648461,
      "learning_rate": 7.365263045108755e-06,
      "loss": 0.0002,
      "step": 58960
    },
    {
      "epoch": 6.318439944283725,
      "grad_norm": 0.13320361077785492,
      "learning_rate": 7.363120111432551e-06,
      "loss": 0.1566,
      "step": 58970
    },
    {
      "epoch": 6.319511411121826,
      "grad_norm": 0.00034915373544208705,
      "learning_rate": 7.360977177756349e-06,
      "loss": 0.0007,
      "step": 58980
    },
    {
      "epoch": 6.320582877959927,
      "grad_norm": 0.010873572900891304,
      "learning_rate": 7.358834244080146e-06,
      "loss": 0.2502,
      "step": 58990
    },
    {
      "epoch": 6.321654344798029,
      "grad_norm": 0.6136327385902405,
      "learning_rate": 7.3566913104039435e-06,
      "loss": 0.0007,
      "step": 59000
    },
    {
      "epoch": 6.32272581163613,
      "grad_norm": 0.0006731136236339808,
      "learning_rate": 7.35454837672774e-06,
      "loss": 0.1953,
      "step": 59010
    },
    {
      "epoch": 6.323797278474231,
      "grad_norm": 0.5132749676704407,
      "learning_rate": 7.352405443051538e-06,
      "loss": 0.3122,
      "step": 59020
    },
    {
      "epoch": 6.324868745312332,
      "grad_norm": 0.013125509954988956,
      "learning_rate": 7.3502625093753356e-06,
      "loss": 0.1322,
      "step": 59030
    },
    {
      "epoch": 6.325940212150434,
      "grad_norm": 0.01573771983385086,
      "learning_rate": 7.348119575699133e-06,
      "loss": 0.0934,
      "step": 59040
    },
    {
      "epoch": 6.327011678988535,
      "grad_norm": 25.02191925048828,
      "learning_rate": 7.345976642022929e-06,
      "loss": 0.3556,
      "step": 59050
    },
    {
      "epoch": 6.3280831458266364,
      "grad_norm": 0.0215457733720541,
      "learning_rate": 7.343833708346727e-06,
      "loss": 0.0006,
      "step": 59060
    },
    {
      "epoch": 6.3291546126647376,
      "grad_norm": 0.07763129472732544,
      "learning_rate": 7.341690774670525e-06,
      "loss": 0.0006,
      "step": 59070
    },
    {
      "epoch": 6.3302260795028396,
      "grad_norm": 0.04679182916879654,
      "learning_rate": 7.339547840994322e-06,
      "loss": 0.0015,
      "step": 59080
    },
    {
      "epoch": 6.331297546340941,
      "grad_norm": 0.013251187279820442,
      "learning_rate": 7.337404907318119e-06,
      "loss": 0.0002,
      "step": 59090
    },
    {
      "epoch": 6.332369013179042,
      "grad_norm": 0.0254677664488554,
      "learning_rate": 7.335261973641916e-06,
      "loss": 0.0023,
      "step": 59100
    },
    {
      "epoch": 6.333440480017144,
      "grad_norm": 0.007953083142638206,
      "learning_rate": 7.3331190399657136e-06,
      "loss": 0.2537,
      "step": 59110
    },
    {
      "epoch": 6.334511946855245,
      "grad_norm": 0.027638044208288193,
      "learning_rate": 7.330976106289511e-06,
      "loss": 0.1623,
      "step": 59120
    },
    {
      "epoch": 6.335583413693346,
      "grad_norm": 0.0013952743029221892,
      "learning_rate": 7.328833172613307e-06,
      "loss": 0.0009,
      "step": 59130
    },
    {
      "epoch": 6.336654880531448,
      "grad_norm": 0.005566921550780535,
      "learning_rate": 7.326690238937106e-06,
      "loss": 0.0004,
      "step": 59140
    },
    {
      "epoch": 6.337726347369549,
      "grad_norm": 0.0013515590690076351,
      "learning_rate": 7.324547305260903e-06,
      "loss": 0.4687,
      "step": 59150
    },
    {
      "epoch": 6.33879781420765,
      "grad_norm": 0.01929110288619995,
      "learning_rate": 7.3224043715847e-06,
      "loss": 0.0013,
      "step": 59160
    },
    {
      "epoch": 6.339869281045751,
      "grad_norm": 0.0017045884160324931,
      "learning_rate": 7.320261437908497e-06,
      "loss": 0.2906,
      "step": 59170
    },
    {
      "epoch": 6.340940747883853,
      "grad_norm": 15.278770446777344,
      "learning_rate": 7.318118504232294e-06,
      "loss": 0.2411,
      "step": 59180
    },
    {
      "epoch": 6.342012214721954,
      "grad_norm": 0.015562541782855988,
      "learning_rate": 7.3159755705560916e-06,
      "loss": 0.0009,
      "step": 59190
    },
    {
      "epoch": 6.3430836815600555,
      "grad_norm": 0.001277804491110146,
      "learning_rate": 7.31383263687989e-06,
      "loss": 0.0911,
      "step": 59200
    },
    {
      "epoch": 6.344155148398157,
      "grad_norm": 0.024035265669226646,
      "learning_rate": 7.311689703203686e-06,
      "loss": 0.0006,
      "step": 59210
    },
    {
      "epoch": 6.345226615236259,
      "grad_norm": 0.0006555852014571428,
      "learning_rate": 7.309546769527484e-06,
      "loss": 0.0007,
      "step": 59220
    },
    {
      "epoch": 6.34629808207436,
      "grad_norm": 0.023448489606380463,
      "learning_rate": 7.307403835851281e-06,
      "loss": 0.0075,
      "step": 59230
    },
    {
      "epoch": 6.347369548912461,
      "grad_norm": 0.016933832317590714,
      "learning_rate": 7.305260902175078e-06,
      "loss": 0.0004,
      "step": 59240
    },
    {
      "epoch": 6.348441015750563,
      "grad_norm": 0.009701317176222801,
      "learning_rate": 7.303117968498875e-06,
      "loss": 0.2521,
      "step": 59250
    },
    {
      "epoch": 6.349512482588664,
      "grad_norm": 104.20626068115234,
      "learning_rate": 7.300975034822673e-06,
      "loss": 0.1289,
      "step": 59260
    },
    {
      "epoch": 6.350583949426765,
      "grad_norm": 0.0058649806305766106,
      "learning_rate": 7.29883210114647e-06,
      "loss": 0.6315,
      "step": 59270
    },
    {
      "epoch": 6.351655416264867,
      "grad_norm": 19.31235694885254,
      "learning_rate": 7.296689167470268e-06,
      "loss": 0.1563,
      "step": 59280
    },
    {
      "epoch": 6.352726883102968,
      "grad_norm": 0.0011620939476415515,
      "learning_rate": 7.294546233794064e-06,
      "loss": 0.0002,
      "step": 59290
    },
    {
      "epoch": 6.353798349941069,
      "grad_norm": 0.03561567887663841,
      "learning_rate": 7.292403300117862e-06,
      "loss": 0.2169,
      "step": 59300
    },
    {
      "epoch": 6.35486981677917,
      "grad_norm": 0.013683759607374668,
      "learning_rate": 7.290260366441659e-06,
      "loss": 0.0005,
      "step": 59310
    },
    {
      "epoch": 6.355941283617272,
      "grad_norm": 57.42596435546875,
      "learning_rate": 7.288117432765457e-06,
      "loss": 0.0266,
      "step": 59320
    },
    {
      "epoch": 6.3570127504553735,
      "grad_norm": 94.43702697753906,
      "learning_rate": 7.285974499089254e-06,
      "loss": 0.1701,
      "step": 59330
    },
    {
      "epoch": 6.358084217293475,
      "grad_norm": 0.0009778010426089168,
      "learning_rate": 7.283831565413051e-06,
      "loss": 0.0903,
      "step": 59340
    },
    {
      "epoch": 6.359155684131576,
      "grad_norm": 0.011226545087993145,
      "learning_rate": 7.281688631736848e-06,
      "loss": 0.29,
      "step": 59350
    },
    {
      "epoch": 6.360227150969678,
      "grad_norm": 0.014700712636113167,
      "learning_rate": 7.279545698060646e-06,
      "loss": 0.168,
      "step": 59360
    },
    {
      "epoch": 6.361298617807779,
      "grad_norm": 0.0011327695101499557,
      "learning_rate": 7.277402764384442e-06,
      "loss": 0.0009,
      "step": 59370
    },
    {
      "epoch": 6.36237008464588,
      "grad_norm": 0.16001059114933014,
      "learning_rate": 7.2752598307082405e-06,
      "loss": 0.1568,
      "step": 59380
    },
    {
      "epoch": 6.363441551483982,
      "grad_norm": 0.006394014693796635,
      "learning_rate": 7.273116897032038e-06,
      "loss": 0.1519,
      "step": 59390
    },
    {
      "epoch": 6.364513018322083,
      "grad_norm": 0.2041892111301422,
      "learning_rate": 7.270973963355835e-06,
      "loss": 0.2272,
      "step": 59400
    },
    {
      "epoch": 6.365584485160184,
      "grad_norm": 0.0027757477946579456,
      "learning_rate": 7.268831029679632e-06,
      "loss": 0.0003,
      "step": 59410
    },
    {
      "epoch": 6.366655951998285,
      "grad_norm": 0.0007381914183497429,
      "learning_rate": 7.266688096003429e-06,
      "loss": 0.0528,
      "step": 59420
    },
    {
      "epoch": 6.367727418836387,
      "grad_norm": 0.29771295189857483,
      "learning_rate": 7.264545162327226e-06,
      "loss": 0.3629,
      "step": 59430
    },
    {
      "epoch": 6.368798885674488,
      "grad_norm": 0.015730563551187515,
      "learning_rate": 7.262402228651025e-06,
      "loss": 0.0004,
      "step": 59440
    },
    {
      "epoch": 6.3698703525125895,
      "grad_norm": 0.0007383652846328914,
      "learning_rate": 7.260259294974821e-06,
      "loss": 0.003,
      "step": 59450
    },
    {
      "epoch": 6.3709418193506915,
      "grad_norm": 0.0011385291581973433,
      "learning_rate": 7.2581163612986185e-06,
      "loss": 0.1221,
      "step": 59460
    },
    {
      "epoch": 6.372013286188793,
      "grad_norm": 0.03536124527454376,
      "learning_rate": 7.255973427622416e-06,
      "loss": 0.0008,
      "step": 59470
    },
    {
      "epoch": 6.373084753026894,
      "grad_norm": 0.0033264525700360537,
      "learning_rate": 7.253830493946213e-06,
      "loss": 0.5596,
      "step": 59480
    },
    {
      "epoch": 6.374156219864995,
      "grad_norm": 0.02736225537955761,
      "learning_rate": 7.25168756027001e-06,
      "loss": 0.0003,
      "step": 59490
    },
    {
      "epoch": 6.375227686703097,
      "grad_norm": 0.04864008352160454,
      "learning_rate": 7.249544626593807e-06,
      "loss": 0.0009,
      "step": 59500
    },
    {
      "epoch": 6.376299153541198,
      "grad_norm": 0.02832040563225746,
      "learning_rate": 7.247401692917605e-06,
      "loss": 0.007,
      "step": 59510
    },
    {
      "epoch": 6.377370620379299,
      "grad_norm": 0.025582505390048027,
      "learning_rate": 7.245258759241403e-06,
      "loss": 0.0003,
      "step": 59520
    },
    {
      "epoch": 6.378442087217401,
      "grad_norm": 0.0062664346769452095,
      "learning_rate": 7.243115825565199e-06,
      "loss": 0.0076,
      "step": 59530
    },
    {
      "epoch": 6.379513554055502,
      "grad_norm": 0.0018967959331348538,
      "learning_rate": 7.2409728918889965e-06,
      "loss": 0.0323,
      "step": 59540
    },
    {
      "epoch": 6.380585020893603,
      "grad_norm": 0.005798404570668936,
      "learning_rate": 7.238829958212794e-06,
      "loss": 0.0031,
      "step": 59550
    },
    {
      "epoch": 6.381656487731704,
      "grad_norm": 0.05844347923994064,
      "learning_rate": 7.236687024536592e-06,
      "loss": 0.0008,
      "step": 59560
    },
    {
      "epoch": 6.382727954569806,
      "grad_norm": 0.0008267511148005724,
      "learning_rate": 7.2345440908603885e-06,
      "loss": 0.0002,
      "step": 59570
    },
    {
      "epoch": 6.3837994214079075,
      "grad_norm": 0.06414181739091873,
      "learning_rate": 7.232401157184186e-06,
      "loss": 0.4691,
      "step": 59580
    },
    {
      "epoch": 6.384870888246009,
      "grad_norm": 0.0019561268854886293,
      "learning_rate": 7.230258223507983e-06,
      "loss": 0.0003,
      "step": 59590
    },
    {
      "epoch": 6.38594235508411,
      "grad_norm": 0.031069189310073853,
      "learning_rate": 7.228115289831781e-06,
      "loss": 0.0007,
      "step": 59600
    },
    {
      "epoch": 6.387013821922212,
      "grad_norm": 0.0066374242305755615,
      "learning_rate": 7.225972356155577e-06,
      "loss": 0.0003,
      "step": 59610
    },
    {
      "epoch": 6.388085288760313,
      "grad_norm": 0.0006295706843957305,
      "learning_rate": 7.2238294224793745e-06,
      "loss": 0.4313,
      "step": 59620
    },
    {
      "epoch": 6.389156755598414,
      "grad_norm": 0.11818540841341019,
      "learning_rate": 7.221686488803173e-06,
      "loss": 0.0008,
      "step": 59630
    },
    {
      "epoch": 6.390228222436516,
      "grad_norm": 0.2277071326971054,
      "learning_rate": 7.21954355512697e-06,
      "loss": 0.2211,
      "step": 59640
    },
    {
      "epoch": 6.391299689274617,
      "grad_norm": 0.028286036103963852,
      "learning_rate": 7.2174006214507665e-06,
      "loss": 0.0003,
      "step": 59650
    },
    {
      "epoch": 6.392371156112718,
      "grad_norm": 0.0016977073391899467,
      "learning_rate": 7.215257687774564e-06,
      "loss": 0.0023,
      "step": 59660
    },
    {
      "epoch": 6.39344262295082,
      "grad_norm": 0.018217694014310837,
      "learning_rate": 7.213114754098361e-06,
      "loss": 0.1173,
      "step": 59670
    },
    {
      "epoch": 6.394514089788921,
      "grad_norm": 0.02551967091858387,
      "learning_rate": 7.2109718204221594e-06,
      "loss": 0.1816,
      "step": 59680
    },
    {
      "epoch": 6.395585556627022,
      "grad_norm": 0.18039749562740326,
      "learning_rate": 7.208828886745955e-06,
      "loss": 0.001,
      "step": 59690
    },
    {
      "epoch": 6.396657023465123,
      "grad_norm": 0.0044714417308568954,
      "learning_rate": 7.206685953069753e-06,
      "loss": 0.1781,
      "step": 59700
    },
    {
      "epoch": 6.397728490303225,
      "grad_norm": 0.0175959300249815,
      "learning_rate": 7.204543019393551e-06,
      "loss": 0.0004,
      "step": 59710
    },
    {
      "epoch": 6.3987999571413265,
      "grad_norm": 0.023311244323849678,
      "learning_rate": 7.202400085717348e-06,
      "loss": 0.1397,
      "step": 59720
    },
    {
      "epoch": 6.399871423979428,
      "grad_norm": 0.052097126841545105,
      "learning_rate": 7.2002571520411445e-06,
      "loss": 0.0003,
      "step": 59730
    },
    {
      "epoch": 6.400942890817529,
      "grad_norm": 0.019811639562249184,
      "learning_rate": 7.198114218364942e-06,
      "loss": 0.0003,
      "step": 59740
    },
    {
      "epoch": 6.402014357655631,
      "grad_norm": 0.04073672369122505,
      "learning_rate": 7.19597128468874e-06,
      "loss": 0.0284,
      "step": 59750
    },
    {
      "epoch": 6.403085824493732,
      "grad_norm": 0.0012618242762982845,
      "learning_rate": 7.1938283510125374e-06,
      "loss": 0.1397,
      "step": 59760
    },
    {
      "epoch": 6.404157291331833,
      "grad_norm": 27.242290496826172,
      "learning_rate": 7.191685417336334e-06,
      "loss": 0.4061,
      "step": 59770
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 0.004451274871826172,
      "learning_rate": 7.189542483660131e-06,
      "loss": 0.0003,
      "step": 59780
    },
    {
      "epoch": 6.406300225008036,
      "grad_norm": 0.11069648712873459,
      "learning_rate": 7.187399549983929e-06,
      "loss": 0.0049,
      "step": 59790
    },
    {
      "epoch": 6.407371691846137,
      "grad_norm": 0.013142426498234272,
      "learning_rate": 7.185256616307726e-06,
      "loss": 0.2279,
      "step": 59800
    },
    {
      "epoch": 6.408443158684239,
      "grad_norm": 1.241186261177063,
      "learning_rate": 7.1831136826315225e-06,
      "loss": 0.0009,
      "step": 59810
    },
    {
      "epoch": 6.40951462552234,
      "grad_norm": 0.007901146076619625,
      "learning_rate": 7.180970748955321e-06,
      "loss": 0.1386,
      "step": 59820
    },
    {
      "epoch": 6.410586092360441,
      "grad_norm": 0.0028179516084492207,
      "learning_rate": 7.178827815279118e-06,
      "loss": 0.0003,
      "step": 59830
    },
    {
      "epoch": 6.4116575591985425,
      "grad_norm": 45.71890640258789,
      "learning_rate": 7.176684881602915e-06,
      "loss": 0.0632,
      "step": 59840
    },
    {
      "epoch": 6.4127290260366445,
      "grad_norm": 0.07534307986497879,
      "learning_rate": 7.174541947926712e-06,
      "loss": 0.7929,
      "step": 59850
    },
    {
      "epoch": 6.413800492874746,
      "grad_norm": 0.06299182772636414,
      "learning_rate": 7.172399014250509e-06,
      "loss": 0.0006,
      "step": 59860
    },
    {
      "epoch": 6.414871959712847,
      "grad_norm": 0.0025609827134758234,
      "learning_rate": 7.1702560805743075e-06,
      "loss": 0.0009,
      "step": 59870
    },
    {
      "epoch": 6.415943426550948,
      "grad_norm": 0.0017409475985914469,
      "learning_rate": 7.168113146898103e-06,
      "loss": 0.0018,
      "step": 59880
    },
    {
      "epoch": 6.41701489338905,
      "grad_norm": 0.02723492868244648,
      "learning_rate": 7.165970213221901e-06,
      "loss": 0.1329,
      "step": 59890
    },
    {
      "epoch": 6.418086360227151,
      "grad_norm": 0.023895729333162308,
      "learning_rate": 7.163827279545699e-06,
      "loss": 0.2402,
      "step": 59900
    },
    {
      "epoch": 6.419157827065252,
      "grad_norm": 0.02546129748225212,
      "learning_rate": 7.161684345869496e-06,
      "loss": 0.0008,
      "step": 59910
    },
    {
      "epoch": 6.420229293903354,
      "grad_norm": 0.03145015239715576,
      "learning_rate": 7.159541412193293e-06,
      "loss": 0.2331,
      "step": 59920
    },
    {
      "epoch": 6.421300760741455,
      "grad_norm": 0.005689405370503664,
      "learning_rate": 7.15739847851709e-06,
      "loss": 0.0021,
      "step": 59930
    },
    {
      "epoch": 6.422372227579556,
      "grad_norm": 0.052035123109817505,
      "learning_rate": 7.155255544840888e-06,
      "loss": 0.0007,
      "step": 59940
    },
    {
      "epoch": 6.423443694417657,
      "grad_norm": 0.03159969300031662,
      "learning_rate": 7.1531126111646855e-06,
      "loss": 0.1569,
      "step": 59950
    },
    {
      "epoch": 6.424515161255759,
      "grad_norm": 0.005015828181058168,
      "learning_rate": 7.150969677488482e-06,
      "loss": 0.3147,
      "step": 59960
    },
    {
      "epoch": 6.4255866280938605,
      "grad_norm": 0.46251171827316284,
      "learning_rate": 7.148826743812279e-06,
      "loss": 0.0028,
      "step": 59970
    },
    {
      "epoch": 6.426658094931962,
      "grad_norm": 0.01169944740831852,
      "learning_rate": 7.146683810136077e-06,
      "loss": 0.0006,
      "step": 59980
    },
    {
      "epoch": 6.427729561770064,
      "grad_norm": 0.05001001060009003,
      "learning_rate": 7.144540876459874e-06,
      "loss": 0.269,
      "step": 59990
    },
    {
      "epoch": 6.428801028608165,
      "grad_norm": 0.09729299694299698,
      "learning_rate": 7.142397942783671e-06,
      "loss": 0.061,
      "step": 60000
    },
    {
      "epoch": 6.429872495446266,
      "grad_norm": 0.5887423157691956,
      "learning_rate": 7.140255009107469e-06,
      "loss": 0.1704,
      "step": 60010
    },
    {
      "epoch": 6.430943962284367,
      "grad_norm": 0.03833816573023796,
      "learning_rate": 7.138112075431266e-06,
      "loss": 0.1498,
      "step": 60020
    },
    {
      "epoch": 6.432015429122469,
      "grad_norm": 0.049889467656612396,
      "learning_rate": 7.1359691417550635e-06,
      "loss": 0.3037,
      "step": 60030
    },
    {
      "epoch": 6.43308689596057,
      "grad_norm": 0.0258641317486763,
      "learning_rate": 7.13382620807886e-06,
      "loss": 0.178,
      "step": 60040
    },
    {
      "epoch": 6.434158362798671,
      "grad_norm": 0.4270475506782532,
      "learning_rate": 7.131683274402657e-06,
      "loss": 0.0663,
      "step": 60050
    },
    {
      "epoch": 6.435229829636773,
      "grad_norm": 0.16023379564285278,
      "learning_rate": 7.129540340726456e-06,
      "loss": 0.0922,
      "step": 60060
    },
    {
      "epoch": 6.436301296474874,
      "grad_norm": 0.0017961888806894422,
      "learning_rate": 7.127397407050253e-06,
      "loss": 0.0009,
      "step": 60070
    },
    {
      "epoch": 6.437372763312975,
      "grad_norm": 0.01999763771891594,
      "learning_rate": 7.1252544733740494e-06,
      "loss": 0.0004,
      "step": 60080
    },
    {
      "epoch": 6.4384442301510765,
      "grad_norm": 0.001069619320333004,
      "learning_rate": 7.123111539697847e-06,
      "loss": 0.0002,
      "step": 60090
    },
    {
      "epoch": 6.4395156969891785,
      "grad_norm": 0.043251894414424896,
      "learning_rate": 7.120968606021644e-06,
      "loss": 0.3697,
      "step": 60100
    },
    {
      "epoch": 6.44058716382728,
      "grad_norm": 0.001903591095469892,
      "learning_rate": 7.1188256723454415e-06,
      "loss": 0.001,
      "step": 60110
    },
    {
      "epoch": 6.441658630665381,
      "grad_norm": 27.683351516723633,
      "learning_rate": 7.116682738669238e-06,
      "loss": 0.0839,
      "step": 60120
    },
    {
      "epoch": 6.442730097503482,
      "grad_norm": 0.02282889559864998,
      "learning_rate": 7.114539804993036e-06,
      "loss": 0.0007,
      "step": 60130
    },
    {
      "epoch": 6.443801564341584,
      "grad_norm": 0.10546430200338364,
      "learning_rate": 7.112396871316834e-06,
      "loss": 0.1014,
      "step": 60140
    },
    {
      "epoch": 6.444873031179685,
      "grad_norm": 0.015777232125401497,
      "learning_rate": 7.110253937640631e-06,
      "loss": 0.0007,
      "step": 60150
    },
    {
      "epoch": 6.445944498017786,
      "grad_norm": 0.3397802710533142,
      "learning_rate": 7.1081110039644274e-06,
      "loss": 0.141,
      "step": 60160
    },
    {
      "epoch": 6.447015964855888,
      "grad_norm": 0.017285889014601707,
      "learning_rate": 7.105968070288225e-06,
      "loss": 0.0001,
      "step": 60170
    },
    {
      "epoch": 6.448087431693989,
      "grad_norm": 0.030785849317908287,
      "learning_rate": 7.103825136612022e-06,
      "loss": 0.2659,
      "step": 60180
    },
    {
      "epoch": 6.44915889853209,
      "grad_norm": 0.02844148688018322,
      "learning_rate": 7.10168220293582e-06,
      "loss": 0.1777,
      "step": 60190
    },
    {
      "epoch": 6.450230365370192,
      "grad_norm": 1.286299705505371,
      "learning_rate": 7.099539269259617e-06,
      "loss": 0.2278,
      "step": 60200
    },
    {
      "epoch": 6.451301832208293,
      "grad_norm": 0.019012408331036568,
      "learning_rate": 7.097396335583414e-06,
      "loss": 0.0029,
      "step": 60210
    },
    {
      "epoch": 6.4523732990463945,
      "grad_norm": 0.07040407508611679,
      "learning_rate": 7.095253401907212e-06,
      "loss": 0.0966,
      "step": 60220
    },
    {
      "epoch": 6.453444765884496,
      "grad_norm": 0.06818857043981552,
      "learning_rate": 7.093110468231009e-06,
      "loss": 0.1906,
      "step": 60230
    },
    {
      "epoch": 6.454516232722598,
      "grad_norm": 0.12594562768936157,
      "learning_rate": 7.0909675345548054e-06,
      "loss": 0.0005,
      "step": 60240
    },
    {
      "epoch": 6.455587699560699,
      "grad_norm": 0.001353158033452928,
      "learning_rate": 7.088824600878604e-06,
      "loss": 0.1796,
      "step": 60250
    },
    {
      "epoch": 6.4566591663988,
      "grad_norm": 0.003156240563839674,
      "learning_rate": 7.086681667202401e-06,
      "loss": 0.001,
      "step": 60260
    },
    {
      "epoch": 6.457730633236901,
      "grad_norm": 0.0010861039627343416,
      "learning_rate": 7.084538733526198e-06,
      "loss": 0.0006,
      "step": 60270
    },
    {
      "epoch": 6.458802100075003,
      "grad_norm": 0.0011234597768634558,
      "learning_rate": 7.082395799849995e-06,
      "loss": 0.0002,
      "step": 60280
    },
    {
      "epoch": 6.459873566913104,
      "grad_norm": 0.017474647611379623,
      "learning_rate": 7.080252866173792e-06,
      "loss": 0.0002,
      "step": 60290
    },
    {
      "epoch": 6.460945033751205,
      "grad_norm": 0.008818188682198524,
      "learning_rate": 7.07810993249759e-06,
      "loss": 0.2977,
      "step": 60300
    },
    {
      "epoch": 6.462016500589307,
      "grad_norm": 0.022080089896917343,
      "learning_rate": 7.075966998821388e-06,
      "loss": 0.0002,
      "step": 60310
    },
    {
      "epoch": 6.463087967427408,
      "grad_norm": 0.012130167335271835,
      "learning_rate": 7.073824065145184e-06,
      "loss": 0.0004,
      "step": 60320
    },
    {
      "epoch": 6.464159434265509,
      "grad_norm": 0.020343678072094917,
      "learning_rate": 7.071681131468982e-06,
      "loss": 0.0002,
      "step": 60330
    },
    {
      "epoch": 6.46523090110361,
      "grad_norm": 0.03917571157217026,
      "learning_rate": 7.069538197792779e-06,
      "loss": 0.1072,
      "step": 60340
    },
    {
      "epoch": 6.466302367941712,
      "grad_norm": 27.41908073425293,
      "learning_rate": 7.067395264116576e-06,
      "loss": 0.0853,
      "step": 60350
    },
    {
      "epoch": 6.4673738347798135,
      "grad_norm": 0.0004250150523148477,
      "learning_rate": 7.065252330440373e-06,
      "loss": 0.0007,
      "step": 60360
    },
    {
      "epoch": 6.468445301617915,
      "grad_norm": 0.1480954885482788,
      "learning_rate": 7.06310939676417e-06,
      "loss": 0.002,
      "step": 60370
    },
    {
      "epoch": 6.469516768456017,
      "grad_norm": 0.009856032207608223,
      "learning_rate": 7.0609664630879684e-06,
      "loss": 0.0004,
      "step": 60380
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 0.006592026446014643,
      "learning_rate": 7.058823529411766e-06,
      "loss": 0.1302,
      "step": 60390
    },
    {
      "epoch": 6.471659702132219,
      "grad_norm": 0.0005494352662935853,
      "learning_rate": 7.056680595735562e-06,
      "loss": 0.0002,
      "step": 60400
    },
    {
      "epoch": 6.47273116897032,
      "grad_norm": 0.01093322690576315,
      "learning_rate": 7.05453766205936e-06,
      "loss": 0.253,
      "step": 60410
    },
    {
      "epoch": 6.473802635808422,
      "grad_norm": 0.16243450343608856,
      "learning_rate": 7.052394728383157e-06,
      "loss": 0.0008,
      "step": 60420
    },
    {
      "epoch": 6.474874102646523,
      "grad_norm": 0.16541063785552979,
      "learning_rate": 7.050251794706955e-06,
      "loss": 0.0002,
      "step": 60430
    },
    {
      "epoch": 6.475945569484624,
      "grad_norm": 0.1331324428319931,
      "learning_rate": 7.048108861030752e-06,
      "loss": 0.0014,
      "step": 60440
    },
    {
      "epoch": 6.477017036322726,
      "grad_norm": 0.03193998336791992,
      "learning_rate": 7.045965927354549e-06,
      "loss": 0.0854,
      "step": 60450
    },
    {
      "epoch": 6.478088503160827,
      "grad_norm": 0.011809497140347958,
      "learning_rate": 7.0438229936783464e-06,
      "loss": 0.0951,
      "step": 60460
    },
    {
      "epoch": 6.479159969998928,
      "grad_norm": 635.911376953125,
      "learning_rate": 7.041680060002144e-06,
      "loss": 0.0974,
      "step": 60470
    },
    {
      "epoch": 6.4802314368370295,
      "grad_norm": 0.014979254454374313,
      "learning_rate": 7.03953712632594e-06,
      "loss": 0.4295,
      "step": 60480
    },
    {
      "epoch": 6.4813029036751315,
      "grad_norm": 0.0076934052631258965,
      "learning_rate": 7.037394192649738e-06,
      "loss": 0.0003,
      "step": 60490
    },
    {
      "epoch": 6.482374370513233,
      "grad_norm": 0.0009140408947132528,
      "learning_rate": 7.035251258973536e-06,
      "loss": 0.0011,
      "step": 60500
    },
    {
      "epoch": 6.483445837351334,
      "grad_norm": 1.1266478300094604,
      "learning_rate": 7.033108325297333e-06,
      "loss": 0.0009,
      "step": 60510
    },
    {
      "epoch": 6.484517304189436,
      "grad_norm": 0.0073381513357162476,
      "learning_rate": 7.03096539162113e-06,
      "loss": 0.0003,
      "step": 60520
    },
    {
      "epoch": 6.485588771027537,
      "grad_norm": 0.0004489657876547426,
      "learning_rate": 7.028822457944927e-06,
      "loss": 0.5504,
      "step": 60530
    },
    {
      "epoch": 6.486660237865638,
      "grad_norm": 0.00041851209243759513,
      "learning_rate": 7.0266795242687244e-06,
      "loss": 0.003,
      "step": 60540
    },
    {
      "epoch": 6.487731704703739,
      "grad_norm": 0.000529220444150269,
      "learning_rate": 7.024536590592523e-06,
      "loss": 0.0001,
      "step": 60550
    },
    {
      "epoch": 6.488803171541841,
      "grad_norm": 62.62504196166992,
      "learning_rate": 7.022393656916318e-06,
      "loss": 0.2801,
      "step": 60560
    },
    {
      "epoch": 6.489874638379942,
      "grad_norm": 0.008385439403355122,
      "learning_rate": 7.0202507232401165e-06,
      "loss": 0.0003,
      "step": 60570
    },
    {
      "epoch": 6.490946105218043,
      "grad_norm": 0.0008754466543905437,
      "learning_rate": 7.018107789563914e-06,
      "loss": 0.1892,
      "step": 60580
    },
    {
      "epoch": 6.492017572056145,
      "grad_norm": 0.0004995748749934137,
      "learning_rate": 7.015964855887711e-06,
      "loss": 0.1837,
      "step": 60590
    },
    {
      "epoch": 6.493089038894246,
      "grad_norm": 0.0006381928687915206,
      "learning_rate": 7.013821922211508e-06,
      "loss": 0.0176,
      "step": 60600
    },
    {
      "epoch": 6.4941605057323475,
      "grad_norm": 0.0017072074115276337,
      "learning_rate": 7.011678988535305e-06,
      "loss": 0.0002,
      "step": 60610
    },
    {
      "epoch": 6.495231972570449,
      "grad_norm": 0.0008723009377717972,
      "learning_rate": 7.009536054859103e-06,
      "loss": 0.0003,
      "step": 60620
    },
    {
      "epoch": 6.496303439408551,
      "grad_norm": 0.03564226254820824,
      "learning_rate": 7.007393121182901e-06,
      "loss": 0.3646,
      "step": 60630
    },
    {
      "epoch": 6.497374906246652,
      "grad_norm": 0.021786702796816826,
      "learning_rate": 7.005250187506697e-06,
      "loss": 0.1296,
      "step": 60640
    },
    {
      "epoch": 6.498446373084753,
      "grad_norm": 0.0052797324024140835,
      "learning_rate": 7.0031072538304945e-06,
      "loss": 0.0003,
      "step": 60650
    },
    {
      "epoch": 6.499517839922854,
      "grad_norm": 0.008572735823690891,
      "learning_rate": 7.000964320154292e-06,
      "loss": 0.3657,
      "step": 60660
    },
    {
      "epoch": 6.500589306760956,
      "grad_norm": 0.0005690600955858827,
      "learning_rate": 6.998821386478089e-06,
      "loss": 0.4857,
      "step": 60670
    },
    {
      "epoch": 6.501660773599057,
      "grad_norm": 0.0007681822753511369,
      "learning_rate": 6.996678452801886e-06,
      "loss": 0.1717,
      "step": 60680
    },
    {
      "epoch": 6.502732240437158,
      "grad_norm": 0.012936575338244438,
      "learning_rate": 6.994535519125684e-06,
      "loss": 0.2128,
      "step": 60690
    },
    {
      "epoch": 6.50380370727526,
      "grad_norm": 0.027983421459794044,
      "learning_rate": 6.992392585449481e-06,
      "loss": 0.0235,
      "step": 60700
    },
    {
      "epoch": 6.504875174113361,
      "grad_norm": 0.001071243197657168,
      "learning_rate": 6.990249651773278e-06,
      "loss": 0.0006,
      "step": 60710
    },
    {
      "epoch": 6.505946640951462,
      "grad_norm": 0.059966325759887695,
      "learning_rate": 6.988106718097075e-06,
      "loss": 0.0007,
      "step": 60720
    },
    {
      "epoch": 6.507018107789564,
      "grad_norm": 0.0013241186970844865,
      "learning_rate": 6.9859637844208725e-06,
      "loss": 0.5109,
      "step": 60730
    },
    {
      "epoch": 6.5080895746276655,
      "grad_norm": 0.01689952053129673,
      "learning_rate": 6.983820850744671e-06,
      "loss": 0.1665,
      "step": 60740
    },
    {
      "epoch": 6.509161041465767,
      "grad_norm": 0.030103035271167755,
      "learning_rate": 6.981677917068466e-06,
      "loss": 0.0008,
      "step": 60750
    },
    {
      "epoch": 6.510232508303868,
      "grad_norm": 0.01449687872081995,
      "learning_rate": 6.9795349833922646e-06,
      "loss": 0.175,
      "step": 60760
    },
    {
      "epoch": 6.51130397514197,
      "grad_norm": 0.04897606745362282,
      "learning_rate": 6.977392049716062e-06,
      "loss": 0.0013,
      "step": 60770
    },
    {
      "epoch": 6.512375441980071,
      "grad_norm": 0.03521231189370155,
      "learning_rate": 6.975249116039859e-06,
      "loss": 0.0003,
      "step": 60780
    },
    {
      "epoch": 6.513446908818172,
      "grad_norm": 13.133048057556152,
      "learning_rate": 6.973106182363656e-06,
      "loss": 0.0607,
      "step": 60790
    },
    {
      "epoch": 6.514518375656273,
      "grad_norm": 3.8144114017486572,
      "learning_rate": 6.970963248687453e-06,
      "loss": 0.0028,
      "step": 60800
    },
    {
      "epoch": 6.515589842494375,
      "grad_norm": 0.042741283774375916,
      "learning_rate": 6.968820315011251e-06,
      "loss": 0.3962,
      "step": 60810
    },
    {
      "epoch": 6.516661309332476,
      "grad_norm": 0.06031371280550957,
      "learning_rate": 6.966677381335049e-06,
      "loss": 0.2054,
      "step": 60820
    },
    {
      "epoch": 6.517732776170577,
      "grad_norm": 0.00032249343348667026,
      "learning_rate": 6.964534447658845e-06,
      "loss": 0.0007,
      "step": 60830
    },
    {
      "epoch": 6.518804243008679,
      "grad_norm": 0.00037142433575354517,
      "learning_rate": 6.9623915139826426e-06,
      "loss": 0.1938,
      "step": 60840
    },
    {
      "epoch": 6.51987570984678,
      "grad_norm": 0.3886524438858032,
      "learning_rate": 6.96024858030644e-06,
      "loss": 0.0006,
      "step": 60850
    },
    {
      "epoch": 6.520947176684881,
      "grad_norm": 0.00043673781328834593,
      "learning_rate": 6.958105646630237e-06,
      "loss": 0.1599,
      "step": 60860
    },
    {
      "epoch": 6.522018643522983,
      "grad_norm": 0.00036828621523454785,
      "learning_rate": 6.955962712954034e-06,
      "loss": 0.0004,
      "step": 60870
    },
    {
      "epoch": 6.5230901103610845,
      "grad_norm": 0.0003883145109284669,
      "learning_rate": 6.953819779277832e-06,
      "loss": 0.0002,
      "step": 60880
    },
    {
      "epoch": 6.524161577199186,
      "grad_norm": 0.013608981855213642,
      "learning_rate": 6.951676845601629e-06,
      "loss": 0.0001,
      "step": 60890
    },
    {
      "epoch": 6.525233044037287,
      "grad_norm": 0.0008631321834400296,
      "learning_rate": 6.949533911925427e-06,
      "loss": 0.1956,
      "step": 60900
    },
    {
      "epoch": 6.526304510875389,
      "grad_norm": 0.010979996994137764,
      "learning_rate": 6.947390978249223e-06,
      "loss": 0.232,
      "step": 60910
    },
    {
      "epoch": 6.52737597771349,
      "grad_norm": 0.009782268665730953,
      "learning_rate": 6.9452480445730206e-06,
      "loss": 0.3726,
      "step": 60920
    },
    {
      "epoch": 6.528447444551591,
      "grad_norm": 0.01827959530055523,
      "learning_rate": 6.943105110896819e-06,
      "loss": 0.3575,
      "step": 60930
    },
    {
      "epoch": 6.529518911389692,
      "grad_norm": 0.13554230332374573,
      "learning_rate": 6.940962177220616e-06,
      "loss": 0.0006,
      "step": 60940
    },
    {
      "epoch": 6.530590378227794,
      "grad_norm": 0.005867220461368561,
      "learning_rate": 6.938819243544413e-06,
      "loss": 0.2308,
      "step": 60950
    },
    {
      "epoch": 6.531661845065895,
      "grad_norm": 0.29789766669273376,
      "learning_rate": 6.93667630986821e-06,
      "loss": 0.2002,
      "step": 60960
    },
    {
      "epoch": 6.532733311903996,
      "grad_norm": 0.06479711830615997,
      "learning_rate": 6.934533376192007e-06,
      "loss": 0.0045,
      "step": 60970
    },
    {
      "epoch": 6.533804778742098,
      "grad_norm": 0.013752996921539307,
      "learning_rate": 6.932390442515805e-06,
      "loss": 0.0048,
      "step": 60980
    },
    {
      "epoch": 6.534876245580199,
      "grad_norm": 0.010220438241958618,
      "learning_rate": 6.930247508839601e-06,
      "loss": 0.452,
      "step": 60990
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 0.0018239949131384492,
      "learning_rate": 6.928104575163399e-06,
      "loss": 0.0004,
      "step": 61000
    },
    {
      "epoch": 6.537019179256402,
      "grad_norm": 0.2501363456249237,
      "learning_rate": 6.925961641487197e-06,
      "loss": 0.07,
      "step": 61010
    },
    {
      "epoch": 6.538090646094504,
      "grad_norm": 0.06652120500802994,
      "learning_rate": 6.923818707810994e-06,
      "loss": 0.0005,
      "step": 61020
    },
    {
      "epoch": 6.539162112932605,
      "grad_norm": 0.000830944802146405,
      "learning_rate": 6.921675774134791e-06,
      "loss": 0.0011,
      "step": 61030
    },
    {
      "epoch": 6.540233579770706,
      "grad_norm": 0.07718013972043991,
      "learning_rate": 6.919532840458588e-06,
      "loss": 0.0096,
      "step": 61040
    },
    {
      "epoch": 6.541305046608807,
      "grad_norm": 0.011935536749660969,
      "learning_rate": 6.917389906782385e-06,
      "loss": 0.1961,
      "step": 61050
    },
    {
      "epoch": 6.542376513446909,
      "grad_norm": 0.0015174284344539046,
      "learning_rate": 6.9152469731061835e-06,
      "loss": 0.0007,
      "step": 61060
    },
    {
      "epoch": 6.54344798028501,
      "grad_norm": 4.45152473449707,
      "learning_rate": 6.91310403942998e-06,
      "loss": 0.0025,
      "step": 61070
    },
    {
      "epoch": 6.544519447123111,
      "grad_norm": 0.008180622942745686,
      "learning_rate": 6.910961105753777e-06,
      "loss": 0.0002,
      "step": 61080
    },
    {
      "epoch": 6.545590913961213,
      "grad_norm": 0.0009116746368817985,
      "learning_rate": 6.908818172077575e-06,
      "loss": 0.0004,
      "step": 61090
    },
    {
      "epoch": 6.546662380799314,
      "grad_norm": 0.019574563950300217,
      "learning_rate": 6.906675238401372e-06,
      "loss": 0.0009,
      "step": 61100
    },
    {
      "epoch": 6.547733847637415,
      "grad_norm": 0.0744478702545166,
      "learning_rate": 6.904532304725169e-06,
      "loss": 0.0004,
      "step": 61110
    },
    {
      "epoch": 6.548805314475517,
      "grad_norm": 0.0036495367530733347,
      "learning_rate": 6.902389371048967e-06,
      "loss": 0.0002,
      "step": 61120
    },
    {
      "epoch": 6.5498767813136185,
      "grad_norm": 0.0012304340489208698,
      "learning_rate": 6.900246437372764e-06,
      "loss": 0.1412,
      "step": 61130
    },
    {
      "epoch": 6.55094824815172,
      "grad_norm": 27.597850799560547,
      "learning_rate": 6.8981035036965615e-06,
      "loss": 0.543,
      "step": 61140
    },
    {
      "epoch": 6.552019714989821,
      "grad_norm": 0.04305502399802208,
      "learning_rate": 6.895960570020358e-06,
      "loss": 0.0003,
      "step": 61150
    },
    {
      "epoch": 6.553091181827923,
      "grad_norm": 0.001899548340588808,
      "learning_rate": 6.893817636344155e-06,
      "loss": 0.0003,
      "step": 61160
    },
    {
      "epoch": 6.554162648666024,
      "grad_norm": 0.15804238617420197,
      "learning_rate": 6.891674702667953e-06,
      "loss": 0.0008,
      "step": 61170
    },
    {
      "epoch": 6.555234115504125,
      "grad_norm": 0.08658239990472794,
      "learning_rate": 6.889531768991751e-06,
      "loss": 0.1537,
      "step": 61180
    },
    {
      "epoch": 6.556305582342226,
      "grad_norm": 0.035426460206508636,
      "learning_rate": 6.8873888353155475e-06,
      "loss": 0.0004,
      "step": 61190
    },
    {
      "epoch": 6.557377049180328,
      "grad_norm": 0.006633039563894272,
      "learning_rate": 6.885245901639345e-06,
      "loss": 0.2426,
      "step": 61200
    },
    {
      "epoch": 6.558448516018429,
      "grad_norm": 0.028053663671016693,
      "learning_rate": 6.883102967963142e-06,
      "loss": 0.0002,
      "step": 61210
    },
    {
      "epoch": 6.55951998285653,
      "grad_norm": 0.0021593861747533083,
      "learning_rate": 6.8809600342869395e-06,
      "loss": 0.1387,
      "step": 61220
    },
    {
      "epoch": 6.560591449694632,
      "grad_norm": 15.563041687011719,
      "learning_rate": 6.878817100610736e-06,
      "loss": 0.2209,
      "step": 61230
    },
    {
      "epoch": 6.561662916532733,
      "grad_norm": 0.03427758067846298,
      "learning_rate": 6.876674166934533e-06,
      "loss": 0.0006,
      "step": 61240
    },
    {
      "epoch": 6.5627343833708345,
      "grad_norm": 0.003012267639860511,
      "learning_rate": 6.874531233258332e-06,
      "loss": 0.0002,
      "step": 61250
    },
    {
      "epoch": 6.5638058502089365,
      "grad_norm": 0.05803416296839714,
      "learning_rate": 6.872388299582129e-06,
      "loss": 0.0002,
      "step": 61260
    },
    {
      "epoch": 6.564877317047038,
      "grad_norm": 0.06874499469995499,
      "learning_rate": 6.8702453659059255e-06,
      "loss": 0.2129,
      "step": 61270
    },
    {
      "epoch": 6.565948783885139,
      "grad_norm": 0.024511143565177917,
      "learning_rate": 6.868102432229723e-06,
      "loss": 0.1581,
      "step": 61280
    },
    {
      "epoch": 6.56702025072324,
      "grad_norm": 0.0013639824464917183,
      "learning_rate": 6.86595949855352e-06,
      "loss": 0.2182,
      "step": 61290
    },
    {
      "epoch": 6.568091717561342,
      "grad_norm": 0.026202764362096786,
      "learning_rate": 6.863816564877318e-06,
      "loss": 0.2015,
      "step": 61300
    },
    {
      "epoch": 6.569163184399443,
      "grad_norm": 0.056748516857624054,
      "learning_rate": 6.861673631201115e-06,
      "loss": 0.0044,
      "step": 61310
    },
    {
      "epoch": 6.570234651237544,
      "grad_norm": 0.01554863341152668,
      "learning_rate": 6.859530697524912e-06,
      "loss": 0.0709,
      "step": 61320
    },
    {
      "epoch": 6.571306118075645,
      "grad_norm": 0.0873691663146019,
      "learning_rate": 6.85738776384871e-06,
      "loss": 0.0006,
      "step": 61330
    },
    {
      "epoch": 6.572377584913747,
      "grad_norm": 0.02405356429517269,
      "learning_rate": 6.855244830172507e-06,
      "loss": 0.2233,
      "step": 61340
    },
    {
      "epoch": 6.573449051751848,
      "grad_norm": 0.015083618462085724,
      "learning_rate": 6.8531018964963035e-06,
      "loss": 0.0009,
      "step": 61350
    },
    {
      "epoch": 6.574520518589949,
      "grad_norm": 0.0008998181438073516,
      "learning_rate": 6.850958962820101e-06,
      "loss": 0.0009,
      "step": 61360
    },
    {
      "epoch": 6.575591985428051,
      "grad_norm": 0.016044845804572105,
      "learning_rate": 6.848816029143899e-06,
      "loss": 0.2783,
      "step": 61370
    },
    {
      "epoch": 6.5766634522661525,
      "grad_norm": 7.218863010406494,
      "learning_rate": 6.846673095467696e-06,
      "loss": 0.0047,
      "step": 61380
    },
    {
      "epoch": 6.577734919104254,
      "grad_norm": 106.73995208740234,
      "learning_rate": 6.844530161791493e-06,
      "loss": 0.0757,
      "step": 61390
    },
    {
      "epoch": 6.578806385942356,
      "grad_norm": 0.010297626256942749,
      "learning_rate": 6.84238722811529e-06,
      "loss": 0.0008,
      "step": 61400
    },
    {
      "epoch": 6.579877852780457,
      "grad_norm": 0.016793904826045036,
      "learning_rate": 6.840244294439088e-06,
      "loss": 0.0003,
      "step": 61410
    },
    {
      "epoch": 6.580949319618558,
      "grad_norm": 0.025235747918486595,
      "learning_rate": 6.838101360762886e-06,
      "loss": 0.0015,
      "step": 61420
    },
    {
      "epoch": 6.582020786456659,
      "grad_norm": 0.0024451876524835825,
      "learning_rate": 6.835958427086682e-06,
      "loss": 0.0003,
      "step": 61430
    },
    {
      "epoch": 6.583092253294761,
      "grad_norm": 0.006227144505828619,
      "learning_rate": 6.83381549341048e-06,
      "loss": 0.0002,
      "step": 61440
    },
    {
      "epoch": 6.584163720132862,
      "grad_norm": 0.008550705388188362,
      "learning_rate": 6.831672559734277e-06,
      "loss": 0.0002,
      "step": 61450
    },
    {
      "epoch": 6.585235186970963,
      "grad_norm": 0.013871178962290287,
      "learning_rate": 6.829529626058074e-06,
      "loss": 0.1666,
      "step": 61460
    },
    {
      "epoch": 6.586306653809064,
      "grad_norm": 0.01051118690520525,
      "learning_rate": 6.827386692381871e-06,
      "loss": 0.4454,
      "step": 61470
    },
    {
      "epoch": 6.587378120647166,
      "grad_norm": 643.864013671875,
      "learning_rate": 6.825243758705668e-06,
      "loss": 0.263,
      "step": 61480
    },
    {
      "epoch": 6.588449587485267,
      "grad_norm": 0.012080404907464981,
      "learning_rate": 6.8231008250294664e-06,
      "loss": 0.1578,
      "step": 61490
    },
    {
      "epoch": 6.589521054323368,
      "grad_norm": 0.06484067440032959,
      "learning_rate": 6.820957891353264e-06,
      "loss": 0.232,
      "step": 61500
    },
    {
      "epoch": 6.59059252116147,
      "grad_norm": 0.0008308794931508601,
      "learning_rate": 6.81881495767706e-06,
      "loss": 0.1521,
      "step": 61510
    },
    {
      "epoch": 6.5916639879995715,
      "grad_norm": 0.004483410157263279,
      "learning_rate": 6.816672024000858e-06,
      "loss": 0.0945,
      "step": 61520
    },
    {
      "epoch": 6.592735454837673,
      "grad_norm": 0.0010743984021246433,
      "learning_rate": 6.814529090324655e-06,
      "loss": 0.1253,
      "step": 61530
    },
    {
      "epoch": 6.593806921675774,
      "grad_norm": 0.03450712934136391,
      "learning_rate": 6.812386156648453e-06,
      "loss": 0.1558,
      "step": 61540
    },
    {
      "epoch": 6.594878388513876,
      "grad_norm": 0.009132723324000835,
      "learning_rate": 6.810243222972249e-06,
      "loss": 0.1177,
      "step": 61550
    },
    {
      "epoch": 6.595949855351977,
      "grad_norm": 0.0010116745252162218,
      "learning_rate": 6.808100289296047e-06,
      "loss": 0.1528,
      "step": 61560
    },
    {
      "epoch": 6.597021322190078,
      "grad_norm": 0.38494575023651123,
      "learning_rate": 6.8059573556198444e-06,
      "loss": 0.1463,
      "step": 61570
    },
    {
      "epoch": 6.598092789028179,
      "grad_norm": 0.010035145096480846,
      "learning_rate": 6.803814421943642e-06,
      "loss": 0.0005,
      "step": 61580
    },
    {
      "epoch": 6.599164255866281,
      "grad_norm": 0.01141447201371193,
      "learning_rate": 6.801671488267438e-06,
      "loss": 0.5338,
      "step": 61590
    },
    {
      "epoch": 6.600235722704382,
      "grad_norm": 0.03164668008685112,
      "learning_rate": 6.799528554591236e-06,
      "loss": 0.0042,
      "step": 61600
    },
    {
      "epoch": 6.601307189542483,
      "grad_norm": 0.0007200822001323104,
      "learning_rate": 6.797385620915034e-06,
      "loss": 0.0003,
      "step": 61610
    },
    {
      "epoch": 6.602378656380585,
      "grad_norm": 0.01642114482820034,
      "learning_rate": 6.79524268723883e-06,
      "loss": 0.1788,
      "step": 61620
    },
    {
      "epoch": 6.603450123218686,
      "grad_norm": 0.011906588450074196,
      "learning_rate": 6.793099753562628e-06,
      "loss": 0.0001,
      "step": 61630
    },
    {
      "epoch": 6.6045215900567875,
      "grad_norm": 0.008370538242161274,
      "learning_rate": 6.790956819886425e-06,
      "loss": 0.001,
      "step": 61640
    },
    {
      "epoch": 6.6055930568948895,
      "grad_norm": 0.011721162125468254,
      "learning_rate": 6.7888138862102224e-06,
      "loss": 0.2097,
      "step": 61650
    },
    {
      "epoch": 6.606664523732991,
      "grad_norm": 0.012884777039289474,
      "learning_rate": 6.786670952534019e-06,
      "loss": 0.3894,
      "step": 61660
    },
    {
      "epoch": 6.607735990571092,
      "grad_norm": 0.026342961937189102,
      "learning_rate": 6.784528018857816e-06,
      "loss": 0.0003,
      "step": 61670
    },
    {
      "epoch": 6.608807457409193,
      "grad_norm": 0.00488226767629385,
      "learning_rate": 6.7823850851816145e-06,
      "loss": 0.3822,
      "step": 61680
    },
    {
      "epoch": 6.609878924247295,
      "grad_norm": 0.004052403848618269,
      "learning_rate": 6.780242151505412e-06,
      "loss": 0.0007,
      "step": 61690
    },
    {
      "epoch": 6.610950391085396,
      "grad_norm": 0.0014868902508169413,
      "learning_rate": 6.778099217829208e-06,
      "loss": 0.0006,
      "step": 61700
    },
    {
      "epoch": 6.612021857923497,
      "grad_norm": 0.017717229202389717,
      "learning_rate": 6.775956284153006e-06,
      "loss": 0.3183,
      "step": 61710
    },
    {
      "epoch": 6.613093324761598,
      "grad_norm": 0.05325750634074211,
      "learning_rate": 6.773813350476803e-06,
      "loss": 0.1027,
      "step": 61720
    },
    {
      "epoch": 6.6141647915997,
      "grad_norm": 0.019504109397530556,
      "learning_rate": 6.771670416800601e-06,
      "loss": 0.0006,
      "step": 61730
    },
    {
      "epoch": 6.615236258437801,
      "grad_norm": 0.013954405672848225,
      "learning_rate": 6.769527483124397e-06,
      "loss": 0.0014,
      "step": 61740
    },
    {
      "epoch": 6.616307725275902,
      "grad_norm": 0.2883951663970947,
      "learning_rate": 6.767384549448195e-06,
      "loss": 0.0011,
      "step": 61750
    },
    {
      "epoch": 6.617379192114004,
      "grad_norm": 0.012444498017430305,
      "learning_rate": 6.7652416157719925e-06,
      "loss": 0.0012,
      "step": 61760
    },
    {
      "epoch": 6.6184506589521055,
      "grad_norm": 0.0008801950025372207,
      "learning_rate": 6.76309868209579e-06,
      "loss": 0.2368,
      "step": 61770
    },
    {
      "epoch": 6.619522125790207,
      "grad_norm": 0.0015074765542522073,
      "learning_rate": 6.760955748419586e-06,
      "loss": 0.0005,
      "step": 61780
    },
    {
      "epoch": 6.620593592628309,
      "grad_norm": 0.010203429497778416,
      "learning_rate": 6.758812814743384e-06,
      "loss": 0.0001,
      "step": 61790
    },
    {
      "epoch": 6.62166505946641,
      "grad_norm": 22.776269912719727,
      "learning_rate": 6.756669881067182e-06,
      "loss": 0.3065,
      "step": 61800
    },
    {
      "epoch": 6.622736526304511,
      "grad_norm": 0.010134694166481495,
      "learning_rate": 6.754526947390979e-06,
      "loss": 0.2211,
      "step": 61810
    },
    {
      "epoch": 6.623807993142612,
      "grad_norm": 0.020672420039772987,
      "learning_rate": 6.752384013714776e-06,
      "loss": 0.0012,
      "step": 61820
    },
    {
      "epoch": 6.624879459980714,
      "grad_norm": 0.0015451478539034724,
      "learning_rate": 6.750241080038573e-06,
      "loss": 0.1328,
      "step": 61830
    },
    {
      "epoch": 6.625950926818815,
      "grad_norm": 17.744213104248047,
      "learning_rate": 6.7480981463623705e-06,
      "loss": 0.206,
      "step": 61840
    },
    {
      "epoch": 6.627022393656916,
      "grad_norm": 0.0009595713345333934,
      "learning_rate": 6.745955212686168e-06,
      "loss": 0.3443,
      "step": 61850
    },
    {
      "epoch": 6.628093860495017,
      "grad_norm": 0.010755307972431183,
      "learning_rate": 6.743812279009964e-06,
      "loss": 0.2208,
      "step": 61860
    },
    {
      "epoch": 6.629165327333119,
      "grad_norm": 26.112356185913086,
      "learning_rate": 6.741669345333763e-06,
      "loss": 0.3611,
      "step": 61870
    },
    {
      "epoch": 6.63023679417122,
      "grad_norm": 108.51228332519531,
      "learning_rate": 6.73952641165756e-06,
      "loss": 0.2539,
      "step": 61880
    },
    {
      "epoch": 6.6313082610093215,
      "grad_norm": 0.0010438670869916677,
      "learning_rate": 6.737383477981357e-06,
      "loss": 0.0007,
      "step": 61890
    },
    {
      "epoch": 6.6323797278474235,
      "grad_norm": 0.02269100956618786,
      "learning_rate": 6.735240544305154e-06,
      "loss": 0.177,
      "step": 61900
    },
    {
      "epoch": 6.633451194685525,
      "grad_norm": 0.05897006019949913,
      "learning_rate": 6.733097610628951e-06,
      "loss": 0.0005,
      "step": 61910
    },
    {
      "epoch": 6.634522661523626,
      "grad_norm": 0.0008077207021415234,
      "learning_rate": 6.730954676952749e-06,
      "loss": 0.0001,
      "step": 61920
    },
    {
      "epoch": 6.635594128361728,
      "grad_norm": 0.0025879484601318836,
      "learning_rate": 6.728811743276547e-06,
      "loss": 0.0004,
      "step": 61930
    },
    {
      "epoch": 6.636665595199829,
      "grad_norm": 0.012186810374259949,
      "learning_rate": 6.726668809600343e-06,
      "loss": 0.1781,
      "step": 61940
    },
    {
      "epoch": 6.63773706203793,
      "grad_norm": 0.14393359422683716,
      "learning_rate": 6.724525875924141e-06,
      "loss": 0.2592,
      "step": 61950
    },
    {
      "epoch": 6.638808528876031,
      "grad_norm": 0.009675920940935612,
      "learning_rate": 6.722382942247938e-06,
      "loss": 0.0853,
      "step": 61960
    },
    {
      "epoch": 6.639879995714133,
      "grad_norm": 0.02190229296684265,
      "learning_rate": 6.720240008571735e-06,
      "loss": 0.0006,
      "step": 61970
    },
    {
      "epoch": 6.640951462552234,
      "grad_norm": 0.008832904510200024,
      "learning_rate": 6.718097074895532e-06,
      "loss": 0.0001,
      "step": 61980
    },
    {
      "epoch": 6.642022929390335,
      "grad_norm": 0.017008861526846886,
      "learning_rate": 6.71595414121933e-06,
      "loss": 0.0003,
      "step": 61990
    },
    {
      "epoch": 6.643094396228436,
      "grad_norm": 0.00037047453224658966,
      "learning_rate": 6.713811207543127e-06,
      "loss": 0.2241,
      "step": 62000
    },
    {
      "epoch": 6.644165863066538,
      "grad_norm": 15.407893180847168,
      "learning_rate": 6.711668273866925e-06,
      "loss": 0.1418,
      "step": 62010
    },
    {
      "epoch": 6.6452373299046394,
      "grad_norm": 0.03317714482545853,
      "learning_rate": 6.709525340190721e-06,
      "loss": 0.2145,
      "step": 62020
    },
    {
      "epoch": 6.6463087967427406,
      "grad_norm": 0.13259245455265045,
      "learning_rate": 6.707382406514519e-06,
      "loss": 0.0004,
      "step": 62030
    },
    {
      "epoch": 6.6473802635808426,
      "grad_norm": 1.6693360805511475,
      "learning_rate": 6.705239472838316e-06,
      "loss": 0.3396,
      "step": 62040
    },
    {
      "epoch": 6.648451730418944,
      "grad_norm": 0.02240435779094696,
      "learning_rate": 6.703096539162114e-06,
      "loss": 0.0067,
      "step": 62050
    },
    {
      "epoch": 6.649523197257045,
      "grad_norm": 5.7164998054504395,
      "learning_rate": 6.700953605485911e-06,
      "loss": 0.0082,
      "step": 62060
    },
    {
      "epoch": 6.650594664095146,
      "grad_norm": 0.01331617683172226,
      "learning_rate": 6.698810671809708e-06,
      "loss": 0.0003,
      "step": 62070
    },
    {
      "epoch": 6.651666130933248,
      "grad_norm": 0.010895052924752235,
      "learning_rate": 6.696667738133505e-06,
      "loss": 0.0016,
      "step": 62080
    },
    {
      "epoch": 6.652737597771349,
      "grad_norm": 0.013062391430139542,
      "learning_rate": 6.694524804457303e-06,
      "loss": 0.0003,
      "step": 62090
    },
    {
      "epoch": 6.65380906460945,
      "grad_norm": 0.02054421231150627,
      "learning_rate": 6.692381870781099e-06,
      "loss": 0.0011,
      "step": 62100
    },
    {
      "epoch": 6.654880531447551,
      "grad_norm": 0.0007463518995791674,
      "learning_rate": 6.6902389371048974e-06,
      "loss": 0.1461,
      "step": 62110
    },
    {
      "epoch": 6.655951998285653,
      "grad_norm": 0.000395612878492102,
      "learning_rate": 6.688096003428695e-06,
      "loss": 0.6092,
      "step": 62120
    },
    {
      "epoch": 6.657023465123754,
      "grad_norm": 0.2184172421693802,
      "learning_rate": 6.685953069752492e-06,
      "loss": 0.0003,
      "step": 62130
    },
    {
      "epoch": 6.658094931961855,
      "grad_norm": 0.00474637933075428,
      "learning_rate": 6.683810136076289e-06,
      "loss": 0.1993,
      "step": 62140
    },
    {
      "epoch": 6.659166398799957,
      "grad_norm": 0.005045188125222921,
      "learning_rate": 6.681667202400086e-06,
      "loss": 0.0005,
      "step": 62150
    },
    {
      "epoch": 6.6602378656380585,
      "grad_norm": 0.00044163610436953604,
      "learning_rate": 6.679524268723883e-06,
      "loss": 0.2925,
      "step": 62160
    },
    {
      "epoch": 6.66130933247616,
      "grad_norm": 0.040798936039209366,
      "learning_rate": 6.6773813350476816e-06,
      "loss": 0.5271,
      "step": 62170
    },
    {
      "epoch": 6.662380799314262,
      "grad_norm": 0.00043745985021814704,
      "learning_rate": 6.675238401371478e-06,
      "loss": 0.0014,
      "step": 62180
    },
    {
      "epoch": 6.663452266152363,
      "grad_norm": 0.008145648054778576,
      "learning_rate": 6.6730954676952754e-06,
      "loss": 0.2774,
      "step": 62190
    },
    {
      "epoch": 6.664523732990464,
      "grad_norm": 0.0004540464433375746,
      "learning_rate": 6.670952534019073e-06,
      "loss": 0.0005,
      "step": 62200
    },
    {
      "epoch": 6.665595199828565,
      "grad_norm": 0.015121369622647762,
      "learning_rate": 6.66880960034287e-06,
      "loss": 0.0003,
      "step": 62210
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.0004943508538417518,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.2921,
      "step": 62220
    },
    {
      "epoch": 6.667738133504768,
      "grad_norm": 0.000866443500854075,
      "learning_rate": 6.664523732990464e-06,
      "loss": 0.0017,
      "step": 62230
    },
    {
      "epoch": 6.668809600342869,
      "grad_norm": 0.03369775414466858,
      "learning_rate": 6.662380799314262e-06,
      "loss": 0.1403,
      "step": 62240
    },
    {
      "epoch": 6.66988106718097,
      "grad_norm": 0.018422208726406097,
      "learning_rate": 6.6602378656380596e-06,
      "loss": 0.0002,
      "step": 62250
    },
    {
      "epoch": 6.670952534019072,
      "grad_norm": 0.00912919919937849,
      "learning_rate": 6.658094931961856e-06,
      "loss": 0.0006,
      "step": 62260
    },
    {
      "epoch": 6.672024000857173,
      "grad_norm": 2.61458420753479,
      "learning_rate": 6.6559519982856534e-06,
      "loss": 0.1149,
      "step": 62270
    },
    {
      "epoch": 6.6730954676952745,
      "grad_norm": 0.05582616850733757,
      "learning_rate": 6.653809064609451e-06,
      "loss": 0.0122,
      "step": 62280
    },
    {
      "epoch": 6.6741669345333765,
      "grad_norm": 0.00036889981129206717,
      "learning_rate": 6.651666130933249e-06,
      "loss": 0.002,
      "step": 62290
    },
    {
      "epoch": 6.675238401371478,
      "grad_norm": 0.000308649759972468,
      "learning_rate": 6.6495231972570455e-06,
      "loss": 0.0007,
      "step": 62300
    },
    {
      "epoch": 6.676309868209579,
      "grad_norm": 0.13007576763629913,
      "learning_rate": 6.647380263580843e-06,
      "loss": 0.1379,
      "step": 62310
    },
    {
      "epoch": 6.677381335047681,
      "grad_norm": 193.05055236816406,
      "learning_rate": 6.64523732990464e-06,
      "loss": 0.0174,
      "step": 62320
    },
    {
      "epoch": 6.678452801885782,
      "grad_norm": 0.0003441421140450984,
      "learning_rate": 6.6430943962284376e-06,
      "loss": 0.0001,
      "step": 62330
    },
    {
      "epoch": 6.679524268723883,
      "grad_norm": 0.0005581922014243901,
      "learning_rate": 6.640951462552234e-06,
      "loss": 0.3725,
      "step": 62340
    },
    {
      "epoch": 6.680595735561984,
      "grad_norm": 0.01238549966365099,
      "learning_rate": 6.6388085288760314e-06,
      "loss": 0.0001,
      "step": 62350
    },
    {
      "epoch": 6.681667202400086,
      "grad_norm": 0.0006561962654814124,
      "learning_rate": 6.63666559519983e-06,
      "loss": 0.3441,
      "step": 62360
    },
    {
      "epoch": 6.682738669238187,
      "grad_norm": 0.2447708249092102,
      "learning_rate": 6.634522661523627e-06,
      "loss": 0.2027,
      "step": 62370
    },
    {
      "epoch": 6.683810136076288,
      "grad_norm": 0.007047739811241627,
      "learning_rate": 6.6323797278474235e-06,
      "loss": 0.1483,
      "step": 62380
    },
    {
      "epoch": 6.684881602914389,
      "grad_norm": 0.04967568814754486,
      "learning_rate": 6.630236794171221e-06,
      "loss": 0.0003,
      "step": 62390
    },
    {
      "epoch": 6.685953069752491,
      "grad_norm": 0.00953285489231348,
      "learning_rate": 6.628093860495018e-06,
      "loss": 0.0007,
      "step": 62400
    },
    {
      "epoch": 6.6870245365905925,
      "grad_norm": 0.0006738579249940813,
      "learning_rate": 6.625950926818816e-06,
      "loss": 0.0003,
      "step": 62410
    },
    {
      "epoch": 6.688096003428694,
      "grad_norm": 0.022143173962831497,
      "learning_rate": 6.623807993142612e-06,
      "loss": 0.1012,
      "step": 62420
    },
    {
      "epoch": 6.689167470266796,
      "grad_norm": 0.0005809951107949018,
      "learning_rate": 6.62166505946641e-06,
      "loss": 0.1852,
      "step": 62430
    },
    {
      "epoch": 6.690238937104897,
      "grad_norm": 0.00060552719514817,
      "learning_rate": 6.619522125790208e-06,
      "loss": 0.0004,
      "step": 62440
    },
    {
      "epoch": 6.691310403942998,
      "grad_norm": 0.0009247772977687418,
      "learning_rate": 6.617379192114005e-06,
      "loss": 0.0139,
      "step": 62450
    },
    {
      "epoch": 6.6923818707811,
      "grad_norm": 0.0022629762534052134,
      "learning_rate": 6.6152362584378015e-06,
      "loss": 0.1181,
      "step": 62460
    },
    {
      "epoch": 6.693453337619201,
      "grad_norm": 0.00771347526460886,
      "learning_rate": 6.613093324761599e-06,
      "loss": 0.0001,
      "step": 62470
    },
    {
      "epoch": 6.694524804457302,
      "grad_norm": 0.015231750905513763,
      "learning_rate": 6.610950391085397e-06,
      "loss": 0.4423,
      "step": 62480
    },
    {
      "epoch": 6.695596271295403,
      "grad_norm": 0.0008394976030103862,
      "learning_rate": 6.608807457409194e-06,
      "loss": 0.0077,
      "step": 62490
    },
    {
      "epoch": 6.696667738133505,
      "grad_norm": 0.07914955914020538,
      "learning_rate": 6.606664523732991e-06,
      "loss": 0.0009,
      "step": 62500
    },
    {
      "epoch": 6.697739204971606,
      "grad_norm": 0.0065648965537548065,
      "learning_rate": 6.604521590056788e-06,
      "loss": 0.0042,
      "step": 62510
    },
    {
      "epoch": 6.698810671809707,
      "grad_norm": 15.173954963684082,
      "learning_rate": 6.602378656380586e-06,
      "loss": 0.4921,
      "step": 62520
    },
    {
      "epoch": 6.6998821386478085,
      "grad_norm": 0.008087996393442154,
      "learning_rate": 6.600235722704382e-06,
      "loss": 0.0003,
      "step": 62530
    },
    {
      "epoch": 6.7009536054859105,
      "grad_norm": 0.20209665596485138,
      "learning_rate": 6.5980927890281795e-06,
      "loss": 0.3381,
      "step": 62540
    },
    {
      "epoch": 6.702025072324012,
      "grad_norm": 0.002131981309503317,
      "learning_rate": 6.595949855351978e-06,
      "loss": 0.1848,
      "step": 62550
    },
    {
      "epoch": 6.703096539162113,
      "grad_norm": 0.76459801197052,
      "learning_rate": 6.593806921675775e-06,
      "loss": 0.0011,
      "step": 62560
    },
    {
      "epoch": 6.704168006000215,
      "grad_norm": 14.148193359375,
      "learning_rate": 6.5916639879995716e-06,
      "loss": 0.3337,
      "step": 62570
    },
    {
      "epoch": 6.705239472838316,
      "grad_norm": 0.4974294602870941,
      "learning_rate": 6.589521054323369e-06,
      "loss": 0.4371,
      "step": 62580
    },
    {
      "epoch": 6.706310939676417,
      "grad_norm": 36.43534469604492,
      "learning_rate": 6.587378120647166e-06,
      "loss": 0.3511,
      "step": 62590
    },
    {
      "epoch": 6.707382406514518,
      "grad_norm": 0.1506401002407074,
      "learning_rate": 6.5852351869709645e-06,
      "loss": 0.6512,
      "step": 62600
    },
    {
      "epoch": 6.70845387335262,
      "grad_norm": 16.848485946655273,
      "learning_rate": 6.58309225329476e-06,
      "loss": 0.2417,
      "step": 62610
    },
    {
      "epoch": 6.709525340190721,
      "grad_norm": 20.84430694580078,
      "learning_rate": 6.580949319618558e-06,
      "loss": 0.1124,
      "step": 62620
    },
    {
      "epoch": 6.710596807028822,
      "grad_norm": 0.16310030221939087,
      "learning_rate": 6.578806385942356e-06,
      "loss": 0.0008,
      "step": 62630
    },
    {
      "epoch": 6.711668273866923,
      "grad_norm": 0.012890744023025036,
      "learning_rate": 6.576663452266153e-06,
      "loss": 0.0034,
      "step": 62640
    },
    {
      "epoch": 6.712739740705025,
      "grad_norm": 0.37945494055747986,
      "learning_rate": 6.5745205185899496e-06,
      "loss": 0.3795,
      "step": 62650
    },
    {
      "epoch": 6.713811207543126,
      "grad_norm": 0.007337815128266811,
      "learning_rate": 6.572377584913747e-06,
      "loss": 0.3808,
      "step": 62660
    },
    {
      "epoch": 6.7148826743812275,
      "grad_norm": 0.05249714478850365,
      "learning_rate": 6.570234651237545e-06,
      "loss": 0.2804,
      "step": 62670
    },
    {
      "epoch": 6.7159541412193295,
      "grad_norm": 0.003888852894306183,
      "learning_rate": 6.5680917175613425e-06,
      "loss": 0.1599,
      "step": 62680
    },
    {
      "epoch": 6.717025608057431,
      "grad_norm": 0.010563643649220467,
      "learning_rate": 6.565948783885139e-06,
      "loss": 0.0365,
      "step": 62690
    },
    {
      "epoch": 6.718097074895532,
      "grad_norm": 0.0035898119676858187,
      "learning_rate": 6.563805850208936e-06,
      "loss": 0.0005,
      "step": 62700
    },
    {
      "epoch": 6.719168541733634,
      "grad_norm": 0.014160385355353355,
      "learning_rate": 6.561662916532734e-06,
      "loss": 0.1433,
      "step": 62710
    },
    {
      "epoch": 6.720240008571735,
      "grad_norm": 0.013510560616850853,
      "learning_rate": 6.559519982856531e-06,
      "loss": 0.0004,
      "step": 62720
    },
    {
      "epoch": 6.721311475409836,
      "grad_norm": 0.012719864957034588,
      "learning_rate": 6.5573770491803276e-06,
      "loss": 0.0012,
      "step": 62730
    },
    {
      "epoch": 6.722382942247937,
      "grad_norm": 16.858957290649414,
      "learning_rate": 6.555234115504126e-06,
      "loss": 0.1919,
      "step": 62740
    },
    {
      "epoch": 6.723454409086039,
      "grad_norm": 0.11784043908119202,
      "learning_rate": 6.553091181827923e-06,
      "loss": 0.0486,
      "step": 62750
    },
    {
      "epoch": 6.72452587592414,
      "grad_norm": 0.11205125600099564,
      "learning_rate": 6.5509482481517205e-06,
      "loss": 0.0006,
      "step": 62760
    },
    {
      "epoch": 6.725597342762241,
      "grad_norm": 0.011137958616018295,
      "learning_rate": 6.548805314475517e-06,
      "loss": 0.0004,
      "step": 62770
    },
    {
      "epoch": 6.726668809600342,
      "grad_norm": 0.009683914482593536,
      "learning_rate": 6.546662380799314e-06,
      "loss": 0.0009,
      "step": 62780
    },
    {
      "epoch": 6.727740276438444,
      "grad_norm": 0.0009608858963474631,
      "learning_rate": 6.5445194471231125e-06,
      "loss": 0.0008,
      "step": 62790
    },
    {
      "epoch": 6.7288117432765455,
      "grad_norm": 0.018252519890666008,
      "learning_rate": 6.54237651344691e-06,
      "loss": 0.0829,
      "step": 62800
    },
    {
      "epoch": 6.729883210114647,
      "grad_norm": 0.46933284401893616,
      "learning_rate": 6.540233579770706e-06,
      "loss": 0.0006,
      "step": 62810
    },
    {
      "epoch": 6.730954676952749,
      "grad_norm": 0.0015690725995227695,
      "learning_rate": 6.538090646094504e-06,
      "loss": 0.0003,
      "step": 62820
    },
    {
      "epoch": 6.73202614379085,
      "grad_norm": 263.56378173828125,
      "learning_rate": 6.535947712418301e-06,
      "loss": 0.1787,
      "step": 62830
    },
    {
      "epoch": 6.733097610628951,
      "grad_norm": 0.004095043987035751,
      "learning_rate": 6.5338047787420985e-06,
      "loss": 0.0271,
      "step": 62840
    },
    {
      "epoch": 6.734169077467053,
      "grad_norm": 0.34850838780403137,
      "learning_rate": 6.531661845065895e-06,
      "loss": 0.0144,
      "step": 62850
    },
    {
      "epoch": 6.735240544305154,
      "grad_norm": 0.0023073884658515453,
      "learning_rate": 6.529518911389693e-06,
      "loss": 0.0003,
      "step": 62860
    },
    {
      "epoch": 6.736312011143255,
      "grad_norm": 0.010056273080408573,
      "learning_rate": 6.5273759777134905e-06,
      "loss": 0.0969,
      "step": 62870
    },
    {
      "epoch": 6.737383477981356,
      "grad_norm": 0.017530886456370354,
      "learning_rate": 6.525233044037288e-06,
      "loss": 0.0002,
      "step": 62880
    },
    {
      "epoch": 6.738454944819458,
      "grad_norm": 0.008133343420922756,
      "learning_rate": 6.523090110361084e-06,
      "loss": 0.5292,
      "step": 62890
    },
    {
      "epoch": 6.739526411657559,
      "grad_norm": 32.30867004394531,
      "learning_rate": 6.520947176684882e-06,
      "loss": 0.1662,
      "step": 62900
    },
    {
      "epoch": 6.74059787849566,
      "grad_norm": 0.008713796734809875,
      "learning_rate": 6.518804243008679e-06,
      "loss": 0.0013,
      "step": 62910
    },
    {
      "epoch": 6.7416693453337615,
      "grad_norm": 0.005256043281406164,
      "learning_rate": 6.516661309332477e-06,
      "loss": 0.0021,
      "step": 62920
    },
    {
      "epoch": 6.7427408121718635,
      "grad_norm": 0.0077538201585412025,
      "learning_rate": 6.514518375656274e-06,
      "loss": 0.2544,
      "step": 62930
    },
    {
      "epoch": 6.743812279009965,
      "grad_norm": 0.0008950969786383212,
      "learning_rate": 6.512375441980071e-06,
      "loss": 0.1808,
      "step": 62940
    },
    {
      "epoch": 6.744883745848066,
      "grad_norm": 0.0020546300802379847,
      "learning_rate": 6.5102325083038685e-06,
      "loss": 0.1339,
      "step": 62950
    },
    {
      "epoch": 6.745955212686168,
      "grad_norm": 0.033303726464509964,
      "learning_rate": 6.508089574627666e-06,
      "loss": 0.0661,
      "step": 62960
    },
    {
      "epoch": 6.747026679524269,
      "grad_norm": 0.0025419043377041817,
      "learning_rate": 6.505946640951462e-06,
      "loss": 0.2763,
      "step": 62970
    },
    {
      "epoch": 6.74809814636237,
      "grad_norm": 0.012447125278413296,
      "learning_rate": 6.503803707275261e-06,
      "loss": 0.0003,
      "step": 62980
    },
    {
      "epoch": 6.749169613200472,
      "grad_norm": 19.57378578186035,
      "learning_rate": 6.501660773599058e-06,
      "loss": 0.1338,
      "step": 62990
    },
    {
      "epoch": 6.750241080038573,
      "grad_norm": 0.021925853565335274,
      "learning_rate": 6.499517839922855e-06,
      "loss": 0.1421,
      "step": 63000
    },
    {
      "epoch": 6.751312546876674,
      "grad_norm": 0.002175122033804655,
      "learning_rate": 6.497374906246652e-06,
      "loss": 0.1427,
      "step": 63010
    },
    {
      "epoch": 6.752384013714775,
      "grad_norm": 0.030124105513095856,
      "learning_rate": 6.495231972570449e-06,
      "loss": 0.1542,
      "step": 63020
    },
    {
      "epoch": 6.753455480552877,
      "grad_norm": 0.0010782345198094845,
      "learning_rate": 6.4930890388942465e-06,
      "loss": 0.0009,
      "step": 63030
    },
    {
      "epoch": 6.754526947390978,
      "grad_norm": 0.017912236973643303,
      "learning_rate": 6.490946105218045e-06,
      "loss": 0.3288,
      "step": 63040
    },
    {
      "epoch": 6.7555984142290795,
      "grad_norm": 27.109981536865234,
      "learning_rate": 6.488803171541841e-06,
      "loss": 0.3232,
      "step": 63050
    },
    {
      "epoch": 6.756669881067181,
      "grad_norm": 0.004394422750920057,
      "learning_rate": 6.486660237865639e-06,
      "loss": 0.253,
      "step": 63060
    },
    {
      "epoch": 6.757741347905283,
      "grad_norm": 0.006747930310666561,
      "learning_rate": 6.484517304189436e-06,
      "loss": 0.1455,
      "step": 63070
    },
    {
      "epoch": 6.758812814743384,
      "grad_norm": 0.01267528161406517,
      "learning_rate": 6.482374370513233e-06,
      "loss": 0.0014,
      "step": 63080
    },
    {
      "epoch": 6.759884281581485,
      "grad_norm": 0.008013486862182617,
      "learning_rate": 6.48023143683703e-06,
      "loss": 0.0039,
      "step": 63090
    },
    {
      "epoch": 6.760955748419587,
      "grad_norm": 0.006050965283066034,
      "learning_rate": 6.478088503160827e-06,
      "loss": 0.114,
      "step": 63100
    },
    {
      "epoch": 6.762027215257688,
      "grad_norm": 0.0016345544718205929,
      "learning_rate": 6.475945569484625e-06,
      "loss": 0.1443,
      "step": 63110
    },
    {
      "epoch": 6.763098682095789,
      "grad_norm": 0.05221176519989967,
      "learning_rate": 6.473802635808423e-06,
      "loss": 0.23,
      "step": 63120
    },
    {
      "epoch": 6.76417014893389,
      "grad_norm": 0.21058058738708496,
      "learning_rate": 6.471659702132219e-06,
      "loss": 0.0022,
      "step": 63130
    },
    {
      "epoch": 6.765241615771992,
      "grad_norm": 0.07689378410577774,
      "learning_rate": 6.469516768456017e-06,
      "loss": 0.0014,
      "step": 63140
    },
    {
      "epoch": 6.766313082610093,
      "grad_norm": 0.6733387112617493,
      "learning_rate": 6.467373834779814e-06,
      "loss": 0.0692,
      "step": 63150
    },
    {
      "epoch": 6.767384549448194,
      "grad_norm": 0.0014756813179701567,
      "learning_rate": 6.465230901103612e-06,
      "loss": 0.0551,
      "step": 63160
    },
    {
      "epoch": 6.7684560162862955,
      "grad_norm": 0.23728612065315247,
      "learning_rate": 6.463087967427409e-06,
      "loss": 0.6276,
      "step": 63170
    },
    {
      "epoch": 6.7695274831243974,
      "grad_norm": 0.06250222027301788,
      "learning_rate": 6.460945033751206e-06,
      "loss": 0.0012,
      "step": 63180
    },
    {
      "epoch": 6.770598949962499,
      "grad_norm": 0.5379307270050049,
      "learning_rate": 6.458802100075003e-06,
      "loss": 0.2121,
      "step": 63190
    },
    {
      "epoch": 6.7716704168006,
      "grad_norm": 0.15589198470115662,
      "learning_rate": 6.456659166398801e-06,
      "loss": 0.0005,
      "step": 63200
    },
    {
      "epoch": 6.772741883638702,
      "grad_norm": 0.0013997205533087254,
      "learning_rate": 6.454516232722597e-06,
      "loss": 0.0006,
      "step": 63210
    },
    {
      "epoch": 6.773813350476803,
      "grad_norm": 0.0021417224779725075,
      "learning_rate": 6.452373299046395e-06,
      "loss": 0.1174,
      "step": 63220
    },
    {
      "epoch": 6.774884817314904,
      "grad_norm": 0.06097280979156494,
      "learning_rate": 6.450230365370193e-06,
      "loss": 0.0075,
      "step": 63230
    },
    {
      "epoch": 6.775956284153006,
      "grad_norm": 0.009990904480218887,
      "learning_rate": 6.44808743169399e-06,
      "loss": 0.0005,
      "step": 63240
    },
    {
      "epoch": 6.777027750991107,
      "grad_norm": 0.009238229133188725,
      "learning_rate": 6.445944498017787e-06,
      "loss": 0.0004,
      "step": 63250
    },
    {
      "epoch": 6.778099217829208,
      "grad_norm": 0.002066440647467971,
      "learning_rate": 6.443801564341584e-06,
      "loss": 0.1266,
      "step": 63260
    },
    {
      "epoch": 6.779170684667309,
      "grad_norm": 0.028844602406024933,
      "learning_rate": 6.441658630665381e-06,
      "loss": 0.1004,
      "step": 63270
    },
    {
      "epoch": 6.780242151505411,
      "grad_norm": 0.013125213794410229,
      "learning_rate": 6.43951569698918e-06,
      "loss": 0.1777,
      "step": 63280
    },
    {
      "epoch": 6.781313618343512,
      "grad_norm": 0.001039846334606409,
      "learning_rate": 6.437372763312975e-06,
      "loss": 0.1576,
      "step": 63290
    },
    {
      "epoch": 6.782385085181613,
      "grad_norm": 0.0015371325425803661,
      "learning_rate": 6.4352298296367735e-06,
      "loss": 0.0002,
      "step": 63300
    },
    {
      "epoch": 6.7834565520197145,
      "grad_norm": 0.01842574216425419,
      "learning_rate": 6.433086895960571e-06,
      "loss": 0.2201,
      "step": 63310
    },
    {
      "epoch": 6.7845280188578165,
      "grad_norm": 0.0008422884275205433,
      "learning_rate": 6.430943962284368e-06,
      "loss": 0.0012,
      "step": 63320
    },
    {
      "epoch": 6.785599485695918,
      "grad_norm": 0.011396903544664383,
      "learning_rate": 6.428801028608165e-06,
      "loss": 0.2495,
      "step": 63330
    },
    {
      "epoch": 6.786670952534019,
      "grad_norm": 0.06494708359241486,
      "learning_rate": 6.426658094931962e-06,
      "loss": 0.1642,
      "step": 63340
    },
    {
      "epoch": 6.787742419372121,
      "grad_norm": 0.0024383917916566133,
      "learning_rate": 6.42451516125576e-06,
      "loss": 0.0013,
      "step": 63350
    },
    {
      "epoch": 6.788813886210222,
      "grad_norm": 0.004057676065713167,
      "learning_rate": 6.422372227579558e-06,
      "loss": 0.2419,
      "step": 63360
    },
    {
      "epoch": 6.789885353048323,
      "grad_norm": 0.014309798367321491,
      "learning_rate": 6.420229293903354e-06,
      "loss": 0.1587,
      "step": 63370
    },
    {
      "epoch": 6.790956819886425,
      "grad_norm": 0.0018647108227014542,
      "learning_rate": 6.4180863602271515e-06,
      "loss": 0.0038,
      "step": 63380
    },
    {
      "epoch": 6.792028286724526,
      "grad_norm": 0.24123606085777283,
      "learning_rate": 6.415943426550949e-06,
      "loss": 0.2024,
      "step": 63390
    },
    {
      "epoch": 6.793099753562627,
      "grad_norm": 0.00925446767359972,
      "learning_rate": 6.413800492874747e-06,
      "loss": 0.0002,
      "step": 63400
    },
    {
      "epoch": 6.794171220400728,
      "grad_norm": 0.022086691111326218,
      "learning_rate": 6.411657559198543e-06,
      "loss": 0.0008,
      "step": 63410
    },
    {
      "epoch": 6.79524268723883,
      "grad_norm": 0.05416938289999962,
      "learning_rate": 6.409514625522341e-06,
      "loss": 0.1571,
      "step": 63420
    },
    {
      "epoch": 6.796314154076931,
      "grad_norm": 0.06434940546751022,
      "learning_rate": 6.407371691846138e-06,
      "loss": 0.0025,
      "step": 63430
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 0.0020607963670045137,
      "learning_rate": 6.405228758169935e-06,
      "loss": 0.0001,
      "step": 63440
    },
    {
      "epoch": 6.798457087753134,
      "grad_norm": 0.01879838854074478,
      "learning_rate": 6.403085824493732e-06,
      "loss": 0.002,
      "step": 63450
    },
    {
      "epoch": 6.799528554591236,
      "grad_norm": 0.11409634351730347,
      "learning_rate": 6.4009428908175294e-06,
      "loss": 0.0004,
      "step": 63460
    },
    {
      "epoch": 6.800600021429337,
      "grad_norm": 0.0011101255659013987,
      "learning_rate": 6.398799957141328e-06,
      "loss": 0.0001,
      "step": 63470
    },
    {
      "epoch": 6.801671488267438,
      "grad_norm": 0.0007572134491056204,
      "learning_rate": 6.396657023465124e-06,
      "loss": 0.1681,
      "step": 63480
    },
    {
      "epoch": 6.80274295510554,
      "grad_norm": 0.00878291204571724,
      "learning_rate": 6.3945140897889215e-06,
      "loss": 0.2616,
      "step": 63490
    },
    {
      "epoch": 6.803814421943641,
      "grad_norm": 0.39058059453964233,
      "learning_rate": 6.392371156112719e-06,
      "loss": 0.0006,
      "step": 63500
    },
    {
      "epoch": 6.804885888781742,
      "grad_norm": 0.001350110280327499,
      "learning_rate": 6.390228222436516e-06,
      "loss": 0.2373,
      "step": 63510
    },
    {
      "epoch": 6.805957355619844,
      "grad_norm": 0.00561155891045928,
      "learning_rate": 6.388085288760313e-06,
      "loss": 0.0007,
      "step": 63520
    },
    {
      "epoch": 6.807028822457945,
      "grad_norm": 37.16099548339844,
      "learning_rate": 6.38594235508411e-06,
      "loss": 0.3371,
      "step": 63530
    },
    {
      "epoch": 6.808100289296046,
      "grad_norm": 0.011689024046063423,
      "learning_rate": 6.383799421407908e-06,
      "loss": 0.1436,
      "step": 63540
    },
    {
      "epoch": 6.809171756134147,
      "grad_norm": 0.001873303554020822,
      "learning_rate": 6.381656487731706e-06,
      "loss": 0.1402,
      "step": 63550
    },
    {
      "epoch": 6.810243222972249,
      "grad_norm": 0.001720856293104589,
      "learning_rate": 6.379513554055502e-06,
      "loss": 0.0005,
      "step": 63560
    },
    {
      "epoch": 6.8113146898103505,
      "grad_norm": 0.0022428540978580713,
      "learning_rate": 6.3773706203792995e-06,
      "loss": 0.0004,
      "step": 63570
    },
    {
      "epoch": 6.812386156648452,
      "grad_norm": 24.96167755126953,
      "learning_rate": 6.375227686703097e-06,
      "loss": 0.1961,
      "step": 63580
    },
    {
      "epoch": 6.813457623486553,
      "grad_norm": 1.075556755065918,
      "learning_rate": 6.373084753026895e-06,
      "loss": 0.2797,
      "step": 63590
    },
    {
      "epoch": 6.814529090324655,
      "grad_norm": 0.003705063369125128,
      "learning_rate": 6.370941819350691e-06,
      "loss": 0.0009,
      "step": 63600
    },
    {
      "epoch": 6.815600557162756,
      "grad_norm": 0.3137543201446533,
      "learning_rate": 6.368798885674489e-06,
      "loss": 0.0037,
      "step": 63610
    },
    {
      "epoch": 6.816672024000857,
      "grad_norm": 0.001296094385907054,
      "learning_rate": 6.366655951998286e-06,
      "loss": 0.1106,
      "step": 63620
    },
    {
      "epoch": 6.817743490838959,
      "grad_norm": 0.009280569851398468,
      "learning_rate": 6.364513018322084e-06,
      "loss": 0.0001,
      "step": 63630
    },
    {
      "epoch": 6.81881495767706,
      "grad_norm": 0.014311794191598892,
      "learning_rate": 6.36237008464588e-06,
      "loss": 0.1784,
      "step": 63640
    },
    {
      "epoch": 6.819886424515161,
      "grad_norm": 0.0010470187989994884,
      "learning_rate": 6.3602271509696775e-06,
      "loss": 0.1655,
      "step": 63650
    },
    {
      "epoch": 6.820957891353262,
      "grad_norm": 0.0011819745413959026,
      "learning_rate": 6.358084217293476e-06,
      "loss": 0.0002,
      "step": 63660
    },
    {
      "epoch": 6.822029358191364,
      "grad_norm": 0.005654165055602789,
      "learning_rate": 6.355941283617273e-06,
      "loss": 0.0002,
      "step": 63670
    },
    {
      "epoch": 6.823100825029465,
      "grad_norm": 0.0010873725404962897,
      "learning_rate": 6.35379834994107e-06,
      "loss": 0.0003,
      "step": 63680
    },
    {
      "epoch": 6.8241722918675665,
      "grad_norm": 0.0028317682445049286,
      "learning_rate": 6.351655416264867e-06,
      "loss": 0.0006,
      "step": 63690
    },
    {
      "epoch": 6.825243758705668,
      "grad_norm": 0.001629791921004653,
      "learning_rate": 6.349512482588664e-06,
      "loss": 0.174,
      "step": 63700
    },
    {
      "epoch": 6.82631522554377,
      "grad_norm": 0.0011281706392765045,
      "learning_rate": 6.347369548912462e-06,
      "loss": 0.0,
      "step": 63710
    },
    {
      "epoch": 6.827386692381871,
      "grad_norm": 0.003360561328008771,
      "learning_rate": 6.345226615236258e-06,
      "loss": 0.0021,
      "step": 63720
    },
    {
      "epoch": 6.828458159219972,
      "grad_norm": 0.005369594786316156,
      "learning_rate": 6.343083681560056e-06,
      "loss": 0.1483,
      "step": 63730
    },
    {
      "epoch": 6.829529626058074,
      "grad_norm": 0.0043976581655442715,
      "learning_rate": 6.340940747883854e-06,
      "loss": 0.3669,
      "step": 63740
    },
    {
      "epoch": 6.830601092896175,
      "grad_norm": 0.0011490205070003867,
      "learning_rate": 6.338797814207651e-06,
      "loss": 0.1337,
      "step": 63750
    },
    {
      "epoch": 6.831672559734276,
      "grad_norm": 25.862213134765625,
      "learning_rate": 6.336654880531448e-06,
      "loss": 0.1187,
      "step": 63760
    },
    {
      "epoch": 6.832744026572378,
      "grad_norm": 0.05017617344856262,
      "learning_rate": 6.334511946855245e-06,
      "loss": 0.0032,
      "step": 63770
    },
    {
      "epoch": 6.833815493410479,
      "grad_norm": 0.22170858085155487,
      "learning_rate": 6.332369013179043e-06,
      "loss": 0.1339,
      "step": 63780
    },
    {
      "epoch": 6.83488696024858,
      "grad_norm": 0.22713857889175415,
      "learning_rate": 6.3302260795028405e-06,
      "loss": 0.0006,
      "step": 63790
    },
    {
      "epoch": 6.835958427086681,
      "grad_norm": 0.24593521654605865,
      "learning_rate": 6.328083145826637e-06,
      "loss": 0.0009,
      "step": 63800
    },
    {
      "epoch": 6.837029893924783,
      "grad_norm": 0.0010243069846183062,
      "learning_rate": 6.325940212150434e-06,
      "loss": 0.2003,
      "step": 63810
    },
    {
      "epoch": 6.838101360762884,
      "grad_norm": 0.005039066541939974,
      "learning_rate": 6.323797278474232e-06,
      "loss": 0.0012,
      "step": 63820
    },
    {
      "epoch": 6.8391728276009855,
      "grad_norm": 0.21919786930084229,
      "learning_rate": 6.321654344798029e-06,
      "loss": 0.2679,
      "step": 63830
    },
    {
      "epoch": 6.840244294439087,
      "grad_norm": 0.21357260644435883,
      "learning_rate": 6.319511411121826e-06,
      "loss": 0.0597,
      "step": 63840
    },
    {
      "epoch": 6.841315761277189,
      "grad_norm": 0.0053709582425653934,
      "learning_rate": 6.317368477445624e-06,
      "loss": 0.0009,
      "step": 63850
    },
    {
      "epoch": 6.84238722811529,
      "grad_norm": 0.0009897120762616396,
      "learning_rate": 6.315225543769421e-06,
      "loss": 0.2601,
      "step": 63860
    },
    {
      "epoch": 6.843458694953391,
      "grad_norm": 0.005152725148946047,
      "learning_rate": 6.3130826100932185e-06,
      "loss": 0.1603,
      "step": 63870
    },
    {
      "epoch": 6.844530161791493,
      "grad_norm": 1.9207321405410767,
      "learning_rate": 6.310939676417015e-06,
      "loss": 0.0007,
      "step": 63880
    },
    {
      "epoch": 6.845601628629594,
      "grad_norm": 0.0054523092694580555,
      "learning_rate": 6.308796742740812e-06,
      "loss": 0.0007,
      "step": 63890
    },
    {
      "epoch": 6.846673095467695,
      "grad_norm": 0.001522300997748971,
      "learning_rate": 6.30665380906461e-06,
      "loss": 0.0013,
      "step": 63900
    },
    {
      "epoch": 6.847744562305797,
      "grad_norm": 0.02290130779147148,
      "learning_rate": 6.304510875388408e-06,
      "loss": 0.0004,
      "step": 63910
    },
    {
      "epoch": 6.848816029143898,
      "grad_norm": 0.000997738796286285,
      "learning_rate": 6.3023679417122044e-06,
      "loss": 0.0001,
      "step": 63920
    },
    {
      "epoch": 6.849887495981999,
      "grad_norm": 0.14992395043373108,
      "learning_rate": 6.300225008036002e-06,
      "loss": 0.7044,
      "step": 63930
    },
    {
      "epoch": 6.8509589628201,
      "grad_norm": 0.001499480684287846,
      "learning_rate": 6.298082074359799e-06,
      "loss": 0.0001,
      "step": 63940
    },
    {
      "epoch": 6.852030429658202,
      "grad_norm": 0.0040083713829517365,
      "learning_rate": 6.2959391406835965e-06,
      "loss": 0.3088,
      "step": 63950
    },
    {
      "epoch": 6.8531018964963035,
      "grad_norm": 0.0031266696751117706,
      "learning_rate": 6.293796207007393e-06,
      "loss": 0.2105,
      "step": 63960
    },
    {
      "epoch": 6.854173363334405,
      "grad_norm": 0.039410896599292755,
      "learning_rate": 6.291653273331191e-06,
      "loss": 0.0761,
      "step": 63970
    },
    {
      "epoch": 6.855244830172506,
      "grad_norm": 0.008987899869680405,
      "learning_rate": 6.2895103396549886e-06,
      "loss": 0.1517,
      "step": 63980
    },
    {
      "epoch": 6.856316297010608,
      "grad_norm": 6.4822001457214355,
      "learning_rate": 6.287367405978786e-06,
      "loss": 0.1209,
      "step": 63990
    },
    {
      "epoch": 6.857387763848709,
      "grad_norm": 0.0023586638271808624,
      "learning_rate": 6.2852244723025824e-06,
      "loss": 0.114,
      "step": 64000
    },
    {
      "epoch": 6.85845923068681,
      "grad_norm": 0.11616173386573792,
      "learning_rate": 6.28308153862638e-06,
      "loss": 0.0044,
      "step": 64010
    },
    {
      "epoch": 6.859530697524912,
      "grad_norm": 0.008597183972597122,
      "learning_rate": 6.280938604950177e-06,
      "loss": 0.0004,
      "step": 64020
    },
    {
      "epoch": 6.860602164363013,
      "grad_norm": 0.011301524937152863,
      "learning_rate": 6.278795671273975e-06,
      "loss": 0.6075,
      "step": 64030
    },
    {
      "epoch": 6.861673631201114,
      "grad_norm": 0.013922841288149357,
      "learning_rate": 6.276652737597772e-06,
      "loss": 0.0006,
      "step": 64040
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 0.029067281633615494,
      "learning_rate": 6.274509803921569e-06,
      "loss": 0.0085,
      "step": 64050
    },
    {
      "epoch": 6.863816564877317,
      "grad_norm": 0.01060261856764555,
      "learning_rate": 6.2723668702453666e-06,
      "loss": 0.2377,
      "step": 64060
    },
    {
      "epoch": 6.864888031715418,
      "grad_norm": 0.006286113988608122,
      "learning_rate": 6.270223936569164e-06,
      "loss": 0.0014,
      "step": 64070
    },
    {
      "epoch": 6.8659594985535195,
      "grad_norm": 0.0042794798500835896,
      "learning_rate": 6.2680810028929604e-06,
      "loss": 0.0202,
      "step": 64080
    },
    {
      "epoch": 6.8670309653916215,
      "grad_norm": 0.010755558498203754,
      "learning_rate": 6.265938069216758e-06,
      "loss": 0.0006,
      "step": 64090
    },
    {
      "epoch": 6.868102432229723,
      "grad_norm": 0.004194843117147684,
      "learning_rate": 6.263795135540556e-06,
      "loss": 0.4084,
      "step": 64100
    },
    {
      "epoch": 6.869173899067824,
      "grad_norm": 0.01403412502259016,
      "learning_rate": 6.261652201864353e-06,
      "loss": 0.0016,
      "step": 64110
    },
    {
      "epoch": 6.870245365905925,
      "grad_norm": 0.001362609094940126,
      "learning_rate": 6.25950926818815e-06,
      "loss": 0.0029,
      "step": 64120
    },
    {
      "epoch": 6.871316832744027,
      "grad_norm": 0.343240350484848,
      "learning_rate": 6.257366334511947e-06,
      "loss": 0.0004,
      "step": 64130
    },
    {
      "epoch": 6.872388299582128,
      "grad_norm": 0.06853695213794708,
      "learning_rate": 6.2552234008357446e-06,
      "loss": 0.0006,
      "step": 64140
    },
    {
      "epoch": 6.873459766420229,
      "grad_norm": 0.03427061438560486,
      "learning_rate": 6.253080467159543e-06,
      "loss": 0.3364,
      "step": 64150
    },
    {
      "epoch": 6.874531233258331,
      "grad_norm": 20.941633224487305,
      "learning_rate": 6.250937533483339e-06,
      "loss": 0.2105,
      "step": 64160
    },
    {
      "epoch": 6.875602700096432,
      "grad_norm": 0.060652997344732285,
      "learning_rate": 6.248794599807137e-06,
      "loss": 0.0006,
      "step": 64170
    },
    {
      "epoch": 6.876674166934533,
      "grad_norm": 0.008801312185823917,
      "learning_rate": 6.246651666130934e-06,
      "loss": 0.0004,
      "step": 64180
    },
    {
      "epoch": 6.877745633772634,
      "grad_norm": 2.576188564300537,
      "learning_rate": 6.244508732454731e-06,
      "loss": 0.0026,
      "step": 64190
    },
    {
      "epoch": 6.878817100610736,
      "grad_norm": 0.0010307030752301216,
      "learning_rate": 6.242365798778528e-06,
      "loss": 0.3332,
      "step": 64200
    },
    {
      "epoch": 6.8798885674488375,
      "grad_norm": 0.15391433238983154,
      "learning_rate": 6.240222865102325e-06,
      "loss": 0.1957,
      "step": 64210
    },
    {
      "epoch": 6.880960034286939,
      "grad_norm": 0.003920953720808029,
      "learning_rate": 6.238079931426123e-06,
      "loss": 0.0002,
      "step": 64220
    },
    {
      "epoch": 6.88203150112504,
      "grad_norm": 0.006018639542162418,
      "learning_rate": 6.235936997749921e-06,
      "loss": 0.1387,
      "step": 64230
    },
    {
      "epoch": 6.883102967963142,
      "grad_norm": 0.002793503925204277,
      "learning_rate": 6.233794064073717e-06,
      "loss": 0.2744,
      "step": 64240
    },
    {
      "epoch": 6.884174434801243,
      "grad_norm": 0.2155110090970993,
      "learning_rate": 6.231651130397515e-06,
      "loss": 0.0033,
      "step": 64250
    },
    {
      "epoch": 6.885245901639344,
      "grad_norm": 0.01837974227964878,
      "learning_rate": 6.229508196721312e-06,
      "loss": 0.0003,
      "step": 64260
    },
    {
      "epoch": 6.886317368477446,
      "grad_norm": 0.0656193196773529,
      "learning_rate": 6.22736526304511e-06,
      "loss": 0.0008,
      "step": 64270
    },
    {
      "epoch": 6.887388835315547,
      "grad_norm": 0.002222756389528513,
      "learning_rate": 6.225222329368906e-06,
      "loss": 0.1326,
      "step": 64280
    },
    {
      "epoch": 6.888460302153648,
      "grad_norm": 0.003193566109985113,
      "learning_rate": 6.223079395692704e-06,
      "loss": 0.1718,
      "step": 64290
    },
    {
      "epoch": 6.88953176899175,
      "grad_norm": 0.0037733286153525114,
      "learning_rate": 6.220936462016501e-06,
      "loss": 0.3054,
      "step": 64300
    },
    {
      "epoch": 6.890603235829851,
      "grad_norm": 0.02571413293480873,
      "learning_rate": 6.218793528340299e-06,
      "loss": 0.042,
      "step": 64310
    },
    {
      "epoch": 6.891674702667952,
      "grad_norm": 0.06635402888059616,
      "learning_rate": 6.216650594664095e-06,
      "loss": 0.1342,
      "step": 64320
    },
    {
      "epoch": 6.8927461695060535,
      "grad_norm": 0.04412780702114105,
      "learning_rate": 6.214507660987893e-06,
      "loss": 0.0005,
      "step": 64330
    },
    {
      "epoch": 6.8938176363441555,
      "grad_norm": 0.0037049425300210714,
      "learning_rate": 6.212364727311691e-06,
      "loss": 0.0044,
      "step": 64340
    },
    {
      "epoch": 6.894889103182257,
      "grad_norm": 0.008935678750276566,
      "learning_rate": 6.210221793635487e-06,
      "loss": 0.0052,
      "step": 64350
    },
    {
      "epoch": 6.895960570020358,
      "grad_norm": 207.69760131835938,
      "learning_rate": 6.208078859959285e-06,
      "loss": 0.2189,
      "step": 64360
    },
    {
      "epoch": 6.897032036858459,
      "grad_norm": 0.22452367842197418,
      "learning_rate": 6.205935926283082e-06,
      "loss": 0.0007,
      "step": 64370
    },
    {
      "epoch": 6.898103503696561,
      "grad_norm": 0.0023676359560340643,
      "learning_rate": 6.203792992606879e-06,
      "loss": 0.0008,
      "step": 64380
    },
    {
      "epoch": 6.899174970534662,
      "grad_norm": 0.5001618266105652,
      "learning_rate": 6.201650058930676e-06,
      "loss": 0.0006,
      "step": 64390
    },
    {
      "epoch": 6.900246437372763,
      "grad_norm": 0.00465118745341897,
      "learning_rate": 6.199507125254473e-06,
      "loss": 0.0173,
      "step": 64400
    },
    {
      "epoch": 6.901317904210865,
      "grad_norm": 0.008334717713296413,
      "learning_rate": 6.1973641915782715e-06,
      "loss": 0.0003,
      "step": 64410
    },
    {
      "epoch": 6.902389371048966,
      "grad_norm": 0.0018875313689932227,
      "learning_rate": 6.195221257902069e-06,
      "loss": 0.0048,
      "step": 64420
    },
    {
      "epoch": 6.903460837887067,
      "grad_norm": 0.0007890918641351163,
      "learning_rate": 6.193078324225865e-06,
      "loss": 0.0001,
      "step": 64430
    },
    {
      "epoch": 6.904532304725169,
      "grad_norm": 0.0029711835086345673,
      "learning_rate": 6.190935390549663e-06,
      "loss": 0.0003,
      "step": 64440
    },
    {
      "epoch": 6.90560377156327,
      "grad_norm": 0.3400769829750061,
      "learning_rate": 6.18879245687346e-06,
      "loss": 0.001,
      "step": 64450
    },
    {
      "epoch": 6.906675238401371,
      "grad_norm": 0.0026664596516638994,
      "learning_rate": 6.186649523197258e-06,
      "loss": 0.3051,
      "step": 64460
    },
    {
      "epoch": 6.9077467052394725,
      "grad_norm": 0.00109725387301296,
      "learning_rate": 6.184506589521054e-06,
      "loss": 0.4298,
      "step": 64470
    },
    {
      "epoch": 6.9088181720775745,
      "grad_norm": 0.0019628952722996473,
      "learning_rate": 6.182363655844852e-06,
      "loss": 0.575,
      "step": 64480
    },
    {
      "epoch": 6.909889638915676,
      "grad_norm": 0.6033515930175781,
      "learning_rate": 6.1802207221686495e-06,
      "loss": 0.0011,
      "step": 64490
    },
    {
      "epoch": 6.910961105753777,
      "grad_norm": 0.0010203886777162552,
      "learning_rate": 6.178077788492447e-06,
      "loss": 0.0001,
      "step": 64500
    },
    {
      "epoch": 6.912032572591878,
      "grad_norm": 0.0009429028141312301,
      "learning_rate": 6.175934854816243e-06,
      "loss": 0.1525,
      "step": 64510
    },
    {
      "epoch": 6.91310403942998,
      "grad_norm": 0.00342552806250751,
      "learning_rate": 6.173791921140041e-06,
      "loss": 0.0003,
      "step": 64520
    },
    {
      "epoch": 6.914175506268081,
      "grad_norm": 0.02417825162410736,
      "learning_rate": 6.171648987463839e-06,
      "loss": 0.0002,
      "step": 64530
    },
    {
      "epoch": 6.915246973106182,
      "grad_norm": 0.0021608341485261917,
      "learning_rate": 6.169506053787636e-06,
      "loss": 0.1159,
      "step": 64540
    },
    {
      "epoch": 6.916318439944284,
      "grad_norm": 0.001942944247275591,
      "learning_rate": 6.167363120111433e-06,
      "loss": 0.0,
      "step": 64550
    },
    {
      "epoch": 6.917389906782385,
      "grad_norm": 0.0018846605671569705,
      "learning_rate": 6.16522018643523e-06,
      "loss": 0.0002,
      "step": 64560
    },
    {
      "epoch": 6.918461373620486,
      "grad_norm": 0.0019433964043855667,
      "learning_rate": 6.1630772527590275e-06,
      "loss": 0.0001,
      "step": 64570
    },
    {
      "epoch": 6.919532840458588,
      "grad_norm": 0.0010401626350358129,
      "learning_rate": 6.160934319082825e-06,
      "loss": 0.0736,
      "step": 64580
    },
    {
      "epoch": 6.920604307296689,
      "grad_norm": 0.017586655914783478,
      "learning_rate": 6.158791385406621e-06,
      "loss": 0.2144,
      "step": 64590
    },
    {
      "epoch": 6.9216757741347905,
      "grad_norm": 0.0025099862832576036,
      "learning_rate": 6.1566484517304195e-06,
      "loss": 0.0,
      "step": 64600
    },
    {
      "epoch": 6.922747240972892,
      "grad_norm": 0.08778774738311768,
      "learning_rate": 6.154505518054217e-06,
      "loss": 0.2576,
      "step": 64610
    },
    {
      "epoch": 6.923818707810994,
      "grad_norm": 0.0006492766551673412,
      "learning_rate": 6.152362584378014e-06,
      "loss": 0.082,
      "step": 64620
    },
    {
      "epoch": 6.924890174649095,
      "grad_norm": 0.0015137232840061188,
      "learning_rate": 6.150219650701811e-06,
      "loss": 0.1345,
      "step": 64630
    },
    {
      "epoch": 6.925961641487196,
      "grad_norm": 25.030485153198242,
      "learning_rate": 6.148076717025608e-06,
      "loss": 0.0176,
      "step": 64640
    },
    {
      "epoch": 6.927033108325297,
      "grad_norm": 0.3945682644844055,
      "learning_rate": 6.145933783349406e-06,
      "loss": 0.0002,
      "step": 64650
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 0.0014809186104685068,
      "learning_rate": 6.143790849673204e-06,
      "loss": 0.0008,
      "step": 64660
    },
    {
      "epoch": 6.9291760420015,
      "grad_norm": 14.47099494934082,
      "learning_rate": 6.141647915997e-06,
      "loss": 0.4832,
      "step": 64670
    },
    {
      "epoch": 6.930247508839601,
      "grad_norm": 0.001203256077133119,
      "learning_rate": 6.1395049823207975e-06,
      "loss": 0.0001,
      "step": 64680
    },
    {
      "epoch": 6.931318975677703,
      "grad_norm": 0.08192840218544006,
      "learning_rate": 6.137362048644595e-06,
      "loss": 0.0001,
      "step": 64690
    },
    {
      "epoch": 6.932390442515804,
      "grad_norm": 0.04997953772544861,
      "learning_rate": 6.135219114968392e-06,
      "loss": 0.0006,
      "step": 64700
    },
    {
      "epoch": 6.933461909353905,
      "grad_norm": 0.0007211942574940622,
      "learning_rate": 6.133076181292189e-06,
      "loss": 0.0973,
      "step": 64710
    },
    {
      "epoch": 6.9345333761920065,
      "grad_norm": 0.031881216913461685,
      "learning_rate": 6.130933247615987e-06,
      "loss": 0.0006,
      "step": 64720
    },
    {
      "epoch": 6.9356048430301085,
      "grad_norm": 0.0018531674286350608,
      "learning_rate": 6.128790313939784e-06,
      "loss": 0.0001,
      "step": 64730
    },
    {
      "epoch": 6.93667630986821,
      "grad_norm": 0.003998134285211563,
      "learning_rate": 6.126647380263582e-06,
      "loss": 0.2969,
      "step": 64740
    },
    {
      "epoch": 6.937747776706311,
      "grad_norm": 0.06553506851196289,
      "learning_rate": 6.124504446587378e-06,
      "loss": 0.0024,
      "step": 64750
    },
    {
      "epoch": 6.938819243544412,
      "grad_norm": 0.001117158681154251,
      "learning_rate": 6.1223615129111755e-06,
      "loss": 0.1253,
      "step": 64760
    },
    {
      "epoch": 6.939890710382514,
      "grad_norm": 0.002262804424390197,
      "learning_rate": 6.120218579234973e-06,
      "loss": 0.0016,
      "step": 64770
    },
    {
      "epoch": 6.940962177220615,
      "grad_norm": 0.0034919774625450373,
      "learning_rate": 6.118075645558771e-06,
      "loss": 0.0001,
      "step": 64780
    },
    {
      "epoch": 6.942033644058716,
      "grad_norm": 0.002566776005551219,
      "learning_rate": 6.115932711882568e-06,
      "loss": 0.2131,
      "step": 64790
    },
    {
      "epoch": 6.943105110896818,
      "grad_norm": 0.0015684098470956087,
      "learning_rate": 6.113789778206365e-06,
      "loss": 0.0001,
      "step": 64800
    },
    {
      "epoch": 6.944176577734919,
      "grad_norm": 0.03598368167877197,
      "learning_rate": 6.111646844530162e-06,
      "loss": 0.0048,
      "step": 64810
    },
    {
      "epoch": 6.94524804457302,
      "grad_norm": 0.000981093617156148,
      "learning_rate": 6.10950391085396e-06,
      "loss": 0.2905,
      "step": 64820
    },
    {
      "epoch": 6.946319511411122,
      "grad_norm": 0.46153441071510315,
      "learning_rate": 6.107360977177756e-06,
      "loss": 0.0012,
      "step": 64830
    },
    {
      "epoch": 6.947390978249223,
      "grad_norm": 0.7105925679206848,
      "learning_rate": 6.105218043501554e-06,
      "loss": 0.1644,
      "step": 64840
    },
    {
      "epoch": 6.9484624450873245,
      "grad_norm": 0.003552177455276251,
      "learning_rate": 6.103075109825352e-06,
      "loss": 0.2767,
      "step": 64850
    },
    {
      "epoch": 6.949533911925426,
      "grad_norm": 0.00135142938233912,
      "learning_rate": 6.100932176149149e-06,
      "loss": 0.186,
      "step": 64860
    },
    {
      "epoch": 6.950605378763528,
      "grad_norm": 0.0065049584954977036,
      "learning_rate": 6.098789242472946e-06,
      "loss": 0.0005,
      "step": 64870
    },
    {
      "epoch": 6.951676845601629,
      "grad_norm": 0.0009598555043339729,
      "learning_rate": 6.096646308796743e-06,
      "loss": 0.0002,
      "step": 64880
    },
    {
      "epoch": 6.95274831243973,
      "grad_norm": 0.0052874088287353516,
      "learning_rate": 6.09450337512054e-06,
      "loss": 0.0007,
      "step": 64890
    },
    {
      "epoch": 6.953819779277831,
      "grad_norm": 0.049285806715488434,
      "learning_rate": 6.0923604414443385e-06,
      "loss": 0.1439,
      "step": 64900
    },
    {
      "epoch": 6.954891246115933,
      "grad_norm": 0.003325299359858036,
      "learning_rate": 6.090217507768135e-06,
      "loss": 0.1455,
      "step": 64910
    },
    {
      "epoch": 6.955962712954034,
      "grad_norm": 0.003806574270129204,
      "learning_rate": 6.088074574091932e-06,
      "loss": 0.0004,
      "step": 64920
    },
    {
      "epoch": 6.957034179792135,
      "grad_norm": 0.519448459148407,
      "learning_rate": 6.08593164041573e-06,
      "loss": 0.3919,
      "step": 64930
    },
    {
      "epoch": 6.958105646630237,
      "grad_norm": 0.007808848284184933,
      "learning_rate": 6.083788706739527e-06,
      "loss": 0.302,
      "step": 64940
    },
    {
      "epoch": 6.959177113468338,
      "grad_norm": 0.02227693237364292,
      "learning_rate": 6.081645773063324e-06,
      "loss": 0.0004,
      "step": 64950
    },
    {
      "epoch": 6.960248580306439,
      "grad_norm": 0.04006838798522949,
      "learning_rate": 6.079502839387121e-06,
      "loss": 0.0015,
      "step": 64960
    },
    {
      "epoch": 6.961320047144541,
      "grad_norm": 0.013768217526376247,
      "learning_rate": 6.077359905710919e-06,
      "loss": 0.0014,
      "step": 64970
    },
    {
      "epoch": 6.962391513982642,
      "grad_norm": 14.25002670288086,
      "learning_rate": 6.0752169720347165e-06,
      "loss": 0.1469,
      "step": 64980
    },
    {
      "epoch": 6.9634629808207436,
      "grad_norm": 0.007374863140285015,
      "learning_rate": 6.073074038358513e-06,
      "loss": 0.2918,
      "step": 64990
    },
    {
      "epoch": 6.964534447658845,
      "grad_norm": 0.0023585520684719086,
      "learning_rate": 6.07093110468231e-06,
      "loss": 0.0009,
      "step": 65000
    },
    {
      "epoch": 6.965605914496947,
      "grad_norm": 0.0012749816523864865,
      "learning_rate": 6.068788171006108e-06,
      "loss": 0.0005,
      "step": 65010
    },
    {
      "epoch": 6.966677381335048,
      "grad_norm": 0.00665018055588007,
      "learning_rate": 6.066645237329906e-06,
      "loss": 0.0011,
      "step": 65020
    },
    {
      "epoch": 6.967748848173149,
      "grad_norm": 0.042201779782772064,
      "learning_rate": 6.0645023036537025e-06,
      "loss": 0.1242,
      "step": 65030
    },
    {
      "epoch": 6.96882031501125,
      "grad_norm": 0.001942969742231071,
      "learning_rate": 6.0623593699775e-06,
      "loss": 0.0011,
      "step": 65040
    },
    {
      "epoch": 6.969891781849352,
      "grad_norm": 0.011674221605062485,
      "learning_rate": 6.060216436301297e-06,
      "loss": 0.0001,
      "step": 65050
    },
    {
      "epoch": 6.970963248687453,
      "grad_norm": 0.009802659042179585,
      "learning_rate": 6.0580735026250945e-06,
      "loss": 0.1384,
      "step": 65060
    },
    {
      "epoch": 6.972034715525554,
      "grad_norm": 0.00661788834258914,
      "learning_rate": 6.055930568948891e-06,
      "loss": 0.0005,
      "step": 65070
    },
    {
      "epoch": 6.973106182363656,
      "grad_norm": 0.003495573066174984,
      "learning_rate": 6.053787635272688e-06,
      "loss": 0.0008,
      "step": 65080
    },
    {
      "epoch": 6.974177649201757,
      "grad_norm": 33.733760833740234,
      "learning_rate": 6.051644701596487e-06,
      "loss": 0.5328,
      "step": 65090
    },
    {
      "epoch": 6.975249116039858,
      "grad_norm": 0.0008561948779970407,
      "learning_rate": 6.049501767920284e-06,
      "loss": 0.2631,
      "step": 65100
    },
    {
      "epoch": 6.97632058287796,
      "grad_norm": 0.009982543997466564,
      "learning_rate": 6.0473588342440805e-06,
      "loss": 0.0001,
      "step": 65110
    },
    {
      "epoch": 6.9773920497160615,
      "grad_norm": 0.0006885360344313085,
      "learning_rate": 6.045215900567878e-06,
      "loss": 0.0004,
      "step": 65120
    },
    {
      "epoch": 6.978463516554163,
      "grad_norm": 0.0019478233298286796,
      "learning_rate": 6.043072966891675e-06,
      "loss": 0.1911,
      "step": 65130
    },
    {
      "epoch": 6.979534983392264,
      "grad_norm": 0.002237305510789156,
      "learning_rate": 6.040930033215473e-06,
      "loss": 0.1924,
      "step": 65140
    },
    {
      "epoch": 6.980606450230366,
      "grad_norm": 0.0018432502401992679,
      "learning_rate": 6.038787099539269e-06,
      "loss": 0.4837,
      "step": 65150
    },
    {
      "epoch": 6.981677917068467,
      "grad_norm": 0.004757597576826811,
      "learning_rate": 6.036644165863067e-06,
      "loss": 0.1934,
      "step": 65160
    },
    {
      "epoch": 6.982749383906568,
      "grad_norm": 0.10199935734272003,
      "learning_rate": 6.034501232186865e-06,
      "loss": 0.2245,
      "step": 65170
    },
    {
      "epoch": 6.983820850744669,
      "grad_norm": 0.05336198955774307,
      "learning_rate": 6.032358298510662e-06,
      "loss": 0.0134,
      "step": 65180
    },
    {
      "epoch": 6.984892317582771,
      "grad_norm": 0.1808546781539917,
      "learning_rate": 6.0302153648344585e-06,
      "loss": 0.1634,
      "step": 65190
    },
    {
      "epoch": 6.985963784420872,
      "grad_norm": 0.08370086550712585,
      "learning_rate": 6.028072431158256e-06,
      "loss": 0.1444,
      "step": 65200
    },
    {
      "epoch": 6.987035251258973,
      "grad_norm": 0.18090315163135529,
      "learning_rate": 6.025929497482054e-06,
      "loss": 0.3675,
      "step": 65210
    },
    {
      "epoch": 6.988106718097075,
      "grad_norm": 0.055287688970565796,
      "learning_rate": 6.023786563805851e-06,
      "loss": 0.1948,
      "step": 65220
    },
    {
      "epoch": 6.989178184935176,
      "grad_norm": 0.06340079009532928,
      "learning_rate": 6.021643630129648e-06,
      "loss": 0.0018,
      "step": 65230
    },
    {
      "epoch": 6.9902496517732775,
      "grad_norm": 0.0029252052772790194,
      "learning_rate": 6.019500696453445e-06,
      "loss": 0.0912,
      "step": 65240
    },
    {
      "epoch": 6.991321118611379,
      "grad_norm": 0.22601188719272614,
      "learning_rate": 6.017357762777243e-06,
      "loss": 0.0011,
      "step": 65250
    },
    {
      "epoch": 6.992392585449481,
      "grad_norm": 0.034842461347579956,
      "learning_rate": 6.015214829101039e-06,
      "loss": 0.0003,
      "step": 65260
    },
    {
      "epoch": 6.993464052287582,
      "grad_norm": 0.04952623322606087,
      "learning_rate": 6.0130718954248365e-06,
      "loss": 0.0008,
      "step": 65270
    },
    {
      "epoch": 6.994535519125683,
      "grad_norm": 0.05315352976322174,
      "learning_rate": 6.010928961748635e-06,
      "loss": 0.0003,
      "step": 65280
    },
    {
      "epoch": 6.995606985963784,
      "grad_norm": 0.002691077534109354,
      "learning_rate": 6.008786028072432e-06,
      "loss": 0.1873,
      "step": 65290
    },
    {
      "epoch": 6.996678452801886,
      "grad_norm": 0.04152023047208786,
      "learning_rate": 6.0066430943962285e-06,
      "loss": 0.469,
      "step": 65300
    },
    {
      "epoch": 6.997749919639987,
      "grad_norm": 0.001849971478804946,
      "learning_rate": 6.004500160720026e-06,
      "loss": 0.0018,
      "step": 65310
    },
    {
      "epoch": 6.998821386478088,
      "grad_norm": 0.04955369234085083,
      "learning_rate": 6.002357227043823e-06,
      "loss": 0.0004,
      "step": 65320
    },
    {
      "epoch": 6.99989285331619,
      "grad_norm": 0.011975906789302826,
      "learning_rate": 6.0002142933676214e-06,
      "loss": 0.0012,
      "step": 65330
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.945,
      "eval_f1": 0.854368932038835,
      "eval_loss": 0.29860639572143555,
      "eval_precision": 0.8784029038112523,
      "eval_recall": 0.8316151202749141,
      "eval_runtime": 480.4135,
      "eval_samples_per_second": 12.489,
      "eval_steps_per_second": 4.163,
      "step": 65331
    },
    {
      "epoch": 7.000964320154291,
      "grad_norm": 0.04131549969315529,
      "learning_rate": 5.998071359691417e-06,
      "loss": 0.0009,
      "step": 65340
    },
    {
      "epoch": 7.002035786992392,
      "grad_norm": 0.241353377699852,
      "learning_rate": 5.995928426015215e-06,
      "loss": 0.0007,
      "step": 65350
    },
    {
      "epoch": 7.003107253830494,
      "grad_norm": 0.04078535735607147,
      "learning_rate": 5.993785492339013e-06,
      "loss": 0.0006,
      "step": 65360
    },
    {
      "epoch": 7.0041787206685955,
      "grad_norm": 0.01450852956622839,
      "learning_rate": 5.99164255866281e-06,
      "loss": 0.001,
      "step": 65370
    },
    {
      "epoch": 7.005250187506697,
      "grad_norm": 0.042743053287267685,
      "learning_rate": 5.9894996249866065e-06,
      "loss": 0.0011,
      "step": 65380
    },
    {
      "epoch": 7.006321654344798,
      "grad_norm": 0.018732169643044472,
      "learning_rate": 5.987356691310404e-06,
      "loss": 0.0002,
      "step": 65390
    },
    {
      "epoch": 7.0073931211829,
      "grad_norm": 44.56338882446289,
      "learning_rate": 5.985213757634202e-06,
      "loss": 0.2748,
      "step": 65400
    },
    {
      "epoch": 7.008464588021001,
      "grad_norm": 0.3611116409301758,
      "learning_rate": 5.9830708239579994e-06,
      "loss": 0.3371,
      "step": 65410
    },
    {
      "epoch": 7.009536054859102,
      "grad_norm": 0.012818488292396069,
      "learning_rate": 5.980927890281796e-06,
      "loss": 0.1282,
      "step": 65420
    },
    {
      "epoch": 7.010607521697204,
      "grad_norm": 0.00638132868334651,
      "learning_rate": 5.978784956605593e-06,
      "loss": 0.0006,
      "step": 65430
    },
    {
      "epoch": 7.011678988535305,
      "grad_norm": 0.010162456892430782,
      "learning_rate": 5.976642022929391e-06,
      "loss": 0.0002,
      "step": 65440
    },
    {
      "epoch": 7.012750455373406,
      "grad_norm": 0.01581861823797226,
      "learning_rate": 5.974499089253189e-06,
      "loss": 0.2151,
      "step": 65450
    },
    {
      "epoch": 7.013821922211507,
      "grad_norm": 0.00062986568082124,
      "learning_rate": 5.9723561555769845e-06,
      "loss": 0.0013,
      "step": 65460
    },
    {
      "epoch": 7.014893389049609,
      "grad_norm": 0.0020756640005856752,
      "learning_rate": 5.970213221900783e-06,
      "loss": 0.0122,
      "step": 65470
    },
    {
      "epoch": 7.01596485588771,
      "grad_norm": 0.013610978610813618,
      "learning_rate": 5.96807028822458e-06,
      "loss": 0.2163,
      "step": 65480
    },
    {
      "epoch": 7.0170363227258115,
      "grad_norm": 0.04240808263421059,
      "learning_rate": 5.9659273545483774e-06,
      "loss": 0.3136,
      "step": 65490
    },
    {
      "epoch": 7.018107789563913,
      "grad_norm": 0.0017779753543436527,
      "learning_rate": 5.963784420872174e-06,
      "loss": 0.0004,
      "step": 65500
    },
    {
      "epoch": 7.019179256402015,
      "grad_norm": 0.003811502130702138,
      "learning_rate": 5.961641487195971e-06,
      "loss": 0.2751,
      "step": 65510
    },
    {
      "epoch": 7.020250723240116,
      "grad_norm": 0.02298278734087944,
      "learning_rate": 5.9594985535197695e-06,
      "loss": 0.0004,
      "step": 65520
    },
    {
      "epoch": 7.021322190078217,
      "grad_norm": 0.011137470602989197,
      "learning_rate": 5.957355619843567e-06,
      "loss": 0.1848,
      "step": 65530
    },
    {
      "epoch": 7.022393656916319,
      "grad_norm": 0.00766393868252635,
      "learning_rate": 5.955212686167363e-06,
      "loss": 0.0004,
      "step": 65540
    },
    {
      "epoch": 7.02346512375442,
      "grad_norm": 0.009710095822811127,
      "learning_rate": 5.953069752491161e-06,
      "loss": 0.0002,
      "step": 65550
    },
    {
      "epoch": 7.024536590592521,
      "grad_norm": 0.0024099622387439013,
      "learning_rate": 5.950926818814958e-06,
      "loss": 0.0003,
      "step": 65560
    },
    {
      "epoch": 7.025608057430622,
      "grad_norm": 0.01848742552101612,
      "learning_rate": 5.9487838851387554e-06,
      "loss": 0.0003,
      "step": 65570
    },
    {
      "epoch": 7.026679524268724,
      "grad_norm": 0.002510018879547715,
      "learning_rate": 5.946640951462552e-06,
      "loss": 0.2463,
      "step": 65580
    },
    {
      "epoch": 7.027750991106825,
      "grad_norm": 0.0224507637321949,
      "learning_rate": 5.94449801778635e-06,
      "loss": 0.0005,
      "step": 65590
    },
    {
      "epoch": 7.028822457944926,
      "grad_norm": 0.05709094554185867,
      "learning_rate": 5.9423550841101475e-06,
      "loss": 0.0002,
      "step": 65600
    },
    {
      "epoch": 7.029893924783028,
      "grad_norm": 0.0038453892339020967,
      "learning_rate": 5.940212150433945e-06,
      "loss": 0.2527,
      "step": 65610
    },
    {
      "epoch": 7.030965391621129,
      "grad_norm": 0.015565706416964531,
      "learning_rate": 5.938069216757741e-06,
      "loss": 0.0004,
      "step": 65620
    },
    {
      "epoch": 7.0320368584592305,
      "grad_norm": 0.001435339916497469,
      "learning_rate": 5.935926283081539e-06,
      "loss": 0.2882,
      "step": 65630
    },
    {
      "epoch": 7.033108325297332,
      "grad_norm": 0.0007077234331518412,
      "learning_rate": 5.933783349405337e-06,
      "loss": 0.0002,
      "step": 65640
    },
    {
      "epoch": 7.034179792135434,
      "grad_norm": 0.014827634207904339,
      "learning_rate": 5.931640415729134e-06,
      "loss": 0.1824,
      "step": 65650
    },
    {
      "epoch": 7.035251258973535,
      "grad_norm": 27.44576072692871,
      "learning_rate": 5.929497482052931e-06,
      "loss": 0.1908,
      "step": 65660
    },
    {
      "epoch": 7.036322725811636,
      "grad_norm": 0.01603381149470806,
      "learning_rate": 5.927354548376728e-06,
      "loss": 0.1645,
      "step": 65670
    },
    {
      "epoch": 7.037394192649738,
      "grad_norm": 0.022720880806446075,
      "learning_rate": 5.9252116147005255e-06,
      "loss": 0.0019,
      "step": 65680
    },
    {
      "epoch": 7.038465659487839,
      "grad_norm": 0.0008615002152509987,
      "learning_rate": 5.923068681024323e-06,
      "loss": 0.1953,
      "step": 65690
    },
    {
      "epoch": 7.03953712632594,
      "grad_norm": 0.011585590429604053,
      "learning_rate": 5.920925747348119e-06,
      "loss": 0.002,
      "step": 65700
    },
    {
      "epoch": 7.040608593164041,
      "grad_norm": 0.01684143766760826,
      "learning_rate": 5.9187828136719176e-06,
      "loss": 0.0002,
      "step": 65710
    },
    {
      "epoch": 7.041680060002143,
      "grad_norm": 0.17347775399684906,
      "learning_rate": 5.916639879995715e-06,
      "loss": 0.001,
      "step": 65720
    },
    {
      "epoch": 7.042751526840244,
      "grad_norm": 0.0030347818974405527,
      "learning_rate": 5.914496946319512e-06,
      "loss": 0.1179,
      "step": 65730
    },
    {
      "epoch": 7.043822993678345,
      "grad_norm": 0.009575777687132359,
      "learning_rate": 5.912354012643309e-06,
      "loss": 0.0007,
      "step": 65740
    },
    {
      "epoch": 7.044894460516447,
      "grad_norm": 0.00883073452860117,
      "learning_rate": 5.910211078967106e-06,
      "loss": 0.0892,
      "step": 65750
    },
    {
      "epoch": 7.0459659273545485,
      "grad_norm": 0.03217834234237671,
      "learning_rate": 5.9080681452909035e-06,
      "loss": 0.1005,
      "step": 65760
    },
    {
      "epoch": 7.04703739419265,
      "grad_norm": 0.0009753801859915257,
      "learning_rate": 5.905925211614702e-06,
      "loss": 0.0029,
      "step": 65770
    },
    {
      "epoch": 7.048108861030751,
      "grad_norm": 0.0006684477557428181,
      "learning_rate": 5.903782277938498e-06,
      "loss": 0.0002,
      "step": 65780
    },
    {
      "epoch": 7.049180327868853,
      "grad_norm": 0.012157662771642208,
      "learning_rate": 5.9016393442622956e-06,
      "loss": 0.0633,
      "step": 65790
    },
    {
      "epoch": 7.050251794706954,
      "grad_norm": 0.0075889211148023605,
      "learning_rate": 5.899496410586093e-06,
      "loss": 0.1817,
      "step": 65800
    },
    {
      "epoch": 7.051323261545055,
      "grad_norm": 0.001495876582339406,
      "learning_rate": 5.89735347690989e-06,
      "loss": 0.3369,
      "step": 65810
    },
    {
      "epoch": 7.052394728383157,
      "grad_norm": 99.83098602294922,
      "learning_rate": 5.895210543233687e-06,
      "loss": 0.2797,
      "step": 65820
    },
    {
      "epoch": 7.053466195221258,
      "grad_norm": 0.008727243170142174,
      "learning_rate": 5.893067609557485e-06,
      "loss": 0.1158,
      "step": 65830
    },
    {
      "epoch": 7.054537662059359,
      "grad_norm": 0.01579269766807556,
      "learning_rate": 5.890924675881282e-06,
      "loss": 0.0042,
      "step": 65840
    },
    {
      "epoch": 7.05560912889746,
      "grad_norm": 0.011272565461695194,
      "learning_rate": 5.88878174220508e-06,
      "loss": 0.0009,
      "step": 65850
    },
    {
      "epoch": 7.056680595735562,
      "grad_norm": 0.009968001395463943,
      "learning_rate": 5.886638808528876e-06,
      "loss": 0.0003,
      "step": 65860
    },
    {
      "epoch": 7.057752062573663,
      "grad_norm": 0.029218286275863647,
      "learning_rate": 5.8844958748526736e-06,
      "loss": 0.0032,
      "step": 65870
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.008554023690521717,
      "learning_rate": 5.882352941176471e-06,
      "loss": 0.0001,
      "step": 65880
    },
    {
      "epoch": 7.0598949962498665,
      "grad_norm": 0.010484314523637295,
      "learning_rate": 5.880210007500269e-06,
      "loss": 0.0008,
      "step": 65890
    },
    {
      "epoch": 7.060966463087968,
      "grad_norm": 0.0007470272248610854,
      "learning_rate": 5.878067073824066e-06,
      "loss": 0.0011,
      "step": 65900
    },
    {
      "epoch": 7.062037929926069,
      "grad_norm": 1.8159618377685547,
      "learning_rate": 5.875924140147863e-06,
      "loss": 0.1964,
      "step": 65910
    },
    {
      "epoch": 7.06310939676417,
      "grad_norm": 60.25710678100586,
      "learning_rate": 5.87378120647166e-06,
      "loss": 0.171,
      "step": 65920
    },
    {
      "epoch": 7.064180863602272,
      "grad_norm": 0.2961476445198059,
      "learning_rate": 5.871638272795458e-06,
      "loss": 0.0005,
      "step": 65930
    },
    {
      "epoch": 7.065252330440373,
      "grad_norm": 0.0006014083046466112,
      "learning_rate": 5.869495339119254e-06,
      "loss": 0.0009,
      "step": 65940
    },
    {
      "epoch": 7.066323797278474,
      "grad_norm": 0.6712015867233276,
      "learning_rate": 5.8673524054430516e-06,
      "loss": 0.5977,
      "step": 65950
    },
    {
      "epoch": 7.067395264116575,
      "grad_norm": 12.73358154296875,
      "learning_rate": 5.86520947176685e-06,
      "loss": 0.0087,
      "step": 65960
    },
    {
      "epoch": 7.068466730954677,
      "grad_norm": 0.004048566333949566,
      "learning_rate": 5.863066538090647e-06,
      "loss": 0.0544,
      "step": 65970
    },
    {
      "epoch": 7.069538197792778,
      "grad_norm": 0.001844645943492651,
      "learning_rate": 5.860923604414444e-06,
      "loss": 0.1632,
      "step": 65980
    },
    {
      "epoch": 7.070609664630879,
      "grad_norm": 0.0015625463565811515,
      "learning_rate": 5.858780670738241e-06,
      "loss": 0.0648,
      "step": 65990
    },
    {
      "epoch": 7.071681131468981,
      "grad_norm": 0.003976454026997089,
      "learning_rate": 5.856637737062038e-06,
      "loss": 0.0002,
      "step": 66000
    },
    {
      "epoch": 7.0727525983070825,
      "grad_norm": 0.0014993975637480617,
      "learning_rate": 5.8544948033858365e-06,
      "loss": 0.0002,
      "step": 66010
    },
    {
      "epoch": 7.073824065145184,
      "grad_norm": 0.011196405626833439,
      "learning_rate": 5.852351869709633e-06,
      "loss": 0.0027,
      "step": 66020
    },
    {
      "epoch": 7.074895531983285,
      "grad_norm": 0.002630179049447179,
      "learning_rate": 5.85020893603343e-06,
      "loss": 0.0002,
      "step": 66030
    },
    {
      "epoch": 7.075966998821387,
      "grad_norm": 0.027239209040999413,
      "learning_rate": 5.848066002357228e-06,
      "loss": 0.0012,
      "step": 66040
    },
    {
      "epoch": 7.077038465659488,
      "grad_norm": 0.005897169001400471,
      "learning_rate": 5.845923068681025e-06,
      "loss": 0.0009,
      "step": 66050
    },
    {
      "epoch": 7.078109932497589,
      "grad_norm": 0.0014843810349702835,
      "learning_rate": 5.843780135004822e-06,
      "loss": 0.0003,
      "step": 66060
    },
    {
      "epoch": 7.079181399335691,
      "grad_norm": 0.0018112531397491693,
      "learning_rate": 5.841637201328619e-06,
      "loss": 0.0002,
      "step": 66070
    },
    {
      "epoch": 7.080252866173792,
      "grad_norm": 0.0015383211430162191,
      "learning_rate": 5.839494267652417e-06,
      "loss": 0.0081,
      "step": 66080
    },
    {
      "epoch": 7.081324333011893,
      "grad_norm": 0.0025866483338177204,
      "learning_rate": 5.8373513339762145e-06,
      "loss": 0.0003,
      "step": 66090
    },
    {
      "epoch": 7.082395799849994,
      "grad_norm": 0.001142795430496335,
      "learning_rate": 5.835208400300011e-06,
      "loss": 0.0002,
      "step": 66100
    },
    {
      "epoch": 7.083467266688096,
      "grad_norm": 0.009636390022933483,
      "learning_rate": 5.833065466623808e-06,
      "loss": 0.0004,
      "step": 66110
    },
    {
      "epoch": 7.084538733526197,
      "grad_norm": 0.0018007366452366114,
      "learning_rate": 5.830922532947606e-06,
      "loss": 0.0041,
      "step": 66120
    },
    {
      "epoch": 7.0856102003642984,
      "grad_norm": 0.004581371787935495,
      "learning_rate": 5.828779599271404e-06,
      "loss": 0.0157,
      "step": 66130
    },
    {
      "epoch": 7.0866816672024004,
      "grad_norm": 0.007300547324120998,
      "learning_rate": 5.8266366655952e-06,
      "loss": 0.0002,
      "step": 66140
    },
    {
      "epoch": 7.087753134040502,
      "grad_norm": 0.016222625970840454,
      "learning_rate": 5.824493731918998e-06,
      "loss": 0.0006,
      "step": 66150
    },
    {
      "epoch": 7.088824600878603,
      "grad_norm": 0.004341532941907644,
      "learning_rate": 5.822350798242795e-06,
      "loss": 0.0003,
      "step": 66160
    },
    {
      "epoch": 7.089896067716704,
      "grad_norm": 0.006803160533308983,
      "learning_rate": 5.820207864566592e-06,
      "loss": 0.1428,
      "step": 66170
    },
    {
      "epoch": 7.090967534554806,
      "grad_norm": 0.0008161456207744777,
      "learning_rate": 5.818064930890389e-06,
      "loss": 0.0004,
      "step": 66180
    },
    {
      "epoch": 7.092039001392907,
      "grad_norm": 0.007775906939059496,
      "learning_rate": 5.815921997214186e-06,
      "loss": 0.0002,
      "step": 66190
    },
    {
      "epoch": 7.093110468231008,
      "grad_norm": 0.0014704912900924683,
      "learning_rate": 5.813779063537985e-06,
      "loss": 0.0001,
      "step": 66200
    },
    {
      "epoch": 7.09418193506911,
      "grad_norm": 0.0005798541242256761,
      "learning_rate": 5.811636129861781e-06,
      "loss": 0.2708,
      "step": 66210
    },
    {
      "epoch": 7.095253401907211,
      "grad_norm": 0.005373649764806032,
      "learning_rate": 5.8094931961855785e-06,
      "loss": 0.0002,
      "step": 66220
    },
    {
      "epoch": 7.096324868745312,
      "grad_norm": 0.004807647317647934,
      "learning_rate": 5.807350262509376e-06,
      "loss": 0.0002,
      "step": 66230
    },
    {
      "epoch": 7.097396335583413,
      "grad_norm": 0.031057259067893028,
      "learning_rate": 5.805207328833173e-06,
      "loss": 0.0003,
      "step": 66240
    },
    {
      "epoch": 7.098467802421515,
      "grad_norm": 29.54792594909668,
      "learning_rate": 5.80306439515697e-06,
      "loss": 0.3989,
      "step": 66250
    },
    {
      "epoch": 7.099539269259616,
      "grad_norm": 0.01689646579325199,
      "learning_rate": 5.800921461480767e-06,
      "loss": 0.1142,
      "step": 66260
    },
    {
      "epoch": 7.1006107360977175,
      "grad_norm": 0.0006109558744356036,
      "learning_rate": 5.798778527804565e-06,
      "loss": 0.1666,
      "step": 66270
    },
    {
      "epoch": 7.1016822029358195,
      "grad_norm": 0.005377447232604027,
      "learning_rate": 5.796635594128363e-06,
      "loss": 0.0002,
      "step": 66280
    },
    {
      "epoch": 7.102753669773921,
      "grad_norm": 0.004612879361957312,
      "learning_rate": 5.794492660452159e-06,
      "loss": 0.0003,
      "step": 66290
    },
    {
      "epoch": 7.103825136612022,
      "grad_norm": 0.03883448988199234,
      "learning_rate": 5.7923497267759565e-06,
      "loss": 0.0011,
      "step": 66300
    },
    {
      "epoch": 7.104896603450123,
      "grad_norm": 0.009247081354260445,
      "learning_rate": 5.790206793099754e-06,
      "loss": 0.1607,
      "step": 66310
    },
    {
      "epoch": 7.105968070288225,
      "grad_norm": 0.02836553566157818,
      "learning_rate": 5.788063859423552e-06,
      "loss": 0.0002,
      "step": 66320
    },
    {
      "epoch": 7.107039537126326,
      "grad_norm": 0.0035976474173367023,
      "learning_rate": 5.785920925747348e-06,
      "loss": 0.0047,
      "step": 66330
    },
    {
      "epoch": 7.108111003964427,
      "grad_norm": 0.005343894474208355,
      "learning_rate": 5.783777992071146e-06,
      "loss": 0.1946,
      "step": 66340
    },
    {
      "epoch": 7.109182470802529,
      "grad_norm": 0.6164698600769043,
      "learning_rate": 5.781635058394943e-06,
      "loss": 0.0009,
      "step": 66350
    },
    {
      "epoch": 7.11025393764063,
      "grad_norm": 0.0006771175540052354,
      "learning_rate": 5.779492124718741e-06,
      "loss": 0.0009,
      "step": 66360
    },
    {
      "epoch": 7.111325404478731,
      "grad_norm": 0.0009458254207856953,
      "learning_rate": 5.777349191042537e-06,
      "loss": 0.0003,
      "step": 66370
    },
    {
      "epoch": 7.112396871316832,
      "grad_norm": 0.0006999323377385736,
      "learning_rate": 5.7752062573663345e-06,
      "loss": 0.0419,
      "step": 66380
    },
    {
      "epoch": 7.113468338154934,
      "grad_norm": 0.0037163521628826857,
      "learning_rate": 5.773063323690133e-06,
      "loss": 0.1943,
      "step": 66390
    },
    {
      "epoch": 7.1145398049930355,
      "grad_norm": 0.007289404980838299,
      "learning_rate": 5.77092039001393e-06,
      "loss": 0.1994,
      "step": 66400
    },
    {
      "epoch": 7.115611271831137,
      "grad_norm": 0.1641402542591095,
      "learning_rate": 5.7687774563377265e-06,
      "loss": 0.0005,
      "step": 66410
    },
    {
      "epoch": 7.116682738669239,
      "grad_norm": 0.0067409430630505085,
      "learning_rate": 5.766634522661524e-06,
      "loss": 0.0883,
      "step": 66420
    },
    {
      "epoch": 7.11775420550734,
      "grad_norm": 0.0010016391752287745,
      "learning_rate": 5.764491588985321e-06,
      "loss": 0.0006,
      "step": 66430
    },
    {
      "epoch": 7.118825672345441,
      "grad_norm": 0.000451037660241127,
      "learning_rate": 5.762348655309119e-06,
      "loss": 0.0001,
      "step": 66440
    },
    {
      "epoch": 7.119897139183542,
      "grad_norm": 0.0006047024508006871,
      "learning_rate": 5.760205721632915e-06,
      "loss": 0.251,
      "step": 66450
    },
    {
      "epoch": 7.120968606021644,
      "grad_norm": 0.05105126276612282,
      "learning_rate": 5.758062787956713e-06,
      "loss": 0.0001,
      "step": 66460
    },
    {
      "epoch": 7.122040072859745,
      "grad_norm": 0.005849509034305811,
      "learning_rate": 5.755919854280511e-06,
      "loss": 0.0003,
      "step": 66470
    },
    {
      "epoch": 7.123111539697846,
      "grad_norm": 0.16559000313282013,
      "learning_rate": 5.753776920604308e-06,
      "loss": 0.0004,
      "step": 66480
    },
    {
      "epoch": 7.124183006535947,
      "grad_norm": 0.11004623770713806,
      "learning_rate": 5.7516339869281045e-06,
      "loss": 0.0077,
      "step": 66490
    },
    {
      "epoch": 7.125254473374049,
      "grad_norm": 57.108585357666016,
      "learning_rate": 5.749491053251902e-06,
      "loss": 0.0219,
      "step": 66500
    },
    {
      "epoch": 7.12632594021215,
      "grad_norm": 0.0013698512921109796,
      "learning_rate": 5.7473481195757e-06,
      "loss": 0.3214,
      "step": 66510
    },
    {
      "epoch": 7.1273974070502515,
      "grad_norm": 0.0005275489529594779,
      "learning_rate": 5.7452051858994975e-06,
      "loss": 0.0001,
      "step": 66520
    },
    {
      "epoch": 7.1284688738883535,
      "grad_norm": 0.0009458081913180649,
      "learning_rate": 5.743062252223294e-06,
      "loss": 0.0001,
      "step": 66530
    },
    {
      "epoch": 7.129540340726455,
      "grad_norm": 0.0005927016609348357,
      "learning_rate": 5.740919318547091e-06,
      "loss": 0.0002,
      "step": 66540
    },
    {
      "epoch": 7.130611807564556,
      "grad_norm": 0.002915571676567197,
      "learning_rate": 5.738776384870889e-06,
      "loss": 0.076,
      "step": 66550
    },
    {
      "epoch": 7.131683274402657,
      "grad_norm": 0.004324378911405802,
      "learning_rate": 5.736633451194686e-06,
      "loss": 0.0002,
      "step": 66560
    },
    {
      "epoch": 7.132754741240759,
      "grad_norm": 0.010776328854262829,
      "learning_rate": 5.7344905175184825e-06,
      "loss": 0.0001,
      "step": 66570
    },
    {
      "epoch": 7.13382620807886,
      "grad_norm": 0.0007128828437998891,
      "learning_rate": 5.732347583842281e-06,
      "loss": 0.1775,
      "step": 66580
    },
    {
      "epoch": 7.134897674916961,
      "grad_norm": 0.010216218419373035,
      "learning_rate": 5.730204650166078e-06,
      "loss": 0.0001,
      "step": 66590
    },
    {
      "epoch": 7.135969141755063,
      "grad_norm": 0.0040311566554009914,
      "learning_rate": 5.7280617164898755e-06,
      "loss": 0.357,
      "step": 66600
    },
    {
      "epoch": 7.137040608593164,
      "grad_norm": 0.004643652588129044,
      "learning_rate": 5.725918782813672e-06,
      "loss": 0.0183,
      "step": 66610
    },
    {
      "epoch": 7.138112075431265,
      "grad_norm": 0.043155331164598465,
      "learning_rate": 5.723775849137469e-06,
      "loss": 0.0001,
      "step": 66620
    },
    {
      "epoch": 7.139183542269366,
      "grad_norm": 0.002209130208939314,
      "learning_rate": 5.721632915461267e-06,
      "loss": 0.2115,
      "step": 66630
    },
    {
      "epoch": 7.140255009107468,
      "grad_norm": 0.003441052045673132,
      "learning_rate": 5.719489981785065e-06,
      "loss": 0.1531,
      "step": 66640
    },
    {
      "epoch": 7.1413264759455695,
      "grad_norm": 0.0028677198570221663,
      "learning_rate": 5.717347048108861e-06,
      "loss": 0.0007,
      "step": 66650
    },
    {
      "epoch": 7.142397942783671,
      "grad_norm": 0.0006364532164297998,
      "learning_rate": 5.715204114432659e-06,
      "loss": 0.0006,
      "step": 66660
    },
    {
      "epoch": 7.143469409621773,
      "grad_norm": 0.0007484054076485336,
      "learning_rate": 5.713061180756456e-06,
      "loss": 0.0004,
      "step": 66670
    },
    {
      "epoch": 7.144540876459874,
      "grad_norm": 0.001506652683019638,
      "learning_rate": 5.7109182470802535e-06,
      "loss": 0.0247,
      "step": 66680
    },
    {
      "epoch": 7.145612343297975,
      "grad_norm": 0.004138185642659664,
      "learning_rate": 5.70877531340405e-06,
      "loss": 0.0006,
      "step": 66690
    },
    {
      "epoch": 7.146683810136076,
      "grad_norm": 0.0028756947722285986,
      "learning_rate": 5.706632379727848e-06,
      "loss": 0.0001,
      "step": 66700
    },
    {
      "epoch": 7.147755276974178,
      "grad_norm": 0.0007241115672513843,
      "learning_rate": 5.7044894460516455e-06,
      "loss": 0.0011,
      "step": 66710
    },
    {
      "epoch": 7.148826743812279,
      "grad_norm": 0.002538214437663555,
      "learning_rate": 5.702346512375443e-06,
      "loss": 0.0001,
      "step": 66720
    },
    {
      "epoch": 7.14989821065038,
      "grad_norm": 0.0007957133348099887,
      "learning_rate": 5.700203578699239e-06,
      "loss": 0.0021,
      "step": 66730
    },
    {
      "epoch": 7.150969677488482,
      "grad_norm": 0.0007345899939537048,
      "learning_rate": 5.698060645023037e-06,
      "loss": 0.3463,
      "step": 66740
    },
    {
      "epoch": 7.152041144326583,
      "grad_norm": 0.07371485233306885,
      "learning_rate": 5.695917711346834e-06,
      "loss": 0.0004,
      "step": 66750
    },
    {
      "epoch": 7.153112611164684,
      "grad_norm": 0.0033653751015663147,
      "learning_rate": 5.693774777670632e-06,
      "loss": 0.0055,
      "step": 66760
    },
    {
      "epoch": 7.154184078002785,
      "grad_norm": 14.432868003845215,
      "learning_rate": 5.691631843994429e-06,
      "loss": 0.2901,
      "step": 66770
    },
    {
      "epoch": 7.155255544840887,
      "grad_norm": 0.003250405192375183,
      "learning_rate": 5.689488910318226e-06,
      "loss": 0.0,
      "step": 66780
    },
    {
      "epoch": 7.1563270116789885,
      "grad_norm": 0.009705291129648685,
      "learning_rate": 5.6873459766420235e-06,
      "loss": 0.2333,
      "step": 66790
    },
    {
      "epoch": 7.15739847851709,
      "grad_norm": 0.0010115004843100905,
      "learning_rate": 5.685203042965821e-06,
      "loss": 0.2653,
      "step": 66800
    },
    {
      "epoch": 7.158469945355192,
      "grad_norm": 0.0003915118286386132,
      "learning_rate": 5.683060109289617e-06,
      "loss": 0.2108,
      "step": 66810
    },
    {
      "epoch": 7.159541412193293,
      "grad_norm": 0.000698246993124485,
      "learning_rate": 5.680917175613415e-06,
      "loss": 0.0002,
      "step": 66820
    },
    {
      "epoch": 7.160612879031394,
      "grad_norm": 0.009515278041362762,
      "learning_rate": 5.678774241937213e-06,
      "loss": 0.0002,
      "step": 66830
    },
    {
      "epoch": 7.161684345869495,
      "grad_norm": 52.919883728027344,
      "learning_rate": 5.67663130826101e-06,
      "loss": 0.1887,
      "step": 66840
    },
    {
      "epoch": 7.162755812707597,
      "grad_norm": 0.0021550559904426336,
      "learning_rate": 5.674488374584807e-06,
      "loss": 0.0006,
      "step": 66850
    },
    {
      "epoch": 7.163827279545698,
      "grad_norm": 0.029683563858270645,
      "learning_rate": 5.672345440908604e-06,
      "loss": 0.0002,
      "step": 66860
    },
    {
      "epoch": 7.164898746383799,
      "grad_norm": 0.012586826458573341,
      "learning_rate": 5.6702025072324015e-06,
      "loss": 0.578,
      "step": 66870
    },
    {
      "epoch": 7.165970213221901,
      "grad_norm": 0.04417834430932999,
      "learning_rate": 5.6680595735562e-06,
      "loss": 0.0011,
      "step": 66880
    },
    {
      "epoch": 7.167041680060002,
      "grad_norm": 89.2900619506836,
      "learning_rate": 5.665916639879996e-06,
      "loss": 0.232,
      "step": 66890
    },
    {
      "epoch": 7.168113146898103,
      "grad_norm": 0.000986770959571004,
      "learning_rate": 5.663773706203794e-06,
      "loss": 0.0001,
      "step": 66900
    },
    {
      "epoch": 7.1691846137362045,
      "grad_norm": 0.005519278347492218,
      "learning_rate": 5.661630772527591e-06,
      "loss": 0.0074,
      "step": 66910
    },
    {
      "epoch": 7.1702560805743065,
      "grad_norm": 0.019300902262330055,
      "learning_rate": 5.659487838851388e-06,
      "loss": 0.0007,
      "step": 66920
    },
    {
      "epoch": 7.171327547412408,
      "grad_norm": 0.10121075063943863,
      "learning_rate": 5.657344905175185e-06,
      "loss": 0.0003,
      "step": 66930
    },
    {
      "epoch": 7.172399014250509,
      "grad_norm": 0.0009001888101920485,
      "learning_rate": 5.655201971498982e-06,
      "loss": 0.1718,
      "step": 66940
    },
    {
      "epoch": 7.173470481088611,
      "grad_norm": 0.012453663162887096,
      "learning_rate": 5.65305903782278e-06,
      "loss": 0.1947,
      "step": 66950
    },
    {
      "epoch": 7.174541947926712,
      "grad_norm": 0.003038305090740323,
      "learning_rate": 5.650916104146578e-06,
      "loss": 0.1349,
      "step": 66960
    },
    {
      "epoch": 7.175613414764813,
      "grad_norm": 0.006343786139041185,
      "learning_rate": 5.648773170470374e-06,
      "loss": 0.1326,
      "step": 66970
    },
    {
      "epoch": 7.176684881602914,
      "grad_norm": 0.008161747828125954,
      "learning_rate": 5.646630236794172e-06,
      "loss": 0.0001,
      "step": 66980
    },
    {
      "epoch": 7.177756348441016,
      "grad_norm": 0.0019429662497714162,
      "learning_rate": 5.644487303117969e-06,
      "loss": 0.0066,
      "step": 66990
    },
    {
      "epoch": 7.178827815279117,
      "grad_norm": 0.005085238721221685,
      "learning_rate": 5.642344369441767e-06,
      "loss": 0.1025,
      "step": 67000
    },
    {
      "epoch": 7.179899282117218,
      "grad_norm": 0.0007138767396099865,
      "learning_rate": 5.640201435765563e-06,
      "loss": 0.0011,
      "step": 67010
    },
    {
      "epoch": 7.180970748955319,
      "grad_norm": 0.005841596983373165,
      "learning_rate": 5.638058502089361e-06,
      "loss": 0.0002,
      "step": 67020
    },
    {
      "epoch": 7.182042215793421,
      "grad_norm": 0.004193795379251242,
      "learning_rate": 5.635915568413158e-06,
      "loss": 0.0003,
      "step": 67030
    },
    {
      "epoch": 7.1831136826315225,
      "grad_norm": 0.07227090001106262,
      "learning_rate": 5.633772634736956e-06,
      "loss": 0.2519,
      "step": 67040
    },
    {
      "epoch": 7.184185149469624,
      "grad_norm": 0.0007665512384846807,
      "learning_rate": 5.631629701060752e-06,
      "loss": 0.0001,
      "step": 67050
    },
    {
      "epoch": 7.185256616307726,
      "grad_norm": 0.005936297122389078,
      "learning_rate": 5.62948676738455e-06,
      "loss": 0.0047,
      "step": 67060
    },
    {
      "epoch": 7.186328083145827,
      "grad_norm": 0.00044732188689522445,
      "learning_rate": 5.627343833708348e-06,
      "loss": 0.0169,
      "step": 67070
    },
    {
      "epoch": 7.187399549983928,
      "grad_norm": 0.007578388787806034,
      "learning_rate": 5.625200900032144e-06,
      "loss": 0.0002,
      "step": 67080
    },
    {
      "epoch": 7.188471016822029,
      "grad_norm": 1.8828933238983154,
      "learning_rate": 5.623057966355942e-06,
      "loss": 0.1782,
      "step": 67090
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 0.001161143183708191,
      "learning_rate": 5.620915032679739e-06,
      "loss": 0.0001,
      "step": 67100
    },
    {
      "epoch": 7.190613950498232,
      "grad_norm": 0.0005086124874651432,
      "learning_rate": 5.618772099003536e-06,
      "loss": 0.0002,
      "step": 67110
    },
    {
      "epoch": 7.191685417336333,
      "grad_norm": 0.0006045717746019363,
      "learning_rate": 5.616629165327333e-06,
      "loss": 0.1725,
      "step": 67120
    },
    {
      "epoch": 7.192756884174435,
      "grad_norm": 0.012571536935865879,
      "learning_rate": 5.61448623165113e-06,
      "loss": 0.0001,
      "step": 67130
    },
    {
      "epoch": 7.193828351012536,
      "grad_norm": 0.004491737112402916,
      "learning_rate": 5.6123432979749284e-06,
      "loss": 0.0004,
      "step": 67140
    },
    {
      "epoch": 7.194899817850637,
      "grad_norm": 0.0004601704713422805,
      "learning_rate": 5.610200364298726e-06,
      "loss": 0.0,
      "step": 67150
    },
    {
      "epoch": 7.1959712846887385,
      "grad_norm": 0.0003106860676780343,
      "learning_rate": 5.608057430622522e-06,
      "loss": 0.0005,
      "step": 67160
    },
    {
      "epoch": 7.1970427515268405,
      "grad_norm": 0.006207755766808987,
      "learning_rate": 5.60591449694632e-06,
      "loss": 0.5511,
      "step": 67170
    },
    {
      "epoch": 7.198114218364942,
      "grad_norm": 0.038077935576438904,
      "learning_rate": 5.603771563270117e-06,
      "loss": 0.0002,
      "step": 67180
    },
    {
      "epoch": 7.199185685203043,
      "grad_norm": 0.003307487815618515,
      "learning_rate": 5.601628629593915e-06,
      "loss": 0.2683,
      "step": 67190
    },
    {
      "epoch": 7.200257152041145,
      "grad_norm": 0.05995560809969902,
      "learning_rate": 5.599485695917711e-06,
      "loss": 0.1386,
      "step": 67200
    },
    {
      "epoch": 7.201328618879246,
      "grad_norm": 0.0010313945822417736,
      "learning_rate": 5.597342762241509e-06,
      "loss": 0.0007,
      "step": 67210
    },
    {
      "epoch": 7.202400085717347,
      "grad_norm": 0.0013199766399338841,
      "learning_rate": 5.5951998285653064e-06,
      "loss": 0.0002,
      "step": 67220
    },
    {
      "epoch": 7.203471552555448,
      "grad_norm": 0.00997710321098566,
      "learning_rate": 5.593056894889104e-06,
      "loss": 0.2635,
      "step": 67230
    },
    {
      "epoch": 7.20454301939355,
      "grad_norm": 0.011302159167826176,
      "learning_rate": 5.5909139612129e-06,
      "loss": 0.3348,
      "step": 67240
    },
    {
      "epoch": 7.205614486231651,
      "grad_norm": 0.0023665728513151407,
      "learning_rate": 5.588771027536698e-06,
      "loss": 0.001,
      "step": 67250
    },
    {
      "epoch": 7.206685953069752,
      "grad_norm": 0.005630113184452057,
      "learning_rate": 5.586628093860496e-06,
      "loss": 0.0001,
      "step": 67260
    },
    {
      "epoch": 7.207757419907854,
      "grad_norm": 0.09184889495372772,
      "learning_rate": 5.584485160184293e-06,
      "loss": 0.1305,
      "step": 67270
    },
    {
      "epoch": 7.208828886745955,
      "grad_norm": 0.07095758616924286,
      "learning_rate": 5.58234222650809e-06,
      "loss": 0.0005,
      "step": 67280
    },
    {
      "epoch": 7.2099003535840565,
      "grad_norm": 0.1159488707780838,
      "learning_rate": 5.580199292831887e-06,
      "loss": 0.0007,
      "step": 67290
    },
    {
      "epoch": 7.210971820422158,
      "grad_norm": 0.019683456048369408,
      "learning_rate": 5.5780563591556844e-06,
      "loss": 0.001,
      "step": 67300
    },
    {
      "epoch": 7.21204328726026,
      "grad_norm": 0.001282231998629868,
      "learning_rate": 5.575913425479483e-06,
      "loss": 0.0002,
      "step": 67310
    },
    {
      "epoch": 7.213114754098361,
      "grad_norm": 0.002575099002569914,
      "learning_rate": 5.573770491803278e-06,
      "loss": 0.0001,
      "step": 67320
    },
    {
      "epoch": 7.214186220936462,
      "grad_norm": 0.0013210456818342209,
      "learning_rate": 5.5716275581270765e-06,
      "loss": 0.0003,
      "step": 67330
    },
    {
      "epoch": 7.215257687774564,
      "grad_norm": 0.0009791385382413864,
      "learning_rate": 5.569484624450874e-06,
      "loss": 0.0002,
      "step": 67340
    },
    {
      "epoch": 7.216329154612665,
      "grad_norm": 46.400386810302734,
      "learning_rate": 5.567341690774671e-06,
      "loss": 0.2302,
      "step": 67350
    },
    {
      "epoch": 7.217400621450766,
      "grad_norm": 1.8190423250198364,
      "learning_rate": 5.565198757098468e-06,
      "loss": 0.0018,
      "step": 67360
    },
    {
      "epoch": 7.218472088288867,
      "grad_norm": 0.04293028265237808,
      "learning_rate": 5.563055823422265e-06,
      "loss": 0.0002,
      "step": 67370
    },
    {
      "epoch": 7.219543555126969,
      "grad_norm": 0.021076954901218414,
      "learning_rate": 5.560912889746063e-06,
      "loss": 0.1346,
      "step": 67380
    },
    {
      "epoch": 7.22061502196507,
      "grad_norm": 0.0008646958158351481,
      "learning_rate": 5.558769956069861e-06,
      "loss": 0.2694,
      "step": 67390
    },
    {
      "epoch": 7.221686488803171,
      "grad_norm": 0.007083576638251543,
      "learning_rate": 5.556627022393657e-06,
      "loss": 0.0009,
      "step": 67400
    },
    {
      "epoch": 7.222757955641273,
      "grad_norm": 0.04789894446730614,
      "learning_rate": 5.5544840887174545e-06,
      "loss": 0.4045,
      "step": 67410
    },
    {
      "epoch": 7.223829422479374,
      "grad_norm": 0.14291884005069733,
      "learning_rate": 5.552341155041252e-06,
      "loss": 0.0005,
      "step": 67420
    },
    {
      "epoch": 7.2249008893174755,
      "grad_norm": 0.0007320675067603588,
      "learning_rate": 5.550198221365049e-06,
      "loss": 0.0187,
      "step": 67430
    },
    {
      "epoch": 7.225972356155577,
      "grad_norm": 0.03869432583451271,
      "learning_rate": 5.548055287688846e-06,
      "loss": 0.2015,
      "step": 67440
    },
    {
      "epoch": 7.227043822993679,
      "grad_norm": 0.18180221319198608,
      "learning_rate": 5.545912354012644e-06,
      "loss": 0.0006,
      "step": 67450
    },
    {
      "epoch": 7.22811528983178,
      "grad_norm": 0.0014112555654719472,
      "learning_rate": 5.543769420336441e-06,
      "loss": 0.1976,
      "step": 67460
    },
    {
      "epoch": 7.229186756669881,
      "grad_norm": 0.006310985889285803,
      "learning_rate": 5.541626486660239e-06,
      "loss": 0.0006,
      "step": 67470
    },
    {
      "epoch": 7.230258223507983,
      "grad_norm": 0.0005876774084754288,
      "learning_rate": 5.539483552984035e-06,
      "loss": 0.1902,
      "step": 67480
    },
    {
      "epoch": 7.231329690346084,
      "grad_norm": 0.0014940720284357667,
      "learning_rate": 5.5373406193078325e-06,
      "loss": 0.0846,
      "step": 67490
    },
    {
      "epoch": 7.232401157184185,
      "grad_norm": 0.0008019269444048405,
      "learning_rate": 5.535197685631631e-06,
      "loss": 0.0004,
      "step": 67500
    },
    {
      "epoch": 7.233472624022286,
      "grad_norm": 0.005739310756325722,
      "learning_rate": 5.533054751955428e-06,
      "loss": 0.0871,
      "step": 67510
    },
    {
      "epoch": 7.234544090860388,
      "grad_norm": 0.008389485999941826,
      "learning_rate": 5.5309118182792246e-06,
      "loss": 0.2954,
      "step": 67520
    },
    {
      "epoch": 7.235615557698489,
      "grad_norm": 0.0007364475750364363,
      "learning_rate": 5.528768884603022e-06,
      "loss": 0.0003,
      "step": 67530
    },
    {
      "epoch": 7.23668702453659,
      "grad_norm": 0.0014043693663552403,
      "learning_rate": 5.526625950926819e-06,
      "loss": 0.5079,
      "step": 67540
    },
    {
      "epoch": 7.2377584913746915,
      "grad_norm": 16.902252197265625,
      "learning_rate": 5.524483017250617e-06,
      "loss": 0.0084,
      "step": 67550
    },
    {
      "epoch": 7.2388299582127935,
      "grad_norm": 0.0012668390991166234,
      "learning_rate": 5.522340083574413e-06,
      "loss": 0.2291,
      "step": 67560
    },
    {
      "epoch": 7.239901425050895,
      "grad_norm": 0.018063029274344444,
      "learning_rate": 5.520197149898211e-06,
      "loss": 0.0718,
      "step": 67570
    },
    {
      "epoch": 7.240972891888996,
      "grad_norm": 0.03325130045413971,
      "learning_rate": 5.518054216222009e-06,
      "loss": 0.0007,
      "step": 67580
    },
    {
      "epoch": 7.242044358727098,
      "grad_norm": 0.22055065631866455,
      "learning_rate": 5.515911282545806e-06,
      "loss": 0.2271,
      "step": 67590
    },
    {
      "epoch": 7.243115825565199,
      "grad_norm": 0.05162572115659714,
      "learning_rate": 5.5137683488696026e-06,
      "loss": 0.0062,
      "step": 67600
    },
    {
      "epoch": 7.2441872924033,
      "grad_norm": 0.4006347954273224,
      "learning_rate": 5.5116254151934e-06,
      "loss": 0.0022,
      "step": 67610
    },
    {
      "epoch": 7.245258759241401,
      "grad_norm": 0.0014822641387581825,
      "learning_rate": 5.509482481517197e-06,
      "loss": 0.0006,
      "step": 67620
    },
    {
      "epoch": 7.246330226079503,
      "grad_norm": 0.005829186178743839,
      "learning_rate": 5.5073395478409955e-06,
      "loss": 0.0001,
      "step": 67630
    },
    {
      "epoch": 7.247401692917604,
      "grad_norm": 0.013317195698618889,
      "learning_rate": 5.505196614164792e-06,
      "loss": 0.0003,
      "step": 67640
    },
    {
      "epoch": 7.248473159755705,
      "grad_norm": 0.1329137086868286,
      "learning_rate": 5.503053680488589e-06,
      "loss": 0.0077,
      "step": 67650
    },
    {
      "epoch": 7.249544626593807,
      "grad_norm": 0.002648748457431793,
      "learning_rate": 5.500910746812387e-06,
      "loss": 0.0003,
      "step": 67660
    },
    {
      "epoch": 7.250616093431908,
      "grad_norm": 0.01090315356850624,
      "learning_rate": 5.498767813136184e-06,
      "loss": 0.1821,
      "step": 67670
    },
    {
      "epoch": 7.2516875602700095,
      "grad_norm": 0.0013809367083013058,
      "learning_rate": 5.4966248794599806e-06,
      "loss": 0.0003,
      "step": 67680
    },
    {
      "epoch": 7.252759027108111,
      "grad_norm": 11.639628410339355,
      "learning_rate": 5.494481945783779e-06,
      "loss": 0.0031,
      "step": 67690
    },
    {
      "epoch": 7.253830493946213,
      "grad_norm": 0.0009815708035603166,
      "learning_rate": 5.492339012107576e-06,
      "loss": 0.0005,
      "step": 67700
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 0.0036802596878260374,
      "learning_rate": 5.4901960784313735e-06,
      "loss": 0.2245,
      "step": 67710
    },
    {
      "epoch": 7.255973427622415,
      "grad_norm": 0.001582822180353105,
      "learning_rate": 5.48805314475517e-06,
      "loss": 0.0005,
      "step": 67720
    },
    {
      "epoch": 7.257044894460517,
      "grad_norm": 0.000678042124491185,
      "learning_rate": 5.485910211078967e-06,
      "loss": 0.0004,
      "step": 67730
    },
    {
      "epoch": 7.258116361298618,
      "grad_norm": 60.92458724975586,
      "learning_rate": 5.483767277402765e-06,
      "loss": 0.3162,
      "step": 67740
    },
    {
      "epoch": 7.259187828136719,
      "grad_norm": 0.009895035065710545,
      "learning_rate": 5.481624343726563e-06,
      "loss": 0.0003,
      "step": 67750
    },
    {
      "epoch": 7.26025929497482,
      "grad_norm": 0.044159065932035446,
      "learning_rate": 5.479481410050359e-06,
      "loss": 0.3389,
      "step": 67760
    },
    {
      "epoch": 7.261330761812922,
      "grad_norm": 0.03582267463207245,
      "learning_rate": 5.477338476374157e-06,
      "loss": 0.0002,
      "step": 67770
    },
    {
      "epoch": 7.262402228651023,
      "grad_norm": 0.016730044037103653,
      "learning_rate": 5.475195542697954e-06,
      "loss": 0.0003,
      "step": 67780
    },
    {
      "epoch": 7.263473695489124,
      "grad_norm": 0.003474494209513068,
      "learning_rate": 5.4730526090217515e-06,
      "loss": 0.0011,
      "step": 67790
    },
    {
      "epoch": 7.264545162327226,
      "grad_norm": 0.03660750761628151,
      "learning_rate": 5.470909675345548e-06,
      "loss": 0.0003,
      "step": 67800
    },
    {
      "epoch": 7.2656166291653275,
      "grad_norm": 0.0008174361428245902,
      "learning_rate": 5.468766741669345e-06,
      "loss": 0.1321,
      "step": 67810
    },
    {
      "epoch": 7.266688096003429,
      "grad_norm": 0.16877523064613342,
      "learning_rate": 5.4666238079931435e-06,
      "loss": 0.0003,
      "step": 67820
    },
    {
      "epoch": 7.26775956284153,
      "grad_norm": 0.0016248158644884825,
      "learning_rate": 5.464480874316941e-06,
      "loss": 0.0005,
      "step": 67830
    },
    {
      "epoch": 7.268831029679632,
      "grad_norm": 0.5050502419471741,
      "learning_rate": 5.462337940640737e-06,
      "loss": 0.0144,
      "step": 67840
    },
    {
      "epoch": 7.269902496517733,
      "grad_norm": 0.0034307034220546484,
      "learning_rate": 5.460195006964535e-06,
      "loss": 0.1496,
      "step": 67850
    },
    {
      "epoch": 7.270973963355834,
      "grad_norm": 0.005628904327750206,
      "learning_rate": 5.458052073288332e-06,
      "loss": 0.0003,
      "step": 67860
    },
    {
      "epoch": 7.272045430193936,
      "grad_norm": 0.0029460685327649117,
      "learning_rate": 5.45590913961213e-06,
      "loss": 0.0001,
      "step": 67870
    },
    {
      "epoch": 7.273116897032037,
      "grad_norm": 0.007539581973105669,
      "learning_rate": 5.453766205935927e-06,
      "loss": 0.1934,
      "step": 67880
    },
    {
      "epoch": 7.274188363870138,
      "grad_norm": 0.0006914365803822875,
      "learning_rate": 5.451623272259724e-06,
      "loss": 0.0004,
      "step": 67890
    },
    {
      "epoch": 7.275259830708239,
      "grad_norm": 0.003056108020246029,
      "learning_rate": 5.4494803385835215e-06,
      "loss": 0.0002,
      "step": 67900
    },
    {
      "epoch": 7.276331297546341,
      "grad_norm": 17.070463180541992,
      "learning_rate": 5.447337404907319e-06,
      "loss": 0.2218,
      "step": 67910
    },
    {
      "epoch": 7.277402764384442,
      "grad_norm": 0.006589900236576796,
      "learning_rate": 5.445194471231115e-06,
      "loss": 0.0001,
      "step": 67920
    },
    {
      "epoch": 7.2784742312225434,
      "grad_norm": 0.005271132569760084,
      "learning_rate": 5.443051537554913e-06,
      "loss": 0.0001,
      "step": 67930
    },
    {
      "epoch": 7.2795456980606446,
      "grad_norm": 0.27086666226387024,
      "learning_rate": 5.440908603878711e-06,
      "loss": 0.0003,
      "step": 67940
    },
    {
      "epoch": 7.2806171648987466,
      "grad_norm": 0.0006356614176183939,
      "learning_rate": 5.438765670202508e-06,
      "loss": 0.3071,
      "step": 67950
    },
    {
      "epoch": 7.281688631736848,
      "grad_norm": 0.015943096950650215,
      "learning_rate": 5.436622736526305e-06,
      "loss": 0.26,
      "step": 67960
    },
    {
      "epoch": 7.282760098574949,
      "grad_norm": 3.3422863483428955,
      "learning_rate": 5.434479802850102e-06,
      "loss": 0.002,
      "step": 67970
    },
    {
      "epoch": 7.283831565413051,
      "grad_norm": 0.04635189473628998,
      "learning_rate": 5.4323368691738995e-06,
      "loss": 0.0002,
      "step": 67980
    },
    {
      "epoch": 7.284903032251152,
      "grad_norm": 0.001677144318819046,
      "learning_rate": 5.430193935497696e-06,
      "loss": 0.1977,
      "step": 67990
    },
    {
      "epoch": 7.285974499089253,
      "grad_norm": 0.02737816981971264,
      "learning_rate": 5.428051001821493e-06,
      "loss": 0.0287,
      "step": 68000
    },
    {
      "epoch": 7.287045965927355,
      "grad_norm": 0.005545366555452347,
      "learning_rate": 5.425908068145292e-06,
      "loss": 0.0439,
      "step": 68010
    },
    {
      "epoch": 7.288117432765456,
      "grad_norm": 16.075271606445312,
      "learning_rate": 5.423765134469089e-06,
      "loss": 0.2448,
      "step": 68020
    },
    {
      "epoch": 7.289188899603557,
      "grad_norm": 0.000757007219363004,
      "learning_rate": 5.4216222007928855e-06,
      "loss": 0.0001,
      "step": 68030
    },
    {
      "epoch": 7.290260366441658,
      "grad_norm": 0.005820401944220066,
      "learning_rate": 5.419479267116683e-06,
      "loss": 0.0003,
      "step": 68040
    },
    {
      "epoch": 7.29133183327976,
      "grad_norm": 0.0025115152820944786,
      "learning_rate": 5.41733633344048e-06,
      "loss": 0.2672,
      "step": 68050
    },
    {
      "epoch": 7.292403300117861,
      "grad_norm": 1119.379150390625,
      "learning_rate": 5.415193399764278e-06,
      "loss": 0.3393,
      "step": 68060
    },
    {
      "epoch": 7.2934747669559625,
      "grad_norm": 0.001074338797479868,
      "learning_rate": 5.413050466088075e-06,
      "loss": 0.0006,
      "step": 68070
    },
    {
      "epoch": 7.294546233794064,
      "grad_norm": 55.80010223388672,
      "learning_rate": 5.410907532411872e-06,
      "loss": 0.0518,
      "step": 68080
    },
    {
      "epoch": 7.295617700632166,
      "grad_norm": 0.010311304591596127,
      "learning_rate": 5.40876459873567e-06,
      "loss": 0.0005,
      "step": 68090
    },
    {
      "epoch": 7.296689167470267,
      "grad_norm": 0.00566518260166049,
      "learning_rate": 5.406621665059467e-06,
      "loss": 0.0001,
      "step": 68100
    },
    {
      "epoch": 7.297760634308368,
      "grad_norm": 0.0013145129196345806,
      "learning_rate": 5.4044787313832635e-06,
      "loss": 0.1754,
      "step": 68110
    },
    {
      "epoch": 7.29883210114647,
      "grad_norm": 0.0034528400283306837,
      "learning_rate": 5.402335797707061e-06,
      "loss": 0.1258,
      "step": 68120
    },
    {
      "epoch": 7.299903567984571,
      "grad_norm": 0.043927840888500214,
      "learning_rate": 5.400192864030859e-06,
      "loss": 0.0004,
      "step": 68130
    },
    {
      "epoch": 7.300975034822672,
      "grad_norm": 0.013631926849484444,
      "learning_rate": 5.398049930354656e-06,
      "loss": 0.2432,
      "step": 68140
    },
    {
      "epoch": 7.302046501660774,
      "grad_norm": 0.001367832301184535,
      "learning_rate": 5.395906996678453e-06,
      "loss": 0.0002,
      "step": 68150
    },
    {
      "epoch": 7.303117968498875,
      "grad_norm": 0.003837251104414463,
      "learning_rate": 5.39376406300225e-06,
      "loss": 0.0028,
      "step": 68160
    },
    {
      "epoch": 7.304189435336976,
      "grad_norm": 0.0006787092424929142,
      "learning_rate": 5.391621129326048e-06,
      "loss": 0.0004,
      "step": 68170
    },
    {
      "epoch": 7.305260902175077,
      "grad_norm": 0.04265064001083374,
      "learning_rate": 5.389478195649846e-06,
      "loss": 0.0003,
      "step": 68180
    },
    {
      "epoch": 7.306332369013179,
      "grad_norm": 0.000709802727214992,
      "learning_rate": 5.3873352619736415e-06,
      "loss": 0.0002,
      "step": 68190
    },
    {
      "epoch": 7.3074038358512805,
      "grad_norm": 0.009056814014911652,
      "learning_rate": 5.38519232829744e-06,
      "loss": 0.1949,
      "step": 68200
    },
    {
      "epoch": 7.308475302689382,
      "grad_norm": 0.013622395694255829,
      "learning_rate": 5.383049394621237e-06,
      "loss": 0.0002,
      "step": 68210
    },
    {
      "epoch": 7.309546769527483,
      "grad_norm": 31.102096557617188,
      "learning_rate": 5.380906460945034e-06,
      "loss": 0.2628,
      "step": 68220
    },
    {
      "epoch": 7.310618236365585,
      "grad_norm": 39.928218841552734,
      "learning_rate": 5.378763527268831e-06,
      "loss": 0.1138,
      "step": 68230
    },
    {
      "epoch": 7.311689703203686,
      "grad_norm": 0.03551352024078369,
      "learning_rate": 5.376620593592628e-06,
      "loss": 0.0002,
      "step": 68240
    },
    {
      "epoch": 7.312761170041787,
      "grad_norm": 0.0006458862335421145,
      "learning_rate": 5.3744776599164265e-06,
      "loss": 0.0004,
      "step": 68250
    },
    {
      "epoch": 7.313832636879889,
      "grad_norm": 0.009523618966341019,
      "learning_rate": 5.372334726240224e-06,
      "loss": 0.0003,
      "step": 68260
    },
    {
      "epoch": 7.31490410371799,
      "grad_norm": 0.003990633878856897,
      "learning_rate": 5.37019179256402e-06,
      "loss": 0.0004,
      "step": 68270
    },
    {
      "epoch": 7.315975570556091,
      "grad_norm": 0.0005998010165058076,
      "learning_rate": 5.368048858887818e-06,
      "loss": 0.0009,
      "step": 68280
    },
    {
      "epoch": 7.317047037394192,
      "grad_norm": 0.00414805905893445,
      "learning_rate": 5.365905925211615e-06,
      "loss": 0.1387,
      "step": 68290
    },
    {
      "epoch": 7.318118504232294,
      "grad_norm": 0.0027936131227761507,
      "learning_rate": 5.363762991535412e-06,
      "loss": 0.0569,
      "step": 68300
    },
    {
      "epoch": 7.319189971070395,
      "grad_norm": 0.14741572737693787,
      "learning_rate": 5.361620057859209e-06,
      "loss": 0.0001,
      "step": 68310
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 0.004541730508208275,
      "learning_rate": 5.359477124183007e-06,
      "loss": 0.1477,
      "step": 68320
    },
    {
      "epoch": 7.3213329047465985,
      "grad_norm": 0.004055963363498449,
      "learning_rate": 5.3573341905068045e-06,
      "loss": 0.1543,
      "step": 68330
    },
    {
      "epoch": 7.3224043715847,
      "grad_norm": 0.03973622992634773,
      "learning_rate": 5.355191256830602e-06,
      "loss": 0.2252,
      "step": 68340
    },
    {
      "epoch": 7.323475838422801,
      "grad_norm": 0.006124905310571194,
      "learning_rate": 5.353048323154398e-06,
      "loss": 0.1005,
      "step": 68350
    },
    {
      "epoch": 7.324547305260902,
      "grad_norm": 0.000665797560941428,
      "learning_rate": 5.350905389478196e-06,
      "loss": 0.0004,
      "step": 68360
    },
    {
      "epoch": 7.325618772099004,
      "grad_norm": 0.0011182671878486872,
      "learning_rate": 5.348762455801994e-06,
      "loss": 0.0006,
      "step": 68370
    },
    {
      "epoch": 7.326690238937105,
      "grad_norm": 0.01687266305088997,
      "learning_rate": 5.346619522125791e-06,
      "loss": 0.1196,
      "step": 68380
    },
    {
      "epoch": 7.327761705775206,
      "grad_norm": 0.004115195479243994,
      "learning_rate": 5.344476588449588e-06,
      "loss": 0.001,
      "step": 68390
    },
    {
      "epoch": 7.328833172613308,
      "grad_norm": 0.00047733273822814226,
      "learning_rate": 5.342333654773385e-06,
      "loss": 0.0005,
      "step": 68400
    },
    {
      "epoch": 7.329904639451409,
      "grad_norm": 0.0045239366590976715,
      "learning_rate": 5.3401907210971825e-06,
      "loss": 0.0001,
      "step": 68410
    },
    {
      "epoch": 7.33097610628951,
      "grad_norm": 0.006697073578834534,
      "learning_rate": 5.33804778742098e-06,
      "loss": 0.0779,
      "step": 68420
    },
    {
      "epoch": 7.332047573127611,
      "grad_norm": 0.014894788153469563,
      "learning_rate": 5.335904853744776e-06,
      "loss": 0.0002,
      "step": 68430
    },
    {
      "epoch": 7.333119039965713,
      "grad_norm": 0.0006027115159668028,
      "learning_rate": 5.3337619200685745e-06,
      "loss": 0.0003,
      "step": 68440
    },
    {
      "epoch": 7.3341905068038145,
      "grad_norm": 0.07006272673606873,
      "learning_rate": 5.331618986392372e-06,
      "loss": 0.298,
      "step": 68450
    },
    {
      "epoch": 7.335261973641916,
      "grad_norm": 0.0036796587519347668,
      "learning_rate": 5.329476052716169e-06,
      "loss": 0.1793,
      "step": 68460
    },
    {
      "epoch": 7.336333440480017,
      "grad_norm": 0.0027239553164690733,
      "learning_rate": 5.327333119039966e-06,
      "loss": 0.0004,
      "step": 68470
    },
    {
      "epoch": 7.337404907318119,
      "grad_norm": 0.0003167479590047151,
      "learning_rate": 5.325190185363763e-06,
      "loss": 0.0001,
      "step": 68480
    },
    {
      "epoch": 7.33847637415622,
      "grad_norm": 0.00030022955616004765,
      "learning_rate": 5.3230472516875605e-06,
      "loss": 0.0001,
      "step": 68490
    },
    {
      "epoch": 7.339547840994321,
      "grad_norm": 0.008068825118243694,
      "learning_rate": 5.320904318011359e-06,
      "loss": 0.0001,
      "step": 68500
    },
    {
      "epoch": 7.340619307832423,
      "grad_norm": 0.004669824615120888,
      "learning_rate": 5.318761384335155e-06,
      "loss": 0.1837,
      "step": 68510
    },
    {
      "epoch": 7.341690774670524,
      "grad_norm": 0.002853351878002286,
      "learning_rate": 5.3166184506589525e-06,
      "loss": 0.0148,
      "step": 68520
    },
    {
      "epoch": 7.342762241508625,
      "grad_norm": 0.0002706350351218134,
      "learning_rate": 5.31447551698275e-06,
      "loss": 0.1539,
      "step": 68530
    },
    {
      "epoch": 7.343833708346727,
      "grad_norm": 0.00026938991504721344,
      "learning_rate": 5.312332583306547e-06,
      "loss": 0.0001,
      "step": 68540
    },
    {
      "epoch": 7.344905175184828,
      "grad_norm": 0.0032240150030702353,
      "learning_rate": 5.310189649630344e-06,
      "loss": 0.0002,
      "step": 68550
    },
    {
      "epoch": 7.345976642022929,
      "grad_norm": 0.05061290040612221,
      "learning_rate": 5.308046715954142e-06,
      "loss": 0.1638,
      "step": 68560
    },
    {
      "epoch": 7.34704810886103,
      "grad_norm": 0.017587145790457726,
      "learning_rate": 5.305903782277939e-06,
      "loss": 0.0002,
      "step": 68570
    },
    {
      "epoch": 7.348119575699132,
      "grad_norm": 0.008161775767803192,
      "learning_rate": 5.303760848601737e-06,
      "loss": 0.0001,
      "step": 68580
    },
    {
      "epoch": 7.3491910425372335,
      "grad_norm": 0.025695472955703735,
      "learning_rate": 5.301617914925533e-06,
      "loss": 0.0012,
      "step": 68590
    },
    {
      "epoch": 7.350262509375335,
      "grad_norm": 0.06843013316392899,
      "learning_rate": 5.2994749812493305e-06,
      "loss": 0.0004,
      "step": 68600
    },
    {
      "epoch": 7.351333976213436,
      "grad_norm": 2.6798861026763916,
      "learning_rate": 5.297332047573128e-06,
      "loss": 0.0009,
      "step": 68610
    },
    {
      "epoch": 7.352405443051538,
      "grad_norm": 0.00028610340086743236,
      "learning_rate": 5.295189113896926e-06,
      "loss": 0.0002,
      "step": 68620
    },
    {
      "epoch": 7.353476909889639,
      "grad_norm": 0.019811874255537987,
      "learning_rate": 5.293046180220723e-06,
      "loss": 0.0002,
      "step": 68630
    },
    {
      "epoch": 7.35454837672774,
      "grad_norm": 0.0002961534191854298,
      "learning_rate": 5.29090324654452e-06,
      "loss": 0.0,
      "step": 68640
    },
    {
      "epoch": 7.355619843565842,
      "grad_norm": 134.32508850097656,
      "learning_rate": 5.288760312868317e-06,
      "loss": 0.1194,
      "step": 68650
    },
    {
      "epoch": 7.356691310403943,
      "grad_norm": 0.1363132745027542,
      "learning_rate": 5.286617379192115e-06,
      "loss": 0.0002,
      "step": 68660
    },
    {
      "epoch": 7.357762777242044,
      "grad_norm": 0.03635827451944351,
      "learning_rate": 5.284474445515911e-06,
      "loss": 0.0005,
      "step": 68670
    },
    {
      "epoch": 7.358834244080145,
      "grad_norm": 19.314193725585938,
      "learning_rate": 5.2823315118397085e-06,
      "loss": 0.2538,
      "step": 68680
    },
    {
      "epoch": 7.359905710918247,
      "grad_norm": 0.0003666820120997727,
      "learning_rate": 5.280188578163507e-06,
      "loss": 0.0001,
      "step": 68690
    },
    {
      "epoch": 7.360977177756348,
      "grad_norm": 0.13478252291679382,
      "learning_rate": 5.278045644487304e-06,
      "loss": 0.2139,
      "step": 68700
    },
    {
      "epoch": 7.3620486445944495,
      "grad_norm": 0.0003029743384104222,
      "learning_rate": 5.275902710811101e-06,
      "loss": 0.0001,
      "step": 68710
    },
    {
      "epoch": 7.3631201114325515,
      "grad_norm": 0.0042021567933261395,
      "learning_rate": 5.273759777134898e-06,
      "loss": 0.0001,
      "step": 68720
    },
    {
      "epoch": 7.364191578270653,
      "grad_norm": 0.00035795988515019417,
      "learning_rate": 5.271616843458695e-06,
      "loss": 0.0,
      "step": 68730
    },
    {
      "epoch": 7.365263045108754,
      "grad_norm": 0.005466846749186516,
      "learning_rate": 5.2694739097824935e-06,
      "loss": 0.1619,
      "step": 68740
    },
    {
      "epoch": 7.366334511946855,
      "grad_norm": 0.014269116334617138,
      "learning_rate": 5.26733097610629e-06,
      "loss": 0.0001,
      "step": 68750
    },
    {
      "epoch": 7.367405978784957,
      "grad_norm": 0.0008958146208897233,
      "learning_rate": 5.265188042430087e-06,
      "loss": 0.2348,
      "step": 68760
    },
    {
      "epoch": 7.368477445623058,
      "grad_norm": 0.005844570230692625,
      "learning_rate": 5.263045108753885e-06,
      "loss": 0.0001,
      "step": 68770
    },
    {
      "epoch": 7.369548912461159,
      "grad_norm": 0.00033150342642329633,
      "learning_rate": 5.260902175077682e-06,
      "loss": 0.0001,
      "step": 68780
    },
    {
      "epoch": 7.370620379299261,
      "grad_norm": 0.0002807073178701103,
      "learning_rate": 5.258759241401479e-06,
      "loss": 0.1701,
      "step": 68790
    },
    {
      "epoch": 7.371691846137362,
      "grad_norm": 1.1200577020645142,
      "learning_rate": 5.256616307725276e-06,
      "loss": 0.1964,
      "step": 68800
    },
    {
      "epoch": 7.372763312975463,
      "grad_norm": 0.008970699273049831,
      "learning_rate": 5.254473374049074e-06,
      "loss": 0.0001,
      "step": 68810
    },
    {
      "epoch": 7.373834779813564,
      "grad_norm": 0.006067049223929644,
      "learning_rate": 5.2523304403728715e-06,
      "loss": 0.0567,
      "step": 68820
    },
    {
      "epoch": 7.374906246651666,
      "grad_norm": 0.0003899338480550796,
      "learning_rate": 5.250187506696668e-06,
      "loss": 0.0002,
      "step": 68830
    },
    {
      "epoch": 7.3759777134897675,
      "grad_norm": 0.06867323070764542,
      "learning_rate": 5.248044573020465e-06,
      "loss": 0.0002,
      "step": 68840
    },
    {
      "epoch": 7.377049180327869,
      "grad_norm": 0.0037872707471251488,
      "learning_rate": 5.245901639344263e-06,
      "loss": 0.0002,
      "step": 68850
    },
    {
      "epoch": 7.378120647165971,
      "grad_norm": 0.0006568842218257487,
      "learning_rate": 5.243758705668061e-06,
      "loss": 0.0002,
      "step": 68860
    },
    {
      "epoch": 7.379192114004072,
      "grad_norm": 0.01016840711236,
      "learning_rate": 5.241615771991857e-06,
      "loss": 0.0001,
      "step": 68870
    },
    {
      "epoch": 7.380263580842173,
      "grad_norm": 0.004263483919203281,
      "learning_rate": 5.239472838315655e-06,
      "loss": 0.0002,
      "step": 68880
    },
    {
      "epoch": 7.381335047680274,
      "grad_norm": 0.00038216373650357127,
      "learning_rate": 5.237329904639452e-06,
      "loss": 0.0001,
      "step": 68890
    },
    {
      "epoch": 7.382406514518376,
      "grad_norm": 0.00042726474930532277,
      "learning_rate": 5.235186970963249e-06,
      "loss": 0.0002,
      "step": 68900
    },
    {
      "epoch": 7.383477981356477,
      "grad_norm": 0.10410665720701218,
      "learning_rate": 5.233044037287046e-06,
      "loss": 0.2011,
      "step": 68910
    },
    {
      "epoch": 7.384549448194578,
      "grad_norm": 0.0003501983592286706,
      "learning_rate": 5.230901103610843e-06,
      "loss": 0.0,
      "step": 68920
    },
    {
      "epoch": 7.38562091503268,
      "grad_norm": 0.011911905370652676,
      "learning_rate": 5.2287581699346416e-06,
      "loss": 0.0002,
      "step": 68930
    },
    {
      "epoch": 7.386692381870781,
      "grad_norm": 0.007348282262682915,
      "learning_rate": 5.226615236258438e-06,
      "loss": 0.2177,
      "step": 68940
    },
    {
      "epoch": 7.387763848708882,
      "grad_norm": 0.0005065303412266076,
      "learning_rate": 5.2244723025822354e-06,
      "loss": 0.0007,
      "step": 68950
    },
    {
      "epoch": 7.3888353155469835,
      "grad_norm": 0.0028650325257331133,
      "learning_rate": 5.222329368906033e-06,
      "loss": 0.0001,
      "step": 68960
    },
    {
      "epoch": 7.3899067823850855,
      "grad_norm": 0.0003541588957887143,
      "learning_rate": 5.22018643522983e-06,
      "loss": 0.1061,
      "step": 68970
    },
    {
      "epoch": 7.390978249223187,
      "grad_norm": 0.00026826790417544544,
      "learning_rate": 5.218043501553627e-06,
      "loss": 0.0,
      "step": 68980
    },
    {
      "epoch": 7.392049716061288,
      "grad_norm": 0.0003566789091564715,
      "learning_rate": 5.215900567877424e-06,
      "loss": 0.225,
      "step": 68990
    },
    {
      "epoch": 7.393121182899389,
      "grad_norm": 0.0022645178250968456,
      "learning_rate": 5.213757634201222e-06,
      "loss": 0.0001,
      "step": 69000
    },
    {
      "epoch": 7.394192649737491,
      "grad_norm": 0.0004126726998947561,
      "learning_rate": 5.2116147005250196e-06,
      "loss": 0.0,
      "step": 69010
    },
    {
      "epoch": 7.395264116575592,
      "grad_norm": 0.0002828632132150233,
      "learning_rate": 5.209471766848816e-06,
      "loss": 0.7474,
      "step": 69020
    },
    {
      "epoch": 7.396335583413693,
      "grad_norm": 0.00029469162109307945,
      "learning_rate": 5.2073288331726134e-06,
      "loss": 0.1603,
      "step": 69030
    },
    {
      "epoch": 7.397407050251795,
      "grad_norm": 0.0004589218006003648,
      "learning_rate": 5.205185899496411e-06,
      "loss": 0.0001,
      "step": 69040
    },
    {
      "epoch": 7.398478517089896,
      "grad_norm": 0.00032569438917562366,
      "learning_rate": 5.203042965820209e-06,
      "loss": 0.6457,
      "step": 69050
    },
    {
      "epoch": 7.399549983927997,
      "grad_norm": 0.0998258888721466,
      "learning_rate": 5.200900032144005e-06,
      "loss": 0.0003,
      "step": 69060
    },
    {
      "epoch": 7.400621450766099,
      "grad_norm": 0.0003899080620612949,
      "learning_rate": 5.198757098467803e-06,
      "loss": 0.058,
      "step": 69070
    },
    {
      "epoch": 7.4016929176042,
      "grad_norm": 0.0023705491330474615,
      "learning_rate": 5.1966141647916e-06,
      "loss": 0.0001,
      "step": 69080
    },
    {
      "epoch": 7.4027643844423014,
      "grad_norm": 0.00037678744411095977,
      "learning_rate": 5.1944712311153976e-06,
      "loss": 0.0002,
      "step": 69090
    },
    {
      "epoch": 7.403835851280403,
      "grad_norm": 0.0032588241156190634,
      "learning_rate": 5.192328297439194e-06,
      "loss": 0.0005,
      "step": 69100
    },
    {
      "epoch": 7.4049073181185046,
      "grad_norm": 0.005729443393647671,
      "learning_rate": 5.1901853637629914e-06,
      "loss": 0.0003,
      "step": 69110
    },
    {
      "epoch": 7.405978784956606,
      "grad_norm": 0.011514200828969479,
      "learning_rate": 5.18804243008679e-06,
      "loss": 0.0004,
      "step": 69120
    },
    {
      "epoch": 7.407050251794707,
      "grad_norm": 0.01937100477516651,
      "learning_rate": 5.185899496410587e-06,
      "loss": 0.144,
      "step": 69130
    },
    {
      "epoch": 7.408121718632808,
      "grad_norm": 0.00041279339347966015,
      "learning_rate": 5.1837565627343835e-06,
      "loss": 0.1374,
      "step": 69140
    },
    {
      "epoch": 7.40919318547091,
      "grad_norm": 0.03919045999646187,
      "learning_rate": 5.181613629058181e-06,
      "loss": 0.0686,
      "step": 69150
    },
    {
      "epoch": 7.410264652309011,
      "grad_norm": 0.005847372114658356,
      "learning_rate": 5.179470695381978e-06,
      "loss": 0.0004,
      "step": 69160
    },
    {
      "epoch": 7.411336119147112,
      "grad_norm": 0.02011975273489952,
      "learning_rate": 5.177327761705776e-06,
      "loss": 0.0002,
      "step": 69170
    },
    {
      "epoch": 7.412407585985214,
      "grad_norm": 0.017311634495854378,
      "learning_rate": 5.175184828029572e-06,
      "loss": 0.0026,
      "step": 69180
    },
    {
      "epoch": 7.413479052823315,
      "grad_norm": 0.0007925779209472239,
      "learning_rate": 5.17304189435337e-06,
      "loss": 0.1762,
      "step": 69190
    },
    {
      "epoch": 7.414550519661416,
      "grad_norm": 0.001305631478317082,
      "learning_rate": 5.170898960677168e-06,
      "loss": 0.271,
      "step": 69200
    },
    {
      "epoch": 7.415621986499517,
      "grad_norm": 0.0006400143029168248,
      "learning_rate": 5.168756027000965e-06,
      "loss": 0.0001,
      "step": 69210
    },
    {
      "epoch": 7.416693453337619,
      "grad_norm": 0.0004933647578582168,
      "learning_rate": 5.1666130933247615e-06,
      "loss": 0.0003,
      "step": 69220
    },
    {
      "epoch": 7.4177649201757205,
      "grad_norm": 0.06323757022619247,
      "learning_rate": 5.164470159648559e-06,
      "loss": 0.3051,
      "step": 69230
    },
    {
      "epoch": 7.418836387013822,
      "grad_norm": 0.0006380789563991129,
      "learning_rate": 5.162327225972357e-06,
      "loss": 0.0005,
      "step": 69240
    },
    {
      "epoch": 7.419907853851924,
      "grad_norm": 0.00036358885699883103,
      "learning_rate": 5.160184292296154e-06,
      "loss": 0.0004,
      "step": 69250
    },
    {
      "epoch": 7.420979320690025,
      "grad_norm": 0.0004015280574094504,
      "learning_rate": 5.158041358619951e-06,
      "loss": 0.0001,
      "step": 69260
    },
    {
      "epoch": 7.422050787528126,
      "grad_norm": 0.00040261592948809266,
      "learning_rate": 5.155898424943748e-06,
      "loss": 0.1223,
      "step": 69270
    },
    {
      "epoch": 7.423122254366227,
      "grad_norm": 0.2754088342189789,
      "learning_rate": 5.153755491267546e-06,
      "loss": 0.0014,
      "step": 69280
    },
    {
      "epoch": 7.424193721204329,
      "grad_norm": 0.00032473893952555954,
      "learning_rate": 5.151612557591343e-06,
      "loss": 0.0002,
      "step": 69290
    },
    {
      "epoch": 7.42526518804243,
      "grad_norm": 0.0003821458958555013,
      "learning_rate": 5.1494696239151395e-06,
      "loss": 0.0001,
      "step": 69300
    },
    {
      "epoch": 7.426336654880531,
      "grad_norm": 0.008717753924429417,
      "learning_rate": 5.147326690238938e-06,
      "loss": 0.1821,
      "step": 69310
    },
    {
      "epoch": 7.427408121718633,
      "grad_norm": 0.03689495846629143,
      "learning_rate": 5.145183756562735e-06,
      "loss": 0.0004,
      "step": 69320
    },
    {
      "epoch": 7.428479588556734,
      "grad_norm": 0.005899704992771149,
      "learning_rate": 5.143040822886532e-06,
      "loss": 0.0009,
      "step": 69330
    },
    {
      "epoch": 7.429551055394835,
      "grad_norm": 0.0032199036795645952,
      "learning_rate": 5.140897889210329e-06,
      "loss": 0.0001,
      "step": 69340
    },
    {
      "epoch": 7.4306225222329365,
      "grad_norm": 0.0008628438226878643,
      "learning_rate": 5.138754955534126e-06,
      "loss": 0.0003,
      "step": 69350
    },
    {
      "epoch": 7.4316939890710385,
      "grad_norm": 0.34214285016059875,
      "learning_rate": 5.1366120218579245e-06,
      "loss": 0.0008,
      "step": 69360
    },
    {
      "epoch": 7.43276545590914,
      "grad_norm": 57.67277526855469,
      "learning_rate": 5.134469088181722e-06,
      "loss": 0.1511,
      "step": 69370
    },
    {
      "epoch": 7.433836922747241,
      "grad_norm": 0.0002683888014871627,
      "learning_rate": 5.132326154505518e-06,
      "loss": 0.0004,
      "step": 69380
    },
    {
      "epoch": 7.434908389585343,
      "grad_norm": 0.004681263118982315,
      "learning_rate": 5.130183220829316e-06,
      "loss": 0.0002,
      "step": 69390
    },
    {
      "epoch": 7.435979856423444,
      "grad_norm": 0.0002399128134129569,
      "learning_rate": 5.128040287153113e-06,
      "loss": 0.0008,
      "step": 69400
    },
    {
      "epoch": 7.437051323261545,
      "grad_norm": 0.015631811693310738,
      "learning_rate": 5.12589735347691e-06,
      "loss": 0.1467,
      "step": 69410
    },
    {
      "epoch": 7.438122790099646,
      "grad_norm": 0.000562916393391788,
      "learning_rate": 5.123754419800707e-06,
      "loss": 0.0001,
      "step": 69420
    },
    {
      "epoch": 7.439194256937748,
      "grad_norm": 0.0057937344536185265,
      "learning_rate": 5.121611486124505e-06,
      "loss": 0.0001,
      "step": 69430
    },
    {
      "epoch": 7.440265723775849,
      "grad_norm": 0.00018610637926030904,
      "learning_rate": 5.1194685524483025e-06,
      "loss": 0.0042,
      "step": 69440
    },
    {
      "epoch": 7.44133719061395,
      "grad_norm": 0.007232287432998419,
      "learning_rate": 5.1173256187721e-06,
      "loss": 0.3691,
      "step": 69450
    },
    {
      "epoch": 7.442408657452052,
      "grad_norm": 0.26212364435195923,
      "learning_rate": 5.115182685095896e-06,
      "loss": 0.0005,
      "step": 69460
    },
    {
      "epoch": 7.443480124290153,
      "grad_norm": 0.001957435393705964,
      "learning_rate": 5.113039751419694e-06,
      "loss": 0.0002,
      "step": 69470
    },
    {
      "epoch": 7.4445515911282545,
      "grad_norm": 0.0067115770652890205,
      "learning_rate": 5.110896817743491e-06,
      "loss": 0.1985,
      "step": 69480
    },
    {
      "epoch": 7.445623057966356,
      "grad_norm": 0.00041199542465619743,
      "learning_rate": 5.108753884067289e-06,
      "loss": 0.0001,
      "step": 69490
    },
    {
      "epoch": 7.446694524804458,
      "grad_norm": 0.004212569445371628,
      "learning_rate": 5.106610950391086e-06,
      "loss": 0.0003,
      "step": 69500
    },
    {
      "epoch": 7.447765991642559,
      "grad_norm": 0.00867092702537775,
      "learning_rate": 5.104468016714883e-06,
      "loss": 0.1824,
      "step": 69510
    },
    {
      "epoch": 7.44883745848066,
      "grad_norm": 0.01429966650903225,
      "learning_rate": 5.1023250830386805e-06,
      "loss": 0.2464,
      "step": 69520
    },
    {
      "epoch": 7.449908925318761,
      "grad_norm": 0.004466772545129061,
      "learning_rate": 5.100182149362478e-06,
      "loss": 0.0008,
      "step": 69530
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 37.269168853759766,
      "learning_rate": 5.098039215686274e-06,
      "loss": 0.0671,
      "step": 69540
    },
    {
      "epoch": 7.452051858994964,
      "grad_norm": 0.006284290459007025,
      "learning_rate": 5.0958962820100725e-06,
      "loss": 0.0001,
      "step": 69550
    },
    {
      "epoch": 7.453123325833065,
      "grad_norm": 0.004071809351444244,
      "learning_rate": 5.09375334833387e-06,
      "loss": 0.0124,
      "step": 69560
    },
    {
      "epoch": 7.454194792671167,
      "grad_norm": 62.48828125,
      "learning_rate": 5.091610414657667e-06,
      "loss": 0.3686,
      "step": 69570
    },
    {
      "epoch": 7.455266259509268,
      "grad_norm": 0.004119847435504198,
      "learning_rate": 5.089467480981464e-06,
      "loss": 0.0,
      "step": 69580
    },
    {
      "epoch": 7.456337726347369,
      "grad_norm": 0.007391422986984253,
      "learning_rate": 5.087324547305261e-06,
      "loss": 0.0004,
      "step": 69590
    },
    {
      "epoch": 7.457409193185471,
      "grad_norm": 0.0002289930562255904,
      "learning_rate": 5.0851816136290585e-06,
      "loss": 0.0001,
      "step": 69600
    },
    {
      "epoch": 7.4584806600235725,
      "grad_norm": 0.0026292302645742893,
      "learning_rate": 5.083038679952857e-06,
      "loss": 0.0001,
      "step": 69610
    },
    {
      "epoch": 7.459552126861674,
      "grad_norm": 0.00025230730534531176,
      "learning_rate": 5.080895746276653e-06,
      "loss": 0.0005,
      "step": 69620
    },
    {
      "epoch": 7.460623593699775,
      "grad_norm": 0.005264445673674345,
      "learning_rate": 5.0787528126004505e-06,
      "loss": 0.0672,
      "step": 69630
    },
    {
      "epoch": 7.461695060537877,
      "grad_norm": 0.00024494860554113984,
      "learning_rate": 5.076609878924248e-06,
      "loss": 0.0001,
      "step": 69640
    },
    {
      "epoch": 7.462766527375978,
      "grad_norm": 0.002758018672466278,
      "learning_rate": 5.074466945248045e-06,
      "loss": 0.3193,
      "step": 69650
    },
    {
      "epoch": 7.463837994214079,
      "grad_norm": 0.0006890647346153855,
      "learning_rate": 5.072324011571842e-06,
      "loss": 0.2752,
      "step": 69660
    },
    {
      "epoch": 7.46490946105218,
      "grad_norm": 0.0002563435409683734,
      "learning_rate": 5.070181077895639e-06,
      "loss": 0.0002,
      "step": 69670
    },
    {
      "epoch": 7.465980927890282,
      "grad_norm": 0.00023187165788840503,
      "learning_rate": 5.068038144219437e-06,
      "loss": 0.0004,
      "step": 69680
    },
    {
      "epoch": 7.467052394728383,
      "grad_norm": 77.17108917236328,
      "learning_rate": 5.065895210543235e-06,
      "loss": 0.199,
      "step": 69690
    },
    {
      "epoch": 7.468123861566484,
      "grad_norm": 0.00018173750140704215,
      "learning_rate": 5.063752276867031e-06,
      "loss": 0.0,
      "step": 69700
    },
    {
      "epoch": 7.469195328404586,
      "grad_norm": 0.00029946115682832897,
      "learning_rate": 5.0616093431908285e-06,
      "loss": 0.0,
      "step": 69710
    },
    {
      "epoch": 7.470266795242687,
      "grad_norm": 0.012360479682683945,
      "learning_rate": 5.059466409514626e-06,
      "loss": 0.1237,
      "step": 69720
    },
    {
      "epoch": 7.471338262080788,
      "grad_norm": 0.0001481914077885449,
      "learning_rate": 5.057323475838424e-06,
      "loss": 0.0255,
      "step": 69730
    },
    {
      "epoch": 7.4724097289188895,
      "grad_norm": 0.0006433696253225207,
      "learning_rate": 5.055180542162221e-06,
      "loss": 0.0003,
      "step": 69740
    },
    {
      "epoch": 7.4734811957569915,
      "grad_norm": 0.00036521960282698274,
      "learning_rate": 5.053037608486018e-06,
      "loss": 0.1555,
      "step": 69750
    },
    {
      "epoch": 7.474552662595093,
      "grad_norm": 0.006942419335246086,
      "learning_rate": 5.050894674809815e-06,
      "loss": 0.0005,
      "step": 69760
    },
    {
      "epoch": 7.475624129433194,
      "grad_norm": 0.0002518207475077361,
      "learning_rate": 5.048751741133613e-06,
      "loss": 0.0011,
      "step": 69770
    },
    {
      "epoch": 7.476695596271296,
      "grad_norm": 0.00022846435604151338,
      "learning_rate": 5.046608807457409e-06,
      "loss": 0.0007,
      "step": 69780
    },
    {
      "epoch": 7.477767063109397,
      "grad_norm": 0.0027755117043852806,
      "learning_rate": 5.0444658737812065e-06,
      "loss": 0.1229,
      "step": 69790
    },
    {
      "epoch": 7.478838529947498,
      "grad_norm": 0.004110364709049463,
      "learning_rate": 5.042322940105005e-06,
      "loss": 0.0001,
      "step": 69800
    },
    {
      "epoch": 7.479909996785599,
      "grad_norm": 0.008848782628774643,
      "learning_rate": 5.040180006428801e-06,
      "loss": 0.0001,
      "step": 69810
    },
    {
      "epoch": 7.480981463623701,
      "grad_norm": 0.00013853427662979811,
      "learning_rate": 5.038037072752599e-06,
      "loss": 0.0001,
      "step": 69820
    },
    {
      "epoch": 7.482052930461802,
      "grad_norm": 0.013545351102948189,
      "learning_rate": 5.035894139076396e-06,
      "loss": 0.0001,
      "step": 69830
    },
    {
      "epoch": 7.483124397299903,
      "grad_norm": 0.008661651983857155,
      "learning_rate": 5.033751205400193e-06,
      "loss": 0.2117,
      "step": 69840
    },
    {
      "epoch": 7.484195864138005,
      "grad_norm": 0.006079333368688822,
      "learning_rate": 5.03160827172399e-06,
      "loss": 0.0,
      "step": 69850
    },
    {
      "epoch": 7.485267330976106,
      "grad_norm": 0.00012927032366860658,
      "learning_rate": 5.029465338047787e-06,
      "loss": 0.1725,
      "step": 69860
    },
    {
      "epoch": 7.4863387978142075,
      "grad_norm": 0.0003362610877957195,
      "learning_rate": 5.027322404371585e-06,
      "loss": 0.2728,
      "step": 69870
    },
    {
      "epoch": 7.487410264652309,
      "grad_norm": 0.0002300608466612175,
      "learning_rate": 5.025179470695383e-06,
      "loss": 0.0,
      "step": 69880
    },
    {
      "epoch": 7.488481731490411,
      "grad_norm": 0.00027956385747529566,
      "learning_rate": 5.023036537019179e-06,
      "loss": 0.0004,
      "step": 69890
    },
    {
      "epoch": 7.489553198328512,
      "grad_norm": 0.015706632286310196,
      "learning_rate": 5.020893603342977e-06,
      "loss": 0.4932,
      "step": 69900
    },
    {
      "epoch": 7.490624665166613,
      "grad_norm": 0.0003353310748934746,
      "learning_rate": 5.018750669666774e-06,
      "loss": 0.0,
      "step": 69910
    },
    {
      "epoch": 7.491696132004715,
      "grad_norm": 0.19371049106121063,
      "learning_rate": 5.016607735990572e-06,
      "loss": 0.0695,
      "step": 69920
    },
    {
      "epoch": 7.492767598842816,
      "grad_norm": 0.0004642754793167114,
      "learning_rate": 5.014464802314369e-06,
      "loss": 0.0017,
      "step": 69930
    },
    {
      "epoch": 7.493839065680917,
      "grad_norm": 0.007886793464422226,
      "learning_rate": 5.012321868638166e-06,
      "loss": 0.0,
      "step": 69940
    },
    {
      "epoch": 7.494910532519018,
      "grad_norm": 25.30455207824707,
      "learning_rate": 5.010178934961963e-06,
      "loss": 0.3276,
      "step": 69950
    },
    {
      "epoch": 7.49598199935712,
      "grad_norm": 0.002600566018372774,
      "learning_rate": 5.008036001285761e-06,
      "loss": 0.0001,
      "step": 69960
    },
    {
      "epoch": 7.497053466195221,
      "grad_norm": 0.0028530543204396963,
      "learning_rate": 5.005893067609557e-06,
      "loss": 0.2133,
      "step": 69970
    },
    {
      "epoch": 7.498124933033322,
      "grad_norm": 0.005335662048310041,
      "learning_rate": 5.003750133933355e-06,
      "loss": 0.0001,
      "step": 69980
    },
    {
      "epoch": 7.499196399871424,
      "grad_norm": 0.004565008450299501,
      "learning_rate": 5.001607200257153e-06,
      "loss": 0.0001,
      "step": 69990
    },
    {
      "epoch": 7.5002678667095255,
      "grad_norm": 0.05033969506621361,
      "learning_rate": 4.999464266580949e-06,
      "loss": 0.271,
      "step": 70000
    },
    {
      "epoch": 7.501339333547627,
      "grad_norm": 0.00032463367097079754,
      "learning_rate": 4.997321332904747e-06,
      "loss": 0.1637,
      "step": 70010
    },
    {
      "epoch": 7.502410800385728,
      "grad_norm": 0.0006186914397403598,
      "learning_rate": 4.995178399228544e-06,
      "loss": 0.0015,
      "step": 70020
    },
    {
      "epoch": 7.50348226722383,
      "grad_norm": 0.007063696626573801,
      "learning_rate": 4.993035465552341e-06,
      "loss": 0.0002,
      "step": 70030
    },
    {
      "epoch": 7.504553734061931,
      "grad_norm": 0.022805072367191315,
      "learning_rate": 4.990892531876139e-06,
      "loss": 0.0001,
      "step": 70040
    },
    {
      "epoch": 7.505625200900032,
      "grad_norm": 0.0028743480797857046,
      "learning_rate": 4.988749598199936e-06,
      "loss": 0.1591,
      "step": 70050
    },
    {
      "epoch": 7.506696667738133,
      "grad_norm": 0.0008882444817572832,
      "learning_rate": 4.9866066645237335e-06,
      "loss": 0.1541,
      "step": 70060
    },
    {
      "epoch": 7.507768134576235,
      "grad_norm": 0.005823719315230846,
      "learning_rate": 4.984463730847531e-06,
      "loss": 0.1388,
      "step": 70070
    },
    {
      "epoch": 7.508839601414336,
      "grad_norm": 0.11185487359762192,
      "learning_rate": 4.982320797171328e-06,
      "loss": 0.0007,
      "step": 70080
    },
    {
      "epoch": 7.509911068252437,
      "grad_norm": 0.003448284463956952,
      "learning_rate": 4.9801778634951255e-06,
      "loss": 0.1804,
      "step": 70090
    },
    {
      "epoch": 7.510982535090539,
      "grad_norm": 0.006975647993385792,
      "learning_rate": 4.978034929818922e-06,
      "loss": 0.0002,
      "step": 70100
    },
    {
      "epoch": 7.51205400192864,
      "grad_norm": 0.002230620477348566,
      "learning_rate": 4.97589199614272e-06,
      "loss": 0.2601,
      "step": 70110
    },
    {
      "epoch": 7.5131254687667415,
      "grad_norm": 0.013915556482970715,
      "learning_rate": 4.973749062466517e-06,
      "loss": 0.0001,
      "step": 70120
    },
    {
      "epoch": 7.5141969356048435,
      "grad_norm": 0.17947135865688324,
      "learning_rate": 4.971606128790314e-06,
      "loss": 0.0004,
      "step": 70130
    },
    {
      "epoch": 7.515268402442945,
      "grad_norm": 0.03126475587487221,
      "learning_rate": 4.9694631951141115e-06,
      "loss": 0.0005,
      "step": 70140
    },
    {
      "epoch": 7.516339869281046,
      "grad_norm": 0.02686791494488716,
      "learning_rate": 4.967320261437909e-06,
      "loss": 0.0001,
      "step": 70150
    },
    {
      "epoch": 7.517411336119147,
      "grad_norm": 0.027587007731199265,
      "learning_rate": 4.965177327761706e-06,
      "loss": 0.2087,
      "step": 70160
    },
    {
      "epoch": 7.518482802957249,
      "grad_norm": 0.0003189408453181386,
      "learning_rate": 4.9630343940855035e-06,
      "loss": 0.0005,
      "step": 70170
    },
    {
      "epoch": 7.51955426979535,
      "grad_norm": 0.008063852787017822,
      "learning_rate": 4.960891460409301e-06,
      "loss": 0.0002,
      "step": 70180
    },
    {
      "epoch": 7.520625736633451,
      "grad_norm": 0.0003141955239698291,
      "learning_rate": 4.958748526733098e-06,
      "loss": 0.0004,
      "step": 70190
    },
    {
      "epoch": 7.521697203471552,
      "grad_norm": 0.00029682237072847784,
      "learning_rate": 4.956605593056895e-06,
      "loss": 0.0002,
      "step": 70200
    },
    {
      "epoch": 7.522768670309654,
      "grad_norm": 0.004356419667601585,
      "learning_rate": 4.954462659380693e-06,
      "loss": 0.6195,
      "step": 70210
    },
    {
      "epoch": 7.523840137147755,
      "grad_norm": 0.005215029697865248,
      "learning_rate": 4.9523197257044895e-06,
      "loss": 0.2808,
      "step": 70220
    },
    {
      "epoch": 7.524911603985856,
      "grad_norm": 0.0008147761109285057,
      "learning_rate": 4.950176792028288e-06,
      "loss": 0.266,
      "step": 70230
    },
    {
      "epoch": 7.525983070823958,
      "grad_norm": 0.0005411489401012659,
      "learning_rate": 4.948033858352084e-06,
      "loss": 0.0032,
      "step": 70240
    },
    {
      "epoch": 7.5270545376620595,
      "grad_norm": 0.00035234264214523137,
      "learning_rate": 4.9458909246758815e-06,
      "loss": 0.0184,
      "step": 70250
    },
    {
      "epoch": 7.528126004500161,
      "grad_norm": 0.02328658103942871,
      "learning_rate": 4.943747990999679e-06,
      "loss": 0.0001,
      "step": 70260
    },
    {
      "epoch": 7.529197471338263,
      "grad_norm": 0.014994681812822819,
      "learning_rate": 4.941605057323476e-06,
      "loss": 0.0018,
      "step": 70270
    },
    {
      "epoch": 7.530268938176364,
      "grad_norm": 0.00838556233793497,
      "learning_rate": 4.939462123647274e-06,
      "loss": 0.0001,
      "step": 70280
    },
    {
      "epoch": 7.531340405014465,
      "grad_norm": 0.0062263477593660355,
      "learning_rate": 4.937319189971071e-06,
      "loss": 0.0002,
      "step": 70290
    },
    {
      "epoch": 7.532411871852566,
      "grad_norm": 1.0251859426498413,
      "learning_rate": 4.935176256294868e-06,
      "loss": 0.3951,
      "step": 70300
    },
    {
      "epoch": 7.533483338690668,
      "grad_norm": 0.0006463266327045858,
      "learning_rate": 4.933033322618666e-06,
      "loss": 0.0002,
      "step": 70310
    },
    {
      "epoch": 7.534554805528769,
      "grad_norm": 0.01827204041182995,
      "learning_rate": 4.930890388942462e-06,
      "loss": 0.2297,
      "step": 70320
    },
    {
      "epoch": 7.53562627236687,
      "grad_norm": 0.0009592912974767387,
      "learning_rate": 4.92874745526626e-06,
      "loss": 0.3879,
      "step": 70330
    },
    {
      "epoch": 7.536697739204971,
      "grad_norm": 0.0013030861737206578,
      "learning_rate": 4.926604521590057e-06,
      "loss": 0.0001,
      "step": 70340
    },
    {
      "epoch": 7.537769206043073,
      "grad_norm": 0.0004906172398477793,
      "learning_rate": 4.924461587913854e-06,
      "loss": 0.2026,
      "step": 70350
    },
    {
      "epoch": 7.538840672881174,
      "grad_norm": 0.009801484644412994,
      "learning_rate": 4.922318654237652e-06,
      "loss": 0.1377,
      "step": 70360
    },
    {
      "epoch": 7.539912139719275,
      "grad_norm": 0.021811461076140404,
      "learning_rate": 4.920175720561449e-06,
      "loss": 0.0001,
      "step": 70370
    },
    {
      "epoch": 7.540983606557377,
      "grad_norm": 0.0011011561146005988,
      "learning_rate": 4.918032786885246e-06,
      "loss": 0.195,
      "step": 70380
    },
    {
      "epoch": 7.5420550733954785,
      "grad_norm": 0.004943836946040392,
      "learning_rate": 4.915889853209044e-06,
      "loss": 0.0004,
      "step": 70390
    },
    {
      "epoch": 7.54312654023358,
      "grad_norm": 0.020102769136428833,
      "learning_rate": 4.913746919532841e-06,
      "loss": 0.0011,
      "step": 70400
    },
    {
      "epoch": 7.544198007071681,
      "grad_norm": 0.0053245085291564465,
      "learning_rate": 4.911603985856638e-06,
      "loss": 0.0006,
      "step": 70410
    },
    {
      "epoch": 7.545269473909783,
      "grad_norm": 0.012991979718208313,
      "learning_rate": 4.909461052180436e-06,
      "loss": 0.1217,
      "step": 70420
    },
    {
      "epoch": 7.546340940747884,
      "grad_norm": 0.011500153690576553,
      "learning_rate": 4.907318118504233e-06,
      "loss": 0.2171,
      "step": 70430
    },
    {
      "epoch": 7.547412407585985,
      "grad_norm": 0.008672598749399185,
      "learning_rate": 4.90517518482803e-06,
      "loss": 0.0002,
      "step": 70440
    },
    {
      "epoch": 7.548483874424086,
      "grad_norm": 0.00044794243876822293,
      "learning_rate": 4.903032251151828e-06,
      "loss": 0.1732,
      "step": 70450
    },
    {
      "epoch": 7.549555341262188,
      "grad_norm": 0.000463460833998397,
      "learning_rate": 4.900889317475624e-06,
      "loss": 0.0002,
      "step": 70460
    },
    {
      "epoch": 7.550626808100289,
      "grad_norm": 0.0004418072639964521,
      "learning_rate": 4.898746383799422e-06,
      "loss": 0.0002,
      "step": 70470
    },
    {
      "epoch": 7.55169827493839,
      "grad_norm": 0.001315078348852694,
      "learning_rate": 4.896603450123219e-06,
      "loss": 0.0005,
      "step": 70480
    },
    {
      "epoch": 7.552769741776492,
      "grad_norm": 101.38386535644531,
      "learning_rate": 4.894460516447016e-06,
      "loss": 0.2158,
      "step": 70490
    },
    {
      "epoch": 7.553841208614593,
      "grad_norm": 0.06340771168470383,
      "learning_rate": 4.892317582770814e-06,
      "loss": 0.2588,
      "step": 70500
    },
    {
      "epoch": 7.5549126754526945,
      "grad_norm": 0.00619063526391983,
      "learning_rate": 4.890174649094611e-06,
      "loss": 0.0001,
      "step": 70510
    },
    {
      "epoch": 7.5559841422907965,
      "grad_norm": 0.002402308862656355,
      "learning_rate": 4.8880317154184084e-06,
      "loss": 0.0001,
      "step": 70520
    },
    {
      "epoch": 7.557055609128898,
      "grad_norm": 0.005598671734333038,
      "learning_rate": 4.885888781742206e-06,
      "loss": 0.0004,
      "step": 70530
    },
    {
      "epoch": 7.558127075966999,
      "grad_norm": 0.0035719238221645355,
      "learning_rate": 4.883745848066002e-06,
      "loss": 0.0001,
      "step": 70540
    },
    {
      "epoch": 7.5591985428051,
      "grad_norm": 0.000515853869728744,
      "learning_rate": 4.8816029143898005e-06,
      "loss": 0.0002,
      "step": 70550
    },
    {
      "epoch": 7.560270009643202,
      "grad_norm": 0.015018165111541748,
      "learning_rate": 4.879459980713597e-06,
      "loss": 0.0007,
      "step": 70560
    },
    {
      "epoch": 7.561341476481303,
      "grad_norm": 0.006068363785743713,
      "learning_rate": 4.877317047037395e-06,
      "loss": 0.2882,
      "step": 70570
    },
    {
      "epoch": 7.562412943319404,
      "grad_norm": 0.013079964555799961,
      "learning_rate": 4.875174113361192e-06,
      "loss": 0.0006,
      "step": 70580
    },
    {
      "epoch": 7.563484410157505,
      "grad_norm": 40.741485595703125,
      "learning_rate": 4.873031179684989e-06,
      "loss": 0.5483,
      "step": 70590
    },
    {
      "epoch": 7.564555876995607,
      "grad_norm": 0.013413215056061745,
      "learning_rate": 4.8708882460087864e-06,
      "loss": 0.0012,
      "step": 70600
    },
    {
      "epoch": 7.565627343833708,
      "grad_norm": 0.018563242629170418,
      "learning_rate": 4.868745312332584e-06,
      "loss": 0.0013,
      "step": 70610
    },
    {
      "epoch": 7.566698810671809,
      "grad_norm": 0.008151402696967125,
      "learning_rate": 4.866602378656381e-06,
      "loss": 0.0041,
      "step": 70620
    },
    {
      "epoch": 7.567770277509911,
      "grad_norm": 0.000810145924333483,
      "learning_rate": 4.8644594449801785e-06,
      "loss": 0.0001,
      "step": 70630
    },
    {
      "epoch": 7.5688417443480125,
      "grad_norm": 0.00049545185174793,
      "learning_rate": 4.862316511303976e-06,
      "loss": 0.0003,
      "step": 70640
    },
    {
      "epoch": 7.569913211186114,
      "grad_norm": 0.008390331640839577,
      "learning_rate": 4.860173577627773e-06,
      "loss": 0.007,
      "step": 70650
    },
    {
      "epoch": 7.570984678024216,
      "grad_norm": 0.0066151926293969154,
      "learning_rate": 4.85803064395157e-06,
      "loss": 0.0001,
      "step": 70660
    },
    {
      "epoch": 7.572056144862317,
      "grad_norm": 0.0006725521525368094,
      "learning_rate": 4.855887710275368e-06,
      "loss": 0.0001,
      "step": 70670
    },
    {
      "epoch": 7.573127611700418,
      "grad_norm": 0.007047136779874563,
      "learning_rate": 4.8537447765991644e-06,
      "loss": 0.0002,
      "step": 70680
    },
    {
      "epoch": 7.574199078538519,
      "grad_norm": 0.17605718970298767,
      "learning_rate": 4.851601842922962e-06,
      "loss": 0.0007,
      "step": 70690
    },
    {
      "epoch": 7.575270545376621,
      "grad_norm": 21.258697509765625,
      "learning_rate": 4.849458909246759e-06,
      "loss": 0.0016,
      "step": 70700
    },
    {
      "epoch": 7.576342012214722,
      "grad_norm": 0.0027275290340185165,
      "learning_rate": 4.8473159755705565e-06,
      "loss": 0.0001,
      "step": 70710
    },
    {
      "epoch": 7.577413479052823,
      "grad_norm": 0.014795450493693352,
      "learning_rate": 4.845173041894354e-06,
      "loss": 0.0003,
      "step": 70720
    },
    {
      "epoch": 7.578484945890924,
      "grad_norm": 0.008583604358136654,
      "learning_rate": 4.84303010821815e-06,
      "loss": 0.001,
      "step": 70730
    },
    {
      "epoch": 7.579556412729026,
      "grad_norm": 0.2165127396583557,
      "learning_rate": 4.8408871745419486e-06,
      "loss": 0.0007,
      "step": 70740
    },
    {
      "epoch": 7.580627879567127,
      "grad_norm": 0.022521894425153732,
      "learning_rate": 4.838744240865745e-06,
      "loss": 0.0003,
      "step": 70750
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 0.005630606785416603,
      "learning_rate": 4.836601307189543e-06,
      "loss": 0.0001,
      "step": 70760
    },
    {
      "epoch": 7.5827708132433305,
      "grad_norm": 0.00044913336751051247,
      "learning_rate": 4.83445837351334e-06,
      "loss": 0.0001,
      "step": 70770
    },
    {
      "epoch": 7.583842280081432,
      "grad_norm": 0.07270769774913788,
      "learning_rate": 4.832315439837137e-06,
      "loss": 0.0003,
      "step": 70780
    },
    {
      "epoch": 7.584913746919533,
      "grad_norm": 0.015893902629613876,
      "learning_rate": 4.8301725061609345e-06,
      "loss": 0.0002,
      "step": 70790
    },
    {
      "epoch": 7.585985213757635,
      "grad_norm": 0.00023518067609984428,
      "learning_rate": 4.828029572484732e-06,
      "loss": 0.1983,
      "step": 70800
    },
    {
      "epoch": 7.587056680595736,
      "grad_norm": 0.00032478393404744565,
      "learning_rate": 4.825886638808529e-06,
      "loss": 0.1482,
      "step": 70810
    },
    {
      "epoch": 7.588128147433837,
      "grad_norm": 14.949795722961426,
      "learning_rate": 4.8237437051323266e-06,
      "loss": 0.2692,
      "step": 70820
    },
    {
      "epoch": 7.589199614271938,
      "grad_norm": 0.013869527727365494,
      "learning_rate": 4.821600771456124e-06,
      "loss": 0.5118,
      "step": 70830
    },
    {
      "epoch": 7.59027108111004,
      "grad_norm": 0.004246072843670845,
      "learning_rate": 4.819457837779921e-06,
      "loss": 0.0001,
      "step": 70840
    },
    {
      "epoch": 7.591342547948141,
      "grad_norm": 5.405339241027832,
      "learning_rate": 4.817314904103718e-06,
      "loss": 0.0032,
      "step": 70850
    },
    {
      "epoch": 7.592414014786242,
      "grad_norm": 0.0017700616735965014,
      "learning_rate": 4.815171970427516e-06,
      "loss": 0.0004,
      "step": 70860
    },
    {
      "epoch": 7.593485481624343,
      "grad_norm": 0.005002254620194435,
      "learning_rate": 4.8130290367513125e-06,
      "loss": 0.0003,
      "step": 70870
    },
    {
      "epoch": 7.594556948462445,
      "grad_norm": 0.007326973602175713,
      "learning_rate": 4.81088610307511e-06,
      "loss": 0.2174,
      "step": 70880
    },
    {
      "epoch": 7.595628415300546,
      "grad_norm": 0.0018813546048477292,
      "learning_rate": 4.808743169398907e-06,
      "loss": 0.1829,
      "step": 70890
    },
    {
      "epoch": 7.5966998821386476,
      "grad_norm": 0.009421775117516518,
      "learning_rate": 4.8066002357227046e-06,
      "loss": 0.0003,
      "step": 70900
    },
    {
      "epoch": 7.5977713489767496,
      "grad_norm": 0.012075661681592464,
      "learning_rate": 4.804457302046502e-06,
      "loss": 0.1125,
      "step": 70910
    },
    {
      "epoch": 7.598842815814851,
      "grad_norm": 0.19107554852962494,
      "learning_rate": 4.802314368370299e-06,
      "loss": 0.0004,
      "step": 70920
    },
    {
      "epoch": 7.599914282652952,
      "grad_norm": 0.2253609597682953,
      "learning_rate": 4.800171434694097e-06,
      "loss": 0.2556,
      "step": 70930
    },
    {
      "epoch": 7.600985749491053,
      "grad_norm": 0.0006300212698988616,
      "learning_rate": 4.798028501017894e-06,
      "loss": 0.013,
      "step": 70940
    },
    {
      "epoch": 7.602057216329155,
      "grad_norm": 0.0054797884076833725,
      "learning_rate": 4.795885567341691e-06,
      "loss": 0.0004,
      "step": 70950
    },
    {
      "epoch": 7.603128683167256,
      "grad_norm": 0.008911775425076485,
      "learning_rate": 4.793742633665489e-06,
      "loss": 0.0001,
      "step": 70960
    },
    {
      "epoch": 7.604200150005357,
      "grad_norm": 0.0004683800507336855,
      "learning_rate": 4.791599699989285e-06,
      "loss": 0.0003,
      "step": 70970
    },
    {
      "epoch": 7.605271616843458,
      "grad_norm": 0.0006662100786343217,
      "learning_rate": 4.789456766313083e-06,
      "loss": 0.0003,
      "step": 70980
    },
    {
      "epoch": 7.60634308368156,
      "grad_norm": 0.006720489822328091,
      "learning_rate": 4.78731383263688e-06,
      "loss": 0.0012,
      "step": 70990
    },
    {
      "epoch": 7.607414550519661,
      "grad_norm": 0.01317937858402729,
      "learning_rate": 4.785170898960677e-06,
      "loss": 0.0002,
      "step": 71000
    },
    {
      "epoch": 7.608486017357762,
      "grad_norm": 0.006590700708329678,
      "learning_rate": 4.783027965284475e-06,
      "loss": 0.1419,
      "step": 71010
    },
    {
      "epoch": 7.609557484195864,
      "grad_norm": 0.00041152103221975267,
      "learning_rate": 4.780885031608272e-06,
      "loss": 0.0003,
      "step": 71020
    },
    {
      "epoch": 7.6106289510339655,
      "grad_norm": 0.08530564606189728,
      "learning_rate": 4.778742097932069e-06,
      "loss": 0.0004,
      "step": 71030
    },
    {
      "epoch": 7.611700417872067,
      "grad_norm": 0.002396299270913005,
      "learning_rate": 4.776599164255867e-06,
      "loss": 0.0001,
      "step": 71040
    },
    {
      "epoch": 7.612771884710169,
      "grad_norm": 0.0003163699002470821,
      "learning_rate": 4.774456230579664e-06,
      "loss": 0.0005,
      "step": 71050
    },
    {
      "epoch": 7.61384335154827,
      "grad_norm": 0.004484544508159161,
      "learning_rate": 4.772313296903461e-06,
      "loss": 0.0017,
      "step": 71060
    },
    {
      "epoch": 7.614914818386371,
      "grad_norm": 0.0070939138531684875,
      "learning_rate": 4.770170363227259e-06,
      "loss": 0.0003,
      "step": 71070
    },
    {
      "epoch": 7.615986285224472,
      "grad_norm": 0.0032842671498656273,
      "learning_rate": 4.768027429551056e-06,
      "loss": 0.0001,
      "step": 71080
    },
    {
      "epoch": 7.617057752062574,
      "grad_norm": 0.0003212016017641872,
      "learning_rate": 4.765884495874853e-06,
      "loss": 0.0002,
      "step": 71090
    },
    {
      "epoch": 7.618129218900675,
      "grad_norm": 0.024695558473467827,
      "learning_rate": 4.763741562198651e-06,
      "loss": 0.0002,
      "step": 71100
    },
    {
      "epoch": 7.619200685738776,
      "grad_norm": 0.004821386653929949,
      "learning_rate": 4.761598628522447e-06,
      "loss": 0.2687,
      "step": 71110
    },
    {
      "epoch": 7.620272152576877,
      "grad_norm": 0.004712184425443411,
      "learning_rate": 4.759455694846245e-06,
      "loss": 0.1537,
      "step": 71120
    },
    {
      "epoch": 7.621343619414979,
      "grad_norm": 0.0002659016172401607,
      "learning_rate": 4.757312761170042e-06,
      "loss": 0.0005,
      "step": 71130
    },
    {
      "epoch": 7.62241508625308,
      "grad_norm": 34.236488342285156,
      "learning_rate": 4.755169827493839e-06,
      "loss": 0.2971,
      "step": 71140
    },
    {
      "epoch": 7.6234865530911815,
      "grad_norm": 0.003579714335501194,
      "learning_rate": 4.753026893817637e-06,
      "loss": 0.179,
      "step": 71150
    },
    {
      "epoch": 7.6245580199292835,
      "grad_norm": 209.3116455078125,
      "learning_rate": 4.750883960141434e-06,
      "loss": 0.4,
      "step": 71160
    },
    {
      "epoch": 7.625629486767385,
      "grad_norm": 0.0055923182517290115,
      "learning_rate": 4.7487410264652315e-06,
      "loss": 0.2105,
      "step": 71170
    },
    {
      "epoch": 7.626700953605486,
      "grad_norm": 0.004853704944252968,
      "learning_rate": 4.746598092789029e-06,
      "loss": 0.0005,
      "step": 71180
    },
    {
      "epoch": 7.627772420443588,
      "grad_norm": 0.007459807675331831,
      "learning_rate": 4.744455159112825e-06,
      "loss": 0.0143,
      "step": 71190
    },
    {
      "epoch": 7.628843887281689,
      "grad_norm": 0.006047169212251902,
      "learning_rate": 4.7423122254366236e-06,
      "loss": 0.0014,
      "step": 71200
    },
    {
      "epoch": 7.62991535411979,
      "grad_norm": 0.004688797052949667,
      "learning_rate": 4.74016929176042e-06,
      "loss": 0.0002,
      "step": 71210
    },
    {
      "epoch": 7.630986820957891,
      "grad_norm": 0.00041382404742762446,
      "learning_rate": 4.738026358084218e-06,
      "loss": 0.0005,
      "step": 71220
    },
    {
      "epoch": 7.632058287795993,
      "grad_norm": 0.005675130058079958,
      "learning_rate": 4.735883424408015e-06,
      "loss": 0.0003,
      "step": 71230
    },
    {
      "epoch": 7.633129754634094,
      "grad_norm": 0.004320634063333273,
      "learning_rate": 4.733740490731812e-06,
      "loss": 0.0001,
      "step": 71240
    },
    {
      "epoch": 7.634201221472195,
      "grad_norm": 0.010162940248847008,
      "learning_rate": 4.7315975570556095e-06,
      "loss": 0.2543,
      "step": 71250
    },
    {
      "epoch": 7.635272688310296,
      "grad_norm": 0.00027884941664524376,
      "learning_rate": 4.729454623379407e-06,
      "loss": 0.0641,
      "step": 71260
    },
    {
      "epoch": 7.636344155148398,
      "grad_norm": 0.007101434748619795,
      "learning_rate": 4.727311689703204e-06,
      "loss": 0.1684,
      "step": 71270
    },
    {
      "epoch": 7.6374156219864995,
      "grad_norm": 0.00019176762725692242,
      "learning_rate": 4.7251687560270016e-06,
      "loss": 0.3433,
      "step": 71280
    },
    {
      "epoch": 7.638487088824601,
      "grad_norm": 0.007064762059599161,
      "learning_rate": 4.723025822350799e-06,
      "loss": 0.3252,
      "step": 71290
    },
    {
      "epoch": 7.639558555662703,
      "grad_norm": 0.0009253707830794156,
      "learning_rate": 4.720882888674596e-06,
      "loss": 0.0003,
      "step": 71300
    },
    {
      "epoch": 7.640630022500804,
      "grad_norm": 0.0003648698912002146,
      "learning_rate": 4.718739954998393e-06,
      "loss": 0.0004,
      "step": 71310
    },
    {
      "epoch": 7.641701489338905,
      "grad_norm": 0.020901355892419815,
      "learning_rate": 4.716597021322191e-06,
      "loss": 0.0003,
      "step": 71320
    },
    {
      "epoch": 7.642772956177007,
      "grad_norm": 0.0008154298993758857,
      "learning_rate": 4.7144540876459875e-06,
      "loss": 0.002,
      "step": 71330
    },
    {
      "epoch": 7.643844423015108,
      "grad_norm": 0.00039038751856423914,
      "learning_rate": 4.712311153969785e-06,
      "loss": 0.0001,
      "step": 71340
    },
    {
      "epoch": 7.644915889853209,
      "grad_norm": 0.0075879208743572235,
      "learning_rate": 4.710168220293582e-06,
      "loss": 0.0007,
      "step": 71350
    },
    {
      "epoch": 7.64598735669131,
      "grad_norm": 0.2326493114233017,
      "learning_rate": 4.7080252866173795e-06,
      "loss": 0.0003,
      "step": 71360
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 0.017224548384547234,
      "learning_rate": 4.705882352941177e-06,
      "loss": 0.0027,
      "step": 71370
    },
    {
      "epoch": 7.648130290367513,
      "grad_norm": 0.011499490588903427,
      "learning_rate": 4.703739419264974e-06,
      "loss": 0.0001,
      "step": 71380
    },
    {
      "epoch": 7.649201757205614,
      "grad_norm": 0.00838179886341095,
      "learning_rate": 4.701596485588772e-06,
      "loss": 0.2166,
      "step": 71390
    },
    {
      "epoch": 7.6502732240437155,
      "grad_norm": 0.012557831592857838,
      "learning_rate": 4.699453551912569e-06,
      "loss": 0.0001,
      "step": 71400
    },
    {
      "epoch": 7.6513446908818175,
      "grad_norm": 0.0664888396859169,
      "learning_rate": 4.697310618236366e-06,
      "loss": 0.2199,
      "step": 71410
    },
    {
      "epoch": 7.652416157719919,
      "grad_norm": 0.06038277596235275,
      "learning_rate": 4.695167684560164e-06,
      "loss": 0.0002,
      "step": 71420
    },
    {
      "epoch": 7.65348762455802,
      "grad_norm": 0.0003736523212864995,
      "learning_rate": 4.69302475088396e-06,
      "loss": 0.0006,
      "step": 71430
    },
    {
      "epoch": 7.654559091396122,
      "grad_norm": 1.0879368782043457,
      "learning_rate": 4.690881817207758e-06,
      "loss": 0.0003,
      "step": 71440
    },
    {
      "epoch": 7.655630558234223,
      "grad_norm": 0.004847569856792688,
      "learning_rate": 4.688738883531555e-06,
      "loss": 0.0003,
      "step": 71450
    },
    {
      "epoch": 7.656702025072324,
      "grad_norm": 40.8001594543457,
      "learning_rate": 4.686595949855352e-06,
      "loss": 0.3306,
      "step": 71460
    },
    {
      "epoch": 7.657773491910425,
      "grad_norm": 0.0029395113233476877,
      "learning_rate": 4.68445301617915e-06,
      "loss": 0.0003,
      "step": 71470
    },
    {
      "epoch": 7.658844958748527,
      "grad_norm": 0.08478810638189316,
      "learning_rate": 4.682310082502947e-06,
      "loss": 0.0162,
      "step": 71480
    },
    {
      "epoch": 7.659916425586628,
      "grad_norm": 0.00017838407075032592,
      "learning_rate": 4.680167148826744e-06,
      "loss": 0.2539,
      "step": 71490
    },
    {
      "epoch": 7.660987892424729,
      "grad_norm": 0.00449698930606246,
      "learning_rate": 4.678024215150542e-06,
      "loss": 0.0007,
      "step": 71500
    },
    {
      "epoch": 7.66205935926283,
      "grad_norm": 0.0005001529934816062,
      "learning_rate": 4.675881281474339e-06,
      "loss": 0.0001,
      "step": 71510
    },
    {
      "epoch": 7.663130826100932,
      "grad_norm": 0.004005546681582928,
      "learning_rate": 4.673738347798136e-06,
      "loss": 0.0989,
      "step": 71520
    },
    {
      "epoch": 7.664202292939033,
      "grad_norm": 0.004572597332298756,
      "learning_rate": 4.671595414121933e-06,
      "loss": 0.0043,
      "step": 71530
    },
    {
      "epoch": 7.6652737597771345,
      "grad_norm": 0.000319395971018821,
      "learning_rate": 4.669452480445731e-06,
      "loss": 0.0002,
      "step": 71540
    },
    {
      "epoch": 7.6663452266152365,
      "grad_norm": 0.00021060070139355958,
      "learning_rate": 4.667309546769528e-06,
      "loss": 0.0175,
      "step": 71550
    },
    {
      "epoch": 7.667416693453338,
      "grad_norm": 0.00020245308405719697,
      "learning_rate": 4.665166613093326e-06,
      "loss": 0.0002,
      "step": 71560
    },
    {
      "epoch": 7.668488160291439,
      "grad_norm": 0.0008043396519497037,
      "learning_rate": 4.663023679417122e-06,
      "loss": 0.0002,
      "step": 71570
    },
    {
      "epoch": 7.669559627129541,
      "grad_norm": 0.004014848731458187,
      "learning_rate": 4.66088074574092e-06,
      "loss": 0.1922,
      "step": 71580
    },
    {
      "epoch": 7.670631093967642,
      "grad_norm": 0.008693111129105091,
      "learning_rate": 4.658737812064717e-06,
      "loss": 0.0062,
      "step": 71590
    },
    {
      "epoch": 7.671702560805743,
      "grad_norm": 0.005619732663035393,
      "learning_rate": 4.656594878388514e-06,
      "loss": 0.0001,
      "step": 71600
    },
    {
      "epoch": 7.672774027643844,
      "grad_norm": 0.008499378338456154,
      "learning_rate": 4.654451944712312e-06,
      "loss": 0.0001,
      "step": 71610
    },
    {
      "epoch": 7.673845494481946,
      "grad_norm": 0.601636528968811,
      "learning_rate": 4.652309011036108e-06,
      "loss": 0.0005,
      "step": 71620
    },
    {
      "epoch": 7.674916961320047,
      "grad_norm": 0.007096822839230299,
      "learning_rate": 4.6501660773599065e-06,
      "loss": 0.0001,
      "step": 71630
    },
    {
      "epoch": 7.675988428158148,
      "grad_norm": 0.00013413232227321714,
      "learning_rate": 4.648023143683703e-06,
      "loss": 0.0001,
      "step": 71640
    },
    {
      "epoch": 7.677059894996249,
      "grad_norm": 0.0001872258580988273,
      "learning_rate": 4.6458802100075e-06,
      "loss": 0.2048,
      "step": 71650
    },
    {
      "epoch": 7.678131361834351,
      "grad_norm": 0.0001472669537179172,
      "learning_rate": 4.643737276331298e-06,
      "loss": 0.0001,
      "step": 71660
    },
    {
      "epoch": 7.6792028286724525,
      "grad_norm": 0.0037330405320972204,
      "learning_rate": 4.641594342655095e-06,
      "loss": 0.0005,
      "step": 71670
    },
    {
      "epoch": 7.680274295510554,
      "grad_norm": 3.0583338737487793,
      "learning_rate": 4.639451408978892e-06,
      "loss": 0.0008,
      "step": 71680
    },
    {
      "epoch": 7.681345762348656,
      "grad_norm": 0.26473531126976013,
      "learning_rate": 4.63730847530269e-06,
      "loss": 0.1638,
      "step": 71690
    },
    {
      "epoch": 7.682417229186757,
      "grad_norm": 0.00021934896358288825,
      "learning_rate": 4.635165541626487e-06,
      "loss": 0.0381,
      "step": 71700
    },
    {
      "epoch": 7.683488696024858,
      "grad_norm": 0.0037048400845378637,
      "learning_rate": 4.6330226079502845e-06,
      "loss": 0.2997,
      "step": 71710
    },
    {
      "epoch": 7.68456016286296,
      "grad_norm": 33.1903076171875,
      "learning_rate": 4.630879674274081e-06,
      "loss": 0.1818,
      "step": 71720
    },
    {
      "epoch": 7.685631629701061,
      "grad_norm": 0.0005272197304293513,
      "learning_rate": 4.628736740597879e-06,
      "loss": 0.0067,
      "step": 71730
    },
    {
      "epoch": 7.686703096539162,
      "grad_norm": 0.00034078891621902585,
      "learning_rate": 4.626593806921676e-06,
      "loss": 0.0002,
      "step": 71740
    },
    {
      "epoch": 7.687774563377263,
      "grad_norm": 0.011065367609262466,
      "learning_rate": 4.624450873245474e-06,
      "loss": 0.0004,
      "step": 71750
    },
    {
      "epoch": 7.688846030215365,
      "grad_norm": 0.20982593297958374,
      "learning_rate": 4.62230793956927e-06,
      "loss": 0.001,
      "step": 71760
    },
    {
      "epoch": 7.689917497053466,
      "grad_norm": 84.72209930419922,
      "learning_rate": 4.620165005893068e-06,
      "loss": 0.1495,
      "step": 71770
    },
    {
      "epoch": 7.690988963891567,
      "grad_norm": 0.00011138958507217467,
      "learning_rate": 4.618022072216865e-06,
      "loss": 0.0,
      "step": 71780
    },
    {
      "epoch": 7.6920604307296685,
      "grad_norm": 0.0001455576129956171,
      "learning_rate": 4.6158791385406625e-06,
      "loss": 0.0001,
      "step": 71790
    },
    {
      "epoch": 7.6931318975677705,
      "grad_norm": 0.00012043065362377092,
      "learning_rate": 4.61373620486446e-06,
      "loss": 0.0,
      "step": 71800
    },
    {
      "epoch": 7.694203364405872,
      "grad_norm": 0.00011090022599091753,
      "learning_rate": 4.611593271188257e-06,
      "loss": 0.0,
      "step": 71810
    },
    {
      "epoch": 7.695274831243973,
      "grad_norm": 0.005252852104604244,
      "learning_rate": 4.6094503375120545e-06,
      "loss": 0.0002,
      "step": 71820
    },
    {
      "epoch": 7.696346298082075,
      "grad_norm": 0.002069453475996852,
      "learning_rate": 4.607307403835852e-06,
      "loss": 0.0001,
      "step": 71830
    },
    {
      "epoch": 7.697417764920176,
      "grad_norm": 17.838605880737305,
      "learning_rate": 4.605164470159648e-06,
      "loss": 0.1958,
      "step": 71840
    },
    {
      "epoch": 7.698489231758277,
      "grad_norm": 0.00017009132716339082,
      "learning_rate": 4.603021536483447e-06,
      "loss": 0.0007,
      "step": 71850
    },
    {
      "epoch": 7.699560698596379,
      "grad_norm": 0.0039390986785292625,
      "learning_rate": 4.600878602807243e-06,
      "loss": 0.1511,
      "step": 71860
    },
    {
      "epoch": 7.70063216543448,
      "grad_norm": 0.00012640786007978022,
      "learning_rate": 4.5987356691310405e-06,
      "loss": 0.2315,
      "step": 71870
    },
    {
      "epoch": 7.701703632272581,
      "grad_norm": 0.009580380283296108,
      "learning_rate": 4.596592735454838e-06,
      "loss": 0.0833,
      "step": 71880
    },
    {
      "epoch": 7.702775099110682,
      "grad_norm": 596.8047485351562,
      "learning_rate": 4.594449801778635e-06,
      "loss": 0.2375,
      "step": 71890
    },
    {
      "epoch": 7.703846565948784,
      "grad_norm": 0.00020654259424190968,
      "learning_rate": 4.5923068681024325e-06,
      "loss": 0.0001,
      "step": 71900
    },
    {
      "epoch": 7.704918032786885,
      "grad_norm": 0.002930181799456477,
      "learning_rate": 4.59016393442623e-06,
      "loss": 0.2715,
      "step": 71910
    },
    {
      "epoch": 7.7059894996249865,
      "grad_norm": 0.4746778905391693,
      "learning_rate": 4.588021000750027e-06,
      "loss": 0.3673,
      "step": 71920
    },
    {
      "epoch": 7.707060966463088,
      "grad_norm": 0.023395519703626633,
      "learning_rate": 4.585878067073825e-06,
      "loss": 0.0001,
      "step": 71930
    },
    {
      "epoch": 7.70813243330119,
      "grad_norm": 27.726774215698242,
      "learning_rate": 4.583735133397622e-06,
      "loss": 0.5331,
      "step": 71940
    },
    {
      "epoch": 7.709203900139291,
      "grad_norm": 157.70703125,
      "learning_rate": 4.581592199721419e-06,
      "loss": 0.0892,
      "step": 71950
    },
    {
      "epoch": 7.710275366977392,
      "grad_norm": 0.002072744769975543,
      "learning_rate": 4.579449266045216e-06,
      "loss": 0.0001,
      "step": 71960
    },
    {
      "epoch": 7.711346833815494,
      "grad_norm": 0.00016361674352083355,
      "learning_rate": 4.577306332369014e-06,
      "loss": 0.0179,
      "step": 71970
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 0.0001658536057220772,
      "learning_rate": 4.5751633986928105e-06,
      "loss": 0.0002,
      "step": 71980
    },
    {
      "epoch": 7.713489767491696,
      "grad_norm": 0.008691485039889812,
      "learning_rate": 4.573020465016608e-06,
      "loss": 0.2698,
      "step": 71990
    },
    {
      "epoch": 7.714561234329797,
      "grad_norm": 0.03460705652832985,
      "learning_rate": 4.570877531340405e-06,
      "loss": 0.0002,
      "step": 72000
    },
    {
      "epoch": 7.715632701167899,
      "grad_norm": 52.7399787902832,
      "learning_rate": 4.568734597664203e-06,
      "loss": 0.2604,
      "step": 72010
    },
    {
      "epoch": 7.716704168006,
      "grad_norm": 0.00040661616367287934,
      "learning_rate": 4.566591663988e-06,
      "loss": 0.0956,
      "step": 72020
    },
    {
      "epoch": 7.717775634844101,
      "grad_norm": 0.00032445567194372416,
      "learning_rate": 4.564448730311797e-06,
      "loss": 0.0437,
      "step": 72030
    },
    {
      "epoch": 7.7188471016822024,
      "grad_norm": 3.0104002952575684,
      "learning_rate": 4.562305796635595e-06,
      "loss": 0.004,
      "step": 72040
    },
    {
      "epoch": 7.7199185685203044,
      "grad_norm": 0.0010860124602913857,
      "learning_rate": 4.560162862959392e-06,
      "loss": 0.1914,
      "step": 72050
    },
    {
      "epoch": 7.720990035358406,
      "grad_norm": 39.02225112915039,
      "learning_rate": 4.5580199292831885e-06,
      "loss": 0.1542,
      "step": 72060
    },
    {
      "epoch": 7.722061502196507,
      "grad_norm": 0.00020346028031781316,
      "learning_rate": 4.555876995606987e-06,
      "loss": 0.0006,
      "step": 72070
    },
    {
      "epoch": 7.723132969034609,
      "grad_norm": 0.00022987675038166344,
      "learning_rate": 4.553734061930783e-06,
      "loss": 0.0003,
      "step": 72080
    },
    {
      "epoch": 7.72420443587271,
      "grad_norm": 0.0075949253514409065,
      "learning_rate": 4.5515911282545814e-06,
      "loss": 0.1534,
      "step": 72090
    },
    {
      "epoch": 7.725275902710811,
      "grad_norm": 0.009316621348261833,
      "learning_rate": 4.549448194578378e-06,
      "loss": 0.0033,
      "step": 72100
    },
    {
      "epoch": 7.726347369548913,
      "grad_norm": 0.006090137176215649,
      "learning_rate": 4.547305260902175e-06,
      "loss": 0.0003,
      "step": 72110
    },
    {
      "epoch": 7.727418836387014,
      "grad_norm": 0.00022464460926130414,
      "learning_rate": 4.545162327225973e-06,
      "loss": 0.0001,
      "step": 72120
    },
    {
      "epoch": 7.728490303225115,
      "grad_norm": 0.01737905479967594,
      "learning_rate": 4.54301939354977e-06,
      "loss": 0.2796,
      "step": 72130
    },
    {
      "epoch": 7.729561770063216,
      "grad_norm": 0.02321944572031498,
      "learning_rate": 4.540876459873567e-06,
      "loss": 0.0001,
      "step": 72140
    },
    {
      "epoch": 7.730633236901318,
      "grad_norm": 0.00022320412972476333,
      "learning_rate": 4.538733526197365e-06,
      "loss": 0.0023,
      "step": 72150
    },
    {
      "epoch": 7.731704703739419,
      "grad_norm": 0.014312739484012127,
      "learning_rate": 4.536590592521162e-06,
      "loss": 0.0003,
      "step": 72160
    },
    {
      "epoch": 7.73277617057752,
      "grad_norm": 0.004875728860497475,
      "learning_rate": 4.5344476588449594e-06,
      "loss": 0.0003,
      "step": 72170
    },
    {
      "epoch": 7.7338476374156215,
      "grad_norm": 0.00017152818327303976,
      "learning_rate": 4.532304725168756e-06,
      "loss": 0.2708,
      "step": 72180
    },
    {
      "epoch": 7.7349191042537235,
      "grad_norm": 0.03683067485690117,
      "learning_rate": 4.530161791492554e-06,
      "loss": 0.1402,
      "step": 72190
    },
    {
      "epoch": 7.735990571091825,
      "grad_norm": 0.056309401988983154,
      "learning_rate": 4.528018857816351e-06,
      "loss": 0.0005,
      "step": 72200
    },
    {
      "epoch": 7.737062037929926,
      "grad_norm": 512.0479125976562,
      "learning_rate": 4.525875924140148e-06,
      "loss": 0.0568,
      "step": 72210
    },
    {
      "epoch": 7.738133504768028,
      "grad_norm": 0.011222385801374912,
      "learning_rate": 4.523732990463945e-06,
      "loss": 0.1674,
      "step": 72220
    },
    {
      "epoch": 7.739204971606129,
      "grad_norm": 0.0002796199987642467,
      "learning_rate": 4.521590056787743e-06,
      "loss": 0.0005,
      "step": 72230
    },
    {
      "epoch": 7.74027643844423,
      "grad_norm": 0.032482732087373734,
      "learning_rate": 4.51944712311154e-06,
      "loss": 0.0001,
      "step": 72240
    },
    {
      "epoch": 7.741347905282332,
      "grad_norm": 0.007386325392872095,
      "learning_rate": 4.5173041894353374e-06,
      "loss": 0.1295,
      "step": 72250
    },
    {
      "epoch": 7.742419372120433,
      "grad_norm": 0.005271021276712418,
      "learning_rate": 4.515161255759135e-06,
      "loss": 0.0005,
      "step": 72260
    },
    {
      "epoch": 7.743490838958534,
      "grad_norm": 0.00018861326680053025,
      "learning_rate": 4.513018322082932e-06,
      "loss": 0.2557,
      "step": 72270
    },
    {
      "epoch": 7.744562305796635,
      "grad_norm": 0.0064161550253629684,
      "learning_rate": 4.5108753884067295e-06,
      "loss": 0.0878,
      "step": 72280
    },
    {
      "epoch": 7.745633772634737,
      "grad_norm": 0.04577131196856499,
      "learning_rate": 4.508732454730527e-06,
      "loss": 0.2199,
      "step": 72290
    },
    {
      "epoch": 7.746705239472838,
      "grad_norm": 0.00017927335284184664,
      "learning_rate": 4.506589521054323e-06,
      "loss": 0.0074,
      "step": 72300
    },
    {
      "epoch": 7.7477767063109395,
      "grad_norm": 0.00024580457829870284,
      "learning_rate": 4.5044465873781216e-06,
      "loss": 0.0873,
      "step": 72310
    },
    {
      "epoch": 7.748848173149041,
      "grad_norm": 0.06198612600564957,
      "learning_rate": 4.502303653701918e-06,
      "loss": 0.006,
      "step": 72320
    },
    {
      "epoch": 7.749919639987143,
      "grad_norm": 0.0003611823485698551,
      "learning_rate": 4.5001607200257154e-06,
      "loss": 0.0014,
      "step": 72330
    },
    {
      "epoch": 7.750991106825244,
      "grad_norm": 25.168237686157227,
      "learning_rate": 4.498017786349513e-06,
      "loss": 0.3825,
      "step": 72340
    },
    {
      "epoch": 7.752062573663345,
      "grad_norm": 0.005184488836675882,
      "learning_rate": 4.49587485267331e-06,
      "loss": 0.0005,
      "step": 72350
    },
    {
      "epoch": 7.753134040501447,
      "grad_norm": 0.00023596758546773344,
      "learning_rate": 4.4937319189971075e-06,
      "loss": 0.0005,
      "step": 72360
    },
    {
      "epoch": 7.754205507339548,
      "grad_norm": 0.0004424767103046179,
      "learning_rate": 4.491588985320905e-06,
      "loss": 0.0003,
      "step": 72370
    },
    {
      "epoch": 7.755276974177649,
      "grad_norm": 0.034613121300935745,
      "learning_rate": 4.489446051644702e-06,
      "loss": 0.1237,
      "step": 72380
    },
    {
      "epoch": 7.756348441015751,
      "grad_norm": 0.006777666043490171,
      "learning_rate": 4.4873031179684996e-06,
      "loss": 0.1915,
      "step": 72390
    },
    {
      "epoch": 7.757419907853852,
      "grad_norm": 0.20679008960723877,
      "learning_rate": 4.485160184292296e-06,
      "loss": 0.4375,
      "step": 72400
    },
    {
      "epoch": 7.758491374691953,
      "grad_norm": 0.14000888168811798,
      "learning_rate": 4.483017250616094e-06,
      "loss": 0.2819,
      "step": 72410
    },
    {
      "epoch": 7.759562841530054,
      "grad_norm": 0.008003022521734238,
      "learning_rate": 4.480874316939891e-06,
      "loss": 0.0025,
      "step": 72420
    },
    {
      "epoch": 7.760634308368156,
      "grad_norm": 0.02014504186809063,
      "learning_rate": 4.478731383263689e-06,
      "loss": 0.0002,
      "step": 72430
    },
    {
      "epoch": 7.7617057752062575,
      "grad_norm": 22.551424026489258,
      "learning_rate": 4.4765884495874855e-06,
      "loss": 0.135,
      "step": 72440
    },
    {
      "epoch": 7.762777242044359,
      "grad_norm": 0.0002583394234534353,
      "learning_rate": 4.474445515911283e-06,
      "loss": 0.349,
      "step": 72450
    },
    {
      "epoch": 7.76384870888246,
      "grad_norm": 38.77588653564453,
      "learning_rate": 4.47230258223508e-06,
      "loss": 0.0831,
      "step": 72460
    },
    {
      "epoch": 7.764920175720562,
      "grad_norm": 13.75218677520752,
      "learning_rate": 4.4701596485588776e-06,
      "loss": 0.0043,
      "step": 72470
    },
    {
      "epoch": 7.765991642558663,
      "grad_norm": 0.0061530969105660915,
      "learning_rate": 4.468016714882675e-06,
      "loss": 0.0707,
      "step": 72480
    },
    {
      "epoch": 7.767063109396764,
      "grad_norm": 0.003881244920194149,
      "learning_rate": 4.4658737812064714e-06,
      "loss": 0.0003,
      "step": 72490
    },
    {
      "epoch": 7.768134576234866,
      "grad_norm": 0.01241381000727415,
      "learning_rate": 4.46373084753027e-06,
      "loss": 0.0015,
      "step": 72500
    },
    {
      "epoch": 7.769206043072967,
      "grad_norm": 0.009260137565433979,
      "learning_rate": 4.461587913854066e-06,
      "loss": 0.0324,
      "step": 72510
    },
    {
      "epoch": 7.770277509911068,
      "grad_norm": 2.9003405570983887,
      "learning_rate": 4.4594449801778635e-06,
      "loss": 0.0019,
      "step": 72520
    },
    {
      "epoch": 7.771348976749169,
      "grad_norm": 0.04432036355137825,
      "learning_rate": 4.457302046501661e-06,
      "loss": 0.0005,
      "step": 72530
    },
    {
      "epoch": 7.772420443587271,
      "grad_norm": 0.00037018844159319997,
      "learning_rate": 4.455159112825458e-06,
      "loss": 0.1471,
      "step": 72540
    },
    {
      "epoch": 7.773491910425372,
      "grad_norm": 0.0005393876344896853,
      "learning_rate": 4.4530161791492556e-06,
      "loss": 0.0126,
      "step": 72550
    },
    {
      "epoch": 7.7745633772634735,
      "grad_norm": 0.0002721277705859393,
      "learning_rate": 4.450873245473053e-06,
      "loss": 0.0002,
      "step": 72560
    },
    {
      "epoch": 7.775634844101575,
      "grad_norm": 0.00026943799457512796,
      "learning_rate": 4.44873031179685e-06,
      "loss": 0.2488,
      "step": 72570
    },
    {
      "epoch": 7.776706310939677,
      "grad_norm": 0.009928043000400066,
      "learning_rate": 4.446587378120648e-06,
      "loss": 0.1601,
      "step": 72580
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 0.0016167719149962068,
      "learning_rate": 4.444444444444444e-06,
      "loss": 0.001,
      "step": 72590
    },
    {
      "epoch": 7.778849244615879,
      "grad_norm": 0.0008266723016276956,
      "learning_rate": 4.442301510768242e-06,
      "loss": 0.0,
      "step": 72600
    },
    {
      "epoch": 7.779920711453981,
      "grad_norm": 0.008179319091141224,
      "learning_rate": 4.440158577092039e-06,
      "loss": 0.002,
      "step": 72610
    },
    {
      "epoch": 7.780992178292082,
      "grad_norm": 0.00034585437970235944,
      "learning_rate": 4.438015643415837e-06,
      "loss": 0.0018,
      "step": 72620
    },
    {
      "epoch": 7.782063645130183,
      "grad_norm": 0.00030628099921159446,
      "learning_rate": 4.4358727097396336e-06,
      "loss": 0.1615,
      "step": 72630
    },
    {
      "epoch": 7.783135111968285,
      "grad_norm": 0.01687793619930744,
      "learning_rate": 4.433729776063431e-06,
      "loss": 0.0003,
      "step": 72640
    },
    {
      "epoch": 7.784206578806386,
      "grad_norm": 0.011681949719786644,
      "learning_rate": 4.431586842387228e-06,
      "loss": 0.1763,
      "step": 72650
    },
    {
      "epoch": 7.785278045644487,
      "grad_norm": 0.0003243205137550831,
      "learning_rate": 4.429443908711026e-06,
      "loss": 0.4112,
      "step": 72660
    },
    {
      "epoch": 7.786349512482588,
      "grad_norm": 0.002516346052289009,
      "learning_rate": 4.427300975034823e-06,
      "loss": 0.2349,
      "step": 72670
    },
    {
      "epoch": 7.78742097932069,
      "grad_norm": 0.0005681939073838294,
      "learning_rate": 4.42515804135862e-06,
      "loss": 0.0008,
      "step": 72680
    },
    {
      "epoch": 7.788492446158791,
      "grad_norm": 0.6386960744857788,
      "learning_rate": 4.423015107682418e-06,
      "loss": 0.0095,
      "step": 72690
    },
    {
      "epoch": 7.7895639129968925,
      "grad_norm": 0.028833359479904175,
      "learning_rate": 4.420872174006215e-06,
      "loss": 0.1653,
      "step": 72700
    },
    {
      "epoch": 7.790635379834994,
      "grad_norm": 0.013799642212688923,
      "learning_rate": 4.4187292403300116e-06,
      "loss": 0.121,
      "step": 72710
    },
    {
      "epoch": 7.791706846673096,
      "grad_norm": 0.001888270489871502,
      "learning_rate": 4.41658630665381e-06,
      "loss": 0.0002,
      "step": 72720
    },
    {
      "epoch": 7.792778313511197,
      "grad_norm": 0.001823524245992303,
      "learning_rate": 4.414443372977606e-06,
      "loss": 0.0002,
      "step": 72730
    },
    {
      "epoch": 7.793849780349298,
      "grad_norm": 0.0344926081597805,
      "learning_rate": 4.412300439301404e-06,
      "loss": 0.0003,
      "step": 72740
    },
    {
      "epoch": 7.7949212471874,
      "grad_norm": 0.0002952392678707838,
      "learning_rate": 4.410157505625201e-06,
      "loss": 0.0016,
      "step": 72750
    },
    {
      "epoch": 7.795992714025501,
      "grad_norm": 0.00647928100079298,
      "learning_rate": 4.408014571948998e-06,
      "loss": 0.0533,
      "step": 72760
    },
    {
      "epoch": 7.797064180863602,
      "grad_norm": 0.0006940801977179945,
      "learning_rate": 4.405871638272796e-06,
      "loss": 0.0001,
      "step": 72770
    },
    {
      "epoch": 7.798135647701704,
      "grad_norm": 0.007495429366827011,
      "learning_rate": 4.403728704596593e-06,
      "loss": 0.0004,
      "step": 72780
    },
    {
      "epoch": 7.799207114539805,
      "grad_norm": 0.00024068047059699893,
      "learning_rate": 4.40158577092039e-06,
      "loss": 0.0004,
      "step": 72790
    },
    {
      "epoch": 7.800278581377906,
      "grad_norm": 0.0004357768630143255,
      "learning_rate": 4.399442837244188e-06,
      "loss": 0.072,
      "step": 72800
    },
    {
      "epoch": 7.801350048216007,
      "grad_norm": 0.000212399463634938,
      "learning_rate": 4.397299903567985e-06,
      "loss": 0.0002,
      "step": 72810
    },
    {
      "epoch": 7.802421515054109,
      "grad_norm": 0.0007330563385039568,
      "learning_rate": 4.3951569698917825e-06,
      "loss": 0.0004,
      "step": 72820
    },
    {
      "epoch": 7.8034929818922105,
      "grad_norm": 0.0024983780458569527,
      "learning_rate": 4.393014036215579e-06,
      "loss": 0.1518,
      "step": 72830
    },
    {
      "epoch": 7.804564448730312,
      "grad_norm": 0.003343986812978983,
      "learning_rate": 4.390871102539377e-06,
      "loss": 0.0007,
      "step": 72840
    },
    {
      "epoch": 7.805635915568413,
      "grad_norm": 0.0005836025229655206,
      "learning_rate": 4.388728168863174e-06,
      "loss": 0.0001,
      "step": 72850
    },
    {
      "epoch": 7.806707382406515,
      "grad_norm": 0.007539600133895874,
      "learning_rate": 4.386585235186971e-06,
      "loss": 0.002,
      "step": 72860
    },
    {
      "epoch": 7.807778849244616,
      "grad_norm": 0.0109266871586442,
      "learning_rate": 4.384442301510768e-06,
      "loss": 0.2162,
      "step": 72870
    },
    {
      "epoch": 7.808850316082717,
      "grad_norm": 0.00014277355512604117,
      "learning_rate": 4.382299367834566e-06,
      "loss": 0.0002,
      "step": 72880
    },
    {
      "epoch": 7.809921782920819,
      "grad_norm": 0.001319620292633772,
      "learning_rate": 4.380156434158363e-06,
      "loss": 0.0033,
      "step": 72890
    },
    {
      "epoch": 7.81099324975892,
      "grad_norm": 0.0007981539238244295,
      "learning_rate": 4.3780135004821605e-06,
      "loss": 0.0001,
      "step": 72900
    },
    {
      "epoch": 7.812064716597021,
      "grad_norm": 0.09382441639900208,
      "learning_rate": 4.375870566805958e-06,
      "loss": 0.1462,
      "step": 72910
    },
    {
      "epoch": 7.813136183435123,
      "grad_norm": 0.00787059310823679,
      "learning_rate": 4.373727633129755e-06,
      "loss": 0.1309,
      "step": 72920
    },
    {
      "epoch": 7.814207650273224,
      "grad_norm": 0.03268187493085861,
      "learning_rate": 4.371584699453552e-06,
      "loss": 0.0002,
      "step": 72930
    },
    {
      "epoch": 7.815279117111325,
      "grad_norm": 0.2700607478618622,
      "learning_rate": 4.36944176577735e-06,
      "loss": 0.0676,
      "step": 72940
    },
    {
      "epoch": 7.8163505839494265,
      "grad_norm": 21.537456512451172,
      "learning_rate": 4.367298832101146e-06,
      "loss": 0.2022,
      "step": 72950
    },
    {
      "epoch": 7.8174220507875285,
      "grad_norm": 0.00018395633378531784,
      "learning_rate": 4.365155898424945e-06,
      "loss": 0.1693,
      "step": 72960
    },
    {
      "epoch": 7.81849351762563,
      "grad_norm": 0.00530607532709837,
      "learning_rate": 4.363012964748741e-06,
      "loss": 0.0174,
      "step": 72970
    },
    {
      "epoch": 7.819564984463731,
      "grad_norm": 0.005960693582892418,
      "learning_rate": 4.3608700310725385e-06,
      "loss": 0.0007,
      "step": 72980
    },
    {
      "epoch": 7.820636451301832,
      "grad_norm": 0.000299078063108027,
      "learning_rate": 4.358727097396336e-06,
      "loss": 0.0003,
      "step": 72990
    },
    {
      "epoch": 7.821707918139934,
      "grad_norm": 0.010865024290978909,
      "learning_rate": 4.356584163720133e-06,
      "loss": 0.0004,
      "step": 73000
    },
    {
      "epoch": 7.822779384978035,
      "grad_norm": 0.0068890685215592384,
      "learning_rate": 4.3544412300439306e-06,
      "loss": 0.1388,
      "step": 73010
    },
    {
      "epoch": 7.823850851816136,
      "grad_norm": 21.335844039916992,
      "learning_rate": 4.352298296367728e-06,
      "loss": 0.1581,
      "step": 73020
    },
    {
      "epoch": 7.824922318654238,
      "grad_norm": 0.04011882096529007,
      "learning_rate": 4.350155362691525e-06,
      "loss": 0.2075,
      "step": 73030
    },
    {
      "epoch": 7.825993785492339,
      "grad_norm": 0.014248126186430454,
      "learning_rate": 4.348012429015323e-06,
      "loss": 0.0026,
      "step": 73040
    },
    {
      "epoch": 7.82706525233044,
      "grad_norm": 0.004916354548186064,
      "learning_rate": 4.345869495339119e-06,
      "loss": 0.0004,
      "step": 73050
    },
    {
      "epoch": 7.828136719168541,
      "grad_norm": 0.00022886863735038787,
      "learning_rate": 4.343726561662917e-06,
      "loss": 0.1794,
      "step": 73060
    },
    {
      "epoch": 7.829208186006643,
      "grad_norm": 0.009733620099723339,
      "learning_rate": 4.341583627986714e-06,
      "loss": 0.1367,
      "step": 73070
    },
    {
      "epoch": 7.8302796528447445,
      "grad_norm": 0.00018177840684074908,
      "learning_rate": 4.339440694310512e-06,
      "loss": 0.0004,
      "step": 73080
    },
    {
      "epoch": 7.831351119682846,
      "grad_norm": 0.0002512377977836877,
      "learning_rate": 4.3372977606343086e-06,
      "loss": 0.0004,
      "step": 73090
    },
    {
      "epoch": 7.832422586520947,
      "grad_norm": 0.012671096250414848,
      "learning_rate": 4.335154826958106e-06,
      "loss": 0.1157,
      "step": 73100
    },
    {
      "epoch": 7.833494053359049,
      "grad_norm": 27.9508113861084,
      "learning_rate": 4.333011893281903e-06,
      "loss": 0.2938,
      "step": 73110
    },
    {
      "epoch": 7.83456552019715,
      "grad_norm": 0.10561609268188477,
      "learning_rate": 4.330868959605701e-06,
      "loss": 0.0093,
      "step": 73120
    },
    {
      "epoch": 7.835636987035251,
      "grad_norm": 0.00022347114281728864,
      "learning_rate": 4.328726025929498e-06,
      "loss": 0.0156,
      "step": 73130
    },
    {
      "epoch": 7.836708453873353,
      "grad_norm": 0.15815410017967224,
      "learning_rate": 4.326583092253295e-06,
      "loss": 0.0006,
      "step": 73140
    },
    {
      "epoch": 7.837779920711454,
      "grad_norm": 0.0002534953528083861,
      "learning_rate": 4.324440158577093e-06,
      "loss": 0.0001,
      "step": 73150
    },
    {
      "epoch": 7.838851387549555,
      "grad_norm": 0.0002080339181702584,
      "learning_rate": 4.32229722490089e-06,
      "loss": 0.0001,
      "step": 73160
    },
    {
      "epoch": 7.839922854387657,
      "grad_norm": 38.36618423461914,
      "learning_rate": 4.3201542912246866e-06,
      "loss": 0.3756,
      "step": 73170
    },
    {
      "epoch": 7.840994321225758,
      "grad_norm": 0.03400437906384468,
      "learning_rate": 4.318011357548485e-06,
      "loss": 0.0003,
      "step": 73180
    },
    {
      "epoch": 7.842065788063859,
      "grad_norm": 128.3009796142578,
      "learning_rate": 4.315868423872281e-06,
      "loss": 0.8612,
      "step": 73190
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 0.02835177816450596,
      "learning_rate": 4.313725490196079e-06,
      "loss": 0.0012,
      "step": 73200
    },
    {
      "epoch": 7.8442087217400625,
      "grad_norm": 0.0005321692442521453,
      "learning_rate": 4.311582556519876e-06,
      "loss": 0.0001,
      "step": 73210
    },
    {
      "epoch": 7.845280188578164,
      "grad_norm": 0.007432138081640005,
      "learning_rate": 4.309439622843673e-06,
      "loss": 0.0022,
      "step": 73220
    },
    {
      "epoch": 7.846351655416265,
      "grad_norm": 0.0005734212463721633,
      "learning_rate": 4.307296689167471e-06,
      "loss": 0.331,
      "step": 73230
    },
    {
      "epoch": 7.847423122254366,
      "grad_norm": 0.0014105477603152394,
      "learning_rate": 4.305153755491268e-06,
      "loss": 0.2615,
      "step": 73240
    },
    {
      "epoch": 7.848494589092468,
      "grad_norm": 0.16449853777885437,
      "learning_rate": 4.303010821815065e-06,
      "loss": 0.0007,
      "step": 73250
    },
    {
      "epoch": 7.849566055930569,
      "grad_norm": 3.641970634460449,
      "learning_rate": 4.300867888138863e-06,
      "loss": 0.1776,
      "step": 73260
    },
    {
      "epoch": 7.85063752276867,
      "grad_norm": 5.723586559295654,
      "learning_rate": 4.29872495446266e-06,
      "loss": 0.0014,
      "step": 73270
    },
    {
      "epoch": 7.851708989606772,
      "grad_norm": 0.0002993606321979314,
      "learning_rate": 4.2965820207864575e-06,
      "loss": 0.0004,
      "step": 73280
    },
    {
      "epoch": 7.852780456444873,
      "grad_norm": 0.1468067467212677,
      "learning_rate": 4.294439087110254e-06,
      "loss": 0.0001,
      "step": 73290
    },
    {
      "epoch": 7.853851923282974,
      "grad_norm": 0.00019516795873641968,
      "learning_rate": 4.292296153434052e-06,
      "loss": 0.0015,
      "step": 73300
    },
    {
      "epoch": 7.854923390121076,
      "grad_norm": 0.006300676614046097,
      "learning_rate": 4.290153219757849e-06,
      "loss": 0.1303,
      "step": 73310
    },
    {
      "epoch": 7.855994856959177,
      "grad_norm": 0.005660187918692827,
      "learning_rate": 4.288010286081646e-06,
      "loss": 0.0001,
      "step": 73320
    },
    {
      "epoch": 7.857066323797278,
      "grad_norm": 0.00018888652266468853,
      "learning_rate": 4.285867352405443e-06,
      "loss": 0.1192,
      "step": 73330
    },
    {
      "epoch": 7.8581377906353795,
      "grad_norm": 166.2489471435547,
      "learning_rate": 4.283724418729241e-06,
      "loss": 0.3625,
      "step": 73340
    },
    {
      "epoch": 7.8592092574734815,
      "grad_norm": 0.005756700877100229,
      "learning_rate": 4.281581485053038e-06,
      "loss": 0.0004,
      "step": 73350
    },
    {
      "epoch": 7.860280724311583,
      "grad_norm": 0.00027917299303226173,
      "learning_rate": 4.2794385513768355e-06,
      "loss": 0.0001,
      "step": 73360
    },
    {
      "epoch": 7.861352191149684,
      "grad_norm": 2.1928446292877197,
      "learning_rate": 4.277295617700633e-06,
      "loss": 0.4142,
      "step": 73370
    },
    {
      "epoch": 7.862423657987785,
      "grad_norm": 0.0001405104121658951,
      "learning_rate": 4.27515268402443e-06,
      "loss": 0.0147,
      "step": 73380
    },
    {
      "epoch": 7.863495124825887,
      "grad_norm": 0.009014834649860859,
      "learning_rate": 4.273009750348227e-06,
      "loss": 0.0001,
      "step": 73390
    },
    {
      "epoch": 7.864566591663988,
      "grad_norm": 0.01761893928050995,
      "learning_rate": 4.270866816672024e-06,
      "loss": 0.0005,
      "step": 73400
    },
    {
      "epoch": 7.865638058502089,
      "grad_norm": 0.41716814041137695,
      "learning_rate": 4.268723882995821e-06,
      "loss": 0.0013,
      "step": 73410
    },
    {
      "epoch": 7.866709525340191,
      "grad_norm": 0.0012442423030734062,
      "learning_rate": 4.266580949319619e-06,
      "loss": 0.162,
      "step": 73420
    },
    {
      "epoch": 7.867780992178292,
      "grad_norm": 0.0002651946560945362,
      "learning_rate": 4.264438015643416e-06,
      "loss": 0.0005,
      "step": 73430
    },
    {
      "epoch": 7.868852459016393,
      "grad_norm": 0.0263561699539423,
      "learning_rate": 4.2622950819672135e-06,
      "loss": 0.0009,
      "step": 73440
    },
    {
      "epoch": 7.869923925854495,
      "grad_norm": 0.0003388951881788671,
      "learning_rate": 4.260152148291011e-06,
      "loss": 0.0002,
      "step": 73450
    },
    {
      "epoch": 7.870995392692596,
      "grad_norm": 1.1987299919128418,
      "learning_rate": 4.258009214614808e-06,
      "loss": 0.1519,
      "step": 73460
    },
    {
      "epoch": 7.8720668595306975,
      "grad_norm": 0.06859022378921509,
      "learning_rate": 4.2558662809386055e-06,
      "loss": 0.0003,
      "step": 73470
    },
    {
      "epoch": 7.873138326368799,
      "grad_norm": 0.004589900374412537,
      "learning_rate": 4.253723347262402e-06,
      "loss": 0.0004,
      "step": 73480
    },
    {
      "epoch": 7.874209793206901,
      "grad_norm": 0.0001345212949672714,
      "learning_rate": 4.2515804135862e-06,
      "loss": 0.2284,
      "step": 73490
    },
    {
      "epoch": 7.875281260045002,
      "grad_norm": 0.014599877409636974,
      "learning_rate": 4.249437479909997e-06,
      "loss": 0.4578,
      "step": 73500
    },
    {
      "epoch": 7.876352726883103,
      "grad_norm": 36.20441436767578,
      "learning_rate": 4.247294546233794e-06,
      "loss": 0.2018,
      "step": 73510
    },
    {
      "epoch": 7.877424193721204,
      "grad_norm": 0.0007228977628983557,
      "learning_rate": 4.2451516125575915e-06,
      "loss": 0.0003,
      "step": 73520
    },
    {
      "epoch": 7.878495660559306,
      "grad_norm": 0.00023026559210848063,
      "learning_rate": 4.243008678881389e-06,
      "loss": 0.0018,
      "step": 73530
    },
    {
      "epoch": 7.879567127397407,
      "grad_norm": 0.00024020869750529528,
      "learning_rate": 4.240865745205186e-06,
      "loss": 0.0011,
      "step": 73540
    },
    {
      "epoch": 7.880638594235508,
      "grad_norm": 0.0004869507974945009,
      "learning_rate": 4.2387228115289835e-06,
      "loss": 0.0005,
      "step": 73550
    },
    {
      "epoch": 7.88171006107361,
      "grad_norm": 0.0015951732639223337,
      "learning_rate": 4.236579877852781e-06,
      "loss": 0.0005,
      "step": 73560
    },
    {
      "epoch": 7.882781527911711,
      "grad_norm": 0.001005101832561195,
      "learning_rate": 4.234436944176578e-06,
      "loss": 0.0001,
      "step": 73570
    },
    {
      "epoch": 7.883852994749812,
      "grad_norm": 0.00032354352879337966,
      "learning_rate": 4.232294010500375e-06,
      "loss": 0.0001,
      "step": 73580
    },
    {
      "epoch": 7.8849244615879135,
      "grad_norm": 0.007942458614706993,
      "learning_rate": 4.230151076824173e-06,
      "loss": 0.3539,
      "step": 73590
    },
    {
      "epoch": 7.8859959284260155,
      "grad_norm": 0.008920553140342236,
      "learning_rate": 4.2280081431479695e-06,
      "loss": 0.316,
      "step": 73600
    },
    {
      "epoch": 7.887067395264117,
      "grad_norm": 0.00020167064212728292,
      "learning_rate": 4.225865209471768e-06,
      "loss": 0.002,
      "step": 73610
    },
    {
      "epoch": 7.888138862102218,
      "grad_norm": 0.0005037953378632665,
      "learning_rate": 4.223722275795564e-06,
      "loss": 0.1354,
      "step": 73620
    },
    {
      "epoch": 7.889210328940319,
      "grad_norm": 0.24755476415157318,
      "learning_rate": 4.2215793421193615e-06,
      "loss": 0.0005,
      "step": 73630
    },
    {
      "epoch": 7.890281795778421,
      "grad_norm": 0.0002551059005782008,
      "learning_rate": 4.219436408443159e-06,
      "loss": 0.0006,
      "step": 73640
    },
    {
      "epoch": 7.891353262616522,
      "grad_norm": 0.00037263394915498793,
      "learning_rate": 4.217293474766956e-06,
      "loss": 0.3468,
      "step": 73650
    },
    {
      "epoch": 7.892424729454623,
      "grad_norm": 0.006707311142235994,
      "learning_rate": 4.215150541090754e-06,
      "loss": 0.0002,
      "step": 73660
    },
    {
      "epoch": 7.893496196292725,
      "grad_norm": 0.011095856316387653,
      "learning_rate": 4.213007607414551e-06,
      "loss": 0.0011,
      "step": 73670
    },
    {
      "epoch": 7.894567663130826,
      "grad_norm": 0.07488608360290527,
      "learning_rate": 4.210864673738348e-06,
      "loss": 0.0011,
      "step": 73680
    },
    {
      "epoch": 7.895639129968927,
      "grad_norm": 0.010806751437485218,
      "learning_rate": 4.208721740062146e-06,
      "loss": 0.0013,
      "step": 73690
    },
    {
      "epoch": 7.896710596807029,
      "grad_norm": 0.013095670379698277,
      "learning_rate": 4.206578806385942e-06,
      "loss": 0.0001,
      "step": 73700
    },
    {
      "epoch": 7.89778206364513,
      "grad_norm": 0.018434297293424606,
      "learning_rate": 4.20443587270974e-06,
      "loss": 0.0005,
      "step": 73710
    },
    {
      "epoch": 7.8988535304832315,
      "grad_norm": 0.004931219387799501,
      "learning_rate": 4.202292939033537e-06,
      "loss": 0.0013,
      "step": 73720
    },
    {
      "epoch": 7.899924997321333,
      "grad_norm": 0.005881679244339466,
      "learning_rate": 4.200150005357334e-06,
      "loss": 0.0001,
      "step": 73730
    },
    {
      "epoch": 7.900996464159435,
      "grad_norm": 0.04129856452345848,
      "learning_rate": 4.198007071681132e-06,
      "loss": 0.0005,
      "step": 73740
    },
    {
      "epoch": 7.902067930997536,
      "grad_norm": 0.00018744055705610663,
      "learning_rate": 4.195864138004929e-06,
      "loss": 0.002,
      "step": 73750
    },
    {
      "epoch": 7.903139397835637,
      "grad_norm": 0.004526803735643625,
      "learning_rate": 4.193721204328726e-06,
      "loss": 0.0002,
      "step": 73760
    },
    {
      "epoch": 7.904210864673738,
      "grad_norm": 0.0003978990134783089,
      "learning_rate": 4.191578270652524e-06,
      "loss": 0.0001,
      "step": 73770
    },
    {
      "epoch": 7.90528233151184,
      "grad_norm": 0.09215332567691803,
      "learning_rate": 4.189435336976321e-06,
      "loss": 0.1695,
      "step": 73780
    },
    {
      "epoch": 7.906353798349941,
      "grad_norm": 0.1353275626897812,
      "learning_rate": 4.187292403300118e-06,
      "loss": 0.0005,
      "step": 73790
    },
    {
      "epoch": 7.907425265188042,
      "grad_norm": 0.0014770606067031622,
      "learning_rate": 4.185149469623916e-06,
      "loss": 0.1848,
      "step": 73800
    },
    {
      "epoch": 7.908496732026144,
      "grad_norm": 0.0003775322693400085,
      "learning_rate": 4.183006535947713e-06,
      "loss": 0.0001,
      "step": 73810
    },
    {
      "epoch": 7.909568198864245,
      "grad_norm": 0.07522334158420563,
      "learning_rate": 4.18086360227151e-06,
      "loss": 0.164,
      "step": 73820
    },
    {
      "epoch": 7.910639665702346,
      "grad_norm": 0.0002132819063263014,
      "learning_rate": 4.178720668595308e-06,
      "loss": 0.0001,
      "step": 73830
    },
    {
      "epoch": 7.911711132540448,
      "grad_norm": 0.0034632342867553234,
      "learning_rate": 4.176577734919104e-06,
      "loss": 0.0003,
      "step": 73840
    },
    {
      "epoch": 7.912782599378549,
      "grad_norm": 0.0001597788359504193,
      "learning_rate": 4.174434801242902e-06,
      "loss": 0.0213,
      "step": 73850
    },
    {
      "epoch": 7.9138540662166506,
      "grad_norm": 0.007665254175662994,
      "learning_rate": 4.172291867566699e-06,
      "loss": 0.0004,
      "step": 73860
    },
    {
      "epoch": 7.914925533054752,
      "grad_norm": 0.003909675404429436,
      "learning_rate": 4.170148933890496e-06,
      "loss": 0.0001,
      "step": 73870
    },
    {
      "epoch": 7.915996999892854,
      "grad_norm": 0.005578416399657726,
      "learning_rate": 4.168006000214294e-06,
      "loss": 0.0001,
      "step": 73880
    },
    {
      "epoch": 7.917068466730955,
      "grad_norm": 0.00019562416127882898,
      "learning_rate": 4.165863066538091e-06,
      "loss": 0.0001,
      "step": 73890
    },
    {
      "epoch": 7.918139933569056,
      "grad_norm": 0.005329484585672617,
      "learning_rate": 4.1637201328618884e-06,
      "loss": 0.0003,
      "step": 73900
    },
    {
      "epoch": 7.919211400407157,
      "grad_norm": 0.013297082856297493,
      "learning_rate": 4.161577199185686e-06,
      "loss": 0.2591,
      "step": 73910
    },
    {
      "epoch": 7.920282867245259,
      "grad_norm": 0.043458662927150726,
      "learning_rate": 4.159434265509482e-06,
      "loss": 0.1547,
      "step": 73920
    },
    {
      "epoch": 7.92135433408336,
      "grad_norm": 0.0039525944739580154,
      "learning_rate": 4.1572913318332805e-06,
      "loss": 0.0002,
      "step": 73930
    },
    {
      "epoch": 7.922425800921461,
      "grad_norm": 0.0001569189189467579,
      "learning_rate": 4.155148398157077e-06,
      "loss": 0.158,
      "step": 73940
    },
    {
      "epoch": 7.923497267759563,
      "grad_norm": 0.00036612313124351203,
      "learning_rate": 4.153005464480875e-06,
      "loss": 0.0001,
      "step": 73950
    },
    {
      "epoch": 7.924568734597664,
      "grad_norm": 0.017971863970160484,
      "learning_rate": 4.150862530804672e-06,
      "loss": 0.0003,
      "step": 73960
    },
    {
      "epoch": 7.925640201435765,
      "grad_norm": 0.00014599815767724067,
      "learning_rate": 4.148719597128469e-06,
      "loss": 0.0001,
      "step": 73970
    },
    {
      "epoch": 7.926711668273867,
      "grad_norm": 0.007659803610295057,
      "learning_rate": 4.1465766634522664e-06,
      "loss": 0.4199,
      "step": 73980
    },
    {
      "epoch": 7.9277831351119685,
      "grad_norm": 0.31182485818862915,
      "learning_rate": 4.144433729776064e-06,
      "loss": 0.0004,
      "step": 73990
    },
    {
      "epoch": 7.92885460195007,
      "grad_norm": 0.0001758582511683926,
      "learning_rate": 4.142290796099861e-06,
      "loss": 0.0002,
      "step": 74000
    },
    {
      "epoch": 7.929926068788171,
      "grad_norm": 0.00010127492714673281,
      "learning_rate": 4.1401478624236585e-06,
      "loss": 0.1493,
      "step": 74010
    },
    {
      "epoch": 7.930997535626273,
      "grad_norm": 0.01052424032241106,
      "learning_rate": 4.138004928747456e-06,
      "loss": 0.0003,
      "step": 74020
    },
    {
      "epoch": 7.932069002464374,
      "grad_norm": 0.008840377442538738,
      "learning_rate": 4.135861995071253e-06,
      "loss": 0.4027,
      "step": 74030
    },
    {
      "epoch": 7.933140469302475,
      "grad_norm": 0.004969496745616198,
      "learning_rate": 4.13371906139505e-06,
      "loss": 0.1106,
      "step": 74040
    },
    {
      "epoch": 7.934211936140576,
      "grad_norm": 0.00021445112361107022,
      "learning_rate": 4.131576127718848e-06,
      "loss": 0.2451,
      "step": 74050
    },
    {
      "epoch": 7.935283402978678,
      "grad_norm": 0.03662330284714699,
      "learning_rate": 4.1294331940426444e-06,
      "loss": 0.0003,
      "step": 74060
    },
    {
      "epoch": 7.936354869816779,
      "grad_norm": 0.20924413204193115,
      "learning_rate": 4.127290260366442e-06,
      "loss": 0.0003,
      "step": 74070
    },
    {
      "epoch": 7.93742633665488,
      "grad_norm": 0.0003483454347588122,
      "learning_rate": 4.125147326690239e-06,
      "loss": 0.1478,
      "step": 74080
    },
    {
      "epoch": 7.938497803492982,
      "grad_norm": 0.00038287873030640185,
      "learning_rate": 4.1230043930140365e-06,
      "loss": 0.0745,
      "step": 74090
    },
    {
      "epoch": 7.939569270331083,
      "grad_norm": 0.0004696747928392142,
      "learning_rate": 4.120861459337834e-06,
      "loss": 0.0001,
      "step": 74100
    },
    {
      "epoch": 7.9406407371691845,
      "grad_norm": 0.00018297731003258377,
      "learning_rate": 4.118718525661631e-06,
      "loss": 0.0001,
      "step": 74110
    },
    {
      "epoch": 7.941712204007286,
      "grad_norm": 0.0003105273353867233,
      "learning_rate": 4.1165755919854286e-06,
      "loss": 0.0007,
      "step": 74120
    },
    {
      "epoch": 7.942783670845388,
      "grad_norm": 0.00013323833991307765,
      "learning_rate": 4.114432658309226e-06,
      "loss": 0.0001,
      "step": 74130
    },
    {
      "epoch": 7.943855137683489,
      "grad_norm": 0.0036425397265702486,
      "learning_rate": 4.112289724633023e-06,
      "loss": 0.1336,
      "step": 74140
    },
    {
      "epoch": 7.94492660452159,
      "grad_norm": 0.008062509819865227,
      "learning_rate": 4.110146790956821e-06,
      "loss": 0.2446,
      "step": 74150
    },
    {
      "epoch": 7.945998071359691,
      "grad_norm": 0.05920307710766792,
      "learning_rate": 4.108003857280617e-06,
      "loss": 0.0008,
      "step": 74160
    },
    {
      "epoch": 7.947069538197793,
      "grad_norm": 0.012342048808932304,
      "learning_rate": 4.105860923604415e-06,
      "loss": 0.0004,
      "step": 74170
    },
    {
      "epoch": 7.948141005035894,
      "grad_norm": 0.0002960785641334951,
      "learning_rate": 4.103717989928212e-06,
      "loss": 0.2698,
      "step": 74180
    },
    {
      "epoch": 7.949212471873995,
      "grad_norm": 0.00016645922733005136,
      "learning_rate": 4.101575056252009e-06,
      "loss": 0.125,
      "step": 74190
    },
    {
      "epoch": 7.950283938712097,
      "grad_norm": 0.005645260214805603,
      "learning_rate": 4.0994321225758066e-06,
      "loss": 0.0003,
      "step": 74200
    },
    {
      "epoch": 7.951355405550198,
      "grad_norm": 0.011950867250561714,
      "learning_rate": 4.097289188899604e-06,
      "loss": 0.0003,
      "step": 74210
    },
    {
      "epoch": 7.952426872388299,
      "grad_norm": 0.015152370557188988,
      "learning_rate": 4.095146255223401e-06,
      "loss": 0.2933,
      "step": 74220
    },
    {
      "epoch": 7.953498339226401,
      "grad_norm": 0.0005835303454659879,
      "learning_rate": 4.093003321547199e-06,
      "loss": 0.0001,
      "step": 74230
    },
    {
      "epoch": 7.9545698060645025,
      "grad_norm": 0.010546746663749218,
      "learning_rate": 4.090860387870996e-06,
      "loss": 0.2636,
      "step": 74240
    },
    {
      "epoch": 7.955641272902604,
      "grad_norm": 0.03925855830311775,
      "learning_rate": 4.088717454194793e-06,
      "loss": 0.0267,
      "step": 74250
    },
    {
      "epoch": 7.956712739740705,
      "grad_norm": 0.0008931017946451902,
      "learning_rate": 4.08657452051859e-06,
      "loss": 0.0015,
      "step": 74260
    },
    {
      "epoch": 7.957784206578807,
      "grad_norm": 0.004386104643344879,
      "learning_rate": 4.084431586842388e-06,
      "loss": 0.7179,
      "step": 74270
    },
    {
      "epoch": 7.958855673416908,
      "grad_norm": 1.4480934143066406,
      "learning_rate": 4.0822886531661846e-06,
      "loss": 0.0007,
      "step": 74280
    },
    {
      "epoch": 7.959927140255009,
      "grad_norm": 0.00029586273012682796,
      "learning_rate": 4.080145719489983e-06,
      "loss": 0.2245,
      "step": 74290
    },
    {
      "epoch": 7.96099860709311,
      "grad_norm": 0.0009170305565930903,
      "learning_rate": 4.078002785813779e-06,
      "loss": 0.0259,
      "step": 74300
    },
    {
      "epoch": 7.962070073931212,
      "grad_norm": 0.0031340732239186764,
      "learning_rate": 4.075859852137577e-06,
      "loss": 0.0003,
      "step": 74310
    },
    {
      "epoch": 7.963141540769313,
      "grad_norm": 0.09106254577636719,
      "learning_rate": 4.073716918461374e-06,
      "loss": 0.0005,
      "step": 74320
    },
    {
      "epoch": 7.964213007607414,
      "grad_norm": 2.12235164642334,
      "learning_rate": 4.071573984785171e-06,
      "loss": 0.1351,
      "step": 74330
    },
    {
      "epoch": 7.965284474445516,
      "grad_norm": 0.20718088746070862,
      "learning_rate": 4.069431051108969e-06,
      "loss": 0.0006,
      "step": 74340
    },
    {
      "epoch": 7.966355941283617,
      "grad_norm": 0.023700149729847908,
      "learning_rate": 4.067288117432765e-06,
      "loss": 0.0005,
      "step": 74350
    },
    {
      "epoch": 7.9674274081217185,
      "grad_norm": 0.00027228714316152036,
      "learning_rate": 4.065145183756563e-06,
      "loss": 0.0001,
      "step": 74360
    },
    {
      "epoch": 7.9684988749598205,
      "grad_norm": 0.0008680119644850492,
      "learning_rate": 4.06300225008036e-06,
      "loss": 0.2316,
      "step": 74370
    },
    {
      "epoch": 7.969570341797922,
      "grad_norm": 0.042668312788009644,
      "learning_rate": 4.060859316404157e-06,
      "loss": 0.178,
      "step": 74380
    },
    {
      "epoch": 7.970641808636023,
      "grad_norm": 0.016537873074412346,
      "learning_rate": 4.058716382727955e-06,
      "loss": 0.0001,
      "step": 74390
    },
    {
      "epoch": 7.971713275474124,
      "grad_norm": 0.01200763788074255,
      "learning_rate": 4.056573449051752e-06,
      "loss": 0.0007,
      "step": 74400
    },
    {
      "epoch": 7.972784742312226,
      "grad_norm": 52.97290802001953,
      "learning_rate": 4.054430515375549e-06,
      "loss": 0.5138,
      "step": 74410
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 0.07375691086053848,
      "learning_rate": 4.052287581699347e-06,
      "loss": 0.0004,
      "step": 74420
    },
    {
      "epoch": 7.974927675988428,
      "grad_norm": 0.052923254668712616,
      "learning_rate": 4.050144648023144e-06,
      "loss": 0.0007,
      "step": 74430
    },
    {
      "epoch": 7.975999142826529,
      "grad_norm": 0.06391029804944992,
      "learning_rate": 4.048001714346941e-06,
      "loss": 0.0015,
      "step": 74440
    },
    {
      "epoch": 7.977070609664631,
      "grad_norm": 0.001437684055417776,
      "learning_rate": 4.045858780670738e-06,
      "loss": 0.073,
      "step": 74450
    },
    {
      "epoch": 7.978142076502732,
      "grad_norm": 15.741928100585938,
      "learning_rate": 4.043715846994536e-06,
      "loss": 0.5741,
      "step": 74460
    },
    {
      "epoch": 7.979213543340833,
      "grad_norm": 0.004737093113362789,
      "learning_rate": 4.041572913318333e-06,
      "loss": 0.0003,
      "step": 74470
    },
    {
      "epoch": 7.980285010178935,
      "grad_norm": 0.00017683810438029468,
      "learning_rate": 4.039429979642131e-06,
      "loss": 0.0004,
      "step": 74480
    },
    {
      "epoch": 7.981356477017036,
      "grad_norm": 0.00027579799643717706,
      "learning_rate": 4.037287045965927e-06,
      "loss": 0.0056,
      "step": 74490
    },
    {
      "epoch": 7.9824279438551375,
      "grad_norm": 0.029921555891633034,
      "learning_rate": 4.035144112289725e-06,
      "loss": 0.1843,
      "step": 74500
    },
    {
      "epoch": 7.9834994106932395,
      "grad_norm": 0.0040555959567427635,
      "learning_rate": 4.033001178613522e-06,
      "loss": 0.0004,
      "step": 74510
    },
    {
      "epoch": 7.984570877531341,
      "grad_norm": 0.004794049542397261,
      "learning_rate": 4.030858244937319e-06,
      "loss": 0.1798,
      "step": 74520
    },
    {
      "epoch": 7.985642344369442,
      "grad_norm": 0.00020619605493266135,
      "learning_rate": 4.028715311261117e-06,
      "loss": 0.0018,
      "step": 74530
    },
    {
      "epoch": 7.986713811207543,
      "grad_norm": 0.0006131802801974118,
      "learning_rate": 4.026572377584914e-06,
      "loss": 0.0005,
      "step": 74540
    },
    {
      "epoch": 7.987785278045645,
      "grad_norm": 0.00692320242524147,
      "learning_rate": 4.0244294439087115e-06,
      "loss": 0.4997,
      "step": 74550
    },
    {
      "epoch": 7.988856744883746,
      "grad_norm": 0.535893976688385,
      "learning_rate": 4.022286510232509e-06,
      "loss": 0.2411,
      "step": 74560
    },
    {
      "epoch": 7.989928211721847,
      "grad_norm": 0.0008362482767552137,
      "learning_rate": 4.020143576556305e-06,
      "loss": 0.1794,
      "step": 74570
    },
    {
      "epoch": 7.990999678559948,
      "grad_norm": 0.048542093485593796,
      "learning_rate": 4.0180006428801036e-06,
      "loss": 0.0004,
      "step": 74580
    },
    {
      "epoch": 7.99207114539805,
      "grad_norm": 0.001802520127967,
      "learning_rate": 4.0158577092039e-06,
      "loss": 0.1655,
      "step": 74590
    },
    {
      "epoch": 7.993142612236151,
      "grad_norm": 0.00599241629242897,
      "learning_rate": 4.013714775527697e-06,
      "loss": 0.0004,
      "step": 74600
    },
    {
      "epoch": 7.994214079074252,
      "grad_norm": 0.007082611322402954,
      "learning_rate": 4.011571841851495e-06,
      "loss": 0.0015,
      "step": 74610
    },
    {
      "epoch": 7.995285545912354,
      "grad_norm": 0.004343672655522823,
      "learning_rate": 4.009428908175292e-06,
      "loss": 0.0001,
      "step": 74620
    },
    {
      "epoch": 7.9963570127504555,
      "grad_norm": 0.00030884999432601035,
      "learning_rate": 4.0072859744990895e-06,
      "loss": 0.1034,
      "step": 74630
    },
    {
      "epoch": 7.997428479588557,
      "grad_norm": 0.050229232758283615,
      "learning_rate": 4.005143040822887e-06,
      "loss": 0.0004,
      "step": 74640
    },
    {
      "epoch": 7.998499946426658,
      "grad_norm": 0.0070381504483520985,
      "learning_rate": 4.003000107146684e-06,
      "loss": 0.0204,
      "step": 74650
    },
    {
      "epoch": 7.99957141326476,
      "grad_norm": 0.00015895107935648412,
      "learning_rate": 4.0008571734704816e-06,
      "loss": 0.0001,
      "step": 74660
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9486666666666667,
      "eval_f1": 0.8652668416447944,
      "eval_loss": 0.38336679339408875,
      "eval_precision": 0.8814616755793226,
      "eval_recall": 0.8496563573883161,
      "eval_runtime": 643.2602,
      "eval_samples_per_second": 9.327,
      "eval_steps_per_second": 3.109,
      "step": 74664
    },
    {
      "epoch": 8.00064288010286,
      "grad_norm": 0.00018846747116185725,
      "learning_rate": 3.998714239794279e-06,
      "loss": 0.0019,
      "step": 74670
    },
    {
      "epoch": 8.001714346940963,
      "grad_norm": 0.06739121675491333,
      "learning_rate": 3.996571306118076e-06,
      "loss": 0.1283,
      "step": 74680
    },
    {
      "epoch": 8.002785813779063,
      "grad_norm": 16.602893829345703,
      "learning_rate": 3.994428372441873e-06,
      "loss": 0.1329,
      "step": 74690
    },
    {
      "epoch": 8.003857280617165,
      "grad_norm": 0.004552325699478388,
      "learning_rate": 3.992285438765671e-06,
      "loss": 0.0011,
      "step": 74700
    },
    {
      "epoch": 8.004928747455267,
      "grad_norm": 0.004864961374551058,
      "learning_rate": 3.9901425050894675e-06,
      "loss": 0.0001,
      "step": 74710
    },
    {
      "epoch": 8.006000214293367,
      "grad_norm": 0.084713414311409,
      "learning_rate": 3.987999571413265e-06,
      "loss": 0.0002,
      "step": 74720
    },
    {
      "epoch": 8.00707168113147,
      "grad_norm": 0.007289936766028404,
      "learning_rate": 3.985856637737062e-06,
      "loss": 0.0002,
      "step": 74730
    },
    {
      "epoch": 8.00814314796957,
      "grad_norm": 0.004830952268093824,
      "learning_rate": 3.9837137040608596e-06,
      "loss": 0.001,
      "step": 74740
    },
    {
      "epoch": 8.009214614807671,
      "grad_norm": 0.19253471493721008,
      "learning_rate": 3.981570770384657e-06,
      "loss": 0.7168,
      "step": 74750
    },
    {
      "epoch": 8.010286081645773,
      "grad_norm": 0.004653871990740299,
      "learning_rate": 3.979427836708454e-06,
      "loss": 0.1013,
      "step": 74760
    },
    {
      "epoch": 8.011357548483874,
      "grad_norm": 0.00041517772478982806,
      "learning_rate": 3.977284903032252e-06,
      "loss": 0.0001,
      "step": 74770
    },
    {
      "epoch": 8.012429015321976,
      "grad_norm": 0.010829495266079903,
      "learning_rate": 3.975141969356049e-06,
      "loss": 0.0002,
      "step": 74780
    },
    {
      "epoch": 8.013500482160078,
      "grad_norm": 0.0003140330081805587,
      "learning_rate": 3.9729990356798455e-06,
      "loss": 0.0076,
      "step": 74790
    },
    {
      "epoch": 8.014571948998178,
      "grad_norm": 0.015957964584231377,
      "learning_rate": 3.970856102003644e-06,
      "loss": 0.0001,
      "step": 74800
    },
    {
      "epoch": 8.01564341583628,
      "grad_norm": 0.03443280979990959,
      "learning_rate": 3.96871316832744e-06,
      "loss": 0.0001,
      "step": 74810
    },
    {
      "epoch": 8.016714882674382,
      "grad_norm": 0.015020769089460373,
      "learning_rate": 3.966570234651238e-06,
      "loss": 0.1507,
      "step": 74820
    },
    {
      "epoch": 8.017786349512482,
      "grad_norm": 0.04171892628073692,
      "learning_rate": 3.964427300975035e-06,
      "loss": 0.0004,
      "step": 74830
    },
    {
      "epoch": 8.018857816350584,
      "grad_norm": 0.008798324503004551,
      "learning_rate": 3.962284367298832e-06,
      "loss": 0.1004,
      "step": 74840
    },
    {
      "epoch": 8.019929283188686,
      "grad_norm": 0.0007651811465620995,
      "learning_rate": 3.96014143362263e-06,
      "loss": 0.146,
      "step": 74850
    },
    {
      "epoch": 8.021000750026786,
      "grad_norm": 0.0004782116157002747,
      "learning_rate": 3.957998499946427e-06,
      "loss": 0.0002,
      "step": 74860
    },
    {
      "epoch": 8.022072216864888,
      "grad_norm": 0.0117611363530159,
      "learning_rate": 3.955855566270224e-06,
      "loss": 0.0002,
      "step": 74870
    },
    {
      "epoch": 8.023143683702989,
      "grad_norm": 0.003961016424000263,
      "learning_rate": 3.953712632594022e-06,
      "loss": 0.0002,
      "step": 74880
    },
    {
      "epoch": 8.02421515054109,
      "grad_norm": 0.0005093977670185268,
      "learning_rate": 3.951569698917819e-06,
      "loss": 0.0004,
      "step": 74890
    },
    {
      "epoch": 8.025286617379193,
      "grad_norm": 0.014290789142251015,
      "learning_rate": 3.949426765241616e-06,
      "loss": 0.3798,
      "step": 74900
    },
    {
      "epoch": 8.026358084217293,
      "grad_norm": 0.0003392149810679257,
      "learning_rate": 3.947283831565413e-06,
      "loss": 0.0005,
      "step": 74910
    },
    {
      "epoch": 8.027429551055395,
      "grad_norm": 0.008665241301059723,
      "learning_rate": 3.945140897889211e-06,
      "loss": 0.0284,
      "step": 74920
    },
    {
      "epoch": 8.028501017893497,
      "grad_norm": 0.0002428581501590088,
      "learning_rate": 3.942997964213008e-06,
      "loss": 0.0,
      "step": 74930
    },
    {
      "epoch": 8.029572484731597,
      "grad_norm": 0.03342747315764427,
      "learning_rate": 3.940855030536806e-06,
      "loss": 0.0001,
      "step": 74940
    },
    {
      "epoch": 8.030643951569699,
      "grad_norm": 0.006139183416962624,
      "learning_rate": 3.938712096860602e-06,
      "loss": 0.0001,
      "step": 74950
    },
    {
      "epoch": 8.031715418407801,
      "grad_norm": 0.004362460225820541,
      "learning_rate": 3.9365691631844e-06,
      "loss": 0.0001,
      "step": 74960
    },
    {
      "epoch": 8.032786885245901,
      "grad_norm": 0.0020718947052955627,
      "learning_rate": 3.934426229508197e-06,
      "loss": 0.0006,
      "step": 74970
    },
    {
      "epoch": 8.033858352084003,
      "grad_norm": 0.006775461137294769,
      "learning_rate": 3.932283295831994e-06,
      "loss": 0.0004,
      "step": 74980
    },
    {
      "epoch": 8.034929818922105,
      "grad_norm": 0.00781147601082921,
      "learning_rate": 3.930140362155792e-06,
      "loss": 0.2228,
      "step": 74990
    },
    {
      "epoch": 8.036001285760205,
      "grad_norm": 0.12952920794487,
      "learning_rate": 3.927997428479589e-06,
      "loss": 0.0676,
      "step": 75000
    },
    {
      "epoch": 8.037072752598307,
      "grad_norm": 0.00013757678971160203,
      "learning_rate": 3.9258544948033865e-06,
      "loss": 0.0001,
      "step": 75010
    },
    {
      "epoch": 8.038144219436408,
      "grad_norm": 0.013083484955132008,
      "learning_rate": 3.923711561127184e-06,
      "loss": 0.0001,
      "step": 75020
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 0.0003571503621060401,
      "learning_rate": 3.92156862745098e-06,
      "loss": 0.0003,
      "step": 75030
    },
    {
      "epoch": 8.040287153112612,
      "grad_norm": 0.0005235410062596202,
      "learning_rate": 3.9194256937747785e-06,
      "loss": 0.0001,
      "step": 75040
    },
    {
      "epoch": 8.041358619950712,
      "grad_norm": 0.00016336645057890564,
      "learning_rate": 3.917282760098575e-06,
      "loss": 0.2553,
      "step": 75050
    },
    {
      "epoch": 8.042430086788814,
      "grad_norm": 0.013233032077550888,
      "learning_rate": 3.915139826422372e-06,
      "loss": 0.0001,
      "step": 75060
    },
    {
      "epoch": 8.043501553626916,
      "grad_norm": 0.00813757162541151,
      "learning_rate": 3.91299689274617e-06,
      "loss": 0.0003,
      "step": 75070
    },
    {
      "epoch": 8.044573020465016,
      "grad_norm": 0.00024232229043263942,
      "learning_rate": 3.910853959069967e-06,
      "loss": 0.0003,
      "step": 75080
    },
    {
      "epoch": 8.045644487303118,
      "grad_norm": 0.00020382086222525686,
      "learning_rate": 3.9087110253937645e-06,
      "loss": 0.0879,
      "step": 75090
    },
    {
      "epoch": 8.04671595414122,
      "grad_norm": 12.368073463439941,
      "learning_rate": 3.906568091717562e-06,
      "loss": 0.0143,
      "step": 75100
    },
    {
      "epoch": 8.04778742097932,
      "grad_norm": 0.008726600557565689,
      "learning_rate": 3.904425158041359e-06,
      "loss": 0.0001,
      "step": 75110
    },
    {
      "epoch": 8.048858887817422,
      "grad_norm": 0.011876249685883522,
      "learning_rate": 3.9022822243651565e-06,
      "loss": 0.2059,
      "step": 75120
    },
    {
      "epoch": 8.049930354655523,
      "grad_norm": 0.0003568533284123987,
      "learning_rate": 3.900139290688954e-06,
      "loss": 0.0004,
      "step": 75130
    },
    {
      "epoch": 8.051001821493625,
      "grad_norm": 0.3374180495738983,
      "learning_rate": 3.897996357012751e-06,
      "loss": 0.1525,
      "step": 75140
    },
    {
      "epoch": 8.052073288331727,
      "grad_norm": 30.011276245117188,
      "learning_rate": 3.895853423336548e-06,
      "loss": 0.0161,
      "step": 75150
    },
    {
      "epoch": 8.053144755169827,
      "grad_norm": 0.00030760164372622967,
      "learning_rate": 3.893710489660346e-06,
      "loss": 0.0001,
      "step": 75160
    },
    {
      "epoch": 8.054216222007929,
      "grad_norm": 0.0006552538834512234,
      "learning_rate": 3.8915675559841425e-06,
      "loss": 0.0001,
      "step": 75170
    },
    {
      "epoch": 8.05528768884603,
      "grad_norm": 27.42618179321289,
      "learning_rate": 3.88942462230794e-06,
      "loss": 0.1826,
      "step": 75180
    },
    {
      "epoch": 8.056359155684131,
      "grad_norm": 0.0037086084485054016,
      "learning_rate": 3.887281688631737e-06,
      "loss": 0.2147,
      "step": 75190
    },
    {
      "epoch": 8.057430622522233,
      "grad_norm": 0.00014727427333127707,
      "learning_rate": 3.8851387549555345e-06,
      "loss": 0.2545,
      "step": 75200
    },
    {
      "epoch": 8.058502089360335,
      "grad_norm": 0.012898582965135574,
      "learning_rate": 3.882995821279332e-06,
      "loss": 0.2915,
      "step": 75210
    },
    {
      "epoch": 8.059573556198435,
      "grad_norm": 0.00030675489688292146,
      "learning_rate": 3.880852887603128e-06,
      "loss": 0.1405,
      "step": 75220
    },
    {
      "epoch": 8.060645023036537,
      "grad_norm": 0.010544614866375923,
      "learning_rate": 3.878709953926927e-06,
      "loss": 0.0001,
      "step": 75230
    },
    {
      "epoch": 8.06171648987464,
      "grad_norm": 0.000692675297614187,
      "learning_rate": 3.876567020250723e-06,
      "loss": 0.0001,
      "step": 75240
    },
    {
      "epoch": 8.06278795671274,
      "grad_norm": 0.005788498092442751,
      "learning_rate": 3.8744240865745205e-06,
      "loss": 0.1673,
      "step": 75250
    },
    {
      "epoch": 8.063859423550841,
      "grad_norm": 0.00030697902548126876,
      "learning_rate": 3.872281152898318e-06,
      "loss": 0.0001,
      "step": 75260
    },
    {
      "epoch": 8.064930890388942,
      "grad_norm": 0.008552971296012402,
      "learning_rate": 3.870138219222115e-06,
      "loss": 0.0003,
      "step": 75270
    },
    {
      "epoch": 8.066002357227044,
      "grad_norm": 0.011167760007083416,
      "learning_rate": 3.8679952855459125e-06,
      "loss": 0.0005,
      "step": 75280
    },
    {
      "epoch": 8.067073824065146,
      "grad_norm": 0.062233537435531616,
      "learning_rate": 3.86585235186971e-06,
      "loss": 0.0002,
      "step": 75290
    },
    {
      "epoch": 8.068145290903246,
      "grad_norm": 21.00615882873535,
      "learning_rate": 3.863709418193507e-06,
      "loss": 0.1917,
      "step": 75300
    },
    {
      "epoch": 8.069216757741348,
      "grad_norm": 0.03644835948944092,
      "learning_rate": 3.861566484517305e-06,
      "loss": 0.2575,
      "step": 75310
    },
    {
      "epoch": 8.07028822457945,
      "grad_norm": 0.007800750900059938,
      "learning_rate": 3.859423550841102e-06,
      "loss": 0.0001,
      "step": 75320
    },
    {
      "epoch": 8.07135969141755,
      "grad_norm": 0.008979011327028275,
      "learning_rate": 3.857280617164899e-06,
      "loss": 0.0003,
      "step": 75330
    },
    {
      "epoch": 8.072431158255652,
      "grad_norm": 0.01919546164572239,
      "learning_rate": 3.855137683488696e-06,
      "loss": 0.0008,
      "step": 75340
    },
    {
      "epoch": 8.073502625093754,
      "grad_norm": 30.02077293395996,
      "learning_rate": 3.852994749812494e-06,
      "loss": 0.1241,
      "step": 75350
    },
    {
      "epoch": 8.074574091931854,
      "grad_norm": 0.013721294701099396,
      "learning_rate": 3.8508518161362905e-06,
      "loss": 0.1962,
      "step": 75360
    },
    {
      "epoch": 8.075645558769956,
      "grad_norm": 0.006796868052333593,
      "learning_rate": 3.848708882460088e-06,
      "loss": 0.0001,
      "step": 75370
    },
    {
      "epoch": 8.076717025608058,
      "grad_norm": 0.001132106757722795,
      "learning_rate": 3.846565948783885e-06,
      "loss": 0.0007,
      "step": 75380
    },
    {
      "epoch": 8.077788492446158,
      "grad_norm": 0.013797084800899029,
      "learning_rate": 3.844423015107683e-06,
      "loss": 0.0005,
      "step": 75390
    },
    {
      "epoch": 8.07885995928426,
      "grad_norm": 0.00015553459525108337,
      "learning_rate": 3.84228008143148e-06,
      "loss": 0.0011,
      "step": 75400
    },
    {
      "epoch": 8.07993142612236,
      "grad_norm": 0.08359027653932571,
      "learning_rate": 3.840137147755277e-06,
      "loss": 0.0002,
      "step": 75410
    },
    {
      "epoch": 8.081002892960463,
      "grad_norm": 0.0028573728632181883,
      "learning_rate": 3.837994214079075e-06,
      "loss": 0.0009,
      "step": 75420
    },
    {
      "epoch": 8.082074359798565,
      "grad_norm": 0.0022144587710499763,
      "learning_rate": 3.835851280402872e-06,
      "loss": 0.1051,
      "step": 75430
    },
    {
      "epoch": 8.083145826636665,
      "grad_norm": 0.00549260014668107,
      "learning_rate": 3.8337083467266685e-06,
      "loss": 0.0085,
      "step": 75440
    },
    {
      "epoch": 8.084217293474767,
      "grad_norm": 0.011466627940535545,
      "learning_rate": 3.831565413050467e-06,
      "loss": 0.1999,
      "step": 75450
    },
    {
      "epoch": 8.085288760312869,
      "grad_norm": 0.00017094610666390508,
      "learning_rate": 3.829422479374263e-06,
      "loss": 0.201,
      "step": 75460
    },
    {
      "epoch": 8.08636022715097,
      "grad_norm": 0.0194145068526268,
      "learning_rate": 3.8272795456980614e-06,
      "loss": 0.0043,
      "step": 75470
    },
    {
      "epoch": 8.087431693989071,
      "grad_norm": 0.0001723731984384358,
      "learning_rate": 3.825136612021858e-06,
      "loss": 0.0001,
      "step": 75480
    },
    {
      "epoch": 8.088503160827173,
      "grad_norm": 0.006399264559149742,
      "learning_rate": 3.822993678345655e-06,
      "loss": 0.0002,
      "step": 75490
    },
    {
      "epoch": 8.089574627665273,
      "grad_norm": 0.018431028351187706,
      "learning_rate": 3.820850744669453e-06,
      "loss": 0.0016,
      "step": 75500
    },
    {
      "epoch": 8.090646094503375,
      "grad_norm": 0.004847047850489616,
      "learning_rate": 3.81870781099325e-06,
      "loss": 0.0005,
      "step": 75510
    },
    {
      "epoch": 8.091717561341477,
      "grad_norm": 0.00016851176042109728,
      "learning_rate": 3.816564877317047e-06,
      "loss": 0.0001,
      "step": 75520
    },
    {
      "epoch": 8.092789028179578,
      "grad_norm": 0.00017755776934791356,
      "learning_rate": 3.8144219436408447e-06,
      "loss": 0.0002,
      "step": 75530
    },
    {
      "epoch": 8.09386049501768,
      "grad_norm": 0.0057107326574623585,
      "learning_rate": 3.8122790099646417e-06,
      "loss": 0.1832,
      "step": 75540
    },
    {
      "epoch": 8.09493196185578,
      "grad_norm": 0.00020933402993250638,
      "learning_rate": 3.8101360762884394e-06,
      "loss": 0.0001,
      "step": 75550
    },
    {
      "epoch": 8.096003428693882,
      "grad_norm": 0.0044113388285040855,
      "learning_rate": 3.8079931426122364e-06,
      "loss": 0.4332,
      "step": 75560
    },
    {
      "epoch": 8.097074895531984,
      "grad_norm": 0.009046454913914204,
      "learning_rate": 3.8058502089360337e-06,
      "loss": 0.0005,
      "step": 75570
    },
    {
      "epoch": 8.098146362370084,
      "grad_norm": 0.008310175500810146,
      "learning_rate": 3.8037072752598307e-06,
      "loss": 0.064,
      "step": 75580
    },
    {
      "epoch": 8.099217829208186,
      "grad_norm": 0.00016925428644753993,
      "learning_rate": 3.8015643415836284e-06,
      "loss": 0.087,
      "step": 75590
    },
    {
      "epoch": 8.100289296046288,
      "grad_norm": 0.00012262996460776776,
      "learning_rate": 3.7994214079074254e-06,
      "loss": 0.0002,
      "step": 75600
    },
    {
      "epoch": 8.101360762884388,
      "grad_norm": 0.00018015566456597298,
      "learning_rate": 3.797278474231223e-06,
      "loss": 0.232,
      "step": 75610
    },
    {
      "epoch": 8.10243222972249,
      "grad_norm": 0.00019839679589495063,
      "learning_rate": 3.79513554055502e-06,
      "loss": 0.1437,
      "step": 75620
    },
    {
      "epoch": 8.103503696560592,
      "grad_norm": 0.5236401557922363,
      "learning_rate": 3.7929926068788174e-06,
      "loss": 0.2003,
      "step": 75630
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 5.518227577209473,
      "learning_rate": 3.7908496732026144e-06,
      "loss": 0.0011,
      "step": 75640
    },
    {
      "epoch": 8.105646630236794,
      "grad_norm": 0.006319523323327303,
      "learning_rate": 3.788706739526412e-06,
      "loss": 0.0002,
      "step": 75650
    },
    {
      "epoch": 8.106718097074895,
      "grad_norm": 0.19676564633846283,
      "learning_rate": 3.786563805850209e-06,
      "loss": 0.0003,
      "step": 75660
    },
    {
      "epoch": 8.107789563912997,
      "grad_norm": 0.00018486101180315018,
      "learning_rate": 3.784420872174007e-06,
      "loss": 0.0002,
      "step": 75670
    },
    {
      "epoch": 8.108861030751099,
      "grad_norm": 0.008392400108277798,
      "learning_rate": 3.782277938497804e-06,
      "loss": 0.0001,
      "step": 75680
    },
    {
      "epoch": 8.109932497589199,
      "grad_norm": 0.00016755081014707685,
      "learning_rate": 3.780135004821601e-06,
      "loss": 0.0002,
      "step": 75690
    },
    {
      "epoch": 8.1110039644273,
      "grad_norm": 0.00012834393419325352,
      "learning_rate": 3.777992071145398e-06,
      "loss": 0.0001,
      "step": 75700
    },
    {
      "epoch": 8.112075431265403,
      "grad_norm": 52.319610595703125,
      "learning_rate": 3.775849137469196e-06,
      "loss": 0.1682,
      "step": 75710
    },
    {
      "epoch": 8.113146898103503,
      "grad_norm": 0.010728921741247177,
      "learning_rate": 3.773706203792993e-06,
      "loss": 0.1327,
      "step": 75720
    },
    {
      "epoch": 8.114218364941605,
      "grad_norm": 0.006339570507407188,
      "learning_rate": 3.77156327011679e-06,
      "loss": 0.0155,
      "step": 75730
    },
    {
      "epoch": 8.115289831779707,
      "grad_norm": 0.0001503132370999083,
      "learning_rate": 3.7694203364405875e-06,
      "loss": 0.0001,
      "step": 75740
    },
    {
      "epoch": 8.116361298617807,
      "grad_norm": 0.0013932501897215843,
      "learning_rate": 3.767277402764385e-06,
      "loss": 0.155,
      "step": 75750
    },
    {
      "epoch": 8.11743276545591,
      "grad_norm": 0.00036079552955925465,
      "learning_rate": 3.765134469088182e-06,
      "loss": 0.0001,
      "step": 75760
    },
    {
      "epoch": 8.118504232294011,
      "grad_norm": 0.008980135433375835,
      "learning_rate": 3.7629915354119796e-06,
      "loss": 0.0001,
      "step": 75770
    },
    {
      "epoch": 8.119575699132112,
      "grad_norm": 0.00015508354408666492,
      "learning_rate": 3.7608486017357765e-06,
      "loss": 0.0004,
      "step": 75780
    },
    {
      "epoch": 8.120647165970214,
      "grad_norm": 0.006446486338973045,
      "learning_rate": 3.758705668059574e-06,
      "loss": 0.1019,
      "step": 75790
    },
    {
      "epoch": 8.121718632808314,
      "grad_norm": 0.0021342255640774965,
      "learning_rate": 3.7565627343833712e-06,
      "loss": 0.0622,
      "step": 75800
    },
    {
      "epoch": 8.122790099646416,
      "grad_norm": 0.0008902735426090658,
      "learning_rate": 3.7544198007071686e-06,
      "loss": 0.0,
      "step": 75810
    },
    {
      "epoch": 8.123861566484518,
      "grad_norm": 0.004235309548676014,
      "learning_rate": 3.7522768670309655e-06,
      "loss": 0.0035,
      "step": 75820
    },
    {
      "epoch": 8.124933033322618,
      "grad_norm": 0.005577577743679285,
      "learning_rate": 3.7501339333547633e-06,
      "loss": 0.0001,
      "step": 75830
    },
    {
      "epoch": 8.12600450016072,
      "grad_norm": 0.00013850598770659417,
      "learning_rate": 3.7479909996785602e-06,
      "loss": 0.0001,
      "step": 75840
    },
    {
      "epoch": 8.127075966998822,
      "grad_norm": 0.0003156470775138587,
      "learning_rate": 3.7458480660023576e-06,
      "loss": 0.0002,
      "step": 75850
    },
    {
      "epoch": 8.128147433836922,
      "grad_norm": 0.0001227247848873958,
      "learning_rate": 3.743705132326155e-06,
      "loss": 0.0005,
      "step": 75860
    },
    {
      "epoch": 8.129218900675024,
      "grad_norm": 0.00016494942246936262,
      "learning_rate": 3.7415621986499523e-06,
      "loss": 0.0002,
      "step": 75870
    },
    {
      "epoch": 8.130290367513126,
      "grad_norm": 0.012877539731562138,
      "learning_rate": 3.7394192649737492e-06,
      "loss": 0.0001,
      "step": 75880
    },
    {
      "epoch": 8.131361834351226,
      "grad_norm": 0.00013247408787719905,
      "learning_rate": 3.737276331297547e-06,
      "loss": 0.0002,
      "step": 75890
    },
    {
      "epoch": 8.132433301189328,
      "grad_norm": 0.003939695656299591,
      "learning_rate": 3.735133397621344e-06,
      "loss": 0.0006,
      "step": 75900
    },
    {
      "epoch": 8.13350476802743,
      "grad_norm": 0.004975405987352133,
      "learning_rate": 3.7329904639451413e-06,
      "loss": 0.0003,
      "step": 75910
    },
    {
      "epoch": 8.13457623486553,
      "grad_norm": 0.007286365143954754,
      "learning_rate": 3.7308475302689382e-06,
      "loss": 0.0015,
      "step": 75920
    },
    {
      "epoch": 8.135647701703633,
      "grad_norm": 0.00011738889588741586,
      "learning_rate": 3.728704596592736e-06,
      "loss": 0.1939,
      "step": 75930
    },
    {
      "epoch": 8.136719168541733,
      "grad_norm": 0.01536807045340538,
      "learning_rate": 3.726561662916533e-06,
      "loss": 0.2186,
      "step": 75940
    },
    {
      "epoch": 8.137790635379835,
      "grad_norm": 0.010395165532827377,
      "learning_rate": 3.7244187292403307e-06,
      "loss": 0.0002,
      "step": 75950
    },
    {
      "epoch": 8.138862102217937,
      "grad_norm": 0.00011924985301448032,
      "learning_rate": 3.7222757955641276e-06,
      "loss": 0.0037,
      "step": 75960
    },
    {
      "epoch": 8.139933569056037,
      "grad_norm": 0.0055771213956177235,
      "learning_rate": 3.720132861887925e-06,
      "loss": 0.2024,
      "step": 75970
    },
    {
      "epoch": 8.141005035894139,
      "grad_norm": 0.006941391155123711,
      "learning_rate": 3.717989928211722e-06,
      "loss": 0.0001,
      "step": 75980
    },
    {
      "epoch": 8.142076502732241,
      "grad_norm": 0.00011370202992111444,
      "learning_rate": 3.7158469945355197e-06,
      "loss": 0.0005,
      "step": 75990
    },
    {
      "epoch": 8.143147969570341,
      "grad_norm": 0.009862487204372883,
      "learning_rate": 3.7137040608593166e-06,
      "loss": 0.1243,
      "step": 76000
    },
    {
      "epoch": 8.144219436408443,
      "grad_norm": 0.004680314101278782,
      "learning_rate": 3.7115611271831144e-06,
      "loss": 0.2459,
      "step": 76010
    },
    {
      "epoch": 8.145290903246545,
      "grad_norm": 0.00011992650979664177,
      "learning_rate": 3.7094181935069114e-06,
      "loss": 0.2239,
      "step": 76020
    },
    {
      "epoch": 8.146362370084645,
      "grad_norm": 0.0003082523471675813,
      "learning_rate": 3.7072752598307087e-06,
      "loss": 0.0004,
      "step": 76030
    },
    {
      "epoch": 8.147433836922747,
      "grad_norm": 0.015285021625459194,
      "learning_rate": 3.7051323261545056e-06,
      "loss": 0.0001,
      "step": 76040
    },
    {
      "epoch": 8.14850530376085,
      "grad_norm": 0.008682847023010254,
      "learning_rate": 3.7029893924783034e-06,
      "loss": 0.0686,
      "step": 76050
    },
    {
      "epoch": 8.14957677059895,
      "grad_norm": 30.41248321533203,
      "learning_rate": 3.7008464588021004e-06,
      "loss": 0.1752,
      "step": 76060
    },
    {
      "epoch": 8.150648237437052,
      "grad_norm": 0.005114471539855003,
      "learning_rate": 3.6987035251258977e-06,
      "loss": 0.0003,
      "step": 76070
    },
    {
      "epoch": 8.151719704275152,
      "grad_norm": 0.008238265290856361,
      "learning_rate": 3.696560591449695e-06,
      "loss": 0.1756,
      "step": 76080
    },
    {
      "epoch": 8.152791171113254,
      "grad_norm": 0.006287730764597654,
      "learning_rate": 3.6944176577734924e-06,
      "loss": 0.0002,
      "step": 76090
    },
    {
      "epoch": 8.153862637951356,
      "grad_norm": 0.05627163127064705,
      "learning_rate": 3.6922747240972894e-06,
      "loss": 0.0002,
      "step": 76100
    },
    {
      "epoch": 8.154934104789456,
      "grad_norm": 0.023116271942853928,
      "learning_rate": 3.690131790421087e-06,
      "loss": 0.0002,
      "step": 76110
    },
    {
      "epoch": 8.156005571627558,
      "grad_norm": 0.00691740307956934,
      "learning_rate": 3.687988856744884e-06,
      "loss": 0.0002,
      "step": 76120
    },
    {
      "epoch": 8.15707703846566,
      "grad_norm": 0.0023433805909007788,
      "learning_rate": 3.685845923068681e-06,
      "loss": 0.0003,
      "step": 76130
    },
    {
      "epoch": 8.15814850530376,
      "grad_norm": 0.00017067916633095592,
      "learning_rate": 3.6837029893924788e-06,
      "loss": 0.0031,
      "step": 76140
    },
    {
      "epoch": 8.159219972141862,
      "grad_norm": 0.005099899601191282,
      "learning_rate": 3.6815600557162757e-06,
      "loss": 0.0446,
      "step": 76150
    },
    {
      "epoch": 8.160291438979964,
      "grad_norm": 0.005655507557094097,
      "learning_rate": 3.679417122040073e-06,
      "loss": 0.0,
      "step": 76160
    },
    {
      "epoch": 8.161362905818065,
      "grad_norm": 0.00012926655472256243,
      "learning_rate": 3.67727418836387e-06,
      "loss": 0.0001,
      "step": 76170
    },
    {
      "epoch": 8.162434372656167,
      "grad_norm": 0.012272819876670837,
      "learning_rate": 3.6751312546876678e-06,
      "loss": 0.0006,
      "step": 76180
    },
    {
      "epoch": 8.163505839494267,
      "grad_norm": 1017.1504516601562,
      "learning_rate": 3.6729883210114647e-06,
      "loss": 0.1458,
      "step": 76190
    },
    {
      "epoch": 8.164577306332369,
      "grad_norm": 0.005279350560158491,
      "learning_rate": 3.6708453873352625e-06,
      "loss": 0.0021,
      "step": 76200
    },
    {
      "epoch": 8.16564877317047,
      "grad_norm": 0.2408810555934906,
      "learning_rate": 3.6687024536590594e-06,
      "loss": 0.0004,
      "step": 76210
    },
    {
      "epoch": 8.166720240008571,
      "grad_norm": 0.00012491969391703606,
      "learning_rate": 3.6665595199828568e-06,
      "loss": 0.0001,
      "step": 76220
    },
    {
      "epoch": 8.167791706846673,
      "grad_norm": 0.00010094920435221866,
      "learning_rate": 3.6644165863066537e-06,
      "loss": 0.0001,
      "step": 76230
    },
    {
      "epoch": 8.168863173684775,
      "grad_norm": 0.0001578290102770552,
      "learning_rate": 3.6622736526304515e-06,
      "loss": 0.2188,
      "step": 76240
    },
    {
      "epoch": 8.169934640522875,
      "grad_norm": 0.0033676254097372293,
      "learning_rate": 3.6601307189542484e-06,
      "loss": 0.0001,
      "step": 76250
    },
    {
      "epoch": 8.171006107360977,
      "grad_norm": 0.0001485354732722044,
      "learning_rate": 3.6579877852780458e-06,
      "loss": 0.0,
      "step": 76260
    },
    {
      "epoch": 8.17207757419908,
      "grad_norm": 0.0024079950526356697,
      "learning_rate": 3.655844851601843e-06,
      "loss": 0.329,
      "step": 76270
    },
    {
      "epoch": 8.17314904103718,
      "grad_norm": 0.0006564591312780976,
      "learning_rate": 3.6537019179256405e-06,
      "loss": 0.0049,
      "step": 76280
    },
    {
      "epoch": 8.174220507875281,
      "grad_norm": 0.002687494270503521,
      "learning_rate": 3.6515589842494374e-06,
      "loss": 0.0,
      "step": 76290
    },
    {
      "epoch": 8.175291974713383,
      "grad_norm": 0.00019753201922867447,
      "learning_rate": 3.649416050573235e-06,
      "loss": 0.254,
      "step": 76300
    },
    {
      "epoch": 8.176363441551484,
      "grad_norm": 0.00018431646458338946,
      "learning_rate": 3.647273116897032e-06,
      "loss": 0.0003,
      "step": 76310
    },
    {
      "epoch": 8.177434908389586,
      "grad_norm": 0.00801322516053915,
      "learning_rate": 3.6451301832208295e-06,
      "loss": 0.0001,
      "step": 76320
    },
    {
      "epoch": 8.178506375227686,
      "grad_norm": 0.00017731872503645718,
      "learning_rate": 3.642987249544627e-06,
      "loss": 0.1302,
      "step": 76330
    },
    {
      "epoch": 8.179577842065788,
      "grad_norm": 0.0037815587129443884,
      "learning_rate": 3.640844315868424e-06,
      "loss": 0.0001,
      "step": 76340
    },
    {
      "epoch": 8.18064930890389,
      "grad_norm": 0.00013059024058748037,
      "learning_rate": 3.638701382192221e-06,
      "loss": 0.0001,
      "step": 76350
    },
    {
      "epoch": 8.18172077574199,
      "grad_norm": 0.013639520853757858,
      "learning_rate": 3.636558448516019e-06,
      "loss": 0.2374,
      "step": 76360
    },
    {
      "epoch": 8.182792242580092,
      "grad_norm": 0.00023982975108083338,
      "learning_rate": 3.634415514839816e-06,
      "loss": 0.0572,
      "step": 76370
    },
    {
      "epoch": 8.183863709418194,
      "grad_norm": 0.0003102903428953141,
      "learning_rate": 3.632272581163613e-06,
      "loss": 0.0001,
      "step": 76380
    },
    {
      "epoch": 8.184935176256294,
      "grad_norm": 0.0004639391554519534,
      "learning_rate": 3.6301296474874106e-06,
      "loss": 0.0001,
      "step": 76390
    },
    {
      "epoch": 8.186006643094396,
      "grad_norm": 0.00018177623860538006,
      "learning_rate": 3.627986713811208e-06,
      "loss": 0.0,
      "step": 76400
    },
    {
      "epoch": 8.187078109932498,
      "grad_norm": 0.00015504320617765188,
      "learning_rate": 3.625843780135005e-06,
      "loss": 0.1809,
      "step": 76410
    },
    {
      "epoch": 8.188149576770599,
      "grad_norm": 0.0064941830933094025,
      "learning_rate": 3.6237008464588026e-06,
      "loss": 0.0002,
      "step": 76420
    },
    {
      "epoch": 8.1892210436087,
      "grad_norm": 0.00024972547544166446,
      "learning_rate": 3.6215579127825996e-06,
      "loss": 0.0001,
      "step": 76430
    },
    {
      "epoch": 8.190292510446803,
      "grad_norm": 0.002666289219632745,
      "learning_rate": 3.619414979106397e-06,
      "loss": 0.2552,
      "step": 76440
    },
    {
      "epoch": 8.191363977284903,
      "grad_norm": 0.011951494961977005,
      "learning_rate": 3.6172720454301943e-06,
      "loss": 0.0001,
      "step": 76450
    },
    {
      "epoch": 8.192435444123005,
      "grad_norm": 0.00033288891427218914,
      "learning_rate": 3.6151291117539916e-06,
      "loss": 0.0007,
      "step": 76460
    },
    {
      "epoch": 8.193506910961105,
      "grad_norm": 0.007216154132038355,
      "learning_rate": 3.6129861780777886e-06,
      "loss": 0.3061,
      "step": 76470
    },
    {
      "epoch": 8.194578377799207,
      "grad_norm": 0.00020946210133843124,
      "learning_rate": 3.6108432444015863e-06,
      "loss": 0.0001,
      "step": 76480
    },
    {
      "epoch": 8.195649844637309,
      "grad_norm": 0.02745150774717331,
      "learning_rate": 3.6087003107253833e-06,
      "loss": 0.1438,
      "step": 76490
    },
    {
      "epoch": 8.19672131147541,
      "grad_norm": 0.0001965408882824704,
      "learning_rate": 3.6065573770491806e-06,
      "loss": 0.1395,
      "step": 76500
    },
    {
      "epoch": 8.197792778313511,
      "grad_norm": 0.00038031343137845397,
      "learning_rate": 3.6044144433729776e-06,
      "loss": 0.0001,
      "step": 76510
    },
    {
      "epoch": 8.198864245151613,
      "grad_norm": 0.025080475956201553,
      "learning_rate": 3.6022715096967753e-06,
      "loss": 0.0011,
      "step": 76520
    },
    {
      "epoch": 8.199935711989713,
      "grad_norm": 0.00023234776745084673,
      "learning_rate": 3.6001285760205723e-06,
      "loss": 0.0009,
      "step": 76530
    },
    {
      "epoch": 8.201007178827815,
      "grad_norm": 0.00026236724806949496,
      "learning_rate": 3.59798564234437e-06,
      "loss": 0.0003,
      "step": 76540
    },
    {
      "epoch": 8.202078645665917,
      "grad_norm": 0.004892752040177584,
      "learning_rate": 3.595842708668167e-06,
      "loss": 0.0001,
      "step": 76550
    },
    {
      "epoch": 8.203150112504018,
      "grad_norm": 0.005597911775112152,
      "learning_rate": 3.5936997749919643e-06,
      "loss": 0.0011,
      "step": 76560
    },
    {
      "epoch": 8.20422157934212,
      "grad_norm": 0.00022862738114781678,
      "learning_rate": 3.5915568413157613e-06,
      "loss": 0.2937,
      "step": 76570
    },
    {
      "epoch": 8.205293046180222,
      "grad_norm": 0.01825420930981636,
      "learning_rate": 3.589413907639559e-06,
      "loss": 0.0002,
      "step": 76580
    },
    {
      "epoch": 8.206364513018322,
      "grad_norm": 0.38246864080429077,
      "learning_rate": 3.587270973963356e-06,
      "loss": 0.0006,
      "step": 76590
    },
    {
      "epoch": 8.207435979856424,
      "grad_norm": 0.008488085120916367,
      "learning_rate": 3.5851280402871538e-06,
      "loss": 0.0022,
      "step": 76600
    },
    {
      "epoch": 8.208507446694524,
      "grad_norm": 0.008558743633329868,
      "learning_rate": 3.5829851066109507e-06,
      "loss": 0.0005,
      "step": 76610
    },
    {
      "epoch": 8.209578913532626,
      "grad_norm": 0.010173872113227844,
      "learning_rate": 3.580842172934748e-06,
      "loss": 0.1884,
      "step": 76620
    },
    {
      "epoch": 8.210650380370728,
      "grad_norm": 0.0026701875030994415,
      "learning_rate": 3.578699239258545e-06,
      "loss": 0.1608,
      "step": 76630
    },
    {
      "epoch": 8.211721847208828,
      "grad_norm": 0.00014057850057724863,
      "learning_rate": 3.5765563055823428e-06,
      "loss": 0.002,
      "step": 76640
    },
    {
      "epoch": 8.21279331404693,
      "grad_norm": 0.00429080193862319,
      "learning_rate": 3.5744133719061397e-06,
      "loss": 0.1461,
      "step": 76650
    },
    {
      "epoch": 8.213864780885032,
      "grad_norm": 0.026100775226950645,
      "learning_rate": 3.572270438229937e-06,
      "loss": 0.0268,
      "step": 76660
    },
    {
      "epoch": 8.214936247723132,
      "grad_norm": 0.00030520130530931056,
      "learning_rate": 3.5701275045537344e-06,
      "loss": 0.0001,
      "step": 76670
    },
    {
      "epoch": 8.216007714561234,
      "grad_norm": 0.007744796108454466,
      "learning_rate": 3.5679845708775318e-06,
      "loss": 0.0003,
      "step": 76680
    },
    {
      "epoch": 8.217079181399336,
      "grad_norm": 0.0001644278527237475,
      "learning_rate": 3.5658416372013287e-06,
      "loss": 0.0005,
      "step": 76690
    },
    {
      "epoch": 8.218150648237437,
      "grad_norm": 0.0021870448254048824,
      "learning_rate": 3.5636987035251265e-06,
      "loss": 0.0002,
      "step": 76700
    },
    {
      "epoch": 8.219222115075539,
      "grad_norm": 0.00017015838238876313,
      "learning_rate": 3.5615557698489234e-06,
      "loss": 0.001,
      "step": 76710
    },
    {
      "epoch": 8.220293581913639,
      "grad_norm": 0.00023086441797204316,
      "learning_rate": 3.5594128361727208e-06,
      "loss": 0.2332,
      "step": 76720
    },
    {
      "epoch": 8.221365048751741,
      "grad_norm": 0.00477891881018877,
      "learning_rate": 3.557269902496518e-06,
      "loss": 0.0004,
      "step": 76730
    },
    {
      "epoch": 8.222436515589843,
      "grad_norm": 0.004247871693223715,
      "learning_rate": 3.5551269688203155e-06,
      "loss": 0.2765,
      "step": 76740
    },
    {
      "epoch": 8.223507982427943,
      "grad_norm": 0.06384339928627014,
      "learning_rate": 3.5529840351441124e-06,
      "loss": 0.2485,
      "step": 76750
    },
    {
      "epoch": 8.224579449266045,
      "grad_norm": 0.012739100493490696,
      "learning_rate": 3.55084110146791e-06,
      "loss": 0.0005,
      "step": 76760
    },
    {
      "epoch": 8.225650916104147,
      "grad_norm": 0.004887066315859556,
      "learning_rate": 3.548698167791707e-06,
      "loss": 0.027,
      "step": 76770
    },
    {
      "epoch": 8.226722382942247,
      "grad_norm": 0.010338326916098595,
      "learning_rate": 3.5465552341155045e-06,
      "loss": 0.1555,
      "step": 76780
    },
    {
      "epoch": 8.22779384978035,
      "grad_norm": 0.004834924358874559,
      "learning_rate": 3.544412300439302e-06,
      "loss": 0.1336,
      "step": 76790
    },
    {
      "epoch": 8.228865316618451,
      "grad_norm": 0.1668577343225479,
      "learning_rate": 3.542269366763099e-06,
      "loss": 0.0003,
      "step": 76800
    },
    {
      "epoch": 8.229936783456552,
      "grad_norm": 0.00018756897770799696,
      "learning_rate": 3.540126433086896e-06,
      "loss": 0.0006,
      "step": 76810
    },
    {
      "epoch": 8.231008250294654,
      "grad_norm": 0.00013202399713918567,
      "learning_rate": 3.537983499410694e-06,
      "loss": 0.0015,
      "step": 76820
    },
    {
      "epoch": 8.232079717132756,
      "grad_norm": 0.003945231903344393,
      "learning_rate": 3.535840565734491e-06,
      "loss": 0.2224,
      "step": 76830
    },
    {
      "epoch": 8.233151183970856,
      "grad_norm": 0.06025484576821327,
      "learning_rate": 3.533697632058288e-06,
      "loss": 0.0008,
      "step": 76840
    },
    {
      "epoch": 8.234222650808958,
      "grad_norm": 0.00014684066991321743,
      "learning_rate": 3.531554698382085e-06,
      "loss": 0.0008,
      "step": 76850
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 0.005117792636156082,
      "learning_rate": 3.529411764705883e-06,
      "loss": 0.0447,
      "step": 76860
    },
    {
      "epoch": 8.23636558448516,
      "grad_norm": 0.012653915211558342,
      "learning_rate": 3.52726883102968e-06,
      "loss": 0.0001,
      "step": 76870
    },
    {
      "epoch": 8.237437051323262,
      "grad_norm": 0.010192523710429668,
      "learning_rate": 3.5251258973534776e-06,
      "loss": 0.2373,
      "step": 76880
    },
    {
      "epoch": 8.238508518161362,
      "grad_norm": 0.03122878447175026,
      "learning_rate": 3.5229829636772745e-06,
      "loss": 0.1427,
      "step": 76890
    },
    {
      "epoch": 8.239579984999464,
      "grad_norm": 0.11880140751600266,
      "learning_rate": 3.520840030001072e-06,
      "loss": 0.1119,
      "step": 76900
    },
    {
      "epoch": 8.240651451837566,
      "grad_norm": 0.05909820646047592,
      "learning_rate": 3.518697096324869e-06,
      "loss": 0.1975,
      "step": 76910
    },
    {
      "epoch": 8.241722918675666,
      "grad_norm": 0.011140987277030945,
      "learning_rate": 3.5165541626486666e-06,
      "loss": 0.0004,
      "step": 76920
    },
    {
      "epoch": 8.242794385513768,
      "grad_norm": 0.4223744869232178,
      "learning_rate": 3.5144112289724635e-06,
      "loss": 0.0013,
      "step": 76930
    },
    {
      "epoch": 8.24386585235187,
      "grad_norm": 0.02025315910577774,
      "learning_rate": 3.5122682952962613e-06,
      "loss": 0.0002,
      "step": 76940
    },
    {
      "epoch": 8.24493731918997,
      "grad_norm": 0.00022614184126723558,
      "learning_rate": 3.5101253616200582e-06,
      "loss": 0.0037,
      "step": 76950
    },
    {
      "epoch": 8.246008786028073,
      "grad_norm": 0.007874155417084694,
      "learning_rate": 3.5079824279438556e-06,
      "loss": 0.0001,
      "step": 76960
    },
    {
      "epoch": 8.247080252866175,
      "grad_norm": 0.011578744277358055,
      "learning_rate": 3.5058394942676525e-06,
      "loss": 0.0004,
      "step": 76970
    },
    {
      "epoch": 8.248151719704275,
      "grad_norm": 0.0002948763140011579,
      "learning_rate": 3.5036965605914503e-06,
      "loss": 0.0002,
      "step": 76980
    },
    {
      "epoch": 8.249223186542377,
      "grad_norm": 0.03758423775434494,
      "learning_rate": 3.5015536269152472e-06,
      "loss": 0.1856,
      "step": 76990
    },
    {
      "epoch": 8.250294653380477,
      "grad_norm": 0.00017677780124358833,
      "learning_rate": 3.4994106932390446e-06,
      "loss": 0.1029,
      "step": 77000
    },
    {
      "epoch": 8.251366120218579,
      "grad_norm": 0.34103870391845703,
      "learning_rate": 3.497267759562842e-06,
      "loss": 0.0376,
      "step": 77010
    },
    {
      "epoch": 8.252437587056681,
      "grad_norm": 0.013831757009029388,
      "learning_rate": 3.495124825886639e-06,
      "loss": 0.0006,
      "step": 77020
    },
    {
      "epoch": 8.253509053894781,
      "grad_norm": 25.751529693603516,
      "learning_rate": 3.4929818922104362e-06,
      "loss": 0.1271,
      "step": 77030
    },
    {
      "epoch": 8.254580520732883,
      "grad_norm": 0.0018274838803336024,
      "learning_rate": 3.490838958534233e-06,
      "loss": 0.1367,
      "step": 77040
    },
    {
      "epoch": 8.255651987570985,
      "grad_norm": 0.00014111495693214238,
      "learning_rate": 3.488696024858031e-06,
      "loss": 0.0008,
      "step": 77050
    },
    {
      "epoch": 8.256723454409086,
      "grad_norm": 0.004823155235499144,
      "learning_rate": 3.486553091181828e-06,
      "loss": 0.0001,
      "step": 77060
    },
    {
      "epoch": 8.257794921247188,
      "grad_norm": 0.0001326210767729208,
      "learning_rate": 3.4844101575056257e-06,
      "loss": 0.128,
      "step": 77070
    },
    {
      "epoch": 8.25886638808529,
      "grad_norm": 0.017149046063423157,
      "learning_rate": 3.4822672238294226e-06,
      "loss": 0.0002,
      "step": 77080
    },
    {
      "epoch": 8.25993785492339,
      "grad_norm": 0.00012685410911217332,
      "learning_rate": 3.48012429015322e-06,
      "loss": 0.12,
      "step": 77090
    },
    {
      "epoch": 8.261009321761492,
      "grad_norm": 0.006827318575233221,
      "learning_rate": 3.477981356477017e-06,
      "loss": 0.0004,
      "step": 77100
    },
    {
      "epoch": 8.262080788599594,
      "grad_norm": 0.0067066410556435585,
      "learning_rate": 3.4758384228008147e-06,
      "loss": 0.226,
      "step": 77110
    },
    {
      "epoch": 8.263152255437694,
      "grad_norm": 0.00034755936940200627,
      "learning_rate": 3.4736954891246116e-06,
      "loss": 0.0001,
      "step": 77120
    },
    {
      "epoch": 8.264223722275796,
      "grad_norm": 0.00015816770610399544,
      "learning_rate": 3.4715525554484094e-06,
      "loss": 0.0001,
      "step": 77130
    },
    {
      "epoch": 8.265295189113896,
      "grad_norm": 0.0002042382548097521,
      "learning_rate": 3.4694096217722063e-06,
      "loss": 0.0005,
      "step": 77140
    },
    {
      "epoch": 8.266366655951998,
      "grad_norm": 0.00014713160635437816,
      "learning_rate": 3.4672666880960037e-06,
      "loss": 0.0005,
      "step": 77150
    },
    {
      "epoch": 8.2674381227901,
      "grad_norm": 0.0041159107349812984,
      "learning_rate": 3.4651237544198006e-06,
      "loss": 0.1968,
      "step": 77160
    },
    {
      "epoch": 8.2685095896282,
      "grad_norm": 2.9945802688598633,
      "learning_rate": 3.4629808207435984e-06,
      "loss": 0.0018,
      "step": 77170
    },
    {
      "epoch": 8.269581056466302,
      "grad_norm": 0.04381300508975983,
      "learning_rate": 3.4608378870673953e-06,
      "loss": 0.0004,
      "step": 77180
    },
    {
      "epoch": 8.270652523304404,
      "grad_norm": 0.0005729817203246057,
      "learning_rate": 3.4586949533911927e-06,
      "loss": 0.0002,
      "step": 77190
    },
    {
      "epoch": 8.271723990142505,
      "grad_norm": 0.01127699762582779,
      "learning_rate": 3.45655201971499e-06,
      "loss": 0.0001,
      "step": 77200
    },
    {
      "epoch": 8.272795456980607,
      "grad_norm": 43.2810173034668,
      "learning_rate": 3.4544090860387874e-06,
      "loss": 0.2235,
      "step": 77210
    },
    {
      "epoch": 8.273866923818709,
      "grad_norm": 0.0003207249101251364,
      "learning_rate": 3.4522661523625843e-06,
      "loss": 0.0003,
      "step": 77220
    },
    {
      "epoch": 8.274938390656809,
      "grad_norm": 46.45026779174805,
      "learning_rate": 3.450123218686382e-06,
      "loss": 0.0114,
      "step": 77230
    },
    {
      "epoch": 8.27600985749491,
      "grad_norm": 0.009330175817012787,
      "learning_rate": 3.447980285010179e-06,
      "loss": 0.1688,
      "step": 77240
    },
    {
      "epoch": 8.277081324333011,
      "grad_norm": 0.006571422331035137,
      "learning_rate": 3.4458373513339764e-06,
      "loss": 0.0005,
      "step": 77250
    },
    {
      "epoch": 8.278152791171113,
      "grad_norm": 0.003533237148076296,
      "learning_rate": 3.4436944176577737e-06,
      "loss": 0.0406,
      "step": 77260
    },
    {
      "epoch": 8.279224258009215,
      "grad_norm": 0.004100719932466745,
      "learning_rate": 3.441551483981571e-06,
      "loss": 0.0001,
      "step": 77270
    },
    {
      "epoch": 8.280295724847315,
      "grad_norm": 0.36944350600242615,
      "learning_rate": 3.439408550305368e-06,
      "loss": 0.189,
      "step": 77280
    },
    {
      "epoch": 8.281367191685417,
      "grad_norm": 0.0072104851715266705,
      "learning_rate": 3.437265616629166e-06,
      "loss": 0.1333,
      "step": 77290
    },
    {
      "epoch": 8.28243865852352,
      "grad_norm": 0.00010735281830420718,
      "learning_rate": 3.4351226829529627e-06,
      "loss": 0.0377,
      "step": 77300
    },
    {
      "epoch": 8.28351012536162,
      "grad_norm": 0.00035203469451516867,
      "learning_rate": 3.43297974927676e-06,
      "loss": 0.1866,
      "step": 77310
    },
    {
      "epoch": 8.284581592199721,
      "grad_norm": 0.020487936213612556,
      "learning_rate": 3.4308368156005574e-06,
      "loss": 0.0006,
      "step": 77320
    },
    {
      "epoch": 8.285653059037823,
      "grad_norm": 0.006025319918990135,
      "learning_rate": 3.428693881924355e-06,
      "loss": 0.01,
      "step": 77330
    },
    {
      "epoch": 8.286724525875924,
      "grad_norm": 0.004363492131233215,
      "learning_rate": 3.4265509482481517e-06,
      "loss": 0.0005,
      "step": 77340
    },
    {
      "epoch": 8.287795992714026,
      "grad_norm": 0.0004025563830509782,
      "learning_rate": 3.4244080145719495e-06,
      "loss": 0.0471,
      "step": 77350
    },
    {
      "epoch": 8.288867459552128,
      "grad_norm": 0.011725823394954205,
      "learning_rate": 3.4222650808957464e-06,
      "loss": 0.0002,
      "step": 77360
    },
    {
      "epoch": 8.289938926390228,
      "grad_norm": 0.00139427010435611,
      "learning_rate": 3.420122147219544e-06,
      "loss": 0.1424,
      "step": 77370
    },
    {
      "epoch": 8.29101039322833,
      "grad_norm": 0.005995957646518946,
      "learning_rate": 3.417979213543341e-06,
      "loss": 0.0001,
      "step": 77380
    },
    {
      "epoch": 8.29208186006643,
      "grad_norm": 0.005021956749260426,
      "learning_rate": 3.4158362798671385e-06,
      "loss": 0.0213,
      "step": 77390
    },
    {
      "epoch": 8.293153326904532,
      "grad_norm": 0.0008855738560669124,
      "learning_rate": 3.4136933461909354e-06,
      "loss": 0.0001,
      "step": 77400
    },
    {
      "epoch": 8.294224793742634,
      "grad_norm": 0.00013570844021160156,
      "learning_rate": 3.4115504125147332e-06,
      "loss": 0.0005,
      "step": 77410
    },
    {
      "epoch": 8.295296260580734,
      "grad_norm": 0.0440041609108448,
      "learning_rate": 3.40940747883853e-06,
      "loss": 0.0001,
      "step": 77420
    },
    {
      "epoch": 8.296367727418836,
      "grad_norm": 0.0003573830472305417,
      "learning_rate": 3.4072645451623275e-06,
      "loss": 0.0,
      "step": 77430
    },
    {
      "epoch": 8.297439194256938,
      "grad_norm": 0.007937672547996044,
      "learning_rate": 3.4051216114861244e-06,
      "loss": 0.0005,
      "step": 77440
    },
    {
      "epoch": 8.298510661095039,
      "grad_norm": 0.00010988008580170572,
      "learning_rate": 3.4029786778099222e-06,
      "loss": 0.0002,
      "step": 77450
    },
    {
      "epoch": 8.29958212793314,
      "grad_norm": 0.12510210275650024,
      "learning_rate": 3.400835744133719e-06,
      "loss": 0.0002,
      "step": 77460
    },
    {
      "epoch": 8.300653594771243,
      "grad_norm": 0.0001294557732762769,
      "learning_rate": 3.398692810457517e-06,
      "loss": 0.0001,
      "step": 77470
    },
    {
      "epoch": 8.301725061609343,
      "grad_norm": 0.0058570075780153275,
      "learning_rate": 3.396549876781314e-06,
      "loss": 0.138,
      "step": 77480
    },
    {
      "epoch": 8.302796528447445,
      "grad_norm": 0.003352940082550049,
      "learning_rate": 3.3944069431051112e-06,
      "loss": 0.0003,
      "step": 77490
    },
    {
      "epoch": 8.303867995285547,
      "grad_norm": 0.00011007556895492598,
      "learning_rate": 3.392264009428908e-06,
      "loss": 0.0018,
      "step": 77500
    },
    {
      "epoch": 8.304939462123647,
      "grad_norm": 0.050760287791490555,
      "learning_rate": 3.390121075752706e-06,
      "loss": 0.0001,
      "step": 77510
    },
    {
      "epoch": 8.306010928961749,
      "grad_norm": 0.005355754401534796,
      "learning_rate": 3.387978142076503e-06,
      "loss": 0.0008,
      "step": 77520
    },
    {
      "epoch": 8.30708239579985,
      "grad_norm": 0.0001632285420782864,
      "learning_rate": 3.3858352084003006e-06,
      "loss": 0.0,
      "step": 77530
    },
    {
      "epoch": 8.308153862637951,
      "grad_norm": 0.05647275224328041,
      "learning_rate": 3.3836922747240976e-06,
      "loss": 0.0006,
      "step": 77540
    },
    {
      "epoch": 8.309225329476053,
      "grad_norm": 0.00839943066239357,
      "learning_rate": 3.381549341047895e-06,
      "loss": 0.0002,
      "step": 77550
    },
    {
      "epoch": 8.310296796314153,
      "grad_norm": 0.0006886137998662889,
      "learning_rate": 3.379406407371692e-06,
      "loss": 0.0,
      "step": 77560
    },
    {
      "epoch": 8.311368263152255,
      "grad_norm": 0.007320517208427191,
      "learning_rate": 3.3772634736954896e-06,
      "loss": 0.0002,
      "step": 77570
    },
    {
      "epoch": 8.312439729990357,
      "grad_norm": 16.548131942749023,
      "learning_rate": 3.3751205400192866e-06,
      "loss": 0.2433,
      "step": 77580
    },
    {
      "epoch": 8.313511196828458,
      "grad_norm": 0.0037051448598504066,
      "learning_rate": 3.372977606343084e-06,
      "loss": 0.0003,
      "step": 77590
    },
    {
      "epoch": 8.31458266366656,
      "grad_norm": 0.0001072675731847994,
      "learning_rate": 3.3708346726668813e-06,
      "loss": 0.0001,
      "step": 77600
    },
    {
      "epoch": 8.315654130504662,
      "grad_norm": 0.006053299643099308,
      "learning_rate": 3.3686917389906786e-06,
      "loss": 0.0,
      "step": 77610
    },
    {
      "epoch": 8.316725597342762,
      "grad_norm": 0.26827165484428406,
      "learning_rate": 3.3665488053144756e-06,
      "loss": 0.0006,
      "step": 77620
    },
    {
      "epoch": 8.317797064180864,
      "grad_norm": 0.010646569542586803,
      "learning_rate": 3.3644058716382734e-06,
      "loss": 0.0001,
      "step": 77630
    },
    {
      "epoch": 8.318868531018964,
      "grad_norm": 0.00011048631859011948,
      "learning_rate": 3.3622629379620703e-06,
      "loss": 0.0001,
      "step": 77640
    },
    {
      "epoch": 8.319939997857066,
      "grad_norm": 0.004398588556796312,
      "learning_rate": 3.3601200042858676e-06,
      "loss": 0.1558,
      "step": 77650
    },
    {
      "epoch": 8.321011464695168,
      "grad_norm": 0.00010187793668592349,
      "learning_rate": 3.357977070609665e-06,
      "loss": 0.2153,
      "step": 77660
    },
    {
      "epoch": 8.322082931533268,
      "grad_norm": 0.00010631354234647006,
      "learning_rate": 3.3558341369334624e-06,
      "loss": 0.0001,
      "step": 77670
    },
    {
      "epoch": 8.32315439837137,
      "grad_norm": 0.004625665955245495,
      "learning_rate": 3.3536912032572593e-06,
      "loss": 0.0001,
      "step": 77680
    },
    {
      "epoch": 8.324225865209472,
      "grad_norm": 0.00010070457210531458,
      "learning_rate": 3.351548269581057e-06,
      "loss": 0.0,
      "step": 77690
    },
    {
      "epoch": 8.325297332047572,
      "grad_norm": 0.011133892461657524,
      "learning_rate": 3.349405335904854e-06,
      "loss": 0.0001,
      "step": 77700
    },
    {
      "epoch": 8.326368798885674,
      "grad_norm": 0.00013824529014527798,
      "learning_rate": 3.3472624022286514e-06,
      "loss": 0.1744,
      "step": 77710
    },
    {
      "epoch": 8.327440265723776,
      "grad_norm": 0.00012140336184529588,
      "learning_rate": 3.3451194685524487e-06,
      "loss": 0.0002,
      "step": 77720
    },
    {
      "epoch": 8.328511732561877,
      "grad_norm": 0.004456507042050362,
      "learning_rate": 3.342976534876246e-06,
      "loss": 0.1037,
      "step": 77730
    },
    {
      "epoch": 8.329583199399979,
      "grad_norm": 0.011151671409606934,
      "learning_rate": 3.340833601200043e-06,
      "loss": 0.0004,
      "step": 77740
    },
    {
      "epoch": 8.33065466623808,
      "grad_norm": 0.013971222564578056,
      "learning_rate": 3.3386906675238408e-06,
      "loss": 0.0002,
      "step": 77750
    },
    {
      "epoch": 8.331726133076181,
      "grad_norm": 0.00845503993332386,
      "learning_rate": 3.3365477338476377e-06,
      "loss": 0.2705,
      "step": 77760
    },
    {
      "epoch": 8.332797599914283,
      "grad_norm": 0.00011797307524830103,
      "learning_rate": 3.334404800171435e-06,
      "loss": 0.2299,
      "step": 77770
    },
    {
      "epoch": 8.333869066752385,
      "grad_norm": 0.0001488337729824707,
      "learning_rate": 3.332261866495232e-06,
      "loss": 0.1262,
      "step": 77780
    },
    {
      "epoch": 8.334940533590485,
      "grad_norm": 23.511077880859375,
      "learning_rate": 3.3301189328190298e-06,
      "loss": 0.1749,
      "step": 77790
    },
    {
      "epoch": 8.336012000428587,
      "grad_norm": 0.00012347738083917648,
      "learning_rate": 3.3279759991428267e-06,
      "loss": 0.1954,
      "step": 77800
    },
    {
      "epoch": 8.337083467266687,
      "grad_norm": 0.007047002669423819,
      "learning_rate": 3.3258330654666245e-06,
      "loss": 0.1297,
      "step": 77810
    },
    {
      "epoch": 8.33815493410479,
      "grad_norm": 0.00011707574594765902,
      "learning_rate": 3.3236901317904214e-06,
      "loss": 0.2282,
      "step": 77820
    },
    {
      "epoch": 8.339226400942891,
      "grad_norm": 0.004455456044524908,
      "learning_rate": 3.3215471981142188e-06,
      "loss": 0.0569,
      "step": 77830
    },
    {
      "epoch": 8.340297867780992,
      "grad_norm": 0.007876870222389698,
      "learning_rate": 3.3194042644380157e-06,
      "loss": 0.0004,
      "step": 77840
    },
    {
      "epoch": 8.341369334619094,
      "grad_norm": 0.00014738939353264868,
      "learning_rate": 3.3172613307618135e-06,
      "loss": 0.0013,
      "step": 77850
    },
    {
      "epoch": 8.342440801457196,
      "grad_norm": 0.02047301083803177,
      "learning_rate": 3.3151183970856104e-06,
      "loss": 0.1557,
      "step": 77860
    },
    {
      "epoch": 8.343512268295296,
      "grad_norm": 0.004197165835648775,
      "learning_rate": 3.312975463409408e-06,
      "loss": 0.0002,
      "step": 77870
    },
    {
      "epoch": 8.344583735133398,
      "grad_norm": 0.019743993878364563,
      "learning_rate": 3.310832529733205e-06,
      "loss": 0.0001,
      "step": 77880
    },
    {
      "epoch": 8.3456552019715,
      "grad_norm": 0.06809704005718231,
      "learning_rate": 3.3086895960570025e-06,
      "loss": 0.0012,
      "step": 77890
    },
    {
      "epoch": 8.3467266688096,
      "grad_norm": 0.00014444885891862214,
      "learning_rate": 3.3065466623807994e-06,
      "loss": 0.0002,
      "step": 77900
    },
    {
      "epoch": 8.347798135647702,
      "grad_norm": 0.00012135369615862146,
      "learning_rate": 3.304403728704597e-06,
      "loss": 0.1707,
      "step": 77910
    },
    {
      "epoch": 8.348869602485802,
      "grad_norm": 0.018419861793518066,
      "learning_rate": 3.302260795028394e-06,
      "loss": 0.0001,
      "step": 77920
    },
    {
      "epoch": 8.349941069323904,
      "grad_norm": 0.00011457903747214004,
      "learning_rate": 3.300117861352191e-06,
      "loss": 0.0001,
      "step": 77930
    },
    {
      "epoch": 8.351012536162006,
      "grad_norm": 0.0002108107873937115,
      "learning_rate": 3.297974927675989e-06,
      "loss": 0.0964,
      "step": 77940
    },
    {
      "epoch": 8.352084003000106,
      "grad_norm": 0.06428218632936478,
      "learning_rate": 3.2958319939997858e-06,
      "loss": 0.0005,
      "step": 77950
    },
    {
      "epoch": 8.353155469838208,
      "grad_norm": 0.010507194325327873,
      "learning_rate": 3.293689060323583e-06,
      "loss": 0.1964,
      "step": 77960
    },
    {
      "epoch": 8.35422693667631,
      "grad_norm": 0.0001315517001785338,
      "learning_rate": 3.29154612664738e-06,
      "loss": 0.2506,
      "step": 77970
    },
    {
      "epoch": 8.35529840351441,
      "grad_norm": 0.00011836747580673546,
      "learning_rate": 3.289403192971178e-06,
      "loss": 0.0004,
      "step": 77980
    },
    {
      "epoch": 8.356369870352513,
      "grad_norm": 0.0013600337551906705,
      "learning_rate": 3.2872602592949748e-06,
      "loss": 0.0001,
      "step": 77990
    },
    {
      "epoch": 8.357441337190615,
      "grad_norm": 0.00024572733673267066,
      "learning_rate": 3.2851173256187726e-06,
      "loss": 0.0002,
      "step": 78000
    },
    {
      "epoch": 8.358512804028715,
      "grad_norm": 0.00010971336450893432,
      "learning_rate": 3.2829743919425695e-06,
      "loss": 0.0004,
      "step": 78010
    },
    {
      "epoch": 8.359584270866817,
      "grad_norm": 0.004647802095860243,
      "learning_rate": 3.280831458266367e-06,
      "loss": 0.0005,
      "step": 78020
    },
    {
      "epoch": 8.360655737704919,
      "grad_norm": 0.006811122875660658,
      "learning_rate": 3.2786885245901638e-06,
      "loss": 0.001,
      "step": 78030
    },
    {
      "epoch": 8.361727204543019,
      "grad_norm": 0.0040927366353571415,
      "learning_rate": 3.2765455909139616e-06,
      "loss": 0.0007,
      "step": 78040
    },
    {
      "epoch": 8.362798671381121,
      "grad_norm": 0.027526838704943657,
      "learning_rate": 3.2744026572377585e-06,
      "loss": 0.0002,
      "step": 78050
    },
    {
      "epoch": 8.363870138219221,
      "grad_norm": 0.004311684053391218,
      "learning_rate": 3.2722597235615563e-06,
      "loss": 0.0001,
      "step": 78060
    },
    {
      "epoch": 8.364941605057323,
      "grad_norm": 0.0003888638748321682,
      "learning_rate": 3.270116789885353e-06,
      "loss": 0.0002,
      "step": 78070
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 0.00010939719504676759,
      "learning_rate": 3.2679738562091506e-06,
      "loss": 0.1802,
      "step": 78080
    },
    {
      "epoch": 8.367084538733526,
      "grad_norm": 0.07052899897098541,
      "learning_rate": 3.2658309225329475e-06,
      "loss": 0.0002,
      "step": 78090
    },
    {
      "epoch": 8.368156005571628,
      "grad_norm": 0.003208288922905922,
      "learning_rate": 3.2636879888567453e-06,
      "loss": 0.0001,
      "step": 78100
    },
    {
      "epoch": 8.36922747240973,
      "grad_norm": 0.0003188915434293449,
      "learning_rate": 3.261545055180542e-06,
      "loss": 0.0072,
      "step": 78110
    },
    {
      "epoch": 8.37029893924783,
      "grad_norm": 0.0023362189531326294,
      "learning_rate": 3.2594021215043396e-06,
      "loss": 0.0005,
      "step": 78120
    },
    {
      "epoch": 8.371370406085932,
      "grad_norm": 0.0001393237616866827,
      "learning_rate": 3.257259187828137e-06,
      "loss": 0.0001,
      "step": 78130
    },
    {
      "epoch": 8.372441872924034,
      "grad_norm": 0.00010881817433983088,
      "learning_rate": 3.2551162541519343e-06,
      "loss": 0.0,
      "step": 78140
    },
    {
      "epoch": 8.373513339762134,
      "grad_norm": 0.004080621991306543,
      "learning_rate": 3.252973320475731e-06,
      "loss": 0.012,
      "step": 78150
    },
    {
      "epoch": 8.374584806600236,
      "grad_norm": 0.003724518930539489,
      "learning_rate": 3.250830386799529e-06,
      "loss": 0.0001,
      "step": 78160
    },
    {
      "epoch": 8.375656273438338,
      "grad_norm": 0.008985927328467369,
      "learning_rate": 3.248687453123326e-06,
      "loss": 0.154,
      "step": 78170
    },
    {
      "epoch": 8.376727740276438,
      "grad_norm": 0.00016147599671967328,
      "learning_rate": 3.2465445194471233e-06,
      "loss": 0.0001,
      "step": 78180
    },
    {
      "epoch": 8.37779920711454,
      "grad_norm": 0.00012089266965631396,
      "learning_rate": 3.2444015857709206e-06,
      "loss": 0.0001,
      "step": 78190
    },
    {
      "epoch": 8.37887067395264,
      "grad_norm": 0.00010252695938106626,
      "learning_rate": 3.242258652094718e-06,
      "loss": 0.2981,
      "step": 78200
    },
    {
      "epoch": 8.379942140790742,
      "grad_norm": 0.006130656693130732,
      "learning_rate": 3.240115718418515e-06,
      "loss": 0.0001,
      "step": 78210
    },
    {
      "epoch": 8.381013607628844,
      "grad_norm": 0.006143694277852774,
      "learning_rate": 3.2379727847423127e-06,
      "loss": 0.0001,
      "step": 78220
    },
    {
      "epoch": 8.382085074466945,
      "grad_norm": 0.009322717785835266,
      "learning_rate": 3.2358298510661096e-06,
      "loss": 0.0002,
      "step": 78230
    },
    {
      "epoch": 8.383156541305047,
      "grad_norm": 0.05582742020487785,
      "learning_rate": 3.233686917389907e-06,
      "loss": 0.0004,
      "step": 78240
    },
    {
      "epoch": 8.384228008143149,
      "grad_norm": 0.06360334903001785,
      "learning_rate": 3.2315439837137043e-06,
      "loss": 0.0007,
      "step": 78250
    },
    {
      "epoch": 8.385299474981249,
      "grad_norm": 0.0016334548126906157,
      "learning_rate": 3.2294010500375017e-06,
      "loss": 0.0001,
      "step": 78260
    },
    {
      "epoch": 8.38637094181935,
      "grad_norm": 23.88473892211914,
      "learning_rate": 3.2272581163612986e-06,
      "loss": 0.0586,
      "step": 78270
    },
    {
      "epoch": 8.387442408657453,
      "grad_norm": 0.0033405832946300507,
      "learning_rate": 3.2251151826850964e-06,
      "loss": 0.0001,
      "step": 78280
    },
    {
      "epoch": 8.388513875495553,
      "grad_norm": 0.00010195306094828993,
      "learning_rate": 3.2229722490088933e-06,
      "loss": 0.0025,
      "step": 78290
    },
    {
      "epoch": 8.389585342333655,
      "grad_norm": 0.00011041422840207815,
      "learning_rate": 3.2208293153326907e-06,
      "loss": 0.0142,
      "step": 78300
    },
    {
      "epoch": 8.390656809171755,
      "grad_norm": 0.00414913147687912,
      "learning_rate": 3.2186863816564876e-06,
      "loss": 0.2002,
      "step": 78310
    },
    {
      "epoch": 8.391728276009857,
      "grad_norm": 0.00229534856043756,
      "learning_rate": 3.2165434479802854e-06,
      "loss": 0.0001,
      "step": 78320
    },
    {
      "epoch": 8.39279974284796,
      "grad_norm": 0.0022953925654292107,
      "learning_rate": 3.2144005143040823e-06,
      "loss": 0.0,
      "step": 78330
    },
    {
      "epoch": 8.39387120968606,
      "grad_norm": 0.008199241943657398,
      "learning_rate": 3.21225758062788e-06,
      "loss": 0.0001,
      "step": 78340
    },
    {
      "epoch": 8.394942676524161,
      "grad_norm": 0.010375185869634151,
      "learning_rate": 3.210114646951677e-06,
      "loss": 0.0001,
      "step": 78350
    },
    {
      "epoch": 8.396014143362263,
      "grad_norm": 0.29988834261894226,
      "learning_rate": 3.2079717132754744e-06,
      "loss": 0.0422,
      "step": 78360
    },
    {
      "epoch": 8.397085610200364,
      "grad_norm": 0.07874912768602371,
      "learning_rate": 3.2058287795992713e-06,
      "loss": 0.0002,
      "step": 78370
    },
    {
      "epoch": 8.398157077038466,
      "grad_norm": 0.00011100053961854428,
      "learning_rate": 3.203685845923069e-06,
      "loss": 0.1061,
      "step": 78380
    },
    {
      "epoch": 8.399228543876568,
      "grad_norm": 0.002553042257204652,
      "learning_rate": 3.201542912246866e-06,
      "loss": 0.0001,
      "step": 78390
    },
    {
      "epoch": 8.400300010714668,
      "grad_norm": 0.00010007857054006308,
      "learning_rate": 3.199399978570664e-06,
      "loss": 0.1117,
      "step": 78400
    },
    {
      "epoch": 8.40137147755277,
      "grad_norm": 0.009684082120656967,
      "learning_rate": 3.1972570448944608e-06,
      "loss": 0.1392,
      "step": 78410
    },
    {
      "epoch": 8.402442944390872,
      "grad_norm": 0.00010891845886362717,
      "learning_rate": 3.195114111218258e-06,
      "loss": 0.1789,
      "step": 78420
    },
    {
      "epoch": 8.403514411228972,
      "grad_norm": 9.949988452717662e-05,
      "learning_rate": 3.192971177542055e-06,
      "loss": 0.2416,
      "step": 78430
    },
    {
      "epoch": 8.404585878067074,
      "grad_norm": 0.00014149092021398246,
      "learning_rate": 3.190828243865853e-06,
      "loss": 0.347,
      "step": 78440
    },
    {
      "epoch": 8.405657344905174,
      "grad_norm": 0.0002728041436057538,
      "learning_rate": 3.1886853101896498e-06,
      "loss": 0.2431,
      "step": 78450
    },
    {
      "epoch": 8.406728811743276,
      "grad_norm": 0.0011565113672986627,
      "learning_rate": 3.1865423765134475e-06,
      "loss": 0.0003,
      "step": 78460
    },
    {
      "epoch": 8.407800278581378,
      "grad_norm": 0.005579785443842411,
      "learning_rate": 3.1843994428372445e-06,
      "loss": 0.0001,
      "step": 78470
    },
    {
      "epoch": 8.408871745419479,
      "grad_norm": 0.03406236320734024,
      "learning_rate": 3.182256509161042e-06,
      "loss": 0.0001,
      "step": 78480
    },
    {
      "epoch": 8.40994321225758,
      "grad_norm": 0.001631581922993064,
      "learning_rate": 3.1801135754848388e-06,
      "loss": 0.0005,
      "step": 78490
    },
    {
      "epoch": 8.411014679095683,
      "grad_norm": 0.0004748671199195087,
      "learning_rate": 3.1779706418086365e-06,
      "loss": 0.1837,
      "step": 78500
    },
    {
      "epoch": 8.412086145933783,
      "grad_norm": 0.00593041954562068,
      "learning_rate": 3.1758277081324335e-06,
      "loss": 0.0002,
      "step": 78510
    },
    {
      "epoch": 8.413157612771885,
      "grad_norm": 0.01611415110528469,
      "learning_rate": 3.173684774456231e-06,
      "loss": 0.0001,
      "step": 78520
    },
    {
      "epoch": 8.414229079609987,
      "grad_norm": 0.0001324217882938683,
      "learning_rate": 3.171541840780028e-06,
      "loss": 0.0003,
      "step": 78530
    },
    {
      "epoch": 8.415300546448087,
      "grad_norm": 0.003094516461715102,
      "learning_rate": 3.1693989071038255e-06,
      "loss": 0.0127,
      "step": 78540
    },
    {
      "epoch": 8.416372013286189,
      "grad_norm": 0.1448327898979187,
      "learning_rate": 3.1672559734276225e-06,
      "loss": 0.0002,
      "step": 78550
    },
    {
      "epoch": 8.417443480124291,
      "grad_norm": 0.0027998515870422125,
      "learning_rate": 3.1651130397514202e-06,
      "loss": 0.0002,
      "step": 78560
    },
    {
      "epoch": 8.418514946962391,
      "grad_norm": 29.689617156982422,
      "learning_rate": 3.162970106075217e-06,
      "loss": 0.1721,
      "step": 78570
    },
    {
      "epoch": 8.419586413800493,
      "grad_norm": 0.00010860407928703353,
      "learning_rate": 3.1608271723990145e-06,
      "loss": 0.0001,
      "step": 78580
    },
    {
      "epoch": 8.420657880638593,
      "grad_norm": 0.00014363316586241126,
      "learning_rate": 3.158684238722812e-06,
      "loss": 0.0001,
      "step": 78590
    },
    {
      "epoch": 8.421729347476695,
      "grad_norm": 0.00017148915503639728,
      "learning_rate": 3.1565413050466092e-06,
      "loss": 0.0034,
      "step": 78600
    },
    {
      "epoch": 8.422800814314797,
      "grad_norm": 0.002085968153551221,
      "learning_rate": 3.154398371370406e-06,
      "loss": 0.0001,
      "step": 78610
    },
    {
      "epoch": 8.423872281152898,
      "grad_norm": 0.0018592607229948044,
      "learning_rate": 3.152255437694204e-06,
      "loss": 0.0015,
      "step": 78620
    },
    {
      "epoch": 8.424943747991,
      "grad_norm": 0.00013272649084683508,
      "learning_rate": 3.150112504018001e-06,
      "loss": 0.0001,
      "step": 78630
    },
    {
      "epoch": 8.426015214829102,
      "grad_norm": 0.005636951420456171,
      "learning_rate": 3.1479695703417982e-06,
      "loss": 0.0001,
      "step": 78640
    },
    {
      "epoch": 8.427086681667202,
      "grad_norm": 0.0008342494256794453,
      "learning_rate": 3.1458266366655956e-06,
      "loss": 0.0001,
      "step": 78650
    },
    {
      "epoch": 8.428158148505304,
      "grad_norm": 0.11301567405462265,
      "learning_rate": 3.143683702989393e-06,
      "loss": 0.0002,
      "step": 78660
    },
    {
      "epoch": 8.429229615343406,
      "grad_norm": 0.00012811599299311638,
      "learning_rate": 3.14154076931319e-06,
      "loss": 0.1072,
      "step": 78670
    },
    {
      "epoch": 8.430301082181506,
      "grad_norm": 9.778260573511943e-05,
      "learning_rate": 3.1393978356369877e-06,
      "loss": 0.0001,
      "step": 78680
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.000186742254300043,
      "learning_rate": 3.1372549019607846e-06,
      "loss": 0.0001,
      "step": 78690
    },
    {
      "epoch": 8.432444015857708,
      "grad_norm": 0.0011006301501765847,
      "learning_rate": 3.135111968284582e-06,
      "loss": 0.0003,
      "step": 78700
    },
    {
      "epoch": 8.43351548269581,
      "grad_norm": 0.0017380985664203763,
      "learning_rate": 3.132969034608379e-06,
      "loss": 0.0001,
      "step": 78710
    },
    {
      "epoch": 8.434586949533912,
      "grad_norm": 0.0001575373171363026,
      "learning_rate": 3.1308261009321767e-06,
      "loss": 0.0001,
      "step": 78720
    },
    {
      "epoch": 8.435658416372013,
      "grad_norm": 0.01560189202427864,
      "learning_rate": 3.1286831672559736e-06,
      "loss": 0.193,
      "step": 78730
    },
    {
      "epoch": 8.436729883210115,
      "grad_norm": 0.00406648637726903,
      "learning_rate": 3.1265402335797714e-06,
      "loss": 0.1675,
      "step": 78740
    },
    {
      "epoch": 8.437801350048217,
      "grad_norm": 0.0012764366110786796,
      "learning_rate": 3.1243972999035683e-06,
      "loss": 0.0052,
      "step": 78750
    },
    {
      "epoch": 8.438872816886317,
      "grad_norm": 0.0001175726720248349,
      "learning_rate": 3.1222543662273657e-06,
      "loss": 0.2426,
      "step": 78760
    },
    {
      "epoch": 8.439944283724419,
      "grad_norm": 6.477606296539307,
      "learning_rate": 3.1201114325511626e-06,
      "loss": 0.0012,
      "step": 78770
    },
    {
      "epoch": 8.44101575056252,
      "grad_norm": 0.017025461420416832,
      "learning_rate": 3.1179684988749604e-06,
      "loss": 0.0928,
      "step": 78780
    },
    {
      "epoch": 8.442087217400621,
      "grad_norm": 9.55579016590491e-05,
      "learning_rate": 3.1158255651987573e-06,
      "loss": 0.0006,
      "step": 78790
    },
    {
      "epoch": 8.443158684238723,
      "grad_norm": 0.006504237186163664,
      "learning_rate": 3.113682631522555e-06,
      "loss": 0.0001,
      "step": 78800
    },
    {
      "epoch": 8.444230151076825,
      "grad_norm": 0.005521625746041536,
      "learning_rate": 3.111539697846352e-06,
      "loss": 0.0002,
      "step": 78810
    },
    {
      "epoch": 8.445301617914925,
      "grad_norm": 0.0032636302057653666,
      "learning_rate": 3.1093967641701494e-06,
      "loss": 0.0003,
      "step": 78820
    },
    {
      "epoch": 8.446373084753027,
      "grad_norm": 0.02211129292845726,
      "learning_rate": 3.1072538304939463e-06,
      "loss": 0.0002,
      "step": 78830
    },
    {
      "epoch": 8.44744455159113,
      "grad_norm": 0.0004287813790142536,
      "learning_rate": 3.1051108968177437e-06,
      "loss": 0.0,
      "step": 78840
    },
    {
      "epoch": 8.44851601842923,
      "grad_norm": 0.20808614790439606,
      "learning_rate": 3.102967963141541e-06,
      "loss": 0.0003,
      "step": 78850
    },
    {
      "epoch": 8.449587485267331,
      "grad_norm": 0.000113764799607452,
      "learning_rate": 3.100825029465338e-06,
      "loss": 0.0001,
      "step": 78860
    },
    {
      "epoch": 8.450658952105432,
      "grad_norm": 0.00011188090138603002,
      "learning_rate": 3.0986820957891357e-06,
      "loss": 0.0002,
      "step": 78870
    },
    {
      "epoch": 8.451730418943534,
      "grad_norm": 0.00010448620014358312,
      "learning_rate": 3.0965391621129327e-06,
      "loss": 0.0,
      "step": 78880
    },
    {
      "epoch": 8.452801885781636,
      "grad_norm": 18.06911849975586,
      "learning_rate": 3.09439622843673e-06,
      "loss": 0.0193,
      "step": 78890
    },
    {
      "epoch": 8.453873352619736,
      "grad_norm": 0.0001552292233100161,
      "learning_rate": 3.092253294760527e-06,
      "loss": 0.0001,
      "step": 78900
    },
    {
      "epoch": 8.454944819457838,
      "grad_norm": 0.0002797799534164369,
      "learning_rate": 3.0901103610843247e-06,
      "loss": 0.0,
      "step": 78910
    },
    {
      "epoch": 8.45601628629594,
      "grad_norm": 0.0006181006319820881,
      "learning_rate": 3.0879674274081217e-06,
      "loss": 0.2695,
      "step": 78920
    },
    {
      "epoch": 8.45708775313404,
      "grad_norm": 0.0019949255511164665,
      "learning_rate": 3.0858244937319194e-06,
      "loss": 0.0015,
      "step": 78930
    },
    {
      "epoch": 8.458159219972142,
      "grad_norm": 0.004473285283893347,
      "learning_rate": 3.0836815600557164e-06,
      "loss": 0.2892,
      "step": 78940
    },
    {
      "epoch": 8.459230686810244,
      "grad_norm": 0.011055365204811096,
      "learning_rate": 3.0815386263795137e-06,
      "loss": 0.0001,
      "step": 78950
    },
    {
      "epoch": 8.460302153648344,
      "grad_norm": 0.02403082512319088,
      "learning_rate": 3.0793956927033107e-06,
      "loss": 0.2227,
      "step": 78960
    },
    {
      "epoch": 8.461373620486446,
      "grad_norm": 0.00015740073285996914,
      "learning_rate": 3.0772527590271084e-06,
      "loss": 0.0001,
      "step": 78970
    },
    {
      "epoch": 8.462445087324546,
      "grad_norm": 4.776919841766357,
      "learning_rate": 3.0751098253509054e-06,
      "loss": 0.0034,
      "step": 78980
    },
    {
      "epoch": 8.463516554162648,
      "grad_norm": 0.013849223032593727,
      "learning_rate": 3.072966891674703e-06,
      "loss": 0.0001,
      "step": 78990
    },
    {
      "epoch": 8.46458802100075,
      "grad_norm": 0.00013338700227905065,
      "learning_rate": 3.0708239579985e-06,
      "loss": 0.0001,
      "step": 79000
    },
    {
      "epoch": 8.46565948783885,
      "grad_norm": 0.00011888535664184019,
      "learning_rate": 3.0686810243222974e-06,
      "loss": 0.0001,
      "step": 79010
    },
    {
      "epoch": 8.466730954676953,
      "grad_norm": 0.008680619299411774,
      "learning_rate": 3.0665380906460944e-06,
      "loss": 0.0429,
      "step": 79020
    },
    {
      "epoch": 8.467802421515055,
      "grad_norm": 0.007031572982668877,
      "learning_rate": 3.064395156969892e-06,
      "loss": 0.0001,
      "step": 79030
    },
    {
      "epoch": 8.468873888353155,
      "grad_norm": 0.007648063823580742,
      "learning_rate": 3.062252223293689e-06,
      "loss": 0.0005,
      "step": 79040
    },
    {
      "epoch": 8.469945355191257,
      "grad_norm": 0.0032263381872326136,
      "learning_rate": 3.0601092896174864e-06,
      "loss": 0.0002,
      "step": 79050
    },
    {
      "epoch": 8.471016822029359,
      "grad_norm": 0.00017779298650566489,
      "learning_rate": 3.057966355941284e-06,
      "loss": 0.0007,
      "step": 79060
    },
    {
      "epoch": 8.47208828886746,
      "grad_norm": 0.015230033546686172,
      "learning_rate": 3.055823422265081e-06,
      "loss": 0.2113,
      "step": 79070
    },
    {
      "epoch": 8.473159755705561,
      "grad_norm": 0.0035211085341870785,
      "learning_rate": 3.053680488588878e-06,
      "loss": 0.0007,
      "step": 79080
    },
    {
      "epoch": 8.474231222543663,
      "grad_norm": 26.584543228149414,
      "learning_rate": 3.051537554912676e-06,
      "loss": 0.3063,
      "step": 79090
    },
    {
      "epoch": 8.475302689381763,
      "grad_norm": 2.4663288593292236,
      "learning_rate": 3.049394621236473e-06,
      "loss": 0.003,
      "step": 79100
    },
    {
      "epoch": 8.476374156219865,
      "grad_norm": 0.0029034619219601154,
      "learning_rate": 3.04725168756027e-06,
      "loss": 0.0001,
      "step": 79110
    },
    {
      "epoch": 8.477445623057966,
      "grad_norm": 0.0007170512108132243,
      "learning_rate": 3.0451087538840675e-06,
      "loss": 0.0106,
      "step": 79120
    },
    {
      "epoch": 8.478517089896068,
      "grad_norm": 0.4596407413482666,
      "learning_rate": 3.042965820207865e-06,
      "loss": 0.0009,
      "step": 79130
    },
    {
      "epoch": 8.47958855673417,
      "grad_norm": 0.0006620604544878006,
      "learning_rate": 3.040822886531662e-06,
      "loss": 0.0004,
      "step": 79140
    },
    {
      "epoch": 8.48066002357227,
      "grad_norm": 0.0002744699886534363,
      "learning_rate": 3.0386799528554596e-06,
      "loss": 0.0003,
      "step": 79150
    },
    {
      "epoch": 8.481731490410372,
      "grad_norm": 0.00011554989032447338,
      "learning_rate": 3.0365370191792565e-06,
      "loss": 0.2174,
      "step": 79160
    },
    {
      "epoch": 8.482802957248474,
      "grad_norm": 0.049881722778081894,
      "learning_rate": 3.034394085503054e-06,
      "loss": 0.0001,
      "step": 79170
    },
    {
      "epoch": 8.483874424086574,
      "grad_norm": 0.002968445885926485,
      "learning_rate": 3.0322511518268512e-06,
      "loss": 0.0001,
      "step": 79180
    },
    {
      "epoch": 8.484945890924676,
      "grad_norm": 0.00014557188842445612,
      "learning_rate": 3.0301082181506486e-06,
      "loss": 0.0002,
      "step": 79190
    },
    {
      "epoch": 8.486017357762778,
      "grad_norm": 0.007059826515614986,
      "learning_rate": 3.0279652844744455e-06,
      "loss": 0.0001,
      "step": 79200
    },
    {
      "epoch": 8.487088824600878,
      "grad_norm": 0.002919444814324379,
      "learning_rate": 3.0258223507982433e-06,
      "loss": 0.0001,
      "step": 79210
    },
    {
      "epoch": 8.48816029143898,
      "grad_norm": 0.0001643277209950611,
      "learning_rate": 3.0236794171220402e-06,
      "loss": 0.3308,
      "step": 79220
    },
    {
      "epoch": 8.489231758277082,
      "grad_norm": 0.00017057155491784215,
      "learning_rate": 3.0215364834458376e-06,
      "loss": 0.0013,
      "step": 79230
    },
    {
      "epoch": 8.490303225115182,
      "grad_norm": 0.04870850220322609,
      "learning_rate": 3.0193935497696345e-06,
      "loss": 0.0002,
      "step": 79240
    },
    {
      "epoch": 8.491374691953284,
      "grad_norm": 0.0018151424592360854,
      "learning_rate": 3.0172506160934323e-06,
      "loss": 0.0,
      "step": 79250
    },
    {
      "epoch": 8.492446158791385,
      "grad_norm": 0.002520145382732153,
      "learning_rate": 3.0151076824172292e-06,
      "loss": 0.0007,
      "step": 79260
    },
    {
      "epoch": 8.493517625629487,
      "grad_norm": 0.000376055104425177,
      "learning_rate": 3.012964748741027e-06,
      "loss": 0.0001,
      "step": 79270
    },
    {
      "epoch": 8.494589092467589,
      "grad_norm": 0.003803863190114498,
      "learning_rate": 3.010821815064824e-06,
      "loss": 0.0005,
      "step": 79280
    },
    {
      "epoch": 8.495660559305689,
      "grad_norm": 0.0001076698608812876,
      "learning_rate": 3.0086788813886213e-06,
      "loss": 0.2045,
      "step": 79290
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 0.005057898350059986,
      "learning_rate": 3.0065359477124182e-06,
      "loss": 0.0004,
      "step": 79300
    },
    {
      "epoch": 8.497803492981893,
      "grad_norm": 0.006954540032893419,
      "learning_rate": 3.004393014036216e-06,
      "loss": 0.0001,
      "step": 79310
    },
    {
      "epoch": 8.498874959819993,
      "grad_norm": 0.0038660820573568344,
      "learning_rate": 3.002250080360013e-06,
      "loss": 0.4869,
      "step": 79320
    },
    {
      "epoch": 8.499946426658095,
      "grad_norm": 0.00013090019638184458,
      "learning_rate": 3.0001071466838107e-06,
      "loss": 0.0001,
      "step": 79330
    },
    {
      "epoch": 8.501017893496197,
      "grad_norm": 0.004902175161987543,
      "learning_rate": 2.9979642130076076e-06,
      "loss": 0.0001,
      "step": 79340
    },
    {
      "epoch": 8.502089360334297,
      "grad_norm": 0.05697588250041008,
      "learning_rate": 2.995821279331405e-06,
      "loss": 0.0003,
      "step": 79350
    },
    {
      "epoch": 8.5031608271724,
      "grad_norm": 0.0033770129084587097,
      "learning_rate": 2.993678345655202e-06,
      "loss": 0.2985,
      "step": 79360
    },
    {
      "epoch": 8.5042322940105,
      "grad_norm": 0.0058382973074913025,
      "learning_rate": 2.9915354119789997e-06,
      "loss": 0.0005,
      "step": 79370
    },
    {
      "epoch": 8.505303760848602,
      "grad_norm": 0.0001655398082220927,
      "learning_rate": 2.9893924783027966e-06,
      "loss": 0.0001,
      "step": 79380
    },
    {
      "epoch": 8.506375227686704,
      "grad_norm": 0.0004381454491522163,
      "learning_rate": 2.9872495446265944e-06,
      "loss": 0.0001,
      "step": 79390
    },
    {
      "epoch": 8.507446694524804,
      "grad_norm": 0.007021344732493162,
      "learning_rate": 2.9851066109503914e-06,
      "loss": 0.1417,
      "step": 79400
    },
    {
      "epoch": 8.508518161362906,
      "grad_norm": 0.0001368409430142492,
      "learning_rate": 2.9829636772741887e-06,
      "loss": 0.0012,
      "step": 79410
    },
    {
      "epoch": 8.509589628201008,
      "grad_norm": 0.00013029803812969476,
      "learning_rate": 2.9808207435979856e-06,
      "loss": 0.0002,
      "step": 79420
    },
    {
      "epoch": 8.510661095039108,
      "grad_norm": 0.006700979545712471,
      "learning_rate": 2.9786778099217834e-06,
      "loss": 0.0001,
      "step": 79430
    },
    {
      "epoch": 8.51173256187721,
      "grad_norm": 0.0001463001244701445,
      "learning_rate": 2.9765348762455804e-06,
      "loss": 0.0001,
      "step": 79440
    },
    {
      "epoch": 8.512804028715312,
      "grad_norm": 0.14614367485046387,
      "learning_rate": 2.9743919425693777e-06,
      "loss": 0.0002,
      "step": 79450
    },
    {
      "epoch": 8.513875495553412,
      "grad_norm": 0.00012202445941511542,
      "learning_rate": 2.972249008893175e-06,
      "loss": 0.0005,
      "step": 79460
    },
    {
      "epoch": 8.514946962391514,
      "grad_norm": 0.0025002777110785246,
      "learning_rate": 2.9701060752169724e-06,
      "loss": 0.0008,
      "step": 79470
    },
    {
      "epoch": 8.516018429229616,
      "grad_norm": 0.008009078912436962,
      "learning_rate": 2.9679631415407694e-06,
      "loss": 0.2136,
      "step": 79480
    },
    {
      "epoch": 8.517089896067716,
      "grad_norm": 0.006616117432713509,
      "learning_rate": 2.965820207864567e-06,
      "loss": 0.0798,
      "step": 79490
    },
    {
      "epoch": 8.518161362905818,
      "grad_norm": 0.0013208731543272734,
      "learning_rate": 2.963677274188364e-06,
      "loss": 0.0001,
      "step": 79500
    },
    {
      "epoch": 8.519232829743919,
      "grad_norm": 0.0002229590027127415,
      "learning_rate": 2.9615343405121614e-06,
      "loss": 0.0002,
      "step": 79510
    },
    {
      "epoch": 8.52030429658202,
      "grad_norm": 0.008967352099716663,
      "learning_rate": 2.9593914068359588e-06,
      "loss": 0.0002,
      "step": 79520
    },
    {
      "epoch": 8.521375763420123,
      "grad_norm": 0.005194441415369511,
      "learning_rate": 2.957248473159756e-06,
      "loss": 0.0,
      "step": 79530
    },
    {
      "epoch": 8.522447230258223,
      "grad_norm": 0.00015757551591377705,
      "learning_rate": 2.955105539483553e-06,
      "loss": 0.1754,
      "step": 79540
    },
    {
      "epoch": 8.523518697096325,
      "grad_norm": 0.00020916723588015884,
      "learning_rate": 2.952962605807351e-06,
      "loss": 0.0001,
      "step": 79550
    },
    {
      "epoch": 8.524590163934427,
      "grad_norm": 0.0022854595445096493,
      "learning_rate": 2.9508196721311478e-06,
      "loss": 0.0,
      "step": 79560
    },
    {
      "epoch": 8.525661630772527,
      "grad_norm": 0.0003362424031365663,
      "learning_rate": 2.948676738454945e-06,
      "loss": 0.1683,
      "step": 79570
    },
    {
      "epoch": 8.526733097610629,
      "grad_norm": 12.459953308105469,
      "learning_rate": 2.9465338047787425e-06,
      "loss": 0.0344,
      "step": 79580
    },
    {
      "epoch": 8.527804564448731,
      "grad_norm": 0.0031838936265558004,
      "learning_rate": 2.94439087110254e-06,
      "loss": 0.0002,
      "step": 79590
    },
    {
      "epoch": 8.528876031286831,
      "grad_norm": 0.0030748515855520964,
      "learning_rate": 2.9422479374263368e-06,
      "loss": 0.2355,
      "step": 79600
    },
    {
      "epoch": 8.529947498124933,
      "grad_norm": 0.003028675215318799,
      "learning_rate": 2.9401050037501346e-06,
      "loss": 0.0004,
      "step": 79610
    },
    {
      "epoch": 8.531018964963035,
      "grad_norm": 0.00030218312167562544,
      "learning_rate": 2.9379620700739315e-06,
      "loss": 0.0005,
      "step": 79620
    },
    {
      "epoch": 8.532090431801135,
      "grad_norm": 0.00010995416960213333,
      "learning_rate": 2.935819136397729e-06,
      "loss": 0.0001,
      "step": 79630
    },
    {
      "epoch": 8.533161898639237,
      "grad_norm": 0.00012001174036413431,
      "learning_rate": 2.9336762027215258e-06,
      "loss": 0.0001,
      "step": 79640
    },
    {
      "epoch": 8.534233365477338,
      "grad_norm": 0.00348287308588624,
      "learning_rate": 2.9315332690453236e-06,
      "loss": 0.0002,
      "step": 79650
    },
    {
      "epoch": 8.53530483231544,
      "grad_norm": 0.00024772045435383916,
      "learning_rate": 2.9293903353691205e-06,
      "loss": 0.0007,
      "step": 79660
    },
    {
      "epoch": 8.536376299153542,
      "grad_norm": 0.0058077601715922356,
      "learning_rate": 2.9272474016929183e-06,
      "loss": 0.1611,
      "step": 79670
    },
    {
      "epoch": 8.537447765991642,
      "grad_norm": 0.003251469461247325,
      "learning_rate": 2.925104468016715e-06,
      "loss": 0.0003,
      "step": 79680
    },
    {
      "epoch": 8.538519232829744,
      "grad_norm": 0.024474764242768288,
      "learning_rate": 2.9229615343405126e-06,
      "loss": 0.2026,
      "step": 79690
    },
    {
      "epoch": 8.539590699667846,
      "grad_norm": 73.04253387451172,
      "learning_rate": 2.9208186006643095e-06,
      "loss": 0.2112,
      "step": 79700
    },
    {
      "epoch": 8.540662166505946,
      "grad_norm": 0.005327974911779165,
      "learning_rate": 2.9186756669881073e-06,
      "loss": 0.0001,
      "step": 79710
    },
    {
      "epoch": 8.541733633344048,
      "grad_norm": 0.004617116414010525,
      "learning_rate": 2.916532733311904e-06,
      "loss": 0.0001,
      "step": 79720
    },
    {
      "epoch": 8.54280510018215,
      "grad_norm": 0.015812542289495468,
      "learning_rate": 2.914389799635702e-06,
      "loss": 0.0002,
      "step": 79730
    },
    {
      "epoch": 8.54387656702025,
      "grad_norm": 0.017080245539546013,
      "learning_rate": 2.912246865959499e-06,
      "loss": 0.1414,
      "step": 79740
    },
    {
      "epoch": 8.544948033858352,
      "grad_norm": 0.0056697227992117405,
      "learning_rate": 2.910103932283296e-06,
      "loss": 0.0002,
      "step": 79750
    },
    {
      "epoch": 8.546019500696453,
      "grad_norm": 0.20124933123588562,
      "learning_rate": 2.907960998607093e-06,
      "loss": 0.0697,
      "step": 79760
    },
    {
      "epoch": 8.547090967534555,
      "grad_norm": 0.015967711806297302,
      "learning_rate": 2.9058180649308906e-06,
      "loss": 0.0002,
      "step": 79770
    },
    {
      "epoch": 8.548162434372657,
      "grad_norm": 0.008811977691948414,
      "learning_rate": 2.903675131254688e-06,
      "loss": 0.3504,
      "step": 79780
    },
    {
      "epoch": 8.549233901210757,
      "grad_norm": 0.0050489832647144794,
      "learning_rate": 2.901532197578485e-06,
      "loss": 0.0001,
      "step": 79790
    },
    {
      "epoch": 8.550305368048859,
      "grad_norm": 0.00419363658875227,
      "learning_rate": 2.8993892639022826e-06,
      "loss": 0.1684,
      "step": 79800
    },
    {
      "epoch": 8.55137683488696,
      "grad_norm": 0.004019852261990309,
      "learning_rate": 2.8972463302260796e-06,
      "loss": 0.0001,
      "step": 79810
    },
    {
      "epoch": 8.552448301725061,
      "grad_norm": 9.934975241776556e-05,
      "learning_rate": 2.895103396549877e-06,
      "loss": 0.0003,
      "step": 79820
    },
    {
      "epoch": 8.553519768563163,
      "grad_norm": 0.0679396316409111,
      "learning_rate": 2.892960462873674e-06,
      "loss": 0.0022,
      "step": 79830
    },
    {
      "epoch": 8.554591235401265,
      "grad_norm": 0.029341567307710648,
      "learning_rate": 2.8908175291974716e-06,
      "loss": 0.0763,
      "step": 79840
    },
    {
      "epoch": 8.555662702239365,
      "grad_norm": 9.960586612578481e-05,
      "learning_rate": 2.8886745955212686e-06,
      "loss": 0.0202,
      "step": 79850
    },
    {
      "epoch": 8.556734169077467,
      "grad_norm": 0.002253045095130801,
      "learning_rate": 2.8865316618450663e-06,
      "loss": 0.0003,
      "step": 79860
    },
    {
      "epoch": 8.55780563591557,
      "grad_norm": 0.02853255718946457,
      "learning_rate": 2.8843887281688633e-06,
      "loss": 0.0003,
      "step": 79870
    },
    {
      "epoch": 8.55887710275367,
      "grad_norm": 0.12714122235774994,
      "learning_rate": 2.8822457944926606e-06,
      "loss": 0.0003,
      "step": 79880
    },
    {
      "epoch": 8.559948569591771,
      "grad_norm": 0.00012628901458811015,
      "learning_rate": 2.8801028608164576e-06,
      "loss": 0.0003,
      "step": 79890
    },
    {
      "epoch": 8.561020036429873,
      "grad_norm": 0.002442337106913328,
      "learning_rate": 2.8779599271402553e-06,
      "loss": 0.0,
      "step": 79900
    },
    {
      "epoch": 8.562091503267974,
      "grad_norm": 0.16650745272636414,
      "learning_rate": 2.8758169934640523e-06,
      "loss": 0.0004,
      "step": 79910
    },
    {
      "epoch": 8.563162970106076,
      "grad_norm": 0.0024676290340721607,
      "learning_rate": 2.87367405978785e-06,
      "loss": 0.2099,
      "step": 79920
    },
    {
      "epoch": 8.564234436944176,
      "grad_norm": 9.90696280496195e-05,
      "learning_rate": 2.871531126111647e-06,
      "loss": 0.0001,
      "step": 79930
    },
    {
      "epoch": 8.565305903782278,
      "grad_norm": 0.00010178294905927032,
      "learning_rate": 2.8693881924354443e-06,
      "loss": 0.3366,
      "step": 79940
    },
    {
      "epoch": 8.56637737062038,
      "grad_norm": 0.0040061683394014835,
      "learning_rate": 2.8672452587592413e-06,
      "loss": 0.0002,
      "step": 79950
    },
    {
      "epoch": 8.56744883745848,
      "grad_norm": 0.011309945024549961,
      "learning_rate": 2.865102325083039e-06,
      "loss": 0.0001,
      "step": 79960
    },
    {
      "epoch": 8.568520304296582,
      "grad_norm": 0.00011245530185988173,
      "learning_rate": 2.862959391406836e-06,
      "loss": 0.0901,
      "step": 79970
    },
    {
      "epoch": 8.569591771134684,
      "grad_norm": 0.00011794595047831535,
      "learning_rate": 2.8608164577306333e-06,
      "loss": 0.0,
      "step": 79980
    },
    {
      "epoch": 8.570663237972784,
      "grad_norm": 0.002670689718797803,
      "learning_rate": 2.8586735240544307e-06,
      "loss": 0.0002,
      "step": 79990
    },
    {
      "epoch": 8.571734704810886,
      "grad_norm": 0.00010694724187487736,
      "learning_rate": 2.856530590378228e-06,
      "loss": 0.0004,
      "step": 80000
    },
    {
      "epoch": 8.572806171648988,
      "grad_norm": 0.00010008399840444326,
      "learning_rate": 2.854387656702025e-06,
      "loss": 0.2187,
      "step": 80010
    },
    {
      "epoch": 8.573877638487089,
      "grad_norm": 0.0003397510154172778,
      "learning_rate": 2.8522447230258228e-06,
      "loss": 0.0003,
      "step": 80020
    },
    {
      "epoch": 8.57494910532519,
      "grad_norm": 0.0003119575558230281,
      "learning_rate": 2.8501017893496197e-06,
      "loss": 0.2666,
      "step": 80030
    },
    {
      "epoch": 8.57602057216329,
      "grad_norm": 0.04540378227829933,
      "learning_rate": 2.847958855673417e-06,
      "loss": 0.0002,
      "step": 80040
    },
    {
      "epoch": 8.577092039001393,
      "grad_norm": 0.002983585698530078,
      "learning_rate": 2.8458159219972144e-06,
      "loss": 0.0001,
      "step": 80050
    },
    {
      "epoch": 8.578163505839495,
      "grad_norm": 0.004329523537307978,
      "learning_rate": 2.8436729883210118e-06,
      "loss": 0.0,
      "step": 80060
    },
    {
      "epoch": 8.579234972677595,
      "grad_norm": 0.01033211499452591,
      "learning_rate": 2.8415300546448087e-06,
      "loss": 0.0003,
      "step": 80070
    },
    {
      "epoch": 8.580306439515697,
      "grad_norm": 0.10655251890420914,
      "learning_rate": 2.8393871209686065e-06,
      "loss": 0.0005,
      "step": 80080
    },
    {
      "epoch": 8.581377906353799,
      "grad_norm": 0.47217684984207153,
      "learning_rate": 2.8372441872924034e-06,
      "loss": 0.0003,
      "step": 80090
    },
    {
      "epoch": 8.5824493731919,
      "grad_norm": 0.20004232227802277,
      "learning_rate": 2.8351012536162008e-06,
      "loss": 0.0004,
      "step": 80100
    },
    {
      "epoch": 8.583520840030001,
      "grad_norm": 8.650842937640846e-05,
      "learning_rate": 2.832958319939998e-06,
      "loss": 0.0,
      "step": 80110
    },
    {
      "epoch": 8.584592306868103,
      "grad_norm": 0.002490366343408823,
      "learning_rate": 2.8308153862637955e-06,
      "loss": 0.0001,
      "step": 80120
    },
    {
      "epoch": 8.585663773706203,
      "grad_norm": 0.00212714821100235,
      "learning_rate": 2.8286724525875924e-06,
      "loss": 0.0001,
      "step": 80130
    },
    {
      "epoch": 8.586735240544305,
      "grad_norm": 0.03897107392549515,
      "learning_rate": 2.82652951891139e-06,
      "loss": 0.165,
      "step": 80140
    },
    {
      "epoch": 8.587806707382406,
      "grad_norm": 0.0024258517660200596,
      "learning_rate": 2.824386585235187e-06,
      "loss": 0.109,
      "step": 80150
    },
    {
      "epoch": 8.588878174220508,
      "grad_norm": 0.0001013501823763363,
      "learning_rate": 2.8222436515589845e-06,
      "loss": 0.0002,
      "step": 80160
    },
    {
      "epoch": 8.58994964105861,
      "grad_norm": 0.00019801277085207403,
      "learning_rate": 2.8201007178827814e-06,
      "loss": 0.0001,
      "step": 80170
    },
    {
      "epoch": 8.59102110789671,
      "grad_norm": 0.0014941071858629584,
      "learning_rate": 2.817957784206579e-06,
      "loss": 0.1775,
      "step": 80180
    },
    {
      "epoch": 8.592092574734812,
      "grad_norm": 5.830986976623535,
      "learning_rate": 2.815814850530376e-06,
      "loss": 0.1536,
      "step": 80190
    },
    {
      "epoch": 8.593164041572914,
      "grad_norm": 0.018353590741753578,
      "learning_rate": 2.813671916854174e-06,
      "loss": 0.1941,
      "step": 80200
    },
    {
      "epoch": 8.594235508411014,
      "grad_norm": 0.15005862712860107,
      "learning_rate": 2.811528983177971e-06,
      "loss": 0.1775,
      "step": 80210
    },
    {
      "epoch": 8.595306975249116,
      "grad_norm": 0.00010689301416277885,
      "learning_rate": 2.809386049501768e-06,
      "loss": 0.0001,
      "step": 80220
    },
    {
      "epoch": 8.596378442087218,
      "grad_norm": 18.77347755432129,
      "learning_rate": 2.807243115825565e-06,
      "loss": 0.1896,
      "step": 80230
    },
    {
      "epoch": 8.597449908925318,
      "grad_norm": 0.0017791829304769635,
      "learning_rate": 2.805100182149363e-06,
      "loss": 0.2139,
      "step": 80240
    },
    {
      "epoch": 8.59852137576342,
      "grad_norm": 0.002625227440148592,
      "learning_rate": 2.80295724847316e-06,
      "loss": 0.0006,
      "step": 80250
    },
    {
      "epoch": 8.599592842601522,
      "grad_norm": 38.02852249145508,
      "learning_rate": 2.8008143147969576e-06,
      "loss": 0.3166,
      "step": 80260
    },
    {
      "epoch": 8.600664309439622,
      "grad_norm": 0.00014127946633379906,
      "learning_rate": 2.7986713811207545e-06,
      "loss": 0.0002,
      "step": 80270
    },
    {
      "epoch": 8.601735776277724,
      "grad_norm": 8.568496559746563e-05,
      "learning_rate": 2.796528447444552e-06,
      "loss": 0.2162,
      "step": 80280
    },
    {
      "epoch": 8.602807243115826,
      "grad_norm": 0.0035455578472465277,
      "learning_rate": 2.794385513768349e-06,
      "loss": 0.0001,
      "step": 80290
    },
    {
      "epoch": 8.603878709953927,
      "grad_norm": 0.0029706801287829876,
      "learning_rate": 2.7922425800921466e-06,
      "loss": 0.2795,
      "step": 80300
    },
    {
      "epoch": 8.604950176792029,
      "grad_norm": 0.00022195844212546945,
      "learning_rate": 2.7900996464159435e-06,
      "loss": 0.0044,
      "step": 80310
    },
    {
      "epoch": 8.606021643630129,
      "grad_norm": 0.00011629692016867921,
      "learning_rate": 2.7879567127397413e-06,
      "loss": 0.0,
      "step": 80320
    },
    {
      "epoch": 8.607093110468231,
      "grad_norm": 0.00011257757432758808,
      "learning_rate": 2.7858137790635383e-06,
      "loss": 0.2117,
      "step": 80330
    },
    {
      "epoch": 8.608164577306333,
      "grad_norm": 0.002421278739348054,
      "learning_rate": 2.7836708453873356e-06,
      "loss": 0.0003,
      "step": 80340
    },
    {
      "epoch": 8.609236044144433,
      "grad_norm": 0.01953458972275257,
      "learning_rate": 2.7815279117111325e-06,
      "loss": 0.1104,
      "step": 80350
    },
    {
      "epoch": 8.610307510982535,
      "grad_norm": 0.0006682031089439988,
      "learning_rate": 2.7793849780349303e-06,
      "loss": 0.0009,
      "step": 80360
    },
    {
      "epoch": 8.611378977820637,
      "grad_norm": 0.037043336778879166,
      "learning_rate": 2.7772420443587272e-06,
      "loss": 0.0004,
      "step": 80370
    },
    {
      "epoch": 8.612450444658737,
      "grad_norm": 0.001928816200233996,
      "learning_rate": 2.7750991106825246e-06,
      "loss": 0.0002,
      "step": 80380
    },
    {
      "epoch": 8.61352191149684,
      "grad_norm": 0.00013214926002547145,
      "learning_rate": 2.772956177006322e-06,
      "loss": 0.0002,
      "step": 80390
    },
    {
      "epoch": 8.614593378334941,
      "grad_norm": 0.16946622729301453,
      "learning_rate": 2.7708132433301193e-06,
      "loss": 0.0007,
      "step": 80400
    },
    {
      "epoch": 8.615664845173042,
      "grad_norm": 0.0001909844286274165,
      "learning_rate": 2.7686703096539162e-06,
      "loss": 0.0055,
      "step": 80410
    },
    {
      "epoch": 8.616736312011144,
      "grad_norm": 0.003357234410941601,
      "learning_rate": 2.766527375977714e-06,
      "loss": 0.0003,
      "step": 80420
    },
    {
      "epoch": 8.617807778849244,
      "grad_norm": 44.37910842895508,
      "learning_rate": 2.764384442301511e-06,
      "loss": 0.1079,
      "step": 80430
    },
    {
      "epoch": 8.618879245687346,
      "grad_norm": 0.02107039839029312,
      "learning_rate": 2.7622415086253083e-06,
      "loss": 0.0106,
      "step": 80440
    },
    {
      "epoch": 8.619950712525448,
      "grad_norm": 0.00010478925833012909,
      "learning_rate": 2.7600985749491057e-06,
      "loss": 0.0053,
      "step": 80450
    },
    {
      "epoch": 8.621022179363548,
      "grad_norm": 0.00106522673740983,
      "learning_rate": 2.757955641272903e-06,
      "loss": 0.0003,
      "step": 80460
    },
    {
      "epoch": 8.62209364620165,
      "grad_norm": 0.00010040968481916934,
      "learning_rate": 2.7558127075967e-06,
      "loss": 0.0001,
      "step": 80470
    },
    {
      "epoch": 8.623165113039752,
      "grad_norm": 0.002611022675409913,
      "learning_rate": 2.7536697739204977e-06,
      "loss": 0.0012,
      "step": 80480
    },
    {
      "epoch": 8.624236579877852,
      "grad_norm": 0.00020839873468503356,
      "learning_rate": 2.7515268402442947e-06,
      "loss": 0.0021,
      "step": 80490
    },
    {
      "epoch": 8.625308046715954,
      "grad_norm": 0.00015624954539816827,
      "learning_rate": 2.749383906568092e-06,
      "loss": 0.0,
      "step": 80500
    },
    {
      "epoch": 8.626379513554056,
      "grad_norm": 0.0028888031374663115,
      "learning_rate": 2.7472409728918894e-06,
      "loss": 0.0001,
      "step": 80510
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 0.00011663566692732275,
      "learning_rate": 2.7450980392156867e-06,
      "loss": 0.0002,
      "step": 80520
    },
    {
      "epoch": 8.628522447230258,
      "grad_norm": 0.002466993173584342,
      "learning_rate": 2.7429551055394837e-06,
      "loss": 0.0001,
      "step": 80530
    },
    {
      "epoch": 8.62959391406836,
      "grad_norm": 0.06491933763027191,
      "learning_rate": 2.7408121718632815e-06,
      "loss": 0.194,
      "step": 80540
    },
    {
      "epoch": 8.63066538090646,
      "grad_norm": 0.0019462358905002475,
      "learning_rate": 2.7386692381870784e-06,
      "loss": 0.0001,
      "step": 80550
    },
    {
      "epoch": 8.631736847744563,
      "grad_norm": 0.00010669312905520201,
      "learning_rate": 2.7365263045108757e-06,
      "loss": 0.002,
      "step": 80560
    },
    {
      "epoch": 8.632808314582663,
      "grad_norm": 0.16415908932685852,
      "learning_rate": 2.7343833708346727e-06,
      "loss": 0.1827,
      "step": 80570
    },
    {
      "epoch": 8.633879781420765,
      "grad_norm": 0.008566093631088734,
      "learning_rate": 2.7322404371584705e-06,
      "loss": 0.0001,
      "step": 80580
    },
    {
      "epoch": 8.634951248258867,
      "grad_norm": 0.0017519430257380009,
      "learning_rate": 2.7300975034822674e-06,
      "loss": 0.0983,
      "step": 80590
    },
    {
      "epoch": 8.636022715096967,
      "grad_norm": 0.9707822203636169,
      "learning_rate": 2.727954569806065e-06,
      "loss": 0.0007,
      "step": 80600
    },
    {
      "epoch": 8.637094181935069,
      "grad_norm": 0.0019157245988026261,
      "learning_rate": 2.725811636129862e-06,
      "loss": 0.173,
      "step": 80610
    },
    {
      "epoch": 8.638165648773171,
      "grad_norm": 0.025118788704276085,
      "learning_rate": 2.7236687024536595e-06,
      "loss": 0.0006,
      "step": 80620
    },
    {
      "epoch": 8.639237115611271,
      "grad_norm": 0.004312618635594845,
      "learning_rate": 2.7215257687774564e-06,
      "loss": 0.1826,
      "step": 80630
    },
    {
      "epoch": 8.640308582449373,
      "grad_norm": 0.00010895039304159582,
      "learning_rate": 2.719382835101254e-06,
      "loss": 0.0012,
      "step": 80640
    },
    {
      "epoch": 8.641380049287475,
      "grad_norm": 0.056716226041316986,
      "learning_rate": 2.717239901425051e-06,
      "loss": 0.1553,
      "step": 80650
    },
    {
      "epoch": 8.642451516125575,
      "grad_norm": 0.0029966123402118683,
      "learning_rate": 2.715096967748848e-06,
      "loss": 0.0002,
      "step": 80660
    },
    {
      "epoch": 8.643522982963677,
      "grad_norm": 0.0004160420212429017,
      "learning_rate": 2.712954034072646e-06,
      "loss": 0.0002,
      "step": 80670
    },
    {
      "epoch": 8.64459444980178,
      "grad_norm": 0.0047299363650381565,
      "learning_rate": 2.7108111003964427e-06,
      "loss": 0.0,
      "step": 80680
    },
    {
      "epoch": 8.64566591663988,
      "grad_norm": 0.007090579252690077,
      "learning_rate": 2.70866816672024e-06,
      "loss": 0.0004,
      "step": 80690
    },
    {
      "epoch": 8.646737383477982,
      "grad_norm": 9.03843465493992e-05,
      "learning_rate": 2.7065252330440375e-06,
      "loss": 0.0001,
      "step": 80700
    },
    {
      "epoch": 8.647808850316082,
      "grad_norm": 0.00010809594095917419,
      "learning_rate": 2.704382299367835e-06,
      "loss": 0.0001,
      "step": 80710
    },
    {
      "epoch": 8.648880317154184,
      "grad_norm": 0.00010992031457135454,
      "learning_rate": 2.7022393656916317e-06,
      "loss": 0.3557,
      "step": 80720
    },
    {
      "epoch": 8.649951783992286,
      "grad_norm": 0.07168872654438019,
      "learning_rate": 2.7000964320154295e-06,
      "loss": 0.0002,
      "step": 80730
    },
    {
      "epoch": 8.651023250830386,
      "grad_norm": 0.00010053909500129521,
      "learning_rate": 2.6979534983392265e-06,
      "loss": 0.0003,
      "step": 80740
    },
    {
      "epoch": 8.652094717668488,
      "grad_norm": 0.006686469539999962,
      "learning_rate": 2.695810564663024e-06,
      "loss": 0.2001,
      "step": 80750
    },
    {
      "epoch": 8.65316618450659,
      "grad_norm": 9.753962513059378e-05,
      "learning_rate": 2.6936676309868207e-06,
      "loss": 0.0005,
      "step": 80760
    },
    {
      "epoch": 8.65423765134469,
      "grad_norm": 0.00010647386807249859,
      "learning_rate": 2.6915246973106185e-06,
      "loss": 0.0908,
      "step": 80770
    },
    {
      "epoch": 8.655309118182792,
      "grad_norm": 9.569160465616733e-05,
      "learning_rate": 2.6893817636344154e-06,
      "loss": 0.0002,
      "step": 80780
    },
    {
      "epoch": 8.656380585020894,
      "grad_norm": 0.005904402118176222,
      "learning_rate": 2.6872388299582132e-06,
      "loss": 0.0,
      "step": 80790
    },
    {
      "epoch": 8.657452051858995,
      "grad_norm": 0.0035471476148813963,
      "learning_rate": 2.68509589628201e-06,
      "loss": 0.0003,
      "step": 80800
    },
    {
      "epoch": 8.658523518697097,
      "grad_norm": 0.00011133759107906371,
      "learning_rate": 2.6829529626058075e-06,
      "loss": 0.2063,
      "step": 80810
    },
    {
      "epoch": 8.659594985535197,
      "grad_norm": 0.0018837969982996583,
      "learning_rate": 2.6808100289296044e-06,
      "loss": 0.0001,
      "step": 80820
    },
    {
      "epoch": 8.660666452373299,
      "grad_norm": 7.963655662024394e-05,
      "learning_rate": 2.6786670952534022e-06,
      "loss": 0.0,
      "step": 80830
    },
    {
      "epoch": 8.6617379192114,
      "grad_norm": 0.002389197237789631,
      "learning_rate": 2.676524161577199e-06,
      "loss": 0.0002,
      "step": 80840
    },
    {
      "epoch": 8.662809386049501,
      "grad_norm": 0.0015259961364790797,
      "learning_rate": 2.674381227900997e-06,
      "loss": 0.0002,
      "step": 80850
    },
    {
      "epoch": 8.663880852887603,
      "grad_norm": 0.0034234398044645786,
      "learning_rate": 2.672238294224794e-06,
      "loss": 0.0003,
      "step": 80860
    },
    {
      "epoch": 8.664952319725705,
      "grad_norm": 0.0013118403730913997,
      "learning_rate": 2.6700953605485912e-06,
      "loss": 0.0002,
      "step": 80870
    },
    {
      "epoch": 8.666023786563805,
      "grad_norm": 0.00076823536073789,
      "learning_rate": 2.667952426872388e-06,
      "loss": 0.0001,
      "step": 80880
    },
    {
      "epoch": 8.667095253401907,
      "grad_norm": 0.002414776012301445,
      "learning_rate": 2.665809493196186e-06,
      "loss": 0.166,
      "step": 80890
    },
    {
      "epoch": 8.66816672024001,
      "grad_norm": 117.18929290771484,
      "learning_rate": 2.663666559519983e-06,
      "loss": 0.091,
      "step": 80900
    },
    {
      "epoch": 8.66923818707811,
      "grad_norm": 8.332214929396287e-05,
      "learning_rate": 2.6615236258437802e-06,
      "loss": 0.0146,
      "step": 80910
    },
    {
      "epoch": 8.670309653916211,
      "grad_norm": 0.008017044514417648,
      "learning_rate": 2.6593806921675776e-06,
      "loss": 0.1531,
      "step": 80920
    },
    {
      "epoch": 8.671381120754313,
      "grad_norm": 0.00304262968711555,
      "learning_rate": 2.657237758491375e-06,
      "loss": 0.2761,
      "step": 80930
    },
    {
      "epoch": 8.672452587592414,
      "grad_norm": 0.007639274466782808,
      "learning_rate": 2.655094824815172e-06,
      "loss": 0.0,
      "step": 80940
    },
    {
      "epoch": 8.673524054430516,
      "grad_norm": 0.0956256091594696,
      "learning_rate": 2.6529518911389697e-06,
      "loss": 0.0007,
      "step": 80950
    },
    {
      "epoch": 8.674595521268618,
      "grad_norm": 0.04115283116698265,
      "learning_rate": 2.6508089574627666e-06,
      "loss": 0.0052,
      "step": 80960
    },
    {
      "epoch": 8.675666988106718,
      "grad_norm": 0.000157506437972188,
      "learning_rate": 2.648666023786564e-06,
      "loss": 0.0,
      "step": 80970
    },
    {
      "epoch": 8.67673845494482,
      "grad_norm": 0.0007905617821961641,
      "learning_rate": 2.6465230901103613e-06,
      "loss": 0.0,
      "step": 80980
    },
    {
      "epoch": 8.67780992178292,
      "grad_norm": 0.0001174577118945308,
      "learning_rate": 2.6443801564341587e-06,
      "loss": 0.0001,
      "step": 80990
    },
    {
      "epoch": 8.678881388621022,
      "grad_norm": 0.03050921857357025,
      "learning_rate": 2.6422372227579556e-06,
      "loss": 0.0087,
      "step": 81000
    },
    {
      "epoch": 8.679952855459124,
      "grad_norm": 0.008270112797617912,
      "learning_rate": 2.6400942890817534e-06,
      "loss": 0.0001,
      "step": 81010
    },
    {
      "epoch": 8.681024322297224,
      "grad_norm": 0.001966072479262948,
      "learning_rate": 2.6379513554055503e-06,
      "loss": 0.0003,
      "step": 81020
    },
    {
      "epoch": 8.682095789135326,
      "grad_norm": 8.304267976200208e-05,
      "learning_rate": 2.6358084217293477e-06,
      "loss": 0.0007,
      "step": 81030
    },
    {
      "epoch": 8.683167255973428,
      "grad_norm": 8.120802522171289e-05,
      "learning_rate": 2.633665488053145e-06,
      "loss": 0.0,
      "step": 81040
    },
    {
      "epoch": 8.684238722811529,
      "grad_norm": 8.618137508165091e-05,
      "learning_rate": 2.6315225543769424e-06,
      "loss": 0.0,
      "step": 81050
    },
    {
      "epoch": 8.68531018964963,
      "grad_norm": 9.124532516580075e-05,
      "learning_rate": 2.6293796207007393e-06,
      "loss": 0.0755,
      "step": 81060
    },
    {
      "epoch": 8.686381656487733,
      "grad_norm": 0.009563521482050419,
      "learning_rate": 2.627236687024537e-06,
      "loss": 0.0003,
      "step": 81070
    },
    {
      "epoch": 8.687453123325833,
      "grad_norm": 0.0024282545782625675,
      "learning_rate": 2.625093753348334e-06,
      "loss": 0.0,
      "step": 81080
    },
    {
      "epoch": 8.688524590163935,
      "grad_norm": 7.90463454904966e-05,
      "learning_rate": 2.6229508196721314e-06,
      "loss": 0.0009,
      "step": 81090
    },
    {
      "epoch": 8.689596057002035,
      "grad_norm": 0.0033256749156862497,
      "learning_rate": 2.6208078859959283e-06,
      "loss": 0.0,
      "step": 81100
    },
    {
      "epoch": 8.690667523840137,
      "grad_norm": 0.0025925009977072477,
      "learning_rate": 2.618664952319726e-06,
      "loss": 0.0002,
      "step": 81110
    },
    {
      "epoch": 8.691738990678239,
      "grad_norm": 8.689348760526627e-05,
      "learning_rate": 2.616522018643523e-06,
      "loss": 0.0001,
      "step": 81120
    },
    {
      "epoch": 8.69281045751634,
      "grad_norm": 8.769344276515767e-05,
      "learning_rate": 2.6143790849673208e-06,
      "loss": 0.0003,
      "step": 81130
    },
    {
      "epoch": 8.693881924354441,
      "grad_norm": 0.029097680002450943,
      "learning_rate": 2.6122361512911177e-06,
      "loss": 0.0001,
      "step": 81140
    },
    {
      "epoch": 8.694953391192543,
      "grad_norm": 2250.4130859375,
      "learning_rate": 2.610093217614915e-06,
      "loss": 0.0054,
      "step": 81150
    },
    {
      "epoch": 8.696024858030643,
      "grad_norm": 0.00010124379332410172,
      "learning_rate": 2.607950283938712e-06,
      "loss": 0.0385,
      "step": 81160
    },
    {
      "epoch": 8.697096324868745,
      "grad_norm": 8.704290667083114e-05,
      "learning_rate": 2.6058073502625098e-06,
      "loss": 0.1543,
      "step": 81170
    },
    {
      "epoch": 8.698167791706847,
      "grad_norm": 0.0014438839862123132,
      "learning_rate": 2.6036644165863067e-06,
      "loss": 0.0001,
      "step": 81180
    },
    {
      "epoch": 8.699239258544948,
      "grad_norm": 0.002291040262207389,
      "learning_rate": 2.6015214829101045e-06,
      "loss": 0.2421,
      "step": 81190
    },
    {
      "epoch": 8.70031072538305,
      "grad_norm": 7.579701923532411e-05,
      "learning_rate": 2.5993785492339014e-06,
      "loss": 0.0,
      "step": 81200
    },
    {
      "epoch": 8.70138219222115,
      "grad_norm": 7.212807395262644e-05,
      "learning_rate": 2.5972356155576988e-06,
      "loss": 0.0004,
      "step": 81210
    },
    {
      "epoch": 8.702453659059252,
      "grad_norm": 0.0012400709092617035,
      "learning_rate": 2.5950926818814957e-06,
      "loss": 0.0001,
      "step": 81220
    },
    {
      "epoch": 8.703525125897354,
      "grad_norm": 0.0030170241370797157,
      "learning_rate": 2.5929497482052935e-06,
      "loss": 0.2228,
      "step": 81230
    },
    {
      "epoch": 8.704596592735454,
      "grad_norm": 0.0008453866466879845,
      "learning_rate": 2.5908068145290904e-06,
      "loss": 0.1888,
      "step": 81240
    },
    {
      "epoch": 8.705668059573556,
      "grad_norm": 0.018980734050273895,
      "learning_rate": 2.588663880852888e-06,
      "loss": 0.0002,
      "step": 81250
    },
    {
      "epoch": 8.706739526411658,
      "grad_norm": 8.863573748385534e-05,
      "learning_rate": 2.586520947176685e-06,
      "loss": 0.0,
      "step": 81260
    },
    {
      "epoch": 8.707810993249758,
      "grad_norm": 7.547946734121069e-05,
      "learning_rate": 2.5843780135004825e-06,
      "loss": 0.0,
      "step": 81270
    },
    {
      "epoch": 8.70888246008786,
      "grad_norm": 7.786406786181033e-05,
      "learning_rate": 2.5822350798242794e-06,
      "loss": 0.0001,
      "step": 81280
    },
    {
      "epoch": 8.709953926925962,
      "grad_norm": 0.0001060687645804137,
      "learning_rate": 2.580092146148077e-06,
      "loss": 0.1261,
      "step": 81290
    },
    {
      "epoch": 8.711025393764062,
      "grad_norm": 0.001441603759303689,
      "learning_rate": 2.577949212471874e-06,
      "loss": 0.0174,
      "step": 81300
    },
    {
      "epoch": 8.712096860602164,
      "grad_norm": 0.13639545440673828,
      "learning_rate": 2.5758062787956715e-06,
      "loss": 0.0004,
      "step": 81310
    },
    {
      "epoch": 8.713168327440266,
      "grad_norm": 0.004503757692873478,
      "learning_rate": 2.573663345119469e-06,
      "loss": 0.0001,
      "step": 81320
    },
    {
      "epoch": 8.714239794278367,
      "grad_norm": 8.439837984042242e-05,
      "learning_rate": 2.571520411443266e-06,
      "loss": 0.0001,
      "step": 81330
    },
    {
      "epoch": 8.715311261116469,
      "grad_norm": 0.0021129033993929625,
      "learning_rate": 2.569377477767063e-06,
      "loss": 0.229,
      "step": 81340
    },
    {
      "epoch": 8.71638272795457,
      "grad_norm": 0.00020471411698963493,
      "learning_rate": 2.567234544090861e-06,
      "loss": 0.1513,
      "step": 81350
    },
    {
      "epoch": 8.717454194792671,
      "grad_norm": 0.0036405089776962996,
      "learning_rate": 2.565091610414658e-06,
      "loss": 0.0001,
      "step": 81360
    },
    {
      "epoch": 8.718525661630773,
      "grad_norm": 0.0014806636609137058,
      "learning_rate": 2.562948676738455e-06,
      "loss": 0.0007,
      "step": 81370
    },
    {
      "epoch": 8.719597128468873,
      "grad_norm": 0.027750540524721146,
      "learning_rate": 2.5608057430622526e-06,
      "loss": 0.0135,
      "step": 81380
    },
    {
      "epoch": 8.720668595306975,
      "grad_norm": 8.996589167509228e-05,
      "learning_rate": 2.55866280938605e-06,
      "loss": 0.0008,
      "step": 81390
    },
    {
      "epoch": 8.721740062145077,
      "grad_norm": 0.005756336729973555,
      "learning_rate": 2.556519875709847e-06,
      "loss": 0.0049,
      "step": 81400
    },
    {
      "epoch": 8.722811528983177,
      "grad_norm": 0.0025789900682866573,
      "learning_rate": 2.5543769420336446e-06,
      "loss": 0.2488,
      "step": 81410
    },
    {
      "epoch": 8.72388299582128,
      "grad_norm": 9.250106086255983e-05,
      "learning_rate": 2.5522340083574416e-06,
      "loss": 0.2024,
      "step": 81420
    },
    {
      "epoch": 8.724954462659381,
      "grad_norm": 0.004621522966772318,
      "learning_rate": 2.550091074681239e-06,
      "loss": 0.0001,
      "step": 81430
    },
    {
      "epoch": 8.726025929497482,
      "grad_norm": 0.02841264195740223,
      "learning_rate": 2.5479481410050363e-06,
      "loss": 0.0004,
      "step": 81440
    },
    {
      "epoch": 8.727097396335584,
      "grad_norm": 0.09470396488904953,
      "learning_rate": 2.5458052073288336e-06,
      "loss": 0.0003,
      "step": 81450
    },
    {
      "epoch": 8.728168863173686,
      "grad_norm": 0.022858599200844765,
      "learning_rate": 2.5436622736526306e-06,
      "loss": 0.0001,
      "step": 81460
    },
    {
      "epoch": 8.729240330011786,
      "grad_norm": 0.002908687572926283,
      "learning_rate": 2.5415193399764283e-06,
      "loss": 0.0002,
      "step": 81470
    },
    {
      "epoch": 8.730311796849888,
      "grad_norm": 9.392832726007327e-05,
      "learning_rate": 2.5393764063002253e-06,
      "loss": 0.0001,
      "step": 81480
    },
    {
      "epoch": 8.731383263687988,
      "grad_norm": 0.002901265397667885,
      "learning_rate": 2.5372334726240226e-06,
      "loss": 0.2296,
      "step": 81490
    },
    {
      "epoch": 8.73245473052609,
      "grad_norm": 0.0016460472252219915,
      "learning_rate": 2.5350905389478196e-06,
      "loss": 0.0002,
      "step": 81500
    },
    {
      "epoch": 8.733526197364192,
      "grad_norm": 0.0001359194575343281,
      "learning_rate": 2.5329476052716173e-06,
      "loss": 0.0,
      "step": 81510
    },
    {
      "epoch": 8.734597664202292,
      "grad_norm": 0.0012471283553168178,
      "learning_rate": 2.5308046715954143e-06,
      "loss": 0.0,
      "step": 81520
    },
    {
      "epoch": 8.735669131040394,
      "grad_norm": 0.0033179561141878366,
      "learning_rate": 2.528661737919212e-06,
      "loss": 0.0001,
      "step": 81530
    },
    {
      "epoch": 8.736740597878496,
      "grad_norm": 0.00012457845150493085,
      "learning_rate": 2.526518804243009e-06,
      "loss": 0.1393,
      "step": 81540
    },
    {
      "epoch": 8.737812064716596,
      "grad_norm": 0.00017507626034785062,
      "learning_rate": 2.5243758705668063e-06,
      "loss": 0.0006,
      "step": 81550
    },
    {
      "epoch": 8.738883531554698,
      "grad_norm": 0.002102467231452465,
      "learning_rate": 2.5222329368906033e-06,
      "loss": 0.0005,
      "step": 81560
    },
    {
      "epoch": 8.7399549983928,
      "grad_norm": 0.0002659170131664723,
      "learning_rate": 2.5200900032144006e-06,
      "loss": 0.0002,
      "step": 81570
    },
    {
      "epoch": 8.7410264652309,
      "grad_norm": 0.009459033608436584,
      "learning_rate": 2.517947069538198e-06,
      "loss": 0.0001,
      "step": 81580
    },
    {
      "epoch": 8.742097932069003,
      "grad_norm": 0.000933874340262264,
      "learning_rate": 2.515804135861995e-06,
      "loss": 0.0086,
      "step": 81590
    },
    {
      "epoch": 8.743169398907105,
      "grad_norm": 0.010650238022208214,
      "learning_rate": 2.5136612021857927e-06,
      "loss": 0.0,
      "step": 81600
    },
    {
      "epoch": 8.744240865745205,
      "grad_norm": 0.021048659458756447,
      "learning_rate": 2.5115182685095896e-06,
      "loss": 0.1645,
      "step": 81610
    },
    {
      "epoch": 8.745312332583307,
      "grad_norm": 0.004703430458903313,
      "learning_rate": 2.509375334833387e-06,
      "loss": 0.0003,
      "step": 81620
    },
    {
      "epoch": 8.746383799421407,
      "grad_norm": 7.811257819412276e-05,
      "learning_rate": 2.5072324011571843e-06,
      "loss": 0.0004,
      "step": 81630
    },
    {
      "epoch": 8.747455266259509,
      "grad_norm": 0.004374196752905846,
      "learning_rate": 2.5050894674809817e-06,
      "loss": 0.1948,
      "step": 81640
    },
    {
      "epoch": 8.748526733097611,
      "grad_norm": 7.64188589528203e-05,
      "learning_rate": 2.5029465338047786e-06,
      "loss": 0.0001,
      "step": 81650
    },
    {
      "epoch": 8.749598199935711,
      "grad_norm": 0.0019754907116293907,
      "learning_rate": 2.5008036001285764e-06,
      "loss": 0.018,
      "step": 81660
    },
    {
      "epoch": 8.750669666773813,
      "grad_norm": 0.0011819914216175675,
      "learning_rate": 2.4986606664523733e-06,
      "loss": 0.0001,
      "step": 81670
    },
    {
      "epoch": 8.751741133611915,
      "grad_norm": 8.315454761032015e-05,
      "learning_rate": 2.4965177327761707e-06,
      "loss": 0.0009,
      "step": 81680
    },
    {
      "epoch": 8.752812600450016,
      "grad_norm": 8.38536216178909e-05,
      "learning_rate": 2.494374799099968e-06,
      "loss": 0.0,
      "step": 81690
    },
    {
      "epoch": 8.753884067288118,
      "grad_norm": 0.04167693480849266,
      "learning_rate": 2.4922318654237654e-06,
      "loss": 0.0002,
      "step": 81700
    },
    {
      "epoch": 8.75495553412622,
      "grad_norm": 0.0027835555374622345,
      "learning_rate": 2.4900889317475628e-06,
      "loss": 0.0004,
      "step": 81710
    },
    {
      "epoch": 8.75602700096432,
      "grad_norm": 6.995770672801882e-05,
      "learning_rate": 2.48794599807136e-06,
      "loss": 0.0001,
      "step": 81720
    },
    {
      "epoch": 8.757098467802422,
      "grad_norm": 5.201596260070801,
      "learning_rate": 2.485803064395157e-06,
      "loss": 0.0009,
      "step": 81730
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 0.0015696872724220157,
      "learning_rate": 2.4836601307189544e-06,
      "loss": 0.0,
      "step": 81740
    },
    {
      "epoch": 8.759241401478624,
      "grad_norm": 0.00010322771413484588,
      "learning_rate": 2.4815171970427518e-06,
      "loss": 0.0533,
      "step": 81750
    },
    {
      "epoch": 8.760312868316726,
      "grad_norm": 59.04335021972656,
      "learning_rate": 2.479374263366549e-06,
      "loss": 0.2212,
      "step": 81760
    },
    {
      "epoch": 8.761384335154826,
      "grad_norm": 0.018020259216427803,
      "learning_rate": 2.4772313296903465e-06,
      "loss": 0.0001,
      "step": 81770
    },
    {
      "epoch": 8.762455801992928,
      "grad_norm": 0.0001085786716430448,
      "learning_rate": 2.475088396014144e-06,
      "loss": 0.0007,
      "step": 81780
    },
    {
      "epoch": 8.76352726883103,
      "grad_norm": 8.847740537021309e-05,
      "learning_rate": 2.4729454623379408e-06,
      "loss": 0.0,
      "step": 81790
    },
    {
      "epoch": 8.76459873566913,
      "grad_norm": 7.825853390386328e-05,
      "learning_rate": 2.470802528661738e-06,
      "loss": 0.4717,
      "step": 81800
    },
    {
      "epoch": 8.765670202507232,
      "grad_norm": 0.016853956505656242,
      "learning_rate": 2.4686595949855355e-06,
      "loss": 0.0,
      "step": 81810
    },
    {
      "epoch": 8.766741669345334,
      "grad_norm": 0.0011113822693005204,
      "learning_rate": 2.466516661309333e-06,
      "loss": 0.0001,
      "step": 81820
    },
    {
      "epoch": 8.767813136183435,
      "grad_norm": 0.0035919426009058952,
      "learning_rate": 2.46437372763313e-06,
      "loss": 0.0005,
      "step": 81830
    },
    {
      "epoch": 8.768884603021537,
      "grad_norm": 6.707383727189153e-05,
      "learning_rate": 2.462230793956927e-06,
      "loss": 0.0001,
      "step": 81840
    },
    {
      "epoch": 8.769956069859639,
      "grad_norm": 0.001148671843111515,
      "learning_rate": 2.4600878602807245e-06,
      "loss": 0.2192,
      "step": 81850
    },
    {
      "epoch": 8.771027536697739,
      "grad_norm": 0.00500226067379117,
      "learning_rate": 2.457944926604522e-06,
      "loss": 0.0,
      "step": 81860
    },
    {
      "epoch": 8.77209900353584,
      "grad_norm": 8.136530959745869e-05,
      "learning_rate": 2.455801992928319e-06,
      "loss": 0.0001,
      "step": 81870
    },
    {
      "epoch": 8.773170470373941,
      "grad_norm": 0.00010386484063928947,
      "learning_rate": 2.4536590592521165e-06,
      "loss": 0.1596,
      "step": 81880
    },
    {
      "epoch": 8.774241937212043,
      "grad_norm": 7.016440213192254e-05,
      "learning_rate": 2.451516125575914e-06,
      "loss": 0.0,
      "step": 81890
    },
    {
      "epoch": 8.775313404050145,
      "grad_norm": 0.0002839666267391294,
      "learning_rate": 2.449373191899711e-06,
      "loss": 0.0,
      "step": 81900
    },
    {
      "epoch": 8.776384870888245,
      "grad_norm": 0.08064346015453339,
      "learning_rate": 2.447230258223508e-06,
      "loss": 0.0001,
      "step": 81910
    },
    {
      "epoch": 8.777456337726347,
      "grad_norm": 0.000115236260171514,
      "learning_rate": 2.4450873245473055e-06,
      "loss": 0.0001,
      "step": 81920
    },
    {
      "epoch": 8.77852780456445,
      "grad_norm": 6.425663741538301e-05,
      "learning_rate": 2.442944390871103e-06,
      "loss": 0.0001,
      "step": 81930
    },
    {
      "epoch": 8.77959927140255,
      "grad_norm": 0.8641718029975891,
      "learning_rate": 2.4408014571949003e-06,
      "loss": 0.0008,
      "step": 81940
    },
    {
      "epoch": 8.780670738240651,
      "grad_norm": 0.0011517074890434742,
      "learning_rate": 2.4386585235186976e-06,
      "loss": 0.193,
      "step": 81950
    },
    {
      "epoch": 8.781742205078753,
      "grad_norm": 0.0016784480540081859,
      "learning_rate": 2.4365155898424945e-06,
      "loss": 0.0001,
      "step": 81960
    },
    {
      "epoch": 8.782813671916854,
      "grad_norm": 0.0017706075450405478,
      "learning_rate": 2.434372656166292e-06,
      "loss": 0.0259,
      "step": 81970
    },
    {
      "epoch": 8.783885138754956,
      "grad_norm": 38.647403717041016,
      "learning_rate": 2.4322297224900893e-06,
      "loss": 0.2024,
      "step": 81980
    },
    {
      "epoch": 8.784956605593058,
      "grad_norm": 0.001702627632766962,
      "learning_rate": 2.4300867888138866e-06,
      "loss": 0.0009,
      "step": 81990
    },
    {
      "epoch": 8.786028072431158,
      "grad_norm": 0.4441593289375305,
      "learning_rate": 2.427943855137684e-06,
      "loss": 0.0009,
      "step": 82000
    },
    {
      "epoch": 8.78709953926926,
      "grad_norm": 0.0016417356673628092,
      "learning_rate": 2.425800921461481e-06,
      "loss": 0.0,
      "step": 82010
    },
    {
      "epoch": 8.788171006107362,
      "grad_norm": 0.00010983044921886176,
      "learning_rate": 2.4236579877852783e-06,
      "loss": 0.375,
      "step": 82020
    },
    {
      "epoch": 8.789242472945462,
      "grad_norm": 7.78765170252882e-05,
      "learning_rate": 2.421515054109075e-06,
      "loss": 0.0002,
      "step": 82030
    },
    {
      "epoch": 8.790313939783564,
      "grad_norm": 0.005988800898194313,
      "learning_rate": 2.4193721204328725e-06,
      "loss": 0.0008,
      "step": 82040
    },
    {
      "epoch": 8.791385406621664,
      "grad_norm": 0.15267932415008545,
      "learning_rate": 2.41722918675667e-06,
      "loss": 0.0002,
      "step": 82050
    },
    {
      "epoch": 8.792456873459766,
      "grad_norm": 7.965316763147712e-05,
      "learning_rate": 2.4150862530804673e-06,
      "loss": 0.0007,
      "step": 82060
    },
    {
      "epoch": 8.793528340297868,
      "grad_norm": 0.0059984102845191956,
      "learning_rate": 2.4129433194042646e-06,
      "loss": 0.0004,
      "step": 82070
    },
    {
      "epoch": 8.794599807135969,
      "grad_norm": 8.131877984851599e-05,
      "learning_rate": 2.410800385728062e-06,
      "loss": 0.0001,
      "step": 82080
    },
    {
      "epoch": 8.79567127397407,
      "grad_norm": 0.0023042657412588596,
      "learning_rate": 2.408657452051859e-06,
      "loss": 0.0002,
      "step": 82090
    },
    {
      "epoch": 8.796742740812173,
      "grad_norm": 8.374255412491038e-05,
      "learning_rate": 2.4065145183756563e-06,
      "loss": 0.0001,
      "step": 82100
    },
    {
      "epoch": 8.797814207650273,
      "grad_norm": 8.557723776903003e-05,
      "learning_rate": 2.4043715846994536e-06,
      "loss": 0.0001,
      "step": 82110
    },
    {
      "epoch": 8.798885674488375,
      "grad_norm": 0.000958485878072679,
      "learning_rate": 2.402228651023251e-06,
      "loss": 0.0001,
      "step": 82120
    },
    {
      "epoch": 8.799957141326477,
      "grad_norm": 0.058997947722673416,
      "learning_rate": 2.4000857173470483e-06,
      "loss": 0.0002,
      "step": 82130
    },
    {
      "epoch": 8.801028608164577,
      "grad_norm": 7.690375059610233e-05,
      "learning_rate": 2.3979427836708457e-06,
      "loss": 0.0,
      "step": 82140
    },
    {
      "epoch": 8.802100075002679,
      "grad_norm": 6.816523091401905e-05,
      "learning_rate": 2.3957998499946426e-06,
      "loss": 0.1314,
      "step": 82150
    },
    {
      "epoch": 8.80317154184078,
      "grad_norm": 7.796622230671346e-05,
      "learning_rate": 2.39365691631844e-06,
      "loss": 0.0,
      "step": 82160
    },
    {
      "epoch": 8.804243008678881,
      "grad_norm": 0.019003091380000114,
      "learning_rate": 2.3915139826422373e-06,
      "loss": 0.0,
      "step": 82170
    },
    {
      "epoch": 8.805314475516983,
      "grad_norm": 7.594856288051233e-05,
      "learning_rate": 2.3893710489660347e-06,
      "loss": 0.0003,
      "step": 82180
    },
    {
      "epoch": 8.806385942355083,
      "grad_norm": 0.009474553167819977,
      "learning_rate": 2.387228115289832e-06,
      "loss": 0.0001,
      "step": 82190
    },
    {
      "epoch": 8.807457409193185,
      "grad_norm": 0.0038383272476494312,
      "learning_rate": 2.3850851816136294e-06,
      "loss": 0.0015,
      "step": 82200
    },
    {
      "epoch": 8.808528876031287,
      "grad_norm": 0.001447365153580904,
      "learning_rate": 2.3829422479374263e-06,
      "loss": 0.1317,
      "step": 82210
    },
    {
      "epoch": 8.809600342869388,
      "grad_norm": 0.0009664812823757529,
      "learning_rate": 2.3807993142612237e-06,
      "loss": 0.0001,
      "step": 82220
    },
    {
      "epoch": 8.81067180970749,
      "grad_norm": 0.0020586326718330383,
      "learning_rate": 2.378656380585021e-06,
      "loss": 0.0001,
      "step": 82230
    },
    {
      "epoch": 8.811743276545592,
      "grad_norm": 0.00012910082296002656,
      "learning_rate": 2.3765134469088184e-06,
      "loss": 0.0001,
      "step": 82240
    },
    {
      "epoch": 8.812814743383692,
      "grad_norm": 0.05285722389817238,
      "learning_rate": 2.3743705132326157e-06,
      "loss": 0.0002,
      "step": 82250
    },
    {
      "epoch": 8.813886210221794,
      "grad_norm": 0.002194633474573493,
      "learning_rate": 2.3722275795564127e-06,
      "loss": 0.0,
      "step": 82260
    },
    {
      "epoch": 8.814957677059894,
      "grad_norm": 5.616802809527144e-05,
      "learning_rate": 2.37008464588021e-06,
      "loss": 0.0,
      "step": 82270
    },
    {
      "epoch": 8.816029143897996,
      "grad_norm": 0.0007765120244584978,
      "learning_rate": 2.3679417122040074e-06,
      "loss": 0.0001,
      "step": 82280
    },
    {
      "epoch": 8.817100610736098,
      "grad_norm": 0.0020488998852670193,
      "learning_rate": 2.3657987785278047e-06,
      "loss": 0.0,
      "step": 82290
    },
    {
      "epoch": 8.818172077574198,
      "grad_norm": 9.160323679680005e-05,
      "learning_rate": 2.363655844851602e-06,
      "loss": 0.0012,
      "step": 82300
    },
    {
      "epoch": 8.8192435444123,
      "grad_norm": 0.00010961203224724159,
      "learning_rate": 2.3615129111753995e-06,
      "loss": 0.003,
      "step": 82310
    },
    {
      "epoch": 8.820315011250402,
      "grad_norm": 7.086795085342601e-05,
      "learning_rate": 2.3593699774991964e-06,
      "loss": 0.0,
      "step": 82320
    },
    {
      "epoch": 8.821386478088503,
      "grad_norm": 7.945916149765253e-05,
      "learning_rate": 2.3572270438229937e-06,
      "loss": 0.0001,
      "step": 82330
    },
    {
      "epoch": 8.822457944926605,
      "grad_norm": 7.144170376705006e-05,
      "learning_rate": 2.355084110146791e-06,
      "loss": 0.0,
      "step": 82340
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 0.006630835589021444,
      "learning_rate": 2.3529411764705885e-06,
      "loss": 0.0001,
      "step": 82350
    },
    {
      "epoch": 8.824600878602807,
      "grad_norm": 0.0031271367333829403,
      "learning_rate": 2.350798242794386e-06,
      "loss": 0.0016,
      "step": 82360
    },
    {
      "epoch": 8.825672345440909,
      "grad_norm": 0.07915114611387253,
      "learning_rate": 2.348655309118183e-06,
      "loss": 0.2278,
      "step": 82370
    },
    {
      "epoch": 8.82674381227901,
      "grad_norm": 0.003998896107077599,
      "learning_rate": 2.34651237544198e-06,
      "loss": 0.0,
      "step": 82380
    },
    {
      "epoch": 8.827815279117111,
      "grad_norm": 0.001588649582117796,
      "learning_rate": 2.3443694417657775e-06,
      "loss": 0.0007,
      "step": 82390
    },
    {
      "epoch": 8.828886745955213,
      "grad_norm": 0.0009383289143443108,
      "learning_rate": 2.342226508089575e-06,
      "loss": 0.0001,
      "step": 82400
    },
    {
      "epoch": 8.829958212793315,
      "grad_norm": 0.0052696652710437775,
      "learning_rate": 2.340083574413372e-06,
      "loss": 0.1931,
      "step": 82410
    },
    {
      "epoch": 8.831029679631415,
      "grad_norm": 0.020502161234617233,
      "learning_rate": 2.3379406407371695e-06,
      "loss": 0.0002,
      "step": 82420
    },
    {
      "epoch": 8.832101146469517,
      "grad_norm": 0.021471502259373665,
      "learning_rate": 2.3357977070609665e-06,
      "loss": 0.0001,
      "step": 82430
    },
    {
      "epoch": 8.833172613307617,
      "grad_norm": 6.659793143626302e-05,
      "learning_rate": 2.333654773384764e-06,
      "loss": 0.1994,
      "step": 82440
    },
    {
      "epoch": 8.83424408014572,
      "grad_norm": 0.09714529663324356,
      "learning_rate": 2.331511839708561e-06,
      "loss": 0.0002,
      "step": 82450
    },
    {
      "epoch": 8.835315546983821,
      "grad_norm": 0.0001312873064307496,
      "learning_rate": 2.3293689060323585e-06,
      "loss": 0.0001,
      "step": 82460
    },
    {
      "epoch": 8.836387013821922,
      "grad_norm": 9.596470044925809e-05,
      "learning_rate": 2.327225972356156e-06,
      "loss": 0.0001,
      "step": 82470
    },
    {
      "epoch": 8.837458480660024,
      "grad_norm": 0.0004644306318368763,
      "learning_rate": 2.3250830386799532e-06,
      "loss": 0.0001,
      "step": 82480
    },
    {
      "epoch": 8.838529947498126,
      "grad_norm": 0.003051202045753598,
      "learning_rate": 2.32294010500375e-06,
      "loss": 0.0,
      "step": 82490
    },
    {
      "epoch": 8.839601414336226,
      "grad_norm": 6.93762704031542e-05,
      "learning_rate": 2.3207971713275475e-06,
      "loss": 0.0002,
      "step": 82500
    },
    {
      "epoch": 8.840672881174328,
      "grad_norm": 0.0046304757706820965,
      "learning_rate": 2.318654237651345e-06,
      "loss": 0.1391,
      "step": 82510
    },
    {
      "epoch": 8.84174434801243,
      "grad_norm": 0.00016432005213573575,
      "learning_rate": 2.3165113039751422e-06,
      "loss": 0.0,
      "step": 82520
    },
    {
      "epoch": 8.84281581485053,
      "grad_norm": 0.0012120635947212577,
      "learning_rate": 2.3143683702989396e-06,
      "loss": 0.0003,
      "step": 82530
    },
    {
      "epoch": 8.843887281688632,
      "grad_norm": 0.00012093965051462874,
      "learning_rate": 2.312225436622737e-06,
      "loss": 0.0,
      "step": 82540
    },
    {
      "epoch": 8.844958748526732,
      "grad_norm": 0.0001259108103113249,
      "learning_rate": 2.310082502946534e-06,
      "loss": 0.0002,
      "step": 82550
    },
    {
      "epoch": 8.846030215364834,
      "grad_norm": 0.0007156232022680342,
      "learning_rate": 2.3079395692703312e-06,
      "loss": 0.0,
      "step": 82560
    },
    {
      "epoch": 8.847101682202936,
      "grad_norm": 0.001963996794074774,
      "learning_rate": 2.3057966355941286e-06,
      "loss": 0.0,
      "step": 82570
    },
    {
      "epoch": 8.848173149041036,
      "grad_norm": 0.0003119781904388219,
      "learning_rate": 2.303653701917926e-06,
      "loss": 0.1963,
      "step": 82580
    },
    {
      "epoch": 8.849244615879138,
      "grad_norm": 7.46009245631285e-05,
      "learning_rate": 2.3015107682417233e-06,
      "loss": 0.0008,
      "step": 82590
    },
    {
      "epoch": 8.85031608271724,
      "grad_norm": 0.0007707191980443895,
      "learning_rate": 2.2993678345655202e-06,
      "loss": 0.0001,
      "step": 82600
    },
    {
      "epoch": 8.85138754955534,
      "grad_norm": 0.0015866191824898124,
      "learning_rate": 2.2972249008893176e-06,
      "loss": 0.0,
      "step": 82610
    },
    {
      "epoch": 8.852459016393443,
      "grad_norm": 0.005954892840236425,
      "learning_rate": 2.295081967213115e-06,
      "loss": 0.0,
      "step": 82620
    },
    {
      "epoch": 8.853530483231545,
      "grad_norm": 6.809812475694343e-05,
      "learning_rate": 2.2929390335369123e-06,
      "loss": 0.0,
      "step": 82630
    },
    {
      "epoch": 8.854601950069645,
      "grad_norm": 0.03229350224137306,
      "learning_rate": 2.2907960998607097e-06,
      "loss": 0.0,
      "step": 82640
    },
    {
      "epoch": 8.855673416907747,
      "grad_norm": 0.0003701206296682358,
      "learning_rate": 2.288653166184507e-06,
      "loss": 0.1569,
      "step": 82650
    },
    {
      "epoch": 8.856744883745849,
      "grad_norm": 0.0007632388733327389,
      "learning_rate": 2.286510232508304e-06,
      "loss": 0.0003,
      "step": 82660
    },
    {
      "epoch": 8.85781635058395,
      "grad_norm": 9.633782610762864e-05,
      "learning_rate": 2.2843672988321013e-06,
      "loss": 0.2107,
      "step": 82670
    },
    {
      "epoch": 8.858887817422051,
      "grad_norm": 7.903819641796872e-05,
      "learning_rate": 2.2822243651558987e-06,
      "loss": 0.0,
      "step": 82680
    },
    {
      "epoch": 8.859959284260151,
      "grad_norm": 0.0012430245988070965,
      "learning_rate": 2.280081431479696e-06,
      "loss": 0.0404,
      "step": 82690
    },
    {
      "epoch": 8.861030751098253,
      "grad_norm": 7.713891682215035e-05,
      "learning_rate": 2.2779384978034934e-06,
      "loss": 0.0254,
      "step": 82700
    },
    {
      "epoch": 8.862102217936355,
      "grad_norm": 418.9886779785156,
      "learning_rate": 2.2757955641272907e-06,
      "loss": 0.0968,
      "step": 82710
    },
    {
      "epoch": 8.863173684774456,
      "grad_norm": 0.020498692989349365,
      "learning_rate": 2.2736526304510877e-06,
      "loss": 0.0,
      "step": 82720
    },
    {
      "epoch": 8.864245151612558,
      "grad_norm": 0.0006517112487927079,
      "learning_rate": 2.271509696774885e-06,
      "loss": 0.1348,
      "step": 82730
    },
    {
      "epoch": 8.86531661845066,
      "grad_norm": 0.010588129051029682,
      "learning_rate": 2.2693667630986824e-06,
      "loss": 0.0,
      "step": 82740
    },
    {
      "epoch": 8.86638808528876,
      "grad_norm": 0.0006480116862803698,
      "learning_rate": 2.2672238294224797e-06,
      "loss": 0.0004,
      "step": 82750
    },
    {
      "epoch": 8.867459552126862,
      "grad_norm": 7.685450691496953e-05,
      "learning_rate": 2.265080895746277e-06,
      "loss": 0.0,
      "step": 82760
    },
    {
      "epoch": 8.868531018964964,
      "grad_norm": 6.477672286564484e-05,
      "learning_rate": 2.262937962070074e-06,
      "loss": 0.0,
      "step": 82770
    },
    {
      "epoch": 8.869602485803064,
      "grad_norm": 0.0019076478201895952,
      "learning_rate": 2.2607950283938714e-06,
      "loss": 0.2736,
      "step": 82780
    },
    {
      "epoch": 8.870673952641166,
      "grad_norm": 0.0008841135422699153,
      "learning_rate": 2.2586520947176687e-06,
      "loss": 0.0002,
      "step": 82790
    },
    {
      "epoch": 8.871745419479268,
      "grad_norm": 0.0028520850464701653,
      "learning_rate": 2.256509161041466e-06,
      "loss": 0.0,
      "step": 82800
    },
    {
      "epoch": 8.872816886317368,
      "grad_norm": 19.894746780395508,
      "learning_rate": 2.2543662273652634e-06,
      "loss": 0.4868,
      "step": 82810
    },
    {
      "epoch": 8.87388835315547,
      "grad_norm": 9.178943582810462e-05,
      "learning_rate": 2.2522232936890608e-06,
      "loss": 0.2333,
      "step": 82820
    },
    {
      "epoch": 8.87495981999357,
      "grad_norm": 8.229932427639142e-05,
      "learning_rate": 2.2500803600128577e-06,
      "loss": 0.1741,
      "step": 82830
    },
    {
      "epoch": 8.876031286831672,
      "grad_norm": 20.899763107299805,
      "learning_rate": 2.247937426336655e-06,
      "loss": 0.1941,
      "step": 82840
    },
    {
      "epoch": 8.877102753669774,
      "grad_norm": 0.0030999670270830393,
      "learning_rate": 2.2457944926604524e-06,
      "loss": 0.4859,
      "step": 82850
    },
    {
      "epoch": 8.878174220507875,
      "grad_norm": 9.341467375634238e-05,
      "learning_rate": 2.2436515589842498e-06,
      "loss": 0.1243,
      "step": 82860
    },
    {
      "epoch": 8.879245687345977,
      "grad_norm": 0.06486847996711731,
      "learning_rate": 2.241508625308047e-06,
      "loss": 0.0001,
      "step": 82870
    },
    {
      "epoch": 8.880317154184079,
      "grad_norm": 0.060771357268095016,
      "learning_rate": 2.2393656916318445e-06,
      "loss": 0.0006,
      "step": 82880
    },
    {
      "epoch": 8.881388621022179,
      "grad_norm": 0.008600694127380848,
      "learning_rate": 2.2372227579556414e-06,
      "loss": 0.0012,
      "step": 82890
    },
    {
      "epoch": 8.88246008786028,
      "grad_norm": 0.004020222928375006,
      "learning_rate": 2.2350798242794388e-06,
      "loss": 0.0,
      "step": 82900
    },
    {
      "epoch": 8.883531554698383,
      "grad_norm": 0.0007706863689236343,
      "learning_rate": 2.2329368906032357e-06,
      "loss": 0.1463,
      "step": 82910
    },
    {
      "epoch": 8.884603021536483,
      "grad_norm": 8.693388372194022e-05,
      "learning_rate": 2.230793956927033e-06,
      "loss": 0.0015,
      "step": 82920
    },
    {
      "epoch": 8.885674488374585,
      "grad_norm": 0.0028211891185492277,
      "learning_rate": 2.2286510232508304e-06,
      "loss": 0.0608,
      "step": 82930
    },
    {
      "epoch": 8.886745955212685,
      "grad_norm": 0.008516521193087101,
      "learning_rate": 2.2265080895746278e-06,
      "loss": 0.3227,
      "step": 82940
    },
    {
      "epoch": 8.887817422050787,
      "grad_norm": 0.00046236594789661467,
      "learning_rate": 2.224365155898425e-06,
      "loss": 0.1819,
      "step": 82950
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 0.006567975971847773,
      "learning_rate": 2.222222222222222e-06,
      "loss": 0.0004,
      "step": 82960
    },
    {
      "epoch": 8.88996035572699,
      "grad_norm": 0.0005386526463553309,
      "learning_rate": 2.2200792885460194e-06,
      "loss": 0.0009,
      "step": 82970
    },
    {
      "epoch": 8.891031822565092,
      "grad_norm": 0.0016437525628134608,
      "learning_rate": 2.2179363548698168e-06,
      "loss": 0.0001,
      "step": 82980
    },
    {
      "epoch": 8.892103289403194,
      "grad_norm": 8.581115253036842e-05,
      "learning_rate": 2.215793421193614e-06,
      "loss": 0.0001,
      "step": 82990
    },
    {
      "epoch": 8.893174756241294,
      "grad_norm": 0.002093732822686434,
      "learning_rate": 2.2136504875174115e-06,
      "loss": 0.0013,
      "step": 83000
    },
    {
      "epoch": 8.894246223079396,
      "grad_norm": 0.008116553537547588,
      "learning_rate": 2.211507553841209e-06,
      "loss": 0.0,
      "step": 83010
    },
    {
      "epoch": 8.895317689917498,
      "grad_norm": 9.482312452746555e-05,
      "learning_rate": 2.2093646201650058e-06,
      "loss": 0.2343,
      "step": 83020
    },
    {
      "epoch": 8.896389156755598,
      "grad_norm": 0.005530608352273703,
      "learning_rate": 2.207221686488803e-06,
      "loss": 0.0002,
      "step": 83030
    },
    {
      "epoch": 8.8974606235937,
      "grad_norm": 0.0021709082648158073,
      "learning_rate": 2.2050787528126005e-06,
      "loss": 0.0021,
      "step": 83040
    },
    {
      "epoch": 8.898532090431802,
      "grad_norm": 0.11600498855113983,
      "learning_rate": 2.202935819136398e-06,
      "loss": 0.0029,
      "step": 83050
    },
    {
      "epoch": 8.899603557269902,
      "grad_norm": 0.2239639312028885,
      "learning_rate": 2.200792885460195e-06,
      "loss": 0.001,
      "step": 83060
    },
    {
      "epoch": 8.900675024108004,
      "grad_norm": 8.713194984011352e-05,
      "learning_rate": 2.1986499517839926e-06,
      "loss": 0.0001,
      "step": 83070
    },
    {
      "epoch": 8.901746490946106,
      "grad_norm": 0.03910785913467407,
      "learning_rate": 2.1965070181077895e-06,
      "loss": 0.2276,
      "step": 83080
    },
    {
      "epoch": 8.902817957784206,
      "grad_norm": 7.553669274784625e-05,
      "learning_rate": 2.194364084431587e-06,
      "loss": 0.0007,
      "step": 83090
    },
    {
      "epoch": 8.903889424622308,
      "grad_norm": 0.20359526574611664,
      "learning_rate": 2.192221150755384e-06,
      "loss": 0.0008,
      "step": 83100
    },
    {
      "epoch": 8.904960891460409,
      "grad_norm": 8.41702421894297e-05,
      "learning_rate": 2.1900782170791816e-06,
      "loss": 0.1182,
      "step": 83110
    },
    {
      "epoch": 8.90603235829851,
      "grad_norm": 0.0009505903581157327,
      "learning_rate": 2.187935283402979e-06,
      "loss": 0.0008,
      "step": 83120
    },
    {
      "epoch": 8.907103825136613,
      "grad_norm": 8.546445315005258e-05,
      "learning_rate": 2.185792349726776e-06,
      "loss": 0.0001,
      "step": 83130
    },
    {
      "epoch": 8.908175291974713,
      "grad_norm": 9.305804269388318e-05,
      "learning_rate": 2.183649416050573e-06,
      "loss": 0.0001,
      "step": 83140
    },
    {
      "epoch": 8.909246758812815,
      "grad_norm": 0.0009599627228453755,
      "learning_rate": 2.1815064823743706e-06,
      "loss": 0.1104,
      "step": 83150
    },
    {
      "epoch": 8.910318225650917,
      "grad_norm": 0.00010703782027121633,
      "learning_rate": 2.179363548698168e-06,
      "loss": 0.0001,
      "step": 83160
    },
    {
      "epoch": 8.911389692489017,
      "grad_norm": 7.257670222315937e-05,
      "learning_rate": 2.1772206150219653e-06,
      "loss": 0.0001,
      "step": 83170
    },
    {
      "epoch": 8.912461159327119,
      "grad_norm": 0.0017660289304330945,
      "learning_rate": 2.1750776813457626e-06,
      "loss": 0.0,
      "step": 83180
    },
    {
      "epoch": 8.913532626165221,
      "grad_norm": 0.02417844533920288,
      "learning_rate": 2.1729347476695596e-06,
      "loss": 0.0002,
      "step": 83190
    },
    {
      "epoch": 8.914604093003321,
      "grad_norm": 0.050901852548122406,
      "learning_rate": 2.170791813993357e-06,
      "loss": 0.0003,
      "step": 83200
    },
    {
      "epoch": 8.915675559841423,
      "grad_norm": 0.021923191845417023,
      "learning_rate": 2.1686488803171543e-06,
      "loss": 0.0004,
      "step": 83210
    },
    {
      "epoch": 8.916747026679523,
      "grad_norm": 0.021671829745173454,
      "learning_rate": 2.1665059466409516e-06,
      "loss": 0.0002,
      "step": 83220
    },
    {
      "epoch": 8.917818493517625,
      "grad_norm": 0.001607311307452619,
      "learning_rate": 2.164363012964749e-06,
      "loss": 0.0001,
      "step": 83230
    },
    {
      "epoch": 8.918889960355727,
      "grad_norm": 15.19847583770752,
      "learning_rate": 2.1622200792885463e-06,
      "loss": 0.1538,
      "step": 83240
    },
    {
      "epoch": 8.919961427193828,
      "grad_norm": 8.446809079032391e-05,
      "learning_rate": 2.1600771456123433e-06,
      "loss": 0.3195,
      "step": 83250
    },
    {
      "epoch": 8.92103289403193,
      "grad_norm": 0.026137331500649452,
      "learning_rate": 2.1579342119361406e-06,
      "loss": 0.0001,
      "step": 83260
    },
    {
      "epoch": 8.922104360870032,
      "grad_norm": 0.13267788290977478,
      "learning_rate": 2.155791278259938e-06,
      "loss": 0.0001,
      "step": 83270
    },
    {
      "epoch": 8.923175827708132,
      "grad_norm": 0.019292088225483894,
      "learning_rate": 2.1536483445837353e-06,
      "loss": 0.1854,
      "step": 83280
    },
    {
      "epoch": 8.924247294546234,
      "grad_norm": 0.17073141038417816,
      "learning_rate": 2.1515054109075327e-06,
      "loss": 0.1529,
      "step": 83290
    },
    {
      "epoch": 8.925318761384336,
      "grad_norm": 0.002641808707267046,
      "learning_rate": 2.14936247723133e-06,
      "loss": 0.1675,
      "step": 83300
    },
    {
      "epoch": 8.926390228222436,
      "grad_norm": 9.81491175480187e-05,
      "learning_rate": 2.147219543555127e-06,
      "loss": 0.0,
      "step": 83310
    },
    {
      "epoch": 8.927461695060538,
      "grad_norm": 0.002094486728310585,
      "learning_rate": 2.1450766098789243e-06,
      "loss": 0.0004,
      "step": 83320
    },
    {
      "epoch": 8.928533161898638,
      "grad_norm": 7.668734906474128e-05,
      "learning_rate": 2.1429336762027217e-06,
      "loss": 0.0001,
      "step": 83330
    },
    {
      "epoch": 8.92960462873674,
      "grad_norm": 0.0009697715286165476,
      "learning_rate": 2.140790742526519e-06,
      "loss": 0.0,
      "step": 83340
    },
    {
      "epoch": 8.930676095574842,
      "grad_norm": 6.396876415237784e-05,
      "learning_rate": 2.1386478088503164e-06,
      "loss": 0.0,
      "step": 83350
    },
    {
      "epoch": 8.931747562412943,
      "grad_norm": 0.03788917884230614,
      "learning_rate": 2.1365048751741133e-06,
      "loss": 0.0001,
      "step": 83360
    },
    {
      "epoch": 8.932819029251045,
      "grad_norm": 227.6160888671875,
      "learning_rate": 2.1343619414979107e-06,
      "loss": 0.1589,
      "step": 83370
    },
    {
      "epoch": 8.933890496089147,
      "grad_norm": 7.015236769802868e-05,
      "learning_rate": 2.132219007821708e-06,
      "loss": 0.0001,
      "step": 83380
    },
    {
      "epoch": 8.934961962927247,
      "grad_norm": 0.024519657716155052,
      "learning_rate": 2.1300760741455054e-06,
      "loss": 0.0001,
      "step": 83390
    },
    {
      "epoch": 8.936033429765349,
      "grad_norm": 7.009894761722535e-05,
      "learning_rate": 2.1279331404693028e-06,
      "loss": 0.2852,
      "step": 83400
    },
    {
      "epoch": 8.93710489660345,
      "grad_norm": 0.13861489295959473,
      "learning_rate": 2.1257902067931e-06,
      "loss": 0.0001,
      "step": 83410
    },
    {
      "epoch": 8.938176363441551,
      "grad_norm": 8.120532584143803e-05,
      "learning_rate": 2.123647273116897e-06,
      "loss": 0.0,
      "step": 83420
    },
    {
      "epoch": 8.939247830279653,
      "grad_norm": 2.456709861755371,
      "learning_rate": 2.1215043394406944e-06,
      "loss": 0.0014,
      "step": 83430
    },
    {
      "epoch": 8.940319297117755,
      "grad_norm": 0.16628476977348328,
      "learning_rate": 2.1193614057644918e-06,
      "loss": 0.0004,
      "step": 83440
    },
    {
      "epoch": 8.941390763955855,
      "grad_norm": 0.004818866029381752,
      "learning_rate": 2.117218472088289e-06,
      "loss": 0.0,
      "step": 83450
    },
    {
      "epoch": 8.942462230793957,
      "grad_norm": 9.359740215586498e-05,
      "learning_rate": 2.1150755384120865e-06,
      "loss": 0.0002,
      "step": 83460
    },
    {
      "epoch": 8.94353369763206,
      "grad_norm": 8.227999205701053e-05,
      "learning_rate": 2.112932604735884e-06,
      "loss": 0.0001,
      "step": 83470
    },
    {
      "epoch": 8.94460516447016,
      "grad_norm": 1.0322507619857788,
      "learning_rate": 2.1107896710596808e-06,
      "loss": 0.3064,
      "step": 83480
    },
    {
      "epoch": 8.945676631308261,
      "grad_norm": 0.0009992612758651376,
      "learning_rate": 2.108646737383478e-06,
      "loss": 0.0005,
      "step": 83490
    },
    {
      "epoch": 8.946748098146362,
      "grad_norm": 8.2512924564071e-05,
      "learning_rate": 2.1065038037072755e-06,
      "loss": 0.0009,
      "step": 83500
    },
    {
      "epoch": 8.947819564984464,
      "grad_norm": 0.000778860121499747,
      "learning_rate": 2.104360870031073e-06,
      "loss": 0.3533,
      "step": 83510
    },
    {
      "epoch": 8.948891031822566,
      "grad_norm": 8.754344162298366e-05,
      "learning_rate": 2.10221793635487e-06,
      "loss": 0.1679,
      "step": 83520
    },
    {
      "epoch": 8.949962498660666,
      "grad_norm": 0.038778938353061676,
      "learning_rate": 2.100075002678667e-06,
      "loss": 0.0002,
      "step": 83530
    },
    {
      "epoch": 8.951033965498768,
      "grad_norm": 0.2687111794948578,
      "learning_rate": 2.0979320690024645e-06,
      "loss": 0.1528,
      "step": 83540
    },
    {
      "epoch": 8.95210543233687,
      "grad_norm": 6.181333446875215e-05,
      "learning_rate": 2.095789135326262e-06,
      "loss": 0.0,
      "step": 83550
    },
    {
      "epoch": 8.95317689917497,
      "grad_norm": 0.18802395462989807,
      "learning_rate": 2.093646201650059e-06,
      "loss": 0.0006,
      "step": 83560
    },
    {
      "epoch": 8.954248366013072,
      "grad_norm": 0.0031807092018425465,
      "learning_rate": 2.0915032679738565e-06,
      "loss": 0.1676,
      "step": 83570
    },
    {
      "epoch": 8.955319832851174,
      "grad_norm": 0.12411036342382431,
      "learning_rate": 2.089360334297654e-06,
      "loss": 0.0005,
      "step": 83580
    },
    {
      "epoch": 8.956391299689274,
      "grad_norm": 24.960718154907227,
      "learning_rate": 2.087217400621451e-06,
      "loss": 0.172,
      "step": 83590
    },
    {
      "epoch": 8.957462766527376,
      "grad_norm": 0.32040828466415405,
      "learning_rate": 2.085074466945248e-06,
      "loss": 0.0003,
      "step": 83600
    },
    {
      "epoch": 8.958534233365476,
      "grad_norm": 0.020368380472064018,
      "learning_rate": 2.0829315332690455e-06,
      "loss": 0.0001,
      "step": 83610
    },
    {
      "epoch": 8.959605700203578,
      "grad_norm": 0.0566614530980587,
      "learning_rate": 2.080788599592843e-06,
      "loss": 0.0001,
      "step": 83620
    },
    {
      "epoch": 8.96067716704168,
      "grad_norm": 0.0001707321498543024,
      "learning_rate": 2.0786456659166403e-06,
      "loss": 0.1014,
      "step": 83630
    },
    {
      "epoch": 8.96174863387978,
      "grad_norm": 0.000740297487936914,
      "learning_rate": 2.0765027322404376e-06,
      "loss": 0.2102,
      "step": 83640
    },
    {
      "epoch": 8.962820100717883,
      "grad_norm": 0.21496345102787018,
      "learning_rate": 2.0743597985642345e-06,
      "loss": 0.0006,
      "step": 83650
    },
    {
      "epoch": 8.963891567555985,
      "grad_norm": 0.0008668796508572996,
      "learning_rate": 2.072216864888032e-06,
      "loss": 0.0001,
      "step": 83660
    },
    {
      "epoch": 8.964963034394085,
      "grad_norm": 0.0001491621951572597,
      "learning_rate": 2.0700739312118293e-06,
      "loss": 0.0,
      "step": 83670
    },
    {
      "epoch": 8.966034501232187,
      "grad_norm": 0.06576772779226303,
      "learning_rate": 2.0679309975356266e-06,
      "loss": 0.0006,
      "step": 83680
    },
    {
      "epoch": 8.967105968070289,
      "grad_norm": 7.267235923791304e-05,
      "learning_rate": 2.065788063859424e-06,
      "loss": 0.0,
      "step": 83690
    },
    {
      "epoch": 8.96817743490839,
      "grad_norm": 0.15839716792106628,
      "learning_rate": 2.063645130183221e-06,
      "loss": 0.0002,
      "step": 83700
    },
    {
      "epoch": 8.969248901746491,
      "grad_norm": 0.017761187627911568,
      "learning_rate": 2.0615021965070183e-06,
      "loss": 0.0002,
      "step": 83710
    },
    {
      "epoch": 8.970320368584591,
      "grad_norm": 2.4529874324798584,
      "learning_rate": 2.0593592628308156e-06,
      "loss": 0.0023,
      "step": 83720
    },
    {
      "epoch": 8.971391835422693,
      "grad_norm": 0.0006408117478713393,
      "learning_rate": 2.057216329154613e-06,
      "loss": 0.0,
      "step": 83730
    },
    {
      "epoch": 8.972463302260795,
      "grad_norm": 0.0020265441853553057,
      "learning_rate": 2.0550733954784103e-06,
      "loss": 0.0,
      "step": 83740
    },
    {
      "epoch": 8.973534769098896,
      "grad_norm": 0.03653346002101898,
      "learning_rate": 2.0529304618022077e-06,
      "loss": 0.001,
      "step": 83750
    },
    {
      "epoch": 8.974606235936998,
      "grad_norm": 0.0007841691840440035,
      "learning_rate": 2.0507875281260046e-06,
      "loss": 0.0001,
      "step": 83760
    },
    {
      "epoch": 8.9756777027751,
      "grad_norm": 0.0015811712946742773,
      "learning_rate": 2.048644594449802e-06,
      "loss": 0.0011,
      "step": 83770
    },
    {
      "epoch": 8.9767491696132,
      "grad_norm": 6.187986582517624e-05,
      "learning_rate": 2.0465016607735993e-06,
      "loss": 0.0003,
      "step": 83780
    },
    {
      "epoch": 8.977820636451302,
      "grad_norm": 5.9267302276566625e-05,
      "learning_rate": 2.0443587270973967e-06,
      "loss": 0.15,
      "step": 83790
    },
    {
      "epoch": 8.978892103289404,
      "grad_norm": 0.0003579110780265182,
      "learning_rate": 2.042215793421194e-06,
      "loss": 0.1567,
      "step": 83800
    },
    {
      "epoch": 8.979963570127504,
      "grad_norm": 0.0011395813198760152,
      "learning_rate": 2.0400728597449914e-06,
      "loss": 0.0686,
      "step": 83810
    },
    {
      "epoch": 8.981035036965606,
      "grad_norm": 0.34602341055870056,
      "learning_rate": 2.0379299260687883e-06,
      "loss": 0.0001,
      "step": 83820
    },
    {
      "epoch": 8.982106503803708,
      "grad_norm": 0.033459167927503586,
      "learning_rate": 2.0357869923925857e-06,
      "loss": 0.2137,
      "step": 83830
    },
    {
      "epoch": 8.983177970641808,
      "grad_norm": 0.0008463411941193044,
      "learning_rate": 2.0336440587163826e-06,
      "loss": 0.0001,
      "step": 83840
    },
    {
      "epoch": 8.98424943747991,
      "grad_norm": 0.0001895070163300261,
      "learning_rate": 2.03150112504018e-06,
      "loss": 0.0,
      "step": 83850
    },
    {
      "epoch": 8.985320904318012,
      "grad_norm": 0.0006673485622741282,
      "learning_rate": 2.0293581913639773e-06,
      "loss": 0.0007,
      "step": 83860
    },
    {
      "epoch": 8.986392371156112,
      "grad_norm": 0.00010705287422752008,
      "learning_rate": 2.0272152576877747e-06,
      "loss": 0.0002,
      "step": 83870
    },
    {
      "epoch": 8.987463837994214,
      "grad_norm": 0.0013236294034868479,
      "learning_rate": 2.025072324011572e-06,
      "loss": 0.0,
      "step": 83880
    },
    {
      "epoch": 8.988535304832315,
      "grad_norm": 0.0019334126263856888,
      "learning_rate": 2.022929390335369e-06,
      "loss": 0.0103,
      "step": 83890
    },
    {
      "epoch": 8.989606771670417,
      "grad_norm": 0.003028132254257798,
      "learning_rate": 2.0207864566591663e-06,
      "loss": 0.0001,
      "step": 83900
    },
    {
      "epoch": 8.990678238508519,
      "grad_norm": 0.0006195304449647665,
      "learning_rate": 2.0186435229829637e-06,
      "loss": 0.0,
      "step": 83910
    },
    {
      "epoch": 8.991749705346619,
      "grad_norm": 0.005724544171243906,
      "learning_rate": 2.016500589306761e-06,
      "loss": 0.0002,
      "step": 83920
    },
    {
      "epoch": 8.99282117218472,
      "grad_norm": 6.174686859594658e-05,
      "learning_rate": 2.0143576556305584e-06,
      "loss": 0.0,
      "step": 83930
    },
    {
      "epoch": 8.993892639022823,
      "grad_norm": 0.02937096171081066,
      "learning_rate": 2.0122147219543557e-06,
      "loss": 0.0,
      "step": 83940
    },
    {
      "epoch": 8.994964105860923,
      "grad_norm": 7.629750325577334e-05,
      "learning_rate": 2.0100717882781527e-06,
      "loss": 0.1101,
      "step": 83950
    },
    {
      "epoch": 8.996035572699025,
      "grad_norm": 0.015672914683818817,
      "learning_rate": 2.00792885460195e-06,
      "loss": 0.1247,
      "step": 83960
    },
    {
      "epoch": 8.997107039537127,
      "grad_norm": 0.0025700789410620928,
      "learning_rate": 2.0057859209257474e-06,
      "loss": 0.0,
      "step": 83970
    },
    {
      "epoch": 8.998178506375227,
      "grad_norm": 0.0009890930959954858,
      "learning_rate": 2.0036429872495447e-06,
      "loss": 0.1905,
      "step": 83980
    },
    {
      "epoch": 8.99924997321333,
      "grad_norm": 8.394094038521871e-05,
      "learning_rate": 2.001500053573342e-06,
      "loss": 0.283,
      "step": 83990
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9495,
      "eval_f1": 0.8678587003924988,
      "eval_loss": 0.39750936627388,
      "eval_precision": 0.8813108945969885,
      "eval_recall": 0.8548109965635738,
      "eval_runtime": 487.8193,
      "eval_samples_per_second": 12.3,
      "eval_steps_per_second": 4.1,
      "step": 83997
    }
  ],
  "logging_steps": 10,
  "max_steps": 93330,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.26271904655737e+16,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
