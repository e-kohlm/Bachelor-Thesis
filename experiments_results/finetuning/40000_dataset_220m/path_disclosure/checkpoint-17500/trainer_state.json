{
  "best_metric": 0.9414414414414415,
  "best_model_checkpoint": "../saved_models/path_disclosure_40000/checkpoint-17500",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 17500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005714285714285715,
      "grad_norm": 42.477561950683594,
      "learning_rate": 1.9998857142857143e-05,
      "loss": 0.6645,
      "step": 1
    },
    {
      "epoch": 0.005714285714285714,
      "grad_norm": 24.609079360961914,
      "learning_rate": 1.9988571428571432e-05,
      "loss": 0.5055,
      "step": 10
    },
    {
      "epoch": 0.011428571428571429,
      "grad_norm": 21.96957015991211,
      "learning_rate": 1.997714285714286e-05,
      "loss": 0.4598,
      "step": 20
    },
    {
      "epoch": 0.017142857142857144,
      "grad_norm": 25.399141311645508,
      "learning_rate": 1.996571428571429e-05,
      "loss": 0.5038,
      "step": 30
    },
    {
      "epoch": 0.022857142857142857,
      "grad_norm": 27.99448585510254,
      "learning_rate": 1.9954285714285715e-05,
      "loss": 0.4738,
      "step": 40
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 24.65215492248535,
      "learning_rate": 1.9942857142857142e-05,
      "loss": 0.4441,
      "step": 50
    },
    {
      "epoch": 0.03428571428571429,
      "grad_norm": 13.122211456298828,
      "learning_rate": 1.9931428571428572e-05,
      "loss": 0.3744,
      "step": 60
    },
    {
      "epoch": 0.04,
      "grad_norm": 15.777149200439453,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 0.4059,
      "step": 70
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 14.464738845825195,
      "learning_rate": 1.990857142857143e-05,
      "loss": 0.2985,
      "step": 80
    },
    {
      "epoch": 0.05142857142857143,
      "grad_norm": 14.620457649230957,
      "learning_rate": 1.989714285714286e-05,
      "loss": 0.5088,
      "step": 90
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 14.261834144592285,
      "learning_rate": 1.988571428571429e-05,
      "loss": 0.3239,
      "step": 100
    },
    {
      "epoch": 0.06285714285714286,
      "grad_norm": 26.499141693115234,
      "learning_rate": 1.9874285714285716e-05,
      "loss": 0.415,
      "step": 110
    },
    {
      "epoch": 0.06857142857142857,
      "grad_norm": 16.468273162841797,
      "learning_rate": 1.9862857142857143e-05,
      "loss": 0.4569,
      "step": 120
    },
    {
      "epoch": 0.07428571428571429,
      "grad_norm": 20.296052932739258,
      "learning_rate": 1.9851428571428573e-05,
      "loss": 0.3509,
      "step": 130
    },
    {
      "epoch": 0.08,
      "grad_norm": 7.30756139755249,
      "learning_rate": 1.9840000000000003e-05,
      "loss": 0.3653,
      "step": 140
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 19.037588119506836,
      "learning_rate": 1.982857142857143e-05,
      "loss": 0.4298,
      "step": 150
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 15.401293754577637,
      "learning_rate": 1.981714285714286e-05,
      "loss": 0.4757,
      "step": 160
    },
    {
      "epoch": 0.09714285714285714,
      "grad_norm": 16.520038604736328,
      "learning_rate": 1.9805714285714287e-05,
      "loss": 0.3646,
      "step": 170
    },
    {
      "epoch": 0.10285714285714286,
      "grad_norm": 21.35186195373535,
      "learning_rate": 1.9794285714285717e-05,
      "loss": 0.3921,
      "step": 180
    },
    {
      "epoch": 0.10857142857142857,
      "grad_norm": 11.358139991760254,
      "learning_rate": 1.9782857142857144e-05,
      "loss": 0.4123,
      "step": 190
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 51.7056884765625,
      "learning_rate": 1.9771428571428574e-05,
      "loss": 0.3754,
      "step": 200
    },
    {
      "epoch": 0.12,
      "grad_norm": 16.791261672973633,
      "learning_rate": 1.976e-05,
      "loss": 0.4008,
      "step": 210
    },
    {
      "epoch": 0.12571428571428572,
      "grad_norm": 20.4163875579834,
      "learning_rate": 1.974857142857143e-05,
      "loss": 0.3903,
      "step": 220
    },
    {
      "epoch": 0.13142857142857142,
      "grad_norm": 15.54834270477295,
      "learning_rate": 1.973714285714286e-05,
      "loss": 0.3058,
      "step": 230
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 15.05101203918457,
      "learning_rate": 1.9725714285714288e-05,
      "loss": 0.3312,
      "step": 240
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 12.159809112548828,
      "learning_rate": 1.9714285714285718e-05,
      "loss": 0.3042,
      "step": 250
    },
    {
      "epoch": 0.14857142857142858,
      "grad_norm": 19.416622161865234,
      "learning_rate": 1.9702857142857144e-05,
      "loss": 0.3436,
      "step": 260
    },
    {
      "epoch": 0.15428571428571428,
      "grad_norm": 32.96628952026367,
      "learning_rate": 1.969142857142857e-05,
      "loss": 0.3369,
      "step": 270
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.485756874084473,
      "learning_rate": 1.968e-05,
      "loss": 0.3317,
      "step": 280
    },
    {
      "epoch": 0.1657142857142857,
      "grad_norm": 15.351442337036133,
      "learning_rate": 1.966857142857143e-05,
      "loss": 0.4094,
      "step": 290
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 11.703850746154785,
      "learning_rate": 1.9657142857142858e-05,
      "loss": 0.4001,
      "step": 300
    },
    {
      "epoch": 0.17714285714285713,
      "grad_norm": 12.916464805603027,
      "learning_rate": 1.964571428571429e-05,
      "loss": 0.3652,
      "step": 310
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 9.984959602355957,
      "learning_rate": 1.963428571428572e-05,
      "loss": 0.3798,
      "step": 320
    },
    {
      "epoch": 0.18857142857142858,
      "grad_norm": 6.770185947418213,
      "learning_rate": 1.9622857142857142e-05,
      "loss": 0.3887,
      "step": 330
    },
    {
      "epoch": 0.19428571428571428,
      "grad_norm": 19.091022491455078,
      "learning_rate": 1.9611428571428572e-05,
      "loss": 0.444,
      "step": 340
    },
    {
      "epoch": 0.2,
      "grad_norm": 13.198528289794922,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.3491,
      "step": 350
    },
    {
      "epoch": 0.2057142857142857,
      "grad_norm": 3.3228282928466797,
      "learning_rate": 1.958857142857143e-05,
      "loss": 0.267,
      "step": 360
    },
    {
      "epoch": 0.21142857142857144,
      "grad_norm": 5.322269439697266,
      "learning_rate": 1.957714285714286e-05,
      "loss": 0.3873,
      "step": 370
    },
    {
      "epoch": 0.21714285714285714,
      "grad_norm": 7.738333702087402,
      "learning_rate": 1.956571428571429e-05,
      "loss": 0.2957,
      "step": 380
    },
    {
      "epoch": 0.22285714285714286,
      "grad_norm": 8.866743087768555,
      "learning_rate": 1.9554285714285716e-05,
      "loss": 0.2979,
      "step": 390
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 8.966200828552246,
      "learning_rate": 1.9542857142857143e-05,
      "loss": 0.3089,
      "step": 400
    },
    {
      "epoch": 0.2342857142857143,
      "grad_norm": 3.0508906841278076,
      "learning_rate": 1.9531428571428573e-05,
      "loss": 0.243,
      "step": 410
    },
    {
      "epoch": 0.24,
      "grad_norm": 11.313065528869629,
      "learning_rate": 1.9520000000000003e-05,
      "loss": 0.4433,
      "step": 420
    },
    {
      "epoch": 0.24571428571428572,
      "grad_norm": 7.315686225891113,
      "learning_rate": 1.950857142857143e-05,
      "loss": 0.2712,
      "step": 430
    },
    {
      "epoch": 0.25142857142857145,
      "grad_norm": 11.579343795776367,
      "learning_rate": 1.949714285714286e-05,
      "loss": 0.3696,
      "step": 440
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 18.84343719482422,
      "learning_rate": 1.9485714285714286e-05,
      "loss": 0.4022,
      "step": 450
    },
    {
      "epoch": 0.26285714285714284,
      "grad_norm": 7.66997766494751,
      "learning_rate": 1.9474285714285717e-05,
      "loss": 0.3286,
      "step": 460
    },
    {
      "epoch": 0.26857142857142857,
      "grad_norm": 7.07444429397583,
      "learning_rate": 1.9462857142857147e-05,
      "loss": 0.3598,
      "step": 470
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 11.999409675598145,
      "learning_rate": 1.9451428571428573e-05,
      "loss": 0.2748,
      "step": 480
    },
    {
      "epoch": 0.28,
      "grad_norm": 13.782447814941406,
      "learning_rate": 1.944e-05,
      "loss": 0.2624,
      "step": 490
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 7.819321632385254,
      "learning_rate": 1.942857142857143e-05,
      "loss": 0.2971,
      "step": 500
    },
    {
      "epoch": 0.2914285714285714,
      "grad_norm": 9.941535949707031,
      "learning_rate": 1.941714285714286e-05,
      "loss": 0.2718,
      "step": 510
    },
    {
      "epoch": 0.29714285714285715,
      "grad_norm": 10.5350980758667,
      "learning_rate": 1.9405714285714287e-05,
      "loss": 0.3667,
      "step": 520
    },
    {
      "epoch": 0.3028571428571429,
      "grad_norm": 16.425020217895508,
      "learning_rate": 1.9394285714285717e-05,
      "loss": 0.3,
      "step": 530
    },
    {
      "epoch": 0.30857142857142855,
      "grad_norm": 11.706927299499512,
      "learning_rate": 1.9382857142857144e-05,
      "loss": 0.3266,
      "step": 540
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 8.944910049438477,
      "learning_rate": 1.937142857142857e-05,
      "loss": 0.3466,
      "step": 550
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.412272930145264,
      "learning_rate": 1.936e-05,
      "loss": 0.3116,
      "step": 560
    },
    {
      "epoch": 0.32571428571428573,
      "grad_norm": 14.384381294250488,
      "learning_rate": 1.934857142857143e-05,
      "loss": 0.2671,
      "step": 570
    },
    {
      "epoch": 0.3314285714285714,
      "grad_norm": 6.587137699127197,
      "learning_rate": 1.9337142857142858e-05,
      "loss": 0.5082,
      "step": 580
    },
    {
      "epoch": 0.33714285714285713,
      "grad_norm": 9.261150360107422,
      "learning_rate": 1.9325714285714288e-05,
      "loss": 0.3096,
      "step": 590
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 11.130976676940918,
      "learning_rate": 1.9314285714285718e-05,
      "loss": 0.4255,
      "step": 600
    },
    {
      "epoch": 0.3485714285714286,
      "grad_norm": 4.036599159240723,
      "learning_rate": 1.9302857142857145e-05,
      "loss": 0.2257,
      "step": 610
    },
    {
      "epoch": 0.35428571428571426,
      "grad_norm": 5.632357597351074,
      "learning_rate": 1.929142857142857e-05,
      "loss": 0.3429,
      "step": 620
    },
    {
      "epoch": 0.36,
      "grad_norm": 10.953107833862305,
      "learning_rate": 1.9280000000000002e-05,
      "loss": 0.3035,
      "step": 630
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 11.062597274780273,
      "learning_rate": 1.926857142857143e-05,
      "loss": 0.2785,
      "step": 640
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 0.42341887950897217,
      "learning_rate": 1.925714285714286e-05,
      "loss": 0.3414,
      "step": 650
    },
    {
      "epoch": 0.37714285714285717,
      "grad_norm": 0.6324787139892578,
      "learning_rate": 1.924571428571429e-05,
      "loss": 0.3113,
      "step": 660
    },
    {
      "epoch": 0.38285714285714284,
      "grad_norm": 10.551584243774414,
      "learning_rate": 1.9234285714285716e-05,
      "loss": 0.2518,
      "step": 670
    },
    {
      "epoch": 0.38857142857142857,
      "grad_norm": 6.923495292663574,
      "learning_rate": 1.9222857142857146e-05,
      "loss": 0.4494,
      "step": 680
    },
    {
      "epoch": 0.3942857142857143,
      "grad_norm": 8.413026809692383,
      "learning_rate": 1.9211428571428572e-05,
      "loss": 0.2967,
      "step": 690
    },
    {
      "epoch": 0.4,
      "grad_norm": 16.361461639404297,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.3166,
      "step": 700
    },
    {
      "epoch": 0.4057142857142857,
      "grad_norm": 10.237800598144531,
      "learning_rate": 1.918857142857143e-05,
      "loss": 0.3218,
      "step": 710
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 9.845559120178223,
      "learning_rate": 1.917714285714286e-05,
      "loss": 0.2606,
      "step": 720
    },
    {
      "epoch": 0.41714285714285715,
      "grad_norm": 8.255255699157715,
      "learning_rate": 1.9165714285714286e-05,
      "loss": 0.2223,
      "step": 730
    },
    {
      "epoch": 0.4228571428571429,
      "grad_norm": 13.548099517822266,
      "learning_rate": 1.9154285714285716e-05,
      "loss": 0.4482,
      "step": 740
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 21.777950286865234,
      "learning_rate": 1.9142857142857146e-05,
      "loss": 0.3142,
      "step": 750
    },
    {
      "epoch": 0.4342857142857143,
      "grad_norm": 2.6463234424591064,
      "learning_rate": 1.9131428571428573e-05,
      "loss": 0.2418,
      "step": 760
    },
    {
      "epoch": 0.44,
      "grad_norm": 11.69808578491211,
      "learning_rate": 1.912e-05,
      "loss": 0.3421,
      "step": 770
    },
    {
      "epoch": 0.44571428571428573,
      "grad_norm": 4.044149398803711,
      "learning_rate": 1.910857142857143e-05,
      "loss": 0.2737,
      "step": 780
    },
    {
      "epoch": 0.4514285714285714,
      "grad_norm": 20.618383407592773,
      "learning_rate": 1.909714285714286e-05,
      "loss": 0.3017,
      "step": 790
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 10.44678020477295,
      "learning_rate": 1.9085714285714287e-05,
      "loss": 0.3207,
      "step": 800
    },
    {
      "epoch": 0.46285714285714286,
      "grad_norm": 9.343465805053711,
      "learning_rate": 1.9074285714285717e-05,
      "loss": 0.3489,
      "step": 810
    },
    {
      "epoch": 0.4685714285714286,
      "grad_norm": 5.944253921508789,
      "learning_rate": 1.9062857142857144e-05,
      "loss": 0.2978,
      "step": 820
    },
    {
      "epoch": 0.4742857142857143,
      "grad_norm": 6.436461925506592,
      "learning_rate": 1.9051428571428574e-05,
      "loss": 0.275,
      "step": 830
    },
    {
      "epoch": 0.48,
      "grad_norm": 16.84486961364746,
      "learning_rate": 1.904e-05,
      "loss": 0.3181,
      "step": 840
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 12.142122268676758,
      "learning_rate": 1.902857142857143e-05,
      "loss": 0.3293,
      "step": 850
    },
    {
      "epoch": 0.49142857142857144,
      "grad_norm": 9.648184776306152,
      "learning_rate": 1.9017142857142858e-05,
      "loss": 0.2231,
      "step": 860
    },
    {
      "epoch": 0.49714285714285716,
      "grad_norm": 24.358903884887695,
      "learning_rate": 1.9005714285714288e-05,
      "loss": 0.2692,
      "step": 870
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 10.299129486083984,
      "learning_rate": 1.8994285714285718e-05,
      "loss": 0.259,
      "step": 880
    },
    {
      "epoch": 0.5085714285714286,
      "grad_norm": 15.483285903930664,
      "learning_rate": 1.8982857142857145e-05,
      "loss": 0.263,
      "step": 890
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 7.831328392028809,
      "learning_rate": 1.8971428571428575e-05,
      "loss": 0.3018,
      "step": 900
    },
    {
      "epoch": 0.52,
      "grad_norm": 13.276427268981934,
      "learning_rate": 1.896e-05,
      "loss": 0.3066,
      "step": 910
    },
    {
      "epoch": 0.5257142857142857,
      "grad_norm": 10.096583366394043,
      "learning_rate": 1.8948571428571428e-05,
      "loss": 0.2233,
      "step": 920
    },
    {
      "epoch": 0.5314285714285715,
      "grad_norm": 7.019724369049072,
      "learning_rate": 1.893714285714286e-05,
      "loss": 0.2706,
      "step": 930
    },
    {
      "epoch": 0.5371428571428571,
      "grad_norm": 9.855876922607422,
      "learning_rate": 1.892571428571429e-05,
      "loss": 0.248,
      "step": 940
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 11.920588493347168,
      "learning_rate": 1.8914285714285715e-05,
      "loss": 0.2631,
      "step": 950
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 13.624735832214355,
      "learning_rate": 1.8902857142857145e-05,
      "loss": 0.2397,
      "step": 960
    },
    {
      "epoch": 0.5542857142857143,
      "grad_norm": 6.593142509460449,
      "learning_rate": 1.8891428571428575e-05,
      "loss": 0.1388,
      "step": 970
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.9836723804473877,
      "learning_rate": 1.8880000000000002e-05,
      "loss": 0.2667,
      "step": 980
    },
    {
      "epoch": 0.5657142857142857,
      "grad_norm": 8.108115196228027,
      "learning_rate": 1.886857142857143e-05,
      "loss": 0.1961,
      "step": 990
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 4.840457916259766,
      "learning_rate": 1.885714285714286e-05,
      "loss": 0.2478,
      "step": 1000
    },
    {
      "epoch": 0.5771428571428572,
      "grad_norm": 4.165658473968506,
      "learning_rate": 1.8845714285714286e-05,
      "loss": 0.3028,
      "step": 1010
    },
    {
      "epoch": 0.5828571428571429,
      "grad_norm": 0.7059597969055176,
      "learning_rate": 1.8834285714285716e-05,
      "loss": 0.2085,
      "step": 1020
    },
    {
      "epoch": 0.5885714285714285,
      "grad_norm": 5.1677069664001465,
      "learning_rate": 1.8822857142857146e-05,
      "loss": 0.2525,
      "step": 1030
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 12.374279975891113,
      "learning_rate": 1.8811428571428573e-05,
      "loss": 0.3106,
      "step": 1040
    },
    {
      "epoch": 0.6,
      "grad_norm": 15.367202758789062,
      "learning_rate": 1.88e-05,
      "loss": 0.1927,
      "step": 1050
    },
    {
      "epoch": 0.6057142857142858,
      "grad_norm": 4.537532806396484,
      "learning_rate": 1.878857142857143e-05,
      "loss": 0.2616,
      "step": 1060
    },
    {
      "epoch": 0.6114285714285714,
      "grad_norm": 0.8351047039031982,
      "learning_rate": 1.877714285714286e-05,
      "loss": 0.1677,
      "step": 1070
    },
    {
      "epoch": 0.6171428571428571,
      "grad_norm": 19.400470733642578,
      "learning_rate": 1.8765714285714287e-05,
      "loss": 0.3878,
      "step": 1080
    },
    {
      "epoch": 0.6228571428571429,
      "grad_norm": 11.824943542480469,
      "learning_rate": 1.8754285714285717e-05,
      "loss": 0.2509,
      "step": 1090
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 5.939833641052246,
      "learning_rate": 1.8742857142857143e-05,
      "loss": 0.242,
      "step": 1100
    },
    {
      "epoch": 0.6342857142857142,
      "grad_norm": 10.282758712768555,
      "learning_rate": 1.8731428571428574e-05,
      "loss": 0.2596,
      "step": 1110
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.960071086883545,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 0.2553,
      "step": 1120
    },
    {
      "epoch": 0.6457142857142857,
      "grad_norm": 9.436866760253906,
      "learning_rate": 1.870857142857143e-05,
      "loss": 0.2958,
      "step": 1130
    },
    {
      "epoch": 0.6514285714285715,
      "grad_norm": 10.308760643005371,
      "learning_rate": 1.8697142857142857e-05,
      "loss": 0.2276,
      "step": 1140
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 2.8466761112213135,
      "learning_rate": 1.8685714285714287e-05,
      "loss": 0.1212,
      "step": 1150
    },
    {
      "epoch": 0.6628571428571428,
      "grad_norm": 6.890729904174805,
      "learning_rate": 1.8674285714285717e-05,
      "loss": 0.5202,
      "step": 1160
    },
    {
      "epoch": 0.6685714285714286,
      "grad_norm": 11.755440711975098,
      "learning_rate": 1.8662857142857144e-05,
      "loss": 0.2192,
      "step": 1170
    },
    {
      "epoch": 0.6742857142857143,
      "grad_norm": 6.395277976989746,
      "learning_rate": 1.8651428571428574e-05,
      "loss": 0.1869,
      "step": 1180
    },
    {
      "epoch": 0.68,
      "grad_norm": 12.414177894592285,
      "learning_rate": 1.864e-05,
      "loss": 0.3209,
      "step": 1190
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 5.337936878204346,
      "learning_rate": 1.8628571428571428e-05,
      "loss": 0.3416,
      "step": 1200
    },
    {
      "epoch": 0.6914285714285714,
      "grad_norm": 6.783049583435059,
      "learning_rate": 1.8617142857142858e-05,
      "loss": 0.3458,
      "step": 1210
    },
    {
      "epoch": 0.6971428571428572,
      "grad_norm": 9.757678031921387,
      "learning_rate": 1.8605714285714288e-05,
      "loss": 0.2104,
      "step": 1220
    },
    {
      "epoch": 0.7028571428571428,
      "grad_norm": 10.720553398132324,
      "learning_rate": 1.8594285714285715e-05,
      "loss": 0.2915,
      "step": 1230
    },
    {
      "epoch": 0.7085714285714285,
      "grad_norm": 11.102523803710938,
      "learning_rate": 1.8582857142857145e-05,
      "loss": 0.2046,
      "step": 1240
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 7.788590908050537,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 0.3594,
      "step": 1250
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.325366735458374,
      "learning_rate": 1.8560000000000002e-05,
      "loss": 0.221,
      "step": 1260
    },
    {
      "epoch": 0.7257142857142858,
      "grad_norm": 8.371231079101562,
      "learning_rate": 1.854857142857143e-05,
      "loss": 0.1907,
      "step": 1270
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 6.2318620681762695,
      "learning_rate": 1.853714285714286e-05,
      "loss": 0.1268,
      "step": 1280
    },
    {
      "epoch": 0.7371428571428571,
      "grad_norm": 10.07876205444336,
      "learning_rate": 1.8525714285714285e-05,
      "loss": 0.2424,
      "step": 1290
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 5.870022773742676,
      "learning_rate": 1.8514285714285716e-05,
      "loss": 0.1106,
      "step": 1300
    },
    {
      "epoch": 0.7485714285714286,
      "grad_norm": 11.715656280517578,
      "learning_rate": 1.8502857142857146e-05,
      "loss": 0.421,
      "step": 1310
    },
    {
      "epoch": 0.7542857142857143,
      "grad_norm": 7.923789978027344,
      "learning_rate": 1.8491428571428573e-05,
      "loss": 0.3538,
      "step": 1320
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0844180583953857,
      "learning_rate": 1.8480000000000003e-05,
      "loss": 0.2695,
      "step": 1330
    },
    {
      "epoch": 0.7657142857142857,
      "grad_norm": 10.123830795288086,
      "learning_rate": 1.846857142857143e-05,
      "loss": 0.2087,
      "step": 1340
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 14.719754219055176,
      "learning_rate": 1.845714285714286e-05,
      "loss": 0.2269,
      "step": 1350
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 1.3328303098678589,
      "learning_rate": 1.8445714285714286e-05,
      "loss": 0.2031,
      "step": 1360
    },
    {
      "epoch": 0.7828571428571428,
      "grad_norm": 13.143266677856445,
      "learning_rate": 1.8434285714285716e-05,
      "loss": 0.2373,
      "step": 1370
    },
    {
      "epoch": 0.7885714285714286,
      "grad_norm": 8.105934143066406,
      "learning_rate": 1.8422857142857143e-05,
      "loss": 0.2267,
      "step": 1380
    },
    {
      "epoch": 0.7942857142857143,
      "grad_norm": 7.631376266479492,
      "learning_rate": 1.8411428571428573e-05,
      "loss": 0.1889,
      "step": 1390
    },
    {
      "epoch": 0.8,
      "grad_norm": 9.019433975219727,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.2346,
      "step": 1400
    },
    {
      "epoch": 0.8057142857142857,
      "grad_norm": 0.9022830128669739,
      "learning_rate": 1.838857142857143e-05,
      "loss": 0.1773,
      "step": 1410
    },
    {
      "epoch": 0.8114285714285714,
      "grad_norm": 7.393615245819092,
      "learning_rate": 1.8377142857142857e-05,
      "loss": 0.2125,
      "step": 1420
    },
    {
      "epoch": 0.8171428571428572,
      "grad_norm": 2.1293511390686035,
      "learning_rate": 1.8365714285714287e-05,
      "loss": 0.2155,
      "step": 1430
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 7.485477924346924,
      "learning_rate": 1.8354285714285717e-05,
      "loss": 0.2905,
      "step": 1440
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 9.04028606414795,
      "learning_rate": 1.8342857142857144e-05,
      "loss": 0.199,
      "step": 1450
    },
    {
      "epoch": 0.8342857142857143,
      "grad_norm": 3.488785743713379,
      "learning_rate": 1.8331428571428574e-05,
      "loss": 0.4698,
      "step": 1460
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.8977808952331543,
      "learning_rate": 1.832e-05,
      "loss": 0.1266,
      "step": 1470
    },
    {
      "epoch": 0.8457142857142858,
      "grad_norm": 13.594452857971191,
      "learning_rate": 1.830857142857143e-05,
      "loss": 0.1566,
      "step": 1480
    },
    {
      "epoch": 0.8514285714285714,
      "grad_norm": 0.8104391694068909,
      "learning_rate": 1.8297142857142858e-05,
      "loss": 0.1069,
      "step": 1490
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 10.304576873779297,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 0.3126,
      "step": 1500
    },
    {
      "epoch": 0.8628571428571429,
      "grad_norm": 3.084136724472046,
      "learning_rate": 1.8274285714285715e-05,
      "loss": 0.183,
      "step": 1510
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 11.735891342163086,
      "learning_rate": 1.8262857142857145e-05,
      "loss": 0.2077,
      "step": 1520
    },
    {
      "epoch": 0.8742857142857143,
      "grad_norm": 6.25170373916626,
      "learning_rate": 1.8251428571428575e-05,
      "loss": 0.187,
      "step": 1530
    },
    {
      "epoch": 0.88,
      "grad_norm": 10.896434783935547,
      "learning_rate": 1.824e-05,
      "loss": 0.1875,
      "step": 1540
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 4.21220064163208,
      "learning_rate": 1.822857142857143e-05,
      "loss": 0.3357,
      "step": 1550
    },
    {
      "epoch": 0.8914285714285715,
      "grad_norm": 6.359614372253418,
      "learning_rate": 1.821714285714286e-05,
      "loss": 0.2781,
      "step": 1560
    },
    {
      "epoch": 0.8971428571428571,
      "grad_norm": 8.219693183898926,
      "learning_rate": 1.8205714285714285e-05,
      "loss": 0.2032,
      "step": 1570
    },
    {
      "epoch": 0.9028571428571428,
      "grad_norm": 1.50458562374115,
      "learning_rate": 1.8194285714285715e-05,
      "loss": 0.1743,
      "step": 1580
    },
    {
      "epoch": 0.9085714285714286,
      "grad_norm": 14.743278503417969,
      "learning_rate": 1.8182857142857145e-05,
      "loss": 0.1953,
      "step": 1590
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.3115895986557007,
      "learning_rate": 1.8171428571428572e-05,
      "loss": 0.1529,
      "step": 1600
    },
    {
      "epoch": 0.92,
      "grad_norm": 5.295215129852295,
      "learning_rate": 1.8160000000000002e-05,
      "loss": 0.1806,
      "step": 1610
    },
    {
      "epoch": 0.9257142857142857,
      "grad_norm": 14.012577056884766,
      "learning_rate": 1.8148571428571432e-05,
      "loss": 0.3191,
      "step": 1620
    },
    {
      "epoch": 0.9314285714285714,
      "grad_norm": 6.025569438934326,
      "learning_rate": 1.813714285714286e-05,
      "loss": 0.2419,
      "step": 1630
    },
    {
      "epoch": 0.9371428571428572,
      "grad_norm": 7.464371204376221,
      "learning_rate": 1.8125714285714286e-05,
      "loss": 0.278,
      "step": 1640
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 1.3327114582061768,
      "learning_rate": 1.8114285714285716e-05,
      "loss": 0.1598,
      "step": 1650
    },
    {
      "epoch": 0.9485714285714286,
      "grad_norm": 15.800171852111816,
      "learning_rate": 1.8102857142857143e-05,
      "loss": 0.1956,
      "step": 1660
    },
    {
      "epoch": 0.9542857142857143,
      "grad_norm": 0.2879549264907837,
      "learning_rate": 1.8091428571428573e-05,
      "loss": 0.0899,
      "step": 1670
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1457231044769287,
      "learning_rate": 1.8080000000000003e-05,
      "loss": 0.2418,
      "step": 1680
    },
    {
      "epoch": 0.9657142857142857,
      "grad_norm": 15.607526779174805,
      "learning_rate": 1.806857142857143e-05,
      "loss": 0.1644,
      "step": 1690
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 21.97756576538086,
      "learning_rate": 1.8057142857142857e-05,
      "loss": 0.2022,
      "step": 1700
    },
    {
      "epoch": 0.9771428571428571,
      "grad_norm": 9.742379188537598,
      "learning_rate": 1.8045714285714287e-05,
      "loss": 0.2084,
      "step": 1710
    },
    {
      "epoch": 0.9828571428571429,
      "grad_norm": 5.8912739753723145,
      "learning_rate": 1.8034285714285717e-05,
      "loss": 0.1212,
      "step": 1720
    },
    {
      "epoch": 0.9885714285714285,
      "grad_norm": 7.1348724365234375,
      "learning_rate": 1.8022857142857144e-05,
      "loss": 0.1356,
      "step": 1730
    },
    {
      "epoch": 0.9942857142857143,
      "grad_norm": 5.980622291564941,
      "learning_rate": 1.8011428571428574e-05,
      "loss": 0.1796,
      "step": 1740
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.39533668756484985,
      "learning_rate": 1.8e-05,
      "loss": 0.1309,
      "step": 1750
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.942346256684492,
      "eval_f1": 0.676663542642924,
      "eval_loss": 0.2165774554014206,
      "eval_precision": 0.907035175879397,
      "eval_recall": 0.5396113602391629,
      "eval_runtime": 51.2423,
      "eval_samples_per_second": 117.091,
      "eval_steps_per_second": 3.669,
      "step": 1750
    },
    {
      "epoch": 1.0057142857142858,
      "grad_norm": 1.1377109289169312,
      "learning_rate": 1.798857142857143e-05,
      "loss": 0.1724,
      "step": 1760
    },
    {
      "epoch": 1.0114285714285713,
      "grad_norm": 18.883686065673828,
      "learning_rate": 1.797714285714286e-05,
      "loss": 0.1623,
      "step": 1770
    },
    {
      "epoch": 1.0171428571428571,
      "grad_norm": 0.10692216455936432,
      "learning_rate": 1.7965714285714287e-05,
      "loss": 0.1673,
      "step": 1780
    },
    {
      "epoch": 1.022857142857143,
      "grad_norm": 5.070716857910156,
      "learning_rate": 1.7954285714285714e-05,
      "loss": 0.2401,
      "step": 1790
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 10.885027885437012,
      "learning_rate": 1.7942857142857144e-05,
      "loss": 0.2098,
      "step": 1800
    },
    {
      "epoch": 1.0342857142857143,
      "grad_norm": 11.709897994995117,
      "learning_rate": 1.7931428571428574e-05,
      "loss": 0.1549,
      "step": 1810
    },
    {
      "epoch": 1.04,
      "grad_norm": 9.914673805236816,
      "learning_rate": 1.792e-05,
      "loss": 0.1578,
      "step": 1820
    },
    {
      "epoch": 1.0457142857142858,
      "grad_norm": 2.2954986095428467,
      "learning_rate": 1.790857142857143e-05,
      "loss": 0.1196,
      "step": 1830
    },
    {
      "epoch": 1.0514285714285714,
      "grad_norm": 1.3376961946487427,
      "learning_rate": 1.7897142857142858e-05,
      "loss": 0.1365,
      "step": 1840
    },
    {
      "epoch": 1.0571428571428572,
      "grad_norm": 1.775328278541565,
      "learning_rate": 1.7885714285714285e-05,
      "loss": 0.093,
      "step": 1850
    },
    {
      "epoch": 1.062857142857143,
      "grad_norm": 0.14609791338443756,
      "learning_rate": 1.7874285714285715e-05,
      "loss": 0.0672,
      "step": 1860
    },
    {
      "epoch": 1.0685714285714285,
      "grad_norm": 17.26458168029785,
      "learning_rate": 1.7862857142857145e-05,
      "loss": 0.2566,
      "step": 1870
    },
    {
      "epoch": 1.0742857142857143,
      "grad_norm": 12.935935974121094,
      "learning_rate": 1.7851428571428572e-05,
      "loss": 0.1276,
      "step": 1880
    },
    {
      "epoch": 1.08,
      "grad_norm": 14.442023277282715,
      "learning_rate": 1.7840000000000002e-05,
      "loss": 0.1549,
      "step": 1890
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 14.789213180541992,
      "learning_rate": 1.7828571428571432e-05,
      "loss": 0.0768,
      "step": 1900
    },
    {
      "epoch": 1.0914285714285714,
      "grad_norm": 17.006685256958008,
      "learning_rate": 1.781714285714286e-05,
      "loss": 0.2057,
      "step": 1910
    },
    {
      "epoch": 1.0971428571428572,
      "grad_norm": 12.430421829223633,
      "learning_rate": 1.7805714285714286e-05,
      "loss": 0.1691,
      "step": 1920
    },
    {
      "epoch": 1.1028571428571428,
      "grad_norm": 0.5528160929679871,
      "learning_rate": 1.7794285714285716e-05,
      "loss": 0.0933,
      "step": 1930
    },
    {
      "epoch": 1.1085714285714285,
      "grad_norm": 1.029407262802124,
      "learning_rate": 1.7782857142857142e-05,
      "loss": 0.0707,
      "step": 1940
    },
    {
      "epoch": 1.1142857142857143,
      "grad_norm": 11.298086166381836,
      "learning_rate": 1.7771428571428573e-05,
      "loss": 0.1711,
      "step": 1950
    },
    {
      "epoch": 1.12,
      "grad_norm": 7.215487003326416,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.1707,
      "step": 1960
    },
    {
      "epoch": 1.1257142857142857,
      "grad_norm": 0.1831262856721878,
      "learning_rate": 1.774857142857143e-05,
      "loss": 0.1366,
      "step": 1970
    },
    {
      "epoch": 1.1314285714285715,
      "grad_norm": 0.6591907739639282,
      "learning_rate": 1.773714285714286e-05,
      "loss": 0.1359,
      "step": 1980
    },
    {
      "epoch": 1.1371428571428572,
      "grad_norm": 12.231712341308594,
      "learning_rate": 1.7725714285714286e-05,
      "loss": 0.1615,
      "step": 1990
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 13.200119018554688,
      "learning_rate": 1.7714285714285717e-05,
      "loss": 0.2638,
      "step": 2000
    },
    {
      "epoch": 1.1485714285714286,
      "grad_norm": 10.163981437683105,
      "learning_rate": 1.7702857142857143e-05,
      "loss": 0.1148,
      "step": 2010
    },
    {
      "epoch": 1.1542857142857144,
      "grad_norm": 22.416006088256836,
      "learning_rate": 1.7691428571428573e-05,
      "loss": 0.1395,
      "step": 2020
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.19911333918571472,
      "learning_rate": 1.768e-05,
      "loss": 0.2898,
      "step": 2030
    },
    {
      "epoch": 1.1657142857142857,
      "grad_norm": 9.072419166564941,
      "learning_rate": 1.766857142857143e-05,
      "loss": 0.1433,
      "step": 2040
    },
    {
      "epoch": 1.1714285714285715,
      "grad_norm": 11.204803466796875,
      "learning_rate": 1.765714285714286e-05,
      "loss": 0.1273,
      "step": 2050
    },
    {
      "epoch": 1.177142857142857,
      "grad_norm": 0.3090071380138397,
      "learning_rate": 1.7645714285714287e-05,
      "loss": 0.1664,
      "step": 2060
    },
    {
      "epoch": 1.1828571428571428,
      "grad_norm": 7.827442646026611,
      "learning_rate": 1.7634285714285714e-05,
      "loss": 0.0868,
      "step": 2070
    },
    {
      "epoch": 1.1885714285714286,
      "grad_norm": 2.324683904647827,
      "learning_rate": 1.7622857142857144e-05,
      "loss": 0.0782,
      "step": 2080
    },
    {
      "epoch": 1.1942857142857144,
      "grad_norm": 1.2220509052276611,
      "learning_rate": 1.7611428571428574e-05,
      "loss": 0.2378,
      "step": 2090
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.20023250579834,
      "learning_rate": 1.76e-05,
      "loss": 0.2777,
      "step": 2100
    },
    {
      "epoch": 1.2057142857142857,
      "grad_norm": 1.3418034315109253,
      "learning_rate": 1.758857142857143e-05,
      "loss": 0.1105,
      "step": 2110
    },
    {
      "epoch": 1.2114285714285715,
      "grad_norm": 0.6773192286491394,
      "learning_rate": 1.7577142857142858e-05,
      "loss": 0.1732,
      "step": 2120
    },
    {
      "epoch": 1.217142857142857,
      "grad_norm": 12.530592918395996,
      "learning_rate": 1.7565714285714288e-05,
      "loss": 0.1871,
      "step": 2130
    },
    {
      "epoch": 1.2228571428571429,
      "grad_norm": 2.0614383220672607,
      "learning_rate": 1.7554285714285715e-05,
      "loss": 0.136,
      "step": 2140
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 0.39131632447242737,
      "learning_rate": 1.7542857142857145e-05,
      "loss": 0.142,
      "step": 2150
    },
    {
      "epoch": 1.2342857142857142,
      "grad_norm": 0.45052722096443176,
      "learning_rate": 1.753142857142857e-05,
      "loss": 0.0457,
      "step": 2160
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.14507032930850983,
      "learning_rate": 1.752e-05,
      "loss": 0.1885,
      "step": 2170
    },
    {
      "epoch": 1.2457142857142858,
      "grad_norm": 0.4271332323551178,
      "learning_rate": 1.7508571428571432e-05,
      "loss": 0.106,
      "step": 2180
    },
    {
      "epoch": 1.2514285714285713,
      "grad_norm": 0.3899342119693756,
      "learning_rate": 1.749714285714286e-05,
      "loss": 0.0416,
      "step": 2190
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 12.800329208374023,
      "learning_rate": 1.748571428571429e-05,
      "loss": 0.2103,
      "step": 2200
    },
    {
      "epoch": 1.262857142857143,
      "grad_norm": 4.5387043952941895,
      "learning_rate": 1.7474285714285715e-05,
      "loss": 0.1434,
      "step": 2210
    },
    {
      "epoch": 1.2685714285714287,
      "grad_norm": 0.1426275074481964,
      "learning_rate": 1.7462857142857142e-05,
      "loss": 0.0845,
      "step": 2220
    },
    {
      "epoch": 1.2742857142857142,
      "grad_norm": 13.957321166992188,
      "learning_rate": 1.7451428571428572e-05,
      "loss": 0.1055,
      "step": 2230
    },
    {
      "epoch": 1.28,
      "grad_norm": 8.571075439453125,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 0.1198,
      "step": 2240
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 12.837272644042969,
      "learning_rate": 1.742857142857143e-05,
      "loss": 0.1196,
      "step": 2250
    },
    {
      "epoch": 1.2914285714285714,
      "grad_norm": 17.641084671020508,
      "learning_rate": 1.741714285714286e-05,
      "loss": 0.2803,
      "step": 2260
    },
    {
      "epoch": 1.2971428571428572,
      "grad_norm": 9.205031394958496,
      "learning_rate": 1.740571428571429e-05,
      "loss": 0.1323,
      "step": 2270
    },
    {
      "epoch": 1.302857142857143,
      "grad_norm": 0.17206400632858276,
      "learning_rate": 1.7394285714285716e-05,
      "loss": 0.1304,
      "step": 2280
    },
    {
      "epoch": 1.3085714285714285,
      "grad_norm": 11.089035034179688,
      "learning_rate": 1.7382857142857143e-05,
      "loss": 0.1503,
      "step": 2290
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 11.122284889221191,
      "learning_rate": 1.7371428571428573e-05,
      "loss": 0.131,
      "step": 2300
    },
    {
      "epoch": 1.32,
      "grad_norm": 6.817927360534668,
      "learning_rate": 1.736e-05,
      "loss": 0.1462,
      "step": 2310
    },
    {
      "epoch": 1.3257142857142856,
      "grad_norm": 2.0289974212646484,
      "learning_rate": 1.734857142857143e-05,
      "loss": 0.0903,
      "step": 2320
    },
    {
      "epoch": 1.3314285714285714,
      "grad_norm": 2.495269536972046,
      "learning_rate": 1.733714285714286e-05,
      "loss": 0.0935,
      "step": 2330
    },
    {
      "epoch": 1.3371428571428572,
      "grad_norm": 0.030408810824155807,
      "learning_rate": 1.7325714285714287e-05,
      "loss": 0.105,
      "step": 2340
    },
    {
      "epoch": 1.342857142857143,
      "grad_norm": 5.645968437194824,
      "learning_rate": 1.7314285714285717e-05,
      "loss": 0.1474,
      "step": 2350
    },
    {
      "epoch": 1.3485714285714285,
      "grad_norm": 0.5238416790962219,
      "learning_rate": 1.7302857142857144e-05,
      "loss": 0.1125,
      "step": 2360
    },
    {
      "epoch": 1.3542857142857143,
      "grad_norm": 14.807342529296875,
      "learning_rate": 1.7291428571428574e-05,
      "loss": 0.1352,
      "step": 2370
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.1612226814031601,
      "learning_rate": 1.728e-05,
      "loss": 0.0889,
      "step": 2380
    },
    {
      "epoch": 1.3657142857142857,
      "grad_norm": 15.567523002624512,
      "learning_rate": 1.726857142857143e-05,
      "loss": 0.0968,
      "step": 2390
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 2.011039972305298,
      "learning_rate": 1.7257142857142857e-05,
      "loss": 0.0924,
      "step": 2400
    },
    {
      "epoch": 1.3771428571428572,
      "grad_norm": 0.03431639075279236,
      "learning_rate": 1.7245714285714288e-05,
      "loss": 0.1343,
      "step": 2410
    },
    {
      "epoch": 1.3828571428571428,
      "grad_norm": 19.640504837036133,
      "learning_rate": 1.7234285714285718e-05,
      "loss": 0.2306,
      "step": 2420
    },
    {
      "epoch": 1.3885714285714286,
      "grad_norm": 0.03580804541707039,
      "learning_rate": 1.7222857142857144e-05,
      "loss": 0.2243,
      "step": 2430
    },
    {
      "epoch": 1.3942857142857144,
      "grad_norm": 4.818218231201172,
      "learning_rate": 1.721142857142857e-05,
      "loss": 0.1628,
      "step": 2440
    },
    {
      "epoch": 1.4,
      "grad_norm": 15.891803741455078,
      "learning_rate": 1.72e-05,
      "loss": 0.1339,
      "step": 2450
    },
    {
      "epoch": 1.4057142857142857,
      "grad_norm": 0.22864294052124023,
      "learning_rate": 1.718857142857143e-05,
      "loss": 0.1261,
      "step": 2460
    },
    {
      "epoch": 1.4114285714285715,
      "grad_norm": 14.303889274597168,
      "learning_rate": 1.7177142857142858e-05,
      "loss": 0.2022,
      "step": 2470
    },
    {
      "epoch": 1.4171428571428573,
      "grad_norm": 11.758710861206055,
      "learning_rate": 1.716571428571429e-05,
      "loss": 0.1342,
      "step": 2480
    },
    {
      "epoch": 1.4228571428571428,
      "grad_norm": 0.873348593711853,
      "learning_rate": 1.7154285714285715e-05,
      "loss": 0.0313,
      "step": 2490
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 11.18155574798584,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.2224,
      "step": 2500
    },
    {
      "epoch": 1.4342857142857142,
      "grad_norm": 8.813028335571289,
      "learning_rate": 1.7131428571428572e-05,
      "loss": 0.1432,
      "step": 2510
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.23669004440307617,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 0.1283,
      "step": 2520
    },
    {
      "epoch": 1.4457142857142857,
      "grad_norm": 9.979911804199219,
      "learning_rate": 1.710857142857143e-05,
      "loss": 0.2439,
      "step": 2530
    },
    {
      "epoch": 1.4514285714285715,
      "grad_norm": 0.19562934339046478,
      "learning_rate": 1.709714285714286e-05,
      "loss": 0.0492,
      "step": 2540
    },
    {
      "epoch": 1.457142857142857,
      "grad_norm": 9.013545989990234,
      "learning_rate": 1.708571428571429e-05,
      "loss": 0.0713,
      "step": 2550
    },
    {
      "epoch": 1.4628571428571429,
      "grad_norm": 0.5974507331848145,
      "learning_rate": 1.7074285714285716e-05,
      "loss": 0.0711,
      "step": 2560
    },
    {
      "epoch": 1.4685714285714286,
      "grad_norm": 0.7584791779518127,
      "learning_rate": 1.7062857142857143e-05,
      "loss": 0.1582,
      "step": 2570
    },
    {
      "epoch": 1.4742857142857142,
      "grad_norm": 11.014422416687012,
      "learning_rate": 1.7051428571428573e-05,
      "loss": 0.2347,
      "step": 2580
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.08840779960155487,
      "learning_rate": 1.704e-05,
      "loss": 0.0397,
      "step": 2590
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 0.7267622947692871,
      "learning_rate": 1.702857142857143e-05,
      "loss": 0.3232,
      "step": 2600
    },
    {
      "epoch": 1.4914285714285715,
      "grad_norm": 0.038815226405858994,
      "learning_rate": 1.701714285714286e-05,
      "loss": 0.0426,
      "step": 2610
    },
    {
      "epoch": 1.497142857142857,
      "grad_norm": 8.028977394104004,
      "learning_rate": 1.7005714285714286e-05,
      "loss": 0.0839,
      "step": 2620
    },
    {
      "epoch": 1.502857142857143,
      "grad_norm": 15.508724212646484,
      "learning_rate": 1.6994285714285717e-05,
      "loss": 0.1185,
      "step": 2630
    },
    {
      "epoch": 1.5085714285714285,
      "grad_norm": 10.656187057495117,
      "learning_rate": 1.6982857142857143e-05,
      "loss": 0.0752,
      "step": 2640
    },
    {
      "epoch": 1.5142857142857142,
      "grad_norm": 1.0591658353805542,
      "learning_rate": 1.6971428571428574e-05,
      "loss": 0.1033,
      "step": 2650
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5190160274505615,
      "learning_rate": 1.696e-05,
      "loss": 0.0282,
      "step": 2660
    },
    {
      "epoch": 1.5257142857142858,
      "grad_norm": 0.21276147663593292,
      "learning_rate": 1.694857142857143e-05,
      "loss": 0.1051,
      "step": 2670
    },
    {
      "epoch": 1.5314285714285716,
      "grad_norm": 5.4392476081848145,
      "learning_rate": 1.6937142857142857e-05,
      "loss": 0.0955,
      "step": 2680
    },
    {
      "epoch": 1.5371428571428571,
      "grad_norm": 0.025365347042679787,
      "learning_rate": 1.6925714285714287e-05,
      "loss": 0.0188,
      "step": 2690
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 6.7477593421936035,
      "learning_rate": 1.6914285714285717e-05,
      "loss": 0.1647,
      "step": 2700
    },
    {
      "epoch": 1.5485714285714285,
      "grad_norm": 9.423017501831055,
      "learning_rate": 1.6902857142857144e-05,
      "loss": 0.1286,
      "step": 2710
    },
    {
      "epoch": 1.5542857142857143,
      "grad_norm": 18.197214126586914,
      "learning_rate": 1.689142857142857e-05,
      "loss": 0.1633,
      "step": 2720
    },
    {
      "epoch": 1.56,
      "grad_norm": 4.901854515075684,
      "learning_rate": 1.688e-05,
      "loss": 0.0194,
      "step": 2730
    },
    {
      "epoch": 1.5657142857142858,
      "grad_norm": 5.653522491455078,
      "learning_rate": 1.686857142857143e-05,
      "loss": 0.0983,
      "step": 2740
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.03241384029388428,
      "learning_rate": 1.6857142857142858e-05,
      "loss": 0.1182,
      "step": 2750
    },
    {
      "epoch": 1.5771428571428572,
      "grad_norm": 17.46676254272461,
      "learning_rate": 1.6845714285714288e-05,
      "loss": 0.1159,
      "step": 2760
    },
    {
      "epoch": 1.5828571428571427,
      "grad_norm": 0.16438858211040497,
      "learning_rate": 1.6834285714285715e-05,
      "loss": 0.0456,
      "step": 2770
    },
    {
      "epoch": 1.5885714285714285,
      "grad_norm": 0.04706142470240593,
      "learning_rate": 1.6822857142857145e-05,
      "loss": 0.0832,
      "step": 2780
    },
    {
      "epoch": 1.5942857142857143,
      "grad_norm": 0.2427462339401245,
      "learning_rate": 1.681142857142857e-05,
      "loss": 0.1464,
      "step": 2790
    },
    {
      "epoch": 1.6,
      "grad_norm": 10.845929145812988,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.2021,
      "step": 2800
    },
    {
      "epoch": 1.6057142857142859,
      "grad_norm": 7.432340145111084,
      "learning_rate": 1.678857142857143e-05,
      "loss": 0.1328,
      "step": 2810
    },
    {
      "epoch": 1.6114285714285714,
      "grad_norm": 24.323789596557617,
      "learning_rate": 1.677714285714286e-05,
      "loss": 0.2512,
      "step": 2820
    },
    {
      "epoch": 1.617142857142857,
      "grad_norm": 13.279935836791992,
      "learning_rate": 1.676571428571429e-05,
      "loss": 0.1529,
      "step": 2830
    },
    {
      "epoch": 1.6228571428571428,
      "grad_norm": 17.545917510986328,
      "learning_rate": 1.6754285714285716e-05,
      "loss": 0.1704,
      "step": 2840
    },
    {
      "epoch": 1.6285714285714286,
      "grad_norm": 9.533480644226074,
      "learning_rate": 1.6742857142857146e-05,
      "loss": 0.1027,
      "step": 2850
    },
    {
      "epoch": 1.6342857142857143,
      "grad_norm": 7.015285491943359,
      "learning_rate": 1.6731428571428572e-05,
      "loss": 0.0735,
      "step": 2860
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 18.674518585205078,
      "learning_rate": 1.672e-05,
      "loss": 0.1291,
      "step": 2870
    },
    {
      "epoch": 1.6457142857142857,
      "grad_norm": 6.241071701049805,
      "learning_rate": 1.670857142857143e-05,
      "loss": 0.0377,
      "step": 2880
    },
    {
      "epoch": 1.6514285714285715,
      "grad_norm": 0.03542109578847885,
      "learning_rate": 1.669714285714286e-05,
      "loss": 0.0656,
      "step": 2890
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 1.0858781337738037,
      "learning_rate": 1.6685714285714286e-05,
      "loss": 0.1282,
      "step": 2900
    },
    {
      "epoch": 1.6628571428571428,
      "grad_norm": 14.936960220336914,
      "learning_rate": 1.6674285714285716e-05,
      "loss": 0.0394,
      "step": 2910
    },
    {
      "epoch": 1.6685714285714286,
      "grad_norm": 3.6397974491119385,
      "learning_rate": 1.6662857142857146e-05,
      "loss": 0.0474,
      "step": 2920
    },
    {
      "epoch": 1.6742857142857144,
      "grad_norm": 0.05135982483625412,
      "learning_rate": 1.6651428571428573e-05,
      "loss": 0.1159,
      "step": 2930
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.2696744203567505,
      "learning_rate": 1.664e-05,
      "loss": 0.0808,
      "step": 2940
    },
    {
      "epoch": 1.6857142857142857,
      "grad_norm": 0.6651809215545654,
      "learning_rate": 1.662857142857143e-05,
      "loss": 0.113,
      "step": 2950
    },
    {
      "epoch": 1.6914285714285713,
      "grad_norm": 7.608311176300049,
      "learning_rate": 1.6617142857142857e-05,
      "loss": 0.1607,
      "step": 2960
    },
    {
      "epoch": 1.697142857142857,
      "grad_norm": 0.03281570225954056,
      "learning_rate": 1.6605714285714287e-05,
      "loss": 0.0791,
      "step": 2970
    },
    {
      "epoch": 1.7028571428571428,
      "grad_norm": 13.637465476989746,
      "learning_rate": 1.6594285714285717e-05,
      "loss": 0.1062,
      "step": 2980
    },
    {
      "epoch": 1.7085714285714286,
      "grad_norm": 0.3598439395427704,
      "learning_rate": 1.6582857142857144e-05,
      "loss": 0.0797,
      "step": 2990
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.18546244502067566,
      "learning_rate": 1.6571428571428574e-05,
      "loss": 0.1122,
      "step": 3000
    },
    {
      "epoch": 1.72,
      "grad_norm": 11.827813148498535,
      "learning_rate": 1.656e-05,
      "loss": 0.1608,
      "step": 3010
    },
    {
      "epoch": 1.7257142857142858,
      "grad_norm": 8.557190895080566,
      "learning_rate": 1.654857142857143e-05,
      "loss": 0.1645,
      "step": 3020
    },
    {
      "epoch": 1.7314285714285713,
      "grad_norm": 2.651273012161255,
      "learning_rate": 1.6537142857142858e-05,
      "loss": 0.069,
      "step": 3030
    },
    {
      "epoch": 1.737142857142857,
      "grad_norm": 1.4903826713562012,
      "learning_rate": 1.6525714285714288e-05,
      "loss": 0.1402,
      "step": 3040
    },
    {
      "epoch": 1.7428571428571429,
      "grad_norm": 0.5355817675590515,
      "learning_rate": 1.6514285714285714e-05,
      "loss": 0.0915,
      "step": 3050
    },
    {
      "epoch": 1.7485714285714287,
      "grad_norm": 0.7710886001586914,
      "learning_rate": 1.6502857142857145e-05,
      "loss": 0.063,
      "step": 3060
    },
    {
      "epoch": 1.7542857142857144,
      "grad_norm": 15.95280933380127,
      "learning_rate": 1.6491428571428575e-05,
      "loss": 0.1544,
      "step": 3070
    },
    {
      "epoch": 1.76,
      "grad_norm": 7.6961469650268555,
      "learning_rate": 1.648e-05,
      "loss": 0.0608,
      "step": 3080
    },
    {
      "epoch": 1.7657142857142856,
      "grad_norm": 0.009748241864144802,
      "learning_rate": 1.6468571428571428e-05,
      "loss": 0.058,
      "step": 3090
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 20.441316604614258,
      "learning_rate": 1.645714285714286e-05,
      "loss": 0.2538,
      "step": 3100
    },
    {
      "epoch": 1.7771428571428571,
      "grad_norm": 21.027423858642578,
      "learning_rate": 1.644571428571429e-05,
      "loss": 0.1326,
      "step": 3110
    },
    {
      "epoch": 1.782857142857143,
      "grad_norm": 6.276472091674805,
      "learning_rate": 1.6434285714285715e-05,
      "loss": 0.0507,
      "step": 3120
    },
    {
      "epoch": 1.7885714285714287,
      "grad_norm": 6.9302659034729,
      "learning_rate": 1.6422857142857145e-05,
      "loss": 0.235,
      "step": 3130
    },
    {
      "epoch": 1.7942857142857143,
      "grad_norm": 15.576233863830566,
      "learning_rate": 1.6411428571428572e-05,
      "loss": 0.1485,
      "step": 3140
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.42731356620788574,
      "learning_rate": 1.64e-05,
      "loss": 0.1332,
      "step": 3150
    },
    {
      "epoch": 1.8057142857142856,
      "grad_norm": 5.6434431076049805,
      "learning_rate": 1.638857142857143e-05,
      "loss": 0.1691,
      "step": 3160
    },
    {
      "epoch": 1.8114285714285714,
      "grad_norm": 11.891531944274902,
      "learning_rate": 1.637714285714286e-05,
      "loss": 0.1654,
      "step": 3170
    },
    {
      "epoch": 1.8171428571428572,
      "grad_norm": 10.865346908569336,
      "learning_rate": 1.6365714285714286e-05,
      "loss": 0.1369,
      "step": 3180
    },
    {
      "epoch": 1.822857142857143,
      "grad_norm": 0.0765911340713501,
      "learning_rate": 1.6354285714285716e-05,
      "loss": 0.0644,
      "step": 3190
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 0.15877091884613037,
      "learning_rate": 1.6342857142857146e-05,
      "loss": 0.0258,
      "step": 3200
    },
    {
      "epoch": 1.8342857142857143,
      "grad_norm": 19.763885498046875,
      "learning_rate": 1.6331428571428573e-05,
      "loss": 0.213,
      "step": 3210
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.9487016797065735,
      "learning_rate": 1.632e-05,
      "loss": 0.1219,
      "step": 3220
    },
    {
      "epoch": 1.8457142857142856,
      "grad_norm": 4.715893268585205,
      "learning_rate": 1.630857142857143e-05,
      "loss": 0.0636,
      "step": 3230
    },
    {
      "epoch": 1.8514285714285714,
      "grad_norm": 13.47585678100586,
      "learning_rate": 1.6297142857142856e-05,
      "loss": 0.0711,
      "step": 3240
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 2.725658893585205,
      "learning_rate": 1.6285714285714287e-05,
      "loss": 0.1264,
      "step": 3250
    },
    {
      "epoch": 1.862857142857143,
      "grad_norm": 5.083413124084473,
      "learning_rate": 1.6274285714285717e-05,
      "loss": 0.2164,
      "step": 3260
    },
    {
      "epoch": 1.8685714285714285,
      "grad_norm": 0.1111488789319992,
      "learning_rate": 1.6262857142857143e-05,
      "loss": 0.1583,
      "step": 3270
    },
    {
      "epoch": 1.8742857142857143,
      "grad_norm": 0.1360425353050232,
      "learning_rate": 1.6251428571428574e-05,
      "loss": 0.0619,
      "step": 3280
    },
    {
      "epoch": 1.88,
      "grad_norm": 6.229352951049805,
      "learning_rate": 1.6240000000000004e-05,
      "loss": 0.1445,
      "step": 3290
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 8.591737747192383,
      "learning_rate": 1.622857142857143e-05,
      "loss": 0.165,
      "step": 3300
    },
    {
      "epoch": 1.8914285714285715,
      "grad_norm": 9.460164070129395,
      "learning_rate": 1.6217142857142857e-05,
      "loss": 0.0776,
      "step": 3310
    },
    {
      "epoch": 1.8971428571428572,
      "grad_norm": 15.111669540405273,
      "learning_rate": 1.6205714285714287e-05,
      "loss": 0.1623,
      "step": 3320
    },
    {
      "epoch": 1.9028571428571428,
      "grad_norm": 0.2543952167034149,
      "learning_rate": 1.6194285714285714e-05,
      "loss": 0.0854,
      "step": 3330
    },
    {
      "epoch": 1.9085714285714286,
      "grad_norm": 16.994714736938477,
      "learning_rate": 1.6182857142857144e-05,
      "loss": 0.0545,
      "step": 3340
    },
    {
      "epoch": 1.9142857142857141,
      "grad_norm": 0.6961798071861267,
      "learning_rate": 1.6171428571428574e-05,
      "loss": 0.0869,
      "step": 3350
    },
    {
      "epoch": 1.92,
      "grad_norm": 12.771647453308105,
      "learning_rate": 1.616e-05,
      "loss": 0.0931,
      "step": 3360
    },
    {
      "epoch": 1.9257142857142857,
      "grad_norm": 3.1876018047332764,
      "learning_rate": 1.6148571428571428e-05,
      "loss": 0.0873,
      "step": 3370
    },
    {
      "epoch": 1.9314285714285715,
      "grad_norm": 7.670049667358398,
      "learning_rate": 1.6137142857142858e-05,
      "loss": 0.1027,
      "step": 3380
    },
    {
      "epoch": 1.9371428571428573,
      "grad_norm": 0.03199908137321472,
      "learning_rate": 1.6125714285714288e-05,
      "loss": 0.1143,
      "step": 3390
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 4.109528541564941,
      "learning_rate": 1.6114285714285715e-05,
      "loss": 0.138,
      "step": 3400
    },
    {
      "epoch": 1.9485714285714286,
      "grad_norm": 7.580557346343994,
      "learning_rate": 1.6102857142857145e-05,
      "loss": 0.1247,
      "step": 3410
    },
    {
      "epoch": 1.9542857142857142,
      "grad_norm": 9.034016609191895,
      "learning_rate": 1.6091428571428572e-05,
      "loss": 0.1542,
      "step": 3420
    },
    {
      "epoch": 1.96,
      "grad_norm": 10.227007865905762,
      "learning_rate": 1.6080000000000002e-05,
      "loss": 0.1071,
      "step": 3430
    },
    {
      "epoch": 1.9657142857142857,
      "grad_norm": 0.06294099241495132,
      "learning_rate": 1.606857142857143e-05,
      "loss": 0.0648,
      "step": 3440
    },
    {
      "epoch": 1.9714285714285715,
      "grad_norm": 14.90295696258545,
      "learning_rate": 1.605714285714286e-05,
      "loss": 0.1304,
      "step": 3450
    },
    {
      "epoch": 1.977142857142857,
      "grad_norm": 0.9779912233352661,
      "learning_rate": 1.6045714285714286e-05,
      "loss": 0.0567,
      "step": 3460
    },
    {
      "epoch": 1.9828571428571429,
      "grad_norm": 0.016967589035630226,
      "learning_rate": 1.6034285714285716e-05,
      "loss": 0.1691,
      "step": 3470
    },
    {
      "epoch": 1.9885714285714284,
      "grad_norm": 0.12321232259273529,
      "learning_rate": 1.6022857142857146e-05,
      "loss": 0.1902,
      "step": 3480
    },
    {
      "epoch": 1.9942857142857142,
      "grad_norm": 35.272071838378906,
      "learning_rate": 1.6011428571428573e-05,
      "loss": 0.2144,
      "step": 3490
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4960249364376068,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.1516,
      "step": 3500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9717580213903744,
      "eval_f1": 0.8769118718135469,
      "eval_loss": 0.09933319687843323,
      "eval_precision": 0.8551136363636364,
      "eval_recall": 0.8998505231689088,
      "eval_runtime": 50.5237,
      "eval_samples_per_second": 118.756,
      "eval_steps_per_second": 3.721,
      "step": 3500
    },
    {
      "epoch": 2.005714285714286,
      "grad_norm": 1.1612387895584106,
      "learning_rate": 1.598857142857143e-05,
      "loss": 0.0135,
      "step": 3510
    },
    {
      "epoch": 2.0114285714285716,
      "grad_norm": 0.03355948626995087,
      "learning_rate": 1.5977142857142856e-05,
      "loss": 0.0386,
      "step": 3520
    },
    {
      "epoch": 2.0171428571428573,
      "grad_norm": 20.322284698486328,
      "learning_rate": 1.5965714285714286e-05,
      "loss": 0.0607,
      "step": 3530
    },
    {
      "epoch": 2.0228571428571427,
      "grad_norm": 1.7446544170379639,
      "learning_rate": 1.5954285714285716e-05,
      "loss": 0.0868,
      "step": 3540
    },
    {
      "epoch": 2.0285714285714285,
      "grad_norm": 4.637397766113281,
      "learning_rate": 1.5942857142857143e-05,
      "loss": 0.0085,
      "step": 3550
    },
    {
      "epoch": 2.0342857142857143,
      "grad_norm": 11.825579643249512,
      "learning_rate": 1.5931428571428573e-05,
      "loss": 0.0836,
      "step": 3560
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.14249303936958313,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 0.0777,
      "step": 3570
    },
    {
      "epoch": 2.045714285714286,
      "grad_norm": 1.3024975061416626,
      "learning_rate": 1.590857142857143e-05,
      "loss": 0.0844,
      "step": 3580
    },
    {
      "epoch": 2.0514285714285716,
      "grad_norm": 10.757514953613281,
      "learning_rate": 1.5897142857142857e-05,
      "loss": 0.0387,
      "step": 3590
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 10.883408546447754,
      "learning_rate": 1.5885714285714287e-05,
      "loss": 0.0199,
      "step": 3600
    },
    {
      "epoch": 2.0628571428571427,
      "grad_norm": 7.1106953620910645,
      "learning_rate": 1.5874285714285714e-05,
      "loss": 0.1301,
      "step": 3610
    },
    {
      "epoch": 2.0685714285714285,
      "grad_norm": 0.05109552666544914,
      "learning_rate": 1.5862857142857144e-05,
      "loss": 0.102,
      "step": 3620
    },
    {
      "epoch": 2.0742857142857143,
      "grad_norm": 1.1102423667907715,
      "learning_rate": 1.5851428571428574e-05,
      "loss": 0.1019,
      "step": 3630
    },
    {
      "epoch": 2.08,
      "grad_norm": 12.935160636901855,
      "learning_rate": 1.584e-05,
      "loss": 0.1411,
      "step": 3640
    },
    {
      "epoch": 2.085714285714286,
      "grad_norm": 0.7136026620864868,
      "learning_rate": 1.582857142857143e-05,
      "loss": 0.0244,
      "step": 3650
    },
    {
      "epoch": 2.0914285714285716,
      "grad_norm": 0.02906700037419796,
      "learning_rate": 1.5817142857142858e-05,
      "loss": 0.0376,
      "step": 3660
    },
    {
      "epoch": 2.097142857142857,
      "grad_norm": 0.9704679846763611,
      "learning_rate": 1.5805714285714288e-05,
      "loss": 0.1065,
      "step": 3670
    },
    {
      "epoch": 2.1028571428571428,
      "grad_norm": 0.440801739692688,
      "learning_rate": 1.5794285714285715e-05,
      "loss": 0.0434,
      "step": 3680
    },
    {
      "epoch": 2.1085714285714285,
      "grad_norm": 0.11148200184106827,
      "learning_rate": 1.5782857142857145e-05,
      "loss": 0.0632,
      "step": 3690
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 1.0253905057907104,
      "learning_rate": 1.577142857142857e-05,
      "loss": 0.0359,
      "step": 3700
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.03579266741871834,
      "learning_rate": 1.576e-05,
      "loss": 0.0051,
      "step": 3710
    },
    {
      "epoch": 2.125714285714286,
      "grad_norm": 0.061142321676015854,
      "learning_rate": 1.5748571428571432e-05,
      "loss": 0.0687,
      "step": 3720
    },
    {
      "epoch": 2.1314285714285712,
      "grad_norm": 5.570180892944336,
      "learning_rate": 1.573714285714286e-05,
      "loss": 0.0686,
      "step": 3730
    },
    {
      "epoch": 2.137142857142857,
      "grad_norm": 0.027299722656607628,
      "learning_rate": 1.5725714285714285e-05,
      "loss": 0.0106,
      "step": 3740
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 18.472570419311523,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.1014,
      "step": 3750
    },
    {
      "epoch": 2.1485714285714286,
      "grad_norm": 0.3528720438480377,
      "learning_rate": 1.5702857142857145e-05,
      "loss": 0.1516,
      "step": 3760
    },
    {
      "epoch": 2.1542857142857144,
      "grad_norm": 0.11843177676200867,
      "learning_rate": 1.5691428571428572e-05,
      "loss": 0.1276,
      "step": 3770
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.08592354506254196,
      "learning_rate": 1.5680000000000002e-05,
      "loss": 0.0141,
      "step": 3780
    },
    {
      "epoch": 2.1657142857142855,
      "grad_norm": 0.04334113374352455,
      "learning_rate": 1.566857142857143e-05,
      "loss": 0.04,
      "step": 3790
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 0.1282901018857956,
      "learning_rate": 1.5657142857142856e-05,
      "loss": 0.103,
      "step": 3800
    },
    {
      "epoch": 2.177142857142857,
      "grad_norm": 0.056368254125118256,
      "learning_rate": 1.5645714285714286e-05,
      "loss": 0.0648,
      "step": 3810
    },
    {
      "epoch": 2.182857142857143,
      "grad_norm": 32.72494125366211,
      "learning_rate": 1.5634285714285716e-05,
      "loss": 0.0983,
      "step": 3820
    },
    {
      "epoch": 2.1885714285714286,
      "grad_norm": 0.6489703059196472,
      "learning_rate": 1.5622857142857143e-05,
      "loss": 0.1169,
      "step": 3830
    },
    {
      "epoch": 2.1942857142857144,
      "grad_norm": 1.9947808980941772,
      "learning_rate": 1.5611428571428573e-05,
      "loss": 0.0919,
      "step": 3840
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.09174385666847229,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.0776,
      "step": 3850
    },
    {
      "epoch": 2.2057142857142855,
      "grad_norm": 0.03167090192437172,
      "learning_rate": 1.558857142857143e-05,
      "loss": 0.072,
      "step": 3860
    },
    {
      "epoch": 2.2114285714285713,
      "grad_norm": 0.02801896259188652,
      "learning_rate": 1.5577142857142857e-05,
      "loss": 0.0798,
      "step": 3870
    },
    {
      "epoch": 2.217142857142857,
      "grad_norm": 0.02943199686706066,
      "learning_rate": 1.5565714285714287e-05,
      "loss": 0.0202,
      "step": 3880
    },
    {
      "epoch": 2.222857142857143,
      "grad_norm": 0.5211408734321594,
      "learning_rate": 1.5554285714285713e-05,
      "loss": 0.1322,
      "step": 3890
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 0.10928136855363846,
      "learning_rate": 1.5542857142857144e-05,
      "loss": 0.013,
      "step": 3900
    },
    {
      "epoch": 2.2342857142857144,
      "grad_norm": 0.03917925804853439,
      "learning_rate": 1.5531428571428574e-05,
      "loss": 0.0243,
      "step": 3910
    },
    {
      "epoch": 2.24,
      "grad_norm": 20.74247932434082,
      "learning_rate": 1.552e-05,
      "loss": 0.0429,
      "step": 3920
    },
    {
      "epoch": 2.2457142857142856,
      "grad_norm": 1.130565881729126,
      "learning_rate": 1.550857142857143e-05,
      "loss": 0.0425,
      "step": 3930
    },
    {
      "epoch": 2.2514285714285713,
      "grad_norm": 0.024766093119978905,
      "learning_rate": 1.549714285714286e-05,
      "loss": 0.0651,
      "step": 3940
    },
    {
      "epoch": 2.257142857142857,
      "grad_norm": 11.666397094726562,
      "learning_rate": 1.5485714285714287e-05,
      "loss": 0.0203,
      "step": 3950
    },
    {
      "epoch": 2.262857142857143,
      "grad_norm": 4.831507205963135,
      "learning_rate": 1.5474285714285714e-05,
      "loss": 0.1112,
      "step": 3960
    },
    {
      "epoch": 2.2685714285714287,
      "grad_norm": 0.02274910919368267,
      "learning_rate": 1.5462857142857144e-05,
      "loss": 0.0702,
      "step": 3970
    },
    {
      "epoch": 2.2742857142857145,
      "grad_norm": 0.13187406957149506,
      "learning_rate": 1.545142857142857e-05,
      "loss": 0.0583,
      "step": 3980
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.05307277292013168,
      "learning_rate": 1.544e-05,
      "loss": 0.01,
      "step": 3990
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 22.888017654418945,
      "learning_rate": 1.542857142857143e-05,
      "loss": 0.0249,
      "step": 4000
    },
    {
      "epoch": 2.2914285714285714,
      "grad_norm": 0.010334961116313934,
      "learning_rate": 1.5417142857142858e-05,
      "loss": 0.0071,
      "step": 4010
    },
    {
      "epoch": 2.297142857142857,
      "grad_norm": 9.8102445602417,
      "learning_rate": 1.5405714285714285e-05,
      "loss": 0.1041,
      "step": 4020
    },
    {
      "epoch": 2.302857142857143,
      "grad_norm": 0.0895962119102478,
      "learning_rate": 1.5394285714285715e-05,
      "loss": 0.0831,
      "step": 4030
    },
    {
      "epoch": 2.3085714285714287,
      "grad_norm": 2.2773237228393555,
      "learning_rate": 1.5382857142857145e-05,
      "loss": 0.0545,
      "step": 4040
    },
    {
      "epoch": 2.314285714285714,
      "grad_norm": 0.2524404525756836,
      "learning_rate": 1.5371428571428572e-05,
      "loss": 0.0061,
      "step": 4050
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.004026054870337248,
      "learning_rate": 1.5360000000000002e-05,
      "loss": 0.0177,
      "step": 4060
    },
    {
      "epoch": 2.3257142857142856,
      "grad_norm": 0.5773526430130005,
      "learning_rate": 1.534857142857143e-05,
      "loss": 0.185,
      "step": 4070
    },
    {
      "epoch": 2.3314285714285714,
      "grad_norm": 0.12409111857414246,
      "learning_rate": 1.533714285714286e-05,
      "loss": 0.0546,
      "step": 4080
    },
    {
      "epoch": 2.337142857142857,
      "grad_norm": 0.003912936430424452,
      "learning_rate": 1.5325714285714286e-05,
      "loss": 0.0044,
      "step": 4090
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 0.04459676891565323,
      "learning_rate": 1.5314285714285716e-05,
      "loss": 0.0696,
      "step": 4100
    },
    {
      "epoch": 2.3485714285714288,
      "grad_norm": 19.6085262298584,
      "learning_rate": 1.5302857142857143e-05,
      "loss": 0.0139,
      "step": 4110
    },
    {
      "epoch": 2.354285714285714,
      "grad_norm": 0.009023754857480526,
      "learning_rate": 1.5291428571428573e-05,
      "loss": 0.0807,
      "step": 4120
    },
    {
      "epoch": 2.36,
      "grad_norm": 17.284128189086914,
      "learning_rate": 1.5280000000000003e-05,
      "loss": 0.0342,
      "step": 4130
    },
    {
      "epoch": 2.3657142857142857,
      "grad_norm": 0.06898584216833115,
      "learning_rate": 1.526857142857143e-05,
      "loss": 0.0534,
      "step": 4140
    },
    {
      "epoch": 2.3714285714285714,
      "grad_norm": 2.3171193599700928,
      "learning_rate": 1.525714285714286e-05,
      "loss": 0.0597,
      "step": 4150
    },
    {
      "epoch": 2.3771428571428572,
      "grad_norm": 0.06879061460494995,
      "learning_rate": 1.5245714285714286e-05,
      "loss": 0.0869,
      "step": 4160
    },
    {
      "epoch": 2.382857142857143,
      "grad_norm": 0.026649687439203262,
      "learning_rate": 1.5234285714285715e-05,
      "loss": 0.0396,
      "step": 4170
    },
    {
      "epoch": 2.388571428571429,
      "grad_norm": 0.9601700305938721,
      "learning_rate": 1.5222857142857143e-05,
      "loss": 0.1117,
      "step": 4180
    },
    {
      "epoch": 2.394285714285714,
      "grad_norm": 0.37168407440185547,
      "learning_rate": 1.5211428571428572e-05,
      "loss": 0.0515,
      "step": 4190
    },
    {
      "epoch": 2.4,
      "grad_norm": 31.142290115356445,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.1498,
      "step": 4200
    },
    {
      "epoch": 2.4057142857142857,
      "grad_norm": 0.01847040094435215,
      "learning_rate": 1.518857142857143e-05,
      "loss": 0.0274,
      "step": 4210
    },
    {
      "epoch": 2.4114285714285715,
      "grad_norm": 0.04997238144278526,
      "learning_rate": 1.5177142857142859e-05,
      "loss": 0.1035,
      "step": 4220
    },
    {
      "epoch": 2.4171428571428573,
      "grad_norm": 10.196866989135742,
      "learning_rate": 1.5165714285714289e-05,
      "loss": 0.0461,
      "step": 4230
    },
    {
      "epoch": 2.422857142857143,
      "grad_norm": 0.005393356550484896,
      "learning_rate": 1.5154285714285714e-05,
      "loss": 0.0568,
      "step": 4240
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.014763608574867249,
      "learning_rate": 1.5142857142857144e-05,
      "loss": 0.0629,
      "step": 4250
    },
    {
      "epoch": 2.434285714285714,
      "grad_norm": 0.01845596358180046,
      "learning_rate": 1.5131428571428572e-05,
      "loss": 0.0522,
      "step": 4260
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.14475011825561523,
      "learning_rate": 1.5120000000000001e-05,
      "loss": 0.1048,
      "step": 4270
    },
    {
      "epoch": 2.4457142857142857,
      "grad_norm": 0.011374292895197868,
      "learning_rate": 1.5108571428571431e-05,
      "loss": 0.0922,
      "step": 4280
    },
    {
      "epoch": 2.4514285714285715,
      "grad_norm": 0.04538848623633385,
      "learning_rate": 1.509714285714286e-05,
      "loss": 0.0328,
      "step": 4290
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 0.1426783949136734,
      "learning_rate": 1.5085714285714288e-05,
      "loss": 0.1051,
      "step": 4300
    },
    {
      "epoch": 2.4628571428571426,
      "grad_norm": 14.56599235534668,
      "learning_rate": 1.5074285714285715e-05,
      "loss": 0.1666,
      "step": 4310
    },
    {
      "epoch": 2.4685714285714284,
      "grad_norm": 14.382623672485352,
      "learning_rate": 1.5062857142857143e-05,
      "loss": 0.0825,
      "step": 4320
    },
    {
      "epoch": 2.474285714285714,
      "grad_norm": 0.031080877408385277,
      "learning_rate": 1.5051428571428572e-05,
      "loss": 0.0385,
      "step": 4330
    },
    {
      "epoch": 2.48,
      "grad_norm": 7.493340492248535,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 0.004,
      "step": 4340
    },
    {
      "epoch": 2.4857142857142858,
      "grad_norm": 3.447484016418457,
      "learning_rate": 1.502857142857143e-05,
      "loss": 0.1035,
      "step": 4350
    },
    {
      "epoch": 2.4914285714285715,
      "grad_norm": 0.10593505948781967,
      "learning_rate": 1.5017142857142859e-05,
      "loss": 0.04,
      "step": 4360
    },
    {
      "epoch": 2.4971428571428573,
      "grad_norm": 8.403741836547852,
      "learning_rate": 1.5005714285714289e-05,
      "loss": 0.1617,
      "step": 4370
    },
    {
      "epoch": 2.5028571428571427,
      "grad_norm": 0.1856420338153839,
      "learning_rate": 1.4994285714285714e-05,
      "loss": 0.0929,
      "step": 4380
    },
    {
      "epoch": 2.5085714285714285,
      "grad_norm": 0.14168493449687958,
      "learning_rate": 1.4982857142857144e-05,
      "loss": 0.0428,
      "step": 4390
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 0.07255702465772629,
      "learning_rate": 1.4971428571428572e-05,
      "loss": 0.0206,
      "step": 4400
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.028552569448947906,
      "learning_rate": 1.496e-05,
      "loss": 0.0238,
      "step": 4410
    },
    {
      "epoch": 2.525714285714286,
      "grad_norm": 12.03953742980957,
      "learning_rate": 1.4948571428571431e-05,
      "loss": 0.0428,
      "step": 4420
    },
    {
      "epoch": 2.5314285714285716,
      "grad_norm": 3.825597047805786,
      "learning_rate": 1.493714285714286e-05,
      "loss": 0.1064,
      "step": 4430
    },
    {
      "epoch": 2.5371428571428574,
      "grad_norm": 8.76039981842041,
      "learning_rate": 1.4925714285714288e-05,
      "loss": 0.2323,
      "step": 4440
    },
    {
      "epoch": 2.5428571428571427,
      "grad_norm": 20.385894775390625,
      "learning_rate": 1.4914285714285715e-05,
      "loss": 0.0559,
      "step": 4450
    },
    {
      "epoch": 2.5485714285714285,
      "grad_norm": 0.4112267792224884,
      "learning_rate": 1.4902857142857143e-05,
      "loss": 0.0614,
      "step": 4460
    },
    {
      "epoch": 2.5542857142857143,
      "grad_norm": 0.5848976373672485,
      "learning_rate": 1.4891428571428571e-05,
      "loss": 0.0527,
      "step": 4470
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.01299827080219984,
      "learning_rate": 1.4880000000000002e-05,
      "loss": 0.054,
      "step": 4480
    },
    {
      "epoch": 2.565714285714286,
      "grad_norm": 2.7524335384368896,
      "learning_rate": 1.486857142857143e-05,
      "loss": 0.0173,
      "step": 4490
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.03248734772205353,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 0.1122,
      "step": 4500
    },
    {
      "epoch": 2.5771428571428574,
      "grad_norm": 0.9707057476043701,
      "learning_rate": 1.4845714285714289e-05,
      "loss": 0.1462,
      "step": 4510
    },
    {
      "epoch": 2.5828571428571427,
      "grad_norm": 0.10173328965902328,
      "learning_rate": 1.4834285714285714e-05,
      "loss": 0.019,
      "step": 4520
    },
    {
      "epoch": 2.5885714285714285,
      "grad_norm": 45.440582275390625,
      "learning_rate": 1.4822857142857144e-05,
      "loss": 0.0266,
      "step": 4530
    },
    {
      "epoch": 2.5942857142857143,
      "grad_norm": 0.0228508822619915,
      "learning_rate": 1.4811428571428572e-05,
      "loss": 0.0746,
      "step": 4540
    },
    {
      "epoch": 2.6,
      "grad_norm": 9.931221008300781,
      "learning_rate": 1.48e-05,
      "loss": 0.0882,
      "step": 4550
    },
    {
      "epoch": 2.605714285714286,
      "grad_norm": 0.029737956821918488,
      "learning_rate": 1.478857142857143e-05,
      "loss": 0.0695,
      "step": 4560
    },
    {
      "epoch": 2.611428571428571,
      "grad_norm": 12.605623245239258,
      "learning_rate": 1.477714285714286e-05,
      "loss": 0.0714,
      "step": 4570
    },
    {
      "epoch": 2.617142857142857,
      "grad_norm": 0.08675409853458405,
      "learning_rate": 1.4765714285714288e-05,
      "loss": 0.0244,
      "step": 4580
    },
    {
      "epoch": 2.6228571428571428,
      "grad_norm": 0.11033762991428375,
      "learning_rate": 1.4754285714285716e-05,
      "loss": 0.064,
      "step": 4590
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 0.05211532488465309,
      "learning_rate": 1.4742857142857143e-05,
      "loss": 0.0928,
      "step": 4600
    },
    {
      "epoch": 2.6342857142857143,
      "grad_norm": 0.411377489566803,
      "learning_rate": 1.4731428571428571e-05,
      "loss": 0.0294,
      "step": 4610
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.06912928074598312,
      "learning_rate": 1.4720000000000001e-05,
      "loss": 0.0335,
      "step": 4620
    },
    {
      "epoch": 2.645714285714286,
      "grad_norm": 21.457035064697266,
      "learning_rate": 1.470857142857143e-05,
      "loss": 0.0637,
      "step": 4630
    },
    {
      "epoch": 2.6514285714285712,
      "grad_norm": 0.024195104837417603,
      "learning_rate": 1.4697142857142858e-05,
      "loss": 0.0089,
      "step": 4640
    },
    {
      "epoch": 2.657142857142857,
      "grad_norm": 6.242079734802246,
      "learning_rate": 1.4685714285714288e-05,
      "loss": 0.1151,
      "step": 4650
    },
    {
      "epoch": 2.662857142857143,
      "grad_norm": 13.353646278381348,
      "learning_rate": 1.4674285714285717e-05,
      "loss": 0.0698,
      "step": 4660
    },
    {
      "epoch": 2.6685714285714286,
      "grad_norm": 0.204344242811203,
      "learning_rate": 1.4662857142857144e-05,
      "loss": 0.0474,
      "step": 4670
    },
    {
      "epoch": 2.6742857142857144,
      "grad_norm": 0.05808769166469574,
      "learning_rate": 1.4651428571428572e-05,
      "loss": 0.0055,
      "step": 4680
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.0552524328231812,
      "learning_rate": 1.464e-05,
      "loss": 0.0667,
      "step": 4690
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 1.2804011106491089,
      "learning_rate": 1.462857142857143e-05,
      "loss": 0.0702,
      "step": 4700
    },
    {
      "epoch": 2.6914285714285713,
      "grad_norm": 0.2667405605316162,
      "learning_rate": 1.4617142857142859e-05,
      "loss": 0.0535,
      "step": 4710
    },
    {
      "epoch": 2.697142857142857,
      "grad_norm": 1.149479866027832,
      "learning_rate": 1.4605714285714287e-05,
      "loss": 0.0565,
      "step": 4720
    },
    {
      "epoch": 2.702857142857143,
      "grad_norm": 0.0674130767583847,
      "learning_rate": 1.4594285714285716e-05,
      "loss": 0.0549,
      "step": 4730
    },
    {
      "epoch": 2.7085714285714286,
      "grad_norm": 0.04411362484097481,
      "learning_rate": 1.4582857142857143e-05,
      "loss": 0.0097,
      "step": 4740
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.06602168083190918,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 0.0635,
      "step": 4750
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 21.143165588378906,
      "learning_rate": 1.4560000000000001e-05,
      "loss": 0.0421,
      "step": 4760
    },
    {
      "epoch": 2.725714285714286,
      "grad_norm": 0.03946394845843315,
      "learning_rate": 1.454857142857143e-05,
      "loss": 0.0693,
      "step": 4770
    },
    {
      "epoch": 2.7314285714285713,
      "grad_norm": 52.500526428222656,
      "learning_rate": 1.4537142857142858e-05,
      "loss": 0.0472,
      "step": 4780
    },
    {
      "epoch": 2.737142857142857,
      "grad_norm": 12.256646156311035,
      "learning_rate": 1.4525714285714288e-05,
      "loss": 0.034,
      "step": 4790
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 10.148387908935547,
      "learning_rate": 1.4514285714285717e-05,
      "loss": 0.111,
      "step": 4800
    },
    {
      "epoch": 2.7485714285714287,
      "grad_norm": 0.14122335612773895,
      "learning_rate": 1.4502857142857143e-05,
      "loss": 0.1289,
      "step": 4810
    },
    {
      "epoch": 2.7542857142857144,
      "grad_norm": 0.05798588693141937,
      "learning_rate": 1.4491428571428572e-05,
      "loss": 0.0648,
      "step": 4820
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.05676412582397461,
      "learning_rate": 1.448e-05,
      "loss": 0.0377,
      "step": 4830
    },
    {
      "epoch": 2.7657142857142856,
      "grad_norm": 0.06485356390476227,
      "learning_rate": 1.446857142857143e-05,
      "loss": 0.0788,
      "step": 4840
    },
    {
      "epoch": 2.7714285714285714,
      "grad_norm": 0.11288831382989883,
      "learning_rate": 1.4457142857142859e-05,
      "loss": 0.0903,
      "step": 4850
    },
    {
      "epoch": 2.777142857142857,
      "grad_norm": 17.310407638549805,
      "learning_rate": 1.4445714285714287e-05,
      "loss": 0.0577,
      "step": 4860
    },
    {
      "epoch": 2.782857142857143,
      "grad_norm": 2.730403423309326,
      "learning_rate": 1.4434285714285716e-05,
      "loss": 0.0052,
      "step": 4870
    },
    {
      "epoch": 2.7885714285714287,
      "grad_norm": 0.033283159136772156,
      "learning_rate": 1.4422857142857146e-05,
      "loss": 0.0891,
      "step": 4880
    },
    {
      "epoch": 2.7942857142857145,
      "grad_norm": 0.10697323828935623,
      "learning_rate": 1.4411428571428573e-05,
      "loss": 0.102,
      "step": 4890
    },
    {
      "epoch": 2.8,
      "grad_norm": 18.204683303833008,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.1405,
      "step": 4900
    },
    {
      "epoch": 2.8057142857142856,
      "grad_norm": 25.13907814025879,
      "learning_rate": 1.438857142857143e-05,
      "loss": 0.1057,
      "step": 4910
    },
    {
      "epoch": 2.8114285714285714,
      "grad_norm": 0.0832117348909378,
      "learning_rate": 1.4377142857142858e-05,
      "loss": 0.0389,
      "step": 4920
    },
    {
      "epoch": 2.817142857142857,
      "grad_norm": 0.02161935158073902,
      "learning_rate": 1.4365714285714288e-05,
      "loss": 0.0025,
      "step": 4930
    },
    {
      "epoch": 2.822857142857143,
      "grad_norm": 11.040215492248535,
      "learning_rate": 1.4354285714285716e-05,
      "loss": 0.0693,
      "step": 4940
    },
    {
      "epoch": 2.8285714285714287,
      "grad_norm": 23.867773056030273,
      "learning_rate": 1.4342857142857145e-05,
      "loss": 0.0429,
      "step": 4950
    },
    {
      "epoch": 2.8342857142857145,
      "grad_norm": 0.020223606377840042,
      "learning_rate": 1.4331428571428572e-05,
      "loss": 0.0359,
      "step": 4960
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.020328037440776825,
      "learning_rate": 1.432e-05,
      "loss": 0.0269,
      "step": 4970
    },
    {
      "epoch": 2.8457142857142856,
      "grad_norm": 0.8542729616165161,
      "learning_rate": 1.430857142857143e-05,
      "loss": 0.0378,
      "step": 4980
    },
    {
      "epoch": 2.8514285714285714,
      "grad_norm": 0.10643985122442245,
      "learning_rate": 1.4297142857142859e-05,
      "loss": 0.06,
      "step": 4990
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 2.383668899536133,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.0113,
      "step": 5000
    },
    {
      "epoch": 2.862857142857143,
      "grad_norm": 0.004576988983899355,
      "learning_rate": 1.4274285714285716e-05,
      "loss": 0.0372,
      "step": 5010
    },
    {
      "epoch": 2.8685714285714283,
      "grad_norm": 0.018942203372716904,
      "learning_rate": 1.4262857142857146e-05,
      "loss": 0.042,
      "step": 5020
    },
    {
      "epoch": 2.8742857142857146,
      "grad_norm": 3.423698663711548,
      "learning_rate": 1.4251428571428572e-05,
      "loss": 0.1149,
      "step": 5030
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.004485734272748232,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 0.0339,
      "step": 5040
    },
    {
      "epoch": 2.8857142857142857,
      "grad_norm": 0.09535713493824005,
      "learning_rate": 1.422857142857143e-05,
      "loss": 0.0829,
      "step": 5050
    },
    {
      "epoch": 2.8914285714285715,
      "grad_norm": 27.12003517150879,
      "learning_rate": 1.4217142857142858e-05,
      "loss": 0.0544,
      "step": 5060
    },
    {
      "epoch": 2.8971428571428572,
      "grad_norm": 0.4910498857498169,
      "learning_rate": 1.4205714285714288e-05,
      "loss": 0.01,
      "step": 5070
    },
    {
      "epoch": 2.902857142857143,
      "grad_norm": 0.17769460380077362,
      "learning_rate": 1.4194285714285716e-05,
      "loss": 0.084,
      "step": 5080
    },
    {
      "epoch": 2.9085714285714284,
      "grad_norm": 0.09815753996372223,
      "learning_rate": 1.4182857142857145e-05,
      "loss": 0.1414,
      "step": 5090
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 0.012847624719142914,
      "learning_rate": 1.4171428571428572e-05,
      "loss": 0.0573,
      "step": 5100
    },
    {
      "epoch": 2.92,
      "grad_norm": 16.626802444458008,
      "learning_rate": 1.416e-05,
      "loss": 0.0805,
      "step": 5110
    },
    {
      "epoch": 2.9257142857142857,
      "grad_norm": 8.92701244354248,
      "learning_rate": 1.414857142857143e-05,
      "loss": 0.0147,
      "step": 5120
    },
    {
      "epoch": 2.9314285714285715,
      "grad_norm": 0.017171939834952354,
      "learning_rate": 1.4137142857142859e-05,
      "loss": 0.0631,
      "step": 5130
    },
    {
      "epoch": 2.9371428571428573,
      "grad_norm": 0.15937241911888123,
      "learning_rate": 1.4125714285714287e-05,
      "loss": 0.0093,
      "step": 5140
    },
    {
      "epoch": 2.942857142857143,
      "grad_norm": 0.08433365821838379,
      "learning_rate": 1.4114285714285715e-05,
      "loss": 0.0956,
      "step": 5150
    },
    {
      "epoch": 2.9485714285714284,
      "grad_norm": 15.782831192016602,
      "learning_rate": 1.4102857142857146e-05,
      "loss": 0.0379,
      "step": 5160
    },
    {
      "epoch": 2.954285714285714,
      "grad_norm": 0.012706063687801361,
      "learning_rate": 1.4091428571428574e-05,
      "loss": 0.0568,
      "step": 5170
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.01316079031676054,
      "learning_rate": 1.408e-05,
      "loss": 0.0006,
      "step": 5180
    },
    {
      "epoch": 2.9657142857142857,
      "grad_norm": 11.10400676727295,
      "learning_rate": 1.406857142857143e-05,
      "loss": 0.1524,
      "step": 5190
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 0.017039788886904716,
      "learning_rate": 1.4057142857142858e-05,
      "loss": 0.0625,
      "step": 5200
    },
    {
      "epoch": 2.977142857142857,
      "grad_norm": 17.25962257385254,
      "learning_rate": 1.4045714285714288e-05,
      "loss": 0.0263,
      "step": 5210
    },
    {
      "epoch": 2.982857142857143,
      "grad_norm": 17.454185485839844,
      "learning_rate": 1.4034285714285716e-05,
      "loss": 0.0298,
      "step": 5220
    },
    {
      "epoch": 2.9885714285714284,
      "grad_norm": 1.5870003700256348,
      "learning_rate": 1.4022857142857145e-05,
      "loss": 0.0612,
      "step": 5230
    },
    {
      "epoch": 2.994285714285714,
      "grad_norm": 0.12204102426767349,
      "learning_rate": 1.4011428571428573e-05,
      "loss": 0.0345,
      "step": 5240
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.0376577377319336,
      "learning_rate": 1.4e-05,
      "loss": 0.1123,
      "step": 5250
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9776069518716578,
      "eval_f1": 0.900445765230312,
      "eval_loss": 0.12484221160411835,
      "eval_precision": 0.8951255539143279,
      "eval_recall": 0.905829596412556,
      "eval_runtime": 50.6008,
      "eval_samples_per_second": 118.575,
      "eval_steps_per_second": 3.715,
      "step": 5250
    },
    {
      "epoch": 3.005714285714286,
      "grad_norm": 13.523513793945312,
      "learning_rate": 1.398857142857143e-05,
      "loss": 0.1077,
      "step": 5260
    },
    {
      "epoch": 3.0114285714285716,
      "grad_norm": 0.004191447980701923,
      "learning_rate": 1.3977142857142858e-05,
      "loss": 0.0015,
      "step": 5270
    },
    {
      "epoch": 3.0171428571428573,
      "grad_norm": 0.06290507316589355,
      "learning_rate": 1.3965714285714287e-05,
      "loss": 0.0684,
      "step": 5280
    },
    {
      "epoch": 3.0228571428571427,
      "grad_norm": 0.19032646715641022,
      "learning_rate": 1.3954285714285715e-05,
      "loss": 0.094,
      "step": 5290
    },
    {
      "epoch": 3.0285714285714285,
      "grad_norm": 0.11946101486682892,
      "learning_rate": 1.3942857142857145e-05,
      "loss": 0.0849,
      "step": 5300
    },
    {
      "epoch": 3.0342857142857143,
      "grad_norm": 0.0171208418905735,
      "learning_rate": 1.3931428571428574e-05,
      "loss": 0.0049,
      "step": 5310
    },
    {
      "epoch": 3.04,
      "grad_norm": 1.9034682512283325,
      "learning_rate": 1.392e-05,
      "loss": 0.0211,
      "step": 5320
    },
    {
      "epoch": 3.045714285714286,
      "grad_norm": 4.4676079750061035,
      "learning_rate": 1.3908571428571429e-05,
      "loss": 0.01,
      "step": 5330
    },
    {
      "epoch": 3.0514285714285716,
      "grad_norm": 3.4716389179229736,
      "learning_rate": 1.3897142857142857e-05,
      "loss": 0.0255,
      "step": 5340
    },
    {
      "epoch": 3.057142857142857,
      "grad_norm": 0.013800389133393764,
      "learning_rate": 1.3885714285714288e-05,
      "loss": 0.0012,
      "step": 5350
    },
    {
      "epoch": 3.0628571428571427,
      "grad_norm": 13.9834623336792,
      "learning_rate": 1.3874285714285716e-05,
      "loss": 0.1081,
      "step": 5360
    },
    {
      "epoch": 3.0685714285714285,
      "grad_norm": 0.008018811233341694,
      "learning_rate": 1.3862857142857144e-05,
      "loss": 0.0008,
      "step": 5370
    },
    {
      "epoch": 3.0742857142857143,
      "grad_norm": 0.007510231342166662,
      "learning_rate": 1.3851428571428573e-05,
      "loss": 0.0207,
      "step": 5380
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.008041121996939182,
      "learning_rate": 1.384e-05,
      "loss": 0.0193,
      "step": 5390
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 0.002261257031932473,
      "learning_rate": 1.382857142857143e-05,
      "loss": 0.0002,
      "step": 5400
    },
    {
      "epoch": 3.0914285714285716,
      "grad_norm": 0.013711312785744667,
      "learning_rate": 1.3817142857142858e-05,
      "loss": 0.0527,
      "step": 5410
    },
    {
      "epoch": 3.097142857142857,
      "grad_norm": 29.732894897460938,
      "learning_rate": 1.3805714285714287e-05,
      "loss": 0.0251,
      "step": 5420
    },
    {
      "epoch": 3.1028571428571428,
      "grad_norm": 0.015783386304974556,
      "learning_rate": 1.3794285714285715e-05,
      "loss": 0.0046,
      "step": 5430
    },
    {
      "epoch": 3.1085714285714285,
      "grad_norm": 0.07469258457422256,
      "learning_rate": 1.3782857142857145e-05,
      "loss": 0.0008,
      "step": 5440
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 13.270716667175293,
      "learning_rate": 1.3771428571428574e-05,
      "loss": 0.0506,
      "step": 5450
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.003187530906870961,
      "learning_rate": 1.376e-05,
      "loss": 0.0005,
      "step": 5460
    },
    {
      "epoch": 3.125714285714286,
      "grad_norm": 0.0053375777788460255,
      "learning_rate": 1.3748571428571429e-05,
      "loss": 0.1395,
      "step": 5470
    },
    {
      "epoch": 3.1314285714285712,
      "grad_norm": 0.019098902121186256,
      "learning_rate": 1.3737142857142857e-05,
      "loss": 0.0276,
      "step": 5480
    },
    {
      "epoch": 3.137142857142857,
      "grad_norm": 0.24537529051303864,
      "learning_rate": 1.3725714285714287e-05,
      "loss": 0.0026,
      "step": 5490
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 0.02020752802491188,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 0.0086,
      "step": 5500
    },
    {
      "epoch": 3.1485714285714286,
      "grad_norm": 0.013898659497499466,
      "learning_rate": 1.3702857142857144e-05,
      "loss": 0.0155,
      "step": 5510
    },
    {
      "epoch": 3.1542857142857144,
      "grad_norm": 0.0025598739739507437,
      "learning_rate": 1.3691428571428573e-05,
      "loss": 0.0204,
      "step": 5520
    },
    {
      "epoch": 3.16,
      "grad_norm": 10.62585163116455,
      "learning_rate": 1.3680000000000003e-05,
      "loss": 0.0085,
      "step": 5530
    },
    {
      "epoch": 3.1657142857142855,
      "grad_norm": 0.02681903913617134,
      "learning_rate": 1.366857142857143e-05,
      "loss": 0.0164,
      "step": 5540
    },
    {
      "epoch": 3.1714285714285713,
      "grad_norm": 0.015362300910055637,
      "learning_rate": 1.3657142857142858e-05,
      "loss": 0.0037,
      "step": 5550
    },
    {
      "epoch": 3.177142857142857,
      "grad_norm": 0.010775991715490818,
      "learning_rate": 1.3645714285714286e-05,
      "loss": 0.0001,
      "step": 5560
    },
    {
      "epoch": 3.182857142857143,
      "grad_norm": 8.080158233642578,
      "learning_rate": 1.3634285714285715e-05,
      "loss": 0.0029,
      "step": 5570
    },
    {
      "epoch": 3.1885714285714286,
      "grad_norm": 0.0028747599571943283,
      "learning_rate": 1.3622857142857145e-05,
      "loss": 0.0001,
      "step": 5580
    },
    {
      "epoch": 3.1942857142857144,
      "grad_norm": 22.477256774902344,
      "learning_rate": 1.3611428571428573e-05,
      "loss": 0.1209,
      "step": 5590
    },
    {
      "epoch": 3.2,
      "grad_norm": 25.22909164428711,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0785,
      "step": 5600
    },
    {
      "epoch": 3.2057142857142855,
      "grad_norm": 0.4433083236217499,
      "learning_rate": 1.3588571428571429e-05,
      "loss": 0.0006,
      "step": 5610
    },
    {
      "epoch": 3.2114285714285713,
      "grad_norm": 0.04682566225528717,
      "learning_rate": 1.3577142857142857e-05,
      "loss": 0.0579,
      "step": 5620
    },
    {
      "epoch": 3.217142857142857,
      "grad_norm": 0.014760473743081093,
      "learning_rate": 1.3565714285714287e-05,
      "loss": 0.0359,
      "step": 5630
    },
    {
      "epoch": 3.222857142857143,
      "grad_norm": 0.030271323397755623,
      "learning_rate": 1.3554285714285716e-05,
      "loss": 0.083,
      "step": 5640
    },
    {
      "epoch": 3.2285714285714286,
      "grad_norm": 0.008560171350836754,
      "learning_rate": 1.3542857142857144e-05,
      "loss": 0.0007,
      "step": 5650
    },
    {
      "epoch": 3.2342857142857144,
      "grad_norm": 0.009755466133356094,
      "learning_rate": 1.3531428571428573e-05,
      "loss": 0.001,
      "step": 5660
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.5718938112258911,
      "learning_rate": 1.3520000000000003e-05,
      "loss": 0.0025,
      "step": 5670
    },
    {
      "epoch": 3.2457142857142856,
      "grad_norm": 0.007998255081474781,
      "learning_rate": 1.350857142857143e-05,
      "loss": 0.0378,
      "step": 5680
    },
    {
      "epoch": 3.2514285714285713,
      "grad_norm": 0.008861154317855835,
      "learning_rate": 1.3497142857142858e-05,
      "loss": 0.0279,
      "step": 5690
    },
    {
      "epoch": 3.257142857142857,
      "grad_norm": 35.619712829589844,
      "learning_rate": 1.3485714285714286e-05,
      "loss": 0.0885,
      "step": 5700
    },
    {
      "epoch": 3.262857142857143,
      "grad_norm": 0.22836419939994812,
      "learning_rate": 1.3474285714285715e-05,
      "loss": 0.1515,
      "step": 5710
    },
    {
      "epoch": 3.2685714285714287,
      "grad_norm": 6.990297317504883,
      "learning_rate": 1.3462857142857145e-05,
      "loss": 0.1323,
      "step": 5720
    },
    {
      "epoch": 3.2742857142857145,
      "grad_norm": 0.05830158293247223,
      "learning_rate": 1.3451428571428573e-05,
      "loss": 0.0104,
      "step": 5730
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 24.025728225708008,
      "learning_rate": 1.3440000000000002e-05,
      "loss": 0.0196,
      "step": 5740
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 0.02140021324157715,
      "learning_rate": 1.3428571428571429e-05,
      "loss": 0.1419,
      "step": 5750
    },
    {
      "epoch": 3.2914285714285714,
      "grad_norm": 0.008433956652879715,
      "learning_rate": 1.3417142857142857e-05,
      "loss": 0.0369,
      "step": 5760
    },
    {
      "epoch": 3.297142857142857,
      "grad_norm": 0.7479490041732788,
      "learning_rate": 1.3405714285714287e-05,
      "loss": 0.0127,
      "step": 5770
    },
    {
      "epoch": 3.302857142857143,
      "grad_norm": 0.05139760673046112,
      "learning_rate": 1.3394285714285716e-05,
      "loss": 0.0249,
      "step": 5780
    },
    {
      "epoch": 3.3085714285714287,
      "grad_norm": 0.029348718002438545,
      "learning_rate": 1.3382857142857144e-05,
      "loss": 0.1353,
      "step": 5790
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 4.003983497619629,
      "learning_rate": 1.3371428571428572e-05,
      "loss": 0.0093,
      "step": 5800
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.012684901244938374,
      "learning_rate": 1.3360000000000003e-05,
      "loss": 0.0857,
      "step": 5810
    },
    {
      "epoch": 3.3257142857142856,
      "grad_norm": 0.11767894774675369,
      "learning_rate": 1.3348571428571431e-05,
      "loss": 0.0903,
      "step": 5820
    },
    {
      "epoch": 3.3314285714285714,
      "grad_norm": 0.00684618903324008,
      "learning_rate": 1.3337142857142858e-05,
      "loss": 0.0036,
      "step": 5830
    },
    {
      "epoch": 3.337142857142857,
      "grad_norm": 0.16522736847400665,
      "learning_rate": 1.3325714285714286e-05,
      "loss": 0.0628,
      "step": 5840
    },
    {
      "epoch": 3.342857142857143,
      "grad_norm": 0.006937237456440926,
      "learning_rate": 1.3314285714285715e-05,
      "loss": 0.059,
      "step": 5850
    },
    {
      "epoch": 3.3485714285714288,
      "grad_norm": 0.07748519629240036,
      "learning_rate": 1.3302857142857145e-05,
      "loss": 0.0433,
      "step": 5860
    },
    {
      "epoch": 3.354285714285714,
      "grad_norm": 0.019142288714647293,
      "learning_rate": 1.3291428571428573e-05,
      "loss": 0.0689,
      "step": 5870
    },
    {
      "epoch": 3.36,
      "grad_norm": 10.041999816894531,
      "learning_rate": 1.3280000000000002e-05,
      "loss": 0.0423,
      "step": 5880
    },
    {
      "epoch": 3.3657142857142857,
      "grad_norm": 27.31066131591797,
      "learning_rate": 1.326857142857143e-05,
      "loss": 0.0097,
      "step": 5890
    },
    {
      "epoch": 3.3714285714285714,
      "grad_norm": 0.0073881023563444614,
      "learning_rate": 1.3257142857142857e-05,
      "loss": 0.0003,
      "step": 5900
    },
    {
      "epoch": 3.3771428571428572,
      "grad_norm": 0.025641143321990967,
      "learning_rate": 1.3245714285714287e-05,
      "loss": 0.0533,
      "step": 5910
    },
    {
      "epoch": 3.382857142857143,
      "grad_norm": 0.013553507626056671,
      "learning_rate": 1.3234285714285715e-05,
      "loss": 0.0688,
      "step": 5920
    },
    {
      "epoch": 3.388571428571429,
      "grad_norm": 0.8614295721054077,
      "learning_rate": 1.3222857142857144e-05,
      "loss": 0.0042,
      "step": 5930
    },
    {
      "epoch": 3.394285714285714,
      "grad_norm": 0.008896732702851295,
      "learning_rate": 1.3211428571428572e-05,
      "loss": 0.0053,
      "step": 5940
    },
    {
      "epoch": 3.4,
      "grad_norm": 9.698267936706543,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.0399,
      "step": 5950
    },
    {
      "epoch": 3.4057142857142857,
      "grad_norm": 8.562102317810059,
      "learning_rate": 1.318857142857143e-05,
      "loss": 0.1435,
      "step": 5960
    },
    {
      "epoch": 3.4114285714285715,
      "grad_norm": 0.08585762977600098,
      "learning_rate": 1.3177142857142858e-05,
      "loss": 0.0178,
      "step": 5970
    },
    {
      "epoch": 3.4171428571428573,
      "grad_norm": 13.633259773254395,
      "learning_rate": 1.3165714285714286e-05,
      "loss": 0.0096,
      "step": 5980
    },
    {
      "epoch": 3.422857142857143,
      "grad_norm": 0.09912969172000885,
      "learning_rate": 1.3154285714285714e-05,
      "loss": 0.0009,
      "step": 5990
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.002677076030522585,
      "learning_rate": 1.3142857142857145e-05,
      "loss": 0.0037,
      "step": 6000
    },
    {
      "epoch": 3.434285714285714,
      "grad_norm": 0.005848506465554237,
      "learning_rate": 1.3131428571428573e-05,
      "loss": 0.0002,
      "step": 6010
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.005557463504374027,
      "learning_rate": 1.3120000000000001e-05,
      "loss": 0.0524,
      "step": 6020
    },
    {
      "epoch": 3.4457142857142857,
      "grad_norm": 0.6784379482269287,
      "learning_rate": 1.310857142857143e-05,
      "loss": 0.0423,
      "step": 6030
    },
    {
      "epoch": 3.4514285714285715,
      "grad_norm": 7.479450702667236,
      "learning_rate": 1.3097142857142857e-05,
      "loss": 0.0553,
      "step": 6040
    },
    {
      "epoch": 3.4571428571428573,
      "grad_norm": 0.01441545132547617,
      "learning_rate": 1.3085714285714287e-05,
      "loss": 0.0825,
      "step": 6050
    },
    {
      "epoch": 3.4628571428571426,
      "grad_norm": 3.6594223976135254,
      "learning_rate": 1.3074285714285715e-05,
      "loss": 0.0568,
      "step": 6060
    },
    {
      "epoch": 3.4685714285714284,
      "grad_norm": 13.064809799194336,
      "learning_rate": 1.3062857142857144e-05,
      "loss": 0.0638,
      "step": 6070
    },
    {
      "epoch": 3.474285714285714,
      "grad_norm": 22.204029083251953,
      "learning_rate": 1.3051428571428572e-05,
      "loss": 0.119,
      "step": 6080
    },
    {
      "epoch": 3.48,
      "grad_norm": 7.85912561416626,
      "learning_rate": 1.3040000000000002e-05,
      "loss": 0.0362,
      "step": 6090
    },
    {
      "epoch": 3.4857142857142858,
      "grad_norm": 0.015132183209061623,
      "learning_rate": 1.302857142857143e-05,
      "loss": 0.0219,
      "step": 6100
    },
    {
      "epoch": 3.4914285714285715,
      "grad_norm": 25.449357986450195,
      "learning_rate": 1.3017142857142859e-05,
      "loss": 0.1268,
      "step": 6110
    },
    {
      "epoch": 3.4971428571428573,
      "grad_norm": 0.1484631896018982,
      "learning_rate": 1.3005714285714286e-05,
      "loss": 0.0323,
      "step": 6120
    },
    {
      "epoch": 3.5028571428571427,
      "grad_norm": 19.33136558532715,
      "learning_rate": 1.2994285714285714e-05,
      "loss": 0.102,
      "step": 6130
    },
    {
      "epoch": 3.5085714285714285,
      "grad_norm": 0.06179029867053032,
      "learning_rate": 1.2982857142857144e-05,
      "loss": 0.0496,
      "step": 6140
    },
    {
      "epoch": 3.5142857142857142,
      "grad_norm": 15.324763298034668,
      "learning_rate": 1.2971428571428573e-05,
      "loss": 0.0438,
      "step": 6150
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.17552465200424194,
      "learning_rate": 1.2960000000000001e-05,
      "loss": 0.0257,
      "step": 6160
    },
    {
      "epoch": 3.525714285714286,
      "grad_norm": 0.004734042566269636,
      "learning_rate": 1.294857142857143e-05,
      "loss": 0.1135,
      "step": 6170
    },
    {
      "epoch": 3.5314285714285716,
      "grad_norm": 0.0814623087644577,
      "learning_rate": 1.293714285714286e-05,
      "loss": 0.0823,
      "step": 6180
    },
    {
      "epoch": 3.5371428571428574,
      "grad_norm": 0.022158334031701088,
      "learning_rate": 1.2925714285714287e-05,
      "loss": 0.0114,
      "step": 6190
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 0.015248989686369896,
      "learning_rate": 1.2914285714285715e-05,
      "loss": 0.0188,
      "step": 6200
    },
    {
      "epoch": 3.5485714285714285,
      "grad_norm": 0.354276180267334,
      "learning_rate": 1.2902857142857143e-05,
      "loss": 0.0501,
      "step": 6210
    },
    {
      "epoch": 3.5542857142857143,
      "grad_norm": 0.6225932836532593,
      "learning_rate": 1.2891428571428572e-05,
      "loss": 0.0454,
      "step": 6220
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.010374274104833603,
      "learning_rate": 1.2880000000000002e-05,
      "loss": 0.0609,
      "step": 6230
    },
    {
      "epoch": 3.565714285714286,
      "grad_norm": 12.700339317321777,
      "learning_rate": 1.286857142857143e-05,
      "loss": 0.0946,
      "step": 6240
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.016066156327724457,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 0.0006,
      "step": 6250
    },
    {
      "epoch": 3.5771428571428574,
      "grad_norm": 16.735061645507812,
      "learning_rate": 1.2845714285714286e-05,
      "loss": 0.0321,
      "step": 6260
    },
    {
      "epoch": 3.5828571428571427,
      "grad_norm": 0.2793700695037842,
      "learning_rate": 1.2834285714285714e-05,
      "loss": 0.0543,
      "step": 6270
    },
    {
      "epoch": 3.5885714285714285,
      "grad_norm": 0.0053908028639853,
      "learning_rate": 1.2822857142857144e-05,
      "loss": 0.0332,
      "step": 6280
    },
    {
      "epoch": 3.5942857142857143,
      "grad_norm": 0.03424635902047157,
      "learning_rate": 1.2811428571428573e-05,
      "loss": 0.0492,
      "step": 6290
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.5837801098823547,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.1075,
      "step": 6300
    },
    {
      "epoch": 3.605714285714286,
      "grad_norm": 23.429407119750977,
      "learning_rate": 1.278857142857143e-05,
      "loss": 0.0065,
      "step": 6310
    },
    {
      "epoch": 3.611428571428571,
      "grad_norm": 0.049021679908037186,
      "learning_rate": 1.277714285714286e-05,
      "loss": 0.0006,
      "step": 6320
    },
    {
      "epoch": 3.617142857142857,
      "grad_norm": 0.019865423440933228,
      "learning_rate": 1.2765714285714286e-05,
      "loss": 0.0339,
      "step": 6330
    },
    {
      "epoch": 3.6228571428571428,
      "grad_norm": 0.05370359495282173,
      "learning_rate": 1.2754285714285715e-05,
      "loss": 0.0608,
      "step": 6340
    },
    {
      "epoch": 3.6285714285714286,
      "grad_norm": 0.006853420287370682,
      "learning_rate": 1.2742857142857143e-05,
      "loss": 0.0319,
      "step": 6350
    },
    {
      "epoch": 3.6342857142857143,
      "grad_norm": 0.007717383559793234,
      "learning_rate": 1.2731428571428572e-05,
      "loss": 0.0009,
      "step": 6360
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.0872097983956337,
      "learning_rate": 1.2720000000000002e-05,
      "loss": 0.0205,
      "step": 6370
    },
    {
      "epoch": 3.645714285714286,
      "grad_norm": 0.00515176123008132,
      "learning_rate": 1.270857142857143e-05,
      "loss": 0.0085,
      "step": 6380
    },
    {
      "epoch": 3.6514285714285712,
      "grad_norm": 17.923343658447266,
      "learning_rate": 1.2697142857142859e-05,
      "loss": 0.0265,
      "step": 6390
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 0.0073020802810788155,
      "learning_rate": 1.2685714285714286e-05,
      "loss": 0.0433,
      "step": 6400
    },
    {
      "epoch": 3.662857142857143,
      "grad_norm": 0.013640910387039185,
      "learning_rate": 1.2674285714285714e-05,
      "loss": 0.0061,
      "step": 6410
    },
    {
      "epoch": 3.6685714285714286,
      "grad_norm": 0.005010916385799646,
      "learning_rate": 1.2662857142857144e-05,
      "loss": 0.0114,
      "step": 6420
    },
    {
      "epoch": 3.6742857142857144,
      "grad_norm": 0.003921089693903923,
      "learning_rate": 1.2651428571428573e-05,
      "loss": 0.0471,
      "step": 6430
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.01615147851407528,
      "learning_rate": 1.2640000000000001e-05,
      "loss": 0.0601,
      "step": 6440
    },
    {
      "epoch": 3.685714285714286,
      "grad_norm": 17.742958068847656,
      "learning_rate": 1.262857142857143e-05,
      "loss": 0.0926,
      "step": 6450
    },
    {
      "epoch": 3.6914285714285713,
      "grad_norm": 0.017428718507289886,
      "learning_rate": 1.261714285714286e-05,
      "loss": 0.0003,
      "step": 6460
    },
    {
      "epoch": 3.697142857142857,
      "grad_norm": 0.006333307828754187,
      "learning_rate": 1.2605714285714288e-05,
      "loss": 0.001,
      "step": 6470
    },
    {
      "epoch": 3.702857142857143,
      "grad_norm": 14.47925853729248,
      "learning_rate": 1.2594285714285715e-05,
      "loss": 0.0053,
      "step": 6480
    },
    {
      "epoch": 3.7085714285714286,
      "grad_norm": 0.07893694937229156,
      "learning_rate": 1.2582857142857143e-05,
      "loss": 0.0306,
      "step": 6490
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 9.771018028259277,
      "learning_rate": 1.2571428571428572e-05,
      "loss": 0.0576,
      "step": 6500
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.004117187112569809,
      "learning_rate": 1.2560000000000002e-05,
      "loss": 0.0948,
      "step": 6510
    },
    {
      "epoch": 3.725714285714286,
      "grad_norm": 0.12413325905799866,
      "learning_rate": 1.254857142857143e-05,
      "loss": 0.0503,
      "step": 6520
    },
    {
      "epoch": 3.7314285714285713,
      "grad_norm": 0.9206525683403015,
      "learning_rate": 1.2537142857142859e-05,
      "loss": 0.047,
      "step": 6530
    },
    {
      "epoch": 3.737142857142857,
      "grad_norm": 4.737766742706299,
      "learning_rate": 1.2525714285714287e-05,
      "loss": 0.0044,
      "step": 6540
    },
    {
      "epoch": 3.742857142857143,
      "grad_norm": 0.12811031937599182,
      "learning_rate": 1.2514285714285714e-05,
      "loss": 0.0515,
      "step": 6550
    },
    {
      "epoch": 3.7485714285714287,
      "grad_norm": 0.006080403458327055,
      "learning_rate": 1.2502857142857144e-05,
      "loss": 0.0121,
      "step": 6560
    },
    {
      "epoch": 3.7542857142857144,
      "grad_norm": 0.20296090841293335,
      "learning_rate": 1.2491428571428572e-05,
      "loss": 0.0003,
      "step": 6570
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.26187172532081604,
      "learning_rate": 1.248e-05,
      "loss": 0.0758,
      "step": 6580
    },
    {
      "epoch": 3.7657142857142856,
      "grad_norm": 0.4399998188018799,
      "learning_rate": 1.246857142857143e-05,
      "loss": 0.0689,
      "step": 6590
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 0.16045673191547394,
      "learning_rate": 1.245714285714286e-05,
      "loss": 0.0537,
      "step": 6600
    },
    {
      "epoch": 3.777142857142857,
      "grad_norm": 0.44557109475135803,
      "learning_rate": 1.2445714285714288e-05,
      "loss": 0.0008,
      "step": 6610
    },
    {
      "epoch": 3.782857142857143,
      "grad_norm": 10.841519355773926,
      "learning_rate": 1.2434285714285715e-05,
      "loss": 0.005,
      "step": 6620
    },
    {
      "epoch": 3.7885714285714287,
      "grad_norm": 16.39516830444336,
      "learning_rate": 1.2422857142857143e-05,
      "loss": 0.0327,
      "step": 6630
    },
    {
      "epoch": 3.7942857142857145,
      "grad_norm": 13.374393463134766,
      "learning_rate": 1.2411428571428571e-05,
      "loss": 0.0575,
      "step": 6640
    },
    {
      "epoch": 3.8,
      "grad_norm": 18.72001838684082,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.0375,
      "step": 6650
    },
    {
      "epoch": 3.8057142857142856,
      "grad_norm": 0.017404165118932724,
      "learning_rate": 1.238857142857143e-05,
      "loss": 0.0433,
      "step": 6660
    },
    {
      "epoch": 3.8114285714285714,
      "grad_norm": 0.6509811282157898,
      "learning_rate": 1.2377142857142858e-05,
      "loss": 0.0545,
      "step": 6670
    },
    {
      "epoch": 3.817142857142857,
      "grad_norm": 6.1911821365356445,
      "learning_rate": 1.2365714285714287e-05,
      "loss": 0.0026,
      "step": 6680
    },
    {
      "epoch": 3.822857142857143,
      "grad_norm": 0.0054299975745379925,
      "learning_rate": 1.2354285714285714e-05,
      "loss": 0.0235,
      "step": 6690
    },
    {
      "epoch": 3.8285714285714287,
      "grad_norm": 0.010950537398457527,
      "learning_rate": 1.2342857142857144e-05,
      "loss": 0.0143,
      "step": 6700
    },
    {
      "epoch": 3.8342857142857145,
      "grad_norm": 0.01192077249288559,
      "learning_rate": 1.2331428571428572e-05,
      "loss": 0.0006,
      "step": 6710
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.003793997224420309,
      "learning_rate": 1.232e-05,
      "loss": 0.0848,
      "step": 6720
    },
    {
      "epoch": 3.8457142857142856,
      "grad_norm": 0.00732443667948246,
      "learning_rate": 1.2308571428571429e-05,
      "loss": 0.0216,
      "step": 6730
    },
    {
      "epoch": 3.8514285714285714,
      "grad_norm": 0.003841312602162361,
      "learning_rate": 1.229714285714286e-05,
      "loss": 0.0425,
      "step": 6740
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 0.027800941839814186,
      "learning_rate": 1.2285714285714288e-05,
      "loss": 0.1328,
      "step": 6750
    },
    {
      "epoch": 3.862857142857143,
      "grad_norm": 0.030784597620368004,
      "learning_rate": 1.2274285714285716e-05,
      "loss": 0.0269,
      "step": 6760
    },
    {
      "epoch": 3.8685714285714283,
      "grad_norm": 0.00757237896323204,
      "learning_rate": 1.2262857142857143e-05,
      "loss": 0.0384,
      "step": 6770
    },
    {
      "epoch": 3.8742857142857146,
      "grad_norm": 0.004647586029022932,
      "learning_rate": 1.2251428571428571e-05,
      "loss": 0.0403,
      "step": 6780
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.0409814715385437,
      "learning_rate": 1.2240000000000001e-05,
      "loss": 0.0348,
      "step": 6790
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 0.043772343546152115,
      "learning_rate": 1.222857142857143e-05,
      "loss": 0.0536,
      "step": 6800
    },
    {
      "epoch": 3.8914285714285715,
      "grad_norm": 0.01377805881202221,
      "learning_rate": 1.2217142857142858e-05,
      "loss": 0.0239,
      "step": 6810
    },
    {
      "epoch": 3.8971428571428572,
      "grad_norm": 0.007440799847245216,
      "learning_rate": 1.2205714285714287e-05,
      "loss": 0.0327,
      "step": 6820
    },
    {
      "epoch": 3.902857142857143,
      "grad_norm": 0.0036327883135527372,
      "learning_rate": 1.2194285714285717e-05,
      "loss": 0.0114,
      "step": 6830
    },
    {
      "epoch": 3.9085714285714284,
      "grad_norm": 0.004358803853392601,
      "learning_rate": 1.2182857142857144e-05,
      "loss": 0.0265,
      "step": 6840
    },
    {
      "epoch": 3.914285714285714,
      "grad_norm": 0.03846686705946922,
      "learning_rate": 1.2171428571428572e-05,
      "loss": 0.0393,
      "step": 6850
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.9040679931640625,
      "learning_rate": 1.216e-05,
      "loss": 0.0216,
      "step": 6860
    },
    {
      "epoch": 3.9257142857142857,
      "grad_norm": 0.2950829565525055,
      "learning_rate": 1.2148571428571429e-05,
      "loss": 0.0799,
      "step": 6870
    },
    {
      "epoch": 3.9314285714285715,
      "grad_norm": 8.96077823638916,
      "learning_rate": 1.2137142857142859e-05,
      "loss": 0.0254,
      "step": 6880
    },
    {
      "epoch": 3.9371428571428573,
      "grad_norm": 0.006528472527861595,
      "learning_rate": 1.2125714285714287e-05,
      "loss": 0.0003,
      "step": 6890
    },
    {
      "epoch": 3.942857142857143,
      "grad_norm": 0.014523793943226337,
      "learning_rate": 1.2114285714285716e-05,
      "loss": 0.0115,
      "step": 6900
    },
    {
      "epoch": 3.9485714285714284,
      "grad_norm": 0.00665154866874218,
      "learning_rate": 1.2102857142857143e-05,
      "loss": 0.049,
      "step": 6910
    },
    {
      "epoch": 3.954285714285714,
      "grad_norm": 0.06933373957872391,
      "learning_rate": 1.2091428571428571e-05,
      "loss": 0.0627,
      "step": 6920
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.01729436032474041,
      "learning_rate": 1.2080000000000001e-05,
      "loss": 0.0097,
      "step": 6930
    },
    {
      "epoch": 3.9657142857142857,
      "grad_norm": 0.01686902530491352,
      "learning_rate": 1.206857142857143e-05,
      "loss": 0.0019,
      "step": 6940
    },
    {
      "epoch": 3.9714285714285715,
      "grad_norm": 0.025417596101760864,
      "learning_rate": 1.2057142857142858e-05,
      "loss": 0.0541,
      "step": 6950
    },
    {
      "epoch": 3.977142857142857,
      "grad_norm": 0.5846201181411743,
      "learning_rate": 1.2045714285714287e-05,
      "loss": 0.0423,
      "step": 6960
    },
    {
      "epoch": 3.982857142857143,
      "grad_norm": 0.003366820514202118,
      "learning_rate": 1.2034285714285717e-05,
      "loss": 0.0548,
      "step": 6970
    },
    {
      "epoch": 3.9885714285714284,
      "grad_norm": 0.5014052391052246,
      "learning_rate": 1.2022857142857143e-05,
      "loss": 0.0782,
      "step": 6980
    },
    {
      "epoch": 3.994285714285714,
      "grad_norm": 0.024397283792495728,
      "learning_rate": 1.2011428571428572e-05,
      "loss": 0.0286,
      "step": 6990
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.009023324586451054,
      "learning_rate": 1.2e-05,
      "loss": 0.0717,
      "step": 7000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9837901069518716,
      "eval_f1": 0.9276659209545116,
      "eval_loss": 0.08505218476057053,
      "eval_precision": 0.9255952380952381,
      "eval_recall": 0.929745889387145,
      "eval_runtime": 49.7815,
      "eval_samples_per_second": 120.527,
      "eval_steps_per_second": 3.777,
      "step": 7000
    },
    {
      "epoch": 4.005714285714285,
      "grad_norm": 0.017236672341823578,
      "learning_rate": 1.1988571428571429e-05,
      "loss": 0.0428,
      "step": 7010
    },
    {
      "epoch": 4.011428571428572,
      "grad_norm": 0.053284794092178345,
      "learning_rate": 1.1977142857142859e-05,
      "loss": 0.001,
      "step": 7020
    },
    {
      "epoch": 4.017142857142857,
      "grad_norm": 0.00895390659570694,
      "learning_rate": 1.1965714285714287e-05,
      "loss": 0.023,
      "step": 7030
    },
    {
      "epoch": 4.022857142857143,
      "grad_norm": 0.045661941170692444,
      "learning_rate": 1.1954285714285716e-05,
      "loss": 0.0202,
      "step": 7040
    },
    {
      "epoch": 4.0285714285714285,
      "grad_norm": 3.1139817237854004,
      "learning_rate": 1.1942857142857144e-05,
      "loss": 0.0642,
      "step": 7050
    },
    {
      "epoch": 4.034285714285715,
      "grad_norm": 0.004084039945155382,
      "learning_rate": 1.1931428571428571e-05,
      "loss": 0.0047,
      "step": 7060
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.004474484361708164,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.0002,
      "step": 7070
    },
    {
      "epoch": 4.045714285714285,
      "grad_norm": 0.05893857404589653,
      "learning_rate": 1.190857142857143e-05,
      "loss": 0.0009,
      "step": 7080
    },
    {
      "epoch": 4.051428571428572,
      "grad_norm": 13.081991195678711,
      "learning_rate": 1.1897142857142858e-05,
      "loss": 0.0043,
      "step": 7090
    },
    {
      "epoch": 4.057142857142857,
      "grad_norm": 11.07394027709961,
      "learning_rate": 1.1885714285714286e-05,
      "loss": 0.0139,
      "step": 7100
    },
    {
      "epoch": 4.062857142857143,
      "grad_norm": 0.008533024229109287,
      "learning_rate": 1.1874285714285717e-05,
      "loss": 0.0303,
      "step": 7110
    },
    {
      "epoch": 4.0685714285714285,
      "grad_norm": 0.9951138496398926,
      "learning_rate": 1.1862857142857145e-05,
      "loss": 0.0033,
      "step": 7120
    },
    {
      "epoch": 4.074285714285715,
      "grad_norm": 0.2429303526878357,
      "learning_rate": 1.1851428571428572e-05,
      "loss": 0.0591,
      "step": 7130
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.00768456282094121,
      "learning_rate": 1.184e-05,
      "loss": 0.0071,
      "step": 7140
    },
    {
      "epoch": 4.085714285714285,
      "grad_norm": 0.018901200965046883,
      "learning_rate": 1.1828571428571429e-05,
      "loss": 0.0016,
      "step": 7150
    },
    {
      "epoch": 4.091428571428572,
      "grad_norm": 0.08998765796422958,
      "learning_rate": 1.1817142857142859e-05,
      "loss": 0.0299,
      "step": 7160
    },
    {
      "epoch": 4.097142857142857,
      "grad_norm": 0.005405578296631575,
      "learning_rate": 1.1805714285714287e-05,
      "loss": 0.0003,
      "step": 7170
    },
    {
      "epoch": 4.102857142857143,
      "grad_norm": 0.009465877898037434,
      "learning_rate": 1.1794285714285716e-05,
      "loss": 0.0035,
      "step": 7180
    },
    {
      "epoch": 4.1085714285714285,
      "grad_norm": 0.0014122307766228914,
      "learning_rate": 1.1782857142857144e-05,
      "loss": 0.0002,
      "step": 7190
    },
    {
      "epoch": 4.114285714285714,
      "grad_norm": 0.008963657543063164,
      "learning_rate": 1.177142857142857e-05,
      "loss": 0.0003,
      "step": 7200
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.0031532635912299156,
      "learning_rate": 1.1760000000000001e-05,
      "loss": 0.0165,
      "step": 7210
    },
    {
      "epoch": 4.1257142857142854,
      "grad_norm": 2.481135129928589,
      "learning_rate": 1.174857142857143e-05,
      "loss": 0.0078,
      "step": 7220
    },
    {
      "epoch": 4.131428571428572,
      "grad_norm": 0.001996746752411127,
      "learning_rate": 1.1737142857142858e-05,
      "loss": 0.0002,
      "step": 7230
    },
    {
      "epoch": 4.137142857142857,
      "grad_norm": 0.003965634386986494,
      "learning_rate": 1.1725714285714286e-05,
      "loss": 0.0068,
      "step": 7240
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 0.009276931174099445,
      "learning_rate": 1.1714285714285716e-05,
      "loss": 0.0585,
      "step": 7250
    },
    {
      "epoch": 4.148571428571429,
      "grad_norm": 1.1855616569519043,
      "learning_rate": 1.1702857142857145e-05,
      "loss": 0.0307,
      "step": 7260
    },
    {
      "epoch": 4.154285714285714,
      "grad_norm": 0.009537624195218086,
      "learning_rate": 1.1691428571428572e-05,
      "loss": 0.0005,
      "step": 7270
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.000698931806255132,
      "learning_rate": 1.168e-05,
      "loss": 0.0248,
      "step": 7280
    },
    {
      "epoch": 4.1657142857142855,
      "grad_norm": 0.001541730365715921,
      "learning_rate": 1.1668571428571428e-05,
      "loss": 0.0484,
      "step": 7290
    },
    {
      "epoch": 4.171428571428572,
      "grad_norm": 0.012657002545893192,
      "learning_rate": 1.1657142857142859e-05,
      "loss": 0.0038,
      "step": 7300
    },
    {
      "epoch": 4.177142857142857,
      "grad_norm": 0.0006143355858512223,
      "learning_rate": 1.1645714285714287e-05,
      "loss": 0.0565,
      "step": 7310
    },
    {
      "epoch": 4.182857142857143,
      "grad_norm": 0.017482610419392586,
      "learning_rate": 1.1634285714285715e-05,
      "loss": 0.069,
      "step": 7320
    },
    {
      "epoch": 4.188571428571429,
      "grad_norm": 0.004832221660763025,
      "learning_rate": 1.1622857142857144e-05,
      "loss": 0.0405,
      "step": 7330
    },
    {
      "epoch": 4.194285714285714,
      "grad_norm": 0.03766680136322975,
      "learning_rate": 1.161142857142857e-05,
      "loss": 0.0004,
      "step": 7340
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.003893580287694931,
      "learning_rate": 1.16e-05,
      "loss": 0.0389,
      "step": 7350
    },
    {
      "epoch": 4.2057142857142855,
      "grad_norm": 0.002966122003272176,
      "learning_rate": 1.158857142857143e-05,
      "loss": 0.0017,
      "step": 7360
    },
    {
      "epoch": 4.211428571428572,
      "grad_norm": 0.002326128538697958,
      "learning_rate": 1.1577142857142858e-05,
      "loss": 0.0022,
      "step": 7370
    },
    {
      "epoch": 4.217142857142857,
      "grad_norm": 0.009566753171384335,
      "learning_rate": 1.1565714285714286e-05,
      "loss": 0.0003,
      "step": 7380
    },
    {
      "epoch": 4.222857142857142,
      "grad_norm": 0.013209698721766472,
      "learning_rate": 1.1554285714285716e-05,
      "loss": 0.0069,
      "step": 7390
    },
    {
      "epoch": 4.228571428571429,
      "grad_norm": 0.011248275637626648,
      "learning_rate": 1.1542857142857145e-05,
      "loss": 0.0004,
      "step": 7400
    },
    {
      "epoch": 4.234285714285714,
      "grad_norm": 0.6206898093223572,
      "learning_rate": 1.1531428571428573e-05,
      "loss": 0.0107,
      "step": 7410
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.003962869290262461,
      "learning_rate": 1.152e-05,
      "loss": 0.0724,
      "step": 7420
    },
    {
      "epoch": 4.2457142857142856,
      "grad_norm": 70.84168243408203,
      "learning_rate": 1.1508571428571428e-05,
      "loss": 0.0257,
      "step": 7430
    },
    {
      "epoch": 4.251428571428572,
      "grad_norm": 7.349556922912598,
      "learning_rate": 1.1497142857142858e-05,
      "loss": 0.1653,
      "step": 7440
    },
    {
      "epoch": 4.257142857142857,
      "grad_norm": 0.48855337500572205,
      "learning_rate": 1.1485714285714287e-05,
      "loss": 0.0041,
      "step": 7450
    },
    {
      "epoch": 4.2628571428571425,
      "grad_norm": 13.62399673461914,
      "learning_rate": 1.1474285714285715e-05,
      "loss": 0.036,
      "step": 7460
    },
    {
      "epoch": 4.268571428571429,
      "grad_norm": 0.0037822581361979246,
      "learning_rate": 1.1462857142857144e-05,
      "loss": 0.0039,
      "step": 7470
    },
    {
      "epoch": 4.274285714285714,
      "grad_norm": 0.017315121367573738,
      "learning_rate": 1.1451428571428574e-05,
      "loss": 0.0913,
      "step": 7480
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.00256366771645844,
      "learning_rate": 1.144e-05,
      "loss": 0.004,
      "step": 7490
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.01859952136874199,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0011,
      "step": 7500
    },
    {
      "epoch": 4.291428571428572,
      "grad_norm": 0.10855677723884583,
      "learning_rate": 1.1417142857142857e-05,
      "loss": 0.0102,
      "step": 7510
    },
    {
      "epoch": 4.297142857142857,
      "grad_norm": 8.107156753540039,
      "learning_rate": 1.1405714285714286e-05,
      "loss": 0.0788,
      "step": 7520
    },
    {
      "epoch": 4.3028571428571425,
      "grad_norm": 0.0697525143623352,
      "learning_rate": 1.1394285714285716e-05,
      "loss": 0.0103,
      "step": 7530
    },
    {
      "epoch": 4.308571428571429,
      "grad_norm": 0.06416866928339005,
      "learning_rate": 1.1382857142857144e-05,
      "loss": 0.005,
      "step": 7540
    },
    {
      "epoch": 4.314285714285714,
      "grad_norm": 0.18153727054595947,
      "learning_rate": 1.1371428571428573e-05,
      "loss": 0.0454,
      "step": 7550
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.002973129041492939,
      "learning_rate": 1.136e-05,
      "loss": 0.0002,
      "step": 7560
    },
    {
      "epoch": 4.325714285714286,
      "grad_norm": 0.004959505517035723,
      "learning_rate": 1.1348571428571428e-05,
      "loss": 0.035,
      "step": 7570
    },
    {
      "epoch": 4.331428571428571,
      "grad_norm": 0.008338197134435177,
      "learning_rate": 1.1337142857142858e-05,
      "loss": 0.0177,
      "step": 7580
    },
    {
      "epoch": 4.337142857142857,
      "grad_norm": 0.005289269145578146,
      "learning_rate": 1.1325714285714287e-05,
      "loss": 0.063,
      "step": 7590
    },
    {
      "epoch": 4.3428571428571425,
      "grad_norm": 0.007373800966888666,
      "learning_rate": 1.1314285714285715e-05,
      "loss": 0.0092,
      "step": 7600
    },
    {
      "epoch": 4.348571428571429,
      "grad_norm": 35.08815002441406,
      "learning_rate": 1.1302857142857144e-05,
      "loss": 0.018,
      "step": 7610
    },
    {
      "epoch": 4.354285714285714,
      "grad_norm": 0.006648022681474686,
      "learning_rate": 1.1291428571428574e-05,
      "loss": 0.0954,
      "step": 7620
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.009233195334672928,
      "learning_rate": 1.128e-05,
      "loss": 0.0388,
      "step": 7630
    },
    {
      "epoch": 4.365714285714286,
      "grad_norm": 0.013728005811572075,
      "learning_rate": 1.1268571428571429e-05,
      "loss": 0.0046,
      "step": 7640
    },
    {
      "epoch": 4.371428571428572,
      "grad_norm": 24.94577407836914,
      "learning_rate": 1.1257142857142857e-05,
      "loss": 0.0706,
      "step": 7650
    },
    {
      "epoch": 4.377142857142857,
      "grad_norm": 0.016366854310035706,
      "learning_rate": 1.1245714285714286e-05,
      "loss": 0.0156,
      "step": 7660
    },
    {
      "epoch": 4.382857142857143,
      "grad_norm": 0.2177046239376068,
      "learning_rate": 1.1234285714285716e-05,
      "loss": 0.0604,
      "step": 7670
    },
    {
      "epoch": 4.388571428571429,
      "grad_norm": 0.0785444974899292,
      "learning_rate": 1.1222857142857144e-05,
      "loss": 0.0187,
      "step": 7680
    },
    {
      "epoch": 4.394285714285714,
      "grad_norm": 0.014398880302906036,
      "learning_rate": 1.1211428571428573e-05,
      "loss": 0.0065,
      "step": 7690
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.0018655998865142465,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0006,
      "step": 7700
    },
    {
      "epoch": 4.405714285714286,
      "grad_norm": 0.003912643063813448,
      "learning_rate": 1.1188571428571428e-05,
      "loss": 0.0078,
      "step": 7710
    },
    {
      "epoch": 4.411428571428571,
      "grad_norm": 0.00870819017291069,
      "learning_rate": 1.1177142857142858e-05,
      "loss": 0.0333,
      "step": 7720
    },
    {
      "epoch": 4.417142857142857,
      "grad_norm": 13.840864181518555,
      "learning_rate": 1.1165714285714287e-05,
      "loss": 0.0536,
      "step": 7730
    },
    {
      "epoch": 4.422857142857143,
      "grad_norm": 0.005952517036348581,
      "learning_rate": 1.1154285714285715e-05,
      "loss": 0.0127,
      "step": 7740
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 0.004262067843228579,
      "learning_rate": 1.1142857142857143e-05,
      "loss": 0.0385,
      "step": 7750
    },
    {
      "epoch": 4.434285714285714,
      "grad_norm": 0.040404047816991806,
      "learning_rate": 1.1131428571428574e-05,
      "loss": 0.0014,
      "step": 7760
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.0250737015157938,
      "learning_rate": 1.1120000000000002e-05,
      "loss": 0.0472,
      "step": 7770
    },
    {
      "epoch": 4.445714285714286,
      "grad_norm": 0.0015200584894046187,
      "learning_rate": 1.1108571428571429e-05,
      "loss": 0.0019,
      "step": 7780
    },
    {
      "epoch": 4.451428571428571,
      "grad_norm": 0.003048684448003769,
      "learning_rate": 1.1097142857142857e-05,
      "loss": 0.0001,
      "step": 7790
    },
    {
      "epoch": 4.457142857142857,
      "grad_norm": 0.0021101627498865128,
      "learning_rate": 1.1085714285714286e-05,
      "loss": 0.0004,
      "step": 7800
    },
    {
      "epoch": 4.462857142857143,
      "grad_norm": 12.75442123413086,
      "learning_rate": 1.1074285714285716e-05,
      "loss": 0.0433,
      "step": 7810
    },
    {
      "epoch": 4.468571428571429,
      "grad_norm": 5.897566795349121,
      "learning_rate": 1.1062857142857144e-05,
      "loss": 0.0012,
      "step": 7820
    },
    {
      "epoch": 4.474285714285714,
      "grad_norm": 0.006680715829133987,
      "learning_rate": 1.1051428571428573e-05,
      "loss": 0.0501,
      "step": 7830
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.005660063587129116,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.0011,
      "step": 7840
    },
    {
      "epoch": 4.485714285714286,
      "grad_norm": 0.0032581216655671597,
      "learning_rate": 1.1028571428571428e-05,
      "loss": 0.0892,
      "step": 7850
    },
    {
      "epoch": 4.491428571428571,
      "grad_norm": 8.185003280639648,
      "learning_rate": 1.1017142857142858e-05,
      "loss": 0.0235,
      "step": 7860
    },
    {
      "epoch": 4.497142857142857,
      "grad_norm": 0.005295033100992441,
      "learning_rate": 1.1005714285714286e-05,
      "loss": 0.0077,
      "step": 7870
    },
    {
      "epoch": 4.502857142857143,
      "grad_norm": 0.006701272912323475,
      "learning_rate": 1.0994285714285715e-05,
      "loss": 0.004,
      "step": 7880
    },
    {
      "epoch": 4.508571428571429,
      "grad_norm": 0.00818231888115406,
      "learning_rate": 1.0982857142857143e-05,
      "loss": 0.0203,
      "step": 7890
    },
    {
      "epoch": 4.514285714285714,
      "grad_norm": 0.0644245445728302,
      "learning_rate": 1.0971428571428573e-05,
      "loss": 0.0013,
      "step": 7900
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.0014440088998526335,
      "learning_rate": 1.0960000000000002e-05,
      "loss": 0.0006,
      "step": 7910
    },
    {
      "epoch": 4.525714285714286,
      "grad_norm": 2.814831256866455,
      "learning_rate": 1.0948571428571429e-05,
      "loss": 0.0014,
      "step": 7920
    },
    {
      "epoch": 4.531428571428571,
      "grad_norm": 1.1948912143707275,
      "learning_rate": 1.0937142857142857e-05,
      "loss": 0.0019,
      "step": 7930
    },
    {
      "epoch": 4.537142857142857,
      "grad_norm": 0.0033551149535924196,
      "learning_rate": 1.0925714285714285e-05,
      "loss": 0.0521,
      "step": 7940
    },
    {
      "epoch": 4.542857142857143,
      "grad_norm": 0.005039380397647619,
      "learning_rate": 1.0914285714285716e-05,
      "loss": 0.0728,
      "step": 7950
    },
    {
      "epoch": 4.548571428571429,
      "grad_norm": 0.0026650114450603724,
      "learning_rate": 1.0902857142857144e-05,
      "loss": 0.089,
      "step": 7960
    },
    {
      "epoch": 4.554285714285714,
      "grad_norm": 0.005085660610347986,
      "learning_rate": 1.0891428571428572e-05,
      "loss": 0.0382,
      "step": 7970
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.3379459381103516,
      "learning_rate": 1.0880000000000001e-05,
      "loss": 0.0563,
      "step": 7980
    },
    {
      "epoch": 4.565714285714286,
      "grad_norm": 9.235734939575195,
      "learning_rate": 1.0868571428571431e-05,
      "loss": 0.0197,
      "step": 7990
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.658893346786499,
      "learning_rate": 1.0857142857142858e-05,
      "loss": 0.0009,
      "step": 8000
    },
    {
      "epoch": 4.577142857142857,
      "grad_norm": 0.10194969922304153,
      "learning_rate": 1.0845714285714286e-05,
      "loss": 0.0344,
      "step": 8010
    },
    {
      "epoch": 4.582857142857143,
      "grad_norm": 0.021065402776002884,
      "learning_rate": 1.0834285714285715e-05,
      "loss": 0.0019,
      "step": 8020
    },
    {
      "epoch": 4.588571428571429,
      "grad_norm": 0.02973177842795849,
      "learning_rate": 1.0822857142857143e-05,
      "loss": 0.0121,
      "step": 8030
    },
    {
      "epoch": 4.594285714285714,
      "grad_norm": 0.009140292182564735,
      "learning_rate": 1.0811428571428573e-05,
      "loss": 0.0004,
      "step": 8040
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.011302846483886242,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.0004,
      "step": 8050
    },
    {
      "epoch": 4.605714285714286,
      "grad_norm": 0.0016294632805511355,
      "learning_rate": 1.078857142857143e-05,
      "loss": 0.0083,
      "step": 8060
    },
    {
      "epoch": 4.611428571428571,
      "grad_norm": 0.046418145298957825,
      "learning_rate": 1.0777142857142857e-05,
      "loss": 0.0001,
      "step": 8070
    },
    {
      "epoch": 4.617142857142857,
      "grad_norm": 0.06495409458875656,
      "learning_rate": 1.0765714285714285e-05,
      "loss": 0.0403,
      "step": 8080
    },
    {
      "epoch": 4.622857142857143,
      "grad_norm": 0.001601900439709425,
      "learning_rate": 1.0754285714285715e-05,
      "loss": 0.0017,
      "step": 8090
    },
    {
      "epoch": 4.628571428571428,
      "grad_norm": 11.694145202636719,
      "learning_rate": 1.0742857142857144e-05,
      "loss": 0.0516,
      "step": 8100
    },
    {
      "epoch": 4.634285714285714,
      "grad_norm": 0.16358153522014618,
      "learning_rate": 1.0731428571428572e-05,
      "loss": 0.0002,
      "step": 8110
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.06196343153715134,
      "learning_rate": 1.072e-05,
      "loss": 0.0162,
      "step": 8120
    },
    {
      "epoch": 4.645714285714286,
      "grad_norm": 0.012991133145987988,
      "learning_rate": 1.070857142857143e-05,
      "loss": 0.0005,
      "step": 8130
    },
    {
      "epoch": 4.651428571428571,
      "grad_norm": 0.014183282852172852,
      "learning_rate": 1.0697142857142858e-05,
      "loss": 0.0405,
      "step": 8140
    },
    {
      "epoch": 4.6571428571428575,
      "grad_norm": 0.0015608348185196519,
      "learning_rate": 1.0685714285714286e-05,
      "loss": 0.0111,
      "step": 8150
    },
    {
      "epoch": 4.662857142857143,
      "grad_norm": 0.0032685366459190845,
      "learning_rate": 1.0674285714285714e-05,
      "loss": 0.0288,
      "step": 8160
    },
    {
      "epoch": 4.668571428571429,
      "grad_norm": 0.5894124507904053,
      "learning_rate": 1.0662857142857143e-05,
      "loss": 0.0006,
      "step": 8170
    },
    {
      "epoch": 4.674285714285714,
      "grad_norm": 2.5665628910064697,
      "learning_rate": 1.0651428571428573e-05,
      "loss": 0.0022,
      "step": 8180
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.02096310257911682,
      "learning_rate": 1.0640000000000001e-05,
      "loss": 0.0001,
      "step": 8190
    },
    {
      "epoch": 4.685714285714286,
      "grad_norm": 0.9102959036827087,
      "learning_rate": 1.062857142857143e-05,
      "loss": 0.0022,
      "step": 8200
    },
    {
      "epoch": 4.691428571428571,
      "grad_norm": 0.002252176869660616,
      "learning_rate": 1.0617142857142857e-05,
      "loss": 0.0014,
      "step": 8210
    },
    {
      "epoch": 4.6971428571428575,
      "grad_norm": 0.010140438564121723,
      "learning_rate": 1.0605714285714285e-05,
      "loss": 0.0001,
      "step": 8220
    },
    {
      "epoch": 4.702857142857143,
      "grad_norm": 8.828311920166016,
      "learning_rate": 1.0594285714285715e-05,
      "loss": 0.016,
      "step": 8230
    },
    {
      "epoch": 4.708571428571428,
      "grad_norm": 0.0017901337705552578,
      "learning_rate": 1.0582857142857144e-05,
      "loss": 0.04,
      "step": 8240
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 0.008335997350513935,
      "learning_rate": 1.0571428571428572e-05,
      "loss": 0.0574,
      "step": 8250
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.09694243967533112,
      "learning_rate": 1.056e-05,
      "loss": 0.0214,
      "step": 8260
    },
    {
      "epoch": 4.725714285714286,
      "grad_norm": 0.0016509585548192263,
      "learning_rate": 1.054857142857143e-05,
      "loss": 0.0614,
      "step": 8270
    },
    {
      "epoch": 4.731428571428571,
      "grad_norm": 0.0018422799184918404,
      "learning_rate": 1.0537142857142857e-05,
      "loss": 0.0044,
      "step": 8280
    },
    {
      "epoch": 4.737142857142857,
      "grad_norm": 9.371163368225098,
      "learning_rate": 1.0525714285714286e-05,
      "loss": 0.0794,
      "step": 8290
    },
    {
      "epoch": 4.742857142857143,
      "grad_norm": 26.725534439086914,
      "learning_rate": 1.0514285714285714e-05,
      "loss": 0.0666,
      "step": 8300
    },
    {
      "epoch": 4.748571428571428,
      "grad_norm": 0.9437032341957092,
      "learning_rate": 1.0502857142857143e-05,
      "loss": 0.0313,
      "step": 8310
    },
    {
      "epoch": 4.7542857142857144,
      "grad_norm": 0.01434609666466713,
      "learning_rate": 1.0491428571428573e-05,
      "loss": 0.1109,
      "step": 8320
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.004711437970399857,
      "learning_rate": 1.0480000000000001e-05,
      "loss": 0.0132,
      "step": 8330
    },
    {
      "epoch": 4.765714285714286,
      "grad_norm": 0.31409457325935364,
      "learning_rate": 1.046857142857143e-05,
      "loss": 0.0338,
      "step": 8340
    },
    {
      "epoch": 4.771428571428571,
      "grad_norm": 0.008019533008337021,
      "learning_rate": 1.045714285714286e-05,
      "loss": 0.0002,
      "step": 8350
    },
    {
      "epoch": 4.777142857142858,
      "grad_norm": 0.0015091145178303123,
      "learning_rate": 1.0445714285714285e-05,
      "loss": 0.035,
      "step": 8360
    },
    {
      "epoch": 4.782857142857143,
      "grad_norm": 0.01077459380030632,
      "learning_rate": 1.0434285714285715e-05,
      "loss": 0.0713,
      "step": 8370
    },
    {
      "epoch": 4.788571428571428,
      "grad_norm": 0.016006339341402054,
      "learning_rate": 1.0422857142857143e-05,
      "loss": 0.0308,
      "step": 8380
    },
    {
      "epoch": 4.7942857142857145,
      "grad_norm": 0.007864503189921379,
      "learning_rate": 1.0411428571428572e-05,
      "loss": 0.0381,
      "step": 8390
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.007502372842282057,
      "learning_rate": 1.04e-05,
      "loss": 0.0019,
      "step": 8400
    },
    {
      "epoch": 4.805714285714286,
      "grad_norm": 0.013993796892464161,
      "learning_rate": 1.038857142857143e-05,
      "loss": 0.0584,
      "step": 8410
    },
    {
      "epoch": 4.811428571428571,
      "grad_norm": 0.04034225642681122,
      "learning_rate": 1.0377142857142859e-05,
      "loss": 0.0402,
      "step": 8420
    },
    {
      "epoch": 4.817142857142857,
      "grad_norm": 0.028331642970442772,
      "learning_rate": 1.0365714285714286e-05,
      "loss": 0.0326,
      "step": 8430
    },
    {
      "epoch": 4.822857142857143,
      "grad_norm": 0.018759123980998993,
      "learning_rate": 1.0354285714285714e-05,
      "loss": 0.0094,
      "step": 8440
    },
    {
      "epoch": 4.828571428571428,
      "grad_norm": 0.08808553963899612,
      "learning_rate": 1.0342857142857143e-05,
      "loss": 0.0018,
      "step": 8450
    },
    {
      "epoch": 4.8342857142857145,
      "grad_norm": 0.004396137781441212,
      "learning_rate": 1.0331428571428573e-05,
      "loss": 0.0067,
      "step": 8460
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.005596006289124489,
      "learning_rate": 1.0320000000000001e-05,
      "loss": 0.0392,
      "step": 8470
    },
    {
      "epoch": 4.845714285714286,
      "grad_norm": 0.0049850246869027615,
      "learning_rate": 1.030857142857143e-05,
      "loss": 0.0549,
      "step": 8480
    },
    {
      "epoch": 4.851428571428571,
      "grad_norm": 0.010575513355433941,
      "learning_rate": 1.029714285714286e-05,
      "loss": 0.0721,
      "step": 8490
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.01720329560339451,
      "learning_rate": 1.0285714285714285e-05,
      "loss": 0.0011,
      "step": 8500
    },
    {
      "epoch": 4.862857142857143,
      "grad_norm": 0.005712926387786865,
      "learning_rate": 1.0274285714285715e-05,
      "loss": 0.0033,
      "step": 8510
    },
    {
      "epoch": 4.868571428571428,
      "grad_norm": 0.012093966826796532,
      "learning_rate": 1.0262857142857143e-05,
      "loss": 0.0556,
      "step": 8520
    },
    {
      "epoch": 4.8742857142857146,
      "grad_norm": 33.535728454589844,
      "learning_rate": 1.0251428571428572e-05,
      "loss": 0.0279,
      "step": 8530
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.016678227111697197,
      "learning_rate": 1.024e-05,
      "loss": 0.0001,
      "step": 8540
    },
    {
      "epoch": 4.885714285714286,
      "grad_norm": 0.006014314014464617,
      "learning_rate": 1.022857142857143e-05,
      "loss": 0.0006,
      "step": 8550
    },
    {
      "epoch": 4.8914285714285715,
      "grad_norm": 0.026078995317220688,
      "learning_rate": 1.0217142857142859e-05,
      "loss": 0.0029,
      "step": 8560
    },
    {
      "epoch": 4.897142857142857,
      "grad_norm": 0.001949630444869399,
      "learning_rate": 1.0205714285714286e-05,
      "loss": 0.0001,
      "step": 8570
    },
    {
      "epoch": 4.902857142857143,
      "grad_norm": 0.00579490140080452,
      "learning_rate": 1.0194285714285714e-05,
      "loss": 0.0026,
      "step": 8580
    },
    {
      "epoch": 4.908571428571428,
      "grad_norm": 0.013790366239845753,
      "learning_rate": 1.0182857142857142e-05,
      "loss": 0.0001,
      "step": 8590
    },
    {
      "epoch": 4.914285714285715,
      "grad_norm": 0.007265046704560518,
      "learning_rate": 1.0171428571428573e-05,
      "loss": 0.0215,
      "step": 8600
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.012194350361824036,
      "learning_rate": 1.0160000000000001e-05,
      "loss": 0.0561,
      "step": 8610
    },
    {
      "epoch": 4.925714285714285,
      "grad_norm": 0.03652258589863777,
      "learning_rate": 1.014857142857143e-05,
      "loss": 0.0111,
      "step": 8620
    },
    {
      "epoch": 4.9314285714285715,
      "grad_norm": 0.06613089889287949,
      "learning_rate": 1.013714285714286e-05,
      "loss": 0.0477,
      "step": 8630
    },
    {
      "epoch": 4.937142857142857,
      "grad_norm": 0.09755194932222366,
      "learning_rate": 1.0125714285714288e-05,
      "loss": 0.0344,
      "step": 8640
    },
    {
      "epoch": 4.942857142857143,
      "grad_norm": 0.016952043399214745,
      "learning_rate": 1.0114285714285715e-05,
      "loss": 0.0336,
      "step": 8650
    },
    {
      "epoch": 4.948571428571428,
      "grad_norm": 0.8214903473854065,
      "learning_rate": 1.0102857142857143e-05,
      "loss": 0.046,
      "step": 8660
    },
    {
      "epoch": 4.954285714285715,
      "grad_norm": 0.006890558172017336,
      "learning_rate": 1.0091428571428572e-05,
      "loss": 0.0004,
      "step": 8670
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.07616781443357468,
      "learning_rate": 1.008e-05,
      "loss": 0.019,
      "step": 8680
    },
    {
      "epoch": 4.965714285714286,
      "grad_norm": 0.002504839329048991,
      "learning_rate": 1.006857142857143e-05,
      "loss": 0.063,
      "step": 8690
    },
    {
      "epoch": 4.9714285714285715,
      "grad_norm": 0.004069856368005276,
      "learning_rate": 1.0057142857142859e-05,
      "loss": 0.0144,
      "step": 8700
    },
    {
      "epoch": 4.977142857142857,
      "grad_norm": 47.661563873291016,
      "learning_rate": 1.0045714285714287e-05,
      "loss": 0.0145,
      "step": 8710
    },
    {
      "epoch": 4.982857142857143,
      "grad_norm": 0.022743554785847664,
      "learning_rate": 1.0034285714285714e-05,
      "loss": 0.0113,
      "step": 8720
    },
    {
      "epoch": 4.988571428571428,
      "grad_norm": 0.039052337408065796,
      "learning_rate": 1.0022857142857142e-05,
      "loss": 0.0208,
      "step": 8730
    },
    {
      "epoch": 4.994285714285715,
      "grad_norm": 0.006086296401917934,
      "learning_rate": 1.0011428571428572e-05,
      "loss": 0.0017,
      "step": 8740
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0010589731391519308,
      "learning_rate": 1e-05,
      "loss": 0.0003,
      "step": 8750
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9844585561497327,
      "eval_f1": 0.9298113207547171,
      "eval_loss": 0.1112128496170044,
      "eval_precision": 0.9390243902439024,
      "eval_recall": 0.9207772795216741,
      "eval_runtime": 53.7233,
      "eval_samples_per_second": 111.683,
      "eval_steps_per_second": 3.499,
      "step": 8750
    },
    {
      "epoch": 5.005714285714285,
      "grad_norm": 0.008289883844554424,
      "learning_rate": 9.98857142857143e-06,
      "loss": 0.036,
      "step": 8760
    },
    {
      "epoch": 5.011428571428572,
      "grad_norm": 2.284797430038452,
      "learning_rate": 9.977142857142858e-06,
      "loss": 0.048,
      "step": 8770
    },
    {
      "epoch": 5.017142857142857,
      "grad_norm": 0.00154628767631948,
      "learning_rate": 9.965714285714286e-06,
      "loss": 0.0017,
      "step": 8780
    },
    {
      "epoch": 5.022857142857143,
      "grad_norm": 0.0037231585010886192,
      "learning_rate": 9.954285714285715e-06,
      "loss": 0.0522,
      "step": 8790
    },
    {
      "epoch": 5.0285714285714285,
      "grad_norm": 0.0052390024065971375,
      "learning_rate": 9.942857142857145e-06,
      "loss": 0.0001,
      "step": 8800
    },
    {
      "epoch": 5.034285714285715,
      "grad_norm": 160.6403350830078,
      "learning_rate": 9.931428571428571e-06,
      "loss": 0.0164,
      "step": 8810
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.3306199908256531,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.017,
      "step": 8820
    },
    {
      "epoch": 5.045714285714285,
      "grad_norm": 0.0015566167421638966,
      "learning_rate": 9.90857142857143e-06,
      "loss": 0.0005,
      "step": 8830
    },
    {
      "epoch": 5.051428571428572,
      "grad_norm": 0.001904499833472073,
      "learning_rate": 9.897142857142858e-06,
      "loss": 0.0,
      "step": 8840
    },
    {
      "epoch": 5.057142857142857,
      "grad_norm": 0.0020042425021529198,
      "learning_rate": 9.885714285714287e-06,
      "loss": 0.0248,
      "step": 8850
    },
    {
      "epoch": 5.062857142857143,
      "grad_norm": 0.1158037781715393,
      "learning_rate": 9.874285714285715e-06,
      "loss": 0.0361,
      "step": 8860
    },
    {
      "epoch": 5.0685714285714285,
      "grad_norm": 0.0007625868311151862,
      "learning_rate": 9.862857142857144e-06,
      "loss": 0.0461,
      "step": 8870
    },
    {
      "epoch": 5.074285714285715,
      "grad_norm": 31.545673370361328,
      "learning_rate": 9.851428571428572e-06,
      "loss": 0.0449,
      "step": 8880
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.003395630279555917,
      "learning_rate": 9.84e-06,
      "loss": 0.0604,
      "step": 8890
    },
    {
      "epoch": 5.085714285714285,
      "grad_norm": 0.0027067100163549185,
      "learning_rate": 9.828571428571429e-06,
      "loss": 0.0002,
      "step": 8900
    },
    {
      "epoch": 5.091428571428572,
      "grad_norm": 0.0029680903535336256,
      "learning_rate": 9.81714285714286e-06,
      "loss": 0.0001,
      "step": 8910
    },
    {
      "epoch": 5.097142857142857,
      "grad_norm": 16.94134521484375,
      "learning_rate": 9.805714285714286e-06,
      "loss": 0.032,
      "step": 8920
    },
    {
      "epoch": 5.102857142857143,
      "grad_norm": 0.005175453145056963,
      "learning_rate": 9.794285714285714e-06,
      "loss": 0.0001,
      "step": 8930
    },
    {
      "epoch": 5.1085714285714285,
      "grad_norm": 0.008631953038275242,
      "learning_rate": 9.782857142857145e-06,
      "loss": 0.0223,
      "step": 8940
    },
    {
      "epoch": 5.114285714285714,
      "grad_norm": 0.02174508571624756,
      "learning_rate": 9.771428571428571e-06,
      "loss": 0.0016,
      "step": 8950
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.005415596999228001,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.0374,
      "step": 8960
    },
    {
      "epoch": 5.1257142857142854,
      "grad_norm": 0.008414801210165024,
      "learning_rate": 9.74857142857143e-06,
      "loss": 0.0001,
      "step": 8970
    },
    {
      "epoch": 5.131428571428572,
      "grad_norm": 0.0027823045384138823,
      "learning_rate": 9.737142857142858e-06,
      "loss": 0.0079,
      "step": 8980
    },
    {
      "epoch": 5.137142857142857,
      "grad_norm": 0.0024412432685494423,
      "learning_rate": 9.725714285714287e-06,
      "loss": 0.059,
      "step": 8990
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.003388696350157261,
      "learning_rate": 9.714285714285715e-06,
      "loss": 0.001,
      "step": 9000
    },
    {
      "epoch": 5.148571428571429,
      "grad_norm": 0.0019662866834551096,
      "learning_rate": 9.702857142857144e-06,
      "loss": 0.0017,
      "step": 9010
    },
    {
      "epoch": 5.154285714285714,
      "grad_norm": 0.01635597087442875,
      "learning_rate": 9.691428571428572e-06,
      "loss": 0.0712,
      "step": 9020
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.0017267465591430664,
      "learning_rate": 9.68e-06,
      "loss": 0.0072,
      "step": 9030
    },
    {
      "epoch": 5.1657142857142855,
      "grad_norm": 0.022483214735984802,
      "learning_rate": 9.668571428571429e-06,
      "loss": 0.0634,
      "step": 9040
    },
    {
      "epoch": 5.171428571428572,
      "grad_norm": 0.012267949990928173,
      "learning_rate": 9.657142857142859e-06,
      "loss": 0.0365,
      "step": 9050
    },
    {
      "epoch": 5.177142857142857,
      "grad_norm": 8.47157096862793,
      "learning_rate": 9.645714285714286e-06,
      "loss": 0.055,
      "step": 9060
    },
    {
      "epoch": 5.182857142857143,
      "grad_norm": 0.003098106011748314,
      "learning_rate": 9.634285714285714e-06,
      "loss": 0.0002,
      "step": 9070
    },
    {
      "epoch": 5.188571428571429,
      "grad_norm": 0.005806002300232649,
      "learning_rate": 9.622857142857144e-06,
      "loss": 0.0001,
      "step": 9080
    },
    {
      "epoch": 5.194285714285714,
      "grad_norm": 0.0020366553217172623,
      "learning_rate": 9.611428571428573e-06,
      "loss": 0.0156,
      "step": 9090
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.014635509811341763,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0012,
      "step": 9100
    },
    {
      "epoch": 5.2057142857142855,
      "grad_norm": 23.382553100585938,
      "learning_rate": 9.58857142857143e-06,
      "loss": 0.0243,
      "step": 9110
    },
    {
      "epoch": 5.211428571428572,
      "grad_norm": 0.01295594871044159,
      "learning_rate": 9.577142857142858e-06,
      "loss": 0.0236,
      "step": 9120
    },
    {
      "epoch": 5.217142857142857,
      "grad_norm": 0.00624161958694458,
      "learning_rate": 9.565714285714287e-06,
      "loss": 0.0219,
      "step": 9130
    },
    {
      "epoch": 5.222857142857142,
      "grad_norm": 0.010508115403354168,
      "learning_rate": 9.554285714285715e-06,
      "loss": 0.0888,
      "step": 9140
    },
    {
      "epoch": 5.228571428571429,
      "grad_norm": 0.00503057986497879,
      "learning_rate": 9.542857142857143e-06,
      "loss": 0.0004,
      "step": 9150
    },
    {
      "epoch": 5.234285714285714,
      "grad_norm": 0.0018369491444900632,
      "learning_rate": 9.531428571428572e-06,
      "loss": 0.0617,
      "step": 9160
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.023775095120072365,
      "learning_rate": 9.52e-06,
      "loss": 0.0344,
      "step": 9170
    },
    {
      "epoch": 5.2457142857142856,
      "grad_norm": 0.0026753840502351522,
      "learning_rate": 9.508571428571429e-06,
      "loss": 0.0046,
      "step": 9180
    },
    {
      "epoch": 5.251428571428572,
      "grad_norm": 120.43689727783203,
      "learning_rate": 9.497142857142859e-06,
      "loss": 0.0277,
      "step": 9190
    },
    {
      "epoch": 5.257142857142857,
      "grad_norm": 0.747163712978363,
      "learning_rate": 9.485714285714287e-06,
      "loss": 0.0405,
      "step": 9200
    },
    {
      "epoch": 5.2628571428571425,
      "grad_norm": 0.038473330438137054,
      "learning_rate": 9.474285714285714e-06,
      "loss": 0.0036,
      "step": 9210
    },
    {
      "epoch": 5.268571428571429,
      "grad_norm": 0.019548004493117332,
      "learning_rate": 9.462857142857144e-06,
      "loss": 0.0384,
      "step": 9220
    },
    {
      "epoch": 5.274285714285714,
      "grad_norm": 0.013723204843699932,
      "learning_rate": 9.451428571428573e-06,
      "loss": 0.0037,
      "step": 9230
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.019741201773285866,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.0002,
      "step": 9240
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 0.0025438889861106873,
      "learning_rate": 9.42857142857143e-06,
      "loss": 0.0518,
      "step": 9250
    },
    {
      "epoch": 5.291428571428572,
      "grad_norm": 0.058305658400058746,
      "learning_rate": 9.417142857142858e-06,
      "loss": 0.0002,
      "step": 9260
    },
    {
      "epoch": 5.297142857142857,
      "grad_norm": 0.00356309674680233,
      "learning_rate": 9.405714285714286e-06,
      "loss": 0.0019,
      "step": 9270
    },
    {
      "epoch": 5.3028571428571425,
      "grad_norm": 0.013892189599573612,
      "learning_rate": 9.394285714285715e-06,
      "loss": 0.0044,
      "step": 9280
    },
    {
      "epoch": 5.308571428571429,
      "grad_norm": 0.00046516500879079103,
      "learning_rate": 9.382857142857143e-06,
      "loss": 0.0324,
      "step": 9290
    },
    {
      "epoch": 5.314285714285714,
      "grad_norm": 0.005617102608084679,
      "learning_rate": 9.371428571428572e-06,
      "loss": 0.0001,
      "step": 9300
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.5573310852050781,
      "learning_rate": 9.360000000000002e-06,
      "loss": 0.0005,
      "step": 9310
    },
    {
      "epoch": 5.325714285714286,
      "grad_norm": 0.03242035210132599,
      "learning_rate": 9.348571428571429e-06,
      "loss": 0.0589,
      "step": 9320
    },
    {
      "epoch": 5.331428571428571,
      "grad_norm": 0.0011389676947146654,
      "learning_rate": 9.337142857142859e-06,
      "loss": 0.0002,
      "step": 9330
    },
    {
      "epoch": 5.337142857142857,
      "grad_norm": 0.004020943306386471,
      "learning_rate": 9.325714285714287e-06,
      "loss": 0.062,
      "step": 9340
    },
    {
      "epoch": 5.3428571428571425,
      "grad_norm": 39.78178405761719,
      "learning_rate": 9.314285714285714e-06,
      "loss": 0.0293,
      "step": 9350
    },
    {
      "epoch": 5.348571428571429,
      "grad_norm": 0.021964047104120255,
      "learning_rate": 9.302857142857144e-06,
      "loss": 0.0001,
      "step": 9360
    },
    {
      "epoch": 5.354285714285714,
      "grad_norm": 0.012667108327150345,
      "learning_rate": 9.291428571428572e-06,
      "loss": 0.0567,
      "step": 9370
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.10122279077768326,
      "learning_rate": 9.280000000000001e-06,
      "loss": 0.0004,
      "step": 9380
    },
    {
      "epoch": 5.365714285714286,
      "grad_norm": 0.008849014528095722,
      "learning_rate": 9.26857142857143e-06,
      "loss": 0.0198,
      "step": 9390
    },
    {
      "epoch": 5.371428571428572,
      "grad_norm": 0.010800046846270561,
      "learning_rate": 9.257142857142858e-06,
      "loss": 0.001,
      "step": 9400
    },
    {
      "epoch": 5.377142857142857,
      "grad_norm": 4.711390972137451,
      "learning_rate": 9.245714285714286e-06,
      "loss": 0.0022,
      "step": 9410
    },
    {
      "epoch": 5.382857142857143,
      "grad_norm": 13.873215675354004,
      "learning_rate": 9.234285714285715e-06,
      "loss": 0.0489,
      "step": 9420
    },
    {
      "epoch": 5.388571428571429,
      "grad_norm": 0.0037612018641084433,
      "learning_rate": 9.222857142857143e-06,
      "loss": 0.0205,
      "step": 9430
    },
    {
      "epoch": 5.394285714285714,
      "grad_norm": 0.007211725227534771,
      "learning_rate": 9.211428571428572e-06,
      "loss": 0.0008,
      "step": 9440
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.2954531908035278,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0005,
      "step": 9450
    },
    {
      "epoch": 5.405714285714286,
      "grad_norm": 10.360432624816895,
      "learning_rate": 9.188571428571428e-06,
      "loss": 0.0367,
      "step": 9460
    },
    {
      "epoch": 5.411428571428571,
      "grad_norm": 14.373661994934082,
      "learning_rate": 9.177142857142859e-06,
      "loss": 0.0567,
      "step": 9470
    },
    {
      "epoch": 5.417142857142857,
      "grad_norm": 0.0010221166303381324,
      "learning_rate": 9.165714285714287e-06,
      "loss": 0.0,
      "step": 9480
    },
    {
      "epoch": 5.422857142857143,
      "grad_norm": 0.025019677355885506,
      "learning_rate": 9.154285714285715e-06,
      "loss": 0.0013,
      "step": 9490
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 22.4100341796875,
      "learning_rate": 9.142857142857144e-06,
      "loss": 0.0218,
      "step": 9500
    },
    {
      "epoch": 5.434285714285714,
      "grad_norm": 0.003607033984735608,
      "learning_rate": 9.131428571428572e-06,
      "loss": 0.0541,
      "step": 9510
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.006172888446599245,
      "learning_rate": 9.12e-06,
      "loss": 0.0074,
      "step": 9520
    },
    {
      "epoch": 5.445714285714286,
      "grad_norm": 0.00429408997297287,
      "learning_rate": 9.10857142857143e-06,
      "loss": 0.0119,
      "step": 9530
    },
    {
      "epoch": 5.451428571428571,
      "grad_norm": 0.00828656554222107,
      "learning_rate": 9.097142857142858e-06,
      "loss": 0.0478,
      "step": 9540
    },
    {
      "epoch": 5.457142857142857,
      "grad_norm": 0.0021763623226433992,
      "learning_rate": 9.085714285714286e-06,
      "loss": 0.0007,
      "step": 9550
    },
    {
      "epoch": 5.462857142857143,
      "grad_norm": 0.0045079514384269714,
      "learning_rate": 9.074285714285716e-06,
      "loss": 0.0045,
      "step": 9560
    },
    {
      "epoch": 5.468571428571429,
      "grad_norm": 0.03625020757317543,
      "learning_rate": 9.062857142857143e-06,
      "loss": 0.0001,
      "step": 9570
    },
    {
      "epoch": 5.474285714285714,
      "grad_norm": 0.0020154693629592657,
      "learning_rate": 9.051428571428571e-06,
      "loss": 0.0221,
      "step": 9580
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.06015852093696594,
      "learning_rate": 9.040000000000002e-06,
      "loss": 0.0001,
      "step": 9590
    },
    {
      "epoch": 5.485714285714286,
      "grad_norm": 0.020259253680706024,
      "learning_rate": 9.028571428571428e-06,
      "loss": 0.0002,
      "step": 9600
    },
    {
      "epoch": 5.491428571428571,
      "grad_norm": 0.018560850992798805,
      "learning_rate": 9.017142857142858e-06,
      "loss": 0.0639,
      "step": 9610
    },
    {
      "epoch": 5.497142857142857,
      "grad_norm": 0.0719107985496521,
      "learning_rate": 9.005714285714287e-06,
      "loss": 0.0502,
      "step": 9620
    },
    {
      "epoch": 5.502857142857143,
      "grad_norm": 0.04864463210105896,
      "learning_rate": 8.994285714285715e-06,
      "loss": 0.0418,
      "step": 9630
    },
    {
      "epoch": 5.508571428571429,
      "grad_norm": 0.004002237692475319,
      "learning_rate": 8.982857142857144e-06,
      "loss": 0.0001,
      "step": 9640
    },
    {
      "epoch": 5.514285714285714,
      "grad_norm": 0.0015042218146845698,
      "learning_rate": 8.971428571428572e-06,
      "loss": 0.0002,
      "step": 9650
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.006272161845117807,
      "learning_rate": 8.96e-06,
      "loss": 0.015,
      "step": 9660
    },
    {
      "epoch": 5.525714285714286,
      "grad_norm": 0.0021323547698557377,
      "learning_rate": 8.948571428571429e-06,
      "loss": 0.031,
      "step": 9670
    },
    {
      "epoch": 5.531428571428571,
      "grad_norm": 0.010629153810441494,
      "learning_rate": 8.937142857142857e-06,
      "loss": 0.0178,
      "step": 9680
    },
    {
      "epoch": 5.537142857142857,
      "grad_norm": 0.008924302645027637,
      "learning_rate": 8.925714285714286e-06,
      "loss": 0.0002,
      "step": 9690
    },
    {
      "epoch": 5.542857142857143,
      "grad_norm": 0.01499198842793703,
      "learning_rate": 8.914285714285716e-06,
      "loss": 0.0001,
      "step": 9700
    },
    {
      "epoch": 5.548571428571429,
      "grad_norm": 0.0038181976415216923,
      "learning_rate": 8.902857142857143e-06,
      "loss": 0.0296,
      "step": 9710
    },
    {
      "epoch": 5.554285714285714,
      "grad_norm": 0.0009383814758621156,
      "learning_rate": 8.891428571428571e-06,
      "loss": 0.0004,
      "step": 9720
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 0.0008425230626016855,
      "learning_rate": 8.880000000000001e-06,
      "loss": 0.0327,
      "step": 9730
    },
    {
      "epoch": 5.565714285714286,
      "grad_norm": 0.009121245704591274,
      "learning_rate": 8.86857142857143e-06,
      "loss": 0.0028,
      "step": 9740
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 0.0592859648168087,
      "learning_rate": 8.857142857142858e-06,
      "loss": 0.0236,
      "step": 9750
    },
    {
      "epoch": 5.577142857142857,
      "grad_norm": 0.011137171648442745,
      "learning_rate": 8.845714285714287e-06,
      "loss": 0.1132,
      "step": 9760
    },
    {
      "epoch": 5.582857142857143,
      "grad_norm": 0.01994512230157852,
      "learning_rate": 8.834285714285715e-06,
      "loss": 0.0021,
      "step": 9770
    },
    {
      "epoch": 5.588571428571429,
      "grad_norm": 0.02595118246972561,
      "learning_rate": 8.822857142857144e-06,
      "loss": 0.0001,
      "step": 9780
    },
    {
      "epoch": 5.594285714285714,
      "grad_norm": 0.004339469131082296,
      "learning_rate": 8.811428571428572e-06,
      "loss": 0.0072,
      "step": 9790
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.008873030543327332,
      "learning_rate": 8.8e-06,
      "loss": 0.0175,
      "step": 9800
    },
    {
      "epoch": 5.605714285714286,
      "grad_norm": 0.008529807440936565,
      "learning_rate": 8.788571428571429e-06,
      "loss": 0.0492,
      "step": 9810
    },
    {
      "epoch": 5.611428571428571,
      "grad_norm": 0.04154258221387863,
      "learning_rate": 8.777142857142857e-06,
      "loss": 0.0032,
      "step": 9820
    },
    {
      "epoch": 5.617142857142857,
      "grad_norm": 0.006950041279196739,
      "learning_rate": 8.765714285714286e-06,
      "loss": 0.001,
      "step": 9830
    },
    {
      "epoch": 5.622857142857143,
      "grad_norm": 0.004421605728566647,
      "learning_rate": 8.754285714285716e-06,
      "loss": 0.0034,
      "step": 9840
    },
    {
      "epoch": 5.628571428571428,
      "grad_norm": 9.497464179992676,
      "learning_rate": 8.742857142857144e-06,
      "loss": 0.0309,
      "step": 9850
    },
    {
      "epoch": 5.634285714285714,
      "grad_norm": 0.0059677050448954105,
      "learning_rate": 8.731428571428571e-06,
      "loss": 0.0156,
      "step": 9860
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.002481728559359908,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.0009,
      "step": 9870
    },
    {
      "epoch": 5.645714285714286,
      "grad_norm": 25.221439361572266,
      "learning_rate": 8.70857142857143e-06,
      "loss": 0.0114,
      "step": 9880
    },
    {
      "epoch": 5.651428571428571,
      "grad_norm": 0.01281105075031519,
      "learning_rate": 8.697142857142858e-06,
      "loss": 0.0001,
      "step": 9890
    },
    {
      "epoch": 5.6571428571428575,
      "grad_norm": 0.005565630737692118,
      "learning_rate": 8.685714285714287e-06,
      "loss": 0.0,
      "step": 9900
    },
    {
      "epoch": 5.662857142857143,
      "grad_norm": 0.0009264372056350112,
      "learning_rate": 8.674285714285715e-06,
      "loss": 0.0001,
      "step": 9910
    },
    {
      "epoch": 5.668571428571429,
      "grad_norm": 0.003210331778973341,
      "learning_rate": 8.662857142857143e-06,
      "loss": 0.0002,
      "step": 9920
    },
    {
      "epoch": 5.674285714285714,
      "grad_norm": 0.016161803156137466,
      "learning_rate": 8.651428571428572e-06,
      "loss": 0.0703,
      "step": 9930
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.002687364351004362,
      "learning_rate": 8.64e-06,
      "loss": 0.0007,
      "step": 9940
    },
    {
      "epoch": 5.685714285714286,
      "grad_norm": 0.003451243042945862,
      "learning_rate": 8.628571428571429e-06,
      "loss": 0.0001,
      "step": 9950
    },
    {
      "epoch": 5.691428571428571,
      "grad_norm": 0.02002955600619316,
      "learning_rate": 8.617142857142859e-06,
      "loss": 0.0001,
      "step": 9960
    },
    {
      "epoch": 5.6971428571428575,
      "grad_norm": 0.00822405144572258,
      "learning_rate": 8.605714285714286e-06,
      "loss": 0.0022,
      "step": 9970
    },
    {
      "epoch": 5.702857142857143,
      "grad_norm": 0.010240172035992146,
      "learning_rate": 8.594285714285716e-06,
      "loss": 0.0001,
      "step": 9980
    },
    {
      "epoch": 5.708571428571428,
      "grad_norm": 0.0009171759593300521,
      "learning_rate": 8.582857142857144e-06,
      "loss": 0.0,
      "step": 9990
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.00031165932887233794,
      "learning_rate": 8.571428571428571e-06,
      "loss": 0.0,
      "step": 10000
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.2248794436454773,
      "learning_rate": 8.560000000000001e-06,
      "loss": 0.0013,
      "step": 10010
    },
    {
      "epoch": 5.725714285714286,
      "grad_norm": 0.0002998215495608747,
      "learning_rate": 8.54857142857143e-06,
      "loss": 0.0016,
      "step": 10020
    },
    {
      "epoch": 5.731428571428571,
      "grad_norm": 18.450973510742188,
      "learning_rate": 8.537142857142858e-06,
      "loss": 0.0335,
      "step": 10030
    },
    {
      "epoch": 5.737142857142857,
      "grad_norm": 0.0013628890737891197,
      "learning_rate": 8.525714285714286e-06,
      "loss": 0.0782,
      "step": 10040
    },
    {
      "epoch": 5.742857142857143,
      "grad_norm": 0.0013736550463363528,
      "learning_rate": 8.514285714285715e-06,
      "loss": 0.0,
      "step": 10050
    },
    {
      "epoch": 5.748571428571428,
      "grad_norm": 0.5063876509666443,
      "learning_rate": 8.502857142857143e-06,
      "loss": 0.0002,
      "step": 10060
    },
    {
      "epoch": 5.7542857142857144,
      "grad_norm": 0.002198252361267805,
      "learning_rate": 8.491428571428572e-06,
      "loss": 0.0334,
      "step": 10070
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.006487075239419937,
      "learning_rate": 8.48e-06,
      "loss": 0.0001,
      "step": 10080
    },
    {
      "epoch": 5.765714285714286,
      "grad_norm": 0.04070465639233589,
      "learning_rate": 8.468571428571429e-06,
      "loss": 0.0546,
      "step": 10090
    },
    {
      "epoch": 5.771428571428571,
      "grad_norm": 0.0021273999009281397,
      "learning_rate": 8.457142857142859e-06,
      "loss": 0.0029,
      "step": 10100
    },
    {
      "epoch": 5.777142857142858,
      "grad_norm": 0.002725309459492564,
      "learning_rate": 8.445714285714285e-06,
      "loss": 0.0736,
      "step": 10110
    },
    {
      "epoch": 5.782857142857143,
      "grad_norm": 0.006460890639573336,
      "learning_rate": 8.434285714285716e-06,
      "loss": 0.0022,
      "step": 10120
    },
    {
      "epoch": 5.788571428571428,
      "grad_norm": 0.0006091670948080719,
      "learning_rate": 8.422857142857144e-06,
      "loss": 0.0001,
      "step": 10130
    },
    {
      "epoch": 5.7942857142857145,
      "grad_norm": 0.13485603034496307,
      "learning_rate": 8.411428571428572e-06,
      "loss": 0.0163,
      "step": 10140
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.022359760478138924,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0441,
      "step": 10150
    },
    {
      "epoch": 5.805714285714286,
      "grad_norm": 0.003055682871490717,
      "learning_rate": 8.38857142857143e-06,
      "loss": 0.0006,
      "step": 10160
    },
    {
      "epoch": 5.811428571428571,
      "grad_norm": 0.0022202394902706146,
      "learning_rate": 8.377142857142858e-06,
      "loss": 0.0002,
      "step": 10170
    },
    {
      "epoch": 5.817142857142857,
      "grad_norm": 0.0028217420913279057,
      "learning_rate": 8.365714285714286e-06,
      "loss": 0.0347,
      "step": 10180
    },
    {
      "epoch": 5.822857142857143,
      "grad_norm": 0.003407893469557166,
      "learning_rate": 8.354285714285715e-06,
      "loss": 0.0003,
      "step": 10190
    },
    {
      "epoch": 5.828571428571428,
      "grad_norm": 0.0011448994046077132,
      "learning_rate": 8.342857142857143e-06,
      "loss": 0.0203,
      "step": 10200
    },
    {
      "epoch": 5.8342857142857145,
      "grad_norm": 0.03288350999355316,
      "learning_rate": 8.331428571428573e-06,
      "loss": 0.0108,
      "step": 10210
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.007865364663302898,
      "learning_rate": 8.32e-06,
      "loss": 0.0001,
      "step": 10220
    },
    {
      "epoch": 5.845714285714286,
      "grad_norm": 0.0034764346200972795,
      "learning_rate": 8.308571428571428e-06,
      "loss": 0.0146,
      "step": 10230
    },
    {
      "epoch": 5.851428571428571,
      "grad_norm": 0.18340013921260834,
      "learning_rate": 8.297142857142859e-06,
      "loss": 0.0014,
      "step": 10240
    },
    {
      "epoch": 5.857142857142857,
      "grad_norm": 0.0014188112691044807,
      "learning_rate": 8.285714285714287e-06,
      "loss": 0.0004,
      "step": 10250
    },
    {
      "epoch": 5.862857142857143,
      "grad_norm": 0.0006372003117576241,
      "learning_rate": 8.274285714285715e-06,
      "loss": 0.0607,
      "step": 10260
    },
    {
      "epoch": 5.868571428571428,
      "grad_norm": 0.020692449063062668,
      "learning_rate": 8.262857142857144e-06,
      "loss": 0.014,
      "step": 10270
    },
    {
      "epoch": 5.8742857142857146,
      "grad_norm": 0.0014801300130784512,
      "learning_rate": 8.251428571428572e-06,
      "loss": 0.0,
      "step": 10280
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.053669389337301254,
      "learning_rate": 8.24e-06,
      "loss": 0.0001,
      "step": 10290
    },
    {
      "epoch": 5.885714285714286,
      "grad_norm": 0.002653283067047596,
      "learning_rate": 8.22857142857143e-06,
      "loss": 0.0032,
      "step": 10300
    },
    {
      "epoch": 5.8914285714285715,
      "grad_norm": 0.002914533019065857,
      "learning_rate": 8.217142857142858e-06,
      "loss": 0.0001,
      "step": 10310
    },
    {
      "epoch": 5.897142857142857,
      "grad_norm": 0.0010058359475806355,
      "learning_rate": 8.205714285714286e-06,
      "loss": 0.0514,
      "step": 10320
    },
    {
      "epoch": 5.902857142857143,
      "grad_norm": 0.0016975782345980406,
      "learning_rate": 8.194285714285714e-06,
      "loss": 0.001,
      "step": 10330
    },
    {
      "epoch": 5.908571428571428,
      "grad_norm": 0.0031167329289019108,
      "learning_rate": 8.182857142857143e-06,
      "loss": 0.0,
      "step": 10340
    },
    {
      "epoch": 5.914285714285715,
      "grad_norm": 0.0033952973317354918,
      "learning_rate": 8.171428571428573e-06,
      "loss": 0.0,
      "step": 10350
    },
    {
      "epoch": 5.92,
      "grad_norm": 2.7258851528167725,
      "learning_rate": 8.16e-06,
      "loss": 0.0329,
      "step": 10360
    },
    {
      "epoch": 5.925714285714285,
      "grad_norm": 0.00370467035099864,
      "learning_rate": 8.148571428571428e-06,
      "loss": 0.063,
      "step": 10370
    },
    {
      "epoch": 5.9314285714285715,
      "grad_norm": 0.0045136092230677605,
      "learning_rate": 8.137142857142858e-06,
      "loss": 0.0001,
      "step": 10380
    },
    {
      "epoch": 5.937142857142857,
      "grad_norm": 0.0026058582589030266,
      "learning_rate": 8.125714285714287e-06,
      "loss": 0.0059,
      "step": 10390
    },
    {
      "epoch": 5.942857142857143,
      "grad_norm": 0.002911200514063239,
      "learning_rate": 8.114285714285715e-06,
      "loss": 0.0,
      "step": 10400
    },
    {
      "epoch": 5.948571428571428,
      "grad_norm": 0.316237211227417,
      "learning_rate": 8.102857142857144e-06,
      "loss": 0.0003,
      "step": 10410
    },
    {
      "epoch": 5.954285714285715,
      "grad_norm": 0.007233982905745506,
      "learning_rate": 8.091428571428572e-06,
      "loss": 0.0176,
      "step": 10420
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.0005867775762453675,
      "learning_rate": 8.08e-06,
      "loss": 0.0004,
      "step": 10430
    },
    {
      "epoch": 5.965714285714286,
      "grad_norm": 27.037694931030273,
      "learning_rate": 8.068571428571429e-06,
      "loss": 0.0093,
      "step": 10440
    },
    {
      "epoch": 5.9714285714285715,
      "grad_norm": 0.000831233395729214,
      "learning_rate": 8.057142857142857e-06,
      "loss": 0.0507,
      "step": 10450
    },
    {
      "epoch": 5.977142857142857,
      "grad_norm": 24.116744995117188,
      "learning_rate": 8.045714285714286e-06,
      "loss": 0.0375,
      "step": 10460
    },
    {
      "epoch": 5.982857142857143,
      "grad_norm": 0.000590096868108958,
      "learning_rate": 8.034285714285714e-06,
      "loss": 0.0002,
      "step": 10470
    },
    {
      "epoch": 5.988571428571428,
      "grad_norm": 0.0016595538472756743,
      "learning_rate": 8.022857142857143e-06,
      "loss": 0.0052,
      "step": 10480
    },
    {
      "epoch": 5.994285714285715,
      "grad_norm": 0.0048094443045556545,
      "learning_rate": 8.011428571428573e-06,
      "loss": 0.0031,
      "step": 10490
    },
    {
      "epoch": 6.0,
      "grad_norm": 24.44669532775879,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.036,
      "step": 10500
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.984792780748663,
      "eval_f1": 0.9313207547169812,
      "eval_loss": 0.10689564794301987,
      "eval_precision": 0.9405487804878049,
      "eval_recall": 0.922272047832586,
      "eval_runtime": 53.7101,
      "eval_samples_per_second": 111.711,
      "eval_steps_per_second": 3.5,
      "step": 10500
    },
    {
      "epoch": 6.005714285714285,
      "grad_norm": 0.0017380943754687905,
      "learning_rate": 7.988571428571428e-06,
      "loss": 0.0,
      "step": 10510
    },
    {
      "epoch": 6.011428571428572,
      "grad_norm": 0.03508070856332779,
      "learning_rate": 7.977142857142858e-06,
      "loss": 0.0001,
      "step": 10520
    },
    {
      "epoch": 6.017142857142857,
      "grad_norm": 0.002497434616088867,
      "learning_rate": 7.965714285714287e-06,
      "loss": 0.0078,
      "step": 10530
    },
    {
      "epoch": 6.022857142857143,
      "grad_norm": 0.049682050943374634,
      "learning_rate": 7.954285714285715e-06,
      "loss": 0.0011,
      "step": 10540
    },
    {
      "epoch": 6.0285714285714285,
      "grad_norm": 0.011481313966214657,
      "learning_rate": 7.942857142857144e-06,
      "loss": 0.001,
      "step": 10550
    },
    {
      "epoch": 6.034285714285715,
      "grad_norm": 0.0005141248693689704,
      "learning_rate": 7.931428571428572e-06,
      "loss": 0.0004,
      "step": 10560
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.002680723089724779,
      "learning_rate": 7.92e-06,
      "loss": 0.0001,
      "step": 10570
    },
    {
      "epoch": 6.045714285714285,
      "grad_norm": 0.00422544963657856,
      "learning_rate": 7.908571428571429e-06,
      "loss": 0.0009,
      "step": 10580
    },
    {
      "epoch": 6.051428571428572,
      "grad_norm": 0.0033701318316161633,
      "learning_rate": 7.897142857142857e-06,
      "loss": 0.0054,
      "step": 10590
    },
    {
      "epoch": 6.057142857142857,
      "grad_norm": 0.00042730040149763227,
      "learning_rate": 7.885714285714286e-06,
      "loss": 0.028,
      "step": 10600
    },
    {
      "epoch": 6.062857142857143,
      "grad_norm": 0.5686629414558411,
      "learning_rate": 7.874285714285716e-06,
      "loss": 0.0573,
      "step": 10610
    },
    {
      "epoch": 6.0685714285714285,
      "grad_norm": 0.09696004539728165,
      "learning_rate": 7.862857142857143e-06,
      "loss": 0.0001,
      "step": 10620
    },
    {
      "epoch": 6.074285714285715,
      "grad_norm": 0.004749876447021961,
      "learning_rate": 7.851428571428573e-06,
      "loss": 0.0101,
      "step": 10630
    },
    {
      "epoch": 6.08,
      "grad_norm": 6.526702404022217,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.0194,
      "step": 10640
    },
    {
      "epoch": 6.085714285714285,
      "grad_norm": 0.009571981616318226,
      "learning_rate": 7.828571428571428e-06,
      "loss": 0.0001,
      "step": 10650
    },
    {
      "epoch": 6.091428571428572,
      "grad_norm": 0.0014925564173609018,
      "learning_rate": 7.817142857142858e-06,
      "loss": 0.0001,
      "step": 10660
    },
    {
      "epoch": 6.097142857142857,
      "grad_norm": 0.0009323530830442905,
      "learning_rate": 7.805714285714286e-06,
      "loss": 0.0002,
      "step": 10670
    },
    {
      "epoch": 6.102857142857143,
      "grad_norm": 0.001240511192008853,
      "learning_rate": 7.794285714285715e-06,
      "loss": 0.0282,
      "step": 10680
    },
    {
      "epoch": 6.1085714285714285,
      "grad_norm": 0.060476209968328476,
      "learning_rate": 7.782857142857143e-06,
      "loss": 0.0097,
      "step": 10690
    },
    {
      "epoch": 6.114285714285714,
      "grad_norm": 0.0004817304143216461,
      "learning_rate": 7.771428571428572e-06,
      "loss": 0.001,
      "step": 10700
    },
    {
      "epoch": 6.12,
      "grad_norm": 19.020416259765625,
      "learning_rate": 7.76e-06,
      "loss": 0.05,
      "step": 10710
    },
    {
      "epoch": 6.1257142857142854,
      "grad_norm": 0.0015087160281836987,
      "learning_rate": 7.74857142857143e-06,
      "loss": 0.0,
      "step": 10720
    },
    {
      "epoch": 6.131428571428572,
      "grad_norm": 0.0004739574796985835,
      "learning_rate": 7.737142857142857e-06,
      "loss": 0.0001,
      "step": 10730
    },
    {
      "epoch": 6.137142857142857,
      "grad_norm": 0.002809035126119852,
      "learning_rate": 7.725714285714286e-06,
      "loss": 0.0,
      "step": 10740
    },
    {
      "epoch": 6.142857142857143,
      "grad_norm": 0.005163190420717001,
      "learning_rate": 7.714285714285716e-06,
      "loss": 0.0001,
      "step": 10750
    },
    {
      "epoch": 6.148571428571429,
      "grad_norm": 0.0015708263963460922,
      "learning_rate": 7.702857142857142e-06,
      "loss": 0.0,
      "step": 10760
    },
    {
      "epoch": 6.154285714285714,
      "grad_norm": 0.08013708889484406,
      "learning_rate": 7.691428571428573e-06,
      "loss": 0.0049,
      "step": 10770
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.1070637702941895,
      "learning_rate": 7.680000000000001e-06,
      "loss": 0.0506,
      "step": 10780
    },
    {
      "epoch": 6.1657142857142855,
      "grad_norm": 0.0062705944292247295,
      "learning_rate": 7.66857142857143e-06,
      "loss": 0.0,
      "step": 10790
    },
    {
      "epoch": 6.171428571428572,
      "grad_norm": 0.002669882494956255,
      "learning_rate": 7.657142857142858e-06,
      "loss": 0.0,
      "step": 10800
    },
    {
      "epoch": 6.177142857142857,
      "grad_norm": 0.0005811918526887894,
      "learning_rate": 7.645714285714286e-06,
      "loss": 0.0,
      "step": 10810
    },
    {
      "epoch": 6.182857142857143,
      "grad_norm": 0.0161373820155859,
      "learning_rate": 7.634285714285715e-06,
      "loss": 0.0001,
      "step": 10820
    },
    {
      "epoch": 6.188571428571429,
      "grad_norm": 0.0021931068040430546,
      "learning_rate": 7.622857142857143e-06,
      "loss": 0.0001,
      "step": 10830
    },
    {
      "epoch": 6.194285714285714,
      "grad_norm": 0.000640445330645889,
      "learning_rate": 7.611428571428572e-06,
      "loss": 0.0,
      "step": 10840
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.0010823286138474941,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0015,
      "step": 10850
    },
    {
      "epoch": 6.2057142857142855,
      "grad_norm": 0.0008768980042077601,
      "learning_rate": 7.588571428571429e-06,
      "loss": 0.0,
      "step": 10860
    },
    {
      "epoch": 6.211428571428572,
      "grad_norm": 0.027623971924185753,
      "learning_rate": 7.577142857142857e-06,
      "loss": 0.0185,
      "step": 10870
    },
    {
      "epoch": 6.217142857142857,
      "grad_norm": 0.0004957843921147287,
      "learning_rate": 7.565714285714286e-06,
      "loss": 0.0001,
      "step": 10880
    },
    {
      "epoch": 6.222857142857142,
      "grad_norm": 1.3260784149169922,
      "learning_rate": 7.5542857142857155e-06,
      "loss": 0.0004,
      "step": 10890
    },
    {
      "epoch": 6.228571428571429,
      "grad_norm": 0.005571700166910887,
      "learning_rate": 7.542857142857144e-06,
      "loss": 0.0,
      "step": 10900
    },
    {
      "epoch": 6.234285714285714,
      "grad_norm": 0.011759907007217407,
      "learning_rate": 7.5314285714285716e-06,
      "loss": 0.0164,
      "step": 10910
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.0004696188843809068,
      "learning_rate": 7.520000000000001e-06,
      "loss": 0.0,
      "step": 10920
    },
    {
      "epoch": 6.2457142857142856,
      "grad_norm": 0.00032110759639181197,
      "learning_rate": 7.508571428571429e-06,
      "loss": 0.0237,
      "step": 10930
    },
    {
      "epoch": 6.251428571428572,
      "grad_norm": 0.0008429040899500251,
      "learning_rate": 7.497142857142857e-06,
      "loss": 0.0355,
      "step": 10940
    },
    {
      "epoch": 6.257142857142857,
      "grad_norm": 0.0021617375314235687,
      "learning_rate": 7.485714285714286e-06,
      "loss": 0.0001,
      "step": 10950
    },
    {
      "epoch": 6.2628571428571425,
      "grad_norm": 0.0012953890254721045,
      "learning_rate": 7.4742857142857154e-06,
      "loss": 0.0001,
      "step": 10960
    },
    {
      "epoch": 6.268571428571429,
      "grad_norm": 0.00037281381082721055,
      "learning_rate": 7.462857142857144e-06,
      "loss": 0.0,
      "step": 10970
    },
    {
      "epoch": 6.274285714285714,
      "grad_norm": 0.0012811548076570034,
      "learning_rate": 7.4514285714285715e-06,
      "loss": 0.0002,
      "step": 10980
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.0005109054036438465,
      "learning_rate": 7.440000000000001e-06,
      "loss": 0.0006,
      "step": 10990
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 0.0007947798585519195,
      "learning_rate": 7.428571428571429e-06,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 6.291428571428572,
      "grad_norm": 0.0010085607646033168,
      "learning_rate": 7.417142857142857e-06,
      "loss": 0.0159,
      "step": 11010
    },
    {
      "epoch": 6.297142857142857,
      "grad_norm": 0.08629381656646729,
      "learning_rate": 7.405714285714286e-06,
      "loss": 0.0003,
      "step": 11020
    },
    {
      "epoch": 6.3028571428571425,
      "grad_norm": 0.0033672505524009466,
      "learning_rate": 7.394285714285715e-06,
      "loss": 0.0,
      "step": 11030
    },
    {
      "epoch": 6.308571428571429,
      "grad_norm": 0.004181427415460348,
      "learning_rate": 7.382857142857144e-06,
      "loss": 0.0004,
      "step": 11040
    },
    {
      "epoch": 6.314285714285714,
      "grad_norm": 0.0011901698308065534,
      "learning_rate": 7.371428571428571e-06,
      "loss": 0.0383,
      "step": 11050
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.0018860960844904184,
      "learning_rate": 7.360000000000001e-06,
      "loss": 0.0398,
      "step": 11060
    },
    {
      "epoch": 6.325714285714286,
      "grad_norm": 0.0009143881616182625,
      "learning_rate": 7.348571428571429e-06,
      "loss": 0.0005,
      "step": 11070
    },
    {
      "epoch": 6.331428571428571,
      "grad_norm": 0.0011695190332829952,
      "learning_rate": 7.337142857142858e-06,
      "loss": 0.0408,
      "step": 11080
    },
    {
      "epoch": 6.337142857142857,
      "grad_norm": 0.006226688623428345,
      "learning_rate": 7.325714285714286e-06,
      "loss": 0.0004,
      "step": 11090
    },
    {
      "epoch": 6.3428571428571425,
      "grad_norm": 0.007384285796433687,
      "learning_rate": 7.314285714285715e-06,
      "loss": 0.0001,
      "step": 11100
    },
    {
      "epoch": 6.348571428571429,
      "grad_norm": 0.0032496540807187557,
      "learning_rate": 7.302857142857144e-06,
      "loss": 0.0013,
      "step": 11110
    },
    {
      "epoch": 6.354285714285714,
      "grad_norm": 0.005771934054791927,
      "learning_rate": 7.291428571428571e-06,
      "loss": 0.0001,
      "step": 11120
    },
    {
      "epoch": 6.36,
      "grad_norm": 5.26786994934082,
      "learning_rate": 7.280000000000001e-06,
      "loss": 0.0007,
      "step": 11130
    },
    {
      "epoch": 6.365714285714286,
      "grad_norm": 0.0009218569030053914,
      "learning_rate": 7.268571428571429e-06,
      "loss": 0.0,
      "step": 11140
    },
    {
      "epoch": 6.371428571428572,
      "grad_norm": 0.0007785657653585076,
      "learning_rate": 7.257142857142858e-06,
      "loss": 0.0,
      "step": 11150
    },
    {
      "epoch": 6.377142857142857,
      "grad_norm": 0.0005714620347134769,
      "learning_rate": 7.245714285714286e-06,
      "loss": 0.008,
      "step": 11160
    },
    {
      "epoch": 6.382857142857143,
      "grad_norm": 0.013318507932126522,
      "learning_rate": 7.234285714285715e-06,
      "loss": 0.0005,
      "step": 11170
    },
    {
      "epoch": 6.388571428571429,
      "grad_norm": 0.005383143667131662,
      "learning_rate": 7.222857142857144e-06,
      "loss": 0.1179,
      "step": 11180
    },
    {
      "epoch": 6.394285714285714,
      "grad_norm": 0.0014041635440662503,
      "learning_rate": 7.211428571428573e-06,
      "loss": 0.0085,
      "step": 11190
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.0006591471610590816,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.0,
      "step": 11200
    },
    {
      "epoch": 6.405714285714286,
      "grad_norm": 0.0008899967651814222,
      "learning_rate": 7.188571428571429e-06,
      "loss": 0.0031,
      "step": 11210
    },
    {
      "epoch": 6.411428571428571,
      "grad_norm": 0.009942530654370785,
      "learning_rate": 7.177142857142858e-06,
      "loss": 0.0049,
      "step": 11220
    },
    {
      "epoch": 6.417142857142857,
      "grad_norm": 0.002828818280249834,
      "learning_rate": 7.165714285714286e-06,
      "loss": 0.0,
      "step": 11230
    },
    {
      "epoch": 6.422857142857143,
      "grad_norm": 0.015739306807518005,
      "learning_rate": 7.154285714285715e-06,
      "loss": 0.0028,
      "step": 11240
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.003526011947542429,
      "learning_rate": 7.1428571428571436e-06,
      "loss": 0.0,
      "step": 11250
    },
    {
      "epoch": 6.434285714285714,
      "grad_norm": 0.0011247831862419844,
      "learning_rate": 7.131428571428573e-06,
      "loss": 0.0106,
      "step": 11260
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.009359161369502544,
      "learning_rate": 7.1200000000000004e-06,
      "loss": 0.0005,
      "step": 11270
    },
    {
      "epoch": 6.445714285714286,
      "grad_norm": 0.00019543850794434547,
      "learning_rate": 7.108571428571429e-06,
      "loss": 0.0001,
      "step": 11280
    },
    {
      "epoch": 6.451428571428571,
      "grad_norm": 42.951725006103516,
      "learning_rate": 7.097142857142858e-06,
      "loss": 0.0316,
      "step": 11290
    },
    {
      "epoch": 6.457142857142857,
      "grad_norm": 0.0532558411359787,
      "learning_rate": 7.085714285714286e-06,
      "loss": 0.0,
      "step": 11300
    },
    {
      "epoch": 6.462857142857143,
      "grad_norm": 0.001284904545173049,
      "learning_rate": 7.074285714285715e-06,
      "loss": 0.0169,
      "step": 11310
    },
    {
      "epoch": 6.468571428571429,
      "grad_norm": 15.063984870910645,
      "learning_rate": 7.0628571428571435e-06,
      "loss": 0.0275,
      "step": 11320
    },
    {
      "epoch": 6.474285714285714,
      "grad_norm": 0.0012044386239722371,
      "learning_rate": 7.051428571428573e-06,
      "loss": 0.0002,
      "step": 11330
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.004341163206845522,
      "learning_rate": 7.04e-06,
      "loss": 0.0,
      "step": 11340
    },
    {
      "epoch": 6.485714285714286,
      "grad_norm": 0.022185618057847023,
      "learning_rate": 7.028571428571429e-06,
      "loss": 0.0,
      "step": 11350
    },
    {
      "epoch": 6.491428571428571,
      "grad_norm": 25.38456916809082,
      "learning_rate": 7.017142857142858e-06,
      "loss": 0.0027,
      "step": 11360
    },
    {
      "epoch": 6.497142857142857,
      "grad_norm": 0.004233888350427151,
      "learning_rate": 7.0057142857142865e-06,
      "loss": 0.0281,
      "step": 11370
    },
    {
      "epoch": 6.502857142857143,
      "grad_norm": 0.0011402239324524999,
      "learning_rate": 6.994285714285715e-06,
      "loss": 0.0,
      "step": 11380
    },
    {
      "epoch": 6.508571428571429,
      "grad_norm": 0.0018980083987116814,
      "learning_rate": 6.982857142857143e-06,
      "loss": 0.0003,
      "step": 11390
    },
    {
      "epoch": 6.514285714285714,
      "grad_norm": 0.0021491621155291796,
      "learning_rate": 6.971428571428573e-06,
      "loss": 0.0005,
      "step": 11400
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.0005370390135794878,
      "learning_rate": 6.96e-06,
      "loss": 0.0003,
      "step": 11410
    },
    {
      "epoch": 6.525714285714286,
      "grad_norm": 13.335753440856934,
      "learning_rate": 6.948571428571429e-06,
      "loss": 0.0417,
      "step": 11420
    },
    {
      "epoch": 6.531428571428571,
      "grad_norm": 0.03261303901672363,
      "learning_rate": 6.937142857142858e-06,
      "loss": 0.0018,
      "step": 11430
    },
    {
      "epoch": 6.537142857142857,
      "grad_norm": 0.0007122516981326044,
      "learning_rate": 6.9257142857142864e-06,
      "loss": 0.0061,
      "step": 11440
    },
    {
      "epoch": 6.542857142857143,
      "grad_norm": 0.04694811627268791,
      "learning_rate": 6.914285714285715e-06,
      "loss": 0.0183,
      "step": 11450
    },
    {
      "epoch": 6.548571428571429,
      "grad_norm": 0.0054426034912467,
      "learning_rate": 6.902857142857143e-06,
      "loss": 0.0003,
      "step": 11460
    },
    {
      "epoch": 6.554285714285714,
      "grad_norm": 0.004511819686740637,
      "learning_rate": 6.891428571428573e-06,
      "loss": 0.0001,
      "step": 11470
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.00042509587365202606,
      "learning_rate": 6.88e-06,
      "loss": 0.0,
      "step": 11480
    },
    {
      "epoch": 6.565714285714286,
      "grad_norm": 0.0010158789809793234,
      "learning_rate": 6.868571428571429e-06,
      "loss": 0.0017,
      "step": 11490
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.00034761711140163243,
      "learning_rate": 6.857142857142858e-06,
      "loss": 0.0283,
      "step": 11500
    },
    {
      "epoch": 6.577142857142857,
      "grad_norm": 0.006143129430711269,
      "learning_rate": 6.845714285714286e-06,
      "loss": 0.0,
      "step": 11510
    },
    {
      "epoch": 6.582857142857143,
      "grad_norm": 0.0009490259108133614,
      "learning_rate": 6.834285714285715e-06,
      "loss": 0.0,
      "step": 11520
    },
    {
      "epoch": 6.588571428571429,
      "grad_norm": 0.009962895885109901,
      "learning_rate": 6.822857142857143e-06,
      "loss": 0.0,
      "step": 11530
    },
    {
      "epoch": 6.594285714285714,
      "grad_norm": 0.0008888124139048159,
      "learning_rate": 6.8114285714285725e-06,
      "loss": 0.0001,
      "step": 11540
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.00043612971785478294,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0006,
      "step": 11550
    },
    {
      "epoch": 6.605714285714286,
      "grad_norm": 0.00011177705891896039,
      "learning_rate": 6.7885714285714286e-06,
      "loss": 0.0027,
      "step": 11560
    },
    {
      "epoch": 6.611428571428571,
      "grad_norm": 0.013539747335016727,
      "learning_rate": 6.777142857142858e-06,
      "loss": 0.0763,
      "step": 11570
    },
    {
      "epoch": 6.617142857142857,
      "grad_norm": 1.3775171041488647,
      "learning_rate": 6.765714285714286e-06,
      "loss": 0.0066,
      "step": 11580
    },
    {
      "epoch": 6.622857142857143,
      "grad_norm": 0.0020643107127398252,
      "learning_rate": 6.754285714285715e-06,
      "loss": 0.0491,
      "step": 11590
    },
    {
      "epoch": 6.628571428571428,
      "grad_norm": 0.0007095313048921525,
      "learning_rate": 6.742857142857143e-06,
      "loss": 0.0013,
      "step": 11600
    },
    {
      "epoch": 6.634285714285714,
      "grad_norm": 0.631771445274353,
      "learning_rate": 6.7314285714285724e-06,
      "loss": 0.0004,
      "step": 11610
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.00855625607073307,
      "learning_rate": 6.720000000000001e-06,
      "loss": 0.0001,
      "step": 11620
    },
    {
      "epoch": 6.645714285714286,
      "grad_norm": 0.004504686687141657,
      "learning_rate": 6.7085714285714285e-06,
      "loss": 0.0001,
      "step": 11630
    },
    {
      "epoch": 6.651428571428571,
      "grad_norm": 0.0008020378882065415,
      "learning_rate": 6.697142857142858e-06,
      "loss": 0.0257,
      "step": 11640
    },
    {
      "epoch": 6.6571428571428575,
      "grad_norm": 0.8800737261772156,
      "learning_rate": 6.685714285714286e-06,
      "loss": 0.0001,
      "step": 11650
    },
    {
      "epoch": 6.662857142857143,
      "grad_norm": 0.002545334631577134,
      "learning_rate": 6.6742857142857155e-06,
      "loss": 0.0,
      "step": 11660
    },
    {
      "epoch": 6.668571428571429,
      "grad_norm": 0.0005875545321032405,
      "learning_rate": 6.662857142857143e-06,
      "loss": 0.0,
      "step": 11670
    },
    {
      "epoch": 6.674285714285714,
      "grad_norm": 0.001477555138990283,
      "learning_rate": 6.651428571428572e-06,
      "loss": 0.0,
      "step": 11680
    },
    {
      "epoch": 6.68,
      "grad_norm": 96.9412612915039,
      "learning_rate": 6.640000000000001e-06,
      "loss": 0.0241,
      "step": 11690
    },
    {
      "epoch": 6.685714285714286,
      "grad_norm": 0.0007739598513580859,
      "learning_rate": 6.628571428571428e-06,
      "loss": 0.0455,
      "step": 11700
    },
    {
      "epoch": 6.691428571428571,
      "grad_norm": 0.0015781060792505741,
      "learning_rate": 6.617142857142858e-06,
      "loss": 0.0,
      "step": 11710
    },
    {
      "epoch": 6.6971428571428575,
      "grad_norm": 33.949745178222656,
      "learning_rate": 6.605714285714286e-06,
      "loss": 0.029,
      "step": 11720
    },
    {
      "epoch": 6.702857142857143,
      "grad_norm": 0.003192555159330368,
      "learning_rate": 6.594285714285715e-06,
      "loss": 0.0,
      "step": 11730
    },
    {
      "epoch": 6.708571428571428,
      "grad_norm": 0.0018137424485757947,
      "learning_rate": 6.582857142857143e-06,
      "loss": 0.0009,
      "step": 11740
    },
    {
      "epoch": 6.714285714285714,
      "grad_norm": 0.0007831334951333702,
      "learning_rate": 6.571428571428572e-06,
      "loss": 0.001,
      "step": 11750
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.0010206701699644327,
      "learning_rate": 6.560000000000001e-06,
      "loss": 0.0001,
      "step": 11760
    },
    {
      "epoch": 6.725714285714286,
      "grad_norm": 0.0009271774324588478,
      "learning_rate": 6.548571428571428e-06,
      "loss": 0.0,
      "step": 11770
    },
    {
      "epoch": 6.731428571428571,
      "grad_norm": 0.00167188816703856,
      "learning_rate": 6.537142857142858e-06,
      "loss": 0.0,
      "step": 11780
    },
    {
      "epoch": 6.737142857142857,
      "grad_norm": 0.001819242024794221,
      "learning_rate": 6.525714285714286e-06,
      "loss": 0.0004,
      "step": 11790
    },
    {
      "epoch": 6.742857142857143,
      "grad_norm": 0.004307264927774668,
      "learning_rate": 6.514285714285715e-06,
      "loss": 0.0001,
      "step": 11800
    },
    {
      "epoch": 6.748571428571428,
      "grad_norm": 0.020916329696774483,
      "learning_rate": 6.502857142857143e-06,
      "loss": 0.0001,
      "step": 11810
    },
    {
      "epoch": 6.7542857142857144,
      "grad_norm": 0.0007669751066714525,
      "learning_rate": 6.491428571428572e-06,
      "loss": 0.0027,
      "step": 11820
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.2736673057079315,
      "learning_rate": 6.480000000000001e-06,
      "loss": 0.0005,
      "step": 11830
    },
    {
      "epoch": 6.765714285714286,
      "grad_norm": 0.0008611584198661149,
      "learning_rate": 6.46857142857143e-06,
      "loss": 0.0002,
      "step": 11840
    },
    {
      "epoch": 6.771428571428571,
      "grad_norm": 0.00043140174238942564,
      "learning_rate": 6.4571428571428575e-06,
      "loss": 0.0,
      "step": 11850
    },
    {
      "epoch": 6.777142857142858,
      "grad_norm": 0.0014019543305039406,
      "learning_rate": 6.445714285714286e-06,
      "loss": 0.0,
      "step": 11860
    },
    {
      "epoch": 6.782857142857143,
      "grad_norm": 0.0027756390627473593,
      "learning_rate": 6.434285714285715e-06,
      "loss": 0.0064,
      "step": 11870
    },
    {
      "epoch": 6.788571428571428,
      "grad_norm": 0.0006293930346146226,
      "learning_rate": 6.422857142857143e-06,
      "loss": 0.0,
      "step": 11880
    },
    {
      "epoch": 6.7942857142857145,
      "grad_norm": 0.0005578831769526005,
      "learning_rate": 6.411428571428572e-06,
      "loss": 0.0226,
      "step": 11890
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.00039396240026690066,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0061,
      "step": 11900
    },
    {
      "epoch": 6.805714285714286,
      "grad_norm": 0.0012413314543664455,
      "learning_rate": 6.38857142857143e-06,
      "loss": 0.0723,
      "step": 11910
    },
    {
      "epoch": 6.811428571428571,
      "grad_norm": 0.0015089160297065973,
      "learning_rate": 6.3771428571428574e-06,
      "loss": 0.0828,
      "step": 11920
    },
    {
      "epoch": 6.817142857142857,
      "grad_norm": 0.0004626707232091576,
      "learning_rate": 6.365714285714286e-06,
      "loss": 0.0409,
      "step": 11930
    },
    {
      "epoch": 6.822857142857143,
      "grad_norm": 0.0008758186595514417,
      "learning_rate": 6.354285714285715e-06,
      "loss": 0.0,
      "step": 11940
    },
    {
      "epoch": 6.828571428571428,
      "grad_norm": 0.0018017926486209035,
      "learning_rate": 6.342857142857143e-06,
      "loss": 0.0013,
      "step": 11950
    },
    {
      "epoch": 6.8342857142857145,
      "grad_norm": 0.01030528824776411,
      "learning_rate": 6.331428571428572e-06,
      "loss": 0.006,
      "step": 11960
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.00026201867149211466,
      "learning_rate": 6.3200000000000005e-06,
      "loss": 0.0001,
      "step": 11970
    },
    {
      "epoch": 6.845714285714286,
      "grad_norm": 0.0017674657283350825,
      "learning_rate": 6.30857142857143e-06,
      "loss": 0.0396,
      "step": 11980
    },
    {
      "epoch": 6.851428571428571,
      "grad_norm": 0.0020902350079268217,
      "learning_rate": 6.297142857142857e-06,
      "loss": 0.0003,
      "step": 11990
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 0.0018624013755470514,
      "learning_rate": 6.285714285714286e-06,
      "loss": 0.0108,
      "step": 12000
    },
    {
      "epoch": 6.862857142857143,
      "grad_norm": 0.0008965092711150646,
      "learning_rate": 6.274285714285715e-06,
      "loss": 0.0003,
      "step": 12010
    },
    {
      "epoch": 6.868571428571428,
      "grad_norm": 0.0007592957117594779,
      "learning_rate": 6.2628571428571435e-06,
      "loss": 0.0005,
      "step": 12020
    },
    {
      "epoch": 6.8742857142857146,
      "grad_norm": 24.79156494140625,
      "learning_rate": 6.251428571428572e-06,
      "loss": 0.0161,
      "step": 12030
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.1005103588104248,
      "learning_rate": 6.24e-06,
      "loss": 0.0005,
      "step": 12040
    },
    {
      "epoch": 6.885714285714286,
      "grad_norm": 0.00035688711795955896,
      "learning_rate": 6.22857142857143e-06,
      "loss": 0.0,
      "step": 12050
    },
    {
      "epoch": 6.8914285714285715,
      "grad_norm": 0.027978109195828438,
      "learning_rate": 6.217142857142857e-06,
      "loss": 0.0,
      "step": 12060
    },
    {
      "epoch": 6.897142857142857,
      "grad_norm": 15.566179275512695,
      "learning_rate": 6.205714285714286e-06,
      "loss": 0.0446,
      "step": 12070
    },
    {
      "epoch": 6.902857142857143,
      "grad_norm": 0.011964707635343075,
      "learning_rate": 6.194285714285715e-06,
      "loss": 0.0003,
      "step": 12080
    },
    {
      "epoch": 6.908571428571428,
      "grad_norm": 0.032660648226737976,
      "learning_rate": 6.1828571428571434e-06,
      "loss": 0.0001,
      "step": 12090
    },
    {
      "epoch": 6.914285714285715,
      "grad_norm": 0.0009457117994315922,
      "learning_rate": 6.171428571428572e-06,
      "loss": 0.0017,
      "step": 12100
    },
    {
      "epoch": 6.92,
      "grad_norm": 0.009027551859617233,
      "learning_rate": 6.16e-06,
      "loss": 0.0001,
      "step": 12110
    },
    {
      "epoch": 6.925714285714285,
      "grad_norm": 0.001319382106885314,
      "learning_rate": 6.14857142857143e-06,
      "loss": 0.0202,
      "step": 12120
    },
    {
      "epoch": 6.9314285714285715,
      "grad_norm": 0.0021377087105065584,
      "learning_rate": 6.137142857142858e-06,
      "loss": 0.0,
      "step": 12130
    },
    {
      "epoch": 6.937142857142857,
      "grad_norm": 23.925691604614258,
      "learning_rate": 6.125714285714286e-06,
      "loss": 0.0077,
      "step": 12140
    },
    {
      "epoch": 6.942857142857143,
      "grad_norm": 0.0007932308944873512,
      "learning_rate": 6.114285714285715e-06,
      "loss": 0.0001,
      "step": 12150
    },
    {
      "epoch": 6.948571428571428,
      "grad_norm": 0.0003693452454172075,
      "learning_rate": 6.102857142857143e-06,
      "loss": 0.031,
      "step": 12160
    },
    {
      "epoch": 6.954285714285715,
      "grad_norm": 0.0009898132411763072,
      "learning_rate": 6.091428571428572e-06,
      "loss": 0.0513,
      "step": 12170
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.002896705409511924,
      "learning_rate": 6.08e-06,
      "loss": 0.083,
      "step": 12180
    },
    {
      "epoch": 6.965714285714286,
      "grad_norm": 0.01138609740883112,
      "learning_rate": 6.0685714285714295e-06,
      "loss": 0.0,
      "step": 12190
    },
    {
      "epoch": 6.9714285714285715,
      "grad_norm": 0.0028238643426448107,
      "learning_rate": 6.057142857142858e-06,
      "loss": 0.0,
      "step": 12200
    },
    {
      "epoch": 6.977142857142857,
      "grad_norm": 0.00551544688642025,
      "learning_rate": 6.0457142857142855e-06,
      "loss": 0.0523,
      "step": 12210
    },
    {
      "epoch": 6.982857142857143,
      "grad_norm": 0.0005135460523888469,
      "learning_rate": 6.034285714285715e-06,
      "loss": 0.0139,
      "step": 12220
    },
    {
      "epoch": 6.988571428571428,
      "grad_norm": 0.005499995779246092,
      "learning_rate": 6.022857142857143e-06,
      "loss": 0.0095,
      "step": 12230
    },
    {
      "epoch": 6.994285714285715,
      "grad_norm": 0.007082440424710512,
      "learning_rate": 6.011428571428572e-06,
      "loss": 0.0016,
      "step": 12240
    },
    {
      "epoch": 7.0,
      "grad_norm": 20.405317306518555,
      "learning_rate": 6e-06,
      "loss": 0.1147,
      "step": 12250
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9859625668449198,
      "eval_f1": 0.936267071320182,
      "eval_loss": 0.09991708397865295,
      "eval_precision": 0.9506933744221879,
      "eval_recall": 0.922272047832586,
      "eval_runtime": 53.8139,
      "eval_samples_per_second": 111.495,
      "eval_steps_per_second": 3.494,
      "step": 12250
    },
    {
      "epoch": 7.005714285714285,
      "grad_norm": 0.06666296720504761,
      "learning_rate": 5.9885714285714294e-06,
      "loss": 0.0135,
      "step": 12260
    },
    {
      "epoch": 7.011428571428572,
      "grad_norm": 0.01158563606441021,
      "learning_rate": 5.977142857142858e-06,
      "loss": 0.0013,
      "step": 12270
    },
    {
      "epoch": 7.017142857142857,
      "grad_norm": 0.0014488301239907742,
      "learning_rate": 5.9657142857142855e-06,
      "loss": 0.003,
      "step": 12280
    },
    {
      "epoch": 7.022857142857143,
      "grad_norm": 0.008350087329745293,
      "learning_rate": 5.954285714285715e-06,
      "loss": 0.0,
      "step": 12290
    },
    {
      "epoch": 7.0285714285714285,
      "grad_norm": 0.0006646206602454185,
      "learning_rate": 5.942857142857143e-06,
      "loss": 0.0116,
      "step": 12300
    },
    {
      "epoch": 7.034285714285715,
      "grad_norm": 0.5749267339706421,
      "learning_rate": 5.9314285714285725e-06,
      "loss": 0.0001,
      "step": 12310
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.0008605053881183267,
      "learning_rate": 5.92e-06,
      "loss": 0.0,
      "step": 12320
    },
    {
      "epoch": 7.045714285714285,
      "grad_norm": 0.004265244118869305,
      "learning_rate": 5.908571428571429e-06,
      "loss": 0.0322,
      "step": 12330
    },
    {
      "epoch": 7.051428571428572,
      "grad_norm": 9.25790023803711,
      "learning_rate": 5.897142857142858e-06,
      "loss": 0.0179,
      "step": 12340
    },
    {
      "epoch": 7.057142857142857,
      "grad_norm": 0.05338791757822037,
      "learning_rate": 5.885714285714285e-06,
      "loss": 0.0001,
      "step": 12350
    },
    {
      "epoch": 7.062857142857143,
      "grad_norm": 0.0057892450131475925,
      "learning_rate": 5.874285714285715e-06,
      "loss": 0.001,
      "step": 12360
    },
    {
      "epoch": 7.0685714285714285,
      "grad_norm": 0.47984421253204346,
      "learning_rate": 5.862857142857143e-06,
      "loss": 0.0001,
      "step": 12370
    },
    {
      "epoch": 7.074285714285715,
      "grad_norm": 0.0015856865793466568,
      "learning_rate": 5.851428571428572e-06,
      "loss": 0.0001,
      "step": 12380
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.007336742244660854,
      "learning_rate": 5.84e-06,
      "loss": 0.0001,
      "step": 12390
    },
    {
      "epoch": 7.085714285714285,
      "grad_norm": 0.005545484367758036,
      "learning_rate": 5.828571428571429e-06,
      "loss": 0.0017,
      "step": 12400
    },
    {
      "epoch": 7.091428571428572,
      "grad_norm": 0.030942227691411972,
      "learning_rate": 5.817142857142858e-06,
      "loss": 0.0001,
      "step": 12410
    },
    {
      "epoch": 7.097142857142857,
      "grad_norm": 0.010124051943421364,
      "learning_rate": 5.805714285714285e-06,
      "loss": 0.0,
      "step": 12420
    },
    {
      "epoch": 7.102857142857143,
      "grad_norm": 0.0016751560615375638,
      "learning_rate": 5.794285714285715e-06,
      "loss": 0.0,
      "step": 12430
    },
    {
      "epoch": 7.1085714285714285,
      "grad_norm": 0.03142589330673218,
      "learning_rate": 5.782857142857143e-06,
      "loss": 0.0004,
      "step": 12440
    },
    {
      "epoch": 7.114285714285714,
      "grad_norm": 0.001591855543665588,
      "learning_rate": 5.771428571428572e-06,
      "loss": 0.0,
      "step": 12450
    },
    {
      "epoch": 7.12,
      "grad_norm": 0.004897221922874451,
      "learning_rate": 5.76e-06,
      "loss": 0.0,
      "step": 12460
    },
    {
      "epoch": 7.1257142857142854,
      "grad_norm": 0.04304783046245575,
      "learning_rate": 5.748571428571429e-06,
      "loss": 0.0001,
      "step": 12470
    },
    {
      "epoch": 7.131428571428572,
      "grad_norm": 0.09053397178649902,
      "learning_rate": 5.737142857142858e-06,
      "loss": 0.0,
      "step": 12480
    },
    {
      "epoch": 7.137142857142857,
      "grad_norm": 0.003883153898641467,
      "learning_rate": 5.725714285714287e-06,
      "loss": 0.0002,
      "step": 12490
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.0010637009982019663,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.0,
      "step": 12500
    },
    {
      "epoch": 7.148571428571429,
      "grad_norm": 0.0037565878592431545,
      "learning_rate": 5.702857142857143e-06,
      "loss": 0.0,
      "step": 12510
    },
    {
      "epoch": 7.154285714285714,
      "grad_norm": 0.0006516217836178839,
      "learning_rate": 5.691428571428572e-06,
      "loss": 0.0,
      "step": 12520
    },
    {
      "epoch": 7.16,
      "grad_norm": 0.000616514531429857,
      "learning_rate": 5.68e-06,
      "loss": 0.0,
      "step": 12530
    },
    {
      "epoch": 7.1657142857142855,
      "grad_norm": 0.008022552356123924,
      "learning_rate": 5.668571428571429e-06,
      "loss": 0.0002,
      "step": 12540
    },
    {
      "epoch": 7.171428571428572,
      "grad_norm": 0.0017658015713095665,
      "learning_rate": 5.6571428571428576e-06,
      "loss": 0.0456,
      "step": 12550
    },
    {
      "epoch": 7.177142857142857,
      "grad_norm": 0.0016973774181678891,
      "learning_rate": 5.645714285714287e-06,
      "loss": 0.0001,
      "step": 12560
    },
    {
      "epoch": 7.182857142857143,
      "grad_norm": 0.0009806923335418105,
      "learning_rate": 5.6342857142857144e-06,
      "loss": 0.0,
      "step": 12570
    },
    {
      "epoch": 7.188571428571429,
      "grad_norm": 0.0029588136821985245,
      "learning_rate": 5.622857142857143e-06,
      "loss": 0.0,
      "step": 12580
    },
    {
      "epoch": 7.194285714285714,
      "grad_norm": 0.0008707019733265042,
      "learning_rate": 5.611428571428572e-06,
      "loss": 0.0,
      "step": 12590
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.003825737861916423,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0001,
      "step": 12600
    },
    {
      "epoch": 7.2057142857142855,
      "grad_norm": 0.0018093455582857132,
      "learning_rate": 5.588571428571429e-06,
      "loss": 0.0001,
      "step": 12610
    },
    {
      "epoch": 7.211428571428572,
      "grad_norm": 0.0005414665210992098,
      "learning_rate": 5.5771428571428575e-06,
      "loss": 0.0,
      "step": 12620
    },
    {
      "epoch": 7.217142857142857,
      "grad_norm": 0.000779216643422842,
      "learning_rate": 5.565714285714287e-06,
      "loss": 0.0,
      "step": 12630
    },
    {
      "epoch": 7.222857142857142,
      "grad_norm": 0.0008884042035788298,
      "learning_rate": 5.554285714285714e-06,
      "loss": 0.0,
      "step": 12640
    },
    {
      "epoch": 7.228571428571429,
      "grad_norm": 0.0009368695318698883,
      "learning_rate": 5.542857142857143e-06,
      "loss": 0.0002,
      "step": 12650
    },
    {
      "epoch": 7.234285714285714,
      "grad_norm": 0.00024881388526409864,
      "learning_rate": 5.531428571428572e-06,
      "loss": 0.0,
      "step": 12660
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.0029258541762828827,
      "learning_rate": 5.5200000000000005e-06,
      "loss": 0.0209,
      "step": 12670
    },
    {
      "epoch": 7.2457142857142856,
      "grad_norm": 0.0010100237559527159,
      "learning_rate": 5.508571428571429e-06,
      "loss": 0.0,
      "step": 12680
    },
    {
      "epoch": 7.251428571428572,
      "grad_norm": 0.0014817938208580017,
      "learning_rate": 5.497142857142857e-06,
      "loss": 0.0005,
      "step": 12690
    },
    {
      "epoch": 7.257142857142857,
      "grad_norm": 0.0005636810674332082,
      "learning_rate": 5.485714285714287e-06,
      "loss": 0.0172,
      "step": 12700
    },
    {
      "epoch": 7.2628571428571425,
      "grad_norm": 0.4009075462818146,
      "learning_rate": 5.474285714285714e-06,
      "loss": 0.0004,
      "step": 12710
    },
    {
      "epoch": 7.268571428571429,
      "grad_norm": 0.0009605269879102707,
      "learning_rate": 5.462857142857143e-06,
      "loss": 0.0,
      "step": 12720
    },
    {
      "epoch": 7.274285714285714,
      "grad_norm": 0.0005474092322401702,
      "learning_rate": 5.451428571428572e-06,
      "loss": 0.0,
      "step": 12730
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.0004953740863129497,
      "learning_rate": 5.4400000000000004e-06,
      "loss": 0.0001,
      "step": 12740
    },
    {
      "epoch": 7.285714285714286,
      "grad_norm": 0.00012598100875038654,
      "learning_rate": 5.428571428571429e-06,
      "loss": 0.0,
      "step": 12750
    },
    {
      "epoch": 7.291428571428572,
      "grad_norm": 0.002175738103687763,
      "learning_rate": 5.417142857142857e-06,
      "loss": 0.0,
      "step": 12760
    },
    {
      "epoch": 7.297142857142857,
      "grad_norm": 0.0003189444832969457,
      "learning_rate": 5.405714285714287e-06,
      "loss": 0.0,
      "step": 12770
    },
    {
      "epoch": 7.3028571428571425,
      "grad_norm": 0.0005231791292317212,
      "learning_rate": 5.394285714285715e-06,
      "loss": 0.0069,
      "step": 12780
    },
    {
      "epoch": 7.308571428571429,
      "grad_norm": 0.0003160611377097666,
      "learning_rate": 5.382857142857143e-06,
      "loss": 0.0045,
      "step": 12790
    },
    {
      "epoch": 7.314285714285714,
      "grad_norm": 0.000276068109087646,
      "learning_rate": 5.371428571428572e-06,
      "loss": 0.0003,
      "step": 12800
    },
    {
      "epoch": 7.32,
      "grad_norm": 0.0004431970592122525,
      "learning_rate": 5.36e-06,
      "loss": 0.0,
      "step": 12810
    },
    {
      "epoch": 7.325714285714286,
      "grad_norm": 0.03932500630617142,
      "learning_rate": 5.348571428571429e-06,
      "loss": 0.0,
      "step": 12820
    },
    {
      "epoch": 7.331428571428571,
      "grad_norm": 8.751387596130371,
      "learning_rate": 5.337142857142857e-06,
      "loss": 0.0528,
      "step": 12830
    },
    {
      "epoch": 7.337142857142857,
      "grad_norm": 0.0015383658464998007,
      "learning_rate": 5.3257142857142865e-06,
      "loss": 0.0183,
      "step": 12840
    },
    {
      "epoch": 7.3428571428571425,
      "grad_norm": 0.0023209108039736748,
      "learning_rate": 5.314285714285715e-06,
      "loss": 0.0103,
      "step": 12850
    },
    {
      "epoch": 7.348571428571429,
      "grad_norm": 0.009653536602854729,
      "learning_rate": 5.3028571428571425e-06,
      "loss": 0.0,
      "step": 12860
    },
    {
      "epoch": 7.354285714285714,
      "grad_norm": 0.005075389984995127,
      "learning_rate": 5.291428571428572e-06,
      "loss": 0.0326,
      "step": 12870
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.0005458051455207169,
      "learning_rate": 5.28e-06,
      "loss": 0.0001,
      "step": 12880
    },
    {
      "epoch": 7.365714285714286,
      "grad_norm": 0.016029471531510353,
      "learning_rate": 5.268571428571429e-06,
      "loss": 0.0002,
      "step": 12890
    },
    {
      "epoch": 7.371428571428572,
      "grad_norm": 9.831399917602539,
      "learning_rate": 5.257142857142857e-06,
      "loss": 0.0373,
      "step": 12900
    },
    {
      "epoch": 7.377142857142857,
      "grad_norm": 0.0030264873057603836,
      "learning_rate": 5.2457142857142864e-06,
      "loss": 0.0,
      "step": 12910
    },
    {
      "epoch": 7.382857142857143,
      "grad_norm": 0.002007065573707223,
      "learning_rate": 5.234285714285715e-06,
      "loss": 0.0003,
      "step": 12920
    },
    {
      "epoch": 7.388571428571429,
      "grad_norm": 0.0013585726264864206,
      "learning_rate": 5.2228571428571425e-06,
      "loss": 0.0175,
      "step": 12930
    },
    {
      "epoch": 7.394285714285714,
      "grad_norm": 0.0005304827936924994,
      "learning_rate": 5.211428571428572e-06,
      "loss": 0.0418,
      "step": 12940
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.006923320237547159,
      "learning_rate": 5.2e-06,
      "loss": 0.0,
      "step": 12950
    },
    {
      "epoch": 7.405714285714286,
      "grad_norm": 0.18685562908649445,
      "learning_rate": 5.1885714285714295e-06,
      "loss": 0.0001,
      "step": 12960
    },
    {
      "epoch": 7.411428571428571,
      "grad_norm": 0.0011913538910448551,
      "learning_rate": 5.177142857142857e-06,
      "loss": 0.0001,
      "step": 12970
    },
    {
      "epoch": 7.417142857142857,
      "grad_norm": 0.0012176083400845528,
      "learning_rate": 5.165714285714286e-06,
      "loss": 0.0001,
      "step": 12980
    },
    {
      "epoch": 7.422857142857143,
      "grad_norm": 0.00018873868975788355,
      "learning_rate": 5.154285714285715e-06,
      "loss": 0.0015,
      "step": 12990
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 0.0014655909035354853,
      "learning_rate": 5.142857142857142e-06,
      "loss": 0.0,
      "step": 13000
    },
    {
      "epoch": 7.434285714285714,
      "grad_norm": 0.00019311820506118238,
      "learning_rate": 5.131428571428572e-06,
      "loss": 0.0,
      "step": 13010
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.22378863394260406,
      "learning_rate": 5.12e-06,
      "loss": 0.0003,
      "step": 13020
    },
    {
      "epoch": 7.445714285714286,
      "grad_norm": 0.0006866593612357974,
      "learning_rate": 5.108571428571429e-06,
      "loss": 0.0001,
      "step": 13030
    },
    {
      "epoch": 7.451428571428571,
      "grad_norm": 0.0006149380933493376,
      "learning_rate": 5.097142857142857e-06,
      "loss": 0.0004,
      "step": 13040
    },
    {
      "epoch": 7.457142857142857,
      "grad_norm": 0.0007054228917695582,
      "learning_rate": 5.085714285714286e-06,
      "loss": 0.0087,
      "step": 13050
    },
    {
      "epoch": 7.462857142857143,
      "grad_norm": 0.0014928829623386264,
      "learning_rate": 5.074285714285715e-06,
      "loss": 0.0,
      "step": 13060
    },
    {
      "epoch": 7.468571428571429,
      "grad_norm": 0.001552468747831881,
      "learning_rate": 5.062857142857144e-06,
      "loss": 0.0001,
      "step": 13070
    },
    {
      "epoch": 7.474285714285714,
      "grad_norm": 0.0004296501283533871,
      "learning_rate": 5.051428571428572e-06,
      "loss": 0.0,
      "step": 13080
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.0005936375237070024,
      "learning_rate": 5.04e-06,
      "loss": 0.0,
      "step": 13090
    },
    {
      "epoch": 7.485714285714286,
      "grad_norm": 0.000392791727790609,
      "learning_rate": 5.028571428571429e-06,
      "loss": 0.0001,
      "step": 13100
    },
    {
      "epoch": 7.491428571428571,
      "grad_norm": 0.000390783156035468,
      "learning_rate": 5.017142857142857e-06,
      "loss": 0.0,
      "step": 13110
    },
    {
      "epoch": 7.497142857142857,
      "grad_norm": 0.00046535712317563593,
      "learning_rate": 5.005714285714286e-06,
      "loss": 0.0,
      "step": 13120
    },
    {
      "epoch": 7.502857142857143,
      "grad_norm": 0.000333935022354126,
      "learning_rate": 4.994285714285715e-06,
      "loss": 0.0003,
      "step": 13130
    },
    {
      "epoch": 7.508571428571429,
      "grad_norm": 0.0005333085427992046,
      "learning_rate": 4.982857142857143e-06,
      "loss": 0.0375,
      "step": 13140
    },
    {
      "epoch": 7.514285714285714,
      "grad_norm": 0.00043467088835313916,
      "learning_rate": 4.971428571428572e-06,
      "loss": 0.0,
      "step": 13150
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.0005431094323284924,
      "learning_rate": 4.960000000000001e-06,
      "loss": 0.0001,
      "step": 13160
    },
    {
      "epoch": 7.525714285714286,
      "grad_norm": 0.0004828207893297076,
      "learning_rate": 4.948571428571429e-06,
      "loss": 0.0001,
      "step": 13170
    },
    {
      "epoch": 7.531428571428571,
      "grad_norm": 0.0004862846981268376,
      "learning_rate": 4.937142857142858e-06,
      "loss": 0.001,
      "step": 13180
    },
    {
      "epoch": 7.537142857142857,
      "grad_norm": 0.00022902720957063138,
      "learning_rate": 4.925714285714286e-06,
      "loss": 0.0005,
      "step": 13190
    },
    {
      "epoch": 7.542857142857143,
      "grad_norm": 0.03299807757139206,
      "learning_rate": 4.9142857142857145e-06,
      "loss": 0.0,
      "step": 13200
    },
    {
      "epoch": 7.548571428571429,
      "grad_norm": 0.00014899425150360912,
      "learning_rate": 4.902857142857143e-06,
      "loss": 0.0008,
      "step": 13210
    },
    {
      "epoch": 7.554285714285714,
      "grad_norm": 0.0016929213888943195,
      "learning_rate": 4.891428571428572e-06,
      "loss": 0.0003,
      "step": 13220
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.0003380620910320431,
      "learning_rate": 4.880000000000001e-06,
      "loss": 0.0001,
      "step": 13230
    },
    {
      "epoch": 7.565714285714286,
      "grad_norm": 0.0002711036941036582,
      "learning_rate": 4.868571428571429e-06,
      "loss": 0.0,
      "step": 13240
    },
    {
      "epoch": 7.571428571428571,
      "grad_norm": 0.0004341956228017807,
      "learning_rate": 4.857142857142858e-06,
      "loss": 0.0,
      "step": 13250
    },
    {
      "epoch": 7.577142857142857,
      "grad_norm": 0.005398602690547705,
      "learning_rate": 4.845714285714286e-06,
      "loss": 0.0,
      "step": 13260
    },
    {
      "epoch": 7.582857142857143,
      "grad_norm": 0.0012247210834175348,
      "learning_rate": 4.8342857142857145e-06,
      "loss": 0.0151,
      "step": 13270
    },
    {
      "epoch": 7.588571428571429,
      "grad_norm": 0.0014981301501393318,
      "learning_rate": 4.822857142857143e-06,
      "loss": 0.0,
      "step": 13280
    },
    {
      "epoch": 7.594285714285714,
      "grad_norm": 0.0003626719699241221,
      "learning_rate": 4.811428571428572e-06,
      "loss": 0.0,
      "step": 13290
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.17105822265148163,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0477,
      "step": 13300
    },
    {
      "epoch": 7.605714285714286,
      "grad_norm": 0.004078974481672049,
      "learning_rate": 4.788571428571429e-06,
      "loss": 0.0001,
      "step": 13310
    },
    {
      "epoch": 7.611428571428571,
      "grad_norm": 0.011395358480513096,
      "learning_rate": 4.7771428571428575e-06,
      "loss": 0.0,
      "step": 13320
    },
    {
      "epoch": 7.617142857142857,
      "grad_norm": 0.004948683548718691,
      "learning_rate": 4.765714285714286e-06,
      "loss": 0.0004,
      "step": 13330
    },
    {
      "epoch": 7.622857142857143,
      "grad_norm": 0.001643814379349351,
      "learning_rate": 4.754285714285714e-06,
      "loss": 0.063,
      "step": 13340
    },
    {
      "epoch": 7.628571428571428,
      "grad_norm": 0.00037978714681230485,
      "learning_rate": 4.742857142857144e-06,
      "loss": 0.0072,
      "step": 13350
    },
    {
      "epoch": 7.634285714285714,
      "grad_norm": 0.00043842376908287406,
      "learning_rate": 4.731428571428572e-06,
      "loss": 0.0389,
      "step": 13360
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.17722411453723907,
      "learning_rate": 4.7200000000000005e-06,
      "loss": 0.0,
      "step": 13370
    },
    {
      "epoch": 7.645714285714286,
      "grad_norm": 0.004132702946662903,
      "learning_rate": 4.708571428571429e-06,
      "loss": 0.0,
      "step": 13380
    },
    {
      "epoch": 7.651428571428571,
      "grad_norm": 0.0010123801184818149,
      "learning_rate": 4.6971428571428574e-06,
      "loss": 0.0003,
      "step": 13390
    },
    {
      "epoch": 7.6571428571428575,
      "grad_norm": 0.0013480469351634383,
      "learning_rate": 4.685714285714286e-06,
      "loss": 0.0005,
      "step": 13400
    },
    {
      "epoch": 7.662857142857143,
      "grad_norm": 0.0006869115750305355,
      "learning_rate": 4.674285714285714e-06,
      "loss": 0.0,
      "step": 13410
    },
    {
      "epoch": 7.668571428571429,
      "grad_norm": 0.0006827949546277523,
      "learning_rate": 4.662857142857144e-06,
      "loss": 0.0004,
      "step": 13420
    },
    {
      "epoch": 7.674285714285714,
      "grad_norm": 0.0009497657301835716,
      "learning_rate": 4.651428571428572e-06,
      "loss": 0.0,
      "step": 13430
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.0004536343622021377,
      "learning_rate": 4.6400000000000005e-06,
      "loss": 0.0424,
      "step": 13440
    },
    {
      "epoch": 7.685714285714286,
      "grad_norm": 2.8895087242126465,
      "learning_rate": 4.628571428571429e-06,
      "loss": 0.0019,
      "step": 13450
    },
    {
      "epoch": 7.691428571428571,
      "grad_norm": 0.001038297894410789,
      "learning_rate": 4.617142857142857e-06,
      "loss": 0.0,
      "step": 13460
    },
    {
      "epoch": 7.6971428571428575,
      "grad_norm": 0.0008870497695170343,
      "learning_rate": 4.605714285714286e-06,
      "loss": 0.0393,
      "step": 13470
    },
    {
      "epoch": 7.702857142857143,
      "grad_norm": 0.013421679846942425,
      "learning_rate": 4.594285714285714e-06,
      "loss": 0.0,
      "step": 13480
    },
    {
      "epoch": 7.708571428571428,
      "grad_norm": 0.0009299613302573562,
      "learning_rate": 4.5828571428571435e-06,
      "loss": 0.0001,
      "step": 13490
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 0.00034950199187733233,
      "learning_rate": 4.571428571428572e-06,
      "loss": 0.0516,
      "step": 13500
    },
    {
      "epoch": 7.72,
      "grad_norm": 0.0005891796317882836,
      "learning_rate": 4.56e-06,
      "loss": 0.0001,
      "step": 13510
    },
    {
      "epoch": 7.725714285714286,
      "grad_norm": 0.0009492509416304529,
      "learning_rate": 4.548571428571429e-06,
      "loss": 0.0926,
      "step": 13520
    },
    {
      "epoch": 7.731428571428571,
      "grad_norm": 0.00042709463741630316,
      "learning_rate": 4.537142857142858e-06,
      "loss": 0.0199,
      "step": 13530
    },
    {
      "epoch": 7.737142857142857,
      "grad_norm": 0.0014649132499471307,
      "learning_rate": 4.525714285714286e-06,
      "loss": 0.0,
      "step": 13540
    },
    {
      "epoch": 7.742857142857143,
      "grad_norm": 0.0011248259106650949,
      "learning_rate": 4.514285714285714e-06,
      "loss": 0.0002,
      "step": 13550
    },
    {
      "epoch": 7.748571428571428,
      "grad_norm": 0.0016701860586181283,
      "learning_rate": 4.5028571428571434e-06,
      "loss": 0.0,
      "step": 13560
    },
    {
      "epoch": 7.7542857142857144,
      "grad_norm": 0.10220485180616379,
      "learning_rate": 4.491428571428572e-06,
      "loss": 0.0001,
      "step": 13570
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.0060313185676932335,
      "learning_rate": 4.48e-06,
      "loss": 0.0001,
      "step": 13580
    },
    {
      "epoch": 7.765714285714286,
      "grad_norm": 25.947368621826172,
      "learning_rate": 4.468571428571429e-06,
      "loss": 0.0452,
      "step": 13590
    },
    {
      "epoch": 7.771428571428571,
      "grad_norm": 0.0006859920104034245,
      "learning_rate": 4.457142857142858e-06,
      "loss": 0.006,
      "step": 13600
    },
    {
      "epoch": 7.777142857142858,
      "grad_norm": 0.002017405815422535,
      "learning_rate": 4.445714285714286e-06,
      "loss": 0.0,
      "step": 13610
    },
    {
      "epoch": 7.782857142857143,
      "grad_norm": 0.007035823073238134,
      "learning_rate": 4.434285714285715e-06,
      "loss": 0.0003,
      "step": 13620
    },
    {
      "epoch": 7.788571428571428,
      "grad_norm": 0.0004708686610683799,
      "learning_rate": 4.422857142857143e-06,
      "loss": 0.0,
      "step": 13630
    },
    {
      "epoch": 7.7942857142857145,
      "grad_norm": 0.0021527644712477922,
      "learning_rate": 4.411428571428572e-06,
      "loss": 0.0,
      "step": 13640
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.005070895422250032,
      "learning_rate": 4.4e-06,
      "loss": 0.0477,
      "step": 13650
    },
    {
      "epoch": 7.805714285714286,
      "grad_norm": 0.0005615378031507134,
      "learning_rate": 4.388571428571429e-06,
      "loss": 0.0007,
      "step": 13660
    },
    {
      "epoch": 7.811428571428571,
      "grad_norm": 0.0024287160485982895,
      "learning_rate": 4.377142857142858e-06,
      "loss": 0.0,
      "step": 13670
    },
    {
      "epoch": 7.817142857142857,
      "grad_norm": 0.0006402501603588462,
      "learning_rate": 4.3657142857142855e-06,
      "loss": 0.0,
      "step": 13680
    },
    {
      "epoch": 7.822857142857143,
      "grad_norm": 0.00034744973527267575,
      "learning_rate": 4.354285714285715e-06,
      "loss": 0.0,
      "step": 13690
    },
    {
      "epoch": 7.828571428571428,
      "grad_norm": 0.002154596848413348,
      "learning_rate": 4.342857142857143e-06,
      "loss": 0.0,
      "step": 13700
    },
    {
      "epoch": 7.8342857142857145,
      "grad_norm": 18.96277618408203,
      "learning_rate": 4.331428571428572e-06,
      "loss": 0.0409,
      "step": 13710
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.00046402495354413986,
      "learning_rate": 4.32e-06,
      "loss": 0.0,
      "step": 13720
    },
    {
      "epoch": 7.845714285714286,
      "grad_norm": 0.0013465953525155783,
      "learning_rate": 4.3085714285714294e-06,
      "loss": 0.0,
      "step": 13730
    },
    {
      "epoch": 7.851428571428571,
      "grad_norm": 0.05516861379146576,
      "learning_rate": 4.297142857142858e-06,
      "loss": 0.0026,
      "step": 13740
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 0.04704827815294266,
      "learning_rate": 4.2857142857142855e-06,
      "loss": 0.0001,
      "step": 13750
    },
    {
      "epoch": 7.862857142857143,
      "grad_norm": 0.008101429790258408,
      "learning_rate": 4.274285714285715e-06,
      "loss": 0.0175,
      "step": 13760
    },
    {
      "epoch": 7.868571428571428,
      "grad_norm": 0.006671302020549774,
      "learning_rate": 4.262857142857143e-06,
      "loss": 0.0015,
      "step": 13770
    },
    {
      "epoch": 7.8742857142857146,
      "grad_norm": 0.0012291517341509461,
      "learning_rate": 4.251428571428572e-06,
      "loss": 0.0484,
      "step": 13780
    },
    {
      "epoch": 7.88,
      "grad_norm": 4.096216201782227,
      "learning_rate": 4.24e-06,
      "loss": 0.0029,
      "step": 13790
    },
    {
      "epoch": 7.885714285714286,
      "grad_norm": 0.0008817834896035492,
      "learning_rate": 4.228571428571429e-06,
      "loss": 0.0001,
      "step": 13800
    },
    {
      "epoch": 7.8914285714285715,
      "grad_norm": 0.008207072503864765,
      "learning_rate": 4.217142857142858e-06,
      "loss": 0.0001,
      "step": 13810
    },
    {
      "epoch": 7.897142857142857,
      "grad_norm": 0.019403086975216866,
      "learning_rate": 4.205714285714286e-06,
      "loss": 0.0002,
      "step": 13820
    },
    {
      "epoch": 7.902857142857143,
      "grad_norm": 0.003468796843662858,
      "learning_rate": 4.194285714285715e-06,
      "loss": 0.0,
      "step": 13830
    },
    {
      "epoch": 7.908571428571428,
      "grad_norm": 1.087048053741455,
      "learning_rate": 4.182857142857143e-06,
      "loss": 0.0001,
      "step": 13840
    },
    {
      "epoch": 7.914285714285715,
      "grad_norm": 0.0627819374203682,
      "learning_rate": 4.1714285714285715e-06,
      "loss": 0.0,
      "step": 13850
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.04037048667669296,
      "learning_rate": 4.16e-06,
      "loss": 0.01,
      "step": 13860
    },
    {
      "epoch": 7.925714285714285,
      "grad_norm": 0.0033112424425780773,
      "learning_rate": 4.148571428571429e-06,
      "loss": 0.0,
      "step": 13870
    },
    {
      "epoch": 7.9314285714285715,
      "grad_norm": 0.029966920614242554,
      "learning_rate": 4.137142857142858e-06,
      "loss": 0.0234,
      "step": 13880
    },
    {
      "epoch": 7.937142857142857,
      "grad_norm": 0.0005397904315032065,
      "learning_rate": 4.125714285714286e-06,
      "loss": 0.0029,
      "step": 13890
    },
    {
      "epoch": 7.942857142857143,
      "grad_norm": 0.0030820462852716446,
      "learning_rate": 4.114285714285715e-06,
      "loss": 0.0001,
      "step": 13900
    },
    {
      "epoch": 7.948571428571428,
      "grad_norm": 0.0019529848359525204,
      "learning_rate": 4.102857142857143e-06,
      "loss": 0.0001,
      "step": 13910
    },
    {
      "epoch": 7.954285714285715,
      "grad_norm": 0.003975846339017153,
      "learning_rate": 4.0914285714285715e-06,
      "loss": 0.0005,
      "step": 13920
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.035550735890865326,
      "learning_rate": 4.08e-06,
      "loss": 0.0,
      "step": 13930
    },
    {
      "epoch": 7.965714285714286,
      "grad_norm": 0.0006530587561428547,
      "learning_rate": 4.068571428571429e-06,
      "loss": 0.0,
      "step": 13940
    },
    {
      "epoch": 7.9714285714285715,
      "grad_norm": 0.0012660862412303686,
      "learning_rate": 4.057142857142858e-06,
      "loss": 0.0462,
      "step": 13950
    },
    {
      "epoch": 7.977142857142857,
      "grad_norm": 0.0011242779437452555,
      "learning_rate": 4.045714285714286e-06,
      "loss": 0.0,
      "step": 13960
    },
    {
      "epoch": 7.982857142857143,
      "grad_norm": 0.019782066345214844,
      "learning_rate": 4.0342857142857145e-06,
      "loss": 0.0002,
      "step": 13970
    },
    {
      "epoch": 7.988571428571428,
      "grad_norm": 0.007307395339012146,
      "learning_rate": 4.022857142857143e-06,
      "loss": 0.0,
      "step": 13980
    },
    {
      "epoch": 7.994285714285715,
      "grad_norm": 0.0005978921544738114,
      "learning_rate": 4.011428571428571e-06,
      "loss": 0.0,
      "step": 13990
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.0009360897238366306,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0001,
      "step": 14000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.986129679144385,
      "eval_f1": 0.9370735405610311,
      "eval_loss": 0.11359693109989166,
      "eval_precision": 0.9507692307692308,
      "eval_recall": 0.9237668161434978,
      "eval_runtime": 55.4252,
      "eval_samples_per_second": 108.254,
      "eval_steps_per_second": 3.392,
      "step": 14000
    },
    {
      "epoch": 8.005714285714285,
      "grad_norm": 0.18297423422336578,
      "learning_rate": 3.988571428571429e-06,
      "loss": 0.0001,
      "step": 14010
    },
    {
      "epoch": 8.01142857142857,
      "grad_norm": 0.00020524450519587845,
      "learning_rate": 3.9771428571428575e-06,
      "loss": 0.0,
      "step": 14020
    },
    {
      "epoch": 8.017142857142858,
      "grad_norm": 0.0020934168715029955,
      "learning_rate": 3.965714285714286e-06,
      "loss": 0.0,
      "step": 14030
    },
    {
      "epoch": 8.022857142857143,
      "grad_norm": 0.09376854449510574,
      "learning_rate": 3.954285714285714e-06,
      "loss": 0.0,
      "step": 14040
    },
    {
      "epoch": 8.028571428571428,
      "grad_norm": 0.0005907726008445024,
      "learning_rate": 3.942857142857143e-06,
      "loss": 0.0,
      "step": 14050
    },
    {
      "epoch": 8.034285714285714,
      "grad_norm": 0.00045951484935358167,
      "learning_rate": 3.931428571428571e-06,
      "loss": 0.0,
      "step": 14060
    },
    {
      "epoch": 8.04,
      "grad_norm": 0.0002810719015542418,
      "learning_rate": 3.920000000000001e-06,
      "loss": 0.0,
      "step": 14070
    },
    {
      "epoch": 8.045714285714286,
      "grad_norm": 0.0003167369868606329,
      "learning_rate": 3.908571428571429e-06,
      "loss": 0.0,
      "step": 14080
    },
    {
      "epoch": 8.051428571428572,
      "grad_norm": 0.0012422848958522081,
      "learning_rate": 3.8971428571428575e-06,
      "loss": 0.0001,
      "step": 14090
    },
    {
      "epoch": 8.057142857142857,
      "grad_norm": 0.0009003312443383038,
      "learning_rate": 3.885714285714286e-06,
      "loss": 0.0,
      "step": 14100
    },
    {
      "epoch": 8.062857142857142,
      "grad_norm": 0.00020426107221283019,
      "learning_rate": 3.874285714285715e-06,
      "loss": 0.0,
      "step": 14110
    },
    {
      "epoch": 8.06857142857143,
      "grad_norm": 0.0008709777612239122,
      "learning_rate": 3.862857142857143e-06,
      "loss": 0.0,
      "step": 14120
    },
    {
      "epoch": 8.074285714285715,
      "grad_norm": 0.002056953264400363,
      "learning_rate": 3.851428571428571e-06,
      "loss": 0.0,
      "step": 14130
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.0013235006481409073,
      "learning_rate": 3.8400000000000005e-06,
      "loss": 0.0,
      "step": 14140
    },
    {
      "epoch": 8.085714285714285,
      "grad_norm": 0.0008770783897489309,
      "learning_rate": 3.828571428571429e-06,
      "loss": 0.0713,
      "step": 14150
    },
    {
      "epoch": 8.09142857142857,
      "grad_norm": 0.000764071533922106,
      "learning_rate": 3.817142857142857e-06,
      "loss": 0.0,
      "step": 14160
    },
    {
      "epoch": 8.097142857142858,
      "grad_norm": 0.31293782591819763,
      "learning_rate": 3.805714285714286e-06,
      "loss": 0.0001,
      "step": 14170
    },
    {
      "epoch": 8.102857142857143,
      "grad_norm": 0.0007350147934630513,
      "learning_rate": 3.7942857142857147e-06,
      "loss": 0.0,
      "step": 14180
    },
    {
      "epoch": 8.108571428571429,
      "grad_norm": 10.240263938903809,
      "learning_rate": 3.782857142857143e-06,
      "loss": 0.0575,
      "step": 14190
    },
    {
      "epoch": 8.114285714285714,
      "grad_norm": 0.010192250832915306,
      "learning_rate": 3.771428571428572e-06,
      "loss": 0.0001,
      "step": 14200
    },
    {
      "epoch": 8.12,
      "grad_norm": 0.001093752682209015,
      "learning_rate": 3.7600000000000004e-06,
      "loss": 0.0,
      "step": 14210
    },
    {
      "epoch": 8.125714285714286,
      "grad_norm": 0.007174139376729727,
      "learning_rate": 3.7485714285714284e-06,
      "loss": 0.0,
      "step": 14220
    },
    {
      "epoch": 8.131428571428572,
      "grad_norm": 0.01554351206868887,
      "learning_rate": 3.7371428571428577e-06,
      "loss": 0.0,
      "step": 14230
    },
    {
      "epoch": 8.137142857142857,
      "grad_norm": 0.001753361662849784,
      "learning_rate": 3.7257142857142857e-06,
      "loss": 0.0,
      "step": 14240
    },
    {
      "epoch": 8.142857142857142,
      "grad_norm": 0.0007199987885542214,
      "learning_rate": 3.7142857142857146e-06,
      "loss": 0.0001,
      "step": 14250
    },
    {
      "epoch": 8.14857142857143,
      "grad_norm": 0.0024852133356034756,
      "learning_rate": 3.702857142857143e-06,
      "loss": 0.0008,
      "step": 14260
    },
    {
      "epoch": 8.154285714285715,
      "grad_norm": 0.018437184393405914,
      "learning_rate": 3.691428571428572e-06,
      "loss": 0.0001,
      "step": 14270
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.000350028247339651,
      "learning_rate": 3.6800000000000003e-06,
      "loss": 0.0001,
      "step": 14280
    },
    {
      "epoch": 8.165714285714285,
      "grad_norm": 0.1545986533164978,
      "learning_rate": 3.668571428571429e-06,
      "loss": 0.0,
      "step": 14290
    },
    {
      "epoch": 8.17142857142857,
      "grad_norm": 0.0006550265243276954,
      "learning_rate": 3.6571428571428576e-06,
      "loss": 0.0052,
      "step": 14300
    },
    {
      "epoch": 8.177142857142858,
      "grad_norm": 0.007441574241966009,
      "learning_rate": 3.6457142857142857e-06,
      "loss": 0.0,
      "step": 14310
    },
    {
      "epoch": 8.182857142857143,
      "grad_norm": 0.0009434358216822147,
      "learning_rate": 3.6342857142857145e-06,
      "loss": 0.0039,
      "step": 14320
    },
    {
      "epoch": 8.188571428571429,
      "grad_norm": 0.0006067342474125326,
      "learning_rate": 3.622857142857143e-06,
      "loss": 0.0,
      "step": 14330
    },
    {
      "epoch": 8.194285714285714,
      "grad_norm": 0.007260845974087715,
      "learning_rate": 3.611428571428572e-06,
      "loss": 0.0196,
      "step": 14340
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.0007308119675144553,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.0,
      "step": 14350
    },
    {
      "epoch": 8.205714285714286,
      "grad_norm": 0.00015727368008811027,
      "learning_rate": 3.588571428571429e-06,
      "loss": 0.0,
      "step": 14360
    },
    {
      "epoch": 8.211428571428572,
      "grad_norm": 0.0007539259386248887,
      "learning_rate": 3.5771428571428576e-06,
      "loss": 0.0,
      "step": 14370
    },
    {
      "epoch": 8.217142857142857,
      "grad_norm": 0.00025343222660012543,
      "learning_rate": 3.5657142857142864e-06,
      "loss": 0.0297,
      "step": 14380
    },
    {
      "epoch": 8.222857142857142,
      "grad_norm": 0.000485872442368418,
      "learning_rate": 3.5542857142857144e-06,
      "loss": 0.0,
      "step": 14390
    },
    {
      "epoch": 8.228571428571428,
      "grad_norm": 0.001240017358213663,
      "learning_rate": 3.542857142857143e-06,
      "loss": 0.0,
      "step": 14400
    },
    {
      "epoch": 8.234285714285715,
      "grad_norm": 6.609251022338867,
      "learning_rate": 3.5314285714285717e-06,
      "loss": 0.0291,
      "step": 14410
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.00044370294199325144,
      "learning_rate": 3.52e-06,
      "loss": 0.0,
      "step": 14420
    },
    {
      "epoch": 8.245714285714286,
      "grad_norm": 0.00012566304940264672,
      "learning_rate": 3.508571428571429e-06,
      "loss": 0.0,
      "step": 14430
    },
    {
      "epoch": 8.251428571428571,
      "grad_norm": 0.002614747965708375,
      "learning_rate": 3.4971428571428575e-06,
      "loss": 0.0001,
      "step": 14440
    },
    {
      "epoch": 8.257142857142856,
      "grad_norm": 0.00016472027346026152,
      "learning_rate": 3.4857142857142863e-06,
      "loss": 0.0173,
      "step": 14450
    },
    {
      "epoch": 8.262857142857143,
      "grad_norm": 0.00021427992032840848,
      "learning_rate": 3.4742857142857144e-06,
      "loss": 0.0,
      "step": 14460
    },
    {
      "epoch": 8.268571428571429,
      "grad_norm": 0.0022965886164456606,
      "learning_rate": 3.4628571428571432e-06,
      "loss": 0.0004,
      "step": 14470
    },
    {
      "epoch": 8.274285714285714,
      "grad_norm": 0.00013468782708514482,
      "learning_rate": 3.4514285714285717e-06,
      "loss": 0.003,
      "step": 14480
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.0004389588430058211,
      "learning_rate": 3.44e-06,
      "loss": 0.0,
      "step": 14490
    },
    {
      "epoch": 8.285714285714286,
      "grad_norm": 0.0003018370480276644,
      "learning_rate": 3.428571428571429e-06,
      "loss": 0.0,
      "step": 14500
    },
    {
      "epoch": 8.291428571428572,
      "grad_norm": 0.005564380437135696,
      "learning_rate": 3.4171428571428574e-06,
      "loss": 0.0,
      "step": 14510
    },
    {
      "epoch": 8.297142857142857,
      "grad_norm": 0.00032138402457349,
      "learning_rate": 3.4057142857142863e-06,
      "loss": 0.0,
      "step": 14520
    },
    {
      "epoch": 8.302857142857142,
      "grad_norm": 0.0003997801395598799,
      "learning_rate": 3.3942857142857143e-06,
      "loss": 0.0001,
      "step": 14530
    },
    {
      "epoch": 8.308571428571428,
      "grad_norm": 0.0009492830140516162,
      "learning_rate": 3.382857142857143e-06,
      "loss": 0.0001,
      "step": 14540
    },
    {
      "epoch": 8.314285714285715,
      "grad_norm": 0.0023256479762494564,
      "learning_rate": 3.3714285714285716e-06,
      "loss": 0.0001,
      "step": 14550
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.002175696659833193,
      "learning_rate": 3.3600000000000004e-06,
      "loss": 0.0039,
      "step": 14560
    },
    {
      "epoch": 8.325714285714286,
      "grad_norm": 0.0003325418510939926,
      "learning_rate": 3.348571428571429e-06,
      "loss": 0.0055,
      "step": 14570
    },
    {
      "epoch": 8.331428571428571,
      "grad_norm": 0.0003181579813826829,
      "learning_rate": 3.3371428571428577e-06,
      "loss": 0.0,
      "step": 14580
    },
    {
      "epoch": 8.337142857142856,
      "grad_norm": 0.0003017149574588984,
      "learning_rate": 3.325714285714286e-06,
      "loss": 0.0,
      "step": 14590
    },
    {
      "epoch": 8.342857142857143,
      "grad_norm": 0.0011034697527065873,
      "learning_rate": 3.314285714285714e-06,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 8.348571428571429,
      "grad_norm": 0.0012664376990869641,
      "learning_rate": 3.302857142857143e-06,
      "loss": 0.0,
      "step": 14610
    },
    {
      "epoch": 8.354285714285714,
      "grad_norm": 0.001688826479949057,
      "learning_rate": 3.2914285714285715e-06,
      "loss": 0.0,
      "step": 14620
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.0023055572528392076,
      "learning_rate": 3.2800000000000004e-06,
      "loss": 0.0,
      "step": 14630
    },
    {
      "epoch": 8.365714285714287,
      "grad_norm": 0.0004604747227858752,
      "learning_rate": 3.268571428571429e-06,
      "loss": 0.0005,
      "step": 14640
    },
    {
      "epoch": 8.371428571428572,
      "grad_norm": 8.699917793273926,
      "learning_rate": 3.2571428571428577e-06,
      "loss": 0.0686,
      "step": 14650
    },
    {
      "epoch": 8.377142857142857,
      "grad_norm": 0.0003205047978553921,
      "learning_rate": 3.245714285714286e-06,
      "loss": 0.0,
      "step": 14660
    },
    {
      "epoch": 8.382857142857143,
      "grad_norm": 0.001075536129064858,
      "learning_rate": 3.234285714285715e-06,
      "loss": 0.0,
      "step": 14670
    },
    {
      "epoch": 8.388571428571428,
      "grad_norm": 0.00012966459325980395,
      "learning_rate": 3.222857142857143e-06,
      "loss": 0.0155,
      "step": 14680
    },
    {
      "epoch": 8.394285714285715,
      "grad_norm": 5.884185314178467,
      "learning_rate": 3.2114285714285714e-06,
      "loss": 0.0047,
      "step": 14690
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.0004013319266960025,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0,
      "step": 14700
    },
    {
      "epoch": 8.405714285714286,
      "grad_norm": 0.000448644655989483,
      "learning_rate": 3.1885714285714287e-06,
      "loss": 0.0001,
      "step": 14710
    },
    {
      "epoch": 8.411428571428571,
      "grad_norm": 0.0002672624250408262,
      "learning_rate": 3.1771428571428576e-06,
      "loss": 0.0,
      "step": 14720
    },
    {
      "epoch": 8.417142857142856,
      "grad_norm": 0.00139656662940979,
      "learning_rate": 3.165714285714286e-06,
      "loss": 0.0167,
      "step": 14730
    },
    {
      "epoch": 8.422857142857143,
      "grad_norm": 0.0014610373182222247,
      "learning_rate": 3.154285714285715e-06,
      "loss": 0.0,
      "step": 14740
    },
    {
      "epoch": 8.428571428571429,
      "grad_norm": 0.0005166677292436361,
      "learning_rate": 3.142857142857143e-06,
      "loss": 0.0,
      "step": 14750
    },
    {
      "epoch": 8.434285714285714,
      "grad_norm": 0.0020961060654371977,
      "learning_rate": 3.1314285714285718e-06,
      "loss": 0.0002,
      "step": 14760
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.0007808086811564863,
      "learning_rate": 3.12e-06,
      "loss": 0.0,
      "step": 14770
    },
    {
      "epoch": 8.445714285714285,
      "grad_norm": 0.0009499128209426999,
      "learning_rate": 3.1085714285714286e-06,
      "loss": 0.0,
      "step": 14780
    },
    {
      "epoch": 8.451428571428572,
      "grad_norm": 0.0007067289552651346,
      "learning_rate": 3.0971428571428575e-06,
      "loss": 0.0,
      "step": 14790
    },
    {
      "epoch": 8.457142857142857,
      "grad_norm": 0.0014576002722606063,
      "learning_rate": 3.085714285714286e-06,
      "loss": 0.0,
      "step": 14800
    },
    {
      "epoch": 8.462857142857143,
      "grad_norm": 0.003825282445177436,
      "learning_rate": 3.074285714285715e-06,
      "loss": 0.0,
      "step": 14810
    },
    {
      "epoch": 8.468571428571428,
      "grad_norm": 25.309934616088867,
      "learning_rate": 3.062857142857143e-06,
      "loss": 0.0366,
      "step": 14820
    },
    {
      "epoch": 8.474285714285715,
      "grad_norm": 0.0004785032942891121,
      "learning_rate": 3.0514285714285717e-06,
      "loss": 0.0,
      "step": 14830
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.0011102409334853292,
      "learning_rate": 3.04e-06,
      "loss": 0.0,
      "step": 14840
    },
    {
      "epoch": 8.485714285714286,
      "grad_norm": 0.0009772609919309616,
      "learning_rate": 3.028571428571429e-06,
      "loss": 0.0002,
      "step": 14850
    },
    {
      "epoch": 8.491428571428571,
      "grad_norm": 0.00024131298414431512,
      "learning_rate": 3.0171428571428574e-06,
      "loss": 0.0002,
      "step": 14860
    },
    {
      "epoch": 8.497142857142856,
      "grad_norm": 0.0003981843183282763,
      "learning_rate": 3.005714285714286e-06,
      "loss": 0.0,
      "step": 14870
    },
    {
      "epoch": 8.502857142857144,
      "grad_norm": 0.0008868855657055974,
      "learning_rate": 2.9942857142857147e-06,
      "loss": 0.0,
      "step": 14880
    },
    {
      "epoch": 8.508571428571429,
      "grad_norm": 0.0006890961085446179,
      "learning_rate": 2.9828571428571427e-06,
      "loss": 0.0,
      "step": 14890
    },
    {
      "epoch": 8.514285714285714,
      "grad_norm": 0.00040999019984155893,
      "learning_rate": 2.9714285714285716e-06,
      "loss": 0.0,
      "step": 14900
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.00024023590958677232,
      "learning_rate": 2.96e-06,
      "loss": 0.0001,
      "step": 14910
    },
    {
      "epoch": 8.525714285714285,
      "grad_norm": 0.00014915905194357038,
      "learning_rate": 2.948571428571429e-06,
      "loss": 0.0,
      "step": 14920
    },
    {
      "epoch": 8.531428571428572,
      "grad_norm": 0.0036511081270873547,
      "learning_rate": 2.9371428571428573e-06,
      "loss": 0.0,
      "step": 14930
    },
    {
      "epoch": 8.537142857142857,
      "grad_norm": 0.028344815596938133,
      "learning_rate": 2.925714285714286e-06,
      "loss": 0.0,
      "step": 14940
    },
    {
      "epoch": 8.542857142857143,
      "grad_norm": 0.00028278425452299416,
      "learning_rate": 2.9142857142857146e-06,
      "loss": 0.0295,
      "step": 14950
    },
    {
      "epoch": 8.548571428571428,
      "grad_norm": 0.000995233771391213,
      "learning_rate": 2.9028571428571427e-06,
      "loss": 0.0,
      "step": 14960
    },
    {
      "epoch": 8.554285714285715,
      "grad_norm": 0.005160648375749588,
      "learning_rate": 2.8914285714285715e-06,
      "loss": 0.001,
      "step": 14970
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.00029354376601986587,
      "learning_rate": 2.88e-06,
      "loss": 0.0,
      "step": 14980
    },
    {
      "epoch": 8.565714285714286,
      "grad_norm": 0.00024252018192782998,
      "learning_rate": 2.868571428571429e-06,
      "loss": 0.0,
      "step": 14990
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.0005411190795712173,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.0001,
      "step": 15000
    },
    {
      "epoch": 8.577142857142857,
      "grad_norm": 0.00129934202414006,
      "learning_rate": 2.845714285714286e-06,
      "loss": 0.0001,
      "step": 15010
    },
    {
      "epoch": 8.582857142857144,
      "grad_norm": 0.0002935989759862423,
      "learning_rate": 2.8342857142857146e-06,
      "loss": 0.0,
      "step": 15020
    },
    {
      "epoch": 8.588571428571429,
      "grad_norm": 0.0016321999719366431,
      "learning_rate": 2.8228571428571434e-06,
      "loss": 0.0327,
      "step": 15030
    },
    {
      "epoch": 8.594285714285714,
      "grad_norm": 0.00013511687575373799,
      "learning_rate": 2.8114285714285714e-06,
      "loss": 0.0,
      "step": 15040
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.0014687504153698683,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0062,
      "step": 15050
    },
    {
      "epoch": 8.605714285714285,
      "grad_norm": 0.00019550189608708024,
      "learning_rate": 2.7885714285714287e-06,
      "loss": 0.0,
      "step": 15060
    },
    {
      "epoch": 8.611428571428572,
      "grad_norm": 0.0018907930934801698,
      "learning_rate": 2.777142857142857e-06,
      "loss": 0.0,
      "step": 15070
    },
    {
      "epoch": 8.617142857142857,
      "grad_norm": 0.008226361125707626,
      "learning_rate": 2.765714285714286e-06,
      "loss": 0.0,
      "step": 15080
    },
    {
      "epoch": 8.622857142857143,
      "grad_norm": 0.0012090037344023585,
      "learning_rate": 2.7542857142857145e-06,
      "loss": 0.0,
      "step": 15090
    },
    {
      "epoch": 8.628571428571428,
      "grad_norm": 0.00030299180070869625,
      "learning_rate": 2.7428571428571433e-06,
      "loss": 0.0164,
      "step": 15100
    },
    {
      "epoch": 8.634285714285713,
      "grad_norm": 0.0015320851234719157,
      "learning_rate": 2.7314285714285714e-06,
      "loss": 0.0186,
      "step": 15110
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.0018889352213591337,
      "learning_rate": 2.7200000000000002e-06,
      "loss": 0.0,
      "step": 15120
    },
    {
      "epoch": 8.645714285714286,
      "grad_norm": 0.0017275535501539707,
      "learning_rate": 2.7085714285714287e-06,
      "loss": 0.0,
      "step": 15130
    },
    {
      "epoch": 8.651428571428571,
      "grad_norm": 0.021535564213991165,
      "learning_rate": 2.6971428571428575e-06,
      "loss": 0.0,
      "step": 15140
    },
    {
      "epoch": 8.657142857142857,
      "grad_norm": 0.0010874341242015362,
      "learning_rate": 2.685714285714286e-06,
      "loss": 0.0001,
      "step": 15150
    },
    {
      "epoch": 8.662857142857142,
      "grad_norm": 27.1119327545166,
      "learning_rate": 2.6742857142857144e-06,
      "loss": 0.0195,
      "step": 15160
    },
    {
      "epoch": 8.668571428571429,
      "grad_norm": 0.09128318727016449,
      "learning_rate": 2.6628571428571433e-06,
      "loss": 0.0478,
      "step": 15170
    },
    {
      "epoch": 8.674285714285714,
      "grad_norm": 0.00013131955347489566,
      "learning_rate": 2.6514285714285713e-06,
      "loss": 0.0,
      "step": 15180
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.0009068124927580357,
      "learning_rate": 2.64e-06,
      "loss": 0.0003,
      "step": 15190
    },
    {
      "epoch": 8.685714285714285,
      "grad_norm": 0.0008497246308252215,
      "learning_rate": 2.6285714285714286e-06,
      "loss": 0.0002,
      "step": 15200
    },
    {
      "epoch": 8.691428571428572,
      "grad_norm": 0.00011117559915874153,
      "learning_rate": 2.6171428571428574e-06,
      "loss": 0.0762,
      "step": 15210
    },
    {
      "epoch": 8.697142857142858,
      "grad_norm": 0.00035057152854278684,
      "learning_rate": 2.605714285714286e-06,
      "loss": 0.0,
      "step": 15220
    },
    {
      "epoch": 8.702857142857143,
      "grad_norm": 73.56163024902344,
      "learning_rate": 2.5942857142857147e-06,
      "loss": 0.0093,
      "step": 15230
    },
    {
      "epoch": 8.708571428571428,
      "grad_norm": 0.0004592377517838031,
      "learning_rate": 2.582857142857143e-06,
      "loss": 0.0,
      "step": 15240
    },
    {
      "epoch": 8.714285714285714,
      "grad_norm": 0.0004214361251797527,
      "learning_rate": 2.571428571428571e-06,
      "loss": 0.0,
      "step": 15250
    },
    {
      "epoch": 8.72,
      "grad_norm": 0.00039142227615229785,
      "learning_rate": 2.56e-06,
      "loss": 0.0,
      "step": 15260
    },
    {
      "epoch": 8.725714285714286,
      "grad_norm": 0.013162091374397278,
      "learning_rate": 2.5485714285714285e-06,
      "loss": 0.0,
      "step": 15270
    },
    {
      "epoch": 8.731428571428571,
      "grad_norm": 0.029704857617616653,
      "learning_rate": 2.5371428571428574e-06,
      "loss": 0.0,
      "step": 15280
    },
    {
      "epoch": 8.737142857142857,
      "grad_norm": 0.0008345555397681892,
      "learning_rate": 2.525714285714286e-06,
      "loss": 0.0,
      "step": 15290
    },
    {
      "epoch": 8.742857142857144,
      "grad_norm": 0.002835242310538888,
      "learning_rate": 2.5142857142857147e-06,
      "loss": 0.0,
      "step": 15300
    },
    {
      "epoch": 8.748571428571429,
      "grad_norm": 7.198099613189697,
      "learning_rate": 2.502857142857143e-06,
      "loss": 0.0741,
      "step": 15310
    },
    {
      "epoch": 8.754285714285714,
      "grad_norm": 0.00029081644606776536,
      "learning_rate": 2.4914285714285715e-06,
      "loss": 0.0,
      "step": 15320
    },
    {
      "epoch": 8.76,
      "grad_norm": 0.00033588812220841646,
      "learning_rate": 2.4800000000000004e-06,
      "loss": 0.0,
      "step": 15330
    },
    {
      "epoch": 8.765714285714285,
      "grad_norm": 0.00013229780597612262,
      "learning_rate": 2.468571428571429e-06,
      "loss": 0.0,
      "step": 15340
    },
    {
      "epoch": 8.771428571428572,
      "grad_norm": 0.00045938152470625937,
      "learning_rate": 2.4571428571428573e-06,
      "loss": 0.0,
      "step": 15350
    },
    {
      "epoch": 8.777142857142858,
      "grad_norm": 0.004045384936034679,
      "learning_rate": 2.445714285714286e-06,
      "loss": 0.0001,
      "step": 15360
    },
    {
      "epoch": 8.782857142857143,
      "grad_norm": 0.0005926565499976277,
      "learning_rate": 2.4342857142857146e-06,
      "loss": 0.0,
      "step": 15370
    },
    {
      "epoch": 8.788571428571428,
      "grad_norm": 50.836795806884766,
      "learning_rate": 2.422857142857143e-06,
      "loss": 0.0341,
      "step": 15380
    },
    {
      "epoch": 8.794285714285714,
      "grad_norm": 7.748679490759969e-05,
      "learning_rate": 2.4114285714285715e-06,
      "loss": 0.0,
      "step": 15390
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.00018937663116957992,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0003,
      "step": 15400
    },
    {
      "epoch": 8.805714285714286,
      "grad_norm": 0.0015854192897677422,
      "learning_rate": 2.3885714285714288e-06,
      "loss": 0.0,
      "step": 15410
    },
    {
      "epoch": 8.811428571428571,
      "grad_norm": 0.00037130009150132537,
      "learning_rate": 2.377142857142857e-06,
      "loss": 0.0,
      "step": 15420
    },
    {
      "epoch": 8.817142857142857,
      "grad_norm": 0.000339795631589368,
      "learning_rate": 2.365714285714286e-06,
      "loss": 0.0,
      "step": 15430
    },
    {
      "epoch": 8.822857142857142,
      "grad_norm": 0.0005070189945399761,
      "learning_rate": 2.3542857142857145e-06,
      "loss": 0.0828,
      "step": 15440
    },
    {
      "epoch": 8.82857142857143,
      "grad_norm": 0.00029450422152876854,
      "learning_rate": 2.342857142857143e-06,
      "loss": 0.0,
      "step": 15450
    },
    {
      "epoch": 8.834285714285715,
      "grad_norm": 0.0002959692501462996,
      "learning_rate": 2.331428571428572e-06,
      "loss": 0.0001,
      "step": 15460
    },
    {
      "epoch": 8.84,
      "grad_norm": 0.0003574420406948775,
      "learning_rate": 2.3200000000000002e-06,
      "loss": 0.0,
      "step": 15470
    },
    {
      "epoch": 8.845714285714285,
      "grad_norm": 0.0004900300991721451,
      "learning_rate": 2.3085714285714287e-06,
      "loss": 0.0282,
      "step": 15480
    },
    {
      "epoch": 8.85142857142857,
      "grad_norm": 0.0022578230127692223,
      "learning_rate": 2.297142857142857e-06,
      "loss": 0.0,
      "step": 15490
    },
    {
      "epoch": 8.857142857142858,
      "grad_norm": 0.000679502438288182,
      "learning_rate": 2.285714285714286e-06,
      "loss": 0.0003,
      "step": 15500
    },
    {
      "epoch": 8.862857142857143,
      "grad_norm": 0.00039680482586845756,
      "learning_rate": 2.2742857142857144e-06,
      "loss": 0.0071,
      "step": 15510
    },
    {
      "epoch": 8.868571428571428,
      "grad_norm": 0.00015235220780596137,
      "learning_rate": 2.262857142857143e-06,
      "loss": 0.0002,
      "step": 15520
    },
    {
      "epoch": 8.874285714285714,
      "grad_norm": 0.003746981965377927,
      "learning_rate": 2.2514285714285717e-06,
      "loss": 0.0262,
      "step": 15530
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.0005361416842788458,
      "learning_rate": 2.24e-06,
      "loss": 0.0388,
      "step": 15540
    },
    {
      "epoch": 8.885714285714286,
      "grad_norm": 0.00035514269256964326,
      "learning_rate": 2.228571428571429e-06,
      "loss": 0.0,
      "step": 15550
    },
    {
      "epoch": 8.891428571428571,
      "grad_norm": 0.0004448635154403746,
      "learning_rate": 2.2171428571428575e-06,
      "loss": 0.0,
      "step": 15560
    },
    {
      "epoch": 8.897142857142857,
      "grad_norm": 0.0004506806726567447,
      "learning_rate": 2.205714285714286e-06,
      "loss": 0.0,
      "step": 15570
    },
    {
      "epoch": 8.902857142857142,
      "grad_norm": 0.06902425736188889,
      "learning_rate": 2.1942857142857143e-06,
      "loss": 0.0004,
      "step": 15580
    },
    {
      "epoch": 8.90857142857143,
      "grad_norm": 0.0006509200902655721,
      "learning_rate": 2.1828571428571428e-06,
      "loss": 0.0153,
      "step": 15590
    },
    {
      "epoch": 8.914285714285715,
      "grad_norm": 0.0005322361248545349,
      "learning_rate": 2.1714285714285716e-06,
      "loss": 0.0,
      "step": 15600
    },
    {
      "epoch": 8.92,
      "grad_norm": 0.018262801691889763,
      "learning_rate": 2.16e-06,
      "loss": 0.0,
      "step": 15610
    },
    {
      "epoch": 8.925714285714285,
      "grad_norm": 0.0013030332047492266,
      "learning_rate": 2.148571428571429e-06,
      "loss": 0.0,
      "step": 15620
    },
    {
      "epoch": 8.93142857142857,
      "grad_norm": 0.0004774833214469254,
      "learning_rate": 2.1371428571428574e-06,
      "loss": 0.0001,
      "step": 15630
    },
    {
      "epoch": 8.937142857142858,
      "grad_norm": 0.001804565661586821,
      "learning_rate": 2.125714285714286e-06,
      "loss": 0.0,
      "step": 15640
    },
    {
      "epoch": 8.942857142857143,
      "grad_norm": 0.00023195930407382548,
      "learning_rate": 2.1142857142857147e-06,
      "loss": 0.0,
      "step": 15650
    },
    {
      "epoch": 8.948571428571428,
      "grad_norm": 0.00013804531772620976,
      "learning_rate": 2.102857142857143e-06,
      "loss": 0.0,
      "step": 15660
    },
    {
      "epoch": 8.954285714285714,
      "grad_norm": 0.0003083123592659831,
      "learning_rate": 2.0914285714285716e-06,
      "loss": 0.0,
      "step": 15670
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.0012340117245912552,
      "learning_rate": 2.08e-06,
      "loss": 0.0,
      "step": 15680
    },
    {
      "epoch": 8.965714285714286,
      "grad_norm": 9.113721898756921e-05,
      "learning_rate": 2.068571428571429e-06,
      "loss": 0.0,
      "step": 15690
    },
    {
      "epoch": 8.971428571428572,
      "grad_norm": 0.407266765832901,
      "learning_rate": 2.0571428571428573e-06,
      "loss": 0.0003,
      "step": 15700
    },
    {
      "epoch": 8.977142857142857,
      "grad_norm": 0.0001661739661358297,
      "learning_rate": 2.0457142857142857e-06,
      "loss": 0.0013,
      "step": 15710
    },
    {
      "epoch": 8.982857142857142,
      "grad_norm": 0.008095970377326012,
      "learning_rate": 2.0342857142857146e-06,
      "loss": 0.0324,
      "step": 15720
    },
    {
      "epoch": 8.98857142857143,
      "grad_norm": 0.0006305503193289042,
      "learning_rate": 2.022857142857143e-06,
      "loss": 0.0341,
      "step": 15730
    },
    {
      "epoch": 8.994285714285715,
      "grad_norm": 0.0005779506755061448,
      "learning_rate": 2.0114285714285715e-06,
      "loss": 0.0,
      "step": 15740
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.0030840844847261906,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0,
      "step": 15750
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9866310160427807,
      "eval_f1": 0.9396681749622927,
      "eval_loss": 0.10659632086753845,
      "eval_precision": 0.9482496194824962,
      "eval_recall": 0.9312406576980568,
      "eval_runtime": 53.4004,
      "eval_samples_per_second": 112.359,
      "eval_steps_per_second": 3.521,
      "step": 15750
    },
    {
      "epoch": 9.005714285714285,
      "grad_norm": 0.0004939843784086406,
      "learning_rate": 1.9885714285714288e-06,
      "loss": 0.0,
      "step": 15760
    },
    {
      "epoch": 9.01142857142857,
      "grad_norm": 0.0005462312255986035,
      "learning_rate": 1.977142857142857e-06,
      "loss": 0.0,
      "step": 15770
    },
    {
      "epoch": 9.017142857142858,
      "grad_norm": 0.003148409305140376,
      "learning_rate": 1.9657142857142856e-06,
      "loss": 0.0005,
      "step": 15780
    },
    {
      "epoch": 9.022857142857143,
      "grad_norm": 0.0008597249398007989,
      "learning_rate": 1.9542857142857145e-06,
      "loss": 0.0001,
      "step": 15790
    },
    {
      "epoch": 9.028571428571428,
      "grad_norm": 0.0015055870171636343,
      "learning_rate": 1.942857142857143e-06,
      "loss": 0.055,
      "step": 15800
    },
    {
      "epoch": 9.034285714285714,
      "grad_norm": 0.005458727478981018,
      "learning_rate": 1.9314285714285714e-06,
      "loss": 0.0,
      "step": 15810
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.0005434512859210372,
      "learning_rate": 1.9200000000000003e-06,
      "loss": 0.0043,
      "step": 15820
    },
    {
      "epoch": 9.045714285714286,
      "grad_norm": 9.69768880167976e-05,
      "learning_rate": 1.9085714285714287e-06,
      "loss": 0.0,
      "step": 15830
    },
    {
      "epoch": 9.051428571428572,
      "grad_norm": 0.0038096511270850897,
      "learning_rate": 1.8971428571428573e-06,
      "loss": 0.0001,
      "step": 15840
    },
    {
      "epoch": 9.057142857142857,
      "grad_norm": 0.0005465238937176764,
      "learning_rate": 1.885714285714286e-06,
      "loss": 0.0,
      "step": 15850
    },
    {
      "epoch": 9.062857142857142,
      "grad_norm": 0.0005962862633168697,
      "learning_rate": 1.8742857142857142e-06,
      "loss": 0.0,
      "step": 15860
    },
    {
      "epoch": 9.06857142857143,
      "grad_norm": 0.002149973763152957,
      "learning_rate": 1.8628571428571429e-06,
      "loss": 0.0,
      "step": 15870
    },
    {
      "epoch": 9.074285714285715,
      "grad_norm": 0.00012110416719224304,
      "learning_rate": 1.8514285714285715e-06,
      "loss": 0.0001,
      "step": 15880
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.00024417275562882423,
      "learning_rate": 1.8400000000000002e-06,
      "loss": 0.0,
      "step": 15890
    },
    {
      "epoch": 9.085714285714285,
      "grad_norm": 0.0009861787548288703,
      "learning_rate": 1.8285714285714288e-06,
      "loss": 0.0,
      "step": 15900
    },
    {
      "epoch": 9.09142857142857,
      "grad_norm": 0.014330179430544376,
      "learning_rate": 1.8171428571428573e-06,
      "loss": 0.0,
      "step": 15910
    },
    {
      "epoch": 9.097142857142858,
      "grad_norm": 0.00391986221075058,
      "learning_rate": 1.805714285714286e-06,
      "loss": 0.0,
      "step": 15920
    },
    {
      "epoch": 9.102857142857143,
      "grad_norm": 0.0014172681840136647,
      "learning_rate": 1.7942857142857146e-06,
      "loss": 0.0001,
      "step": 15930
    },
    {
      "epoch": 9.108571428571429,
      "grad_norm": 0.008223704993724823,
      "learning_rate": 1.7828571428571432e-06,
      "loss": 0.0001,
      "step": 15940
    },
    {
      "epoch": 9.114285714285714,
      "grad_norm": 0.0009259944199584424,
      "learning_rate": 1.7714285714285714e-06,
      "loss": 0.0,
      "step": 15950
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.000615057535469532,
      "learning_rate": 1.76e-06,
      "loss": 0.0739,
      "step": 15960
    },
    {
      "epoch": 9.125714285714286,
      "grad_norm": 0.1457255333662033,
      "learning_rate": 1.7485714285714287e-06,
      "loss": 0.0015,
      "step": 15970
    },
    {
      "epoch": 9.131428571428572,
      "grad_norm": 0.00021482803276740015,
      "learning_rate": 1.7371428571428572e-06,
      "loss": 0.0006,
      "step": 15980
    },
    {
      "epoch": 9.137142857142857,
      "grad_norm": 0.0002920701226685196,
      "learning_rate": 1.7257142857142858e-06,
      "loss": 0.0,
      "step": 15990
    },
    {
      "epoch": 9.142857142857142,
      "grad_norm": 0.0056835138238966465,
      "learning_rate": 1.7142857142857145e-06,
      "loss": 0.0,
      "step": 16000
    },
    {
      "epoch": 9.14857142857143,
      "grad_norm": 0.001478860736824572,
      "learning_rate": 1.7028571428571431e-06,
      "loss": 0.0,
      "step": 16010
    },
    {
      "epoch": 9.154285714285715,
      "grad_norm": 0.0001737425773171708,
      "learning_rate": 1.6914285714285716e-06,
      "loss": 0.0,
      "step": 16020
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.0023193780798465014,
      "learning_rate": 1.6800000000000002e-06,
      "loss": 0.0153,
      "step": 16030
    },
    {
      "epoch": 9.165714285714285,
      "grad_norm": 0.00045192736433818936,
      "learning_rate": 1.6685714285714289e-06,
      "loss": 0.0,
      "step": 16040
    },
    {
      "epoch": 9.17142857142857,
      "grad_norm": 0.24481850862503052,
      "learning_rate": 1.657142857142857e-06,
      "loss": 0.0,
      "step": 16050
    },
    {
      "epoch": 9.177142857142858,
      "grad_norm": 0.0009664898971095681,
      "learning_rate": 1.6457142857142857e-06,
      "loss": 0.0,
      "step": 16060
    },
    {
      "epoch": 9.182857142857143,
      "grad_norm": 0.00029147372697480023,
      "learning_rate": 1.6342857142857144e-06,
      "loss": 0.0,
      "step": 16070
    },
    {
      "epoch": 9.188571428571429,
      "grad_norm": 0.0004592687473632395,
      "learning_rate": 1.622857142857143e-06,
      "loss": 0.0,
      "step": 16080
    },
    {
      "epoch": 9.194285714285714,
      "grad_norm": 0.018220826983451843,
      "learning_rate": 1.6114285714285715e-06,
      "loss": 0.0,
      "step": 16090
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.0018557525472715497,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.0,
      "step": 16100
    },
    {
      "epoch": 9.205714285714286,
      "grad_norm": 0.003934107720851898,
      "learning_rate": 1.5885714285714288e-06,
      "loss": 0.0033,
      "step": 16110
    },
    {
      "epoch": 9.211428571428572,
      "grad_norm": 0.0029092617332935333,
      "learning_rate": 1.5771428571428574e-06,
      "loss": 0.032,
      "step": 16120
    },
    {
      "epoch": 9.217142857142857,
      "grad_norm": 0.0010933773592114449,
      "learning_rate": 1.5657142857142859e-06,
      "loss": 0.0,
      "step": 16130
    },
    {
      "epoch": 9.222857142857142,
      "grad_norm": 0.000692454632371664,
      "learning_rate": 1.5542857142857143e-06,
      "loss": 0.0,
      "step": 16140
    },
    {
      "epoch": 9.228571428571428,
      "grad_norm": 0.002895752666518092,
      "learning_rate": 1.542857142857143e-06,
      "loss": 0.0,
      "step": 16150
    },
    {
      "epoch": 9.234285714285715,
      "grad_norm": 0.0011993246152997017,
      "learning_rate": 1.5314285714285714e-06,
      "loss": 0.0,
      "step": 16160
    },
    {
      "epoch": 9.24,
      "grad_norm": 0.00032080127857625484,
      "learning_rate": 1.52e-06,
      "loss": 0.0031,
      "step": 16170
    },
    {
      "epoch": 9.245714285714286,
      "grad_norm": 0.0011247650254517794,
      "learning_rate": 1.5085714285714287e-06,
      "loss": 0.0,
      "step": 16180
    },
    {
      "epoch": 9.251428571428571,
      "grad_norm": 0.0002799573412630707,
      "learning_rate": 1.4971428571428574e-06,
      "loss": 0.0,
      "step": 16190
    },
    {
      "epoch": 9.257142857142856,
      "grad_norm": 0.012348704040050507,
      "learning_rate": 1.4857142857142858e-06,
      "loss": 0.0,
      "step": 16200
    },
    {
      "epoch": 9.262857142857143,
      "grad_norm": 0.00043159115011803806,
      "learning_rate": 1.4742857142857144e-06,
      "loss": 0.0,
      "step": 16210
    },
    {
      "epoch": 9.268571428571429,
      "grad_norm": 0.00025090225972235203,
      "learning_rate": 1.462857142857143e-06,
      "loss": 0.0,
      "step": 16220
    },
    {
      "epoch": 9.274285714285714,
      "grad_norm": 6.5310468673706055,
      "learning_rate": 1.4514285714285713e-06,
      "loss": 0.0137,
      "step": 16230
    },
    {
      "epoch": 9.28,
      "grad_norm": 0.0009766126750037074,
      "learning_rate": 1.44e-06,
      "loss": 0.0338,
      "step": 16240
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 0.0005210601375438273,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 0.0,
      "step": 16250
    },
    {
      "epoch": 9.291428571428572,
      "grad_norm": 0.0001515828917035833,
      "learning_rate": 1.4171428571428573e-06,
      "loss": 0.0,
      "step": 16260
    },
    {
      "epoch": 9.297142857142857,
      "grad_norm": 0.0005957187968306243,
      "learning_rate": 1.4057142857142857e-06,
      "loss": 0.0,
      "step": 16270
    },
    {
      "epoch": 9.302857142857142,
      "grad_norm": 0.00012588017852976918,
      "learning_rate": 1.3942857142857144e-06,
      "loss": 0.0,
      "step": 16280
    },
    {
      "epoch": 9.308571428571428,
      "grad_norm": 0.0008731095585972071,
      "learning_rate": 1.382857142857143e-06,
      "loss": 0.0,
      "step": 16290
    },
    {
      "epoch": 9.314285714285715,
      "grad_norm": 0.0005101672722958028,
      "learning_rate": 1.3714285714285717e-06,
      "loss": 0.0,
      "step": 16300
    },
    {
      "epoch": 9.32,
      "grad_norm": 0.0002059008984360844,
      "learning_rate": 1.3600000000000001e-06,
      "loss": 0.0203,
      "step": 16310
    },
    {
      "epoch": 9.325714285714286,
      "grad_norm": 0.000569419062230736,
      "learning_rate": 1.3485714285714288e-06,
      "loss": 0.0,
      "step": 16320
    },
    {
      "epoch": 9.331428571428571,
      "grad_norm": 0.0002643055922817439,
      "learning_rate": 1.3371428571428572e-06,
      "loss": 0.0,
      "step": 16330
    },
    {
      "epoch": 9.337142857142856,
      "grad_norm": 0.00041797157609835267,
      "learning_rate": 1.3257142857142856e-06,
      "loss": 0.0,
      "step": 16340
    },
    {
      "epoch": 9.342857142857143,
      "grad_norm": 0.0008716518641449511,
      "learning_rate": 1.3142857142857143e-06,
      "loss": 0.0,
      "step": 16350
    },
    {
      "epoch": 9.348571428571429,
      "grad_norm": 0.00800999253988266,
      "learning_rate": 1.302857142857143e-06,
      "loss": 0.0,
      "step": 16360
    },
    {
      "epoch": 9.354285714285714,
      "grad_norm": 0.00019355237600393593,
      "learning_rate": 1.2914285714285716e-06,
      "loss": 0.0,
      "step": 16370
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.001274113543331623,
      "learning_rate": 1.28e-06,
      "loss": 0.0,
      "step": 16380
    },
    {
      "epoch": 9.365714285714287,
      "grad_norm": 0.04495946317911148,
      "learning_rate": 1.2685714285714287e-06,
      "loss": 0.0203,
      "step": 16390
    },
    {
      "epoch": 9.371428571428572,
      "grad_norm": 0.0010976470075547695,
      "learning_rate": 1.2571428571428573e-06,
      "loss": 0.0047,
      "step": 16400
    },
    {
      "epoch": 9.377142857142857,
      "grad_norm": 0.0015859995037317276,
      "learning_rate": 1.2457142857142858e-06,
      "loss": 0.0,
      "step": 16410
    },
    {
      "epoch": 9.382857142857143,
      "grad_norm": 0.00036335221375338733,
      "learning_rate": 1.2342857142857144e-06,
      "loss": 0.001,
      "step": 16420
    },
    {
      "epoch": 9.388571428571428,
      "grad_norm": 8.121890277834609e-05,
      "learning_rate": 1.222857142857143e-06,
      "loss": 0.0,
      "step": 16430
    },
    {
      "epoch": 9.394285714285715,
      "grad_norm": 0.0001210814225487411,
      "learning_rate": 1.2114285714285715e-06,
      "loss": 0.0,
      "step": 16440
    },
    {
      "epoch": 9.4,
      "grad_norm": 7.918834307929501e-05,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.0,
      "step": 16450
    },
    {
      "epoch": 9.405714285714286,
      "grad_norm": 0.0015999313909560442,
      "learning_rate": 1.1885714285714286e-06,
      "loss": 0.0268,
      "step": 16460
    },
    {
      "epoch": 9.411428571428571,
      "grad_norm": 0.0003756069636438042,
      "learning_rate": 1.1771428571428572e-06,
      "loss": 0.0,
      "step": 16470
    },
    {
      "epoch": 9.417142857142856,
      "grad_norm": 0.005628430284559727,
      "learning_rate": 1.165714285714286e-06,
      "loss": 0.0,
      "step": 16480
    },
    {
      "epoch": 9.422857142857143,
      "grad_norm": 0.000708717096131295,
      "learning_rate": 1.1542857142857143e-06,
      "loss": 0.0,
      "step": 16490
    },
    {
      "epoch": 9.428571428571429,
      "grad_norm": 0.007287336513400078,
      "learning_rate": 1.142857142857143e-06,
      "loss": 0.0,
      "step": 16500
    },
    {
      "epoch": 9.434285714285714,
      "grad_norm": 0.0007329701911658049,
      "learning_rate": 1.1314285714285714e-06,
      "loss": 0.0,
      "step": 16510
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.00019068364053964615,
      "learning_rate": 1.12e-06,
      "loss": 0.0,
      "step": 16520
    },
    {
      "epoch": 9.445714285714285,
      "grad_norm": 0.00041274476097896695,
      "learning_rate": 1.1085714285714287e-06,
      "loss": 0.0,
      "step": 16530
    },
    {
      "epoch": 9.451428571428572,
      "grad_norm": 0.0003746274742297828,
      "learning_rate": 1.0971428571428572e-06,
      "loss": 0.0,
      "step": 16540
    },
    {
      "epoch": 9.457142857142857,
      "grad_norm": 0.0002708979300223291,
      "learning_rate": 1.0857142857142858e-06,
      "loss": 0.0003,
      "step": 16550
    },
    {
      "epoch": 9.462857142857143,
      "grad_norm": 0.00033813260961323977,
      "learning_rate": 1.0742857142857145e-06,
      "loss": 0.0,
      "step": 16560
    },
    {
      "epoch": 9.468571428571428,
      "grad_norm": 0.0218739602714777,
      "learning_rate": 1.062857142857143e-06,
      "loss": 0.0,
      "step": 16570
    },
    {
      "epoch": 9.474285714285715,
      "grad_norm": 0.0008220618474297225,
      "learning_rate": 1.0514285714285716e-06,
      "loss": 0.0,
      "step": 16580
    },
    {
      "epoch": 9.48,
      "grad_norm": 0.10457050055265427,
      "learning_rate": 1.04e-06,
      "loss": 0.0,
      "step": 16590
    },
    {
      "epoch": 9.485714285714286,
      "grad_norm": 0.0025044488720595837,
      "learning_rate": 1.0285714285714286e-06,
      "loss": 0.0001,
      "step": 16600
    },
    {
      "epoch": 9.491428571428571,
      "grad_norm": 0.0005697684828191996,
      "learning_rate": 1.0171428571428573e-06,
      "loss": 0.0,
      "step": 16610
    },
    {
      "epoch": 9.497142857142856,
      "grad_norm": 0.2723165452480316,
      "learning_rate": 1.0057142857142857e-06,
      "loss": 0.0002,
      "step": 16620
    },
    {
      "epoch": 9.502857142857144,
      "grad_norm": 0.00038277829298749566,
      "learning_rate": 9.942857142857144e-07,
      "loss": 0.0001,
      "step": 16630
    },
    {
      "epoch": 9.508571428571429,
      "grad_norm": 0.00014467774599324912,
      "learning_rate": 9.828571428571428e-07,
      "loss": 0.0001,
      "step": 16640
    },
    {
      "epoch": 9.514285714285714,
      "grad_norm": 0.00020856212358921766,
      "learning_rate": 9.714285714285715e-07,
      "loss": 0.0,
      "step": 16650
    },
    {
      "epoch": 9.52,
      "grad_norm": 0.0009473999962210655,
      "learning_rate": 9.600000000000001e-07,
      "loss": 0.0,
      "step": 16660
    },
    {
      "epoch": 9.525714285714285,
      "grad_norm": 0.0002664521452970803,
      "learning_rate": 9.485714285714287e-07,
      "loss": 0.0,
      "step": 16670
    },
    {
      "epoch": 9.531428571428572,
      "grad_norm": 0.00037343782605603337,
      "learning_rate": 9.371428571428571e-07,
      "loss": 0.0,
      "step": 16680
    },
    {
      "epoch": 9.537142857142857,
      "grad_norm": 0.021577943116426468,
      "learning_rate": 9.257142857142858e-07,
      "loss": 0.0,
      "step": 16690
    },
    {
      "epoch": 9.542857142857143,
      "grad_norm": 0.0006518880254589021,
      "learning_rate": 9.142857142857144e-07,
      "loss": 0.0,
      "step": 16700
    },
    {
      "epoch": 9.548571428571428,
      "grad_norm": 0.0002698224561754614,
      "learning_rate": 9.02857142857143e-07,
      "loss": 0.0,
      "step": 16710
    },
    {
      "epoch": 9.554285714285715,
      "grad_norm": 0.00929643027484417,
      "learning_rate": 8.914285714285716e-07,
      "loss": 0.0,
      "step": 16720
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.009795913472771645,
      "learning_rate": 8.8e-07,
      "loss": 0.0,
      "step": 16730
    },
    {
      "epoch": 9.565714285714286,
      "grad_norm": 0.003335023997351527,
      "learning_rate": 8.685714285714286e-07,
      "loss": 0.0,
      "step": 16740
    },
    {
      "epoch": 9.571428571428571,
      "grad_norm": 0.0014343957882374525,
      "learning_rate": 8.571428571428572e-07,
      "loss": 0.005,
      "step": 16750
    },
    {
      "epoch": 9.577142857142857,
      "grad_norm": 8.652660471852869e-05,
      "learning_rate": 8.457142857142858e-07,
      "loss": 0.0,
      "step": 16760
    },
    {
      "epoch": 9.582857142857144,
      "grad_norm": 0.0017883823020383716,
      "learning_rate": 8.342857142857144e-07,
      "loss": 0.0,
      "step": 16770
    },
    {
      "epoch": 9.588571428571429,
      "grad_norm": 0.001525449799373746,
      "learning_rate": 8.228571428571429e-07,
      "loss": 0.0001,
      "step": 16780
    },
    {
      "epoch": 9.594285714285714,
      "grad_norm": 0.00018192132120020688,
      "learning_rate": 8.114285714285715e-07,
      "loss": 0.0,
      "step": 16790
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.007465700153261423,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.0,
      "step": 16800
    },
    {
      "epoch": 9.605714285714285,
      "grad_norm": 0.00016443031199742109,
      "learning_rate": 7.885714285714287e-07,
      "loss": 0.0001,
      "step": 16810
    },
    {
      "epoch": 9.611428571428572,
      "grad_norm": 0.0003990276891272515,
      "learning_rate": 7.771428571428572e-07,
      "loss": 0.0,
      "step": 16820
    },
    {
      "epoch": 9.617142857142857,
      "grad_norm": 0.002017644699662924,
      "learning_rate": 7.657142857142857e-07,
      "loss": 0.0,
      "step": 16830
    },
    {
      "epoch": 9.622857142857143,
      "grad_norm": 0.007950990460813046,
      "learning_rate": 7.542857142857144e-07,
      "loss": 0.0,
      "step": 16840
    },
    {
      "epoch": 9.628571428571428,
      "grad_norm": 1.3363333940505981,
      "learning_rate": 7.428571428571429e-07,
      "loss": 0.0015,
      "step": 16850
    },
    {
      "epoch": 9.634285714285713,
      "grad_norm": 0.00039178342558443546,
      "learning_rate": 7.314285714285715e-07,
      "loss": 0.0,
      "step": 16860
    },
    {
      "epoch": 9.64,
      "grad_norm": 0.00014511965855490416,
      "learning_rate": 7.2e-07,
      "loss": 0.0,
      "step": 16870
    },
    {
      "epoch": 9.645714285714286,
      "grad_norm": 0.0003211165894754231,
      "learning_rate": 7.085714285714286e-07,
      "loss": 0.0001,
      "step": 16880
    },
    {
      "epoch": 9.651428571428571,
      "grad_norm": 0.00020928216690663248,
      "learning_rate": 6.971428571428572e-07,
      "loss": 0.0,
      "step": 16890
    },
    {
      "epoch": 9.657142857142857,
      "grad_norm": 0.0005488075548782945,
      "learning_rate": 6.857142857142858e-07,
      "loss": 0.0,
      "step": 16900
    },
    {
      "epoch": 9.662857142857142,
      "grad_norm": 0.00020284549100324512,
      "learning_rate": 6.742857142857144e-07,
      "loss": 0.0,
      "step": 16910
    },
    {
      "epoch": 9.668571428571429,
      "grad_norm": 0.0008475619833916426,
      "learning_rate": 6.628571428571428e-07,
      "loss": 0.0,
      "step": 16920
    },
    {
      "epoch": 9.674285714285714,
      "grad_norm": 0.0102162417024374,
      "learning_rate": 6.514285714285715e-07,
      "loss": 0.0,
      "step": 16930
    },
    {
      "epoch": 9.68,
      "grad_norm": 0.0012110448442399502,
      "learning_rate": 6.4e-07,
      "loss": 0.0,
      "step": 16940
    },
    {
      "epoch": 9.685714285714285,
      "grad_norm": 0.003382715629413724,
      "learning_rate": 6.285714285714287e-07,
      "loss": 0.0,
      "step": 16950
    },
    {
      "epoch": 9.691428571428572,
      "grad_norm": 0.0010680068517103791,
      "learning_rate": 6.171428571428572e-07,
      "loss": 0.0,
      "step": 16960
    },
    {
      "epoch": 9.697142857142858,
      "grad_norm": 0.0006511739920824766,
      "learning_rate": 6.057142857142858e-07,
      "loss": 0.0,
      "step": 16970
    },
    {
      "epoch": 9.702857142857143,
      "grad_norm": 0.00040521053597331047,
      "learning_rate": 5.942857142857143e-07,
      "loss": 0.0,
      "step": 16980
    },
    {
      "epoch": 9.708571428571428,
      "grad_norm": 0.017010530456900597,
      "learning_rate": 5.82857142857143e-07,
      "loss": 0.0,
      "step": 16990
    },
    {
      "epoch": 9.714285714285714,
      "grad_norm": 0.002388270106166601,
      "learning_rate": 5.714285714285715e-07,
      "loss": 0.0,
      "step": 17000
    },
    {
      "epoch": 9.72,
      "grad_norm": 0.0002062575804302469,
      "learning_rate": 5.6e-07,
      "loss": 0.0,
      "step": 17010
    },
    {
      "epoch": 9.725714285714286,
      "grad_norm": 0.0007587395375594497,
      "learning_rate": 5.485714285714286e-07,
      "loss": 0.0,
      "step": 17020
    },
    {
      "epoch": 9.731428571428571,
      "grad_norm": 0.0004214465734548867,
      "learning_rate": 5.371428571428572e-07,
      "loss": 0.0,
      "step": 17030
    },
    {
      "epoch": 9.737142857142857,
      "grad_norm": 0.00028757183463312685,
      "learning_rate": 5.257142857142858e-07,
      "loss": 0.0001,
      "step": 17040
    },
    {
      "epoch": 9.742857142857144,
      "grad_norm": 0.001577527727931738,
      "learning_rate": 5.142857142857143e-07,
      "loss": 0.0004,
      "step": 17050
    },
    {
      "epoch": 9.748571428571429,
      "grad_norm": 0.000620806124061346,
      "learning_rate": 5.028571428571429e-07,
      "loss": 0.0,
      "step": 17060
    },
    {
      "epoch": 9.754285714285714,
      "grad_norm": 0.0009265068219974637,
      "learning_rate": 4.914285714285714e-07,
      "loss": 0.0,
      "step": 17070
    },
    {
      "epoch": 9.76,
      "grad_norm": 0.00018583383643999696,
      "learning_rate": 4.800000000000001e-07,
      "loss": 0.0,
      "step": 17080
    },
    {
      "epoch": 9.765714285714285,
      "grad_norm": 0.00017987939645536244,
      "learning_rate": 4.6857142857142855e-07,
      "loss": 0.0,
      "step": 17090
    },
    {
      "epoch": 9.771428571428572,
      "grad_norm": 0.0003674527397379279,
      "learning_rate": 4.571428571428572e-07,
      "loss": 0.0,
      "step": 17100
    },
    {
      "epoch": 9.777142857142858,
      "grad_norm": 0.00026667467318475246,
      "learning_rate": 4.457142857142858e-07,
      "loss": 0.0654,
      "step": 17110
    },
    {
      "epoch": 9.782857142857143,
      "grad_norm": 0.00024071987718343735,
      "learning_rate": 4.342857142857143e-07,
      "loss": 0.0,
      "step": 17120
    },
    {
      "epoch": 9.788571428571428,
      "grad_norm": 0.0016124313697218895,
      "learning_rate": 4.228571428571429e-07,
      "loss": 0.0,
      "step": 17130
    },
    {
      "epoch": 9.794285714285714,
      "grad_norm": 0.0017211426747962832,
      "learning_rate": 4.1142857142857144e-07,
      "loss": 0.0,
      "step": 17140
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.0016055789310485125,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 0.0,
      "step": 17150
    },
    {
      "epoch": 9.805714285714286,
      "grad_norm": 0.0005511055933311582,
      "learning_rate": 3.885714285714286e-07,
      "loss": 0.0001,
      "step": 17160
    },
    {
      "epoch": 9.811428571428571,
      "grad_norm": 0.00036466849269345403,
      "learning_rate": 3.771428571428572e-07,
      "loss": 0.0,
      "step": 17170
    },
    {
      "epoch": 9.817142857142857,
      "grad_norm": 0.0005676685250364244,
      "learning_rate": 3.657142857142858e-07,
      "loss": 0.0,
      "step": 17180
    },
    {
      "epoch": 9.822857142857142,
      "grad_norm": 0.02519346959888935,
      "learning_rate": 3.542857142857143e-07,
      "loss": 0.0,
      "step": 17190
    },
    {
      "epoch": 9.82857142857143,
      "grad_norm": 0.003296623472124338,
      "learning_rate": 3.428571428571429e-07,
      "loss": 0.0,
      "step": 17200
    },
    {
      "epoch": 9.834285714285715,
      "grad_norm": 0.0019713740330189466,
      "learning_rate": 3.314285714285714e-07,
      "loss": 0.0,
      "step": 17210
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.0002702336641959846,
      "learning_rate": 3.2e-07,
      "loss": 0.0,
      "step": 17220
    },
    {
      "epoch": 9.845714285714285,
      "grad_norm": 0.0004871188721153885,
      "learning_rate": 3.085714285714286e-07,
      "loss": 0.0,
      "step": 17230
    },
    {
      "epoch": 9.85142857142857,
      "grad_norm": 0.0005675349966622889,
      "learning_rate": 2.9714285714285715e-07,
      "loss": 0.0197,
      "step": 17240
    },
    {
      "epoch": 9.857142857142858,
      "grad_norm": 0.00012769688328262419,
      "learning_rate": 2.8571428571428575e-07,
      "loss": 0.0032,
      "step": 17250
    },
    {
      "epoch": 9.862857142857143,
      "grad_norm": 8.65141992107965e-05,
      "learning_rate": 2.742857142857143e-07,
      "loss": 0.0001,
      "step": 17260
    },
    {
      "epoch": 9.868571428571428,
      "grad_norm": 0.0011592443333938718,
      "learning_rate": 2.628571428571429e-07,
      "loss": 0.0001,
      "step": 17270
    },
    {
      "epoch": 9.874285714285714,
      "grad_norm": 0.008285130374133587,
      "learning_rate": 2.5142857142857143e-07,
      "loss": 0.0,
      "step": 17280
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.0032917058560997248,
      "learning_rate": 2.4000000000000003e-07,
      "loss": 0.0048,
      "step": 17290
    },
    {
      "epoch": 9.885714285714286,
      "grad_norm": 0.00016659028187859803,
      "learning_rate": 2.285714285714286e-07,
      "loss": 0.0,
      "step": 17300
    },
    {
      "epoch": 9.891428571428571,
      "grad_norm": 0.188074991106987,
      "learning_rate": 2.1714285714285715e-07,
      "loss": 0.0001,
      "step": 17310
    },
    {
      "epoch": 9.897142857142857,
      "grad_norm": 0.0003443257592152804,
      "learning_rate": 2.0571428571428572e-07,
      "loss": 0.0,
      "step": 17320
    },
    {
      "epoch": 9.902857142857142,
      "grad_norm": 0.00020952944760210812,
      "learning_rate": 1.942857142857143e-07,
      "loss": 0.0,
      "step": 17330
    },
    {
      "epoch": 9.90857142857143,
      "grad_norm": 0.0013611280592158437,
      "learning_rate": 1.828571428571429e-07,
      "loss": 0.0,
      "step": 17340
    },
    {
      "epoch": 9.914285714285715,
      "grad_norm": 0.00023939706443343312,
      "learning_rate": 1.7142857142857146e-07,
      "loss": 0.0,
      "step": 17350
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.0017129877815023065,
      "learning_rate": 1.6e-07,
      "loss": 0.0,
      "step": 17360
    },
    {
      "epoch": 9.925714285714285,
      "grad_norm": 0.00010015154839493334,
      "learning_rate": 1.4857142857142857e-07,
      "loss": 0.0345,
      "step": 17370
    },
    {
      "epoch": 9.93142857142857,
      "grad_norm": 0.0011648662621155381,
      "learning_rate": 1.3714285714285715e-07,
      "loss": 0.0001,
      "step": 17380
    },
    {
      "epoch": 9.937142857142858,
      "grad_norm": 0.0002793174353428185,
      "learning_rate": 1.2571428571428572e-07,
      "loss": 0.0,
      "step": 17390
    },
    {
      "epoch": 9.942857142857143,
      "grad_norm": 0.0007144854171201587,
      "learning_rate": 1.142857142857143e-07,
      "loss": 0.0001,
      "step": 17400
    },
    {
      "epoch": 9.948571428571428,
      "grad_norm": 0.06128964573144913,
      "learning_rate": 1.0285714285714286e-07,
      "loss": 0.0178,
      "step": 17410
    },
    {
      "epoch": 9.954285714285714,
      "grad_norm": 0.0002377652854193002,
      "learning_rate": 9.142857142857144e-08,
      "loss": 0.0,
      "step": 17420
    },
    {
      "epoch": 9.96,
      "grad_norm": 0.0003046410856768489,
      "learning_rate": 8e-08,
      "loss": 0.0553,
      "step": 17430
    },
    {
      "epoch": 9.965714285714286,
      "grad_norm": 0.002103813225403428,
      "learning_rate": 6.857142857142857e-08,
      "loss": 0.0256,
      "step": 17440
    },
    {
      "epoch": 9.971428571428572,
      "grad_norm": 0.00015262172382790595,
      "learning_rate": 5.714285714285715e-08,
      "loss": 0.0,
      "step": 17450
    },
    {
      "epoch": 9.977142857142857,
      "grad_norm": 0.00014412440941669047,
      "learning_rate": 4.571428571428572e-08,
      "loss": 0.0001,
      "step": 17460
    },
    {
      "epoch": 9.982857142857142,
      "grad_norm": 0.00020635707187466323,
      "learning_rate": 3.4285714285714286e-08,
      "loss": 0.0,
      "step": 17470
    },
    {
      "epoch": 9.98857142857143,
      "grad_norm": 0.0007265068707056344,
      "learning_rate": 2.285714285714286e-08,
      "loss": 0.0,
      "step": 17480
    },
    {
      "epoch": 9.994285714285715,
      "grad_norm": 0.00019420978787820786,
      "learning_rate": 1.142857142857143e-08,
      "loss": 0.0,
      "step": 17490
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0005161745939403772,
      "learning_rate": 0.0,
      "loss": 0.0146,
      "step": 17500
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9869652406417112,
      "eval_f1": 0.9414414414414415,
      "eval_loss": 0.10616807639598846,
      "eval_precision": 0.9457013574660633,
      "eval_recall": 0.9372197309417041,
      "eval_runtime": 54.2871,
      "eval_samples_per_second": 110.523,
      "eval_steps_per_second": 3.463,
      "step": 17500
    }
  ],
  "logging_steps": 10,
  "max_steps": 17500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.052568266926624e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
