{
  "best_metric": 0.9358490566037735,
  "best_model_checkpoint": "../saved_models/open_redirect_40000/checkpoint-12250",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 12250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005714285714285715,
      "grad_norm": 152.3962860107422,
      "learning_rate": 1.9998857142857143e-05,
      "loss": 0.8194,
      "step": 1
    },
    {
      "epoch": 0.005714285714285714,
      "grad_norm": 18.077943801879883,
      "learning_rate": 1.9988571428571432e-05,
      "loss": 0.4794,
      "step": 10
    },
    {
      "epoch": 0.011428571428571429,
      "grad_norm": 12.376200675964355,
      "learning_rate": 1.997714285714286e-05,
      "loss": 0.7336,
      "step": 20
    },
    {
      "epoch": 0.017142857142857144,
      "grad_norm": 26.993511199951172,
      "learning_rate": 1.996571428571429e-05,
      "loss": 0.3149,
      "step": 30
    },
    {
      "epoch": 0.022857142857142857,
      "grad_norm": 68.7391357421875,
      "learning_rate": 1.9954285714285715e-05,
      "loss": 0.4926,
      "step": 40
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 3.1198575496673584,
      "learning_rate": 1.9942857142857142e-05,
      "loss": 0.289,
      "step": 50
    },
    {
      "epoch": 0.03428571428571429,
      "grad_norm": 23.592971801757812,
      "learning_rate": 1.9931428571428572e-05,
      "loss": 0.6014,
      "step": 60
    },
    {
      "epoch": 0.04,
      "grad_norm": 22.63159942626953,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 0.5492,
      "step": 70
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 18.86667251586914,
      "learning_rate": 1.990857142857143e-05,
      "loss": 0.4924,
      "step": 80
    },
    {
      "epoch": 0.05142857142857143,
      "grad_norm": 24.72309112548828,
      "learning_rate": 1.989714285714286e-05,
      "loss": 0.3963,
      "step": 90
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 27.324586868286133,
      "learning_rate": 1.988571428571429e-05,
      "loss": 0.4809,
      "step": 100
    },
    {
      "epoch": 0.06285714285714286,
      "grad_norm": 17.148488998413086,
      "learning_rate": 1.9874285714285716e-05,
      "loss": 0.329,
      "step": 110
    },
    {
      "epoch": 0.06857142857142857,
      "grad_norm": 20.468183517456055,
      "learning_rate": 1.9862857142857143e-05,
      "loss": 0.5993,
      "step": 120
    },
    {
      "epoch": 0.07428571428571429,
      "grad_norm": 9.855440139770508,
      "learning_rate": 1.9851428571428573e-05,
      "loss": 0.4783,
      "step": 130
    },
    {
      "epoch": 0.08,
      "grad_norm": 23.066265106201172,
      "learning_rate": 1.9840000000000003e-05,
      "loss": 0.421,
      "step": 140
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 23.59786033630371,
      "learning_rate": 1.982857142857143e-05,
      "loss": 0.5812,
      "step": 150
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 11.071243286132812,
      "learning_rate": 1.981714285714286e-05,
      "loss": 0.451,
      "step": 160
    },
    {
      "epoch": 0.09714285714285714,
      "grad_norm": 8.184548377990723,
      "learning_rate": 1.9805714285714287e-05,
      "loss": 0.4019,
      "step": 170
    },
    {
      "epoch": 0.10285714285714286,
      "grad_norm": 16.468883514404297,
      "learning_rate": 1.9794285714285717e-05,
      "loss": 0.5345,
      "step": 180
    },
    {
      "epoch": 0.10857142857142857,
      "grad_norm": 9.530181884765625,
      "learning_rate": 1.9782857142857144e-05,
      "loss": 0.4507,
      "step": 190
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 12.164594650268555,
      "learning_rate": 1.9771428571428574e-05,
      "loss": 0.4906,
      "step": 200
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.092110633850098,
      "learning_rate": 1.976e-05,
      "loss": 0.4377,
      "step": 210
    },
    {
      "epoch": 0.12571428571428572,
      "grad_norm": 5.2541117668151855,
      "learning_rate": 1.974857142857143e-05,
      "loss": 0.3761,
      "step": 220
    },
    {
      "epoch": 0.13142857142857142,
      "grad_norm": 12.636744499206543,
      "learning_rate": 1.973714285714286e-05,
      "loss": 0.407,
      "step": 230
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 11.657770156860352,
      "learning_rate": 1.9725714285714288e-05,
      "loss": 0.413,
      "step": 240
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 12.948966026306152,
      "learning_rate": 1.9714285714285718e-05,
      "loss": 0.3545,
      "step": 250
    },
    {
      "epoch": 0.14857142857142858,
      "grad_norm": 9.471715927124023,
      "learning_rate": 1.9702857142857144e-05,
      "loss": 0.4483,
      "step": 260
    },
    {
      "epoch": 0.15428571428571428,
      "grad_norm": 9.043966293334961,
      "learning_rate": 1.969142857142857e-05,
      "loss": 0.4489,
      "step": 270
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.521231651306152,
      "learning_rate": 1.968e-05,
      "loss": 0.409,
      "step": 280
    },
    {
      "epoch": 0.1657142857142857,
      "grad_norm": 5.861060619354248,
      "learning_rate": 1.966857142857143e-05,
      "loss": 0.3631,
      "step": 290
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 7.956064224243164,
      "learning_rate": 1.9657142857142858e-05,
      "loss": 0.4209,
      "step": 300
    },
    {
      "epoch": 0.17714285714285713,
      "grad_norm": 9.18301010131836,
      "learning_rate": 1.964571428571429e-05,
      "loss": 0.4484,
      "step": 310
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 9.680551528930664,
      "learning_rate": 1.963428571428572e-05,
      "loss": 0.38,
      "step": 320
    },
    {
      "epoch": 0.18857142857142858,
      "grad_norm": 7.326653003692627,
      "learning_rate": 1.9622857142857142e-05,
      "loss": 0.4241,
      "step": 330
    },
    {
      "epoch": 0.19428571428571428,
      "grad_norm": 5.4797773361206055,
      "learning_rate": 1.9611428571428572e-05,
      "loss": 0.3842,
      "step": 340
    },
    {
      "epoch": 0.2,
      "grad_norm": 17.293752670288086,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.3986,
      "step": 350
    },
    {
      "epoch": 0.2057142857142857,
      "grad_norm": 8.532806396484375,
      "learning_rate": 1.958857142857143e-05,
      "loss": 0.4036,
      "step": 360
    },
    {
      "epoch": 0.21142857142857144,
      "grad_norm": 9.43725299835205,
      "learning_rate": 1.957714285714286e-05,
      "loss": 0.4724,
      "step": 370
    },
    {
      "epoch": 0.21714285714285714,
      "grad_norm": 7.472758769989014,
      "learning_rate": 1.956571428571429e-05,
      "loss": 0.3661,
      "step": 380
    },
    {
      "epoch": 0.22285714285714286,
      "grad_norm": 9.500805854797363,
      "learning_rate": 1.9554285714285716e-05,
      "loss": 0.4228,
      "step": 390
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 5.819807052612305,
      "learning_rate": 1.9542857142857143e-05,
      "loss": 0.382,
      "step": 400
    },
    {
      "epoch": 0.2342857142857143,
      "grad_norm": 7.85776424407959,
      "learning_rate": 1.9531428571428573e-05,
      "loss": 0.4551,
      "step": 410
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.796383857727051,
      "learning_rate": 1.9520000000000003e-05,
      "loss": 0.4616,
      "step": 420
    },
    {
      "epoch": 0.24571428571428572,
      "grad_norm": 8.400083541870117,
      "learning_rate": 1.950857142857143e-05,
      "loss": 0.3947,
      "step": 430
    },
    {
      "epoch": 0.25142857142857145,
      "grad_norm": 9.449995040893555,
      "learning_rate": 1.949714285714286e-05,
      "loss": 0.406,
      "step": 440
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 8.267642974853516,
      "learning_rate": 1.9485714285714286e-05,
      "loss": 0.4068,
      "step": 450
    },
    {
      "epoch": 0.26285714285714284,
      "grad_norm": 16.598533630371094,
      "learning_rate": 1.9474285714285717e-05,
      "loss": 0.4358,
      "step": 460
    },
    {
      "epoch": 0.26857142857142857,
      "grad_norm": 8.070167541503906,
      "learning_rate": 1.9462857142857147e-05,
      "loss": 0.412,
      "step": 470
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 3.5108773708343506,
      "learning_rate": 1.9451428571428573e-05,
      "loss": 0.3434,
      "step": 480
    },
    {
      "epoch": 0.28,
      "grad_norm": 10.071125030517578,
      "learning_rate": 1.944e-05,
      "loss": 0.3606,
      "step": 490
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 9.548630714416504,
      "learning_rate": 1.942857142857143e-05,
      "loss": 0.4418,
      "step": 500
    },
    {
      "epoch": 0.2914285714285714,
      "grad_norm": 10.584481239318848,
      "learning_rate": 1.941714285714286e-05,
      "loss": 0.3292,
      "step": 510
    },
    {
      "epoch": 0.29714285714285715,
      "grad_norm": 5.533085346221924,
      "learning_rate": 1.9405714285714287e-05,
      "loss": 0.3691,
      "step": 520
    },
    {
      "epoch": 0.3028571428571429,
      "grad_norm": 9.467925071716309,
      "learning_rate": 1.9394285714285717e-05,
      "loss": 0.382,
      "step": 530
    },
    {
      "epoch": 0.30857142857142855,
      "grad_norm": 14.629916191101074,
      "learning_rate": 1.9382857142857144e-05,
      "loss": 0.4483,
      "step": 540
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 10.975384712219238,
      "learning_rate": 1.937142857142857e-05,
      "loss": 0.3609,
      "step": 550
    },
    {
      "epoch": 0.32,
      "grad_norm": 13.074840545654297,
      "learning_rate": 1.936e-05,
      "loss": 0.37,
      "step": 560
    },
    {
      "epoch": 0.32571428571428573,
      "grad_norm": 7.630520343780518,
      "learning_rate": 1.934857142857143e-05,
      "loss": 0.3008,
      "step": 570
    },
    {
      "epoch": 0.3314285714285714,
      "grad_norm": 7.416971206665039,
      "learning_rate": 1.9337142857142858e-05,
      "loss": 0.428,
      "step": 580
    },
    {
      "epoch": 0.33714285714285713,
      "grad_norm": 3.5871388912200928,
      "learning_rate": 1.9325714285714288e-05,
      "loss": 0.315,
      "step": 590
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 9.117737770080566,
      "learning_rate": 1.9314285714285718e-05,
      "loss": 0.4791,
      "step": 600
    },
    {
      "epoch": 0.3485714285714286,
      "grad_norm": 14.510160446166992,
      "learning_rate": 1.9302857142857145e-05,
      "loss": 0.3044,
      "step": 610
    },
    {
      "epoch": 0.35428571428571426,
      "grad_norm": 9.190573692321777,
      "learning_rate": 1.929142857142857e-05,
      "loss": 0.4009,
      "step": 620
    },
    {
      "epoch": 0.36,
      "grad_norm": 10.848758697509766,
      "learning_rate": 1.9280000000000002e-05,
      "loss": 0.3365,
      "step": 630
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 7.730981349945068,
      "learning_rate": 1.926857142857143e-05,
      "loss": 0.3361,
      "step": 640
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 4.988539695739746,
      "learning_rate": 1.925714285714286e-05,
      "loss": 0.315,
      "step": 650
    },
    {
      "epoch": 0.37714285714285717,
      "grad_norm": 2.37005352973938,
      "learning_rate": 1.924571428571429e-05,
      "loss": 0.2313,
      "step": 660
    },
    {
      "epoch": 0.38285714285714284,
      "grad_norm": 10.57374382019043,
      "learning_rate": 1.9234285714285716e-05,
      "loss": 0.422,
      "step": 670
    },
    {
      "epoch": 0.38857142857142857,
      "grad_norm": 4.32633638381958,
      "learning_rate": 1.9222857142857146e-05,
      "loss": 0.3094,
      "step": 680
    },
    {
      "epoch": 0.3942857142857143,
      "grad_norm": 7.863930702209473,
      "learning_rate": 1.9211428571428572e-05,
      "loss": 0.3439,
      "step": 690
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.401704788208008,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.2644,
      "step": 700
    },
    {
      "epoch": 0.4057142857142857,
      "grad_norm": 6.52803897857666,
      "learning_rate": 1.918857142857143e-05,
      "loss": 0.381,
      "step": 710
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 9.396662712097168,
      "learning_rate": 1.917714285714286e-05,
      "loss": 0.3776,
      "step": 720
    },
    {
      "epoch": 0.41714285714285715,
      "grad_norm": 1.8566569089889526,
      "learning_rate": 1.9165714285714286e-05,
      "loss": 0.3434,
      "step": 730
    },
    {
      "epoch": 0.4228571428571429,
      "grad_norm": 10.467426300048828,
      "learning_rate": 1.9154285714285716e-05,
      "loss": 0.3551,
      "step": 740
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 8.168497085571289,
      "learning_rate": 1.9142857142857146e-05,
      "loss": 0.2504,
      "step": 750
    },
    {
      "epoch": 0.4342857142857143,
      "grad_norm": 6.3188157081604,
      "learning_rate": 1.9131428571428573e-05,
      "loss": 0.3649,
      "step": 760
    },
    {
      "epoch": 0.44,
      "grad_norm": 11.739938735961914,
      "learning_rate": 1.912e-05,
      "loss": 0.3198,
      "step": 770
    },
    {
      "epoch": 0.44571428571428573,
      "grad_norm": 7.637740135192871,
      "learning_rate": 1.910857142857143e-05,
      "loss": 0.3793,
      "step": 780
    },
    {
      "epoch": 0.4514285714285714,
      "grad_norm": 8.520683288574219,
      "learning_rate": 1.909714285714286e-05,
      "loss": 0.2848,
      "step": 790
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 8.493246078491211,
      "learning_rate": 1.9085714285714287e-05,
      "loss": 0.3853,
      "step": 800
    },
    {
      "epoch": 0.46285714285714286,
      "grad_norm": 10.775470733642578,
      "learning_rate": 1.9074285714285717e-05,
      "loss": 0.3016,
      "step": 810
    },
    {
      "epoch": 0.4685714285714286,
      "grad_norm": 6.037624835968018,
      "learning_rate": 1.9062857142857144e-05,
      "loss": 0.2073,
      "step": 820
    },
    {
      "epoch": 0.4742857142857143,
      "grad_norm": 9.139137268066406,
      "learning_rate": 1.9051428571428574e-05,
      "loss": 0.3462,
      "step": 830
    },
    {
      "epoch": 0.48,
      "grad_norm": 9.061614990234375,
      "learning_rate": 1.904e-05,
      "loss": 0.2704,
      "step": 840
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 8.093024253845215,
      "learning_rate": 1.902857142857143e-05,
      "loss": 0.2667,
      "step": 850
    },
    {
      "epoch": 0.49142857142857144,
      "grad_norm": 14.621190071105957,
      "learning_rate": 1.9017142857142858e-05,
      "loss": 0.3402,
      "step": 860
    },
    {
      "epoch": 0.49714285714285716,
      "grad_norm": 11.522472381591797,
      "learning_rate": 1.9005714285714288e-05,
      "loss": 0.3282,
      "step": 870
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 6.304717540740967,
      "learning_rate": 1.8994285714285718e-05,
      "loss": 0.251,
      "step": 880
    },
    {
      "epoch": 0.5085714285714286,
      "grad_norm": 13.494245529174805,
      "learning_rate": 1.8982857142857145e-05,
      "loss": 0.3005,
      "step": 890
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 3.6499810218811035,
      "learning_rate": 1.8971428571428575e-05,
      "loss": 0.2976,
      "step": 900
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.02448034286499,
      "learning_rate": 1.896e-05,
      "loss": 0.2632,
      "step": 910
    },
    {
      "epoch": 0.5257142857142857,
      "grad_norm": 8.055861473083496,
      "learning_rate": 1.8948571428571428e-05,
      "loss": 0.201,
      "step": 920
    },
    {
      "epoch": 0.5314285714285715,
      "grad_norm": 15.587167739868164,
      "learning_rate": 1.893714285714286e-05,
      "loss": 0.3347,
      "step": 930
    },
    {
      "epoch": 0.5371428571428571,
      "grad_norm": 8.861448287963867,
      "learning_rate": 1.892571428571429e-05,
      "loss": 0.2259,
      "step": 940
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 8.467462539672852,
      "learning_rate": 1.8914285714285715e-05,
      "loss": 0.3106,
      "step": 950
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 5.292970180511475,
      "learning_rate": 1.8902857142857145e-05,
      "loss": 0.2489,
      "step": 960
    },
    {
      "epoch": 0.5542857142857143,
      "grad_norm": 10.745888710021973,
      "learning_rate": 1.8891428571428575e-05,
      "loss": 0.304,
      "step": 970
    },
    {
      "epoch": 0.56,
      "grad_norm": 10.380525588989258,
      "learning_rate": 1.8880000000000002e-05,
      "loss": 0.3096,
      "step": 980
    },
    {
      "epoch": 0.5657142857142857,
      "grad_norm": 6.328782558441162,
      "learning_rate": 1.886857142857143e-05,
      "loss": 0.2503,
      "step": 990
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 12.873332023620605,
      "learning_rate": 1.885714285714286e-05,
      "loss": 0.2309,
      "step": 1000
    },
    {
      "epoch": 0.5771428571428572,
      "grad_norm": 6.546156406402588,
      "learning_rate": 1.8845714285714286e-05,
      "loss": 0.2868,
      "step": 1010
    },
    {
      "epoch": 0.5828571428571429,
      "grad_norm": 14.154296875,
      "learning_rate": 1.8834285714285716e-05,
      "loss": 0.3146,
      "step": 1020
    },
    {
      "epoch": 0.5885714285714285,
      "grad_norm": 1.6544480323791504,
      "learning_rate": 1.8822857142857146e-05,
      "loss": 0.2133,
      "step": 1030
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 12.289823532104492,
      "learning_rate": 1.8811428571428573e-05,
      "loss": 0.2518,
      "step": 1040
    },
    {
      "epoch": 0.6,
      "grad_norm": 7.550543308258057,
      "learning_rate": 1.88e-05,
      "loss": 0.2597,
      "step": 1050
    },
    {
      "epoch": 0.6057142857142858,
      "grad_norm": 8.42509937286377,
      "learning_rate": 1.878857142857143e-05,
      "loss": 0.287,
      "step": 1060
    },
    {
      "epoch": 0.6114285714285714,
      "grad_norm": 12.294645309448242,
      "learning_rate": 1.877714285714286e-05,
      "loss": 0.27,
      "step": 1070
    },
    {
      "epoch": 0.6171428571428571,
      "grad_norm": 10.147531509399414,
      "learning_rate": 1.8765714285714287e-05,
      "loss": 0.2976,
      "step": 1080
    },
    {
      "epoch": 0.6228571428571429,
      "grad_norm": 12.554800987243652,
      "learning_rate": 1.8754285714285717e-05,
      "loss": 0.3057,
      "step": 1090
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 9.04076862335205,
      "learning_rate": 1.8742857142857143e-05,
      "loss": 0.2623,
      "step": 1100
    },
    {
      "epoch": 0.6342857142857142,
      "grad_norm": 11.317946434020996,
      "learning_rate": 1.8731428571428574e-05,
      "loss": 0.2065,
      "step": 1110
    },
    {
      "epoch": 0.64,
      "grad_norm": 9.063776969909668,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 0.2564,
      "step": 1120
    },
    {
      "epoch": 0.6457142857142857,
      "grad_norm": 3.47039794921875,
      "learning_rate": 1.870857142857143e-05,
      "loss": 0.2566,
      "step": 1130
    },
    {
      "epoch": 0.6514285714285715,
      "grad_norm": 2.6394994258880615,
      "learning_rate": 1.8697142857142857e-05,
      "loss": 0.2093,
      "step": 1140
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 7.982324123382568,
      "learning_rate": 1.8685714285714287e-05,
      "loss": 0.2724,
      "step": 1150
    },
    {
      "epoch": 0.6628571428571428,
      "grad_norm": 12.874324798583984,
      "learning_rate": 1.8674285714285717e-05,
      "loss": 0.3741,
      "step": 1160
    },
    {
      "epoch": 0.6685714285714286,
      "grad_norm": 16.173662185668945,
      "learning_rate": 1.8662857142857144e-05,
      "loss": 0.3072,
      "step": 1170
    },
    {
      "epoch": 0.6742857142857143,
      "grad_norm": 8.299016952514648,
      "learning_rate": 1.8651428571428574e-05,
      "loss": 0.2714,
      "step": 1180
    },
    {
      "epoch": 0.68,
      "grad_norm": 15.03200626373291,
      "learning_rate": 1.864e-05,
      "loss": 0.3885,
      "step": 1190
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 12.069793701171875,
      "learning_rate": 1.8628571428571428e-05,
      "loss": 0.3568,
      "step": 1200
    },
    {
      "epoch": 0.6914285714285714,
      "grad_norm": 10.06696891784668,
      "learning_rate": 1.8617142857142858e-05,
      "loss": 0.2697,
      "step": 1210
    },
    {
      "epoch": 0.6971428571428572,
      "grad_norm": 17.68910789489746,
      "learning_rate": 1.8605714285714288e-05,
      "loss": 0.3056,
      "step": 1220
    },
    {
      "epoch": 0.7028571428571428,
      "grad_norm": 7.04074239730835,
      "learning_rate": 1.8594285714285715e-05,
      "loss": 0.2206,
      "step": 1230
    },
    {
      "epoch": 0.7085714285714285,
      "grad_norm": 12.470552444458008,
      "learning_rate": 1.8582857142857145e-05,
      "loss": 0.2288,
      "step": 1240
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 9.162248611450195,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 0.4782,
      "step": 1250
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.343416213989258,
      "learning_rate": 1.8560000000000002e-05,
      "loss": 0.2297,
      "step": 1260
    },
    {
      "epoch": 0.7257142857142858,
      "grad_norm": 21.69700050354004,
      "learning_rate": 1.854857142857143e-05,
      "loss": 0.2005,
      "step": 1270
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 9.464151382446289,
      "learning_rate": 1.853714285714286e-05,
      "loss": 0.2614,
      "step": 1280
    },
    {
      "epoch": 0.7371428571428571,
      "grad_norm": 4.705657005310059,
      "learning_rate": 1.8525714285714285e-05,
      "loss": 0.1859,
      "step": 1290
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 7.701251029968262,
      "learning_rate": 1.8514285714285716e-05,
      "loss": 0.1661,
      "step": 1300
    },
    {
      "epoch": 0.7485714285714286,
      "grad_norm": 10.888569831848145,
      "learning_rate": 1.8502857142857146e-05,
      "loss": 0.2627,
      "step": 1310
    },
    {
      "epoch": 0.7542857142857143,
      "grad_norm": 14.189963340759277,
      "learning_rate": 1.8491428571428573e-05,
      "loss": 0.2547,
      "step": 1320
    },
    {
      "epoch": 0.76,
      "grad_norm": 13.37141227722168,
      "learning_rate": 1.8480000000000003e-05,
      "loss": 0.2833,
      "step": 1330
    },
    {
      "epoch": 0.7657142857142857,
      "grad_norm": 9.710814476013184,
      "learning_rate": 1.846857142857143e-05,
      "loss": 0.1863,
      "step": 1340
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 6.268887996673584,
      "learning_rate": 1.845714285714286e-05,
      "loss": 0.2641,
      "step": 1350
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 10.20964527130127,
      "learning_rate": 1.8445714285714286e-05,
      "loss": 0.2261,
      "step": 1360
    },
    {
      "epoch": 0.7828571428571428,
      "grad_norm": 17.93502426147461,
      "learning_rate": 1.8434285714285716e-05,
      "loss": 0.3219,
      "step": 1370
    },
    {
      "epoch": 0.7885714285714286,
      "grad_norm": 1.7295633554458618,
      "learning_rate": 1.8422857142857143e-05,
      "loss": 0.173,
      "step": 1380
    },
    {
      "epoch": 0.7942857142857143,
      "grad_norm": 4.0937275886535645,
      "learning_rate": 1.8411428571428573e-05,
      "loss": 0.2801,
      "step": 1390
    },
    {
      "epoch": 0.8,
      "grad_norm": 14.007879257202148,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.2408,
      "step": 1400
    },
    {
      "epoch": 0.8057142857142857,
      "grad_norm": 14.226612091064453,
      "learning_rate": 1.838857142857143e-05,
      "loss": 0.1935,
      "step": 1410
    },
    {
      "epoch": 0.8114285714285714,
      "grad_norm": 5.339355945587158,
      "learning_rate": 1.8377142857142857e-05,
      "loss": 0.2683,
      "step": 1420
    },
    {
      "epoch": 0.8171428571428572,
      "grad_norm": 1.481709361076355,
      "learning_rate": 1.8365714285714287e-05,
      "loss": 0.1336,
      "step": 1430
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 14.090778350830078,
      "learning_rate": 1.8354285714285717e-05,
      "loss": 0.2822,
      "step": 1440
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 9.705304145812988,
      "learning_rate": 1.8342857142857144e-05,
      "loss": 0.2165,
      "step": 1450
    },
    {
      "epoch": 0.8342857142857143,
      "grad_norm": 9.602710723876953,
      "learning_rate": 1.8331428571428574e-05,
      "loss": 0.1882,
      "step": 1460
    },
    {
      "epoch": 0.84,
      "grad_norm": 12.072163581848145,
      "learning_rate": 1.832e-05,
      "loss": 0.1909,
      "step": 1470
    },
    {
      "epoch": 0.8457142857142858,
      "grad_norm": 13.791359901428223,
      "learning_rate": 1.830857142857143e-05,
      "loss": 0.2462,
      "step": 1480
    },
    {
      "epoch": 0.8514285714285714,
      "grad_norm": 15.88005256652832,
      "learning_rate": 1.8297142857142858e-05,
      "loss": 0.1966,
      "step": 1490
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 6.7439422607421875,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 0.2017,
      "step": 1500
    },
    {
      "epoch": 0.8628571428571429,
      "grad_norm": 13.659331321716309,
      "learning_rate": 1.8274285714285715e-05,
      "loss": 0.2849,
      "step": 1510
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 2.62154483795166,
      "learning_rate": 1.8262857142857145e-05,
      "loss": 0.1863,
      "step": 1520
    },
    {
      "epoch": 0.8742857142857143,
      "grad_norm": 9.926300048828125,
      "learning_rate": 1.8251428571428575e-05,
      "loss": 0.2407,
      "step": 1530
    },
    {
      "epoch": 0.88,
      "grad_norm": 8.166239738464355,
      "learning_rate": 1.824e-05,
      "loss": 0.2617,
      "step": 1540
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 13.161648750305176,
      "learning_rate": 1.822857142857143e-05,
      "loss": 0.3023,
      "step": 1550
    },
    {
      "epoch": 0.8914285714285715,
      "grad_norm": 2.621809720993042,
      "learning_rate": 1.821714285714286e-05,
      "loss": 0.2694,
      "step": 1560
    },
    {
      "epoch": 0.8971428571428571,
      "grad_norm": 8.685898780822754,
      "learning_rate": 1.8205714285714285e-05,
      "loss": 0.1016,
      "step": 1570
    },
    {
      "epoch": 0.9028571428571428,
      "grad_norm": 9.225349426269531,
      "learning_rate": 1.8194285714285715e-05,
      "loss": 0.1545,
      "step": 1580
    },
    {
      "epoch": 0.9085714285714286,
      "grad_norm": 3.082282304763794,
      "learning_rate": 1.8182857142857145e-05,
      "loss": 0.1426,
      "step": 1590
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 9.24902629852295,
      "learning_rate": 1.8171428571428572e-05,
      "loss": 0.2308,
      "step": 1600
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.5473359823226929,
      "learning_rate": 1.8160000000000002e-05,
      "loss": 0.1708,
      "step": 1610
    },
    {
      "epoch": 0.9257142857142857,
      "grad_norm": 9.585261344909668,
      "learning_rate": 1.8148571428571432e-05,
      "loss": 0.2473,
      "step": 1620
    },
    {
      "epoch": 0.9314285714285714,
      "grad_norm": 8.759573936462402,
      "learning_rate": 1.813714285714286e-05,
      "loss": 0.1952,
      "step": 1630
    },
    {
      "epoch": 0.9371428571428572,
      "grad_norm": 6.281344890594482,
      "learning_rate": 1.8125714285714286e-05,
      "loss": 0.2019,
      "step": 1640
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 0.34324562549591064,
      "learning_rate": 1.8114285714285716e-05,
      "loss": 0.2554,
      "step": 1650
    },
    {
      "epoch": 0.9485714285714286,
      "grad_norm": 9.103185653686523,
      "learning_rate": 1.8102857142857143e-05,
      "loss": 0.1651,
      "step": 1660
    },
    {
      "epoch": 0.9542857142857143,
      "grad_norm": 0.3400559425354004,
      "learning_rate": 1.8091428571428573e-05,
      "loss": 0.1009,
      "step": 1670
    },
    {
      "epoch": 0.96,
      "grad_norm": 19.999187469482422,
      "learning_rate": 1.8080000000000003e-05,
      "loss": 0.2069,
      "step": 1680
    },
    {
      "epoch": 0.9657142857142857,
      "grad_norm": 10.35463809967041,
      "learning_rate": 1.806857142857143e-05,
      "loss": 0.2074,
      "step": 1690
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 6.416211128234863,
      "learning_rate": 1.8057142857142857e-05,
      "loss": 0.1902,
      "step": 1700
    },
    {
      "epoch": 0.9771428571428571,
      "grad_norm": 9.33540153503418,
      "learning_rate": 1.8045714285714287e-05,
      "loss": 0.1835,
      "step": 1710
    },
    {
      "epoch": 0.9828571428571429,
      "grad_norm": 6.309079647064209,
      "learning_rate": 1.8034285714285717e-05,
      "loss": 0.1742,
      "step": 1720
    },
    {
      "epoch": 0.9885714285714285,
      "grad_norm": 1.9766771793365479,
      "learning_rate": 1.8022857142857144e-05,
      "loss": 0.2009,
      "step": 1730
    },
    {
      "epoch": 0.9942857142857143,
      "grad_norm": 1.879321575164795,
      "learning_rate": 1.8011428571428574e-05,
      "loss": 0.2188,
      "step": 1740
    },
    {
      "epoch": 1.0,
      "grad_norm": 9.343682289123535,
      "learning_rate": 1.8e-05,
      "loss": 0.1896,
      "step": 1750
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9461898395721925,
      "eval_f1": 0.771631205673759,
      "eval_loss": 0.16315285861492157,
      "eval_precision": 0.8816855753646677,
      "eval_recall": 0.6860025220680959,
      "eval_runtime": 56.0894,
      "eval_samples_per_second": 106.972,
      "eval_steps_per_second": 3.352,
      "step": 1750
    },
    {
      "epoch": 1.0057142857142858,
      "grad_norm": 2.4724936485290527,
      "learning_rate": 1.798857142857143e-05,
      "loss": 0.1873,
      "step": 1760
    },
    {
      "epoch": 1.0114285714285713,
      "grad_norm": 3.6619601249694824,
      "learning_rate": 1.797714285714286e-05,
      "loss": 0.1657,
      "step": 1770
    },
    {
      "epoch": 1.0171428571428571,
      "grad_norm": 15.372180938720703,
      "learning_rate": 1.7965714285714287e-05,
      "loss": 0.0783,
      "step": 1780
    },
    {
      "epoch": 1.022857142857143,
      "grad_norm": 16.517894744873047,
      "learning_rate": 1.7954285714285714e-05,
      "loss": 0.2479,
      "step": 1790
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 7.934584617614746,
      "learning_rate": 1.7942857142857144e-05,
      "loss": 0.1786,
      "step": 1800
    },
    {
      "epoch": 1.0342857142857143,
      "grad_norm": 10.045391082763672,
      "learning_rate": 1.7931428571428574e-05,
      "loss": 0.3056,
      "step": 1810
    },
    {
      "epoch": 1.04,
      "grad_norm": 10.201040267944336,
      "learning_rate": 1.792e-05,
      "loss": 0.2578,
      "step": 1820
    },
    {
      "epoch": 1.0457142857142858,
      "grad_norm": 8.350825309753418,
      "learning_rate": 1.790857142857143e-05,
      "loss": 0.1733,
      "step": 1830
    },
    {
      "epoch": 1.0514285714285714,
      "grad_norm": 2.6429502964019775,
      "learning_rate": 1.7897142857142858e-05,
      "loss": 0.1843,
      "step": 1840
    },
    {
      "epoch": 1.0571428571428572,
      "grad_norm": 0.20333988964557648,
      "learning_rate": 1.7885714285714285e-05,
      "loss": 0.1542,
      "step": 1850
    },
    {
      "epoch": 1.062857142857143,
      "grad_norm": 4.941990375518799,
      "learning_rate": 1.7874285714285715e-05,
      "loss": 0.1082,
      "step": 1860
    },
    {
      "epoch": 1.0685714285714285,
      "grad_norm": 3.3718433380126953,
      "learning_rate": 1.7862857142857145e-05,
      "loss": 0.0307,
      "step": 1870
    },
    {
      "epoch": 1.0742857142857143,
      "grad_norm": 20.662656784057617,
      "learning_rate": 1.7851428571428572e-05,
      "loss": 0.2644,
      "step": 1880
    },
    {
      "epoch": 1.08,
      "grad_norm": 8.969339370727539,
      "learning_rate": 1.7840000000000002e-05,
      "loss": 0.0762,
      "step": 1890
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 0.6443754434585571,
      "learning_rate": 1.7828571428571432e-05,
      "loss": 0.2576,
      "step": 1900
    },
    {
      "epoch": 1.0914285714285714,
      "grad_norm": 16.66537094116211,
      "learning_rate": 1.781714285714286e-05,
      "loss": 0.1408,
      "step": 1910
    },
    {
      "epoch": 1.0971428571428572,
      "grad_norm": 2.587658643722534,
      "learning_rate": 1.7805714285714286e-05,
      "loss": 0.1937,
      "step": 1920
    },
    {
      "epoch": 1.1028571428571428,
      "grad_norm": 11.938704490661621,
      "learning_rate": 1.7794285714285716e-05,
      "loss": 0.1704,
      "step": 1930
    },
    {
      "epoch": 1.1085714285714285,
      "grad_norm": 12.468421936035156,
      "learning_rate": 1.7782857142857142e-05,
      "loss": 0.1614,
      "step": 1940
    },
    {
      "epoch": 1.1142857142857143,
      "grad_norm": 6.334518909454346,
      "learning_rate": 1.7771428571428573e-05,
      "loss": 0.1665,
      "step": 1950
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.04803593456745148,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.0458,
      "step": 1960
    },
    {
      "epoch": 1.1257142857142857,
      "grad_norm": 9.427963256835938,
      "learning_rate": 1.774857142857143e-05,
      "loss": 0.3083,
      "step": 1970
    },
    {
      "epoch": 1.1314285714285715,
      "grad_norm": 12.654135704040527,
      "learning_rate": 1.773714285714286e-05,
      "loss": 0.2426,
      "step": 1980
    },
    {
      "epoch": 1.1371428571428572,
      "grad_norm": 10.990890502929688,
      "learning_rate": 1.7725714285714286e-05,
      "loss": 0.2939,
      "step": 1990
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 9.116172790527344,
      "learning_rate": 1.7714285714285717e-05,
      "loss": 0.1443,
      "step": 2000
    },
    {
      "epoch": 1.1485714285714286,
      "grad_norm": 11.686861991882324,
      "learning_rate": 1.7702857142857143e-05,
      "loss": 0.1829,
      "step": 2010
    },
    {
      "epoch": 1.1542857142857144,
      "grad_norm": 12.872554779052734,
      "learning_rate": 1.7691428571428573e-05,
      "loss": 0.0824,
      "step": 2020
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.664551734924316,
      "learning_rate": 1.768e-05,
      "loss": 0.2094,
      "step": 2030
    },
    {
      "epoch": 1.1657142857142857,
      "grad_norm": 6.108489036560059,
      "learning_rate": 1.766857142857143e-05,
      "loss": 0.171,
      "step": 2040
    },
    {
      "epoch": 1.1714285714285715,
      "grad_norm": 0.07513981312513351,
      "learning_rate": 1.765714285714286e-05,
      "loss": 0.1167,
      "step": 2050
    },
    {
      "epoch": 1.177142857142857,
      "grad_norm": 20.391372680664062,
      "learning_rate": 1.7645714285714287e-05,
      "loss": 0.2236,
      "step": 2060
    },
    {
      "epoch": 1.1828571428571428,
      "grad_norm": 14.2567777633667,
      "learning_rate": 1.7634285714285714e-05,
      "loss": 0.1227,
      "step": 2070
    },
    {
      "epoch": 1.1885714285714286,
      "grad_norm": 3.80456805229187,
      "learning_rate": 1.7622857142857144e-05,
      "loss": 0.1638,
      "step": 2080
    },
    {
      "epoch": 1.1942857142857144,
      "grad_norm": 8.964751243591309,
      "learning_rate": 1.7611428571428574e-05,
      "loss": 0.1604,
      "step": 2090
    },
    {
      "epoch": 1.2,
      "grad_norm": 17.098093032836914,
      "learning_rate": 1.76e-05,
      "loss": 0.1165,
      "step": 2100
    },
    {
      "epoch": 1.2057142857142857,
      "grad_norm": 8.558725357055664,
      "learning_rate": 1.758857142857143e-05,
      "loss": 0.1648,
      "step": 2110
    },
    {
      "epoch": 1.2114285714285715,
      "grad_norm": 18.94797134399414,
      "learning_rate": 1.7577142857142858e-05,
      "loss": 0.3156,
      "step": 2120
    },
    {
      "epoch": 1.217142857142857,
      "grad_norm": 9.025993347167969,
      "learning_rate": 1.7565714285714288e-05,
      "loss": 0.0671,
      "step": 2130
    },
    {
      "epoch": 1.2228571428571429,
      "grad_norm": 8.299955368041992,
      "learning_rate": 1.7554285714285715e-05,
      "loss": 0.148,
      "step": 2140
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 43.198455810546875,
      "learning_rate": 1.7542857142857145e-05,
      "loss": 0.2299,
      "step": 2150
    },
    {
      "epoch": 1.2342857142857142,
      "grad_norm": 9.967758178710938,
      "learning_rate": 1.753142857142857e-05,
      "loss": 0.1196,
      "step": 2160
    },
    {
      "epoch": 1.24,
      "grad_norm": 9.641989707946777,
      "learning_rate": 1.752e-05,
      "loss": 0.1554,
      "step": 2170
    },
    {
      "epoch": 1.2457142857142858,
      "grad_norm": 18.80243682861328,
      "learning_rate": 1.7508571428571432e-05,
      "loss": 0.1817,
      "step": 2180
    },
    {
      "epoch": 1.2514285714285713,
      "grad_norm": 9.129779815673828,
      "learning_rate": 1.749714285714286e-05,
      "loss": 0.2264,
      "step": 2190
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 0.7154133319854736,
      "learning_rate": 1.748571428571429e-05,
      "loss": 0.2022,
      "step": 2200
    },
    {
      "epoch": 1.262857142857143,
      "grad_norm": 2.77604079246521,
      "learning_rate": 1.7474285714285715e-05,
      "loss": 0.0886,
      "step": 2210
    },
    {
      "epoch": 1.2685714285714287,
      "grad_norm": 18.947607040405273,
      "learning_rate": 1.7462857142857142e-05,
      "loss": 0.1646,
      "step": 2220
    },
    {
      "epoch": 1.2742857142857142,
      "grad_norm": 10.638097763061523,
      "learning_rate": 1.7451428571428572e-05,
      "loss": 0.1288,
      "step": 2230
    },
    {
      "epoch": 1.28,
      "grad_norm": 7.02099084854126,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 0.1723,
      "step": 2240
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 17.126781463623047,
      "learning_rate": 1.742857142857143e-05,
      "loss": 0.0774,
      "step": 2250
    },
    {
      "epoch": 1.2914285714285714,
      "grad_norm": 10.20018482208252,
      "learning_rate": 1.741714285714286e-05,
      "loss": 0.283,
      "step": 2260
    },
    {
      "epoch": 1.2971428571428572,
      "grad_norm": 4.602967262268066,
      "learning_rate": 1.740571428571429e-05,
      "loss": 0.2517,
      "step": 2270
    },
    {
      "epoch": 1.302857142857143,
      "grad_norm": 2.8840818405151367,
      "learning_rate": 1.7394285714285716e-05,
      "loss": 0.0937,
      "step": 2280
    },
    {
      "epoch": 1.3085714285714285,
      "grad_norm": 10.063597679138184,
      "learning_rate": 1.7382857142857143e-05,
      "loss": 0.1593,
      "step": 2290
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 11.411953926086426,
      "learning_rate": 1.7371428571428573e-05,
      "loss": 0.1656,
      "step": 2300
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.000393867492676,
      "learning_rate": 1.736e-05,
      "loss": 0.1125,
      "step": 2310
    },
    {
      "epoch": 1.3257142857142856,
      "grad_norm": 5.109760761260986,
      "learning_rate": 1.734857142857143e-05,
      "loss": 0.1289,
      "step": 2320
    },
    {
      "epoch": 1.3314285714285714,
      "grad_norm": 0.8646678328514099,
      "learning_rate": 1.733714285714286e-05,
      "loss": 0.1069,
      "step": 2330
    },
    {
      "epoch": 1.3371428571428572,
      "grad_norm": 14.682716369628906,
      "learning_rate": 1.7325714285714287e-05,
      "loss": 0.1994,
      "step": 2340
    },
    {
      "epoch": 1.342857142857143,
      "grad_norm": 0.9498914480209351,
      "learning_rate": 1.7314285714285717e-05,
      "loss": 0.19,
      "step": 2350
    },
    {
      "epoch": 1.3485714285714285,
      "grad_norm": 8.032270431518555,
      "learning_rate": 1.7302857142857144e-05,
      "loss": 0.1401,
      "step": 2360
    },
    {
      "epoch": 1.3542857142857143,
      "grad_norm": 10.475859642028809,
      "learning_rate": 1.7291428571428574e-05,
      "loss": 0.0736,
      "step": 2370
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 10.407779693603516,
      "learning_rate": 1.728e-05,
      "loss": 0.2435,
      "step": 2380
    },
    {
      "epoch": 1.3657142857142857,
      "grad_norm": 10.322989463806152,
      "learning_rate": 1.726857142857143e-05,
      "loss": 0.2096,
      "step": 2390
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 3.348674774169922,
      "learning_rate": 1.7257142857142857e-05,
      "loss": 0.1036,
      "step": 2400
    },
    {
      "epoch": 1.3771428571428572,
      "grad_norm": 1.570691466331482,
      "learning_rate": 1.7245714285714288e-05,
      "loss": 0.1214,
      "step": 2410
    },
    {
      "epoch": 1.3828571428571428,
      "grad_norm": 13.268455505371094,
      "learning_rate": 1.7234285714285718e-05,
      "loss": 0.171,
      "step": 2420
    },
    {
      "epoch": 1.3885714285714286,
      "grad_norm": 1.325249433517456,
      "learning_rate": 1.7222857142857144e-05,
      "loss": 0.0349,
      "step": 2430
    },
    {
      "epoch": 1.3942857142857144,
      "grad_norm": 11.920591354370117,
      "learning_rate": 1.721142857142857e-05,
      "loss": 0.0738,
      "step": 2440
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.10699141770601273,
      "learning_rate": 1.72e-05,
      "loss": 0.103,
      "step": 2450
    },
    {
      "epoch": 1.4057142857142857,
      "grad_norm": 7.655333042144775,
      "learning_rate": 1.718857142857143e-05,
      "loss": 0.2074,
      "step": 2460
    },
    {
      "epoch": 1.4114285714285715,
      "grad_norm": 1.1891183853149414,
      "learning_rate": 1.7177142857142858e-05,
      "loss": 0.1558,
      "step": 2470
    },
    {
      "epoch": 1.4171428571428573,
      "grad_norm": 18.885967254638672,
      "learning_rate": 1.716571428571429e-05,
      "loss": 0.2578,
      "step": 2480
    },
    {
      "epoch": 1.4228571428571428,
      "grad_norm": 13.39553451538086,
      "learning_rate": 1.7154285714285715e-05,
      "loss": 0.1241,
      "step": 2490
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.4597913324832916,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.2191,
      "step": 2500
    },
    {
      "epoch": 1.4342857142857142,
      "grad_norm": 10.317317008972168,
      "learning_rate": 1.7131428571428572e-05,
      "loss": 0.1084,
      "step": 2510
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.38475510478019714,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 0.1947,
      "step": 2520
    },
    {
      "epoch": 1.4457142857142857,
      "grad_norm": 9.84854507446289,
      "learning_rate": 1.710857142857143e-05,
      "loss": 0.1753,
      "step": 2530
    },
    {
      "epoch": 1.4514285714285715,
      "grad_norm": 8.577589988708496,
      "learning_rate": 1.709714285714286e-05,
      "loss": 0.0969,
      "step": 2540
    },
    {
      "epoch": 1.457142857142857,
      "grad_norm": 0.03693579137325287,
      "learning_rate": 1.708571428571429e-05,
      "loss": 0.1211,
      "step": 2550
    },
    {
      "epoch": 1.4628571428571429,
      "grad_norm": 19.397994995117188,
      "learning_rate": 1.7074285714285716e-05,
      "loss": 0.1128,
      "step": 2560
    },
    {
      "epoch": 1.4685714285714286,
      "grad_norm": 1.748002290725708,
      "learning_rate": 1.7062857142857143e-05,
      "loss": 0.2583,
      "step": 2570
    },
    {
      "epoch": 1.4742857142857142,
      "grad_norm": 3.182889461517334,
      "learning_rate": 1.7051428571428573e-05,
      "loss": 0.1272,
      "step": 2580
    },
    {
      "epoch": 1.48,
      "grad_norm": 19.886287689208984,
      "learning_rate": 1.704e-05,
      "loss": 0.1354,
      "step": 2590
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 0.9964302182197571,
      "learning_rate": 1.702857142857143e-05,
      "loss": 0.1368,
      "step": 2600
    },
    {
      "epoch": 1.4914285714285715,
      "grad_norm": 13.17175006866455,
      "learning_rate": 1.701714285714286e-05,
      "loss": 0.0815,
      "step": 2610
    },
    {
      "epoch": 1.497142857142857,
      "grad_norm": 4.5094194412231445,
      "learning_rate": 1.7005714285714286e-05,
      "loss": 0.105,
      "step": 2620
    },
    {
      "epoch": 1.502857142857143,
      "grad_norm": 1.700177788734436,
      "learning_rate": 1.6994285714285717e-05,
      "loss": 0.0458,
      "step": 2630
    },
    {
      "epoch": 1.5085714285714285,
      "grad_norm": 6.94557523727417,
      "learning_rate": 1.6982857142857143e-05,
      "loss": 0.1323,
      "step": 2640
    },
    {
      "epoch": 1.5142857142857142,
      "grad_norm": 8.854972839355469,
      "learning_rate": 1.6971428571428574e-05,
      "loss": 0.1532,
      "step": 2650
    },
    {
      "epoch": 1.52,
      "grad_norm": 11.105834007263184,
      "learning_rate": 1.696e-05,
      "loss": 0.1385,
      "step": 2660
    },
    {
      "epoch": 1.5257142857142858,
      "grad_norm": 4.218008518218994,
      "learning_rate": 1.694857142857143e-05,
      "loss": 0.0949,
      "step": 2670
    },
    {
      "epoch": 1.5314285714285716,
      "grad_norm": 16.361337661743164,
      "learning_rate": 1.6937142857142857e-05,
      "loss": 0.1476,
      "step": 2680
    },
    {
      "epoch": 1.5371428571428571,
      "grad_norm": 0.4478384852409363,
      "learning_rate": 1.6925714285714287e-05,
      "loss": 0.0957,
      "step": 2690
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 1.2821786403656006,
      "learning_rate": 1.6914285714285717e-05,
      "loss": 0.1162,
      "step": 2700
    },
    {
      "epoch": 1.5485714285714285,
      "grad_norm": 0.0824246034026146,
      "learning_rate": 1.6902857142857144e-05,
      "loss": 0.1462,
      "step": 2710
    },
    {
      "epoch": 1.5542857142857143,
      "grad_norm": 1.3341927528381348,
      "learning_rate": 1.689142857142857e-05,
      "loss": 0.1408,
      "step": 2720
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.08233661204576492,
      "learning_rate": 1.688e-05,
      "loss": 0.2061,
      "step": 2730
    },
    {
      "epoch": 1.5657142857142858,
      "grad_norm": 0.07801054418087006,
      "learning_rate": 1.686857142857143e-05,
      "loss": 0.0654,
      "step": 2740
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 10.999133110046387,
      "learning_rate": 1.6857142857142858e-05,
      "loss": 0.1172,
      "step": 2750
    },
    {
      "epoch": 1.5771428571428572,
      "grad_norm": 2.829360246658325,
      "learning_rate": 1.6845714285714288e-05,
      "loss": 0.0708,
      "step": 2760
    },
    {
      "epoch": 1.5828571428571427,
      "grad_norm": 5.197282791137695,
      "learning_rate": 1.6834285714285715e-05,
      "loss": 0.1418,
      "step": 2770
    },
    {
      "epoch": 1.5885714285714285,
      "grad_norm": 10.060215950012207,
      "learning_rate": 1.6822857142857145e-05,
      "loss": 0.1429,
      "step": 2780
    },
    {
      "epoch": 1.5942857142857143,
      "grad_norm": 0.6126607060432434,
      "learning_rate": 1.681142857142857e-05,
      "loss": 0.088,
      "step": 2790
    },
    {
      "epoch": 1.6,
      "grad_norm": 12.816444396972656,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0873,
      "step": 2800
    },
    {
      "epoch": 1.6057142857142859,
      "grad_norm": 17.071208953857422,
      "learning_rate": 1.678857142857143e-05,
      "loss": 0.2001,
      "step": 2810
    },
    {
      "epoch": 1.6114285714285714,
      "grad_norm": 2.4295008182525635,
      "learning_rate": 1.677714285714286e-05,
      "loss": 0.0972,
      "step": 2820
    },
    {
      "epoch": 1.617142857142857,
      "grad_norm": 2.0062835216522217,
      "learning_rate": 1.676571428571429e-05,
      "loss": 0.1091,
      "step": 2830
    },
    {
      "epoch": 1.6228571428571428,
      "grad_norm": 10.400745391845703,
      "learning_rate": 1.6754285714285716e-05,
      "loss": 0.1269,
      "step": 2840
    },
    {
      "epoch": 1.6285714285714286,
      "grad_norm": 4.2295732498168945,
      "learning_rate": 1.6742857142857146e-05,
      "loss": 0.0905,
      "step": 2850
    },
    {
      "epoch": 1.6342857142857143,
      "grad_norm": 0.10116491466760635,
      "learning_rate": 1.6731428571428572e-05,
      "loss": 0.1223,
      "step": 2860
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.0732293576002121,
      "learning_rate": 1.672e-05,
      "loss": 0.1464,
      "step": 2870
    },
    {
      "epoch": 1.6457142857142857,
      "grad_norm": 0.38329535722732544,
      "learning_rate": 1.670857142857143e-05,
      "loss": 0.0828,
      "step": 2880
    },
    {
      "epoch": 1.6514285714285715,
      "grad_norm": 0.24156413972377777,
      "learning_rate": 1.669714285714286e-05,
      "loss": 0.2298,
      "step": 2890
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 0.18089434504508972,
      "learning_rate": 1.6685714285714286e-05,
      "loss": 0.0645,
      "step": 2900
    },
    {
      "epoch": 1.6628571428571428,
      "grad_norm": 12.071842193603516,
      "learning_rate": 1.6674285714285716e-05,
      "loss": 0.1182,
      "step": 2910
    },
    {
      "epoch": 1.6685714285714286,
      "grad_norm": 14.770495414733887,
      "learning_rate": 1.6662857142857146e-05,
      "loss": 0.1648,
      "step": 2920
    },
    {
      "epoch": 1.6742857142857144,
      "grad_norm": 10.525808334350586,
      "learning_rate": 1.6651428571428573e-05,
      "loss": 0.1298,
      "step": 2930
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.06932807713747025,
      "learning_rate": 1.664e-05,
      "loss": 0.0795,
      "step": 2940
    },
    {
      "epoch": 1.6857142857142857,
      "grad_norm": 0.355711430311203,
      "learning_rate": 1.662857142857143e-05,
      "loss": 0.0447,
      "step": 2950
    },
    {
      "epoch": 1.6914285714285713,
      "grad_norm": 12.292215347290039,
      "learning_rate": 1.6617142857142857e-05,
      "loss": 0.1658,
      "step": 2960
    },
    {
      "epoch": 1.697142857142857,
      "grad_norm": 8.261096954345703,
      "learning_rate": 1.6605714285714287e-05,
      "loss": 0.1985,
      "step": 2970
    },
    {
      "epoch": 1.7028571428571428,
      "grad_norm": 12.16043758392334,
      "learning_rate": 1.6594285714285717e-05,
      "loss": 0.2262,
      "step": 2980
    },
    {
      "epoch": 1.7085714285714286,
      "grad_norm": 0.12087657302618027,
      "learning_rate": 1.6582857142857144e-05,
      "loss": 0.0759,
      "step": 2990
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 18.989315032958984,
      "learning_rate": 1.6571428571428574e-05,
      "loss": 0.1472,
      "step": 3000
    },
    {
      "epoch": 1.72,
      "grad_norm": 8.367131233215332,
      "learning_rate": 1.656e-05,
      "loss": 0.1811,
      "step": 3010
    },
    {
      "epoch": 1.7257142857142858,
      "grad_norm": 18.03797149658203,
      "learning_rate": 1.654857142857143e-05,
      "loss": 0.2069,
      "step": 3020
    },
    {
      "epoch": 1.7314285714285713,
      "grad_norm": 19.295644760131836,
      "learning_rate": 1.6537142857142858e-05,
      "loss": 0.2233,
      "step": 3030
    },
    {
      "epoch": 1.737142857142857,
      "grad_norm": 1.1546509265899658,
      "learning_rate": 1.6525714285714288e-05,
      "loss": 0.0278,
      "step": 3040
    },
    {
      "epoch": 1.7428571428571429,
      "grad_norm": 0.6094495058059692,
      "learning_rate": 1.6514285714285714e-05,
      "loss": 0.0949,
      "step": 3050
    },
    {
      "epoch": 1.7485714285714287,
      "grad_norm": 4.93423318862915,
      "learning_rate": 1.6502857142857145e-05,
      "loss": 0.1396,
      "step": 3060
    },
    {
      "epoch": 1.7542857142857144,
      "grad_norm": 11.492733001708984,
      "learning_rate": 1.6491428571428575e-05,
      "loss": 0.2007,
      "step": 3070
    },
    {
      "epoch": 1.76,
      "grad_norm": 11.488128662109375,
      "learning_rate": 1.648e-05,
      "loss": 0.2813,
      "step": 3080
    },
    {
      "epoch": 1.7657142857142856,
      "grad_norm": 18.34518051147461,
      "learning_rate": 1.6468571428571428e-05,
      "loss": 0.0776,
      "step": 3090
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 16.94249725341797,
      "learning_rate": 1.645714285714286e-05,
      "loss": 0.1448,
      "step": 3100
    },
    {
      "epoch": 1.7771428571428571,
      "grad_norm": 24.274288177490234,
      "learning_rate": 1.644571428571429e-05,
      "loss": 0.1602,
      "step": 3110
    },
    {
      "epoch": 1.782857142857143,
      "grad_norm": 34.70793914794922,
      "learning_rate": 1.6434285714285715e-05,
      "loss": 0.2725,
      "step": 3120
    },
    {
      "epoch": 1.7885714285714287,
      "grad_norm": 96.65573120117188,
      "learning_rate": 1.6422857142857145e-05,
      "loss": 0.1764,
      "step": 3130
    },
    {
      "epoch": 1.7942857142857143,
      "grad_norm": 7.479729652404785,
      "learning_rate": 1.6411428571428572e-05,
      "loss": 0.0894,
      "step": 3140
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.2509042024612427,
      "learning_rate": 1.64e-05,
      "loss": 0.0979,
      "step": 3150
    },
    {
      "epoch": 1.8057142857142856,
      "grad_norm": 11.294879913330078,
      "learning_rate": 1.638857142857143e-05,
      "loss": 0.0526,
      "step": 3160
    },
    {
      "epoch": 1.8114285714285714,
      "grad_norm": 9.115999221801758,
      "learning_rate": 1.637714285714286e-05,
      "loss": 0.1171,
      "step": 3170
    },
    {
      "epoch": 1.8171428571428572,
      "grad_norm": 2.015630006790161,
      "learning_rate": 1.6365714285714286e-05,
      "loss": 0.0525,
      "step": 3180
    },
    {
      "epoch": 1.822857142857143,
      "grad_norm": 14.20838451385498,
      "learning_rate": 1.6354285714285716e-05,
      "loss": 0.123,
      "step": 3190
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 0.028542645275592804,
      "learning_rate": 1.6342857142857146e-05,
      "loss": 0.1566,
      "step": 3200
    },
    {
      "epoch": 1.8342857142857143,
      "grad_norm": 0.28752651810646057,
      "learning_rate": 1.6331428571428573e-05,
      "loss": 0.1367,
      "step": 3210
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.34962210059165955,
      "learning_rate": 1.632e-05,
      "loss": 0.0587,
      "step": 3220
    },
    {
      "epoch": 1.8457142857142856,
      "grad_norm": 1.7023026943206787,
      "learning_rate": 1.630857142857143e-05,
      "loss": 0.0536,
      "step": 3230
    },
    {
      "epoch": 1.8514285714285714,
      "grad_norm": 0.04255567118525505,
      "learning_rate": 1.6297142857142856e-05,
      "loss": 0.0769,
      "step": 3240
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 6.771317481994629,
      "learning_rate": 1.6285714285714287e-05,
      "loss": 0.2851,
      "step": 3250
    },
    {
      "epoch": 1.862857142857143,
      "grad_norm": 19.347904205322266,
      "learning_rate": 1.6274285714285717e-05,
      "loss": 0.1654,
      "step": 3260
    },
    {
      "epoch": 1.8685714285714285,
      "grad_norm": 0.4413418471813202,
      "learning_rate": 1.6262857142857143e-05,
      "loss": 0.163,
      "step": 3270
    },
    {
      "epoch": 1.8742857142857143,
      "grad_norm": 16.788742065429688,
      "learning_rate": 1.6251428571428574e-05,
      "loss": 0.1744,
      "step": 3280
    },
    {
      "epoch": 1.88,
      "grad_norm": 7.71016788482666,
      "learning_rate": 1.6240000000000004e-05,
      "loss": 0.2007,
      "step": 3290
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 0.2006063610315323,
      "learning_rate": 1.622857142857143e-05,
      "loss": 0.0965,
      "step": 3300
    },
    {
      "epoch": 1.8914285714285715,
      "grad_norm": 0.8053349852561951,
      "learning_rate": 1.6217142857142857e-05,
      "loss": 0.0706,
      "step": 3310
    },
    {
      "epoch": 1.8971428571428572,
      "grad_norm": 8.514482498168945,
      "learning_rate": 1.6205714285714287e-05,
      "loss": 0.1701,
      "step": 3320
    },
    {
      "epoch": 1.9028571428571428,
      "grad_norm": 6.444735527038574,
      "learning_rate": 1.6194285714285714e-05,
      "loss": 0.108,
      "step": 3330
    },
    {
      "epoch": 1.9085714285714286,
      "grad_norm": 2.47773814201355,
      "learning_rate": 1.6182857142857144e-05,
      "loss": 0.0669,
      "step": 3340
    },
    {
      "epoch": 1.9142857142857141,
      "grad_norm": 0.28156137466430664,
      "learning_rate": 1.6171428571428574e-05,
      "loss": 0.0975,
      "step": 3350
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.10579173266887665,
      "learning_rate": 1.616e-05,
      "loss": 0.127,
      "step": 3360
    },
    {
      "epoch": 1.9257142857142857,
      "grad_norm": 16.58383560180664,
      "learning_rate": 1.6148571428571428e-05,
      "loss": 0.1396,
      "step": 3370
    },
    {
      "epoch": 1.9314285714285715,
      "grad_norm": 0.7067145705223083,
      "learning_rate": 1.6137142857142858e-05,
      "loss": 0.1486,
      "step": 3380
    },
    {
      "epoch": 1.9371428571428573,
      "grad_norm": 0.9330097436904907,
      "learning_rate": 1.6125714285714288e-05,
      "loss": 0.162,
      "step": 3390
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 28.18960952758789,
      "learning_rate": 1.6114285714285715e-05,
      "loss": 0.0854,
      "step": 3400
    },
    {
      "epoch": 1.9485714285714286,
      "grad_norm": 5.93660306930542,
      "learning_rate": 1.6102857142857145e-05,
      "loss": 0.1456,
      "step": 3410
    },
    {
      "epoch": 1.9542857142857142,
      "grad_norm": 0.22598092257976532,
      "learning_rate": 1.6091428571428572e-05,
      "loss": 0.098,
      "step": 3420
    },
    {
      "epoch": 1.96,
      "grad_norm": 21.148250579833984,
      "learning_rate": 1.6080000000000002e-05,
      "loss": 0.2039,
      "step": 3430
    },
    {
      "epoch": 1.9657142857142857,
      "grad_norm": 19.956825256347656,
      "learning_rate": 1.606857142857143e-05,
      "loss": 0.1208,
      "step": 3440
    },
    {
      "epoch": 1.9714285714285715,
      "grad_norm": 0.11359062790870667,
      "learning_rate": 1.605714285714286e-05,
      "loss": 0.0835,
      "step": 3450
    },
    {
      "epoch": 1.977142857142857,
      "grad_norm": 0.08597882091999054,
      "learning_rate": 1.6045714285714286e-05,
      "loss": 0.0979,
      "step": 3460
    },
    {
      "epoch": 1.9828571428571429,
      "grad_norm": 0.552787184715271,
      "learning_rate": 1.6034285714285716e-05,
      "loss": 0.1805,
      "step": 3470
    },
    {
      "epoch": 1.9885714285714284,
      "grad_norm": 11.733917236328125,
      "learning_rate": 1.6022857142857146e-05,
      "loss": 0.2388,
      "step": 3480
    },
    {
      "epoch": 1.9942857142857142,
      "grad_norm": 0.19067446887493134,
      "learning_rate": 1.6011428571428573e-05,
      "loss": 0.1672,
      "step": 3490
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.17074359953403473,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.1247,
      "step": 3500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9712566844919787,
      "eval_f1": 0.887728459530026,
      "eval_loss": 0.10256067663431168,
      "eval_precision": 0.9201623815967523,
      "eval_recall": 0.8575031525851198,
      "eval_runtime": 55.737,
      "eval_samples_per_second": 107.648,
      "eval_steps_per_second": 3.373,
      "step": 3500
    },
    {
      "epoch": 2.005714285714286,
      "grad_norm": 2.018543243408203,
      "learning_rate": 1.598857142857143e-05,
      "loss": 0.1059,
      "step": 3510
    },
    {
      "epoch": 2.0114285714285716,
      "grad_norm": 0.20897939801216125,
      "learning_rate": 1.5977142857142856e-05,
      "loss": 0.0803,
      "step": 3520
    },
    {
      "epoch": 2.0171428571428573,
      "grad_norm": 0.052881620824337006,
      "learning_rate": 1.5965714285714286e-05,
      "loss": 0.0514,
      "step": 3530
    },
    {
      "epoch": 2.0228571428571427,
      "grad_norm": 0.07616601884365082,
      "learning_rate": 1.5954285714285716e-05,
      "loss": 0.0454,
      "step": 3540
    },
    {
      "epoch": 2.0285714285714285,
      "grad_norm": 20.158870697021484,
      "learning_rate": 1.5942857142857143e-05,
      "loss": 0.1267,
      "step": 3550
    },
    {
      "epoch": 2.0342857142857143,
      "grad_norm": 0.4988063871860504,
      "learning_rate": 1.5931428571428573e-05,
      "loss": 0.0497,
      "step": 3560
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.03597235679626465,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 0.0211,
      "step": 3570
    },
    {
      "epoch": 2.045714285714286,
      "grad_norm": 2.2104649543762207,
      "learning_rate": 1.590857142857143e-05,
      "loss": 0.0782,
      "step": 3580
    },
    {
      "epoch": 2.0514285714285716,
      "grad_norm": 0.44546619057655334,
      "learning_rate": 1.5897142857142857e-05,
      "loss": 0.0507,
      "step": 3590
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 1.437565565109253,
      "learning_rate": 1.5885714285714287e-05,
      "loss": 0.1427,
      "step": 3600
    },
    {
      "epoch": 2.0628571428571427,
      "grad_norm": 0.8255206942558289,
      "learning_rate": 1.5874285714285714e-05,
      "loss": 0.0491,
      "step": 3610
    },
    {
      "epoch": 2.0685714285714285,
      "grad_norm": 13.146966934204102,
      "learning_rate": 1.5862857142857144e-05,
      "loss": 0.0575,
      "step": 3620
    },
    {
      "epoch": 2.0742857142857143,
      "grad_norm": 9.235913276672363,
      "learning_rate": 1.5851428571428574e-05,
      "loss": 0.0704,
      "step": 3630
    },
    {
      "epoch": 2.08,
      "grad_norm": 19.822093963623047,
      "learning_rate": 1.584e-05,
      "loss": 0.0651,
      "step": 3640
    },
    {
      "epoch": 2.085714285714286,
      "grad_norm": 17.919452667236328,
      "learning_rate": 1.582857142857143e-05,
      "loss": 0.2027,
      "step": 3650
    },
    {
      "epoch": 2.0914285714285716,
      "grad_norm": 2.2497856616973877,
      "learning_rate": 1.5817142857142858e-05,
      "loss": 0.0392,
      "step": 3660
    },
    {
      "epoch": 2.097142857142857,
      "grad_norm": 1.1120727062225342,
      "learning_rate": 1.5805714285714288e-05,
      "loss": 0.017,
      "step": 3670
    },
    {
      "epoch": 2.1028571428571428,
      "grad_norm": 22.09349250793457,
      "learning_rate": 1.5794285714285715e-05,
      "loss": 0.1171,
      "step": 3680
    },
    {
      "epoch": 2.1085714285714285,
      "grad_norm": 0.023714199662208557,
      "learning_rate": 1.5782857142857145e-05,
      "loss": 0.0378,
      "step": 3690
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 0.011674657464027405,
      "learning_rate": 1.577142857142857e-05,
      "loss": 0.0729,
      "step": 3700
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.45906955003738403,
      "learning_rate": 1.576e-05,
      "loss": 0.0635,
      "step": 3710
    },
    {
      "epoch": 2.125714285714286,
      "grad_norm": 0.27744439244270325,
      "learning_rate": 1.5748571428571432e-05,
      "loss": 0.0351,
      "step": 3720
    },
    {
      "epoch": 2.1314285714285712,
      "grad_norm": 11.029067993164062,
      "learning_rate": 1.573714285714286e-05,
      "loss": 0.0539,
      "step": 3730
    },
    {
      "epoch": 2.137142857142857,
      "grad_norm": 0.5340468883514404,
      "learning_rate": 1.5725714285714285e-05,
      "loss": 0.1579,
      "step": 3740
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 2.075985908508301,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.2288,
      "step": 3750
    },
    {
      "epoch": 2.1485714285714286,
      "grad_norm": 1.1724485158920288,
      "learning_rate": 1.5702857142857145e-05,
      "loss": 0.1498,
      "step": 3760
    },
    {
      "epoch": 2.1542857142857144,
      "grad_norm": 7.240707874298096,
      "learning_rate": 1.5691428571428572e-05,
      "loss": 0.0525,
      "step": 3770
    },
    {
      "epoch": 2.16,
      "grad_norm": 8.188538551330566,
      "learning_rate": 1.5680000000000002e-05,
      "loss": 0.1069,
      "step": 3780
    },
    {
      "epoch": 2.1657142857142855,
      "grad_norm": 0.03571159765124321,
      "learning_rate": 1.566857142857143e-05,
      "loss": 0.114,
      "step": 3790
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 11.661910057067871,
      "learning_rate": 1.5657142857142856e-05,
      "loss": 0.1599,
      "step": 3800
    },
    {
      "epoch": 2.177142857142857,
      "grad_norm": 0.2084767371416092,
      "learning_rate": 1.5645714285714286e-05,
      "loss": 0.1014,
      "step": 3810
    },
    {
      "epoch": 2.182857142857143,
      "grad_norm": 7.9631452560424805,
      "learning_rate": 1.5634285714285716e-05,
      "loss": 0.0476,
      "step": 3820
    },
    {
      "epoch": 2.1885714285714286,
      "grad_norm": 1.8855303525924683,
      "learning_rate": 1.5622857142857143e-05,
      "loss": 0.0359,
      "step": 3830
    },
    {
      "epoch": 2.1942857142857144,
      "grad_norm": 11.588423728942871,
      "learning_rate": 1.5611428571428573e-05,
      "loss": 0.0399,
      "step": 3840
    },
    {
      "epoch": 2.2,
      "grad_norm": 12.671412467956543,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.1134,
      "step": 3850
    },
    {
      "epoch": 2.2057142857142855,
      "grad_norm": 8.194817543029785,
      "learning_rate": 1.558857142857143e-05,
      "loss": 0.088,
      "step": 3860
    },
    {
      "epoch": 2.2114285714285713,
      "grad_norm": 13.466160774230957,
      "learning_rate": 1.5577142857142857e-05,
      "loss": 0.1589,
      "step": 3870
    },
    {
      "epoch": 2.217142857142857,
      "grad_norm": 8.111775398254395,
      "learning_rate": 1.5565714285714287e-05,
      "loss": 0.0976,
      "step": 3880
    },
    {
      "epoch": 2.222857142857143,
      "grad_norm": 9.271849632263184,
      "learning_rate": 1.5554285714285713e-05,
      "loss": 0.0665,
      "step": 3890
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 16.335981369018555,
      "learning_rate": 1.5542857142857144e-05,
      "loss": 0.137,
      "step": 3900
    },
    {
      "epoch": 2.2342857142857144,
      "grad_norm": 0.02760339342057705,
      "learning_rate": 1.5531428571428574e-05,
      "loss": 0.0225,
      "step": 3910
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.14015178382396698,
      "learning_rate": 1.552e-05,
      "loss": 0.1132,
      "step": 3920
    },
    {
      "epoch": 2.2457142857142856,
      "grad_norm": 0.4389728903770447,
      "learning_rate": 1.550857142857143e-05,
      "loss": 0.0177,
      "step": 3930
    },
    {
      "epoch": 2.2514285714285713,
      "grad_norm": 0.08568519353866577,
      "learning_rate": 1.549714285714286e-05,
      "loss": 0.084,
      "step": 3940
    },
    {
      "epoch": 2.257142857142857,
      "grad_norm": 0.08580534160137177,
      "learning_rate": 1.5485714285714287e-05,
      "loss": 0.1148,
      "step": 3950
    },
    {
      "epoch": 2.262857142857143,
      "grad_norm": 0.2959829270839691,
      "learning_rate": 1.5474285714285714e-05,
      "loss": 0.0838,
      "step": 3960
    },
    {
      "epoch": 2.2685714285714287,
      "grad_norm": 0.36035388708114624,
      "learning_rate": 1.5462857142857144e-05,
      "loss": 0.0488,
      "step": 3970
    },
    {
      "epoch": 2.2742857142857145,
      "grad_norm": 12.061114311218262,
      "learning_rate": 1.545142857142857e-05,
      "loss": 0.1525,
      "step": 3980
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 19.23589515686035,
      "learning_rate": 1.544e-05,
      "loss": 0.1069,
      "step": 3990
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 11.406641006469727,
      "learning_rate": 1.542857142857143e-05,
      "loss": 0.0791,
      "step": 4000
    },
    {
      "epoch": 2.2914285714285714,
      "grad_norm": 4.47114896774292,
      "learning_rate": 1.5417142857142858e-05,
      "loss": 0.0555,
      "step": 4010
    },
    {
      "epoch": 2.297142857142857,
      "grad_norm": 11.763666152954102,
      "learning_rate": 1.5405714285714285e-05,
      "loss": 0.0828,
      "step": 4020
    },
    {
      "epoch": 2.302857142857143,
      "grad_norm": 18.8986759185791,
      "learning_rate": 1.5394285714285715e-05,
      "loss": 0.0557,
      "step": 4030
    },
    {
      "epoch": 2.3085714285714287,
      "grad_norm": 13.591392517089844,
      "learning_rate": 1.5382857142857145e-05,
      "loss": 0.0423,
      "step": 4040
    },
    {
      "epoch": 2.314285714285714,
      "grad_norm": 12.75783920288086,
      "learning_rate": 1.5371428571428572e-05,
      "loss": 0.1924,
      "step": 4050
    },
    {
      "epoch": 2.32,
      "grad_norm": 6.035647869110107,
      "learning_rate": 1.5360000000000002e-05,
      "loss": 0.0679,
      "step": 4060
    },
    {
      "epoch": 2.3257142857142856,
      "grad_norm": 19.999189376831055,
      "learning_rate": 1.534857142857143e-05,
      "loss": 0.245,
      "step": 4070
    },
    {
      "epoch": 2.3314285714285714,
      "grad_norm": 6.408323764801025,
      "learning_rate": 1.533714285714286e-05,
      "loss": 0.04,
      "step": 4080
    },
    {
      "epoch": 2.337142857142857,
      "grad_norm": 9.65699577331543,
      "learning_rate": 1.5325714285714286e-05,
      "loss": 0.1187,
      "step": 4090
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 24.137985229492188,
      "learning_rate": 1.5314285714285716e-05,
      "loss": 0.0283,
      "step": 4100
    },
    {
      "epoch": 2.3485714285714288,
      "grad_norm": 9.251198768615723,
      "learning_rate": 1.5302857142857143e-05,
      "loss": 0.0745,
      "step": 4110
    },
    {
      "epoch": 2.354285714285714,
      "grad_norm": 8.360595703125,
      "learning_rate": 1.5291428571428573e-05,
      "loss": 0.1456,
      "step": 4120
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.034190841019153595,
      "learning_rate": 1.5280000000000003e-05,
      "loss": 0.0245,
      "step": 4130
    },
    {
      "epoch": 2.3657142857142857,
      "grad_norm": 0.039588507264852524,
      "learning_rate": 1.526857142857143e-05,
      "loss": 0.043,
      "step": 4140
    },
    {
      "epoch": 2.3714285714285714,
      "grad_norm": 0.2423403561115265,
      "learning_rate": 1.525714285714286e-05,
      "loss": 0.0592,
      "step": 4150
    },
    {
      "epoch": 2.3771428571428572,
      "grad_norm": 8.371020317077637,
      "learning_rate": 1.5245714285714286e-05,
      "loss": 0.1247,
      "step": 4160
    },
    {
      "epoch": 2.382857142857143,
      "grad_norm": 0.0897764265537262,
      "learning_rate": 1.5234285714285715e-05,
      "loss": 0.0211,
      "step": 4170
    },
    {
      "epoch": 2.388571428571429,
      "grad_norm": 13.856385231018066,
      "learning_rate": 1.5222857142857143e-05,
      "loss": 0.0871,
      "step": 4180
    },
    {
      "epoch": 2.394285714285714,
      "grad_norm": 0.09869231283664703,
      "learning_rate": 1.5211428571428572e-05,
      "loss": 0.0363,
      "step": 4190
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.0103278374299407,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.092,
      "step": 4200
    },
    {
      "epoch": 2.4057142857142857,
      "grad_norm": 34.019264221191406,
      "learning_rate": 1.518857142857143e-05,
      "loss": 0.1279,
      "step": 4210
    },
    {
      "epoch": 2.4114285714285715,
      "grad_norm": 12.788991928100586,
      "learning_rate": 1.5177142857142859e-05,
      "loss": 0.1466,
      "step": 4220
    },
    {
      "epoch": 2.4171428571428573,
      "grad_norm": 0.09843146055936813,
      "learning_rate": 1.5165714285714289e-05,
      "loss": 0.0396,
      "step": 4230
    },
    {
      "epoch": 2.422857142857143,
      "grad_norm": 9.628761291503906,
      "learning_rate": 1.5154285714285714e-05,
      "loss": 0.0994,
      "step": 4240
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.026537995785474777,
      "learning_rate": 1.5142857142857144e-05,
      "loss": 0.1285,
      "step": 4250
    },
    {
      "epoch": 2.434285714285714,
      "grad_norm": 15.772164344787598,
      "learning_rate": 1.5131428571428572e-05,
      "loss": 0.1405,
      "step": 4260
    },
    {
      "epoch": 2.44,
      "grad_norm": 11.255559921264648,
      "learning_rate": 1.5120000000000001e-05,
      "loss": 0.049,
      "step": 4270
    },
    {
      "epoch": 2.4457142857142857,
      "grad_norm": 0.2509278655052185,
      "learning_rate": 1.5108571428571431e-05,
      "loss": 0.115,
      "step": 4280
    },
    {
      "epoch": 2.4514285714285715,
      "grad_norm": 0.06864835321903229,
      "learning_rate": 1.509714285714286e-05,
      "loss": 0.0746,
      "step": 4290
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 0.24380014836788177,
      "learning_rate": 1.5085714285714288e-05,
      "loss": 0.0647,
      "step": 4300
    },
    {
      "epoch": 2.4628571428571426,
      "grad_norm": 0.4770677089691162,
      "learning_rate": 1.5074285714285715e-05,
      "loss": 0.0927,
      "step": 4310
    },
    {
      "epoch": 2.4685714285714284,
      "grad_norm": 0.056466374546289444,
      "learning_rate": 1.5062857142857143e-05,
      "loss": 0.0612,
      "step": 4320
    },
    {
      "epoch": 2.474285714285714,
      "grad_norm": 0.018045278266072273,
      "learning_rate": 1.5051428571428572e-05,
      "loss": 0.0175,
      "step": 4330
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.026148753240704536,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 0.17,
      "step": 4340
    },
    {
      "epoch": 2.4857142857142858,
      "grad_norm": 0.14180944859981537,
      "learning_rate": 1.502857142857143e-05,
      "loss": 0.0587,
      "step": 4350
    },
    {
      "epoch": 2.4914285714285715,
      "grad_norm": 0.2735172212123871,
      "learning_rate": 1.5017142857142859e-05,
      "loss": 0.1014,
      "step": 4360
    },
    {
      "epoch": 2.4971428571428573,
      "grad_norm": 0.3188166916370392,
      "learning_rate": 1.5005714285714289e-05,
      "loss": 0.1931,
      "step": 4370
    },
    {
      "epoch": 2.5028571428571427,
      "grad_norm": 16.956371307373047,
      "learning_rate": 1.4994285714285714e-05,
      "loss": 0.0615,
      "step": 4380
    },
    {
      "epoch": 2.5085714285714285,
      "grad_norm": 18.00519561767578,
      "learning_rate": 1.4982857142857144e-05,
      "loss": 0.0737,
      "step": 4390
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 0.04245655983686447,
      "learning_rate": 1.4971428571428572e-05,
      "loss": 0.0745,
      "step": 4400
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.09004196524620056,
      "learning_rate": 1.496e-05,
      "loss": 0.0344,
      "step": 4410
    },
    {
      "epoch": 2.525714285714286,
      "grad_norm": 0.14435197412967682,
      "learning_rate": 1.4948571428571431e-05,
      "loss": 0.1032,
      "step": 4420
    },
    {
      "epoch": 2.5314285714285716,
      "grad_norm": 17.075305938720703,
      "learning_rate": 1.493714285714286e-05,
      "loss": 0.0846,
      "step": 4430
    },
    {
      "epoch": 2.5371428571428574,
      "grad_norm": 12.611346244812012,
      "learning_rate": 1.4925714285714288e-05,
      "loss": 0.129,
      "step": 4440
    },
    {
      "epoch": 2.5428571428571427,
      "grad_norm": 1.0454870462417603,
      "learning_rate": 1.4914285714285715e-05,
      "loss": 0.0861,
      "step": 4450
    },
    {
      "epoch": 2.5485714285714285,
      "grad_norm": 0.5369561910629272,
      "learning_rate": 1.4902857142857143e-05,
      "loss": 0.0844,
      "step": 4460
    },
    {
      "epoch": 2.5542857142857143,
      "grad_norm": 4.557708740234375,
      "learning_rate": 1.4891428571428571e-05,
      "loss": 0.0684,
      "step": 4470
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.2538820505142212,
      "learning_rate": 1.4880000000000002e-05,
      "loss": 0.1495,
      "step": 4480
    },
    {
      "epoch": 2.565714285714286,
      "grad_norm": 0.0869818776845932,
      "learning_rate": 1.486857142857143e-05,
      "loss": 0.1355,
      "step": 4490
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 25.5894775390625,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 0.0935,
      "step": 4500
    },
    {
      "epoch": 2.5771428571428574,
      "grad_norm": 7.86143159866333,
      "learning_rate": 1.4845714285714289e-05,
      "loss": 0.0999,
      "step": 4510
    },
    {
      "epoch": 2.5828571428571427,
      "grad_norm": 1.281378149986267,
      "learning_rate": 1.4834285714285714e-05,
      "loss": 0.106,
      "step": 4520
    },
    {
      "epoch": 2.5885714285714285,
      "grad_norm": 0.022793950513005257,
      "learning_rate": 1.4822857142857144e-05,
      "loss": 0.0538,
      "step": 4530
    },
    {
      "epoch": 2.5942857142857143,
      "grad_norm": 8.917265892028809,
      "learning_rate": 1.4811428571428572e-05,
      "loss": 0.1582,
      "step": 4540
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.2743905484676361,
      "learning_rate": 1.48e-05,
      "loss": 0.0167,
      "step": 4550
    },
    {
      "epoch": 2.605714285714286,
      "grad_norm": 0.02028047665953636,
      "learning_rate": 1.478857142857143e-05,
      "loss": 0.0421,
      "step": 4560
    },
    {
      "epoch": 2.611428571428571,
      "grad_norm": 0.039022043347358704,
      "learning_rate": 1.477714285714286e-05,
      "loss": 0.0764,
      "step": 4570
    },
    {
      "epoch": 2.617142857142857,
      "grad_norm": 8.346392631530762,
      "learning_rate": 1.4765714285714288e-05,
      "loss": 0.0302,
      "step": 4580
    },
    {
      "epoch": 2.6228571428571428,
      "grad_norm": 1.07005774974823,
      "learning_rate": 1.4754285714285716e-05,
      "loss": 0.1094,
      "step": 4590
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 18.84552574157715,
      "learning_rate": 1.4742857142857143e-05,
      "loss": 0.168,
      "step": 4600
    },
    {
      "epoch": 2.6342857142857143,
      "grad_norm": 1.2333118915557861,
      "learning_rate": 1.4731428571428571e-05,
      "loss": 0.1164,
      "step": 4610
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.25680723786354065,
      "learning_rate": 1.4720000000000001e-05,
      "loss": 0.0808,
      "step": 4620
    },
    {
      "epoch": 2.645714285714286,
      "grad_norm": 11.13634204864502,
      "learning_rate": 1.470857142857143e-05,
      "loss": 0.039,
      "step": 4630
    },
    {
      "epoch": 2.6514285714285712,
      "grad_norm": 0.029026733711361885,
      "learning_rate": 1.4697142857142858e-05,
      "loss": 0.0753,
      "step": 4640
    },
    {
      "epoch": 2.657142857142857,
      "grad_norm": 0.0671335905790329,
      "learning_rate": 1.4685714285714288e-05,
      "loss": 0.0363,
      "step": 4650
    },
    {
      "epoch": 2.662857142857143,
      "grad_norm": 1.9685908555984497,
      "learning_rate": 1.4674285714285717e-05,
      "loss": 0.0503,
      "step": 4660
    },
    {
      "epoch": 2.6685714285714286,
      "grad_norm": 0.018174713477492332,
      "learning_rate": 1.4662857142857144e-05,
      "loss": 0.1067,
      "step": 4670
    },
    {
      "epoch": 2.6742857142857144,
      "grad_norm": 9.435351371765137,
      "learning_rate": 1.4651428571428572e-05,
      "loss": 0.1861,
      "step": 4680
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.07419568300247192,
      "learning_rate": 1.464e-05,
      "loss": 0.0551,
      "step": 4690
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 18.5526065826416,
      "learning_rate": 1.462857142857143e-05,
      "loss": 0.0942,
      "step": 4700
    },
    {
      "epoch": 2.6914285714285713,
      "grad_norm": 0.06855075806379318,
      "learning_rate": 1.4617142857142859e-05,
      "loss": 0.0341,
      "step": 4710
    },
    {
      "epoch": 2.697142857142857,
      "grad_norm": 0.9060332179069519,
      "learning_rate": 1.4605714285714287e-05,
      "loss": 0.0889,
      "step": 4720
    },
    {
      "epoch": 2.702857142857143,
      "grad_norm": 0.08351003378629684,
      "learning_rate": 1.4594285714285716e-05,
      "loss": 0.1037,
      "step": 4730
    },
    {
      "epoch": 2.7085714285714286,
      "grad_norm": 1.4219918251037598,
      "learning_rate": 1.4582857142857143e-05,
      "loss": 0.1354,
      "step": 4740
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 22.848997116088867,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 0.1718,
      "step": 4750
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.13782186806201935,
      "learning_rate": 1.4560000000000001e-05,
      "loss": 0.0974,
      "step": 4760
    },
    {
      "epoch": 2.725714285714286,
      "grad_norm": 8.705879211425781,
      "learning_rate": 1.454857142857143e-05,
      "loss": 0.1097,
      "step": 4770
    },
    {
      "epoch": 2.7314285714285713,
      "grad_norm": 13.309490203857422,
      "learning_rate": 1.4537142857142858e-05,
      "loss": 0.0696,
      "step": 4780
    },
    {
      "epoch": 2.737142857142857,
      "grad_norm": 3.0904388427734375,
      "learning_rate": 1.4525714285714288e-05,
      "loss": 0.1149,
      "step": 4790
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 0.24488845467567444,
      "learning_rate": 1.4514285714285717e-05,
      "loss": 0.0524,
      "step": 4800
    },
    {
      "epoch": 2.7485714285714287,
      "grad_norm": 0.684831440448761,
      "learning_rate": 1.4502857142857143e-05,
      "loss": 0.0077,
      "step": 4810
    },
    {
      "epoch": 2.7542857142857144,
      "grad_norm": 0.813892662525177,
      "learning_rate": 1.4491428571428572e-05,
      "loss": 0.1371,
      "step": 4820
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.473599374294281,
      "learning_rate": 1.448e-05,
      "loss": 0.0435,
      "step": 4830
    },
    {
      "epoch": 2.7657142857142856,
      "grad_norm": 0.27157890796661377,
      "learning_rate": 1.446857142857143e-05,
      "loss": 0.0476,
      "step": 4840
    },
    {
      "epoch": 2.7714285714285714,
      "grad_norm": 5.195364952087402,
      "learning_rate": 1.4457142857142859e-05,
      "loss": 0.0358,
      "step": 4850
    },
    {
      "epoch": 2.777142857142857,
      "grad_norm": 19.313108444213867,
      "learning_rate": 1.4445714285714287e-05,
      "loss": 0.0933,
      "step": 4860
    },
    {
      "epoch": 2.782857142857143,
      "grad_norm": 0.026556728407740593,
      "learning_rate": 1.4434285714285716e-05,
      "loss": 0.092,
      "step": 4870
    },
    {
      "epoch": 2.7885714285714287,
      "grad_norm": 0.05095389857888222,
      "learning_rate": 1.4422857142857146e-05,
      "loss": 0.0809,
      "step": 4880
    },
    {
      "epoch": 2.7942857142857145,
      "grad_norm": 0.07949096709489822,
      "learning_rate": 1.4411428571428573e-05,
      "loss": 0.0455,
      "step": 4890
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.547890663146973,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.0626,
      "step": 4900
    },
    {
      "epoch": 2.8057142857142856,
      "grad_norm": 22.838834762573242,
      "learning_rate": 1.438857142857143e-05,
      "loss": 0.0335,
      "step": 4910
    },
    {
      "epoch": 2.8114285714285714,
      "grad_norm": 3.636913776397705,
      "learning_rate": 1.4377142857142858e-05,
      "loss": 0.0546,
      "step": 4920
    },
    {
      "epoch": 2.817142857142857,
      "grad_norm": 19.0515193939209,
      "learning_rate": 1.4365714285714288e-05,
      "loss": 0.105,
      "step": 4930
    },
    {
      "epoch": 2.822857142857143,
      "grad_norm": 1.0877113342285156,
      "learning_rate": 1.4354285714285716e-05,
      "loss": 0.093,
      "step": 4940
    },
    {
      "epoch": 2.8285714285714287,
      "grad_norm": 11.757185935974121,
      "learning_rate": 1.4342857142857145e-05,
      "loss": 0.0957,
      "step": 4950
    },
    {
      "epoch": 2.8342857142857145,
      "grad_norm": 11.691770553588867,
      "learning_rate": 1.4331428571428572e-05,
      "loss": 0.0546,
      "step": 4960
    },
    {
      "epoch": 2.84,
      "grad_norm": 26.276453018188477,
      "learning_rate": 1.432e-05,
      "loss": 0.0719,
      "step": 4970
    },
    {
      "epoch": 2.8457142857142856,
      "grad_norm": 1.9419047832489014,
      "learning_rate": 1.430857142857143e-05,
      "loss": 0.0114,
      "step": 4980
    },
    {
      "epoch": 2.8514285714285714,
      "grad_norm": 1.3490211963653564,
      "learning_rate": 1.4297142857142859e-05,
      "loss": 0.0441,
      "step": 4990
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.01747499592602253,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.0158,
      "step": 5000
    },
    {
      "epoch": 2.862857142857143,
      "grad_norm": 0.08100560307502747,
      "learning_rate": 1.4274285714285716e-05,
      "loss": 0.069,
      "step": 5010
    },
    {
      "epoch": 2.8685714285714283,
      "grad_norm": 32.80885696411133,
      "learning_rate": 1.4262857142857146e-05,
      "loss": 0.1448,
      "step": 5020
    },
    {
      "epoch": 2.8742857142857146,
      "grad_norm": 17.754384994506836,
      "learning_rate": 1.4251428571428572e-05,
      "loss": 0.1269,
      "step": 5030
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.6367231607437134,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 0.027,
      "step": 5040
    },
    {
      "epoch": 2.8857142857142857,
      "grad_norm": 11.3068208694458,
      "learning_rate": 1.422857142857143e-05,
      "loss": 0.0963,
      "step": 5050
    },
    {
      "epoch": 2.8914285714285715,
      "grad_norm": 14.922874450683594,
      "learning_rate": 1.4217142857142858e-05,
      "loss": 0.0789,
      "step": 5060
    },
    {
      "epoch": 2.8971428571428572,
      "grad_norm": 12.92313003540039,
      "learning_rate": 1.4205714285714288e-05,
      "loss": 0.1476,
      "step": 5070
    },
    {
      "epoch": 2.902857142857143,
      "grad_norm": 0.1844935417175293,
      "learning_rate": 1.4194285714285716e-05,
      "loss": 0.2098,
      "step": 5080
    },
    {
      "epoch": 2.9085714285714284,
      "grad_norm": 1.3814785480499268,
      "learning_rate": 1.4182857142857145e-05,
      "loss": 0.0213,
      "step": 5090
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 12.612282752990723,
      "learning_rate": 1.4171428571428572e-05,
      "loss": 0.0824,
      "step": 5100
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.010983849875628948,
      "learning_rate": 1.416e-05,
      "loss": 0.0639,
      "step": 5110
    },
    {
      "epoch": 2.9257142857142857,
      "grad_norm": 0.015588046982884407,
      "learning_rate": 1.414857142857143e-05,
      "loss": 0.1418,
      "step": 5120
    },
    {
      "epoch": 2.9314285714285715,
      "grad_norm": 0.07956677675247192,
      "learning_rate": 1.4137142857142859e-05,
      "loss": 0.1611,
      "step": 5130
    },
    {
      "epoch": 2.9371428571428573,
      "grad_norm": 0.39700257778167725,
      "learning_rate": 1.4125714285714287e-05,
      "loss": 0.0256,
      "step": 5140
    },
    {
      "epoch": 2.942857142857143,
      "grad_norm": 0.13169345259666443,
      "learning_rate": 1.4114285714285715e-05,
      "loss": 0.1958,
      "step": 5150
    },
    {
      "epoch": 2.9485714285714284,
      "grad_norm": 0.25970450043678284,
      "learning_rate": 1.4102857142857146e-05,
      "loss": 0.0955,
      "step": 5160
    },
    {
      "epoch": 2.954285714285714,
      "grad_norm": 1.3884575366973877,
      "learning_rate": 1.4091428571428574e-05,
      "loss": 0.0773,
      "step": 5170
    },
    {
      "epoch": 2.96,
      "grad_norm": 8.67286205291748,
      "learning_rate": 1.408e-05,
      "loss": 0.096,
      "step": 5180
    },
    {
      "epoch": 2.9657142857142857,
      "grad_norm": 13.264007568359375,
      "learning_rate": 1.406857142857143e-05,
      "loss": 0.112,
      "step": 5190
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 19.64134979248047,
      "learning_rate": 1.4057142857142858e-05,
      "loss": 0.1547,
      "step": 5200
    },
    {
      "epoch": 2.977142857142857,
      "grad_norm": 6.876113414764404,
      "learning_rate": 1.4045714285714288e-05,
      "loss": 0.0948,
      "step": 5210
    },
    {
      "epoch": 2.982857142857143,
      "grad_norm": 13.970927238464355,
      "learning_rate": 1.4034285714285716e-05,
      "loss": 0.1266,
      "step": 5220
    },
    {
      "epoch": 2.9885714285714284,
      "grad_norm": 0.39627358317375183,
      "learning_rate": 1.4022857142857145e-05,
      "loss": 0.1026,
      "step": 5230
    },
    {
      "epoch": 2.994285714285714,
      "grad_norm": 0.202278271317482,
      "learning_rate": 1.4011428571428573e-05,
      "loss": 0.0146,
      "step": 5240
    },
    {
      "epoch": 3.0,
      "grad_norm": 7.545971870422363,
      "learning_rate": 1.4e-05,
      "loss": 0.1436,
      "step": 5250
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9742647058823529,
      "eval_f1": 0.9035087719298246,
      "eval_loss": 0.10064205527305603,
      "eval_precision": 0.8978829389788294,
      "eval_recall": 0.9092055485498108,
      "eval_runtime": 58.7272,
      "eval_samples_per_second": 102.167,
      "eval_steps_per_second": 3.201,
      "step": 5250
    },
    {
      "epoch": 3.005714285714286,
      "grad_norm": 0.02610989846289158,
      "learning_rate": 1.398857142857143e-05,
      "loss": 0.0126,
      "step": 5260
    },
    {
      "epoch": 3.0114285714285716,
      "grad_norm": 0.011019601486623287,
      "learning_rate": 1.3977142857142858e-05,
      "loss": 0.0109,
      "step": 5270
    },
    {
      "epoch": 3.0171428571428573,
      "grad_norm": 7.671435356140137,
      "learning_rate": 1.3965714285714287e-05,
      "loss": 0.1092,
      "step": 5280
    },
    {
      "epoch": 3.0228571428571427,
      "grad_norm": 0.05961466580629349,
      "learning_rate": 1.3954285714285715e-05,
      "loss": 0.0964,
      "step": 5290
    },
    {
      "epoch": 3.0285714285714285,
      "grad_norm": 0.8312934637069702,
      "learning_rate": 1.3942857142857145e-05,
      "loss": 0.0017,
      "step": 5300
    },
    {
      "epoch": 3.0342857142857143,
      "grad_norm": 2.199648141860962,
      "learning_rate": 1.3931428571428574e-05,
      "loss": 0.0759,
      "step": 5310
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.15131573379039764,
      "learning_rate": 1.392e-05,
      "loss": 0.0791,
      "step": 5320
    },
    {
      "epoch": 3.045714285714286,
      "grad_norm": 0.2327519804239273,
      "learning_rate": 1.3908571428571429e-05,
      "loss": 0.0018,
      "step": 5330
    },
    {
      "epoch": 3.0514285714285716,
      "grad_norm": 0.022321464493870735,
      "learning_rate": 1.3897142857142857e-05,
      "loss": 0.0222,
      "step": 5340
    },
    {
      "epoch": 3.057142857142857,
      "grad_norm": 0.01774260774254799,
      "learning_rate": 1.3885714285714288e-05,
      "loss": 0.0862,
      "step": 5350
    },
    {
      "epoch": 3.0628571428571427,
      "grad_norm": 0.0274109598249197,
      "learning_rate": 1.3874285714285716e-05,
      "loss": 0.051,
      "step": 5360
    },
    {
      "epoch": 3.0685714285714285,
      "grad_norm": 0.02787686139345169,
      "learning_rate": 1.3862857142857144e-05,
      "loss": 0.0536,
      "step": 5370
    },
    {
      "epoch": 3.0742857142857143,
      "grad_norm": 0.20716311037540436,
      "learning_rate": 1.3851428571428573e-05,
      "loss": 0.0352,
      "step": 5380
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.23392599821090698,
      "learning_rate": 1.384e-05,
      "loss": 0.0266,
      "step": 5390
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 0.9037802219390869,
      "learning_rate": 1.382857142857143e-05,
      "loss": 0.0594,
      "step": 5400
    },
    {
      "epoch": 3.0914285714285716,
      "grad_norm": 0.09604518115520477,
      "learning_rate": 1.3817142857142858e-05,
      "loss": 0.1513,
      "step": 5410
    },
    {
      "epoch": 3.097142857142857,
      "grad_norm": 13.638616561889648,
      "learning_rate": 1.3805714285714287e-05,
      "loss": 0.1959,
      "step": 5420
    },
    {
      "epoch": 3.1028571428571428,
      "grad_norm": 0.5005958080291748,
      "learning_rate": 1.3794285714285715e-05,
      "loss": 0.0515,
      "step": 5430
    },
    {
      "epoch": 3.1085714285714285,
      "grad_norm": 12.082098960876465,
      "learning_rate": 1.3782857142857145e-05,
      "loss": 0.0624,
      "step": 5440
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 0.39963892102241516,
      "learning_rate": 1.3771428571428574e-05,
      "loss": 0.0967,
      "step": 5450
    },
    {
      "epoch": 3.12,
      "grad_norm": 6.460691928863525,
      "learning_rate": 1.376e-05,
      "loss": 0.0773,
      "step": 5460
    },
    {
      "epoch": 3.125714285714286,
      "grad_norm": 7.976339817047119,
      "learning_rate": 1.3748571428571429e-05,
      "loss": 0.1646,
      "step": 5470
    },
    {
      "epoch": 3.1314285714285712,
      "grad_norm": 0.06526657938957214,
      "learning_rate": 1.3737142857142857e-05,
      "loss": 0.0471,
      "step": 5480
    },
    {
      "epoch": 3.137142857142857,
      "grad_norm": 0.35597413778305054,
      "learning_rate": 1.3725714285714287e-05,
      "loss": 0.1115,
      "step": 5490
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 0.4109916388988495,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 0.0192,
      "step": 5500
    },
    {
      "epoch": 3.1485714285714286,
      "grad_norm": 0.013822976499795914,
      "learning_rate": 1.3702857142857144e-05,
      "loss": 0.0036,
      "step": 5510
    },
    {
      "epoch": 3.1542857142857144,
      "grad_norm": 3.5199427604675293,
      "learning_rate": 1.3691428571428573e-05,
      "loss": 0.055,
      "step": 5520
    },
    {
      "epoch": 3.16,
      "grad_norm": 18.92344093322754,
      "learning_rate": 1.3680000000000003e-05,
      "loss": 0.0513,
      "step": 5530
    },
    {
      "epoch": 3.1657142857142855,
      "grad_norm": 1.3950062990188599,
      "learning_rate": 1.366857142857143e-05,
      "loss": 0.0065,
      "step": 5540
    },
    {
      "epoch": 3.1714285714285713,
      "grad_norm": 4.4210124015808105,
      "learning_rate": 1.3657142857142858e-05,
      "loss": 0.1028,
      "step": 5550
    },
    {
      "epoch": 3.177142857142857,
      "grad_norm": 19.757883071899414,
      "learning_rate": 1.3645714285714286e-05,
      "loss": 0.0642,
      "step": 5560
    },
    {
      "epoch": 3.182857142857143,
      "grad_norm": 0.025467636063694954,
      "learning_rate": 1.3634285714285715e-05,
      "loss": 0.1144,
      "step": 5570
    },
    {
      "epoch": 3.1885714285714286,
      "grad_norm": 0.08982500433921814,
      "learning_rate": 1.3622857142857145e-05,
      "loss": 0.0222,
      "step": 5580
    },
    {
      "epoch": 3.1942857142857144,
      "grad_norm": 0.0324629470705986,
      "learning_rate": 1.3611428571428573e-05,
      "loss": 0.0368,
      "step": 5590
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.024151291698217392,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0204,
      "step": 5600
    },
    {
      "epoch": 3.2057142857142855,
      "grad_norm": 0.061421122401952744,
      "learning_rate": 1.3588571428571429e-05,
      "loss": 0.0018,
      "step": 5610
    },
    {
      "epoch": 3.2114285714285713,
      "grad_norm": 16.08051300048828,
      "learning_rate": 1.3577142857142857e-05,
      "loss": 0.0679,
      "step": 5620
    },
    {
      "epoch": 3.217142857142857,
      "grad_norm": 0.003251776099205017,
      "learning_rate": 1.3565714285714287e-05,
      "loss": 0.1326,
      "step": 5630
    },
    {
      "epoch": 3.222857142857143,
      "grad_norm": 0.03447569161653519,
      "learning_rate": 1.3554285714285716e-05,
      "loss": 0.0131,
      "step": 5640
    },
    {
      "epoch": 3.2285714285714286,
      "grad_norm": 0.016097180545330048,
      "learning_rate": 1.3542857142857144e-05,
      "loss": 0.0331,
      "step": 5650
    },
    {
      "epoch": 3.2342857142857144,
      "grad_norm": 0.0490649975836277,
      "learning_rate": 1.3531428571428573e-05,
      "loss": 0.0186,
      "step": 5660
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.0028549523558467627,
      "learning_rate": 1.3520000000000003e-05,
      "loss": 0.0023,
      "step": 5670
    },
    {
      "epoch": 3.2457142857142856,
      "grad_norm": 0.0013235550140962005,
      "learning_rate": 1.350857142857143e-05,
      "loss": 0.1376,
      "step": 5680
    },
    {
      "epoch": 3.2514285714285713,
      "grad_norm": 0.001834486029110849,
      "learning_rate": 1.3497142857142858e-05,
      "loss": 0.0165,
      "step": 5690
    },
    {
      "epoch": 3.257142857142857,
      "grad_norm": 19.10718536376953,
      "learning_rate": 1.3485714285714286e-05,
      "loss": 0.2047,
      "step": 5700
    },
    {
      "epoch": 3.262857142857143,
      "grad_norm": 0.019556749612092972,
      "learning_rate": 1.3474285714285715e-05,
      "loss": 0.0663,
      "step": 5710
    },
    {
      "epoch": 3.2685714285714287,
      "grad_norm": 6.861557960510254,
      "learning_rate": 1.3462857142857145e-05,
      "loss": 0.0878,
      "step": 5720
    },
    {
      "epoch": 3.2742857142857145,
      "grad_norm": 0.04653695598244667,
      "learning_rate": 1.3451428571428573e-05,
      "loss": 0.0159,
      "step": 5730
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 24.717853546142578,
      "learning_rate": 1.3440000000000002e-05,
      "loss": 0.0762,
      "step": 5740
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 16.57335662841797,
      "learning_rate": 1.3428571428571429e-05,
      "loss": 0.064,
      "step": 5750
    },
    {
      "epoch": 3.2914285714285714,
      "grad_norm": 14.261213302612305,
      "learning_rate": 1.3417142857142857e-05,
      "loss": 0.0547,
      "step": 5760
    },
    {
      "epoch": 3.297142857142857,
      "grad_norm": 0.2959915101528168,
      "learning_rate": 1.3405714285714287e-05,
      "loss": 0.0802,
      "step": 5770
    },
    {
      "epoch": 3.302857142857143,
      "grad_norm": 8.325749397277832,
      "learning_rate": 1.3394285714285716e-05,
      "loss": 0.0799,
      "step": 5780
    },
    {
      "epoch": 3.3085714285714287,
      "grad_norm": 0.037958405911922455,
      "learning_rate": 1.3382857142857144e-05,
      "loss": 0.1697,
      "step": 5790
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 0.09389924257993698,
      "learning_rate": 1.3371428571428572e-05,
      "loss": 0.0829,
      "step": 5800
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.0688324123620987,
      "learning_rate": 1.3360000000000003e-05,
      "loss": 0.0331,
      "step": 5810
    },
    {
      "epoch": 3.3257142857142856,
      "grad_norm": 2.6705658435821533,
      "learning_rate": 1.3348571428571431e-05,
      "loss": 0.0764,
      "step": 5820
    },
    {
      "epoch": 3.3314285714285714,
      "grad_norm": 19.58802604675293,
      "learning_rate": 1.3337142857142858e-05,
      "loss": 0.0471,
      "step": 5830
    },
    {
      "epoch": 3.337142857142857,
      "grad_norm": 0.06185586750507355,
      "learning_rate": 1.3325714285714286e-05,
      "loss": 0.0183,
      "step": 5840
    },
    {
      "epoch": 3.342857142857143,
      "grad_norm": 10.371798515319824,
      "learning_rate": 1.3314285714285715e-05,
      "loss": 0.1047,
      "step": 5850
    },
    {
      "epoch": 3.3485714285714288,
      "grad_norm": 0.07540008425712585,
      "learning_rate": 1.3302857142857145e-05,
      "loss": 0.0886,
      "step": 5860
    },
    {
      "epoch": 3.354285714285714,
      "grad_norm": 4.433803081512451,
      "learning_rate": 1.3291428571428573e-05,
      "loss": 0.0184,
      "step": 5870
    },
    {
      "epoch": 3.36,
      "grad_norm": 27.684749603271484,
      "learning_rate": 1.3280000000000002e-05,
      "loss": 0.0762,
      "step": 5880
    },
    {
      "epoch": 3.3657142857142857,
      "grad_norm": 0.08831572532653809,
      "learning_rate": 1.326857142857143e-05,
      "loss": 0.1084,
      "step": 5890
    },
    {
      "epoch": 3.3714285714285714,
      "grad_norm": 0.009073730558156967,
      "learning_rate": 1.3257142857142857e-05,
      "loss": 0.0843,
      "step": 5900
    },
    {
      "epoch": 3.3771428571428572,
      "grad_norm": 0.5288899540901184,
      "learning_rate": 1.3245714285714287e-05,
      "loss": 0.1116,
      "step": 5910
    },
    {
      "epoch": 3.382857142857143,
      "grad_norm": 0.18577690422534943,
      "learning_rate": 1.3234285714285715e-05,
      "loss": 0.0587,
      "step": 5920
    },
    {
      "epoch": 3.388571428571429,
      "grad_norm": 1.6954067945480347,
      "learning_rate": 1.3222857142857144e-05,
      "loss": 0.0696,
      "step": 5930
    },
    {
      "epoch": 3.394285714285714,
      "grad_norm": 0.10830717533826828,
      "learning_rate": 1.3211428571428572e-05,
      "loss": 0.1122,
      "step": 5940
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.7467994689941406,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.0368,
      "step": 5950
    },
    {
      "epoch": 3.4057142857142857,
      "grad_norm": 0.8565022945404053,
      "learning_rate": 1.318857142857143e-05,
      "loss": 0.0455,
      "step": 5960
    },
    {
      "epoch": 3.4114285714285715,
      "grad_norm": 6.426966190338135,
      "learning_rate": 1.3177142857142858e-05,
      "loss": 0.0365,
      "step": 5970
    },
    {
      "epoch": 3.4171428571428573,
      "grad_norm": 0.16596998274326324,
      "learning_rate": 1.3165714285714286e-05,
      "loss": 0.0648,
      "step": 5980
    },
    {
      "epoch": 3.422857142857143,
      "grad_norm": 11.835220336914062,
      "learning_rate": 1.3154285714285714e-05,
      "loss": 0.1271,
      "step": 5990
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.0741799846291542,
      "learning_rate": 1.3142857142857145e-05,
      "loss": 0.0318,
      "step": 6000
    },
    {
      "epoch": 3.434285714285714,
      "grad_norm": 0.29184743762016296,
      "learning_rate": 1.3131428571428573e-05,
      "loss": 0.1117,
      "step": 6010
    },
    {
      "epoch": 3.44,
      "grad_norm": 8.314754486083984,
      "learning_rate": 1.3120000000000001e-05,
      "loss": 0.067,
      "step": 6020
    },
    {
      "epoch": 3.4457142857142857,
      "grad_norm": 0.1854906678199768,
      "learning_rate": 1.310857142857143e-05,
      "loss": 0.1514,
      "step": 6030
    },
    {
      "epoch": 3.4514285714285715,
      "grad_norm": 6.764267444610596,
      "learning_rate": 1.3097142857142857e-05,
      "loss": 0.0338,
      "step": 6040
    },
    {
      "epoch": 3.4571428571428573,
      "grad_norm": 0.19676481187343597,
      "learning_rate": 1.3085714285714287e-05,
      "loss": 0.1108,
      "step": 6050
    },
    {
      "epoch": 3.4628571428571426,
      "grad_norm": 0.07141557335853577,
      "learning_rate": 1.3074285714285715e-05,
      "loss": 0.026,
      "step": 6060
    },
    {
      "epoch": 3.4685714285714284,
      "grad_norm": 0.4193957448005676,
      "learning_rate": 1.3062857142857144e-05,
      "loss": 0.0082,
      "step": 6070
    },
    {
      "epoch": 3.474285714285714,
      "grad_norm": 21.449886322021484,
      "learning_rate": 1.3051428571428572e-05,
      "loss": 0.0927,
      "step": 6080
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.15739299356937408,
      "learning_rate": 1.3040000000000002e-05,
      "loss": 0.086,
      "step": 6090
    },
    {
      "epoch": 3.4857142857142858,
      "grad_norm": 0.09802531450986862,
      "learning_rate": 1.302857142857143e-05,
      "loss": 0.0886,
      "step": 6100
    },
    {
      "epoch": 3.4914285714285715,
      "grad_norm": 7.5356879234313965,
      "learning_rate": 1.3017142857142859e-05,
      "loss": 0.0832,
      "step": 6110
    },
    {
      "epoch": 3.4971428571428573,
      "grad_norm": 0.0654449611902237,
      "learning_rate": 1.3005714285714286e-05,
      "loss": 0.0677,
      "step": 6120
    },
    {
      "epoch": 3.5028571428571427,
      "grad_norm": 2.1051807403564453,
      "learning_rate": 1.2994285714285714e-05,
      "loss": 0.0336,
      "step": 6130
    },
    {
      "epoch": 3.5085714285714285,
      "grad_norm": 1.2133216857910156,
      "learning_rate": 1.2982857142857144e-05,
      "loss": 0.0266,
      "step": 6140
    },
    {
      "epoch": 3.5142857142857142,
      "grad_norm": 0.04042261838912964,
      "learning_rate": 1.2971428571428573e-05,
      "loss": 0.0739,
      "step": 6150
    },
    {
      "epoch": 3.52,
      "grad_norm": 11.798251152038574,
      "learning_rate": 1.2960000000000001e-05,
      "loss": 0.033,
      "step": 6160
    },
    {
      "epoch": 3.525714285714286,
      "grad_norm": 0.017829224467277527,
      "learning_rate": 1.294857142857143e-05,
      "loss": 0.0902,
      "step": 6170
    },
    {
      "epoch": 3.5314285714285716,
      "grad_norm": 0.38740935921669006,
      "learning_rate": 1.293714285714286e-05,
      "loss": 0.0344,
      "step": 6180
    },
    {
      "epoch": 3.5371428571428574,
      "grad_norm": 9.493614196777344,
      "learning_rate": 1.2925714285714287e-05,
      "loss": 0.0849,
      "step": 6190
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 10.887242317199707,
      "learning_rate": 1.2914285714285715e-05,
      "loss": 0.0164,
      "step": 6200
    },
    {
      "epoch": 3.5485714285714285,
      "grad_norm": 0.09280750155448914,
      "learning_rate": 1.2902857142857143e-05,
      "loss": 0.0167,
      "step": 6210
    },
    {
      "epoch": 3.5542857142857143,
      "grad_norm": 0.2176036536693573,
      "learning_rate": 1.2891428571428572e-05,
      "loss": 0.0012,
      "step": 6220
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.42839887738227844,
      "learning_rate": 1.2880000000000002e-05,
      "loss": 0.134,
      "step": 6230
    },
    {
      "epoch": 3.565714285714286,
      "grad_norm": 0.19284096360206604,
      "learning_rate": 1.286857142857143e-05,
      "loss": 0.0095,
      "step": 6240
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.8971611261367798,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 0.0474,
      "step": 6250
    },
    {
      "epoch": 3.5771428571428574,
      "grad_norm": 0.020591868087649345,
      "learning_rate": 1.2845714285714286e-05,
      "loss": 0.0356,
      "step": 6260
    },
    {
      "epoch": 3.5828571428571427,
      "grad_norm": 0.0183319803327322,
      "learning_rate": 1.2834285714285714e-05,
      "loss": 0.0454,
      "step": 6270
    },
    {
      "epoch": 3.5885714285714285,
      "grad_norm": 0.022410694509744644,
      "learning_rate": 1.2822857142857144e-05,
      "loss": 0.0117,
      "step": 6280
    },
    {
      "epoch": 3.5942857142857143,
      "grad_norm": 15.731139183044434,
      "learning_rate": 1.2811428571428573e-05,
      "loss": 0.025,
      "step": 6290
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.0978720411658287,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0059,
      "step": 6300
    },
    {
      "epoch": 3.605714285714286,
      "grad_norm": 0.0038193794898688793,
      "learning_rate": 1.278857142857143e-05,
      "loss": 0.0166,
      "step": 6310
    },
    {
      "epoch": 3.611428571428571,
      "grad_norm": 0.008832783438265324,
      "learning_rate": 1.277714285714286e-05,
      "loss": 0.0021,
      "step": 6320
    },
    {
      "epoch": 3.617142857142857,
      "grad_norm": 0.021715115755796432,
      "learning_rate": 1.2765714285714286e-05,
      "loss": 0.0936,
      "step": 6330
    },
    {
      "epoch": 3.6228571428571428,
      "grad_norm": 0.014547004364430904,
      "learning_rate": 1.2754285714285715e-05,
      "loss": 0.1005,
      "step": 6340
    },
    {
      "epoch": 3.6285714285714286,
      "grad_norm": 0.012800304219126701,
      "learning_rate": 1.2742857142857143e-05,
      "loss": 0.1076,
      "step": 6350
    },
    {
      "epoch": 3.6342857142857143,
      "grad_norm": 2.748497247695923,
      "learning_rate": 1.2731428571428572e-05,
      "loss": 0.0052,
      "step": 6360
    },
    {
      "epoch": 3.64,
      "grad_norm": 7.436798572540283,
      "learning_rate": 1.2720000000000002e-05,
      "loss": 0.0839,
      "step": 6370
    },
    {
      "epoch": 3.645714285714286,
      "grad_norm": 0.16012467443943024,
      "learning_rate": 1.270857142857143e-05,
      "loss": 0.0009,
      "step": 6380
    },
    {
      "epoch": 3.6514285714285712,
      "grad_norm": 0.029165837913751602,
      "learning_rate": 1.2697142857142859e-05,
      "loss": 0.0802,
      "step": 6390
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 0.0007660467526875436,
      "learning_rate": 1.2685714285714286e-05,
      "loss": 0.0636,
      "step": 6400
    },
    {
      "epoch": 3.662857142857143,
      "grad_norm": 0.4333827495574951,
      "learning_rate": 1.2674285714285714e-05,
      "loss": 0.1685,
      "step": 6410
    },
    {
      "epoch": 3.6685714285714286,
      "grad_norm": 16.1954288482666,
      "learning_rate": 1.2662857142857144e-05,
      "loss": 0.0968,
      "step": 6420
    },
    {
      "epoch": 3.6742857142857144,
      "grad_norm": 0.026052633300423622,
      "learning_rate": 1.2651428571428573e-05,
      "loss": 0.0157,
      "step": 6430
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.02128695324063301,
      "learning_rate": 1.2640000000000001e-05,
      "loss": 0.0026,
      "step": 6440
    },
    {
      "epoch": 3.685714285714286,
      "grad_norm": 0.03670462965965271,
      "learning_rate": 1.262857142857143e-05,
      "loss": 0.0578,
      "step": 6450
    },
    {
      "epoch": 3.6914285714285713,
      "grad_norm": 0.016179945319890976,
      "learning_rate": 1.261714285714286e-05,
      "loss": 0.104,
      "step": 6460
    },
    {
      "epoch": 3.697142857142857,
      "grad_norm": 0.1085967943072319,
      "learning_rate": 1.2605714285714288e-05,
      "loss": 0.1014,
      "step": 6470
    },
    {
      "epoch": 3.702857142857143,
      "grad_norm": 0.005795458797365427,
      "learning_rate": 1.2594285714285715e-05,
      "loss": 0.0028,
      "step": 6480
    },
    {
      "epoch": 3.7085714285714286,
      "grad_norm": 0.07907048612833023,
      "learning_rate": 1.2582857142857143e-05,
      "loss": 0.0915,
      "step": 6490
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 6.984023571014404,
      "learning_rate": 1.2571428571428572e-05,
      "loss": 0.0748,
      "step": 6500
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 14.580279350280762,
      "learning_rate": 1.2560000000000002e-05,
      "loss": 0.0965,
      "step": 6510
    },
    {
      "epoch": 3.725714285714286,
      "grad_norm": 0.026788096874952316,
      "learning_rate": 1.254857142857143e-05,
      "loss": 0.0673,
      "step": 6520
    },
    {
      "epoch": 3.7314285714285713,
      "grad_norm": 0.326734334230423,
      "learning_rate": 1.2537142857142859e-05,
      "loss": 0.0708,
      "step": 6530
    },
    {
      "epoch": 3.737142857142857,
      "grad_norm": 0.03296714648604393,
      "learning_rate": 1.2525714285714287e-05,
      "loss": 0.0467,
      "step": 6540
    },
    {
      "epoch": 3.742857142857143,
      "grad_norm": 0.02585357055068016,
      "learning_rate": 1.2514285714285714e-05,
      "loss": 0.0298,
      "step": 6550
    },
    {
      "epoch": 3.7485714285714287,
      "grad_norm": 0.01739535480737686,
      "learning_rate": 1.2502857142857144e-05,
      "loss": 0.0172,
      "step": 6560
    },
    {
      "epoch": 3.7542857142857144,
      "grad_norm": 0.12502208352088928,
      "learning_rate": 1.2491428571428572e-05,
      "loss": 0.0702,
      "step": 6570
    },
    {
      "epoch": 3.76,
      "grad_norm": 14.994475364685059,
      "learning_rate": 1.248e-05,
      "loss": 0.1471,
      "step": 6580
    },
    {
      "epoch": 3.7657142857142856,
      "grad_norm": 0.04107603803277016,
      "learning_rate": 1.246857142857143e-05,
      "loss": 0.0726,
      "step": 6590
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 0.09447473287582397,
      "learning_rate": 1.245714285714286e-05,
      "loss": 0.0111,
      "step": 6600
    },
    {
      "epoch": 3.777142857142857,
      "grad_norm": 0.19802799820899963,
      "learning_rate": 1.2445714285714288e-05,
      "loss": 0.1016,
      "step": 6610
    },
    {
      "epoch": 3.782857142857143,
      "grad_norm": 0.07911323010921478,
      "learning_rate": 1.2434285714285715e-05,
      "loss": 0.0393,
      "step": 6620
    },
    {
      "epoch": 3.7885714285714287,
      "grad_norm": 1.434239387512207,
      "learning_rate": 1.2422857142857143e-05,
      "loss": 0.0205,
      "step": 6630
    },
    {
      "epoch": 3.7942857142857145,
      "grad_norm": 13.990839958190918,
      "learning_rate": 1.2411428571428571e-05,
      "loss": 0.0434,
      "step": 6640
    },
    {
      "epoch": 3.8,
      "grad_norm": 10.015752792358398,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.1061,
      "step": 6650
    },
    {
      "epoch": 3.8057142857142856,
      "grad_norm": 6.347072601318359,
      "learning_rate": 1.238857142857143e-05,
      "loss": 0.07,
      "step": 6660
    },
    {
      "epoch": 3.8114285714285714,
      "grad_norm": 0.12436104565858841,
      "learning_rate": 1.2377142857142858e-05,
      "loss": 0.0013,
      "step": 6670
    },
    {
      "epoch": 3.817142857142857,
      "grad_norm": 0.03993666544556618,
      "learning_rate": 1.2365714285714287e-05,
      "loss": 0.03,
      "step": 6680
    },
    {
      "epoch": 3.822857142857143,
      "grad_norm": 0.06476415693759918,
      "learning_rate": 1.2354285714285714e-05,
      "loss": 0.0055,
      "step": 6690
    },
    {
      "epoch": 3.8285714285714287,
      "grad_norm": 9.261151313781738,
      "learning_rate": 1.2342857142857144e-05,
      "loss": 0.1213,
      "step": 6700
    },
    {
      "epoch": 3.8342857142857145,
      "grad_norm": 0.03021259419620037,
      "learning_rate": 1.2331428571428572e-05,
      "loss": 0.1038,
      "step": 6710
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.030608877539634705,
      "learning_rate": 1.232e-05,
      "loss": 0.0644,
      "step": 6720
    },
    {
      "epoch": 3.8457142857142856,
      "grad_norm": 15.120418548583984,
      "learning_rate": 1.2308571428571429e-05,
      "loss": 0.1062,
      "step": 6730
    },
    {
      "epoch": 3.8514285714285714,
      "grad_norm": 0.013907209038734436,
      "learning_rate": 1.229714285714286e-05,
      "loss": 0.0604,
      "step": 6740
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 10.720620155334473,
      "learning_rate": 1.2285714285714288e-05,
      "loss": 0.0428,
      "step": 6750
    },
    {
      "epoch": 3.862857142857143,
      "grad_norm": 1.2175943851470947,
      "learning_rate": 1.2274285714285716e-05,
      "loss": 0.075,
      "step": 6760
    },
    {
      "epoch": 3.8685714285714283,
      "grad_norm": 1.2277525663375854,
      "learning_rate": 1.2262857142857143e-05,
      "loss": 0.1188,
      "step": 6770
    },
    {
      "epoch": 3.8742857142857146,
      "grad_norm": 19.39629554748535,
      "learning_rate": 1.2251428571428571e-05,
      "loss": 0.0581,
      "step": 6780
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.047872863709926605,
      "learning_rate": 1.2240000000000001e-05,
      "loss": 0.001,
      "step": 6790
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 16.374950408935547,
      "learning_rate": 1.222857142857143e-05,
      "loss": 0.096,
      "step": 6800
    },
    {
      "epoch": 3.8914285714285715,
      "grad_norm": 0.016061829403042793,
      "learning_rate": 1.2217142857142858e-05,
      "loss": 0.0321,
      "step": 6810
    },
    {
      "epoch": 3.8971428571428572,
      "grad_norm": 0.013842419721186161,
      "learning_rate": 1.2205714285714287e-05,
      "loss": 0.094,
      "step": 6820
    },
    {
      "epoch": 3.902857142857143,
      "grad_norm": 4.2031989097595215,
      "learning_rate": 1.2194285714285717e-05,
      "loss": 0.0123,
      "step": 6830
    },
    {
      "epoch": 3.9085714285714284,
      "grad_norm": 0.20956137776374817,
      "learning_rate": 1.2182857142857144e-05,
      "loss": 0.0428,
      "step": 6840
    },
    {
      "epoch": 3.914285714285714,
      "grad_norm": 0.041090160608291626,
      "learning_rate": 1.2171428571428572e-05,
      "loss": 0.0655,
      "step": 6850
    },
    {
      "epoch": 3.92,
      "grad_norm": 19.984161376953125,
      "learning_rate": 1.216e-05,
      "loss": 0.1005,
      "step": 6860
    },
    {
      "epoch": 3.9257142857142857,
      "grad_norm": 0.18975722789764404,
      "learning_rate": 1.2148571428571429e-05,
      "loss": 0.1402,
      "step": 6870
    },
    {
      "epoch": 3.9314285714285715,
      "grad_norm": 8.110401153564453,
      "learning_rate": 1.2137142857142859e-05,
      "loss": 0.1196,
      "step": 6880
    },
    {
      "epoch": 3.9371428571428573,
      "grad_norm": 0.12935198843479156,
      "learning_rate": 1.2125714285714287e-05,
      "loss": 0.078,
      "step": 6890
    },
    {
      "epoch": 3.942857142857143,
      "grad_norm": 0.07027590274810791,
      "learning_rate": 1.2114285714285716e-05,
      "loss": 0.0168,
      "step": 6900
    },
    {
      "epoch": 3.9485714285714284,
      "grad_norm": 0.06480870395898819,
      "learning_rate": 1.2102857142857143e-05,
      "loss": 0.0356,
      "step": 6910
    },
    {
      "epoch": 3.954285714285714,
      "grad_norm": 0.07374812662601471,
      "learning_rate": 1.2091428571428571e-05,
      "loss": 0.0288,
      "step": 6920
    },
    {
      "epoch": 3.96,
      "grad_norm": 18.58941078186035,
      "learning_rate": 1.2080000000000001e-05,
      "loss": 0.0273,
      "step": 6930
    },
    {
      "epoch": 3.9657142857142857,
      "grad_norm": 0.12388622760772705,
      "learning_rate": 1.206857142857143e-05,
      "loss": 0.0766,
      "step": 6940
    },
    {
      "epoch": 3.9714285714285715,
      "grad_norm": 0.279399573802948,
      "learning_rate": 1.2057142857142858e-05,
      "loss": 0.0288,
      "step": 6950
    },
    {
      "epoch": 3.977142857142857,
      "grad_norm": 2.1664462089538574,
      "learning_rate": 1.2045714285714287e-05,
      "loss": 0.0028,
      "step": 6960
    },
    {
      "epoch": 3.982857142857143,
      "grad_norm": 1.2610195875167847,
      "learning_rate": 1.2034285714285717e-05,
      "loss": 0.1801,
      "step": 6970
    },
    {
      "epoch": 3.9885714285714284,
      "grad_norm": 0.035811129957437515,
      "learning_rate": 1.2022857142857143e-05,
      "loss": 0.0395,
      "step": 6980
    },
    {
      "epoch": 3.994285714285714,
      "grad_norm": 0.04887313023209572,
      "learning_rate": 1.2011428571428572e-05,
      "loss": 0.0888,
      "step": 6990
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.12584646046161652,
      "learning_rate": 1.2e-05,
      "loss": 0.0167,
      "step": 7000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9781082887700535,
      "eval_f1": 0.9185829707893101,
      "eval_loss": 0.10592137277126312,
      "eval_precision": 0.9056372549019608,
      "eval_recall": 0.9319041614123581,
      "eval_runtime": 56.2085,
      "eval_samples_per_second": 106.745,
      "eval_steps_per_second": 3.345,
      "step": 7000
    },
    {
      "epoch": 4.005714285714285,
      "grad_norm": 10.512815475463867,
      "learning_rate": 1.1988571428571429e-05,
      "loss": 0.1101,
      "step": 7010
    },
    {
      "epoch": 4.011428571428572,
      "grad_norm": 11.965438842773438,
      "learning_rate": 1.1977142857142859e-05,
      "loss": 0.0563,
      "step": 7020
    },
    {
      "epoch": 4.017142857142857,
      "grad_norm": 0.01632092334330082,
      "learning_rate": 1.1965714285714287e-05,
      "loss": 0.0722,
      "step": 7030
    },
    {
      "epoch": 4.022857142857143,
      "grad_norm": 15.255346298217773,
      "learning_rate": 1.1954285714285716e-05,
      "loss": 0.0507,
      "step": 7040
    },
    {
      "epoch": 4.0285714285714285,
      "grad_norm": 0.018920568749308586,
      "learning_rate": 1.1942857142857144e-05,
      "loss": 0.0022,
      "step": 7050
    },
    {
      "epoch": 4.034285714285715,
      "grad_norm": 0.11194545030593872,
      "learning_rate": 1.1931428571428571e-05,
      "loss": 0.0562,
      "step": 7060
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.5338773727416992,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.0848,
      "step": 7070
    },
    {
      "epoch": 4.045714285714285,
      "grad_norm": 0.020200558006763458,
      "learning_rate": 1.190857142857143e-05,
      "loss": 0.0422,
      "step": 7080
    },
    {
      "epoch": 4.051428571428572,
      "grad_norm": 0.09313484281301498,
      "learning_rate": 1.1897142857142858e-05,
      "loss": 0.0281,
      "step": 7090
    },
    {
      "epoch": 4.057142857142857,
      "grad_norm": 0.012309355661273003,
      "learning_rate": 1.1885714285714286e-05,
      "loss": 0.0062,
      "step": 7100
    },
    {
      "epoch": 4.062857142857143,
      "grad_norm": 0.02515960857272148,
      "learning_rate": 1.1874285714285717e-05,
      "loss": 0.0007,
      "step": 7110
    },
    {
      "epoch": 4.0685714285714285,
      "grad_norm": 0.006699079647660255,
      "learning_rate": 1.1862857142857145e-05,
      "loss": 0.0026,
      "step": 7120
    },
    {
      "epoch": 4.074285714285715,
      "grad_norm": 0.02337348647415638,
      "learning_rate": 1.1851428571428572e-05,
      "loss": 0.034,
      "step": 7130
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.2857615649700165,
      "learning_rate": 1.184e-05,
      "loss": 0.0599,
      "step": 7140
    },
    {
      "epoch": 4.085714285714285,
      "grad_norm": 0.014278857968747616,
      "learning_rate": 1.1828571428571429e-05,
      "loss": 0.0308,
      "step": 7150
    },
    {
      "epoch": 4.091428571428572,
      "grad_norm": 0.02123253047466278,
      "learning_rate": 1.1817142857142859e-05,
      "loss": 0.055,
      "step": 7160
    },
    {
      "epoch": 4.097142857142857,
      "grad_norm": 9.660703659057617,
      "learning_rate": 1.1805714285714287e-05,
      "loss": 0.0107,
      "step": 7170
    },
    {
      "epoch": 4.102857142857143,
      "grad_norm": 0.09393361955881119,
      "learning_rate": 1.1794285714285716e-05,
      "loss": 0.0008,
      "step": 7180
    },
    {
      "epoch": 4.1085714285714285,
      "grad_norm": 0.06963155418634415,
      "learning_rate": 1.1782857142857144e-05,
      "loss": 0.0006,
      "step": 7190
    },
    {
      "epoch": 4.114285714285714,
      "grad_norm": 0.0058304667472839355,
      "learning_rate": 1.177142857142857e-05,
      "loss": 0.0179,
      "step": 7200
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.04369629919528961,
      "learning_rate": 1.1760000000000001e-05,
      "loss": 0.0161,
      "step": 7210
    },
    {
      "epoch": 4.1257142857142854,
      "grad_norm": 0.09797057509422302,
      "learning_rate": 1.174857142857143e-05,
      "loss": 0.0242,
      "step": 7220
    },
    {
      "epoch": 4.131428571428572,
      "grad_norm": 2.7343382835388184,
      "learning_rate": 1.1737142857142858e-05,
      "loss": 0.0753,
      "step": 7230
    },
    {
      "epoch": 4.137142857142857,
      "grad_norm": 0.004986340180039406,
      "learning_rate": 1.1725714285714286e-05,
      "loss": 0.0537,
      "step": 7240
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 26.836795806884766,
      "learning_rate": 1.1714285714285716e-05,
      "loss": 0.0866,
      "step": 7250
    },
    {
      "epoch": 4.148571428571429,
      "grad_norm": 0.007283846382051706,
      "learning_rate": 1.1702857142857145e-05,
      "loss": 0.1241,
      "step": 7260
    },
    {
      "epoch": 4.154285714285714,
      "grad_norm": 3.0138235092163086,
      "learning_rate": 1.1691428571428572e-05,
      "loss": 0.0162,
      "step": 7270
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.008108407258987427,
      "learning_rate": 1.168e-05,
      "loss": 0.0009,
      "step": 7280
    },
    {
      "epoch": 4.1657142857142855,
      "grad_norm": 0.03439145162701607,
      "learning_rate": 1.1668571428571428e-05,
      "loss": 0.0784,
      "step": 7290
    },
    {
      "epoch": 4.171428571428572,
      "grad_norm": 0.05440853163599968,
      "learning_rate": 1.1657142857142859e-05,
      "loss": 0.004,
      "step": 7300
    },
    {
      "epoch": 4.177142857142857,
      "grad_norm": 0.003484092652797699,
      "learning_rate": 1.1645714285714287e-05,
      "loss": 0.0024,
      "step": 7310
    },
    {
      "epoch": 4.182857142857143,
      "grad_norm": 9.133429527282715,
      "learning_rate": 1.1634285714285715e-05,
      "loss": 0.102,
      "step": 7320
    },
    {
      "epoch": 4.188571428571429,
      "grad_norm": 0.10679076611995697,
      "learning_rate": 1.1622857142857144e-05,
      "loss": 0.1446,
      "step": 7330
    },
    {
      "epoch": 4.194285714285714,
      "grad_norm": 0.15510199964046478,
      "learning_rate": 1.161142857142857e-05,
      "loss": 0.004,
      "step": 7340
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.008244461379945278,
      "learning_rate": 1.16e-05,
      "loss": 0.006,
      "step": 7350
    },
    {
      "epoch": 4.2057142857142855,
      "grad_norm": 0.011431614868342876,
      "learning_rate": 1.158857142857143e-05,
      "loss": 0.0655,
      "step": 7360
    },
    {
      "epoch": 4.211428571428572,
      "grad_norm": 0.0059136212803423405,
      "learning_rate": 1.1577142857142858e-05,
      "loss": 0.0639,
      "step": 7370
    },
    {
      "epoch": 4.217142857142857,
      "grad_norm": 0.020416270941495895,
      "learning_rate": 1.1565714285714286e-05,
      "loss": 0.0485,
      "step": 7380
    },
    {
      "epoch": 4.222857142857142,
      "grad_norm": 19.1518611907959,
      "learning_rate": 1.1554285714285716e-05,
      "loss": 0.0188,
      "step": 7390
    },
    {
      "epoch": 4.228571428571429,
      "grad_norm": 0.08116956055164337,
      "learning_rate": 1.1542857142857145e-05,
      "loss": 0.084,
      "step": 7400
    },
    {
      "epoch": 4.234285714285714,
      "grad_norm": 0.019459733739495277,
      "learning_rate": 1.1531428571428573e-05,
      "loss": 0.0143,
      "step": 7410
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.030960239470005035,
      "learning_rate": 1.152e-05,
      "loss": 0.0521,
      "step": 7420
    },
    {
      "epoch": 4.2457142857142856,
      "grad_norm": 8.938582420349121,
      "learning_rate": 1.1508571428571428e-05,
      "loss": 0.0659,
      "step": 7430
    },
    {
      "epoch": 4.251428571428572,
      "grad_norm": 0.10409325361251831,
      "learning_rate": 1.1497142857142858e-05,
      "loss": 0.0394,
      "step": 7440
    },
    {
      "epoch": 4.257142857142857,
      "grad_norm": 0.02218901365995407,
      "learning_rate": 1.1485714285714287e-05,
      "loss": 0.0548,
      "step": 7450
    },
    {
      "epoch": 4.2628571428571425,
      "grad_norm": 0.30128586292266846,
      "learning_rate": 1.1474285714285715e-05,
      "loss": 0.0362,
      "step": 7460
    },
    {
      "epoch": 4.268571428571429,
      "grad_norm": 0.09753865003585815,
      "learning_rate": 1.1462857142857144e-05,
      "loss": 0.0844,
      "step": 7470
    },
    {
      "epoch": 4.274285714285714,
      "grad_norm": 0.0438108965754509,
      "learning_rate": 1.1451428571428574e-05,
      "loss": 0.0245,
      "step": 7480
    },
    {
      "epoch": 4.28,
      "grad_norm": 1.294985294342041,
      "learning_rate": 1.144e-05,
      "loss": 0.0887,
      "step": 7490
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.3435782194137573,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0395,
      "step": 7500
    },
    {
      "epoch": 4.291428571428572,
      "grad_norm": 6.324498653411865,
      "learning_rate": 1.1417142857142857e-05,
      "loss": 0.0615,
      "step": 7510
    },
    {
      "epoch": 4.297142857142857,
      "grad_norm": 0.0015265810070559382,
      "learning_rate": 1.1405714285714286e-05,
      "loss": 0.002,
      "step": 7520
    },
    {
      "epoch": 4.3028571428571425,
      "grad_norm": 0.01320401206612587,
      "learning_rate": 1.1394285714285716e-05,
      "loss": 0.0003,
      "step": 7530
    },
    {
      "epoch": 4.308571428571429,
      "grad_norm": 0.1584329754114151,
      "learning_rate": 1.1382857142857144e-05,
      "loss": 0.0347,
      "step": 7540
    },
    {
      "epoch": 4.314285714285714,
      "grad_norm": 0.1435961276292801,
      "learning_rate": 1.1371428571428573e-05,
      "loss": 0.0457,
      "step": 7550
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.006638684775680304,
      "learning_rate": 1.136e-05,
      "loss": 0.0004,
      "step": 7560
    },
    {
      "epoch": 4.325714285714286,
      "grad_norm": 0.9338825941085815,
      "learning_rate": 1.1348571428571428e-05,
      "loss": 0.0292,
      "step": 7570
    },
    {
      "epoch": 4.331428571428571,
      "grad_norm": 0.009318542666733265,
      "learning_rate": 1.1337142857142858e-05,
      "loss": 0.0187,
      "step": 7580
    },
    {
      "epoch": 4.337142857142857,
      "grad_norm": 0.02162431739270687,
      "learning_rate": 1.1325714285714287e-05,
      "loss": 0.0004,
      "step": 7590
    },
    {
      "epoch": 4.3428571428571425,
      "grad_norm": 5.18455171585083,
      "learning_rate": 1.1314285714285715e-05,
      "loss": 0.0972,
      "step": 7600
    },
    {
      "epoch": 4.348571428571429,
      "grad_norm": 8.454720497131348,
      "learning_rate": 1.1302857142857144e-05,
      "loss": 0.0359,
      "step": 7610
    },
    {
      "epoch": 4.354285714285714,
      "grad_norm": 5.705512523651123,
      "learning_rate": 1.1291428571428574e-05,
      "loss": 0.0219,
      "step": 7620
    },
    {
      "epoch": 4.36,
      "grad_norm": 7.7738423347473145,
      "learning_rate": 1.128e-05,
      "loss": 0.091,
      "step": 7630
    },
    {
      "epoch": 4.365714285714286,
      "grad_norm": 0.04323364421725273,
      "learning_rate": 1.1268571428571429e-05,
      "loss": 0.0612,
      "step": 7640
    },
    {
      "epoch": 4.371428571428572,
      "grad_norm": 0.013362442143261433,
      "learning_rate": 1.1257142857142857e-05,
      "loss": 0.0431,
      "step": 7650
    },
    {
      "epoch": 4.377142857142857,
      "grad_norm": 15.20934772491455,
      "learning_rate": 1.1245714285714286e-05,
      "loss": 0.0748,
      "step": 7660
    },
    {
      "epoch": 4.382857142857143,
      "grad_norm": 10.277928352355957,
      "learning_rate": 1.1234285714285716e-05,
      "loss": 0.0634,
      "step": 7670
    },
    {
      "epoch": 4.388571428571429,
      "grad_norm": 0.03613138943910599,
      "learning_rate": 1.1222857142857144e-05,
      "loss": 0.0269,
      "step": 7680
    },
    {
      "epoch": 4.394285714285714,
      "grad_norm": 0.32959407567977905,
      "learning_rate": 1.1211428571428573e-05,
      "loss": 0.0476,
      "step": 7690
    },
    {
      "epoch": 4.4,
      "grad_norm": 8.74209976196289,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0523,
      "step": 7700
    },
    {
      "epoch": 4.405714285714286,
      "grad_norm": 0.3026800751686096,
      "learning_rate": 1.1188571428571428e-05,
      "loss": 0.0283,
      "step": 7710
    },
    {
      "epoch": 4.411428571428571,
      "grad_norm": 0.013006812892854214,
      "learning_rate": 1.1177142857142858e-05,
      "loss": 0.0126,
      "step": 7720
    },
    {
      "epoch": 4.417142857142857,
      "grad_norm": 0.08340294659137726,
      "learning_rate": 1.1165714285714287e-05,
      "loss": 0.0459,
      "step": 7730
    },
    {
      "epoch": 4.422857142857143,
      "grad_norm": 0.00440503703430295,
      "learning_rate": 1.1154285714285715e-05,
      "loss": 0.0649,
      "step": 7740
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 0.08220382034778595,
      "learning_rate": 1.1142857142857143e-05,
      "loss": 0.0051,
      "step": 7750
    },
    {
      "epoch": 4.434285714285714,
      "grad_norm": 9.799430847167969,
      "learning_rate": 1.1131428571428574e-05,
      "loss": 0.0096,
      "step": 7760
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.024712542071938515,
      "learning_rate": 1.1120000000000002e-05,
      "loss": 0.0264,
      "step": 7770
    },
    {
      "epoch": 4.445714285714286,
      "grad_norm": 0.21230880916118622,
      "learning_rate": 1.1108571428571429e-05,
      "loss": 0.002,
      "step": 7780
    },
    {
      "epoch": 4.451428571428571,
      "grad_norm": 0.04764468967914581,
      "learning_rate": 1.1097142857142857e-05,
      "loss": 0.0002,
      "step": 7790
    },
    {
      "epoch": 4.457142857142857,
      "grad_norm": 19.121389389038086,
      "learning_rate": 1.1085714285714286e-05,
      "loss": 0.0459,
      "step": 7800
    },
    {
      "epoch": 4.462857142857143,
      "grad_norm": 0.04667510837316513,
      "learning_rate": 1.1074285714285716e-05,
      "loss": 0.0887,
      "step": 7810
    },
    {
      "epoch": 4.468571428571429,
      "grad_norm": 0.0016638904344290495,
      "learning_rate": 1.1062857142857144e-05,
      "loss": 0.0274,
      "step": 7820
    },
    {
      "epoch": 4.474285714285714,
      "grad_norm": 0.2965202331542969,
      "learning_rate": 1.1051428571428573e-05,
      "loss": 0.0884,
      "step": 7830
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.08727343380451202,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.0286,
      "step": 7840
    },
    {
      "epoch": 4.485714285714286,
      "grad_norm": 0.024284372106194496,
      "learning_rate": 1.1028571428571428e-05,
      "loss": 0.0004,
      "step": 7850
    },
    {
      "epoch": 4.491428571428571,
      "grad_norm": 7.414970397949219,
      "learning_rate": 1.1017142857142858e-05,
      "loss": 0.0409,
      "step": 7860
    },
    {
      "epoch": 4.497142857142857,
      "grad_norm": 0.07688073813915253,
      "learning_rate": 1.1005714285714286e-05,
      "loss": 0.0231,
      "step": 7870
    },
    {
      "epoch": 4.502857142857143,
      "grad_norm": 6.46159029006958,
      "learning_rate": 1.0994285714285715e-05,
      "loss": 0.0821,
      "step": 7880
    },
    {
      "epoch": 4.508571428571429,
      "grad_norm": 0.006565817631781101,
      "learning_rate": 1.0982857142857143e-05,
      "loss": 0.0751,
      "step": 7890
    },
    {
      "epoch": 4.514285714285714,
      "grad_norm": 0.008678947575390339,
      "learning_rate": 1.0971428571428573e-05,
      "loss": 0.005,
      "step": 7900
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.0184448454529047,
      "learning_rate": 1.0960000000000002e-05,
      "loss": 0.0614,
      "step": 7910
    },
    {
      "epoch": 4.525714285714286,
      "grad_norm": 0.007873830385506153,
      "learning_rate": 1.0948571428571429e-05,
      "loss": 0.0008,
      "step": 7920
    },
    {
      "epoch": 4.531428571428571,
      "grad_norm": 4.832582473754883,
      "learning_rate": 1.0937142857142857e-05,
      "loss": 0.0897,
      "step": 7930
    },
    {
      "epoch": 4.537142857142857,
      "grad_norm": 0.039475392550230026,
      "learning_rate": 1.0925714285714285e-05,
      "loss": 0.0225,
      "step": 7940
    },
    {
      "epoch": 4.542857142857143,
      "grad_norm": 1.42202627658844,
      "learning_rate": 1.0914285714285716e-05,
      "loss": 0.0341,
      "step": 7950
    },
    {
      "epoch": 4.548571428571429,
      "grad_norm": 0.15037798881530762,
      "learning_rate": 1.0902857142857144e-05,
      "loss": 0.0418,
      "step": 7960
    },
    {
      "epoch": 4.554285714285714,
      "grad_norm": 10.85245418548584,
      "learning_rate": 1.0891428571428572e-05,
      "loss": 0.0312,
      "step": 7970
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.019213685765862465,
      "learning_rate": 1.0880000000000001e-05,
      "loss": 0.002,
      "step": 7980
    },
    {
      "epoch": 4.565714285714286,
      "grad_norm": 0.005448846146464348,
      "learning_rate": 1.0868571428571431e-05,
      "loss": 0.0047,
      "step": 7990
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.007244917564094067,
      "learning_rate": 1.0857142857142858e-05,
      "loss": 0.0646,
      "step": 8000
    },
    {
      "epoch": 4.577142857142857,
      "grad_norm": 10.625605583190918,
      "learning_rate": 1.0845714285714286e-05,
      "loss": 0.0788,
      "step": 8010
    },
    {
      "epoch": 4.582857142857143,
      "grad_norm": 0.1394202560186386,
      "learning_rate": 1.0834285714285715e-05,
      "loss": 0.1261,
      "step": 8020
    },
    {
      "epoch": 4.588571428571429,
      "grad_norm": 0.027856769040226936,
      "learning_rate": 1.0822857142857143e-05,
      "loss": 0.0362,
      "step": 8030
    },
    {
      "epoch": 4.594285714285714,
      "grad_norm": 0.1300196498632431,
      "learning_rate": 1.0811428571428573e-05,
      "loss": 0.0445,
      "step": 8040
    },
    {
      "epoch": 4.6,
      "grad_norm": 2.8337199687957764,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.0516,
      "step": 8050
    },
    {
      "epoch": 4.605714285714286,
      "grad_norm": 0.17746539413928986,
      "learning_rate": 1.078857142857143e-05,
      "loss": 0.0657,
      "step": 8060
    },
    {
      "epoch": 4.611428571428571,
      "grad_norm": 22.354822158813477,
      "learning_rate": 1.0777142857142857e-05,
      "loss": 0.01,
      "step": 8070
    },
    {
      "epoch": 4.617142857142857,
      "grad_norm": 9.884613990783691,
      "learning_rate": 1.0765714285714285e-05,
      "loss": 0.0569,
      "step": 8080
    },
    {
      "epoch": 4.622857142857143,
      "grad_norm": 0.02311621606349945,
      "learning_rate": 1.0754285714285715e-05,
      "loss": 0.0534,
      "step": 8090
    },
    {
      "epoch": 4.628571428571428,
      "grad_norm": 0.14874514937400818,
      "learning_rate": 1.0742857142857144e-05,
      "loss": 0.0389,
      "step": 8100
    },
    {
      "epoch": 4.634285714285714,
      "grad_norm": 0.01760248653590679,
      "learning_rate": 1.0731428571428572e-05,
      "loss": 0.0212,
      "step": 8110
    },
    {
      "epoch": 4.64,
      "grad_norm": 8.888644218444824,
      "learning_rate": 1.072e-05,
      "loss": 0.0976,
      "step": 8120
    },
    {
      "epoch": 4.645714285714286,
      "grad_norm": 0.1627451777458191,
      "learning_rate": 1.070857142857143e-05,
      "loss": 0.0199,
      "step": 8130
    },
    {
      "epoch": 4.651428571428571,
      "grad_norm": 0.24226228892803192,
      "learning_rate": 1.0697142857142858e-05,
      "loss": 0.0095,
      "step": 8140
    },
    {
      "epoch": 4.6571428571428575,
      "grad_norm": 0.048497263342142105,
      "learning_rate": 1.0685714285714286e-05,
      "loss": 0.0704,
      "step": 8150
    },
    {
      "epoch": 4.662857142857143,
      "grad_norm": 0.009840617887675762,
      "learning_rate": 1.0674285714285714e-05,
      "loss": 0.0337,
      "step": 8160
    },
    {
      "epoch": 4.668571428571429,
      "grad_norm": 5.321723461151123,
      "learning_rate": 1.0662857142857143e-05,
      "loss": 0.0464,
      "step": 8170
    },
    {
      "epoch": 4.674285714285714,
      "grad_norm": 0.0476139560341835,
      "learning_rate": 1.0651428571428573e-05,
      "loss": 0.0297,
      "step": 8180
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.03566906228661537,
      "learning_rate": 1.0640000000000001e-05,
      "loss": 0.0239,
      "step": 8190
    },
    {
      "epoch": 4.685714285714286,
      "grad_norm": 0.05761055275797844,
      "learning_rate": 1.062857142857143e-05,
      "loss": 0.0157,
      "step": 8200
    },
    {
      "epoch": 4.691428571428571,
      "grad_norm": 0.0512373149394989,
      "learning_rate": 1.0617142857142857e-05,
      "loss": 0.0014,
      "step": 8210
    },
    {
      "epoch": 4.6971428571428575,
      "grad_norm": 0.014622232876718044,
      "learning_rate": 1.0605714285714285e-05,
      "loss": 0.0436,
      "step": 8220
    },
    {
      "epoch": 4.702857142857143,
      "grad_norm": 0.020163286477327347,
      "learning_rate": 1.0594285714285715e-05,
      "loss": 0.0005,
      "step": 8230
    },
    {
      "epoch": 4.708571428571428,
      "grad_norm": 0.02802109904587269,
      "learning_rate": 1.0582857142857144e-05,
      "loss": 0.1207,
      "step": 8240
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 11.851643562316895,
      "learning_rate": 1.0571428571428572e-05,
      "loss": 0.1004,
      "step": 8250
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.3014845550060272,
      "learning_rate": 1.056e-05,
      "loss": 0.002,
      "step": 8260
    },
    {
      "epoch": 4.725714285714286,
      "grad_norm": 0.1727033108472824,
      "learning_rate": 1.054857142857143e-05,
      "loss": 0.0083,
      "step": 8270
    },
    {
      "epoch": 4.731428571428571,
      "grad_norm": 0.0601845346391201,
      "learning_rate": 1.0537142857142857e-05,
      "loss": 0.0632,
      "step": 8280
    },
    {
      "epoch": 4.737142857142857,
      "grad_norm": 0.05136670172214508,
      "learning_rate": 1.0525714285714286e-05,
      "loss": 0.095,
      "step": 8290
    },
    {
      "epoch": 4.742857142857143,
      "grad_norm": 0.017654096707701683,
      "learning_rate": 1.0514285714285714e-05,
      "loss": 0.0506,
      "step": 8300
    },
    {
      "epoch": 4.748571428571428,
      "grad_norm": 0.028600256890058517,
      "learning_rate": 1.0502857142857143e-05,
      "loss": 0.0907,
      "step": 8310
    },
    {
      "epoch": 4.7542857142857144,
      "grad_norm": 0.19452297687530518,
      "learning_rate": 1.0491428571428573e-05,
      "loss": 0.0616,
      "step": 8320
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.1340761035680771,
      "learning_rate": 1.0480000000000001e-05,
      "loss": 0.0079,
      "step": 8330
    },
    {
      "epoch": 4.765714285714286,
      "grad_norm": 21.628154754638672,
      "learning_rate": 1.046857142857143e-05,
      "loss": 0.1097,
      "step": 8340
    },
    {
      "epoch": 4.771428571428571,
      "grad_norm": 5.969886302947998,
      "learning_rate": 1.045714285714286e-05,
      "loss": 0.0314,
      "step": 8350
    },
    {
      "epoch": 4.777142857142858,
      "grad_norm": 9.439533233642578,
      "learning_rate": 1.0445714285714285e-05,
      "loss": 0.0849,
      "step": 8360
    },
    {
      "epoch": 4.782857142857143,
      "grad_norm": 1.1037750244140625,
      "learning_rate": 1.0434285714285715e-05,
      "loss": 0.055,
      "step": 8370
    },
    {
      "epoch": 4.788571428571428,
      "grad_norm": 1.7789145708084106,
      "learning_rate": 1.0422857142857143e-05,
      "loss": 0.024,
      "step": 8380
    },
    {
      "epoch": 4.7942857142857145,
      "grad_norm": 0.36916133761405945,
      "learning_rate": 1.0411428571428572e-05,
      "loss": 0.0075,
      "step": 8390
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.9542756676673889,
      "learning_rate": 1.04e-05,
      "loss": 0.004,
      "step": 8400
    },
    {
      "epoch": 4.805714285714286,
      "grad_norm": 0.009212791919708252,
      "learning_rate": 1.038857142857143e-05,
      "loss": 0.0104,
      "step": 8410
    },
    {
      "epoch": 4.811428571428571,
      "grad_norm": 0.010653400793671608,
      "learning_rate": 1.0377142857142859e-05,
      "loss": 0.0484,
      "step": 8420
    },
    {
      "epoch": 4.817142857142857,
      "grad_norm": 0.36325910687446594,
      "learning_rate": 1.0365714285714286e-05,
      "loss": 0.0224,
      "step": 8430
    },
    {
      "epoch": 4.822857142857143,
      "grad_norm": 0.009065566584467888,
      "learning_rate": 1.0354285714285714e-05,
      "loss": 0.0258,
      "step": 8440
    },
    {
      "epoch": 4.828571428571428,
      "grad_norm": 0.2883334159851074,
      "learning_rate": 1.0342857142857143e-05,
      "loss": 0.0257,
      "step": 8450
    },
    {
      "epoch": 4.8342857142857145,
      "grad_norm": 0.011746123433113098,
      "learning_rate": 1.0331428571428573e-05,
      "loss": 0.0389,
      "step": 8460
    },
    {
      "epoch": 4.84,
      "grad_norm": 10.120943069458008,
      "learning_rate": 1.0320000000000001e-05,
      "loss": 0.0536,
      "step": 8470
    },
    {
      "epoch": 4.845714285714286,
      "grad_norm": 0.4728478193283081,
      "learning_rate": 1.030857142857143e-05,
      "loss": 0.0715,
      "step": 8480
    },
    {
      "epoch": 4.851428571428571,
      "grad_norm": 0.02853763848543167,
      "learning_rate": 1.029714285714286e-05,
      "loss": 0.016,
      "step": 8490
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.0347587987780571,
      "learning_rate": 1.0285714285714285e-05,
      "loss": 0.0588,
      "step": 8500
    },
    {
      "epoch": 4.862857142857143,
      "grad_norm": 0.008130062371492386,
      "learning_rate": 1.0274285714285715e-05,
      "loss": 0.0291,
      "step": 8510
    },
    {
      "epoch": 4.868571428571428,
      "grad_norm": 0.04151401296257973,
      "learning_rate": 1.0262857142857143e-05,
      "loss": 0.0117,
      "step": 8520
    },
    {
      "epoch": 4.8742857142857146,
      "grad_norm": 0.06162292882800102,
      "learning_rate": 1.0251428571428572e-05,
      "loss": 0.1197,
      "step": 8530
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.01033494807779789,
      "learning_rate": 1.024e-05,
      "loss": 0.064,
      "step": 8540
    },
    {
      "epoch": 4.885714285714286,
      "grad_norm": 0.03416992351412773,
      "learning_rate": 1.022857142857143e-05,
      "loss": 0.0722,
      "step": 8550
    },
    {
      "epoch": 4.8914285714285715,
      "grad_norm": 0.34837183356285095,
      "learning_rate": 1.0217142857142859e-05,
      "loss": 0.0386,
      "step": 8560
    },
    {
      "epoch": 4.897142857142857,
      "grad_norm": 19.225330352783203,
      "learning_rate": 1.0205714285714286e-05,
      "loss": 0.067,
      "step": 8570
    },
    {
      "epoch": 4.902857142857143,
      "grad_norm": 0.031072700396180153,
      "learning_rate": 1.0194285714285714e-05,
      "loss": 0.068,
      "step": 8580
    },
    {
      "epoch": 4.908571428571428,
      "grad_norm": 0.06877566128969193,
      "learning_rate": 1.0182857142857142e-05,
      "loss": 0.0598,
      "step": 8590
    },
    {
      "epoch": 4.914285714285715,
      "grad_norm": 0.027347180992364883,
      "learning_rate": 1.0171428571428573e-05,
      "loss": 0.005,
      "step": 8600
    },
    {
      "epoch": 4.92,
      "grad_norm": 9.181511878967285,
      "learning_rate": 1.0160000000000001e-05,
      "loss": 0.1824,
      "step": 8610
    },
    {
      "epoch": 4.925714285714285,
      "grad_norm": 1.7852064371109009,
      "learning_rate": 1.014857142857143e-05,
      "loss": 0.0245,
      "step": 8620
    },
    {
      "epoch": 4.9314285714285715,
      "grad_norm": 7.751638889312744,
      "learning_rate": 1.013714285714286e-05,
      "loss": 0.0993,
      "step": 8630
    },
    {
      "epoch": 4.937142857142857,
      "grad_norm": 0.01628187671303749,
      "learning_rate": 1.0125714285714288e-05,
      "loss": 0.0184,
      "step": 8640
    },
    {
      "epoch": 4.942857142857143,
      "grad_norm": 17.033761978149414,
      "learning_rate": 1.0114285714285715e-05,
      "loss": 0.0425,
      "step": 8650
    },
    {
      "epoch": 4.948571428571428,
      "grad_norm": 0.038663219660520554,
      "learning_rate": 1.0102857142857143e-05,
      "loss": 0.0228,
      "step": 8660
    },
    {
      "epoch": 4.954285714285715,
      "grad_norm": 8.662274360656738,
      "learning_rate": 1.0091428571428572e-05,
      "loss": 0.1061,
      "step": 8670
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.14025162160396576,
      "learning_rate": 1.008e-05,
      "loss": 0.0269,
      "step": 8680
    },
    {
      "epoch": 4.965714285714286,
      "grad_norm": 0.051022063940763474,
      "learning_rate": 1.006857142857143e-05,
      "loss": 0.0332,
      "step": 8690
    },
    {
      "epoch": 4.9714285714285715,
      "grad_norm": 0.026465555652976036,
      "learning_rate": 1.0057142857142859e-05,
      "loss": 0.0231,
      "step": 8700
    },
    {
      "epoch": 4.977142857142857,
      "grad_norm": 0.2993873655796051,
      "learning_rate": 1.0045714285714287e-05,
      "loss": 0.0576,
      "step": 8710
    },
    {
      "epoch": 4.982857142857143,
      "grad_norm": 11.635605812072754,
      "learning_rate": 1.0034285714285714e-05,
      "loss": 0.0284,
      "step": 8720
    },
    {
      "epoch": 4.988571428571428,
      "grad_norm": 0.004916683305054903,
      "learning_rate": 1.0022857142857142e-05,
      "loss": 0.0031,
      "step": 8730
    },
    {
      "epoch": 4.994285714285715,
      "grad_norm": 11.31294059753418,
      "learning_rate": 1.0011428571428572e-05,
      "loss": 0.0949,
      "step": 8740
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.06270841509103775,
      "learning_rate": 1e-05,
      "loss": 0.0844,
      "step": 8750
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9812834224598931,
      "eval_f1": 0.9299999999999999,
      "eval_loss": 0.0877995491027832,
      "eval_precision": 0.9219330855018587,
      "eval_recall": 0.9382093316519546,
      "eval_runtime": 56.9454,
      "eval_samples_per_second": 105.364,
      "eval_steps_per_second": 3.301,
      "step": 8750
    },
    {
      "epoch": 5.005714285714285,
      "grad_norm": 1.7350103855133057,
      "learning_rate": 9.98857142857143e-06,
      "loss": 0.0043,
      "step": 8760
    },
    {
      "epoch": 5.011428571428572,
      "grad_norm": 0.008760235272347927,
      "learning_rate": 9.977142857142858e-06,
      "loss": 0.0007,
      "step": 8770
    },
    {
      "epoch": 5.017142857142857,
      "grad_norm": 0.007345238700509071,
      "learning_rate": 9.965714285714286e-06,
      "loss": 0.0338,
      "step": 8780
    },
    {
      "epoch": 5.022857142857143,
      "grad_norm": 0.010971437208354473,
      "learning_rate": 9.954285714285715e-06,
      "loss": 0.0055,
      "step": 8790
    },
    {
      "epoch": 5.0285714285714285,
      "grad_norm": 0.0028909125830978155,
      "learning_rate": 9.942857142857145e-06,
      "loss": 0.0206,
      "step": 8800
    },
    {
      "epoch": 5.034285714285715,
      "grad_norm": 0.001060636481270194,
      "learning_rate": 9.931428571428571e-06,
      "loss": 0.0246,
      "step": 8810
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.016002951189875603,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.0333,
      "step": 8820
    },
    {
      "epoch": 5.045714285714285,
      "grad_norm": 0.0062131271697580814,
      "learning_rate": 9.90857142857143e-06,
      "loss": 0.042,
      "step": 8830
    },
    {
      "epoch": 5.051428571428572,
      "grad_norm": 0.010014261119067669,
      "learning_rate": 9.897142857142858e-06,
      "loss": 0.0003,
      "step": 8840
    },
    {
      "epoch": 5.057142857142857,
      "grad_norm": 0.04313046112656593,
      "learning_rate": 9.885714285714287e-06,
      "loss": 0.0397,
      "step": 8850
    },
    {
      "epoch": 5.062857142857143,
      "grad_norm": 0.001950683887116611,
      "learning_rate": 9.874285714285715e-06,
      "loss": 0.0004,
      "step": 8860
    },
    {
      "epoch": 5.0685714285714285,
      "grad_norm": 21.395286560058594,
      "learning_rate": 9.862857142857144e-06,
      "loss": 0.0285,
      "step": 8870
    },
    {
      "epoch": 5.074285714285715,
      "grad_norm": 0.020638611167669296,
      "learning_rate": 9.851428571428572e-06,
      "loss": 0.0158,
      "step": 8880
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.0659610703587532,
      "learning_rate": 9.84e-06,
      "loss": 0.0099,
      "step": 8890
    },
    {
      "epoch": 5.085714285714285,
      "grad_norm": 0.01873539388179779,
      "learning_rate": 9.828571428571429e-06,
      "loss": 0.0286,
      "step": 8900
    },
    {
      "epoch": 5.091428571428572,
      "grad_norm": 0.011041908524930477,
      "learning_rate": 9.81714285714286e-06,
      "loss": 0.14,
      "step": 8910
    },
    {
      "epoch": 5.097142857142857,
      "grad_norm": 0.0689946636557579,
      "learning_rate": 9.805714285714286e-06,
      "loss": 0.0496,
      "step": 8920
    },
    {
      "epoch": 5.102857142857143,
      "grad_norm": 0.0192593801766634,
      "learning_rate": 9.794285714285714e-06,
      "loss": 0.0005,
      "step": 8930
    },
    {
      "epoch": 5.1085714285714285,
      "grad_norm": 0.043236829340457916,
      "learning_rate": 9.782857142857145e-06,
      "loss": 0.0962,
      "step": 8940
    },
    {
      "epoch": 5.114285714285714,
      "grad_norm": 0.004126180429011583,
      "learning_rate": 9.771428571428571e-06,
      "loss": 0.011,
      "step": 8950
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.07110511511564255,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.0628,
      "step": 8960
    },
    {
      "epoch": 5.1257142857142854,
      "grad_norm": 0.007194156292825937,
      "learning_rate": 9.74857142857143e-06,
      "loss": 0.0032,
      "step": 8970
    },
    {
      "epoch": 5.131428571428572,
      "grad_norm": 0.12512996792793274,
      "learning_rate": 9.737142857142858e-06,
      "loss": 0.0003,
      "step": 8980
    },
    {
      "epoch": 5.137142857142857,
      "grad_norm": 0.050185587257146835,
      "learning_rate": 9.725714285714287e-06,
      "loss": 0.0005,
      "step": 8990
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.022485719993710518,
      "learning_rate": 9.714285714285715e-06,
      "loss": 0.0161,
      "step": 9000
    },
    {
      "epoch": 5.148571428571429,
      "grad_norm": 0.008455118164420128,
      "learning_rate": 9.702857142857144e-06,
      "loss": 0.0173,
      "step": 9010
    },
    {
      "epoch": 5.154285714285714,
      "grad_norm": 0.0012283546384423971,
      "learning_rate": 9.691428571428572e-06,
      "loss": 0.0495,
      "step": 9020
    },
    {
      "epoch": 5.16,
      "grad_norm": 6.760712146759033,
      "learning_rate": 9.68e-06,
      "loss": 0.0451,
      "step": 9030
    },
    {
      "epoch": 5.1657142857142855,
      "grad_norm": 0.04581557586789131,
      "learning_rate": 9.668571428571429e-06,
      "loss": 0.0236,
      "step": 9040
    },
    {
      "epoch": 5.171428571428572,
      "grad_norm": 0.0002153115055989474,
      "learning_rate": 9.657142857142859e-06,
      "loss": 0.0151,
      "step": 9050
    },
    {
      "epoch": 5.177142857142857,
      "grad_norm": 0.03190170228481293,
      "learning_rate": 9.645714285714286e-06,
      "loss": 0.0203,
      "step": 9060
    },
    {
      "epoch": 5.182857142857143,
      "grad_norm": 0.0024165604263544083,
      "learning_rate": 9.634285714285714e-06,
      "loss": 0.0115,
      "step": 9070
    },
    {
      "epoch": 5.188571428571429,
      "grad_norm": 0.025361832231283188,
      "learning_rate": 9.622857142857144e-06,
      "loss": 0.0064,
      "step": 9080
    },
    {
      "epoch": 5.194285714285714,
      "grad_norm": 0.007503215689212084,
      "learning_rate": 9.611428571428573e-06,
      "loss": 0.0556,
      "step": 9090
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.0066377283073961735,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0029,
      "step": 9100
    },
    {
      "epoch": 5.2057142857142855,
      "grad_norm": 0.01386833842843771,
      "learning_rate": 9.58857142857143e-06,
      "loss": 0.0377,
      "step": 9110
    },
    {
      "epoch": 5.211428571428572,
      "grad_norm": 0.04898276925086975,
      "learning_rate": 9.577142857142858e-06,
      "loss": 0.0242,
      "step": 9120
    },
    {
      "epoch": 5.217142857142857,
      "grad_norm": 0.01957572065293789,
      "learning_rate": 9.565714285714287e-06,
      "loss": 0.0005,
      "step": 9130
    },
    {
      "epoch": 5.222857142857142,
      "grad_norm": 0.03102223202586174,
      "learning_rate": 9.554285714285715e-06,
      "loss": 0.0753,
      "step": 9140
    },
    {
      "epoch": 5.228571428571429,
      "grad_norm": 0.001530924579128623,
      "learning_rate": 9.542857142857143e-06,
      "loss": 0.051,
      "step": 9150
    },
    {
      "epoch": 5.234285714285714,
      "grad_norm": 1.7744975090026855,
      "learning_rate": 9.531428571428572e-06,
      "loss": 0.0055,
      "step": 9160
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.2104140669107437,
      "learning_rate": 9.52e-06,
      "loss": 0.0014,
      "step": 9170
    },
    {
      "epoch": 5.2457142857142856,
      "grad_norm": 0.05515876039862633,
      "learning_rate": 9.508571428571429e-06,
      "loss": 0.0171,
      "step": 9180
    },
    {
      "epoch": 5.251428571428572,
      "grad_norm": 0.025338446721434593,
      "learning_rate": 9.497142857142859e-06,
      "loss": 0.0012,
      "step": 9190
    },
    {
      "epoch": 5.257142857142857,
      "grad_norm": 0.0009601109777577221,
      "learning_rate": 9.485714285714287e-06,
      "loss": 0.032,
      "step": 9200
    },
    {
      "epoch": 5.2628571428571425,
      "grad_norm": 0.014656014740467072,
      "learning_rate": 9.474285714285714e-06,
      "loss": 0.0299,
      "step": 9210
    },
    {
      "epoch": 5.268571428571429,
      "grad_norm": 0.4583283066749573,
      "learning_rate": 9.462857142857144e-06,
      "loss": 0.0136,
      "step": 9220
    },
    {
      "epoch": 5.274285714285714,
      "grad_norm": 5.449659824371338,
      "learning_rate": 9.451428571428573e-06,
      "loss": 0.0438,
      "step": 9230
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.0020947307348251343,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.0004,
      "step": 9240
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 0.0008162433514371514,
      "learning_rate": 9.42857142857143e-06,
      "loss": 0.0128,
      "step": 9250
    },
    {
      "epoch": 5.291428571428572,
      "grad_norm": 0.0021904739551246166,
      "learning_rate": 9.417142857142858e-06,
      "loss": 0.0012,
      "step": 9260
    },
    {
      "epoch": 5.297142857142857,
      "grad_norm": 0.04238300025463104,
      "learning_rate": 9.405714285714286e-06,
      "loss": 0.0126,
      "step": 9270
    },
    {
      "epoch": 5.3028571428571425,
      "grad_norm": 0.0015361262485384941,
      "learning_rate": 9.394285714285715e-06,
      "loss": 0.0078,
      "step": 9280
    },
    {
      "epoch": 5.308571428571429,
      "grad_norm": 0.341336190700531,
      "learning_rate": 9.382857142857143e-06,
      "loss": 0.0235,
      "step": 9290
    },
    {
      "epoch": 5.314285714285714,
      "grad_norm": 0.0030784280970692635,
      "learning_rate": 9.371428571428572e-06,
      "loss": 0.0034,
      "step": 9300
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.014858354814350605,
      "learning_rate": 9.360000000000002e-06,
      "loss": 0.0011,
      "step": 9310
    },
    {
      "epoch": 5.325714285714286,
      "grad_norm": 0.001317288028076291,
      "learning_rate": 9.348571428571429e-06,
      "loss": 0.081,
      "step": 9320
    },
    {
      "epoch": 5.331428571428571,
      "grad_norm": 0.0005470067262649536,
      "learning_rate": 9.337142857142859e-06,
      "loss": 0.014,
      "step": 9330
    },
    {
      "epoch": 5.337142857142857,
      "grad_norm": 8.733745574951172,
      "learning_rate": 9.325714285714287e-06,
      "loss": 0.0461,
      "step": 9340
    },
    {
      "epoch": 5.3428571428571425,
      "grad_norm": 0.6012207269668579,
      "learning_rate": 9.314285714285714e-06,
      "loss": 0.0673,
      "step": 9350
    },
    {
      "epoch": 5.348571428571429,
      "grad_norm": 0.0013483273796737194,
      "learning_rate": 9.302857142857144e-06,
      "loss": 0.0033,
      "step": 9360
    },
    {
      "epoch": 5.354285714285714,
      "grad_norm": 0.005872806068509817,
      "learning_rate": 9.291428571428572e-06,
      "loss": 0.0554,
      "step": 9370
    },
    {
      "epoch": 5.36,
      "grad_norm": 6.209837436676025,
      "learning_rate": 9.280000000000001e-06,
      "loss": 0.0126,
      "step": 9380
    },
    {
      "epoch": 5.365714285714286,
      "grad_norm": 7.830411434173584,
      "learning_rate": 9.26857142857143e-06,
      "loss": 0.0394,
      "step": 9390
    },
    {
      "epoch": 5.371428571428572,
      "grad_norm": 0.001531468122266233,
      "learning_rate": 9.257142857142858e-06,
      "loss": 0.0297,
      "step": 9400
    },
    {
      "epoch": 5.377142857142857,
      "grad_norm": 29.66012191772461,
      "learning_rate": 9.245714285714286e-06,
      "loss": 0.1138,
      "step": 9410
    },
    {
      "epoch": 5.382857142857143,
      "grad_norm": 1.5098530054092407,
      "learning_rate": 9.234285714285715e-06,
      "loss": 0.0551,
      "step": 9420
    },
    {
      "epoch": 5.388571428571429,
      "grad_norm": 5.996950149536133,
      "learning_rate": 9.222857142857143e-06,
      "loss": 0.0606,
      "step": 9430
    },
    {
      "epoch": 5.394285714285714,
      "grad_norm": 0.0034392361994832754,
      "learning_rate": 9.211428571428572e-06,
      "loss": 0.0004,
      "step": 9440
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.0019396936986595392,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0191,
      "step": 9450
    },
    {
      "epoch": 5.405714285714286,
      "grad_norm": 0.0008580783614888787,
      "learning_rate": 9.188571428571428e-06,
      "loss": 0.0491,
      "step": 9460
    },
    {
      "epoch": 5.411428571428571,
      "grad_norm": 0.0023166206665337086,
      "learning_rate": 9.177142857142859e-06,
      "loss": 0.0172,
      "step": 9470
    },
    {
      "epoch": 5.417142857142857,
      "grad_norm": 0.0021006804890930653,
      "learning_rate": 9.165714285714287e-06,
      "loss": 0.0002,
      "step": 9480
    },
    {
      "epoch": 5.422857142857143,
      "grad_norm": 0.01969803310930729,
      "learning_rate": 9.154285714285715e-06,
      "loss": 0.0291,
      "step": 9490
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 0.006424316670745611,
      "learning_rate": 9.142857142857144e-06,
      "loss": 0.0003,
      "step": 9500
    },
    {
      "epoch": 5.434285714285714,
      "grad_norm": 0.05716030299663544,
      "learning_rate": 9.131428571428572e-06,
      "loss": 0.0009,
      "step": 9510
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.0017262361943721771,
      "learning_rate": 9.12e-06,
      "loss": 0.0085,
      "step": 9520
    },
    {
      "epoch": 5.445714285714286,
      "grad_norm": 0.05136106535792351,
      "learning_rate": 9.10857142857143e-06,
      "loss": 0.0519,
      "step": 9530
    },
    {
      "epoch": 5.451428571428571,
      "grad_norm": 0.055509209632873535,
      "learning_rate": 9.097142857142858e-06,
      "loss": 0.0428,
      "step": 9540
    },
    {
      "epoch": 5.457142857142857,
      "grad_norm": 0.01886584237217903,
      "learning_rate": 9.085714285714286e-06,
      "loss": 0.0416,
      "step": 9550
    },
    {
      "epoch": 5.462857142857143,
      "grad_norm": 0.014736341312527657,
      "learning_rate": 9.074285714285716e-06,
      "loss": 0.0188,
      "step": 9560
    },
    {
      "epoch": 5.468571428571429,
      "grad_norm": 0.023500680923461914,
      "learning_rate": 9.062857142857143e-06,
      "loss": 0.0204,
      "step": 9570
    },
    {
      "epoch": 5.474285714285714,
      "grad_norm": 0.012533496133983135,
      "learning_rate": 9.051428571428571e-06,
      "loss": 0.0579,
      "step": 9580
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.2306946963071823,
      "learning_rate": 9.040000000000002e-06,
      "loss": 0.0342,
      "step": 9590
    },
    {
      "epoch": 5.485714285714286,
      "grad_norm": 0.012224545702338219,
      "learning_rate": 9.028571428571428e-06,
      "loss": 0.0386,
      "step": 9600
    },
    {
      "epoch": 5.491428571428571,
      "grad_norm": 0.2186831831932068,
      "learning_rate": 9.017142857142858e-06,
      "loss": 0.0463,
      "step": 9610
    },
    {
      "epoch": 5.497142857142857,
      "grad_norm": 4.258452415466309,
      "learning_rate": 9.005714285714287e-06,
      "loss": 0.1082,
      "step": 9620
    },
    {
      "epoch": 5.502857142857143,
      "grad_norm": 0.4579993188381195,
      "learning_rate": 8.994285714285715e-06,
      "loss": 0.0046,
      "step": 9630
    },
    {
      "epoch": 5.508571428571429,
      "grad_norm": 0.01577836088836193,
      "learning_rate": 8.982857142857144e-06,
      "loss": 0.0033,
      "step": 9640
    },
    {
      "epoch": 5.514285714285714,
      "grad_norm": 6.178711891174316,
      "learning_rate": 8.971428571428572e-06,
      "loss": 0.0564,
      "step": 9650
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.07408637553453445,
      "learning_rate": 8.96e-06,
      "loss": 0.0366,
      "step": 9660
    },
    {
      "epoch": 5.525714285714286,
      "grad_norm": 0.0070743984542787075,
      "learning_rate": 8.948571428571429e-06,
      "loss": 0.0187,
      "step": 9670
    },
    {
      "epoch": 5.531428571428571,
      "grad_norm": 0.0034822861198335886,
      "learning_rate": 8.937142857142857e-06,
      "loss": 0.0206,
      "step": 9680
    },
    {
      "epoch": 5.537142857142857,
      "grad_norm": 0.009416041895747185,
      "learning_rate": 8.925714285714286e-06,
      "loss": 0.0133,
      "step": 9690
    },
    {
      "epoch": 5.542857142857143,
      "grad_norm": 0.009515635669231415,
      "learning_rate": 8.914285714285716e-06,
      "loss": 0.0105,
      "step": 9700
    },
    {
      "epoch": 5.548571428571429,
      "grad_norm": 35.2880859375,
      "learning_rate": 8.902857142857143e-06,
      "loss": 0.1057,
      "step": 9710
    },
    {
      "epoch": 5.554285714285714,
      "grad_norm": 0.04820135235786438,
      "learning_rate": 8.891428571428571e-06,
      "loss": 0.0033,
      "step": 9720
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 43.28849792480469,
      "learning_rate": 8.880000000000001e-06,
      "loss": 0.0546,
      "step": 9730
    },
    {
      "epoch": 5.565714285714286,
      "grad_norm": 0.3501712679862976,
      "learning_rate": 8.86857142857143e-06,
      "loss": 0.0066,
      "step": 9740
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 6.569375514984131,
      "learning_rate": 8.857142857142858e-06,
      "loss": 0.0255,
      "step": 9750
    },
    {
      "epoch": 5.577142857142857,
      "grad_norm": 0.0051084477454423904,
      "learning_rate": 8.845714285714287e-06,
      "loss": 0.0003,
      "step": 9760
    },
    {
      "epoch": 5.582857142857143,
      "grad_norm": 0.01180934440344572,
      "learning_rate": 8.834285714285715e-06,
      "loss": 0.0229,
      "step": 9770
    },
    {
      "epoch": 5.588571428571429,
      "grad_norm": 0.004837643820792437,
      "learning_rate": 8.822857142857144e-06,
      "loss": 0.0015,
      "step": 9780
    },
    {
      "epoch": 5.594285714285714,
      "grad_norm": 0.041212014853954315,
      "learning_rate": 8.811428571428572e-06,
      "loss": 0.0377,
      "step": 9790
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.0370038747787476,
      "learning_rate": 8.8e-06,
      "loss": 0.0378,
      "step": 9800
    },
    {
      "epoch": 5.605714285714286,
      "grad_norm": 0.04786901921033859,
      "learning_rate": 8.788571428571429e-06,
      "loss": 0.0984,
      "step": 9810
    },
    {
      "epoch": 5.611428571428571,
      "grad_norm": 0.36702796816825867,
      "learning_rate": 8.777142857142857e-06,
      "loss": 0.0008,
      "step": 9820
    },
    {
      "epoch": 5.617142857142857,
      "grad_norm": 0.01592293381690979,
      "learning_rate": 8.765714285714286e-06,
      "loss": 0.0004,
      "step": 9830
    },
    {
      "epoch": 5.622857142857143,
      "grad_norm": 0.0524933747947216,
      "learning_rate": 8.754285714285716e-06,
      "loss": 0.0389,
      "step": 9840
    },
    {
      "epoch": 5.628571428571428,
      "grad_norm": 0.0042813848704099655,
      "learning_rate": 8.742857142857144e-06,
      "loss": 0.0551,
      "step": 9850
    },
    {
      "epoch": 5.634285714285714,
      "grad_norm": 0.00767223397269845,
      "learning_rate": 8.731428571428571e-06,
      "loss": 0.0048,
      "step": 9860
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.022619541734457016,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.0002,
      "step": 9870
    },
    {
      "epoch": 5.645714285714286,
      "grad_norm": 2.3690385818481445,
      "learning_rate": 8.70857142857143e-06,
      "loss": 0.023,
      "step": 9880
    },
    {
      "epoch": 5.651428571428571,
      "grad_norm": 0.0057409158907830715,
      "learning_rate": 8.697142857142858e-06,
      "loss": 0.0015,
      "step": 9890
    },
    {
      "epoch": 5.6571428571428575,
      "grad_norm": 0.013420320115983486,
      "learning_rate": 8.685714285714287e-06,
      "loss": 0.0038,
      "step": 9900
    },
    {
      "epoch": 5.662857142857143,
      "grad_norm": 42.082794189453125,
      "learning_rate": 8.674285714285715e-06,
      "loss": 0.0234,
      "step": 9910
    },
    {
      "epoch": 5.668571428571429,
      "grad_norm": 0.026824111118912697,
      "learning_rate": 8.662857142857143e-06,
      "loss": 0.1558,
      "step": 9920
    },
    {
      "epoch": 5.674285714285714,
      "grad_norm": 0.16090494394302368,
      "learning_rate": 8.651428571428572e-06,
      "loss": 0.0129,
      "step": 9930
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.010933627374470234,
      "learning_rate": 8.64e-06,
      "loss": 0.0782,
      "step": 9940
    },
    {
      "epoch": 5.685714285714286,
      "grad_norm": 0.0055786678567528725,
      "learning_rate": 8.628571428571429e-06,
      "loss": 0.0172,
      "step": 9950
    },
    {
      "epoch": 5.691428571428571,
      "grad_norm": 4.931252956390381,
      "learning_rate": 8.617142857142859e-06,
      "loss": 0.0105,
      "step": 9960
    },
    {
      "epoch": 5.6971428571428575,
      "grad_norm": 4.480772972106934,
      "learning_rate": 8.605714285714286e-06,
      "loss": 0.0694,
      "step": 9970
    },
    {
      "epoch": 5.702857142857143,
      "grad_norm": 0.4874449074268341,
      "learning_rate": 8.594285714285716e-06,
      "loss": 0.0552,
      "step": 9980
    },
    {
      "epoch": 5.708571428571428,
      "grad_norm": 0.008030226454138756,
      "learning_rate": 8.582857142857144e-06,
      "loss": 0.0379,
      "step": 9990
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.0027802439872175455,
      "learning_rate": 8.571428571428571e-06,
      "loss": 0.0662,
      "step": 10000
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.03951740637421608,
      "learning_rate": 8.560000000000001e-06,
      "loss": 0.0015,
      "step": 10010
    },
    {
      "epoch": 5.725714285714286,
      "grad_norm": 18.325794219970703,
      "learning_rate": 8.54857142857143e-06,
      "loss": 0.0493,
      "step": 10020
    },
    {
      "epoch": 5.731428571428571,
      "grad_norm": 0.016033081337809563,
      "learning_rate": 8.537142857142858e-06,
      "loss": 0.0397,
      "step": 10030
    },
    {
      "epoch": 5.737142857142857,
      "grad_norm": 4.1525139808654785,
      "learning_rate": 8.525714285714286e-06,
      "loss": 0.0707,
      "step": 10040
    },
    {
      "epoch": 5.742857142857143,
      "grad_norm": 0.5571603178977966,
      "learning_rate": 8.514285714285715e-06,
      "loss": 0.1101,
      "step": 10050
    },
    {
      "epoch": 5.748571428571428,
      "grad_norm": 0.6580905914306641,
      "learning_rate": 8.502857142857143e-06,
      "loss": 0.0015,
      "step": 10060
    },
    {
      "epoch": 5.7542857142857144,
      "grad_norm": 0.014395377598702908,
      "learning_rate": 8.491428571428572e-06,
      "loss": 0.0235,
      "step": 10070
    },
    {
      "epoch": 5.76,
      "grad_norm": 6.272642612457275,
      "learning_rate": 8.48e-06,
      "loss": 0.023,
      "step": 10080
    },
    {
      "epoch": 5.765714285714286,
      "grad_norm": 0.022735675796866417,
      "learning_rate": 8.468571428571429e-06,
      "loss": 0.1087,
      "step": 10090
    },
    {
      "epoch": 5.771428571428571,
      "grad_norm": 0.07339534163475037,
      "learning_rate": 8.457142857142859e-06,
      "loss": 0.0378,
      "step": 10100
    },
    {
      "epoch": 5.777142857142858,
      "grad_norm": 0.0065926178358495235,
      "learning_rate": 8.445714285714285e-06,
      "loss": 0.0302,
      "step": 10110
    },
    {
      "epoch": 5.782857142857143,
      "grad_norm": 0.027920469641685486,
      "learning_rate": 8.434285714285716e-06,
      "loss": 0.0032,
      "step": 10120
    },
    {
      "epoch": 5.788571428571428,
      "grad_norm": 0.0035009647253900766,
      "learning_rate": 8.422857142857144e-06,
      "loss": 0.0611,
      "step": 10130
    },
    {
      "epoch": 5.7942857142857145,
      "grad_norm": 0.0029888469725847244,
      "learning_rate": 8.411428571428572e-06,
      "loss": 0.0216,
      "step": 10140
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.0020072709303349257,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.1164,
      "step": 10150
    },
    {
      "epoch": 5.805714285714286,
      "grad_norm": 0.009753909893333912,
      "learning_rate": 8.38857142857143e-06,
      "loss": 0.0394,
      "step": 10160
    },
    {
      "epoch": 5.811428571428571,
      "grad_norm": 0.14423635601997375,
      "learning_rate": 8.377142857142858e-06,
      "loss": 0.0073,
      "step": 10170
    },
    {
      "epoch": 5.817142857142857,
      "grad_norm": 0.019924389198422432,
      "learning_rate": 8.365714285714286e-06,
      "loss": 0.0034,
      "step": 10180
    },
    {
      "epoch": 5.822857142857143,
      "grad_norm": 20.631338119506836,
      "learning_rate": 8.354285714285715e-06,
      "loss": 0.1027,
      "step": 10190
    },
    {
      "epoch": 5.828571428571428,
      "grad_norm": 0.002297033090144396,
      "learning_rate": 8.342857142857143e-06,
      "loss": 0.0543,
      "step": 10200
    },
    {
      "epoch": 5.8342857142857145,
      "grad_norm": 2.5633440017700195,
      "learning_rate": 8.331428571428573e-06,
      "loss": 0.0764,
      "step": 10210
    },
    {
      "epoch": 5.84,
      "grad_norm": 8.779040336608887,
      "learning_rate": 8.32e-06,
      "loss": 0.0559,
      "step": 10220
    },
    {
      "epoch": 5.845714285714286,
      "grad_norm": 9.797771453857422,
      "learning_rate": 8.308571428571428e-06,
      "loss": 0.0546,
      "step": 10230
    },
    {
      "epoch": 5.851428571428571,
      "grad_norm": 12.460640907287598,
      "learning_rate": 8.297142857142859e-06,
      "loss": 0.0061,
      "step": 10240
    },
    {
      "epoch": 5.857142857142857,
      "grad_norm": 0.028738409280776978,
      "learning_rate": 8.285714285714287e-06,
      "loss": 0.0569,
      "step": 10250
    },
    {
      "epoch": 5.862857142857143,
      "grad_norm": 0.002738568466156721,
      "learning_rate": 8.274285714285715e-06,
      "loss": 0.0278,
      "step": 10260
    },
    {
      "epoch": 5.868571428571428,
      "grad_norm": 4.297938346862793,
      "learning_rate": 8.262857142857144e-06,
      "loss": 0.0531,
      "step": 10270
    },
    {
      "epoch": 5.8742857142857146,
      "grad_norm": 0.011778241954743862,
      "learning_rate": 8.251428571428572e-06,
      "loss": 0.049,
      "step": 10280
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.0050896527245640755,
      "learning_rate": 8.24e-06,
      "loss": 0.0196,
      "step": 10290
    },
    {
      "epoch": 5.885714285714286,
      "grad_norm": 0.0017243119655176997,
      "learning_rate": 8.22857142857143e-06,
      "loss": 0.0433,
      "step": 10300
    },
    {
      "epoch": 5.8914285714285715,
      "grad_norm": 0.03889438137412071,
      "learning_rate": 8.217142857142858e-06,
      "loss": 0.0184,
      "step": 10310
    },
    {
      "epoch": 5.897142857142857,
      "grad_norm": 0.21331296861171722,
      "learning_rate": 8.205714285714286e-06,
      "loss": 0.0435,
      "step": 10320
    },
    {
      "epoch": 5.902857142857143,
      "grad_norm": 0.89883953332901,
      "learning_rate": 8.194285714285714e-06,
      "loss": 0.0399,
      "step": 10330
    },
    {
      "epoch": 5.908571428571428,
      "grad_norm": 0.0716506615281105,
      "learning_rate": 8.182857142857143e-06,
      "loss": 0.0195,
      "step": 10340
    },
    {
      "epoch": 5.914285714285715,
      "grad_norm": 22.608110427856445,
      "learning_rate": 8.171428571428573e-06,
      "loss": 0.0359,
      "step": 10350
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.29294782876968384,
      "learning_rate": 8.16e-06,
      "loss": 0.0031,
      "step": 10360
    },
    {
      "epoch": 5.925714285714285,
      "grad_norm": 0.0010079509811475873,
      "learning_rate": 8.148571428571428e-06,
      "loss": 0.003,
      "step": 10370
    },
    {
      "epoch": 5.9314285714285715,
      "grad_norm": 2.155557155609131,
      "learning_rate": 8.137142857142858e-06,
      "loss": 0.0706,
      "step": 10380
    },
    {
      "epoch": 5.937142857142857,
      "grad_norm": 0.004680951591581106,
      "learning_rate": 8.125714285714287e-06,
      "loss": 0.0002,
      "step": 10390
    },
    {
      "epoch": 5.942857142857143,
      "grad_norm": 0.0025144207756966352,
      "learning_rate": 8.114285714285715e-06,
      "loss": 0.0115,
      "step": 10400
    },
    {
      "epoch": 5.948571428571428,
      "grad_norm": 0.0026043085381388664,
      "learning_rate": 8.102857142857144e-06,
      "loss": 0.0538,
      "step": 10410
    },
    {
      "epoch": 5.954285714285715,
      "grad_norm": 0.013584070838987827,
      "learning_rate": 8.091428571428572e-06,
      "loss": 0.0005,
      "step": 10420
    },
    {
      "epoch": 5.96,
      "grad_norm": 1.2848129272460938,
      "learning_rate": 8.08e-06,
      "loss": 0.0386,
      "step": 10430
    },
    {
      "epoch": 5.965714285714286,
      "grad_norm": 12.269299507141113,
      "learning_rate": 8.068571428571429e-06,
      "loss": 0.0708,
      "step": 10440
    },
    {
      "epoch": 5.9714285714285715,
      "grad_norm": 0.005818508565425873,
      "learning_rate": 8.057142857142857e-06,
      "loss": 0.0435,
      "step": 10450
    },
    {
      "epoch": 5.977142857142857,
      "grad_norm": 0.03663729131221771,
      "learning_rate": 8.045714285714286e-06,
      "loss": 0.1055,
      "step": 10460
    },
    {
      "epoch": 5.982857142857143,
      "grad_norm": 0.023535432294011116,
      "learning_rate": 8.034285714285714e-06,
      "loss": 0.0531,
      "step": 10470
    },
    {
      "epoch": 5.988571428571428,
      "grad_norm": 10.071290016174316,
      "learning_rate": 8.022857142857143e-06,
      "loss": 0.0324,
      "step": 10480
    },
    {
      "epoch": 5.994285714285715,
      "grad_norm": 0.006013540551066399,
      "learning_rate": 8.011428571428573e-06,
      "loss": 0.0408,
      "step": 10490
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.007586285471916199,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0196,
      "step": 10500
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9804478609625669,
      "eval_f1": 0.9267376330619913,
      "eval_loss": 0.08074024319648743,
      "eval_precision": 0.9203980099502488,
      "eval_recall": 0.9331651954602774,
      "eval_runtime": 53.9152,
      "eval_samples_per_second": 111.286,
      "eval_steps_per_second": 3.487,
      "step": 10500
    },
    {
      "epoch": 6.005714285714285,
      "grad_norm": 0.018752198666334152,
      "learning_rate": 7.988571428571428e-06,
      "loss": 0.02,
      "step": 10510
    },
    {
      "epoch": 6.011428571428572,
      "grad_norm": 0.031315580010414124,
      "learning_rate": 7.977142857142858e-06,
      "loss": 0.0198,
      "step": 10520
    },
    {
      "epoch": 6.017142857142857,
      "grad_norm": 0.057181015610694885,
      "learning_rate": 7.965714285714287e-06,
      "loss": 0.061,
      "step": 10530
    },
    {
      "epoch": 6.022857142857143,
      "grad_norm": 0.013234345242381096,
      "learning_rate": 7.954285714285715e-06,
      "loss": 0.0018,
      "step": 10540
    },
    {
      "epoch": 6.0285714285714285,
      "grad_norm": 0.011606978252530098,
      "learning_rate": 7.942857142857144e-06,
      "loss": 0.0939,
      "step": 10550
    },
    {
      "epoch": 6.034285714285715,
      "grad_norm": 0.016889864578843117,
      "learning_rate": 7.931428571428572e-06,
      "loss": 0.0071,
      "step": 10560
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.036159515380859375,
      "learning_rate": 7.92e-06,
      "loss": 0.0591,
      "step": 10570
    },
    {
      "epoch": 6.045714285714285,
      "grad_norm": 4.876478672027588,
      "learning_rate": 7.908571428571429e-06,
      "loss": 0.0492,
      "step": 10580
    },
    {
      "epoch": 6.051428571428572,
      "grad_norm": 0.025111492723226547,
      "learning_rate": 7.897142857142857e-06,
      "loss": 0.0003,
      "step": 10590
    },
    {
      "epoch": 6.057142857142857,
      "grad_norm": 0.014099908992648125,
      "learning_rate": 7.885714285714286e-06,
      "loss": 0.0005,
      "step": 10600
    },
    {
      "epoch": 6.062857142857143,
      "grad_norm": 0.013280953280627728,
      "learning_rate": 7.874285714285716e-06,
      "loss": 0.0758,
      "step": 10610
    },
    {
      "epoch": 6.0685714285714285,
      "grad_norm": 0.017391176894307137,
      "learning_rate": 7.862857142857143e-06,
      "loss": 0.0211,
      "step": 10620
    },
    {
      "epoch": 6.074285714285715,
      "grad_norm": 0.0035639945417642593,
      "learning_rate": 7.851428571428573e-06,
      "loss": 0.0431,
      "step": 10630
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.006857757456600666,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.0197,
      "step": 10640
    },
    {
      "epoch": 6.085714285714285,
      "grad_norm": 0.004203741438686848,
      "learning_rate": 7.828571428571428e-06,
      "loss": 0.0294,
      "step": 10650
    },
    {
      "epoch": 6.091428571428572,
      "grad_norm": 0.06095278263092041,
      "learning_rate": 7.817142857142858e-06,
      "loss": 0.0009,
      "step": 10660
    },
    {
      "epoch": 6.097142857142857,
      "grad_norm": 0.10492713004350662,
      "learning_rate": 7.805714285714286e-06,
      "loss": 0.0007,
      "step": 10670
    },
    {
      "epoch": 6.102857142857143,
      "grad_norm": 0.002533180173486471,
      "learning_rate": 7.794285714285715e-06,
      "loss": 0.0004,
      "step": 10680
    },
    {
      "epoch": 6.1085714285714285,
      "grad_norm": 0.06579158455133438,
      "learning_rate": 7.782857142857143e-06,
      "loss": 0.0172,
      "step": 10690
    },
    {
      "epoch": 6.114285714285714,
      "grad_norm": 0.009754386730492115,
      "learning_rate": 7.771428571428572e-06,
      "loss": 0.0274,
      "step": 10700
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.013575725257396698,
      "learning_rate": 7.76e-06,
      "loss": 0.0286,
      "step": 10710
    },
    {
      "epoch": 6.1257142857142854,
      "grad_norm": 0.041397158056497574,
      "learning_rate": 7.74857142857143e-06,
      "loss": 0.0016,
      "step": 10720
    },
    {
      "epoch": 6.131428571428572,
      "grad_norm": 0.14921970665454865,
      "learning_rate": 7.737142857142857e-06,
      "loss": 0.0008,
      "step": 10730
    },
    {
      "epoch": 6.137142857142857,
      "grad_norm": 0.0893096923828125,
      "learning_rate": 7.725714285714286e-06,
      "loss": 0.0219,
      "step": 10740
    },
    {
      "epoch": 6.142857142857143,
      "grad_norm": 0.07462533563375473,
      "learning_rate": 7.714285714285716e-06,
      "loss": 0.0355,
      "step": 10750
    },
    {
      "epoch": 6.148571428571429,
      "grad_norm": 0.021997597068548203,
      "learning_rate": 7.702857142857142e-06,
      "loss": 0.0167,
      "step": 10760
    },
    {
      "epoch": 6.154285714285714,
      "grad_norm": 0.000986397615633905,
      "learning_rate": 7.691428571428573e-06,
      "loss": 0.0084,
      "step": 10770
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.013860347680747509,
      "learning_rate": 7.680000000000001e-06,
      "loss": 0.0159,
      "step": 10780
    },
    {
      "epoch": 6.1657142857142855,
      "grad_norm": 0.0007202861015684903,
      "learning_rate": 7.66857142857143e-06,
      "loss": 0.0002,
      "step": 10790
    },
    {
      "epoch": 6.171428571428572,
      "grad_norm": 0.0010059162741526961,
      "learning_rate": 7.657142857142858e-06,
      "loss": 0.0539,
      "step": 10800
    },
    {
      "epoch": 6.177142857142857,
      "grad_norm": 6.917919158935547,
      "learning_rate": 7.645714285714286e-06,
      "loss": 0.0376,
      "step": 10810
    },
    {
      "epoch": 6.182857142857143,
      "grad_norm": 0.0036991683300584555,
      "learning_rate": 7.634285714285715e-06,
      "loss": 0.0822,
      "step": 10820
    },
    {
      "epoch": 6.188571428571429,
      "grad_norm": 15.568516731262207,
      "learning_rate": 7.622857142857143e-06,
      "loss": 0.0563,
      "step": 10830
    },
    {
      "epoch": 6.194285714285714,
      "grad_norm": 0.0036972379311919212,
      "learning_rate": 7.611428571428572e-06,
      "loss": 0.0211,
      "step": 10840
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.011879203841090202,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0381,
      "step": 10850
    },
    {
      "epoch": 6.2057142857142855,
      "grad_norm": 0.041909947991371155,
      "learning_rate": 7.588571428571429e-06,
      "loss": 0.0663,
      "step": 10860
    },
    {
      "epoch": 6.211428571428572,
      "grad_norm": 0.0380636602640152,
      "learning_rate": 7.577142857142857e-06,
      "loss": 0.0224,
      "step": 10870
    },
    {
      "epoch": 6.217142857142857,
      "grad_norm": 0.020636744797229767,
      "learning_rate": 7.565714285714286e-06,
      "loss": 0.0513,
      "step": 10880
    },
    {
      "epoch": 6.222857142857142,
      "grad_norm": 0.03187635913491249,
      "learning_rate": 7.5542857142857155e-06,
      "loss": 0.0003,
      "step": 10890
    },
    {
      "epoch": 6.228571428571429,
      "grad_norm": 0.001951111014932394,
      "learning_rate": 7.542857142857144e-06,
      "loss": 0.0182,
      "step": 10900
    },
    {
      "epoch": 6.234285714285714,
      "grad_norm": 0.02702229470014572,
      "learning_rate": 7.5314285714285716e-06,
      "loss": 0.0068,
      "step": 10910
    },
    {
      "epoch": 6.24,
      "grad_norm": 26.62265968322754,
      "learning_rate": 7.520000000000001e-06,
      "loss": 0.0074,
      "step": 10920
    },
    {
      "epoch": 6.2457142857142856,
      "grad_norm": 0.004669873975217342,
      "learning_rate": 7.508571428571429e-06,
      "loss": 0.0535,
      "step": 10930
    },
    {
      "epoch": 6.251428571428572,
      "grad_norm": 0.05154329538345337,
      "learning_rate": 7.497142857142857e-06,
      "loss": 0.0214,
      "step": 10940
    },
    {
      "epoch": 6.257142857142857,
      "grad_norm": 0.36407989263534546,
      "learning_rate": 7.485714285714286e-06,
      "loss": 0.0008,
      "step": 10950
    },
    {
      "epoch": 6.2628571428571425,
      "grad_norm": 0.044965170323848724,
      "learning_rate": 7.4742857142857154e-06,
      "loss": 0.0004,
      "step": 10960
    },
    {
      "epoch": 6.268571428571429,
      "grad_norm": 0.005092949140816927,
      "learning_rate": 7.462857142857144e-06,
      "loss": 0.0164,
      "step": 10970
    },
    {
      "epoch": 6.274285714285714,
      "grad_norm": 0.026206186041235924,
      "learning_rate": 7.4514285714285715e-06,
      "loss": 0.002,
      "step": 10980
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.003713213838636875,
      "learning_rate": 7.440000000000001e-06,
      "loss": 0.0052,
      "step": 10990
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 0.0026842206716537476,
      "learning_rate": 7.428571428571429e-06,
      "loss": 0.0001,
      "step": 11000
    },
    {
      "epoch": 6.291428571428572,
      "grad_norm": 0.03937897831201553,
      "learning_rate": 7.417142857142857e-06,
      "loss": 0.0563,
      "step": 11010
    },
    {
      "epoch": 6.297142857142857,
      "grad_norm": 0.022488439455628395,
      "learning_rate": 7.405714285714286e-06,
      "loss": 0.0698,
      "step": 11020
    },
    {
      "epoch": 6.3028571428571425,
      "grad_norm": 0.12485901266336441,
      "learning_rate": 7.394285714285715e-06,
      "loss": 0.0694,
      "step": 11030
    },
    {
      "epoch": 6.308571428571429,
      "grad_norm": 0.012823965400457382,
      "learning_rate": 7.382857142857144e-06,
      "loss": 0.0004,
      "step": 11040
    },
    {
      "epoch": 6.314285714285714,
      "grad_norm": 0.018300160765647888,
      "learning_rate": 7.371428571428571e-06,
      "loss": 0.0018,
      "step": 11050
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.008437505923211575,
      "learning_rate": 7.360000000000001e-06,
      "loss": 0.017,
      "step": 11060
    },
    {
      "epoch": 6.325714285714286,
      "grad_norm": 0.5945309400558472,
      "learning_rate": 7.348571428571429e-06,
      "loss": 0.0507,
      "step": 11070
    },
    {
      "epoch": 6.331428571428571,
      "grad_norm": 1.3494123220443726,
      "learning_rate": 7.337142857142858e-06,
      "loss": 0.0363,
      "step": 11080
    },
    {
      "epoch": 6.337142857142857,
      "grad_norm": 3.0928757190704346,
      "learning_rate": 7.325714285714286e-06,
      "loss": 0.0667,
      "step": 11090
    },
    {
      "epoch": 6.3428571428571425,
      "grad_norm": 0.003163970774039626,
      "learning_rate": 7.314285714285715e-06,
      "loss": 0.0705,
      "step": 11100
    },
    {
      "epoch": 6.348571428571429,
      "grad_norm": 0.08959120512008667,
      "learning_rate": 7.302857142857144e-06,
      "loss": 0.0197,
      "step": 11110
    },
    {
      "epoch": 6.354285714285714,
      "grad_norm": 0.012612503953278065,
      "learning_rate": 7.291428571428571e-06,
      "loss": 0.0245,
      "step": 11120
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.00518631050363183,
      "learning_rate": 7.280000000000001e-06,
      "loss": 0.0115,
      "step": 11130
    },
    {
      "epoch": 6.365714285714286,
      "grad_norm": 0.005425332114100456,
      "learning_rate": 7.268571428571429e-06,
      "loss": 0.0288,
      "step": 11140
    },
    {
      "epoch": 6.371428571428572,
      "grad_norm": 0.7341980338096619,
      "learning_rate": 7.257142857142858e-06,
      "loss": 0.0371,
      "step": 11150
    },
    {
      "epoch": 6.377142857142857,
      "grad_norm": 0.028638988733291626,
      "learning_rate": 7.245714285714286e-06,
      "loss": 0.0376,
      "step": 11160
    },
    {
      "epoch": 6.382857142857143,
      "grad_norm": 0.0007261319551616907,
      "learning_rate": 7.234285714285715e-06,
      "loss": 0.0327,
      "step": 11170
    },
    {
      "epoch": 6.388571428571429,
      "grad_norm": 0.002570914337411523,
      "learning_rate": 7.222857142857144e-06,
      "loss": 0.0215,
      "step": 11180
    },
    {
      "epoch": 6.394285714285714,
      "grad_norm": 5.8682122230529785,
      "learning_rate": 7.211428571428573e-06,
      "loss": 0.0019,
      "step": 11190
    },
    {
      "epoch": 6.4,
      "grad_norm": 2.9826316833496094,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.0298,
      "step": 11200
    },
    {
      "epoch": 6.405714285714286,
      "grad_norm": 0.0011420586379244924,
      "learning_rate": 7.188571428571429e-06,
      "loss": 0.0448,
      "step": 11210
    },
    {
      "epoch": 6.411428571428571,
      "grad_norm": 8.295130729675293,
      "learning_rate": 7.177142857142858e-06,
      "loss": 0.0306,
      "step": 11220
    },
    {
      "epoch": 6.417142857142857,
      "grad_norm": 9.559252738952637,
      "learning_rate": 7.165714285714286e-06,
      "loss": 0.0278,
      "step": 11230
    },
    {
      "epoch": 6.422857142857143,
      "grad_norm": 10.91778564453125,
      "learning_rate": 7.154285714285715e-06,
      "loss": 0.0157,
      "step": 11240
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.0022331858053803444,
      "learning_rate": 7.1428571428571436e-06,
      "loss": 0.0008,
      "step": 11250
    },
    {
      "epoch": 6.434285714285714,
      "grad_norm": 18.40965461730957,
      "learning_rate": 7.131428571428573e-06,
      "loss": 0.0018,
      "step": 11260
    },
    {
      "epoch": 6.44,
      "grad_norm": 9.783485412597656,
      "learning_rate": 7.1200000000000004e-06,
      "loss": 0.0264,
      "step": 11270
    },
    {
      "epoch": 6.445714285714286,
      "grad_norm": 0.012860316783189774,
      "learning_rate": 7.108571428571429e-06,
      "loss": 0.0148,
      "step": 11280
    },
    {
      "epoch": 6.451428571428571,
      "grad_norm": 0.04264414310455322,
      "learning_rate": 7.097142857142858e-06,
      "loss": 0.0004,
      "step": 11290
    },
    {
      "epoch": 6.457142857142857,
      "grad_norm": 0.00154939666390419,
      "learning_rate": 7.085714285714286e-06,
      "loss": 0.0001,
      "step": 11300
    },
    {
      "epoch": 6.462857142857143,
      "grad_norm": 0.04128248244524002,
      "learning_rate": 7.074285714285715e-06,
      "loss": 0.0184,
      "step": 11310
    },
    {
      "epoch": 6.468571428571429,
      "grad_norm": 0.01072158943861723,
      "learning_rate": 7.0628571428571435e-06,
      "loss": 0.0018,
      "step": 11320
    },
    {
      "epoch": 6.474285714285714,
      "grad_norm": 0.001081621740013361,
      "learning_rate": 7.051428571428573e-06,
      "loss": 0.0239,
      "step": 11330
    },
    {
      "epoch": 6.48,
      "grad_norm": 8.841371536254883,
      "learning_rate": 7.04e-06,
      "loss": 0.0487,
      "step": 11340
    },
    {
      "epoch": 6.485714285714286,
      "grad_norm": 0.007794798817485571,
      "learning_rate": 7.028571428571429e-06,
      "loss": 0.0528,
      "step": 11350
    },
    {
      "epoch": 6.491428571428571,
      "grad_norm": 0.02434062957763672,
      "learning_rate": 7.017142857142858e-06,
      "loss": 0.0561,
      "step": 11360
    },
    {
      "epoch": 6.497142857142857,
      "grad_norm": 0.009383752942085266,
      "learning_rate": 7.0057142857142865e-06,
      "loss": 0.0048,
      "step": 11370
    },
    {
      "epoch": 6.502857142857143,
      "grad_norm": 0.004310464486479759,
      "learning_rate": 6.994285714285715e-06,
      "loss": 0.0994,
      "step": 11380
    },
    {
      "epoch": 6.508571428571429,
      "grad_norm": 11.032529830932617,
      "learning_rate": 6.982857142857143e-06,
      "loss": 0.0093,
      "step": 11390
    },
    {
      "epoch": 6.514285714285714,
      "grad_norm": 13.973828315734863,
      "learning_rate": 6.971428571428573e-06,
      "loss": 0.0131,
      "step": 11400
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.020786330103874207,
      "learning_rate": 6.96e-06,
      "loss": 0.0156,
      "step": 11410
    },
    {
      "epoch": 6.525714285714286,
      "grad_norm": 0.38179269433021545,
      "learning_rate": 6.948571428571429e-06,
      "loss": 0.0679,
      "step": 11420
    },
    {
      "epoch": 6.531428571428571,
      "grad_norm": 3.348360538482666,
      "learning_rate": 6.937142857142858e-06,
      "loss": 0.0107,
      "step": 11430
    },
    {
      "epoch": 6.537142857142857,
      "grad_norm": 1.0867114067077637,
      "learning_rate": 6.9257142857142864e-06,
      "loss": 0.0583,
      "step": 11440
    },
    {
      "epoch": 6.542857142857143,
      "grad_norm": 0.001381761278025806,
      "learning_rate": 6.914285714285715e-06,
      "loss": 0.036,
      "step": 11450
    },
    {
      "epoch": 6.548571428571429,
      "grad_norm": 0.015190617181360722,
      "learning_rate": 6.902857142857143e-06,
      "loss": 0.0089,
      "step": 11460
    },
    {
      "epoch": 6.554285714285714,
      "grad_norm": 0.006701426114886999,
      "learning_rate": 6.891428571428573e-06,
      "loss": 0.0114,
      "step": 11470
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.8204368352890015,
      "learning_rate": 6.88e-06,
      "loss": 0.009,
      "step": 11480
    },
    {
      "epoch": 6.565714285714286,
      "grad_norm": 0.0008065358269959688,
      "learning_rate": 6.868571428571429e-06,
      "loss": 0.0006,
      "step": 11490
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.5859500169754028,
      "learning_rate": 6.857142857142858e-06,
      "loss": 0.0325,
      "step": 11500
    },
    {
      "epoch": 6.577142857142857,
      "grad_norm": 6.49266242980957,
      "learning_rate": 6.845714285714286e-06,
      "loss": 0.0556,
      "step": 11510
    },
    {
      "epoch": 6.582857142857143,
      "grad_norm": 40.08197021484375,
      "learning_rate": 6.834285714285715e-06,
      "loss": 0.0589,
      "step": 11520
    },
    {
      "epoch": 6.588571428571429,
      "grad_norm": 0.008841077797114849,
      "learning_rate": 6.822857142857143e-06,
      "loss": 0.0139,
      "step": 11530
    },
    {
      "epoch": 6.594285714285714,
      "grad_norm": 0.013239534571766853,
      "learning_rate": 6.8114285714285725e-06,
      "loss": 0.0014,
      "step": 11540
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.0025953836739063263,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0018,
      "step": 11550
    },
    {
      "epoch": 6.605714285714286,
      "grad_norm": 7.217376708984375,
      "learning_rate": 6.7885714285714286e-06,
      "loss": 0.0771,
      "step": 11560
    },
    {
      "epoch": 6.611428571428571,
      "grad_norm": 0.06725434958934784,
      "learning_rate": 6.777142857142858e-06,
      "loss": 0.0235,
      "step": 11570
    },
    {
      "epoch": 6.617142857142857,
      "grad_norm": 0.05742697790265083,
      "learning_rate": 6.765714285714286e-06,
      "loss": 0.0164,
      "step": 11580
    },
    {
      "epoch": 6.622857142857143,
      "grad_norm": 23.649757385253906,
      "learning_rate": 6.754285714285715e-06,
      "loss": 0.0118,
      "step": 11590
    },
    {
      "epoch": 6.628571428571428,
      "grad_norm": 2.362975597381592,
      "learning_rate": 6.742857142857143e-06,
      "loss": 0.0418,
      "step": 11600
    },
    {
      "epoch": 6.634285714285714,
      "grad_norm": 0.008755876682698727,
      "learning_rate": 6.7314285714285724e-06,
      "loss": 0.02,
      "step": 11610
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.0011984520824626088,
      "learning_rate": 6.720000000000001e-06,
      "loss": 0.0208,
      "step": 11620
    },
    {
      "epoch": 6.645714285714286,
      "grad_norm": 0.0036166985519230366,
      "learning_rate": 6.7085714285714285e-06,
      "loss": 0.0012,
      "step": 11630
    },
    {
      "epoch": 6.651428571428571,
      "grad_norm": 0.0005311087006703019,
      "learning_rate": 6.697142857142858e-06,
      "loss": 0.0005,
      "step": 11640
    },
    {
      "epoch": 6.6571428571428575,
      "grad_norm": 1.2649543285369873,
      "learning_rate": 6.685714285714286e-06,
      "loss": 0.0138,
      "step": 11650
    },
    {
      "epoch": 6.662857142857143,
      "grad_norm": 0.0031234053894877434,
      "learning_rate": 6.6742857142857155e-06,
      "loss": 0.0154,
      "step": 11660
    },
    {
      "epoch": 6.668571428571429,
      "grad_norm": 0.012267915531992912,
      "learning_rate": 6.662857142857143e-06,
      "loss": 0.0001,
      "step": 11670
    },
    {
      "epoch": 6.674285714285714,
      "grad_norm": 1.6365703344345093,
      "learning_rate": 6.651428571428572e-06,
      "loss": 0.0058,
      "step": 11680
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.002884255489334464,
      "learning_rate": 6.640000000000001e-06,
      "loss": 0.0361,
      "step": 11690
    },
    {
      "epoch": 6.685714285714286,
      "grad_norm": 0.0041998992674052715,
      "learning_rate": 6.628571428571428e-06,
      "loss": 0.0384,
      "step": 11700
    },
    {
      "epoch": 6.691428571428571,
      "grad_norm": 0.055526625365018845,
      "learning_rate": 6.617142857142858e-06,
      "loss": 0.0075,
      "step": 11710
    },
    {
      "epoch": 6.6971428571428575,
      "grad_norm": 0.01080716960132122,
      "learning_rate": 6.605714285714286e-06,
      "loss": 0.0001,
      "step": 11720
    },
    {
      "epoch": 6.702857142857143,
      "grad_norm": 0.22125346958637238,
      "learning_rate": 6.594285714285715e-06,
      "loss": 0.0007,
      "step": 11730
    },
    {
      "epoch": 6.708571428571428,
      "grad_norm": 0.001319092232733965,
      "learning_rate": 6.582857142857143e-06,
      "loss": 0.0126,
      "step": 11740
    },
    {
      "epoch": 6.714285714285714,
      "grad_norm": 0.0034780476707965136,
      "learning_rate": 6.571428571428572e-06,
      "loss": 0.0017,
      "step": 11750
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.01197147648781538,
      "learning_rate": 6.560000000000001e-06,
      "loss": 0.0471,
      "step": 11760
    },
    {
      "epoch": 6.725714285714286,
      "grad_norm": 0.002674996154382825,
      "learning_rate": 6.548571428571428e-06,
      "loss": 0.0025,
      "step": 11770
    },
    {
      "epoch": 6.731428571428571,
      "grad_norm": 0.0004773593391291797,
      "learning_rate": 6.537142857142858e-06,
      "loss": 0.0543,
      "step": 11780
    },
    {
      "epoch": 6.737142857142857,
      "grad_norm": 0.0007160038803704083,
      "learning_rate": 6.525714285714286e-06,
      "loss": 0.0003,
      "step": 11790
    },
    {
      "epoch": 6.742857142857143,
      "grad_norm": 0.004286247305572033,
      "learning_rate": 6.514285714285715e-06,
      "loss": 0.0311,
      "step": 11800
    },
    {
      "epoch": 6.748571428571428,
      "grad_norm": 0.000793231709394604,
      "learning_rate": 6.502857142857143e-06,
      "loss": 0.0095,
      "step": 11810
    },
    {
      "epoch": 6.7542857142857144,
      "grad_norm": 3.7802469730377197,
      "learning_rate": 6.491428571428572e-06,
      "loss": 0.1095,
      "step": 11820
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.0007815409917384386,
      "learning_rate": 6.480000000000001e-06,
      "loss": 0.0001,
      "step": 11830
    },
    {
      "epoch": 6.765714285714286,
      "grad_norm": 0.0026873492170125246,
      "learning_rate": 6.46857142857143e-06,
      "loss": 0.0004,
      "step": 11840
    },
    {
      "epoch": 6.771428571428571,
      "grad_norm": 10.41086483001709,
      "learning_rate": 6.4571428571428575e-06,
      "loss": 0.0423,
      "step": 11850
    },
    {
      "epoch": 6.777142857142858,
      "grad_norm": 0.004000551532953978,
      "learning_rate": 6.445714285714286e-06,
      "loss": 0.0635,
      "step": 11860
    },
    {
      "epoch": 6.782857142857143,
      "grad_norm": 0.035003725439310074,
      "learning_rate": 6.434285714285715e-06,
      "loss": 0.0081,
      "step": 11870
    },
    {
      "epoch": 6.788571428571428,
      "grad_norm": 0.0015798754757270217,
      "learning_rate": 6.422857142857143e-06,
      "loss": 0.0681,
      "step": 11880
    },
    {
      "epoch": 6.7942857142857145,
      "grad_norm": 0.001779949408955872,
      "learning_rate": 6.411428571428572e-06,
      "loss": 0.0176,
      "step": 11890
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.3555338382720947,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0016,
      "step": 11900
    },
    {
      "epoch": 6.805714285714286,
      "grad_norm": 0.009588922373950481,
      "learning_rate": 6.38857142857143e-06,
      "loss": 0.0153,
      "step": 11910
    },
    {
      "epoch": 6.811428571428571,
      "grad_norm": 4.661919593811035,
      "learning_rate": 6.3771428571428574e-06,
      "loss": 0.0027,
      "step": 11920
    },
    {
      "epoch": 6.817142857142857,
      "grad_norm": 0.0020425792317837477,
      "learning_rate": 6.365714285714286e-06,
      "loss": 0.0144,
      "step": 11930
    },
    {
      "epoch": 6.822857142857143,
      "grad_norm": 0.08790659159421921,
      "learning_rate": 6.354285714285715e-06,
      "loss": 0.0598,
      "step": 11940
    },
    {
      "epoch": 6.828571428571428,
      "grad_norm": 0.020605675876140594,
      "learning_rate": 6.342857142857143e-06,
      "loss": 0.0224,
      "step": 11950
    },
    {
      "epoch": 6.8342857142857145,
      "grad_norm": 0.0016583558171987534,
      "learning_rate": 6.331428571428572e-06,
      "loss": 0.054,
      "step": 11960
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.006034206133335829,
      "learning_rate": 6.3200000000000005e-06,
      "loss": 0.0001,
      "step": 11970
    },
    {
      "epoch": 6.845714285714286,
      "grad_norm": 14.05608081817627,
      "learning_rate": 6.30857142857143e-06,
      "loss": 0.0403,
      "step": 11980
    },
    {
      "epoch": 6.851428571428571,
      "grad_norm": 0.002261637942865491,
      "learning_rate": 6.297142857142857e-06,
      "loss": 0.0376,
      "step": 11990
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 0.002262135734781623,
      "learning_rate": 6.285714285714286e-06,
      "loss": 0.0111,
      "step": 12000
    },
    {
      "epoch": 6.862857142857143,
      "grad_norm": 0.3794557750225067,
      "learning_rate": 6.274285714285715e-06,
      "loss": 0.0008,
      "step": 12010
    },
    {
      "epoch": 6.868571428571428,
      "grad_norm": 0.18233351409435272,
      "learning_rate": 6.2628571428571435e-06,
      "loss": 0.0094,
      "step": 12020
    },
    {
      "epoch": 6.8742857142857146,
      "grad_norm": 8.225781440734863,
      "learning_rate": 6.251428571428572e-06,
      "loss": 0.1438,
      "step": 12030
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.003378489287570119,
      "learning_rate": 6.24e-06,
      "loss": 0.0346,
      "step": 12040
    },
    {
      "epoch": 6.885714285714286,
      "grad_norm": 0.030876630917191505,
      "learning_rate": 6.22857142857143e-06,
      "loss": 0.0314,
      "step": 12050
    },
    {
      "epoch": 6.8914285714285715,
      "grad_norm": 0.03093608468770981,
      "learning_rate": 6.217142857142857e-06,
      "loss": 0.0009,
      "step": 12060
    },
    {
      "epoch": 6.897142857142857,
      "grad_norm": 0.03166215866804123,
      "learning_rate": 6.205714285714286e-06,
      "loss": 0.0351,
      "step": 12070
    },
    {
      "epoch": 6.902857142857143,
      "grad_norm": 0.007909955456852913,
      "learning_rate": 6.194285714285715e-06,
      "loss": 0.0095,
      "step": 12080
    },
    {
      "epoch": 6.908571428571428,
      "grad_norm": 0.0017249691300094128,
      "learning_rate": 6.1828571428571434e-06,
      "loss": 0.022,
      "step": 12090
    },
    {
      "epoch": 6.914285714285715,
      "grad_norm": 0.02147008664906025,
      "learning_rate": 6.171428571428572e-06,
      "loss": 0.0016,
      "step": 12100
    },
    {
      "epoch": 6.92,
      "grad_norm": 0.028000833466649055,
      "learning_rate": 6.16e-06,
      "loss": 0.0201,
      "step": 12110
    },
    {
      "epoch": 6.925714285714285,
      "grad_norm": 0.3668809235095978,
      "learning_rate": 6.14857142857143e-06,
      "loss": 0.025,
      "step": 12120
    },
    {
      "epoch": 6.9314285714285715,
      "grad_norm": 0.0019147236598655581,
      "learning_rate": 6.137142857142858e-06,
      "loss": 0.0166,
      "step": 12130
    },
    {
      "epoch": 6.937142857142857,
      "grad_norm": 0.03997064754366875,
      "learning_rate": 6.125714285714286e-06,
      "loss": 0.0002,
      "step": 12140
    },
    {
      "epoch": 6.942857142857143,
      "grad_norm": 0.006177341099828482,
      "learning_rate": 6.114285714285715e-06,
      "loss": 0.0176,
      "step": 12150
    },
    {
      "epoch": 6.948571428571428,
      "grad_norm": 0.005539062432944775,
      "learning_rate": 6.102857142857143e-06,
      "loss": 0.0339,
      "step": 12160
    },
    {
      "epoch": 6.954285714285715,
      "grad_norm": 0.001540363417007029,
      "learning_rate": 6.091428571428572e-06,
      "loss": 0.007,
      "step": 12170
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.006654816679656506,
      "learning_rate": 6.08e-06,
      "loss": 0.0007,
      "step": 12180
    },
    {
      "epoch": 6.965714285714286,
      "grad_norm": 0.014004225842654705,
      "learning_rate": 6.0685714285714295e-06,
      "loss": 0.0745,
      "step": 12190
    },
    {
      "epoch": 6.9714285714285715,
      "grad_norm": 0.008540785871446133,
      "learning_rate": 6.057142857142858e-06,
      "loss": 0.0119,
      "step": 12200
    },
    {
      "epoch": 6.977142857142857,
      "grad_norm": 0.0010433703428134322,
      "learning_rate": 6.0457142857142855e-06,
      "loss": 0.0001,
      "step": 12210
    },
    {
      "epoch": 6.982857142857143,
      "grad_norm": 0.02253701351583004,
      "learning_rate": 6.034285714285715e-06,
      "loss": 0.0153,
      "step": 12220
    },
    {
      "epoch": 6.988571428571428,
      "grad_norm": 1.2998780012130737,
      "learning_rate": 6.022857142857143e-06,
      "loss": 0.0025,
      "step": 12230
    },
    {
      "epoch": 6.994285714285715,
      "grad_norm": 10.070626258850098,
      "learning_rate": 6.011428571428572e-06,
      "loss": 0.0926,
      "step": 12240
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.1470213085412979,
      "learning_rate": 6e-06,
      "loss": 0.0263,
      "step": 12250
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9829545454545454,
      "eval_f1": 0.9358490566037735,
      "eval_loss": 0.09135881811380386,
      "eval_precision": 0.9335006273525721,
      "eval_recall": 0.9382093316519546,
      "eval_runtime": 57.2391,
      "eval_samples_per_second": 104.823,
      "eval_steps_per_second": 3.284,
      "step": 12250
    }
  ],
  "logging_steps": 10,
  "max_steps": 17500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.82368702479744e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
