{
  "best_metric": 0.948985507246377,
  "best_model_checkpoint": "../saved_models/open_redirect_ep20_770/checkpoint-34678",
  "epoch": 14.0,
  "eval_steps": 500,
  "global_step": 34678,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0004037141703673799,
      "grad_norm": 45.28807067871094,
      "learning_rate": 1.9999596285829635e-05,
      "loss": 0.9946,
      "step": 1
    },
    {
      "epoch": 0.004037141703673799,
      "grad_norm": 27.669649124145508,
      "learning_rate": 1.9995962858296326e-05,
      "loss": 0.5742,
      "step": 10
    },
    {
      "epoch": 0.008074283407347598,
      "grad_norm": 24.939559936523438,
      "learning_rate": 1.9991925716592654e-05,
      "loss": 0.5276,
      "step": 20
    },
    {
      "epoch": 0.012111425111021397,
      "grad_norm": 49.38640594482422,
      "learning_rate": 1.9987888574888982e-05,
      "loss": 0.5165,
      "step": 30
    },
    {
      "epoch": 0.016148566814695196,
      "grad_norm": 26.538341522216797,
      "learning_rate": 1.9983851433185307e-05,
      "loss": 0.4311,
      "step": 40
    },
    {
      "epoch": 0.020185708518368994,
      "grad_norm": 23.454553604125977,
      "learning_rate": 1.997981429148163e-05,
      "loss": 0.5493,
      "step": 50
    },
    {
      "epoch": 0.024222850222042795,
      "grad_norm": 19.714366912841797,
      "learning_rate": 1.997577714977796e-05,
      "loss": 0.4719,
      "step": 60
    },
    {
      "epoch": 0.028259991925716592,
      "grad_norm": 10.558022499084473,
      "learning_rate": 1.9971740008074284e-05,
      "loss": 0.3891,
      "step": 70
    },
    {
      "epoch": 0.03229713362939039,
      "grad_norm": 14.826197624206543,
      "learning_rate": 1.9967702866370612e-05,
      "loss": 0.5112,
      "step": 80
    },
    {
      "epoch": 0.036334275333064193,
      "grad_norm": 22.144107818603516,
      "learning_rate": 1.996366572466694e-05,
      "loss": 0.4305,
      "step": 90
    },
    {
      "epoch": 0.04037141703673799,
      "grad_norm": 22.411428451538086,
      "learning_rate": 1.9959628582963265e-05,
      "loss": 0.3925,
      "step": 100
    },
    {
      "epoch": 0.04440855874041179,
      "grad_norm": 16.664958953857422,
      "learning_rate": 1.995559144125959e-05,
      "loss": 0.3644,
      "step": 110
    },
    {
      "epoch": 0.04844570044408559,
      "grad_norm": 21.802627563476562,
      "learning_rate": 1.9951554299555914e-05,
      "loss": 0.4865,
      "step": 120
    },
    {
      "epoch": 0.05248284214775938,
      "grad_norm": 9.76812744140625,
      "learning_rate": 1.994751715785224e-05,
      "loss": 0.359,
      "step": 130
    },
    {
      "epoch": 0.056519983851433184,
      "grad_norm": 21.691091537475586,
      "learning_rate": 1.994348001614857e-05,
      "loss": 0.4603,
      "step": 140
    },
    {
      "epoch": 0.060557125555106985,
      "grad_norm": 14.577890396118164,
      "learning_rate": 1.9939442874444894e-05,
      "loss": 0.42,
      "step": 150
    },
    {
      "epoch": 0.06459426725878079,
      "grad_norm": 49.205875396728516,
      "learning_rate": 1.993540573274122e-05,
      "loss": 0.4312,
      "step": 160
    },
    {
      "epoch": 0.06863140896245458,
      "grad_norm": 20.82292366027832,
      "learning_rate": 1.9931368591037547e-05,
      "loss": 0.4855,
      "step": 170
    },
    {
      "epoch": 0.07266855066612839,
      "grad_norm": 13.915488243103027,
      "learning_rate": 1.9927331449333875e-05,
      "loss": 0.4603,
      "step": 180
    },
    {
      "epoch": 0.07670569236980218,
      "grad_norm": 14.131781578063965,
      "learning_rate": 1.99232943076302e-05,
      "loss": 0.3316,
      "step": 190
    },
    {
      "epoch": 0.08074283407347597,
      "grad_norm": 28.762042999267578,
      "learning_rate": 1.9919257165926527e-05,
      "loss": 0.48,
      "step": 200
    },
    {
      "epoch": 0.08477997577714978,
      "grad_norm": 17.131853103637695,
      "learning_rate": 1.9915220024222852e-05,
      "loss": 0.3462,
      "step": 210
    },
    {
      "epoch": 0.08881711748082358,
      "grad_norm": 20.758094787597656,
      "learning_rate": 1.9911182882519177e-05,
      "loss": 0.4366,
      "step": 220
    },
    {
      "epoch": 0.09285425918449737,
      "grad_norm": 14.917722702026367,
      "learning_rate": 1.9907145740815505e-05,
      "loss": 0.4242,
      "step": 230
    },
    {
      "epoch": 0.09689140088817118,
      "grad_norm": 16.510204315185547,
      "learning_rate": 1.9903108599111833e-05,
      "loss": 0.3992,
      "step": 240
    },
    {
      "epoch": 0.10092854259184497,
      "grad_norm": 14.917680740356445,
      "learning_rate": 1.9899071457408157e-05,
      "loss": 0.3069,
      "step": 250
    },
    {
      "epoch": 0.10496568429551877,
      "grad_norm": 20.170839309692383,
      "learning_rate": 1.9895034315704482e-05,
      "loss": 0.433,
      "step": 260
    },
    {
      "epoch": 0.10900282599919257,
      "grad_norm": 11.815665245056152,
      "learning_rate": 1.989099717400081e-05,
      "loss": 0.4226,
      "step": 270
    },
    {
      "epoch": 0.11303996770286637,
      "grad_norm": 19.019458770751953,
      "learning_rate": 1.9886960032297134e-05,
      "loss": 0.4378,
      "step": 280
    },
    {
      "epoch": 0.11707710940654018,
      "grad_norm": 10.814006805419922,
      "learning_rate": 1.9882922890593462e-05,
      "loss": 0.4269,
      "step": 290
    },
    {
      "epoch": 0.12111425111021397,
      "grad_norm": 12.77285099029541,
      "learning_rate": 1.9878885748889787e-05,
      "loss": 0.4075,
      "step": 300
    },
    {
      "epoch": 0.12515139281388776,
      "grad_norm": 15.367541313171387,
      "learning_rate": 1.9874848607186115e-05,
      "loss": 0.3634,
      "step": 310
    },
    {
      "epoch": 0.12918853451756157,
      "grad_norm": 9.872554779052734,
      "learning_rate": 1.987081146548244e-05,
      "loss": 0.4138,
      "step": 320
    },
    {
      "epoch": 0.13322567622123538,
      "grad_norm": 5.502648830413818,
      "learning_rate": 1.9866774323778767e-05,
      "loss": 0.3018,
      "step": 330
    },
    {
      "epoch": 0.13726281792490916,
      "grad_norm": 7.67258358001709,
      "learning_rate": 1.9862737182075092e-05,
      "loss": 0.3977,
      "step": 340
    },
    {
      "epoch": 0.14129995962858297,
      "grad_norm": 12.639798164367676,
      "learning_rate": 1.985870004037142e-05,
      "loss": 0.5051,
      "step": 350
    },
    {
      "epoch": 0.14533710133225677,
      "grad_norm": 6.088746070861816,
      "learning_rate": 1.9854662898667745e-05,
      "loss": 0.3514,
      "step": 360
    },
    {
      "epoch": 0.14937424303593055,
      "grad_norm": 13.107335090637207,
      "learning_rate": 1.985062575696407e-05,
      "loss": 0.3789,
      "step": 370
    },
    {
      "epoch": 0.15341138473960436,
      "grad_norm": 12.130998611450195,
      "learning_rate": 1.9846588615260397e-05,
      "loss": 0.3273,
      "step": 380
    },
    {
      "epoch": 0.15744852644327817,
      "grad_norm": 7.454360485076904,
      "learning_rate": 1.9842551473556725e-05,
      "loss": 0.2793,
      "step": 390
    },
    {
      "epoch": 0.16148566814695195,
      "grad_norm": 6.150635719299316,
      "learning_rate": 1.983851433185305e-05,
      "loss": 0.2922,
      "step": 400
    },
    {
      "epoch": 0.16552280985062576,
      "grad_norm": 12.668294906616211,
      "learning_rate": 1.9834477190149374e-05,
      "loss": 0.3326,
      "step": 410
    },
    {
      "epoch": 0.16955995155429957,
      "grad_norm": 9.763555526733398,
      "learning_rate": 1.9830440048445702e-05,
      "loss": 0.3612,
      "step": 420
    },
    {
      "epoch": 0.17359709325797335,
      "grad_norm": 2.8737919330596924,
      "learning_rate": 1.9826402906742027e-05,
      "loss": 0.2899,
      "step": 430
    },
    {
      "epoch": 0.17763423496164715,
      "grad_norm": 9.057808876037598,
      "learning_rate": 1.9822365765038355e-05,
      "loss": 0.3413,
      "step": 440
    },
    {
      "epoch": 0.18167137666532096,
      "grad_norm": 7.241419315338135,
      "learning_rate": 1.9818328623334683e-05,
      "loss": 0.3775,
      "step": 450
    },
    {
      "epoch": 0.18570851836899474,
      "grad_norm": 9.609626770019531,
      "learning_rate": 1.9814291481631007e-05,
      "loss": 0.3898,
      "step": 460
    },
    {
      "epoch": 0.18974566007266855,
      "grad_norm": 11.459792137145996,
      "learning_rate": 1.9810254339927332e-05,
      "loss": 0.3453,
      "step": 470
    },
    {
      "epoch": 0.19378280177634236,
      "grad_norm": 10.871983528137207,
      "learning_rate": 1.980621719822366e-05,
      "loss": 0.3003,
      "step": 480
    },
    {
      "epoch": 0.19781994348001614,
      "grad_norm": 9.779363632202148,
      "learning_rate": 1.9802180056519985e-05,
      "loss": 0.4076,
      "step": 490
    },
    {
      "epoch": 0.20185708518368994,
      "grad_norm": 10.239665031433105,
      "learning_rate": 1.9798142914816313e-05,
      "loss": 0.2929,
      "step": 500
    },
    {
      "epoch": 0.20589422688736375,
      "grad_norm": 9.124340057373047,
      "learning_rate": 1.9794105773112637e-05,
      "loss": 0.2861,
      "step": 510
    },
    {
      "epoch": 0.20993136859103753,
      "grad_norm": 12.552823066711426,
      "learning_rate": 1.9790068631408965e-05,
      "loss": 0.3439,
      "step": 520
    },
    {
      "epoch": 0.21396851029471134,
      "grad_norm": 7.4498186111450195,
      "learning_rate": 1.978603148970529e-05,
      "loss": 0.2641,
      "step": 530
    },
    {
      "epoch": 0.21800565199838515,
      "grad_norm": 12.385202407836914,
      "learning_rate": 1.9781994348001618e-05,
      "loss": 0.3821,
      "step": 540
    },
    {
      "epoch": 0.22204279370205895,
      "grad_norm": 6.844030857086182,
      "learning_rate": 1.9777957206297942e-05,
      "loss": 0.3097,
      "step": 550
    },
    {
      "epoch": 0.22607993540573273,
      "grad_norm": 4.315828800201416,
      "learning_rate": 1.977392006459427e-05,
      "loss": 0.2893,
      "step": 560
    },
    {
      "epoch": 0.23011707710940654,
      "grad_norm": 7.381258964538574,
      "learning_rate": 1.9769882922890595e-05,
      "loss": 0.2177,
      "step": 570
    },
    {
      "epoch": 0.23415421881308035,
      "grad_norm": 7.414671897888184,
      "learning_rate": 1.976584578118692e-05,
      "loss": 0.2485,
      "step": 580
    },
    {
      "epoch": 0.23819136051675413,
      "grad_norm": 7.020367622375488,
      "learning_rate": 1.9761808639483247e-05,
      "loss": 0.2876,
      "step": 590
    },
    {
      "epoch": 0.24222850222042794,
      "grad_norm": 7.530378341674805,
      "learning_rate": 1.9757771497779575e-05,
      "loss": 0.3796,
      "step": 600
    },
    {
      "epoch": 0.24626564392410175,
      "grad_norm": 9.211369514465332,
      "learning_rate": 1.97537343560759e-05,
      "loss": 0.3208,
      "step": 610
    },
    {
      "epoch": 0.2503027856277755,
      "grad_norm": 8.916119575500488,
      "learning_rate": 1.9749697214372225e-05,
      "loss": 0.2221,
      "step": 620
    },
    {
      "epoch": 0.25433992733144933,
      "grad_norm": 8.682999610900879,
      "learning_rate": 1.9745660072668553e-05,
      "loss": 0.2761,
      "step": 630
    },
    {
      "epoch": 0.25837706903512314,
      "grad_norm": 8.456517219543457,
      "learning_rate": 1.9741622930964877e-05,
      "loss": 0.2752,
      "step": 640
    },
    {
      "epoch": 0.26241421073879695,
      "grad_norm": 8.781246185302734,
      "learning_rate": 1.9737585789261205e-05,
      "loss": 0.3068,
      "step": 650
    },
    {
      "epoch": 0.26645135244247076,
      "grad_norm": 9.803278923034668,
      "learning_rate": 1.973354864755753e-05,
      "loss": 0.3252,
      "step": 660
    },
    {
      "epoch": 0.2704884941461445,
      "grad_norm": 7.451014041900635,
      "learning_rate": 1.9729511505853858e-05,
      "loss": 0.2642,
      "step": 670
    },
    {
      "epoch": 0.2745256358498183,
      "grad_norm": 5.439160346984863,
      "learning_rate": 1.9725474364150182e-05,
      "loss": 0.1794,
      "step": 680
    },
    {
      "epoch": 0.2785627775534921,
      "grad_norm": 9.59693717956543,
      "learning_rate": 1.972143722244651e-05,
      "loss": 0.2423,
      "step": 690
    },
    {
      "epoch": 0.28259991925716593,
      "grad_norm": 8.295819282531738,
      "learning_rate": 1.971740008074284e-05,
      "loss": 0.293,
      "step": 700
    },
    {
      "epoch": 0.28663706096083974,
      "grad_norm": 8.019469261169434,
      "learning_rate": 1.9713362939039163e-05,
      "loss": 0.2252,
      "step": 710
    },
    {
      "epoch": 0.29067420266451355,
      "grad_norm": 7.777987957000732,
      "learning_rate": 1.9709325797335488e-05,
      "loss": 0.2619,
      "step": 720
    },
    {
      "epoch": 0.2947113443681873,
      "grad_norm": 6.212387561798096,
      "learning_rate": 1.9705288655631812e-05,
      "loss": 0.2565,
      "step": 730
    },
    {
      "epoch": 0.2987484860718611,
      "grad_norm": 6.127292633056641,
      "learning_rate": 1.970125151392814e-05,
      "loss": 0.22,
      "step": 740
    },
    {
      "epoch": 0.3027856277755349,
      "grad_norm": 10.677777290344238,
      "learning_rate": 1.9697214372224468e-05,
      "loss": 0.3505,
      "step": 750
    },
    {
      "epoch": 0.3068227694792087,
      "grad_norm": 27.171092987060547,
      "learning_rate": 1.9693177230520793e-05,
      "loss": 0.2345,
      "step": 760
    },
    {
      "epoch": 0.31085991118288253,
      "grad_norm": 7.160130023956299,
      "learning_rate": 1.9689140088817117e-05,
      "loss": 0.2419,
      "step": 770
    },
    {
      "epoch": 0.31489705288655634,
      "grad_norm": 7.631844520568848,
      "learning_rate": 1.9685102947113445e-05,
      "loss": 0.2327,
      "step": 780
    },
    {
      "epoch": 0.3189341945902301,
      "grad_norm": 17.117095947265625,
      "learning_rate": 1.968106580540977e-05,
      "loss": 0.248,
      "step": 790
    },
    {
      "epoch": 0.3229713362939039,
      "grad_norm": 6.5354838371276855,
      "learning_rate": 1.9677028663706098e-05,
      "loss": 0.196,
      "step": 800
    },
    {
      "epoch": 0.3270084779975777,
      "grad_norm": 4.84266996383667,
      "learning_rate": 1.9672991522002426e-05,
      "loss": 0.1917,
      "step": 810
    },
    {
      "epoch": 0.3310456197012515,
      "grad_norm": 8.061930656433105,
      "learning_rate": 1.966895438029875e-05,
      "loss": 0.2807,
      "step": 820
    },
    {
      "epoch": 0.3350827614049253,
      "grad_norm": 11.721091270446777,
      "learning_rate": 1.9664917238595075e-05,
      "loss": 0.2269,
      "step": 830
    },
    {
      "epoch": 0.33911990310859913,
      "grad_norm": 9.59533977508545,
      "learning_rate": 1.9660880096891403e-05,
      "loss": 0.2275,
      "step": 840
    },
    {
      "epoch": 0.34315704481227294,
      "grad_norm": 3.8002920150756836,
      "learning_rate": 1.965684295518773e-05,
      "loss": 0.1751,
      "step": 850
    },
    {
      "epoch": 0.3471941865159467,
      "grad_norm": 12.027857780456543,
      "learning_rate": 1.9652805813484056e-05,
      "loss": 0.3593,
      "step": 860
    },
    {
      "epoch": 0.3512313282196205,
      "grad_norm": 8.56255054473877,
      "learning_rate": 1.964876867178038e-05,
      "loss": 0.2925,
      "step": 870
    },
    {
      "epoch": 0.3552684699232943,
      "grad_norm": 10.15006160736084,
      "learning_rate": 1.9644731530076708e-05,
      "loss": 0.2334,
      "step": 880
    },
    {
      "epoch": 0.3593056116269681,
      "grad_norm": 3.723801851272583,
      "learning_rate": 1.9640694388373033e-05,
      "loss": 0.1489,
      "step": 890
    },
    {
      "epoch": 0.3633427533306419,
      "grad_norm": 4.603481769561768,
      "learning_rate": 1.963665724666936e-05,
      "loss": 0.3507,
      "step": 900
    },
    {
      "epoch": 0.36737989503431573,
      "grad_norm": 9.742719650268555,
      "learning_rate": 1.9632620104965685e-05,
      "loss": 0.2464,
      "step": 910
    },
    {
      "epoch": 0.3714170367379895,
      "grad_norm": 7.708787441253662,
      "learning_rate": 1.9628582963262013e-05,
      "loss": 0.2394,
      "step": 920
    },
    {
      "epoch": 0.3754541784416633,
      "grad_norm": 1.2051091194152832,
      "learning_rate": 1.9624545821558338e-05,
      "loss": 0.122,
      "step": 930
    },
    {
      "epoch": 0.3794913201453371,
      "grad_norm": 6.784141540527344,
      "learning_rate": 1.9620508679854662e-05,
      "loss": 0.2243,
      "step": 940
    },
    {
      "epoch": 0.3835284618490109,
      "grad_norm": 7.594195365905762,
      "learning_rate": 1.961647153815099e-05,
      "loss": 0.2016,
      "step": 950
    },
    {
      "epoch": 0.3875656035526847,
      "grad_norm": 8.05856990814209,
      "learning_rate": 1.961243439644732e-05,
      "loss": 0.1737,
      "step": 960
    },
    {
      "epoch": 0.3916027452563585,
      "grad_norm": 4.525352478027344,
      "learning_rate": 1.9608397254743643e-05,
      "loss": 0.2291,
      "step": 970
    },
    {
      "epoch": 0.39563988696003227,
      "grad_norm": 5.244279384613037,
      "learning_rate": 1.9604360113039968e-05,
      "loss": 0.2132,
      "step": 980
    },
    {
      "epoch": 0.3996770286637061,
      "grad_norm": 5.699328899383545,
      "learning_rate": 1.9600322971336296e-05,
      "loss": 0.1518,
      "step": 990
    },
    {
      "epoch": 0.4037141703673799,
      "grad_norm": 7.181819438934326,
      "learning_rate": 1.9596285829632624e-05,
      "loss": 0.1676,
      "step": 1000
    },
    {
      "epoch": 0.4077513120710537,
      "grad_norm": 4.5162577629089355,
      "learning_rate": 1.9592248687928948e-05,
      "loss": 0.1458,
      "step": 1010
    },
    {
      "epoch": 0.4117884537747275,
      "grad_norm": 10.822314262390137,
      "learning_rate": 1.9588211546225273e-05,
      "loss": 0.2278,
      "step": 1020
    },
    {
      "epoch": 0.4158255954784013,
      "grad_norm": 9.090109825134277,
      "learning_rate": 1.95841744045216e-05,
      "loss": 0.1998,
      "step": 1030
    },
    {
      "epoch": 0.41986273718207506,
      "grad_norm": 9.813949584960938,
      "learning_rate": 1.9580137262817925e-05,
      "loss": 0.2346,
      "step": 1040
    },
    {
      "epoch": 0.42389987888574887,
      "grad_norm": 1.0537457466125488,
      "learning_rate": 1.9576100121114253e-05,
      "loss": 0.2096,
      "step": 1050
    },
    {
      "epoch": 0.4279370205894227,
      "grad_norm": 11.599430084228516,
      "learning_rate": 1.957206297941058e-05,
      "loss": 0.2118,
      "step": 1060
    },
    {
      "epoch": 0.4319741622930965,
      "grad_norm": 4.969560623168945,
      "learning_rate": 1.9568025837706906e-05,
      "loss": 0.1391,
      "step": 1070
    },
    {
      "epoch": 0.4360113039967703,
      "grad_norm": 10.846647262573242,
      "learning_rate": 1.956398869600323e-05,
      "loss": 0.2241,
      "step": 1080
    },
    {
      "epoch": 0.4400484457004441,
      "grad_norm": 9.867003440856934,
      "learning_rate": 1.9559951554299555e-05,
      "loss": 0.1659,
      "step": 1090
    },
    {
      "epoch": 0.4440855874041179,
      "grad_norm": 3.269524335861206,
      "learning_rate": 1.9555914412595883e-05,
      "loss": 0.2084,
      "step": 1100
    },
    {
      "epoch": 0.44812272910779166,
      "grad_norm": 6.110382556915283,
      "learning_rate": 1.955187727089221e-05,
      "loss": 0.089,
      "step": 1110
    },
    {
      "epoch": 0.45215987081146547,
      "grad_norm": 0.7783820033073425,
      "learning_rate": 1.9547840129188536e-05,
      "loss": 0.1076,
      "step": 1120
    },
    {
      "epoch": 0.4561970125151393,
      "grad_norm": 7.377457618713379,
      "learning_rate": 1.9543802987484864e-05,
      "loss": 0.1446,
      "step": 1130
    },
    {
      "epoch": 0.4602341542188131,
      "grad_norm": 0.5345250964164734,
      "learning_rate": 1.9539765845781188e-05,
      "loss": 0.1756,
      "step": 1140
    },
    {
      "epoch": 0.4642712959224869,
      "grad_norm": 6.948530673980713,
      "learning_rate": 1.9535728704077516e-05,
      "loss": 0.0998,
      "step": 1150
    },
    {
      "epoch": 0.4683084376261607,
      "grad_norm": 9.154096603393555,
      "learning_rate": 1.953169156237384e-05,
      "loss": 0.2202,
      "step": 1160
    },
    {
      "epoch": 0.47234557932983445,
      "grad_norm": 5.205479145050049,
      "learning_rate": 1.952765442067017e-05,
      "loss": 0.1459,
      "step": 1170
    },
    {
      "epoch": 0.47638272103350826,
      "grad_norm": 8.372993469238281,
      "learning_rate": 1.9523617278966493e-05,
      "loss": 0.1356,
      "step": 1180
    },
    {
      "epoch": 0.48041986273718207,
      "grad_norm": 8.830714225769043,
      "learning_rate": 1.9519580137262818e-05,
      "loss": 0.1872,
      "step": 1190
    },
    {
      "epoch": 0.4844570044408559,
      "grad_norm": 8.869768142700195,
      "learning_rate": 1.9515542995559146e-05,
      "loss": 0.1662,
      "step": 1200
    },
    {
      "epoch": 0.4884941461445297,
      "grad_norm": 5.079578399658203,
      "learning_rate": 1.9511505853855474e-05,
      "loss": 0.1557,
      "step": 1210
    },
    {
      "epoch": 0.4925312878482035,
      "grad_norm": 9.34778118133545,
      "learning_rate": 1.95074687121518e-05,
      "loss": 0.1729,
      "step": 1220
    },
    {
      "epoch": 0.49656842955187724,
      "grad_norm": 2.7823240756988525,
      "learning_rate": 1.9503431570448123e-05,
      "loss": 0.0962,
      "step": 1230
    },
    {
      "epoch": 0.500605571255551,
      "grad_norm": 3.0991766452789307,
      "learning_rate": 1.949939442874445e-05,
      "loss": 0.1728,
      "step": 1240
    },
    {
      "epoch": 0.5046427129592249,
      "grad_norm": 7.616968154907227,
      "learning_rate": 1.9495357287040776e-05,
      "loss": 0.1754,
      "step": 1250
    },
    {
      "epoch": 0.5086798546628987,
      "grad_norm": 5.973700523376465,
      "learning_rate": 1.9491320145337104e-05,
      "loss": 0.1644,
      "step": 1260
    },
    {
      "epoch": 0.5127169963665724,
      "grad_norm": 8.115468978881836,
      "learning_rate": 1.9487283003633428e-05,
      "loss": 0.1293,
      "step": 1270
    },
    {
      "epoch": 0.5167541380702463,
      "grad_norm": 5.533811092376709,
      "learning_rate": 1.9483245861929756e-05,
      "loss": 0.0998,
      "step": 1280
    },
    {
      "epoch": 0.52079127977392,
      "grad_norm": 4.880007743835449,
      "learning_rate": 1.947920872022608e-05,
      "loss": 0.1699,
      "step": 1290
    },
    {
      "epoch": 0.5248284214775939,
      "grad_norm": 7.445016384124756,
      "learning_rate": 1.947517157852241e-05,
      "loss": 0.2041,
      "step": 1300
    },
    {
      "epoch": 0.5288655631812677,
      "grad_norm": 14.012777328491211,
      "learning_rate": 1.9471134436818733e-05,
      "loss": 0.2002,
      "step": 1310
    },
    {
      "epoch": 0.5329027048849415,
      "grad_norm": 6.67465877532959,
      "learning_rate": 1.946709729511506e-05,
      "loss": 0.1699,
      "step": 1320
    },
    {
      "epoch": 0.5369398465886153,
      "grad_norm": 7.21381950378418,
      "learning_rate": 1.9463060153411386e-05,
      "loss": 0.2161,
      "step": 1330
    },
    {
      "epoch": 0.540976988292289,
      "grad_norm": 6.962815761566162,
      "learning_rate": 1.945902301170771e-05,
      "loss": 0.1245,
      "step": 1340
    },
    {
      "epoch": 0.5450141299959629,
      "grad_norm": 3.3884575366973877,
      "learning_rate": 1.945498587000404e-05,
      "loss": 0.1079,
      "step": 1350
    },
    {
      "epoch": 0.5490512716996366,
      "grad_norm": 5.006270885467529,
      "learning_rate": 1.9450948728300366e-05,
      "loss": 0.1306,
      "step": 1360
    },
    {
      "epoch": 0.5530884134033105,
      "grad_norm": 9.851774215698242,
      "learning_rate": 1.944691158659669e-05,
      "loss": 0.177,
      "step": 1370
    },
    {
      "epoch": 0.5571255551069842,
      "grad_norm": 10.1220703125,
      "learning_rate": 1.9442874444893016e-05,
      "loss": 0.2347,
      "step": 1380
    },
    {
      "epoch": 0.561162696810658,
      "grad_norm": 0.4486869275569916,
      "learning_rate": 1.9438837303189344e-05,
      "loss": 0.1362,
      "step": 1390
    },
    {
      "epoch": 0.5651998385143319,
      "grad_norm": 2.799809694290161,
      "learning_rate": 1.9434800161485668e-05,
      "loss": 0.1127,
      "step": 1400
    },
    {
      "epoch": 0.5692369802180056,
      "grad_norm": 4.006972789764404,
      "learning_rate": 1.9430763019781996e-05,
      "loss": 0.1604,
      "step": 1410
    },
    {
      "epoch": 0.5732741219216795,
      "grad_norm": 1.4764994382858276,
      "learning_rate": 1.9426725878078324e-05,
      "loss": 0.177,
      "step": 1420
    },
    {
      "epoch": 0.5773112636253532,
      "grad_norm": 8.086320877075195,
      "learning_rate": 1.942268873637465e-05,
      "loss": 0.1834,
      "step": 1430
    },
    {
      "epoch": 0.5813484053290271,
      "grad_norm": 7.045469760894775,
      "learning_rate": 1.9418651594670973e-05,
      "loss": 0.1673,
      "step": 1440
    },
    {
      "epoch": 0.5853855470327008,
      "grad_norm": 5.379717826843262,
      "learning_rate": 1.94146144529673e-05,
      "loss": 0.0951,
      "step": 1450
    },
    {
      "epoch": 0.5894226887363746,
      "grad_norm": 7.2942938804626465,
      "learning_rate": 1.9410577311263626e-05,
      "loss": 0.1906,
      "step": 1460
    },
    {
      "epoch": 0.5934598304400485,
      "grad_norm": 3.072638988494873,
      "learning_rate": 1.9406540169559954e-05,
      "loss": 0.1021,
      "step": 1470
    },
    {
      "epoch": 0.5974969721437222,
      "grad_norm": 10.065744400024414,
      "learning_rate": 1.940250302785628e-05,
      "loss": 0.2419,
      "step": 1480
    },
    {
      "epoch": 0.6015341138473961,
      "grad_norm": 6.033128261566162,
      "learning_rate": 1.9398465886152607e-05,
      "loss": 0.1335,
      "step": 1490
    },
    {
      "epoch": 0.6055712555510698,
      "grad_norm": 3.7480666637420654,
      "learning_rate": 1.939442874444893e-05,
      "loss": 0.1302,
      "step": 1500
    },
    {
      "epoch": 0.6096083972547437,
      "grad_norm": 4.58302640914917,
      "learning_rate": 1.939039160274526e-05,
      "loss": 0.1316,
      "step": 1510
    },
    {
      "epoch": 0.6136455389584174,
      "grad_norm": 3.5152454376220703,
      "learning_rate": 1.9386354461041584e-05,
      "loss": 0.1596,
      "step": 1520
    },
    {
      "epoch": 0.6176826806620912,
      "grad_norm": 2.9660706520080566,
      "learning_rate": 1.938231731933791e-05,
      "loss": 0.1238,
      "step": 1530
    },
    {
      "epoch": 0.6217198223657651,
      "grad_norm": 6.686392307281494,
      "learning_rate": 1.9378280177634236e-05,
      "loss": 0.1662,
      "step": 1540
    },
    {
      "epoch": 0.6257569640694388,
      "grad_norm": 5.360498428344727,
      "learning_rate": 1.937424303593056e-05,
      "loss": 0.1693,
      "step": 1550
    },
    {
      "epoch": 0.6297941057731127,
      "grad_norm": 6.564006328582764,
      "learning_rate": 1.937020589422689e-05,
      "loss": 0.1773,
      "step": 1560
    },
    {
      "epoch": 0.6338312474767864,
      "grad_norm": 5.3640899658203125,
      "learning_rate": 1.9366168752523217e-05,
      "loss": 0.0947,
      "step": 1570
    },
    {
      "epoch": 0.6378683891804602,
      "grad_norm": 5.917983055114746,
      "learning_rate": 1.936213161081954e-05,
      "loss": 0.1332,
      "step": 1580
    },
    {
      "epoch": 0.641905530884134,
      "grad_norm": 3.7843291759490967,
      "learning_rate": 1.9358094469115866e-05,
      "loss": 0.0922,
      "step": 1590
    },
    {
      "epoch": 0.6459426725878078,
      "grad_norm": 5.506004333496094,
      "learning_rate": 1.9354057327412194e-05,
      "loss": 0.1333,
      "step": 1600
    },
    {
      "epoch": 0.6499798142914817,
      "grad_norm": 9.675610542297363,
      "learning_rate": 1.935002018570852e-05,
      "loss": 0.1572,
      "step": 1610
    },
    {
      "epoch": 0.6540169559951554,
      "grad_norm": 5.667003631591797,
      "learning_rate": 1.9345983044004847e-05,
      "loss": 0.0795,
      "step": 1620
    },
    {
      "epoch": 0.6580540976988293,
      "grad_norm": 11.479463577270508,
      "learning_rate": 1.934194590230117e-05,
      "loss": 0.1467,
      "step": 1630
    },
    {
      "epoch": 0.662091239402503,
      "grad_norm": 9.565793991088867,
      "learning_rate": 1.93379087605975e-05,
      "loss": 0.1404,
      "step": 1640
    },
    {
      "epoch": 0.6661283811061768,
      "grad_norm": 5.100596904754639,
      "learning_rate": 1.9333871618893824e-05,
      "loss": 0.0898,
      "step": 1650
    },
    {
      "epoch": 0.6701655228098506,
      "grad_norm": 5.794035911560059,
      "learning_rate": 1.9329834477190152e-05,
      "loss": 0.0828,
      "step": 1660
    },
    {
      "epoch": 0.6742026645135244,
      "grad_norm": 2.5868916511535645,
      "learning_rate": 1.932579733548648e-05,
      "loss": 0.0752,
      "step": 1670
    },
    {
      "epoch": 0.6782398062171983,
      "grad_norm": 7.064138889312744,
      "learning_rate": 1.9321760193782804e-05,
      "loss": 0.1753,
      "step": 1680
    },
    {
      "epoch": 0.682276947920872,
      "grad_norm": 3.9225072860717773,
      "learning_rate": 1.931772305207913e-05,
      "loss": 0.1906,
      "step": 1690
    },
    {
      "epoch": 0.6863140896245459,
      "grad_norm": 4.706597805023193,
      "learning_rate": 1.9313685910375453e-05,
      "loss": 0.1047,
      "step": 1700
    },
    {
      "epoch": 0.6903512313282196,
      "grad_norm": 11.03895378112793,
      "learning_rate": 1.930964876867178e-05,
      "loss": 0.1323,
      "step": 1710
    },
    {
      "epoch": 0.6943883730318934,
      "grad_norm": 8.259696960449219,
      "learning_rate": 1.930561162696811e-05,
      "loss": 0.084,
      "step": 1720
    },
    {
      "epoch": 0.6984255147355672,
      "grad_norm": 1.0181432962417603,
      "learning_rate": 1.9301574485264434e-05,
      "loss": 0.0645,
      "step": 1730
    },
    {
      "epoch": 0.702462656439241,
      "grad_norm": 6.613389492034912,
      "learning_rate": 1.9297537343560762e-05,
      "loss": 0.0886,
      "step": 1740
    },
    {
      "epoch": 0.7064997981429149,
      "grad_norm": 12.783584594726562,
      "learning_rate": 1.9293500201857087e-05,
      "loss": 0.1774,
      "step": 1750
    },
    {
      "epoch": 0.7105369398465886,
      "grad_norm": 17.18682098388672,
      "learning_rate": 1.928946306015341e-05,
      "loss": 0.1765,
      "step": 1760
    },
    {
      "epoch": 0.7145740815502624,
      "grad_norm": 0.5588286519050598,
      "learning_rate": 1.928542591844974e-05,
      "loss": 0.16,
      "step": 1770
    },
    {
      "epoch": 0.7186112232539362,
      "grad_norm": 0.457583487033844,
      "learning_rate": 1.9281388776746067e-05,
      "loss": 0.1062,
      "step": 1780
    },
    {
      "epoch": 0.72264836495761,
      "grad_norm": 6.351079940795898,
      "learning_rate": 1.9277351635042392e-05,
      "loss": 0.1126,
      "step": 1790
    },
    {
      "epoch": 0.7266855066612838,
      "grad_norm": 7.81146764755249,
      "learning_rate": 1.9273314493338716e-05,
      "loss": 0.1132,
      "step": 1800
    },
    {
      "epoch": 0.7307226483649576,
      "grad_norm": 0.6817606687545776,
      "learning_rate": 1.9269277351635044e-05,
      "loss": 0.1768,
      "step": 1810
    },
    {
      "epoch": 0.7347597900686315,
      "grad_norm": 5.2847580909729,
      "learning_rate": 1.9265240209931372e-05,
      "loss": 0.0822,
      "step": 1820
    },
    {
      "epoch": 0.7387969317723052,
      "grad_norm": 7.099053859710693,
      "learning_rate": 1.9261203068227697e-05,
      "loss": 0.105,
      "step": 1830
    },
    {
      "epoch": 0.742834073475979,
      "grad_norm": 4.791110992431641,
      "learning_rate": 1.925716592652402e-05,
      "loss": 0.1054,
      "step": 1840
    },
    {
      "epoch": 0.7468712151796528,
      "grad_norm": 4.302231788635254,
      "learning_rate": 1.925312878482035e-05,
      "loss": 0.1396,
      "step": 1850
    },
    {
      "epoch": 0.7509083568833266,
      "grad_norm": 4.733180522918701,
      "learning_rate": 1.9249091643116674e-05,
      "loss": 0.0909,
      "step": 1860
    },
    {
      "epoch": 0.7549454985870004,
      "grad_norm": 2.973280429840088,
      "learning_rate": 1.9245054501413002e-05,
      "loss": 0.1259,
      "step": 1870
    },
    {
      "epoch": 0.7589826402906742,
      "grad_norm": 8.724084854125977,
      "learning_rate": 1.9241017359709327e-05,
      "loss": 0.1435,
      "step": 1880
    },
    {
      "epoch": 0.7630197819943481,
      "grad_norm": 6.4231462478637695,
      "learning_rate": 1.9236980218005655e-05,
      "loss": 0.1493,
      "step": 1890
    },
    {
      "epoch": 0.7670569236980218,
      "grad_norm": 1.6023873090744019,
      "learning_rate": 1.923294307630198e-05,
      "loss": 0.1534,
      "step": 1900
    },
    {
      "epoch": 0.7710940654016956,
      "grad_norm": 0.36861562728881836,
      "learning_rate": 1.9228905934598304e-05,
      "loss": 0.1059,
      "step": 1910
    },
    {
      "epoch": 0.7751312071053694,
      "grad_norm": 20.421188354492188,
      "learning_rate": 1.9224868792894632e-05,
      "loss": 0.1356,
      "step": 1920
    },
    {
      "epoch": 0.7791683488090432,
      "grad_norm": 7.497392654418945,
      "learning_rate": 1.922083165119096e-05,
      "loss": 0.0875,
      "step": 1930
    },
    {
      "epoch": 0.783205490512717,
      "grad_norm": 1.1400738954544067,
      "learning_rate": 1.9216794509487284e-05,
      "loss": 0.0956,
      "step": 1940
    },
    {
      "epoch": 0.7872426322163908,
      "grad_norm": 0.09462404251098633,
      "learning_rate": 1.921275736778361e-05,
      "loss": 0.1052,
      "step": 1950
    },
    {
      "epoch": 0.7912797739200645,
      "grad_norm": 13.53249454498291,
      "learning_rate": 1.9208720226079937e-05,
      "loss": 0.1136,
      "step": 1960
    },
    {
      "epoch": 0.7953169156237384,
      "grad_norm": 2.9569480419158936,
      "learning_rate": 1.9204683084376265e-05,
      "loss": 0.1025,
      "step": 1970
    },
    {
      "epoch": 0.7993540573274122,
      "grad_norm": 0.9593192338943481,
      "learning_rate": 1.920064594267259e-05,
      "loss": 0.1955,
      "step": 1980
    },
    {
      "epoch": 0.803391199031086,
      "grad_norm": 7.448164463043213,
      "learning_rate": 1.9196608800968917e-05,
      "loss": 0.0773,
      "step": 1990
    },
    {
      "epoch": 0.8074283407347598,
      "grad_norm": 6.449789047241211,
      "learning_rate": 1.9192571659265242e-05,
      "loss": 0.1523,
      "step": 2000
    },
    {
      "epoch": 0.8114654824384336,
      "grad_norm": 2.1936581134796143,
      "learning_rate": 1.9188534517561567e-05,
      "loss": 0.0744,
      "step": 2010
    },
    {
      "epoch": 0.8155026241421074,
      "grad_norm": 6.058863639831543,
      "learning_rate": 1.9184497375857895e-05,
      "loss": 0.0664,
      "step": 2020
    },
    {
      "epoch": 0.8195397658457811,
      "grad_norm": 7.465693473815918,
      "learning_rate": 1.9180460234154223e-05,
      "loss": 0.1119,
      "step": 2030
    },
    {
      "epoch": 0.823576907549455,
      "grad_norm": 8.73966121673584,
      "learning_rate": 1.9176423092450547e-05,
      "loss": 0.091,
      "step": 2040
    },
    {
      "epoch": 0.8276140492531288,
      "grad_norm": 0.48559311032295227,
      "learning_rate": 1.9172385950746872e-05,
      "loss": 0.1022,
      "step": 2050
    },
    {
      "epoch": 0.8316511909568026,
      "grad_norm": 2.6347203254699707,
      "learning_rate": 1.9168348809043196e-05,
      "loss": 0.0842,
      "step": 2060
    },
    {
      "epoch": 0.8356883326604764,
      "grad_norm": 11.341208457946777,
      "learning_rate": 1.9164311667339524e-05,
      "loss": 0.0752,
      "step": 2070
    },
    {
      "epoch": 0.8397254743641501,
      "grad_norm": 10.995793342590332,
      "learning_rate": 1.9160274525635852e-05,
      "loss": 0.0954,
      "step": 2080
    },
    {
      "epoch": 0.843762616067824,
      "grad_norm": 7.7206597328186035,
      "learning_rate": 1.9156237383932177e-05,
      "loss": 0.1286,
      "step": 2090
    },
    {
      "epoch": 0.8477997577714977,
      "grad_norm": 13.025567054748535,
      "learning_rate": 1.9152200242228505e-05,
      "loss": 0.1693,
      "step": 2100
    },
    {
      "epoch": 0.8518368994751716,
      "grad_norm": 2.997126579284668,
      "learning_rate": 1.914816310052483e-05,
      "loss": 0.0938,
      "step": 2110
    },
    {
      "epoch": 0.8558740411788454,
      "grad_norm": 11.695396423339844,
      "learning_rate": 1.9144125958821158e-05,
      "loss": 0.1885,
      "step": 2120
    },
    {
      "epoch": 0.8599111828825192,
      "grad_norm": 8.558727264404297,
      "learning_rate": 1.9140088817117482e-05,
      "loss": 0.1073,
      "step": 2130
    },
    {
      "epoch": 0.863948324586193,
      "grad_norm": 10.851404190063477,
      "learning_rate": 1.913605167541381e-05,
      "loss": 0.1275,
      "step": 2140
    },
    {
      "epoch": 0.8679854662898667,
      "grad_norm": 14.367414474487305,
      "learning_rate": 1.9132014533710135e-05,
      "loss": 0.1416,
      "step": 2150
    },
    {
      "epoch": 0.8720226079935406,
      "grad_norm": 6.882972240447998,
      "learning_rate": 1.912797739200646e-05,
      "loss": 0.1006,
      "step": 2160
    },
    {
      "epoch": 0.8760597496972143,
      "grad_norm": 4.699747085571289,
      "learning_rate": 1.9123940250302787e-05,
      "loss": 0.1103,
      "step": 2170
    },
    {
      "epoch": 0.8800968914008882,
      "grad_norm": 4.850769519805908,
      "learning_rate": 1.9119903108599115e-05,
      "loss": 0.1408,
      "step": 2180
    },
    {
      "epoch": 0.884134033104562,
      "grad_norm": 7.263097286224365,
      "learning_rate": 1.911586596689544e-05,
      "loss": 0.1129,
      "step": 2190
    },
    {
      "epoch": 0.8881711748082358,
      "grad_norm": 3.078639030456543,
      "learning_rate": 1.9111828825191764e-05,
      "loss": 0.0472,
      "step": 2200
    },
    {
      "epoch": 0.8922083165119096,
      "grad_norm": 6.258382320404053,
      "learning_rate": 1.9107791683488092e-05,
      "loss": 0.1155,
      "step": 2210
    },
    {
      "epoch": 0.8962454582155833,
      "grad_norm": 0.9533706903457642,
      "learning_rate": 1.9103754541784417e-05,
      "loss": 0.1852,
      "step": 2220
    },
    {
      "epoch": 0.9002825999192572,
      "grad_norm": 5.1776227951049805,
      "learning_rate": 1.9099717400080745e-05,
      "loss": 0.1196,
      "step": 2230
    },
    {
      "epoch": 0.9043197416229309,
      "grad_norm": 4.375617504119873,
      "learning_rate": 1.909568025837707e-05,
      "loss": 0.0666,
      "step": 2240
    },
    {
      "epoch": 0.9083568833266048,
      "grad_norm": 8.331934928894043,
      "learning_rate": 1.9091643116673398e-05,
      "loss": 0.1322,
      "step": 2250
    },
    {
      "epoch": 0.9123940250302786,
      "grad_norm": 4.990726470947266,
      "learning_rate": 1.9087605974969722e-05,
      "loss": 0.1786,
      "step": 2260
    },
    {
      "epoch": 0.9164311667339523,
      "grad_norm": 8.64992904663086,
      "learning_rate": 1.908356883326605e-05,
      "loss": 0.0957,
      "step": 2270
    },
    {
      "epoch": 0.9204683084376262,
      "grad_norm": 1.6286964416503906,
      "learning_rate": 1.9079531691562375e-05,
      "loss": 0.1702,
      "step": 2280
    },
    {
      "epoch": 0.9245054501412999,
      "grad_norm": 5.5652289390563965,
      "learning_rate": 1.9075494549858703e-05,
      "loss": 0.1384,
      "step": 2290
    },
    {
      "epoch": 0.9285425918449738,
      "grad_norm": 5.500596046447754,
      "learning_rate": 1.9071457408155027e-05,
      "loss": 0.0792,
      "step": 2300
    },
    {
      "epoch": 0.9325797335486475,
      "grad_norm": 1.9619781970977783,
      "learning_rate": 1.9067420266451352e-05,
      "loss": 0.0821,
      "step": 2310
    },
    {
      "epoch": 0.9366168752523214,
      "grad_norm": 0.3608243763446808,
      "learning_rate": 1.906338312474768e-05,
      "loss": 0.1214,
      "step": 2320
    },
    {
      "epoch": 0.9406540169559952,
      "grad_norm": 3.9700634479522705,
      "learning_rate": 1.9059345983044008e-05,
      "loss": 0.109,
      "step": 2330
    },
    {
      "epoch": 0.9446911586596689,
      "grad_norm": 1.3179738521575928,
      "learning_rate": 1.9055308841340332e-05,
      "loss": 0.082,
      "step": 2340
    },
    {
      "epoch": 0.9487283003633428,
      "grad_norm": 9.671677589416504,
      "learning_rate": 1.905127169963666e-05,
      "loss": 0.1662,
      "step": 2350
    },
    {
      "epoch": 0.9527654420670165,
      "grad_norm": 6.156385898590088,
      "learning_rate": 1.9047234557932985e-05,
      "loss": 0.1038,
      "step": 2360
    },
    {
      "epoch": 0.9568025837706904,
      "grad_norm": 4.150074481964111,
      "learning_rate": 1.904319741622931e-05,
      "loss": 0.0953,
      "step": 2370
    },
    {
      "epoch": 0.9608397254743641,
      "grad_norm": 5.909424304962158,
      "learning_rate": 1.9039160274525638e-05,
      "loss": 0.1216,
      "step": 2380
    },
    {
      "epoch": 0.964876867178038,
      "grad_norm": 0.08628471940755844,
      "learning_rate": 1.9035123132821966e-05,
      "loss": 0.149,
      "step": 2390
    },
    {
      "epoch": 0.9689140088817118,
      "grad_norm": 9.47997760772705,
      "learning_rate": 1.903108599111829e-05,
      "loss": 0.0532,
      "step": 2400
    },
    {
      "epoch": 0.9729511505853855,
      "grad_norm": 97.71588134765625,
      "learning_rate": 1.9027048849414615e-05,
      "loss": 0.0895,
      "step": 2410
    },
    {
      "epoch": 0.9769882922890594,
      "grad_norm": 0.7054836750030518,
      "learning_rate": 1.9023011707710943e-05,
      "loss": 0.1045,
      "step": 2420
    },
    {
      "epoch": 0.9810254339927331,
      "grad_norm": 0.02381771057844162,
      "learning_rate": 1.9018974566007267e-05,
      "loss": 0.0669,
      "step": 2430
    },
    {
      "epoch": 0.985062575696407,
      "grad_norm": 5.493979454040527,
      "learning_rate": 1.9014937424303595e-05,
      "loss": 0.1537,
      "step": 2440
    },
    {
      "epoch": 0.9890997174000807,
      "grad_norm": 4.511861801147461,
      "learning_rate": 1.901090028259992e-05,
      "loss": 0.0246,
      "step": 2450
    },
    {
      "epoch": 0.9931368591037545,
      "grad_norm": 2.8255743980407715,
      "learning_rate": 1.9006863140896248e-05,
      "loss": 0.1292,
      "step": 2460
    },
    {
      "epoch": 0.9971740008074284,
      "grad_norm": 10.522472381591797,
      "learning_rate": 1.9002825999192572e-05,
      "loss": 0.0458,
      "step": 2470
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9702830188679246,
      "eval_f1": 0.89505830094392,
      "eval_loss": 0.09872080385684967,
      "eval_precision": 0.8657357679914071,
      "eval_recall": 0.9264367816091954,
      "eval_runtime": 445.4169,
      "eval_samples_per_second": 28.602,
      "eval_steps_per_second": 1.192,
      "step": 2477
    },
    {
      "epoch": 1.001211142511102,
      "grad_norm": 3.983034372329712,
      "learning_rate": 1.89987888574889e-05,
      "loss": 0.1077,
      "step": 2480
    },
    {
      "epoch": 1.0052482842147759,
      "grad_norm": 0.5556391477584839,
      "learning_rate": 1.8994751715785225e-05,
      "loss": 0.0388,
      "step": 2490
    },
    {
      "epoch": 1.0092854259184498,
      "grad_norm": 7.3547492027282715,
      "learning_rate": 1.8990714574081553e-05,
      "loss": 0.0911,
      "step": 2500
    },
    {
      "epoch": 1.0133225676221236,
      "grad_norm": 0.05282486975193024,
      "learning_rate": 1.8986677432377878e-05,
      "loss": 0.0726,
      "step": 2510
    },
    {
      "epoch": 1.0173597093257973,
      "grad_norm": 0.29431238770484924,
      "learning_rate": 1.8982640290674202e-05,
      "loss": 0.0586,
      "step": 2520
    },
    {
      "epoch": 1.021396851029471,
      "grad_norm": 5.61954927444458,
      "learning_rate": 1.897860314897053e-05,
      "loss": 0.0884,
      "step": 2530
    },
    {
      "epoch": 1.0254339927331448,
      "grad_norm": 0.8197753429412842,
      "learning_rate": 1.8974566007266858e-05,
      "loss": 0.1131,
      "step": 2540
    },
    {
      "epoch": 1.0294711344368188,
      "grad_norm": 0.10769902169704437,
      "learning_rate": 1.8970528865563183e-05,
      "loss": 0.1022,
      "step": 2550
    },
    {
      "epoch": 1.0335082761404926,
      "grad_norm": 1.2862780094146729,
      "learning_rate": 1.8966491723859507e-05,
      "loss": 0.0259,
      "step": 2560
    },
    {
      "epoch": 1.0375454178441663,
      "grad_norm": 1.2850981950759888,
      "learning_rate": 1.8962454582155835e-05,
      "loss": 0.0873,
      "step": 2570
    },
    {
      "epoch": 1.04158255954784,
      "grad_norm": 0.3473874032497406,
      "learning_rate": 1.895841744045216e-05,
      "loss": 0.0741,
      "step": 2580
    },
    {
      "epoch": 1.0456197012515138,
      "grad_norm": 10.9734525680542,
      "learning_rate": 1.8954380298748488e-05,
      "loss": 0.0735,
      "step": 2590
    },
    {
      "epoch": 1.0496568429551878,
      "grad_norm": 1.0133544206619263,
      "learning_rate": 1.8950343157044816e-05,
      "loss": 0.0609,
      "step": 2600
    },
    {
      "epoch": 1.0536939846588615,
      "grad_norm": 0.31022417545318604,
      "learning_rate": 1.894630601534114e-05,
      "loss": 0.0465,
      "step": 2610
    },
    {
      "epoch": 1.0577311263625353,
      "grad_norm": 2.6146249771118164,
      "learning_rate": 1.8942268873637465e-05,
      "loss": 0.0707,
      "step": 2620
    },
    {
      "epoch": 1.061768268066209,
      "grad_norm": 6.0666069984436035,
      "learning_rate": 1.8938231731933793e-05,
      "loss": 0.0287,
      "step": 2630
    },
    {
      "epoch": 1.065805409769883,
      "grad_norm": 3.847822904586792,
      "learning_rate": 1.893419459023012e-05,
      "loss": 0.038,
      "step": 2640
    },
    {
      "epoch": 1.0698425514735568,
      "grad_norm": 0.12493948638439178,
      "learning_rate": 1.8930157448526446e-05,
      "loss": 0.0686,
      "step": 2650
    },
    {
      "epoch": 1.0738796931772305,
      "grad_norm": 0.08887027204036713,
      "learning_rate": 1.892612030682277e-05,
      "loss": 0.0759,
      "step": 2660
    },
    {
      "epoch": 1.0779168348809043,
      "grad_norm": 0.2785246968269348,
      "learning_rate": 1.8922083165119095e-05,
      "loss": 0.0518,
      "step": 2670
    },
    {
      "epoch": 1.081953976584578,
      "grad_norm": 11.271309852600098,
      "learning_rate": 1.8918046023415423e-05,
      "loss": 0.1365,
      "step": 2680
    },
    {
      "epoch": 1.085991118288252,
      "grad_norm": 6.949279308319092,
      "learning_rate": 1.891400888171175e-05,
      "loss": 0.1021,
      "step": 2690
    },
    {
      "epoch": 1.0900282599919258,
      "grad_norm": 2.749448776245117,
      "learning_rate": 1.8909971740008075e-05,
      "loss": 0.039,
      "step": 2700
    },
    {
      "epoch": 1.0940654016955995,
      "grad_norm": 5.777152061462402,
      "learning_rate": 1.8905934598304403e-05,
      "loss": 0.1064,
      "step": 2710
    },
    {
      "epoch": 1.0981025433992733,
      "grad_norm": 55.30674362182617,
      "learning_rate": 1.8901897456600728e-05,
      "loss": 0.0691,
      "step": 2720
    },
    {
      "epoch": 1.102139685102947,
      "grad_norm": 0.3337481617927551,
      "learning_rate": 1.8897860314897053e-05,
      "loss": 0.0748,
      "step": 2730
    },
    {
      "epoch": 1.106176826806621,
      "grad_norm": 2.6748642921447754,
      "learning_rate": 1.889382317319338e-05,
      "loss": 0.0801,
      "step": 2740
    },
    {
      "epoch": 1.1102139685102947,
      "grad_norm": 1.313663363456726,
      "learning_rate": 1.888978603148971e-05,
      "loss": 0.0571,
      "step": 2750
    },
    {
      "epoch": 1.1142511102139685,
      "grad_norm": 6.335641860961914,
      "learning_rate": 1.8885748889786033e-05,
      "loss": 0.1028,
      "step": 2760
    },
    {
      "epoch": 1.1182882519176423,
      "grad_norm": 3.188126564025879,
      "learning_rate": 1.8881711748082358e-05,
      "loss": 0.0658,
      "step": 2770
    },
    {
      "epoch": 1.122325393621316,
      "grad_norm": 8.916508674621582,
      "learning_rate": 1.8877674606378686e-05,
      "loss": 0.0969,
      "step": 2780
    },
    {
      "epoch": 1.12636253532499,
      "grad_norm": 0.14739488065242767,
      "learning_rate": 1.8873637464675014e-05,
      "loss": 0.0807,
      "step": 2790
    },
    {
      "epoch": 1.1303996770286637,
      "grad_norm": 1.2220780849456787,
      "learning_rate": 1.8869600322971338e-05,
      "loss": 0.1169,
      "step": 2800
    },
    {
      "epoch": 1.1344368187323375,
      "grad_norm": 10.407272338867188,
      "learning_rate": 1.8865563181267663e-05,
      "loss": 0.0922,
      "step": 2810
    },
    {
      "epoch": 1.1384739604360112,
      "grad_norm": 10.256190299987793,
      "learning_rate": 1.886152603956399e-05,
      "loss": 0.1398,
      "step": 2820
    },
    {
      "epoch": 1.142511102139685,
      "grad_norm": 5.859317302703857,
      "learning_rate": 1.8857488897860315e-05,
      "loss": 0.0941,
      "step": 2830
    },
    {
      "epoch": 1.146548243843359,
      "grad_norm": 1.34792959690094,
      "learning_rate": 1.8853451756156643e-05,
      "loss": 0.1088,
      "step": 2840
    },
    {
      "epoch": 1.1505853855470327,
      "grad_norm": 5.503056526184082,
      "learning_rate": 1.884941461445297e-05,
      "loss": 0.0862,
      "step": 2850
    },
    {
      "epoch": 1.1546225272507065,
      "grad_norm": 6.733094692230225,
      "learning_rate": 1.8845377472749296e-05,
      "loss": 0.1016,
      "step": 2860
    },
    {
      "epoch": 1.1586596689543802,
      "grad_norm": 1.2414828538894653,
      "learning_rate": 1.884134033104562e-05,
      "loss": 0.0283,
      "step": 2870
    },
    {
      "epoch": 1.1626968106580542,
      "grad_norm": 0.7545153498649597,
      "learning_rate": 1.8837303189341945e-05,
      "loss": 0.0272,
      "step": 2880
    },
    {
      "epoch": 1.166733952361728,
      "grad_norm": 0.05993303284049034,
      "learning_rate": 1.8833266047638273e-05,
      "loss": 0.0916,
      "step": 2890
    },
    {
      "epoch": 1.1707710940654017,
      "grad_norm": 0.7173922061920166,
      "learning_rate": 1.88292289059346e-05,
      "loss": 0.0357,
      "step": 2900
    },
    {
      "epoch": 1.1748082357690754,
      "grad_norm": 18.30394172668457,
      "learning_rate": 1.8825191764230926e-05,
      "loss": 0.0866,
      "step": 2910
    },
    {
      "epoch": 1.1788453774727492,
      "grad_norm": 5.647458553314209,
      "learning_rate": 1.882115462252725e-05,
      "loss": 0.0983,
      "step": 2920
    },
    {
      "epoch": 1.1828825191764232,
      "grad_norm": 2.1881015300750732,
      "learning_rate": 1.8817117480823578e-05,
      "loss": 0.066,
      "step": 2930
    },
    {
      "epoch": 1.186919660880097,
      "grad_norm": 0.7877639532089233,
      "learning_rate": 1.8813080339119906e-05,
      "loss": 0.0928,
      "step": 2940
    },
    {
      "epoch": 1.1909568025837707,
      "grad_norm": 2.790416955947876,
      "learning_rate": 1.880904319741623e-05,
      "loss": 0.039,
      "step": 2950
    },
    {
      "epoch": 1.1949939442874444,
      "grad_norm": 4.1729350090026855,
      "learning_rate": 1.880500605571256e-05,
      "loss": 0.0535,
      "step": 2960
    },
    {
      "epoch": 1.1990310859911184,
      "grad_norm": 8.68192195892334,
      "learning_rate": 1.8800968914008883e-05,
      "loss": 0.0487,
      "step": 2970
    },
    {
      "epoch": 1.2030682276947922,
      "grad_norm": 1.2788699865341187,
      "learning_rate": 1.8796931772305208e-05,
      "loss": 0.0565,
      "step": 2980
    },
    {
      "epoch": 1.207105369398466,
      "grad_norm": 0.014595442451536655,
      "learning_rate": 1.8792894630601536e-05,
      "loss": 0.0717,
      "step": 2990
    },
    {
      "epoch": 1.2111425111021397,
      "grad_norm": 0.25244927406311035,
      "learning_rate": 1.8788857488897864e-05,
      "loss": 0.0478,
      "step": 3000
    },
    {
      "epoch": 1.2151796528058134,
      "grad_norm": 6.059257507324219,
      "learning_rate": 1.878482034719419e-05,
      "loss": 0.0945,
      "step": 3010
    },
    {
      "epoch": 1.2192167945094874,
      "grad_norm": 2.872877836227417,
      "learning_rate": 1.8780783205490513e-05,
      "loss": 0.0864,
      "step": 3020
    },
    {
      "epoch": 1.2232539362131611,
      "grad_norm": 0.13988633453845978,
      "learning_rate": 1.877674606378684e-05,
      "loss": 0.1445,
      "step": 3030
    },
    {
      "epoch": 1.227291077916835,
      "grad_norm": 0.06997045129537582,
      "learning_rate": 1.8772708922083166e-05,
      "loss": 0.0577,
      "step": 3040
    },
    {
      "epoch": 1.2313282196205086,
      "grad_norm": 4.283986568450928,
      "learning_rate": 1.8768671780379494e-05,
      "loss": 0.0593,
      "step": 3050
    },
    {
      "epoch": 1.2353653613241824,
      "grad_norm": 4.368648529052734,
      "learning_rate": 1.876463463867582e-05,
      "loss": 0.0874,
      "step": 3060
    },
    {
      "epoch": 1.2394025030278564,
      "grad_norm": 0.40404513478279114,
      "learning_rate": 1.8760597496972146e-05,
      "loss": 0.1208,
      "step": 3070
    },
    {
      "epoch": 1.2434396447315301,
      "grad_norm": 3.8353943824768066,
      "learning_rate": 1.875656035526847e-05,
      "loss": 0.0459,
      "step": 3080
    },
    {
      "epoch": 1.2474767864352039,
      "grad_norm": 3.302515983581543,
      "learning_rate": 1.87525232135648e-05,
      "loss": 0.0729,
      "step": 3090
    },
    {
      "epoch": 1.2515139281388776,
      "grad_norm": 3.0995638370513916,
      "learning_rate": 1.8748486071861123e-05,
      "loss": 0.0464,
      "step": 3100
    },
    {
      "epoch": 1.2555510698425514,
      "grad_norm": 0.7952812314033508,
      "learning_rate": 1.874444893015745e-05,
      "loss": 0.0842,
      "step": 3110
    },
    {
      "epoch": 1.2595882115462254,
      "grad_norm": 1.9140516519546509,
      "learning_rate": 1.8740411788453776e-05,
      "loss": 0.1463,
      "step": 3120
    },
    {
      "epoch": 1.263625353249899,
      "grad_norm": 0.05227689817547798,
      "learning_rate": 1.87363746467501e-05,
      "loss": 0.0877,
      "step": 3130
    },
    {
      "epoch": 1.2676624949535729,
      "grad_norm": 5.711827278137207,
      "learning_rate": 1.873233750504643e-05,
      "loss": 0.0535,
      "step": 3140
    },
    {
      "epoch": 1.2716996366572466,
      "grad_norm": 3.7930545806884766,
      "learning_rate": 1.8728300363342757e-05,
      "loss": 0.0557,
      "step": 3150
    },
    {
      "epoch": 1.2757367783609204,
      "grad_norm": 10.85129451751709,
      "learning_rate": 1.872426322163908e-05,
      "loss": 0.1142,
      "step": 3160
    },
    {
      "epoch": 1.2797739200645943,
      "grad_norm": 5.0942511558532715,
      "learning_rate": 1.8720226079935406e-05,
      "loss": 0.0884,
      "step": 3170
    },
    {
      "epoch": 1.283811061768268,
      "grad_norm": 2.0127651691436768,
      "learning_rate": 1.8716188938231734e-05,
      "loss": 0.0744,
      "step": 3180
    },
    {
      "epoch": 1.2878482034719418,
      "grad_norm": 2.5613369941711426,
      "learning_rate": 1.871215179652806e-05,
      "loss": 0.0789,
      "step": 3190
    },
    {
      "epoch": 1.2918853451756156,
      "grad_norm": 0.7333980202674866,
      "learning_rate": 1.8708114654824386e-05,
      "loss": 0.0983,
      "step": 3200
    },
    {
      "epoch": 1.2959224868792893,
      "grad_norm": 0.731738805770874,
      "learning_rate": 1.8704077513120714e-05,
      "loss": 0.0996,
      "step": 3210
    },
    {
      "epoch": 1.2999596285829633,
      "grad_norm": 5.173943042755127,
      "learning_rate": 1.870004037141704e-05,
      "loss": 0.0999,
      "step": 3220
    },
    {
      "epoch": 1.303996770286637,
      "grad_norm": 6.021742820739746,
      "learning_rate": 1.8696003229713364e-05,
      "loss": 0.0772,
      "step": 3230
    },
    {
      "epoch": 1.3080339119903108,
      "grad_norm": 7.311779499053955,
      "learning_rate": 1.869196608800969e-05,
      "loss": 0.095,
      "step": 3240
    },
    {
      "epoch": 1.3120710536939846,
      "grad_norm": 13.817401885986328,
      "learning_rate": 1.8687928946306016e-05,
      "loss": 0.1491,
      "step": 3250
    },
    {
      "epoch": 1.3161081953976583,
      "grad_norm": 14.045305252075195,
      "learning_rate": 1.8683891804602344e-05,
      "loss": 0.0682,
      "step": 3260
    },
    {
      "epoch": 1.3201453371013323,
      "grad_norm": 4.103174686431885,
      "learning_rate": 1.867985466289867e-05,
      "loss": 0.0119,
      "step": 3270
    },
    {
      "epoch": 1.324182478805006,
      "grad_norm": 10.494582176208496,
      "learning_rate": 1.8675817521194997e-05,
      "loss": 0.0911,
      "step": 3280
    },
    {
      "epoch": 1.3282196205086798,
      "grad_norm": 8.170334815979004,
      "learning_rate": 1.867178037949132e-05,
      "loss": 0.1089,
      "step": 3290
    },
    {
      "epoch": 1.3322567622123538,
      "grad_norm": 8.012077331542969,
      "learning_rate": 1.866774323778765e-05,
      "loss": 0.0948,
      "step": 3300
    },
    {
      "epoch": 1.3362939039160273,
      "grad_norm": 1.9305917024612427,
      "learning_rate": 1.8663706096083974e-05,
      "loss": 0.0638,
      "step": 3310
    },
    {
      "epoch": 1.3403310456197013,
      "grad_norm": 4.230148792266846,
      "learning_rate": 1.8659668954380302e-05,
      "loss": 0.0517,
      "step": 3320
    },
    {
      "epoch": 1.344368187323375,
      "grad_norm": 8.48487377166748,
      "learning_rate": 1.8655631812676626e-05,
      "loss": 0.0783,
      "step": 3330
    },
    {
      "epoch": 1.3484053290270488,
      "grad_norm": 2.1739308834075928,
      "learning_rate": 1.865159467097295e-05,
      "loss": 0.0265,
      "step": 3340
    },
    {
      "epoch": 1.3524424707307228,
      "grad_norm": 4.647208213806152,
      "learning_rate": 1.864755752926928e-05,
      "loss": 0.101,
      "step": 3350
    },
    {
      "epoch": 1.3564796124343965,
      "grad_norm": 12.122150421142578,
      "learning_rate": 1.8643520387565607e-05,
      "loss": 0.0509,
      "step": 3360
    },
    {
      "epoch": 1.3605167541380703,
      "grad_norm": 0.24248793721199036,
      "learning_rate": 1.863948324586193e-05,
      "loss": 0.0936,
      "step": 3370
    },
    {
      "epoch": 1.364553895841744,
      "grad_norm": 0.21963410079479218,
      "learning_rate": 1.8635446104158256e-05,
      "loss": 0.0294,
      "step": 3380
    },
    {
      "epoch": 1.3685910375454178,
      "grad_norm": 3.172605037689209,
      "learning_rate": 1.8631408962454584e-05,
      "loss": 0.069,
      "step": 3390
    },
    {
      "epoch": 1.3726281792490918,
      "grad_norm": 0.1746700257062912,
      "learning_rate": 1.862737182075091e-05,
      "loss": 0.076,
      "step": 3400
    },
    {
      "epoch": 1.3766653209527655,
      "grad_norm": 0.047463901340961456,
      "learning_rate": 1.8623334679047237e-05,
      "loss": 0.0415,
      "step": 3410
    },
    {
      "epoch": 1.3807024626564393,
      "grad_norm": 0.09354295581579208,
      "learning_rate": 1.861929753734356e-05,
      "loss": 0.096,
      "step": 3420
    },
    {
      "epoch": 1.384739604360113,
      "grad_norm": 12.007442474365234,
      "learning_rate": 1.861526039563989e-05,
      "loss": 0.0897,
      "step": 3430
    },
    {
      "epoch": 1.3887767460637868,
      "grad_norm": 0.783820390701294,
      "learning_rate": 1.8611223253936214e-05,
      "loss": 0.0617,
      "step": 3440
    },
    {
      "epoch": 1.3928138877674607,
      "grad_norm": 10.015615463256836,
      "learning_rate": 1.8607186112232542e-05,
      "loss": 0.1259,
      "step": 3450
    },
    {
      "epoch": 1.3968510294711345,
      "grad_norm": 1.795286774635315,
      "learning_rate": 1.860314897052887e-05,
      "loss": 0.0463,
      "step": 3460
    },
    {
      "epoch": 1.4008881711748082,
      "grad_norm": 9.472810745239258,
      "learning_rate": 1.8599111828825194e-05,
      "loss": 0.1182,
      "step": 3470
    },
    {
      "epoch": 1.404925312878482,
      "grad_norm": 1.0377556085586548,
      "learning_rate": 1.859507468712152e-05,
      "loss": 0.0335,
      "step": 3480
    },
    {
      "epoch": 1.4089624545821557,
      "grad_norm": 3.0626320838928223,
      "learning_rate": 1.8591037545417844e-05,
      "loss": 0.055,
      "step": 3490
    },
    {
      "epoch": 1.4129995962858297,
      "grad_norm": 0.6531855463981628,
      "learning_rate": 1.858700040371417e-05,
      "loss": 0.037,
      "step": 3500
    },
    {
      "epoch": 1.4170367379895035,
      "grad_norm": 2.580965042114258,
      "learning_rate": 1.85829632620105e-05,
      "loss": 0.0353,
      "step": 3510
    },
    {
      "epoch": 1.4210738796931772,
      "grad_norm": 3.8761680126190186,
      "learning_rate": 1.8578926120306824e-05,
      "loss": 0.0748,
      "step": 3520
    },
    {
      "epoch": 1.425111021396851,
      "grad_norm": 0.5310941338539124,
      "learning_rate": 1.857488897860315e-05,
      "loss": 0.0247,
      "step": 3530
    },
    {
      "epoch": 1.4291481631005247,
      "grad_norm": 0.38192248344421387,
      "learning_rate": 1.8570851836899477e-05,
      "loss": 0.0556,
      "step": 3540
    },
    {
      "epoch": 1.4331853048041987,
      "grad_norm": 12.591996192932129,
      "learning_rate": 1.85668146951958e-05,
      "loss": 0.0484,
      "step": 3550
    },
    {
      "epoch": 1.4372224465078725,
      "grad_norm": 10.937806129455566,
      "learning_rate": 1.856277755349213e-05,
      "loss": 0.128,
      "step": 3560
    },
    {
      "epoch": 1.4412595882115462,
      "grad_norm": 0.04088008403778076,
      "learning_rate": 1.8558740411788457e-05,
      "loss": 0.1083,
      "step": 3570
    },
    {
      "epoch": 1.44529672991522,
      "grad_norm": 8.952812194824219,
      "learning_rate": 1.8554703270084782e-05,
      "loss": 0.0338,
      "step": 3580
    },
    {
      "epoch": 1.4493338716188937,
      "grad_norm": 9.573286056518555,
      "learning_rate": 1.8550666128381106e-05,
      "loss": 0.0804,
      "step": 3590
    },
    {
      "epoch": 1.4533710133225677,
      "grad_norm": 0.5293586254119873,
      "learning_rate": 1.8546628986677434e-05,
      "loss": 0.0904,
      "step": 3600
    },
    {
      "epoch": 1.4574081550262414,
      "grad_norm": 3.155487298965454,
      "learning_rate": 1.8542591844973762e-05,
      "loss": 0.0992,
      "step": 3610
    },
    {
      "epoch": 1.4614452967299152,
      "grad_norm": 0.3122557997703552,
      "learning_rate": 1.8538554703270087e-05,
      "loss": 0.1047,
      "step": 3620
    },
    {
      "epoch": 1.465482438433589,
      "grad_norm": 6.058115005493164,
      "learning_rate": 1.853451756156641e-05,
      "loss": 0.0953,
      "step": 3630
    },
    {
      "epoch": 1.4695195801372627,
      "grad_norm": 0.6235564947128296,
      "learning_rate": 1.853048041986274e-05,
      "loss": 0.0506,
      "step": 3640
    },
    {
      "epoch": 1.4735567218409367,
      "grad_norm": 7.765923500061035,
      "learning_rate": 1.8526443278159064e-05,
      "loss": 0.0747,
      "step": 3650
    },
    {
      "epoch": 1.4775938635446104,
      "grad_norm": 1.5256630182266235,
      "learning_rate": 1.8522406136455392e-05,
      "loss": 0.0991,
      "step": 3660
    },
    {
      "epoch": 1.4816310052482842,
      "grad_norm": 6.151076793670654,
      "learning_rate": 1.8518368994751717e-05,
      "loss": 0.0702,
      "step": 3670
    },
    {
      "epoch": 1.4856681469519581,
      "grad_norm": 5.139127731323242,
      "learning_rate": 1.8514331853048045e-05,
      "loss": 0.0372,
      "step": 3680
    },
    {
      "epoch": 1.4897052886556317,
      "grad_norm": 0.17301876842975616,
      "learning_rate": 1.851029471134437e-05,
      "loss": 0.0726,
      "step": 3690
    },
    {
      "epoch": 1.4937424303593057,
      "grad_norm": 13.461207389831543,
      "learning_rate": 1.8506257569640694e-05,
      "loss": 0.0724,
      "step": 3700
    },
    {
      "epoch": 1.4977795720629794,
      "grad_norm": 0.5443107485771179,
      "learning_rate": 1.8502220427937022e-05,
      "loss": 0.0386,
      "step": 3710
    },
    {
      "epoch": 1.5018167137666532,
      "grad_norm": 0.02081654593348503,
      "learning_rate": 1.849818328623335e-05,
      "loss": 0.0511,
      "step": 3720
    },
    {
      "epoch": 1.5058538554703271,
      "grad_norm": 4.084422588348389,
      "learning_rate": 1.8494146144529674e-05,
      "loss": 0.0561,
      "step": 3730
    },
    {
      "epoch": 1.5098909971740007,
      "grad_norm": 8.828242301940918,
      "learning_rate": 1.8490109002826e-05,
      "loss": 0.0744,
      "step": 3740
    },
    {
      "epoch": 1.5139281388776746,
      "grad_norm": 10.752327919006348,
      "learning_rate": 1.8486071861122327e-05,
      "loss": 0.081,
      "step": 3750
    },
    {
      "epoch": 1.5179652805813484,
      "grad_norm": 0.01931813545525074,
      "learning_rate": 1.8482034719418655e-05,
      "loss": 0.0969,
      "step": 3760
    },
    {
      "epoch": 1.5220024222850221,
      "grad_norm": 0.6380029320716858,
      "learning_rate": 1.847799757771498e-05,
      "loss": 0.052,
      "step": 3770
    },
    {
      "epoch": 1.5260395639886961,
      "grad_norm": 9.635918617248535,
      "learning_rate": 1.8473960436011304e-05,
      "loss": 0.1129,
      "step": 3780
    },
    {
      "epoch": 1.5300767056923696,
      "grad_norm": 0.03187950327992439,
      "learning_rate": 1.8469923294307632e-05,
      "loss": 0.0771,
      "step": 3790
    },
    {
      "epoch": 1.5341138473960436,
      "grad_norm": 6.693275451660156,
      "learning_rate": 1.8465886152603957e-05,
      "loss": 0.0689,
      "step": 3800
    },
    {
      "epoch": 1.5381509890997174,
      "grad_norm": 1.7400621175765991,
      "learning_rate": 1.8461849010900285e-05,
      "loss": 0.0245,
      "step": 3810
    },
    {
      "epoch": 1.5421881308033911,
      "grad_norm": 6.019394874572754,
      "learning_rate": 1.8457811869196613e-05,
      "loss": 0.0989,
      "step": 3820
    },
    {
      "epoch": 1.546225272507065,
      "grad_norm": 1.4485483169555664,
      "learning_rate": 1.8453774727492937e-05,
      "loss": 0.0217,
      "step": 3830
    },
    {
      "epoch": 1.5502624142107388,
      "grad_norm": 0.2242346853017807,
      "learning_rate": 1.8449737585789262e-05,
      "loss": 0.0645,
      "step": 3840
    },
    {
      "epoch": 1.5542995559144126,
      "grad_norm": 0.03636619821190834,
      "learning_rate": 1.8445700444085587e-05,
      "loss": 0.099,
      "step": 3850
    },
    {
      "epoch": 1.5583366976180864,
      "grad_norm": 1.4782930612564087,
      "learning_rate": 1.8441663302381914e-05,
      "loss": 0.1173,
      "step": 3860
    },
    {
      "epoch": 1.56237383932176,
      "grad_norm": 0.14050839841365814,
      "learning_rate": 1.8437626160678242e-05,
      "loss": 0.1554,
      "step": 3870
    },
    {
      "epoch": 1.566410981025434,
      "grad_norm": 0.40116044878959656,
      "learning_rate": 1.8433589018974567e-05,
      "loss": 0.0674,
      "step": 3880
    },
    {
      "epoch": 1.5704481227291078,
      "grad_norm": 0.3179764151573181,
      "learning_rate": 1.8429551877270895e-05,
      "loss": 0.0874,
      "step": 3890
    },
    {
      "epoch": 1.5744852644327816,
      "grad_norm": 5.6640777587890625,
      "learning_rate": 1.842551473556722e-05,
      "loss": 0.0458,
      "step": 3900
    },
    {
      "epoch": 1.5785224061364553,
      "grad_norm": 8.992898941040039,
      "learning_rate": 1.8421477593863548e-05,
      "loss": 0.1068,
      "step": 3910
    },
    {
      "epoch": 1.582559547840129,
      "grad_norm": 0.2724994421005249,
      "learning_rate": 1.8417440452159872e-05,
      "loss": 0.0499,
      "step": 3920
    },
    {
      "epoch": 1.586596689543803,
      "grad_norm": 4.746088981628418,
      "learning_rate": 1.84134033104562e-05,
      "loss": 0.1465,
      "step": 3930
    },
    {
      "epoch": 1.5906338312474768,
      "grad_norm": 4.370208263397217,
      "learning_rate": 1.8409366168752525e-05,
      "loss": 0.0389,
      "step": 3940
    },
    {
      "epoch": 1.5946709729511506,
      "grad_norm": 6.5944013595581055,
      "learning_rate": 1.840532902704885e-05,
      "loss": 0.1091,
      "step": 3950
    },
    {
      "epoch": 1.5987081146548245,
      "grad_norm": 0.04238724708557129,
      "learning_rate": 1.8401291885345177e-05,
      "loss": 0.0337,
      "step": 3960
    },
    {
      "epoch": 1.602745256358498,
      "grad_norm": 1.4085801839828491,
      "learning_rate": 1.8397254743641505e-05,
      "loss": 0.0639,
      "step": 3970
    },
    {
      "epoch": 1.606782398062172,
      "grad_norm": 0.9100654125213623,
      "learning_rate": 1.839321760193783e-05,
      "loss": 0.0515,
      "step": 3980
    },
    {
      "epoch": 1.6108195397658458,
      "grad_norm": 0.5323731303215027,
      "learning_rate": 1.8389180460234155e-05,
      "loss": 0.0159,
      "step": 3990
    },
    {
      "epoch": 1.6148566814695196,
      "grad_norm": 0.05152669921517372,
      "learning_rate": 1.8385143318530483e-05,
      "loss": 0.0813,
      "step": 4000
    },
    {
      "epoch": 1.6188938231731935,
      "grad_norm": 0.8747943639755249,
      "learning_rate": 1.8381106176826807e-05,
      "loss": 0.0713,
      "step": 4010
    },
    {
      "epoch": 1.622930964876867,
      "grad_norm": 5.079986095428467,
      "learning_rate": 1.8377069035123135e-05,
      "loss": 0.1216,
      "step": 4020
    },
    {
      "epoch": 1.626968106580541,
      "grad_norm": 14.835662841796875,
      "learning_rate": 1.837303189341946e-05,
      "loss": 0.1178,
      "step": 4030
    },
    {
      "epoch": 1.6310052482842148,
      "grad_norm": 9.14452838897705,
      "learning_rate": 1.8368994751715788e-05,
      "loss": 0.0455,
      "step": 4040
    },
    {
      "epoch": 1.6350423899878885,
      "grad_norm": 1.2562576532363892,
      "learning_rate": 1.8364957610012112e-05,
      "loss": 0.0611,
      "step": 4050
    },
    {
      "epoch": 1.6390795316915625,
      "grad_norm": 10.284343719482422,
      "learning_rate": 1.836092046830844e-05,
      "loss": 0.0635,
      "step": 4060
    },
    {
      "epoch": 1.643116673395236,
      "grad_norm": 0.5241027474403381,
      "learning_rate": 1.8356883326604765e-05,
      "loss": 0.0587,
      "step": 4070
    },
    {
      "epoch": 1.64715381509891,
      "grad_norm": 0.061963874846696854,
      "learning_rate": 1.8352846184901093e-05,
      "loss": 0.0542,
      "step": 4080
    },
    {
      "epoch": 1.6511909568025838,
      "grad_norm": 2.839677572250366,
      "learning_rate": 1.8348809043197417e-05,
      "loss": 0.1106,
      "step": 4090
    },
    {
      "epoch": 1.6552280985062575,
      "grad_norm": 4.556849002838135,
      "learning_rate": 1.8344771901493742e-05,
      "loss": 0.124,
      "step": 4100
    },
    {
      "epoch": 1.6592652402099315,
      "grad_norm": 0.053172528743743896,
      "learning_rate": 1.834073475979007e-05,
      "loss": 0.0808,
      "step": 4110
    },
    {
      "epoch": 1.663302381913605,
      "grad_norm": 6.277965545654297,
      "learning_rate": 1.8336697618086398e-05,
      "loss": 0.0782,
      "step": 4120
    },
    {
      "epoch": 1.667339523617279,
      "grad_norm": 1.2155693769454956,
      "learning_rate": 1.8332660476382723e-05,
      "loss": 0.114,
      "step": 4130
    },
    {
      "epoch": 1.6713766653209527,
      "grad_norm": 1.7055004835128784,
      "learning_rate": 1.8328623334679047e-05,
      "loss": 0.1244,
      "step": 4140
    },
    {
      "epoch": 1.6754138070246265,
      "grad_norm": 0.3898770213127136,
      "learning_rate": 1.8324586192975375e-05,
      "loss": 0.0956,
      "step": 4150
    },
    {
      "epoch": 1.6794509487283005,
      "grad_norm": 2.4486279487609863,
      "learning_rate": 1.83205490512717e-05,
      "loss": 0.0745,
      "step": 4160
    },
    {
      "epoch": 1.683488090431974,
      "grad_norm": 1.43505859375,
      "learning_rate": 1.8316511909568028e-05,
      "loss": 0.0923,
      "step": 4170
    },
    {
      "epoch": 1.687525232135648,
      "grad_norm": 12.969547271728516,
      "learning_rate": 1.8312474767864356e-05,
      "loss": 0.0762,
      "step": 4180
    },
    {
      "epoch": 1.6915623738393217,
      "grad_norm": 0.980158805847168,
      "learning_rate": 1.830843762616068e-05,
      "loss": 0.0673,
      "step": 4190
    },
    {
      "epoch": 1.6955995155429955,
      "grad_norm": 0.026440728455781937,
      "learning_rate": 1.8304400484457005e-05,
      "loss": 0.0325,
      "step": 4200
    },
    {
      "epoch": 1.6996366572466695,
      "grad_norm": 1.1428587436676025,
      "learning_rate": 1.8300363342753333e-05,
      "loss": 0.0497,
      "step": 4210
    },
    {
      "epoch": 1.7036737989503432,
      "grad_norm": 7.166422367095947,
      "learning_rate": 1.8296326201049657e-05,
      "loss": 0.079,
      "step": 4220
    },
    {
      "epoch": 1.707710940654017,
      "grad_norm": 5.133905410766602,
      "learning_rate": 1.8292289059345985e-05,
      "loss": 0.113,
      "step": 4230
    },
    {
      "epoch": 1.7117480823576907,
      "grad_norm": 6.975506782531738,
      "learning_rate": 1.828825191764231e-05,
      "loss": 0.1251,
      "step": 4240
    },
    {
      "epoch": 1.7157852240613645,
      "grad_norm": 0.44437292218208313,
      "learning_rate": 1.8284214775938638e-05,
      "loss": 0.063,
      "step": 4250
    },
    {
      "epoch": 1.7198223657650384,
      "grad_norm": 0.9542014002799988,
      "learning_rate": 1.8280177634234963e-05,
      "loss": 0.0482,
      "step": 4260
    },
    {
      "epoch": 1.7238595074687122,
      "grad_norm": 6.535538673400879,
      "learning_rate": 1.827614049253129e-05,
      "loss": 0.0504,
      "step": 4270
    },
    {
      "epoch": 1.727896649172386,
      "grad_norm": 2.097973108291626,
      "learning_rate": 1.8272103350827615e-05,
      "loss": 0.1857,
      "step": 4280
    },
    {
      "epoch": 1.7319337908760597,
      "grad_norm": 0.8202714323997498,
      "learning_rate": 1.8268066209123943e-05,
      "loss": 0.0674,
      "step": 4290
    },
    {
      "epoch": 1.7359709325797335,
      "grad_norm": 5.82046365737915,
      "learning_rate": 1.8264029067420268e-05,
      "loss": 0.049,
      "step": 4300
    },
    {
      "epoch": 1.7400080742834074,
      "grad_norm": 13.697654724121094,
      "learning_rate": 1.8259991925716592e-05,
      "loss": 0.0853,
      "step": 4310
    },
    {
      "epoch": 1.7440452159870812,
      "grad_norm": 3.193544864654541,
      "learning_rate": 1.825595478401292e-05,
      "loss": 0.0637,
      "step": 4320
    },
    {
      "epoch": 1.748082357690755,
      "grad_norm": 8.276168823242188,
      "learning_rate": 1.8251917642309248e-05,
      "loss": 0.0521,
      "step": 4330
    },
    {
      "epoch": 1.752119499394429,
      "grad_norm": 11.84963607788086,
      "learning_rate": 1.8247880500605573e-05,
      "loss": 0.0496,
      "step": 4340
    },
    {
      "epoch": 1.7561566410981024,
      "grad_norm": 0.023795371875166893,
      "learning_rate": 1.8243843358901897e-05,
      "loss": 0.0114,
      "step": 4350
    },
    {
      "epoch": 1.7601937828017764,
      "grad_norm": 0.03680570051074028,
      "learning_rate": 1.8239806217198225e-05,
      "loss": 0.0603,
      "step": 4360
    },
    {
      "epoch": 1.7642309245054502,
      "grad_norm": 0.040608104318380356,
      "learning_rate": 1.823576907549455e-05,
      "loss": 0.0287,
      "step": 4370
    },
    {
      "epoch": 1.768268066209124,
      "grad_norm": 2.211115598678589,
      "learning_rate": 1.8231731933790878e-05,
      "loss": 0.0968,
      "step": 4380
    },
    {
      "epoch": 1.7723052079127979,
      "grad_norm": 4.808506965637207,
      "learning_rate": 1.8227694792087203e-05,
      "loss": 0.0521,
      "step": 4390
    },
    {
      "epoch": 1.7763423496164714,
      "grad_norm": 8.664738655090332,
      "learning_rate": 1.822365765038353e-05,
      "loss": 0.081,
      "step": 4400
    },
    {
      "epoch": 1.7803794913201454,
      "grad_norm": 0.4535583555698395,
      "learning_rate": 1.8219620508679855e-05,
      "loss": 0.0527,
      "step": 4410
    },
    {
      "epoch": 1.7844166330238191,
      "grad_norm": 1.3204290866851807,
      "learning_rate": 1.8215583366976183e-05,
      "loss": 0.0688,
      "step": 4420
    },
    {
      "epoch": 1.788453774727493,
      "grad_norm": 11.389792442321777,
      "learning_rate": 1.821154622527251e-05,
      "loss": 0.1093,
      "step": 4430
    },
    {
      "epoch": 1.7924909164311669,
      "grad_norm": 0.6750830411911011,
      "learning_rate": 1.8207509083568836e-05,
      "loss": 0.0974,
      "step": 4440
    },
    {
      "epoch": 1.7965280581348404,
      "grad_norm": 0.013314890675246716,
      "learning_rate": 1.820347194186516e-05,
      "loss": 0.0505,
      "step": 4450
    },
    {
      "epoch": 1.8005651998385144,
      "grad_norm": 0.018531374633312225,
      "learning_rate": 1.8199434800161485e-05,
      "loss": 0.0731,
      "step": 4460
    },
    {
      "epoch": 1.8046023415421881,
      "grad_norm": 6.595797061920166,
      "learning_rate": 1.8195397658457813e-05,
      "loss": 0.128,
      "step": 4470
    },
    {
      "epoch": 1.8086394832458619,
      "grad_norm": 4.521429538726807,
      "learning_rate": 1.819136051675414e-05,
      "loss": 0.073,
      "step": 4480
    },
    {
      "epoch": 1.8126766249495359,
      "grad_norm": 4.444892883300781,
      "learning_rate": 1.8187323375050465e-05,
      "loss": 0.0331,
      "step": 4490
    },
    {
      "epoch": 1.8167137666532094,
      "grad_norm": 1.0955370664596558,
      "learning_rate": 1.8183286233346793e-05,
      "loss": 0.0612,
      "step": 4500
    },
    {
      "epoch": 1.8207509083568834,
      "grad_norm": 0.018476955592632294,
      "learning_rate": 1.8179249091643118e-05,
      "loss": 0.0615,
      "step": 4510
    },
    {
      "epoch": 1.824788050060557,
      "grad_norm": 0.07160124182701111,
      "learning_rate": 1.8175211949939443e-05,
      "loss": 0.0671,
      "step": 4520
    },
    {
      "epoch": 1.8288251917642309,
      "grad_norm": 0.44081318378448486,
      "learning_rate": 1.817117480823577e-05,
      "loss": 0.0903,
      "step": 4530
    },
    {
      "epoch": 1.8328623334679048,
      "grad_norm": 0.9432722330093384,
      "learning_rate": 1.81671376665321e-05,
      "loss": 0.1033,
      "step": 4540
    },
    {
      "epoch": 1.8368994751715784,
      "grad_norm": 0.30068016052246094,
      "learning_rate": 1.8163100524828423e-05,
      "loss": 0.0899,
      "step": 4550
    },
    {
      "epoch": 1.8409366168752523,
      "grad_norm": 0.855371356010437,
      "learning_rate": 1.8159063383124748e-05,
      "loss": 0.0654,
      "step": 4560
    },
    {
      "epoch": 1.844973758578926,
      "grad_norm": 12.804683685302734,
      "learning_rate": 1.8155026241421076e-05,
      "loss": 0.0748,
      "step": 4570
    },
    {
      "epoch": 1.8490109002825998,
      "grad_norm": 1.9481996297836304,
      "learning_rate": 1.8150989099717404e-05,
      "loss": 0.0781,
      "step": 4580
    },
    {
      "epoch": 1.8530480419862738,
      "grad_norm": 2.5111942291259766,
      "learning_rate": 1.814695195801373e-05,
      "loss": 0.0592,
      "step": 4590
    },
    {
      "epoch": 1.8570851836899476,
      "grad_norm": 8.746065139770508,
      "learning_rate": 1.8142914816310053e-05,
      "loss": 0.1132,
      "step": 4600
    },
    {
      "epoch": 1.8611223253936213,
      "grad_norm": 0.03018668293952942,
      "learning_rate": 1.813887767460638e-05,
      "loss": 0.0325,
      "step": 4610
    },
    {
      "epoch": 1.865159467097295,
      "grad_norm": 0.016784092411398888,
      "learning_rate": 1.8134840532902706e-05,
      "loss": 0.0834,
      "step": 4620
    },
    {
      "epoch": 1.8691966088009688,
      "grad_norm": 9.294300079345703,
      "learning_rate": 1.8130803391199034e-05,
      "loss": 0.0717,
      "step": 4630
    },
    {
      "epoch": 1.8732337505046428,
      "grad_norm": 0.0699126347899437,
      "learning_rate": 1.8126766249495358e-05,
      "loss": 0.0388,
      "step": 4640
    },
    {
      "epoch": 1.8772708922083166,
      "grad_norm": 5.943856239318848,
      "learning_rate": 1.8122729107791686e-05,
      "loss": 0.0892,
      "step": 4650
    },
    {
      "epoch": 1.8813080339119903,
      "grad_norm": 0.14772479236125946,
      "learning_rate": 1.811869196608801e-05,
      "loss": 0.0853,
      "step": 4660
    },
    {
      "epoch": 1.885345175615664,
      "grad_norm": 0.0725829005241394,
      "learning_rate": 1.8114654824384335e-05,
      "loss": 0.0846,
      "step": 4670
    },
    {
      "epoch": 1.8893823173193378,
      "grad_norm": 2.8639280796051025,
      "learning_rate": 1.8110617682680663e-05,
      "loss": 0.0123,
      "step": 4680
    },
    {
      "epoch": 1.8934194590230118,
      "grad_norm": 0.29180800914764404,
      "learning_rate": 1.810658054097699e-05,
      "loss": 0.0857,
      "step": 4690
    },
    {
      "epoch": 1.8974566007266855,
      "grad_norm": 5.378145217895508,
      "learning_rate": 1.8102543399273316e-05,
      "loss": 0.0863,
      "step": 4700
    },
    {
      "epoch": 1.9014937424303593,
      "grad_norm": 0.004233722109347582,
      "learning_rate": 1.809850625756964e-05,
      "loss": 0.0847,
      "step": 4710
    },
    {
      "epoch": 1.9055308841340333,
      "grad_norm": 0.11127161979675293,
      "learning_rate": 1.809446911586597e-05,
      "loss": 0.0453,
      "step": 4720
    },
    {
      "epoch": 1.9095680258377068,
      "grad_norm": 5.126205921173096,
      "learning_rate": 1.8090431974162296e-05,
      "loss": 0.0621,
      "step": 4730
    },
    {
      "epoch": 1.9136051675413808,
      "grad_norm": 0.1672021448612213,
      "learning_rate": 1.808639483245862e-05,
      "loss": 0.0275,
      "step": 4740
    },
    {
      "epoch": 1.9176423092450545,
      "grad_norm": 0.0702831819653511,
      "learning_rate": 1.808235769075495e-05,
      "loss": 0.0819,
      "step": 4750
    },
    {
      "epoch": 1.9216794509487283,
      "grad_norm": 0.03914172574877739,
      "learning_rate": 1.8078320549051274e-05,
      "loss": 0.0994,
      "step": 4760
    },
    {
      "epoch": 1.9257165926524022,
      "grad_norm": 9.193268775939941,
      "learning_rate": 1.8074283407347598e-05,
      "loss": 0.0504,
      "step": 4770
    },
    {
      "epoch": 1.9297537343560758,
      "grad_norm": 6.839931964874268,
      "learning_rate": 1.8070246265643926e-05,
      "loss": 0.0081,
      "step": 4780
    },
    {
      "epoch": 1.9337908760597498,
      "grad_norm": 0.1827893853187561,
      "learning_rate": 1.8066209123940254e-05,
      "loss": 0.112,
      "step": 4790
    },
    {
      "epoch": 1.9378280177634235,
      "grad_norm": 4.196626663208008,
      "learning_rate": 1.806217198223658e-05,
      "loss": 0.0555,
      "step": 4800
    },
    {
      "epoch": 1.9418651594670973,
      "grad_norm": 2.3067128658294678,
      "learning_rate": 1.8058134840532903e-05,
      "loss": 0.0929,
      "step": 4810
    },
    {
      "epoch": 1.9459023011707712,
      "grad_norm": 0.16362828016281128,
      "learning_rate": 1.8054097698829228e-05,
      "loss": 0.1322,
      "step": 4820
    },
    {
      "epoch": 1.9499394428744448,
      "grad_norm": 4.108554363250732,
      "learning_rate": 1.8050060557125556e-05,
      "loss": 0.0935,
      "step": 4830
    },
    {
      "epoch": 1.9539765845781187,
      "grad_norm": 1.8201720714569092,
      "learning_rate": 1.8046023415421884e-05,
      "loss": 0.0488,
      "step": 4840
    },
    {
      "epoch": 1.9580137262817925,
      "grad_norm": 3.9695794582366943,
      "learning_rate": 1.804198627371821e-05,
      "loss": 0.0385,
      "step": 4850
    },
    {
      "epoch": 1.9620508679854662,
      "grad_norm": 2.8745882511138916,
      "learning_rate": 1.8037949132014536e-05,
      "loss": 0.1023,
      "step": 4860
    },
    {
      "epoch": 1.9660880096891402,
      "grad_norm": 1.4735205173492432,
      "learning_rate": 1.803391199031086e-05,
      "loss": 0.0599,
      "step": 4870
    },
    {
      "epoch": 1.9701251513928137,
      "grad_norm": 3.6866977214813232,
      "learning_rate": 1.8029874848607186e-05,
      "loss": 0.1362,
      "step": 4880
    },
    {
      "epoch": 1.9741622930964877,
      "grad_norm": 0.05004957318305969,
      "learning_rate": 1.8025837706903514e-05,
      "loss": 0.0454,
      "step": 4890
    },
    {
      "epoch": 1.9781994348001615,
      "grad_norm": 0.02434682846069336,
      "learning_rate": 1.802180056519984e-05,
      "loss": 0.0475,
      "step": 4900
    },
    {
      "epoch": 1.9822365765038352,
      "grad_norm": 9.962422370910645,
      "learning_rate": 1.8017763423496166e-05,
      "loss": 0.064,
      "step": 4910
    },
    {
      "epoch": 1.9862737182075092,
      "grad_norm": 0.07738447934389114,
      "learning_rate": 1.801372628179249e-05,
      "loss": 0.1125,
      "step": 4920
    },
    {
      "epoch": 1.9903108599111827,
      "grad_norm": 0.5732712745666504,
      "learning_rate": 1.800968914008882e-05,
      "loss": 0.0375,
      "step": 4930
    },
    {
      "epoch": 1.9943480016148567,
      "grad_norm": 3.804006338119507,
      "learning_rate": 1.8005651998385147e-05,
      "loss": 0.0492,
      "step": 4940
    },
    {
      "epoch": 1.9983851433185305,
      "grad_norm": 2.2661352157592773,
      "learning_rate": 1.800161485668147e-05,
      "loss": 0.0564,
      "step": 4950
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9789308176100628,
      "eval_f1": 0.9239931934203063,
      "eval_loss": 0.07751435041427612,
      "eval_precision": 0.9120940649496081,
      "eval_recall": 0.9362068965517242,
      "eval_runtime": 444.5215,
      "eval_samples_per_second": 28.66,
      "eval_steps_per_second": 1.195,
      "step": 4954
    },
    {
      "epoch": 2.002422285022204,
      "grad_norm": 4.463025093078613,
      "learning_rate": 1.7997577714977796e-05,
      "loss": 0.0557,
      "step": 4960
    },
    {
      "epoch": 2.006459426725878,
      "grad_norm": 0.03708725795149803,
      "learning_rate": 1.7993540573274124e-05,
      "loss": 0.0816,
      "step": 4970
    },
    {
      "epoch": 2.0104965684295517,
      "grad_norm": 7.4670820236206055,
      "learning_rate": 1.798950343157045e-05,
      "loss": 0.0609,
      "step": 4980
    },
    {
      "epoch": 2.0145337101332257,
      "grad_norm": 0.08872229605913162,
      "learning_rate": 1.7985466289866776e-05,
      "loss": 0.0095,
      "step": 4990
    },
    {
      "epoch": 2.0185708518368997,
      "grad_norm": 3.28309965133667,
      "learning_rate": 1.79814291481631e-05,
      "loss": 0.0853,
      "step": 5000
    },
    {
      "epoch": 2.022607993540573,
      "grad_norm": 4.8094162940979,
      "learning_rate": 1.797739200645943e-05,
      "loss": 0.0737,
      "step": 5010
    },
    {
      "epoch": 2.026645135244247,
      "grad_norm": 4.645274639129639,
      "learning_rate": 1.7973354864755754e-05,
      "loss": 0.0468,
      "step": 5020
    },
    {
      "epoch": 2.0306822769479207,
      "grad_norm": 0.3580711781978607,
      "learning_rate": 1.7969317723052078e-05,
      "loss": 0.0407,
      "step": 5030
    },
    {
      "epoch": 2.0347194186515947,
      "grad_norm": 0.17829614877700806,
      "learning_rate": 1.7965280581348406e-05,
      "loss": 0.0403,
      "step": 5040
    },
    {
      "epoch": 2.0387565603552686,
      "grad_norm": 3.600349187850952,
      "learning_rate": 1.7961243439644734e-05,
      "loss": 0.0798,
      "step": 5050
    },
    {
      "epoch": 2.042793702058942,
      "grad_norm": 0.014237994328141212,
      "learning_rate": 1.795720629794106e-05,
      "loss": 0.0427,
      "step": 5060
    },
    {
      "epoch": 2.046830843762616,
      "grad_norm": 3.732682466506958,
      "learning_rate": 1.7953169156237383e-05,
      "loss": 0.0306,
      "step": 5070
    },
    {
      "epoch": 2.0508679854662897,
      "grad_norm": 0.0965421125292778,
      "learning_rate": 1.794913201453371e-05,
      "loss": 0.0184,
      "step": 5080
    },
    {
      "epoch": 2.0549051271699637,
      "grad_norm": 0.016843002289533615,
      "learning_rate": 1.794509487283004e-05,
      "loss": 0.0533,
      "step": 5090
    },
    {
      "epoch": 2.0589422688736376,
      "grad_norm": 0.014206543564796448,
      "learning_rate": 1.7941057731126364e-05,
      "loss": 0.0552,
      "step": 5100
    },
    {
      "epoch": 2.062979410577311,
      "grad_norm": 2.510850667953491,
      "learning_rate": 1.7937020589422692e-05,
      "loss": 0.0565,
      "step": 5110
    },
    {
      "epoch": 2.067016552280985,
      "grad_norm": 0.05347810313105583,
      "learning_rate": 1.7932983447719016e-05,
      "loss": 0.0484,
      "step": 5120
    },
    {
      "epoch": 2.0710536939846587,
      "grad_norm": 3.30684232711792,
      "learning_rate": 1.792894630601534e-05,
      "loss": 0.0262,
      "step": 5130
    },
    {
      "epoch": 2.0750908356883326,
      "grad_norm": 3.770639181137085,
      "learning_rate": 1.792490916431167e-05,
      "loss": 0.0299,
      "step": 5140
    },
    {
      "epoch": 2.0791279773920066,
      "grad_norm": 0.10159001499414444,
      "learning_rate": 1.7920872022607997e-05,
      "loss": 0.043,
      "step": 5150
    },
    {
      "epoch": 2.08316511909568,
      "grad_norm": 0.048741623759269714,
      "learning_rate": 1.791683488090432e-05,
      "loss": 0.0462,
      "step": 5160
    },
    {
      "epoch": 2.087202260799354,
      "grad_norm": 0.42631059885025024,
      "learning_rate": 1.7912797739200646e-05,
      "loss": 0.1751,
      "step": 5170
    },
    {
      "epoch": 2.0912394025030276,
      "grad_norm": 17.73215675354004,
      "learning_rate": 1.7908760597496974e-05,
      "loss": 0.0539,
      "step": 5180
    },
    {
      "epoch": 2.0952765442067016,
      "grad_norm": 0.5181434154510498,
      "learning_rate": 1.79047234557933e-05,
      "loss": 0.043,
      "step": 5190
    },
    {
      "epoch": 2.0993136859103756,
      "grad_norm": 5.182719707489014,
      "learning_rate": 1.7900686314089627e-05,
      "loss": 0.0362,
      "step": 5200
    },
    {
      "epoch": 2.103350827614049,
      "grad_norm": 0.9985907077789307,
      "learning_rate": 1.789664917238595e-05,
      "loss": 0.0246,
      "step": 5210
    },
    {
      "epoch": 2.107387969317723,
      "grad_norm": 2.1751699447631836,
      "learning_rate": 1.789261203068228e-05,
      "loss": 0.1048,
      "step": 5220
    },
    {
      "epoch": 2.111425111021397,
      "grad_norm": 0.07476690411567688,
      "learning_rate": 1.7888574888978604e-05,
      "loss": 0.0212,
      "step": 5230
    },
    {
      "epoch": 2.1154622527250706,
      "grad_norm": 0.8579968810081482,
      "learning_rate": 1.7884537747274932e-05,
      "loss": 0.0796,
      "step": 5240
    },
    {
      "epoch": 2.1194993944287446,
      "grad_norm": 0.0565938726067543,
      "learning_rate": 1.7880500605571257e-05,
      "loss": 0.0289,
      "step": 5250
    },
    {
      "epoch": 2.123536536132418,
      "grad_norm": 0.0462823361158371,
      "learning_rate": 1.7876463463867584e-05,
      "loss": 0.0783,
      "step": 5260
    },
    {
      "epoch": 2.127573677836092,
      "grad_norm": 1.8497540950775146,
      "learning_rate": 1.787242632216391e-05,
      "loss": 0.0148,
      "step": 5270
    },
    {
      "epoch": 2.131610819539766,
      "grad_norm": 0.005156253930181265,
      "learning_rate": 1.7868389180460234e-05,
      "loss": 0.0209,
      "step": 5280
    },
    {
      "epoch": 2.1356479612434396,
      "grad_norm": 6.858593463897705,
      "learning_rate": 1.786435203875656e-05,
      "loss": 0.0283,
      "step": 5290
    },
    {
      "epoch": 2.1396851029471136,
      "grad_norm": 5.44193696975708,
      "learning_rate": 1.786031489705289e-05,
      "loss": 0.0567,
      "step": 5300
    },
    {
      "epoch": 2.143722244650787,
      "grad_norm": 0.005023173522204161,
      "learning_rate": 1.7856277755349214e-05,
      "loss": 0.0041,
      "step": 5310
    },
    {
      "epoch": 2.147759386354461,
      "grad_norm": 5.575230121612549,
      "learning_rate": 1.785224061364554e-05,
      "loss": 0.1214,
      "step": 5320
    },
    {
      "epoch": 2.151796528058135,
      "grad_norm": 0.1117488294839859,
      "learning_rate": 1.7848203471941867e-05,
      "loss": 0.074,
      "step": 5330
    },
    {
      "epoch": 2.1558336697618086,
      "grad_norm": 0.35652464628219604,
      "learning_rate": 1.784416633023819e-05,
      "loss": 0.0131,
      "step": 5340
    },
    {
      "epoch": 2.1598708114654825,
      "grad_norm": 4.031291961669922,
      "learning_rate": 1.784012918853452e-05,
      "loss": 0.0626,
      "step": 5350
    },
    {
      "epoch": 2.163907953169156,
      "grad_norm": 0.23017799854278564,
      "learning_rate": 1.7836092046830847e-05,
      "loss": 0.0295,
      "step": 5360
    },
    {
      "epoch": 2.16794509487283,
      "grad_norm": 2.776252508163452,
      "learning_rate": 1.7832054905127172e-05,
      "loss": 0.05,
      "step": 5370
    },
    {
      "epoch": 2.171982236576504,
      "grad_norm": 0.8873290419578552,
      "learning_rate": 1.7828017763423497e-05,
      "loss": 0.0539,
      "step": 5380
    },
    {
      "epoch": 2.1760193782801776,
      "grad_norm": 0.21891741454601288,
      "learning_rate": 1.7823980621719825e-05,
      "loss": 0.0897,
      "step": 5390
    },
    {
      "epoch": 2.1800565199838515,
      "grad_norm": 0.17134900391101837,
      "learning_rate": 1.7819943480016153e-05,
      "loss": 0.0248,
      "step": 5400
    },
    {
      "epoch": 2.184093661687525,
      "grad_norm": 2.0674068927764893,
      "learning_rate": 1.7815906338312477e-05,
      "loss": 0.1233,
      "step": 5410
    },
    {
      "epoch": 2.188130803391199,
      "grad_norm": 2.3070740699768066,
      "learning_rate": 1.7811869196608802e-05,
      "loss": 0.015,
      "step": 5420
    },
    {
      "epoch": 2.192167945094873,
      "grad_norm": 0.0738389790058136,
      "learning_rate": 1.7807832054905126e-05,
      "loss": 0.0421,
      "step": 5430
    },
    {
      "epoch": 2.1962050867985465,
      "grad_norm": 0.016593147069215775,
      "learning_rate": 1.7803794913201454e-05,
      "loss": 0.0354,
      "step": 5440
    },
    {
      "epoch": 2.2002422285022205,
      "grad_norm": 0.43809354305267334,
      "learning_rate": 1.7799757771497782e-05,
      "loss": 0.0519,
      "step": 5450
    },
    {
      "epoch": 2.204279370205894,
      "grad_norm": 4.098537445068359,
      "learning_rate": 1.7795720629794107e-05,
      "loss": 0.0657,
      "step": 5460
    },
    {
      "epoch": 2.208316511909568,
      "grad_norm": 7.785652160644531,
      "learning_rate": 1.7791683488090435e-05,
      "loss": 0.02,
      "step": 5470
    },
    {
      "epoch": 2.212353653613242,
      "grad_norm": 0.3246205747127533,
      "learning_rate": 1.778764634638676e-05,
      "loss": 0.0579,
      "step": 5480
    },
    {
      "epoch": 2.2163907953169155,
      "grad_norm": 1.0144503116607666,
      "learning_rate": 1.7783609204683084e-05,
      "loss": 0.0272,
      "step": 5490
    },
    {
      "epoch": 2.2204279370205895,
      "grad_norm": 2.77089262008667,
      "learning_rate": 1.7779572062979412e-05,
      "loss": 0.1055,
      "step": 5500
    },
    {
      "epoch": 2.224465078724263,
      "grad_norm": 0.263313889503479,
      "learning_rate": 1.777553492127574e-05,
      "loss": 0.0656,
      "step": 5510
    },
    {
      "epoch": 2.228502220427937,
      "grad_norm": 4.252655982971191,
      "learning_rate": 1.7771497779572065e-05,
      "loss": 0.0186,
      "step": 5520
    },
    {
      "epoch": 2.232539362131611,
      "grad_norm": 0.13456982374191284,
      "learning_rate": 1.776746063786839e-05,
      "loss": 0.0483,
      "step": 5530
    },
    {
      "epoch": 2.2365765038352845,
      "grad_norm": 0.06205049529671669,
      "learning_rate": 1.7763423496164717e-05,
      "loss": 0.0383,
      "step": 5540
    },
    {
      "epoch": 2.2406136455389585,
      "grad_norm": 3.2902112007141113,
      "learning_rate": 1.7759386354461042e-05,
      "loss": 0.0956,
      "step": 5550
    },
    {
      "epoch": 2.244650787242632,
      "grad_norm": 0.2948648929595947,
      "learning_rate": 1.775534921275737e-05,
      "loss": 0.0471,
      "step": 5560
    },
    {
      "epoch": 2.248687928946306,
      "grad_norm": 1.8306949138641357,
      "learning_rate": 1.7751312071053694e-05,
      "loss": 0.0465,
      "step": 5570
    },
    {
      "epoch": 2.25272507064998,
      "grad_norm": 0.0423135831952095,
      "learning_rate": 1.7747274929350022e-05,
      "loss": 0.0343,
      "step": 5580
    },
    {
      "epoch": 2.2567622123536535,
      "grad_norm": 5.031295299530029,
      "learning_rate": 1.7743237787646347e-05,
      "loss": 0.0398,
      "step": 5590
    },
    {
      "epoch": 2.2607993540573275,
      "grad_norm": 25.42702293395996,
      "learning_rate": 1.7739200645942675e-05,
      "loss": 0.0508,
      "step": 5600
    },
    {
      "epoch": 2.264836495761001,
      "grad_norm": 4.400991439819336,
      "learning_rate": 1.7735163504239003e-05,
      "loss": 0.0222,
      "step": 5610
    },
    {
      "epoch": 2.268873637464675,
      "grad_norm": 6.442019939422607,
      "learning_rate": 1.7731126362535327e-05,
      "loss": 0.1894,
      "step": 5620
    },
    {
      "epoch": 2.272910779168349,
      "grad_norm": 1.7484045028686523,
      "learning_rate": 1.7727089220831652e-05,
      "loss": 0.0464,
      "step": 5630
    },
    {
      "epoch": 2.2769479208720225,
      "grad_norm": 3.9956471920013428,
      "learning_rate": 1.7723052079127977e-05,
      "loss": 0.0176,
      "step": 5640
    },
    {
      "epoch": 2.2809850625756964,
      "grad_norm": 19.598167419433594,
      "learning_rate": 1.7719014937424305e-05,
      "loss": 0.0781,
      "step": 5650
    },
    {
      "epoch": 2.28502220427937,
      "grad_norm": 0.14255055785179138,
      "learning_rate": 1.7714977795720633e-05,
      "loss": 0.0488,
      "step": 5660
    },
    {
      "epoch": 2.289059345983044,
      "grad_norm": 1.381002426147461,
      "learning_rate": 1.7710940654016957e-05,
      "loss": 0.0546,
      "step": 5670
    },
    {
      "epoch": 2.293096487686718,
      "grad_norm": 1.3407955169677734,
      "learning_rate": 1.7706903512313282e-05,
      "loss": 0.0451,
      "step": 5680
    },
    {
      "epoch": 2.2971336293903915,
      "grad_norm": 0.07565629482269287,
      "learning_rate": 1.770286637060961e-05,
      "loss": 0.0355,
      "step": 5690
    },
    {
      "epoch": 2.3011707710940654,
      "grad_norm": 5.058255195617676,
      "learning_rate": 1.7698829228905934e-05,
      "loss": 0.033,
      "step": 5700
    },
    {
      "epoch": 2.305207912797739,
      "grad_norm": 0.028981376439332962,
      "learning_rate": 1.7694792087202262e-05,
      "loss": 0.0876,
      "step": 5710
    },
    {
      "epoch": 2.309245054501413,
      "grad_norm": 8.883803367614746,
      "learning_rate": 1.769075494549859e-05,
      "loss": 0.0222,
      "step": 5720
    },
    {
      "epoch": 2.313282196205087,
      "grad_norm": 2.8785693645477295,
      "learning_rate": 1.7686717803794915e-05,
      "loss": 0.0981,
      "step": 5730
    },
    {
      "epoch": 2.3173193379087604,
      "grad_norm": 0.1384776383638382,
      "learning_rate": 1.768268066209124e-05,
      "loss": 0.0276,
      "step": 5740
    },
    {
      "epoch": 2.3213564796124344,
      "grad_norm": 0.16137449443340302,
      "learning_rate": 1.7678643520387567e-05,
      "loss": 0.0054,
      "step": 5750
    },
    {
      "epoch": 2.3253936213161084,
      "grad_norm": 0.06445661932229996,
      "learning_rate": 1.7674606378683895e-05,
      "loss": 0.0376,
      "step": 5760
    },
    {
      "epoch": 2.329430763019782,
      "grad_norm": 0.023200904950499535,
      "learning_rate": 1.767056923698022e-05,
      "loss": 0.009,
      "step": 5770
    },
    {
      "epoch": 2.333467904723456,
      "grad_norm": 2.25161075592041,
      "learning_rate": 1.7666532095276545e-05,
      "loss": 0.0454,
      "step": 5780
    },
    {
      "epoch": 2.3375050464271294,
      "grad_norm": 3.0183165073394775,
      "learning_rate": 1.7662494953572873e-05,
      "loss": 0.0334,
      "step": 5790
    },
    {
      "epoch": 2.3415421881308034,
      "grad_norm": 0.06933007389307022,
      "learning_rate": 1.7658457811869197e-05,
      "loss": 0.0902,
      "step": 5800
    },
    {
      "epoch": 2.3455793298344774,
      "grad_norm": 0.051317356526851654,
      "learning_rate": 1.7654420670165525e-05,
      "loss": 0.1205,
      "step": 5810
    },
    {
      "epoch": 2.349616471538151,
      "grad_norm": 0.02764388546347618,
      "learning_rate": 1.765038352846185e-05,
      "loss": 0.1187,
      "step": 5820
    },
    {
      "epoch": 2.353653613241825,
      "grad_norm": 0.0194595605134964,
      "learning_rate": 1.7646346386758178e-05,
      "loss": 0.1006,
      "step": 5830
    },
    {
      "epoch": 2.3576907549454984,
      "grad_norm": 21.637727737426758,
      "learning_rate": 1.7642309245054502e-05,
      "loss": 0.148,
      "step": 5840
    },
    {
      "epoch": 2.3617278966491724,
      "grad_norm": 0.2680833041667938,
      "learning_rate": 1.7638272103350827e-05,
      "loss": 0.0335,
      "step": 5850
    },
    {
      "epoch": 2.3657650383528464,
      "grad_norm": 7.795822620391846,
      "learning_rate": 1.7634234961647155e-05,
      "loss": 0.1107,
      "step": 5860
    },
    {
      "epoch": 2.36980218005652,
      "grad_norm": 7.994634628295898,
      "learning_rate": 1.7630197819943483e-05,
      "loss": 0.009,
      "step": 5870
    },
    {
      "epoch": 2.373839321760194,
      "grad_norm": 26.724437713623047,
      "learning_rate": 1.7626160678239808e-05,
      "loss": 0.0493,
      "step": 5880
    },
    {
      "epoch": 2.377876463463868,
      "grad_norm": 0.05700111389160156,
      "learning_rate": 1.7622123536536132e-05,
      "loss": 0.0306,
      "step": 5890
    },
    {
      "epoch": 2.3819136051675414,
      "grad_norm": 0.255041241645813,
      "learning_rate": 1.761808639483246e-05,
      "loss": 0.0292,
      "step": 5900
    },
    {
      "epoch": 2.3859507468712153,
      "grad_norm": 0.02790781483054161,
      "learning_rate": 1.7614049253128788e-05,
      "loss": 0.053,
      "step": 5910
    },
    {
      "epoch": 2.389987888574889,
      "grad_norm": 1.3141225576400757,
      "learning_rate": 1.7610012111425113e-05,
      "loss": 0.0861,
      "step": 5920
    },
    {
      "epoch": 2.394025030278563,
      "grad_norm": 0.014149176888167858,
      "learning_rate": 1.7605974969721437e-05,
      "loss": 0.0049,
      "step": 5930
    },
    {
      "epoch": 2.398062171982237,
      "grad_norm": 0.013889072462916374,
      "learning_rate": 1.7601937828017765e-05,
      "loss": 0.0108,
      "step": 5940
    },
    {
      "epoch": 2.4020993136859103,
      "grad_norm": 0.08549722284078598,
      "learning_rate": 1.759790068631409e-05,
      "loss": 0.0463,
      "step": 5950
    },
    {
      "epoch": 2.4061364553895843,
      "grad_norm": 10.359251022338867,
      "learning_rate": 1.7593863544610418e-05,
      "loss": 0.076,
      "step": 5960
    },
    {
      "epoch": 2.410173597093258,
      "grad_norm": 0.36189571022987366,
      "learning_rate": 1.7589826402906746e-05,
      "loss": 0.0262,
      "step": 5970
    },
    {
      "epoch": 2.414210738796932,
      "grad_norm": 2.1537749767303467,
      "learning_rate": 1.758578926120307e-05,
      "loss": 0.0655,
      "step": 5980
    },
    {
      "epoch": 2.418247880500606,
      "grad_norm": 2.811882972717285,
      "learning_rate": 1.7581752119499395e-05,
      "loss": 0.078,
      "step": 5990
    },
    {
      "epoch": 2.4222850222042793,
      "grad_norm": 0.015874095261096954,
      "learning_rate": 1.757771497779572e-05,
      "loss": 0.1459,
      "step": 6000
    },
    {
      "epoch": 2.4263221639079533,
      "grad_norm": 1.9388952255249023,
      "learning_rate": 1.7573677836092048e-05,
      "loss": 0.0573,
      "step": 6010
    },
    {
      "epoch": 2.430359305611627,
      "grad_norm": 0.3142384886741638,
      "learning_rate": 1.7569640694388376e-05,
      "loss": 0.0182,
      "step": 6020
    },
    {
      "epoch": 2.434396447315301,
      "grad_norm": 0.018596407026052475,
      "learning_rate": 1.75656035526847e-05,
      "loss": 0.0247,
      "step": 6030
    },
    {
      "epoch": 2.438433589018975,
      "grad_norm": 0.08947858214378357,
      "learning_rate": 1.7561566410981025e-05,
      "loss": 0.0588,
      "step": 6040
    },
    {
      "epoch": 2.4424707307226483,
      "grad_norm": 0.0132744824513793,
      "learning_rate": 1.7557529269277353e-05,
      "loss": 0.0172,
      "step": 6050
    },
    {
      "epoch": 2.4465078724263223,
      "grad_norm": 1.2947731018066406,
      "learning_rate": 1.755349212757368e-05,
      "loss": 0.0277,
      "step": 6060
    },
    {
      "epoch": 2.450545014129996,
      "grad_norm": 0.04669283702969551,
      "learning_rate": 1.7549454985870005e-05,
      "loss": 0.0696,
      "step": 6070
    },
    {
      "epoch": 2.45458215583367,
      "grad_norm": 3.644925594329834,
      "learning_rate": 1.7545417844166333e-05,
      "loss": 0.0936,
      "step": 6080
    },
    {
      "epoch": 2.4586192975373438,
      "grad_norm": 11.426898002624512,
      "learning_rate": 1.7541380702462658e-05,
      "loss": 0.0573,
      "step": 6090
    },
    {
      "epoch": 2.4626564392410173,
      "grad_norm": 2.300093650817871,
      "learning_rate": 1.7537343560758982e-05,
      "loss": 0.0592,
      "step": 6100
    },
    {
      "epoch": 2.4666935809446913,
      "grad_norm": 2.940248966217041,
      "learning_rate": 1.753330641905531e-05,
      "loss": 0.0258,
      "step": 6110
    },
    {
      "epoch": 2.470730722648365,
      "grad_norm": 0.1449308842420578,
      "learning_rate": 1.752926927735164e-05,
      "loss": 0.0787,
      "step": 6120
    },
    {
      "epoch": 2.4747678643520388,
      "grad_norm": 0.0407608337700367,
      "learning_rate": 1.7525232135647963e-05,
      "loss": 0.0208,
      "step": 6130
    },
    {
      "epoch": 2.4788050060557127,
      "grad_norm": 0.05060189589858055,
      "learning_rate": 1.7521194993944288e-05,
      "loss": 0.0153,
      "step": 6140
    },
    {
      "epoch": 2.4828421477593863,
      "grad_norm": 0.037781357765197754,
      "learning_rate": 1.7517157852240616e-05,
      "loss": 0.1807,
      "step": 6150
    },
    {
      "epoch": 2.4868792894630602,
      "grad_norm": 6.271254539489746,
      "learning_rate": 1.751312071053694e-05,
      "loss": 0.0602,
      "step": 6160
    },
    {
      "epoch": 2.490916431166734,
      "grad_norm": 4.538585662841797,
      "learning_rate": 1.7509083568833268e-05,
      "loss": 0.0418,
      "step": 6170
    },
    {
      "epoch": 2.4949535728704078,
      "grad_norm": 0.03929371386766434,
      "learning_rate": 1.7505046427129593e-05,
      "loss": 0.0368,
      "step": 6180
    },
    {
      "epoch": 2.4989907145740817,
      "grad_norm": 0.47240880131721497,
      "learning_rate": 1.750100928542592e-05,
      "loss": 0.065,
      "step": 6190
    },
    {
      "epoch": 2.5030278562777553,
      "grad_norm": 0.025310980156064034,
      "learning_rate": 1.7496972143722245e-05,
      "loss": 0.0069,
      "step": 6200
    },
    {
      "epoch": 2.5070649979814292,
      "grad_norm": 8.354297637939453,
      "learning_rate": 1.7492935002018573e-05,
      "loss": 0.0383,
      "step": 6210
    },
    {
      "epoch": 2.5111021396851028,
      "grad_norm": 3.238166332244873,
      "learning_rate": 1.7488897860314898e-05,
      "loss": 0.032,
      "step": 6220
    },
    {
      "epoch": 2.5151392813887767,
      "grad_norm": 3.1736230850219727,
      "learning_rate": 1.7484860718611226e-05,
      "loss": 0.0774,
      "step": 6230
    },
    {
      "epoch": 2.5191764230924507,
      "grad_norm": 0.06251367181539536,
      "learning_rate": 1.748082357690755e-05,
      "loss": 0.061,
      "step": 6240
    },
    {
      "epoch": 2.5232135647961242,
      "grad_norm": 0.2694622874259949,
      "learning_rate": 1.7476786435203875e-05,
      "loss": 0.0045,
      "step": 6250
    },
    {
      "epoch": 2.527250706499798,
      "grad_norm": 0.2446313202381134,
      "learning_rate": 1.7472749293500203e-05,
      "loss": 0.0421,
      "step": 6260
    },
    {
      "epoch": 2.5312878482034717,
      "grad_norm": 0.06634637713432312,
      "learning_rate": 1.746871215179653e-05,
      "loss": 0.0444,
      "step": 6270
    },
    {
      "epoch": 2.5353249899071457,
      "grad_norm": 0.04592764377593994,
      "learning_rate": 1.7464675010092856e-05,
      "loss": 0.1149,
      "step": 6280
    },
    {
      "epoch": 2.5393621316108197,
      "grad_norm": 7.818732261657715,
      "learning_rate": 1.746063786838918e-05,
      "loss": 0.0999,
      "step": 6290
    },
    {
      "epoch": 2.5433992733144932,
      "grad_norm": 0.4612138271331787,
      "learning_rate": 1.7456600726685508e-05,
      "loss": 0.1,
      "step": 6300
    },
    {
      "epoch": 2.547436415018167,
      "grad_norm": 3.8747053146362305,
      "learning_rate": 1.7452563584981833e-05,
      "loss": 0.0556,
      "step": 6310
    },
    {
      "epoch": 2.5514735567218407,
      "grad_norm": 1.210169792175293,
      "learning_rate": 1.744852644327816e-05,
      "loss": 0.101,
      "step": 6320
    },
    {
      "epoch": 2.5555106984255147,
      "grad_norm": 0.23635220527648926,
      "learning_rate": 1.744448930157449e-05,
      "loss": 0.0435,
      "step": 6330
    },
    {
      "epoch": 2.5595478401291887,
      "grad_norm": 4.603768825531006,
      "learning_rate": 1.7440452159870813e-05,
      "loss": 0.0354,
      "step": 6340
    },
    {
      "epoch": 2.563584981832862,
      "grad_norm": 0.6577786803245544,
      "learning_rate": 1.7436415018167138e-05,
      "loss": 0.0436,
      "step": 6350
    },
    {
      "epoch": 2.567622123536536,
      "grad_norm": 5.2133026123046875,
      "learning_rate": 1.7432377876463466e-05,
      "loss": 0.0835,
      "step": 6360
    },
    {
      "epoch": 2.5716592652402097,
      "grad_norm": 7.123495578765869,
      "learning_rate": 1.742834073475979e-05,
      "loss": 0.0715,
      "step": 6370
    },
    {
      "epoch": 2.5756964069438837,
      "grad_norm": 1.7305399179458618,
      "learning_rate": 1.742430359305612e-05,
      "loss": 0.0304,
      "step": 6380
    },
    {
      "epoch": 2.5797335486475577,
      "grad_norm": 0.02695648930966854,
      "learning_rate": 1.7420266451352443e-05,
      "loss": 0.084,
      "step": 6390
    },
    {
      "epoch": 2.583770690351231,
      "grad_norm": 0.07140947133302689,
      "learning_rate": 1.741622930964877e-05,
      "loss": 0.1016,
      "step": 6400
    },
    {
      "epoch": 2.587807832054905,
      "grad_norm": 0.19154123961925507,
      "learning_rate": 1.7412192167945096e-05,
      "loss": 0.0373,
      "step": 6410
    },
    {
      "epoch": 2.5918449737585787,
      "grad_norm": 0.35840409994125366,
      "learning_rate": 1.7408155026241424e-05,
      "loss": 0.0703,
      "step": 6420
    },
    {
      "epoch": 2.5958821154622527,
      "grad_norm": 0.06450778990983963,
      "learning_rate": 1.7404117884537748e-05,
      "loss": 0.0518,
      "step": 6430
    },
    {
      "epoch": 2.5999192571659266,
      "grad_norm": 4.621079444885254,
      "learning_rate": 1.7400080742834076e-05,
      "loss": 0.0424,
      "step": 6440
    },
    {
      "epoch": 2.6039563988696,
      "grad_norm": 2.4840784072875977,
      "learning_rate": 1.73960436011304e-05,
      "loss": 0.0531,
      "step": 6450
    },
    {
      "epoch": 2.607993540573274,
      "grad_norm": 6.001626014709473,
      "learning_rate": 1.7392006459426725e-05,
      "loss": 0.0588,
      "step": 6460
    },
    {
      "epoch": 2.6120306822769477,
      "grad_norm": 8.962393760681152,
      "learning_rate": 1.7387969317723053e-05,
      "loss": 0.0606,
      "step": 6470
    },
    {
      "epoch": 2.6160678239806217,
      "grad_norm": 10.971391677856445,
      "learning_rate": 1.738393217601938e-05,
      "loss": 0.0759,
      "step": 6480
    },
    {
      "epoch": 2.6201049656842956,
      "grad_norm": 0.07241711020469666,
      "learning_rate": 1.7379895034315706e-05,
      "loss": 0.037,
      "step": 6490
    },
    {
      "epoch": 2.624142107387969,
      "grad_norm": 0.008403855375945568,
      "learning_rate": 1.737585789261203e-05,
      "loss": 0.036,
      "step": 6500
    },
    {
      "epoch": 2.628179249091643,
      "grad_norm": 0.12637624144554138,
      "learning_rate": 1.737182075090836e-05,
      "loss": 0.0768,
      "step": 6510
    },
    {
      "epoch": 2.6322163907953167,
      "grad_norm": 10.943730354309082,
      "learning_rate": 1.7367783609204683e-05,
      "loss": 0.0611,
      "step": 6520
    },
    {
      "epoch": 2.6362535324989906,
      "grad_norm": 17.055511474609375,
      "learning_rate": 1.736374646750101e-05,
      "loss": 0.031,
      "step": 6530
    },
    {
      "epoch": 2.6402906742026646,
      "grad_norm": 0.03680882975459099,
      "learning_rate": 1.7359709325797336e-05,
      "loss": 0.0597,
      "step": 6540
    },
    {
      "epoch": 2.6443278159063386,
      "grad_norm": 0.004130897577852011,
      "learning_rate": 1.7355672184093664e-05,
      "loss": 0.0548,
      "step": 6550
    },
    {
      "epoch": 2.648364957610012,
      "grad_norm": 0.7961242198944092,
      "learning_rate": 1.7351635042389988e-05,
      "loss": 0.0376,
      "step": 6560
    },
    {
      "epoch": 2.6524020993136856,
      "grad_norm": 0.13081686198711395,
      "learning_rate": 1.7347597900686316e-05,
      "loss": 0.0663,
      "step": 6570
    },
    {
      "epoch": 2.6564392410173596,
      "grad_norm": 0.13057053089141846,
      "learning_rate": 1.7343560758982644e-05,
      "loss": 0.0443,
      "step": 6580
    },
    {
      "epoch": 2.6604763827210336,
      "grad_norm": 0.0054020751267671585,
      "learning_rate": 1.733952361727897e-05,
      "loss": 0.0089,
      "step": 6590
    },
    {
      "epoch": 2.6645135244247076,
      "grad_norm": 4.213027000427246,
      "learning_rate": 1.7335486475575293e-05,
      "loss": 0.0484,
      "step": 6600
    },
    {
      "epoch": 2.668550666128381,
      "grad_norm": 0.3249545991420746,
      "learning_rate": 1.7331449333871618e-05,
      "loss": 0.0954,
      "step": 6610
    },
    {
      "epoch": 2.6725878078320546,
      "grad_norm": 0.17634567618370056,
      "learning_rate": 1.7327412192167946e-05,
      "loss": 0.062,
      "step": 6620
    },
    {
      "epoch": 2.6766249495357286,
      "grad_norm": 2.4346923828125,
      "learning_rate": 1.7323375050464274e-05,
      "loss": 0.0187,
      "step": 6630
    },
    {
      "epoch": 2.6806620912394026,
      "grad_norm": 0.03469855710864067,
      "learning_rate": 1.73193379087606e-05,
      "loss": 0.0631,
      "step": 6640
    },
    {
      "epoch": 2.6846992329430766,
      "grad_norm": 0.8593005537986755,
      "learning_rate": 1.7315300767056927e-05,
      "loss": 0.0479,
      "step": 6650
    },
    {
      "epoch": 2.68873637464675,
      "grad_norm": 7.3431620597839355,
      "learning_rate": 1.731126362535325e-05,
      "loss": 0.0345,
      "step": 6660
    },
    {
      "epoch": 2.692773516350424,
      "grad_norm": 6.295708179473877,
      "learning_rate": 1.7307226483649576e-05,
      "loss": 0.0822,
      "step": 6670
    },
    {
      "epoch": 2.6968106580540976,
      "grad_norm": 0.016577767208218575,
      "learning_rate": 1.7303189341945904e-05,
      "loss": 0.047,
      "step": 6680
    },
    {
      "epoch": 2.7008477997577716,
      "grad_norm": 0.11061030626296997,
      "learning_rate": 1.729915220024223e-05,
      "loss": 0.0342,
      "step": 6690
    },
    {
      "epoch": 2.7048849414614455,
      "grad_norm": 5.481801509857178,
      "learning_rate": 1.7295115058538556e-05,
      "loss": 0.0639,
      "step": 6700
    },
    {
      "epoch": 2.708922083165119,
      "grad_norm": 0.779048502445221,
      "learning_rate": 1.729107791683488e-05,
      "loss": 0.0577,
      "step": 6710
    },
    {
      "epoch": 2.712959224868793,
      "grad_norm": 10.050070762634277,
      "learning_rate": 1.728704077513121e-05,
      "loss": 0.1026,
      "step": 6720
    },
    {
      "epoch": 2.7169963665724666,
      "grad_norm": 3.1111276149749756,
      "learning_rate": 1.7283003633427537e-05,
      "loss": 0.0273,
      "step": 6730
    },
    {
      "epoch": 2.7210335082761405,
      "grad_norm": 0.04155873879790306,
      "learning_rate": 1.727896649172386e-05,
      "loss": 0.0749,
      "step": 6740
    },
    {
      "epoch": 2.7250706499798145,
      "grad_norm": 0.04844342917203903,
      "learning_rate": 1.7274929350020186e-05,
      "loss": 0.054,
      "step": 6750
    },
    {
      "epoch": 2.729107791683488,
      "grad_norm": 3.309906244277954,
      "learning_rate": 1.7270892208316514e-05,
      "loss": 0.0347,
      "step": 6760
    },
    {
      "epoch": 2.733144933387162,
      "grad_norm": 4.23687744140625,
      "learning_rate": 1.726685506661284e-05,
      "loss": 0.0564,
      "step": 6770
    },
    {
      "epoch": 2.7371820750908356,
      "grad_norm": 2.8240253925323486,
      "learning_rate": 1.7262817924909167e-05,
      "loss": 0.0484,
      "step": 6780
    },
    {
      "epoch": 2.7412192167945095,
      "grad_norm": 0.7223816514015198,
      "learning_rate": 1.725878078320549e-05,
      "loss": 0.0106,
      "step": 6790
    },
    {
      "epoch": 2.7452563584981835,
      "grad_norm": 0.14505410194396973,
      "learning_rate": 1.725474364150182e-05,
      "loss": 0.0253,
      "step": 6800
    },
    {
      "epoch": 2.749293500201857,
      "grad_norm": 0.13983556628227234,
      "learning_rate": 1.7250706499798144e-05,
      "loss": 0.0714,
      "step": 6810
    },
    {
      "epoch": 2.753330641905531,
      "grad_norm": 0.015170569531619549,
      "learning_rate": 1.724666935809447e-05,
      "loss": 0.014,
      "step": 6820
    },
    {
      "epoch": 2.7573677836092045,
      "grad_norm": 0.009666603058576584,
      "learning_rate": 1.7242632216390796e-05,
      "loss": 0.066,
      "step": 6830
    },
    {
      "epoch": 2.7614049253128785,
      "grad_norm": 0.0070279729552567005,
      "learning_rate": 1.7238595074687124e-05,
      "loss": 0.0393,
      "step": 6840
    },
    {
      "epoch": 2.7654420670165525,
      "grad_norm": 0.8946846723556519,
      "learning_rate": 1.723455793298345e-05,
      "loss": 0.0413,
      "step": 6850
    },
    {
      "epoch": 2.769479208720226,
      "grad_norm": 0.026475656777620316,
      "learning_rate": 1.7230520791279773e-05,
      "loss": 0.0176,
      "step": 6860
    },
    {
      "epoch": 2.7735163504239,
      "grad_norm": 0.3239860534667969,
      "learning_rate": 1.72264836495761e-05,
      "loss": 0.0026,
      "step": 6870
    },
    {
      "epoch": 2.7775534921275735,
      "grad_norm": 12.097074508666992,
      "learning_rate": 1.722244650787243e-05,
      "loss": 0.0223,
      "step": 6880
    },
    {
      "epoch": 2.7815906338312475,
      "grad_norm": 0.05197647958993912,
      "learning_rate": 1.7218409366168754e-05,
      "loss": 0.0209,
      "step": 6890
    },
    {
      "epoch": 2.7856277755349215,
      "grad_norm": 0.07526378333568573,
      "learning_rate": 1.721437222446508e-05,
      "loss": 0.0949,
      "step": 6900
    },
    {
      "epoch": 2.789664917238595,
      "grad_norm": 0.011551878415048122,
      "learning_rate": 1.7210335082761407e-05,
      "loss": 0.0968,
      "step": 6910
    },
    {
      "epoch": 2.793702058942269,
      "grad_norm": 7.8915886878967285,
      "learning_rate": 1.720629794105773e-05,
      "loss": 0.1212,
      "step": 6920
    },
    {
      "epoch": 2.7977392006459425,
      "grad_norm": 3.4624855518341064,
      "learning_rate": 1.720226079935406e-05,
      "loss": 0.0256,
      "step": 6930
    },
    {
      "epoch": 2.8017763423496165,
      "grad_norm": 1.7743083238601685,
      "learning_rate": 1.7198223657650387e-05,
      "loss": 0.0238,
      "step": 6940
    },
    {
      "epoch": 2.8058134840532905,
      "grad_norm": 11.331963539123535,
      "learning_rate": 1.7194186515946712e-05,
      "loss": 0.0457,
      "step": 6950
    },
    {
      "epoch": 2.809850625756964,
      "grad_norm": 0.32927432656288147,
      "learning_rate": 1.7190149374243036e-05,
      "loss": 0.0127,
      "step": 6960
    },
    {
      "epoch": 2.813887767460638,
      "grad_norm": 0.010270251892507076,
      "learning_rate": 1.718611223253936e-05,
      "loss": 0.018,
      "step": 6970
    },
    {
      "epoch": 2.8179249091643115,
      "grad_norm": 10.082989692687988,
      "learning_rate": 1.718207509083569e-05,
      "loss": 0.0463,
      "step": 6980
    },
    {
      "epoch": 2.8219620508679855,
      "grad_norm": 3.617424488067627,
      "learning_rate": 1.7178037949132017e-05,
      "loss": 0.027,
      "step": 6990
    },
    {
      "epoch": 2.8259991925716594,
      "grad_norm": 2.676701545715332,
      "learning_rate": 1.717400080742834e-05,
      "loss": 0.0756,
      "step": 7000
    },
    {
      "epoch": 2.830036334275333,
      "grad_norm": 0.16562534868717194,
      "learning_rate": 1.716996366572467e-05,
      "loss": 0.0188,
      "step": 7010
    },
    {
      "epoch": 2.834073475979007,
      "grad_norm": 2.8159122467041016,
      "learning_rate": 1.7165926524020994e-05,
      "loss": 0.0503,
      "step": 7020
    },
    {
      "epoch": 2.8381106176826805,
      "grad_norm": 0.03290598466992378,
      "learning_rate": 1.7161889382317322e-05,
      "loss": 0.0118,
      "step": 7030
    },
    {
      "epoch": 2.8421477593863544,
      "grad_norm": 5.54113245010376,
      "learning_rate": 1.7157852240613647e-05,
      "loss": 0.0305,
      "step": 7040
    },
    {
      "epoch": 2.8461849010900284,
      "grad_norm": 5.721187591552734,
      "learning_rate": 1.7153815098909975e-05,
      "loss": 0.1064,
      "step": 7050
    },
    {
      "epoch": 2.850222042793702,
      "grad_norm": 4.477302551269531,
      "learning_rate": 1.71497779572063e-05,
      "loss": 0.0084,
      "step": 7060
    },
    {
      "epoch": 2.854259184497376,
      "grad_norm": 0.2821093499660492,
      "learning_rate": 1.7145740815502624e-05,
      "loss": 0.0189,
      "step": 7070
    },
    {
      "epoch": 2.8582963262010495,
      "grad_norm": 0.009748725220561028,
      "learning_rate": 1.7141703673798952e-05,
      "loss": 0.0357,
      "step": 7080
    },
    {
      "epoch": 2.8623334679047234,
      "grad_norm": 0.06294266879558563,
      "learning_rate": 1.713766653209528e-05,
      "loss": 0.1012,
      "step": 7090
    },
    {
      "epoch": 2.8663706096083974,
      "grad_norm": 2.4933202266693115,
      "learning_rate": 1.7133629390391604e-05,
      "loss": 0.034,
      "step": 7100
    },
    {
      "epoch": 2.870407751312071,
      "grad_norm": 0.012884125113487244,
      "learning_rate": 1.712959224868793e-05,
      "loss": 0.0545,
      "step": 7110
    },
    {
      "epoch": 2.874444893015745,
      "grad_norm": 8.130475997924805,
      "learning_rate": 1.7125555106984257e-05,
      "loss": 0.0333,
      "step": 7120
    },
    {
      "epoch": 2.8784820347194184,
      "grad_norm": 0.1284341663122177,
      "learning_rate": 1.712151796528058e-05,
      "loss": 0.0563,
      "step": 7130
    },
    {
      "epoch": 2.8825191764230924,
      "grad_norm": 4.621744632720947,
      "learning_rate": 1.711748082357691e-05,
      "loss": 0.0614,
      "step": 7140
    },
    {
      "epoch": 2.8865563181267664,
      "grad_norm": 7.360837459564209,
      "learning_rate": 1.7113443681873234e-05,
      "loss": 0.0405,
      "step": 7150
    },
    {
      "epoch": 2.89059345983044,
      "grad_norm": 0.01941712200641632,
      "learning_rate": 1.7109406540169562e-05,
      "loss": 0.0458,
      "step": 7160
    },
    {
      "epoch": 2.894630601534114,
      "grad_norm": 3.7507989406585693,
      "learning_rate": 1.7105369398465887e-05,
      "loss": 0.035,
      "step": 7170
    },
    {
      "epoch": 2.8986677432377874,
      "grad_norm": 7.050987243652344,
      "learning_rate": 1.7101332256762215e-05,
      "loss": 0.097,
      "step": 7180
    },
    {
      "epoch": 2.9027048849414614,
      "grad_norm": 0.6627100110054016,
      "learning_rate": 1.709729511505854e-05,
      "loss": 0.0252,
      "step": 7190
    },
    {
      "epoch": 2.9067420266451354,
      "grad_norm": 10.589841842651367,
      "learning_rate": 1.7093257973354867e-05,
      "loss": 0.0971,
      "step": 7200
    },
    {
      "epoch": 2.910779168348809,
      "grad_norm": 0.14888976514339447,
      "learning_rate": 1.7089220831651192e-05,
      "loss": 0.0203,
      "step": 7210
    },
    {
      "epoch": 2.914816310052483,
      "grad_norm": 6.094535827636719,
      "learning_rate": 1.7085183689947516e-05,
      "loss": 0.1261,
      "step": 7220
    },
    {
      "epoch": 2.9188534517561564,
      "grad_norm": 1.0453276634216309,
      "learning_rate": 1.7081146548243844e-05,
      "loss": 0.0098,
      "step": 7230
    },
    {
      "epoch": 2.9228905934598304,
      "grad_norm": 8.244091987609863,
      "learning_rate": 1.7077109406540172e-05,
      "loss": 0.0329,
      "step": 7240
    },
    {
      "epoch": 2.9269277351635044,
      "grad_norm": 0.4460565447807312,
      "learning_rate": 1.7073072264836497e-05,
      "loss": 0.0371,
      "step": 7250
    },
    {
      "epoch": 2.930964876867178,
      "grad_norm": 5.792065143585205,
      "learning_rate": 1.7069035123132825e-05,
      "loss": 0.0413,
      "step": 7260
    },
    {
      "epoch": 2.935002018570852,
      "grad_norm": 0.026717109605669975,
      "learning_rate": 1.706499798142915e-05,
      "loss": 0.0093,
      "step": 7270
    },
    {
      "epoch": 2.9390391602745254,
      "grad_norm": 0.354705810546875,
      "learning_rate": 1.7060960839725474e-05,
      "loss": 0.0092,
      "step": 7280
    },
    {
      "epoch": 2.9430763019781994,
      "grad_norm": 10.39104175567627,
      "learning_rate": 1.7056923698021802e-05,
      "loss": 0.0275,
      "step": 7290
    },
    {
      "epoch": 2.9471134436818733,
      "grad_norm": 0.0035960315726697445,
      "learning_rate": 1.705288655631813e-05,
      "loss": 0.0173,
      "step": 7300
    },
    {
      "epoch": 2.9511505853855473,
      "grad_norm": 0.025634320452809334,
      "learning_rate": 1.7048849414614455e-05,
      "loss": 0.0347,
      "step": 7310
    },
    {
      "epoch": 2.955187727089221,
      "grad_norm": 0.04724124073982239,
      "learning_rate": 1.704481227291078e-05,
      "loss": 0.0538,
      "step": 7320
    },
    {
      "epoch": 2.9592248687928944,
      "grad_norm": 0.005276721436530352,
      "learning_rate": 1.7040775131207107e-05,
      "loss": 0.0872,
      "step": 7330
    },
    {
      "epoch": 2.9632620104965683,
      "grad_norm": 0.02150818705558777,
      "learning_rate": 1.7036737989503432e-05,
      "loss": 0.1249,
      "step": 7340
    },
    {
      "epoch": 2.9672991522002423,
      "grad_norm": 2.85715913772583,
      "learning_rate": 1.703270084779976e-05,
      "loss": 0.0153,
      "step": 7350
    },
    {
      "epoch": 2.9713362939039163,
      "grad_norm": 0.016456497833132744,
      "learning_rate": 1.7028663706096084e-05,
      "loss": 0.0449,
      "step": 7360
    },
    {
      "epoch": 2.97537343560759,
      "grad_norm": 0.5470654964447021,
      "learning_rate": 1.7024626564392412e-05,
      "loss": 0.0247,
      "step": 7370
    },
    {
      "epoch": 2.9794105773112634,
      "grad_norm": 0.7328516244888306,
      "learning_rate": 1.7020589422688737e-05,
      "loss": 0.044,
      "step": 7380
    },
    {
      "epoch": 2.9834477190149373,
      "grad_norm": 3.462757110595703,
      "learning_rate": 1.7016552280985065e-05,
      "loss": 0.0974,
      "step": 7390
    },
    {
      "epoch": 2.9874848607186113,
      "grad_norm": 0.016559449955821037,
      "learning_rate": 1.701251513928139e-05,
      "loss": 0.0129,
      "step": 7400
    },
    {
      "epoch": 2.9915220024222853,
      "grad_norm": 3.238262176513672,
      "learning_rate": 1.7008477997577718e-05,
      "loss": 0.0113,
      "step": 7410
    },
    {
      "epoch": 2.995559144125959,
      "grad_norm": 0.8954494595527649,
      "learning_rate": 1.7004440855874042e-05,
      "loss": 0.0199,
      "step": 7420
    },
    {
      "epoch": 2.999596285829633,
      "grad_norm": 4.797427654266357,
      "learning_rate": 1.7000403714170367e-05,
      "loss": 0.084,
      "step": 7430
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9836477987421384,
      "eval_f1": 0.9398148148148149,
      "eval_loss": 0.0654696598649025,
      "eval_precision": 0.9463869463869464,
      "eval_recall": 0.9333333333333333,
      "eval_runtime": 445.9305,
      "eval_samples_per_second": 28.569,
      "eval_steps_per_second": 1.191,
      "step": 7431
    },
    {
      "epoch": 3.0036334275333063,
      "grad_norm": 0.039318691939115524,
      "learning_rate": 1.6996366572466695e-05,
      "loss": 0.0373,
      "step": 7440
    },
    {
      "epoch": 3.0076705692369803,
      "grad_norm": 0.8635672926902771,
      "learning_rate": 1.6992329430763023e-05,
      "loss": 0.0213,
      "step": 7450
    },
    {
      "epoch": 3.011707710940654,
      "grad_norm": 0.026402510702610016,
      "learning_rate": 1.6988292289059347e-05,
      "loss": 0.0302,
      "step": 7460
    },
    {
      "epoch": 3.015744852644328,
      "grad_norm": 2.4811654090881348,
      "learning_rate": 1.6984255147355672e-05,
      "loss": 0.0209,
      "step": 7470
    },
    {
      "epoch": 3.0197819943480018,
      "grad_norm": 2.3789303302764893,
      "learning_rate": 1.6980218005652e-05,
      "loss": 0.0117,
      "step": 7480
    },
    {
      "epoch": 3.0238191360516753,
      "grad_norm": 0.011550407856702805,
      "learning_rate": 1.6976180863948324e-05,
      "loss": 0.0401,
      "step": 7490
    },
    {
      "epoch": 3.0278562777553493,
      "grad_norm": 4.386717319488525,
      "learning_rate": 1.6972143722244652e-05,
      "loss": 0.0554,
      "step": 7500
    },
    {
      "epoch": 3.031893419459023,
      "grad_norm": 0.025644972920417786,
      "learning_rate": 1.696810658054098e-05,
      "loss": 0.0191,
      "step": 7510
    },
    {
      "epoch": 3.0359305611626968,
      "grad_norm": 0.12247470766305923,
      "learning_rate": 1.6964069438837305e-05,
      "loss": 0.0163,
      "step": 7520
    },
    {
      "epoch": 3.0399677028663707,
      "grad_norm": 2.481093168258667,
      "learning_rate": 1.696003229713363e-05,
      "loss": 0.0693,
      "step": 7530
    },
    {
      "epoch": 3.0440048445700443,
      "grad_norm": 0.24916550517082214,
      "learning_rate": 1.6955995155429958e-05,
      "loss": 0.0184,
      "step": 7540
    },
    {
      "epoch": 3.0480419862737183,
      "grad_norm": 0.020093856379389763,
      "learning_rate": 1.6951958013726286e-05,
      "loss": 0.0002,
      "step": 7550
    },
    {
      "epoch": 3.0520791279773922,
      "grad_norm": 0.03257155045866966,
      "learning_rate": 1.694792087202261e-05,
      "loss": 0.0428,
      "step": 7560
    },
    {
      "epoch": 3.0561162696810658,
      "grad_norm": 0.018809041008353233,
      "learning_rate": 1.6943883730318935e-05,
      "loss": 0.0078,
      "step": 7570
    },
    {
      "epoch": 3.0601534113847397,
      "grad_norm": 1.8685102462768555,
      "learning_rate": 1.693984658861526e-05,
      "loss": 0.0134,
      "step": 7580
    },
    {
      "epoch": 3.0641905530884133,
      "grad_norm": 1.6887195110321045,
      "learning_rate": 1.6935809446911587e-05,
      "loss": 0.1277,
      "step": 7590
    },
    {
      "epoch": 3.0682276947920872,
      "grad_norm": 0.022989820688962936,
      "learning_rate": 1.6931772305207915e-05,
      "loss": 0.0978,
      "step": 7600
    },
    {
      "epoch": 3.072264836495761,
      "grad_norm": 33.09358215332031,
      "learning_rate": 1.692773516350424e-05,
      "loss": 0.0789,
      "step": 7610
    },
    {
      "epoch": 3.0763019781994347,
      "grad_norm": 1.0503672361373901,
      "learning_rate": 1.6923698021800568e-05,
      "loss": 0.0141,
      "step": 7620
    },
    {
      "epoch": 3.0803391199031087,
      "grad_norm": 0.0798511728644371,
      "learning_rate": 1.6919660880096892e-05,
      "loss": 0.042,
      "step": 7630
    },
    {
      "epoch": 3.0843762616067822,
      "grad_norm": 0.9667218327522278,
      "learning_rate": 1.6915623738393217e-05,
      "loss": 0.0403,
      "step": 7640
    },
    {
      "epoch": 3.088413403310456,
      "grad_norm": 0.007457762490957975,
      "learning_rate": 1.6911586596689545e-05,
      "loss": 0.0249,
      "step": 7650
    },
    {
      "epoch": 3.09245054501413,
      "grad_norm": 0.05631297081708908,
      "learning_rate": 1.6907549454985873e-05,
      "loss": 0.0972,
      "step": 7660
    },
    {
      "epoch": 3.0964876867178037,
      "grad_norm": 0.2990357279777527,
      "learning_rate": 1.6903512313282198e-05,
      "loss": 0.0475,
      "step": 7670
    },
    {
      "epoch": 3.1005248284214777,
      "grad_norm": 0.025140630081295967,
      "learning_rate": 1.6899475171578522e-05,
      "loss": 0.0276,
      "step": 7680
    },
    {
      "epoch": 3.1045619701251512,
      "grad_norm": 1.014373779296875,
      "learning_rate": 1.689543802987485e-05,
      "loss": 0.0678,
      "step": 7690
    },
    {
      "epoch": 3.108599111828825,
      "grad_norm": 0.009870611131191254,
      "learning_rate": 1.6891400888171178e-05,
      "loss": 0.0113,
      "step": 7700
    },
    {
      "epoch": 3.112636253532499,
      "grad_norm": 0.009931075386703014,
      "learning_rate": 1.6887363746467503e-05,
      "loss": 0.0457,
      "step": 7710
    },
    {
      "epoch": 3.1166733952361727,
      "grad_norm": 0.04756214842200279,
      "learning_rate": 1.6883326604763827e-05,
      "loss": 0.0157,
      "step": 7720
    },
    {
      "epoch": 3.1207105369398467,
      "grad_norm": 4.63983678817749,
      "learning_rate": 1.6879289463060155e-05,
      "loss": 0.0439,
      "step": 7730
    },
    {
      "epoch": 3.12474767864352,
      "grad_norm": 0.008433881215751171,
      "learning_rate": 1.687525232135648e-05,
      "loss": 0.0472,
      "step": 7740
    },
    {
      "epoch": 3.128784820347194,
      "grad_norm": 0.013760379515588284,
      "learning_rate": 1.6871215179652808e-05,
      "loss": 0.0248,
      "step": 7750
    },
    {
      "epoch": 3.132821962050868,
      "grad_norm": 7.36331033706665,
      "learning_rate": 1.6867178037949133e-05,
      "loss": 0.0072,
      "step": 7760
    },
    {
      "epoch": 3.1368591037545417,
      "grad_norm": 0.07298577576875687,
      "learning_rate": 1.686314089624546e-05,
      "loss": 0.0356,
      "step": 7770
    },
    {
      "epoch": 3.1408962454582157,
      "grad_norm": 0.10146435350179672,
      "learning_rate": 1.6859103754541785e-05,
      "loss": 0.0259,
      "step": 7780
    },
    {
      "epoch": 3.144933387161889,
      "grad_norm": 0.01473391056060791,
      "learning_rate": 1.685506661283811e-05,
      "loss": 0.045,
      "step": 7790
    },
    {
      "epoch": 3.148970528865563,
      "grad_norm": 0.4372994303703308,
      "learning_rate": 1.6851029471134438e-05,
      "loss": 0.0247,
      "step": 7800
    },
    {
      "epoch": 3.153007670569237,
      "grad_norm": 0.48926717042922974,
      "learning_rate": 1.6846992329430766e-05,
      "loss": 0.0642,
      "step": 7810
    },
    {
      "epoch": 3.1570448122729107,
      "grad_norm": 1.0439831018447876,
      "learning_rate": 1.684295518772709e-05,
      "loss": 0.0057,
      "step": 7820
    },
    {
      "epoch": 3.1610819539765846,
      "grad_norm": 2.6679041385650635,
      "learning_rate": 1.6838918046023415e-05,
      "loss": 0.0389,
      "step": 7830
    },
    {
      "epoch": 3.165119095680258,
      "grad_norm": 0.033064503222703934,
      "learning_rate": 1.6834880904319743e-05,
      "loss": 0.0599,
      "step": 7840
    },
    {
      "epoch": 3.169156237383932,
      "grad_norm": 0.057137928903102875,
      "learning_rate": 1.683084376261607e-05,
      "loss": 0.0069,
      "step": 7850
    },
    {
      "epoch": 3.173193379087606,
      "grad_norm": 0.018131239339709282,
      "learning_rate": 1.6826806620912395e-05,
      "loss": 0.0209,
      "step": 7860
    },
    {
      "epoch": 3.1772305207912797,
      "grad_norm": 2.37568998336792,
      "learning_rate": 1.6822769479208723e-05,
      "loss": 0.0253,
      "step": 7870
    },
    {
      "epoch": 3.1812676624949536,
      "grad_norm": 1.4889501333236694,
      "learning_rate": 1.6818732337505048e-05,
      "loss": 0.0216,
      "step": 7880
    },
    {
      "epoch": 3.185304804198627,
      "grad_norm": 6.63511848449707,
      "learning_rate": 1.6814695195801373e-05,
      "loss": 0.0431,
      "step": 7890
    },
    {
      "epoch": 3.189341945902301,
      "grad_norm": 1.2082340717315674,
      "learning_rate": 1.68106580540977e-05,
      "loss": 0.0313,
      "step": 7900
    },
    {
      "epoch": 3.193379087605975,
      "grad_norm": 0.017296085134148598,
      "learning_rate": 1.680662091239403e-05,
      "loss": 0.0891,
      "step": 7910
    },
    {
      "epoch": 3.1974162293096486,
      "grad_norm": 3.642831802368164,
      "learning_rate": 1.6802583770690353e-05,
      "loss": 0.0823,
      "step": 7920
    },
    {
      "epoch": 3.2014533710133226,
      "grad_norm": 0.0667896568775177,
      "learning_rate": 1.6798546628986678e-05,
      "loss": 0.0259,
      "step": 7930
    },
    {
      "epoch": 3.205490512716996,
      "grad_norm": 0.2225877195596695,
      "learning_rate": 1.6794509487283002e-05,
      "loss": 0.0785,
      "step": 7940
    },
    {
      "epoch": 3.20952765442067,
      "grad_norm": 0.0037596221081912518,
      "learning_rate": 1.679047234557933e-05,
      "loss": 0.0126,
      "step": 7950
    },
    {
      "epoch": 3.213564796124344,
      "grad_norm": 2.417976140975952,
      "learning_rate": 1.6786435203875658e-05,
      "loss": 0.0788,
      "step": 7960
    },
    {
      "epoch": 3.2176019378280176,
      "grad_norm": 1.798376202583313,
      "learning_rate": 1.6782398062171983e-05,
      "loss": 0.0353,
      "step": 7970
    },
    {
      "epoch": 3.2216390795316916,
      "grad_norm": 0.041441455483436584,
      "learning_rate": 1.677836092046831e-05,
      "loss": 0.0423,
      "step": 7980
    },
    {
      "epoch": 3.225676221235365,
      "grad_norm": 0.18432025611400604,
      "learning_rate": 1.6774323778764635e-05,
      "loss": 0.0499,
      "step": 7990
    },
    {
      "epoch": 3.229713362939039,
      "grad_norm": 1.5268200635910034,
      "learning_rate": 1.6770286637060963e-05,
      "loss": 0.0759,
      "step": 8000
    },
    {
      "epoch": 3.233750504642713,
      "grad_norm": 4.3716630935668945,
      "learning_rate": 1.6766249495357288e-05,
      "loss": 0.0587,
      "step": 8010
    },
    {
      "epoch": 3.2377876463463866,
      "grad_norm": 0.05112798139452934,
      "learning_rate": 1.6762212353653616e-05,
      "loss": 0.0194,
      "step": 8020
    },
    {
      "epoch": 3.2418247880500606,
      "grad_norm": 0.11543039232492447,
      "learning_rate": 1.675817521194994e-05,
      "loss": 0.0386,
      "step": 8030
    },
    {
      "epoch": 3.2458619297537346,
      "grad_norm": 0.0425250381231308,
      "learning_rate": 1.6754138070246265e-05,
      "loss": 0.0318,
      "step": 8040
    },
    {
      "epoch": 3.249899071457408,
      "grad_norm": 0.05653742700815201,
      "learning_rate": 1.6750100928542593e-05,
      "loss": 0.0361,
      "step": 8050
    },
    {
      "epoch": 3.253936213161082,
      "grad_norm": 7.170351982116699,
      "learning_rate": 1.674606378683892e-05,
      "loss": 0.096,
      "step": 8060
    },
    {
      "epoch": 3.2579733548647556,
      "grad_norm": 0.023605626076459885,
      "learning_rate": 1.6742026645135246e-05,
      "loss": 0.055,
      "step": 8070
    },
    {
      "epoch": 3.2620104965684296,
      "grad_norm": 0.026126157492399216,
      "learning_rate": 1.673798950343157e-05,
      "loss": 0.0601,
      "step": 8080
    },
    {
      "epoch": 3.2660476382721035,
      "grad_norm": 0.20602063834667206,
      "learning_rate": 1.6733952361727898e-05,
      "loss": 0.0044,
      "step": 8090
    },
    {
      "epoch": 3.270084779975777,
      "grad_norm": 2.844449520111084,
      "learning_rate": 1.6729915220024223e-05,
      "loss": 0.0664,
      "step": 8100
    },
    {
      "epoch": 3.274121921679451,
      "grad_norm": 0.032654065638780594,
      "learning_rate": 1.672587807832055e-05,
      "loss": 0.0108,
      "step": 8110
    },
    {
      "epoch": 3.2781590633831246,
      "grad_norm": 0.020001374185085297,
      "learning_rate": 1.672184093661688e-05,
      "loss": 0.0748,
      "step": 8120
    },
    {
      "epoch": 3.2821962050867985,
      "grad_norm": 0.016841934993863106,
      "learning_rate": 1.6717803794913203e-05,
      "loss": 0.0312,
      "step": 8130
    },
    {
      "epoch": 3.2862333467904725,
      "grad_norm": 0.24270564317703247,
      "learning_rate": 1.6713766653209528e-05,
      "loss": 0.0009,
      "step": 8140
    },
    {
      "epoch": 3.290270488494146,
      "grad_norm": 8.845754623413086,
      "learning_rate": 1.6709729511505856e-05,
      "loss": 0.0417,
      "step": 8150
    },
    {
      "epoch": 3.29430763019782,
      "grad_norm": 0.00753297982737422,
      "learning_rate": 1.670569236980218e-05,
      "loss": 0.0165,
      "step": 8160
    },
    {
      "epoch": 3.2983447719014936,
      "grad_norm": 0.03909289464354515,
      "learning_rate": 1.670165522809851e-05,
      "loss": 0.0276,
      "step": 8170
    },
    {
      "epoch": 3.3023819136051675,
      "grad_norm": 10.062054634094238,
      "learning_rate": 1.6697618086394833e-05,
      "loss": 0.0829,
      "step": 8180
    },
    {
      "epoch": 3.3064190553088415,
      "grad_norm": 0.00723968306556344,
      "learning_rate": 1.6693580944691158e-05,
      "loss": 0.0173,
      "step": 8190
    },
    {
      "epoch": 3.310456197012515,
      "grad_norm": 0.05432532727718353,
      "learning_rate": 1.6689543802987486e-05,
      "loss": 0.0507,
      "step": 8200
    },
    {
      "epoch": 3.314493338716189,
      "grad_norm": 0.04857850819826126,
      "learning_rate": 1.6685506661283814e-05,
      "loss": 0.0113,
      "step": 8210
    },
    {
      "epoch": 3.318530480419863,
      "grad_norm": 14.938092231750488,
      "learning_rate": 1.668146951958014e-05,
      "loss": 0.0733,
      "step": 8220
    },
    {
      "epoch": 3.3225676221235365,
      "grad_norm": 0.011041812598705292,
      "learning_rate": 1.6677432377876466e-05,
      "loss": 0.03,
      "step": 8230
    },
    {
      "epoch": 3.3266047638272105,
      "grad_norm": 1.560896396636963,
      "learning_rate": 1.667339523617279e-05,
      "loss": 0.0803,
      "step": 8240
    },
    {
      "epoch": 3.330641905530884,
      "grad_norm": 0.0009964443743228912,
      "learning_rate": 1.6669358094469115e-05,
      "loss": 0.0513,
      "step": 8250
    },
    {
      "epoch": 3.334679047234558,
      "grad_norm": 2.2508177757263184,
      "learning_rate": 1.6665320952765443e-05,
      "loss": 0.0255,
      "step": 8260
    },
    {
      "epoch": 3.338716188938232,
      "grad_norm": 0.019969740882515907,
      "learning_rate": 1.666128381106177e-05,
      "loss": 0.0064,
      "step": 8270
    },
    {
      "epoch": 3.3427533306419055,
      "grad_norm": 0.0071594747714698315,
      "learning_rate": 1.6657246669358096e-05,
      "loss": 0.0232,
      "step": 8280
    },
    {
      "epoch": 3.3467904723455795,
      "grad_norm": 14.946146965026855,
      "learning_rate": 1.665320952765442e-05,
      "loss": 0.1006,
      "step": 8290
    },
    {
      "epoch": 3.350827614049253,
      "grad_norm": 0.006200140807777643,
      "learning_rate": 1.664917238595075e-05,
      "loss": 0.016,
      "step": 8300
    },
    {
      "epoch": 3.354864755752927,
      "grad_norm": 0.4619058072566986,
      "learning_rate": 1.6645135244247073e-05,
      "loss": 0.0645,
      "step": 8310
    },
    {
      "epoch": 3.358901897456601,
      "grad_norm": 1.5899674892425537,
      "learning_rate": 1.66410981025434e-05,
      "loss": 0.0544,
      "step": 8320
    },
    {
      "epoch": 3.3629390391602745,
      "grad_norm": 0.1431940346956253,
      "learning_rate": 1.6637060960839726e-05,
      "loss": 0.0051,
      "step": 8330
    },
    {
      "epoch": 3.3669761808639485,
      "grad_norm": 0.8735072612762451,
      "learning_rate": 1.6633023819136054e-05,
      "loss": 0.0407,
      "step": 8340
    },
    {
      "epoch": 3.371013322567622,
      "grad_norm": 0.008903289213776588,
      "learning_rate": 1.662898667743238e-05,
      "loss": 0.126,
      "step": 8350
    },
    {
      "epoch": 3.375050464271296,
      "grad_norm": 0.13484355807304382,
      "learning_rate": 1.6624949535728706e-05,
      "loss": 0.0359,
      "step": 8360
    },
    {
      "epoch": 3.37908760597497,
      "grad_norm": 0.05225609615445137,
      "learning_rate": 1.662091239402503e-05,
      "loss": 0.0097,
      "step": 8370
    },
    {
      "epoch": 3.3831247476786435,
      "grad_norm": 0.034308675676584244,
      "learning_rate": 1.661687525232136e-05,
      "loss": 0.0158,
      "step": 8380
    },
    {
      "epoch": 3.3871618893823174,
      "grad_norm": 0.08549422770738602,
      "learning_rate": 1.6612838110617683e-05,
      "loss": 0.0628,
      "step": 8390
    },
    {
      "epoch": 3.391199031085991,
      "grad_norm": 2.1797006130218506,
      "learning_rate": 1.6608800968914008e-05,
      "loss": 0.0263,
      "step": 8400
    },
    {
      "epoch": 3.395236172789665,
      "grad_norm": 0.11889699101448059,
      "learning_rate": 1.6604763827210336e-05,
      "loss": 0.0614,
      "step": 8410
    },
    {
      "epoch": 3.399273314493339,
      "grad_norm": 0.04693888872861862,
      "learning_rate": 1.6600726685506664e-05,
      "loss": 0.0344,
      "step": 8420
    },
    {
      "epoch": 3.4033104561970124,
      "grad_norm": 0.008360156789422035,
      "learning_rate": 1.659668954380299e-05,
      "loss": 0.0222,
      "step": 8430
    },
    {
      "epoch": 3.4073475979006864,
      "grad_norm": 6.235832214355469,
      "learning_rate": 1.6592652402099313e-05,
      "loss": 0.0219,
      "step": 8440
    },
    {
      "epoch": 3.41138473960436,
      "grad_norm": 3.0809428691864014,
      "learning_rate": 1.658861526039564e-05,
      "loss": 0.0476,
      "step": 8450
    },
    {
      "epoch": 3.415421881308034,
      "grad_norm": 0.031825173646211624,
      "learning_rate": 1.6584578118691966e-05,
      "loss": 0.0103,
      "step": 8460
    },
    {
      "epoch": 3.419459023011708,
      "grad_norm": 4.505325794219971,
      "learning_rate": 1.6580540976988294e-05,
      "loss": 0.0488,
      "step": 8470
    },
    {
      "epoch": 3.4234961647153814,
      "grad_norm": 0.008981430903077126,
      "learning_rate": 1.6576503835284622e-05,
      "loss": 0.0175,
      "step": 8480
    },
    {
      "epoch": 3.4275333064190554,
      "grad_norm": 6.4760823249816895,
      "learning_rate": 1.6572466693580946e-05,
      "loss": 0.0617,
      "step": 8490
    },
    {
      "epoch": 3.431570448122729,
      "grad_norm": 0.15326540172100067,
      "learning_rate": 1.656842955187727e-05,
      "loss": 0.0275,
      "step": 8500
    },
    {
      "epoch": 3.435607589826403,
      "grad_norm": 0.4672533869743347,
      "learning_rate": 1.65643924101736e-05,
      "loss": 0.0305,
      "step": 8510
    },
    {
      "epoch": 3.439644731530077,
      "grad_norm": 1.350459337234497,
      "learning_rate": 1.6560355268469927e-05,
      "loss": 0.0209,
      "step": 8520
    },
    {
      "epoch": 3.4436818732337504,
      "grad_norm": 4.918323993682861,
      "learning_rate": 1.655631812676625e-05,
      "loss": 0.0851,
      "step": 8530
    },
    {
      "epoch": 3.4477190149374244,
      "grad_norm": 4.428493976593018,
      "learning_rate": 1.6552280985062576e-05,
      "loss": 0.0382,
      "step": 8540
    },
    {
      "epoch": 3.451756156641098,
      "grad_norm": 0.4631558954715729,
      "learning_rate": 1.6548243843358904e-05,
      "loss": 0.0101,
      "step": 8550
    },
    {
      "epoch": 3.455793298344772,
      "grad_norm": 0.009090560488402843,
      "learning_rate": 1.654420670165523e-05,
      "loss": 0.0078,
      "step": 8560
    },
    {
      "epoch": 3.459830440048446,
      "grad_norm": 0.011391835287213326,
      "learning_rate": 1.6540169559951557e-05,
      "loss": 0.0109,
      "step": 8570
    },
    {
      "epoch": 3.4638675817521194,
      "grad_norm": 2.8166422843933105,
      "learning_rate": 1.653613241824788e-05,
      "loss": 0.0371,
      "step": 8580
    },
    {
      "epoch": 3.4679047234557934,
      "grad_norm": 0.012189370580017567,
      "learning_rate": 1.653209527654421e-05,
      "loss": 0.0313,
      "step": 8590
    },
    {
      "epoch": 3.471941865159467,
      "grad_norm": 4.811033725738525,
      "learning_rate": 1.6528058134840534e-05,
      "loss": 0.0402,
      "step": 8600
    },
    {
      "epoch": 3.475979006863141,
      "grad_norm": 0.007648366969078779,
      "learning_rate": 1.652402099313686e-05,
      "loss": 0.0186,
      "step": 8610
    },
    {
      "epoch": 3.480016148566815,
      "grad_norm": 0.056955091655254364,
      "learning_rate": 1.6519983851433186e-05,
      "loss": 0.0573,
      "step": 8620
    },
    {
      "epoch": 3.4840532902704884,
      "grad_norm": 3.4703943729400635,
      "learning_rate": 1.6515946709729514e-05,
      "loss": 0.0701,
      "step": 8630
    },
    {
      "epoch": 3.4880904319741624,
      "grad_norm": 3.8700475692749023,
      "learning_rate": 1.651190956802584e-05,
      "loss": 0.074,
      "step": 8640
    },
    {
      "epoch": 3.492127573677836,
      "grad_norm": 0.03231894597411156,
      "learning_rate": 1.6507872426322164e-05,
      "loss": 0.0627,
      "step": 8650
    },
    {
      "epoch": 3.49616471538151,
      "grad_norm": 0.036684390157461166,
      "learning_rate": 1.650383528461849e-05,
      "loss": 0.0071,
      "step": 8660
    },
    {
      "epoch": 3.500201857085184,
      "grad_norm": 0.34514254331588745,
      "learning_rate": 1.649979814291482e-05,
      "loss": 0.0196,
      "step": 8670
    },
    {
      "epoch": 3.5042389987888574,
      "grad_norm": 0.11905687302350998,
      "learning_rate": 1.6495761001211144e-05,
      "loss": 0.0391,
      "step": 8680
    },
    {
      "epoch": 3.5082761404925313,
      "grad_norm": 1.6862694025039673,
      "learning_rate": 1.649172385950747e-05,
      "loss": 0.0226,
      "step": 8690
    },
    {
      "epoch": 3.512313282196205,
      "grad_norm": 0.498405784368515,
      "learning_rate": 1.6487686717803797e-05,
      "loss": 0.0178,
      "step": 8700
    },
    {
      "epoch": 3.516350423899879,
      "grad_norm": 0.01827506348490715,
      "learning_rate": 1.648364957610012e-05,
      "loss": 0.1043,
      "step": 8710
    },
    {
      "epoch": 3.520387565603553,
      "grad_norm": 0.2878532111644745,
      "learning_rate": 1.647961243439645e-05,
      "loss": 0.1257,
      "step": 8720
    },
    {
      "epoch": 3.5244247073072263,
      "grad_norm": 0.04103337600827217,
      "learning_rate": 1.6475575292692777e-05,
      "loss": 0.0095,
      "step": 8730
    },
    {
      "epoch": 3.5284618490109003,
      "grad_norm": 2.243443727493286,
      "learning_rate": 1.6471538150989102e-05,
      "loss": 0.0142,
      "step": 8740
    },
    {
      "epoch": 3.532498990714574,
      "grad_norm": 0.14650943875312805,
      "learning_rate": 1.6467501009285426e-05,
      "loss": 0.0504,
      "step": 8750
    },
    {
      "epoch": 3.536536132418248,
      "grad_norm": 4.37496280670166,
      "learning_rate": 1.646346386758175e-05,
      "loss": 0.0449,
      "step": 8760
    },
    {
      "epoch": 3.540573274121922,
      "grad_norm": 2.7329530715942383,
      "learning_rate": 1.645942672587808e-05,
      "loss": 0.0122,
      "step": 8770
    },
    {
      "epoch": 3.5446104158255953,
      "grad_norm": 0.19181810319423676,
      "learning_rate": 1.6455389584174407e-05,
      "loss": 0.0112,
      "step": 8780
    },
    {
      "epoch": 3.5486475575292693,
      "grad_norm": 2.3979249000549316,
      "learning_rate": 1.645135244247073e-05,
      "loss": 0.046,
      "step": 8790
    },
    {
      "epoch": 3.552684699232943,
      "grad_norm": 0.012983191758394241,
      "learning_rate": 1.6447315300767056e-05,
      "loss": 0.0292,
      "step": 8800
    },
    {
      "epoch": 3.556721840936617,
      "grad_norm": 0.07528933882713318,
      "learning_rate": 1.6443278159063384e-05,
      "loss": 0.0238,
      "step": 8810
    },
    {
      "epoch": 3.560758982640291,
      "grad_norm": 2.4138987064361572,
      "learning_rate": 1.6439241017359712e-05,
      "loss": 0.0246,
      "step": 8820
    },
    {
      "epoch": 3.5647961243439643,
      "grad_norm": 6.369697570800781,
      "learning_rate": 1.6435203875656037e-05,
      "loss": 0.0499,
      "step": 8830
    },
    {
      "epoch": 3.5688332660476383,
      "grad_norm": 0.007344909943640232,
      "learning_rate": 1.6431166733952365e-05,
      "loss": 0.0382,
      "step": 8840
    },
    {
      "epoch": 3.572870407751312,
      "grad_norm": 1.822921872138977,
      "learning_rate": 1.642712959224869e-05,
      "loss": 0.0681,
      "step": 8850
    },
    {
      "epoch": 3.576907549454986,
      "grad_norm": 0.055717553943395615,
      "learning_rate": 1.6423092450545014e-05,
      "loss": 0.0241,
      "step": 8860
    },
    {
      "epoch": 3.5809446911586598,
      "grad_norm": 1.646242380142212,
      "learning_rate": 1.6419055308841342e-05,
      "loss": 0.0145,
      "step": 8870
    },
    {
      "epoch": 3.5849818328623337,
      "grad_norm": 0.014243749901652336,
      "learning_rate": 1.641501816713767e-05,
      "loss": 0.0515,
      "step": 8880
    },
    {
      "epoch": 3.5890189745660073,
      "grad_norm": 2.3345253467559814,
      "learning_rate": 1.6410981025433994e-05,
      "loss": 0.0064,
      "step": 8890
    },
    {
      "epoch": 3.593056116269681,
      "grad_norm": 0.023732848465442657,
      "learning_rate": 1.640694388373032e-05,
      "loss": 0.0912,
      "step": 8900
    },
    {
      "epoch": 3.5970932579733548,
      "grad_norm": 3.949873447418213,
      "learning_rate": 1.6402906742026647e-05,
      "loss": 0.0623,
      "step": 8910
    },
    {
      "epoch": 3.6011303996770287,
      "grad_norm": 5.544873237609863,
      "learning_rate": 1.639886960032297e-05,
      "loss": 0.0062,
      "step": 8920
    },
    {
      "epoch": 3.6051675413807027,
      "grad_norm": 0.010914473794400692,
      "learning_rate": 1.63948324586193e-05,
      "loss": 0.0328,
      "step": 8930
    },
    {
      "epoch": 3.6092046830843763,
      "grad_norm": 2.0319318771362305,
      "learning_rate": 1.6390795316915624e-05,
      "loss": 0.0665,
      "step": 8940
    },
    {
      "epoch": 3.61324182478805,
      "grad_norm": 1.8568477630615234,
      "learning_rate": 1.6386758175211952e-05,
      "loss": 0.0175,
      "step": 8950
    },
    {
      "epoch": 3.6172789664917238,
      "grad_norm": 0.9897969365119934,
      "learning_rate": 1.6382721033508277e-05,
      "loss": 0.0201,
      "step": 8960
    },
    {
      "epoch": 3.6213161081953977,
      "grad_norm": 0.1826530396938324,
      "learning_rate": 1.6378683891804605e-05,
      "loss": 0.0084,
      "step": 8970
    },
    {
      "epoch": 3.6253532498990717,
      "grad_norm": 0.01031534094363451,
      "learning_rate": 1.637464675010093e-05,
      "loss": 0.0136,
      "step": 8980
    },
    {
      "epoch": 3.6293903916027452,
      "grad_norm": 0.08428346365690231,
      "learning_rate": 1.6370609608397257e-05,
      "loss": 0.0268,
      "step": 8990
    },
    {
      "epoch": 3.633427533306419,
      "grad_norm": 0.012585744261741638,
      "learning_rate": 1.6366572466693582e-05,
      "loss": 0.0724,
      "step": 9000
    },
    {
      "epoch": 3.6374646750100927,
      "grad_norm": 0.46723929047584534,
      "learning_rate": 1.6362535324989907e-05,
      "loss": 0.0322,
      "step": 9010
    },
    {
      "epoch": 3.6415018167137667,
      "grad_norm": 7.754339694976807,
      "learning_rate": 1.6358498183286234e-05,
      "loss": 0.0684,
      "step": 9020
    },
    {
      "epoch": 3.6455389584174407,
      "grad_norm": 0.005890099331736565,
      "learning_rate": 1.6354461041582562e-05,
      "loss": 0.0965,
      "step": 9030
    },
    {
      "epoch": 3.649576100121114,
      "grad_norm": 0.056664153933525085,
      "learning_rate": 1.6350423899878887e-05,
      "loss": 0.0678,
      "step": 9040
    },
    {
      "epoch": 3.653613241824788,
      "grad_norm": 0.22018298506736755,
      "learning_rate": 1.634638675817521e-05,
      "loss": 0.0216,
      "step": 9050
    },
    {
      "epoch": 3.6576503835284617,
      "grad_norm": 0.023919127881526947,
      "learning_rate": 1.634234961647154e-05,
      "loss": 0.0388,
      "step": 9060
    },
    {
      "epoch": 3.6616875252321357,
      "grad_norm": 1.993912935256958,
      "learning_rate": 1.6338312474767864e-05,
      "loss": 0.0318,
      "step": 9070
    },
    {
      "epoch": 3.6657246669358097,
      "grad_norm": 0.3100610375404358,
      "learning_rate": 1.6334275333064192e-05,
      "loss": 0.0496,
      "step": 9080
    },
    {
      "epoch": 3.669761808639483,
      "grad_norm": 6.61688232421875,
      "learning_rate": 1.633023819136052e-05,
      "loss": 0.098,
      "step": 9090
    },
    {
      "epoch": 3.673798950343157,
      "grad_norm": 0.15481001138687134,
      "learning_rate": 1.6326201049656845e-05,
      "loss": 0.0211,
      "step": 9100
    },
    {
      "epoch": 3.6778360920468307,
      "grad_norm": 2.179025411605835,
      "learning_rate": 1.632216390795317e-05,
      "loss": 0.0949,
      "step": 9110
    },
    {
      "epoch": 3.6818732337505047,
      "grad_norm": 2.2916548252105713,
      "learning_rate": 1.6318126766249497e-05,
      "loss": 0.0483,
      "step": 9120
    },
    {
      "epoch": 3.6859103754541787,
      "grad_norm": 0.012904378585517406,
      "learning_rate": 1.6314089624545822e-05,
      "loss": 0.0207,
      "step": 9130
    },
    {
      "epoch": 3.689947517157852,
      "grad_norm": 0.026976389810442924,
      "learning_rate": 1.631005248284215e-05,
      "loss": 0.0175,
      "step": 9140
    },
    {
      "epoch": 3.693984658861526,
      "grad_norm": 0.17321594059467316,
      "learning_rate": 1.6306015341138475e-05,
      "loss": 0.0543,
      "step": 9150
    },
    {
      "epoch": 3.6980218005651997,
      "grad_norm": 0.23898403346538544,
      "learning_rate": 1.6301978199434803e-05,
      "loss": 0.025,
      "step": 9160
    },
    {
      "epoch": 3.7020589422688737,
      "grad_norm": 0.08123929798603058,
      "learning_rate": 1.6297941057731127e-05,
      "loss": 0.043,
      "step": 9170
    },
    {
      "epoch": 3.7060960839725476,
      "grad_norm": 0.031502507627010345,
      "learning_rate": 1.6293903916027455e-05,
      "loss": 0.039,
      "step": 9180
    },
    {
      "epoch": 3.710133225676221,
      "grad_norm": 2.1505274772644043,
      "learning_rate": 1.628986677432378e-05,
      "loss": 0.0571,
      "step": 9190
    },
    {
      "epoch": 3.714170367379895,
      "grad_norm": 0.008903914131224155,
      "learning_rate": 1.6285829632620108e-05,
      "loss": 0.0515,
      "step": 9200
    },
    {
      "epoch": 3.7182075090835687,
      "grad_norm": 6.804274559020996,
      "learning_rate": 1.6281792490916432e-05,
      "loss": 0.0438,
      "step": 9210
    },
    {
      "epoch": 3.7222446507872426,
      "grad_norm": 0.038791295140981674,
      "learning_rate": 1.6277755349212757e-05,
      "loss": 0.0079,
      "step": 9220
    },
    {
      "epoch": 3.7262817924909166,
      "grad_norm": 2.9482157230377197,
      "learning_rate": 1.6273718207509085e-05,
      "loss": 0.0139,
      "step": 9230
    },
    {
      "epoch": 3.73031893419459,
      "grad_norm": 0.014715718105435371,
      "learning_rate": 1.6269681065805413e-05,
      "loss": 0.0422,
      "step": 9240
    },
    {
      "epoch": 3.734356075898264,
      "grad_norm": 0.04714620113372803,
      "learning_rate": 1.6265643924101737e-05,
      "loss": 0.0142,
      "step": 9250
    },
    {
      "epoch": 3.7383932176019377,
      "grad_norm": 0.007176459766924381,
      "learning_rate": 1.6261606782398062e-05,
      "loss": 0.0366,
      "step": 9260
    },
    {
      "epoch": 3.7424303593056116,
      "grad_norm": 0.09468308091163635,
      "learning_rate": 1.625756964069439e-05,
      "loss": 0.0166,
      "step": 9270
    },
    {
      "epoch": 3.7464675010092856,
      "grad_norm": 0.008384996093809605,
      "learning_rate": 1.6253532498990715e-05,
      "loss": 0.0008,
      "step": 9280
    },
    {
      "epoch": 3.750504642712959,
      "grad_norm": 0.009639507159590721,
      "learning_rate": 1.6249495357287043e-05,
      "loss": 0.011,
      "step": 9290
    },
    {
      "epoch": 3.754541784416633,
      "grad_norm": 0.001636479515582323,
      "learning_rate": 1.6245458215583367e-05,
      "loss": 0.0233,
      "step": 9300
    },
    {
      "epoch": 3.7585789261203066,
      "grad_norm": 0.010094800963997841,
      "learning_rate": 1.6241421073879695e-05,
      "loss": 0.1062,
      "step": 9310
    },
    {
      "epoch": 3.7626160678239806,
      "grad_norm": 0.05552665516734123,
      "learning_rate": 1.623738393217602e-05,
      "loss": 0.0064,
      "step": 9320
    },
    {
      "epoch": 3.7666532095276546,
      "grad_norm": 1.1187353134155273,
      "learning_rate": 1.6233346790472348e-05,
      "loss": 0.0068,
      "step": 9330
    },
    {
      "epoch": 3.770690351231328,
      "grad_norm": 3.033621311187744,
      "learning_rate": 1.6229309648768676e-05,
      "loss": 0.0527,
      "step": 9340
    },
    {
      "epoch": 3.774727492935002,
      "grad_norm": 35.81254959106445,
      "learning_rate": 1.6225272507065e-05,
      "loss": 0.0243,
      "step": 9350
    },
    {
      "epoch": 3.7787646346386756,
      "grad_norm": 0.004302068613469601,
      "learning_rate": 1.6221235365361325e-05,
      "loss": 0.0216,
      "step": 9360
    },
    {
      "epoch": 3.7828017763423496,
      "grad_norm": 9.106681823730469,
      "learning_rate": 1.621719822365765e-05,
      "loss": 0.0325,
      "step": 9370
    },
    {
      "epoch": 3.7868389180460236,
      "grad_norm": 2.090087652206421,
      "learning_rate": 1.6213161081953977e-05,
      "loss": 0.0813,
      "step": 9380
    },
    {
      "epoch": 3.790876059749697,
      "grad_norm": 5.499818801879883,
      "learning_rate": 1.6209123940250305e-05,
      "loss": 0.0503,
      "step": 9390
    },
    {
      "epoch": 3.794913201453371,
      "grad_norm": 0.3035893440246582,
      "learning_rate": 1.620508679854663e-05,
      "loss": 0.0279,
      "step": 9400
    },
    {
      "epoch": 3.7989503431570446,
      "grad_norm": 0.01878412626683712,
      "learning_rate": 1.6201049656842958e-05,
      "loss": 0.0539,
      "step": 9410
    },
    {
      "epoch": 3.8029874848607186,
      "grad_norm": 0.04101491719484329,
      "learning_rate": 1.6197012515139283e-05,
      "loss": 0.0168,
      "step": 9420
    },
    {
      "epoch": 3.8070246265643926,
      "grad_norm": 0.2235432267189026,
      "learning_rate": 1.6192975373435607e-05,
      "loss": 0.0121,
      "step": 9430
    },
    {
      "epoch": 3.811061768268066,
      "grad_norm": 1.360944151878357,
      "learning_rate": 1.6188938231731935e-05,
      "loss": 0.0309,
      "step": 9440
    },
    {
      "epoch": 3.81509890997174,
      "grad_norm": 0.1941545307636261,
      "learning_rate": 1.6184901090028263e-05,
      "loss": 0.0763,
      "step": 9450
    },
    {
      "epoch": 3.8191360516754136,
      "grad_norm": 0.028991514816880226,
      "learning_rate": 1.6180863948324588e-05,
      "loss": 0.0504,
      "step": 9460
    },
    {
      "epoch": 3.8231731933790876,
      "grad_norm": 1.9191298484802246,
      "learning_rate": 1.6176826806620912e-05,
      "loss": 0.0181,
      "step": 9470
    },
    {
      "epoch": 3.8272103350827615,
      "grad_norm": 0.006921372376382351,
      "learning_rate": 1.617278966491724e-05,
      "loss": 0.0375,
      "step": 9480
    },
    {
      "epoch": 3.831247476786435,
      "grad_norm": 2.400101661682129,
      "learning_rate": 1.6168752523213568e-05,
      "loss": 0.0455,
      "step": 9490
    },
    {
      "epoch": 3.835284618490109,
      "grad_norm": 1.4836419820785522,
      "learning_rate": 1.6164715381509893e-05,
      "loss": 0.009,
      "step": 9500
    },
    {
      "epoch": 3.8393217601937826,
      "grad_norm": 0.003166034584864974,
      "learning_rate": 1.6160678239806217e-05,
      "loss": 0.0367,
      "step": 9510
    },
    {
      "epoch": 3.8433589018974565,
      "grad_norm": 0.5222913026809692,
      "learning_rate": 1.6156641098102545e-05,
      "loss": 0.0156,
      "step": 9520
    },
    {
      "epoch": 3.8473960436011305,
      "grad_norm": 4.5634636878967285,
      "learning_rate": 1.615260395639887e-05,
      "loss": 0.0416,
      "step": 9530
    },
    {
      "epoch": 3.851433185304804,
      "grad_norm": 0.0037223398685455322,
      "learning_rate": 1.6148566814695198e-05,
      "loss": 0.0684,
      "step": 9540
    },
    {
      "epoch": 3.855470327008478,
      "grad_norm": 0.003932479303330183,
      "learning_rate": 1.6144529672991523e-05,
      "loss": 0.0274,
      "step": 9550
    },
    {
      "epoch": 3.8595074687121516,
      "grad_norm": 0.18397878110408783,
      "learning_rate": 1.614049253128785e-05,
      "loss": 0.0042,
      "step": 9560
    },
    {
      "epoch": 3.8635446104158255,
      "grad_norm": 1.9641622304916382,
      "learning_rate": 1.6136455389584175e-05,
      "loss": 0.0239,
      "step": 9570
    },
    {
      "epoch": 3.8675817521194995,
      "grad_norm": 5.759408950805664,
      "learning_rate": 1.61324182478805e-05,
      "loss": 0.0742,
      "step": 9580
    },
    {
      "epoch": 3.871618893823173,
      "grad_norm": 0.012203523889183998,
      "learning_rate": 1.6128381106176828e-05,
      "loss": 0.0459,
      "step": 9590
    },
    {
      "epoch": 3.875656035526847,
      "grad_norm": 2.7589058876037598,
      "learning_rate": 1.6124343964473156e-05,
      "loss": 0.0276,
      "step": 9600
    },
    {
      "epoch": 3.8796931772305205,
      "grad_norm": 1.9795167446136475,
      "learning_rate": 1.612030682276948e-05,
      "loss": 0.0431,
      "step": 9610
    },
    {
      "epoch": 3.8837303189341945,
      "grad_norm": 0.07643211632966995,
      "learning_rate": 1.6116269681065805e-05,
      "loss": 0.0541,
      "step": 9620
    },
    {
      "epoch": 3.8877674606378685,
      "grad_norm": 1.4791911840438843,
      "learning_rate": 1.6112232539362133e-05,
      "loss": 0.0606,
      "step": 9630
    },
    {
      "epoch": 3.8918046023415425,
      "grad_norm": 0.0057573518715798855,
      "learning_rate": 1.610819539765846e-05,
      "loss": 0.0127,
      "step": 9640
    },
    {
      "epoch": 3.895841744045216,
      "grad_norm": 0.008387777954339981,
      "learning_rate": 1.6104158255954785e-05,
      "loss": 0.009,
      "step": 9650
    },
    {
      "epoch": 3.8998788857488895,
      "grad_norm": 0.18695126473903656,
      "learning_rate": 1.610012111425111e-05,
      "loss": 0.068,
      "step": 9660
    },
    {
      "epoch": 3.9039160274525635,
      "grad_norm": 0.16604265570640564,
      "learning_rate": 1.6096083972547438e-05,
      "loss": 0.0664,
      "step": 9670
    },
    {
      "epoch": 3.9079531691562375,
      "grad_norm": 5.527320861816406,
      "learning_rate": 1.6092046830843763e-05,
      "loss": 0.0963,
      "step": 9680
    },
    {
      "epoch": 3.9119903108599114,
      "grad_norm": 0.3116972744464874,
      "learning_rate": 1.608800968914009e-05,
      "loss": 0.0048,
      "step": 9690
    },
    {
      "epoch": 3.916027452563585,
      "grad_norm": 0.04899906367063522,
      "learning_rate": 1.608397254743642e-05,
      "loss": 0.0758,
      "step": 9700
    },
    {
      "epoch": 3.9200645942672585,
      "grad_norm": 3.9018545150756836,
      "learning_rate": 1.6079935405732743e-05,
      "loss": 0.0555,
      "step": 9710
    },
    {
      "epoch": 3.9241017359709325,
      "grad_norm": 2.0967328548431396,
      "learning_rate": 1.6075898264029068e-05,
      "loss": 0.0353,
      "step": 9720
    },
    {
      "epoch": 3.9281388776746065,
      "grad_norm": 2.010617971420288,
      "learning_rate": 1.6071861122325392e-05,
      "loss": 0.0176,
      "step": 9730
    },
    {
      "epoch": 3.9321760193782804,
      "grad_norm": 0.43090763688087463,
      "learning_rate": 1.606782398062172e-05,
      "loss": 0.0246,
      "step": 9740
    },
    {
      "epoch": 3.936213161081954,
      "grad_norm": 5.0854973793029785,
      "learning_rate": 1.606378683891805e-05,
      "loss": 0.0352,
      "step": 9750
    },
    {
      "epoch": 3.940250302785628,
      "grad_norm": 0.01747119426727295,
      "learning_rate": 1.6059749697214373e-05,
      "loss": 0.0264,
      "step": 9760
    },
    {
      "epoch": 3.9442874444893015,
      "grad_norm": 0.07221796363592148,
      "learning_rate": 1.60557125555107e-05,
      "loss": 0.0205,
      "step": 9770
    },
    {
      "epoch": 3.9483245861929754,
      "grad_norm": 0.5609356760978699,
      "learning_rate": 1.6051675413807026e-05,
      "loss": 0.0117,
      "step": 9780
    },
    {
      "epoch": 3.9523617278966494,
      "grad_norm": 0.05525048077106476,
      "learning_rate": 1.6047638272103353e-05,
      "loss": 0.0491,
      "step": 9790
    },
    {
      "epoch": 3.956398869600323,
      "grad_norm": 4.8341593742370605,
      "learning_rate": 1.6043601130399678e-05,
      "loss": 0.0315,
      "step": 9800
    },
    {
      "epoch": 3.960436011303997,
      "grad_norm": 7.09559440612793,
      "learning_rate": 1.6039563988696006e-05,
      "loss": 0.0928,
      "step": 9810
    },
    {
      "epoch": 3.9644731530076704,
      "grad_norm": 0.003406988922506571,
      "learning_rate": 1.603552684699233e-05,
      "loss": 0.0021,
      "step": 9820
    },
    {
      "epoch": 3.9685102947113444,
      "grad_norm": 0.022693486884236336,
      "learning_rate": 1.6031489705288655e-05,
      "loss": 0.0211,
      "step": 9830
    },
    {
      "epoch": 3.9725474364150184,
      "grad_norm": 1.868095874786377,
      "learning_rate": 1.6027452563584983e-05,
      "loss": 0.0263,
      "step": 9840
    },
    {
      "epoch": 3.976584578118692,
      "grad_norm": 0.0035558976233005524,
      "learning_rate": 1.602341542188131e-05,
      "loss": 0.0631,
      "step": 9850
    },
    {
      "epoch": 3.980621719822366,
      "grad_norm": 0.3444140553474426,
      "learning_rate": 1.6019378280177636e-05,
      "loss": 0.0505,
      "step": 9860
    },
    {
      "epoch": 3.9846588615260394,
      "grad_norm": 0.08029940724372864,
      "learning_rate": 1.601534113847396e-05,
      "loss": 0.0181,
      "step": 9870
    },
    {
      "epoch": 3.9886960032297134,
      "grad_norm": 0.016491807997226715,
      "learning_rate": 1.601130399677029e-05,
      "loss": 0.0116,
      "step": 9880
    },
    {
      "epoch": 3.9927331449333874,
      "grad_norm": 3.6776223182678223,
      "learning_rate": 1.6007266855066613e-05,
      "loss": 0.097,
      "step": 9890
    },
    {
      "epoch": 3.996770286637061,
      "grad_norm": 0.04023587703704834,
      "learning_rate": 1.600322971336294e-05,
      "loss": 0.0409,
      "step": 9900
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9841981132075471,
      "eval_f1": 0.9415867480383608,
      "eval_loss": 0.052571963518857956,
      "eval_precision": 0.9523809523809523,
      "eval_recall": 0.9310344827586207,
      "eval_runtime": 444.2844,
      "eval_samples_per_second": 28.675,
      "eval_steps_per_second": 1.195,
      "step": 9908
    },
    {
      "epoch": 4.000807428340734,
      "grad_norm": 2.33514666557312,
      "learning_rate": 1.5999192571659266e-05,
      "loss": 0.0494,
      "step": 9910
    },
    {
      "epoch": 4.004844570044408,
      "grad_norm": 0.016669724136590958,
      "learning_rate": 1.5995155429955594e-05,
      "loss": 0.0007,
      "step": 9920
    },
    {
      "epoch": 4.008881711748082,
      "grad_norm": 2.112445831298828,
      "learning_rate": 1.5991118288251918e-05,
      "loss": 0.0202,
      "step": 9930
    },
    {
      "epoch": 4.012918853451756,
      "grad_norm": 5.676009178161621,
      "learning_rate": 1.5987081146548246e-05,
      "loss": 0.0241,
      "step": 9940
    },
    {
      "epoch": 4.01695599515543,
      "grad_norm": 0.02369481697678566,
      "learning_rate": 1.598304400484457e-05,
      "loss": 0.0255,
      "step": 9950
    },
    {
      "epoch": 4.020993136859103,
      "grad_norm": 0.0922226831316948,
      "learning_rate": 1.59790068631409e-05,
      "loss": 0.03,
      "step": 9960
    },
    {
      "epoch": 4.025030278562777,
      "grad_norm": 0.02715183235704899,
      "learning_rate": 1.5974969721437223e-05,
      "loss": 0.0189,
      "step": 9970
    },
    {
      "epoch": 4.029067420266451,
      "grad_norm": 0.011541412211954594,
      "learning_rate": 1.5970932579733548e-05,
      "loss": 0.0183,
      "step": 9980
    },
    {
      "epoch": 4.033104561970125,
      "grad_norm": 0.017907682806253433,
      "learning_rate": 1.5966895438029876e-05,
      "loss": 0.0392,
      "step": 9990
    },
    {
      "epoch": 4.037141703673799,
      "grad_norm": 5.102048873901367,
      "learning_rate": 1.5962858296326204e-05,
      "loss": 0.0163,
      "step": 10000
    },
    {
      "epoch": 4.041178845377472,
      "grad_norm": 0.006278298329561949,
      "learning_rate": 1.595882115462253e-05,
      "loss": 0.0126,
      "step": 10010
    },
    {
      "epoch": 4.045215987081146,
      "grad_norm": 11.954549789428711,
      "learning_rate": 1.5954784012918856e-05,
      "loss": 0.0346,
      "step": 10020
    },
    {
      "epoch": 4.04925312878482,
      "grad_norm": 0.20535139739513397,
      "learning_rate": 1.595074687121518e-05,
      "loss": 0.0341,
      "step": 10030
    },
    {
      "epoch": 4.053290270488494,
      "grad_norm": 0.05373002961277962,
      "learning_rate": 1.5946709729511506e-05,
      "loss": 0.0108,
      "step": 10040
    },
    {
      "epoch": 4.057327412192168,
      "grad_norm": 2.5466949939727783,
      "learning_rate": 1.5942672587807834e-05,
      "loss": 0.0349,
      "step": 10050
    },
    {
      "epoch": 4.061364553895841,
      "grad_norm": 0.011625261977314949,
      "learning_rate": 1.593863544610416e-05,
      "loss": 0.0503,
      "step": 10060
    },
    {
      "epoch": 4.065401695599515,
      "grad_norm": 0.007704479154199362,
      "learning_rate": 1.5934598304400486e-05,
      "loss": 0.0008,
      "step": 10070
    },
    {
      "epoch": 4.069438837303189,
      "grad_norm": 0.05918386951088905,
      "learning_rate": 1.593056116269681e-05,
      "loss": 0.0247,
      "step": 10080
    },
    {
      "epoch": 4.073475979006863,
      "grad_norm": 0.08144511282444,
      "learning_rate": 1.592652402099314e-05,
      "loss": 0.0651,
      "step": 10090
    },
    {
      "epoch": 4.077513120710537,
      "grad_norm": 0.2689480483531952,
      "learning_rate": 1.5922486879289463e-05,
      "loss": 0.0164,
      "step": 10100
    },
    {
      "epoch": 4.08155026241421,
      "grad_norm": 1.393827199935913,
      "learning_rate": 1.591844973758579e-05,
      "loss": 0.0202,
      "step": 10110
    },
    {
      "epoch": 4.085587404117884,
      "grad_norm": 1.2916128635406494,
      "learning_rate": 1.5914412595882116e-05,
      "loss": 0.0131,
      "step": 10120
    },
    {
      "epoch": 4.089624545821558,
      "grad_norm": 0.20141074061393738,
      "learning_rate": 1.5910375454178444e-05,
      "loss": 0.0254,
      "step": 10130
    },
    {
      "epoch": 4.093661687525232,
      "grad_norm": 0.008196579292416573,
      "learning_rate": 1.590633831247477e-05,
      "loss": 0.0192,
      "step": 10140
    },
    {
      "epoch": 4.097698829228906,
      "grad_norm": 0.024376241490244865,
      "learning_rate": 1.5902301170771096e-05,
      "loss": 0.0242,
      "step": 10150
    },
    {
      "epoch": 4.101735970932579,
      "grad_norm": 0.024402890354394913,
      "learning_rate": 1.589826402906742e-05,
      "loss": 0.0294,
      "step": 10160
    },
    {
      "epoch": 4.105773112636253,
      "grad_norm": 0.17433537542819977,
      "learning_rate": 1.589422688736375e-05,
      "loss": 0.0317,
      "step": 10170
    },
    {
      "epoch": 4.109810254339927,
      "grad_norm": 0.048966847360134125,
      "learning_rate": 1.5890189745660074e-05,
      "loss": 0.01,
      "step": 10180
    },
    {
      "epoch": 4.113847396043601,
      "grad_norm": 2.166069746017456,
      "learning_rate": 1.5886152603956398e-05,
      "loss": 0.0396,
      "step": 10190
    },
    {
      "epoch": 4.117884537747275,
      "grad_norm": 0.01068819873034954,
      "learning_rate": 1.5882115462252726e-05,
      "loss": 0.0025,
      "step": 10200
    },
    {
      "epoch": 4.121921679450948,
      "grad_norm": 0.0066777379252016544,
      "learning_rate": 1.5878078320549054e-05,
      "loss": 0.0749,
      "step": 10210
    },
    {
      "epoch": 4.125958821154622,
      "grad_norm": 0.017752131447196007,
      "learning_rate": 1.587404117884538e-05,
      "loss": 0.0239,
      "step": 10220
    },
    {
      "epoch": 4.129995962858296,
      "grad_norm": 0.1881067454814911,
      "learning_rate": 1.5870004037141703e-05,
      "loss": 0.0127,
      "step": 10230
    },
    {
      "epoch": 4.13403310456197,
      "grad_norm": 1.1237356662750244,
      "learning_rate": 1.586596689543803e-05,
      "loss": 0.0146,
      "step": 10240
    },
    {
      "epoch": 4.138070246265644,
      "grad_norm": 0.01255048532038927,
      "learning_rate": 1.5861929753734356e-05,
      "loss": 0.0167,
      "step": 10250
    },
    {
      "epoch": 4.142107387969317,
      "grad_norm": 0.0276828370988369,
      "learning_rate": 1.5857892612030684e-05,
      "loss": 0.0195,
      "step": 10260
    },
    {
      "epoch": 4.146144529672991,
      "grad_norm": 0.005527261178940535,
      "learning_rate": 1.585385547032701e-05,
      "loss": 0.0201,
      "step": 10270
    },
    {
      "epoch": 4.150181671376665,
      "grad_norm": 20.985448837280273,
      "learning_rate": 1.5849818328623336e-05,
      "loss": 0.0905,
      "step": 10280
    },
    {
      "epoch": 4.154218813080339,
      "grad_norm": 0.8712067604064941,
      "learning_rate": 1.584578118691966e-05,
      "loss": 0.0163,
      "step": 10290
    },
    {
      "epoch": 4.158255954784013,
      "grad_norm": 0.015211270190775394,
      "learning_rate": 1.584174404521599e-05,
      "loss": 0.0651,
      "step": 10300
    },
    {
      "epoch": 4.162293096487686,
      "grad_norm": 0.2477157562971115,
      "learning_rate": 1.5837706903512317e-05,
      "loss": 0.0383,
      "step": 10310
    },
    {
      "epoch": 4.16633023819136,
      "grad_norm": 0.08156721293926239,
      "learning_rate": 1.583366976180864e-05,
      "loss": 0.0774,
      "step": 10320
    },
    {
      "epoch": 4.170367379895034,
      "grad_norm": 0.1040758565068245,
      "learning_rate": 1.5829632620104966e-05,
      "loss": 0.0057,
      "step": 10330
    },
    {
      "epoch": 4.174404521598708,
      "grad_norm": 2.3250975608825684,
      "learning_rate": 1.582559547840129e-05,
      "loss": 0.0377,
      "step": 10340
    },
    {
      "epoch": 4.178441663302382,
      "grad_norm": 2.7352609634399414,
      "learning_rate": 1.582155833669762e-05,
      "loss": 0.0418,
      "step": 10350
    },
    {
      "epoch": 4.182478805006055,
      "grad_norm": 1.7278132438659668,
      "learning_rate": 1.5817521194993947e-05,
      "loss": 0.0145,
      "step": 10360
    },
    {
      "epoch": 4.186515946709729,
      "grad_norm": 0.008946147747337818,
      "learning_rate": 1.581348405329027e-05,
      "loss": 0.0641,
      "step": 10370
    },
    {
      "epoch": 4.190553088413403,
      "grad_norm": 0.586516797542572,
      "learning_rate": 1.58094469115866e-05,
      "loss": 0.0057,
      "step": 10380
    },
    {
      "epoch": 4.194590230117077,
      "grad_norm": 2.3979218006134033,
      "learning_rate": 1.5805409769882924e-05,
      "loss": 0.1193,
      "step": 10390
    },
    {
      "epoch": 4.198627371820751,
      "grad_norm": 0.04977748170495033,
      "learning_rate": 1.580137262817925e-05,
      "loss": 0.0007,
      "step": 10400
    },
    {
      "epoch": 4.202664513524425,
      "grad_norm": 2.072704315185547,
      "learning_rate": 1.5797335486475577e-05,
      "loss": 0.0122,
      "step": 10410
    },
    {
      "epoch": 4.206701655228098,
      "grad_norm": 0.006117554847151041,
      "learning_rate": 1.5793298344771904e-05,
      "loss": 0.0445,
      "step": 10420
    },
    {
      "epoch": 4.210738796931772,
      "grad_norm": 1.6511226892471313,
      "learning_rate": 1.578926120306823e-05,
      "loss": 0.0063,
      "step": 10430
    },
    {
      "epoch": 4.214775938635446,
      "grad_norm": 2.4741415977478027,
      "learning_rate": 1.5785224061364554e-05,
      "loss": 0.0148,
      "step": 10440
    },
    {
      "epoch": 4.21881308033912,
      "grad_norm": 0.011869095265865326,
      "learning_rate": 1.578118691966088e-05,
      "loss": 0.0432,
      "step": 10450
    },
    {
      "epoch": 4.222850222042794,
      "grad_norm": 0.05024617910385132,
      "learning_rate": 1.577714977795721e-05,
      "loss": 0.026,
      "step": 10460
    },
    {
      "epoch": 4.226887363746467,
      "grad_norm": 1.3203918933868408,
      "learning_rate": 1.5773112636253534e-05,
      "loss": 0.0043,
      "step": 10470
    },
    {
      "epoch": 4.230924505450141,
      "grad_norm": 2.3107516765594482,
      "learning_rate": 1.576907549454986e-05,
      "loss": 0.11,
      "step": 10480
    },
    {
      "epoch": 4.234961647153815,
      "grad_norm": 0.6716333627700806,
      "learning_rate": 1.5765038352846187e-05,
      "loss": 0.0555,
      "step": 10490
    },
    {
      "epoch": 4.238998788857489,
      "grad_norm": 0.11345012485980988,
      "learning_rate": 1.576100121114251e-05,
      "loss": 0.004,
      "step": 10500
    },
    {
      "epoch": 4.243035930561163,
      "grad_norm": 0.13485166430473328,
      "learning_rate": 1.575696406943884e-05,
      "loss": 0.0394,
      "step": 10510
    },
    {
      "epoch": 4.247073072264836,
      "grad_norm": 0.04477395489811897,
      "learning_rate": 1.5752926927735164e-05,
      "loss": 0.0564,
      "step": 10520
    },
    {
      "epoch": 4.25111021396851,
      "grad_norm": 3.38751220703125,
      "learning_rate": 1.5748889786031492e-05,
      "loss": 0.0404,
      "step": 10530
    },
    {
      "epoch": 4.255147355672184,
      "grad_norm": 0.011250220239162445,
      "learning_rate": 1.5744852644327817e-05,
      "loss": 0.0186,
      "step": 10540
    },
    {
      "epoch": 4.259184497375858,
      "grad_norm": 0.019524436444044113,
      "learning_rate": 1.574081550262414e-05,
      "loss": 0.0272,
      "step": 10550
    },
    {
      "epoch": 4.263221639079532,
      "grad_norm": 0.008832105435431004,
      "learning_rate": 1.573677836092047e-05,
      "loss": 0.0206,
      "step": 10560
    },
    {
      "epoch": 4.267258780783205,
      "grad_norm": 0.05831841379404068,
      "learning_rate": 1.5732741219216797e-05,
      "loss": 0.0225,
      "step": 10570
    },
    {
      "epoch": 4.271295922486879,
      "grad_norm": 0.08521637320518494,
      "learning_rate": 1.572870407751312e-05,
      "loss": 0.0122,
      "step": 10580
    },
    {
      "epoch": 4.275333064190553,
      "grad_norm": 0.10436399281024933,
      "learning_rate": 1.5724666935809446e-05,
      "loss": 0.1032,
      "step": 10590
    },
    {
      "epoch": 4.279370205894227,
      "grad_norm": 4.239959716796875,
      "learning_rate": 1.5720629794105774e-05,
      "loss": 0.0295,
      "step": 10600
    },
    {
      "epoch": 4.283407347597901,
      "grad_norm": 0.09435528516769409,
      "learning_rate": 1.5716592652402102e-05,
      "loss": 0.0659,
      "step": 10610
    },
    {
      "epoch": 4.287444489301574,
      "grad_norm": 0.06966836005449295,
      "learning_rate": 1.5712555510698427e-05,
      "loss": 0.0477,
      "step": 10620
    },
    {
      "epoch": 4.291481631005248,
      "grad_norm": 4.919617176055908,
      "learning_rate": 1.5708518368994755e-05,
      "loss": 0.0129,
      "step": 10630
    },
    {
      "epoch": 4.295518772708922,
      "grad_norm": 2.581066846847534,
      "learning_rate": 1.570448122729108e-05,
      "loss": 0.0388,
      "step": 10640
    },
    {
      "epoch": 4.299555914412596,
      "grad_norm": 0.031668003648519516,
      "learning_rate": 1.5700444085587404e-05,
      "loss": 0.0879,
      "step": 10650
    },
    {
      "epoch": 4.30359305611627,
      "grad_norm": 0.11006351560354233,
      "learning_rate": 1.5696406943883732e-05,
      "loss": 0.0312,
      "step": 10660
    },
    {
      "epoch": 4.307630197819943,
      "grad_norm": 2.609926700592041,
      "learning_rate": 1.569236980218006e-05,
      "loss": 0.0116,
      "step": 10670
    },
    {
      "epoch": 4.311667339523617,
      "grad_norm": 2.57212233543396,
      "learning_rate": 1.5688332660476385e-05,
      "loss": 0.0494,
      "step": 10680
    },
    {
      "epoch": 4.315704481227291,
      "grad_norm": 4.230518341064453,
      "learning_rate": 1.568429551877271e-05,
      "loss": 0.1238,
      "step": 10690
    },
    {
      "epoch": 4.319741622930965,
      "grad_norm": 2.1130764484405518,
      "learning_rate": 1.5680258377069034e-05,
      "loss": 0.0506,
      "step": 10700
    },
    {
      "epoch": 4.323778764634639,
      "grad_norm": 4.791827201843262,
      "learning_rate": 1.5676221235365362e-05,
      "loss": 0.0235,
      "step": 10710
    },
    {
      "epoch": 4.327815906338312,
      "grad_norm": 1.8411773443222046,
      "learning_rate": 1.567218409366169e-05,
      "loss": 0.0797,
      "step": 10720
    },
    {
      "epoch": 4.331853048041986,
      "grad_norm": 3.291572332382202,
      "learning_rate": 1.5668146951958014e-05,
      "loss": 0.0456,
      "step": 10730
    },
    {
      "epoch": 4.33589018974566,
      "grad_norm": 0.1154000386595726,
      "learning_rate": 1.5664109810254342e-05,
      "loss": 0.0318,
      "step": 10740
    },
    {
      "epoch": 4.339927331449334,
      "grad_norm": 0.012805838137865067,
      "learning_rate": 1.5660072668550667e-05,
      "loss": 0.0319,
      "step": 10750
    },
    {
      "epoch": 4.343964473153008,
      "grad_norm": 0.010026791132986546,
      "learning_rate": 1.5656035526846995e-05,
      "loss": 0.0157,
      "step": 10760
    },
    {
      "epoch": 4.348001614856681,
      "grad_norm": 0.3797178864479065,
      "learning_rate": 1.565199838514332e-05,
      "loss": 0.006,
      "step": 10770
    },
    {
      "epoch": 4.352038756560355,
      "grad_norm": 0.23986536264419556,
      "learning_rate": 1.5647961243439647e-05,
      "loss": 0.0033,
      "step": 10780
    },
    {
      "epoch": 4.356075898264029,
      "grad_norm": 0.006383059546351433,
      "learning_rate": 1.5643924101735972e-05,
      "loss": 0.0117,
      "step": 10790
    },
    {
      "epoch": 4.360113039967703,
      "grad_norm": 0.004810272250324488,
      "learning_rate": 1.5639886960032297e-05,
      "loss": 0.0181,
      "step": 10800
    },
    {
      "epoch": 4.364150181671377,
      "grad_norm": 15.815820693969727,
      "learning_rate": 1.5635849818328625e-05,
      "loss": 0.0459,
      "step": 10810
    },
    {
      "epoch": 4.36818732337505,
      "grad_norm": 0.0012793283676728606,
      "learning_rate": 1.5631812676624953e-05,
      "loss": 0.0493,
      "step": 10820
    },
    {
      "epoch": 4.372224465078724,
      "grad_norm": 3.0275990962982178,
      "learning_rate": 1.5627775534921277e-05,
      "loss": 0.0331,
      "step": 10830
    },
    {
      "epoch": 4.376261606782398,
      "grad_norm": 0.001660274458117783,
      "learning_rate": 1.5623738393217602e-05,
      "loss": 0.0246,
      "step": 10840
    },
    {
      "epoch": 4.380298748486072,
      "grad_norm": 0.006641634274274111,
      "learning_rate": 1.561970125151393e-05,
      "loss": 0.0106,
      "step": 10850
    },
    {
      "epoch": 4.384335890189746,
      "grad_norm": 0.0019874207209795713,
      "learning_rate": 1.5615664109810254e-05,
      "loss": 0.0743,
      "step": 10860
    },
    {
      "epoch": 4.388373031893419,
      "grad_norm": 3.280665159225464,
      "learning_rate": 1.5611626968106582e-05,
      "loss": 0.0458,
      "step": 10870
    },
    {
      "epoch": 4.392410173597093,
      "grad_norm": 0.04851137474179268,
      "learning_rate": 1.560758982640291e-05,
      "loss": 0.0092,
      "step": 10880
    },
    {
      "epoch": 4.396447315300767,
      "grad_norm": 1.5332961082458496,
      "learning_rate": 1.5603552684699235e-05,
      "loss": 0.0191,
      "step": 10890
    },
    {
      "epoch": 4.400484457004441,
      "grad_norm": 3.9695000648498535,
      "learning_rate": 1.559951554299556e-05,
      "loss": 0.122,
      "step": 10900
    },
    {
      "epoch": 4.404521598708115,
      "grad_norm": 0.25170040130615234,
      "learning_rate": 1.5595478401291887e-05,
      "loss": 0.017,
      "step": 10910
    },
    {
      "epoch": 4.408558740411788,
      "grad_norm": 0.004793636035174131,
      "learning_rate": 1.5591441259588212e-05,
      "loss": 0.0163,
      "step": 10920
    },
    {
      "epoch": 4.412595882115462,
      "grad_norm": 2.0040273666381836,
      "learning_rate": 1.558740411788454e-05,
      "loss": 0.0194,
      "step": 10930
    },
    {
      "epoch": 4.416633023819136,
      "grad_norm": 0.01191483810544014,
      "learning_rate": 1.5583366976180865e-05,
      "loss": 0.001,
      "step": 10940
    },
    {
      "epoch": 4.42067016552281,
      "grad_norm": 0.005528736859560013,
      "learning_rate": 1.557932983447719e-05,
      "loss": 0.0045,
      "step": 10950
    },
    {
      "epoch": 4.424707307226484,
      "grad_norm": 0.004763302393257618,
      "learning_rate": 1.5575292692773517e-05,
      "loss": 0.0098,
      "step": 10960
    },
    {
      "epoch": 4.428744448930157,
      "grad_norm": 3.838747024536133,
      "learning_rate": 1.5571255551069845e-05,
      "loss": 0.0631,
      "step": 10970
    },
    {
      "epoch": 4.432781590633831,
      "grad_norm": 0.31381654739379883,
      "learning_rate": 1.556721840936617e-05,
      "loss": 0.032,
      "step": 10980
    },
    {
      "epoch": 4.436818732337505,
      "grad_norm": 5.360084056854248,
      "learning_rate": 1.5563181267662498e-05,
      "loss": 0.049,
      "step": 10990
    },
    {
      "epoch": 4.440855874041179,
      "grad_norm": 0.017291435971856117,
      "learning_rate": 1.5559144125958822e-05,
      "loss": 0.0316,
      "step": 11000
    },
    {
      "epoch": 4.444893015744853,
      "grad_norm": 0.2262943536043167,
      "learning_rate": 1.5555106984255147e-05,
      "loss": 0.0485,
      "step": 11010
    },
    {
      "epoch": 4.448930157448526,
      "grad_norm": 1.3619537353515625,
      "learning_rate": 1.5551069842551475e-05,
      "loss": 0.0352,
      "step": 11020
    },
    {
      "epoch": 4.4529672991522,
      "grad_norm": 0.39260825514793396,
      "learning_rate": 1.5547032700847803e-05,
      "loss": 0.0262,
      "step": 11030
    },
    {
      "epoch": 4.457004440855874,
      "grad_norm": 2.433885097503662,
      "learning_rate": 1.5542995559144127e-05,
      "loss": 0.0198,
      "step": 11040
    },
    {
      "epoch": 4.461041582559548,
      "grad_norm": 0.0694851353764534,
      "learning_rate": 1.5538958417440452e-05,
      "loss": 0.0126,
      "step": 11050
    },
    {
      "epoch": 4.465078724263222,
      "grad_norm": 0.012517441995441914,
      "learning_rate": 1.553492127573678e-05,
      "loss": 0.0832,
      "step": 11060
    },
    {
      "epoch": 4.469115865966895,
      "grad_norm": 1.9128258228302002,
      "learning_rate": 1.5530884134033105e-05,
      "loss": 0.0364,
      "step": 11070
    },
    {
      "epoch": 4.473153007670569,
      "grad_norm": 0.08597467839717865,
      "learning_rate": 1.5526846992329433e-05,
      "loss": 0.024,
      "step": 11080
    },
    {
      "epoch": 4.477190149374243,
      "grad_norm": 0.05809558182954788,
      "learning_rate": 1.5522809850625757e-05,
      "loss": 0.0372,
      "step": 11090
    },
    {
      "epoch": 4.481227291077917,
      "grad_norm": 2.0421996116638184,
      "learning_rate": 1.5518772708922085e-05,
      "loss": 0.0296,
      "step": 11100
    },
    {
      "epoch": 4.485264432781591,
      "grad_norm": 0.005263159982860088,
      "learning_rate": 1.551473556721841e-05,
      "loss": 0.0024,
      "step": 11110
    },
    {
      "epoch": 4.489301574485264,
      "grad_norm": 0.00816410779953003,
      "learning_rate": 1.5510698425514738e-05,
      "loss": 0.0047,
      "step": 11120
    },
    {
      "epoch": 4.493338716188938,
      "grad_norm": 2.2491579055786133,
      "learning_rate": 1.5506661283811062e-05,
      "loss": 0.0373,
      "step": 11130
    },
    {
      "epoch": 4.497375857892612,
      "grad_norm": 0.0260907132178545,
      "learning_rate": 1.550262414210739e-05,
      "loss": 0.0019,
      "step": 11140
    },
    {
      "epoch": 4.501412999596286,
      "grad_norm": 0.010683553293347359,
      "learning_rate": 1.5498587000403715e-05,
      "loss": 0.018,
      "step": 11150
    },
    {
      "epoch": 4.50545014129996,
      "grad_norm": 0.01906893402338028,
      "learning_rate": 1.549454985870004e-05,
      "loss": 0.021,
      "step": 11160
    },
    {
      "epoch": 4.509487283003633,
      "grad_norm": 0.00393438758328557,
      "learning_rate": 1.5490512716996368e-05,
      "loss": 0.0457,
      "step": 11170
    },
    {
      "epoch": 4.513524424707307,
      "grad_norm": 0.0010869767284020782,
      "learning_rate": 1.5486475575292696e-05,
      "loss": 0.0556,
      "step": 11180
    },
    {
      "epoch": 4.517561566410981,
      "grad_norm": 0.13924720883369446,
      "learning_rate": 1.548243843358902e-05,
      "loss": 0.0313,
      "step": 11190
    },
    {
      "epoch": 4.521598708114655,
      "grad_norm": 0.10479113459587097,
      "learning_rate": 1.5478401291885345e-05,
      "loss": 0.0632,
      "step": 11200
    },
    {
      "epoch": 4.525635849818329,
      "grad_norm": 1.9328194856643677,
      "learning_rate": 1.5474364150181673e-05,
      "loss": 0.0838,
      "step": 11210
    },
    {
      "epoch": 4.529672991522002,
      "grad_norm": 0.01719430461525917,
      "learning_rate": 1.5470327008477997e-05,
      "loss": 0.0356,
      "step": 11220
    },
    {
      "epoch": 4.533710133225676,
      "grad_norm": 0.24748438596725464,
      "learning_rate": 1.5466289866774325e-05,
      "loss": 0.0167,
      "step": 11230
    },
    {
      "epoch": 4.53774727492935,
      "grad_norm": 0.12016298621892929,
      "learning_rate": 1.5462252725070653e-05,
      "loss": 0.0252,
      "step": 11240
    },
    {
      "epoch": 4.541784416633024,
      "grad_norm": 0.017660481855273247,
      "learning_rate": 1.5458215583366978e-05,
      "loss": 0.0666,
      "step": 11250
    },
    {
      "epoch": 4.545821558336698,
      "grad_norm": 0.2994735836982727,
      "learning_rate": 1.5454178441663302e-05,
      "loss": 0.0465,
      "step": 11260
    },
    {
      "epoch": 4.549858700040371,
      "grad_norm": 8.532173156738281,
      "learning_rate": 1.545014129995963e-05,
      "loss": 0.0278,
      "step": 11270
    },
    {
      "epoch": 4.553895841744045,
      "grad_norm": 0.008472672663629055,
      "learning_rate": 1.544610415825596e-05,
      "loss": 0.0292,
      "step": 11280
    },
    {
      "epoch": 4.557932983447719,
      "grad_norm": 1.3595062494277954,
      "learning_rate": 1.5442067016552283e-05,
      "loss": 0.0421,
      "step": 11290
    },
    {
      "epoch": 4.561970125151393,
      "grad_norm": 0.005566517356783152,
      "learning_rate": 1.5438029874848608e-05,
      "loss": 0.0226,
      "step": 11300
    },
    {
      "epoch": 4.566007266855067,
      "grad_norm": 2.76838755607605,
      "learning_rate": 1.5433992733144936e-05,
      "loss": 0.0529,
      "step": 11310
    },
    {
      "epoch": 4.57004440855874,
      "grad_norm": 0.007750154938548803,
      "learning_rate": 1.542995559144126e-05,
      "loss": 0.0217,
      "step": 11320
    },
    {
      "epoch": 4.574081550262414,
      "grad_norm": 2.0546817779541016,
      "learning_rate": 1.5425918449737588e-05,
      "loss": 0.0171,
      "step": 11330
    },
    {
      "epoch": 4.578118691966088,
      "grad_norm": 0.00586371636018157,
      "learning_rate": 1.5421881308033913e-05,
      "loss": 0.0305,
      "step": 11340
    },
    {
      "epoch": 4.582155833669762,
      "grad_norm": 0.3498706519603729,
      "learning_rate": 1.541784416633024e-05,
      "loss": 0.1267,
      "step": 11350
    },
    {
      "epoch": 4.586192975373436,
      "grad_norm": 0.001864929567091167,
      "learning_rate": 1.5413807024626565e-05,
      "loss": 0.005,
      "step": 11360
    },
    {
      "epoch": 4.590230117077109,
      "grad_norm": 0.201773002743721,
      "learning_rate": 1.540976988292289e-05,
      "loss": 0.0279,
      "step": 11370
    },
    {
      "epoch": 4.594267258780783,
      "grad_norm": 0.003938640002161264,
      "learning_rate": 1.5405732741219218e-05,
      "loss": 0.0835,
      "step": 11380
    },
    {
      "epoch": 4.598304400484457,
      "grad_norm": 2.606875419616699,
      "learning_rate": 1.5401695599515546e-05,
      "loss": 0.0992,
      "step": 11390
    },
    {
      "epoch": 4.602341542188131,
      "grad_norm": 0.5407155156135559,
      "learning_rate": 1.539765845781187e-05,
      "loss": 0.0334,
      "step": 11400
    },
    {
      "epoch": 4.606378683891805,
      "grad_norm": 5.418800354003906,
      "learning_rate": 1.5393621316108195e-05,
      "loss": 0.0145,
      "step": 11410
    },
    {
      "epoch": 4.610415825595478,
      "grad_norm": 18.47381591796875,
      "learning_rate": 1.5389584174404523e-05,
      "loss": 0.0554,
      "step": 11420
    },
    {
      "epoch": 4.614452967299152,
      "grad_norm": 2.500731945037842,
      "learning_rate": 1.538554703270085e-05,
      "loss": 0.0238,
      "step": 11430
    },
    {
      "epoch": 4.618490109002826,
      "grad_norm": 0.031338881701231,
      "learning_rate": 1.5381509890997176e-05,
      "loss": 0.0254,
      "step": 11440
    },
    {
      "epoch": 4.6225272507065,
      "grad_norm": 0.0866050124168396,
      "learning_rate": 1.53774727492935e-05,
      "loss": 0.0417,
      "step": 11450
    },
    {
      "epoch": 4.626564392410174,
      "grad_norm": 0.008117464371025562,
      "learning_rate": 1.5373435607589828e-05,
      "loss": 0.0705,
      "step": 11460
    },
    {
      "epoch": 4.630601534113848,
      "grad_norm": 1.0388991832733154,
      "learning_rate": 1.5369398465886153e-05,
      "loss": 0.0087,
      "step": 11470
    },
    {
      "epoch": 4.634638675817521,
      "grad_norm": 0.9022786021232605,
      "learning_rate": 1.536536132418248e-05,
      "loss": 0.079,
      "step": 11480
    },
    {
      "epoch": 4.638675817521195,
      "grad_norm": 2.1973695755004883,
      "learning_rate": 1.536132418247881e-05,
      "loss": 0.0414,
      "step": 11490
    },
    {
      "epoch": 4.642712959224869,
      "grad_norm": 13.326282501220703,
      "learning_rate": 1.5357287040775133e-05,
      "loss": 0.0427,
      "step": 11500
    },
    {
      "epoch": 4.646750100928543,
      "grad_norm": 0.8584516644477844,
      "learning_rate": 1.5353249899071458e-05,
      "loss": 0.0168,
      "step": 11510
    },
    {
      "epoch": 4.650787242632217,
      "grad_norm": 0.01967189833521843,
      "learning_rate": 1.5349212757367782e-05,
      "loss": 0.0356,
      "step": 11520
    },
    {
      "epoch": 4.65482438433589,
      "grad_norm": 0.012101382948458195,
      "learning_rate": 1.534517561566411e-05,
      "loss": 0.0273,
      "step": 11530
    },
    {
      "epoch": 4.658861526039564,
      "grad_norm": 0.00996896531432867,
      "learning_rate": 1.534113847396044e-05,
      "loss": 0.0115,
      "step": 11540
    },
    {
      "epoch": 4.662898667743238,
      "grad_norm": 0.04739980027079582,
      "learning_rate": 1.5337101332256763e-05,
      "loss": 0.0125,
      "step": 11550
    },
    {
      "epoch": 4.666935809446912,
      "grad_norm": 1.808611273765564,
      "learning_rate": 1.5333064190553088e-05,
      "loss": 0.0089,
      "step": 11560
    },
    {
      "epoch": 4.670972951150586,
      "grad_norm": 0.002220527036115527,
      "learning_rate": 1.5329027048849416e-05,
      "loss": 0.0083,
      "step": 11570
    },
    {
      "epoch": 4.675010092854259,
      "grad_norm": 0.029208935797214508,
      "learning_rate": 1.5324989907145744e-05,
      "loss": 0.0148,
      "step": 11580
    },
    {
      "epoch": 4.679047234557933,
      "grad_norm": 5.4044671058654785,
      "learning_rate": 1.5320952765442068e-05,
      "loss": 0.045,
      "step": 11590
    },
    {
      "epoch": 4.683084376261607,
      "grad_norm": 2.002070188522339,
      "learning_rate": 1.5316915623738396e-05,
      "loss": 0.0044,
      "step": 11600
    },
    {
      "epoch": 4.687121517965281,
      "grad_norm": 5.178907871246338,
      "learning_rate": 1.531287848203472e-05,
      "loss": 0.0428,
      "step": 11610
    },
    {
      "epoch": 4.691158659668955,
      "grad_norm": 15.938695907592773,
      "learning_rate": 1.5308841340331045e-05,
      "loss": 0.0987,
      "step": 11620
    },
    {
      "epoch": 4.695195801372628,
      "grad_norm": 0.06719369441270828,
      "learning_rate": 1.5304804198627373e-05,
      "loss": 0.0073,
      "step": 11630
    },
    {
      "epoch": 4.699232943076302,
      "grad_norm": 0.04380493983626366,
      "learning_rate": 1.53007670569237e-05,
      "loss": 0.0336,
      "step": 11640
    },
    {
      "epoch": 4.703270084779976,
      "grad_norm": 0.00922070536762476,
      "learning_rate": 1.5296729915220026e-05,
      "loss": 0.0184,
      "step": 11650
    },
    {
      "epoch": 4.70730722648365,
      "grad_norm": 0.2811160087585449,
      "learning_rate": 1.529269277351635e-05,
      "loss": 0.0055,
      "step": 11660
    },
    {
      "epoch": 4.711344368187324,
      "grad_norm": 0.026065105572342873,
      "learning_rate": 1.528865563181268e-05,
      "loss": 0.0568,
      "step": 11670
    },
    {
      "epoch": 4.715381509890997,
      "grad_norm": 0.3906879723072052,
      "learning_rate": 1.5284618490109003e-05,
      "loss": 0.0151,
      "step": 11680
    },
    {
      "epoch": 4.719418651594671,
      "grad_norm": 2.02126145362854,
      "learning_rate": 1.528058134840533e-05,
      "loss": 0.0575,
      "step": 11690
    },
    {
      "epoch": 4.723455793298345,
      "grad_norm": 8.36074161529541,
      "learning_rate": 1.5276544206701656e-05,
      "loss": 0.0332,
      "step": 11700
    },
    {
      "epoch": 4.727492935002019,
      "grad_norm": 0.564045250415802,
      "learning_rate": 1.5272507064997984e-05,
      "loss": 0.001,
      "step": 11710
    },
    {
      "epoch": 4.731530076705693,
      "grad_norm": 1.8324239253997803,
      "learning_rate": 1.5268469923294308e-05,
      "loss": 0.0323,
      "step": 11720
    },
    {
      "epoch": 4.735567218409366,
      "grad_norm": 0.021784786134958267,
      "learning_rate": 1.5264432781590636e-05,
      "loss": 0.0059,
      "step": 11730
    },
    {
      "epoch": 4.73960436011304,
      "grad_norm": 0.008393274620175362,
      "learning_rate": 1.526039563988696e-05,
      "loss": 0.0589,
      "step": 11740
    },
    {
      "epoch": 4.743641501816714,
      "grad_norm": 0.5161134004592896,
      "learning_rate": 1.5256358498183289e-05,
      "loss": 0.0466,
      "step": 11750
    },
    {
      "epoch": 4.747678643520388,
      "grad_norm": 2.2404472827911377,
      "learning_rate": 1.5252321356479613e-05,
      "loss": 0.0598,
      "step": 11760
    },
    {
      "epoch": 4.751715785224062,
      "grad_norm": 2.6519885063171387,
      "learning_rate": 1.524828421477594e-05,
      "loss": 0.0941,
      "step": 11770
    },
    {
      "epoch": 4.755752926927736,
      "grad_norm": 0.24099522829055786,
      "learning_rate": 1.5244247073072268e-05,
      "loss": 0.0479,
      "step": 11780
    },
    {
      "epoch": 4.759790068631409,
      "grad_norm": 0.6156583428382874,
      "learning_rate": 1.5240209931368592e-05,
      "loss": 0.0194,
      "step": 11790
    },
    {
      "epoch": 4.763827210335083,
      "grad_norm": 0.038726743310689926,
      "learning_rate": 1.5236172789664919e-05,
      "loss": 0.0196,
      "step": 11800
    },
    {
      "epoch": 4.767864352038757,
      "grad_norm": 0.0354328379034996,
      "learning_rate": 1.5232135647961243e-05,
      "loss": 0.0112,
      "step": 11810
    },
    {
      "epoch": 4.771901493742431,
      "grad_norm": 4.293288707733154,
      "learning_rate": 1.5228098506257571e-05,
      "loss": 0.0283,
      "step": 11820
    },
    {
      "epoch": 4.775938635446105,
      "grad_norm": 11.79372787475586,
      "learning_rate": 1.5224061364553897e-05,
      "loss": 0.0437,
      "step": 11830
    },
    {
      "epoch": 4.779975777149778,
      "grad_norm": 2.288968324661255,
      "learning_rate": 1.5220024222850222e-05,
      "loss": 0.0546,
      "step": 11840
    },
    {
      "epoch": 4.784012918853452,
      "grad_norm": 0.019537094980478287,
      "learning_rate": 1.521598708114655e-05,
      "loss": 0.0373,
      "step": 11850
    },
    {
      "epoch": 4.788050060557126,
      "grad_norm": 0.00690879300236702,
      "learning_rate": 1.5211949939442876e-05,
      "loss": 0.0168,
      "step": 11860
    },
    {
      "epoch": 4.7920872022608,
      "grad_norm": 0.4648618996143341,
      "learning_rate": 1.52079127977392e-05,
      "loss": 0.0632,
      "step": 11870
    },
    {
      "epoch": 4.796124343964474,
      "grad_norm": 0.21338079869747162,
      "learning_rate": 1.5203875656035527e-05,
      "loss": 0.0093,
      "step": 11880
    },
    {
      "epoch": 4.800161485668147,
      "grad_norm": 0.00821490678936243,
      "learning_rate": 1.5199838514331855e-05,
      "loss": 0.0515,
      "step": 11890
    },
    {
      "epoch": 4.804198627371821,
      "grad_norm": 0.03259407356381416,
      "learning_rate": 1.5195801372628181e-05,
      "loss": 0.0892,
      "step": 11900
    },
    {
      "epoch": 4.808235769075495,
      "grad_norm": 1.841742753982544,
      "learning_rate": 1.5191764230924506e-05,
      "loss": 0.0392,
      "step": 11910
    },
    {
      "epoch": 4.812272910779169,
      "grad_norm": 2.787954568862915,
      "learning_rate": 1.5187727089220834e-05,
      "loss": 0.0785,
      "step": 11920
    },
    {
      "epoch": 4.816310052482843,
      "grad_norm": 0.09240897744894028,
      "learning_rate": 1.518368994751716e-05,
      "loss": 0.0243,
      "step": 11930
    },
    {
      "epoch": 4.820347194186516,
      "grad_norm": 0.018199222162365913,
      "learning_rate": 1.5179652805813485e-05,
      "loss": 0.0161,
      "step": 11940
    },
    {
      "epoch": 4.82438433589019,
      "grad_norm": 1.962183952331543,
      "learning_rate": 1.5175615664109811e-05,
      "loss": 0.0341,
      "step": 11950
    },
    {
      "epoch": 4.828421477593864,
      "grad_norm": 2.114043951034546,
      "learning_rate": 1.5171578522406139e-05,
      "loss": 0.0277,
      "step": 11960
    },
    {
      "epoch": 4.832458619297538,
      "grad_norm": 0.029711896553635597,
      "learning_rate": 1.5167541380702464e-05,
      "loss": 0.0879,
      "step": 11970
    },
    {
      "epoch": 4.836495761001212,
      "grad_norm": 0.24837182462215424,
      "learning_rate": 1.516350423899879e-05,
      "loss": 0.0079,
      "step": 11980
    },
    {
      "epoch": 4.840532902704885,
      "grad_norm": 0.5632131099700928,
      "learning_rate": 1.5159467097295115e-05,
      "loss": 0.0038,
      "step": 11990
    },
    {
      "epoch": 4.844570044408559,
      "grad_norm": 0.01314574759453535,
      "learning_rate": 1.5155429955591443e-05,
      "loss": 0.0079,
      "step": 12000
    },
    {
      "epoch": 4.848607186112233,
      "grad_norm": 0.0059874048456549644,
      "learning_rate": 1.5151392813887769e-05,
      "loss": 0.0127,
      "step": 12010
    },
    {
      "epoch": 4.852644327815907,
      "grad_norm": 0.062375329434871674,
      "learning_rate": 1.5147355672184093e-05,
      "loss": 0.019,
      "step": 12020
    },
    {
      "epoch": 4.856681469519581,
      "grad_norm": 0.060113325715065,
      "learning_rate": 1.5143318530480421e-05,
      "loss": 0.0188,
      "step": 12030
    },
    {
      "epoch": 4.860718611223254,
      "grad_norm": 4.5996222496032715,
      "learning_rate": 1.5139281388776748e-05,
      "loss": 0.0645,
      "step": 12040
    },
    {
      "epoch": 4.864755752926928,
      "grad_norm": 0.22195085883140564,
      "learning_rate": 1.5135244247073074e-05,
      "loss": 0.0538,
      "step": 12050
    },
    {
      "epoch": 4.868792894630602,
      "grad_norm": 2.2196426391601562,
      "learning_rate": 1.5131207105369399e-05,
      "loss": 0.0338,
      "step": 12060
    },
    {
      "epoch": 4.872830036334276,
      "grad_norm": 0.010743966326117516,
      "learning_rate": 1.5127169963665727e-05,
      "loss": 0.023,
      "step": 12070
    },
    {
      "epoch": 4.87686717803795,
      "grad_norm": 2.628109931945801,
      "learning_rate": 1.5123132821962053e-05,
      "loss": 0.0395,
      "step": 12080
    },
    {
      "epoch": 4.880904319741623,
      "grad_norm": 0.006435907445847988,
      "learning_rate": 1.5119095680258377e-05,
      "loss": 0.0287,
      "step": 12090
    },
    {
      "epoch": 4.884941461445297,
      "grad_norm": 0.005627680569887161,
      "learning_rate": 1.5115058538554705e-05,
      "loss": 0.0092,
      "step": 12100
    },
    {
      "epoch": 4.888978603148971,
      "grad_norm": 0.1612830013036728,
      "learning_rate": 1.5111021396851032e-05,
      "loss": 0.0078,
      "step": 12110
    },
    {
      "epoch": 4.893015744852645,
      "grad_norm": 0.0023609986528754234,
      "learning_rate": 1.5106984255147356e-05,
      "loss": 0.0283,
      "step": 12120
    },
    {
      "epoch": 4.8970528865563185,
      "grad_norm": 0.0037410338409245014,
      "learning_rate": 1.5102947113443683e-05,
      "loss": 0.0371,
      "step": 12130
    },
    {
      "epoch": 4.901090028259992,
      "grad_norm": 3.362229824066162,
      "learning_rate": 1.509890997174001e-05,
      "loss": 0.0182,
      "step": 12140
    },
    {
      "epoch": 4.905127169963666,
      "grad_norm": 4.753110885620117,
      "learning_rate": 1.5094872830036335e-05,
      "loss": 0.0413,
      "step": 12150
    },
    {
      "epoch": 4.90916431166734,
      "grad_norm": 0.0032649950589984655,
      "learning_rate": 1.5090835688332661e-05,
      "loss": 0.0252,
      "step": 12160
    },
    {
      "epoch": 4.9132014533710135,
      "grad_norm": 0.00557685038074851,
      "learning_rate": 1.508679854662899e-05,
      "loss": 0.008,
      "step": 12170
    },
    {
      "epoch": 4.9172385950746875,
      "grad_norm": 0.002177674090489745,
      "learning_rate": 1.5082761404925314e-05,
      "loss": 0.038,
      "step": 12180
    },
    {
      "epoch": 4.921275736778361,
      "grad_norm": 9.227740287780762,
      "learning_rate": 1.507872426322164e-05,
      "loss": 0.0409,
      "step": 12190
    },
    {
      "epoch": 4.925312878482035,
      "grad_norm": 0.005279934965074062,
      "learning_rate": 1.5074687121517965e-05,
      "loss": 0.0235,
      "step": 12200
    },
    {
      "epoch": 4.929350020185709,
      "grad_norm": 0.05116273835301399,
      "learning_rate": 1.5070649979814293e-05,
      "loss": 0.0732,
      "step": 12210
    },
    {
      "epoch": 4.9333871618893825,
      "grad_norm": 0.013823173008859158,
      "learning_rate": 1.506661283811062e-05,
      "loss": 0.0158,
      "step": 12220
    },
    {
      "epoch": 4.9374243035930565,
      "grad_norm": 0.07969017326831818,
      "learning_rate": 1.5062575696406945e-05,
      "loss": 0.015,
      "step": 12230
    },
    {
      "epoch": 4.94146144529673,
      "grad_norm": 0.027904855087399483,
      "learning_rate": 1.505853855470327e-05,
      "loss": 0.0586,
      "step": 12240
    },
    {
      "epoch": 4.945498587000404,
      "grad_norm": 0.005866870284080505,
      "learning_rate": 1.5054501412999598e-05,
      "loss": 0.0012,
      "step": 12250
    },
    {
      "epoch": 4.9495357287040775,
      "grad_norm": 1.3756922483444214,
      "learning_rate": 1.5050464271295924e-05,
      "loss": 0.0099,
      "step": 12260
    },
    {
      "epoch": 4.9535728704077515,
      "grad_norm": 0.002746276557445526,
      "learning_rate": 1.5046427129592249e-05,
      "loss": 0.071,
      "step": 12270
    },
    {
      "epoch": 4.9576100121114255,
      "grad_norm": 0.005369457881897688,
      "learning_rate": 1.5042389987888577e-05,
      "loss": 0.0621,
      "step": 12280
    },
    {
      "epoch": 4.961647153815099,
      "grad_norm": 1.072465181350708,
      "learning_rate": 1.5038352846184903e-05,
      "loss": 0.0136,
      "step": 12290
    },
    {
      "epoch": 4.9656842955187726,
      "grad_norm": 0.0073632653802633286,
      "learning_rate": 1.5034315704481228e-05,
      "loss": 0.0142,
      "step": 12300
    },
    {
      "epoch": 4.9697214372224465,
      "grad_norm": 2.4129457473754883,
      "learning_rate": 1.5030278562777554e-05,
      "loss": 0.0085,
      "step": 12310
    },
    {
      "epoch": 4.9737585789261205,
      "grad_norm": 6.995929718017578,
      "learning_rate": 1.5026241421073882e-05,
      "loss": 0.0352,
      "step": 12320
    },
    {
      "epoch": 4.9777957206297945,
      "grad_norm": 0.006727856118232012,
      "learning_rate": 1.5022204279370207e-05,
      "loss": 0.0091,
      "step": 12330
    },
    {
      "epoch": 4.981832862333468,
      "grad_norm": 5.945104598999023,
      "learning_rate": 1.5018167137666533e-05,
      "loss": 0.0328,
      "step": 12340
    },
    {
      "epoch": 4.9858700040371415,
      "grad_norm": 0.001625535311177373,
      "learning_rate": 1.5014129995962861e-05,
      "loss": 0.0263,
      "step": 12350
    },
    {
      "epoch": 4.9899071457408155,
      "grad_norm": 0.24470588564872742,
      "learning_rate": 1.5010092854259186e-05,
      "loss": 0.0408,
      "step": 12360
    },
    {
      "epoch": 4.9939442874444895,
      "grad_norm": 0.007562713697552681,
      "learning_rate": 1.5006055712555512e-05,
      "loss": 0.0221,
      "step": 12370
    },
    {
      "epoch": 4.9979814291481635,
      "grad_norm": 0.881618857383728,
      "learning_rate": 1.5002018570851838e-05,
      "loss": 0.0111,
      "step": 12380
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9845911949685534,
      "eval_f1": 0.943089430894309,
      "eval_loss": 0.06259997189044952,
      "eval_precision": 0.9530516431924883,
      "eval_recall": 0.9333333333333333,
      "eval_runtime": 445.8575,
      "eval_samples_per_second": 28.574,
      "eval_steps_per_second": 1.191,
      "step": 12385
    },
    {
      "epoch": 5.0020185708518365,
      "grad_norm": 0.10969983786344528,
      "learning_rate": 1.4997981429148164e-05,
      "loss": 0.0052,
      "step": 12390
    },
    {
      "epoch": 5.0060557125555105,
      "grad_norm": 0.008794240653514862,
      "learning_rate": 1.499394428744449e-05,
      "loss": 0.0226,
      "step": 12400
    },
    {
      "epoch": 5.0100928542591845,
      "grad_norm": 1.4848792552947998,
      "learning_rate": 1.4989907145740817e-05,
      "loss": 0.0268,
      "step": 12410
    },
    {
      "epoch": 5.0141299959628585,
      "grad_norm": 0.019384484738111496,
      "learning_rate": 1.4985870004037142e-05,
      "loss": 0.0042,
      "step": 12420
    },
    {
      "epoch": 5.018167137666532,
      "grad_norm": 4.958566665649414,
      "learning_rate": 1.498183286233347e-05,
      "loss": 0.0156,
      "step": 12430
    },
    {
      "epoch": 5.0222042793702055,
      "grad_norm": 0.8556169271469116,
      "learning_rate": 1.4977795720629796e-05,
      "loss": 0.0065,
      "step": 12440
    },
    {
      "epoch": 5.0262414210738795,
      "grad_norm": 0.003736836137250066,
      "learning_rate": 1.497375857892612e-05,
      "loss": 0.0211,
      "step": 12450
    },
    {
      "epoch": 5.0302785627775535,
      "grad_norm": 0.0016439545433968306,
      "learning_rate": 1.4969721437222448e-05,
      "loss": 0.0181,
      "step": 12460
    },
    {
      "epoch": 5.0343157044812274,
      "grad_norm": 0.0016547234263271093,
      "learning_rate": 1.4965684295518775e-05,
      "loss": 0.0644,
      "step": 12470
    },
    {
      "epoch": 5.038352846184901,
      "grad_norm": 0.029147451743483543,
      "learning_rate": 1.49616471538151e-05,
      "loss": 0.0289,
      "step": 12480
    },
    {
      "epoch": 5.0423899878885745,
      "grad_norm": 0.0014119319384917617,
      "learning_rate": 1.4957610012111426e-05,
      "loss": 0.0334,
      "step": 12490
    },
    {
      "epoch": 5.0464271295922485,
      "grad_norm": 0.24418343603610992,
      "learning_rate": 1.4953572870407754e-05,
      "loss": 0.0043,
      "step": 12500
    },
    {
      "epoch": 5.0504642712959225,
      "grad_norm": 1.467745304107666,
      "learning_rate": 1.4949535728704078e-05,
      "loss": 0.0045,
      "step": 12510
    },
    {
      "epoch": 5.054501412999596,
      "grad_norm": 0.0019477643072605133,
      "learning_rate": 1.4945498587000404e-05,
      "loss": 0.0101,
      "step": 12520
    },
    {
      "epoch": 5.05853855470327,
      "grad_norm": 0.005821297876536846,
      "learning_rate": 1.4941461445296732e-05,
      "loss": 0.0016,
      "step": 12530
    },
    {
      "epoch": 5.0625756964069435,
      "grad_norm": 0.002621150342747569,
      "learning_rate": 1.4937424303593057e-05,
      "loss": 0.0249,
      "step": 12540
    },
    {
      "epoch": 5.0666128381106175,
      "grad_norm": 0.003389092395082116,
      "learning_rate": 1.4933387161889383e-05,
      "loss": 0.0323,
      "step": 12550
    },
    {
      "epoch": 5.070649979814291,
      "grad_norm": 1.3999810218811035,
      "learning_rate": 1.492935002018571e-05,
      "loss": 0.0248,
      "step": 12560
    },
    {
      "epoch": 5.074687121517965,
      "grad_norm": 17.843652725219727,
      "learning_rate": 1.4925312878482038e-05,
      "loss": 0.071,
      "step": 12570
    },
    {
      "epoch": 5.078724263221639,
      "grad_norm": 1.275726079940796,
      "learning_rate": 1.4921275736778362e-05,
      "loss": 0.0058,
      "step": 12580
    },
    {
      "epoch": 5.0827614049253125,
      "grad_norm": 0.002143912948668003,
      "learning_rate": 1.4917238595074688e-05,
      "loss": 0.0094,
      "step": 12590
    },
    {
      "epoch": 5.0867985466289865,
      "grad_norm": 0.005563519429415464,
      "learning_rate": 1.4913201453371013e-05,
      "loss": 0.031,
      "step": 12600
    },
    {
      "epoch": 5.09083568833266,
      "grad_norm": 23.537878036499023,
      "learning_rate": 1.4909164311667341e-05,
      "loss": 0.0191,
      "step": 12610
    },
    {
      "epoch": 5.094872830036334,
      "grad_norm": 0.04030203819274902,
      "learning_rate": 1.4905127169963667e-05,
      "loss": 0.0281,
      "step": 12620
    },
    {
      "epoch": 5.098909971740008,
      "grad_norm": 0.9232673048973083,
      "learning_rate": 1.4901090028259992e-05,
      "loss": 0.0668,
      "step": 12630
    },
    {
      "epoch": 5.1029471134436815,
      "grad_norm": 0.030354715883731842,
      "learning_rate": 1.489705288655632e-05,
      "loss": 0.0265,
      "step": 12640
    },
    {
      "epoch": 5.106984255147355,
      "grad_norm": 0.019163254648447037,
      "learning_rate": 1.4893015744852646e-05,
      "loss": 0.0121,
      "step": 12650
    },
    {
      "epoch": 5.111021396851029,
      "grad_norm": 0.0026060971431434155,
      "learning_rate": 1.488897860314897e-05,
      "loss": 0.0667,
      "step": 12660
    },
    {
      "epoch": 5.115058538554703,
      "grad_norm": 0.8068026900291443,
      "learning_rate": 1.4884941461445297e-05,
      "loss": 0.0107,
      "step": 12670
    },
    {
      "epoch": 5.119095680258377,
      "grad_norm": 1.613569736480713,
      "learning_rate": 1.4880904319741625e-05,
      "loss": 0.0149,
      "step": 12680
    },
    {
      "epoch": 5.12313282196205,
      "grad_norm": 0.0020353796426206827,
      "learning_rate": 1.487686717803795e-05,
      "loss": 0.0136,
      "step": 12690
    },
    {
      "epoch": 5.127169963665724,
      "grad_norm": 1.4325467348098755,
      "learning_rate": 1.4872830036334276e-05,
      "loss": 0.0107,
      "step": 12700
    },
    {
      "epoch": 5.131207105369398,
      "grad_norm": 0.0025851232931017876,
      "learning_rate": 1.4868792894630604e-05,
      "loss": 0.0197,
      "step": 12710
    },
    {
      "epoch": 5.135244247073072,
      "grad_norm": 0.03868718445301056,
      "learning_rate": 1.4864755752926928e-05,
      "loss": 0.0345,
      "step": 12720
    },
    {
      "epoch": 5.139281388776746,
      "grad_norm": 0.03594030812382698,
      "learning_rate": 1.4860718611223255e-05,
      "loss": 0.0597,
      "step": 12730
    },
    {
      "epoch": 5.143318530480419,
      "grad_norm": 0.0123808104544878,
      "learning_rate": 1.4856681469519581e-05,
      "loss": 0.0517,
      "step": 12740
    },
    {
      "epoch": 5.147355672184093,
      "grad_norm": 0.10026492923498154,
      "learning_rate": 1.4852644327815909e-05,
      "loss": 0.0061,
      "step": 12750
    },
    {
      "epoch": 5.151392813887767,
      "grad_norm": 0.27280518412590027,
      "learning_rate": 1.4848607186112234e-05,
      "loss": 0.006,
      "step": 12760
    },
    {
      "epoch": 5.155429955591441,
      "grad_norm": 0.05821053311228752,
      "learning_rate": 1.484457004440856e-05,
      "loss": 0.0248,
      "step": 12770
    },
    {
      "epoch": 5.159467097295115,
      "grad_norm": 0.05318780615925789,
      "learning_rate": 1.4840532902704888e-05,
      "loss": 0.0065,
      "step": 12780
    },
    {
      "epoch": 5.163504238998788,
      "grad_norm": 0.0023535992950201035,
      "learning_rate": 1.4836495761001212e-05,
      "loss": 0.0166,
      "step": 12790
    },
    {
      "epoch": 5.167541380702462,
      "grad_norm": 0.011485935188829899,
      "learning_rate": 1.4832458619297539e-05,
      "loss": 0.0301,
      "step": 12800
    },
    {
      "epoch": 5.171578522406136,
      "grad_norm": 0.018970316275954247,
      "learning_rate": 1.4828421477593863e-05,
      "loss": 0.0062,
      "step": 12810
    },
    {
      "epoch": 5.17561566410981,
      "grad_norm": 0.027140693739056587,
      "learning_rate": 1.4824384335890191e-05,
      "loss": 0.0086,
      "step": 12820
    },
    {
      "epoch": 5.179652805813484,
      "grad_norm": 0.006410344038158655,
      "learning_rate": 1.4820347194186518e-05,
      "loss": 0.0016,
      "step": 12830
    },
    {
      "epoch": 5.183689947517158,
      "grad_norm": 0.6815573573112488,
      "learning_rate": 1.4816310052482842e-05,
      "loss": 0.0021,
      "step": 12840
    },
    {
      "epoch": 5.187727089220831,
      "grad_norm": 0.0027375915087759495,
      "learning_rate": 1.4812272910779168e-05,
      "loss": 0.0244,
      "step": 12850
    },
    {
      "epoch": 5.191764230924505,
      "grad_norm": 0.00238616275601089,
      "learning_rate": 1.4808235769075496e-05,
      "loss": 0.0264,
      "step": 12860
    },
    {
      "epoch": 5.195801372628179,
      "grad_norm": 0.2390967607498169,
      "learning_rate": 1.4804198627371821e-05,
      "loss": 0.0183,
      "step": 12870
    },
    {
      "epoch": 5.199838514331853,
      "grad_norm": 0.006053355988115072,
      "learning_rate": 1.4800161485668147e-05,
      "loss": 0.0255,
      "step": 12880
    },
    {
      "epoch": 5.203875656035527,
      "grad_norm": 0.0018987016519531608,
      "learning_rate": 1.4796124343964475e-05,
      "loss": 0.0169,
      "step": 12890
    },
    {
      "epoch": 5.2079127977392,
      "grad_norm": 7.3250250816345215,
      "learning_rate": 1.4792087202260802e-05,
      "loss": 0.0509,
      "step": 12900
    },
    {
      "epoch": 5.211949939442874,
      "grad_norm": 0.018695330247282982,
      "learning_rate": 1.4788050060557126e-05,
      "loss": 0.02,
      "step": 12910
    },
    {
      "epoch": 5.215987081146548,
      "grad_norm": 0.007501776330173016,
      "learning_rate": 1.4784012918853452e-05,
      "loss": 0.0176,
      "step": 12920
    },
    {
      "epoch": 5.220024222850222,
      "grad_norm": 6.3787841796875,
      "learning_rate": 1.477997577714978e-05,
      "loss": 0.0585,
      "step": 12930
    },
    {
      "epoch": 5.224061364553896,
      "grad_norm": 0.029867712408304214,
      "learning_rate": 1.4775938635446105e-05,
      "loss": 0.0629,
      "step": 12940
    },
    {
      "epoch": 5.228098506257569,
      "grad_norm": 1.6492797136306763,
      "learning_rate": 1.4771901493742431e-05,
      "loss": 0.045,
      "step": 12950
    },
    {
      "epoch": 5.232135647961243,
      "grad_norm": 1.0488471984863281,
      "learning_rate": 1.476786435203876e-05,
      "loss": 0.0105,
      "step": 12960
    },
    {
      "epoch": 5.236172789664917,
      "grad_norm": 5.773508071899414,
      "learning_rate": 1.4763827210335084e-05,
      "loss": 0.0172,
      "step": 12970
    },
    {
      "epoch": 5.240209931368591,
      "grad_norm": 0.010468176566064358,
      "learning_rate": 1.475979006863141e-05,
      "loss": 0.0302,
      "step": 12980
    },
    {
      "epoch": 5.244247073072265,
      "grad_norm": 0.015968546271324158,
      "learning_rate": 1.4755752926927735e-05,
      "loss": 0.0065,
      "step": 12990
    },
    {
      "epoch": 5.248284214775938,
      "grad_norm": 0.002581442706286907,
      "learning_rate": 1.4751715785224063e-05,
      "loss": 0.0033,
      "step": 13000
    },
    {
      "epoch": 5.252321356479612,
      "grad_norm": 0.09946337342262268,
      "learning_rate": 1.4747678643520389e-05,
      "loss": 0.0326,
      "step": 13010
    },
    {
      "epoch": 5.256358498183286,
      "grad_norm": 3.6118311882019043,
      "learning_rate": 1.4743641501816714e-05,
      "loss": 0.0354,
      "step": 13020
    },
    {
      "epoch": 5.26039563988696,
      "grad_norm": 0.001970141427591443,
      "learning_rate": 1.473960436011304e-05,
      "loss": 0.011,
      "step": 13030
    },
    {
      "epoch": 5.264432781590634,
      "grad_norm": 2.473533868789673,
      "learning_rate": 1.4735567218409368e-05,
      "loss": 0.0326,
      "step": 13040
    },
    {
      "epoch": 5.268469923294307,
      "grad_norm": 0.16949880123138428,
      "learning_rate": 1.4731530076705694e-05,
      "loss": 0.0101,
      "step": 13050
    },
    {
      "epoch": 5.272507064997981,
      "grad_norm": 1.3641504049301147,
      "learning_rate": 1.4727492935002019e-05,
      "loss": 0.0079,
      "step": 13060
    },
    {
      "epoch": 5.276544206701655,
      "grad_norm": 0.002532052341848612,
      "learning_rate": 1.4723455793298347e-05,
      "loss": 0.0068,
      "step": 13070
    },
    {
      "epoch": 5.280581348405329,
      "grad_norm": 0.000640951853711158,
      "learning_rate": 1.4719418651594673e-05,
      "loss": 0.0169,
      "step": 13080
    },
    {
      "epoch": 5.284618490109003,
      "grad_norm": 0.01838490180671215,
      "learning_rate": 1.4715381509890998e-05,
      "loss": 0.0111,
      "step": 13090
    },
    {
      "epoch": 5.288655631812676,
      "grad_norm": 0.7741809487342834,
      "learning_rate": 1.4711344368187324e-05,
      "loss": 0.0023,
      "step": 13100
    },
    {
      "epoch": 5.29269277351635,
      "grad_norm": 0.0013165016425773501,
      "learning_rate": 1.4707307226483652e-05,
      "loss": 0.0176,
      "step": 13110
    },
    {
      "epoch": 5.296729915220024,
      "grad_norm": 0.0014744388172402978,
      "learning_rate": 1.4703270084779977e-05,
      "loss": 0.0182,
      "step": 13120
    },
    {
      "epoch": 5.300767056923698,
      "grad_norm": 0.003018558956682682,
      "learning_rate": 1.4699232943076303e-05,
      "loss": 0.0456,
      "step": 13130
    },
    {
      "epoch": 5.304804198627372,
      "grad_norm": 2.0075416564941406,
      "learning_rate": 1.469519580137263e-05,
      "loss": 0.024,
      "step": 13140
    },
    {
      "epoch": 5.308841340331045,
      "grad_norm": 0.021849321201443672,
      "learning_rate": 1.4691158659668955e-05,
      "loss": 0.0328,
      "step": 13150
    },
    {
      "epoch": 5.312878482034719,
      "grad_norm": 0.012539719231426716,
      "learning_rate": 1.4687121517965282e-05,
      "loss": 0.0537,
      "step": 13160
    },
    {
      "epoch": 5.316915623738393,
      "grad_norm": 3.2057714462280273,
      "learning_rate": 1.4683084376261606e-05,
      "loss": 0.0349,
      "step": 13170
    },
    {
      "epoch": 5.320952765442067,
      "grad_norm": 0.002004095586016774,
      "learning_rate": 1.4679047234557934e-05,
      "loss": 0.0102,
      "step": 13180
    },
    {
      "epoch": 5.324989907145741,
      "grad_norm": 0.7262450456619263,
      "learning_rate": 1.467501009285426e-05,
      "loss": 0.0131,
      "step": 13190
    },
    {
      "epoch": 5.329027048849414,
      "grad_norm": 0.0016079018823802471,
      "learning_rate": 1.4670972951150587e-05,
      "loss": 0.0308,
      "step": 13200
    },
    {
      "epoch": 5.333064190553088,
      "grad_norm": 0.14239202439785004,
      "learning_rate": 1.4666935809446913e-05,
      "loss": 0.0004,
      "step": 13210
    },
    {
      "epoch": 5.337101332256762,
      "grad_norm": 0.0016083435621112585,
      "learning_rate": 1.466289866774324e-05,
      "loss": 0.0298,
      "step": 13220
    },
    {
      "epoch": 5.341138473960436,
      "grad_norm": 8.973861694335938,
      "learning_rate": 1.4658861526039566e-05,
      "loss": 0.0224,
      "step": 13230
    },
    {
      "epoch": 5.34517561566411,
      "grad_norm": 1.7606314420700073,
      "learning_rate": 1.465482438433589e-05,
      "loss": 0.0201,
      "step": 13240
    },
    {
      "epoch": 5.349212757367783,
      "grad_norm": 0.003977316431701183,
      "learning_rate": 1.4650787242632218e-05,
      "loss": 0.0254,
      "step": 13250
    },
    {
      "epoch": 5.353249899071457,
      "grad_norm": 0.001728975330479443,
      "learning_rate": 1.4646750100928545e-05,
      "loss": 0.0082,
      "step": 13260
    },
    {
      "epoch": 5.357287040775131,
      "grad_norm": 0.0016779765719547868,
      "learning_rate": 1.4642712959224869e-05,
      "loss": 0.0314,
      "step": 13270
    },
    {
      "epoch": 5.361324182478805,
      "grad_norm": 3.6871397495269775,
      "learning_rate": 1.4638675817521195e-05,
      "loss": 0.049,
      "step": 13280
    },
    {
      "epoch": 5.365361324182479,
      "grad_norm": 0.0016522714868187904,
      "learning_rate": 1.4634638675817523e-05,
      "loss": 0.0014,
      "step": 13290
    },
    {
      "epoch": 5.369398465886152,
      "grad_norm": 0.004193554166704416,
      "learning_rate": 1.4630601534113848e-05,
      "loss": 0.0137,
      "step": 13300
    },
    {
      "epoch": 5.373435607589826,
      "grad_norm": 7.438400745391846,
      "learning_rate": 1.4626564392410174e-05,
      "loss": 0.0425,
      "step": 13310
    },
    {
      "epoch": 5.3774727492935,
      "grad_norm": 5.546029567718506,
      "learning_rate": 1.4622527250706502e-05,
      "loss": 0.0907,
      "step": 13320
    },
    {
      "epoch": 5.381509890997174,
      "grad_norm": 0.020129308104515076,
      "learning_rate": 1.4618490109002827e-05,
      "loss": 0.02,
      "step": 13330
    },
    {
      "epoch": 5.385547032700848,
      "grad_norm": 0.4386121332645416,
      "learning_rate": 1.4614452967299153e-05,
      "loss": 0.082,
      "step": 13340
    },
    {
      "epoch": 5.389584174404521,
      "grad_norm": 11.438191413879395,
      "learning_rate": 1.461041582559548e-05,
      "loss": 0.0278,
      "step": 13350
    },
    {
      "epoch": 5.393621316108195,
      "grad_norm": 0.07848499715328217,
      "learning_rate": 1.4606378683891806e-05,
      "loss": 0.0131,
      "step": 13360
    },
    {
      "epoch": 5.397658457811869,
      "grad_norm": 1.1613246202468872,
      "learning_rate": 1.4602341542188132e-05,
      "loss": 0.0124,
      "step": 13370
    },
    {
      "epoch": 5.401695599515543,
      "grad_norm": 0.006233429070562124,
      "learning_rate": 1.4598304400484458e-05,
      "loss": 0.0308,
      "step": 13380
    },
    {
      "epoch": 5.405732741219217,
      "grad_norm": 0.00472821481525898,
      "learning_rate": 1.4594267258780785e-05,
      "loss": 0.0102,
      "step": 13390
    },
    {
      "epoch": 5.40976988292289,
      "grad_norm": 3.5480120182037354,
      "learning_rate": 1.4590230117077111e-05,
      "loss": 0.0173,
      "step": 13400
    },
    {
      "epoch": 5.413807024626564,
      "grad_norm": 0.05917086452245712,
      "learning_rate": 1.4586192975373437e-05,
      "loss": 0.0568,
      "step": 13410
    },
    {
      "epoch": 5.417844166330238,
      "grad_norm": 2.120243787765503,
      "learning_rate": 1.4582155833669762e-05,
      "loss": 0.0055,
      "step": 13420
    },
    {
      "epoch": 5.421881308033912,
      "grad_norm": 4.089347839355469,
      "learning_rate": 1.457811869196609e-05,
      "loss": 0.0382,
      "step": 13430
    },
    {
      "epoch": 5.425918449737586,
      "grad_norm": 1.7448461055755615,
      "learning_rate": 1.4574081550262416e-05,
      "loss": 0.04,
      "step": 13440
    },
    {
      "epoch": 5.42995559144126,
      "grad_norm": 3.5989835262298584,
      "learning_rate": 1.457004440855874e-05,
      "loss": 0.0215,
      "step": 13450
    },
    {
      "epoch": 5.433992733144933,
      "grad_norm": 0.47475624084472656,
      "learning_rate": 1.4566007266855067e-05,
      "loss": 0.0613,
      "step": 13460
    },
    {
      "epoch": 5.438029874848607,
      "grad_norm": 0.003076678141951561,
      "learning_rate": 1.4561970125151395e-05,
      "loss": 0.0001,
      "step": 13470
    },
    {
      "epoch": 5.442067016552281,
      "grad_norm": 0.013143992982804775,
      "learning_rate": 1.455793298344772e-05,
      "loss": 0.0284,
      "step": 13480
    },
    {
      "epoch": 5.446104158255955,
      "grad_norm": 0.00862904917448759,
      "learning_rate": 1.4553895841744046e-05,
      "loss": 0.0191,
      "step": 13490
    },
    {
      "epoch": 5.450141299959629,
      "grad_norm": 0.0028618653304874897,
      "learning_rate": 1.4549858700040374e-05,
      "loss": 0.0054,
      "step": 13500
    },
    {
      "epoch": 5.454178441663302,
      "grad_norm": 0.008182882331311703,
      "learning_rate": 1.4545821558336698e-05,
      "loss": 0.0099,
      "step": 13510
    },
    {
      "epoch": 5.458215583366976,
      "grad_norm": 2.468982219696045,
      "learning_rate": 1.4541784416633025e-05,
      "loss": 0.0262,
      "step": 13520
    },
    {
      "epoch": 5.46225272507065,
      "grad_norm": 0.00804479606449604,
      "learning_rate": 1.4537747274929351e-05,
      "loss": 0.0242,
      "step": 13530
    },
    {
      "epoch": 5.466289866774324,
      "grad_norm": 1.637732982635498,
      "learning_rate": 1.4533710133225677e-05,
      "loss": 0.0304,
      "step": 13540
    },
    {
      "epoch": 5.470327008477998,
      "grad_norm": 0.0046558440662920475,
      "learning_rate": 1.4529672991522003e-05,
      "loss": 0.0092,
      "step": 13550
    },
    {
      "epoch": 5.474364150181671,
      "grad_norm": 0.05728525295853615,
      "learning_rate": 1.452563584981833e-05,
      "loss": 0.0006,
      "step": 13560
    },
    {
      "epoch": 5.478401291885345,
      "grad_norm": 0.03156757727265358,
      "learning_rate": 1.4521598708114658e-05,
      "loss": 0.0227,
      "step": 13570
    },
    {
      "epoch": 5.482438433589019,
      "grad_norm": 0.010049181990325451,
      "learning_rate": 1.4517561566410982e-05,
      "loss": 0.0809,
      "step": 13580
    },
    {
      "epoch": 5.486475575292693,
      "grad_norm": 1.9464545249938965,
      "learning_rate": 1.4513524424707309e-05,
      "loss": 0.0386,
      "step": 13590
    },
    {
      "epoch": 5.490512716996367,
      "grad_norm": 2.0154330730438232,
      "learning_rate": 1.4509487283003633e-05,
      "loss": 0.0209,
      "step": 13600
    },
    {
      "epoch": 5.49454985870004,
      "grad_norm": 0.015789780765771866,
      "learning_rate": 1.4505450141299961e-05,
      "loss": 0.051,
      "step": 13610
    },
    {
      "epoch": 5.498587000403714,
      "grad_norm": 0.8556531667709351,
      "learning_rate": 1.4501412999596287e-05,
      "loss": 0.0326,
      "step": 13620
    },
    {
      "epoch": 5.502624142107388,
      "grad_norm": 2.0196733474731445,
      "learning_rate": 1.4497375857892612e-05,
      "loss": 0.0302,
      "step": 13630
    },
    {
      "epoch": 5.506661283811062,
      "grad_norm": 0.01263684593141079,
      "learning_rate": 1.449333871618894e-05,
      "loss": 0.0179,
      "step": 13640
    },
    {
      "epoch": 5.510698425514736,
      "grad_norm": 0.007429036777466536,
      "learning_rate": 1.4489301574485266e-05,
      "loss": 0.0189,
      "step": 13650
    },
    {
      "epoch": 5.514735567218409,
      "grad_norm": 0.0022640798706561327,
      "learning_rate": 1.4485264432781591e-05,
      "loss": 0.0093,
      "step": 13660
    },
    {
      "epoch": 5.518772708922083,
      "grad_norm": 2.030647039413452,
      "learning_rate": 1.4481227291077917e-05,
      "loss": 0.0105,
      "step": 13670
    },
    {
      "epoch": 5.522809850625757,
      "grad_norm": 0.004028909839689732,
      "learning_rate": 1.4477190149374245e-05,
      "loss": 0.0259,
      "step": 13680
    },
    {
      "epoch": 5.526846992329431,
      "grad_norm": 4.580214500427246,
      "learning_rate": 1.447315300767057e-05,
      "loss": 0.0447,
      "step": 13690
    },
    {
      "epoch": 5.530884134033105,
      "grad_norm": 0.09179149568080902,
      "learning_rate": 1.4469115865966896e-05,
      "loss": 0.0246,
      "step": 13700
    },
    {
      "epoch": 5.534921275736778,
      "grad_norm": 0.018024630844593048,
      "learning_rate": 1.4465078724263222e-05,
      "loss": 0.0489,
      "step": 13710
    },
    {
      "epoch": 5.538958417440452,
      "grad_norm": 0.005812752526253462,
      "learning_rate": 1.446104158255955e-05,
      "loss": 0.015,
      "step": 13720
    },
    {
      "epoch": 5.542995559144126,
      "grad_norm": 2.2813313007354736,
      "learning_rate": 1.4457004440855875e-05,
      "loss": 0.0128,
      "step": 13730
    },
    {
      "epoch": 5.5470327008478,
      "grad_norm": 0.012117966078221798,
      "learning_rate": 1.4452967299152201e-05,
      "loss": 0.0596,
      "step": 13740
    },
    {
      "epoch": 5.551069842551474,
      "grad_norm": 0.8907437920570374,
      "learning_rate": 1.444893015744853e-05,
      "loss": 0.0842,
      "step": 13750
    },
    {
      "epoch": 5.555106984255147,
      "grad_norm": 0.004271641839295626,
      "learning_rate": 1.4444893015744854e-05,
      "loss": 0.007,
      "step": 13760
    },
    {
      "epoch": 5.559144125958821,
      "grad_norm": 0.007166695781052113,
      "learning_rate": 1.444085587404118e-05,
      "loss": 0.0151,
      "step": 13770
    },
    {
      "epoch": 5.563181267662495,
      "grad_norm": 0.005367433652281761,
      "learning_rate": 1.4436818732337505e-05,
      "loss": 0.0171,
      "step": 13780
    },
    {
      "epoch": 5.567218409366169,
      "grad_norm": 0.025356804952025414,
      "learning_rate": 1.4432781590633833e-05,
      "loss": 0.0418,
      "step": 13790
    },
    {
      "epoch": 5.571255551069843,
      "grad_norm": 0.004650048445910215,
      "learning_rate": 1.4428744448930159e-05,
      "loss": 0.074,
      "step": 13800
    },
    {
      "epoch": 5.575292692773516,
      "grad_norm": 0.051830071955919266,
      "learning_rate": 1.4424707307226484e-05,
      "loss": 0.0053,
      "step": 13810
    },
    {
      "epoch": 5.57932983447719,
      "grad_norm": 0.0028096367605030537,
      "learning_rate": 1.4420670165522812e-05,
      "loss": 0.0225,
      "step": 13820
    },
    {
      "epoch": 5.583366976180864,
      "grad_norm": 1.3046414852142334,
      "learning_rate": 1.4416633023819138e-05,
      "loss": 0.0098,
      "step": 13830
    },
    {
      "epoch": 5.587404117884538,
      "grad_norm": 0.021256471052765846,
      "learning_rate": 1.4412595882115462e-05,
      "loss": 0.0434,
      "step": 13840
    },
    {
      "epoch": 5.591441259588212,
      "grad_norm": 0.007954280823469162,
      "learning_rate": 1.4408558740411789e-05,
      "loss": 0.0516,
      "step": 13850
    },
    {
      "epoch": 5.595478401291885,
      "grad_norm": 0.028219079598784447,
      "learning_rate": 1.4404521598708117e-05,
      "loss": 0.0094,
      "step": 13860
    },
    {
      "epoch": 5.599515542995559,
      "grad_norm": 2.4951999187469482,
      "learning_rate": 1.4400484457004443e-05,
      "loss": 0.099,
      "step": 13870
    },
    {
      "epoch": 5.603552684699233,
      "grad_norm": 1.6501437425613403,
      "learning_rate": 1.4396447315300768e-05,
      "loss": 0.0286,
      "step": 13880
    },
    {
      "epoch": 5.607589826402907,
      "grad_norm": 0.30938151478767395,
      "learning_rate": 1.4392410173597094e-05,
      "loss": 0.0065,
      "step": 13890
    },
    {
      "epoch": 5.611626968106581,
      "grad_norm": 0.025517884641885757,
      "learning_rate": 1.4388373031893422e-05,
      "loss": 0.009,
      "step": 13900
    },
    {
      "epoch": 5.615664109810254,
      "grad_norm": 0.023612484335899353,
      "learning_rate": 1.4384335890189746e-05,
      "loss": 0.0107,
      "step": 13910
    },
    {
      "epoch": 5.619701251513928,
      "grad_norm": 0.010810374282300472,
      "learning_rate": 1.4380298748486073e-05,
      "loss": 0.0307,
      "step": 13920
    },
    {
      "epoch": 5.623738393217602,
      "grad_norm": 4.3947296142578125,
      "learning_rate": 1.43762616067824e-05,
      "loss": 0.0453,
      "step": 13930
    },
    {
      "epoch": 5.627775534921276,
      "grad_norm": 0.0036384460981935263,
      "learning_rate": 1.4372224465078725e-05,
      "loss": 0.0069,
      "step": 13940
    },
    {
      "epoch": 5.63181267662495,
      "grad_norm": 1.576904058456421,
      "learning_rate": 1.4368187323375052e-05,
      "loss": 0.0109,
      "step": 13950
    },
    {
      "epoch": 5.635849818328623,
      "grad_norm": 0.006937023717910051,
      "learning_rate": 1.4364150181671376e-05,
      "loss": 0.0006,
      "step": 13960
    },
    {
      "epoch": 5.639886960032297,
      "grad_norm": 1.556617021560669,
      "learning_rate": 1.4360113039967704e-05,
      "loss": 0.047,
      "step": 13970
    },
    {
      "epoch": 5.643924101735971,
      "grad_norm": 5.465968608856201,
      "learning_rate": 1.435607589826403e-05,
      "loss": 0.0156,
      "step": 13980
    },
    {
      "epoch": 5.647961243439645,
      "grad_norm": 0.026691900566220284,
      "learning_rate": 1.4352038756560355e-05,
      "loss": 0.0055,
      "step": 13990
    },
    {
      "epoch": 5.651998385143319,
      "grad_norm": 0.006392612121999264,
      "learning_rate": 1.4348001614856683e-05,
      "loss": 0.0266,
      "step": 14000
    },
    {
      "epoch": 5.656035526846992,
      "grad_norm": 0.016179103404283524,
      "learning_rate": 1.434396447315301e-05,
      "loss": 0.0104,
      "step": 14010
    },
    {
      "epoch": 5.660072668550666,
      "grad_norm": 0.006972115486860275,
      "learning_rate": 1.4339927331449336e-05,
      "loss": 0.0053,
      "step": 14020
    },
    {
      "epoch": 5.66410981025434,
      "grad_norm": 3.79293155670166,
      "learning_rate": 1.433589018974566e-05,
      "loss": 0.0406,
      "step": 14030
    },
    {
      "epoch": 5.668146951958014,
      "grad_norm": 0.09722062200307846,
      "learning_rate": 1.4331853048041988e-05,
      "loss": 0.0184,
      "step": 14040
    },
    {
      "epoch": 5.672184093661688,
      "grad_norm": 0.010513808578252792,
      "learning_rate": 1.4327815906338314e-05,
      "loss": 0.0025,
      "step": 14050
    },
    {
      "epoch": 5.676221235365361,
      "grad_norm": 0.008068431168794632,
      "learning_rate": 1.4323778764634639e-05,
      "loss": 0.0084,
      "step": 14060
    },
    {
      "epoch": 5.680258377069035,
      "grad_norm": 0.013361417688429356,
      "learning_rate": 1.4319741622930967e-05,
      "loss": 0.0277,
      "step": 14070
    },
    {
      "epoch": 5.684295518772709,
      "grad_norm": 0.004553984850645065,
      "learning_rate": 1.4315704481227293e-05,
      "loss": 0.0301,
      "step": 14080
    },
    {
      "epoch": 5.688332660476383,
      "grad_norm": 1.2557041645050049,
      "learning_rate": 1.4311667339523618e-05,
      "loss": 0.0337,
      "step": 14090
    },
    {
      "epoch": 5.692369802180057,
      "grad_norm": 0.01671890914440155,
      "learning_rate": 1.4307630197819944e-05,
      "loss": 0.0015,
      "step": 14100
    },
    {
      "epoch": 5.69640694388373,
      "grad_norm": 0.012931687757372856,
      "learning_rate": 1.4303593056116272e-05,
      "loss": 0.0996,
      "step": 14110
    },
    {
      "epoch": 5.700444085587404,
      "grad_norm": 1.1531888246536255,
      "learning_rate": 1.4299555914412597e-05,
      "loss": 0.0508,
      "step": 14120
    },
    {
      "epoch": 5.704481227291078,
      "grad_norm": 1.9179320335388184,
      "learning_rate": 1.4295518772708923e-05,
      "loss": 0.0099,
      "step": 14130
    },
    {
      "epoch": 5.708518368994752,
      "grad_norm": 1.8616701364517212,
      "learning_rate": 1.4291481631005248e-05,
      "loss": 0.0325,
      "step": 14140
    },
    {
      "epoch": 5.712555510698426,
      "grad_norm": 0.9795293211936951,
      "learning_rate": 1.4287444489301576e-05,
      "loss": 0.0285,
      "step": 14150
    },
    {
      "epoch": 5.716592652402099,
      "grad_norm": 0.01713528297841549,
      "learning_rate": 1.4283407347597902e-05,
      "loss": 0.0576,
      "step": 14160
    },
    {
      "epoch": 5.720629794105773,
      "grad_norm": 1.3813281059265137,
      "learning_rate": 1.4279370205894228e-05,
      "loss": 0.006,
      "step": 14170
    },
    {
      "epoch": 5.724666935809447,
      "grad_norm": 2.1337742805480957,
      "learning_rate": 1.4275333064190554e-05,
      "loss": 0.0553,
      "step": 14180
    },
    {
      "epoch": 5.728704077513121,
      "grad_norm": 8.625452995300293,
      "learning_rate": 1.427129592248688e-05,
      "loss": 0.0353,
      "step": 14190
    },
    {
      "epoch": 5.732741219216795,
      "grad_norm": 0.0334942452609539,
      "learning_rate": 1.4267258780783207e-05,
      "loss": 0.0018,
      "step": 14200
    },
    {
      "epoch": 5.736778360920468,
      "grad_norm": 0.04057799279689789,
      "learning_rate": 1.4263221639079532e-05,
      "loss": 0.0324,
      "step": 14210
    },
    {
      "epoch": 5.740815502624142,
      "grad_norm": 0.014728977344930172,
      "learning_rate": 1.425918449737586e-05,
      "loss": 0.0356,
      "step": 14220
    },
    {
      "epoch": 5.744852644327816,
      "grad_norm": 1.2289878129959106,
      "learning_rate": 1.4255147355672186e-05,
      "loss": 0.0136,
      "step": 14230
    },
    {
      "epoch": 5.74888978603149,
      "grad_norm": 0.023040112107992172,
      "learning_rate": 1.425111021396851e-05,
      "loss": 0.0103,
      "step": 14240
    },
    {
      "epoch": 5.752926927735164,
      "grad_norm": 0.011904607526957989,
      "learning_rate": 1.4247073072264838e-05,
      "loss": 0.0228,
      "step": 14250
    },
    {
      "epoch": 5.756964069438837,
      "grad_norm": 0.004891425371170044,
      "learning_rate": 1.4243035930561165e-05,
      "loss": 0.077,
      "step": 14260
    },
    {
      "epoch": 5.761001211142511,
      "grad_norm": 0.03446507081389427,
      "learning_rate": 1.423899878885749e-05,
      "loss": 0.061,
      "step": 14270
    },
    {
      "epoch": 5.765038352846185,
      "grad_norm": 2.7130143642425537,
      "learning_rate": 1.4234961647153816e-05,
      "loss": 0.0334,
      "step": 14280
    },
    {
      "epoch": 5.769075494549859,
      "grad_norm": 2.4403111934661865,
      "learning_rate": 1.4230924505450144e-05,
      "loss": 0.0251,
      "step": 14290
    },
    {
      "epoch": 5.773112636253533,
      "grad_norm": 0.09964802861213684,
      "learning_rate": 1.4226887363746468e-05,
      "loss": 0.0354,
      "step": 14300
    },
    {
      "epoch": 5.777149777957206,
      "grad_norm": 5.100865364074707,
      "learning_rate": 1.4222850222042795e-05,
      "loss": 0.0252,
      "step": 14310
    },
    {
      "epoch": 5.78118691966088,
      "grad_norm": 0.04950755834579468,
      "learning_rate": 1.421881308033912e-05,
      "loss": 0.0303,
      "step": 14320
    },
    {
      "epoch": 5.785224061364554,
      "grad_norm": 0.0028632108587771654,
      "learning_rate": 1.4214775938635447e-05,
      "loss": 0.0138,
      "step": 14330
    },
    {
      "epoch": 5.789261203068228,
      "grad_norm": 0.032585397362709045,
      "learning_rate": 1.4210738796931773e-05,
      "loss": 0.0735,
      "step": 14340
    },
    {
      "epoch": 5.793298344771902,
      "grad_norm": 0.443453311920166,
      "learning_rate": 1.42067016552281e-05,
      "loss": 0.0175,
      "step": 14350
    },
    {
      "epoch": 5.797335486475575,
      "grad_norm": 1.7426326274871826,
      "learning_rate": 1.4202664513524426e-05,
      "loss": 0.0324,
      "step": 14360
    },
    {
      "epoch": 5.801372628179249,
      "grad_norm": 11.998184204101562,
      "learning_rate": 1.4198627371820752e-05,
      "loss": 0.0258,
      "step": 14370
    },
    {
      "epoch": 5.805409769882923,
      "grad_norm": 0.06248554587364197,
      "learning_rate": 1.4194590230117079e-05,
      "loss": 0.0177,
      "step": 14380
    },
    {
      "epoch": 5.809446911586597,
      "grad_norm": 2.1763525009155273,
      "learning_rate": 1.4190553088413403e-05,
      "loss": 0.0291,
      "step": 14390
    },
    {
      "epoch": 5.813484053290271,
      "grad_norm": 0.005511494353413582,
      "learning_rate": 1.4186515946709731e-05,
      "loss": 0.0486,
      "step": 14400
    },
    {
      "epoch": 5.817521194993944,
      "grad_norm": 7.643428802490234,
      "learning_rate": 1.4182478805006057e-05,
      "loss": 0.0288,
      "step": 14410
    },
    {
      "epoch": 5.821558336697618,
      "grad_norm": 0.019236836582422256,
      "learning_rate": 1.4178441663302382e-05,
      "loss": 0.0683,
      "step": 14420
    },
    {
      "epoch": 5.825595478401292,
      "grad_norm": 0.8062050342559814,
      "learning_rate": 1.417440452159871e-05,
      "loss": 0.0188,
      "step": 14430
    },
    {
      "epoch": 5.829632620104966,
      "grad_norm": 2.676542043685913,
      "learning_rate": 1.4170367379895036e-05,
      "loss": 0.0442,
      "step": 14440
    },
    {
      "epoch": 5.83366976180864,
      "grad_norm": 0.1702479124069214,
      "learning_rate": 1.416633023819136e-05,
      "loss": 0.0549,
      "step": 14450
    },
    {
      "epoch": 5.837706903512313,
      "grad_norm": 0.6762452125549316,
      "learning_rate": 1.4162293096487687e-05,
      "loss": 0.011,
      "step": 14460
    },
    {
      "epoch": 5.841744045215987,
      "grad_norm": 0.028019730001688004,
      "learning_rate": 1.4158255954784015e-05,
      "loss": 0.0204,
      "step": 14470
    },
    {
      "epoch": 5.845781186919661,
      "grad_norm": 0.0039242906495928764,
      "learning_rate": 1.415421881308034e-05,
      "loss": 0.0283,
      "step": 14480
    },
    {
      "epoch": 5.849818328623335,
      "grad_norm": 1.9594213962554932,
      "learning_rate": 1.4150181671376666e-05,
      "loss": 0.0126,
      "step": 14490
    },
    {
      "epoch": 5.853855470327009,
      "grad_norm": 1.1779789924621582,
      "learning_rate": 1.4146144529672994e-05,
      "loss": 0.0126,
      "step": 14500
    },
    {
      "epoch": 5.857892612030682,
      "grad_norm": 1.0963513851165771,
      "learning_rate": 1.4142107387969319e-05,
      "loss": 0.0057,
      "step": 14510
    },
    {
      "epoch": 5.861929753734356,
      "grad_norm": 0.001904542208649218,
      "learning_rate": 1.4138070246265645e-05,
      "loss": 0.0085,
      "step": 14520
    },
    {
      "epoch": 5.86596689543803,
      "grad_norm": 16.169952392578125,
      "learning_rate": 1.4134033104561971e-05,
      "loss": 0.0282,
      "step": 14530
    },
    {
      "epoch": 5.870004037141704,
      "grad_norm": 0.0032940746750682592,
      "learning_rate": 1.4129995962858299e-05,
      "loss": 0.0409,
      "step": 14540
    },
    {
      "epoch": 5.874041178845378,
      "grad_norm": 0.005674376152455807,
      "learning_rate": 1.4125958821154624e-05,
      "loss": 0.0525,
      "step": 14550
    },
    {
      "epoch": 5.878078320549051,
      "grad_norm": 1.76104736328125,
      "learning_rate": 1.412192167945095e-05,
      "loss": 0.0503,
      "step": 14560
    },
    {
      "epoch": 5.882115462252725,
      "grad_norm": 3.1134862899780273,
      "learning_rate": 1.4117884537747275e-05,
      "loss": 0.0246,
      "step": 14570
    },
    {
      "epoch": 5.886152603956399,
      "grad_norm": 0.009564788080751896,
      "learning_rate": 1.4113847396043603e-05,
      "loss": 0.0524,
      "step": 14580
    },
    {
      "epoch": 5.890189745660073,
      "grad_norm": 4.406320571899414,
      "learning_rate": 1.4109810254339929e-05,
      "loss": 0.0176,
      "step": 14590
    },
    {
      "epoch": 5.894226887363747,
      "grad_norm": 1.3639851808547974,
      "learning_rate": 1.4105773112636253e-05,
      "loss": 0.0189,
      "step": 14600
    },
    {
      "epoch": 5.898264029067421,
      "grad_norm": 0.4457392394542694,
      "learning_rate": 1.4101735970932581e-05,
      "loss": 0.0249,
      "step": 14610
    },
    {
      "epoch": 5.902301170771094,
      "grad_norm": 0.005719542969018221,
      "learning_rate": 1.4097698829228908e-05,
      "loss": 0.0339,
      "step": 14620
    },
    {
      "epoch": 5.906338312474768,
      "grad_norm": 0.12616707384586334,
      "learning_rate": 1.4093661687525232e-05,
      "loss": 0.0371,
      "step": 14630
    },
    {
      "epoch": 5.910375454178442,
      "grad_norm": 0.04464001581072807,
      "learning_rate": 1.4089624545821559e-05,
      "loss": 0.0227,
      "step": 14640
    },
    {
      "epoch": 5.914412595882116,
      "grad_norm": 0.07656005769968033,
      "learning_rate": 1.4085587404117887e-05,
      "loss": 0.0131,
      "step": 14650
    },
    {
      "epoch": 5.91844973758579,
      "grad_norm": 1.832169532775879,
      "learning_rate": 1.4081550262414211e-05,
      "loss": 0.01,
      "step": 14660
    },
    {
      "epoch": 5.922486879289463,
      "grad_norm": 6.246830463409424,
      "learning_rate": 1.4077513120710537e-05,
      "loss": 0.0722,
      "step": 14670
    },
    {
      "epoch": 5.926524020993137,
      "grad_norm": 0.5683432817459106,
      "learning_rate": 1.4073475979006865e-05,
      "loss": 0.0063,
      "step": 14680
    },
    {
      "epoch": 5.930561162696811,
      "grad_norm": 0.0203365720808506,
      "learning_rate": 1.4069438837303192e-05,
      "loss": 0.013,
      "step": 14690
    },
    {
      "epoch": 5.934598304400485,
      "grad_norm": 2.2679367065429688,
      "learning_rate": 1.4065401695599516e-05,
      "loss": 0.0494,
      "step": 14700
    },
    {
      "epoch": 5.938635446104159,
      "grad_norm": 3.3018054962158203,
      "learning_rate": 1.4061364553895843e-05,
      "loss": 0.0575,
      "step": 14710
    },
    {
      "epoch": 5.942672587807832,
      "grad_norm": 0.018845055252313614,
      "learning_rate": 1.405732741219217e-05,
      "loss": 0.0179,
      "step": 14720
    },
    {
      "epoch": 5.946709729511506,
      "grad_norm": 0.016323387622833252,
      "learning_rate": 1.4053290270488495e-05,
      "loss": 0.0426,
      "step": 14730
    },
    {
      "epoch": 5.95074687121518,
      "grad_norm": 0.05272609740495682,
      "learning_rate": 1.4049253128784821e-05,
      "loss": 0.0286,
      "step": 14740
    },
    {
      "epoch": 5.954784012918854,
      "grad_norm": 0.014657439664006233,
      "learning_rate": 1.4045215987081146e-05,
      "loss": 0.0271,
      "step": 14750
    },
    {
      "epoch": 5.958821154622528,
      "grad_norm": 0.009232938289642334,
      "learning_rate": 1.4041178845377474e-05,
      "loss": 0.0228,
      "step": 14760
    },
    {
      "epoch": 5.962858296326201,
      "grad_norm": 0.24664022028446198,
      "learning_rate": 1.40371417036738e-05,
      "loss": 0.03,
      "step": 14770
    },
    {
      "epoch": 5.966895438029875,
      "grad_norm": 0.15975727140903473,
      "learning_rate": 1.4033104561970125e-05,
      "loss": 0.0034,
      "step": 14780
    },
    {
      "epoch": 5.970932579733549,
      "grad_norm": 0.019701724871993065,
      "learning_rate": 1.4029067420266453e-05,
      "loss": 0.0721,
      "step": 14790
    },
    {
      "epoch": 5.974969721437223,
      "grad_norm": 0.006722267251461744,
      "learning_rate": 1.402503027856278e-05,
      "loss": 0.0446,
      "step": 14800
    },
    {
      "epoch": 5.979006863140897,
      "grad_norm": 3.510153293609619,
      "learning_rate": 1.4020993136859104e-05,
      "loss": 0.0224,
      "step": 14810
    },
    {
      "epoch": 5.98304400484457,
      "grad_norm": 22.149614334106445,
      "learning_rate": 1.401695599515543e-05,
      "loss": 0.0246,
      "step": 14820
    },
    {
      "epoch": 5.987081146548244,
      "grad_norm": 0.021258356049656868,
      "learning_rate": 1.4012918853451758e-05,
      "loss": 0.0201,
      "step": 14830
    },
    {
      "epoch": 5.991118288251918,
      "grad_norm": 0.003251096000894904,
      "learning_rate": 1.4008881711748084e-05,
      "loss": 0.0017,
      "step": 14840
    },
    {
      "epoch": 5.995155429955592,
      "grad_norm": 0.0026244274340569973,
      "learning_rate": 1.4004844570044409e-05,
      "loss": 0.0307,
      "step": 14850
    },
    {
      "epoch": 5.999192571659266,
      "grad_norm": 8.41354751586914,
      "learning_rate": 1.4000807428340737e-05,
      "loss": 0.038,
      "step": 14860
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.984748427672956,
      "eval_f1": 0.9441244239631337,
      "eval_loss": 0.06938108056783676,
      "eval_precision": 0.9463048498845266,
      "eval_recall": 0.9419540229885057,
      "eval_runtime": 444.4595,
      "eval_samples_per_second": 28.664,
      "eval_steps_per_second": 1.195,
      "step": 14862
    },
    {
      "epoch": 6.003229713362939,
      "grad_norm": 1.2547845840454102,
      "learning_rate": 1.3996770286637063e-05,
      "loss": 0.0148,
      "step": 14870
    },
    {
      "epoch": 6.007266855066613,
      "grad_norm": 0.006000495050102472,
      "learning_rate": 1.3992733144933388e-05,
      "loss": 0.0228,
      "step": 14880
    },
    {
      "epoch": 6.011303996770287,
      "grad_norm": 0.002794362837448716,
      "learning_rate": 1.3988696003229714e-05,
      "loss": 0.0023,
      "step": 14890
    },
    {
      "epoch": 6.015341138473961,
      "grad_norm": 5.699621200561523,
      "learning_rate": 1.3984658861526042e-05,
      "loss": 0.0372,
      "step": 14900
    },
    {
      "epoch": 6.0193782801776345,
      "grad_norm": 0.005647691898047924,
      "learning_rate": 1.3980621719822367e-05,
      "loss": 0.0285,
      "step": 14910
    },
    {
      "epoch": 6.023415421881308,
      "grad_norm": 0.021697351709008217,
      "learning_rate": 1.3976584578118693e-05,
      "loss": 0.0276,
      "step": 14920
    },
    {
      "epoch": 6.027452563584982,
      "grad_norm": 0.05338409170508385,
      "learning_rate": 1.3972547436415018e-05,
      "loss": 0.0168,
      "step": 14930
    },
    {
      "epoch": 6.031489705288656,
      "grad_norm": 0.019048096612095833,
      "learning_rate": 1.3968510294711346e-05,
      "loss": 0.027,
      "step": 14940
    },
    {
      "epoch": 6.0355268469923296,
      "grad_norm": 0.14519041776657104,
      "learning_rate": 1.3964473153007672e-05,
      "loss": 0.0628,
      "step": 14950
    },
    {
      "epoch": 6.0395639886960035,
      "grad_norm": 0.08835817873477936,
      "learning_rate": 1.3960436011303996e-05,
      "loss": 0.0262,
      "step": 14960
    },
    {
      "epoch": 6.043601130399677,
      "grad_norm": 1.5869269371032715,
      "learning_rate": 1.3956398869600324e-05,
      "loss": 0.0521,
      "step": 14970
    },
    {
      "epoch": 6.047638272103351,
      "grad_norm": 0.011712095700204372,
      "learning_rate": 1.395236172789665e-05,
      "loss": 0.0601,
      "step": 14980
    },
    {
      "epoch": 6.051675413807025,
      "grad_norm": 53.42415237426758,
      "learning_rate": 1.3948324586192977e-05,
      "loss": 0.0392,
      "step": 14990
    },
    {
      "epoch": 6.0557125555106985,
      "grad_norm": 0.1346222460269928,
      "learning_rate": 1.3944287444489302e-05,
      "loss": 0.0252,
      "step": 15000
    },
    {
      "epoch": 6.0597496972143725,
      "grad_norm": 1.3799139261245728,
      "learning_rate": 1.394025030278563e-05,
      "loss": 0.0237,
      "step": 15010
    },
    {
      "epoch": 6.063786838918046,
      "grad_norm": 0.005472371820360422,
      "learning_rate": 1.3936213161081956e-05,
      "loss": 0.0175,
      "step": 15020
    },
    {
      "epoch": 6.06782398062172,
      "grad_norm": 0.019434379413723946,
      "learning_rate": 1.393217601937828e-05,
      "loss": 0.0129,
      "step": 15030
    },
    {
      "epoch": 6.0718611223253935,
      "grad_norm": 0.0010915165767073631,
      "learning_rate": 1.3928138877674608e-05,
      "loss": 0.0155,
      "step": 15040
    },
    {
      "epoch": 6.0758982640290675,
      "grad_norm": 0.0007957094931043684,
      "learning_rate": 1.3924101735970935e-05,
      "loss": 0.0059,
      "step": 15050
    },
    {
      "epoch": 6.0799354057327415,
      "grad_norm": 0.01225192379206419,
      "learning_rate": 1.392006459426726e-05,
      "loss": 0.01,
      "step": 15060
    },
    {
      "epoch": 6.0839725474364155,
      "grad_norm": 0.001422487897798419,
      "learning_rate": 1.3916027452563586e-05,
      "loss": 0.009,
      "step": 15070
    },
    {
      "epoch": 6.0880096891400886,
      "grad_norm": 0.00937864650040865,
      "learning_rate": 1.3911990310859914e-05,
      "loss": 0.013,
      "step": 15080
    },
    {
      "epoch": 6.0920468308437625,
      "grad_norm": 0.10022059082984924,
      "learning_rate": 1.3907953169156238e-05,
      "loss": 0.0372,
      "step": 15090
    },
    {
      "epoch": 6.0960839725474365,
      "grad_norm": 1.8332749605178833,
      "learning_rate": 1.3903916027452564e-05,
      "loss": 0.004,
      "step": 15100
    },
    {
      "epoch": 6.1001211142511105,
      "grad_norm": 7.3408284187316895,
      "learning_rate": 1.3899878885748892e-05,
      "loss": 0.0238,
      "step": 15110
    },
    {
      "epoch": 6.1041582559547845,
      "grad_norm": 0.0017042307881638408,
      "learning_rate": 1.3895841744045217e-05,
      "loss": 0.0289,
      "step": 15120
    },
    {
      "epoch": 6.1081953976584575,
      "grad_norm": 1.9856070280075073,
      "learning_rate": 1.3891804602341543e-05,
      "loss": 0.0136,
      "step": 15130
    },
    {
      "epoch": 6.1122325393621315,
      "grad_norm": 0.24436596035957336,
      "learning_rate": 1.388776746063787e-05,
      "loss": 0.0126,
      "step": 15140
    },
    {
      "epoch": 6.1162696810658055,
      "grad_norm": 0.0029260895680636168,
      "learning_rate": 1.3883730318934196e-05,
      "loss": 0.0271,
      "step": 15150
    },
    {
      "epoch": 6.1203068227694795,
      "grad_norm": 0.00335808377712965,
      "learning_rate": 1.3879693177230522e-05,
      "loss": 0.0241,
      "step": 15160
    },
    {
      "epoch": 6.124343964473153,
      "grad_norm": 2.0995466709136963,
      "learning_rate": 1.3875656035526848e-05,
      "loss": 0.0383,
      "step": 15170
    },
    {
      "epoch": 6.1283811061768265,
      "grad_norm": 4.732878684997559,
      "learning_rate": 1.3871618893823173e-05,
      "loss": 0.0189,
      "step": 15180
    },
    {
      "epoch": 6.1324182478805005,
      "grad_norm": 0.008201743476092815,
      "learning_rate": 1.3867581752119501e-05,
      "loss": 0.0264,
      "step": 15190
    },
    {
      "epoch": 6.1364553895841745,
      "grad_norm": 0.0034108527470380068,
      "learning_rate": 1.3863544610415827e-05,
      "loss": 0.0157,
      "step": 15200
    },
    {
      "epoch": 6.140492531287848,
      "grad_norm": 0.0032850310672074556,
      "learning_rate": 1.3859507468712152e-05,
      "loss": 0.0299,
      "step": 15210
    },
    {
      "epoch": 6.144529672991522,
      "grad_norm": 0.011296057142317295,
      "learning_rate": 1.385547032700848e-05,
      "loss": 0.0244,
      "step": 15220
    },
    {
      "epoch": 6.1485668146951955,
      "grad_norm": 0.8524380326271057,
      "learning_rate": 1.3851433185304806e-05,
      "loss": 0.0347,
      "step": 15230
    },
    {
      "epoch": 6.1526039563988695,
      "grad_norm": 0.005915680900216103,
      "learning_rate": 1.384739604360113e-05,
      "loss": 0.0106,
      "step": 15240
    },
    {
      "epoch": 6.1566410981025435,
      "grad_norm": 1.9662816524505615,
      "learning_rate": 1.3843358901897457e-05,
      "loss": 0.0232,
      "step": 15250
    },
    {
      "epoch": 6.160678239806217,
      "grad_norm": 0.8849234580993652,
      "learning_rate": 1.3839321760193785e-05,
      "loss": 0.008,
      "step": 15260
    },
    {
      "epoch": 6.164715381509891,
      "grad_norm": 0.023721298202872276,
      "learning_rate": 1.383528461849011e-05,
      "loss": 0.0075,
      "step": 15270
    },
    {
      "epoch": 6.1687525232135645,
      "grad_norm": 0.0012850828934460878,
      "learning_rate": 1.3831247476786436e-05,
      "loss": 0.0029,
      "step": 15280
    },
    {
      "epoch": 6.1727896649172385,
      "grad_norm": 0.017458844929933548,
      "learning_rate": 1.3827210335082764e-05,
      "loss": 0.0179,
      "step": 15290
    },
    {
      "epoch": 6.176826806620912,
      "grad_norm": 0.021027425304055214,
      "learning_rate": 1.3823173193379088e-05,
      "loss": 0.0141,
      "step": 15300
    },
    {
      "epoch": 6.180863948324586,
      "grad_norm": 0.00297558237798512,
      "learning_rate": 1.3819136051675415e-05,
      "loss": 0.0011,
      "step": 15310
    },
    {
      "epoch": 6.18490109002826,
      "grad_norm": 0.00899045541882515,
      "learning_rate": 1.3815098909971741e-05,
      "loss": 0.072,
      "step": 15320
    },
    {
      "epoch": 6.1889382317319335,
      "grad_norm": 2.205212116241455,
      "learning_rate": 1.3811061768268067e-05,
      "loss": 0.0242,
      "step": 15330
    },
    {
      "epoch": 6.1929753734356074,
      "grad_norm": 0.11149720847606659,
      "learning_rate": 1.3807024626564394e-05,
      "loss": 0.014,
      "step": 15340
    },
    {
      "epoch": 6.197012515139281,
      "grad_norm": 0.0037594176828861237,
      "learning_rate": 1.380298748486072e-05,
      "loss": 0.0249,
      "step": 15350
    },
    {
      "epoch": 6.201049656842955,
      "grad_norm": 0.18632099032402039,
      "learning_rate": 1.3798950343157044e-05,
      "loss": 0.0004,
      "step": 15360
    },
    {
      "epoch": 6.205086798546629,
      "grad_norm": 1.22878098487854,
      "learning_rate": 1.3794913201453372e-05,
      "loss": 0.0282,
      "step": 15370
    },
    {
      "epoch": 6.2091239402503025,
      "grad_norm": 1.3809008598327637,
      "learning_rate": 1.3790876059749699e-05,
      "loss": 0.0138,
      "step": 15380
    },
    {
      "epoch": 6.213161081953976,
      "grad_norm": 0.0021862878929823637,
      "learning_rate": 1.3786838918046023e-05,
      "loss": 0.0441,
      "step": 15390
    },
    {
      "epoch": 6.21719822365765,
      "grad_norm": 0.003126820782199502,
      "learning_rate": 1.3782801776342351e-05,
      "loss": 0.0106,
      "step": 15400
    },
    {
      "epoch": 6.221235365361324,
      "grad_norm": 0.004099571146070957,
      "learning_rate": 1.3778764634638678e-05,
      "loss": 0.0044,
      "step": 15410
    },
    {
      "epoch": 6.225272507064998,
      "grad_norm": 0.008603050373494625,
      "learning_rate": 1.3774727492935002e-05,
      "loss": 0.0066,
      "step": 15420
    },
    {
      "epoch": 6.229309648768671,
      "grad_norm": 1.4109807014465332,
      "learning_rate": 1.3770690351231328e-05,
      "loss": 0.0297,
      "step": 15430
    },
    {
      "epoch": 6.233346790472345,
      "grad_norm": 2.5915229320526123,
      "learning_rate": 1.3766653209527656e-05,
      "loss": 0.0154,
      "step": 15440
    },
    {
      "epoch": 6.237383932176019,
      "grad_norm": 0.03912912309169769,
      "learning_rate": 1.3762616067823981e-05,
      "loss": 0.0294,
      "step": 15450
    },
    {
      "epoch": 6.241421073879693,
      "grad_norm": 0.9524598717689514,
      "learning_rate": 1.3758578926120307e-05,
      "loss": 0.0169,
      "step": 15460
    },
    {
      "epoch": 6.245458215583367,
      "grad_norm": 0.004827337805181742,
      "learning_rate": 1.3754541784416635e-05,
      "loss": 0.0207,
      "step": 15470
    },
    {
      "epoch": 6.24949535728704,
      "grad_norm": 1.9952540397644043,
      "learning_rate": 1.375050464271296e-05,
      "loss": 0.0326,
      "step": 15480
    },
    {
      "epoch": 6.253532498990714,
      "grad_norm": 0.001544903963804245,
      "learning_rate": 1.3746467501009286e-05,
      "loss": 0.0051,
      "step": 15490
    },
    {
      "epoch": 6.257569640694388,
      "grad_norm": 4.881040573120117,
      "learning_rate": 1.3742430359305612e-05,
      "loss": 0.0114,
      "step": 15500
    },
    {
      "epoch": 6.261606782398062,
      "grad_norm": 1.6898560523986816,
      "learning_rate": 1.373839321760194e-05,
      "loss": 0.0052,
      "step": 15510
    },
    {
      "epoch": 6.265643924101736,
      "grad_norm": 0.00896307360380888,
      "learning_rate": 1.3734356075898265e-05,
      "loss": 0.0253,
      "step": 15520
    },
    {
      "epoch": 6.269681065805409,
      "grad_norm": 2.948629856109619,
      "learning_rate": 1.3730318934194591e-05,
      "loss": 0.0231,
      "step": 15530
    },
    {
      "epoch": 6.273718207509083,
      "grad_norm": 0.3126041293144226,
      "learning_rate": 1.372628179249092e-05,
      "loss": 0.0106,
      "step": 15540
    },
    {
      "epoch": 6.277755349212757,
      "grad_norm": 0.022566890344023705,
      "learning_rate": 1.3722244650787244e-05,
      "loss": 0.0153,
      "step": 15550
    },
    {
      "epoch": 6.281792490916431,
      "grad_norm": 1.2510544061660767,
      "learning_rate": 1.371820750908357e-05,
      "loss": 0.0245,
      "step": 15560
    },
    {
      "epoch": 6.285829632620105,
      "grad_norm": 2.5472350120544434,
      "learning_rate": 1.3714170367379895e-05,
      "loss": 0.0571,
      "step": 15570
    },
    {
      "epoch": 6.289866774323778,
      "grad_norm": 0.2752322852611542,
      "learning_rate": 1.3710133225676223e-05,
      "loss": 0.0191,
      "step": 15580
    },
    {
      "epoch": 6.293903916027452,
      "grad_norm": 0.010741696693003178,
      "learning_rate": 1.3706096083972549e-05,
      "loss": 0.0295,
      "step": 15590
    },
    {
      "epoch": 6.297941057731126,
      "grad_norm": 0.010453772731125355,
      "learning_rate": 1.3702058942268874e-05,
      "loss": 0.0841,
      "step": 15600
    },
    {
      "epoch": 6.3019781994348,
      "grad_norm": 0.00213355990126729,
      "learning_rate": 1.36980218005652e-05,
      "loss": 0.0303,
      "step": 15610
    },
    {
      "epoch": 6.306015341138474,
      "grad_norm": 1.2919366359710693,
      "learning_rate": 1.3693984658861528e-05,
      "loss": 0.0149,
      "step": 15620
    },
    {
      "epoch": 6.310052482842147,
      "grad_norm": 1.8290058374404907,
      "learning_rate": 1.3689947517157853e-05,
      "loss": 0.014,
      "step": 15630
    },
    {
      "epoch": 6.314089624545821,
      "grad_norm": 0.016764730215072632,
      "learning_rate": 1.3685910375454179e-05,
      "loss": 0.0264,
      "step": 15640
    },
    {
      "epoch": 6.318126766249495,
      "grad_norm": 0.4425203204154968,
      "learning_rate": 1.3681873233750507e-05,
      "loss": 0.0197,
      "step": 15650
    },
    {
      "epoch": 6.322163907953169,
      "grad_norm": 0.04600485786795616,
      "learning_rate": 1.3677836092046833e-05,
      "loss": 0.0161,
      "step": 15660
    },
    {
      "epoch": 6.326201049656843,
      "grad_norm": 0.00314133008942008,
      "learning_rate": 1.3673798950343158e-05,
      "loss": 0.0241,
      "step": 15670
    },
    {
      "epoch": 6.330238191360516,
      "grad_norm": 0.009100881405174732,
      "learning_rate": 1.3669761808639484e-05,
      "loss": 0.0079,
      "step": 15680
    },
    {
      "epoch": 6.33427533306419,
      "grad_norm": 0.013083573430776596,
      "learning_rate": 1.3665724666935812e-05,
      "loss": 0.0012,
      "step": 15690
    },
    {
      "epoch": 6.338312474767864,
      "grad_norm": 1.7457879781723022,
      "learning_rate": 1.3661687525232137e-05,
      "loss": 0.0439,
      "step": 15700
    },
    {
      "epoch": 6.342349616471538,
      "grad_norm": 0.057333942502737045,
      "learning_rate": 1.3657650383528463e-05,
      "loss": 0.051,
      "step": 15710
    },
    {
      "epoch": 6.346386758175212,
      "grad_norm": 0.010096182115375996,
      "learning_rate": 1.365361324182479e-05,
      "loss": 0.0015,
      "step": 15720
    },
    {
      "epoch": 6.350423899878885,
      "grad_norm": 5.193143844604492,
      "learning_rate": 1.3649576100121115e-05,
      "loss": 0.0241,
      "step": 15730
    },
    {
      "epoch": 6.354461041582559,
      "grad_norm": 2.1228268146514893,
      "learning_rate": 1.3645538958417442e-05,
      "loss": 0.0158,
      "step": 15740
    },
    {
      "epoch": 6.358498183286233,
      "grad_norm": 1.6664048433303833,
      "learning_rate": 1.3641501816713766e-05,
      "loss": 0.0472,
      "step": 15750
    },
    {
      "epoch": 6.362535324989907,
      "grad_norm": 2.1701042652130127,
      "learning_rate": 1.3637464675010094e-05,
      "loss": 0.0414,
      "step": 15760
    },
    {
      "epoch": 6.366572466693581,
      "grad_norm": 0.0065180533565580845,
      "learning_rate": 1.363342753330642e-05,
      "loss": 0.0031,
      "step": 15770
    },
    {
      "epoch": 6.370609608397254,
      "grad_norm": 0.00711164390668273,
      "learning_rate": 1.3629390391602745e-05,
      "loss": 0.0274,
      "step": 15780
    },
    {
      "epoch": 6.374646750100928,
      "grad_norm": 0.009743612259626389,
      "learning_rate": 1.3625353249899071e-05,
      "loss": 0.0802,
      "step": 15790
    },
    {
      "epoch": 6.378683891804602,
      "grad_norm": 0.28498178720474243,
      "learning_rate": 1.36213161081954e-05,
      "loss": 0.0126,
      "step": 15800
    },
    {
      "epoch": 6.382721033508276,
      "grad_norm": 4.8809123039245605,
      "learning_rate": 1.3617278966491726e-05,
      "loss": 0.0268,
      "step": 15810
    },
    {
      "epoch": 6.38675817521195,
      "grad_norm": 4.31362247467041,
      "learning_rate": 1.361324182478805e-05,
      "loss": 0.0692,
      "step": 15820
    },
    {
      "epoch": 6.390795316915623,
      "grad_norm": 0.024119727313518524,
      "learning_rate": 1.3609204683084378e-05,
      "loss": 0.0206,
      "step": 15830
    },
    {
      "epoch": 6.394832458619297,
      "grad_norm": 0.885774552822113,
      "learning_rate": 1.3605167541380705e-05,
      "loss": 0.0132,
      "step": 15840
    },
    {
      "epoch": 6.398869600322971,
      "grad_norm": 0.026187263429164886,
      "learning_rate": 1.3601130399677029e-05,
      "loss": 0.0554,
      "step": 15850
    },
    {
      "epoch": 6.402906742026645,
      "grad_norm": 0.005379066802561283,
      "learning_rate": 1.3597093257973355e-05,
      "loss": 0.0076,
      "step": 15860
    },
    {
      "epoch": 6.406943883730319,
      "grad_norm": 1.510742425918579,
      "learning_rate": 1.3593056116269683e-05,
      "loss": 0.0143,
      "step": 15870
    },
    {
      "epoch": 6.410981025433992,
      "grad_norm": 0.012790024280548096,
      "learning_rate": 1.3589018974566008e-05,
      "loss": 0.0159,
      "step": 15880
    },
    {
      "epoch": 6.415018167137666,
      "grad_norm": 0.8505412340164185,
      "learning_rate": 1.3584981832862334e-05,
      "loss": 0.0131,
      "step": 15890
    },
    {
      "epoch": 6.41905530884134,
      "grad_norm": 0.07175733894109726,
      "learning_rate": 1.3580944691158662e-05,
      "loss": 0.0565,
      "step": 15900
    },
    {
      "epoch": 6.423092450545014,
      "grad_norm": 0.004318682476878166,
      "learning_rate": 1.3576907549454987e-05,
      "loss": 0.0358,
      "step": 15910
    },
    {
      "epoch": 6.427129592248688,
      "grad_norm": 0.8422093391418457,
      "learning_rate": 1.3572870407751313e-05,
      "loss": 0.009,
      "step": 15920
    },
    {
      "epoch": 6.431166733952361,
      "grad_norm": 0.019004760310053825,
      "learning_rate": 1.3568833266047638e-05,
      "loss": 0.0052,
      "step": 15930
    },
    {
      "epoch": 6.435203875656035,
      "grad_norm": 5.187372207641602,
      "learning_rate": 1.3564796124343966e-05,
      "loss": 0.0571,
      "step": 15940
    },
    {
      "epoch": 6.439241017359709,
      "grad_norm": 1.125538945198059,
      "learning_rate": 1.3560758982640292e-05,
      "loss": 0.0086,
      "step": 15950
    },
    {
      "epoch": 6.443278159063383,
      "grad_norm": 0.025593556463718414,
      "learning_rate": 1.3556721840936618e-05,
      "loss": 0.0041,
      "step": 15960
    },
    {
      "epoch": 6.447315300767057,
      "grad_norm": 2.279172897338867,
      "learning_rate": 1.3552684699232945e-05,
      "loss": 0.0142,
      "step": 15970
    },
    {
      "epoch": 6.45135244247073,
      "grad_norm": 1.3208550214767456,
      "learning_rate": 1.3548647557529271e-05,
      "loss": 0.0171,
      "step": 15980
    },
    {
      "epoch": 6.455389584174404,
      "grad_norm": 0.002084691310301423,
      "learning_rate": 1.3544610415825597e-05,
      "loss": 0.0341,
      "step": 15990
    },
    {
      "epoch": 6.459426725878078,
      "grad_norm": 0.05772584676742554,
      "learning_rate": 1.3540573274121922e-05,
      "loss": 0.055,
      "step": 16000
    },
    {
      "epoch": 6.463463867581752,
      "grad_norm": 2.0312249660491943,
      "learning_rate": 1.353653613241825e-05,
      "loss": 0.0416,
      "step": 16010
    },
    {
      "epoch": 6.467501009285426,
      "grad_norm": 0.008894531056284904,
      "learning_rate": 1.3532498990714576e-05,
      "loss": 0.0108,
      "step": 16020
    },
    {
      "epoch": 6.4715381509891,
      "grad_norm": 0.006393628194928169,
      "learning_rate": 1.35284618490109e-05,
      "loss": 0.007,
      "step": 16030
    },
    {
      "epoch": 6.475575292692773,
      "grad_norm": 0.011288066394627094,
      "learning_rate": 1.3524424707307227e-05,
      "loss": 0.0096,
      "step": 16040
    },
    {
      "epoch": 6.479612434396447,
      "grad_norm": 0.34888210892677307,
      "learning_rate": 1.3520387565603555e-05,
      "loss": 0.042,
      "step": 16050
    },
    {
      "epoch": 6.483649576100121,
      "grad_norm": 0.006488170940428972,
      "learning_rate": 1.351635042389988e-05,
      "loss": 0.0065,
      "step": 16060
    },
    {
      "epoch": 6.487686717803795,
      "grad_norm": 0.0015653802547603846,
      "learning_rate": 1.3512313282196206e-05,
      "loss": 0.0036,
      "step": 16070
    },
    {
      "epoch": 6.491723859507469,
      "grad_norm": 0.00972586777061224,
      "learning_rate": 1.3508276140492534e-05,
      "loss": 0.0435,
      "step": 16080
    },
    {
      "epoch": 6.495761001211142,
      "grad_norm": 0.9688485264778137,
      "learning_rate": 1.3504238998788858e-05,
      "loss": 0.0433,
      "step": 16090
    },
    {
      "epoch": 6.499798142914816,
      "grad_norm": 3.686194658279419,
      "learning_rate": 1.3500201857085185e-05,
      "loss": 0.0446,
      "step": 16100
    },
    {
      "epoch": 6.50383528461849,
      "grad_norm": 0.001507375156506896,
      "learning_rate": 1.3496164715381511e-05,
      "loss": 0.0533,
      "step": 16110
    },
    {
      "epoch": 6.507872426322164,
      "grad_norm": 0.016233602538704872,
      "learning_rate": 1.3492127573677837e-05,
      "loss": 0.0112,
      "step": 16120
    },
    {
      "epoch": 6.511909568025838,
      "grad_norm": 0.025075336918234825,
      "learning_rate": 1.3488090431974163e-05,
      "loss": 0.0193,
      "step": 16130
    },
    {
      "epoch": 6.515946709729511,
      "grad_norm": 1.9922022819519043,
      "learning_rate": 1.348405329027049e-05,
      "loss": 0.0104,
      "step": 16140
    },
    {
      "epoch": 6.519983851433185,
      "grad_norm": 1.4152299165725708,
      "learning_rate": 1.3480016148566816e-05,
      "loss": 0.0317,
      "step": 16150
    },
    {
      "epoch": 6.524020993136859,
      "grad_norm": 0.01041888352483511,
      "learning_rate": 1.3475979006863142e-05,
      "loss": 0.036,
      "step": 16160
    },
    {
      "epoch": 6.528058134840533,
      "grad_norm": 0.028001466765999794,
      "learning_rate": 1.3471941865159469e-05,
      "loss": 0.0004,
      "step": 16170
    },
    {
      "epoch": 6.532095276544207,
      "grad_norm": 0.003379108151420951,
      "learning_rate": 1.3467904723455793e-05,
      "loss": 0.0028,
      "step": 16180
    },
    {
      "epoch": 6.53613241824788,
      "grad_norm": 0.246235191822052,
      "learning_rate": 1.3463867581752121e-05,
      "loss": 0.0177,
      "step": 16190
    },
    {
      "epoch": 6.540169559951554,
      "grad_norm": 0.02201874926686287,
      "learning_rate": 1.3459830440048447e-05,
      "loss": 0.0206,
      "step": 16200
    },
    {
      "epoch": 6.544206701655228,
      "grad_norm": 0.0035374583676457405,
      "learning_rate": 1.3455793298344772e-05,
      "loss": 0.0271,
      "step": 16210
    },
    {
      "epoch": 6.548243843358902,
      "grad_norm": 0.008201748132705688,
      "learning_rate": 1.3451756156641098e-05,
      "loss": 0.0016,
      "step": 16220
    },
    {
      "epoch": 6.552280985062576,
      "grad_norm": 2.5864953994750977,
      "learning_rate": 1.3447719014937426e-05,
      "loss": 0.0151,
      "step": 16230
    },
    {
      "epoch": 6.556318126766249,
      "grad_norm": 0.0027564219199121,
      "learning_rate": 1.3443681873233751e-05,
      "loss": 0.052,
      "step": 16240
    },
    {
      "epoch": 6.560355268469923,
      "grad_norm": 0.232549786567688,
      "learning_rate": 1.3439644731530077e-05,
      "loss": 0.0069,
      "step": 16250
    },
    {
      "epoch": 6.564392410173597,
      "grad_norm": 0.004035620018839836,
      "learning_rate": 1.3435607589826405e-05,
      "loss": 0.0402,
      "step": 16260
    },
    {
      "epoch": 6.568429551877271,
      "grad_norm": 0.0040439129807055,
      "learning_rate": 1.343157044812273e-05,
      "loss": 0.0483,
      "step": 16270
    },
    {
      "epoch": 6.572466693580945,
      "grad_norm": 0.014924498274922371,
      "learning_rate": 1.3427533306419056e-05,
      "loss": 0.0424,
      "step": 16280
    },
    {
      "epoch": 6.576503835284618,
      "grad_norm": 0.11099260300397873,
      "learning_rate": 1.3423496164715382e-05,
      "loss": 0.0559,
      "step": 16290
    },
    {
      "epoch": 6.580540976988292,
      "grad_norm": 0.014238712377846241,
      "learning_rate": 1.3419459023011709e-05,
      "loss": 0.0364,
      "step": 16300
    },
    {
      "epoch": 6.584578118691966,
      "grad_norm": 0.06644098460674286,
      "learning_rate": 1.3415421881308035e-05,
      "loss": 0.0427,
      "step": 16310
    },
    {
      "epoch": 6.58861526039564,
      "grad_norm": 3.472342014312744,
      "learning_rate": 1.3411384739604361e-05,
      "loss": 0.0343,
      "step": 16320
    },
    {
      "epoch": 6.592652402099314,
      "grad_norm": 0.180752694606781,
      "learning_rate": 1.340734759790069e-05,
      "loss": 0.0348,
      "step": 16330
    },
    {
      "epoch": 6.596689543802987,
      "grad_norm": 0.021898848935961723,
      "learning_rate": 1.3403310456197014e-05,
      "loss": 0.0482,
      "step": 16340
    },
    {
      "epoch": 6.600726685506661,
      "grad_norm": 0.011464796029031277,
      "learning_rate": 1.339927331449334e-05,
      "loss": 0.0105,
      "step": 16350
    },
    {
      "epoch": 6.604763827210335,
      "grad_norm": 6.389804840087891,
      "learning_rate": 1.3395236172789665e-05,
      "loss": 0.0342,
      "step": 16360
    },
    {
      "epoch": 6.608800968914009,
      "grad_norm": 0.02716904506087303,
      "learning_rate": 1.3391199031085993e-05,
      "loss": 0.0033,
      "step": 16370
    },
    {
      "epoch": 6.612838110617683,
      "grad_norm": 0.25719431042671204,
      "learning_rate": 1.3387161889382319e-05,
      "loss": 0.0112,
      "step": 16380
    },
    {
      "epoch": 6.616875252321356,
      "grad_norm": 0.05483724921941757,
      "learning_rate": 1.3383124747678644e-05,
      "loss": 0.0042,
      "step": 16390
    },
    {
      "epoch": 6.62091239402503,
      "grad_norm": 10.875446319580078,
      "learning_rate": 1.3379087605974972e-05,
      "loss": 0.0679,
      "step": 16400
    },
    {
      "epoch": 6.624949535728704,
      "grad_norm": 2.763052463531494,
      "learning_rate": 1.3375050464271298e-05,
      "loss": 0.0543,
      "step": 16410
    },
    {
      "epoch": 6.628986677432378,
      "grad_norm": 0.0646105408668518,
      "learning_rate": 1.3371013322567622e-05,
      "loss": 0.0127,
      "step": 16420
    },
    {
      "epoch": 6.633023819136052,
      "grad_norm": 0.007074792869389057,
      "learning_rate": 1.3366976180863949e-05,
      "loss": 0.0035,
      "step": 16430
    },
    {
      "epoch": 6.637060960839726,
      "grad_norm": 0.004534970503300428,
      "learning_rate": 1.3362939039160277e-05,
      "loss": 0.0174,
      "step": 16440
    },
    {
      "epoch": 6.641098102543399,
      "grad_norm": 0.004712491296231747,
      "learning_rate": 1.3358901897456601e-05,
      "loss": 0.1161,
      "step": 16450
    },
    {
      "epoch": 6.645135244247073,
      "grad_norm": 3.9092512130737305,
      "learning_rate": 1.3354864755752928e-05,
      "loss": 0.0203,
      "step": 16460
    },
    {
      "epoch": 6.649172385950747,
      "grad_norm": 0.11319688707590103,
      "learning_rate": 1.3350827614049254e-05,
      "loss": 0.0097,
      "step": 16470
    },
    {
      "epoch": 6.653209527654421,
      "grad_norm": 3.0053210258483887,
      "learning_rate": 1.3346790472345582e-05,
      "loss": 0.0207,
      "step": 16480
    },
    {
      "epoch": 6.657246669358095,
      "grad_norm": 1.1455142498016357,
      "learning_rate": 1.3342753330641906e-05,
      "loss": 0.0283,
      "step": 16490
    },
    {
      "epoch": 6.661283811061768,
      "grad_norm": 0.9156071543693542,
      "learning_rate": 1.3338716188938233e-05,
      "loss": 0.0171,
      "step": 16500
    },
    {
      "epoch": 6.665320952765442,
      "grad_norm": 0.017376108095049858,
      "learning_rate": 1.333467904723456e-05,
      "loss": 0.0178,
      "step": 16510
    },
    {
      "epoch": 6.669358094469116,
      "grad_norm": 1.4496709108352661,
      "learning_rate": 1.3330641905530885e-05,
      "loss": 0.0253,
      "step": 16520
    },
    {
      "epoch": 6.67339523617279,
      "grad_norm": 0.06947585940361023,
      "learning_rate": 1.3326604763827212e-05,
      "loss": 0.0025,
      "step": 16530
    },
    {
      "epoch": 6.677432377876464,
      "grad_norm": 0.11723488569259644,
      "learning_rate": 1.3322567622123536e-05,
      "loss": 0.0046,
      "step": 16540
    },
    {
      "epoch": 6.681469519580137,
      "grad_norm": 0.004214887041598558,
      "learning_rate": 1.3318530480419864e-05,
      "loss": 0.0231,
      "step": 16550
    },
    {
      "epoch": 6.685506661283811,
      "grad_norm": 0.01348753273487091,
      "learning_rate": 1.331449333871619e-05,
      "loss": 0.0356,
      "step": 16560
    },
    {
      "epoch": 6.689543802987485,
      "grad_norm": 9.407095909118652,
      "learning_rate": 1.3310456197012515e-05,
      "loss": 0.0658,
      "step": 16570
    },
    {
      "epoch": 6.693580944691159,
      "grad_norm": 0.03818733990192413,
      "learning_rate": 1.3306419055308843e-05,
      "loss": 0.0114,
      "step": 16580
    },
    {
      "epoch": 6.697618086394833,
      "grad_norm": 0.014105014503002167,
      "learning_rate": 1.330238191360517e-05,
      "loss": 0.054,
      "step": 16590
    },
    {
      "epoch": 6.701655228098506,
      "grad_norm": 3.8647327423095703,
      "learning_rate": 1.3298344771901494e-05,
      "loss": 0.0527,
      "step": 16600
    },
    {
      "epoch": 6.70569236980218,
      "grad_norm": 0.00713956356048584,
      "learning_rate": 1.329430763019782e-05,
      "loss": 0.0302,
      "step": 16610
    },
    {
      "epoch": 6.709729511505854,
      "grad_norm": 0.03899957612156868,
      "learning_rate": 1.3290270488494148e-05,
      "loss": 0.0068,
      "step": 16620
    },
    {
      "epoch": 6.713766653209528,
      "grad_norm": 0.5958447456359863,
      "learning_rate": 1.3286233346790474e-05,
      "loss": 0.0144,
      "step": 16630
    },
    {
      "epoch": 6.717803794913202,
      "grad_norm": 0.036790866404771805,
      "learning_rate": 1.3282196205086799e-05,
      "loss": 0.0012,
      "step": 16640
    },
    {
      "epoch": 6.721840936616875,
      "grad_norm": 0.012468190863728523,
      "learning_rate": 1.3278159063383125e-05,
      "loss": 0.0335,
      "step": 16650
    },
    {
      "epoch": 6.725878078320549,
      "grad_norm": 2.87211537361145,
      "learning_rate": 1.3274121921679453e-05,
      "loss": 0.0316,
      "step": 16660
    },
    {
      "epoch": 6.729915220024223,
      "grad_norm": 1.6283406019210815,
      "learning_rate": 1.3270084779975778e-05,
      "loss": 0.0082,
      "step": 16670
    },
    {
      "epoch": 6.733952361727897,
      "grad_norm": 0.0060104443691670895,
      "learning_rate": 1.3266047638272104e-05,
      "loss": 0.0435,
      "step": 16680
    },
    {
      "epoch": 6.737989503431571,
      "grad_norm": 0.01931830309331417,
      "learning_rate": 1.3262010496568432e-05,
      "loss": 0.0162,
      "step": 16690
    },
    {
      "epoch": 6.742026645135244,
      "grad_norm": 0.008140666410326958,
      "learning_rate": 1.3257973354864757e-05,
      "loss": 0.0612,
      "step": 16700
    },
    {
      "epoch": 6.746063786838918,
      "grad_norm": 0.6426790356636047,
      "learning_rate": 1.3253936213161083e-05,
      "loss": 0.0403,
      "step": 16710
    },
    {
      "epoch": 6.750100928542592,
      "grad_norm": 7.20064640045166,
      "learning_rate": 1.3249899071457408e-05,
      "loss": 0.0671,
      "step": 16720
    },
    {
      "epoch": 6.754138070246266,
      "grad_norm": 0.03977261483669281,
      "learning_rate": 1.3245861929753736e-05,
      "loss": 0.0487,
      "step": 16730
    },
    {
      "epoch": 6.75817521194994,
      "grad_norm": 0.5687898397445679,
      "learning_rate": 1.3241824788050062e-05,
      "loss": 0.017,
      "step": 16740
    },
    {
      "epoch": 6.762212353653613,
      "grad_norm": 1.017714500427246,
      "learning_rate": 1.3237787646346386e-05,
      "loss": 0.031,
      "step": 16750
    },
    {
      "epoch": 6.766249495357287,
      "grad_norm": 0.05435045808553696,
      "learning_rate": 1.3233750504642714e-05,
      "loss": 0.0058,
      "step": 16760
    },
    {
      "epoch": 6.770286637060961,
      "grad_norm": 10.604165077209473,
      "learning_rate": 1.322971336293904e-05,
      "loss": 0.0281,
      "step": 16770
    },
    {
      "epoch": 6.774323778764635,
      "grad_norm": 2.0282814502716064,
      "learning_rate": 1.3225676221235367e-05,
      "loss": 0.0574,
      "step": 16780
    },
    {
      "epoch": 6.778360920468309,
      "grad_norm": 1.0688555240631104,
      "learning_rate": 1.3221639079531692e-05,
      "loss": 0.0289,
      "step": 16790
    },
    {
      "epoch": 6.782398062171982,
      "grad_norm": 0.009967489168047905,
      "learning_rate": 1.321760193782802e-05,
      "loss": 0.018,
      "step": 16800
    },
    {
      "epoch": 6.786435203875656,
      "grad_norm": 16.9420166015625,
      "learning_rate": 1.3213564796124346e-05,
      "loss": 0.0533,
      "step": 16810
    },
    {
      "epoch": 6.79047234557933,
      "grad_norm": 0.07813669741153717,
      "learning_rate": 1.320952765442067e-05,
      "loss": 0.0262,
      "step": 16820
    },
    {
      "epoch": 6.794509487283004,
      "grad_norm": 0.8988681435585022,
      "learning_rate": 1.3205490512716998e-05,
      "loss": 0.0157,
      "step": 16830
    },
    {
      "epoch": 6.798546628986678,
      "grad_norm": 0.05070706084370613,
      "learning_rate": 1.3201453371013325e-05,
      "loss": 0.0284,
      "step": 16840
    },
    {
      "epoch": 6.802583770690351,
      "grad_norm": 1.0122205018997192,
      "learning_rate": 1.319741622930965e-05,
      "loss": 0.0104,
      "step": 16850
    },
    {
      "epoch": 6.806620912394025,
      "grad_norm": 2.673027992248535,
      "learning_rate": 1.3193379087605976e-05,
      "loss": 0.0348,
      "step": 16860
    },
    {
      "epoch": 6.810658054097699,
      "grad_norm": 0.4043278396129608,
      "learning_rate": 1.3189341945902304e-05,
      "loss": 0.013,
      "step": 16870
    },
    {
      "epoch": 6.814695195801373,
      "grad_norm": 2.6909024715423584,
      "learning_rate": 1.3185304804198628e-05,
      "loss": 0.0198,
      "step": 16880
    },
    {
      "epoch": 6.818732337505047,
      "grad_norm": 2.9950003623962402,
      "learning_rate": 1.3181267662494955e-05,
      "loss": 0.0188,
      "step": 16890
    },
    {
      "epoch": 6.82276947920872,
      "grad_norm": 0.003427651710808277,
      "learning_rate": 1.3177230520791279e-05,
      "loss": 0.0455,
      "step": 16900
    },
    {
      "epoch": 6.826806620912394,
      "grad_norm": 0.006843273062258959,
      "learning_rate": 1.3173193379087607e-05,
      "loss": 0.0064,
      "step": 16910
    },
    {
      "epoch": 6.830843762616068,
      "grad_norm": 0.0384180024266243,
      "learning_rate": 1.3169156237383933e-05,
      "loss": 0.012,
      "step": 16920
    },
    {
      "epoch": 6.834880904319742,
      "grad_norm": 0.013831039890646935,
      "learning_rate": 1.316511909568026e-05,
      "loss": 0.0171,
      "step": 16930
    },
    {
      "epoch": 6.838918046023416,
      "grad_norm": 0.019607068970799446,
      "learning_rate": 1.3161081953976586e-05,
      "loss": 0.001,
      "step": 16940
    },
    {
      "epoch": 6.842955187727089,
      "grad_norm": 0.009574249386787415,
      "learning_rate": 1.3157044812272912e-05,
      "loss": 0.0177,
      "step": 16950
    },
    {
      "epoch": 6.846992329430763,
      "grad_norm": 0.0009888226632028818,
      "learning_rate": 1.3153007670569239e-05,
      "loss": 0.0013,
      "step": 16960
    },
    {
      "epoch": 6.851029471134437,
      "grad_norm": 0.003257734701037407,
      "learning_rate": 1.3148970528865563e-05,
      "loss": 0.0328,
      "step": 16970
    },
    {
      "epoch": 6.855066612838111,
      "grad_norm": 0.001222669961862266,
      "learning_rate": 1.3144933387161891e-05,
      "loss": 0.011,
      "step": 16980
    },
    {
      "epoch": 6.859103754541785,
      "grad_norm": 0.003095092251896858,
      "learning_rate": 1.3140896245458217e-05,
      "loss": 0.0171,
      "step": 16990
    },
    {
      "epoch": 6.863140896245458,
      "grad_norm": 0.010590910911560059,
      "learning_rate": 1.3136859103754542e-05,
      "loss": 0.0766,
      "step": 17000
    },
    {
      "epoch": 6.867178037949132,
      "grad_norm": 0.10187923908233643,
      "learning_rate": 1.313282196205087e-05,
      "loss": 0.0189,
      "step": 17010
    },
    {
      "epoch": 6.871215179652806,
      "grad_norm": 1.1202538013458252,
      "learning_rate": 1.3128784820347196e-05,
      "loss": 0.0194,
      "step": 17020
    },
    {
      "epoch": 6.87525232135648,
      "grad_norm": 0.003901037387549877,
      "learning_rate": 1.312474767864352e-05,
      "loss": 0.0023,
      "step": 17030
    },
    {
      "epoch": 6.879289463060154,
      "grad_norm": 1.205236792564392,
      "learning_rate": 1.3120710536939847e-05,
      "loss": 0.065,
      "step": 17040
    },
    {
      "epoch": 6.883326604763827,
      "grad_norm": 0.003201717510819435,
      "learning_rate": 1.3116673395236175e-05,
      "loss": 0.0307,
      "step": 17050
    },
    {
      "epoch": 6.887363746467501,
      "grad_norm": 0.004442975390702486,
      "learning_rate": 1.31126362535325e-05,
      "loss": 0.0096,
      "step": 17060
    },
    {
      "epoch": 6.891400888171175,
      "grad_norm": 0.04477416351437569,
      "learning_rate": 1.3108599111828826e-05,
      "loss": 0.0093,
      "step": 17070
    },
    {
      "epoch": 6.895438029874849,
      "grad_norm": 0.13437430560588837,
      "learning_rate": 1.310456197012515e-05,
      "loss": 0.0205,
      "step": 17080
    },
    {
      "epoch": 6.899475171578523,
      "grad_norm": 2.24316668510437,
      "learning_rate": 1.3100524828421479e-05,
      "loss": 0.0327,
      "step": 17090
    },
    {
      "epoch": 6.903512313282196,
      "grad_norm": 1.0817888975143433,
      "learning_rate": 1.3096487686717805e-05,
      "loss": 0.0465,
      "step": 17100
    },
    {
      "epoch": 6.90754945498587,
      "grad_norm": 7.194112777709961,
      "learning_rate": 1.3092450545014131e-05,
      "loss": 0.0302,
      "step": 17110
    },
    {
      "epoch": 6.911586596689544,
      "grad_norm": 0.9736719727516174,
      "learning_rate": 1.3088413403310457e-05,
      "loss": 0.0423,
      "step": 17120
    },
    {
      "epoch": 6.915623738393218,
      "grad_norm": 0.018556717783212662,
      "learning_rate": 1.3084376261606784e-05,
      "loss": 0.0215,
      "step": 17130
    },
    {
      "epoch": 6.919660880096892,
      "grad_norm": 0.00892606470733881,
      "learning_rate": 1.308033911990311e-05,
      "loss": 0.0065,
      "step": 17140
    },
    {
      "epoch": 6.923698021800565,
      "grad_norm": 2.3300695419311523,
      "learning_rate": 1.3076301978199435e-05,
      "loss": 0.0137,
      "step": 17150
    },
    {
      "epoch": 6.927735163504239,
      "grad_norm": 12.697942733764648,
      "learning_rate": 1.3072264836495763e-05,
      "loss": 0.0285,
      "step": 17160
    },
    {
      "epoch": 6.931772305207913,
      "grad_norm": 0.006517418194562197,
      "learning_rate": 1.3068227694792089e-05,
      "loss": 0.0069,
      "step": 17170
    },
    {
      "epoch": 6.935809446911587,
      "grad_norm": 0.0024058418348431587,
      "learning_rate": 1.3064190553088413e-05,
      "loss": 0.0191,
      "step": 17180
    },
    {
      "epoch": 6.939846588615261,
      "grad_norm": 0.020253192633390427,
      "learning_rate": 1.3060153411384741e-05,
      "loss": 0.0532,
      "step": 17190
    },
    {
      "epoch": 6.943883730318934,
      "grad_norm": 1.3583053350448608,
      "learning_rate": 1.3056116269681068e-05,
      "loss": 0.0134,
      "step": 17200
    },
    {
      "epoch": 6.947920872022608,
      "grad_norm": 0.004744221922010183,
      "learning_rate": 1.3052079127977392e-05,
      "loss": 0.0773,
      "step": 17210
    },
    {
      "epoch": 6.951958013726282,
      "grad_norm": 1.1216323375701904,
      "learning_rate": 1.3048041986273719e-05,
      "loss": 0.001,
      "step": 17220
    },
    {
      "epoch": 6.955995155429956,
      "grad_norm": 14.938406944274902,
      "learning_rate": 1.3044004844570047e-05,
      "loss": 0.0341,
      "step": 17230
    },
    {
      "epoch": 6.96003229713363,
      "grad_norm": 1.0041422843933105,
      "learning_rate": 1.3039967702866371e-05,
      "loss": 0.0166,
      "step": 17240
    },
    {
      "epoch": 6.964069438837303,
      "grad_norm": 0.0024517602287232876,
      "learning_rate": 1.3035930561162697e-05,
      "loss": 0.0231,
      "step": 17250
    },
    {
      "epoch": 6.968106580540977,
      "grad_norm": 0.0656978115439415,
      "learning_rate": 1.3031893419459024e-05,
      "loss": 0.0077,
      "step": 17260
    },
    {
      "epoch": 6.972143722244651,
      "grad_norm": 0.0029839591588824987,
      "learning_rate": 1.302785627775535e-05,
      "loss": 0.0115,
      "step": 17270
    },
    {
      "epoch": 6.976180863948325,
      "grad_norm": 2.280761241912842,
      "learning_rate": 1.3023819136051676e-05,
      "loss": 0.0186,
      "step": 17280
    },
    {
      "epoch": 6.980218005651999,
      "grad_norm": 12.28091049194336,
      "learning_rate": 1.3019781994348003e-05,
      "loss": 0.0436,
      "step": 17290
    },
    {
      "epoch": 6.984255147355672,
      "grad_norm": 0.0012556178262457252,
      "learning_rate": 1.301574485264433e-05,
      "loss": 0.0131,
      "step": 17300
    },
    {
      "epoch": 6.988292289059346,
      "grad_norm": 0.059086721390485764,
      "learning_rate": 1.3011707710940655e-05,
      "loss": 0.0099,
      "step": 17310
    },
    {
      "epoch": 6.99232943076302,
      "grad_norm": 1.566162109375,
      "learning_rate": 1.3007670569236981e-05,
      "loss": 0.0387,
      "step": 17320
    },
    {
      "epoch": 6.996366572466694,
      "grad_norm": 0.012988275848329067,
      "learning_rate": 1.3003633427533306e-05,
      "loss": 0.0001,
      "step": 17330
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9849842767295598,
      "eval_f1": 0.9458156028368794,
      "eval_loss": 0.05883656069636345,
      "eval_precision": 0.9338935574229692,
      "eval_recall": 0.9580459770114943,
      "eval_runtime": 443.552,
      "eval_samples_per_second": 28.723,
      "eval_steps_per_second": 1.197,
      "step": 17339
    },
    {
      "epoch": 7.000403714170368,
      "grad_norm": 0.004326139576733112,
      "learning_rate": 1.2999596285829634e-05,
      "loss": 0.0079,
      "step": 17340
    },
    {
      "epoch": 7.004440855874041,
      "grad_norm": 0.016090955585241318,
      "learning_rate": 1.299555914412596e-05,
      "loss": 0.0196,
      "step": 17350
    },
    {
      "epoch": 7.008477997577715,
      "grad_norm": 1.3126068115234375,
      "learning_rate": 1.2991522002422285e-05,
      "loss": 0.0217,
      "step": 17360
    },
    {
      "epoch": 7.012515139281389,
      "grad_norm": 1.3931963443756104,
      "learning_rate": 1.2987484860718613e-05,
      "loss": 0.0178,
      "step": 17370
    },
    {
      "epoch": 7.016552280985063,
      "grad_norm": 0.013786224648356438,
      "learning_rate": 1.298344771901494e-05,
      "loss": 0.006,
      "step": 17380
    },
    {
      "epoch": 7.020589422688737,
      "grad_norm": 0.9774723052978516,
      "learning_rate": 1.2979410577311264e-05,
      "loss": 0.0087,
      "step": 17390
    },
    {
      "epoch": 7.02462656439241,
      "grad_norm": 0.031360652297735214,
      "learning_rate": 1.297537343560759e-05,
      "loss": 0.0249,
      "step": 17400
    },
    {
      "epoch": 7.028663706096084,
      "grad_norm": 0.003683297196403146,
      "learning_rate": 1.2971336293903918e-05,
      "loss": 0.0553,
      "step": 17410
    },
    {
      "epoch": 7.032700847799758,
      "grad_norm": 0.06503836810588837,
      "learning_rate": 1.2967299152200243e-05,
      "loss": 0.0219,
      "step": 17420
    },
    {
      "epoch": 7.036737989503432,
      "grad_norm": 11.964336395263672,
      "learning_rate": 1.2963262010496569e-05,
      "loss": 0.0489,
      "step": 17430
    },
    {
      "epoch": 7.040775131207106,
      "grad_norm": 0.8243865370750427,
      "learning_rate": 1.2959224868792897e-05,
      "loss": 0.0015,
      "step": 17440
    },
    {
      "epoch": 7.04481227291078,
      "grad_norm": 0.007714048493653536,
      "learning_rate": 1.2955187727089223e-05,
      "loss": 0.0193,
      "step": 17450
    },
    {
      "epoch": 7.048849414614453,
      "grad_norm": 5.188741683959961,
      "learning_rate": 1.2951150585385548e-05,
      "loss": 0.0087,
      "step": 17460
    },
    {
      "epoch": 7.052886556318127,
      "grad_norm": 1.1379024982452393,
      "learning_rate": 1.2947113443681874e-05,
      "loss": 0.0241,
      "step": 17470
    },
    {
      "epoch": 7.056923698021801,
      "grad_norm": 0.0026432897429913282,
      "learning_rate": 1.2943076301978202e-05,
      "loss": 0.0106,
      "step": 17480
    },
    {
      "epoch": 7.060960839725475,
      "grad_norm": 0.004630275070667267,
      "learning_rate": 1.2939039160274527e-05,
      "loss": 0.0146,
      "step": 17490
    },
    {
      "epoch": 7.064997981429149,
      "grad_norm": 0.0018798429518938065,
      "learning_rate": 1.2935002018570853e-05,
      "loss": 0.0272,
      "step": 17500
    },
    {
      "epoch": 7.069035123132822,
      "grad_norm": 0.0027857322711497545,
      "learning_rate": 1.2930964876867178e-05,
      "loss": 0.0118,
      "step": 17510
    },
    {
      "epoch": 7.073072264836496,
      "grad_norm": 0.003248349530622363,
      "learning_rate": 1.2926927735163506e-05,
      "loss": 0.0048,
      "step": 17520
    },
    {
      "epoch": 7.07710940654017,
      "grad_norm": 0.31528985500335693,
      "learning_rate": 1.2922890593459832e-05,
      "loss": 0.0258,
      "step": 17530
    },
    {
      "epoch": 7.081146548243844,
      "grad_norm": 3.3492398262023926,
      "learning_rate": 1.2918853451756156e-05,
      "loss": 0.0278,
      "step": 17540
    },
    {
      "epoch": 7.085183689947518,
      "grad_norm": 0.12257923185825348,
      "learning_rate": 1.2914816310052484e-05,
      "loss": 0.0295,
      "step": 17550
    },
    {
      "epoch": 7.089220831651191,
      "grad_norm": 0.7814992666244507,
      "learning_rate": 1.291077916834881e-05,
      "loss": 0.0175,
      "step": 17560
    },
    {
      "epoch": 7.093257973354865,
      "grad_norm": 0.006728715263307095,
      "learning_rate": 1.2906742026645135e-05,
      "loss": 0.0053,
      "step": 17570
    },
    {
      "epoch": 7.097295115058539,
      "grad_norm": 0.0476827546954155,
      "learning_rate": 1.2902704884941462e-05,
      "loss": 0.0062,
      "step": 17580
    },
    {
      "epoch": 7.101332256762213,
      "grad_norm": 11.242932319641113,
      "learning_rate": 1.289866774323779e-05,
      "loss": 0.0503,
      "step": 17590
    },
    {
      "epoch": 7.1053693984658866,
      "grad_norm": 4.1002421379089355,
      "learning_rate": 1.2894630601534114e-05,
      "loss": 0.0517,
      "step": 17600
    },
    {
      "epoch": 7.10940654016956,
      "grad_norm": 0.5780258774757385,
      "learning_rate": 1.289059345983044e-05,
      "loss": 0.0406,
      "step": 17610
    },
    {
      "epoch": 7.113443681873234,
      "grad_norm": 0.07952933013439178,
      "learning_rate": 1.2886556318126768e-05,
      "loss": 0.0394,
      "step": 17620
    },
    {
      "epoch": 7.117480823576908,
      "grad_norm": 0.7236468195915222,
      "learning_rate": 1.2882519176423095e-05,
      "loss": 0.0225,
      "step": 17630
    },
    {
      "epoch": 7.121517965280582,
      "grad_norm": 0.023297253996133804,
      "learning_rate": 1.287848203471942e-05,
      "loss": 0.0164,
      "step": 17640
    },
    {
      "epoch": 7.1255551069842555,
      "grad_norm": 1.6014630794525146,
      "learning_rate": 1.2874444893015746e-05,
      "loss": 0.0197,
      "step": 17650
    },
    {
      "epoch": 7.129592248687929,
      "grad_norm": 0.0029625187162309885,
      "learning_rate": 1.2870407751312074e-05,
      "loss": 0.0126,
      "step": 17660
    },
    {
      "epoch": 7.133629390391603,
      "grad_norm": 0.00786453764885664,
      "learning_rate": 1.2866370609608398e-05,
      "loss": 0.0128,
      "step": 17670
    },
    {
      "epoch": 7.137666532095277,
      "grad_norm": 0.0557553805410862,
      "learning_rate": 1.2862333467904724e-05,
      "loss": 0.0006,
      "step": 17680
    },
    {
      "epoch": 7.1417036737989505,
      "grad_norm": 4.665084362030029,
      "learning_rate": 1.2858296326201049e-05,
      "loss": 0.0055,
      "step": 17690
    },
    {
      "epoch": 7.1457408155026245,
      "grad_norm": 2.2592551708221436,
      "learning_rate": 1.2854259184497377e-05,
      "loss": 0.0139,
      "step": 17700
    },
    {
      "epoch": 7.149777957206298,
      "grad_norm": 0.02200128138065338,
      "learning_rate": 1.2850222042793703e-05,
      "loss": 0.0245,
      "step": 17710
    },
    {
      "epoch": 7.153815098909972,
      "grad_norm": 1.3902500867843628,
      "learning_rate": 1.2846184901090028e-05,
      "loss": 0.013,
      "step": 17720
    },
    {
      "epoch": 7.1578522406136456,
      "grad_norm": 0.7004517316818237,
      "learning_rate": 1.2842147759386356e-05,
      "loss": 0.0076,
      "step": 17730
    },
    {
      "epoch": 7.1618893823173195,
      "grad_norm": 2.259150266647339,
      "learning_rate": 1.2838110617682682e-05,
      "loss": 0.0106,
      "step": 17740
    },
    {
      "epoch": 7.1659265240209935,
      "grad_norm": 1.157468557357788,
      "learning_rate": 1.2834073475979007e-05,
      "loss": 0.0151,
      "step": 17750
    },
    {
      "epoch": 7.169963665724667,
      "grad_norm": 0.024977758526802063,
      "learning_rate": 1.2830036334275333e-05,
      "loss": 0.0479,
      "step": 17760
    },
    {
      "epoch": 7.174000807428341,
      "grad_norm": 0.005315075162798166,
      "learning_rate": 1.2825999192571661e-05,
      "loss": 0.0054,
      "step": 17770
    },
    {
      "epoch": 7.1780379491320145,
      "grad_norm": 1.2464464902877808,
      "learning_rate": 1.2821962050867987e-05,
      "loss": 0.019,
      "step": 17780
    },
    {
      "epoch": 7.1820750908356885,
      "grad_norm": 1.174269676208496,
      "learning_rate": 1.2817924909164312e-05,
      "loss": 0.0597,
      "step": 17790
    },
    {
      "epoch": 7.1861122325393625,
      "grad_norm": 6.566869735717773,
      "learning_rate": 1.281388776746064e-05,
      "loss": 0.008,
      "step": 17800
    },
    {
      "epoch": 7.190149374243036,
      "grad_norm": 0.18142728507518768,
      "learning_rate": 1.2809850625756966e-05,
      "loss": 0.0214,
      "step": 17810
    },
    {
      "epoch": 7.1941865159467095,
      "grad_norm": 0.31648483872413635,
      "learning_rate": 1.280581348405329e-05,
      "loss": 0.0145,
      "step": 17820
    },
    {
      "epoch": 7.1982236576503835,
      "grad_norm": 1.0636152029037476,
      "learning_rate": 1.2801776342349617e-05,
      "loss": 0.0065,
      "step": 17830
    },
    {
      "epoch": 7.2022607993540575,
      "grad_norm": 0.0038404790684580803,
      "learning_rate": 1.2797739200645945e-05,
      "loss": 0.0151,
      "step": 17840
    },
    {
      "epoch": 7.2062979410577315,
      "grad_norm": 2.3833208084106445,
      "learning_rate": 1.279370205894227e-05,
      "loss": 0.0563,
      "step": 17850
    },
    {
      "epoch": 7.210335082761405,
      "grad_norm": 0.0032554722856730223,
      "learning_rate": 1.2789664917238596e-05,
      "loss": 0.0071,
      "step": 17860
    },
    {
      "epoch": 7.2143722244650785,
      "grad_norm": 1.7451481819152832,
      "learning_rate": 1.2785627775534924e-05,
      "loss": 0.0277,
      "step": 17870
    },
    {
      "epoch": 7.2184093661687525,
      "grad_norm": 0.003368428675457835,
      "learning_rate": 1.2781590633831248e-05,
      "loss": 0.0069,
      "step": 17880
    },
    {
      "epoch": 7.2224465078724265,
      "grad_norm": 0.011023787781596184,
      "learning_rate": 1.2777553492127575e-05,
      "loss": 0.0162,
      "step": 17890
    },
    {
      "epoch": 7.2264836495761005,
      "grad_norm": 0.145132377743721,
      "learning_rate": 1.27735163504239e-05,
      "loss": 0.0048,
      "step": 17900
    },
    {
      "epoch": 7.2305207912797735,
      "grad_norm": 1.5425760746002197,
      "learning_rate": 1.2769479208720227e-05,
      "loss": 0.0078,
      "step": 17910
    },
    {
      "epoch": 7.2345579329834475,
      "grad_norm": 0.01024867407977581,
      "learning_rate": 1.2765442067016554e-05,
      "loss": 0.0172,
      "step": 17920
    },
    {
      "epoch": 7.2385950746871215,
      "grad_norm": 0.002306066919118166,
      "learning_rate": 1.276140492531288e-05,
      "loss": 0.0316,
      "step": 17930
    },
    {
      "epoch": 7.2426322163907955,
      "grad_norm": 0.03996261954307556,
      "learning_rate": 1.2757367783609204e-05,
      "loss": 0.0053,
      "step": 17940
    },
    {
      "epoch": 7.246669358094469,
      "grad_norm": 1.1117057800292969,
      "learning_rate": 1.2753330641905532e-05,
      "loss": 0.0078,
      "step": 17950
    },
    {
      "epoch": 7.2507064997981425,
      "grad_norm": 0.011181759648025036,
      "learning_rate": 1.2749293500201859e-05,
      "loss": 0.0177,
      "step": 17960
    },
    {
      "epoch": 7.2547436415018165,
      "grad_norm": 0.0031521569471806288,
      "learning_rate": 1.2745256358498183e-05,
      "loss": 0.0203,
      "step": 17970
    },
    {
      "epoch": 7.2587807832054905,
      "grad_norm": 0.0010952271986752748,
      "learning_rate": 1.2741219216794511e-05,
      "loss": 0.0058,
      "step": 17980
    },
    {
      "epoch": 7.2628179249091644,
      "grad_norm": 0.0013504205271601677,
      "learning_rate": 1.2737182075090838e-05,
      "loss": 0.0082,
      "step": 17990
    },
    {
      "epoch": 7.266855066612838,
      "grad_norm": 0.0034550705458968878,
      "learning_rate": 1.2733144933387162e-05,
      "loss": 0.0022,
      "step": 18000
    },
    {
      "epoch": 7.2708922083165115,
      "grad_norm": 1.5820575952529907,
      "learning_rate": 1.2729107791683488e-05,
      "loss": 0.011,
      "step": 18010
    },
    {
      "epoch": 7.2749293500201855,
      "grad_norm": 0.0032701422460377216,
      "learning_rate": 1.2725070649979816e-05,
      "loss": 0.0164,
      "step": 18020
    },
    {
      "epoch": 7.2789664917238595,
      "grad_norm": 0.1552935391664505,
      "learning_rate": 1.2721033508276141e-05,
      "loss": 0.0064,
      "step": 18030
    },
    {
      "epoch": 7.283003633427533,
      "grad_norm": 0.0028079610783606768,
      "learning_rate": 1.2716996366572467e-05,
      "loss": 0.0207,
      "step": 18040
    },
    {
      "epoch": 7.287040775131207,
      "grad_norm": 0.08931862562894821,
      "learning_rate": 1.2712959224868795e-05,
      "loss": 0.0006,
      "step": 18050
    },
    {
      "epoch": 7.2910779168348805,
      "grad_norm": 0.45429399609565735,
      "learning_rate": 1.270892208316512e-05,
      "loss": 0.0093,
      "step": 18060
    },
    {
      "epoch": 7.2951150585385545,
      "grad_norm": 7.2795329093933105,
      "learning_rate": 1.2704884941461446e-05,
      "loss": 0.0259,
      "step": 18070
    },
    {
      "epoch": 7.299152200242228,
      "grad_norm": 0.0014075469225645065,
      "learning_rate": 1.2700847799757772e-05,
      "loss": 0.03,
      "step": 18080
    },
    {
      "epoch": 7.303189341945902,
      "grad_norm": 0.37844663858413696,
      "learning_rate": 1.2696810658054099e-05,
      "loss": 0.0287,
      "step": 18090
    },
    {
      "epoch": 7.307226483649576,
      "grad_norm": 0.6882905960083008,
      "learning_rate": 1.2692773516350425e-05,
      "loss": 0.0219,
      "step": 18100
    },
    {
      "epoch": 7.31126362535325,
      "grad_norm": 0.011643177829682827,
      "learning_rate": 1.2688736374646751e-05,
      "loss": 0.0184,
      "step": 18110
    },
    {
      "epoch": 7.3153007670569234,
      "grad_norm": 0.002227816265076399,
      "learning_rate": 1.2684699232943076e-05,
      "loss": 0.0046,
      "step": 18120
    },
    {
      "epoch": 7.319337908760597,
      "grad_norm": 0.0017706999788060784,
      "learning_rate": 1.2680662091239404e-05,
      "loss": 0.0086,
      "step": 18130
    },
    {
      "epoch": 7.323375050464271,
      "grad_norm": 4.29116153717041,
      "learning_rate": 1.267662494953573e-05,
      "loss": 0.0146,
      "step": 18140
    },
    {
      "epoch": 7.327412192167945,
      "grad_norm": 0.4132170081138611,
      "learning_rate": 1.2672587807832055e-05,
      "loss": 0.0247,
      "step": 18150
    },
    {
      "epoch": 7.331449333871619,
      "grad_norm": 0.0010363643523305655,
      "learning_rate": 1.2668550666128383e-05,
      "loss": 0.0208,
      "step": 18160
    },
    {
      "epoch": 7.335486475575292,
      "grad_norm": 0.34106600284576416,
      "learning_rate": 1.2664513524424709e-05,
      "loss": 0.0231,
      "step": 18170
    },
    {
      "epoch": 7.339523617278966,
      "grad_norm": 0.012052733451128006,
      "learning_rate": 1.2660476382721034e-05,
      "loss": 0.0332,
      "step": 18180
    },
    {
      "epoch": 7.34356075898264,
      "grad_norm": 0.005348716396838427,
      "learning_rate": 1.265643924101736e-05,
      "loss": 0.0022,
      "step": 18190
    },
    {
      "epoch": 7.347597900686314,
      "grad_norm": 0.0012715201592072845,
      "learning_rate": 1.2652402099313688e-05,
      "loss": 0.0033,
      "step": 18200
    },
    {
      "epoch": 7.351635042389988,
      "grad_norm": 0.001550059299916029,
      "learning_rate": 1.2648364957610013e-05,
      "loss": 0.0006,
      "step": 18210
    },
    {
      "epoch": 7.355672184093661,
      "grad_norm": 0.00573705043643713,
      "learning_rate": 1.2644327815906339e-05,
      "loss": 0.0098,
      "step": 18220
    },
    {
      "epoch": 7.359709325797335,
      "grad_norm": 0.005707299802452326,
      "learning_rate": 1.2640290674202667e-05,
      "loss": 0.029,
      "step": 18230
    },
    {
      "epoch": 7.363746467501009,
      "grad_norm": 1.159769892692566,
      "learning_rate": 1.2636253532498991e-05,
      "loss": 0.0119,
      "step": 18240
    },
    {
      "epoch": 7.367783609204683,
      "grad_norm": 0.005327651742845774,
      "learning_rate": 1.2632216390795318e-05,
      "loss": 0.075,
      "step": 18250
    },
    {
      "epoch": 7.371820750908357,
      "grad_norm": 0.38211050629615784,
      "learning_rate": 1.2628179249091644e-05,
      "loss": 0.0152,
      "step": 18260
    },
    {
      "epoch": 7.37585789261203,
      "grad_norm": 0.0033124322071671486,
      "learning_rate": 1.262414210738797e-05,
      "loss": 0.0274,
      "step": 18270
    },
    {
      "epoch": 7.379895034315704,
      "grad_norm": 0.7408086061477661,
      "learning_rate": 1.2620104965684297e-05,
      "loss": 0.0179,
      "step": 18280
    },
    {
      "epoch": 7.383932176019378,
      "grad_norm": 0.03786532208323479,
      "learning_rate": 1.2616067823980623e-05,
      "loss": 0.0274,
      "step": 18290
    },
    {
      "epoch": 7.387969317723052,
      "grad_norm": 1.5566492080688477,
      "learning_rate": 1.261203068227695e-05,
      "loss": 0.0128,
      "step": 18300
    },
    {
      "epoch": 7.392006459426726,
      "grad_norm": 0.08033079653978348,
      "learning_rate": 1.2607993540573275e-05,
      "loss": 0.0742,
      "step": 18310
    },
    {
      "epoch": 7.396043601130399,
      "grad_norm": 0.018018847331404686,
      "learning_rate": 1.2603956398869602e-05,
      "loss": 0.0154,
      "step": 18320
    },
    {
      "epoch": 7.400080742834073,
      "grad_norm": 0.0035111827310174704,
      "learning_rate": 1.2599919257165926e-05,
      "loss": 0.0171,
      "step": 18330
    },
    {
      "epoch": 7.404117884537747,
      "grad_norm": 0.004569963552057743,
      "learning_rate": 1.2595882115462254e-05,
      "loss": 0.0038,
      "step": 18340
    },
    {
      "epoch": 7.408155026241421,
      "grad_norm": 1.6745421886444092,
      "learning_rate": 1.259184497375858e-05,
      "loss": 0.0123,
      "step": 18350
    },
    {
      "epoch": 7.412192167945095,
      "grad_norm": 0.0035905339755117893,
      "learning_rate": 1.2587807832054905e-05,
      "loss": 0.0039,
      "step": 18360
    },
    {
      "epoch": 7.416229309648768,
      "grad_norm": 0.005769380368292332,
      "learning_rate": 1.2583770690351231e-05,
      "loss": 0.0007,
      "step": 18370
    },
    {
      "epoch": 7.420266451352442,
      "grad_norm": 0.0015361279947683215,
      "learning_rate": 1.257973354864756e-05,
      "loss": 0.0035,
      "step": 18380
    },
    {
      "epoch": 7.424303593056116,
      "grad_norm": 0.8390430212020874,
      "learning_rate": 1.2575696406943884e-05,
      "loss": 0.0154,
      "step": 18390
    },
    {
      "epoch": 7.42834073475979,
      "grad_norm": 0.0013312142109498382,
      "learning_rate": 1.257165926524021e-05,
      "loss": 0.0192,
      "step": 18400
    },
    {
      "epoch": 7.432377876463464,
      "grad_norm": 0.0009595321025699377,
      "learning_rate": 1.2567622123536538e-05,
      "loss": 0.007,
      "step": 18410
    },
    {
      "epoch": 7.436415018167137,
      "grad_norm": 0.0032495830673724413,
      "learning_rate": 1.2563584981832863e-05,
      "loss": 0.048,
      "step": 18420
    },
    {
      "epoch": 7.440452159870811,
      "grad_norm": 2.1773624420166016,
      "learning_rate": 1.2559547840129189e-05,
      "loss": 0.0312,
      "step": 18430
    },
    {
      "epoch": 7.444489301574485,
      "grad_norm": 0.0013914963928982615,
      "learning_rate": 1.2555510698425515e-05,
      "loss": 0.0358,
      "step": 18440
    },
    {
      "epoch": 7.448526443278159,
      "grad_norm": 14.362532615661621,
      "learning_rate": 1.2551473556721843e-05,
      "loss": 0.0359,
      "step": 18450
    },
    {
      "epoch": 7.452563584981833,
      "grad_norm": 0.23404540121555328,
      "learning_rate": 1.2547436415018168e-05,
      "loss": 0.0383,
      "step": 18460
    },
    {
      "epoch": 7.456600726685506,
      "grad_norm": 0.11821155250072479,
      "learning_rate": 1.2543399273314494e-05,
      "loss": 0.0016,
      "step": 18470
    },
    {
      "epoch": 7.46063786838918,
      "grad_norm": 0.004779303912073374,
      "learning_rate": 1.2539362131610822e-05,
      "loss": 0.0253,
      "step": 18480
    },
    {
      "epoch": 7.464675010092854,
      "grad_norm": 0.003985316026955843,
      "learning_rate": 1.2535324989907147e-05,
      "loss": 0.0136,
      "step": 18490
    },
    {
      "epoch": 7.468712151796528,
      "grad_norm": 0.18142090737819672,
      "learning_rate": 1.2531287848203473e-05,
      "loss": 0.005,
      "step": 18500
    },
    {
      "epoch": 7.472749293500202,
      "grad_norm": 2.5370113849639893,
      "learning_rate": 1.2527250706499798e-05,
      "loss": 0.0203,
      "step": 18510
    },
    {
      "epoch": 7.476786435203875,
      "grad_norm": 0.9778153896331787,
      "learning_rate": 1.2523213564796126e-05,
      "loss": 0.0139,
      "step": 18520
    },
    {
      "epoch": 7.480823576907549,
      "grad_norm": 13.323507308959961,
      "learning_rate": 1.2519176423092452e-05,
      "loss": 0.035,
      "step": 18530
    },
    {
      "epoch": 7.484860718611223,
      "grad_norm": 0.011770746670663357,
      "learning_rate": 1.2515139281388777e-05,
      "loss": 0.0165,
      "step": 18540
    },
    {
      "epoch": 7.488897860314897,
      "grad_norm": 1.443307876586914,
      "learning_rate": 1.2511102139685103e-05,
      "loss": 0.0506,
      "step": 18550
    },
    {
      "epoch": 7.492935002018571,
      "grad_norm": 0.0013063109945505857,
      "learning_rate": 1.2507064997981431e-05,
      "loss": 0.0139,
      "step": 18560
    },
    {
      "epoch": 7.496972143722244,
      "grad_norm": 0.014617678709328175,
      "learning_rate": 1.2503027856277755e-05,
      "loss": 0.026,
      "step": 18570
    },
    {
      "epoch": 7.501009285425918,
      "grad_norm": 0.0022913359571248293,
      "learning_rate": 1.2498990714574082e-05,
      "loss": 0.0008,
      "step": 18580
    },
    {
      "epoch": 7.505046427129592,
      "grad_norm": 1.6174826622009277,
      "learning_rate": 1.249495357287041e-05,
      "loss": 0.0065,
      "step": 18590
    },
    {
      "epoch": 7.509083568833266,
      "grad_norm": 0.08342721313238144,
      "learning_rate": 1.2490916431166736e-05,
      "loss": 0.0113,
      "step": 18600
    },
    {
      "epoch": 7.51312071053694,
      "grad_norm": 0.002436403650790453,
      "learning_rate": 1.248687928946306e-05,
      "loss": 0.0607,
      "step": 18610
    },
    {
      "epoch": 7.517157852240613,
      "grad_norm": 0.8508592247962952,
      "learning_rate": 1.2482842147759387e-05,
      "loss": 0.0356,
      "step": 18620
    },
    {
      "epoch": 7.521194993944287,
      "grad_norm": 0.027220342308282852,
      "learning_rate": 1.2478805006055715e-05,
      "loss": 0.0339,
      "step": 18630
    },
    {
      "epoch": 7.525232135647961,
      "grad_norm": 0.011987815611064434,
      "learning_rate": 1.247476786435204e-05,
      "loss": 0.0095,
      "step": 18640
    },
    {
      "epoch": 7.529269277351635,
      "grad_norm": 0.010356610640883446,
      "learning_rate": 1.2470730722648366e-05,
      "loss": 0.023,
      "step": 18650
    },
    {
      "epoch": 7.533306419055309,
      "grad_norm": 0.002802017843350768,
      "learning_rate": 1.2466693580944694e-05,
      "loss": 0.0597,
      "step": 18660
    },
    {
      "epoch": 7.537343560758982,
      "grad_norm": 0.005725047085434198,
      "learning_rate": 1.2462656439241018e-05,
      "loss": 0.0242,
      "step": 18670
    },
    {
      "epoch": 7.541380702462656,
      "grad_norm": 1.1851153373718262,
      "learning_rate": 1.2458619297537345e-05,
      "loss": 0.0124,
      "step": 18680
    },
    {
      "epoch": 7.54541784416633,
      "grad_norm": 0.004065848421305418,
      "learning_rate": 1.245458215583367e-05,
      "loss": 0.0288,
      "step": 18690
    },
    {
      "epoch": 7.549454985870004,
      "grad_norm": 0.7208253741264343,
      "learning_rate": 1.2450545014129997e-05,
      "loss": 0.0161,
      "step": 18700
    },
    {
      "epoch": 7.553492127573678,
      "grad_norm": 0.7166386842727661,
      "learning_rate": 1.2446507872426323e-05,
      "loss": 0.0103,
      "step": 18710
    },
    {
      "epoch": 7.557529269277351,
      "grad_norm": 1.9075623750686646,
      "learning_rate": 1.2442470730722648e-05,
      "loss": 0.0162,
      "step": 18720
    },
    {
      "epoch": 7.561566410981025,
      "grad_norm": 2.15512752532959,
      "learning_rate": 1.2438433589018976e-05,
      "loss": 0.0192,
      "step": 18730
    },
    {
      "epoch": 7.565603552684699,
      "grad_norm": 0.9772019982337952,
      "learning_rate": 1.2434396447315302e-05,
      "loss": 0.0106,
      "step": 18740
    },
    {
      "epoch": 7.569640694388373,
      "grad_norm": 0.0006496054120361805,
      "learning_rate": 1.2430359305611629e-05,
      "loss": 0.0084,
      "step": 18750
    },
    {
      "epoch": 7.573677836092047,
      "grad_norm": 32.08388900756836,
      "learning_rate": 1.2426322163907953e-05,
      "loss": 0.0259,
      "step": 18760
    },
    {
      "epoch": 7.57771497779572,
      "grad_norm": 1.634406566619873,
      "learning_rate": 1.2422285022204281e-05,
      "loss": 0.0219,
      "step": 18770
    },
    {
      "epoch": 7.581752119499394,
      "grad_norm": 0.002247006166726351,
      "learning_rate": 1.2418247880500607e-05,
      "loss": 0.065,
      "step": 18780
    },
    {
      "epoch": 7.585789261203068,
      "grad_norm": 0.008687485009431839,
      "learning_rate": 1.2414210738796932e-05,
      "loss": 0.0219,
      "step": 18790
    },
    {
      "epoch": 7.589826402906742,
      "grad_norm": 0.6557982563972473,
      "learning_rate": 1.2410173597093258e-05,
      "loss": 0.0161,
      "step": 18800
    },
    {
      "epoch": 7.593863544610416,
      "grad_norm": 0.0011117963586002588,
      "learning_rate": 1.2406136455389586e-05,
      "loss": 0.0087,
      "step": 18810
    },
    {
      "epoch": 7.597900686314089,
      "grad_norm": 0.006540228147059679,
      "learning_rate": 1.2402099313685911e-05,
      "loss": 0.0096,
      "step": 18820
    },
    {
      "epoch": 7.601937828017763,
      "grad_norm": 0.004779697861522436,
      "learning_rate": 1.2398062171982237e-05,
      "loss": 0.0103,
      "step": 18830
    },
    {
      "epoch": 7.605974969721437,
      "grad_norm": 0.002683313563466072,
      "learning_rate": 1.2394025030278565e-05,
      "loss": 0.0241,
      "step": 18840
    },
    {
      "epoch": 7.610012111425111,
      "grad_norm": 0.09173799306154251,
      "learning_rate": 1.238998788857489e-05,
      "loss": 0.0349,
      "step": 18850
    },
    {
      "epoch": 7.614049253128785,
      "grad_norm": 0.027007197961211205,
      "learning_rate": 1.2385950746871216e-05,
      "loss": 0.0027,
      "step": 18860
    },
    {
      "epoch": 7.618086394832458,
      "grad_norm": 0.003312859684228897,
      "learning_rate": 1.238191360516754e-05,
      "loss": 0.0249,
      "step": 18870
    },
    {
      "epoch": 7.622123536536132,
      "grad_norm": 0.00998454075306654,
      "learning_rate": 1.2377876463463869e-05,
      "loss": 0.0063,
      "step": 18880
    },
    {
      "epoch": 7.626160678239806,
      "grad_norm": 3.4365246295928955,
      "learning_rate": 1.2373839321760195e-05,
      "loss": 0.018,
      "step": 18890
    },
    {
      "epoch": 7.63019781994348,
      "grad_norm": 0.0014300154289230704,
      "learning_rate": 1.2369802180056521e-05,
      "loss": 0.0084,
      "step": 18900
    },
    {
      "epoch": 7.634234961647154,
      "grad_norm": 0.007727351505309343,
      "learning_rate": 1.2365765038352848e-05,
      "loss": 0.0203,
      "step": 18910
    },
    {
      "epoch": 7.638272103350827,
      "grad_norm": 0.017314065247774124,
      "learning_rate": 1.2361727896649174e-05,
      "loss": 0.0198,
      "step": 18920
    },
    {
      "epoch": 7.642309245054501,
      "grad_norm": 0.08097533881664276,
      "learning_rate": 1.23576907549455e-05,
      "loss": 0.0004,
      "step": 18930
    },
    {
      "epoch": 7.646346386758175,
      "grad_norm": 25.460010528564453,
      "learning_rate": 1.2353653613241825e-05,
      "loss": 0.0344,
      "step": 18940
    },
    {
      "epoch": 7.650383528461849,
      "grad_norm": 0.0019640247337520123,
      "learning_rate": 1.2349616471538153e-05,
      "loss": 0.007,
      "step": 18950
    },
    {
      "epoch": 7.654420670165523,
      "grad_norm": 5.530426502227783,
      "learning_rate": 1.2345579329834479e-05,
      "loss": 0.0363,
      "step": 18960
    },
    {
      "epoch": 7.658457811869196,
      "grad_norm": 0.6618199944496155,
      "learning_rate": 1.2341542188130804e-05,
      "loss": 0.0095,
      "step": 18970
    },
    {
      "epoch": 7.66249495357287,
      "grad_norm": 0.0051130387000739574,
      "learning_rate": 1.233750504642713e-05,
      "loss": 0.05,
      "step": 18980
    },
    {
      "epoch": 7.666532095276544,
      "grad_norm": 5.942842483520508,
      "learning_rate": 1.2333467904723458e-05,
      "loss": 0.0427,
      "step": 18990
    },
    {
      "epoch": 7.670569236980218,
      "grad_norm": 2.5635623931884766,
      "learning_rate": 1.2329430763019782e-05,
      "loss": 0.025,
      "step": 19000
    },
    {
      "epoch": 7.674606378683892,
      "grad_norm": 0.5370029807090759,
      "learning_rate": 1.2325393621316109e-05,
      "loss": 0.0357,
      "step": 19010
    },
    {
      "epoch": 7.678643520387565,
      "grad_norm": 0.009540352039039135,
      "learning_rate": 1.2321356479612437e-05,
      "loss": 0.0127,
      "step": 19020
    },
    {
      "epoch": 7.682680662091239,
      "grad_norm": 0.01955011859536171,
      "learning_rate": 1.2317319337908761e-05,
      "loss": 0.0456,
      "step": 19030
    },
    {
      "epoch": 7.686717803794913,
      "grad_norm": 0.014393381774425507,
      "learning_rate": 1.2313282196205088e-05,
      "loss": 0.0142,
      "step": 19040
    },
    {
      "epoch": 7.690754945498587,
      "grad_norm": 0.019715262576937675,
      "learning_rate": 1.2309245054501414e-05,
      "loss": 0.0275,
      "step": 19050
    },
    {
      "epoch": 7.694792087202261,
      "grad_norm": 1.0323548316955566,
      "learning_rate": 1.230520791279774e-05,
      "loss": 0.0184,
      "step": 19060
    },
    {
      "epoch": 7.698829228905934,
      "grad_norm": 0.9555184245109558,
      "learning_rate": 1.2301170771094066e-05,
      "loss": 0.0262,
      "step": 19070
    },
    {
      "epoch": 7.702866370609608,
      "grad_norm": 3.2667083740234375,
      "learning_rate": 1.2297133629390393e-05,
      "loss": 0.0263,
      "step": 19080
    },
    {
      "epoch": 7.706903512313282,
      "grad_norm": 0.045377034693956375,
      "learning_rate": 1.2293096487686719e-05,
      "loss": 0.0179,
      "step": 19090
    },
    {
      "epoch": 7.710940654016956,
      "grad_norm": 0.09548487514257431,
      "learning_rate": 1.2289059345983045e-05,
      "loss": 0.0391,
      "step": 19100
    },
    {
      "epoch": 7.71497779572063,
      "grad_norm": 0.022246098145842552,
      "learning_rate": 1.2285022204279372e-05,
      "loss": 0.0225,
      "step": 19110
    },
    {
      "epoch": 7.719014937424303,
      "grad_norm": 0.002817552536725998,
      "learning_rate": 1.2280985062575696e-05,
      "loss": 0.0147,
      "step": 19120
    },
    {
      "epoch": 7.723052079127977,
      "grad_norm": 0.2804313898086548,
      "learning_rate": 1.2276947920872024e-05,
      "loss": 0.0084,
      "step": 19130
    },
    {
      "epoch": 7.727089220831651,
      "grad_norm": 1.1592410802841187,
      "learning_rate": 1.227291077916835e-05,
      "loss": 0.0044,
      "step": 19140
    },
    {
      "epoch": 7.731126362535325,
      "grad_norm": 0.010545141994953156,
      "learning_rate": 1.2268873637464675e-05,
      "loss": 0.0179,
      "step": 19150
    },
    {
      "epoch": 7.735163504238999,
      "grad_norm": 0.005410010926425457,
      "learning_rate": 1.2264836495761001e-05,
      "loss": 0.0285,
      "step": 19160
    },
    {
      "epoch": 7.739200645942672,
      "grad_norm": 0.017141222953796387,
      "learning_rate": 1.226079935405733e-05,
      "loss": 0.0302,
      "step": 19170
    },
    {
      "epoch": 7.743237787646346,
      "grad_norm": 1.4931079149246216,
      "learning_rate": 1.2256762212353654e-05,
      "loss": 0.0172,
      "step": 19180
    },
    {
      "epoch": 7.74727492935002,
      "grad_norm": 6.402813911437988,
      "learning_rate": 1.225272507064998e-05,
      "loss": 0.0203,
      "step": 19190
    },
    {
      "epoch": 7.751312071053694,
      "grad_norm": 1.7270584106445312,
      "learning_rate": 1.2248687928946308e-05,
      "loss": 0.0125,
      "step": 19200
    },
    {
      "epoch": 7.755349212757368,
      "grad_norm": 0.06555171310901642,
      "learning_rate": 1.2244650787242633e-05,
      "loss": 0.0002,
      "step": 19210
    },
    {
      "epoch": 7.759386354461042,
      "grad_norm": 0.007835522294044495,
      "learning_rate": 1.2240613645538959e-05,
      "loss": 0.0204,
      "step": 19220
    },
    {
      "epoch": 7.763423496164715,
      "grad_norm": 0.010665739886462688,
      "learning_rate": 1.2236576503835285e-05,
      "loss": 0.0126,
      "step": 19230
    },
    {
      "epoch": 7.767460637868389,
      "grad_norm": 0.0022092144936323166,
      "learning_rate": 1.2232539362131612e-05,
      "loss": 0.0116,
      "step": 19240
    },
    {
      "epoch": 7.771497779572063,
      "grad_norm": 1.3746987581253052,
      "learning_rate": 1.2228502220427938e-05,
      "loss": 0.0158,
      "step": 19250
    },
    {
      "epoch": 7.775534921275737,
      "grad_norm": 0.8941712975502014,
      "learning_rate": 1.2224465078724264e-05,
      "loss": 0.022,
      "step": 19260
    },
    {
      "epoch": 7.779572062979411,
      "grad_norm": 0.021131016314029694,
      "learning_rate": 1.2220427937020592e-05,
      "loss": 0.018,
      "step": 19270
    },
    {
      "epoch": 7.783609204683084,
      "grad_norm": 0.007186174858361483,
      "learning_rate": 1.2216390795316917e-05,
      "loss": 0.0216,
      "step": 19280
    },
    {
      "epoch": 7.787646346386758,
      "grad_norm": 6.6080427169799805,
      "learning_rate": 1.2212353653613243e-05,
      "loss": 0.0645,
      "step": 19290
    },
    {
      "epoch": 7.791683488090432,
      "grad_norm": 0.0017693864647299051,
      "learning_rate": 1.2208316511909568e-05,
      "loss": 0.0365,
      "step": 19300
    },
    {
      "epoch": 7.795720629794106,
      "grad_norm": 0.08602029085159302,
      "learning_rate": 1.2204279370205896e-05,
      "loss": 0.0229,
      "step": 19310
    },
    {
      "epoch": 7.79975777149778,
      "grad_norm": 0.02423456683754921,
      "learning_rate": 1.2200242228502222e-05,
      "loss": 0.0012,
      "step": 19320
    },
    {
      "epoch": 7.803794913201453,
      "grad_norm": 0.005102076567709446,
      "learning_rate": 1.2196205086798546e-05,
      "loss": 0.0224,
      "step": 19330
    },
    {
      "epoch": 7.807832054905127,
      "grad_norm": 31.57552146911621,
      "learning_rate": 1.2192167945094874e-05,
      "loss": 0.018,
      "step": 19340
    },
    {
      "epoch": 7.811869196608801,
      "grad_norm": 1.6623692512512207,
      "learning_rate": 1.21881308033912e-05,
      "loss": 0.0133,
      "step": 19350
    },
    {
      "epoch": 7.815906338312475,
      "grad_norm": 5.030890941619873,
      "learning_rate": 1.2184093661687525e-05,
      "loss": 0.043,
      "step": 19360
    },
    {
      "epoch": 7.819943480016149,
      "grad_norm": 0.005311550106853247,
      "learning_rate": 1.2180056519983852e-05,
      "loss": 0.0322,
      "step": 19370
    },
    {
      "epoch": 7.823980621719822,
      "grad_norm": 0.0006592096178792417,
      "learning_rate": 1.217601937828018e-05,
      "loss": 0.0148,
      "step": 19380
    },
    {
      "epoch": 7.828017763423496,
      "grad_norm": 0.0010305565083399415,
      "learning_rate": 1.2171982236576504e-05,
      "loss": 0.0233,
      "step": 19390
    },
    {
      "epoch": 7.83205490512717,
      "grad_norm": 0.0011605239706113935,
      "learning_rate": 1.216794509487283e-05,
      "loss": 0.0194,
      "step": 19400
    },
    {
      "epoch": 7.836092046830844,
      "grad_norm": 0.005645263008773327,
      "learning_rate": 1.2163907953169157e-05,
      "loss": 0.0285,
      "step": 19410
    },
    {
      "epoch": 7.840129188534518,
      "grad_norm": 0.0012679466744884849,
      "learning_rate": 1.2159870811465485e-05,
      "loss": 0.018,
      "step": 19420
    },
    {
      "epoch": 7.844166330238191,
      "grad_norm": 0.7617835998535156,
      "learning_rate": 1.215583366976181e-05,
      "loss": 0.0096,
      "step": 19430
    },
    {
      "epoch": 7.848203471941865,
      "grad_norm": 0.009950367733836174,
      "learning_rate": 1.2151796528058136e-05,
      "loss": 0.0146,
      "step": 19440
    },
    {
      "epoch": 7.852240613645539,
      "grad_norm": 2.1911163330078125,
      "learning_rate": 1.2147759386354464e-05,
      "loss": 0.026,
      "step": 19450
    },
    {
      "epoch": 7.856277755349213,
      "grad_norm": 1.5822465419769287,
      "learning_rate": 1.2143722244650788e-05,
      "loss": 0.0199,
      "step": 19460
    },
    {
      "epoch": 7.860314897052887,
      "grad_norm": 0.06646614521741867,
      "learning_rate": 1.2139685102947115e-05,
      "loss": 0.0221,
      "step": 19470
    },
    {
      "epoch": 7.86435203875656,
      "grad_norm": 0.004055209923535585,
      "learning_rate": 1.2135647961243439e-05,
      "loss": 0.0294,
      "step": 19480
    },
    {
      "epoch": 7.868389180460234,
      "grad_norm": 1.9795807600021362,
      "learning_rate": 1.2131610819539767e-05,
      "loss": 0.0432,
      "step": 19490
    },
    {
      "epoch": 7.872426322163908,
      "grad_norm": 0.08014466613531113,
      "learning_rate": 1.2127573677836093e-05,
      "loss": 0.0027,
      "step": 19500
    },
    {
      "epoch": 7.876463463867582,
      "grad_norm": 0.005324034485965967,
      "learning_rate": 1.2123536536132418e-05,
      "loss": 0.0379,
      "step": 19510
    },
    {
      "epoch": 7.880500605571256,
      "grad_norm": 0.1259448379278183,
      "learning_rate": 1.2119499394428746e-05,
      "loss": 0.0208,
      "step": 19520
    },
    {
      "epoch": 7.88453774727493,
      "grad_norm": 0.004183247219771147,
      "learning_rate": 1.2115462252725072e-05,
      "loss": 0.0131,
      "step": 19530
    },
    {
      "epoch": 7.888574888978603,
      "grad_norm": 0.0053459396585822105,
      "learning_rate": 1.2111425111021397e-05,
      "loss": 0.0271,
      "step": 19540
    },
    {
      "epoch": 7.892612030682277,
      "grad_norm": 0.001164735178463161,
      "learning_rate": 1.2107387969317723e-05,
      "loss": 0.0359,
      "step": 19550
    },
    {
      "epoch": 7.896649172385951,
      "grad_norm": 0.0033399625681340694,
      "learning_rate": 1.2103350827614051e-05,
      "loss": 0.0738,
      "step": 19560
    },
    {
      "epoch": 7.900686314089625,
      "grad_norm": 0.0732063353061676,
      "learning_rate": 1.2099313685910377e-05,
      "loss": 0.0313,
      "step": 19570
    },
    {
      "epoch": 7.904723455793299,
      "grad_norm": 0.04705652594566345,
      "learning_rate": 1.2095276544206702e-05,
      "loss": 0.0082,
      "step": 19580
    },
    {
      "epoch": 7.908760597496972,
      "grad_norm": 0.9540029168128967,
      "learning_rate": 1.2091239402503028e-05,
      "loss": 0.0231,
      "step": 19590
    },
    {
      "epoch": 7.912797739200646,
      "grad_norm": 0.10430624336004257,
      "learning_rate": 1.2087202260799356e-05,
      "loss": 0.0548,
      "step": 19600
    },
    {
      "epoch": 7.91683488090432,
      "grad_norm": 0.8267818689346313,
      "learning_rate": 1.208316511909568e-05,
      "loss": 0.0204,
      "step": 19610
    },
    {
      "epoch": 7.920872022607994,
      "grad_norm": 2.696479082107544,
      "learning_rate": 1.2079127977392007e-05,
      "loss": 0.0151,
      "step": 19620
    },
    {
      "epoch": 7.924909164311668,
      "grad_norm": 0.002633195137605071,
      "learning_rate": 1.2075090835688335e-05,
      "loss": 0.0019,
      "step": 19630
    },
    {
      "epoch": 7.928946306015341,
      "grad_norm": 0.004198606591671705,
      "learning_rate": 1.207105369398466e-05,
      "loss": 0.0068,
      "step": 19640
    },
    {
      "epoch": 7.932983447719015,
      "grad_norm": 3.257378101348877,
      "learning_rate": 1.2067016552280986e-05,
      "loss": 0.0386,
      "step": 19650
    },
    {
      "epoch": 7.937020589422689,
      "grad_norm": 3.591069459915161,
      "learning_rate": 1.206297941057731e-05,
      "loss": 0.0395,
      "step": 19660
    },
    {
      "epoch": 7.941057731126363,
      "grad_norm": 0.008544335141777992,
      "learning_rate": 1.2058942268873639e-05,
      "loss": 0.0041,
      "step": 19670
    },
    {
      "epoch": 7.945094872830037,
      "grad_norm": 0.0014215176925063133,
      "learning_rate": 1.2054905127169965e-05,
      "loss": 0.0048,
      "step": 19680
    },
    {
      "epoch": 7.94913201453371,
      "grad_norm": 0.09804250299930573,
      "learning_rate": 1.205086798546629e-05,
      "loss": 0.0153,
      "step": 19690
    },
    {
      "epoch": 7.953169156237384,
      "grad_norm": 0.08267306536436081,
      "learning_rate": 1.2046830843762617e-05,
      "loss": 0.0211,
      "step": 19700
    },
    {
      "epoch": 7.957206297941058,
      "grad_norm": 0.06397794932126999,
      "learning_rate": 1.2042793702058944e-05,
      "loss": 0.0179,
      "step": 19710
    },
    {
      "epoch": 7.961243439644732,
      "grad_norm": 0.0006828347686678171,
      "learning_rate": 1.203875656035527e-05,
      "loss": 0.0034,
      "step": 19720
    },
    {
      "epoch": 7.965280581348406,
      "grad_norm": 0.01837570033967495,
      "learning_rate": 1.2034719418651595e-05,
      "loss": 0.0113,
      "step": 19730
    },
    {
      "epoch": 7.969317723052079,
      "grad_norm": 1.784367322921753,
      "learning_rate": 1.2030682276947923e-05,
      "loss": 0.0157,
      "step": 19740
    },
    {
      "epoch": 7.973354864755753,
      "grad_norm": 0.0008602730231359601,
      "learning_rate": 1.2026645135244249e-05,
      "loss": 0.0282,
      "step": 19750
    },
    {
      "epoch": 7.977392006459427,
      "grad_norm": 0.019146839156746864,
      "learning_rate": 1.2022607993540573e-05,
      "loss": 0.0132,
      "step": 19760
    },
    {
      "epoch": 7.981429148163101,
      "grad_norm": 0.0025913389399647713,
      "learning_rate": 1.2018570851836901e-05,
      "loss": 0.0097,
      "step": 19770
    },
    {
      "epoch": 7.985466289866775,
      "grad_norm": 0.03556809201836586,
      "learning_rate": 1.2014533710133228e-05,
      "loss": 0.0084,
      "step": 19780
    },
    {
      "epoch": 7.989503431570448,
      "grad_norm": 0.0980105847120285,
      "learning_rate": 1.2010496568429552e-05,
      "loss": 0.0121,
      "step": 19790
    },
    {
      "epoch": 7.993540573274122,
      "grad_norm": 0.0006765291909687221,
      "learning_rate": 1.2006459426725879e-05,
      "loss": 0.0122,
      "step": 19800
    },
    {
      "epoch": 7.997577714977796,
      "grad_norm": 0.009205933660268784,
      "learning_rate": 1.2002422285022207e-05,
      "loss": 0.0002,
      "step": 19810
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9838836477987422,
      "eval_f1": 0.9414453013424735,
      "eval_loss": 0.060246873646974564,
      "eval_precision": 0.935831913685406,
      "eval_recall": 0.9471264367816092,
      "eval_runtime": 446.6152,
      "eval_samples_per_second": 28.526,
      "eval_steps_per_second": 1.189,
      "step": 19816
    },
    {
      "epoch": 8.001614856681469,
      "grad_norm": 0.0005392783205024898,
      "learning_rate": 1.1998385143318531e-05,
      "loss": 0.0044,
      "step": 19820
    },
    {
      "epoch": 8.005651998385144,
      "grad_norm": 1.5116254091262817,
      "learning_rate": 1.1994348001614857e-05,
      "loss": 0.0354,
      "step": 19830
    },
    {
      "epoch": 8.009689140088817,
      "grad_norm": 0.014390937983989716,
      "learning_rate": 1.1990310859911182e-05,
      "loss": 0.0112,
      "step": 19840
    },
    {
      "epoch": 8.013726281792492,
      "grad_norm": 0.0011795518221333623,
      "learning_rate": 1.198627371820751e-05,
      "loss": 0.0171,
      "step": 19850
    },
    {
      "epoch": 8.017763423496165,
      "grad_norm": 0.007230320479720831,
      "learning_rate": 1.1982236576503836e-05,
      "loss": 0.0036,
      "step": 19860
    },
    {
      "epoch": 8.021800565199838,
      "grad_norm": 4.040022850036621,
      "learning_rate": 1.1978199434800163e-05,
      "loss": 0.0497,
      "step": 19870
    },
    {
      "epoch": 8.025837706903513,
      "grad_norm": 0.007044052239507437,
      "learning_rate": 1.1974162293096489e-05,
      "loss": 0.0114,
      "step": 19880
    },
    {
      "epoch": 8.029874848607186,
      "grad_norm": 2.2424678802490234,
      "learning_rate": 1.1970125151392815e-05,
      "loss": 0.0337,
      "step": 19890
    },
    {
      "epoch": 8.03391199031086,
      "grad_norm": 1.65120530128479,
      "learning_rate": 1.1966088009689141e-05,
      "loss": 0.0153,
      "step": 19900
    },
    {
      "epoch": 8.037949132014534,
      "grad_norm": 0.4085404872894287,
      "learning_rate": 1.1962050867985466e-05,
      "loss": 0.0072,
      "step": 19910
    },
    {
      "epoch": 8.041986273718207,
      "grad_norm": 5.905406951904297,
      "learning_rate": 1.1958013726281794e-05,
      "loss": 0.0349,
      "step": 19920
    },
    {
      "epoch": 8.046023415421882,
      "grad_norm": 0.007148699834942818,
      "learning_rate": 1.195397658457812e-05,
      "loss": 0.0067,
      "step": 19930
    },
    {
      "epoch": 8.050060557125555,
      "grad_norm": 0.7970741987228394,
      "learning_rate": 1.1949939442874445e-05,
      "loss": 0.0062,
      "step": 19940
    },
    {
      "epoch": 8.05409769882923,
      "grad_norm": 0.025447342544794083,
      "learning_rate": 1.1945902301170773e-05,
      "loss": 0.0458,
      "step": 19950
    },
    {
      "epoch": 8.058134840532903,
      "grad_norm": 1.3949636220932007,
      "learning_rate": 1.19418651594671e-05,
      "loss": 0.0164,
      "step": 19960
    },
    {
      "epoch": 8.062171982236576,
      "grad_norm": 0.016990752890706062,
      "learning_rate": 1.1937828017763424e-05,
      "loss": 0.0112,
      "step": 19970
    },
    {
      "epoch": 8.06620912394025,
      "grad_norm": 0.8943023681640625,
      "learning_rate": 1.193379087605975e-05,
      "loss": 0.0072,
      "step": 19980
    },
    {
      "epoch": 8.070246265643924,
      "grad_norm": 0.0672181099653244,
      "learning_rate": 1.1929753734356078e-05,
      "loss": 0.0127,
      "step": 19990
    },
    {
      "epoch": 8.074283407347599,
      "grad_norm": 1.2515344619750977,
      "learning_rate": 1.1925716592652403e-05,
      "loss": 0.0596,
      "step": 20000
    },
    {
      "epoch": 8.078320549051272,
      "grad_norm": 0.0013862154446542263,
      "learning_rate": 1.1921679450948729e-05,
      "loss": 0.0042,
      "step": 20010
    },
    {
      "epoch": 8.082357690754945,
      "grad_norm": 26.79981803894043,
      "learning_rate": 1.1917642309245055e-05,
      "loss": 0.0568,
      "step": 20020
    },
    {
      "epoch": 8.08639483245862,
      "grad_norm": 0.24806970357894897,
      "learning_rate": 1.1913605167541381e-05,
      "loss": 0.0036,
      "step": 20030
    },
    {
      "epoch": 8.090431974162293,
      "grad_norm": 0.010185016319155693,
      "learning_rate": 1.1909568025837708e-05,
      "loss": 0.0574,
      "step": 20040
    },
    {
      "epoch": 8.094469115865968,
      "grad_norm": 0.08721873164176941,
      "learning_rate": 1.1905530884134034e-05,
      "loss": 0.0384,
      "step": 20050
    },
    {
      "epoch": 8.09850625756964,
      "grad_norm": 0.012292779050767422,
      "learning_rate": 1.190149374243036e-05,
      "loss": 0.0082,
      "step": 20060
    },
    {
      "epoch": 8.102543399273314,
      "grad_norm": 0.018162699416279793,
      "learning_rate": 1.1897456600726687e-05,
      "loss": 0.0101,
      "step": 20070
    },
    {
      "epoch": 8.106580540976989,
      "grad_norm": 1.1425217390060425,
      "learning_rate": 1.1893419459023013e-05,
      "loss": 0.0131,
      "step": 20080
    },
    {
      "epoch": 8.110617682680662,
      "grad_norm": 0.10383772850036621,
      "learning_rate": 1.1889382317319338e-05,
      "loss": 0.0004,
      "step": 20090
    },
    {
      "epoch": 8.114654824384337,
      "grad_norm": 0.001606724108569324,
      "learning_rate": 1.1885345175615665e-05,
      "loss": 0.009,
      "step": 20100
    },
    {
      "epoch": 8.11869196608801,
      "grad_norm": 0.00685612577944994,
      "learning_rate": 1.1881308033911992e-05,
      "loss": 0.0355,
      "step": 20110
    },
    {
      "epoch": 8.122729107791683,
      "grad_norm": 0.013445630669593811,
      "learning_rate": 1.1877270892208316e-05,
      "loss": 0.0026,
      "step": 20120
    },
    {
      "epoch": 8.126766249495358,
      "grad_norm": 1.5158973932266235,
      "learning_rate": 1.1873233750504644e-05,
      "loss": 0.0171,
      "step": 20130
    },
    {
      "epoch": 8.13080339119903,
      "grad_norm": 0.009481800720095634,
      "learning_rate": 1.186919660880097e-05,
      "loss": 0.0111,
      "step": 20140
    },
    {
      "epoch": 8.134840532902706,
      "grad_norm": 0.0005782453808933496,
      "learning_rate": 1.1865159467097295e-05,
      "loss": 0.0112,
      "step": 20150
    },
    {
      "epoch": 8.138877674606379,
      "grad_norm": 0.0019698170945048332,
      "learning_rate": 1.1861122325393622e-05,
      "loss": 0.0214,
      "step": 20160
    },
    {
      "epoch": 8.142914816310052,
      "grad_norm": 0.00226271222345531,
      "learning_rate": 1.185708518368995e-05,
      "loss": 0.0078,
      "step": 20170
    },
    {
      "epoch": 8.146951958013727,
      "grad_norm": 0.000706296821590513,
      "learning_rate": 1.1853048041986274e-05,
      "loss": 0.0202,
      "step": 20180
    },
    {
      "epoch": 8.1509890997174,
      "grad_norm": 0.0005366945406422019,
      "learning_rate": 1.18490109002826e-05,
      "loss": 0.0075,
      "step": 20190
    },
    {
      "epoch": 8.155026241421075,
      "grad_norm": 1.1721456050872803,
      "learning_rate": 1.1844973758578928e-05,
      "loss": 0.0125,
      "step": 20200
    },
    {
      "epoch": 8.159063383124748,
      "grad_norm": 0.027094779536128044,
      "learning_rate": 1.1840936616875253e-05,
      "loss": 0.0085,
      "step": 20210
    },
    {
      "epoch": 8.16310052482842,
      "grad_norm": 1.8737143278121948,
      "learning_rate": 1.183689947517158e-05,
      "loss": 0.0051,
      "step": 20220
    },
    {
      "epoch": 8.167137666532096,
      "grad_norm": 0.000557555875275284,
      "learning_rate": 1.1832862333467906e-05,
      "loss": 0.0329,
      "step": 20230
    },
    {
      "epoch": 8.171174808235769,
      "grad_norm": 0.012626220472157001,
      "learning_rate": 1.1828825191764234e-05,
      "loss": 0.0122,
      "step": 20240
    },
    {
      "epoch": 8.175211949939444,
      "grad_norm": 0.009137822315096855,
      "learning_rate": 1.1824788050060558e-05,
      "loss": 0.0033,
      "step": 20250
    },
    {
      "epoch": 8.179249091643117,
      "grad_norm": 0.002918374026194215,
      "learning_rate": 1.1820750908356884e-05,
      "loss": 0.0161,
      "step": 20260
    },
    {
      "epoch": 8.18328623334679,
      "grad_norm": 0.019701117649674416,
      "learning_rate": 1.1816713766653209e-05,
      "loss": 0.0062,
      "step": 20270
    },
    {
      "epoch": 8.187323375050465,
      "grad_norm": 0.017521381378173828,
      "learning_rate": 1.1812676624949537e-05,
      "loss": 0.0079,
      "step": 20280
    },
    {
      "epoch": 8.191360516754138,
      "grad_norm": 1.4722867012023926,
      "learning_rate": 1.1808639483245863e-05,
      "loss": 0.0436,
      "step": 20290
    },
    {
      "epoch": 8.195397658457813,
      "grad_norm": 0.3954065144062042,
      "learning_rate": 1.1804602341542188e-05,
      "loss": 0.0325,
      "step": 20300
    },
    {
      "epoch": 8.199434800161486,
      "grad_norm": 0.024852383881807327,
      "learning_rate": 1.1800565199838516e-05,
      "loss": 0.0256,
      "step": 20310
    },
    {
      "epoch": 8.203471941865159,
      "grad_norm": 0.0007089308346621692,
      "learning_rate": 1.1796528058134842e-05,
      "loss": 0.0214,
      "step": 20320
    },
    {
      "epoch": 8.207509083568834,
      "grad_norm": 0.001411609468050301,
      "learning_rate": 1.1792490916431167e-05,
      "loss": 0.0147,
      "step": 20330
    },
    {
      "epoch": 8.211546225272507,
      "grad_norm": 0.0007645075093023479,
      "learning_rate": 1.1788453774727493e-05,
      "loss": 0.0033,
      "step": 20340
    },
    {
      "epoch": 8.215583366976182,
      "grad_norm": 0.05986325442790985,
      "learning_rate": 1.1784416633023821e-05,
      "loss": 0.0332,
      "step": 20350
    },
    {
      "epoch": 8.219620508679855,
      "grad_norm": 0.0012979325838387012,
      "learning_rate": 1.1780379491320146e-05,
      "loss": 0.0166,
      "step": 20360
    },
    {
      "epoch": 8.223657650383528,
      "grad_norm": 17.384435653686523,
      "learning_rate": 1.1776342349616472e-05,
      "loss": 0.0508,
      "step": 20370
    },
    {
      "epoch": 8.227694792087203,
      "grad_norm": 0.0015236458275467157,
      "learning_rate": 1.17723052079128e-05,
      "loss": 0.011,
      "step": 20380
    },
    {
      "epoch": 8.231731933790876,
      "grad_norm": 4.565437316894531,
      "learning_rate": 1.1768268066209126e-05,
      "loss": 0.0463,
      "step": 20390
    },
    {
      "epoch": 8.23576907549455,
      "grad_norm": 1.4480692148208618,
      "learning_rate": 1.176423092450545e-05,
      "loss": 0.0173,
      "step": 20400
    },
    {
      "epoch": 8.239806217198224,
      "grad_norm": 0.00788107793778181,
      "learning_rate": 1.1760193782801777e-05,
      "loss": 0.0113,
      "step": 20410
    },
    {
      "epoch": 8.243843358901897,
      "grad_norm": 0.03763420507311821,
      "learning_rate": 1.1756156641098105e-05,
      "loss": 0.0102,
      "step": 20420
    },
    {
      "epoch": 8.247880500605572,
      "grad_norm": 0.7897327542304993,
      "learning_rate": 1.175211949939443e-05,
      "loss": 0.0079,
      "step": 20430
    },
    {
      "epoch": 8.251917642309245,
      "grad_norm": 0.0066602397710084915,
      "learning_rate": 1.1748082357690756e-05,
      "loss": 0.0046,
      "step": 20440
    },
    {
      "epoch": 8.25595478401292,
      "grad_norm": 17.243677139282227,
      "learning_rate": 1.174404521598708e-05,
      "loss": 0.0378,
      "step": 20450
    },
    {
      "epoch": 8.259991925716593,
      "grad_norm": 1.3431633710861206,
      "learning_rate": 1.1740008074283408e-05,
      "loss": 0.0126,
      "step": 20460
    },
    {
      "epoch": 8.264029067420266,
      "grad_norm": 0.0024750058073550463,
      "learning_rate": 1.1735970932579735e-05,
      "loss": 0.018,
      "step": 20470
    },
    {
      "epoch": 8.26806620912394,
      "grad_norm": 0.0008917867671698332,
      "learning_rate": 1.173193379087606e-05,
      "loss": 0.0206,
      "step": 20480
    },
    {
      "epoch": 8.272103350827614,
      "grad_norm": 0.011064800433814526,
      "learning_rate": 1.1727896649172387e-05,
      "loss": 0.0171,
      "step": 20490
    },
    {
      "epoch": 8.276140492531288,
      "grad_norm": 0.0015013590455055237,
      "learning_rate": 1.1723859507468714e-05,
      "loss": 0.0054,
      "step": 20500
    },
    {
      "epoch": 8.280177634234962,
      "grad_norm": 0.0033371634781360626,
      "learning_rate": 1.1719822365765038e-05,
      "loss": 0.0134,
      "step": 20510
    },
    {
      "epoch": 8.284214775938635,
      "grad_norm": 0.0004387587250676006,
      "learning_rate": 1.1715785224061364e-05,
      "loss": 0.012,
      "step": 20520
    },
    {
      "epoch": 8.28825191764231,
      "grad_norm": 0.0031667950097471476,
      "learning_rate": 1.1711748082357692e-05,
      "loss": 0.0242,
      "step": 20530
    },
    {
      "epoch": 8.292289059345983,
      "grad_norm": 1.5197983980178833,
      "learning_rate": 1.1707710940654019e-05,
      "loss": 0.0087,
      "step": 20540
    },
    {
      "epoch": 8.296326201049657,
      "grad_norm": 0.23357048630714417,
      "learning_rate": 1.1703673798950343e-05,
      "loss": 0.0218,
      "step": 20550
    },
    {
      "epoch": 8.30036334275333,
      "grad_norm": 1.3165433406829834,
      "learning_rate": 1.1699636657246671e-05,
      "loss": 0.0154,
      "step": 20560
    },
    {
      "epoch": 8.304400484457004,
      "grad_norm": 2.2182326316833496,
      "learning_rate": 1.1695599515542998e-05,
      "loss": 0.0149,
      "step": 20570
    },
    {
      "epoch": 8.308437626160678,
      "grad_norm": 0.013479831628501415,
      "learning_rate": 1.1691562373839322e-05,
      "loss": 0.0057,
      "step": 20580
    },
    {
      "epoch": 8.312474767864352,
      "grad_norm": 1.141020655632019,
      "learning_rate": 1.1687525232135648e-05,
      "loss": 0.0137,
      "step": 20590
    },
    {
      "epoch": 8.316511909568026,
      "grad_norm": 0.17151077091693878,
      "learning_rate": 1.1683488090431976e-05,
      "loss": 0.0131,
      "step": 20600
    },
    {
      "epoch": 8.3205490512717,
      "grad_norm": 0.0014666813658550382,
      "learning_rate": 1.1679450948728301e-05,
      "loss": 0.0236,
      "step": 20610
    },
    {
      "epoch": 8.324586192975373,
      "grad_norm": 0.0011818151688203216,
      "learning_rate": 1.1675413807024627e-05,
      "loss": 0.0065,
      "step": 20620
    },
    {
      "epoch": 8.328623334679047,
      "grad_norm": 0.0012562914052978158,
      "learning_rate": 1.1671376665320955e-05,
      "loss": 0.0,
      "step": 20630
    },
    {
      "epoch": 8.33266047638272,
      "grad_norm": 0.9182899594306946,
      "learning_rate": 1.166733952361728e-05,
      "loss": 0.0077,
      "step": 20640
    },
    {
      "epoch": 8.336697618086395,
      "grad_norm": 0.001236335257999599,
      "learning_rate": 1.1663302381913606e-05,
      "loss": 0.0092,
      "step": 20650
    },
    {
      "epoch": 8.340734759790069,
      "grad_norm": 3.0532736778259277,
      "learning_rate": 1.165926524020993e-05,
      "loss": 0.0325,
      "step": 20660
    },
    {
      "epoch": 8.344771901493742,
      "grad_norm": 0.00047301375889219344,
      "learning_rate": 1.1655228098506259e-05,
      "loss": 0.0145,
      "step": 20670
    },
    {
      "epoch": 8.348809043197416,
      "grad_norm": 0.0007582654361613095,
      "learning_rate": 1.1651190956802585e-05,
      "loss": 0.0079,
      "step": 20680
    },
    {
      "epoch": 8.35284618490109,
      "grad_norm": 0.0009108379599638283,
      "learning_rate": 1.1647153815098911e-05,
      "loss": 0.0155,
      "step": 20690
    },
    {
      "epoch": 8.356883326604764,
      "grad_norm": 0.010955318808555603,
      "learning_rate": 1.1643116673395236e-05,
      "loss": 0.0099,
      "step": 20700
    },
    {
      "epoch": 8.360920468308437,
      "grad_norm": 0.0003949237579945475,
      "learning_rate": 1.1639079531691564e-05,
      "loss": 0.0073,
      "step": 20710
    },
    {
      "epoch": 8.36495761001211,
      "grad_norm": 0.004633291624486446,
      "learning_rate": 1.163504238998789e-05,
      "loss": 0.0169,
      "step": 20720
    },
    {
      "epoch": 8.368994751715785,
      "grad_norm": 1.5686556100845337,
      "learning_rate": 1.1631005248284215e-05,
      "loss": 0.0206,
      "step": 20730
    },
    {
      "epoch": 8.373031893419459,
      "grad_norm": 0.0005825277767144144,
      "learning_rate": 1.1626968106580543e-05,
      "loss": 0.0007,
      "step": 20740
    },
    {
      "epoch": 8.377069035123133,
      "grad_norm": 0.002096249023452401,
      "learning_rate": 1.1622930964876869e-05,
      "loss": 0.0123,
      "step": 20750
    },
    {
      "epoch": 8.381106176826806,
      "grad_norm": 0.0003606037062127143,
      "learning_rate": 1.1618893823173194e-05,
      "loss": 0.0073,
      "step": 20760
    },
    {
      "epoch": 8.38514331853048,
      "grad_norm": 0.0006202841177582741,
      "learning_rate": 1.161485668146952e-05,
      "loss": 0.0048,
      "step": 20770
    },
    {
      "epoch": 8.389180460234154,
      "grad_norm": 0.0013264110311865807,
      "learning_rate": 1.1610819539765848e-05,
      "loss": 0.0048,
      "step": 20780
    },
    {
      "epoch": 8.393217601937828,
      "grad_norm": 0.0007997381617315114,
      "learning_rate": 1.1606782398062173e-05,
      "loss": 0.0129,
      "step": 20790
    },
    {
      "epoch": 8.397254743641502,
      "grad_norm": 0.00019710062770172954,
      "learning_rate": 1.1602745256358499e-05,
      "loss": 0.0201,
      "step": 20800
    },
    {
      "epoch": 8.401291885345175,
      "grad_norm": 0.0004294628743082285,
      "learning_rate": 1.1598708114654827e-05,
      "loss": 0.0031,
      "step": 20810
    },
    {
      "epoch": 8.40532902704885,
      "grad_norm": 0.0006995648145675659,
      "learning_rate": 1.1594670972951151e-05,
      "loss": 0.0103,
      "step": 20820
    },
    {
      "epoch": 8.409366168752523,
      "grad_norm": 1.5781883001327515,
      "learning_rate": 1.1590633831247478e-05,
      "loss": 0.0897,
      "step": 20830
    },
    {
      "epoch": 8.413403310456196,
      "grad_norm": 0.0020813841838389635,
      "learning_rate": 1.1586596689543804e-05,
      "loss": 0.0,
      "step": 20840
    },
    {
      "epoch": 8.417440452159871,
      "grad_norm": 10.303330421447754,
      "learning_rate": 1.158255954784013e-05,
      "loss": 0.0171,
      "step": 20850
    },
    {
      "epoch": 8.421477593863544,
      "grad_norm": 3.6848537921905518,
      "learning_rate": 1.1578522406136457e-05,
      "loss": 0.0509,
      "step": 20860
    },
    {
      "epoch": 8.42551473556722,
      "grad_norm": 0.0031702094711363316,
      "learning_rate": 1.1574485264432783e-05,
      "loss": 0.0248,
      "step": 20870
    },
    {
      "epoch": 8.429551877270892,
      "grad_norm": 0.0005944353179074824,
      "learning_rate": 1.1570448122729107e-05,
      "loss": 0.0133,
      "step": 20880
    },
    {
      "epoch": 8.433589018974565,
      "grad_norm": 0.0005049809697084129,
      "learning_rate": 1.1566410981025435e-05,
      "loss": 0.0056,
      "step": 20890
    },
    {
      "epoch": 8.43762616067824,
      "grad_norm": 0.0018353776540607214,
      "learning_rate": 1.1562373839321762e-05,
      "loss": 0.0127,
      "step": 20900
    },
    {
      "epoch": 8.441663302381913,
      "grad_norm": 0.7038222551345825,
      "learning_rate": 1.1558336697618086e-05,
      "loss": 0.0017,
      "step": 20910
    },
    {
      "epoch": 8.445700444085588,
      "grad_norm": 0.000716791779268533,
      "learning_rate": 1.1554299555914414e-05,
      "loss": 0.0103,
      "step": 20920
    },
    {
      "epoch": 8.449737585789261,
      "grad_norm": 0.2047237753868103,
      "learning_rate": 1.155026241421074e-05,
      "loss": 0.0173,
      "step": 20930
    },
    {
      "epoch": 8.453774727492934,
      "grad_norm": 0.0007186559960246086,
      "learning_rate": 1.1546225272507065e-05,
      "loss": 0.0179,
      "step": 20940
    },
    {
      "epoch": 8.45781186919661,
      "grad_norm": 0.010386952199041843,
      "learning_rate": 1.1542188130803391e-05,
      "loss": 0.0048,
      "step": 20950
    },
    {
      "epoch": 8.461849010900282,
      "grad_norm": 0.8326563239097595,
      "learning_rate": 1.153815098909972e-05,
      "loss": 0.0299,
      "step": 20960
    },
    {
      "epoch": 8.465886152603957,
      "grad_norm": 2.5974936485290527,
      "learning_rate": 1.1534113847396044e-05,
      "loss": 0.0049,
      "step": 20970
    },
    {
      "epoch": 8.46992329430763,
      "grad_norm": 0.0005366955301724374,
      "learning_rate": 1.153007670569237e-05,
      "loss": 0.0026,
      "step": 20980
    },
    {
      "epoch": 8.473960436011303,
      "grad_norm": 0.0005588406347669661,
      "learning_rate": 1.1526039563988698e-05,
      "loss": 0.0033,
      "step": 20990
    },
    {
      "epoch": 8.477997577714978,
      "grad_norm": 0.0017616698751226068,
      "learning_rate": 1.1522002422285023e-05,
      "loss": 0.0103,
      "step": 21000
    },
    {
      "epoch": 8.482034719418651,
      "grad_norm": 0.0006703013204969466,
      "learning_rate": 1.1517965280581349e-05,
      "loss": 0.0234,
      "step": 21010
    },
    {
      "epoch": 8.486071861122326,
      "grad_norm": 0.0009709462756291032,
      "learning_rate": 1.1513928138877675e-05,
      "loss": 0.0436,
      "step": 21020
    },
    {
      "epoch": 8.490109002826,
      "grad_norm": 0.0008009846205823123,
      "learning_rate": 1.1509890997174002e-05,
      "loss": 0.0365,
      "step": 21030
    },
    {
      "epoch": 8.494146144529672,
      "grad_norm": 0.000864270783495158,
      "learning_rate": 1.1505853855470328e-05,
      "loss": 0.013,
      "step": 21040
    },
    {
      "epoch": 8.498183286233347,
      "grad_norm": 0.08690904825925827,
      "learning_rate": 1.1501816713766654e-05,
      "loss": 0.0428,
      "step": 21050
    },
    {
      "epoch": 8.50222042793702,
      "grad_norm": 0.03307478502392769,
      "learning_rate": 1.1497779572062982e-05,
      "loss": 0.0556,
      "step": 21060
    },
    {
      "epoch": 8.506257569640695,
      "grad_norm": 0.0030102881137281656,
      "learning_rate": 1.1493742430359307e-05,
      "loss": 0.0159,
      "step": 21070
    },
    {
      "epoch": 8.510294711344368,
      "grad_norm": 1.034091591835022,
      "learning_rate": 1.1489705288655633e-05,
      "loss": 0.012,
      "step": 21080
    },
    {
      "epoch": 8.514331853048041,
      "grad_norm": 2.7543256282806396,
      "learning_rate": 1.1485668146951958e-05,
      "loss": 0.0123,
      "step": 21090
    },
    {
      "epoch": 8.518368994751716,
      "grad_norm": 0.002834123093634844,
      "learning_rate": 1.1481631005248286e-05,
      "loss": 0.0043,
      "step": 21100
    },
    {
      "epoch": 8.52240613645539,
      "grad_norm": 0.026213329285383224,
      "learning_rate": 1.1477593863544612e-05,
      "loss": 0.0619,
      "step": 21110
    },
    {
      "epoch": 8.526443278159064,
      "grad_norm": 0.003445808542892337,
      "learning_rate": 1.1473556721840937e-05,
      "loss": 0.0113,
      "step": 21120
    },
    {
      "epoch": 8.530480419862737,
      "grad_norm": 0.8484371304512024,
      "learning_rate": 1.1469519580137263e-05,
      "loss": 0.0102,
      "step": 21130
    },
    {
      "epoch": 8.53451756156641,
      "grad_norm": 0.02560913935303688,
      "learning_rate": 1.1465482438433591e-05,
      "loss": 0.0218,
      "step": 21140
    },
    {
      "epoch": 8.538554703270085,
      "grad_norm": 0.005020599812269211,
      "learning_rate": 1.1461445296729915e-05,
      "loss": 0.0082,
      "step": 21150
    },
    {
      "epoch": 8.542591844973758,
      "grad_norm": 1.8447070121765137,
      "learning_rate": 1.1457408155026242e-05,
      "loss": 0.0209,
      "step": 21160
    },
    {
      "epoch": 8.546628986677433,
      "grad_norm": 0.978929340839386,
      "learning_rate": 1.145337101332257e-05,
      "loss": 0.017,
      "step": 21170
    },
    {
      "epoch": 8.550666128381106,
      "grad_norm": 0.4930907189846039,
      "learning_rate": 1.1449333871618894e-05,
      "loss": 0.0017,
      "step": 21180
    },
    {
      "epoch": 8.55470327008478,
      "grad_norm": 0.40760481357574463,
      "learning_rate": 1.144529672991522e-05,
      "loss": 0.0054,
      "step": 21190
    },
    {
      "epoch": 8.558740411788454,
      "grad_norm": 0.006207274738699198,
      "learning_rate": 1.1441259588211547e-05,
      "loss": 0.0163,
      "step": 21200
    },
    {
      "epoch": 8.562777553492127,
      "grad_norm": 0.0028604590333998203,
      "learning_rate": 1.1437222446507875e-05,
      "loss": 0.0076,
      "step": 21210
    },
    {
      "epoch": 8.566814695195802,
      "grad_norm": 0.005771818570792675,
      "learning_rate": 1.14331853048042e-05,
      "loss": 0.0102,
      "step": 21220
    },
    {
      "epoch": 8.570851836899475,
      "grad_norm": 0.0059463209472596645,
      "learning_rate": 1.1429148163100526e-05,
      "loss": 0.0602,
      "step": 21230
    },
    {
      "epoch": 8.574888978603148,
      "grad_norm": 0.005140623543411493,
      "learning_rate": 1.1425111021396854e-05,
      "loss": 0.0104,
      "step": 21240
    },
    {
      "epoch": 8.578926120306823,
      "grad_norm": 0.002256577368825674,
      "learning_rate": 1.1421073879693178e-05,
      "loss": 0.0344,
      "step": 21250
    },
    {
      "epoch": 8.582963262010496,
      "grad_norm": 0.0018755624769255519,
      "learning_rate": 1.1417036737989505e-05,
      "loss": 0.0437,
      "step": 21260
    },
    {
      "epoch": 8.587000403714171,
      "grad_norm": 0.00267092976719141,
      "learning_rate": 1.141299959628583e-05,
      "loss": 0.0129,
      "step": 21270
    },
    {
      "epoch": 8.591037545417844,
      "grad_norm": 0.003373505314812064,
      "learning_rate": 1.1408962454582157e-05,
      "loss": 0.014,
      "step": 21280
    },
    {
      "epoch": 8.595074687121517,
      "grad_norm": 7.0120110511779785,
      "learning_rate": 1.1404925312878483e-05,
      "loss": 0.0527,
      "step": 21290
    },
    {
      "epoch": 8.599111828825192,
      "grad_norm": 0.0059256539680063725,
      "learning_rate": 1.1400888171174808e-05,
      "loss": 0.0268,
      "step": 21300
    },
    {
      "epoch": 8.603148970528865,
      "grad_norm": 0.00405259570106864,
      "learning_rate": 1.1396851029471134e-05,
      "loss": 0.0191,
      "step": 21310
    },
    {
      "epoch": 8.60718611223254,
      "grad_norm": 0.006892765406519175,
      "learning_rate": 1.1392813887767462e-05,
      "loss": 0.0108,
      "step": 21320
    },
    {
      "epoch": 8.611223253936213,
      "grad_norm": 0.007351231761276722,
      "learning_rate": 1.1388776746063787e-05,
      "loss": 0.0229,
      "step": 21330
    },
    {
      "epoch": 8.615260395639886,
      "grad_norm": 0.007669869344681501,
      "learning_rate": 1.1384739604360113e-05,
      "loss": 0.0067,
      "step": 21340
    },
    {
      "epoch": 8.619297537343561,
      "grad_norm": 2.9327332973480225,
      "learning_rate": 1.1380702462656441e-05,
      "loss": 0.0444,
      "step": 21350
    },
    {
      "epoch": 8.623334679047234,
      "grad_norm": 1.9850138425827026,
      "learning_rate": 1.1376665320952767e-05,
      "loss": 0.0155,
      "step": 21360
    },
    {
      "epoch": 8.62737182075091,
      "grad_norm": 0.13680699467658997,
      "learning_rate": 1.1372628179249092e-05,
      "loss": 0.0565,
      "step": 21370
    },
    {
      "epoch": 8.631408962454582,
      "grad_norm": 0.03362409025430679,
      "learning_rate": 1.1368591037545418e-05,
      "loss": 0.0431,
      "step": 21380
    },
    {
      "epoch": 8.635446104158255,
      "grad_norm": 1.5377697944641113,
      "learning_rate": 1.1364553895841746e-05,
      "loss": 0.0158,
      "step": 21390
    },
    {
      "epoch": 8.63948324586193,
      "grad_norm": 0.06509450078010559,
      "learning_rate": 1.1360516754138071e-05,
      "loss": 0.0024,
      "step": 21400
    },
    {
      "epoch": 8.643520387565603,
      "grad_norm": 0.009150665253400803,
      "learning_rate": 1.1356479612434397e-05,
      "loss": 0.0024,
      "step": 21410
    },
    {
      "epoch": 8.647557529269278,
      "grad_norm": 0.001519915764220059,
      "learning_rate": 1.1352442470730725e-05,
      "loss": 0.006,
      "step": 21420
    },
    {
      "epoch": 8.651594670972951,
      "grad_norm": 0.0018328833393752575,
      "learning_rate": 1.134840532902705e-05,
      "loss": 0.012,
      "step": 21430
    },
    {
      "epoch": 8.655631812676624,
      "grad_norm": 3.1314120292663574,
      "learning_rate": 1.1344368187323376e-05,
      "loss": 0.0241,
      "step": 21440
    },
    {
      "epoch": 8.6596689543803,
      "grad_norm": 0.20926296710968018,
      "learning_rate": 1.13403310456197e-05,
      "loss": 0.0083,
      "step": 21450
    },
    {
      "epoch": 8.663706096083972,
      "grad_norm": 0.001988170202821493,
      "learning_rate": 1.1336293903916029e-05,
      "loss": 0.0084,
      "step": 21460
    },
    {
      "epoch": 8.667743237787647,
      "grad_norm": 0.1180531233549118,
      "learning_rate": 1.1332256762212355e-05,
      "loss": 0.0051,
      "step": 21470
    },
    {
      "epoch": 8.67178037949132,
      "grad_norm": 0.0027030264027416706,
      "learning_rate": 1.132821962050868e-05,
      "loss": 0.0124,
      "step": 21480
    },
    {
      "epoch": 8.675817521194993,
      "grad_norm": 1.2388633489608765,
      "learning_rate": 1.1324182478805006e-05,
      "loss": 0.0495,
      "step": 21490
    },
    {
      "epoch": 8.679854662898668,
      "grad_norm": 0.0027900352142751217,
      "learning_rate": 1.1320145337101334e-05,
      "loss": 0.0331,
      "step": 21500
    },
    {
      "epoch": 8.683891804602341,
      "grad_norm": 8.551274299621582,
      "learning_rate": 1.131610819539766e-05,
      "loss": 0.09,
      "step": 21510
    },
    {
      "epoch": 8.687928946306016,
      "grad_norm": 3.287590265274048,
      "learning_rate": 1.1312071053693985e-05,
      "loss": 0.0977,
      "step": 21520
    },
    {
      "epoch": 8.69196608800969,
      "grad_norm": 0.27236229181289673,
      "learning_rate": 1.1308033911990313e-05,
      "loss": 0.0086,
      "step": 21530
    },
    {
      "epoch": 8.696003229713362,
      "grad_norm": 1.0672321319580078,
      "learning_rate": 1.1303996770286639e-05,
      "loss": 0.015,
      "step": 21540
    },
    {
      "epoch": 8.700040371417037,
      "grad_norm": 0.007344093173742294,
      "learning_rate": 1.1299959628582964e-05,
      "loss": 0.0004,
      "step": 21550
    },
    {
      "epoch": 8.70407751312071,
      "grad_norm": 0.11986421793699265,
      "learning_rate": 1.129592248687929e-05,
      "loss": 0.005,
      "step": 21560
    },
    {
      "epoch": 8.708114654824385,
      "grad_norm": 0.002670241054147482,
      "learning_rate": 1.1291885345175618e-05,
      "loss": 0.024,
      "step": 21570
    },
    {
      "epoch": 8.712151796528058,
      "grad_norm": 5.164099216461182,
      "learning_rate": 1.1287848203471942e-05,
      "loss": 0.0335,
      "step": 21580
    },
    {
      "epoch": 8.716188938231731,
      "grad_norm": 0.03497244790196419,
      "learning_rate": 1.1283811061768269e-05,
      "loss": 0.0126,
      "step": 21590
    },
    {
      "epoch": 8.720226079935406,
      "grad_norm": 0.004733951296657324,
      "learning_rate": 1.1279773920064597e-05,
      "loss": 0.0181,
      "step": 21600
    },
    {
      "epoch": 8.72426322163908,
      "grad_norm": 0.004296364728361368,
      "learning_rate": 1.1275736778360921e-05,
      "loss": 0.0163,
      "step": 21610
    },
    {
      "epoch": 8.728300363342754,
      "grad_norm": 0.01805945858359337,
      "learning_rate": 1.1271699636657248e-05,
      "loss": 0.0189,
      "step": 21620
    },
    {
      "epoch": 8.732337505046427,
      "grad_norm": 0.005439741536974907,
      "learning_rate": 1.1267662494953572e-05,
      "loss": 0.0007,
      "step": 21630
    },
    {
      "epoch": 8.7363746467501,
      "grad_norm": 1.3306825160980225,
      "learning_rate": 1.12636253532499e-05,
      "loss": 0.0126,
      "step": 21640
    },
    {
      "epoch": 8.740411788453775,
      "grad_norm": 0.008193357847630978,
      "learning_rate": 1.1259588211546226e-05,
      "loss": 0.0034,
      "step": 21650
    },
    {
      "epoch": 8.744448930157448,
      "grad_norm": 0.0018290019361302257,
      "learning_rate": 1.1255551069842553e-05,
      "loss": 0.0045,
      "step": 21660
    },
    {
      "epoch": 8.748486071861123,
      "grad_norm": 0.003561136545613408,
      "learning_rate": 1.1251513928138879e-05,
      "loss": 0.0641,
      "step": 21670
    },
    {
      "epoch": 8.752523213564796,
      "grad_norm": 0.005648425314575434,
      "learning_rate": 1.1247476786435205e-05,
      "loss": 0.0472,
      "step": 21680
    },
    {
      "epoch": 8.75656035526847,
      "grad_norm": 0.023739386349916458,
      "learning_rate": 1.1243439644731532e-05,
      "loss": 0.009,
      "step": 21690
    },
    {
      "epoch": 8.760597496972144,
      "grad_norm": 1.552106499671936,
      "learning_rate": 1.1239402503027856e-05,
      "loss": 0.029,
      "step": 21700
    },
    {
      "epoch": 8.764634638675817,
      "grad_norm": 1.1743675470352173,
      "learning_rate": 1.1235365361324184e-05,
      "loss": 0.0361,
      "step": 21710
    },
    {
      "epoch": 8.768671780379492,
      "grad_norm": 1.3887815475463867,
      "learning_rate": 1.123132821962051e-05,
      "loss": 0.0154,
      "step": 21720
    },
    {
      "epoch": 8.772708922083165,
      "grad_norm": 0.1171705573797226,
      "learning_rate": 1.1227291077916835e-05,
      "loss": 0.043,
      "step": 21730
    },
    {
      "epoch": 8.776746063786838,
      "grad_norm": 0.11453864723443985,
      "learning_rate": 1.1223253936213161e-05,
      "loss": 0.0045,
      "step": 21740
    },
    {
      "epoch": 8.780783205490513,
      "grad_norm": 0.01843988709151745,
      "learning_rate": 1.121921679450949e-05,
      "loss": 0.0127,
      "step": 21750
    },
    {
      "epoch": 8.784820347194186,
      "grad_norm": 0.04372885450720787,
      "learning_rate": 1.1215179652805814e-05,
      "loss": 0.0173,
      "step": 21760
    },
    {
      "epoch": 8.788857488897861,
      "grad_norm": 0.02846333757042885,
      "learning_rate": 1.121114251110214e-05,
      "loss": 0.0092,
      "step": 21770
    },
    {
      "epoch": 8.792894630601534,
      "grad_norm": 0.1529252976179123,
      "learning_rate": 1.1207105369398468e-05,
      "loss": 0.0107,
      "step": 21780
    },
    {
      "epoch": 8.796931772305207,
      "grad_norm": 0.010917605832219124,
      "learning_rate": 1.1203068227694793e-05,
      "loss": 0.0133,
      "step": 21790
    },
    {
      "epoch": 8.800968914008882,
      "grad_norm": 0.009412039071321487,
      "learning_rate": 1.1199031085991119e-05,
      "loss": 0.0166,
      "step": 21800
    },
    {
      "epoch": 8.805006055712555,
      "grad_norm": 0.014021337032318115,
      "learning_rate": 1.1194993944287444e-05,
      "loss": 0.0121,
      "step": 21810
    },
    {
      "epoch": 8.80904319741623,
      "grad_norm": 1.4021308422088623,
      "learning_rate": 1.1190956802583772e-05,
      "loss": 0.0561,
      "step": 21820
    },
    {
      "epoch": 8.813080339119903,
      "grad_norm": 0.006254303269088268,
      "learning_rate": 1.1186919660880098e-05,
      "loss": 0.0198,
      "step": 21830
    },
    {
      "epoch": 8.817117480823576,
      "grad_norm": 1.649608850479126,
      "learning_rate": 1.1182882519176424e-05,
      "loss": 0.0195,
      "step": 21840
    },
    {
      "epoch": 8.821154622527251,
      "grad_norm": 5.536837100982666,
      "learning_rate": 1.117884537747275e-05,
      "loss": 0.0322,
      "step": 21850
    },
    {
      "epoch": 8.825191764230924,
      "grad_norm": 0.0050461492501199245,
      "learning_rate": 1.1174808235769077e-05,
      "loss": 0.0199,
      "step": 21860
    },
    {
      "epoch": 8.829228905934599,
      "grad_norm": 0.8500535488128662,
      "learning_rate": 1.1170771094065403e-05,
      "loss": 0.0075,
      "step": 21870
    },
    {
      "epoch": 8.833266047638272,
      "grad_norm": 0.005088674370199442,
      "learning_rate": 1.1166733952361728e-05,
      "loss": 0.0011,
      "step": 21880
    },
    {
      "epoch": 8.837303189341945,
      "grad_norm": 0.006409132853150368,
      "learning_rate": 1.1162696810658056e-05,
      "loss": 0.0834,
      "step": 21890
    },
    {
      "epoch": 8.84134033104562,
      "grad_norm": 0.009180629625916481,
      "learning_rate": 1.1158659668954382e-05,
      "loss": 0.0063,
      "step": 21900
    },
    {
      "epoch": 8.845377472749293,
      "grad_norm": 0.06536274403333664,
      "learning_rate": 1.1154622527250706e-05,
      "loss": 0.0408,
      "step": 21910
    },
    {
      "epoch": 8.849414614452968,
      "grad_norm": 1.8611632585525513,
      "learning_rate": 1.1150585385547033e-05,
      "loss": 0.0228,
      "step": 21920
    },
    {
      "epoch": 8.853451756156641,
      "grad_norm": 9.884369850158691,
      "learning_rate": 1.114654824384336e-05,
      "loss": 0.0023,
      "step": 21930
    },
    {
      "epoch": 8.857488897860314,
      "grad_norm": 0.005116085521876812,
      "learning_rate": 1.1142511102139685e-05,
      "loss": 0.0079,
      "step": 21940
    },
    {
      "epoch": 8.861526039563989,
      "grad_norm": 0.005443109665066004,
      "learning_rate": 1.1138473960436012e-05,
      "loss": 0.0084,
      "step": 21950
    },
    {
      "epoch": 8.865563181267662,
      "grad_norm": 4.6061530113220215,
      "learning_rate": 1.113443681873234e-05,
      "loss": 0.0341,
      "step": 21960
    },
    {
      "epoch": 8.869600322971337,
      "grad_norm": 1.264045000076294,
      "learning_rate": 1.1130399677028664e-05,
      "loss": 0.0721,
      "step": 21970
    },
    {
      "epoch": 8.87363746467501,
      "grad_norm": 1.4580163955688477,
      "learning_rate": 1.112636253532499e-05,
      "loss": 0.0053,
      "step": 21980
    },
    {
      "epoch": 8.877674606378683,
      "grad_norm": 0.002060248516499996,
      "learning_rate": 1.1122325393621317e-05,
      "loss": 0.0025,
      "step": 21990
    },
    {
      "epoch": 8.881711748082358,
      "grad_norm": 0.006607379298657179,
      "learning_rate": 1.1118288251917643e-05,
      "loss": 0.0379,
      "step": 22000
    },
    {
      "epoch": 8.885748889786031,
      "grad_norm": 0.016356442123651505,
      "learning_rate": 1.111425111021397e-05,
      "loss": 0.0086,
      "step": 22010
    },
    {
      "epoch": 8.889786031489706,
      "grad_norm": 1.262266755104065,
      "learning_rate": 1.1110213968510296e-05,
      "loss": 0.0161,
      "step": 22020
    },
    {
      "epoch": 8.893823173193379,
      "grad_norm": 0.04657699912786484,
      "learning_rate": 1.1106176826806624e-05,
      "loss": 0.0131,
      "step": 22030
    },
    {
      "epoch": 8.897860314897052,
      "grad_norm": 0.03729803115129471,
      "learning_rate": 1.1102139685102948e-05,
      "loss": 0.034,
      "step": 22040
    },
    {
      "epoch": 8.901897456600727,
      "grad_norm": 0.3256889283657074,
      "learning_rate": 1.1098102543399275e-05,
      "loss": 0.0005,
      "step": 22050
    },
    {
      "epoch": 8.9059345983044,
      "grad_norm": 1.228926181793213,
      "learning_rate": 1.1094065401695599e-05,
      "loss": 0.0103,
      "step": 22060
    },
    {
      "epoch": 8.909971740008075,
      "grad_norm": 0.21439425647258759,
      "learning_rate": 1.1090028259991927e-05,
      "loss": 0.0396,
      "step": 22070
    },
    {
      "epoch": 8.914008881711748,
      "grad_norm": 0.00296095316298306,
      "learning_rate": 1.1085991118288253e-05,
      "loss": 0.0101,
      "step": 22080
    },
    {
      "epoch": 8.918046023415421,
      "grad_norm": 0.003198666498064995,
      "learning_rate": 1.1081953976584578e-05,
      "loss": 0.0005,
      "step": 22090
    },
    {
      "epoch": 8.922083165119096,
      "grad_norm": 1.06955087184906,
      "learning_rate": 1.1077916834880906e-05,
      "loss": 0.0253,
      "step": 22100
    },
    {
      "epoch": 8.926120306822769,
      "grad_norm": 0.01369820348918438,
      "learning_rate": 1.1073879693177232e-05,
      "loss": 0.033,
      "step": 22110
    },
    {
      "epoch": 8.930157448526444,
      "grad_norm": 2.3278138637542725,
      "learning_rate": 1.1069842551473557e-05,
      "loss": 0.0442,
      "step": 22120
    },
    {
      "epoch": 8.934194590230117,
      "grad_norm": 0.3216360807418823,
      "learning_rate": 1.1065805409769883e-05,
      "loss": 0.0071,
      "step": 22130
    },
    {
      "epoch": 8.93823173193379,
      "grad_norm": 0.6898555159568787,
      "learning_rate": 1.1061768268066211e-05,
      "loss": 0.0099,
      "step": 22140
    },
    {
      "epoch": 8.942268873637465,
      "grad_norm": 0.5017428398132324,
      "learning_rate": 1.1057731126362536e-05,
      "loss": 0.0332,
      "step": 22150
    },
    {
      "epoch": 8.946306015341138,
      "grad_norm": 0.01431388221681118,
      "learning_rate": 1.1053693984658862e-05,
      "loss": 0.0147,
      "step": 22160
    },
    {
      "epoch": 8.950343157044813,
      "grad_norm": 0.013973325490951538,
      "learning_rate": 1.1049656842955188e-05,
      "loss": 0.0586,
      "step": 22170
    },
    {
      "epoch": 8.954380298748486,
      "grad_norm": 0.8630902767181396,
      "learning_rate": 1.1045619701251516e-05,
      "loss": 0.0217,
      "step": 22180
    },
    {
      "epoch": 8.958417440452159,
      "grad_norm": 1.178139090538025,
      "learning_rate": 1.104158255954784e-05,
      "loss": 0.0147,
      "step": 22190
    },
    {
      "epoch": 8.962454582155834,
      "grad_norm": 0.011730466037988663,
      "learning_rate": 1.1037545417844167e-05,
      "loss": 0.0442,
      "step": 22200
    },
    {
      "epoch": 8.966491723859507,
      "grad_norm": 0.014909961260855198,
      "learning_rate": 1.1033508276140495e-05,
      "loss": 0.0059,
      "step": 22210
    },
    {
      "epoch": 8.970528865563182,
      "grad_norm": 0.0025352993980050087,
      "learning_rate": 1.102947113443682e-05,
      "loss": 0.0189,
      "step": 22220
    },
    {
      "epoch": 8.974566007266855,
      "grad_norm": 0.07182472199201584,
      "learning_rate": 1.1025433992733146e-05,
      "loss": 0.044,
      "step": 22230
    },
    {
      "epoch": 8.978603148970528,
      "grad_norm": 0.15220928192138672,
      "learning_rate": 1.102139685102947e-05,
      "loss": 0.0631,
      "step": 22240
    },
    {
      "epoch": 8.982640290674203,
      "grad_norm": 0.004426836967468262,
      "learning_rate": 1.1017359709325799e-05,
      "loss": 0.0107,
      "step": 22250
    },
    {
      "epoch": 8.986677432377876,
      "grad_norm": 6.02294921875,
      "learning_rate": 1.1013322567622125e-05,
      "loss": 0.0243,
      "step": 22260
    },
    {
      "epoch": 8.99071457408155,
      "grad_norm": 0.2356698215007782,
      "learning_rate": 1.100928542591845e-05,
      "loss": 0.0113,
      "step": 22270
    },
    {
      "epoch": 8.994751715785224,
      "grad_norm": 2.239881992340088,
      "learning_rate": 1.1005248284214777e-05,
      "loss": 0.0136,
      "step": 22280
    },
    {
      "epoch": 8.998788857488897,
      "grad_norm": 0.017482217401266098,
      "learning_rate": 1.1001211142511104e-05,
      "loss": 0.0096,
      "step": 22290
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9842767295597484,
      "eval_f1": 0.9430199430199431,
      "eval_loss": 0.06560597568750381,
      "eval_precision": 0.9350282485875706,
      "eval_recall": 0.9511494252873564,
      "eval_runtime": 442.1287,
      "eval_samples_per_second": 28.815,
      "eval_steps_per_second": 1.201,
      "step": 22293
    },
    {
      "epoch": 9.002825999192572,
      "grad_norm": 1.9426720142364502,
      "learning_rate": 1.0997174000807428e-05,
      "loss": 0.0139,
      "step": 22300
    },
    {
      "epoch": 9.006863140896245,
      "grad_norm": 1.5488301515579224,
      "learning_rate": 1.0993136859103755e-05,
      "loss": 0.0143,
      "step": 22310
    },
    {
      "epoch": 9.01090028259992,
      "grad_norm": 0.0074459584429860115,
      "learning_rate": 1.0989099717400083e-05,
      "loss": 0.009,
      "step": 22320
    },
    {
      "epoch": 9.014937424303593,
      "grad_norm": 1.2047886848449707,
      "learning_rate": 1.0985062575696409e-05,
      "loss": 0.0226,
      "step": 22330
    },
    {
      "epoch": 9.018974566007266,
      "grad_norm": 1.7267755270004272,
      "learning_rate": 1.0981025433992733e-05,
      "loss": 0.0056,
      "step": 22340
    },
    {
      "epoch": 9.02301170771094,
      "grad_norm": 0.0017627628985792398,
      "learning_rate": 1.097698829228906e-05,
      "loss": 0.0218,
      "step": 22350
    },
    {
      "epoch": 9.027048849414614,
      "grad_norm": 0.007118018809705973,
      "learning_rate": 1.0972951150585388e-05,
      "loss": 0.008,
      "step": 22360
    },
    {
      "epoch": 9.031085991118289,
      "grad_norm": 0.0009799422696232796,
      "learning_rate": 1.0968914008881712e-05,
      "loss": 0.013,
      "step": 22370
    },
    {
      "epoch": 9.035123132821962,
      "grad_norm": 0.011018075048923492,
      "learning_rate": 1.0964876867178039e-05,
      "loss": 0.0179,
      "step": 22380
    },
    {
      "epoch": 9.039160274525635,
      "grad_norm": 0.00260334019549191,
      "learning_rate": 1.0960839725474367e-05,
      "loss": 0.0187,
      "step": 22390
    },
    {
      "epoch": 9.04319741622931,
      "grad_norm": 0.7291247248649597,
      "learning_rate": 1.0956802583770691e-05,
      "loss": 0.0062,
      "step": 22400
    },
    {
      "epoch": 9.047234557932983,
      "grad_norm": 0.008302113972604275,
      "learning_rate": 1.0952765442067017e-05,
      "loss": 0.0027,
      "step": 22410
    },
    {
      "epoch": 9.051271699636658,
      "grad_norm": 1.1655430793762207,
      "learning_rate": 1.0948728300363342e-05,
      "loss": 0.0044,
      "step": 22420
    },
    {
      "epoch": 9.05530884134033,
      "grad_norm": 0.005592004396021366,
      "learning_rate": 1.094469115865967e-05,
      "loss": 0.0321,
      "step": 22430
    },
    {
      "epoch": 9.059345983044004,
      "grad_norm": 0.002293187892064452,
      "learning_rate": 1.0940654016955996e-05,
      "loss": 0.0054,
      "step": 22440
    },
    {
      "epoch": 9.063383124747679,
      "grad_norm": 0.029570646584033966,
      "learning_rate": 1.0936616875252321e-05,
      "loss": 0.0035,
      "step": 22450
    },
    {
      "epoch": 9.067420266451352,
      "grad_norm": 0.9107231497764587,
      "learning_rate": 1.0932579733548649e-05,
      "loss": 0.015,
      "step": 22460
    },
    {
      "epoch": 9.071457408155027,
      "grad_norm": 0.008946675807237625,
      "learning_rate": 1.0928542591844975e-05,
      "loss": 0.0129,
      "step": 22470
    },
    {
      "epoch": 9.0754945498587,
      "grad_norm": 0.9991847276687622,
      "learning_rate": 1.09245054501413e-05,
      "loss": 0.0055,
      "step": 22480
    },
    {
      "epoch": 9.079531691562375,
      "grad_norm": 0.004456109832972288,
      "learning_rate": 1.0920468308437626e-05,
      "loss": 0.0401,
      "step": 22490
    },
    {
      "epoch": 9.083568833266048,
      "grad_norm": 0.0009833663934841752,
      "learning_rate": 1.0916431166733954e-05,
      "loss": 0.0105,
      "step": 22500
    },
    {
      "epoch": 9.087605974969721,
      "grad_norm": 0.00561140663921833,
      "learning_rate": 1.091239402503028e-05,
      "loss": 0.0393,
      "step": 22510
    },
    {
      "epoch": 9.091643116673396,
      "grad_norm": 0.0014561188872903585,
      "learning_rate": 1.0908356883326605e-05,
      "loss": 0.0333,
      "step": 22520
    },
    {
      "epoch": 9.095680258377069,
      "grad_norm": 2.212902307510376,
      "learning_rate": 1.0904319741622933e-05,
      "loss": 0.0072,
      "step": 22530
    },
    {
      "epoch": 9.099717400080744,
      "grad_norm": 0.002650299808010459,
      "learning_rate": 1.090028259991926e-05,
      "loss": 0.0028,
      "step": 22540
    },
    {
      "epoch": 9.103754541784417,
      "grad_norm": 1.0653610229492188,
      "learning_rate": 1.0896245458215584e-05,
      "loss": 0.0033,
      "step": 22550
    },
    {
      "epoch": 9.10779168348809,
      "grad_norm": 0.002325992565602064,
      "learning_rate": 1.089220831651191e-05,
      "loss": 0.0215,
      "step": 22560
    },
    {
      "epoch": 9.111828825191765,
      "grad_norm": 3.6538808345794678,
      "learning_rate": 1.0888171174808238e-05,
      "loss": 0.0209,
      "step": 22570
    },
    {
      "epoch": 9.115865966895438,
      "grad_norm": 0.0026074449997395277,
      "learning_rate": 1.0884134033104563e-05,
      "loss": 0.0107,
      "step": 22580
    },
    {
      "epoch": 9.119903108599113,
      "grad_norm": 0.003577825613319874,
      "learning_rate": 1.0880096891400889e-05,
      "loss": 0.0189,
      "step": 22590
    },
    {
      "epoch": 9.123940250302786,
      "grad_norm": 0.0037084980867803097,
      "learning_rate": 1.0876059749697214e-05,
      "loss": 0.0088,
      "step": 22600
    },
    {
      "epoch": 9.127977392006459,
      "grad_norm": 0.0141602149233222,
      "learning_rate": 1.0872022607993541e-05,
      "loss": 0.0122,
      "step": 22610
    },
    {
      "epoch": 9.132014533710134,
      "grad_norm": 0.009101582691073418,
      "learning_rate": 1.0867985466289868e-05,
      "loss": 0.0258,
      "step": 22620
    },
    {
      "epoch": 9.136051675413807,
      "grad_norm": 9.068480491638184,
      "learning_rate": 1.0863948324586192e-05,
      "loss": 0.0338,
      "step": 22630
    },
    {
      "epoch": 9.140088817117482,
      "grad_norm": 2.1093380451202393,
      "learning_rate": 1.085991118288252e-05,
      "loss": 0.0107,
      "step": 22640
    },
    {
      "epoch": 9.144125958821155,
      "grad_norm": 0.03861543536186218,
      "learning_rate": 1.0855874041178847e-05,
      "loss": 0.0143,
      "step": 22650
    },
    {
      "epoch": 9.148163100524828,
      "grad_norm": 0.9943781495094299,
      "learning_rate": 1.0851836899475173e-05,
      "loss": 0.0061,
      "step": 22660
    },
    {
      "epoch": 9.152200242228503,
      "grad_norm": 0.03398396447300911,
      "learning_rate": 1.0847799757771498e-05,
      "loss": 0.0073,
      "step": 22670
    },
    {
      "epoch": 9.156237383932176,
      "grad_norm": 1.023987889289856,
      "learning_rate": 1.0843762616067825e-05,
      "loss": 0.0073,
      "step": 22680
    },
    {
      "epoch": 9.16027452563585,
      "grad_norm": 0.006220795214176178,
      "learning_rate": 1.0839725474364152e-05,
      "loss": 0.0084,
      "step": 22690
    },
    {
      "epoch": 9.164311667339524,
      "grad_norm": 0.10633789747953415,
      "learning_rate": 1.0835688332660476e-05,
      "loss": 0.0529,
      "step": 22700
    },
    {
      "epoch": 9.168348809043197,
      "grad_norm": 0.006706810090690851,
      "learning_rate": 1.0831651190956804e-05,
      "loss": 0.018,
      "step": 22710
    },
    {
      "epoch": 9.172385950746872,
      "grad_norm": 5.577468395233154,
      "learning_rate": 1.082761404925313e-05,
      "loss": 0.0577,
      "step": 22720
    },
    {
      "epoch": 9.176423092450545,
      "grad_norm": 0.09770362824201584,
      "learning_rate": 1.0823576907549455e-05,
      "loss": 0.0114,
      "step": 22730
    },
    {
      "epoch": 9.18046023415422,
      "grad_norm": 1.3754220008850098,
      "learning_rate": 1.0819539765845782e-05,
      "loss": 0.0175,
      "step": 22740
    },
    {
      "epoch": 9.184497375857893,
      "grad_norm": 2.2990827560424805,
      "learning_rate": 1.081550262414211e-05,
      "loss": 0.0074,
      "step": 22750
    },
    {
      "epoch": 9.188534517561566,
      "grad_norm": 0.01590052805840969,
      "learning_rate": 1.0811465482438434e-05,
      "loss": 0.0008,
      "step": 22760
    },
    {
      "epoch": 9.19257165926524,
      "grad_norm": 0.0008595336112193763,
      "learning_rate": 1.080742834073476e-05,
      "loss": 0.0576,
      "step": 22770
    },
    {
      "epoch": 9.196608800968914,
      "grad_norm": 0.0023448315914720297,
      "learning_rate": 1.0803391199031085e-05,
      "loss": 0.0053,
      "step": 22780
    },
    {
      "epoch": 9.200645942672589,
      "grad_norm": 0.005519601050764322,
      "learning_rate": 1.0799354057327413e-05,
      "loss": 0.0107,
      "step": 22790
    },
    {
      "epoch": 9.204683084376262,
      "grad_norm": 0.004708458203822374,
      "learning_rate": 1.079531691562374e-05,
      "loss": 0.0122,
      "step": 22800
    },
    {
      "epoch": 9.208720226079935,
      "grad_norm": 1.3239933252334595,
      "learning_rate": 1.0791279773920066e-05,
      "loss": 0.0138,
      "step": 22810
    },
    {
      "epoch": 9.21275736778361,
      "grad_norm": 0.002827295335009694,
      "learning_rate": 1.0787242632216392e-05,
      "loss": 0.0021,
      "step": 22820
    },
    {
      "epoch": 9.216794509487283,
      "grad_norm": 0.0020742902997881174,
      "learning_rate": 1.0783205490512718e-05,
      "loss": 0.0102,
      "step": 22830
    },
    {
      "epoch": 9.220831651190958,
      "grad_norm": 0.025268325582146645,
      "learning_rate": 1.0779168348809044e-05,
      "loss": 0.0045,
      "step": 22840
    },
    {
      "epoch": 9.22486879289463,
      "grad_norm": 0.011851931922137737,
      "learning_rate": 1.0775131207105369e-05,
      "loss": 0.0063,
      "step": 22850
    },
    {
      "epoch": 9.228905934598304,
      "grad_norm": 1.1461594104766846,
      "learning_rate": 1.0771094065401697e-05,
      "loss": 0.0069,
      "step": 22860
    },
    {
      "epoch": 9.232943076301979,
      "grad_norm": 1.3905868530273438,
      "learning_rate": 1.0767056923698023e-05,
      "loss": 0.0216,
      "step": 22870
    },
    {
      "epoch": 9.236980218005652,
      "grad_norm": 0.007706730626523495,
      "learning_rate": 1.0763019781994348e-05,
      "loss": 0.0421,
      "step": 22880
    },
    {
      "epoch": 9.241017359709327,
      "grad_norm": 0.9445691704750061,
      "learning_rate": 1.0758982640290676e-05,
      "loss": 0.0166,
      "step": 22890
    },
    {
      "epoch": 9.245054501413,
      "grad_norm": 0.00810988899320364,
      "learning_rate": 1.0754945498587002e-05,
      "loss": 0.0093,
      "step": 22900
    },
    {
      "epoch": 9.249091643116673,
      "grad_norm": 0.0021711483132094145,
      "learning_rate": 1.0750908356883327e-05,
      "loss": 0.0212,
      "step": 22910
    },
    {
      "epoch": 9.253128784820348,
      "grad_norm": 0.0021435043308883905,
      "learning_rate": 1.0746871215179653e-05,
      "loss": 0.0048,
      "step": 22920
    },
    {
      "epoch": 9.25716592652402,
      "grad_norm": 0.69762122631073,
      "learning_rate": 1.0742834073475981e-05,
      "loss": 0.0087,
      "step": 22930
    },
    {
      "epoch": 9.261203068227696,
      "grad_norm": 0.010678060352802277,
      "learning_rate": 1.0738796931772306e-05,
      "loss": 0.0109,
      "step": 22940
    },
    {
      "epoch": 9.265240209931369,
      "grad_norm": 0.06490711867809296,
      "learning_rate": 1.0734759790068632e-05,
      "loss": 0.0619,
      "step": 22950
    },
    {
      "epoch": 9.269277351635042,
      "grad_norm": 2.8578736782073975,
      "learning_rate": 1.073072264836496e-05,
      "loss": 0.0226,
      "step": 22960
    },
    {
      "epoch": 9.273314493338717,
      "grad_norm": 0.00902580562978983,
      "learning_rate": 1.0726685506661284e-05,
      "loss": 0.005,
      "step": 22970
    },
    {
      "epoch": 9.27735163504239,
      "grad_norm": 0.12736627459526062,
      "learning_rate": 1.072264836495761e-05,
      "loss": 0.0116,
      "step": 22980
    },
    {
      "epoch": 9.281388776746065,
      "grad_norm": 0.002784163923934102,
      "learning_rate": 1.0718611223253937e-05,
      "loss": 0.0164,
      "step": 22990
    },
    {
      "epoch": 9.285425918449738,
      "grad_norm": 0.002514539984986186,
      "learning_rate": 1.0714574081550263e-05,
      "loss": 0.0055,
      "step": 23000
    },
    {
      "epoch": 9.28946306015341,
      "grad_norm": 0.0072610522620379925,
      "learning_rate": 1.071053693984659e-05,
      "loss": 0.0264,
      "step": 23010
    },
    {
      "epoch": 9.293500201857086,
      "grad_norm": 0.001380645320750773,
      "learning_rate": 1.0706499798142916e-05,
      "loss": 0.0132,
      "step": 23020
    },
    {
      "epoch": 9.297537343560759,
      "grad_norm": 1.646533489227295,
      "learning_rate": 1.070246265643924e-05,
      "loss": 0.0018,
      "step": 23030
    },
    {
      "epoch": 9.301574485264434,
      "grad_norm": 0.9318931698799133,
      "learning_rate": 1.0698425514735568e-05,
      "loss": 0.0105,
      "step": 23040
    },
    {
      "epoch": 9.305611626968107,
      "grad_norm": 1.4197841882705688,
      "learning_rate": 1.0694388373031895e-05,
      "loss": 0.0477,
      "step": 23050
    },
    {
      "epoch": 9.30964876867178,
      "grad_norm": 0.002018751809373498,
      "learning_rate": 1.069035123132822e-05,
      "loss": 0.0063,
      "step": 23060
    },
    {
      "epoch": 9.313685910375455,
      "grad_norm": 0.0027783429250121117,
      "learning_rate": 1.0686314089624547e-05,
      "loss": 0.0453,
      "step": 23070
    },
    {
      "epoch": 9.317723052079128,
      "grad_norm": 0.009296162985265255,
      "learning_rate": 1.0682276947920874e-05,
      "loss": 0.0001,
      "step": 23080
    },
    {
      "epoch": 9.321760193782803,
      "grad_norm": 1.2110131978988647,
      "learning_rate": 1.0678239806217198e-05,
      "loss": 0.0121,
      "step": 23090
    },
    {
      "epoch": 9.325797335486476,
      "grad_norm": 1.6704121828079224,
      "learning_rate": 1.0674202664513524e-05,
      "loss": 0.0129,
      "step": 23100
    },
    {
      "epoch": 9.329834477190149,
      "grad_norm": 0.0025995115283876657,
      "learning_rate": 1.0670165522809852e-05,
      "loss": 0.0272,
      "step": 23110
    },
    {
      "epoch": 9.333871618893824,
      "grad_norm": 0.0012802514247596264,
      "learning_rate": 1.0666128381106177e-05,
      "loss": 0.0075,
      "step": 23120
    },
    {
      "epoch": 9.337908760597497,
      "grad_norm": 0.5813391804695129,
      "learning_rate": 1.0662091239402503e-05,
      "loss": 0.0273,
      "step": 23130
    },
    {
      "epoch": 9.341945902301172,
      "grad_norm": 0.002216760767623782,
      "learning_rate": 1.0658054097698831e-05,
      "loss": 0.04,
      "step": 23140
    },
    {
      "epoch": 9.345983044004845,
      "grad_norm": 0.007190402131527662,
      "learning_rate": 1.0654016955995156e-05,
      "loss": 0.007,
      "step": 23150
    },
    {
      "epoch": 9.350020185708518,
      "grad_norm": 0.0011825053952634335,
      "learning_rate": 1.0649979814291482e-05,
      "loss": 0.0064,
      "step": 23160
    },
    {
      "epoch": 9.354057327412193,
      "grad_norm": 0.0007532751769758761,
      "learning_rate": 1.0645942672587808e-05,
      "loss": 0.0017,
      "step": 23170
    },
    {
      "epoch": 9.358094469115866,
      "grad_norm": 0.07942433655261993,
      "learning_rate": 1.0641905530884136e-05,
      "loss": 0.0119,
      "step": 23180
    },
    {
      "epoch": 9.36213161081954,
      "grad_norm": 0.00045424586278386414,
      "learning_rate": 1.0637868389180461e-05,
      "loss": 0.0088,
      "step": 23190
    },
    {
      "epoch": 9.366168752523214,
      "grad_norm": 0.09265320003032684,
      "learning_rate": 1.0633831247476787e-05,
      "loss": 0.0063,
      "step": 23200
    },
    {
      "epoch": 9.370205894226887,
      "grad_norm": 0.7465733885765076,
      "learning_rate": 1.0629794105773112e-05,
      "loss": 0.0139,
      "step": 23210
    },
    {
      "epoch": 9.374243035930562,
      "grad_norm": 0.0026401737704873085,
      "learning_rate": 1.062575696406944e-05,
      "loss": 0.0717,
      "step": 23220
    },
    {
      "epoch": 9.378280177634235,
      "grad_norm": 0.0008511107298545539,
      "learning_rate": 1.0621719822365766e-05,
      "loss": 0.0097,
      "step": 23230
    },
    {
      "epoch": 9.38231731933791,
      "grad_norm": 3.5301733016967773,
      "learning_rate": 1.061768268066209e-05,
      "loss": 0.0233,
      "step": 23240
    },
    {
      "epoch": 9.386354461041583,
      "grad_norm": 0.6800657510757446,
      "learning_rate": 1.0613645538958419e-05,
      "loss": 0.0104,
      "step": 23250
    },
    {
      "epoch": 9.390391602745256,
      "grad_norm": 0.005078629124909639,
      "learning_rate": 1.0609608397254745e-05,
      "loss": 0.0251,
      "step": 23260
    },
    {
      "epoch": 9.39442874444893,
      "grad_norm": 0.0015867134789004922,
      "learning_rate": 1.060557125555107e-05,
      "loss": 0.0233,
      "step": 23270
    },
    {
      "epoch": 9.398465886152604,
      "grad_norm": 0.0020130423363298178,
      "learning_rate": 1.0601534113847396e-05,
      "loss": 0.0137,
      "step": 23280
    },
    {
      "epoch": 9.402503027856278,
      "grad_norm": 0.003634192980825901,
      "learning_rate": 1.0597496972143724e-05,
      "loss": 0.0112,
      "step": 23290
    },
    {
      "epoch": 9.406540169559952,
      "grad_norm": 0.041023656725883484,
      "learning_rate": 1.0593459830440049e-05,
      "loss": 0.0259,
      "step": 23300
    },
    {
      "epoch": 9.410577311263625,
      "grad_norm": 0.05659868195652962,
      "learning_rate": 1.0589422688736375e-05,
      "loss": 0.0052,
      "step": 23310
    },
    {
      "epoch": 9.4146144529673,
      "grad_norm": 9.867969512939453,
      "learning_rate": 1.0585385547032703e-05,
      "loss": 0.0198,
      "step": 23320
    },
    {
      "epoch": 9.418651594670973,
      "grad_norm": 0.008860260248184204,
      "learning_rate": 1.0581348405329029e-05,
      "loss": 0.0313,
      "step": 23330
    },
    {
      "epoch": 9.422688736374647,
      "grad_norm": 0.016123145818710327,
      "learning_rate": 1.0577311263625354e-05,
      "loss": 0.0091,
      "step": 23340
    },
    {
      "epoch": 9.42672587807832,
      "grad_norm": 0.003195381024852395,
      "learning_rate": 1.057327412192168e-05,
      "loss": 0.0384,
      "step": 23350
    },
    {
      "epoch": 9.430763019781994,
      "grad_norm": 2.2745113372802734,
      "learning_rate": 1.0569236980218008e-05,
      "loss": 0.049,
      "step": 23360
    },
    {
      "epoch": 9.434800161485668,
      "grad_norm": 0.8592033982276917,
      "learning_rate": 1.0565199838514333e-05,
      "loss": 0.0122,
      "step": 23370
    },
    {
      "epoch": 9.438837303189342,
      "grad_norm": 2.1647748947143555,
      "learning_rate": 1.0561162696810659e-05,
      "loss": 0.0128,
      "step": 23380
    },
    {
      "epoch": 9.442874444893016,
      "grad_norm": 0.012300538830459118,
      "learning_rate": 1.0557125555106987e-05,
      "loss": 0.0197,
      "step": 23390
    },
    {
      "epoch": 9.44691158659669,
      "grad_norm": 0.7618919610977173,
      "learning_rate": 1.0553088413403311e-05,
      "loss": 0.0137,
      "step": 23400
    },
    {
      "epoch": 9.450948728300363,
      "grad_norm": 0.001766660250723362,
      "learning_rate": 1.0549051271699638e-05,
      "loss": 0.0092,
      "step": 23410
    },
    {
      "epoch": 9.454985870004037,
      "grad_norm": 4.182134628295898,
      "learning_rate": 1.0545014129995962e-05,
      "loss": 0.0121,
      "step": 23420
    },
    {
      "epoch": 9.45902301170771,
      "grad_norm": 0.007048410829156637,
      "learning_rate": 1.054097698829229e-05,
      "loss": 0.032,
      "step": 23430
    },
    {
      "epoch": 9.463060153411385,
      "grad_norm": 0.007288582157343626,
      "learning_rate": 1.0536939846588617e-05,
      "loss": 0.0149,
      "step": 23440
    },
    {
      "epoch": 9.467097295115058,
      "grad_norm": 0.05528362840414047,
      "learning_rate": 1.0532902704884941e-05,
      "loss": 0.0028,
      "step": 23450
    },
    {
      "epoch": 9.471134436818732,
      "grad_norm": 0.0014540853444486856,
      "learning_rate": 1.0528865563181267e-05,
      "loss": 0.0077,
      "step": 23460
    },
    {
      "epoch": 9.475171578522406,
      "grad_norm": 5.799294948577881,
      "learning_rate": 1.0524828421477595e-05,
      "loss": 0.0078,
      "step": 23470
    },
    {
      "epoch": 9.47920872022608,
      "grad_norm": 0.04819469526410103,
      "learning_rate": 1.0520791279773922e-05,
      "loss": 0.0325,
      "step": 23480
    },
    {
      "epoch": 9.483245861929754,
      "grad_norm": 1.737341046333313,
      "learning_rate": 1.0516754138070246e-05,
      "loss": 0.0087,
      "step": 23490
    },
    {
      "epoch": 9.487283003633427,
      "grad_norm": 0.0005495563964359462,
      "learning_rate": 1.0512716996366574e-05,
      "loss": 0.0037,
      "step": 23500
    },
    {
      "epoch": 9.4913201453371,
      "grad_norm": 0.011358639225363731,
      "learning_rate": 1.05086798546629e-05,
      "loss": 0.0288,
      "step": 23510
    },
    {
      "epoch": 9.495357287040775,
      "grad_norm": 2.025249481201172,
      "learning_rate": 1.0504642712959225e-05,
      "loss": 0.0124,
      "step": 23520
    },
    {
      "epoch": 9.499394428744449,
      "grad_norm": 0.026358650997281075,
      "learning_rate": 1.0500605571255551e-05,
      "loss": 0.0288,
      "step": 23530
    },
    {
      "epoch": 9.503431570448123,
      "grad_norm": 0.01270960457623005,
      "learning_rate": 1.049656842955188e-05,
      "loss": 0.0184,
      "step": 23540
    },
    {
      "epoch": 9.507468712151796,
      "grad_norm": 0.0020665216725319624,
      "learning_rate": 1.0492531287848204e-05,
      "loss": 0.0225,
      "step": 23550
    },
    {
      "epoch": 9.51150585385547,
      "grad_norm": 0.5255076885223389,
      "learning_rate": 1.048849414614453e-05,
      "loss": 0.0234,
      "step": 23560
    },
    {
      "epoch": 9.515542995559144,
      "grad_norm": 0.09035137295722961,
      "learning_rate": 1.0484457004440858e-05,
      "loss": 0.0038,
      "step": 23570
    },
    {
      "epoch": 9.519580137262817,
      "grad_norm": 0.0015600410988554358,
      "learning_rate": 1.0480419862737183e-05,
      "loss": 0.0223,
      "step": 23580
    },
    {
      "epoch": 9.523617278966492,
      "grad_norm": 1.8123416900634766,
      "learning_rate": 1.0476382721033509e-05,
      "loss": 0.0225,
      "step": 23590
    },
    {
      "epoch": 9.527654420670165,
      "grad_norm": 0.0004911576397716999,
      "learning_rate": 1.0472345579329834e-05,
      "loss": 0.0259,
      "step": 23600
    },
    {
      "epoch": 9.531691562373839,
      "grad_norm": 0.046282343566417694,
      "learning_rate": 1.0468308437626162e-05,
      "loss": 0.0026,
      "step": 23610
    },
    {
      "epoch": 9.535728704077513,
      "grad_norm": 1.5923166275024414,
      "learning_rate": 1.0464271295922488e-05,
      "loss": 0.0249,
      "step": 23620
    },
    {
      "epoch": 9.539765845781186,
      "grad_norm": 0.005257054697722197,
      "learning_rate": 1.0460234154218814e-05,
      "loss": 0.0125,
      "step": 23630
    },
    {
      "epoch": 9.543802987484861,
      "grad_norm": 0.0013838558224961162,
      "learning_rate": 1.0456197012515139e-05,
      "loss": 0.0169,
      "step": 23640
    },
    {
      "epoch": 9.547840129188534,
      "grad_norm": 0.00019971503934357315,
      "learning_rate": 1.0452159870811467e-05,
      "loss": 0.0142,
      "step": 23650
    },
    {
      "epoch": 9.551877270892208,
      "grad_norm": 1.6067883968353271,
      "learning_rate": 1.0448122729107793e-05,
      "loss": 0.008,
      "step": 23660
    },
    {
      "epoch": 9.555914412595882,
      "grad_norm": 0.0004679368284996599,
      "learning_rate": 1.0444085587404118e-05,
      "loss": 0.0095,
      "step": 23670
    },
    {
      "epoch": 9.559951554299555,
      "grad_norm": 1.2032995223999023,
      "learning_rate": 1.0440048445700446e-05,
      "loss": 0.0071,
      "step": 23680
    },
    {
      "epoch": 9.56398869600323,
      "grad_norm": 0.027569502592086792,
      "learning_rate": 1.0436011303996772e-05,
      "loss": 0.0057,
      "step": 23690
    },
    {
      "epoch": 9.568025837706903,
      "grad_norm": 1.090592861175537,
      "learning_rate": 1.0431974162293097e-05,
      "loss": 0.0193,
      "step": 23700
    },
    {
      "epoch": 9.572062979410576,
      "grad_norm": 0.0009835691889747977,
      "learning_rate": 1.0427937020589423e-05,
      "loss": 0.0077,
      "step": 23710
    },
    {
      "epoch": 9.576100121114251,
      "grad_norm": 0.0004835450672544539,
      "learning_rate": 1.0423899878885751e-05,
      "loss": 0.024,
      "step": 23720
    },
    {
      "epoch": 9.580137262817924,
      "grad_norm": 0.0012384479632601142,
      "learning_rate": 1.0419862737182075e-05,
      "loss": 0.0018,
      "step": 23730
    },
    {
      "epoch": 9.5841744045216,
      "grad_norm": 0.7265664935112,
      "learning_rate": 1.0415825595478402e-05,
      "loss": 0.0428,
      "step": 23740
    },
    {
      "epoch": 9.588211546225272,
      "grad_norm": 1.4170048236846924,
      "learning_rate": 1.041178845377473e-05,
      "loss": 0.0104,
      "step": 23750
    },
    {
      "epoch": 9.592248687928947,
      "grad_norm": 0.0012842494761571288,
      "learning_rate": 1.0407751312071054e-05,
      "loss": 0.0155,
      "step": 23760
    },
    {
      "epoch": 9.59628582963262,
      "grad_norm": 0.004153666086494923,
      "learning_rate": 1.040371417036738e-05,
      "loss": 0.0001,
      "step": 23770
    },
    {
      "epoch": 9.600322971336293,
      "grad_norm": 0.0012226238613948226,
      "learning_rate": 1.0399677028663707e-05,
      "loss": 0.0547,
      "step": 23780
    },
    {
      "epoch": 9.604360113039968,
      "grad_norm": 0.004686804488301277,
      "learning_rate": 1.0395639886960033e-05,
      "loss": 0.0211,
      "step": 23790
    },
    {
      "epoch": 9.608397254743641,
      "grad_norm": 0.0028135646134614944,
      "learning_rate": 1.039160274525636e-05,
      "loss": 0.0062,
      "step": 23800
    },
    {
      "epoch": 9.612434396447316,
      "grad_norm": 4.084144115447998,
      "learning_rate": 1.0387565603552686e-05,
      "loss": 0.0699,
      "step": 23810
    },
    {
      "epoch": 9.61647153815099,
      "grad_norm": 6.724809169769287,
      "learning_rate": 1.038352846184901e-05,
      "loss": 0.0083,
      "step": 23820
    },
    {
      "epoch": 9.620508679854662,
      "grad_norm": 0.0010900484630838037,
      "learning_rate": 1.0379491320145338e-05,
      "loss": 0.0347,
      "step": 23830
    },
    {
      "epoch": 9.624545821558337,
      "grad_norm": 0.0015882456209510565,
      "learning_rate": 1.0375454178441665e-05,
      "loss": 0.0403,
      "step": 23840
    },
    {
      "epoch": 9.62858296326201,
      "grad_norm": 0.0017048921436071396,
      "learning_rate": 1.037141703673799e-05,
      "loss": 0.0203,
      "step": 23850
    },
    {
      "epoch": 9.632620104965685,
      "grad_norm": 0.0025636767968535423,
      "learning_rate": 1.0367379895034317e-05,
      "loss": 0.0035,
      "step": 23860
    },
    {
      "epoch": 9.636657246669358,
      "grad_norm": 0.002959187375381589,
      "learning_rate": 1.0363342753330643e-05,
      "loss": 0.0191,
      "step": 23870
    },
    {
      "epoch": 9.640694388373031,
      "grad_norm": 0.00647194217890501,
      "learning_rate": 1.0359305611626968e-05,
      "loss": 0.027,
      "step": 23880
    },
    {
      "epoch": 9.644731530076706,
      "grad_norm": 0.0014722960768267512,
      "learning_rate": 1.0355268469923294e-05,
      "loss": 0.0022,
      "step": 23890
    },
    {
      "epoch": 9.64876867178038,
      "grad_norm": 0.002562835579738021,
      "learning_rate": 1.0351231328219622e-05,
      "loss": 0.0053,
      "step": 23900
    },
    {
      "epoch": 9.652805813484054,
      "grad_norm": 0.10135631263256073,
      "learning_rate": 1.0347194186515947e-05,
      "loss": 0.01,
      "step": 23910
    },
    {
      "epoch": 9.656842955187727,
      "grad_norm": 0.008477427065372467,
      "learning_rate": 1.0343157044812273e-05,
      "loss": 0.0428,
      "step": 23920
    },
    {
      "epoch": 9.6608800968914,
      "grad_norm": 0.008939298801124096,
      "learning_rate": 1.0339119903108601e-05,
      "loss": 0.0106,
      "step": 23930
    },
    {
      "epoch": 9.664917238595075,
      "grad_norm": 3.0320143699645996,
      "learning_rate": 1.0335082761404926e-05,
      "loss": 0.0182,
      "step": 23940
    },
    {
      "epoch": 9.668954380298748,
      "grad_norm": 0.0016687118913978338,
      "learning_rate": 1.0331045619701252e-05,
      "loss": 0.0129,
      "step": 23950
    },
    {
      "epoch": 9.672991522002423,
      "grad_norm": 0.005906254518777132,
      "learning_rate": 1.0327008477997578e-05,
      "loss": 0.0079,
      "step": 23960
    },
    {
      "epoch": 9.677028663706096,
      "grad_norm": 0.004274525213986635,
      "learning_rate": 1.0322971336293905e-05,
      "loss": 0.0213,
      "step": 23970
    },
    {
      "epoch": 9.68106580540977,
      "grad_norm": 0.004068411886692047,
      "learning_rate": 1.0318934194590231e-05,
      "loss": 0.0096,
      "step": 23980
    },
    {
      "epoch": 9.685102947113444,
      "grad_norm": 0.0010659084655344486,
      "learning_rate": 1.0314897052886557e-05,
      "loss": 0.0078,
      "step": 23990
    },
    {
      "epoch": 9.689140088817117,
      "grad_norm": 0.0004876700695604086,
      "learning_rate": 1.0310859911182885e-05,
      "loss": 0.0048,
      "step": 24000
    },
    {
      "epoch": 9.693177230520792,
      "grad_norm": 0.05288994312286377,
      "learning_rate": 1.030682276947921e-05,
      "loss": 0.0266,
      "step": 24010
    },
    {
      "epoch": 9.697214372224465,
      "grad_norm": 0.0005836003692820668,
      "learning_rate": 1.0302785627775536e-05,
      "loss": 0.0302,
      "step": 24020
    },
    {
      "epoch": 9.701251513928138,
      "grad_norm": 0.0024200219195336103,
      "learning_rate": 1.029874848607186e-05,
      "loss": 0.0045,
      "step": 24030
    },
    {
      "epoch": 9.705288655631813,
      "grad_norm": 0.00479729613289237,
      "learning_rate": 1.0294711344368189e-05,
      "loss": 0.01,
      "step": 24040
    },
    {
      "epoch": 9.709325797335486,
      "grad_norm": 2.5469119548797607,
      "learning_rate": 1.0290674202664515e-05,
      "loss": 0.0343,
      "step": 24050
    },
    {
      "epoch": 9.713362939039161,
      "grad_norm": 0.0010140201775357127,
      "learning_rate": 1.028663706096084e-05,
      "loss": 0.0339,
      "step": 24060
    },
    {
      "epoch": 9.717400080742834,
      "grad_norm": 0.5318247079849243,
      "learning_rate": 1.0282599919257166e-05,
      "loss": 0.0168,
      "step": 24070
    },
    {
      "epoch": 9.721437222446507,
      "grad_norm": 0.0047426288947463036,
      "learning_rate": 1.0278562777553494e-05,
      "loss": 0.0015,
      "step": 24080
    },
    {
      "epoch": 9.725474364150182,
      "grad_norm": 0.0030748427379876375,
      "learning_rate": 1.0274525635849818e-05,
      "loss": 0.0103,
      "step": 24090
    },
    {
      "epoch": 9.729511505853855,
      "grad_norm": 0.006768574006855488,
      "learning_rate": 1.0270488494146145e-05,
      "loss": 0.0053,
      "step": 24100
    },
    {
      "epoch": 9.73354864755753,
      "grad_norm": 0.001749210525304079,
      "learning_rate": 1.0266451352442473e-05,
      "loss": 0.01,
      "step": 24110
    },
    {
      "epoch": 9.737585789261203,
      "grad_norm": 0.0023175780661404133,
      "learning_rate": 1.0262414210738797e-05,
      "loss": 0.0053,
      "step": 24120
    },
    {
      "epoch": 9.741622930964876,
      "grad_norm": 0.41294142603874207,
      "learning_rate": 1.0258377069035124e-05,
      "loss": 0.0231,
      "step": 24130
    },
    {
      "epoch": 9.745660072668551,
      "grad_norm": 0.0040923794731497765,
      "learning_rate": 1.025433992733145e-05,
      "loss": 0.0392,
      "step": 24140
    },
    {
      "epoch": 9.749697214372224,
      "grad_norm": 0.0016954122111201286,
      "learning_rate": 1.0250302785627778e-05,
      "loss": 0.0047,
      "step": 24150
    },
    {
      "epoch": 9.7537343560759,
      "grad_norm": 0.6986666917800903,
      "learning_rate": 1.0246265643924102e-05,
      "loss": 0.0062,
      "step": 24160
    },
    {
      "epoch": 9.757771497779572,
      "grad_norm": 0.016875341534614563,
      "learning_rate": 1.0242228502220429e-05,
      "loss": 0.0068,
      "step": 24170
    },
    {
      "epoch": 9.761808639483245,
      "grad_norm": 0.0010532260639593005,
      "learning_rate": 1.0238191360516757e-05,
      "loss": 0.0093,
      "step": 24180
    },
    {
      "epoch": 9.76584578118692,
      "grad_norm": 0.03081502579152584,
      "learning_rate": 1.0234154218813081e-05,
      "loss": 0.0268,
      "step": 24190
    },
    {
      "epoch": 9.769882922890593,
      "grad_norm": 0.001581830671057105,
      "learning_rate": 1.0230117077109408e-05,
      "loss": 0.012,
      "step": 24200
    },
    {
      "epoch": 9.773920064594268,
      "grad_norm": 2.2487661838531494,
      "learning_rate": 1.0226079935405732e-05,
      "loss": 0.012,
      "step": 24210
    },
    {
      "epoch": 9.777957206297941,
      "grad_norm": 0.0012429171474650502,
      "learning_rate": 1.022204279370206e-05,
      "loss": 0.0189,
      "step": 24220
    },
    {
      "epoch": 9.781994348001614,
      "grad_norm": 0.0031935253646224737,
      "learning_rate": 1.0218005651998386e-05,
      "loss": 0.0129,
      "step": 24230
    },
    {
      "epoch": 9.78603148970529,
      "grad_norm": 0.0031081712804734707,
      "learning_rate": 1.0213968510294711e-05,
      "loss": 0.0054,
      "step": 24240
    },
    {
      "epoch": 9.790068631408962,
      "grad_norm": 0.0025372046511620283,
      "learning_rate": 1.0209931368591037e-05,
      "loss": 0.0155,
      "step": 24250
    },
    {
      "epoch": 9.794105773112637,
      "grad_norm": 0.0008676017168909311,
      "learning_rate": 1.0205894226887365e-05,
      "loss": 0.0156,
      "step": 24260
    },
    {
      "epoch": 9.79814291481631,
      "grad_norm": 3.713857650756836,
      "learning_rate": 1.020185708518369e-05,
      "loss": 0.0443,
      "step": 24270
    },
    {
      "epoch": 9.802180056519983,
      "grad_norm": 1.1894510984420776,
      "learning_rate": 1.0197819943480016e-05,
      "loss": 0.0177,
      "step": 24280
    },
    {
      "epoch": 9.806217198223658,
      "grad_norm": 0.3710145950317383,
      "learning_rate": 1.0193782801776344e-05,
      "loss": 0.0286,
      "step": 24290
    },
    {
      "epoch": 9.810254339927331,
      "grad_norm": 0.0015161893097683787,
      "learning_rate": 1.018974566007267e-05,
      "loss": 0.0394,
      "step": 24300
    },
    {
      "epoch": 9.814291481631006,
      "grad_norm": 0.09576593339443207,
      "learning_rate": 1.0185708518368995e-05,
      "loss": 0.042,
      "step": 24310
    },
    {
      "epoch": 9.81832862333468,
      "grad_norm": 0.0012454689713194966,
      "learning_rate": 1.0181671376665321e-05,
      "loss": 0.0414,
      "step": 24320
    },
    {
      "epoch": 9.822365765038352,
      "grad_norm": 0.013310175389051437,
      "learning_rate": 1.017763423496165e-05,
      "loss": 0.0142,
      "step": 24330
    },
    {
      "epoch": 9.826402906742027,
      "grad_norm": 0.004490641877055168,
      "learning_rate": 1.0173597093257974e-05,
      "loss": 0.012,
      "step": 24340
    },
    {
      "epoch": 9.8304400484457,
      "grad_norm": 0.04991156607866287,
      "learning_rate": 1.01695599515543e-05,
      "loss": 0.0027,
      "step": 24350
    },
    {
      "epoch": 9.834477190149375,
      "grad_norm": 0.007228432223200798,
      "learning_rate": 1.0165522809850628e-05,
      "loss": 0.0362,
      "step": 24360
    },
    {
      "epoch": 9.838514331853048,
      "grad_norm": 0.18127135932445526,
      "learning_rate": 1.0161485668146953e-05,
      "loss": 0.0051,
      "step": 24370
    },
    {
      "epoch": 9.842551473556721,
      "grad_norm": 1.371433973312378,
      "learning_rate": 1.0157448526443279e-05,
      "loss": 0.0545,
      "step": 24380
    },
    {
      "epoch": 9.846588615260396,
      "grad_norm": 0.019478607922792435,
      "learning_rate": 1.0153411384739604e-05,
      "loss": 0.011,
      "step": 24390
    },
    {
      "epoch": 9.85062575696407,
      "grad_norm": 3.833397388458252,
      "learning_rate": 1.0149374243035932e-05,
      "loss": 0.0213,
      "step": 24400
    },
    {
      "epoch": 9.854662898667744,
      "grad_norm": 0.026459714397788048,
      "learning_rate": 1.0145337101332258e-05,
      "loss": 0.0065,
      "step": 24410
    },
    {
      "epoch": 9.858700040371417,
      "grad_norm": 0.010010105557739735,
      "learning_rate": 1.0141299959628582e-05,
      "loss": 0.0139,
      "step": 24420
    },
    {
      "epoch": 9.86273718207509,
      "grad_norm": 0.007817585952579975,
      "learning_rate": 1.013726281792491e-05,
      "loss": 0.0096,
      "step": 24430
    },
    {
      "epoch": 9.866774323778765,
      "grad_norm": 0.006006489973515272,
      "learning_rate": 1.0133225676221237e-05,
      "loss": 0.0357,
      "step": 24440
    },
    {
      "epoch": 9.870811465482438,
      "grad_norm": 0.005311611574143171,
      "learning_rate": 1.0129188534517563e-05,
      "loss": 0.0103,
      "step": 24450
    },
    {
      "epoch": 9.874848607186113,
      "grad_norm": 0.11378910392522812,
      "learning_rate": 1.0125151392813888e-05,
      "loss": 0.0029,
      "step": 24460
    },
    {
      "epoch": 9.878885748889786,
      "grad_norm": 0.00603112019598484,
      "learning_rate": 1.0121114251110216e-05,
      "loss": 0.0041,
      "step": 24470
    },
    {
      "epoch": 9.88292289059346,
      "grad_norm": 1.3733389377593994,
      "learning_rate": 1.0117077109406542e-05,
      "loss": 0.0384,
      "step": 24480
    },
    {
      "epoch": 9.886960032297134,
      "grad_norm": 0.01282263733446598,
      "learning_rate": 1.0113039967702866e-05,
      "loss": 0.0026,
      "step": 24490
    },
    {
      "epoch": 9.890997174000807,
      "grad_norm": 2.5704987049102783,
      "learning_rate": 1.0109002825999193e-05,
      "loss": 0.0616,
      "step": 24500
    },
    {
      "epoch": 9.895034315704482,
      "grad_norm": 0.0615987628698349,
      "learning_rate": 1.010496568429552e-05,
      "loss": 0.0166,
      "step": 24510
    },
    {
      "epoch": 9.899071457408155,
      "grad_norm": 0.031222714111208916,
      "learning_rate": 1.0100928542591845e-05,
      "loss": 0.0269,
      "step": 24520
    },
    {
      "epoch": 9.903108599111828,
      "grad_norm": 0.007477954495698214,
      "learning_rate": 1.0096891400888172e-05,
      "loss": 0.0262,
      "step": 24530
    },
    {
      "epoch": 9.907145740815503,
      "grad_norm": 1.3821622133255005,
      "learning_rate": 1.00928542591845e-05,
      "loss": 0.0142,
      "step": 24540
    },
    {
      "epoch": 9.911182882519176,
      "grad_norm": 1.08182954788208,
      "learning_rate": 1.0088817117480824e-05,
      "loss": 0.0173,
      "step": 24550
    },
    {
      "epoch": 9.915220024222851,
      "grad_norm": 0.056749191135168076,
      "learning_rate": 1.008477997577715e-05,
      "loss": 0.0364,
      "step": 24560
    },
    {
      "epoch": 9.919257165926524,
      "grad_norm": 0.0030168918892741203,
      "learning_rate": 1.0080742834073475e-05,
      "loss": 0.0126,
      "step": 24570
    },
    {
      "epoch": 9.923294307630197,
      "grad_norm": 5.845935344696045,
      "learning_rate": 1.0076705692369803e-05,
      "loss": 0.0327,
      "step": 24580
    },
    {
      "epoch": 9.927331449333872,
      "grad_norm": 0.010509953834116459,
      "learning_rate": 1.007266855066613e-05,
      "loss": 0.0209,
      "step": 24590
    },
    {
      "epoch": 9.931368591037545,
      "grad_norm": 4.777632713317871,
      "learning_rate": 1.0068631408962456e-05,
      "loss": 0.0269,
      "step": 24600
    },
    {
      "epoch": 9.93540573274122,
      "grad_norm": 0.002904202789068222,
      "learning_rate": 1.0064594267258782e-05,
      "loss": 0.0404,
      "step": 24610
    },
    {
      "epoch": 9.939442874444893,
      "grad_norm": 0.0033659543842077255,
      "learning_rate": 1.0060557125555108e-05,
      "loss": 0.0088,
      "step": 24620
    },
    {
      "epoch": 9.943480016148566,
      "grad_norm": 1.411341905593872,
      "learning_rate": 1.0056519983851434e-05,
      "loss": 0.0117,
      "step": 24630
    },
    {
      "epoch": 9.947517157852241,
      "grad_norm": 0.042820610105991364,
      "learning_rate": 1.0052482842147759e-05,
      "loss": 0.0325,
      "step": 24640
    },
    {
      "epoch": 9.951554299555914,
      "grad_norm": 1.7065731287002563,
      "learning_rate": 1.0048445700444087e-05,
      "loss": 0.0153,
      "step": 24650
    },
    {
      "epoch": 9.955591441259589,
      "grad_norm": 1.0152021646499634,
      "learning_rate": 1.0044408558740413e-05,
      "loss": 0.0177,
      "step": 24660
    },
    {
      "epoch": 9.959628582963262,
      "grad_norm": 0.7082903981208801,
      "learning_rate": 1.0040371417036738e-05,
      "loss": 0.0153,
      "step": 24670
    },
    {
      "epoch": 9.963665724666935,
      "grad_norm": 0.014326383359730244,
      "learning_rate": 1.0036334275333064e-05,
      "loss": 0.0153,
      "step": 24680
    },
    {
      "epoch": 9.96770286637061,
      "grad_norm": 0.6680399179458618,
      "learning_rate": 1.0032297133629392e-05,
      "loss": 0.05,
      "step": 24690
    },
    {
      "epoch": 9.971740008074283,
      "grad_norm": 1.634390950202942,
      "learning_rate": 1.0028259991925717e-05,
      "loss": 0.0174,
      "step": 24700
    },
    {
      "epoch": 9.975777149777958,
      "grad_norm": 1.624098777770996,
      "learning_rate": 1.0024222850222043e-05,
      "loss": 0.0091,
      "step": 24710
    },
    {
      "epoch": 9.979814291481631,
      "grad_norm": 0.17163094878196716,
      "learning_rate": 1.0020185708518371e-05,
      "loss": 0.0237,
      "step": 24720
    },
    {
      "epoch": 9.983851433185304,
      "grad_norm": 0.025349747389554977,
      "learning_rate": 1.0016148566814696e-05,
      "loss": 0.0115,
      "step": 24730
    },
    {
      "epoch": 9.987888574888979,
      "grad_norm": 0.023435892537236214,
      "learning_rate": 1.0012111425111022e-05,
      "loss": 0.0127,
      "step": 24740
    },
    {
      "epoch": 9.991925716592652,
      "grad_norm": 1.586100697517395,
      "learning_rate": 1.0008074283407348e-05,
      "loss": 0.0054,
      "step": 24750
    },
    {
      "epoch": 9.995962858296327,
      "grad_norm": 0.00129686389118433,
      "learning_rate": 1.0004037141703675e-05,
      "loss": 0.0176,
      "step": 24760
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.004785985220223665,
      "learning_rate": 1e-05,
      "loss": 0.0104,
      "step": 24770
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9849056603773585,
      "eval_f1": 0.9453614114968697,
      "eval_loss": 0.06187790259718895,
      "eval_precision": 0.9363021420518602,
      "eval_recall": 0.9545977011494253,
      "eval_runtime": 442.4513,
      "eval_samples_per_second": 28.794,
      "eval_steps_per_second": 1.2,
      "step": 24770
    },
    {
      "epoch": 10.004037141703673,
      "grad_norm": 0.0036718654446303844,
      "learning_rate": 9.995962858296327e-06,
      "loss": 0.0001,
      "step": 24780
    },
    {
      "epoch": 10.008074283407348,
      "grad_norm": 9.155202865600586,
      "learning_rate": 9.991925716592653e-06,
      "loss": 0.0295,
      "step": 24790
    },
    {
      "epoch": 10.012111425111021,
      "grad_norm": 0.0010074537713080645,
      "learning_rate": 9.98788857488898e-06,
      "loss": 0.0349,
      "step": 24800
    },
    {
      "epoch": 10.016148566814696,
      "grad_norm": 2.6159114837646484,
      "learning_rate": 9.983851433185306e-06,
      "loss": 0.0217,
      "step": 24810
    },
    {
      "epoch": 10.020185708518369,
      "grad_norm": 0.006761779543012381,
      "learning_rate": 9.979814291481632e-06,
      "loss": 0.0167,
      "step": 24820
    },
    {
      "epoch": 10.024222850222042,
      "grad_norm": 1.891283631324768,
      "learning_rate": 9.975777149777957e-06,
      "loss": 0.015,
      "step": 24830
    },
    {
      "epoch": 10.028259991925717,
      "grad_norm": 1.0972801446914673,
      "learning_rate": 9.971740008074285e-06,
      "loss": 0.023,
      "step": 24840
    },
    {
      "epoch": 10.03229713362939,
      "grad_norm": 0.002754860557615757,
      "learning_rate": 9.96770286637061e-06,
      "loss": 0.0384,
      "step": 24850
    },
    {
      "epoch": 10.036334275333065,
      "grad_norm": 1.4039586782455444,
      "learning_rate": 9.963665724666937e-06,
      "loss": 0.0125,
      "step": 24860
    },
    {
      "epoch": 10.040371417036738,
      "grad_norm": 0.0014205161714926362,
      "learning_rate": 9.959628582963264e-06,
      "loss": 0.0072,
      "step": 24870
    },
    {
      "epoch": 10.044408558740411,
      "grad_norm": 0.0016869092360138893,
      "learning_rate": 9.955591441259588e-06,
      "loss": 0.0572,
      "step": 24880
    },
    {
      "epoch": 10.048445700444086,
      "grad_norm": 2.214653491973877,
      "learning_rate": 9.951554299555916e-06,
      "loss": 0.0416,
      "step": 24890
    },
    {
      "epoch": 10.052482842147759,
      "grad_norm": 0.0055915978737175465,
      "learning_rate": 9.947517157852241e-06,
      "loss": 0.0433,
      "step": 24900
    },
    {
      "epoch": 10.056519983851434,
      "grad_norm": 0.005521383602172136,
      "learning_rate": 9.943480016148567e-06,
      "loss": 0.0217,
      "step": 24910
    },
    {
      "epoch": 10.060557125555107,
      "grad_norm": 14.66208553314209,
      "learning_rate": 9.939442874444893e-06,
      "loss": 0.0217,
      "step": 24920
    },
    {
      "epoch": 10.06459426725878,
      "grad_norm": 0.002644916530698538,
      "learning_rate": 9.93540573274122e-06,
      "loss": 0.0162,
      "step": 24930
    },
    {
      "epoch": 10.068631408962455,
      "grad_norm": 4.414356708526611,
      "learning_rate": 9.931368591037546e-06,
      "loss": 0.0131,
      "step": 24940
    },
    {
      "epoch": 10.072668550666128,
      "grad_norm": 0.0030277196783572435,
      "learning_rate": 9.927331449333872e-06,
      "loss": 0.0023,
      "step": 24950
    },
    {
      "epoch": 10.076705692369803,
      "grad_norm": 1.635016918182373,
      "learning_rate": 9.923294307630199e-06,
      "loss": 0.0196,
      "step": 24960
    },
    {
      "epoch": 10.080742834073476,
      "grad_norm": 0.0012182757491245866,
      "learning_rate": 9.919257165926525e-06,
      "loss": 0.0013,
      "step": 24970
    },
    {
      "epoch": 10.084779975777149,
      "grad_norm": 4.275399208068848,
      "learning_rate": 9.915220024222851e-06,
      "loss": 0.0251,
      "step": 24980
    },
    {
      "epoch": 10.088817117480824,
      "grad_norm": 0.0008214967674575746,
      "learning_rate": 9.911182882519177e-06,
      "loss": 0.0138,
      "step": 24990
    },
    {
      "epoch": 10.092854259184497,
      "grad_norm": 1.1239875555038452,
      "learning_rate": 9.907145740815504e-06,
      "loss": 0.0055,
      "step": 25000
    },
    {
      "epoch": 10.096891400888172,
      "grad_norm": 0.004838386084884405,
      "learning_rate": 9.90310859911183e-06,
      "loss": 0.0068,
      "step": 25010
    },
    {
      "epoch": 10.100928542591845,
      "grad_norm": 0.0031580801587551832,
      "learning_rate": 9.899071457408156e-06,
      "loss": 0.0012,
      "step": 25020
    },
    {
      "epoch": 10.104965684295518,
      "grad_norm": 0.0023045141715556383,
      "learning_rate": 9.895034315704483e-06,
      "loss": 0.0123,
      "step": 25030
    },
    {
      "epoch": 10.109002825999193,
      "grad_norm": 0.021668141707777977,
      "learning_rate": 9.890997174000809e-06,
      "loss": 0.0161,
      "step": 25040
    },
    {
      "epoch": 10.113039967702866,
      "grad_norm": 0.002887798473238945,
      "learning_rate": 9.886960032297135e-06,
      "loss": 0.0002,
      "step": 25050
    },
    {
      "epoch": 10.11707710940654,
      "grad_norm": 0.0034536386374384165,
      "learning_rate": 9.88292289059346e-06,
      "loss": 0.0232,
      "step": 25060
    },
    {
      "epoch": 10.121114251110214,
      "grad_norm": 0.010255351662635803,
      "learning_rate": 9.878885748889788e-06,
      "loss": 0.0518,
      "step": 25070
    },
    {
      "epoch": 10.125151392813887,
      "grad_norm": 0.0019246835727244616,
      "learning_rate": 9.874848607186112e-06,
      "loss": 0.0229,
      "step": 25080
    },
    {
      "epoch": 10.129188534517562,
      "grad_norm": 0.0029714747797697783,
      "learning_rate": 9.870811465482439e-06,
      "loss": 0.0003,
      "step": 25090
    },
    {
      "epoch": 10.133225676221235,
      "grad_norm": 0.05455641448497772,
      "learning_rate": 9.866774323778765e-06,
      "loss": 0.0466,
      "step": 25100
    },
    {
      "epoch": 10.13726281792491,
      "grad_norm": 0.019966378808021545,
      "learning_rate": 9.862737182075091e-06,
      "loss": 0.0197,
      "step": 25110
    },
    {
      "epoch": 10.141299959628583,
      "grad_norm": 0.007646000478416681,
      "learning_rate": 9.85870004037142e-06,
      "loss": 0.0161,
      "step": 25120
    },
    {
      "epoch": 10.145337101332256,
      "grad_norm": 0.019274242222309113,
      "learning_rate": 9.854662898667744e-06,
      "loss": 0.0081,
      "step": 25130
    },
    {
      "epoch": 10.14937424303593,
      "grad_norm": 1.6705728769302368,
      "learning_rate": 9.85062575696407e-06,
      "loss": 0.0276,
      "step": 25140
    },
    {
      "epoch": 10.153411384739604,
      "grad_norm": 0.35243648290634155,
      "learning_rate": 9.846588615260396e-06,
      "loss": 0.022,
      "step": 25150
    },
    {
      "epoch": 10.157448526443279,
      "grad_norm": 16.82210922241211,
      "learning_rate": 9.842551473556723e-06,
      "loss": 0.018,
      "step": 25160
    },
    {
      "epoch": 10.161485668146952,
      "grad_norm": 2.6019413471221924,
      "learning_rate": 9.838514331853049e-06,
      "loss": 0.0148,
      "step": 25170
    },
    {
      "epoch": 10.165522809850625,
      "grad_norm": 0.0036816971842199564,
      "learning_rate": 9.834477190149375e-06,
      "loss": 0.0126,
      "step": 25180
    },
    {
      "epoch": 10.1695599515543,
      "grad_norm": 3.0475919246673584,
      "learning_rate": 9.830440048445701e-06,
      "loss": 0.0124,
      "step": 25190
    },
    {
      "epoch": 10.173597093257973,
      "grad_norm": 0.058428842574357986,
      "learning_rate": 9.826402906742028e-06,
      "loss": 0.0335,
      "step": 25200
    },
    {
      "epoch": 10.177634234961648,
      "grad_norm": 0.003352554515004158,
      "learning_rate": 9.822365765038354e-06,
      "loss": 0.0298,
      "step": 25210
    },
    {
      "epoch": 10.18167137666532,
      "grad_norm": 2.1379401683807373,
      "learning_rate": 9.81832862333468e-06,
      "loss": 0.0284,
      "step": 25220
    },
    {
      "epoch": 10.185708518368994,
      "grad_norm": 0.0851522907614708,
      "learning_rate": 9.814291481631007e-06,
      "loss": 0.0147,
      "step": 25230
    },
    {
      "epoch": 10.189745660072669,
      "grad_norm": 0.009706974029541016,
      "learning_rate": 9.810254339927331e-06,
      "loss": 0.0065,
      "step": 25240
    },
    {
      "epoch": 10.193782801776342,
      "grad_norm": 0.0074635096825659275,
      "learning_rate": 9.80621719822366e-06,
      "loss": 0.0223,
      "step": 25250
    },
    {
      "epoch": 10.197819943480017,
      "grad_norm": 1.8258848190307617,
      "learning_rate": 9.802180056519984e-06,
      "loss": 0.0169,
      "step": 25260
    },
    {
      "epoch": 10.20185708518369,
      "grad_norm": 6.994968891143799,
      "learning_rate": 9.798142914816312e-06,
      "loss": 0.0249,
      "step": 25270
    },
    {
      "epoch": 10.205894226887363,
      "grad_norm": 1.5368086099624634,
      "learning_rate": 9.794105773112636e-06,
      "loss": 0.0053,
      "step": 25280
    },
    {
      "epoch": 10.209931368591038,
      "grad_norm": 0.019739290699362755,
      "learning_rate": 9.790068631408963e-06,
      "loss": 0.0077,
      "step": 25290
    },
    {
      "epoch": 10.21396851029471,
      "grad_norm": 0.007392393425107002,
      "learning_rate": 9.78603148970529e-06,
      "loss": 0.004,
      "step": 25300
    },
    {
      "epoch": 10.218005651998386,
      "grad_norm": 0.009709595702588558,
      "learning_rate": 9.781994348001615e-06,
      "loss": 0.0155,
      "step": 25310
    },
    {
      "epoch": 10.222042793702059,
      "grad_norm": 0.0011035299394279718,
      "learning_rate": 9.777957206297942e-06,
      "loss": 0.0002,
      "step": 25320
    },
    {
      "epoch": 10.226079935405732,
      "grad_norm": 3.008733034133911,
      "learning_rate": 9.773920064594268e-06,
      "loss": 0.007,
      "step": 25330
    },
    {
      "epoch": 10.230117077109407,
      "grad_norm": 0.001984472619369626,
      "learning_rate": 9.769882922890594e-06,
      "loss": 0.0506,
      "step": 25340
    },
    {
      "epoch": 10.23415421881308,
      "grad_norm": 0.001024288241751492,
      "learning_rate": 9.76584578118692e-06,
      "loss": 0.0008,
      "step": 25350
    },
    {
      "epoch": 10.238191360516755,
      "grad_norm": 1.2491716146469116,
      "learning_rate": 9.761808639483247e-06,
      "loss": 0.0493,
      "step": 25360
    },
    {
      "epoch": 10.242228502220428,
      "grad_norm": 1.5806752443313599,
      "learning_rate": 9.757771497779573e-06,
      "loss": 0.0068,
      "step": 25370
    },
    {
      "epoch": 10.2462656439241,
      "grad_norm": 0.001660037785768509,
      "learning_rate": 9.7537343560759e-06,
      "loss": 0.0276,
      "step": 25380
    },
    {
      "epoch": 10.250302785627776,
      "grad_norm": 0.005087733268737793,
      "learning_rate": 9.749697214372226e-06,
      "loss": 0.0075,
      "step": 25390
    },
    {
      "epoch": 10.254339927331449,
      "grad_norm": 0.12822505831718445,
      "learning_rate": 9.745660072668552e-06,
      "loss": 0.0022,
      "step": 25400
    },
    {
      "epoch": 10.258377069035124,
      "grad_norm": 0.002362083876505494,
      "learning_rate": 9.741622930964878e-06,
      "loss": 0.0024,
      "step": 25410
    },
    {
      "epoch": 10.262414210738797,
      "grad_norm": 0.7240227460861206,
      "learning_rate": 9.737585789261204e-06,
      "loss": 0.0147,
      "step": 25420
    },
    {
      "epoch": 10.26645135244247,
      "grad_norm": 0.009628494270145893,
      "learning_rate": 9.73354864755753e-06,
      "loss": 0.0036,
      "step": 25430
    },
    {
      "epoch": 10.270488494146145,
      "grad_norm": 0.000692318077199161,
      "learning_rate": 9.729511505853855e-06,
      "loss": 0.0089,
      "step": 25440
    },
    {
      "epoch": 10.274525635849818,
      "grad_norm": 0.004027022514492273,
      "learning_rate": 9.725474364150183e-06,
      "loss": 0.0422,
      "step": 25450
    },
    {
      "epoch": 10.278562777553493,
      "grad_norm": 0.00487055629491806,
      "learning_rate": 9.721437222446508e-06,
      "loss": 0.0061,
      "step": 25460
    },
    {
      "epoch": 10.282599919257166,
      "grad_norm": 1.0105534791946411,
      "learning_rate": 9.717400080742834e-06,
      "loss": 0.0094,
      "step": 25470
    },
    {
      "epoch": 10.286637060960839,
      "grad_norm": 0.002153464127331972,
      "learning_rate": 9.713362939039162e-06,
      "loss": 0.0083,
      "step": 25480
    },
    {
      "epoch": 10.290674202664514,
      "grad_norm": 0.015914924442768097,
      "learning_rate": 9.709325797335487e-06,
      "loss": 0.0058,
      "step": 25490
    },
    {
      "epoch": 10.294711344368187,
      "grad_norm": 0.0024166880175471306,
      "learning_rate": 9.705288655631813e-06,
      "loss": 0.0137,
      "step": 25500
    },
    {
      "epoch": 10.298748486071862,
      "grad_norm": 1.5169264078140259,
      "learning_rate": 9.70125151392814e-06,
      "loss": 0.0319,
      "step": 25510
    },
    {
      "epoch": 10.302785627775535,
      "grad_norm": 0.0050165425054728985,
      "learning_rate": 9.697214372224466e-06,
      "loss": 0.0064,
      "step": 25520
    },
    {
      "epoch": 10.306822769479208,
      "grad_norm": 0.0017036900389939547,
      "learning_rate": 9.693177230520792e-06,
      "loss": 0.0145,
      "step": 25530
    },
    {
      "epoch": 10.310859911182883,
      "grad_norm": 0.0017349388217553496,
      "learning_rate": 9.689140088817118e-06,
      "loss": 0.0102,
      "step": 25540
    },
    {
      "epoch": 10.314897052886556,
      "grad_norm": 0.0006775758229196072,
      "learning_rate": 9.685102947113444e-06,
      "loss": 0.0184,
      "step": 25550
    },
    {
      "epoch": 10.31893419459023,
      "grad_norm": 2.406193256378174,
      "learning_rate": 9.68106580540977e-06,
      "loss": 0.0023,
      "step": 25560
    },
    {
      "epoch": 10.322971336293904,
      "grad_norm": 0.002319046063348651,
      "learning_rate": 9.677028663706097e-06,
      "loss": 0.015,
      "step": 25570
    },
    {
      "epoch": 10.327008477997577,
      "grad_norm": 0.0017429175786674023,
      "learning_rate": 9.672991522002423e-06,
      "loss": 0.0627,
      "step": 25580
    },
    {
      "epoch": 10.331045619701252,
      "grad_norm": 0.0008914085919968784,
      "learning_rate": 9.66895438029875e-06,
      "loss": 0.0038,
      "step": 25590
    },
    {
      "epoch": 10.335082761404925,
      "grad_norm": 0.02455270104110241,
      "learning_rate": 9.664917238595076e-06,
      "loss": 0.0075,
      "step": 25600
    },
    {
      "epoch": 10.3391199031086,
      "grad_norm": 0.0005997829139232635,
      "learning_rate": 9.660880096891402e-06,
      "loss": 0.0231,
      "step": 25610
    },
    {
      "epoch": 10.343157044812273,
      "grad_norm": 0.0018716627964749932,
      "learning_rate": 9.656842955187727e-06,
      "loss": 0.0149,
      "step": 25620
    },
    {
      "epoch": 10.347194186515946,
      "grad_norm": 0.01251272764056921,
      "learning_rate": 9.652805813484055e-06,
      "loss": 0.0061,
      "step": 25630
    },
    {
      "epoch": 10.35123132821962,
      "grad_norm": 1.9250428676605225,
      "learning_rate": 9.648768671780381e-06,
      "loss": 0.0229,
      "step": 25640
    },
    {
      "epoch": 10.355268469923294,
      "grad_norm": 0.012616566382348537,
      "learning_rate": 9.644731530076706e-06,
      "loss": 0.0261,
      "step": 25650
    },
    {
      "epoch": 10.359305611626969,
      "grad_norm": 0.042849138379096985,
      "learning_rate": 9.640694388373034e-06,
      "loss": 0.0131,
      "step": 25660
    },
    {
      "epoch": 10.363342753330642,
      "grad_norm": 0.010455882176756859,
      "learning_rate": 9.636657246669358e-06,
      "loss": 0.0126,
      "step": 25670
    },
    {
      "epoch": 10.367379895034317,
      "grad_norm": 0.7591912746429443,
      "learning_rate": 9.632620104965686e-06,
      "loss": 0.06,
      "step": 25680
    },
    {
      "epoch": 10.37141703673799,
      "grad_norm": 0.003671885235235095,
      "learning_rate": 9.62858296326201e-06,
      "loss": 0.0052,
      "step": 25690
    },
    {
      "epoch": 10.375454178441663,
      "grad_norm": 0.0021651452407240868,
      "learning_rate": 9.624545821558337e-06,
      "loss": 0.0034,
      "step": 25700
    },
    {
      "epoch": 10.379491320145338,
      "grad_norm": 0.0026158683467656374,
      "learning_rate": 9.620508679854663e-06,
      "loss": 0.0027,
      "step": 25710
    },
    {
      "epoch": 10.38352846184901,
      "grad_norm": 0.0016297113616019487,
      "learning_rate": 9.61647153815099e-06,
      "loss": 0.0245,
      "step": 25720
    },
    {
      "epoch": 10.387565603552686,
      "grad_norm": 3.527550458908081,
      "learning_rate": 9.612434396447316e-06,
      "loss": 0.0322,
      "step": 25730
    },
    {
      "epoch": 10.391602745256359,
      "grad_norm": 0.8988478779792786,
      "learning_rate": 9.608397254743642e-06,
      "loss": 0.0144,
      "step": 25740
    },
    {
      "epoch": 10.395639886960032,
      "grad_norm": 0.5795464515686035,
      "learning_rate": 9.604360113039968e-06,
      "loss": 0.0149,
      "step": 25750
    },
    {
      "epoch": 10.399677028663707,
      "grad_norm": 0.0020622482988983393,
      "learning_rate": 9.600322971336295e-06,
      "loss": 0.017,
      "step": 25760
    },
    {
      "epoch": 10.40371417036738,
      "grad_norm": 0.006084656808525324,
      "learning_rate": 9.596285829632621e-06,
      "loss": 0.0359,
      "step": 25770
    },
    {
      "epoch": 10.407751312071055,
      "grad_norm": 0.010639967396855354,
      "learning_rate": 9.592248687928947e-06,
      "loss": 0.0173,
      "step": 25780
    },
    {
      "epoch": 10.411788453774728,
      "grad_norm": 0.02740461379289627,
      "learning_rate": 9.588211546225274e-06,
      "loss": 0.0116,
      "step": 25790
    },
    {
      "epoch": 10.4158255954784,
      "grad_norm": 0.008430910296738148,
      "learning_rate": 9.584174404521598e-06,
      "loss": 0.0095,
      "step": 25800
    },
    {
      "epoch": 10.419862737182076,
      "grad_norm": 1.9054852724075317,
      "learning_rate": 9.580137262817926e-06,
      "loss": 0.0341,
      "step": 25810
    },
    {
      "epoch": 10.423899878885749,
      "grad_norm": 0.6965465545654297,
      "learning_rate": 9.576100121114252e-06,
      "loss": 0.0379,
      "step": 25820
    },
    {
      "epoch": 10.427937020589424,
      "grad_norm": 1.797181487083435,
      "learning_rate": 9.572062979410579e-06,
      "loss": 0.0142,
      "step": 25830
    },
    {
      "epoch": 10.431974162293097,
      "grad_norm": 0.15314316749572754,
      "learning_rate": 9.568025837706905e-06,
      "loss": 0.0183,
      "step": 25840
    },
    {
      "epoch": 10.43601130399677,
      "grad_norm": 0.011724099516868591,
      "learning_rate": 9.56398869600323e-06,
      "loss": 0.0092,
      "step": 25850
    },
    {
      "epoch": 10.440048445700445,
      "grad_norm": 0.006730970926582813,
      "learning_rate": 9.559951554299558e-06,
      "loss": 0.0478,
      "step": 25860
    },
    {
      "epoch": 10.444085587404118,
      "grad_norm": 0.01135021448135376,
      "learning_rate": 9.555914412595882e-06,
      "loss": 0.001,
      "step": 25870
    },
    {
      "epoch": 10.448122729107792,
      "grad_norm": 0.011533495970070362,
      "learning_rate": 9.551877270892208e-06,
      "loss": 0.0141,
      "step": 25880
    },
    {
      "epoch": 10.452159870811466,
      "grad_norm": 10.212002754211426,
      "learning_rate": 9.547840129188535e-06,
      "loss": 0.0948,
      "step": 25890
    },
    {
      "epoch": 10.456197012515139,
      "grad_norm": 0.014215592294931412,
      "learning_rate": 9.543802987484861e-06,
      "loss": 0.0002,
      "step": 25900
    },
    {
      "epoch": 10.460234154218814,
      "grad_norm": 0.08933984488248825,
      "learning_rate": 9.539765845781187e-06,
      "loss": 0.0183,
      "step": 25910
    },
    {
      "epoch": 10.464271295922487,
      "grad_norm": 0.05350838974118233,
      "learning_rate": 9.535728704077514e-06,
      "loss": 0.0504,
      "step": 25920
    },
    {
      "epoch": 10.468308437626161,
      "grad_norm": 2.8986892700195312,
      "learning_rate": 9.53169156237384e-06,
      "loss": 0.0238,
      "step": 25930
    },
    {
      "epoch": 10.472345579329835,
      "grad_norm": 0.008406382985413074,
      "learning_rate": 9.527654420670166e-06,
      "loss": 0.0045,
      "step": 25940
    },
    {
      "epoch": 10.476382721033508,
      "grad_norm": 0.0037997569888830185,
      "learning_rate": 9.523617278966493e-06,
      "loss": 0.001,
      "step": 25950
    },
    {
      "epoch": 10.480419862737183,
      "grad_norm": 0.007451473269611597,
      "learning_rate": 9.519580137262819e-06,
      "loss": 0.0083,
      "step": 25960
    },
    {
      "epoch": 10.484457004440856,
      "grad_norm": 0.0032428286504000425,
      "learning_rate": 9.515542995559145e-06,
      "loss": 0.0156,
      "step": 25970
    },
    {
      "epoch": 10.48849414614453,
      "grad_norm": 0.026852793991565704,
      "learning_rate": 9.511505853855471e-06,
      "loss": 0.019,
      "step": 25980
    },
    {
      "epoch": 10.492531287848204,
      "grad_norm": 0.0016656300285831094,
      "learning_rate": 9.507468712151798e-06,
      "loss": 0.0191,
      "step": 25990
    },
    {
      "epoch": 10.496568429551877,
      "grad_norm": 1.234216570854187,
      "learning_rate": 9.503431570448124e-06,
      "loss": 0.0305,
      "step": 26000
    },
    {
      "epoch": 10.500605571255551,
      "grad_norm": 0.010624997317790985,
      "learning_rate": 9.49939442874445e-06,
      "loss": 0.0179,
      "step": 26010
    },
    {
      "epoch": 10.504642712959225,
      "grad_norm": 11.123210906982422,
      "learning_rate": 9.495357287040777e-06,
      "loss": 0.0119,
      "step": 26020
    },
    {
      "epoch": 10.5086798546629,
      "grad_norm": 0.009433561004698277,
      "learning_rate": 9.491320145337101e-06,
      "loss": 0.0201,
      "step": 26030
    },
    {
      "epoch": 10.512716996366573,
      "grad_norm": 0.0027389475144445896,
      "learning_rate": 9.487283003633429e-06,
      "loss": 0.0003,
      "step": 26040
    },
    {
      "epoch": 10.516754138070246,
      "grad_norm": 0.02521202154457569,
      "learning_rate": 9.483245861929754e-06,
      "loss": 0.016,
      "step": 26050
    },
    {
      "epoch": 10.52079127977392,
      "grad_norm": 1.1864888668060303,
      "learning_rate": 9.47920872022608e-06,
      "loss": 0.0085,
      "step": 26060
    },
    {
      "epoch": 10.524828421477594,
      "grad_norm": 0.0021995101124048233,
      "learning_rate": 9.475171578522408e-06,
      "loss": 0.0075,
      "step": 26070
    },
    {
      "epoch": 10.528865563181268,
      "grad_norm": 0.002184511860832572,
      "learning_rate": 9.471134436818733e-06,
      "loss": 0.0098,
      "step": 26080
    },
    {
      "epoch": 10.532902704884942,
      "grad_norm": 0.0011610151268541813,
      "learning_rate": 9.46709729511506e-06,
      "loss": 0.014,
      "step": 26090
    },
    {
      "epoch": 10.536939846588615,
      "grad_norm": 0.001692680991254747,
      "learning_rate": 9.463060153411385e-06,
      "loss": 0.0131,
      "step": 26100
    },
    {
      "epoch": 10.54097698829229,
      "grad_norm": 0.003417887957766652,
      "learning_rate": 9.459023011707711e-06,
      "loss": 0.0036,
      "step": 26110
    },
    {
      "epoch": 10.545014129995963,
      "grad_norm": 0.02828856185078621,
      "learning_rate": 9.454985870004038e-06,
      "loss": 0.0074,
      "step": 26120
    },
    {
      "epoch": 10.549051271699637,
      "grad_norm": 1.0941075086593628,
      "learning_rate": 9.450948728300364e-06,
      "loss": 0.0162,
      "step": 26130
    },
    {
      "epoch": 10.55308841340331,
      "grad_norm": 0.0019336719997227192,
      "learning_rate": 9.44691158659669e-06,
      "loss": 0.0116,
      "step": 26140
    },
    {
      "epoch": 10.557125555106984,
      "grad_norm": 0.0008351854048669338,
      "learning_rate": 9.442874444893017e-06,
      "loss": 0.0063,
      "step": 26150
    },
    {
      "epoch": 10.561162696810658,
      "grad_norm": 0.0038359183818101883,
      "learning_rate": 9.438837303189343e-06,
      "loss": 0.0761,
      "step": 26160
    },
    {
      "epoch": 10.565199838514332,
      "grad_norm": 2.5539422035217285,
      "learning_rate": 9.434800161485669e-06,
      "loss": 0.0138,
      "step": 26170
    },
    {
      "epoch": 10.569236980218006,
      "grad_norm": 0.0019351789960637689,
      "learning_rate": 9.430763019781995e-06,
      "loss": 0.0152,
      "step": 26180
    },
    {
      "epoch": 10.57327412192168,
      "grad_norm": 1.3987971544265747,
      "learning_rate": 9.426725878078322e-06,
      "loss": 0.0325,
      "step": 26190
    },
    {
      "epoch": 10.577311263625353,
      "grad_norm": 0.0029523991979658604,
      "learning_rate": 9.422688736374648e-06,
      "loss": 0.0,
      "step": 26200
    },
    {
      "epoch": 10.581348405329027,
      "grad_norm": 0.008670845068991184,
      "learning_rate": 9.418651594670973e-06,
      "loss": 0.008,
      "step": 26210
    },
    {
      "epoch": 10.5853855470327,
      "grad_norm": 1.5073204040527344,
      "learning_rate": 9.4146144529673e-06,
      "loss": 0.018,
      "step": 26220
    },
    {
      "epoch": 10.589422688736375,
      "grad_norm": 0.002055898541584611,
      "learning_rate": 9.410577311263625e-06,
      "loss": 0.0001,
      "step": 26230
    },
    {
      "epoch": 10.593459830440048,
      "grad_norm": 0.0360979400575161,
      "learning_rate": 9.406540169559953e-06,
      "loss": 0.0099,
      "step": 26240
    },
    {
      "epoch": 10.597496972143722,
      "grad_norm": 0.13058122992515564,
      "learning_rate": 9.40250302785628e-06,
      "loss": 0.0287,
      "step": 26250
    },
    {
      "epoch": 10.601534113847396,
      "grad_norm": 0.0006736069335602224,
      "learning_rate": 9.398465886152604e-06,
      "loss": 0.0059,
      "step": 26260
    },
    {
      "epoch": 10.60557125555107,
      "grad_norm": 0.001382332295179367,
      "learning_rate": 9.394428744448932e-06,
      "loss": 0.0088,
      "step": 26270
    },
    {
      "epoch": 10.609608397254744,
      "grad_norm": 0.014503470622003078,
      "learning_rate": 9.390391602745257e-06,
      "loss": 0.0063,
      "step": 26280
    },
    {
      "epoch": 10.613645538958417,
      "grad_norm": 0.0007233018986880779,
      "learning_rate": 9.386354461041583e-06,
      "loss": 0.0404,
      "step": 26290
    },
    {
      "epoch": 10.61768268066209,
      "grad_norm": 0.0015857042744755745,
      "learning_rate": 9.38231731933791e-06,
      "loss": 0.0047,
      "step": 26300
    },
    {
      "epoch": 10.621719822365765,
      "grad_norm": 1.1798449754714966,
      "learning_rate": 9.378280177634235e-06,
      "loss": 0.0059,
      "step": 26310
    },
    {
      "epoch": 10.625756964069438,
      "grad_norm": 0.055563103407621384,
      "learning_rate": 9.374243035930562e-06,
      "loss": 0.0041,
      "step": 26320
    },
    {
      "epoch": 10.629794105773113,
      "grad_norm": 1.366123080253601,
      "learning_rate": 9.370205894226888e-06,
      "loss": 0.0104,
      "step": 26330
    },
    {
      "epoch": 10.633831247476786,
      "grad_norm": 0.004207619000226259,
      "learning_rate": 9.366168752523214e-06,
      "loss": 0.0199,
      "step": 26340
    },
    {
      "epoch": 10.63786838918046,
      "grad_norm": 0.000943349557928741,
      "learning_rate": 9.36213161081954e-06,
      "loss": 0.0045,
      "step": 26350
    },
    {
      "epoch": 10.641905530884134,
      "grad_norm": 0.005696083884686232,
      "learning_rate": 9.358094469115867e-06,
      "loss": 0.007,
      "step": 26360
    },
    {
      "epoch": 10.645942672587807,
      "grad_norm": 0.0008771498687565327,
      "learning_rate": 9.354057327412193e-06,
      "loss": 0.0053,
      "step": 26370
    },
    {
      "epoch": 10.649979814291482,
      "grad_norm": 0.0013899519108235836,
      "learning_rate": 9.35002018570852e-06,
      "loss": 0.0202,
      "step": 26380
    },
    {
      "epoch": 10.654016955995155,
      "grad_norm": 0.0009975304128602147,
      "learning_rate": 9.345983044004846e-06,
      "loss": 0.0136,
      "step": 26390
    },
    {
      "epoch": 10.658054097698828,
      "grad_norm": 0.033200256526470184,
      "learning_rate": 9.341945902301172e-06,
      "loss": 0.0134,
      "step": 26400
    },
    {
      "epoch": 10.662091239402503,
      "grad_norm": 0.0052182418294250965,
      "learning_rate": 9.337908760597498e-06,
      "loss": 0.0081,
      "step": 26410
    },
    {
      "epoch": 10.666128381106176,
      "grad_norm": 0.07832268625497818,
      "learning_rate": 9.333871618893825e-06,
      "loss": 0.0065,
      "step": 26420
    },
    {
      "epoch": 10.670165522809851,
      "grad_norm": 0.09455841779708862,
      "learning_rate": 9.329834477190151e-06,
      "loss": 0.0079,
      "step": 26430
    },
    {
      "epoch": 10.674202664513524,
      "grad_norm": 1.0258663892745972,
      "learning_rate": 9.325797335486475e-06,
      "loss": 0.0448,
      "step": 26440
    },
    {
      "epoch": 10.678239806217197,
      "grad_norm": 0.0011803301749750972,
      "learning_rate": 9.321760193782803e-06,
      "loss": 0.0097,
      "step": 26450
    },
    {
      "epoch": 10.682276947920872,
      "grad_norm": 0.009889066219329834,
      "learning_rate": 9.317723052079128e-06,
      "loss": 0.0026,
      "step": 26460
    },
    {
      "epoch": 10.686314089624545,
      "grad_norm": 0.00841374322772026,
      "learning_rate": 9.313685910375454e-06,
      "loss": 0.01,
      "step": 26470
    },
    {
      "epoch": 10.69035123132822,
      "grad_norm": 3.5564510822296143,
      "learning_rate": 9.30964876867178e-06,
      "loss": 0.0264,
      "step": 26480
    },
    {
      "epoch": 10.694388373031893,
      "grad_norm": 0.0035755157005041838,
      "learning_rate": 9.305611626968107e-06,
      "loss": 0.0126,
      "step": 26490
    },
    {
      "epoch": 10.698425514735566,
      "grad_norm": 2.8379368782043457,
      "learning_rate": 9.301574485264435e-06,
      "loss": 0.0128,
      "step": 26500
    },
    {
      "epoch": 10.702462656439241,
      "grad_norm": 1.2810596227645874,
      "learning_rate": 9.29753734356076e-06,
      "loss": 0.0047,
      "step": 26510
    },
    {
      "epoch": 10.706499798142914,
      "grad_norm": 0.0007132231839932501,
      "learning_rate": 9.293500201857086e-06,
      "loss": 0.0186,
      "step": 26520
    },
    {
      "epoch": 10.71053693984659,
      "grad_norm": 2.2155258655548096,
      "learning_rate": 9.289463060153412e-06,
      "loss": 0.0065,
      "step": 26530
    },
    {
      "epoch": 10.714574081550262,
      "grad_norm": 0.00291093229316175,
      "learning_rate": 9.285425918449738e-06,
      "loss": 0.0064,
      "step": 26540
    },
    {
      "epoch": 10.718611223253935,
      "grad_norm": 2.1964075565338135,
      "learning_rate": 9.281388776746065e-06,
      "loss": 0.017,
      "step": 26550
    },
    {
      "epoch": 10.72264836495761,
      "grad_norm": 0.003397619118914008,
      "learning_rate": 9.277351635042391e-06,
      "loss": 0.0204,
      "step": 26560
    },
    {
      "epoch": 10.726685506661283,
      "grad_norm": 0.008195554837584496,
      "learning_rate": 9.273314493338717e-06,
      "loss": 0.0383,
      "step": 26570
    },
    {
      "epoch": 10.730722648364958,
      "grad_norm": 0.004676009528338909,
      "learning_rate": 9.269277351635043e-06,
      "loss": 0.0235,
      "step": 26580
    },
    {
      "epoch": 10.734759790068631,
      "grad_norm": 0.0032021957449615,
      "learning_rate": 9.26524020993137e-06,
      "loss": 0.008,
      "step": 26590
    },
    {
      "epoch": 10.738796931772304,
      "grad_norm": 0.0014705946668982506,
      "learning_rate": 9.261203068227696e-06,
      "loss": 0.0001,
      "step": 26600
    },
    {
      "epoch": 10.74283407347598,
      "grad_norm": 0.000709313026163727,
      "learning_rate": 9.257165926524022e-06,
      "loss": 0.0125,
      "step": 26610
    },
    {
      "epoch": 10.746871215179652,
      "grad_norm": 0.0018142160261049867,
      "learning_rate": 9.253128784820347e-06,
      "loss": 0.0099,
      "step": 26620
    },
    {
      "epoch": 10.750908356883327,
      "grad_norm": 0.010312041267752647,
      "learning_rate": 9.249091643116675e-06,
      "loss": 0.0113,
      "step": 26630
    },
    {
      "epoch": 10.754945498587,
      "grad_norm": 0.0011255914578214288,
      "learning_rate": 9.245054501413e-06,
      "loss": 0.0116,
      "step": 26640
    },
    {
      "epoch": 10.758982640290673,
      "grad_norm": 0.0013478075852617621,
      "learning_rate": 9.241017359709328e-06,
      "loss": 0.0021,
      "step": 26650
    },
    {
      "epoch": 10.763019781994348,
      "grad_norm": 0.9128870368003845,
      "learning_rate": 9.236980218005652e-06,
      "loss": 0.0364,
      "step": 26660
    },
    {
      "epoch": 10.767056923698021,
      "grad_norm": 1.5542534589767456,
      "learning_rate": 9.232943076301978e-06,
      "loss": 0.021,
      "step": 26670
    },
    {
      "epoch": 10.771094065401696,
      "grad_norm": 2.367082357406616,
      "learning_rate": 9.228905934598306e-06,
      "loss": 0.0137,
      "step": 26680
    },
    {
      "epoch": 10.77513120710537,
      "grad_norm": 1.8850876092910767,
      "learning_rate": 9.224868792894631e-06,
      "loss": 0.0382,
      "step": 26690
    },
    {
      "epoch": 10.779168348809042,
      "grad_norm": 0.0020993833895772696,
      "learning_rate": 9.220831651190957e-06,
      "loss": 0.0058,
      "step": 26700
    },
    {
      "epoch": 10.783205490512717,
      "grad_norm": 0.013674180954694748,
      "learning_rate": 9.216794509487284e-06,
      "loss": 0.017,
      "step": 26710
    },
    {
      "epoch": 10.78724263221639,
      "grad_norm": 0.0028893842827528715,
      "learning_rate": 9.21275736778361e-06,
      "loss": 0.0471,
      "step": 26720
    },
    {
      "epoch": 10.791279773920065,
      "grad_norm": 1.5822265148162842,
      "learning_rate": 9.208720226079936e-06,
      "loss": 0.0133,
      "step": 26730
    },
    {
      "epoch": 10.795316915623738,
      "grad_norm": 0.001303845434449613,
      "learning_rate": 9.204683084376262e-06,
      "loss": 0.0564,
      "step": 26740
    },
    {
      "epoch": 10.799354057327411,
      "grad_norm": 0.001167649868875742,
      "learning_rate": 9.200645942672589e-06,
      "loss": 0.0294,
      "step": 26750
    },
    {
      "epoch": 10.803391199031086,
      "grad_norm": 0.0017460648668929935,
      "learning_rate": 9.196608800968915e-06,
      "loss": 0.037,
      "step": 26760
    },
    {
      "epoch": 10.80742834073476,
      "grad_norm": 0.004518726374953985,
      "learning_rate": 9.192571659265241e-06,
      "loss": 0.0105,
      "step": 26770
    },
    {
      "epoch": 10.811465482438434,
      "grad_norm": 4.136159896850586,
      "learning_rate": 9.188534517561568e-06,
      "loss": 0.0429,
      "step": 26780
    },
    {
      "epoch": 10.815502624142107,
      "grad_norm": 0.004795161075890064,
      "learning_rate": 9.184497375857894e-06,
      "loss": 0.0341,
      "step": 26790
    },
    {
      "epoch": 10.81953976584578,
      "grad_norm": 0.009192286990582943,
      "learning_rate": 9.18046023415422e-06,
      "loss": 0.0069,
      "step": 26800
    },
    {
      "epoch": 10.823576907549455,
      "grad_norm": 1.3882477283477783,
      "learning_rate": 9.176423092450546e-06,
      "loss": 0.0193,
      "step": 26810
    },
    {
      "epoch": 10.827614049253128,
      "grad_norm": 0.007187655661255121,
      "learning_rate": 9.172385950746871e-06,
      "loss": 0.032,
      "step": 26820
    },
    {
      "epoch": 10.831651190956803,
      "grad_norm": 0.1587814837694168,
      "learning_rate": 9.168348809043199e-06,
      "loss": 0.0024,
      "step": 26830
    },
    {
      "epoch": 10.835688332660476,
      "grad_norm": 0.030650122091174126,
      "learning_rate": 9.164311667339524e-06,
      "loss": 0.0128,
      "step": 26840
    },
    {
      "epoch": 10.83972547436415,
      "grad_norm": 0.03611007332801819,
      "learning_rate": 9.16027452563585e-06,
      "loss": 0.0034,
      "step": 26850
    },
    {
      "epoch": 10.843762616067824,
      "grad_norm": 0.006874621845781803,
      "learning_rate": 9.156237383932178e-06,
      "loss": 0.0274,
      "step": 26860
    },
    {
      "epoch": 10.847799757771497,
      "grad_norm": 1.2243832349777222,
      "learning_rate": 9.152200242228502e-06,
      "loss": 0.0089,
      "step": 26870
    },
    {
      "epoch": 10.851836899475172,
      "grad_norm": 1.495857834815979,
      "learning_rate": 9.148163100524829e-06,
      "loss": 0.0462,
      "step": 26880
    },
    {
      "epoch": 10.855874041178845,
      "grad_norm": 0.9252333641052246,
      "learning_rate": 9.144125958821155e-06,
      "loss": 0.0236,
      "step": 26890
    },
    {
      "epoch": 10.85991118288252,
      "grad_norm": 0.00636292202398181,
      "learning_rate": 9.140088817117481e-06,
      "loss": 0.0163,
      "step": 26900
    },
    {
      "epoch": 10.863948324586193,
      "grad_norm": 0.00197339104488492,
      "learning_rate": 9.136051675413808e-06,
      "loss": 0.0204,
      "step": 26910
    },
    {
      "epoch": 10.867985466289866,
      "grad_norm": 1.3003203868865967,
      "learning_rate": 9.132014533710134e-06,
      "loss": 0.0056,
      "step": 26920
    },
    {
      "epoch": 10.872022607993541,
      "grad_norm": 1.3881241083145142,
      "learning_rate": 9.12797739200646e-06,
      "loss": 0.0073,
      "step": 26930
    },
    {
      "epoch": 10.876059749697214,
      "grad_norm": 0.9048773646354675,
      "learning_rate": 9.123940250302786e-06,
      "loss": 0.0135,
      "step": 26940
    },
    {
      "epoch": 10.880096891400889,
      "grad_norm": 0.07428241521120071,
      "learning_rate": 9.119903108599113e-06,
      "loss": 0.0062,
      "step": 26950
    },
    {
      "epoch": 10.884134033104562,
      "grad_norm": 0.008625995367765427,
      "learning_rate": 9.115865966895439e-06,
      "loss": 0.0048,
      "step": 26960
    },
    {
      "epoch": 10.888171174808235,
      "grad_norm": 0.0009567358065396547,
      "learning_rate": 9.111828825191765e-06,
      "loss": 0.0082,
      "step": 26970
    },
    {
      "epoch": 10.89220831651191,
      "grad_norm": 0.7452138066291809,
      "learning_rate": 9.107791683488092e-06,
      "loss": 0.0232,
      "step": 26980
    },
    {
      "epoch": 10.896245458215583,
      "grad_norm": 0.0014086265582591295,
      "learning_rate": 9.103754541784418e-06,
      "loss": 0.0117,
      "step": 26990
    },
    {
      "epoch": 10.900282599919258,
      "grad_norm": 0.0009514575940556824,
      "learning_rate": 9.099717400080742e-06,
      "loss": 0.0062,
      "step": 27000
    },
    {
      "epoch": 10.904319741622931,
      "grad_norm": 0.003925398923456669,
      "learning_rate": 9.09568025837707e-06,
      "loss": 0.0069,
      "step": 27010
    },
    {
      "epoch": 10.908356883326604,
      "grad_norm": 0.002492435509338975,
      "learning_rate": 9.091643116673397e-06,
      "loss": 0.0107,
      "step": 27020
    },
    {
      "epoch": 10.912394025030279,
      "grad_norm": 0.025549106299877167,
      "learning_rate": 9.087605974969721e-06,
      "loss": 0.008,
      "step": 27030
    },
    {
      "epoch": 10.916431166733952,
      "grad_norm": 0.002898570615798235,
      "learning_rate": 9.08356883326605e-06,
      "loss": 0.0198,
      "step": 27040
    },
    {
      "epoch": 10.920468308437627,
      "grad_norm": 0.0009191228891722858,
      "learning_rate": 9.079531691562374e-06,
      "loss": 0.0076,
      "step": 27050
    },
    {
      "epoch": 10.9245054501413,
      "grad_norm": 0.007283311802893877,
      "learning_rate": 9.075494549858702e-06,
      "loss": 0.0353,
      "step": 27060
    },
    {
      "epoch": 10.928542591844973,
      "grad_norm": 0.0012653343146666884,
      "learning_rate": 9.071457408155026e-06,
      "loss": 0.0069,
      "step": 27070
    },
    {
      "epoch": 10.932579733548648,
      "grad_norm": 0.0009443711605854332,
      "learning_rate": 9.067420266451353e-06,
      "loss": 0.0096,
      "step": 27080
    },
    {
      "epoch": 10.936616875252321,
      "grad_norm": 0.0009405426098965108,
      "learning_rate": 9.063383124747679e-06,
      "loss": 0.0109,
      "step": 27090
    },
    {
      "epoch": 10.940654016955996,
      "grad_norm": 0.004083962645381689,
      "learning_rate": 9.059345983044005e-06,
      "loss": 0.0032,
      "step": 27100
    },
    {
      "epoch": 10.94469115865967,
      "grad_norm": 0.004980219528079033,
      "learning_rate": 9.055308841340332e-06,
      "loss": 0.0305,
      "step": 27110
    },
    {
      "epoch": 10.948728300363342,
      "grad_norm": 0.002879674779251218,
      "learning_rate": 9.051271699636658e-06,
      "loss": 0.0094,
      "step": 27120
    },
    {
      "epoch": 10.952765442067017,
      "grad_norm": 0.0595325343310833,
      "learning_rate": 9.047234557932984e-06,
      "loss": 0.0223,
      "step": 27130
    },
    {
      "epoch": 10.95680258377069,
      "grad_norm": 0.005174586549401283,
      "learning_rate": 9.04319741622931e-06,
      "loss": 0.0181,
      "step": 27140
    },
    {
      "epoch": 10.960839725474365,
      "grad_norm": 0.08167816698551178,
      "learning_rate": 9.039160274525637e-06,
      "loss": 0.0074,
      "step": 27150
    },
    {
      "epoch": 10.964876867178038,
      "grad_norm": 0.006347003858536482,
      "learning_rate": 9.035123132821963e-06,
      "loss": 0.0064,
      "step": 27160
    },
    {
      "epoch": 10.968914008881711,
      "grad_norm": 0.859629213809967,
      "learning_rate": 9.03108599111829e-06,
      "loss": 0.0215,
      "step": 27170
    },
    {
      "epoch": 10.972951150585386,
      "grad_norm": 0.7659289240837097,
      "learning_rate": 9.027048849414614e-06,
      "loss": 0.0097,
      "step": 27180
    },
    {
      "epoch": 10.97698829228906,
      "grad_norm": 1.17842435836792,
      "learning_rate": 9.023011707710942e-06,
      "loss": 0.0183,
      "step": 27190
    },
    {
      "epoch": 10.981025433992734,
      "grad_norm": 0.005488918162882328,
      "learning_rate": 9.018974566007268e-06,
      "loss": 0.0136,
      "step": 27200
    },
    {
      "epoch": 10.985062575696407,
      "grad_norm": 0.0006282979156821966,
      "learning_rate": 9.014937424303593e-06,
      "loss": 0.0221,
      "step": 27210
    },
    {
      "epoch": 10.98909971740008,
      "grad_norm": 0.07717005163431168,
      "learning_rate": 9.01090028259992e-06,
      "loss": 0.0033,
      "step": 27220
    },
    {
      "epoch": 10.993136859103755,
      "grad_norm": 19.00962257385254,
      "learning_rate": 9.006863140896245e-06,
      "loss": 0.0416,
      "step": 27230
    },
    {
      "epoch": 10.997174000807428,
      "grad_norm": 2.593459367752075,
      "learning_rate": 9.002825999192573e-06,
      "loss": 0.0142,
      "step": 27240
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.9853773584905661,
      "eval_f1": 0.9464285714285714,
      "eval_loss": 0.06636233627796173,
      "eval_precision": 0.9486143187066974,
      "eval_recall": 0.9442528735632184,
      "eval_runtime": 444.9111,
      "eval_samples_per_second": 28.635,
      "eval_steps_per_second": 1.193,
      "step": 27247
    },
    {
      "epoch": 11.001211142511103,
      "grad_norm": 0.002553802914917469,
      "learning_rate": 8.998788857488898e-06,
      "loss": 0.0528,
      "step": 27250
    },
    {
      "epoch": 11.005248284214776,
      "grad_norm": 0.0020733827259391546,
      "learning_rate": 8.994751715785224e-06,
      "loss": 0.0186,
      "step": 27260
    },
    {
      "epoch": 11.00928542591845,
      "grad_norm": 0.0030379313975572586,
      "learning_rate": 8.99071457408155e-06,
      "loss": 0.0362,
      "step": 27270
    },
    {
      "epoch": 11.013322567622124,
      "grad_norm": 0.0023416676558554173,
      "learning_rate": 8.986677432377877e-06,
      "loss": 0.0137,
      "step": 27280
    },
    {
      "epoch": 11.017359709325797,
      "grad_norm": 0.0010039422195404768,
      "learning_rate": 8.982640290674203e-06,
      "loss": 0.0072,
      "step": 27290
    },
    {
      "epoch": 11.021396851029472,
      "grad_norm": 0.0030114746186882257,
      "learning_rate": 8.97860314897053e-06,
      "loss": 0.0412,
      "step": 27300
    },
    {
      "epoch": 11.025433992733145,
      "grad_norm": 4.1508307456970215,
      "learning_rate": 8.974566007266856e-06,
      "loss": 0.0225,
      "step": 27310
    },
    {
      "epoch": 11.029471134436818,
      "grad_norm": 0.0024590000975877047,
      "learning_rate": 8.970528865563182e-06,
      "loss": 0.0048,
      "step": 27320
    },
    {
      "epoch": 11.033508276140493,
      "grad_norm": 0.0016695476369932294,
      "learning_rate": 8.966491723859508e-06,
      "loss": 0.013,
      "step": 27330
    },
    {
      "epoch": 11.037545417844166,
      "grad_norm": 0.0007426634547300637,
      "learning_rate": 8.962454582155835e-06,
      "loss": 0.005,
      "step": 27340
    },
    {
      "epoch": 11.041582559547841,
      "grad_norm": 0.0008511167834512889,
      "learning_rate": 8.95841744045216e-06,
      "loss": 0.0064,
      "step": 27350
    },
    {
      "epoch": 11.045619701251514,
      "grad_norm": 0.0015044495230540633,
      "learning_rate": 8.954380298748487e-06,
      "loss": 0.0135,
      "step": 27360
    },
    {
      "epoch": 11.049656842955187,
      "grad_norm": 0.0021893593948334455,
      "learning_rate": 8.950343157044813e-06,
      "loss": 0.0104,
      "step": 27370
    },
    {
      "epoch": 11.053693984658862,
      "grad_norm": 0.0007730929646641016,
      "learning_rate": 8.94630601534114e-06,
      "loss": 0.0,
      "step": 27380
    },
    {
      "epoch": 11.057731126362535,
      "grad_norm": 1.232374668121338,
      "learning_rate": 8.942268873637466e-06,
      "loss": 0.0202,
      "step": 27390
    },
    {
      "epoch": 11.06176826806621,
      "grad_norm": 1.3692508935928345,
      "learning_rate": 8.938231731933792e-06,
      "loss": 0.0299,
      "step": 27400
    },
    {
      "epoch": 11.065805409769883,
      "grad_norm": 0.0011151671642437577,
      "learning_rate": 8.934194590230117e-06,
      "loss": 0.0063,
      "step": 27410
    },
    {
      "epoch": 11.069842551473556,
      "grad_norm": 2.1715469360351562,
      "learning_rate": 8.930157448526445e-06,
      "loss": 0.011,
      "step": 27420
    },
    {
      "epoch": 11.073879693177231,
      "grad_norm": 0.0009241891093552113,
      "learning_rate": 8.92612030682277e-06,
      "loss": 0.0043,
      "step": 27430
    },
    {
      "epoch": 11.077916834880904,
      "grad_norm": 1.0638008117675781,
      "learning_rate": 8.922083165119096e-06,
      "loss": 0.0087,
      "step": 27440
    },
    {
      "epoch": 11.081953976584579,
      "grad_norm": 0.019034255295991898,
      "learning_rate": 8.918046023415424e-06,
      "loss": 0.0109,
      "step": 27450
    },
    {
      "epoch": 11.085991118288252,
      "grad_norm": 0.0007277924451045692,
      "learning_rate": 8.914008881711748e-06,
      "loss": 0.002,
      "step": 27460
    },
    {
      "epoch": 11.090028259991925,
      "grad_norm": 0.0006443003658205271,
      "learning_rate": 8.909971740008076e-06,
      "loss": 0.0016,
      "step": 27470
    },
    {
      "epoch": 11.0940654016956,
      "grad_norm": 0.6179346442222595,
      "learning_rate": 8.905934598304401e-06,
      "loss": 0.0208,
      "step": 27480
    },
    {
      "epoch": 11.098102543399273,
      "grad_norm": 0.0006627237889915705,
      "learning_rate": 8.901897456600727e-06,
      "loss": 0.0131,
      "step": 27490
    },
    {
      "epoch": 11.102139685102948,
      "grad_norm": 0.0014003498945385218,
      "learning_rate": 8.897860314897053e-06,
      "loss": 0.0066,
      "step": 27500
    },
    {
      "epoch": 11.106176826806621,
      "grad_norm": 1.7790452241897583,
      "learning_rate": 8.89382317319338e-06,
      "loss": 0.0201,
      "step": 27510
    },
    {
      "epoch": 11.110213968510294,
      "grad_norm": 0.0012669956777244806,
      "learning_rate": 8.889786031489706e-06,
      "loss": 0.0318,
      "step": 27520
    },
    {
      "epoch": 11.114251110213969,
      "grad_norm": 1.506795883178711,
      "learning_rate": 8.885748889786032e-06,
      "loss": 0.0195,
      "step": 27530
    },
    {
      "epoch": 11.118288251917642,
      "grad_norm": 1.595810890197754,
      "learning_rate": 8.881711748082359e-06,
      "loss": 0.0055,
      "step": 27540
    },
    {
      "epoch": 11.122325393621317,
      "grad_norm": 1.4642876386642456,
      "learning_rate": 8.877674606378685e-06,
      "loss": 0.0078,
      "step": 27550
    },
    {
      "epoch": 11.12636253532499,
      "grad_norm": 0.0023827285040169954,
      "learning_rate": 8.873637464675011e-06,
      "loss": 0.0084,
      "step": 27560
    },
    {
      "epoch": 11.130399677028663,
      "grad_norm": 0.0009583066566847265,
      "learning_rate": 8.869600322971337e-06,
      "loss": 0.0105,
      "step": 27570
    },
    {
      "epoch": 11.134436818732338,
      "grad_norm": 0.0008630483062006533,
      "learning_rate": 8.865563181267664e-06,
      "loss": 0.0077,
      "step": 27580
    },
    {
      "epoch": 11.138473960436011,
      "grad_norm": 0.0007282255101017654,
      "learning_rate": 8.861526039563988e-06,
      "loss": 0.0047,
      "step": 27590
    },
    {
      "epoch": 11.142511102139686,
      "grad_norm": 1.5794686079025269,
      "learning_rate": 8.857488897860316e-06,
      "loss": 0.0036,
      "step": 27600
    },
    {
      "epoch": 11.146548243843359,
      "grad_norm": 0.00037218770012259483,
      "learning_rate": 8.853451756156641e-06,
      "loss": 0.0143,
      "step": 27610
    },
    {
      "epoch": 11.150585385547032,
      "grad_norm": 0.0008676747092977166,
      "learning_rate": 8.849414614452967e-06,
      "loss": 0.0088,
      "step": 27620
    },
    {
      "epoch": 11.154622527250707,
      "grad_norm": 0.0007205729489214718,
      "learning_rate": 8.845377472749295e-06,
      "loss": 0.012,
      "step": 27630
    },
    {
      "epoch": 11.15865966895438,
      "grad_norm": 0.0015633008442819118,
      "learning_rate": 8.84134033104562e-06,
      "loss": 0.0124,
      "step": 27640
    },
    {
      "epoch": 11.162696810658055,
      "grad_norm": 2.2169225215911865,
      "learning_rate": 8.837303189341948e-06,
      "loss": 0.0129,
      "step": 27650
    },
    {
      "epoch": 11.166733952361728,
      "grad_norm": 0.015499573200941086,
      "learning_rate": 8.833266047638272e-06,
      "loss": 0.0056,
      "step": 27660
    },
    {
      "epoch": 11.170771094065401,
      "grad_norm": 0.00042534206295385957,
      "learning_rate": 8.829228905934599e-06,
      "loss": 0.0094,
      "step": 27670
    },
    {
      "epoch": 11.174808235769076,
      "grad_norm": 0.0024293868336826563,
      "learning_rate": 8.825191764230925e-06,
      "loss": 0.0074,
      "step": 27680
    },
    {
      "epoch": 11.178845377472749,
      "grad_norm": 0.0007258995901793242,
      "learning_rate": 8.821154622527251e-06,
      "loss": 0.0041,
      "step": 27690
    },
    {
      "epoch": 11.182882519176424,
      "grad_norm": 1.2179337739944458,
      "learning_rate": 8.817117480823577e-06,
      "loss": 0.0122,
      "step": 27700
    },
    {
      "epoch": 11.186919660880097,
      "grad_norm": 0.008872240781784058,
      "learning_rate": 8.813080339119904e-06,
      "loss": 0.0048,
      "step": 27710
    },
    {
      "epoch": 11.19095680258377,
      "grad_norm": 0.4201125204563141,
      "learning_rate": 8.80904319741623e-06,
      "loss": 0.0075,
      "step": 27720
    },
    {
      "epoch": 11.194993944287445,
      "grad_norm": 0.00035163460415787995,
      "learning_rate": 8.805006055712556e-06,
      "loss": 0.0007,
      "step": 27730
    },
    {
      "epoch": 11.199031085991118,
      "grad_norm": 0.0011645565973594785,
      "learning_rate": 8.800968914008883e-06,
      "loss": 0.0162,
      "step": 27740
    },
    {
      "epoch": 11.203068227694793,
      "grad_norm": 0.00047257720143534243,
      "learning_rate": 8.796931772305209e-06,
      "loss": 0.0203,
      "step": 27750
    },
    {
      "epoch": 11.207105369398466,
      "grad_norm": 0.0037665418349206448,
      "learning_rate": 8.792894630601535e-06,
      "loss": 0.0422,
      "step": 27760
    },
    {
      "epoch": 11.211142511102139,
      "grad_norm": 0.0022972356528043747,
      "learning_rate": 8.78885748889786e-06,
      "loss": 0.0026,
      "step": 27770
    },
    {
      "epoch": 11.215179652805814,
      "grad_norm": 0.001007281243801117,
      "learning_rate": 8.784820347194188e-06,
      "loss": 0.0136,
      "step": 27780
    },
    {
      "epoch": 11.219216794509487,
      "grad_norm": 1.1957604885101318,
      "learning_rate": 8.780783205490512e-06,
      "loss": 0.0063,
      "step": 27790
    },
    {
      "epoch": 11.223253936213162,
      "grad_norm": 0.01736185885965824,
      "learning_rate": 8.77674606378684e-06,
      "loss": 0.0082,
      "step": 27800
    },
    {
      "epoch": 11.227291077916835,
      "grad_norm": 0.0017267321236431599,
      "learning_rate": 8.772708922083167e-06,
      "loss": 0.0059,
      "step": 27810
    },
    {
      "epoch": 11.231328219620508,
      "grad_norm": 2.465707778930664,
      "learning_rate": 8.768671780379491e-06,
      "loss": 0.0479,
      "step": 27820
    },
    {
      "epoch": 11.235365361324183,
      "grad_norm": 0.7422181963920593,
      "learning_rate": 8.76463463867582e-06,
      "loss": 0.0039,
      "step": 27830
    },
    {
      "epoch": 11.239402503027856,
      "grad_norm": 2.319403886795044,
      "learning_rate": 8.760597496972144e-06,
      "loss": 0.0145,
      "step": 27840
    },
    {
      "epoch": 11.24343964473153,
      "grad_norm": 0.4003916382789612,
      "learning_rate": 8.75656035526847e-06,
      "loss": 0.032,
      "step": 27850
    },
    {
      "epoch": 11.247476786435204,
      "grad_norm": 0.34613141417503357,
      "learning_rate": 8.752523213564796e-06,
      "loss": 0.0123,
      "step": 27860
    },
    {
      "epoch": 11.251513928138877,
      "grad_norm": 0.4308805763721466,
      "learning_rate": 8.748486071861123e-06,
      "loss": 0.0029,
      "step": 27870
    },
    {
      "epoch": 11.255551069842552,
      "grad_norm": 2.2054269313812256,
      "learning_rate": 8.744448930157449e-06,
      "loss": 0.0256,
      "step": 27880
    },
    {
      "epoch": 11.259588211546225,
      "grad_norm": 1.1159451007843018,
      "learning_rate": 8.740411788453775e-06,
      "loss": 0.0256,
      "step": 27890
    },
    {
      "epoch": 11.2636253532499,
      "grad_norm": 0.9418319463729858,
      "learning_rate": 8.736374646750102e-06,
      "loss": 0.0254,
      "step": 27900
    },
    {
      "epoch": 11.267662494953573,
      "grad_norm": 2.1141817569732666,
      "learning_rate": 8.732337505046428e-06,
      "loss": 0.0083,
      "step": 27910
    },
    {
      "epoch": 11.271699636657246,
      "grad_norm": 0.03860106319189072,
      "learning_rate": 8.728300363342754e-06,
      "loss": 0.0164,
      "step": 27920
    },
    {
      "epoch": 11.27573677836092,
      "grad_norm": 1.463435411453247,
      "learning_rate": 8.72426322163908e-06,
      "loss": 0.0162,
      "step": 27930
    },
    {
      "epoch": 11.279773920064594,
      "grad_norm": 0.9633913636207581,
      "learning_rate": 8.720226079935407e-06,
      "loss": 0.0143,
      "step": 27940
    },
    {
      "epoch": 11.283811061768269,
      "grad_norm": 0.001349413301795721,
      "learning_rate": 8.716188938231733e-06,
      "loss": 0.0146,
      "step": 27950
    },
    {
      "epoch": 11.287848203471942,
      "grad_norm": 0.000954357092268765,
      "learning_rate": 8.71215179652806e-06,
      "loss": 0.018,
      "step": 27960
    },
    {
      "epoch": 11.291885345175615,
      "grad_norm": 0.006428646855056286,
      "learning_rate": 8.708114654824386e-06,
      "loss": 0.0068,
      "step": 27970
    },
    {
      "epoch": 11.29592248687929,
      "grad_norm": 0.01576545462012291,
      "learning_rate": 8.704077513120712e-06,
      "loss": 0.0067,
      "step": 27980
    },
    {
      "epoch": 11.299959628582963,
      "grad_norm": 0.0176202692091465,
      "learning_rate": 8.700040371417038e-06,
      "loss": 0.0171,
      "step": 27990
    },
    {
      "epoch": 11.303996770286638,
      "grad_norm": 2.0312423706054688,
      "learning_rate": 8.696003229713363e-06,
      "loss": 0.0148,
      "step": 28000
    },
    {
      "epoch": 11.30803391199031,
      "grad_norm": 0.010414376854896545,
      "learning_rate": 8.69196608800969e-06,
      "loss": 0.0325,
      "step": 28010
    },
    {
      "epoch": 11.312071053693984,
      "grad_norm": 0.00421379879117012,
      "learning_rate": 8.687928946306015e-06,
      "loss": 0.0047,
      "step": 28020
    },
    {
      "epoch": 11.316108195397659,
      "grad_norm": 0.0008745985687710345,
      "learning_rate": 8.683891804602342e-06,
      "loss": 0.0049,
      "step": 28030
    },
    {
      "epoch": 11.320145337101332,
      "grad_norm": 0.0018318227957934141,
      "learning_rate": 8.679854662898668e-06,
      "loss": 0.008,
      "step": 28040
    },
    {
      "epoch": 11.324182478805007,
      "grad_norm": 0.07970783114433289,
      "learning_rate": 8.675817521194994e-06,
      "loss": 0.0076,
      "step": 28050
    },
    {
      "epoch": 11.32821962050868,
      "grad_norm": 2.1633880138397217,
      "learning_rate": 8.671780379491322e-06,
      "loss": 0.0429,
      "step": 28060
    },
    {
      "epoch": 11.332256762212353,
      "grad_norm": 0.0005699580069631338,
      "learning_rate": 8.667743237787647e-06,
      "loss": 0.0233,
      "step": 28070
    },
    {
      "epoch": 11.336293903916028,
      "grad_norm": 0.042286068201065063,
      "learning_rate": 8.663706096083973e-06,
      "loss": 0.0751,
      "step": 28080
    },
    {
      "epoch": 11.3403310456197,
      "grad_norm": 0.007793950382620096,
      "learning_rate": 8.6596689543803e-06,
      "loss": 0.0325,
      "step": 28090
    },
    {
      "epoch": 11.344368187323376,
      "grad_norm": 0.006559529807418585,
      "learning_rate": 8.655631812676626e-06,
      "loss": 0.0003,
      "step": 28100
    },
    {
      "epoch": 11.348405329027049,
      "grad_norm": 0.03830872103571892,
      "learning_rate": 8.651594670972952e-06,
      "loss": 0.0124,
      "step": 28110
    },
    {
      "epoch": 11.352442470730722,
      "grad_norm": 0.0031494610011577606,
      "learning_rate": 8.647557529269278e-06,
      "loss": 0.009,
      "step": 28120
    },
    {
      "epoch": 11.356479612434397,
      "grad_norm": 0.006978361867368221,
      "learning_rate": 8.643520387565604e-06,
      "loss": 0.0078,
      "step": 28130
    },
    {
      "epoch": 11.36051675413807,
      "grad_norm": 0.004333471413701773,
      "learning_rate": 8.63948324586193e-06,
      "loss": 0.0146,
      "step": 28140
    },
    {
      "epoch": 11.364553895841745,
      "grad_norm": 0.0220487043261528,
      "learning_rate": 8.635446104158257e-06,
      "loss": 0.0338,
      "step": 28150
    },
    {
      "epoch": 11.368591037545418,
      "grad_norm": 0.012147091329097748,
      "learning_rate": 8.631408962454583e-06,
      "loss": 0.02,
      "step": 28160
    },
    {
      "epoch": 11.37262817924909,
      "grad_norm": 0.018034394830465317,
      "learning_rate": 8.62737182075091e-06,
      "loss": 0.0027,
      "step": 28170
    },
    {
      "epoch": 11.376665320952766,
      "grad_norm": 0.003729988355189562,
      "learning_rate": 8.623334679047234e-06,
      "loss": 0.0074,
      "step": 28180
    },
    {
      "epoch": 11.380702462656439,
      "grad_norm": 0.02962641231715679,
      "learning_rate": 8.619297537343562e-06,
      "loss": 0.0149,
      "step": 28190
    },
    {
      "epoch": 11.384739604360114,
      "grad_norm": 1.2690702676773071,
      "learning_rate": 8.615260395639887e-06,
      "loss": 0.0223,
      "step": 28200
    },
    {
      "epoch": 11.388776746063787,
      "grad_norm": 0.03680788725614548,
      "learning_rate": 8.611223253936215e-06,
      "loss": 0.0227,
      "step": 28210
    },
    {
      "epoch": 11.39281388776746,
      "grad_norm": 0.0036481732968240976,
      "learning_rate": 8.60718611223254e-06,
      "loss": 0.0068,
      "step": 28220
    },
    {
      "epoch": 11.396851029471135,
      "grad_norm": 0.002464265562593937,
      "learning_rate": 8.603148970528866e-06,
      "loss": 0.0174,
      "step": 28230
    },
    {
      "epoch": 11.400888171174808,
      "grad_norm": 0.718232274055481,
      "learning_rate": 8.599111828825194e-06,
      "loss": 0.0046,
      "step": 28240
    },
    {
      "epoch": 11.404925312878483,
      "grad_norm": 0.004590080585330725,
      "learning_rate": 8.595074687121518e-06,
      "loss": 0.0037,
      "step": 28250
    },
    {
      "epoch": 11.408962454582156,
      "grad_norm": 0.001653506187722087,
      "learning_rate": 8.591037545417844e-06,
      "loss": 0.0164,
      "step": 28260
    },
    {
      "epoch": 11.412999596285829,
      "grad_norm": 0.00129016546998173,
      "learning_rate": 8.58700040371417e-06,
      "loss": 0.0394,
      "step": 28270
    },
    {
      "epoch": 11.417036737989504,
      "grad_norm": 0.008523382246494293,
      "learning_rate": 8.582963262010497e-06,
      "loss": 0.0158,
      "step": 28280
    },
    {
      "epoch": 11.421073879693177,
      "grad_norm": 0.005571683868765831,
      "learning_rate": 8.578926120306823e-06,
      "loss": 0.0083,
      "step": 28290
    },
    {
      "epoch": 11.425111021396852,
      "grad_norm": 0.0017676528077572584,
      "learning_rate": 8.57488897860315e-06,
      "loss": 0.0056,
      "step": 28300
    },
    {
      "epoch": 11.429148163100525,
      "grad_norm": 0.005720337387174368,
      "learning_rate": 8.570851836899476e-06,
      "loss": 0.0384,
      "step": 28310
    },
    {
      "epoch": 11.433185304804198,
      "grad_norm": 0.002170417457818985,
      "learning_rate": 8.566814695195802e-06,
      "loss": 0.0038,
      "step": 28320
    },
    {
      "epoch": 11.437222446507873,
      "grad_norm": 0.00575739610940218,
      "learning_rate": 8.562777553492128e-06,
      "loss": 0.008,
      "step": 28330
    },
    {
      "epoch": 11.441259588211546,
      "grad_norm": 0.0016086434479802847,
      "learning_rate": 8.558740411788455e-06,
      "loss": 0.0233,
      "step": 28340
    },
    {
      "epoch": 11.44529672991522,
      "grad_norm": 1.2140591144561768,
      "learning_rate": 8.554703270084781e-06,
      "loss": 0.0094,
      "step": 28350
    },
    {
      "epoch": 11.449333871618894,
      "grad_norm": 2.128750801086426,
      "learning_rate": 8.550666128381107e-06,
      "loss": 0.0102,
      "step": 28360
    },
    {
      "epoch": 11.453371013322567,
      "grad_norm": 1.14076566696167,
      "learning_rate": 8.546628986677434e-06,
      "loss": 0.0658,
      "step": 28370
    },
    {
      "epoch": 11.457408155026242,
      "grad_norm": 2.588503360748291,
      "learning_rate": 8.542591844973758e-06,
      "loss": 0.0264,
      "step": 28380
    },
    {
      "epoch": 11.461445296729915,
      "grad_norm": 0.0009005560423247516,
      "learning_rate": 8.538554703270086e-06,
      "loss": 0.0074,
      "step": 28390
    },
    {
      "epoch": 11.46548243843359,
      "grad_norm": 0.002991983899846673,
      "learning_rate": 8.534517561566412e-06,
      "loss": 0.0205,
      "step": 28400
    },
    {
      "epoch": 11.469519580137263,
      "grad_norm": 0.0012157665332779288,
      "learning_rate": 8.530480419862737e-06,
      "loss": 0.0001,
      "step": 28410
    },
    {
      "epoch": 11.473556721840936,
      "grad_norm": 0.0008108033798635006,
      "learning_rate": 8.526443278159065e-06,
      "loss": 0.0006,
      "step": 28420
    },
    {
      "epoch": 11.47759386354461,
      "grad_norm": 0.003091638209298253,
      "learning_rate": 8.52240613645539e-06,
      "loss": 0.0397,
      "step": 28430
    },
    {
      "epoch": 11.481631005248284,
      "grad_norm": 2.458876848220825,
      "learning_rate": 8.518368994751716e-06,
      "loss": 0.0156,
      "step": 28440
    },
    {
      "epoch": 11.485668146951959,
      "grad_norm": 0.002397682284936309,
      "learning_rate": 8.514331853048042e-06,
      "loss": 0.0176,
      "step": 28450
    },
    {
      "epoch": 11.489705288655632,
      "grad_norm": 0.006851117592304945,
      "learning_rate": 8.510294711344368e-06,
      "loss": 0.0104,
      "step": 28460
    },
    {
      "epoch": 11.493742430359305,
      "grad_norm": 0.0066061243414878845,
      "learning_rate": 8.506257569640695e-06,
      "loss": 0.0086,
      "step": 28470
    },
    {
      "epoch": 11.49777957206298,
      "grad_norm": 0.0019231829792261124,
      "learning_rate": 8.502220427937021e-06,
      "loss": 0.0098,
      "step": 28480
    },
    {
      "epoch": 11.501816713766653,
      "grad_norm": 0.010592964477837086,
      "learning_rate": 8.498183286233347e-06,
      "loss": 0.006,
      "step": 28490
    },
    {
      "epoch": 11.505853855470328,
      "grad_norm": 34.38673400878906,
      "learning_rate": 8.494146144529674e-06,
      "loss": 0.0233,
      "step": 28500
    },
    {
      "epoch": 11.509890997174,
      "grad_norm": 0.019698210060596466,
      "learning_rate": 8.490109002826e-06,
      "loss": 0.0156,
      "step": 28510
    },
    {
      "epoch": 11.513928138877674,
      "grad_norm": 0.0009779290994629264,
      "learning_rate": 8.486071861122326e-06,
      "loss": 0.0033,
      "step": 28520
    },
    {
      "epoch": 11.517965280581349,
      "grad_norm": 0.0003189833660144359,
      "learning_rate": 8.482034719418653e-06,
      "loss": 0.0116,
      "step": 28530
    },
    {
      "epoch": 11.522002422285022,
      "grad_norm": 0.0006842685397714376,
      "learning_rate": 8.477997577714979e-06,
      "loss": 0.0146,
      "step": 28540
    },
    {
      "epoch": 11.526039563988697,
      "grad_norm": 0.0010624019196256995,
      "learning_rate": 8.473960436011305e-06,
      "loss": 0.0149,
      "step": 28550
    },
    {
      "epoch": 11.53007670569237,
      "grad_norm": 0.0025129388086497784,
      "learning_rate": 8.46992329430763e-06,
      "loss": 0.033,
      "step": 28560
    },
    {
      "epoch": 11.534113847396043,
      "grad_norm": 0.07601068913936615,
      "learning_rate": 8.465886152603958e-06,
      "loss": 0.0017,
      "step": 28570
    },
    {
      "epoch": 11.538150989099718,
      "grad_norm": 0.0009774811333045363,
      "learning_rate": 8.461849010900284e-06,
      "loss": 0.0079,
      "step": 28580
    },
    {
      "epoch": 11.54218813080339,
      "grad_norm": 1.2185204029083252,
      "learning_rate": 8.457811869196609e-06,
      "loss": 0.0148,
      "step": 28590
    },
    {
      "epoch": 11.546225272507066,
      "grad_norm": 0.0025466259103268385,
      "learning_rate": 8.453774727492937e-06,
      "loss": 0.0021,
      "step": 28600
    },
    {
      "epoch": 11.550262414210739,
      "grad_norm": 0.0012426575412973762,
      "learning_rate": 8.449737585789261e-06,
      "loss": 0.0119,
      "step": 28610
    },
    {
      "epoch": 11.554299555914412,
      "grad_norm": 0.0031858477741479874,
      "learning_rate": 8.445700444085589e-06,
      "loss": 0.0056,
      "step": 28620
    },
    {
      "epoch": 11.558336697618087,
      "grad_norm": 0.0006575157167389989,
      "learning_rate": 8.441663302381914e-06,
      "loss": 0.015,
      "step": 28630
    },
    {
      "epoch": 11.56237383932176,
      "grad_norm": 2.0656542778015137,
      "learning_rate": 8.43762616067824e-06,
      "loss": 0.0107,
      "step": 28640
    },
    {
      "epoch": 11.566410981025435,
      "grad_norm": 0.0023108399473130703,
      "learning_rate": 8.433589018974566e-06,
      "loss": 0.032,
      "step": 28650
    },
    {
      "epoch": 11.570448122729108,
      "grad_norm": 1.8829114437103271,
      "learning_rate": 8.429551877270893e-06,
      "loss": 0.0105,
      "step": 28660
    },
    {
      "epoch": 11.57448526443278,
      "grad_norm": 0.01858994923532009,
      "learning_rate": 8.425514735567219e-06,
      "loss": 0.0081,
      "step": 28670
    },
    {
      "epoch": 11.578522406136456,
      "grad_norm": 0.005046134814620018,
      "learning_rate": 8.421477593863545e-06,
      "loss": 0.0175,
      "step": 28680
    },
    {
      "epoch": 11.582559547840129,
      "grad_norm": 4.541342258453369,
      "learning_rate": 8.417440452159871e-06,
      "loss": 0.0253,
      "step": 28690
    },
    {
      "epoch": 11.586596689543804,
      "grad_norm": 0.003444866742938757,
      "learning_rate": 8.413403310456198e-06,
      "loss": 0.0029,
      "step": 28700
    },
    {
      "epoch": 11.590633831247477,
      "grad_norm": 0.0016788870561867952,
      "learning_rate": 8.409366168752524e-06,
      "loss": 0.005,
      "step": 28710
    },
    {
      "epoch": 11.59467097295115,
      "grad_norm": 0.0007836532313376665,
      "learning_rate": 8.40532902704885e-06,
      "loss": 0.0037,
      "step": 28720
    },
    {
      "epoch": 11.598708114654825,
      "grad_norm": 0.0034112988505512476,
      "learning_rate": 8.401291885345177e-06,
      "loss": 0.0147,
      "step": 28730
    },
    {
      "epoch": 11.602745256358498,
      "grad_norm": 0.008987902663648129,
      "learning_rate": 8.397254743641501e-06,
      "loss": 0.0187,
      "step": 28740
    },
    {
      "epoch": 11.606782398062172,
      "grad_norm": 0.007482127286493778,
      "learning_rate": 8.393217601937829e-06,
      "loss": 0.0088,
      "step": 28750
    },
    {
      "epoch": 11.610819539765846,
      "grad_norm": 1.1337987184524536,
      "learning_rate": 8.389180460234155e-06,
      "loss": 0.0156,
      "step": 28760
    },
    {
      "epoch": 11.614856681469519,
      "grad_norm": 0.028288228437304497,
      "learning_rate": 8.385143318530482e-06,
      "loss": 0.0528,
      "step": 28770
    },
    {
      "epoch": 11.618893823173194,
      "grad_norm": 0.015418842434883118,
      "learning_rate": 8.381106176826808e-06,
      "loss": 0.012,
      "step": 28780
    },
    {
      "epoch": 11.622930964876867,
      "grad_norm": 0.09144806861877441,
      "learning_rate": 8.377069035123133e-06,
      "loss": 0.0056,
      "step": 28790
    },
    {
      "epoch": 11.626968106580541,
      "grad_norm": 2.1672792434692383,
      "learning_rate": 8.37303189341946e-06,
      "loss": 0.0068,
      "step": 28800
    },
    {
      "epoch": 11.631005248284215,
      "grad_norm": 1.1430251598358154,
      "learning_rate": 8.368994751715785e-06,
      "loss": 0.0159,
      "step": 28810
    },
    {
      "epoch": 11.635042389987888,
      "grad_norm": 0.040418848395347595,
      "learning_rate": 8.364957610012111e-06,
      "loss": 0.0044,
      "step": 28820
    },
    {
      "epoch": 11.639079531691563,
      "grad_norm": 0.0004972557071596384,
      "learning_rate": 8.36092046830844e-06,
      "loss": 0.0241,
      "step": 28830
    },
    {
      "epoch": 11.643116673395236,
      "grad_norm": 0.0010378977749496698,
      "learning_rate": 8.356883326604764e-06,
      "loss": 0.0155,
      "step": 28840
    },
    {
      "epoch": 11.64715381509891,
      "grad_norm": 0.0018363922135904431,
      "learning_rate": 8.35284618490109e-06,
      "loss": 0.0001,
      "step": 28850
    },
    {
      "epoch": 11.651190956802584,
      "grad_norm": 0.02637183479964733,
      "learning_rate": 8.348809043197417e-06,
      "loss": 0.0011,
      "step": 28860
    },
    {
      "epoch": 11.655228098506257,
      "grad_norm": 0.019937368109822273,
      "learning_rate": 8.344771901493743e-06,
      "loss": 0.0023,
      "step": 28870
    },
    {
      "epoch": 11.659265240209931,
      "grad_norm": 0.08163303881883621,
      "learning_rate": 8.34073475979007e-06,
      "loss": 0.0052,
      "step": 28880
    },
    {
      "epoch": 11.663302381913605,
      "grad_norm": 0.001161190215498209,
      "learning_rate": 8.336697618086395e-06,
      "loss": 0.0077,
      "step": 28890
    },
    {
      "epoch": 11.66733952361728,
      "grad_norm": 0.0009084783960133791,
      "learning_rate": 8.332660476382722e-06,
      "loss": 0.0299,
      "step": 28900
    },
    {
      "epoch": 11.671376665320953,
      "grad_norm": 0.0012739363592118025,
      "learning_rate": 8.328623334679048e-06,
      "loss": 0.0424,
      "step": 28910
    },
    {
      "epoch": 11.675413807024627,
      "grad_norm": 0.006878936197608709,
      "learning_rate": 8.324586192975374e-06,
      "loss": 0.0027,
      "step": 28920
    },
    {
      "epoch": 11.6794509487283,
      "grad_norm": 0.0032334907446056604,
      "learning_rate": 8.3205490512717e-06,
      "loss": 0.0042,
      "step": 28930
    },
    {
      "epoch": 11.683488090431974,
      "grad_norm": 3.0365710258483887,
      "learning_rate": 8.316511909568027e-06,
      "loss": 0.0702,
      "step": 28940
    },
    {
      "epoch": 11.687525232135648,
      "grad_norm": 1.7864981889724731,
      "learning_rate": 8.312474767864353e-06,
      "loss": 0.0185,
      "step": 28950
    },
    {
      "epoch": 11.691562373839322,
      "grad_norm": 0.0044968463480472565,
      "learning_rate": 8.30843762616068e-06,
      "loss": 0.0183,
      "step": 28960
    },
    {
      "epoch": 11.695599515542996,
      "grad_norm": 0.0005884099518880248,
      "learning_rate": 8.304400484457004e-06,
      "loss": 0.0304,
      "step": 28970
    },
    {
      "epoch": 11.69963665724667,
      "grad_norm": 0.0010718650883063674,
      "learning_rate": 8.300363342753332e-06,
      "loss": 0.0098,
      "step": 28980
    },
    {
      "epoch": 11.703673798950343,
      "grad_norm": 0.0008979634731076658,
      "learning_rate": 8.296326201049657e-06,
      "loss": 0.0051,
      "step": 28990
    },
    {
      "epoch": 11.707710940654017,
      "grad_norm": 0.0190434530377388,
      "learning_rate": 8.292289059345983e-06,
      "loss": 0.0161,
      "step": 29000
    },
    {
      "epoch": 11.71174808235769,
      "grad_norm": 9.761935234069824,
      "learning_rate": 8.288251917642311e-06,
      "loss": 0.0448,
      "step": 29010
    },
    {
      "epoch": 11.715785224061365,
      "grad_norm": 0.0015823479043319821,
      "learning_rate": 8.284214775938635e-06,
      "loss": 0.0143,
      "step": 29020
    },
    {
      "epoch": 11.719822365765038,
      "grad_norm": 0.06264577805995941,
      "learning_rate": 8.280177634234963e-06,
      "loss": 0.0466,
      "step": 29030
    },
    {
      "epoch": 11.723859507468712,
      "grad_norm": 0.1234547421336174,
      "learning_rate": 8.276140492531288e-06,
      "loss": 0.0067,
      "step": 29040
    },
    {
      "epoch": 11.727896649172386,
      "grad_norm": 0.009929955005645752,
      "learning_rate": 8.272103350827614e-06,
      "loss": 0.0063,
      "step": 29050
    },
    {
      "epoch": 11.73193379087606,
      "grad_norm": 0.0004943569074384868,
      "learning_rate": 8.26806620912394e-06,
      "loss": 0.0258,
      "step": 29060
    },
    {
      "epoch": 11.735970932579734,
      "grad_norm": 0.5016826391220093,
      "learning_rate": 8.264029067420267e-06,
      "loss": 0.001,
      "step": 29070
    },
    {
      "epoch": 11.740008074283407,
      "grad_norm": 0.0005628560902550817,
      "learning_rate": 8.259991925716593e-06,
      "loss": 0.0104,
      "step": 29080
    },
    {
      "epoch": 11.74404521598708,
      "grad_norm": 0.0019307391485199332,
      "learning_rate": 8.25595478401292e-06,
      "loss": 0.0244,
      "step": 29090
    },
    {
      "epoch": 11.748082357690755,
      "grad_norm": 0.0015642581274732947,
      "learning_rate": 8.251917642309246e-06,
      "loss": 0.0061,
      "step": 29100
    },
    {
      "epoch": 11.752119499394428,
      "grad_norm": 3.05767822265625,
      "learning_rate": 8.247880500605572e-06,
      "loss": 0.0187,
      "step": 29110
    },
    {
      "epoch": 11.756156641098103,
      "grad_norm": 0.0031636799685657024,
      "learning_rate": 8.243843358901898e-06,
      "loss": 0.0102,
      "step": 29120
    },
    {
      "epoch": 11.760193782801776,
      "grad_norm": 1.6598341464996338,
      "learning_rate": 8.239806217198225e-06,
      "loss": 0.0121,
      "step": 29130
    },
    {
      "epoch": 11.76423092450545,
      "grad_norm": 0.0017107217572629452,
      "learning_rate": 8.235769075494551e-06,
      "loss": 0.0051,
      "step": 29140
    },
    {
      "epoch": 11.768268066209124,
      "grad_norm": 0.0013232891215011477,
      "learning_rate": 8.231731933790876e-06,
      "loss": 0.0142,
      "step": 29150
    },
    {
      "epoch": 11.772305207912797,
      "grad_norm": 0.6868324279785156,
      "learning_rate": 8.227694792087203e-06,
      "loss": 0.0106,
      "step": 29160
    },
    {
      "epoch": 11.776342349616472,
      "grad_norm": 0.00036064768210053444,
      "learning_rate": 8.223657650383528e-06,
      "loss": 0.0042,
      "step": 29170
    },
    {
      "epoch": 11.780379491320145,
      "grad_norm": 0.0002853832265827805,
      "learning_rate": 8.219620508679856e-06,
      "loss": 0.008,
      "step": 29180
    },
    {
      "epoch": 11.784416633023818,
      "grad_norm": 0.0005923918215557933,
      "learning_rate": 8.215583366976182e-06,
      "loss": 0.0121,
      "step": 29190
    },
    {
      "epoch": 11.788453774727493,
      "grad_norm": 0.0037419290747493505,
      "learning_rate": 8.211546225272507e-06,
      "loss": 0.0096,
      "step": 29200
    },
    {
      "epoch": 11.792490916431166,
      "grad_norm": 0.004364141263067722,
      "learning_rate": 8.207509083568835e-06,
      "loss": 0.0001,
      "step": 29210
    },
    {
      "epoch": 11.796528058134841,
      "grad_norm": 0.31117767095565796,
      "learning_rate": 8.20347194186516e-06,
      "loss": 0.0117,
      "step": 29220
    },
    {
      "epoch": 11.800565199838514,
      "grad_norm": 2.9095606803894043,
      "learning_rate": 8.199434800161486e-06,
      "loss": 0.033,
      "step": 29230
    },
    {
      "epoch": 11.804602341542187,
      "grad_norm": 1.4751598834991455,
      "learning_rate": 8.195397658457812e-06,
      "loss": 0.016,
      "step": 29240
    },
    {
      "epoch": 11.808639483245862,
      "grad_norm": 0.00046025455230847,
      "learning_rate": 8.191360516754138e-06,
      "loss": 0.0406,
      "step": 29250
    },
    {
      "epoch": 11.812676624949535,
      "grad_norm": 1.637237310409546,
      "learning_rate": 8.187323375050465e-06,
      "loss": 0.0252,
      "step": 29260
    },
    {
      "epoch": 11.81671376665321,
      "grad_norm": 0.6643186211585999,
      "learning_rate": 8.183286233346791e-06,
      "loss": 0.0038,
      "step": 29270
    },
    {
      "epoch": 11.820750908356883,
      "grad_norm": 6.604429244995117,
      "learning_rate": 8.179249091643117e-06,
      "loss": 0.0033,
      "step": 29280
    },
    {
      "epoch": 11.824788050060556,
      "grad_norm": 0.0008354866877198219,
      "learning_rate": 8.175211949939444e-06,
      "loss": 0.0116,
      "step": 29290
    },
    {
      "epoch": 11.828825191764231,
      "grad_norm": 0.0036582585889846087,
      "learning_rate": 8.17117480823577e-06,
      "loss": 0.0126,
      "step": 29300
    },
    {
      "epoch": 11.832862333467904,
      "grad_norm": 1.5451065301895142,
      "learning_rate": 8.167137666532096e-06,
      "loss": 0.0053,
      "step": 29310
    },
    {
      "epoch": 11.83689947517158,
      "grad_norm": 0.0012510159285739064,
      "learning_rate": 8.163100524828422e-06,
      "loss": 0.001,
      "step": 29320
    },
    {
      "epoch": 11.840936616875252,
      "grad_norm": 1.1636834144592285,
      "learning_rate": 8.159063383124749e-06,
      "loss": 0.0085,
      "step": 29330
    },
    {
      "epoch": 11.844973758578925,
      "grad_norm": 0.0008395725162699819,
      "learning_rate": 8.155026241421075e-06,
      "loss": 0.0112,
      "step": 29340
    },
    {
      "epoch": 11.8490109002826,
      "grad_norm": 0.0012820563279092312,
      "learning_rate": 8.150989099717401e-06,
      "loss": 0.0352,
      "step": 29350
    },
    {
      "epoch": 11.853048041986273,
      "grad_norm": 0.002171056577935815,
      "learning_rate": 8.146951958013728e-06,
      "loss": 0.0095,
      "step": 29360
    },
    {
      "epoch": 11.857085183689948,
      "grad_norm": 0.0004549206350930035,
      "learning_rate": 8.142914816310054e-06,
      "loss": 0.0228,
      "step": 29370
    },
    {
      "epoch": 11.861122325393621,
      "grad_norm": 0.00025698766694404185,
      "learning_rate": 8.138877674606378e-06,
      "loss": 0.0145,
      "step": 29380
    },
    {
      "epoch": 11.865159467097294,
      "grad_norm": 0.021591059863567352,
      "learning_rate": 8.134840532902706e-06,
      "loss": 0.0114,
      "step": 29390
    },
    {
      "epoch": 11.86919660880097,
      "grad_norm": 0.5928791165351868,
      "learning_rate": 8.130803391199031e-06,
      "loss": 0.016,
      "step": 29400
    },
    {
      "epoch": 11.873233750504642,
      "grad_norm": 2.571899890899658,
      "learning_rate": 8.126766249495357e-06,
      "loss": 0.0386,
      "step": 29410
    },
    {
      "epoch": 11.877270892208317,
      "grad_norm": 0.0065756794065237045,
      "learning_rate": 8.122729107791684e-06,
      "loss": 0.0049,
      "step": 29420
    },
    {
      "epoch": 11.88130803391199,
      "grad_norm": 1.0881179571151733,
      "learning_rate": 8.11869196608801e-06,
      "loss": 0.0465,
      "step": 29430
    },
    {
      "epoch": 11.885345175615663,
      "grad_norm": 3.6268885135650635,
      "learning_rate": 8.114654824384338e-06,
      "loss": 0.0306,
      "step": 29440
    },
    {
      "epoch": 11.889382317319338,
      "grad_norm": 1.3658722639083862,
      "learning_rate": 8.110617682680662e-06,
      "loss": 0.016,
      "step": 29450
    },
    {
      "epoch": 11.893419459023011,
      "grad_norm": 1.7727642059326172,
      "learning_rate": 8.106580540976989e-06,
      "loss": 0.0508,
      "step": 29460
    },
    {
      "epoch": 11.897456600726686,
      "grad_norm": 0.004774929024279118,
      "learning_rate": 8.102543399273315e-06,
      "loss": 0.0017,
      "step": 29470
    },
    {
      "epoch": 11.90149374243036,
      "grad_norm": 5.312587738037109,
      "learning_rate": 8.098506257569641e-06,
      "loss": 0.05,
      "step": 29480
    },
    {
      "epoch": 11.905530884134032,
      "grad_norm": 0.005742112174630165,
      "learning_rate": 8.094469115865968e-06,
      "loss": 0.0001,
      "step": 29490
    },
    {
      "epoch": 11.909568025837707,
      "grad_norm": 0.0038774695713073015,
      "learning_rate": 8.090431974162294e-06,
      "loss": 0.041,
      "step": 29500
    },
    {
      "epoch": 11.91360516754138,
      "grad_norm": 0.019243476912379265,
      "learning_rate": 8.08639483245862e-06,
      "loss": 0.011,
      "step": 29510
    },
    {
      "epoch": 11.917642309245055,
      "grad_norm": 1.8858026266098022,
      "learning_rate": 8.082357690754946e-06,
      "loss": 0.0132,
      "step": 29520
    },
    {
      "epoch": 11.921679450948728,
      "grad_norm": 0.8092091679573059,
      "learning_rate": 8.078320549051273e-06,
      "loss": 0.0132,
      "step": 29530
    },
    {
      "epoch": 11.925716592652401,
      "grad_norm": 0.02007262222468853,
      "learning_rate": 8.074283407347599e-06,
      "loss": 0.0084,
      "step": 29540
    },
    {
      "epoch": 11.929753734356076,
      "grad_norm": 0.00759883364662528,
      "learning_rate": 8.070246265643925e-06,
      "loss": 0.0052,
      "step": 29550
    },
    {
      "epoch": 11.93379087605975,
      "grad_norm": 0.0012153886491432786,
      "learning_rate": 8.06620912394025e-06,
      "loss": 0.0094,
      "step": 29560
    },
    {
      "epoch": 11.937828017763424,
      "grad_norm": 3.801297426223755,
      "learning_rate": 8.062171982236578e-06,
      "loss": 0.0182,
      "step": 29570
    },
    {
      "epoch": 11.941865159467097,
      "grad_norm": 0.005525324493646622,
      "learning_rate": 8.058134840532902e-06,
      "loss": 0.021,
      "step": 29580
    },
    {
      "epoch": 11.94590230117077,
      "grad_norm": 1.5802990198135376,
      "learning_rate": 8.05409769882923e-06,
      "loss": 0.0087,
      "step": 29590
    },
    {
      "epoch": 11.949939442874445,
      "grad_norm": 0.001896071364171803,
      "learning_rate": 8.050060557125555e-06,
      "loss": 0.0114,
      "step": 29600
    },
    {
      "epoch": 11.953976584578118,
      "grad_norm": 0.0010993225732818246,
      "learning_rate": 8.046023415421881e-06,
      "loss": 0.014,
      "step": 29610
    },
    {
      "epoch": 11.958013726281793,
      "grad_norm": 0.013057367876172066,
      "learning_rate": 8.04198627371821e-06,
      "loss": 0.0064,
      "step": 29620
    },
    {
      "epoch": 11.962050867985466,
      "grad_norm": 1.0339192152023315,
      "learning_rate": 8.037949132014534e-06,
      "loss": 0.0114,
      "step": 29630
    },
    {
      "epoch": 11.96608800968914,
      "grad_norm": 0.0007838025339879096,
      "learning_rate": 8.03391199031086e-06,
      "loss": 0.0329,
      "step": 29640
    },
    {
      "epoch": 11.970125151392814,
      "grad_norm": 0.8161188960075378,
      "learning_rate": 8.029874848607186e-06,
      "loss": 0.0035,
      "step": 29650
    },
    {
      "epoch": 11.974162293096487,
      "grad_norm": 1.630382776260376,
      "learning_rate": 8.025837706903513e-06,
      "loss": 0.0065,
      "step": 29660
    },
    {
      "epoch": 11.978199434800162,
      "grad_norm": 0.5191516876220703,
      "learning_rate": 8.021800565199839e-06,
      "loss": 0.0224,
      "step": 29670
    },
    {
      "epoch": 11.982236576503835,
      "grad_norm": 0.8892392516136169,
      "learning_rate": 8.017763423496165e-06,
      "loss": 0.034,
      "step": 29680
    },
    {
      "epoch": 11.986273718207508,
      "grad_norm": 0.021072715520858765,
      "learning_rate": 8.013726281792492e-06,
      "loss": 0.0212,
      "step": 29690
    },
    {
      "epoch": 11.990310859911183,
      "grad_norm": 1.2423198223114014,
      "learning_rate": 8.009689140088818e-06,
      "loss": 0.0088,
      "step": 29700
    },
    {
      "epoch": 11.994348001614856,
      "grad_norm": 4.21844482421875,
      "learning_rate": 8.005651998385144e-06,
      "loss": 0.0097,
      "step": 29710
    },
    {
      "epoch": 11.998385143318531,
      "grad_norm": 0.004253810737282038,
      "learning_rate": 8.00161485668147e-06,
      "loss": 0.0064,
      "step": 29720
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.9852987421383648,
      "eval_f1": 0.9467691431824651,
      "eval_loss": 0.060362558811903,
      "eval_precision": 0.9379582628313593,
      "eval_recall": 0.9557471264367816,
      "eval_runtime": 443.066,
      "eval_samples_per_second": 28.754,
      "eval_steps_per_second": 1.198,
      "step": 29724
    },
    {
      "epoch": 12.002422285022204,
      "grad_norm": 0.0006340059917420149,
      "learning_rate": 7.997577714977797e-06,
      "loss": 0.0178,
      "step": 29730
    },
    {
      "epoch": 12.006459426725877,
      "grad_norm": 0.0022156271152198315,
      "learning_rate": 7.993540573274123e-06,
      "loss": 0.012,
      "step": 29740
    },
    {
      "epoch": 12.010496568429552,
      "grad_norm": 0.5666344165802002,
      "learning_rate": 7.98950343157045e-06,
      "loss": 0.0061,
      "step": 29750
    },
    {
      "epoch": 12.014533710133225,
      "grad_norm": 0.5891322493553162,
      "learning_rate": 7.985466289866774e-06,
      "loss": 0.0288,
      "step": 29760
    },
    {
      "epoch": 12.0185708518369,
      "grad_norm": 0.7316294312477112,
      "learning_rate": 7.981429148163102e-06,
      "loss": 0.0092,
      "step": 29770
    },
    {
      "epoch": 12.022607993540573,
      "grad_norm": 0.001847894862294197,
      "learning_rate": 7.977392006459428e-06,
      "loss": 0.0022,
      "step": 29780
    },
    {
      "epoch": 12.026645135244246,
      "grad_norm": 0.01988079957664013,
      "learning_rate": 7.973354864755753e-06,
      "loss": 0.006,
      "step": 29790
    },
    {
      "epoch": 12.030682276947921,
      "grad_norm": 0.4863618314266205,
      "learning_rate": 7.96931772305208e-06,
      "loss": 0.0286,
      "step": 29800
    },
    {
      "epoch": 12.034719418651594,
      "grad_norm": 0.0005222012405283749,
      "learning_rate": 7.965280581348405e-06,
      "loss": 0.0124,
      "step": 29810
    },
    {
      "epoch": 12.038756560355269,
      "grad_norm": 0.5513717532157898,
      "learning_rate": 7.961243439644732e-06,
      "loss": 0.0151,
      "step": 29820
    },
    {
      "epoch": 12.042793702058942,
      "grad_norm": 0.002827663905918598,
      "learning_rate": 7.957206297941058e-06,
      "loss": 0.0127,
      "step": 29830
    },
    {
      "epoch": 12.046830843762615,
      "grad_norm": 0.6141130924224854,
      "learning_rate": 7.953169156237384e-06,
      "loss": 0.0303,
      "step": 29840
    },
    {
      "epoch": 12.05086798546629,
      "grad_norm": 0.00021558288426604122,
      "learning_rate": 7.94913201453371e-06,
      "loss": 0.0077,
      "step": 29850
    },
    {
      "epoch": 12.054905127169963,
      "grad_norm": 0.0013989030849188566,
      "learning_rate": 7.945094872830037e-06,
      "loss": 0.0259,
      "step": 29860
    },
    {
      "epoch": 12.058942268873638,
      "grad_norm": 1.8504412174224854,
      "learning_rate": 7.941057731126363e-06,
      "loss": 0.0216,
      "step": 29870
    },
    {
      "epoch": 12.062979410577311,
      "grad_norm": 0.0011004708940163255,
      "learning_rate": 7.93702058942269e-06,
      "loss": 0.0225,
      "step": 29880
    },
    {
      "epoch": 12.067016552280984,
      "grad_norm": 0.0017049397574737668,
      "learning_rate": 7.932983447719016e-06,
      "loss": 0.0091,
      "step": 29890
    },
    {
      "epoch": 12.071053693984659,
      "grad_norm": 0.00021293916506692767,
      "learning_rate": 7.928946306015342e-06,
      "loss": 0.0048,
      "step": 29900
    },
    {
      "epoch": 12.075090835688332,
      "grad_norm": 0.0002039749379036948,
      "learning_rate": 7.924909164311668e-06,
      "loss": 0.0004,
      "step": 29910
    },
    {
      "epoch": 12.079127977392007,
      "grad_norm": 1.5591843128204346,
      "learning_rate": 7.920872022607995e-06,
      "loss": 0.0131,
      "step": 29920
    },
    {
      "epoch": 12.08316511909568,
      "grad_norm": 0.00022435183927882463,
      "learning_rate": 7.91683488090432e-06,
      "loss": 0.0054,
      "step": 29930
    },
    {
      "epoch": 12.087202260799353,
      "grad_norm": 1.316580891609192,
      "learning_rate": 7.912797739200645e-06,
      "loss": 0.0246,
      "step": 29940
    },
    {
      "epoch": 12.091239402503028,
      "grad_norm": 0.0008029898162931204,
      "learning_rate": 7.908760597496973e-06,
      "loss": 0.0077,
      "step": 29950
    },
    {
      "epoch": 12.095276544206701,
      "grad_norm": 0.0007970179431140423,
      "learning_rate": 7.9047234557933e-06,
      "loss": 0.0078,
      "step": 29960
    },
    {
      "epoch": 12.099313685910376,
      "grad_norm": 0.0005173643003217876,
      "learning_rate": 7.900686314089624e-06,
      "loss": 0.0006,
      "step": 29970
    },
    {
      "epoch": 12.10335082761405,
      "grad_norm": 0.0019648317247629166,
      "learning_rate": 7.896649172385952e-06,
      "loss": 0.0025,
      "step": 29980
    },
    {
      "epoch": 12.107387969317722,
      "grad_norm": 0.0004550589947029948,
      "learning_rate": 7.892612030682277e-06,
      "loss": 0.0172,
      "step": 29990
    },
    {
      "epoch": 12.111425111021397,
      "grad_norm": 0.0013585148844867945,
      "learning_rate": 7.888574888978605e-06,
      "loss": 0.0135,
      "step": 30000
    },
    {
      "epoch": 12.11546225272507,
      "grad_norm": 0.10165059566497803,
      "learning_rate": 7.88453774727493e-06,
      "loss": 0.0186,
      "step": 30010
    },
    {
      "epoch": 12.119499394428745,
      "grad_norm": 0.00014565214223694056,
      "learning_rate": 7.880500605571256e-06,
      "loss": 0.0138,
      "step": 30020
    },
    {
      "epoch": 12.123536536132418,
      "grad_norm": 0.0010390242096036673,
      "learning_rate": 7.876463463867582e-06,
      "loss": 0.0,
      "step": 30030
    },
    {
      "epoch": 12.127573677836091,
      "grad_norm": 0.02701103687286377,
      "learning_rate": 7.872426322163908e-06,
      "loss": 0.0241,
      "step": 30040
    },
    {
      "epoch": 12.131610819539766,
      "grad_norm": 0.0004847108793910593,
      "learning_rate": 7.868389180460235e-06,
      "loss": 0.014,
      "step": 30050
    },
    {
      "epoch": 12.13564796124344,
      "grad_norm": 0.005377435125410557,
      "learning_rate": 7.86435203875656e-06,
      "loss": 0.0096,
      "step": 30060
    },
    {
      "epoch": 12.139685102947114,
      "grad_norm": 0.0025936549063771963,
      "learning_rate": 7.860314897052887e-06,
      "loss": 0.0117,
      "step": 30070
    },
    {
      "epoch": 12.143722244650787,
      "grad_norm": 0.0041909231804311275,
      "learning_rate": 7.856277755349213e-06,
      "loss": 0.0111,
      "step": 30080
    },
    {
      "epoch": 12.14775938635446,
      "grad_norm": 0.0008785960380919278,
      "learning_rate": 7.85224061364554e-06,
      "loss": 0.0014,
      "step": 30090
    },
    {
      "epoch": 12.151796528058135,
      "grad_norm": 0.002191768027842045,
      "learning_rate": 7.848203471941866e-06,
      "loss": 0.0096,
      "step": 30100
    },
    {
      "epoch": 12.155833669761808,
      "grad_norm": 1.254240870475769,
      "learning_rate": 7.844166330238192e-06,
      "loss": 0.0132,
      "step": 30110
    },
    {
      "epoch": 12.159870811465483,
      "grad_norm": 0.0008200749871321023,
      "learning_rate": 7.840129188534517e-06,
      "loss": 0.0115,
      "step": 30120
    },
    {
      "epoch": 12.163907953169156,
      "grad_norm": 2.5031208992004395,
      "learning_rate": 7.836092046830845e-06,
      "loss": 0.0421,
      "step": 30130
    },
    {
      "epoch": 12.167945094872831,
      "grad_norm": 0.0005549001507461071,
      "learning_rate": 7.832054905127171e-06,
      "loss": 0.0071,
      "step": 30140
    },
    {
      "epoch": 12.171982236576504,
      "grad_norm": 1.0642976760864258,
      "learning_rate": 7.828017763423497e-06,
      "loss": 0.0054,
      "step": 30150
    },
    {
      "epoch": 12.176019378280177,
      "grad_norm": 0.0014101631240919232,
      "learning_rate": 7.823980621719824e-06,
      "loss": 0.0107,
      "step": 30160
    },
    {
      "epoch": 12.180056519983852,
      "grad_norm": 0.00038248536293394864,
      "learning_rate": 7.819943480016148e-06,
      "loss": 0.0077,
      "step": 30170
    },
    {
      "epoch": 12.184093661687525,
      "grad_norm": 0.0005830196314491332,
      "learning_rate": 7.815906338312476e-06,
      "loss": 0.0119,
      "step": 30180
    },
    {
      "epoch": 12.1881308033912,
      "grad_norm": 0.0015069032087922096,
      "learning_rate": 7.811869196608801e-06,
      "loss": 0.0099,
      "step": 30190
    },
    {
      "epoch": 12.192167945094873,
      "grad_norm": 0.47477471828460693,
      "learning_rate": 7.807832054905127e-06,
      "loss": 0.0161,
      "step": 30200
    },
    {
      "epoch": 12.196205086798546,
      "grad_norm": 0.0009501813328824937,
      "learning_rate": 7.803794913201455e-06,
      "loss": 0.008,
      "step": 30210
    },
    {
      "epoch": 12.200242228502221,
      "grad_norm": 0.000887060072273016,
      "learning_rate": 7.79975777149778e-06,
      "loss": 0.0161,
      "step": 30220
    },
    {
      "epoch": 12.204279370205894,
      "grad_norm": 0.9755727052688599,
      "learning_rate": 7.795720629794106e-06,
      "loss": 0.012,
      "step": 30230
    },
    {
      "epoch": 12.208316511909569,
      "grad_norm": 1.356885552406311,
      "learning_rate": 7.791683488090432e-06,
      "loss": 0.0126,
      "step": 30240
    },
    {
      "epoch": 12.212353653613242,
      "grad_norm": 2.4823176860809326,
      "learning_rate": 7.787646346386759e-06,
      "loss": 0.0166,
      "step": 30250
    },
    {
      "epoch": 12.216390795316915,
      "grad_norm": 0.0009390686172991991,
      "learning_rate": 7.783609204683085e-06,
      "loss": 0.0025,
      "step": 30260
    },
    {
      "epoch": 12.22042793702059,
      "grad_norm": 0.002149813575670123,
      "learning_rate": 7.779572062979411e-06,
      "loss": 0.0128,
      "step": 30270
    },
    {
      "epoch": 12.224465078724263,
      "grad_norm": 0.0005481530097313225,
      "learning_rate": 7.775534921275737e-06,
      "loss": 0.0227,
      "step": 30280
    },
    {
      "epoch": 12.228502220427938,
      "grad_norm": 1.7136449813842773,
      "learning_rate": 7.771497779572064e-06,
      "loss": 0.0362,
      "step": 30290
    },
    {
      "epoch": 12.232539362131611,
      "grad_norm": 0.00027457159012556076,
      "learning_rate": 7.76746063786839e-06,
      "loss": 0.0,
      "step": 30300
    },
    {
      "epoch": 12.236576503835284,
      "grad_norm": 0.0007537730853073299,
      "learning_rate": 7.763423496164716e-06,
      "loss": 0.007,
      "step": 30310
    },
    {
      "epoch": 12.240613645538959,
      "grad_norm": 1.334115982055664,
      "learning_rate": 7.759386354461043e-06,
      "loss": 0.0203,
      "step": 30320
    },
    {
      "epoch": 12.244650787242632,
      "grad_norm": 0.00011287731467746198,
      "learning_rate": 7.755349212757369e-06,
      "loss": 0.0075,
      "step": 30330
    },
    {
      "epoch": 12.248687928946307,
      "grad_norm": 0.0007660993724130094,
      "learning_rate": 7.751312071053695e-06,
      "loss": 0.0051,
      "step": 30340
    },
    {
      "epoch": 12.25272507064998,
      "grad_norm": 0.0004404180508572608,
      "learning_rate": 7.74727492935002e-06,
      "loss": 0.0154,
      "step": 30350
    },
    {
      "epoch": 12.256762212353653,
      "grad_norm": 0.00018326572899241,
      "learning_rate": 7.743237787646348e-06,
      "loss": 0.0012,
      "step": 30360
    },
    {
      "epoch": 12.260799354057328,
      "grad_norm": 0.0003506382054183632,
      "learning_rate": 7.739200645942672e-06,
      "loss": 0.0122,
      "step": 30370
    },
    {
      "epoch": 12.264836495761001,
      "grad_norm": 0.0003388647746760398,
      "learning_rate": 7.735163504238999e-06,
      "loss": 0.0013,
      "step": 30380
    },
    {
      "epoch": 12.268873637464676,
      "grad_norm": 0.0059785726480185986,
      "learning_rate": 7.731126362535327e-06,
      "loss": 0.016,
      "step": 30390
    },
    {
      "epoch": 12.272910779168349,
      "grad_norm": 0.0005790653522126377,
      "learning_rate": 7.727089220831651e-06,
      "loss": 0.0013,
      "step": 30400
    },
    {
      "epoch": 12.276947920872022,
      "grad_norm": 0.0005268402746878564,
      "learning_rate": 7.72305207912798e-06,
      "loss": 0.0078,
      "step": 30410
    },
    {
      "epoch": 12.280985062575697,
      "grad_norm": 0.00011939730029553175,
      "learning_rate": 7.719014937424304e-06,
      "loss": 0.011,
      "step": 30420
    },
    {
      "epoch": 12.28502220427937,
      "grad_norm": 1.5729819536209106,
      "learning_rate": 7.71497779572063e-06,
      "loss": 0.0281,
      "step": 30430
    },
    {
      "epoch": 12.289059345983045,
      "grad_norm": 1.7414811849594116,
      "learning_rate": 7.710940654016956e-06,
      "loss": 0.0252,
      "step": 30440
    },
    {
      "epoch": 12.293096487686718,
      "grad_norm": 1.0635887384414673,
      "learning_rate": 7.706903512313283e-06,
      "loss": 0.0146,
      "step": 30450
    },
    {
      "epoch": 12.297133629390391,
      "grad_norm": 0.00045705007505603135,
      "learning_rate": 7.702866370609609e-06,
      "loss": 0.0052,
      "step": 30460
    },
    {
      "epoch": 12.301170771094066,
      "grad_norm": 0.000574188306927681,
      "learning_rate": 7.698829228905935e-06,
      "loss": 0.0143,
      "step": 30470
    },
    {
      "epoch": 12.305207912797739,
      "grad_norm": 0.9043504595756531,
      "learning_rate": 7.694792087202262e-06,
      "loss": 0.0045,
      "step": 30480
    },
    {
      "epoch": 12.309245054501414,
      "grad_norm": 0.6396326422691345,
      "learning_rate": 7.690754945498588e-06,
      "loss": 0.0098,
      "step": 30490
    },
    {
      "epoch": 12.313282196205087,
      "grad_norm": 0.00026385902310721576,
      "learning_rate": 7.686717803794914e-06,
      "loss": 0.0447,
      "step": 30500
    },
    {
      "epoch": 12.31731933790876,
      "grad_norm": 0.00028274321812205017,
      "learning_rate": 7.68268066209124e-06,
      "loss": 0.004,
      "step": 30510
    },
    {
      "epoch": 12.321356479612435,
      "grad_norm": 0.0009613172733224928,
      "learning_rate": 7.678643520387567e-06,
      "loss": 0.0373,
      "step": 30520
    },
    {
      "epoch": 12.325393621316108,
      "grad_norm": 0.0008488351013511419,
      "learning_rate": 7.674606378683891e-06,
      "loss": 0.0028,
      "step": 30530
    },
    {
      "epoch": 12.329430763019783,
      "grad_norm": 0.00031855935230851173,
      "learning_rate": 7.67056923698022e-06,
      "loss": 0.0054,
      "step": 30540
    },
    {
      "epoch": 12.333467904723456,
      "grad_norm": 0.03686339780688286,
      "learning_rate": 7.666532095276544e-06,
      "loss": 0.011,
      "step": 30550
    },
    {
      "epoch": 12.337505046427129,
      "grad_norm": 0.5552636981010437,
      "learning_rate": 7.662494953572872e-06,
      "loss": 0.0013,
      "step": 30560
    },
    {
      "epoch": 12.341542188130804,
      "grad_norm": 0.00042927268077619374,
      "learning_rate": 7.658457811869198e-06,
      "loss": 0.0064,
      "step": 30570
    },
    {
      "epoch": 12.345579329834477,
      "grad_norm": 0.003380412235856056,
      "learning_rate": 7.654420670165523e-06,
      "loss": 0.0074,
      "step": 30580
    },
    {
      "epoch": 12.349616471538152,
      "grad_norm": 1.0639890432357788,
      "learning_rate": 7.65038352846185e-06,
      "loss": 0.0148,
      "step": 30590
    },
    {
      "epoch": 12.353653613241825,
      "grad_norm": 0.0011942065320909023,
      "learning_rate": 7.646346386758175e-06,
      "loss": 0.0091,
      "step": 30600
    },
    {
      "epoch": 12.357690754945498,
      "grad_norm": 0.30588141083717346,
      "learning_rate": 7.642309245054502e-06,
      "loss": 0.005,
      "step": 30610
    },
    {
      "epoch": 12.361727896649173,
      "grad_norm": 1.4895045757293701,
      "learning_rate": 7.638272103350828e-06,
      "loss": 0.0043,
      "step": 30620
    },
    {
      "epoch": 12.365765038352846,
      "grad_norm": 0.8705765008926392,
      "learning_rate": 7.634234961647154e-06,
      "loss": 0.0184,
      "step": 30630
    },
    {
      "epoch": 12.36980218005652,
      "grad_norm": 0.0013721128925681114,
      "learning_rate": 7.63019781994348e-06,
      "loss": 0.0,
      "step": 30640
    },
    {
      "epoch": 12.373839321760194,
      "grad_norm": 0.008003083057701588,
      "learning_rate": 7.626160678239807e-06,
      "loss": 0.0034,
      "step": 30650
    },
    {
      "epoch": 12.377876463463867,
      "grad_norm": 0.00423613702878356,
      "learning_rate": 7.622123536536134e-06,
      "loss": 0.0098,
      "step": 30660
    },
    {
      "epoch": 12.381913605167542,
      "grad_norm": 3.464081048965454,
      "learning_rate": 7.618086394832459e-06,
      "loss": 0.0321,
      "step": 30670
    },
    {
      "epoch": 12.385950746871215,
      "grad_norm": 1.9508442878723145,
      "learning_rate": 7.6140492531287855e-06,
      "loss": 0.0045,
      "step": 30680
    },
    {
      "epoch": 12.38998788857489,
      "grad_norm": 0.00017204947653226554,
      "learning_rate": 7.610012111425111e-06,
      "loss": 0.0073,
      "step": 30690
    },
    {
      "epoch": 12.394025030278563,
      "grad_norm": 0.0035126397851854563,
      "learning_rate": 7.605974969721438e-06,
      "loss": 0.0,
      "step": 30700
    },
    {
      "epoch": 12.398062171982236,
      "grad_norm": 0.0011155063984915614,
      "learning_rate": 7.6019378280177636e-06,
      "loss": 0.0144,
      "step": 30710
    },
    {
      "epoch": 12.40209931368591,
      "grad_norm": 0.0009943899931386113,
      "learning_rate": 7.597900686314091e-06,
      "loss": 0.0046,
      "step": 30720
    },
    {
      "epoch": 12.406136455389584,
      "grad_norm": 0.0005232923431321979,
      "learning_rate": 7.593863544610417e-06,
      "loss": 0.0025,
      "step": 30730
    },
    {
      "epoch": 12.410173597093259,
      "grad_norm": 0.07650303095579147,
      "learning_rate": 7.5898264029067424e-06,
      "loss": 0.0103,
      "step": 30740
    },
    {
      "epoch": 12.414210738796932,
      "grad_norm": 0.0013070162385702133,
      "learning_rate": 7.5857892612030696e-06,
      "loss": 0.0155,
      "step": 30750
    },
    {
      "epoch": 12.418247880500605,
      "grad_norm": 0.005785651970654726,
      "learning_rate": 7.581752119499395e-06,
      "loss": 0.0096,
      "step": 30760
    },
    {
      "epoch": 12.42228502220428,
      "grad_norm": 0.0010426697554066777,
      "learning_rate": 7.577714977795721e-06,
      "loss": 0.0054,
      "step": 30770
    },
    {
      "epoch": 12.426322163907953,
      "grad_norm": 0.4566112160682678,
      "learning_rate": 7.573677836092047e-06,
      "loss": 0.0204,
      "step": 30780
    },
    {
      "epoch": 12.430359305611628,
      "grad_norm": 0.004312658682465553,
      "learning_rate": 7.569640694388374e-06,
      "loss": 0.0304,
      "step": 30790
    },
    {
      "epoch": 12.4343964473153,
      "grad_norm": 1.307883620262146,
      "learning_rate": 7.565603552684699e-06,
      "loss": 0.0272,
      "step": 30800
    },
    {
      "epoch": 12.438433589018974,
      "grad_norm": 1.3333717584609985,
      "learning_rate": 7.5615664109810264e-06,
      "loss": 0.0183,
      "step": 30810
    },
    {
      "epoch": 12.442470730722649,
      "grad_norm": 0.0001785019412636757,
      "learning_rate": 7.557529269277353e-06,
      "loss": 0.0187,
      "step": 30820
    },
    {
      "epoch": 12.446507872426322,
      "grad_norm": 0.0005652904510498047,
      "learning_rate": 7.553492127573678e-06,
      "loss": 0.0029,
      "step": 30830
    },
    {
      "epoch": 12.450545014129997,
      "grad_norm": 0.5971322059631348,
      "learning_rate": 7.549454985870005e-06,
      "loss": 0.0036,
      "step": 30840
    },
    {
      "epoch": 12.45458215583367,
      "grad_norm": 0.004242938011884689,
      "learning_rate": 7.545417844166331e-06,
      "loss": 0.0109,
      "step": 30850
    },
    {
      "epoch": 12.458619297537343,
      "grad_norm": 0.0007792548276484013,
      "learning_rate": 7.541380702462657e-06,
      "loss": 0.0173,
      "step": 30860
    },
    {
      "epoch": 12.462656439241018,
      "grad_norm": 0.0009905598126351833,
      "learning_rate": 7.5373435607589825e-06,
      "loss": 0.0512,
      "step": 30870
    },
    {
      "epoch": 12.46669358094469,
      "grad_norm": 0.0010961125371977687,
      "learning_rate": 7.53330641905531e-06,
      "loss": 0.0272,
      "step": 30880
    },
    {
      "epoch": 12.470730722648366,
      "grad_norm": 0.4656572639942169,
      "learning_rate": 7.529269277351635e-06,
      "loss": 0.0047,
      "step": 30890
    },
    {
      "epoch": 12.474767864352039,
      "grad_norm": 0.3604455590248108,
      "learning_rate": 7.525232135647962e-06,
      "loss": 0.0044,
      "step": 30900
    },
    {
      "epoch": 12.478805006055712,
      "grad_norm": 3.1280744075775146,
      "learning_rate": 7.5211949939442885e-06,
      "loss": 0.0432,
      "step": 30910
    },
    {
      "epoch": 12.482842147759387,
      "grad_norm": 0.0003750438045244664,
      "learning_rate": 7.517157852240614e-06,
      "loss": 0.0037,
      "step": 30920
    },
    {
      "epoch": 12.48687928946306,
      "grad_norm": 1.3831838369369507,
      "learning_rate": 7.513120710536941e-06,
      "loss": 0.0092,
      "step": 30930
    },
    {
      "epoch": 12.490916431166735,
      "grad_norm": 3.427035331726074,
      "learning_rate": 7.5090835688332665e-06,
      "loss": 0.0022,
      "step": 30940
    },
    {
      "epoch": 12.494953572870408,
      "grad_norm": 1.5795782804489136,
      "learning_rate": 7.505046427129593e-06,
      "loss": 0.0133,
      "step": 30950
    },
    {
      "epoch": 12.49899071457408,
      "grad_norm": 0.026587584987282753,
      "learning_rate": 7.501009285425919e-06,
      "loss": 0.0078,
      "step": 30960
    },
    {
      "epoch": 12.503027856277756,
      "grad_norm": 0.17730465531349182,
      "learning_rate": 7.496972143722245e-06,
      "loss": 0.0303,
      "step": 30970
    },
    {
      "epoch": 12.507064997981429,
      "grad_norm": 0.0018463052110746503,
      "learning_rate": 7.492935002018571e-06,
      "loss": 0.0273,
      "step": 30980
    },
    {
      "epoch": 12.511102139685104,
      "grad_norm": 0.07965878397226334,
      "learning_rate": 7.488897860314898e-06,
      "loss": 0.0257,
      "step": 30990
    },
    {
      "epoch": 12.515139281388777,
      "grad_norm": 0.024995146319270134,
      "learning_rate": 7.484860718611224e-06,
      "loss": 0.0093,
      "step": 31000
    },
    {
      "epoch": 12.51917642309245,
      "grad_norm": 0.0014048349112272263,
      "learning_rate": 7.48082357690755e-06,
      "loss": 0.0083,
      "step": 31010
    },
    {
      "epoch": 12.523213564796125,
      "grad_norm": 0.0021158780436962843,
      "learning_rate": 7.476786435203877e-06,
      "loss": 0.0145,
      "step": 31020
    },
    {
      "epoch": 12.527250706499798,
      "grad_norm": 1.3759933710098267,
      "learning_rate": 7.472749293500202e-06,
      "loss": 0.004,
      "step": 31030
    },
    {
      "epoch": 12.531287848203473,
      "grad_norm": 0.0008258750312961638,
      "learning_rate": 7.4687121517965285e-06,
      "loss": 0.0049,
      "step": 31040
    },
    {
      "epoch": 12.535324989907146,
      "grad_norm": 0.0005729999975301325,
      "learning_rate": 7.464675010092855e-06,
      "loss": 0.0222,
      "step": 31050
    },
    {
      "epoch": 12.539362131610819,
      "grad_norm": 0.001342268195003271,
      "learning_rate": 7.460637868389181e-06,
      "loss": 0.025,
      "step": 31060
    },
    {
      "epoch": 12.543399273314494,
      "grad_norm": 0.0006076463614590466,
      "learning_rate": 7.4566007266855065e-06,
      "loss": 0.026,
      "step": 31070
    },
    {
      "epoch": 12.547436415018167,
      "grad_norm": 0.002117756986990571,
      "learning_rate": 7.452563584981834e-06,
      "loss": 0.0196,
      "step": 31080
    },
    {
      "epoch": 12.551473556721842,
      "grad_norm": 0.025846509262919426,
      "learning_rate": 7.44852644327816e-06,
      "loss": 0.0107,
      "step": 31090
    },
    {
      "epoch": 12.555510698425515,
      "grad_norm": 1.3366225957870483,
      "learning_rate": 7.444489301574485e-06,
      "loss": 0.0114,
      "step": 31100
    },
    {
      "epoch": 12.559547840129188,
      "grad_norm": 0.9004894495010376,
      "learning_rate": 7.4404521598708125e-06,
      "loss": 0.0141,
      "step": 31110
    },
    {
      "epoch": 12.563584981832863,
      "grad_norm": 0.0004644894797820598,
      "learning_rate": 7.436415018167138e-06,
      "loss": 0.0091,
      "step": 31120
    },
    {
      "epoch": 12.567622123536536,
      "grad_norm": 0.00830000825226307,
      "learning_rate": 7.432377876463464e-06,
      "loss": 0.0274,
      "step": 31130
    },
    {
      "epoch": 12.57165926524021,
      "grad_norm": 0.8388525247573853,
      "learning_rate": 7.4283407347597905e-06,
      "loss": 0.0053,
      "step": 31140
    },
    {
      "epoch": 12.575696406943884,
      "grad_norm": 1.6212538480758667,
      "learning_rate": 7.424303593056117e-06,
      "loss": 0.034,
      "step": 31150
    },
    {
      "epoch": 12.579733548647557,
      "grad_norm": 0.0007831714465282857,
      "learning_rate": 7.420266451352444e-06,
      "loss": 0.0347,
      "step": 31160
    },
    {
      "epoch": 12.583770690351232,
      "grad_norm": 1.8176592588424683,
      "learning_rate": 7.416229309648769e-06,
      "loss": 0.0316,
      "step": 31170
    },
    {
      "epoch": 12.587807832054905,
      "grad_norm": 0.006099579390138388,
      "learning_rate": 7.412192167945096e-06,
      "loss": 0.0215,
      "step": 31180
    },
    {
      "epoch": 12.59184497375858,
      "grad_norm": 1.4076693058013916,
      "learning_rate": 7.408155026241421e-06,
      "loss": 0.0277,
      "step": 31190
    },
    {
      "epoch": 12.595882115462253,
      "grad_norm": 0.028173308819532394,
      "learning_rate": 7.404117884537748e-06,
      "loss": 0.0001,
      "step": 31200
    },
    {
      "epoch": 12.599919257165926,
      "grad_norm": 0.004551967605948448,
      "learning_rate": 7.400080742834074e-06,
      "loss": 0.0174,
      "step": 31210
    },
    {
      "epoch": 12.6039563988696,
      "grad_norm": 0.004747070837765932,
      "learning_rate": 7.396043601130401e-06,
      "loss": 0.0043,
      "step": 31220
    },
    {
      "epoch": 12.607993540573274,
      "grad_norm": 0.0035850408021360636,
      "learning_rate": 7.392006459426726e-06,
      "loss": 0.0092,
      "step": 31230
    },
    {
      "epoch": 12.612030682276949,
      "grad_norm": 0.7104561924934387,
      "learning_rate": 7.3879693177230525e-06,
      "loss": 0.0119,
      "step": 31240
    },
    {
      "epoch": 12.616067823980622,
      "grad_norm": 0.0017462910618633032,
      "learning_rate": 7.38393217601938e-06,
      "loss": 0.0134,
      "step": 31250
    },
    {
      "epoch": 12.620104965684295,
      "grad_norm": 1.6492305994033813,
      "learning_rate": 7.379895034315705e-06,
      "loss": 0.0206,
      "step": 31260
    },
    {
      "epoch": 12.62414210738797,
      "grad_norm": 0.7437086701393127,
      "learning_rate": 7.375857892612031e-06,
      "loss": 0.0124,
      "step": 31270
    },
    {
      "epoch": 12.628179249091643,
      "grad_norm": 0.0004377417790237814,
      "learning_rate": 7.371820750908357e-06,
      "loss": 0.025,
      "step": 31280
    },
    {
      "epoch": 12.632216390795318,
      "grad_norm": 0.5947539806365967,
      "learning_rate": 7.367783609204684e-06,
      "loss": 0.0207,
      "step": 31290
    },
    {
      "epoch": 12.63625353249899,
      "grad_norm": 0.9172638058662415,
      "learning_rate": 7.363746467501009e-06,
      "loss": 0.0031,
      "step": 31300
    },
    {
      "epoch": 12.640290674202664,
      "grad_norm": 0.0005873560439795256,
      "learning_rate": 7.3597093257973365e-06,
      "loss": 0.0056,
      "step": 31310
    },
    {
      "epoch": 12.644327815906339,
      "grad_norm": 0.6585423946380615,
      "learning_rate": 7.355672184093662e-06,
      "loss": 0.0504,
      "step": 31320
    },
    {
      "epoch": 12.648364957610012,
      "grad_norm": 0.716962456703186,
      "learning_rate": 7.351635042389988e-06,
      "loss": 0.0022,
      "step": 31330
    },
    {
      "epoch": 12.652402099313687,
      "grad_norm": 0.000267646333668381,
      "learning_rate": 7.347597900686315e-06,
      "loss": 0.0186,
      "step": 31340
    },
    {
      "epoch": 12.65643924101736,
      "grad_norm": 0.6810278296470642,
      "learning_rate": 7.343560758982641e-06,
      "loss": 0.0132,
      "step": 31350
    },
    {
      "epoch": 12.660476382721033,
      "grad_norm": 0.0001232564536621794,
      "learning_rate": 7.339523617278967e-06,
      "loss": 0.0214,
      "step": 31360
    },
    {
      "epoch": 12.664513524424708,
      "grad_norm": 0.00949222594499588,
      "learning_rate": 7.335486475575293e-06,
      "loss": 0.0039,
      "step": 31370
    },
    {
      "epoch": 12.66855066612838,
      "grad_norm": 0.0012472959933802485,
      "learning_rate": 7.33144933387162e-06,
      "loss": 0.0002,
      "step": 31380
    },
    {
      "epoch": 12.672587807832056,
      "grad_norm": 1.3249543905258179,
      "learning_rate": 7.327412192167945e-06,
      "loss": 0.022,
      "step": 31390
    },
    {
      "epoch": 12.676624949535729,
      "grad_norm": 0.00013053888687863946,
      "learning_rate": 7.323375050464272e-06,
      "loss": 0.0296,
      "step": 31400
    },
    {
      "epoch": 12.680662091239402,
      "grad_norm": 0.0005527332541532815,
      "learning_rate": 7.319337908760598e-06,
      "loss": 0.014,
      "step": 31410
    },
    {
      "epoch": 12.684699232943077,
      "grad_norm": 0.002151806140318513,
      "learning_rate": 7.315300767056924e-06,
      "loss": 0.059,
      "step": 31420
    },
    {
      "epoch": 12.68873637464675,
      "grad_norm": 0.009660198353230953,
      "learning_rate": 7.311263625353251e-06,
      "loss": 0.0042,
      "step": 31430
    },
    {
      "epoch": 12.692773516350425,
      "grad_norm": 2.4381444454193115,
      "learning_rate": 7.307226483649577e-06,
      "loss": 0.0186,
      "step": 31440
    },
    {
      "epoch": 12.696810658054098,
      "grad_norm": 0.011703905649483204,
      "learning_rate": 7.303189341945903e-06,
      "loss": 0.0037,
      "step": 31450
    },
    {
      "epoch": 12.70084779975777,
      "grad_norm": 0.0005509313195943832,
      "learning_rate": 7.299152200242229e-06,
      "loss": 0.0041,
      "step": 31460
    },
    {
      "epoch": 12.704884941461446,
      "grad_norm": 0.0031805308535695076,
      "learning_rate": 7.2951150585385554e-06,
      "loss": 0.0072,
      "step": 31470
    },
    {
      "epoch": 12.708922083165119,
      "grad_norm": 0.012584771029651165,
      "learning_rate": 7.291077916834881e-06,
      "loss": 0.008,
      "step": 31480
    },
    {
      "epoch": 12.712959224868793,
      "grad_norm": 0.012477993033826351,
      "learning_rate": 7.287040775131208e-06,
      "loss": 0.0073,
      "step": 31490
    },
    {
      "epoch": 12.716996366572467,
      "grad_norm": 2.4707531929016113,
      "learning_rate": 7.2830036334275335e-06,
      "loss": 0.0113,
      "step": 31500
    },
    {
      "epoch": 12.72103350827614,
      "grad_norm": 0.0009331252076663077,
      "learning_rate": 7.27896649172386e-06,
      "loss": 0.007,
      "step": 31510
    },
    {
      "epoch": 12.725070649979815,
      "grad_norm": 0.0006275668274611235,
      "learning_rate": 7.274929350020187e-06,
      "loss": 0.0091,
      "step": 31520
    },
    {
      "epoch": 12.729107791683488,
      "grad_norm": 1.7379615306854248,
      "learning_rate": 7.270892208316512e-06,
      "loss": 0.0119,
      "step": 31530
    },
    {
      "epoch": 12.733144933387162,
      "grad_norm": 0.003797162091359496,
      "learning_rate": 7.266855066612839e-06,
      "loss": 0.0058,
      "step": 31540
    },
    {
      "epoch": 12.737182075090836,
      "grad_norm": 1.0737898349761963,
      "learning_rate": 7.262817924909165e-06,
      "loss": 0.0182,
      "step": 31550
    },
    {
      "epoch": 12.741219216794509,
      "grad_norm": 0.028585204854607582,
      "learning_rate": 7.258780783205491e-06,
      "loss": 0.0042,
      "step": 31560
    },
    {
      "epoch": 12.745256358498184,
      "grad_norm": 0.002154864836484194,
      "learning_rate": 7.254743641501817e-06,
      "loss": 0.0003,
      "step": 31570
    },
    {
      "epoch": 12.749293500201857,
      "grad_norm": 0.21580122411251068,
      "learning_rate": 7.250706499798144e-06,
      "loss": 0.0123,
      "step": 31580
    },
    {
      "epoch": 12.753330641905531,
      "grad_norm": 0.006536690052598715,
      "learning_rate": 7.24666935809447e-06,
      "loss": 0.0121,
      "step": 31590
    },
    {
      "epoch": 12.757367783609205,
      "grad_norm": 0.0015397133538499475,
      "learning_rate": 7.2426322163907955e-06,
      "loss": 0.0133,
      "step": 31600
    },
    {
      "epoch": 12.761404925312878,
      "grad_norm": 1.1226258277893066,
      "learning_rate": 7.238595074687123e-06,
      "loss": 0.0219,
      "step": 31610
    },
    {
      "epoch": 12.765442067016552,
      "grad_norm": 1.6927517652511597,
      "learning_rate": 7.234557932983448e-06,
      "loss": 0.0109,
      "step": 31620
    },
    {
      "epoch": 12.769479208720226,
      "grad_norm": 0.04979662969708443,
      "learning_rate": 7.230520791279775e-06,
      "loss": 0.0239,
      "step": 31630
    },
    {
      "epoch": 12.7735163504239,
      "grad_norm": 0.0006016679690219462,
      "learning_rate": 7.226483649576101e-06,
      "loss": 0.0237,
      "step": 31640
    },
    {
      "epoch": 12.777553492127574,
      "grad_norm": 0.03856966271996498,
      "learning_rate": 7.222446507872427e-06,
      "loss": 0.0104,
      "step": 31650
    },
    {
      "epoch": 12.781590633831247,
      "grad_norm": 1.0065053701400757,
      "learning_rate": 7.218409366168752e-06,
      "loss": 0.012,
      "step": 31660
    },
    {
      "epoch": 12.785627775534921,
      "grad_norm": 0.001287319464609027,
      "learning_rate": 7.2143722244650795e-06,
      "loss": 0.0078,
      "step": 31670
    },
    {
      "epoch": 12.789664917238595,
      "grad_norm": 0.0007993774488568306,
      "learning_rate": 7.210335082761406e-06,
      "loss": 0.0058,
      "step": 31680
    },
    {
      "epoch": 12.79370205894227,
      "grad_norm": 0.0006761003169231117,
      "learning_rate": 7.206297941057731e-06,
      "loss": 0.0139,
      "step": 31690
    },
    {
      "epoch": 12.797739200645943,
      "grad_norm": 0.0014004214899614453,
      "learning_rate": 7.202260799354058e-06,
      "loss": 0.0503,
      "step": 31700
    },
    {
      "epoch": 12.801776342349616,
      "grad_norm": 0.0039663659408688545,
      "learning_rate": 7.198223657650384e-06,
      "loss": 0.0041,
      "step": 31710
    },
    {
      "epoch": 12.80581348405329,
      "grad_norm": 0.003992223646491766,
      "learning_rate": 7.194186515946711e-06,
      "loss": 0.0124,
      "step": 31720
    },
    {
      "epoch": 12.809850625756964,
      "grad_norm": 0.0024778498336672783,
      "learning_rate": 7.190149374243036e-06,
      "loss": 0.0133,
      "step": 31730
    },
    {
      "epoch": 12.813887767460638,
      "grad_norm": 0.0019699877593666315,
      "learning_rate": 7.186112232539363e-06,
      "loss": 0.0275,
      "step": 31740
    },
    {
      "epoch": 12.817924909164311,
      "grad_norm": 0.006946222856640816,
      "learning_rate": 7.182075090835688e-06,
      "loss": 0.015,
      "step": 31750
    },
    {
      "epoch": 12.821962050867985,
      "grad_norm": 0.07119022309780121,
      "learning_rate": 7.178037949132015e-06,
      "loss": 0.0113,
      "step": 31760
    },
    {
      "epoch": 12.82599919257166,
      "grad_norm": 1.3731764554977417,
      "learning_rate": 7.1740008074283415e-06,
      "loss": 0.009,
      "step": 31770
    },
    {
      "epoch": 12.830036334275333,
      "grad_norm": 1.2952510118484497,
      "learning_rate": 7.169963665724668e-06,
      "loss": 0.0139,
      "step": 31780
    },
    {
      "epoch": 12.834073475979007,
      "grad_norm": 0.0026012493763118982,
      "learning_rate": 7.165926524020994e-06,
      "loss": 0.0157,
      "step": 31790
    },
    {
      "epoch": 12.83811061768268,
      "grad_norm": 0.0019361790036782622,
      "learning_rate": 7.1618893823173195e-06,
      "loss": 0.0101,
      "step": 31800
    },
    {
      "epoch": 12.842147759386354,
      "grad_norm": 1.252655267715454,
      "learning_rate": 7.157852240613647e-06,
      "loss": 0.0158,
      "step": 31810
    },
    {
      "epoch": 12.846184901090028,
      "grad_norm": 1.4003267288208008,
      "learning_rate": 7.153815098909972e-06,
      "loss": 0.0087,
      "step": 31820
    },
    {
      "epoch": 12.850222042793702,
      "grad_norm": 0.0008145024767145514,
      "learning_rate": 7.149777957206298e-06,
      "loss": 0.0094,
      "step": 31830
    },
    {
      "epoch": 12.854259184497376,
      "grad_norm": 0.007986219599843025,
      "learning_rate": 7.145740815502624e-06,
      "loss": 0.0085,
      "step": 31840
    },
    {
      "epoch": 12.85829632620105,
      "grad_norm": 1.9466966390609741,
      "learning_rate": 7.141703673798951e-06,
      "loss": 0.0213,
      "step": 31850
    },
    {
      "epoch": 12.862333467904723,
      "grad_norm": 0.5028676986694336,
      "learning_rate": 7.137666532095277e-06,
      "loss": 0.0215,
      "step": 31860
    },
    {
      "epoch": 12.866370609608397,
      "grad_norm": 0.0005294436705298722,
      "learning_rate": 7.1336293903916035e-06,
      "loss": 0.0545,
      "step": 31870
    },
    {
      "epoch": 12.87040775131207,
      "grad_norm": 0.0006279467488639057,
      "learning_rate": 7.12959224868793e-06,
      "loss": 0.0164,
      "step": 31880
    },
    {
      "epoch": 12.874444893015745,
      "grad_norm": 0.0006231071893125772,
      "learning_rate": 7.125555106984255e-06,
      "loss": 0.003,
      "step": 31890
    },
    {
      "epoch": 12.878482034719418,
      "grad_norm": 0.002217639470472932,
      "learning_rate": 7.121517965280582e-06,
      "loss": 0.0077,
      "step": 31900
    },
    {
      "epoch": 12.882519176423092,
      "grad_norm": 0.0007839985773898661,
      "learning_rate": 7.117480823576908e-06,
      "loss": 0.0213,
      "step": 31910
    },
    {
      "epoch": 12.886556318126766,
      "grad_norm": 0.005214429926127195,
      "learning_rate": 7.113443681873234e-06,
      "loss": 0.0098,
      "step": 31920
    },
    {
      "epoch": 12.89059345983044,
      "grad_norm": 2.078897714614868,
      "learning_rate": 7.10940654016956e-06,
      "loss": 0.0139,
      "step": 31930
    },
    {
      "epoch": 12.894630601534114,
      "grad_norm": 0.007356176618486643,
      "learning_rate": 7.105369398465887e-06,
      "loss": 0.0034,
      "step": 31940
    },
    {
      "epoch": 12.898667743237787,
      "grad_norm": 0.0026344566140323877,
      "learning_rate": 7.101332256762213e-06,
      "loss": 0.0151,
      "step": 31950
    },
    {
      "epoch": 12.90270488494146,
      "grad_norm": 0.0010730436770245433,
      "learning_rate": 7.097295115058539e-06,
      "loss": 0.026,
      "step": 31960
    },
    {
      "epoch": 12.906742026645135,
      "grad_norm": 0.002404905157163739,
      "learning_rate": 7.0932579733548655e-06,
      "loss": 0.0024,
      "step": 31970
    },
    {
      "epoch": 12.910779168348808,
      "grad_norm": 0.00557439960539341,
      "learning_rate": 7.089220831651191e-06,
      "loss": 0.0102,
      "step": 31980
    },
    {
      "epoch": 12.914816310052483,
      "grad_norm": 0.005792025942355394,
      "learning_rate": 7.085183689947518e-06,
      "loss": 0.0055,
      "step": 31990
    },
    {
      "epoch": 12.918853451756156,
      "grad_norm": 0.0065664490684866905,
      "learning_rate": 7.0811465482438436e-06,
      "loss": 0.005,
      "step": 32000
    },
    {
      "epoch": 12.922890593459831,
      "grad_norm": 0.0007042031502351165,
      "learning_rate": 7.07710940654017e-06,
      "loss": 0.005,
      "step": 32010
    },
    {
      "epoch": 12.926927735163504,
      "grad_norm": 1.3888919353485107,
      "learning_rate": 7.073072264836497e-06,
      "loss": 0.0264,
      "step": 32020
    },
    {
      "epoch": 12.930964876867177,
      "grad_norm": 0.0030322386883199215,
      "learning_rate": 7.069035123132822e-06,
      "loss": 0.0169,
      "step": 32030
    },
    {
      "epoch": 12.935002018570852,
      "grad_norm": 0.0006072237738408148,
      "learning_rate": 7.0649979814291496e-06,
      "loss": 0.0091,
      "step": 32040
    },
    {
      "epoch": 12.939039160274525,
      "grad_norm": 1.4542423486709595,
      "learning_rate": 7.060960839725475e-06,
      "loss": 0.0134,
      "step": 32050
    },
    {
      "epoch": 12.9430763019782,
      "grad_norm": 1.1385248899459839,
      "learning_rate": 7.056923698021801e-06,
      "loss": 0.0136,
      "step": 32060
    },
    {
      "epoch": 12.947113443681873,
      "grad_norm": 0.0009566016378812492,
      "learning_rate": 7.052886556318127e-06,
      "loss": 0.0099,
      "step": 32070
    },
    {
      "epoch": 12.951150585385546,
      "grad_norm": 1.0727068185806274,
      "learning_rate": 7.048849414614454e-06,
      "loss": 0.0143,
      "step": 32080
    },
    {
      "epoch": 12.955187727089221,
      "grad_norm": 0.0002652078401297331,
      "learning_rate": 7.044812272910779e-06,
      "loss": 0.0152,
      "step": 32090
    },
    {
      "epoch": 12.959224868792894,
      "grad_norm": 0.003420615568757057,
      "learning_rate": 7.040775131207106e-06,
      "loss": 0.0137,
      "step": 32100
    },
    {
      "epoch": 12.96326201049657,
      "grad_norm": 2.4514474868774414,
      "learning_rate": 7.036737989503433e-06,
      "loss": 0.0232,
      "step": 32110
    },
    {
      "epoch": 12.967299152200242,
      "grad_norm": 0.01732281967997551,
      "learning_rate": 7.032700847799758e-06,
      "loss": 0.0456,
      "step": 32120
    },
    {
      "epoch": 12.971336293903915,
      "grad_norm": 0.00058666558470577,
      "learning_rate": 7.028663706096085e-06,
      "loss": 0.0099,
      "step": 32130
    },
    {
      "epoch": 12.97537343560759,
      "grad_norm": 0.00043163597001694143,
      "learning_rate": 7.024626564392411e-06,
      "loss": 0.0176,
      "step": 32140
    },
    {
      "epoch": 12.979410577311263,
      "grad_norm": 0.0036641419865190983,
      "learning_rate": 7.020589422688737e-06,
      "loss": 0.0045,
      "step": 32150
    },
    {
      "epoch": 12.983447719014938,
      "grad_norm": 1.2206734418869019,
      "learning_rate": 7.0165522809850625e-06,
      "loss": 0.0137,
      "step": 32160
    },
    {
      "epoch": 12.987484860718611,
      "grad_norm": 0.0005432444158941507,
      "learning_rate": 7.01251513928139e-06,
      "loss": 0.0018,
      "step": 32170
    },
    {
      "epoch": 12.991522002422284,
      "grad_norm": 0.0006378082907758653,
      "learning_rate": 7.008477997577715e-06,
      "loss": 0.0476,
      "step": 32180
    },
    {
      "epoch": 12.99555914412596,
      "grad_norm": 1.522383213043213,
      "learning_rate": 7.004440855874042e-06,
      "loss": 0.0145,
      "step": 32190
    },
    {
      "epoch": 12.999596285829632,
      "grad_norm": 0.0012501671444624662,
      "learning_rate": 7.0004037141703685e-06,
      "loss": 0.0232,
      "step": 32200
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.9845125786163522,
      "eval_f1": 0.943954480796586,
      "eval_loss": 0.059324052184820175,
      "eval_precision": 0.9346478873239437,
      "eval_recall": 0.9534482758620689,
      "eval_runtime": 444.845,
      "eval_samples_per_second": 28.639,
      "eval_steps_per_second": 1.194,
      "step": 32201
    },
    {
      "epoch": 13.003633427533307,
      "grad_norm": 0.0014638140564784408,
      "learning_rate": 6.996366572466694e-06,
      "loss": 0.0083,
      "step": 32210
    },
    {
      "epoch": 13.00767056923698,
      "grad_norm": 0.0010431703412905335,
      "learning_rate": 6.992329430763021e-06,
      "loss": 0.019,
      "step": 32220
    },
    {
      "epoch": 13.011707710940653,
      "grad_norm": 2.980381965637207,
      "learning_rate": 6.9882922890593465e-06,
      "loss": 0.0115,
      "step": 32230
    },
    {
      "epoch": 13.015744852644328,
      "grad_norm": 0.00237283855676651,
      "learning_rate": 6.984255147355673e-06,
      "loss": 0.0082,
      "step": 32240
    },
    {
      "epoch": 13.019781994348001,
      "grad_norm": 1.3270093202590942,
      "learning_rate": 6.980218005651998e-06,
      "loss": 0.0106,
      "step": 32250
    },
    {
      "epoch": 13.023819136051676,
      "grad_norm": 0.0033350957091897726,
      "learning_rate": 6.976180863948325e-06,
      "loss": 0.0062,
      "step": 32260
    },
    {
      "epoch": 13.02785627775535,
      "grad_norm": 0.017371976748108864,
      "learning_rate": 6.972143722244651e-06,
      "loss": 0.0043,
      "step": 32270
    },
    {
      "epoch": 13.031893419459022,
      "grad_norm": 1.1266933679580688,
      "learning_rate": 6.968106580540978e-06,
      "loss": 0.0256,
      "step": 32280
    },
    {
      "epoch": 13.035930561162697,
      "grad_norm": 0.0008915197104215622,
      "learning_rate": 6.964069438837304e-06,
      "loss": 0.0062,
      "step": 32290
    },
    {
      "epoch": 13.03996770286637,
      "grad_norm": 0.000949529989156872,
      "learning_rate": 6.96003229713363e-06,
      "loss": 0.0062,
      "step": 32300
    },
    {
      "epoch": 13.044004844570045,
      "grad_norm": 0.0006986754015088081,
      "learning_rate": 6.955995155429957e-06,
      "loss": 0.0031,
      "step": 32310
    },
    {
      "epoch": 13.048041986273718,
      "grad_norm": 0.0038318680599331856,
      "learning_rate": 6.951958013726282e-06,
      "loss": 0.0087,
      "step": 32320
    },
    {
      "epoch": 13.052079127977391,
      "grad_norm": 2.4424233436584473,
      "learning_rate": 6.9479208720226085e-06,
      "loss": 0.0182,
      "step": 32330
    },
    {
      "epoch": 13.056116269681066,
      "grad_norm": 0.49783724546432495,
      "learning_rate": 6.943883730318935e-06,
      "loss": 0.0057,
      "step": 32340
    },
    {
      "epoch": 13.06015341138474,
      "grad_norm": 0.0007392613333649933,
      "learning_rate": 6.939846588615261e-06,
      "loss": 0.017,
      "step": 32350
    },
    {
      "epoch": 13.064190553088414,
      "grad_norm": 0.08204727619886398,
      "learning_rate": 6.9358094469115865e-06,
      "loss": 0.0064,
      "step": 32360
    },
    {
      "epoch": 13.068227694792087,
      "grad_norm": 0.0006248264107853174,
      "learning_rate": 6.931772305207914e-06,
      "loss": 0.0077,
      "step": 32370
    },
    {
      "epoch": 13.07226483649576,
      "grad_norm": 0.0009581710328347981,
      "learning_rate": 6.92773516350424e-06,
      "loss": 0.0076,
      "step": 32380
    },
    {
      "epoch": 13.076301978199435,
      "grad_norm": 1.2242168188095093,
      "learning_rate": 6.923698021800565e-06,
      "loss": 0.0173,
      "step": 32390
    },
    {
      "epoch": 13.080339119903108,
      "grad_norm": 0.0005495789810083807,
      "learning_rate": 6.9196608800968925e-06,
      "loss": 0.0101,
      "step": 32400
    },
    {
      "epoch": 13.084376261606783,
      "grad_norm": 0.006985368672758341,
      "learning_rate": 6.915623738393218e-06,
      "loss": 0.0312,
      "step": 32410
    },
    {
      "epoch": 13.088413403310456,
      "grad_norm": 1.1993731260299683,
      "learning_rate": 6.911586596689544e-06,
      "loss": 0.0049,
      "step": 32420
    },
    {
      "epoch": 13.09245054501413,
      "grad_norm": 1.3587815761566162,
      "learning_rate": 6.9075494549858705e-06,
      "loss": 0.0166,
      "step": 32430
    },
    {
      "epoch": 13.096487686717804,
      "grad_norm": 0.005449389573186636,
      "learning_rate": 6.903512313282197e-06,
      "loss": 0.0055,
      "step": 32440
    },
    {
      "epoch": 13.100524828421477,
      "grad_norm": 0.017942078411579132,
      "learning_rate": 6.899475171578522e-06,
      "loss": 0.0056,
      "step": 32450
    },
    {
      "epoch": 13.104561970125152,
      "grad_norm": 0.0023362552747130394,
      "learning_rate": 6.895438029874849e-06,
      "loss": 0.0144,
      "step": 32460
    },
    {
      "epoch": 13.108599111828825,
      "grad_norm": 1.0453929901123047,
      "learning_rate": 6.891400888171176e-06,
      "loss": 0.0173,
      "step": 32470
    },
    {
      "epoch": 13.112636253532498,
      "grad_norm": 0.8134042620658875,
      "learning_rate": 6.887363746467501e-06,
      "loss": 0.0173,
      "step": 32480
    },
    {
      "epoch": 13.116673395236173,
      "grad_norm": 1.0702935457229614,
      "learning_rate": 6.883326604763828e-06,
      "loss": 0.0101,
      "step": 32490
    },
    {
      "epoch": 13.120710536939846,
      "grad_norm": 0.0009551119292154908,
      "learning_rate": 6.879289463060154e-06,
      "loss": 0.0062,
      "step": 32500
    },
    {
      "epoch": 13.124747678643521,
      "grad_norm": 1.0606834888458252,
      "learning_rate": 6.87525232135648e-06,
      "loss": 0.0029,
      "step": 32510
    },
    {
      "epoch": 13.128784820347194,
      "grad_norm": 0.0009996487060561776,
      "learning_rate": 6.871215179652806e-06,
      "loss": 0.0113,
      "step": 32520
    },
    {
      "epoch": 13.132821962050867,
      "grad_norm": 0.020121648907661438,
      "learning_rate": 6.8671780379491325e-06,
      "loss": 0.0089,
      "step": 32530
    },
    {
      "epoch": 13.136859103754542,
      "grad_norm": 0.0023172073997557163,
      "learning_rate": 6.86314089624546e-06,
      "loss": 0.0139,
      "step": 32540
    },
    {
      "epoch": 13.140896245458215,
      "grad_norm": 0.0005124381277710199,
      "learning_rate": 6.859103754541785e-06,
      "loss": 0.0032,
      "step": 32550
    },
    {
      "epoch": 13.14493338716189,
      "grad_norm": 0.9454643130302429,
      "learning_rate": 6.855066612838111e-06,
      "loss": 0.0092,
      "step": 32560
    },
    {
      "epoch": 13.148970528865563,
      "grad_norm": 0.0008741457713767886,
      "learning_rate": 6.851029471134437e-06,
      "loss": 0.0094,
      "step": 32570
    },
    {
      "epoch": 13.153007670569236,
      "grad_norm": 0.0005332628497853875,
      "learning_rate": 6.846992329430764e-06,
      "loss": 0.0049,
      "step": 32580
    },
    {
      "epoch": 13.157044812272911,
      "grad_norm": 1.918705940246582,
      "learning_rate": 6.842955187727089e-06,
      "loss": 0.0091,
      "step": 32590
    },
    {
      "epoch": 13.161081953976584,
      "grad_norm": 0.0024538785219192505,
      "learning_rate": 6.8389180460234165e-06,
      "loss": 0.0063,
      "step": 32600
    },
    {
      "epoch": 13.165119095680259,
      "grad_norm": 0.0006576946470886469,
      "learning_rate": 6.834880904319742e-06,
      "loss": 0.0217,
      "step": 32610
    },
    {
      "epoch": 13.169156237383932,
      "grad_norm": 0.0034422543831169605,
      "learning_rate": 6.830843762616068e-06,
      "loss": 0.0053,
      "step": 32620
    },
    {
      "epoch": 13.173193379087605,
      "grad_norm": 0.0006771024782210588,
      "learning_rate": 6.826806620912395e-06,
      "loss": 0.0192,
      "step": 32630
    },
    {
      "epoch": 13.17723052079128,
      "grad_norm": 0.014885366894304752,
      "learning_rate": 6.822769479208721e-06,
      "loss": 0.0217,
      "step": 32640
    },
    {
      "epoch": 13.181267662494953,
      "grad_norm": 0.0005429931334219873,
      "learning_rate": 6.818732337505047e-06,
      "loss": 0.0154,
      "step": 32650
    },
    {
      "epoch": 13.185304804198628,
      "grad_norm": 1.771117091178894,
      "learning_rate": 6.8146951958013726e-06,
      "loss": 0.0151,
      "step": 32660
    },
    {
      "epoch": 13.189341945902301,
      "grad_norm": 0.0012895582476630807,
      "learning_rate": 6.8106580540977e-06,
      "loss": 0.03,
      "step": 32670
    },
    {
      "epoch": 13.193379087605974,
      "grad_norm": 0.0072495718486607075,
      "learning_rate": 6.806620912394025e-06,
      "loss": 0.0006,
      "step": 32680
    },
    {
      "epoch": 13.197416229309649,
      "grad_norm": 1.7253168821334839,
      "learning_rate": 6.802583770690352e-06,
      "loss": 0.017,
      "step": 32690
    },
    {
      "epoch": 13.201453371013322,
      "grad_norm": 0.0006684409454464912,
      "learning_rate": 6.798546628986678e-06,
      "loss": 0.0051,
      "step": 32700
    },
    {
      "epoch": 13.205490512716997,
      "grad_norm": 1.142972707748413,
      "learning_rate": 6.794509487283004e-06,
      "loss": 0.0125,
      "step": 32710
    },
    {
      "epoch": 13.20952765442067,
      "grad_norm": 0.0011648235376924276,
      "learning_rate": 6.790472345579331e-06,
      "loss": 0.0052,
      "step": 32720
    },
    {
      "epoch": 13.213564796124343,
      "grad_norm": 0.0005833228351548314,
      "learning_rate": 6.7864352038756566e-06,
      "loss": 0.006,
      "step": 32730
    },
    {
      "epoch": 13.217601937828018,
      "grad_norm": 0.0024576918222010136,
      "learning_rate": 6.782398062171983e-06,
      "loss": 0.0094,
      "step": 32740
    },
    {
      "epoch": 13.221639079531691,
      "grad_norm": 0.0004427165549714118,
      "learning_rate": 6.778360920468309e-06,
      "loss": 0.0032,
      "step": 32750
    },
    {
      "epoch": 13.225676221235366,
      "grad_norm": 0.00040870075463317335,
      "learning_rate": 6.7743237787646354e-06,
      "loss": 0.0104,
      "step": 32760
    },
    {
      "epoch": 13.229713362939039,
      "grad_norm": 0.0015255335019901395,
      "learning_rate": 6.770286637060961e-06,
      "loss": 0.0148,
      "step": 32770
    },
    {
      "epoch": 13.233750504642712,
      "grad_norm": 1.5690553188323975,
      "learning_rate": 6.766249495357288e-06,
      "loss": 0.0083,
      "step": 32780
    },
    {
      "epoch": 13.237787646346387,
      "grad_norm": 0.0005454663187265396,
      "learning_rate": 6.7622123536536134e-06,
      "loss": 0.0,
      "step": 32790
    },
    {
      "epoch": 13.24182478805006,
      "grad_norm": 1.012313961982727,
      "learning_rate": 6.75817521194994e-06,
      "loss": 0.008,
      "step": 32800
    },
    {
      "epoch": 13.245861929753735,
      "grad_norm": 0.6983024477958679,
      "learning_rate": 6.754138070246267e-06,
      "loss": 0.0078,
      "step": 32810
    },
    {
      "epoch": 13.249899071457408,
      "grad_norm": 0.6627936959266663,
      "learning_rate": 6.750100928542592e-06,
      "loss": 0.0015,
      "step": 32820
    },
    {
      "epoch": 13.253936213161081,
      "grad_norm": 0.0005447881412692368,
      "learning_rate": 6.746063786838919e-06,
      "loss": 0.0032,
      "step": 32830
    },
    {
      "epoch": 13.257973354864756,
      "grad_norm": 0.0002790178405120969,
      "learning_rate": 6.742026645135245e-06,
      "loss": 0.0224,
      "step": 32840
    },
    {
      "epoch": 13.26201049656843,
      "grad_norm": 0.0003716824867296964,
      "learning_rate": 6.737989503431571e-06,
      "loss": 0.0019,
      "step": 32850
    },
    {
      "epoch": 13.266047638272104,
      "grad_norm": 0.00041382640483789146,
      "learning_rate": 6.733952361727897e-06,
      "loss": 0.0086,
      "step": 32860
    },
    {
      "epoch": 13.270084779975777,
      "grad_norm": 0.002371056703850627,
      "learning_rate": 6.729915220024224e-06,
      "loss": 0.0145,
      "step": 32870
    },
    {
      "epoch": 13.27412192167945,
      "grad_norm": 0.45520538091659546,
      "learning_rate": 6.725878078320549e-06,
      "loss": 0.0024,
      "step": 32880
    },
    {
      "epoch": 13.278159063383125,
      "grad_norm": 1.2753698825836182,
      "learning_rate": 6.7218409366168755e-06,
      "loss": 0.0036,
      "step": 32890
    },
    {
      "epoch": 13.282196205086798,
      "grad_norm": 0.0012011362705379725,
      "learning_rate": 6.717803794913203e-06,
      "loss": 0.0035,
      "step": 32900
    },
    {
      "epoch": 13.286233346790473,
      "grad_norm": 0.0001497066259616986,
      "learning_rate": 6.713766653209528e-06,
      "loss": 0.0059,
      "step": 32910
    },
    {
      "epoch": 13.290270488494146,
      "grad_norm": 0.0003103640046902001,
      "learning_rate": 6.709729511505854e-06,
      "loss": 0.0592,
      "step": 32920
    },
    {
      "epoch": 13.29430763019782,
      "grad_norm": 0.001672145095653832,
      "learning_rate": 6.705692369802181e-06,
      "loss": 0.0517,
      "step": 32930
    },
    {
      "epoch": 13.298344771901494,
      "grad_norm": 0.0021214382722973824,
      "learning_rate": 6.701655228098507e-06,
      "loss": 0.0126,
      "step": 32940
    },
    {
      "epoch": 13.302381913605167,
      "grad_norm": 1.5894086360931396,
      "learning_rate": 6.697618086394832e-06,
      "loss": 0.0204,
      "step": 32950
    },
    {
      "epoch": 13.306419055308842,
      "grad_norm": 0.005373483523726463,
      "learning_rate": 6.6935809446911595e-06,
      "loss": 0.0139,
      "step": 32960
    },
    {
      "epoch": 13.310456197012515,
      "grad_norm": 0.003197004087269306,
      "learning_rate": 6.689543802987486e-06,
      "loss": 0.0077,
      "step": 32970
    },
    {
      "epoch": 13.314493338716188,
      "grad_norm": 0.8267511129379272,
      "learning_rate": 6.685506661283811e-06,
      "loss": 0.0057,
      "step": 32980
    },
    {
      "epoch": 13.318530480419863,
      "grad_norm": 0.5050197839736938,
      "learning_rate": 6.681469519580138e-06,
      "loss": 0.0202,
      "step": 32990
    },
    {
      "epoch": 13.322567622123536,
      "grad_norm": 0.0029094440396875143,
      "learning_rate": 6.677432377876464e-06,
      "loss": 0.0026,
      "step": 33000
    },
    {
      "epoch": 13.326604763827211,
      "grad_norm": 0.0022156909108161926,
      "learning_rate": 6.673395236172791e-06,
      "loss": 0.0135,
      "step": 33010
    },
    {
      "epoch": 13.330641905530884,
      "grad_norm": 0.004350071772933006,
      "learning_rate": 6.669358094469116e-06,
      "loss": 0.02,
      "step": 33020
    },
    {
      "epoch": 13.334679047234557,
      "grad_norm": 3.9770689010620117,
      "learning_rate": 6.665320952765443e-06,
      "loss": 0.0087,
      "step": 33030
    },
    {
      "epoch": 13.338716188938232,
      "grad_norm": 0.003833518596366048,
      "learning_rate": 6.661283811061768e-06,
      "loss": 0.0273,
      "step": 33040
    },
    {
      "epoch": 13.342753330641905,
      "grad_norm": 2.059971809387207,
      "learning_rate": 6.657246669358095e-06,
      "loss": 0.0492,
      "step": 33050
    },
    {
      "epoch": 13.34679047234558,
      "grad_norm": 0.005359773989766836,
      "learning_rate": 6.6532095276544215e-06,
      "loss": 0.0199,
      "step": 33060
    },
    {
      "epoch": 13.350827614049253,
      "grad_norm": 1.0490965843200684,
      "learning_rate": 6.649172385950747e-06,
      "loss": 0.0043,
      "step": 33070
    },
    {
      "epoch": 13.354864755752926,
      "grad_norm": 1.4346479177474976,
      "learning_rate": 6.645135244247074e-06,
      "loss": 0.0085,
      "step": 33080
    },
    {
      "epoch": 13.358901897456601,
      "grad_norm": 3.005180597305298,
      "learning_rate": 6.6410981025433995e-06,
      "loss": 0.0308,
      "step": 33090
    },
    {
      "epoch": 13.362939039160274,
      "grad_norm": 0.5086738467216492,
      "learning_rate": 6.637060960839727e-06,
      "loss": 0.0256,
      "step": 33100
    },
    {
      "epoch": 13.366976180863949,
      "grad_norm": 0.0627446100115776,
      "learning_rate": 6.633023819136052e-06,
      "loss": 0.0096,
      "step": 33110
    },
    {
      "epoch": 13.371013322567622,
      "grad_norm": 0.003160999156534672,
      "learning_rate": 6.628986677432378e-06,
      "loss": 0.009,
      "step": 33120
    },
    {
      "epoch": 13.375050464271295,
      "grad_norm": 0.0019553694874048233,
      "learning_rate": 6.624949535728704e-06,
      "loss": 0.0171,
      "step": 33130
    },
    {
      "epoch": 13.37908760597497,
      "grad_norm": 0.0026803486980497837,
      "learning_rate": 6.620912394025031e-06,
      "loss": 0.0146,
      "step": 33140
    },
    {
      "epoch": 13.383124747678643,
      "grad_norm": 0.0014307606033980846,
      "learning_rate": 6.616875252321357e-06,
      "loss": 0.0428,
      "step": 33150
    },
    {
      "epoch": 13.387161889382318,
      "grad_norm": 0.0011871169554069638,
      "learning_rate": 6.6128381106176835e-06,
      "loss": 0.0147,
      "step": 33160
    },
    {
      "epoch": 13.391199031085991,
      "grad_norm": 0.0012785288272425532,
      "learning_rate": 6.60880096891401e-06,
      "loss": 0.0256,
      "step": 33170
    },
    {
      "epoch": 13.395236172789666,
      "grad_norm": 1.3764809370040894,
      "learning_rate": 6.604763827210335e-06,
      "loss": 0.0194,
      "step": 33180
    },
    {
      "epoch": 13.399273314493339,
      "grad_norm": 0.0027805909048765898,
      "learning_rate": 6.600726685506662e-06,
      "loss": 0.0019,
      "step": 33190
    },
    {
      "epoch": 13.403310456197012,
      "grad_norm": 0.0018583117052912712,
      "learning_rate": 6.596689543802988e-06,
      "loss": 0.0181,
      "step": 33200
    },
    {
      "epoch": 13.407347597900687,
      "grad_norm": 0.028462927788496017,
      "learning_rate": 6.592652402099314e-06,
      "loss": 0.0125,
      "step": 33210
    },
    {
      "epoch": 13.41138473960436,
      "grad_norm": 0.0017197317210957408,
      "learning_rate": 6.5886152603956396e-06,
      "loss": 0.0152,
      "step": 33220
    },
    {
      "epoch": 13.415421881308035,
      "grad_norm": 0.010866859927773476,
      "learning_rate": 6.584578118691967e-06,
      "loss": 0.0093,
      "step": 33230
    },
    {
      "epoch": 13.419459023011708,
      "grad_norm": 0.00239484291523695,
      "learning_rate": 6.580540976988293e-06,
      "loss": 0.0064,
      "step": 33240
    },
    {
      "epoch": 13.423496164715381,
      "grad_norm": 0.018473204225301743,
      "learning_rate": 6.576503835284619e-06,
      "loss": 0.0185,
      "step": 33250
    },
    {
      "epoch": 13.427533306419056,
      "grad_norm": 0.0016175555065274239,
      "learning_rate": 6.5724666935809455e-06,
      "loss": 0.0001,
      "step": 33260
    },
    {
      "epoch": 13.431570448122729,
      "grad_norm": 1.0008760690689087,
      "learning_rate": 6.568429551877271e-06,
      "loss": 0.0278,
      "step": 33270
    },
    {
      "epoch": 13.435607589826404,
      "grad_norm": 0.9566481709480286,
      "learning_rate": 6.564392410173598e-06,
      "loss": 0.0021,
      "step": 33280
    },
    {
      "epoch": 13.439644731530077,
      "grad_norm": 0.0019001063192263246,
      "learning_rate": 6.5603552684699236e-06,
      "loss": 0.0032,
      "step": 33290
    },
    {
      "epoch": 13.44368187323375,
      "grad_norm": 0.0017615397227928042,
      "learning_rate": 6.55631812676625e-06,
      "loss": 0.0033,
      "step": 33300
    },
    {
      "epoch": 13.447719014937425,
      "grad_norm": 0.0007307003252208233,
      "learning_rate": 6.552280985062575e-06,
      "loss": 0.0124,
      "step": 33310
    },
    {
      "epoch": 13.451756156641098,
      "grad_norm": 0.0005890858010388911,
      "learning_rate": 6.548243843358902e-06,
      "loss": 0.0002,
      "step": 33320
    },
    {
      "epoch": 13.455793298344773,
      "grad_norm": 1.3612748384475708,
      "learning_rate": 6.544206701655229e-06,
      "loss": 0.0069,
      "step": 33330
    },
    {
      "epoch": 13.459830440048446,
      "grad_norm": 0.0007584508857689798,
      "learning_rate": 6.540169559951555e-06,
      "loss": 0.0082,
      "step": 33340
    },
    {
      "epoch": 13.463867581752119,
      "grad_norm": 0.0007401319453492761,
      "learning_rate": 6.536132418247881e-06,
      "loss": 0.0068,
      "step": 33350
    },
    {
      "epoch": 13.467904723455794,
      "grad_norm": 1.8321641683578491,
      "learning_rate": 6.532095276544207e-06,
      "loss": 0.007,
      "step": 33360
    },
    {
      "epoch": 13.471941865159467,
      "grad_norm": 0.1816568523645401,
      "learning_rate": 6.528058134840534e-06,
      "loss": 0.0059,
      "step": 33370
    },
    {
      "epoch": 13.475979006863142,
      "grad_norm": 0.0005928006139583886,
      "learning_rate": 6.524020993136859e-06,
      "loss": 0.0017,
      "step": 33380
    },
    {
      "epoch": 13.480016148566815,
      "grad_norm": 0.01490875706076622,
      "learning_rate": 6.519983851433186e-06,
      "loss": 0.0,
      "step": 33390
    },
    {
      "epoch": 13.484053290270488,
      "grad_norm": 0.0011063192505389452,
      "learning_rate": 6.515946709729512e-06,
      "loss": 0.0063,
      "step": 33400
    },
    {
      "epoch": 13.488090431974163,
      "grad_norm": 0.0007321532466448843,
      "learning_rate": 6.511909568025838e-06,
      "loss": 0.0044,
      "step": 33410
    },
    {
      "epoch": 13.492127573677836,
      "grad_norm": 0.0010037750471383333,
      "learning_rate": 6.507872426322165e-06,
      "loss": 0.0138,
      "step": 33420
    },
    {
      "epoch": 13.49616471538151,
      "grad_norm": 0.0007417825981974602,
      "learning_rate": 6.503835284618491e-06,
      "loss": 0.0118,
      "step": 33430
    },
    {
      "epoch": 13.500201857085184,
      "grad_norm": 0.0005252835690043867,
      "learning_rate": 6.499798142914817e-06,
      "loss": 0.0135,
      "step": 33440
    },
    {
      "epoch": 13.504238998788857,
      "grad_norm": 0.0007071272120811045,
      "learning_rate": 6.4957610012111425e-06,
      "loss": 0.0079,
      "step": 33450
    },
    {
      "epoch": 13.508276140492532,
      "grad_norm": 0.0006149747059680521,
      "learning_rate": 6.49172385950747e-06,
      "loss": 0.0187,
      "step": 33460
    },
    {
      "epoch": 13.512313282196205,
      "grad_norm": 1.0944299697875977,
      "learning_rate": 6.487686717803795e-06,
      "loss": 0.0161,
      "step": 33470
    },
    {
      "epoch": 13.51635042389988,
      "grad_norm": 0.001280380878597498,
      "learning_rate": 6.483649576100121e-06,
      "loss": 0.0041,
      "step": 33480
    },
    {
      "epoch": 13.520387565603553,
      "grad_norm": 0.002079673809930682,
      "learning_rate": 6.4796124343964484e-06,
      "loss": 0.0194,
      "step": 33490
    },
    {
      "epoch": 13.524424707307226,
      "grad_norm": 0.001669671037234366,
      "learning_rate": 6.475575292692774e-06,
      "loss": 0.0158,
      "step": 33500
    },
    {
      "epoch": 13.5284618490109,
      "grad_norm": 0.0018990134121850133,
      "learning_rate": 6.471538150989101e-06,
      "loss": 0.0141,
      "step": 33510
    },
    {
      "epoch": 13.532498990714574,
      "grad_norm": 0.011138919740915298,
      "learning_rate": 6.4675010092854265e-06,
      "loss": 0.0004,
      "step": 33520
    },
    {
      "epoch": 13.536536132418249,
      "grad_norm": 1.6832910776138306,
      "learning_rate": 6.463463867581753e-06,
      "loss": 0.0069,
      "step": 33530
    },
    {
      "epoch": 13.540573274121922,
      "grad_norm": 0.0032880338840186596,
      "learning_rate": 6.459426725878078e-06,
      "loss": 0.0101,
      "step": 33540
    },
    {
      "epoch": 13.544610415825595,
      "grad_norm": 0.0004432111163623631,
      "learning_rate": 6.455389584174405e-06,
      "loss": 0.0169,
      "step": 33550
    },
    {
      "epoch": 13.54864755752927,
      "grad_norm": 0.011635330505669117,
      "learning_rate": 6.451352442470731e-06,
      "loss": 0.0,
      "step": 33560
    },
    {
      "epoch": 13.552684699232943,
      "grad_norm": 0.020322714000940323,
      "learning_rate": 6.447315300767057e-06,
      "loss": 0.0415,
      "step": 33570
    },
    {
      "epoch": 13.556721840936618,
      "grad_norm": 1.056934118270874,
      "learning_rate": 6.443278159063384e-06,
      "loss": 0.015,
      "step": 33580
    },
    {
      "epoch": 13.56075898264029,
      "grad_norm": 0.0011835834011435509,
      "learning_rate": 6.43924101735971e-06,
      "loss": 0.0018,
      "step": 33590
    },
    {
      "epoch": 13.564796124343964,
      "grad_norm": 1.0269616842269897,
      "learning_rate": 6.435203875656037e-06,
      "loss": 0.0157,
      "step": 33600
    },
    {
      "epoch": 13.568833266047639,
      "grad_norm": 0.0012498979922384024,
      "learning_rate": 6.431166733952362e-06,
      "loss": 0.0072,
      "step": 33610
    },
    {
      "epoch": 13.572870407751312,
      "grad_norm": 0.032206904143095016,
      "learning_rate": 6.4271295922486885e-06,
      "loss": 0.0009,
      "step": 33620
    },
    {
      "epoch": 13.576907549454987,
      "grad_norm": 1.6492111682891846,
      "learning_rate": 6.423092450545014e-06,
      "loss": 0.0165,
      "step": 33630
    },
    {
      "epoch": 13.58094469115866,
      "grad_norm": 0.002871893346309662,
      "learning_rate": 6.419055308841341e-06,
      "loss": 0.0065,
      "step": 33640
    },
    {
      "epoch": 13.584981832862333,
      "grad_norm": 1.1164406538009644,
      "learning_rate": 6.4150181671376665e-06,
      "loss": 0.0198,
      "step": 33650
    },
    {
      "epoch": 13.589018974566008,
      "grad_norm": 0.0015607301611453295,
      "learning_rate": 6.410981025433994e-06,
      "loss": 0.0189,
      "step": 33660
    },
    {
      "epoch": 13.59305611626968,
      "grad_norm": 0.0010870766127482057,
      "learning_rate": 6.40694388373032e-06,
      "loss": 0.0143,
      "step": 33670
    },
    {
      "epoch": 13.597093257973356,
      "grad_norm": 0.0005412267637439072,
      "learning_rate": 6.402906742026645e-06,
      "loss": 0.0035,
      "step": 33680
    },
    {
      "epoch": 13.601130399677029,
      "grad_norm": 1.061639428138733,
      "learning_rate": 6.3988696003229725e-06,
      "loss": 0.0159,
      "step": 33690
    },
    {
      "epoch": 13.605167541380702,
      "grad_norm": 1.0222209692001343,
      "learning_rate": 6.394832458619298e-06,
      "loss": 0.0077,
      "step": 33700
    },
    {
      "epoch": 13.609204683084377,
      "grad_norm": 1.0524811744689941,
      "learning_rate": 6.390795316915624e-06,
      "loss": 0.0368,
      "step": 33710
    },
    {
      "epoch": 13.61324182478805,
      "grad_norm": 0.0008457619696855545,
      "learning_rate": 6.38675817521195e-06,
      "loss": 0.0239,
      "step": 33720
    },
    {
      "epoch": 13.617278966491725,
      "grad_norm": 0.9937427639961243,
      "learning_rate": 6.382721033508277e-06,
      "loss": 0.0145,
      "step": 33730
    },
    {
      "epoch": 13.621316108195398,
      "grad_norm": 0.0009565503569319844,
      "learning_rate": 6.378683891804602e-06,
      "loss": 0.0111,
      "step": 33740
    },
    {
      "epoch": 13.62535324989907,
      "grad_norm": 1.6147366762161255,
      "learning_rate": 6.374646750100929e-06,
      "loss": 0.0099,
      "step": 33750
    },
    {
      "epoch": 13.629390391602746,
      "grad_norm": 0.056975070387125015,
      "learning_rate": 6.370609608397256e-06,
      "loss": 0.0135,
      "step": 33760
    },
    {
      "epoch": 13.633427533306419,
      "grad_norm": 0.011440273374319077,
      "learning_rate": 6.366572466693581e-06,
      "loss": 0.0254,
      "step": 33770
    },
    {
      "epoch": 13.637464675010094,
      "grad_norm": 1.3164401054382324,
      "learning_rate": 6.362535324989908e-06,
      "loss": 0.0162,
      "step": 33780
    },
    {
      "epoch": 13.641501816713767,
      "grad_norm": 0.12574319541454315,
      "learning_rate": 6.358498183286234e-06,
      "loss": 0.0188,
      "step": 33790
    },
    {
      "epoch": 13.64553895841744,
      "grad_norm": 2.9963483810424805,
      "learning_rate": 6.35446104158256e-06,
      "loss": 0.0872,
      "step": 33800
    },
    {
      "epoch": 13.649576100121115,
      "grad_norm": 1.2434968948364258,
      "learning_rate": 6.350423899878886e-06,
      "loss": 0.0172,
      "step": 33810
    },
    {
      "epoch": 13.653613241824788,
      "grad_norm": 0.07116449624300003,
      "learning_rate": 6.3463867581752125e-06,
      "loss": 0.014,
      "step": 33820
    },
    {
      "epoch": 13.657650383528463,
      "grad_norm": 1.5470707416534424,
      "learning_rate": 6.342349616471538e-06,
      "loss": 0.0234,
      "step": 33830
    },
    {
      "epoch": 13.661687525232136,
      "grad_norm": 1.4574044942855835,
      "learning_rate": 6.338312474767865e-06,
      "loss": 0.0088,
      "step": 33840
    },
    {
      "epoch": 13.665724666935809,
      "grad_norm": 0.0019059352343901992,
      "learning_rate": 6.334275333064191e-06,
      "loss": 0.0093,
      "step": 33850
    },
    {
      "epoch": 13.669761808639484,
      "grad_norm": 1.4189136028289795,
      "learning_rate": 6.330238191360517e-06,
      "loss": 0.0097,
      "step": 33860
    },
    {
      "epoch": 13.673798950343157,
      "grad_norm": 0.016151584684848785,
      "learning_rate": 6.326201049656844e-06,
      "loss": 0.0076,
      "step": 33870
    },
    {
      "epoch": 13.677836092046832,
      "grad_norm": 0.20761360228061676,
      "learning_rate": 6.322163907953169e-06,
      "loss": 0.0092,
      "step": 33880
    },
    {
      "epoch": 13.681873233750505,
      "grad_norm": 0.001063307747244835,
      "learning_rate": 6.318126766249496e-06,
      "loss": 0.0254,
      "step": 33890
    },
    {
      "epoch": 13.685910375454178,
      "grad_norm": 0.0017354968003928661,
      "learning_rate": 6.314089624545822e-06,
      "loss": 0.0106,
      "step": 33900
    },
    {
      "epoch": 13.689947517157853,
      "grad_norm": 0.0013125994009897113,
      "learning_rate": 6.310052482842148e-06,
      "loss": 0.0112,
      "step": 33910
    },
    {
      "epoch": 13.693984658861526,
      "grad_norm": 0.0015457018744200468,
      "learning_rate": 6.306015341138475e-06,
      "loss": 0.0091,
      "step": 33920
    },
    {
      "epoch": 13.6980218005652,
      "grad_norm": 0.0009609421831555665,
      "learning_rate": 6.301978199434801e-06,
      "loss": 0.0315,
      "step": 33930
    },
    {
      "epoch": 13.702058942268874,
      "grad_norm": 0.001159185660071671,
      "learning_rate": 6.297941057731127e-06,
      "loss": 0.018,
      "step": 33940
    },
    {
      "epoch": 13.706096083972547,
      "grad_norm": 0.0008938857936300337,
      "learning_rate": 6.2939039160274526e-06,
      "loss": 0.0168,
      "step": 33950
    },
    {
      "epoch": 13.710133225676222,
      "grad_norm": 0.0009397072717547417,
      "learning_rate": 6.28986677432378e-06,
      "loss": 0.0137,
      "step": 33960
    },
    {
      "epoch": 13.714170367379895,
      "grad_norm": 0.0012470033252611756,
      "learning_rate": 6.285829632620105e-06,
      "loss": 0.0076,
      "step": 33970
    },
    {
      "epoch": 13.71820750908357,
      "grad_norm": 1.7383671998977661,
      "learning_rate": 6.2817924909164314e-06,
      "loss": 0.0285,
      "step": 33980
    },
    {
      "epoch": 13.722244650787243,
      "grad_norm": 0.0023027826100587845,
      "learning_rate": 6.277755349212758e-06,
      "loss": 0.0052,
      "step": 33990
    },
    {
      "epoch": 13.726281792490916,
      "grad_norm": 1.742753028869629,
      "learning_rate": 6.273718207509084e-06,
      "loss": 0.0231,
      "step": 34000
    },
    {
      "epoch": 13.73031893419459,
      "grad_norm": 0.0006592288264073431,
      "learning_rate": 6.269681065805411e-06,
      "loss": 0.0413,
      "step": 34010
    },
    {
      "epoch": 13.734356075898264,
      "grad_norm": 0.002663572086021304,
      "learning_rate": 6.2656439241017366e-06,
      "loss": 0.0084,
      "step": 34020
    },
    {
      "epoch": 13.738393217601939,
      "grad_norm": 1.441625952720642,
      "learning_rate": 6.261606782398063e-06,
      "loss": 0.0082,
      "step": 34030
    },
    {
      "epoch": 13.742430359305612,
      "grad_norm": 0.006092410068958998,
      "learning_rate": 6.257569640694388e-06,
      "loss": 0.0084,
      "step": 34040
    },
    {
      "epoch": 13.746467501009285,
      "grad_norm": 0.018314342945814133,
      "learning_rate": 6.2535324989907154e-06,
      "loss": 0.0054,
      "step": 34050
    },
    {
      "epoch": 13.75050464271296,
      "grad_norm": 0.0028966176323592663,
      "learning_rate": 6.249495357287041e-06,
      "loss": 0.0069,
      "step": 34060
    },
    {
      "epoch": 13.754541784416633,
      "grad_norm": 2.3193416595458984,
      "learning_rate": 6.245458215583368e-06,
      "loss": 0.0115,
      "step": 34070
    },
    {
      "epoch": 13.758578926120308,
      "grad_norm": 1.6669937372207642,
      "learning_rate": 6.2414210738796934e-06,
      "loss": 0.0165,
      "step": 34080
    },
    {
      "epoch": 13.76261606782398,
      "grad_norm": 0.001065927790477872,
      "learning_rate": 6.23738393217602e-06,
      "loss": 0.0301,
      "step": 34090
    },
    {
      "epoch": 13.766653209527654,
      "grad_norm": 0.05776865780353546,
      "learning_rate": 6.233346790472347e-06,
      "loss": 0.006,
      "step": 34100
    },
    {
      "epoch": 13.770690351231329,
      "grad_norm": 0.0009362309938296676,
      "learning_rate": 6.229309648768672e-06,
      "loss": 0.003,
      "step": 34110
    },
    {
      "epoch": 13.774727492935002,
      "grad_norm": 0.21377423405647278,
      "learning_rate": 6.225272507064999e-06,
      "loss": 0.0052,
      "step": 34120
    },
    {
      "epoch": 13.778764634638677,
      "grad_norm": 0.0010183897102251649,
      "learning_rate": 6.221235365361324e-06,
      "loss": 0.0105,
      "step": 34130
    },
    {
      "epoch": 13.78280177634235,
      "grad_norm": 0.0005062518175691366,
      "learning_rate": 6.217198223657651e-06,
      "loss": 0.0071,
      "step": 34140
    },
    {
      "epoch": 13.786838918046023,
      "grad_norm": 0.0006914194673299789,
      "learning_rate": 6.213161081953977e-06,
      "loss": 0.0077,
      "step": 34150
    },
    {
      "epoch": 13.790876059749698,
      "grad_norm": 1.7289973497390747,
      "learning_rate": 6.209123940250304e-06,
      "loss": 0.0104,
      "step": 34160
    },
    {
      "epoch": 13.79491320145337,
      "grad_norm": 0.00288559403270483,
      "learning_rate": 6.205086798546629e-06,
      "loss": 0.0142,
      "step": 34170
    },
    {
      "epoch": 13.798950343157045,
      "grad_norm": 0.0010567409917712212,
      "learning_rate": 6.2010496568429555e-06,
      "loss": 0.0019,
      "step": 34180
    },
    {
      "epoch": 13.802987484860719,
      "grad_norm": 0.0013946054968982935,
      "learning_rate": 6.197012515139283e-06,
      "loss": 0.0141,
      "step": 34190
    },
    {
      "epoch": 13.807024626564392,
      "grad_norm": 0.0009076852002181113,
      "learning_rate": 6.192975373435608e-06,
      "loss": 0.0163,
      "step": 34200
    },
    {
      "epoch": 13.811061768268067,
      "grad_norm": 0.015751268714666367,
      "learning_rate": 6.188938231731934e-06,
      "loss": 0.02,
      "step": 34210
    },
    {
      "epoch": 13.81509890997174,
      "grad_norm": 0.0006655077449977398,
      "learning_rate": 6.184901090028261e-06,
      "loss": 0.0109,
      "step": 34220
    },
    {
      "epoch": 13.819136051675414,
      "grad_norm": 0.0005622233147732913,
      "learning_rate": 6.180863948324587e-06,
      "loss": 0.0055,
      "step": 34230
    },
    {
      "epoch": 13.823173193379088,
      "grad_norm": 0.8126783967018127,
      "learning_rate": 6.176826806620912e-06,
      "loss": 0.0021,
      "step": 34240
    },
    {
      "epoch": 13.82721033508276,
      "grad_norm": 1.9219530820846558,
      "learning_rate": 6.1727896649172395e-06,
      "loss": 0.0041,
      "step": 34250
    },
    {
      "epoch": 13.831247476786436,
      "grad_norm": 0.007288267370313406,
      "learning_rate": 6.168752523213565e-06,
      "loss": 0.015,
      "step": 34260
    },
    {
      "epoch": 13.835284618490109,
      "grad_norm": 0.0004312609089538455,
      "learning_rate": 6.164715381509891e-06,
      "loss": 0.008,
      "step": 34270
    },
    {
      "epoch": 13.839321760193783,
      "grad_norm": 0.0006332938210107386,
      "learning_rate": 6.160678239806218e-06,
      "loss": 0.0157,
      "step": 34280
    },
    {
      "epoch": 13.843358901897457,
      "grad_norm": 0.0445525087416172,
      "learning_rate": 6.156641098102544e-06,
      "loss": 0.0206,
      "step": 34290
    },
    {
      "epoch": 13.84739604360113,
      "grad_norm": 0.005705888848751783,
      "learning_rate": 6.15260395639887e-06,
      "loss": 0.0304,
      "step": 34300
    },
    {
      "epoch": 13.851433185304804,
      "grad_norm": 0.0016851350665092468,
      "learning_rate": 6.148566814695196e-06,
      "loss": 0.0004,
      "step": 34310
    },
    {
      "epoch": 13.855470327008478,
      "grad_norm": 0.0006924726185388863,
      "learning_rate": 6.144529672991523e-06,
      "loss": 0.0079,
      "step": 34320
    },
    {
      "epoch": 13.859507468712152,
      "grad_norm": 0.0007410336984321475,
      "learning_rate": 6.140492531287848e-06,
      "loss": 0.0125,
      "step": 34330
    },
    {
      "epoch": 13.863544610415826,
      "grad_norm": 1.5731525421142578,
      "learning_rate": 6.136455389584175e-06,
      "loss": 0.0194,
      "step": 34340
    },
    {
      "epoch": 13.867581752119499,
      "grad_norm": 0.002522297902032733,
      "learning_rate": 6.132418247880501e-06,
      "loss": 0.0021,
      "step": 34350
    },
    {
      "epoch": 13.871618893823173,
      "grad_norm": 0.19134439527988434,
      "learning_rate": 6.128381106176827e-06,
      "loss": 0.0023,
      "step": 34360
    },
    {
      "epoch": 13.875656035526847,
      "grad_norm": 1.339978814125061,
      "learning_rate": 6.124343964473154e-06,
      "loss": 0.0117,
      "step": 34370
    },
    {
      "epoch": 13.879693177230521,
      "grad_norm": 0.0007897521136328578,
      "learning_rate": 6.1203068227694795e-06,
      "loss": 0.0079,
      "step": 34380
    },
    {
      "epoch": 13.883730318934195,
      "grad_norm": 0.0005200788145884871,
      "learning_rate": 6.116269681065806e-06,
      "loss": 0.0111,
      "step": 34390
    },
    {
      "epoch": 13.887767460637868,
      "grad_norm": 0.0014332541031762958,
      "learning_rate": 6.112232539362132e-06,
      "loss": 0.0147,
      "step": 34400
    },
    {
      "epoch": 13.891804602341542,
      "grad_norm": 0.0004744605685118586,
      "learning_rate": 6.108195397658458e-06,
      "loss": 0.0035,
      "step": 34410
    },
    {
      "epoch": 13.895841744045216,
      "grad_norm": 1.1922575235366821,
      "learning_rate": 6.104158255954784e-06,
      "loss": 0.0137,
      "step": 34420
    },
    {
      "epoch": 13.89987888574889,
      "grad_norm": 0.0005107462638989091,
      "learning_rate": 6.100121114251111e-06,
      "loss": 0.0104,
      "step": 34430
    },
    {
      "epoch": 13.903916027452563,
      "grad_norm": 1.2934226989746094,
      "learning_rate": 6.096083972547437e-06,
      "loss": 0.0124,
      "step": 34440
    },
    {
      "epoch": 13.907953169156237,
      "grad_norm": 0.00050751818343997,
      "learning_rate": 6.092046830843763e-06,
      "loss": 0.0061,
      "step": 34450
    },
    {
      "epoch": 13.911990310859911,
      "grad_norm": 1.2385512590408325,
      "learning_rate": 6.08800968914009e-06,
      "loss": 0.0101,
      "step": 34460
    },
    {
      "epoch": 13.916027452563585,
      "grad_norm": 1.044793963432312,
      "learning_rate": 6.083972547436415e-06,
      "loss": 0.0064,
      "step": 34470
    },
    {
      "epoch": 13.92006459426726,
      "grad_norm": 1.4571106433868408,
      "learning_rate": 6.079935405732742e-06,
      "loss": 0.0125,
      "step": 34480
    },
    {
      "epoch": 13.924101735970932,
      "grad_norm": 0.0028661347460001707,
      "learning_rate": 6.075898264029068e-06,
      "loss": 0.0024,
      "step": 34490
    },
    {
      "epoch": 13.928138877674606,
      "grad_norm": 0.00027618734748102725,
      "learning_rate": 6.071861122325394e-06,
      "loss": 0.0001,
      "step": 34500
    },
    {
      "epoch": 13.93217601937828,
      "grad_norm": 0.00043498422019183636,
      "learning_rate": 6.0678239806217195e-06,
      "loss": 0.0265,
      "step": 34510
    },
    {
      "epoch": 13.936213161081954,
      "grad_norm": 0.00481046549975872,
      "learning_rate": 6.063786838918047e-06,
      "loss": 0.0119,
      "step": 34520
    },
    {
      "epoch": 13.940250302785628,
      "grad_norm": 0.0005042437696829438,
      "learning_rate": 6.059749697214373e-06,
      "loss": 0.0058,
      "step": 34530
    },
    {
      "epoch": 13.944287444489301,
      "grad_norm": 0.0008925346774049103,
      "learning_rate": 6.055712555510698e-06,
      "loss": 0.0037,
      "step": 34540
    },
    {
      "epoch": 13.948324586192975,
      "grad_norm": 0.0009563505300320685,
      "learning_rate": 6.0516754138070255e-06,
      "loss": 0.0106,
      "step": 34550
    },
    {
      "epoch": 13.95236172789665,
      "grad_norm": 1.4900758266448975,
      "learning_rate": 6.047638272103351e-06,
      "loss": 0.0175,
      "step": 34560
    },
    {
      "epoch": 13.956398869600322,
      "grad_norm": 0.0007655696826986969,
      "learning_rate": 6.043601130399678e-06,
      "loss": 0.0121,
      "step": 34570
    },
    {
      "epoch": 13.960436011303997,
      "grad_norm": 0.004311167169362307,
      "learning_rate": 6.0395639886960036e-06,
      "loss": 0.0041,
      "step": 34580
    },
    {
      "epoch": 13.96447315300767,
      "grad_norm": 0.00022551453730557114,
      "learning_rate": 6.03552684699233e-06,
      "loss": 0.0088,
      "step": 34590
    },
    {
      "epoch": 13.968510294711344,
      "grad_norm": 0.0003846243489533663,
      "learning_rate": 6.031489705288655e-06,
      "loss": 0.0294,
      "step": 34600
    },
    {
      "epoch": 13.972547436415018,
      "grad_norm": 66.39534759521484,
      "learning_rate": 6.027452563584982e-06,
      "loss": 0.0265,
      "step": 34610
    },
    {
      "epoch": 13.976584578118691,
      "grad_norm": 0.0004985401756130159,
      "learning_rate": 6.023415421881309e-06,
      "loss": 0.0,
      "step": 34620
    },
    {
      "epoch": 13.980621719822366,
      "grad_norm": 0.0004445460217539221,
      "learning_rate": 6.019378280177635e-06,
      "loss": 0.0098,
      "step": 34630
    },
    {
      "epoch": 13.98465886152604,
      "grad_norm": 0.8915378451347351,
      "learning_rate": 6.015341138473961e-06,
      "loss": 0.0042,
      "step": 34640
    },
    {
      "epoch": 13.988696003229713,
      "grad_norm": 0.4390126168727875,
      "learning_rate": 6.011303996770287e-06,
      "loss": 0.0044,
      "step": 34650
    },
    {
      "epoch": 13.992733144933387,
      "grad_norm": 0.0011000302620232105,
      "learning_rate": 6.007266855066614e-06,
      "loss": 0.0098,
      "step": 34660
    },
    {
      "epoch": 13.99677028663706,
      "grad_norm": 0.0006659498903900385,
      "learning_rate": 6.003229713362939e-06,
      "loss": 0.0048,
      "step": 34670
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.9861635220125786,
      "eval_f1": 0.948985507246377,
      "eval_loss": 0.06739737838506699,
      "eval_precision": 0.9573099415204679,
      "eval_recall": 0.9408045977011494,
      "eval_runtime": 444.2283,
      "eval_samples_per_second": 28.679,
      "eval_steps_per_second": 1.195,
      "step": 34678
    }
  ],
  "logging_steps": 10,
  "max_steps": 49540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.274981834369869e+17,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
