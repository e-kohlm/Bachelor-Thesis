{
  "best_metric": 0.9640479360852197,
  "best_model_checkpoint": "../saved_models/xss_optim_model/checkpoint-3419",
  "epoch": 16.999378495960222,
  "eval_steps": 500,
  "global_step": 3419,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004972032318210068,
      "grad_norm": 31.808246612548828,
      "learning_rate": 6.338028169014085e-08,
      "loss": 0.9627,
      "step": 1
    },
    {
      "epoch": 0.049720323182100686,
      "grad_norm": 30.47230339050293,
      "learning_rate": 6.338028169014085e-07,
      "loss": 0.9932,
      "step": 10
    },
    {
      "epoch": 0.09944064636420137,
      "grad_norm": 63.506019592285156,
      "learning_rate": 1.267605633802817e-06,
      "loss": 0.8341,
      "step": 20
    },
    {
      "epoch": 0.14916096954630206,
      "grad_norm": 34.43156051635742,
      "learning_rate": 1.9014084507042254e-06,
      "loss": 0.5832,
      "step": 30
    },
    {
      "epoch": 0.19888129272840274,
      "grad_norm": 11.448445320129395,
      "learning_rate": 2.535211267605634e-06,
      "loss": 0.3901,
      "step": 40
    },
    {
      "epoch": 0.24860161591050342,
      "grad_norm": 7.8840718269348145,
      "learning_rate": 3.1690140845070423e-06,
      "loss": 0.3441,
      "step": 50
    },
    {
      "epoch": 0.2983219390926041,
      "grad_norm": 8.449873924255371,
      "learning_rate": 3.8028169014084508e-06,
      "loss": 0.3334,
      "step": 60
    },
    {
      "epoch": 0.3480422622747048,
      "grad_norm": 7.201341152191162,
      "learning_rate": 4.43661971830986e-06,
      "loss": 0.3503,
      "step": 70
    },
    {
      "epoch": 0.3977625854568055,
      "grad_norm": 10.978935241699219,
      "learning_rate": 5.070422535211268e-06,
      "loss": 0.3288,
      "step": 80
    },
    {
      "epoch": 0.44748290863890616,
      "grad_norm": 142.34934997558594,
      "learning_rate": 5.7042253521126766e-06,
      "loss": 0.3304,
      "step": 90
    },
    {
      "epoch": 0.49720323182100684,
      "grad_norm": 6.268683910369873,
      "learning_rate": 6.338028169014085e-06,
      "loss": 0.3193,
      "step": 100
    },
    {
      "epoch": 0.5469235550031075,
      "grad_norm": 8.012531280517578,
      "learning_rate": 6.971830985915493e-06,
      "loss": 0.2813,
      "step": 110
    },
    {
      "epoch": 0.5966438781852083,
      "grad_norm": 9.285627365112305,
      "learning_rate": 7.6056338028169015e-06,
      "loss": 0.2822,
      "step": 120
    },
    {
      "epoch": 0.6463642013673089,
      "grad_norm": 9.859875679016113,
      "learning_rate": 8.23943661971831e-06,
      "loss": 0.2704,
      "step": 130
    },
    {
      "epoch": 0.6960845245494096,
      "grad_norm": 12.073461532592773,
      "learning_rate": 8.87323943661972e-06,
      "loss": 0.2736,
      "step": 140
    },
    {
      "epoch": 0.7458048477315102,
      "grad_norm": 12.539349555969238,
      "learning_rate": 9.507042253521126e-06,
      "loss": 0.2707,
      "step": 150
    },
    {
      "epoch": 0.795525170913611,
      "grad_norm": 6.094889163970947,
      "learning_rate": 1.0140845070422535e-05,
      "loss": 0.2752,
      "step": 160
    },
    {
      "epoch": 0.8452454940957116,
      "grad_norm": 6.510918617248535,
      "learning_rate": 1.0774647887323943e-05,
      "loss": 0.2377,
      "step": 170
    },
    {
      "epoch": 0.8949658172778123,
      "grad_norm": 7.901252746582031,
      "learning_rate": 1.1408450704225353e-05,
      "loss": 0.2771,
      "step": 180
    },
    {
      "epoch": 0.944686140459913,
      "grad_norm": 22.47471046447754,
      "learning_rate": 1.2042253521126761e-05,
      "loss": 0.216,
      "step": 190
    },
    {
      "epoch": 0.9944064636420137,
      "grad_norm": 4.677630424499512,
      "learning_rate": 1.267605633802817e-05,
      "loss": 0.2228,
      "step": 200
    },
    {
      "epoch": 0.9993784959602238,
      "eval_accuracy": 0.9216327519379846,
      "eval_f1": 0.4269264836138175,
      "eval_loss": 0.2183496356010437,
      "eval_precision": 0.6443850267379679,
      "eval_recall": 0.31920529801324504,
      "eval_runtime": 152.2738,
      "eval_samples_per_second": 54.356,
      "eval_steps_per_second": 2.266,
      "step": 201
    },
    {
      "epoch": 1.0441267868241144,
      "grad_norm": 6.669588565826416,
      "learning_rate": 1.3309859154929577e-05,
      "loss": 0.2207,
      "step": 210
    },
    {
      "epoch": 1.093847110006215,
      "grad_norm": 7.107614517211914,
      "learning_rate": 1.3943661971830985e-05,
      "loss": 0.211,
      "step": 220
    },
    {
      "epoch": 1.1435674331883157,
      "grad_norm": 4.725609302520752,
      "learning_rate": 1.4577464788732395e-05,
      "loss": 0.1949,
      "step": 230
    },
    {
      "epoch": 1.1932877563704163,
      "grad_norm": 5.000751495361328,
      "learning_rate": 1.5211267605633803e-05,
      "loss": 0.1655,
      "step": 240
    },
    {
      "epoch": 1.2430080795525171,
      "grad_norm": 18.5136775970459,
      "learning_rate": 1.5845070422535213e-05,
      "loss": 0.2173,
      "step": 250
    },
    {
      "epoch": 1.2927284027346178,
      "grad_norm": 4.860351085662842,
      "learning_rate": 1.647887323943662e-05,
      "loss": 0.1909,
      "step": 260
    },
    {
      "epoch": 1.3424487259167184,
      "grad_norm": 4.1791558265686035,
      "learning_rate": 1.711267605633803e-05,
      "loss": 0.1669,
      "step": 270
    },
    {
      "epoch": 1.3921690490988192,
      "grad_norm": 3.7489523887634277,
      "learning_rate": 1.774647887323944e-05,
      "loss": 0.1644,
      "step": 280
    },
    {
      "epoch": 1.4418893722809198,
      "grad_norm": 3.743624448776245,
      "learning_rate": 1.7981839582983017e-05,
      "loss": 0.1625,
      "step": 290
    },
    {
      "epoch": 1.4916096954630205,
      "grad_norm": 4.987804412841797,
      "learning_rate": 1.7951572221288045e-05,
      "loss": 0.1726,
      "step": 300
    },
    {
      "epoch": 1.5413300186451213,
      "grad_norm": 4.702805519104004,
      "learning_rate": 1.7921304859593072e-05,
      "loss": 0.1489,
      "step": 310
    },
    {
      "epoch": 1.5910503418272217,
      "grad_norm": 2.1810476779937744,
      "learning_rate": 1.78910374978981e-05,
      "loss": 0.1191,
      "step": 320
    },
    {
      "epoch": 1.6407706650093226,
      "grad_norm": 3.393953800201416,
      "learning_rate": 1.786077013620313e-05,
      "loss": 0.1186,
      "step": 330
    },
    {
      "epoch": 1.6904909881914234,
      "grad_norm": 2.6269466876983643,
      "learning_rate": 1.7830502774508157e-05,
      "loss": 0.1266,
      "step": 340
    },
    {
      "epoch": 1.7402113113735238,
      "grad_norm": 2.8925251960754395,
      "learning_rate": 1.7800235412813184e-05,
      "loss": 0.1248,
      "step": 350
    },
    {
      "epoch": 1.7899316345556247,
      "grad_norm": 4.222083568572998,
      "learning_rate": 1.776996805111821e-05,
      "loss": 0.1057,
      "step": 360
    },
    {
      "epoch": 1.8396519577377253,
      "grad_norm": 3.3983092308044434,
      "learning_rate": 1.773970068942324e-05,
      "loss": 0.1089,
      "step": 370
    },
    {
      "epoch": 1.889372280919826,
      "grad_norm": 2.870786428451538,
      "learning_rate": 1.7709433327728266e-05,
      "loss": 0.0895,
      "step": 380
    },
    {
      "epoch": 1.9390926041019267,
      "grad_norm": 3.7257378101348877,
      "learning_rate": 1.7679165966033293e-05,
      "loss": 0.095,
      "step": 390
    },
    {
      "epoch": 1.9888129272840274,
      "grad_norm": 3.28300142288208,
      "learning_rate": 1.7648898604338324e-05,
      "loss": 0.098,
      "step": 400
    },
    {
      "epoch": 1.9987569919204475,
      "eval_accuracy": 0.9705668604651163,
      "eval_f1": 0.8117738187451589,
      "eval_loss": 0.07950849086046219,
      "eval_precision": 0.9776119402985075,
      "eval_recall": 0.6940397350993377,
      "eval_runtime": 163.4518,
      "eval_samples_per_second": 50.639,
      "eval_steps_per_second": 2.111,
      "step": 402
    },
    {
      "epoch": 2.038533250466128,
      "grad_norm": 2.8785014152526855,
      "learning_rate": 1.761863124264335e-05,
      "loss": 0.089,
      "step": 410
    },
    {
      "epoch": 2.088253573648229,
      "grad_norm": 3.2790091037750244,
      "learning_rate": 1.7588363880948378e-05,
      "loss": 0.0636,
      "step": 420
    },
    {
      "epoch": 2.1379738968303292,
      "grad_norm": 3.718918800354004,
      "learning_rate": 1.7558096519253405e-05,
      "loss": 0.068,
      "step": 430
    },
    {
      "epoch": 2.18769422001243,
      "grad_norm": 2.728140115737915,
      "learning_rate": 1.7527829157558433e-05,
      "loss": 0.0692,
      "step": 440
    },
    {
      "epoch": 2.237414543194531,
      "grad_norm": 2.951847791671753,
      "learning_rate": 1.749756179586346e-05,
      "loss": 0.0672,
      "step": 450
    },
    {
      "epoch": 2.2871348663766313,
      "grad_norm": 1.969802737236023,
      "learning_rate": 1.7467294434168487e-05,
      "loss": 0.0613,
      "step": 460
    },
    {
      "epoch": 2.336855189558732,
      "grad_norm": 3.321913480758667,
      "learning_rate": 1.7437027072473518e-05,
      "loss": 0.0697,
      "step": 470
    },
    {
      "epoch": 2.3865755127408326,
      "grad_norm": 2.2364025115966797,
      "learning_rate": 1.7406759710778545e-05,
      "loss": 0.0577,
      "step": 480
    },
    {
      "epoch": 2.4362958359229334,
      "grad_norm": 2.351309061050415,
      "learning_rate": 1.7376492349083572e-05,
      "loss": 0.0434,
      "step": 490
    },
    {
      "epoch": 2.4860161591050343,
      "grad_norm": 2.0121991634368896,
      "learning_rate": 1.73462249873886e-05,
      "loss": 0.0487,
      "step": 500
    },
    {
      "epoch": 2.5357364822871347,
      "grad_norm": 3.669743776321411,
      "learning_rate": 1.7315957625693627e-05,
      "loss": 0.0775,
      "step": 510
    },
    {
      "epoch": 2.5854568054692355,
      "grad_norm": 0.8329832553863525,
      "learning_rate": 1.7285690263998657e-05,
      "loss": 0.0463,
      "step": 520
    },
    {
      "epoch": 2.6351771286513364,
      "grad_norm": 1.152266502380371,
      "learning_rate": 1.725542290230368e-05,
      "loss": 0.0402,
      "step": 530
    },
    {
      "epoch": 2.6848974518334368,
      "grad_norm": 2.433105230331421,
      "learning_rate": 1.722515554060871e-05,
      "loss": 0.0446,
      "step": 540
    },
    {
      "epoch": 2.7346177750155376,
      "grad_norm": 2.6330246925354004,
      "learning_rate": 1.719488817891374e-05,
      "loss": 0.0414,
      "step": 550
    },
    {
      "epoch": 2.7843380981976384,
      "grad_norm": 3.918315887451172,
      "learning_rate": 1.7164620817218766e-05,
      "loss": 0.047,
      "step": 560
    },
    {
      "epoch": 2.834058421379739,
      "grad_norm": 2.000295877456665,
      "learning_rate": 1.7134353455523793e-05,
      "loss": 0.0603,
      "step": 570
    },
    {
      "epoch": 2.8837787445618397,
      "grad_norm": 3.4282240867614746,
      "learning_rate": 1.710408609382882e-05,
      "loss": 0.0463,
      "step": 580
    },
    {
      "epoch": 2.9334990677439405,
      "grad_norm": 2.7329752445220947,
      "learning_rate": 1.707381873213385e-05,
      "loss": 0.0462,
      "step": 590
    },
    {
      "epoch": 2.983219390926041,
      "grad_norm": 5.8620123863220215,
      "learning_rate": 1.704355137043888e-05,
      "loss": 0.0454,
      "step": 600
    },
    {
      "epoch": 2.9981354878806714,
      "eval_accuracy": 0.9806201550387597,
      "eval_f1": 0.8848920863309353,
      "eval_loss": 0.062553271651268,
      "eval_precision": 0.968503937007874,
      "eval_recall": 0.8145695364238411,
      "eval_runtime": 162.416,
      "eval_samples_per_second": 50.962,
      "eval_steps_per_second": 2.124,
      "step": 603
    },
    {
      "epoch": 3.032939714108142,
      "grad_norm": 4.827388763427734,
      "learning_rate": 1.7013284008743906e-05,
      "loss": 0.0483,
      "step": 610
    },
    {
      "epoch": 3.082660037290242,
      "grad_norm": 2.492973566055298,
      "learning_rate": 1.6983016647048933e-05,
      "loss": 0.039,
      "step": 620
    },
    {
      "epoch": 3.132380360472343,
      "grad_norm": 2.9225215911865234,
      "learning_rate": 1.695274928535396e-05,
      "loss": 0.0178,
      "step": 630
    },
    {
      "epoch": 3.182100683654444,
      "grad_norm": 3.62530255317688,
      "learning_rate": 1.6922481923658987e-05,
      "loss": 0.0379,
      "step": 640
    },
    {
      "epoch": 3.2318210068365443,
      "grad_norm": 2.8834023475646973,
      "learning_rate": 1.6892214561964015e-05,
      "loss": 0.0204,
      "step": 650
    },
    {
      "epoch": 3.281541330018645,
      "grad_norm": 3.416412830352783,
      "learning_rate": 1.6861947200269045e-05,
      "loss": 0.0364,
      "step": 660
    },
    {
      "epoch": 3.331261653200746,
      "grad_norm": 1.4497843980789185,
      "learning_rate": 1.6831679838574072e-05,
      "loss": 0.0254,
      "step": 670
    },
    {
      "epoch": 3.3809819763828464,
      "grad_norm": 5.840702533721924,
      "learning_rate": 1.68014124768791e-05,
      "loss": 0.048,
      "step": 680
    },
    {
      "epoch": 3.430702299564947,
      "grad_norm": 2.3216605186462402,
      "learning_rate": 1.6771145115184127e-05,
      "loss": 0.0363,
      "step": 690
    },
    {
      "epoch": 3.4804226227470476,
      "grad_norm": 2.4493408203125,
      "learning_rate": 1.6740877753489154e-05,
      "loss": 0.0328,
      "step": 700
    },
    {
      "epoch": 3.5301429459291485,
      "grad_norm": 2.426752805709839,
      "learning_rate": 1.671061039179418e-05,
      "loss": 0.0413,
      "step": 710
    },
    {
      "epoch": 3.5798632691112493,
      "grad_norm": 1.0268430709838867,
      "learning_rate": 1.668034303009921e-05,
      "loss": 0.028,
      "step": 720
    },
    {
      "epoch": 3.6295835922933497,
      "grad_norm": 1.2019652128219604,
      "learning_rate": 1.665007566840424e-05,
      "loss": 0.0311,
      "step": 730
    },
    {
      "epoch": 3.6793039154754505,
      "grad_norm": 2.6180636882781982,
      "learning_rate": 1.6619808306709266e-05,
      "loss": 0.0355,
      "step": 740
    },
    {
      "epoch": 3.7290242386575514,
      "grad_norm": 3.883972406387329,
      "learning_rate": 1.6589540945014294e-05,
      "loss": 0.0275,
      "step": 750
    },
    {
      "epoch": 3.778744561839652,
      "grad_norm": 0.7908416390419006,
      "learning_rate": 1.655927358331932e-05,
      "loss": 0.0281,
      "step": 760
    },
    {
      "epoch": 3.8284648850217526,
      "grad_norm": 2.2821648120880127,
      "learning_rate": 1.6529006221624348e-05,
      "loss": 0.0251,
      "step": 770
    },
    {
      "epoch": 3.8781852082038535,
      "grad_norm": 1.040973424911499,
      "learning_rate": 1.6498738859929375e-05,
      "loss": 0.0296,
      "step": 780
    },
    {
      "epoch": 3.927905531385954,
      "grad_norm": 1.460119366645813,
      "learning_rate": 1.6468471498234403e-05,
      "loss": 0.0303,
      "step": 790
    },
    {
      "epoch": 3.9776258545680547,
      "grad_norm": 2.8493845462799072,
      "learning_rate": 1.6438204136539433e-05,
      "loss": 0.0443,
      "step": 800
    },
    {
      "epoch": 3.997513983840895,
      "eval_accuracy": 0.9901889534883721,
      "eval_f1": 0.9463931171409663,
      "eval_loss": 0.02780325338244438,
      "eval_precision": 0.9457671957671958,
      "eval_recall": 0.9470198675496688,
      "eval_runtime": 154.777,
      "eval_samples_per_second": 53.477,
      "eval_steps_per_second": 2.229,
      "step": 804
    },
    {
      "epoch": 4.027346177750156,
      "grad_norm": 1.596673846244812,
      "learning_rate": 1.640793677484446e-05,
      "loss": 0.0194,
      "step": 810
    },
    {
      "epoch": 4.077066500932256,
      "grad_norm": 1.4959408044815063,
      "learning_rate": 1.6377669413149488e-05,
      "loss": 0.0174,
      "step": 820
    },
    {
      "epoch": 4.126786824114356,
      "grad_norm": 1.1649588346481323,
      "learning_rate": 1.6347402051454515e-05,
      "loss": 0.0218,
      "step": 830
    },
    {
      "epoch": 4.176507147296458,
      "grad_norm": 1.7748942375183105,
      "learning_rate": 1.6317134689759542e-05,
      "loss": 0.0229,
      "step": 840
    },
    {
      "epoch": 4.226227470478558,
      "grad_norm": 2.237515687942505,
      "learning_rate": 1.6286867328064573e-05,
      "loss": 0.0241,
      "step": 850
    },
    {
      "epoch": 4.2759477936606585,
      "grad_norm": 1.57949697971344,
      "learning_rate": 1.62565999663696e-05,
      "loss": 0.0157,
      "step": 860
    },
    {
      "epoch": 4.32566811684276,
      "grad_norm": 1.8600021600723267,
      "learning_rate": 1.6226332604674627e-05,
      "loss": 0.0258,
      "step": 870
    },
    {
      "epoch": 4.37538844002486,
      "grad_norm": 0.6309171319007874,
      "learning_rate": 1.6196065242979654e-05,
      "loss": 0.0403,
      "step": 880
    },
    {
      "epoch": 4.425108763206961,
      "grad_norm": 1.9713830947875977,
      "learning_rate": 1.616579788128468e-05,
      "loss": 0.0208,
      "step": 890
    },
    {
      "epoch": 4.474829086389062,
      "grad_norm": 1.7465195655822754,
      "learning_rate": 1.613553051958971e-05,
      "loss": 0.0248,
      "step": 900
    },
    {
      "epoch": 4.524549409571162,
      "grad_norm": 2.2781426906585693,
      "learning_rate": 1.6105263157894736e-05,
      "loss": 0.0187,
      "step": 910
    },
    {
      "epoch": 4.574269732753263,
      "grad_norm": 1.369356632232666,
      "learning_rate": 1.6074995796199767e-05,
      "loss": 0.0208,
      "step": 920
    },
    {
      "epoch": 4.623990055935364,
      "grad_norm": 1.4254816770553589,
      "learning_rate": 1.6044728434504794e-05,
      "loss": 0.022,
      "step": 930
    },
    {
      "epoch": 4.673710379117464,
      "grad_norm": 1.9632740020751953,
      "learning_rate": 1.601446107280982e-05,
      "loss": 0.0209,
      "step": 940
    },
    {
      "epoch": 4.723430702299565,
      "grad_norm": 0.7811506390571594,
      "learning_rate": 1.5984193711114848e-05,
      "loss": 0.03,
      "step": 950
    },
    {
      "epoch": 4.773151025481665,
      "grad_norm": 1.0712021589279175,
      "learning_rate": 1.5953926349419876e-05,
      "loss": 0.0208,
      "step": 960
    },
    {
      "epoch": 4.822871348663766,
      "grad_norm": 0.5080078840255737,
      "learning_rate": 1.5923658987724903e-05,
      "loss": 0.0245,
      "step": 970
    },
    {
      "epoch": 4.872591671845867,
      "grad_norm": 1.5494709014892578,
      "learning_rate": 1.589339162602993e-05,
      "loss": 0.024,
      "step": 980
    },
    {
      "epoch": 4.922311995027968,
      "grad_norm": 2.7507522106170654,
      "learning_rate": 1.586312426433496e-05,
      "loss": 0.0221,
      "step": 990
    },
    {
      "epoch": 4.9720323182100685,
      "grad_norm": 0.9700673818588257,
      "learning_rate": 1.5832856902639988e-05,
      "loss": 0.0204,
      "step": 1000
    },
    {
      "epoch": 4.996892479801119,
      "eval_accuracy": 0.9917635658914729,
      "eval_f1": 0.9544846050870147,
      "eval_loss": 0.02398965135216713,
      "eval_precision": 0.9648173207036536,
      "eval_recall": 0.9443708609271523,
      "eval_runtime": 154.7167,
      "eval_samples_per_second": 53.498,
      "eval_steps_per_second": 2.23,
      "step": 1005
    },
    {
      "epoch": 5.021752641392169,
      "grad_norm": 0.8236544728279114,
      "learning_rate": 1.5802589540945015e-05,
      "loss": 0.0158,
      "step": 1010
    },
    {
      "epoch": 5.071472964574269,
      "grad_norm": 1.4458461999893188,
      "learning_rate": 1.5772322179250042e-05,
      "loss": 0.0116,
      "step": 1020
    },
    {
      "epoch": 5.121193287756371,
      "grad_norm": 0.8074588179588318,
      "learning_rate": 1.574205481755507e-05,
      "loss": 0.021,
      "step": 1030
    },
    {
      "epoch": 5.170913610938471,
      "grad_norm": 1.7386714220046997,
      "learning_rate": 1.5711787455860097e-05,
      "loss": 0.0116,
      "step": 1040
    },
    {
      "epoch": 5.220633934120571,
      "grad_norm": 3.324780225753784,
      "learning_rate": 1.5681520094165124e-05,
      "loss": 0.017,
      "step": 1050
    },
    {
      "epoch": 5.270354257302673,
      "grad_norm": 1.5958523750305176,
      "learning_rate": 1.5651252732470155e-05,
      "loss": 0.011,
      "step": 1060
    },
    {
      "epoch": 5.320074580484773,
      "grad_norm": 0.8141359686851501,
      "learning_rate": 1.5620985370775182e-05,
      "loss": 0.0188,
      "step": 1070
    },
    {
      "epoch": 5.3697949036668735,
      "grad_norm": 0.5223938226699829,
      "learning_rate": 1.559071800908021e-05,
      "loss": 0.0202,
      "step": 1080
    },
    {
      "epoch": 5.419515226848975,
      "grad_norm": 3.119889259338379,
      "learning_rate": 1.5560450647385236e-05,
      "loss": 0.015,
      "step": 1090
    },
    {
      "epoch": 5.469235550031075,
      "grad_norm": 2.058922290802002,
      "learning_rate": 1.5530183285690263e-05,
      "loss": 0.0226,
      "step": 1100
    },
    {
      "epoch": 5.518955873213176,
      "grad_norm": 1.1797693967819214,
      "learning_rate": 1.5499915923995294e-05,
      "loss": 0.0173,
      "step": 1110
    },
    {
      "epoch": 5.568676196395277,
      "grad_norm": 4.330338001251221,
      "learning_rate": 1.5469648562300318e-05,
      "loss": 0.0139,
      "step": 1120
    },
    {
      "epoch": 5.618396519577377,
      "grad_norm": 2.4072909355163574,
      "learning_rate": 1.543938120060535e-05,
      "loss": 0.0227,
      "step": 1130
    },
    {
      "epoch": 5.668116842759478,
      "grad_norm": 0.9803557991981506,
      "learning_rate": 1.5409113838910376e-05,
      "loss": 0.0113,
      "step": 1140
    },
    {
      "epoch": 5.717837165941579,
      "grad_norm": 1.7374507188796997,
      "learning_rate": 1.5378846477215403e-05,
      "loss": 0.0165,
      "step": 1150
    },
    {
      "epoch": 5.767557489123679,
      "grad_norm": 0.9066780209541321,
      "learning_rate": 1.534857911552043e-05,
      "loss": 0.0175,
      "step": 1160
    },
    {
      "epoch": 5.81727781230578,
      "grad_norm": 0.8749892115592957,
      "learning_rate": 1.5318311753825457e-05,
      "loss": 0.0194,
      "step": 1170
    },
    {
      "epoch": 5.866998135487881,
      "grad_norm": 0.06787870824337006,
      "learning_rate": 1.5288044392130488e-05,
      "loss": 0.0229,
      "step": 1180
    },
    {
      "epoch": 5.9167184586699815,
      "grad_norm": 1.2257606983184814,
      "learning_rate": 1.5257777030435515e-05,
      "loss": 0.0185,
      "step": 1190
    },
    {
      "epoch": 5.966438781852082,
      "grad_norm": 0.16067160665988922,
      "learning_rate": 1.522750966874054e-05,
      "loss": 0.0092,
      "step": 1200
    },
    {
      "epoch": 5.996270975761343,
      "eval_accuracy": 0.9914001937984496,
      "eval_f1": 0.9524447421299397,
      "eval_loss": 0.02866430953145027,
      "eval_precision": 0.9634146341463414,
      "eval_recall": 0.9417218543046357,
      "eval_runtime": 162.6199,
      "eval_samples_per_second": 50.898,
      "eval_steps_per_second": 2.122,
      "step": 1206
    },
    {
      "epoch": 6.016159105034183,
      "grad_norm": 1.170433521270752,
      "learning_rate": 1.5197242307045568e-05,
      "loss": 0.0184,
      "step": 1210
    },
    {
      "epoch": 6.065879428216284,
      "grad_norm": 1.7788935899734497,
      "learning_rate": 1.5166974945350597e-05,
      "loss": 0.0167,
      "step": 1220
    },
    {
      "epoch": 6.115599751398384,
      "grad_norm": 0.2954435348510742,
      "learning_rate": 1.5136707583655624e-05,
      "loss": 0.0111,
      "step": 1230
    },
    {
      "epoch": 6.165320074580484,
      "grad_norm": 1.8091543912887573,
      "learning_rate": 1.5106440221960653e-05,
      "loss": 0.0148,
      "step": 1240
    },
    {
      "epoch": 6.215040397762586,
      "grad_norm": 0.17504188418388367,
      "learning_rate": 1.507617286026568e-05,
      "loss": 0.0111,
      "step": 1250
    },
    {
      "epoch": 6.264760720944686,
      "grad_norm": 1.005997657775879,
      "learning_rate": 1.504590549857071e-05,
      "loss": 0.0145,
      "step": 1260
    },
    {
      "epoch": 6.3144810441267865,
      "grad_norm": 1.3748639822006226,
      "learning_rate": 1.5015638136875736e-05,
      "loss": 0.0081,
      "step": 1270
    },
    {
      "epoch": 6.364201367308888,
      "grad_norm": 0.8661011457443237,
      "learning_rate": 1.4985370775180765e-05,
      "loss": 0.0253,
      "step": 1280
    },
    {
      "epoch": 6.413921690490988,
      "grad_norm": 0.9584190249443054,
      "learning_rate": 1.4955103413485791e-05,
      "loss": 0.0194,
      "step": 1290
    },
    {
      "epoch": 6.4636420136730885,
      "grad_norm": 1.296828269958496,
      "learning_rate": 1.4924836051790818e-05,
      "loss": 0.0143,
      "step": 1300
    },
    {
      "epoch": 6.51336233685519,
      "grad_norm": 0.922501802444458,
      "learning_rate": 1.4894568690095847e-05,
      "loss": 0.0162,
      "step": 1310
    },
    {
      "epoch": 6.56308266003729,
      "grad_norm": 1.4604641199111938,
      "learning_rate": 1.4864301328400874e-05,
      "loss": 0.0152,
      "step": 1320
    },
    {
      "epoch": 6.612802983219391,
      "grad_norm": 0.5451632738113403,
      "learning_rate": 1.4834033966705903e-05,
      "loss": 0.0157,
      "step": 1330
    },
    {
      "epoch": 6.662523306401492,
      "grad_norm": 1.1103051900863647,
      "learning_rate": 1.480376660501093e-05,
      "loss": 0.0148,
      "step": 1340
    },
    {
      "epoch": 6.712243629583592,
      "grad_norm": 0.7339736819267273,
      "learning_rate": 1.477349924331596e-05,
      "loss": 0.0092,
      "step": 1350
    },
    {
      "epoch": 6.761963952765693,
      "grad_norm": 0.1229110062122345,
      "learning_rate": 1.4743231881620987e-05,
      "loss": 0.0111,
      "step": 1360
    },
    {
      "epoch": 6.811684275947794,
      "grad_norm": 0.835602879524231,
      "learning_rate": 1.4712964519926012e-05,
      "loss": 0.0231,
      "step": 1370
    },
    {
      "epoch": 6.861404599129894,
      "grad_norm": 0.6612330079078674,
      "learning_rate": 1.4682697158231041e-05,
      "loss": 0.0123,
      "step": 1380
    },
    {
      "epoch": 6.911124922311995,
      "grad_norm": 0.2503260672092438,
      "learning_rate": 1.4652429796536068e-05,
      "loss": 0.0075,
      "step": 1390
    },
    {
      "epoch": 6.960845245494095,
      "grad_norm": 1.6782015562057495,
      "learning_rate": 1.4622162434841097e-05,
      "loss": 0.0138,
      "step": 1400
    },
    {
      "epoch": 6.995649471721566,
      "eval_accuracy": 0.9914001937984496,
      "eval_f1": 0.951929587000677,
      "eval_loss": 0.03278264403343201,
      "eval_precision": 0.9736842105263158,
      "eval_recall": 0.9311258278145695,
      "eval_runtime": 160.3753,
      "eval_samples_per_second": 51.61,
      "eval_steps_per_second": 2.151,
      "step": 1407
    },
    {
      "epoch": 7.0105655686761965,
      "grad_norm": 0.5567379593849182,
      "learning_rate": 1.4591895073146124e-05,
      "loss": 0.0118,
      "step": 1410
    },
    {
      "epoch": 7.060285891858297,
      "grad_norm": 3.2100274562835693,
      "learning_rate": 1.4561627711451152e-05,
      "loss": 0.0101,
      "step": 1420
    },
    {
      "epoch": 7.110006215040398,
      "grad_norm": 0.9083825945854187,
      "learning_rate": 1.453136034975618e-05,
      "loss": 0.011,
      "step": 1430
    },
    {
      "epoch": 7.159726538222499,
      "grad_norm": 0.3865908086299896,
      "learning_rate": 1.4501092988061208e-05,
      "loss": 0.006,
      "step": 1440
    },
    {
      "epoch": 7.209446861404599,
      "grad_norm": 1.8931220769882202,
      "learning_rate": 1.4470825626366237e-05,
      "loss": 0.0112,
      "step": 1450
    },
    {
      "epoch": 7.259167184586699,
      "grad_norm": 0.8133530616760254,
      "learning_rate": 1.4440558264671262e-05,
      "loss": 0.0117,
      "step": 1460
    },
    {
      "epoch": 7.308887507768801,
      "grad_norm": 0.8512936234474182,
      "learning_rate": 1.4410290902976291e-05,
      "loss": 0.0073,
      "step": 1470
    },
    {
      "epoch": 7.358607830950901,
      "grad_norm": 0.974574089050293,
      "learning_rate": 1.4380023541281318e-05,
      "loss": 0.0177,
      "step": 1480
    },
    {
      "epoch": 7.4083281541330015,
      "grad_norm": 0.9358316659927368,
      "learning_rate": 1.4349756179586346e-05,
      "loss": 0.0115,
      "step": 1490
    },
    {
      "epoch": 7.458048477315103,
      "grad_norm": 0.6447280645370483,
      "learning_rate": 1.4319488817891375e-05,
      "loss": 0.0075,
      "step": 1500
    },
    {
      "epoch": 7.507768800497203,
      "grad_norm": 0.14209753274917603,
      "learning_rate": 1.4289221456196402e-05,
      "loss": 0.0102,
      "step": 1510
    },
    {
      "epoch": 7.557489123679304,
      "grad_norm": 1.6572757959365845,
      "learning_rate": 1.425895409450143e-05,
      "loss": 0.0109,
      "step": 1520
    },
    {
      "epoch": 7.607209446861405,
      "grad_norm": 0.5541573762893677,
      "learning_rate": 1.4228686732806458e-05,
      "loss": 0.0106,
      "step": 1530
    },
    {
      "epoch": 7.656929770043505,
      "grad_norm": 1.4695789813995361,
      "learning_rate": 1.4198419371111483e-05,
      "loss": 0.0103,
      "step": 1540
    },
    {
      "epoch": 7.706650093225606,
      "grad_norm": 0.7237182855606079,
      "learning_rate": 1.4168152009416512e-05,
      "loss": 0.012,
      "step": 1550
    },
    {
      "epoch": 7.756370416407707,
      "grad_norm": 0.5562697649002075,
      "learning_rate": 1.413788464772154e-05,
      "loss": 0.0209,
      "step": 1560
    },
    {
      "epoch": 7.806090739589807,
      "grad_norm": 0.863461971282959,
      "learning_rate": 1.4107617286026569e-05,
      "loss": 0.0209,
      "step": 1570
    },
    {
      "epoch": 7.855811062771908,
      "grad_norm": 0.4028792977333069,
      "learning_rate": 1.4077349924331596e-05,
      "loss": 0.0063,
      "step": 1580
    },
    {
      "epoch": 7.905531385954009,
      "grad_norm": 0.6622275710105896,
      "learning_rate": 1.4047082562636625e-05,
      "loss": 0.0102,
      "step": 1590
    },
    {
      "epoch": 7.9552517091361095,
      "grad_norm": 1.4921177625656128,
      "learning_rate": 1.4016815200941652e-05,
      "loss": 0.0136,
      "step": 1600
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9921269379844961,
      "eval_f1": 0.9561107359891964,
      "eval_loss": 0.02727266401052475,
      "eval_precision": 0.9752066115702479,
      "eval_recall": 0.937748344370861,
      "eval_runtime": 156.2887,
      "eval_samples_per_second": 52.96,
      "eval_steps_per_second": 2.207,
      "step": 1609
    },
    {
      "epoch": 8.00497203231821,
      "grad_norm": 1.8622130155563354,
      "learning_rate": 1.398654783924668e-05,
      "loss": 0.0111,
      "step": 1610
    },
    {
      "epoch": 8.054692355500311,
      "grad_norm": 0.23577556014060974,
      "learning_rate": 1.3956280477551706e-05,
      "loss": 0.0038,
      "step": 1620
    },
    {
      "epoch": 8.104412678682412,
      "grad_norm": 1.1310346126556396,
      "learning_rate": 1.3926013115856734e-05,
      "loss": 0.0128,
      "step": 1630
    },
    {
      "epoch": 8.154133001864512,
      "grad_norm": 0.3193475306034088,
      "learning_rate": 1.3895745754161762e-05,
      "loss": 0.0084,
      "step": 1640
    },
    {
      "epoch": 8.203853325046612,
      "grad_norm": 1.231766700744629,
      "learning_rate": 1.386547839246679e-05,
      "loss": 0.009,
      "step": 1650
    },
    {
      "epoch": 8.253573648228713,
      "grad_norm": 0.04058237001299858,
      "learning_rate": 1.3835211030771819e-05,
      "loss": 0.007,
      "step": 1660
    },
    {
      "epoch": 8.303293971410815,
      "grad_norm": 0.902178168296814,
      "learning_rate": 1.3804943669076846e-05,
      "loss": 0.0112,
      "step": 1670
    },
    {
      "epoch": 8.353014294592915,
      "grad_norm": 5.210655689239502,
      "learning_rate": 1.3774676307381875e-05,
      "loss": 0.0111,
      "step": 1680
    },
    {
      "epoch": 8.402734617775016,
      "grad_norm": 1.9861501455307007,
      "learning_rate": 1.3744408945686902e-05,
      "loss": 0.0116,
      "step": 1690
    },
    {
      "epoch": 8.452454940957116,
      "grad_norm": 0.4484211802482605,
      "learning_rate": 1.371414158399193e-05,
      "loss": 0.0078,
      "step": 1700
    },
    {
      "epoch": 8.502175264139217,
      "grad_norm": 0.6022301912307739,
      "learning_rate": 1.3683874222296956e-05,
      "loss": 0.0082,
      "step": 1710
    },
    {
      "epoch": 8.551895587321317,
      "grad_norm": 0.967078685760498,
      "learning_rate": 1.3653606860601984e-05,
      "loss": 0.0171,
      "step": 1720
    },
    {
      "epoch": 8.60161591050342,
      "grad_norm": 0.49207261204719543,
      "learning_rate": 1.3623339498907013e-05,
      "loss": 0.0152,
      "step": 1730
    },
    {
      "epoch": 8.65133623368552,
      "grad_norm": 0.31313556432724,
      "learning_rate": 1.359307213721204e-05,
      "loss": 0.0071,
      "step": 1740
    },
    {
      "epoch": 8.70105655686762,
      "grad_norm": 0.018245110288262367,
      "learning_rate": 1.3562804775517067e-05,
      "loss": 0.0092,
      "step": 1750
    },
    {
      "epoch": 8.75077688004972,
      "grad_norm": 0.5609791874885559,
      "learning_rate": 1.3532537413822096e-05,
      "loss": 0.0149,
      "step": 1760
    },
    {
      "epoch": 8.80049720323182,
      "grad_norm": 2.366248846054077,
      "learning_rate": 1.3502270052127123e-05,
      "loss": 0.0189,
      "step": 1770
    },
    {
      "epoch": 8.850217526413921,
      "grad_norm": 0.33798837661743164,
      "learning_rate": 1.3472002690432152e-05,
      "loss": 0.0104,
      "step": 1780
    },
    {
      "epoch": 8.899937849596022,
      "grad_norm": 0.41551220417022705,
      "learning_rate": 1.3441735328737178e-05,
      "loss": 0.0111,
      "step": 1790
    },
    {
      "epoch": 8.949658172778124,
      "grad_norm": 0.10572884231805801,
      "learning_rate": 1.3411467967042207e-05,
      "loss": 0.0073,
      "step": 1800
    },
    {
      "epoch": 8.999378495960224,
      "grad_norm": 0.9778445363044739,
      "learning_rate": 1.3381200605347234e-05,
      "loss": 0.0107,
      "step": 1810
    },
    {
      "epoch": 8.999378495960224,
      "eval_accuracy": 0.9922480620155039,
      "eval_f1": 0.957503320053121,
      "eval_loss": 0.029770970344543457,
      "eval_precision": 0.9600532623169108,
      "eval_recall": 0.9549668874172186,
      "eval_runtime": 137.2728,
      "eval_samples_per_second": 60.296,
      "eval_steps_per_second": 2.513,
      "step": 1810
    },
    {
      "epoch": 9.049098819142325,
      "grad_norm": 1.7165744304656982,
      "learning_rate": 1.3350933243652261e-05,
      "loss": 0.0144,
      "step": 1820
    },
    {
      "epoch": 9.098819142324425,
      "grad_norm": 2.064732074737549,
      "learning_rate": 1.332066588195729e-05,
      "loss": 0.0105,
      "step": 1830
    },
    {
      "epoch": 9.148539465506525,
      "grad_norm": 1.125145435333252,
      "learning_rate": 1.3290398520262317e-05,
      "loss": 0.0067,
      "step": 1840
    },
    {
      "epoch": 9.198259788688626,
      "grad_norm": 2.1305742263793945,
      "learning_rate": 1.3260131158567346e-05,
      "loss": 0.0074,
      "step": 1850
    },
    {
      "epoch": 9.247980111870728,
      "grad_norm": 0.47547081112861633,
      "learning_rate": 1.3229863796872373e-05,
      "loss": 0.0153,
      "step": 1860
    },
    {
      "epoch": 9.297700435052828,
      "grad_norm": 2.6211163997650146,
      "learning_rate": 1.3199596435177402e-05,
      "loss": 0.0141,
      "step": 1870
    },
    {
      "epoch": 9.347420758234929,
      "grad_norm": 1.1046688556671143,
      "learning_rate": 1.3169329073482428e-05,
      "loss": 0.0071,
      "step": 1880
    },
    {
      "epoch": 9.397141081417029,
      "grad_norm": 0.7249337434768677,
      "learning_rate": 1.3139061711787455e-05,
      "loss": 0.0081,
      "step": 1890
    },
    {
      "epoch": 9.44686140459913,
      "grad_norm": 0.321194052696228,
      "learning_rate": 1.3108794350092484e-05,
      "loss": 0.0091,
      "step": 1900
    },
    {
      "epoch": 9.49658172778123,
      "grad_norm": 0.8852511048316956,
      "learning_rate": 1.3078526988397511e-05,
      "loss": 0.0074,
      "step": 1910
    },
    {
      "epoch": 9.546302050963332,
      "grad_norm": 0.02308788150548935,
      "learning_rate": 1.304825962670254e-05,
      "loss": 0.0106,
      "step": 1920
    },
    {
      "epoch": 9.596022374145432,
      "grad_norm": 0.5435774326324463,
      "learning_rate": 1.3017992265007567e-05,
      "loss": 0.0113,
      "step": 1930
    },
    {
      "epoch": 9.645742697327533,
      "grad_norm": 0.71451735496521,
      "learning_rate": 1.2987724903312596e-05,
      "loss": 0.0058,
      "step": 1940
    },
    {
      "epoch": 9.695463020509633,
      "grad_norm": 0.7767199873924255,
      "learning_rate": 1.2957457541617623e-05,
      "loss": 0.0109,
      "step": 1950
    },
    {
      "epoch": 9.745183343691734,
      "grad_norm": 1.4534343481063843,
      "learning_rate": 1.2927190179922649e-05,
      "loss": 0.0091,
      "step": 1960
    },
    {
      "epoch": 9.794903666873834,
      "grad_norm": 0.19016815721988678,
      "learning_rate": 1.2896922818227678e-05,
      "loss": 0.0123,
      "step": 1970
    },
    {
      "epoch": 9.844623990055936,
      "grad_norm": 1.006964087486267,
      "learning_rate": 1.2866655456532705e-05,
      "loss": 0.011,
      "step": 1980
    },
    {
      "epoch": 9.894344313238037,
      "grad_norm": 0.43587133288383484,
      "learning_rate": 1.2836388094837734e-05,
      "loss": 0.0081,
      "step": 1990
    },
    {
      "epoch": 9.944064636420137,
      "grad_norm": 0.5303491353988647,
      "learning_rate": 1.2806120733142761e-05,
      "loss": 0.0135,
      "step": 2000
    },
    {
      "epoch": 9.993784959602237,
      "grad_norm": 0.0348907969892025,
      "learning_rate": 1.277585337144779e-05,
      "loss": 0.0058,
      "step": 2010
    },
    {
      "epoch": 9.998756991920448,
      "eval_accuracy": 0.9924903100775194,
      "eval_f1": 0.958611481975968,
      "eval_loss": 0.022526390850543976,
      "eval_precision": 0.9663526244952894,
      "eval_recall": 0.9509933774834437,
      "eval_runtime": 155.9884,
      "eval_samples_per_second": 53.062,
      "eval_steps_per_second": 2.212,
      "step": 2011
    },
    {
      "epoch": 10.043505282784338,
      "grad_norm": 0.6969180703163147,
      "learning_rate": 1.2745586009752817e-05,
      "loss": 0.0043,
      "step": 2020
    },
    {
      "epoch": 10.093225605966438,
      "grad_norm": 0.19205151498317719,
      "learning_rate": 1.2715318648057845e-05,
      "loss": 0.0037,
      "step": 2030
    },
    {
      "epoch": 10.142945929148539,
      "grad_norm": 0.25655800104141235,
      "learning_rate": 1.2685051286362872e-05,
      "loss": 0.0042,
      "step": 2040
    },
    {
      "epoch": 10.19266625233064,
      "grad_norm": 0.766722559928894,
      "learning_rate": 1.2654783924667899e-05,
      "loss": 0.0062,
      "step": 2050
    },
    {
      "epoch": 10.242386575512741,
      "grad_norm": 0.724442183971405,
      "learning_rate": 1.2624516562972928e-05,
      "loss": 0.0085,
      "step": 2060
    },
    {
      "epoch": 10.292106898694842,
      "grad_norm": 0.7354185581207275,
      "learning_rate": 1.2594249201277955e-05,
      "loss": 0.0041,
      "step": 2070
    },
    {
      "epoch": 10.341827221876942,
      "grad_norm": 0.01024552620947361,
      "learning_rate": 1.2563981839582982e-05,
      "loss": 0.0087,
      "step": 2080
    },
    {
      "epoch": 10.391547545059042,
      "grad_norm": 0.42505520582199097,
      "learning_rate": 1.2533714477888011e-05,
      "loss": 0.0063,
      "step": 2090
    },
    {
      "epoch": 10.441267868241143,
      "grad_norm": 0.0519946850836277,
      "learning_rate": 1.2503447116193039e-05,
      "loss": 0.0048,
      "step": 2100
    },
    {
      "epoch": 10.490988191423245,
      "grad_norm": 0.36479467153549194,
      "learning_rate": 1.2473179754498068e-05,
      "loss": 0.0124,
      "step": 2110
    },
    {
      "epoch": 10.540708514605345,
      "grad_norm": 1.1456965208053589,
      "learning_rate": 1.2442912392803095e-05,
      "loss": 0.009,
      "step": 2120
    },
    {
      "epoch": 10.590428837787446,
      "grad_norm": 0.16124486923217773,
      "learning_rate": 1.2412645031108122e-05,
      "loss": 0.0036,
      "step": 2130
    },
    {
      "epoch": 10.640149160969546,
      "grad_norm": 0.8941903114318848,
      "learning_rate": 1.238237766941315e-05,
      "loss": 0.0157,
      "step": 2140
    },
    {
      "epoch": 10.689869484151647,
      "grad_norm": 0.29592397809028625,
      "learning_rate": 1.2352110307718176e-05,
      "loss": 0.0117,
      "step": 2150
    },
    {
      "epoch": 10.739589807333747,
      "grad_norm": 0.20350581407546997,
      "learning_rate": 1.2321842946023205e-05,
      "loss": 0.0048,
      "step": 2160
    },
    {
      "epoch": 10.789310130515847,
      "grad_norm": 0.6517699956893921,
      "learning_rate": 1.2291575584328233e-05,
      "loss": 0.007,
      "step": 2170
    },
    {
      "epoch": 10.83903045369795,
      "grad_norm": 0.710537850856781,
      "learning_rate": 1.2261308222633262e-05,
      "loss": 0.0093,
      "step": 2180
    },
    {
      "epoch": 10.88875077688005,
      "grad_norm": 1.3364969491958618,
      "learning_rate": 1.2231040860938289e-05,
      "loss": 0.0132,
      "step": 2190
    },
    {
      "epoch": 10.93847110006215,
      "grad_norm": 0.28756803274154663,
      "learning_rate": 1.2200773499243318e-05,
      "loss": 0.0112,
      "step": 2200
    },
    {
      "epoch": 10.98819142324425,
      "grad_norm": 0.010683593340218067,
      "learning_rate": 1.2170506137548343e-05,
      "loss": 0.0052,
      "step": 2210
    },
    {
      "epoch": 10.99813548788067,
      "eval_accuracy": 0.9923691860465116,
      "eval_f1": 0.9576897246474143,
      "eval_loss": 0.02402034029364586,
      "eval_precision": 0.9713896457765667,
      "eval_recall": 0.9443708609271523,
      "eval_runtime": 161.9079,
      "eval_samples_per_second": 51.122,
      "eval_steps_per_second": 2.131,
      "step": 2212
    },
    {
      "epoch": 11.037911746426351,
      "grad_norm": 0.839729905128479,
      "learning_rate": 1.214023877585337e-05,
      "loss": 0.0089,
      "step": 2220
    },
    {
      "epoch": 11.087632069608452,
      "grad_norm": 0.35376036167144775,
      "learning_rate": 1.21099714141584e-05,
      "loss": 0.0059,
      "step": 2230
    },
    {
      "epoch": 11.137352392790554,
      "grad_norm": 0.08102631568908691,
      "learning_rate": 1.2079704052463427e-05,
      "loss": 0.0072,
      "step": 2240
    },
    {
      "epoch": 11.187072715972654,
      "grad_norm": 0.30741098523139954,
      "learning_rate": 1.2049436690768455e-05,
      "loss": 0.005,
      "step": 2250
    },
    {
      "epoch": 11.236793039154755,
      "grad_norm": 1.4237765073776245,
      "learning_rate": 1.2019169329073483e-05,
      "loss": 0.0067,
      "step": 2260
    },
    {
      "epoch": 11.286513362336855,
      "grad_norm": 0.1242266446352005,
      "learning_rate": 1.1988901967378512e-05,
      "loss": 0.0057,
      "step": 2270
    },
    {
      "epoch": 11.336233685518955,
      "grad_norm": 0.4728282392024994,
      "learning_rate": 1.1958634605683539e-05,
      "loss": 0.0076,
      "step": 2280
    },
    {
      "epoch": 11.385954008701056,
      "grad_norm": 0.6228153109550476,
      "learning_rate": 1.1928367243988566e-05,
      "loss": 0.0059,
      "step": 2290
    },
    {
      "epoch": 11.435674331883158,
      "grad_norm": 0.061899956315755844,
      "learning_rate": 1.1898099882293593e-05,
      "loss": 0.0068,
      "step": 2300
    },
    {
      "epoch": 11.485394655065258,
      "grad_norm": 0.36192217469215393,
      "learning_rate": 1.186783252059862e-05,
      "loss": 0.0068,
      "step": 2310
    },
    {
      "epoch": 11.535114978247359,
      "grad_norm": 0.696560800075531,
      "learning_rate": 1.183756515890365e-05,
      "loss": 0.0055,
      "step": 2320
    },
    {
      "epoch": 11.58483530142946,
      "grad_norm": 1.3053189516067505,
      "learning_rate": 1.1807297797208677e-05,
      "loss": 0.0071,
      "step": 2330
    },
    {
      "epoch": 11.63455562461156,
      "grad_norm": 1.0020813941955566,
      "learning_rate": 1.1777030435513706e-05,
      "loss": 0.0078,
      "step": 2340
    },
    {
      "epoch": 11.68427594779366,
      "grad_norm": 1.0169856548309326,
      "learning_rate": 1.1746763073818733e-05,
      "loss": 0.0135,
      "step": 2350
    },
    {
      "epoch": 11.733996270975762,
      "grad_norm": 0.8859665989875793,
      "learning_rate": 1.171649571212376e-05,
      "loss": 0.0113,
      "step": 2360
    },
    {
      "epoch": 11.783716594157863,
      "grad_norm": 0.4181542992591858,
      "learning_rate": 1.1686228350428789e-05,
      "loss": 0.0057,
      "step": 2370
    },
    {
      "epoch": 11.833436917339963,
      "grad_norm": 0.3204992115497589,
      "learning_rate": 1.1655960988733815e-05,
      "loss": 0.0091,
      "step": 2380
    },
    {
      "epoch": 11.883157240522063,
      "grad_norm": 0.021486351266503334,
      "learning_rate": 1.1625693627038843e-05,
      "loss": 0.0046,
      "step": 2390
    },
    {
      "epoch": 11.932877563704164,
      "grad_norm": 0.9590409994125366,
      "learning_rate": 1.159542626534387e-05,
      "loss": 0.0065,
      "step": 2400
    },
    {
      "epoch": 11.982597886886264,
      "grad_norm": 0.6105401515960693,
      "learning_rate": 1.1565158903648898e-05,
      "loss": 0.0041,
      "step": 2410
    },
    {
      "epoch": 11.997513983840895,
      "eval_accuracy": 0.9932170542635659,
      "eval_f1": 0.9625668449197862,
      "eval_loss": 0.02270619012415409,
      "eval_precision": 0.97165991902834,
      "eval_recall": 0.9536423841059603,
      "eval_runtime": 160.845,
      "eval_samples_per_second": 51.459,
      "eval_steps_per_second": 2.145,
      "step": 2413
    },
    {
      "epoch": 12.032318210068366,
      "grad_norm": 1.0471158027648926,
      "learning_rate": 1.1534891541953927e-05,
      "loss": 0.0071,
      "step": 2420
    },
    {
      "epoch": 12.082038533250467,
      "grad_norm": 0.06142527237534523,
      "learning_rate": 1.1504624180258954e-05,
      "loss": 0.0058,
      "step": 2430
    },
    {
      "epoch": 12.131758856432567,
      "grad_norm": 14.456595420837402,
      "learning_rate": 1.1474356818563983e-05,
      "loss": 0.0134,
      "step": 2440
    },
    {
      "epoch": 12.181479179614668,
      "grad_norm": 0.028177659958600998,
      "learning_rate": 1.144408945686901e-05,
      "loss": 0.005,
      "step": 2450
    },
    {
      "epoch": 12.231199502796768,
      "grad_norm": 0.8678846955299377,
      "learning_rate": 1.1413822095174037e-05,
      "loss": 0.0117,
      "step": 2460
    },
    {
      "epoch": 12.280919825978868,
      "grad_norm": 0.43282246589660645,
      "learning_rate": 1.1383554733479065e-05,
      "loss": 0.008,
      "step": 2470
    },
    {
      "epoch": 12.330640149160969,
      "grad_norm": 0.03855888545513153,
      "learning_rate": 1.1353287371784092e-05,
      "loss": 0.0043,
      "step": 2480
    },
    {
      "epoch": 12.380360472343071,
      "grad_norm": 0.729327917098999,
      "learning_rate": 1.132302001008912e-05,
      "loss": 0.0047,
      "step": 2490
    },
    {
      "epoch": 12.430080795525171,
      "grad_norm": 0.2992672026157379,
      "learning_rate": 1.1292752648394148e-05,
      "loss": 0.0059,
      "step": 2500
    },
    {
      "epoch": 12.479801118707272,
      "grad_norm": 0.0075875334441661835,
      "learning_rate": 1.1262485286699177e-05,
      "loss": 0.0078,
      "step": 2510
    },
    {
      "epoch": 12.529521441889372,
      "grad_norm": 0.004553731065243483,
      "learning_rate": 1.1232217925004204e-05,
      "loss": 0.0052,
      "step": 2520
    },
    {
      "epoch": 12.579241765071473,
      "grad_norm": 1.0662692785263062,
      "learning_rate": 1.1201950563309233e-05,
      "loss": 0.0081,
      "step": 2530
    },
    {
      "epoch": 12.628962088253573,
      "grad_norm": 0.44501006603240967,
      "learning_rate": 1.117168320161426e-05,
      "loss": 0.0031,
      "step": 2540
    },
    {
      "epoch": 12.678682411435675,
      "grad_norm": 0.7021583914756775,
      "learning_rate": 1.1141415839919286e-05,
      "loss": 0.0089,
      "step": 2550
    },
    {
      "epoch": 12.728402734617775,
      "grad_norm": 0.7523435354232788,
      "learning_rate": 1.1111148478224315e-05,
      "loss": 0.0046,
      "step": 2560
    },
    {
      "epoch": 12.778123057799876,
      "grad_norm": 0.7742643356323242,
      "learning_rate": 1.1080881116529342e-05,
      "loss": 0.0058,
      "step": 2570
    },
    {
      "epoch": 12.827843380981976,
      "grad_norm": 0.5088775753974915,
      "learning_rate": 1.1050613754834371e-05,
      "loss": 0.0092,
      "step": 2580
    },
    {
      "epoch": 12.877563704164077,
      "grad_norm": 0.2400965690612793,
      "learning_rate": 1.1020346393139398e-05,
      "loss": 0.0079,
      "step": 2590
    },
    {
      "epoch": 12.927284027346177,
      "grad_norm": 2.11838960647583,
      "learning_rate": 1.0990079031444427e-05,
      "loss": 0.0094,
      "step": 2600
    },
    {
      "epoch": 12.97700435052828,
      "grad_norm": 0.724907398223877,
      "learning_rate": 1.0959811669749454e-05,
      "loss": 0.0044,
      "step": 2610
    },
    {
      "epoch": 12.996892479801119,
      "eval_accuracy": 0.9927325581395349,
      "eval_f1": 0.960212201591512,
      "eval_loss": 0.029880966991186142,
      "eval_precision": 0.9614873837981408,
      "eval_recall": 0.9589403973509933,
      "eval_runtime": 161.7149,
      "eval_samples_per_second": 51.183,
      "eval_steps_per_second": 2.133,
      "step": 2614
    },
    {
      "epoch": 13.02672467371038,
      "grad_norm": 0.08898695558309555,
      "learning_rate": 1.0929544308054482e-05,
      "loss": 0.0027,
      "step": 2620
    },
    {
      "epoch": 13.07644499689248,
      "grad_norm": 0.4306108355522156,
      "learning_rate": 1.0899276946359509e-05,
      "loss": 0.0033,
      "step": 2630
    },
    {
      "epoch": 13.12616532007458,
      "grad_norm": 0.38016143441200256,
      "learning_rate": 1.0869009584664536e-05,
      "loss": 0.0029,
      "step": 2640
    },
    {
      "epoch": 13.17588564325668,
      "grad_norm": 0.16855095326900482,
      "learning_rate": 1.0838742222969565e-05,
      "loss": 0.0093,
      "step": 2650
    },
    {
      "epoch": 13.225605966438781,
      "grad_norm": 1.6506309509277344,
      "learning_rate": 1.0808474861274592e-05,
      "loss": 0.01,
      "step": 2660
    },
    {
      "epoch": 13.275326289620882,
      "grad_norm": 0.18218876421451569,
      "learning_rate": 1.0778207499579621e-05,
      "loss": 0.0057,
      "step": 2670
    },
    {
      "epoch": 13.325046612802984,
      "grad_norm": 0.18880438804626465,
      "learning_rate": 1.0747940137884648e-05,
      "loss": 0.0065,
      "step": 2680
    },
    {
      "epoch": 13.374766935985084,
      "grad_norm": 0.8096245527267456,
      "learning_rate": 1.0717672776189675e-05,
      "loss": 0.0096,
      "step": 2690
    },
    {
      "epoch": 13.424487259167185,
      "grad_norm": 1.1830923557281494,
      "learning_rate": 1.0687405414494704e-05,
      "loss": 0.0073,
      "step": 2700
    },
    {
      "epoch": 13.474207582349285,
      "grad_norm": 0.24364513158798218,
      "learning_rate": 1.0657138052799732e-05,
      "loss": 0.0058,
      "step": 2710
    },
    {
      "epoch": 13.523927905531385,
      "grad_norm": 1.176200270652771,
      "learning_rate": 1.0626870691104759e-05,
      "loss": 0.0108,
      "step": 2720
    },
    {
      "epoch": 13.573648228713486,
      "grad_norm": 0.9213740229606628,
      "learning_rate": 1.0596603329409786e-05,
      "loss": 0.0073,
      "step": 2730
    },
    {
      "epoch": 13.623368551895588,
      "grad_norm": 0.09481604397296906,
      "learning_rate": 1.0566335967714813e-05,
      "loss": 0.0065,
      "step": 2740
    },
    {
      "epoch": 13.673088875077688,
      "grad_norm": 0.30066654086112976,
      "learning_rate": 1.0536068606019842e-05,
      "loss": 0.0085,
      "step": 2750
    },
    {
      "epoch": 13.722809198259789,
      "grad_norm": 0.005681927781552076,
      "learning_rate": 1.050580124432487e-05,
      "loss": 0.0074,
      "step": 2760
    },
    {
      "epoch": 13.77252952144189,
      "grad_norm": 0.23090539872646332,
      "learning_rate": 1.0475533882629898e-05,
      "loss": 0.0079,
      "step": 2770
    },
    {
      "epoch": 13.82224984462399,
      "grad_norm": 0.3954731523990631,
      "learning_rate": 1.0445266520934926e-05,
      "loss": 0.003,
      "step": 2780
    },
    {
      "epoch": 13.87197016780609,
      "grad_norm": 0.8254634141921997,
      "learning_rate": 1.0414999159239955e-05,
      "loss": 0.0082,
      "step": 2790
    },
    {
      "epoch": 13.921690490988192,
      "grad_norm": 0.019902948290109634,
      "learning_rate": 1.038473179754498e-05,
      "loss": 0.0036,
      "step": 2800
    },
    {
      "epoch": 13.971410814170293,
      "grad_norm": 0.04127751290798187,
      "learning_rate": 1.0354464435850007e-05,
      "loss": 0.004,
      "step": 2810
    },
    {
      "epoch": 13.996270975761343,
      "eval_accuracy": 0.9918846899224806,
      "eval_f1": 0.9551239115874078,
      "eval_loss": 0.030029909685254097,
      "eval_precision": 0.9661246612466124,
      "eval_recall": 0.9443708609271523,
      "eval_runtime": 153.8476,
      "eval_samples_per_second": 53.8,
      "eval_steps_per_second": 2.242,
      "step": 2815
    },
    {
      "epoch": 14.021131137352393,
      "grad_norm": 0.741542637348175,
      "learning_rate": 1.0324197074155036e-05,
      "loss": 0.0048,
      "step": 2820
    },
    {
      "epoch": 14.070851460534493,
      "grad_norm": 0.04984916374087334,
      "learning_rate": 1.0293929712460063e-05,
      "loss": 0.0029,
      "step": 2830
    },
    {
      "epoch": 14.120571783716594,
      "grad_norm": 0.7227408289909363,
      "learning_rate": 1.0263662350765092e-05,
      "loss": 0.0113,
      "step": 2840
    },
    {
      "epoch": 14.170292106898694,
      "grad_norm": 0.4652267098426819,
      "learning_rate": 1.023339498907012e-05,
      "loss": 0.0051,
      "step": 2850
    },
    {
      "epoch": 14.220012430080796,
      "grad_norm": 1.8103529214859009,
      "learning_rate": 1.0203127627375148e-05,
      "loss": 0.0074,
      "step": 2860
    },
    {
      "epoch": 14.269732753262897,
      "grad_norm": 3.2656726837158203,
      "learning_rate": 1.0172860265680176e-05,
      "loss": 0.0072,
      "step": 2870
    },
    {
      "epoch": 14.319453076444997,
      "grad_norm": 0.23048114776611328,
      "learning_rate": 1.0142592903985201e-05,
      "loss": 0.0064,
      "step": 2880
    },
    {
      "epoch": 14.369173399627098,
      "grad_norm": 0.01214488036930561,
      "learning_rate": 1.011232554229023e-05,
      "loss": 0.0076,
      "step": 2890
    },
    {
      "epoch": 14.418893722809198,
      "grad_norm": 0.7064346671104431,
      "learning_rate": 1.0082058180595257e-05,
      "loss": 0.0078,
      "step": 2900
    },
    {
      "epoch": 14.468614045991298,
      "grad_norm": 0.004695606883615255,
      "learning_rate": 1.0051790818900286e-05,
      "loss": 0.006,
      "step": 2910
    },
    {
      "epoch": 14.518334369173399,
      "grad_norm": 0.03510252758860588,
      "learning_rate": 1.0021523457205314e-05,
      "loss": 0.0054,
      "step": 2920
    },
    {
      "epoch": 14.568054692355501,
      "grad_norm": 0.23330765962600708,
      "learning_rate": 9.991256095510342e-06,
      "loss": 0.0051,
      "step": 2930
    },
    {
      "epoch": 14.617775015537601,
      "grad_norm": 4.144706726074219,
      "learning_rate": 9.96098873381537e-06,
      "loss": 0.0073,
      "step": 2940
    },
    {
      "epoch": 14.667495338719702,
      "grad_norm": 0.6748954653739929,
      "learning_rate": 9.930721372120397e-06,
      "loss": 0.0076,
      "step": 2950
    },
    {
      "epoch": 14.717215661901802,
      "grad_norm": 0.10336462408304214,
      "learning_rate": 9.900454010425426e-06,
      "loss": 0.0087,
      "step": 2960
    },
    {
      "epoch": 14.766935985083903,
      "grad_norm": 0.0032573058269917965,
      "learning_rate": 9.870186648730451e-06,
      "loss": 0.0046,
      "step": 2970
    },
    {
      "epoch": 14.816656308266003,
      "grad_norm": 0.31963321566581726,
      "learning_rate": 9.83991928703548e-06,
      "loss": 0.0048,
      "step": 2980
    },
    {
      "epoch": 14.866376631448105,
      "grad_norm": 0.09089010953903198,
      "learning_rate": 9.809651925340508e-06,
      "loss": 0.0098,
      "step": 2990
    },
    {
      "epoch": 14.916096954630206,
      "grad_norm": 0.02034841477870941,
      "learning_rate": 9.779384563645536e-06,
      "loss": 0.0062,
      "step": 3000
    },
    {
      "epoch": 14.965817277812306,
      "grad_norm": 0.40051326155662537,
      "learning_rate": 9.749117201950564e-06,
      "loss": 0.0121,
      "step": 3010
    },
    {
      "epoch": 14.995649471721567,
      "eval_accuracy": 0.9922480620155039,
      "eval_f1": 0.9573333333333334,
      "eval_loss": 0.02723603881895542,
      "eval_precision": 0.963758389261745,
      "eval_recall": 0.9509933774834437,
      "eval_runtime": 148.8222,
      "eval_samples_per_second": 55.617,
      "eval_steps_per_second": 2.318,
      "step": 3016
    },
    {
      "epoch": 15.015537600994406,
      "grad_norm": 0.2845911979675293,
      "learning_rate": 9.718849840255591e-06,
      "loss": 0.0027,
      "step": 3020
    },
    {
      "epoch": 15.065257924176507,
      "grad_norm": 0.03346104547381401,
      "learning_rate": 9.68858247856062e-06,
      "loss": 0.0061,
      "step": 3030
    },
    {
      "epoch": 15.114978247358607,
      "grad_norm": 0.3568786382675171,
      "learning_rate": 9.658315116865647e-06,
      "loss": 0.0069,
      "step": 3040
    },
    {
      "epoch": 15.16469857054071,
      "grad_norm": 0.3617344796657562,
      "learning_rate": 9.628047755170674e-06,
      "loss": 0.0032,
      "step": 3050
    },
    {
      "epoch": 15.21441889372281,
      "grad_norm": 0.009407049044966698,
      "learning_rate": 9.597780393475701e-06,
      "loss": 0.0051,
      "step": 3060
    },
    {
      "epoch": 15.26413921690491,
      "grad_norm": 0.3583632707595825,
      "learning_rate": 9.567513031780729e-06,
      "loss": 0.003,
      "step": 3070
    },
    {
      "epoch": 15.31385954008701,
      "grad_norm": 0.04836603254079819,
      "learning_rate": 9.537245670085758e-06,
      "loss": 0.0058,
      "step": 3080
    },
    {
      "epoch": 15.363579863269111,
      "grad_norm": 0.5804132223129272,
      "learning_rate": 9.506978308390785e-06,
      "loss": 0.0043,
      "step": 3090
    },
    {
      "epoch": 15.413300186451211,
      "grad_norm": 1.1572564840316772,
      "learning_rate": 9.476710946695814e-06,
      "loss": 0.0055,
      "step": 3100
    },
    {
      "epoch": 15.463020509633312,
      "grad_norm": 0.8994612693786621,
      "learning_rate": 9.446443585000841e-06,
      "loss": 0.0103,
      "step": 3110
    },
    {
      "epoch": 15.512740832815414,
      "grad_norm": 0.46758928894996643,
      "learning_rate": 9.41617622330587e-06,
      "loss": 0.0097,
      "step": 3120
    },
    {
      "epoch": 15.562461155997514,
      "grad_norm": 0.5851216316223145,
      "learning_rate": 9.385908861610897e-06,
      "loss": 0.0072,
      "step": 3130
    },
    {
      "epoch": 15.612181479179615,
      "grad_norm": 0.2602200508117676,
      "learning_rate": 9.355641499915923e-06,
      "loss": 0.0061,
      "step": 3140
    },
    {
      "epoch": 15.661901802361715,
      "grad_norm": 0.6397581100463867,
      "learning_rate": 9.325374138220952e-06,
      "loss": 0.0088,
      "step": 3150
    },
    {
      "epoch": 15.711622125543816,
      "grad_norm": 0.22582432627677917,
      "learning_rate": 9.295106776525979e-06,
      "loss": 0.0113,
      "step": 3160
    },
    {
      "epoch": 15.761342448725916,
      "grad_norm": 0.46995261311531067,
      "learning_rate": 9.264839414831008e-06,
      "loss": 0.0042,
      "step": 3170
    },
    {
      "epoch": 15.811062771908018,
      "grad_norm": 0.220281720161438,
      "learning_rate": 9.234572053136035e-06,
      "loss": 0.0048,
      "step": 3180
    },
    {
      "epoch": 15.860783095090119,
      "grad_norm": 0.2609346807003021,
      "learning_rate": 9.204304691441064e-06,
      "loss": 0.0047,
      "step": 3190
    },
    {
      "epoch": 15.910503418272219,
      "grad_norm": 0.03534157574176788,
      "learning_rate": 9.174037329746091e-06,
      "loss": 0.0109,
      "step": 3200
    },
    {
      "epoch": 15.96022374145432,
      "grad_norm": 0.3816593885421753,
      "learning_rate": 9.14376996805112e-06,
      "loss": 0.0045,
      "step": 3210
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.9924903100775194,
      "eval_f1": 0.9588313413014606,
      "eval_loss": 0.02635752223432064,
      "eval_precision": 0.9613848202396804,
      "eval_recall": 0.9562913907284768,
      "eval_runtime": 155.3992,
      "eval_samples_per_second": 53.263,
      "eval_steps_per_second": 2.22,
      "step": 3218
    },
    {
      "epoch": 16.00994406463642,
      "grad_norm": 0.6477170586585999,
      "learning_rate": 9.113502606356146e-06,
      "loss": 0.0065,
      "step": 3220
    },
    {
      "epoch": 16.059664387818522,
      "grad_norm": 0.09009016305208206,
      "learning_rate": 9.083235244661173e-06,
      "loss": 0.0052,
      "step": 3230
    },
    {
      "epoch": 16.109384711000622,
      "grad_norm": 0.7164307236671448,
      "learning_rate": 9.052967882966202e-06,
      "loss": 0.0044,
      "step": 3240
    },
    {
      "epoch": 16.159105034182723,
      "grad_norm": 0.5128191113471985,
      "learning_rate": 9.022700521271229e-06,
      "loss": 0.0049,
      "step": 3250
    },
    {
      "epoch": 16.208825357364823,
      "grad_norm": 0.06149029731750488,
      "learning_rate": 8.992433159576258e-06,
      "loss": 0.0056,
      "step": 3260
    },
    {
      "epoch": 16.258545680546924,
      "grad_norm": 0.9672443270683289,
      "learning_rate": 8.962165797881285e-06,
      "loss": 0.0045,
      "step": 3270
    },
    {
      "epoch": 16.308266003729024,
      "grad_norm": 0.04050297290086746,
      "learning_rate": 8.931898436186312e-06,
      "loss": 0.0046,
      "step": 3280
    },
    {
      "epoch": 16.357986326911124,
      "grad_norm": 0.21743957698345184,
      "learning_rate": 8.90163107449134e-06,
      "loss": 0.005,
      "step": 3290
    },
    {
      "epoch": 16.407706650093225,
      "grad_norm": 1.852054238319397,
      "learning_rate": 8.871363712796368e-06,
      "loss": 0.0066,
      "step": 3300
    },
    {
      "epoch": 16.457426973275325,
      "grad_norm": 0.3708566129207611,
      "learning_rate": 8.841096351101396e-06,
      "loss": 0.005,
      "step": 3310
    },
    {
      "epoch": 16.507147296457426,
      "grad_norm": 0.4036347270011902,
      "learning_rate": 8.810828989406425e-06,
      "loss": 0.0078,
      "step": 3320
    },
    {
      "epoch": 16.556867619639526,
      "grad_norm": 0.05479341000318527,
      "learning_rate": 8.780561627711452e-06,
      "loss": 0.0067,
      "step": 3330
    },
    {
      "epoch": 16.60658794282163,
      "grad_norm": 0.3705449402332306,
      "learning_rate": 8.750294266016479e-06,
      "loss": 0.0031,
      "step": 3340
    },
    {
      "epoch": 16.65630826600373,
      "grad_norm": 0.006246296223253012,
      "learning_rate": 8.720026904321506e-06,
      "loss": 0.0033,
      "step": 3350
    },
    {
      "epoch": 16.70602858918583,
      "grad_norm": 3.0680932998657227,
      "learning_rate": 8.689759542626535e-06,
      "loss": 0.0054,
      "step": 3360
    },
    {
      "epoch": 16.75574891236793,
      "grad_norm": 0.13046295940876007,
      "learning_rate": 8.659492180931562e-06,
      "loss": 0.003,
      "step": 3370
    },
    {
      "epoch": 16.80546923555003,
      "grad_norm": 0.211247980594635,
      "learning_rate": 8.62922481923659e-06,
      "loss": 0.0093,
      "step": 3380
    },
    {
      "epoch": 16.855189558732132,
      "grad_norm": 0.4865247905254364,
      "learning_rate": 8.598957457541619e-06,
      "loss": 0.0102,
      "step": 3390
    },
    {
      "epoch": 16.904909881914232,
      "grad_norm": 0.17633916437625885,
      "learning_rate": 8.568690095846646e-06,
      "loss": 0.0043,
      "step": 3400
    },
    {
      "epoch": 16.954630205096333,
      "grad_norm": 0.3852486312389374,
      "learning_rate": 8.538422734151673e-06,
      "loss": 0.0051,
      "step": 3410
    },
    {
      "epoch": 16.999378495960222,
      "eval_accuracy": 0.9934593023255814,
      "eval_f1": 0.9640479360852197,
      "eval_loss": 0.02848023921251297,
      "eval_precision": 0.9692101740294511,
      "eval_recall": 0.9589403973509933,
      "eval_runtime": 160.5728,
      "eval_samples_per_second": 51.547,
      "eval_steps_per_second": 2.149,
      "step": 3419
    }
  ],
  "logging_steps": 10,
  "max_steps": 6231,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 31,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4727739118128272e+17,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
