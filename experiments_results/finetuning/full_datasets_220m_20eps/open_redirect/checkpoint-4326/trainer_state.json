{
  "best_metric": 0.9438790346030822,
  "best_model_checkpoint": "../saved_models/open_redirect_ep20/checkpoint-4326",
  "epoch": 14.0,
  "eval_steps": 500,
  "global_step": 4326,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003236245954692557,
      "grad_norm": 28.100130081176758,
      "learning_rate": 1.999676375404531e-05,
      "loss": 0.7173,
      "step": 1
    },
    {
      "epoch": 0.032362459546925564,
      "grad_norm": 14.183168411254883,
      "learning_rate": 1.9967637540453075e-05,
      "loss": 0.4968,
      "step": 10
    },
    {
      "epoch": 0.06472491909385113,
      "grad_norm": 14.778162002563477,
      "learning_rate": 1.993527508090615e-05,
      "loss": 0.4205,
      "step": 20
    },
    {
      "epoch": 0.0970873786407767,
      "grad_norm": 15.631199836730957,
      "learning_rate": 1.9902912621359225e-05,
      "loss": 0.4521,
      "step": 30
    },
    {
      "epoch": 0.12944983818770225,
      "grad_norm": 8.152338981628418,
      "learning_rate": 1.9870550161812298e-05,
      "loss": 0.4288,
      "step": 40
    },
    {
      "epoch": 0.16181229773462782,
      "grad_norm": 8.287955284118652,
      "learning_rate": 1.9838187702265374e-05,
      "loss": 0.4191,
      "step": 50
    },
    {
      "epoch": 0.1941747572815534,
      "grad_norm": 11.543176651000977,
      "learning_rate": 1.9805825242718447e-05,
      "loss": 0.4065,
      "step": 60
    },
    {
      "epoch": 0.22653721682847897,
      "grad_norm": 13.46258544921875,
      "learning_rate": 1.977346278317152e-05,
      "loss": 0.414,
      "step": 70
    },
    {
      "epoch": 0.2588996763754045,
      "grad_norm": 6.757519721984863,
      "learning_rate": 1.9741100323624597e-05,
      "loss": 0.3981,
      "step": 80
    },
    {
      "epoch": 0.2912621359223301,
      "grad_norm": 28.516752243041992,
      "learning_rate": 1.970873786407767e-05,
      "loss": 0.4164,
      "step": 90
    },
    {
      "epoch": 0.32362459546925565,
      "grad_norm": 4.933414936065674,
      "learning_rate": 1.9676375404530747e-05,
      "loss": 0.4002,
      "step": 100
    },
    {
      "epoch": 0.3559870550161812,
      "grad_norm": 6.402087688446045,
      "learning_rate": 1.964401294498382e-05,
      "loss": 0.3934,
      "step": 110
    },
    {
      "epoch": 0.3883495145631068,
      "grad_norm": 4.647715091705322,
      "learning_rate": 1.9611650485436893e-05,
      "loss": 0.3925,
      "step": 120
    },
    {
      "epoch": 0.42071197411003236,
      "grad_norm": 4.883022308349609,
      "learning_rate": 1.957928802588997e-05,
      "loss": 0.3747,
      "step": 130
    },
    {
      "epoch": 0.45307443365695793,
      "grad_norm": 6.319106578826904,
      "learning_rate": 1.9546925566343043e-05,
      "loss": 0.355,
      "step": 140
    },
    {
      "epoch": 0.4854368932038835,
      "grad_norm": 3.966155529022217,
      "learning_rate": 1.951456310679612e-05,
      "loss": 0.3628,
      "step": 150
    },
    {
      "epoch": 0.517799352750809,
      "grad_norm": 3.600754499435425,
      "learning_rate": 1.9482200647249193e-05,
      "loss": 0.331,
      "step": 160
    },
    {
      "epoch": 0.5501618122977346,
      "grad_norm": 3.797725200653076,
      "learning_rate": 1.944983818770227e-05,
      "loss": 0.328,
      "step": 170
    },
    {
      "epoch": 0.5825242718446602,
      "grad_norm": 5.401144504547119,
      "learning_rate": 1.9417475728155343e-05,
      "loss": 0.3041,
      "step": 180
    },
    {
      "epoch": 0.6148867313915858,
      "grad_norm": 3.146850109100342,
      "learning_rate": 1.9385113268608416e-05,
      "loss": 0.3387,
      "step": 190
    },
    {
      "epoch": 0.6472491909385113,
      "grad_norm": 3.5875391960144043,
      "learning_rate": 1.9352750809061492e-05,
      "loss": 0.2933,
      "step": 200
    },
    {
      "epoch": 0.6796116504854369,
      "grad_norm": 5.681952953338623,
      "learning_rate": 1.9320388349514565e-05,
      "loss": 0.2814,
      "step": 210
    },
    {
      "epoch": 0.7119741100323624,
      "grad_norm": 5.259305477142334,
      "learning_rate": 1.928802588996764e-05,
      "loss": 0.2981,
      "step": 220
    },
    {
      "epoch": 0.7443365695792881,
      "grad_norm": 3.736238956451416,
      "learning_rate": 1.9255663430420715e-05,
      "loss": 0.3008,
      "step": 230
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 3.7569937705993652,
      "learning_rate": 1.922330097087379e-05,
      "loss": 0.2749,
      "step": 240
    },
    {
      "epoch": 0.8090614886731392,
      "grad_norm": 6.151744365692139,
      "learning_rate": 1.919093851132686e-05,
      "loss": 0.2272,
      "step": 250
    },
    {
      "epoch": 0.8414239482200647,
      "grad_norm": 3.9231786727905273,
      "learning_rate": 1.9158576051779935e-05,
      "loss": 0.2271,
      "step": 260
    },
    {
      "epoch": 0.8737864077669902,
      "grad_norm": 3.2986204624176025,
      "learning_rate": 1.912621359223301e-05,
      "loss": 0.2317,
      "step": 270
    },
    {
      "epoch": 0.9061488673139159,
      "grad_norm": 5.212878704071045,
      "learning_rate": 1.9093851132686084e-05,
      "loss": 0.2449,
      "step": 280
    },
    {
      "epoch": 0.9385113268608414,
      "grad_norm": 3.618311882019043,
      "learning_rate": 1.9061488673139158e-05,
      "loss": 0.225,
      "step": 290
    },
    {
      "epoch": 0.970873786407767,
      "grad_norm": 3.411760091781616,
      "learning_rate": 1.9029126213592234e-05,
      "loss": 0.2218,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9341194968553459,
      "eval_f1": 0.7265013054830286,
      "eval_loss": 0.17074266076087952,
      "eval_precision": 0.8406344410876133,
      "eval_recall": 0.6396551724137931,
      "eval_runtime": 228.5202,
      "eval_samples_per_second": 55.75,
      "eval_steps_per_second": 2.324,
      "step": 309
    },
    {
      "epoch": 1.0032362459546926,
      "grad_norm": 3.531285285949707,
      "learning_rate": 1.8996763754045307e-05,
      "loss": 0.2181,
      "step": 310
    },
    {
      "epoch": 1.035598705501618,
      "grad_norm": 4.136743545532227,
      "learning_rate": 1.8964401294498384e-05,
      "loss": 0.177,
      "step": 320
    },
    {
      "epoch": 1.0679611650485437,
      "grad_norm": 4.5086493492126465,
      "learning_rate": 1.8932038834951457e-05,
      "loss": 0.1811,
      "step": 330
    },
    {
      "epoch": 1.1003236245954693,
      "grad_norm": 5.547194004058838,
      "learning_rate": 1.8899676375404534e-05,
      "loss": 0.1761,
      "step": 340
    },
    {
      "epoch": 1.132686084142395,
      "grad_norm": 5.333426475524902,
      "learning_rate": 1.8867313915857607e-05,
      "loss": 0.1836,
      "step": 350
    },
    {
      "epoch": 1.1650485436893203,
      "grad_norm": 4.7997145652771,
      "learning_rate": 1.883495145631068e-05,
      "loss": 0.1892,
      "step": 360
    },
    {
      "epoch": 1.197411003236246,
      "grad_norm": 4.185267925262451,
      "learning_rate": 1.8802588996763757e-05,
      "loss": 0.1472,
      "step": 370
    },
    {
      "epoch": 1.2297734627831716,
      "grad_norm": 4.133906841278076,
      "learning_rate": 1.877022653721683e-05,
      "loss": 0.1628,
      "step": 380
    },
    {
      "epoch": 1.262135922330097,
      "grad_norm": 3.0450170040130615,
      "learning_rate": 1.8737864077669906e-05,
      "loss": 0.1545,
      "step": 390
    },
    {
      "epoch": 1.2944983818770226,
      "grad_norm": 2.8002498149871826,
      "learning_rate": 1.870550161812298e-05,
      "loss": 0.1404,
      "step": 400
    },
    {
      "epoch": 1.3268608414239482,
      "grad_norm": 9.708704948425293,
      "learning_rate": 1.8673139158576053e-05,
      "loss": 0.1474,
      "step": 410
    },
    {
      "epoch": 1.3592233009708738,
      "grad_norm": 6.865055084228516,
      "learning_rate": 1.864077669902913e-05,
      "loss": 0.1482,
      "step": 420
    },
    {
      "epoch": 1.3915857605177995,
      "grad_norm": 3.0585904121398926,
      "learning_rate": 1.8608414239482202e-05,
      "loss": 0.1322,
      "step": 430
    },
    {
      "epoch": 1.4239482200647249,
      "grad_norm": 3.3453400135040283,
      "learning_rate": 1.8576051779935276e-05,
      "loss": 0.135,
      "step": 440
    },
    {
      "epoch": 1.4563106796116505,
      "grad_norm": 14.937621116638184,
      "learning_rate": 1.8543689320388352e-05,
      "loss": 0.1159,
      "step": 450
    },
    {
      "epoch": 1.4886731391585761,
      "grad_norm": 2.8601415157318115,
      "learning_rate": 1.8511326860841425e-05,
      "loss": 0.1396,
      "step": 460
    },
    {
      "epoch": 1.5210355987055015,
      "grad_norm": 3.2200465202331543,
      "learning_rate": 1.84789644012945e-05,
      "loss": 0.1106,
      "step": 470
    },
    {
      "epoch": 1.5533980582524272,
      "grad_norm": 3.155492067337036,
      "learning_rate": 1.8446601941747575e-05,
      "loss": 0.1128,
      "step": 480
    },
    {
      "epoch": 1.5857605177993528,
      "grad_norm": 6.997700214385986,
      "learning_rate": 1.8414239482200648e-05,
      "loss": 0.1276,
      "step": 490
    },
    {
      "epoch": 1.6181229773462782,
      "grad_norm": 3.879528760910034,
      "learning_rate": 1.838187702265372e-05,
      "loss": 0.1181,
      "step": 500
    },
    {
      "epoch": 1.650485436893204,
      "grad_norm": 2.9035768508911133,
      "learning_rate": 1.8349514563106798e-05,
      "loss": 0.1166,
      "step": 510
    },
    {
      "epoch": 1.6828478964401294,
      "grad_norm": 2.826261520385742,
      "learning_rate": 1.831715210355987e-05,
      "loss": 0.1208,
      "step": 520
    },
    {
      "epoch": 1.715210355987055,
      "grad_norm": 4.510382175445557,
      "learning_rate": 1.8284789644012944e-05,
      "loss": 0.1056,
      "step": 530
    },
    {
      "epoch": 1.7475728155339807,
      "grad_norm": 4.190099239349365,
      "learning_rate": 1.825242718446602e-05,
      "loss": 0.1049,
      "step": 540
    },
    {
      "epoch": 1.779935275080906,
      "grad_norm": 3.5904767513275146,
      "learning_rate": 1.8220064724919094e-05,
      "loss": 0.0855,
      "step": 550
    },
    {
      "epoch": 1.8122977346278317,
      "grad_norm": 5.315802574157715,
      "learning_rate": 1.818770226537217e-05,
      "loss": 0.0887,
      "step": 560
    },
    {
      "epoch": 1.8446601941747574,
      "grad_norm": 6.19271993637085,
      "learning_rate": 1.8155339805825244e-05,
      "loss": 0.1031,
      "step": 570
    },
    {
      "epoch": 1.8770226537216828,
      "grad_norm": 3.4429938793182373,
      "learning_rate": 1.812297734627832e-05,
      "loss": 0.1097,
      "step": 580
    },
    {
      "epoch": 1.9093851132686084,
      "grad_norm": 1.9493407011032104,
      "learning_rate": 1.8090614886731394e-05,
      "loss": 0.1075,
      "step": 590
    },
    {
      "epoch": 1.941747572815534,
      "grad_norm": 9.176253318786621,
      "learning_rate": 1.8058252427184467e-05,
      "loss": 0.1053,
      "step": 600
    },
    {
      "epoch": 1.9741100323624594,
      "grad_norm": 2.7202374935150146,
      "learning_rate": 1.8025889967637543e-05,
      "loss": 0.0962,
      "step": 610
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9705188679245284,
      "eval_f1": 0.8909566734515848,
      "eval_loss": 0.07529179006814957,
      "eval_precision": 0.901706886403767,
      "eval_recall": 0.8804597701149425,
      "eval_runtime": 228.434,
      "eval_samples_per_second": 55.771,
      "eval_steps_per_second": 2.325,
      "step": 618
    },
    {
      "epoch": 2.0064724919093853,
      "grad_norm": 4.770703315734863,
      "learning_rate": 1.7993527508090616e-05,
      "loss": 0.1006,
      "step": 620
    },
    {
      "epoch": 2.0388349514563107,
      "grad_norm": 2.898402214050293,
      "learning_rate": 1.7961165048543693e-05,
      "loss": 0.078,
      "step": 630
    },
    {
      "epoch": 2.071197411003236,
      "grad_norm": 4.255122661590576,
      "learning_rate": 1.7928802588996766e-05,
      "loss": 0.0634,
      "step": 640
    },
    {
      "epoch": 2.103559870550162,
      "grad_norm": 4.292178153991699,
      "learning_rate": 1.789644012944984e-05,
      "loss": 0.0651,
      "step": 650
    },
    {
      "epoch": 2.1359223300970873,
      "grad_norm": 2.9580230712890625,
      "learning_rate": 1.7864077669902916e-05,
      "loss": 0.081,
      "step": 660
    },
    {
      "epoch": 2.168284789644013,
      "grad_norm": 2.0574870109558105,
      "learning_rate": 1.783171521035599e-05,
      "loss": 0.0754,
      "step": 670
    },
    {
      "epoch": 2.2006472491909386,
      "grad_norm": 2.5749192237854004,
      "learning_rate": 1.7799352750809062e-05,
      "loss": 0.0697,
      "step": 680
    },
    {
      "epoch": 2.233009708737864,
      "grad_norm": 2.3495569229125977,
      "learning_rate": 1.776699029126214e-05,
      "loss": 0.067,
      "step": 690
    },
    {
      "epoch": 2.26537216828479,
      "grad_norm": 1.727064609527588,
      "learning_rate": 1.7734627831715212e-05,
      "loss": 0.0683,
      "step": 700
    },
    {
      "epoch": 2.2977346278317152,
      "grad_norm": 1.9327152967453003,
      "learning_rate": 1.7702265372168285e-05,
      "loss": 0.0836,
      "step": 710
    },
    {
      "epoch": 2.3300970873786406,
      "grad_norm": 2.176084041595459,
      "learning_rate": 1.7669902912621362e-05,
      "loss": 0.0615,
      "step": 720
    },
    {
      "epoch": 2.3624595469255665,
      "grad_norm": 3.1527836322784424,
      "learning_rate": 1.7637540453074435e-05,
      "loss": 0.0812,
      "step": 730
    },
    {
      "epoch": 2.394822006472492,
      "grad_norm": 1.7484955787658691,
      "learning_rate": 1.7605177993527508e-05,
      "loss": 0.0622,
      "step": 740
    },
    {
      "epoch": 2.4271844660194173,
      "grad_norm": 2.3196299076080322,
      "learning_rate": 1.7572815533980585e-05,
      "loss": 0.0657,
      "step": 750
    },
    {
      "epoch": 2.459546925566343,
      "grad_norm": 2.509263515472412,
      "learning_rate": 1.7540453074433658e-05,
      "loss": 0.0663,
      "step": 760
    },
    {
      "epoch": 2.4919093851132685,
      "grad_norm": 1.4928743839263916,
      "learning_rate": 1.750809061488673e-05,
      "loss": 0.0728,
      "step": 770
    },
    {
      "epoch": 2.524271844660194,
      "grad_norm": 2.4140193462371826,
      "learning_rate": 1.7475728155339808e-05,
      "loss": 0.0624,
      "step": 780
    },
    {
      "epoch": 2.55663430420712,
      "grad_norm": 2.0750062465667725,
      "learning_rate": 1.744336569579288e-05,
      "loss": 0.0823,
      "step": 790
    },
    {
      "epoch": 2.588996763754045,
      "grad_norm": 1.335776925086975,
      "learning_rate": 1.7411003236245957e-05,
      "loss": 0.0617,
      "step": 800
    },
    {
      "epoch": 2.6213592233009706,
      "grad_norm": 2.581632614135742,
      "learning_rate": 1.737864077669903e-05,
      "loss": 0.0643,
      "step": 810
    },
    {
      "epoch": 2.6537216828478964,
      "grad_norm": 3.8121681213378906,
      "learning_rate": 1.7346278317152107e-05,
      "loss": 0.0658,
      "step": 820
    },
    {
      "epoch": 2.686084142394822,
      "grad_norm": 1.944686770439148,
      "learning_rate": 1.731391585760518e-05,
      "loss": 0.0673,
      "step": 830
    },
    {
      "epoch": 2.7184466019417477,
      "grad_norm": 2.4684882164001465,
      "learning_rate": 1.7281553398058253e-05,
      "loss": 0.0816,
      "step": 840
    },
    {
      "epoch": 2.750809061488673,
      "grad_norm": 4.262505531311035,
      "learning_rate": 1.724919093851133e-05,
      "loss": 0.0552,
      "step": 850
    },
    {
      "epoch": 2.783171521035599,
      "grad_norm": 2.838918447494507,
      "learning_rate": 1.7216828478964403e-05,
      "loss": 0.0597,
      "step": 860
    },
    {
      "epoch": 2.8155339805825244,
      "grad_norm": 3.071948289871216,
      "learning_rate": 1.7184466019417476e-05,
      "loss": 0.0698,
      "step": 870
    },
    {
      "epoch": 2.8478964401294498,
      "grad_norm": 1.7863389253616333,
      "learning_rate": 1.7152103559870553e-05,
      "loss": 0.0404,
      "step": 880
    },
    {
      "epoch": 2.8802588996763756,
      "grad_norm": 2.772186040878296,
      "learning_rate": 1.7119741100323626e-05,
      "loss": 0.0547,
      "step": 890
    },
    {
      "epoch": 2.912621359223301,
      "grad_norm": 2.0692543983459473,
      "learning_rate": 1.70873786407767e-05,
      "loss": 0.0675,
      "step": 900
    },
    {
      "epoch": 2.9449838187702264,
      "grad_norm": 2.623880624771118,
      "learning_rate": 1.7055016181229776e-05,
      "loss": 0.0428,
      "step": 910
    },
    {
      "epoch": 2.9773462783171523,
      "grad_norm": 2.9758753776550293,
      "learning_rate": 1.702265372168285e-05,
      "loss": 0.0581,
      "step": 920
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9790094339622641,
      "eval_f1": 0.9232979029014651,
      "eval_loss": 0.05303119122982025,
      "eval_precision": 0.9230327398047099,
      "eval_recall": 0.9235632183908046,
      "eval_runtime": 230.6113,
      "eval_samples_per_second": 55.244,
      "eval_steps_per_second": 2.303,
      "step": 927
    },
    {
      "epoch": 3.0097087378640777,
      "grad_norm": 2.3731207847595215,
      "learning_rate": 1.6990291262135922e-05,
      "loss": 0.0572,
      "step": 930
    },
    {
      "epoch": 3.042071197411003,
      "grad_norm": 2.338984251022339,
      "learning_rate": 1.6957928802589e-05,
      "loss": 0.0367,
      "step": 940
    },
    {
      "epoch": 3.074433656957929,
      "grad_norm": 1.8185731172561646,
      "learning_rate": 1.6925566343042072e-05,
      "loss": 0.0485,
      "step": 950
    },
    {
      "epoch": 3.1067961165048543,
      "grad_norm": 2.7378346920013428,
      "learning_rate": 1.6893203883495145e-05,
      "loss": 0.0421,
      "step": 960
    },
    {
      "epoch": 3.1391585760517797,
      "grad_norm": 3.011960983276367,
      "learning_rate": 1.686084142394822e-05,
      "loss": 0.0453,
      "step": 970
    },
    {
      "epoch": 3.1715210355987056,
      "grad_norm": 2.4472498893737793,
      "learning_rate": 1.6828478964401295e-05,
      "loss": 0.0449,
      "step": 980
    },
    {
      "epoch": 3.203883495145631,
      "grad_norm": 2.0910778045654297,
      "learning_rate": 1.6796116504854368e-05,
      "loss": 0.0469,
      "step": 990
    },
    {
      "epoch": 3.236245954692557,
      "grad_norm": 3.8901052474975586,
      "learning_rate": 1.6763754045307445e-05,
      "loss": 0.0615,
      "step": 1000
    },
    {
      "epoch": 3.2686084142394822,
      "grad_norm": 2.624915599822998,
      "learning_rate": 1.6731391585760518e-05,
      "loss": 0.0467,
      "step": 1010
    },
    {
      "epoch": 3.3009708737864076,
      "grad_norm": 3.562624216079712,
      "learning_rate": 1.6699029126213594e-05,
      "loss": 0.042,
      "step": 1020
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 3.07130765914917,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0474,
      "step": 1030
    },
    {
      "epoch": 3.365695792880259,
      "grad_norm": 3.028024435043335,
      "learning_rate": 1.6634304207119744e-05,
      "loss": 0.0386,
      "step": 1040
    },
    {
      "epoch": 3.3980582524271843,
      "grad_norm": 2.599231004714966,
      "learning_rate": 1.6601941747572817e-05,
      "loss": 0.0469,
      "step": 1050
    },
    {
      "epoch": 3.43042071197411,
      "grad_norm": 3.172135829925537,
      "learning_rate": 1.6569579288025894e-05,
      "loss": 0.046,
      "step": 1060
    },
    {
      "epoch": 3.4627831715210355,
      "grad_norm": 2.451374053955078,
      "learning_rate": 1.6537216828478967e-05,
      "loss": 0.0597,
      "step": 1070
    },
    {
      "epoch": 3.4951456310679614,
      "grad_norm": 0.8721897006034851,
      "learning_rate": 1.650485436893204e-05,
      "loss": 0.0558,
      "step": 1080
    },
    {
      "epoch": 3.527508090614887,
      "grad_norm": 1.0768256187438965,
      "learning_rate": 1.6472491909385117e-05,
      "loss": 0.0408,
      "step": 1090
    },
    {
      "epoch": 3.559870550161812,
      "grad_norm": 2.4605841636657715,
      "learning_rate": 1.644012944983819e-05,
      "loss": 0.0425,
      "step": 1100
    },
    {
      "epoch": 3.592233009708738,
      "grad_norm": 3.151116132736206,
      "learning_rate": 1.6407766990291263e-05,
      "loss": 0.0461,
      "step": 1110
    },
    {
      "epoch": 3.6245954692556634,
      "grad_norm": 1.3041152954101562,
      "learning_rate": 1.637540453074434e-05,
      "loss": 0.0532,
      "step": 1120
    },
    {
      "epoch": 3.656957928802589,
      "grad_norm": 5.035350322723389,
      "learning_rate": 1.6343042071197413e-05,
      "loss": 0.0503,
      "step": 1130
    },
    {
      "epoch": 3.6893203883495147,
      "grad_norm": 1.3524516820907593,
      "learning_rate": 1.6310679611650486e-05,
      "loss": 0.0461,
      "step": 1140
    },
    {
      "epoch": 3.72168284789644,
      "grad_norm": 2.9785871505737305,
      "learning_rate": 1.6278317152103563e-05,
      "loss": 0.0408,
      "step": 1150
    },
    {
      "epoch": 3.7540453074433655,
      "grad_norm": 1.382780909538269,
      "learning_rate": 1.6245954692556636e-05,
      "loss": 0.0323,
      "step": 1160
    },
    {
      "epoch": 3.7864077669902914,
      "grad_norm": 2.48290753364563,
      "learning_rate": 1.621359223300971e-05,
      "loss": 0.0436,
      "step": 1170
    },
    {
      "epoch": 3.8187702265372168,
      "grad_norm": 3.181445598602295,
      "learning_rate": 1.6181229773462785e-05,
      "loss": 0.0385,
      "step": 1180
    },
    {
      "epoch": 3.851132686084142,
      "grad_norm": 3.2275538444519043,
      "learning_rate": 1.614886731391586e-05,
      "loss": 0.0517,
      "step": 1190
    },
    {
      "epoch": 3.883495145631068,
      "grad_norm": 1.7723280191421509,
      "learning_rate": 1.6116504854368932e-05,
      "loss": 0.0628,
      "step": 1200
    },
    {
      "epoch": 3.9158576051779934,
      "grad_norm": 2.120434045791626,
      "learning_rate": 1.608414239482201e-05,
      "loss": 0.0363,
      "step": 1210
    },
    {
      "epoch": 3.948220064724919,
      "grad_norm": 3.334543228149414,
      "learning_rate": 1.605177993527508e-05,
      "loss": 0.0352,
      "step": 1220
    },
    {
      "epoch": 3.9805825242718447,
      "grad_norm": 3.4952187538146973,
      "learning_rate": 1.6019417475728155e-05,
      "loss": 0.0601,
      "step": 1230
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.982625786163522,
      "eval_f1": 0.9374114981591618,
      "eval_loss": 0.048901114612817764,
      "eval_precision": 0.9240647682858738,
      "eval_recall": 0.9511494252873564,
      "eval_runtime": 229.6775,
      "eval_samples_per_second": 55.469,
      "eval_steps_per_second": 2.312,
      "step": 1236
    },
    {
      "epoch": 4.0129449838187705,
      "grad_norm": 1.227648377418518,
      "learning_rate": 1.598705501618123e-05,
      "loss": 0.0412,
      "step": 1240
    },
    {
      "epoch": 4.0453074433656955,
      "grad_norm": 1.4401384592056274,
      "learning_rate": 1.5954692556634304e-05,
      "loss": 0.0259,
      "step": 1250
    },
    {
      "epoch": 4.077669902912621,
      "grad_norm": 1.0312353372573853,
      "learning_rate": 1.592233009708738e-05,
      "loss": 0.0272,
      "step": 1260
    },
    {
      "epoch": 4.110032362459547,
      "grad_norm": 1.1882812976837158,
      "learning_rate": 1.5889967637540454e-05,
      "loss": 0.0311,
      "step": 1270
    },
    {
      "epoch": 4.142394822006472,
      "grad_norm": 2.331256151199341,
      "learning_rate": 1.585760517799353e-05,
      "loss": 0.0358,
      "step": 1280
    },
    {
      "epoch": 4.174757281553398,
      "grad_norm": 2.560265302658081,
      "learning_rate": 1.5825242718446604e-05,
      "loss": 0.046,
      "step": 1290
    },
    {
      "epoch": 4.207119741100324,
      "grad_norm": 2.1798481941223145,
      "learning_rate": 1.5792880258899677e-05,
      "loss": 0.0314,
      "step": 1300
    },
    {
      "epoch": 4.239482200647249,
      "grad_norm": 1.3979424238204956,
      "learning_rate": 1.5760517799352754e-05,
      "loss": 0.0327,
      "step": 1310
    },
    {
      "epoch": 4.271844660194175,
      "grad_norm": 2.9066364765167236,
      "learning_rate": 1.5728155339805827e-05,
      "loss": 0.0273,
      "step": 1320
    },
    {
      "epoch": 4.3042071197411005,
      "grad_norm": 0.602742612361908,
      "learning_rate": 1.56957928802589e-05,
      "loss": 0.0407,
      "step": 1330
    },
    {
      "epoch": 4.336569579288026,
      "grad_norm": 16.615190505981445,
      "learning_rate": 1.5663430420711977e-05,
      "loss": 0.0328,
      "step": 1340
    },
    {
      "epoch": 4.368932038834951,
      "grad_norm": 1.4086487293243408,
      "learning_rate": 1.563106796116505e-05,
      "loss": 0.0251,
      "step": 1350
    },
    {
      "epoch": 4.401294498381877,
      "grad_norm": 16.64470863342285,
      "learning_rate": 1.5598705501618123e-05,
      "loss": 0.0409,
      "step": 1360
    },
    {
      "epoch": 4.433656957928803,
      "grad_norm": 1.166933298110962,
      "learning_rate": 1.55663430420712e-05,
      "loss": 0.0375,
      "step": 1370
    },
    {
      "epoch": 4.466019417475728,
      "grad_norm": 2.1347172260284424,
      "learning_rate": 1.5533980582524273e-05,
      "loss": 0.0339,
      "step": 1380
    },
    {
      "epoch": 4.498381877022654,
      "grad_norm": 1.481235146522522,
      "learning_rate": 1.5501618122977346e-05,
      "loss": 0.0349,
      "step": 1390
    },
    {
      "epoch": 4.53074433656958,
      "grad_norm": 2.7998015880584717,
      "learning_rate": 1.5469255663430422e-05,
      "loss": 0.04,
      "step": 1400
    },
    {
      "epoch": 4.563106796116505,
      "grad_norm": 1.477156639099121,
      "learning_rate": 1.5436893203883496e-05,
      "loss": 0.0366,
      "step": 1410
    },
    {
      "epoch": 4.5954692556634305,
      "grad_norm": 1.1063876152038574,
      "learning_rate": 1.540453074433657e-05,
      "loss": 0.0427,
      "step": 1420
    },
    {
      "epoch": 4.627831715210356,
      "grad_norm": 2.7487778663635254,
      "learning_rate": 1.5372168284789645e-05,
      "loss": 0.0378,
      "step": 1430
    },
    {
      "epoch": 4.660194174757281,
      "grad_norm": 0.9738099575042725,
      "learning_rate": 1.533980582524272e-05,
      "loss": 0.0438,
      "step": 1440
    },
    {
      "epoch": 4.692556634304207,
      "grad_norm": 3.2156260013580322,
      "learning_rate": 1.530744336569579e-05,
      "loss": 0.039,
      "step": 1450
    },
    {
      "epoch": 4.724919093851133,
      "grad_norm": 1.07814359664917,
      "learning_rate": 1.5275080906148868e-05,
      "loss": 0.0267,
      "step": 1460
    },
    {
      "epoch": 4.757281553398058,
      "grad_norm": 2.7948009967803955,
      "learning_rate": 1.5242718446601943e-05,
      "loss": 0.0327,
      "step": 1470
    },
    {
      "epoch": 4.789644012944984,
      "grad_norm": 3.4602036476135254,
      "learning_rate": 1.5210355987055016e-05,
      "loss": 0.035,
      "step": 1480
    },
    {
      "epoch": 4.82200647249191,
      "grad_norm": 2.1788532733917236,
      "learning_rate": 1.5177993527508093e-05,
      "loss": 0.0475,
      "step": 1490
    },
    {
      "epoch": 4.854368932038835,
      "grad_norm": 1.1306194067001343,
      "learning_rate": 1.5145631067961166e-05,
      "loss": 0.0395,
      "step": 1500
    },
    {
      "epoch": 4.88673139158576,
      "grad_norm": 1.0519189834594727,
      "learning_rate": 1.511326860841424e-05,
      "loss": 0.0448,
      "step": 1510
    },
    {
      "epoch": 4.919093851132686,
      "grad_norm": 1.7584999799728394,
      "learning_rate": 1.5080906148867316e-05,
      "loss": 0.0337,
      "step": 1520
    },
    {
      "epoch": 4.951456310679612,
      "grad_norm": 1.0368165969848633,
      "learning_rate": 1.5048543689320389e-05,
      "loss": 0.026,
      "step": 1530
    },
    {
      "epoch": 4.983818770226537,
      "grad_norm": 2.2345497608184814,
      "learning_rate": 1.5016181229773464e-05,
      "loss": 0.0278,
      "step": 1540
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9825471698113207,
      "eval_f1": 0.9373589164785553,
      "eval_loss": 0.047939468175172806,
      "eval_precision": 0.9207317073170732,
      "eval_recall": 0.9545977011494253,
      "eval_runtime": 227.8952,
      "eval_samples_per_second": 55.903,
      "eval_steps_per_second": 2.33,
      "step": 1545
    },
    {
      "epoch": 5.016181229773463,
      "grad_norm": 1.0791717767715454,
      "learning_rate": 1.4983818770226539e-05,
      "loss": 0.0258,
      "step": 1550
    },
    {
      "epoch": 5.048543689320389,
      "grad_norm": 1.516353726387024,
      "learning_rate": 1.4951456310679614e-05,
      "loss": 0.0196,
      "step": 1560
    },
    {
      "epoch": 5.080906148867314,
      "grad_norm": 0.4899190366268158,
      "learning_rate": 1.4919093851132687e-05,
      "loss": 0.0194,
      "step": 1570
    },
    {
      "epoch": 5.11326860841424,
      "grad_norm": 1.5791455507278442,
      "learning_rate": 1.4886731391585763e-05,
      "loss": 0.0289,
      "step": 1580
    },
    {
      "epoch": 5.145631067961165,
      "grad_norm": 2.415692090988159,
      "learning_rate": 1.4854368932038836e-05,
      "loss": 0.0348,
      "step": 1590
    },
    {
      "epoch": 5.17799352750809,
      "grad_norm": 1.4579722881317139,
      "learning_rate": 1.482200647249191e-05,
      "loss": 0.0224,
      "step": 1600
    },
    {
      "epoch": 5.210355987055016,
      "grad_norm": 0.9478632211685181,
      "learning_rate": 1.4789644012944986e-05,
      "loss": 0.0282,
      "step": 1610
    },
    {
      "epoch": 5.242718446601942,
      "grad_norm": 2.383364677429199,
      "learning_rate": 1.475728155339806e-05,
      "loss": 0.0359,
      "step": 1620
    },
    {
      "epoch": 5.275080906148867,
      "grad_norm": 1.1210163831710815,
      "learning_rate": 1.4724919093851133e-05,
      "loss": 0.0223,
      "step": 1630
    },
    {
      "epoch": 5.307443365695793,
      "grad_norm": 1.4569419622421265,
      "learning_rate": 1.4692556634304209e-05,
      "loss": 0.0337,
      "step": 1640
    },
    {
      "epoch": 5.339805825242719,
      "grad_norm": 1.3594322204589844,
      "learning_rate": 1.4660194174757282e-05,
      "loss": 0.0302,
      "step": 1650
    },
    {
      "epoch": 5.372168284789644,
      "grad_norm": 2.4434216022491455,
      "learning_rate": 1.4627831715210357e-05,
      "loss": 0.031,
      "step": 1660
    },
    {
      "epoch": 5.4045307443365695,
      "grad_norm": 1.167007565498352,
      "learning_rate": 1.4595469255663432e-05,
      "loss": 0.0322,
      "step": 1670
    },
    {
      "epoch": 5.436893203883495,
      "grad_norm": 0.727372407913208,
      "learning_rate": 1.4563106796116507e-05,
      "loss": 0.0408,
      "step": 1680
    },
    {
      "epoch": 5.46925566343042,
      "grad_norm": 1.4067026376724243,
      "learning_rate": 1.453074433656958e-05,
      "loss": 0.0262,
      "step": 1690
    },
    {
      "epoch": 5.501618122977346,
      "grad_norm": 1.5742089748382568,
      "learning_rate": 1.4498381877022657e-05,
      "loss": 0.0251,
      "step": 1700
    },
    {
      "epoch": 5.533980582524272,
      "grad_norm": 2.2857284545898438,
      "learning_rate": 1.446601941747573e-05,
      "loss": 0.0308,
      "step": 1710
    },
    {
      "epoch": 5.566343042071198,
      "grad_norm": 2.9077253341674805,
      "learning_rate": 1.4433656957928803e-05,
      "loss": 0.0358,
      "step": 1720
    },
    {
      "epoch": 5.598705501618123,
      "grad_norm": 2.7430450916290283,
      "learning_rate": 1.440129449838188e-05,
      "loss": 0.029,
      "step": 1730
    },
    {
      "epoch": 5.631067961165049,
      "grad_norm": 1.2573360204696655,
      "learning_rate": 1.4368932038834953e-05,
      "loss": 0.0222,
      "step": 1740
    },
    {
      "epoch": 5.663430420711974,
      "grad_norm": 1.3537832498550415,
      "learning_rate": 1.4336569579288026e-05,
      "loss": 0.0132,
      "step": 1750
    },
    {
      "epoch": 5.6957928802588995,
      "grad_norm": 1.5940558910369873,
      "learning_rate": 1.4304207119741102e-05,
      "loss": 0.0292,
      "step": 1760
    },
    {
      "epoch": 5.728155339805825,
      "grad_norm": 1.5004595518112183,
      "learning_rate": 1.4271844660194176e-05,
      "loss": 0.0361,
      "step": 1770
    },
    {
      "epoch": 5.760517799352751,
      "grad_norm": 1.8120858669281006,
      "learning_rate": 1.423948220064725e-05,
      "loss": 0.031,
      "step": 1780
    },
    {
      "epoch": 5.792880258899676,
      "grad_norm": 1.0709290504455566,
      "learning_rate": 1.4207119741100325e-05,
      "loss": 0.0299,
      "step": 1790
    },
    {
      "epoch": 5.825242718446602,
      "grad_norm": 1.0639992952346802,
      "learning_rate": 1.41747572815534e-05,
      "loss": 0.0343,
      "step": 1800
    },
    {
      "epoch": 5.857605177993528,
      "grad_norm": 0.3845638036727905,
      "learning_rate": 1.4142394822006473e-05,
      "loss": 0.0306,
      "step": 1810
    },
    {
      "epoch": 5.889967637540453,
      "grad_norm": 3.5683133602142334,
      "learning_rate": 1.4110032362459547e-05,
      "loss": 0.0305,
      "step": 1820
    },
    {
      "epoch": 5.922330097087379,
      "grad_norm": 2.176945209503174,
      "learning_rate": 1.4077669902912623e-05,
      "loss": 0.0259,
      "step": 1830
    },
    {
      "epoch": 5.9546925566343045,
      "grad_norm": 1.629014253616333,
      "learning_rate": 1.4045307443365696e-05,
      "loss": 0.0232,
      "step": 1840
    },
    {
      "epoch": 5.9870550161812295,
      "grad_norm": 1.4155406951904297,
      "learning_rate": 1.401294498381877e-05,
      "loss": 0.0321,
      "step": 1850
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.982940251572327,
      "eval_f1": 0.9384047686630713,
      "eval_loss": 0.047982290387153625,
      "eval_precision": 0.9270891755468312,
      "eval_recall": 0.95,
      "eval_runtime": 228.6489,
      "eval_samples_per_second": 55.719,
      "eval_steps_per_second": 2.322,
      "step": 1854
    },
    {
      "epoch": 6.019417475728155,
      "grad_norm": 1.3572105169296265,
      "learning_rate": 1.3980582524271846e-05,
      "loss": 0.0165,
      "step": 1860
    },
    {
      "epoch": 6.051779935275081,
      "grad_norm": 1.226032018661499,
      "learning_rate": 1.394822006472492e-05,
      "loss": 0.0253,
      "step": 1870
    },
    {
      "epoch": 6.084142394822006,
      "grad_norm": 0.1791832596063614,
      "learning_rate": 1.3915857605177994e-05,
      "loss": 0.0163,
      "step": 1880
    },
    {
      "epoch": 6.116504854368932,
      "grad_norm": 1.2926772832870483,
      "learning_rate": 1.3883495145631069e-05,
      "loss": 0.0272,
      "step": 1890
    },
    {
      "epoch": 6.148867313915858,
      "grad_norm": 0.8855411410331726,
      "learning_rate": 1.3851132686084144e-05,
      "loss": 0.0394,
      "step": 1900
    },
    {
      "epoch": 6.181229773462783,
      "grad_norm": 1.4425941705703735,
      "learning_rate": 1.3818770226537217e-05,
      "loss": 0.0157,
      "step": 1910
    },
    {
      "epoch": 6.213592233009709,
      "grad_norm": 1.142771601676941,
      "learning_rate": 1.3786407766990294e-05,
      "loss": 0.026,
      "step": 1920
    },
    {
      "epoch": 6.2459546925566345,
      "grad_norm": 0.4741244614124298,
      "learning_rate": 1.3754045307443367e-05,
      "loss": 0.0171,
      "step": 1930
    },
    {
      "epoch": 6.2783171521035595,
      "grad_norm": 1.835337519645691,
      "learning_rate": 1.372168284789644e-05,
      "loss": 0.0179,
      "step": 1940
    },
    {
      "epoch": 6.310679611650485,
      "grad_norm": 1.430952787399292,
      "learning_rate": 1.3689320388349517e-05,
      "loss": 0.0293,
      "step": 1950
    },
    {
      "epoch": 6.343042071197411,
      "grad_norm": 0.7324807643890381,
      "learning_rate": 1.365695792880259e-05,
      "loss": 0.0229,
      "step": 1960
    },
    {
      "epoch": 6.375404530744337,
      "grad_norm": 0.8478654623031616,
      "learning_rate": 1.3624595469255663e-05,
      "loss": 0.0177,
      "step": 1970
    },
    {
      "epoch": 6.407766990291262,
      "grad_norm": 1.4440816640853882,
      "learning_rate": 1.359223300970874e-05,
      "loss": 0.0273,
      "step": 1980
    },
    {
      "epoch": 6.440129449838188,
      "grad_norm": 0.8064577579498291,
      "learning_rate": 1.3559870550161813e-05,
      "loss": 0.0218,
      "step": 1990
    },
    {
      "epoch": 6.472491909385114,
      "grad_norm": 0.4147037863731384,
      "learning_rate": 1.3527508090614887e-05,
      "loss": 0.0268,
      "step": 2000
    },
    {
      "epoch": 6.504854368932039,
      "grad_norm": 1.9627230167388916,
      "learning_rate": 1.3495145631067962e-05,
      "loss": 0.0257,
      "step": 2010
    },
    {
      "epoch": 6.5372168284789645,
      "grad_norm": 1.6127971410751343,
      "learning_rate": 1.3462783171521037e-05,
      "loss": 0.0222,
      "step": 2020
    },
    {
      "epoch": 6.56957928802589,
      "grad_norm": 1.598862886428833,
      "learning_rate": 1.343042071197411e-05,
      "loss": 0.0368,
      "step": 2030
    },
    {
      "epoch": 6.601941747572815,
      "grad_norm": 0.5367519855499268,
      "learning_rate": 1.3398058252427187e-05,
      "loss": 0.0276,
      "step": 2040
    },
    {
      "epoch": 6.634304207119741,
      "grad_norm": 0.8273904323577881,
      "learning_rate": 1.336569579288026e-05,
      "loss": 0.0253,
      "step": 2050
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 1.6502437591552734,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.026,
      "step": 2060
    },
    {
      "epoch": 6.699029126213592,
      "grad_norm": 2.530778646469116,
      "learning_rate": 1.330097087378641e-05,
      "loss": 0.0314,
      "step": 2070
    },
    {
      "epoch": 6.731391585760518,
      "grad_norm": 1.227658748626709,
      "learning_rate": 1.3268608414239483e-05,
      "loss": 0.0245,
      "step": 2080
    },
    {
      "epoch": 6.763754045307444,
      "grad_norm": 0.97053062915802,
      "learning_rate": 1.3236245954692556e-05,
      "loss": 0.0256,
      "step": 2090
    },
    {
      "epoch": 6.796116504854369,
      "grad_norm": 3.5416207313537598,
      "learning_rate": 1.3203883495145633e-05,
      "loss": 0.0334,
      "step": 2100
    },
    {
      "epoch": 6.828478964401294,
      "grad_norm": 2.395364999771118,
      "learning_rate": 1.3171521035598706e-05,
      "loss": 0.0274,
      "step": 2110
    },
    {
      "epoch": 6.86084142394822,
      "grad_norm": 1.1611775159835815,
      "learning_rate": 1.313915857605178e-05,
      "loss": 0.0192,
      "step": 2120
    },
    {
      "epoch": 6.893203883495145,
      "grad_norm": 0.5287896990776062,
      "learning_rate": 1.3106796116504856e-05,
      "loss": 0.0239,
      "step": 2130
    },
    {
      "epoch": 6.925566343042071,
      "grad_norm": 2.255162477493286,
      "learning_rate": 1.307443365695793e-05,
      "loss": 0.0375,
      "step": 2140
    },
    {
      "epoch": 6.957928802588997,
      "grad_norm": 0.3048645257949829,
      "learning_rate": 1.3042071197411004e-05,
      "loss": 0.0265,
      "step": 2150
    },
    {
      "epoch": 6.990291262135923,
      "grad_norm": 4.401638031005859,
      "learning_rate": 1.300970873786408e-05,
      "loss": 0.0323,
      "step": 2160
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9834119496855346,
      "eval_f1": 0.9391404672627631,
      "eval_loss": 0.05090351775288582,
      "eval_precision": 0.9426751592356688,
      "eval_recall": 0.9356321839080459,
      "eval_runtime": 229.3721,
      "eval_samples_per_second": 55.543,
      "eval_steps_per_second": 2.315,
      "step": 2163
    },
    {
      "epoch": 7.022653721682848,
      "grad_norm": 1.9180413484573364,
      "learning_rate": 1.2977346278317153e-05,
      "loss": 0.0187,
      "step": 2170
    },
    {
      "epoch": 7.055016181229774,
      "grad_norm": 2.569971799850464,
      "learning_rate": 1.2944983818770227e-05,
      "loss": 0.0178,
      "step": 2180
    },
    {
      "epoch": 7.087378640776699,
      "grad_norm": 1.486512541770935,
      "learning_rate": 1.2912621359223303e-05,
      "loss": 0.0195,
      "step": 2190
    },
    {
      "epoch": 7.119741100323624,
      "grad_norm": 1.2007009983062744,
      "learning_rate": 1.2880258899676376e-05,
      "loss": 0.0274,
      "step": 2200
    },
    {
      "epoch": 7.15210355987055,
      "grad_norm": 2.154754877090454,
      "learning_rate": 1.284789644012945e-05,
      "loss": 0.0205,
      "step": 2210
    },
    {
      "epoch": 7.184466019417476,
      "grad_norm": 1.7185299396514893,
      "learning_rate": 1.2815533980582526e-05,
      "loss": 0.0192,
      "step": 2220
    },
    {
      "epoch": 7.216828478964401,
      "grad_norm": 0.6996737122535706,
      "learning_rate": 1.27831715210356e-05,
      "loss": 0.0149,
      "step": 2230
    },
    {
      "epoch": 7.249190938511327,
      "grad_norm": 1.8269433975219727,
      "learning_rate": 1.2750809061488674e-05,
      "loss": 0.0218,
      "step": 2240
    },
    {
      "epoch": 7.281553398058253,
      "grad_norm": 1.6835999488830566,
      "learning_rate": 1.2718446601941749e-05,
      "loss": 0.0175,
      "step": 2250
    },
    {
      "epoch": 7.313915857605178,
      "grad_norm": 2.0832974910736084,
      "learning_rate": 1.2686084142394824e-05,
      "loss": 0.0149,
      "step": 2260
    },
    {
      "epoch": 7.3462783171521036,
      "grad_norm": 0.8654006123542786,
      "learning_rate": 1.2653721682847897e-05,
      "loss": 0.0181,
      "step": 2270
    },
    {
      "epoch": 7.378640776699029,
      "grad_norm": 1.7111964225769043,
      "learning_rate": 1.2621359223300974e-05,
      "loss": 0.0214,
      "step": 2280
    },
    {
      "epoch": 7.411003236245954,
      "grad_norm": 1.3194096088409424,
      "learning_rate": 1.2588996763754047e-05,
      "loss": 0.0217,
      "step": 2290
    },
    {
      "epoch": 7.44336569579288,
      "grad_norm": 1.7172483205795288,
      "learning_rate": 1.255663430420712e-05,
      "loss": 0.0182,
      "step": 2300
    },
    {
      "epoch": 7.475728155339806,
      "grad_norm": 0.8030053377151489,
      "learning_rate": 1.2524271844660197e-05,
      "loss": 0.017,
      "step": 2310
    },
    {
      "epoch": 7.508090614886731,
      "grad_norm": 2.4338972568511963,
      "learning_rate": 1.249190938511327e-05,
      "loss": 0.0229,
      "step": 2320
    },
    {
      "epoch": 7.540453074433657,
      "grad_norm": 0.5961252450942993,
      "learning_rate": 1.2459546925566343e-05,
      "loss": 0.0217,
      "step": 2330
    },
    {
      "epoch": 7.572815533980583,
      "grad_norm": 1.3515557050704956,
      "learning_rate": 1.2427184466019418e-05,
      "loss": 0.0198,
      "step": 2340
    },
    {
      "epoch": 7.605177993527509,
      "grad_norm": 0.9283620119094849,
      "learning_rate": 1.2394822006472493e-05,
      "loss": 0.0243,
      "step": 2350
    },
    {
      "epoch": 7.6375404530744335,
      "grad_norm": 1.621301531791687,
      "learning_rate": 1.2362459546925568e-05,
      "loss": 0.0186,
      "step": 2360
    },
    {
      "epoch": 7.669902912621359,
      "grad_norm": 2.0659732818603516,
      "learning_rate": 1.233009708737864e-05,
      "loss": 0.0294,
      "step": 2370
    },
    {
      "epoch": 7.702265372168284,
      "grad_norm": 0.9079552292823792,
      "learning_rate": 1.2297734627831717e-05,
      "loss": 0.022,
      "step": 2380
    },
    {
      "epoch": 7.73462783171521,
      "grad_norm": 2.191183090209961,
      "learning_rate": 1.226537216828479e-05,
      "loss": 0.0223,
      "step": 2390
    },
    {
      "epoch": 7.766990291262136,
      "grad_norm": 0.8247981071472168,
      "learning_rate": 1.2233009708737864e-05,
      "loss": 0.0139,
      "step": 2400
    },
    {
      "epoch": 7.799352750809062,
      "grad_norm": 0.5162779688835144,
      "learning_rate": 1.220064724919094e-05,
      "loss": 0.0208,
      "step": 2410
    },
    {
      "epoch": 7.831715210355987,
      "grad_norm": 0.5380356311798096,
      "learning_rate": 1.2168284789644013e-05,
      "loss": 0.0145,
      "step": 2420
    },
    {
      "epoch": 7.864077669902913,
      "grad_norm": 2.4254345893859863,
      "learning_rate": 1.2135922330097088e-05,
      "loss": 0.0266,
      "step": 2430
    },
    {
      "epoch": 7.8964401294498385,
      "grad_norm": 1.235791563987732,
      "learning_rate": 1.2103559870550163e-05,
      "loss": 0.0193,
      "step": 2440
    },
    {
      "epoch": 7.9288025889967635,
      "grad_norm": 0.8745328187942505,
      "learning_rate": 1.2071197411003236e-05,
      "loss": 0.0199,
      "step": 2450
    },
    {
      "epoch": 7.961165048543689,
      "grad_norm": 2.3791420459747314,
      "learning_rate": 1.2038834951456311e-05,
      "loss": 0.0212,
      "step": 2460
    },
    {
      "epoch": 7.993527508090615,
      "grad_norm": 2.3752219676971436,
      "learning_rate": 1.2006472491909386e-05,
      "loss": 0.0192,
      "step": 2470
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9838836477987422,
      "eval_f1": 0.9414453013424735,
      "eval_loss": 0.048842903226614,
      "eval_precision": 0.935831913685406,
      "eval_recall": 0.9471264367816092,
      "eval_runtime": 228.5398,
      "eval_samples_per_second": 55.745,
      "eval_steps_per_second": 2.323,
      "step": 2472
    },
    {
      "epoch": 8.025889967637541,
      "grad_norm": 0.9924912452697754,
      "learning_rate": 1.1974110032362461e-05,
      "loss": 0.019,
      "step": 2480
    },
    {
      "epoch": 8.058252427184467,
      "grad_norm": 2.1479332447052,
      "learning_rate": 1.1941747572815534e-05,
      "loss": 0.0184,
      "step": 2490
    },
    {
      "epoch": 8.090614886731391,
      "grad_norm": 1.2442972660064697,
      "learning_rate": 1.190938511326861e-05,
      "loss": 0.0185,
      "step": 2500
    },
    {
      "epoch": 8.122977346278317,
      "grad_norm": 0.43405064940452576,
      "learning_rate": 1.1877022653721684e-05,
      "loss": 0.0122,
      "step": 2510
    },
    {
      "epoch": 8.155339805825243,
      "grad_norm": 0.6623590588569641,
      "learning_rate": 1.1844660194174757e-05,
      "loss": 0.019,
      "step": 2520
    },
    {
      "epoch": 8.187702265372168,
      "grad_norm": 1.3000675439834595,
      "learning_rate": 1.1812297734627834e-05,
      "loss": 0.0156,
      "step": 2530
    },
    {
      "epoch": 8.220064724919094,
      "grad_norm": 0.7326796650886536,
      "learning_rate": 1.1779935275080907e-05,
      "loss": 0.0255,
      "step": 2540
    },
    {
      "epoch": 8.25242718446602,
      "grad_norm": 0.7655932307243347,
      "learning_rate": 1.1747572815533982e-05,
      "loss": 0.0137,
      "step": 2550
    },
    {
      "epoch": 8.284789644012944,
      "grad_norm": 0.7901124954223633,
      "learning_rate": 1.1715210355987056e-05,
      "loss": 0.0202,
      "step": 2560
    },
    {
      "epoch": 8.31715210355987,
      "grad_norm": 0.6395066380500793,
      "learning_rate": 1.168284789644013e-05,
      "loss": 0.0132,
      "step": 2570
    },
    {
      "epoch": 8.349514563106796,
      "grad_norm": 0.8528722524642944,
      "learning_rate": 1.1650485436893204e-05,
      "loss": 0.0222,
      "step": 2580
    },
    {
      "epoch": 8.381877022653722,
      "grad_norm": 0.6297568678855896,
      "learning_rate": 1.161812297734628e-05,
      "loss": 0.0236,
      "step": 2590
    },
    {
      "epoch": 8.414239482200648,
      "grad_norm": 0.24434523284435272,
      "learning_rate": 1.1585760517799354e-05,
      "loss": 0.0175,
      "step": 2600
    },
    {
      "epoch": 8.446601941747574,
      "grad_norm": 4.413974761962891,
      "learning_rate": 1.1553398058252427e-05,
      "loss": 0.0186,
      "step": 2610
    },
    {
      "epoch": 8.478964401294498,
      "grad_norm": 2.6018998622894287,
      "learning_rate": 1.1521035598705504e-05,
      "loss": 0.0216,
      "step": 2620
    },
    {
      "epoch": 8.511326860841423,
      "grad_norm": 2.7766470909118652,
      "learning_rate": 1.1488673139158577e-05,
      "loss": 0.0245,
      "step": 2630
    },
    {
      "epoch": 8.54368932038835,
      "grad_norm": 2.042901039123535,
      "learning_rate": 1.145631067961165e-05,
      "loss": 0.0168,
      "step": 2640
    },
    {
      "epoch": 8.576051779935275,
      "grad_norm": 0.784672200679779,
      "learning_rate": 1.1423948220064727e-05,
      "loss": 0.0203,
      "step": 2650
    },
    {
      "epoch": 8.608414239482201,
      "grad_norm": 3.6491143703460693,
      "learning_rate": 1.13915857605178e-05,
      "loss": 0.0198,
      "step": 2660
    },
    {
      "epoch": 8.640776699029127,
      "grad_norm": 0.8749479055404663,
      "learning_rate": 1.1359223300970875e-05,
      "loss": 0.018,
      "step": 2670
    },
    {
      "epoch": 8.673139158576053,
      "grad_norm": 4.62471342086792,
      "learning_rate": 1.132686084142395e-05,
      "loss": 0.0149,
      "step": 2680
    },
    {
      "epoch": 8.705501618122977,
      "grad_norm": 1.9259480237960815,
      "learning_rate": 1.1294498381877023e-05,
      "loss": 0.0204,
      "step": 2690
    },
    {
      "epoch": 8.737864077669903,
      "grad_norm": 0.799888551235199,
      "learning_rate": 1.1262135922330098e-05,
      "loss": 0.0193,
      "step": 2700
    },
    {
      "epoch": 8.770226537216828,
      "grad_norm": 1.18780517578125,
      "learning_rate": 1.1229773462783173e-05,
      "loss": 0.0136,
      "step": 2710
    },
    {
      "epoch": 8.802588996763754,
      "grad_norm": 0.766192615032196,
      "learning_rate": 1.1197411003236248e-05,
      "loss": 0.0162,
      "step": 2720
    },
    {
      "epoch": 8.83495145631068,
      "grad_norm": 1.317150592803955,
      "learning_rate": 1.116504854368932e-05,
      "loss": 0.0167,
      "step": 2730
    },
    {
      "epoch": 8.867313915857606,
      "grad_norm": 1.3166178464889526,
      "learning_rate": 1.1132686084142397e-05,
      "loss": 0.0196,
      "step": 2740
    },
    {
      "epoch": 8.89967637540453,
      "grad_norm": 1.660171627998352,
      "learning_rate": 1.110032362459547e-05,
      "loss": 0.0208,
      "step": 2750
    },
    {
      "epoch": 8.932038834951456,
      "grad_norm": 3.846954822540283,
      "learning_rate": 1.1067961165048544e-05,
      "loss": 0.0133,
      "step": 2760
    },
    {
      "epoch": 8.964401294498382,
      "grad_norm": 0.8420286178588867,
      "learning_rate": 1.103559870550162e-05,
      "loss": 0.0224,
      "step": 2770
    },
    {
      "epoch": 8.996763754045308,
      "grad_norm": 1.2702046632766724,
      "learning_rate": 1.1003236245954693e-05,
      "loss": 0.0268,
      "step": 2780
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9839622641509433,
      "eval_f1": 0.942242355605889,
      "eval_loss": 0.04928493872284889,
      "eval_precision": 0.9285714285714286,
      "eval_recall": 0.9563218390804598,
      "eval_runtime": 229.6394,
      "eval_samples_per_second": 55.478,
      "eval_steps_per_second": 2.312,
      "step": 2781
    },
    {
      "epoch": 9.029126213592233,
      "grad_norm": 0.5622931718826294,
      "learning_rate": 1.0970873786407768e-05,
      "loss": 0.0164,
      "step": 2790
    },
    {
      "epoch": 9.06148867313916,
      "grad_norm": 1.1902750730514526,
      "learning_rate": 1.0938511326860843e-05,
      "loss": 0.015,
      "step": 2800
    },
    {
      "epoch": 9.093851132686083,
      "grad_norm": 0.3103979229927063,
      "learning_rate": 1.0906148867313916e-05,
      "loss": 0.0132,
      "step": 2810
    },
    {
      "epoch": 9.12621359223301,
      "grad_norm": 2.1448471546173096,
      "learning_rate": 1.0873786407766991e-05,
      "loss": 0.0116,
      "step": 2820
    },
    {
      "epoch": 9.158576051779935,
      "grad_norm": 2.2201614379882812,
      "learning_rate": 1.0841423948220066e-05,
      "loss": 0.0199,
      "step": 2830
    },
    {
      "epoch": 9.190938511326861,
      "grad_norm": 2.075333595275879,
      "learning_rate": 1.0809061488673141e-05,
      "loss": 0.019,
      "step": 2840
    },
    {
      "epoch": 9.223300970873787,
      "grad_norm": 1.0665719509124756,
      "learning_rate": 1.0776699029126214e-05,
      "loss": 0.0097,
      "step": 2850
    },
    {
      "epoch": 9.255663430420713,
      "grad_norm": 1.696720838546753,
      "learning_rate": 1.0744336569579287e-05,
      "loss": 0.0169,
      "step": 2860
    },
    {
      "epoch": 9.288025889967638,
      "grad_norm": 0.7582957148551941,
      "learning_rate": 1.0711974110032364e-05,
      "loss": 0.0162,
      "step": 2870
    },
    {
      "epoch": 9.320388349514563,
      "grad_norm": 1.9358924627304077,
      "learning_rate": 1.0679611650485437e-05,
      "loss": 0.0187,
      "step": 2880
    },
    {
      "epoch": 9.352750809061488,
      "grad_norm": 0.9675357341766357,
      "learning_rate": 1.0647249190938512e-05,
      "loss": 0.0144,
      "step": 2890
    },
    {
      "epoch": 9.385113268608414,
      "grad_norm": 0.6547310948371887,
      "learning_rate": 1.0614886731391587e-05,
      "loss": 0.0198,
      "step": 2900
    },
    {
      "epoch": 9.41747572815534,
      "grad_norm": 1.4639250040054321,
      "learning_rate": 1.0582524271844662e-05,
      "loss": 0.0157,
      "step": 2910
    },
    {
      "epoch": 9.449838187702266,
      "grad_norm": 0.6329661011695862,
      "learning_rate": 1.0550161812297735e-05,
      "loss": 0.0227,
      "step": 2920
    },
    {
      "epoch": 9.482200647249192,
      "grad_norm": 0.09759794175624847,
      "learning_rate": 1.051779935275081e-05,
      "loss": 0.0157,
      "step": 2930
    },
    {
      "epoch": 9.514563106796116,
      "grad_norm": 0.4898570477962494,
      "learning_rate": 1.0485436893203885e-05,
      "loss": 0.0253,
      "step": 2940
    },
    {
      "epoch": 9.546925566343042,
      "grad_norm": 1.3066149950027466,
      "learning_rate": 1.0453074433656958e-05,
      "loss": 0.0213,
      "step": 2950
    },
    {
      "epoch": 9.579288025889968,
      "grad_norm": 0.8595615029335022,
      "learning_rate": 1.0420711974110034e-05,
      "loss": 0.0161,
      "step": 2960
    },
    {
      "epoch": 9.611650485436893,
      "grad_norm": 0.8338367342948914,
      "learning_rate": 1.0388349514563107e-05,
      "loss": 0.0194,
      "step": 2970
    },
    {
      "epoch": 9.64401294498382,
      "grad_norm": 4.106608867645264,
      "learning_rate": 1.035598705501618e-05,
      "loss": 0.014,
      "step": 2980
    },
    {
      "epoch": 9.676375404530745,
      "grad_norm": 0.43970194458961487,
      "learning_rate": 1.0323624595469257e-05,
      "loss": 0.0127,
      "step": 2990
    },
    {
      "epoch": 9.70873786407767,
      "grad_norm": 0.6748088598251343,
      "learning_rate": 1.029126213592233e-05,
      "loss": 0.017,
      "step": 3000
    },
    {
      "epoch": 9.741100323624595,
      "grad_norm": 2.5522091388702393,
      "learning_rate": 1.0258899676375405e-05,
      "loss": 0.0154,
      "step": 3010
    },
    {
      "epoch": 9.77346278317152,
      "grad_norm": 0.7433790564537048,
      "learning_rate": 1.022653721682848e-05,
      "loss": 0.016,
      "step": 3020
    },
    {
      "epoch": 9.805825242718447,
      "grad_norm": 0.5985204577445984,
      "learning_rate": 1.0194174757281555e-05,
      "loss": 0.0156,
      "step": 3030
    },
    {
      "epoch": 9.838187702265373,
      "grad_norm": 1.1882388591766357,
      "learning_rate": 1.0161812297734628e-05,
      "loss": 0.0167,
      "step": 3040
    },
    {
      "epoch": 9.870550161812298,
      "grad_norm": 0.6971453428268433,
      "learning_rate": 1.0129449838187703e-05,
      "loss": 0.0164,
      "step": 3050
    },
    {
      "epoch": 9.902912621359224,
      "grad_norm": 0.8337605595588684,
      "learning_rate": 1.0097087378640778e-05,
      "loss": 0.0137,
      "step": 3060
    },
    {
      "epoch": 9.935275080906148,
      "grad_norm": 1.6130884885787964,
      "learning_rate": 1.0064724919093851e-05,
      "loss": 0.0216,
      "step": 3070
    },
    {
      "epoch": 9.967637540453074,
      "grad_norm": 0.5734055042266846,
      "learning_rate": 1.0032362459546928e-05,
      "loss": 0.02,
      "step": 3080
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.9554724097251892,
      "learning_rate": 1e-05,
      "loss": 0.0176,
      "step": 3090
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9834905660377359,
      "eval_f1": 0.9403409090909091,
      "eval_loss": 0.04661404713988304,
      "eval_precision": 0.9297752808988764,
      "eval_recall": 0.9511494252873564,
      "eval_runtime": 227.6697,
      "eval_samples_per_second": 55.958,
      "eval_steps_per_second": 2.332,
      "step": 3090
    },
    {
      "epoch": 10.032362459546926,
      "grad_norm": 0.24597400426864624,
      "learning_rate": 9.967637540453076e-06,
      "loss": 0.0146,
      "step": 3100
    },
    {
      "epoch": 10.064724919093852,
      "grad_norm": 0.7526976466178894,
      "learning_rate": 9.935275080906149e-06,
      "loss": 0.0173,
      "step": 3110
    },
    {
      "epoch": 10.097087378640778,
      "grad_norm": 1.029160499572754,
      "learning_rate": 9.902912621359224e-06,
      "loss": 0.0118,
      "step": 3120
    },
    {
      "epoch": 10.129449838187702,
      "grad_norm": 0.507642924785614,
      "learning_rate": 9.870550161812299e-06,
      "loss": 0.0153,
      "step": 3130
    },
    {
      "epoch": 10.161812297734627,
      "grad_norm": 0.6731227040290833,
      "learning_rate": 9.838187702265373e-06,
      "loss": 0.0197,
      "step": 3140
    },
    {
      "epoch": 10.194174757281553,
      "grad_norm": 0.36939993500709534,
      "learning_rate": 9.805825242718447e-06,
      "loss": 0.0102,
      "step": 3150
    },
    {
      "epoch": 10.22653721682848,
      "grad_norm": 0.6177302598953247,
      "learning_rate": 9.773462783171522e-06,
      "loss": 0.0148,
      "step": 3160
    },
    {
      "epoch": 10.258899676375405,
      "grad_norm": 0.6962805986404419,
      "learning_rate": 9.741100323624596e-06,
      "loss": 0.017,
      "step": 3170
    },
    {
      "epoch": 10.29126213592233,
      "grad_norm": 0.9052748084068298,
      "learning_rate": 9.708737864077671e-06,
      "loss": 0.0142,
      "step": 3180
    },
    {
      "epoch": 10.323624595469255,
      "grad_norm": 0.2989717125892639,
      "learning_rate": 9.676375404530746e-06,
      "loss": 0.0102,
      "step": 3190
    },
    {
      "epoch": 10.35598705501618,
      "grad_norm": 0.7211737632751465,
      "learning_rate": 9.64401294498382e-06,
      "loss": 0.0167,
      "step": 3200
    },
    {
      "epoch": 10.388349514563107,
      "grad_norm": 2.657531976699829,
      "learning_rate": 9.611650485436894e-06,
      "loss": 0.0169,
      "step": 3210
    },
    {
      "epoch": 10.420711974110032,
      "grad_norm": 1.2761958837509155,
      "learning_rate": 9.579288025889967e-06,
      "loss": 0.0149,
      "step": 3220
    },
    {
      "epoch": 10.453074433656958,
      "grad_norm": 1.7560971975326538,
      "learning_rate": 9.546925566343042e-06,
      "loss": 0.017,
      "step": 3230
    },
    {
      "epoch": 10.485436893203884,
      "grad_norm": 0.7897120714187622,
      "learning_rate": 9.514563106796117e-06,
      "loss": 0.0105,
      "step": 3240
    },
    {
      "epoch": 10.517799352750808,
      "grad_norm": 1.099757194519043,
      "learning_rate": 9.482200647249192e-06,
      "loss": 0.0175,
      "step": 3250
    },
    {
      "epoch": 10.550161812297734,
      "grad_norm": 0.959750235080719,
      "learning_rate": 9.449838187702267e-06,
      "loss": 0.0139,
      "step": 3260
    },
    {
      "epoch": 10.58252427184466,
      "grad_norm": 0.8094189167022705,
      "learning_rate": 9.41747572815534e-06,
      "loss": 0.0255,
      "step": 3270
    },
    {
      "epoch": 10.614886731391586,
      "grad_norm": 5.1109442710876465,
      "learning_rate": 9.385113268608415e-06,
      "loss": 0.016,
      "step": 3280
    },
    {
      "epoch": 10.647249190938512,
      "grad_norm": 0.9759031534194946,
      "learning_rate": 9.35275080906149e-06,
      "loss": 0.0095,
      "step": 3290
    },
    {
      "epoch": 10.679611650485437,
      "grad_norm": 1.0039774179458618,
      "learning_rate": 9.320388349514565e-06,
      "loss": 0.0122,
      "step": 3300
    },
    {
      "epoch": 10.711974110032362,
      "grad_norm": 0.7899894118309021,
      "learning_rate": 9.288025889967638e-06,
      "loss": 0.0145,
      "step": 3310
    },
    {
      "epoch": 10.744336569579287,
      "grad_norm": 0.6022337675094604,
      "learning_rate": 9.255663430420713e-06,
      "loss": 0.018,
      "step": 3320
    },
    {
      "epoch": 10.776699029126213,
      "grad_norm": 2.1109774112701416,
      "learning_rate": 9.223300970873788e-06,
      "loss": 0.0204,
      "step": 3330
    },
    {
      "epoch": 10.809061488673139,
      "grad_norm": 0.9087496995925903,
      "learning_rate": 9.19093851132686e-06,
      "loss": 0.0162,
      "step": 3340
    },
    {
      "epoch": 10.841423948220065,
      "grad_norm": 1.0797425508499146,
      "learning_rate": 9.158576051779936e-06,
      "loss": 0.0137,
      "step": 3350
    },
    {
      "epoch": 10.87378640776699,
      "grad_norm": 0.7148990035057068,
      "learning_rate": 9.12621359223301e-06,
      "loss": 0.0223,
      "step": 3360
    },
    {
      "epoch": 10.906148867313917,
      "grad_norm": 0.4527067542076111,
      "learning_rate": 9.093851132686085e-06,
      "loss": 0.0126,
      "step": 3370
    },
    {
      "epoch": 10.93851132686084,
      "grad_norm": 2.5620388984680176,
      "learning_rate": 9.06148867313916e-06,
      "loss": 0.0159,
      "step": 3380
    },
    {
      "epoch": 10.970873786407767,
      "grad_norm": 0.9531296491622925,
      "learning_rate": 9.029126213592233e-06,
      "loss": 0.0167,
      "step": 3390
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.9841194968553459,
      "eval_f1": 0.9422196796338673,
      "eval_loss": 0.05362393334507942,
      "eval_precision": 0.9379271070615034,
      "eval_recall": 0.946551724137931,
      "eval_runtime": 228.4074,
      "eval_samples_per_second": 55.778,
      "eval_steps_per_second": 2.325,
      "step": 3399
    },
    {
      "epoch": 11.003236245954692,
      "grad_norm": 0.5208390355110168,
      "learning_rate": 8.996763754045308e-06,
      "loss": 0.0167,
      "step": 3400
    },
    {
      "epoch": 11.035598705501618,
      "grad_norm": 2.292367696762085,
      "learning_rate": 8.964401294498383e-06,
      "loss": 0.0149,
      "step": 3410
    },
    {
      "epoch": 11.067961165048544,
      "grad_norm": 4.662018775939941,
      "learning_rate": 8.932038834951458e-06,
      "loss": 0.0091,
      "step": 3420
    },
    {
      "epoch": 11.10032362459547,
      "grad_norm": 0.07979622483253479,
      "learning_rate": 8.899676375404531e-06,
      "loss": 0.0103,
      "step": 3430
    },
    {
      "epoch": 11.132686084142394,
      "grad_norm": 0.6102339029312134,
      "learning_rate": 8.867313915857606e-06,
      "loss": 0.0202,
      "step": 3440
    },
    {
      "epoch": 11.16504854368932,
      "grad_norm": 0.7909083366394043,
      "learning_rate": 8.834951456310681e-06,
      "loss": 0.0109,
      "step": 3450
    },
    {
      "epoch": 11.197411003236246,
      "grad_norm": 1.9342710971832275,
      "learning_rate": 8.802588996763754e-06,
      "loss": 0.016,
      "step": 3460
    },
    {
      "epoch": 11.229773462783172,
      "grad_norm": 2.669363498687744,
      "learning_rate": 8.770226537216829e-06,
      "loss": 0.0132,
      "step": 3470
    },
    {
      "epoch": 11.262135922330097,
      "grad_norm": 0.9051795601844788,
      "learning_rate": 8.737864077669904e-06,
      "loss": 0.016,
      "step": 3480
    },
    {
      "epoch": 11.294498381877023,
      "grad_norm": 0.5316286683082581,
      "learning_rate": 8.705501618122979e-06,
      "loss": 0.0135,
      "step": 3490
    },
    {
      "epoch": 11.326860841423947,
      "grad_norm": 0.6627459526062012,
      "learning_rate": 8.673139158576054e-06,
      "loss": 0.0081,
      "step": 3500
    },
    {
      "epoch": 11.359223300970873,
      "grad_norm": 0.6589155197143555,
      "learning_rate": 8.640776699029127e-06,
      "loss": 0.0142,
      "step": 3510
    },
    {
      "epoch": 11.391585760517799,
      "grad_norm": 1.318164348602295,
      "learning_rate": 8.608414239482202e-06,
      "loss": 0.0173,
      "step": 3520
    },
    {
      "epoch": 11.423948220064725,
      "grad_norm": 0.603262186050415,
      "learning_rate": 8.576051779935276e-06,
      "loss": 0.0108,
      "step": 3530
    },
    {
      "epoch": 11.45631067961165,
      "grad_norm": 0.7111062407493591,
      "learning_rate": 8.54368932038835e-06,
      "loss": 0.0109,
      "step": 3540
    },
    {
      "epoch": 11.488673139158577,
      "grad_norm": 0.4108533561229706,
      "learning_rate": 8.511326860841424e-06,
      "loss": 0.0188,
      "step": 3550
    },
    {
      "epoch": 11.521035598705502,
      "grad_norm": 0.950138509273529,
      "learning_rate": 8.4789644012945e-06,
      "loss": 0.0141,
      "step": 3560
    },
    {
      "epoch": 11.553398058252426,
      "grad_norm": 0.2684799134731293,
      "learning_rate": 8.446601941747573e-06,
      "loss": 0.0121,
      "step": 3570
    },
    {
      "epoch": 11.585760517799352,
      "grad_norm": 0.27068647742271423,
      "learning_rate": 8.414239482200647e-06,
      "loss": 0.0086,
      "step": 3580
    },
    {
      "epoch": 11.618122977346278,
      "grad_norm": 5.223369598388672,
      "learning_rate": 8.381877022653722e-06,
      "loss": 0.0221,
      "step": 3590
    },
    {
      "epoch": 11.650485436893204,
      "grad_norm": 0.23008041083812714,
      "learning_rate": 8.349514563106797e-06,
      "loss": 0.008,
      "step": 3600
    },
    {
      "epoch": 11.68284789644013,
      "grad_norm": 0.35099759697914124,
      "learning_rate": 8.317152103559872e-06,
      "loss": 0.0138,
      "step": 3610
    },
    {
      "epoch": 11.715210355987056,
      "grad_norm": 7.092932224273682,
      "learning_rate": 8.284789644012947e-06,
      "loss": 0.0215,
      "step": 3620
    },
    {
      "epoch": 11.74757281553398,
      "grad_norm": 3.522602081298828,
      "learning_rate": 8.25242718446602e-06,
      "loss": 0.0165,
      "step": 3630
    },
    {
      "epoch": 11.779935275080906,
      "grad_norm": 0.3551856279373169,
      "learning_rate": 8.220064724919095e-06,
      "loss": 0.0191,
      "step": 3640
    },
    {
      "epoch": 11.812297734627832,
      "grad_norm": 1.595644235610962,
      "learning_rate": 8.18770226537217e-06,
      "loss": 0.0151,
      "step": 3650
    },
    {
      "epoch": 11.844660194174757,
      "grad_norm": 0.7120805978775024,
      "learning_rate": 8.155339805825243e-06,
      "loss": 0.0158,
      "step": 3660
    },
    {
      "epoch": 11.877022653721683,
      "grad_norm": 0.5746515393257141,
      "learning_rate": 8.122977346278318e-06,
      "loss": 0.022,
      "step": 3670
    },
    {
      "epoch": 11.909385113268609,
      "grad_norm": 0.6896653771400452,
      "learning_rate": 8.090614886731393e-06,
      "loss": 0.0146,
      "step": 3680
    },
    {
      "epoch": 11.941747572815533,
      "grad_norm": 0.4898199439048767,
      "learning_rate": 8.058252427184466e-06,
      "loss": 0.0123,
      "step": 3690
    },
    {
      "epoch": 11.974110032362459,
      "grad_norm": 2.467517614364624,
      "learning_rate": 8.02588996763754e-06,
      "loss": 0.0146,
      "step": 3700
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.9839622641509433,
      "eval_f1": 0.941814033086138,
      "eval_loss": 0.05490109324455261,
      "eval_precision": 0.934881087202718,
      "eval_recall": 0.9488505747126437,
      "eval_runtime": 229.6063,
      "eval_samples_per_second": 55.486,
      "eval_steps_per_second": 2.313,
      "step": 3708
    },
    {
      "epoch": 12.006472491909385,
      "grad_norm": 0.9426917433738708,
      "learning_rate": 7.993527508090616e-06,
      "loss": 0.0108,
      "step": 3710
    },
    {
      "epoch": 12.03883495145631,
      "grad_norm": 0.5052424669265747,
      "learning_rate": 7.96116504854369e-06,
      "loss": 0.0127,
      "step": 3720
    },
    {
      "epoch": 12.071197411003237,
      "grad_norm": 0.02997526526451111,
      "learning_rate": 7.928802588996765e-06,
      "loss": 0.0136,
      "step": 3730
    },
    {
      "epoch": 12.103559870550162,
      "grad_norm": 0.7108815908432007,
      "learning_rate": 7.896440129449839e-06,
      "loss": 0.0128,
      "step": 3740
    },
    {
      "epoch": 12.135922330097088,
      "grad_norm": 0.8592578768730164,
      "learning_rate": 7.864077669902913e-06,
      "loss": 0.0137,
      "step": 3750
    },
    {
      "epoch": 12.168284789644012,
      "grad_norm": 0.5383979678153992,
      "learning_rate": 7.831715210355988e-06,
      "loss": 0.01,
      "step": 3760
    },
    {
      "epoch": 12.200647249190938,
      "grad_norm": 0.4203982949256897,
      "learning_rate": 7.799352750809061e-06,
      "loss": 0.0088,
      "step": 3770
    },
    {
      "epoch": 12.233009708737864,
      "grad_norm": 0.021359506994485855,
      "learning_rate": 7.766990291262136e-06,
      "loss": 0.012,
      "step": 3780
    },
    {
      "epoch": 12.26537216828479,
      "grad_norm": 0.7436479330062866,
      "learning_rate": 7.734627831715211e-06,
      "loss": 0.0134,
      "step": 3790
    },
    {
      "epoch": 12.297734627831716,
      "grad_norm": 0.5497457385063171,
      "learning_rate": 7.702265372168284e-06,
      "loss": 0.0111,
      "step": 3800
    },
    {
      "epoch": 12.330097087378642,
      "grad_norm": 0.9336520433425903,
      "learning_rate": 7.66990291262136e-06,
      "loss": 0.0101,
      "step": 3810
    },
    {
      "epoch": 12.362459546925566,
      "grad_norm": 0.8714805245399475,
      "learning_rate": 7.637540453074434e-06,
      "loss": 0.0098,
      "step": 3820
    },
    {
      "epoch": 12.394822006472491,
      "grad_norm": 1.8595737218856812,
      "learning_rate": 7.605177993527508e-06,
      "loss": 0.0101,
      "step": 3830
    },
    {
      "epoch": 12.427184466019417,
      "grad_norm": 1.102599859237671,
      "learning_rate": 7.572815533980583e-06,
      "loss": 0.0133,
      "step": 3840
    },
    {
      "epoch": 12.459546925566343,
      "grad_norm": 0.736469566822052,
      "learning_rate": 7.540453074433658e-06,
      "loss": 0.0143,
      "step": 3850
    },
    {
      "epoch": 12.491909385113269,
      "grad_norm": 0.6656847596168518,
      "learning_rate": 7.508090614886732e-06,
      "loss": 0.0121,
      "step": 3860
    },
    {
      "epoch": 12.524271844660195,
      "grad_norm": 0.36740773916244507,
      "learning_rate": 7.475728155339807e-06,
      "loss": 0.0141,
      "step": 3870
    },
    {
      "epoch": 12.556634304207119,
      "grad_norm": 0.45268407464027405,
      "learning_rate": 7.443365695792882e-06,
      "loss": 0.0133,
      "step": 3880
    },
    {
      "epoch": 12.588996763754045,
      "grad_norm": 0.6642335057258606,
      "learning_rate": 7.411003236245955e-06,
      "loss": 0.0165,
      "step": 3890
    },
    {
      "epoch": 12.62135922330097,
      "grad_norm": 0.9040948748588562,
      "learning_rate": 7.37864077669903e-06,
      "loss": 0.0202,
      "step": 3900
    },
    {
      "epoch": 12.653721682847896,
      "grad_norm": 1.786261796951294,
      "learning_rate": 7.3462783171521046e-06,
      "loss": 0.0163,
      "step": 3910
    },
    {
      "epoch": 12.686084142394822,
      "grad_norm": 1.0224920511245728,
      "learning_rate": 7.3139158576051786e-06,
      "loss": 0.0139,
      "step": 3920
    },
    {
      "epoch": 12.718446601941748,
      "grad_norm": 0.4279027581214905,
      "learning_rate": 7.2815533980582534e-06,
      "loss": 0.0118,
      "step": 3930
    },
    {
      "epoch": 12.750809061488674,
      "grad_norm": 0.692698061466217,
      "learning_rate": 7.249190938511328e-06,
      "loss": 0.0084,
      "step": 3940
    },
    {
      "epoch": 12.783171521035598,
      "grad_norm": 5.367372035980225,
      "learning_rate": 7.2168284789644015e-06,
      "loss": 0.0159,
      "step": 3950
    },
    {
      "epoch": 12.815533980582524,
      "grad_norm": 1.4452909231185913,
      "learning_rate": 7.184466019417476e-06,
      "loss": 0.0146,
      "step": 3960
    },
    {
      "epoch": 12.84789644012945,
      "grad_norm": 1.24327552318573,
      "learning_rate": 7.152103559870551e-06,
      "loss": 0.0162,
      "step": 3970
    },
    {
      "epoch": 12.880258899676376,
      "grad_norm": 0.2731983959674835,
      "learning_rate": 7.119741100323625e-06,
      "loss": 0.0152,
      "step": 3980
    },
    {
      "epoch": 12.912621359223301,
      "grad_norm": 0.8740742206573486,
      "learning_rate": 7.0873786407767e-06,
      "loss": 0.0117,
      "step": 3990
    },
    {
      "epoch": 12.944983818770227,
      "grad_norm": 0.7836674451828003,
      "learning_rate": 7.055016181229773e-06,
      "loss": 0.0225,
      "step": 4000
    },
    {
      "epoch": 12.977346278317151,
      "grad_norm": 0.6686720848083496,
      "learning_rate": 7.022653721682848e-06,
      "loss": 0.0197,
      "step": 4010
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.9834905660377359,
      "eval_f1": 0.940068493150685,
      "eval_loss": 0.052326004952192307,
      "eval_precision": 0.9336734693877551,
      "eval_recall": 0.946551724137931,
      "eval_runtime": 228.4081,
      "eval_samples_per_second": 55.777,
      "eval_steps_per_second": 2.325,
      "step": 4017
    },
    {
      "epoch": 13.009708737864077,
      "grad_norm": 0.3721465468406677,
      "learning_rate": 6.990291262135923e-06,
      "loss": 0.0102,
      "step": 4020
    },
    {
      "epoch": 13.042071197411003,
      "grad_norm": 0.18981947004795074,
      "learning_rate": 6.957928802588997e-06,
      "loss": 0.0085,
      "step": 4030
    },
    {
      "epoch": 13.074433656957929,
      "grad_norm": 1.353758692741394,
      "learning_rate": 6.925566343042072e-06,
      "loss": 0.0141,
      "step": 4040
    },
    {
      "epoch": 13.106796116504855,
      "grad_norm": 0.5993704199790955,
      "learning_rate": 6.893203883495147e-06,
      "loss": 0.0095,
      "step": 4050
    },
    {
      "epoch": 13.13915857605178,
      "grad_norm": 0.6389353275299072,
      "learning_rate": 6.86084142394822e-06,
      "loss": 0.0096,
      "step": 4060
    },
    {
      "epoch": 13.171521035598705,
      "grad_norm": 1.1902544498443604,
      "learning_rate": 6.828478964401295e-06,
      "loss": 0.0107,
      "step": 4070
    },
    {
      "epoch": 13.20388349514563,
      "grad_norm": 0.12469145655632019,
      "learning_rate": 6.79611650485437e-06,
      "loss": 0.0142,
      "step": 4080
    },
    {
      "epoch": 13.236245954692556,
      "grad_norm": 0.45201876759529114,
      "learning_rate": 6.763754045307444e-06,
      "loss": 0.0087,
      "step": 4090
    },
    {
      "epoch": 13.268608414239482,
      "grad_norm": 0.8954793810844421,
      "learning_rate": 6.731391585760519e-06,
      "loss": 0.013,
      "step": 4100
    },
    {
      "epoch": 13.300970873786408,
      "grad_norm": 0.5281984806060791,
      "learning_rate": 6.6990291262135935e-06,
      "loss": 0.0123,
      "step": 4110
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 1.9418889284133911,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0114,
      "step": 4120
    },
    {
      "epoch": 13.36569579288026,
      "grad_norm": 0.43733689188957214,
      "learning_rate": 6.6343042071197415e-06,
      "loss": 0.0117,
      "step": 4130
    },
    {
      "epoch": 13.398058252427184,
      "grad_norm": 2.497884511947632,
      "learning_rate": 6.601941747572816e-06,
      "loss": 0.0208,
      "step": 4140
    },
    {
      "epoch": 13.43042071197411,
      "grad_norm": 0.5377058982849121,
      "learning_rate": 6.56957928802589e-06,
      "loss": 0.0096,
      "step": 4150
    },
    {
      "epoch": 13.462783171521036,
      "grad_norm": 0.0052729155868291855,
      "learning_rate": 6.537216828478965e-06,
      "loss": 0.0057,
      "step": 4160
    },
    {
      "epoch": 13.495145631067961,
      "grad_norm": 0.6940239667892456,
      "learning_rate": 6.50485436893204e-06,
      "loss": 0.0084,
      "step": 4170
    },
    {
      "epoch": 13.527508090614887,
      "grad_norm": 1.5737117528915405,
      "learning_rate": 6.472491909385113e-06,
      "loss": 0.0155,
      "step": 4180
    },
    {
      "epoch": 13.559870550161813,
      "grad_norm": 0.4020974338054657,
      "learning_rate": 6.440129449838188e-06,
      "loss": 0.0119,
      "step": 4190
    },
    {
      "epoch": 13.592233009708737,
      "grad_norm": 0.8695218563079834,
      "learning_rate": 6.407766990291263e-06,
      "loss": 0.0128,
      "step": 4200
    },
    {
      "epoch": 13.624595469255663,
      "grad_norm": 0.5817437767982483,
      "learning_rate": 6.375404530744337e-06,
      "loss": 0.0148,
      "step": 4210
    },
    {
      "epoch": 13.656957928802589,
      "grad_norm": 0.3230096399784088,
      "learning_rate": 6.343042071197412e-06,
      "loss": 0.0114,
      "step": 4220
    },
    {
      "epoch": 13.689320388349515,
      "grad_norm": 0.9753721952438354,
      "learning_rate": 6.310679611650487e-06,
      "loss": 0.013,
      "step": 4230
    },
    {
      "epoch": 13.72168284789644,
      "grad_norm": 0.2778748869895935,
      "learning_rate": 6.27831715210356e-06,
      "loss": 0.0161,
      "step": 4240
    },
    {
      "epoch": 13.754045307443366,
      "grad_norm": 0.6534509658813477,
      "learning_rate": 6.245954692556635e-06,
      "loss": 0.0089,
      "step": 4250
    },
    {
      "epoch": 13.78640776699029,
      "grad_norm": 0.2565572261810303,
      "learning_rate": 6.213592233009709e-06,
      "loss": 0.0094,
      "step": 4260
    },
    {
      "epoch": 13.818770226537216,
      "grad_norm": 0.30461588501930237,
      "learning_rate": 6.181229773462784e-06,
      "loss": 0.0147,
      "step": 4270
    },
    {
      "epoch": 13.851132686084142,
      "grad_norm": 0.6926625370979309,
      "learning_rate": 6.148867313915859e-06,
      "loss": 0.011,
      "step": 4280
    },
    {
      "epoch": 13.883495145631068,
      "grad_norm": 0.7308045029640198,
      "learning_rate": 6.116504854368932e-06,
      "loss": 0.0125,
      "step": 4290
    },
    {
      "epoch": 13.915857605177994,
      "grad_norm": 0.5592593550682068,
      "learning_rate": 6.084142394822007e-06,
      "loss": 0.0112,
      "step": 4300
    },
    {
      "epoch": 13.94822006472492,
      "grad_norm": 0.3896554112434387,
      "learning_rate": 6.0517799352750815e-06,
      "loss": 0.0117,
      "step": 4310
    },
    {
      "epoch": 13.980582524271846,
      "grad_norm": 0.5651114583015442,
      "learning_rate": 6.0194174757281556e-06,
      "loss": 0.0098,
      "step": 4320
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.9848270440251572,
      "eval_f1": 0.9438790346030822,
      "eval_loss": 0.054832763969898224,
      "eval_precision": 0.9552678045909359,
      "eval_recall": 0.9327586206896552,
      "eval_runtime": 228.3895,
      "eval_samples_per_second": 55.782,
      "eval_steps_per_second": 2.325,
      "step": 4326
    }
  ],
  "logging_steps": 10,
  "max_steps": 6180,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0890219553731584e+17,
  "train_batch_size": 192,
  "trial_name": null,
  "trial_params": null
}
