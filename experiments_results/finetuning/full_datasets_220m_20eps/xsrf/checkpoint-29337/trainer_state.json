{
  "best_metric": 0.9753959276018099,
  "best_model_checkpoint": "../saved_models/xsrf_ep20/checkpoint-29337",
  "epoch": 11.0,
  "eval_steps": 500,
  "global_step": 29337,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0003749531308586427,
      "grad_norm": 43.79384231567383,
      "learning_rate": 1.999962504686914e-05,
      "loss": 0.9337,
      "step": 1
    },
    {
      "epoch": 0.0037495313085864268,
      "grad_norm": 12.945588111877441,
      "learning_rate": 1.9996250468691418e-05,
      "loss": 0.5166,
      "step": 10
    },
    {
      "epoch": 0.0074990626171728535,
      "grad_norm": 34.692604064941406,
      "learning_rate": 1.9992500937382827e-05,
      "loss": 0.4,
      "step": 20
    },
    {
      "epoch": 0.01124859392575928,
      "grad_norm": 11.817858695983887,
      "learning_rate": 1.9988751406074243e-05,
      "loss": 0.3846,
      "step": 30
    },
    {
      "epoch": 0.014998125234345707,
      "grad_norm": 12.485127449035645,
      "learning_rate": 1.9985001874765655e-05,
      "loss": 0.498,
      "step": 40
    },
    {
      "epoch": 0.018747656542932135,
      "grad_norm": 15.790155410766602,
      "learning_rate": 1.998125234345707e-05,
      "loss": 0.4365,
      "step": 50
    },
    {
      "epoch": 0.02249718785151856,
      "grad_norm": 13.60780143737793,
      "learning_rate": 1.9977502812148483e-05,
      "loss": 0.3952,
      "step": 60
    },
    {
      "epoch": 0.026246719160104987,
      "grad_norm": 46.63576126098633,
      "learning_rate": 1.9973753280839896e-05,
      "loss": 0.4443,
      "step": 70
    },
    {
      "epoch": 0.029996250468691414,
      "grad_norm": 13.543705940246582,
      "learning_rate": 1.9970003749531312e-05,
      "loss": 0.4431,
      "step": 80
    },
    {
      "epoch": 0.03374578177727784,
      "grad_norm": 65.52336120605469,
      "learning_rate": 1.9966254218222724e-05,
      "loss": 0.3523,
      "step": 90
    },
    {
      "epoch": 0.03749531308586427,
      "grad_norm": 15.419509887695312,
      "learning_rate": 1.9962504686914137e-05,
      "loss": 0.4061,
      "step": 100
    },
    {
      "epoch": 0.0412448443944507,
      "grad_norm": 27.059593200683594,
      "learning_rate": 1.9958755155605553e-05,
      "loss": 0.4481,
      "step": 110
    },
    {
      "epoch": 0.04499437570303712,
      "grad_norm": 8.575799942016602,
      "learning_rate": 1.9955005624296965e-05,
      "loss": 0.4152,
      "step": 120
    },
    {
      "epoch": 0.048743907011623545,
      "grad_norm": 17.290149688720703,
      "learning_rate": 1.9951256092988378e-05,
      "loss": 0.3581,
      "step": 130
    },
    {
      "epoch": 0.05249343832020997,
      "grad_norm": 13.087054252624512,
      "learning_rate": 1.9947506561679793e-05,
      "loss": 0.3555,
      "step": 140
    },
    {
      "epoch": 0.0562429696287964,
      "grad_norm": 11.824036598205566,
      "learning_rate": 1.9943757030371206e-05,
      "loss": 0.3969,
      "step": 150
    },
    {
      "epoch": 0.05999250093738283,
      "grad_norm": 10.351150512695312,
      "learning_rate": 1.994000749906262e-05,
      "loss": 0.3644,
      "step": 160
    },
    {
      "epoch": 0.06374203224596925,
      "grad_norm": 10.63371467590332,
      "learning_rate": 1.993625796775403e-05,
      "loss": 0.4089,
      "step": 170
    },
    {
      "epoch": 0.06749156355455568,
      "grad_norm": 13.405364990234375,
      "learning_rate": 1.9932508436445447e-05,
      "loss": 0.4295,
      "step": 180
    },
    {
      "epoch": 0.0712410948631421,
      "grad_norm": 7.484456539154053,
      "learning_rate": 1.992875890513686e-05,
      "loss": 0.3851,
      "step": 190
    },
    {
      "epoch": 0.07499062617172854,
      "grad_norm": 13.092879295349121,
      "learning_rate": 1.9925009373828272e-05,
      "loss": 0.3598,
      "step": 200
    },
    {
      "epoch": 0.07874015748031496,
      "grad_norm": 5.334779739379883,
      "learning_rate": 1.9921259842519688e-05,
      "loss": 0.3694,
      "step": 210
    },
    {
      "epoch": 0.0824896887889014,
      "grad_norm": 5.689721584320068,
      "learning_rate": 1.99175103112111e-05,
      "loss": 0.4443,
      "step": 220
    },
    {
      "epoch": 0.08623922009748781,
      "grad_norm": 7.173852443695068,
      "learning_rate": 1.9913760779902513e-05,
      "loss": 0.3787,
      "step": 230
    },
    {
      "epoch": 0.08998875140607424,
      "grad_norm": 3.4502015113830566,
      "learning_rate": 1.991001124859393e-05,
      "loss": 0.3123,
      "step": 240
    },
    {
      "epoch": 0.09373828271466067,
      "grad_norm": 8.497529983520508,
      "learning_rate": 1.990626171728534e-05,
      "loss": 0.3173,
      "step": 250
    },
    {
      "epoch": 0.09748781402324709,
      "grad_norm": 10.711456298828125,
      "learning_rate": 1.9902512185976754e-05,
      "loss": 0.3539,
      "step": 260
    },
    {
      "epoch": 0.10123734533183353,
      "grad_norm": 8.277186393737793,
      "learning_rate": 1.989876265466817e-05,
      "loss": 0.3268,
      "step": 270
    },
    {
      "epoch": 0.10498687664041995,
      "grad_norm": 7.475594520568848,
      "learning_rate": 1.9895013123359582e-05,
      "loss": 0.332,
      "step": 280
    },
    {
      "epoch": 0.10873640794900638,
      "grad_norm": 10.12879467010498,
      "learning_rate": 1.9891263592050994e-05,
      "loss": 0.3075,
      "step": 290
    },
    {
      "epoch": 0.1124859392575928,
      "grad_norm": 37.240177154541016,
      "learning_rate": 1.9887514060742407e-05,
      "loss": 0.2994,
      "step": 300
    },
    {
      "epoch": 0.11623547056617922,
      "grad_norm": 7.1509928703308105,
      "learning_rate": 1.9883764529433823e-05,
      "loss": 0.3443,
      "step": 310
    },
    {
      "epoch": 0.11998500187476566,
      "grad_norm": 7.348039150238037,
      "learning_rate": 1.9880014998125235e-05,
      "loss": 0.3081,
      "step": 320
    },
    {
      "epoch": 0.12373453318335208,
      "grad_norm": 6.674579620361328,
      "learning_rate": 1.9876265466816648e-05,
      "loss": 0.3683,
      "step": 330
    },
    {
      "epoch": 0.1274840644919385,
      "grad_norm": 5.27418327331543,
      "learning_rate": 1.9872515935508064e-05,
      "loss": 0.3092,
      "step": 340
    },
    {
      "epoch": 0.13123359580052493,
      "grad_norm": 6.783160209655762,
      "learning_rate": 1.9868766404199476e-05,
      "loss": 0.4008,
      "step": 350
    },
    {
      "epoch": 0.13498312710911137,
      "grad_norm": 5.35952091217041,
      "learning_rate": 1.986501687289089e-05,
      "loss": 0.364,
      "step": 360
    },
    {
      "epoch": 0.13873265841769777,
      "grad_norm": 6.7516326904296875,
      "learning_rate": 1.9861267341582305e-05,
      "loss": 0.2688,
      "step": 370
    },
    {
      "epoch": 0.1424821897262842,
      "grad_norm": 4.909388065338135,
      "learning_rate": 1.9857517810273717e-05,
      "loss": 0.2673,
      "step": 380
    },
    {
      "epoch": 0.14623172103487064,
      "grad_norm": 5.930046558380127,
      "learning_rate": 1.985376827896513e-05,
      "loss": 0.3491,
      "step": 390
    },
    {
      "epoch": 0.14998125234345708,
      "grad_norm": 6.345607280731201,
      "learning_rate": 1.9850018747656545e-05,
      "loss": 0.3685,
      "step": 400
    },
    {
      "epoch": 0.15373078365204348,
      "grad_norm": 4.70917272567749,
      "learning_rate": 1.9846269216347958e-05,
      "loss": 0.3395,
      "step": 410
    },
    {
      "epoch": 0.15748031496062992,
      "grad_norm": 9.7245512008667,
      "learning_rate": 1.984251968503937e-05,
      "loss": 0.2961,
      "step": 420
    },
    {
      "epoch": 0.16122984626921635,
      "grad_norm": 5.87684440612793,
      "learning_rate": 1.9838770153730783e-05,
      "loss": 0.3105,
      "step": 430
    },
    {
      "epoch": 0.1649793775778028,
      "grad_norm": 23.17629051208496,
      "learning_rate": 1.98350206224222e-05,
      "loss": 0.3418,
      "step": 440
    },
    {
      "epoch": 0.1687289088863892,
      "grad_norm": 7.512950897216797,
      "learning_rate": 1.9831271091113615e-05,
      "loss": 0.3474,
      "step": 450
    },
    {
      "epoch": 0.17247844019497563,
      "grad_norm": 7.442775726318359,
      "learning_rate": 1.9827521559805024e-05,
      "loss": 0.2937,
      "step": 460
    },
    {
      "epoch": 0.17622797150356206,
      "grad_norm": 8.763176918029785,
      "learning_rate": 1.982377202849644e-05,
      "loss": 0.3008,
      "step": 470
    },
    {
      "epoch": 0.17997750281214847,
      "grad_norm": 5.089291095733643,
      "learning_rate": 1.9820022497187856e-05,
      "loss": 0.2351,
      "step": 480
    },
    {
      "epoch": 0.1837270341207349,
      "grad_norm": 4.831735134124756,
      "learning_rate": 1.9816272965879265e-05,
      "loss": 0.2571,
      "step": 490
    },
    {
      "epoch": 0.18747656542932134,
      "grad_norm": 7.066135883331299,
      "learning_rate": 1.981252343457068e-05,
      "loss": 0.3009,
      "step": 500
    },
    {
      "epoch": 0.19122609673790777,
      "grad_norm": 4.134705543518066,
      "learning_rate": 1.9808773903262093e-05,
      "loss": 0.2861,
      "step": 510
    },
    {
      "epoch": 0.19497562804649418,
      "grad_norm": 5.044273376464844,
      "learning_rate": 1.980502437195351e-05,
      "loss": 0.2532,
      "step": 520
    },
    {
      "epoch": 0.19872515935508062,
      "grad_norm": 4.944314956665039,
      "learning_rate": 1.980127484064492e-05,
      "loss": 0.2802,
      "step": 530
    },
    {
      "epoch": 0.20247469066366705,
      "grad_norm": 7.4979963302612305,
      "learning_rate": 1.9797525309336334e-05,
      "loss": 0.3129,
      "step": 540
    },
    {
      "epoch": 0.20622422197225346,
      "grad_norm": 7.725257873535156,
      "learning_rate": 1.979377577802775e-05,
      "loss": 0.2682,
      "step": 550
    },
    {
      "epoch": 0.2099737532808399,
      "grad_norm": 13.142579078674316,
      "learning_rate": 1.9790026246719162e-05,
      "loss": 0.2748,
      "step": 560
    },
    {
      "epoch": 0.21372328458942633,
      "grad_norm": 7.219686508178711,
      "learning_rate": 1.9786276715410575e-05,
      "loss": 0.2438,
      "step": 570
    },
    {
      "epoch": 0.21747281589801276,
      "grad_norm": 5.258193016052246,
      "learning_rate": 1.978252718410199e-05,
      "loss": 0.2721,
      "step": 580
    },
    {
      "epoch": 0.22122234720659917,
      "grad_norm": 9.242711067199707,
      "learning_rate": 1.9778777652793403e-05,
      "loss": 0.2828,
      "step": 590
    },
    {
      "epoch": 0.2249718785151856,
      "grad_norm": 5.726379871368408,
      "learning_rate": 1.9775028121484816e-05,
      "loss": 0.2698,
      "step": 600
    },
    {
      "epoch": 0.22872140982377204,
      "grad_norm": 7.0484466552734375,
      "learning_rate": 1.977127859017623e-05,
      "loss": 0.2905,
      "step": 610
    },
    {
      "epoch": 0.23247094113235844,
      "grad_norm": 6.249504089355469,
      "learning_rate": 1.9767529058867644e-05,
      "loss": 0.252,
      "step": 620
    },
    {
      "epoch": 0.23622047244094488,
      "grad_norm": 7.067031383514404,
      "learning_rate": 1.9763779527559057e-05,
      "loss": 0.2424,
      "step": 630
    },
    {
      "epoch": 0.2399700037495313,
      "grad_norm": 6.264758586883545,
      "learning_rate": 1.976002999625047e-05,
      "loss": 0.2754,
      "step": 640
    },
    {
      "epoch": 0.24371953505811775,
      "grad_norm": 6.892160415649414,
      "learning_rate": 1.9756280464941885e-05,
      "loss": 0.2526,
      "step": 650
    },
    {
      "epoch": 0.24746906636670415,
      "grad_norm": 5.922248363494873,
      "learning_rate": 1.9752530933633297e-05,
      "loss": 0.2426,
      "step": 660
    },
    {
      "epoch": 0.2512185976752906,
      "grad_norm": 6.588134288787842,
      "learning_rate": 1.974878140232471e-05,
      "loss": 0.2526,
      "step": 670
    },
    {
      "epoch": 0.254968128983877,
      "grad_norm": 5.264699935913086,
      "learning_rate": 1.9745031871016126e-05,
      "loss": 0.2553,
      "step": 680
    },
    {
      "epoch": 0.25871766029246346,
      "grad_norm": 4.881000995635986,
      "learning_rate": 1.9741282339707538e-05,
      "loss": 0.2725,
      "step": 690
    },
    {
      "epoch": 0.26246719160104987,
      "grad_norm": 5.2217278480529785,
      "learning_rate": 1.973753280839895e-05,
      "loss": 0.232,
      "step": 700
    },
    {
      "epoch": 0.26621672290963627,
      "grad_norm": 7.313785552978516,
      "learning_rate": 1.9733783277090367e-05,
      "loss": 0.2331,
      "step": 710
    },
    {
      "epoch": 0.26996625421822273,
      "grad_norm": 27.090482711791992,
      "learning_rate": 1.973003374578178e-05,
      "loss": 0.2142,
      "step": 720
    },
    {
      "epoch": 0.27371578552680914,
      "grad_norm": 9.030502319335938,
      "learning_rate": 1.972628421447319e-05,
      "loss": 0.2765,
      "step": 730
    },
    {
      "epoch": 0.27746531683539555,
      "grad_norm": 6.6600446701049805,
      "learning_rate": 1.9722534683164607e-05,
      "loss": 0.2206,
      "step": 740
    },
    {
      "epoch": 0.281214848143982,
      "grad_norm": 6.3801493644714355,
      "learning_rate": 1.971878515185602e-05,
      "loss": 0.2636,
      "step": 750
    },
    {
      "epoch": 0.2849643794525684,
      "grad_norm": 5.839882850646973,
      "learning_rate": 1.9715035620547432e-05,
      "loss": 0.237,
      "step": 760
    },
    {
      "epoch": 0.2887139107611549,
      "grad_norm": 3.055370569229126,
      "learning_rate": 1.9711286089238845e-05,
      "loss": 0.1953,
      "step": 770
    },
    {
      "epoch": 0.2924634420697413,
      "grad_norm": 4.174562454223633,
      "learning_rate": 1.970753655793026e-05,
      "loss": 0.22,
      "step": 780
    },
    {
      "epoch": 0.2962129733783277,
      "grad_norm": 5.416112422943115,
      "learning_rate": 1.9703787026621673e-05,
      "loss": 0.2149,
      "step": 790
    },
    {
      "epoch": 0.29996250468691416,
      "grad_norm": 14.024301528930664,
      "learning_rate": 1.9700037495313086e-05,
      "loss": 0.2276,
      "step": 800
    },
    {
      "epoch": 0.30371203599550056,
      "grad_norm": 4.478726387023926,
      "learning_rate": 1.9696287964004502e-05,
      "loss": 0.2269,
      "step": 810
    },
    {
      "epoch": 0.30746156730408697,
      "grad_norm": 3.5723509788513184,
      "learning_rate": 1.9692538432695914e-05,
      "loss": 0.1899,
      "step": 820
    },
    {
      "epoch": 0.31121109861267343,
      "grad_norm": 10.182151794433594,
      "learning_rate": 1.9688788901387327e-05,
      "loss": 0.2612,
      "step": 830
    },
    {
      "epoch": 0.31496062992125984,
      "grad_norm": 2.8742501735687256,
      "learning_rate": 1.9685039370078743e-05,
      "loss": 0.2268,
      "step": 840
    },
    {
      "epoch": 0.31871016122984624,
      "grad_norm": 4.012927532196045,
      "learning_rate": 1.9681289838770155e-05,
      "loss": 0.2222,
      "step": 850
    },
    {
      "epoch": 0.3224596925384327,
      "grad_norm": 5.028637409210205,
      "learning_rate": 1.9677540307461568e-05,
      "loss": 0.1965,
      "step": 860
    },
    {
      "epoch": 0.3262092238470191,
      "grad_norm": 8.301695823669434,
      "learning_rate": 1.9673790776152983e-05,
      "loss": 0.1648,
      "step": 870
    },
    {
      "epoch": 0.3299587551556056,
      "grad_norm": 5.388348579406738,
      "learning_rate": 1.9670041244844396e-05,
      "loss": 0.2286,
      "step": 880
    },
    {
      "epoch": 0.333708286464192,
      "grad_norm": 4.722405910491943,
      "learning_rate": 1.966629171353581e-05,
      "loss": 0.2503,
      "step": 890
    },
    {
      "epoch": 0.3374578177727784,
      "grad_norm": 7.649892807006836,
      "learning_rate": 1.966254218222722e-05,
      "loss": 0.2573,
      "step": 900
    },
    {
      "epoch": 0.34120734908136485,
      "grad_norm": 5.625217914581299,
      "learning_rate": 1.9658792650918637e-05,
      "loss": 0.2639,
      "step": 910
    },
    {
      "epoch": 0.34495688038995126,
      "grad_norm": 6.874326705932617,
      "learning_rate": 1.9655043119610053e-05,
      "loss": 0.233,
      "step": 920
    },
    {
      "epoch": 0.34870641169853767,
      "grad_norm": 5.719024658203125,
      "learning_rate": 1.9651293588301462e-05,
      "loss": 0.1956,
      "step": 930
    },
    {
      "epoch": 0.35245594300712413,
      "grad_norm": 5.220556259155273,
      "learning_rate": 1.9647544056992878e-05,
      "loss": 0.1944,
      "step": 940
    },
    {
      "epoch": 0.35620547431571054,
      "grad_norm": 5.182559490203857,
      "learning_rate": 1.9643794525684294e-05,
      "loss": 0.181,
      "step": 950
    },
    {
      "epoch": 0.35995500562429694,
      "grad_norm": 3.560917854309082,
      "learning_rate": 1.9640044994375703e-05,
      "loss": 0.1923,
      "step": 960
    },
    {
      "epoch": 0.3637045369328834,
      "grad_norm": 3.8194751739501953,
      "learning_rate": 1.963629546306712e-05,
      "loss": 0.2184,
      "step": 970
    },
    {
      "epoch": 0.3674540682414698,
      "grad_norm": 4.475009441375732,
      "learning_rate": 1.963254593175853e-05,
      "loss": 0.2181,
      "step": 980
    },
    {
      "epoch": 0.3712035995500562,
      "grad_norm": 8.561201095581055,
      "learning_rate": 1.9628796400449947e-05,
      "loss": 0.1862,
      "step": 990
    },
    {
      "epoch": 0.3749531308586427,
      "grad_norm": 2.7679309844970703,
      "learning_rate": 1.962504686914136e-05,
      "loss": 0.1919,
      "step": 1000
    },
    {
      "epoch": 0.3787026621672291,
      "grad_norm": 8.628823280334473,
      "learning_rate": 1.9621297337832772e-05,
      "loss": 0.1786,
      "step": 1010
    },
    {
      "epoch": 0.38245219347581555,
      "grad_norm": 5.557149410247803,
      "learning_rate": 1.9617547806524188e-05,
      "loss": 0.1854,
      "step": 1020
    },
    {
      "epoch": 0.38620172478440196,
      "grad_norm": 2.577164649963379,
      "learning_rate": 1.96137982752156e-05,
      "loss": 0.1899,
      "step": 1030
    },
    {
      "epoch": 0.38995125609298836,
      "grad_norm": 7.26982307434082,
      "learning_rate": 1.9610048743907013e-05,
      "loss": 0.1978,
      "step": 1040
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 5.632422924041748,
      "learning_rate": 1.960629921259843e-05,
      "loss": 0.1891,
      "step": 1050
    },
    {
      "epoch": 0.39745031871016123,
      "grad_norm": 6.368051528930664,
      "learning_rate": 1.960254968128984e-05,
      "loss": 0.182,
      "step": 1060
    },
    {
      "epoch": 0.40119985001874764,
      "grad_norm": 4.851492881774902,
      "learning_rate": 1.9598800149981254e-05,
      "loss": 0.1666,
      "step": 1070
    },
    {
      "epoch": 0.4049493813273341,
      "grad_norm": 4.463593006134033,
      "learning_rate": 1.959505061867267e-05,
      "loss": 0.1853,
      "step": 1080
    },
    {
      "epoch": 0.4086989126359205,
      "grad_norm": 6.841119289398193,
      "learning_rate": 1.9591301087364082e-05,
      "loss": 0.2018,
      "step": 1090
    },
    {
      "epoch": 0.4124484439445069,
      "grad_norm": 6.4515767097473145,
      "learning_rate": 1.9587551556055495e-05,
      "loss": 0.1901,
      "step": 1100
    },
    {
      "epoch": 0.4161979752530934,
      "grad_norm": 4.513023376464844,
      "learning_rate": 1.9583802024746907e-05,
      "loss": 0.1694,
      "step": 1110
    },
    {
      "epoch": 0.4199475065616798,
      "grad_norm": 14.09104061126709,
      "learning_rate": 1.9580052493438323e-05,
      "loss": 0.1535,
      "step": 1120
    },
    {
      "epoch": 0.4236970378702662,
      "grad_norm": 6.089542388916016,
      "learning_rate": 1.9576302962129735e-05,
      "loss": 0.1691,
      "step": 1130
    },
    {
      "epoch": 0.42744656917885265,
      "grad_norm": 11.51169490814209,
      "learning_rate": 1.9572553430821148e-05,
      "loss": 0.1346,
      "step": 1140
    },
    {
      "epoch": 0.43119610048743906,
      "grad_norm": 4.572627544403076,
      "learning_rate": 1.9568803899512564e-05,
      "loss": 0.1715,
      "step": 1150
    },
    {
      "epoch": 0.4349456317960255,
      "grad_norm": 6.02508544921875,
      "learning_rate": 1.9565054368203976e-05,
      "loss": 0.1144,
      "step": 1160
    },
    {
      "epoch": 0.43869516310461193,
      "grad_norm": 2.6260876655578613,
      "learning_rate": 1.956130483689539e-05,
      "loss": 0.1705,
      "step": 1170
    },
    {
      "epoch": 0.44244469441319834,
      "grad_norm": 5.280847549438477,
      "learning_rate": 1.9557555305586805e-05,
      "loss": 0.1512,
      "step": 1180
    },
    {
      "epoch": 0.4461942257217848,
      "grad_norm": 7.415008068084717,
      "learning_rate": 1.9553805774278217e-05,
      "loss": 0.166,
      "step": 1190
    },
    {
      "epoch": 0.4499437570303712,
      "grad_norm": 4.99002742767334,
      "learning_rate": 1.955005624296963e-05,
      "loss": 0.2121,
      "step": 1200
    },
    {
      "epoch": 0.4536932883389576,
      "grad_norm": 4.2266621589660645,
      "learning_rate": 1.9546306711661046e-05,
      "loss": 0.145,
      "step": 1210
    },
    {
      "epoch": 0.4574428196475441,
      "grad_norm": 2.9806647300720215,
      "learning_rate": 1.9542557180352458e-05,
      "loss": 0.1745,
      "step": 1220
    },
    {
      "epoch": 0.4611923509561305,
      "grad_norm": 3.0732667446136475,
      "learning_rate": 1.953880764904387e-05,
      "loss": 0.1161,
      "step": 1230
    },
    {
      "epoch": 0.4649418822647169,
      "grad_norm": 3.590319871902466,
      "learning_rate": 1.9535058117735283e-05,
      "loss": 0.1927,
      "step": 1240
    },
    {
      "epoch": 0.46869141357330335,
      "grad_norm": 4.716139316558838,
      "learning_rate": 1.95313085864267e-05,
      "loss": 0.1799,
      "step": 1250
    },
    {
      "epoch": 0.47244094488188976,
      "grad_norm": 6.9612531661987305,
      "learning_rate": 1.952755905511811e-05,
      "loss": 0.1749,
      "step": 1260
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 6.387828350067139,
      "learning_rate": 1.9523809523809524e-05,
      "loss": 0.148,
      "step": 1270
    },
    {
      "epoch": 0.4799400074990626,
      "grad_norm": 3.400050163269043,
      "learning_rate": 1.952005999250094e-05,
      "loss": 0.1581,
      "step": 1280
    },
    {
      "epoch": 0.48368953880764903,
      "grad_norm": 5.66917085647583,
      "learning_rate": 1.9516310461192352e-05,
      "loss": 0.1808,
      "step": 1290
    },
    {
      "epoch": 0.4874390701162355,
      "grad_norm": 6.467467308044434,
      "learning_rate": 1.9512560929883765e-05,
      "loss": 0.1606,
      "step": 1300
    },
    {
      "epoch": 0.4911886014248219,
      "grad_norm": 4.453497886657715,
      "learning_rate": 1.950881139857518e-05,
      "loss": 0.1218,
      "step": 1310
    },
    {
      "epoch": 0.4949381327334083,
      "grad_norm": 7.588212966918945,
      "learning_rate": 1.9505061867266593e-05,
      "loss": 0.1579,
      "step": 1320
    },
    {
      "epoch": 0.49868766404199477,
      "grad_norm": 2.347876787185669,
      "learning_rate": 1.9501312335958006e-05,
      "loss": 0.1496,
      "step": 1330
    },
    {
      "epoch": 0.5024371953505812,
      "grad_norm": 6.509267330169678,
      "learning_rate": 1.949756280464942e-05,
      "loss": 0.1598,
      "step": 1340
    },
    {
      "epoch": 0.5061867266591676,
      "grad_norm": 2.5897867679595947,
      "learning_rate": 1.9493813273340834e-05,
      "loss": 0.1446,
      "step": 1350
    },
    {
      "epoch": 0.509936257967754,
      "grad_norm": 3.4993388652801514,
      "learning_rate": 1.9490063742032246e-05,
      "loss": 0.1591,
      "step": 1360
    },
    {
      "epoch": 0.5136857892763405,
      "grad_norm": 2.92578387260437,
      "learning_rate": 1.948631421072366e-05,
      "loss": 0.1465,
      "step": 1370
    },
    {
      "epoch": 0.5174353205849269,
      "grad_norm": 3.567833185195923,
      "learning_rate": 1.9482564679415075e-05,
      "loss": 0.1409,
      "step": 1380
    },
    {
      "epoch": 0.5211848518935133,
      "grad_norm": 4.257269859313965,
      "learning_rate": 1.947881514810649e-05,
      "loss": 0.132,
      "step": 1390
    },
    {
      "epoch": 0.5249343832020997,
      "grad_norm": 10.492402076721191,
      "learning_rate": 1.94750656167979e-05,
      "loss": 0.1582,
      "step": 1400
    },
    {
      "epoch": 0.5286839145106862,
      "grad_norm": 6.162323474884033,
      "learning_rate": 1.9471316085489316e-05,
      "loss": 0.1927,
      "step": 1410
    },
    {
      "epoch": 0.5324334458192725,
      "grad_norm": 6.333585262298584,
      "learning_rate": 1.9467566554180728e-05,
      "loss": 0.1732,
      "step": 1420
    },
    {
      "epoch": 0.536182977127859,
      "grad_norm": 3.965871810913086,
      "learning_rate": 1.946381702287214e-05,
      "loss": 0.1506,
      "step": 1430
    },
    {
      "epoch": 0.5399325084364455,
      "grad_norm": 3.1630570888519287,
      "learning_rate": 1.9460067491563557e-05,
      "loss": 0.1299,
      "step": 1440
    },
    {
      "epoch": 0.5436820397450318,
      "grad_norm": 6.167692184448242,
      "learning_rate": 1.945631796025497e-05,
      "loss": 0.0792,
      "step": 1450
    },
    {
      "epoch": 0.5474315710536183,
      "grad_norm": 8.362566947937012,
      "learning_rate": 1.9452568428946385e-05,
      "loss": 0.1383,
      "step": 1460
    },
    {
      "epoch": 0.5511811023622047,
      "grad_norm": 15.104353904724121,
      "learning_rate": 1.9448818897637797e-05,
      "loss": 0.1395,
      "step": 1470
    },
    {
      "epoch": 0.5549306336707911,
      "grad_norm": 6.660952568054199,
      "learning_rate": 1.944506936632921e-05,
      "loss": 0.1304,
      "step": 1480
    },
    {
      "epoch": 0.5586801649793776,
      "grad_norm": 11.581657409667969,
      "learning_rate": 1.9441319835020626e-05,
      "loss": 0.1402,
      "step": 1490
    },
    {
      "epoch": 0.562429696287964,
      "grad_norm": 1.9542118310928345,
      "learning_rate": 1.943757030371204e-05,
      "loss": 0.1237,
      "step": 1500
    },
    {
      "epoch": 0.5661792275965505,
      "grad_norm": 10.897820472717285,
      "learning_rate": 1.943382077240345e-05,
      "loss": 0.1373,
      "step": 1510
    },
    {
      "epoch": 0.5699287589051368,
      "grad_norm": 4.850577354431152,
      "learning_rate": 1.9430071241094867e-05,
      "loss": 0.1215,
      "step": 1520
    },
    {
      "epoch": 0.5736782902137233,
      "grad_norm": 5.429379940032959,
      "learning_rate": 1.942632170978628e-05,
      "loss": 0.134,
      "step": 1530
    },
    {
      "epoch": 0.5774278215223098,
      "grad_norm": 4.681661605834961,
      "learning_rate": 1.9422572178477692e-05,
      "loss": 0.1058,
      "step": 1540
    },
    {
      "epoch": 0.5811773528308961,
      "grad_norm": 3.7557015419006348,
      "learning_rate": 1.9418822647169104e-05,
      "loss": 0.1139,
      "step": 1550
    },
    {
      "epoch": 0.5849268841394826,
      "grad_norm": 6.092104434967041,
      "learning_rate": 1.941507311586052e-05,
      "loss": 0.1286,
      "step": 1560
    },
    {
      "epoch": 0.588676415448069,
      "grad_norm": 4.2682695388793945,
      "learning_rate": 1.9411323584551933e-05,
      "loss": 0.1302,
      "step": 1570
    },
    {
      "epoch": 0.5924259467566554,
      "grad_norm": 8.203808784484863,
      "learning_rate": 1.9407574053243345e-05,
      "loss": 0.1226,
      "step": 1580
    },
    {
      "epoch": 0.5961754780652418,
      "grad_norm": 7.830501556396484,
      "learning_rate": 1.940382452193476e-05,
      "loss": 0.1453,
      "step": 1590
    },
    {
      "epoch": 0.5999250093738283,
      "grad_norm": 8.589569091796875,
      "learning_rate": 1.9400074990626173e-05,
      "loss": 0.1574,
      "step": 1600
    },
    {
      "epoch": 0.6036745406824147,
      "grad_norm": 2.5616767406463623,
      "learning_rate": 1.9396325459317586e-05,
      "loss": 0.138,
      "step": 1610
    },
    {
      "epoch": 0.6074240719910011,
      "grad_norm": 4.063249588012695,
      "learning_rate": 1.9392575928009002e-05,
      "loss": 0.141,
      "step": 1620
    },
    {
      "epoch": 0.6111736032995876,
      "grad_norm": 4.02497673034668,
      "learning_rate": 1.9388826396700414e-05,
      "loss": 0.1448,
      "step": 1630
    },
    {
      "epoch": 0.6149231346081739,
      "grad_norm": 3.895735263824463,
      "learning_rate": 1.9385076865391827e-05,
      "loss": 0.1061,
      "step": 1640
    },
    {
      "epoch": 0.6186726659167604,
      "grad_norm": 1.2512853145599365,
      "learning_rate": 1.9381327334083243e-05,
      "loss": 0.0906,
      "step": 1650
    },
    {
      "epoch": 0.6224221972253469,
      "grad_norm": 6.337036609649658,
      "learning_rate": 1.9377577802774655e-05,
      "loss": 0.157,
      "step": 1660
    },
    {
      "epoch": 0.6261717285339332,
      "grad_norm": 2.5126583576202393,
      "learning_rate": 1.9373828271466068e-05,
      "loss": 0.1415,
      "step": 1670
    },
    {
      "epoch": 0.6299212598425197,
      "grad_norm": 4.910245895385742,
      "learning_rate": 1.937007874015748e-05,
      "loss": 0.1235,
      "step": 1680
    },
    {
      "epoch": 0.6336707911511061,
      "grad_norm": 5.85009241104126,
      "learning_rate": 1.9366329208848896e-05,
      "loss": 0.1428,
      "step": 1690
    },
    {
      "epoch": 0.6374203224596925,
      "grad_norm": 6.41151237487793,
      "learning_rate": 1.936257967754031e-05,
      "loss": 0.136,
      "step": 1700
    },
    {
      "epoch": 0.641169853768279,
      "grad_norm": 2.778289318084717,
      "learning_rate": 1.935883014623172e-05,
      "loss": 0.1078,
      "step": 1710
    },
    {
      "epoch": 0.6449193850768654,
      "grad_norm": 16.934452056884766,
      "learning_rate": 1.9355080614923137e-05,
      "loss": 0.1494,
      "step": 1720
    },
    {
      "epoch": 0.6486689163854518,
      "grad_norm": 2.7655348777770996,
      "learning_rate": 1.935133108361455e-05,
      "loss": 0.083,
      "step": 1730
    },
    {
      "epoch": 0.6524184476940382,
      "grad_norm": 2.920816421508789,
      "learning_rate": 1.9347581552305962e-05,
      "loss": 0.1334,
      "step": 1740
    },
    {
      "epoch": 0.6561679790026247,
      "grad_norm": 4.340709209442139,
      "learning_rate": 1.9343832020997378e-05,
      "loss": 0.1367,
      "step": 1750
    },
    {
      "epoch": 0.6599175103112112,
      "grad_norm": 3.615671157836914,
      "learning_rate": 1.934008248968879e-05,
      "loss": 0.1517,
      "step": 1760
    },
    {
      "epoch": 0.6636670416197975,
      "grad_norm": 4.645755290985107,
      "learning_rate": 1.9336332958380203e-05,
      "loss": 0.1256,
      "step": 1770
    },
    {
      "epoch": 0.667416572928384,
      "grad_norm": 7.276289939880371,
      "learning_rate": 1.933258342707162e-05,
      "loss": 0.0896,
      "step": 1780
    },
    {
      "epoch": 0.6711661042369704,
      "grad_norm": 2.436959981918335,
      "learning_rate": 1.932883389576303e-05,
      "loss": 0.1293,
      "step": 1790
    },
    {
      "epoch": 0.6749156355455568,
      "grad_norm": 0.754202127456665,
      "learning_rate": 1.9325084364454444e-05,
      "loss": 0.0942,
      "step": 1800
    },
    {
      "epoch": 0.6786651668541432,
      "grad_norm": 10.556313514709473,
      "learning_rate": 1.932133483314586e-05,
      "loss": 0.1659,
      "step": 1810
    },
    {
      "epoch": 0.6824146981627297,
      "grad_norm": 9.401507377624512,
      "learning_rate": 1.9317585301837272e-05,
      "loss": 0.129,
      "step": 1820
    },
    {
      "epoch": 0.6861642294713161,
      "grad_norm": 5.885099411010742,
      "learning_rate": 1.9313835770528685e-05,
      "loss": 0.1624,
      "step": 1830
    },
    {
      "epoch": 0.6899137607799025,
      "grad_norm": 9.820000648498535,
      "learning_rate": 1.9310086239220097e-05,
      "loss": 0.1147,
      "step": 1840
    },
    {
      "epoch": 0.693663292088489,
      "grad_norm": 4.603486061096191,
      "learning_rate": 1.9306336707911513e-05,
      "loss": 0.0864,
      "step": 1850
    },
    {
      "epoch": 0.6974128233970753,
      "grad_norm": 3.7057180404663086,
      "learning_rate": 1.930258717660293e-05,
      "loss": 0.0848,
      "step": 1860
    },
    {
      "epoch": 0.7011623547056618,
      "grad_norm": 7.4444804191589355,
      "learning_rate": 1.9298837645294338e-05,
      "loss": 0.1156,
      "step": 1870
    },
    {
      "epoch": 0.7049118860142483,
      "grad_norm": 3.265317678451538,
      "learning_rate": 1.9295088113985754e-05,
      "loss": 0.1045,
      "step": 1880
    },
    {
      "epoch": 0.7086614173228346,
      "grad_norm": 3.228085994720459,
      "learning_rate": 1.9291338582677166e-05,
      "loss": 0.1152,
      "step": 1890
    },
    {
      "epoch": 0.7124109486314211,
      "grad_norm": 2.2728679180145264,
      "learning_rate": 1.928758905136858e-05,
      "loss": 0.1105,
      "step": 1900
    },
    {
      "epoch": 0.7161604799400075,
      "grad_norm": 2.7115461826324463,
      "learning_rate": 1.9283839520059995e-05,
      "loss": 0.0952,
      "step": 1910
    },
    {
      "epoch": 0.7199100112485939,
      "grad_norm": 3.991743564605713,
      "learning_rate": 1.9280089988751407e-05,
      "loss": 0.1197,
      "step": 1920
    },
    {
      "epoch": 0.7236595425571803,
      "grad_norm": 5.363742351531982,
      "learning_rate": 1.9276340457442823e-05,
      "loss": 0.1426,
      "step": 1930
    },
    {
      "epoch": 0.7274090738657668,
      "grad_norm": 7.704312801361084,
      "learning_rate": 1.9272590926134235e-05,
      "loss": 0.1292,
      "step": 1940
    },
    {
      "epoch": 0.7311586051743532,
      "grad_norm": 1.5295424461364746,
      "learning_rate": 1.9268841394825648e-05,
      "loss": 0.0991,
      "step": 1950
    },
    {
      "epoch": 0.7349081364829396,
      "grad_norm": 4.007376670837402,
      "learning_rate": 1.9265091863517064e-05,
      "loss": 0.1073,
      "step": 1960
    },
    {
      "epoch": 0.7386576677915261,
      "grad_norm": 6.856256008148193,
      "learning_rate": 1.9261342332208476e-05,
      "loss": 0.0953,
      "step": 1970
    },
    {
      "epoch": 0.7424071991001124,
      "grad_norm": 4.9537882804870605,
      "learning_rate": 1.925759280089989e-05,
      "loss": 0.1736,
      "step": 1980
    },
    {
      "epoch": 0.7461567304086989,
      "grad_norm": 4.274913311004639,
      "learning_rate": 1.9253843269591305e-05,
      "loss": 0.1099,
      "step": 1990
    },
    {
      "epoch": 0.7499062617172854,
      "grad_norm": 4.655187129974365,
      "learning_rate": 1.9250093738282717e-05,
      "loss": 0.0649,
      "step": 2000
    },
    {
      "epoch": 0.7536557930258717,
      "grad_norm": 13.813246726989746,
      "learning_rate": 1.924634420697413e-05,
      "loss": 0.1261,
      "step": 2010
    },
    {
      "epoch": 0.7574053243344582,
      "grad_norm": 0.4257213771343231,
      "learning_rate": 1.9242594675665542e-05,
      "loss": 0.1316,
      "step": 2020
    },
    {
      "epoch": 0.7611548556430446,
      "grad_norm": 2.7200703620910645,
      "learning_rate": 1.9238845144356958e-05,
      "loss": 0.0843,
      "step": 2030
    },
    {
      "epoch": 0.7649043869516311,
      "grad_norm": 5.519855499267578,
      "learning_rate": 1.923509561304837e-05,
      "loss": 0.0921,
      "step": 2040
    },
    {
      "epoch": 0.7686539182602175,
      "grad_norm": 9.810850143432617,
      "learning_rate": 1.9231346081739783e-05,
      "loss": 0.1261,
      "step": 2050
    },
    {
      "epoch": 0.7724034495688039,
      "grad_norm": 6.1469244956970215,
      "learning_rate": 1.92275965504312e-05,
      "loss": 0.0821,
      "step": 2060
    },
    {
      "epoch": 0.7761529808773904,
      "grad_norm": 15.121304512023926,
      "learning_rate": 1.922384701912261e-05,
      "loss": 0.0988,
      "step": 2070
    },
    {
      "epoch": 0.7799025121859767,
      "grad_norm": 5.51246976852417,
      "learning_rate": 1.9220097487814024e-05,
      "loss": 0.1109,
      "step": 2080
    },
    {
      "epoch": 0.7836520434945632,
      "grad_norm": 2.810983896255493,
      "learning_rate": 1.921634795650544e-05,
      "loss": 0.0963,
      "step": 2090
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 6.247832775115967,
      "learning_rate": 1.9212598425196852e-05,
      "loss": 0.1193,
      "step": 2100
    },
    {
      "epoch": 0.791151106111736,
      "grad_norm": 2.0496509075164795,
      "learning_rate": 1.9208848893888265e-05,
      "loss": 0.1159,
      "step": 2110
    },
    {
      "epoch": 0.7949006374203225,
      "grad_norm": 7.341362953186035,
      "learning_rate": 1.920509936257968e-05,
      "loss": 0.113,
      "step": 2120
    },
    {
      "epoch": 0.7986501687289089,
      "grad_norm": 4.754990100860596,
      "learning_rate": 1.9201349831271093e-05,
      "loss": 0.1205,
      "step": 2130
    },
    {
      "epoch": 0.8023997000374953,
      "grad_norm": 4.027239799499512,
      "learning_rate": 1.9197600299962506e-05,
      "loss": 0.1037,
      "step": 2140
    },
    {
      "epoch": 0.8061492313460817,
      "grad_norm": 3.646669864654541,
      "learning_rate": 1.9193850768653918e-05,
      "loss": 0.0819,
      "step": 2150
    },
    {
      "epoch": 0.8098987626546682,
      "grad_norm": 6.021709442138672,
      "learning_rate": 1.9190101237345334e-05,
      "loss": 0.1068,
      "step": 2160
    },
    {
      "epoch": 0.8136482939632546,
      "grad_norm": 3.0344810485839844,
      "learning_rate": 1.9186351706036747e-05,
      "loss": 0.0893,
      "step": 2170
    },
    {
      "epoch": 0.817397825271841,
      "grad_norm": 1.3991413116455078,
      "learning_rate": 1.918260217472816e-05,
      "loss": 0.0684,
      "step": 2180
    },
    {
      "epoch": 0.8211473565804275,
      "grad_norm": 2.034525156021118,
      "learning_rate": 1.9178852643419575e-05,
      "loss": 0.0934,
      "step": 2190
    },
    {
      "epoch": 0.8248968878890138,
      "grad_norm": 5.068839073181152,
      "learning_rate": 1.9175103112110987e-05,
      "loss": 0.1469,
      "step": 2200
    },
    {
      "epoch": 0.8286464191976003,
      "grad_norm": 2.1788182258605957,
      "learning_rate": 1.91713535808024e-05,
      "loss": 0.1452,
      "step": 2210
    },
    {
      "epoch": 0.8323959505061868,
      "grad_norm": 15.10725212097168,
      "learning_rate": 1.9167604049493816e-05,
      "loss": 0.0996,
      "step": 2220
    },
    {
      "epoch": 0.8361454818147731,
      "grad_norm": 6.202535152435303,
      "learning_rate": 1.916385451818523e-05,
      "loss": 0.0819,
      "step": 2230
    },
    {
      "epoch": 0.8398950131233596,
      "grad_norm": 7.418252944946289,
      "learning_rate": 1.916010498687664e-05,
      "loss": 0.1081,
      "step": 2240
    },
    {
      "epoch": 0.843644544431946,
      "grad_norm": 3.9589881896972656,
      "learning_rate": 1.9156355455568057e-05,
      "loss": 0.0876,
      "step": 2250
    },
    {
      "epoch": 0.8473940757405324,
      "grad_norm": 3.7005817890167236,
      "learning_rate": 1.915260592425947e-05,
      "loss": 0.0895,
      "step": 2260
    },
    {
      "epoch": 0.8511436070491188,
      "grad_norm": 13.964189529418945,
      "learning_rate": 1.914885639295088e-05,
      "loss": 0.1832,
      "step": 2270
    },
    {
      "epoch": 0.8548931383577053,
      "grad_norm": 5.626776695251465,
      "learning_rate": 1.9145106861642294e-05,
      "loss": 0.0823,
      "step": 2280
    },
    {
      "epoch": 0.8586426696662918,
      "grad_norm": 4.734350204467773,
      "learning_rate": 1.914135733033371e-05,
      "loss": 0.121,
      "step": 2290
    },
    {
      "epoch": 0.8623922009748781,
      "grad_norm": 5.011897563934326,
      "learning_rate": 1.9137607799025123e-05,
      "loss": 0.1056,
      "step": 2300
    },
    {
      "epoch": 0.8661417322834646,
      "grad_norm": 4.446615695953369,
      "learning_rate": 1.9133858267716535e-05,
      "loss": 0.0548,
      "step": 2310
    },
    {
      "epoch": 0.869891263592051,
      "grad_norm": 11.938965797424316,
      "learning_rate": 1.913010873640795e-05,
      "loss": 0.1107,
      "step": 2320
    },
    {
      "epoch": 0.8736407949006374,
      "grad_norm": 3.906890392303467,
      "learning_rate": 1.9126359205099367e-05,
      "loss": 0.0915,
      "step": 2330
    },
    {
      "epoch": 0.8773903262092239,
      "grad_norm": 5.900190830230713,
      "learning_rate": 1.9122609673790776e-05,
      "loss": 0.0888,
      "step": 2340
    },
    {
      "epoch": 0.8811398575178103,
      "grad_norm": 5.154822826385498,
      "learning_rate": 1.9118860142482192e-05,
      "loss": 0.1146,
      "step": 2350
    },
    {
      "epoch": 0.8848893888263967,
      "grad_norm": 6.387962341308594,
      "learning_rate": 1.9115110611173604e-05,
      "loss": 0.0768,
      "step": 2360
    },
    {
      "epoch": 0.8886389201349831,
      "grad_norm": 1.7055755853652954,
      "learning_rate": 1.9111361079865017e-05,
      "loss": 0.082,
      "step": 2370
    },
    {
      "epoch": 0.8923884514435696,
      "grad_norm": 6.037840366363525,
      "learning_rate": 1.9107611548556433e-05,
      "loss": 0.0946,
      "step": 2380
    },
    {
      "epoch": 0.896137982752156,
      "grad_norm": 6.08791971206665,
      "learning_rate": 1.9103862017247845e-05,
      "loss": 0.0541,
      "step": 2390
    },
    {
      "epoch": 0.8998875140607424,
      "grad_norm": 0.1921478807926178,
      "learning_rate": 1.910011248593926e-05,
      "loss": 0.054,
      "step": 2400
    },
    {
      "epoch": 0.9036370453693289,
      "grad_norm": 3.907144546508789,
      "learning_rate": 1.909636295463067e-05,
      "loss": 0.1149,
      "step": 2410
    },
    {
      "epoch": 0.9073865766779152,
      "grad_norm": 1.163142204284668,
      "learning_rate": 1.9092613423322086e-05,
      "loss": 0.0773,
      "step": 2420
    },
    {
      "epoch": 0.9111361079865017,
      "grad_norm": 4.515849590301514,
      "learning_rate": 1.9088863892013502e-05,
      "loss": 0.0842,
      "step": 2430
    },
    {
      "epoch": 0.9148856392950881,
      "grad_norm": 4.9209442138671875,
      "learning_rate": 1.9085114360704914e-05,
      "loss": 0.0979,
      "step": 2440
    },
    {
      "epoch": 0.9186351706036745,
      "grad_norm": 6.199173450469971,
      "learning_rate": 1.9081364829396327e-05,
      "loss": 0.1212,
      "step": 2450
    },
    {
      "epoch": 0.922384701912261,
      "grad_norm": 4.831721305847168,
      "learning_rate": 1.9077615298087743e-05,
      "loss": 0.0657,
      "step": 2460
    },
    {
      "epoch": 0.9261342332208474,
      "grad_norm": 7.011257171630859,
      "learning_rate": 1.9073865766779155e-05,
      "loss": 0.0958,
      "step": 2470
    },
    {
      "epoch": 0.9298837645294338,
      "grad_norm": 5.259850978851318,
      "learning_rate": 1.9070116235470568e-05,
      "loss": 0.1069,
      "step": 2480
    },
    {
      "epoch": 0.9336332958380202,
      "grad_norm": 6.012189865112305,
      "learning_rate": 1.906636670416198e-05,
      "loss": 0.1022,
      "step": 2490
    },
    {
      "epoch": 0.9373828271466067,
      "grad_norm": 7.050934314727783,
      "learning_rate": 1.9062617172853396e-05,
      "loss": 0.1174,
      "step": 2500
    },
    {
      "epoch": 0.941132358455193,
      "grad_norm": 2.6196768283843994,
      "learning_rate": 1.905886764154481e-05,
      "loss": 0.0976,
      "step": 2510
    },
    {
      "epoch": 0.9448818897637795,
      "grad_norm": 5.529755592346191,
      "learning_rate": 1.905511811023622e-05,
      "loss": 0.0781,
      "step": 2520
    },
    {
      "epoch": 0.948631421072366,
      "grad_norm": 7.268599987030029,
      "learning_rate": 1.9051368578927637e-05,
      "loss": 0.0745,
      "step": 2530
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 4.6503424644470215,
      "learning_rate": 1.904761904761905e-05,
      "loss": 0.1194,
      "step": 2540
    },
    {
      "epoch": 0.9561304836895388,
      "grad_norm": 5.056396007537842,
      "learning_rate": 1.9043869516310462e-05,
      "loss": 0.0726,
      "step": 2550
    },
    {
      "epoch": 0.9598800149981253,
      "grad_norm": 1.217655062675476,
      "learning_rate": 1.9040119985001878e-05,
      "loss": 0.122,
      "step": 2560
    },
    {
      "epoch": 0.9636295463067117,
      "grad_norm": 3.297724485397339,
      "learning_rate": 1.903637045369329e-05,
      "loss": 0.0662,
      "step": 2570
    },
    {
      "epoch": 0.9673790776152981,
      "grad_norm": 3.5395560264587402,
      "learning_rate": 1.9032620922384703e-05,
      "loss": 0.092,
      "step": 2580
    },
    {
      "epoch": 0.9711286089238845,
      "grad_norm": 4.129652500152588,
      "learning_rate": 1.902887139107612e-05,
      "loss": 0.0676,
      "step": 2590
    },
    {
      "epoch": 0.974878140232471,
      "grad_norm": 5.063810348510742,
      "learning_rate": 1.902512185976753e-05,
      "loss": 0.0739,
      "step": 2600
    },
    {
      "epoch": 0.9786276715410573,
      "grad_norm": 4.93869161605835,
      "learning_rate": 1.9021372328458944e-05,
      "loss": 0.1018,
      "step": 2610
    },
    {
      "epoch": 0.9823772028496438,
      "grad_norm": 4.311721324920654,
      "learning_rate": 1.9017622797150356e-05,
      "loss": 0.099,
      "step": 2620
    },
    {
      "epoch": 0.9861267341582303,
      "grad_norm": 5.534433841705322,
      "learning_rate": 1.9013873265841772e-05,
      "loss": 0.1016,
      "step": 2630
    },
    {
      "epoch": 0.9898762654668166,
      "grad_norm": 4.296401023864746,
      "learning_rate": 1.9010123734533185e-05,
      "loss": 0.0671,
      "step": 2640
    },
    {
      "epoch": 0.9936257967754031,
      "grad_norm": 3.7300562858581543,
      "learning_rate": 1.9006374203224597e-05,
      "loss": 0.079,
      "step": 2650
    },
    {
      "epoch": 0.9973753280839895,
      "grad_norm": 6.677083492279053,
      "learning_rate": 1.9002624671916013e-05,
      "loss": 0.0778,
      "step": 2660
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9732429279673375,
      "eval_f1": 0.8897566836887956,
      "eval_loss": 0.0774083361029625,
      "eval_precision": 0.9551757497581426,
      "eval_recall": 0.8327242057913973,
      "eval_runtime": 868.8511,
      "eval_samples_per_second": 31.574,
      "eval_steps_per_second": 1.317,
      "step": 2667
    },
    {
      "epoch": 1.001124859392576,
      "grad_norm": 0.14101071655750275,
      "learning_rate": 1.8998875140607425e-05,
      "loss": 0.0943,
      "step": 2670
    },
    {
      "epoch": 1.0048743907011624,
      "grad_norm": 3.2010185718536377,
      "learning_rate": 1.8995125609298838e-05,
      "loss": 0.0474,
      "step": 2680
    },
    {
      "epoch": 1.0086239220097488,
      "grad_norm": 1.5459004640579224,
      "learning_rate": 1.8991376077990254e-05,
      "loss": 0.0559,
      "step": 2690
    },
    {
      "epoch": 1.0123734533183353,
      "grad_norm": 2.819000720977783,
      "learning_rate": 1.8987626546681666e-05,
      "loss": 0.1068,
      "step": 2700
    },
    {
      "epoch": 1.0161229846269217,
      "grad_norm": 2.2481257915496826,
      "learning_rate": 1.898387701537308e-05,
      "loss": 0.1069,
      "step": 2710
    },
    {
      "epoch": 1.019872515935508,
      "grad_norm": 4.229959964752197,
      "learning_rate": 1.8980127484064495e-05,
      "loss": 0.097,
      "step": 2720
    },
    {
      "epoch": 1.0236220472440944,
      "grad_norm": 0.7040084004402161,
      "learning_rate": 1.8976377952755907e-05,
      "loss": 0.0576,
      "step": 2730
    },
    {
      "epoch": 1.027371578552681,
      "grad_norm": 1.5155149698257446,
      "learning_rate": 1.897262842144732e-05,
      "loss": 0.0554,
      "step": 2740
    },
    {
      "epoch": 1.0311211098612674,
      "grad_norm": 8.718505859375,
      "learning_rate": 1.8968878890138732e-05,
      "loss": 0.0496,
      "step": 2750
    },
    {
      "epoch": 1.0348706411698538,
      "grad_norm": 2.8503787517547607,
      "learning_rate": 1.8965129358830148e-05,
      "loss": 0.0553,
      "step": 2760
    },
    {
      "epoch": 1.0386201724784403,
      "grad_norm": 2.4077789783477783,
      "learning_rate": 1.896137982752156e-05,
      "loss": 0.0687,
      "step": 2770
    },
    {
      "epoch": 1.0423697037870265,
      "grad_norm": 5.431771755218506,
      "learning_rate": 1.8957630296212973e-05,
      "loss": 0.0489,
      "step": 2780
    },
    {
      "epoch": 1.046119235095613,
      "grad_norm": 6.333937644958496,
      "learning_rate": 1.895388076490439e-05,
      "loss": 0.1096,
      "step": 2790
    },
    {
      "epoch": 1.0498687664041995,
      "grad_norm": 4.528743267059326,
      "learning_rate": 1.89501312335958e-05,
      "loss": 0.0613,
      "step": 2800
    },
    {
      "epoch": 1.053618297712786,
      "grad_norm": 4.799342632293701,
      "learning_rate": 1.8946381702287214e-05,
      "loss": 0.099,
      "step": 2810
    },
    {
      "epoch": 1.0573678290213724,
      "grad_norm": 4.0897440910339355,
      "learning_rate": 1.894263217097863e-05,
      "loss": 0.1118,
      "step": 2820
    },
    {
      "epoch": 1.0611173603299588,
      "grad_norm": 3.164933681488037,
      "learning_rate": 1.8938882639670042e-05,
      "loss": 0.0767,
      "step": 2830
    },
    {
      "epoch": 1.064866891638545,
      "grad_norm": 0.7373620867729187,
      "learning_rate": 1.8935133108361455e-05,
      "loss": 0.0836,
      "step": 2840
    },
    {
      "epoch": 1.0686164229471316,
      "grad_norm": 0.6240936517715454,
      "learning_rate": 1.893138357705287e-05,
      "loss": 0.0571,
      "step": 2850
    },
    {
      "epoch": 1.072365954255718,
      "grad_norm": 9.03050708770752,
      "learning_rate": 1.8927634045744283e-05,
      "loss": 0.0844,
      "step": 2860
    },
    {
      "epoch": 1.0761154855643045,
      "grad_norm": 6.148168087005615,
      "learning_rate": 1.89238845144357e-05,
      "loss": 0.1075,
      "step": 2870
    },
    {
      "epoch": 1.079865016872891,
      "grad_norm": 2.383268117904663,
      "learning_rate": 1.8920134983127108e-05,
      "loss": 0.0712,
      "step": 2880
    },
    {
      "epoch": 1.0836145481814774,
      "grad_norm": 6.5269575119018555,
      "learning_rate": 1.8916385451818524e-05,
      "loss": 0.1098,
      "step": 2890
    },
    {
      "epoch": 1.0873640794900636,
      "grad_norm": 3.3806512355804443,
      "learning_rate": 1.891263592050994e-05,
      "loss": 0.0617,
      "step": 2900
    },
    {
      "epoch": 1.09111361079865,
      "grad_norm": 4.851531982421875,
      "learning_rate": 1.8908886389201352e-05,
      "loss": 0.0664,
      "step": 2910
    },
    {
      "epoch": 1.0948631421072366,
      "grad_norm": 3.0799829959869385,
      "learning_rate": 1.8905136857892765e-05,
      "loss": 0.0572,
      "step": 2920
    },
    {
      "epoch": 1.098612673415823,
      "grad_norm": 1.063706398010254,
      "learning_rate": 1.890138732658418e-05,
      "loss": 0.0522,
      "step": 2930
    },
    {
      "epoch": 1.1023622047244095,
      "grad_norm": 2.547321319580078,
      "learning_rate": 1.8897637795275593e-05,
      "loss": 0.0377,
      "step": 2940
    },
    {
      "epoch": 1.106111736032996,
      "grad_norm": 0.05402296036481857,
      "learning_rate": 1.8893888263967006e-05,
      "loss": 0.0436,
      "step": 2950
    },
    {
      "epoch": 1.1098612673415822,
      "grad_norm": 3.142526626586914,
      "learning_rate": 1.8890138732658418e-05,
      "loss": 0.0314,
      "step": 2960
    },
    {
      "epoch": 1.1136107986501687,
      "grad_norm": 5.099065780639648,
      "learning_rate": 1.8886389201349834e-05,
      "loss": 0.1128,
      "step": 2970
    },
    {
      "epoch": 1.1173603299587551,
      "grad_norm": 4.488048076629639,
      "learning_rate": 1.8882639670041247e-05,
      "loss": 0.1031,
      "step": 2980
    },
    {
      "epoch": 1.1211098612673416,
      "grad_norm": 8.37503719329834,
      "learning_rate": 1.887889013873266e-05,
      "loss": 0.0754,
      "step": 2990
    },
    {
      "epoch": 1.124859392575928,
      "grad_norm": 4.321930408477783,
      "learning_rate": 1.8875140607424075e-05,
      "loss": 0.0691,
      "step": 3000
    },
    {
      "epoch": 1.1286089238845145,
      "grad_norm": 1.6333394050598145,
      "learning_rate": 1.8871391076115488e-05,
      "loss": 0.0366,
      "step": 3010
    },
    {
      "epoch": 1.132358455193101,
      "grad_norm": 4.517513751983643,
      "learning_rate": 1.88676415448069e-05,
      "loss": 0.06,
      "step": 3020
    },
    {
      "epoch": 1.1361079865016872,
      "grad_norm": 0.5673322677612305,
      "learning_rate": 1.8863892013498316e-05,
      "loss": 0.0253,
      "step": 3030
    },
    {
      "epoch": 1.1398575178102737,
      "grad_norm": 4.816463947296143,
      "learning_rate": 1.886014248218973e-05,
      "loss": 0.085,
      "step": 3040
    },
    {
      "epoch": 1.1436070491188601,
      "grad_norm": 1.7344132661819458,
      "learning_rate": 1.885639295088114e-05,
      "loss": 0.0593,
      "step": 3050
    },
    {
      "epoch": 1.1473565804274466,
      "grad_norm": 1.2304099798202515,
      "learning_rate": 1.8852643419572557e-05,
      "loss": 0.0676,
      "step": 3060
    },
    {
      "epoch": 1.151106111736033,
      "grad_norm": 1.3503282070159912,
      "learning_rate": 1.884889388826397e-05,
      "loss": 0.0495,
      "step": 3070
    },
    {
      "epoch": 1.1548556430446195,
      "grad_norm": 1.9216184616088867,
      "learning_rate": 1.8845144356955382e-05,
      "loss": 0.0631,
      "step": 3080
    },
    {
      "epoch": 1.1586051743532058,
      "grad_norm": 2.3680920600891113,
      "learning_rate": 1.8841394825646794e-05,
      "loss": 0.0792,
      "step": 3090
    },
    {
      "epoch": 1.1623547056617922,
      "grad_norm": 9.278555870056152,
      "learning_rate": 1.883764529433821e-05,
      "loss": 0.0559,
      "step": 3100
    },
    {
      "epoch": 1.1661042369703787,
      "grad_norm": 5.12541389465332,
      "learning_rate": 1.8833895763029623e-05,
      "loss": 0.0643,
      "step": 3110
    },
    {
      "epoch": 1.1698537682789651,
      "grad_norm": 0.5790496468544006,
      "learning_rate": 1.8830146231721035e-05,
      "loss": 0.0568,
      "step": 3120
    },
    {
      "epoch": 1.1736032995875516,
      "grad_norm": 4.672746181488037,
      "learning_rate": 1.882639670041245e-05,
      "loss": 0.0704,
      "step": 3130
    },
    {
      "epoch": 1.177352830896138,
      "grad_norm": 9.387811660766602,
      "learning_rate": 1.8822647169103864e-05,
      "loss": 0.0837,
      "step": 3140
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 2.2641048431396484,
      "learning_rate": 1.8818897637795276e-05,
      "loss": 0.0457,
      "step": 3150
    },
    {
      "epoch": 1.1848518935133108,
      "grad_norm": 2.792736530303955,
      "learning_rate": 1.8815148106486692e-05,
      "loss": 0.0538,
      "step": 3160
    },
    {
      "epoch": 1.1886014248218972,
      "grad_norm": 5.8987932205200195,
      "learning_rate": 1.8811398575178104e-05,
      "loss": 0.0539,
      "step": 3170
    },
    {
      "epoch": 1.1923509561304837,
      "grad_norm": 3.4770259857177734,
      "learning_rate": 1.8807649043869517e-05,
      "loss": 0.0557,
      "step": 3180
    },
    {
      "epoch": 1.1961004874390702,
      "grad_norm": 2.2481048107147217,
      "learning_rate": 1.8803899512560933e-05,
      "loss": 0.0331,
      "step": 3190
    },
    {
      "epoch": 1.1998500187476566,
      "grad_norm": 1.8970404863357544,
      "learning_rate": 1.8800149981252345e-05,
      "loss": 0.0721,
      "step": 3200
    },
    {
      "epoch": 1.2035995500562429,
      "grad_norm": 6.041759967803955,
      "learning_rate": 1.8796400449943758e-05,
      "loss": 0.0536,
      "step": 3210
    },
    {
      "epoch": 1.2073490813648293,
      "grad_norm": 0.3237074911594391,
      "learning_rate": 1.879265091863517e-05,
      "loss": 0.0487,
      "step": 3220
    },
    {
      "epoch": 1.2110986126734158,
      "grad_norm": 3.6701581478118896,
      "learning_rate": 1.8788901387326586e-05,
      "loss": 0.1049,
      "step": 3230
    },
    {
      "epoch": 1.2148481439820022,
      "grad_norm": 4.16197395324707,
      "learning_rate": 1.8785151856018e-05,
      "loss": 0.091,
      "step": 3240
    },
    {
      "epoch": 1.2185976752905887,
      "grad_norm": 0.6223547458648682,
      "learning_rate": 1.878140232470941e-05,
      "loss": 0.0707,
      "step": 3250
    },
    {
      "epoch": 1.2223472065991752,
      "grad_norm": 5.319467067718506,
      "learning_rate": 1.8777652793400827e-05,
      "loss": 0.0897,
      "step": 3260
    },
    {
      "epoch": 1.2260967379077616,
      "grad_norm": 1.6028578281402588,
      "learning_rate": 1.877390326209224e-05,
      "loss": 0.0447,
      "step": 3270
    },
    {
      "epoch": 1.2298462692163479,
      "grad_norm": 5.990649223327637,
      "learning_rate": 1.8770153730783652e-05,
      "loss": 0.1031,
      "step": 3280
    },
    {
      "epoch": 1.2335958005249343,
      "grad_norm": 3.7401490211486816,
      "learning_rate": 1.8766404199475068e-05,
      "loss": 0.0898,
      "step": 3290
    },
    {
      "epoch": 1.2373453318335208,
      "grad_norm": 3.9085307121276855,
      "learning_rate": 1.876265466816648e-05,
      "loss": 0.0721,
      "step": 3300
    },
    {
      "epoch": 1.2410948631421073,
      "grad_norm": 5.427596569061279,
      "learning_rate": 1.8758905136857893e-05,
      "loss": 0.0588,
      "step": 3310
    },
    {
      "epoch": 1.2448443944506937,
      "grad_norm": 5.137045860290527,
      "learning_rate": 1.875515560554931e-05,
      "loss": 0.0483,
      "step": 3320
    },
    {
      "epoch": 1.24859392575928,
      "grad_norm": 4.917011260986328,
      "learning_rate": 1.875140607424072e-05,
      "loss": 0.0634,
      "step": 3330
    },
    {
      "epoch": 1.2523434570678664,
      "grad_norm": 4.888295650482178,
      "learning_rate": 1.8747656542932137e-05,
      "loss": 0.0612,
      "step": 3340
    },
    {
      "epoch": 1.256092988376453,
      "grad_norm": 5.055961608886719,
      "learning_rate": 1.8743907011623546e-05,
      "loss": 0.0713,
      "step": 3350
    },
    {
      "epoch": 1.2598425196850394,
      "grad_norm": 2.9750325679779053,
      "learning_rate": 1.8740157480314962e-05,
      "loss": 0.0738,
      "step": 3360
    },
    {
      "epoch": 1.2635920509936258,
      "grad_norm": 3.5054385662078857,
      "learning_rate": 1.8736407949006378e-05,
      "loss": 0.0261,
      "step": 3370
    },
    {
      "epoch": 1.2673415823022123,
      "grad_norm": 6.826432704925537,
      "learning_rate": 1.873265841769779e-05,
      "loss": 0.0921,
      "step": 3380
    },
    {
      "epoch": 1.2710911136107987,
      "grad_norm": 12.743643760681152,
      "learning_rate": 1.8728908886389203e-05,
      "loss": 0.0764,
      "step": 3390
    },
    {
      "epoch": 1.2748406449193852,
      "grad_norm": 0.5119888186454773,
      "learning_rate": 1.8725159355080615e-05,
      "loss": 0.0348,
      "step": 3400
    },
    {
      "epoch": 1.2785901762279714,
      "grad_norm": 0.7937233448028564,
      "learning_rate": 1.872140982377203e-05,
      "loss": 0.0318,
      "step": 3410
    },
    {
      "epoch": 1.282339707536558,
      "grad_norm": 6.399708271026611,
      "learning_rate": 1.8717660292463444e-05,
      "loss": 0.0758,
      "step": 3420
    },
    {
      "epoch": 1.2860892388451444,
      "grad_norm": 3.5017590522766113,
      "learning_rate": 1.8713910761154856e-05,
      "loss": 0.0997,
      "step": 3430
    },
    {
      "epoch": 1.2898387701537308,
      "grad_norm": 16.711402893066406,
      "learning_rate": 1.8710161229846272e-05,
      "loss": 0.0411,
      "step": 3440
    },
    {
      "epoch": 1.2935883014623173,
      "grad_norm": 1.2773548364639282,
      "learning_rate": 1.8706411698537685e-05,
      "loss": 0.0701,
      "step": 3450
    },
    {
      "epoch": 1.2973378327709035,
      "grad_norm": 3.7588932514190674,
      "learning_rate": 1.8702662167229097e-05,
      "loss": 0.0592,
      "step": 3460
    },
    {
      "epoch": 1.30108736407949,
      "grad_norm": 4.228743076324463,
      "learning_rate": 1.8698912635920513e-05,
      "loss": 0.0474,
      "step": 3470
    },
    {
      "epoch": 1.3048368953880765,
      "grad_norm": 2.8081119060516357,
      "learning_rate": 1.8695163104611926e-05,
      "loss": 0.0467,
      "step": 3480
    },
    {
      "epoch": 1.308586426696663,
      "grad_norm": 3.2604594230651855,
      "learning_rate": 1.8691413573303338e-05,
      "loss": 0.0706,
      "step": 3490
    },
    {
      "epoch": 1.3123359580052494,
      "grad_norm": 0.09664388000965118,
      "learning_rate": 1.8687664041994754e-05,
      "loss": 0.0397,
      "step": 3500
    },
    {
      "epoch": 1.3160854893138358,
      "grad_norm": 2.677562952041626,
      "learning_rate": 1.8683914510686166e-05,
      "loss": 0.0953,
      "step": 3510
    },
    {
      "epoch": 1.3198350206224223,
      "grad_norm": 1.729398250579834,
      "learning_rate": 1.868016497937758e-05,
      "loss": 0.1012,
      "step": 3520
    },
    {
      "epoch": 1.3235845519310085,
      "grad_norm": 4.284608840942383,
      "learning_rate": 1.867641544806899e-05,
      "loss": 0.0646,
      "step": 3530
    },
    {
      "epoch": 1.327334083239595,
      "grad_norm": 3.7108728885650635,
      "learning_rate": 1.8672665916760407e-05,
      "loss": 0.0772,
      "step": 3540
    },
    {
      "epoch": 1.3310836145481815,
      "grad_norm": 6.0561113357543945,
      "learning_rate": 1.866891638545182e-05,
      "loss": 0.0801,
      "step": 3550
    },
    {
      "epoch": 1.334833145856768,
      "grad_norm": 0.05023536831140518,
      "learning_rate": 1.8665166854143232e-05,
      "loss": 0.0764,
      "step": 3560
    },
    {
      "epoch": 1.3385826771653544,
      "grad_norm": 10.185288429260254,
      "learning_rate": 1.8661417322834648e-05,
      "loss": 0.0848,
      "step": 3570
    },
    {
      "epoch": 1.3423322084739406,
      "grad_norm": 4.019924640655518,
      "learning_rate": 1.865766779152606e-05,
      "loss": 0.0724,
      "step": 3580
    },
    {
      "epoch": 1.346081739782527,
      "grad_norm": 7.9802117347717285,
      "learning_rate": 1.8653918260217473e-05,
      "loss": 0.0658,
      "step": 3590
    },
    {
      "epoch": 1.3498312710911136,
      "grad_norm": 0.8088780045509338,
      "learning_rate": 1.865016872890889e-05,
      "loss": 0.0671,
      "step": 3600
    },
    {
      "epoch": 1.3535808023997,
      "grad_norm": 2.2136430740356445,
      "learning_rate": 1.86464191976003e-05,
      "loss": 0.0518,
      "step": 3610
    },
    {
      "epoch": 1.3573303337082865,
      "grad_norm": 6.0493693351745605,
      "learning_rate": 1.8642669666291714e-05,
      "loss": 0.0484,
      "step": 3620
    },
    {
      "epoch": 1.361079865016873,
      "grad_norm": 2.922196388244629,
      "learning_rate": 1.863892013498313e-05,
      "loss": 0.0584,
      "step": 3630
    },
    {
      "epoch": 1.3648293963254594,
      "grad_norm": 2.5799896717071533,
      "learning_rate": 1.8635170603674542e-05,
      "loss": 0.0497,
      "step": 3640
    },
    {
      "epoch": 1.3685789276340459,
      "grad_norm": 7.397877216339111,
      "learning_rate": 1.8631421072365955e-05,
      "loss": 0.086,
      "step": 3650
    },
    {
      "epoch": 1.3723284589426321,
      "grad_norm": 2.9325101375579834,
      "learning_rate": 1.8627671541057367e-05,
      "loss": 0.0611,
      "step": 3660
    },
    {
      "epoch": 1.3760779902512186,
      "grad_norm": 2.6407899856567383,
      "learning_rate": 1.8623922009748783e-05,
      "loss": 0.0686,
      "step": 3670
    },
    {
      "epoch": 1.379827521559805,
      "grad_norm": 0.6823965311050415,
      "learning_rate": 1.8620172478440196e-05,
      "loss": 0.0215,
      "step": 3680
    },
    {
      "epoch": 1.3835770528683915,
      "grad_norm": 7.460624694824219,
      "learning_rate": 1.8616422947131608e-05,
      "loss": 0.0378,
      "step": 3690
    },
    {
      "epoch": 1.3873265841769777,
      "grad_norm": 0.3075098395347595,
      "learning_rate": 1.8612673415823024e-05,
      "loss": 0.0749,
      "step": 3700
    },
    {
      "epoch": 1.3910761154855642,
      "grad_norm": 2.8011903762817383,
      "learning_rate": 1.8608923884514437e-05,
      "loss": 0.0535,
      "step": 3710
    },
    {
      "epoch": 1.3948256467941507,
      "grad_norm": 0.3954907953739166,
      "learning_rate": 1.860517435320585e-05,
      "loss": 0.0661,
      "step": 3720
    },
    {
      "epoch": 1.3985751781027371,
      "grad_norm": 12.321444511413574,
      "learning_rate": 1.8601424821897265e-05,
      "loss": 0.0728,
      "step": 3730
    },
    {
      "epoch": 1.4023247094113236,
      "grad_norm": 1.912266492843628,
      "learning_rate": 1.8597675290588678e-05,
      "loss": 0.0891,
      "step": 3740
    },
    {
      "epoch": 1.40607424071991,
      "grad_norm": 0.4782479405403137,
      "learning_rate": 1.859392575928009e-05,
      "loss": 0.0398,
      "step": 3750
    },
    {
      "epoch": 1.4098237720284965,
      "grad_norm": 1.8856768608093262,
      "learning_rate": 1.8590176227971506e-05,
      "loss": 0.0688,
      "step": 3760
    },
    {
      "epoch": 1.413573303337083,
      "grad_norm": 6.813032627105713,
      "learning_rate": 1.858642669666292e-05,
      "loss": 0.0526,
      "step": 3770
    },
    {
      "epoch": 1.4173228346456692,
      "grad_norm": 2.100602626800537,
      "learning_rate": 1.858267716535433e-05,
      "loss": 0.0541,
      "step": 3780
    },
    {
      "epoch": 1.4210723659542557,
      "grad_norm": 0.5317448377609253,
      "learning_rate": 1.8578927634045743e-05,
      "loss": 0.046,
      "step": 3790
    },
    {
      "epoch": 1.4248218972628421,
      "grad_norm": 5.255768299102783,
      "learning_rate": 1.857517810273716e-05,
      "loss": 0.0725,
      "step": 3800
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 5.038381099700928,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 0.0354,
      "step": 3810
    },
    {
      "epoch": 1.432320959880015,
      "grad_norm": 1.6337109804153442,
      "learning_rate": 1.8567679040119984e-05,
      "loss": 0.0967,
      "step": 3820
    },
    {
      "epoch": 1.4360704911886013,
      "grad_norm": 2.3630034923553467,
      "learning_rate": 1.85639295088114e-05,
      "loss": 0.0652,
      "step": 3830
    },
    {
      "epoch": 1.4398200224971878,
      "grad_norm": 1.4142847061157227,
      "learning_rate": 1.8560179977502816e-05,
      "loss": 0.0727,
      "step": 3840
    },
    {
      "epoch": 1.4435695538057742,
      "grad_norm": 3.648808717727661,
      "learning_rate": 1.855643044619423e-05,
      "loss": 0.0743,
      "step": 3850
    },
    {
      "epoch": 1.4473190851143607,
      "grad_norm": 2.8355705738067627,
      "learning_rate": 1.855268091488564e-05,
      "loss": 0.0409,
      "step": 3860
    },
    {
      "epoch": 1.4510686164229472,
      "grad_norm": 4.065879821777344,
      "learning_rate": 1.8548931383577053e-05,
      "loss": 0.0783,
      "step": 3870
    },
    {
      "epoch": 1.4548181477315336,
      "grad_norm": 0.6935106515884399,
      "learning_rate": 1.854518185226847e-05,
      "loss": 0.0623,
      "step": 3880
    },
    {
      "epoch": 1.45856767904012,
      "grad_norm": 7.097862243652344,
      "learning_rate": 1.8541432320959882e-05,
      "loss": 0.0572,
      "step": 3890
    },
    {
      "epoch": 1.4623172103487065,
      "grad_norm": 2.6870150566101074,
      "learning_rate": 1.8537682789651294e-05,
      "loss": 0.0522,
      "step": 3900
    },
    {
      "epoch": 1.4660667416572928,
      "grad_norm": 4.9525628089904785,
      "learning_rate": 1.853393325834271e-05,
      "loss": 0.0433,
      "step": 3910
    },
    {
      "epoch": 1.4698162729658792,
      "grad_norm": 0.6984530687332153,
      "learning_rate": 1.8530183727034123e-05,
      "loss": 0.0546,
      "step": 3920
    },
    {
      "epoch": 1.4735658042744657,
      "grad_norm": 0.48244884610176086,
      "learning_rate": 1.8526434195725535e-05,
      "loss": 0.0404,
      "step": 3930
    },
    {
      "epoch": 1.4773153355830522,
      "grad_norm": 9.596485137939453,
      "learning_rate": 1.852268466441695e-05,
      "loss": 0.0629,
      "step": 3940
    },
    {
      "epoch": 1.4810648668916384,
      "grad_norm": 2.3417837619781494,
      "learning_rate": 1.8518935133108364e-05,
      "loss": 0.0247,
      "step": 3950
    },
    {
      "epoch": 1.4848143982002249,
      "grad_norm": 3.639029026031494,
      "learning_rate": 1.8515185601799776e-05,
      "loss": 0.0712,
      "step": 3960
    },
    {
      "epoch": 1.4885639295088113,
      "grad_norm": 2.8758561611175537,
      "learning_rate": 1.8511436070491192e-05,
      "loss": 0.0732,
      "step": 3970
    },
    {
      "epoch": 1.4923134608173978,
      "grad_norm": 4.087376594543457,
      "learning_rate": 1.8507686539182604e-05,
      "loss": 0.045,
      "step": 3980
    },
    {
      "epoch": 1.4960629921259843,
      "grad_norm": 4.054265022277832,
      "learning_rate": 1.8503937007874017e-05,
      "loss": 0.0882,
      "step": 3990
    },
    {
      "epoch": 1.4998125234345707,
      "grad_norm": 3.8407585620880127,
      "learning_rate": 1.850018747656543e-05,
      "loss": 0.0564,
      "step": 4000
    },
    {
      "epoch": 1.5035620547431572,
      "grad_norm": 2.102916955947876,
      "learning_rate": 1.8496437945256845e-05,
      "loss": 0.0525,
      "step": 4010
    },
    {
      "epoch": 1.5073115860517436,
      "grad_norm": 4.7758002281188965,
      "learning_rate": 1.8492688413948258e-05,
      "loss": 0.0692,
      "step": 4020
    },
    {
      "epoch": 1.51106111736033,
      "grad_norm": 7.855788230895996,
      "learning_rate": 1.848893888263967e-05,
      "loss": 0.0769,
      "step": 4030
    },
    {
      "epoch": 1.5148106486689163,
      "grad_norm": 0.3033478260040283,
      "learning_rate": 1.8485189351331086e-05,
      "loss": 0.0583,
      "step": 4040
    },
    {
      "epoch": 1.5185601799775028,
      "grad_norm": 1.0816547870635986,
      "learning_rate": 1.84814398200225e-05,
      "loss": 0.0311,
      "step": 4050
    },
    {
      "epoch": 1.5223097112860893,
      "grad_norm": 6.120344638824463,
      "learning_rate": 1.847769028871391e-05,
      "loss": 0.0472,
      "step": 4060
    },
    {
      "epoch": 1.5260592425946755,
      "grad_norm": 4.804201602935791,
      "learning_rate": 1.8473940757405327e-05,
      "loss": 0.08,
      "step": 4070
    },
    {
      "epoch": 1.529808773903262,
      "grad_norm": 3.7904956340789795,
      "learning_rate": 1.847019122609674e-05,
      "loss": 0.0475,
      "step": 4080
    },
    {
      "epoch": 1.5335583052118484,
      "grad_norm": 4.947249889373779,
      "learning_rate": 1.8466441694788152e-05,
      "loss": 0.0245,
      "step": 4090
    },
    {
      "epoch": 1.537307836520435,
      "grad_norm": 5.32640266418457,
      "learning_rate": 1.8462692163479568e-05,
      "loss": 0.0315,
      "step": 4100
    },
    {
      "epoch": 1.5410573678290214,
      "grad_norm": 6.770166873931885,
      "learning_rate": 1.845894263217098e-05,
      "loss": 0.0606,
      "step": 4110
    },
    {
      "epoch": 1.5448068991376078,
      "grad_norm": 10.222084999084473,
      "learning_rate": 1.8455193100862393e-05,
      "loss": 0.1057,
      "step": 4120
    },
    {
      "epoch": 1.5485564304461943,
      "grad_norm": 1.057916283607483,
      "learning_rate": 1.8451443569553805e-05,
      "loss": 0.0872,
      "step": 4130
    },
    {
      "epoch": 1.5523059617547807,
      "grad_norm": 3.111967086791992,
      "learning_rate": 1.844769403824522e-05,
      "loss": 0.0453,
      "step": 4140
    },
    {
      "epoch": 1.5560554930633672,
      "grad_norm": 1.815494418144226,
      "learning_rate": 1.8443944506936634e-05,
      "loss": 0.0477,
      "step": 4150
    },
    {
      "epoch": 1.5598050243719535,
      "grad_norm": 8.971829414367676,
      "learning_rate": 1.8440194975628046e-05,
      "loss": 0.1016,
      "step": 4160
    },
    {
      "epoch": 1.56355455568054,
      "grad_norm": 1.1351635456085205,
      "learning_rate": 1.8436445444319462e-05,
      "loss": 0.0297,
      "step": 4170
    },
    {
      "epoch": 1.5673040869891264,
      "grad_norm": 4.6030426025390625,
      "learning_rate": 1.8432695913010875e-05,
      "loss": 0.0852,
      "step": 4180
    },
    {
      "epoch": 1.5710536182977128,
      "grad_norm": 3.941415786743164,
      "learning_rate": 1.8428946381702287e-05,
      "loss": 0.0699,
      "step": 4190
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.6462041139602661,
      "learning_rate": 1.8425196850393703e-05,
      "loss": 0.0815,
      "step": 4200
    },
    {
      "epoch": 1.5785526809148855,
      "grad_norm": 7.8997602462768555,
      "learning_rate": 1.8421447319085116e-05,
      "loss": 0.0534,
      "step": 4210
    },
    {
      "epoch": 1.582302212223472,
      "grad_norm": 5.291945934295654,
      "learning_rate": 1.8417697787776528e-05,
      "loss": 0.0416,
      "step": 4220
    },
    {
      "epoch": 1.5860517435320585,
      "grad_norm": 0.947324812412262,
      "learning_rate": 1.8413948256467944e-05,
      "loss": 0.0539,
      "step": 4230
    },
    {
      "epoch": 1.589801274840645,
      "grad_norm": 1.194006323814392,
      "learning_rate": 1.8410198725159356e-05,
      "loss": 0.0569,
      "step": 4240
    },
    {
      "epoch": 1.5935508061492314,
      "grad_norm": 3.3111720085144043,
      "learning_rate": 1.840644919385077e-05,
      "loss": 0.0384,
      "step": 4250
    },
    {
      "epoch": 1.5973003374578179,
      "grad_norm": 3.328463077545166,
      "learning_rate": 1.840269966254218e-05,
      "loss": 0.0561,
      "step": 4260
    },
    {
      "epoch": 1.6010498687664043,
      "grad_norm": 0.32798245549201965,
      "learning_rate": 1.8398950131233597e-05,
      "loss": 0.0603,
      "step": 4270
    },
    {
      "epoch": 1.6047994000749908,
      "grad_norm": 3.98388671875,
      "learning_rate": 1.8395200599925013e-05,
      "loss": 0.0562,
      "step": 4280
    },
    {
      "epoch": 1.608548931383577,
      "grad_norm": 2.5070676803588867,
      "learning_rate": 1.8391451068616422e-05,
      "loss": 0.0365,
      "step": 4290
    },
    {
      "epoch": 1.6122984626921635,
      "grad_norm": 5.8899970054626465,
      "learning_rate": 1.8387701537307838e-05,
      "loss": 0.0364,
      "step": 4300
    },
    {
      "epoch": 1.61604799400075,
      "grad_norm": 0.3839176595211029,
      "learning_rate": 1.8383952005999254e-05,
      "loss": 0.0592,
      "step": 4310
    },
    {
      "epoch": 1.6197975253093362,
      "grad_norm": 9.485700607299805,
      "learning_rate": 1.8380202474690667e-05,
      "loss": 0.0391,
      "step": 4320
    },
    {
      "epoch": 1.6235470566179226,
      "grad_norm": 0.059967104345560074,
      "learning_rate": 1.837645294338208e-05,
      "loss": 0.0558,
      "step": 4330
    },
    {
      "epoch": 1.627296587926509,
      "grad_norm": 2.2241387367248535,
      "learning_rate": 1.837270341207349e-05,
      "loss": 0.0445,
      "step": 4340
    },
    {
      "epoch": 1.6310461192350956,
      "grad_norm": 2.9754691123962402,
      "learning_rate": 1.8368953880764907e-05,
      "loss": 0.1074,
      "step": 4350
    },
    {
      "epoch": 1.634795650543682,
      "grad_norm": 1.3132870197296143,
      "learning_rate": 1.836520434945632e-05,
      "loss": 0.037,
      "step": 4360
    },
    {
      "epoch": 1.6385451818522685,
      "grad_norm": 0.7827043533325195,
      "learning_rate": 1.8361454818147732e-05,
      "loss": 0.0483,
      "step": 4370
    },
    {
      "epoch": 1.642294713160855,
      "grad_norm": 1.0971934795379639,
      "learning_rate": 1.8357705286839148e-05,
      "loss": 0.0958,
      "step": 4380
    },
    {
      "epoch": 1.6460442444694414,
      "grad_norm": 10.392206192016602,
      "learning_rate": 1.835395575553056e-05,
      "loss": 0.0469,
      "step": 4390
    },
    {
      "epoch": 1.6497937757780279,
      "grad_norm": 0.9232845306396484,
      "learning_rate": 1.8350206224221973e-05,
      "loss": 0.0409,
      "step": 4400
    },
    {
      "epoch": 1.6535433070866141,
      "grad_norm": 0.3272177577018738,
      "learning_rate": 1.834645669291339e-05,
      "loss": 0.0389,
      "step": 4410
    },
    {
      "epoch": 1.6572928383952006,
      "grad_norm": 2.1600921154022217,
      "learning_rate": 1.83427071616048e-05,
      "loss": 0.0573,
      "step": 4420
    },
    {
      "epoch": 1.661042369703787,
      "grad_norm": 1.869057536125183,
      "learning_rate": 1.8338957630296214e-05,
      "loss": 0.0859,
      "step": 4430
    },
    {
      "epoch": 1.6647919010123733,
      "grad_norm": 1.591393232345581,
      "learning_rate": 1.833520809898763e-05,
      "loss": 0.0514,
      "step": 4440
    },
    {
      "epoch": 1.6685414323209597,
      "grad_norm": 6.181228160858154,
      "learning_rate": 1.8331458567679042e-05,
      "loss": 0.0828,
      "step": 4450
    },
    {
      "epoch": 1.6722909636295462,
      "grad_norm": 3.5061097145080566,
      "learning_rate": 1.8327709036370455e-05,
      "loss": 0.0662,
      "step": 4460
    },
    {
      "epoch": 1.6760404949381327,
      "grad_norm": 2.1311440467834473,
      "learning_rate": 1.8323959505061867e-05,
      "loss": 0.0532,
      "step": 4470
    },
    {
      "epoch": 1.6797900262467191,
      "grad_norm": 3.0848166942596436,
      "learning_rate": 1.8320209973753283e-05,
      "loss": 0.0407,
      "step": 4480
    },
    {
      "epoch": 1.6835395575553056,
      "grad_norm": 4.915986061096191,
      "learning_rate": 1.8316460442444696e-05,
      "loss": 0.0373,
      "step": 4490
    },
    {
      "epoch": 1.687289088863892,
      "grad_norm": 7.229348182678223,
      "learning_rate": 1.831271091113611e-05,
      "loss": 0.0609,
      "step": 4500
    },
    {
      "epoch": 1.6910386201724785,
      "grad_norm": 6.553388595581055,
      "learning_rate": 1.8308961379827524e-05,
      "loss": 0.0707,
      "step": 4510
    },
    {
      "epoch": 1.694788151481065,
      "grad_norm": 0.22086183726787567,
      "learning_rate": 1.8305211848518937e-05,
      "loss": 0.072,
      "step": 4520
    },
    {
      "epoch": 1.6985376827896514,
      "grad_norm": 1.36994469165802,
      "learning_rate": 1.830146231721035e-05,
      "loss": 0.0713,
      "step": 4530
    },
    {
      "epoch": 1.7022872140982377,
      "grad_norm": 7.447640895843506,
      "learning_rate": 1.8297712785901765e-05,
      "loss": 0.0771,
      "step": 4540
    },
    {
      "epoch": 1.7060367454068242,
      "grad_norm": 4.252657413482666,
      "learning_rate": 1.8293963254593178e-05,
      "loss": 0.086,
      "step": 4550
    },
    {
      "epoch": 1.7097862767154106,
      "grad_norm": 1.5212167501449585,
      "learning_rate": 1.829021372328459e-05,
      "loss": 0.0916,
      "step": 4560
    },
    {
      "epoch": 1.7135358080239969,
      "grad_norm": 0.8531008362770081,
      "learning_rate": 1.8286464191976006e-05,
      "loss": 0.0431,
      "step": 4570
    },
    {
      "epoch": 1.7172853393325833,
      "grad_norm": 0.7118815183639526,
      "learning_rate": 1.828271466066742e-05,
      "loss": 0.0302,
      "step": 4580
    },
    {
      "epoch": 1.7210348706411698,
      "grad_norm": 4.169647216796875,
      "learning_rate": 1.827896512935883e-05,
      "loss": 0.0743,
      "step": 4590
    },
    {
      "epoch": 1.7247844019497562,
      "grad_norm": 4.051088809967041,
      "learning_rate": 1.8275215598050243e-05,
      "loss": 0.0314,
      "step": 4600
    },
    {
      "epoch": 1.7285339332583427,
      "grad_norm": 4.330721855163574,
      "learning_rate": 1.827146606674166e-05,
      "loss": 0.0587,
      "step": 4610
    },
    {
      "epoch": 1.7322834645669292,
      "grad_norm": 4.468472003936768,
      "learning_rate": 1.8267716535433072e-05,
      "loss": 0.0899,
      "step": 4620
    },
    {
      "epoch": 1.7360329958755156,
      "grad_norm": 2.7305328845977783,
      "learning_rate": 1.8263967004124484e-05,
      "loss": 0.0421,
      "step": 4630
    },
    {
      "epoch": 1.739782527184102,
      "grad_norm": 0.17379149794578552,
      "learning_rate": 1.82602174728159e-05,
      "loss": 0.0198,
      "step": 4640
    },
    {
      "epoch": 1.7435320584926886,
      "grad_norm": 3.723078727722168,
      "learning_rate": 1.8256467941507313e-05,
      "loss": 0.0541,
      "step": 4650
    },
    {
      "epoch": 1.7472815898012748,
      "grad_norm": 3.304572343826294,
      "learning_rate": 1.8252718410198725e-05,
      "loss": 0.047,
      "step": 4660
    },
    {
      "epoch": 1.7510311211098613,
      "grad_norm": 5.000499725341797,
      "learning_rate": 1.824896887889014e-05,
      "loss": 0.035,
      "step": 4670
    },
    {
      "epoch": 1.7547806524184477,
      "grad_norm": 1.7838023900985718,
      "learning_rate": 1.8245219347581554e-05,
      "loss": 0.0368,
      "step": 4680
    },
    {
      "epoch": 1.758530183727034,
      "grad_norm": 5.010620594024658,
      "learning_rate": 1.8241469816272966e-05,
      "loss": 0.0557,
      "step": 4690
    },
    {
      "epoch": 1.7622797150356204,
      "grad_norm": 3.5529611110687256,
      "learning_rate": 1.8237720284964382e-05,
      "loss": 0.0458,
      "step": 4700
    },
    {
      "epoch": 1.7660292463442069,
      "grad_norm": 8.450414657592773,
      "learning_rate": 1.8233970753655794e-05,
      "loss": 0.0456,
      "step": 4710
    },
    {
      "epoch": 1.7697787776527933,
      "grad_norm": 0.5471948385238647,
      "learning_rate": 1.8230221222347207e-05,
      "loss": 0.0229,
      "step": 4720
    },
    {
      "epoch": 1.7735283089613798,
      "grad_norm": 0.3840267062187195,
      "learning_rate": 1.822647169103862e-05,
      "loss": 0.0802,
      "step": 4730
    },
    {
      "epoch": 1.7772778402699663,
      "grad_norm": 3.15705943107605,
      "learning_rate": 1.8222722159730035e-05,
      "loss": 0.1235,
      "step": 4740
    },
    {
      "epoch": 1.7810273715785527,
      "grad_norm": 3.006443500518799,
      "learning_rate": 1.821897262842145e-05,
      "loss": 0.0292,
      "step": 4750
    },
    {
      "epoch": 1.7847769028871392,
      "grad_norm": 0.6269790530204773,
      "learning_rate": 1.821522309711286e-05,
      "loss": 0.0578,
      "step": 4760
    },
    {
      "epoch": 1.7885264341957257,
      "grad_norm": 1.2008622884750366,
      "learning_rate": 1.8211473565804276e-05,
      "loss": 0.0365,
      "step": 4770
    },
    {
      "epoch": 1.7922759655043121,
      "grad_norm": 1.4855360984802246,
      "learning_rate": 1.820772403449569e-05,
      "loss": 0.0429,
      "step": 4780
    },
    {
      "epoch": 1.7960254968128984,
      "grad_norm": 0.674528181552887,
      "learning_rate": 1.8203974503187105e-05,
      "loss": 0.0935,
      "step": 4790
    },
    {
      "epoch": 1.7997750281214848,
      "grad_norm": 4.648583889007568,
      "learning_rate": 1.8200224971878517e-05,
      "loss": 0.0755,
      "step": 4800
    },
    {
      "epoch": 1.8035245594300713,
      "grad_norm": 4.2258429527282715,
      "learning_rate": 1.819647544056993e-05,
      "loss": 0.0413,
      "step": 4810
    },
    {
      "epoch": 1.8072740907386575,
      "grad_norm": 0.8410405516624451,
      "learning_rate": 1.8192725909261345e-05,
      "loss": 0.0326,
      "step": 4820
    },
    {
      "epoch": 1.811023622047244,
      "grad_norm": 2.6290578842163086,
      "learning_rate": 1.8188976377952758e-05,
      "loss": 0.0565,
      "step": 4830
    },
    {
      "epoch": 1.8147731533558304,
      "grad_norm": 0.394206702709198,
      "learning_rate": 1.818522684664417e-05,
      "loss": 0.0363,
      "step": 4840
    },
    {
      "epoch": 1.818522684664417,
      "grad_norm": 2.589308023452759,
      "learning_rate": 1.8181477315335586e-05,
      "loss": 0.0387,
      "step": 4850
    },
    {
      "epoch": 1.8222722159730034,
      "grad_norm": 1.889775037765503,
      "learning_rate": 1.8177727784027e-05,
      "loss": 0.0215,
      "step": 4860
    },
    {
      "epoch": 1.8260217472815898,
      "grad_norm": 0.4458447992801666,
      "learning_rate": 1.817397825271841e-05,
      "loss": 0.0733,
      "step": 4870
    },
    {
      "epoch": 1.8297712785901763,
      "grad_norm": 2.808776617050171,
      "learning_rate": 1.8170228721409827e-05,
      "loss": 0.0568,
      "step": 4880
    },
    {
      "epoch": 1.8335208098987628,
      "grad_norm": 5.362389087677002,
      "learning_rate": 1.816647919010124e-05,
      "loss": 0.0619,
      "step": 4890
    },
    {
      "epoch": 1.8372703412073492,
      "grad_norm": 6.056384086608887,
      "learning_rate": 1.8162729658792652e-05,
      "loss": 0.0792,
      "step": 4900
    },
    {
      "epoch": 1.8410198725159355,
      "grad_norm": 4.346902847290039,
      "learning_rate": 1.8158980127484065e-05,
      "loss": 0.0456,
      "step": 4910
    },
    {
      "epoch": 1.844769403824522,
      "grad_norm": 1.7289015054702759,
      "learning_rate": 1.815523059617548e-05,
      "loss": 0.0347,
      "step": 4920
    },
    {
      "epoch": 1.8485189351331084,
      "grad_norm": 5.47685432434082,
      "learning_rate": 1.8151481064866893e-05,
      "loss": 0.0601,
      "step": 4930
    },
    {
      "epoch": 1.8522684664416946,
      "grad_norm": 3.1432929039001465,
      "learning_rate": 1.8147731533558306e-05,
      "loss": 0.0413,
      "step": 4940
    },
    {
      "epoch": 1.856017997750281,
      "grad_norm": 0.45244795083999634,
      "learning_rate": 1.814398200224972e-05,
      "loss": 0.0438,
      "step": 4950
    },
    {
      "epoch": 1.8597675290588676,
      "grad_norm": 1.9170066118240356,
      "learning_rate": 1.8140232470941134e-05,
      "loss": 0.0576,
      "step": 4960
    },
    {
      "epoch": 1.863517060367454,
      "grad_norm": 7.329104423522949,
      "learning_rate": 1.8136482939632546e-05,
      "loss": 0.0461,
      "step": 4970
    },
    {
      "epoch": 1.8672665916760405,
      "grad_norm": 2.6579227447509766,
      "learning_rate": 1.8132733408323962e-05,
      "loss": 0.0502,
      "step": 4980
    },
    {
      "epoch": 1.871016122984627,
      "grad_norm": 0.3179139494895935,
      "learning_rate": 1.8128983877015375e-05,
      "loss": 0.0492,
      "step": 4990
    },
    {
      "epoch": 1.8747656542932134,
      "grad_norm": 4.3844499588012695,
      "learning_rate": 1.8125234345706787e-05,
      "loss": 0.0619,
      "step": 5000
    },
    {
      "epoch": 1.8785151856017999,
      "grad_norm": 4.675167083740234,
      "learning_rate": 1.8121484814398203e-05,
      "loss": 0.0398,
      "step": 5010
    },
    {
      "epoch": 1.8822647169103863,
      "grad_norm": 0.07768528908491135,
      "learning_rate": 1.8117735283089616e-05,
      "loss": 0.0393,
      "step": 5020
    },
    {
      "epoch": 1.8860142482189728,
      "grad_norm": 1.4453773498535156,
      "learning_rate": 1.8113985751781028e-05,
      "loss": 0.0515,
      "step": 5030
    },
    {
      "epoch": 1.889763779527559,
      "grad_norm": 2.7994749546051025,
      "learning_rate": 1.811023622047244e-05,
      "loss": 0.0556,
      "step": 5040
    },
    {
      "epoch": 1.8935133108361455,
      "grad_norm": 3.5824568271636963,
      "learning_rate": 1.8106486689163856e-05,
      "loss": 0.0372,
      "step": 5050
    },
    {
      "epoch": 1.897262842144732,
      "grad_norm": 0.6587910652160645,
      "learning_rate": 1.810273715785527e-05,
      "loss": 0.0477,
      "step": 5060
    },
    {
      "epoch": 1.9010123734533182,
      "grad_norm": 2.627624273300171,
      "learning_rate": 1.809898762654668e-05,
      "loss": 0.0707,
      "step": 5070
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 0.8231619000434875,
      "learning_rate": 1.8095238095238097e-05,
      "loss": 0.0501,
      "step": 5080
    },
    {
      "epoch": 1.9085114360704911,
      "grad_norm": 4.43925142288208,
      "learning_rate": 1.809148856392951e-05,
      "loss": 0.052,
      "step": 5090
    },
    {
      "epoch": 1.9122609673790776,
      "grad_norm": 5.674166679382324,
      "learning_rate": 1.8087739032620922e-05,
      "loss": 0.0321,
      "step": 5100
    },
    {
      "epoch": 1.916010498687664,
      "grad_norm": 6.947929859161377,
      "learning_rate": 1.8083989501312338e-05,
      "loss": 0.0308,
      "step": 5110
    },
    {
      "epoch": 1.9197600299962505,
      "grad_norm": 2.901151418685913,
      "learning_rate": 1.808023997000375e-05,
      "loss": 0.0273,
      "step": 5120
    },
    {
      "epoch": 1.923509561304837,
      "grad_norm": 3.8634908199310303,
      "learning_rate": 1.8076490438695163e-05,
      "loss": 0.0722,
      "step": 5130
    },
    {
      "epoch": 1.9272590926134234,
      "grad_norm": 0.7743242383003235,
      "learning_rate": 1.807274090738658e-05,
      "loss": 0.0189,
      "step": 5140
    },
    {
      "epoch": 1.93100862392201,
      "grad_norm": 0.38833484053611755,
      "learning_rate": 1.806899137607799e-05,
      "loss": 0.0619,
      "step": 5150
    },
    {
      "epoch": 1.9347581552305961,
      "grad_norm": 0.24591098725795746,
      "learning_rate": 1.8065241844769404e-05,
      "loss": 0.0241,
      "step": 5160
    },
    {
      "epoch": 1.9385076865391826,
      "grad_norm": 6.019565582275391,
      "learning_rate": 1.8061492313460817e-05,
      "loss": 0.0378,
      "step": 5170
    },
    {
      "epoch": 1.942257217847769,
      "grad_norm": 4.786801338195801,
      "learning_rate": 1.8057742782152232e-05,
      "loss": 0.0426,
      "step": 5180
    },
    {
      "epoch": 1.9460067491563553,
      "grad_norm": 3.6025302410125732,
      "learning_rate": 1.8053993250843645e-05,
      "loss": 0.0429,
      "step": 5190
    },
    {
      "epoch": 1.9497562804649418,
      "grad_norm": 0.21192583441734314,
      "learning_rate": 1.8050243719535057e-05,
      "loss": 0.0551,
      "step": 5200
    },
    {
      "epoch": 1.9535058117735282,
      "grad_norm": 3.2355706691741943,
      "learning_rate": 1.8046494188226473e-05,
      "loss": 0.0604,
      "step": 5210
    },
    {
      "epoch": 1.9572553430821147,
      "grad_norm": 3.8305463790893555,
      "learning_rate": 1.804274465691789e-05,
      "loss": 0.074,
      "step": 5220
    },
    {
      "epoch": 1.9610048743907011,
      "grad_norm": 8.001988410949707,
      "learning_rate": 1.80389951256093e-05,
      "loss": 0.0441,
      "step": 5230
    },
    {
      "epoch": 1.9647544056992876,
      "grad_norm": 2.2219767570495605,
      "learning_rate": 1.8035245594300714e-05,
      "loss": 0.0473,
      "step": 5240
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 0.9679638147354126,
      "learning_rate": 1.8031496062992127e-05,
      "loss": 0.0431,
      "step": 5250
    },
    {
      "epoch": 1.9722534683164605,
      "grad_norm": 4.151545524597168,
      "learning_rate": 1.8027746531683543e-05,
      "loss": 0.0497,
      "step": 5260
    },
    {
      "epoch": 1.976002999625047,
      "grad_norm": 2.416212558746338,
      "learning_rate": 1.8023997000374955e-05,
      "loss": 0.0574,
      "step": 5270
    },
    {
      "epoch": 1.9797525309336335,
      "grad_norm": 4.3175435066223145,
      "learning_rate": 1.8020247469066368e-05,
      "loss": 0.0637,
      "step": 5280
    },
    {
      "epoch": 1.9835020622422197,
      "grad_norm": 1.5330418348312378,
      "learning_rate": 1.8016497937757783e-05,
      "loss": 0.0506,
      "step": 5290
    },
    {
      "epoch": 1.9872515935508062,
      "grad_norm": 3.3524363040924072,
      "learning_rate": 1.8012748406449196e-05,
      "loss": 0.065,
      "step": 5300
    },
    {
      "epoch": 1.9910011248593926,
      "grad_norm": 1.6627317667007446,
      "learning_rate": 1.800899887514061e-05,
      "loss": 0.0506,
      "step": 5310
    },
    {
      "epoch": 1.9947506561679789,
      "grad_norm": 4.222489833831787,
      "learning_rate": 1.8005249343832024e-05,
      "loss": 0.0545,
      "step": 5320
    },
    {
      "epoch": 1.9985001874765653,
      "grad_norm": 0.19898934662342072,
      "learning_rate": 1.8001499812523437e-05,
      "loss": 0.0645,
      "step": 5330
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9862933799941674,
      "eval_f1": 0.9464692482915718,
      "eval_loss": 0.03699832037091255,
      "eval_precision": 0.9587539659648111,
      "eval_recall": 0.9344953612594883,
      "eval_runtime": 866.4312,
      "eval_samples_per_second": 31.662,
      "eval_steps_per_second": 1.32,
      "step": 5334
    },
    {
      "epoch": 2.002249718785152,
      "grad_norm": 2.9097278118133545,
      "learning_rate": 1.799775028121485e-05,
      "loss": 0.0486,
      "step": 5340
    },
    {
      "epoch": 2.0059992500937383,
      "grad_norm": 1.4397971630096436,
      "learning_rate": 1.7994000749906265e-05,
      "loss": 0.0473,
      "step": 5350
    },
    {
      "epoch": 2.0097487814023247,
      "grad_norm": 6.500608444213867,
      "learning_rate": 1.7990251218597678e-05,
      "loss": 0.0323,
      "step": 5360
    },
    {
      "epoch": 2.013498312710911,
      "grad_norm": 2.7019331455230713,
      "learning_rate": 1.798650168728909e-05,
      "loss": 0.0478,
      "step": 5370
    },
    {
      "epoch": 2.0172478440194976,
      "grad_norm": 1.5731861591339111,
      "learning_rate": 1.7982752155980503e-05,
      "loss": 0.0228,
      "step": 5380
    },
    {
      "epoch": 2.020997375328084,
      "grad_norm": 2.7426414489746094,
      "learning_rate": 1.797900262467192e-05,
      "loss": 0.0401,
      "step": 5390
    },
    {
      "epoch": 2.0247469066366706,
      "grad_norm": 10.492328643798828,
      "learning_rate": 1.797525309336333e-05,
      "loss": 0.0645,
      "step": 5400
    },
    {
      "epoch": 2.028496437945257,
      "grad_norm": 0.08712489157915115,
      "learning_rate": 1.7971503562054744e-05,
      "loss": 0.0528,
      "step": 5410
    },
    {
      "epoch": 2.0322459692538435,
      "grad_norm": 4.02371883392334,
      "learning_rate": 1.796775403074616e-05,
      "loss": 0.0408,
      "step": 5420
    },
    {
      "epoch": 2.0359955005624295,
      "grad_norm": 0.3431732952594757,
      "learning_rate": 1.7964004499437572e-05,
      "loss": 0.0379,
      "step": 5430
    },
    {
      "epoch": 2.039745031871016,
      "grad_norm": 2.821343421936035,
      "learning_rate": 1.7960254968128984e-05,
      "loss": 0.015,
      "step": 5440
    },
    {
      "epoch": 2.0434945631796024,
      "grad_norm": 4.390161037445068,
      "learning_rate": 1.79565054368204e-05,
      "loss": 0.0629,
      "step": 5450
    },
    {
      "epoch": 2.047244094488189,
      "grad_norm": 2.1995186805725098,
      "learning_rate": 1.7952755905511813e-05,
      "loss": 0.0305,
      "step": 5460
    },
    {
      "epoch": 2.0509936257967754,
      "grad_norm": 0.5999758839607239,
      "learning_rate": 1.7949006374203225e-05,
      "loss": 0.0487,
      "step": 5470
    },
    {
      "epoch": 2.054743157105362,
      "grad_norm": 1.6720601320266724,
      "learning_rate": 1.794525684289464e-05,
      "loss": 0.0393,
      "step": 5480
    },
    {
      "epoch": 2.0584926884139483,
      "grad_norm": 6.937250137329102,
      "learning_rate": 1.7941507311586054e-05,
      "loss": 0.0412,
      "step": 5490
    },
    {
      "epoch": 2.0622422197225347,
      "grad_norm": 0.2698308825492859,
      "learning_rate": 1.7937757780277466e-05,
      "loss": 0.0558,
      "step": 5500
    },
    {
      "epoch": 2.065991751031121,
      "grad_norm": 3.1703569889068604,
      "learning_rate": 1.793400824896888e-05,
      "loss": 0.0429,
      "step": 5510
    },
    {
      "epoch": 2.0697412823397077,
      "grad_norm": 0.5616909861564636,
      "learning_rate": 1.7930258717660295e-05,
      "loss": 0.0194,
      "step": 5520
    },
    {
      "epoch": 2.073490813648294,
      "grad_norm": 0.9954331517219543,
      "learning_rate": 1.7926509186351707e-05,
      "loss": 0.0187,
      "step": 5530
    },
    {
      "epoch": 2.0772403449568806,
      "grad_norm": 4.846337795257568,
      "learning_rate": 1.792275965504312e-05,
      "loss": 0.0426,
      "step": 5540
    },
    {
      "epoch": 2.0809898762654666,
      "grad_norm": 8.4894437789917,
      "learning_rate": 1.7919010123734535e-05,
      "loss": 0.0841,
      "step": 5550
    },
    {
      "epoch": 2.084739407574053,
      "grad_norm": 1.9751248359680176,
      "learning_rate": 1.7915260592425948e-05,
      "loss": 0.0613,
      "step": 5560
    },
    {
      "epoch": 2.0884889388826395,
      "grad_norm": 0.4337887763977051,
      "learning_rate": 1.791151106111736e-05,
      "loss": 0.0463,
      "step": 5570
    },
    {
      "epoch": 2.092238470191226,
      "grad_norm": 0.20912468433380127,
      "learning_rate": 1.7907761529808776e-05,
      "loss": 0.0319,
      "step": 5580
    },
    {
      "epoch": 2.0959880014998125,
      "grad_norm": 6.187357425689697,
      "learning_rate": 1.790401199850019e-05,
      "loss": 0.067,
      "step": 5590
    },
    {
      "epoch": 2.099737532808399,
      "grad_norm": 0.8330063223838806,
      "learning_rate": 1.79002624671916e-05,
      "loss": 0.02,
      "step": 5600
    },
    {
      "epoch": 2.1034870641169854,
      "grad_norm": 1.8111317157745361,
      "learning_rate": 1.7896512935883017e-05,
      "loss": 0.0498,
      "step": 5610
    },
    {
      "epoch": 2.107236595425572,
      "grad_norm": 2.2751564979553223,
      "learning_rate": 1.789276340457443e-05,
      "loss": 0.066,
      "step": 5620
    },
    {
      "epoch": 2.1109861267341583,
      "grad_norm": 0.26910877227783203,
      "learning_rate": 1.7889013873265842e-05,
      "loss": 0.0293,
      "step": 5630
    },
    {
      "epoch": 2.1147356580427448,
      "grad_norm": 0.23088766634464264,
      "learning_rate": 1.7885264341957255e-05,
      "loss": 0.0211,
      "step": 5640
    },
    {
      "epoch": 2.1184851893513312,
      "grad_norm": 1.9740196466445923,
      "learning_rate": 1.788151481064867e-05,
      "loss": 0.0487,
      "step": 5650
    },
    {
      "epoch": 2.1222347206599177,
      "grad_norm": 1.125234842300415,
      "learning_rate": 1.7877765279340083e-05,
      "loss": 0.0268,
      "step": 5660
    },
    {
      "epoch": 2.1259842519685037,
      "grad_norm": 32.51238250732422,
      "learning_rate": 1.7874015748031495e-05,
      "loss": 0.0314,
      "step": 5670
    },
    {
      "epoch": 2.12973378327709,
      "grad_norm": 4.996102333068848,
      "learning_rate": 1.787026621672291e-05,
      "loss": 0.0381,
      "step": 5680
    },
    {
      "epoch": 2.1334833145856766,
      "grad_norm": 4.736313819885254,
      "learning_rate": 1.7866516685414327e-05,
      "loss": 0.0296,
      "step": 5690
    },
    {
      "epoch": 2.137232845894263,
      "grad_norm": 6.607599258422852,
      "learning_rate": 1.7862767154105736e-05,
      "loss": 0.0119,
      "step": 5700
    },
    {
      "epoch": 2.1409823772028496,
      "grad_norm": 0.979972243309021,
      "learning_rate": 1.7859017622797152e-05,
      "loss": 0.0665,
      "step": 5710
    },
    {
      "epoch": 2.144731908511436,
      "grad_norm": 7.226452350616455,
      "learning_rate": 1.7855268091488565e-05,
      "loss": 0.0634,
      "step": 5720
    },
    {
      "epoch": 2.1484814398200225,
      "grad_norm": 2.850355863571167,
      "learning_rate": 1.785151856017998e-05,
      "loss": 0.036,
      "step": 5730
    },
    {
      "epoch": 2.152230971128609,
      "grad_norm": 1.454965353012085,
      "learning_rate": 1.7847769028871393e-05,
      "loss": 0.0264,
      "step": 5740
    },
    {
      "epoch": 2.1559805024371954,
      "grad_norm": 1.2996324300765991,
      "learning_rate": 1.7844019497562806e-05,
      "loss": 0.0464,
      "step": 5750
    },
    {
      "epoch": 2.159730033745782,
      "grad_norm": 7.617470741271973,
      "learning_rate": 1.784026996625422e-05,
      "loss": 0.0839,
      "step": 5760
    },
    {
      "epoch": 2.1634795650543683,
      "grad_norm": 0.5183233022689819,
      "learning_rate": 1.783652043494563e-05,
      "loss": 0.071,
      "step": 5770
    },
    {
      "epoch": 2.167229096362955,
      "grad_norm": 0.028516963124275208,
      "learning_rate": 1.7832770903637046e-05,
      "loss": 0.0369,
      "step": 5780
    },
    {
      "epoch": 2.1709786276715413,
      "grad_norm": 0.16982582211494446,
      "learning_rate": 1.7829021372328462e-05,
      "loss": 0.0321,
      "step": 5790
    },
    {
      "epoch": 2.1747281589801273,
      "grad_norm": 0.052705831825733185,
      "learning_rate": 1.7825271841019875e-05,
      "loss": 0.0247,
      "step": 5800
    },
    {
      "epoch": 2.1784776902887137,
      "grad_norm": 8.16632080078125,
      "learning_rate": 1.7821522309711287e-05,
      "loss": 0.0646,
      "step": 5810
    },
    {
      "epoch": 2.1822272215973,
      "grad_norm": 0.03192750737071037,
      "learning_rate": 1.7817772778402703e-05,
      "loss": 0.0425,
      "step": 5820
    },
    {
      "epoch": 2.1859767529058867,
      "grad_norm": 0.09961241483688354,
      "learning_rate": 1.7814023247094116e-05,
      "loss": 0.0326,
      "step": 5830
    },
    {
      "epoch": 2.189726284214473,
      "grad_norm": 3.233344316482544,
      "learning_rate": 1.7810273715785528e-05,
      "loss": 0.0437,
      "step": 5840
    },
    {
      "epoch": 2.1934758155230596,
      "grad_norm": 0.2900411784648895,
      "learning_rate": 1.780652418447694e-05,
      "loss": 0.0573,
      "step": 5850
    },
    {
      "epoch": 2.197225346831646,
      "grad_norm": 3.1446242332458496,
      "learning_rate": 1.7802774653168357e-05,
      "loss": 0.0437,
      "step": 5860
    },
    {
      "epoch": 2.2009748781402325,
      "grad_norm": 0.24060803651809692,
      "learning_rate": 1.779902512185977e-05,
      "loss": 0.0204,
      "step": 5870
    },
    {
      "epoch": 2.204724409448819,
      "grad_norm": 0.4629461169242859,
      "learning_rate": 1.779527559055118e-05,
      "loss": 0.0505,
      "step": 5880
    },
    {
      "epoch": 2.2084739407574054,
      "grad_norm": 0.35355064272880554,
      "learning_rate": 1.7791526059242597e-05,
      "loss": 0.022,
      "step": 5890
    },
    {
      "epoch": 2.212223472065992,
      "grad_norm": 3.7624011039733887,
      "learning_rate": 1.778777652793401e-05,
      "loss": 0.0306,
      "step": 5900
    },
    {
      "epoch": 2.2159730033745784,
      "grad_norm": 3.404733896255493,
      "learning_rate": 1.7784026996625422e-05,
      "loss": 0.0149,
      "step": 5910
    },
    {
      "epoch": 2.2197225346831644,
      "grad_norm": 0.02473502606153488,
      "learning_rate": 1.778027746531684e-05,
      "loss": 0.0184,
      "step": 5920
    },
    {
      "epoch": 2.223472065991751,
      "grad_norm": 0.825314998626709,
      "learning_rate": 1.777652793400825e-05,
      "loss": 0.031,
      "step": 5930
    },
    {
      "epoch": 2.2272215973003373,
      "grad_norm": 3.1944217681884766,
      "learning_rate": 1.7772778402699663e-05,
      "loss": 0.0171,
      "step": 5940
    },
    {
      "epoch": 2.2309711286089238,
      "grad_norm": 2.856783628463745,
      "learning_rate": 1.776902887139108e-05,
      "loss": 0.0542,
      "step": 5950
    },
    {
      "epoch": 2.2347206599175102,
      "grad_norm": 1.7208216190338135,
      "learning_rate": 1.776527934008249e-05,
      "loss": 0.046,
      "step": 5960
    },
    {
      "epoch": 2.2384701912260967,
      "grad_norm": 5.032953262329102,
      "learning_rate": 1.7761529808773904e-05,
      "loss": 0.0403,
      "step": 5970
    },
    {
      "epoch": 2.242219722534683,
      "grad_norm": 0.027533268555998802,
      "learning_rate": 1.7757780277465317e-05,
      "loss": 0.027,
      "step": 5980
    },
    {
      "epoch": 2.2459692538432696,
      "grad_norm": 0.019898155704140663,
      "learning_rate": 1.7754030746156733e-05,
      "loss": 0.0339,
      "step": 5990
    },
    {
      "epoch": 2.249718785151856,
      "grad_norm": 6.161532878875732,
      "learning_rate": 1.7750281214848145e-05,
      "loss": 0.0447,
      "step": 6000
    },
    {
      "epoch": 2.2534683164604425,
      "grad_norm": 3.9753525257110596,
      "learning_rate": 1.7746531683539558e-05,
      "loss": 0.0408,
      "step": 6010
    },
    {
      "epoch": 2.257217847769029,
      "grad_norm": 0.13696089386940002,
      "learning_rate": 1.7742782152230973e-05,
      "loss": 0.0271,
      "step": 6020
    },
    {
      "epoch": 2.2609673790776155,
      "grad_norm": 2.9817745685577393,
      "learning_rate": 1.7739032620922386e-05,
      "loss": 0.0166,
      "step": 6030
    },
    {
      "epoch": 2.264716910386202,
      "grad_norm": 0.06824991852045059,
      "learning_rate": 1.77352830896138e-05,
      "loss": 0.061,
      "step": 6040
    },
    {
      "epoch": 2.2684664416947884,
      "grad_norm": 2.5107805728912354,
      "learning_rate": 1.7731533558305214e-05,
      "loss": 0.0589,
      "step": 6050
    },
    {
      "epoch": 2.2722159730033744,
      "grad_norm": 4.172094821929932,
      "learning_rate": 1.7727784026996627e-05,
      "loss": 0.0852,
      "step": 6060
    },
    {
      "epoch": 2.275965504311961,
      "grad_norm": 2.1193838119506836,
      "learning_rate": 1.772403449568804e-05,
      "loss": 0.0334,
      "step": 6070
    },
    {
      "epoch": 2.2797150356205473,
      "grad_norm": 9.054017066955566,
      "learning_rate": 1.7720284964379455e-05,
      "loss": 0.038,
      "step": 6080
    },
    {
      "epoch": 2.283464566929134,
      "grad_norm": 15.843073844909668,
      "learning_rate": 1.7716535433070868e-05,
      "loss": 0.0579,
      "step": 6090
    },
    {
      "epoch": 2.2872140982377203,
      "grad_norm": 0.056941498070955276,
      "learning_rate": 1.771278590176228e-05,
      "loss": 0.022,
      "step": 6100
    },
    {
      "epoch": 2.2909636295463067,
      "grad_norm": 0.49438491463661194,
      "learning_rate": 1.7709036370453693e-05,
      "loss": 0.0194,
      "step": 6110
    },
    {
      "epoch": 2.294713160854893,
      "grad_norm": 3.057274341583252,
      "learning_rate": 1.770528683914511e-05,
      "loss": 0.045,
      "step": 6120
    },
    {
      "epoch": 2.2984626921634796,
      "grad_norm": 2.4989843368530273,
      "learning_rate": 1.770153730783652e-05,
      "loss": 0.0603,
      "step": 6130
    },
    {
      "epoch": 2.302212223472066,
      "grad_norm": 1.212890625,
      "learning_rate": 1.7697787776527934e-05,
      "loss": 0.0276,
      "step": 6140
    },
    {
      "epoch": 2.3059617547806526,
      "grad_norm": 1.392261266708374,
      "learning_rate": 1.769403824521935e-05,
      "loss": 0.0411,
      "step": 6150
    },
    {
      "epoch": 2.309711286089239,
      "grad_norm": 13.270868301391602,
      "learning_rate": 1.7690288713910762e-05,
      "loss": 0.0313,
      "step": 6160
    },
    {
      "epoch": 2.313460817397825,
      "grad_norm": 4.241600036621094,
      "learning_rate": 1.7686539182602174e-05,
      "loss": 0.0178,
      "step": 6170
    },
    {
      "epoch": 2.3172103487064115,
      "grad_norm": 4.041130065917969,
      "learning_rate": 1.768278965129359e-05,
      "loss": 0.0504,
      "step": 6180
    },
    {
      "epoch": 2.320959880014998,
      "grad_norm": 0.7779455780982971,
      "learning_rate": 1.7679040119985003e-05,
      "loss": 0.054,
      "step": 6190
    },
    {
      "epoch": 2.3247094113235844,
      "grad_norm": 2.4373648166656494,
      "learning_rate": 1.767529058867642e-05,
      "loss": 0.0329,
      "step": 6200
    },
    {
      "epoch": 2.328458942632171,
      "grad_norm": 8.725549697875977,
      "learning_rate": 1.767154105736783e-05,
      "loss": 0.0484,
      "step": 6210
    },
    {
      "epoch": 2.3322084739407574,
      "grad_norm": 3.6694347858428955,
      "learning_rate": 1.7667791526059244e-05,
      "loss": 0.0655,
      "step": 6220
    },
    {
      "epoch": 2.335958005249344,
      "grad_norm": 2.0986061096191406,
      "learning_rate": 1.766404199475066e-05,
      "loss": 0.0182,
      "step": 6230
    },
    {
      "epoch": 2.3397075365579303,
      "grad_norm": 2.7625067234039307,
      "learning_rate": 1.766029246344207e-05,
      "loss": 0.037,
      "step": 6240
    },
    {
      "epoch": 2.3434570678665168,
      "grad_norm": 3.698746919631958,
      "learning_rate": 1.7656542932133484e-05,
      "loss": 0.0571,
      "step": 6250
    },
    {
      "epoch": 2.347206599175103,
      "grad_norm": 0.018188919872045517,
      "learning_rate": 1.76527934008249e-05,
      "loss": 0.0282,
      "step": 6260
    },
    {
      "epoch": 2.3509561304836897,
      "grad_norm": 0.6137081384658813,
      "learning_rate": 1.7649043869516313e-05,
      "loss": 0.0322,
      "step": 6270
    },
    {
      "epoch": 2.354705661792276,
      "grad_norm": 1.0207558870315552,
      "learning_rate": 1.7645294338207725e-05,
      "loss": 0.0387,
      "step": 6280
    },
    {
      "epoch": 2.3584551931008626,
      "grad_norm": 9.782621383666992,
      "learning_rate": 1.7641544806899138e-05,
      "loss": 0.0487,
      "step": 6290
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 2.970386505126953,
      "learning_rate": 1.7637795275590554e-05,
      "loss": 0.0461,
      "step": 6300
    },
    {
      "epoch": 2.365954255718035,
      "grad_norm": 5.314249515533447,
      "learning_rate": 1.7634045744281966e-05,
      "loss": 0.0618,
      "step": 6310
    },
    {
      "epoch": 2.3697037870266215,
      "grad_norm": 1.4428036212921143,
      "learning_rate": 1.763029621297338e-05,
      "loss": 0.0643,
      "step": 6320
    },
    {
      "epoch": 2.373453318335208,
      "grad_norm": 1.8231174945831299,
      "learning_rate": 1.7626546681664795e-05,
      "loss": 0.0482,
      "step": 6330
    },
    {
      "epoch": 2.3772028496437945,
      "grad_norm": 0.9112123847007751,
      "learning_rate": 1.7622797150356207e-05,
      "loss": 0.0141,
      "step": 6340
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.1678941398859024,
      "learning_rate": 1.761904761904762e-05,
      "loss": 0.0233,
      "step": 6350
    },
    {
      "epoch": 2.3847019122609674,
      "grad_norm": 2.626781940460205,
      "learning_rate": 1.7615298087739035e-05,
      "loss": 0.0553,
      "step": 6360
    },
    {
      "epoch": 2.388451443569554,
      "grad_norm": 4.666801452636719,
      "learning_rate": 1.7611548556430448e-05,
      "loss": 0.0553,
      "step": 6370
    },
    {
      "epoch": 2.3922009748781403,
      "grad_norm": 0.11963028460741043,
      "learning_rate": 1.760779902512186e-05,
      "loss": 0.028,
      "step": 6380
    },
    {
      "epoch": 2.395950506186727,
      "grad_norm": 9.96588134765625,
      "learning_rate": 1.7604049493813276e-05,
      "loss": 0.0421,
      "step": 6390
    },
    {
      "epoch": 2.3997000374953132,
      "grad_norm": 0.07684531807899475,
      "learning_rate": 1.760029996250469e-05,
      "loss": 0.021,
      "step": 6400
    },
    {
      "epoch": 2.4034495688038997,
      "grad_norm": 0.08474956452846527,
      "learning_rate": 1.75965504311961e-05,
      "loss": 0.0129,
      "step": 6410
    },
    {
      "epoch": 2.4071991001124857,
      "grad_norm": 0.48793068528175354,
      "learning_rate": 1.7592800899887517e-05,
      "loss": 0.0126,
      "step": 6420
    },
    {
      "epoch": 2.410948631421072,
      "grad_norm": 2.278884172439575,
      "learning_rate": 1.758905136857893e-05,
      "loss": 0.0323,
      "step": 6430
    },
    {
      "epoch": 2.4146981627296586,
      "grad_norm": 4.97076416015625,
      "learning_rate": 1.7585301837270342e-05,
      "loss": 0.0408,
      "step": 6440
    },
    {
      "epoch": 2.418447694038245,
      "grad_norm": 0.44238120317459106,
      "learning_rate": 1.7581552305961755e-05,
      "loss": 0.0568,
      "step": 6450
    },
    {
      "epoch": 2.4221972253468316,
      "grad_norm": 0.33776912093162537,
      "learning_rate": 1.757780277465317e-05,
      "loss": 0.0464,
      "step": 6460
    },
    {
      "epoch": 2.425946756655418,
      "grad_norm": 5.208932399749756,
      "learning_rate": 1.7574053243344583e-05,
      "loss": 0.0452,
      "step": 6470
    },
    {
      "epoch": 2.4296962879640045,
      "grad_norm": 3.8403115272521973,
      "learning_rate": 1.7570303712035996e-05,
      "loss": 0.0248,
      "step": 6480
    },
    {
      "epoch": 2.433445819272591,
      "grad_norm": 0.09006288647651672,
      "learning_rate": 1.756655418072741e-05,
      "loss": 0.0324,
      "step": 6490
    },
    {
      "epoch": 2.4371953505811774,
      "grad_norm": 1.3201371431350708,
      "learning_rate": 1.7562804649418824e-05,
      "loss": 0.0462,
      "step": 6500
    },
    {
      "epoch": 2.440944881889764,
      "grad_norm": 0.027116835117340088,
      "learning_rate": 1.7559055118110236e-05,
      "loss": 0.0262,
      "step": 6510
    },
    {
      "epoch": 2.4446944131983503,
      "grad_norm": 0.8891956806182861,
      "learning_rate": 1.7555305586801652e-05,
      "loss": 0.0304,
      "step": 6520
    },
    {
      "epoch": 2.448443944506937,
      "grad_norm": 0.22321034967899323,
      "learning_rate": 1.7551556055493065e-05,
      "loss": 0.0269,
      "step": 6530
    },
    {
      "epoch": 2.4521934758155233,
      "grad_norm": 0.037284012883901596,
      "learning_rate": 1.7547806524184477e-05,
      "loss": 0.0061,
      "step": 6540
    },
    {
      "epoch": 2.4559430071241097,
      "grad_norm": 3.4174017906188965,
      "learning_rate": 1.7544056992875893e-05,
      "loss": 0.0317,
      "step": 6550
    },
    {
      "epoch": 2.4596925384326958,
      "grad_norm": 4.3719987869262695,
      "learning_rate": 1.7540307461567306e-05,
      "loss": 0.0596,
      "step": 6560
    },
    {
      "epoch": 2.463442069741282,
      "grad_norm": 0.024770325049757957,
      "learning_rate": 1.7536557930258718e-05,
      "loss": 0.0211,
      "step": 6570
    },
    {
      "epoch": 2.4671916010498687,
      "grad_norm": 0.006930874660611153,
      "learning_rate": 1.753280839895013e-05,
      "loss": 0.0317,
      "step": 6580
    },
    {
      "epoch": 2.470941132358455,
      "grad_norm": 2.087656259536743,
      "learning_rate": 1.7529058867641547e-05,
      "loss": 0.0387,
      "step": 6590
    },
    {
      "epoch": 2.4746906636670416,
      "grad_norm": 0.049519531428813934,
      "learning_rate": 1.752530933633296e-05,
      "loss": 0.0584,
      "step": 6600
    },
    {
      "epoch": 2.478440194975628,
      "grad_norm": 9.242857933044434,
      "learning_rate": 1.752155980502437e-05,
      "loss": 0.0704,
      "step": 6610
    },
    {
      "epoch": 2.4821897262842145,
      "grad_norm": 0.020741494372487068,
      "learning_rate": 1.7517810273715787e-05,
      "loss": 0.0357,
      "step": 6620
    },
    {
      "epoch": 2.485939257592801,
      "grad_norm": 0.06779647618532181,
      "learning_rate": 1.75140607424072e-05,
      "loss": 0.0487,
      "step": 6630
    },
    {
      "epoch": 2.4896887889013875,
      "grad_norm": 8.666701316833496,
      "learning_rate": 1.7510311211098612e-05,
      "loss": 0.0377,
      "step": 6640
    },
    {
      "epoch": 2.493438320209974,
      "grad_norm": 0.28062355518341064,
      "learning_rate": 1.7506561679790028e-05,
      "loss": 0.0618,
      "step": 6650
    },
    {
      "epoch": 2.49718785151856,
      "grad_norm": 0.9450178146362305,
      "learning_rate": 1.750281214848144e-05,
      "loss": 0.052,
      "step": 6660
    },
    {
      "epoch": 2.5009373828271464,
      "grad_norm": 0.31838276982307434,
      "learning_rate": 1.7499062617172857e-05,
      "loss": 0.0178,
      "step": 6670
    },
    {
      "epoch": 2.504686914135733,
      "grad_norm": 2.657517433166504,
      "learning_rate": 1.749531308586427e-05,
      "loss": 0.0408,
      "step": 6680
    },
    {
      "epoch": 2.5084364454443193,
      "grad_norm": 0.2138429880142212,
      "learning_rate": 1.749156355455568e-05,
      "loss": 0.0237,
      "step": 6690
    },
    {
      "epoch": 2.512185976752906,
      "grad_norm": 0.03957321494817734,
      "learning_rate": 1.7487814023247098e-05,
      "loss": 0.009,
      "step": 6700
    },
    {
      "epoch": 2.5159355080614922,
      "grad_norm": 0.17756648361682892,
      "learning_rate": 1.7484064491938507e-05,
      "loss": 0.0551,
      "step": 6710
    },
    {
      "epoch": 2.5196850393700787,
      "grad_norm": 0.16506598889827728,
      "learning_rate": 1.7480314960629923e-05,
      "loss": 0.0252,
      "step": 6720
    },
    {
      "epoch": 2.523434570678665,
      "grad_norm": 1.5891854763031006,
      "learning_rate": 1.747656542932134e-05,
      "loss": 0.0313,
      "step": 6730
    },
    {
      "epoch": 2.5271841019872516,
      "grad_norm": 0.5331214666366577,
      "learning_rate": 1.747281589801275e-05,
      "loss": 0.0469,
      "step": 6740
    },
    {
      "epoch": 2.530933633295838,
      "grad_norm": 0.12113595008850098,
      "learning_rate": 1.7469066366704163e-05,
      "loss": 0.037,
      "step": 6750
    },
    {
      "epoch": 2.5346831646044246,
      "grad_norm": 3.928741931915283,
      "learning_rate": 1.7465316835395576e-05,
      "loss": 0.0569,
      "step": 6760
    },
    {
      "epoch": 2.538432695913011,
      "grad_norm": 0.6142418384552002,
      "learning_rate": 1.7461567304086992e-05,
      "loss": 0.0265,
      "step": 6770
    },
    {
      "epoch": 2.5421822272215975,
      "grad_norm": 3.3180930614471436,
      "learning_rate": 1.7457817772778404e-05,
      "loss": 0.06,
      "step": 6780
    },
    {
      "epoch": 2.545931758530184,
      "grad_norm": 3.9030208587646484,
      "learning_rate": 1.7454068241469817e-05,
      "loss": 0.0482,
      "step": 6790
    },
    {
      "epoch": 2.5496812898387704,
      "grad_norm": 8.453695297241211,
      "learning_rate": 1.7450318710161233e-05,
      "loss": 0.0414,
      "step": 6800
    },
    {
      "epoch": 2.5534308211473564,
      "grad_norm": 0.39287006855010986,
      "learning_rate": 1.7446569178852645e-05,
      "loss": 0.0314,
      "step": 6810
    },
    {
      "epoch": 2.557180352455943,
      "grad_norm": 1.526267647743225,
      "learning_rate": 1.7442819647544058e-05,
      "loss": 0.0326,
      "step": 6820
    },
    {
      "epoch": 2.5609298837645293,
      "grad_norm": 2.846386432647705,
      "learning_rate": 1.7439070116235474e-05,
      "loss": 0.0803,
      "step": 6830
    },
    {
      "epoch": 2.564679415073116,
      "grad_norm": 3.6287777423858643,
      "learning_rate": 1.7435320584926886e-05,
      "loss": 0.0397,
      "step": 6840
    },
    {
      "epoch": 2.5684289463817023,
      "grad_norm": 2.39194917678833,
      "learning_rate": 1.74315710536183e-05,
      "loss": 0.022,
      "step": 6850
    },
    {
      "epoch": 2.5721784776902887,
      "grad_norm": 1.2469300031661987,
      "learning_rate": 1.7427821522309714e-05,
      "loss": 0.0245,
      "step": 6860
    },
    {
      "epoch": 2.575928008998875,
      "grad_norm": 0.4844411313533783,
      "learning_rate": 1.7424071991001127e-05,
      "loss": 0.0528,
      "step": 6870
    },
    {
      "epoch": 2.5796775403074617,
      "grad_norm": 4.0281829833984375,
      "learning_rate": 1.742032245969254e-05,
      "loss": 0.0218,
      "step": 6880
    },
    {
      "epoch": 2.583427071616048,
      "grad_norm": 1.8706761598587036,
      "learning_rate": 1.7416572928383952e-05,
      "loss": 0.0526,
      "step": 6890
    },
    {
      "epoch": 2.5871766029246346,
      "grad_norm": 0.27280393242836,
      "learning_rate": 1.7412823397075368e-05,
      "loss": 0.0347,
      "step": 6900
    },
    {
      "epoch": 2.5909261342332206,
      "grad_norm": 0.08895223587751389,
      "learning_rate": 1.740907386576678e-05,
      "loss": 0.0481,
      "step": 6910
    },
    {
      "epoch": 2.594675665541807,
      "grad_norm": 3.7324001789093018,
      "learning_rate": 1.7405324334458193e-05,
      "loss": 0.0271,
      "step": 6920
    },
    {
      "epoch": 2.5984251968503935,
      "grad_norm": 1.1157931089401245,
      "learning_rate": 1.740157480314961e-05,
      "loss": 0.0416,
      "step": 6930
    },
    {
      "epoch": 2.60217472815898,
      "grad_norm": 3.6274352073669434,
      "learning_rate": 1.739782527184102e-05,
      "loss": 0.0271,
      "step": 6940
    },
    {
      "epoch": 2.6059242594675665,
      "grad_norm": 2.3031935691833496,
      "learning_rate": 1.7394075740532434e-05,
      "loss": 0.0386,
      "step": 6950
    },
    {
      "epoch": 2.609673790776153,
      "grad_norm": 0.0558936670422554,
      "learning_rate": 1.739032620922385e-05,
      "loss": 0.0204,
      "step": 6960
    },
    {
      "epoch": 2.6134233220847394,
      "grad_norm": 0.01751568540930748,
      "learning_rate": 1.7386576677915262e-05,
      "loss": 0.0274,
      "step": 6970
    },
    {
      "epoch": 2.617172853393326,
      "grad_norm": 1.1018869876861572,
      "learning_rate": 1.7382827146606674e-05,
      "loss": 0.0361,
      "step": 6980
    },
    {
      "epoch": 2.6209223847019123,
      "grad_norm": 4.324753761291504,
      "learning_rate": 1.737907761529809e-05,
      "loss": 0.0565,
      "step": 6990
    },
    {
      "epoch": 2.6246719160104988,
      "grad_norm": 2.1895790100097656,
      "learning_rate": 1.7375328083989503e-05,
      "loss": 0.0103,
      "step": 7000
    },
    {
      "epoch": 2.6284214473190852,
      "grad_norm": 4.508315563201904,
      "learning_rate": 1.7371578552680915e-05,
      "loss": 0.0229,
      "step": 7010
    },
    {
      "epoch": 2.6321709786276717,
      "grad_norm": 5.014945983886719,
      "learning_rate": 1.7367829021372328e-05,
      "loss": 0.0639,
      "step": 7020
    },
    {
      "epoch": 2.635920509936258,
      "grad_norm": 7.130429267883301,
      "learning_rate": 1.7364079490063744e-05,
      "loss": 0.0414,
      "step": 7030
    },
    {
      "epoch": 2.6396700412448446,
      "grad_norm": 1.3606669902801514,
      "learning_rate": 1.7360329958755156e-05,
      "loss": 0.0146,
      "step": 7040
    },
    {
      "epoch": 2.643419572553431,
      "grad_norm": 5.201420307159424,
      "learning_rate": 1.735658042744657e-05,
      "loss": 0.0227,
      "step": 7050
    },
    {
      "epoch": 2.647169103862017,
      "grad_norm": 3.2299551963806152,
      "learning_rate": 1.7352830896137985e-05,
      "loss": 0.0415,
      "step": 7060
    },
    {
      "epoch": 2.6509186351706036,
      "grad_norm": 1.0134118795394897,
      "learning_rate": 1.7349081364829397e-05,
      "loss": 0.0099,
      "step": 7070
    },
    {
      "epoch": 2.65466816647919,
      "grad_norm": 0.01286567747592926,
      "learning_rate": 1.734533183352081e-05,
      "loss": 0.0134,
      "step": 7080
    },
    {
      "epoch": 2.6584176977877765,
      "grad_norm": 3.222304344177246,
      "learning_rate": 1.7341582302212225e-05,
      "loss": 0.0233,
      "step": 7090
    },
    {
      "epoch": 2.662167229096363,
      "grad_norm": 0.21634776890277863,
      "learning_rate": 1.7337832770903638e-05,
      "loss": 0.0368,
      "step": 7100
    },
    {
      "epoch": 2.6659167604049494,
      "grad_norm": 3.453784704208374,
      "learning_rate": 1.733408323959505e-05,
      "loss": 0.0194,
      "step": 7110
    },
    {
      "epoch": 2.669666291713536,
      "grad_norm": 0.007818871177732944,
      "learning_rate": 1.7330333708286466e-05,
      "loss": 0.023,
      "step": 7120
    },
    {
      "epoch": 2.6734158230221223,
      "grad_norm": 0.08956094831228256,
      "learning_rate": 1.732658417697788e-05,
      "loss": 0.0513,
      "step": 7130
    },
    {
      "epoch": 2.677165354330709,
      "grad_norm": 0.007661075331270695,
      "learning_rate": 1.7322834645669295e-05,
      "loss": 0.0205,
      "step": 7140
    },
    {
      "epoch": 2.6809148856392953,
      "grad_norm": 0.06460724025964737,
      "learning_rate": 1.7319085114360704e-05,
      "loss": 0.0578,
      "step": 7150
    },
    {
      "epoch": 2.6846644169478813,
      "grad_norm": 0.15391302108764648,
      "learning_rate": 1.731533558305212e-05,
      "loss": 0.0206,
      "step": 7160
    },
    {
      "epoch": 2.6884139482564677,
      "grad_norm": 2.2535929679870605,
      "learning_rate": 1.7311586051743536e-05,
      "loss": 0.0292,
      "step": 7170
    },
    {
      "epoch": 2.692163479565054,
      "grad_norm": 0.015352766960859299,
      "learning_rate": 1.7307836520434945e-05,
      "loss": 0.033,
      "step": 7180
    },
    {
      "epoch": 2.6959130108736407,
      "grad_norm": 2.0642457008361816,
      "learning_rate": 1.730408698912636e-05,
      "loss": 0.0269,
      "step": 7190
    },
    {
      "epoch": 2.699662542182227,
      "grad_norm": 2.837022066116333,
      "learning_rate": 1.7300337457817776e-05,
      "loss": 0.0575,
      "step": 7200
    },
    {
      "epoch": 2.7034120734908136,
      "grad_norm": 4.507418155670166,
      "learning_rate": 1.729658792650919e-05,
      "loss": 0.0158,
      "step": 7210
    },
    {
      "epoch": 2.7071616047994,
      "grad_norm": 3.265510320663452,
      "learning_rate": 1.72928383952006e-05,
      "loss": 0.0204,
      "step": 7220
    },
    {
      "epoch": 2.7109111361079865,
      "grad_norm": 0.19248142838478088,
      "learning_rate": 1.7289088863892014e-05,
      "loss": 0.0328,
      "step": 7230
    },
    {
      "epoch": 2.714660667416573,
      "grad_norm": 0.8082330822944641,
      "learning_rate": 1.728533933258343e-05,
      "loss": 0.0141,
      "step": 7240
    },
    {
      "epoch": 2.7184101987251594,
      "grad_norm": 0.08093401789665222,
      "learning_rate": 1.7281589801274842e-05,
      "loss": 0.0205,
      "step": 7250
    },
    {
      "epoch": 2.722159730033746,
      "grad_norm": 1.0876450538635254,
      "learning_rate": 1.7277840269966255e-05,
      "loss": 0.0532,
      "step": 7260
    },
    {
      "epoch": 2.7259092613423324,
      "grad_norm": 0.7496967315673828,
      "learning_rate": 1.727409073865767e-05,
      "loss": 0.0366,
      "step": 7270
    },
    {
      "epoch": 2.729658792650919,
      "grad_norm": 0.12382352352142334,
      "learning_rate": 1.7270341207349083e-05,
      "loss": 0.0236,
      "step": 7280
    },
    {
      "epoch": 2.7334083239595053,
      "grad_norm": 0.528637170791626,
      "learning_rate": 1.7266591676040496e-05,
      "loss": 0.0256,
      "step": 7290
    },
    {
      "epoch": 2.7371578552680917,
      "grad_norm": 0.2297203689813614,
      "learning_rate": 1.726284214473191e-05,
      "loss": 0.0352,
      "step": 7300
    },
    {
      "epoch": 2.7409073865766778,
      "grad_norm": 0.14639827609062195,
      "learning_rate": 1.7259092613423324e-05,
      "loss": 0.0681,
      "step": 7310
    },
    {
      "epoch": 2.7446569178852642,
      "grad_norm": 4.440756320953369,
      "learning_rate": 1.7255343082114737e-05,
      "loss": 0.0684,
      "step": 7320
    },
    {
      "epoch": 2.7484064491938507,
      "grad_norm": 1.0391347408294678,
      "learning_rate": 1.7251593550806152e-05,
      "loss": 0.0553,
      "step": 7330
    },
    {
      "epoch": 2.752155980502437,
      "grad_norm": 0.3066660761833191,
      "learning_rate": 1.7247844019497565e-05,
      "loss": 0.0228,
      "step": 7340
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 0.16515350341796875,
      "learning_rate": 1.7244094488188977e-05,
      "loss": 0.0347,
      "step": 7350
    },
    {
      "epoch": 2.75965504311961,
      "grad_norm": 0.09443359822034836,
      "learning_rate": 1.724034495688039e-05,
      "loss": 0.0281,
      "step": 7360
    },
    {
      "epoch": 2.7634045744281965,
      "grad_norm": 0.023393331095576286,
      "learning_rate": 1.7236595425571806e-05,
      "loss": 0.0296,
      "step": 7370
    },
    {
      "epoch": 2.767154105736783,
      "grad_norm": 5.689098834991455,
      "learning_rate": 1.7232845894263218e-05,
      "loss": 0.0346,
      "step": 7380
    },
    {
      "epoch": 2.7709036370453695,
      "grad_norm": 1.181404948234558,
      "learning_rate": 1.722909636295463e-05,
      "loss": 0.0173,
      "step": 7390
    },
    {
      "epoch": 2.7746531683539555,
      "grad_norm": 3.452594518661499,
      "learning_rate": 1.7225346831646047e-05,
      "loss": 0.051,
      "step": 7400
    },
    {
      "epoch": 2.778402699662542,
      "grad_norm": 1.7899680137634277,
      "learning_rate": 1.722159730033746e-05,
      "loss": 0.0431,
      "step": 7410
    },
    {
      "epoch": 2.7821522309711284,
      "grad_norm": 0.28096091747283936,
      "learning_rate": 1.721784776902887e-05,
      "loss": 0.0447,
      "step": 7420
    },
    {
      "epoch": 2.785901762279715,
      "grad_norm": 0.21302510797977448,
      "learning_rate": 1.7214098237720288e-05,
      "loss": 0.0367,
      "step": 7430
    },
    {
      "epoch": 2.7896512935883013,
      "grad_norm": 0.13653989136219025,
      "learning_rate": 1.72103487064117e-05,
      "loss": 0.0362,
      "step": 7440
    },
    {
      "epoch": 2.793400824896888,
      "grad_norm": 1.7972971200942993,
      "learning_rate": 1.7206599175103113e-05,
      "loss": 0.0416,
      "step": 7450
    },
    {
      "epoch": 2.7971503562054743,
      "grad_norm": 0.6026917099952698,
      "learning_rate": 1.720284964379453e-05,
      "loss": 0.0405,
      "step": 7460
    },
    {
      "epoch": 2.8008998875140607,
      "grad_norm": 15.344314575195312,
      "learning_rate": 1.719910011248594e-05,
      "loss": 0.0421,
      "step": 7470
    },
    {
      "epoch": 2.804649418822647,
      "grad_norm": 0.9115570187568665,
      "learning_rate": 1.7195350581177353e-05,
      "loss": 0.012,
      "step": 7480
    },
    {
      "epoch": 2.8083989501312336,
      "grad_norm": 2.2412455081939697,
      "learning_rate": 1.7191601049868766e-05,
      "loss": 0.0646,
      "step": 7490
    },
    {
      "epoch": 2.81214848143982,
      "grad_norm": 0.1376127302646637,
      "learning_rate": 1.7187851518560182e-05,
      "loss": 0.0432,
      "step": 7500
    },
    {
      "epoch": 2.8158980127484066,
      "grad_norm": 0.10935405641794205,
      "learning_rate": 1.7184101987251594e-05,
      "loss": 0.0215,
      "step": 7510
    },
    {
      "epoch": 2.819647544056993,
      "grad_norm": 8.767192840576172,
      "learning_rate": 1.7180352455943007e-05,
      "loss": 0.0248,
      "step": 7520
    },
    {
      "epoch": 2.8233970753655795,
      "grad_norm": 0.16968083381652832,
      "learning_rate": 1.7176602924634423e-05,
      "loss": 0.0533,
      "step": 7530
    },
    {
      "epoch": 2.827146606674166,
      "grad_norm": 0.08401139825582504,
      "learning_rate": 1.7172853393325835e-05,
      "loss": 0.0362,
      "step": 7540
    },
    {
      "epoch": 2.8308961379827524,
      "grad_norm": 4.6028828620910645,
      "learning_rate": 1.7169103862017248e-05,
      "loss": 0.0579,
      "step": 7550
    },
    {
      "epoch": 2.8346456692913384,
      "grad_norm": 6.321003437042236,
      "learning_rate": 1.7165354330708663e-05,
      "loss": 0.0281,
      "step": 7560
    },
    {
      "epoch": 2.838395200599925,
      "grad_norm": 0.054582465440034866,
      "learning_rate": 1.7161604799400076e-05,
      "loss": 0.0347,
      "step": 7570
    },
    {
      "epoch": 2.8421447319085114,
      "grad_norm": 0.8879329562187195,
      "learning_rate": 1.715785526809149e-05,
      "loss": 0.0241,
      "step": 7580
    },
    {
      "epoch": 2.845894263217098,
      "grad_norm": 0.06516771763563156,
      "learning_rate": 1.7154105736782904e-05,
      "loss": 0.0242,
      "step": 7590
    },
    {
      "epoch": 2.8496437945256843,
      "grad_norm": 5.938682556152344,
      "learning_rate": 1.7150356205474317e-05,
      "loss": 0.0326,
      "step": 7600
    },
    {
      "epoch": 2.8533933258342707,
      "grad_norm": 0.026964234188199043,
      "learning_rate": 1.7146606674165733e-05,
      "loss": 0.03,
      "step": 7610
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 22.378324508666992,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.058,
      "step": 7620
    },
    {
      "epoch": 2.8608923884514437,
      "grad_norm": 0.3677605986595154,
      "learning_rate": 1.7139107611548558e-05,
      "loss": 0.0234,
      "step": 7630
    },
    {
      "epoch": 2.86464191976003,
      "grad_norm": 0.026998275890946388,
      "learning_rate": 1.7135358080239974e-05,
      "loss": 0.0184,
      "step": 7640
    },
    {
      "epoch": 2.868391451068616,
      "grad_norm": 0.022981613874435425,
      "learning_rate": 1.7131608548931383e-05,
      "loss": 0.0491,
      "step": 7650
    },
    {
      "epoch": 2.8721409823772026,
      "grad_norm": 0.036382775753736496,
      "learning_rate": 1.71278590176228e-05,
      "loss": 0.0119,
      "step": 7660
    },
    {
      "epoch": 2.875890513685789,
      "grad_norm": 1.4117289781570435,
      "learning_rate": 1.7124109486314214e-05,
      "loss": 0.0244,
      "step": 7670
    },
    {
      "epoch": 2.8796400449943755,
      "grad_norm": 0.4180748462677002,
      "learning_rate": 1.7120359955005627e-05,
      "loss": 0.052,
      "step": 7680
    },
    {
      "epoch": 2.883389576302962,
      "grad_norm": 4.496241092681885,
      "learning_rate": 1.711661042369704e-05,
      "loss": 0.0756,
      "step": 7690
    },
    {
      "epoch": 2.8871391076115485,
      "grad_norm": 0.3287613093852997,
      "learning_rate": 1.7112860892388452e-05,
      "loss": 0.0124,
      "step": 7700
    },
    {
      "epoch": 2.890888638920135,
      "grad_norm": 0.35579484701156616,
      "learning_rate": 1.7109111361079868e-05,
      "loss": 0.0304,
      "step": 7710
    },
    {
      "epoch": 2.8946381702287214,
      "grad_norm": 7.716428279876709,
      "learning_rate": 1.710536182977128e-05,
      "loss": 0.032,
      "step": 7720
    },
    {
      "epoch": 2.898387701537308,
      "grad_norm": 2.5694711208343506,
      "learning_rate": 1.7101612298462693e-05,
      "loss": 0.0217,
      "step": 7730
    },
    {
      "epoch": 2.9021372328458943,
      "grad_norm": 3.7587170600891113,
      "learning_rate": 1.709786276715411e-05,
      "loss": 0.0176,
      "step": 7740
    },
    {
      "epoch": 2.9058867641544808,
      "grad_norm": 5.130130767822266,
      "learning_rate": 1.709411323584552e-05,
      "loss": 0.072,
      "step": 7750
    },
    {
      "epoch": 2.9096362954630672,
      "grad_norm": 3.3365163803100586,
      "learning_rate": 1.7090363704536934e-05,
      "loss": 0.0839,
      "step": 7760
    },
    {
      "epoch": 2.9133858267716537,
      "grad_norm": 3.4159302711486816,
      "learning_rate": 1.708661417322835e-05,
      "loss": 0.021,
      "step": 7770
    },
    {
      "epoch": 2.91713535808024,
      "grad_norm": 0.14958471059799194,
      "learning_rate": 1.7082864641919762e-05,
      "loss": 0.0471,
      "step": 7780
    },
    {
      "epoch": 2.9208848893888266,
      "grad_norm": 0.5413101315498352,
      "learning_rate": 1.7079115110611175e-05,
      "loss": 0.0306,
      "step": 7790
    },
    {
      "epoch": 2.924634420697413,
      "grad_norm": 1.3480955362319946,
      "learning_rate": 1.707536557930259e-05,
      "loss": 0.0379,
      "step": 7800
    },
    {
      "epoch": 2.928383952005999,
      "grad_norm": 0.02730962447822094,
      "learning_rate": 1.7071616047994003e-05,
      "loss": 0.0263,
      "step": 7810
    },
    {
      "epoch": 2.9321334833145856,
      "grad_norm": 0.15144069492816925,
      "learning_rate": 1.7067866516685415e-05,
      "loss": 0.0193,
      "step": 7820
    },
    {
      "epoch": 2.935883014623172,
      "grad_norm": 4.416378021240234,
      "learning_rate": 1.7064116985376828e-05,
      "loss": 0.0273,
      "step": 7830
    },
    {
      "epoch": 2.9396325459317585,
      "grad_norm": 1.2606595754623413,
      "learning_rate": 1.7060367454068244e-05,
      "loss": 0.0361,
      "step": 7840
    },
    {
      "epoch": 2.943382077240345,
      "grad_norm": 1.601150393486023,
      "learning_rate": 1.7056617922759656e-05,
      "loss": 0.0299,
      "step": 7850
    },
    {
      "epoch": 2.9471316085489314,
      "grad_norm": 0.715969443321228,
      "learning_rate": 1.705286839145107e-05,
      "loss": 0.0248,
      "step": 7860
    },
    {
      "epoch": 2.950881139857518,
      "grad_norm": 1.6632232666015625,
      "learning_rate": 1.7049118860142485e-05,
      "loss": 0.0292,
      "step": 7870
    },
    {
      "epoch": 2.9546306711661043,
      "grad_norm": 1.1401431560516357,
      "learning_rate": 1.7045369328833897e-05,
      "loss": 0.0379,
      "step": 7880
    },
    {
      "epoch": 2.958380202474691,
      "grad_norm": 0.807651937007904,
      "learning_rate": 1.704161979752531e-05,
      "loss": 0.0281,
      "step": 7890
    },
    {
      "epoch": 2.962129733783277,
      "grad_norm": 1.380322813987732,
      "learning_rate": 1.7037870266216726e-05,
      "loss": 0.0533,
      "step": 7900
    },
    {
      "epoch": 2.9658792650918633,
      "grad_norm": 0.7904195189476013,
      "learning_rate": 1.7034120734908138e-05,
      "loss": 0.0387,
      "step": 7910
    },
    {
      "epoch": 2.9696287964004497,
      "grad_norm": 1.2247645854949951,
      "learning_rate": 1.703037120359955e-05,
      "loss": 0.0209,
      "step": 7920
    },
    {
      "epoch": 2.973378327709036,
      "grad_norm": 0.061133973300457,
      "learning_rate": 1.7026621672290966e-05,
      "loss": 0.0173,
      "step": 7930
    },
    {
      "epoch": 2.9771278590176227,
      "grad_norm": 3.620007276535034,
      "learning_rate": 1.702287214098238e-05,
      "loss": 0.0686,
      "step": 7940
    },
    {
      "epoch": 2.980877390326209,
      "grad_norm": 0.6303698420524597,
      "learning_rate": 1.701912260967379e-05,
      "loss": 0.0281,
      "step": 7950
    },
    {
      "epoch": 2.9846269216347956,
      "grad_norm": 0.9250231385231018,
      "learning_rate": 1.7015373078365204e-05,
      "loss": 0.0417,
      "step": 7960
    },
    {
      "epoch": 2.988376452943382,
      "grad_norm": 1.5652693510055542,
      "learning_rate": 1.701162354705662e-05,
      "loss": 0.0238,
      "step": 7970
    },
    {
      "epoch": 2.9921259842519685,
      "grad_norm": 1.4473978281021118,
      "learning_rate": 1.7007874015748032e-05,
      "loss": 0.0309,
      "step": 7980
    },
    {
      "epoch": 2.995875515560555,
      "grad_norm": 1.2638019323349,
      "learning_rate": 1.7004124484439445e-05,
      "loss": 0.0208,
      "step": 7990
    },
    {
      "epoch": 2.9996250468691414,
      "grad_norm": 0.0663798376917839,
      "learning_rate": 1.700037495313086e-05,
      "loss": 0.0731,
      "step": 8000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.989355497229513,
      "eval_f1": 0.9589887640449438,
      "eval_loss": 0.03625037148594856,
      "eval_precision": 0.9581813078866124,
      "eval_recall": 0.9597975822322181,
      "eval_runtime": 908.0601,
      "eval_samples_per_second": 30.211,
      "eval_steps_per_second": 1.26,
      "step": 8001
    },
    {
      "epoch": 3.003374578177728,
      "grad_norm": 0.18048694729804993,
      "learning_rate": 1.6996625421822273e-05,
      "loss": 0.0264,
      "step": 8010
    },
    {
      "epoch": 3.0071241094863144,
      "grad_norm": 0.8826498985290527,
      "learning_rate": 1.6992875890513686e-05,
      "loss": 0.0118,
      "step": 8020
    },
    {
      "epoch": 3.010873640794901,
      "grad_norm": 0.6957702040672302,
      "learning_rate": 1.69891263592051e-05,
      "loss": 0.0343,
      "step": 8030
    },
    {
      "epoch": 3.014623172103487,
      "grad_norm": 0.009358547627925873,
      "learning_rate": 1.6985376827896514e-05,
      "loss": 0.048,
      "step": 8040
    },
    {
      "epoch": 3.0183727034120733,
      "grad_norm": 0.08673878759145737,
      "learning_rate": 1.6981627296587927e-05,
      "loss": 0.0073,
      "step": 8050
    },
    {
      "epoch": 3.0221222347206598,
      "grad_norm": 0.25967586040496826,
      "learning_rate": 1.6977877765279342e-05,
      "loss": 0.0426,
      "step": 8060
    },
    {
      "epoch": 3.0258717660292462,
      "grad_norm": 2.946035623550415,
      "learning_rate": 1.6974128233970755e-05,
      "loss": 0.022,
      "step": 8070
    },
    {
      "epoch": 3.0296212973378327,
      "grad_norm": 4.321765899658203,
      "learning_rate": 1.697037870266217e-05,
      "loss": 0.0338,
      "step": 8080
    },
    {
      "epoch": 3.033370828646419,
      "grad_norm": 0.24103973805904388,
      "learning_rate": 1.696662917135358e-05,
      "loss": 0.0204,
      "step": 8090
    },
    {
      "epoch": 3.0371203599550056,
      "grad_norm": 2.092041492462158,
      "learning_rate": 1.6962879640044996e-05,
      "loss": 0.0145,
      "step": 8100
    },
    {
      "epoch": 3.040869891263592,
      "grad_norm": 0.3552645444869995,
      "learning_rate": 1.695913010873641e-05,
      "loss": 0.0451,
      "step": 8110
    },
    {
      "epoch": 3.0446194225721785,
      "grad_norm": 0.6439607739448547,
      "learning_rate": 1.695538057742782e-05,
      "loss": 0.0188,
      "step": 8120
    },
    {
      "epoch": 3.048368953880765,
      "grad_norm": 0.47491616010665894,
      "learning_rate": 1.6951631046119237e-05,
      "loss": 0.0221,
      "step": 8130
    },
    {
      "epoch": 3.0521184851893515,
      "grad_norm": 0.4877811074256897,
      "learning_rate": 1.694788151481065e-05,
      "loss": 0.028,
      "step": 8140
    },
    {
      "epoch": 3.055868016497938,
      "grad_norm": 3.1252505779266357,
      "learning_rate": 1.6944131983502065e-05,
      "loss": 0.0345,
      "step": 8150
    },
    {
      "epoch": 3.0596175478065244,
      "grad_norm": 4.351434230804443,
      "learning_rate": 1.6940382452193477e-05,
      "loss": 0.0222,
      "step": 8160
    },
    {
      "epoch": 3.0633670791151104,
      "grad_norm": 3.8555874824523926,
      "learning_rate": 1.693663292088489e-05,
      "loss": 0.0297,
      "step": 8170
    },
    {
      "epoch": 3.067116610423697,
      "grad_norm": 11.173456192016602,
      "learning_rate": 1.6932883389576306e-05,
      "loss": 0.0387,
      "step": 8180
    },
    {
      "epoch": 3.0708661417322833,
      "grad_norm": 0.12482798099517822,
      "learning_rate": 1.692913385826772e-05,
      "loss": 0.0354,
      "step": 8190
    },
    {
      "epoch": 3.07461567304087,
      "grad_norm": 3.2295656204223633,
      "learning_rate": 1.692538432695913e-05,
      "loss": 0.035,
      "step": 8200
    },
    {
      "epoch": 3.0783652043494563,
      "grad_norm": 1.0676016807556152,
      "learning_rate": 1.6921634795650547e-05,
      "loss": 0.0225,
      "step": 8210
    },
    {
      "epoch": 3.0821147356580427,
      "grad_norm": 1.4119950532913208,
      "learning_rate": 1.691788526434196e-05,
      "loss": 0.0137,
      "step": 8220
    },
    {
      "epoch": 3.085864266966629,
      "grad_norm": 2.9346632957458496,
      "learning_rate": 1.6914135733033372e-05,
      "loss": 0.0333,
      "step": 8230
    },
    {
      "epoch": 3.0896137982752157,
      "grad_norm": 0.028681214898824692,
      "learning_rate": 1.6910386201724788e-05,
      "loss": 0.0173,
      "step": 8240
    },
    {
      "epoch": 3.093363329583802,
      "grad_norm": 0.0024709333665668964,
      "learning_rate": 1.69066366704162e-05,
      "loss": 0.0617,
      "step": 8250
    },
    {
      "epoch": 3.0971128608923886,
      "grad_norm": 0.710441529750824,
      "learning_rate": 1.6902887139107613e-05,
      "loss": 0.0198,
      "step": 8260
    },
    {
      "epoch": 3.100862392200975,
      "grad_norm": 14.44047737121582,
      "learning_rate": 1.6899137607799025e-05,
      "loss": 0.038,
      "step": 8270
    },
    {
      "epoch": 3.1046119235095615,
      "grad_norm": 5.301029682159424,
      "learning_rate": 1.689538807649044e-05,
      "loss": 0.0333,
      "step": 8280
    },
    {
      "epoch": 3.1083614548181475,
      "grad_norm": 4.807271957397461,
      "learning_rate": 1.6891638545181853e-05,
      "loss": 0.053,
      "step": 8290
    },
    {
      "epoch": 3.112110986126734,
      "grad_norm": 22.301435470581055,
      "learning_rate": 1.6887889013873266e-05,
      "loss": 0.0415,
      "step": 8300
    },
    {
      "epoch": 3.1158605174353204,
      "grad_norm": 2.8270113468170166,
      "learning_rate": 1.6884139482564682e-05,
      "loss": 0.0462,
      "step": 8310
    },
    {
      "epoch": 3.119610048743907,
      "grad_norm": 1.6044307947158813,
      "learning_rate": 1.6880389951256094e-05,
      "loss": 0.0296,
      "step": 8320
    },
    {
      "epoch": 3.1233595800524934,
      "grad_norm": 1.316211223602295,
      "learning_rate": 1.6876640419947507e-05,
      "loss": 0.0285,
      "step": 8330
    },
    {
      "epoch": 3.12710911136108,
      "grad_norm": 5.7415266036987305,
      "learning_rate": 1.6872890888638923e-05,
      "loss": 0.0274,
      "step": 8340
    },
    {
      "epoch": 3.1308586426696663,
      "grad_norm": 2.2325615882873535,
      "learning_rate": 1.6869141357330335e-05,
      "loss": 0.0122,
      "step": 8350
    },
    {
      "epoch": 3.1346081739782528,
      "grad_norm": 0.004901212174445391,
      "learning_rate": 1.6865391826021748e-05,
      "loss": 0.0215,
      "step": 8360
    },
    {
      "epoch": 3.138357705286839,
      "grad_norm": 5.092606544494629,
      "learning_rate": 1.6861642294713164e-05,
      "loss": 0.0211,
      "step": 8370
    },
    {
      "epoch": 3.1421072365954257,
      "grad_norm": 6.91093635559082,
      "learning_rate": 1.6857892763404576e-05,
      "loss": 0.028,
      "step": 8380
    },
    {
      "epoch": 3.145856767904012,
      "grad_norm": 1.76260507106781,
      "learning_rate": 1.685414323209599e-05,
      "loss": 0.0321,
      "step": 8390
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 5.41963005065918,
      "learning_rate": 1.68503937007874e-05,
      "loss": 0.0279,
      "step": 8400
    },
    {
      "epoch": 3.1533558305211846,
      "grad_norm": 1.3715927600860596,
      "learning_rate": 1.6846644169478817e-05,
      "loss": 0.0233,
      "step": 8410
    },
    {
      "epoch": 3.157105361829771,
      "grad_norm": 16.107608795166016,
      "learning_rate": 1.684289463817023e-05,
      "loss": 0.0279,
      "step": 8420
    },
    {
      "epoch": 3.1608548931383575,
      "grad_norm": 0.013396648690104485,
      "learning_rate": 1.6839145106861642e-05,
      "loss": 0.0016,
      "step": 8430
    },
    {
      "epoch": 3.164604424446944,
      "grad_norm": 5.5042595863342285,
      "learning_rate": 1.6835395575553058e-05,
      "loss": 0.0518,
      "step": 8440
    },
    {
      "epoch": 3.1683539557555305,
      "grad_norm": 0.871085524559021,
      "learning_rate": 1.683164604424447e-05,
      "loss": 0.0366,
      "step": 8450
    },
    {
      "epoch": 3.172103487064117,
      "grad_norm": 0.08691983669996262,
      "learning_rate": 1.6827896512935883e-05,
      "loss": 0.0185,
      "step": 8460
    },
    {
      "epoch": 3.1758530183727034,
      "grad_norm": 0.27655935287475586,
      "learning_rate": 1.68241469816273e-05,
      "loss": 0.016,
      "step": 8470
    },
    {
      "epoch": 3.17960254968129,
      "grad_norm": 0.600524365901947,
      "learning_rate": 1.682039745031871e-05,
      "loss": 0.0129,
      "step": 8480
    },
    {
      "epoch": 3.1833520809898763,
      "grad_norm": 6.2750163078308105,
      "learning_rate": 1.6816647919010124e-05,
      "loss": 0.054,
      "step": 8490
    },
    {
      "epoch": 3.187101612298463,
      "grad_norm": 2.5923004150390625,
      "learning_rate": 1.681289838770154e-05,
      "loss": 0.0028,
      "step": 8500
    },
    {
      "epoch": 3.1908511436070492,
      "grad_norm": 2.4522149562835693,
      "learning_rate": 1.6809148856392952e-05,
      "loss": 0.0399,
      "step": 8510
    },
    {
      "epoch": 3.1946006749156357,
      "grad_norm": 0.4696073532104492,
      "learning_rate": 1.6805399325084365e-05,
      "loss": 0.0108,
      "step": 8520
    },
    {
      "epoch": 3.198350206224222,
      "grad_norm": 2.225062131881714,
      "learning_rate": 1.6801649793775777e-05,
      "loss": 0.0282,
      "step": 8530
    },
    {
      "epoch": 3.2020997375328086,
      "grad_norm": 0.02087613381445408,
      "learning_rate": 1.6797900262467193e-05,
      "loss": 0.0543,
      "step": 8540
    },
    {
      "epoch": 3.2058492688413947,
      "grad_norm": 3.8767852783203125,
      "learning_rate": 1.679415073115861e-05,
      "loss": 0.0459,
      "step": 8550
    },
    {
      "epoch": 3.209598800149981,
      "grad_norm": 1.7427868843078613,
      "learning_rate": 1.6790401199850018e-05,
      "loss": 0.0608,
      "step": 8560
    },
    {
      "epoch": 3.2133483314585676,
      "grad_norm": 3.760514259338379,
      "learning_rate": 1.6786651668541434e-05,
      "loss": 0.0168,
      "step": 8570
    },
    {
      "epoch": 3.217097862767154,
      "grad_norm": 0.22184759378433228,
      "learning_rate": 1.678290213723285e-05,
      "loss": 0.0265,
      "step": 8580
    },
    {
      "epoch": 3.2208473940757405,
      "grad_norm": 0.07778694480657578,
      "learning_rate": 1.677915260592426e-05,
      "loss": 0.0264,
      "step": 8590
    },
    {
      "epoch": 3.224596925384327,
      "grad_norm": 1.2032335996627808,
      "learning_rate": 1.6775403074615675e-05,
      "loss": 0.0458,
      "step": 8600
    },
    {
      "epoch": 3.2283464566929134,
      "grad_norm": 0.780469536781311,
      "learning_rate": 1.6771653543307087e-05,
      "loss": 0.0251,
      "step": 8610
    },
    {
      "epoch": 3.2320959880015,
      "grad_norm": 2.5259945392608643,
      "learning_rate": 1.6767904011998503e-05,
      "loss": 0.034,
      "step": 8620
    },
    {
      "epoch": 3.2358455193100863,
      "grad_norm": 0.7269219756126404,
      "learning_rate": 1.6764154480689916e-05,
      "loss": 0.0177,
      "step": 8630
    },
    {
      "epoch": 3.239595050618673,
      "grad_norm": 0.8754006624221802,
      "learning_rate": 1.6760404949381328e-05,
      "loss": 0.0289,
      "step": 8640
    },
    {
      "epoch": 3.2433445819272593,
      "grad_norm": 0.5992810726165771,
      "learning_rate": 1.6756655418072744e-05,
      "loss": 0.0334,
      "step": 8650
    },
    {
      "epoch": 3.2470941132358453,
      "grad_norm": 8.713123321533203,
      "learning_rate": 1.6752905886764156e-05,
      "loss": 0.0146,
      "step": 8660
    },
    {
      "epoch": 3.2508436445444318,
      "grad_norm": 0.11906743794679642,
      "learning_rate": 1.674915635545557e-05,
      "loss": 0.0438,
      "step": 8670
    },
    {
      "epoch": 3.254593175853018,
      "grad_norm": 5.533257007598877,
      "learning_rate": 1.6745406824146985e-05,
      "loss": 0.0374,
      "step": 8680
    },
    {
      "epoch": 3.2583427071616047,
      "grad_norm": 0.050255924463272095,
      "learning_rate": 1.6741657292838397e-05,
      "loss": 0.0343,
      "step": 8690
    },
    {
      "epoch": 3.262092238470191,
      "grad_norm": 4.346309185028076,
      "learning_rate": 1.673790776152981e-05,
      "loss": 0.0343,
      "step": 8700
    },
    {
      "epoch": 3.2658417697787776,
      "grad_norm": 0.012946820817887783,
      "learning_rate": 1.6734158230221226e-05,
      "loss": 0.026,
      "step": 8710
    },
    {
      "epoch": 3.269591301087364,
      "grad_norm": 1.2476437091827393,
      "learning_rate": 1.6730408698912638e-05,
      "loss": 0.0251,
      "step": 8720
    },
    {
      "epoch": 3.2733408323959505,
      "grad_norm": 1.3557502031326294,
      "learning_rate": 1.672665916760405e-05,
      "loss": 0.0267,
      "step": 8730
    },
    {
      "epoch": 3.277090363704537,
      "grad_norm": 0.07731492817401886,
      "learning_rate": 1.6722909636295463e-05,
      "loss": 0.0312,
      "step": 8740
    },
    {
      "epoch": 3.2808398950131235,
      "grad_norm": 0.044195834547281265,
      "learning_rate": 1.671916010498688e-05,
      "loss": 0.0207,
      "step": 8750
    },
    {
      "epoch": 3.28458942632171,
      "grad_norm": 0.01343582570552826,
      "learning_rate": 1.671541057367829e-05,
      "loss": 0.0289,
      "step": 8760
    },
    {
      "epoch": 3.2883389576302964,
      "grad_norm": 0.010440230369567871,
      "learning_rate": 1.6711661042369704e-05,
      "loss": 0.0142,
      "step": 8770
    },
    {
      "epoch": 3.292088488938883,
      "grad_norm": 0.01863306760787964,
      "learning_rate": 1.670791151106112e-05,
      "loss": 0.0159,
      "step": 8780
    },
    {
      "epoch": 3.2958380202474693,
      "grad_norm": 0.253866970539093,
      "learning_rate": 1.6704161979752532e-05,
      "loss": 0.0362,
      "step": 8790
    },
    {
      "epoch": 3.2995875515560553,
      "grad_norm": 3.6218831539154053,
      "learning_rate": 1.6700412448443945e-05,
      "loss": 0.0405,
      "step": 8800
    },
    {
      "epoch": 3.303337082864642,
      "grad_norm": 3.9003305435180664,
      "learning_rate": 1.669666291713536e-05,
      "loss": 0.0148,
      "step": 8810
    },
    {
      "epoch": 3.3070866141732282,
      "grad_norm": 14.96562385559082,
      "learning_rate": 1.6692913385826773e-05,
      "loss": 0.062,
      "step": 8820
    },
    {
      "epoch": 3.3108361454818147,
      "grad_norm": 0.8467336893081665,
      "learning_rate": 1.6689163854518186e-05,
      "loss": 0.0476,
      "step": 8830
    },
    {
      "epoch": 3.314585676790401,
      "grad_norm": 0.561915397644043,
      "learning_rate": 1.66854143232096e-05,
      "loss": 0.0202,
      "step": 8840
    },
    {
      "epoch": 3.3183352080989876,
      "grad_norm": 2.796091079711914,
      "learning_rate": 1.6681664791901014e-05,
      "loss": 0.0234,
      "step": 8850
    },
    {
      "epoch": 3.322084739407574,
      "grad_norm": 0.12940414249897003,
      "learning_rate": 1.6677915260592427e-05,
      "loss": 0.0409,
      "step": 8860
    },
    {
      "epoch": 3.3258342707161606,
      "grad_norm": 0.08964448422193527,
      "learning_rate": 1.667416572928384e-05,
      "loss": 0.0196,
      "step": 8870
    },
    {
      "epoch": 3.329583802024747,
      "grad_norm": 0.891514003276825,
      "learning_rate": 1.6670416197975255e-05,
      "loss": 0.0393,
      "step": 8880
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 3.173170566558838,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.017,
      "step": 8890
    },
    {
      "epoch": 3.33708286464192,
      "grad_norm": 5.322088718414307,
      "learning_rate": 1.666291713535808e-05,
      "loss": 0.0687,
      "step": 8900
    },
    {
      "epoch": 3.340832395950506,
      "grad_norm": 0.25921446084976196,
      "learning_rate": 1.6659167604049496e-05,
      "loss": 0.0151,
      "step": 8910
    },
    {
      "epoch": 3.3445819272590924,
      "grad_norm": 0.1097574234008789,
      "learning_rate": 1.665541807274091e-05,
      "loss": 0.0137,
      "step": 8920
    },
    {
      "epoch": 3.348331458567679,
      "grad_norm": 0.18690016865730286,
      "learning_rate": 1.665166854143232e-05,
      "loss": 0.015,
      "step": 8930
    },
    {
      "epoch": 3.3520809898762653,
      "grad_norm": 11.004636764526367,
      "learning_rate": 1.6647919010123737e-05,
      "loss": 0.0285,
      "step": 8940
    },
    {
      "epoch": 3.355830521184852,
      "grad_norm": 0.01671788841485977,
      "learning_rate": 1.664416947881515e-05,
      "loss": 0.0207,
      "step": 8950
    },
    {
      "epoch": 3.3595800524934383,
      "grad_norm": 3.739370107650757,
      "learning_rate": 1.6640419947506562e-05,
      "loss": 0.0164,
      "step": 8960
    },
    {
      "epoch": 3.3633295838020247,
      "grad_norm": 3.474680185317993,
      "learning_rate": 1.6636670416197978e-05,
      "loss": 0.0258,
      "step": 8970
    },
    {
      "epoch": 3.367079115110611,
      "grad_norm": 0.4286739230155945,
      "learning_rate": 1.663292088488939e-05,
      "loss": 0.0343,
      "step": 8980
    },
    {
      "epoch": 3.3708286464191977,
      "grad_norm": 2.8895299434661865,
      "learning_rate": 1.6629171353580803e-05,
      "loss": 0.0255,
      "step": 8990
    },
    {
      "epoch": 3.374578177727784,
      "grad_norm": 1.9315394163131714,
      "learning_rate": 1.6625421822272215e-05,
      "loss": 0.0214,
      "step": 9000
    },
    {
      "epoch": 3.3783277090363706,
      "grad_norm": 0.02271384559571743,
      "learning_rate": 1.662167229096363e-05,
      "loss": 0.0393,
      "step": 9010
    },
    {
      "epoch": 3.382077240344957,
      "grad_norm": 0.4976016879081726,
      "learning_rate": 1.6617922759655047e-05,
      "loss": 0.0272,
      "step": 9020
    },
    {
      "epoch": 3.3858267716535435,
      "grad_norm": 1.227545976638794,
      "learning_rate": 1.6614173228346456e-05,
      "loss": 0.0108,
      "step": 9030
    },
    {
      "epoch": 3.38957630296213,
      "grad_norm": 6.966075897216797,
      "learning_rate": 1.6610423697037872e-05,
      "loss": 0.0464,
      "step": 9040
    },
    {
      "epoch": 3.393325834270716,
      "grad_norm": 0.014691018499433994,
      "learning_rate": 1.6606674165729288e-05,
      "loss": 0.0295,
      "step": 9050
    },
    {
      "epoch": 3.3970753655793025,
      "grad_norm": 0.26602330803871155,
      "learning_rate": 1.6602924634420697e-05,
      "loss": 0.0427,
      "step": 9060
    },
    {
      "epoch": 3.400824896887889,
      "grad_norm": 0.18687567114830017,
      "learning_rate": 1.6599175103112113e-05,
      "loss": 0.0469,
      "step": 9070
    },
    {
      "epoch": 3.4045744281964754,
      "grad_norm": 0.06819252669811249,
      "learning_rate": 1.6595425571803525e-05,
      "loss": 0.0399,
      "step": 9080
    },
    {
      "epoch": 3.408323959505062,
      "grad_norm": 0.05996331572532654,
      "learning_rate": 1.659167604049494e-05,
      "loss": 0.0474,
      "step": 9090
    },
    {
      "epoch": 3.4120734908136483,
      "grad_norm": 3.349177122116089,
      "learning_rate": 1.6587926509186354e-05,
      "loss": 0.0502,
      "step": 9100
    },
    {
      "epoch": 3.4158230221222348,
      "grad_norm": 7.71027135848999,
      "learning_rate": 1.6584176977877766e-05,
      "loss": 0.0283,
      "step": 9110
    },
    {
      "epoch": 3.4195725534308212,
      "grad_norm": 0.08306481689214706,
      "learning_rate": 1.6580427446569182e-05,
      "loss": 0.0554,
      "step": 9120
    },
    {
      "epoch": 3.4233220847394077,
      "grad_norm": 2.974299669265747,
      "learning_rate": 1.6576677915260594e-05,
      "loss": 0.0274,
      "step": 9130
    },
    {
      "epoch": 3.427071616047994,
      "grad_norm": 1.1031633615493774,
      "learning_rate": 1.6572928383952007e-05,
      "loss": 0.0273,
      "step": 9140
    },
    {
      "epoch": 3.4308211473565806,
      "grad_norm": 2.6040937900543213,
      "learning_rate": 1.6569178852643423e-05,
      "loss": 0.047,
      "step": 9150
    },
    {
      "epoch": 3.4345706786651666,
      "grad_norm": 0.7590983510017395,
      "learning_rate": 1.6565429321334835e-05,
      "loss": 0.0562,
      "step": 9160
    },
    {
      "epoch": 3.438320209973753,
      "grad_norm": 0.09608659148216248,
      "learning_rate": 1.6561679790026248e-05,
      "loss": 0.0327,
      "step": 9170
    },
    {
      "epoch": 3.4420697412823396,
      "grad_norm": 0.05369949713349342,
      "learning_rate": 1.6557930258717664e-05,
      "loss": 0.0255,
      "step": 9180
    },
    {
      "epoch": 3.445819272590926,
      "grad_norm": 2.9010350704193115,
      "learning_rate": 1.6554180727409076e-05,
      "loss": 0.0214,
      "step": 9190
    },
    {
      "epoch": 3.4495688038995125,
      "grad_norm": 0.1635105013847351,
      "learning_rate": 1.655043119610049e-05,
      "loss": 0.0427,
      "step": 9200
    },
    {
      "epoch": 3.453318335208099,
      "grad_norm": 3.8209190368652344,
      "learning_rate": 1.65466816647919e-05,
      "loss": 0.0276,
      "step": 9210
    },
    {
      "epoch": 3.4570678665166854,
      "grad_norm": 0.19055496156215668,
      "learning_rate": 1.6542932133483317e-05,
      "loss": 0.0066,
      "step": 9220
    },
    {
      "epoch": 3.460817397825272,
      "grad_norm": 0.19542208313941956,
      "learning_rate": 1.653918260217473e-05,
      "loss": 0.0267,
      "step": 9230
    },
    {
      "epoch": 3.4645669291338583,
      "grad_norm": 0.009364571422338486,
      "learning_rate": 1.6535433070866142e-05,
      "loss": 0.018,
      "step": 9240
    },
    {
      "epoch": 3.468316460442445,
      "grad_norm": 2.142226219177246,
      "learning_rate": 1.6531683539557558e-05,
      "loss": 0.0711,
      "step": 9250
    },
    {
      "epoch": 3.4720659917510313,
      "grad_norm": 0.738821804523468,
      "learning_rate": 1.652793400824897e-05,
      "loss": 0.0152,
      "step": 9260
    },
    {
      "epoch": 3.4758155230596177,
      "grad_norm": 6.410311698913574,
      "learning_rate": 1.6524184476940383e-05,
      "loss": 0.0125,
      "step": 9270
    },
    {
      "epoch": 3.479565054368204,
      "grad_norm": 0.5423250198364258,
      "learning_rate": 1.65204349456318e-05,
      "loss": 0.0133,
      "step": 9280
    },
    {
      "epoch": 3.4833145856767906,
      "grad_norm": 3.664655923843384,
      "learning_rate": 1.651668541432321e-05,
      "loss": 0.0397,
      "step": 9290
    },
    {
      "epoch": 3.4870641169853767,
      "grad_norm": 0.012713759206235409,
      "learning_rate": 1.6512935883014624e-05,
      "loss": 0.0203,
      "step": 9300
    },
    {
      "epoch": 3.490813648293963,
      "grad_norm": 3.9383633136749268,
      "learning_rate": 1.650918635170604e-05,
      "loss": 0.0343,
      "step": 9310
    },
    {
      "epoch": 3.4945631796025496,
      "grad_norm": 14.965826988220215,
      "learning_rate": 1.6505436820397452e-05,
      "loss": 0.0602,
      "step": 9320
    },
    {
      "epoch": 3.498312710911136,
      "grad_norm": 0.8833275437355042,
      "learning_rate": 1.6501687289088865e-05,
      "loss": 0.0203,
      "step": 9330
    },
    {
      "epoch": 3.5020622422197225,
      "grad_norm": 0.04089641198515892,
      "learning_rate": 1.6497937757780277e-05,
      "loss": 0.0272,
      "step": 9340
    },
    {
      "epoch": 3.505811773528309,
      "grad_norm": 0.06295698881149292,
      "learning_rate": 1.6494188226471693e-05,
      "loss": 0.0229,
      "step": 9350
    },
    {
      "epoch": 3.5095613048368954,
      "grad_norm": 2.013904333114624,
      "learning_rate": 1.6490438695163105e-05,
      "loss": 0.0185,
      "step": 9360
    },
    {
      "epoch": 3.513310836145482,
      "grad_norm": 0.06458253413438797,
      "learning_rate": 1.6486689163854518e-05,
      "loss": 0.0354,
      "step": 9370
    },
    {
      "epoch": 3.5170603674540684,
      "grad_norm": 0.03504861518740654,
      "learning_rate": 1.6482939632545934e-05,
      "loss": 0.058,
      "step": 9380
    },
    {
      "epoch": 3.520809898762655,
      "grad_norm": 1.1094218492507935,
      "learning_rate": 1.6479190101237346e-05,
      "loss": 0.0379,
      "step": 9390
    },
    {
      "epoch": 3.524559430071241,
      "grad_norm": 2.4626471996307373,
      "learning_rate": 1.647544056992876e-05,
      "loss": 0.0157,
      "step": 9400
    },
    {
      "epoch": 3.5283089613798273,
      "grad_norm": 0.025698557496070862,
      "learning_rate": 1.6471691038620175e-05,
      "loss": 0.043,
      "step": 9410
    },
    {
      "epoch": 3.5320584926884138,
      "grad_norm": 3.4402692317962646,
      "learning_rate": 1.6467941507311587e-05,
      "loss": 0.0413,
      "step": 9420
    },
    {
      "epoch": 3.5358080239970002,
      "grad_norm": 2.7200610637664795,
      "learning_rate": 1.6464191976003e-05,
      "loss": 0.0461,
      "step": 9430
    },
    {
      "epoch": 3.5395575553055867,
      "grad_norm": 0.28128471970558167,
      "learning_rate": 1.6460442444694416e-05,
      "loss": 0.034,
      "step": 9440
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 0.23620754480361938,
      "learning_rate": 1.6456692913385828e-05,
      "loss": 0.0222,
      "step": 9450
    },
    {
      "epoch": 3.5470566179227596,
      "grad_norm": 0.20399785041809082,
      "learning_rate": 1.645294338207724e-05,
      "loss": 0.005,
      "step": 9460
    },
    {
      "epoch": 3.550806149231346,
      "grad_norm": 4.906375408172607,
      "learning_rate": 1.6449193850768653e-05,
      "loss": 0.036,
      "step": 9470
    },
    {
      "epoch": 3.5545556805399325,
      "grad_norm": 0.21520280838012695,
      "learning_rate": 1.644544431946007e-05,
      "loss": 0.055,
      "step": 9480
    },
    {
      "epoch": 3.558305211848519,
      "grad_norm": 11.108736038208008,
      "learning_rate": 1.6441694788151485e-05,
      "loss": 0.0218,
      "step": 9490
    },
    {
      "epoch": 3.5620547431571055,
      "grad_norm": 0.32729753851890564,
      "learning_rate": 1.6437945256842894e-05,
      "loss": 0.0099,
      "step": 9500
    },
    {
      "epoch": 3.565804274465692,
      "grad_norm": 0.6283239126205444,
      "learning_rate": 1.643419572553431e-05,
      "loss": 0.0321,
      "step": 9510
    },
    {
      "epoch": 3.5695538057742784,
      "grad_norm": 0.03673708066344261,
      "learning_rate": 1.6430446194225722e-05,
      "loss": 0.0247,
      "step": 9520
    },
    {
      "epoch": 3.573303337082865,
      "grad_norm": 0.012407642789185047,
      "learning_rate": 1.6426696662917135e-05,
      "loss": 0.0082,
      "step": 9530
    },
    {
      "epoch": 3.5770528683914513,
      "grad_norm": 25.595516204833984,
      "learning_rate": 1.642294713160855e-05,
      "loss": 0.0387,
      "step": 9540
    },
    {
      "epoch": 3.5808023997000373,
      "grad_norm": 0.004108623135834932,
      "learning_rate": 1.6419197600299963e-05,
      "loss": 0.0404,
      "step": 9550
    },
    {
      "epoch": 3.584551931008624,
      "grad_norm": 9.808923721313477,
      "learning_rate": 1.641544806899138e-05,
      "loss": 0.0264,
      "step": 9560
    },
    {
      "epoch": 3.5883014623172103,
      "grad_norm": 7.727325439453125,
      "learning_rate": 1.641169853768279e-05,
      "loss": 0.0271,
      "step": 9570
    },
    {
      "epoch": 3.5920509936257967,
      "grad_norm": 1.8506512641906738,
      "learning_rate": 1.6407949006374204e-05,
      "loss": 0.0284,
      "step": 9580
    },
    {
      "epoch": 3.595800524934383,
      "grad_norm": 0.0033411297481507063,
      "learning_rate": 1.640419947506562e-05,
      "loss": 0.0261,
      "step": 9590
    },
    {
      "epoch": 3.5995500562429696,
      "grad_norm": 25.57278060913086,
      "learning_rate": 1.6400449943757032e-05,
      "loss": 0.0285,
      "step": 9600
    },
    {
      "epoch": 3.603299587551556,
      "grad_norm": 0.4996713101863861,
      "learning_rate": 1.6396700412448445e-05,
      "loss": 0.0232,
      "step": 9610
    },
    {
      "epoch": 3.6070491188601426,
      "grad_norm": 0.20719408988952637,
      "learning_rate": 1.639295088113986e-05,
      "loss": 0.0187,
      "step": 9620
    },
    {
      "epoch": 3.610798650168729,
      "grad_norm": 1.7452195882797241,
      "learning_rate": 1.6389201349831273e-05,
      "loss": 0.0316,
      "step": 9630
    },
    {
      "epoch": 3.6145481814773155,
      "grad_norm": 2.390388250350952,
      "learning_rate": 1.6385451818522686e-05,
      "loss": 0.0407,
      "step": 9640
    },
    {
      "epoch": 3.6182977127859015,
      "grad_norm": 0.1404791921377182,
      "learning_rate": 1.63817022872141e-05,
      "loss": 0.0207,
      "step": 9650
    },
    {
      "epoch": 3.622047244094488,
      "grad_norm": 2.2428276538848877,
      "learning_rate": 1.6377952755905514e-05,
      "loss": 0.0299,
      "step": 9660
    },
    {
      "epoch": 3.6257967754030744,
      "grad_norm": 0.7641432285308838,
      "learning_rate": 1.6374203224596927e-05,
      "loss": 0.0286,
      "step": 9670
    },
    {
      "epoch": 3.629546306711661,
      "grad_norm": 0.025017760694026947,
      "learning_rate": 1.637045369328834e-05,
      "loss": 0.0686,
      "step": 9680
    },
    {
      "epoch": 3.6332958380202474,
      "grad_norm": 0.0737265944480896,
      "learning_rate": 1.6366704161979755e-05,
      "loss": 0.0434,
      "step": 9690
    },
    {
      "epoch": 3.637045369328834,
      "grad_norm": 1.4762130975723267,
      "learning_rate": 1.6362954630671168e-05,
      "loss": 0.0241,
      "step": 9700
    },
    {
      "epoch": 3.6407949006374203,
      "grad_norm": 0.17042557895183563,
      "learning_rate": 1.635920509936258e-05,
      "loss": 0.0482,
      "step": 9710
    },
    {
      "epoch": 3.6445444319460067,
      "grad_norm": 3.0285556316375732,
      "learning_rate": 1.6355455568053996e-05,
      "loss": 0.0442,
      "step": 9720
    },
    {
      "epoch": 3.648293963254593,
      "grad_norm": 0.4560606777667999,
      "learning_rate": 1.635170603674541e-05,
      "loss": 0.021,
      "step": 9730
    },
    {
      "epoch": 3.6520434945631797,
      "grad_norm": 6.369187355041504,
      "learning_rate": 1.634795650543682e-05,
      "loss": 0.0283,
      "step": 9740
    },
    {
      "epoch": 3.655793025871766,
      "grad_norm": 4.807985782623291,
      "learning_rate": 1.6344206974128237e-05,
      "loss": 0.05,
      "step": 9750
    },
    {
      "epoch": 3.6595425571803526,
      "grad_norm": 0.12476347386837006,
      "learning_rate": 1.634045744281965e-05,
      "loss": 0.0579,
      "step": 9760
    },
    {
      "epoch": 3.663292088488939,
      "grad_norm": 0.02075842209160328,
      "learning_rate": 1.6336707911511062e-05,
      "loss": 0.0253,
      "step": 9770
    },
    {
      "epoch": 3.6670416197975255,
      "grad_norm": 0.048664338886737823,
      "learning_rate": 1.6332958380202474e-05,
      "loss": 0.0101,
      "step": 9780
    },
    {
      "epoch": 3.670791151106112,
      "grad_norm": 1.0411787033081055,
      "learning_rate": 1.632920884889389e-05,
      "loss": 0.0352,
      "step": 9790
    },
    {
      "epoch": 3.674540682414698,
      "grad_norm": 7.218909740447998,
      "learning_rate": 1.6325459317585303e-05,
      "loss": 0.038,
      "step": 9800
    },
    {
      "epoch": 3.6782902137232845,
      "grad_norm": 5.0204010009765625,
      "learning_rate": 1.6321709786276715e-05,
      "loss": 0.0212,
      "step": 9810
    },
    {
      "epoch": 3.682039745031871,
      "grad_norm": 0.40890106558799744,
      "learning_rate": 1.631796025496813e-05,
      "loss": 0.0392,
      "step": 9820
    },
    {
      "epoch": 3.6857892763404574,
      "grad_norm": 4.95996618270874,
      "learning_rate": 1.6314210723659544e-05,
      "loss": 0.0478,
      "step": 9830
    },
    {
      "epoch": 3.689538807649044,
      "grad_norm": 0.30349472165107727,
      "learning_rate": 1.6310461192350956e-05,
      "loss": 0.0118,
      "step": 9840
    },
    {
      "epoch": 3.6932883389576303,
      "grad_norm": 6.102111339569092,
      "learning_rate": 1.6306711661042372e-05,
      "loss": 0.0424,
      "step": 9850
    },
    {
      "epoch": 3.6970378702662168,
      "grad_norm": 0.09986446797847748,
      "learning_rate": 1.6302962129733784e-05,
      "loss": 0.0251,
      "step": 9860
    },
    {
      "epoch": 3.7007874015748032,
      "grad_norm": 5.147911071777344,
      "learning_rate": 1.6299212598425197e-05,
      "loss": 0.0289,
      "step": 9870
    },
    {
      "epoch": 3.7045369328833897,
      "grad_norm": 0.6030094027519226,
      "learning_rate": 1.6295463067116613e-05,
      "loss": 0.0237,
      "step": 9880
    },
    {
      "epoch": 3.708286464191976,
      "grad_norm": 1.4012386798858643,
      "learning_rate": 1.6291713535808025e-05,
      "loss": 0.0267,
      "step": 9890
    },
    {
      "epoch": 3.712035995500562,
      "grad_norm": 1.3038532733917236,
      "learning_rate": 1.6287964004499438e-05,
      "loss": 0.0266,
      "step": 9900
    },
    {
      "epoch": 3.7157855268091486,
      "grad_norm": 1.4336317777633667,
      "learning_rate": 1.6284214473190854e-05,
      "loss": 0.043,
      "step": 9910
    },
    {
      "epoch": 3.719535058117735,
      "grad_norm": 0.04080819711089134,
      "learning_rate": 1.6280464941882266e-05,
      "loss": 0.0068,
      "step": 9920
    },
    {
      "epoch": 3.7232845894263216,
      "grad_norm": 1.3443998098373413,
      "learning_rate": 1.627671541057368e-05,
      "loss": 0.0268,
      "step": 9930
    },
    {
      "epoch": 3.727034120734908,
      "grad_norm": 0.033571068197488785,
      "learning_rate": 1.627296587926509e-05,
      "loss": 0.0195,
      "step": 9940
    },
    {
      "epoch": 3.7307836520434945,
      "grad_norm": 0.45586034655570984,
      "learning_rate": 1.6269216347956507e-05,
      "loss": 0.0126,
      "step": 9950
    },
    {
      "epoch": 3.734533183352081,
      "grad_norm": 0.24042581021785736,
      "learning_rate": 1.6265466816647923e-05,
      "loss": 0.0264,
      "step": 9960
    },
    {
      "epoch": 3.7382827146606674,
      "grad_norm": 0.930325448513031,
      "learning_rate": 1.6261717285339332e-05,
      "loss": 0.0364,
      "step": 9970
    },
    {
      "epoch": 3.742032245969254,
      "grad_norm": 1.157175898551941,
      "learning_rate": 1.6257967754030748e-05,
      "loss": 0.0344,
      "step": 9980
    },
    {
      "epoch": 3.7457817772778403,
      "grad_norm": 0.04008825123310089,
      "learning_rate": 1.625421822272216e-05,
      "loss": 0.0098,
      "step": 9990
    },
    {
      "epoch": 3.749531308586427,
      "grad_norm": 0.01109158806502819,
      "learning_rate": 1.6250468691413573e-05,
      "loss": 0.0318,
      "step": 10000
    },
    {
      "epoch": 3.7532808398950133,
      "grad_norm": 4.430171489715576,
      "learning_rate": 1.624671916010499e-05,
      "loss": 0.0463,
      "step": 10010
    },
    {
      "epoch": 3.7570303712035997,
      "grad_norm": 0.017630377784371376,
      "learning_rate": 1.62429696287964e-05,
      "loss": 0.0091,
      "step": 10020
    },
    {
      "epoch": 3.760779902512186,
      "grad_norm": 4.885030746459961,
      "learning_rate": 1.6239220097487817e-05,
      "loss": 0.0267,
      "step": 10030
    },
    {
      "epoch": 3.7645294338207727,
      "grad_norm": 0.8566957712173462,
      "learning_rate": 1.623547056617923e-05,
      "loss": 0.0226,
      "step": 10040
    },
    {
      "epoch": 3.7682789651293587,
      "grad_norm": 0.1087896078824997,
      "learning_rate": 1.6231721034870642e-05,
      "loss": 0.0278,
      "step": 10050
    },
    {
      "epoch": 3.772028496437945,
      "grad_norm": 6.832635879516602,
      "learning_rate": 1.6227971503562058e-05,
      "loss": 0.0216,
      "step": 10060
    },
    {
      "epoch": 3.7757780277465316,
      "grad_norm": 0.05846049636602402,
      "learning_rate": 1.622422197225347e-05,
      "loss": 0.0397,
      "step": 10070
    },
    {
      "epoch": 3.779527559055118,
      "grad_norm": 1.639183759689331,
      "learning_rate": 1.6220472440944883e-05,
      "loss": 0.0068,
      "step": 10080
    },
    {
      "epoch": 3.7832770903637045,
      "grad_norm": 0.007733192294836044,
      "learning_rate": 1.62167229096363e-05,
      "loss": 0.0347,
      "step": 10090
    },
    {
      "epoch": 3.787026621672291,
      "grad_norm": 0.024619974195957184,
      "learning_rate": 1.621297337832771e-05,
      "loss": 0.0307,
      "step": 10100
    },
    {
      "epoch": 3.7907761529808774,
      "grad_norm": 0.28213801980018616,
      "learning_rate": 1.6209223847019124e-05,
      "loss": 0.0233,
      "step": 10110
    },
    {
      "epoch": 3.794525684289464,
      "grad_norm": 0.1365918219089508,
      "learning_rate": 1.6205474315710536e-05,
      "loss": 0.0147,
      "step": 10120
    },
    {
      "epoch": 3.7982752155980504,
      "grad_norm": 0.20215463638305664,
      "learning_rate": 1.6201724784401952e-05,
      "loss": 0.0996,
      "step": 10130
    },
    {
      "epoch": 3.802024746906637,
      "grad_norm": 0.8238208889961243,
      "learning_rate": 1.6197975253093365e-05,
      "loss": 0.0055,
      "step": 10140
    },
    {
      "epoch": 3.805774278215223,
      "grad_norm": 3.116248846054077,
      "learning_rate": 1.6194225721784777e-05,
      "loss": 0.0227,
      "step": 10150
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 0.06379418075084686,
      "learning_rate": 1.6190476190476193e-05,
      "loss": 0.0189,
      "step": 10160
    },
    {
      "epoch": 3.8132733408323958,
      "grad_norm": 2.620314598083496,
      "learning_rate": 1.6186726659167606e-05,
      "loss": 0.025,
      "step": 10170
    },
    {
      "epoch": 3.8170228721409822,
      "grad_norm": 1.1678749322891235,
      "learning_rate": 1.6182977127859018e-05,
      "loss": 0.0428,
      "step": 10180
    },
    {
      "epoch": 3.8207724034495687,
      "grad_norm": 1.1553924083709717,
      "learning_rate": 1.6179227596550434e-05,
      "loss": 0.0387,
      "step": 10190
    },
    {
      "epoch": 3.824521934758155,
      "grad_norm": 0.010290962643921375,
      "learning_rate": 1.6175478065241846e-05,
      "loss": 0.0113,
      "step": 10200
    },
    {
      "epoch": 3.8282714660667416,
      "grad_norm": 1.8736172914505005,
      "learning_rate": 1.617172853393326e-05,
      "loss": 0.0477,
      "step": 10210
    },
    {
      "epoch": 3.832020997375328,
      "grad_norm": 0.01773453876376152,
      "learning_rate": 1.6167979002624675e-05,
      "loss": 0.0239,
      "step": 10220
    },
    {
      "epoch": 3.8357705286839145,
      "grad_norm": 0.6231867671012878,
      "learning_rate": 1.6164229471316087e-05,
      "loss": 0.0363,
      "step": 10230
    },
    {
      "epoch": 3.839520059992501,
      "grad_norm": 0.17499332129955292,
      "learning_rate": 1.61604799400075e-05,
      "loss": 0.0199,
      "step": 10240
    },
    {
      "epoch": 3.8432695913010875,
      "grad_norm": 0.27023595571517944,
      "learning_rate": 1.6156730408698912e-05,
      "loss": 0.0139,
      "step": 10250
    },
    {
      "epoch": 3.847019122609674,
      "grad_norm": 19.224172592163086,
      "learning_rate": 1.6152980877390328e-05,
      "loss": 0.0442,
      "step": 10260
    },
    {
      "epoch": 3.8507686539182604,
      "grad_norm": 0.04377800226211548,
      "learning_rate": 1.614923134608174e-05,
      "loss": 0.0236,
      "step": 10270
    },
    {
      "epoch": 3.854518185226847,
      "grad_norm": 0.08440797030925751,
      "learning_rate": 1.6145481814773153e-05,
      "loss": 0.0451,
      "step": 10280
    },
    {
      "epoch": 3.8582677165354333,
      "grad_norm": 2.823441743850708,
      "learning_rate": 1.614173228346457e-05,
      "loss": 0.0433,
      "step": 10290
    },
    {
      "epoch": 3.8620172478440193,
      "grad_norm": 6.7650604248046875,
      "learning_rate": 1.613798275215598e-05,
      "loss": 0.0292,
      "step": 10300
    },
    {
      "epoch": 3.865766779152606,
      "grad_norm": 1.4240238666534424,
      "learning_rate": 1.6134233220847394e-05,
      "loss": 0.0221,
      "step": 10310
    },
    {
      "epoch": 3.8695163104611923,
      "grad_norm": 0.6303179264068604,
      "learning_rate": 1.613048368953881e-05,
      "loss": 0.0096,
      "step": 10320
    },
    {
      "epoch": 3.8732658417697787,
      "grad_norm": 0.11848585307598114,
      "learning_rate": 1.6126734158230222e-05,
      "loss": 0.0325,
      "step": 10330
    },
    {
      "epoch": 3.877015373078365,
      "grad_norm": 1.2122037410736084,
      "learning_rate": 1.6122984626921635e-05,
      "loss": 0.0223,
      "step": 10340
    },
    {
      "epoch": 3.8807649043869517,
      "grad_norm": 0.022187955677509308,
      "learning_rate": 1.611923509561305e-05,
      "loss": 0.013,
      "step": 10350
    },
    {
      "epoch": 3.884514435695538,
      "grad_norm": 6.98920202255249,
      "learning_rate": 1.6115485564304463e-05,
      "loss": 0.0434,
      "step": 10360
    },
    {
      "epoch": 3.8882639670041246,
      "grad_norm": 7.111078262329102,
      "learning_rate": 1.6111736032995876e-05,
      "loss": 0.0521,
      "step": 10370
    },
    {
      "epoch": 3.892013498312711,
      "grad_norm": 0.06569604575634003,
      "learning_rate": 1.6107986501687288e-05,
      "loss": 0.0499,
      "step": 10380
    },
    {
      "epoch": 3.8957630296212975,
      "grad_norm": 0.4758501946926117,
      "learning_rate": 1.6104236970378704e-05,
      "loss": 0.0251,
      "step": 10390
    },
    {
      "epoch": 3.8995125609298835,
      "grad_norm": 0.6639007925987244,
      "learning_rate": 1.6100487439070117e-05,
      "loss": 0.0376,
      "step": 10400
    },
    {
      "epoch": 3.90326209223847,
      "grad_norm": 0.2638314664363861,
      "learning_rate": 1.609673790776153e-05,
      "loss": 0.0501,
      "step": 10410
    },
    {
      "epoch": 3.9070116235470564,
      "grad_norm": 2.3358452320098877,
      "learning_rate": 1.6092988376452945e-05,
      "loss": 0.0355,
      "step": 10420
    },
    {
      "epoch": 3.910761154855643,
      "grad_norm": 1.8265472650527954,
      "learning_rate": 1.608923884514436e-05,
      "loss": 0.0244,
      "step": 10430
    },
    {
      "epoch": 3.9145106861642294,
      "grad_norm": 0.14368200302124023,
      "learning_rate": 1.608548931383577e-05,
      "loss": 0.0271,
      "step": 10440
    },
    {
      "epoch": 3.918260217472816,
      "grad_norm": 0.3155007064342499,
      "learning_rate": 1.6081739782527186e-05,
      "loss": 0.0263,
      "step": 10450
    },
    {
      "epoch": 3.9220097487814023,
      "grad_norm": 0.9926931262016296,
      "learning_rate": 1.60779902512186e-05,
      "loss": 0.0186,
      "step": 10460
    },
    {
      "epoch": 3.9257592800899888,
      "grad_norm": 3.420414686203003,
      "learning_rate": 1.607424071991001e-05,
      "loss": 0.0272,
      "step": 10470
    },
    {
      "epoch": 3.929508811398575,
      "grad_norm": 0.02664073556661606,
      "learning_rate": 1.6070491188601427e-05,
      "loss": 0.0325,
      "step": 10480
    },
    {
      "epoch": 3.9332583427071617,
      "grad_norm": 1.536407470703125,
      "learning_rate": 1.606674165729284e-05,
      "loss": 0.0551,
      "step": 10490
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 2.1480696201324463,
      "learning_rate": 1.6062992125984255e-05,
      "loss": 0.0267,
      "step": 10500
    },
    {
      "epoch": 3.9407574053243346,
      "grad_norm": 0.061009880155324936,
      "learning_rate": 1.6059242594675664e-05,
      "loss": 0.0288,
      "step": 10510
    },
    {
      "epoch": 3.944506936632921,
      "grad_norm": 0.19282768666744232,
      "learning_rate": 1.605549306336708e-05,
      "loss": 0.0279,
      "step": 10520
    },
    {
      "epoch": 3.9482564679415075,
      "grad_norm": 2.727276563644409,
      "learning_rate": 1.6051743532058496e-05,
      "loss": 0.0504,
      "step": 10530
    },
    {
      "epoch": 3.952005999250094,
      "grad_norm": 0.2369248867034912,
      "learning_rate": 1.604799400074991e-05,
      "loss": 0.0163,
      "step": 10540
    },
    {
      "epoch": 3.95575553055868,
      "grad_norm": 0.31581297516822815,
      "learning_rate": 1.604424446944132e-05,
      "loss": 0.0274,
      "step": 10550
    },
    {
      "epoch": 3.9595050618672665,
      "grad_norm": 0.9773281216621399,
      "learning_rate": 1.6040494938132737e-05,
      "loss": 0.0085,
      "step": 10560
    },
    {
      "epoch": 3.963254593175853,
      "grad_norm": 0.793643057346344,
      "learning_rate": 1.603674540682415e-05,
      "loss": 0.0392,
      "step": 10570
    },
    {
      "epoch": 3.9670041244844394,
      "grad_norm": 2.884340286254883,
      "learning_rate": 1.6032995875515562e-05,
      "loss": 0.0135,
      "step": 10580
    },
    {
      "epoch": 3.970753655793026,
      "grad_norm": 20.0054931640625,
      "learning_rate": 1.6029246344206974e-05,
      "loss": 0.0376,
      "step": 10590
    },
    {
      "epoch": 3.9745031871016123,
      "grad_norm": 8.084142684936523,
      "learning_rate": 1.602549681289839e-05,
      "loss": 0.0335,
      "step": 10600
    },
    {
      "epoch": 3.978252718410199,
      "grad_norm": 0.10319086909294128,
      "learning_rate": 1.6021747281589803e-05,
      "loss": 0.0294,
      "step": 10610
    },
    {
      "epoch": 3.9820022497187852,
      "grad_norm": 0.07209540903568268,
      "learning_rate": 1.6017997750281215e-05,
      "loss": 0.0536,
      "step": 10620
    },
    {
      "epoch": 3.9857517810273717,
      "grad_norm": 4.3992791175842285,
      "learning_rate": 1.601424821897263e-05,
      "loss": 0.0212,
      "step": 10630
    },
    {
      "epoch": 3.9895013123359577,
      "grad_norm": 0.8735030293464661,
      "learning_rate": 1.6010498687664044e-05,
      "loss": 0.0443,
      "step": 10640
    },
    {
      "epoch": 3.993250843644544,
      "grad_norm": 2.5261971950531006,
      "learning_rate": 1.6006749156355456e-05,
      "loss": 0.0242,
      "step": 10650
    },
    {
      "epoch": 3.9970003749531307,
      "grad_norm": 1.809030294418335,
      "learning_rate": 1.6002999625046872e-05,
      "loss": 0.0329,
      "step": 10660
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9907042869641295,
      "eval_f1": 0.9638656652968685,
      "eval_loss": 0.029064001515507698,
      "eval_precision": 0.9717142857142858,
      "eval_recall": 0.9561428169806017,
      "eval_runtime": 917.5571,
      "eval_samples_per_second": 29.898,
      "eval_steps_per_second": 1.247,
      "step": 10668
    },
    {
      "epoch": 4.000749906261717,
      "grad_norm": 0.03258688375353813,
      "learning_rate": 1.5999250093738284e-05,
      "loss": 0.0131,
      "step": 10670
    },
    {
      "epoch": 4.004499437570304,
      "grad_norm": 1.0849305391311646,
      "learning_rate": 1.5995500562429697e-05,
      "loss": 0.0335,
      "step": 10680
    },
    {
      "epoch": 4.00824896887889,
      "grad_norm": 1.0363423824310303,
      "learning_rate": 1.5991751031121113e-05,
      "loss": 0.0275,
      "step": 10690
    },
    {
      "epoch": 4.0119985001874765,
      "grad_norm": 2.2411675453186035,
      "learning_rate": 1.5988001499812525e-05,
      "loss": 0.0251,
      "step": 10700
    },
    {
      "epoch": 4.015748031496063,
      "grad_norm": 0.06556452810764313,
      "learning_rate": 1.5984251968503938e-05,
      "loss": 0.0289,
      "step": 10710
    },
    {
      "epoch": 4.019497562804649,
      "grad_norm": 0.5781726837158203,
      "learning_rate": 1.598050243719535e-05,
      "loss": 0.0125,
      "step": 10720
    },
    {
      "epoch": 4.023247094113236,
      "grad_norm": 4.116667747497559,
      "learning_rate": 1.5976752905886766e-05,
      "loss": 0.0091,
      "step": 10730
    },
    {
      "epoch": 4.026996625421822,
      "grad_norm": 0.4162810742855072,
      "learning_rate": 1.597300337457818e-05,
      "loss": 0.02,
      "step": 10740
    },
    {
      "epoch": 4.030746156730409,
      "grad_norm": 0.2210153192281723,
      "learning_rate": 1.596925384326959e-05,
      "loss": 0.0377,
      "step": 10750
    },
    {
      "epoch": 4.034495688038995,
      "grad_norm": 0.027469675987958908,
      "learning_rate": 1.5965504311961007e-05,
      "loss": 0.0344,
      "step": 10760
    },
    {
      "epoch": 4.038245219347582,
      "grad_norm": 0.37740692496299744,
      "learning_rate": 1.596175478065242e-05,
      "loss": 0.0258,
      "step": 10770
    },
    {
      "epoch": 4.041994750656168,
      "grad_norm": 0.11481620371341705,
      "learning_rate": 1.5958005249343832e-05,
      "loss": 0.0142,
      "step": 10780
    },
    {
      "epoch": 4.045744281964755,
      "grad_norm": 14.371910095214844,
      "learning_rate": 1.5954255718035248e-05,
      "loss": 0.0196,
      "step": 10790
    },
    {
      "epoch": 4.049493813273341,
      "grad_norm": 5.621613025665283,
      "learning_rate": 1.595050618672666e-05,
      "loss": 0.0086,
      "step": 10800
    },
    {
      "epoch": 4.053243344581928,
      "grad_norm": 0.26560115814208984,
      "learning_rate": 1.5946756655418073e-05,
      "loss": 0.0564,
      "step": 10810
    },
    {
      "epoch": 4.056992875890514,
      "grad_norm": 1.7428077459335327,
      "learning_rate": 1.594300712410949e-05,
      "loss": 0.0082,
      "step": 10820
    },
    {
      "epoch": 4.0607424071991005,
      "grad_norm": 0.022221362218260765,
      "learning_rate": 1.59392575928009e-05,
      "loss": 0.0457,
      "step": 10830
    },
    {
      "epoch": 4.064491938507687,
      "grad_norm": 5.390637397766113,
      "learning_rate": 1.5935508061492314e-05,
      "loss": 0.0293,
      "step": 10840
    },
    {
      "epoch": 4.0682414698162725,
      "grad_norm": 3.2871718406677246,
      "learning_rate": 1.5931758530183726e-05,
      "loss": 0.0373,
      "step": 10850
    },
    {
      "epoch": 4.071991001124859,
      "grad_norm": 0.08295917510986328,
      "learning_rate": 1.5928008998875142e-05,
      "loss": 0.0197,
      "step": 10860
    },
    {
      "epoch": 4.0757405324334455,
      "grad_norm": 0.03415939584374428,
      "learning_rate": 1.5924259467566555e-05,
      "loss": 0.0178,
      "step": 10870
    },
    {
      "epoch": 4.079490063742032,
      "grad_norm": 0.7674599289894104,
      "learning_rate": 1.5920509936257967e-05,
      "loss": 0.0451,
      "step": 10880
    },
    {
      "epoch": 4.083239595050618,
      "grad_norm": 0.26543617248535156,
      "learning_rate": 1.5916760404949383e-05,
      "loss": 0.0163,
      "step": 10890
    },
    {
      "epoch": 4.086989126359205,
      "grad_norm": 0.13155950605869293,
      "learning_rate": 1.5913010873640796e-05,
      "loss": 0.0246,
      "step": 10900
    },
    {
      "epoch": 4.090738657667791,
      "grad_norm": 0.013716506771743298,
      "learning_rate": 1.5909261342332208e-05,
      "loss": 0.0254,
      "step": 10910
    },
    {
      "epoch": 4.094488188976378,
      "grad_norm": 1.4603633880615234,
      "learning_rate": 1.5905511811023624e-05,
      "loss": 0.0285,
      "step": 10920
    },
    {
      "epoch": 4.098237720284964,
      "grad_norm": 0.1171441525220871,
      "learning_rate": 1.5901762279715036e-05,
      "loss": 0.0296,
      "step": 10930
    },
    {
      "epoch": 4.101987251593551,
      "grad_norm": 3.0236330032348633,
      "learning_rate": 1.589801274840645e-05,
      "loss": 0.0357,
      "step": 10940
    },
    {
      "epoch": 4.105736782902137,
      "grad_norm": 0.49933651089668274,
      "learning_rate": 1.5894263217097865e-05,
      "loss": 0.028,
      "step": 10950
    },
    {
      "epoch": 4.109486314210724,
      "grad_norm": 0.08716100454330444,
      "learning_rate": 1.5890513685789277e-05,
      "loss": 0.0299,
      "step": 10960
    },
    {
      "epoch": 4.11323584551931,
      "grad_norm": 4.230315685272217,
      "learning_rate": 1.5886764154480693e-05,
      "loss": 0.0243,
      "step": 10970
    },
    {
      "epoch": 4.116985376827897,
      "grad_norm": 1.0440996885299683,
      "learning_rate": 1.5883014623172102e-05,
      "loss": 0.0256,
      "step": 10980
    },
    {
      "epoch": 4.120734908136483,
      "grad_norm": 0.9067225456237793,
      "learning_rate": 1.5879265091863518e-05,
      "loss": 0.0116,
      "step": 10990
    },
    {
      "epoch": 4.1244844394450695,
      "grad_norm": 1.0140342712402344,
      "learning_rate": 1.5875515560554934e-05,
      "loss": 0.0153,
      "step": 11000
    },
    {
      "epoch": 4.128233970753656,
      "grad_norm": 0.0034950922708958387,
      "learning_rate": 1.5871766029246347e-05,
      "loss": 0.0081,
      "step": 11010
    },
    {
      "epoch": 4.131983502062242,
      "grad_norm": 0.013201775960624218,
      "learning_rate": 1.586801649793776e-05,
      "loss": 0.019,
      "step": 11020
    },
    {
      "epoch": 4.135733033370829,
      "grad_norm": 0.004318905528634787,
      "learning_rate": 1.5864266966629175e-05,
      "loss": 0.0123,
      "step": 11030
    },
    {
      "epoch": 4.139482564679415,
      "grad_norm": 0.12620186805725098,
      "learning_rate": 1.5860517435320587e-05,
      "loss": 0.0215,
      "step": 11040
    },
    {
      "epoch": 4.143232095988002,
      "grad_norm": 0.03211761265993118,
      "learning_rate": 1.5856767904012e-05,
      "loss": 0.0525,
      "step": 11050
    },
    {
      "epoch": 4.146981627296588,
      "grad_norm": 0.11613424122333527,
      "learning_rate": 1.5853018372703412e-05,
      "loss": 0.0447,
      "step": 11060
    },
    {
      "epoch": 4.150731158605175,
      "grad_norm": 3.6460888385772705,
      "learning_rate": 1.5849268841394828e-05,
      "loss": 0.0387,
      "step": 11070
    },
    {
      "epoch": 4.154480689913761,
      "grad_norm": 1.6903706789016724,
      "learning_rate": 1.584551931008624e-05,
      "loss": 0.029,
      "step": 11080
    },
    {
      "epoch": 4.158230221222347,
      "grad_norm": 1.1547131538391113,
      "learning_rate": 1.5841769778777653e-05,
      "loss": 0.0109,
      "step": 11090
    },
    {
      "epoch": 4.161979752530933,
      "grad_norm": 0.1825740486383438,
      "learning_rate": 1.583802024746907e-05,
      "loss": 0.0171,
      "step": 11100
    },
    {
      "epoch": 4.16572928383952,
      "grad_norm": 3.233449697494507,
      "learning_rate": 1.583427071616048e-05,
      "loss": 0.0313,
      "step": 11110
    },
    {
      "epoch": 4.169478815148106,
      "grad_norm": 0.9856785535812378,
      "learning_rate": 1.5830521184851894e-05,
      "loss": 0.0153,
      "step": 11120
    },
    {
      "epoch": 4.173228346456693,
      "grad_norm": 0.035069745033979416,
      "learning_rate": 1.582677165354331e-05,
      "loss": 0.0704,
      "step": 11130
    },
    {
      "epoch": 4.176977877765279,
      "grad_norm": 0.8279734253883362,
      "learning_rate": 1.5823022122234723e-05,
      "loss": 0.006,
      "step": 11140
    },
    {
      "epoch": 4.1807274090738655,
      "grad_norm": 0.529405951499939,
      "learning_rate": 1.5819272590926135e-05,
      "loss": 0.0036,
      "step": 11150
    },
    {
      "epoch": 4.184476940382452,
      "grad_norm": 0.009671037085354328,
      "learning_rate": 1.581552305961755e-05,
      "loss": 0.0198,
      "step": 11160
    },
    {
      "epoch": 4.1882264716910385,
      "grad_norm": 0.007504674606025219,
      "learning_rate": 1.5811773528308963e-05,
      "loss": 0.0108,
      "step": 11170
    },
    {
      "epoch": 4.191976002999625,
      "grad_norm": 0.37652695178985596,
      "learning_rate": 1.5808023997000376e-05,
      "loss": 0.0068,
      "step": 11180
    },
    {
      "epoch": 4.195725534308211,
      "grad_norm": 0.04344893991947174,
      "learning_rate": 1.580427446569179e-05,
      "loss": 0.0264,
      "step": 11190
    },
    {
      "epoch": 4.199475065616798,
      "grad_norm": 0.13359671831130981,
      "learning_rate": 1.5800524934383204e-05,
      "loss": 0.0225,
      "step": 11200
    },
    {
      "epoch": 4.203224596925384,
      "grad_norm": 0.05662684142589569,
      "learning_rate": 1.5796775403074617e-05,
      "loss": 0.002,
      "step": 11210
    },
    {
      "epoch": 4.206974128233971,
      "grad_norm": 0.06565263867378235,
      "learning_rate": 1.579302587176603e-05,
      "loss": 0.0027,
      "step": 11220
    },
    {
      "epoch": 4.210723659542557,
      "grad_norm": 0.9249039888381958,
      "learning_rate": 1.5789276340457445e-05,
      "loss": 0.0203,
      "step": 11230
    },
    {
      "epoch": 4.214473190851144,
      "grad_norm": 1.483870029449463,
      "learning_rate": 1.5785526809148858e-05,
      "loss": 0.0284,
      "step": 11240
    },
    {
      "epoch": 4.21822272215973,
      "grad_norm": 1.0085633993148804,
      "learning_rate": 1.578177727784027e-05,
      "loss": 0.029,
      "step": 11250
    },
    {
      "epoch": 4.221972253468317,
      "grad_norm": 4.204573631286621,
      "learning_rate": 1.5778027746531686e-05,
      "loss": 0.0817,
      "step": 11260
    },
    {
      "epoch": 4.225721784776903,
      "grad_norm": 0.1435372233390808,
      "learning_rate": 1.57742782152231e-05,
      "loss": 0.0168,
      "step": 11270
    },
    {
      "epoch": 4.2294713160854895,
      "grad_norm": 1.3210558891296387,
      "learning_rate": 1.577052868391451e-05,
      "loss": 0.0286,
      "step": 11280
    },
    {
      "epoch": 4.233220847394076,
      "grad_norm": 0.03858067840337753,
      "learning_rate": 1.5766779152605927e-05,
      "loss": 0.0136,
      "step": 11290
    },
    {
      "epoch": 4.2369703787026625,
      "grad_norm": 0.0932900607585907,
      "learning_rate": 1.576302962129734e-05,
      "loss": 0.0152,
      "step": 11300
    },
    {
      "epoch": 4.240719910011249,
      "grad_norm": 5.610198974609375,
      "learning_rate": 1.5759280089988752e-05,
      "loss": 0.0274,
      "step": 11310
    },
    {
      "epoch": 4.244469441319835,
      "grad_norm": 0.17962020635604858,
      "learning_rate": 1.5755530558680164e-05,
      "loss": 0.0264,
      "step": 11320
    },
    {
      "epoch": 4.248218972628422,
      "grad_norm": 0.1113576591014862,
      "learning_rate": 1.575178102737158e-05,
      "loss": 0.0453,
      "step": 11330
    },
    {
      "epoch": 4.251968503937007,
      "grad_norm": 0.28229641914367676,
      "learning_rate": 1.5748031496062993e-05,
      "loss": 0.0155,
      "step": 11340
    },
    {
      "epoch": 4.255718035245594,
      "grad_norm": 0.04435348883271217,
      "learning_rate": 1.5744281964754405e-05,
      "loss": 0.0254,
      "step": 11350
    },
    {
      "epoch": 4.25946756655418,
      "grad_norm": 0.03354889154434204,
      "learning_rate": 1.574053243344582e-05,
      "loss": 0.0175,
      "step": 11360
    },
    {
      "epoch": 4.263217097862767,
      "grad_norm": 0.010716238059103489,
      "learning_rate": 1.5736782902137234e-05,
      "loss": 0.0347,
      "step": 11370
    },
    {
      "epoch": 4.266966629171353,
      "grad_norm": 0.03543185442686081,
      "learning_rate": 1.5733033370828646e-05,
      "loss": 0.0264,
      "step": 11380
    },
    {
      "epoch": 4.27071616047994,
      "grad_norm": 6.810245037078857,
      "learning_rate": 1.5729283839520062e-05,
      "loss": 0.0266,
      "step": 11390
    },
    {
      "epoch": 4.274465691788526,
      "grad_norm": 2.5763068199157715,
      "learning_rate": 1.5725534308211474e-05,
      "loss": 0.0321,
      "step": 11400
    },
    {
      "epoch": 4.278215223097113,
      "grad_norm": 3.0287678241729736,
      "learning_rate": 1.5721784776902887e-05,
      "loss": 0.0257,
      "step": 11410
    },
    {
      "epoch": 4.281964754405699,
      "grad_norm": 0.46357008814811707,
      "learning_rate": 1.5718035245594303e-05,
      "loss": 0.0189,
      "step": 11420
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 1.0387821197509766,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.0354,
      "step": 11430
    },
    {
      "epoch": 4.289463817022872,
      "grad_norm": 0.7123990058898926,
      "learning_rate": 1.571053618297713e-05,
      "loss": 0.0201,
      "step": 11440
    },
    {
      "epoch": 4.2932133483314585,
      "grad_norm": 0.19130782783031464,
      "learning_rate": 1.570678665166854e-05,
      "loss": 0.0087,
      "step": 11450
    },
    {
      "epoch": 4.296962879640045,
      "grad_norm": 1.0884804725646973,
      "learning_rate": 1.5703037120359956e-05,
      "loss": 0.0162,
      "step": 11460
    },
    {
      "epoch": 4.300712410948631,
      "grad_norm": 0.21768638491630554,
      "learning_rate": 1.5699287589051372e-05,
      "loss": 0.0252,
      "step": 11470
    },
    {
      "epoch": 4.304461942257218,
      "grad_norm": 4.959259986877441,
      "learning_rate": 1.5695538057742785e-05,
      "loss": 0.0285,
      "step": 11480
    },
    {
      "epoch": 4.308211473565804,
      "grad_norm": 0.12319205701351166,
      "learning_rate": 1.5691788526434197e-05,
      "loss": 0.0079,
      "step": 11490
    },
    {
      "epoch": 4.311961004874391,
      "grad_norm": 0.1137247309088707,
      "learning_rate": 1.568803899512561e-05,
      "loss": 0.02,
      "step": 11500
    },
    {
      "epoch": 4.315710536182977,
      "grad_norm": 0.014903713017702103,
      "learning_rate": 1.5684289463817025e-05,
      "loss": 0.0148,
      "step": 11510
    },
    {
      "epoch": 4.319460067491564,
      "grad_norm": 0.4095093905925751,
      "learning_rate": 1.5680539932508438e-05,
      "loss": 0.044,
      "step": 11520
    },
    {
      "epoch": 4.32320959880015,
      "grad_norm": 0.034482818096876144,
      "learning_rate": 1.567679040119985e-05,
      "loss": 0.0187,
      "step": 11530
    },
    {
      "epoch": 4.326959130108737,
      "grad_norm": 0.06793228536844254,
      "learning_rate": 1.5673040869891266e-05,
      "loss": 0.0195,
      "step": 11540
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 0.019422082230448723,
      "learning_rate": 1.566929133858268e-05,
      "loss": 0.0074,
      "step": 11550
    },
    {
      "epoch": 4.33445819272591,
      "grad_norm": 0.006267526187002659,
      "learning_rate": 1.566554180727409e-05,
      "loss": 0.0079,
      "step": 11560
    },
    {
      "epoch": 4.338207724034496,
      "grad_norm": 1.7472360134124756,
      "learning_rate": 1.5661792275965507e-05,
      "loss": 0.0119,
      "step": 11570
    },
    {
      "epoch": 4.3419572553430825,
      "grad_norm": 0.2182459682226181,
      "learning_rate": 1.565804274465692e-05,
      "loss": 0.0348,
      "step": 11580
    },
    {
      "epoch": 4.345706786651668,
      "grad_norm": 0.8840571045875549,
      "learning_rate": 1.5654293213348332e-05,
      "loss": 0.0291,
      "step": 11590
    },
    {
      "epoch": 4.349456317960255,
      "grad_norm": 0.011089049279689789,
      "learning_rate": 1.5650543682039748e-05,
      "loss": 0.0409,
      "step": 11600
    },
    {
      "epoch": 4.353205849268841,
      "grad_norm": 0.3636930584907532,
      "learning_rate": 1.564679415073116e-05,
      "loss": 0.0051,
      "step": 11610
    },
    {
      "epoch": 4.3569553805774275,
      "grad_norm": 0.5173287987709045,
      "learning_rate": 1.5643044619422573e-05,
      "loss": 0.0253,
      "step": 11620
    },
    {
      "epoch": 4.360704911886014,
      "grad_norm": 0.32565316557884216,
      "learning_rate": 1.5639295088113986e-05,
      "loss": 0.0386,
      "step": 11630
    },
    {
      "epoch": 4.3644544431946,
      "grad_norm": 0.01509159803390503,
      "learning_rate": 1.56355455568054e-05,
      "loss": 0.0059,
      "step": 11640
    },
    {
      "epoch": 4.368203974503187,
      "grad_norm": 0.8604424595832825,
      "learning_rate": 1.5631796025496814e-05,
      "loss": 0.0275,
      "step": 11650
    },
    {
      "epoch": 4.371953505811773,
      "grad_norm": 1.2257286310195923,
      "learning_rate": 1.5628046494188226e-05,
      "loss": 0.0206,
      "step": 11660
    },
    {
      "epoch": 4.37570303712036,
      "grad_norm": 44.700897216796875,
      "learning_rate": 1.5624296962879642e-05,
      "loss": 0.0356,
      "step": 11670
    },
    {
      "epoch": 4.379452568428946,
      "grad_norm": 0.05004804581403732,
      "learning_rate": 1.5620547431571055e-05,
      "loss": 0.0047,
      "step": 11680
    },
    {
      "epoch": 4.383202099737533,
      "grad_norm": 0.0219372920691967,
      "learning_rate": 1.5616797900262467e-05,
      "loss": 0.0133,
      "step": 11690
    },
    {
      "epoch": 4.386951631046119,
      "grad_norm": 0.017591530457139015,
      "learning_rate": 1.5613048368953883e-05,
      "loss": 0.0239,
      "step": 11700
    },
    {
      "epoch": 4.390701162354706,
      "grad_norm": 0.9649991393089294,
      "learning_rate": 1.5609298837645296e-05,
      "loss": 0.0052,
      "step": 11710
    },
    {
      "epoch": 4.394450693663292,
      "grad_norm": 4.331035137176514,
      "learning_rate": 1.5605549306336708e-05,
      "loss": 0.017,
      "step": 11720
    },
    {
      "epoch": 4.398200224971879,
      "grad_norm": 2.347834587097168,
      "learning_rate": 1.5601799775028124e-05,
      "loss": 0.0268,
      "step": 11730
    },
    {
      "epoch": 4.401949756280465,
      "grad_norm": 0.11422742158174515,
      "learning_rate": 1.5598050243719537e-05,
      "loss": 0.005,
      "step": 11740
    },
    {
      "epoch": 4.4056992875890515,
      "grad_norm": 3.695866584777832,
      "learning_rate": 1.559430071241095e-05,
      "loss": 0.0158,
      "step": 11750
    },
    {
      "epoch": 4.409448818897638,
      "grad_norm": 0.04279602691531181,
      "learning_rate": 1.559055118110236e-05,
      "loss": 0.0354,
      "step": 11760
    },
    {
      "epoch": 4.413198350206224,
      "grad_norm": 1.862198829650879,
      "learning_rate": 1.5586801649793777e-05,
      "loss": 0.0392,
      "step": 11770
    },
    {
      "epoch": 4.416947881514811,
      "grad_norm": 0.5775256752967834,
      "learning_rate": 1.558305211848519e-05,
      "loss": 0.0265,
      "step": 11780
    },
    {
      "epoch": 4.420697412823397,
      "grad_norm": 0.058694303035736084,
      "learning_rate": 1.5579302587176602e-05,
      "loss": 0.0112,
      "step": 11790
    },
    {
      "epoch": 4.424446944131984,
      "grad_norm": 0.2399328351020813,
      "learning_rate": 1.5575553055868018e-05,
      "loss": 0.0346,
      "step": 11800
    },
    {
      "epoch": 4.42819647544057,
      "grad_norm": 0.14612123370170593,
      "learning_rate": 1.557180352455943e-05,
      "loss": 0.0261,
      "step": 11810
    },
    {
      "epoch": 4.431946006749157,
      "grad_norm": 4.382146835327148,
      "learning_rate": 1.5568053993250843e-05,
      "loss": 0.0023,
      "step": 11820
    },
    {
      "epoch": 4.435695538057743,
      "grad_norm": 0.475208580493927,
      "learning_rate": 1.556430446194226e-05,
      "loss": 0.0179,
      "step": 11830
    },
    {
      "epoch": 4.439445069366329,
      "grad_norm": 0.8283337950706482,
      "learning_rate": 1.556055493063367e-05,
      "loss": 0.0185,
      "step": 11840
    },
    {
      "epoch": 4.443194600674915,
      "grad_norm": 0.5127010941505432,
      "learning_rate": 1.5556805399325084e-05,
      "loss": 0.0173,
      "step": 11850
    },
    {
      "epoch": 4.446944131983502,
      "grad_norm": 1.0032031536102295,
      "learning_rate": 1.55530558680165e-05,
      "loss": 0.0234,
      "step": 11860
    },
    {
      "epoch": 4.450693663292088,
      "grad_norm": 0.29059258103370667,
      "learning_rate": 1.5549306336707912e-05,
      "loss": 0.0268,
      "step": 11870
    },
    {
      "epoch": 4.454443194600675,
      "grad_norm": 3.114178419113159,
      "learning_rate": 1.5545556805399325e-05,
      "loss": 0.0389,
      "step": 11880
    },
    {
      "epoch": 4.458192725909261,
      "grad_norm": 0.6924020051956177,
      "learning_rate": 1.5541807274090737e-05,
      "loss": 0.0316,
      "step": 11890
    },
    {
      "epoch": 4.4619422572178475,
      "grad_norm": 1.5103387832641602,
      "learning_rate": 1.5538057742782153e-05,
      "loss": 0.0249,
      "step": 11900
    },
    {
      "epoch": 4.465691788526434,
      "grad_norm": 0.06363438814878464,
      "learning_rate": 1.553430821147357e-05,
      "loss": 0.015,
      "step": 11910
    },
    {
      "epoch": 4.4694413198350205,
      "grad_norm": 1.8273136615753174,
      "learning_rate": 1.553055868016498e-05,
      "loss": 0.0271,
      "step": 11920
    },
    {
      "epoch": 4.473190851143607,
      "grad_norm": 0.05377143621444702,
      "learning_rate": 1.5526809148856394e-05,
      "loss": 0.0164,
      "step": 11930
    },
    {
      "epoch": 4.476940382452193,
      "grad_norm": 5.273720741271973,
      "learning_rate": 1.552305961754781e-05,
      "loss": 0.0209,
      "step": 11940
    },
    {
      "epoch": 4.48068991376078,
      "grad_norm": 0.1477249562740326,
      "learning_rate": 1.5519310086239223e-05,
      "loss": 0.0393,
      "step": 11950
    },
    {
      "epoch": 4.484439445069366,
      "grad_norm": 0.29340073466300964,
      "learning_rate": 1.5515560554930635e-05,
      "loss": 0.024,
      "step": 11960
    },
    {
      "epoch": 4.488188976377953,
      "grad_norm": 0.028753919526934624,
      "learning_rate": 1.5511811023622048e-05,
      "loss": 0.0278,
      "step": 11970
    },
    {
      "epoch": 4.491938507686539,
      "grad_norm": 0.5365424752235413,
      "learning_rate": 1.5508061492313463e-05,
      "loss": 0.0243,
      "step": 11980
    },
    {
      "epoch": 4.495688038995126,
      "grad_norm": 0.8266575336456299,
      "learning_rate": 1.5504311961004876e-05,
      "loss": 0.0224,
      "step": 11990
    },
    {
      "epoch": 4.499437570303712,
      "grad_norm": 0.014357561245560646,
      "learning_rate": 1.550056242969629e-05,
      "loss": 0.0346,
      "step": 12000
    },
    {
      "epoch": 4.503187101612299,
      "grad_norm": 0.04824365675449371,
      "learning_rate": 1.5496812898387704e-05,
      "loss": 0.0335,
      "step": 12010
    },
    {
      "epoch": 4.506936632920885,
      "grad_norm": 3.5503034591674805,
      "learning_rate": 1.5493063367079117e-05,
      "loss": 0.0173,
      "step": 12020
    },
    {
      "epoch": 4.5106861642294716,
      "grad_norm": 2.25315523147583,
      "learning_rate": 1.548931383577053e-05,
      "loss": 0.0184,
      "step": 12030
    },
    {
      "epoch": 4.514435695538058,
      "grad_norm": 0.6018942594528198,
      "learning_rate": 1.5485564304461945e-05,
      "loss": 0.0146,
      "step": 12040
    },
    {
      "epoch": 4.5181852268466445,
      "grad_norm": 2.5373294353485107,
      "learning_rate": 1.5481814773153358e-05,
      "loss": 0.02,
      "step": 12050
    },
    {
      "epoch": 4.521934758155231,
      "grad_norm": 0.7342926263809204,
      "learning_rate": 1.547806524184477e-05,
      "loss": 0.0162,
      "step": 12060
    },
    {
      "epoch": 4.525684289463817,
      "grad_norm": 0.015890084207057953,
      "learning_rate": 1.5474315710536186e-05,
      "loss": 0.0103,
      "step": 12070
    },
    {
      "epoch": 4.529433820772404,
      "grad_norm": 1.021232008934021,
      "learning_rate": 1.54705661792276e-05,
      "loss": 0.0051,
      "step": 12080
    },
    {
      "epoch": 4.533183352080989,
      "grad_norm": 0.05744016170501709,
      "learning_rate": 1.546681664791901e-05,
      "loss": 0.0433,
      "step": 12090
    },
    {
      "epoch": 4.536932883389577,
      "grad_norm": 0.08118372410535812,
      "learning_rate": 1.5463067116610424e-05,
      "loss": 0.0309,
      "step": 12100
    },
    {
      "epoch": 4.540682414698162,
      "grad_norm": 1.293190360069275,
      "learning_rate": 1.545931758530184e-05,
      "loss": 0.0332,
      "step": 12110
    },
    {
      "epoch": 4.544431946006749,
      "grad_norm": 0.2686010003089905,
      "learning_rate": 1.5455568053993252e-05,
      "loss": 0.0315,
      "step": 12120
    },
    {
      "epoch": 4.548181477315335,
      "grad_norm": 3.0137417316436768,
      "learning_rate": 1.5451818522684664e-05,
      "loss": 0.0235,
      "step": 12130
    },
    {
      "epoch": 4.551931008623922,
      "grad_norm": 0.03743666410446167,
      "learning_rate": 1.544806899137608e-05,
      "loss": 0.0088,
      "step": 12140
    },
    {
      "epoch": 4.555680539932508,
      "grad_norm": 6.4291887283325195,
      "learning_rate": 1.5444319460067493e-05,
      "loss": 0.0256,
      "step": 12150
    },
    {
      "epoch": 4.559430071241095,
      "grad_norm": 0.0032002388034015894,
      "learning_rate": 1.5440569928758905e-05,
      "loss": 0.0109,
      "step": 12160
    },
    {
      "epoch": 4.563179602549681,
      "grad_norm": 0.0625811293721199,
      "learning_rate": 1.543682039745032e-05,
      "loss": 0.0311,
      "step": 12170
    },
    {
      "epoch": 4.566929133858268,
      "grad_norm": 0.01289682649075985,
      "learning_rate": 1.5433070866141734e-05,
      "loss": 0.0122,
      "step": 12180
    },
    {
      "epoch": 4.570678665166854,
      "grad_norm": 0.01674884557723999,
      "learning_rate": 1.5429321334833146e-05,
      "loss": 0.0155,
      "step": 12190
    },
    {
      "epoch": 4.5744281964754405,
      "grad_norm": 4.037479400634766,
      "learning_rate": 1.5425571803524562e-05,
      "loss": 0.0273,
      "step": 12200
    },
    {
      "epoch": 4.578177727784027,
      "grad_norm": 0.028563253581523895,
      "learning_rate": 1.5421822272215975e-05,
      "loss": 0.0331,
      "step": 12210
    },
    {
      "epoch": 4.5819272590926134,
      "grad_norm": 0.013573248870670795,
      "learning_rate": 1.5418072740907387e-05,
      "loss": 0.0161,
      "step": 12220
    },
    {
      "epoch": 4.5856767904012,
      "grad_norm": 8.427665710449219,
      "learning_rate": 1.54143232095988e-05,
      "loss": 0.041,
      "step": 12230
    },
    {
      "epoch": 4.589426321709786,
      "grad_norm": 2.200402021408081,
      "learning_rate": 1.5410573678290215e-05,
      "loss": 0.0414,
      "step": 12240
    },
    {
      "epoch": 4.593175853018373,
      "grad_norm": 0.5857268571853638,
      "learning_rate": 1.5406824146981628e-05,
      "loss": 0.0043,
      "step": 12250
    },
    {
      "epoch": 4.596925384326959,
      "grad_norm": 0.02313566580414772,
      "learning_rate": 1.540307461567304e-05,
      "loss": 0.0063,
      "step": 12260
    },
    {
      "epoch": 4.600674915635546,
      "grad_norm": 0.0636688619852066,
      "learning_rate": 1.5399325084364456e-05,
      "loss": 0.0075,
      "step": 12270
    },
    {
      "epoch": 4.604424446944132,
      "grad_norm": 1.0042470693588257,
      "learning_rate": 1.539557555305587e-05,
      "loss": 0.0078,
      "step": 12280
    },
    {
      "epoch": 4.608173978252719,
      "grad_norm": 0.1804247796535492,
      "learning_rate": 1.539182602174728e-05,
      "loss": 0.0252,
      "step": 12290
    },
    {
      "epoch": 4.611923509561305,
      "grad_norm": 0.004841144196689129,
      "learning_rate": 1.5388076490438697e-05,
      "loss": 0.019,
      "step": 12300
    },
    {
      "epoch": 4.615673040869892,
      "grad_norm": 0.013151653110980988,
      "learning_rate": 1.538432695913011e-05,
      "loss": 0.0195,
      "step": 12310
    },
    {
      "epoch": 4.619422572178478,
      "grad_norm": 0.13261380791664124,
      "learning_rate": 1.5380577427821522e-05,
      "loss": 0.0239,
      "step": 12320
    },
    {
      "epoch": 4.6231721034870645,
      "grad_norm": 19.374629974365234,
      "learning_rate": 1.5376827896512938e-05,
      "loss": 0.0503,
      "step": 12330
    },
    {
      "epoch": 4.62692163479565,
      "grad_norm": 0.013942648656666279,
      "learning_rate": 1.537307836520435e-05,
      "loss": 0.0028,
      "step": 12340
    },
    {
      "epoch": 4.6306711661042375,
      "grad_norm": 0.8509348630905151,
      "learning_rate": 1.5369328833895763e-05,
      "loss": 0.0263,
      "step": 12350
    },
    {
      "epoch": 4.634420697412823,
      "grad_norm": 0.011040661484003067,
      "learning_rate": 1.5365579302587176e-05,
      "loss": 0.0372,
      "step": 12360
    },
    {
      "epoch": 4.6381702287214095,
      "grad_norm": 5.623086452484131,
      "learning_rate": 1.536182977127859e-05,
      "loss": 0.0272,
      "step": 12370
    },
    {
      "epoch": 4.641919760029996,
      "grad_norm": 0.02953656017780304,
      "learning_rate": 1.5358080239970007e-05,
      "loss": 0.0094,
      "step": 12380
    },
    {
      "epoch": 4.645669291338582,
      "grad_norm": 0.06759218871593475,
      "learning_rate": 1.5354330708661416e-05,
      "loss": 0.0154,
      "step": 12390
    },
    {
      "epoch": 4.649418822647169,
      "grad_norm": 0.1503991037607193,
      "learning_rate": 1.5350581177352832e-05,
      "loss": 0.0216,
      "step": 12400
    },
    {
      "epoch": 4.653168353955755,
      "grad_norm": 0.003423847956582904,
      "learning_rate": 1.5346831646044248e-05,
      "loss": 0.0258,
      "step": 12410
    },
    {
      "epoch": 4.656917885264342,
      "grad_norm": 4.6175312995910645,
      "learning_rate": 1.534308211473566e-05,
      "loss": 0.0309,
      "step": 12420
    },
    {
      "epoch": 4.660667416572928,
      "grad_norm": 0.8230020999908447,
      "learning_rate": 1.5339332583427073e-05,
      "loss": 0.015,
      "step": 12430
    },
    {
      "epoch": 4.664416947881515,
      "grad_norm": 0.010232069529592991,
      "learning_rate": 1.5335583052118486e-05,
      "loss": 0.0135,
      "step": 12440
    },
    {
      "epoch": 4.668166479190101,
      "grad_norm": 0.008898412808775902,
      "learning_rate": 1.53318335208099e-05,
      "loss": 0.0236,
      "step": 12450
    },
    {
      "epoch": 4.671916010498688,
      "grad_norm": 0.466204971075058,
      "learning_rate": 1.5328083989501314e-05,
      "loss": 0.0208,
      "step": 12460
    },
    {
      "epoch": 4.675665541807274,
      "grad_norm": 8.597558975219727,
      "learning_rate": 1.5324334458192726e-05,
      "loss": 0.0269,
      "step": 12470
    },
    {
      "epoch": 4.679415073115861,
      "grad_norm": 3.627833127975464,
      "learning_rate": 1.5320584926884142e-05,
      "loss": 0.0236,
      "step": 12480
    },
    {
      "epoch": 4.683164604424447,
      "grad_norm": 0.24275994300842285,
      "learning_rate": 1.5316835395575555e-05,
      "loss": 0.0363,
      "step": 12490
    },
    {
      "epoch": 4.6869141357330335,
      "grad_norm": 1.548966646194458,
      "learning_rate": 1.5313085864266967e-05,
      "loss": 0.0171,
      "step": 12500
    },
    {
      "epoch": 4.69066366704162,
      "grad_norm": 0.05616350471973419,
      "learning_rate": 1.5309336332958383e-05,
      "loss": 0.0128,
      "step": 12510
    },
    {
      "epoch": 4.694413198350206,
      "grad_norm": 1.4824532270431519,
      "learning_rate": 1.5305586801649796e-05,
      "loss": 0.0285,
      "step": 12520
    },
    {
      "epoch": 4.698162729658793,
      "grad_norm": 0.5011611580848694,
      "learning_rate": 1.5301837270341208e-05,
      "loss": 0.0262,
      "step": 12530
    },
    {
      "epoch": 4.701912260967379,
      "grad_norm": 1.6386839151382446,
      "learning_rate": 1.5298087739032624e-05,
      "loss": 0.0376,
      "step": 12540
    },
    {
      "epoch": 4.705661792275966,
      "grad_norm": 0.21181952953338623,
      "learning_rate": 1.5294338207724037e-05,
      "loss": 0.0197,
      "step": 12550
    },
    {
      "epoch": 4.709411323584552,
      "grad_norm": 0.03975534066557884,
      "learning_rate": 1.529058867641545e-05,
      "loss": 0.0078,
      "step": 12560
    },
    {
      "epoch": 4.713160854893139,
      "grad_norm": 0.0120535371825099,
      "learning_rate": 1.528683914510686e-05,
      "loss": 0.0255,
      "step": 12570
    },
    {
      "epoch": 4.716910386201725,
      "grad_norm": 1.5210504531860352,
      "learning_rate": 1.5283089613798277e-05,
      "loss": 0.0299,
      "step": 12580
    },
    {
      "epoch": 4.720659917510311,
      "grad_norm": 1.7164772748947144,
      "learning_rate": 1.527934008248969e-05,
      "loss": 0.0081,
      "step": 12590
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 0.23550517857074738,
      "learning_rate": 1.5275590551181102e-05,
      "loss": 0.0153,
      "step": 12600
    },
    {
      "epoch": 4.728158980127484,
      "grad_norm": 0.013386041857302189,
      "learning_rate": 1.527184101987252e-05,
      "loss": 0.0167,
      "step": 12610
    },
    {
      "epoch": 4.73190851143607,
      "grad_norm": 7.8982415199279785,
      "learning_rate": 1.526809148856393e-05,
      "loss": 0.0202,
      "step": 12620
    },
    {
      "epoch": 4.735658042744657,
      "grad_norm": 2.736389398574829,
      "learning_rate": 1.5264341957255343e-05,
      "loss": 0.0299,
      "step": 12630
    },
    {
      "epoch": 4.739407574053243,
      "grad_norm": 0.10283266752958298,
      "learning_rate": 1.526059242594676e-05,
      "loss": 0.0171,
      "step": 12640
    },
    {
      "epoch": 4.7431571053618296,
      "grad_norm": 1.3938806056976318,
      "learning_rate": 1.525684289463817e-05,
      "loss": 0.017,
      "step": 12650
    },
    {
      "epoch": 4.746906636670416,
      "grad_norm": 0.17966148257255554,
      "learning_rate": 1.5253093363329586e-05,
      "loss": 0.0178,
      "step": 12660
    },
    {
      "epoch": 4.7506561679790025,
      "grad_norm": 0.4109087884426117,
      "learning_rate": 1.5249343832021e-05,
      "loss": 0.0373,
      "step": 12670
    },
    {
      "epoch": 4.754405699287589,
      "grad_norm": 0.8570234179496765,
      "learning_rate": 1.5245594300712413e-05,
      "loss": 0.0065,
      "step": 12680
    },
    {
      "epoch": 4.758155230596175,
      "grad_norm": 0.08922678977251053,
      "learning_rate": 1.5241844769403827e-05,
      "loss": 0.0076,
      "step": 12690
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.14812439680099487,
      "learning_rate": 1.523809523809524e-05,
      "loss": 0.0108,
      "step": 12700
    },
    {
      "epoch": 4.765654293213348,
      "grad_norm": 2.1306912899017334,
      "learning_rate": 1.5234345706786653e-05,
      "loss": 0.0581,
      "step": 12710
    },
    {
      "epoch": 4.769403824521935,
      "grad_norm": 0.27150964736938477,
      "learning_rate": 1.5230596175478068e-05,
      "loss": 0.0112,
      "step": 12720
    },
    {
      "epoch": 4.773153355830521,
      "grad_norm": 0.17602132260799408,
      "learning_rate": 1.522684664416948e-05,
      "loss": 0.0123,
      "step": 12730
    },
    {
      "epoch": 4.776902887139108,
      "grad_norm": 2.088024377822876,
      "learning_rate": 1.5223097112860894e-05,
      "loss": 0.0125,
      "step": 12740
    },
    {
      "epoch": 4.780652418447694,
      "grad_norm": 0.23588934540748596,
      "learning_rate": 1.5219347581552307e-05,
      "loss": 0.0153,
      "step": 12750
    },
    {
      "epoch": 4.784401949756281,
      "grad_norm": 1.298888087272644,
      "learning_rate": 1.5215598050243721e-05,
      "loss": 0.0445,
      "step": 12760
    },
    {
      "epoch": 4.788151481064867,
      "grad_norm": 0.015511220321059227,
      "learning_rate": 1.5211848518935135e-05,
      "loss": 0.0186,
      "step": 12770
    },
    {
      "epoch": 4.791901012373454,
      "grad_norm": 0.42580530047416687,
      "learning_rate": 1.5208098987626548e-05,
      "loss": 0.0217,
      "step": 12780
    },
    {
      "epoch": 4.79565054368204,
      "grad_norm": 1.0497885942459106,
      "learning_rate": 1.5204349456317962e-05,
      "loss": 0.0245,
      "step": 12790
    },
    {
      "epoch": 4.7994000749906265,
      "grad_norm": 0.6544966697692871,
      "learning_rate": 1.5200599925009376e-05,
      "loss": 0.0283,
      "step": 12800
    },
    {
      "epoch": 4.803149606299213,
      "grad_norm": 0.03851072117686272,
      "learning_rate": 1.5196850393700789e-05,
      "loss": 0.0401,
      "step": 12810
    },
    {
      "epoch": 4.806899137607799,
      "grad_norm": 6.306578159332275,
      "learning_rate": 1.5193100862392203e-05,
      "loss": 0.038,
      "step": 12820
    },
    {
      "epoch": 4.810648668916386,
      "grad_norm": 0.009597331285476685,
      "learning_rate": 1.5189351331083615e-05,
      "loss": 0.0221,
      "step": 12830
    },
    {
      "epoch": 4.8143982002249714,
      "grad_norm": 0.36771127581596375,
      "learning_rate": 1.518560179977503e-05,
      "loss": 0.0168,
      "step": 12840
    },
    {
      "epoch": 4.818147731533559,
      "grad_norm": 1.8568766117095947,
      "learning_rate": 1.5181852268466444e-05,
      "loss": 0.0382,
      "step": 12850
    },
    {
      "epoch": 4.821897262842144,
      "grad_norm": 1.060158610343933,
      "learning_rate": 1.5178102737157856e-05,
      "loss": 0.0168,
      "step": 12860
    },
    {
      "epoch": 4.825646794150731,
      "grad_norm": 0.0236787311732769,
      "learning_rate": 1.517435320584927e-05,
      "loss": 0.021,
      "step": 12870
    },
    {
      "epoch": 4.829396325459317,
      "grad_norm": 0.024859542027115822,
      "learning_rate": 1.5170603674540683e-05,
      "loss": 0.0339,
      "step": 12880
    },
    {
      "epoch": 4.833145856767904,
      "grad_norm": 7.758992671966553,
      "learning_rate": 1.5166854143232097e-05,
      "loss": 0.0559,
      "step": 12890
    },
    {
      "epoch": 4.83689538807649,
      "grad_norm": 0.5401000380516052,
      "learning_rate": 1.5163104611923511e-05,
      "loss": 0.0116,
      "step": 12900
    },
    {
      "epoch": 4.840644919385077,
      "grad_norm": 0.01377671305090189,
      "learning_rate": 1.5159355080614924e-05,
      "loss": 0.01,
      "step": 12910
    },
    {
      "epoch": 4.844394450693663,
      "grad_norm": 13.621747016906738,
      "learning_rate": 1.5155605549306338e-05,
      "loss": 0.0414,
      "step": 12920
    },
    {
      "epoch": 4.84814398200225,
      "grad_norm": 0.01900269091129303,
      "learning_rate": 1.5151856017997752e-05,
      "loss": 0.0243,
      "step": 12930
    },
    {
      "epoch": 4.851893513310836,
      "grad_norm": 1.0477056503295898,
      "learning_rate": 1.5148106486689165e-05,
      "loss": 0.0295,
      "step": 12940
    },
    {
      "epoch": 4.8556430446194225,
      "grad_norm": 0.8748095631599426,
      "learning_rate": 1.5144356955380579e-05,
      "loss": 0.0134,
      "step": 12950
    },
    {
      "epoch": 4.859392575928009,
      "grad_norm": 0.21882420778274536,
      "learning_rate": 1.5140607424071991e-05,
      "loss": 0.0554,
      "step": 12960
    },
    {
      "epoch": 4.8631421072365955,
      "grad_norm": 0.011421062983572483,
      "learning_rate": 1.5136857892763405e-05,
      "loss": 0.0128,
      "step": 12970
    },
    {
      "epoch": 4.866891638545182,
      "grad_norm": 0.006767802406102419,
      "learning_rate": 1.513310836145482e-05,
      "loss": 0.0137,
      "step": 12980
    },
    {
      "epoch": 4.870641169853768,
      "grad_norm": 0.1953733265399933,
      "learning_rate": 1.5129358830146232e-05,
      "loss": 0.0469,
      "step": 12990
    },
    {
      "epoch": 4.874390701162355,
      "grad_norm": 0.13886912167072296,
      "learning_rate": 1.5125609298837646e-05,
      "loss": 0.0226,
      "step": 13000
    },
    {
      "epoch": 4.878140232470941,
      "grad_norm": 0.06488275527954102,
      "learning_rate": 1.5121859767529059e-05,
      "loss": 0.0327,
      "step": 13010
    },
    {
      "epoch": 4.881889763779528,
      "grad_norm": 1.5924482345581055,
      "learning_rate": 1.5118110236220473e-05,
      "loss": 0.0319,
      "step": 13020
    },
    {
      "epoch": 4.885639295088114,
      "grad_norm": 18.417142868041992,
      "learning_rate": 1.5114360704911887e-05,
      "loss": 0.0259,
      "step": 13030
    },
    {
      "epoch": 4.889388826396701,
      "grad_norm": 0.02093925140798092,
      "learning_rate": 1.51106111736033e-05,
      "loss": 0.0212,
      "step": 13040
    },
    {
      "epoch": 4.893138357705287,
      "grad_norm": 0.013322095386683941,
      "learning_rate": 1.5106861642294714e-05,
      "loss": 0.0224,
      "step": 13050
    },
    {
      "epoch": 4.896887889013874,
      "grad_norm": 1.5246922969818115,
      "learning_rate": 1.510311211098613e-05,
      "loss": 0.0552,
      "step": 13060
    },
    {
      "epoch": 4.90063742032246,
      "grad_norm": 2.3251864910125732,
      "learning_rate": 1.509936257967754e-05,
      "loss": 0.0162,
      "step": 13070
    },
    {
      "epoch": 4.9043869516310465,
      "grad_norm": 0.19092795252799988,
      "learning_rate": 1.5095613048368956e-05,
      "loss": 0.0252,
      "step": 13080
    },
    {
      "epoch": 4.908136482939632,
      "grad_norm": 1.5522682666778564,
      "learning_rate": 1.5091863517060367e-05,
      "loss": 0.0343,
      "step": 13090
    },
    {
      "epoch": 4.9118860142482195,
      "grad_norm": 0.8286580443382263,
      "learning_rate": 1.5088113985751781e-05,
      "loss": 0.0374,
      "step": 13100
    },
    {
      "epoch": 4.915635545556805,
      "grad_norm": 1.0589903593063354,
      "learning_rate": 1.5084364454443197e-05,
      "loss": 0.0171,
      "step": 13110
    },
    {
      "epoch": 4.9193850768653915,
      "grad_norm": 0.044056568294763565,
      "learning_rate": 1.5080614923134608e-05,
      "loss": 0.0267,
      "step": 13120
    },
    {
      "epoch": 4.923134608173978,
      "grad_norm": 0.5045660734176636,
      "learning_rate": 1.5076865391826024e-05,
      "loss": 0.0063,
      "step": 13130
    },
    {
      "epoch": 4.926884139482564,
      "grad_norm": 0.03869073837995529,
      "learning_rate": 1.5073115860517435e-05,
      "loss": 0.0153,
      "step": 13140
    },
    {
      "epoch": 4.930633670791151,
      "grad_norm": 0.004615373443812132,
      "learning_rate": 1.506936632920885e-05,
      "loss": 0.0195,
      "step": 13150
    },
    {
      "epoch": 4.934383202099737,
      "grad_norm": 24.18392562866211,
      "learning_rate": 1.5065616797900265e-05,
      "loss": 0.0107,
      "step": 13160
    },
    {
      "epoch": 4.938132733408324,
      "grad_norm": 0.0387667678296566,
      "learning_rate": 1.5061867266591677e-05,
      "loss": 0.0082,
      "step": 13170
    },
    {
      "epoch": 4.94188226471691,
      "grad_norm": 0.007488748524338007,
      "learning_rate": 1.5058117735283091e-05,
      "loss": 0.0211,
      "step": 13180
    },
    {
      "epoch": 4.945631796025497,
      "grad_norm": 4.192272186279297,
      "learning_rate": 1.5054368203974506e-05,
      "loss": 0.0422,
      "step": 13190
    },
    {
      "epoch": 4.949381327334083,
      "grad_norm": 0.44730058312416077,
      "learning_rate": 1.5050618672665918e-05,
      "loss": 0.0331,
      "step": 13200
    },
    {
      "epoch": 4.95313085864267,
      "grad_norm": 0.029542716220021248,
      "learning_rate": 1.5046869141357332e-05,
      "loss": 0.0461,
      "step": 13210
    },
    {
      "epoch": 4.956880389951256,
      "grad_norm": 0.09376765042543411,
      "learning_rate": 1.5043119610048745e-05,
      "loss": 0.0109,
      "step": 13220
    },
    {
      "epoch": 4.960629921259843,
      "grad_norm": 0.26645994186401367,
      "learning_rate": 1.5039370078740159e-05,
      "loss": 0.0116,
      "step": 13230
    },
    {
      "epoch": 4.964379452568429,
      "grad_norm": 0.4125417172908783,
      "learning_rate": 1.5035620547431573e-05,
      "loss": 0.0226,
      "step": 13240
    },
    {
      "epoch": 4.9681289838770155,
      "grad_norm": 2.3100550174713135,
      "learning_rate": 1.5031871016122986e-05,
      "loss": 0.026,
      "step": 13250
    },
    {
      "epoch": 4.971878515185602,
      "grad_norm": 0.08529271930456161,
      "learning_rate": 1.50281214848144e-05,
      "loss": 0.0074,
      "step": 13260
    },
    {
      "epoch": 4.975628046494188,
      "grad_norm": 3.1015732288360596,
      "learning_rate": 1.5024371953505812e-05,
      "loss": 0.0589,
      "step": 13270
    },
    {
      "epoch": 4.979377577802775,
      "grad_norm": 3.577399253845215,
      "learning_rate": 1.5020622422197227e-05,
      "loss": 0.0401,
      "step": 13280
    },
    {
      "epoch": 4.983127109111361,
      "grad_norm": 0.6692865490913391,
      "learning_rate": 1.501687289088864e-05,
      "loss": 0.0262,
      "step": 13290
    },
    {
      "epoch": 4.986876640419948,
      "grad_norm": 7.365094184875488,
      "learning_rate": 1.5013123359580053e-05,
      "loss": 0.0476,
      "step": 13300
    },
    {
      "epoch": 4.990626171728534,
      "grad_norm": 0.438286155462265,
      "learning_rate": 1.5009373828271467e-05,
      "loss": 0.0262,
      "step": 13310
    },
    {
      "epoch": 4.99437570303712,
      "grad_norm": 2.127068281173706,
      "learning_rate": 1.5005624296962882e-05,
      "loss": 0.0244,
      "step": 13320
    },
    {
      "epoch": 4.998125234345707,
      "grad_norm": 0.01779269613325596,
      "learning_rate": 1.5001874765654294e-05,
      "loss": 0.03,
      "step": 13330
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.990485564304462,
      "eval_f1": 0.963623693379791,
      "eval_loss": 0.03085637092590332,
      "eval_precision": 0.9555002763957988,
      "eval_recall": 0.9718864211414113,
      "eval_runtime": 914.404,
      "eval_samples_per_second": 30.001,
      "eval_steps_per_second": 1.251,
      "step": 13335
    },
    {
      "epoch": 5.001874765654293,
      "grad_norm": 0.034813448786735535,
      "learning_rate": 1.4998125234345708e-05,
      "loss": 0.0268,
      "step": 13340
    },
    {
      "epoch": 5.005624296962879,
      "grad_norm": 0.04984620213508606,
      "learning_rate": 1.499437570303712e-05,
      "loss": 0.0061,
      "step": 13350
    },
    {
      "epoch": 5.009373828271466,
      "grad_norm": 25.04831314086914,
      "learning_rate": 1.4990626171728535e-05,
      "loss": 0.0446,
      "step": 13360
    },
    {
      "epoch": 5.013123359580052,
      "grad_norm": 0.014629258774220943,
      "learning_rate": 1.498687664041995e-05,
      "loss": 0.0427,
      "step": 13370
    },
    {
      "epoch": 5.016872890888639,
      "grad_norm": 4.407782554626465,
      "learning_rate": 1.4983127109111362e-05,
      "loss": 0.053,
      "step": 13380
    },
    {
      "epoch": 5.020622422197225,
      "grad_norm": 0.3611542880535126,
      "learning_rate": 1.4979377577802776e-05,
      "loss": 0.003,
      "step": 13390
    },
    {
      "epoch": 5.024371953505812,
      "grad_norm": 0.5243575572967529,
      "learning_rate": 1.497562804649419e-05,
      "loss": 0.0032,
      "step": 13400
    },
    {
      "epoch": 5.028121484814398,
      "grad_norm": 0.023173905909061432,
      "learning_rate": 1.4971878515185603e-05,
      "loss": 0.041,
      "step": 13410
    },
    {
      "epoch": 5.0318710161229845,
      "grad_norm": 0.04003001004457474,
      "learning_rate": 1.4968128983877017e-05,
      "loss": 0.0496,
      "step": 13420
    },
    {
      "epoch": 5.035620547431571,
      "grad_norm": 7.470524311065674,
      "learning_rate": 1.496437945256843e-05,
      "loss": 0.0339,
      "step": 13430
    },
    {
      "epoch": 5.039370078740157,
      "grad_norm": 0.11393797397613525,
      "learning_rate": 1.4960629921259843e-05,
      "loss": 0.0375,
      "step": 13440
    },
    {
      "epoch": 5.043119610048744,
      "grad_norm": 0.15601414442062378,
      "learning_rate": 1.4956880389951258e-05,
      "loss": 0.0415,
      "step": 13450
    },
    {
      "epoch": 5.04686914135733,
      "grad_norm": 1.2690740823745728,
      "learning_rate": 1.495313085864267e-05,
      "loss": 0.0105,
      "step": 13460
    },
    {
      "epoch": 5.050618672665917,
      "grad_norm": 1.1527179479599,
      "learning_rate": 1.4949381327334084e-05,
      "loss": 0.0249,
      "step": 13470
    },
    {
      "epoch": 5.054368203974503,
      "grad_norm": 0.9341403245925903,
      "learning_rate": 1.4945631796025497e-05,
      "loss": 0.0118,
      "step": 13480
    },
    {
      "epoch": 5.05811773528309,
      "grad_norm": 0.8282168507575989,
      "learning_rate": 1.4941882264716911e-05,
      "loss": 0.0471,
      "step": 13490
    },
    {
      "epoch": 5.061867266591676,
      "grad_norm": 0.7168505787849426,
      "learning_rate": 1.4938132733408325e-05,
      "loss": 0.0192,
      "step": 13500
    },
    {
      "epoch": 5.065616797900263,
      "grad_norm": 2.4468400478363037,
      "learning_rate": 1.4934383202099738e-05,
      "loss": 0.0232,
      "step": 13510
    },
    {
      "epoch": 5.069366329208849,
      "grad_norm": 0.12381280213594437,
      "learning_rate": 1.4930633670791152e-05,
      "loss": 0.0133,
      "step": 13520
    },
    {
      "epoch": 5.073115860517436,
      "grad_norm": 0.5096615552902222,
      "learning_rate": 1.4926884139482568e-05,
      "loss": 0.0048,
      "step": 13530
    },
    {
      "epoch": 5.076865391826022,
      "grad_norm": 11.449788093566895,
      "learning_rate": 1.4923134608173979e-05,
      "loss": 0.0367,
      "step": 13540
    },
    {
      "epoch": 5.0806149231346085,
      "grad_norm": 0.7913252115249634,
      "learning_rate": 1.4919385076865394e-05,
      "loss": 0.0205,
      "step": 13550
    },
    {
      "epoch": 5.084364454443195,
      "grad_norm": 0.08892446011304855,
      "learning_rate": 1.4915635545556805e-05,
      "loss": 0.0145,
      "step": 13560
    },
    {
      "epoch": 5.088113985751781,
      "grad_norm": 0.13905955851078033,
      "learning_rate": 1.4911886014248221e-05,
      "loss": 0.0175,
      "step": 13570
    },
    {
      "epoch": 5.091863517060368,
      "grad_norm": 0.15916237235069275,
      "learning_rate": 1.4908136482939635e-05,
      "loss": 0.0047,
      "step": 13580
    },
    {
      "epoch": 5.0956130483689535,
      "grad_norm": 1.7041095495224,
      "learning_rate": 1.4904386951631046e-05,
      "loss": 0.0199,
      "step": 13590
    },
    {
      "epoch": 5.09936257967754,
      "grad_norm": 0.0437425933778286,
      "learning_rate": 1.4900637420322462e-05,
      "loss": 0.0247,
      "step": 13600
    },
    {
      "epoch": 5.103112110986126,
      "grad_norm": 8.845259666442871,
      "learning_rate": 1.4896887889013873e-05,
      "loss": 0.0147,
      "step": 13610
    },
    {
      "epoch": 5.106861642294713,
      "grad_norm": 0.07963218539953232,
      "learning_rate": 1.4893138357705289e-05,
      "loss": 0.0244,
      "step": 13620
    },
    {
      "epoch": 5.110611173603299,
      "grad_norm": 2.586998224258423,
      "learning_rate": 1.4889388826396703e-05,
      "loss": 0.0212,
      "step": 13630
    },
    {
      "epoch": 5.114360704911886,
      "grad_norm": 0.08083276450634003,
      "learning_rate": 1.4885639295088115e-05,
      "loss": 0.0212,
      "step": 13640
    },
    {
      "epoch": 5.118110236220472,
      "grad_norm": 0.629902720451355,
      "learning_rate": 1.488188976377953e-05,
      "loss": 0.0073,
      "step": 13650
    },
    {
      "epoch": 5.121859767529059,
      "grad_norm": 0.8893008828163147,
      "learning_rate": 1.4878140232470944e-05,
      "loss": 0.0093,
      "step": 13660
    },
    {
      "epoch": 5.125609298837645,
      "grad_norm": 0.06882794201374054,
      "learning_rate": 1.4874390701162356e-05,
      "loss": 0.0023,
      "step": 13670
    },
    {
      "epoch": 5.129358830146232,
      "grad_norm": 1.2438327074050903,
      "learning_rate": 1.487064116985377e-05,
      "loss": 0.0353,
      "step": 13680
    },
    {
      "epoch": 5.133108361454818,
      "grad_norm": 0.00996406003832817,
      "learning_rate": 1.4866891638545183e-05,
      "loss": 0.0248,
      "step": 13690
    },
    {
      "epoch": 5.1368578927634045,
      "grad_norm": 0.004762423224747181,
      "learning_rate": 1.4863142107236597e-05,
      "loss": 0.0093,
      "step": 13700
    },
    {
      "epoch": 5.140607424071991,
      "grad_norm": 0.03025735355913639,
      "learning_rate": 1.4859392575928011e-05,
      "loss": 0.0122,
      "step": 13710
    },
    {
      "epoch": 5.1443569553805775,
      "grad_norm": 0.39289426803588867,
      "learning_rate": 1.4855643044619424e-05,
      "loss": 0.0187,
      "step": 13720
    },
    {
      "epoch": 5.148106486689164,
      "grad_norm": 0.49615412950515747,
      "learning_rate": 1.4851893513310838e-05,
      "loss": 0.011,
      "step": 13730
    },
    {
      "epoch": 5.15185601799775,
      "grad_norm": 0.023411598056554794,
      "learning_rate": 1.484814398200225e-05,
      "loss": 0.0158,
      "step": 13740
    },
    {
      "epoch": 5.155605549306337,
      "grad_norm": 0.05239125341176987,
      "learning_rate": 1.4844394450693665e-05,
      "loss": 0.0352,
      "step": 13750
    },
    {
      "epoch": 5.159355080614923,
      "grad_norm": 0.9356235265731812,
      "learning_rate": 1.4840644919385079e-05,
      "loss": 0.0178,
      "step": 13760
    },
    {
      "epoch": 5.16310461192351,
      "grad_norm": 1.8152894973754883,
      "learning_rate": 1.4836895388076491e-05,
      "loss": 0.0159,
      "step": 13770
    },
    {
      "epoch": 5.166854143232096,
      "grad_norm": 25.52716827392578,
      "learning_rate": 1.4833145856767905e-05,
      "loss": 0.0146,
      "step": 13780
    },
    {
      "epoch": 5.170603674540683,
      "grad_norm": 8.643040657043457,
      "learning_rate": 1.482939632545932e-05,
      "loss": 0.02,
      "step": 13790
    },
    {
      "epoch": 5.174353205849269,
      "grad_norm": 0.0237903892993927,
      "learning_rate": 1.4825646794150732e-05,
      "loss": 0.0061,
      "step": 13800
    },
    {
      "epoch": 5.178102737157856,
      "grad_norm": 0.6115960478782654,
      "learning_rate": 1.4821897262842146e-05,
      "loss": 0.0198,
      "step": 13810
    },
    {
      "epoch": 5.181852268466442,
      "grad_norm": 0.001680795568972826,
      "learning_rate": 1.4818147731533559e-05,
      "loss": 0.013,
      "step": 13820
    },
    {
      "epoch": 5.1856017997750286,
      "grad_norm": 4.94997501373291,
      "learning_rate": 1.4814398200224973e-05,
      "loss": 0.0303,
      "step": 13830
    },
    {
      "epoch": 5.189351331083614,
      "grad_norm": 2.62821626663208,
      "learning_rate": 1.4810648668916387e-05,
      "loss": 0.0333,
      "step": 13840
    },
    {
      "epoch": 5.193100862392201,
      "grad_norm": 0.5318862795829773,
      "learning_rate": 1.48068991376078e-05,
      "loss": 0.0291,
      "step": 13850
    },
    {
      "epoch": 5.196850393700787,
      "grad_norm": 0.22633495926856995,
      "learning_rate": 1.4803149606299214e-05,
      "loss": 0.0195,
      "step": 13860
    },
    {
      "epoch": 5.2005999250093735,
      "grad_norm": 0.9959431290626526,
      "learning_rate": 1.4799400074990626e-05,
      "loss": 0.0141,
      "step": 13870
    },
    {
      "epoch": 5.20434945631796,
      "grad_norm": 0.8274542093276978,
      "learning_rate": 1.479565054368204e-05,
      "loss": 0.0103,
      "step": 13880
    },
    {
      "epoch": 5.208098987626546,
      "grad_norm": 1.019882321357727,
      "learning_rate": 1.4791901012373455e-05,
      "loss": 0.0168,
      "step": 13890
    },
    {
      "epoch": 5.211848518935133,
      "grad_norm": 2.2940080165863037,
      "learning_rate": 1.4788151481064867e-05,
      "loss": 0.0103,
      "step": 13900
    },
    {
      "epoch": 5.215598050243719,
      "grad_norm": 2.868851661682129,
      "learning_rate": 1.4784401949756281e-05,
      "loss": 0.0265,
      "step": 13910
    },
    {
      "epoch": 5.219347581552306,
      "grad_norm": 0.14862744510173798,
      "learning_rate": 1.4780652418447696e-05,
      "loss": 0.0091,
      "step": 13920
    },
    {
      "epoch": 5.223097112860892,
      "grad_norm": 1.8680425882339478,
      "learning_rate": 1.4776902887139108e-05,
      "loss": 0.0124,
      "step": 13930
    },
    {
      "epoch": 5.226846644169479,
      "grad_norm": 0.04335465282201767,
      "learning_rate": 1.4773153355830522e-05,
      "loss": 0.0087,
      "step": 13940
    },
    {
      "epoch": 5.230596175478065,
      "grad_norm": 0.737289547920227,
      "learning_rate": 1.4769403824521935e-05,
      "loss": 0.049,
      "step": 13950
    },
    {
      "epoch": 5.234345706786652,
      "grad_norm": 0.12846936285495758,
      "learning_rate": 1.4765654293213349e-05,
      "loss": 0.0178,
      "step": 13960
    },
    {
      "epoch": 5.238095238095238,
      "grad_norm": 0.15224730968475342,
      "learning_rate": 1.4761904761904763e-05,
      "loss": 0.0116,
      "step": 13970
    },
    {
      "epoch": 5.241844769403825,
      "grad_norm": 0.01150191854685545,
      "learning_rate": 1.4758155230596176e-05,
      "loss": 0.0036,
      "step": 13980
    },
    {
      "epoch": 5.245594300712411,
      "grad_norm": 3.412137985229492,
      "learning_rate": 1.475440569928759e-05,
      "loss": 0.0404,
      "step": 13990
    },
    {
      "epoch": 5.2493438320209975,
      "grad_norm": 0.19285829365253448,
      "learning_rate": 1.4750656167979002e-05,
      "loss": 0.0178,
      "step": 14000
    },
    {
      "epoch": 5.253093363329584,
      "grad_norm": 0.33547961711883545,
      "learning_rate": 1.4746906636670417e-05,
      "loss": 0.0202,
      "step": 14010
    },
    {
      "epoch": 5.2568428946381704,
      "grad_norm": 3.628981351852417,
      "learning_rate": 1.4743157105361832e-05,
      "loss": 0.0203,
      "step": 14020
    },
    {
      "epoch": 5.260592425946757,
      "grad_norm": 0.4223959743976593,
      "learning_rate": 1.4739407574053243e-05,
      "loss": 0.0226,
      "step": 14030
    },
    {
      "epoch": 5.264341957255343,
      "grad_norm": 5.443716049194336,
      "learning_rate": 1.4735658042744659e-05,
      "loss": 0.0291,
      "step": 14040
    },
    {
      "epoch": 5.26809148856393,
      "grad_norm": 6.436868190765381,
      "learning_rate": 1.4731908511436073e-05,
      "loss": 0.0312,
      "step": 14050
    },
    {
      "epoch": 5.271841019872516,
      "grad_norm": 0.056587617844343185,
      "learning_rate": 1.4728158980127484e-05,
      "loss": 0.0089,
      "step": 14060
    },
    {
      "epoch": 5.275590551181103,
      "grad_norm": 12.9736909866333,
      "learning_rate": 1.47244094488189e-05,
      "loss": 0.0268,
      "step": 14070
    },
    {
      "epoch": 5.279340082489689,
      "grad_norm": 0.009352248162031174,
      "learning_rate": 1.472065991751031e-05,
      "loss": 0.0101,
      "step": 14080
    },
    {
      "epoch": 5.283089613798275,
      "grad_norm": 0.1878531277179718,
      "learning_rate": 1.4716910386201727e-05,
      "loss": 0.0214,
      "step": 14090
    },
    {
      "epoch": 5.286839145106861,
      "grad_norm": 0.019107436761260033,
      "learning_rate": 1.4713160854893141e-05,
      "loss": 0.0133,
      "step": 14100
    },
    {
      "epoch": 5.290588676415448,
      "grad_norm": 0.013555221259593964,
      "learning_rate": 1.4709411323584553e-05,
      "loss": 0.0079,
      "step": 14110
    },
    {
      "epoch": 5.294338207724034,
      "grad_norm": 0.02103833109140396,
      "learning_rate": 1.4705661792275968e-05,
      "loss": 0.012,
      "step": 14120
    },
    {
      "epoch": 5.298087739032621,
      "grad_norm": 0.0030236749444156885,
      "learning_rate": 1.470191226096738e-05,
      "loss": 0.0205,
      "step": 14130
    },
    {
      "epoch": 5.301837270341207,
      "grad_norm": 0.3448358476161957,
      "learning_rate": 1.4698162729658794e-05,
      "loss": 0.0058,
      "step": 14140
    },
    {
      "epoch": 5.305586801649794,
      "grad_norm": 1.8767378330230713,
      "learning_rate": 1.4694413198350208e-05,
      "loss": 0.0352,
      "step": 14150
    },
    {
      "epoch": 5.30933633295838,
      "grad_norm": 0.0549495592713356,
      "learning_rate": 1.4690663667041621e-05,
      "loss": 0.0203,
      "step": 14160
    },
    {
      "epoch": 5.3130858642669665,
      "grad_norm": 3.2984654903411865,
      "learning_rate": 1.4686914135733035e-05,
      "loss": 0.0198,
      "step": 14170
    },
    {
      "epoch": 5.316835395575553,
      "grad_norm": 1.2286269664764404,
      "learning_rate": 1.468316460442445e-05,
      "loss": 0.0353,
      "step": 14180
    },
    {
      "epoch": 5.320584926884139,
      "grad_norm": 0.052651967853307724,
      "learning_rate": 1.4679415073115862e-05,
      "loss": 0.0071,
      "step": 14190
    },
    {
      "epoch": 5.324334458192726,
      "grad_norm": 2.419288396835327,
      "learning_rate": 1.4675665541807276e-05,
      "loss": 0.0166,
      "step": 14200
    },
    {
      "epoch": 5.328083989501312,
      "grad_norm": 3.898296594619751,
      "learning_rate": 1.4671916010498688e-05,
      "loss": 0.0437,
      "step": 14210
    },
    {
      "epoch": 5.331833520809899,
      "grad_norm": 0.07910922914743423,
      "learning_rate": 1.4668166479190103e-05,
      "loss": 0.0232,
      "step": 14220
    },
    {
      "epoch": 5.335583052118485,
      "grad_norm": 0.5469794869422913,
      "learning_rate": 1.4664416947881517e-05,
      "loss": 0.0075,
      "step": 14230
    },
    {
      "epoch": 5.339332583427072,
      "grad_norm": 2.2389211654663086,
      "learning_rate": 1.466066741657293e-05,
      "loss": 0.0215,
      "step": 14240
    },
    {
      "epoch": 5.343082114735658,
      "grad_norm": 0.8025185465812683,
      "learning_rate": 1.4656917885264344e-05,
      "loss": 0.0275,
      "step": 14250
    },
    {
      "epoch": 5.346831646044245,
      "grad_norm": 0.07773863524198532,
      "learning_rate": 1.4653168353955756e-05,
      "loss": 0.0248,
      "step": 14260
    },
    {
      "epoch": 5.350581177352831,
      "grad_norm": 0.015364906750619411,
      "learning_rate": 1.464941882264717e-05,
      "loss": 0.0137,
      "step": 14270
    },
    {
      "epoch": 5.354330708661418,
      "grad_norm": 0.01872565783560276,
      "learning_rate": 1.4645669291338584e-05,
      "loss": 0.0089,
      "step": 14280
    },
    {
      "epoch": 5.358080239970004,
      "grad_norm": 0.019541677087545395,
      "learning_rate": 1.4641919760029997e-05,
      "loss": 0.0571,
      "step": 14290
    },
    {
      "epoch": 5.3618297712785905,
      "grad_norm": 0.026729371398687363,
      "learning_rate": 1.4638170228721411e-05,
      "loss": 0.0112,
      "step": 14300
    },
    {
      "epoch": 5.365579302587177,
      "grad_norm": 0.03130783140659332,
      "learning_rate": 1.4634420697412825e-05,
      "loss": 0.0136,
      "step": 14310
    },
    {
      "epoch": 5.369328833895763,
      "grad_norm": 0.33941322565078735,
      "learning_rate": 1.4630671166104238e-05,
      "loss": 0.0318,
      "step": 14320
    },
    {
      "epoch": 5.37307836520435,
      "grad_norm": 0.06906945258378983,
      "learning_rate": 1.4626921634795652e-05,
      "loss": 0.0298,
      "step": 14330
    },
    {
      "epoch": 5.3768278965129355,
      "grad_norm": 2.6183383464813232,
      "learning_rate": 1.4623172103487064e-05,
      "loss": 0.0274,
      "step": 14340
    },
    {
      "epoch": 5.380577427821522,
      "grad_norm": 0.6826265454292297,
      "learning_rate": 1.4619422572178479e-05,
      "loss": 0.0292,
      "step": 14350
    },
    {
      "epoch": 5.384326959130108,
      "grad_norm": 0.017026495188474655,
      "learning_rate": 1.4615673040869893e-05,
      "loss": 0.0076,
      "step": 14360
    },
    {
      "epoch": 5.388076490438695,
      "grad_norm": 0.21600022912025452,
      "learning_rate": 1.4611923509561305e-05,
      "loss": 0.0116,
      "step": 14370
    },
    {
      "epoch": 5.391826021747281,
      "grad_norm": 0.007540410850197077,
      "learning_rate": 1.460817397825272e-05,
      "loss": 0.0108,
      "step": 14380
    },
    {
      "epoch": 5.395575553055868,
      "grad_norm": 0.009699789807200432,
      "learning_rate": 1.4604424446944132e-05,
      "loss": 0.0083,
      "step": 14390
    },
    {
      "epoch": 5.399325084364454,
      "grad_norm": 1.2054321765899658,
      "learning_rate": 1.4600674915635546e-05,
      "loss": 0.0131,
      "step": 14400
    },
    {
      "epoch": 5.403074615673041,
      "grad_norm": 1.3461366891860962,
      "learning_rate": 1.459692538432696e-05,
      "loss": 0.0114,
      "step": 14410
    },
    {
      "epoch": 5.406824146981627,
      "grad_norm": 0.025568079203367233,
      "learning_rate": 1.4593175853018373e-05,
      "loss": 0.0331,
      "step": 14420
    },
    {
      "epoch": 5.410573678290214,
      "grad_norm": 0.008471246808767319,
      "learning_rate": 1.4589426321709787e-05,
      "loss": 0.0091,
      "step": 14430
    },
    {
      "epoch": 5.4143232095988,
      "grad_norm": 0.008370083756744862,
      "learning_rate": 1.4585676790401201e-05,
      "loss": 0.0232,
      "step": 14440
    },
    {
      "epoch": 5.4180727409073866,
      "grad_norm": 0.2120242416858673,
      "learning_rate": 1.4581927259092614e-05,
      "loss": 0.0026,
      "step": 14450
    },
    {
      "epoch": 5.421822272215973,
      "grad_norm": 0.01205180399119854,
      "learning_rate": 1.4578177727784028e-05,
      "loss": 0.0214,
      "step": 14460
    },
    {
      "epoch": 5.4255718035245595,
      "grad_norm": 4.840353488922119,
      "learning_rate": 1.457442819647544e-05,
      "loss": 0.022,
      "step": 14470
    },
    {
      "epoch": 5.429321334833146,
      "grad_norm": 0.023044191300868988,
      "learning_rate": 1.4570678665166855e-05,
      "loss": 0.0099,
      "step": 14480
    },
    {
      "epoch": 5.433070866141732,
      "grad_norm": 0.03231317922472954,
      "learning_rate": 1.456692913385827e-05,
      "loss": 0.0045,
      "step": 14490
    },
    {
      "epoch": 5.436820397450319,
      "grad_norm": 4.903918266296387,
      "learning_rate": 1.4563179602549681e-05,
      "loss": 0.0379,
      "step": 14500
    },
    {
      "epoch": 5.440569928758905,
      "grad_norm": 0.0050585283897817135,
      "learning_rate": 1.4559430071241097e-05,
      "loss": 0.0094,
      "step": 14510
    },
    {
      "epoch": 5.444319460067492,
      "grad_norm": 4.713932037353516,
      "learning_rate": 1.4555680539932511e-05,
      "loss": 0.0415,
      "step": 14520
    },
    {
      "epoch": 5.448068991376078,
      "grad_norm": 2.379009485244751,
      "learning_rate": 1.4551931008623922e-05,
      "loss": 0.0165,
      "step": 14530
    },
    {
      "epoch": 5.451818522684665,
      "grad_norm": 0.2648187577724457,
      "learning_rate": 1.4548181477315338e-05,
      "loss": 0.0228,
      "step": 14540
    },
    {
      "epoch": 5.455568053993251,
      "grad_norm": 3.402082681655884,
      "learning_rate": 1.4544431946006749e-05,
      "loss": 0.037,
      "step": 14550
    },
    {
      "epoch": 5.459317585301838,
      "grad_norm": 1.3216408491134644,
      "learning_rate": 1.4540682414698165e-05,
      "loss": 0.0178,
      "step": 14560
    },
    {
      "epoch": 5.463067116610424,
      "grad_norm": 0.45158126950263977,
      "learning_rate": 1.4536932883389579e-05,
      "loss": 0.0069,
      "step": 14570
    },
    {
      "epoch": 5.466816647919011,
      "grad_norm": 0.07024020701646805,
      "learning_rate": 1.4533183352080991e-05,
      "loss": 0.0144,
      "step": 14580
    },
    {
      "epoch": 5.470566179227596,
      "grad_norm": 8.166516304016113,
      "learning_rate": 1.4529433820772406e-05,
      "loss": 0.0055,
      "step": 14590
    },
    {
      "epoch": 5.474315710536183,
      "grad_norm": 1.295185923576355,
      "learning_rate": 1.4525684289463818e-05,
      "loss": 0.0214,
      "step": 14600
    },
    {
      "epoch": 5.478065241844769,
      "grad_norm": 0.2679188549518585,
      "learning_rate": 1.4521934758155232e-05,
      "loss": 0.0345,
      "step": 14610
    },
    {
      "epoch": 5.4818147731533555,
      "grad_norm": 0.002839308464899659,
      "learning_rate": 1.4518185226846646e-05,
      "loss": 0.003,
      "step": 14620
    },
    {
      "epoch": 5.485564304461942,
      "grad_norm": 0.009135628119111061,
      "learning_rate": 1.4514435695538059e-05,
      "loss": 0.0285,
      "step": 14630
    },
    {
      "epoch": 5.4893138357705284,
      "grad_norm": 0.12225618213415146,
      "learning_rate": 1.4510686164229473e-05,
      "loss": 0.0519,
      "step": 14640
    },
    {
      "epoch": 5.493063367079115,
      "grad_norm": 3.8078198432922363,
      "learning_rate": 1.4506936632920887e-05,
      "loss": 0.0309,
      "step": 14650
    },
    {
      "epoch": 5.496812898387701,
      "grad_norm": 0.08614250272512436,
      "learning_rate": 1.45031871016123e-05,
      "loss": 0.042,
      "step": 14660
    },
    {
      "epoch": 5.500562429696288,
      "grad_norm": 2.7379279136657715,
      "learning_rate": 1.4499437570303714e-05,
      "loss": 0.048,
      "step": 14670
    },
    {
      "epoch": 5.504311961004874,
      "grad_norm": 0.09835253655910492,
      "learning_rate": 1.4495688038995126e-05,
      "loss": 0.0205,
      "step": 14680
    },
    {
      "epoch": 5.508061492313461,
      "grad_norm": 3.019726037979126,
      "learning_rate": 1.449193850768654e-05,
      "loss": 0.0232,
      "step": 14690
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.12989675998687744,
      "learning_rate": 1.4488188976377955e-05,
      "loss": 0.006,
      "step": 14700
    },
    {
      "epoch": 5.515560554930634,
      "grad_norm": 0.016062557697296143,
      "learning_rate": 1.4484439445069367e-05,
      "loss": 0.0158,
      "step": 14710
    },
    {
      "epoch": 5.51931008623922,
      "grad_norm": 0.03397155925631523,
      "learning_rate": 1.4480689913760782e-05,
      "loss": 0.0265,
      "step": 14720
    },
    {
      "epoch": 5.523059617547807,
      "grad_norm": 0.15101657807826996,
      "learning_rate": 1.4476940382452194e-05,
      "loss": 0.0335,
      "step": 14730
    },
    {
      "epoch": 5.526809148856393,
      "grad_norm": 0.05661965534090996,
      "learning_rate": 1.4473190851143608e-05,
      "loss": 0.0229,
      "step": 14740
    },
    {
      "epoch": 5.5305586801649795,
      "grad_norm": 0.33511027693748474,
      "learning_rate": 1.4469441319835022e-05,
      "loss": 0.0155,
      "step": 14750
    },
    {
      "epoch": 5.534308211473566,
      "grad_norm": 0.9008433818817139,
      "learning_rate": 1.4465691788526435e-05,
      "loss": 0.0073,
      "step": 14760
    },
    {
      "epoch": 5.5380577427821525,
      "grad_norm": 0.8646251559257507,
      "learning_rate": 1.4461942257217849e-05,
      "loss": 0.0164,
      "step": 14770
    },
    {
      "epoch": 5.541807274090739,
      "grad_norm": 0.34597641229629517,
      "learning_rate": 1.4458192725909263e-05,
      "loss": 0.0079,
      "step": 14780
    },
    {
      "epoch": 5.545556805399325,
      "grad_norm": 1.0117089748382568,
      "learning_rate": 1.4454443194600676e-05,
      "loss": 0.0258,
      "step": 14790
    },
    {
      "epoch": 5.549306336707912,
      "grad_norm": 5.050477981567383,
      "learning_rate": 1.445069366329209e-05,
      "loss": 0.0317,
      "step": 14800
    },
    {
      "epoch": 5.553055868016498,
      "grad_norm": 1.3416179418563843,
      "learning_rate": 1.4446944131983502e-05,
      "loss": 0.0269,
      "step": 14810
    },
    {
      "epoch": 5.556805399325084,
      "grad_norm": 0.059199266135692596,
      "learning_rate": 1.4443194600674917e-05,
      "loss": 0.0142,
      "step": 14820
    },
    {
      "epoch": 5.560554930633671,
      "grad_norm": 6.580699443817139,
      "learning_rate": 1.443944506936633e-05,
      "loss": 0.0286,
      "step": 14830
    },
    {
      "epoch": 5.564304461942257,
      "grad_norm": 0.37300777435302734,
      "learning_rate": 1.4435695538057743e-05,
      "loss": 0.0033,
      "step": 14840
    },
    {
      "epoch": 5.568053993250843,
      "grad_norm": 2.175278425216675,
      "learning_rate": 1.4431946006749158e-05,
      "loss": 0.0248,
      "step": 14850
    },
    {
      "epoch": 5.57180352455943,
      "grad_norm": 0.018301840871572495,
      "learning_rate": 1.442819647544057e-05,
      "loss": 0.0601,
      "step": 14860
    },
    {
      "epoch": 5.575553055868016,
      "grad_norm": 0.47447022795677185,
      "learning_rate": 1.4424446944131984e-05,
      "loss": 0.0264,
      "step": 14870
    },
    {
      "epoch": 5.579302587176603,
      "grad_norm": 0.024091849103569984,
      "learning_rate": 1.4420697412823398e-05,
      "loss": 0.011,
      "step": 14880
    },
    {
      "epoch": 5.583052118485189,
      "grad_norm": 0.007798459846526384,
      "learning_rate": 1.4416947881514811e-05,
      "loss": 0.0239,
      "step": 14890
    },
    {
      "epoch": 5.586801649793776,
      "grad_norm": 0.4583699703216553,
      "learning_rate": 1.4413198350206225e-05,
      "loss": 0.0318,
      "step": 14900
    },
    {
      "epoch": 5.590551181102362,
      "grad_norm": 2.8269755840301514,
      "learning_rate": 1.440944881889764e-05,
      "loss": 0.027,
      "step": 14910
    },
    {
      "epoch": 5.5943007124109485,
      "grad_norm": 1.876448154449463,
      "learning_rate": 1.4405699287589052e-05,
      "loss": 0.0189,
      "step": 14920
    },
    {
      "epoch": 5.598050243719535,
      "grad_norm": 12.786581993103027,
      "learning_rate": 1.4401949756280466e-05,
      "loss": 0.0293,
      "step": 14930
    },
    {
      "epoch": 5.601799775028121,
      "grad_norm": 0.8115161657333374,
      "learning_rate": 1.4398200224971878e-05,
      "loss": 0.011,
      "step": 14940
    },
    {
      "epoch": 5.605549306336708,
      "grad_norm": 0.10626664757728577,
      "learning_rate": 1.4394450693663293e-05,
      "loss": 0.0316,
      "step": 14950
    },
    {
      "epoch": 5.609298837645294,
      "grad_norm": 0.11444918811321259,
      "learning_rate": 1.4390701162354708e-05,
      "loss": 0.0281,
      "step": 14960
    },
    {
      "epoch": 5.613048368953881,
      "grad_norm": 0.021053871139883995,
      "learning_rate": 1.438695163104612e-05,
      "loss": 0.0048,
      "step": 14970
    },
    {
      "epoch": 5.616797900262467,
      "grad_norm": 10.175999641418457,
      "learning_rate": 1.4383202099737535e-05,
      "loss": 0.0154,
      "step": 14980
    },
    {
      "epoch": 5.620547431571054,
      "grad_norm": 0.04736066609621048,
      "learning_rate": 1.4379452568428946e-05,
      "loss": 0.0269,
      "step": 14990
    },
    {
      "epoch": 5.62429696287964,
      "grad_norm": 0.4938758313655853,
      "learning_rate": 1.437570303712036e-05,
      "loss": 0.0257,
      "step": 15000
    },
    {
      "epoch": 5.628046494188227,
      "grad_norm": 0.09659851342439651,
      "learning_rate": 1.4371953505811776e-05,
      "loss": 0.0073,
      "step": 15010
    },
    {
      "epoch": 5.631796025496813,
      "grad_norm": 3.344212770462036,
      "learning_rate": 1.4368203974503187e-05,
      "loss": 0.016,
      "step": 15020
    },
    {
      "epoch": 5.6355455568054,
      "grad_norm": 0.015667680650949478,
      "learning_rate": 1.4364454443194603e-05,
      "loss": 0.0111,
      "step": 15030
    },
    {
      "epoch": 5.639295088113986,
      "grad_norm": 0.012314006686210632,
      "learning_rate": 1.4360704911886017e-05,
      "loss": 0.0527,
      "step": 15040
    },
    {
      "epoch": 5.6430446194225725,
      "grad_norm": 2.5651793479919434,
      "learning_rate": 1.435695538057743e-05,
      "loss": 0.0174,
      "step": 15050
    },
    {
      "epoch": 5.646794150731159,
      "grad_norm": 0.5886321067810059,
      "learning_rate": 1.4353205849268844e-05,
      "loss": 0.0337,
      "step": 15060
    },
    {
      "epoch": 5.6505436820397446,
      "grad_norm": 4.517295837402344,
      "learning_rate": 1.4349456317960256e-05,
      "loss": 0.0141,
      "step": 15070
    },
    {
      "epoch": 5.654293213348332,
      "grad_norm": 0.04743122681975365,
      "learning_rate": 1.434570678665167e-05,
      "loss": 0.0165,
      "step": 15080
    },
    {
      "epoch": 5.6580427446569175,
      "grad_norm": 2.5166094303131104,
      "learning_rate": 1.4341957255343084e-05,
      "loss": 0.0156,
      "step": 15090
    },
    {
      "epoch": 5.661792275965504,
      "grad_norm": 0.02435516193509102,
      "learning_rate": 1.4338207724034497e-05,
      "loss": 0.0215,
      "step": 15100
    },
    {
      "epoch": 5.66554180727409,
      "grad_norm": 2.7636308670043945,
      "learning_rate": 1.4334458192725911e-05,
      "loss": 0.0284,
      "step": 15110
    },
    {
      "epoch": 5.669291338582677,
      "grad_norm": 0.4495090842247009,
      "learning_rate": 1.4330708661417324e-05,
      "loss": 0.0337,
      "step": 15120
    },
    {
      "epoch": 5.673040869891263,
      "grad_norm": 0.07353641837835312,
      "learning_rate": 1.4326959130108738e-05,
      "loss": 0.0104,
      "step": 15130
    },
    {
      "epoch": 5.67679040119985,
      "grad_norm": 0.013846956193447113,
      "learning_rate": 1.4323209598800152e-05,
      "loss": 0.0232,
      "step": 15140
    },
    {
      "epoch": 5.680539932508436,
      "grad_norm": 0.06349708139896393,
      "learning_rate": 1.4319460067491565e-05,
      "loss": 0.018,
      "step": 15150
    },
    {
      "epoch": 5.684289463817023,
      "grad_norm": 0.8425775766372681,
      "learning_rate": 1.4315710536182979e-05,
      "loss": 0.0127,
      "step": 15160
    },
    {
      "epoch": 5.688038995125609,
      "grad_norm": 0.016878245398402214,
      "learning_rate": 1.4311961004874393e-05,
      "loss": 0.0163,
      "step": 15170
    },
    {
      "epoch": 5.691788526434196,
      "grad_norm": 1.1815361976623535,
      "learning_rate": 1.4308211473565805e-05,
      "loss": 0.0258,
      "step": 15180
    },
    {
      "epoch": 5.695538057742782,
      "grad_norm": 0.07711130380630493,
      "learning_rate": 1.430446194225722e-05,
      "loss": 0.024,
      "step": 15190
    },
    {
      "epoch": 5.699287589051369,
      "grad_norm": 0.028592245653271675,
      "learning_rate": 1.4300712410948632e-05,
      "loss": 0.0114,
      "step": 15200
    },
    {
      "epoch": 5.703037120359955,
      "grad_norm": 0.7681913375854492,
      "learning_rate": 1.4296962879640046e-05,
      "loss": 0.0333,
      "step": 15210
    },
    {
      "epoch": 5.7067866516685415,
      "grad_norm": 0.058891963213682175,
      "learning_rate": 1.429321334833146e-05,
      "loss": 0.0199,
      "step": 15220
    },
    {
      "epoch": 5.710536182977128,
      "grad_norm": 0.056622471660375595,
      "learning_rate": 1.4289463817022873e-05,
      "loss": 0.0052,
      "step": 15230
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 3.066941738128662,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.0523,
      "step": 15240
    },
    {
      "epoch": 5.718035245594301,
      "grad_norm": 0.1930217295885086,
      "learning_rate": 1.42819647544057e-05,
      "loss": 0.0199,
      "step": 15250
    },
    {
      "epoch": 5.721784776902887,
      "grad_norm": 0.019920913502573967,
      "learning_rate": 1.4278215223097114e-05,
      "loss": 0.0137,
      "step": 15260
    },
    {
      "epoch": 5.725534308211474,
      "grad_norm": 0.27974075078964233,
      "learning_rate": 1.4274465691788528e-05,
      "loss": 0.0093,
      "step": 15270
    },
    {
      "epoch": 5.72928383952006,
      "grad_norm": 2.049600839614868,
      "learning_rate": 1.427071616047994e-05,
      "loss": 0.0495,
      "step": 15280
    },
    {
      "epoch": 5.733033370828647,
      "grad_norm": 0.10309182852506638,
      "learning_rate": 1.4266966629171355e-05,
      "loss": 0.0141,
      "step": 15290
    },
    {
      "epoch": 5.736782902137233,
      "grad_norm": 3.4638314247131348,
      "learning_rate": 1.4263217097862769e-05,
      "loss": 0.0134,
      "step": 15300
    },
    {
      "epoch": 5.74053243344582,
      "grad_norm": 3.4292490482330322,
      "learning_rate": 1.4259467566554181e-05,
      "loss": 0.0381,
      "step": 15310
    },
    {
      "epoch": 5.744281964754405,
      "grad_norm": 2.342369794845581,
      "learning_rate": 1.4255718035245596e-05,
      "loss": 0.0311,
      "step": 15320
    },
    {
      "epoch": 5.748031496062993,
      "grad_norm": 0.05477182939648628,
      "learning_rate": 1.4251968503937008e-05,
      "loss": 0.0197,
      "step": 15330
    },
    {
      "epoch": 5.751781027371578,
      "grad_norm": 7.147130489349365,
      "learning_rate": 1.4248218972628422e-05,
      "loss": 0.0157,
      "step": 15340
    },
    {
      "epoch": 5.755530558680165,
      "grad_norm": 1.7764430046081543,
      "learning_rate": 1.4244469441319836e-05,
      "loss": 0.0171,
      "step": 15350
    },
    {
      "epoch": 5.759280089988751,
      "grad_norm": 0.398662805557251,
      "learning_rate": 1.4240719910011249e-05,
      "loss": 0.0285,
      "step": 15360
    },
    {
      "epoch": 5.7630296212973375,
      "grad_norm": 0.2546575367450714,
      "learning_rate": 1.4236970378702663e-05,
      "loss": 0.0099,
      "step": 15370
    },
    {
      "epoch": 5.766779152605924,
      "grad_norm": 6.748496055603027,
      "learning_rate": 1.4233220847394076e-05,
      "loss": 0.0176,
      "step": 15380
    },
    {
      "epoch": 5.7705286839145105,
      "grad_norm": 2.3634440898895264,
      "learning_rate": 1.422947131608549e-05,
      "loss": 0.0155,
      "step": 15390
    },
    {
      "epoch": 5.774278215223097,
      "grad_norm": 0.02200200781226158,
      "learning_rate": 1.4225721784776904e-05,
      "loss": 0.0108,
      "step": 15400
    },
    {
      "epoch": 5.778027746531683,
      "grad_norm": 0.20446664094924927,
      "learning_rate": 1.4221972253468316e-05,
      "loss": 0.0283,
      "step": 15410
    },
    {
      "epoch": 5.78177727784027,
      "grad_norm": 0.08058352768421173,
      "learning_rate": 1.421822272215973e-05,
      "loss": 0.024,
      "step": 15420
    },
    {
      "epoch": 5.785526809148856,
      "grad_norm": 0.9282535314559937,
      "learning_rate": 1.4214473190851147e-05,
      "loss": 0.0295,
      "step": 15430
    },
    {
      "epoch": 5.789276340457443,
      "grad_norm": 12.655360221862793,
      "learning_rate": 1.4210723659542557e-05,
      "loss": 0.0202,
      "step": 15440
    },
    {
      "epoch": 5.793025871766029,
      "grad_norm": 7.375067234039307,
      "learning_rate": 1.4206974128233973e-05,
      "loss": 0.0343,
      "step": 15450
    },
    {
      "epoch": 5.796775403074616,
      "grad_norm": 0.2799331247806549,
      "learning_rate": 1.4203224596925384e-05,
      "loss": 0.0239,
      "step": 15460
    },
    {
      "epoch": 5.800524934383202,
      "grad_norm": 0.08106669038534164,
      "learning_rate": 1.4199475065616798e-05,
      "loss": 0.0149,
      "step": 15470
    },
    {
      "epoch": 5.804274465691789,
      "grad_norm": 1.9235810041427612,
      "learning_rate": 1.4195725534308214e-05,
      "loss": 0.0046,
      "step": 15480
    },
    {
      "epoch": 5.808023997000375,
      "grad_norm": 2.909414291381836,
      "learning_rate": 1.4191976002999625e-05,
      "loss": 0.0221,
      "step": 15490
    },
    {
      "epoch": 5.8117735283089615,
      "grad_norm": 0.020611168816685677,
      "learning_rate": 1.418822647169104e-05,
      "loss": 0.0387,
      "step": 15500
    },
    {
      "epoch": 5.815523059617548,
      "grad_norm": 0.6582443118095398,
      "learning_rate": 1.4184476940382452e-05,
      "loss": 0.0082,
      "step": 15510
    },
    {
      "epoch": 5.8192725909261345,
      "grad_norm": 0.8999082446098328,
      "learning_rate": 1.4180727409073867e-05,
      "loss": 0.0229,
      "step": 15520
    },
    {
      "epoch": 5.823022122234721,
      "grad_norm": 1.604352593421936,
      "learning_rate": 1.4176977877765282e-05,
      "loss": 0.0114,
      "step": 15530
    },
    {
      "epoch": 5.826771653543307,
      "grad_norm": 0.4360370635986328,
      "learning_rate": 1.4173228346456694e-05,
      "loss": 0.0493,
      "step": 15540
    },
    {
      "epoch": 5.830521184851894,
      "grad_norm": 0.19137884676456451,
      "learning_rate": 1.4169478815148108e-05,
      "loss": 0.03,
      "step": 15550
    },
    {
      "epoch": 5.83427071616048,
      "grad_norm": 1.712211012840271,
      "learning_rate": 1.4165729283839523e-05,
      "loss": 0.0251,
      "step": 15560
    },
    {
      "epoch": 5.838020247469066,
      "grad_norm": 1.205673098564148,
      "learning_rate": 1.4161979752530935e-05,
      "loss": 0.0239,
      "step": 15570
    },
    {
      "epoch": 5.841769778777653,
      "grad_norm": 0.5526602268218994,
      "learning_rate": 1.415823022122235e-05,
      "loss": 0.0181,
      "step": 15580
    },
    {
      "epoch": 5.845519310086239,
      "grad_norm": 0.20129534602165222,
      "learning_rate": 1.4154480689913762e-05,
      "loss": 0.0283,
      "step": 15590
    },
    {
      "epoch": 5.849268841394825,
      "grad_norm": 0.011017168872058392,
      "learning_rate": 1.4150731158605176e-05,
      "loss": 0.0376,
      "step": 15600
    },
    {
      "epoch": 5.853018372703412,
      "grad_norm": 0.05257517471909523,
      "learning_rate": 1.414698162729659e-05,
      "loss": 0.0181,
      "step": 15610
    },
    {
      "epoch": 5.856767904011998,
      "grad_norm": 0.7355020046234131,
      "learning_rate": 1.4143232095988003e-05,
      "loss": 0.0456,
      "step": 15620
    },
    {
      "epoch": 5.860517435320585,
      "grad_norm": 1.5277756452560425,
      "learning_rate": 1.4139482564679417e-05,
      "loss": 0.0218,
      "step": 15630
    },
    {
      "epoch": 5.864266966629171,
      "grad_norm": 5.560258865356445,
      "learning_rate": 1.413573303337083e-05,
      "loss": 0.0044,
      "step": 15640
    },
    {
      "epoch": 5.868016497937758,
      "grad_norm": 0.46917760372161865,
      "learning_rate": 1.4131983502062243e-05,
      "loss": 0.0176,
      "step": 15650
    },
    {
      "epoch": 5.871766029246344,
      "grad_norm": 0.020341672003269196,
      "learning_rate": 1.4128233970753658e-05,
      "loss": 0.0087,
      "step": 15660
    },
    {
      "epoch": 5.8755155605549305,
      "grad_norm": 45.21072006225586,
      "learning_rate": 1.412448443944507e-05,
      "loss": 0.0333,
      "step": 15670
    },
    {
      "epoch": 5.879265091863517,
      "grad_norm": 0.07342814654111862,
      "learning_rate": 1.4120734908136484e-05,
      "loss": 0.0215,
      "step": 15680
    },
    {
      "epoch": 5.883014623172103,
      "grad_norm": 5.504114627838135,
      "learning_rate": 1.4116985376827898e-05,
      "loss": 0.0349,
      "step": 15690
    },
    {
      "epoch": 5.88676415448069,
      "grad_norm": 0.013381855562329292,
      "learning_rate": 1.4113235845519311e-05,
      "loss": 0.0026,
      "step": 15700
    },
    {
      "epoch": 5.890513685789276,
      "grad_norm": 0.013914809562265873,
      "learning_rate": 1.4109486314210725e-05,
      "loss": 0.0096,
      "step": 15710
    },
    {
      "epoch": 5.894263217097863,
      "grad_norm": 1.005569577217102,
      "learning_rate": 1.4105736782902138e-05,
      "loss": 0.0158,
      "step": 15720
    },
    {
      "epoch": 5.898012748406449,
      "grad_norm": 0.2890344560146332,
      "learning_rate": 1.4101987251593552e-05,
      "loss": 0.0446,
      "step": 15730
    },
    {
      "epoch": 5.901762279715036,
      "grad_norm": 1.56356680393219,
      "learning_rate": 1.4098237720284966e-05,
      "loss": 0.026,
      "step": 15740
    },
    {
      "epoch": 5.905511811023622,
      "grad_norm": 0.2515813410282135,
      "learning_rate": 1.4094488188976379e-05,
      "loss": 0.0088,
      "step": 15750
    },
    {
      "epoch": 5.909261342332209,
      "grad_norm": 0.018650593236088753,
      "learning_rate": 1.4090738657667793e-05,
      "loss": 0.0041,
      "step": 15760
    },
    {
      "epoch": 5.913010873640795,
      "grad_norm": 1.544304609298706,
      "learning_rate": 1.4086989126359207e-05,
      "loss": 0.0286,
      "step": 15770
    },
    {
      "epoch": 5.916760404949382,
      "grad_norm": 1.3110216856002808,
      "learning_rate": 1.408323959505062e-05,
      "loss": 0.0051,
      "step": 15780
    },
    {
      "epoch": 5.920509936257968,
      "grad_norm": 1.0548536777496338,
      "learning_rate": 1.4079490063742034e-05,
      "loss": 0.0322,
      "step": 15790
    },
    {
      "epoch": 5.9242594675665545,
      "grad_norm": 1.2686935663223267,
      "learning_rate": 1.4075740532433446e-05,
      "loss": 0.0091,
      "step": 15800
    },
    {
      "epoch": 5.928008998875141,
      "grad_norm": 5.320404052734375,
      "learning_rate": 1.407199100112486e-05,
      "loss": 0.0261,
      "step": 15810
    },
    {
      "epoch": 5.931758530183727,
      "grad_norm": 2.027621269226074,
      "learning_rate": 1.4068241469816274e-05,
      "loss": 0.0489,
      "step": 15820
    },
    {
      "epoch": 5.935508061492314,
      "grad_norm": 0.029587378725409508,
      "learning_rate": 1.4064491938507687e-05,
      "loss": 0.0134,
      "step": 15830
    },
    {
      "epoch": 5.9392575928008995,
      "grad_norm": 0.029978232458233833,
      "learning_rate": 1.4060742407199101e-05,
      "loss": 0.0059,
      "step": 15840
    },
    {
      "epoch": 5.943007124109486,
      "grad_norm": 1.0527527332305908,
      "learning_rate": 1.4056992875890514e-05,
      "loss": 0.0054,
      "step": 15850
    },
    {
      "epoch": 5.946756655418072,
      "grad_norm": 2.9138615131378174,
      "learning_rate": 1.4053243344581928e-05,
      "loss": 0.0286,
      "step": 15860
    },
    {
      "epoch": 5.950506186726659,
      "grad_norm": 0.5741363167762756,
      "learning_rate": 1.4049493813273342e-05,
      "loss": 0.0319,
      "step": 15870
    },
    {
      "epoch": 5.954255718035245,
      "grad_norm": 1.6869616508483887,
      "learning_rate": 1.4045744281964754e-05,
      "loss": 0.0765,
      "step": 15880
    },
    {
      "epoch": 5.958005249343832,
      "grad_norm": 0.037082500755786896,
      "learning_rate": 1.4041994750656169e-05,
      "loss": 0.0121,
      "step": 15890
    },
    {
      "epoch": 5.961754780652418,
      "grad_norm": 0.0038337851874530315,
      "learning_rate": 1.4038245219347585e-05,
      "loss": 0.0201,
      "step": 15900
    },
    {
      "epoch": 5.965504311961005,
      "grad_norm": 0.011656186543405056,
      "learning_rate": 1.4034495688038995e-05,
      "loss": 0.0172,
      "step": 15910
    },
    {
      "epoch": 5.969253843269591,
      "grad_norm": 0.46701136231422424,
      "learning_rate": 1.4030746156730411e-05,
      "loss": 0.0565,
      "step": 15920
    },
    {
      "epoch": 5.973003374578178,
      "grad_norm": 1.4968087673187256,
      "learning_rate": 1.4026996625421822e-05,
      "loss": 0.0221,
      "step": 15930
    },
    {
      "epoch": 5.976752905886764,
      "grad_norm": 3.571786403656006,
      "learning_rate": 1.4023247094113236e-05,
      "loss": 0.0154,
      "step": 15940
    },
    {
      "epoch": 5.980502437195351,
      "grad_norm": 2.0498828887939453,
      "learning_rate": 1.4019497562804652e-05,
      "loss": 0.0201,
      "step": 15950
    },
    {
      "epoch": 5.984251968503937,
      "grad_norm": 3.114304304122925,
      "learning_rate": 1.4015748031496063e-05,
      "loss": 0.0296,
      "step": 15960
    },
    {
      "epoch": 5.9880014998125235,
      "grad_norm": 0.01810074783861637,
      "learning_rate": 1.4011998500187479e-05,
      "loss": 0.0213,
      "step": 15970
    },
    {
      "epoch": 5.99175103112111,
      "grad_norm": 1.5789997577667236,
      "learning_rate": 1.400824896887889e-05,
      "loss": 0.0149,
      "step": 15980
    },
    {
      "epoch": 5.995500562429696,
      "grad_norm": 0.5351600646972656,
      "learning_rate": 1.4004499437570305e-05,
      "loss": 0.0259,
      "step": 15990
    },
    {
      "epoch": 5.999250093738283,
      "grad_norm": 0.3518941104412079,
      "learning_rate": 1.400074990626172e-05,
      "loss": 0.0022,
      "step": 16000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9919437153689122,
      "eval_f1": 0.9691728274515274,
      "eval_loss": 0.023133534938097,
      "eval_precision": 0.9617940199335548,
      "eval_recall": 0.9766657295473714,
      "eval_runtime": 918.878,
      "eval_samples_per_second": 29.855,
      "eval_steps_per_second": 1.245,
      "step": 16002
    },
    {
      "epoch": 6.002999625046869,
      "grad_norm": 0.015382463112473488,
      "learning_rate": 1.3997000374953132e-05,
      "loss": 0.0249,
      "step": 16010
    },
    {
      "epoch": 6.006749156355456,
      "grad_norm": 1.1701947450637817,
      "learning_rate": 1.3993250843644546e-05,
      "loss": 0.0231,
      "step": 16020
    },
    {
      "epoch": 6.010498687664042,
      "grad_norm": 0.01776575855910778,
      "learning_rate": 1.398950131233596e-05,
      "loss": 0.0223,
      "step": 16030
    },
    {
      "epoch": 6.014248218972629,
      "grad_norm": 1.2216181755065918,
      "learning_rate": 1.3985751781027373e-05,
      "loss": 0.0132,
      "step": 16040
    },
    {
      "epoch": 6.017997750281215,
      "grad_norm": 1.185804009437561,
      "learning_rate": 1.3982002249718787e-05,
      "loss": 0.0261,
      "step": 16050
    },
    {
      "epoch": 6.021747281589802,
      "grad_norm": 0.7323492169380188,
      "learning_rate": 1.39782527184102e-05,
      "loss": 0.0107,
      "step": 16060
    },
    {
      "epoch": 6.025496812898388,
      "grad_norm": 0.2391567975282669,
      "learning_rate": 1.3974503187101614e-05,
      "loss": 0.0053,
      "step": 16070
    },
    {
      "epoch": 6.029246344206974,
      "grad_norm": 0.7483670711517334,
      "learning_rate": 1.3970753655793028e-05,
      "loss": 0.0119,
      "step": 16080
    },
    {
      "epoch": 6.03299587551556,
      "grad_norm": 0.8541374206542969,
      "learning_rate": 1.396700412448444e-05,
      "loss": 0.0254,
      "step": 16090
    },
    {
      "epoch": 6.036745406824147,
      "grad_norm": 5.832377910614014,
      "learning_rate": 1.3963254593175855e-05,
      "loss": 0.0066,
      "step": 16100
    },
    {
      "epoch": 6.040494938132733,
      "grad_norm": 0.9647855162620544,
      "learning_rate": 1.3959505061867267e-05,
      "loss": 0.0168,
      "step": 16110
    },
    {
      "epoch": 6.0442444694413195,
      "grad_norm": 0.4385536313056946,
      "learning_rate": 1.3955755530558681e-05,
      "loss": 0.0034,
      "step": 16120
    },
    {
      "epoch": 6.047994000749906,
      "grad_norm": 1.0892345905303955,
      "learning_rate": 1.3952005999250096e-05,
      "loss": 0.0401,
      "step": 16130
    },
    {
      "epoch": 6.0517435320584925,
      "grad_norm": 1.3008602857589722,
      "learning_rate": 1.3948256467941508e-05,
      "loss": 0.0078,
      "step": 16140
    },
    {
      "epoch": 6.055493063367079,
      "grad_norm": 0.004192080814391375,
      "learning_rate": 1.3944506936632922e-05,
      "loss": 0.0183,
      "step": 16150
    },
    {
      "epoch": 6.059242594675665,
      "grad_norm": 0.003854312701150775,
      "learning_rate": 1.3940757405324337e-05,
      "loss": 0.0059,
      "step": 16160
    },
    {
      "epoch": 6.062992125984252,
      "grad_norm": 0.48836061358451843,
      "learning_rate": 1.3937007874015749e-05,
      "loss": 0.017,
      "step": 16170
    },
    {
      "epoch": 6.066741657292838,
      "grad_norm": 0.051061324775218964,
      "learning_rate": 1.3933258342707163e-05,
      "loss": 0.0137,
      "step": 16180
    },
    {
      "epoch": 6.070491188601425,
      "grad_norm": 0.870253324508667,
      "learning_rate": 1.3929508811398576e-05,
      "loss": 0.0071,
      "step": 16190
    },
    {
      "epoch": 6.074240719910011,
      "grad_norm": 0.4644821286201477,
      "learning_rate": 1.392575928008999e-05,
      "loss": 0.0265,
      "step": 16200
    },
    {
      "epoch": 6.077990251218598,
      "grad_norm": 0.7772889733314514,
      "learning_rate": 1.3922009748781404e-05,
      "loss": 0.0301,
      "step": 16210
    },
    {
      "epoch": 6.081739782527184,
      "grad_norm": 17.44525909423828,
      "learning_rate": 1.3918260217472817e-05,
      "loss": 0.0248,
      "step": 16220
    },
    {
      "epoch": 6.085489313835771,
      "grad_norm": 0.09892309457063675,
      "learning_rate": 1.391451068616423e-05,
      "loss": 0.0072,
      "step": 16230
    },
    {
      "epoch": 6.089238845144357,
      "grad_norm": 0.21634671092033386,
      "learning_rate": 1.3910761154855643e-05,
      "loss": 0.0205,
      "step": 16240
    },
    {
      "epoch": 6.0929883764529436,
      "grad_norm": 1.8954790830612183,
      "learning_rate": 1.3907011623547057e-05,
      "loss": 0.0153,
      "step": 16250
    },
    {
      "epoch": 6.09673790776153,
      "grad_norm": 0.002262251218780875,
      "learning_rate": 1.3903262092238472e-05,
      "loss": 0.0168,
      "step": 16260
    },
    {
      "epoch": 6.1004874390701165,
      "grad_norm": 0.6227297782897949,
      "learning_rate": 1.3899512560929884e-05,
      "loss": 0.0201,
      "step": 16270
    },
    {
      "epoch": 6.104236970378703,
      "grad_norm": 0.8024324178695679,
      "learning_rate": 1.3895763029621298e-05,
      "loss": 0.0147,
      "step": 16280
    },
    {
      "epoch": 6.107986501687289,
      "grad_norm": 0.00683575589209795,
      "learning_rate": 1.3892013498312712e-05,
      "loss": 0.0219,
      "step": 16290
    },
    {
      "epoch": 6.111736032995876,
      "grad_norm": 0.9521889090538025,
      "learning_rate": 1.3888263967004125e-05,
      "loss": 0.0107,
      "step": 16300
    },
    {
      "epoch": 6.115485564304462,
      "grad_norm": 0.04680155590176582,
      "learning_rate": 1.388451443569554e-05,
      "loss": 0.0023,
      "step": 16310
    },
    {
      "epoch": 6.119235095613049,
      "grad_norm": 0.002229335019364953,
      "learning_rate": 1.3880764904386952e-05,
      "loss": 0.0118,
      "step": 16320
    },
    {
      "epoch": 6.122984626921634,
      "grad_norm": 0.8010548949241638,
      "learning_rate": 1.3877015373078366e-05,
      "loss": 0.0129,
      "step": 16330
    },
    {
      "epoch": 6.126734158230221,
      "grad_norm": 5.855721473693848,
      "learning_rate": 1.387326584176978e-05,
      "loss": 0.0087,
      "step": 16340
    },
    {
      "epoch": 6.130483689538807,
      "grad_norm": 0.6899258494377136,
      "learning_rate": 1.3869516310461193e-05,
      "loss": 0.0265,
      "step": 16350
    },
    {
      "epoch": 6.134233220847394,
      "grad_norm": 0.015871582552790642,
      "learning_rate": 1.3865766779152607e-05,
      "loss": 0.0332,
      "step": 16360
    },
    {
      "epoch": 6.13798275215598,
      "grad_norm": 0.0032306830398738384,
      "learning_rate": 1.386201724784402e-05,
      "loss": 0.0076,
      "step": 16370
    },
    {
      "epoch": 6.141732283464567,
      "grad_norm": 0.19877679646015167,
      "learning_rate": 1.3858267716535433e-05,
      "loss": 0.0148,
      "step": 16380
    },
    {
      "epoch": 6.145481814773153,
      "grad_norm": 1.0032879114151,
      "learning_rate": 1.385451818522685e-05,
      "loss": 0.0068,
      "step": 16390
    },
    {
      "epoch": 6.14923134608174,
      "grad_norm": 5.763602256774902,
      "learning_rate": 1.385076865391826e-05,
      "loss": 0.0246,
      "step": 16400
    },
    {
      "epoch": 6.152980877390326,
      "grad_norm": 0.016807639971375465,
      "learning_rate": 1.3847019122609674e-05,
      "loss": 0.0265,
      "step": 16410
    },
    {
      "epoch": 6.1567304086989125,
      "grad_norm": 0.007105257827788591,
      "learning_rate": 1.384326959130109e-05,
      "loss": 0.0048,
      "step": 16420
    },
    {
      "epoch": 6.160479940007499,
      "grad_norm": 1.5883792638778687,
      "learning_rate": 1.3839520059992501e-05,
      "loss": 0.0182,
      "step": 16430
    },
    {
      "epoch": 6.1642294713160855,
      "grad_norm": 0.00284744706004858,
      "learning_rate": 1.3835770528683917e-05,
      "loss": 0.0049,
      "step": 16440
    },
    {
      "epoch": 6.167979002624672,
      "grad_norm": 5.397422790527344,
      "learning_rate": 1.3832020997375328e-05,
      "loss": 0.0458,
      "step": 16450
    },
    {
      "epoch": 6.171728533933258,
      "grad_norm": 1.0866602659225464,
      "learning_rate": 1.3828271466066744e-05,
      "loss": 0.0081,
      "step": 16460
    },
    {
      "epoch": 6.175478065241845,
      "grad_norm": 0.00998144131153822,
      "learning_rate": 1.3824521934758158e-05,
      "loss": 0.0184,
      "step": 16470
    },
    {
      "epoch": 6.179227596550431,
      "grad_norm": 1.4430198669433594,
      "learning_rate": 1.382077240344957e-05,
      "loss": 0.0346,
      "step": 16480
    },
    {
      "epoch": 6.182977127859018,
      "grad_norm": 5.3541951179504395,
      "learning_rate": 1.3817022872140984e-05,
      "loss": 0.0411,
      "step": 16490
    },
    {
      "epoch": 6.186726659167604,
      "grad_norm": 1.939538836479187,
      "learning_rate": 1.3813273340832395e-05,
      "loss": 0.0093,
      "step": 16500
    },
    {
      "epoch": 6.190476190476191,
      "grad_norm": 0.009328983724117279,
      "learning_rate": 1.3809523809523811e-05,
      "loss": 0.0111,
      "step": 16510
    },
    {
      "epoch": 6.194225721784777,
      "grad_norm": 0.25003528594970703,
      "learning_rate": 1.3805774278215225e-05,
      "loss": 0.0139,
      "step": 16520
    },
    {
      "epoch": 6.197975253093364,
      "grad_norm": 1.511362075805664,
      "learning_rate": 1.3802024746906638e-05,
      "loss": 0.005,
      "step": 16530
    },
    {
      "epoch": 6.20172478440195,
      "grad_norm": 3.913207530975342,
      "learning_rate": 1.3798275215598052e-05,
      "loss": 0.0124,
      "step": 16540
    },
    {
      "epoch": 6.2054743157105365,
      "grad_norm": 0.6698901653289795,
      "learning_rate": 1.3794525684289466e-05,
      "loss": 0.0233,
      "step": 16550
    },
    {
      "epoch": 6.209223847019123,
      "grad_norm": 0.008824043907225132,
      "learning_rate": 1.3790776152980879e-05,
      "loss": 0.0141,
      "step": 16560
    },
    {
      "epoch": 6.2129733783277095,
      "grad_norm": 7.106150150299072,
      "learning_rate": 1.3787026621672293e-05,
      "loss": 0.0253,
      "step": 16570
    },
    {
      "epoch": 6.216722909636295,
      "grad_norm": 0.45207321643829346,
      "learning_rate": 1.3783277090363705e-05,
      "loss": 0.0248,
      "step": 16580
    },
    {
      "epoch": 6.2204724409448815,
      "grad_norm": 0.05543897673487663,
      "learning_rate": 1.377952755905512e-05,
      "loss": 0.011,
      "step": 16590
    },
    {
      "epoch": 6.224221972253468,
      "grad_norm": 0.008891798555850983,
      "learning_rate": 1.3775778027746534e-05,
      "loss": 0.0151,
      "step": 16600
    },
    {
      "epoch": 6.227971503562054,
      "grad_norm": 0.0041025299578905106,
      "learning_rate": 1.3772028496437946e-05,
      "loss": 0.0072,
      "step": 16610
    },
    {
      "epoch": 6.231721034870641,
      "grad_norm": 0.005326473619788885,
      "learning_rate": 1.376827896512936e-05,
      "loss": 0.0128,
      "step": 16620
    },
    {
      "epoch": 6.235470566179227,
      "grad_norm": 0.02361859194934368,
      "learning_rate": 1.3764529433820773e-05,
      "loss": 0.0202,
      "step": 16630
    },
    {
      "epoch": 6.239220097487814,
      "grad_norm": 1.9442346096038818,
      "learning_rate": 1.3760779902512187e-05,
      "loss": 0.0172,
      "step": 16640
    },
    {
      "epoch": 6.2429696287964,
      "grad_norm": 0.4759844243526459,
      "learning_rate": 1.3757030371203601e-05,
      "loss": 0.0108,
      "step": 16650
    },
    {
      "epoch": 6.246719160104987,
      "grad_norm": 0.09884575009346008,
      "learning_rate": 1.3753280839895014e-05,
      "loss": 0.0086,
      "step": 16660
    },
    {
      "epoch": 6.250468691413573,
      "grad_norm": 0.12710446119308472,
      "learning_rate": 1.3749531308586428e-05,
      "loss": 0.0221,
      "step": 16670
    },
    {
      "epoch": 6.25421822272216,
      "grad_norm": 2.291245222091675,
      "learning_rate": 1.3745781777277842e-05,
      "loss": 0.044,
      "step": 16680
    },
    {
      "epoch": 6.257967754030746,
      "grad_norm": 0.1908661127090454,
      "learning_rate": 1.3742032245969255e-05,
      "loss": 0.0093,
      "step": 16690
    },
    {
      "epoch": 6.261717285339333,
      "grad_norm": 0.6263306736946106,
      "learning_rate": 1.3738282714660669e-05,
      "loss": 0.0171,
      "step": 16700
    },
    {
      "epoch": 6.265466816647919,
      "grad_norm": 0.0763634443283081,
      "learning_rate": 1.3734533183352081e-05,
      "loss": 0.0033,
      "step": 16710
    },
    {
      "epoch": 6.2692163479565055,
      "grad_norm": 4.933274745941162,
      "learning_rate": 1.3730783652043495e-05,
      "loss": 0.018,
      "step": 16720
    },
    {
      "epoch": 6.272965879265092,
      "grad_norm": 3.983637571334839,
      "learning_rate": 1.372703412073491e-05,
      "loss": 0.0255,
      "step": 16730
    },
    {
      "epoch": 6.276715410573678,
      "grad_norm": 0.003382853465154767,
      "learning_rate": 1.3723284589426322e-05,
      "loss": 0.0341,
      "step": 16740
    },
    {
      "epoch": 6.280464941882265,
      "grad_norm": 0.6073840260505676,
      "learning_rate": 1.3719535058117736e-05,
      "loss": 0.0044,
      "step": 16750
    },
    {
      "epoch": 6.284214473190851,
      "grad_norm": 1.8490346670150757,
      "learning_rate": 1.3715785526809149e-05,
      "loss": 0.0152,
      "step": 16760
    },
    {
      "epoch": 6.287964004499438,
      "grad_norm": 5.566597938537598,
      "learning_rate": 1.3712035995500563e-05,
      "loss": 0.0296,
      "step": 16770
    },
    {
      "epoch": 6.291713535808024,
      "grad_norm": 7.23358154296875,
      "learning_rate": 1.3708286464191977e-05,
      "loss": 0.0232,
      "step": 16780
    },
    {
      "epoch": 6.295463067116611,
      "grad_norm": 2.5025110244750977,
      "learning_rate": 1.370453693288339e-05,
      "loss": 0.0198,
      "step": 16790
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 1.1515274047851562,
      "learning_rate": 1.3700787401574804e-05,
      "loss": 0.0145,
      "step": 16800
    },
    {
      "epoch": 6.302962129733784,
      "grad_norm": 0.2308163344860077,
      "learning_rate": 1.3697037870266218e-05,
      "loss": 0.0085,
      "step": 16810
    },
    {
      "epoch": 6.306711661042369,
      "grad_norm": 0.05650759115815163,
      "learning_rate": 1.369328833895763e-05,
      "loss": 0.0212,
      "step": 16820
    },
    {
      "epoch": 6.310461192350957,
      "grad_norm": 0.007025478407740593,
      "learning_rate": 1.3689538807649045e-05,
      "loss": 0.0062,
      "step": 16830
    },
    {
      "epoch": 6.314210723659542,
      "grad_norm": 0.6892557740211487,
      "learning_rate": 1.3685789276340457e-05,
      "loss": 0.026,
      "step": 16840
    },
    {
      "epoch": 6.317960254968129,
      "grad_norm": 0.9022564888000488,
      "learning_rate": 1.3682039745031871e-05,
      "loss": 0.0078,
      "step": 16850
    },
    {
      "epoch": 6.321709786276715,
      "grad_norm": 0.007063229568302631,
      "learning_rate": 1.3678290213723287e-05,
      "loss": 0.0043,
      "step": 16860
    },
    {
      "epoch": 6.3254593175853016,
      "grad_norm": 0.8105969429016113,
      "learning_rate": 1.3674540682414698e-05,
      "loss": 0.0349,
      "step": 16870
    },
    {
      "epoch": 6.329208848893888,
      "grad_norm": 0.8282779455184937,
      "learning_rate": 1.3670791151106112e-05,
      "loss": 0.0077,
      "step": 16880
    },
    {
      "epoch": 6.3329583802024745,
      "grad_norm": 2.2332522869110107,
      "learning_rate": 1.3667041619797528e-05,
      "loss": 0.0447,
      "step": 16890
    },
    {
      "epoch": 6.336707911511061,
      "grad_norm": 0.09618636220693588,
      "learning_rate": 1.3663292088488939e-05,
      "loss": 0.0324,
      "step": 16900
    },
    {
      "epoch": 6.340457442819647,
      "grad_norm": 0.01435021124780178,
      "learning_rate": 1.3659542557180355e-05,
      "loss": 0.0226,
      "step": 16910
    },
    {
      "epoch": 6.344206974128234,
      "grad_norm": 0.9296609163284302,
      "learning_rate": 1.3655793025871766e-05,
      "loss": 0.0102,
      "step": 16920
    },
    {
      "epoch": 6.34795650543682,
      "grad_norm": 0.3355908691883087,
      "learning_rate": 1.3652043494563182e-05,
      "loss": 0.0182,
      "step": 16930
    },
    {
      "epoch": 6.351706036745407,
      "grad_norm": 0.027365969493985176,
      "learning_rate": 1.3648293963254596e-05,
      "loss": 0.014,
      "step": 16940
    },
    {
      "epoch": 6.355455568053993,
      "grad_norm": 1.7520357370376587,
      "learning_rate": 1.3644544431946008e-05,
      "loss": 0.0128,
      "step": 16950
    },
    {
      "epoch": 6.35920509936258,
      "grad_norm": 0.3755810856819153,
      "learning_rate": 1.3640794900637422e-05,
      "loss": 0.0079,
      "step": 16960
    },
    {
      "epoch": 6.362954630671166,
      "grad_norm": 0.023321043699979782,
      "learning_rate": 1.3637045369328833e-05,
      "loss": 0.0183,
      "step": 16970
    },
    {
      "epoch": 6.366704161979753,
      "grad_norm": 0.028698856011033058,
      "learning_rate": 1.3633295838020249e-05,
      "loss": 0.0074,
      "step": 16980
    },
    {
      "epoch": 6.370453693288339,
      "grad_norm": 1.0036875009536743,
      "learning_rate": 1.3629546306711663e-05,
      "loss": 0.0335,
      "step": 16990
    },
    {
      "epoch": 6.374203224596926,
      "grad_norm": 0.4438002407550812,
      "learning_rate": 1.3625796775403076e-05,
      "loss": 0.0231,
      "step": 17000
    },
    {
      "epoch": 6.377952755905512,
      "grad_norm": 0.023147860541939735,
      "learning_rate": 1.362204724409449e-05,
      "loss": 0.0145,
      "step": 17010
    },
    {
      "epoch": 6.3817022872140985,
      "grad_norm": 6.910396575927734,
      "learning_rate": 1.3618297712785904e-05,
      "loss": 0.0118,
      "step": 17020
    },
    {
      "epoch": 6.385451818522685,
      "grad_norm": 0.36778637766838074,
      "learning_rate": 1.3614548181477317e-05,
      "loss": 0.0085,
      "step": 17030
    },
    {
      "epoch": 6.389201349831271,
      "grad_norm": 0.2248915135860443,
      "learning_rate": 1.361079865016873e-05,
      "loss": 0.0089,
      "step": 17040
    },
    {
      "epoch": 6.392950881139858,
      "grad_norm": 0.1058819591999054,
      "learning_rate": 1.3607049118860143e-05,
      "loss": 0.0163,
      "step": 17050
    },
    {
      "epoch": 6.396700412448444,
      "grad_norm": 0.1684749573469162,
      "learning_rate": 1.3603299587551558e-05,
      "loss": 0.0197,
      "step": 17060
    },
    {
      "epoch": 6.40044994375703,
      "grad_norm": 0.010066111572086811,
      "learning_rate": 1.3599550056242972e-05,
      "loss": 0.0356,
      "step": 17070
    },
    {
      "epoch": 6.404199475065617,
      "grad_norm": 4.583465099334717,
      "learning_rate": 1.3595800524934384e-05,
      "loss": 0.0262,
      "step": 17080
    },
    {
      "epoch": 6.407949006374203,
      "grad_norm": 1.8078100681304932,
      "learning_rate": 1.3592050993625798e-05,
      "loss": 0.0288,
      "step": 17090
    },
    {
      "epoch": 6.411698537682789,
      "grad_norm": 0.02631262317299843,
      "learning_rate": 1.3588301462317211e-05,
      "loss": 0.0155,
      "step": 17100
    },
    {
      "epoch": 6.415448068991376,
      "grad_norm": 0.10386878252029419,
      "learning_rate": 1.3584551931008625e-05,
      "loss": 0.0046,
      "step": 17110
    },
    {
      "epoch": 6.419197600299962,
      "grad_norm": 0.0060600703582167625,
      "learning_rate": 1.358080239970004e-05,
      "loss": 0.0089,
      "step": 17120
    },
    {
      "epoch": 6.422947131608549,
      "grad_norm": 0.9920668005943298,
      "learning_rate": 1.3577052868391452e-05,
      "loss": 0.0076,
      "step": 17130
    },
    {
      "epoch": 6.426696662917135,
      "grad_norm": 1.1144555807113647,
      "learning_rate": 1.3573303337082866e-05,
      "loss": 0.0156,
      "step": 17140
    },
    {
      "epoch": 6.430446194225722,
      "grad_norm": 9.606437683105469,
      "learning_rate": 1.356955380577428e-05,
      "loss": 0.0036,
      "step": 17150
    },
    {
      "epoch": 6.434195725534308,
      "grad_norm": 1.3077045679092407,
      "learning_rate": 1.3565804274465693e-05,
      "loss": 0.0469,
      "step": 17160
    },
    {
      "epoch": 6.4379452568428945,
      "grad_norm": 2.0994248390197754,
      "learning_rate": 1.3562054743157107e-05,
      "loss": 0.0186,
      "step": 17170
    },
    {
      "epoch": 6.441694788151481,
      "grad_norm": 0.003898852737620473,
      "learning_rate": 1.355830521184852e-05,
      "loss": 0.0175,
      "step": 17180
    },
    {
      "epoch": 6.4454443194600675,
      "grad_norm": 5.999805450439453,
      "learning_rate": 1.3554555680539933e-05,
      "loss": 0.0331,
      "step": 17190
    },
    {
      "epoch": 6.449193850768654,
      "grad_norm": 1.0668998956680298,
      "learning_rate": 1.3550806149231348e-05,
      "loss": 0.0148,
      "step": 17200
    },
    {
      "epoch": 6.45294338207724,
      "grad_norm": 1.7574397325515747,
      "learning_rate": 1.354705661792276e-05,
      "loss": 0.0264,
      "step": 17210
    },
    {
      "epoch": 6.456692913385827,
      "grad_norm": 0.7764918208122253,
      "learning_rate": 1.3543307086614174e-05,
      "loss": 0.0191,
      "step": 17220
    },
    {
      "epoch": 6.460442444694413,
      "grad_norm": 0.003496603574603796,
      "learning_rate": 1.3539557555305587e-05,
      "loss": 0.0297,
      "step": 17230
    },
    {
      "epoch": 6.464191976003,
      "grad_norm": 4.438084602355957,
      "learning_rate": 1.3535808023997001e-05,
      "loss": 0.0157,
      "step": 17240
    },
    {
      "epoch": 6.467941507311586,
      "grad_norm": 0.4708661437034607,
      "learning_rate": 1.3532058492688415e-05,
      "loss": 0.0051,
      "step": 17250
    },
    {
      "epoch": 6.471691038620173,
      "grad_norm": 0.5202255845069885,
      "learning_rate": 1.3528308961379828e-05,
      "loss": 0.0257,
      "step": 17260
    },
    {
      "epoch": 6.475440569928759,
      "grad_norm": 1.0732076168060303,
      "learning_rate": 1.3524559430071242e-05,
      "loss": 0.0066,
      "step": 17270
    },
    {
      "epoch": 6.479190101237346,
      "grad_norm": 1.4191734790802002,
      "learning_rate": 1.3520809898762656e-05,
      "loss": 0.0243,
      "step": 17280
    },
    {
      "epoch": 6.482939632545932,
      "grad_norm": 0.4951295256614685,
      "learning_rate": 1.3517060367454069e-05,
      "loss": 0.0014,
      "step": 17290
    },
    {
      "epoch": 6.4866891638545185,
      "grad_norm": 0.793478786945343,
      "learning_rate": 1.3513310836145483e-05,
      "loss": 0.0192,
      "step": 17300
    },
    {
      "epoch": 6.490438695163105,
      "grad_norm": 0.008031250908970833,
      "learning_rate": 1.3509561304836895e-05,
      "loss": 0.0318,
      "step": 17310
    },
    {
      "epoch": 6.494188226471691,
      "grad_norm": 0.7576481699943542,
      "learning_rate": 1.350581177352831e-05,
      "loss": 0.0093,
      "step": 17320
    },
    {
      "epoch": 6.497937757780278,
      "grad_norm": 0.7369427680969238,
      "learning_rate": 1.3502062242219725e-05,
      "loss": 0.0162,
      "step": 17330
    },
    {
      "epoch": 6.5016872890888635,
      "grad_norm": 0.12341619282960892,
      "learning_rate": 1.3498312710911136e-05,
      "loss": 0.0179,
      "step": 17340
    },
    {
      "epoch": 6.50543682039745,
      "grad_norm": 0.2287815362215042,
      "learning_rate": 1.349456317960255e-05,
      "loss": 0.0057,
      "step": 17350
    },
    {
      "epoch": 6.509186351706036,
      "grad_norm": 0.7375425100326538,
      "learning_rate": 1.3490813648293963e-05,
      "loss": 0.0237,
      "step": 17360
    },
    {
      "epoch": 6.512935883014623,
      "grad_norm": 3.38027024269104,
      "learning_rate": 1.3487064116985377e-05,
      "loss": 0.0216,
      "step": 17370
    },
    {
      "epoch": 6.516685414323209,
      "grad_norm": 1.2281229496002197,
      "learning_rate": 1.3483314585676793e-05,
      "loss": 0.0164,
      "step": 17380
    },
    {
      "epoch": 6.520434945631796,
      "grad_norm": 0.4570949673652649,
      "learning_rate": 1.3479565054368204e-05,
      "loss": 0.0262,
      "step": 17390
    },
    {
      "epoch": 6.524184476940382,
      "grad_norm": 0.3158780038356781,
      "learning_rate": 1.347581552305962e-05,
      "loss": 0.0076,
      "step": 17400
    },
    {
      "epoch": 6.527934008248969,
      "grad_norm": 0.015022385865449905,
      "learning_rate": 1.3472065991751034e-05,
      "loss": 0.0265,
      "step": 17410
    },
    {
      "epoch": 6.531683539557555,
      "grad_norm": 7.054877758026123,
      "learning_rate": 1.3468316460442446e-05,
      "loss": 0.034,
      "step": 17420
    },
    {
      "epoch": 6.535433070866142,
      "grad_norm": 0.006547045893967152,
      "learning_rate": 1.346456692913386e-05,
      "loss": 0.0011,
      "step": 17430
    },
    {
      "epoch": 6.539182602174728,
      "grad_norm": 0.004214954562485218,
      "learning_rate": 1.3460817397825271e-05,
      "loss": 0.0243,
      "step": 17440
    },
    {
      "epoch": 6.542932133483315,
      "grad_norm": 0.07936880737543106,
      "learning_rate": 1.3457067866516687e-05,
      "loss": 0.0163,
      "step": 17450
    },
    {
      "epoch": 6.546681664791901,
      "grad_norm": 16.272960662841797,
      "learning_rate": 1.3453318335208101e-05,
      "loss": 0.05,
      "step": 17460
    },
    {
      "epoch": 6.5504311961004875,
      "grad_norm": 12.600116729736328,
      "learning_rate": 1.3449568803899514e-05,
      "loss": 0.0475,
      "step": 17470
    },
    {
      "epoch": 6.554180727409074,
      "grad_norm": 3.624730348587036,
      "learning_rate": 1.3445819272590928e-05,
      "loss": 0.0106,
      "step": 17480
    },
    {
      "epoch": 6.55793025871766,
      "grad_norm": 0.005017705727368593,
      "learning_rate": 1.344206974128234e-05,
      "loss": 0.0357,
      "step": 17490
    },
    {
      "epoch": 6.561679790026247,
      "grad_norm": 0.4078477621078491,
      "learning_rate": 1.3438320209973755e-05,
      "loss": 0.0065,
      "step": 17500
    },
    {
      "epoch": 6.565429321334833,
      "grad_norm": 1.614320158958435,
      "learning_rate": 1.3434570678665169e-05,
      "loss": 0.0314,
      "step": 17510
    },
    {
      "epoch": 6.56917885264342,
      "grad_norm": 1.0944461822509766,
      "learning_rate": 1.3430821147356581e-05,
      "loss": 0.0443,
      "step": 17520
    },
    {
      "epoch": 6.572928383952006,
      "grad_norm": 0.05247936025261879,
      "learning_rate": 1.3427071616047996e-05,
      "loss": 0.0168,
      "step": 17530
    },
    {
      "epoch": 6.576677915260593,
      "grad_norm": 0.008698790334165096,
      "learning_rate": 1.342332208473941e-05,
      "loss": 0.0089,
      "step": 17540
    },
    {
      "epoch": 6.580427446569179,
      "grad_norm": 0.012838277034461498,
      "learning_rate": 1.3419572553430822e-05,
      "loss": 0.0059,
      "step": 17550
    },
    {
      "epoch": 6.584176977877766,
      "grad_norm": 0.019680745899677277,
      "learning_rate": 1.3415823022122236e-05,
      "loss": 0.0194,
      "step": 17560
    },
    {
      "epoch": 6.587926509186351,
      "grad_norm": 0.044443465769290924,
      "learning_rate": 1.3412073490813649e-05,
      "loss": 0.0061,
      "step": 17570
    },
    {
      "epoch": 6.591676040494939,
      "grad_norm": 0.025848403573036194,
      "learning_rate": 1.3408323959505063e-05,
      "loss": 0.0123,
      "step": 17580
    },
    {
      "epoch": 6.595425571803524,
      "grad_norm": 1.2036126852035522,
      "learning_rate": 1.3404574428196477e-05,
      "loss": 0.0211,
      "step": 17590
    },
    {
      "epoch": 6.599175103112111,
      "grad_norm": 0.0745094045996666,
      "learning_rate": 1.340082489688789e-05,
      "loss": 0.0184,
      "step": 17600
    },
    {
      "epoch": 6.602924634420697,
      "grad_norm": 1.5449090003967285,
      "learning_rate": 1.3397075365579304e-05,
      "loss": 0.0188,
      "step": 17610
    },
    {
      "epoch": 6.606674165729284,
      "grad_norm": 0.02666771039366722,
      "learning_rate": 1.3393325834270716e-05,
      "loss": 0.01,
      "step": 17620
    },
    {
      "epoch": 6.61042369703787,
      "grad_norm": 0.008078405633568764,
      "learning_rate": 1.338957630296213e-05,
      "loss": 0.0166,
      "step": 17630
    },
    {
      "epoch": 6.6141732283464565,
      "grad_norm": 0.46382227540016174,
      "learning_rate": 1.3385826771653545e-05,
      "loss": 0.0076,
      "step": 17640
    },
    {
      "epoch": 6.617922759655043,
      "grad_norm": 0.3807882070541382,
      "learning_rate": 1.3382077240344957e-05,
      "loss": 0.012,
      "step": 17650
    },
    {
      "epoch": 6.621672290963629,
      "grad_norm": 0.01173754408955574,
      "learning_rate": 1.3378327709036372e-05,
      "loss": 0.004,
      "step": 17660
    },
    {
      "epoch": 6.625421822272216,
      "grad_norm": 0.5360261797904968,
      "learning_rate": 1.3374578177727786e-05,
      "loss": 0.015,
      "step": 17670
    },
    {
      "epoch": 6.629171353580802,
      "grad_norm": 0.010345143266022205,
      "learning_rate": 1.3370828646419198e-05,
      "loss": 0.0096,
      "step": 17680
    },
    {
      "epoch": 6.632920884889389,
      "grad_norm": 0.08817724883556366,
      "learning_rate": 1.3367079115110612e-05,
      "loss": 0.0275,
      "step": 17690
    },
    {
      "epoch": 6.636670416197975,
      "grad_norm": 12.830486297607422,
      "learning_rate": 1.3363329583802025e-05,
      "loss": 0.0155,
      "step": 17700
    },
    {
      "epoch": 6.640419947506562,
      "grad_norm": 1.3285894393920898,
      "learning_rate": 1.3359580052493439e-05,
      "loss": 0.0307,
      "step": 17710
    },
    {
      "epoch": 6.644169478815148,
      "grad_norm": 0.016511520370841026,
      "learning_rate": 1.3355830521184853e-05,
      "loss": 0.0184,
      "step": 17720
    },
    {
      "epoch": 6.647919010123735,
      "grad_norm": 0.823247492313385,
      "learning_rate": 1.3352080989876266e-05,
      "loss": 0.0095,
      "step": 17730
    },
    {
      "epoch": 6.651668541432321,
      "grad_norm": 0.728737473487854,
      "learning_rate": 1.334833145856768e-05,
      "loss": 0.038,
      "step": 17740
    },
    {
      "epoch": 6.655418072740908,
      "grad_norm": 4.393097877502441,
      "learning_rate": 1.3344581927259092e-05,
      "loss": 0.0082,
      "step": 17750
    },
    {
      "epoch": 6.659167604049494,
      "grad_norm": 0.007358878385275602,
      "learning_rate": 1.3340832395950507e-05,
      "loss": 0.004,
      "step": 17760
    },
    {
      "epoch": 6.6629171353580805,
      "grad_norm": 0.010207392275333405,
      "learning_rate": 1.333708286464192e-05,
      "loss": 0.018,
      "step": 17770
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.015711534768342972,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0099,
      "step": 17780
    },
    {
      "epoch": 6.670416197975253,
      "grad_norm": 0.002592934761196375,
      "learning_rate": 1.3329583802024747e-05,
      "loss": 0.0129,
      "step": 17790
    },
    {
      "epoch": 6.67416572928384,
      "grad_norm": 0.669880747795105,
      "learning_rate": 1.3325834270716163e-05,
      "loss": 0.0202,
      "step": 17800
    },
    {
      "epoch": 6.677915260592426,
      "grad_norm": 0.009802143089473248,
      "learning_rate": 1.3322084739407574e-05,
      "loss": 0.0035,
      "step": 17810
    },
    {
      "epoch": 6.681664791901012,
      "grad_norm": 1.2180263996124268,
      "learning_rate": 1.3318335208098988e-05,
      "loss": 0.0052,
      "step": 17820
    },
    {
      "epoch": 6.685414323209599,
      "grad_norm": 0.2468727082014084,
      "learning_rate": 1.33145856767904e-05,
      "loss": 0.0113,
      "step": 17830
    },
    {
      "epoch": 6.689163854518185,
      "grad_norm": 0.1370810866355896,
      "learning_rate": 1.3310836145481815e-05,
      "loss": 0.0228,
      "step": 17840
    },
    {
      "epoch": 6.692913385826771,
      "grad_norm": 0.057155925780534744,
      "learning_rate": 1.3307086614173231e-05,
      "loss": 0.0038,
      "step": 17850
    },
    {
      "epoch": 6.696662917135358,
      "grad_norm": 0.0012763419654220343,
      "learning_rate": 1.3303337082864642e-05,
      "loss": 0.0026,
      "step": 17860
    },
    {
      "epoch": 6.700412448443944,
      "grad_norm": 20.68486976623535,
      "learning_rate": 1.3299587551556058e-05,
      "loss": 0.0228,
      "step": 17870
    },
    {
      "epoch": 6.704161979752531,
      "grad_norm": 0.08320348709821701,
      "learning_rate": 1.3295838020247468e-05,
      "loss": 0.0068,
      "step": 17880
    },
    {
      "epoch": 6.707911511061117,
      "grad_norm": 0.24205148220062256,
      "learning_rate": 1.3292088488938884e-05,
      "loss": 0.0408,
      "step": 17890
    },
    {
      "epoch": 6.711661042369704,
      "grad_norm": 1.1030033826828003,
      "learning_rate": 1.3288338957630298e-05,
      "loss": 0.0129,
      "step": 17900
    },
    {
      "epoch": 6.71541057367829,
      "grad_norm": 0.7605140805244446,
      "learning_rate": 1.3284589426321711e-05,
      "loss": 0.0098,
      "step": 17910
    },
    {
      "epoch": 6.7191601049868765,
      "grad_norm": 0.0018776925280690193,
      "learning_rate": 1.3280839895013125e-05,
      "loss": 0.0082,
      "step": 17920
    },
    {
      "epoch": 6.722909636295463,
      "grad_norm": 0.013623298145830631,
      "learning_rate": 1.327709036370454e-05,
      "loss": 0.0124,
      "step": 17930
    },
    {
      "epoch": 6.7266591676040495,
      "grad_norm": 0.20209470391273499,
      "learning_rate": 1.3273340832395952e-05,
      "loss": 0.0055,
      "step": 17940
    },
    {
      "epoch": 6.730408698912636,
      "grad_norm": 9.108907699584961,
      "learning_rate": 1.3269591301087366e-05,
      "loss": 0.0166,
      "step": 17950
    },
    {
      "epoch": 6.734158230221222,
      "grad_norm": 1.5360822677612305,
      "learning_rate": 1.3265841769778779e-05,
      "loss": 0.0321,
      "step": 17960
    },
    {
      "epoch": 6.737907761529809,
      "grad_norm": 1.3266634941101074,
      "learning_rate": 1.3262092238470193e-05,
      "loss": 0.0144,
      "step": 17970
    },
    {
      "epoch": 6.741657292838395,
      "grad_norm": 0.0069264634512364864,
      "learning_rate": 1.3258342707161607e-05,
      "loss": 0.0212,
      "step": 17980
    },
    {
      "epoch": 6.745406824146982,
      "grad_norm": 0.03542326018214226,
      "learning_rate": 1.325459317585302e-05,
      "loss": 0.0208,
      "step": 17990
    },
    {
      "epoch": 6.749156355455568,
      "grad_norm": 12.274130821228027,
      "learning_rate": 1.3250843644544434e-05,
      "loss": 0.0262,
      "step": 18000
    },
    {
      "epoch": 6.752905886764155,
      "grad_norm": 0.003126428695395589,
      "learning_rate": 1.3247094113235848e-05,
      "loss": 0.0142,
      "step": 18010
    },
    {
      "epoch": 6.756655418072741,
      "grad_norm": 0.45058178901672363,
      "learning_rate": 1.324334458192726e-05,
      "loss": 0.0086,
      "step": 18020
    },
    {
      "epoch": 6.760404949381328,
      "grad_norm": 0.37893998622894287,
      "learning_rate": 1.3239595050618674e-05,
      "loss": 0.0092,
      "step": 18030
    },
    {
      "epoch": 6.764154480689914,
      "grad_norm": 0.021817846223711967,
      "learning_rate": 1.3235845519310087e-05,
      "loss": 0.037,
      "step": 18040
    },
    {
      "epoch": 6.767904011998501,
      "grad_norm": 0.7690982818603516,
      "learning_rate": 1.3232095988001501e-05,
      "loss": 0.0154,
      "step": 18050
    },
    {
      "epoch": 6.771653543307087,
      "grad_norm": 0.9292029142379761,
      "learning_rate": 1.3228346456692915e-05,
      "loss": 0.0239,
      "step": 18060
    },
    {
      "epoch": 6.775403074615673,
      "grad_norm": 0.8222754001617432,
      "learning_rate": 1.3224596925384328e-05,
      "loss": 0.024,
      "step": 18070
    },
    {
      "epoch": 6.77915260592426,
      "grad_norm": 0.3448076546192169,
      "learning_rate": 1.3220847394075742e-05,
      "loss": 0.0109,
      "step": 18080
    },
    {
      "epoch": 6.7829021372328455,
      "grad_norm": 0.005321567412465811,
      "learning_rate": 1.3217097862767154e-05,
      "loss": 0.0166,
      "step": 18090
    },
    {
      "epoch": 6.786651668541432,
      "grad_norm": 0.9335528612136841,
      "learning_rate": 1.3213348331458569e-05,
      "loss": 0.015,
      "step": 18100
    },
    {
      "epoch": 6.790401199850018,
      "grad_norm": 0.5925849676132202,
      "learning_rate": 1.3209598800149983e-05,
      "loss": 0.0282,
      "step": 18110
    },
    {
      "epoch": 6.794150731158605,
      "grad_norm": 1.3592623472213745,
      "learning_rate": 1.3205849268841395e-05,
      "loss": 0.0172,
      "step": 18120
    },
    {
      "epoch": 6.797900262467191,
      "grad_norm": 0.9614720344543457,
      "learning_rate": 1.320209973753281e-05,
      "loss": 0.0068,
      "step": 18130
    },
    {
      "epoch": 6.801649793775778,
      "grad_norm": 5.492603302001953,
      "learning_rate": 1.3198350206224224e-05,
      "loss": 0.0304,
      "step": 18140
    },
    {
      "epoch": 6.805399325084364,
      "grad_norm": 0.15016505122184753,
      "learning_rate": 1.3194600674915636e-05,
      "loss": 0.0283,
      "step": 18150
    },
    {
      "epoch": 6.809148856392951,
      "grad_norm": 1.7230333089828491,
      "learning_rate": 1.319085114360705e-05,
      "loss": 0.0081,
      "step": 18160
    },
    {
      "epoch": 6.812898387701537,
      "grad_norm": 0.007725994568318129,
      "learning_rate": 1.3187101612298463e-05,
      "loss": 0.0029,
      "step": 18170
    },
    {
      "epoch": 6.816647919010124,
      "grad_norm": 0.014110145159065723,
      "learning_rate": 1.3183352080989877e-05,
      "loss": 0.0238,
      "step": 18180
    },
    {
      "epoch": 6.82039745031871,
      "grad_norm": 0.09630335122346878,
      "learning_rate": 1.3179602549681291e-05,
      "loss": 0.0187,
      "step": 18190
    },
    {
      "epoch": 6.824146981627297,
      "grad_norm": 0.009949288330972195,
      "learning_rate": 1.3175853018372704e-05,
      "loss": 0.0245,
      "step": 18200
    },
    {
      "epoch": 6.827896512935883,
      "grad_norm": 0.04113001003861427,
      "learning_rate": 1.3172103487064118e-05,
      "loss": 0.0083,
      "step": 18210
    },
    {
      "epoch": 6.8316460442444695,
      "grad_norm": 0.021118370816111565,
      "learning_rate": 1.316835395575553e-05,
      "loss": 0.0073,
      "step": 18220
    },
    {
      "epoch": 6.835395575553056,
      "grad_norm": 0.4161348044872284,
      "learning_rate": 1.3164604424446945e-05,
      "loss": 0.0243,
      "step": 18230
    },
    {
      "epoch": 6.8391451068616425,
      "grad_norm": 0.07679475098848343,
      "learning_rate": 1.3160854893138359e-05,
      "loss": 0.0134,
      "step": 18240
    },
    {
      "epoch": 6.842894638170229,
      "grad_norm": 1.2640469074249268,
      "learning_rate": 1.3157105361829771e-05,
      "loss": 0.0117,
      "step": 18250
    },
    {
      "epoch": 6.846644169478815,
      "grad_norm": 2.630815267562866,
      "learning_rate": 1.3153355830521186e-05,
      "loss": 0.0235,
      "step": 18260
    },
    {
      "epoch": 6.850393700787402,
      "grad_norm": 0.20571553707122803,
      "learning_rate": 1.3149606299212601e-05,
      "loss": 0.0196,
      "step": 18270
    },
    {
      "epoch": 6.854143232095988,
      "grad_norm": 0.09140318632125854,
      "learning_rate": 1.3145856767904012e-05,
      "loss": 0.0191,
      "step": 18280
    },
    {
      "epoch": 6.857892763404575,
      "grad_norm": 0.28179892897605896,
      "learning_rate": 1.3142107236595426e-05,
      "loss": 0.0223,
      "step": 18290
    },
    {
      "epoch": 6.861642294713161,
      "grad_norm": 0.03430181369185448,
      "learning_rate": 1.3138357705286839e-05,
      "loss": 0.029,
      "step": 18300
    },
    {
      "epoch": 6.865391826021748,
      "grad_norm": 2.0343821048736572,
      "learning_rate": 1.3134608173978253e-05,
      "loss": 0.014,
      "step": 18310
    },
    {
      "epoch": 6.869141357330333,
      "grad_norm": 3.1222329139709473,
      "learning_rate": 1.3130858642669669e-05,
      "loss": 0.0186,
      "step": 18320
    },
    {
      "epoch": 6.872890888638921,
      "grad_norm": 0.12131443619728088,
      "learning_rate": 1.312710911136108e-05,
      "loss": 0.0145,
      "step": 18330
    },
    {
      "epoch": 6.876640419947506,
      "grad_norm": 0.029216283932328224,
      "learning_rate": 1.3123359580052496e-05,
      "loss": 0.0148,
      "step": 18340
    },
    {
      "epoch": 6.880389951256093,
      "grad_norm": 0.045018818229436874,
      "learning_rate": 1.3119610048743906e-05,
      "loss": 0.0108,
      "step": 18350
    },
    {
      "epoch": 6.884139482564679,
      "grad_norm": 0.9268301725387573,
      "learning_rate": 1.3115860517435322e-05,
      "loss": 0.0063,
      "step": 18360
    },
    {
      "epoch": 6.887889013873266,
      "grad_norm": 0.01729077845811844,
      "learning_rate": 1.3112110986126736e-05,
      "loss": 0.0021,
      "step": 18370
    },
    {
      "epoch": 6.891638545181852,
      "grad_norm": 0.18304914236068726,
      "learning_rate": 1.3108361454818149e-05,
      "loss": 0.014,
      "step": 18380
    },
    {
      "epoch": 6.8953880764904385,
      "grad_norm": 0.0026245107874274254,
      "learning_rate": 1.3104611923509563e-05,
      "loss": 0.0089,
      "step": 18390
    },
    {
      "epoch": 6.899137607799025,
      "grad_norm": 0.006405457388609648,
      "learning_rate": 1.3100862392200977e-05,
      "loss": 0.0211,
      "step": 18400
    },
    {
      "epoch": 6.902887139107611,
      "grad_norm": 0.006665460765361786,
      "learning_rate": 1.309711286089239e-05,
      "loss": 0.0219,
      "step": 18410
    },
    {
      "epoch": 6.906636670416198,
      "grad_norm": 0.001962886657565832,
      "learning_rate": 1.3093363329583804e-05,
      "loss": 0.0089,
      "step": 18420
    },
    {
      "epoch": 6.910386201724784,
      "grad_norm": 0.5627968311309814,
      "learning_rate": 1.3089613798275217e-05,
      "loss": 0.0056,
      "step": 18430
    },
    {
      "epoch": 6.914135733033371,
      "grad_norm": 0.009903649799525738,
      "learning_rate": 1.308586426696663e-05,
      "loss": 0.0053,
      "step": 18440
    },
    {
      "epoch": 6.917885264341957,
      "grad_norm": 0.004532288759946823,
      "learning_rate": 1.3082114735658045e-05,
      "loss": 0.0193,
      "step": 18450
    },
    {
      "epoch": 6.921634795650544,
      "grad_norm": 1.9315826892852783,
      "learning_rate": 1.3078365204349457e-05,
      "loss": 0.0153,
      "step": 18460
    },
    {
      "epoch": 6.92538432695913,
      "grad_norm": 0.46712616086006165,
      "learning_rate": 1.3074615673040872e-05,
      "loss": 0.0107,
      "step": 18470
    },
    {
      "epoch": 6.929133858267717,
      "grad_norm": 0.11297481507062912,
      "learning_rate": 1.3070866141732284e-05,
      "loss": 0.0134,
      "step": 18480
    },
    {
      "epoch": 6.932883389576303,
      "grad_norm": 3.5061912536621094,
      "learning_rate": 1.3067116610423698e-05,
      "loss": 0.0217,
      "step": 18490
    },
    {
      "epoch": 6.93663292088489,
      "grad_norm": 0.5438123941421509,
      "learning_rate": 1.3063367079115112e-05,
      "loss": 0.0358,
      "step": 18500
    },
    {
      "epoch": 6.940382452193476,
      "grad_norm": 0.03613436594605446,
      "learning_rate": 1.3059617547806525e-05,
      "loss": 0.0228,
      "step": 18510
    },
    {
      "epoch": 6.9441319835020625,
      "grad_norm": 0.5833883881568909,
      "learning_rate": 1.3055868016497939e-05,
      "loss": 0.0134,
      "step": 18520
    },
    {
      "epoch": 6.947881514810649,
      "grad_norm": 0.011579695157706738,
      "learning_rate": 1.3052118485189353e-05,
      "loss": 0.0117,
      "step": 18530
    },
    {
      "epoch": 6.951631046119235,
      "grad_norm": 0.007366333622485399,
      "learning_rate": 1.3048368953880766e-05,
      "loss": 0.0071,
      "step": 18540
    },
    {
      "epoch": 6.955380577427822,
      "grad_norm": 0.0037509161047637463,
      "learning_rate": 1.304461942257218e-05,
      "loss": 0.011,
      "step": 18550
    },
    {
      "epoch": 6.959130108736408,
      "grad_norm": 0.6728549599647522,
      "learning_rate": 1.3040869891263593e-05,
      "loss": 0.0294,
      "step": 18560
    },
    {
      "epoch": 6.962879640044994,
      "grad_norm": 0.04263385757803917,
      "learning_rate": 1.3037120359955007e-05,
      "loss": 0.0056,
      "step": 18570
    },
    {
      "epoch": 6.966629171353581,
      "grad_norm": 4.276421546936035,
      "learning_rate": 1.3033370828646421e-05,
      "loss": 0.0204,
      "step": 18580
    },
    {
      "epoch": 6.970378702662167,
      "grad_norm": 0.35529863834381104,
      "learning_rate": 1.3029621297337833e-05,
      "loss": 0.0185,
      "step": 18590
    },
    {
      "epoch": 6.974128233970753,
      "grad_norm": 0.0032499926164746284,
      "learning_rate": 1.3025871766029248e-05,
      "loss": 0.0148,
      "step": 18600
    },
    {
      "epoch": 6.97787776527934,
      "grad_norm": 2.000962495803833,
      "learning_rate": 1.302212223472066e-05,
      "loss": 0.0153,
      "step": 18610
    },
    {
      "epoch": 6.981627296587926,
      "grad_norm": 1.1322720050811768,
      "learning_rate": 1.3018372703412074e-05,
      "loss": 0.0182,
      "step": 18620
    },
    {
      "epoch": 6.985376827896513,
      "grad_norm": 0.9160913825035095,
      "learning_rate": 1.3014623172103488e-05,
      "loss": 0.0223,
      "step": 18630
    },
    {
      "epoch": 6.989126359205099,
      "grad_norm": 0.5659048557281494,
      "learning_rate": 1.3010873640794901e-05,
      "loss": 0.0036,
      "step": 18640
    },
    {
      "epoch": 6.992875890513686,
      "grad_norm": 3.8079633712768555,
      "learning_rate": 1.3007124109486315e-05,
      "loss": 0.0314,
      "step": 18650
    },
    {
      "epoch": 6.996625421822272,
      "grad_norm": 0.01079242117702961,
      "learning_rate": 1.300337457817773e-05,
      "loss": 0.016,
      "step": 18660
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.991761446485856,
      "eval_f1": 0.9684885666480759,
      "eval_loss": 0.023692050948739052,
      "eval_precision": 0.9607192254495159,
      "eval_recall": 0.9763845937587855,
      "eval_runtime": 873.0704,
      "eval_samples_per_second": 31.421,
      "eval_steps_per_second": 1.31,
      "step": 18669
    },
    {
      "epoch": 7.000374953130859,
      "grad_norm": 0.04712784290313721,
      "learning_rate": 1.2999625046869142e-05,
      "loss": 0.0296,
      "step": 18670
    },
    {
      "epoch": 7.004124484439445,
      "grad_norm": 0.38064849376678467,
      "learning_rate": 1.2995875515560556e-05,
      "loss": 0.0102,
      "step": 18680
    },
    {
      "epoch": 7.0078740157480315,
      "grad_norm": 0.6332159042358398,
      "learning_rate": 1.2992125984251968e-05,
      "loss": 0.0115,
      "step": 18690
    },
    {
      "epoch": 7.011623547056618,
      "grad_norm": 0.0046128747053444386,
      "learning_rate": 1.2988376452943383e-05,
      "loss": 0.0082,
      "step": 18700
    },
    {
      "epoch": 7.015373078365204,
      "grad_norm": 0.8661311268806458,
      "learning_rate": 1.2984626921634797e-05,
      "loss": 0.0071,
      "step": 18710
    },
    {
      "epoch": 7.019122609673791,
      "grad_norm": 0.00724447937682271,
      "learning_rate": 1.298087739032621e-05,
      "loss": 0.0245,
      "step": 18720
    },
    {
      "epoch": 7.022872140982377,
      "grad_norm": 0.4899517893791199,
      "learning_rate": 1.2977127859017624e-05,
      "loss": 0.0107,
      "step": 18730
    },
    {
      "epoch": 7.026621672290964,
      "grad_norm": 1.2160974740982056,
      "learning_rate": 1.2973378327709036e-05,
      "loss": 0.0124,
      "step": 18740
    },
    {
      "epoch": 7.03037120359955,
      "grad_norm": 0.020711630582809448,
      "learning_rate": 1.296962879640045e-05,
      "loss": 0.0101,
      "step": 18750
    },
    {
      "epoch": 7.034120734908137,
      "grad_norm": 0.2754174768924713,
      "learning_rate": 1.2965879265091864e-05,
      "loss": 0.0152,
      "step": 18760
    },
    {
      "epoch": 7.037870266216723,
      "grad_norm": 0.4832399785518646,
      "learning_rate": 1.2962129733783277e-05,
      "loss": 0.0159,
      "step": 18770
    },
    {
      "epoch": 7.04161979752531,
      "grad_norm": 0.008049610070884228,
      "learning_rate": 1.2958380202474691e-05,
      "loss": 0.0044,
      "step": 18780
    },
    {
      "epoch": 7.045369328833896,
      "grad_norm": 0.0026435607578605413,
      "learning_rate": 1.2954630671166107e-05,
      "loss": 0.0241,
      "step": 18790
    },
    {
      "epoch": 7.049118860142483,
      "grad_norm": 0.9349678158760071,
      "learning_rate": 1.2950881139857518e-05,
      "loss": 0.0045,
      "step": 18800
    },
    {
      "epoch": 7.052868391451069,
      "grad_norm": 2.2283241748809814,
      "learning_rate": 1.2947131608548934e-05,
      "loss": 0.0234,
      "step": 18810
    },
    {
      "epoch": 7.056617922759655,
      "grad_norm": 0.05764419212937355,
      "learning_rate": 1.2943382077240344e-05,
      "loss": 0.0047,
      "step": 18820
    },
    {
      "epoch": 7.060367454068241,
      "grad_norm": 0.0029324705246835947,
      "learning_rate": 1.293963254593176e-05,
      "loss": 0.0265,
      "step": 18830
    },
    {
      "epoch": 7.0641169853768275,
      "grad_norm": 3.0390260219573975,
      "learning_rate": 1.2935883014623175e-05,
      "loss": 0.0175,
      "step": 18840
    },
    {
      "epoch": 7.067866516685414,
      "grad_norm": 0.007604372687637806,
      "learning_rate": 1.2932133483314587e-05,
      "loss": 0.0311,
      "step": 18850
    },
    {
      "epoch": 7.0716160479940005,
      "grad_norm": 0.005230959504842758,
      "learning_rate": 1.2928383952006001e-05,
      "loss": 0.004,
      "step": 18860
    },
    {
      "epoch": 7.075365579302587,
      "grad_norm": 0.4519985318183899,
      "learning_rate": 1.2924634420697412e-05,
      "loss": 0.0073,
      "step": 18870
    },
    {
      "epoch": 7.079115110611173,
      "grad_norm": 0.010072123259305954,
      "learning_rate": 1.2920884889388828e-05,
      "loss": 0.0065,
      "step": 18880
    },
    {
      "epoch": 7.08286464191976,
      "grad_norm": 0.9070951342582703,
      "learning_rate": 1.2917135358080242e-05,
      "loss": 0.0171,
      "step": 18890
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.013990696519613266,
      "learning_rate": 1.2913385826771655e-05,
      "loss": 0.0269,
      "step": 18900
    },
    {
      "epoch": 7.090363704536933,
      "grad_norm": 0.00479618227109313,
      "learning_rate": 1.2909636295463069e-05,
      "loss": 0.0102,
      "step": 18910
    },
    {
      "epoch": 7.094113235845519,
      "grad_norm": 0.7614030241966248,
      "learning_rate": 1.2905886764154483e-05,
      "loss": 0.0124,
      "step": 18920
    },
    {
      "epoch": 7.097862767154106,
      "grad_norm": 1.630900502204895,
      "learning_rate": 1.2902137232845895e-05,
      "loss": 0.0338,
      "step": 18930
    },
    {
      "epoch": 7.101612298462692,
      "grad_norm": 0.6725981831550598,
      "learning_rate": 1.289838770153731e-05,
      "loss": 0.025,
      "step": 18940
    },
    {
      "epoch": 7.105361829771279,
      "grad_norm": 0.0034444406628608704,
      "learning_rate": 1.2894638170228722e-05,
      "loss": 0.0142,
      "step": 18950
    },
    {
      "epoch": 7.109111361079865,
      "grad_norm": 0.775262176990509,
      "learning_rate": 1.2890888638920136e-05,
      "loss": 0.0048,
      "step": 18960
    },
    {
      "epoch": 7.1128608923884515,
      "grad_norm": 0.9082639813423157,
      "learning_rate": 1.288713910761155e-05,
      "loss": 0.0137,
      "step": 18970
    },
    {
      "epoch": 7.116610423697038,
      "grad_norm": 0.0027335858903825283,
      "learning_rate": 1.2883389576302963e-05,
      "loss": 0.0269,
      "step": 18980
    },
    {
      "epoch": 7.1203599550056245,
      "grad_norm": 0.03306083753705025,
      "learning_rate": 1.2879640044994377e-05,
      "loss": 0.0257,
      "step": 18990
    },
    {
      "epoch": 7.124109486314211,
      "grad_norm": 0.8741517066955566,
      "learning_rate": 1.287589051368579e-05,
      "loss": 0.0204,
      "step": 19000
    },
    {
      "epoch": 7.127859017622797,
      "grad_norm": 2.4537203311920166,
      "learning_rate": 1.2872140982377204e-05,
      "loss": 0.0505,
      "step": 19010
    },
    {
      "epoch": 7.131608548931384,
      "grad_norm": 0.04544834792613983,
      "learning_rate": 1.2868391451068618e-05,
      "loss": 0.0121,
      "step": 19020
    },
    {
      "epoch": 7.13535808023997,
      "grad_norm": 0.9464208483695984,
      "learning_rate": 1.286464191976003e-05,
      "loss": 0.0074,
      "step": 19030
    },
    {
      "epoch": 7.139107611548557,
      "grad_norm": 0.0682806596159935,
      "learning_rate": 1.2860892388451445e-05,
      "loss": 0.0095,
      "step": 19040
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.010735630989074707,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 0.005,
      "step": 19050
    },
    {
      "epoch": 7.14660667416573,
      "grad_norm": 0.4870723783969879,
      "learning_rate": 1.2853393325834271e-05,
      "loss": 0.0123,
      "step": 19060
    },
    {
      "epoch": 7.150356205474315,
      "grad_norm": 0.7533687353134155,
      "learning_rate": 1.2849643794525686e-05,
      "loss": 0.0337,
      "step": 19070
    },
    {
      "epoch": 7.154105736782902,
      "grad_norm": 0.030499210581183434,
      "learning_rate": 1.2845894263217098e-05,
      "loss": 0.0054,
      "step": 19080
    },
    {
      "epoch": 7.157855268091488,
      "grad_norm": 1.138456106185913,
      "learning_rate": 1.2842144731908512e-05,
      "loss": 0.0198,
      "step": 19090
    },
    {
      "epoch": 7.161604799400075,
      "grad_norm": 0.08370553702116013,
      "learning_rate": 1.2838395200599926e-05,
      "loss": 0.019,
      "step": 19100
    },
    {
      "epoch": 7.165354330708661,
      "grad_norm": 0.012242329306900501,
      "learning_rate": 1.2834645669291339e-05,
      "loss": 0.0021,
      "step": 19110
    },
    {
      "epoch": 7.169103862017248,
      "grad_norm": 0.9938986301422119,
      "learning_rate": 1.2830896137982753e-05,
      "loss": 0.009,
      "step": 19120
    },
    {
      "epoch": 7.172853393325834,
      "grad_norm": 0.09555674344301224,
      "learning_rate": 1.2827146606674166e-05,
      "loss": 0.029,
      "step": 19130
    },
    {
      "epoch": 7.1766029246344205,
      "grad_norm": 0.009816812351346016,
      "learning_rate": 1.282339707536558e-05,
      "loss": 0.0021,
      "step": 19140
    },
    {
      "epoch": 7.180352455943007,
      "grad_norm": 1.122698426246643,
      "learning_rate": 1.2819647544056994e-05,
      "loss": 0.0098,
      "step": 19150
    },
    {
      "epoch": 7.184101987251593,
      "grad_norm": 0.9907193779945374,
      "learning_rate": 1.2815898012748407e-05,
      "loss": 0.0122,
      "step": 19160
    },
    {
      "epoch": 7.18785151856018,
      "grad_norm": 0.878593921661377,
      "learning_rate": 1.281214848143982e-05,
      "loss": 0.0066,
      "step": 19170
    },
    {
      "epoch": 7.191601049868766,
      "grad_norm": 0.004700973629951477,
      "learning_rate": 1.2808398950131235e-05,
      "loss": 0.0031,
      "step": 19180
    },
    {
      "epoch": 7.195350581177353,
      "grad_norm": 1.8634828329086304,
      "learning_rate": 1.2804649418822647e-05,
      "loss": 0.0203,
      "step": 19190
    },
    {
      "epoch": 7.199100112485939,
      "grad_norm": 1.392483115196228,
      "learning_rate": 1.2800899887514062e-05,
      "loss": 0.0078,
      "step": 19200
    },
    {
      "epoch": 7.202849643794526,
      "grad_norm": 0.008046268485486507,
      "learning_rate": 1.2797150356205474e-05,
      "loss": 0.0083,
      "step": 19210
    },
    {
      "epoch": 7.206599175103112,
      "grad_norm": 0.07745523750782013,
      "learning_rate": 1.2793400824896888e-05,
      "loss": 0.0033,
      "step": 19220
    },
    {
      "epoch": 7.210348706411699,
      "grad_norm": 0.6536927819252014,
      "learning_rate": 1.2789651293588302e-05,
      "loss": 0.0182,
      "step": 19230
    },
    {
      "epoch": 7.214098237720285,
      "grad_norm": 0.004954589996486902,
      "learning_rate": 1.2785901762279715e-05,
      "loss": 0.0129,
      "step": 19240
    },
    {
      "epoch": 7.217847769028872,
      "grad_norm": 0.0702250674366951,
      "learning_rate": 1.2782152230971129e-05,
      "loss": 0.0244,
      "step": 19250
    },
    {
      "epoch": 7.221597300337458,
      "grad_norm": 0.05274021998047829,
      "learning_rate": 1.2778402699662545e-05,
      "loss": 0.0127,
      "step": 19260
    },
    {
      "epoch": 7.2253468316460445,
      "grad_norm": 0.8477676510810852,
      "learning_rate": 1.2774653168353956e-05,
      "loss": 0.0207,
      "step": 19270
    },
    {
      "epoch": 7.229096362954631,
      "grad_norm": 0.008469369262456894,
      "learning_rate": 1.2770903637045372e-05,
      "loss": 0.0157,
      "step": 19280
    },
    {
      "epoch": 7.2328458942632174,
      "grad_norm": 0.014296887442469597,
      "learning_rate": 1.2767154105736782e-05,
      "loss": 0.0192,
      "step": 19290
    },
    {
      "epoch": 7.236595425571804,
      "grad_norm": 0.01863701455295086,
      "learning_rate": 1.2763404574428198e-05,
      "loss": 0.0096,
      "step": 19300
    },
    {
      "epoch": 7.24034495688039,
      "grad_norm": 1.037563681602478,
      "learning_rate": 1.2759655043119613e-05,
      "loss": 0.0171,
      "step": 19310
    },
    {
      "epoch": 7.244094488188976,
      "grad_norm": 1.5571708679199219,
      "learning_rate": 1.2755905511811025e-05,
      "loss": 0.0143,
      "step": 19320
    },
    {
      "epoch": 7.247844019497562,
      "grad_norm": 0.014955870807170868,
      "learning_rate": 1.275215598050244e-05,
      "loss": 0.0098,
      "step": 19330
    },
    {
      "epoch": 7.251593550806149,
      "grad_norm": 0.8851572275161743,
      "learning_rate": 1.274840644919385e-05,
      "loss": 0.0107,
      "step": 19340
    },
    {
      "epoch": 7.255343082114735,
      "grad_norm": 0.46500852704048157,
      "learning_rate": 1.2744656917885266e-05,
      "loss": 0.0192,
      "step": 19350
    },
    {
      "epoch": 7.259092613423322,
      "grad_norm": 0.013157935813069344,
      "learning_rate": 1.274090738657668e-05,
      "loss": 0.0057,
      "step": 19360
    },
    {
      "epoch": 7.262842144731908,
      "grad_norm": 0.49654483795166016,
      "learning_rate": 1.2737157855268093e-05,
      "loss": 0.0171,
      "step": 19370
    },
    {
      "epoch": 7.266591676040495,
      "grad_norm": 0.024901527911424637,
      "learning_rate": 1.2733408323959507e-05,
      "loss": 0.0179,
      "step": 19380
    },
    {
      "epoch": 7.270341207349081,
      "grad_norm": 0.0036304895766079426,
      "learning_rate": 1.2729658792650921e-05,
      "loss": 0.0151,
      "step": 19390
    },
    {
      "epoch": 7.274090738657668,
      "grad_norm": 0.5078441500663757,
      "learning_rate": 1.2725909261342333e-05,
      "loss": 0.012,
      "step": 19400
    },
    {
      "epoch": 7.277840269966254,
      "grad_norm": 0.025018444284796715,
      "learning_rate": 1.2722159730033748e-05,
      "loss": 0.0118,
      "step": 19410
    },
    {
      "epoch": 7.281589801274841,
      "grad_norm": 1.014723300933838,
      "learning_rate": 1.271841019872516e-05,
      "loss": 0.0069,
      "step": 19420
    },
    {
      "epoch": 7.285339332583427,
      "grad_norm": 3.093834638595581,
      "learning_rate": 1.2714660667416574e-05,
      "loss": 0.0421,
      "step": 19430
    },
    {
      "epoch": 7.2890888638920135,
      "grad_norm": 1.5659538507461548,
      "learning_rate": 1.2710911136107989e-05,
      "loss": 0.0229,
      "step": 19440
    },
    {
      "epoch": 7.2928383952006,
      "grad_norm": 0.010704564861953259,
      "learning_rate": 1.2707161604799401e-05,
      "loss": 0.0231,
      "step": 19450
    },
    {
      "epoch": 7.296587926509186,
      "grad_norm": 0.11258269846439362,
      "learning_rate": 1.2703412073490815e-05,
      "loss": 0.0137,
      "step": 19460
    },
    {
      "epoch": 7.300337457817773,
      "grad_norm": 0.009867755696177483,
      "learning_rate": 1.2699662542182228e-05,
      "loss": 0.0067,
      "step": 19470
    },
    {
      "epoch": 7.304086989126359,
      "grad_norm": 0.013344025239348412,
      "learning_rate": 1.2695913010873642e-05,
      "loss": 0.0054,
      "step": 19480
    },
    {
      "epoch": 7.307836520434946,
      "grad_norm": 0.00330159324221313,
      "learning_rate": 1.2692163479565056e-05,
      "loss": 0.0224,
      "step": 19490
    },
    {
      "epoch": 7.311586051743532,
      "grad_norm": 0.00660248938947916,
      "learning_rate": 1.2688413948256469e-05,
      "loss": 0.0081,
      "step": 19500
    },
    {
      "epoch": 7.315335583052119,
      "grad_norm": 0.006164469290524721,
      "learning_rate": 1.2684664416947883e-05,
      "loss": 0.0074,
      "step": 19510
    },
    {
      "epoch": 7.319085114360705,
      "grad_norm": 3.6985020637512207,
      "learning_rate": 1.2680914885639297e-05,
      "loss": 0.0254,
      "step": 19520
    },
    {
      "epoch": 7.322834645669292,
      "grad_norm": 0.016805000603199005,
      "learning_rate": 1.267716535433071e-05,
      "loss": 0.0116,
      "step": 19530
    },
    {
      "epoch": 7.326584176977878,
      "grad_norm": 3.0367631912231445,
      "learning_rate": 1.2673415823022124e-05,
      "loss": 0.0253,
      "step": 19540
    },
    {
      "epoch": 7.330333708286465,
      "grad_norm": 5.227891445159912,
      "learning_rate": 1.2669666291713536e-05,
      "loss": 0.0231,
      "step": 19550
    },
    {
      "epoch": 7.334083239595051,
      "grad_norm": 0.006631135009229183,
      "learning_rate": 1.266591676040495e-05,
      "loss": 0.0047,
      "step": 19560
    },
    {
      "epoch": 7.337832770903637,
      "grad_norm": 1.0750199556350708,
      "learning_rate": 1.2662167229096365e-05,
      "loss": 0.0269,
      "step": 19570
    },
    {
      "epoch": 7.341582302212223,
      "grad_norm": 0.08169036358594894,
      "learning_rate": 1.2658417697787777e-05,
      "loss": 0.0124,
      "step": 19580
    },
    {
      "epoch": 7.3453318335208095,
      "grad_norm": 0.032129447907209396,
      "learning_rate": 1.2654668166479191e-05,
      "loss": 0.0148,
      "step": 19590
    },
    {
      "epoch": 7.349081364829396,
      "grad_norm": 1.0955023765563965,
      "learning_rate": 1.2650918635170604e-05,
      "loss": 0.0138,
      "step": 19600
    },
    {
      "epoch": 7.3528308961379825,
      "grad_norm": 3.316042184829712,
      "learning_rate": 1.2647169103862018e-05,
      "loss": 0.0232,
      "step": 19610
    },
    {
      "epoch": 7.356580427446569,
      "grad_norm": 0.03688868507742882,
      "learning_rate": 1.2643419572553432e-05,
      "loss": 0.009,
      "step": 19620
    },
    {
      "epoch": 7.360329958755155,
      "grad_norm": 0.01078386977314949,
      "learning_rate": 1.2639670041244845e-05,
      "loss": 0.0275,
      "step": 19630
    },
    {
      "epoch": 7.364079490063742,
      "grad_norm": 0.011919789016246796,
      "learning_rate": 1.2635920509936259e-05,
      "loss": 0.0004,
      "step": 19640
    },
    {
      "epoch": 7.367829021372328,
      "grad_norm": 0.4359992742538452,
      "learning_rate": 1.2632170978627673e-05,
      "loss": 0.0182,
      "step": 19650
    },
    {
      "epoch": 7.371578552680915,
      "grad_norm": 0.012160953134298325,
      "learning_rate": 1.2628421447319085e-05,
      "loss": 0.0026,
      "step": 19660
    },
    {
      "epoch": 7.375328083989501,
      "grad_norm": 0.025213543325662613,
      "learning_rate": 1.26246719160105e-05,
      "loss": 0.0036,
      "step": 19670
    },
    {
      "epoch": 7.379077615298088,
      "grad_norm": 2.9614646434783936,
      "learning_rate": 1.2620922384701912e-05,
      "loss": 0.0135,
      "step": 19680
    },
    {
      "epoch": 7.382827146606674,
      "grad_norm": 0.719713032245636,
      "learning_rate": 1.2617172853393326e-05,
      "loss": 0.0297,
      "step": 19690
    },
    {
      "epoch": 7.386576677915261,
      "grad_norm": 0.007589756976813078,
      "learning_rate": 1.261342332208474e-05,
      "loss": 0.0037,
      "step": 19700
    },
    {
      "epoch": 7.390326209223847,
      "grad_norm": 0.04228142648935318,
      "learning_rate": 1.2609673790776153e-05,
      "loss": 0.0134,
      "step": 19710
    },
    {
      "epoch": 7.3940757405324335,
      "grad_norm": 0.005381056573241949,
      "learning_rate": 1.2605924259467567e-05,
      "loss": 0.0071,
      "step": 19720
    },
    {
      "epoch": 7.39782527184102,
      "grad_norm": 0.009169062599539757,
      "learning_rate": 1.260217472815898e-05,
      "loss": 0.0164,
      "step": 19730
    },
    {
      "epoch": 7.4015748031496065,
      "grad_norm": 0.003858765121549368,
      "learning_rate": 1.2598425196850394e-05,
      "loss": 0.0075,
      "step": 19740
    },
    {
      "epoch": 7.405324334458193,
      "grad_norm": 0.0024230012204498053,
      "learning_rate": 1.259467566554181e-05,
      "loss": 0.0006,
      "step": 19750
    },
    {
      "epoch": 7.409073865766779,
      "grad_norm": 0.028269993141293526,
      "learning_rate": 1.259092613423322e-05,
      "loss": 0.013,
      "step": 19760
    },
    {
      "epoch": 7.412823397075366,
      "grad_norm": 0.01526995562016964,
      "learning_rate": 1.2587176602924636e-05,
      "loss": 0.0094,
      "step": 19770
    },
    {
      "epoch": 7.416572928383952,
      "grad_norm": 4.959786891937256,
      "learning_rate": 1.258342707161605e-05,
      "loss": 0.0265,
      "step": 19780
    },
    {
      "epoch": 7.420322459692539,
      "grad_norm": 0.8525492548942566,
      "learning_rate": 1.2579677540307463e-05,
      "loss": 0.018,
      "step": 19790
    },
    {
      "epoch": 7.424071991001125,
      "grad_norm": 0.4915194511413574,
      "learning_rate": 1.2575928008998877e-05,
      "loss": 0.018,
      "step": 19800
    },
    {
      "epoch": 7.427821522309712,
      "grad_norm": 9.352157592773438,
      "learning_rate": 1.2572178477690288e-05,
      "loss": 0.0221,
      "step": 19810
    },
    {
      "epoch": 7.431571053618297,
      "grad_norm": 0.008174970746040344,
      "learning_rate": 1.2568428946381704e-05,
      "loss": 0.003,
      "step": 19820
    },
    {
      "epoch": 7.435320584926884,
      "grad_norm": 0.5864478349685669,
      "learning_rate": 1.2564679415073118e-05,
      "loss": 0.0162,
      "step": 19830
    },
    {
      "epoch": 7.43907011623547,
      "grad_norm": 0.02047683857381344,
      "learning_rate": 1.256092988376453e-05,
      "loss": 0.0034,
      "step": 19840
    },
    {
      "epoch": 7.442819647544057,
      "grad_norm": 0.008549989201128483,
      "learning_rate": 1.2557180352455945e-05,
      "loss": 0.0209,
      "step": 19850
    },
    {
      "epoch": 7.446569178852643,
      "grad_norm": 0.6297338604927063,
      "learning_rate": 1.2553430821147357e-05,
      "loss": 0.0138,
      "step": 19860
    },
    {
      "epoch": 7.45031871016123,
      "grad_norm": 0.004946735221892595,
      "learning_rate": 1.2549681289838772e-05,
      "loss": 0.015,
      "step": 19870
    },
    {
      "epoch": 7.454068241469816,
      "grad_norm": 0.002826159354299307,
      "learning_rate": 1.2545931758530186e-05,
      "loss": 0.0044,
      "step": 19880
    },
    {
      "epoch": 7.4578177727784025,
      "grad_norm": 0.052293356508016586,
      "learning_rate": 1.2542182227221598e-05,
      "loss": 0.0045,
      "step": 19890
    },
    {
      "epoch": 7.461567304086989,
      "grad_norm": 0.24251338839530945,
      "learning_rate": 1.2538432695913012e-05,
      "loss": 0.0099,
      "step": 19900
    },
    {
      "epoch": 7.4653168353955754,
      "grad_norm": 0.011086923070251942,
      "learning_rate": 1.2534683164604427e-05,
      "loss": 0.017,
      "step": 19910
    },
    {
      "epoch": 7.469066366704162,
      "grad_norm": 7.364962577819824,
      "learning_rate": 1.2530933633295839e-05,
      "loss": 0.0514,
      "step": 19920
    },
    {
      "epoch": 7.472815898012748,
      "grad_norm": 0.0015887973131611943,
      "learning_rate": 1.2527184101987253e-05,
      "loss": 0.0091,
      "step": 19930
    },
    {
      "epoch": 7.476565429321335,
      "grad_norm": 0.7543975114822388,
      "learning_rate": 1.2523434570678666e-05,
      "loss": 0.0305,
      "step": 19940
    },
    {
      "epoch": 7.480314960629921,
      "grad_norm": 0.02058333344757557,
      "learning_rate": 1.251968503937008e-05,
      "loss": 0.0204,
      "step": 19950
    },
    {
      "epoch": 7.484064491938508,
      "grad_norm": 0.39650940895080566,
      "learning_rate": 1.2515935508061494e-05,
      "loss": 0.0134,
      "step": 19960
    },
    {
      "epoch": 7.487814023247094,
      "grad_norm": 1.3468866348266602,
      "learning_rate": 1.2512185976752907e-05,
      "loss": 0.0184,
      "step": 19970
    },
    {
      "epoch": 7.491563554555681,
      "grad_norm": 0.005492254626005888,
      "learning_rate": 1.250843644544432e-05,
      "loss": 0.0155,
      "step": 19980
    },
    {
      "epoch": 7.495313085864267,
      "grad_norm": 0.07792925834655762,
      "learning_rate": 1.2504686914135733e-05,
      "loss": 0.0035,
      "step": 19990
    },
    {
      "epoch": 7.499062617172854,
      "grad_norm": 2.246448040008545,
      "learning_rate": 1.2500937382827147e-05,
      "loss": 0.0346,
      "step": 20000
    },
    {
      "epoch": 7.50281214848144,
      "grad_norm": 0.002209794707596302,
      "learning_rate": 1.2497187851518562e-05,
      "loss": 0.0102,
      "step": 20010
    },
    {
      "epoch": 7.5065616797900265,
      "grad_norm": 0.002141625387594104,
      "learning_rate": 1.2493438320209974e-05,
      "loss": 0.0097,
      "step": 20020
    },
    {
      "epoch": 7.510311211098613,
      "grad_norm": 0.6938466429710388,
      "learning_rate": 1.2489688788901388e-05,
      "loss": 0.0058,
      "step": 20030
    },
    {
      "epoch": 7.5140607424071995,
      "grad_norm": 0.12375852465629578,
      "learning_rate": 1.2485939257592803e-05,
      "loss": 0.0045,
      "step": 20040
    },
    {
      "epoch": 7.517810273715785,
      "grad_norm": 2.1766648292541504,
      "learning_rate": 1.2482189726284215e-05,
      "loss": 0.0312,
      "step": 20050
    },
    {
      "epoch": 7.521559805024372,
      "grad_norm": 0.00728946877643466,
      "learning_rate": 1.247844019497563e-05,
      "loss": 0.0055,
      "step": 20060
    },
    {
      "epoch": 7.525309336332958,
      "grad_norm": 0.7398970127105713,
      "learning_rate": 1.2474690663667042e-05,
      "loss": 0.0136,
      "step": 20070
    },
    {
      "epoch": 7.529058867641545,
      "grad_norm": 0.07095910608768463,
      "learning_rate": 1.2470941132358456e-05,
      "loss": 0.0018,
      "step": 20080
    },
    {
      "epoch": 7.532808398950131,
      "grad_norm": 0.0017512203194200993,
      "learning_rate": 1.246719160104987e-05,
      "loss": 0.0381,
      "step": 20090
    },
    {
      "epoch": 7.536557930258717,
      "grad_norm": 1.080271601676941,
      "learning_rate": 1.2463442069741283e-05,
      "loss": 0.0134,
      "step": 20100
    },
    {
      "epoch": 7.540307461567304,
      "grad_norm": 0.00364877562969923,
      "learning_rate": 1.2459692538432697e-05,
      "loss": 0.0101,
      "step": 20110
    },
    {
      "epoch": 7.54405699287589,
      "grad_norm": 7.46533727645874,
      "learning_rate": 1.245594300712411e-05,
      "loss": 0.0112,
      "step": 20120
    },
    {
      "epoch": 7.547806524184477,
      "grad_norm": 0.616316556930542,
      "learning_rate": 1.2452193475815523e-05,
      "loss": 0.0069,
      "step": 20130
    },
    {
      "epoch": 7.551556055493063,
      "grad_norm": 0.0812593474984169,
      "learning_rate": 1.2448443944506938e-05,
      "loss": 0.0148,
      "step": 20140
    },
    {
      "epoch": 7.55530558680165,
      "grad_norm": 3.890458106994629,
      "learning_rate": 1.244469441319835e-05,
      "loss": 0.0197,
      "step": 20150
    },
    {
      "epoch": 7.559055118110236,
      "grad_norm": 0.057169344276189804,
      "learning_rate": 1.2440944881889764e-05,
      "loss": 0.011,
      "step": 20160
    },
    {
      "epoch": 7.562804649418823,
      "grad_norm": 0.0030430424958467484,
      "learning_rate": 1.2437195350581179e-05,
      "loss": 0.0169,
      "step": 20170
    },
    {
      "epoch": 7.566554180727409,
      "grad_norm": 4.038267135620117,
      "learning_rate": 1.2433445819272591e-05,
      "loss": 0.0357,
      "step": 20180
    },
    {
      "epoch": 7.5703037120359955,
      "grad_norm": 0.11305912584066391,
      "learning_rate": 1.2429696287964005e-05,
      "loss": 0.0254,
      "step": 20190
    },
    {
      "epoch": 7.574053243344582,
      "grad_norm": 0.021213645115494728,
      "learning_rate": 1.2425946756655418e-05,
      "loss": 0.0111,
      "step": 20200
    },
    {
      "epoch": 7.577802774653168,
      "grad_norm": 0.025759689509868622,
      "learning_rate": 1.2422197225346832e-05,
      "loss": 0.0122,
      "step": 20210
    },
    {
      "epoch": 7.581552305961755,
      "grad_norm": 4.311279773712158,
      "learning_rate": 1.2418447694038248e-05,
      "loss": 0.0199,
      "step": 20220
    },
    {
      "epoch": 7.585301837270341,
      "grad_norm": 0.003947551362216473,
      "learning_rate": 1.2414698162729659e-05,
      "loss": 0.0021,
      "step": 20230
    },
    {
      "epoch": 7.589051368578928,
      "grad_norm": 0.3854878544807434,
      "learning_rate": 1.2410948631421074e-05,
      "loss": 0.0022,
      "step": 20240
    },
    {
      "epoch": 7.592800899887514,
      "grad_norm": 0.8140202164649963,
      "learning_rate": 1.2407199100112485e-05,
      "loss": 0.0193,
      "step": 20250
    },
    {
      "epoch": 7.596550431196101,
      "grad_norm": 0.6673043370246887,
      "learning_rate": 1.2403449568803901e-05,
      "loss": 0.0059,
      "step": 20260
    },
    {
      "epoch": 7.600299962504687,
      "grad_norm": 0.008256502449512482,
      "learning_rate": 1.2399700037495315e-05,
      "loss": 0.0082,
      "step": 20270
    },
    {
      "epoch": 7.604049493813274,
      "grad_norm": 0.6979395747184753,
      "learning_rate": 1.2395950506186726e-05,
      "loss": 0.0063,
      "step": 20280
    },
    {
      "epoch": 7.60779902512186,
      "grad_norm": 0.30980855226516724,
      "learning_rate": 1.2392200974878142e-05,
      "loss": 0.0078,
      "step": 20290
    },
    {
      "epoch": 7.611548556430446,
      "grad_norm": 0.4942251741886139,
      "learning_rate": 1.2388451443569556e-05,
      "loss": 0.0019,
      "step": 20300
    },
    {
      "epoch": 7.615298087739033,
      "grad_norm": 0.8038011193275452,
      "learning_rate": 1.2384701912260969e-05,
      "loss": 0.0212,
      "step": 20310
    },
    {
      "epoch": 7.619047619047619,
      "grad_norm": 8.425140380859375,
      "learning_rate": 1.2380952380952383e-05,
      "loss": 0.0175,
      "step": 20320
    },
    {
      "epoch": 7.622797150356205,
      "grad_norm": 0.002104421379044652,
      "learning_rate": 1.2377202849643795e-05,
      "loss": 0.0059,
      "step": 20330
    },
    {
      "epoch": 7.6265466816647915,
      "grad_norm": 0.0019011258846148849,
      "learning_rate": 1.237345331833521e-05,
      "loss": 0.0142,
      "step": 20340
    },
    {
      "epoch": 7.630296212973378,
      "grad_norm": 0.20282714068889618,
      "learning_rate": 1.2369703787026624e-05,
      "loss": 0.0367,
      "step": 20350
    },
    {
      "epoch": 7.6340457442819645,
      "grad_norm": 2.152155876159668,
      "learning_rate": 1.2365954255718036e-05,
      "loss": 0.008,
      "step": 20360
    },
    {
      "epoch": 7.637795275590551,
      "grad_norm": 0.16844256222248077,
      "learning_rate": 1.236220472440945e-05,
      "loss": 0.008,
      "step": 20370
    },
    {
      "epoch": 7.641544806899137,
      "grad_norm": 0.006430326960980892,
      "learning_rate": 1.2358455193100865e-05,
      "loss": 0.0231,
      "step": 20380
    },
    {
      "epoch": 7.645294338207724,
      "grad_norm": 0.47502589225769043,
      "learning_rate": 1.2354705661792277e-05,
      "loss": 0.0392,
      "step": 20390
    },
    {
      "epoch": 7.64904386951631,
      "grad_norm": 1.6045268774032593,
      "learning_rate": 1.2350956130483691e-05,
      "loss": 0.0154,
      "step": 20400
    },
    {
      "epoch": 7.652793400824897,
      "grad_norm": 0.9877075552940369,
      "learning_rate": 1.2347206599175104e-05,
      "loss": 0.0144,
      "step": 20410
    },
    {
      "epoch": 7.656542932133483,
      "grad_norm": 1.0946595668792725,
      "learning_rate": 1.2343457067866518e-05,
      "loss": 0.0121,
      "step": 20420
    },
    {
      "epoch": 7.66029246344207,
      "grad_norm": 0.36156606674194336,
      "learning_rate": 1.2339707536557932e-05,
      "loss": 0.0098,
      "step": 20430
    },
    {
      "epoch": 7.664041994750656,
      "grad_norm": 0.0578644759953022,
      "learning_rate": 1.2335958005249345e-05,
      "loss": 0.0145,
      "step": 20440
    },
    {
      "epoch": 7.667791526059243,
      "grad_norm": 0.0012737297220155597,
      "learning_rate": 1.2332208473940759e-05,
      "loss": 0.0091,
      "step": 20450
    },
    {
      "epoch": 7.671541057367829,
      "grad_norm": 0.0023207170888781548,
      "learning_rate": 1.2328458942632171e-05,
      "loss": 0.001,
      "step": 20460
    },
    {
      "epoch": 7.675290588676416,
      "grad_norm": 0.0005164401372894645,
      "learning_rate": 1.2324709411323586e-05,
      "loss": 0.0055,
      "step": 20470
    },
    {
      "epoch": 7.679040119985002,
      "grad_norm": 1.163038730621338,
      "learning_rate": 1.2320959880015e-05,
      "loss": 0.0228,
      "step": 20480
    },
    {
      "epoch": 7.6827896512935885,
      "grad_norm": 8.092281341552734,
      "learning_rate": 1.2317210348706412e-05,
      "loss": 0.0256,
      "step": 20490
    },
    {
      "epoch": 7.686539182602175,
      "grad_norm": 0.0028530117124319077,
      "learning_rate": 1.2313460817397826e-05,
      "loss": 0.0211,
      "step": 20500
    },
    {
      "epoch": 7.690288713910761,
      "grad_norm": 0.15904884040355682,
      "learning_rate": 1.230971128608924e-05,
      "loss": 0.017,
      "step": 20510
    },
    {
      "epoch": 7.694038245219348,
      "grad_norm": 0.08656638115644455,
      "learning_rate": 1.2305961754780653e-05,
      "loss": 0.029,
      "step": 20520
    },
    {
      "epoch": 7.697787776527934,
      "grad_norm": 1.383918046951294,
      "learning_rate": 1.2302212223472067e-05,
      "loss": 0.029,
      "step": 20530
    },
    {
      "epoch": 7.701537307836521,
      "grad_norm": 0.3879595696926117,
      "learning_rate": 1.229846269216348e-05,
      "loss": 0.0052,
      "step": 20540
    },
    {
      "epoch": 7.705286839145106,
      "grad_norm": 0.012963698245584965,
      "learning_rate": 1.2294713160854894e-05,
      "loss": 0.012,
      "step": 20550
    },
    {
      "epoch": 7.709036370453694,
      "grad_norm": 0.7361207008361816,
      "learning_rate": 1.2290963629546308e-05,
      "loss": 0.0096,
      "step": 20560
    },
    {
      "epoch": 7.712785901762279,
      "grad_norm": 0.0020279698073863983,
      "learning_rate": 1.228721409823772e-05,
      "loss": 0.0161,
      "step": 20570
    },
    {
      "epoch": 7.716535433070866,
      "grad_norm": 0.009829604998230934,
      "learning_rate": 1.2283464566929135e-05,
      "loss": 0.0077,
      "step": 20580
    },
    {
      "epoch": 7.720284964379452,
      "grad_norm": 0.007434503175318241,
      "learning_rate": 1.2279715035620547e-05,
      "loss": 0.0127,
      "step": 20590
    },
    {
      "epoch": 7.724034495688039,
      "grad_norm": 1.0305495262145996,
      "learning_rate": 1.2275965504311961e-05,
      "loss": 0.0134,
      "step": 20600
    },
    {
      "epoch": 7.727784026996625,
      "grad_norm": 0.5836799740791321,
      "learning_rate": 1.2272215973003376e-05,
      "loss": 0.0033,
      "step": 20610
    },
    {
      "epoch": 7.731533558305212,
      "grad_norm": 7.300298690795898,
      "learning_rate": 1.2268466441694788e-05,
      "loss": 0.0144,
      "step": 20620
    },
    {
      "epoch": 7.735283089613798,
      "grad_norm": 0.05806323140859604,
      "learning_rate": 1.2264716910386202e-05,
      "loss": 0.03,
      "step": 20630
    },
    {
      "epoch": 7.7390326209223845,
      "grad_norm": 0.006744303274899721,
      "learning_rate": 1.2260967379077617e-05,
      "loss": 0.0036,
      "step": 20640
    },
    {
      "epoch": 7.742782152230971,
      "grad_norm": 0.7214682102203369,
      "learning_rate": 1.2257217847769029e-05,
      "loss": 0.0032,
      "step": 20650
    },
    {
      "epoch": 7.7465316835395575,
      "grad_norm": 0.012297812849283218,
      "learning_rate": 1.2253468316460443e-05,
      "loss": 0.0203,
      "step": 20660
    },
    {
      "epoch": 7.750281214848144,
      "grad_norm": 0.01102261058986187,
      "learning_rate": 1.2249718785151856e-05,
      "loss": 0.0358,
      "step": 20670
    },
    {
      "epoch": 7.75403074615673,
      "grad_norm": 1.016356110572815,
      "learning_rate": 1.224596925384327e-05,
      "loss": 0.0119,
      "step": 20680
    },
    {
      "epoch": 7.757780277465317,
      "grad_norm": 0.18856820464134216,
      "learning_rate": 1.2242219722534686e-05,
      "loss": 0.0146,
      "step": 20690
    },
    {
      "epoch": 7.761529808773903,
      "grad_norm": 0.6310149431228638,
      "learning_rate": 1.2238470191226097e-05,
      "loss": 0.0253,
      "step": 20700
    },
    {
      "epoch": 7.76527934008249,
      "grad_norm": 0.0033514390233904123,
      "learning_rate": 1.2234720659917512e-05,
      "loss": 0.0081,
      "step": 20710
    },
    {
      "epoch": 7.769028871391076,
      "grad_norm": 0.004515914246439934,
      "learning_rate": 1.2230971128608923e-05,
      "loss": 0.0102,
      "step": 20720
    },
    {
      "epoch": 7.772778402699663,
      "grad_norm": 1.2538177967071533,
      "learning_rate": 1.2227221597300339e-05,
      "loss": 0.0177,
      "step": 20730
    },
    {
      "epoch": 7.776527934008249,
      "grad_norm": 0.002250666031613946,
      "learning_rate": 1.2223472065991753e-05,
      "loss": 0.0093,
      "step": 20740
    },
    {
      "epoch": 7.780277465316836,
      "grad_norm": 0.02407129295170307,
      "learning_rate": 1.2219722534683164e-05,
      "loss": 0.0043,
      "step": 20750
    },
    {
      "epoch": 7.784026996625422,
      "grad_norm": 0.0017550702905282378,
      "learning_rate": 1.221597300337458e-05,
      "loss": 0.0283,
      "step": 20760
    },
    {
      "epoch": 7.7877765279340085,
      "grad_norm": 0.0015106237260624766,
      "learning_rate": 1.2212223472065994e-05,
      "loss": 0.0401,
      "step": 20770
    },
    {
      "epoch": 7.791526059242595,
      "grad_norm": 0.041898902505636215,
      "learning_rate": 1.2208473940757407e-05,
      "loss": 0.0098,
      "step": 20780
    },
    {
      "epoch": 7.7952755905511815,
      "grad_norm": 0.2135820984840393,
      "learning_rate": 1.2204724409448821e-05,
      "loss": 0.0083,
      "step": 20790
    },
    {
      "epoch": 7.799025121859767,
      "grad_norm": 0.3961407244205475,
      "learning_rate": 1.2200974878140233e-05,
      "loss": 0.0137,
      "step": 20800
    },
    {
      "epoch": 7.802774653168354,
      "grad_norm": 0.6417019367218018,
      "learning_rate": 1.2197225346831648e-05,
      "loss": 0.01,
      "step": 20810
    },
    {
      "epoch": 7.80652418447694,
      "grad_norm": 0.3269088864326477,
      "learning_rate": 1.2193475815523062e-05,
      "loss": 0.022,
      "step": 20820
    },
    {
      "epoch": 7.810273715785526,
      "grad_norm": 0.8648145198822021,
      "learning_rate": 1.2189726284214474e-05,
      "loss": 0.0054,
      "step": 20830
    },
    {
      "epoch": 7.814023247094113,
      "grad_norm": 0.7665737271308899,
      "learning_rate": 1.2185976752905888e-05,
      "loss": 0.0159,
      "step": 20840
    },
    {
      "epoch": 7.817772778402699,
      "grad_norm": 0.002110260771587491,
      "learning_rate": 1.2182227221597301e-05,
      "loss": 0.0101,
      "step": 20850
    },
    {
      "epoch": 7.821522309711286,
      "grad_norm": 0.7655208110809326,
      "learning_rate": 1.2178477690288715e-05,
      "loss": 0.035,
      "step": 20860
    },
    {
      "epoch": 7.825271841019872,
      "grad_norm": 0.33309340476989746,
      "learning_rate": 1.217472815898013e-05,
      "loss": 0.0088,
      "step": 20870
    },
    {
      "epoch": 7.829021372328459,
      "grad_norm": 0.005001366138458252,
      "learning_rate": 1.2170978627671542e-05,
      "loss": 0.0143,
      "step": 20880
    },
    {
      "epoch": 7.832770903637045,
      "grad_norm": 0.6104930639266968,
      "learning_rate": 1.2167229096362956e-05,
      "loss": 0.0085,
      "step": 20890
    },
    {
      "epoch": 7.836520434945632,
      "grad_norm": 8.24809741973877,
      "learning_rate": 1.216347956505437e-05,
      "loss": 0.0349,
      "step": 20900
    },
    {
      "epoch": 7.840269966254218,
      "grad_norm": 0.5716085433959961,
      "learning_rate": 1.2159730033745783e-05,
      "loss": 0.0093,
      "step": 20910
    },
    {
      "epoch": 7.844019497562805,
      "grad_norm": 0.42864012718200684,
      "learning_rate": 1.2155980502437197e-05,
      "loss": 0.0052,
      "step": 20920
    },
    {
      "epoch": 7.847769028871391,
      "grad_norm": 0.002259030705317855,
      "learning_rate": 1.215223097112861e-05,
      "loss": 0.0075,
      "step": 20930
    },
    {
      "epoch": 7.8515185601799775,
      "grad_norm": 0.0024748039431869984,
      "learning_rate": 1.2148481439820024e-05,
      "loss": 0.0031,
      "step": 20940
    },
    {
      "epoch": 7.855268091488564,
      "grad_norm": 14.323094367980957,
      "learning_rate": 1.2144731908511438e-05,
      "loss": 0.0203,
      "step": 20950
    },
    {
      "epoch": 7.85901762279715,
      "grad_norm": 0.0063109141774475574,
      "learning_rate": 1.214098237720285e-05,
      "loss": 0.0115,
      "step": 20960
    },
    {
      "epoch": 7.862767154105737,
      "grad_norm": 15.36977767944336,
      "learning_rate": 1.2137232845894264e-05,
      "loss": 0.0215,
      "step": 20970
    },
    {
      "epoch": 7.866516685414323,
      "grad_norm": 0.006796610075980425,
      "learning_rate": 1.2133483314585677e-05,
      "loss": 0.0062,
      "step": 20980
    },
    {
      "epoch": 7.87026621672291,
      "grad_norm": 8.836569786071777,
      "learning_rate": 1.2129733783277091e-05,
      "loss": 0.0233,
      "step": 20990
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 0.0030316472984850407,
      "learning_rate": 1.2125984251968505e-05,
      "loss": 0.0199,
      "step": 21000
    },
    {
      "epoch": 7.877765279340083,
      "grad_norm": 1.0079727172851562,
      "learning_rate": 1.2122234720659918e-05,
      "loss": 0.0202,
      "step": 21010
    },
    {
      "epoch": 7.881514810648669,
      "grad_norm": 0.172518789768219,
      "learning_rate": 1.2118485189351332e-05,
      "loss": 0.0039,
      "step": 21020
    },
    {
      "epoch": 7.885264341957256,
      "grad_norm": 1.0251052379608154,
      "learning_rate": 1.2114735658042746e-05,
      "loss": 0.012,
      "step": 21030
    },
    {
      "epoch": 7.889013873265842,
      "grad_norm": 0.014720456674695015,
      "learning_rate": 1.2110986126734159e-05,
      "loss": 0.0048,
      "step": 21040
    },
    {
      "epoch": 7.892763404574428,
      "grad_norm": 1.1047935485839844,
      "learning_rate": 1.2107236595425573e-05,
      "loss": 0.0285,
      "step": 21050
    },
    {
      "epoch": 7.896512935883015,
      "grad_norm": 0.6132311224937439,
      "learning_rate": 1.2103487064116985e-05,
      "loss": 0.0161,
      "step": 21060
    },
    {
      "epoch": 7.900262467191601,
      "grad_norm": 0.661599338054657,
      "learning_rate": 1.20997375328084e-05,
      "loss": 0.0053,
      "step": 21070
    },
    {
      "epoch": 7.904011998500187,
      "grad_norm": 0.022602781653404236,
      "learning_rate": 1.2095988001499814e-05,
      "loss": 0.01,
      "step": 21080
    },
    {
      "epoch": 7.907761529808774,
      "grad_norm": 0.006159557495266199,
      "learning_rate": 1.2092238470191226e-05,
      "loss": 0.0089,
      "step": 21090
    },
    {
      "epoch": 7.91151106111736,
      "grad_norm": 0.06928099691867828,
      "learning_rate": 1.208848893888264e-05,
      "loss": 0.0059,
      "step": 21100
    },
    {
      "epoch": 7.9152605924259465,
      "grad_norm": 0.9128063917160034,
      "learning_rate": 1.2084739407574053e-05,
      "loss": 0.0323,
      "step": 21110
    },
    {
      "epoch": 7.919010123734533,
      "grad_norm": 0.8590265512466431,
      "learning_rate": 1.2080989876265467e-05,
      "loss": 0.013,
      "step": 21120
    },
    {
      "epoch": 7.922759655043119,
      "grad_norm": 0.6275426745414734,
      "learning_rate": 1.2077240344956881e-05,
      "loss": 0.0209,
      "step": 21130
    },
    {
      "epoch": 7.926509186351706,
      "grad_norm": 0.40170255303382874,
      "learning_rate": 1.2073490813648294e-05,
      "loss": 0.0112,
      "step": 21140
    },
    {
      "epoch": 7.930258717660292,
      "grad_norm": 0.0015401133568957448,
      "learning_rate": 1.2069741282339708e-05,
      "loss": 0.017,
      "step": 21150
    },
    {
      "epoch": 7.934008248968879,
      "grad_norm": 0.8261138796806335,
      "learning_rate": 1.2065991751031124e-05,
      "loss": 0.0178,
      "step": 21160
    },
    {
      "epoch": 7.937757780277465,
      "grad_norm": 1.1772217750549316,
      "learning_rate": 1.2062242219722535e-05,
      "loss": 0.005,
      "step": 21170
    },
    {
      "epoch": 7.941507311586052,
      "grad_norm": 0.47971901297569275,
      "learning_rate": 1.205849268841395e-05,
      "loss": 0.0217,
      "step": 21180
    },
    {
      "epoch": 7.945256842894638,
      "grad_norm": 0.005271465517580509,
      "learning_rate": 1.2054743157105361e-05,
      "loss": 0.009,
      "step": 21190
    },
    {
      "epoch": 7.949006374203225,
      "grad_norm": 0.010378333739936352,
      "learning_rate": 1.2050993625796777e-05,
      "loss": 0.0252,
      "step": 21200
    },
    {
      "epoch": 7.952755905511811,
      "grad_norm": 7.38197660446167,
      "learning_rate": 1.2047244094488191e-05,
      "loss": 0.0038,
      "step": 21210
    },
    {
      "epoch": 7.956505436820398,
      "grad_norm": 1.0448576211929321,
      "learning_rate": 1.2043494563179602e-05,
      "loss": 0.0133,
      "step": 21220
    },
    {
      "epoch": 7.960254968128984,
      "grad_norm": 1.009464144706726,
      "learning_rate": 1.2039745031871018e-05,
      "loss": 0.0089,
      "step": 21230
    },
    {
      "epoch": 7.9640044994375705,
      "grad_norm": 0.4054635167121887,
      "learning_rate": 1.2035995500562429e-05,
      "loss": 0.0083,
      "step": 21240
    },
    {
      "epoch": 7.967754030746157,
      "grad_norm": 0.6633195877075195,
      "learning_rate": 1.2032245969253845e-05,
      "loss": 0.0055,
      "step": 21250
    },
    {
      "epoch": 7.971503562054743,
      "grad_norm": 0.9777769446372986,
      "learning_rate": 1.2028496437945259e-05,
      "loss": 0.0209,
      "step": 21260
    },
    {
      "epoch": 7.97525309336333,
      "grad_norm": 1.514276385307312,
      "learning_rate": 1.2024746906636671e-05,
      "loss": 0.0164,
      "step": 21270
    },
    {
      "epoch": 7.979002624671916,
      "grad_norm": 0.7379502058029175,
      "learning_rate": 1.2020997375328086e-05,
      "loss": 0.0417,
      "step": 21280
    },
    {
      "epoch": 7.982752155980503,
      "grad_norm": 0.6641814112663269,
      "learning_rate": 1.20172478440195e-05,
      "loss": 0.0171,
      "step": 21290
    },
    {
      "epoch": 7.986501687289088,
      "grad_norm": 0.24695956707000732,
      "learning_rate": 1.2013498312710912e-05,
      "loss": 0.0219,
      "step": 21300
    },
    {
      "epoch": 7.990251218597676,
      "grad_norm": 0.01802532747387886,
      "learning_rate": 1.2009748781402326e-05,
      "loss": 0.0269,
      "step": 21310
    },
    {
      "epoch": 7.994000749906261,
      "grad_norm": 0.07270953059196472,
      "learning_rate": 1.2005999250093739e-05,
      "loss": 0.0083,
      "step": 21320
    },
    {
      "epoch": 7.997750281214848,
      "grad_norm": 0.26478710770606995,
      "learning_rate": 1.2002249718785153e-05,
      "loss": 0.0247,
      "step": 21330
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9919072615923009,
      "eval_f1": 0.9690117252931323,
      "eval_loss": 0.026289816945791245,
      "eval_precision": 0.9622955364568894,
      "eval_recall": 0.9758223221816137,
      "eval_runtime": 869.9714,
      "eval_samples_per_second": 31.533,
      "eval_steps_per_second": 1.315,
      "step": 21336
    },
    {
      "epoch": 8.001499812523434,
      "grad_norm": 0.02090916410088539,
      "learning_rate": 1.1998500187476567e-05,
      "loss": 0.0228,
      "step": 21340
    },
    {
      "epoch": 8.005249343832022,
      "grad_norm": 0.004214385990053415,
      "learning_rate": 1.199475065616798e-05,
      "loss": 0.0114,
      "step": 21350
    },
    {
      "epoch": 8.008998875140607,
      "grad_norm": 17.748029708862305,
      "learning_rate": 1.1991001124859394e-05,
      "loss": 0.0123,
      "step": 21360
    },
    {
      "epoch": 8.012748406449195,
      "grad_norm": 0.2897830009460449,
      "learning_rate": 1.1987251593550807e-05,
      "loss": 0.012,
      "step": 21370
    },
    {
      "epoch": 8.01649793775778,
      "grad_norm": 0.9772964119911194,
      "learning_rate": 1.198350206224222e-05,
      "loss": 0.0049,
      "step": 21380
    },
    {
      "epoch": 8.020247469066367,
      "grad_norm": 0.4157504439353943,
      "learning_rate": 1.1979752530933635e-05,
      "loss": 0.008,
      "step": 21390
    },
    {
      "epoch": 8.023997000374953,
      "grad_norm": 0.16604860126972198,
      "learning_rate": 1.1976002999625047e-05,
      "loss": 0.0243,
      "step": 21400
    },
    {
      "epoch": 8.02774653168354,
      "grad_norm": 0.28932350873947144,
      "learning_rate": 1.1972253468316462e-05,
      "loss": 0.0071,
      "step": 21410
    },
    {
      "epoch": 8.031496062992126,
      "grad_norm": 0.005074862390756607,
      "learning_rate": 1.1968503937007876e-05,
      "loss": 0.0286,
      "step": 21420
    },
    {
      "epoch": 8.035245594300713,
      "grad_norm": 0.004990973509848118,
      "learning_rate": 1.1964754405699288e-05,
      "loss": 0.0213,
      "step": 21430
    },
    {
      "epoch": 8.038995125609299,
      "grad_norm": 0.3084639608860016,
      "learning_rate": 1.1961004874390702e-05,
      "loss": 0.0302,
      "step": 21440
    },
    {
      "epoch": 8.042744656917884,
      "grad_norm": 1.4731189012527466,
      "learning_rate": 1.1957255343082115e-05,
      "loss": 0.0071,
      "step": 21450
    },
    {
      "epoch": 8.046494188226472,
      "grad_norm": 0.018344532698392868,
      "learning_rate": 1.1953505811773529e-05,
      "loss": 0.0589,
      "step": 21460
    },
    {
      "epoch": 8.050243719535057,
      "grad_norm": 0.4542475938796997,
      "learning_rate": 1.1949756280464943e-05,
      "loss": 0.0153,
      "step": 21470
    },
    {
      "epoch": 8.053993250843645,
      "grad_norm": 0.002620625775307417,
      "learning_rate": 1.1946006749156356e-05,
      "loss": 0.0092,
      "step": 21480
    },
    {
      "epoch": 8.05774278215223,
      "grad_norm": 0.004852794576436281,
      "learning_rate": 1.194225721784777e-05,
      "loss": 0.0206,
      "step": 21490
    },
    {
      "epoch": 8.061492313460818,
      "grad_norm": 0.03695021942257881,
      "learning_rate": 1.1938507686539184e-05,
      "loss": 0.0123,
      "step": 21500
    },
    {
      "epoch": 8.065241844769403,
      "grad_norm": 0.49491432309150696,
      "learning_rate": 1.1934758155230597e-05,
      "loss": 0.0082,
      "step": 21510
    },
    {
      "epoch": 8.06899137607799,
      "grad_norm": 0.4601726531982422,
      "learning_rate": 1.1931008623922011e-05,
      "loss": 0.0041,
      "step": 21520
    },
    {
      "epoch": 8.072740907386576,
      "grad_norm": 0.7369433045387268,
      "learning_rate": 1.1927259092613423e-05,
      "loss": 0.0332,
      "step": 21530
    },
    {
      "epoch": 8.076490438695163,
      "grad_norm": 0.0065200901590287685,
      "learning_rate": 1.1923509561304838e-05,
      "loss": 0.0056,
      "step": 21540
    },
    {
      "epoch": 8.080239970003749,
      "grad_norm": 0.7689898014068604,
      "learning_rate": 1.1919760029996252e-05,
      "loss": 0.0127,
      "step": 21550
    },
    {
      "epoch": 8.083989501312336,
      "grad_norm": 0.44966429471969604,
      "learning_rate": 1.1916010498687664e-05,
      "loss": 0.0173,
      "step": 21560
    },
    {
      "epoch": 8.087739032620922,
      "grad_norm": 0.05685588717460632,
      "learning_rate": 1.1912260967379078e-05,
      "loss": 0.0035,
      "step": 21570
    },
    {
      "epoch": 8.09148856392951,
      "grad_norm": 0.05972284451127052,
      "learning_rate": 1.1908511436070491e-05,
      "loss": 0.017,
      "step": 21580
    },
    {
      "epoch": 8.095238095238095,
      "grad_norm": 1.0411922931671143,
      "learning_rate": 1.1904761904761905e-05,
      "loss": 0.0124,
      "step": 21590
    },
    {
      "epoch": 8.098987626546682,
      "grad_norm": 0.04975297302007675,
      "learning_rate": 1.190101237345332e-05,
      "loss": 0.0129,
      "step": 21600
    },
    {
      "epoch": 8.102737157855268,
      "grad_norm": 0.024805929511785507,
      "learning_rate": 1.1897262842144732e-05,
      "loss": 0.015,
      "step": 21610
    },
    {
      "epoch": 8.106486689163855,
      "grad_norm": 0.597423255443573,
      "learning_rate": 1.1893513310836146e-05,
      "loss": 0.0074,
      "step": 21620
    },
    {
      "epoch": 8.11023622047244,
      "grad_norm": 0.004653898999094963,
      "learning_rate": 1.1889763779527562e-05,
      "loss": 0.0074,
      "step": 21630
    },
    {
      "epoch": 8.113985751781028,
      "grad_norm": 0.07394302636384964,
      "learning_rate": 1.1886014248218973e-05,
      "loss": 0.0093,
      "step": 21640
    },
    {
      "epoch": 8.117735283089614,
      "grad_norm": 0.044095851480960846,
      "learning_rate": 1.1882264716910389e-05,
      "loss": 0.0051,
      "step": 21650
    },
    {
      "epoch": 8.121484814398201,
      "grad_norm": 0.5335224866867065,
      "learning_rate": 1.18785151856018e-05,
      "loss": 0.0076,
      "step": 21660
    },
    {
      "epoch": 8.125234345706787,
      "grad_norm": 1.095058560371399,
      "learning_rate": 1.1874765654293215e-05,
      "loss": 0.005,
      "step": 21670
    },
    {
      "epoch": 8.128983877015374,
      "grad_norm": 0.24579277634620667,
      "learning_rate": 1.187101612298463e-05,
      "loss": 0.03,
      "step": 21680
    },
    {
      "epoch": 8.13273340832396,
      "grad_norm": 1.3826628923416138,
      "learning_rate": 1.186726659167604e-05,
      "loss": 0.0173,
      "step": 21690
    },
    {
      "epoch": 8.136482939632545,
      "grad_norm": 0.01211358979344368,
      "learning_rate": 1.1863517060367456e-05,
      "loss": 0.0069,
      "step": 21700
    },
    {
      "epoch": 8.140232470941132,
      "grad_norm": 0.0017773037543520331,
      "learning_rate": 1.1859767529058867e-05,
      "loss": 0.0145,
      "step": 21710
    },
    {
      "epoch": 8.143982002249718,
      "grad_norm": 0.4790154695510864,
      "learning_rate": 1.1856017997750283e-05,
      "loss": 0.022,
      "step": 21720
    },
    {
      "epoch": 8.147731533558305,
      "grad_norm": 1.242271900177002,
      "learning_rate": 1.1852268466441697e-05,
      "loss": 0.021,
      "step": 21730
    },
    {
      "epoch": 8.151481064866891,
      "grad_norm": 1.7620962858200073,
      "learning_rate": 1.184851893513311e-05,
      "loss": 0.0123,
      "step": 21740
    },
    {
      "epoch": 8.155230596175478,
      "grad_norm": 0.025850394740700722,
      "learning_rate": 1.1844769403824524e-05,
      "loss": 0.0063,
      "step": 21750
    },
    {
      "epoch": 8.158980127484064,
      "grad_norm": 0.19891144335269928,
      "learning_rate": 1.1841019872515938e-05,
      "loss": 0.0126,
      "step": 21760
    },
    {
      "epoch": 8.162729658792651,
      "grad_norm": 0.019563093781471252,
      "learning_rate": 1.183727034120735e-05,
      "loss": 0.0053,
      "step": 21770
    },
    {
      "epoch": 8.166479190101237,
      "grad_norm": 0.0026412520091980696,
      "learning_rate": 1.1833520809898764e-05,
      "loss": 0.0162,
      "step": 21780
    },
    {
      "epoch": 8.170228721409824,
      "grad_norm": 0.8555474877357483,
      "learning_rate": 1.1829771278590177e-05,
      "loss": 0.0199,
      "step": 21790
    },
    {
      "epoch": 8.17397825271841,
      "grad_norm": 0.027090687304735184,
      "learning_rate": 1.1826021747281591e-05,
      "loss": 0.0102,
      "step": 21800
    },
    {
      "epoch": 8.177727784026997,
      "grad_norm": 0.27294376492500305,
      "learning_rate": 1.1822272215973005e-05,
      "loss": 0.007,
      "step": 21810
    },
    {
      "epoch": 8.181477315335583,
      "grad_norm": 0.0074111404828727245,
      "learning_rate": 1.1818522684664418e-05,
      "loss": 0.0074,
      "step": 21820
    },
    {
      "epoch": 8.18522684664417,
      "grad_norm": 0.10390381515026093,
      "learning_rate": 1.1814773153355832e-05,
      "loss": 0.0013,
      "step": 21830
    },
    {
      "epoch": 8.188976377952756,
      "grad_norm": 0.2724559009075165,
      "learning_rate": 1.1811023622047245e-05,
      "loss": 0.0119,
      "step": 21840
    },
    {
      "epoch": 8.192725909261343,
      "grad_norm": 0.546532928943634,
      "learning_rate": 1.1807274090738659e-05,
      "loss": 0.005,
      "step": 21850
    },
    {
      "epoch": 8.196475440569928,
      "grad_norm": 15.142062187194824,
      "learning_rate": 1.1803524559430073e-05,
      "loss": 0.0203,
      "step": 21860
    },
    {
      "epoch": 8.200224971878516,
      "grad_norm": 0.007673619780689478,
      "learning_rate": 1.1799775028121485e-05,
      "loss": 0.0038,
      "step": 21870
    },
    {
      "epoch": 8.203974503187101,
      "grad_norm": 0.12724056839942932,
      "learning_rate": 1.17960254968129e-05,
      "loss": 0.0075,
      "step": 21880
    },
    {
      "epoch": 8.207724034495689,
      "grad_norm": 0.5438165664672852,
      "learning_rate": 1.1792275965504314e-05,
      "loss": 0.0043,
      "step": 21890
    },
    {
      "epoch": 8.211473565804274,
      "grad_norm": 0.002555652055889368,
      "learning_rate": 1.1788526434195726e-05,
      "loss": 0.0293,
      "step": 21900
    },
    {
      "epoch": 8.215223097112862,
      "grad_norm": 0.3312249183654785,
      "learning_rate": 1.178477690288714e-05,
      "loss": 0.0103,
      "step": 21910
    },
    {
      "epoch": 8.218972628421447,
      "grad_norm": 0.0026050107553601265,
      "learning_rate": 1.1781027371578553e-05,
      "loss": 0.0071,
      "step": 21920
    },
    {
      "epoch": 8.222722159730035,
      "grad_norm": 0.0023154017981141806,
      "learning_rate": 1.1777277840269967e-05,
      "loss": 0.0334,
      "step": 21930
    },
    {
      "epoch": 8.22647169103862,
      "grad_norm": 0.00400562584400177,
      "learning_rate": 1.1773528308961381e-05,
      "loss": 0.0182,
      "step": 21940
    },
    {
      "epoch": 8.230221222347206,
      "grad_norm": 0.0053369817323982716,
      "learning_rate": 1.1769778777652794e-05,
      "loss": 0.0163,
      "step": 21950
    },
    {
      "epoch": 8.233970753655793,
      "grad_norm": 0.12342803180217743,
      "learning_rate": 1.1766029246344208e-05,
      "loss": 0.0084,
      "step": 21960
    },
    {
      "epoch": 8.237720284964379,
      "grad_norm": 0.010159406810998917,
      "learning_rate": 1.176227971503562e-05,
      "loss": 0.0106,
      "step": 21970
    },
    {
      "epoch": 8.241469816272966,
      "grad_norm": 0.2696499824523926,
      "learning_rate": 1.1758530183727035e-05,
      "loss": 0.0129,
      "step": 21980
    },
    {
      "epoch": 8.245219347581552,
      "grad_norm": 1.8931602239608765,
      "learning_rate": 1.1754780652418449e-05,
      "loss": 0.0283,
      "step": 21990
    },
    {
      "epoch": 8.248968878890139,
      "grad_norm": 0.05872786045074463,
      "learning_rate": 1.1751031121109861e-05,
      "loss": 0.021,
      "step": 22000
    },
    {
      "epoch": 8.252718410198725,
      "grad_norm": 0.001410572207532823,
      "learning_rate": 1.1747281589801276e-05,
      "loss": 0.0133,
      "step": 22010
    },
    {
      "epoch": 8.256467941507312,
      "grad_norm": 0.2560567557811737,
      "learning_rate": 1.174353205849269e-05,
      "loss": 0.0089,
      "step": 22020
    },
    {
      "epoch": 8.260217472815897,
      "grad_norm": 0.026861365884542465,
      "learning_rate": 1.1739782527184102e-05,
      "loss": 0.0466,
      "step": 22030
    },
    {
      "epoch": 8.263967004124485,
      "grad_norm": 0.529097855091095,
      "learning_rate": 1.1736032995875516e-05,
      "loss": 0.0136,
      "step": 22040
    },
    {
      "epoch": 8.26771653543307,
      "grad_norm": 0.0915520042181015,
      "learning_rate": 1.1732283464566929e-05,
      "loss": 0.0075,
      "step": 22050
    },
    {
      "epoch": 8.271466066741658,
      "grad_norm": 0.0023216777481138706,
      "learning_rate": 1.1728533933258343e-05,
      "loss": 0.0024,
      "step": 22060
    },
    {
      "epoch": 8.275215598050243,
      "grad_norm": 0.15447616577148438,
      "learning_rate": 1.1724784401949757e-05,
      "loss": 0.0048,
      "step": 22070
    },
    {
      "epoch": 8.27896512935883,
      "grad_norm": 0.02519454061985016,
      "learning_rate": 1.172103487064117e-05,
      "loss": 0.0039,
      "step": 22080
    },
    {
      "epoch": 8.282714660667416,
      "grad_norm": 0.0072452411986887455,
      "learning_rate": 1.1717285339332584e-05,
      "loss": 0.0023,
      "step": 22090
    },
    {
      "epoch": 8.286464191976004,
      "grad_norm": 0.16540390253067017,
      "learning_rate": 1.1713535808023996e-05,
      "loss": 0.0081,
      "step": 22100
    },
    {
      "epoch": 8.29021372328459,
      "grad_norm": 0.04052557051181793,
      "learning_rate": 1.170978627671541e-05,
      "loss": 0.014,
      "step": 22110
    },
    {
      "epoch": 8.293963254593177,
      "grad_norm": 0.011738854460418224,
      "learning_rate": 1.1706036745406827e-05,
      "loss": 0.0105,
      "step": 22120
    },
    {
      "epoch": 8.297712785901762,
      "grad_norm": 0.1971205770969391,
      "learning_rate": 1.1702287214098237e-05,
      "loss": 0.0245,
      "step": 22130
    },
    {
      "epoch": 8.30146231721035,
      "grad_norm": 1.076918125152588,
      "learning_rate": 1.1698537682789653e-05,
      "loss": 0.0149,
      "step": 22140
    },
    {
      "epoch": 8.305211848518935,
      "grad_norm": 2.3941097259521484,
      "learning_rate": 1.1694788151481067e-05,
      "loss": 0.0126,
      "step": 22150
    },
    {
      "epoch": 8.308961379827522,
      "grad_norm": 5.049296855926514,
      "learning_rate": 1.1691038620172478e-05,
      "loss": 0.0053,
      "step": 22160
    },
    {
      "epoch": 8.312710911136108,
      "grad_norm": 4.154383182525635,
      "learning_rate": 1.1687289088863894e-05,
      "loss": 0.0238,
      "step": 22170
    },
    {
      "epoch": 8.316460442444694,
      "grad_norm": 0.7247231006622314,
      "learning_rate": 1.1683539557555305e-05,
      "loss": 0.0215,
      "step": 22180
    },
    {
      "epoch": 8.32020997375328,
      "grad_norm": 0.9616262912750244,
      "learning_rate": 1.167979002624672e-05,
      "loss": 0.0089,
      "step": 22190
    },
    {
      "epoch": 8.323959505061866,
      "grad_norm": 14.549546241760254,
      "learning_rate": 1.1676040494938135e-05,
      "loss": 0.017,
      "step": 22200
    },
    {
      "epoch": 8.327709036370454,
      "grad_norm": 1.1468747854232788,
      "learning_rate": 1.1672290963629547e-05,
      "loss": 0.0075,
      "step": 22210
    },
    {
      "epoch": 8.33145856767904,
      "grad_norm": 0.003366622608155012,
      "learning_rate": 1.1668541432320962e-05,
      "loss": 0.011,
      "step": 22220
    },
    {
      "epoch": 8.335208098987627,
      "grad_norm": 10.29210090637207,
      "learning_rate": 1.1664791901012374e-05,
      "loss": 0.0275,
      "step": 22230
    },
    {
      "epoch": 8.338957630296212,
      "grad_norm": 0.2723308205604553,
      "learning_rate": 1.1661042369703788e-05,
      "loss": 0.0315,
      "step": 22240
    },
    {
      "epoch": 8.3427071616048,
      "grad_norm": 3.33280086517334,
      "learning_rate": 1.1657292838395203e-05,
      "loss": 0.0196,
      "step": 22250
    },
    {
      "epoch": 8.346456692913385,
      "grad_norm": 0.019941158592700958,
      "learning_rate": 1.1653543307086615e-05,
      "loss": 0.0138,
      "step": 22260
    },
    {
      "epoch": 8.350206224221973,
      "grad_norm": 0.8735376596450806,
      "learning_rate": 1.164979377577803e-05,
      "loss": 0.0039,
      "step": 22270
    },
    {
      "epoch": 8.353955755530558,
      "grad_norm": 0.8146023154258728,
      "learning_rate": 1.1646044244469443e-05,
      "loss": 0.0185,
      "step": 22280
    },
    {
      "epoch": 8.357705286839145,
      "grad_norm": 0.9140271544456482,
      "learning_rate": 1.1642294713160856e-05,
      "loss": 0.0321,
      "step": 22290
    },
    {
      "epoch": 8.361454818147731,
      "grad_norm": 2.5843071937561035,
      "learning_rate": 1.163854518185227e-05,
      "loss": 0.0085,
      "step": 22300
    },
    {
      "epoch": 8.365204349456318,
      "grad_norm": 25.05372428894043,
      "learning_rate": 1.1634795650543683e-05,
      "loss": 0.0154,
      "step": 22310
    },
    {
      "epoch": 8.368953880764904,
      "grad_norm": 0.0023209175560623407,
      "learning_rate": 1.1631046119235097e-05,
      "loss": 0.0284,
      "step": 22320
    },
    {
      "epoch": 8.372703412073491,
      "grad_norm": 0.004809000063687563,
      "learning_rate": 1.1627296587926511e-05,
      "loss": 0.0105,
      "step": 22330
    },
    {
      "epoch": 8.376452943382077,
      "grad_norm": 6.240997791290283,
      "learning_rate": 1.1623547056617923e-05,
      "loss": 0.0283,
      "step": 22340
    },
    {
      "epoch": 8.380202474690664,
      "grad_norm": 0.2125147134065628,
      "learning_rate": 1.1619797525309338e-05,
      "loss": 0.0105,
      "step": 22350
    },
    {
      "epoch": 8.38395200599925,
      "grad_norm": 1.0946946144104004,
      "learning_rate": 1.161604799400075e-05,
      "loss": 0.0139,
      "step": 22360
    },
    {
      "epoch": 8.387701537307837,
      "grad_norm": 0.44639405608177185,
      "learning_rate": 1.1612298462692164e-05,
      "loss": 0.009,
      "step": 22370
    },
    {
      "epoch": 8.391451068616423,
      "grad_norm": 0.8799514174461365,
      "learning_rate": 1.1608548931383578e-05,
      "loss": 0.0051,
      "step": 22380
    },
    {
      "epoch": 8.39520059992501,
      "grad_norm": 0.0043129511177539825,
      "learning_rate": 1.1604799400074991e-05,
      "loss": 0.0105,
      "step": 22390
    },
    {
      "epoch": 8.398950131233596,
      "grad_norm": 2.2471985816955566,
      "learning_rate": 1.1601049868766405e-05,
      "loss": 0.0219,
      "step": 22400
    },
    {
      "epoch": 8.402699662542183,
      "grad_norm": 0.00860188901424408,
      "learning_rate": 1.159730033745782e-05,
      "loss": 0.0018,
      "step": 22410
    },
    {
      "epoch": 8.406449193850769,
      "grad_norm": 0.11785540729761124,
      "learning_rate": 1.1593550806149232e-05,
      "loss": 0.0237,
      "step": 22420
    },
    {
      "epoch": 8.410198725159354,
      "grad_norm": 8.217832565307617,
      "learning_rate": 1.1589801274840646e-05,
      "loss": 0.0246,
      "step": 22430
    },
    {
      "epoch": 8.413948256467942,
      "grad_norm": 0.012168685905635357,
      "learning_rate": 1.1586051743532059e-05,
      "loss": 0.0105,
      "step": 22440
    },
    {
      "epoch": 8.417697787776527,
      "grad_norm": 0.12975193560123444,
      "learning_rate": 1.1582302212223473e-05,
      "loss": 0.0071,
      "step": 22450
    },
    {
      "epoch": 8.421447319085114,
      "grad_norm": 0.10742094367742538,
      "learning_rate": 1.1578552680914887e-05,
      "loss": 0.0137,
      "step": 22460
    },
    {
      "epoch": 8.4251968503937,
      "grad_norm": 0.003377289278432727,
      "learning_rate": 1.15748031496063e-05,
      "loss": 0.0051,
      "step": 22470
    },
    {
      "epoch": 8.428946381702287,
      "grad_norm": 0.014373751357197762,
      "learning_rate": 1.1571053618297714e-05,
      "loss": 0.0033,
      "step": 22480
    },
    {
      "epoch": 8.432695913010873,
      "grad_norm": 0.7004631161689758,
      "learning_rate": 1.1567304086989126e-05,
      "loss": 0.0181,
      "step": 22490
    },
    {
      "epoch": 8.43644544431946,
      "grad_norm": 0.005290146451443434,
      "learning_rate": 1.156355455568054e-05,
      "loss": 0.0185,
      "step": 22500
    },
    {
      "epoch": 8.440194975628046,
      "grad_norm": 0.004311760887503624,
      "learning_rate": 1.1559805024371954e-05,
      "loss": 0.0136,
      "step": 22510
    },
    {
      "epoch": 8.443944506936633,
      "grad_norm": 2.945030450820923,
      "learning_rate": 1.1556055493063367e-05,
      "loss": 0.0265,
      "step": 22520
    },
    {
      "epoch": 8.447694038245219,
      "grad_norm": 0.6213713884353638,
      "learning_rate": 1.1552305961754781e-05,
      "loss": 0.0141,
      "step": 22530
    },
    {
      "epoch": 8.451443569553806,
      "grad_norm": 0.0035087112337350845,
      "learning_rate": 1.1548556430446195e-05,
      "loss": 0.0068,
      "step": 22540
    },
    {
      "epoch": 8.455193100862392,
      "grad_norm": 0.10920030623674393,
      "learning_rate": 1.1544806899137608e-05,
      "loss": 0.0186,
      "step": 22550
    },
    {
      "epoch": 8.458942632170979,
      "grad_norm": 0.0013999344082549214,
      "learning_rate": 1.1541057367829022e-05,
      "loss": 0.0036,
      "step": 22560
    },
    {
      "epoch": 8.462692163479565,
      "grad_norm": 0.05710208788514137,
      "learning_rate": 1.1537307836520435e-05,
      "loss": 0.0065,
      "step": 22570
    },
    {
      "epoch": 8.466441694788152,
      "grad_norm": 0.05163869261741638,
      "learning_rate": 1.1533558305211849e-05,
      "loss": 0.025,
      "step": 22580
    },
    {
      "epoch": 8.470191226096738,
      "grad_norm": 0.002998959505930543,
      "learning_rate": 1.1529808773903265e-05,
      "loss": 0.0256,
      "step": 22590
    },
    {
      "epoch": 8.473940757405325,
      "grad_norm": 0.5815330743789673,
      "learning_rate": 1.1526059242594675e-05,
      "loss": 0.0052,
      "step": 22600
    },
    {
      "epoch": 8.47769028871391,
      "grad_norm": 3.2955267429351807,
      "learning_rate": 1.1522309711286091e-05,
      "loss": 0.041,
      "step": 22610
    },
    {
      "epoch": 8.481439820022498,
      "grad_norm": 1.864813208580017,
      "learning_rate": 1.1518560179977505e-05,
      "loss": 0.0297,
      "step": 22620
    },
    {
      "epoch": 8.485189351331083,
      "grad_norm": 0.002524132141843438,
      "learning_rate": 1.1514810648668916e-05,
      "loss": 0.0106,
      "step": 22630
    },
    {
      "epoch": 8.48893888263967,
      "grad_norm": 3.575763702392578,
      "learning_rate": 1.1511061117360332e-05,
      "loss": 0.0133,
      "step": 22640
    },
    {
      "epoch": 8.492688413948256,
      "grad_norm": 0.0011509592877700925,
      "learning_rate": 1.1507311586051743e-05,
      "loss": 0.008,
      "step": 22650
    },
    {
      "epoch": 8.496437945256844,
      "grad_norm": 0.0007657716632820666,
      "learning_rate": 1.1503562054743159e-05,
      "loss": 0.0173,
      "step": 22660
    },
    {
      "epoch": 8.50018747656543,
      "grad_norm": 0.03253563120961189,
      "learning_rate": 1.1499812523434573e-05,
      "loss": 0.0043,
      "step": 22670
    },
    {
      "epoch": 8.503937007874015,
      "grad_norm": 0.0021442279685288668,
      "learning_rate": 1.1496062992125985e-05,
      "loss": 0.0158,
      "step": 22680
    },
    {
      "epoch": 8.507686539182602,
      "grad_norm": 0.0006479047588072717,
      "learning_rate": 1.14923134608174e-05,
      "loss": 0.0159,
      "step": 22690
    },
    {
      "epoch": 8.511436070491188,
      "grad_norm": 1.202200174331665,
      "learning_rate": 1.1488563929508812e-05,
      "loss": 0.0116,
      "step": 22700
    },
    {
      "epoch": 8.515185601799775,
      "grad_norm": 0.42160847783088684,
      "learning_rate": 1.1484814398200226e-05,
      "loss": 0.0055,
      "step": 22710
    },
    {
      "epoch": 8.51893513310836,
      "grad_norm": 0.0006243647076189518,
      "learning_rate": 1.148106486689164e-05,
      "loss": 0.0065,
      "step": 22720
    },
    {
      "epoch": 8.522684664416948,
      "grad_norm": 0.04257162660360336,
      "learning_rate": 1.1477315335583053e-05,
      "loss": 0.0283,
      "step": 22730
    },
    {
      "epoch": 8.526434195725534,
      "grad_norm": 0.005089584272354841,
      "learning_rate": 1.1473565804274467e-05,
      "loss": 0.008,
      "step": 22740
    },
    {
      "epoch": 8.530183727034121,
      "grad_norm": 0.0009632749133743346,
      "learning_rate": 1.1469816272965881e-05,
      "loss": 0.0093,
      "step": 22750
    },
    {
      "epoch": 8.533933258342707,
      "grad_norm": 0.9756752252578735,
      "learning_rate": 1.1466066741657294e-05,
      "loss": 0.0078,
      "step": 22760
    },
    {
      "epoch": 8.537682789651294,
      "grad_norm": 0.24280422925949097,
      "learning_rate": 1.1462317210348708e-05,
      "loss": 0.0161,
      "step": 22770
    },
    {
      "epoch": 8.54143232095988,
      "grad_norm": 0.15076228976249695,
      "learning_rate": 1.145856767904012e-05,
      "loss": 0.0163,
      "step": 22780
    },
    {
      "epoch": 8.545181852268467,
      "grad_norm": 0.36269932985305786,
      "learning_rate": 1.1454818147731535e-05,
      "loss": 0.0085,
      "step": 22790
    },
    {
      "epoch": 8.548931383577052,
      "grad_norm": 0.0011781267821788788,
      "learning_rate": 1.1451068616422949e-05,
      "loss": 0.0133,
      "step": 22800
    },
    {
      "epoch": 8.55268091488564,
      "grad_norm": 0.001828206004574895,
      "learning_rate": 1.1447319085114361e-05,
      "loss": 0.0212,
      "step": 22810
    },
    {
      "epoch": 8.556430446194225,
      "grad_norm": 0.005614107474684715,
      "learning_rate": 1.1443569553805776e-05,
      "loss": 0.0255,
      "step": 22820
    },
    {
      "epoch": 8.560179977502813,
      "grad_norm": 0.029868552461266518,
      "learning_rate": 1.1439820022497188e-05,
      "loss": 0.005,
      "step": 22830
    },
    {
      "epoch": 8.563929508811398,
      "grad_norm": 1.0533453226089478,
      "learning_rate": 1.1436070491188602e-05,
      "loss": 0.0068,
      "step": 22840
    },
    {
      "epoch": 8.567679040119986,
      "grad_norm": 0.48700642585754395,
      "learning_rate": 1.1432320959880017e-05,
      "loss": 0.0337,
      "step": 22850
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.005350422114133835,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0055,
      "step": 22860
    },
    {
      "epoch": 8.575178102737159,
      "grad_norm": 0.3941788971424103,
      "learning_rate": 1.1424821897262843e-05,
      "loss": 0.0069,
      "step": 22870
    },
    {
      "epoch": 8.578927634045744,
      "grad_norm": 10.45553970336914,
      "learning_rate": 1.1421072365954257e-05,
      "loss": 0.0161,
      "step": 22880
    },
    {
      "epoch": 8.582677165354331,
      "grad_norm": 0.4830378592014313,
      "learning_rate": 1.141732283464567e-05,
      "loss": 0.0057,
      "step": 22890
    },
    {
      "epoch": 8.586426696662917,
      "grad_norm": 0.05292590707540512,
      "learning_rate": 1.1413573303337084e-05,
      "loss": 0.0102,
      "step": 22900
    },
    {
      "epoch": 8.590176227971504,
      "grad_norm": 1.023144006729126,
      "learning_rate": 1.1409823772028497e-05,
      "loss": 0.0125,
      "step": 22910
    },
    {
      "epoch": 8.59392575928009,
      "grad_norm": 0.835322916507721,
      "learning_rate": 1.140607424071991e-05,
      "loss": 0.0064,
      "step": 22920
    },
    {
      "epoch": 8.597675290588676,
      "grad_norm": 0.006258725188672543,
      "learning_rate": 1.1402324709411325e-05,
      "loss": 0.0066,
      "step": 22930
    },
    {
      "epoch": 8.601424821897263,
      "grad_norm": 0.002080023754388094,
      "learning_rate": 1.1398575178102737e-05,
      "loss": 0.01,
      "step": 22940
    },
    {
      "epoch": 8.605174353205848,
      "grad_norm": 0.5348876118659973,
      "learning_rate": 1.1394825646794152e-05,
      "loss": 0.0077,
      "step": 22950
    },
    {
      "epoch": 8.608923884514436,
      "grad_norm": 0.3883720338344574,
      "learning_rate": 1.1391076115485564e-05,
      "loss": 0.0125,
      "step": 22960
    },
    {
      "epoch": 8.612673415823021,
      "grad_norm": 0.4163760244846344,
      "learning_rate": 1.1387326584176978e-05,
      "loss": 0.0028,
      "step": 22970
    },
    {
      "epoch": 8.616422947131609,
      "grad_norm": 0.002690657740458846,
      "learning_rate": 1.1383577052868393e-05,
      "loss": 0.0099,
      "step": 22980
    },
    {
      "epoch": 8.620172478440194,
      "grad_norm": 0.006796650122851133,
      "learning_rate": 1.1379827521559805e-05,
      "loss": 0.0236,
      "step": 22990
    },
    {
      "epoch": 8.623922009748782,
      "grad_norm": 0.37532535195350647,
      "learning_rate": 1.137607799025122e-05,
      "loss": 0.006,
      "step": 23000
    },
    {
      "epoch": 8.627671541057367,
      "grad_norm": 1.9967221021652222,
      "learning_rate": 1.1372328458942633e-05,
      "loss": 0.0162,
      "step": 23010
    },
    {
      "epoch": 8.631421072365955,
      "grad_norm": 0.5628626942634583,
      "learning_rate": 1.1368578927634046e-05,
      "loss": 0.0038,
      "step": 23020
    },
    {
      "epoch": 8.63517060367454,
      "grad_norm": 3.4401209354400635,
      "learning_rate": 1.136482939632546e-05,
      "loss": 0.0179,
      "step": 23030
    },
    {
      "epoch": 8.638920134983127,
      "grad_norm": 4.498873233795166,
      "learning_rate": 1.1361079865016873e-05,
      "loss": 0.0109,
      "step": 23040
    },
    {
      "epoch": 8.642669666291713,
      "grad_norm": 0.3988635540008545,
      "learning_rate": 1.1357330333708287e-05,
      "loss": 0.01,
      "step": 23050
    },
    {
      "epoch": 8.6464191976003,
      "grad_norm": 0.28865042328834534,
      "learning_rate": 1.1353580802399703e-05,
      "loss": 0.011,
      "step": 23060
    },
    {
      "epoch": 8.650168728908886,
      "grad_norm": 0.0034858102444559336,
      "learning_rate": 1.1349831271091113e-05,
      "loss": 0.0091,
      "step": 23070
    },
    {
      "epoch": 8.653918260217473,
      "grad_norm": 0.005777393933385611,
      "learning_rate": 1.134608173978253e-05,
      "loss": 0.0099,
      "step": 23080
    },
    {
      "epoch": 8.657667791526059,
      "grad_norm": 0.010514935478568077,
      "learning_rate": 1.134233220847394e-05,
      "loss": 0.0149,
      "step": 23090
    },
    {
      "epoch": 8.661417322834646,
      "grad_norm": 0.0563780851662159,
      "learning_rate": 1.1338582677165354e-05,
      "loss": 0.0052,
      "step": 23100
    },
    {
      "epoch": 8.665166854143232,
      "grad_norm": 2.030095100402832,
      "learning_rate": 1.133483314585677e-05,
      "loss": 0.0131,
      "step": 23110
    },
    {
      "epoch": 8.66891638545182,
      "grad_norm": 0.0030145065393298864,
      "learning_rate": 1.1331083614548181e-05,
      "loss": 0.0132,
      "step": 23120
    },
    {
      "epoch": 8.672665916760405,
      "grad_norm": 0.04312429949641228,
      "learning_rate": 1.1327334083239597e-05,
      "loss": 0.0137,
      "step": 23130
    },
    {
      "epoch": 8.676415448068992,
      "grad_norm": 0.006078517530113459,
      "learning_rate": 1.1323584551931011e-05,
      "loss": 0.0263,
      "step": 23140
    },
    {
      "epoch": 8.680164979377578,
      "grad_norm": 0.0027491652872413397,
      "learning_rate": 1.1319835020622424e-05,
      "loss": 0.0174,
      "step": 23150
    },
    {
      "epoch": 8.683914510686165,
      "grad_norm": 1.4182987213134766,
      "learning_rate": 1.1316085489313838e-05,
      "loss": 0.014,
      "step": 23160
    },
    {
      "epoch": 8.68766404199475,
      "grad_norm": 0.18875595927238464,
      "learning_rate": 1.131233595800525e-05,
      "loss": 0.0073,
      "step": 23170
    },
    {
      "epoch": 8.691413573303336,
      "grad_norm": 0.022763356566429138,
      "learning_rate": 1.1308586426696664e-05,
      "loss": 0.0077,
      "step": 23180
    },
    {
      "epoch": 8.695163104611924,
      "grad_norm": 0.4448320269584656,
      "learning_rate": 1.1304836895388079e-05,
      "loss": 0.0099,
      "step": 23190
    },
    {
      "epoch": 8.69891263592051,
      "grad_norm": 0.531085729598999,
      "learning_rate": 1.1301087364079491e-05,
      "loss": 0.0031,
      "step": 23200
    },
    {
      "epoch": 8.702662167229096,
      "grad_norm": 2.248222589492798,
      "learning_rate": 1.1297337832770905e-05,
      "loss": 0.0187,
      "step": 23210
    },
    {
      "epoch": 8.706411698537682,
      "grad_norm": 0.005120266228914261,
      "learning_rate": 1.1293588301462318e-05,
      "loss": 0.0161,
      "step": 23220
    },
    {
      "epoch": 8.71016122984627,
      "grad_norm": 0.0021662446670234203,
      "learning_rate": 1.1289838770153732e-05,
      "loss": 0.0155,
      "step": 23230
    },
    {
      "epoch": 8.713910761154855,
      "grad_norm": 1.298990249633789,
      "learning_rate": 1.1286089238845146e-05,
      "loss": 0.0108,
      "step": 23240
    },
    {
      "epoch": 8.717660292463442,
      "grad_norm": 0.004940989892929792,
      "learning_rate": 1.1282339707536559e-05,
      "loss": 0.0076,
      "step": 23250
    },
    {
      "epoch": 8.721409823772028,
      "grad_norm": 0.1656752973794937,
      "learning_rate": 1.1278590176227973e-05,
      "loss": 0.005,
      "step": 23260
    },
    {
      "epoch": 8.725159355080615,
      "grad_norm": 0.0018774062627926469,
      "learning_rate": 1.1274840644919387e-05,
      "loss": 0.0008,
      "step": 23270
    },
    {
      "epoch": 8.7289088863892,
      "grad_norm": 0.41252875328063965,
      "learning_rate": 1.12710911136108e-05,
      "loss": 0.0063,
      "step": 23280
    },
    {
      "epoch": 8.732658417697788,
      "grad_norm": 0.8635730147361755,
      "learning_rate": 1.1267341582302214e-05,
      "loss": 0.0123,
      "step": 23290
    },
    {
      "epoch": 8.736407949006374,
      "grad_norm": 0.00694378511980176,
      "learning_rate": 1.1263592050993626e-05,
      "loss": 0.0049,
      "step": 23300
    },
    {
      "epoch": 8.740157480314961,
      "grad_norm": 0.9585635662078857,
      "learning_rate": 1.125984251968504e-05,
      "loss": 0.0025,
      "step": 23310
    },
    {
      "epoch": 8.743907011623547,
      "grad_norm": 12.2872896194458,
      "learning_rate": 1.1256092988376455e-05,
      "loss": 0.0084,
      "step": 23320
    },
    {
      "epoch": 8.747656542932134,
      "grad_norm": 0.034612588584423065,
      "learning_rate": 1.1252343457067867e-05,
      "loss": 0.0354,
      "step": 23330
    },
    {
      "epoch": 8.75140607424072,
      "grad_norm": 1.2296503782272339,
      "learning_rate": 1.1248593925759281e-05,
      "loss": 0.021,
      "step": 23340
    },
    {
      "epoch": 8.755155605549307,
      "grad_norm": 0.008109678514301777,
      "learning_rate": 1.1244844394450694e-05,
      "loss": 0.0062,
      "step": 23350
    },
    {
      "epoch": 8.758905136857893,
      "grad_norm": 0.7064802050590515,
      "learning_rate": 1.1241094863142108e-05,
      "loss": 0.0106,
      "step": 23360
    },
    {
      "epoch": 8.76265466816648,
      "grad_norm": 0.0016114439349621534,
      "learning_rate": 1.1237345331833522e-05,
      "loss": 0.0064,
      "step": 23370
    },
    {
      "epoch": 8.766404199475065,
      "grad_norm": 0.6401469707489014,
      "learning_rate": 1.1233595800524935e-05,
      "loss": 0.0031,
      "step": 23380
    },
    {
      "epoch": 8.770153730783653,
      "grad_norm": 0.0012795340735465288,
      "learning_rate": 1.1229846269216349e-05,
      "loss": 0.0128,
      "step": 23390
    },
    {
      "epoch": 8.773903262092238,
      "grad_norm": 2.399522304534912,
      "learning_rate": 1.1226096737907763e-05,
      "loss": 0.0038,
      "step": 23400
    },
    {
      "epoch": 8.777652793400826,
      "grad_norm": 0.3997029960155487,
      "learning_rate": 1.1222347206599175e-05,
      "loss": 0.0208,
      "step": 23410
    },
    {
      "epoch": 8.781402324709411,
      "grad_norm": 0.01785927638411522,
      "learning_rate": 1.121859767529059e-05,
      "loss": 0.0047,
      "step": 23420
    },
    {
      "epoch": 8.785151856017997,
      "grad_norm": 0.03418930247426033,
      "learning_rate": 1.1214848143982002e-05,
      "loss": 0.0277,
      "step": 23430
    },
    {
      "epoch": 8.788901387326584,
      "grad_norm": 1.0952702760696411,
      "learning_rate": 1.1211098612673416e-05,
      "loss": 0.0055,
      "step": 23440
    },
    {
      "epoch": 8.79265091863517,
      "grad_norm": 0.0026773030404001474,
      "learning_rate": 1.120734908136483e-05,
      "loss": 0.0139,
      "step": 23450
    },
    {
      "epoch": 8.796400449943757,
      "grad_norm": 0.0022679013200104237,
      "learning_rate": 1.1203599550056243e-05,
      "loss": 0.0141,
      "step": 23460
    },
    {
      "epoch": 8.800149981252343,
      "grad_norm": 0.022768396884202957,
      "learning_rate": 1.1199850018747657e-05,
      "loss": 0.0113,
      "step": 23470
    },
    {
      "epoch": 8.80389951256093,
      "grad_norm": 0.0036311710719019175,
      "learning_rate": 1.119610048743907e-05,
      "loss": 0.0121,
      "step": 23480
    },
    {
      "epoch": 8.807649043869516,
      "grad_norm": 0.323146253824234,
      "learning_rate": 1.1192350956130484e-05,
      "loss": 0.0125,
      "step": 23490
    },
    {
      "epoch": 8.811398575178103,
      "grad_norm": 3.9571115970611572,
      "learning_rate": 1.1188601424821898e-05,
      "loss": 0.0171,
      "step": 23500
    },
    {
      "epoch": 8.815148106486689,
      "grad_norm": 3.1360185146331787,
      "learning_rate": 1.118485189351331e-05,
      "loss": 0.0147,
      "step": 23510
    },
    {
      "epoch": 8.818897637795276,
      "grad_norm": 0.9122593402862549,
      "learning_rate": 1.1181102362204725e-05,
      "loss": 0.008,
      "step": 23520
    },
    {
      "epoch": 8.822647169103861,
      "grad_norm": 1.0848690271377563,
      "learning_rate": 1.117735283089614e-05,
      "loss": 0.0125,
      "step": 23530
    },
    {
      "epoch": 8.826396700412449,
      "grad_norm": 0.7893026471138,
      "learning_rate": 1.1173603299587551e-05,
      "loss": 0.0166,
      "step": 23540
    },
    {
      "epoch": 8.830146231721034,
      "grad_norm": 0.21483299136161804,
      "learning_rate": 1.1169853768278967e-05,
      "loss": 0.0092,
      "step": 23550
    },
    {
      "epoch": 8.833895763029622,
      "grad_norm": 0.02440931461751461,
      "learning_rate": 1.1166104236970378e-05,
      "loss": 0.0111,
      "step": 23560
    },
    {
      "epoch": 8.837645294338207,
      "grad_norm": 0.003861462464556098,
      "learning_rate": 1.1162354705661792e-05,
      "loss": 0.0111,
      "step": 23570
    },
    {
      "epoch": 8.841394825646795,
      "grad_norm": 0.0013919712509959936,
      "learning_rate": 1.1158605174353208e-05,
      "loss": 0.0132,
      "step": 23580
    },
    {
      "epoch": 8.84514435695538,
      "grad_norm": 0.0010898577747866511,
      "learning_rate": 1.1154855643044619e-05,
      "loss": 0.0126,
      "step": 23590
    },
    {
      "epoch": 8.848893888263968,
      "grad_norm": 0.5607500076293945,
      "learning_rate": 1.1151106111736035e-05,
      "loss": 0.0318,
      "step": 23600
    },
    {
      "epoch": 8.852643419572553,
      "grad_norm": 0.0006661899387836456,
      "learning_rate": 1.1147356580427446e-05,
      "loss": 0.007,
      "step": 23610
    },
    {
      "epoch": 8.85639295088114,
      "grad_norm": 0.004332897253334522,
      "learning_rate": 1.1143607049118862e-05,
      "loss": 0.0074,
      "step": 23620
    },
    {
      "epoch": 8.860142482189726,
      "grad_norm": 0.49077245593070984,
      "learning_rate": 1.1139857517810276e-05,
      "loss": 0.0008,
      "step": 23630
    },
    {
      "epoch": 8.863892013498313,
      "grad_norm": 1.3963325023651123,
      "learning_rate": 1.1136107986501688e-05,
      "loss": 0.0104,
      "step": 23640
    },
    {
      "epoch": 8.867641544806899,
      "grad_norm": 0.06620001047849655,
      "learning_rate": 1.1132358455193102e-05,
      "loss": 0.0202,
      "step": 23650
    },
    {
      "epoch": 8.871391076115486,
      "grad_norm": 1.8112666606903076,
      "learning_rate": 1.1128608923884517e-05,
      "loss": 0.0059,
      "step": 23660
    },
    {
      "epoch": 8.875140607424072,
      "grad_norm": 6.223667144775391,
      "learning_rate": 1.1124859392575929e-05,
      "loss": 0.0358,
      "step": 23670
    },
    {
      "epoch": 8.878890138732658,
      "grad_norm": 0.0013903832295909524,
      "learning_rate": 1.1121109861267343e-05,
      "loss": 0.0044,
      "step": 23680
    },
    {
      "epoch": 8.882639670041245,
      "grad_norm": 0.00653894804418087,
      "learning_rate": 1.1117360329958756e-05,
      "loss": 0.0142,
      "step": 23690
    },
    {
      "epoch": 8.88638920134983,
      "grad_norm": 1.1612069606781006,
      "learning_rate": 1.111361079865017e-05,
      "loss": 0.0122,
      "step": 23700
    },
    {
      "epoch": 8.890138732658418,
      "grad_norm": 0.001039177761413157,
      "learning_rate": 1.1109861267341584e-05,
      "loss": 0.0095,
      "step": 23710
    },
    {
      "epoch": 8.893888263967003,
      "grad_norm": 0.014032116159796715,
      "learning_rate": 1.1106111736032997e-05,
      "loss": 0.0084,
      "step": 23720
    },
    {
      "epoch": 8.89763779527559,
      "grad_norm": 0.007651923224329948,
      "learning_rate": 1.1102362204724411e-05,
      "loss": 0.0022,
      "step": 23730
    },
    {
      "epoch": 8.901387326584176,
      "grad_norm": 2.1252448558807373,
      "learning_rate": 1.1098612673415823e-05,
      "loss": 0.0487,
      "step": 23740
    },
    {
      "epoch": 8.905136857892764,
      "grad_norm": 0.01621660776436329,
      "learning_rate": 1.1094863142107238e-05,
      "loss": 0.038,
      "step": 23750
    },
    {
      "epoch": 8.90888638920135,
      "grad_norm": 0.01494086254388094,
      "learning_rate": 1.1091113610798652e-05,
      "loss": 0.0101,
      "step": 23760
    },
    {
      "epoch": 8.912635920509937,
      "grad_norm": 0.42554718255996704,
      "learning_rate": 1.1087364079490064e-05,
      "loss": 0.0069,
      "step": 23770
    },
    {
      "epoch": 8.916385451818522,
      "grad_norm": 0.38440167903900146,
      "learning_rate": 1.1083614548181478e-05,
      "loss": 0.0101,
      "step": 23780
    },
    {
      "epoch": 8.92013498312711,
      "grad_norm": 4.675952911376953,
      "learning_rate": 1.1079865016872893e-05,
      "loss": 0.0205,
      "step": 23790
    },
    {
      "epoch": 8.923884514435695,
      "grad_norm": 0.783539891242981,
      "learning_rate": 1.1076115485564305e-05,
      "loss": 0.0068,
      "step": 23800
    },
    {
      "epoch": 8.927634045744282,
      "grad_norm": 11.631898880004883,
      "learning_rate": 1.107236595425572e-05,
      "loss": 0.0269,
      "step": 23810
    },
    {
      "epoch": 8.931383577052868,
      "grad_norm": 0.021045316010713577,
      "learning_rate": 1.1068616422947132e-05,
      "loss": 0.0112,
      "step": 23820
    },
    {
      "epoch": 8.935133108361455,
      "grad_norm": 0.2632686495780945,
      "learning_rate": 1.1064866891638546e-05,
      "loss": 0.0052,
      "step": 23830
    },
    {
      "epoch": 8.938882639670041,
      "grad_norm": 0.0012343506095930934,
      "learning_rate": 1.106111736032996e-05,
      "loss": 0.0175,
      "step": 23840
    },
    {
      "epoch": 8.942632170978628,
      "grad_norm": 0.0025138428900390863,
      "learning_rate": 1.1057367829021373e-05,
      "loss": 0.0105,
      "step": 23850
    },
    {
      "epoch": 8.946381702287214,
      "grad_norm": 0.03595498949289322,
      "learning_rate": 1.1053618297712787e-05,
      "loss": 0.0082,
      "step": 23860
    },
    {
      "epoch": 8.950131233595801,
      "grad_norm": 0.7671193480491638,
      "learning_rate": 1.1049868766404201e-05,
      "loss": 0.027,
      "step": 23870
    },
    {
      "epoch": 8.953880764904387,
      "grad_norm": 2.6567039489746094,
      "learning_rate": 1.1046119235095614e-05,
      "loss": 0.0322,
      "step": 23880
    },
    {
      "epoch": 8.957630296212974,
      "grad_norm": 9.355782508850098,
      "learning_rate": 1.1042369703787028e-05,
      "loss": 0.0229,
      "step": 23890
    },
    {
      "epoch": 8.96137982752156,
      "grad_norm": 0.0021565728820860386,
      "learning_rate": 1.103862017247844e-05,
      "loss": 0.0201,
      "step": 23900
    },
    {
      "epoch": 8.965129358830147,
      "grad_norm": 0.9702633023262024,
      "learning_rate": 1.1034870641169854e-05,
      "loss": 0.0146,
      "step": 23910
    },
    {
      "epoch": 8.968878890138733,
      "grad_norm": 0.0018291890155524015,
      "learning_rate": 1.1031121109861269e-05,
      "loss": 0.0049,
      "step": 23920
    },
    {
      "epoch": 8.972628421447318,
      "grad_norm": 0.00318625895306468,
      "learning_rate": 1.1027371578552681e-05,
      "loss": 0.0429,
      "step": 23930
    },
    {
      "epoch": 8.976377952755906,
      "grad_norm": 0.04374322667717934,
      "learning_rate": 1.1023622047244095e-05,
      "loss": 0.0123,
      "step": 23940
    },
    {
      "epoch": 8.980127484064491,
      "grad_norm": 0.38196828961372375,
      "learning_rate": 1.1019872515935508e-05,
      "loss": 0.002,
      "step": 23950
    },
    {
      "epoch": 8.983877015373078,
      "grad_norm": 0.005215415731072426,
      "learning_rate": 1.1016122984626922e-05,
      "loss": 0.0049,
      "step": 23960
    },
    {
      "epoch": 8.987626546681664,
      "grad_norm": 0.01590881310403347,
      "learning_rate": 1.1012373453318336e-05,
      "loss": 0.0246,
      "step": 23970
    },
    {
      "epoch": 8.991376077990251,
      "grad_norm": 0.015367401763796806,
      "learning_rate": 1.1008623922009749e-05,
      "loss": 0.0084,
      "step": 23980
    },
    {
      "epoch": 8.995125609298837,
      "grad_norm": 1.3559188842773438,
      "learning_rate": 1.1004874390701163e-05,
      "loss": 0.0124,
      "step": 23990
    },
    {
      "epoch": 8.998875140607424,
      "grad_norm": 0.004825860261917114,
      "learning_rate": 1.1001124859392579e-05,
      "loss": 0.0029,
      "step": 24000
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9929644211140274,
      "eval_f1": 0.9727362621839243,
      "eval_loss": 0.02312333509325981,
      "eval_precision": 0.9775695627484384,
      "eval_recall": 0.9679505201012089,
      "eval_runtime": 870.8254,
      "eval_samples_per_second": 31.502,
      "eval_steps_per_second": 1.314,
      "step": 24003
    },
    {
      "epoch": 9.00262467191601,
      "grad_norm": 0.35464149713516235,
      "learning_rate": 1.099737532808399e-05,
      "loss": 0.012,
      "step": 24010
    },
    {
      "epoch": 9.006374203224597,
      "grad_norm": 0.018193570896983147,
      "learning_rate": 1.0993625796775405e-05,
      "loss": 0.0168,
      "step": 24020
    },
    {
      "epoch": 9.010123734533183,
      "grad_norm": 0.0020072408951818943,
      "learning_rate": 1.0989876265466816e-05,
      "loss": 0.0103,
      "step": 24030
    },
    {
      "epoch": 9.01387326584177,
      "grad_norm": 0.07027948647737503,
      "learning_rate": 1.098612673415823e-05,
      "loss": 0.0234,
      "step": 24040
    },
    {
      "epoch": 9.017622797150356,
      "grad_norm": 0.007648064289242029,
      "learning_rate": 1.0982377202849646e-05,
      "loss": 0.0232,
      "step": 24050
    },
    {
      "epoch": 9.021372328458943,
      "grad_norm": 0.003583805402740836,
      "learning_rate": 1.0978627671541057e-05,
      "loss": 0.0329,
      "step": 24060
    },
    {
      "epoch": 9.025121859767529,
      "grad_norm": 0.17728573083877563,
      "learning_rate": 1.0974878140232473e-05,
      "loss": 0.0089,
      "step": 24070
    },
    {
      "epoch": 9.028871391076116,
      "grad_norm": 0.007518233731389046,
      "learning_rate": 1.0971128608923884e-05,
      "loss": 0.0101,
      "step": 24080
    },
    {
      "epoch": 9.032620922384702,
      "grad_norm": 0.7962910532951355,
      "learning_rate": 1.09673790776153e-05,
      "loss": 0.006,
      "step": 24090
    },
    {
      "epoch": 9.036370453693289,
      "grad_norm": 0.5645474195480347,
      "learning_rate": 1.0963629546306714e-05,
      "loss": 0.0095,
      "step": 24100
    },
    {
      "epoch": 9.040119985001875,
      "grad_norm": 1.5284192562103271,
      "learning_rate": 1.0959880014998126e-05,
      "loss": 0.0121,
      "step": 24110
    },
    {
      "epoch": 9.043869516310462,
      "grad_norm": 0.24534863233566284,
      "learning_rate": 1.095613048368954e-05,
      "loss": 0.0477,
      "step": 24120
    },
    {
      "epoch": 9.047619047619047,
      "grad_norm": 0.012661624699831009,
      "learning_rate": 1.0952380952380955e-05,
      "loss": 0.0101,
      "step": 24130
    },
    {
      "epoch": 9.051368578927635,
      "grad_norm": 0.011791812255978584,
      "learning_rate": 1.0948631421072367e-05,
      "loss": 0.0076,
      "step": 24140
    },
    {
      "epoch": 9.05511811023622,
      "grad_norm": 0.6551526188850403,
      "learning_rate": 1.0944881889763781e-05,
      "loss": 0.0141,
      "step": 24150
    },
    {
      "epoch": 9.058867641544808,
      "grad_norm": 0.0033194769639521837,
      "learning_rate": 1.0941132358455194e-05,
      "loss": 0.0034,
      "step": 24160
    },
    {
      "epoch": 9.062617172853393,
      "grad_norm": 0.21178974211215973,
      "learning_rate": 1.0937382827146608e-05,
      "loss": 0.0072,
      "step": 24170
    },
    {
      "epoch": 9.066366704161979,
      "grad_norm": 0.011734399013221264,
      "learning_rate": 1.0933633295838022e-05,
      "loss": 0.0071,
      "step": 24180
    },
    {
      "epoch": 9.070116235470566,
      "grad_norm": 1.3653285503387451,
      "learning_rate": 1.0929883764529435e-05,
      "loss": 0.006,
      "step": 24190
    },
    {
      "epoch": 9.073865766779152,
      "grad_norm": 0.0020898410584777594,
      "learning_rate": 1.0926134233220849e-05,
      "loss": 0.0154,
      "step": 24200
    },
    {
      "epoch": 9.07761529808774,
      "grad_norm": 0.0014477374497801065,
      "learning_rate": 1.0922384701912261e-05,
      "loss": 0.004,
      "step": 24210
    },
    {
      "epoch": 9.081364829396325,
      "grad_norm": 0.0027226849924772978,
      "learning_rate": 1.0918635170603676e-05,
      "loss": 0.0026,
      "step": 24220
    },
    {
      "epoch": 9.085114360704912,
      "grad_norm": 0.0015341936377808452,
      "learning_rate": 1.091488563929509e-05,
      "loss": 0.014,
      "step": 24230
    },
    {
      "epoch": 9.088863892013498,
      "grad_norm": 1.2889310121536255,
      "learning_rate": 1.0911136107986502e-05,
      "loss": 0.0095,
      "step": 24240
    },
    {
      "epoch": 9.092613423322085,
      "grad_norm": 0.026454385370016098,
      "learning_rate": 1.0907386576677916e-05,
      "loss": 0.0124,
      "step": 24250
    },
    {
      "epoch": 9.09636295463067,
      "grad_norm": 0.014123463071882725,
      "learning_rate": 1.090363704536933e-05,
      "loss": 0.0023,
      "step": 24260
    },
    {
      "epoch": 9.100112485939258,
      "grad_norm": 0.0012384584406390786,
      "learning_rate": 1.0899887514060743e-05,
      "loss": 0.0088,
      "step": 24270
    },
    {
      "epoch": 9.103862017247843,
      "grad_norm": 0.9455877542495728,
      "learning_rate": 1.0896137982752157e-05,
      "loss": 0.0293,
      "step": 24280
    },
    {
      "epoch": 9.10761154855643,
      "grad_norm": 4.089407444000244,
      "learning_rate": 1.089238845144357e-05,
      "loss": 0.0196,
      "step": 24290
    },
    {
      "epoch": 9.111361079865016,
      "grad_norm": 0.0032492962200194597,
      "learning_rate": 1.0888638920134984e-05,
      "loss": 0.0415,
      "step": 24300
    },
    {
      "epoch": 9.115110611173604,
      "grad_norm": 0.557281494140625,
      "learning_rate": 1.0884889388826398e-05,
      "loss": 0.0188,
      "step": 24310
    },
    {
      "epoch": 9.11886014248219,
      "grad_norm": 0.029145633801817894,
      "learning_rate": 1.088113985751781e-05,
      "loss": 0.0103,
      "step": 24320
    },
    {
      "epoch": 9.122609673790777,
      "grad_norm": 0.6191834211349487,
      "learning_rate": 1.0877390326209225e-05,
      "loss": 0.0026,
      "step": 24330
    },
    {
      "epoch": 9.126359205099362,
      "grad_norm": 0.032400958240032196,
      "learning_rate": 1.0873640794900637e-05,
      "loss": 0.0052,
      "step": 24340
    },
    {
      "epoch": 9.13010873640795,
      "grad_norm": 0.010270272381603718,
      "learning_rate": 1.0869891263592052e-05,
      "loss": 0.0139,
      "step": 24350
    },
    {
      "epoch": 9.133858267716535,
      "grad_norm": 0.03045395202934742,
      "learning_rate": 1.0866141732283466e-05,
      "loss": 0.0068,
      "step": 24360
    },
    {
      "epoch": 9.137607799025123,
      "grad_norm": 1.653685212135315,
      "learning_rate": 1.0862392200974878e-05,
      "loss": 0.0118,
      "step": 24370
    },
    {
      "epoch": 9.141357330333708,
      "grad_norm": 0.4535782039165497,
      "learning_rate": 1.0858642669666292e-05,
      "loss": 0.0016,
      "step": 24380
    },
    {
      "epoch": 9.145106861642295,
      "grad_norm": 1.3056097030639648,
      "learning_rate": 1.0854893138357707e-05,
      "loss": 0.0117,
      "step": 24390
    },
    {
      "epoch": 9.148856392950881,
      "grad_norm": 0.008940627798438072,
      "learning_rate": 1.0851143607049119e-05,
      "loss": 0.0132,
      "step": 24400
    },
    {
      "epoch": 9.152605924259468,
      "grad_norm": 0.02940364181995392,
      "learning_rate": 1.0847394075740533e-05,
      "loss": 0.0376,
      "step": 24410
    },
    {
      "epoch": 9.156355455568054,
      "grad_norm": 0.6010638475418091,
      "learning_rate": 1.0843644544431946e-05,
      "loss": 0.0119,
      "step": 24420
    },
    {
      "epoch": 9.16010498687664,
      "grad_norm": 0.004998158197849989,
      "learning_rate": 1.083989501312336e-05,
      "loss": 0.007,
      "step": 24430
    },
    {
      "epoch": 9.163854518185227,
      "grad_norm": 0.23203261196613312,
      "learning_rate": 1.0836145481814774e-05,
      "loss": 0.0119,
      "step": 24440
    },
    {
      "epoch": 9.167604049493812,
      "grad_norm": 0.12989701330661774,
      "learning_rate": 1.0832395950506187e-05,
      "loss": 0.0128,
      "step": 24450
    },
    {
      "epoch": 9.1713535808024,
      "grad_norm": 0.2761772871017456,
      "learning_rate": 1.08286464191976e-05,
      "loss": 0.0033,
      "step": 24460
    },
    {
      "epoch": 9.175103112110985,
      "grad_norm": 0.003344824304804206,
      "learning_rate": 1.0824896887889013e-05,
      "loss": 0.0046,
      "step": 24470
    },
    {
      "epoch": 9.178852643419573,
      "grad_norm": 0.003334061009809375,
      "learning_rate": 1.0821147356580428e-05,
      "loss": 0.0063,
      "step": 24480
    },
    {
      "epoch": 9.182602174728158,
      "grad_norm": 0.0026358766481280327,
      "learning_rate": 1.0817397825271843e-05,
      "loss": 0.0075,
      "step": 24490
    },
    {
      "epoch": 9.186351706036746,
      "grad_norm": 0.009432348422706127,
      "learning_rate": 1.0813648293963254e-05,
      "loss": 0.0072,
      "step": 24500
    },
    {
      "epoch": 9.190101237345331,
      "grad_norm": 0.003447702620178461,
      "learning_rate": 1.0809898762654668e-05,
      "loss": 0.0153,
      "step": 24510
    },
    {
      "epoch": 9.193850768653919,
      "grad_norm": 0.1484881192445755,
      "learning_rate": 1.0806149231346084e-05,
      "loss": 0.0099,
      "step": 24520
    },
    {
      "epoch": 9.197600299962504,
      "grad_norm": 0.022663641721010208,
      "learning_rate": 1.0802399700037495e-05,
      "loss": 0.052,
      "step": 24530
    },
    {
      "epoch": 9.201349831271092,
      "grad_norm": 0.5034094452857971,
      "learning_rate": 1.0798650168728911e-05,
      "loss": 0.0238,
      "step": 24540
    },
    {
      "epoch": 9.205099362579677,
      "grad_norm": 0.04294133558869362,
      "learning_rate": 1.0794900637420322e-05,
      "loss": 0.007,
      "step": 24550
    },
    {
      "epoch": 9.208848893888264,
      "grad_norm": 0.8013333082199097,
      "learning_rate": 1.0791151106111738e-05,
      "loss": 0.0067,
      "step": 24560
    },
    {
      "epoch": 9.21259842519685,
      "grad_norm": 0.17026598751544952,
      "learning_rate": 1.0787401574803152e-05,
      "loss": 0.0104,
      "step": 24570
    },
    {
      "epoch": 9.216347956505437,
      "grad_norm": 0.057909220457077026,
      "learning_rate": 1.0783652043494564e-05,
      "loss": 0.0234,
      "step": 24580
    },
    {
      "epoch": 9.220097487814023,
      "grad_norm": 2.2136707305908203,
      "learning_rate": 1.0779902512185978e-05,
      "loss": 0.0129,
      "step": 24590
    },
    {
      "epoch": 9.22384701912261,
      "grad_norm": 0.14334873855113983,
      "learning_rate": 1.0776152980877391e-05,
      "loss": 0.0043,
      "step": 24600
    },
    {
      "epoch": 9.227596550431196,
      "grad_norm": 0.6194328665733337,
      "learning_rate": 1.0772403449568805e-05,
      "loss": 0.0128,
      "step": 24610
    },
    {
      "epoch": 9.231346081739783,
      "grad_norm": 0.003344031050801277,
      "learning_rate": 1.076865391826022e-05,
      "loss": 0.0108,
      "step": 24620
    },
    {
      "epoch": 9.235095613048369,
      "grad_norm": 2.5044145584106445,
      "learning_rate": 1.0764904386951632e-05,
      "loss": 0.0199,
      "step": 24630
    },
    {
      "epoch": 9.238845144356956,
      "grad_norm": 0.07939641922712326,
      "learning_rate": 1.0761154855643046e-05,
      "loss": 0.0083,
      "step": 24640
    },
    {
      "epoch": 9.242594675665542,
      "grad_norm": 0.009849773719906807,
      "learning_rate": 1.075740532433446e-05,
      "loss": 0.0082,
      "step": 24650
    },
    {
      "epoch": 9.246344206974129,
      "grad_norm": 0.010734561830759048,
      "learning_rate": 1.0753655793025873e-05,
      "loss": 0.0019,
      "step": 24660
    },
    {
      "epoch": 9.250093738282715,
      "grad_norm": 0.004802077542990446,
      "learning_rate": 1.0749906261717287e-05,
      "loss": 0.0211,
      "step": 24670
    },
    {
      "epoch": 9.2538432695913,
      "grad_norm": 0.3955286741256714,
      "learning_rate": 1.07461567304087e-05,
      "loss": 0.0093,
      "step": 24680
    },
    {
      "epoch": 9.257592800899888,
      "grad_norm": 0.004312711767852306,
      "learning_rate": 1.0742407199100114e-05,
      "loss": 0.0103,
      "step": 24690
    },
    {
      "epoch": 9.261342332208473,
      "grad_norm": 1.1170316934585571,
      "learning_rate": 1.0738657667791528e-05,
      "loss": 0.0086,
      "step": 24700
    },
    {
      "epoch": 9.26509186351706,
      "grad_norm": 0.7250997424125671,
      "learning_rate": 1.073490813648294e-05,
      "loss": 0.0204,
      "step": 24710
    },
    {
      "epoch": 9.268841394825646,
      "grad_norm": 0.8757369518280029,
      "learning_rate": 1.0731158605174354e-05,
      "loss": 0.0054,
      "step": 24720
    },
    {
      "epoch": 9.272590926134233,
      "grad_norm": 0.001552756642922759,
      "learning_rate": 1.0727409073865767e-05,
      "loss": 0.0115,
      "step": 24730
    },
    {
      "epoch": 9.276340457442819,
      "grad_norm": 0.001148842042312026,
      "learning_rate": 1.0723659542557181e-05,
      "loss": 0.0045,
      "step": 24740
    },
    {
      "epoch": 9.280089988751406,
      "grad_norm": 0.4250431954860687,
      "learning_rate": 1.0719910011248595e-05,
      "loss": 0.0051,
      "step": 24750
    },
    {
      "epoch": 9.283839520059992,
      "grad_norm": 0.0011482962872833014,
      "learning_rate": 1.0716160479940008e-05,
      "loss": 0.0323,
      "step": 24760
    },
    {
      "epoch": 9.28758905136858,
      "grad_norm": 0.0028399373404681683,
      "learning_rate": 1.0712410948631422e-05,
      "loss": 0.0137,
      "step": 24770
    },
    {
      "epoch": 9.291338582677165,
      "grad_norm": 0.0019184970296919346,
      "learning_rate": 1.0708661417322836e-05,
      "loss": 0.0033,
      "step": 24780
    },
    {
      "epoch": 9.295088113985752,
      "grad_norm": 0.5063824653625488,
      "learning_rate": 1.0704911886014249e-05,
      "loss": 0.0052,
      "step": 24790
    },
    {
      "epoch": 9.298837645294338,
      "grad_norm": 0.08899931609630585,
      "learning_rate": 1.0701162354705663e-05,
      "loss": 0.0199,
      "step": 24800
    },
    {
      "epoch": 9.302587176602925,
      "grad_norm": 0.10954347252845764,
      "learning_rate": 1.0697412823397075e-05,
      "loss": 0.0153,
      "step": 24810
    },
    {
      "epoch": 9.30633670791151,
      "grad_norm": 0.674642026424408,
      "learning_rate": 1.069366329208849e-05,
      "loss": 0.0125,
      "step": 24820
    },
    {
      "epoch": 9.310086239220098,
      "grad_norm": 0.010247630998492241,
      "learning_rate": 1.0689913760779904e-05,
      "loss": 0.0053,
      "step": 24830
    },
    {
      "epoch": 9.313835770528684,
      "grad_norm": 0.011532462202012539,
      "learning_rate": 1.0686164229471316e-05,
      "loss": 0.0137,
      "step": 24840
    },
    {
      "epoch": 9.317585301837271,
      "grad_norm": 0.11733708530664444,
      "learning_rate": 1.068241469816273e-05,
      "loss": 0.0049,
      "step": 24850
    },
    {
      "epoch": 9.321334833145857,
      "grad_norm": 0.004141894169151783,
      "learning_rate": 1.0678665166854143e-05,
      "loss": 0.005,
      "step": 24860
    },
    {
      "epoch": 9.325084364454444,
      "grad_norm": 0.003663733834400773,
      "learning_rate": 1.0674915635545557e-05,
      "loss": 0.0138,
      "step": 24870
    },
    {
      "epoch": 9.32883389576303,
      "grad_norm": 1.12066650390625,
      "learning_rate": 1.0671166104236971e-05,
      "loss": 0.0172,
      "step": 24880
    },
    {
      "epoch": 9.332583427071617,
      "grad_norm": 0.9086399674415588,
      "learning_rate": 1.0667416572928384e-05,
      "loss": 0.0143,
      "step": 24890
    },
    {
      "epoch": 9.336332958380202,
      "grad_norm": 12.227746963500977,
      "learning_rate": 1.0663667041619798e-05,
      "loss": 0.0224,
      "step": 24900
    },
    {
      "epoch": 9.34008248968879,
      "grad_norm": 0.016024017706513405,
      "learning_rate": 1.0659917510311212e-05,
      "loss": 0.0046,
      "step": 24910
    },
    {
      "epoch": 9.343832020997375,
      "grad_norm": 0.002302455250173807,
      "learning_rate": 1.0656167979002625e-05,
      "loss": 0.0199,
      "step": 24920
    },
    {
      "epoch": 9.34758155230596,
      "grad_norm": 0.8614606261253357,
      "learning_rate": 1.0652418447694039e-05,
      "loss": 0.0065,
      "step": 24930
    },
    {
      "epoch": 9.351331083614548,
      "grad_norm": 0.09845239669084549,
      "learning_rate": 1.0648668916385451e-05,
      "loss": 0.0071,
      "step": 24940
    },
    {
      "epoch": 9.355080614923134,
      "grad_norm": 0.1967327892780304,
      "learning_rate": 1.0644919385076866e-05,
      "loss": 0.0028,
      "step": 24950
    },
    {
      "epoch": 9.358830146231721,
      "grad_norm": 0.009133145213127136,
      "learning_rate": 1.0641169853768281e-05,
      "loss": 0.018,
      "step": 24960
    },
    {
      "epoch": 9.362579677540307,
      "grad_norm": 0.010356591083109379,
      "learning_rate": 1.0637420322459692e-05,
      "loss": 0.005,
      "step": 24970
    },
    {
      "epoch": 9.366329208848894,
      "grad_norm": 0.36698874831199646,
      "learning_rate": 1.0633670791151106e-05,
      "loss": 0.0059,
      "step": 24980
    },
    {
      "epoch": 9.37007874015748,
      "grad_norm": 0.00465002516284585,
      "learning_rate": 1.0629921259842522e-05,
      "loss": 0.0107,
      "step": 24990
    },
    {
      "epoch": 9.373828271466067,
      "grad_norm": 0.2256534844636917,
      "learning_rate": 1.0626171728533933e-05,
      "loss": 0.0074,
      "step": 25000
    },
    {
      "epoch": 9.377577802774653,
      "grad_norm": 0.03928887099027634,
      "learning_rate": 1.0622422197225349e-05,
      "loss": 0.0098,
      "step": 25010
    },
    {
      "epoch": 9.38132733408324,
      "grad_norm": 0.0021285326220095158,
      "learning_rate": 1.061867266591676e-05,
      "loss": 0.0177,
      "step": 25020
    },
    {
      "epoch": 9.385076865391826,
      "grad_norm": 0.0018224373925477266,
      "learning_rate": 1.0614923134608176e-05,
      "loss": 0.0065,
      "step": 25030
    },
    {
      "epoch": 9.388826396700413,
      "grad_norm": 0.5829164981842041,
      "learning_rate": 1.061117360329959e-05,
      "loss": 0.0092,
      "step": 25040
    },
    {
      "epoch": 9.392575928008998,
      "grad_norm": 0.03443370386958122,
      "learning_rate": 1.0607424071991002e-05,
      "loss": 0.0039,
      "step": 25050
    },
    {
      "epoch": 9.396325459317586,
      "grad_norm": 0.008483574725687504,
      "learning_rate": 1.0603674540682417e-05,
      "loss": 0.0109,
      "step": 25060
    },
    {
      "epoch": 9.400074990626171,
      "grad_norm": 1.4210513830184937,
      "learning_rate": 1.0599925009373829e-05,
      "loss": 0.0157,
      "step": 25070
    },
    {
      "epoch": 9.403824521934759,
      "grad_norm": 0.0013602987164631486,
      "learning_rate": 1.0596175478065243e-05,
      "loss": 0.0549,
      "step": 25080
    },
    {
      "epoch": 9.407574053243344,
      "grad_norm": 0.00260696979239583,
      "learning_rate": 1.0592425946756657e-05,
      "loss": 0.0041,
      "step": 25090
    },
    {
      "epoch": 9.411323584551932,
      "grad_norm": 0.0022071406710892916,
      "learning_rate": 1.058867641544807e-05,
      "loss": 0.0105,
      "step": 25100
    },
    {
      "epoch": 9.415073115860517,
      "grad_norm": 0.6783698797225952,
      "learning_rate": 1.0584926884139484e-05,
      "loss": 0.0083,
      "step": 25110
    },
    {
      "epoch": 9.418822647169105,
      "grad_norm": 0.3415948152542114,
      "learning_rate": 1.0581177352830898e-05,
      "loss": 0.0072,
      "step": 25120
    },
    {
      "epoch": 9.42257217847769,
      "grad_norm": 1.1746327877044678,
      "learning_rate": 1.057742782152231e-05,
      "loss": 0.0057,
      "step": 25130
    },
    {
      "epoch": 9.426321709786277,
      "grad_norm": 0.004574858117848635,
      "learning_rate": 1.0573678290213725e-05,
      "loss": 0.0086,
      "step": 25140
    },
    {
      "epoch": 9.430071241094863,
      "grad_norm": 0.00041534638148732483,
      "learning_rate": 1.0569928758905137e-05,
      "loss": 0.016,
      "step": 25150
    },
    {
      "epoch": 9.43382077240345,
      "grad_norm": 1.5475014448165894,
      "learning_rate": 1.0566179227596552e-05,
      "loss": 0.0099,
      "step": 25160
    },
    {
      "epoch": 9.437570303712036,
      "grad_norm": 0.007552586030215025,
      "learning_rate": 1.0562429696287966e-05,
      "loss": 0.0081,
      "step": 25170
    },
    {
      "epoch": 9.441319835020622,
      "grad_norm": 0.4061269164085388,
      "learning_rate": 1.0558680164979378e-05,
      "loss": 0.0008,
      "step": 25180
    },
    {
      "epoch": 9.445069366329209,
      "grad_norm": 12.928359985351562,
      "learning_rate": 1.0554930633670792e-05,
      "loss": 0.0069,
      "step": 25190
    },
    {
      "epoch": 9.448818897637794,
      "grad_norm": 0.0017122330609709024,
      "learning_rate": 1.0551181102362205e-05,
      "loss": 0.0077,
      "step": 25200
    },
    {
      "epoch": 9.452568428946382,
      "grad_norm": 2.367428779602051,
      "learning_rate": 1.054743157105362e-05,
      "loss": 0.0154,
      "step": 25210
    },
    {
      "epoch": 9.456317960254967,
      "grad_norm": 1.70923912525177,
      "learning_rate": 1.0543682039745033e-05,
      "loss": 0.0182,
      "step": 25220
    },
    {
      "epoch": 9.460067491563555,
      "grad_norm": 0.003895493457093835,
      "learning_rate": 1.0539932508436446e-05,
      "loss": 0.0085,
      "step": 25230
    },
    {
      "epoch": 9.46381702287214,
      "grad_norm": 0.13313433527946472,
      "learning_rate": 1.053618297712786e-05,
      "loss": 0.0241,
      "step": 25240
    },
    {
      "epoch": 9.467566554180728,
      "grad_norm": 0.37108153104782104,
      "learning_rate": 1.0532433445819274e-05,
      "loss": 0.0136,
      "step": 25250
    },
    {
      "epoch": 9.471316085489313,
      "grad_norm": 0.00206832611002028,
      "learning_rate": 1.0528683914510687e-05,
      "loss": 0.0018,
      "step": 25260
    },
    {
      "epoch": 9.4750656167979,
      "grad_norm": 0.636043131351471,
      "learning_rate": 1.0524934383202101e-05,
      "loss": 0.0151,
      "step": 25270
    },
    {
      "epoch": 9.478815148106486,
      "grad_norm": 0.006491212174296379,
      "learning_rate": 1.0521184851893513e-05,
      "loss": 0.0047,
      "step": 25280
    },
    {
      "epoch": 9.482564679415074,
      "grad_norm": 0.7907460331916809,
      "learning_rate": 1.0517435320584928e-05,
      "loss": 0.0072,
      "step": 25290
    },
    {
      "epoch": 9.486314210723659,
      "grad_norm": 0.06473997235298157,
      "learning_rate": 1.0513685789276342e-05,
      "loss": 0.007,
      "step": 25300
    },
    {
      "epoch": 9.490063742032246,
      "grad_norm": 0.0027659565676003695,
      "learning_rate": 1.0509936257967754e-05,
      "loss": 0.0048,
      "step": 25310
    },
    {
      "epoch": 9.493813273340832,
      "grad_norm": 0.6258512735366821,
      "learning_rate": 1.0506186726659168e-05,
      "loss": 0.0211,
      "step": 25320
    },
    {
      "epoch": 9.49756280464942,
      "grad_norm": 11.89854621887207,
      "learning_rate": 1.0502437195350581e-05,
      "loss": 0.017,
      "step": 25330
    },
    {
      "epoch": 9.501312335958005,
      "grad_norm": 6.181664943695068,
      "learning_rate": 1.0498687664041995e-05,
      "loss": 0.0257,
      "step": 25340
    },
    {
      "epoch": 9.505061867266592,
      "grad_norm": 0.0029368437826633453,
      "learning_rate": 1.049493813273341e-05,
      "loss": 0.0074,
      "step": 25350
    },
    {
      "epoch": 9.508811398575178,
      "grad_norm": 0.11104317754507065,
      "learning_rate": 1.0491188601424822e-05,
      "loss": 0.0076,
      "step": 25360
    },
    {
      "epoch": 9.512560929883765,
      "grad_norm": 0.7212111949920654,
      "learning_rate": 1.0487439070116236e-05,
      "loss": 0.0087,
      "step": 25370
    },
    {
      "epoch": 9.51631046119235,
      "grad_norm": 0.008357561193406582,
      "learning_rate": 1.048368953880765e-05,
      "loss": 0.0091,
      "step": 25380
    },
    {
      "epoch": 9.520059992500938,
      "grad_norm": 0.0019797286950051785,
      "learning_rate": 1.0479940007499063e-05,
      "loss": 0.0036,
      "step": 25390
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 0.00156059255823493,
      "learning_rate": 1.0476190476190477e-05,
      "loss": 0.0127,
      "step": 25400
    },
    {
      "epoch": 9.527559055118111,
      "grad_norm": 0.003435988212004304,
      "learning_rate": 1.047244094488189e-05,
      "loss": 0.0108,
      "step": 25410
    },
    {
      "epoch": 9.531308586426697,
      "grad_norm": 2.7104227542877197,
      "learning_rate": 1.0468691413573304e-05,
      "loss": 0.0437,
      "step": 25420
    },
    {
      "epoch": 9.535058117735282,
      "grad_norm": 3.60652494430542,
      "learning_rate": 1.046494188226472e-05,
      "loss": 0.0112,
      "step": 25430
    },
    {
      "epoch": 9.53880764904387,
      "grad_norm": 0.004010800272226334,
      "learning_rate": 1.046119235095613e-05,
      "loss": 0.0068,
      "step": 25440
    },
    {
      "epoch": 9.542557180352455,
      "grad_norm": 0.5668421983718872,
      "learning_rate": 1.0457442819647544e-05,
      "loss": 0.01,
      "step": 25450
    },
    {
      "epoch": 9.546306711661042,
      "grad_norm": 0.016584984958171844,
      "learning_rate": 1.0453693288338957e-05,
      "loss": 0.003,
      "step": 25460
    },
    {
      "epoch": 9.550056242969628,
      "grad_norm": 0.751687228679657,
      "learning_rate": 1.0449943757030371e-05,
      "loss": 0.0354,
      "step": 25470
    },
    {
      "epoch": 9.553805774278215,
      "grad_norm": 0.06461799144744873,
      "learning_rate": 1.0446194225721787e-05,
      "loss": 0.005,
      "step": 25480
    },
    {
      "epoch": 9.557555305586801,
      "grad_norm": 0.007822718471288681,
      "learning_rate": 1.0442444694413198e-05,
      "loss": 0.0054,
      "step": 25490
    },
    {
      "epoch": 9.561304836895388,
      "grad_norm": 0.5466812252998352,
      "learning_rate": 1.0438695163104614e-05,
      "loss": 0.0031,
      "step": 25500
    },
    {
      "epoch": 9.565054368203974,
      "grad_norm": 0.3041350245475769,
      "learning_rate": 1.0434945631796028e-05,
      "loss": 0.0127,
      "step": 25510
    },
    {
      "epoch": 9.568803899512561,
      "grad_norm": 0.01007340382784605,
      "learning_rate": 1.043119610048744e-05,
      "loss": 0.0118,
      "step": 25520
    },
    {
      "epoch": 9.572553430821147,
      "grad_norm": 1.62355375289917,
      "learning_rate": 1.0427446569178855e-05,
      "loss": 0.0191,
      "step": 25530
    },
    {
      "epoch": 9.576302962129734,
      "grad_norm": 0.032044995576143265,
      "learning_rate": 1.0423697037870267e-05,
      "loss": 0.0026,
      "step": 25540
    },
    {
      "epoch": 9.58005249343832,
      "grad_norm": 0.014950712211430073,
      "learning_rate": 1.0419947506561681e-05,
      "loss": 0.0001,
      "step": 25550
    },
    {
      "epoch": 9.583802024746907,
      "grad_norm": 0.003822500351816416,
      "learning_rate": 1.0416197975253095e-05,
      "loss": 0.0143,
      "step": 25560
    },
    {
      "epoch": 9.587551556055493,
      "grad_norm": 0.061197567731142044,
      "learning_rate": 1.0412448443944508e-05,
      "loss": 0.0176,
      "step": 25570
    },
    {
      "epoch": 9.59130108736408,
      "grad_norm": 0.002010322641581297,
      "learning_rate": 1.0408698912635922e-05,
      "loss": 0.0069,
      "step": 25580
    },
    {
      "epoch": 9.595050618672666,
      "grad_norm": 0.006775927729904652,
      "learning_rate": 1.0404949381327335e-05,
      "loss": 0.0074,
      "step": 25590
    },
    {
      "epoch": 9.598800149981253,
      "grad_norm": 0.02872048318386078,
      "learning_rate": 1.0401199850018749e-05,
      "loss": 0.0122,
      "step": 25600
    },
    {
      "epoch": 9.602549681289839,
      "grad_norm": 0.011286438442766666,
      "learning_rate": 1.0397450318710163e-05,
      "loss": 0.007,
      "step": 25610
    },
    {
      "epoch": 9.606299212598426,
      "grad_norm": 0.003078312613070011,
      "learning_rate": 1.0393700787401575e-05,
      "loss": 0.0107,
      "step": 25620
    },
    {
      "epoch": 9.610048743907011,
      "grad_norm": 0.4745400547981262,
      "learning_rate": 1.038995125609299e-05,
      "loss": 0.0064,
      "step": 25630
    },
    {
      "epoch": 9.613798275215599,
      "grad_norm": 1.5649179220199585,
      "learning_rate": 1.0386201724784404e-05,
      "loss": 0.0263,
      "step": 25640
    },
    {
      "epoch": 9.617547806524184,
      "grad_norm": 5.2688984870910645,
      "learning_rate": 1.0382452193475816e-05,
      "loss": 0.0135,
      "step": 25650
    },
    {
      "epoch": 9.621297337832772,
      "grad_norm": 0.01330114807933569,
      "learning_rate": 1.037870266216723e-05,
      "loss": 0.0069,
      "step": 25660
    },
    {
      "epoch": 9.625046869141357,
      "grad_norm": 0.5811477899551392,
      "learning_rate": 1.0374953130858643e-05,
      "loss": 0.007,
      "step": 25670
    },
    {
      "epoch": 9.628796400449943,
      "grad_norm": 0.249983012676239,
      "learning_rate": 1.0371203599550057e-05,
      "loss": 0.0137,
      "step": 25680
    },
    {
      "epoch": 9.63254593175853,
      "grad_norm": 0.021504336968064308,
      "learning_rate": 1.0367454068241471e-05,
      "loss": 0.0144,
      "step": 25690
    },
    {
      "epoch": 9.636295463067116,
      "grad_norm": 0.004400037229061127,
      "learning_rate": 1.0363704536932884e-05,
      "loss": 0.0015,
      "step": 25700
    },
    {
      "epoch": 9.640044994375703,
      "grad_norm": 0.4348849654197693,
      "learning_rate": 1.0359955005624298e-05,
      "loss": 0.0039,
      "step": 25710
    },
    {
      "epoch": 9.643794525684289,
      "grad_norm": 12.97897720336914,
      "learning_rate": 1.035620547431571e-05,
      "loss": 0.0192,
      "step": 25720
    },
    {
      "epoch": 9.647544056992876,
      "grad_norm": 0.005713847931474447,
      "learning_rate": 1.0352455943007125e-05,
      "loss": 0.0211,
      "step": 25730
    },
    {
      "epoch": 9.651293588301462,
      "grad_norm": 0.0423818863928318,
      "learning_rate": 1.0348706411698539e-05,
      "loss": 0.0034,
      "step": 25740
    },
    {
      "epoch": 9.655043119610049,
      "grad_norm": 0.0022245466243475676,
      "learning_rate": 1.0344956880389951e-05,
      "loss": 0.016,
      "step": 25750
    },
    {
      "epoch": 9.658792650918635,
      "grad_norm": 0.02962663024663925,
      "learning_rate": 1.0341207349081366e-05,
      "loss": 0.0081,
      "step": 25760
    },
    {
      "epoch": 9.662542182227222,
      "grad_norm": 12.197083473205566,
      "learning_rate": 1.033745781777278e-05,
      "loss": 0.0138,
      "step": 25770
    },
    {
      "epoch": 9.666291713535808,
      "grad_norm": 0.7424095869064331,
      "learning_rate": 1.0333708286464192e-05,
      "loss": 0.0111,
      "step": 25780
    },
    {
      "epoch": 9.670041244844395,
      "grad_norm": 0.6991605162620544,
      "learning_rate": 1.0329958755155606e-05,
      "loss": 0.0138,
      "step": 25790
    },
    {
      "epoch": 9.67379077615298,
      "grad_norm": 0.44175875186920166,
      "learning_rate": 1.0326209223847019e-05,
      "loss": 0.0131,
      "step": 25800
    },
    {
      "epoch": 9.677540307461568,
      "grad_norm": 0.955225944519043,
      "learning_rate": 1.0322459692538433e-05,
      "loss": 0.0103,
      "step": 25810
    },
    {
      "epoch": 9.681289838770153,
      "grad_norm": 1.4737516641616821,
      "learning_rate": 1.0318710161229847e-05,
      "loss": 0.0088,
      "step": 25820
    },
    {
      "epoch": 9.68503937007874,
      "grad_norm": 0.004323553293943405,
      "learning_rate": 1.031496062992126e-05,
      "loss": 0.0111,
      "step": 25830
    },
    {
      "epoch": 9.688788901387326,
      "grad_norm": 0.0011332290014252067,
      "learning_rate": 1.0311211098612674e-05,
      "loss": 0.0097,
      "step": 25840
    },
    {
      "epoch": 9.692538432695914,
      "grad_norm": 1.596977949142456,
      "learning_rate": 1.0307461567304087e-05,
      "loss": 0.0267,
      "step": 25850
    },
    {
      "epoch": 9.6962879640045,
      "grad_norm": 0.0019889301620423794,
      "learning_rate": 1.03037120359955e-05,
      "loss": 0.0141,
      "step": 25860
    },
    {
      "epoch": 9.700037495313087,
      "grad_norm": 0.0011735635343939066,
      "learning_rate": 1.0299962504686915e-05,
      "loss": 0.0035,
      "step": 25870
    },
    {
      "epoch": 9.703787026621672,
      "grad_norm": 0.7298408150672913,
      "learning_rate": 1.0296212973378327e-05,
      "loss": 0.0118,
      "step": 25880
    },
    {
      "epoch": 9.70753655793026,
      "grad_norm": 0.00523863872513175,
      "learning_rate": 1.0292463442069742e-05,
      "loss": 0.0288,
      "step": 25890
    },
    {
      "epoch": 9.711286089238845,
      "grad_norm": 0.454319566488266,
      "learning_rate": 1.0288713910761157e-05,
      "loss": 0.0064,
      "step": 25900
    },
    {
      "epoch": 9.715035620547432,
      "grad_norm": 0.003749361727386713,
      "learning_rate": 1.0284964379452568e-05,
      "loss": 0.0278,
      "step": 25910
    },
    {
      "epoch": 9.718785151856018,
      "grad_norm": 0.5503894686698914,
      "learning_rate": 1.0281214848143982e-05,
      "loss": 0.0122,
      "step": 25920
    },
    {
      "epoch": 9.722534683164604,
      "grad_norm": 0.682121992111206,
      "learning_rate": 1.0277465316835395e-05,
      "loss": 0.0215,
      "step": 25930
    },
    {
      "epoch": 9.726284214473191,
      "grad_norm": 0.006983802188187838,
      "learning_rate": 1.0273715785526809e-05,
      "loss": 0.0227,
      "step": 25940
    },
    {
      "epoch": 9.730033745781776,
      "grad_norm": 0.43981578946113586,
      "learning_rate": 1.0269966254218225e-05,
      "loss": 0.0083,
      "step": 25950
    },
    {
      "epoch": 9.733783277090364,
      "grad_norm": 0.002449203049764037,
      "learning_rate": 1.0266216722909636e-05,
      "loss": 0.003,
      "step": 25960
    },
    {
      "epoch": 9.73753280839895,
      "grad_norm": 0.1655682772397995,
      "learning_rate": 1.0262467191601052e-05,
      "loss": 0.0067,
      "step": 25970
    },
    {
      "epoch": 9.741282339707537,
      "grad_norm": 0.6375250816345215,
      "learning_rate": 1.0258717660292463e-05,
      "loss": 0.0095,
      "step": 25980
    },
    {
      "epoch": 9.745031871016122,
      "grad_norm": 1.5855398178100586,
      "learning_rate": 1.0254968128983878e-05,
      "loss": 0.0064,
      "step": 25990
    },
    {
      "epoch": 9.74878140232471,
      "grad_norm": 0.00171760399825871,
      "learning_rate": 1.0251218597675293e-05,
      "loss": 0.0169,
      "step": 26000
    },
    {
      "epoch": 9.752530933633295,
      "grad_norm": 0.0024959847796708345,
      "learning_rate": 1.0247469066366705e-05,
      "loss": 0.0056,
      "step": 26010
    },
    {
      "epoch": 9.756280464941883,
      "grad_norm": 0.09307996183633804,
      "learning_rate": 1.024371953505812e-05,
      "loss": 0.0145,
      "step": 26020
    },
    {
      "epoch": 9.760029996250468,
      "grad_norm": 0.9254119992256165,
      "learning_rate": 1.0239970003749533e-05,
      "loss": 0.022,
      "step": 26030
    },
    {
      "epoch": 9.763779527559056,
      "grad_norm": 0.0016039180336520076,
      "learning_rate": 1.0236220472440946e-05,
      "loss": 0.0081,
      "step": 26040
    },
    {
      "epoch": 9.767529058867641,
      "grad_norm": 1.8783859014511108,
      "learning_rate": 1.023247094113236e-05,
      "loss": 0.0198,
      "step": 26050
    },
    {
      "epoch": 9.771278590176228,
      "grad_norm": 0.2809285819530487,
      "learning_rate": 1.0228721409823773e-05,
      "loss": 0.0128,
      "step": 26060
    },
    {
      "epoch": 9.775028121484814,
      "grad_norm": 1.3008228540420532,
      "learning_rate": 1.0224971878515187e-05,
      "loss": 0.0163,
      "step": 26070
    },
    {
      "epoch": 9.778777652793401,
      "grad_norm": 0.6998201012611389,
      "learning_rate": 1.0221222347206601e-05,
      "loss": 0.025,
      "step": 26080
    },
    {
      "epoch": 9.782527184101987,
      "grad_norm": 1.1050902605056763,
      "learning_rate": 1.0217472815898013e-05,
      "loss": 0.0157,
      "step": 26090
    },
    {
      "epoch": 9.786276715410574,
      "grad_norm": 0.7558162212371826,
      "learning_rate": 1.0213723284589428e-05,
      "loss": 0.0068,
      "step": 26100
    },
    {
      "epoch": 9.79002624671916,
      "grad_norm": 1.2921230792999268,
      "learning_rate": 1.0209973753280842e-05,
      "loss": 0.0114,
      "step": 26110
    },
    {
      "epoch": 9.793775778027747,
      "grad_norm": 0.0019927064422518015,
      "learning_rate": 1.0206224221972254e-05,
      "loss": 0.019,
      "step": 26120
    },
    {
      "epoch": 9.797525309336333,
      "grad_norm": 0.0011774289887398481,
      "learning_rate": 1.0202474690663669e-05,
      "loss": 0.0085,
      "step": 26130
    },
    {
      "epoch": 9.80127484064492,
      "grad_norm": 1.051810622215271,
      "learning_rate": 1.0198725159355081e-05,
      "loss": 0.0522,
      "step": 26140
    },
    {
      "epoch": 9.805024371953506,
      "grad_norm": 0.0039038548711687326,
      "learning_rate": 1.0194975628046495e-05,
      "loss": 0.0098,
      "step": 26150
    },
    {
      "epoch": 9.808773903262093,
      "grad_norm": 3.690215587615967,
      "learning_rate": 1.019122609673791e-05,
      "loss": 0.0187,
      "step": 26160
    },
    {
      "epoch": 9.812523434570679,
      "grad_norm": 0.11623307317495346,
      "learning_rate": 1.0187476565429322e-05,
      "loss": 0.0076,
      "step": 26170
    },
    {
      "epoch": 9.816272965879264,
      "grad_norm": 0.006790222600102425,
      "learning_rate": 1.0183727034120736e-05,
      "loss": 0.0065,
      "step": 26180
    },
    {
      "epoch": 9.820022497187852,
      "grad_norm": 1.694340467453003,
      "learning_rate": 1.0179977502812149e-05,
      "loss": 0.0222,
      "step": 26190
    },
    {
      "epoch": 9.823772028496437,
      "grad_norm": 0.750332772731781,
      "learning_rate": 1.0176227971503563e-05,
      "loss": 0.0161,
      "step": 26200
    },
    {
      "epoch": 9.827521559805025,
      "grad_norm": 0.03955276682972908,
      "learning_rate": 1.0172478440194977e-05,
      "loss": 0.0232,
      "step": 26210
    },
    {
      "epoch": 9.83127109111361,
      "grad_norm": 0.004458975046873093,
      "learning_rate": 1.016872890888639e-05,
      "loss": 0.0054,
      "step": 26220
    },
    {
      "epoch": 9.835020622422197,
      "grad_norm": 0.016107553616166115,
      "learning_rate": 1.0164979377577804e-05,
      "loss": 0.0077,
      "step": 26230
    },
    {
      "epoch": 9.838770153730783,
      "grad_norm": 0.023930970579385757,
      "learning_rate": 1.0161229846269218e-05,
      "loss": 0.0109,
      "step": 26240
    },
    {
      "epoch": 9.84251968503937,
      "grad_norm": 0.41366633772850037,
      "learning_rate": 1.015748031496063e-05,
      "loss": 0.0218,
      "step": 26250
    },
    {
      "epoch": 9.846269216347956,
      "grad_norm": 0.007004354614764452,
      "learning_rate": 1.0153730783652045e-05,
      "loss": 0.015,
      "step": 26260
    },
    {
      "epoch": 9.850018747656543,
      "grad_norm": 0.3686215281486511,
      "learning_rate": 1.0149981252343457e-05,
      "loss": 0.0111,
      "step": 26270
    },
    {
      "epoch": 9.853768278965129,
      "grad_norm": 12.948811531066895,
      "learning_rate": 1.0146231721034871e-05,
      "loss": 0.0257,
      "step": 26280
    },
    {
      "epoch": 9.857517810273716,
      "grad_norm": 0.7841300368309021,
      "learning_rate": 1.0142482189726285e-05,
      "loss": 0.0126,
      "step": 26290
    },
    {
      "epoch": 9.861267341582302,
      "grad_norm": 2.3527979850769043,
      "learning_rate": 1.0138732658417698e-05,
      "loss": 0.011,
      "step": 26300
    },
    {
      "epoch": 9.86501687289089,
      "grad_norm": 0.028774667531251907,
      "learning_rate": 1.0134983127109112e-05,
      "loss": 0.0093,
      "step": 26310
    },
    {
      "epoch": 9.868766404199475,
      "grad_norm": 0.028613580390810966,
      "learning_rate": 1.0131233595800525e-05,
      "loss": 0.027,
      "step": 26320
    },
    {
      "epoch": 9.872515935508062,
      "grad_norm": 0.006036240607500076,
      "learning_rate": 1.0127484064491939e-05,
      "loss": 0.0049,
      "step": 26330
    },
    {
      "epoch": 9.876265466816648,
      "grad_norm": 2.033968687057495,
      "learning_rate": 1.0123734533183353e-05,
      "loss": 0.0079,
      "step": 26340
    },
    {
      "epoch": 9.880014998125235,
      "grad_norm": 0.8442152738571167,
      "learning_rate": 1.0119985001874765e-05,
      "loss": 0.0171,
      "step": 26350
    },
    {
      "epoch": 9.88376452943382,
      "grad_norm": 0.6371945142745972,
      "learning_rate": 1.011623547056618e-05,
      "loss": 0.0094,
      "step": 26360
    },
    {
      "epoch": 9.887514060742408,
      "grad_norm": 0.035785820335149765,
      "learning_rate": 1.0112485939257596e-05,
      "loss": 0.0093,
      "step": 26370
    },
    {
      "epoch": 9.891263592050993,
      "grad_norm": 0.42098915576934814,
      "learning_rate": 1.0108736407949006e-05,
      "loss": 0.0053,
      "step": 26380
    },
    {
      "epoch": 9.89501312335958,
      "grad_norm": 0.6570502519607544,
      "learning_rate": 1.010498687664042e-05,
      "loss": 0.004,
      "step": 26390
    },
    {
      "epoch": 9.898762654668166,
      "grad_norm": 0.005040889140218496,
      "learning_rate": 1.0101237345331833e-05,
      "loss": 0.002,
      "step": 26400
    },
    {
      "epoch": 9.902512185976754,
      "grad_norm": 0.6300867199897766,
      "learning_rate": 1.0097487814023247e-05,
      "loss": 0.013,
      "step": 26410
    },
    {
      "epoch": 9.90626171728534,
      "grad_norm": 0.0013659780379384756,
      "learning_rate": 1.0093738282714663e-05,
      "loss": 0.0038,
      "step": 26420
    },
    {
      "epoch": 9.910011248593925,
      "grad_norm": 0.5085026025772095,
      "learning_rate": 1.0089988751406074e-05,
      "loss": 0.0128,
      "step": 26430
    },
    {
      "epoch": 9.913760779902512,
      "grad_norm": 0.5087355375289917,
      "learning_rate": 1.008623922009749e-05,
      "loss": 0.0072,
      "step": 26440
    },
    {
      "epoch": 9.917510311211098,
      "grad_norm": 0.49986106157302856,
      "learning_rate": 1.00824896887889e-05,
      "loss": 0.0087,
      "step": 26450
    },
    {
      "epoch": 9.921259842519685,
      "grad_norm": 0.0018892836524173617,
      "learning_rate": 1.0078740157480316e-05,
      "loss": 0.008,
      "step": 26460
    },
    {
      "epoch": 9.92500937382827,
      "grad_norm": 0.003445181529968977,
      "learning_rate": 1.007499062617173e-05,
      "loss": 0.0362,
      "step": 26470
    },
    {
      "epoch": 9.928758905136858,
      "grad_norm": 0.02150118723511696,
      "learning_rate": 1.0071241094863143e-05,
      "loss": 0.0076,
      "step": 26480
    },
    {
      "epoch": 9.932508436445444,
      "grad_norm": 0.003646623343229294,
      "learning_rate": 1.0067491563554557e-05,
      "loss": 0.0116,
      "step": 26490
    },
    {
      "epoch": 9.936257967754031,
      "grad_norm": 0.007779969833791256,
      "learning_rate": 1.0063742032245971e-05,
      "loss": 0.0112,
      "step": 26500
    },
    {
      "epoch": 9.940007499062617,
      "grad_norm": 0.006133878603577614,
      "learning_rate": 1.0059992500937384e-05,
      "loss": 0.0095,
      "step": 26510
    },
    {
      "epoch": 9.943757030371204,
      "grad_norm": 0.8128701448440552,
      "learning_rate": 1.0056242969628798e-05,
      "loss": 0.0147,
      "step": 26520
    },
    {
      "epoch": 9.94750656167979,
      "grad_norm": 0.8997612595558167,
      "learning_rate": 1.005249343832021e-05,
      "loss": 0.0112,
      "step": 26530
    },
    {
      "epoch": 9.951256092988377,
      "grad_norm": 0.13577938079833984,
      "learning_rate": 1.0048743907011625e-05,
      "loss": 0.006,
      "step": 26540
    },
    {
      "epoch": 9.955005624296962,
      "grad_norm": 0.14064328372478485,
      "learning_rate": 1.0044994375703039e-05,
      "loss": 0.019,
      "step": 26550
    },
    {
      "epoch": 9.95875515560555,
      "grad_norm": 0.34980857372283936,
      "learning_rate": 1.0041244844394452e-05,
      "loss": 0.0037,
      "step": 26560
    },
    {
      "epoch": 9.962504686914135,
      "grad_norm": 0.2843119204044342,
      "learning_rate": 1.0037495313085866e-05,
      "loss": 0.0046,
      "step": 26570
    },
    {
      "epoch": 9.966254218222723,
      "grad_norm": 8.225932121276855,
      "learning_rate": 1.0033745781777278e-05,
      "loss": 0.0143,
      "step": 26580
    },
    {
      "epoch": 9.970003749531308,
      "grad_norm": 1.58999764919281,
      "learning_rate": 1.0029996250468692e-05,
      "loss": 0.0129,
      "step": 26590
    },
    {
      "epoch": 9.973753280839896,
      "grad_norm": 0.0029279764275997877,
      "learning_rate": 1.0026246719160107e-05,
      "loss": 0.0066,
      "step": 26600
    },
    {
      "epoch": 9.977502812148481,
      "grad_norm": 1.288062334060669,
      "learning_rate": 1.0022497187851519e-05,
      "loss": 0.0072,
      "step": 26610
    },
    {
      "epoch": 9.981252343457069,
      "grad_norm": 0.7728356122970581,
      "learning_rate": 1.0018747656542933e-05,
      "loss": 0.0338,
      "step": 26620
    },
    {
      "epoch": 9.985001874765654,
      "grad_norm": 0.2745373547077179,
      "learning_rate": 1.0014998125234347e-05,
      "loss": 0.0056,
      "step": 26630
    },
    {
      "epoch": 9.988751406074242,
      "grad_norm": 0.3282855749130249,
      "learning_rate": 1.001124859392576e-05,
      "loss": 0.0081,
      "step": 26640
    },
    {
      "epoch": 9.992500937382827,
      "grad_norm": 0.12542390823364258,
      "learning_rate": 1.0007499062617174e-05,
      "loss": 0.0084,
      "step": 26650
    },
    {
      "epoch": 9.996250468691414,
      "grad_norm": 0.0021803677082061768,
      "learning_rate": 1.0003749531308587e-05,
      "loss": 0.0066,
      "step": 26660
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.7017084360122681,
      "learning_rate": 1e-05,
      "loss": 0.0082,
      "step": 26670
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.99332895888014,
      "eval_f1": 0.9740609496810774,
      "eval_loss": 0.023334244266152382,
      "eval_precision": 0.982275586049171,
      "eval_recall": 0.9659825695811076,
      "eval_runtime": 873.5479,
      "eval_samples_per_second": 31.404,
      "eval_steps_per_second": 1.31,
      "step": 26670
    },
    {
      "epoch": 10.003749531308586,
      "grad_norm": 0.9006727933883667,
      "learning_rate": 9.996250468691413e-06,
      "loss": 0.011,
      "step": 26680
    },
    {
      "epoch": 10.007499062617173,
      "grad_norm": 0.0026825652457773685,
      "learning_rate": 9.992500937382827e-06,
      "loss": 0.0053,
      "step": 26690
    },
    {
      "epoch": 10.011248593925758,
      "grad_norm": 0.0024272005539387465,
      "learning_rate": 9.988751406074242e-06,
      "loss": 0.0078,
      "step": 26700
    },
    {
      "epoch": 10.014998125234346,
      "grad_norm": 0.21326158940792084,
      "learning_rate": 9.985001874765656e-06,
      "loss": 0.0247,
      "step": 26710
    },
    {
      "epoch": 10.018747656542931,
      "grad_norm": 0.6790494918823242,
      "learning_rate": 9.981252343457068e-06,
      "loss": 0.0199,
      "step": 26720
    },
    {
      "epoch": 10.022497187851519,
      "grad_norm": 0.5368677973747253,
      "learning_rate": 9.977502812148483e-06,
      "loss": 0.0146,
      "step": 26730
    },
    {
      "epoch": 10.026246719160104,
      "grad_norm": 0.004709702450782061,
      "learning_rate": 9.973753280839897e-06,
      "loss": 0.01,
      "step": 26740
    },
    {
      "epoch": 10.029996250468692,
      "grad_norm": 0.0053908503614366055,
      "learning_rate": 9.97000374953131e-06,
      "loss": 0.0027,
      "step": 26750
    },
    {
      "epoch": 10.033745781777277,
      "grad_norm": 0.0026293136179447174,
      "learning_rate": 9.966254218222723e-06,
      "loss": 0.007,
      "step": 26760
    },
    {
      "epoch": 10.037495313085865,
      "grad_norm": 0.362805038690567,
      "learning_rate": 9.962504686914136e-06,
      "loss": 0.0238,
      "step": 26770
    },
    {
      "epoch": 10.04124484439445,
      "grad_norm": 0.6555476784706116,
      "learning_rate": 9.95875515560555e-06,
      "loss": 0.0057,
      "step": 26780
    },
    {
      "epoch": 10.044994375703038,
      "grad_norm": 1.3741834163665771,
      "learning_rate": 9.955005624296964e-06,
      "loss": 0.0358,
      "step": 26790
    },
    {
      "epoch": 10.048743907011623,
      "grad_norm": 0.009282881394028664,
      "learning_rate": 9.951256092988377e-06,
      "loss": 0.0025,
      "step": 26800
    },
    {
      "epoch": 10.05249343832021,
      "grad_norm": 0.0075910212472081184,
      "learning_rate": 9.947506561679791e-06,
      "loss": 0.0154,
      "step": 26810
    },
    {
      "epoch": 10.056242969628796,
      "grad_norm": 0.003224221058189869,
      "learning_rate": 9.943757030371203e-06,
      "loss": 0.0052,
      "step": 26820
    },
    {
      "epoch": 10.059992500937383,
      "grad_norm": 0.36661550402641296,
      "learning_rate": 9.940007499062618e-06,
      "loss": 0.0112,
      "step": 26830
    },
    {
      "epoch": 10.063742032245969,
      "grad_norm": 0.04238269105553627,
      "learning_rate": 9.936257967754032e-06,
      "loss": 0.0044,
      "step": 26840
    },
    {
      "epoch": 10.067491563554556,
      "grad_norm": 1.0145291090011597,
      "learning_rate": 9.932508436445444e-06,
      "loss": 0.0077,
      "step": 26850
    },
    {
      "epoch": 10.071241094863142,
      "grad_norm": 0.0020186242181807756,
      "learning_rate": 9.928758905136859e-06,
      "loss": 0.0065,
      "step": 26860
    },
    {
      "epoch": 10.07499062617173,
      "grad_norm": 0.002449484309181571,
      "learning_rate": 9.925009373828273e-06,
      "loss": 0.0024,
      "step": 26870
    },
    {
      "epoch": 10.078740157480315,
      "grad_norm": 0.07535911351442337,
      "learning_rate": 9.921259842519685e-06,
      "loss": 0.0105,
      "step": 26880
    },
    {
      "epoch": 10.082489688788902,
      "grad_norm": 2.503253936767578,
      "learning_rate": 9.9175103112111e-06,
      "loss": 0.0096,
      "step": 26890
    },
    {
      "epoch": 10.086239220097488,
      "grad_norm": 0.004238554742187262,
      "learning_rate": 9.913760779902512e-06,
      "loss": 0.0076,
      "step": 26900
    },
    {
      "epoch": 10.089988751406075,
      "grad_norm": 0.5914106369018555,
      "learning_rate": 9.910011248593928e-06,
      "loss": 0.0109,
      "step": 26910
    },
    {
      "epoch": 10.09373828271466,
      "grad_norm": 0.0012301428942009807,
      "learning_rate": 9.90626171728534e-06,
      "loss": 0.0149,
      "step": 26920
    },
    {
      "epoch": 10.097487814023246,
      "grad_norm": 0.027273600921034813,
      "learning_rate": 9.902512185976754e-06,
      "loss": 0.0128,
      "step": 26930
    },
    {
      "epoch": 10.101237345331834,
      "grad_norm": 0.0019275964004918933,
      "learning_rate": 9.898762654668167e-06,
      "loss": 0.01,
      "step": 26940
    },
    {
      "epoch": 10.10498687664042,
      "grad_norm": 0.23757010698318481,
      "learning_rate": 9.895013123359581e-06,
      "loss": 0.0175,
      "step": 26950
    },
    {
      "epoch": 10.108736407949007,
      "grad_norm": 0.8434447050094604,
      "learning_rate": 9.891263592050995e-06,
      "loss": 0.0161,
      "step": 26960
    },
    {
      "epoch": 10.112485939257592,
      "grad_norm": 0.0018525682389736176,
      "learning_rate": 9.887514060742408e-06,
      "loss": 0.0175,
      "step": 26970
    },
    {
      "epoch": 10.11623547056618,
      "grad_norm": 0.0034470618702471256,
      "learning_rate": 9.883764529433822e-06,
      "loss": 0.0062,
      "step": 26980
    },
    {
      "epoch": 10.119985001874765,
      "grad_norm": 0.7347424030303955,
      "learning_rate": 9.880014998125235e-06,
      "loss": 0.0061,
      "step": 26990
    },
    {
      "epoch": 10.123734533183352,
      "grad_norm": 0.005945821758359671,
      "learning_rate": 9.876265466816649e-06,
      "loss": 0.0091,
      "step": 27000
    },
    {
      "epoch": 10.127484064491938,
      "grad_norm": 0.052490487694740295,
      "learning_rate": 9.872515935508063e-06,
      "loss": 0.0098,
      "step": 27010
    },
    {
      "epoch": 10.131233595800525,
      "grad_norm": 0.0027404946740716696,
      "learning_rate": 9.868766404199475e-06,
      "loss": 0.0098,
      "step": 27020
    },
    {
      "epoch": 10.13498312710911,
      "grad_norm": 0.0018823358695954084,
      "learning_rate": 9.86501687289089e-06,
      "loss": 0.0061,
      "step": 27030
    },
    {
      "epoch": 10.138732658417698,
      "grad_norm": 0.6099352836608887,
      "learning_rate": 9.861267341582304e-06,
      "loss": 0.0055,
      "step": 27040
    },
    {
      "epoch": 10.142482189726284,
      "grad_norm": 0.0015218676999211311,
      "learning_rate": 9.857517810273716e-06,
      "loss": 0.0073,
      "step": 27050
    },
    {
      "epoch": 10.146231721034871,
      "grad_norm": 0.6692315340042114,
      "learning_rate": 9.85376827896513e-06,
      "loss": 0.0163,
      "step": 27060
    },
    {
      "epoch": 10.149981252343457,
      "grad_norm": 0.0020242216996848583,
      "learning_rate": 9.850018747656543e-06,
      "loss": 0.008,
      "step": 27070
    },
    {
      "epoch": 10.153730783652044,
      "grad_norm": 0.8602341413497925,
      "learning_rate": 9.846269216347957e-06,
      "loss": 0.0079,
      "step": 27080
    },
    {
      "epoch": 10.15748031496063,
      "grad_norm": 0.10398687422275543,
      "learning_rate": 9.842519685039371e-06,
      "loss": 0.0082,
      "step": 27090
    },
    {
      "epoch": 10.161229846269217,
      "grad_norm": 0.4874342978000641,
      "learning_rate": 9.838770153730784e-06,
      "loss": 0.0104,
      "step": 27100
    },
    {
      "epoch": 10.164979377577803,
      "grad_norm": 0.6838062405586243,
      "learning_rate": 9.835020622422198e-06,
      "loss": 0.0138,
      "step": 27110
    },
    {
      "epoch": 10.16872890888639,
      "grad_norm": 0.046523794531822205,
      "learning_rate": 9.83127109111361e-06,
      "loss": 0.0746,
      "step": 27120
    },
    {
      "epoch": 10.172478440194975,
      "grad_norm": 0.6130042672157288,
      "learning_rate": 9.827521559805026e-06,
      "loss": 0.0173,
      "step": 27130
    },
    {
      "epoch": 10.176227971503563,
      "grad_norm": 0.001522177830338478,
      "learning_rate": 9.823772028496439e-06,
      "loss": 0.0051,
      "step": 27140
    },
    {
      "epoch": 10.179977502812148,
      "grad_norm": 0.7267139554023743,
      "learning_rate": 9.820022497187851e-06,
      "loss": 0.0029,
      "step": 27150
    },
    {
      "epoch": 10.183727034120736,
      "grad_norm": 0.8000152111053467,
      "learning_rate": 9.816272965879266e-06,
      "loss": 0.0058,
      "step": 27160
    },
    {
      "epoch": 10.187476565429321,
      "grad_norm": 1.8860063552856445,
      "learning_rate": 9.81252343457068e-06,
      "loss": 0.0195,
      "step": 27170
    },
    {
      "epoch": 10.191226096737907,
      "grad_norm": 0.6381800770759583,
      "learning_rate": 9.808773903262094e-06,
      "loss": 0.0124,
      "step": 27180
    },
    {
      "epoch": 10.194975628046494,
      "grad_norm": 8.956685066223145,
      "learning_rate": 9.805024371953506e-06,
      "loss": 0.0101,
      "step": 27190
    },
    {
      "epoch": 10.19872515935508,
      "grad_norm": 0.003794947173446417,
      "learning_rate": 9.80127484064492e-06,
      "loss": 0.0067,
      "step": 27200
    },
    {
      "epoch": 10.202474690663667,
      "grad_norm": 0.5258706212043762,
      "learning_rate": 9.797525309336335e-06,
      "loss": 0.0037,
      "step": 27210
    },
    {
      "epoch": 10.206224221972253,
      "grad_norm": 0.0026564812287688255,
      "learning_rate": 9.793775778027747e-06,
      "loss": 0.0059,
      "step": 27220
    },
    {
      "epoch": 10.20997375328084,
      "grad_norm": 0.002323342487215996,
      "learning_rate": 9.790026246719161e-06,
      "loss": 0.0038,
      "step": 27230
    },
    {
      "epoch": 10.213723284589426,
      "grad_norm": 0.0015490762889385223,
      "learning_rate": 9.786276715410574e-06,
      "loss": 0.0056,
      "step": 27240
    },
    {
      "epoch": 10.217472815898013,
      "grad_norm": 2.736077070236206,
      "learning_rate": 9.782527184101988e-06,
      "loss": 0.0082,
      "step": 27250
    },
    {
      "epoch": 10.221222347206599,
      "grad_norm": 0.0017143944278359413,
      "learning_rate": 9.778777652793402e-06,
      "loss": 0.024,
      "step": 27260
    },
    {
      "epoch": 10.224971878515186,
      "grad_norm": 0.09959892928600311,
      "learning_rate": 9.775028121484815e-06,
      "loss": 0.0233,
      "step": 27270
    },
    {
      "epoch": 10.228721409823772,
      "grad_norm": 0.0027526705525815487,
      "learning_rate": 9.771278590176229e-06,
      "loss": 0.0279,
      "step": 27280
    },
    {
      "epoch": 10.232470941132359,
      "grad_norm": 0.405409574508667,
      "learning_rate": 9.767529058867642e-06,
      "loss": 0.0124,
      "step": 27290
    },
    {
      "epoch": 10.236220472440944,
      "grad_norm": 0.003902520751580596,
      "learning_rate": 9.763779527559056e-06,
      "loss": 0.004,
      "step": 27300
    },
    {
      "epoch": 10.239970003749532,
      "grad_norm": 0.0023183454759418964,
      "learning_rate": 9.76002999625047e-06,
      "loss": 0.0076,
      "step": 27310
    },
    {
      "epoch": 10.243719535058117,
      "grad_norm": 2.2082326412200928,
      "learning_rate": 9.756280464941882e-06,
      "loss": 0.0207,
      "step": 27320
    },
    {
      "epoch": 10.247469066366705,
      "grad_norm": 0.059859756380319595,
      "learning_rate": 9.752530933633297e-06,
      "loss": 0.0042,
      "step": 27330
    },
    {
      "epoch": 10.25121859767529,
      "grad_norm": 0.6817448735237122,
      "learning_rate": 9.74878140232471e-06,
      "loss": 0.0113,
      "step": 27340
    },
    {
      "epoch": 10.254968128983878,
      "grad_norm": 0.3402259945869446,
      "learning_rate": 9.745031871016123e-06,
      "loss": 0.0226,
      "step": 27350
    },
    {
      "epoch": 10.258717660292463,
      "grad_norm": 1.967276692390442,
      "learning_rate": 9.741282339707537e-06,
      "loss": 0.0054,
      "step": 27360
    },
    {
      "epoch": 10.26246719160105,
      "grad_norm": 0.004053219687193632,
      "learning_rate": 9.73753280839895e-06,
      "loss": 0.0052,
      "step": 27370
    },
    {
      "epoch": 10.266216722909636,
      "grad_norm": 2.3073832988739014,
      "learning_rate": 9.733783277090364e-06,
      "loss": 0.0178,
      "step": 27380
    },
    {
      "epoch": 10.269966254218224,
      "grad_norm": 0.6573453545570374,
      "learning_rate": 9.730033745781778e-06,
      "loss": 0.0363,
      "step": 27390
    },
    {
      "epoch": 10.273715785526809,
      "grad_norm": 0.0071991560980677605,
      "learning_rate": 9.726284214473192e-06,
      "loss": 0.0143,
      "step": 27400
    },
    {
      "epoch": 10.277465316835396,
      "grad_norm": 1.0259979963302612,
      "learning_rate": 9.722534683164605e-06,
      "loss": 0.0242,
      "step": 27410
    },
    {
      "epoch": 10.281214848143982,
      "grad_norm": 0.9764440059661865,
      "learning_rate": 9.71878515185602e-06,
      "loss": 0.0035,
      "step": 27420
    },
    {
      "epoch": 10.284964379452568,
      "grad_norm": 0.013027937151491642,
      "learning_rate": 9.715035620547433e-06,
      "loss": 0.0106,
      "step": 27430
    },
    {
      "epoch": 10.288713910761155,
      "grad_norm": 0.8958955407142639,
      "learning_rate": 9.711286089238846e-06,
      "loss": 0.0211,
      "step": 27440
    },
    {
      "epoch": 10.29246344206974,
      "grad_norm": 0.02044997550547123,
      "learning_rate": 9.70753655793026e-06,
      "loss": 0.0056,
      "step": 27450
    },
    {
      "epoch": 10.296212973378328,
      "grad_norm": 0.3311152458190918,
      "learning_rate": 9.703787026621673e-06,
      "loss": 0.0042,
      "step": 27460
    },
    {
      "epoch": 10.299962504686913,
      "grad_norm": 0.007433354388922453,
      "learning_rate": 9.700037495313087e-06,
      "loss": 0.0117,
      "step": 27470
    },
    {
      "epoch": 10.3037120359955,
      "grad_norm": 0.003258059499785304,
      "learning_rate": 9.696287964004501e-06,
      "loss": 0.0095,
      "step": 27480
    },
    {
      "epoch": 10.307461567304086,
      "grad_norm": 1.4836434125900269,
      "learning_rate": 9.692538432695913e-06,
      "loss": 0.0214,
      "step": 27490
    },
    {
      "epoch": 10.311211098612674,
      "grad_norm": 0.005337405484169722,
      "learning_rate": 9.688788901387328e-06,
      "loss": 0.007,
      "step": 27500
    },
    {
      "epoch": 10.31496062992126,
      "grad_norm": 2.1206958293914795,
      "learning_rate": 9.68503937007874e-06,
      "loss": 0.0423,
      "step": 27510
    },
    {
      "epoch": 10.318710161229847,
      "grad_norm": 0.0047435821034014225,
      "learning_rate": 9.681289838770154e-06,
      "loss": 0.0095,
      "step": 27520
    },
    {
      "epoch": 10.322459692538432,
      "grad_norm": 0.006825720891356468,
      "learning_rate": 9.677540307461568e-06,
      "loss": 0.0048,
      "step": 27530
    },
    {
      "epoch": 10.32620922384702,
      "grad_norm": 0.004624242428690195,
      "learning_rate": 9.673790776152981e-06,
      "loss": 0.0045,
      "step": 27540
    },
    {
      "epoch": 10.329958755155605,
      "grad_norm": 0.02690954878926277,
      "learning_rate": 9.670041244844395e-06,
      "loss": 0.0269,
      "step": 27550
    },
    {
      "epoch": 10.333708286464192,
      "grad_norm": 6.158226013183594,
      "learning_rate": 9.66629171353581e-06,
      "loss": 0.0266,
      "step": 27560
    },
    {
      "epoch": 10.337457817772778,
      "grad_norm": 0.02924647554755211,
      "learning_rate": 9.662542182227222e-06,
      "loss": 0.0015,
      "step": 27570
    },
    {
      "epoch": 10.341207349081365,
      "grad_norm": 0.9107730984687805,
      "learning_rate": 9.658792650918636e-06,
      "loss": 0.0177,
      "step": 27580
    },
    {
      "epoch": 10.344956880389951,
      "grad_norm": 0.24482226371765137,
      "learning_rate": 9.655043119610049e-06,
      "loss": 0.0101,
      "step": 27590
    },
    {
      "epoch": 10.348706411698538,
      "grad_norm": 0.7877710461616516,
      "learning_rate": 9.651293588301464e-06,
      "loss": 0.0216,
      "step": 27600
    },
    {
      "epoch": 10.352455943007124,
      "grad_norm": 0.1621445268392563,
      "learning_rate": 9.647544056992877e-06,
      "loss": 0.0028,
      "step": 27610
    },
    {
      "epoch": 10.356205474315711,
      "grad_norm": 0.007668872829526663,
      "learning_rate": 9.64379452568429e-06,
      "loss": 0.0131,
      "step": 27620
    },
    {
      "epoch": 10.359955005624297,
      "grad_norm": 0.008155967108905315,
      "learning_rate": 9.640044994375704e-06,
      "loss": 0.0065,
      "step": 27630
    },
    {
      "epoch": 10.363704536932884,
      "grad_norm": 2.2930071353912354,
      "learning_rate": 9.636295463067118e-06,
      "loss": 0.0354,
      "step": 27640
    },
    {
      "epoch": 10.36745406824147,
      "grad_norm": 0.010429274290800095,
      "learning_rate": 9.632545931758532e-06,
      "loss": 0.006,
      "step": 27650
    },
    {
      "epoch": 10.371203599550057,
      "grad_norm": 0.8082526326179504,
      "learning_rate": 9.628796400449944e-06,
      "loss": 0.0064,
      "step": 27660
    },
    {
      "epoch": 10.374953130858643,
      "grad_norm": 5.632317543029785,
      "learning_rate": 9.625046869141359e-06,
      "loss": 0.0159,
      "step": 27670
    },
    {
      "epoch": 10.378702662167228,
      "grad_norm": 0.0031181650701910257,
      "learning_rate": 9.621297337832771e-06,
      "loss": 0.0057,
      "step": 27680
    },
    {
      "epoch": 10.382452193475816,
      "grad_norm": 0.9277395606040955,
      "learning_rate": 9.617547806524185e-06,
      "loss": 0.0113,
      "step": 27690
    },
    {
      "epoch": 10.386201724784401,
      "grad_norm": 0.2991150915622711,
      "learning_rate": 9.6137982752156e-06,
      "loss": 0.0025,
      "step": 27700
    },
    {
      "epoch": 10.389951256092989,
      "grad_norm": 1.2104564905166626,
      "learning_rate": 9.610048743907012e-06,
      "loss": 0.0056,
      "step": 27710
    },
    {
      "epoch": 10.393700787401574,
      "grad_norm": 0.002356693847104907,
      "learning_rate": 9.606299212598426e-06,
      "loss": 0.0064,
      "step": 27720
    },
    {
      "epoch": 10.397450318710161,
      "grad_norm": 8.011289596557617,
      "learning_rate": 9.60254968128984e-06,
      "loss": 0.0128,
      "step": 27730
    },
    {
      "epoch": 10.401199850018747,
      "grad_norm": 0.002457115100696683,
      "learning_rate": 9.598800149981253e-06,
      "loss": 0.0128,
      "step": 27740
    },
    {
      "epoch": 10.404949381327334,
      "grad_norm": 0.005894726607948542,
      "learning_rate": 9.595050618672667e-06,
      "loss": 0.0032,
      "step": 27750
    },
    {
      "epoch": 10.40869891263592,
      "grad_norm": 0.001670721685513854,
      "learning_rate": 9.59130108736408e-06,
      "loss": 0.0162,
      "step": 27760
    },
    {
      "epoch": 10.412448443944507,
      "grad_norm": 0.5335953235626221,
      "learning_rate": 9.587551556055494e-06,
      "loss": 0.0014,
      "step": 27770
    },
    {
      "epoch": 10.416197975253093,
      "grad_norm": 0.004184504505246878,
      "learning_rate": 9.583802024746908e-06,
      "loss": 0.0206,
      "step": 27780
    },
    {
      "epoch": 10.41994750656168,
      "grad_norm": 0.00565629918128252,
      "learning_rate": 9.58005249343832e-06,
      "loss": 0.0089,
      "step": 27790
    },
    {
      "epoch": 10.423697037870266,
      "grad_norm": 0.5498137474060059,
      "learning_rate": 9.576302962129735e-06,
      "loss": 0.0084,
      "step": 27800
    },
    {
      "epoch": 10.427446569178853,
      "grad_norm": 0.0039174193516373634,
      "learning_rate": 9.572553430821147e-06,
      "loss": 0.0093,
      "step": 27810
    },
    {
      "epoch": 10.431196100487439,
      "grad_norm": 0.002785962773486972,
      "learning_rate": 9.568803899512561e-06,
      "loss": 0.0006,
      "step": 27820
    },
    {
      "epoch": 10.434945631796026,
      "grad_norm": 0.007166767492890358,
      "learning_rate": 9.565054368203975e-06,
      "loss": 0.0281,
      "step": 27830
    },
    {
      "epoch": 10.438695163104612,
      "grad_norm": 0.002793371444568038,
      "learning_rate": 9.561304836895388e-06,
      "loss": 0.0033,
      "step": 27840
    },
    {
      "epoch": 10.442444694413199,
      "grad_norm": 0.005124147981405258,
      "learning_rate": 9.557555305586802e-06,
      "loss": 0.0038,
      "step": 27850
    },
    {
      "epoch": 10.446194225721785,
      "grad_norm": 2.718090057373047,
      "learning_rate": 9.553805774278216e-06,
      "loss": 0.0079,
      "step": 27860
    },
    {
      "epoch": 10.449943757030372,
      "grad_norm": 0.003251629415899515,
      "learning_rate": 9.55005624296963e-06,
      "loss": 0.0101,
      "step": 27870
    },
    {
      "epoch": 10.453693288338958,
      "grad_norm": 0.8065592646598816,
      "learning_rate": 9.546306711661043e-06,
      "loss": 0.0146,
      "step": 27880
    },
    {
      "epoch": 10.457442819647545,
      "grad_norm": 0.0034345402382314205,
      "learning_rate": 9.542557180352457e-06,
      "loss": 0.0071,
      "step": 27890
    },
    {
      "epoch": 10.46119235095613,
      "grad_norm": 0.0053208195604383945,
      "learning_rate": 9.538807649043871e-06,
      "loss": 0.012,
      "step": 27900
    },
    {
      "epoch": 10.464941882264718,
      "grad_norm": 0.012559337541460991,
      "learning_rate": 9.535058117735284e-06,
      "loss": 0.0132,
      "step": 27910
    },
    {
      "epoch": 10.468691413573303,
      "grad_norm": 0.36624544858932495,
      "learning_rate": 9.531308586426698e-06,
      "loss": 0.0034,
      "step": 27920
    },
    {
      "epoch": 10.472440944881889,
      "grad_norm": 0.004723748657852411,
      "learning_rate": 9.52755905511811e-06,
      "loss": 0.0198,
      "step": 27930
    },
    {
      "epoch": 10.476190476190476,
      "grad_norm": 0.014091823250055313,
      "learning_rate": 9.523809523809525e-06,
      "loss": 0.0089,
      "step": 27940
    },
    {
      "epoch": 10.479940007499062,
      "grad_norm": 0.011921204626560211,
      "learning_rate": 9.520059992500939e-06,
      "loss": 0.0081,
      "step": 27950
    },
    {
      "epoch": 10.48368953880765,
      "grad_norm": 0.7387338280677795,
      "learning_rate": 9.516310461192351e-06,
      "loss": 0.0056,
      "step": 27960
    },
    {
      "epoch": 10.487439070116235,
      "grad_norm": 0.4084799885749817,
      "learning_rate": 9.512560929883766e-06,
      "loss": 0.0052,
      "step": 27970
    },
    {
      "epoch": 10.491188601424822,
      "grad_norm": 0.002526087686419487,
      "learning_rate": 9.508811398575178e-06,
      "loss": 0.0038,
      "step": 27980
    },
    {
      "epoch": 10.494938132733408,
      "grad_norm": 0.006224589888006449,
      "learning_rate": 9.505061867266592e-06,
      "loss": 0.0199,
      "step": 27990
    },
    {
      "epoch": 10.498687664041995,
      "grad_norm": 28.758140563964844,
      "learning_rate": 9.501312335958006e-06,
      "loss": 0.0067,
      "step": 28000
    },
    {
      "epoch": 10.50243719535058,
      "grad_norm": 0.00264567113481462,
      "learning_rate": 9.497562804649419e-06,
      "loss": 0.0062,
      "step": 28010
    },
    {
      "epoch": 10.506186726659168,
      "grad_norm": 0.003767221001908183,
      "learning_rate": 9.493813273340833e-06,
      "loss": 0.0021,
      "step": 28020
    },
    {
      "epoch": 10.509936257967754,
      "grad_norm": 0.009406114928424358,
      "learning_rate": 9.490063742032247e-06,
      "loss": 0.0024,
      "step": 28030
    },
    {
      "epoch": 10.513685789276341,
      "grad_norm": 0.006519548129290342,
      "learning_rate": 9.48631421072366e-06,
      "loss": 0.0051,
      "step": 28040
    },
    {
      "epoch": 10.517435320584926,
      "grad_norm": 0.22342410683631897,
      "learning_rate": 9.482564679415074e-06,
      "loss": 0.0336,
      "step": 28050
    },
    {
      "epoch": 10.521184851893514,
      "grad_norm": 0.5495243668556213,
      "learning_rate": 9.478815148106487e-06,
      "loss": 0.0054,
      "step": 28060
    },
    {
      "epoch": 10.5249343832021,
      "grad_norm": 0.0038016983307898045,
      "learning_rate": 9.4750656167979e-06,
      "loss": 0.014,
      "step": 28070
    },
    {
      "epoch": 10.528683914510687,
      "grad_norm": 0.08396628499031067,
      "learning_rate": 9.471316085489315e-06,
      "loss": 0.0097,
      "step": 28080
    },
    {
      "epoch": 10.532433445819272,
      "grad_norm": 0.0038840093184262514,
      "learning_rate": 9.467566554180727e-06,
      "loss": 0.0089,
      "step": 28090
    },
    {
      "epoch": 10.53618297712786,
      "grad_norm": 0.007161820773035288,
      "learning_rate": 9.463817022872142e-06,
      "loss": 0.0243,
      "step": 28100
    },
    {
      "epoch": 10.539932508436445,
      "grad_norm": 0.5206093192100525,
      "learning_rate": 9.460067491563554e-06,
      "loss": 0.0117,
      "step": 28110
    },
    {
      "epoch": 10.543682039745033,
      "grad_norm": 0.5516361594200134,
      "learning_rate": 9.45631796025497e-06,
      "loss": 0.0099,
      "step": 28120
    },
    {
      "epoch": 10.547431571053618,
      "grad_norm": 0.026631560176610947,
      "learning_rate": 9.452568428946382e-06,
      "loss": 0.0192,
      "step": 28130
    },
    {
      "epoch": 10.551181102362206,
      "grad_norm": 0.0038096087519079447,
      "learning_rate": 9.448818897637797e-06,
      "loss": 0.0107,
      "step": 28140
    },
    {
      "epoch": 10.554930633670791,
      "grad_norm": 0.1875045746564865,
      "learning_rate": 9.445069366329209e-06,
      "loss": 0.0041,
      "step": 28150
    },
    {
      "epoch": 10.558680164979378,
      "grad_norm": 0.007374120410531759,
      "learning_rate": 9.441319835020623e-06,
      "loss": 0.0245,
      "step": 28160
    },
    {
      "epoch": 10.562429696287964,
      "grad_norm": 0.46304836869239807,
      "learning_rate": 9.437570303712038e-06,
      "loss": 0.011,
      "step": 28170
    },
    {
      "epoch": 10.56617922759655,
      "grad_norm": 0.02861643396317959,
      "learning_rate": 9.43382077240345e-06,
      "loss": 0.016,
      "step": 28180
    },
    {
      "epoch": 10.569928758905137,
      "grad_norm": 0.0049115135334432125,
      "learning_rate": 9.430071241094864e-06,
      "loss": 0.0165,
      "step": 28190
    },
    {
      "epoch": 10.573678290213723,
      "grad_norm": 0.012989633716642857,
      "learning_rate": 9.426321709786278e-06,
      "loss": 0.0078,
      "step": 28200
    },
    {
      "epoch": 10.57742782152231,
      "grad_norm": 0.019997693598270416,
      "learning_rate": 9.422572178477691e-06,
      "loss": 0.0014,
      "step": 28210
    },
    {
      "epoch": 10.581177352830895,
      "grad_norm": 0.006277424283325672,
      "learning_rate": 9.418822647169105e-06,
      "loss": 0.01,
      "step": 28220
    },
    {
      "epoch": 10.584926884139483,
      "grad_norm": 0.00585572887212038,
      "learning_rate": 9.415073115860518e-06,
      "loss": 0.0028,
      "step": 28230
    },
    {
      "epoch": 10.588676415448068,
      "grad_norm": 0.006545939017087221,
      "learning_rate": 9.411323584551932e-06,
      "loss": 0.0065,
      "step": 28240
    },
    {
      "epoch": 10.592425946756656,
      "grad_norm": 0.689210832118988,
      "learning_rate": 9.407574053243346e-06,
      "loss": 0.0386,
      "step": 28250
    },
    {
      "epoch": 10.596175478065241,
      "grad_norm": 0.05784314498305321,
      "learning_rate": 9.403824521934758e-06,
      "loss": 0.0039,
      "step": 28260
    },
    {
      "epoch": 10.599925009373829,
      "grad_norm": 0.022979844361543655,
      "learning_rate": 9.400074990626173e-06,
      "loss": 0.0179,
      "step": 28270
    },
    {
      "epoch": 10.603674540682414,
      "grad_norm": 0.849806010723114,
      "learning_rate": 9.396325459317585e-06,
      "loss": 0.008,
      "step": 28280
    },
    {
      "epoch": 10.607424071991002,
      "grad_norm": 0.5225467681884766,
      "learning_rate": 9.392575928009e-06,
      "loss": 0.0055,
      "step": 28290
    },
    {
      "epoch": 10.611173603299587,
      "grad_norm": 0.04096177965402603,
      "learning_rate": 9.388826396700413e-06,
      "loss": 0.0068,
      "step": 28300
    },
    {
      "epoch": 10.614923134608174,
      "grad_norm": 0.0027251930441707373,
      "learning_rate": 9.385076865391826e-06,
      "loss": 0.0101,
      "step": 28310
    },
    {
      "epoch": 10.61867266591676,
      "grad_norm": 0.043057747185230255,
      "learning_rate": 9.38132733408324e-06,
      "loss": 0.0104,
      "step": 28320
    },
    {
      "epoch": 10.622422197225347,
      "grad_norm": 0.23852142691612244,
      "learning_rate": 9.377577802774654e-06,
      "loss": 0.0092,
      "step": 28330
    },
    {
      "epoch": 10.626171728533933,
      "grad_norm": 0.03511407598853111,
      "learning_rate": 9.373828271466069e-06,
      "loss": 0.0129,
      "step": 28340
    },
    {
      "epoch": 10.62992125984252,
      "grad_norm": 0.0033250206615775824,
      "learning_rate": 9.370078740157481e-06,
      "loss": 0.0169,
      "step": 28350
    },
    {
      "epoch": 10.633670791151106,
      "grad_norm": 0.00350122875533998,
      "learning_rate": 9.366329208848895e-06,
      "loss": 0.0028,
      "step": 28360
    },
    {
      "epoch": 10.637420322459693,
      "grad_norm": 0.015079270116984844,
      "learning_rate": 9.362579677540308e-06,
      "loss": 0.0136,
      "step": 28370
    },
    {
      "epoch": 10.641169853768279,
      "grad_norm": 0.014956993982195854,
      "learning_rate": 9.358830146231722e-06,
      "loss": 0.0074,
      "step": 28380
    },
    {
      "epoch": 10.644919385076866,
      "grad_norm": 1.944904088973999,
      "learning_rate": 9.355080614923136e-06,
      "loss": 0.0259,
      "step": 28390
    },
    {
      "epoch": 10.648668916385452,
      "grad_norm": 0.052735526114702225,
      "learning_rate": 9.351331083614549e-06,
      "loss": 0.0047,
      "step": 28400
    },
    {
      "epoch": 10.65241844769404,
      "grad_norm": 0.33190396428108215,
      "learning_rate": 9.347581552305963e-06,
      "loss": 0.0057,
      "step": 28410
    },
    {
      "epoch": 10.656167979002625,
      "grad_norm": 0.6456528902053833,
      "learning_rate": 9.343832020997377e-06,
      "loss": 0.0085,
      "step": 28420
    },
    {
      "epoch": 10.65991751031121,
      "grad_norm": 0.7439767718315125,
      "learning_rate": 9.34008248968879e-06,
      "loss": 0.0111,
      "step": 28430
    },
    {
      "epoch": 10.663667041619798,
      "grad_norm": 0.002231036312878132,
      "learning_rate": 9.336332958380204e-06,
      "loss": 0.0051,
      "step": 28440
    },
    {
      "epoch": 10.667416572928383,
      "grad_norm": 0.02318836748600006,
      "learning_rate": 9.332583427071616e-06,
      "loss": 0.0058,
      "step": 28450
    },
    {
      "epoch": 10.67116610423697,
      "grad_norm": 0.19900856912136078,
      "learning_rate": 9.32883389576303e-06,
      "loss": 0.0043,
      "step": 28460
    },
    {
      "epoch": 10.674915635545556,
      "grad_norm": 1.3238377571105957,
      "learning_rate": 9.325084364454445e-06,
      "loss": 0.0176,
      "step": 28470
    },
    {
      "epoch": 10.678665166854143,
      "grad_norm": 0.5870963335037231,
      "learning_rate": 9.321334833145857e-06,
      "loss": 0.0074,
      "step": 28480
    },
    {
      "epoch": 10.682414698162729,
      "grad_norm": 0.0014247625367715955,
      "learning_rate": 9.317585301837271e-06,
      "loss": 0.0383,
      "step": 28490
    },
    {
      "epoch": 10.686164229471316,
      "grad_norm": 1.162207841873169,
      "learning_rate": 9.313835770528684e-06,
      "loss": 0.0042,
      "step": 28500
    },
    {
      "epoch": 10.689913760779902,
      "grad_norm": 0.8062925934791565,
      "learning_rate": 9.310086239220098e-06,
      "loss": 0.0056,
      "step": 28510
    },
    {
      "epoch": 10.69366329208849,
      "grad_norm": 0.001667494187131524,
      "learning_rate": 9.306336707911512e-06,
      "loss": 0.0046,
      "step": 28520
    },
    {
      "epoch": 10.697412823397075,
      "grad_norm": 0.624043881893158,
      "learning_rate": 9.302587176602925e-06,
      "loss": 0.0286,
      "step": 28530
    },
    {
      "epoch": 10.701162354705662,
      "grad_norm": 0.3552245497703552,
      "learning_rate": 9.298837645294339e-06,
      "loss": 0.001,
      "step": 28540
    },
    {
      "epoch": 10.704911886014248,
      "grad_norm": 0.5942878723144531,
      "learning_rate": 9.295088113985753e-06,
      "loss": 0.0046,
      "step": 28550
    },
    {
      "epoch": 10.708661417322835,
      "grad_norm": 1.151443362236023,
      "learning_rate": 9.291338582677165e-06,
      "loss": 0.0185,
      "step": 28560
    },
    {
      "epoch": 10.71241094863142,
      "grad_norm": 0.002958587370812893,
      "learning_rate": 9.28758905136858e-06,
      "loss": 0.0209,
      "step": 28570
    },
    {
      "epoch": 10.716160479940008,
      "grad_norm": 0.0020889993757009506,
      "learning_rate": 9.283839520059992e-06,
      "loss": 0.0102,
      "step": 28580
    },
    {
      "epoch": 10.719910011248594,
      "grad_norm": 0.526469886302948,
      "learning_rate": 9.280089988751408e-06,
      "loss": 0.0106,
      "step": 28590
    },
    {
      "epoch": 10.723659542557181,
      "grad_norm": 1.0129764080047607,
      "learning_rate": 9.27634045744282e-06,
      "loss": 0.0062,
      "step": 28600
    },
    {
      "epoch": 10.727409073865767,
      "grad_norm": 0.03643159195780754,
      "learning_rate": 9.272590926134235e-06,
      "loss": 0.0031,
      "step": 28610
    },
    {
      "epoch": 10.731158605174354,
      "grad_norm": 0.0029541810508817434,
      "learning_rate": 9.268841394825647e-06,
      "loss": 0.011,
      "step": 28620
    },
    {
      "epoch": 10.73490813648294,
      "grad_norm": 0.001768583315424621,
      "learning_rate": 9.265091863517061e-06,
      "loss": 0.0032,
      "step": 28630
    },
    {
      "epoch": 10.738657667791527,
      "grad_norm": 0.15111158788204193,
      "learning_rate": 9.261342332208476e-06,
      "loss": 0.0108,
      "step": 28640
    },
    {
      "epoch": 10.742407199100112,
      "grad_norm": 0.0050196051597595215,
      "learning_rate": 9.257592800899888e-06,
      "loss": 0.0006,
      "step": 28650
    },
    {
      "epoch": 10.7461567304087,
      "grad_norm": 0.7241492867469788,
      "learning_rate": 9.253843269591302e-06,
      "loss": 0.0159,
      "step": 28660
    },
    {
      "epoch": 10.749906261717285,
      "grad_norm": 0.03575323149561882,
      "learning_rate": 9.250093738282715e-06,
      "loss": 0.0079,
      "step": 28670
    },
    {
      "epoch": 10.753655793025871,
      "grad_norm": 0.0017553039360791445,
      "learning_rate": 9.246344206974129e-06,
      "loss": 0.0104,
      "step": 28680
    },
    {
      "epoch": 10.757405324334458,
      "grad_norm": 1.3330785036087036,
      "learning_rate": 9.242594675665543e-06,
      "loss": 0.0152,
      "step": 28690
    },
    {
      "epoch": 10.761154855643044,
      "grad_norm": 0.4331074059009552,
      "learning_rate": 9.238845144356956e-06,
      "loss": 0.008,
      "step": 28700
    },
    {
      "epoch": 10.764904386951631,
      "grad_norm": 1.2565083503723145,
      "learning_rate": 9.23509561304837e-06,
      "loss": 0.016,
      "step": 28710
    },
    {
      "epoch": 10.768653918260217,
      "grad_norm": 1.10176420211792,
      "learning_rate": 9.231346081739784e-06,
      "loss": 0.0131,
      "step": 28720
    },
    {
      "epoch": 10.772403449568804,
      "grad_norm": 0.46860066056251526,
      "learning_rate": 9.227596550431196e-06,
      "loss": 0.0078,
      "step": 28730
    },
    {
      "epoch": 10.77615298087739,
      "grad_norm": 0.23900209367275238,
      "learning_rate": 9.22384701912261e-06,
      "loss": 0.0083,
      "step": 28740
    },
    {
      "epoch": 10.779902512185977,
      "grad_norm": 0.0137472003698349,
      "learning_rate": 9.220097487814023e-06,
      "loss": 0.003,
      "step": 28750
    },
    {
      "epoch": 10.783652043494563,
      "grad_norm": 0.003206884255632758,
      "learning_rate": 9.216347956505437e-06,
      "loss": 0.0188,
      "step": 28760
    },
    {
      "epoch": 10.78740157480315,
      "grad_norm": 0.0026384287048131227,
      "learning_rate": 9.212598425196852e-06,
      "loss": 0.0068,
      "step": 28770
    },
    {
      "epoch": 10.791151106111736,
      "grad_norm": 0.006133338436484337,
      "learning_rate": 9.208848893888264e-06,
      "loss": 0.0056,
      "step": 28780
    },
    {
      "epoch": 10.794900637420323,
      "grad_norm": 0.0023000927176326513,
      "learning_rate": 9.205099362579678e-06,
      "loss": 0.0086,
      "step": 28790
    },
    {
      "epoch": 10.798650168728908,
      "grad_norm": 0.0022932349238544703,
      "learning_rate": 9.20134983127109e-06,
      "loss": 0.004,
      "step": 28800
    },
    {
      "epoch": 10.802399700037496,
      "grad_norm": 0.002460625022649765,
      "learning_rate": 9.197600299962507e-06,
      "loss": 0.0247,
      "step": 28810
    },
    {
      "epoch": 10.806149231346081,
      "grad_norm": 0.003922044299542904,
      "learning_rate": 9.193850768653919e-06,
      "loss": 0.0109,
      "step": 28820
    },
    {
      "epoch": 10.809898762654669,
      "grad_norm": 0.456315815448761,
      "learning_rate": 9.190101237345333e-06,
      "loss": 0.0081,
      "step": 28830
    },
    {
      "epoch": 10.813648293963254,
      "grad_norm": 0.3754592835903168,
      "learning_rate": 9.186351706036746e-06,
      "loss": 0.0051,
      "step": 28840
    },
    {
      "epoch": 10.817397825271842,
      "grad_norm": 0.7720760107040405,
      "learning_rate": 9.18260217472816e-06,
      "loss": 0.0374,
      "step": 28850
    },
    {
      "epoch": 10.821147356580427,
      "grad_norm": 0.016542496159672737,
      "learning_rate": 9.178852643419574e-06,
      "loss": 0.0205,
      "step": 28860
    },
    {
      "epoch": 10.824896887889015,
      "grad_norm": 0.3446621894836426,
      "learning_rate": 9.175103112110987e-06,
      "loss": 0.0107,
      "step": 28870
    },
    {
      "epoch": 10.8286464191976,
      "grad_norm": 0.015201094560325146,
      "learning_rate": 9.1713535808024e-06,
      "loss": 0.0128,
      "step": 28880
    },
    {
      "epoch": 10.832395950506188,
      "grad_norm": 0.4745529592037201,
      "learning_rate": 9.167604049493815e-06,
      "loss": 0.021,
      "step": 28890
    },
    {
      "epoch": 10.836145481814773,
      "grad_norm": 0.07928208261728287,
      "learning_rate": 9.163854518185227e-06,
      "loss": 0.0123,
      "step": 28900
    },
    {
      "epoch": 10.83989501312336,
      "grad_norm": 0.0024042949080467224,
      "learning_rate": 9.160104986876642e-06,
      "loss": 0.0057,
      "step": 28910
    },
    {
      "epoch": 10.843644544431946,
      "grad_norm": 0.007924685254693031,
      "learning_rate": 9.156355455568054e-06,
      "loss": 0.0247,
      "step": 28920
    },
    {
      "epoch": 10.847394075740532,
      "grad_norm": 0.6693070530891418,
      "learning_rate": 9.152605924259468e-06,
      "loss": 0.0087,
      "step": 28930
    },
    {
      "epoch": 10.851143607049119,
      "grad_norm": 0.14707191288471222,
      "learning_rate": 9.148856392950883e-06,
      "loss": 0.0157,
      "step": 28940
    },
    {
      "epoch": 10.854893138357705,
      "grad_norm": 0.002362567698583007,
      "learning_rate": 9.145106861642295e-06,
      "loss": 0.0084,
      "step": 28950
    },
    {
      "epoch": 10.858642669666292,
      "grad_norm": 0.9018670916557312,
      "learning_rate": 9.14135733033371e-06,
      "loss": 0.0135,
      "step": 28960
    },
    {
      "epoch": 10.862392200974877,
      "grad_norm": 0.5725424289703369,
      "learning_rate": 9.137607799025122e-06,
      "loss": 0.0082,
      "step": 28970
    },
    {
      "epoch": 10.866141732283465,
      "grad_norm": 0.01231942605227232,
      "learning_rate": 9.133858267716536e-06,
      "loss": 0.011,
      "step": 28980
    },
    {
      "epoch": 10.86989126359205,
      "grad_norm": 0.0021197900641709566,
      "learning_rate": 9.13010873640795e-06,
      "loss": 0.0224,
      "step": 28990
    },
    {
      "epoch": 10.873640794900638,
      "grad_norm": 3.3671820163726807,
      "learning_rate": 9.126359205099363e-06,
      "loss": 0.0135,
      "step": 29000
    },
    {
      "epoch": 10.877390326209223,
      "grad_norm": 0.044283706694841385,
      "learning_rate": 9.122609673790777e-06,
      "loss": 0.0074,
      "step": 29010
    },
    {
      "epoch": 10.88113985751781,
      "grad_norm": 2.8193793296813965,
      "learning_rate": 9.118860142482191e-06,
      "loss": 0.0134,
      "step": 29020
    },
    {
      "epoch": 10.884889388826396,
      "grad_norm": 1.7649339437484741,
      "learning_rate": 9.115110611173603e-06,
      "loss": 0.0162,
      "step": 29030
    },
    {
      "epoch": 10.888638920134984,
      "grad_norm": 0.2856002748012543,
      "learning_rate": 9.111361079865018e-06,
      "loss": 0.0068,
      "step": 29040
    },
    {
      "epoch": 10.89238845144357,
      "grad_norm": 0.7049036622047424,
      "learning_rate": 9.10761154855643e-06,
      "loss": 0.0052,
      "step": 29050
    },
    {
      "epoch": 10.896137982752157,
      "grad_norm": 0.11506359279155731,
      "learning_rate": 9.103862017247844e-06,
      "loss": 0.0052,
      "step": 29060
    },
    {
      "epoch": 10.899887514060742,
      "grad_norm": 0.05699057877063751,
      "learning_rate": 9.100112485939259e-06,
      "loss": 0.0132,
      "step": 29070
    },
    {
      "epoch": 10.90363704536933,
      "grad_norm": 0.48450231552124023,
      "learning_rate": 9.096362954630673e-06,
      "loss": 0.0088,
      "step": 29080
    },
    {
      "epoch": 10.907386576677915,
      "grad_norm": 1.3623125553131104,
      "learning_rate": 9.092613423322085e-06,
      "loss": 0.0233,
      "step": 29090
    },
    {
      "epoch": 10.911136107986502,
      "grad_norm": 0.0032028371933847666,
      "learning_rate": 9.0888638920135e-06,
      "loss": 0.0014,
      "step": 29100
    },
    {
      "epoch": 10.914885639295088,
      "grad_norm": 0.0016757312696427107,
      "learning_rate": 9.085114360704914e-06,
      "loss": 0.0086,
      "step": 29110
    },
    {
      "epoch": 10.918635170603675,
      "grad_norm": 0.001763079664669931,
      "learning_rate": 9.081364829396326e-06,
      "loss": 0.0074,
      "step": 29120
    },
    {
      "epoch": 10.92238470191226,
      "grad_norm": 0.01312220562249422,
      "learning_rate": 9.07761529808774e-06,
      "loss": 0.0147,
      "step": 29130
    },
    {
      "epoch": 10.926134233220848,
      "grad_norm": 0.5015589594841003,
      "learning_rate": 9.073865766779153e-06,
      "loss": 0.0178,
      "step": 29140
    },
    {
      "epoch": 10.929883764529434,
      "grad_norm": 5.917994022369385,
      "learning_rate": 9.070116235470567e-06,
      "loss": 0.0132,
      "step": 29150
    },
    {
      "epoch": 10.933633295838021,
      "grad_norm": 0.6117621660232544,
      "learning_rate": 9.066366704161981e-06,
      "loss": 0.0047,
      "step": 29160
    },
    {
      "epoch": 10.937382827146607,
      "grad_norm": 0.5801051259040833,
      "learning_rate": 9.062617172853394e-06,
      "loss": 0.0057,
      "step": 29170
    },
    {
      "epoch": 10.941132358455192,
      "grad_norm": 0.1716099977493286,
      "learning_rate": 9.058867641544808e-06,
      "loss": 0.0052,
      "step": 29180
    },
    {
      "epoch": 10.94488188976378,
      "grad_norm": 0.624274492263794,
      "learning_rate": 9.05511811023622e-06,
      "loss": 0.023,
      "step": 29190
    },
    {
      "epoch": 10.948631421072365,
      "grad_norm": 0.024914706125855446,
      "learning_rate": 9.051368578927634e-06,
      "loss": 0.0118,
      "step": 29200
    },
    {
      "epoch": 10.952380952380953,
      "grad_norm": 0.0014887395082041621,
      "learning_rate": 9.047619047619049e-06,
      "loss": 0.0086,
      "step": 29210
    },
    {
      "epoch": 10.956130483689538,
      "grad_norm": 0.7700115442276001,
      "learning_rate": 9.043869516310461e-06,
      "loss": 0.0103,
      "step": 29220
    },
    {
      "epoch": 10.959880014998125,
      "grad_norm": 1.1088041067123413,
      "learning_rate": 9.040119985001875e-06,
      "loss": 0.0141,
      "step": 29230
    },
    {
      "epoch": 10.963629546306711,
      "grad_norm": 0.0027977782301604748,
      "learning_rate": 9.03637045369329e-06,
      "loss": 0.0061,
      "step": 29240
    },
    {
      "epoch": 10.967379077615298,
      "grad_norm": 0.0012500694720074534,
      "learning_rate": 9.032620922384702e-06,
      "loss": 0.0063,
      "step": 29250
    },
    {
      "epoch": 10.971128608923884,
      "grad_norm": 0.4675714373588562,
      "learning_rate": 9.028871391076116e-06,
      "loss": 0.0044,
      "step": 29260
    },
    {
      "epoch": 10.974878140232471,
      "grad_norm": 0.0009564261417835951,
      "learning_rate": 9.025121859767529e-06,
      "loss": 0.0049,
      "step": 29270
    },
    {
      "epoch": 10.978627671541057,
      "grad_norm": 0.02840845100581646,
      "learning_rate": 9.021372328458945e-06,
      "loss": 0.0146,
      "step": 29280
    },
    {
      "epoch": 10.982377202849644,
      "grad_norm": 0.0014611096121370792,
      "learning_rate": 9.017622797150357e-06,
      "loss": 0.0036,
      "step": 29290
    },
    {
      "epoch": 10.98612673415823,
      "grad_norm": 0.9326669573783875,
      "learning_rate": 9.013873265841771e-06,
      "loss": 0.0108,
      "step": 29300
    },
    {
      "epoch": 10.989876265466817,
      "grad_norm": 0.659094512462616,
      "learning_rate": 9.010123734533184e-06,
      "loss": 0.0189,
      "step": 29310
    },
    {
      "epoch": 10.993625796775403,
      "grad_norm": 0.0009066748316399753,
      "learning_rate": 9.006374203224598e-06,
      "loss": 0.021,
      "step": 29320
    },
    {
      "epoch": 10.99737532808399,
      "grad_norm": 0.023590998724102974,
      "learning_rate": 9.002624671916012e-06,
      "loss": 0.0042,
      "step": 29330
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.9936570428696413,
      "eval_f1": 0.9753959276018099,
      "eval_loss": 0.02311132475733757,
      "eval_precision": 0.9812233285917497,
      "eval_recall": 0.9696373348327242,
      "eval_runtime": 869.6527,
      "eval_samples_per_second": 31.545,
      "eval_steps_per_second": 1.315,
      "step": 29337
    }
  ],
  "logging_steps": 10,
  "max_steps": 53340,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.5498902402388096e+17,
  "train_batch_size": 48,
  "trial_name": null,
  "trial_params": null
}
