{
  "best_metric": 0.9721508140531278,
  "best_model_checkpoint": "../saved_models/command_injection/checkpoint-54870",
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 54870,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002733734281027884,
      "grad_norm": 30.45844841003418,
      "learning_rate": 1.99997266265719e-05,
      "loss": 0.6786,
      "step": 1
    },
    {
      "epoch": 0.002733734281027884,
      "grad_norm": 27.036523818969727,
      "learning_rate": 1.999726626571897e-05,
      "loss": 0.5559,
      "step": 10
    },
    {
      "epoch": 0.005467468562055768,
      "grad_norm": 20.09220314025879,
      "learning_rate": 1.999453253143795e-05,
      "loss": 0.4549,
      "step": 20
    },
    {
      "epoch": 0.008201202843083653,
      "grad_norm": 15.745601654052734,
      "learning_rate": 1.9991798797156918e-05,
      "loss": 0.4711,
      "step": 30
    },
    {
      "epoch": 0.010934937124111536,
      "grad_norm": 14.339380264282227,
      "learning_rate": 1.9989065062875888e-05,
      "loss": 0.3491,
      "step": 40
    },
    {
      "epoch": 0.01366867140513942,
      "grad_norm": 14.441752433776855,
      "learning_rate": 1.998633132859486e-05,
      "loss": 0.3904,
      "step": 50
    },
    {
      "epoch": 0.016402405686167305,
      "grad_norm": 15.3068265914917,
      "learning_rate": 1.9983597594313835e-05,
      "loss": 0.442,
      "step": 60
    },
    {
      "epoch": 0.01913613996719519,
      "grad_norm": 20.178897857666016,
      "learning_rate": 1.9980863860032805e-05,
      "loss": 0.3666,
      "step": 70
    },
    {
      "epoch": 0.02186987424822307,
      "grad_norm": 5.507610321044922,
      "learning_rate": 1.9978130125751778e-05,
      "loss": 0.3485,
      "step": 80
    },
    {
      "epoch": 0.024603608529250958,
      "grad_norm": 14.853147506713867,
      "learning_rate": 1.997539639147075e-05,
      "loss": 0.3291,
      "step": 90
    },
    {
      "epoch": 0.02733734281027884,
      "grad_norm": 21.950008392333984,
      "learning_rate": 1.997266265718972e-05,
      "loss": 0.4939,
      "step": 100
    },
    {
      "epoch": 0.030071077091306724,
      "grad_norm": 11.133777618408203,
      "learning_rate": 1.9969928922908695e-05,
      "loss": 0.4009,
      "step": 110
    },
    {
      "epoch": 0.03280481137233461,
      "grad_norm": 7.171159267425537,
      "learning_rate": 1.9967195188627665e-05,
      "loss": 0.2671,
      "step": 120
    },
    {
      "epoch": 0.035538545653362494,
      "grad_norm": 5.404509544372559,
      "learning_rate": 1.9964461454346638e-05,
      "loss": 0.2407,
      "step": 130
    },
    {
      "epoch": 0.03827227993439038,
      "grad_norm": 13.54181957244873,
      "learning_rate": 1.996172772006561e-05,
      "loss": 0.5517,
      "step": 140
    },
    {
      "epoch": 0.04100601421541826,
      "grad_norm": 11.48808765411377,
      "learning_rate": 1.995899398578458e-05,
      "loss": 0.3813,
      "step": 150
    },
    {
      "epoch": 0.04373974849644614,
      "grad_norm": 24.581344604492188,
      "learning_rate": 1.9956260251503555e-05,
      "loss": 0.4487,
      "step": 160
    },
    {
      "epoch": 0.046473482777474026,
      "grad_norm": 9.018819808959961,
      "learning_rate": 1.9953526517222528e-05,
      "loss": 0.3743,
      "step": 170
    },
    {
      "epoch": 0.049207217058501916,
      "grad_norm": 11.323673248291016,
      "learning_rate": 1.9950792782941498e-05,
      "loss": 0.335,
      "step": 180
    },
    {
      "epoch": 0.0519409513395298,
      "grad_norm": 4.385958194732666,
      "learning_rate": 1.994805904866047e-05,
      "loss": 0.2913,
      "step": 190
    },
    {
      "epoch": 0.05467468562055768,
      "grad_norm": 9.734057426452637,
      "learning_rate": 1.9945325314379445e-05,
      "loss": 0.408,
      "step": 200
    },
    {
      "epoch": 0.057408419901585565,
      "grad_norm": 11.559172630310059,
      "learning_rate": 1.9942591580098415e-05,
      "loss": 0.3269,
      "step": 210
    },
    {
      "epoch": 0.06014215418261345,
      "grad_norm": 8.54415512084961,
      "learning_rate": 1.9939857845817388e-05,
      "loss": 0.3413,
      "step": 220
    },
    {
      "epoch": 0.06287588846364134,
      "grad_norm": 10.90685749053955,
      "learning_rate": 1.993712411153636e-05,
      "loss": 0.3627,
      "step": 230
    },
    {
      "epoch": 0.06560962274466922,
      "grad_norm": 14.113151550292969,
      "learning_rate": 1.993439037725533e-05,
      "loss": 0.3196,
      "step": 240
    },
    {
      "epoch": 0.0683433570256971,
      "grad_norm": 8.20461368560791,
      "learning_rate": 1.9931656642974305e-05,
      "loss": 0.3643,
      "step": 250
    },
    {
      "epoch": 0.07107709130672499,
      "grad_norm": 9.372036933898926,
      "learning_rate": 1.9928922908693275e-05,
      "loss": 0.3652,
      "step": 260
    },
    {
      "epoch": 0.07381082558775287,
      "grad_norm": 9.614445686340332,
      "learning_rate": 1.9926189174412248e-05,
      "loss": 0.3688,
      "step": 270
    },
    {
      "epoch": 0.07654455986878075,
      "grad_norm": 7.611500263214111,
      "learning_rate": 1.992345544013122e-05,
      "loss": 0.2576,
      "step": 280
    },
    {
      "epoch": 0.07927829414980864,
      "grad_norm": 4.773839950561523,
      "learning_rate": 1.992072170585019e-05,
      "loss": 0.2721,
      "step": 290
    },
    {
      "epoch": 0.08201202843083652,
      "grad_norm": 9.21631908416748,
      "learning_rate": 1.9917987971569165e-05,
      "loss": 0.389,
      "step": 300
    },
    {
      "epoch": 0.0847457627118644,
      "grad_norm": 6.601722240447998,
      "learning_rate": 1.9915254237288138e-05,
      "loss": 0.2966,
      "step": 310
    },
    {
      "epoch": 0.08747949699289229,
      "grad_norm": 8.372444152832031,
      "learning_rate": 1.9912520503007108e-05,
      "loss": 0.1945,
      "step": 320
    },
    {
      "epoch": 0.09021323127392017,
      "grad_norm": 8.185548782348633,
      "learning_rate": 1.990978676872608e-05,
      "loss": 0.3526,
      "step": 330
    },
    {
      "epoch": 0.09294696555494805,
      "grad_norm": 7.2377753257751465,
      "learning_rate": 1.9907053034445055e-05,
      "loss": 0.2322,
      "step": 340
    },
    {
      "epoch": 0.09568069983597595,
      "grad_norm": 7.153341293334961,
      "learning_rate": 1.9904319300164025e-05,
      "loss": 0.4296,
      "step": 350
    },
    {
      "epoch": 0.09841443411700383,
      "grad_norm": 11.29092788696289,
      "learning_rate": 1.9901585565882998e-05,
      "loss": 0.3363,
      "step": 360
    },
    {
      "epoch": 0.10114816839803172,
      "grad_norm": 6.14671516418457,
      "learning_rate": 1.989885183160197e-05,
      "loss": 0.3586,
      "step": 370
    },
    {
      "epoch": 0.1038819026790596,
      "grad_norm": 18.24514389038086,
      "learning_rate": 1.989611809732094e-05,
      "loss": 0.3473,
      "step": 380
    },
    {
      "epoch": 0.10661563696008748,
      "grad_norm": 5.8513054847717285,
      "learning_rate": 1.9893384363039915e-05,
      "loss": 0.2575,
      "step": 390
    },
    {
      "epoch": 0.10934937124111536,
      "grad_norm": 8.76420783996582,
      "learning_rate": 1.9890650628758885e-05,
      "loss": 0.2413,
      "step": 400
    },
    {
      "epoch": 0.11208310552214325,
      "grad_norm": 11.837913513183594,
      "learning_rate": 1.9887916894477858e-05,
      "loss": 0.3107,
      "step": 410
    },
    {
      "epoch": 0.11481683980317113,
      "grad_norm": 10.326220512390137,
      "learning_rate": 1.988518316019683e-05,
      "loss": 0.2671,
      "step": 420
    },
    {
      "epoch": 0.11755057408419901,
      "grad_norm": 6.071012020111084,
      "learning_rate": 1.98824494259158e-05,
      "loss": 0.2854,
      "step": 430
    },
    {
      "epoch": 0.1202843083652269,
      "grad_norm": 8.059638977050781,
      "learning_rate": 1.9879715691634775e-05,
      "loss": 0.2617,
      "step": 440
    },
    {
      "epoch": 0.12301804264625478,
      "grad_norm": 9.7509183883667,
      "learning_rate": 1.9876981957353748e-05,
      "loss": 0.2681,
      "step": 450
    },
    {
      "epoch": 0.12575177692728268,
      "grad_norm": 11.74151611328125,
      "learning_rate": 1.9874248223072718e-05,
      "loss": 0.2215,
      "step": 460
    },
    {
      "epoch": 0.12848551120831056,
      "grad_norm": 12.705333709716797,
      "learning_rate": 1.987151448879169e-05,
      "loss": 0.2686,
      "step": 470
    },
    {
      "epoch": 0.13121924548933844,
      "grad_norm": 10.235986709594727,
      "learning_rate": 1.9868780754510665e-05,
      "loss": 0.2763,
      "step": 480
    },
    {
      "epoch": 0.13395297977036633,
      "grad_norm": 8.875417709350586,
      "learning_rate": 1.9866047020229635e-05,
      "loss": 0.3156,
      "step": 490
    },
    {
      "epoch": 0.1366867140513942,
      "grad_norm": 11.401656150817871,
      "learning_rate": 1.9863313285948608e-05,
      "loss": 0.307,
      "step": 500
    },
    {
      "epoch": 0.1394204483324221,
      "grad_norm": 15.176795959472656,
      "learning_rate": 1.986057955166758e-05,
      "loss": 0.2476,
      "step": 510
    },
    {
      "epoch": 0.14215418261344998,
      "grad_norm": 10.802628517150879,
      "learning_rate": 1.985784581738655e-05,
      "loss": 0.2489,
      "step": 520
    },
    {
      "epoch": 0.14488791689447786,
      "grad_norm": 6.660488605499268,
      "learning_rate": 1.9855112083105525e-05,
      "loss": 0.3139,
      "step": 530
    },
    {
      "epoch": 0.14762165117550574,
      "grad_norm": 8.651589393615723,
      "learning_rate": 1.9852378348824498e-05,
      "loss": 0.3058,
      "step": 540
    },
    {
      "epoch": 0.15035538545653362,
      "grad_norm": 8.908405303955078,
      "learning_rate": 1.9849644614543468e-05,
      "loss": 0.2345,
      "step": 550
    },
    {
      "epoch": 0.1530891197375615,
      "grad_norm": 7.778443336486816,
      "learning_rate": 1.984691088026244e-05,
      "loss": 0.2404,
      "step": 560
    },
    {
      "epoch": 0.1558228540185894,
      "grad_norm": 5.942718505859375,
      "learning_rate": 1.984417714598141e-05,
      "loss": 0.2342,
      "step": 570
    },
    {
      "epoch": 0.15855658829961727,
      "grad_norm": 6.559171199798584,
      "learning_rate": 1.9841443411700385e-05,
      "loss": 0.3351,
      "step": 580
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 7.81329870223999,
      "learning_rate": 1.9838709677419358e-05,
      "loss": 0.2676,
      "step": 590
    },
    {
      "epoch": 0.16402405686167304,
      "grad_norm": 7.097992897033691,
      "learning_rate": 1.9835975943138328e-05,
      "loss": 0.2674,
      "step": 600
    },
    {
      "epoch": 0.16675779114270092,
      "grad_norm": 10.840770721435547,
      "learning_rate": 1.98332422088573e-05,
      "loss": 0.273,
      "step": 610
    },
    {
      "epoch": 0.1694915254237288,
      "grad_norm": 4.957657814025879,
      "learning_rate": 1.9830508474576275e-05,
      "loss": 0.1803,
      "step": 620
    },
    {
      "epoch": 0.1722252597047567,
      "grad_norm": 6.675185203552246,
      "learning_rate": 1.9827774740295245e-05,
      "loss": 0.2264,
      "step": 630
    },
    {
      "epoch": 0.17495899398578457,
      "grad_norm": 4.625522136688232,
      "learning_rate": 1.9825041006014215e-05,
      "loss": 0.2246,
      "step": 640
    },
    {
      "epoch": 0.17769272826681246,
      "grad_norm": 3.825732469558716,
      "learning_rate": 1.982230727173319e-05,
      "loss": 0.1686,
      "step": 650
    },
    {
      "epoch": 0.18042646254784034,
      "grad_norm": 7.560173034667969,
      "learning_rate": 1.981957353745216e-05,
      "loss": 0.2755,
      "step": 660
    },
    {
      "epoch": 0.18316019682886822,
      "grad_norm": 5.50249719619751,
      "learning_rate": 1.981683980317113e-05,
      "loss": 0.2637,
      "step": 670
    },
    {
      "epoch": 0.1858939311098961,
      "grad_norm": 7.428067207336426,
      "learning_rate": 1.9814106068890108e-05,
      "loss": 0.2249,
      "step": 680
    },
    {
      "epoch": 0.18862766539092402,
      "grad_norm": 8.821269989013672,
      "learning_rate": 1.9811372334609078e-05,
      "loss": 0.181,
      "step": 690
    },
    {
      "epoch": 0.1913613996719519,
      "grad_norm": 4.719484329223633,
      "learning_rate": 1.9808638600328048e-05,
      "loss": 0.1967,
      "step": 700
    },
    {
      "epoch": 0.19409513395297978,
      "grad_norm": 8.154922485351562,
      "learning_rate": 1.980590486604702e-05,
      "loss": 0.2129,
      "step": 710
    },
    {
      "epoch": 0.19682886823400766,
      "grad_norm": 2.8430304527282715,
      "learning_rate": 1.9803171131765995e-05,
      "loss": 0.1836,
      "step": 720
    },
    {
      "epoch": 0.19956260251503555,
      "grad_norm": 10.848190307617188,
      "learning_rate": 1.9800437397484965e-05,
      "loss": 0.2522,
      "step": 730
    },
    {
      "epoch": 0.20229633679606343,
      "grad_norm": 14.728821754455566,
      "learning_rate": 1.9797703663203938e-05,
      "loss": 0.277,
      "step": 740
    },
    {
      "epoch": 0.2050300710770913,
      "grad_norm": 6.170296669006348,
      "learning_rate": 1.979496992892291e-05,
      "loss": 0.2551,
      "step": 750
    },
    {
      "epoch": 0.2077638053581192,
      "grad_norm": 7.876561164855957,
      "learning_rate": 1.979223619464188e-05,
      "loss": 0.2405,
      "step": 760
    },
    {
      "epoch": 0.21049753963914708,
      "grad_norm": 5.225423336029053,
      "learning_rate": 1.9789502460360855e-05,
      "loss": 0.2481,
      "step": 770
    },
    {
      "epoch": 0.21323127392017496,
      "grad_norm": 4.726667404174805,
      "learning_rate": 1.9786768726079825e-05,
      "loss": 0.2073,
      "step": 780
    },
    {
      "epoch": 0.21596500820120285,
      "grad_norm": 7.184600830078125,
      "learning_rate": 1.9784034991798798e-05,
      "loss": 0.2325,
      "step": 790
    },
    {
      "epoch": 0.21869874248223073,
      "grad_norm": 4.854421138763428,
      "learning_rate": 1.978130125751777e-05,
      "loss": 0.1669,
      "step": 800
    },
    {
      "epoch": 0.2214324767632586,
      "grad_norm": 6.185165882110596,
      "learning_rate": 1.977856752323674e-05,
      "loss": 0.1785,
      "step": 810
    },
    {
      "epoch": 0.2241662110442865,
      "grad_norm": 3.1864712238311768,
      "learning_rate": 1.9775833788955715e-05,
      "loss": 0.1437,
      "step": 820
    },
    {
      "epoch": 0.22689994532531438,
      "grad_norm": 2.687309503555298,
      "learning_rate": 1.9773100054674688e-05,
      "loss": 0.2317,
      "step": 830
    },
    {
      "epoch": 0.22963367960634226,
      "grad_norm": 8.025569915771484,
      "learning_rate": 1.9770366320393658e-05,
      "loss": 0.2836,
      "step": 840
    },
    {
      "epoch": 0.23236741388737014,
      "grad_norm": 6.1138434410095215,
      "learning_rate": 1.976763258611263e-05,
      "loss": 0.164,
      "step": 850
    },
    {
      "epoch": 0.23510114816839803,
      "grad_norm": 4.594547271728516,
      "learning_rate": 1.9764898851831605e-05,
      "loss": 0.2183,
      "step": 860
    },
    {
      "epoch": 0.2378348824494259,
      "grad_norm": 1.492061972618103,
      "learning_rate": 1.9762165117550575e-05,
      "loss": 0.1959,
      "step": 870
    },
    {
      "epoch": 0.2405686167304538,
      "grad_norm": 6.722840785980225,
      "learning_rate": 1.9759431383269548e-05,
      "loss": 0.1819,
      "step": 880
    },
    {
      "epoch": 0.24330235101148168,
      "grad_norm": 6.410202503204346,
      "learning_rate": 1.975669764898852e-05,
      "loss": 0.1396,
      "step": 890
    },
    {
      "epoch": 0.24603608529250956,
      "grad_norm": 11.372159004211426,
      "learning_rate": 1.975396391470749e-05,
      "loss": 0.2035,
      "step": 900
    },
    {
      "epoch": 0.24876981957353744,
      "grad_norm": 4.108923435211182,
      "learning_rate": 1.9751230180426465e-05,
      "loss": 0.1817,
      "step": 910
    },
    {
      "epoch": 0.25150355385456535,
      "grad_norm": 7.034514427185059,
      "learning_rate": 1.9748496446145435e-05,
      "loss": 0.1942,
      "step": 920
    },
    {
      "epoch": 0.2542372881355932,
      "grad_norm": 14.446418762207031,
      "learning_rate": 1.9745762711864408e-05,
      "loss": 0.1659,
      "step": 930
    },
    {
      "epoch": 0.2569710224166211,
      "grad_norm": 7.08936071395874,
      "learning_rate": 1.974302897758338e-05,
      "loss": 0.2488,
      "step": 940
    },
    {
      "epoch": 0.259704756697649,
      "grad_norm": 7.940866470336914,
      "learning_rate": 1.974029524330235e-05,
      "loss": 0.1903,
      "step": 950
    },
    {
      "epoch": 0.2624384909786769,
      "grad_norm": 2.7163634300231934,
      "learning_rate": 1.9737561509021325e-05,
      "loss": 0.1164,
      "step": 960
    },
    {
      "epoch": 0.26517222525970474,
      "grad_norm": 2.9335997104644775,
      "learning_rate": 1.9734827774740298e-05,
      "loss": 0.1083,
      "step": 970
    },
    {
      "epoch": 0.26790595954073265,
      "grad_norm": 5.703333854675293,
      "learning_rate": 1.9732094040459268e-05,
      "loss": 0.2379,
      "step": 980
    },
    {
      "epoch": 0.2706396938217605,
      "grad_norm": 2.2022149562835693,
      "learning_rate": 1.972936030617824e-05,
      "loss": 0.22,
      "step": 990
    },
    {
      "epoch": 0.2733734281027884,
      "grad_norm": 3.2287020683288574,
      "learning_rate": 1.9726626571897215e-05,
      "loss": 0.1397,
      "step": 1000
    },
    {
      "epoch": 0.2761071623838163,
      "grad_norm": 8.240922927856445,
      "learning_rate": 1.9723892837616185e-05,
      "loss": 0.2237,
      "step": 1010
    },
    {
      "epoch": 0.2788408966648442,
      "grad_norm": 6.752801895141602,
      "learning_rate": 1.9721159103335158e-05,
      "loss": 0.2508,
      "step": 1020
    },
    {
      "epoch": 0.28157463094587204,
      "grad_norm": 5.465122699737549,
      "learning_rate": 1.971842536905413e-05,
      "loss": 0.1192,
      "step": 1030
    },
    {
      "epoch": 0.28430836522689995,
      "grad_norm": 4.527413845062256,
      "learning_rate": 1.97156916347731e-05,
      "loss": 0.2596,
      "step": 1040
    },
    {
      "epoch": 0.2870420995079278,
      "grad_norm": 4.636478424072266,
      "learning_rate": 1.9712957900492075e-05,
      "loss": 0.1094,
      "step": 1050
    },
    {
      "epoch": 0.2897758337889557,
      "grad_norm": 4.1122822761535645,
      "learning_rate": 1.9710224166211045e-05,
      "loss": 0.1976,
      "step": 1060
    },
    {
      "epoch": 0.29250956806998357,
      "grad_norm": 10.919280052185059,
      "learning_rate": 1.9707490431930018e-05,
      "loss": 0.0983,
      "step": 1070
    },
    {
      "epoch": 0.2952433023510115,
      "grad_norm": 8.04781723022461,
      "learning_rate": 1.970475669764899e-05,
      "loss": 0.1329,
      "step": 1080
    },
    {
      "epoch": 0.29797703663203934,
      "grad_norm": 9.09710693359375,
      "learning_rate": 1.970202296336796e-05,
      "loss": 0.1402,
      "step": 1090
    },
    {
      "epoch": 0.30071077091306725,
      "grad_norm": 7.527217388153076,
      "learning_rate": 1.9699289229086935e-05,
      "loss": 0.1227,
      "step": 1100
    },
    {
      "epoch": 0.30344450519409516,
      "grad_norm": 0.8390681147575378,
      "learning_rate": 1.9696555494805908e-05,
      "loss": 0.1516,
      "step": 1110
    },
    {
      "epoch": 0.306178239475123,
      "grad_norm": 8.591230392456055,
      "learning_rate": 1.9693821760524878e-05,
      "loss": 0.152,
      "step": 1120
    },
    {
      "epoch": 0.3089119737561509,
      "grad_norm": 5.046983242034912,
      "learning_rate": 1.969108802624385e-05,
      "loss": 0.1924,
      "step": 1130
    },
    {
      "epoch": 0.3116457080371788,
      "grad_norm": 5.541715621948242,
      "learning_rate": 1.9688354291962825e-05,
      "loss": 0.1731,
      "step": 1140
    },
    {
      "epoch": 0.3143794423182067,
      "grad_norm": 7.953851222991943,
      "learning_rate": 1.9685620557681795e-05,
      "loss": 0.2542,
      "step": 1150
    },
    {
      "epoch": 0.31711317659923455,
      "grad_norm": 7.7351250648498535,
      "learning_rate": 1.9682886823400768e-05,
      "loss": 0.1534,
      "step": 1160
    },
    {
      "epoch": 0.31984691088026246,
      "grad_norm": 5.05627965927124,
      "learning_rate": 1.968015308911974e-05,
      "loss": 0.2142,
      "step": 1170
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 5.5183587074279785,
      "learning_rate": 1.967741935483871e-05,
      "loss": 0.1546,
      "step": 1180
    },
    {
      "epoch": 0.3253143794423182,
      "grad_norm": 7.3799614906311035,
      "learning_rate": 1.9674685620557685e-05,
      "loss": 0.2098,
      "step": 1190
    },
    {
      "epoch": 0.3280481137233461,
      "grad_norm": 7.83111047744751,
      "learning_rate": 1.9671951886276655e-05,
      "loss": 0.2041,
      "step": 1200
    },
    {
      "epoch": 0.330781848004374,
      "grad_norm": 9.935672760009766,
      "learning_rate": 1.9669218151995628e-05,
      "loss": 0.1019,
      "step": 1210
    },
    {
      "epoch": 0.33351558228540185,
      "grad_norm": 5.653110504150391,
      "learning_rate": 1.96664844177146e-05,
      "loss": 0.1647,
      "step": 1220
    },
    {
      "epoch": 0.33624931656642976,
      "grad_norm": 5.823814392089844,
      "learning_rate": 1.966375068343357e-05,
      "loss": 0.2772,
      "step": 1230
    },
    {
      "epoch": 0.3389830508474576,
      "grad_norm": 4.016809463500977,
      "learning_rate": 1.9661016949152545e-05,
      "loss": 0.146,
      "step": 1240
    },
    {
      "epoch": 0.3417167851284855,
      "grad_norm": 6.236647605895996,
      "learning_rate": 1.9658283214871518e-05,
      "loss": 0.1852,
      "step": 1250
    },
    {
      "epoch": 0.3444505194095134,
      "grad_norm": 3.4336464405059814,
      "learning_rate": 1.9655549480590488e-05,
      "loss": 0.123,
      "step": 1260
    },
    {
      "epoch": 0.3471842536905413,
      "grad_norm": 10.442962646484375,
      "learning_rate": 1.9652815746309458e-05,
      "loss": 0.0785,
      "step": 1270
    },
    {
      "epoch": 0.34991798797156914,
      "grad_norm": 4.696276664733887,
      "learning_rate": 1.9650082012028435e-05,
      "loss": 0.1935,
      "step": 1280
    },
    {
      "epoch": 0.35265172225259706,
      "grad_norm": 18.316320419311523,
      "learning_rate": 1.9647348277747405e-05,
      "loss": 0.1766,
      "step": 1290
    },
    {
      "epoch": 0.3553854565336249,
      "grad_norm": 11.236917495727539,
      "learning_rate": 1.9644614543466374e-05,
      "loss": 0.0886,
      "step": 1300
    },
    {
      "epoch": 0.3581191908146528,
      "grad_norm": 0.3829491138458252,
      "learning_rate": 1.964188080918535e-05,
      "loss": 0.1659,
      "step": 1310
    },
    {
      "epoch": 0.3608529250956807,
      "grad_norm": 2.848127841949463,
      "learning_rate": 1.963914707490432e-05,
      "loss": 0.19,
      "step": 1320
    },
    {
      "epoch": 0.3635866593767086,
      "grad_norm": 7.91800594329834,
      "learning_rate": 1.963641334062329e-05,
      "loss": 0.1298,
      "step": 1330
    },
    {
      "epoch": 0.36632039365773644,
      "grad_norm": 3.825286626815796,
      "learning_rate": 1.9633679606342265e-05,
      "loss": 0.1755,
      "step": 1340
    },
    {
      "epoch": 0.36905412793876435,
      "grad_norm": 3.309077501296997,
      "learning_rate": 1.9630945872061238e-05,
      "loss": 0.1368,
      "step": 1350
    },
    {
      "epoch": 0.3717878622197922,
      "grad_norm": 9.403355598449707,
      "learning_rate": 1.9628212137780208e-05,
      "loss": 0.1387,
      "step": 1360
    },
    {
      "epoch": 0.3745215965008201,
      "grad_norm": 7.299758434295654,
      "learning_rate": 1.962547840349918e-05,
      "loss": 0.1896,
      "step": 1370
    },
    {
      "epoch": 0.37725533078184803,
      "grad_norm": 3.940324306488037,
      "learning_rate": 1.9622744669218155e-05,
      "loss": 0.1542,
      "step": 1380
    },
    {
      "epoch": 0.3799890650628759,
      "grad_norm": 7.623434543609619,
      "learning_rate": 1.9620010934937124e-05,
      "loss": 0.1287,
      "step": 1390
    },
    {
      "epoch": 0.3827227993439038,
      "grad_norm": 1.8703233003616333,
      "learning_rate": 1.9617277200656098e-05,
      "loss": 0.2003,
      "step": 1400
    },
    {
      "epoch": 0.38545653362493165,
      "grad_norm": 0.6939108967781067,
      "learning_rate": 1.9614543466375068e-05,
      "loss": 0.1224,
      "step": 1410
    },
    {
      "epoch": 0.38819026790595956,
      "grad_norm": 7.042153358459473,
      "learning_rate": 1.961180973209404e-05,
      "loss": 0.0855,
      "step": 1420
    },
    {
      "epoch": 0.3909240021869874,
      "grad_norm": 7.878354549407959,
      "learning_rate": 1.9609075997813014e-05,
      "loss": 0.1185,
      "step": 1430
    },
    {
      "epoch": 0.39365773646801533,
      "grad_norm": 4.509891033172607,
      "learning_rate": 1.9606342263531984e-05,
      "loss": 0.1392,
      "step": 1440
    },
    {
      "epoch": 0.3963914707490432,
      "grad_norm": 5.707671642303467,
      "learning_rate": 1.9603608529250958e-05,
      "loss": 0.0899,
      "step": 1450
    },
    {
      "epoch": 0.3991252050300711,
      "grad_norm": 7.268327236175537,
      "learning_rate": 1.960087479496993e-05,
      "loss": 0.1119,
      "step": 1460
    },
    {
      "epoch": 0.40185893931109895,
      "grad_norm": 0.7225461602210999,
      "learning_rate": 1.95981410606889e-05,
      "loss": 0.0682,
      "step": 1470
    },
    {
      "epoch": 0.40459267359212686,
      "grad_norm": 8.969792366027832,
      "learning_rate": 1.9595407326407874e-05,
      "loss": 0.0772,
      "step": 1480
    },
    {
      "epoch": 0.4073264078731547,
      "grad_norm": 0.8047063946723938,
      "learning_rate": 1.9592673592126848e-05,
      "loss": 0.1247,
      "step": 1490
    },
    {
      "epoch": 0.4100601421541826,
      "grad_norm": 11.22863483428955,
      "learning_rate": 1.9589939857845818e-05,
      "loss": 0.2161,
      "step": 1500
    },
    {
      "epoch": 0.4127938764352105,
      "grad_norm": 7.212063789367676,
      "learning_rate": 1.958720612356479e-05,
      "loss": 0.1179,
      "step": 1510
    },
    {
      "epoch": 0.4155276107162384,
      "grad_norm": 3.370189666748047,
      "learning_rate": 1.9584472389283764e-05,
      "loss": 0.1572,
      "step": 1520
    },
    {
      "epoch": 0.41826134499726625,
      "grad_norm": 3.5510311126708984,
      "learning_rate": 1.9581738655002734e-05,
      "loss": 0.1037,
      "step": 1530
    },
    {
      "epoch": 0.42099507927829416,
      "grad_norm": 7.812742710113525,
      "learning_rate": 1.9579004920721708e-05,
      "loss": 0.1222,
      "step": 1540
    },
    {
      "epoch": 0.423728813559322,
      "grad_norm": 0.20695975422859192,
      "learning_rate": 1.9576271186440678e-05,
      "loss": 0.2294,
      "step": 1550
    },
    {
      "epoch": 0.4264625478403499,
      "grad_norm": 2.005284070968628,
      "learning_rate": 1.957353745215965e-05,
      "loss": 0.1249,
      "step": 1560
    },
    {
      "epoch": 0.4291962821213778,
      "grad_norm": 6.611394882202148,
      "learning_rate": 1.9570803717878624e-05,
      "loss": 0.1428,
      "step": 1570
    },
    {
      "epoch": 0.4319300164024057,
      "grad_norm": 8.090119361877441,
      "learning_rate": 1.9568069983597594e-05,
      "loss": 0.0837,
      "step": 1580
    },
    {
      "epoch": 0.43466375068343355,
      "grad_norm": 15.156116485595703,
      "learning_rate": 1.9565336249316568e-05,
      "loss": 0.1444,
      "step": 1590
    },
    {
      "epoch": 0.43739748496446146,
      "grad_norm": 0.904506266117096,
      "learning_rate": 1.956260251503554e-05,
      "loss": 0.0305,
      "step": 1600
    },
    {
      "epoch": 0.4401312192454893,
      "grad_norm": 18.591781616210938,
      "learning_rate": 1.955986878075451e-05,
      "loss": 0.1229,
      "step": 1610
    },
    {
      "epoch": 0.4428649535265172,
      "grad_norm": 7.923791885375977,
      "learning_rate": 1.9557135046473484e-05,
      "loss": 0.042,
      "step": 1620
    },
    {
      "epoch": 0.4455986878075451,
      "grad_norm": 4.401944160461426,
      "learning_rate": 1.9554401312192458e-05,
      "loss": 0.2199,
      "step": 1630
    },
    {
      "epoch": 0.448332422088573,
      "grad_norm": 1.5431482791900635,
      "learning_rate": 1.9551667577911428e-05,
      "loss": 0.1732,
      "step": 1640
    },
    {
      "epoch": 0.4510661563696009,
      "grad_norm": 3.65822172164917,
      "learning_rate": 1.95489338436304e-05,
      "loss": 0.1425,
      "step": 1650
    },
    {
      "epoch": 0.45379989065062876,
      "grad_norm": 3.6766104698181152,
      "learning_rate": 1.9546200109349374e-05,
      "loss": 0.1433,
      "step": 1660
    },
    {
      "epoch": 0.45653362493165667,
      "grad_norm": 8.652105331420898,
      "learning_rate": 1.9543466375068344e-05,
      "loss": 0.1972,
      "step": 1670
    },
    {
      "epoch": 0.4592673592126845,
      "grad_norm": 1.8028146028518677,
      "learning_rate": 1.9540732640787318e-05,
      "loss": 0.0702,
      "step": 1680
    },
    {
      "epoch": 0.46200109349371243,
      "grad_norm": 2.3454689979553223,
      "learning_rate": 1.953799890650629e-05,
      "loss": 0.1454,
      "step": 1690
    },
    {
      "epoch": 0.4647348277747403,
      "grad_norm": 7.5476298332214355,
      "learning_rate": 1.953526517222526e-05,
      "loss": 0.1135,
      "step": 1700
    },
    {
      "epoch": 0.4674685620557682,
      "grad_norm": 0.23503486812114716,
      "learning_rate": 1.9532531437944234e-05,
      "loss": 0.1416,
      "step": 1710
    },
    {
      "epoch": 0.47020229633679606,
      "grad_norm": 7.151422500610352,
      "learning_rate": 1.9529797703663204e-05,
      "loss": 0.1505,
      "step": 1720
    },
    {
      "epoch": 0.47293603061782397,
      "grad_norm": 2.5722110271453857,
      "learning_rate": 1.9527063969382178e-05,
      "loss": 0.0822,
      "step": 1730
    },
    {
      "epoch": 0.4756697648988518,
      "grad_norm": 0.7263998985290527,
      "learning_rate": 1.952433023510115e-05,
      "loss": 0.1026,
      "step": 1740
    },
    {
      "epoch": 0.47840349917987973,
      "grad_norm": 1.4865765571594238,
      "learning_rate": 1.952159650082012e-05,
      "loss": 0.0842,
      "step": 1750
    },
    {
      "epoch": 0.4811372334609076,
      "grad_norm": 2.855517864227295,
      "learning_rate": 1.9518862766539094e-05,
      "loss": 0.0328,
      "step": 1760
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 3.8386425971984863,
      "learning_rate": 1.9516129032258068e-05,
      "loss": 0.1776,
      "step": 1770
    },
    {
      "epoch": 0.48660470202296335,
      "grad_norm": 1.3967657089233398,
      "learning_rate": 1.9513395297977038e-05,
      "loss": 0.1209,
      "step": 1780
    },
    {
      "epoch": 0.48933843630399126,
      "grad_norm": 7.377339839935303,
      "learning_rate": 1.951066156369601e-05,
      "loss": 0.1448,
      "step": 1790
    },
    {
      "epoch": 0.4920721705850191,
      "grad_norm": 1.2658342123031616,
      "learning_rate": 1.9507927829414984e-05,
      "loss": 0.0934,
      "step": 1800
    },
    {
      "epoch": 0.49480590486604703,
      "grad_norm": 5.119266510009766,
      "learning_rate": 1.9505194095133954e-05,
      "loss": 0.0706,
      "step": 1810
    },
    {
      "epoch": 0.4975396391470749,
      "grad_norm": 10.595892906188965,
      "learning_rate": 1.9502460360852928e-05,
      "loss": 0.1496,
      "step": 1820
    },
    {
      "epoch": 0.5002733734281027,
      "grad_norm": 6.071438312530518,
      "learning_rate": 1.94997266265719e-05,
      "loss": 0.1065,
      "step": 1830
    },
    {
      "epoch": 0.5030071077091307,
      "grad_norm": 4.408604145050049,
      "learning_rate": 1.949699289229087e-05,
      "loss": 0.1157,
      "step": 1840
    },
    {
      "epoch": 0.5057408419901586,
      "grad_norm": 2.834224224090576,
      "learning_rate": 1.9494259158009844e-05,
      "loss": 0.1683,
      "step": 1850
    },
    {
      "epoch": 0.5084745762711864,
      "grad_norm": 2.8813087940216064,
      "learning_rate": 1.9491525423728814e-05,
      "loss": 0.0542,
      "step": 1860
    },
    {
      "epoch": 0.5112083105522143,
      "grad_norm": 4.034458160400391,
      "learning_rate": 1.9488791689447788e-05,
      "loss": 0.1594,
      "step": 1870
    },
    {
      "epoch": 0.5139420448332422,
      "grad_norm": 5.91728401184082,
      "learning_rate": 1.948605795516676e-05,
      "loss": 0.0988,
      "step": 1880
    },
    {
      "epoch": 0.5166757791142701,
      "grad_norm": 5.181671142578125,
      "learning_rate": 1.948332422088573e-05,
      "loss": 0.0638,
      "step": 1890
    },
    {
      "epoch": 0.519409513395298,
      "grad_norm": 3.2167303562164307,
      "learning_rate": 1.9480590486604704e-05,
      "loss": 0.1209,
      "step": 1900
    },
    {
      "epoch": 0.5221432476763258,
      "grad_norm": 0.9106525778770447,
      "learning_rate": 1.9477856752323678e-05,
      "loss": 0.0394,
      "step": 1910
    },
    {
      "epoch": 0.5248769819573538,
      "grad_norm": 0.49007439613342285,
      "learning_rate": 1.9475123018042648e-05,
      "loss": 0.0991,
      "step": 1920
    },
    {
      "epoch": 0.5276107162383816,
      "grad_norm": 7.646872043609619,
      "learning_rate": 1.9472389283761618e-05,
      "loss": 0.0836,
      "step": 1930
    },
    {
      "epoch": 0.5303444505194095,
      "grad_norm": 10.349737167358398,
      "learning_rate": 1.9469655549480594e-05,
      "loss": 0.0771,
      "step": 1940
    },
    {
      "epoch": 0.5330781848004374,
      "grad_norm": 5.814757823944092,
      "learning_rate": 1.9466921815199564e-05,
      "loss": 0.0869,
      "step": 1950
    },
    {
      "epoch": 0.5358119190814653,
      "grad_norm": 6.554683208465576,
      "learning_rate": 1.9464188080918534e-05,
      "loss": 0.1025,
      "step": 1960
    },
    {
      "epoch": 0.5385456533624932,
      "grad_norm": 11.33087158203125,
      "learning_rate": 1.946145434663751e-05,
      "loss": 0.1575,
      "step": 1970
    },
    {
      "epoch": 0.541279387643521,
      "grad_norm": 6.751777172088623,
      "learning_rate": 1.945872061235648e-05,
      "loss": 0.1131,
      "step": 1980
    },
    {
      "epoch": 0.544013121924549,
      "grad_norm": 5.407217502593994,
      "learning_rate": 1.945598687807545e-05,
      "loss": 0.0977,
      "step": 1990
    },
    {
      "epoch": 0.5467468562055768,
      "grad_norm": 7.4447526931762695,
      "learning_rate": 1.9453253143794424e-05,
      "loss": 0.1179,
      "step": 2000
    },
    {
      "epoch": 0.5494805904866047,
      "grad_norm": 3.8297975063323975,
      "learning_rate": 1.9450519409513398e-05,
      "loss": 0.0741,
      "step": 2010
    },
    {
      "epoch": 0.5522143247676325,
      "grad_norm": 0.1919253170490265,
      "learning_rate": 1.9447785675232368e-05,
      "loss": 0.0873,
      "step": 2020
    },
    {
      "epoch": 0.5549480590486605,
      "grad_norm": 2.1343588829040527,
      "learning_rate": 1.944505194095134e-05,
      "loss": 0.0682,
      "step": 2030
    },
    {
      "epoch": 0.5576817933296884,
      "grad_norm": 5.284481525421143,
      "learning_rate": 1.9442318206670314e-05,
      "loss": 0.1536,
      "step": 2040
    },
    {
      "epoch": 0.5604155276107162,
      "grad_norm": 2.072552442550659,
      "learning_rate": 1.9439584472389284e-05,
      "loss": 0.0986,
      "step": 2050
    },
    {
      "epoch": 0.5631492618917441,
      "grad_norm": 3.550541639328003,
      "learning_rate": 1.9436850738108258e-05,
      "loss": 0.1171,
      "step": 2060
    },
    {
      "epoch": 0.565882996172772,
      "grad_norm": 0.31403613090515137,
      "learning_rate": 1.9434117003827228e-05,
      "loss": 0.0722,
      "step": 2070
    },
    {
      "epoch": 0.5686167304537999,
      "grad_norm": 0.32010042667388916,
      "learning_rate": 1.94313832695462e-05,
      "loss": 0.0622,
      "step": 2080
    },
    {
      "epoch": 0.5713504647348278,
      "grad_norm": 6.8533148765563965,
      "learning_rate": 1.9428649535265174e-05,
      "loss": 0.109,
      "step": 2090
    },
    {
      "epoch": 0.5740841990158556,
      "grad_norm": 0.4315266013145447,
      "learning_rate": 1.9425915800984144e-05,
      "loss": 0.1506,
      "step": 2100
    },
    {
      "epoch": 0.5768179332968836,
      "grad_norm": 2.342186212539673,
      "learning_rate": 1.9423182066703118e-05,
      "loss": 0.0565,
      "step": 2110
    },
    {
      "epoch": 0.5795516675779114,
      "grad_norm": 7.394104957580566,
      "learning_rate": 1.942044833242209e-05,
      "loss": 0.074,
      "step": 2120
    },
    {
      "epoch": 0.5822854018589393,
      "grad_norm": 1.6469358205795288,
      "learning_rate": 1.941771459814106e-05,
      "loss": 0.0976,
      "step": 2130
    },
    {
      "epoch": 0.5850191361399671,
      "grad_norm": 6.24978494644165,
      "learning_rate": 1.9414980863860034e-05,
      "loss": 0.0942,
      "step": 2140
    },
    {
      "epoch": 0.5877528704209951,
      "grad_norm": 12.100945472717285,
      "learning_rate": 1.9412247129579008e-05,
      "loss": 0.0765,
      "step": 2150
    },
    {
      "epoch": 0.590486604702023,
      "grad_norm": 6.218242168426514,
      "learning_rate": 1.9409513395297978e-05,
      "loss": 0.0516,
      "step": 2160
    },
    {
      "epoch": 0.5932203389830508,
      "grad_norm": 9.231489181518555,
      "learning_rate": 1.940677966101695e-05,
      "loss": 0.1001,
      "step": 2170
    },
    {
      "epoch": 0.5959540732640787,
      "grad_norm": 2.946726083755493,
      "learning_rate": 1.9404045926735924e-05,
      "loss": 0.1074,
      "step": 2180
    },
    {
      "epoch": 0.5986878075451066,
      "grad_norm": 10.043635368347168,
      "learning_rate": 1.9401312192454894e-05,
      "loss": 0.0873,
      "step": 2190
    },
    {
      "epoch": 0.6014215418261345,
      "grad_norm": 2.8789620399475098,
      "learning_rate": 1.9398578458173868e-05,
      "loss": 0.0435,
      "step": 2200
    },
    {
      "epoch": 0.6041552761071624,
      "grad_norm": 5.684756755828857,
      "learning_rate": 1.9395844723892838e-05,
      "loss": 0.1146,
      "step": 2210
    },
    {
      "epoch": 0.6068890103881903,
      "grad_norm": 0.1439841091632843,
      "learning_rate": 1.939311098961181e-05,
      "loss": 0.0763,
      "step": 2220
    },
    {
      "epoch": 0.6096227446692182,
      "grad_norm": 3.6979236602783203,
      "learning_rate": 1.9390377255330784e-05,
      "loss": 0.066,
      "step": 2230
    },
    {
      "epoch": 0.612356478950246,
      "grad_norm": 11.627763748168945,
      "learning_rate": 1.9387643521049754e-05,
      "loss": 0.0933,
      "step": 2240
    },
    {
      "epoch": 0.6150902132312739,
      "grad_norm": 0.3545699715614319,
      "learning_rate": 1.9384909786768728e-05,
      "loss": 0.0844,
      "step": 2250
    },
    {
      "epoch": 0.6178239475123019,
      "grad_norm": 1.9465693235397339,
      "learning_rate": 1.93821760524877e-05,
      "loss": 0.032,
      "step": 2260
    },
    {
      "epoch": 0.6205576817933297,
      "grad_norm": 6.3971848487854,
      "learning_rate": 1.937944231820667e-05,
      "loss": 0.1022,
      "step": 2270
    },
    {
      "epoch": 0.6232914160743576,
      "grad_norm": 5.035484790802002,
      "learning_rate": 1.9376708583925644e-05,
      "loss": 0.1837,
      "step": 2280
    },
    {
      "epoch": 0.6260251503553854,
      "grad_norm": 5.071230888366699,
      "learning_rate": 1.9373974849644618e-05,
      "loss": 0.1097,
      "step": 2290
    },
    {
      "epoch": 0.6287588846364134,
      "grad_norm": 9.008184432983398,
      "learning_rate": 1.9371241115363588e-05,
      "loss": 0.1591,
      "step": 2300
    },
    {
      "epoch": 0.6314926189174412,
      "grad_norm": 8.511387825012207,
      "learning_rate": 1.936850738108256e-05,
      "loss": 0.0707,
      "step": 2310
    },
    {
      "epoch": 0.6342263531984691,
      "grad_norm": 0.35761940479278564,
      "learning_rate": 1.9365773646801534e-05,
      "loss": 0.0217,
      "step": 2320
    },
    {
      "epoch": 0.636960087479497,
      "grad_norm": 4.239157199859619,
      "learning_rate": 1.9363039912520504e-05,
      "loss": 0.1246,
      "step": 2330
    },
    {
      "epoch": 0.6396938217605249,
      "grad_norm": 0.08790905773639679,
      "learning_rate": 1.9360306178239478e-05,
      "loss": 0.0922,
      "step": 2340
    },
    {
      "epoch": 0.6424275560415528,
      "grad_norm": 7.072148323059082,
      "learning_rate": 1.9357572443958447e-05,
      "loss": 0.0708,
      "step": 2350
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 0.7004073858261108,
      "learning_rate": 1.935483870967742e-05,
      "loss": 0.1717,
      "step": 2360
    },
    {
      "epoch": 0.6478950246036085,
      "grad_norm": 11.075864791870117,
      "learning_rate": 1.9352104975396394e-05,
      "loss": 0.0632,
      "step": 2370
    },
    {
      "epoch": 0.6506287588846364,
      "grad_norm": 0.23579469323158264,
      "learning_rate": 1.9349371241115364e-05,
      "loss": 0.086,
      "step": 2380
    },
    {
      "epoch": 0.6533624931656643,
      "grad_norm": 4.282989025115967,
      "learning_rate": 1.9346637506834337e-05,
      "loss": 0.0975,
      "step": 2390
    },
    {
      "epoch": 0.6560962274466922,
      "grad_norm": 12.620209693908691,
      "learning_rate": 1.934390377255331e-05,
      "loss": 0.1031,
      "step": 2400
    },
    {
      "epoch": 0.65882996172772,
      "grad_norm": 4.581153392791748,
      "learning_rate": 1.934117003827228e-05,
      "loss": 0.0985,
      "step": 2410
    },
    {
      "epoch": 0.661563696008748,
      "grad_norm": 4.489535331726074,
      "learning_rate": 1.9338436303991254e-05,
      "loss": 0.0663,
      "step": 2420
    },
    {
      "epoch": 0.6642974302897758,
      "grad_norm": 0.8771091103553772,
      "learning_rate": 1.9335702569710228e-05,
      "loss": 0.0951,
      "step": 2430
    },
    {
      "epoch": 0.6670311645708037,
      "grad_norm": 9.634757041931152,
      "learning_rate": 1.9332968835429197e-05,
      "loss": 0.1063,
      "step": 2440
    },
    {
      "epoch": 0.6697648988518315,
      "grad_norm": 1.4350521564483643,
      "learning_rate": 1.933023510114817e-05,
      "loss": 0.1043,
      "step": 2450
    },
    {
      "epoch": 0.6724986331328595,
      "grad_norm": 0.11781476438045502,
      "learning_rate": 1.9327501366867144e-05,
      "loss": 0.0599,
      "step": 2460
    },
    {
      "epoch": 0.6752323674138874,
      "grad_norm": 9.020049095153809,
      "learning_rate": 1.9324767632586114e-05,
      "loss": 0.1542,
      "step": 2470
    },
    {
      "epoch": 0.6779661016949152,
      "grad_norm": 8.700103759765625,
      "learning_rate": 1.9322033898305087e-05,
      "loss": 0.1096,
      "step": 2480
    },
    {
      "epoch": 0.6806998359759432,
      "grad_norm": 9.036839485168457,
      "learning_rate": 1.9319300164024057e-05,
      "loss": 0.1301,
      "step": 2490
    },
    {
      "epoch": 0.683433570256971,
      "grad_norm": 6.374411106109619,
      "learning_rate": 1.931656642974303e-05,
      "loss": 0.0959,
      "step": 2500
    },
    {
      "epoch": 0.6861673045379989,
      "grad_norm": 0.2404375672340393,
      "learning_rate": 1.9313832695462004e-05,
      "loss": 0.0573,
      "step": 2510
    },
    {
      "epoch": 0.6889010388190268,
      "grad_norm": 1.8888219594955444,
      "learning_rate": 1.9311098961180974e-05,
      "loss": 0.0537,
      "step": 2520
    },
    {
      "epoch": 0.6916347731000547,
      "grad_norm": 0.07359694689512253,
      "learning_rate": 1.9308365226899947e-05,
      "loss": 0.0497,
      "step": 2530
    },
    {
      "epoch": 0.6943685073810826,
      "grad_norm": 10.605510711669922,
      "learning_rate": 1.930563149261892e-05,
      "loss": 0.0946,
      "step": 2540
    },
    {
      "epoch": 0.6971022416621104,
      "grad_norm": 1.2898609638214111,
      "learning_rate": 1.930289775833789e-05,
      "loss": 0.0782,
      "step": 2550
    },
    {
      "epoch": 0.6998359759431383,
      "grad_norm": 5.607003688812256,
      "learning_rate": 1.930016402405686e-05,
      "loss": 0.1259,
      "step": 2560
    },
    {
      "epoch": 0.7025697102241663,
      "grad_norm": 5.563931465148926,
      "learning_rate": 1.9297430289775837e-05,
      "loss": 0.1003,
      "step": 2570
    },
    {
      "epoch": 0.7053034445051941,
      "grad_norm": 5.502371311187744,
      "learning_rate": 1.9294696555494807e-05,
      "loss": 0.0918,
      "step": 2580
    },
    {
      "epoch": 0.708037178786222,
      "grad_norm": 11.300328254699707,
      "learning_rate": 1.9291962821213777e-05,
      "loss": 0.1707,
      "step": 2590
    },
    {
      "epoch": 0.7107709130672498,
      "grad_norm": 2.8313493728637695,
      "learning_rate": 1.9289229086932754e-05,
      "loss": 0.0686,
      "step": 2600
    },
    {
      "epoch": 0.7135046473482778,
      "grad_norm": 5.134523391723633,
      "learning_rate": 1.9286495352651724e-05,
      "loss": 0.0811,
      "step": 2610
    },
    {
      "epoch": 0.7162383816293056,
      "grad_norm": 3.4403438568115234,
      "learning_rate": 1.9283761618370694e-05,
      "loss": 0.0462,
      "step": 2620
    },
    {
      "epoch": 0.7189721159103335,
      "grad_norm": 4.088755130767822,
      "learning_rate": 1.9281027884089667e-05,
      "loss": 0.1273,
      "step": 2630
    },
    {
      "epoch": 0.7217058501913614,
      "grad_norm": 4.621654033660889,
      "learning_rate": 1.927829414980864e-05,
      "loss": 0.1378,
      "step": 2640
    },
    {
      "epoch": 0.7244395844723893,
      "grad_norm": 0.09558666497468948,
      "learning_rate": 1.927556041552761e-05,
      "loss": 0.1191,
      "step": 2650
    },
    {
      "epoch": 0.7271733187534172,
      "grad_norm": 8.087906837463379,
      "learning_rate": 1.9272826681246584e-05,
      "loss": 0.1017,
      "step": 2660
    },
    {
      "epoch": 0.729907053034445,
      "grad_norm": 2.148066520690918,
      "learning_rate": 1.9270092946965557e-05,
      "loss": 0.058,
      "step": 2670
    },
    {
      "epoch": 0.7326407873154729,
      "grad_norm": 8.643769264221191,
      "learning_rate": 1.9267359212684527e-05,
      "loss": 0.1612,
      "step": 2680
    },
    {
      "epoch": 0.7353745215965009,
      "grad_norm": 6.575643539428711,
      "learning_rate": 1.92646254784035e-05,
      "loss": 0.075,
      "step": 2690
    },
    {
      "epoch": 0.7381082558775287,
      "grad_norm": 10.320653915405273,
      "learning_rate": 1.9261891744122474e-05,
      "loss": 0.0658,
      "step": 2700
    },
    {
      "epoch": 0.7408419901585566,
      "grad_norm": 4.570800304412842,
      "learning_rate": 1.9259158009841444e-05,
      "loss": 0.1067,
      "step": 2710
    },
    {
      "epoch": 0.7435757244395844,
      "grad_norm": 6.17179536819458,
      "learning_rate": 1.9256424275560417e-05,
      "loss": 0.0418,
      "step": 2720
    },
    {
      "epoch": 0.7463094587206124,
      "grad_norm": 9.326069831848145,
      "learning_rate": 1.9253690541279387e-05,
      "loss": 0.1083,
      "step": 2730
    },
    {
      "epoch": 0.7490431930016402,
      "grad_norm": 0.5813769698143005,
      "learning_rate": 1.925095680699836e-05,
      "loss": 0.1001,
      "step": 2740
    },
    {
      "epoch": 0.7517769272826681,
      "grad_norm": 2.350102186203003,
      "learning_rate": 1.9248223072717334e-05,
      "loss": 0.0705,
      "step": 2750
    },
    {
      "epoch": 0.7545106615636961,
      "grad_norm": 7.673653602600098,
      "learning_rate": 1.9245489338436304e-05,
      "loss": 0.1352,
      "step": 2760
    },
    {
      "epoch": 0.7572443958447239,
      "grad_norm": 2.225247383117676,
      "learning_rate": 1.9242755604155277e-05,
      "loss": 0.0228,
      "step": 2770
    },
    {
      "epoch": 0.7599781301257518,
      "grad_norm": 0.4476022720336914,
      "learning_rate": 1.924002186987425e-05,
      "loss": 0.0656,
      "step": 2780
    },
    {
      "epoch": 0.7627118644067796,
      "grad_norm": 11.337409019470215,
      "learning_rate": 1.923728813559322e-05,
      "loss": 0.0692,
      "step": 2790
    },
    {
      "epoch": 0.7654455986878076,
      "grad_norm": 0.10273857414722443,
      "learning_rate": 1.9234554401312194e-05,
      "loss": 0.1025,
      "step": 2800
    },
    {
      "epoch": 0.7681793329688354,
      "grad_norm": 1.0267363786697388,
      "learning_rate": 1.9231820667031167e-05,
      "loss": 0.0124,
      "step": 2810
    },
    {
      "epoch": 0.7709130672498633,
      "grad_norm": 3.934617757797241,
      "learning_rate": 1.9229086932750137e-05,
      "loss": 0.1013,
      "step": 2820
    },
    {
      "epoch": 0.7736468015308912,
      "grad_norm": 0.2406492978334427,
      "learning_rate": 1.922635319846911e-05,
      "loss": 0.0932,
      "step": 2830
    },
    {
      "epoch": 0.7763805358119191,
      "grad_norm": 0.532787024974823,
      "learning_rate": 1.9223619464188084e-05,
      "loss": 0.0714,
      "step": 2840
    },
    {
      "epoch": 0.779114270092947,
      "grad_norm": 13.137112617492676,
      "learning_rate": 1.9220885729907054e-05,
      "loss": 0.0421,
      "step": 2850
    },
    {
      "epoch": 0.7818480043739748,
      "grad_norm": 0.08645643293857574,
      "learning_rate": 1.9218151995626027e-05,
      "loss": 0.0453,
      "step": 2860
    },
    {
      "epoch": 0.7845817386550027,
      "grad_norm": 0.476481169462204,
      "learning_rate": 1.9215418261344997e-05,
      "loss": 0.0669,
      "step": 2870
    },
    {
      "epoch": 0.7873154729360307,
      "grad_norm": 5.5600056648254395,
      "learning_rate": 1.921268452706397e-05,
      "loss": 0.1588,
      "step": 2880
    },
    {
      "epoch": 0.7900492072170585,
      "grad_norm": 0.0791124626994133,
      "learning_rate": 1.9209950792782944e-05,
      "loss": 0.0522,
      "step": 2890
    },
    {
      "epoch": 0.7927829414980864,
      "grad_norm": 0.11880757659673691,
      "learning_rate": 1.9207217058501914e-05,
      "loss": 0.1618,
      "step": 2900
    },
    {
      "epoch": 0.7955166757791142,
      "grad_norm": 4.457196235656738,
      "learning_rate": 1.9204483324220887e-05,
      "loss": 0.0896,
      "step": 2910
    },
    {
      "epoch": 0.7982504100601422,
      "grad_norm": 4.215353488922119,
      "learning_rate": 1.920174958993986e-05,
      "loss": 0.0896,
      "step": 2920
    },
    {
      "epoch": 0.80098414434117,
      "grad_norm": 7.142439842224121,
      "learning_rate": 1.919901585565883e-05,
      "loss": 0.0833,
      "step": 2930
    },
    {
      "epoch": 0.8037178786221979,
      "grad_norm": 8.40478515625,
      "learning_rate": 1.9196282121377804e-05,
      "loss": 0.0566,
      "step": 2940
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 7.030796051025391,
      "learning_rate": 1.9193548387096777e-05,
      "loss": 0.1182,
      "step": 2950
    },
    {
      "epoch": 0.8091853471842537,
      "grad_norm": 1.865112543106079,
      "learning_rate": 1.9190814652815747e-05,
      "loss": 0.0317,
      "step": 2960
    },
    {
      "epoch": 0.8119190814652816,
      "grad_norm": 0.08554406464099884,
      "learning_rate": 1.918808091853472e-05,
      "loss": 0.1078,
      "step": 2970
    },
    {
      "epoch": 0.8146528157463094,
      "grad_norm": 19.799104690551758,
      "learning_rate": 1.9185347184253694e-05,
      "loss": 0.0147,
      "step": 2980
    },
    {
      "epoch": 0.8173865500273373,
      "grad_norm": 5.991786956787109,
      "learning_rate": 1.9182613449972664e-05,
      "loss": 0.081,
      "step": 2990
    },
    {
      "epoch": 0.8201202843083653,
      "grad_norm": 0.028615187853574753,
      "learning_rate": 1.9179879715691637e-05,
      "loss": 0.0747,
      "step": 3000
    },
    {
      "epoch": 0.8228540185893931,
      "grad_norm": 0.11100301891565323,
      "learning_rate": 1.9177145981410607e-05,
      "loss": 0.0418,
      "step": 3010
    },
    {
      "epoch": 0.825587752870421,
      "grad_norm": 0.11062335968017578,
      "learning_rate": 1.917441224712958e-05,
      "loss": 0.03,
      "step": 3020
    },
    {
      "epoch": 0.8283214871514489,
      "grad_norm": 0.4337542951107025,
      "learning_rate": 1.9171678512848554e-05,
      "loss": 0.085,
      "step": 3030
    },
    {
      "epoch": 0.8310552214324768,
      "grad_norm": 6.5925374031066895,
      "learning_rate": 1.9168944778567524e-05,
      "loss": 0.1007,
      "step": 3040
    },
    {
      "epoch": 0.8337889557135046,
      "grad_norm": 7.435234069824219,
      "learning_rate": 1.9166211044286497e-05,
      "loss": 0.0846,
      "step": 3050
    },
    {
      "epoch": 0.8365226899945325,
      "grad_norm": 0.1162920743227005,
      "learning_rate": 1.916347731000547e-05,
      "loss": 0.0496,
      "step": 3060
    },
    {
      "epoch": 0.8392564242755605,
      "grad_norm": 12.603660583496094,
      "learning_rate": 1.916074357572444e-05,
      "loss": 0.039,
      "step": 3070
    },
    {
      "epoch": 0.8419901585565883,
      "grad_norm": 9.487699508666992,
      "learning_rate": 1.9158009841443414e-05,
      "loss": 0.1243,
      "step": 3080
    },
    {
      "epoch": 0.8447238928376162,
      "grad_norm": 0.36565178632736206,
      "learning_rate": 1.9155276107162387e-05,
      "loss": 0.1128,
      "step": 3090
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 4.916693687438965,
      "learning_rate": 1.9152542372881357e-05,
      "loss": 0.1027,
      "step": 3100
    },
    {
      "epoch": 0.850191361399672,
      "grad_norm": 0.4835937023162842,
      "learning_rate": 1.914980863860033e-05,
      "loss": 0.0359,
      "step": 3110
    },
    {
      "epoch": 0.8529250956806999,
      "grad_norm": 3.6843247413635254,
      "learning_rate": 1.9147074904319304e-05,
      "loss": 0.1417,
      "step": 3120
    },
    {
      "epoch": 0.8556588299617277,
      "grad_norm": 5.596935272216797,
      "learning_rate": 1.9144341170038274e-05,
      "loss": 0.1319,
      "step": 3130
    },
    {
      "epoch": 0.8583925642427556,
      "grad_norm": 10.640746116638184,
      "learning_rate": 1.9141607435757247e-05,
      "loss": 0.0866,
      "step": 3140
    },
    {
      "epoch": 0.8611262985237835,
      "grad_norm": 1.4608166217803955,
      "learning_rate": 1.9138873701476217e-05,
      "loss": 0.0458,
      "step": 3150
    },
    {
      "epoch": 0.8638600328048114,
      "grad_norm": 7.375757217407227,
      "learning_rate": 1.913613996719519e-05,
      "loss": 0.1769,
      "step": 3160
    },
    {
      "epoch": 0.8665937670858392,
      "grad_norm": 0.1958455890417099,
      "learning_rate": 1.9133406232914164e-05,
      "loss": 0.0509,
      "step": 3170
    },
    {
      "epoch": 0.8693275013668671,
      "grad_norm": 4.757929801940918,
      "learning_rate": 1.9130672498633134e-05,
      "loss": 0.0795,
      "step": 3180
    },
    {
      "epoch": 0.8720612356478951,
      "grad_norm": 8.402974128723145,
      "learning_rate": 1.9127938764352107e-05,
      "loss": 0.0516,
      "step": 3190
    },
    {
      "epoch": 0.8747949699289229,
      "grad_norm": 9.730925559997559,
      "learning_rate": 1.912520503007108e-05,
      "loss": 0.0402,
      "step": 3200
    },
    {
      "epoch": 0.8775287042099508,
      "grad_norm": 6.417638778686523,
      "learning_rate": 1.912247129579005e-05,
      "loss": 0.0538,
      "step": 3210
    },
    {
      "epoch": 0.8802624384909786,
      "grad_norm": 0.06688239425420761,
      "learning_rate": 1.911973756150902e-05,
      "loss": 0.1262,
      "step": 3220
    },
    {
      "epoch": 0.8829961727720066,
      "grad_norm": 0.10406296700239182,
      "learning_rate": 1.9117003827227997e-05,
      "loss": 0.0574,
      "step": 3230
    },
    {
      "epoch": 0.8857299070530344,
      "grad_norm": 4.099969863891602,
      "learning_rate": 1.9114270092946967e-05,
      "loss": 0.0716,
      "step": 3240
    },
    {
      "epoch": 0.8884636413340623,
      "grad_norm": 5.733481407165527,
      "learning_rate": 1.9111536358665937e-05,
      "loss": 0.0476,
      "step": 3250
    },
    {
      "epoch": 0.8911973756150902,
      "grad_norm": 4.059279441833496,
      "learning_rate": 1.9108802624384914e-05,
      "loss": 0.0927,
      "step": 3260
    },
    {
      "epoch": 0.8939311098961181,
      "grad_norm": 0.06317012757062912,
      "learning_rate": 1.9106068890103884e-05,
      "loss": 0.1102,
      "step": 3270
    },
    {
      "epoch": 0.896664844177146,
      "grad_norm": 0.09257610887289047,
      "learning_rate": 1.9103335155822854e-05,
      "loss": 0.0502,
      "step": 3280
    },
    {
      "epoch": 0.8993985784581738,
      "grad_norm": 4.749589920043945,
      "learning_rate": 1.9100601421541827e-05,
      "loss": 0.2174,
      "step": 3290
    },
    {
      "epoch": 0.9021323127392018,
      "grad_norm": 1.5154021978378296,
      "learning_rate": 1.90978676872608e-05,
      "loss": 0.0872,
      "step": 3300
    },
    {
      "epoch": 0.9048660470202297,
      "grad_norm": 4.752306938171387,
      "learning_rate": 1.909513395297977e-05,
      "loss": 0.1064,
      "step": 3310
    },
    {
      "epoch": 0.9075997813012575,
      "grad_norm": 0.03840760141611099,
      "learning_rate": 1.9092400218698744e-05,
      "loss": 0.0463,
      "step": 3320
    },
    {
      "epoch": 0.9103335155822854,
      "grad_norm": 1.7016429901123047,
      "learning_rate": 1.9089666484417717e-05,
      "loss": 0.0926,
      "step": 3330
    },
    {
      "epoch": 0.9130672498633133,
      "grad_norm": 2.0727672576904297,
      "learning_rate": 1.9086932750136687e-05,
      "loss": 0.1037,
      "step": 3340
    },
    {
      "epoch": 0.9158009841443412,
      "grad_norm": 5.732620716094971,
      "learning_rate": 1.908419901585566e-05,
      "loss": 0.093,
      "step": 3350
    },
    {
      "epoch": 0.918534718425369,
      "grad_norm": 0.7594749927520752,
      "learning_rate": 1.908146528157463e-05,
      "loss": 0.0418,
      "step": 3360
    },
    {
      "epoch": 0.9212684527063969,
      "grad_norm": 2.614771842956543,
      "learning_rate": 1.9078731547293604e-05,
      "loss": 0.0447,
      "step": 3370
    },
    {
      "epoch": 0.9240021869874249,
      "grad_norm": 0.014322863891720772,
      "learning_rate": 1.9075997813012577e-05,
      "loss": 0.0034,
      "step": 3380
    },
    {
      "epoch": 0.9267359212684527,
      "grad_norm": 3.731306314468384,
      "learning_rate": 1.9073264078731547e-05,
      "loss": 0.07,
      "step": 3390
    },
    {
      "epoch": 0.9294696555494806,
      "grad_norm": 0.023050129413604736,
      "learning_rate": 1.907053034445052e-05,
      "loss": 0.1157,
      "step": 3400
    },
    {
      "epoch": 0.9322033898305084,
      "grad_norm": 5.411881446838379,
      "learning_rate": 1.9067796610169494e-05,
      "loss": 0.0857,
      "step": 3410
    },
    {
      "epoch": 0.9349371241115364,
      "grad_norm": 5.227423667907715,
      "learning_rate": 1.9065062875888464e-05,
      "loss": 0.0893,
      "step": 3420
    },
    {
      "epoch": 0.9376708583925643,
      "grad_norm": 4.72672700881958,
      "learning_rate": 1.9062329141607437e-05,
      "loss": 0.1016,
      "step": 3430
    },
    {
      "epoch": 0.9404045926735921,
      "grad_norm": 2.315619468688965,
      "learning_rate": 1.905959540732641e-05,
      "loss": 0.078,
      "step": 3440
    },
    {
      "epoch": 0.94313832695462,
      "grad_norm": 0.26662591099739075,
      "learning_rate": 1.905686167304538e-05,
      "loss": 0.0311,
      "step": 3450
    },
    {
      "epoch": 0.9458720612356479,
      "grad_norm": 0.02961592935025692,
      "learning_rate": 1.9054127938764354e-05,
      "loss": 0.0311,
      "step": 3460
    },
    {
      "epoch": 0.9486057955166758,
      "grad_norm": 5.221703052520752,
      "learning_rate": 1.9051394204483327e-05,
      "loss": 0.0772,
      "step": 3470
    },
    {
      "epoch": 0.9513395297977036,
      "grad_norm": 4.644862651824951,
      "learning_rate": 1.9048660470202297e-05,
      "loss": 0.0887,
      "step": 3480
    },
    {
      "epoch": 0.9540732640787315,
      "grad_norm": 0.06692218780517578,
      "learning_rate": 1.904592673592127e-05,
      "loss": 0.0581,
      "step": 3490
    },
    {
      "epoch": 0.9568069983597595,
      "grad_norm": 8.805639266967773,
      "learning_rate": 1.904319300164024e-05,
      "loss": 0.0926,
      "step": 3500
    },
    {
      "epoch": 0.9595407326407873,
      "grad_norm": 6.092121124267578,
      "learning_rate": 1.9040459267359214e-05,
      "loss": 0.0531,
      "step": 3510
    },
    {
      "epoch": 0.9622744669218152,
      "grad_norm": 5.871363639831543,
      "learning_rate": 1.9037725533078187e-05,
      "loss": 0.0698,
      "step": 3520
    },
    {
      "epoch": 0.965008201202843,
      "grad_norm": 18.90679168701172,
      "learning_rate": 1.9034991798797157e-05,
      "loss": 0.1088,
      "step": 3530
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 3.249626398086548,
      "learning_rate": 1.903225806451613e-05,
      "loss": 0.0457,
      "step": 3540
    },
    {
      "epoch": 0.9704756697648989,
      "grad_norm": 9.198846817016602,
      "learning_rate": 1.9029524330235104e-05,
      "loss": 0.0668,
      "step": 3550
    },
    {
      "epoch": 0.9732094040459267,
      "grad_norm": 3.4452426433563232,
      "learning_rate": 1.9026790595954074e-05,
      "loss": 0.0743,
      "step": 3560
    },
    {
      "epoch": 0.9759431383269547,
      "grad_norm": 0.08140353858470917,
      "learning_rate": 1.9024056861673047e-05,
      "loss": 0.0859,
      "step": 3570
    },
    {
      "epoch": 0.9786768726079825,
      "grad_norm": 11.061924934387207,
      "learning_rate": 1.902132312739202e-05,
      "loss": 0.0683,
      "step": 3580
    },
    {
      "epoch": 0.9814106068890104,
      "grad_norm": 0.37499168515205383,
      "learning_rate": 1.901858939311099e-05,
      "loss": 0.0723,
      "step": 3590
    },
    {
      "epoch": 0.9841443411700382,
      "grad_norm": 5.429396629333496,
      "learning_rate": 1.9015855658829964e-05,
      "loss": 0.0849,
      "step": 3600
    },
    {
      "epoch": 0.9868780754510662,
      "grad_norm": 13.914372444152832,
      "learning_rate": 1.9013121924548937e-05,
      "loss": 0.1584,
      "step": 3610
    },
    {
      "epoch": 0.9896118097320941,
      "grad_norm": 4.520893096923828,
      "learning_rate": 1.9010388190267907e-05,
      "loss": 0.1099,
      "step": 3620
    },
    {
      "epoch": 0.9923455440131219,
      "grad_norm": 0.7347161769866943,
      "learning_rate": 1.900765445598688e-05,
      "loss": 0.0585,
      "step": 3630
    },
    {
      "epoch": 0.9950792782941498,
      "grad_norm": 7.665010452270508,
      "learning_rate": 1.900492072170585e-05,
      "loss": 0.1126,
      "step": 3640
    },
    {
      "epoch": 0.9978130125751777,
      "grad_norm": 9.87407112121582,
      "learning_rate": 1.9002186987424824e-05,
      "loss": 0.1192,
      "step": 3650
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9802575564069816,
      "eval_f1": 0.9194003910493156,
      "eval_loss": 0.06312639266252518,
      "eval_precision": 0.9362831858407079,
      "eval_recall": 0.903115663679044,
      "eval_runtime": 805.4568,
      "eval_samples_per_second": 23.358,
      "eval_steps_per_second": 0.973,
      "step": 3658
    },
    {
      "epoch": 1.0005467468562055,
      "grad_norm": 0.11341550946235657,
      "learning_rate": 1.8999453253143797e-05,
      "loss": 0.0161,
      "step": 3660
    },
    {
      "epoch": 1.0032804811372336,
      "grad_norm": 1.279972791671753,
      "learning_rate": 1.8996719518862767e-05,
      "loss": 0.0372,
      "step": 3670
    },
    {
      "epoch": 1.0060142154182614,
      "grad_norm": 0.4708857536315918,
      "learning_rate": 1.899398578458174e-05,
      "loss": 0.0204,
      "step": 3680
    },
    {
      "epoch": 1.0087479496992893,
      "grad_norm": 3.2541582584381104,
      "learning_rate": 1.8991252050300714e-05,
      "loss": 0.0641,
      "step": 3690
    },
    {
      "epoch": 1.0114816839803171,
      "grad_norm": 7.415857315063477,
      "learning_rate": 1.8988518316019684e-05,
      "loss": 0.0387,
      "step": 3700
    },
    {
      "epoch": 1.014215418261345,
      "grad_norm": 0.05594949051737785,
      "learning_rate": 1.8985784581738657e-05,
      "loss": 0.0613,
      "step": 3710
    },
    {
      "epoch": 1.0169491525423728,
      "grad_norm": 6.311244487762451,
      "learning_rate": 1.898305084745763e-05,
      "loss": 0.0962,
      "step": 3720
    },
    {
      "epoch": 1.0196828868234007,
      "grad_norm": 0.2088802009820938,
      "learning_rate": 1.89803171131766e-05,
      "loss": 0.0606,
      "step": 3730
    },
    {
      "epoch": 1.0224166211044285,
      "grad_norm": 6.011527061462402,
      "learning_rate": 1.8977583378895574e-05,
      "loss": 0.0494,
      "step": 3740
    },
    {
      "epoch": 1.0251503553854566,
      "grad_norm": 1.2467700242996216,
      "learning_rate": 1.8974849644614547e-05,
      "loss": 0.0417,
      "step": 3750
    },
    {
      "epoch": 1.0278840896664845,
      "grad_norm": 0.06221606954932213,
      "learning_rate": 1.8972115910333517e-05,
      "loss": 0.0239,
      "step": 3760
    },
    {
      "epoch": 1.0306178239475123,
      "grad_norm": 0.04472532868385315,
      "learning_rate": 1.896938217605249e-05,
      "loss": 0.0733,
      "step": 3770
    },
    {
      "epoch": 1.0333515582285402,
      "grad_norm": 0.031240656971931458,
      "learning_rate": 1.8966648441771464e-05,
      "loss": 0.0431,
      "step": 3780
    },
    {
      "epoch": 1.036085292509568,
      "grad_norm": 0.9903076887130737,
      "learning_rate": 1.8963914707490434e-05,
      "loss": 0.0837,
      "step": 3790
    },
    {
      "epoch": 1.038819026790596,
      "grad_norm": 0.39131954312324524,
      "learning_rate": 1.8961180973209407e-05,
      "loss": 0.1189,
      "step": 3800
    },
    {
      "epoch": 1.0415527610716238,
      "grad_norm": 1.0372673273086548,
      "learning_rate": 1.8958447238928377e-05,
      "loss": 0.0437,
      "step": 3810
    },
    {
      "epoch": 1.0442864953526518,
      "grad_norm": 14.891864776611328,
      "learning_rate": 1.895571350464735e-05,
      "loss": 0.1228,
      "step": 3820
    },
    {
      "epoch": 1.0470202296336797,
      "grad_norm": 12.426850318908691,
      "learning_rate": 1.8952979770366324e-05,
      "loss": 0.1586,
      "step": 3830
    },
    {
      "epoch": 1.0497539639147075,
      "grad_norm": 7.692131996154785,
      "learning_rate": 1.8950246036085294e-05,
      "loss": 0.08,
      "step": 3840
    },
    {
      "epoch": 1.0524876981957354,
      "grad_norm": 8.748990058898926,
      "learning_rate": 1.8947512301804267e-05,
      "loss": 0.0574,
      "step": 3850
    },
    {
      "epoch": 1.0552214324767633,
      "grad_norm": 0.0653085857629776,
      "learning_rate": 1.894477856752324e-05,
      "loss": 0.0656,
      "step": 3860
    },
    {
      "epoch": 1.057955166757791,
      "grad_norm": 0.07630354911088943,
      "learning_rate": 1.894204483324221e-05,
      "loss": 0.0094,
      "step": 3870
    },
    {
      "epoch": 1.060688901038819,
      "grad_norm": 4.284538269042969,
      "learning_rate": 1.893931109896118e-05,
      "loss": 0.0367,
      "step": 3880
    },
    {
      "epoch": 1.0634226353198468,
      "grad_norm": 0.17243452370166779,
      "learning_rate": 1.8936577364680157e-05,
      "loss": 0.0741,
      "step": 3890
    },
    {
      "epoch": 1.066156369600875,
      "grad_norm": 0.04384435713291168,
      "learning_rate": 1.8933843630399127e-05,
      "loss": 0.049,
      "step": 3900
    },
    {
      "epoch": 1.0688901038819028,
      "grad_norm": 12.592963218688965,
      "learning_rate": 1.8931109896118097e-05,
      "loss": 0.056,
      "step": 3910
    },
    {
      "epoch": 1.0716238381629306,
      "grad_norm": 0.09645692259073257,
      "learning_rate": 1.8928376161837074e-05,
      "loss": 0.0679,
      "step": 3920
    },
    {
      "epoch": 1.0743575724439585,
      "grad_norm": 1.979670524597168,
      "learning_rate": 1.8925642427556044e-05,
      "loss": 0.0662,
      "step": 3930
    },
    {
      "epoch": 1.0770913067249863,
      "grad_norm": 1.6200000047683716,
      "learning_rate": 1.8922908693275014e-05,
      "loss": 0.1207,
      "step": 3940
    },
    {
      "epoch": 1.0798250410060142,
      "grad_norm": 5.45700740814209,
      "learning_rate": 1.8920174958993987e-05,
      "loss": 0.0248,
      "step": 3950
    },
    {
      "epoch": 1.082558775287042,
      "grad_norm": 5.7331109046936035,
      "learning_rate": 1.891744122471296e-05,
      "loss": 0.0427,
      "step": 3960
    },
    {
      "epoch": 1.0852925095680699,
      "grad_norm": 0.04775868356227875,
      "learning_rate": 1.891470749043193e-05,
      "loss": 0.0146,
      "step": 3970
    },
    {
      "epoch": 1.088026243849098,
      "grad_norm": 1.5337306261062622,
      "learning_rate": 1.8911973756150904e-05,
      "loss": 0.0397,
      "step": 3980
    },
    {
      "epoch": 1.0907599781301258,
      "grad_norm": 10.140280723571777,
      "learning_rate": 1.8909240021869877e-05,
      "loss": 0.0279,
      "step": 3990
    },
    {
      "epoch": 1.0934937124111537,
      "grad_norm": 0.3304232954978943,
      "learning_rate": 1.8906506287588847e-05,
      "loss": 0.0294,
      "step": 4000
    },
    {
      "epoch": 1.0962274466921815,
      "grad_norm": 0.1336306780576706,
      "learning_rate": 1.890377255330782e-05,
      "loss": 0.0425,
      "step": 4010
    },
    {
      "epoch": 1.0989611809732094,
      "grad_norm": 3.895449161529541,
      "learning_rate": 1.890103881902679e-05,
      "loss": 0.0672,
      "step": 4020
    },
    {
      "epoch": 1.1016949152542372,
      "grad_norm": 1.5891810655593872,
      "learning_rate": 1.8898305084745764e-05,
      "loss": 0.0633,
      "step": 4030
    },
    {
      "epoch": 1.104428649535265,
      "grad_norm": 15.673554420471191,
      "learning_rate": 1.8895571350464737e-05,
      "loss": 0.0453,
      "step": 4040
    },
    {
      "epoch": 1.1071623838162932,
      "grad_norm": 0.3383961021900177,
      "learning_rate": 1.8892837616183707e-05,
      "loss": 0.0698,
      "step": 4050
    },
    {
      "epoch": 1.109896118097321,
      "grad_norm": 15.266427040100098,
      "learning_rate": 1.889010388190268e-05,
      "loss": 0.1216,
      "step": 4060
    },
    {
      "epoch": 1.1126298523783489,
      "grad_norm": 4.443842887878418,
      "learning_rate": 1.8887370147621654e-05,
      "loss": 0.0599,
      "step": 4070
    },
    {
      "epoch": 1.1153635866593767,
      "grad_norm": 0.08998909592628479,
      "learning_rate": 1.8884636413340624e-05,
      "loss": 0.0695,
      "step": 4080
    },
    {
      "epoch": 1.1180973209404046,
      "grad_norm": 0.09440306574106216,
      "learning_rate": 1.8881902679059597e-05,
      "loss": 0.023,
      "step": 4090
    },
    {
      "epoch": 1.1208310552214324,
      "grad_norm": 0.08839010447263718,
      "learning_rate": 1.887916894477857e-05,
      "loss": 0.0238,
      "step": 4100
    },
    {
      "epoch": 1.1235647895024603,
      "grad_norm": 6.407587051391602,
      "learning_rate": 1.887643521049754e-05,
      "loss": 0.0545,
      "step": 4110
    },
    {
      "epoch": 1.1262985237834882,
      "grad_norm": 0.02706790715456009,
      "learning_rate": 1.8873701476216514e-05,
      "loss": 0.0999,
      "step": 4120
    },
    {
      "epoch": 1.129032258064516,
      "grad_norm": 3.72280216217041,
      "learning_rate": 1.8870967741935487e-05,
      "loss": 0.093,
      "step": 4130
    },
    {
      "epoch": 1.131765992345544,
      "grad_norm": 0.4499056339263916,
      "learning_rate": 1.8868234007654457e-05,
      "loss": 0.0213,
      "step": 4140
    },
    {
      "epoch": 1.134499726626572,
      "grad_norm": 0.5213032364845276,
      "learning_rate": 1.886550027337343e-05,
      "loss": 0.037,
      "step": 4150
    },
    {
      "epoch": 1.1372334609075998,
      "grad_norm": 0.18591536581516266,
      "learning_rate": 1.88627665390924e-05,
      "loss": 0.0274,
      "step": 4160
    },
    {
      "epoch": 1.1399671951886277,
      "grad_norm": 7.075926303863525,
      "learning_rate": 1.8860032804811374e-05,
      "loss": 0.1014,
      "step": 4170
    },
    {
      "epoch": 1.1427009294696555,
      "grad_norm": 0.28907233476638794,
      "learning_rate": 1.8857299070530347e-05,
      "loss": 0.0275,
      "step": 4180
    },
    {
      "epoch": 1.1454346637506834,
      "grad_norm": 9.555708885192871,
      "learning_rate": 1.8854565336249317e-05,
      "loss": 0.1013,
      "step": 4190
    },
    {
      "epoch": 1.1481683980317112,
      "grad_norm": 4.293788909912109,
      "learning_rate": 1.885183160196829e-05,
      "loss": 0.1083,
      "step": 4200
    },
    {
      "epoch": 1.1509021323127393,
      "grad_norm": 0.12902861833572388,
      "learning_rate": 1.8849097867687264e-05,
      "loss": 0.0892,
      "step": 4210
    },
    {
      "epoch": 1.1536358665937672,
      "grad_norm": 0.3657539188861847,
      "learning_rate": 1.8846364133406234e-05,
      "loss": 0.0336,
      "step": 4220
    },
    {
      "epoch": 1.156369600874795,
      "grad_norm": 6.1371893882751465,
      "learning_rate": 1.8843630399125207e-05,
      "loss": 0.0661,
      "step": 4230
    },
    {
      "epoch": 1.1591033351558229,
      "grad_norm": 4.2234649658203125,
      "learning_rate": 1.884089666484418e-05,
      "loss": 0.0768,
      "step": 4240
    },
    {
      "epoch": 1.1618370694368507,
      "grad_norm": 14.98460865020752,
      "learning_rate": 1.883816293056315e-05,
      "loss": 0.0968,
      "step": 4250
    },
    {
      "epoch": 1.1645708037178786,
      "grad_norm": 0.44800299406051636,
      "learning_rate": 1.8835429196282124e-05,
      "loss": 0.0066,
      "step": 4260
    },
    {
      "epoch": 1.1673045379989064,
      "grad_norm": 0.18373538553714752,
      "learning_rate": 1.8832695462001097e-05,
      "loss": 0.0852,
      "step": 4270
    },
    {
      "epoch": 1.1700382722799345,
      "grad_norm": 2.0340120792388916,
      "learning_rate": 1.8829961727720067e-05,
      "loss": 0.1132,
      "step": 4280
    },
    {
      "epoch": 1.1727720065609624,
      "grad_norm": 12.037202835083008,
      "learning_rate": 1.882722799343904e-05,
      "loss": 0.0723,
      "step": 4290
    },
    {
      "epoch": 1.1755057408419902,
      "grad_norm": 0.23283840715885162,
      "learning_rate": 1.882449425915801e-05,
      "loss": 0.0514,
      "step": 4300
    },
    {
      "epoch": 1.178239475123018,
      "grad_norm": 0.04001551866531372,
      "learning_rate": 1.8821760524876983e-05,
      "loss": 0.0765,
      "step": 4310
    },
    {
      "epoch": 1.180973209404046,
      "grad_norm": 4.062176704406738,
      "learning_rate": 1.8819026790595957e-05,
      "loss": 0.0817,
      "step": 4320
    },
    {
      "epoch": 1.1837069436850738,
      "grad_norm": 4.96673583984375,
      "learning_rate": 1.8816293056314927e-05,
      "loss": 0.0433,
      "step": 4330
    },
    {
      "epoch": 1.1864406779661016,
      "grad_norm": 6.388113498687744,
      "learning_rate": 1.88135593220339e-05,
      "loss": 0.052,
      "step": 4340
    },
    {
      "epoch": 1.1891744122471295,
      "grad_norm": 0.022126594558358192,
      "learning_rate": 1.8810825587752874e-05,
      "loss": 0.0578,
      "step": 4350
    },
    {
      "epoch": 1.1919081465281574,
      "grad_norm": 0.1481075882911682,
      "learning_rate": 1.8808091853471843e-05,
      "loss": 0.0431,
      "step": 4360
    },
    {
      "epoch": 1.1946418808091854,
      "grad_norm": 0.12942466139793396,
      "learning_rate": 1.8805358119190817e-05,
      "loss": 0.0475,
      "step": 4370
    },
    {
      "epoch": 1.1973756150902133,
      "grad_norm": 15.175833702087402,
      "learning_rate": 1.880262438490979e-05,
      "loss": 0.0975,
      "step": 4380
    },
    {
      "epoch": 1.2001093493712411,
      "grad_norm": 5.308738708496094,
      "learning_rate": 1.879989065062876e-05,
      "loss": 0.1085,
      "step": 4390
    },
    {
      "epoch": 1.202843083652269,
      "grad_norm": 14.3132963180542,
      "learning_rate": 1.8797156916347733e-05,
      "loss": 0.0595,
      "step": 4400
    },
    {
      "epoch": 1.2055768179332969,
      "grad_norm": 0.09865093231201172,
      "learning_rate": 1.8794423182066707e-05,
      "loss": 0.0501,
      "step": 4410
    },
    {
      "epoch": 1.2083105522143247,
      "grad_norm": 0.0731106847524643,
      "learning_rate": 1.8791689447785677e-05,
      "loss": 0.1345,
      "step": 4420
    },
    {
      "epoch": 1.2110442864953526,
      "grad_norm": 0.5361419916152954,
      "learning_rate": 1.878895571350465e-05,
      "loss": 0.0599,
      "step": 4430
    },
    {
      "epoch": 1.2137780207763806,
      "grad_norm": 2.0911693572998047,
      "learning_rate": 1.878622197922362e-05,
      "loss": 0.0282,
      "step": 4440
    },
    {
      "epoch": 1.2165117550574085,
      "grad_norm": 4.380501747131348,
      "learning_rate": 1.8783488244942593e-05,
      "loss": 0.0712,
      "step": 4450
    },
    {
      "epoch": 1.2192454893384364,
      "grad_norm": 0.012289649806916714,
      "learning_rate": 1.8780754510661567e-05,
      "loss": 0.064,
      "step": 4460
    },
    {
      "epoch": 1.2219792236194642,
      "grad_norm": 4.366628646850586,
      "learning_rate": 1.8778020776380537e-05,
      "loss": 0.0335,
      "step": 4470
    },
    {
      "epoch": 1.224712957900492,
      "grad_norm": 5.776366710662842,
      "learning_rate": 1.877528704209951e-05,
      "loss": 0.0296,
      "step": 4480
    },
    {
      "epoch": 1.22744669218152,
      "grad_norm": 23.000835418701172,
      "learning_rate": 1.8772553307818483e-05,
      "loss": 0.1089,
      "step": 4490
    },
    {
      "epoch": 1.2301804264625478,
      "grad_norm": 0.7618626952171326,
      "learning_rate": 1.8769819573537453e-05,
      "loss": 0.0138,
      "step": 4500
    },
    {
      "epoch": 1.2329141607435758,
      "grad_norm": 0.623241126537323,
      "learning_rate": 1.8767085839256423e-05,
      "loss": 0.0365,
      "step": 4510
    },
    {
      "epoch": 1.2356478950246037,
      "grad_norm": 0.4018130600452423,
      "learning_rate": 1.87643521049754e-05,
      "loss": 0.0516,
      "step": 4520
    },
    {
      "epoch": 1.2383816293056316,
      "grad_norm": 25.138893127441406,
      "learning_rate": 1.876161837069437e-05,
      "loss": 0.1338,
      "step": 4530
    },
    {
      "epoch": 1.2411153635866594,
      "grad_norm": 0.05340108647942543,
      "learning_rate": 1.875888463641334e-05,
      "loss": 0.1208,
      "step": 4540
    },
    {
      "epoch": 1.2438490978676873,
      "grad_norm": 5.716830253601074,
      "learning_rate": 1.8756150902132317e-05,
      "loss": 0.0987,
      "step": 4550
    },
    {
      "epoch": 1.2465828321487151,
      "grad_norm": 0.1883327215909958,
      "learning_rate": 1.8753417167851287e-05,
      "loss": 0.1309,
      "step": 4560
    },
    {
      "epoch": 1.249316566429743,
      "grad_norm": 0.4516041874885559,
      "learning_rate": 1.8750683433570257e-05,
      "loss": 0.0501,
      "step": 4570
    },
    {
      "epoch": 1.2520503007107708,
      "grad_norm": 1.173213243484497,
      "learning_rate": 1.874794969928923e-05,
      "loss": 0.0544,
      "step": 4580
    },
    {
      "epoch": 1.2547840349917987,
      "grad_norm": 6.861616611480713,
      "learning_rate": 1.8745215965008203e-05,
      "loss": 0.0378,
      "step": 4590
    },
    {
      "epoch": 1.2575177692728268,
      "grad_norm": 0.045830484479665756,
      "learning_rate": 1.8742482230727173e-05,
      "loss": 0.048,
      "step": 4600
    },
    {
      "epoch": 1.2602515035538546,
      "grad_norm": 10.313228607177734,
      "learning_rate": 1.8739748496446147e-05,
      "loss": 0.0657,
      "step": 4610
    },
    {
      "epoch": 1.2629852378348825,
      "grad_norm": 4.049241542816162,
      "learning_rate": 1.873701476216512e-05,
      "loss": 0.1044,
      "step": 4620
    },
    {
      "epoch": 1.2657189721159103,
      "grad_norm": 1.7210638523101807,
      "learning_rate": 1.873428102788409e-05,
      "loss": 0.072,
      "step": 4630
    },
    {
      "epoch": 1.2684527063969382,
      "grad_norm": 5.553732395172119,
      "learning_rate": 1.8731547293603063e-05,
      "loss": 0.0229,
      "step": 4640
    },
    {
      "epoch": 1.271186440677966,
      "grad_norm": 0.2633780837059021,
      "learning_rate": 1.8728813559322033e-05,
      "loss": 0.0636,
      "step": 4650
    },
    {
      "epoch": 1.273920174958994,
      "grad_norm": 0.17223100364208221,
      "learning_rate": 1.8726079825041007e-05,
      "loss": 0.0689,
      "step": 4660
    },
    {
      "epoch": 1.276653909240022,
      "grad_norm": 0.5782150626182556,
      "learning_rate": 1.872334609075998e-05,
      "loss": 0.0781,
      "step": 4670
    },
    {
      "epoch": 1.2793876435210498,
      "grad_norm": 0.05641263723373413,
      "learning_rate": 1.872061235647895e-05,
      "loss": 0.1342,
      "step": 4680
    },
    {
      "epoch": 1.2821213778020777,
      "grad_norm": 0.6623943448066711,
      "learning_rate": 1.8717878622197923e-05,
      "loss": 0.0541,
      "step": 4690
    },
    {
      "epoch": 1.2848551120831055,
      "grad_norm": 1.633396863937378,
      "learning_rate": 1.8715144887916897e-05,
      "loss": 0.0349,
      "step": 4700
    },
    {
      "epoch": 1.2875888463641334,
      "grad_norm": 4.332719802856445,
      "learning_rate": 1.8712411153635867e-05,
      "loss": 0.0664,
      "step": 4710
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 0.2381424754858017,
      "learning_rate": 1.870967741935484e-05,
      "loss": 0.0363,
      "step": 4720
    },
    {
      "epoch": 1.293056314926189,
      "grad_norm": 0.025123052299022675,
      "learning_rate": 1.8706943685073813e-05,
      "loss": 0.0663,
      "step": 4730
    },
    {
      "epoch": 1.2957900492072172,
      "grad_norm": 4.303057670593262,
      "learning_rate": 1.8704209950792783e-05,
      "loss": 0.0973,
      "step": 4740
    },
    {
      "epoch": 1.2985237834882448,
      "grad_norm": 2.807098865509033,
      "learning_rate": 1.8701476216511757e-05,
      "loss": 0.0476,
      "step": 4750
    },
    {
      "epoch": 1.301257517769273,
      "grad_norm": 0.10982291400432587,
      "learning_rate": 1.869874248223073e-05,
      "loss": 0.0429,
      "step": 4760
    },
    {
      "epoch": 1.3039912520503008,
      "grad_norm": 0.466831773519516,
      "learning_rate": 1.86960087479497e-05,
      "loss": 0.039,
      "step": 4770
    },
    {
      "epoch": 1.3067249863313286,
      "grad_norm": 3.9407410621643066,
      "learning_rate": 1.8693275013668673e-05,
      "loss": 0.0801,
      "step": 4780
    },
    {
      "epoch": 1.3094587206123565,
      "grad_norm": 3.179414749145508,
      "learning_rate": 1.8690541279387643e-05,
      "loss": 0.1196,
      "step": 4790
    },
    {
      "epoch": 1.3121924548933843,
      "grad_norm": 5.663359642028809,
      "learning_rate": 1.8687807545106617e-05,
      "loss": 0.1522,
      "step": 4800
    },
    {
      "epoch": 1.3149261891744122,
      "grad_norm": 0.06508881598711014,
      "learning_rate": 1.868507381082559e-05,
      "loss": 0.0256,
      "step": 4810
    },
    {
      "epoch": 1.31765992345544,
      "grad_norm": 10.563244819641113,
      "learning_rate": 1.868234007654456e-05,
      "loss": 0.0367,
      "step": 4820
    },
    {
      "epoch": 1.320393657736468,
      "grad_norm": 0.14083662629127502,
      "learning_rate": 1.8679606342263533e-05,
      "loss": 0.071,
      "step": 4830
    },
    {
      "epoch": 1.323127392017496,
      "grad_norm": 2.6033051013946533,
      "learning_rate": 1.8676872607982507e-05,
      "loss": 0.0399,
      "step": 4840
    },
    {
      "epoch": 1.3258611262985238,
      "grad_norm": 0.17493456602096558,
      "learning_rate": 1.8674138873701477e-05,
      "loss": 0.0516,
      "step": 4850
    },
    {
      "epoch": 1.3285948605795517,
      "grad_norm": 3.4310197830200195,
      "learning_rate": 1.867140513942045e-05,
      "loss": 0.0876,
      "step": 4860
    },
    {
      "epoch": 1.3313285948605795,
      "grad_norm": 1.839287281036377,
      "learning_rate": 1.8668671405139423e-05,
      "loss": 0.0941,
      "step": 4870
    },
    {
      "epoch": 1.3340623291416074,
      "grad_norm": 4.553006172180176,
      "learning_rate": 1.8665937670858393e-05,
      "loss": 0.0527,
      "step": 4880
    },
    {
      "epoch": 1.3367960634226352,
      "grad_norm": 10.538494110107422,
      "learning_rate": 1.8663203936577367e-05,
      "loss": 0.0211,
      "step": 4890
    },
    {
      "epoch": 1.3395297977036633,
      "grad_norm": 0.04978039488196373,
      "learning_rate": 1.866047020229634e-05,
      "loss": 0.0334,
      "step": 4900
    },
    {
      "epoch": 1.342263531984691,
      "grad_norm": 0.012249909341335297,
      "learning_rate": 1.865773646801531e-05,
      "loss": 0.0554,
      "step": 4910
    },
    {
      "epoch": 1.344997266265719,
      "grad_norm": 0.02779114432632923,
      "learning_rate": 1.8655002733734283e-05,
      "loss": 0.1197,
      "step": 4920
    },
    {
      "epoch": 1.3477310005467469,
      "grad_norm": 0.16948455572128296,
      "learning_rate": 1.8652268999453257e-05,
      "loss": 0.1123,
      "step": 4930
    },
    {
      "epoch": 1.3504647348277747,
      "grad_norm": 13.279362678527832,
      "learning_rate": 1.8649535265172227e-05,
      "loss": 0.0752,
      "step": 4940
    },
    {
      "epoch": 1.3531984691088026,
      "grad_norm": 0.07068293541669846,
      "learning_rate": 1.86468015308912e-05,
      "loss": 0.0223,
      "step": 4950
    },
    {
      "epoch": 1.3559322033898304,
      "grad_norm": 0.018654009327292442,
      "learning_rate": 1.864406779661017e-05,
      "loss": 0.0259,
      "step": 4960
    },
    {
      "epoch": 1.3586659376708585,
      "grad_norm": 0.01767890155315399,
      "learning_rate": 1.8641334062329143e-05,
      "loss": 0.0346,
      "step": 4970
    },
    {
      "epoch": 1.3613996719518862,
      "grad_norm": 1.4647555351257324,
      "learning_rate": 1.8638600328048117e-05,
      "loss": 0.0686,
      "step": 4980
    },
    {
      "epoch": 1.3641334062329142,
      "grad_norm": 2.052973985671997,
      "learning_rate": 1.8635866593767087e-05,
      "loss": 0.0633,
      "step": 4990
    },
    {
      "epoch": 1.366867140513942,
      "grad_norm": 3.2831153869628906,
      "learning_rate": 1.863313285948606e-05,
      "loss": 0.0227,
      "step": 5000
    },
    {
      "epoch": 1.36960087479497,
      "grad_norm": 0.1024513989686966,
      "learning_rate": 1.8630399125205033e-05,
      "loss": 0.0448,
      "step": 5010
    },
    {
      "epoch": 1.3723346090759978,
      "grad_norm": 6.731858253479004,
      "learning_rate": 1.8627665390924003e-05,
      "loss": 0.0554,
      "step": 5020
    },
    {
      "epoch": 1.3750683433570257,
      "grad_norm": 4.3162031173706055,
      "learning_rate": 1.8624931656642977e-05,
      "loss": 0.051,
      "step": 5030
    },
    {
      "epoch": 1.3778020776380535,
      "grad_norm": 0.04930487275123596,
      "learning_rate": 1.862219792236195e-05,
      "loss": 0.0669,
      "step": 5040
    },
    {
      "epoch": 1.3805358119190814,
      "grad_norm": 3.2850592136383057,
      "learning_rate": 1.861946418808092e-05,
      "loss": 0.0368,
      "step": 5050
    },
    {
      "epoch": 1.3832695462001094,
      "grad_norm": 0.10914699733257294,
      "learning_rate": 1.8616730453799893e-05,
      "loss": 0.0747,
      "step": 5060
    },
    {
      "epoch": 1.3860032804811373,
      "grad_norm": 0.04147161543369293,
      "learning_rate": 1.8613996719518867e-05,
      "loss": 0.0185,
      "step": 5070
    },
    {
      "epoch": 1.3887370147621652,
      "grad_norm": 2.705185890197754,
      "learning_rate": 1.8611262985237837e-05,
      "loss": 0.0266,
      "step": 5080
    },
    {
      "epoch": 1.391470749043193,
      "grad_norm": 17.54345703125,
      "learning_rate": 1.860852925095681e-05,
      "loss": 0.0927,
      "step": 5090
    },
    {
      "epoch": 1.3942044833242209,
      "grad_norm": 1.9136589765548706,
      "learning_rate": 1.860579551667578e-05,
      "loss": 0.0647,
      "step": 5100
    },
    {
      "epoch": 1.3969382176052487,
      "grad_norm": 0.5612471699714661,
      "learning_rate": 1.8603061782394753e-05,
      "loss": 0.0136,
      "step": 5110
    },
    {
      "epoch": 1.3996719518862766,
      "grad_norm": 0.0675169974565506,
      "learning_rate": 1.8600328048113727e-05,
      "loss": 0.0969,
      "step": 5120
    },
    {
      "epoch": 1.4024056861673047,
      "grad_norm": 0.9476542472839355,
      "learning_rate": 1.8597594313832697e-05,
      "loss": 0.0378,
      "step": 5130
    },
    {
      "epoch": 1.4051394204483323,
      "grad_norm": 0.30367511510849,
      "learning_rate": 1.859486057955167e-05,
      "loss": 0.0087,
      "step": 5140
    },
    {
      "epoch": 1.4078731547293604,
      "grad_norm": 4.634422779083252,
      "learning_rate": 1.8592126845270643e-05,
      "loss": 0.112,
      "step": 5150
    },
    {
      "epoch": 1.4106068890103882,
      "grad_norm": 0.4903567433357239,
      "learning_rate": 1.8589393110989613e-05,
      "loss": 0.0841,
      "step": 5160
    },
    {
      "epoch": 1.413340623291416,
      "grad_norm": 1.0253695249557495,
      "learning_rate": 1.8586659376708583e-05,
      "loss": 0.0612,
      "step": 5170
    },
    {
      "epoch": 1.416074357572444,
      "grad_norm": 0.5480077862739563,
      "learning_rate": 1.858392564242756e-05,
      "loss": 0.066,
      "step": 5180
    },
    {
      "epoch": 1.4188080918534718,
      "grad_norm": 1.3327527046203613,
      "learning_rate": 1.858119190814653e-05,
      "loss": 0.127,
      "step": 5190
    },
    {
      "epoch": 1.4215418261344999,
      "grad_norm": 0.07196889072656631,
      "learning_rate": 1.85784581738655e-05,
      "loss": 0.0317,
      "step": 5200
    },
    {
      "epoch": 1.4242755604155275,
      "grad_norm": 0.1657361388206482,
      "learning_rate": 1.8575724439584477e-05,
      "loss": 0.0809,
      "step": 5210
    },
    {
      "epoch": 1.4270092946965556,
      "grad_norm": 0.12896667420864105,
      "learning_rate": 1.8572990705303447e-05,
      "loss": 0.0439,
      "step": 5220
    },
    {
      "epoch": 1.4297430289775834,
      "grad_norm": 5.61533260345459,
      "learning_rate": 1.8570256971022416e-05,
      "loss": 0.0628,
      "step": 5230
    },
    {
      "epoch": 1.4324767632586113,
      "grad_norm": 1.3158296346664429,
      "learning_rate": 1.856752323674139e-05,
      "loss": 0.0409,
      "step": 5240
    },
    {
      "epoch": 1.4352104975396391,
      "grad_norm": 0.09559178352355957,
      "learning_rate": 1.8564789502460363e-05,
      "loss": 0.0142,
      "step": 5250
    },
    {
      "epoch": 1.437944231820667,
      "grad_norm": 2.608145236968994,
      "learning_rate": 1.8562055768179333e-05,
      "loss": 0.0601,
      "step": 5260
    },
    {
      "epoch": 1.4406779661016949,
      "grad_norm": 1.1985599994659424,
      "learning_rate": 1.8559322033898307e-05,
      "loss": 0.0767,
      "step": 5270
    },
    {
      "epoch": 1.4434117003827227,
      "grad_norm": 3.7231485843658447,
      "learning_rate": 1.855658829961728e-05,
      "loss": 0.1284,
      "step": 5280
    },
    {
      "epoch": 1.4461454346637508,
      "grad_norm": 0.06117302551865578,
      "learning_rate": 1.855385456533625e-05,
      "loss": 0.0168,
      "step": 5290
    },
    {
      "epoch": 1.4488791689447786,
      "grad_norm": 0.936621904373169,
      "learning_rate": 1.8551120831055223e-05,
      "loss": 0.0587,
      "step": 5300
    },
    {
      "epoch": 1.4516129032258065,
      "grad_norm": 3.975314140319824,
      "learning_rate": 1.8548387096774193e-05,
      "loss": 0.076,
      "step": 5310
    },
    {
      "epoch": 1.4543466375068343,
      "grad_norm": 0.043176691979169846,
      "learning_rate": 1.8545653362493166e-05,
      "loss": 0.0494,
      "step": 5320
    },
    {
      "epoch": 1.4570803717878622,
      "grad_norm": 6.23706579208374,
      "learning_rate": 1.854291962821214e-05,
      "loss": 0.0624,
      "step": 5330
    },
    {
      "epoch": 1.45981410606889,
      "grad_norm": 8.533411026000977,
      "learning_rate": 1.854018589393111e-05,
      "loss": 0.0528,
      "step": 5340
    },
    {
      "epoch": 1.462547840349918,
      "grad_norm": 0.0782957449555397,
      "learning_rate": 1.8537452159650083e-05,
      "loss": 0.0728,
      "step": 5350
    },
    {
      "epoch": 1.465281574630946,
      "grad_norm": 0.07747520506381989,
      "learning_rate": 1.8534718425369056e-05,
      "loss": 0.0819,
      "step": 5360
    },
    {
      "epoch": 1.4680153089119736,
      "grad_norm": 0.9435980916023254,
      "learning_rate": 1.8531984691088026e-05,
      "loss": 0.0655,
      "step": 5370
    },
    {
      "epoch": 1.4707490431930017,
      "grad_norm": 4.797680854797363,
      "learning_rate": 1.8529250956807e-05,
      "loss": 0.0538,
      "step": 5380
    },
    {
      "epoch": 1.4734827774740296,
      "grad_norm": 8.621809959411621,
      "learning_rate": 1.8526517222525973e-05,
      "loss": 0.084,
      "step": 5390
    },
    {
      "epoch": 1.4762165117550574,
      "grad_norm": 3.539708137512207,
      "learning_rate": 1.8523783488244943e-05,
      "loss": 0.0413,
      "step": 5400
    },
    {
      "epoch": 1.4789502460360853,
      "grad_norm": 29.163372039794922,
      "learning_rate": 1.8521049753963916e-05,
      "loss": 0.036,
      "step": 5410
    },
    {
      "epoch": 1.4816839803171131,
      "grad_norm": 0.11551839113235474,
      "learning_rate": 1.851831601968289e-05,
      "loss": 0.0732,
      "step": 5420
    },
    {
      "epoch": 1.484417714598141,
      "grad_norm": 5.291749477386475,
      "learning_rate": 1.851558228540186e-05,
      "loss": 0.0191,
      "step": 5430
    },
    {
      "epoch": 1.4871514488791688,
      "grad_norm": 0.010377324186265469,
      "learning_rate": 1.8512848551120833e-05,
      "loss": 0.0366,
      "step": 5440
    },
    {
      "epoch": 1.489885183160197,
      "grad_norm": 7.669831275939941,
      "learning_rate": 1.8510114816839803e-05,
      "loss": 0.0752,
      "step": 5450
    },
    {
      "epoch": 1.4926189174412248,
      "grad_norm": 4.912127494812012,
      "learning_rate": 1.8507381082558776e-05,
      "loss": 0.0669,
      "step": 5460
    },
    {
      "epoch": 1.4953526517222526,
      "grad_norm": 0.9789388179779053,
      "learning_rate": 1.850464734827775e-05,
      "loss": 0.069,
      "step": 5470
    },
    {
      "epoch": 1.4980863860032805,
      "grad_norm": 4.8278326988220215,
      "learning_rate": 1.850191361399672e-05,
      "loss": 0.0501,
      "step": 5480
    },
    {
      "epoch": 1.5008201202843083,
      "grad_norm": 0.3966640830039978,
      "learning_rate": 1.8499179879715693e-05,
      "loss": 0.0882,
      "step": 5490
    },
    {
      "epoch": 1.5035538545653364,
      "grad_norm": 3.0794613361358643,
      "learning_rate": 1.8496446145434666e-05,
      "loss": 0.0347,
      "step": 5500
    },
    {
      "epoch": 1.506287588846364,
      "grad_norm": 4.850934028625488,
      "learning_rate": 1.8493712411153636e-05,
      "loss": 0.0544,
      "step": 5510
    },
    {
      "epoch": 1.5090213231273921,
      "grad_norm": 0.05453808978199959,
      "learning_rate": 1.849097867687261e-05,
      "loss": 0.0796,
      "step": 5520
    },
    {
      "epoch": 1.5117550574084198,
      "grad_norm": 2.8416593074798584,
      "learning_rate": 1.8488244942591583e-05,
      "loss": 0.0598,
      "step": 5530
    },
    {
      "epoch": 1.5144887916894478,
      "grad_norm": 3.3060126304626465,
      "learning_rate": 1.8485511208310553e-05,
      "loss": 0.159,
      "step": 5540
    },
    {
      "epoch": 1.5172225259704757,
      "grad_norm": 0.43180927634239197,
      "learning_rate": 1.8482777474029526e-05,
      "loss": 0.0188,
      "step": 5550
    },
    {
      "epoch": 1.5199562602515035,
      "grad_norm": 6.781445026397705,
      "learning_rate": 1.84800437397485e-05,
      "loss": 0.0644,
      "step": 5560
    },
    {
      "epoch": 1.5226899945325314,
      "grad_norm": 0.08864746242761612,
      "learning_rate": 1.847731000546747e-05,
      "loss": 0.0285,
      "step": 5570
    },
    {
      "epoch": 1.5254237288135593,
      "grad_norm": 4.321002960205078,
      "learning_rate": 1.8474576271186443e-05,
      "loss": 0.0957,
      "step": 5580
    },
    {
      "epoch": 1.5281574630945873,
      "grad_norm": 0.32021382451057434,
      "learning_rate": 1.8471842536905413e-05,
      "loss": 0.0852,
      "step": 5590
    },
    {
      "epoch": 1.530891197375615,
      "grad_norm": 0.10154986381530762,
      "learning_rate": 1.8469108802624386e-05,
      "loss": 0.0558,
      "step": 5600
    },
    {
      "epoch": 1.533624931656643,
      "grad_norm": 1.0086710453033447,
      "learning_rate": 1.846637506834336e-05,
      "loss": 0.0371,
      "step": 5610
    },
    {
      "epoch": 1.536358665937671,
      "grad_norm": 0.6902957558631897,
      "learning_rate": 1.846364133406233e-05,
      "loss": 0.0647,
      "step": 5620
    },
    {
      "epoch": 1.5390924002186988,
      "grad_norm": 1.9612972736358643,
      "learning_rate": 1.8460907599781303e-05,
      "loss": 0.052,
      "step": 5630
    },
    {
      "epoch": 1.5418261344997266,
      "grad_norm": 1.0026264190673828,
      "learning_rate": 1.8458173865500276e-05,
      "loss": 0.0556,
      "step": 5640
    },
    {
      "epoch": 1.5445598687807545,
      "grad_norm": 0.27791258692741394,
      "learning_rate": 1.8455440131219246e-05,
      "loss": 0.0214,
      "step": 5650
    },
    {
      "epoch": 1.5472936030617825,
      "grad_norm": 5.4384989738464355,
      "learning_rate": 1.845270639693822e-05,
      "loss": 0.0748,
      "step": 5660
    },
    {
      "epoch": 1.5500273373428102,
      "grad_norm": 0.0682988315820694,
      "learning_rate": 1.8449972662657193e-05,
      "loss": 0.0793,
      "step": 5670
    },
    {
      "epoch": 1.5527610716238383,
      "grad_norm": 0.04434892535209656,
      "learning_rate": 1.8447238928376163e-05,
      "loss": 0.0963,
      "step": 5680
    },
    {
      "epoch": 1.5554948059048659,
      "grad_norm": 0.7286006808280945,
      "learning_rate": 1.8444505194095136e-05,
      "loss": 0.0236,
      "step": 5690
    },
    {
      "epoch": 1.558228540185894,
      "grad_norm": 1.8821245431900024,
      "learning_rate": 1.844177145981411e-05,
      "loss": 0.0279,
      "step": 5700
    },
    {
      "epoch": 1.5609622744669218,
      "grad_norm": 0.17636528611183167,
      "learning_rate": 1.843903772553308e-05,
      "loss": 0.0581,
      "step": 5710
    },
    {
      "epoch": 1.5636960087479497,
      "grad_norm": 0.03853347525000572,
      "learning_rate": 1.8436303991252053e-05,
      "loss": 0.0401,
      "step": 5720
    },
    {
      "epoch": 1.5664297430289775,
      "grad_norm": 11.879264831542969,
      "learning_rate": 1.8433570256971023e-05,
      "loss": 0.0815,
      "step": 5730
    },
    {
      "epoch": 1.5691634773100054,
      "grad_norm": 4.108919620513916,
      "learning_rate": 1.8430836522689996e-05,
      "loss": 0.0491,
      "step": 5740
    },
    {
      "epoch": 1.5718972115910335,
      "grad_norm": 0.23009353876113892,
      "learning_rate": 1.842810278840897e-05,
      "loss": 0.0816,
      "step": 5750
    },
    {
      "epoch": 1.574630945872061,
      "grad_norm": 4.891101360321045,
      "learning_rate": 1.842536905412794e-05,
      "loss": 0.139,
      "step": 5760
    },
    {
      "epoch": 1.5773646801530892,
      "grad_norm": 2.2652480602264404,
      "learning_rate": 1.8422635319846913e-05,
      "loss": 0.091,
      "step": 5770
    },
    {
      "epoch": 1.580098414434117,
      "grad_norm": 0.1537225991487503,
      "learning_rate": 1.8419901585565886e-05,
      "loss": 0.0412,
      "step": 5780
    },
    {
      "epoch": 1.5828321487151449,
      "grad_norm": 2.960310697555542,
      "learning_rate": 1.8417167851284856e-05,
      "loss": 0.0572,
      "step": 5790
    },
    {
      "epoch": 1.5855658829961727,
      "grad_norm": 0.4332738518714905,
      "learning_rate": 1.8414434117003826e-05,
      "loss": 0.0684,
      "step": 5800
    },
    {
      "epoch": 1.5882996172772006,
      "grad_norm": 0.08470360189676285,
      "learning_rate": 1.8411700382722803e-05,
      "loss": 0.0257,
      "step": 5810
    },
    {
      "epoch": 1.5910333515582287,
      "grad_norm": 0.16443806886672974,
      "learning_rate": 1.8408966648441773e-05,
      "loss": 0.0424,
      "step": 5820
    },
    {
      "epoch": 1.5937670858392563,
      "grad_norm": 0.05442676693201065,
      "learning_rate": 1.8406232914160743e-05,
      "loss": 0.0177,
      "step": 5830
    },
    {
      "epoch": 1.5965008201202844,
      "grad_norm": 0.03723705932497978,
      "learning_rate": 1.840349917987972e-05,
      "loss": 0.0782,
      "step": 5840
    },
    {
      "epoch": 1.5992345544013122,
      "grad_norm": 3.083768844604492,
      "learning_rate": 1.840076544559869e-05,
      "loss": 0.0611,
      "step": 5850
    },
    {
      "epoch": 1.60196828868234,
      "grad_norm": 7.886168479919434,
      "learning_rate": 1.839803171131766e-05,
      "loss": 0.0471,
      "step": 5860
    },
    {
      "epoch": 1.604702022963368,
      "grad_norm": 0.035090263932943344,
      "learning_rate": 1.8395297977036633e-05,
      "loss": 0.0436,
      "step": 5870
    },
    {
      "epoch": 1.6074357572443958,
      "grad_norm": 0.28621238470077515,
      "learning_rate": 1.8392564242755606e-05,
      "loss": 0.0139,
      "step": 5880
    },
    {
      "epoch": 1.6101694915254239,
      "grad_norm": 0.06559064984321594,
      "learning_rate": 1.8389830508474576e-05,
      "loss": 0.0388,
      "step": 5890
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.3170241415500641,
      "learning_rate": 1.838709677419355e-05,
      "loss": 0.0662,
      "step": 5900
    },
    {
      "epoch": 1.6156369600874796,
      "grad_norm": 0.21264685690402985,
      "learning_rate": 1.8384363039912523e-05,
      "loss": 0.0285,
      "step": 5910
    },
    {
      "epoch": 1.6183706943685072,
      "grad_norm": 6.896042823791504,
      "learning_rate": 1.8381629305631493e-05,
      "loss": 0.0911,
      "step": 5920
    },
    {
      "epoch": 1.6211044286495353,
      "grad_norm": 0.2988758087158203,
      "learning_rate": 1.8378895571350466e-05,
      "loss": 0.0501,
      "step": 5930
    },
    {
      "epoch": 1.6238381629305632,
      "grad_norm": 0.21070483326911926,
      "learning_rate": 1.837616183706944e-05,
      "loss": 0.0331,
      "step": 5940
    },
    {
      "epoch": 1.626571897211591,
      "grad_norm": 0.032528650015592575,
      "learning_rate": 1.837342810278841e-05,
      "loss": 0.0043,
      "step": 5950
    },
    {
      "epoch": 1.6293056314926189,
      "grad_norm": 0.08480355143547058,
      "learning_rate": 1.8370694368507383e-05,
      "loss": 0.0514,
      "step": 5960
    },
    {
      "epoch": 1.6320393657736467,
      "grad_norm": 6.959727764129639,
      "learning_rate": 1.8367960634226353e-05,
      "loss": 0.1059,
      "step": 5970
    },
    {
      "epoch": 1.6347731000546748,
      "grad_norm": 0.5005184412002563,
      "learning_rate": 1.8365226899945326e-05,
      "loss": 0.0842,
      "step": 5980
    },
    {
      "epoch": 1.6375068343357024,
      "grad_norm": 0.06568652391433716,
      "learning_rate": 1.83624931656643e-05,
      "loss": 0.0179,
      "step": 5990
    },
    {
      "epoch": 1.6402405686167305,
      "grad_norm": 0.025830432772636414,
      "learning_rate": 1.835975943138327e-05,
      "loss": 0.0301,
      "step": 6000
    },
    {
      "epoch": 1.6429743028977584,
      "grad_norm": 0.11851723492145538,
      "learning_rate": 1.8357025697102243e-05,
      "loss": 0.0448,
      "step": 6010
    },
    {
      "epoch": 1.6457080371787862,
      "grad_norm": 0.018449945375323296,
      "learning_rate": 1.8354291962821216e-05,
      "loss": 0.0163,
      "step": 6020
    },
    {
      "epoch": 1.648441771459814,
      "grad_norm": 0.012306885793805122,
      "learning_rate": 1.8351558228540186e-05,
      "loss": 0.1132,
      "step": 6030
    },
    {
      "epoch": 1.651175505740842,
      "grad_norm": 2.5246479511260986,
      "learning_rate": 1.834882449425916e-05,
      "loss": 0.0636,
      "step": 6040
    },
    {
      "epoch": 1.65390924002187,
      "grad_norm": 4.6736369132995605,
      "learning_rate": 1.8346090759978133e-05,
      "loss": 0.1158,
      "step": 6050
    },
    {
      "epoch": 1.6566429743028976,
      "grad_norm": 0.45035964250564575,
      "learning_rate": 1.8343357025697103e-05,
      "loss": 0.0598,
      "step": 6060
    },
    {
      "epoch": 1.6593767085839257,
      "grad_norm": 0.5406486392021179,
      "learning_rate": 1.8340623291416076e-05,
      "loss": 0.0373,
      "step": 6070
    },
    {
      "epoch": 1.6621104428649536,
      "grad_norm": 0.00875683594495058,
      "learning_rate": 1.833788955713505e-05,
      "loss": 0.0136,
      "step": 6080
    },
    {
      "epoch": 1.6648441771459814,
      "grad_norm": 0.016090480610728264,
      "learning_rate": 1.833515582285402e-05,
      "loss": 0.0688,
      "step": 6090
    },
    {
      "epoch": 1.6675779114270093,
      "grad_norm": 0.8803724050521851,
      "learning_rate": 1.8332422088572993e-05,
      "loss": 0.1172,
      "step": 6100
    },
    {
      "epoch": 1.6703116457080371,
      "grad_norm": 0.11774879693984985,
      "learning_rate": 1.8329688354291963e-05,
      "loss": 0.0533,
      "step": 6110
    },
    {
      "epoch": 1.6730453799890652,
      "grad_norm": 0.2059195339679718,
      "learning_rate": 1.8326954620010936e-05,
      "loss": 0.0449,
      "step": 6120
    },
    {
      "epoch": 1.6757791142700929,
      "grad_norm": 0.0487222820520401,
      "learning_rate": 1.832422088572991e-05,
      "loss": 0.0351,
      "step": 6130
    },
    {
      "epoch": 1.678512848551121,
      "grad_norm": 1.0712213516235352,
      "learning_rate": 1.832148715144888e-05,
      "loss": 0.0136,
      "step": 6140
    },
    {
      "epoch": 1.6812465828321486,
      "grad_norm": 0.7870027422904968,
      "learning_rate": 1.8318753417167853e-05,
      "loss": 0.075,
      "step": 6150
    },
    {
      "epoch": 1.6839803171131766,
      "grad_norm": 0.15037782490253448,
      "learning_rate": 1.8316019682886826e-05,
      "loss": 0.0761,
      "step": 6160
    },
    {
      "epoch": 1.6867140513942045,
      "grad_norm": 0.1735619455575943,
      "learning_rate": 1.8313285948605796e-05,
      "loss": 0.0229,
      "step": 6170
    },
    {
      "epoch": 1.6894477856752323,
      "grad_norm": 0.044767826795578,
      "learning_rate": 1.831055221432477e-05,
      "loss": 0.0069,
      "step": 6180
    },
    {
      "epoch": 1.6921815199562602,
      "grad_norm": 6.852522373199463,
      "learning_rate": 1.8307818480043743e-05,
      "loss": 0.0789,
      "step": 6190
    },
    {
      "epoch": 1.694915254237288,
      "grad_norm": 7.628345966339111,
      "learning_rate": 1.8305084745762713e-05,
      "loss": 0.0381,
      "step": 6200
    },
    {
      "epoch": 1.6976489885183161,
      "grad_norm": 0.049005649983882904,
      "learning_rate": 1.8302351011481686e-05,
      "loss": 0.0336,
      "step": 6210
    },
    {
      "epoch": 1.7003827227993438,
      "grad_norm": 6.485945701599121,
      "learning_rate": 1.829961727720066e-05,
      "loss": 0.0915,
      "step": 6220
    },
    {
      "epoch": 1.7031164570803718,
      "grad_norm": 0.09402500092983246,
      "learning_rate": 1.829688354291963e-05,
      "loss": 0.0627,
      "step": 6230
    },
    {
      "epoch": 1.7058501913613997,
      "grad_norm": 1.053597092628479,
      "learning_rate": 1.8294149808638603e-05,
      "loss": 0.099,
      "step": 6240
    },
    {
      "epoch": 1.7085839256424276,
      "grad_norm": 0.07543567568063736,
      "learning_rate": 1.8291416074357573e-05,
      "loss": 0.0497,
      "step": 6250
    },
    {
      "epoch": 1.7113176599234554,
      "grad_norm": 2.4105823040008545,
      "learning_rate": 1.8288682340076546e-05,
      "loss": 0.0571,
      "step": 6260
    },
    {
      "epoch": 1.7140513942044833,
      "grad_norm": 0.042111821472644806,
      "learning_rate": 1.828594860579552e-05,
      "loss": 0.0256,
      "step": 6270
    },
    {
      "epoch": 1.7167851284855113,
      "grad_norm": 0.2323111593723297,
      "learning_rate": 1.828321487151449e-05,
      "loss": 0.0378,
      "step": 6280
    },
    {
      "epoch": 1.719518862766539,
      "grad_norm": 0.08741339296102524,
      "learning_rate": 1.8280481137233463e-05,
      "loss": 0.0151,
      "step": 6290
    },
    {
      "epoch": 1.722252597047567,
      "grad_norm": 0.032004885375499725,
      "learning_rate": 1.8277747402952436e-05,
      "loss": 0.0313,
      "step": 6300
    },
    {
      "epoch": 1.724986331328595,
      "grad_norm": 0.5919473767280579,
      "learning_rate": 1.8275013668671406e-05,
      "loss": 0.0598,
      "step": 6310
    },
    {
      "epoch": 1.7277200656096228,
      "grad_norm": 0.06947409361600876,
      "learning_rate": 1.827227993439038e-05,
      "loss": 0.1755,
      "step": 6320
    },
    {
      "epoch": 1.7304537998906506,
      "grad_norm": 0.11950083822011948,
      "learning_rate": 1.8269546200109353e-05,
      "loss": 0.0107,
      "step": 6330
    },
    {
      "epoch": 1.7331875341716785,
      "grad_norm": 3.2464311122894287,
      "learning_rate": 1.8266812465828323e-05,
      "loss": 0.074,
      "step": 6340
    },
    {
      "epoch": 1.7359212684527066,
      "grad_norm": 7.578397274017334,
      "learning_rate": 1.8264078731547296e-05,
      "loss": 0.0562,
      "step": 6350
    },
    {
      "epoch": 1.7386550027337342,
      "grad_norm": 11.213315963745117,
      "learning_rate": 1.826134499726627e-05,
      "loss": 0.0638,
      "step": 6360
    },
    {
      "epoch": 1.7413887370147623,
      "grad_norm": 5.270351409912109,
      "learning_rate": 1.825861126298524e-05,
      "loss": 0.0239,
      "step": 6370
    },
    {
      "epoch": 1.74412247129579,
      "grad_norm": 0.20782019197940826,
      "learning_rate": 1.8255877528704213e-05,
      "loss": 0.0258,
      "step": 6380
    },
    {
      "epoch": 1.746856205576818,
      "grad_norm": 8.641993522644043,
      "learning_rate": 1.8253143794423183e-05,
      "loss": 0.0793,
      "step": 6390
    },
    {
      "epoch": 1.7495899398578458,
      "grad_norm": 4.340672016143799,
      "learning_rate": 1.8250410060142156e-05,
      "loss": 0.0419,
      "step": 6400
    },
    {
      "epoch": 1.7523236741388737,
      "grad_norm": 0.6390278339385986,
      "learning_rate": 1.824767632586113e-05,
      "loss": 0.1124,
      "step": 6410
    },
    {
      "epoch": 1.7550574084199015,
      "grad_norm": 0.07328478991985321,
      "learning_rate": 1.82449425915801e-05,
      "loss": 0.1436,
      "step": 6420
    },
    {
      "epoch": 1.7577911427009294,
      "grad_norm": 1.2353824377059937,
      "learning_rate": 1.8242208857299073e-05,
      "loss": 0.0396,
      "step": 6430
    },
    {
      "epoch": 1.7605248769819575,
      "grad_norm": 0.1621326506137848,
      "learning_rate": 1.8239475123018046e-05,
      "loss": 0.0409,
      "step": 6440
    },
    {
      "epoch": 1.763258611262985,
      "grad_norm": 0.0344318151473999,
      "learning_rate": 1.8236741388737016e-05,
      "loss": 0.0333,
      "step": 6450
    },
    {
      "epoch": 1.7659923455440132,
      "grad_norm": 0.20576438307762146,
      "learning_rate": 1.8234007654455986e-05,
      "loss": 0.0704,
      "step": 6460
    },
    {
      "epoch": 1.768726079825041,
      "grad_norm": 0.015823930501937866,
      "learning_rate": 1.8231273920174963e-05,
      "loss": 0.0385,
      "step": 6470
    },
    {
      "epoch": 1.771459814106069,
      "grad_norm": 0.11741451174020767,
      "learning_rate": 1.8228540185893933e-05,
      "loss": 0.0611,
      "step": 6480
    },
    {
      "epoch": 1.7741935483870968,
      "grad_norm": 0.18132686614990234,
      "learning_rate": 1.8225806451612903e-05,
      "loss": 0.0576,
      "step": 6490
    },
    {
      "epoch": 1.7769272826681246,
      "grad_norm": 0.38832297921180725,
      "learning_rate": 1.822307271733188e-05,
      "loss": 0.0199,
      "step": 6500
    },
    {
      "epoch": 1.7796610169491527,
      "grad_norm": 0.023331690579652786,
      "learning_rate": 1.822033898305085e-05,
      "loss": 0.0455,
      "step": 6510
    },
    {
      "epoch": 1.7823947512301803,
      "grad_norm": 14.868735313415527,
      "learning_rate": 1.821760524876982e-05,
      "loss": 0.0638,
      "step": 6520
    },
    {
      "epoch": 1.7851284855112084,
      "grad_norm": 1.2996095418930054,
      "learning_rate": 1.8214871514488793e-05,
      "loss": 0.0609,
      "step": 6530
    },
    {
      "epoch": 1.787862219792236,
      "grad_norm": 11.875158309936523,
      "learning_rate": 1.8212137780207766e-05,
      "loss": 0.1132,
      "step": 6540
    },
    {
      "epoch": 1.790595954073264,
      "grad_norm": 2.1212642192840576,
      "learning_rate": 1.8209404045926736e-05,
      "loss": 0.0696,
      "step": 6550
    },
    {
      "epoch": 1.793329688354292,
      "grad_norm": 5.942644119262695,
      "learning_rate": 1.820667031164571e-05,
      "loss": 0.0534,
      "step": 6560
    },
    {
      "epoch": 1.7960634226353198,
      "grad_norm": 0.17959240078926086,
      "learning_rate": 1.8203936577364683e-05,
      "loss": 0.0946,
      "step": 6570
    },
    {
      "epoch": 1.798797156916348,
      "grad_norm": 0.07677256315946579,
      "learning_rate": 1.8201202843083653e-05,
      "loss": 0.021,
      "step": 6580
    },
    {
      "epoch": 1.8015308911973755,
      "grad_norm": 4.017730712890625,
      "learning_rate": 1.8198469108802626e-05,
      "loss": 0.0711,
      "step": 6590
    },
    {
      "epoch": 1.8042646254784036,
      "grad_norm": 0.88515704870224,
      "learning_rate": 1.8195735374521596e-05,
      "loss": 0.0669,
      "step": 6600
    },
    {
      "epoch": 1.8069983597594312,
      "grad_norm": 0.23472075164318085,
      "learning_rate": 1.819300164024057e-05,
      "loss": 0.0619,
      "step": 6610
    },
    {
      "epoch": 1.8097320940404593,
      "grad_norm": 2.922175407409668,
      "learning_rate": 1.8190267905959543e-05,
      "loss": 0.096,
      "step": 6620
    },
    {
      "epoch": 1.8124658283214872,
      "grad_norm": 0.6833284497261047,
      "learning_rate": 1.8187534171678513e-05,
      "loss": 0.0326,
      "step": 6630
    },
    {
      "epoch": 1.815199562602515,
      "grad_norm": 0.06852884590625763,
      "learning_rate": 1.8184800437397486e-05,
      "loss": 0.0808,
      "step": 6640
    },
    {
      "epoch": 1.8179332968835429,
      "grad_norm": 0.05195913091301918,
      "learning_rate": 1.818206670311646e-05,
      "loss": 0.007,
      "step": 6650
    },
    {
      "epoch": 1.8206670311645707,
      "grad_norm": 0.05955250933766365,
      "learning_rate": 1.817933296883543e-05,
      "loss": 0.0142,
      "step": 6660
    },
    {
      "epoch": 1.8234007654455988,
      "grad_norm": 37.46281814575195,
      "learning_rate": 1.8176599234554403e-05,
      "loss": 0.0731,
      "step": 6670
    },
    {
      "epoch": 1.8261344997266264,
      "grad_norm": 1.1924713850021362,
      "learning_rate": 1.8173865500273376e-05,
      "loss": 0.0603,
      "step": 6680
    },
    {
      "epoch": 1.8288682340076545,
      "grad_norm": 7.1745805740356445,
      "learning_rate": 1.8171131765992346e-05,
      "loss": 0.1021,
      "step": 6690
    },
    {
      "epoch": 1.8316019682886824,
      "grad_norm": 8.118321418762207,
      "learning_rate": 1.816839803171132e-05,
      "loss": 0.0468,
      "step": 6700
    },
    {
      "epoch": 1.8343357025697102,
      "grad_norm": 0.050627078860998154,
      "learning_rate": 1.8165664297430293e-05,
      "loss": 0.0336,
      "step": 6710
    },
    {
      "epoch": 1.837069436850738,
      "grad_norm": 8.048582077026367,
      "learning_rate": 1.8162930563149263e-05,
      "loss": 0.0996,
      "step": 6720
    },
    {
      "epoch": 1.839803171131766,
      "grad_norm": 12.264741897583008,
      "learning_rate": 1.8160196828868236e-05,
      "loss": 0.0308,
      "step": 6730
    },
    {
      "epoch": 1.842536905412794,
      "grad_norm": 3.154484272003174,
      "learning_rate": 1.8157463094587206e-05,
      "loss": 0.0413,
      "step": 6740
    },
    {
      "epoch": 1.8452706396938217,
      "grad_norm": 0.6062716245651245,
      "learning_rate": 1.815472936030618e-05,
      "loss": 0.0451,
      "step": 6750
    },
    {
      "epoch": 1.8480043739748497,
      "grad_norm": 0.3286207318305969,
      "learning_rate": 1.8151995626025153e-05,
      "loss": 0.0497,
      "step": 6760
    },
    {
      "epoch": 1.8507381082558774,
      "grad_norm": 0.07134688645601273,
      "learning_rate": 1.8149261891744123e-05,
      "loss": 0.0569,
      "step": 6770
    },
    {
      "epoch": 1.8534718425369054,
      "grad_norm": 0.14861220121383667,
      "learning_rate": 1.8146528157463096e-05,
      "loss": 0.0626,
      "step": 6780
    },
    {
      "epoch": 1.8562055768179333,
      "grad_norm": 2.047348976135254,
      "learning_rate": 1.814379442318207e-05,
      "loss": 0.0698,
      "step": 6790
    },
    {
      "epoch": 1.8589393110989612,
      "grad_norm": 7.278010368347168,
      "learning_rate": 1.814106068890104e-05,
      "loss": 0.11,
      "step": 6800
    },
    {
      "epoch": 1.861673045379989,
      "grad_norm": 11.847770690917969,
      "learning_rate": 1.8138326954620013e-05,
      "loss": 0.0412,
      "step": 6810
    },
    {
      "epoch": 1.8644067796610169,
      "grad_norm": 21.200061798095703,
      "learning_rate": 1.8135593220338986e-05,
      "loss": 0.0601,
      "step": 6820
    },
    {
      "epoch": 1.867140513942045,
      "grad_norm": 0.017681563273072243,
      "learning_rate": 1.8132859486057956e-05,
      "loss": 0.0497,
      "step": 6830
    },
    {
      "epoch": 1.8698742482230726,
      "grad_norm": 0.3115732967853546,
      "learning_rate": 1.813012575177693e-05,
      "loss": 0.043,
      "step": 6840
    },
    {
      "epoch": 1.8726079825041007,
      "grad_norm": 0.025460077449679375,
      "learning_rate": 1.8127392017495903e-05,
      "loss": 0.0612,
      "step": 6850
    },
    {
      "epoch": 1.8753417167851285,
      "grad_norm": 15.743271827697754,
      "learning_rate": 1.8124658283214873e-05,
      "loss": 0.0762,
      "step": 6860
    },
    {
      "epoch": 1.8780754510661564,
      "grad_norm": 4.198514461517334,
      "learning_rate": 1.8121924548933846e-05,
      "loss": 0.0406,
      "step": 6870
    },
    {
      "epoch": 1.8808091853471842,
      "grad_norm": 5.474569320678711,
      "learning_rate": 1.8119190814652816e-05,
      "loss": 0.0771,
      "step": 6880
    },
    {
      "epoch": 1.883542919628212,
      "grad_norm": 0.20328383147716522,
      "learning_rate": 1.811645708037179e-05,
      "loss": 0.0669,
      "step": 6890
    },
    {
      "epoch": 1.8862766539092402,
      "grad_norm": 3.577644109725952,
      "learning_rate": 1.8113723346090763e-05,
      "loss": 0.0519,
      "step": 6900
    },
    {
      "epoch": 1.8890103881902678,
      "grad_norm": 8.16498851776123,
      "learning_rate": 1.8110989611809733e-05,
      "loss": 0.0975,
      "step": 6910
    },
    {
      "epoch": 1.8917441224712959,
      "grad_norm": 1.529914140701294,
      "learning_rate": 1.8108255877528706e-05,
      "loss": 0.0373,
      "step": 6920
    },
    {
      "epoch": 1.8944778567523237,
      "grad_norm": 0.053633078932762146,
      "learning_rate": 1.810552214324768e-05,
      "loss": 0.0585,
      "step": 6930
    },
    {
      "epoch": 1.8972115910333516,
      "grad_norm": 0.8116952776908875,
      "learning_rate": 1.810278840896665e-05,
      "loss": 0.0575,
      "step": 6940
    },
    {
      "epoch": 1.8999453253143794,
      "grad_norm": 0.19693483412265778,
      "learning_rate": 1.8100054674685623e-05,
      "loss": 0.0277,
      "step": 6950
    },
    {
      "epoch": 1.9026790595954073,
      "grad_norm": 13.8906888961792,
      "learning_rate": 1.8097320940404596e-05,
      "loss": 0.1528,
      "step": 6960
    },
    {
      "epoch": 1.9054127938764354,
      "grad_norm": 0.06758902221918106,
      "learning_rate": 1.8094587206123566e-05,
      "loss": 0.033,
      "step": 6970
    },
    {
      "epoch": 1.908146528157463,
      "grad_norm": 63.40412902832031,
      "learning_rate": 1.809185347184254e-05,
      "loss": 0.0323,
      "step": 6980
    },
    {
      "epoch": 1.910880262438491,
      "grad_norm": 4.629422187805176,
      "learning_rate": 1.8089119737561513e-05,
      "loss": 0.0797,
      "step": 6990
    },
    {
      "epoch": 1.9136139967195187,
      "grad_norm": 4.198437213897705,
      "learning_rate": 1.8086386003280483e-05,
      "loss": 0.0545,
      "step": 7000
    },
    {
      "epoch": 1.9163477310005468,
      "grad_norm": 0.5494967103004456,
      "learning_rate": 1.8083652268999456e-05,
      "loss": 0.011,
      "step": 7010
    },
    {
      "epoch": 1.9190814652815746,
      "grad_norm": 0.005512423347681761,
      "learning_rate": 1.808091853471843e-05,
      "loss": 0.0187,
      "step": 7020
    },
    {
      "epoch": 1.9218151995626025,
      "grad_norm": 5.525424957275391,
      "learning_rate": 1.80781848004374e-05,
      "loss": 0.0508,
      "step": 7030
    },
    {
      "epoch": 1.9245489338436303,
      "grad_norm": 0.05782053992152214,
      "learning_rate": 1.8075451066156373e-05,
      "loss": 0.0675,
      "step": 7040
    },
    {
      "epoch": 1.9272826681246582,
      "grad_norm": 3.6434428691864014,
      "learning_rate": 1.8072717331875343e-05,
      "loss": 0.0506,
      "step": 7050
    },
    {
      "epoch": 1.9300164024056863,
      "grad_norm": 16.16387176513672,
      "learning_rate": 1.8069983597594316e-05,
      "loss": 0.0535,
      "step": 7060
    },
    {
      "epoch": 1.932750136686714,
      "grad_norm": 0.07861541211605072,
      "learning_rate": 1.806724986331329e-05,
      "loss": 0.0429,
      "step": 7070
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.170813649892807,
      "learning_rate": 1.806451612903226e-05,
      "loss": 0.0681,
      "step": 7080
    },
    {
      "epoch": 1.9382176052487698,
      "grad_norm": 2.772038698196411,
      "learning_rate": 1.8061782394751233e-05,
      "loss": 0.0711,
      "step": 7090
    },
    {
      "epoch": 1.9409513395297977,
      "grad_norm": 0.4082868993282318,
      "learning_rate": 1.8059048660470203e-05,
      "loss": 0.016,
      "step": 7100
    },
    {
      "epoch": 1.9436850738108256,
      "grad_norm": 0.7020182609558105,
      "learning_rate": 1.8056314926189176e-05,
      "loss": 0.027,
      "step": 7110
    },
    {
      "epoch": 1.9464188080918534,
      "grad_norm": 0.04283137246966362,
      "learning_rate": 1.8053581191908146e-05,
      "loss": 0.0849,
      "step": 7120
    },
    {
      "epoch": 1.9491525423728815,
      "grad_norm": 0.15555168688297272,
      "learning_rate": 1.805084745762712e-05,
      "loss": 0.0826,
      "step": 7130
    },
    {
      "epoch": 1.9518862766539091,
      "grad_norm": 0.07099500298500061,
      "learning_rate": 1.8048113723346093e-05,
      "loss": 0.0342,
      "step": 7140
    },
    {
      "epoch": 1.9546200109349372,
      "grad_norm": 2.015469789505005,
      "learning_rate": 1.8045379989065062e-05,
      "loss": 0.0373,
      "step": 7150
    },
    {
      "epoch": 1.957353745215965,
      "grad_norm": 0.9480121731758118,
      "learning_rate": 1.8042646254784036e-05,
      "loss": 0.0637,
      "step": 7160
    },
    {
      "epoch": 1.960087479496993,
      "grad_norm": 0.1161874309182167,
      "learning_rate": 1.803991252050301e-05,
      "loss": 0.0721,
      "step": 7170
    },
    {
      "epoch": 1.9628212137780208,
      "grad_norm": 0.17871594429016113,
      "learning_rate": 1.803717878622198e-05,
      "loss": 0.0257,
      "step": 7180
    },
    {
      "epoch": 1.9655549480590486,
      "grad_norm": 0.16003142297267914,
      "learning_rate": 1.8034445051940953e-05,
      "loss": 0.0121,
      "step": 7190
    },
    {
      "epoch": 1.9682886823400767,
      "grad_norm": 1.1015363931655884,
      "learning_rate": 1.8031711317659926e-05,
      "loss": 0.0069,
      "step": 7200
    },
    {
      "epoch": 1.9710224166211043,
      "grad_norm": 1.0643205642700195,
      "learning_rate": 1.8028977583378896e-05,
      "loss": 0.0249,
      "step": 7210
    },
    {
      "epoch": 1.9737561509021324,
      "grad_norm": 0.030268704518675804,
      "learning_rate": 1.802624384909787e-05,
      "loss": 0.047,
      "step": 7220
    },
    {
      "epoch": 1.97648988518316,
      "grad_norm": 0.037808287888765335,
      "learning_rate": 1.8023510114816843e-05,
      "loss": 0.0369,
      "step": 7230
    },
    {
      "epoch": 1.9792236194641881,
      "grad_norm": 0.03600572422146797,
      "learning_rate": 1.8020776380535812e-05,
      "loss": 0.0006,
      "step": 7240
    },
    {
      "epoch": 1.981957353745216,
      "grad_norm": 0.03133852407336235,
      "learning_rate": 1.8018042646254786e-05,
      "loss": 0.0861,
      "step": 7250
    },
    {
      "epoch": 1.9846910880262438,
      "grad_norm": 3.626668930053711,
      "learning_rate": 1.8015308911973756e-05,
      "loss": 0.0313,
      "step": 7260
    },
    {
      "epoch": 1.9874248223072717,
      "grad_norm": 0.03214982524514198,
      "learning_rate": 1.801257517769273e-05,
      "loss": 0.0417,
      "step": 7270
    },
    {
      "epoch": 1.9901585565882995,
      "grad_norm": 0.02037549391388893,
      "learning_rate": 1.8009841443411702e-05,
      "loss": 0.0387,
      "step": 7280
    },
    {
      "epoch": 1.9928922908693276,
      "grad_norm": 10.509302139282227,
      "learning_rate": 1.8007107709130672e-05,
      "loss": 0.0432,
      "step": 7290
    },
    {
      "epoch": 1.9956260251503553,
      "grad_norm": 0.024017121642827988,
      "learning_rate": 1.8004373974849646e-05,
      "loss": 0.0848,
      "step": 7300
    },
    {
      "epoch": 1.9983597594313833,
      "grad_norm": 0.026950720697641373,
      "learning_rate": 1.800164024056862e-05,
      "loss": 0.0513,
      "step": 7310
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9845679012345679,
      "eval_f1": 0.9368741837178929,
      "eval_loss": 0.05554484948515892,
      "eval_precision": 0.9560195468680587,
      "eval_recall": 0.9184805804524114,
      "eval_runtime": 797.0961,
      "eval_samples_per_second": 23.603,
      "eval_steps_per_second": 0.984,
      "step": 7316
    },
    {
      "epoch": 2.001093493712411,
      "grad_norm": 0.30215775966644287,
      "learning_rate": 1.799890650628759e-05,
      "loss": 0.0241,
      "step": 7320
    },
    {
      "epoch": 2.003827227993439,
      "grad_norm": 0.06281600892543793,
      "learning_rate": 1.7996172772006562e-05,
      "loss": 0.1284,
      "step": 7330
    },
    {
      "epoch": 2.006560962274467,
      "grad_norm": 0.33069896697998047,
      "learning_rate": 1.7993439037725536e-05,
      "loss": 0.0375,
      "step": 7340
    },
    {
      "epoch": 2.0092946965554948,
      "grad_norm": 22.751867294311523,
      "learning_rate": 1.7990705303444506e-05,
      "loss": 0.0315,
      "step": 7350
    },
    {
      "epoch": 2.012028430836523,
      "grad_norm": 1.20298433303833,
      "learning_rate": 1.798797156916348e-05,
      "loss": 0.041,
      "step": 7360
    },
    {
      "epoch": 2.0147621651175505,
      "grad_norm": 0.2980659604072571,
      "learning_rate": 1.7985237834882452e-05,
      "loss": 0.0669,
      "step": 7370
    },
    {
      "epoch": 2.0174958993985785,
      "grad_norm": 0.02292271889746189,
      "learning_rate": 1.7982504100601422e-05,
      "loss": 0.0207,
      "step": 7380
    },
    {
      "epoch": 2.020229633679606,
      "grad_norm": 14.933024406433105,
      "learning_rate": 1.7979770366320396e-05,
      "loss": 0.0985,
      "step": 7390
    },
    {
      "epoch": 2.0229633679606343,
      "grad_norm": 0.04662279039621353,
      "learning_rate": 1.7977036632039366e-05,
      "loss": 0.0434,
      "step": 7400
    },
    {
      "epoch": 2.0256971022416623,
      "grad_norm": 0.6248227953910828,
      "learning_rate": 1.797430289775834e-05,
      "loss": 0.0507,
      "step": 7410
    },
    {
      "epoch": 2.02843083652269,
      "grad_norm": 12.563932418823242,
      "learning_rate": 1.7971569163477312e-05,
      "loss": 0.0363,
      "step": 7420
    },
    {
      "epoch": 2.031164570803718,
      "grad_norm": 0.6509860157966614,
      "learning_rate": 1.7968835429196282e-05,
      "loss": 0.0332,
      "step": 7430
    },
    {
      "epoch": 2.0338983050847457,
      "grad_norm": 0.013569636270403862,
      "learning_rate": 1.7966101694915256e-05,
      "loss": 0.0424,
      "step": 7440
    },
    {
      "epoch": 2.0366320393657737,
      "grad_norm": 0.23780888319015503,
      "learning_rate": 1.796336796063423e-05,
      "loss": 0.0426,
      "step": 7450
    },
    {
      "epoch": 2.0393657736468014,
      "grad_norm": 0.01205280888825655,
      "learning_rate": 1.79606342263532e-05,
      "loss": 0.0349,
      "step": 7460
    },
    {
      "epoch": 2.0420995079278295,
      "grad_norm": 0.010101117193698883,
      "learning_rate": 1.7957900492072172e-05,
      "loss": 0.0376,
      "step": 7470
    },
    {
      "epoch": 2.044833242208857,
      "grad_norm": 0.14866302907466888,
      "learning_rate": 1.7955166757791146e-05,
      "loss": 0.0612,
      "step": 7480
    },
    {
      "epoch": 2.047566976489885,
      "grad_norm": 0.06696347147226334,
      "learning_rate": 1.7952433023510116e-05,
      "loss": 0.0401,
      "step": 7490
    },
    {
      "epoch": 2.0503007107709132,
      "grad_norm": 0.03292284533381462,
      "learning_rate": 1.794969928922909e-05,
      "loss": 0.0285,
      "step": 7500
    },
    {
      "epoch": 2.053034445051941,
      "grad_norm": 0.01809990406036377,
      "learning_rate": 1.7946965554948062e-05,
      "loss": 0.0329,
      "step": 7510
    },
    {
      "epoch": 2.055768179332969,
      "grad_norm": 5.7588090896606445,
      "learning_rate": 1.7944231820667032e-05,
      "loss": 0.0668,
      "step": 7520
    },
    {
      "epoch": 2.0585019136139966,
      "grad_norm": 4.23253059387207,
      "learning_rate": 1.7941498086386006e-05,
      "loss": 0.0398,
      "step": 7530
    },
    {
      "epoch": 2.0612356478950247,
      "grad_norm": 0.2639116644859314,
      "learning_rate": 1.7938764352104976e-05,
      "loss": 0.0263,
      "step": 7540
    },
    {
      "epoch": 2.0639693821760523,
      "grad_norm": 26.467763900756836,
      "learning_rate": 1.793603061782395e-05,
      "loss": 0.0681,
      "step": 7550
    },
    {
      "epoch": 2.0667031164570804,
      "grad_norm": 4.147358417510986,
      "learning_rate": 1.7933296883542922e-05,
      "loss": 0.0592,
      "step": 7560
    },
    {
      "epoch": 2.0694368507381085,
      "grad_norm": 0.01532335951924324,
      "learning_rate": 1.7930563149261892e-05,
      "loss": 0.0066,
      "step": 7570
    },
    {
      "epoch": 2.072170585019136,
      "grad_norm": 0.024363592267036438,
      "learning_rate": 1.7927829414980866e-05,
      "loss": 0.0398,
      "step": 7580
    },
    {
      "epoch": 2.074904319300164,
      "grad_norm": 2.6668479442596436,
      "learning_rate": 1.792509568069984e-05,
      "loss": 0.0154,
      "step": 7590
    },
    {
      "epoch": 2.077638053581192,
      "grad_norm": 15.035091400146484,
      "learning_rate": 1.792236194641881e-05,
      "loss": 0.086,
      "step": 7600
    },
    {
      "epoch": 2.08037178786222,
      "grad_norm": 0.42736193537712097,
      "learning_rate": 1.7919628212137782e-05,
      "loss": 0.0479,
      "step": 7610
    },
    {
      "epoch": 2.0831055221432475,
      "grad_norm": 0.03732015937566757,
      "learning_rate": 1.7916894477856756e-05,
      "loss": 0.0549,
      "step": 7620
    },
    {
      "epoch": 2.0858392564242756,
      "grad_norm": 2.0208334922790527,
      "learning_rate": 1.7914160743575726e-05,
      "loss": 0.0232,
      "step": 7630
    },
    {
      "epoch": 2.0885729907053037,
      "grad_norm": 2.648515462875366,
      "learning_rate": 1.79114270092947e-05,
      "loss": 0.0411,
      "step": 7640
    },
    {
      "epoch": 2.0913067249863313,
      "grad_norm": 0.022506335750222206,
      "learning_rate": 1.7908693275013672e-05,
      "loss": 0.0663,
      "step": 7650
    },
    {
      "epoch": 2.0940404592673594,
      "grad_norm": 0.06309522688388824,
      "learning_rate": 1.7905959540732642e-05,
      "loss": 0.039,
      "step": 7660
    },
    {
      "epoch": 2.096774193548387,
      "grad_norm": 8.395130157470703,
      "learning_rate": 1.7903225806451612e-05,
      "loss": 0.0541,
      "step": 7670
    },
    {
      "epoch": 2.099507927829415,
      "grad_norm": 2.5711312294006348,
      "learning_rate": 1.7900492072170586e-05,
      "loss": 0.0738,
      "step": 7680
    },
    {
      "epoch": 2.1022416621104427,
      "grad_norm": 3.2304811477661133,
      "learning_rate": 1.789775833788956e-05,
      "loss": 0.0155,
      "step": 7690
    },
    {
      "epoch": 2.104975396391471,
      "grad_norm": 0.3917495310306549,
      "learning_rate": 1.789502460360853e-05,
      "loss": 0.0789,
      "step": 7700
    },
    {
      "epoch": 2.1077091306724984,
      "grad_norm": 0.15324023365974426,
      "learning_rate": 1.7892290869327502e-05,
      "loss": 0.0327,
      "step": 7710
    },
    {
      "epoch": 2.1104428649535265,
      "grad_norm": 3.343404531478882,
      "learning_rate": 1.7889557135046476e-05,
      "loss": 0.0072,
      "step": 7720
    },
    {
      "epoch": 2.1131765992345546,
      "grad_norm": 0.03685692325234413,
      "learning_rate": 1.7886823400765446e-05,
      "loss": 0.0514,
      "step": 7730
    },
    {
      "epoch": 2.115910333515582,
      "grad_norm": 0.2180313915014267,
      "learning_rate": 1.788408966648442e-05,
      "loss": 0.0529,
      "step": 7740
    },
    {
      "epoch": 2.1186440677966103,
      "grad_norm": 0.27301275730133057,
      "learning_rate": 1.788135593220339e-05,
      "loss": 0.0555,
      "step": 7750
    },
    {
      "epoch": 2.121377802077638,
      "grad_norm": 0.026275040581822395,
      "learning_rate": 1.7878622197922362e-05,
      "loss": 0.0275,
      "step": 7760
    },
    {
      "epoch": 2.124111536358666,
      "grad_norm": 15.166696548461914,
      "learning_rate": 1.7875888463641336e-05,
      "loss": 0.0922,
      "step": 7770
    },
    {
      "epoch": 2.1268452706396936,
      "grad_norm": 0.006270915735512972,
      "learning_rate": 1.7873154729360306e-05,
      "loss": 0.0177,
      "step": 7780
    },
    {
      "epoch": 2.1295790049207217,
      "grad_norm": 0.17753757536411285,
      "learning_rate": 1.787042099507928e-05,
      "loss": 0.0385,
      "step": 7790
    },
    {
      "epoch": 2.13231273920175,
      "grad_norm": 0.0697866827249527,
      "learning_rate": 1.7867687260798252e-05,
      "loss": 0.0222,
      "step": 7800
    },
    {
      "epoch": 2.1350464734827774,
      "grad_norm": 0.14384667575359344,
      "learning_rate": 1.7864953526517222e-05,
      "loss": 0.0224,
      "step": 7810
    },
    {
      "epoch": 2.1377802077638055,
      "grad_norm": 0.33890849351882935,
      "learning_rate": 1.7862219792236196e-05,
      "loss": 0.0313,
      "step": 7820
    },
    {
      "epoch": 2.140513942044833,
      "grad_norm": 18.854219436645508,
      "learning_rate": 1.785948605795517e-05,
      "loss": 0.0286,
      "step": 7830
    },
    {
      "epoch": 2.143247676325861,
      "grad_norm": 4.385248184204102,
      "learning_rate": 1.785675232367414e-05,
      "loss": 0.0422,
      "step": 7840
    },
    {
      "epoch": 2.145981410606889,
      "grad_norm": 7.95991849899292,
      "learning_rate": 1.7854018589393112e-05,
      "loss": 0.0751,
      "step": 7850
    },
    {
      "epoch": 2.148715144887917,
      "grad_norm": 0.005270435009151697,
      "learning_rate": 1.7851284855112086e-05,
      "loss": 0.0144,
      "step": 7860
    },
    {
      "epoch": 2.151448879168945,
      "grad_norm": 0.01245961431413889,
      "learning_rate": 1.7848551120831056e-05,
      "loss": 0.011,
      "step": 7870
    },
    {
      "epoch": 2.1541826134499726,
      "grad_norm": 14.700140953063965,
      "learning_rate": 1.784581738655003e-05,
      "loss": 0.0152,
      "step": 7880
    },
    {
      "epoch": 2.1569163477310007,
      "grad_norm": 0.002555836457759142,
      "learning_rate": 1.7843083652269e-05,
      "loss": 0.0511,
      "step": 7890
    },
    {
      "epoch": 2.1596500820120283,
      "grad_norm": 0.533326268196106,
      "learning_rate": 1.7840349917987972e-05,
      "loss": 0.0339,
      "step": 7900
    },
    {
      "epoch": 2.1623838162930564,
      "grad_norm": 0.060674555599689484,
      "learning_rate": 1.7837616183706946e-05,
      "loss": 0.0405,
      "step": 7910
    },
    {
      "epoch": 2.165117550574084,
      "grad_norm": 40.70930862426758,
      "learning_rate": 1.7834882449425916e-05,
      "loss": 0.0597,
      "step": 7920
    },
    {
      "epoch": 2.167851284855112,
      "grad_norm": 9.88902473449707,
      "learning_rate": 1.783214871514489e-05,
      "loss": 0.0401,
      "step": 7930
    },
    {
      "epoch": 2.1705850191361398,
      "grad_norm": 43.7512092590332,
      "learning_rate": 1.7829414980863862e-05,
      "loss": 0.0422,
      "step": 7940
    },
    {
      "epoch": 2.173318753417168,
      "grad_norm": 0.004524507559835911,
      "learning_rate": 1.7826681246582832e-05,
      "loss": 0.0302,
      "step": 7950
    },
    {
      "epoch": 2.176052487698196,
      "grad_norm": 8.867009162902832,
      "learning_rate": 1.7823947512301806e-05,
      "loss": 0.0268,
      "step": 7960
    },
    {
      "epoch": 2.1787862219792236,
      "grad_norm": 0.1281459480524063,
      "learning_rate": 1.782121377802078e-05,
      "loss": 0.044,
      "step": 7970
    },
    {
      "epoch": 2.1815199562602516,
      "grad_norm": 0.0728297159075737,
      "learning_rate": 1.781848004373975e-05,
      "loss": 0.0113,
      "step": 7980
    },
    {
      "epoch": 2.1842536905412793,
      "grad_norm": 0.020118238404393196,
      "learning_rate": 1.7815746309458722e-05,
      "loss": 0.0853,
      "step": 7990
    },
    {
      "epoch": 2.1869874248223073,
      "grad_norm": 18.41336441040039,
      "learning_rate": 1.7813012575177696e-05,
      "loss": 0.0182,
      "step": 8000
    },
    {
      "epoch": 2.189721159103335,
      "grad_norm": 0.019703486934304237,
      "learning_rate": 1.7810278840896666e-05,
      "loss": 0.0603,
      "step": 8010
    },
    {
      "epoch": 2.192454893384363,
      "grad_norm": 0.03021182306110859,
      "learning_rate": 1.780754510661564e-05,
      "loss": 0.046,
      "step": 8020
    },
    {
      "epoch": 2.1951886276653907,
      "grad_norm": 0.14155738055706024,
      "learning_rate": 1.780481137233461e-05,
      "loss": 0.0623,
      "step": 8030
    },
    {
      "epoch": 2.1979223619464188,
      "grad_norm": 0.6025945544242859,
      "learning_rate": 1.7802077638053582e-05,
      "loss": 0.0637,
      "step": 8040
    },
    {
      "epoch": 2.200656096227447,
      "grad_norm": 0.11122659593820572,
      "learning_rate": 1.7799343903772556e-05,
      "loss": 0.0103,
      "step": 8050
    },
    {
      "epoch": 2.2033898305084745,
      "grad_norm": 14.902359962463379,
      "learning_rate": 1.7796610169491526e-05,
      "loss": 0.0421,
      "step": 8060
    },
    {
      "epoch": 2.2061235647895026,
      "grad_norm": 1.0267289876937866,
      "learning_rate": 1.77938764352105e-05,
      "loss": 0.0225,
      "step": 8070
    },
    {
      "epoch": 2.20885729907053,
      "grad_norm": 0.020882654935121536,
      "learning_rate": 1.7791142700929472e-05,
      "loss": 0.0691,
      "step": 8080
    },
    {
      "epoch": 2.2115910333515583,
      "grad_norm": 5.28154182434082,
      "learning_rate": 1.7788408966648442e-05,
      "loss": 0.0595,
      "step": 8090
    },
    {
      "epoch": 2.2143247676325863,
      "grad_norm": 6.0492658615112305,
      "learning_rate": 1.7785675232367416e-05,
      "loss": 0.0468,
      "step": 8100
    },
    {
      "epoch": 2.217058501913614,
      "grad_norm": 2.0340635776519775,
      "learning_rate": 1.778294149808639e-05,
      "loss": 0.0263,
      "step": 8110
    },
    {
      "epoch": 2.219792236194642,
      "grad_norm": 0.13527175784111023,
      "learning_rate": 1.778020776380536e-05,
      "loss": 0.0654,
      "step": 8120
    },
    {
      "epoch": 2.2225259704756697,
      "grad_norm": 0.12053994089365005,
      "learning_rate": 1.7777474029524332e-05,
      "loss": 0.0047,
      "step": 8130
    },
    {
      "epoch": 2.2252597047566978,
      "grad_norm": 2.164983034133911,
      "learning_rate": 1.7774740295243306e-05,
      "loss": 0.0331,
      "step": 8140
    },
    {
      "epoch": 2.2279934390377254,
      "grad_norm": 0.1873636245727539,
      "learning_rate": 1.7772006560962276e-05,
      "loss": 0.0266,
      "step": 8150
    },
    {
      "epoch": 2.2307271733187535,
      "grad_norm": 1.423741340637207,
      "learning_rate": 1.776927282668125e-05,
      "loss": 0.0487,
      "step": 8160
    },
    {
      "epoch": 2.233460907599781,
      "grad_norm": 0.11308523267507553,
      "learning_rate": 1.7766539092400222e-05,
      "loss": 0.0518,
      "step": 8170
    },
    {
      "epoch": 2.236194641880809,
      "grad_norm": 9.320941925048828,
      "learning_rate": 1.7763805358119192e-05,
      "loss": 0.0888,
      "step": 8180
    },
    {
      "epoch": 2.2389283761618373,
      "grad_norm": 0.40719088912010193,
      "learning_rate": 1.7761071623838166e-05,
      "loss": 0.0366,
      "step": 8190
    },
    {
      "epoch": 2.241662110442865,
      "grad_norm": 0.15011435747146606,
      "learning_rate": 1.7758337889557135e-05,
      "loss": 0.0484,
      "step": 8200
    },
    {
      "epoch": 2.244395844723893,
      "grad_norm": 10.487956047058105,
      "learning_rate": 1.775560415527611e-05,
      "loss": 0.0151,
      "step": 8210
    },
    {
      "epoch": 2.2471295790049206,
      "grad_norm": 0.23275797069072723,
      "learning_rate": 1.7752870420995082e-05,
      "loss": 0.0446,
      "step": 8220
    },
    {
      "epoch": 2.2498633132859487,
      "grad_norm": 0.04634735360741615,
      "learning_rate": 1.7750136686714052e-05,
      "loss": 0.0073,
      "step": 8230
    },
    {
      "epoch": 2.2525970475669763,
      "grad_norm": 0.6273918151855469,
      "learning_rate": 1.7747402952433025e-05,
      "loss": 0.0691,
      "step": 8240
    },
    {
      "epoch": 2.2553307818480044,
      "grad_norm": 4.064212799072266,
      "learning_rate": 1.7744669218152e-05,
      "loss": 0.062,
      "step": 8250
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 5.091439247131348,
      "learning_rate": 1.774193548387097e-05,
      "loss": 0.0223,
      "step": 8260
    },
    {
      "epoch": 2.26079825041006,
      "grad_norm": 2.3768746852874756,
      "learning_rate": 1.773920174958994e-05,
      "loss": 0.0361,
      "step": 8270
    },
    {
      "epoch": 2.263531984691088,
      "grad_norm": 1.0425728559494019,
      "learning_rate": 1.7736468015308916e-05,
      "loss": 0.012,
      "step": 8280
    },
    {
      "epoch": 2.266265718972116,
      "grad_norm": 2.6548192501068115,
      "learning_rate": 1.7733734281027885e-05,
      "loss": 0.054,
      "step": 8290
    },
    {
      "epoch": 2.268999453253144,
      "grad_norm": 0.1033795028924942,
      "learning_rate": 1.7731000546746855e-05,
      "loss": 0.0825,
      "step": 8300
    },
    {
      "epoch": 2.2717331875341715,
      "grad_norm": 0.043624166399240494,
      "learning_rate": 1.7728266812465832e-05,
      "loss": 0.0231,
      "step": 8310
    },
    {
      "epoch": 2.2744669218151996,
      "grad_norm": 0.034764643758535385,
      "learning_rate": 1.7725533078184802e-05,
      "loss": 0.0018,
      "step": 8320
    },
    {
      "epoch": 2.2772006560962277,
      "grad_norm": 0.031233957037329674,
      "learning_rate": 1.7722799343903772e-05,
      "loss": 0.0682,
      "step": 8330
    },
    {
      "epoch": 2.2799343903772553,
      "grad_norm": 0.030643383041024208,
      "learning_rate": 1.7720065609622745e-05,
      "loss": 0.0669,
      "step": 8340
    },
    {
      "epoch": 2.2826681246582834,
      "grad_norm": 13.193704605102539,
      "learning_rate": 1.771733187534172e-05,
      "loss": 0.0807,
      "step": 8350
    },
    {
      "epoch": 2.285401858939311,
      "grad_norm": 2.173192024230957,
      "learning_rate": 1.771459814106069e-05,
      "loss": 0.0524,
      "step": 8360
    },
    {
      "epoch": 2.288135593220339,
      "grad_norm": 0.020933546125888824,
      "learning_rate": 1.7711864406779662e-05,
      "loss": 0.0098,
      "step": 8370
    },
    {
      "epoch": 2.2908693275013667,
      "grad_norm": 0.029329607263207436,
      "learning_rate": 1.7709130672498635e-05,
      "loss": 0.0058,
      "step": 8380
    },
    {
      "epoch": 2.293603061782395,
      "grad_norm": 2.0275495052337646,
      "learning_rate": 1.7706396938217605e-05,
      "loss": 0.075,
      "step": 8390
    },
    {
      "epoch": 2.2963367960634224,
      "grad_norm": 0.025224551558494568,
      "learning_rate": 1.770366320393658e-05,
      "loss": 0.0584,
      "step": 8400
    },
    {
      "epoch": 2.2990705303444505,
      "grad_norm": 0.19426950812339783,
      "learning_rate": 1.770092946965555e-05,
      "loss": 0.1145,
      "step": 8410
    },
    {
      "epoch": 2.3018042646254786,
      "grad_norm": 0.007435294799506664,
      "learning_rate": 1.7698195735374522e-05,
      "loss": 0.0646,
      "step": 8420
    },
    {
      "epoch": 2.3045379989065062,
      "grad_norm": 0.14084012806415558,
      "learning_rate": 1.7695462001093495e-05,
      "loss": 0.0114,
      "step": 8430
    },
    {
      "epoch": 2.3072717331875343,
      "grad_norm": 0.044299740344285965,
      "learning_rate": 1.7692728266812465e-05,
      "loss": 0.046,
      "step": 8440
    },
    {
      "epoch": 2.310005467468562,
      "grad_norm": 0.0810030996799469,
      "learning_rate": 1.768999453253144e-05,
      "loss": 0.024,
      "step": 8450
    },
    {
      "epoch": 2.31273920174959,
      "grad_norm": 10.707371711730957,
      "learning_rate": 1.7687260798250412e-05,
      "loss": 0.032,
      "step": 8460
    },
    {
      "epoch": 2.3154729360306177,
      "grad_norm": 0.015386969782412052,
      "learning_rate": 1.7684527063969382e-05,
      "loss": 0.0269,
      "step": 8470
    },
    {
      "epoch": 2.3182066703116457,
      "grad_norm": 11.145057678222656,
      "learning_rate": 1.7681793329688355e-05,
      "loss": 0.1009,
      "step": 8480
    },
    {
      "epoch": 2.3209404045926734,
      "grad_norm": 0.023502880707383156,
      "learning_rate": 1.767905959540733e-05,
      "loss": 0.0065,
      "step": 8490
    },
    {
      "epoch": 2.3236741388737014,
      "grad_norm": 2.577423334121704,
      "learning_rate": 1.76763258611263e-05,
      "loss": 0.0703,
      "step": 8500
    },
    {
      "epoch": 2.3264078731547295,
      "grad_norm": 4.672402381896973,
      "learning_rate": 1.7673592126845272e-05,
      "loss": 0.0384,
      "step": 8510
    },
    {
      "epoch": 2.329141607435757,
      "grad_norm": 0.13100408017635345,
      "learning_rate": 1.7670858392564245e-05,
      "loss": 0.0141,
      "step": 8520
    },
    {
      "epoch": 2.3318753417167852,
      "grad_norm": 6.202671051025391,
      "learning_rate": 1.7668124658283215e-05,
      "loss": 0.0091,
      "step": 8530
    },
    {
      "epoch": 2.334609075997813,
      "grad_norm": 0.017368383705615997,
      "learning_rate": 1.766539092400219e-05,
      "loss": 0.0718,
      "step": 8540
    },
    {
      "epoch": 2.337342810278841,
      "grad_norm": 90.06724548339844,
      "learning_rate": 1.766265718972116e-05,
      "loss": 0.0681,
      "step": 8550
    },
    {
      "epoch": 2.340076544559869,
      "grad_norm": 2.210207939147949,
      "learning_rate": 1.7659923455440132e-05,
      "loss": 0.0946,
      "step": 8560
    },
    {
      "epoch": 2.3428102788408967,
      "grad_norm": 46.04289627075195,
      "learning_rate": 1.7657189721159105e-05,
      "loss": 0.0272,
      "step": 8570
    },
    {
      "epoch": 2.3455440131219247,
      "grad_norm": 0.23589196801185608,
      "learning_rate": 1.7654455986878075e-05,
      "loss": 0.0487,
      "step": 8580
    },
    {
      "epoch": 2.3482777474029524,
      "grad_norm": 2.8083343505859375,
      "learning_rate": 1.765172225259705e-05,
      "loss": 0.0192,
      "step": 8590
    },
    {
      "epoch": 2.3510114816839804,
      "grad_norm": 0.4786410629749298,
      "learning_rate": 1.7648988518316022e-05,
      "loss": 0.0317,
      "step": 8600
    },
    {
      "epoch": 2.353745215965008,
      "grad_norm": 0.04747532308101654,
      "learning_rate": 1.7646254784034992e-05,
      "loss": 0.057,
      "step": 8610
    },
    {
      "epoch": 2.356478950246036,
      "grad_norm": 2.0418365001678467,
      "learning_rate": 1.7643521049753965e-05,
      "loss": 0.0354,
      "step": 8620
    },
    {
      "epoch": 2.359212684527064,
      "grad_norm": 1.0081665515899658,
      "learning_rate": 1.764078731547294e-05,
      "loss": 0.0142,
      "step": 8630
    },
    {
      "epoch": 2.361946418808092,
      "grad_norm": 0.011606128886342049,
      "learning_rate": 1.763805358119191e-05,
      "loss": 0.0253,
      "step": 8640
    },
    {
      "epoch": 2.36468015308912,
      "grad_norm": 2.9073100090026855,
      "learning_rate": 1.7635319846910882e-05,
      "loss": 0.1068,
      "step": 8650
    },
    {
      "epoch": 2.3674138873701476,
      "grad_norm": 0.09876719117164612,
      "learning_rate": 1.7632586112629855e-05,
      "loss": 0.0516,
      "step": 8660
    },
    {
      "epoch": 2.3701476216511757,
      "grad_norm": 5.695230484008789,
      "learning_rate": 1.7629852378348825e-05,
      "loss": 0.0532,
      "step": 8670
    },
    {
      "epoch": 2.3728813559322033,
      "grad_norm": 0.08825264126062393,
      "learning_rate": 1.76271186440678e-05,
      "loss": 0.0433,
      "step": 8680
    },
    {
      "epoch": 2.3756150902132314,
      "grad_norm": 0.08841133862733841,
      "learning_rate": 1.762438490978677e-05,
      "loss": 0.092,
      "step": 8690
    },
    {
      "epoch": 2.378348824494259,
      "grad_norm": 0.08372481167316437,
      "learning_rate": 1.7621651175505742e-05,
      "loss": 0.0335,
      "step": 8700
    },
    {
      "epoch": 2.381082558775287,
      "grad_norm": 0.14622192084789276,
      "learning_rate": 1.7618917441224715e-05,
      "loss": 0.0494,
      "step": 8710
    },
    {
      "epoch": 2.3838162930563147,
      "grad_norm": 0.20899967849254608,
      "learning_rate": 1.7616183706943685e-05,
      "loss": 0.0508,
      "step": 8720
    },
    {
      "epoch": 2.386550027337343,
      "grad_norm": 0.1126970425248146,
      "learning_rate": 1.761344997266266e-05,
      "loss": 0.0387,
      "step": 8730
    },
    {
      "epoch": 2.389283761618371,
      "grad_norm": 3.803647518157959,
      "learning_rate": 1.7610716238381632e-05,
      "loss": 0.0597,
      "step": 8740
    },
    {
      "epoch": 2.3920174958993985,
      "grad_norm": 0.03633410856127739,
      "learning_rate": 1.7607982504100602e-05,
      "loss": 0.064,
      "step": 8750
    },
    {
      "epoch": 2.3947512301804266,
      "grad_norm": 10.532319068908691,
      "learning_rate": 1.7605248769819575e-05,
      "loss": 0.0701,
      "step": 8760
    },
    {
      "epoch": 2.397484964461454,
      "grad_norm": 0.7527461647987366,
      "learning_rate": 1.760251503553855e-05,
      "loss": 0.0204,
      "step": 8770
    },
    {
      "epoch": 2.4002186987424823,
      "grad_norm": 0.07276706397533417,
      "learning_rate": 1.759978130125752e-05,
      "loss": 0.0038,
      "step": 8780
    },
    {
      "epoch": 2.4029524330235104,
      "grad_norm": 5.533208847045898,
      "learning_rate": 1.7597047566976492e-05,
      "loss": 0.0847,
      "step": 8790
    },
    {
      "epoch": 2.405686167304538,
      "grad_norm": 0.0138724809512496,
      "learning_rate": 1.7594313832695465e-05,
      "loss": 0.0139,
      "step": 8800
    },
    {
      "epoch": 2.408419901585566,
      "grad_norm": 2.582689046859741,
      "learning_rate": 1.7591580098414435e-05,
      "loss": 0.0163,
      "step": 8810
    },
    {
      "epoch": 2.4111536358665937,
      "grad_norm": 0.03963158652186394,
      "learning_rate": 1.758884636413341e-05,
      "loss": 0.0126,
      "step": 8820
    },
    {
      "epoch": 2.413887370147622,
      "grad_norm": 0.022452307865023613,
      "learning_rate": 1.758611262985238e-05,
      "loss": 0.024,
      "step": 8830
    },
    {
      "epoch": 2.4166211044286494,
      "grad_norm": 5.949535846710205,
      "learning_rate": 1.7583378895571352e-05,
      "loss": 0.0623,
      "step": 8840
    },
    {
      "epoch": 2.4193548387096775,
      "grad_norm": 0.6473085880279541,
      "learning_rate": 1.7580645161290325e-05,
      "loss": 0.0461,
      "step": 8850
    },
    {
      "epoch": 2.422088572990705,
      "grad_norm": 0.029021667316555977,
      "learning_rate": 1.7577911427009295e-05,
      "loss": 0.0105,
      "step": 8860
    },
    {
      "epoch": 2.424822307271733,
      "grad_norm": 0.01794174127280712,
      "learning_rate": 1.757517769272827e-05,
      "loss": 0.0314,
      "step": 8870
    },
    {
      "epoch": 2.4275560415527613,
      "grad_norm": 0.023380305618047714,
      "learning_rate": 1.7572443958447242e-05,
      "loss": 0.0214,
      "step": 8880
    },
    {
      "epoch": 2.430289775833789,
      "grad_norm": 1.87533438205719,
      "learning_rate": 1.7569710224166212e-05,
      "loss": 0.0619,
      "step": 8890
    },
    {
      "epoch": 2.433023510114817,
      "grad_norm": 3.928462266921997,
      "learning_rate": 1.7566976489885182e-05,
      "loss": 0.0711,
      "step": 8900
    },
    {
      "epoch": 2.4357572443958446,
      "grad_norm": 1.6305850744247437,
      "learning_rate": 1.756424275560416e-05,
      "loss": 0.0434,
      "step": 8910
    },
    {
      "epoch": 2.4384909786768727,
      "grad_norm": 7.977596282958984,
      "learning_rate": 1.756150902132313e-05,
      "loss": 0.0389,
      "step": 8920
    },
    {
      "epoch": 2.4412247129579003,
      "grad_norm": 7.1836957931518555,
      "learning_rate": 1.75587752870421e-05,
      "loss": 0.0192,
      "step": 8930
    },
    {
      "epoch": 2.4439584472389284,
      "grad_norm": 0.005109645891934633,
      "learning_rate": 1.7556041552761075e-05,
      "loss": 0.0369,
      "step": 8940
    },
    {
      "epoch": 2.446692181519956,
      "grad_norm": 0.024478154256939888,
      "learning_rate": 1.7553307818480045e-05,
      "loss": 0.0504,
      "step": 8950
    },
    {
      "epoch": 2.449425915800984,
      "grad_norm": 0.1398463249206543,
      "learning_rate": 1.7550574084199015e-05,
      "loss": 0.0125,
      "step": 8960
    },
    {
      "epoch": 2.452159650082012,
      "grad_norm": 0.05958353728055954,
      "learning_rate": 1.754784034991799e-05,
      "loss": 0.0603,
      "step": 8970
    },
    {
      "epoch": 2.45489338436304,
      "grad_norm": 0.9993892312049866,
      "learning_rate": 1.7545106615636962e-05,
      "loss": 0.0208,
      "step": 8980
    },
    {
      "epoch": 2.457627118644068,
      "grad_norm": 8.509848594665527,
      "learning_rate": 1.7542372881355932e-05,
      "loss": 0.0342,
      "step": 8990
    },
    {
      "epoch": 2.4603608529250955,
      "grad_norm": 2.1102800369262695,
      "learning_rate": 1.7539639147074905e-05,
      "loss": 0.0476,
      "step": 9000
    },
    {
      "epoch": 2.4630945872061236,
      "grad_norm": 0.0513356477022171,
      "learning_rate": 1.753690541279388e-05,
      "loss": 0.0473,
      "step": 9010
    },
    {
      "epoch": 2.4658283214871517,
      "grad_norm": 2.8083858489990234,
      "learning_rate": 1.753417167851285e-05,
      "loss": 0.0736,
      "step": 9020
    },
    {
      "epoch": 2.4685620557681793,
      "grad_norm": 3.539140224456787,
      "learning_rate": 1.7531437944231822e-05,
      "loss": 0.0363,
      "step": 9030
    },
    {
      "epoch": 2.4712957900492074,
      "grad_norm": 0.1646401584148407,
      "learning_rate": 1.7528704209950792e-05,
      "loss": 0.0277,
      "step": 9040
    },
    {
      "epoch": 2.474029524330235,
      "grad_norm": 2.5830180644989014,
      "learning_rate": 1.7525970475669765e-05,
      "loss": 0.0037,
      "step": 9050
    },
    {
      "epoch": 2.476763258611263,
      "grad_norm": 0.016585130244493484,
      "learning_rate": 1.752323674138874e-05,
      "loss": 0.0134,
      "step": 9060
    },
    {
      "epoch": 2.4794969928922908,
      "grad_norm": 7.500126838684082,
      "learning_rate": 1.752050300710771e-05,
      "loss": 0.0581,
      "step": 9070
    },
    {
      "epoch": 2.482230727173319,
      "grad_norm": 0.009857048280537128,
      "learning_rate": 1.7517769272826682e-05,
      "loss": 0.009,
      "step": 9080
    },
    {
      "epoch": 2.4849644614543465,
      "grad_norm": 0.26779329776763916,
      "learning_rate": 1.7515035538545655e-05,
      "loss": 0.0716,
      "step": 9090
    },
    {
      "epoch": 2.4876981957353745,
      "grad_norm": 0.024208251386880875,
      "learning_rate": 1.7512301804264625e-05,
      "loss": 0.031,
      "step": 9100
    },
    {
      "epoch": 2.4904319300164026,
      "grad_norm": 5.064222812652588,
      "learning_rate": 1.75095680699836e-05,
      "loss": 0.0458,
      "step": 9110
    },
    {
      "epoch": 2.4931656642974303,
      "grad_norm": 0.06112033128738403,
      "learning_rate": 1.7506834335702572e-05,
      "loss": 0.0289,
      "step": 9120
    },
    {
      "epoch": 2.4958993985784583,
      "grad_norm": 3.36897873878479,
      "learning_rate": 1.7504100601421542e-05,
      "loss": 0.0152,
      "step": 9130
    },
    {
      "epoch": 2.498633132859486,
      "grad_norm": 16.990291595458984,
      "learning_rate": 1.7501366867140515e-05,
      "loss": 0.0294,
      "step": 9140
    },
    {
      "epoch": 2.501366867140514,
      "grad_norm": 0.05847995728254318,
      "learning_rate": 1.749863313285949e-05,
      "loss": 0.016,
      "step": 9150
    },
    {
      "epoch": 2.5041006014215417,
      "grad_norm": 0.425147145986557,
      "learning_rate": 1.749589939857846e-05,
      "loss": 0.0606,
      "step": 9160
    },
    {
      "epoch": 2.5068343357025697,
      "grad_norm": 0.04617096856236458,
      "learning_rate": 1.7493165664297432e-05,
      "loss": 0.0676,
      "step": 9170
    },
    {
      "epoch": 2.5095680699835974,
      "grad_norm": 5.824822902679443,
      "learning_rate": 1.7490431930016405e-05,
      "loss": 0.0459,
      "step": 9180
    },
    {
      "epoch": 2.5123018042646255,
      "grad_norm": 1.1611449718475342,
      "learning_rate": 1.7487698195735375e-05,
      "loss": 0.1225,
      "step": 9190
    },
    {
      "epoch": 2.5150355385456535,
      "grad_norm": 0.31131717562675476,
      "learning_rate": 1.748496446145435e-05,
      "loss": 0.0546,
      "step": 9200
    },
    {
      "epoch": 2.517769272826681,
      "grad_norm": 40.79819869995117,
      "learning_rate": 1.748223072717332e-05,
      "loss": 0.0424,
      "step": 9210
    },
    {
      "epoch": 2.5205030071077092,
      "grad_norm": 0.36185160279273987,
      "learning_rate": 1.7479496992892292e-05,
      "loss": 0.062,
      "step": 9220
    },
    {
      "epoch": 2.523236741388737,
      "grad_norm": 0.037755828350782394,
      "learning_rate": 1.7476763258611265e-05,
      "loss": 0.1102,
      "step": 9230
    },
    {
      "epoch": 2.525970475669765,
      "grad_norm": 5.132978916168213,
      "learning_rate": 1.7474029524330235e-05,
      "loss": 0.0265,
      "step": 9240
    },
    {
      "epoch": 2.528704209950793,
      "grad_norm": 0.2133350521326065,
      "learning_rate": 1.747129579004921e-05,
      "loss": 0.02,
      "step": 9250
    },
    {
      "epoch": 2.5314379442318207,
      "grad_norm": 1.6558188199996948,
      "learning_rate": 1.7468562055768182e-05,
      "loss": 0.04,
      "step": 9260
    },
    {
      "epoch": 2.5341716785128483,
      "grad_norm": 0.019510526210069656,
      "learning_rate": 1.7465828321487152e-05,
      "loss": 0.0714,
      "step": 9270
    },
    {
      "epoch": 2.5369054127938764,
      "grad_norm": 0.011955242604017258,
      "learning_rate": 1.7463094587206125e-05,
      "loss": 0.064,
      "step": 9280
    },
    {
      "epoch": 2.5396391470749045,
      "grad_norm": 0.018486781045794487,
      "learning_rate": 1.74603608529251e-05,
      "loss": 0.0055,
      "step": 9290
    },
    {
      "epoch": 2.542372881355932,
      "grad_norm": 1.5019350051879883,
      "learning_rate": 1.745762711864407e-05,
      "loss": 0.0598,
      "step": 9300
    },
    {
      "epoch": 2.54510661563696,
      "grad_norm": 0.020346172153949738,
      "learning_rate": 1.7454893384363042e-05,
      "loss": 0.0801,
      "step": 9310
    },
    {
      "epoch": 2.547840349917988,
      "grad_norm": 12.089091300964355,
      "learning_rate": 1.7452159650082015e-05,
      "loss": 0.0307,
      "step": 9320
    },
    {
      "epoch": 2.550574084199016,
      "grad_norm": 22.70539665222168,
      "learning_rate": 1.7449425915800985e-05,
      "loss": 0.0792,
      "step": 9330
    },
    {
      "epoch": 2.553307818480044,
      "grad_norm": 7.827919006347656,
      "learning_rate": 1.744669218151996e-05,
      "loss": 0.0356,
      "step": 9340
    },
    {
      "epoch": 2.5560415527610716,
      "grad_norm": 0.07668472826480865,
      "learning_rate": 1.744395844723893e-05,
      "loss": 0.0703,
      "step": 9350
    },
    {
      "epoch": 2.5587752870420997,
      "grad_norm": 5.819796562194824,
      "learning_rate": 1.7441224712957902e-05,
      "loss": 0.0648,
      "step": 9360
    },
    {
      "epoch": 2.5615090213231273,
      "grad_norm": 1.3963903188705444,
      "learning_rate": 1.7438490978676875e-05,
      "loss": 0.051,
      "step": 9370
    },
    {
      "epoch": 2.5642427556041554,
      "grad_norm": 0.02738802880048752,
      "learning_rate": 1.7435757244395845e-05,
      "loss": 0.0427,
      "step": 9380
    },
    {
      "epoch": 2.566976489885183,
      "grad_norm": 0.077267125248909,
      "learning_rate": 1.743302351011482e-05,
      "loss": 0.1734,
      "step": 9390
    },
    {
      "epoch": 2.569710224166211,
      "grad_norm": 3.9197089672088623,
      "learning_rate": 1.7430289775833792e-05,
      "loss": 0.0469,
      "step": 9400
    },
    {
      "epoch": 2.5724439584472387,
      "grad_norm": 4.3341779708862305,
      "learning_rate": 1.7427556041552762e-05,
      "loss": 0.0607,
      "step": 9410
    },
    {
      "epoch": 2.575177692728267,
      "grad_norm": 6.058370113372803,
      "learning_rate": 1.7424822307271735e-05,
      "loss": 0.0387,
      "step": 9420
    },
    {
      "epoch": 2.577911427009295,
      "grad_norm": 1.6666969060897827,
      "learning_rate": 1.742208857299071e-05,
      "loss": 0.0073,
      "step": 9430
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 22.54921531677246,
      "learning_rate": 1.741935483870968e-05,
      "loss": 0.0357,
      "step": 9440
    },
    {
      "epoch": 2.5833788955713506,
      "grad_norm": 3.2769339084625244,
      "learning_rate": 1.7416621104428652e-05,
      "loss": 0.0575,
      "step": 9450
    },
    {
      "epoch": 2.586112629852378,
      "grad_norm": 0.0419439934194088,
      "learning_rate": 1.7413887370147625e-05,
      "loss": 0.0225,
      "step": 9460
    },
    {
      "epoch": 2.5888463641334063,
      "grad_norm": 0.22664009034633636,
      "learning_rate": 1.7411153635866595e-05,
      "loss": 0.0403,
      "step": 9470
    },
    {
      "epoch": 2.5915800984144344,
      "grad_norm": 0.04143054038286209,
      "learning_rate": 1.740841990158557e-05,
      "loss": 0.0325,
      "step": 9480
    },
    {
      "epoch": 2.594313832695462,
      "grad_norm": 0.41771480441093445,
      "learning_rate": 1.740568616730454e-05,
      "loss": 0.0403,
      "step": 9490
    },
    {
      "epoch": 2.5970475669764896,
      "grad_norm": 0.370386004447937,
      "learning_rate": 1.7402952433023512e-05,
      "loss": 0.0115,
      "step": 9500
    },
    {
      "epoch": 2.5997813012575177,
      "grad_norm": 0.10989633947610855,
      "learning_rate": 1.7400218698742485e-05,
      "loss": 0.032,
      "step": 9510
    },
    {
      "epoch": 2.602515035538546,
      "grad_norm": 0.050188418477773666,
      "learning_rate": 1.7397484964461455e-05,
      "loss": 0.0986,
      "step": 9520
    },
    {
      "epoch": 2.6052487698195734,
      "grad_norm": 0.196813702583313,
      "learning_rate": 1.739475123018043e-05,
      "loss": 0.039,
      "step": 9530
    },
    {
      "epoch": 2.6079825041006015,
      "grad_norm": 4.652904987335205,
      "learning_rate": 1.7392017495899402e-05,
      "loss": 0.0391,
      "step": 9540
    },
    {
      "epoch": 2.610716238381629,
      "grad_norm": 2.7630300521850586,
      "learning_rate": 1.7389283761618372e-05,
      "loss": 0.0314,
      "step": 9550
    },
    {
      "epoch": 2.613449972662657,
      "grad_norm": 5.936429500579834,
      "learning_rate": 1.738655002733734e-05,
      "loss": 0.0225,
      "step": 9560
    },
    {
      "epoch": 2.6161837069436853,
      "grad_norm": 6.972879409790039,
      "learning_rate": 1.738381629305632e-05,
      "loss": 0.0185,
      "step": 9570
    },
    {
      "epoch": 2.618917441224713,
      "grad_norm": 0.016345586627721786,
      "learning_rate": 1.738108255877529e-05,
      "loss": 0.0879,
      "step": 9580
    },
    {
      "epoch": 2.621651175505741,
      "grad_norm": 0.5117426514625549,
      "learning_rate": 1.737834882449426e-05,
      "loss": 0.0589,
      "step": 9590
    },
    {
      "epoch": 2.6243849097867686,
      "grad_norm": 0.008793143555521965,
      "learning_rate": 1.7375615090213235e-05,
      "loss": 0.0657,
      "step": 9600
    },
    {
      "epoch": 2.6271186440677967,
      "grad_norm": 0.041936080902814865,
      "learning_rate": 1.7372881355932205e-05,
      "loss": 0.0435,
      "step": 9610
    },
    {
      "epoch": 2.6298523783488243,
      "grad_norm": 0.2864764928817749,
      "learning_rate": 1.7370147621651175e-05,
      "loss": 0.0051,
      "step": 9620
    },
    {
      "epoch": 2.6325861126298524,
      "grad_norm": 0.5150178670883179,
      "learning_rate": 1.736741388737015e-05,
      "loss": 0.0296,
      "step": 9630
    },
    {
      "epoch": 2.63531984691088,
      "grad_norm": 1.835866928100586,
      "learning_rate": 1.736468015308912e-05,
      "loss": 0.0227,
      "step": 9640
    },
    {
      "epoch": 2.638053581191908,
      "grad_norm": 0.013982266187667847,
      "learning_rate": 1.736194641880809e-05,
      "loss": 0.0081,
      "step": 9650
    },
    {
      "epoch": 2.640787315472936,
      "grad_norm": 1.5509051084518433,
      "learning_rate": 1.7359212684527065e-05,
      "loss": 0.0478,
      "step": 9660
    },
    {
      "epoch": 2.643521049753964,
      "grad_norm": 0.012581145390868187,
      "learning_rate": 1.735647895024604e-05,
      "loss": 0.064,
      "step": 9670
    },
    {
      "epoch": 2.646254784034992,
      "grad_norm": 0.085825115442276,
      "learning_rate": 1.735374521596501e-05,
      "loss": 0.0325,
      "step": 9680
    },
    {
      "epoch": 2.6489885183160196,
      "grad_norm": 0.47462576627731323,
      "learning_rate": 1.735101148168398e-05,
      "loss": 0.039,
      "step": 9690
    },
    {
      "epoch": 2.6517222525970476,
      "grad_norm": 0.005853924434632063,
      "learning_rate": 1.734827774740295e-05,
      "loss": 0.07,
      "step": 9700
    },
    {
      "epoch": 2.6544559868780757,
      "grad_norm": 2.2057971954345703,
      "learning_rate": 1.7345544013121925e-05,
      "loss": 0.0714,
      "step": 9710
    },
    {
      "epoch": 2.6571897211591033,
      "grad_norm": 0.1106729656457901,
      "learning_rate": 1.73428102788409e-05,
      "loss": 0.049,
      "step": 9720
    },
    {
      "epoch": 2.659923455440131,
      "grad_norm": 3.2816996574401855,
      "learning_rate": 1.7340076544559868e-05,
      "loss": 0.0711,
      "step": 9730
    },
    {
      "epoch": 2.662657189721159,
      "grad_norm": 0.016624657437205315,
      "learning_rate": 1.733734281027884e-05,
      "loss": 0.0132,
      "step": 9740
    },
    {
      "epoch": 2.665390924002187,
      "grad_norm": 2.601006269454956,
      "learning_rate": 1.7334609075997815e-05,
      "loss": 0.0991,
      "step": 9750
    },
    {
      "epoch": 2.6681246582832148,
      "grad_norm": 3.1232194900512695,
      "learning_rate": 1.7331875341716785e-05,
      "loss": 0.0397,
      "step": 9760
    },
    {
      "epoch": 2.670858392564243,
      "grad_norm": 0.13987649977207184,
      "learning_rate": 1.7329141607435758e-05,
      "loss": 0.0593,
      "step": 9770
    },
    {
      "epoch": 2.6735921268452705,
      "grad_norm": 0.1686001867055893,
      "learning_rate": 1.732640787315473e-05,
      "loss": 0.0129,
      "step": 9780
    },
    {
      "epoch": 2.6763258611262986,
      "grad_norm": 0.11094051599502563,
      "learning_rate": 1.73236741388737e-05,
      "loss": 0.0154,
      "step": 9790
    },
    {
      "epoch": 2.6790595954073266,
      "grad_norm": 0.25901156663894653,
      "learning_rate": 1.7320940404592675e-05,
      "loss": 0.0224,
      "step": 9800
    },
    {
      "epoch": 2.6817933296883543,
      "grad_norm": 0.0029859403148293495,
      "learning_rate": 1.731820667031165e-05,
      "loss": 0.0165,
      "step": 9810
    },
    {
      "epoch": 2.684527063969382,
      "grad_norm": 0.02073746733367443,
      "learning_rate": 1.7315472936030618e-05,
      "loss": 0.0522,
      "step": 9820
    },
    {
      "epoch": 2.68726079825041,
      "grad_norm": 0.11985357105731964,
      "learning_rate": 1.731273920174959e-05,
      "loss": 0.0702,
      "step": 9830
    },
    {
      "epoch": 2.689994532531438,
      "grad_norm": 4.722657680511475,
      "learning_rate": 1.731000546746856e-05,
      "loss": 0.0835,
      "step": 9840
    },
    {
      "epoch": 2.6927282668124657,
      "grad_norm": 0.054290223866701126,
      "learning_rate": 1.7307271733187535e-05,
      "loss": 0.0578,
      "step": 9850
    },
    {
      "epoch": 2.6954620010934938,
      "grad_norm": 0.25756990909576416,
      "learning_rate": 1.7304537998906508e-05,
      "loss": 0.0361,
      "step": 9860
    },
    {
      "epoch": 2.6981957353745214,
      "grad_norm": 7.691431999206543,
      "learning_rate": 1.7301804264625478e-05,
      "loss": 0.0214,
      "step": 9870
    },
    {
      "epoch": 2.7009294696555495,
      "grad_norm": 0.5570029020309448,
      "learning_rate": 1.729907053034445e-05,
      "loss": 0.0465,
      "step": 9880
    },
    {
      "epoch": 2.7036632039365776,
      "grad_norm": 2.559584379196167,
      "learning_rate": 1.7296336796063425e-05,
      "loss": 0.0587,
      "step": 9890
    },
    {
      "epoch": 2.706396938217605,
      "grad_norm": 0.11967405676841736,
      "learning_rate": 1.7293603061782395e-05,
      "loss": 0.0746,
      "step": 9900
    },
    {
      "epoch": 2.7091306724986333,
      "grad_norm": 0.09542639553546906,
      "learning_rate": 1.7290869327501368e-05,
      "loss": 0.095,
      "step": 9910
    },
    {
      "epoch": 2.711864406779661,
      "grad_norm": 0.03918034955859184,
      "learning_rate": 1.728813559322034e-05,
      "loss": 0.0227,
      "step": 9920
    },
    {
      "epoch": 2.714598141060689,
      "grad_norm": 4.919156074523926,
      "learning_rate": 1.728540185893931e-05,
      "loss": 0.0707,
      "step": 9930
    },
    {
      "epoch": 2.717331875341717,
      "grad_norm": 2.891521453857422,
      "learning_rate": 1.7282668124658285e-05,
      "loss": 0.0126,
      "step": 9940
    },
    {
      "epoch": 2.7200656096227447,
      "grad_norm": 0.04018304497003555,
      "learning_rate": 1.7279934390377258e-05,
      "loss": 0.0886,
      "step": 9950
    },
    {
      "epoch": 2.7227993439037723,
      "grad_norm": 0.41645264625549316,
      "learning_rate": 1.7277200656096228e-05,
      "loss": 0.0184,
      "step": 9960
    },
    {
      "epoch": 2.7255330781848004,
      "grad_norm": 0.022725045680999756,
      "learning_rate": 1.72744669218152e-05,
      "loss": 0.1071,
      "step": 9970
    },
    {
      "epoch": 2.7282668124658285,
      "grad_norm": 2.4450972080230713,
      "learning_rate": 1.727173318753417e-05,
      "loss": 0.0324,
      "step": 9980
    },
    {
      "epoch": 2.731000546746856,
      "grad_norm": 0.020654592663049698,
      "learning_rate": 1.7268999453253145e-05,
      "loss": 0.0391,
      "step": 9990
    },
    {
      "epoch": 2.733734281027884,
      "grad_norm": 16.2795352935791,
      "learning_rate": 1.7266265718972118e-05,
      "loss": 0.0229,
      "step": 10000
    },
    {
      "epoch": 2.736468015308912,
      "grad_norm": 7.340780258178711,
      "learning_rate": 1.7263531984691088e-05,
      "loss": 0.0307,
      "step": 10010
    },
    {
      "epoch": 2.73920174958994,
      "grad_norm": 0.004671690985560417,
      "learning_rate": 1.726079825041006e-05,
      "loss": 0.004,
      "step": 10020
    },
    {
      "epoch": 2.741935483870968,
      "grad_norm": 0.03737695515155792,
      "learning_rate": 1.7258064516129035e-05,
      "loss": 0.0596,
      "step": 10030
    },
    {
      "epoch": 2.7446692181519956,
      "grad_norm": 0.09773280471563339,
      "learning_rate": 1.7255330781848005e-05,
      "loss": 0.1335,
      "step": 10040
    },
    {
      "epoch": 2.7474029524330232,
      "grad_norm": 1.5617003440856934,
      "learning_rate": 1.7252597047566978e-05,
      "loss": 0.0213,
      "step": 10050
    },
    {
      "epoch": 2.7501366867140513,
      "grad_norm": 4.745231628417969,
      "learning_rate": 1.724986331328595e-05,
      "loss": 0.0408,
      "step": 10060
    },
    {
      "epoch": 2.7528704209950794,
      "grad_norm": 16.03300666809082,
      "learning_rate": 1.724712957900492e-05,
      "loss": 0.0388,
      "step": 10070
    },
    {
      "epoch": 2.755604155276107,
      "grad_norm": 9.115933418273926,
      "learning_rate": 1.7244395844723895e-05,
      "loss": 0.0184,
      "step": 10080
    },
    {
      "epoch": 2.758337889557135,
      "grad_norm": 0.01977217011153698,
      "learning_rate": 1.7241662110442868e-05,
      "loss": 0.0056,
      "step": 10090
    },
    {
      "epoch": 2.7610716238381627,
      "grad_norm": 0.3074509799480438,
      "learning_rate": 1.7238928376161838e-05,
      "loss": 0.0655,
      "step": 10100
    },
    {
      "epoch": 2.763805358119191,
      "grad_norm": 3.471738815307617,
      "learning_rate": 1.723619464188081e-05,
      "loss": 0.0251,
      "step": 10110
    },
    {
      "epoch": 2.766539092400219,
      "grad_norm": 5.266933917999268,
      "learning_rate": 1.723346090759978e-05,
      "loss": 0.0758,
      "step": 10120
    },
    {
      "epoch": 2.7692728266812465,
      "grad_norm": 11.394932746887207,
      "learning_rate": 1.7230727173318755e-05,
      "loss": 0.0351,
      "step": 10130
    },
    {
      "epoch": 2.7720065609622746,
      "grad_norm": 0.10521207749843597,
      "learning_rate": 1.7227993439037728e-05,
      "loss": 0.0411,
      "step": 10140
    },
    {
      "epoch": 2.7747402952433022,
      "grad_norm": 0.14189599454402924,
      "learning_rate": 1.7225259704756698e-05,
      "loss": 0.0276,
      "step": 10150
    },
    {
      "epoch": 2.7774740295243303,
      "grad_norm": 8.756546020507812,
      "learning_rate": 1.722252597047567e-05,
      "loss": 0.0669,
      "step": 10160
    },
    {
      "epoch": 2.7802077638053584,
      "grad_norm": 0.028905972838401794,
      "learning_rate": 1.7219792236194645e-05,
      "loss": 0.0271,
      "step": 10170
    },
    {
      "epoch": 2.782941498086386,
      "grad_norm": 38.32137680053711,
      "learning_rate": 1.7217058501913615e-05,
      "loss": 0.0965,
      "step": 10180
    },
    {
      "epoch": 2.7856752323674137,
      "grad_norm": 0.17870721220970154,
      "learning_rate": 1.7214324767632585e-05,
      "loss": 0.0272,
      "step": 10190
    },
    {
      "epoch": 2.7884089666484417,
      "grad_norm": 4.612064361572266,
      "learning_rate": 1.721159103335156e-05,
      "loss": 0.0467,
      "step": 10200
    },
    {
      "epoch": 2.79114270092947,
      "grad_norm": 3.961581230163574,
      "learning_rate": 1.720885729907053e-05,
      "loss": 0.1141,
      "step": 10210
    },
    {
      "epoch": 2.7938764352104974,
      "grad_norm": 0.08620737493038177,
      "learning_rate": 1.72061235647895e-05,
      "loss": 0.0669,
      "step": 10220
    },
    {
      "epoch": 2.7966101694915255,
      "grad_norm": 0.7193191647529602,
      "learning_rate": 1.7203389830508478e-05,
      "loss": 0.0388,
      "step": 10230
    },
    {
      "epoch": 2.799343903772553,
      "grad_norm": 0.2864244282245636,
      "learning_rate": 1.7200656096227448e-05,
      "loss": 0.01,
      "step": 10240
    },
    {
      "epoch": 2.8020776380535812,
      "grad_norm": 0.027413643896579742,
      "learning_rate": 1.7197922361946418e-05,
      "loss": 0.0298,
      "step": 10250
    },
    {
      "epoch": 2.8048113723346093,
      "grad_norm": 6.921449661254883,
      "learning_rate": 1.7195188627665395e-05,
      "loss": 0.0297,
      "step": 10260
    },
    {
      "epoch": 2.807545106615637,
      "grad_norm": 0.0021943734027445316,
      "learning_rate": 1.7192454893384365e-05,
      "loss": 0.0258,
      "step": 10270
    },
    {
      "epoch": 2.8102788408966646,
      "grad_norm": 15.514073371887207,
      "learning_rate": 1.7189721159103335e-05,
      "loss": 0.1031,
      "step": 10280
    },
    {
      "epoch": 2.8130125751776927,
      "grad_norm": 0.17643874883651733,
      "learning_rate": 1.7186987424822308e-05,
      "loss": 0.0566,
      "step": 10290
    },
    {
      "epoch": 2.8157463094587207,
      "grad_norm": 0.2518841624259949,
      "learning_rate": 1.718425369054128e-05,
      "loss": 0.0066,
      "step": 10300
    },
    {
      "epoch": 2.8184800437397484,
      "grad_norm": 0.12260831892490387,
      "learning_rate": 1.718151995626025e-05,
      "loss": 0.0016,
      "step": 10310
    },
    {
      "epoch": 2.8212137780207764,
      "grad_norm": 0.027535511180758476,
      "learning_rate": 1.7178786221979225e-05,
      "loss": 0.0259,
      "step": 10320
    },
    {
      "epoch": 2.823947512301804,
      "grad_norm": 1.4232248067855835,
      "learning_rate": 1.7176052487698198e-05,
      "loss": 0.0606,
      "step": 10330
    },
    {
      "epoch": 2.826681246582832,
      "grad_norm": 0.04302801191806793,
      "learning_rate": 1.7173318753417168e-05,
      "loss": 0.0227,
      "step": 10340
    },
    {
      "epoch": 2.8294149808638602,
      "grad_norm": 0.07174398005008698,
      "learning_rate": 1.717058501913614e-05,
      "loss": 0.0192,
      "step": 10350
    },
    {
      "epoch": 2.832148715144888,
      "grad_norm": 0.027044769376516342,
      "learning_rate": 1.716785128485511e-05,
      "loss": 0.0699,
      "step": 10360
    },
    {
      "epoch": 2.834882449425916,
      "grad_norm": 4.036646842956543,
      "learning_rate": 1.7165117550574085e-05,
      "loss": 0.0355,
      "step": 10370
    },
    {
      "epoch": 2.8376161837069436,
      "grad_norm": 17.92243003845215,
      "learning_rate": 1.7162383816293058e-05,
      "loss": 0.0369,
      "step": 10380
    },
    {
      "epoch": 2.8403499179879717,
      "grad_norm": 2.034830093383789,
      "learning_rate": 1.7159650082012028e-05,
      "loss": 0.0335,
      "step": 10390
    },
    {
      "epoch": 2.8430836522689997,
      "grad_norm": 1.0633025169372559,
      "learning_rate": 1.7156916347731e-05,
      "loss": 0.0349,
      "step": 10400
    },
    {
      "epoch": 2.8458173865500274,
      "grad_norm": 3.97979474067688,
      "learning_rate": 1.7154182613449975e-05,
      "loss": 0.025,
      "step": 10410
    },
    {
      "epoch": 2.848551120831055,
      "grad_norm": 1.3731837272644043,
      "learning_rate": 1.7151448879168945e-05,
      "loss": 0.0641,
      "step": 10420
    },
    {
      "epoch": 2.851284855112083,
      "grad_norm": 0.09463169425725937,
      "learning_rate": 1.7148715144887918e-05,
      "loss": 0.0201,
      "step": 10430
    },
    {
      "epoch": 2.854018589393111,
      "grad_norm": 0.06019080430269241,
      "learning_rate": 1.714598141060689e-05,
      "loss": 0.0671,
      "step": 10440
    },
    {
      "epoch": 2.856752323674139,
      "grad_norm": 0.03869685158133507,
      "learning_rate": 1.714324767632586e-05,
      "loss": 0.0722,
      "step": 10450
    },
    {
      "epoch": 2.859486057955167,
      "grad_norm": 6.954437255859375,
      "learning_rate": 1.7140513942044835e-05,
      "loss": 0.052,
      "step": 10460
    },
    {
      "epoch": 2.8622197922361945,
      "grad_norm": 0.25063765048980713,
      "learning_rate": 1.7137780207763808e-05,
      "loss": 0.0318,
      "step": 10470
    },
    {
      "epoch": 2.8649535265172226,
      "grad_norm": 0.5869572758674622,
      "learning_rate": 1.7135046473482778e-05,
      "loss": 0.0719,
      "step": 10480
    },
    {
      "epoch": 2.8676872607982506,
      "grad_norm": 0.2303803712129593,
      "learning_rate": 1.713231273920175e-05,
      "loss": 0.0545,
      "step": 10490
    },
    {
      "epoch": 2.8704209950792783,
      "grad_norm": 1.2410287857055664,
      "learning_rate": 1.712957900492072e-05,
      "loss": 0.1018,
      "step": 10500
    },
    {
      "epoch": 2.873154729360306,
      "grad_norm": 0.4039192497730255,
      "learning_rate": 1.7126845270639695e-05,
      "loss": 0.0088,
      "step": 10510
    },
    {
      "epoch": 2.875888463641334,
      "grad_norm": 0.0806742012500763,
      "learning_rate": 1.7124111536358668e-05,
      "loss": 0.0462,
      "step": 10520
    },
    {
      "epoch": 2.878622197922362,
      "grad_norm": 2.288050413131714,
      "learning_rate": 1.7121377802077638e-05,
      "loss": 0.0365,
      "step": 10530
    },
    {
      "epoch": 2.8813559322033897,
      "grad_norm": 35.99818420410156,
      "learning_rate": 1.711864406779661e-05,
      "loss": 0.0242,
      "step": 10540
    },
    {
      "epoch": 2.884089666484418,
      "grad_norm": 0.01207956112921238,
      "learning_rate": 1.7115910333515585e-05,
      "loss": 0.058,
      "step": 10550
    },
    {
      "epoch": 2.8868234007654454,
      "grad_norm": 0.011439126916229725,
      "learning_rate": 1.7113176599234555e-05,
      "loss": 0.0567,
      "step": 10560
    },
    {
      "epoch": 2.8895571350464735,
      "grad_norm": 15.408135414123535,
      "learning_rate": 1.7110442864953528e-05,
      "loss": 0.0489,
      "step": 10570
    },
    {
      "epoch": 2.8922908693275016,
      "grad_norm": 0.20076504349708557,
      "learning_rate": 1.71077091306725e-05,
      "loss": 0.011,
      "step": 10580
    },
    {
      "epoch": 2.895024603608529,
      "grad_norm": 0.028427492827177048,
      "learning_rate": 1.710497539639147e-05,
      "loss": 0.0056,
      "step": 10590
    },
    {
      "epoch": 2.8977583378895573,
      "grad_norm": 0.011819256469607353,
      "learning_rate": 1.7102241662110445e-05,
      "loss": 0.0333,
      "step": 10600
    },
    {
      "epoch": 2.900492072170585,
      "grad_norm": 8.6267671585083,
      "learning_rate": 1.7099507927829418e-05,
      "loss": 0.0728,
      "step": 10610
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.057213347405195236,
      "learning_rate": 1.7096774193548388e-05,
      "loss": 0.0904,
      "step": 10620
    },
    {
      "epoch": 2.9059595407326406,
      "grad_norm": 0.10839084535837173,
      "learning_rate": 1.709404045926736e-05,
      "loss": 0.0046,
      "step": 10630
    },
    {
      "epoch": 2.9086932750136687,
      "grad_norm": 0.02635314129292965,
      "learning_rate": 1.709130672498633e-05,
      "loss": 0.0452,
      "step": 10640
    },
    {
      "epoch": 2.9114270092946963,
      "grad_norm": 3.95095157623291,
      "learning_rate": 1.7088572990705305e-05,
      "loss": 0.06,
      "step": 10650
    },
    {
      "epoch": 2.9141607435757244,
      "grad_norm": 0.5649007558822632,
      "learning_rate": 1.7085839256424278e-05,
      "loss": 0.0202,
      "step": 10660
    },
    {
      "epoch": 2.9168944778567525,
      "grad_norm": 0.09901672601699829,
      "learning_rate": 1.7083105522143248e-05,
      "loss": 0.0489,
      "step": 10670
    },
    {
      "epoch": 2.91962821213778,
      "grad_norm": 1.9047095775604248,
      "learning_rate": 1.708037178786222e-05,
      "loss": 0.023,
      "step": 10680
    },
    {
      "epoch": 2.922361946418808,
      "grad_norm": 0.72245854139328,
      "learning_rate": 1.7077638053581195e-05,
      "loss": 0.0407,
      "step": 10690
    },
    {
      "epoch": 2.925095680699836,
      "grad_norm": 0.4615107476711273,
      "learning_rate": 1.7074904319300165e-05,
      "loss": 0.0084,
      "step": 10700
    },
    {
      "epoch": 2.927829414980864,
      "grad_norm": 0.7611373066902161,
      "learning_rate": 1.7072170585019138e-05,
      "loss": 0.0882,
      "step": 10710
    },
    {
      "epoch": 2.930563149261892,
      "grad_norm": 0.01872611790895462,
      "learning_rate": 1.706943685073811e-05,
      "loss": 0.057,
      "step": 10720
    },
    {
      "epoch": 2.9332968835429196,
      "grad_norm": 0.6286728978157043,
      "learning_rate": 1.706670311645708e-05,
      "loss": 0.0224,
      "step": 10730
    },
    {
      "epoch": 2.9360306178239473,
      "grad_norm": 0.0362110435962677,
      "learning_rate": 1.7063969382176055e-05,
      "loss": 0.0229,
      "step": 10740
    },
    {
      "epoch": 2.9387643521049753,
      "grad_norm": 2.255289316177368,
      "learning_rate": 1.7061235647895028e-05,
      "loss": 0.0361,
      "step": 10750
    },
    {
      "epoch": 2.9414980863860034,
      "grad_norm": 0.049440570175647736,
      "learning_rate": 1.7058501913613998e-05,
      "loss": 0.0296,
      "step": 10760
    },
    {
      "epoch": 2.944231820667031,
      "grad_norm": 0.06445645540952682,
      "learning_rate": 1.705576817933297e-05,
      "loss": 0.0131,
      "step": 10770
    },
    {
      "epoch": 2.946965554948059,
      "grad_norm": 3.6576476097106934,
      "learning_rate": 1.705303444505194e-05,
      "loss": 0.0722,
      "step": 10780
    },
    {
      "epoch": 2.9496992892290868,
      "grad_norm": 0.06503733992576599,
      "learning_rate": 1.7050300710770915e-05,
      "loss": 0.019,
      "step": 10790
    },
    {
      "epoch": 2.952433023510115,
      "grad_norm": 0.09518243372440338,
      "learning_rate": 1.7047566976489888e-05,
      "loss": 0.0421,
      "step": 10800
    },
    {
      "epoch": 2.955166757791143,
      "grad_norm": 5.677380084991455,
      "learning_rate": 1.7044833242208858e-05,
      "loss": 0.0233,
      "step": 10810
    },
    {
      "epoch": 2.9579004920721705,
      "grad_norm": 0.015528330579400063,
      "learning_rate": 1.704209950792783e-05,
      "loss": 0.0104,
      "step": 10820
    },
    {
      "epoch": 2.9606342263531986,
      "grad_norm": 0.01639803685247898,
      "learning_rate": 1.7039365773646805e-05,
      "loss": 0.0171,
      "step": 10830
    },
    {
      "epoch": 2.9633679606342263,
      "grad_norm": 4.238729953765869,
      "learning_rate": 1.7036632039365775e-05,
      "loss": 0.0951,
      "step": 10840
    },
    {
      "epoch": 2.9661016949152543,
      "grad_norm": 0.0781279131770134,
      "learning_rate": 1.7033898305084745e-05,
      "loss": 0.0616,
      "step": 10850
    },
    {
      "epoch": 2.968835429196282,
      "grad_norm": 1.2104523181915283,
      "learning_rate": 1.703116457080372e-05,
      "loss": 0.0272,
      "step": 10860
    },
    {
      "epoch": 2.97156916347731,
      "grad_norm": 0.04771919921040535,
      "learning_rate": 1.702843083652269e-05,
      "loss": 0.0401,
      "step": 10870
    },
    {
      "epoch": 2.9743028977583377,
      "grad_norm": 0.11062594503164291,
      "learning_rate": 1.702569710224166e-05,
      "loss": 0.0401,
      "step": 10880
    },
    {
      "epoch": 2.9770366320393657,
      "grad_norm": 11.414756774902344,
      "learning_rate": 1.7022963367960638e-05,
      "loss": 0.1018,
      "step": 10890
    },
    {
      "epoch": 2.979770366320394,
      "grad_norm": 9.642991065979004,
      "learning_rate": 1.7020229633679608e-05,
      "loss": 0.0261,
      "step": 10900
    },
    {
      "epoch": 2.9825041006014215,
      "grad_norm": 0.029958348721265793,
      "learning_rate": 1.7017495899398578e-05,
      "loss": 0.0258,
      "step": 10910
    },
    {
      "epoch": 2.9852378348824495,
      "grad_norm": 3.2031185626983643,
      "learning_rate": 1.701476216511755e-05,
      "loss": 0.0323,
      "step": 10920
    },
    {
      "epoch": 2.987971569163477,
      "grad_norm": 0.08423465490341187,
      "learning_rate": 1.7012028430836525e-05,
      "loss": 0.0321,
      "step": 10930
    },
    {
      "epoch": 2.9907053034445052,
      "grad_norm": 3.775053024291992,
      "learning_rate": 1.7009294696555495e-05,
      "loss": 0.0482,
      "step": 10940
    },
    {
      "epoch": 2.9934390377255333,
      "grad_norm": 0.2513318657875061,
      "learning_rate": 1.7006560962274468e-05,
      "loss": 0.0483,
      "step": 10950
    },
    {
      "epoch": 2.996172772006561,
      "grad_norm": 0.03286739066243172,
      "learning_rate": 1.700382722799344e-05,
      "loss": 0.0286,
      "step": 10960
    },
    {
      "epoch": 2.9989065062875886,
      "grad_norm": 0.4230666756629944,
      "learning_rate": 1.700109349371241e-05,
      "loss": 0.0056,
      "step": 10970
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9870157513835675,
      "eval_f1": 0.9474590869939707,
      "eval_loss": 0.059345778077840805,
      "eval_precision": 0.9561060408518036,
      "eval_recall": 0.9389671361502347,
      "eval_runtime": 796.0714,
      "eval_samples_per_second": 23.634,
      "eval_steps_per_second": 0.985,
      "step": 10974
    },
    {
      "epoch": 3.0016402405686167,
      "grad_norm": 11.387584686279297,
      "learning_rate": 1.6998359759431385e-05,
      "loss": 0.0191,
      "step": 10980
    },
    {
      "epoch": 3.0043739748496447,
      "grad_norm": 1.7355867624282837,
      "learning_rate": 1.6995626025150355e-05,
      "loss": 0.0095,
      "step": 10990
    },
    {
      "epoch": 3.0071077091306724,
      "grad_norm": 0.04346268251538277,
      "learning_rate": 1.6992892290869328e-05,
      "loss": 0.0044,
      "step": 11000
    },
    {
      "epoch": 3.0098414434117005,
      "grad_norm": 0.012844628654420376,
      "learning_rate": 1.69901585565883e-05,
      "loss": 0.0685,
      "step": 11010
    },
    {
      "epoch": 3.012575177692728,
      "grad_norm": 0.1451050490140915,
      "learning_rate": 1.698742482230727e-05,
      "loss": 0.0008,
      "step": 11020
    },
    {
      "epoch": 3.015308911973756,
      "grad_norm": 0.04955381155014038,
      "learning_rate": 1.6984691088026245e-05,
      "loss": 0.0006,
      "step": 11030
    },
    {
      "epoch": 3.0180426462547842,
      "grad_norm": 0.0095076784491539,
      "learning_rate": 1.6981957353745218e-05,
      "loss": 0.0132,
      "step": 11040
    },
    {
      "epoch": 3.020776380535812,
      "grad_norm": 0.03624323382973671,
      "learning_rate": 1.6979223619464188e-05,
      "loss": 0.0053,
      "step": 11050
    },
    {
      "epoch": 3.02351011481684,
      "grad_norm": 2.288522720336914,
      "learning_rate": 1.697648988518316e-05,
      "loss": 0.1289,
      "step": 11060
    },
    {
      "epoch": 3.0262438490978676,
      "grad_norm": 0.16246935725212097,
      "learning_rate": 1.6973756150902135e-05,
      "loss": 0.0206,
      "step": 11070
    },
    {
      "epoch": 3.0289775833788957,
      "grad_norm": 0.6547805666923523,
      "learning_rate": 1.6971022416621104e-05,
      "loss": 0.0391,
      "step": 11080
    },
    {
      "epoch": 3.0317113176599233,
      "grad_norm": 2.3170084953308105,
      "learning_rate": 1.6968288682340078e-05,
      "loss": 0.0329,
      "step": 11090
    },
    {
      "epoch": 3.0344450519409514,
      "grad_norm": 0.046216294169425964,
      "learning_rate": 1.696555494805905e-05,
      "loss": 0.0205,
      "step": 11100
    },
    {
      "epoch": 3.037178786221979,
      "grad_norm": 0.009814000688493252,
      "learning_rate": 1.696282121377802e-05,
      "loss": 0.0074,
      "step": 11110
    },
    {
      "epoch": 3.039912520503007,
      "grad_norm": 15.815552711486816,
      "learning_rate": 1.6960087479496995e-05,
      "loss": 0.0186,
      "step": 11120
    },
    {
      "epoch": 3.042646254784035,
      "grad_norm": 0.006275140680372715,
      "learning_rate": 1.6957353745215964e-05,
      "loss": 0.0184,
      "step": 11130
    },
    {
      "epoch": 3.045379989065063,
      "grad_norm": 0.007448283489793539,
      "learning_rate": 1.6954620010934938e-05,
      "loss": 0.0001,
      "step": 11140
    },
    {
      "epoch": 3.048113723346091,
      "grad_norm": 0.013413209468126297,
      "learning_rate": 1.695188627665391e-05,
      "loss": 0.0177,
      "step": 11150
    },
    {
      "epoch": 3.0508474576271185,
      "grad_norm": 0.004028679337352514,
      "learning_rate": 1.694915254237288e-05,
      "loss": 0.0136,
      "step": 11160
    },
    {
      "epoch": 3.0535811919081466,
      "grad_norm": 1.210810661315918,
      "learning_rate": 1.6946418808091854e-05,
      "loss": 0.008,
      "step": 11170
    },
    {
      "epoch": 3.056314926189174,
      "grad_norm": 0.0038827925454825163,
      "learning_rate": 1.6943685073810828e-05,
      "loss": 0.0376,
      "step": 11180
    },
    {
      "epoch": 3.0590486604702023,
      "grad_norm": 0.004293803125619888,
      "learning_rate": 1.6940951339529798e-05,
      "loss": 0.0287,
      "step": 11190
    },
    {
      "epoch": 3.0617823947512304,
      "grad_norm": 0.20536591112613678,
      "learning_rate": 1.693821760524877e-05,
      "loss": 0.0152,
      "step": 11200
    },
    {
      "epoch": 3.064516129032258,
      "grad_norm": 0.0037381057627499104,
      "learning_rate": 1.6935483870967744e-05,
      "loss": 0.0002,
      "step": 11210
    },
    {
      "epoch": 3.067249863313286,
      "grad_norm": 2.865628480911255,
      "learning_rate": 1.6932750136686714e-05,
      "loss": 0.0518,
      "step": 11220
    },
    {
      "epoch": 3.0699835975943137,
      "grad_norm": 0.0051242331974208355,
      "learning_rate": 1.6930016402405688e-05,
      "loss": 0.0257,
      "step": 11230
    },
    {
      "epoch": 3.072717331875342,
      "grad_norm": 0.37201786041259766,
      "learning_rate": 1.692728266812466e-05,
      "loss": 0.0728,
      "step": 11240
    },
    {
      "epoch": 3.0754510661563694,
      "grad_norm": 0.38131144642829895,
      "learning_rate": 1.692454893384363e-05,
      "loss": 0.0632,
      "step": 11250
    },
    {
      "epoch": 3.0781848004373975,
      "grad_norm": 5.265907287597656,
      "learning_rate": 1.6921815199562604e-05,
      "loss": 0.0054,
      "step": 11260
    },
    {
      "epoch": 3.0809185347184256,
      "grad_norm": 0.013149894773960114,
      "learning_rate": 1.6919081465281574e-05,
      "loss": 0.0019,
      "step": 11270
    },
    {
      "epoch": 3.083652268999453,
      "grad_norm": 0.17732566595077515,
      "learning_rate": 1.6916347731000548e-05,
      "loss": 0.0004,
      "step": 11280
    },
    {
      "epoch": 3.0863860032804813,
      "grad_norm": 0.007533146534115076,
      "learning_rate": 1.691361399671952e-05,
      "loss": 0.0239,
      "step": 11290
    },
    {
      "epoch": 3.089119737561509,
      "grad_norm": 0.8092749714851379,
      "learning_rate": 1.691088026243849e-05,
      "loss": 0.0159,
      "step": 11300
    },
    {
      "epoch": 3.091853471842537,
      "grad_norm": 0.025176914408802986,
      "learning_rate": 1.6908146528157464e-05,
      "loss": 0.0334,
      "step": 11310
    },
    {
      "epoch": 3.0945872061235646,
      "grad_norm": 0.45460858941078186,
      "learning_rate": 1.6905412793876438e-05,
      "loss": 0.041,
      "step": 11320
    },
    {
      "epoch": 3.0973209404045927,
      "grad_norm": 0.012531604617834091,
      "learning_rate": 1.6902679059595408e-05,
      "loss": 0.0297,
      "step": 11330
    },
    {
      "epoch": 3.1000546746856203,
      "grad_norm": 0.0033259165938943624,
      "learning_rate": 1.689994532531438e-05,
      "loss": 0.049,
      "step": 11340
    },
    {
      "epoch": 3.1027884089666484,
      "grad_norm": 5.658019542694092,
      "learning_rate": 1.6897211591033354e-05,
      "loss": 0.0771,
      "step": 11350
    },
    {
      "epoch": 3.1055221432476765,
      "grad_norm": 0.005488261114805937,
      "learning_rate": 1.6894477856752324e-05,
      "loss": 0.0371,
      "step": 11360
    },
    {
      "epoch": 3.108255877528704,
      "grad_norm": 13.190712928771973,
      "learning_rate": 1.6891744122471298e-05,
      "loss": 0.0994,
      "step": 11370
    },
    {
      "epoch": 3.110989611809732,
      "grad_norm": 7.398776531219482,
      "learning_rate": 1.688901038819027e-05,
      "loss": 0.0482,
      "step": 11380
    },
    {
      "epoch": 3.11372334609076,
      "grad_norm": 2.9855854511260986,
      "learning_rate": 1.688627665390924e-05,
      "loss": 0.0539,
      "step": 11390
    },
    {
      "epoch": 3.116457080371788,
      "grad_norm": 0.08036523312330246,
      "learning_rate": 1.6883542919628214e-05,
      "loss": 0.0509,
      "step": 11400
    },
    {
      "epoch": 3.1191908146528156,
      "grad_norm": 0.1440703570842743,
      "learning_rate": 1.6880809185347188e-05,
      "loss": 0.0323,
      "step": 11410
    },
    {
      "epoch": 3.1219245489338436,
      "grad_norm": 0.013757389038801193,
      "learning_rate": 1.6878075451066158e-05,
      "loss": 0.0327,
      "step": 11420
    },
    {
      "epoch": 3.1246582832148717,
      "grad_norm": 0.009223557077348232,
      "learning_rate": 1.687534171678513e-05,
      "loss": 0.0561,
      "step": 11430
    },
    {
      "epoch": 3.1273920174958993,
      "grad_norm": 3.6780152320861816,
      "learning_rate": 1.68726079825041e-05,
      "loss": 0.0152,
      "step": 11440
    },
    {
      "epoch": 3.1301257517769274,
      "grad_norm": 0.0066080582328140736,
      "learning_rate": 1.6869874248223074e-05,
      "loss": 0.0198,
      "step": 11450
    },
    {
      "epoch": 3.132859486057955,
      "grad_norm": 6.384989261627197,
      "learning_rate": 1.6867140513942048e-05,
      "loss": 0.0329,
      "step": 11460
    },
    {
      "epoch": 3.135593220338983,
      "grad_norm": 3.9710652828216553,
      "learning_rate": 1.6864406779661018e-05,
      "loss": 0.0335,
      "step": 11470
    },
    {
      "epoch": 3.1383269546200108,
      "grad_norm": 2.7229950428009033,
      "learning_rate": 1.686167304537999e-05,
      "loss": 0.0462,
      "step": 11480
    },
    {
      "epoch": 3.141060688901039,
      "grad_norm": 0.027241544798016548,
      "learning_rate": 1.6858939311098964e-05,
      "loss": 0.0319,
      "step": 11490
    },
    {
      "epoch": 3.143794423182067,
      "grad_norm": 0.04022340476512909,
      "learning_rate": 1.6856205576817934e-05,
      "loss": 0.0475,
      "step": 11500
    },
    {
      "epoch": 3.1465281574630946,
      "grad_norm": 0.01094520092010498,
      "learning_rate": 1.6853471842536904e-05,
      "loss": 0.001,
      "step": 11510
    },
    {
      "epoch": 3.1492618917441226,
      "grad_norm": 5.711486339569092,
      "learning_rate": 1.685073810825588e-05,
      "loss": 0.0573,
      "step": 11520
    },
    {
      "epoch": 3.1519956260251503,
      "grad_norm": 0.15648888051509857,
      "learning_rate": 1.684800437397485e-05,
      "loss": 0.0011,
      "step": 11530
    },
    {
      "epoch": 3.1547293603061783,
      "grad_norm": 0.017757315188646317,
      "learning_rate": 1.684527063969382e-05,
      "loss": 0.0275,
      "step": 11540
    },
    {
      "epoch": 3.157463094587206,
      "grad_norm": 0.009666224010288715,
      "learning_rate": 1.6842536905412798e-05,
      "loss": 0.0172,
      "step": 11550
    },
    {
      "epoch": 3.160196828868234,
      "grad_norm": 3.8936169147491455,
      "learning_rate": 1.6839803171131768e-05,
      "loss": 0.0121,
      "step": 11560
    },
    {
      "epoch": 3.1629305631492617,
      "grad_norm": 0.1670333296060562,
      "learning_rate": 1.6837069436850738e-05,
      "loss": 0.0416,
      "step": 11570
    },
    {
      "epoch": 3.1656642974302898,
      "grad_norm": 0.15638865530490875,
      "learning_rate": 1.683433570256971e-05,
      "loss": 0.0546,
      "step": 11580
    },
    {
      "epoch": 3.168398031711318,
      "grad_norm": 1.1918237209320068,
      "learning_rate": 1.6831601968288684e-05,
      "loss": 0.0273,
      "step": 11590
    },
    {
      "epoch": 3.1711317659923455,
      "grad_norm": 14.409744262695312,
      "learning_rate": 1.6828868234007654e-05,
      "loss": 0.0302,
      "step": 11600
    },
    {
      "epoch": 3.1738655002733736,
      "grad_norm": 0.011081530712544918,
      "learning_rate": 1.6826134499726628e-05,
      "loss": 0.0108,
      "step": 11610
    },
    {
      "epoch": 3.176599234554401,
      "grad_norm": 0.0369059219956398,
      "learning_rate": 1.68234007654456e-05,
      "loss": 0.0124,
      "step": 11620
    },
    {
      "epoch": 3.1793329688354293,
      "grad_norm": 4.0718464851379395,
      "learning_rate": 1.682066703116457e-05,
      "loss": 0.0563,
      "step": 11630
    },
    {
      "epoch": 3.182066703116457,
      "grad_norm": 0.05599994957447052,
      "learning_rate": 1.6817933296883544e-05,
      "loss": 0.0138,
      "step": 11640
    },
    {
      "epoch": 3.184800437397485,
      "grad_norm": 0.009669732302427292,
      "learning_rate": 1.6815199562602514e-05,
      "loss": 0.0044,
      "step": 11650
    },
    {
      "epoch": 3.187534171678513,
      "grad_norm": 0.008294820785522461,
      "learning_rate": 1.6812465828321488e-05,
      "loss": 0.0213,
      "step": 11660
    },
    {
      "epoch": 3.1902679059595407,
      "grad_norm": 1.1523358821868896,
      "learning_rate": 1.680973209404046e-05,
      "loss": 0.0304,
      "step": 11670
    },
    {
      "epoch": 3.1930016402405688,
      "grad_norm": 1.1394027471542358,
      "learning_rate": 1.680699835975943e-05,
      "loss": 0.0321,
      "step": 11680
    },
    {
      "epoch": 3.1957353745215964,
      "grad_norm": 3.766718864440918,
      "learning_rate": 1.6804264625478404e-05,
      "loss": 0.087,
      "step": 11690
    },
    {
      "epoch": 3.1984691088026245,
      "grad_norm": 4.508281230926514,
      "learning_rate": 1.6801530891197378e-05,
      "loss": 0.0887,
      "step": 11700
    },
    {
      "epoch": 3.201202843083652,
      "grad_norm": 0.26999661326408386,
      "learning_rate": 1.6798797156916348e-05,
      "loss": 0.0058,
      "step": 11710
    },
    {
      "epoch": 3.20393657736468,
      "grad_norm": 3.8255674839019775,
      "learning_rate": 1.679606342263532e-05,
      "loss": 0.0014,
      "step": 11720
    },
    {
      "epoch": 3.2066703116457083,
      "grad_norm": 0.7403247952461243,
      "learning_rate": 1.6793329688354294e-05,
      "loss": 0.0051,
      "step": 11730
    },
    {
      "epoch": 3.209404045926736,
      "grad_norm": 3.262160062789917,
      "learning_rate": 1.6790595954073264e-05,
      "loss": 0.0645,
      "step": 11740
    },
    {
      "epoch": 3.212137780207764,
      "grad_norm": 0.011630254797637463,
      "learning_rate": 1.6787862219792238e-05,
      "loss": 0.0206,
      "step": 11750
    },
    {
      "epoch": 3.2148715144887916,
      "grad_norm": 0.015607565641403198,
      "learning_rate": 1.678512848551121e-05,
      "loss": 0.0682,
      "step": 11760
    },
    {
      "epoch": 3.2176052487698197,
      "grad_norm": 0.017607782036066055,
      "learning_rate": 1.678239475123018e-05,
      "loss": 0.0738,
      "step": 11770
    },
    {
      "epoch": 3.2203389830508473,
      "grad_norm": 8.003267288208008,
      "learning_rate": 1.6779661016949154e-05,
      "loss": 0.0697,
      "step": 11780
    },
    {
      "epoch": 3.2230727173318754,
      "grad_norm": 8.599587440490723,
      "learning_rate": 1.6776927282668124e-05,
      "loss": 0.093,
      "step": 11790
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 4.162344455718994,
      "learning_rate": 1.6774193548387098e-05,
      "loss": 0.0315,
      "step": 11800
    },
    {
      "epoch": 3.228540185893931,
      "grad_norm": 4.858377456665039,
      "learning_rate": 1.677145981410607e-05,
      "loss": 0.0171,
      "step": 11810
    },
    {
      "epoch": 3.231273920174959,
      "grad_norm": 0.18238700926303864,
      "learning_rate": 1.676872607982504e-05,
      "loss": 0.1334,
      "step": 11820
    },
    {
      "epoch": 3.234007654455987,
      "grad_norm": 0.5179039239883423,
      "learning_rate": 1.6765992345544014e-05,
      "loss": 0.0519,
      "step": 11830
    },
    {
      "epoch": 3.236741388737015,
      "grad_norm": 0.06832274049520493,
      "learning_rate": 1.6763258611262988e-05,
      "loss": 0.0805,
      "step": 11840
    },
    {
      "epoch": 3.2394751230180425,
      "grad_norm": 8.19424057006836,
      "learning_rate": 1.6760524876981958e-05,
      "loss": 0.0094,
      "step": 11850
    },
    {
      "epoch": 3.2422088572990706,
      "grad_norm": 0.06560903042554855,
      "learning_rate": 1.675779114270093e-05,
      "loss": 0.0481,
      "step": 11860
    },
    {
      "epoch": 3.2449425915800982,
      "grad_norm": 0.07505056262016296,
      "learning_rate": 1.6755057408419904e-05,
      "loss": 0.0125,
      "step": 11870
    },
    {
      "epoch": 3.2476763258611263,
      "grad_norm": 0.010014564730226994,
      "learning_rate": 1.6752323674138874e-05,
      "loss": 0.0168,
      "step": 11880
    },
    {
      "epoch": 3.250410060142154,
      "grad_norm": 0.025351867079734802,
      "learning_rate": 1.6749589939857848e-05,
      "loss": 0.0666,
      "step": 11890
    },
    {
      "epoch": 3.253143794423182,
      "grad_norm": 3.093738317489624,
      "learning_rate": 1.674685620557682e-05,
      "loss": 0.0308,
      "step": 11900
    },
    {
      "epoch": 3.25587752870421,
      "grad_norm": 2.7001922130584717,
      "learning_rate": 1.674412247129579e-05,
      "loss": 0.0722,
      "step": 11910
    },
    {
      "epoch": 3.2586112629852377,
      "grad_norm": 0.13208691775798798,
      "learning_rate": 1.6741388737014764e-05,
      "loss": 0.0185,
      "step": 11920
    },
    {
      "epoch": 3.261344997266266,
      "grad_norm": 1.0494489669799805,
      "learning_rate": 1.6738655002733734e-05,
      "loss": 0.0597,
      "step": 11930
    },
    {
      "epoch": 3.2640787315472934,
      "grad_norm": 0.05171118676662445,
      "learning_rate": 1.6735921268452708e-05,
      "loss": 0.0295,
      "step": 11940
    },
    {
      "epoch": 3.2668124658283215,
      "grad_norm": 0.14132088422775269,
      "learning_rate": 1.673318753417168e-05,
      "loss": 0.0603,
      "step": 11950
    },
    {
      "epoch": 3.2695462001093496,
      "grad_norm": 0.1067996695637703,
      "learning_rate": 1.673045379989065e-05,
      "loss": 0.0511,
      "step": 11960
    },
    {
      "epoch": 3.2722799343903772,
      "grad_norm": 0.01754118874669075,
      "learning_rate": 1.6727720065609624e-05,
      "loss": 0.0231,
      "step": 11970
    },
    {
      "epoch": 3.2750136686714053,
      "grad_norm": 0.07941073179244995,
      "learning_rate": 1.6724986331328598e-05,
      "loss": 0.0056,
      "step": 11980
    },
    {
      "epoch": 3.277747402952433,
      "grad_norm": 0.12016815692186356,
      "learning_rate": 1.6722252597047568e-05,
      "loss": 0.0302,
      "step": 11990
    },
    {
      "epoch": 3.280481137233461,
      "grad_norm": 2.2566709518432617,
      "learning_rate": 1.671951886276654e-05,
      "loss": 0.0303,
      "step": 12000
    },
    {
      "epoch": 3.2832148715144887,
      "grad_norm": 0.16768886148929596,
      "learning_rate": 1.6716785128485514e-05,
      "loss": 0.0156,
      "step": 12010
    },
    {
      "epoch": 3.2859486057955167,
      "grad_norm": 0.011803948320448399,
      "learning_rate": 1.6714051394204484e-05,
      "loss": 0.0299,
      "step": 12020
    },
    {
      "epoch": 3.2886823400765444,
      "grad_norm": 0.04071715101599693,
      "learning_rate": 1.6711317659923458e-05,
      "loss": 0.0248,
      "step": 12030
    },
    {
      "epoch": 3.2914160743575724,
      "grad_norm": 0.006734963972121477,
      "learning_rate": 1.670858392564243e-05,
      "loss": 0.0179,
      "step": 12040
    },
    {
      "epoch": 3.2941498086386005,
      "grad_norm": 12.918371200561523,
      "learning_rate": 1.67058501913614e-05,
      "loss": 0.0692,
      "step": 12050
    },
    {
      "epoch": 3.296883542919628,
      "grad_norm": 0.011155040934681892,
      "learning_rate": 1.6703116457080374e-05,
      "loss": 0.0339,
      "step": 12060
    },
    {
      "epoch": 3.2996172772006562,
      "grad_norm": 0.005048300605267286,
      "learning_rate": 1.6700382722799344e-05,
      "loss": 0.0536,
      "step": 12070
    },
    {
      "epoch": 3.302351011481684,
      "grad_norm": 4.669321537017822,
      "learning_rate": 1.6697648988518318e-05,
      "loss": 0.039,
      "step": 12080
    },
    {
      "epoch": 3.305084745762712,
      "grad_norm": 0.49656522274017334,
      "learning_rate": 1.669491525423729e-05,
      "loss": 0.0689,
      "step": 12090
    },
    {
      "epoch": 3.3078184800437396,
      "grad_norm": 2.006282091140747,
      "learning_rate": 1.669218151995626e-05,
      "loss": 0.0273,
      "step": 12100
    },
    {
      "epoch": 3.3105522143247677,
      "grad_norm": 0.2179281860589981,
      "learning_rate": 1.6689447785675234e-05,
      "loss": 0.0157,
      "step": 12110
    },
    {
      "epoch": 3.3132859486057953,
      "grad_norm": 0.04767114669084549,
      "learning_rate": 1.6686714051394208e-05,
      "loss": 0.0424,
      "step": 12120
    },
    {
      "epoch": 3.3160196828868234,
      "grad_norm": 1.1581999063491821,
      "learning_rate": 1.6683980317113177e-05,
      "loss": 0.0278,
      "step": 12130
    },
    {
      "epoch": 3.3187534171678514,
      "grad_norm": 5.890209674835205,
      "learning_rate": 1.6681246582832147e-05,
      "loss": 0.0719,
      "step": 12140
    },
    {
      "epoch": 3.321487151448879,
      "grad_norm": 0.08579444140195847,
      "learning_rate": 1.6678512848551124e-05,
      "loss": 0.0063,
      "step": 12150
    },
    {
      "epoch": 3.324220885729907,
      "grad_norm": 0.3195676803588867,
      "learning_rate": 1.6675779114270094e-05,
      "loss": 0.0316,
      "step": 12160
    },
    {
      "epoch": 3.326954620010935,
      "grad_norm": 0.516563892364502,
      "learning_rate": 1.6673045379989064e-05,
      "loss": 0.0406,
      "step": 12170
    },
    {
      "epoch": 3.329688354291963,
      "grad_norm": 0.0259527750313282,
      "learning_rate": 1.667031164570804e-05,
      "loss": 0.0212,
      "step": 12180
    },
    {
      "epoch": 3.332422088572991,
      "grad_norm": 20.543542861938477,
      "learning_rate": 1.666757791142701e-05,
      "loss": 0.0315,
      "step": 12190
    },
    {
      "epoch": 3.3351558228540186,
      "grad_norm": 0.010988075286149979,
      "learning_rate": 1.666484417714598e-05,
      "loss": 0.0232,
      "step": 12200
    },
    {
      "epoch": 3.3378895571350466,
      "grad_norm": 0.6138170957565308,
      "learning_rate": 1.6662110442864954e-05,
      "loss": 0.0292,
      "step": 12210
    },
    {
      "epoch": 3.3406232914160743,
      "grad_norm": 0.05803191289305687,
      "learning_rate": 1.6659376708583927e-05,
      "loss": 0.0181,
      "step": 12220
    },
    {
      "epoch": 3.3433570256971024,
      "grad_norm": 0.10393834114074707,
      "learning_rate": 1.6656642974302897e-05,
      "loss": 0.0433,
      "step": 12230
    },
    {
      "epoch": 3.34609075997813,
      "grad_norm": 0.002980327932164073,
      "learning_rate": 1.665390924002187e-05,
      "loss": 0.002,
      "step": 12240
    },
    {
      "epoch": 3.348824494259158,
      "grad_norm": 0.026300106197595596,
      "learning_rate": 1.6651175505740844e-05,
      "loss": 0.0995,
      "step": 12250
    },
    {
      "epoch": 3.3515582285401857,
      "grad_norm": 6.681774139404297,
      "learning_rate": 1.6648441771459814e-05,
      "loss": 0.067,
      "step": 12260
    },
    {
      "epoch": 3.354291962821214,
      "grad_norm": 0.3081664443016052,
      "learning_rate": 1.6645708037178787e-05,
      "loss": 0.0281,
      "step": 12270
    },
    {
      "epoch": 3.357025697102242,
      "grad_norm": 0.0932636484503746,
      "learning_rate": 1.6642974302897757e-05,
      "loss": 0.043,
      "step": 12280
    },
    {
      "epoch": 3.3597594313832695,
      "grad_norm": 0.05509388819336891,
      "learning_rate": 1.664024056861673e-05,
      "loss": 0.0181,
      "step": 12290
    },
    {
      "epoch": 3.3624931656642976,
      "grad_norm": 0.2369994819164276,
      "learning_rate": 1.6637506834335704e-05,
      "loss": 0.0377,
      "step": 12300
    },
    {
      "epoch": 3.365226899945325,
      "grad_norm": 1.7830060720443726,
      "learning_rate": 1.6634773100054674e-05,
      "loss": 0.0587,
      "step": 12310
    },
    {
      "epoch": 3.3679606342263533,
      "grad_norm": 0.02233954519033432,
      "learning_rate": 1.6632039365773647e-05,
      "loss": 0.0167,
      "step": 12320
    },
    {
      "epoch": 3.370694368507381,
      "grad_norm": 11.373160362243652,
      "learning_rate": 1.662930563149262e-05,
      "loss": 0.0205,
      "step": 12330
    },
    {
      "epoch": 3.373428102788409,
      "grad_norm": 0.04592139646410942,
      "learning_rate": 1.662657189721159e-05,
      "loss": 0.0294,
      "step": 12340
    },
    {
      "epoch": 3.3761618370694366,
      "grad_norm": 0.03299610689282417,
      "learning_rate": 1.6623838162930564e-05,
      "loss": 0.0015,
      "step": 12350
    },
    {
      "epoch": 3.3788955713504647,
      "grad_norm": 0.01528625376522541,
      "learning_rate": 1.6621104428649537e-05,
      "loss": 0.0126,
      "step": 12360
    },
    {
      "epoch": 3.3816293056314928,
      "grad_norm": 0.022749990224838257,
      "learning_rate": 1.6618370694368507e-05,
      "loss": 0.0225,
      "step": 12370
    },
    {
      "epoch": 3.3843630399125204,
      "grad_norm": 0.005935510620474815,
      "learning_rate": 1.661563696008748e-05,
      "loss": 0.0064,
      "step": 12380
    },
    {
      "epoch": 3.3870967741935485,
      "grad_norm": 1.20119047164917,
      "learning_rate": 1.6612903225806454e-05,
      "loss": 0.0509,
      "step": 12390
    },
    {
      "epoch": 3.389830508474576,
      "grad_norm": 0.1809181123971939,
      "learning_rate": 1.6610169491525424e-05,
      "loss": 0.0068,
      "step": 12400
    },
    {
      "epoch": 3.392564242755604,
      "grad_norm": 18.174015045166016,
      "learning_rate": 1.6607435757244397e-05,
      "loss": 0.051,
      "step": 12410
    },
    {
      "epoch": 3.3952979770366323,
      "grad_norm": 0.058905646204948425,
      "learning_rate": 1.660470202296337e-05,
      "loss": 0.035,
      "step": 12420
    },
    {
      "epoch": 3.39803171131766,
      "grad_norm": 0.016346992924809456,
      "learning_rate": 1.660196828868234e-05,
      "loss": 0.0173,
      "step": 12430
    },
    {
      "epoch": 3.400765445598688,
      "grad_norm": 0.011446529068052769,
      "learning_rate": 1.6599234554401314e-05,
      "loss": 0.0139,
      "step": 12440
    },
    {
      "epoch": 3.4034991798797156,
      "grad_norm": 0.2553701102733612,
      "learning_rate": 1.6596500820120284e-05,
      "loss": 0.0456,
      "step": 12450
    },
    {
      "epoch": 3.4062329141607437,
      "grad_norm": 0.061861392110586166,
      "learning_rate": 1.6593767085839257e-05,
      "loss": 0.0241,
      "step": 12460
    },
    {
      "epoch": 3.4089666484417713,
      "grad_norm": 0.20593605935573578,
      "learning_rate": 1.659103335155823e-05,
      "loss": 0.0329,
      "step": 12470
    },
    {
      "epoch": 3.4117003827227994,
      "grad_norm": 0.013952723704278469,
      "learning_rate": 1.65882996172772e-05,
      "loss": 0.0245,
      "step": 12480
    },
    {
      "epoch": 3.414434117003827,
      "grad_norm": 2.4871139526367188,
      "learning_rate": 1.6585565882996174e-05,
      "loss": 0.0409,
      "step": 12490
    },
    {
      "epoch": 3.417167851284855,
      "grad_norm": 0.034411825239658356,
      "learning_rate": 1.6582832148715147e-05,
      "loss": 0.0013,
      "step": 12500
    },
    {
      "epoch": 3.419901585565883,
      "grad_norm": 4.778554916381836,
      "learning_rate": 1.6580098414434117e-05,
      "loss": 0.028,
      "step": 12510
    },
    {
      "epoch": 3.422635319846911,
      "grad_norm": 0.37894028425216675,
      "learning_rate": 1.657736468015309e-05,
      "loss": 0.0381,
      "step": 12520
    },
    {
      "epoch": 3.425369054127939,
      "grad_norm": 0.015424064360558987,
      "learning_rate": 1.6574630945872064e-05,
      "loss": 0.0395,
      "step": 12530
    },
    {
      "epoch": 3.4281027884089665,
      "grad_norm": 0.04578524827957153,
      "learning_rate": 1.6571897211591034e-05,
      "loss": 0.0391,
      "step": 12540
    },
    {
      "epoch": 3.4308365226899946,
      "grad_norm": 3.2757728099823,
      "learning_rate": 1.6569163477310007e-05,
      "loss": 0.046,
      "step": 12550
    },
    {
      "epoch": 3.4335702569710222,
      "grad_norm": 6.389564037322998,
      "learning_rate": 1.656642974302898e-05,
      "loss": 0.061,
      "step": 12560
    },
    {
      "epoch": 3.4363039912520503,
      "grad_norm": 0.08643080294132233,
      "learning_rate": 1.656369600874795e-05,
      "loss": 0.0227,
      "step": 12570
    },
    {
      "epoch": 3.439037725533078,
      "grad_norm": 0.017970675602555275,
      "learning_rate": 1.6560962274466924e-05,
      "loss": 0.0341,
      "step": 12580
    },
    {
      "epoch": 3.441771459814106,
      "grad_norm": 3.0205767154693604,
      "learning_rate": 1.6558228540185894e-05,
      "loss": 0.0711,
      "step": 12590
    },
    {
      "epoch": 3.444505194095134,
      "grad_norm": 0.39629557728767395,
      "learning_rate": 1.6555494805904867e-05,
      "loss": 0.0692,
      "step": 12600
    },
    {
      "epoch": 3.4472389283761617,
      "grad_norm": 0.038205835968256,
      "learning_rate": 1.655276107162384e-05,
      "loss": 0.0222,
      "step": 12610
    },
    {
      "epoch": 3.44997266265719,
      "grad_norm": 0.017929598689079285,
      "learning_rate": 1.655002733734281e-05,
      "loss": 0.0489,
      "step": 12620
    },
    {
      "epoch": 3.4527063969382175,
      "grad_norm": 1.502304196357727,
      "learning_rate": 1.6547293603061784e-05,
      "loss": 0.026,
      "step": 12630
    },
    {
      "epoch": 3.4554401312192455,
      "grad_norm": 0.06570358574390411,
      "learning_rate": 1.6544559868780757e-05,
      "loss": 0.0124,
      "step": 12640
    },
    {
      "epoch": 3.4581738655002736,
      "grad_norm": 1.34079909324646,
      "learning_rate": 1.6541826134499727e-05,
      "loss": 0.0336,
      "step": 12650
    },
    {
      "epoch": 3.4609075997813012,
      "grad_norm": 0.604431688785553,
      "learning_rate": 1.65390924002187e-05,
      "loss": 0.0275,
      "step": 12660
    },
    {
      "epoch": 3.4636413340623293,
      "grad_norm": 0.47089818120002747,
      "learning_rate": 1.6536358665937674e-05,
      "loss": 0.0337,
      "step": 12670
    },
    {
      "epoch": 3.466375068343357,
      "grad_norm": 0.027886049821972847,
      "learning_rate": 1.6533624931656644e-05,
      "loss": 0.1129,
      "step": 12680
    },
    {
      "epoch": 3.469108802624385,
      "grad_norm": 4.076914310455322,
      "learning_rate": 1.6530891197375617e-05,
      "loss": 0.0469,
      "step": 12690
    },
    {
      "epoch": 3.4718425369054127,
      "grad_norm": 4.3450117111206055,
      "learning_rate": 1.652815746309459e-05,
      "loss": 0.0428,
      "step": 12700
    },
    {
      "epoch": 3.4745762711864407,
      "grad_norm": 24.19953155517578,
      "learning_rate": 1.652542372881356e-05,
      "loss": 0.0114,
      "step": 12710
    },
    {
      "epoch": 3.4773100054674684,
      "grad_norm": 17.15056037902832,
      "learning_rate": 1.6522689994532534e-05,
      "loss": 0.0554,
      "step": 12720
    },
    {
      "epoch": 3.4800437397484965,
      "grad_norm": 0.7243680357933044,
      "learning_rate": 1.6519956260251504e-05,
      "loss": 0.047,
      "step": 12730
    },
    {
      "epoch": 3.4827774740295245,
      "grad_norm": 0.3573133051395416,
      "learning_rate": 1.6517222525970477e-05,
      "loss": 0.0093,
      "step": 12740
    },
    {
      "epoch": 3.485511208310552,
      "grad_norm": 2.191429853439331,
      "learning_rate": 1.651448879168945e-05,
      "loss": 0.0401,
      "step": 12750
    },
    {
      "epoch": 3.4882449425915802,
      "grad_norm": 0.024554582312703133,
      "learning_rate": 1.651175505740842e-05,
      "loss": 0.008,
      "step": 12760
    },
    {
      "epoch": 3.490978676872608,
      "grad_norm": 0.012200596742331982,
      "learning_rate": 1.6509021323127394e-05,
      "loss": 0.0145,
      "step": 12770
    },
    {
      "epoch": 3.493712411153636,
      "grad_norm": 0.004542600829154253,
      "learning_rate": 1.6506287588846367e-05,
      "loss": 0.062,
      "step": 12780
    },
    {
      "epoch": 3.4964461454346636,
      "grad_norm": 3.6844382286071777,
      "learning_rate": 1.6503553854565337e-05,
      "loss": 0.0543,
      "step": 12790
    },
    {
      "epoch": 3.4991798797156917,
      "grad_norm": 0.015531306155025959,
      "learning_rate": 1.6500820120284307e-05,
      "loss": 0.0334,
      "step": 12800
    },
    {
      "epoch": 3.5019136139967193,
      "grad_norm": 0.06457033008337021,
      "learning_rate": 1.6498086386003284e-05,
      "loss": 0.0244,
      "step": 12810
    },
    {
      "epoch": 3.5046473482777474,
      "grad_norm": 13.9456205368042,
      "learning_rate": 1.6495352651722254e-05,
      "loss": 0.0144,
      "step": 12820
    },
    {
      "epoch": 3.5073810825587755,
      "grad_norm": 0.4214249849319458,
      "learning_rate": 1.6492618917441224e-05,
      "loss": 0.0182,
      "step": 12830
    },
    {
      "epoch": 3.510114816839803,
      "grad_norm": 0.3514765799045563,
      "learning_rate": 1.64898851831602e-05,
      "loss": 0.0074,
      "step": 12840
    },
    {
      "epoch": 3.512848551120831,
      "grad_norm": 0.5894051790237427,
      "learning_rate": 1.648715144887917e-05,
      "loss": 0.041,
      "step": 12850
    },
    {
      "epoch": 3.515582285401859,
      "grad_norm": 3.5890138149261475,
      "learning_rate": 1.648441771459814e-05,
      "loss": 0.0338,
      "step": 12860
    },
    {
      "epoch": 3.518316019682887,
      "grad_norm": 0.030894547700881958,
      "learning_rate": 1.6481683980317114e-05,
      "loss": 0.0022,
      "step": 12870
    },
    {
      "epoch": 3.521049753963915,
      "grad_norm": 0.008759490214288235,
      "learning_rate": 1.6478950246036087e-05,
      "loss": 0.0492,
      "step": 12880
    },
    {
      "epoch": 3.5237834882449426,
      "grad_norm": 4.748762130737305,
      "learning_rate": 1.6476216511755057e-05,
      "loss": 0.1152,
      "step": 12890
    },
    {
      "epoch": 3.52651722252597,
      "grad_norm": 11.252155303955078,
      "learning_rate": 1.647348277747403e-05,
      "loss": 0.0162,
      "step": 12900
    },
    {
      "epoch": 3.5292509568069983,
      "grad_norm": 0.3168533146381378,
      "learning_rate": 1.6470749043193004e-05,
      "loss": 0.0337,
      "step": 12910
    },
    {
      "epoch": 3.5319846910880264,
      "grad_norm": 0.04744047671556473,
      "learning_rate": 1.6468015308911974e-05,
      "loss": 0.0428,
      "step": 12920
    },
    {
      "epoch": 3.534718425369054,
      "grad_norm": 0.210483580827713,
      "learning_rate": 1.6465281574630947e-05,
      "loss": 0.0073,
      "step": 12930
    },
    {
      "epoch": 3.537452159650082,
      "grad_norm": 6.549068927764893,
      "learning_rate": 1.6462547840349917e-05,
      "loss": 0.058,
      "step": 12940
    },
    {
      "epoch": 3.5401858939311097,
      "grad_norm": 0.4180815815925598,
      "learning_rate": 1.645981410606889e-05,
      "loss": 0.0031,
      "step": 12950
    },
    {
      "epoch": 3.542919628212138,
      "grad_norm": 0.03482240438461304,
      "learning_rate": 1.6457080371787864e-05,
      "loss": 0.0077,
      "step": 12960
    },
    {
      "epoch": 3.545653362493166,
      "grad_norm": 0.0065802172757685184,
      "learning_rate": 1.6454346637506834e-05,
      "loss": 0.0559,
      "step": 12970
    },
    {
      "epoch": 3.5483870967741935,
      "grad_norm": 1.3805711269378662,
      "learning_rate": 1.6451612903225807e-05,
      "loss": 0.0148,
      "step": 12980
    },
    {
      "epoch": 3.5511208310552216,
      "grad_norm": 0.9619681239128113,
      "learning_rate": 1.644887916894478e-05,
      "loss": 0.034,
      "step": 12990
    },
    {
      "epoch": 3.553854565336249,
      "grad_norm": 2.772441864013672,
      "learning_rate": 1.644614543466375e-05,
      "loss": 0.0281,
      "step": 13000
    },
    {
      "epoch": 3.5565882996172773,
      "grad_norm": 0.009977586567401886,
      "learning_rate": 1.6443411700382724e-05,
      "loss": 0.0262,
      "step": 13010
    },
    {
      "epoch": 3.559322033898305,
      "grad_norm": 0.018633248284459114,
      "learning_rate": 1.6440677966101697e-05,
      "loss": 0.0151,
      "step": 13020
    },
    {
      "epoch": 3.562055768179333,
      "grad_norm": 5.637383937835693,
      "learning_rate": 1.6437944231820667e-05,
      "loss": 0.0329,
      "step": 13030
    },
    {
      "epoch": 3.5647895024603606,
      "grad_norm": 0.06506112217903137,
      "learning_rate": 1.643521049753964e-05,
      "loss": 0.0039,
      "step": 13040
    },
    {
      "epoch": 3.5675232367413887,
      "grad_norm": 2.0284981727600098,
      "learning_rate": 1.6432476763258614e-05,
      "loss": 0.0478,
      "step": 13050
    },
    {
      "epoch": 3.570256971022417,
      "grad_norm": 0.24855180084705353,
      "learning_rate": 1.6429743028977584e-05,
      "loss": 0.0612,
      "step": 13060
    },
    {
      "epoch": 3.5729907053034444,
      "grad_norm": 0.9067977666854858,
      "learning_rate": 1.6427009294696557e-05,
      "loss": 0.0177,
      "step": 13070
    },
    {
      "epoch": 3.5757244395844725,
      "grad_norm": 2.064194917678833,
      "learning_rate": 1.6424275560415527e-05,
      "loss": 0.0389,
      "step": 13080
    },
    {
      "epoch": 3.5784581738655,
      "grad_norm": 0.058985281735658646,
      "learning_rate": 1.64215418261345e-05,
      "loss": 0.0695,
      "step": 13090
    },
    {
      "epoch": 3.581191908146528,
      "grad_norm": 16.44679832458496,
      "learning_rate": 1.6418808091853474e-05,
      "loss": 0.0167,
      "step": 13100
    },
    {
      "epoch": 3.5839256424275563,
      "grad_norm": 0.6673113107681274,
      "learning_rate": 1.6416074357572444e-05,
      "loss": 0.0456,
      "step": 13110
    },
    {
      "epoch": 3.586659376708584,
      "grad_norm": 5.732841968536377,
      "learning_rate": 1.6413340623291417e-05,
      "loss": 0.0446,
      "step": 13120
    },
    {
      "epoch": 3.5893931109896116,
      "grad_norm": 0.2657773494720459,
      "learning_rate": 1.641060688901039e-05,
      "loss": 0.0594,
      "step": 13130
    },
    {
      "epoch": 3.5921268452706396,
      "grad_norm": 0.058543410152196884,
      "learning_rate": 1.640787315472936e-05,
      "loss": 0.0584,
      "step": 13140
    },
    {
      "epoch": 3.5948605795516677,
      "grad_norm": 1.8434972763061523,
      "learning_rate": 1.6405139420448334e-05,
      "loss": 0.0286,
      "step": 13150
    },
    {
      "epoch": 3.5975943138326953,
      "grad_norm": 0.18508195877075195,
      "learning_rate": 1.6402405686167307e-05,
      "loss": 0.0022,
      "step": 13160
    },
    {
      "epoch": 3.6003280481137234,
      "grad_norm": 0.5196493864059448,
      "learning_rate": 1.6399671951886277e-05,
      "loss": 0.0128,
      "step": 13170
    },
    {
      "epoch": 3.603061782394751,
      "grad_norm": 0.03398571535944939,
      "learning_rate": 1.639693821760525e-05,
      "loss": 0.0388,
      "step": 13180
    },
    {
      "epoch": 3.605795516675779,
      "grad_norm": 0.038778841495513916,
      "learning_rate": 1.6394204483324224e-05,
      "loss": 0.0225,
      "step": 13190
    },
    {
      "epoch": 3.608529250956807,
      "grad_norm": 0.00816621258854866,
      "learning_rate": 1.6391470749043194e-05,
      "loss": 0.0572,
      "step": 13200
    },
    {
      "epoch": 3.611262985237835,
      "grad_norm": 0.32595574855804443,
      "learning_rate": 1.6388737014762167e-05,
      "loss": 0.0137,
      "step": 13210
    },
    {
      "epoch": 3.613996719518863,
      "grad_norm": 0.0539441853761673,
      "learning_rate": 1.6386003280481137e-05,
      "loss": 0.0256,
      "step": 13220
    },
    {
      "epoch": 3.6167304537998906,
      "grad_norm": 0.02172471210360527,
      "learning_rate": 1.638326954620011e-05,
      "loss": 0.0396,
      "step": 13230
    },
    {
      "epoch": 3.6194641880809186,
      "grad_norm": 3.0595943927764893,
      "learning_rate": 1.6380535811919084e-05,
      "loss": 0.0574,
      "step": 13240
    },
    {
      "epoch": 3.6221979223619463,
      "grad_norm": 15.246149063110352,
      "learning_rate": 1.6377802077638054e-05,
      "loss": 0.0489,
      "step": 13250
    },
    {
      "epoch": 3.6249316566429743,
      "grad_norm": 0.008450018242001534,
      "learning_rate": 1.6375068343357027e-05,
      "loss": 0.0018,
      "step": 13260
    },
    {
      "epoch": 3.627665390924002,
      "grad_norm": 5.052774906158447,
      "learning_rate": 1.6372334609076e-05,
      "loss": 0.0372,
      "step": 13270
    },
    {
      "epoch": 3.63039912520503,
      "grad_norm": 0.005826882552355528,
      "learning_rate": 1.636960087479497e-05,
      "loss": 0.0373,
      "step": 13280
    },
    {
      "epoch": 3.633132859486058,
      "grad_norm": 0.37314483523368835,
      "learning_rate": 1.6366867140513944e-05,
      "loss": 0.0589,
      "step": 13290
    },
    {
      "epoch": 3.6358665937670858,
      "grad_norm": 0.05341752991080284,
      "learning_rate": 1.6364133406232917e-05,
      "loss": 0.0038,
      "step": 13300
    },
    {
      "epoch": 3.638600328048114,
      "grad_norm": 0.8784862160682678,
      "learning_rate": 1.6361399671951887e-05,
      "loss": 0.0147,
      "step": 13310
    },
    {
      "epoch": 3.6413340623291415,
      "grad_norm": 0.10942010581493378,
      "learning_rate": 1.635866593767086e-05,
      "loss": 0.0088,
      "step": 13320
    },
    {
      "epoch": 3.6440677966101696,
      "grad_norm": 0.3160102367401123,
      "learning_rate": 1.6355932203389834e-05,
      "loss": 0.0316,
      "step": 13330
    },
    {
      "epoch": 3.6468015308911976,
      "grad_norm": 0.004486440680921078,
      "learning_rate": 1.6353198469108804e-05,
      "loss": 0.0012,
      "step": 13340
    },
    {
      "epoch": 3.6495352651722253,
      "grad_norm": 7.880189418792725,
      "learning_rate": 1.6350464734827777e-05,
      "loss": 0.1102,
      "step": 13350
    },
    {
      "epoch": 3.652268999453253,
      "grad_norm": 18.0208797454834,
      "learning_rate": 1.6347731000546747e-05,
      "loss": 0.0669,
      "step": 13360
    },
    {
      "epoch": 3.655002733734281,
      "grad_norm": 0.033590372651815414,
      "learning_rate": 1.634499726626572e-05,
      "loss": 0.0257,
      "step": 13370
    },
    {
      "epoch": 3.657736468015309,
      "grad_norm": 0.014505506493151188,
      "learning_rate": 1.6342263531984694e-05,
      "loss": 0.001,
      "step": 13380
    },
    {
      "epoch": 3.6604702022963367,
      "grad_norm": 0.3848922550678253,
      "learning_rate": 1.6339529797703664e-05,
      "loss": 0.0594,
      "step": 13390
    },
    {
      "epoch": 3.6632039365773648,
      "grad_norm": 2.1580004692077637,
      "learning_rate": 1.6336796063422637e-05,
      "loss": 0.0448,
      "step": 13400
    },
    {
      "epoch": 3.6659376708583924,
      "grad_norm": 4.037026405334473,
      "learning_rate": 1.633406232914161e-05,
      "loss": 0.0456,
      "step": 13410
    },
    {
      "epoch": 3.6686714051394205,
      "grad_norm": 0.17064715921878815,
      "learning_rate": 1.633132859486058e-05,
      "loss": 0.0115,
      "step": 13420
    },
    {
      "epoch": 3.6714051394204485,
      "grad_norm": 0.3781094253063202,
      "learning_rate": 1.632859486057955e-05,
      "loss": 0.0361,
      "step": 13430
    },
    {
      "epoch": 3.674138873701476,
      "grad_norm": 15.524712562561035,
      "learning_rate": 1.6325861126298527e-05,
      "loss": 0.0141,
      "step": 13440
    },
    {
      "epoch": 3.6768726079825043,
      "grad_norm": 0.026454877108335495,
      "learning_rate": 1.6323127392017497e-05,
      "loss": 0.035,
      "step": 13450
    },
    {
      "epoch": 3.679606342263532,
      "grad_norm": 0.38269662857055664,
      "learning_rate": 1.6320393657736467e-05,
      "loss": 0.0408,
      "step": 13460
    },
    {
      "epoch": 3.68234007654456,
      "grad_norm": 0.4804697632789612,
      "learning_rate": 1.6317659923455444e-05,
      "loss": 0.0174,
      "step": 13470
    },
    {
      "epoch": 3.6850738108255876,
      "grad_norm": 0.02200104296207428,
      "learning_rate": 1.6314926189174414e-05,
      "loss": 0.0116,
      "step": 13480
    },
    {
      "epoch": 3.6878075451066157,
      "grad_norm": 6.9771809577941895,
      "learning_rate": 1.6312192454893384e-05,
      "loss": 0.0585,
      "step": 13490
    },
    {
      "epoch": 3.6905412793876433,
      "grad_norm": 0.5180791616439819,
      "learning_rate": 1.630945872061236e-05,
      "loss": 0.1076,
      "step": 13500
    },
    {
      "epoch": 3.6932750136686714,
      "grad_norm": 6.819267749786377,
      "learning_rate": 1.630672498633133e-05,
      "loss": 0.0198,
      "step": 13510
    },
    {
      "epoch": 3.6960087479496995,
      "grad_norm": 0.06035741791129112,
      "learning_rate": 1.63039912520503e-05,
      "loss": 0.0028,
      "step": 13520
    },
    {
      "epoch": 3.698742482230727,
      "grad_norm": 7.132274627685547,
      "learning_rate": 1.6301257517769274e-05,
      "loss": 0.0509,
      "step": 13530
    },
    {
      "epoch": 3.701476216511755,
      "grad_norm": 0.2151913195848465,
      "learning_rate": 1.6298523783488247e-05,
      "loss": 0.0067,
      "step": 13540
    },
    {
      "epoch": 3.704209950792783,
      "grad_norm": 0.0513862781226635,
      "learning_rate": 1.6295790049207217e-05,
      "loss": 0.0714,
      "step": 13550
    },
    {
      "epoch": 3.706943685073811,
      "grad_norm": 1.3118566274642944,
      "learning_rate": 1.629305631492619e-05,
      "loss": 0.0103,
      "step": 13560
    },
    {
      "epoch": 3.709677419354839,
      "grad_norm": 0.004444781690835953,
      "learning_rate": 1.6290322580645164e-05,
      "loss": 0.0279,
      "step": 13570
    },
    {
      "epoch": 3.7124111536358666,
      "grad_norm": 0.31909888982772827,
      "learning_rate": 1.6287588846364134e-05,
      "loss": 0.0406,
      "step": 13580
    },
    {
      "epoch": 3.7151448879168942,
      "grad_norm": 1.3622864484786987,
      "learning_rate": 1.6284855112083107e-05,
      "loss": 0.0615,
      "step": 13590
    },
    {
      "epoch": 3.7178786221979223,
      "grad_norm": 0.00977640226483345,
      "learning_rate": 1.6282121377802077e-05,
      "loss": 0.0412,
      "step": 13600
    },
    {
      "epoch": 3.7206123564789504,
      "grad_norm": 7.2607526779174805,
      "learning_rate": 1.627938764352105e-05,
      "loss": 0.0486,
      "step": 13610
    },
    {
      "epoch": 3.723346090759978,
      "grad_norm": 4.978967189788818,
      "learning_rate": 1.6276653909240024e-05,
      "loss": 0.0655,
      "step": 13620
    },
    {
      "epoch": 3.726079825041006,
      "grad_norm": 0.2473461925983429,
      "learning_rate": 1.6273920174958994e-05,
      "loss": 0.0332,
      "step": 13630
    },
    {
      "epoch": 3.7288135593220337,
      "grad_norm": 1.4199342727661133,
      "learning_rate": 1.6271186440677967e-05,
      "loss": 0.0158,
      "step": 13640
    },
    {
      "epoch": 3.731547293603062,
      "grad_norm": 14.671606063842773,
      "learning_rate": 1.626845270639694e-05,
      "loss": 0.0455,
      "step": 13650
    },
    {
      "epoch": 3.73428102788409,
      "grad_norm": 0.12201596051454544,
      "learning_rate": 1.626571897211591e-05,
      "loss": 0.0904,
      "step": 13660
    },
    {
      "epoch": 3.7370147621651175,
      "grad_norm": 0.4298741817474365,
      "learning_rate": 1.6262985237834884e-05,
      "loss": 0.0293,
      "step": 13670
    },
    {
      "epoch": 3.7397484964461456,
      "grad_norm": 0.026182010769844055,
      "learning_rate": 1.6260251503553857e-05,
      "loss": 0.0025,
      "step": 13680
    },
    {
      "epoch": 3.7424822307271732,
      "grad_norm": 0.007531930226832628,
      "learning_rate": 1.6257517769272827e-05,
      "loss": 0.0139,
      "step": 13690
    },
    {
      "epoch": 3.7452159650082013,
      "grad_norm": 2.6271309852600098,
      "learning_rate": 1.62547840349918e-05,
      "loss": 0.0916,
      "step": 13700
    },
    {
      "epoch": 3.747949699289229,
      "grad_norm": 6.698622226715088,
      "learning_rate": 1.6252050300710774e-05,
      "loss": 0.0349,
      "step": 13710
    },
    {
      "epoch": 3.750683433570257,
      "grad_norm": 0.2721571922302246,
      "learning_rate": 1.6249316566429744e-05,
      "loss": 0.0186,
      "step": 13720
    },
    {
      "epoch": 3.7534171678512847,
      "grad_norm": 0.03589801862835884,
      "learning_rate": 1.6246582832148717e-05,
      "loss": 0.0502,
      "step": 13730
    },
    {
      "epoch": 3.7561509021323127,
      "grad_norm": 0.24442990124225616,
      "learning_rate": 1.6243849097867687e-05,
      "loss": 0.0177,
      "step": 13740
    },
    {
      "epoch": 3.758884636413341,
      "grad_norm": 0.7750478386878967,
      "learning_rate": 1.624111536358666e-05,
      "loss": 0.0707,
      "step": 13750
    },
    {
      "epoch": 3.7616183706943684,
      "grad_norm": 0.5630428791046143,
      "learning_rate": 1.6238381629305634e-05,
      "loss": 0.0166,
      "step": 13760
    },
    {
      "epoch": 3.7643521049753965,
      "grad_norm": 0.05920202657580376,
      "learning_rate": 1.6235647895024604e-05,
      "loss": 0.0171,
      "step": 13770
    },
    {
      "epoch": 3.767085839256424,
      "grad_norm": 0.02834397740662098,
      "learning_rate": 1.6232914160743577e-05,
      "loss": 0.0508,
      "step": 13780
    },
    {
      "epoch": 3.7698195735374522,
      "grad_norm": 0.1985243707895279,
      "learning_rate": 1.623018042646255e-05,
      "loss": 0.0086,
      "step": 13790
    },
    {
      "epoch": 3.7725533078184803,
      "grad_norm": 0.37798333168029785,
      "learning_rate": 1.622744669218152e-05,
      "loss": 0.0212,
      "step": 13800
    },
    {
      "epoch": 3.775287042099508,
      "grad_norm": 2.993048667907715,
      "learning_rate": 1.6224712957900494e-05,
      "loss": 0.0166,
      "step": 13810
    },
    {
      "epoch": 3.7780207763805356,
      "grad_norm": 2.606635332107544,
      "learning_rate": 1.6221979223619467e-05,
      "loss": 0.0365,
      "step": 13820
    },
    {
      "epoch": 3.7807545106615636,
      "grad_norm": 0.31310924887657166,
      "learning_rate": 1.6219245489338437e-05,
      "loss": 0.0556,
      "step": 13830
    },
    {
      "epoch": 3.7834882449425917,
      "grad_norm": 0.9070329666137695,
      "learning_rate": 1.621651175505741e-05,
      "loss": 0.0107,
      "step": 13840
    },
    {
      "epoch": 3.7862219792236194,
      "grad_norm": 3.6626033782958984,
      "learning_rate": 1.6213778020776384e-05,
      "loss": 0.0184,
      "step": 13850
    },
    {
      "epoch": 3.7889557135046474,
      "grad_norm": 1.5358532667160034,
      "learning_rate": 1.6211044286495354e-05,
      "loss": 0.0227,
      "step": 13860
    },
    {
      "epoch": 3.791689447785675,
      "grad_norm": 0.025283318012952805,
      "learning_rate": 1.6208310552214327e-05,
      "loss": 0.0071,
      "step": 13870
    },
    {
      "epoch": 3.794423182066703,
      "grad_norm": 0.0485512875020504,
      "learning_rate": 1.6205576817933297e-05,
      "loss": 0.0034,
      "step": 13880
    },
    {
      "epoch": 3.7971569163477312,
      "grad_norm": 0.008365773595869541,
      "learning_rate": 1.620284308365227e-05,
      "loss": 0.0812,
      "step": 13890
    },
    {
      "epoch": 3.799890650628759,
      "grad_norm": 0.007903390564024448,
      "learning_rate": 1.6200109349371244e-05,
      "loss": 0.0861,
      "step": 13900
    },
    {
      "epoch": 3.8026243849097865,
      "grad_norm": 0.10532253235578537,
      "learning_rate": 1.6197375615090214e-05,
      "loss": 0.0579,
      "step": 13910
    },
    {
      "epoch": 3.8053581191908146,
      "grad_norm": 0.13674356043338776,
      "learning_rate": 1.6194641880809187e-05,
      "loss": 0.0454,
      "step": 13920
    },
    {
      "epoch": 3.8080918534718426,
      "grad_norm": 0.021284151822328568,
      "learning_rate": 1.619190814652816e-05,
      "loss": 0.0125,
      "step": 13930
    },
    {
      "epoch": 3.8108255877528703,
      "grad_norm": 0.033373646438121796,
      "learning_rate": 1.618917441224713e-05,
      "loss": 0.0477,
      "step": 13940
    },
    {
      "epoch": 3.8135593220338984,
      "grad_norm": 0.04501922056078911,
      "learning_rate": 1.6186440677966104e-05,
      "loss": 0.0165,
      "step": 13950
    },
    {
      "epoch": 3.816293056314926,
      "grad_norm": 0.1104467585682869,
      "learning_rate": 1.6183706943685077e-05,
      "loss": 0.0109,
      "step": 13960
    },
    {
      "epoch": 3.819026790595954,
      "grad_norm": 3.0326180458068848,
      "learning_rate": 1.6180973209404047e-05,
      "loss": 0.0595,
      "step": 13970
    },
    {
      "epoch": 3.821760524876982,
      "grad_norm": 0.30944186449050903,
      "learning_rate": 1.617823947512302e-05,
      "loss": 0.0535,
      "step": 13980
    },
    {
      "epoch": 3.82449425915801,
      "grad_norm": 0.030102793127298355,
      "learning_rate": 1.6175505740841994e-05,
      "loss": 0.0238,
      "step": 13990
    },
    {
      "epoch": 3.827227993439038,
      "grad_norm": 2.440002918243408,
      "learning_rate": 1.6172772006560964e-05,
      "loss": 0.0361,
      "step": 14000
    },
    {
      "epoch": 3.8299617277200655,
      "grad_norm": 0.026375947520136833,
      "learning_rate": 1.6170038272279937e-05,
      "loss": 0.0209,
      "step": 14010
    },
    {
      "epoch": 3.8326954620010936,
      "grad_norm": 18.433740615844727,
      "learning_rate": 1.6167304537998907e-05,
      "loss": 0.0439,
      "step": 14020
    },
    {
      "epoch": 3.8354291962821216,
      "grad_norm": 4.43791389465332,
      "learning_rate": 1.616457080371788e-05,
      "loss": 0.055,
      "step": 14030
    },
    {
      "epoch": 3.8381629305631493,
      "grad_norm": 0.07626629620790482,
      "learning_rate": 1.6161837069436854e-05,
      "loss": 0.0143,
      "step": 14040
    },
    {
      "epoch": 3.840896664844177,
      "grad_norm": 0.031079791486263275,
      "learning_rate": 1.6159103335155823e-05,
      "loss": 0.0247,
      "step": 14050
    },
    {
      "epoch": 3.843630399125205,
      "grad_norm": 25.484310150146484,
      "learning_rate": 1.6156369600874797e-05,
      "loss": 0.0125,
      "step": 14060
    },
    {
      "epoch": 3.846364133406233,
      "grad_norm": 1.8441619873046875,
      "learning_rate": 1.615363586659377e-05,
      "loss": 0.0874,
      "step": 14070
    },
    {
      "epoch": 3.8490978676872607,
      "grad_norm": 0.08497390896081924,
      "learning_rate": 1.615090213231274e-05,
      "loss": 0.0089,
      "step": 14080
    },
    {
      "epoch": 3.8518316019682888,
      "grad_norm": 7.661189556121826,
      "learning_rate": 1.614816839803171e-05,
      "loss": 0.0794,
      "step": 14090
    },
    {
      "epoch": 3.8545653362493164,
      "grad_norm": 0.0266477782279253,
      "learning_rate": 1.6145434663750687e-05,
      "loss": 0.0375,
      "step": 14100
    },
    {
      "epoch": 3.8572990705303445,
      "grad_norm": 0.13762925565242767,
      "learning_rate": 1.6142700929469657e-05,
      "loss": 0.0249,
      "step": 14110
    },
    {
      "epoch": 3.8600328048113726,
      "grad_norm": 0.1392548531293869,
      "learning_rate": 1.6139967195188627e-05,
      "loss": 0.0293,
      "step": 14120
    },
    {
      "epoch": 3.8627665390924,
      "grad_norm": 0.049122076481580734,
      "learning_rate": 1.6137233460907604e-05,
      "loss": 0.0323,
      "step": 14130
    },
    {
      "epoch": 3.865500273373428,
      "grad_norm": 2.931933641433716,
      "learning_rate": 1.6134499726626573e-05,
      "loss": 0.0409,
      "step": 14140
    },
    {
      "epoch": 3.868234007654456,
      "grad_norm": 0.06922557204961777,
      "learning_rate": 1.6131765992345543e-05,
      "loss": 0.0437,
      "step": 14150
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.023632464930415154,
      "learning_rate": 1.6129032258064517e-05,
      "loss": 0.0334,
      "step": 14160
    },
    {
      "epoch": 3.8737014762165116,
      "grad_norm": 0.02135167084634304,
      "learning_rate": 1.612629852378349e-05,
      "loss": 0.0141,
      "step": 14170
    },
    {
      "epoch": 3.8764352104975397,
      "grad_norm": 0.019708722829818726,
      "learning_rate": 1.612356478950246e-05,
      "loss": 0.0026,
      "step": 14180
    },
    {
      "epoch": 3.8791689447785673,
      "grad_norm": 0.04195772111415863,
      "learning_rate": 1.6120831055221433e-05,
      "loss": 0.0421,
      "step": 14190
    },
    {
      "epoch": 3.8819026790595954,
      "grad_norm": 0.02629854902625084,
      "learning_rate": 1.6118097320940407e-05,
      "loss": 0.0327,
      "step": 14200
    },
    {
      "epoch": 3.8846364133406235,
      "grad_norm": 0.03543063625693321,
      "learning_rate": 1.6115363586659377e-05,
      "loss": 0.0483,
      "step": 14210
    },
    {
      "epoch": 3.887370147621651,
      "grad_norm": 0.10413223505020142,
      "learning_rate": 1.611262985237835e-05,
      "loss": 0.0589,
      "step": 14220
    },
    {
      "epoch": 3.890103881902679,
      "grad_norm": 0.048330504447221756,
      "learning_rate": 1.610989611809732e-05,
      "loss": 0.003,
      "step": 14230
    },
    {
      "epoch": 3.892837616183707,
      "grad_norm": 0.02389327622950077,
      "learning_rate": 1.6107162383816293e-05,
      "loss": 0.0024,
      "step": 14240
    },
    {
      "epoch": 3.895571350464735,
      "grad_norm": 0.024499397724866867,
      "learning_rate": 1.6104428649535267e-05,
      "loss": 0.0023,
      "step": 14250
    },
    {
      "epoch": 3.898305084745763,
      "grad_norm": 0.016570808365941048,
      "learning_rate": 1.6101694915254237e-05,
      "loss": 0.0191,
      "step": 14260
    },
    {
      "epoch": 3.9010388190267906,
      "grad_norm": 0.01757846213877201,
      "learning_rate": 1.609896118097321e-05,
      "loss": 0.0043,
      "step": 14270
    },
    {
      "epoch": 3.9037725533078182,
      "grad_norm": 2.577709197998047,
      "learning_rate": 1.6096227446692183e-05,
      "loss": 0.0221,
      "step": 14280
    },
    {
      "epoch": 3.9065062875888463,
      "grad_norm": 0.005536849144846201,
      "learning_rate": 1.6093493712411153e-05,
      "loss": 0.0703,
      "step": 14290
    },
    {
      "epoch": 3.9092400218698744,
      "grad_norm": 1.258134126663208,
      "learning_rate": 1.6090759978130127e-05,
      "loss": 0.0419,
      "step": 14300
    },
    {
      "epoch": 3.911973756150902,
      "grad_norm": 0.11669333279132843,
      "learning_rate": 1.60880262438491e-05,
      "loss": 0.0202,
      "step": 14310
    },
    {
      "epoch": 3.91470749043193,
      "grad_norm": 10.259221076965332,
      "learning_rate": 1.608529250956807e-05,
      "loss": 0.0782,
      "step": 14320
    },
    {
      "epoch": 3.9174412247129577,
      "grad_norm": 7.24513578414917,
      "learning_rate": 1.6082558775287043e-05,
      "loss": 0.0315,
      "step": 14330
    },
    {
      "epoch": 3.920174958993986,
      "grad_norm": 0.4156194031238556,
      "learning_rate": 1.6079825041006017e-05,
      "loss": 0.0109,
      "step": 14340
    },
    {
      "epoch": 3.922908693275014,
      "grad_norm": 0.01904076524078846,
      "learning_rate": 1.6077091306724987e-05,
      "loss": 0.0081,
      "step": 14350
    },
    {
      "epoch": 3.9256424275560415,
      "grad_norm": 0.023609057068824768,
      "learning_rate": 1.607435757244396e-05,
      "loss": 0.0159,
      "step": 14360
    },
    {
      "epoch": 3.928376161837069,
      "grad_norm": 0.011737629771232605,
      "learning_rate": 1.607162383816293e-05,
      "loss": 0.0239,
      "step": 14370
    },
    {
      "epoch": 3.9311098961180972,
      "grad_norm": 1.235966682434082,
      "learning_rate": 1.6068890103881903e-05,
      "loss": 0.0342,
      "step": 14380
    },
    {
      "epoch": 3.9338436303991253,
      "grad_norm": 1.671063780784607,
      "learning_rate": 1.6066156369600877e-05,
      "loss": 0.03,
      "step": 14390
    },
    {
      "epoch": 3.936577364680153,
      "grad_norm": 0.010608086362481117,
      "learning_rate": 1.6063422635319847e-05,
      "loss": 0.075,
      "step": 14400
    },
    {
      "epoch": 3.939311098961181,
      "grad_norm": 0.12292488664388657,
      "learning_rate": 1.606068890103882e-05,
      "loss": 0.0331,
      "step": 14410
    },
    {
      "epoch": 3.9420448332422087,
      "grad_norm": 0.20292271673679352,
      "learning_rate": 1.6057955166757793e-05,
      "loss": 0.0441,
      "step": 14420
    },
    {
      "epoch": 3.9447785675232367,
      "grad_norm": 0.03651244565844536,
      "learning_rate": 1.6055221432476763e-05,
      "loss": 0.0091,
      "step": 14430
    },
    {
      "epoch": 3.947512301804265,
      "grad_norm": 0.14603421092033386,
      "learning_rate": 1.6052487698195737e-05,
      "loss": 0.0079,
      "step": 14440
    },
    {
      "epoch": 3.9502460360852925,
      "grad_norm": 7.128701686859131,
      "learning_rate": 1.604975396391471e-05,
      "loss": 0.0567,
      "step": 14450
    },
    {
      "epoch": 3.9529797703663205,
      "grad_norm": 18.823291778564453,
      "learning_rate": 1.604702022963368e-05,
      "loss": 0.0525,
      "step": 14460
    },
    {
      "epoch": 3.955713504647348,
      "grad_norm": 0.9646340012550354,
      "learning_rate": 1.6044286495352653e-05,
      "loss": 0.0432,
      "step": 14470
    },
    {
      "epoch": 3.9584472389283762,
      "grad_norm": 0.03406064212322235,
      "learning_rate": 1.6041552761071627e-05,
      "loss": 0.0109,
      "step": 14480
    },
    {
      "epoch": 3.9611809732094043,
      "grad_norm": 0.1455652117729187,
      "learning_rate": 1.6038819026790597e-05,
      "loss": 0.011,
      "step": 14490
    },
    {
      "epoch": 3.963914707490432,
      "grad_norm": 0.020958509296178818,
      "learning_rate": 1.603608529250957e-05,
      "loss": 0.0633,
      "step": 14500
    },
    {
      "epoch": 3.9666484417714596,
      "grad_norm": 0.016991689801216125,
      "learning_rate": 1.603335155822854e-05,
      "loss": 0.0389,
      "step": 14510
    },
    {
      "epoch": 3.9693821760524877,
      "grad_norm": 0.03479921072721481,
      "learning_rate": 1.6030617823947513e-05,
      "loss": 0.0082,
      "step": 14520
    },
    {
      "epoch": 3.9721159103335157,
      "grad_norm": 0.013649238273501396,
      "learning_rate": 1.6027884089666487e-05,
      "loss": 0.0104,
      "step": 14530
    },
    {
      "epoch": 3.9748496446145434,
      "grad_norm": 0.014903740957379341,
      "learning_rate": 1.6025150355385457e-05,
      "loss": 0.0432,
      "step": 14540
    },
    {
      "epoch": 3.9775833788955715,
      "grad_norm": 1.5298991203308105,
      "learning_rate": 1.602241662110443e-05,
      "loss": 0.0498,
      "step": 14550
    },
    {
      "epoch": 3.980317113176599,
      "grad_norm": 0.036315128207206726,
      "learning_rate": 1.6019682886823403e-05,
      "loss": 0.0395,
      "step": 14560
    },
    {
      "epoch": 3.983050847457627,
      "grad_norm": 0.023093372583389282,
      "learning_rate": 1.6016949152542373e-05,
      "loss": 0.0239,
      "step": 14570
    },
    {
      "epoch": 3.9857845817386552,
      "grad_norm": 0.7716279029846191,
      "learning_rate": 1.6014215418261347e-05,
      "loss": 0.0097,
      "step": 14580
    },
    {
      "epoch": 3.988518316019683,
      "grad_norm": 3.9851951599121094,
      "learning_rate": 1.601148168398032e-05,
      "loss": 0.0679,
      "step": 14590
    },
    {
      "epoch": 3.9912520503007105,
      "grad_norm": 4.954869270324707,
      "learning_rate": 1.600874794969929e-05,
      "loss": 0.0224,
      "step": 14600
    },
    {
      "epoch": 3.9939857845817386,
      "grad_norm": 1.8127256631851196,
      "learning_rate": 1.6006014215418263e-05,
      "loss": 0.0443,
      "step": 14610
    },
    {
      "epoch": 3.9967195188627667,
      "grad_norm": 0.29553335905075073,
      "learning_rate": 1.6003280481137237e-05,
      "loss": 0.0221,
      "step": 14620
    },
    {
      "epoch": 3.9994532531437943,
      "grad_norm": 0.018231209367513657,
      "learning_rate": 1.6000546746856207e-05,
      "loss": 0.022,
      "step": 14630
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9896764580672627,
      "eval_f1": 0.958845990666101,
      "eval_loss": 0.035976797342300415,
      "eval_precision": 0.9531843104175454,
      "eval_recall": 0.9645753307725139,
      "eval_runtime": 795.5057,
      "eval_samples_per_second": 23.65,
      "eval_steps_per_second": 0.986,
      "step": 14632
    },
    {
      "epoch": 4.002186987424822,
      "grad_norm": 0.10848229378461838,
      "learning_rate": 1.599781301257518e-05,
      "loss": 0.0263,
      "step": 14640
    },
    {
      "epoch": 4.00492072170585,
      "grad_norm": 0.06549239903688431,
      "learning_rate": 1.5995079278294153e-05,
      "loss": 0.0161,
      "step": 14650
    },
    {
      "epoch": 4.007654455986878,
      "grad_norm": 0.007181822322309017,
      "learning_rate": 1.5992345544013123e-05,
      "loss": 0.0099,
      "step": 14660
    },
    {
      "epoch": 4.010388190267906,
      "grad_norm": 0.011988168582320213,
      "learning_rate": 1.5989611809732097e-05,
      "loss": 0.0345,
      "step": 14670
    },
    {
      "epoch": 4.013121924548934,
      "grad_norm": 0.027217335999011993,
      "learning_rate": 1.5986878075451067e-05,
      "loss": 0.0357,
      "step": 14680
    },
    {
      "epoch": 4.015855658829961,
      "grad_norm": 0.01802493818104267,
      "learning_rate": 1.598414434117004e-05,
      "loss": 0.0298,
      "step": 14690
    },
    {
      "epoch": 4.0185893931109895,
      "grad_norm": 0.007197210565209389,
      "learning_rate": 1.5981410606889013e-05,
      "loss": 0.0234,
      "step": 14700
    },
    {
      "epoch": 4.021323127392018,
      "grad_norm": 0.018850522115826607,
      "learning_rate": 1.5978676872607983e-05,
      "loss": 0.0028,
      "step": 14710
    },
    {
      "epoch": 4.024056861673046,
      "grad_norm": 0.4556870460510254,
      "learning_rate": 1.5975943138326957e-05,
      "loss": 0.0216,
      "step": 14720
    },
    {
      "epoch": 4.026790595954073,
      "grad_norm": 0.02647531032562256,
      "learning_rate": 1.597320940404593e-05,
      "loss": 0.0362,
      "step": 14730
    },
    {
      "epoch": 4.029524330235101,
      "grad_norm": 0.03237416595220566,
      "learning_rate": 1.59704756697649e-05,
      "loss": 0.0597,
      "step": 14740
    },
    {
      "epoch": 4.032258064516129,
      "grad_norm": 0.049205340445041656,
      "learning_rate": 1.596774193548387e-05,
      "loss": 0.0566,
      "step": 14750
    },
    {
      "epoch": 4.034991798797157,
      "grad_norm": 0.7303090691566467,
      "learning_rate": 1.5965008201202847e-05,
      "loss": 0.0087,
      "step": 14760
    },
    {
      "epoch": 4.037725533078185,
      "grad_norm": 0.15850399434566498,
      "learning_rate": 1.5962274466921817e-05,
      "loss": 0.019,
      "step": 14770
    },
    {
      "epoch": 4.040459267359212,
      "grad_norm": 7.021432876586914,
      "learning_rate": 1.5959540732640787e-05,
      "loss": 0.0476,
      "step": 14780
    },
    {
      "epoch": 4.04319300164024,
      "grad_norm": 0.012231942266225815,
      "learning_rate": 1.5956806998359763e-05,
      "loss": 0.0035,
      "step": 14790
    },
    {
      "epoch": 4.0459267359212685,
      "grad_norm": 0.017280003055930138,
      "learning_rate": 1.5954073264078733e-05,
      "loss": 0.004,
      "step": 14800
    },
    {
      "epoch": 4.048660470202297,
      "grad_norm": 0.2974083423614502,
      "learning_rate": 1.5951339529797703e-05,
      "loss": 0.0064,
      "step": 14810
    },
    {
      "epoch": 4.051394204483325,
      "grad_norm": 0.009817895479500294,
      "learning_rate": 1.5948605795516677e-05,
      "loss": 0.0256,
      "step": 14820
    },
    {
      "epoch": 4.054127938764352,
      "grad_norm": 0.004531397949904203,
      "learning_rate": 1.594587206123565e-05,
      "loss": 0.0042,
      "step": 14830
    },
    {
      "epoch": 4.05686167304538,
      "grad_norm": 5.905909061431885,
      "learning_rate": 1.594313832695462e-05,
      "loss": 0.0433,
      "step": 14840
    },
    {
      "epoch": 4.059595407326408,
      "grad_norm": 0.01698651723563671,
      "learning_rate": 1.5940404592673593e-05,
      "loss": 0.0188,
      "step": 14850
    },
    {
      "epoch": 4.062329141607436,
      "grad_norm": 0.004350060597062111,
      "learning_rate": 1.5937670858392567e-05,
      "loss": 0.0214,
      "step": 14860
    },
    {
      "epoch": 4.065062875888463,
      "grad_norm": 0.043763283640146255,
      "learning_rate": 1.5934937124111537e-05,
      "loss": 0.0752,
      "step": 14870
    },
    {
      "epoch": 4.067796610169491,
      "grad_norm": 2.6643636226654053,
      "learning_rate": 1.593220338983051e-05,
      "loss": 0.0123,
      "step": 14880
    },
    {
      "epoch": 4.070530344450519,
      "grad_norm": 0.04029327630996704,
      "learning_rate": 1.592946965554948e-05,
      "loss": 0.0101,
      "step": 14890
    },
    {
      "epoch": 4.0732640787315475,
      "grad_norm": 1.1050710678100586,
      "learning_rate": 1.5926735921268453e-05,
      "loss": 0.0119,
      "step": 14900
    },
    {
      "epoch": 4.075997813012576,
      "grad_norm": 0.010399313643574715,
      "learning_rate": 1.5924002186987427e-05,
      "loss": 0.0161,
      "step": 14910
    },
    {
      "epoch": 4.078731547293603,
      "grad_norm": 0.017496585845947266,
      "learning_rate": 1.5921268452706397e-05,
      "loss": 0.0216,
      "step": 14920
    },
    {
      "epoch": 4.081465281574631,
      "grad_norm": 0.07736174762248993,
      "learning_rate": 1.591853471842537e-05,
      "loss": 0.0323,
      "step": 14930
    },
    {
      "epoch": 4.084199015855659,
      "grad_norm": 0.001307866652496159,
      "learning_rate": 1.5915800984144343e-05,
      "loss": 0.0031,
      "step": 14940
    },
    {
      "epoch": 4.086932750136687,
      "grad_norm": 4.643521308898926,
      "learning_rate": 1.5913067249863313e-05,
      "loss": 0.0244,
      "step": 14950
    },
    {
      "epoch": 4.089666484417714,
      "grad_norm": 0.03810415789484978,
      "learning_rate": 1.5910333515582287e-05,
      "loss": 0.0051,
      "step": 14960
    },
    {
      "epoch": 4.092400218698742,
      "grad_norm": 4.635673999786377,
      "learning_rate": 1.590759978130126e-05,
      "loss": 0.0024,
      "step": 14970
    },
    {
      "epoch": 4.09513395297977,
      "grad_norm": 1.0396441221237183,
      "learning_rate": 1.590486604702023e-05,
      "loss": 0.0358,
      "step": 14980
    },
    {
      "epoch": 4.097867687260798,
      "grad_norm": 0.031354427337646484,
      "learning_rate": 1.5902132312739203e-05,
      "loss": 0.0626,
      "step": 14990
    },
    {
      "epoch": 4.1006014215418265,
      "grad_norm": 5.77264928817749,
      "learning_rate": 1.5899398578458177e-05,
      "loss": 0.058,
      "step": 15000
    },
    {
      "epoch": 4.103335155822854,
      "grad_norm": 3.1416354179382324,
      "learning_rate": 1.5896664844177147e-05,
      "loss": 0.0383,
      "step": 15010
    },
    {
      "epoch": 4.106068890103882,
      "grad_norm": 3.6531200408935547,
      "learning_rate": 1.589393110989612e-05,
      "loss": 0.0983,
      "step": 15020
    },
    {
      "epoch": 4.10880262438491,
      "grad_norm": 0.26067471504211426,
      "learning_rate": 1.589119737561509e-05,
      "loss": 0.0659,
      "step": 15030
    },
    {
      "epoch": 4.111536358665938,
      "grad_norm": 1.7139233350753784,
      "learning_rate": 1.5888463641334063e-05,
      "loss": 0.017,
      "step": 15040
    },
    {
      "epoch": 4.114270092946965,
      "grad_norm": 0.03355233371257782,
      "learning_rate": 1.5885729907053037e-05,
      "loss": 0.0628,
      "step": 15050
    },
    {
      "epoch": 4.117003827227993,
      "grad_norm": 0.023453859612345695,
      "learning_rate": 1.5882996172772006e-05,
      "loss": 0.0171,
      "step": 15060
    },
    {
      "epoch": 4.119737561509021,
      "grad_norm": 0.49680790305137634,
      "learning_rate": 1.588026243849098e-05,
      "loss": 0.0046,
      "step": 15070
    },
    {
      "epoch": 4.122471295790049,
      "grad_norm": 0.006671804469078779,
      "learning_rate": 1.5877528704209953e-05,
      "loss": 0.0008,
      "step": 15080
    },
    {
      "epoch": 4.125205030071077,
      "grad_norm": 0.04819997772574425,
      "learning_rate": 1.5874794969928923e-05,
      "loss": 0.0725,
      "step": 15090
    },
    {
      "epoch": 4.127938764352105,
      "grad_norm": 3.2112088203430176,
      "learning_rate": 1.5872061235647896e-05,
      "loss": 0.0426,
      "step": 15100
    },
    {
      "epoch": 4.130672498633133,
      "grad_norm": 0.057323455810546875,
      "learning_rate": 1.586932750136687e-05,
      "loss": 0.0178,
      "step": 15110
    },
    {
      "epoch": 4.133406232914161,
      "grad_norm": 0.01001804694533348,
      "learning_rate": 1.586659376708584e-05,
      "loss": 0.0201,
      "step": 15120
    },
    {
      "epoch": 4.136139967195189,
      "grad_norm": 0.012804901227355003,
      "learning_rate": 1.5863860032804813e-05,
      "loss": 0.0086,
      "step": 15130
    },
    {
      "epoch": 4.138873701476217,
      "grad_norm": 0.008754802867770195,
      "learning_rate": 1.5861126298523786e-05,
      "loss": 0.0246,
      "step": 15140
    },
    {
      "epoch": 4.141607435757244,
      "grad_norm": 0.008854486048221588,
      "learning_rate": 1.5858392564242756e-05,
      "loss": 0.0018,
      "step": 15150
    },
    {
      "epoch": 4.144341170038272,
      "grad_norm": 0.05001532658934593,
      "learning_rate": 1.585565882996173e-05,
      "loss": 0.0194,
      "step": 15160
    },
    {
      "epoch": 4.1470749043193,
      "grad_norm": 0.6256678104400635,
      "learning_rate": 1.58529250956807e-05,
      "loss": 0.0572,
      "step": 15170
    },
    {
      "epoch": 4.149808638600328,
      "grad_norm": 3.064943313598633,
      "learning_rate": 1.5850191361399673e-05,
      "loss": 0.0708,
      "step": 15180
    },
    {
      "epoch": 4.1525423728813555,
      "grad_norm": 0.020854013040661812,
      "learning_rate": 1.5847457627118646e-05,
      "loss": 0.0235,
      "step": 15190
    },
    {
      "epoch": 4.155276107162384,
      "grad_norm": 4.714365005493164,
      "learning_rate": 1.5844723892837616e-05,
      "loss": 0.0116,
      "step": 15200
    },
    {
      "epoch": 4.158009841443412,
      "grad_norm": 0.5929773449897766,
      "learning_rate": 1.584199015855659e-05,
      "loss": 0.0073,
      "step": 15210
    },
    {
      "epoch": 4.16074357572444,
      "grad_norm": 0.0084011759608984,
      "learning_rate": 1.5839256424275563e-05,
      "loss": 0.0006,
      "step": 15220
    },
    {
      "epoch": 4.163477310005468,
      "grad_norm": 0.008829248137772083,
      "learning_rate": 1.5836522689994533e-05,
      "loss": 0.0387,
      "step": 15230
    },
    {
      "epoch": 4.166211044286495,
      "grad_norm": 0.01710817962884903,
      "learning_rate": 1.5833788955713506e-05,
      "loss": 0.0066,
      "step": 15240
    },
    {
      "epoch": 4.168944778567523,
      "grad_norm": 0.023411903530359268,
      "learning_rate": 1.583105522143248e-05,
      "loss": 0.0178,
      "step": 15250
    },
    {
      "epoch": 4.171678512848551,
      "grad_norm": 1.7771466970443726,
      "learning_rate": 1.582832148715145e-05,
      "loss": 0.0234,
      "step": 15260
    },
    {
      "epoch": 4.174412247129579,
      "grad_norm": 1.840275764465332,
      "learning_rate": 1.5825587752870423e-05,
      "loss": 0.0208,
      "step": 15270
    },
    {
      "epoch": 4.177145981410607,
      "grad_norm": 0.6088808178901672,
      "learning_rate": 1.5822854018589396e-05,
      "loss": 0.0052,
      "step": 15280
    },
    {
      "epoch": 4.1798797156916345,
      "grad_norm": 0.002398625249043107,
      "learning_rate": 1.5820120284308366e-05,
      "loss": 0.0069,
      "step": 15290
    },
    {
      "epoch": 4.182613449972663,
      "grad_norm": 0.2948094606399536,
      "learning_rate": 1.581738655002734e-05,
      "loss": 0.0212,
      "step": 15300
    },
    {
      "epoch": 4.185347184253691,
      "grad_norm": 0.006063149310648441,
      "learning_rate": 1.581465281574631e-05,
      "loss": 0.0024,
      "step": 15310
    },
    {
      "epoch": 4.188080918534719,
      "grad_norm": 0.059475235641002655,
      "learning_rate": 1.5811919081465283e-05,
      "loss": 0.0084,
      "step": 15320
    },
    {
      "epoch": 4.190814652815746,
      "grad_norm": 0.05629422515630722,
      "learning_rate": 1.5809185347184256e-05,
      "loss": 0.0005,
      "step": 15330
    },
    {
      "epoch": 4.193548387096774,
      "grad_norm": 0.008092052303254604,
      "learning_rate": 1.5806451612903226e-05,
      "loss": 0.0015,
      "step": 15340
    },
    {
      "epoch": 4.196282121377802,
      "grad_norm": 0.003053249092772603,
      "learning_rate": 1.58037178786222e-05,
      "loss": 0.0438,
      "step": 15350
    },
    {
      "epoch": 4.19901585565883,
      "grad_norm": 0.01869024895131588,
      "learning_rate": 1.5800984144341173e-05,
      "loss": 0.0003,
      "step": 15360
    },
    {
      "epoch": 4.201749589939858,
      "grad_norm": 0.023185214027762413,
      "learning_rate": 1.5798250410060143e-05,
      "loss": 0.003,
      "step": 15370
    },
    {
      "epoch": 4.204483324220885,
      "grad_norm": 1.331695556640625,
      "learning_rate": 1.5795516675779113e-05,
      "loss": 0.0459,
      "step": 15380
    },
    {
      "epoch": 4.2072170585019135,
      "grad_norm": 0.07539083063602448,
      "learning_rate": 1.579278294149809e-05,
      "loss": 0.0054,
      "step": 15390
    },
    {
      "epoch": 4.209950792782942,
      "grad_norm": 0.002136910567060113,
      "learning_rate": 1.579004920721706e-05,
      "loss": 0.0035,
      "step": 15400
    },
    {
      "epoch": 4.21268452706397,
      "grad_norm": 0.18170690536499023,
      "learning_rate": 1.578731547293603e-05,
      "loss": 0.0195,
      "step": 15410
    },
    {
      "epoch": 4.215418261344997,
      "grad_norm": 0.026366380974650383,
      "learning_rate": 1.5784581738655006e-05,
      "loss": 0.03,
      "step": 15420
    },
    {
      "epoch": 4.218151995626025,
      "grad_norm": 1.1889262199401855,
      "learning_rate": 1.5781848004373976e-05,
      "loss": 0.0565,
      "step": 15430
    },
    {
      "epoch": 4.220885729907053,
      "grad_norm": 1.3028239011764526,
      "learning_rate": 1.5779114270092946e-05,
      "loss": 0.0075,
      "step": 15440
    },
    {
      "epoch": 4.223619464188081,
      "grad_norm": 0.8720467686653137,
      "learning_rate": 1.577638053581192e-05,
      "loss": 0.0341,
      "step": 15450
    },
    {
      "epoch": 4.226353198469109,
      "grad_norm": 0.09852283447980881,
      "learning_rate": 1.5773646801530893e-05,
      "loss": 0.0732,
      "step": 15460
    },
    {
      "epoch": 4.229086932750136,
      "grad_norm": 0.011104822158813477,
      "learning_rate": 1.5770913067249863e-05,
      "loss": 0.0061,
      "step": 15470
    },
    {
      "epoch": 4.231820667031164,
      "grad_norm": 0.013747316785156727,
      "learning_rate": 1.5768179332968836e-05,
      "loss": 0.0076,
      "step": 15480
    },
    {
      "epoch": 4.2345544013121925,
      "grad_norm": 3.7335095405578613,
      "learning_rate": 1.576544559868781e-05,
      "loss": 0.0131,
      "step": 15490
    },
    {
      "epoch": 4.237288135593221,
      "grad_norm": 1.5924208164215088,
      "learning_rate": 1.576271186440678e-05,
      "loss": 0.0267,
      "step": 15500
    },
    {
      "epoch": 4.240021869874248,
      "grad_norm": 0.014706659130752087,
      "learning_rate": 1.5759978130125753e-05,
      "loss": 0.0078,
      "step": 15510
    },
    {
      "epoch": 4.242755604155276,
      "grad_norm": 0.01751282811164856,
      "learning_rate": 1.5757244395844723e-05,
      "loss": 0.0674,
      "step": 15520
    },
    {
      "epoch": 4.245489338436304,
      "grad_norm": 0.12467973679304123,
      "learning_rate": 1.5754510661563696e-05,
      "loss": 0.0343,
      "step": 15530
    },
    {
      "epoch": 4.248223072717332,
      "grad_norm": 0.003266777377575636,
      "learning_rate": 1.575177692728267e-05,
      "loss": 0.0265,
      "step": 15540
    },
    {
      "epoch": 4.25095680699836,
      "grad_norm": 0.16530682146549225,
      "learning_rate": 1.574904319300164e-05,
      "loss": 0.0061,
      "step": 15550
    },
    {
      "epoch": 4.253690541279387,
      "grad_norm": 0.003312045242637396,
      "learning_rate": 1.5746309458720613e-05,
      "loss": 0.0352,
      "step": 15560
    },
    {
      "epoch": 4.256424275560415,
      "grad_norm": 0.004623753949999809,
      "learning_rate": 1.5743575724439586e-05,
      "loss": 0.0015,
      "step": 15570
    },
    {
      "epoch": 4.259158009841443,
      "grad_norm": 0.011325518600642681,
      "learning_rate": 1.5740841990158556e-05,
      "loss": 0.0018,
      "step": 15580
    },
    {
      "epoch": 4.2618917441224715,
      "grad_norm": 3.4232113361358643,
      "learning_rate": 1.573810825587753e-05,
      "loss": 0.0259,
      "step": 15590
    },
    {
      "epoch": 4.2646254784035,
      "grad_norm": 0.0050163352862000465,
      "learning_rate": 1.5735374521596503e-05,
      "loss": 0.0304,
      "step": 15600
    },
    {
      "epoch": 4.267359212684527,
      "grad_norm": 6.8711419105529785,
      "learning_rate": 1.5732640787315473e-05,
      "loss": 0.0228,
      "step": 15610
    },
    {
      "epoch": 4.270092946965555,
      "grad_norm": 0.011750027537345886,
      "learning_rate": 1.5729907053034446e-05,
      "loss": 0.0066,
      "step": 15620
    },
    {
      "epoch": 4.272826681246583,
      "grad_norm": 0.07808700948953629,
      "learning_rate": 1.572717331875342e-05,
      "loss": 0.0005,
      "step": 15630
    },
    {
      "epoch": 4.275560415527611,
      "grad_norm": 0.05974676460027695,
      "learning_rate": 1.572443958447239e-05,
      "loss": 0.0164,
      "step": 15640
    },
    {
      "epoch": 4.278294149808638,
      "grad_norm": 0.01206759363412857,
      "learning_rate": 1.5721705850191363e-05,
      "loss": 0.0193,
      "step": 15650
    },
    {
      "epoch": 4.281027884089666,
      "grad_norm": 0.02959764190018177,
      "learning_rate": 1.5718972115910336e-05,
      "loss": 0.0258,
      "step": 15660
    },
    {
      "epoch": 4.283761618370694,
      "grad_norm": 4.084488391876221,
      "learning_rate": 1.5716238381629306e-05,
      "loss": 0.0212,
      "step": 15670
    },
    {
      "epoch": 4.286495352651722,
      "grad_norm": 5.272955417633057,
      "learning_rate": 1.571350464734828e-05,
      "loss": 0.0464,
      "step": 15680
    },
    {
      "epoch": 4.2892290869327505,
      "grad_norm": 0.2650388479232788,
      "learning_rate": 1.571077091306725e-05,
      "loss": 0.0395,
      "step": 15690
    },
    {
      "epoch": 4.291962821213778,
      "grad_norm": 0.009833445772528648,
      "learning_rate": 1.5708037178786223e-05,
      "loss": 0.0234,
      "step": 15700
    },
    {
      "epoch": 4.294696555494806,
      "grad_norm": 0.055374760180711746,
      "learning_rate": 1.5705303444505196e-05,
      "loss": 0.0365,
      "step": 15710
    },
    {
      "epoch": 4.297430289775834,
      "grad_norm": 0.014720440842211246,
      "learning_rate": 1.5702569710224166e-05,
      "loss": 0.0936,
      "step": 15720
    },
    {
      "epoch": 4.300164024056862,
      "grad_norm": 0.1176455095410347,
      "learning_rate": 1.569983597594314e-05,
      "loss": 0.0025,
      "step": 15730
    },
    {
      "epoch": 4.30289775833789,
      "grad_norm": 0.026548363268375397,
      "learning_rate": 1.5697102241662113e-05,
      "loss": 0.0308,
      "step": 15740
    },
    {
      "epoch": 4.305631492618917,
      "grad_norm": 0.015134631656110287,
      "learning_rate": 1.5694368507381083e-05,
      "loss": 0.0094,
      "step": 15750
    },
    {
      "epoch": 4.308365226899945,
      "grad_norm": 5.098839282989502,
      "learning_rate": 1.5691634773100056e-05,
      "loss": 0.0391,
      "step": 15760
    },
    {
      "epoch": 4.311098961180973,
      "grad_norm": 0.04753914475440979,
      "learning_rate": 1.568890103881903e-05,
      "loss": 0.0178,
      "step": 15770
    },
    {
      "epoch": 4.313832695462001,
      "grad_norm": 0.1137278750538826,
      "learning_rate": 1.5686167304538e-05,
      "loss": 0.061,
      "step": 15780
    },
    {
      "epoch": 4.316566429743029,
      "grad_norm": 0.5445125699043274,
      "learning_rate": 1.5683433570256973e-05,
      "loss": 0.0172,
      "step": 15790
    },
    {
      "epoch": 4.319300164024057,
      "grad_norm": 3.479450225830078,
      "learning_rate": 1.5680699835975946e-05,
      "loss": 0.0186,
      "step": 15800
    },
    {
      "epoch": 4.322033898305085,
      "grad_norm": 0.015448687598109245,
      "learning_rate": 1.5677966101694916e-05,
      "loss": 0.034,
      "step": 15810
    },
    {
      "epoch": 4.324767632586113,
      "grad_norm": 0.012312299571931362,
      "learning_rate": 1.567523236741389e-05,
      "loss": 0.0088,
      "step": 15820
    },
    {
      "epoch": 4.327501366867141,
      "grad_norm": 0.01700955629348755,
      "learning_rate": 1.567249863313286e-05,
      "loss": 0.0279,
      "step": 15830
    },
    {
      "epoch": 4.330235101148168,
      "grad_norm": 0.00938806589692831,
      "learning_rate": 1.5669764898851833e-05,
      "loss": 0.0469,
      "step": 15840
    },
    {
      "epoch": 4.332968835429196,
      "grad_norm": 2.297783374786377,
      "learning_rate": 1.5667031164570806e-05,
      "loss": 0.0262,
      "step": 15850
    },
    {
      "epoch": 4.335702569710224,
      "grad_norm": 1.9236125946044922,
      "learning_rate": 1.5664297430289776e-05,
      "loss": 0.0312,
      "step": 15860
    },
    {
      "epoch": 4.338436303991252,
      "grad_norm": 0.4771150052547455,
      "learning_rate": 1.566156369600875e-05,
      "loss": 0.0114,
      "step": 15870
    },
    {
      "epoch": 4.3411700382722795,
      "grad_norm": 5.8906354904174805,
      "learning_rate": 1.5658829961727723e-05,
      "loss": 0.0512,
      "step": 15880
    },
    {
      "epoch": 4.343903772553308,
      "grad_norm": 0.11420174688100815,
      "learning_rate": 1.5656096227446693e-05,
      "loss": 0.001,
      "step": 15890
    },
    {
      "epoch": 4.346637506834336,
      "grad_norm": 0.006645713001489639,
      "learning_rate": 1.5653362493165666e-05,
      "loss": 0.0009,
      "step": 15900
    },
    {
      "epoch": 4.349371241115364,
      "grad_norm": 0.010400602594017982,
      "learning_rate": 1.565062875888464e-05,
      "loss": 0.0082,
      "step": 15910
    },
    {
      "epoch": 4.352104975396392,
      "grad_norm": 2.5733790397644043,
      "learning_rate": 1.564789502460361e-05,
      "loss": 0.0432,
      "step": 15920
    },
    {
      "epoch": 4.354838709677419,
      "grad_norm": 0.052880000323057175,
      "learning_rate": 1.5645161290322583e-05,
      "loss": 0.0193,
      "step": 15930
    },
    {
      "epoch": 4.357572443958447,
      "grad_norm": 0.04255972430109978,
      "learning_rate": 1.5642427556041556e-05,
      "loss": 0.0518,
      "step": 15940
    },
    {
      "epoch": 4.360306178239475,
      "grad_norm": 0.00780596025288105,
      "learning_rate": 1.5639693821760526e-05,
      "loss": 0.0211,
      "step": 15950
    },
    {
      "epoch": 4.363039912520503,
      "grad_norm": 0.5595806837081909,
      "learning_rate": 1.56369600874795e-05,
      "loss": 0.0391,
      "step": 15960
    },
    {
      "epoch": 4.3657736468015305,
      "grad_norm": 0.010397554375231266,
      "learning_rate": 1.563422635319847e-05,
      "loss": 0.0388,
      "step": 15970
    },
    {
      "epoch": 4.3685073810825585,
      "grad_norm": 2.9328324794769287,
      "learning_rate": 1.5631492618917443e-05,
      "loss": 0.0563,
      "step": 15980
    },
    {
      "epoch": 4.371241115363587,
      "grad_norm": 0.005504196509718895,
      "learning_rate": 1.5628758884636416e-05,
      "loss": 0.0153,
      "step": 15990
    },
    {
      "epoch": 4.373974849644615,
      "grad_norm": 0.018266353756189346,
      "learning_rate": 1.5626025150355386e-05,
      "loss": 0.0226,
      "step": 16000
    },
    {
      "epoch": 4.376708583925643,
      "grad_norm": 0.011932101100683212,
      "learning_rate": 1.562329141607436e-05,
      "loss": 0.0485,
      "step": 16010
    },
    {
      "epoch": 4.37944231820667,
      "grad_norm": 0.013985724188387394,
      "learning_rate": 1.5620557681793333e-05,
      "loss": 0.0078,
      "step": 16020
    },
    {
      "epoch": 4.382176052487698,
      "grad_norm": 0.11369301378726959,
      "learning_rate": 1.5617823947512303e-05,
      "loss": 0.0092,
      "step": 16030
    },
    {
      "epoch": 4.384909786768726,
      "grad_norm": 5.116694450378418,
      "learning_rate": 1.5615090213231273e-05,
      "loss": 0.0392,
      "step": 16040
    },
    {
      "epoch": 4.387643521049754,
      "grad_norm": 0.009453121572732925,
      "learning_rate": 1.561235647895025e-05,
      "loss": 0.0123,
      "step": 16050
    },
    {
      "epoch": 4.390377255330781,
      "grad_norm": 12.234853744506836,
      "learning_rate": 1.560962274466922e-05,
      "loss": 0.0335,
      "step": 16060
    },
    {
      "epoch": 4.3931109896118095,
      "grad_norm": 0.004467525519430637,
      "learning_rate": 1.560688901038819e-05,
      "loss": 0.0279,
      "step": 16070
    },
    {
      "epoch": 4.3958447238928375,
      "grad_norm": 0.018254069611430168,
      "learning_rate": 1.5604155276107166e-05,
      "loss": 0.0129,
      "step": 16080
    },
    {
      "epoch": 4.398578458173866,
      "grad_norm": 0.3708919584751129,
      "learning_rate": 1.5601421541826136e-05,
      "loss": 0.0661,
      "step": 16090
    },
    {
      "epoch": 4.401312192454894,
      "grad_norm": 0.72958904504776,
      "learning_rate": 1.5598687807545106e-05,
      "loss": 0.0715,
      "step": 16100
    },
    {
      "epoch": 4.404045926735921,
      "grad_norm": 0.023654548451304436,
      "learning_rate": 1.559595407326408e-05,
      "loss": 0.0073,
      "step": 16110
    },
    {
      "epoch": 4.406779661016949,
      "grad_norm": 0.03293526545166969,
      "learning_rate": 1.5593220338983053e-05,
      "loss": 0.0207,
      "step": 16120
    },
    {
      "epoch": 4.409513395297977,
      "grad_norm": 0.009859640151262283,
      "learning_rate": 1.5590486604702023e-05,
      "loss": 0.0151,
      "step": 16130
    },
    {
      "epoch": 4.412247129579005,
      "grad_norm": 43.8065185546875,
      "learning_rate": 1.5587752870420996e-05,
      "loss": 0.0118,
      "step": 16140
    },
    {
      "epoch": 4.414980863860033,
      "grad_norm": 0.26648232340812683,
      "learning_rate": 1.558501913613997e-05,
      "loss": 0.0278,
      "step": 16150
    },
    {
      "epoch": 4.41771459814106,
      "grad_norm": 0.2851075530052185,
      "learning_rate": 1.558228540185894e-05,
      "loss": 0.0354,
      "step": 16160
    },
    {
      "epoch": 4.4204483324220885,
      "grad_norm": 0.018700718879699707,
      "learning_rate": 1.5579551667577913e-05,
      "loss": 0.0076,
      "step": 16170
    },
    {
      "epoch": 4.4231820667031165,
      "grad_norm": 0.07136973738670349,
      "learning_rate": 1.5576817933296883e-05,
      "loss": 0.0535,
      "step": 16180
    },
    {
      "epoch": 4.425915800984145,
      "grad_norm": 2.9213767051696777,
      "learning_rate": 1.5574084199015856e-05,
      "loss": 0.007,
      "step": 16190
    },
    {
      "epoch": 4.428649535265173,
      "grad_norm": 0.136027529835701,
      "learning_rate": 1.557135046473483e-05,
      "loss": 0.0577,
      "step": 16200
    },
    {
      "epoch": 4.4313832695462,
      "grad_norm": 0.5090791583061218,
      "learning_rate": 1.55686167304538e-05,
      "loss": 0.019,
      "step": 16210
    },
    {
      "epoch": 4.434117003827228,
      "grad_norm": 3.078415870666504,
      "learning_rate": 1.5565882996172773e-05,
      "loss": 0.0249,
      "step": 16220
    },
    {
      "epoch": 4.436850738108256,
      "grad_norm": 0.025935374200344086,
      "learning_rate": 1.5563149261891746e-05,
      "loss": 0.0778,
      "step": 16230
    },
    {
      "epoch": 4.439584472389284,
      "grad_norm": 10.723076820373535,
      "learning_rate": 1.5560415527610716e-05,
      "loss": 0.0622,
      "step": 16240
    },
    {
      "epoch": 4.442318206670311,
      "grad_norm": 0.022408073768019676,
      "learning_rate": 1.555768179332969e-05,
      "loss": 0.0044,
      "step": 16250
    },
    {
      "epoch": 4.445051940951339,
      "grad_norm": 0.8642690181732178,
      "learning_rate": 1.5554948059048663e-05,
      "loss": 0.0099,
      "step": 16260
    },
    {
      "epoch": 4.4477856752323675,
      "grad_norm": 7.611024856567383,
      "learning_rate": 1.5552214324767633e-05,
      "loss": 0.0105,
      "step": 16270
    },
    {
      "epoch": 4.4505194095133955,
      "grad_norm": 0.0090429512783885,
      "learning_rate": 1.5549480590486606e-05,
      "loss": 0.001,
      "step": 16280
    },
    {
      "epoch": 4.453253143794424,
      "grad_norm": 0.007566444575786591,
      "learning_rate": 1.554674685620558e-05,
      "loss": 0.0276,
      "step": 16290
    },
    {
      "epoch": 4.455986878075451,
      "grad_norm": 1.0225019454956055,
      "learning_rate": 1.554401312192455e-05,
      "loss": 0.0109,
      "step": 16300
    },
    {
      "epoch": 4.458720612356479,
      "grad_norm": 0.055332984775304794,
      "learning_rate": 1.5541279387643523e-05,
      "loss": 0.0064,
      "step": 16310
    },
    {
      "epoch": 4.461454346637507,
      "grad_norm": 0.006563560571521521,
      "learning_rate": 1.5538545653362493e-05,
      "loss": 0.001,
      "step": 16320
    },
    {
      "epoch": 4.464188080918535,
      "grad_norm": 0.10175158828496933,
      "learning_rate": 1.5535811919081466e-05,
      "loss": 0.0013,
      "step": 16330
    },
    {
      "epoch": 4.466921815199562,
      "grad_norm": 6.104351043701172,
      "learning_rate": 1.553307818480044e-05,
      "loss": 0.025,
      "step": 16340
    },
    {
      "epoch": 4.46965554948059,
      "grad_norm": 0.2535703480243683,
      "learning_rate": 1.553034445051941e-05,
      "loss": 0.0281,
      "step": 16350
    },
    {
      "epoch": 4.472389283761618,
      "grad_norm": 0.003923945594578981,
      "learning_rate": 1.5527610716238383e-05,
      "loss": 0.0471,
      "step": 16360
    },
    {
      "epoch": 4.4751230180426464,
      "grad_norm": 0.006333084311336279,
      "learning_rate": 1.5524876981957356e-05,
      "loss": 0.0197,
      "step": 16370
    },
    {
      "epoch": 4.4778567523236745,
      "grad_norm": 0.014054563827812672,
      "learning_rate": 1.5522143247676326e-05,
      "loss": 0.0736,
      "step": 16380
    },
    {
      "epoch": 4.480590486604702,
      "grad_norm": 0.0627482533454895,
      "learning_rate": 1.55194095133953e-05,
      "loss": 0.0235,
      "step": 16390
    },
    {
      "epoch": 4.48332422088573,
      "grad_norm": 1.9665778875350952,
      "learning_rate": 1.5516675779114273e-05,
      "loss": 0.0464,
      "step": 16400
    },
    {
      "epoch": 4.486057955166758,
      "grad_norm": 0.16511711478233337,
      "learning_rate": 1.5513942044833243e-05,
      "loss": 0.0071,
      "step": 16410
    },
    {
      "epoch": 4.488791689447786,
      "grad_norm": 3.323357343673706,
      "learning_rate": 1.5511208310552216e-05,
      "loss": 0.0589,
      "step": 16420
    },
    {
      "epoch": 4.491525423728813,
      "grad_norm": 0.1502862572669983,
      "learning_rate": 1.550847457627119e-05,
      "loss": 0.0104,
      "step": 16430
    },
    {
      "epoch": 4.494259158009841,
      "grad_norm": 0.015270908363163471,
      "learning_rate": 1.550574084199016e-05,
      "loss": 0.0066,
      "step": 16440
    },
    {
      "epoch": 4.496992892290869,
      "grad_norm": 2.6337056159973145,
      "learning_rate": 1.5503007107709133e-05,
      "loss": 0.0953,
      "step": 16450
    },
    {
      "epoch": 4.499726626571897,
      "grad_norm": 0.2959795892238617,
      "learning_rate": 1.5500273373428103e-05,
      "loss": 0.0267,
      "step": 16460
    },
    {
      "epoch": 4.5024603608529254,
      "grad_norm": 0.03196825087070465,
      "learning_rate": 1.5497539639147076e-05,
      "loss": 0.0343,
      "step": 16470
    },
    {
      "epoch": 4.505194095133953,
      "grad_norm": 0.006247467361390591,
      "learning_rate": 1.549480590486605e-05,
      "loss": 0.009,
      "step": 16480
    },
    {
      "epoch": 4.507927829414981,
      "grad_norm": 0.1621917486190796,
      "learning_rate": 1.549207217058502e-05,
      "loss": 0.065,
      "step": 16490
    },
    {
      "epoch": 4.510661563696009,
      "grad_norm": 0.8740044832229614,
      "learning_rate": 1.5489338436303993e-05,
      "loss": 0.0635,
      "step": 16500
    },
    {
      "epoch": 4.513395297977037,
      "grad_norm": 0.9059857130050659,
      "learning_rate": 1.5486604702022966e-05,
      "loss": 0.0122,
      "step": 16510
    },
    {
      "epoch": 4.516129032258064,
      "grad_norm": 0.0439392626285553,
      "learning_rate": 1.5483870967741936e-05,
      "loss": 0.0187,
      "step": 16520
    },
    {
      "epoch": 4.518862766539092,
      "grad_norm": 0.10525732487440109,
      "learning_rate": 1.548113723346091e-05,
      "loss": 0.0205,
      "step": 16530
    },
    {
      "epoch": 4.52159650082012,
      "grad_norm": 0.02644873410463333,
      "learning_rate": 1.5478403499179883e-05,
      "loss": 0.0012,
      "step": 16540
    },
    {
      "epoch": 4.524330235101148,
      "grad_norm": 0.3227357864379883,
      "learning_rate": 1.5475669764898853e-05,
      "loss": 0.0317,
      "step": 16550
    },
    {
      "epoch": 4.527063969382176,
      "grad_norm": 0.04026413708925247,
      "learning_rate": 1.5472936030617826e-05,
      "loss": 0.0348,
      "step": 16560
    },
    {
      "epoch": 4.529797703663204,
      "grad_norm": 0.26210713386535645,
      "learning_rate": 1.54702022963368e-05,
      "loss": 0.0135,
      "step": 16570
    },
    {
      "epoch": 4.532531437944232,
      "grad_norm": 2.9357542991638184,
      "learning_rate": 1.546746856205577e-05,
      "loss": 0.0416,
      "step": 16580
    },
    {
      "epoch": 4.53526517222526,
      "grad_norm": 0.07630464434623718,
      "learning_rate": 1.5464734827774743e-05,
      "loss": 0.0493,
      "step": 16590
    },
    {
      "epoch": 4.537998906506288,
      "grad_norm": 0.04560602456331253,
      "learning_rate": 1.5462001093493713e-05,
      "loss": 0.0166,
      "step": 16600
    },
    {
      "epoch": 4.540732640787315,
      "grad_norm": 1.1717060804367065,
      "learning_rate": 1.5459267359212686e-05,
      "loss": 0.0071,
      "step": 16610
    },
    {
      "epoch": 4.543466375068343,
      "grad_norm": 3.6504688262939453,
      "learning_rate": 1.545653362493166e-05,
      "loss": 0.0222,
      "step": 16620
    },
    {
      "epoch": 4.546200109349371,
      "grad_norm": 0.014279285445809364,
      "learning_rate": 1.545379989065063e-05,
      "loss": 0.0436,
      "step": 16630
    },
    {
      "epoch": 4.548933843630399,
      "grad_norm": 0.5839537382125854,
      "learning_rate": 1.5451066156369603e-05,
      "loss": 0.0235,
      "step": 16640
    },
    {
      "epoch": 4.551667577911427,
      "grad_norm": 0.028518928214907646,
      "learning_rate": 1.5448332422088576e-05,
      "loss": 0.0495,
      "step": 16650
    },
    {
      "epoch": 4.554401312192455,
      "grad_norm": 0.005999205633997917,
      "learning_rate": 1.5445598687807546e-05,
      "loss": 0.0055,
      "step": 16660
    },
    {
      "epoch": 4.5571350464734826,
      "grad_norm": 0.008568591438233852,
      "learning_rate": 1.5442864953526516e-05,
      "loss": 0.0055,
      "step": 16670
    },
    {
      "epoch": 4.559868780754511,
      "grad_norm": 1.1888394355773926,
      "learning_rate": 1.5440131219245493e-05,
      "loss": 0.0475,
      "step": 16680
    },
    {
      "epoch": 4.562602515035539,
      "grad_norm": 0.00825414340943098,
      "learning_rate": 1.5437397484964463e-05,
      "loss": 0.0337,
      "step": 16690
    },
    {
      "epoch": 4.565336249316567,
      "grad_norm": 5.468445777893066,
      "learning_rate": 1.5434663750683433e-05,
      "loss": 0.0543,
      "step": 16700
    },
    {
      "epoch": 4.568069983597594,
      "grad_norm": 0.03562813252210617,
      "learning_rate": 1.543193001640241e-05,
      "loss": 0.0199,
      "step": 16710
    },
    {
      "epoch": 4.570803717878622,
      "grad_norm": 1.262234091758728,
      "learning_rate": 1.542919628212138e-05,
      "loss": 0.0444,
      "step": 16720
    },
    {
      "epoch": 4.57353745215965,
      "grad_norm": 0.9810042977333069,
      "learning_rate": 1.542646254784035e-05,
      "loss": 0.0488,
      "step": 16730
    },
    {
      "epoch": 4.576271186440678,
      "grad_norm": 0.006769931875169277,
      "learning_rate": 1.5423728813559326e-05,
      "loss": 0.0589,
      "step": 16740
    },
    {
      "epoch": 4.579004920721706,
      "grad_norm": 0.023258568719029427,
      "learning_rate": 1.5420995079278296e-05,
      "loss": 0.0202,
      "step": 16750
    },
    {
      "epoch": 4.5817386550027335,
      "grad_norm": 0.4530823528766632,
      "learning_rate": 1.5418261344997266e-05,
      "loss": 0.0226,
      "step": 16760
    },
    {
      "epoch": 4.5844723892837616,
      "grad_norm": 0.029184523969888687,
      "learning_rate": 1.541552761071624e-05,
      "loss": 0.0293,
      "step": 16770
    },
    {
      "epoch": 4.58720612356479,
      "grad_norm": 0.22662588953971863,
      "learning_rate": 1.5412793876435213e-05,
      "loss": 0.0096,
      "step": 16780
    },
    {
      "epoch": 4.589939857845818,
      "grad_norm": 0.00466190604493022,
      "learning_rate": 1.5410060142154183e-05,
      "loss": 0.0006,
      "step": 16790
    },
    {
      "epoch": 4.592673592126845,
      "grad_norm": 0.013192527927458286,
      "learning_rate": 1.5407326407873156e-05,
      "loss": 0.0168,
      "step": 16800
    },
    {
      "epoch": 4.595407326407873,
      "grad_norm": 0.028187302872538567,
      "learning_rate": 1.540459267359213e-05,
      "loss": 0.0641,
      "step": 16810
    },
    {
      "epoch": 4.598141060688901,
      "grad_norm": 4.673950672149658,
      "learning_rate": 1.54018589393111e-05,
      "loss": 0.0566,
      "step": 16820
    },
    {
      "epoch": 4.600874794969929,
      "grad_norm": 0.11280687153339386,
      "learning_rate": 1.5399125205030073e-05,
      "loss": 0.0407,
      "step": 16830
    },
    {
      "epoch": 4.603608529250957,
      "grad_norm": 0.026083262637257576,
      "learning_rate": 1.5396391470749043e-05,
      "loss": 0.0083,
      "step": 16840
    },
    {
      "epoch": 4.606342263531984,
      "grad_norm": 0.019718848168849945,
      "learning_rate": 1.5393657736468016e-05,
      "loss": 0.014,
      "step": 16850
    },
    {
      "epoch": 4.6090759978130125,
      "grad_norm": 0.5520306825637817,
      "learning_rate": 1.539092400218699e-05,
      "loss": 0.0126,
      "step": 16860
    },
    {
      "epoch": 4.6118097320940405,
      "grad_norm": 0.2968447506427765,
      "learning_rate": 1.538819026790596e-05,
      "loss": 0.0464,
      "step": 16870
    },
    {
      "epoch": 4.614543466375069,
      "grad_norm": 28.44058609008789,
      "learning_rate": 1.5385456533624933e-05,
      "loss": 0.0082,
      "step": 16880
    },
    {
      "epoch": 4.617277200656096,
      "grad_norm": 0.02335919253528118,
      "learning_rate": 1.5382722799343906e-05,
      "loss": 0.0251,
      "step": 16890
    },
    {
      "epoch": 4.620010934937124,
      "grad_norm": 0.035801906138658524,
      "learning_rate": 1.5379989065062876e-05,
      "loss": 0.0007,
      "step": 16900
    },
    {
      "epoch": 4.622744669218152,
      "grad_norm": 4.107207298278809,
      "learning_rate": 1.537725533078185e-05,
      "loss": 0.033,
      "step": 16910
    },
    {
      "epoch": 4.62547840349918,
      "grad_norm": 0.09782329946756363,
      "learning_rate": 1.5374521596500823e-05,
      "loss": 0.0281,
      "step": 16920
    },
    {
      "epoch": 4.628212137780208,
      "grad_norm": 0.016972338780760765,
      "learning_rate": 1.5371787862219793e-05,
      "loss": 0.0134,
      "step": 16930
    },
    {
      "epoch": 4.630945872061235,
      "grad_norm": 0.031992364674806595,
      "learning_rate": 1.5369054127938766e-05,
      "loss": 0.0187,
      "step": 16940
    },
    {
      "epoch": 4.633679606342263,
      "grad_norm": 0.00408026110380888,
      "learning_rate": 1.536632039365774e-05,
      "loss": 0.0065,
      "step": 16950
    },
    {
      "epoch": 4.6364133406232915,
      "grad_norm": 0.004491891711950302,
      "learning_rate": 1.536358665937671e-05,
      "loss": 0.0006,
      "step": 16960
    },
    {
      "epoch": 4.6391470749043195,
      "grad_norm": 0.005130059085786343,
      "learning_rate": 1.5360852925095683e-05,
      "loss": 0.075,
      "step": 16970
    },
    {
      "epoch": 4.641880809185347,
      "grad_norm": 0.17514343559741974,
      "learning_rate": 1.5358119190814652e-05,
      "loss": 0.0417,
      "step": 16980
    },
    {
      "epoch": 4.644614543466375,
      "grad_norm": 0.019587572664022446,
      "learning_rate": 1.5355385456533626e-05,
      "loss": 0.0294,
      "step": 16990
    },
    {
      "epoch": 4.647348277747403,
      "grad_norm": 5.31946325302124,
      "learning_rate": 1.53526517222526e-05,
      "loss": 0.0732,
      "step": 17000
    },
    {
      "epoch": 4.650082012028431,
      "grad_norm": 0.0361957810819149,
      "learning_rate": 1.534991798797157e-05,
      "loss": 0.01,
      "step": 17010
    },
    {
      "epoch": 4.652815746309459,
      "grad_norm": 0.011553780175745487,
      "learning_rate": 1.5347184253690542e-05,
      "loss": 0.0202,
      "step": 17020
    },
    {
      "epoch": 4.655549480590486,
      "grad_norm": 0.024080926552414894,
      "learning_rate": 1.5344450519409516e-05,
      "loss": 0.0778,
      "step": 17030
    },
    {
      "epoch": 4.658283214871514,
      "grad_norm": 0.03425353392958641,
      "learning_rate": 1.5341716785128486e-05,
      "loss": 0.0279,
      "step": 17040
    },
    {
      "epoch": 4.661016949152542,
      "grad_norm": 3.0270793437957764,
      "learning_rate": 1.533898305084746e-05,
      "loss": 0.0298,
      "step": 17050
    },
    {
      "epoch": 4.6637506834335705,
      "grad_norm": 20.6051082611084,
      "learning_rate": 1.5336249316566433e-05,
      "loss": 0.0442,
      "step": 17060
    },
    {
      "epoch": 4.666484417714598,
      "grad_norm": 0.022186847403645515,
      "learning_rate": 1.5333515582285402e-05,
      "loss": 0.0015,
      "step": 17070
    },
    {
      "epoch": 4.669218151995626,
      "grad_norm": 0.06627818197011948,
      "learning_rate": 1.5330781848004376e-05,
      "loss": 0.0228,
      "step": 17080
    },
    {
      "epoch": 4.671951886276654,
      "grad_norm": 0.04676220938563347,
      "learning_rate": 1.532804811372335e-05,
      "loss": 0.0323,
      "step": 17090
    },
    {
      "epoch": 4.674685620557682,
      "grad_norm": 0.018944747745990753,
      "learning_rate": 1.532531437944232e-05,
      "loss": 0.0136,
      "step": 17100
    },
    {
      "epoch": 4.67741935483871,
      "grad_norm": 0.38807937502861023,
      "learning_rate": 1.5322580645161292e-05,
      "loss": 0.1041,
      "step": 17110
    },
    {
      "epoch": 4.680153089119738,
      "grad_norm": 0.17998816072940826,
      "learning_rate": 1.5319846910880262e-05,
      "loss": 0.0506,
      "step": 17120
    },
    {
      "epoch": 4.682886823400765,
      "grad_norm": 0.02196619287133217,
      "learning_rate": 1.5317113176599236e-05,
      "loss": 0.0127,
      "step": 17130
    },
    {
      "epoch": 4.685620557681793,
      "grad_norm": 0.06612546741962433,
      "learning_rate": 1.531437944231821e-05,
      "loss": 0.0156,
      "step": 17140
    },
    {
      "epoch": 4.688354291962821,
      "grad_norm": 0.024929741397500038,
      "learning_rate": 1.531164570803718e-05,
      "loss": 0.0165,
      "step": 17150
    },
    {
      "epoch": 4.6910880262438495,
      "grad_norm": 0.016711873933672905,
      "learning_rate": 1.5308911973756152e-05,
      "loss": 0.0223,
      "step": 17160
    },
    {
      "epoch": 4.693821760524877,
      "grad_norm": 0.08109331130981445,
      "learning_rate": 1.5306178239475126e-05,
      "loss": 0.0432,
      "step": 17170
    },
    {
      "epoch": 4.696555494805905,
      "grad_norm": 0.04638972133398056,
      "learning_rate": 1.5303444505194096e-05,
      "loss": 0.048,
      "step": 17180
    },
    {
      "epoch": 4.699289229086933,
      "grad_norm": 0.10206809639930725,
      "learning_rate": 1.530071077091307e-05,
      "loss": 0.0092,
      "step": 17190
    },
    {
      "epoch": 4.702022963367961,
      "grad_norm": 0.20538952946662903,
      "learning_rate": 1.5297977036632042e-05,
      "loss": 0.067,
      "step": 17200
    },
    {
      "epoch": 4.704756697648989,
      "grad_norm": 0.08141644299030304,
      "learning_rate": 1.5295243302351012e-05,
      "loss": 0.0039,
      "step": 17210
    },
    {
      "epoch": 4.707490431930016,
      "grad_norm": 12.6945161819458,
      "learning_rate": 1.5292509568069986e-05,
      "loss": 0.0398,
      "step": 17220
    },
    {
      "epoch": 4.710224166211044,
      "grad_norm": 0.0183758232742548,
      "learning_rate": 1.528977583378896e-05,
      "loss": 0.0408,
      "step": 17230
    },
    {
      "epoch": 4.712957900492072,
      "grad_norm": 0.016086367890238762,
      "learning_rate": 1.528704209950793e-05,
      "loss": 0.0013,
      "step": 17240
    },
    {
      "epoch": 4.7156916347731,
      "grad_norm": 0.005459208972752094,
      "learning_rate": 1.5284308365226902e-05,
      "loss": 0.0093,
      "step": 17250
    },
    {
      "epoch": 4.718425369054128,
      "grad_norm": 0.01361795049160719,
      "learning_rate": 1.5281574630945872e-05,
      "loss": 0.0201,
      "step": 17260
    },
    {
      "epoch": 4.721159103335156,
      "grad_norm": 70.21510314941406,
      "learning_rate": 1.5278840896664846e-05,
      "loss": 0.0219,
      "step": 17270
    },
    {
      "epoch": 4.723892837616184,
      "grad_norm": 0.0682704970240593,
      "learning_rate": 1.527610716238382e-05,
      "loss": 0.0107,
      "step": 17280
    },
    {
      "epoch": 4.726626571897212,
      "grad_norm": 0.017743613570928574,
      "learning_rate": 1.527337342810279e-05,
      "loss": 0.0343,
      "step": 17290
    },
    {
      "epoch": 4.72936030617824,
      "grad_norm": 0.33860862255096436,
      "learning_rate": 1.5270639693821762e-05,
      "loss": 0.0266,
      "step": 17300
    },
    {
      "epoch": 4.732094040459267,
      "grad_norm": 0.013126335106790066,
      "learning_rate": 1.5267905959540736e-05,
      "loss": 0.0035,
      "step": 17310
    },
    {
      "epoch": 4.734827774740295,
      "grad_norm": 0.01058008149266243,
      "learning_rate": 1.5265172225259706e-05,
      "loss": 0.0194,
      "step": 17320
    },
    {
      "epoch": 4.737561509021323,
      "grad_norm": 1.5729180574417114,
      "learning_rate": 1.5262438490978676e-05,
      "loss": 0.018,
      "step": 17330
    },
    {
      "epoch": 4.740295243302351,
      "grad_norm": 0.00436435965821147,
      "learning_rate": 1.5259704756697652e-05,
      "loss": 0.0002,
      "step": 17340
    },
    {
      "epoch": 4.7430289775833785,
      "grad_norm": 0.0031154684256762266,
      "learning_rate": 1.5256971022416622e-05,
      "loss": 0.0041,
      "step": 17350
    },
    {
      "epoch": 4.745762711864407,
      "grad_norm": 0.005206902511417866,
      "learning_rate": 1.5254237288135594e-05,
      "loss": 0.0036,
      "step": 17360
    },
    {
      "epoch": 4.748496446145435,
      "grad_norm": 0.010335142724215984,
      "learning_rate": 1.5251503553854567e-05,
      "loss": 0.0629,
      "step": 17370
    },
    {
      "epoch": 4.751230180426463,
      "grad_norm": 2.578505277633667,
      "learning_rate": 1.5248769819573539e-05,
      "loss": 0.0527,
      "step": 17380
    },
    {
      "epoch": 4.753963914707491,
      "grad_norm": 0.20469236373901367,
      "learning_rate": 1.524603608529251e-05,
      "loss": 0.0309,
      "step": 17390
    },
    {
      "epoch": 4.756697648988518,
      "grad_norm": 0.1421433538198471,
      "learning_rate": 1.5243302351011482e-05,
      "loss": 0.0206,
      "step": 17400
    },
    {
      "epoch": 4.759431383269546,
      "grad_norm": 0.4339980185031891,
      "learning_rate": 1.5240568616730456e-05,
      "loss": 0.0108,
      "step": 17410
    },
    {
      "epoch": 4.762165117550574,
      "grad_norm": 0.008532652631402016,
      "learning_rate": 1.5237834882449427e-05,
      "loss": 0.0448,
      "step": 17420
    },
    {
      "epoch": 4.764898851831602,
      "grad_norm": 0.006885439623147249,
      "learning_rate": 1.5235101148168399e-05,
      "loss": 0.0227,
      "step": 17430
    },
    {
      "epoch": 4.767632586112629,
      "grad_norm": 3.175938367843628,
      "learning_rate": 1.5232367413887372e-05,
      "loss": 0.0558,
      "step": 17440
    },
    {
      "epoch": 4.7703663203936575,
      "grad_norm": 0.8783986568450928,
      "learning_rate": 1.5229633679606344e-05,
      "loss": 0.014,
      "step": 17450
    },
    {
      "epoch": 4.773100054674686,
      "grad_norm": 0.036533765494823456,
      "learning_rate": 1.5226899945325316e-05,
      "loss": 0.0416,
      "step": 17460
    },
    {
      "epoch": 4.775833788955714,
      "grad_norm": 0.29289668798446655,
      "learning_rate": 1.5224166211044287e-05,
      "loss": 0.02,
      "step": 17470
    },
    {
      "epoch": 4.778567523236742,
      "grad_norm": 0.007200730964541435,
      "learning_rate": 1.522143247676326e-05,
      "loss": 0.0012,
      "step": 17480
    },
    {
      "epoch": 4.781301257517769,
      "grad_norm": 0.06951193511486053,
      "learning_rate": 1.5218698742482232e-05,
      "loss": 0.0045,
      "step": 17490
    },
    {
      "epoch": 4.784034991798797,
      "grad_norm": 0.021679118275642395,
      "learning_rate": 1.5215965008201204e-05,
      "loss": 0.0159,
      "step": 17500
    },
    {
      "epoch": 4.786768726079825,
      "grad_norm": 0.03442718833684921,
      "learning_rate": 1.5213231273920177e-05,
      "loss": 0.0434,
      "step": 17510
    },
    {
      "epoch": 4.789502460360853,
      "grad_norm": 0.003783726366236806,
      "learning_rate": 1.5210497539639149e-05,
      "loss": 0.0173,
      "step": 17520
    },
    {
      "epoch": 4.79223619464188,
      "grad_norm": 6.770921230316162,
      "learning_rate": 1.520776380535812e-05,
      "loss": 0.0289,
      "step": 17530
    },
    {
      "epoch": 4.794969928922908,
      "grad_norm": 0.640788197517395,
      "learning_rate": 1.5205030071077092e-05,
      "loss": 0.0122,
      "step": 17540
    },
    {
      "epoch": 4.7977036632039365,
      "grad_norm": 0.009799989871680737,
      "learning_rate": 1.5202296336796066e-05,
      "loss": 0.0584,
      "step": 17550
    },
    {
      "epoch": 4.800437397484965,
      "grad_norm": 0.0173116996884346,
      "learning_rate": 1.5199562602515037e-05,
      "loss": 0.0102,
      "step": 17560
    },
    {
      "epoch": 4.803171131765993,
      "grad_norm": 0.02252507396042347,
      "learning_rate": 1.5196828868234009e-05,
      "loss": 0.0087,
      "step": 17570
    },
    {
      "epoch": 4.805904866047021,
      "grad_norm": 2.235076904296875,
      "learning_rate": 1.5194095133952982e-05,
      "loss": 0.0102,
      "step": 17580
    },
    {
      "epoch": 4.808638600328048,
      "grad_norm": 0.024406440556049347,
      "learning_rate": 1.5191361399671954e-05,
      "loss": 0.0573,
      "step": 17590
    },
    {
      "epoch": 4.811372334609076,
      "grad_norm": 2.3488523960113525,
      "learning_rate": 1.5188627665390926e-05,
      "loss": 0.0518,
      "step": 17600
    },
    {
      "epoch": 4.814106068890104,
      "grad_norm": 2.0041511058807373,
      "learning_rate": 1.5185893931109896e-05,
      "loss": 0.0182,
      "step": 17610
    },
    {
      "epoch": 4.816839803171132,
      "grad_norm": 0.5458724498748779,
      "learning_rate": 1.518316019682887e-05,
      "loss": 0.0076,
      "step": 17620
    },
    {
      "epoch": 4.819573537452159,
      "grad_norm": 3.3454482555389404,
      "learning_rate": 1.5180426462547842e-05,
      "loss": 0.0538,
      "step": 17630
    },
    {
      "epoch": 4.822307271733187,
      "grad_norm": 6.482699871063232,
      "learning_rate": 1.5177692728266812e-05,
      "loss": 0.0288,
      "step": 17640
    },
    {
      "epoch": 4.8250410060142155,
      "grad_norm": 0.05697567015886307,
      "learning_rate": 1.5174958993985787e-05,
      "loss": 0.0495,
      "step": 17650
    },
    {
      "epoch": 4.827774740295244,
      "grad_norm": 0.6558037996292114,
      "learning_rate": 1.5172225259704759e-05,
      "loss": 0.0133,
      "step": 17660
    },
    {
      "epoch": 4.830508474576272,
      "grad_norm": 0.02449355088174343,
      "learning_rate": 1.5169491525423729e-05,
      "loss": 0.0137,
      "step": 17670
    },
    {
      "epoch": 4.833242208857299,
      "grad_norm": 0.0036165202036499977,
      "learning_rate": 1.51667577911427e-05,
      "loss": 0.0189,
      "step": 17680
    },
    {
      "epoch": 4.835975943138327,
      "grad_norm": 0.4246765077114105,
      "learning_rate": 1.5164024056861676e-05,
      "loss": 0.0294,
      "step": 17690
    },
    {
      "epoch": 4.838709677419355,
      "grad_norm": 0.003495441284030676,
      "learning_rate": 1.5161290322580646e-05,
      "loss": 0.0004,
      "step": 17700
    },
    {
      "epoch": 4.841443411700383,
      "grad_norm": 0.007467640098184347,
      "learning_rate": 1.5158556588299617e-05,
      "loss": 0.0018,
      "step": 17710
    },
    {
      "epoch": 4.84417714598141,
      "grad_norm": 0.0014383118832483888,
      "learning_rate": 1.5155822854018592e-05,
      "loss": 0.0209,
      "step": 17720
    },
    {
      "epoch": 4.846910880262438,
      "grad_norm": 0.000947393651586026,
      "learning_rate": 1.5153089119737562e-05,
      "loss": 0.0145,
      "step": 17730
    },
    {
      "epoch": 4.849644614543466,
      "grad_norm": 0.0008144428720697761,
      "learning_rate": 1.5150355385456534e-05,
      "loss": 0.0001,
      "step": 17740
    },
    {
      "epoch": 4.8523783488244945,
      "grad_norm": 0.0008109269547276199,
      "learning_rate": 1.5147621651175506e-05,
      "loss": 0.0522,
      "step": 17750
    },
    {
      "epoch": 4.855112083105523,
      "grad_norm": 0.0013590510934591293,
      "learning_rate": 1.5144887916894479e-05,
      "loss": 0.0834,
      "step": 17760
    },
    {
      "epoch": 4.85784581738655,
      "grad_norm": 0.03727323189377785,
      "learning_rate": 1.514215418261345e-05,
      "loss": 0.0185,
      "step": 17770
    },
    {
      "epoch": 4.860579551667578,
      "grad_norm": 2.4389309883117676,
      "learning_rate": 1.5139420448332422e-05,
      "loss": 0.0337,
      "step": 17780
    },
    {
      "epoch": 4.863313285948606,
      "grad_norm": 0.4860003590583801,
      "learning_rate": 1.5136686714051396e-05,
      "loss": 0.0192,
      "step": 17790
    },
    {
      "epoch": 4.866047020229634,
      "grad_norm": 1.1817957162857056,
      "learning_rate": 1.5133952979770367e-05,
      "loss": 0.0018,
      "step": 17800
    },
    {
      "epoch": 4.868780754510661,
      "grad_norm": 0.6052564382553101,
      "learning_rate": 1.5131219245489339e-05,
      "loss": 0.0048,
      "step": 17810
    },
    {
      "epoch": 4.871514488791689,
      "grad_norm": 12.271090507507324,
      "learning_rate": 1.5128485511208312e-05,
      "loss": 0.0051,
      "step": 17820
    },
    {
      "epoch": 4.874248223072717,
      "grad_norm": 0.24211478233337402,
      "learning_rate": 1.5125751776927284e-05,
      "loss": 0.0192,
      "step": 17830
    },
    {
      "epoch": 4.876981957353745,
      "grad_norm": 0.005209801252931356,
      "learning_rate": 1.5123018042646256e-05,
      "loss": 0.0201,
      "step": 17840
    },
    {
      "epoch": 4.8797156916347735,
      "grad_norm": 0.010711460374295712,
      "learning_rate": 1.5120284308365227e-05,
      "loss": 0.0118,
      "step": 17850
    },
    {
      "epoch": 4.882449425915801,
      "grad_norm": 3.6801998615264893,
      "learning_rate": 1.51175505740842e-05,
      "loss": 0.0462,
      "step": 17860
    },
    {
      "epoch": 4.885183160196829,
      "grad_norm": 0.011312711983919144,
      "learning_rate": 1.5114816839803172e-05,
      "loss": 0.0133,
      "step": 17870
    },
    {
      "epoch": 4.887916894477857,
      "grad_norm": 0.3828263580799103,
      "learning_rate": 1.5112083105522144e-05,
      "loss": 0.0685,
      "step": 17880
    },
    {
      "epoch": 4.890650628758885,
      "grad_norm": 1.1800851821899414,
      "learning_rate": 1.5109349371241117e-05,
      "loss": 0.0242,
      "step": 17890
    },
    {
      "epoch": 4.893384363039912,
      "grad_norm": 0.08861344307661057,
      "learning_rate": 1.5106615636960089e-05,
      "loss": 0.0175,
      "step": 17900
    },
    {
      "epoch": 4.89611809732094,
      "grad_norm": 4.1043524742126465,
      "learning_rate": 1.510388190267906e-05,
      "loss": 0.0212,
      "step": 17910
    },
    {
      "epoch": 4.898851831601968,
      "grad_norm": 1.7624540328979492,
      "learning_rate": 1.5101148168398032e-05,
      "loss": 0.0664,
      "step": 17920
    },
    {
      "epoch": 4.901585565882996,
      "grad_norm": 0.004594659432768822,
      "learning_rate": 1.5098414434117006e-05,
      "loss": 0.002,
      "step": 17930
    },
    {
      "epoch": 4.904319300164024,
      "grad_norm": 0.0036744028329849243,
      "learning_rate": 1.5095680699835977e-05,
      "loss": 0.0002,
      "step": 17940
    },
    {
      "epoch": 4.907053034445052,
      "grad_norm": 0.3763941824436188,
      "learning_rate": 1.5092946965554949e-05,
      "loss": 0.0125,
      "step": 17950
    },
    {
      "epoch": 4.90978676872608,
      "grad_norm": 0.0035477669443935156,
      "learning_rate": 1.5090213231273922e-05,
      "loss": 0.0317,
      "step": 17960
    },
    {
      "epoch": 4.912520503007108,
      "grad_norm": 19.447650909423828,
      "learning_rate": 1.5087479496992894e-05,
      "loss": 0.056,
      "step": 17970
    },
    {
      "epoch": 4.915254237288136,
      "grad_norm": 0.5092708468437195,
      "learning_rate": 1.5084745762711865e-05,
      "loss": 0.0488,
      "step": 17980
    },
    {
      "epoch": 4.917987971569163,
      "grad_norm": 0.01990346424281597,
      "learning_rate": 1.5082012028430837e-05,
      "loss": 0.0133,
      "step": 17990
    },
    {
      "epoch": 4.920721705850191,
      "grad_norm": 1.5071219205856323,
      "learning_rate": 1.507927829414981e-05,
      "loss": 0.0417,
      "step": 18000
    },
    {
      "epoch": 4.923455440131219,
      "grad_norm": 0.017452970147132874,
      "learning_rate": 1.5076544559868782e-05,
      "loss": 0.003,
      "step": 18010
    },
    {
      "epoch": 4.926189174412247,
      "grad_norm": 0.0262577086687088,
      "learning_rate": 1.5073810825587754e-05,
      "loss": 0.013,
      "step": 18020
    },
    {
      "epoch": 4.928922908693275,
      "grad_norm": 1.2132917642593384,
      "learning_rate": 1.5071077091306727e-05,
      "loss": 0.0248,
      "step": 18030
    },
    {
      "epoch": 4.931656642974303,
      "grad_norm": 0.9164429306983948,
      "learning_rate": 1.5068343357025699e-05,
      "loss": 0.0252,
      "step": 18040
    },
    {
      "epoch": 4.934390377255331,
      "grad_norm": 0.015562294982373714,
      "learning_rate": 1.506560962274467e-05,
      "loss": 0.0212,
      "step": 18050
    },
    {
      "epoch": 4.937124111536359,
      "grad_norm": 0.03650795295834541,
      "learning_rate": 1.5062875888463642e-05,
      "loss": 0.0107,
      "step": 18060
    },
    {
      "epoch": 4.939857845817387,
      "grad_norm": 0.08747241646051407,
      "learning_rate": 1.5060142154182615e-05,
      "loss": 0.0567,
      "step": 18070
    },
    {
      "epoch": 4.942591580098415,
      "grad_norm": 0.00878623966127634,
      "learning_rate": 1.5057408419901587e-05,
      "loss": 0.0269,
      "step": 18080
    },
    {
      "epoch": 4.945325314379442,
      "grad_norm": 0.0023839673958718777,
      "learning_rate": 1.5054674685620559e-05,
      "loss": 0.0012,
      "step": 18090
    },
    {
      "epoch": 4.94805904866047,
      "grad_norm": 0.6000239849090576,
      "learning_rate": 1.5051940951339532e-05,
      "loss": 0.0035,
      "step": 18100
    },
    {
      "epoch": 4.950792782941498,
      "grad_norm": 0.003928035032004118,
      "learning_rate": 1.5049207217058504e-05,
      "loss": 0.0331,
      "step": 18110
    },
    {
      "epoch": 4.953526517222526,
      "grad_norm": 0.00831051915884018,
      "learning_rate": 1.5046473482777475e-05,
      "loss": 0.0405,
      "step": 18120
    },
    {
      "epoch": 4.956260251503554,
      "grad_norm": 0.008515706285834312,
      "learning_rate": 1.5043739748496447e-05,
      "loss": 0.0321,
      "step": 18130
    },
    {
      "epoch": 4.9589939857845815,
      "grad_norm": 2.5378975868225098,
      "learning_rate": 1.504100601421542e-05,
      "loss": 0.0226,
      "step": 18140
    },
    {
      "epoch": 4.96172772006561,
      "grad_norm": 0.1775902658700943,
      "learning_rate": 1.5038272279934392e-05,
      "loss": 0.0665,
      "step": 18150
    },
    {
      "epoch": 4.964461454346638,
      "grad_norm": 0.5499064922332764,
      "learning_rate": 1.5035538545653364e-05,
      "loss": 0.0037,
      "step": 18160
    },
    {
      "epoch": 4.967195188627666,
      "grad_norm": 0.8855282068252563,
      "learning_rate": 1.5032804811372337e-05,
      "loss": 0.0249,
      "step": 18170
    },
    {
      "epoch": 4.969928922908693,
      "grad_norm": 0.012700165621936321,
      "learning_rate": 1.5030071077091309e-05,
      "loss": 0.0125,
      "step": 18180
    },
    {
      "epoch": 4.972662657189721,
      "grad_norm": 0.006836244370788336,
      "learning_rate": 1.502733734281028e-05,
      "loss": 0.032,
      "step": 18190
    },
    {
      "epoch": 4.975396391470749,
      "grad_norm": 0.2585156559944153,
      "learning_rate": 1.5024603608529252e-05,
      "loss": 0.0103,
      "step": 18200
    },
    {
      "epoch": 4.978130125751777,
      "grad_norm": 0.03303142637014389,
      "learning_rate": 1.5021869874248225e-05,
      "loss": 0.0204,
      "step": 18210
    },
    {
      "epoch": 4.980863860032805,
      "grad_norm": 34.8221435546875,
      "learning_rate": 1.5019136139967197e-05,
      "loss": 0.0409,
      "step": 18220
    },
    {
      "epoch": 4.983597594313832,
      "grad_norm": 0.12535132467746735,
      "learning_rate": 1.5016402405686169e-05,
      "loss": 0.0012,
      "step": 18230
    },
    {
      "epoch": 4.9863313285948605,
      "grad_norm": 0.004920953884720802,
      "learning_rate": 1.5013668671405142e-05,
      "loss": 0.0159,
      "step": 18240
    },
    {
      "epoch": 4.989065062875889,
      "grad_norm": 0.06349420547485352,
      "learning_rate": 1.5010934937124114e-05,
      "loss": 0.0005,
      "step": 18250
    },
    {
      "epoch": 4.991798797156917,
      "grad_norm": 0.14053119719028473,
      "learning_rate": 1.5008201202843085e-05,
      "loss": 0.0348,
      "step": 18260
    },
    {
      "epoch": 4.994532531437944,
      "grad_norm": 1.190657138824463,
      "learning_rate": 1.5005467468562055e-05,
      "loss": 0.0084,
      "step": 18270
    },
    {
      "epoch": 4.997266265718972,
      "grad_norm": 0.12508846819400787,
      "learning_rate": 1.500273373428103e-05,
      "loss": 0.0083,
      "step": 18280
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.003980798646807671,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.011,
      "step": 18290
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9898361004682844,
      "eval_f1": 0.958756208162384,
      "eval_loss": 0.0441877581179142,
      "eval_precision": 0.9702797202797203,
      "eval_recall": 0.9475032010243278,
      "eval_runtime": 796.8568,
      "eval_samples_per_second": 23.61,
      "eval_steps_per_second": 0.984,
      "step": 18290
    },
    {
      "epoch": 5.002733734281028,
      "grad_norm": 0.003605360398069024,
      "learning_rate": 1.4997266265718972e-05,
      "loss": 0.0072,
      "step": 18300
    },
    {
      "epoch": 5.005467468562056,
      "grad_norm": 0.003336407244205475,
      "learning_rate": 1.4994532531437947e-05,
      "loss": 0.0009,
      "step": 18310
    },
    {
      "epoch": 5.008201202843083,
      "grad_norm": 0.003254360519349575,
      "learning_rate": 1.4991798797156917e-05,
      "loss": 0.0971,
      "step": 18320
    },
    {
      "epoch": 5.010934937124111,
      "grad_norm": 0.22014956176280975,
      "learning_rate": 1.4989065062875889e-05,
      "loss": 0.0633,
      "step": 18330
    },
    {
      "epoch": 5.0136686714051395,
      "grad_norm": 0.009596328251063824,
      "learning_rate": 1.498633132859486e-05,
      "loss": 0.0015,
      "step": 18340
    },
    {
      "epoch": 5.016402405686168,
      "grad_norm": 0.6749267578125,
      "learning_rate": 1.4983597594313834e-05,
      "loss": 0.0144,
      "step": 18350
    },
    {
      "epoch": 5.019136139967195,
      "grad_norm": 0.3872849643230438,
      "learning_rate": 1.4980863860032805e-05,
      "loss": 0.0245,
      "step": 18360
    },
    {
      "epoch": 5.021869874248223,
      "grad_norm": 0.03964923322200775,
      "learning_rate": 1.4978130125751777e-05,
      "loss": 0.0124,
      "step": 18370
    },
    {
      "epoch": 5.024603608529251,
      "grad_norm": 0.03423886373639107,
      "learning_rate": 1.497539639147075e-05,
      "loss": 0.0119,
      "step": 18380
    },
    {
      "epoch": 5.027337342810279,
      "grad_norm": 0.010458503849804401,
      "learning_rate": 1.4972662657189722e-05,
      "loss": 0.0014,
      "step": 18390
    },
    {
      "epoch": 5.030071077091307,
      "grad_norm": 0.683242678642273,
      "learning_rate": 1.4969928922908694e-05,
      "loss": 0.017,
      "step": 18400
    },
    {
      "epoch": 5.032804811372334,
      "grad_norm": 0.004767360165715218,
      "learning_rate": 1.4967195188627665e-05,
      "loss": 0.0161,
      "step": 18410
    },
    {
      "epoch": 5.035538545653362,
      "grad_norm": 10.199996948242188,
      "learning_rate": 1.4964461454346639e-05,
      "loss": 0.0215,
      "step": 18420
    },
    {
      "epoch": 5.03827227993439,
      "grad_norm": 0.012777355499565601,
      "learning_rate": 1.496172772006561e-05,
      "loss": 0.0254,
      "step": 18430
    },
    {
      "epoch": 5.0410060142154185,
      "grad_norm": 0.1743031144142151,
      "learning_rate": 1.4958993985784582e-05,
      "loss": 0.0163,
      "step": 18440
    },
    {
      "epoch": 5.043739748496447,
      "grad_norm": 0.007922139018774033,
      "learning_rate": 1.4956260251503555e-05,
      "loss": 0.0145,
      "step": 18450
    },
    {
      "epoch": 5.046473482777474,
      "grad_norm": 0.04299631714820862,
      "learning_rate": 1.4953526517222527e-05,
      "loss": 0.0394,
      "step": 18460
    },
    {
      "epoch": 5.049207217058502,
      "grad_norm": 0.007168445270508528,
      "learning_rate": 1.4950792782941499e-05,
      "loss": 0.0531,
      "step": 18470
    },
    {
      "epoch": 5.05194095133953,
      "grad_norm": 0.014155961573123932,
      "learning_rate": 1.494805904866047e-05,
      "loss": 0.0485,
      "step": 18480
    },
    {
      "epoch": 5.054674685620558,
      "grad_norm": 0.0487356036901474,
      "learning_rate": 1.4945325314379444e-05,
      "loss": 0.0129,
      "step": 18490
    },
    {
      "epoch": 5.057408419901585,
      "grad_norm": 3.6510894298553467,
      "learning_rate": 1.4942591580098415e-05,
      "loss": 0.0288,
      "step": 18500
    },
    {
      "epoch": 5.060142154182613,
      "grad_norm": 0.08979873359203339,
      "learning_rate": 1.4939857845817387e-05,
      "loss": 0.0324,
      "step": 18510
    },
    {
      "epoch": 5.062875888463641,
      "grad_norm": 2.129563331604004,
      "learning_rate": 1.493712411153636e-05,
      "loss": 0.0099,
      "step": 18520
    },
    {
      "epoch": 5.065609622744669,
      "grad_norm": 0.005415973253548145,
      "learning_rate": 1.4934390377255332e-05,
      "loss": 0.0278,
      "step": 18530
    },
    {
      "epoch": 5.0683433570256975,
      "grad_norm": 2.1220924854278564,
      "learning_rate": 1.4931656642974304e-05,
      "loss": 0.0085,
      "step": 18540
    },
    {
      "epoch": 5.071077091306725,
      "grad_norm": 5.851621627807617,
      "learning_rate": 1.4928922908693275e-05,
      "loss": 0.0141,
      "step": 18550
    },
    {
      "epoch": 5.073810825587753,
      "grad_norm": 0.11039628088474274,
      "learning_rate": 1.4926189174412249e-05,
      "loss": 0.0327,
      "step": 18560
    },
    {
      "epoch": 5.076544559868781,
      "grad_norm": 0.010341625660657883,
      "learning_rate": 1.492345544013122e-05,
      "loss": 0.0037,
      "step": 18570
    },
    {
      "epoch": 5.079278294149809,
      "grad_norm": 0.005688655190169811,
      "learning_rate": 1.4920721705850192e-05,
      "loss": 0.0153,
      "step": 18580
    },
    {
      "epoch": 5.082012028430836,
      "grad_norm": 0.021534057334065437,
      "learning_rate": 1.4917987971569165e-05,
      "loss": 0.0166,
      "step": 18590
    },
    {
      "epoch": 5.084745762711864,
      "grad_norm": 0.025687189772725105,
      "learning_rate": 1.4915254237288137e-05,
      "loss": 0.0294,
      "step": 18600
    },
    {
      "epoch": 5.087479496992892,
      "grad_norm": 0.011787466704845428,
      "learning_rate": 1.4912520503007109e-05,
      "loss": 0.0164,
      "step": 18610
    },
    {
      "epoch": 5.09021323127392,
      "grad_norm": 0.00453356234356761,
      "learning_rate": 1.490978676872608e-05,
      "loss": 0.0262,
      "step": 18620
    },
    {
      "epoch": 5.092946965554948,
      "grad_norm": 2.6122238636016846,
      "learning_rate": 1.4907053034445054e-05,
      "loss": 0.0185,
      "step": 18630
    },
    {
      "epoch": 5.095680699835976,
      "grad_norm": 7.722999095916748,
      "learning_rate": 1.4904319300164025e-05,
      "loss": 0.0334,
      "step": 18640
    },
    {
      "epoch": 5.098414434117004,
      "grad_norm": 0.013084269128739834,
      "learning_rate": 1.4901585565882997e-05,
      "loss": 0.0059,
      "step": 18650
    },
    {
      "epoch": 5.101148168398032,
      "grad_norm": 0.014546473510563374,
      "learning_rate": 1.489885183160197e-05,
      "loss": 0.0328,
      "step": 18660
    },
    {
      "epoch": 5.10388190267906,
      "grad_norm": 0.0305679552257061,
      "learning_rate": 1.4896118097320942e-05,
      "loss": 0.0184,
      "step": 18670
    },
    {
      "epoch": 5.106615636960088,
      "grad_norm": 1.004699945449829,
      "learning_rate": 1.4893384363039914e-05,
      "loss": 0.0172,
      "step": 18680
    },
    {
      "epoch": 5.109349371241115,
      "grad_norm": 0.007544691674411297,
      "learning_rate": 1.4890650628758885e-05,
      "loss": 0.0256,
      "step": 18690
    },
    {
      "epoch": 5.112083105522143,
      "grad_norm": 0.005614016205072403,
      "learning_rate": 1.4887916894477859e-05,
      "loss": 0.0089,
      "step": 18700
    },
    {
      "epoch": 5.114816839803171,
      "grad_norm": 0.5119045972824097,
      "learning_rate": 1.488518316019683e-05,
      "loss": 0.0024,
      "step": 18710
    },
    {
      "epoch": 5.117550574084199,
      "grad_norm": 5.166245460510254,
      "learning_rate": 1.4882449425915802e-05,
      "loss": 0.0072,
      "step": 18720
    },
    {
      "epoch": 5.1202843083652265,
      "grad_norm": 0.0019223294220864773,
      "learning_rate": 1.4879715691634775e-05,
      "loss": 0.0044,
      "step": 18730
    },
    {
      "epoch": 5.123018042646255,
      "grad_norm": 0.049198660999536514,
      "learning_rate": 1.4876981957353747e-05,
      "loss": 0.0231,
      "step": 18740
    },
    {
      "epoch": 5.125751776927283,
      "grad_norm": 0.1929863542318344,
      "learning_rate": 1.4874248223072719e-05,
      "loss": 0.0018,
      "step": 18750
    },
    {
      "epoch": 5.128485511208311,
      "grad_norm": 0.013654346577823162,
      "learning_rate": 1.487151448879169e-05,
      "loss": 0.0011,
      "step": 18760
    },
    {
      "epoch": 5.131219245489339,
      "grad_norm": 0.0015162235358729959,
      "learning_rate": 1.4868780754510664e-05,
      "loss": 0.0265,
      "step": 18770
    },
    {
      "epoch": 5.133952979770366,
      "grad_norm": 0.002334082964807749,
      "learning_rate": 1.4866047020229635e-05,
      "loss": 0.004,
      "step": 18780
    },
    {
      "epoch": 5.136686714051394,
      "grad_norm": 9.10394287109375,
      "learning_rate": 1.4863313285948607e-05,
      "loss": 0.0299,
      "step": 18790
    },
    {
      "epoch": 5.139420448332422,
      "grad_norm": 0.0016043508658185601,
      "learning_rate": 1.486057955166758e-05,
      "loss": 0.025,
      "step": 18800
    },
    {
      "epoch": 5.14215418261345,
      "grad_norm": 0.005455747712403536,
      "learning_rate": 1.4857845817386552e-05,
      "loss": 0.0544,
      "step": 18810
    },
    {
      "epoch": 5.144887916894477,
      "grad_norm": 0.014010105282068253,
      "learning_rate": 1.4855112083105524e-05,
      "loss": 0.0194,
      "step": 18820
    },
    {
      "epoch": 5.1476216511755055,
      "grad_norm": 0.0314764529466629,
      "learning_rate": 1.4852378348824497e-05,
      "loss": 0.0439,
      "step": 18830
    },
    {
      "epoch": 5.150355385456534,
      "grad_norm": 0.004237666260451078,
      "learning_rate": 1.4849644614543469e-05,
      "loss": 0.0011,
      "step": 18840
    },
    {
      "epoch": 5.153089119737562,
      "grad_norm": 0.09143640100955963,
      "learning_rate": 1.484691088026244e-05,
      "loss": 0.0435,
      "step": 18850
    },
    {
      "epoch": 5.15582285401859,
      "grad_norm": 0.0720151886343956,
      "learning_rate": 1.484417714598141e-05,
      "loss": 0.0104,
      "step": 18860
    },
    {
      "epoch": 5.158556588299617,
      "grad_norm": 0.006581034045666456,
      "learning_rate": 1.4841443411700385e-05,
      "loss": 0.0066,
      "step": 18870
    },
    {
      "epoch": 5.161290322580645,
      "grad_norm": 0.003523568157106638,
      "learning_rate": 1.4838709677419357e-05,
      "loss": 0.0077,
      "step": 18880
    },
    {
      "epoch": 5.164024056861673,
      "grad_norm": 0.0031025114003568888,
      "learning_rate": 1.4835975943138327e-05,
      "loss": 0.0093,
      "step": 18890
    },
    {
      "epoch": 5.166757791142701,
      "grad_norm": 0.006043820641934872,
      "learning_rate": 1.4833242208857302e-05,
      "loss": 0.0492,
      "step": 18900
    },
    {
      "epoch": 5.169491525423728,
      "grad_norm": 0.056640371680259705,
      "learning_rate": 1.4830508474576274e-05,
      "loss": 0.0245,
      "step": 18910
    },
    {
      "epoch": 5.172225259704756,
      "grad_norm": 0.1188933476805687,
      "learning_rate": 1.4827774740295243e-05,
      "loss": 0.0034,
      "step": 18920
    },
    {
      "epoch": 5.1749589939857845,
      "grad_norm": 0.08574236929416656,
      "learning_rate": 1.4825041006014215e-05,
      "loss": 0.0326,
      "step": 18930
    },
    {
      "epoch": 5.177692728266813,
      "grad_norm": 0.029421240091323853,
      "learning_rate": 1.482230727173319e-05,
      "loss": 0.0376,
      "step": 18940
    },
    {
      "epoch": 5.180426462547841,
      "grad_norm": 0.3821658790111542,
      "learning_rate": 1.481957353745216e-05,
      "loss": 0.0034,
      "step": 18950
    },
    {
      "epoch": 5.183160196828868,
      "grad_norm": 0.004867156036198139,
      "learning_rate": 1.4816839803171132e-05,
      "loss": 0.0119,
      "step": 18960
    },
    {
      "epoch": 5.185893931109896,
      "grad_norm": 0.11001146584749222,
      "learning_rate": 1.4814106068890107e-05,
      "loss": 0.0608,
      "step": 18970
    },
    {
      "epoch": 5.188627665390924,
      "grad_norm": 0.4934654235839844,
      "learning_rate": 1.4811372334609077e-05,
      "loss": 0.0046,
      "step": 18980
    },
    {
      "epoch": 5.191361399671952,
      "grad_norm": 3.5925841331481934,
      "learning_rate": 1.4808638600328048e-05,
      "loss": 0.0035,
      "step": 18990
    },
    {
      "epoch": 5.19409513395298,
      "grad_norm": 0.2919580042362213,
      "learning_rate": 1.480590486604702e-05,
      "loss": 0.0514,
      "step": 19000
    },
    {
      "epoch": 5.196828868234007,
      "grad_norm": 0.0810738205909729,
      "learning_rate": 1.4803171131765993e-05,
      "loss": 0.0274,
      "step": 19010
    },
    {
      "epoch": 5.199562602515035,
      "grad_norm": 8.704806327819824,
      "learning_rate": 1.4800437397484965e-05,
      "loss": 0.0284,
      "step": 19020
    },
    {
      "epoch": 5.2022963367960635,
      "grad_norm": 0.006887608673423529,
      "learning_rate": 1.4797703663203937e-05,
      "loss": 0.0004,
      "step": 19030
    },
    {
      "epoch": 5.205030071077092,
      "grad_norm": 0.045080527663230896,
      "learning_rate": 1.479496992892291e-05,
      "loss": 0.0712,
      "step": 19040
    },
    {
      "epoch": 5.207763805358119,
      "grad_norm": 0.19304761290550232,
      "learning_rate": 1.4792236194641882e-05,
      "loss": 0.0013,
      "step": 19050
    },
    {
      "epoch": 5.210497539639147,
      "grad_norm": 2.026374340057373,
      "learning_rate": 1.4789502460360853e-05,
      "loss": 0.0673,
      "step": 19060
    },
    {
      "epoch": 5.213231273920175,
      "grad_norm": 0.031666483730077744,
      "learning_rate": 1.4786768726079825e-05,
      "loss": 0.0365,
      "step": 19070
    },
    {
      "epoch": 5.215965008201203,
      "grad_norm": 0.05314502492547035,
      "learning_rate": 1.4784034991798798e-05,
      "loss": 0.0118,
      "step": 19080
    },
    {
      "epoch": 5.218698742482231,
      "grad_norm": 1.9412744045257568,
      "learning_rate": 1.478130125751777e-05,
      "loss": 0.0066,
      "step": 19090
    },
    {
      "epoch": 5.221432476763258,
      "grad_norm": 0.029086407274007797,
      "learning_rate": 1.4778567523236742e-05,
      "loss": 0.0006,
      "step": 19100
    },
    {
      "epoch": 5.224166211044286,
      "grad_norm": 0.009934128262102604,
      "learning_rate": 1.4775833788955715e-05,
      "loss": 0.009,
      "step": 19110
    },
    {
      "epoch": 5.226899945325314,
      "grad_norm": 0.006090893410146236,
      "learning_rate": 1.4773100054674687e-05,
      "loss": 0.0028,
      "step": 19120
    },
    {
      "epoch": 5.2296336796063425,
      "grad_norm": 0.47823432087898254,
      "learning_rate": 1.4770366320393658e-05,
      "loss": 0.0423,
      "step": 19130
    },
    {
      "epoch": 5.232367413887371,
      "grad_norm": 0.8764489889144897,
      "learning_rate": 1.476763258611263e-05,
      "loss": 0.0465,
      "step": 19140
    },
    {
      "epoch": 5.235101148168398,
      "grad_norm": 0.012905267998576164,
      "learning_rate": 1.4764898851831603e-05,
      "loss": 0.0196,
      "step": 19150
    },
    {
      "epoch": 5.237834882449426,
      "grad_norm": 0.007605725433677435,
      "learning_rate": 1.4762165117550575e-05,
      "loss": 0.0111,
      "step": 19160
    },
    {
      "epoch": 5.240568616730454,
      "grad_norm": 8.476181030273438,
      "learning_rate": 1.4759431383269547e-05,
      "loss": 0.0252,
      "step": 19170
    },
    {
      "epoch": 5.243302351011482,
      "grad_norm": 0.005514983087778091,
      "learning_rate": 1.475669764898852e-05,
      "loss": 0.0326,
      "step": 19180
    },
    {
      "epoch": 5.246036085292509,
      "grad_norm": 0.006699998397380114,
      "learning_rate": 1.4753963914707492e-05,
      "loss": 0.0172,
      "step": 19190
    },
    {
      "epoch": 5.248769819573537,
      "grad_norm": 0.010775254108011723,
      "learning_rate": 1.4751230180426463e-05,
      "loss": 0.0004,
      "step": 19200
    },
    {
      "epoch": 5.251503553854565,
      "grad_norm": 1.6245222091674805,
      "learning_rate": 1.4748496446145435e-05,
      "loss": 0.0062,
      "step": 19210
    },
    {
      "epoch": 5.254237288135593,
      "grad_norm": 0.009829191491007805,
      "learning_rate": 1.4745762711864408e-05,
      "loss": 0.0006,
      "step": 19220
    },
    {
      "epoch": 5.2569710224166215,
      "grad_norm": 6.620339393615723,
      "learning_rate": 1.474302897758338e-05,
      "loss": 0.0679,
      "step": 19230
    },
    {
      "epoch": 5.259704756697649,
      "grad_norm": 0.012739524245262146,
      "learning_rate": 1.4740295243302352e-05,
      "loss": 0.0642,
      "step": 19240
    },
    {
      "epoch": 5.262438490978677,
      "grad_norm": 0.04243909940123558,
      "learning_rate": 1.4737561509021325e-05,
      "loss": 0.0064,
      "step": 19250
    },
    {
      "epoch": 5.265172225259705,
      "grad_norm": 0.028588350862264633,
      "learning_rate": 1.4734827774740297e-05,
      "loss": 0.037,
      "step": 19260
    },
    {
      "epoch": 5.267905959540733,
      "grad_norm": 0.43337973952293396,
      "learning_rate": 1.4732094040459268e-05,
      "loss": 0.0059,
      "step": 19270
    },
    {
      "epoch": 5.27063969382176,
      "grad_norm": 0.01674978993833065,
      "learning_rate": 1.472936030617824e-05,
      "loss": 0.0353,
      "step": 19280
    },
    {
      "epoch": 5.273373428102788,
      "grad_norm": 0.016450563445687294,
      "learning_rate": 1.4726626571897213e-05,
      "loss": 0.0238,
      "step": 19290
    },
    {
      "epoch": 5.276107162383816,
      "grad_norm": 0.008812758140265942,
      "learning_rate": 1.4723892837616185e-05,
      "loss": 0.0105,
      "step": 19300
    },
    {
      "epoch": 5.278840896664844,
      "grad_norm": 0.00431128591299057,
      "learning_rate": 1.4721159103335157e-05,
      "loss": 0.0373,
      "step": 19310
    },
    {
      "epoch": 5.281574630945872,
      "grad_norm": 0.09190928190946579,
      "learning_rate": 1.471842536905413e-05,
      "loss": 0.0277,
      "step": 19320
    },
    {
      "epoch": 5.2843083652269,
      "grad_norm": 0.02120835706591606,
      "learning_rate": 1.4715691634773102e-05,
      "loss": 0.0405,
      "step": 19330
    },
    {
      "epoch": 5.287042099507928,
      "grad_norm": 6.207897186279297,
      "learning_rate": 1.4712957900492073e-05,
      "loss": 0.0428,
      "step": 19340
    },
    {
      "epoch": 5.289775833788956,
      "grad_norm": 0.04440939053893089,
      "learning_rate": 1.4710224166211045e-05,
      "loss": 0.0028,
      "step": 19350
    },
    {
      "epoch": 5.292509568069984,
      "grad_norm": 0.08699934184551239,
      "learning_rate": 1.4707490431930018e-05,
      "loss": 0.0039,
      "step": 19360
    },
    {
      "epoch": 5.295243302351011,
      "grad_norm": 0.010747716762125492,
      "learning_rate": 1.470475669764899e-05,
      "loss": 0.0006,
      "step": 19370
    },
    {
      "epoch": 5.297977036632039,
      "grad_norm": 0.009277177043259144,
      "learning_rate": 1.4702022963367962e-05,
      "loss": 0.0231,
      "step": 19380
    },
    {
      "epoch": 5.300710770913067,
      "grad_norm": 4.226246356964111,
      "learning_rate": 1.4699289229086935e-05,
      "loss": 0.052,
      "step": 19390
    },
    {
      "epoch": 5.303444505194095,
      "grad_norm": 0.056267306208610535,
      "learning_rate": 1.4696555494805907e-05,
      "loss": 0.0027,
      "step": 19400
    },
    {
      "epoch": 5.306178239475123,
      "grad_norm": 0.04016296565532684,
      "learning_rate": 1.4693821760524878e-05,
      "loss": 0.026,
      "step": 19410
    },
    {
      "epoch": 5.3089119737561505,
      "grad_norm": 0.061010025441646576,
      "learning_rate": 1.469108802624385e-05,
      "loss": 0.0015,
      "step": 19420
    },
    {
      "epoch": 5.311645708037179,
      "grad_norm": 0.010415922850370407,
      "learning_rate": 1.4688354291962823e-05,
      "loss": 0.0012,
      "step": 19430
    },
    {
      "epoch": 5.314379442318207,
      "grad_norm": 0.01645638979971409,
      "learning_rate": 1.4685620557681795e-05,
      "loss": 0.0516,
      "step": 19440
    },
    {
      "epoch": 5.317113176599235,
      "grad_norm": 1.593556523323059,
      "learning_rate": 1.4682886823400767e-05,
      "loss": 0.0626,
      "step": 19450
    },
    {
      "epoch": 5.319846910880263,
      "grad_norm": 0.023050427436828613,
      "learning_rate": 1.468015308911974e-05,
      "loss": 0.0295,
      "step": 19460
    },
    {
      "epoch": 5.32258064516129,
      "grad_norm": 0.03406061232089996,
      "learning_rate": 1.4677419354838712e-05,
      "loss": 0.0134,
      "step": 19470
    },
    {
      "epoch": 5.325314379442318,
      "grad_norm": 0.09293763339519501,
      "learning_rate": 1.4674685620557683e-05,
      "loss": 0.0294,
      "step": 19480
    },
    {
      "epoch": 5.328048113723346,
      "grad_norm": 0.14971336722373962,
      "learning_rate": 1.4671951886276653e-05,
      "loss": 0.0113,
      "step": 19490
    },
    {
      "epoch": 5.330781848004374,
      "grad_norm": 0.487626314163208,
      "learning_rate": 1.4669218151995628e-05,
      "loss": 0.0243,
      "step": 19500
    },
    {
      "epoch": 5.3335155822854015,
      "grad_norm": 0.01137436181306839,
      "learning_rate": 1.46664844177146e-05,
      "loss": 0.0251,
      "step": 19510
    },
    {
      "epoch": 5.3362493165664295,
      "grad_norm": 0.02345333993434906,
      "learning_rate": 1.466375068343357e-05,
      "loss": 0.0011,
      "step": 19520
    },
    {
      "epoch": 5.338983050847458,
      "grad_norm": 2.3535189628601074,
      "learning_rate": 1.4661016949152545e-05,
      "loss": 0.0168,
      "step": 19530
    },
    {
      "epoch": 5.341716785128486,
      "grad_norm": 0.018723264336586,
      "learning_rate": 1.4658283214871517e-05,
      "loss": 0.0436,
      "step": 19540
    },
    {
      "epoch": 5.344450519409514,
      "grad_norm": 0.6679877042770386,
      "learning_rate": 1.4655549480590487e-05,
      "loss": 0.0319,
      "step": 19550
    },
    {
      "epoch": 5.347184253690541,
      "grad_norm": 0.06741238385438919,
      "learning_rate": 1.4652815746309458e-05,
      "loss": 0.0235,
      "step": 19560
    },
    {
      "epoch": 5.349917987971569,
      "grad_norm": 5.060357093811035,
      "learning_rate": 1.4650082012028433e-05,
      "loss": 0.0415,
      "step": 19570
    },
    {
      "epoch": 5.352651722252597,
      "grad_norm": 0.333433598279953,
      "learning_rate": 1.4647348277747403e-05,
      "loss": 0.0138,
      "step": 19580
    },
    {
      "epoch": 5.355385456533625,
      "grad_norm": 0.09756223112344742,
      "learning_rate": 1.4644614543466375e-05,
      "loss": 0.0129,
      "step": 19590
    },
    {
      "epoch": 5.358119190814653,
      "grad_norm": 0.03063875250518322,
      "learning_rate": 1.464188080918535e-05,
      "loss": 0.0269,
      "step": 19600
    },
    {
      "epoch": 5.3608529250956805,
      "grad_norm": 0.006814761087298393,
      "learning_rate": 1.463914707490432e-05,
      "loss": 0.0006,
      "step": 19610
    },
    {
      "epoch": 5.3635866593767085,
      "grad_norm": 2.2325263023376465,
      "learning_rate": 1.4636413340623292e-05,
      "loss": 0.0152,
      "step": 19620
    },
    {
      "epoch": 5.366320393657737,
      "grad_norm": 0.003767248708754778,
      "learning_rate": 1.4633679606342263e-05,
      "loss": 0.0469,
      "step": 19630
    },
    {
      "epoch": 5.369054127938765,
      "grad_norm": 0.03770190849900246,
      "learning_rate": 1.4630945872061237e-05,
      "loss": 0.0257,
      "step": 19640
    },
    {
      "epoch": 5.371787862219792,
      "grad_norm": 0.05565422400832176,
      "learning_rate": 1.4628212137780208e-05,
      "loss": 0.0176,
      "step": 19650
    },
    {
      "epoch": 5.37452159650082,
      "grad_norm": 0.009265712462365627,
      "learning_rate": 1.462547840349918e-05,
      "loss": 0.0241,
      "step": 19660
    },
    {
      "epoch": 5.377255330781848,
      "grad_norm": 2.2577309608459473,
      "learning_rate": 1.4622744669218153e-05,
      "loss": 0.0178,
      "step": 19670
    },
    {
      "epoch": 5.379989065062876,
      "grad_norm": 0.026761140674352646,
      "learning_rate": 1.4620010934937125e-05,
      "loss": 0.0443,
      "step": 19680
    },
    {
      "epoch": 5.382722799343904,
      "grad_norm": 2.421107769012451,
      "learning_rate": 1.4617277200656097e-05,
      "loss": 0.0253,
      "step": 19690
    },
    {
      "epoch": 5.385456533624931,
      "grad_norm": 0.34027695655822754,
      "learning_rate": 1.4614543466375068e-05,
      "loss": 0.0186,
      "step": 19700
    },
    {
      "epoch": 5.3881902679059595,
      "grad_norm": 0.016108438372612,
      "learning_rate": 1.4611809732094042e-05,
      "loss": 0.0333,
      "step": 19710
    },
    {
      "epoch": 5.3909240021869875,
      "grad_norm": 0.012294397689402103,
      "learning_rate": 1.4609075997813013e-05,
      "loss": 0.024,
      "step": 19720
    },
    {
      "epoch": 5.393657736468016,
      "grad_norm": 0.48305580019950867,
      "learning_rate": 1.4606342263531985e-05,
      "loss": 0.0629,
      "step": 19730
    },
    {
      "epoch": 5.396391470749043,
      "grad_norm": 0.014013724401593208,
      "learning_rate": 1.4603608529250958e-05,
      "loss": 0.0468,
      "step": 19740
    },
    {
      "epoch": 5.399125205030071,
      "grad_norm": 1.759544849395752,
      "learning_rate": 1.460087479496993e-05,
      "loss": 0.0229,
      "step": 19750
    },
    {
      "epoch": 5.401858939311099,
      "grad_norm": 0.015407471917569637,
      "learning_rate": 1.4598141060688902e-05,
      "loss": 0.016,
      "step": 19760
    },
    {
      "epoch": 5.404592673592127,
      "grad_norm": 0.07392069697380066,
      "learning_rate": 1.4595407326407873e-05,
      "loss": 0.0353,
      "step": 19770
    },
    {
      "epoch": 5.407326407873155,
      "grad_norm": 5.913608551025391,
      "learning_rate": 1.4592673592126847e-05,
      "loss": 0.0301,
      "step": 19780
    },
    {
      "epoch": 5.410060142154182,
      "grad_norm": 0.030805546790361404,
      "learning_rate": 1.4589939857845818e-05,
      "loss": 0.0208,
      "step": 19790
    },
    {
      "epoch": 5.41279387643521,
      "grad_norm": 0.030090786516666412,
      "learning_rate": 1.458720612356479e-05,
      "loss": 0.0222,
      "step": 19800
    },
    {
      "epoch": 5.4155276107162384,
      "grad_norm": 0.47905775904655457,
      "learning_rate": 1.4584472389283763e-05,
      "loss": 0.0131,
      "step": 19810
    },
    {
      "epoch": 5.4182613449972665,
      "grad_norm": 0.0025024539791047573,
      "learning_rate": 1.4581738655002735e-05,
      "loss": 0.0062,
      "step": 19820
    },
    {
      "epoch": 5.420995079278294,
      "grad_norm": 2.1534368991851807,
      "learning_rate": 1.4579004920721707e-05,
      "loss": 0.0494,
      "step": 19830
    },
    {
      "epoch": 5.423728813559322,
      "grad_norm": 4.3463850021362305,
      "learning_rate": 1.4576271186440678e-05,
      "loss": 0.0534,
      "step": 19840
    },
    {
      "epoch": 5.42646254784035,
      "grad_norm": 0.005228459369391203,
      "learning_rate": 1.4573537452159652e-05,
      "loss": 0.0024,
      "step": 19850
    },
    {
      "epoch": 5.429196282121378,
      "grad_norm": 0.07669807225465775,
      "learning_rate": 1.4570803717878623e-05,
      "loss": 0.067,
      "step": 19860
    },
    {
      "epoch": 5.431930016402406,
      "grad_norm": 0.03193419799208641,
      "learning_rate": 1.4568069983597595e-05,
      "loss": 0.0023,
      "step": 19870
    },
    {
      "epoch": 5.434663750683433,
      "grad_norm": 1.3131632804870605,
      "learning_rate": 1.4565336249316568e-05,
      "loss": 0.0338,
      "step": 19880
    },
    {
      "epoch": 5.437397484964461,
      "grad_norm": 0.6024014949798584,
      "learning_rate": 1.456260251503554e-05,
      "loss": 0.0239,
      "step": 19890
    },
    {
      "epoch": 5.440131219245489,
      "grad_norm": 0.9571362733840942,
      "learning_rate": 1.4559868780754512e-05,
      "loss": 0.0075,
      "step": 19900
    },
    {
      "epoch": 5.4428649535265174,
      "grad_norm": 0.059205688536167145,
      "learning_rate": 1.4557135046473485e-05,
      "loss": 0.0008,
      "step": 19910
    },
    {
      "epoch": 5.445598687807545,
      "grad_norm": 0.005508671514689922,
      "learning_rate": 1.4554401312192457e-05,
      "loss": 0.0107,
      "step": 19920
    },
    {
      "epoch": 5.448332422088573,
      "grad_norm": 0.008313149213790894,
      "learning_rate": 1.4551667577911428e-05,
      "loss": 0.0038,
      "step": 19930
    },
    {
      "epoch": 5.451066156369601,
      "grad_norm": 0.0036625824868679047,
      "learning_rate": 1.45489338436304e-05,
      "loss": 0.0395,
      "step": 19940
    },
    {
      "epoch": 5.453799890650629,
      "grad_norm": 0.6594804525375366,
      "learning_rate": 1.4546200109349373e-05,
      "loss": 0.0107,
      "step": 19950
    },
    {
      "epoch": 5.456533624931657,
      "grad_norm": 0.006050354801118374,
      "learning_rate": 1.4543466375068345e-05,
      "loss": 0.0132,
      "step": 19960
    },
    {
      "epoch": 5.459267359212684,
      "grad_norm": 2.252484083175659,
      "learning_rate": 1.4540732640787316e-05,
      "loss": 0.0567,
      "step": 19970
    },
    {
      "epoch": 5.462001093493712,
      "grad_norm": 0.00369646237231791,
      "learning_rate": 1.453799890650629e-05,
      "loss": 0.0318,
      "step": 19980
    },
    {
      "epoch": 5.46473482777474,
      "grad_norm": 0.03951394557952881,
      "learning_rate": 1.4535265172225261e-05,
      "loss": 0.0339,
      "step": 19990
    },
    {
      "epoch": 5.467468562055768,
      "grad_norm": 0.25763022899627686,
      "learning_rate": 1.4532531437944233e-05,
      "loss": 0.0012,
      "step": 20000
    },
    {
      "epoch": 5.470202296336796,
      "grad_norm": 0.010015638545155525,
      "learning_rate": 1.4529797703663205e-05,
      "loss": 0.0221,
      "step": 20010
    },
    {
      "epoch": 5.472936030617824,
      "grad_norm": 0.15069513022899628,
      "learning_rate": 1.4527063969382178e-05,
      "loss": 0.0113,
      "step": 20020
    },
    {
      "epoch": 5.475669764898852,
      "grad_norm": 0.0034743063151836395,
      "learning_rate": 1.452433023510115e-05,
      "loss": 0.0021,
      "step": 20030
    },
    {
      "epoch": 5.47840349917988,
      "grad_norm": 0.0045289876870810986,
      "learning_rate": 1.4521596500820121e-05,
      "loss": 0.0254,
      "step": 20040
    },
    {
      "epoch": 5.481137233460908,
      "grad_norm": 0.006070460192859173,
      "learning_rate": 1.4518862766539095e-05,
      "loss": 0.0053,
      "step": 20050
    },
    {
      "epoch": 5.483870967741936,
      "grad_norm": 0.11235956102609634,
      "learning_rate": 1.4516129032258066e-05,
      "loss": 0.0072,
      "step": 20060
    },
    {
      "epoch": 5.486604702022963,
      "grad_norm": 0.01262606494128704,
      "learning_rate": 1.4513395297977038e-05,
      "loss": 0.0508,
      "step": 20070
    },
    {
      "epoch": 5.489338436303991,
      "grad_norm": 0.08492422103881836,
      "learning_rate": 1.451066156369601e-05,
      "loss": 0.0207,
      "step": 20080
    },
    {
      "epoch": 5.492072170585019,
      "grad_norm": 9.648324966430664,
      "learning_rate": 1.4507927829414983e-05,
      "loss": 0.0099,
      "step": 20090
    },
    {
      "epoch": 5.494805904866047,
      "grad_norm": 0.004702019039541483,
      "learning_rate": 1.4505194095133955e-05,
      "loss": 0.004,
      "step": 20100
    },
    {
      "epoch": 5.4975396391470746,
      "grad_norm": 0.032568007707595825,
      "learning_rate": 1.4502460360852926e-05,
      "loss": 0.003,
      "step": 20110
    },
    {
      "epoch": 5.500273373428103,
      "grad_norm": 0.002582082524895668,
      "learning_rate": 1.44997266265719e-05,
      "loss": 0.0276,
      "step": 20120
    },
    {
      "epoch": 5.503007107709131,
      "grad_norm": 7.871533393859863,
      "learning_rate": 1.4496992892290871e-05,
      "loss": 0.0074,
      "step": 20130
    },
    {
      "epoch": 5.505740841990159,
      "grad_norm": 0.002929745940491557,
      "learning_rate": 1.4494259158009843e-05,
      "loss": 0.0231,
      "step": 20140
    },
    {
      "epoch": 5.508474576271187,
      "grad_norm": 0.03930366411805153,
      "learning_rate": 1.4491525423728813e-05,
      "loss": 0.0082,
      "step": 20150
    },
    {
      "epoch": 5.511208310552214,
      "grad_norm": 0.04002619907259941,
      "learning_rate": 1.4488791689447788e-05,
      "loss": 0.0087,
      "step": 20160
    },
    {
      "epoch": 5.513942044833242,
      "grad_norm": 0.008425027132034302,
      "learning_rate": 1.448605795516676e-05,
      "loss": 0.0035,
      "step": 20170
    },
    {
      "epoch": 5.51667577911427,
      "grad_norm": 0.0010874535655602813,
      "learning_rate": 1.448332422088573e-05,
      "loss": 0.001,
      "step": 20180
    },
    {
      "epoch": 5.519409513395298,
      "grad_norm": 0.007446364965289831,
      "learning_rate": 1.4480590486604705e-05,
      "loss": 0.0579,
      "step": 20190
    },
    {
      "epoch": 5.5221432476763255,
      "grad_norm": 0.317143052816391,
      "learning_rate": 1.4477856752323676e-05,
      "loss": 0.015,
      "step": 20200
    },
    {
      "epoch": 5.5248769819573536,
      "grad_norm": 0.0018644355004653335,
      "learning_rate": 1.4475123018042646e-05,
      "loss": 0.0409,
      "step": 20210
    },
    {
      "epoch": 5.527610716238382,
      "grad_norm": 0.007874875329434872,
      "learning_rate": 1.4472389283761618e-05,
      "loss": 0.0039,
      "step": 20220
    },
    {
      "epoch": 5.53034445051941,
      "grad_norm": 0.0038688727654516697,
      "learning_rate": 1.4469655549480593e-05,
      "loss": 0.0147,
      "step": 20230
    },
    {
      "epoch": 5.533078184800438,
      "grad_norm": 0.20626232028007507,
      "learning_rate": 1.4466921815199563e-05,
      "loss": 0.0108,
      "step": 20240
    },
    {
      "epoch": 5.535811919081465,
      "grad_norm": 2.647763967514038,
      "learning_rate": 1.4464188080918535e-05,
      "loss": 0.021,
      "step": 20250
    },
    {
      "epoch": 5.538545653362493,
      "grad_norm": 0.005309585016220808,
      "learning_rate": 1.446145434663751e-05,
      "loss": 0.0391,
      "step": 20260
    },
    {
      "epoch": 5.541279387643521,
      "grad_norm": 0.9574306011199951,
      "learning_rate": 1.445872061235648e-05,
      "loss": 0.0086,
      "step": 20270
    },
    {
      "epoch": 5.544013121924549,
      "grad_norm": 0.003920839633792639,
      "learning_rate": 1.4455986878075451e-05,
      "loss": 0.0395,
      "step": 20280
    },
    {
      "epoch": 5.546746856205576,
      "grad_norm": 32.789180755615234,
      "learning_rate": 1.4453253143794423e-05,
      "loss": 0.0303,
      "step": 20290
    },
    {
      "epoch": 5.5494805904866045,
      "grad_norm": 0.0035118022933602333,
      "learning_rate": 1.4450519409513396e-05,
      "loss": 0.0386,
      "step": 20300
    },
    {
      "epoch": 5.5522143247676325,
      "grad_norm": 0.023145686835050583,
      "learning_rate": 1.4447785675232368e-05,
      "loss": 0.0448,
      "step": 20310
    },
    {
      "epoch": 5.554948059048661,
      "grad_norm": 0.03229029104113579,
      "learning_rate": 1.444505194095134e-05,
      "loss": 0.0496,
      "step": 20320
    },
    {
      "epoch": 5.557681793329689,
      "grad_norm": 0.04848277568817139,
      "learning_rate": 1.4442318206670313e-05,
      "loss": 0.0093,
      "step": 20330
    },
    {
      "epoch": 5.560415527610716,
      "grad_norm": 3.137922763824463,
      "learning_rate": 1.4439584472389285e-05,
      "loss": 0.0353,
      "step": 20340
    },
    {
      "epoch": 5.563149261891744,
      "grad_norm": 0.11200730502605438,
      "learning_rate": 1.4436850738108256e-05,
      "loss": 0.0037,
      "step": 20350
    },
    {
      "epoch": 5.565882996172772,
      "grad_norm": 0.011492394842207432,
      "learning_rate": 1.4434117003827228e-05,
      "loss": 0.0248,
      "step": 20360
    },
    {
      "epoch": 5.5686167304538,
      "grad_norm": 4.583516597747803,
      "learning_rate": 1.4431383269546201e-05,
      "loss": 0.0386,
      "step": 20370
    },
    {
      "epoch": 5.571350464734827,
      "grad_norm": 0.9688547253608704,
      "learning_rate": 1.4428649535265173e-05,
      "loss": 0.0103,
      "step": 20380
    },
    {
      "epoch": 5.574084199015855,
      "grad_norm": 1.7850735187530518,
      "learning_rate": 1.4425915800984145e-05,
      "loss": 0.0076,
      "step": 20390
    },
    {
      "epoch": 5.5768179332968835,
      "grad_norm": 0.5442290306091309,
      "learning_rate": 1.4423182066703118e-05,
      "loss": 0.0025,
      "step": 20400
    },
    {
      "epoch": 5.5795516675779115,
      "grad_norm": 0.4157925248146057,
      "learning_rate": 1.442044833242209e-05,
      "loss": 0.0399,
      "step": 20410
    },
    {
      "epoch": 5.58228540185894,
      "grad_norm": 0.0015272068558260798,
      "learning_rate": 1.4417714598141061e-05,
      "loss": 0.0304,
      "step": 20420
    },
    {
      "epoch": 5.585019136139967,
      "grad_norm": 0.0016628379235044122,
      "learning_rate": 1.4414980863860033e-05,
      "loss": 0.0191,
      "step": 20430
    },
    {
      "epoch": 5.587752870420995,
      "grad_norm": 0.005144536029547453,
      "learning_rate": 1.4412247129579006e-05,
      "loss": 0.0494,
      "step": 20440
    },
    {
      "epoch": 5.590486604702023,
      "grad_norm": 1.9634590148925781,
      "learning_rate": 1.4409513395297978e-05,
      "loss": 0.0189,
      "step": 20450
    },
    {
      "epoch": 5.593220338983051,
      "grad_norm": 0.005651466082781553,
      "learning_rate": 1.440677966101695e-05,
      "loss": 0.0108,
      "step": 20460
    },
    {
      "epoch": 5.595954073264078,
      "grad_norm": 0.02513994835317135,
      "learning_rate": 1.4404045926735923e-05,
      "loss": 0.0395,
      "step": 20470
    },
    {
      "epoch": 5.598687807545106,
      "grad_norm": 0.006085106637328863,
      "learning_rate": 1.4401312192454895e-05,
      "loss": 0.0271,
      "step": 20480
    },
    {
      "epoch": 5.601421541826134,
      "grad_norm": 0.020336249843239784,
      "learning_rate": 1.4398578458173866e-05,
      "loss": 0.03,
      "step": 20490
    },
    {
      "epoch": 5.6041552761071625,
      "grad_norm": 0.9684935212135315,
      "learning_rate": 1.4395844723892838e-05,
      "loss": 0.0097,
      "step": 20500
    },
    {
      "epoch": 5.6068890103881905,
      "grad_norm": 0.877581775188446,
      "learning_rate": 1.4393110989611811e-05,
      "loss": 0.0136,
      "step": 20510
    },
    {
      "epoch": 5.609622744669219,
      "grad_norm": 0.007805695291608572,
      "learning_rate": 1.4390377255330783e-05,
      "loss": 0.038,
      "step": 20520
    },
    {
      "epoch": 5.612356478950246,
      "grad_norm": 0.11066149920225143,
      "learning_rate": 1.4387643521049755e-05,
      "loss": 0.0008,
      "step": 20530
    },
    {
      "epoch": 5.615090213231274,
      "grad_norm": 0.03284250944852829,
      "learning_rate": 1.4384909786768728e-05,
      "loss": 0.0539,
      "step": 20540
    },
    {
      "epoch": 5.617823947512302,
      "grad_norm": 0.015748903155326843,
      "learning_rate": 1.43821760524877e-05,
      "loss": 0.0195,
      "step": 20550
    },
    {
      "epoch": 5.62055768179333,
      "grad_norm": 0.01962684653699398,
      "learning_rate": 1.4379442318206671e-05,
      "loss": 0.0012,
      "step": 20560
    },
    {
      "epoch": 5.623291416074357,
      "grad_norm": 1.52121102809906,
      "learning_rate": 1.4376708583925643e-05,
      "loss": 0.0165,
      "step": 20570
    },
    {
      "epoch": 5.626025150355385,
      "grad_norm": 3.4367191791534424,
      "learning_rate": 1.4373974849644616e-05,
      "loss": 0.032,
      "step": 20580
    },
    {
      "epoch": 5.628758884636413,
      "grad_norm": 3.137356996536255,
      "learning_rate": 1.4371241115363588e-05,
      "loss": 0.0494,
      "step": 20590
    },
    {
      "epoch": 5.6314926189174415,
      "grad_norm": 0.0023588037583976984,
      "learning_rate": 1.436850738108256e-05,
      "loss": 0.0103,
      "step": 20600
    },
    {
      "epoch": 5.6342263531984695,
      "grad_norm": 0.06368844211101532,
      "learning_rate": 1.4365773646801533e-05,
      "loss": 0.0025,
      "step": 20610
    },
    {
      "epoch": 5.636960087479497,
      "grad_norm": 1.1639821529388428,
      "learning_rate": 1.4363039912520505e-05,
      "loss": 0.0278,
      "step": 20620
    },
    {
      "epoch": 5.639693821760525,
      "grad_norm": 0.008666293695569038,
      "learning_rate": 1.4360306178239476e-05,
      "loss": 0.0158,
      "step": 20630
    },
    {
      "epoch": 5.642427556041553,
      "grad_norm": 0.001538383192382753,
      "learning_rate": 1.4357572443958448e-05,
      "loss": 0.0251,
      "step": 20640
    },
    {
      "epoch": 5.645161290322581,
      "grad_norm": 0.0017325821099802852,
      "learning_rate": 1.4354838709677421e-05,
      "loss": 0.0149,
      "step": 20650
    },
    {
      "epoch": 5.647895024603608,
      "grad_norm": 1.3399319648742676,
      "learning_rate": 1.4352104975396393e-05,
      "loss": 0.0097,
      "step": 20660
    },
    {
      "epoch": 5.650628758884636,
      "grad_norm": 5.7303690910339355,
      "learning_rate": 1.4349371241115365e-05,
      "loss": 0.0691,
      "step": 20670
    },
    {
      "epoch": 5.653362493165664,
      "grad_norm": 0.006038379855453968,
      "learning_rate": 1.4346637506834338e-05,
      "loss": 0.0021,
      "step": 20680
    },
    {
      "epoch": 5.656096227446692,
      "grad_norm": 0.004607551731169224,
      "learning_rate": 1.434390377255331e-05,
      "loss": 0.0581,
      "step": 20690
    },
    {
      "epoch": 5.6588299617277205,
      "grad_norm": 0.01348275225609541,
      "learning_rate": 1.4341170038272281e-05,
      "loss": 0.027,
      "step": 20700
    },
    {
      "epoch": 5.661563696008748,
      "grad_norm": 0.003732329932972789,
      "learning_rate": 1.4338436303991253e-05,
      "loss": 0.0402,
      "step": 20710
    },
    {
      "epoch": 5.664297430289776,
      "grad_norm": 0.21100148558616638,
      "learning_rate": 1.4335702569710226e-05,
      "loss": 0.0379,
      "step": 20720
    },
    {
      "epoch": 5.667031164570804,
      "grad_norm": 2.005427598953247,
      "learning_rate": 1.4332968835429198e-05,
      "loss": 0.0262,
      "step": 20730
    },
    {
      "epoch": 5.669764898851832,
      "grad_norm": 0.010690836235880852,
      "learning_rate": 1.433023510114817e-05,
      "loss": 0.0021,
      "step": 20740
    },
    {
      "epoch": 5.672498633132859,
      "grad_norm": 0.011297072283923626,
      "learning_rate": 1.4327501366867143e-05,
      "loss": 0.0025,
      "step": 20750
    },
    {
      "epoch": 5.675232367413887,
      "grad_norm": 0.006991969421505928,
      "learning_rate": 1.4324767632586115e-05,
      "loss": 0.0274,
      "step": 20760
    },
    {
      "epoch": 5.677966101694915,
      "grad_norm": 0.007442294619977474,
      "learning_rate": 1.4322033898305086e-05,
      "loss": 0.0071,
      "step": 20770
    },
    {
      "epoch": 5.680699835975943,
      "grad_norm": 0.005833562929183245,
      "learning_rate": 1.4319300164024056e-05,
      "loss": 0.0047,
      "step": 20780
    },
    {
      "epoch": 5.683433570256971,
      "grad_norm": 0.13761571049690247,
      "learning_rate": 1.4316566429743031e-05,
      "loss": 0.0081,
      "step": 20790
    },
    {
      "epoch": 5.686167304537999,
      "grad_norm": 1.809975028038025,
      "learning_rate": 1.4313832695462003e-05,
      "loss": 0.0887,
      "step": 20800
    },
    {
      "epoch": 5.688901038819027,
      "grad_norm": 0.006472807377576828,
      "learning_rate": 1.4311098961180973e-05,
      "loss": 0.0079,
      "step": 20810
    },
    {
      "epoch": 5.691634773100055,
      "grad_norm": 0.013231060467660427,
      "learning_rate": 1.4308365226899948e-05,
      "loss": 0.0273,
      "step": 20820
    },
    {
      "epoch": 5.694368507381083,
      "grad_norm": 0.04769457131624222,
      "learning_rate": 1.430563149261892e-05,
      "loss": 0.0118,
      "step": 20830
    },
    {
      "epoch": 5.69710224166211,
      "grad_norm": 3.3429930210113525,
      "learning_rate": 1.430289775833789e-05,
      "loss": 0.0441,
      "step": 20840
    },
    {
      "epoch": 5.699835975943138,
      "grad_norm": 0.018276654183864594,
      "learning_rate": 1.4300164024056861e-05,
      "loss": 0.0185,
      "step": 20850
    },
    {
      "epoch": 5.702569710224166,
      "grad_norm": 0.011888244189321995,
      "learning_rate": 1.4297430289775836e-05,
      "loss": 0.0017,
      "step": 20860
    },
    {
      "epoch": 5.705303444505194,
      "grad_norm": 0.009986341930925846,
      "learning_rate": 1.4294696555494806e-05,
      "loss": 0.0162,
      "step": 20870
    },
    {
      "epoch": 5.708037178786222,
      "grad_norm": 0.008957325480878353,
      "learning_rate": 1.4291962821213778e-05,
      "loss": 0.0006,
      "step": 20880
    },
    {
      "epoch": 5.7107709130672495,
      "grad_norm": 0.007229730952531099,
      "learning_rate": 1.4289229086932753e-05,
      "loss": 0.0059,
      "step": 20890
    },
    {
      "epoch": 5.713504647348278,
      "grad_norm": 0.007713528349995613,
      "learning_rate": 1.4286495352651723e-05,
      "loss": 0.025,
      "step": 20900
    },
    {
      "epoch": 5.716238381629306,
      "grad_norm": 0.013052791357040405,
      "learning_rate": 1.4283761618370694e-05,
      "loss": 0.0013,
      "step": 20910
    },
    {
      "epoch": 5.718972115910334,
      "grad_norm": 0.009293721988797188,
      "learning_rate": 1.4281027884089666e-05,
      "loss": 0.0003,
      "step": 20920
    },
    {
      "epoch": 5.721705850191361,
      "grad_norm": 0.008554725907742977,
      "learning_rate": 1.427829414980864e-05,
      "loss": 0.0293,
      "step": 20930
    },
    {
      "epoch": 5.724439584472389,
      "grad_norm": 0.006137159187346697,
      "learning_rate": 1.4275560415527611e-05,
      "loss": 0.038,
      "step": 20940
    },
    {
      "epoch": 5.727173318753417,
      "grad_norm": 0.019100725650787354,
      "learning_rate": 1.4272826681246583e-05,
      "loss": 0.004,
      "step": 20950
    },
    {
      "epoch": 5.729907053034445,
      "grad_norm": 11.41999340057373,
      "learning_rate": 1.4270092946965556e-05,
      "loss": 0.0227,
      "step": 20960
    },
    {
      "epoch": 5.732640787315473,
      "grad_norm": 0.013035103678703308,
      "learning_rate": 1.4267359212684528e-05,
      "loss": 0.0002,
      "step": 20970
    },
    {
      "epoch": 5.735374521596501,
      "grad_norm": 2.311248540878296,
      "learning_rate": 1.42646254784035e-05,
      "loss": 0.0287,
      "step": 20980
    },
    {
      "epoch": 5.7381082558775285,
      "grad_norm": 0.006779714487493038,
      "learning_rate": 1.4261891744122473e-05,
      "loss": 0.0335,
      "step": 20990
    },
    {
      "epoch": 5.740841990158557,
      "grad_norm": 0.016092078760266304,
      "learning_rate": 1.4259158009841444e-05,
      "loss": 0.001,
      "step": 21000
    },
    {
      "epoch": 5.743575724439585,
      "grad_norm": 0.02242976799607277,
      "learning_rate": 1.4256424275560416e-05,
      "loss": 0.0013,
      "step": 21010
    },
    {
      "epoch": 5.746309458720613,
      "grad_norm": 5.216825485229492,
      "learning_rate": 1.4253690541279388e-05,
      "loss": 0.0236,
      "step": 21020
    },
    {
      "epoch": 5.74904319300164,
      "grad_norm": 0.017433322966098785,
      "learning_rate": 1.4250956806998361e-05,
      "loss": 0.0131,
      "step": 21030
    },
    {
      "epoch": 5.751776927282668,
      "grad_norm": 0.007058167830109596,
      "learning_rate": 1.4248223072717333e-05,
      "loss": 0.0359,
      "step": 21040
    },
    {
      "epoch": 5.754510661563696,
      "grad_norm": 0.016267932951450348,
      "learning_rate": 1.4245489338436304e-05,
      "loss": 0.0019,
      "step": 21050
    },
    {
      "epoch": 5.757244395844724,
      "grad_norm": 0.02524380199611187,
      "learning_rate": 1.4242755604155278e-05,
      "loss": 0.03,
      "step": 21060
    },
    {
      "epoch": 5.759978130125752,
      "grad_norm": 0.015456506982445717,
      "learning_rate": 1.424002186987425e-05,
      "loss": 0.0071,
      "step": 21070
    },
    {
      "epoch": 5.762711864406779,
      "grad_norm": 0.019349344074726105,
      "learning_rate": 1.4237288135593221e-05,
      "loss": 0.0014,
      "step": 21080
    },
    {
      "epoch": 5.7654455986878075,
      "grad_norm": 0.0117753641679883,
      "learning_rate": 1.4234554401312193e-05,
      "loss": 0.0087,
      "step": 21090
    },
    {
      "epoch": 5.768179332968836,
      "grad_norm": 10.731654167175293,
      "learning_rate": 1.4231820667031166e-05,
      "loss": 0.0502,
      "step": 21100
    },
    {
      "epoch": 5.770913067249864,
      "grad_norm": 0.012013786472380161,
      "learning_rate": 1.4229086932750138e-05,
      "loss": 0.0172,
      "step": 21110
    },
    {
      "epoch": 5.773646801530891,
      "grad_norm": 0.2090187668800354,
      "learning_rate": 1.422635319846911e-05,
      "loss": 0.0098,
      "step": 21120
    },
    {
      "epoch": 5.776380535811919,
      "grad_norm": 2.8532681465148926,
      "learning_rate": 1.4223619464188083e-05,
      "loss": 0.004,
      "step": 21130
    },
    {
      "epoch": 5.779114270092947,
      "grad_norm": 0.002804530318826437,
      "learning_rate": 1.4220885729907054e-05,
      "loss": 0.0139,
      "step": 21140
    },
    {
      "epoch": 5.781848004373975,
      "grad_norm": 0.03838923200964928,
      "learning_rate": 1.4218151995626026e-05,
      "loss": 0.0203,
      "step": 21150
    },
    {
      "epoch": 5.784581738655003,
      "grad_norm": 0.003508754074573517,
      "learning_rate": 1.4215418261344998e-05,
      "loss": 0.0031,
      "step": 21160
    },
    {
      "epoch": 5.78731547293603,
      "grad_norm": 3.001047372817993,
      "learning_rate": 1.4212684527063971e-05,
      "loss": 0.0707,
      "step": 21170
    },
    {
      "epoch": 5.790049207217058,
      "grad_norm": 2.49495267868042,
      "learning_rate": 1.4209950792782943e-05,
      "loss": 0.0152,
      "step": 21180
    },
    {
      "epoch": 5.7927829414980865,
      "grad_norm": 0.023633038625121117,
      "learning_rate": 1.4207217058501914e-05,
      "loss": 0.0249,
      "step": 21190
    },
    {
      "epoch": 5.795516675779115,
      "grad_norm": 0.16149622201919556,
      "learning_rate": 1.4204483324220888e-05,
      "loss": 0.0039,
      "step": 21200
    },
    {
      "epoch": 5.798250410060142,
      "grad_norm": 0.007943278178572655,
      "learning_rate": 1.420174958993986e-05,
      "loss": 0.0099,
      "step": 21210
    },
    {
      "epoch": 5.80098414434117,
      "grad_norm": 32.383060455322266,
      "learning_rate": 1.4199015855658831e-05,
      "loss": 0.0751,
      "step": 21220
    },
    {
      "epoch": 5.803717878622198,
      "grad_norm": 0.12324109673500061,
      "learning_rate": 1.4196282121377803e-05,
      "loss": 0.005,
      "step": 21230
    },
    {
      "epoch": 5.806451612903226,
      "grad_norm": 0.004695761017501354,
      "learning_rate": 1.4193548387096776e-05,
      "loss": 0.002,
      "step": 21240
    },
    {
      "epoch": 5.809185347184254,
      "grad_norm": 0.020337291061878204,
      "learning_rate": 1.4190814652815748e-05,
      "loss": 0.0325,
      "step": 21250
    },
    {
      "epoch": 5.811919081465281,
      "grad_norm": 0.008250865153968334,
      "learning_rate": 1.418808091853472e-05,
      "loss": 0.0411,
      "step": 21260
    },
    {
      "epoch": 5.814652815746309,
      "grad_norm": 0.02032480016350746,
      "learning_rate": 1.4185347184253693e-05,
      "loss": 0.0278,
      "step": 21270
    },
    {
      "epoch": 5.817386550027337,
      "grad_norm": 0.010505815036594868,
      "learning_rate": 1.4182613449972664e-05,
      "loss": 0.0229,
      "step": 21280
    },
    {
      "epoch": 5.8201202843083655,
      "grad_norm": 0.015670159831643105,
      "learning_rate": 1.4179879715691636e-05,
      "loss": 0.0174,
      "step": 21290
    },
    {
      "epoch": 5.822854018589393,
      "grad_norm": 0.007891147397458553,
      "learning_rate": 1.4177145981410608e-05,
      "loss": 0.0435,
      "step": 21300
    },
    {
      "epoch": 5.825587752870421,
      "grad_norm": 0.14090214669704437,
      "learning_rate": 1.4174412247129581e-05,
      "loss": 0.0141,
      "step": 21310
    },
    {
      "epoch": 5.828321487151449,
      "grad_norm": 0.020741136744618416,
      "learning_rate": 1.4171678512848553e-05,
      "loss": 0.0027,
      "step": 21320
    },
    {
      "epoch": 5.831055221432477,
      "grad_norm": 0.003928720951080322,
      "learning_rate": 1.4168944778567524e-05,
      "loss": 0.0132,
      "step": 21330
    },
    {
      "epoch": 5.833788955713505,
      "grad_norm": 0.04047191143035889,
      "learning_rate": 1.4166211044286498e-05,
      "loss": 0.0138,
      "step": 21340
    },
    {
      "epoch": 5.836522689994532,
      "grad_norm": 0.004202454350888729,
      "learning_rate": 1.416347731000547e-05,
      "loss": 0.0304,
      "step": 21350
    },
    {
      "epoch": 5.83925642427556,
      "grad_norm": 1.3822482824325562,
      "learning_rate": 1.4160743575724441e-05,
      "loss": 0.01,
      "step": 21360
    },
    {
      "epoch": 5.841990158556588,
      "grad_norm": 0.0014850030420348048,
      "learning_rate": 1.4158009841443413e-05,
      "loss": 0.0172,
      "step": 21370
    },
    {
      "epoch": 5.844723892837616,
      "grad_norm": 0.0030961206648498774,
      "learning_rate": 1.4155276107162386e-05,
      "loss": 0.0005,
      "step": 21380
    },
    {
      "epoch": 5.847457627118644,
      "grad_norm": 0.0045524477027356625,
      "learning_rate": 1.4152542372881358e-05,
      "loss": 0.0367,
      "step": 21390
    },
    {
      "epoch": 5.850191361399672,
      "grad_norm": 0.4370051324367523,
      "learning_rate": 1.414980863860033e-05,
      "loss": 0.0403,
      "step": 21400
    },
    {
      "epoch": 5.8529250956807,
      "grad_norm": 0.005086549557745457,
      "learning_rate": 1.4147074904319303e-05,
      "loss": 0.0047,
      "step": 21410
    },
    {
      "epoch": 5.855658829961728,
      "grad_norm": 0.07708985358476639,
      "learning_rate": 1.4144341170038274e-05,
      "loss": 0.0166,
      "step": 21420
    },
    {
      "epoch": 5.858392564242756,
      "grad_norm": 0.29010552167892456,
      "learning_rate": 1.4141607435757246e-05,
      "loss": 0.0017,
      "step": 21430
    },
    {
      "epoch": 5.861126298523784,
      "grad_norm": 0.006093696691095829,
      "learning_rate": 1.4138873701476216e-05,
      "loss": 0.007,
      "step": 21440
    },
    {
      "epoch": 5.863860032804811,
      "grad_norm": 0.32780760526657104,
      "learning_rate": 1.4136139967195191e-05,
      "loss": 0.0421,
      "step": 21450
    },
    {
      "epoch": 5.866593767085839,
      "grad_norm": 4.959964275360107,
      "learning_rate": 1.4133406232914163e-05,
      "loss": 0.0204,
      "step": 21460
    },
    {
      "epoch": 5.869327501366867,
      "grad_norm": 4.852173805236816,
      "learning_rate": 1.4130672498633133e-05,
      "loss": 0.0162,
      "step": 21470
    },
    {
      "epoch": 5.872061235647895,
      "grad_norm": 0.0015038703568279743,
      "learning_rate": 1.4127938764352108e-05,
      "loss": 0.0043,
      "step": 21480
    },
    {
      "epoch": 5.874794969928923,
      "grad_norm": 0.03575146570801735,
      "learning_rate": 1.412520503007108e-05,
      "loss": 0.0141,
      "step": 21490
    },
    {
      "epoch": 5.877528704209951,
      "grad_norm": 0.010568262077867985,
      "learning_rate": 1.412247129579005e-05,
      "loss": 0.0321,
      "step": 21500
    },
    {
      "epoch": 5.880262438490979,
      "grad_norm": 0.017765002325177193,
      "learning_rate": 1.4119737561509021e-05,
      "loss": 0.026,
      "step": 21510
    },
    {
      "epoch": 5.882996172772007,
      "grad_norm": 0.005196264013648033,
      "learning_rate": 1.4117003827227996e-05,
      "loss": 0.0068,
      "step": 21520
    },
    {
      "epoch": 5.885729907053035,
      "grad_norm": 0.010021421127021313,
      "learning_rate": 1.4114270092946966e-05,
      "loss": 0.0121,
      "step": 21530
    },
    {
      "epoch": 5.888463641334062,
      "grad_norm": 0.380362331867218,
      "learning_rate": 1.4111536358665938e-05,
      "loss": 0.0063,
      "step": 21540
    },
    {
      "epoch": 5.89119737561509,
      "grad_norm": 0.7845824956893921,
      "learning_rate": 1.4108802624384913e-05,
      "loss": 0.0121,
      "step": 21550
    },
    {
      "epoch": 5.893931109896118,
      "grad_norm": 0.006843191105872393,
      "learning_rate": 1.4106068890103883e-05,
      "loss": 0.014,
      "step": 21560
    },
    {
      "epoch": 5.896664844177146,
      "grad_norm": 0.004391036927700043,
      "learning_rate": 1.4103335155822854e-05,
      "loss": 0.0271,
      "step": 21570
    },
    {
      "epoch": 5.8993985784581735,
      "grad_norm": 0.0010202339617535472,
      "learning_rate": 1.4100601421541826e-05,
      "loss": 0.0104,
      "step": 21580
    },
    {
      "epoch": 5.902132312739202,
      "grad_norm": 0.0036653089337050915,
      "learning_rate": 1.40978676872608e-05,
      "loss": 0.0708,
      "step": 21590
    },
    {
      "epoch": 5.90486604702023,
      "grad_norm": 0.007546849548816681,
      "learning_rate": 1.4095133952979771e-05,
      "loss": 0.0118,
      "step": 21600
    },
    {
      "epoch": 5.907599781301258,
      "grad_norm": 0.2673778533935547,
      "learning_rate": 1.4092400218698743e-05,
      "loss": 0.0499,
      "step": 21610
    },
    {
      "epoch": 5.910333515582286,
      "grad_norm": 0.006033007986843586,
      "learning_rate": 1.4089666484417716e-05,
      "loss": 0.0478,
      "step": 21620
    },
    {
      "epoch": 5.913067249863313,
      "grad_norm": 3.822577953338623,
      "learning_rate": 1.4086932750136688e-05,
      "loss": 0.0244,
      "step": 21630
    },
    {
      "epoch": 5.915800984144341,
      "grad_norm": 0.0018546690698713064,
      "learning_rate": 1.408419901585566e-05,
      "loss": 0.0075,
      "step": 21640
    },
    {
      "epoch": 5.918534718425369,
      "grad_norm": 0.007110524922609329,
      "learning_rate": 1.4081465281574631e-05,
      "loss": 0.0458,
      "step": 21650
    },
    {
      "epoch": 5.921268452706397,
      "grad_norm": 1.3359596729278564,
      "learning_rate": 1.4078731547293604e-05,
      "loss": 0.0441,
      "step": 21660
    },
    {
      "epoch": 5.924002186987424,
      "grad_norm": 3.3628907203674316,
      "learning_rate": 1.4075997813012576e-05,
      "loss": 0.0097,
      "step": 21670
    },
    {
      "epoch": 5.9267359212684525,
      "grad_norm": 0.005002527963370085,
      "learning_rate": 1.4073264078731548e-05,
      "loss": 0.0261,
      "step": 21680
    },
    {
      "epoch": 5.929469655549481,
      "grad_norm": 1.3103514909744263,
      "learning_rate": 1.4070530344450521e-05,
      "loss": 0.0322,
      "step": 21690
    },
    {
      "epoch": 5.932203389830509,
      "grad_norm": 0.12843815982341766,
      "learning_rate": 1.4067796610169493e-05,
      "loss": 0.0009,
      "step": 21700
    },
    {
      "epoch": 5.934937124111537,
      "grad_norm": 0.14691714942455292,
      "learning_rate": 1.4065062875888464e-05,
      "loss": 0.0135,
      "step": 21710
    },
    {
      "epoch": 5.937670858392564,
      "grad_norm": 0.044970735907554626,
      "learning_rate": 1.4062329141607436e-05,
      "loss": 0.0169,
      "step": 21720
    },
    {
      "epoch": 5.940404592673592,
      "grad_norm": 1.267411708831787,
      "learning_rate": 1.405959540732641e-05,
      "loss": 0.044,
      "step": 21730
    },
    {
      "epoch": 5.94313832695462,
      "grad_norm": 0.5576584339141846,
      "learning_rate": 1.4056861673045381e-05,
      "loss": 0.02,
      "step": 21740
    },
    {
      "epoch": 5.945872061235648,
      "grad_norm": 0.004076663870364428,
      "learning_rate": 1.4054127938764353e-05,
      "loss": 0.0127,
      "step": 21750
    },
    {
      "epoch": 5.948605795516675,
      "grad_norm": 0.002950628288090229,
      "learning_rate": 1.4051394204483326e-05,
      "loss": 0.0433,
      "step": 21760
    },
    {
      "epoch": 5.951339529797703,
      "grad_norm": 0.15635570883750916,
      "learning_rate": 1.4048660470202298e-05,
      "loss": 0.0156,
      "step": 21770
    },
    {
      "epoch": 5.9540732640787315,
      "grad_norm": 0.012952628545463085,
      "learning_rate": 1.404592673592127e-05,
      "loss": 0.0021,
      "step": 21780
    },
    {
      "epoch": 5.95680699835976,
      "grad_norm": 34.61347961425781,
      "learning_rate": 1.4043193001640241e-05,
      "loss": 0.1416,
      "step": 21790
    },
    {
      "epoch": 5.959540732640788,
      "grad_norm": 0.013571199961006641,
      "learning_rate": 1.4040459267359214e-05,
      "loss": 0.0257,
      "step": 21800
    },
    {
      "epoch": 5.962274466921815,
      "grad_norm": 10.321309089660645,
      "learning_rate": 1.4037725533078186e-05,
      "loss": 0.0161,
      "step": 21810
    },
    {
      "epoch": 5.965008201202843,
      "grad_norm": 0.045126013457775116,
      "learning_rate": 1.4034991798797158e-05,
      "loss": 0.0015,
      "step": 21820
    },
    {
      "epoch": 5.967741935483871,
      "grad_norm": 0.14151659607887268,
      "learning_rate": 1.4032258064516131e-05,
      "loss": 0.0046,
      "step": 21830
    },
    {
      "epoch": 5.970475669764899,
      "grad_norm": 2.9327008724212646,
      "learning_rate": 1.4029524330235103e-05,
      "loss": 0.0436,
      "step": 21840
    },
    {
      "epoch": 5.973209404045926,
      "grad_norm": 0.03869429975748062,
      "learning_rate": 1.4026790595954074e-05,
      "loss": 0.0136,
      "step": 21850
    },
    {
      "epoch": 5.975943138326954,
      "grad_norm": 0.9884206056594849,
      "learning_rate": 1.4024056861673046e-05,
      "loss": 0.0206,
      "step": 21860
    },
    {
      "epoch": 5.978676872607982,
      "grad_norm": 7.775888919830322,
      "learning_rate": 1.402132312739202e-05,
      "loss": 0.0559,
      "step": 21870
    },
    {
      "epoch": 5.9814106068890105,
      "grad_norm": 0.03911903128027916,
      "learning_rate": 1.401858939311099e-05,
      "loss": 0.0156,
      "step": 21880
    },
    {
      "epoch": 5.984144341170039,
      "grad_norm": 0.04703537002205849,
      "learning_rate": 1.4015855658829962e-05,
      "loss": 0.0244,
      "step": 21890
    },
    {
      "epoch": 5.986878075451067,
      "grad_norm": 0.01585671678185463,
      "learning_rate": 1.4013121924548936e-05,
      "loss": 0.025,
      "step": 21900
    },
    {
      "epoch": 5.989611809732094,
      "grad_norm": 0.03914613276720047,
      "learning_rate": 1.4010388190267907e-05,
      "loss": 0.0121,
      "step": 21910
    },
    {
      "epoch": 5.992345544013122,
      "grad_norm": 0.1729901283979416,
      "learning_rate": 1.400765445598688e-05,
      "loss": 0.0553,
      "step": 21920
    },
    {
      "epoch": 5.99507927829415,
      "grad_norm": 0.050120286643505096,
      "learning_rate": 1.400492072170585e-05,
      "loss": 0.0119,
      "step": 21930
    },
    {
      "epoch": 5.997813012575178,
      "grad_norm": 0.005628723651170731,
      "learning_rate": 1.4002186987424824e-05,
      "loss": 0.0272,
      "step": 21940
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9904214559386973,
      "eval_f1": 0.9613235926085087,
      "eval_loss": 0.040246374905109406,
      "eval_precision": 0.9679792297706621,
      "eval_recall": 0.9547588561673068,
      "eval_runtime": 797.5257,
      "eval_samples_per_second": 23.59,
      "eval_steps_per_second": 0.983,
      "step": 21948
    },
    {
      "epoch": 6.000546746856205,
      "grad_norm": 3.1001009941101074,
      "learning_rate": 1.3999453253143796e-05,
      "loss": 0.0457,
      "step": 21950
    },
    {
      "epoch": 6.003280481137233,
      "grad_norm": 0.012080547399818897,
      "learning_rate": 1.3996719518862767e-05,
      "loss": 0.0402,
      "step": 21960
    },
    {
      "epoch": 6.006014215418261,
      "grad_norm": 0.048691295087337494,
      "learning_rate": 1.399398578458174e-05,
      "loss": 0.0261,
      "step": 21970
    },
    {
      "epoch": 6.0087479496992895,
      "grad_norm": 2.693821430206299,
      "learning_rate": 1.3991252050300712e-05,
      "loss": 0.0078,
      "step": 21980
    },
    {
      "epoch": 6.011481683980317,
      "grad_norm": 0.2264513373374939,
      "learning_rate": 1.3988518316019684e-05,
      "loss": 0.0028,
      "step": 21990
    },
    {
      "epoch": 6.014215418261345,
      "grad_norm": 0.00659182108938694,
      "learning_rate": 1.3985784581738656e-05,
      "loss": 0.0261,
      "step": 22000
    },
    {
      "epoch": 6.016949152542373,
      "grad_norm": 0.0055953701958060265,
      "learning_rate": 1.3983050847457629e-05,
      "loss": 0.0121,
      "step": 22010
    },
    {
      "epoch": 6.019682886823401,
      "grad_norm": 0.006413761992007494,
      "learning_rate": 1.39803171131766e-05,
      "loss": 0.0133,
      "step": 22020
    },
    {
      "epoch": 6.022416621104429,
      "grad_norm": 0.5062879323959351,
      "learning_rate": 1.3977583378895572e-05,
      "loss": 0.0003,
      "step": 22030
    },
    {
      "epoch": 6.025150355385456,
      "grad_norm": 0.0053362189792096615,
      "learning_rate": 1.3974849644614546e-05,
      "loss": 0.0275,
      "step": 22040
    },
    {
      "epoch": 6.027884089666484,
      "grad_norm": 0.006861112546175718,
      "learning_rate": 1.3972115910333517e-05,
      "loss": 0.0348,
      "step": 22050
    },
    {
      "epoch": 6.030617823947512,
      "grad_norm": 0.30539363622665405,
      "learning_rate": 1.3969382176052489e-05,
      "loss": 0.0397,
      "step": 22060
    },
    {
      "epoch": 6.03335155822854,
      "grad_norm": 148.3621063232422,
      "learning_rate": 1.3966648441771462e-05,
      "loss": 0.0643,
      "step": 22070
    },
    {
      "epoch": 6.0360852925095685,
      "grad_norm": 0.36789631843566895,
      "learning_rate": 1.3963914707490434e-05,
      "loss": 0.0018,
      "step": 22080
    },
    {
      "epoch": 6.038819026790596,
      "grad_norm": 0.13882659375667572,
      "learning_rate": 1.3961180973209406e-05,
      "loss": 0.0253,
      "step": 22090
    },
    {
      "epoch": 6.041552761071624,
      "grad_norm": 0.04939889535307884,
      "learning_rate": 1.3958447238928376e-05,
      "loss": 0.0172,
      "step": 22100
    },
    {
      "epoch": 6.044286495352652,
      "grad_norm": 0.09277458488941193,
      "learning_rate": 1.395571350464735e-05,
      "loss": 0.0384,
      "step": 22110
    },
    {
      "epoch": 6.04702022963368,
      "grad_norm": 1.4283543825149536,
      "learning_rate": 1.3952979770366322e-05,
      "loss": 0.0232,
      "step": 22120
    },
    {
      "epoch": 6.049753963914707,
      "grad_norm": 0.01144631952047348,
      "learning_rate": 1.3950246036085292e-05,
      "loss": 0.0005,
      "step": 22130
    },
    {
      "epoch": 6.052487698195735,
      "grad_norm": 3.2164347171783447,
      "learning_rate": 1.3947512301804267e-05,
      "loss": 0.0062,
      "step": 22140
    },
    {
      "epoch": 6.055221432476763,
      "grad_norm": 1.5990270376205444,
      "learning_rate": 1.3944778567523239e-05,
      "loss": 0.0299,
      "step": 22150
    },
    {
      "epoch": 6.057955166757791,
      "grad_norm": 0.0036830517929047346,
      "learning_rate": 1.3942044833242209e-05,
      "loss": 0.0077,
      "step": 22160
    },
    {
      "epoch": 6.060688901038819,
      "grad_norm": 0.014663812704384327,
      "learning_rate": 1.393931109896118e-05,
      "loss": 0.0125,
      "step": 22170
    },
    {
      "epoch": 6.063422635319847,
      "grad_norm": 0.07665109634399414,
      "learning_rate": 1.3936577364680156e-05,
      "loss": 0.0133,
      "step": 22180
    },
    {
      "epoch": 6.066156369600875,
      "grad_norm": 0.007935632951557636,
      "learning_rate": 1.3933843630399126e-05,
      "loss": 0.0178,
      "step": 22190
    },
    {
      "epoch": 6.068890103881903,
      "grad_norm": 0.0028451234102249146,
      "learning_rate": 1.3931109896118097e-05,
      "loss": 0.0022,
      "step": 22200
    },
    {
      "epoch": 6.071623838162931,
      "grad_norm": 0.0061097596772015095,
      "learning_rate": 1.3928376161837072e-05,
      "loss": 0.0033,
      "step": 22210
    },
    {
      "epoch": 6.074357572443958,
      "grad_norm": 0.0025919140316545963,
      "learning_rate": 1.3925642427556042e-05,
      "loss": 0.0133,
      "step": 22220
    },
    {
      "epoch": 6.077091306724986,
      "grad_norm": 0.00214835605584085,
      "learning_rate": 1.3922908693275014e-05,
      "loss": 0.0002,
      "step": 22230
    },
    {
      "epoch": 6.079825041006014,
      "grad_norm": 7.565682888031006,
      "learning_rate": 1.3920174958993986e-05,
      "loss": 0.0394,
      "step": 22240
    },
    {
      "epoch": 6.082558775287042,
      "grad_norm": 0.0018298093928024173,
      "learning_rate": 1.3917441224712959e-05,
      "loss": 0.0072,
      "step": 22250
    },
    {
      "epoch": 6.08529250956807,
      "grad_norm": 0.0020910983439534903,
      "learning_rate": 1.391470749043193e-05,
      "loss": 0.0096,
      "step": 22260
    },
    {
      "epoch": 6.0880262438490975,
      "grad_norm": 0.0017981581622734666,
      "learning_rate": 1.3911973756150902e-05,
      "loss": 0.0013,
      "step": 22270
    },
    {
      "epoch": 6.090759978130126,
      "grad_norm": 0.0015655485913157463,
      "learning_rate": 1.3909240021869876e-05,
      "loss": 0.0001,
      "step": 22280
    },
    {
      "epoch": 6.093493712411154,
      "grad_norm": 0.005243080668151379,
      "learning_rate": 1.3906506287588847e-05,
      "loss": 0.0223,
      "step": 22290
    },
    {
      "epoch": 6.096227446692182,
      "grad_norm": 1.330356240272522,
      "learning_rate": 1.3903772553307819e-05,
      "loss": 0.0488,
      "step": 22300
    },
    {
      "epoch": 6.09896118097321,
      "grad_norm": 17.63664436340332,
      "learning_rate": 1.390103881902679e-05,
      "loss": 0.0616,
      "step": 22310
    },
    {
      "epoch": 6.101694915254237,
      "grad_norm": 0.005880427081137896,
      "learning_rate": 1.3898305084745764e-05,
      "loss": 0.0049,
      "step": 22320
    },
    {
      "epoch": 6.104428649535265,
      "grad_norm": 0.2190900593996048,
      "learning_rate": 1.3895571350464736e-05,
      "loss": 0.0065,
      "step": 22330
    },
    {
      "epoch": 6.107162383816293,
      "grad_norm": 4.590662956237793,
      "learning_rate": 1.3892837616183707e-05,
      "loss": 0.0284,
      "step": 22340
    },
    {
      "epoch": 6.109896118097321,
      "grad_norm": 0.049445562064647675,
      "learning_rate": 1.389010388190268e-05,
      "loss": 0.014,
      "step": 22350
    },
    {
      "epoch": 6.112629852378348,
      "grad_norm": 27.171077728271484,
      "learning_rate": 1.3887370147621652e-05,
      "loss": 0.0612,
      "step": 22360
    },
    {
      "epoch": 6.1153635866593765,
      "grad_norm": 0.0022463668137788773,
      "learning_rate": 1.3884636413340624e-05,
      "loss": 0.022,
      "step": 22370
    },
    {
      "epoch": 6.118097320940405,
      "grad_norm": 0.2086552232503891,
      "learning_rate": 1.3881902679059596e-05,
      "loss": 0.0019,
      "step": 22380
    },
    {
      "epoch": 6.120831055221433,
      "grad_norm": 0.1900264322757721,
      "learning_rate": 1.3879168944778569e-05,
      "loss": 0.0425,
      "step": 22390
    },
    {
      "epoch": 6.123564789502461,
      "grad_norm": 0.0889376550912857,
      "learning_rate": 1.387643521049754e-05,
      "loss": 0.0027,
      "step": 22400
    },
    {
      "epoch": 6.126298523783488,
      "grad_norm": 0.006745610386133194,
      "learning_rate": 1.3873701476216512e-05,
      "loss": 0.0006,
      "step": 22410
    },
    {
      "epoch": 6.129032258064516,
      "grad_norm": 7.329746246337891,
      "learning_rate": 1.3870967741935486e-05,
      "loss": 0.034,
      "step": 22420
    },
    {
      "epoch": 6.131765992345544,
      "grad_norm": 0.009693008847534657,
      "learning_rate": 1.3868234007654457e-05,
      "loss": 0.0256,
      "step": 22430
    },
    {
      "epoch": 6.134499726626572,
      "grad_norm": 1.7603191137313843,
      "learning_rate": 1.3865500273373429e-05,
      "loss": 0.0026,
      "step": 22440
    },
    {
      "epoch": 6.137233460907599,
      "grad_norm": 0.003911966923624277,
      "learning_rate": 1.38627665390924e-05,
      "loss": 0.0255,
      "step": 22450
    },
    {
      "epoch": 6.139967195188627,
      "grad_norm": 2.8970446586608887,
      "learning_rate": 1.3860032804811374e-05,
      "loss": 0.0293,
      "step": 22460
    },
    {
      "epoch": 6.1427009294696555,
      "grad_norm": 9.993213653564453,
      "learning_rate": 1.3857299070530346e-05,
      "loss": 0.0098,
      "step": 22470
    },
    {
      "epoch": 6.145434663750684,
      "grad_norm": 0.007926889695227146,
      "learning_rate": 1.3854565336249317e-05,
      "loss": 0.001,
      "step": 22480
    },
    {
      "epoch": 6.148168398031712,
      "grad_norm": 2.658815383911133,
      "learning_rate": 1.385183160196829e-05,
      "loss": 0.0475,
      "step": 22490
    },
    {
      "epoch": 6.150902132312739,
      "grad_norm": 1.4701440334320068,
      "learning_rate": 1.3849097867687262e-05,
      "loss": 0.0012,
      "step": 22500
    },
    {
      "epoch": 6.153635866593767,
      "grad_norm": 0.02037789300084114,
      "learning_rate": 1.3846364133406234e-05,
      "loss": 0.0282,
      "step": 22510
    },
    {
      "epoch": 6.156369600874795,
      "grad_norm": 0.001989874755963683,
      "learning_rate": 1.3843630399125206e-05,
      "loss": 0.0178,
      "step": 22520
    },
    {
      "epoch": 6.159103335155823,
      "grad_norm": 0.021681511774659157,
      "learning_rate": 1.3840896664844179e-05,
      "loss": 0.0133,
      "step": 22530
    },
    {
      "epoch": 6.161837069436851,
      "grad_norm": 1.0923858880996704,
      "learning_rate": 1.383816293056315e-05,
      "loss": 0.003,
      "step": 22540
    },
    {
      "epoch": 6.164570803717878,
      "grad_norm": 0.1050468310713768,
      "learning_rate": 1.3835429196282122e-05,
      "loss": 0.0005,
      "step": 22550
    },
    {
      "epoch": 6.167304537998906,
      "grad_norm": 0.0069580418057739735,
      "learning_rate": 1.3832695462001096e-05,
      "loss": 0.0022,
      "step": 22560
    },
    {
      "epoch": 6.1700382722799345,
      "grad_norm": 0.0043387943878769875,
      "learning_rate": 1.3829961727720067e-05,
      "loss": 0.0319,
      "step": 22570
    },
    {
      "epoch": 6.172772006560963,
      "grad_norm": 0.016753537580370903,
      "learning_rate": 1.3827227993439039e-05,
      "loss": 0.0311,
      "step": 22580
    },
    {
      "epoch": 6.17550574084199,
      "grad_norm": 0.11018519848585129,
      "learning_rate": 1.382449425915801e-05,
      "loss": 0.0066,
      "step": 22590
    },
    {
      "epoch": 6.178239475123018,
      "grad_norm": 0.002559644402936101,
      "learning_rate": 1.3821760524876984e-05,
      "loss": 0.059,
      "step": 22600
    },
    {
      "epoch": 6.180973209404046,
      "grad_norm": 0.004699683748185635,
      "learning_rate": 1.3819026790595956e-05,
      "loss": 0.0009,
      "step": 22610
    },
    {
      "epoch": 6.183706943685074,
      "grad_norm": 2.597602605819702,
      "learning_rate": 1.3816293056314927e-05,
      "loss": 0.0261,
      "step": 22620
    },
    {
      "epoch": 6.186440677966102,
      "grad_norm": 0.0028351033106446266,
      "learning_rate": 1.38135593220339e-05,
      "loss": 0.0059,
      "step": 22630
    },
    {
      "epoch": 6.189174412247129,
      "grad_norm": 1.7477136850357056,
      "learning_rate": 1.3810825587752872e-05,
      "loss": 0.0023,
      "step": 22640
    },
    {
      "epoch": 6.191908146528157,
      "grad_norm": 0.07562161982059479,
      "learning_rate": 1.3808091853471844e-05,
      "loss": 0.0029,
      "step": 22650
    },
    {
      "epoch": 6.194641880809185,
      "grad_norm": 7.502881050109863,
      "learning_rate": 1.3805358119190816e-05,
      "loss": 0.0221,
      "step": 22660
    },
    {
      "epoch": 6.1973756150902135,
      "grad_norm": 16.4939022064209,
      "learning_rate": 1.3802624384909789e-05,
      "loss": 0.0575,
      "step": 22670
    },
    {
      "epoch": 6.200109349371241,
      "grad_norm": 0.005074821878224611,
      "learning_rate": 1.379989065062876e-05,
      "loss": 0.013,
      "step": 22680
    },
    {
      "epoch": 6.202843083652269,
      "grad_norm": 0.036412835121154785,
      "learning_rate": 1.3797156916347732e-05,
      "loss": 0.0253,
      "step": 22690
    },
    {
      "epoch": 6.205576817933297,
      "grad_norm": 0.0021546136122196913,
      "learning_rate": 1.3794423182066706e-05,
      "loss": 0.0061,
      "step": 22700
    },
    {
      "epoch": 6.208310552214325,
      "grad_norm": 0.913703203201294,
      "learning_rate": 1.3791689447785677e-05,
      "loss": 0.0329,
      "step": 22710
    },
    {
      "epoch": 6.211044286495353,
      "grad_norm": 0.12664823234081268,
      "learning_rate": 1.3788955713504649e-05,
      "loss": 0.012,
      "step": 22720
    },
    {
      "epoch": 6.21377802077638,
      "grad_norm": 0.01244591735303402,
      "learning_rate": 1.3786221979223619e-05,
      "loss": 0.0047,
      "step": 22730
    },
    {
      "epoch": 6.216511755057408,
      "grad_norm": 4.064479827880859,
      "learning_rate": 1.3783488244942594e-05,
      "loss": 0.014,
      "step": 22740
    },
    {
      "epoch": 6.219245489338436,
      "grad_norm": 0.0029241016600281,
      "learning_rate": 1.3780754510661566e-05,
      "loss": 0.0036,
      "step": 22750
    },
    {
      "epoch": 6.221979223619464,
      "grad_norm": 0.01555707212537527,
      "learning_rate": 1.3778020776380536e-05,
      "loss": 0.0854,
      "step": 22760
    },
    {
      "epoch": 6.224712957900492,
      "grad_norm": 0.005207499489188194,
      "learning_rate": 1.377528704209951e-05,
      "loss": 0.0021,
      "step": 22770
    },
    {
      "epoch": 6.22744669218152,
      "grad_norm": 0.003195937257260084,
      "learning_rate": 1.3772553307818482e-05,
      "loss": 0.0401,
      "step": 22780
    },
    {
      "epoch": 6.230180426462548,
      "grad_norm": 1.4043782949447632,
      "learning_rate": 1.3769819573537452e-05,
      "loss": 0.0421,
      "step": 22790
    },
    {
      "epoch": 6.232914160743576,
      "grad_norm": 0.12481722980737686,
      "learning_rate": 1.3767085839256424e-05,
      "loss": 0.0034,
      "step": 22800
    },
    {
      "epoch": 6.235647895024604,
      "grad_norm": 0.015473033301532269,
      "learning_rate": 1.3764352104975399e-05,
      "loss": 0.011,
      "step": 22810
    },
    {
      "epoch": 6.238381629305631,
      "grad_norm": 0.2726184129714966,
      "learning_rate": 1.3761618370694369e-05,
      "loss": 0.0604,
      "step": 22820
    },
    {
      "epoch": 6.241115363586659,
      "grad_norm": 0.0165264829993248,
      "learning_rate": 1.375888463641334e-05,
      "loss": 0.0146,
      "step": 22830
    },
    {
      "epoch": 6.243849097867687,
      "grad_norm": 0.9821237921714783,
      "learning_rate": 1.3756150902132316e-05,
      "loss": 0.025,
      "step": 22840
    },
    {
      "epoch": 6.246582832148715,
      "grad_norm": 0.3697145879268646,
      "learning_rate": 1.3753417167851285e-05,
      "loss": 0.0069,
      "step": 22850
    },
    {
      "epoch": 6.249316566429743,
      "grad_norm": 0.0023064808920025826,
      "learning_rate": 1.3750683433570257e-05,
      "loss": 0.0019,
      "step": 22860
    },
    {
      "epoch": 6.252050300710771,
      "grad_norm": 0.1347944438457489,
      "learning_rate": 1.3747949699289229e-05,
      "loss": 0.0222,
      "step": 22870
    },
    {
      "epoch": 6.254784034991799,
      "grad_norm": 4.617179870605469,
      "learning_rate": 1.3745215965008202e-05,
      "loss": 0.0251,
      "step": 22880
    },
    {
      "epoch": 6.257517769272827,
      "grad_norm": 0.0016986029222607613,
      "learning_rate": 1.3742482230727174e-05,
      "loss": 0.0037,
      "step": 22890
    },
    {
      "epoch": 6.260251503553855,
      "grad_norm": 0.001226048800162971,
      "learning_rate": 1.3739748496446145e-05,
      "loss": 0.0114,
      "step": 22900
    },
    {
      "epoch": 6.262985237834882,
      "grad_norm": 0.48231953382492065,
      "learning_rate": 1.3737014762165119e-05,
      "loss": 0.0087,
      "step": 22910
    },
    {
      "epoch": 6.26571897211591,
      "grad_norm": 0.0010444794315844774,
      "learning_rate": 1.373428102788409e-05,
      "loss": 0.0021,
      "step": 22920
    },
    {
      "epoch": 6.268452706396938,
      "grad_norm": 0.002057297620922327,
      "learning_rate": 1.3731547293603062e-05,
      "loss": 0.0357,
      "step": 22930
    },
    {
      "epoch": 6.271186440677966,
      "grad_norm": 0.0032205565366894007,
      "learning_rate": 1.3728813559322034e-05,
      "loss": 0.014,
      "step": 22940
    },
    {
      "epoch": 6.273920174958994,
      "grad_norm": 0.12776067852973938,
      "learning_rate": 1.3726079825041007e-05,
      "loss": 0.0041,
      "step": 22950
    },
    {
      "epoch": 6.2766539092400215,
      "grad_norm": 2.5651869773864746,
      "learning_rate": 1.3723346090759979e-05,
      "loss": 0.0153,
      "step": 22960
    },
    {
      "epoch": 6.27938764352105,
      "grad_norm": 1.3166207075119019,
      "learning_rate": 1.372061235647895e-05,
      "loss": 0.0038,
      "step": 22970
    },
    {
      "epoch": 6.282121377802078,
      "grad_norm": 0.0014591828221455216,
      "learning_rate": 1.3717878622197924e-05,
      "loss": 0.0395,
      "step": 22980
    },
    {
      "epoch": 6.284855112083106,
      "grad_norm": 0.0015667007537558675,
      "learning_rate": 1.3715144887916895e-05,
      "loss": 0.0002,
      "step": 22990
    },
    {
      "epoch": 6.287588846364134,
      "grad_norm": 0.0028733855579048395,
      "learning_rate": 1.3712411153635867e-05,
      "loss": 0.0336,
      "step": 23000
    },
    {
      "epoch": 6.290322580645161,
      "grad_norm": 0.016962330788373947,
      "learning_rate": 1.3709677419354839e-05,
      "loss": 0.0101,
      "step": 23010
    },
    {
      "epoch": 6.293056314926189,
      "grad_norm": 0.0031805280596017838,
      "learning_rate": 1.3706943685073812e-05,
      "loss": 0.0374,
      "step": 23020
    },
    {
      "epoch": 6.295790049207217,
      "grad_norm": 0.002306956797838211,
      "learning_rate": 1.3704209950792784e-05,
      "loss": 0.0036,
      "step": 23030
    },
    {
      "epoch": 6.298523783488245,
      "grad_norm": 0.02872280217707157,
      "learning_rate": 1.3701476216511755e-05,
      "loss": 0.0022,
      "step": 23040
    },
    {
      "epoch": 6.3012575177692725,
      "grad_norm": 0.018313121050596237,
      "learning_rate": 1.3698742482230729e-05,
      "loss": 0.0038,
      "step": 23050
    },
    {
      "epoch": 6.3039912520503005,
      "grad_norm": 0.12611787021160126,
      "learning_rate": 1.36960087479497e-05,
      "loss": 0.0227,
      "step": 23060
    },
    {
      "epoch": 6.306724986331329,
      "grad_norm": 0.004480412229895592,
      "learning_rate": 1.3693275013668672e-05,
      "loss": 0.0622,
      "step": 23070
    },
    {
      "epoch": 6.309458720612357,
      "grad_norm": 0.23338887095451355,
      "learning_rate": 1.3690541279387644e-05,
      "loss": 0.026,
      "step": 23080
    },
    {
      "epoch": 6.312192454893385,
      "grad_norm": 0.002352372743189335,
      "learning_rate": 1.3687807545106617e-05,
      "loss": 0.0436,
      "step": 23090
    },
    {
      "epoch": 6.314926189174412,
      "grad_norm": 0.9057266712188721,
      "learning_rate": 1.3685073810825589e-05,
      "loss": 0.0094,
      "step": 23100
    },
    {
      "epoch": 6.31765992345544,
      "grad_norm": 0.008326247334480286,
      "learning_rate": 1.368234007654456e-05,
      "loss": 0.0098,
      "step": 23110
    },
    {
      "epoch": 6.320393657736468,
      "grad_norm": 0.0024563923943787813,
      "learning_rate": 1.3679606342263534e-05,
      "loss": 0.0018,
      "step": 23120
    },
    {
      "epoch": 6.323127392017496,
      "grad_norm": 7.408450603485107,
      "learning_rate": 1.3676872607982505e-05,
      "loss": 0.0544,
      "step": 23130
    },
    {
      "epoch": 6.325861126298523,
      "grad_norm": 0.014165481552481651,
      "learning_rate": 1.3674138873701477e-05,
      "loss": 0.0031,
      "step": 23140
    },
    {
      "epoch": 6.3285948605795515,
      "grad_norm": 0.0027757168281823397,
      "learning_rate": 1.367140513942045e-05,
      "loss": 0.0026,
      "step": 23150
    },
    {
      "epoch": 6.3313285948605795,
      "grad_norm": 21.13216781616211,
      "learning_rate": 1.3668671405139422e-05,
      "loss": 0.039,
      "step": 23160
    },
    {
      "epoch": 6.334062329141608,
      "grad_norm": 0.02612330950796604,
      "learning_rate": 1.3665937670858394e-05,
      "loss": 0.0288,
      "step": 23170
    },
    {
      "epoch": 6.336796063422636,
      "grad_norm": 0.27559489011764526,
      "learning_rate": 1.3663203936577365e-05,
      "loss": 0.0138,
      "step": 23180
    },
    {
      "epoch": 6.339529797703663,
      "grad_norm": 0.003207694971933961,
      "learning_rate": 1.3660470202296339e-05,
      "loss": 0.0048,
      "step": 23190
    },
    {
      "epoch": 6.342263531984691,
      "grad_norm": 5.08120059967041,
      "learning_rate": 1.365773646801531e-05,
      "loss": 0.0593,
      "step": 23200
    },
    {
      "epoch": 6.344997266265719,
      "grad_norm": 0.2259291708469391,
      "learning_rate": 1.3655002733734282e-05,
      "loss": 0.0028,
      "step": 23210
    },
    {
      "epoch": 6.347731000546747,
      "grad_norm": 2.0225677490234375,
      "learning_rate": 1.3652268999453255e-05,
      "loss": 0.0072,
      "step": 23220
    },
    {
      "epoch": 6.350464734827774,
      "grad_norm": 0.01206313818693161,
      "learning_rate": 1.3649535265172227e-05,
      "loss": 0.0284,
      "step": 23230
    },
    {
      "epoch": 6.353198469108802,
      "grad_norm": 0.35886240005493164,
      "learning_rate": 1.3646801530891199e-05,
      "loss": 0.0021,
      "step": 23240
    },
    {
      "epoch": 6.3559322033898304,
      "grad_norm": 4.321910381317139,
      "learning_rate": 1.364406779661017e-05,
      "loss": 0.0329,
      "step": 23250
    },
    {
      "epoch": 6.3586659376708585,
      "grad_norm": 2.4261374473571777,
      "learning_rate": 1.3641334062329144e-05,
      "loss": 0.0478,
      "step": 23260
    },
    {
      "epoch": 6.361399671951887,
      "grad_norm": 0.014490380883216858,
      "learning_rate": 1.3638600328048115e-05,
      "loss": 0.0003,
      "step": 23270
    },
    {
      "epoch": 6.364133406232914,
      "grad_norm": 0.007188606541603804,
      "learning_rate": 1.3635866593767087e-05,
      "loss": 0.0004,
      "step": 23280
    },
    {
      "epoch": 6.366867140513942,
      "grad_norm": 1.256348967552185,
      "learning_rate": 1.363313285948606e-05,
      "loss": 0.0413,
      "step": 23290
    },
    {
      "epoch": 6.36960087479497,
      "grad_norm": 2.32328462600708,
      "learning_rate": 1.3630399125205032e-05,
      "loss": 0.0109,
      "step": 23300
    },
    {
      "epoch": 6.372334609075998,
      "grad_norm": 0.007934951223433018,
      "learning_rate": 1.3627665390924004e-05,
      "loss": 0.0004,
      "step": 23310
    },
    {
      "epoch": 6.375068343357026,
      "grad_norm": 0.6005553007125854,
      "learning_rate": 1.3624931656642975e-05,
      "loss": 0.0087,
      "step": 23320
    },
    {
      "epoch": 6.377802077638053,
      "grad_norm": 0.0035484859254211187,
      "learning_rate": 1.3622197922361949e-05,
      "loss": 0.0055,
      "step": 23330
    },
    {
      "epoch": 6.380535811919081,
      "grad_norm": 0.006176821421831846,
      "learning_rate": 1.361946418808092e-05,
      "loss": 0.0452,
      "step": 23340
    },
    {
      "epoch": 6.3832695462001094,
      "grad_norm": 0.006017895415425301,
      "learning_rate": 1.3616730453799892e-05,
      "loss": 0.0247,
      "step": 23350
    },
    {
      "epoch": 6.3860032804811375,
      "grad_norm": 0.009446723386645317,
      "learning_rate": 1.3613996719518865e-05,
      "loss": 0.0169,
      "step": 23360
    },
    {
      "epoch": 6.388737014762165,
      "grad_norm": 0.016082648187875748,
      "learning_rate": 1.3611262985237837e-05,
      "loss": 0.0129,
      "step": 23370
    },
    {
      "epoch": 6.391470749043193,
      "grad_norm": 0.011020481586456299,
      "learning_rate": 1.3608529250956809e-05,
      "loss": 0.0082,
      "step": 23380
    },
    {
      "epoch": 6.394204483324221,
      "grad_norm": 1.8475698232650757,
      "learning_rate": 1.3605795516675779e-05,
      "loss": 0.014,
      "step": 23390
    },
    {
      "epoch": 6.396938217605249,
      "grad_norm": 64.72689056396484,
      "learning_rate": 1.3603061782394754e-05,
      "loss": 0.0537,
      "step": 23400
    },
    {
      "epoch": 6.399671951886277,
      "grad_norm": 0.0033998852595686913,
      "learning_rate": 1.3600328048113725e-05,
      "loss": 0.0494,
      "step": 23410
    },
    {
      "epoch": 6.402405686167304,
      "grad_norm": 0.004958225414156914,
      "learning_rate": 1.3597594313832695e-05,
      "loss": 0.01,
      "step": 23420
    },
    {
      "epoch": 6.405139420448332,
      "grad_norm": 0.0024700413923710585,
      "learning_rate": 1.359486057955167e-05,
      "loss": 0.0036,
      "step": 23430
    },
    {
      "epoch": 6.40787315472936,
      "grad_norm": 0.001991349272429943,
      "learning_rate": 1.3592126845270642e-05,
      "loss": 0.001,
      "step": 23440
    },
    {
      "epoch": 6.410606889010388,
      "grad_norm": 1.7929795980453491,
      "learning_rate": 1.3589393110989612e-05,
      "loss": 0.0362,
      "step": 23450
    },
    {
      "epoch": 6.4133406232914165,
      "grad_norm": 0.0026889420114457607,
      "learning_rate": 1.3586659376708584e-05,
      "loss": 0.0201,
      "step": 23460
    },
    {
      "epoch": 6.416074357572444,
      "grad_norm": 0.019238019362092018,
      "learning_rate": 1.3583925642427559e-05,
      "loss": 0.0011,
      "step": 23470
    },
    {
      "epoch": 6.418808091853472,
      "grad_norm": 1.3928176164627075,
      "learning_rate": 1.3581191908146529e-05,
      "loss": 0.0022,
      "step": 23480
    },
    {
      "epoch": 6.4215418261345,
      "grad_norm": 0.007115992717444897,
      "learning_rate": 1.35784581738655e-05,
      "loss": 0.0168,
      "step": 23490
    },
    {
      "epoch": 6.424275560415528,
      "grad_norm": 0.0031103072687983513,
      "learning_rate": 1.3575724439584475e-05,
      "loss": 0.0531,
      "step": 23500
    },
    {
      "epoch": 6.427009294696555,
      "grad_norm": 2.207273483276367,
      "learning_rate": 1.3572990705303445e-05,
      "loss": 0.0954,
      "step": 23510
    },
    {
      "epoch": 6.429743028977583,
      "grad_norm": 0.3055448830127716,
      "learning_rate": 1.3570256971022417e-05,
      "loss": 0.0075,
      "step": 23520
    },
    {
      "epoch": 6.432476763258611,
      "grad_norm": 0.03720185533165932,
      "learning_rate": 1.3567523236741389e-05,
      "loss": 0.0292,
      "step": 23530
    },
    {
      "epoch": 6.435210497539639,
      "grad_norm": 0.007607417646795511,
      "learning_rate": 1.3564789502460362e-05,
      "loss": 0.0067,
      "step": 23540
    },
    {
      "epoch": 6.437944231820667,
      "grad_norm": 0.08458781987428665,
      "learning_rate": 1.3562055768179334e-05,
      "loss": 0.0303,
      "step": 23550
    },
    {
      "epoch": 6.440677966101695,
      "grad_norm": 0.005398075561970472,
      "learning_rate": 1.3559322033898305e-05,
      "loss": 0.001,
      "step": 23560
    },
    {
      "epoch": 6.443411700382723,
      "grad_norm": 0.02020884118974209,
      "learning_rate": 1.3556588299617279e-05,
      "loss": 0.0065,
      "step": 23570
    },
    {
      "epoch": 6.446145434663751,
      "grad_norm": 0.007534361910074949,
      "learning_rate": 1.355385456533625e-05,
      "loss": 0.0267,
      "step": 23580
    },
    {
      "epoch": 6.448879168944779,
      "grad_norm": 0.06606477499008179,
      "learning_rate": 1.3551120831055222e-05,
      "loss": 0.0465,
      "step": 23590
    },
    {
      "epoch": 6.451612903225806,
      "grad_norm": 0.04866303130984306,
      "learning_rate": 1.3548387096774194e-05,
      "loss": 0.0135,
      "step": 23600
    },
    {
      "epoch": 6.454346637506834,
      "grad_norm": 0.004240887239575386,
      "learning_rate": 1.3545653362493167e-05,
      "loss": 0.008,
      "step": 23610
    },
    {
      "epoch": 6.457080371787862,
      "grad_norm": 0.07029324024915695,
      "learning_rate": 1.3542919628212139e-05,
      "loss": 0.0008,
      "step": 23620
    },
    {
      "epoch": 6.45981410606889,
      "grad_norm": 0.06376630067825317,
      "learning_rate": 1.354018589393111e-05,
      "loss": 0.0109,
      "step": 23630
    },
    {
      "epoch": 6.462547840349918,
      "grad_norm": 0.014280187897384167,
      "learning_rate": 1.3537452159650084e-05,
      "loss": 0.0213,
      "step": 23640
    },
    {
      "epoch": 6.4652815746309455,
      "grad_norm": 0.012597753666341305,
      "learning_rate": 1.3534718425369055e-05,
      "loss": 0.0032,
      "step": 23650
    },
    {
      "epoch": 6.468015308911974,
      "grad_norm": 1.5481178760528564,
      "learning_rate": 1.3531984691088027e-05,
      "loss": 0.0139,
      "step": 23660
    },
    {
      "epoch": 6.470749043193002,
      "grad_norm": 0.046202823519706726,
      "learning_rate": 1.3529250956806999e-05,
      "loss": 0.0003,
      "step": 23670
    },
    {
      "epoch": 6.47348277747403,
      "grad_norm": 0.0010695595992729068,
      "learning_rate": 1.3526517222525972e-05,
      "loss": 0.0101,
      "step": 23680
    },
    {
      "epoch": 6.476216511755057,
      "grad_norm": 0.00889614038169384,
      "learning_rate": 1.3523783488244944e-05,
      "loss": 0.0025,
      "step": 23690
    },
    {
      "epoch": 6.478950246036085,
      "grad_norm": 0.0027601809706538916,
      "learning_rate": 1.3521049753963915e-05,
      "loss": 0.0046,
      "step": 23700
    },
    {
      "epoch": 6.481683980317113,
      "grad_norm": 0.0069528985768556595,
      "learning_rate": 1.3518316019682889e-05,
      "loss": 0.0154,
      "step": 23710
    },
    {
      "epoch": 6.484417714598141,
      "grad_norm": 0.004189229104667902,
      "learning_rate": 1.351558228540186e-05,
      "loss": 0.0038,
      "step": 23720
    },
    {
      "epoch": 6.487151448879169,
      "grad_norm": 0.0022997884079813957,
      "learning_rate": 1.3512848551120832e-05,
      "loss": 0.0169,
      "step": 23730
    },
    {
      "epoch": 6.4898851831601965,
      "grad_norm": 0.007169347256422043,
      "learning_rate": 1.3510114816839804e-05,
      "loss": 0.0529,
      "step": 23740
    },
    {
      "epoch": 6.4926189174412245,
      "grad_norm": 0.18751026690006256,
      "learning_rate": 1.3507381082558777e-05,
      "loss": 0.0689,
      "step": 23750
    },
    {
      "epoch": 6.495352651722253,
      "grad_norm": 0.0691274031996727,
      "learning_rate": 1.3504647348277749e-05,
      "loss": 0.0199,
      "step": 23760
    },
    {
      "epoch": 6.498086386003281,
      "grad_norm": 0.00915239192545414,
      "learning_rate": 1.350191361399672e-05,
      "loss": 0.0111,
      "step": 23770
    },
    {
      "epoch": 6.500820120284308,
      "grad_norm": 0.013587485067546368,
      "learning_rate": 1.3499179879715694e-05,
      "loss": 0.0049,
      "step": 23780
    },
    {
      "epoch": 6.503553854565336,
      "grad_norm": 0.8128566145896912,
      "learning_rate": 1.3496446145434665e-05,
      "loss": 0.0216,
      "step": 23790
    },
    {
      "epoch": 6.506287588846364,
      "grad_norm": 0.0035317239817231894,
      "learning_rate": 1.3493712411153637e-05,
      "loss": 0.0265,
      "step": 23800
    },
    {
      "epoch": 6.509021323127392,
      "grad_norm": 1.372124433517456,
      "learning_rate": 1.3490978676872609e-05,
      "loss": 0.0536,
      "step": 23810
    },
    {
      "epoch": 6.51175505740842,
      "grad_norm": 0.007272146176546812,
      "learning_rate": 1.3488244942591582e-05,
      "loss": 0.0076,
      "step": 23820
    },
    {
      "epoch": 6.514488791689448,
      "grad_norm": 0.044357359409332275,
      "learning_rate": 1.3485511208310554e-05,
      "loss": 0.0035,
      "step": 23830
    },
    {
      "epoch": 6.5172225259704755,
      "grad_norm": 0.004535776097327471,
      "learning_rate": 1.3482777474029525e-05,
      "loss": 0.0036,
      "step": 23840
    },
    {
      "epoch": 6.5199562602515035,
      "grad_norm": 0.0038047663401812315,
      "learning_rate": 1.3480043739748499e-05,
      "loss": 0.0222,
      "step": 23850
    },
    {
      "epoch": 6.522689994532532,
      "grad_norm": 0.027457814663648605,
      "learning_rate": 1.347731000546747e-05,
      "loss": 0.0077,
      "step": 23860
    },
    {
      "epoch": 6.52542372881356,
      "grad_norm": 0.0019271528581157327,
      "learning_rate": 1.3474576271186442e-05,
      "loss": 0.0092,
      "step": 23870
    },
    {
      "epoch": 6.528157463094587,
      "grad_norm": 0.0027367451693862677,
      "learning_rate": 1.3471842536905413e-05,
      "loss": 0.0208,
      "step": 23880
    },
    {
      "epoch": 6.530891197375615,
      "grad_norm": 1.6712300777435303,
      "learning_rate": 1.3469108802624387e-05,
      "loss": 0.0032,
      "step": 23890
    },
    {
      "epoch": 6.533624931656643,
      "grad_norm": 0.003096821717917919,
      "learning_rate": 1.3466375068343358e-05,
      "loss": 0.0197,
      "step": 23900
    },
    {
      "epoch": 6.536358665937671,
      "grad_norm": 0.012652854435145855,
      "learning_rate": 1.346364133406233e-05,
      "loss": 0.0155,
      "step": 23910
    },
    {
      "epoch": 6.539092400218699,
      "grad_norm": 0.0014782104408368468,
      "learning_rate": 1.3460907599781303e-05,
      "loss": 0.0051,
      "step": 23920
    },
    {
      "epoch": 6.541826134499726,
      "grad_norm": 0.0052733039483428,
      "learning_rate": 1.3458173865500275e-05,
      "loss": 0.0252,
      "step": 23930
    },
    {
      "epoch": 6.5445598687807545,
      "grad_norm": 2.361640691757202,
      "learning_rate": 1.3455440131219247e-05,
      "loss": 0.0203,
      "step": 23940
    },
    {
      "epoch": 6.5472936030617825,
      "grad_norm": 1.2162892818450928,
      "learning_rate": 1.3452706396938218e-05,
      "loss": 0.0032,
      "step": 23950
    },
    {
      "epoch": 6.550027337342811,
      "grad_norm": 0.0028285840526223183,
      "learning_rate": 1.3449972662657192e-05,
      "loss": 0.0027,
      "step": 23960
    },
    {
      "epoch": 6.552761071623838,
      "grad_norm": 0.04140408709645271,
      "learning_rate": 1.3447238928376163e-05,
      "loss": 0.0003,
      "step": 23970
    },
    {
      "epoch": 6.555494805904866,
      "grad_norm": 0.005085141863673925,
      "learning_rate": 1.3444505194095135e-05,
      "loss": 0.0014,
      "step": 23980
    },
    {
      "epoch": 6.558228540185894,
      "grad_norm": 0.6397041082382202,
      "learning_rate": 1.3441771459814108e-05,
      "loss": 0.0242,
      "step": 23990
    },
    {
      "epoch": 6.560962274466922,
      "grad_norm": 0.008869009092450142,
      "learning_rate": 1.343903772553308e-05,
      "loss": 0.0401,
      "step": 24000
    },
    {
      "epoch": 6.56369600874795,
      "grad_norm": 0.011661075055599213,
      "learning_rate": 1.3436303991252052e-05,
      "loss": 0.0271,
      "step": 24010
    },
    {
      "epoch": 6.566429743028977,
      "grad_norm": 0.005909724626690149,
      "learning_rate": 1.3433570256971022e-05,
      "loss": 0.0311,
      "step": 24020
    },
    {
      "epoch": 6.569163477310005,
      "grad_norm": 0.11427391320466995,
      "learning_rate": 1.3430836522689997e-05,
      "loss": 0.0524,
      "step": 24030
    },
    {
      "epoch": 6.5718972115910335,
      "grad_norm": 0.0147788655012846,
      "learning_rate": 1.3428102788408968e-05,
      "loss": 0.0199,
      "step": 24040
    },
    {
      "epoch": 6.5746309458720615,
      "grad_norm": 0.14165566861629486,
      "learning_rate": 1.3425369054127938e-05,
      "loss": 0.0273,
      "step": 24050
    },
    {
      "epoch": 6.577364680153089,
      "grad_norm": 0.01713372953236103,
      "learning_rate": 1.3422635319846913e-05,
      "loss": 0.0068,
      "step": 24060
    },
    {
      "epoch": 6.580098414434117,
      "grad_norm": 16.761381149291992,
      "learning_rate": 1.3419901585565885e-05,
      "loss": 0.1237,
      "step": 24070
    },
    {
      "epoch": 6.582832148715145,
      "grad_norm": 0.05475831404328346,
      "learning_rate": 1.3417167851284855e-05,
      "loss": 0.0115,
      "step": 24080
    },
    {
      "epoch": 6.585565882996173,
      "grad_norm": 0.0072504496201872826,
      "learning_rate": 1.3414434117003827e-05,
      "loss": 0.0142,
      "step": 24090
    },
    {
      "epoch": 6.588299617277201,
      "grad_norm": 0.20441512763500214,
      "learning_rate": 1.3411700382722802e-05,
      "loss": 0.0216,
      "step": 24100
    },
    {
      "epoch": 6.591033351558228,
      "grad_norm": 0.17188295722007751,
      "learning_rate": 1.3408966648441772e-05,
      "loss": 0.0034,
      "step": 24110
    },
    {
      "epoch": 6.593767085839256,
      "grad_norm": 3.6704928874969482,
      "learning_rate": 1.3406232914160743e-05,
      "loss": 0.0271,
      "step": 24120
    },
    {
      "epoch": 6.596500820120284,
      "grad_norm": 0.006191476713865995,
      "learning_rate": 1.3403499179879718e-05,
      "loss": 0.0032,
      "step": 24130
    },
    {
      "epoch": 6.5992345544013125,
      "grad_norm": 0.0018287956481799483,
      "learning_rate": 1.3400765445598688e-05,
      "loss": 0.004,
      "step": 24140
    },
    {
      "epoch": 6.60196828868234,
      "grad_norm": 0.00195458740927279,
      "learning_rate": 1.339803171131766e-05,
      "loss": 0.005,
      "step": 24150
    },
    {
      "epoch": 6.604702022963368,
      "grad_norm": 0.08437524735927582,
      "learning_rate": 1.3395297977036632e-05,
      "loss": 0.0139,
      "step": 24160
    },
    {
      "epoch": 6.607435757244396,
      "grad_norm": 0.010208439081907272,
      "learning_rate": 1.3392564242755605e-05,
      "loss": 0.0111,
      "step": 24170
    },
    {
      "epoch": 6.610169491525424,
      "grad_norm": 0.0029801044147461653,
      "learning_rate": 1.3389830508474577e-05,
      "loss": 0.0164,
      "step": 24180
    },
    {
      "epoch": 6.612903225806452,
      "grad_norm": 12.862756729125977,
      "learning_rate": 1.3387096774193548e-05,
      "loss": 0.0074,
      "step": 24190
    },
    {
      "epoch": 6.615636960087479,
      "grad_norm": 0.2931888699531555,
      "learning_rate": 1.3384363039912522e-05,
      "loss": 0.0018,
      "step": 24200
    },
    {
      "epoch": 6.618370694368507,
      "grad_norm": 1.1772834062576294,
      "learning_rate": 1.3381629305631493e-05,
      "loss": 0.0042,
      "step": 24210
    },
    {
      "epoch": 6.621104428649535,
      "grad_norm": 0.005821693688631058,
      "learning_rate": 1.3378895571350465e-05,
      "loss": 0.0069,
      "step": 24220
    },
    {
      "epoch": 6.623838162930563,
      "grad_norm": 0.01878732442855835,
      "learning_rate": 1.3376161837069438e-05,
      "loss": 0.0441,
      "step": 24230
    },
    {
      "epoch": 6.626571897211591,
      "grad_norm": 0.015950843691825867,
      "learning_rate": 1.337342810278841e-05,
      "loss": 0.0435,
      "step": 24240
    },
    {
      "epoch": 6.629305631492619,
      "grad_norm": 0.007678213529288769,
      "learning_rate": 1.3370694368507382e-05,
      "loss": 0.0025,
      "step": 24250
    },
    {
      "epoch": 6.632039365773647,
      "grad_norm": 0.43910032510757446,
      "learning_rate": 1.3367960634226353e-05,
      "loss": 0.019,
      "step": 24260
    },
    {
      "epoch": 6.634773100054675,
      "grad_norm": 3.8650195598602295,
      "learning_rate": 1.3365226899945327e-05,
      "loss": 0.0709,
      "step": 24270
    },
    {
      "epoch": 6.637506834335703,
      "grad_norm": 0.010551845654845238,
      "learning_rate": 1.3362493165664298e-05,
      "loss": 0.0238,
      "step": 24280
    },
    {
      "epoch": 6.64024056861673,
      "grad_norm": 0.02348368801176548,
      "learning_rate": 1.335975943138327e-05,
      "loss": 0.0122,
      "step": 24290
    },
    {
      "epoch": 6.642974302897758,
      "grad_norm": 0.08083457499742508,
      "learning_rate": 1.3357025697102243e-05,
      "loss": 0.0593,
      "step": 24300
    },
    {
      "epoch": 6.645708037178786,
      "grad_norm": 0.03365208953619003,
      "learning_rate": 1.3354291962821215e-05,
      "loss": 0.0205,
      "step": 24310
    },
    {
      "epoch": 6.648441771459814,
      "grad_norm": 1.1193453073501587,
      "learning_rate": 1.3351558228540187e-05,
      "loss": 0.0056,
      "step": 24320
    },
    {
      "epoch": 6.651175505740842,
      "grad_norm": 0.10666606575250626,
      "learning_rate": 1.3348824494259158e-05,
      "loss": 0.0156,
      "step": 24330
    },
    {
      "epoch": 6.65390924002187,
      "grad_norm": 0.07723665237426758,
      "learning_rate": 1.3346090759978132e-05,
      "loss": 0.0188,
      "step": 24340
    },
    {
      "epoch": 6.656642974302898,
      "grad_norm": 0.052954383194446564,
      "learning_rate": 1.3343357025697103e-05,
      "loss": 0.0283,
      "step": 24350
    },
    {
      "epoch": 6.659376708583926,
      "grad_norm": 0.048616357147693634,
      "learning_rate": 1.3340623291416075e-05,
      "loss": 0.0065,
      "step": 24360
    },
    {
      "epoch": 6.662110442864954,
      "grad_norm": 0.006446133367717266,
      "learning_rate": 1.3337889557135048e-05,
      "loss": 0.0036,
      "step": 24370
    },
    {
      "epoch": 6.664844177145982,
      "grad_norm": 5.256809234619141,
      "learning_rate": 1.333515582285402e-05,
      "loss": 0.0191,
      "step": 24380
    },
    {
      "epoch": 6.667577911427009,
      "grad_norm": 0.005090033169835806,
      "learning_rate": 1.3332422088572992e-05,
      "loss": 0.0009,
      "step": 24390
    },
    {
      "epoch": 6.670311645708037,
      "grad_norm": 0.009359998628497124,
      "learning_rate": 1.3329688354291963e-05,
      "loss": 0.0026,
      "step": 24400
    },
    {
      "epoch": 6.673045379989065,
      "grad_norm": 0.004389334004372358,
      "learning_rate": 1.3326954620010937e-05,
      "loss": 0.0538,
      "step": 24410
    },
    {
      "epoch": 6.675779114270093,
      "grad_norm": 5.847284317016602,
      "learning_rate": 1.3324220885729908e-05,
      "loss": 0.0128,
      "step": 24420
    },
    {
      "epoch": 6.6785128485511205,
      "grad_norm": 0.3020872175693512,
      "learning_rate": 1.332148715144888e-05,
      "loss": 0.0028,
      "step": 24430
    },
    {
      "epoch": 6.681246582832149,
      "grad_norm": 0.0157943032681942,
      "learning_rate": 1.3318753417167853e-05,
      "loss": 0.0256,
      "step": 24440
    },
    {
      "epoch": 6.683980317113177,
      "grad_norm": 0.11439426988363266,
      "learning_rate": 1.3316019682886825e-05,
      "loss": 0.0749,
      "step": 24450
    },
    {
      "epoch": 6.686714051394205,
      "grad_norm": 0.377350777387619,
      "learning_rate": 1.3313285948605797e-05,
      "loss": 0.079,
      "step": 24460
    },
    {
      "epoch": 6.689447785675233,
      "grad_norm": 0.09421171993017197,
      "learning_rate": 1.3310552214324768e-05,
      "loss": 0.0028,
      "step": 24470
    },
    {
      "epoch": 6.69218151995626,
      "grad_norm": 0.21450833976268768,
      "learning_rate": 1.3307818480043742e-05,
      "loss": 0.0381,
      "step": 24480
    },
    {
      "epoch": 6.694915254237288,
      "grad_norm": 0.010938392952084541,
      "learning_rate": 1.3305084745762713e-05,
      "loss": 0.0122,
      "step": 24490
    },
    {
      "epoch": 6.697648988518316,
      "grad_norm": 0.08916826546192169,
      "learning_rate": 1.3302351011481685e-05,
      "loss": 0.0658,
      "step": 24500
    },
    {
      "epoch": 6.700382722799344,
      "grad_norm": 0.06682048738002777,
      "learning_rate": 1.3299617277200658e-05,
      "loss": 0.0236,
      "step": 24510
    },
    {
      "epoch": 6.703116457080371,
      "grad_norm": 0.027556801214814186,
      "learning_rate": 1.329688354291963e-05,
      "loss": 0.0298,
      "step": 24520
    },
    {
      "epoch": 6.7058501913613995,
      "grad_norm": 0.036409031599760056,
      "learning_rate": 1.3294149808638602e-05,
      "loss": 0.0232,
      "step": 24530
    },
    {
      "epoch": 6.708583925642428,
      "grad_norm": 0.02892235293984413,
      "learning_rate": 1.3291416074357573e-05,
      "loss": 0.0021,
      "step": 24540
    },
    {
      "epoch": 6.711317659923456,
      "grad_norm": 0.033271364867687225,
      "learning_rate": 1.3288682340076547e-05,
      "loss": 0.0722,
      "step": 24550
    },
    {
      "epoch": 6.714051394204484,
      "grad_norm": 2.998861789703369,
      "learning_rate": 1.3285948605795518e-05,
      "loss": 0.0256,
      "step": 24560
    },
    {
      "epoch": 6.716785128485511,
      "grad_norm": 0.02561621367931366,
      "learning_rate": 1.328321487151449e-05,
      "loss": 0.0132,
      "step": 24570
    },
    {
      "epoch": 6.719518862766539,
      "grad_norm": 0.016779372468590736,
      "learning_rate": 1.3280481137233463e-05,
      "loss": 0.0006,
      "step": 24580
    },
    {
      "epoch": 6.722252597047567,
      "grad_norm": 0.044333480298519135,
      "learning_rate": 1.3277747402952435e-05,
      "loss": 0.0832,
      "step": 24590
    },
    {
      "epoch": 6.724986331328595,
      "grad_norm": 0.03434820473194122,
      "learning_rate": 1.3275013668671407e-05,
      "loss": 0.0507,
      "step": 24600
    },
    {
      "epoch": 6.727720065609622,
      "grad_norm": 0.05603351444005966,
      "learning_rate": 1.3272279934390378e-05,
      "loss": 0.0176,
      "step": 24610
    },
    {
      "epoch": 6.73045379989065,
      "grad_norm": 0.06652812659740448,
      "learning_rate": 1.3269546200109352e-05,
      "loss": 0.0224,
      "step": 24620
    },
    {
      "epoch": 6.7331875341716785,
      "grad_norm": 0.032760441303253174,
      "learning_rate": 1.3266812465828323e-05,
      "loss": 0.0051,
      "step": 24630
    },
    {
      "epoch": 6.735921268452707,
      "grad_norm": 10.8704833984375,
      "learning_rate": 1.3264078731547295e-05,
      "loss": 0.0243,
      "step": 24640
    },
    {
      "epoch": 6.738655002733735,
      "grad_norm": 0.008217454887926579,
      "learning_rate": 1.3261344997266268e-05,
      "loss": 0.0121,
      "step": 24650
    },
    {
      "epoch": 6.741388737014762,
      "grad_norm": 3.217815399169922,
      "learning_rate": 1.325861126298524e-05,
      "loss": 0.0042,
      "step": 24660
    },
    {
      "epoch": 6.74412247129579,
      "grad_norm": 0.0041832574643194675,
      "learning_rate": 1.3255877528704212e-05,
      "loss": 0.0006,
      "step": 24670
    },
    {
      "epoch": 6.746856205576818,
      "grad_norm": 0.005151322111487389,
      "learning_rate": 1.3253143794423182e-05,
      "loss": 0.0106,
      "step": 24680
    },
    {
      "epoch": 6.749589939857846,
      "grad_norm": 23.53267478942871,
      "learning_rate": 1.3250410060142157e-05,
      "loss": 0.0065,
      "step": 24690
    },
    {
      "epoch": 6.752323674138873,
      "grad_norm": 0.32132574915885925,
      "learning_rate": 1.3247676325861128e-05,
      "loss": 0.0066,
      "step": 24700
    },
    {
      "epoch": 6.755057408419901,
      "grad_norm": 0.16726939380168915,
      "learning_rate": 1.3244942591580098e-05,
      "loss": 0.021,
      "step": 24710
    },
    {
      "epoch": 6.757791142700929,
      "grad_norm": 0.006268060300499201,
      "learning_rate": 1.3242208857299073e-05,
      "loss": 0.0281,
      "step": 24720
    },
    {
      "epoch": 6.7605248769819575,
      "grad_norm": 0.008151962421834469,
      "learning_rate": 1.3239475123018045e-05,
      "loss": 0.015,
      "step": 24730
    },
    {
      "epoch": 6.7632586112629856,
      "grad_norm": 1.3460644483566284,
      "learning_rate": 1.3236741388737015e-05,
      "loss": 0.0206,
      "step": 24740
    },
    {
      "epoch": 6.765992345544013,
      "grad_norm": 0.005017674993723631,
      "learning_rate": 1.3234007654455986e-05,
      "loss": 0.0347,
      "step": 24750
    },
    {
      "epoch": 6.768726079825041,
      "grad_norm": 0.008796409703791142,
      "learning_rate": 1.3231273920174962e-05,
      "loss": 0.0269,
      "step": 24760
    },
    {
      "epoch": 6.771459814106069,
      "grad_norm": 3.4329144954681396,
      "learning_rate": 1.3228540185893932e-05,
      "loss": 0.0154,
      "step": 24770
    },
    {
      "epoch": 6.774193548387097,
      "grad_norm": 0.011678490787744522,
      "learning_rate": 1.3225806451612903e-05,
      "loss": 0.0076,
      "step": 24780
    },
    {
      "epoch": 6.776927282668124,
      "grad_norm": 0.027194427326321602,
      "learning_rate": 1.3223072717331878e-05,
      "loss": 0.0102,
      "step": 24790
    },
    {
      "epoch": 6.779661016949152,
      "grad_norm": 0.021784182637929916,
      "learning_rate": 1.3220338983050848e-05,
      "loss": 0.0009,
      "step": 24800
    },
    {
      "epoch": 6.78239475123018,
      "grad_norm": 0.013068458996713161,
      "learning_rate": 1.321760524876982e-05,
      "loss": 0.0135,
      "step": 24810
    },
    {
      "epoch": 6.785128485511208,
      "grad_norm": 0.04169883579015732,
      "learning_rate": 1.3214871514488791e-05,
      "loss": 0.0004,
      "step": 24820
    },
    {
      "epoch": 6.7878622197922365,
      "grad_norm": 0.00256345490925014,
      "learning_rate": 1.3212137780207765e-05,
      "loss": 0.0542,
      "step": 24830
    },
    {
      "epoch": 6.7905959540732646,
      "grad_norm": 0.5561187267303467,
      "learning_rate": 1.3209404045926736e-05,
      "loss": 0.005,
      "step": 24840
    },
    {
      "epoch": 6.793329688354292,
      "grad_norm": 1.8595179319381714,
      "learning_rate": 1.3206670311645708e-05,
      "loss": 0.0575,
      "step": 24850
    },
    {
      "epoch": 6.79606342263532,
      "grad_norm": 0.13147179782390594,
      "learning_rate": 1.3203936577364681e-05,
      "loss": 0.0296,
      "step": 24860
    },
    {
      "epoch": 6.798797156916348,
      "grad_norm": 0.046055663377046585,
      "learning_rate": 1.3201202843083653e-05,
      "loss": 0.022,
      "step": 24870
    },
    {
      "epoch": 6.801530891197376,
      "grad_norm": 0.08730066567659378,
      "learning_rate": 1.3198469108802625e-05,
      "loss": 0.0097,
      "step": 24880
    },
    {
      "epoch": 6.804264625478403,
      "grad_norm": 0.01929238997399807,
      "learning_rate": 1.3195735374521596e-05,
      "loss": 0.0187,
      "step": 24890
    },
    {
      "epoch": 6.806998359759431,
      "grad_norm": 0.19552063941955566,
      "learning_rate": 1.319300164024057e-05,
      "loss": 0.0124,
      "step": 24900
    },
    {
      "epoch": 6.809732094040459,
      "grad_norm": 0.077485591173172,
      "learning_rate": 1.3190267905959541e-05,
      "loss": 0.0268,
      "step": 24910
    },
    {
      "epoch": 6.812465828321487,
      "grad_norm": 0.0758080780506134,
      "learning_rate": 1.3187534171678513e-05,
      "loss": 0.014,
      "step": 24920
    },
    {
      "epoch": 6.8151995626025155,
      "grad_norm": 0.0047380649484694,
      "learning_rate": 1.3184800437397486e-05,
      "loss": 0.0063,
      "step": 24930
    },
    {
      "epoch": 6.817933296883543,
      "grad_norm": 0.016528436914086342,
      "learning_rate": 1.3182066703116458e-05,
      "loss": 0.0045,
      "step": 24940
    },
    {
      "epoch": 6.820667031164571,
      "grad_norm": 0.005298325791954994,
      "learning_rate": 1.317933296883543e-05,
      "loss": 0.0048,
      "step": 24950
    },
    {
      "epoch": 6.823400765445599,
      "grad_norm": 0.006852314807474613,
      "learning_rate": 1.3176599234554401e-05,
      "loss": 0.0159,
      "step": 24960
    },
    {
      "epoch": 6.826134499726627,
      "grad_norm": 0.14115238189697266,
      "learning_rate": 1.3173865500273375e-05,
      "loss": 0.0064,
      "step": 24970
    },
    {
      "epoch": 6.828868234007654,
      "grad_norm": 0.008873122744262218,
      "learning_rate": 1.3171131765992346e-05,
      "loss": 0.0593,
      "step": 24980
    },
    {
      "epoch": 6.831601968288682,
      "grad_norm": 0.3864177167415619,
      "learning_rate": 1.3168398031711318e-05,
      "loss": 0.0228,
      "step": 24990
    },
    {
      "epoch": 6.83433570256971,
      "grad_norm": 0.026329630985856056,
      "learning_rate": 1.3165664297430291e-05,
      "loss": 0.017,
      "step": 25000
    },
    {
      "epoch": 6.837069436850738,
      "grad_norm": 0.017071940004825592,
      "learning_rate": 1.3162930563149263e-05,
      "loss": 0.0122,
      "step": 25010
    },
    {
      "epoch": 6.839803171131766,
      "grad_norm": 0.04291754215955734,
      "learning_rate": 1.3160196828868235e-05,
      "loss": 0.0003,
      "step": 25020
    },
    {
      "epoch": 6.842536905412794,
      "grad_norm": 0.3740149438381195,
      "learning_rate": 1.3157463094587206e-05,
      "loss": 0.0095,
      "step": 25030
    },
    {
      "epoch": 6.845270639693822,
      "grad_norm": 1.2934091091156006,
      "learning_rate": 1.315472936030618e-05,
      "loss": 0.0193,
      "step": 25040
    },
    {
      "epoch": 6.84800437397485,
      "grad_norm": 0.0066844080574810505,
      "learning_rate": 1.3151995626025151e-05,
      "loss": 0.0025,
      "step": 25050
    },
    {
      "epoch": 6.850738108255878,
      "grad_norm": 0.06157997250556946,
      "learning_rate": 1.3149261891744123e-05,
      "loss": 0.0002,
      "step": 25060
    },
    {
      "epoch": 6.853471842536905,
      "grad_norm": 0.04976237565279007,
      "learning_rate": 1.3146528157463096e-05,
      "loss": 0.0127,
      "step": 25070
    },
    {
      "epoch": 6.856205576817933,
      "grad_norm": 0.0702417716383934,
      "learning_rate": 1.3143794423182068e-05,
      "loss": 0.0351,
      "step": 25080
    },
    {
      "epoch": 6.858939311098961,
      "grad_norm": 0.0027319281361997128,
      "learning_rate": 1.314106068890104e-05,
      "loss": 0.0268,
      "step": 25090
    },
    {
      "epoch": 6.861673045379989,
      "grad_norm": 0.004774957895278931,
      "learning_rate": 1.3138326954620011e-05,
      "loss": 0.0379,
      "step": 25100
    },
    {
      "epoch": 6.864406779661017,
      "grad_norm": 0.010442471131682396,
      "learning_rate": 1.3135593220338985e-05,
      "loss": 0.0044,
      "step": 25110
    },
    {
      "epoch": 6.8671405139420445,
      "grad_norm": 0.03675394132733345,
      "learning_rate": 1.3132859486057956e-05,
      "loss": 0.0112,
      "step": 25120
    },
    {
      "epoch": 6.869874248223073,
      "grad_norm": 5.171331882476807,
      "learning_rate": 1.3130125751776928e-05,
      "loss": 0.0739,
      "step": 25130
    },
    {
      "epoch": 6.872607982504101,
      "grad_norm": 0.024321192875504494,
      "learning_rate": 1.3127392017495901e-05,
      "loss": 0.0298,
      "step": 25140
    },
    {
      "epoch": 6.875341716785129,
      "grad_norm": 0.023605573922395706,
      "learning_rate": 1.3124658283214873e-05,
      "loss": 0.0069,
      "step": 25150
    },
    {
      "epoch": 6.878075451066156,
      "grad_norm": 0.028649166226387024,
      "learning_rate": 1.3121924548933845e-05,
      "loss": 0.0101,
      "step": 25160
    },
    {
      "epoch": 6.880809185347184,
      "grad_norm": 0.0072916429489851,
      "learning_rate": 1.3119190814652816e-05,
      "loss": 0.0003,
      "step": 25170
    },
    {
      "epoch": 6.883542919628212,
      "grad_norm": 0.0035036089830100536,
      "learning_rate": 1.311645708037179e-05,
      "loss": 0.0104,
      "step": 25180
    },
    {
      "epoch": 6.88627665390924,
      "grad_norm": 0.2218049168586731,
      "learning_rate": 1.3113723346090761e-05,
      "loss": 0.0057,
      "step": 25190
    },
    {
      "epoch": 6.889010388190268,
      "grad_norm": 0.004252703860402107,
      "learning_rate": 1.3110989611809733e-05,
      "loss": 0.0039,
      "step": 25200
    },
    {
      "epoch": 6.891744122471295,
      "grad_norm": 0.0033249917905777693,
      "learning_rate": 1.3108255877528706e-05,
      "loss": 0.0118,
      "step": 25210
    },
    {
      "epoch": 6.8944778567523235,
      "grad_norm": 0.06486044079065323,
      "learning_rate": 1.3105522143247678e-05,
      "loss": 0.0325,
      "step": 25220
    },
    {
      "epoch": 6.897211591033352,
      "grad_norm": 0.30891790986061096,
      "learning_rate": 1.310278840896665e-05,
      "loss": 0.016,
      "step": 25230
    },
    {
      "epoch": 6.89994532531438,
      "grad_norm": 0.0038663181476294994,
      "learning_rate": 1.3100054674685621e-05,
      "loss": 0.0385,
      "step": 25240
    },
    {
      "epoch": 6.902679059595407,
      "grad_norm": 0.00710067804902792,
      "learning_rate": 1.3097320940404595e-05,
      "loss": 0.0069,
      "step": 25250
    },
    {
      "epoch": 6.905412793876435,
      "grad_norm": 2.3516716957092285,
      "learning_rate": 1.3094587206123566e-05,
      "loss": 0.0201,
      "step": 25260
    },
    {
      "epoch": 6.908146528157463,
      "grad_norm": 0.2614457607269287,
      "learning_rate": 1.3091853471842538e-05,
      "loss": 0.0234,
      "step": 25270
    },
    {
      "epoch": 6.910880262438491,
      "grad_norm": 0.39235442876815796,
      "learning_rate": 1.3089119737561511e-05,
      "loss": 0.004,
      "step": 25280
    },
    {
      "epoch": 6.913613996719519,
      "grad_norm": 0.04119006171822548,
      "learning_rate": 1.3086386003280483e-05,
      "loss": 0.0136,
      "step": 25290
    },
    {
      "epoch": 6.916347731000547,
      "grad_norm": 0.4190713167190552,
      "learning_rate": 1.3083652268999455e-05,
      "loss": 0.0463,
      "step": 25300
    },
    {
      "epoch": 6.919081465281574,
      "grad_norm": 0.004644588101655245,
      "learning_rate": 1.3080918534718428e-05,
      "loss": 0.0656,
      "step": 25310
    },
    {
      "epoch": 6.9218151995626025,
      "grad_norm": 0.047924596816301346,
      "learning_rate": 1.30781848004374e-05,
      "loss": 0.086,
      "step": 25320
    },
    {
      "epoch": 6.924548933843631,
      "grad_norm": 0.42923927307128906,
      "learning_rate": 1.3075451066156371e-05,
      "loss": 0.01,
      "step": 25330
    },
    {
      "epoch": 6.927282668124659,
      "grad_norm": 0.027801068499684334,
      "learning_rate": 1.3072717331875341e-05,
      "loss": 0.047,
      "step": 25340
    },
    {
      "epoch": 6.930016402405686,
      "grad_norm": 1.270374059677124,
      "learning_rate": 1.3069983597594316e-05,
      "loss": 0.0084,
      "step": 25350
    },
    {
      "epoch": 6.932750136686714,
      "grad_norm": 0.3539668917655945,
      "learning_rate": 1.3067249863313288e-05,
      "loss": 0.011,
      "step": 25360
    },
    {
      "epoch": 6.935483870967742,
      "grad_norm": 0.07274243235588074,
      "learning_rate": 1.3064516129032258e-05,
      "loss": 0.0235,
      "step": 25370
    },
    {
      "epoch": 6.93821760524877,
      "grad_norm": 12.050739288330078,
      "learning_rate": 1.3061782394751233e-05,
      "loss": 0.0326,
      "step": 25380
    },
    {
      "epoch": 6.940951339529798,
      "grad_norm": 0.0035285090561956167,
      "learning_rate": 1.3059048660470203e-05,
      "loss": 0.0176,
      "step": 25390
    },
    {
      "epoch": 6.943685073810825,
      "grad_norm": 0.011218604631721973,
      "learning_rate": 1.3056314926189175e-05,
      "loss": 0.0103,
      "step": 25400
    },
    {
      "epoch": 6.946418808091853,
      "grad_norm": 0.02762189321219921,
      "learning_rate": 1.3053581191908146e-05,
      "loss": 0.0046,
      "step": 25410
    },
    {
      "epoch": 6.9491525423728815,
      "grad_norm": 0.005800590850412846,
      "learning_rate": 1.305084745762712e-05,
      "loss": 0.0002,
      "step": 25420
    },
    {
      "epoch": 6.95188627665391,
      "grad_norm": 0.008109033107757568,
      "learning_rate": 1.3048113723346091e-05,
      "loss": 0.069,
      "step": 25430
    },
    {
      "epoch": 6.954620010934937,
      "grad_norm": 7.720003604888916,
      "learning_rate": 1.3045379989065063e-05,
      "loss": 0.0351,
      "step": 25440
    },
    {
      "epoch": 6.957353745215965,
      "grad_norm": 0.00916107464581728,
      "learning_rate": 1.3042646254784036e-05,
      "loss": 0.0142,
      "step": 25450
    },
    {
      "epoch": 6.960087479496993,
      "grad_norm": 0.01001434400677681,
      "learning_rate": 1.3039912520503008e-05,
      "loss": 0.0224,
      "step": 25460
    },
    {
      "epoch": 6.962821213778021,
      "grad_norm": 0.0031634673941880465,
      "learning_rate": 1.303717878622198e-05,
      "loss": 0.0095,
      "step": 25470
    },
    {
      "epoch": 6.965554948059049,
      "grad_norm": 0.003961492329835892,
      "learning_rate": 1.3034445051940951e-05,
      "loss": 0.0007,
      "step": 25480
    },
    {
      "epoch": 6.968288682340076,
      "grad_norm": 0.0018805627478286624,
      "learning_rate": 1.3031711317659925e-05,
      "loss": 0.0013,
      "step": 25490
    },
    {
      "epoch": 6.971022416621104,
      "grad_norm": 0.004610456991940737,
      "learning_rate": 1.3028977583378896e-05,
      "loss": 0.0461,
      "step": 25500
    },
    {
      "epoch": 6.973756150902132,
      "grad_norm": 0.0021144754718989134,
      "learning_rate": 1.3026243849097868e-05,
      "loss": 0.0012,
      "step": 25510
    },
    {
      "epoch": 6.9764898851831605,
      "grad_norm": 0.002465897938236594,
      "learning_rate": 1.3023510114816841e-05,
      "loss": 0.0013,
      "step": 25520
    },
    {
      "epoch": 6.979223619464188,
      "grad_norm": 0.0025395432021468878,
      "learning_rate": 1.3020776380535813e-05,
      "loss": 0.0051,
      "step": 25530
    },
    {
      "epoch": 6.981957353745216,
      "grad_norm": 6.957839488983154,
      "learning_rate": 1.3018042646254785e-05,
      "loss": 0.0171,
      "step": 25540
    },
    {
      "epoch": 6.984691088026244,
      "grad_norm": 6.693002700805664,
      "learning_rate": 1.3015308911973756e-05,
      "loss": 0.1443,
      "step": 25550
    },
    {
      "epoch": 6.987424822307272,
      "grad_norm": 0.08016263693571091,
      "learning_rate": 1.301257517769273e-05,
      "loss": 0.004,
      "step": 25560
    },
    {
      "epoch": 6.9901585565883,
      "grad_norm": 0.03343077003955841,
      "learning_rate": 1.3009841443411701e-05,
      "loss": 0.0428,
      "step": 25570
    },
    {
      "epoch": 6.992892290869327,
      "grad_norm": 0.04624747484922409,
      "learning_rate": 1.3007107709130673e-05,
      "loss": 0.014,
      "step": 25580
    },
    {
      "epoch": 6.995626025150355,
      "grad_norm": 2.833958387374878,
      "learning_rate": 1.3004373974849646e-05,
      "loss": 0.0117,
      "step": 25590
    },
    {
      "epoch": 6.998359759431383,
      "grad_norm": 0.06905000656843185,
      "learning_rate": 1.3001640240568618e-05,
      "loss": 0.0027,
      "step": 25600
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9915389527458492,
      "eval_f1": 0.9663064208518755,
      "eval_loss": 0.030951596796512604,
      "eval_precision": 0.9595959595959596,
      "eval_recall": 0.9731113956466069,
      "eval_runtime": 796.4646,
      "eval_samples_per_second": 23.622,
      "eval_steps_per_second": 0.984,
      "step": 25606
    },
    {
      "epoch": 7.001093493712411,
      "grad_norm": 2.296751022338867,
      "learning_rate": 1.299890650628759e-05,
      "loss": 0.0106,
      "step": 25610
    },
    {
      "epoch": 7.003827227993439,
      "grad_norm": 0.00466544646769762,
      "learning_rate": 1.2996172772006561e-05,
      "loss": 0.0008,
      "step": 25620
    },
    {
      "epoch": 7.006560962274467,
      "grad_norm": 0.012827951461076736,
      "learning_rate": 1.2993439037725535e-05,
      "loss": 0.0185,
      "step": 25630
    },
    {
      "epoch": 7.009294696555495,
      "grad_norm": 1.007510781288147,
      "learning_rate": 1.2990705303444506e-05,
      "loss": 0.0265,
      "step": 25640
    },
    {
      "epoch": 7.012028430836523,
      "grad_norm": 0.004030733369290829,
      "learning_rate": 1.2987971569163478e-05,
      "loss": 0.0178,
      "step": 25650
    },
    {
      "epoch": 7.014762165117551,
      "grad_norm": 0.008573822677135468,
      "learning_rate": 1.2985237834882451e-05,
      "loss": 0.0321,
      "step": 25660
    },
    {
      "epoch": 7.017495899398578,
      "grad_norm": 5.972553253173828,
      "learning_rate": 1.2982504100601423e-05,
      "loss": 0.0197,
      "step": 25670
    },
    {
      "epoch": 7.020229633679606,
      "grad_norm": 0.02620466984808445,
      "learning_rate": 1.2979770366320395e-05,
      "loss": 0.0357,
      "step": 25680
    },
    {
      "epoch": 7.022963367960634,
      "grad_norm": 0.03949587419629097,
      "learning_rate": 1.2977036632039366e-05,
      "loss": 0.001,
      "step": 25690
    },
    {
      "epoch": 7.025697102241662,
      "grad_norm": 2.802659511566162,
      "learning_rate": 1.297430289775834e-05,
      "loss": 0.0588,
      "step": 25700
    },
    {
      "epoch": 7.02843083652269,
      "grad_norm": 0.039498090744018555,
      "learning_rate": 1.2971569163477311e-05,
      "loss": 0.0044,
      "step": 25710
    },
    {
      "epoch": 7.031164570803718,
      "grad_norm": 0.010398571379482746,
      "learning_rate": 1.2968835429196283e-05,
      "loss": 0.0072,
      "step": 25720
    },
    {
      "epoch": 7.033898305084746,
      "grad_norm": 0.0037287718150764704,
      "learning_rate": 1.2966101694915256e-05,
      "loss": 0.0034,
      "step": 25730
    },
    {
      "epoch": 7.036632039365774,
      "grad_norm": 0.05165370553731918,
      "learning_rate": 1.2963367960634228e-05,
      "loss": 0.0003,
      "step": 25740
    },
    {
      "epoch": 7.039365773646802,
      "grad_norm": 0.0011167218908667564,
      "learning_rate": 1.29606342263532e-05,
      "loss": 0.002,
      "step": 25750
    },
    {
      "epoch": 7.042099507927829,
      "grad_norm": 0.055731821805238724,
      "learning_rate": 1.2957900492072171e-05,
      "loss": 0.0353,
      "step": 25760
    },
    {
      "epoch": 7.044833242208857,
      "grad_norm": 0.3799937665462494,
      "learning_rate": 1.2955166757791145e-05,
      "loss": 0.0006,
      "step": 25770
    },
    {
      "epoch": 7.047566976489885,
      "grad_norm": 3.5921711921691895,
      "learning_rate": 1.2952433023510116e-05,
      "loss": 0.0134,
      "step": 25780
    },
    {
      "epoch": 7.050300710770913,
      "grad_norm": 0.0030761370435357094,
      "learning_rate": 1.2949699289229088e-05,
      "loss": 0.0003,
      "step": 25790
    },
    {
      "epoch": 7.053034445051941,
      "grad_norm": 0.03667176142334938,
      "learning_rate": 1.2946965554948061e-05,
      "loss": 0.0035,
      "step": 25800
    },
    {
      "epoch": 7.0557681793329685,
      "grad_norm": 1.9611402750015259,
      "learning_rate": 1.2944231820667033e-05,
      "loss": 0.0048,
      "step": 25810
    },
    {
      "epoch": 7.058501913613997,
      "grad_norm": 0.005431979428976774,
      "learning_rate": 1.2941498086386004e-05,
      "loss": 0.0003,
      "step": 25820
    },
    {
      "epoch": 7.061235647895025,
      "grad_norm": 1.7535127401351929,
      "learning_rate": 1.2938764352104976e-05,
      "loss": 0.0236,
      "step": 25830
    },
    {
      "epoch": 7.063969382176053,
      "grad_norm": 0.009932554326951504,
      "learning_rate": 1.293603061782395e-05,
      "loss": 0.0155,
      "step": 25840
    },
    {
      "epoch": 7.06670311645708,
      "grad_norm": 0.0039051007479429245,
      "learning_rate": 1.2933296883542921e-05,
      "loss": 0.0086,
      "step": 25850
    },
    {
      "epoch": 7.069436850738108,
      "grad_norm": 0.0035684669855982065,
      "learning_rate": 1.2930563149261893e-05,
      "loss": 0.0018,
      "step": 25860
    },
    {
      "epoch": 7.072170585019136,
      "grad_norm": 0.003436184488236904,
      "learning_rate": 1.2927829414980866e-05,
      "loss": 0.0009,
      "step": 25870
    },
    {
      "epoch": 7.074904319300164,
      "grad_norm": 0.002129467437043786,
      "learning_rate": 1.2925095680699838e-05,
      "loss": 0.0002,
      "step": 25880
    },
    {
      "epoch": 7.077638053581192,
      "grad_norm": 0.0014997946564108133,
      "learning_rate": 1.292236194641881e-05,
      "loss": 0.0001,
      "step": 25890
    },
    {
      "epoch": 7.080371787862219,
      "grad_norm": 0.002098489087074995,
      "learning_rate": 1.2919628212137781e-05,
      "loss": 0.0001,
      "step": 25900
    },
    {
      "epoch": 7.0831055221432475,
      "grad_norm": 3.390470504760742,
      "learning_rate": 1.2916894477856754e-05,
      "loss": 0.0244,
      "step": 25910
    },
    {
      "epoch": 7.085839256424276,
      "grad_norm": 0.003666900796815753,
      "learning_rate": 1.2914160743575726e-05,
      "loss": 0.0097,
      "step": 25920
    },
    {
      "epoch": 7.088572990705304,
      "grad_norm": 0.0022509200498461723,
      "learning_rate": 1.2911427009294698e-05,
      "loss": 0.0395,
      "step": 25930
    },
    {
      "epoch": 7.091306724986332,
      "grad_norm": 0.008972539566457272,
      "learning_rate": 1.2908693275013671e-05,
      "loss": 0.0055,
      "step": 25940
    },
    {
      "epoch": 7.094040459267359,
      "grad_norm": 0.004766023252159357,
      "learning_rate": 1.2905959540732643e-05,
      "loss": 0.0139,
      "step": 25950
    },
    {
      "epoch": 7.096774193548387,
      "grad_norm": 3.4818363189697266,
      "learning_rate": 1.2903225806451613e-05,
      "loss": 0.0375,
      "step": 25960
    },
    {
      "epoch": 7.099507927829415,
      "grad_norm": 7.630241870880127,
      "learning_rate": 1.2900492072170584e-05,
      "loss": 0.0402,
      "step": 25970
    },
    {
      "epoch": 7.102241662110443,
      "grad_norm": 0.19981494545936584,
      "learning_rate": 1.289775833788956e-05,
      "loss": 0.0013,
      "step": 25980
    },
    {
      "epoch": 7.10497539639147,
      "grad_norm": 0.023468734696507454,
      "learning_rate": 1.289502460360853e-05,
      "loss": 0.0192,
      "step": 25990
    },
    {
      "epoch": 7.107709130672498,
      "grad_norm": 0.6543045043945312,
      "learning_rate": 1.2892290869327501e-05,
      "loss": 0.003,
      "step": 26000
    },
    {
      "epoch": 7.1104428649535265,
      "grad_norm": 0.00777586130425334,
      "learning_rate": 1.2889557135046476e-05,
      "loss": 0.0179,
      "step": 26010
    },
    {
      "epoch": 7.113176599234555,
      "grad_norm": 0.004765354096889496,
      "learning_rate": 1.2886823400765446e-05,
      "loss": 0.0295,
      "step": 26020
    },
    {
      "epoch": 7.115910333515583,
      "grad_norm": 0.8440664410591125,
      "learning_rate": 1.2884089666484418e-05,
      "loss": 0.0075,
      "step": 26030
    },
    {
      "epoch": 7.11864406779661,
      "grad_norm": 0.002105297287926078,
      "learning_rate": 1.288135593220339e-05,
      "loss": 0.0184,
      "step": 26040
    },
    {
      "epoch": 7.121377802077638,
      "grad_norm": 0.04806669056415558,
      "learning_rate": 1.2878622197922363e-05,
      "loss": 0.0015,
      "step": 26050
    },
    {
      "epoch": 7.124111536358666,
      "grad_norm": 0.008317927829921246,
      "learning_rate": 1.2875888463641334e-05,
      "loss": 0.0012,
      "step": 26060
    },
    {
      "epoch": 7.126845270639694,
      "grad_norm": 0.0017921925755217671,
      "learning_rate": 1.2873154729360306e-05,
      "loss": 0.0001,
      "step": 26070
    },
    {
      "epoch": 7.129579004920721,
      "grad_norm": 2.515303134918213,
      "learning_rate": 1.287042099507928e-05,
      "loss": 0.0334,
      "step": 26080
    },
    {
      "epoch": 7.132312739201749,
      "grad_norm": 1.3540499210357666,
      "learning_rate": 1.2867687260798251e-05,
      "loss": 0.0031,
      "step": 26090
    },
    {
      "epoch": 7.135046473482777,
      "grad_norm": 1.4595627784729004,
      "learning_rate": 1.2864953526517223e-05,
      "loss": 0.0323,
      "step": 26100
    },
    {
      "epoch": 7.1377802077638055,
      "grad_norm": 0.0028534792363643646,
      "learning_rate": 1.2862219792236194e-05,
      "loss": 0.0179,
      "step": 26110
    },
    {
      "epoch": 7.140513942044834,
      "grad_norm": 0.004825599491596222,
      "learning_rate": 1.2859486057955168e-05,
      "loss": 0.0054,
      "step": 26120
    },
    {
      "epoch": 7.143247676325861,
      "grad_norm": 0.0013940982753410935,
      "learning_rate": 1.285675232367414e-05,
      "loss": 0.0032,
      "step": 26130
    },
    {
      "epoch": 7.145981410606889,
      "grad_norm": 0.0028595211915671825,
      "learning_rate": 1.2854018589393111e-05,
      "loss": 0.0073,
      "step": 26140
    },
    {
      "epoch": 7.148715144887917,
      "grad_norm": 0.23040607571601868,
      "learning_rate": 1.2851284855112084e-05,
      "loss": 0.0024,
      "step": 26150
    },
    {
      "epoch": 7.151448879168945,
      "grad_norm": 0.0009817249374464154,
      "learning_rate": 1.2848551120831056e-05,
      "loss": 0.0064,
      "step": 26160
    },
    {
      "epoch": 7.154182613449973,
      "grad_norm": 0.0009848530171439052,
      "learning_rate": 1.2845817386550028e-05,
      "loss": 0.0062,
      "step": 26170
    },
    {
      "epoch": 7.156916347731,
      "grad_norm": 0.0007718920242041349,
      "learning_rate": 1.2843083652269e-05,
      "loss": 0.0013,
      "step": 26180
    },
    {
      "epoch": 7.159650082012028,
      "grad_norm": 4.309924125671387,
      "learning_rate": 1.2840349917987973e-05,
      "loss": 0.045,
      "step": 26190
    },
    {
      "epoch": 7.162383816293056,
      "grad_norm": 0.0017309277318418026,
      "learning_rate": 1.2837616183706944e-05,
      "loss": 0.0298,
      "step": 26200
    },
    {
      "epoch": 7.1651175505740845,
      "grad_norm": 2.0334601402282715,
      "learning_rate": 1.2834882449425916e-05,
      "loss": 0.0077,
      "step": 26210
    },
    {
      "epoch": 7.167851284855112,
      "grad_norm": 17.040374755859375,
      "learning_rate": 1.283214871514489e-05,
      "loss": 0.0087,
      "step": 26220
    },
    {
      "epoch": 7.17058501913614,
      "grad_norm": 0.001612435793504119,
      "learning_rate": 1.2829414980863861e-05,
      "loss": 0.0324,
      "step": 26230
    },
    {
      "epoch": 7.173318753417168,
      "grad_norm": 23.764135360717773,
      "learning_rate": 1.2826681246582833e-05,
      "loss": 0.0316,
      "step": 26240
    },
    {
      "epoch": 7.176052487698196,
      "grad_norm": 0.0044097620993852615,
      "learning_rate": 1.2823947512301804e-05,
      "loss": 0.0382,
      "step": 26250
    },
    {
      "epoch": 7.178786221979224,
      "grad_norm": 0.8373686671257019,
      "learning_rate": 1.2821213778020778e-05,
      "loss": 0.0022,
      "step": 26260
    },
    {
      "epoch": 7.181519956260251,
      "grad_norm": 0.0014293128624558449,
      "learning_rate": 1.281848004373975e-05,
      "loss": 0.003,
      "step": 26270
    },
    {
      "epoch": 7.184253690541279,
      "grad_norm": 0.0008535781526006758,
      "learning_rate": 1.2815746309458721e-05,
      "loss": 0.0004,
      "step": 26280
    },
    {
      "epoch": 7.186987424822307,
      "grad_norm": 0.8297879695892334,
      "learning_rate": 1.2813012575177694e-05,
      "loss": 0.005,
      "step": 26290
    },
    {
      "epoch": 7.189721159103335,
      "grad_norm": 17.46888542175293,
      "learning_rate": 1.2810278840896666e-05,
      "loss": 0.0592,
      "step": 26300
    },
    {
      "epoch": 7.192454893384363,
      "grad_norm": 1.4502763748168945,
      "learning_rate": 1.2807545106615638e-05,
      "loss": 0.01,
      "step": 26310
    },
    {
      "epoch": 7.195188627665391,
      "grad_norm": 0.05256172642111778,
      "learning_rate": 1.280481137233461e-05,
      "loss": 0.0076,
      "step": 26320
    },
    {
      "epoch": 7.197922361946419,
      "grad_norm": 0.9003481864929199,
      "learning_rate": 1.2802077638053583e-05,
      "loss": 0.0413,
      "step": 26330
    },
    {
      "epoch": 7.200656096227447,
      "grad_norm": 0.0006543138297274709,
      "learning_rate": 1.2799343903772554e-05,
      "loss": 0.0025,
      "step": 26340
    },
    {
      "epoch": 7.203389830508475,
      "grad_norm": 0.008500437252223492,
      "learning_rate": 1.2796610169491526e-05,
      "loss": 0.0074,
      "step": 26350
    },
    {
      "epoch": 7.206123564789502,
      "grad_norm": 0.0008615113911218941,
      "learning_rate": 1.27938764352105e-05,
      "loss": 0.0062,
      "step": 26360
    },
    {
      "epoch": 7.20885729907053,
      "grad_norm": 0.18347187340259552,
      "learning_rate": 1.2791142700929471e-05,
      "loss": 0.023,
      "step": 26370
    },
    {
      "epoch": 7.211591033351558,
      "grad_norm": 0.004244484473019838,
      "learning_rate": 1.2788408966648443e-05,
      "loss": 0.0001,
      "step": 26380
    },
    {
      "epoch": 7.214324767632586,
      "grad_norm": 0.005204054061323404,
      "learning_rate": 1.2785675232367416e-05,
      "loss": 0.0253,
      "step": 26390
    },
    {
      "epoch": 7.217058501913614,
      "grad_norm": 0.021711435168981552,
      "learning_rate": 1.2782941498086388e-05,
      "loss": 0.008,
      "step": 26400
    },
    {
      "epoch": 7.219792236194642,
      "grad_norm": 0.0010046438546851277,
      "learning_rate": 1.278020776380536e-05,
      "loss": 0.0046,
      "step": 26410
    },
    {
      "epoch": 7.22252597047567,
      "grad_norm": 0.002095259027555585,
      "learning_rate": 1.2777474029524331e-05,
      "loss": 0.0217,
      "step": 26420
    },
    {
      "epoch": 7.225259704756698,
      "grad_norm": 14.803008079528809,
      "learning_rate": 1.2774740295243304e-05,
      "loss": 0.0647,
      "step": 26430
    },
    {
      "epoch": 7.227993439037726,
      "grad_norm": 0.018709249794483185,
      "learning_rate": 1.2772006560962276e-05,
      "loss": 0.0216,
      "step": 26440
    },
    {
      "epoch": 7.230727173318753,
      "grad_norm": 0.9375651478767395,
      "learning_rate": 1.2769272826681248e-05,
      "loss": 0.021,
      "step": 26450
    },
    {
      "epoch": 7.233460907599781,
      "grad_norm": 0.0025950269773602486,
      "learning_rate": 1.2766539092400221e-05,
      "loss": 0.0058,
      "step": 26460
    },
    {
      "epoch": 7.236194641880809,
      "grad_norm": 0.12123765796422958,
      "learning_rate": 1.2763805358119193e-05,
      "loss": 0.005,
      "step": 26470
    },
    {
      "epoch": 7.238928376161837,
      "grad_norm": 0.0009287088178098202,
      "learning_rate": 1.2761071623838164e-05,
      "loss": 0.0117,
      "step": 26480
    },
    {
      "epoch": 7.241662110442865,
      "grad_norm": 0.001053579617291689,
      "learning_rate": 1.2758337889557136e-05,
      "loss": 0.0018,
      "step": 26490
    },
    {
      "epoch": 7.2443958447238925,
      "grad_norm": 0.00439419923350215,
      "learning_rate": 1.275560415527611e-05,
      "loss": 0.0059,
      "step": 26500
    },
    {
      "epoch": 7.247129579004921,
      "grad_norm": 0.0010990746086463332,
      "learning_rate": 1.2752870420995081e-05,
      "loss": 0.0,
      "step": 26510
    },
    {
      "epoch": 7.249863313285949,
      "grad_norm": 0.7426118850708008,
      "learning_rate": 1.2750136686714053e-05,
      "loss": 0.0028,
      "step": 26520
    },
    {
      "epoch": 7.252597047566977,
      "grad_norm": 0.0012047461932525039,
      "learning_rate": 1.2747402952433026e-05,
      "loss": 0.0446,
      "step": 26530
    },
    {
      "epoch": 7.255330781848004,
      "grad_norm": 0.0031849490478634834,
      "learning_rate": 1.2744669218151998e-05,
      "loss": 0.0244,
      "step": 26540
    },
    {
      "epoch": 7.258064516129032,
      "grad_norm": 0.002354599768295884,
      "learning_rate": 1.274193548387097e-05,
      "loss": 0.0088,
      "step": 26550
    },
    {
      "epoch": 7.26079825041006,
      "grad_norm": 0.0033243978396058083,
      "learning_rate": 1.273920174958994e-05,
      "loss": 0.0225,
      "step": 26560
    },
    {
      "epoch": 7.263531984691088,
      "grad_norm": 0.012708349153399467,
      "learning_rate": 1.2736468015308914e-05,
      "loss": 0.0001,
      "step": 26570
    },
    {
      "epoch": 7.266265718972116,
      "grad_norm": 0.0011881099781021476,
      "learning_rate": 1.2733734281027886e-05,
      "loss": 0.0433,
      "step": 26580
    },
    {
      "epoch": 7.2689994532531435,
      "grad_norm": 0.01682848297059536,
      "learning_rate": 1.2731000546746856e-05,
      "loss": 0.0018,
      "step": 26590
    },
    {
      "epoch": 7.2717331875341715,
      "grad_norm": 0.035703144967556,
      "learning_rate": 1.2728266812465831e-05,
      "loss": 0.0001,
      "step": 26600
    },
    {
      "epoch": 7.2744669218152,
      "grad_norm": 0.06255790591239929,
      "learning_rate": 1.2725533078184803e-05,
      "loss": 0.0194,
      "step": 26610
    },
    {
      "epoch": 7.277200656096228,
      "grad_norm": 0.0021534764673560858,
      "learning_rate": 1.2722799343903773e-05,
      "loss": 0.0526,
      "step": 26620
    },
    {
      "epoch": 7.279934390377255,
      "grad_norm": 0.00491304649040103,
      "learning_rate": 1.2720065609622744e-05,
      "loss": 0.0353,
      "step": 26630
    },
    {
      "epoch": 7.282668124658283,
      "grad_norm": 0.004472046159207821,
      "learning_rate": 1.271733187534172e-05,
      "loss": 0.0007,
      "step": 26640
    },
    {
      "epoch": 7.285401858939311,
      "grad_norm": 0.09701153635978699,
      "learning_rate": 1.271459814106069e-05,
      "loss": 0.0062,
      "step": 26650
    },
    {
      "epoch": 7.288135593220339,
      "grad_norm": 2.0269646644592285,
      "learning_rate": 1.2711864406779661e-05,
      "loss": 0.0134,
      "step": 26660
    },
    {
      "epoch": 7.290869327501367,
      "grad_norm": 0.0022645555436611176,
      "learning_rate": 1.2709130672498636e-05,
      "loss": 0.0165,
      "step": 26670
    },
    {
      "epoch": 7.293603061782394,
      "grad_norm": 0.01767255924642086,
      "learning_rate": 1.2706396938217606e-05,
      "loss": 0.013,
      "step": 26680
    },
    {
      "epoch": 7.2963367960634224,
      "grad_norm": 2.7531442642211914,
      "learning_rate": 1.2703663203936578e-05,
      "loss": 0.01,
      "step": 26690
    },
    {
      "epoch": 7.2990705303444505,
      "grad_norm": 0.0064925821498036385,
      "learning_rate": 1.270092946965555e-05,
      "loss": 0.0463,
      "step": 26700
    },
    {
      "epoch": 7.301804264625479,
      "grad_norm": 0.026755888015031815,
      "learning_rate": 1.2698195735374523e-05,
      "loss": 0.0106,
      "step": 26710
    },
    {
      "epoch": 7.304537998906507,
      "grad_norm": 0.04134700447320938,
      "learning_rate": 1.2695462001093494e-05,
      "loss": 0.0077,
      "step": 26720
    },
    {
      "epoch": 7.307271733187534,
      "grad_norm": 0.0013699475675821304,
      "learning_rate": 1.2692728266812466e-05,
      "loss": 0.0204,
      "step": 26730
    },
    {
      "epoch": 7.310005467468562,
      "grad_norm": 0.002355655888095498,
      "learning_rate": 1.268999453253144e-05,
      "loss": 0.0049,
      "step": 26740
    },
    {
      "epoch": 7.31273920174959,
      "grad_norm": 0.0007639118121005595,
      "learning_rate": 1.268726079825041e-05,
      "loss": 0.0192,
      "step": 26750
    },
    {
      "epoch": 7.315472936030618,
      "grad_norm": 0.001151521340943873,
      "learning_rate": 1.2684527063969382e-05,
      "loss": 0.0041,
      "step": 26760
    },
    {
      "epoch": 7.318206670311646,
      "grad_norm": 1.335923433303833,
      "learning_rate": 1.2681793329688354e-05,
      "loss": 0.0073,
      "step": 26770
    },
    {
      "epoch": 7.320940404592673,
      "grad_norm": 1.0366848707199097,
      "learning_rate": 1.2679059595407327e-05,
      "loss": 0.0076,
      "step": 26780
    },
    {
      "epoch": 7.3236741388737014,
      "grad_norm": 0.7247969508171082,
      "learning_rate": 1.2676325861126299e-05,
      "loss": 0.0018,
      "step": 26790
    },
    {
      "epoch": 7.3264078731547295,
      "grad_norm": 1.5712352991104126,
      "learning_rate": 1.267359212684527e-05,
      "loss": 0.0095,
      "step": 26800
    },
    {
      "epoch": 7.329141607435758,
      "grad_norm": 0.0009718299843370914,
      "learning_rate": 1.2670858392564244e-05,
      "loss": 0.0,
      "step": 26810
    },
    {
      "epoch": 7.331875341716785,
      "grad_norm": 0.0011719921603798866,
      "learning_rate": 1.2668124658283216e-05,
      "loss": 0.0225,
      "step": 26820
    },
    {
      "epoch": 7.334609075997813,
      "grad_norm": 0.0008293885039165616,
      "learning_rate": 1.2665390924002187e-05,
      "loss": 0.0,
      "step": 26830
    },
    {
      "epoch": 7.337342810278841,
      "grad_norm": 0.21121877431869507,
      "learning_rate": 1.2662657189721159e-05,
      "loss": 0.0053,
      "step": 26840
    },
    {
      "epoch": 7.340076544559869,
      "grad_norm": 0.0011043499689549208,
      "learning_rate": 1.2659923455440132e-05,
      "loss": 0.0099,
      "step": 26850
    },
    {
      "epoch": 7.342810278840897,
      "grad_norm": 9.116312980651855,
      "learning_rate": 1.2657189721159104e-05,
      "loss": 0.0036,
      "step": 26860
    },
    {
      "epoch": 7.345544013121924,
      "grad_norm": 0.0159438606351614,
      "learning_rate": 1.2654455986878076e-05,
      "loss": 0.0104,
      "step": 26870
    },
    {
      "epoch": 7.348277747402952,
      "grad_norm": 1.3777236938476562,
      "learning_rate": 1.2651722252597049e-05,
      "loss": 0.0037,
      "step": 26880
    },
    {
      "epoch": 7.35101148168398,
      "grad_norm": 2.4420673847198486,
      "learning_rate": 1.264898851831602e-05,
      "loss": 0.0061,
      "step": 26890
    },
    {
      "epoch": 7.3537452159650085,
      "grad_norm": 0.21255555748939514,
      "learning_rate": 1.2646254784034992e-05,
      "loss": 0.0133,
      "step": 26900
    },
    {
      "epoch": 7.356478950246036,
      "grad_norm": 0.0012322468683123589,
      "learning_rate": 1.2643521049753964e-05,
      "loss": 0.0136,
      "step": 26910
    },
    {
      "epoch": 7.359212684527064,
      "grad_norm": 1.5879424810409546,
      "learning_rate": 1.2640787315472937e-05,
      "loss": 0.0173,
      "step": 26920
    },
    {
      "epoch": 7.361946418808092,
      "grad_norm": 1.703926920890808,
      "learning_rate": 1.2638053581191909e-05,
      "loss": 0.0193,
      "step": 26930
    },
    {
      "epoch": 7.36468015308912,
      "grad_norm": 0.0011019575176760554,
      "learning_rate": 1.263531984691088e-05,
      "loss": 0.0338,
      "step": 26940
    },
    {
      "epoch": 7.367413887370148,
      "grad_norm": 0.008069700561463833,
      "learning_rate": 1.2632586112629854e-05,
      "loss": 0.0212,
      "step": 26950
    },
    {
      "epoch": 7.370147621651175,
      "grad_norm": 1.2757036685943604,
      "learning_rate": 1.2629852378348826e-05,
      "loss": 0.006,
      "step": 26960
    },
    {
      "epoch": 7.372881355932203,
      "grad_norm": 0.006820549722760916,
      "learning_rate": 1.2627118644067797e-05,
      "loss": 0.0257,
      "step": 26970
    },
    {
      "epoch": 7.375615090213231,
      "grad_norm": 0.003507538465783,
      "learning_rate": 1.2624384909786769e-05,
      "loss": 0.0347,
      "step": 26980
    },
    {
      "epoch": 7.378348824494259,
      "grad_norm": 0.008471791632473469,
      "learning_rate": 1.2621651175505742e-05,
      "loss": 0.0215,
      "step": 26990
    },
    {
      "epoch": 7.381082558775287,
      "grad_norm": 0.08902160078287125,
      "learning_rate": 1.2618917441224714e-05,
      "loss": 0.0346,
      "step": 27000
    },
    {
      "epoch": 7.383816293056315,
      "grad_norm": 0.018059367313981056,
      "learning_rate": 1.2616183706943686e-05,
      "loss": 0.0205,
      "step": 27010
    },
    {
      "epoch": 7.386550027337343,
      "grad_norm": 0.013882777653634548,
      "learning_rate": 1.2613449972662659e-05,
      "loss": 0.0003,
      "step": 27020
    },
    {
      "epoch": 7.389283761618371,
      "grad_norm": 0.01147758960723877,
      "learning_rate": 1.261071623838163e-05,
      "loss": 0.017,
      "step": 27030
    },
    {
      "epoch": 7.392017495899399,
      "grad_norm": 0.001939424080774188,
      "learning_rate": 1.2607982504100602e-05,
      "loss": 0.008,
      "step": 27040
    },
    {
      "epoch": 7.394751230180426,
      "grad_norm": 0.0032991268672049046,
      "learning_rate": 1.2605248769819574e-05,
      "loss": 0.0045,
      "step": 27050
    },
    {
      "epoch": 7.397484964461454,
      "grad_norm": 0.010574933141469955,
      "learning_rate": 1.2602515035538547e-05,
      "loss": 0.0005,
      "step": 27060
    },
    {
      "epoch": 7.400218698742482,
      "grad_norm": 0.002107250737026334,
      "learning_rate": 1.2599781301257519e-05,
      "loss": 0.0379,
      "step": 27070
    },
    {
      "epoch": 7.40295243302351,
      "grad_norm": 0.201956108212471,
      "learning_rate": 1.259704756697649e-05,
      "loss": 0.0412,
      "step": 27080
    },
    {
      "epoch": 7.4056861673045375,
      "grad_norm": 3.868788003921509,
      "learning_rate": 1.2594313832695464e-05,
      "loss": 0.0124,
      "step": 27090
    },
    {
      "epoch": 7.408419901585566,
      "grad_norm": 0.04977726936340332,
      "learning_rate": 1.2591580098414436e-05,
      "loss": 0.0076,
      "step": 27100
    },
    {
      "epoch": 7.411153635866594,
      "grad_norm": 0.003666606731712818,
      "learning_rate": 1.2588846364133407e-05,
      "loss": 0.0032,
      "step": 27110
    },
    {
      "epoch": 7.413887370147622,
      "grad_norm": 0.0018957436550408602,
      "learning_rate": 1.2586112629852379e-05,
      "loss": 0.0003,
      "step": 27120
    },
    {
      "epoch": 7.41662110442865,
      "grad_norm": 0.01308100763708353,
      "learning_rate": 1.2583378895571352e-05,
      "loss": 0.0224,
      "step": 27130
    },
    {
      "epoch": 7.419354838709677,
      "grad_norm": 0.1400936394929886,
      "learning_rate": 1.2580645161290324e-05,
      "loss": 0.0011,
      "step": 27140
    },
    {
      "epoch": 7.422088572990705,
      "grad_norm": 0.129015251994133,
      "learning_rate": 1.2577911427009296e-05,
      "loss": 0.0044,
      "step": 27150
    },
    {
      "epoch": 7.424822307271733,
      "grad_norm": 0.009322261437773705,
      "learning_rate": 1.2575177692728269e-05,
      "loss": 0.0251,
      "step": 27160
    },
    {
      "epoch": 7.427556041552761,
      "grad_norm": 0.004689842462539673,
      "learning_rate": 1.257244395844724e-05,
      "loss": 0.0233,
      "step": 27170
    },
    {
      "epoch": 7.430289775833789,
      "grad_norm": 0.0015911322552710772,
      "learning_rate": 1.2569710224166212e-05,
      "loss": 0.0145,
      "step": 27180
    },
    {
      "epoch": 7.4330235101148165,
      "grad_norm": 0.014057689346373081,
      "learning_rate": 1.2566976489885182e-05,
      "loss": 0.0036,
      "step": 27190
    },
    {
      "epoch": 7.435757244395845,
      "grad_norm": 0.3419139087200165,
      "learning_rate": 1.2564242755604157e-05,
      "loss": 0.0091,
      "step": 27200
    },
    {
      "epoch": 7.438490978676873,
      "grad_norm": 0.006355081219226122,
      "learning_rate": 1.2561509021323129e-05,
      "loss": 0.0053,
      "step": 27210
    },
    {
      "epoch": 7.441224712957901,
      "grad_norm": 0.032586563378572464,
      "learning_rate": 1.2558775287042099e-05,
      "loss": 0.0083,
      "step": 27220
    },
    {
      "epoch": 7.443958447238928,
      "grad_norm": 0.0016404743073508143,
      "learning_rate": 1.2556041552761074e-05,
      "loss": 0.0161,
      "step": 27230
    },
    {
      "epoch": 7.446692181519956,
      "grad_norm": 0.08415953814983368,
      "learning_rate": 1.2553307818480046e-05,
      "loss": 0.0239,
      "step": 27240
    },
    {
      "epoch": 7.449425915800984,
      "grad_norm": 0.0017073791241273284,
      "learning_rate": 1.2550574084199016e-05,
      "loss": 0.0136,
      "step": 27250
    },
    {
      "epoch": 7.452159650082012,
      "grad_norm": 0.05686085298657417,
      "learning_rate": 1.2547840349917987e-05,
      "loss": 0.0014,
      "step": 27260
    },
    {
      "epoch": 7.45489338436304,
      "grad_norm": 0.0018650166457518935,
      "learning_rate": 1.2545106615636962e-05,
      "loss": 0.0048,
      "step": 27270
    },
    {
      "epoch": 7.4576271186440675,
      "grad_norm": 0.014623104594647884,
      "learning_rate": 1.2542372881355932e-05,
      "loss": 0.0004,
      "step": 27280
    },
    {
      "epoch": 7.4603608529250955,
      "grad_norm": 0.007339592091739178,
      "learning_rate": 1.2539639147074904e-05,
      "loss": 0.0001,
      "step": 27290
    },
    {
      "epoch": 7.463094587206124,
      "grad_norm": 0.012131358496844769,
      "learning_rate": 1.2536905412793879e-05,
      "loss": 0.0055,
      "step": 27300
    },
    {
      "epoch": 7.465828321487152,
      "grad_norm": 0.001542825368233025,
      "learning_rate": 1.2534171678512849e-05,
      "loss": 0.0006,
      "step": 27310
    },
    {
      "epoch": 7.46856205576818,
      "grad_norm": 0.0024531972594559193,
      "learning_rate": 1.253143794423182e-05,
      "loss": 0.03,
      "step": 27320
    },
    {
      "epoch": 7.471295790049207,
      "grad_norm": 0.0011002045357599854,
      "learning_rate": 1.2528704209950792e-05,
      "loss": 0.0001,
      "step": 27330
    },
    {
      "epoch": 7.474029524330235,
      "grad_norm": 1.18204665184021,
      "learning_rate": 1.2525970475669766e-05,
      "loss": 0.0323,
      "step": 27340
    },
    {
      "epoch": 7.476763258611263,
      "grad_norm": 2.0343616008758545,
      "learning_rate": 1.2523236741388737e-05,
      "loss": 0.0369,
      "step": 27350
    },
    {
      "epoch": 7.479496992892291,
      "grad_norm": 0.056616127490997314,
      "learning_rate": 1.2520503007107709e-05,
      "loss": 0.0062,
      "step": 27360
    },
    {
      "epoch": 7.482230727173318,
      "grad_norm": 0.3087862730026245,
      "learning_rate": 1.2517769272826682e-05,
      "loss": 0.0013,
      "step": 27370
    },
    {
      "epoch": 7.4849644614543465,
      "grad_norm": 0.016084939241409302,
      "learning_rate": 1.2515035538545654e-05,
      "loss": 0.0009,
      "step": 27380
    },
    {
      "epoch": 7.4876981957353745,
      "grad_norm": 6.037439346313477,
      "learning_rate": 1.2512301804264626e-05,
      "loss": 0.0493,
      "step": 27390
    },
    {
      "epoch": 7.490431930016403,
      "grad_norm": 0.08503434807062149,
      "learning_rate": 1.2509568069983597e-05,
      "loss": 0.0174,
      "step": 27400
    },
    {
      "epoch": 7.493165664297431,
      "grad_norm": 0.02070378139615059,
      "learning_rate": 1.250683433570257e-05,
      "loss": 0.0016,
      "step": 27410
    },
    {
      "epoch": 7.495899398578458,
      "grad_norm": 0.0027611935511231422,
      "learning_rate": 1.2504100601421542e-05,
      "loss": 0.0049,
      "step": 27420
    },
    {
      "epoch": 7.498633132859486,
      "grad_norm": 0.3648225665092468,
      "learning_rate": 1.2501366867140514e-05,
      "loss": 0.0047,
      "step": 27430
    },
    {
      "epoch": 7.501366867140514,
      "grad_norm": 0.012620399706065655,
      "learning_rate": 1.2498633132859487e-05,
      "loss": 0.002,
      "step": 27440
    },
    {
      "epoch": 7.504100601421542,
      "grad_norm": 0.0017926321597769856,
      "learning_rate": 1.2495899398578459e-05,
      "loss": 0.0239,
      "step": 27450
    },
    {
      "epoch": 7.506834335702569,
      "grad_norm": 0.07502425462007523,
      "learning_rate": 1.249316566429743e-05,
      "loss": 0.0119,
      "step": 27460
    },
    {
      "epoch": 7.509568069983597,
      "grad_norm": 0.0019863019697368145,
      "learning_rate": 1.2490431930016404e-05,
      "loss": 0.0067,
      "step": 27470
    },
    {
      "epoch": 7.5123018042646255,
      "grad_norm": 0.0015872030053287745,
      "learning_rate": 1.2487698195735376e-05,
      "loss": 0.0367,
      "step": 27480
    },
    {
      "epoch": 7.5150355385456535,
      "grad_norm": 0.0028989664278924465,
      "learning_rate": 1.2484964461454347e-05,
      "loss": 0.0088,
      "step": 27490
    },
    {
      "epoch": 7.517769272826682,
      "grad_norm": 2.0015790462493896,
      "learning_rate": 1.2482230727173319e-05,
      "loss": 0.0094,
      "step": 27500
    },
    {
      "epoch": 7.520503007107709,
      "grad_norm": 0.009792598895728588,
      "learning_rate": 1.2479496992892292e-05,
      "loss": 0.0012,
      "step": 27510
    },
    {
      "epoch": 7.523236741388737,
      "grad_norm": 0.005967210978269577,
      "learning_rate": 1.2476763258611264e-05,
      "loss": 0.0186,
      "step": 27520
    },
    {
      "epoch": 7.525970475669765,
      "grad_norm": 0.022071361541748047,
      "learning_rate": 1.2474029524330236e-05,
      "loss": 0.0008,
      "step": 27530
    },
    {
      "epoch": 7.528704209950793,
      "grad_norm": 0.03409615159034729,
      "learning_rate": 1.2471295790049209e-05,
      "loss": 0.0047,
      "step": 27540
    },
    {
      "epoch": 7.53143794423182,
      "grad_norm": 7.7275800704956055,
      "learning_rate": 1.246856205576818e-05,
      "loss": 0.0689,
      "step": 27550
    },
    {
      "epoch": 7.534171678512848,
      "grad_norm": 0.01722302846610546,
      "learning_rate": 1.2465828321487152e-05,
      "loss": 0.0068,
      "step": 27560
    },
    {
      "epoch": 7.536905412793876,
      "grad_norm": 0.1174532026052475,
      "learning_rate": 1.2463094587206124e-05,
      "loss": 0.0347,
      "step": 27570
    },
    {
      "epoch": 7.5396391470749045,
      "grad_norm": 0.03806986287236214,
      "learning_rate": 1.2460360852925097e-05,
      "loss": 0.0107,
      "step": 27580
    },
    {
      "epoch": 7.5423728813559325,
      "grad_norm": 0.013816701248288155,
      "learning_rate": 1.2457627118644069e-05,
      "loss": 0.0064,
      "step": 27590
    },
    {
      "epoch": 7.54510661563696,
      "grad_norm": 0.036321260035037994,
      "learning_rate": 1.245489338436304e-05,
      "loss": 0.0362,
      "step": 27600
    },
    {
      "epoch": 7.547840349917988,
      "grad_norm": 5.422554969787598,
      "learning_rate": 1.2452159650082014e-05,
      "loss": 0.0228,
      "step": 27610
    },
    {
      "epoch": 7.550574084199016,
      "grad_norm": 4.11153507232666,
      "learning_rate": 1.2449425915800986e-05,
      "loss": 0.0309,
      "step": 27620
    },
    {
      "epoch": 7.553307818480044,
      "grad_norm": 0.004328250885009766,
      "learning_rate": 1.2446692181519957e-05,
      "loss": 0.0003,
      "step": 27630
    },
    {
      "epoch": 7.556041552761071,
      "grad_norm": 0.006694203242659569,
      "learning_rate": 1.2443958447238929e-05,
      "loss": 0.0073,
      "step": 27640
    },
    {
      "epoch": 7.558775287042099,
      "grad_norm": 0.010030059143900871,
      "learning_rate": 1.2441224712957902e-05,
      "loss": 0.0002,
      "step": 27650
    },
    {
      "epoch": 7.561509021323127,
      "grad_norm": 0.00396314961835742,
      "learning_rate": 1.2438490978676874e-05,
      "loss": 0.0196,
      "step": 27660
    },
    {
      "epoch": 7.564242755604155,
      "grad_norm": 0.003633272834122181,
      "learning_rate": 1.2435757244395846e-05,
      "loss": 0.0308,
      "step": 27670
    },
    {
      "epoch": 7.5669764898851835,
      "grad_norm": 0.2153400033712387,
      "learning_rate": 1.2433023510114819e-05,
      "loss": 0.0015,
      "step": 27680
    },
    {
      "epoch": 7.5697102241662115,
      "grad_norm": 1.0222530364990234,
      "learning_rate": 1.243028977583379e-05,
      "loss": 0.0152,
      "step": 27690
    },
    {
      "epoch": 7.572443958447239,
      "grad_norm": 0.0023673789110034704,
      "learning_rate": 1.2427556041552762e-05,
      "loss": 0.0322,
      "step": 27700
    },
    {
      "epoch": 7.575177692728267,
      "grad_norm": 8.860138893127441,
      "learning_rate": 1.2424822307271734e-05,
      "loss": 0.0306,
      "step": 27710
    },
    {
      "epoch": 7.577911427009295,
      "grad_norm": 4.661062717437744,
      "learning_rate": 1.2422088572990707e-05,
      "loss": 0.0346,
      "step": 27720
    },
    {
      "epoch": 7.580645161290323,
      "grad_norm": 0.001254733302630484,
      "learning_rate": 1.2419354838709679e-05,
      "loss": 0.0001,
      "step": 27730
    },
    {
      "epoch": 7.58337889557135,
      "grad_norm": 0.9982760548591614,
      "learning_rate": 1.241662110442865e-05,
      "loss": 0.0664,
      "step": 27740
    },
    {
      "epoch": 7.586112629852378,
      "grad_norm": 0.03442981839179993,
      "learning_rate": 1.2413887370147624e-05,
      "loss": 0.0149,
      "step": 27750
    },
    {
      "epoch": 7.588846364133406,
      "grad_norm": 0.43054190278053284,
      "learning_rate": 1.2411153635866596e-05,
      "loss": 0.0071,
      "step": 27760
    },
    {
      "epoch": 7.591580098414434,
      "grad_norm": 0.11359040439128876,
      "learning_rate": 1.2408419901585567e-05,
      "loss": 0.0168,
      "step": 27770
    },
    {
      "epoch": 7.5943138326954625,
      "grad_norm": 0.00867724884301424,
      "learning_rate": 1.2405686167304539e-05,
      "loss": 0.0339,
      "step": 27780
    },
    {
      "epoch": 7.59704756697649,
      "grad_norm": 1.5809463262557983,
      "learning_rate": 1.2402952433023512e-05,
      "loss": 0.019,
      "step": 27790
    },
    {
      "epoch": 7.599781301257518,
      "grad_norm": 0.011348261497914791,
      "learning_rate": 1.2400218698742484e-05,
      "loss": 0.0284,
      "step": 27800
    },
    {
      "epoch": 7.602515035538546,
      "grad_norm": 0.12782536447048187,
      "learning_rate": 1.2397484964461455e-05,
      "loss": 0.0241,
      "step": 27810
    },
    {
      "epoch": 7.605248769819574,
      "grad_norm": 0.1038365438580513,
      "learning_rate": 1.2394751230180429e-05,
      "loss": 0.0159,
      "step": 27820
    },
    {
      "epoch": 7.607982504100601,
      "grad_norm": 0.039288248866796494,
      "learning_rate": 1.23920174958994e-05,
      "loss": 0.0153,
      "step": 27830
    },
    {
      "epoch": 7.610716238381629,
      "grad_norm": 0.03189292177557945,
      "learning_rate": 1.2389283761618372e-05,
      "loss": 0.0391,
      "step": 27840
    },
    {
      "epoch": 7.613449972662657,
      "grad_norm": 4.491488456726074,
      "learning_rate": 1.2386550027337342e-05,
      "loss": 0.0157,
      "step": 27850
    },
    {
      "epoch": 7.616183706943685,
      "grad_norm": 0.06848131865262985,
      "learning_rate": 1.2383816293056317e-05,
      "loss": 0.0335,
      "step": 27860
    },
    {
      "epoch": 7.618917441224713,
      "grad_norm": 0.1667988896369934,
      "learning_rate": 1.2381082558775289e-05,
      "loss": 0.0522,
      "step": 27870
    },
    {
      "epoch": 7.621651175505741,
      "grad_norm": 20.04926872253418,
      "learning_rate": 1.2378348824494259e-05,
      "loss": 0.0228,
      "step": 27880
    },
    {
      "epoch": 7.624384909786769,
      "grad_norm": 0.6957484483718872,
      "learning_rate": 1.2375615090213234e-05,
      "loss": 0.0166,
      "step": 27890
    },
    {
      "epoch": 7.627118644067797,
      "grad_norm": 5.036467552185059,
      "learning_rate": 1.2372881355932205e-05,
      "loss": 0.0296,
      "step": 27900
    },
    {
      "epoch": 7.629852378348825,
      "grad_norm": 0.03451358899474144,
      "learning_rate": 1.2370147621651175e-05,
      "loss": 0.0294,
      "step": 27910
    },
    {
      "epoch": 7.632586112629852,
      "grad_norm": 0.009502533823251724,
      "learning_rate": 1.2367413887370147e-05,
      "loss": 0.001,
      "step": 27920
    },
    {
      "epoch": 7.63531984691088,
      "grad_norm": 0.003194577991962433,
      "learning_rate": 1.2364680153089122e-05,
      "loss": 0.0012,
      "step": 27930
    },
    {
      "epoch": 7.638053581191908,
      "grad_norm": 0.007368078455328941,
      "learning_rate": 1.2361946418808092e-05,
      "loss": 0.0031,
      "step": 27940
    },
    {
      "epoch": 7.640787315472936,
      "grad_norm": 0.012058394961059093,
      "learning_rate": 1.2359212684527064e-05,
      "loss": 0.0101,
      "step": 27950
    },
    {
      "epoch": 7.643521049753964,
      "grad_norm": 0.004383102059364319,
      "learning_rate": 1.2356478950246039e-05,
      "loss": 0.0004,
      "step": 27960
    },
    {
      "epoch": 7.6462547840349915,
      "grad_norm": 0.0029796382877975702,
      "learning_rate": 1.2353745215965009e-05,
      "loss": 0.0189,
      "step": 27970
    },
    {
      "epoch": 7.64898851831602,
      "grad_norm": 0.0197279155254364,
      "learning_rate": 1.235101148168398e-05,
      "loss": 0.024,
      "step": 27980
    },
    {
      "epoch": 7.651722252597048,
      "grad_norm": 0.015054342336952686,
      "learning_rate": 1.2348277747402952e-05,
      "loss": 0.0002,
      "step": 27990
    },
    {
      "epoch": 7.654455986878076,
      "grad_norm": 0.8171949982643127,
      "learning_rate": 1.2345544013121925e-05,
      "loss": 0.0005,
      "step": 28000
    },
    {
      "epoch": 7.657189721159103,
      "grad_norm": 0.017838597297668457,
      "learning_rate": 1.2342810278840897e-05,
      "loss": 0.0048,
      "step": 28010
    },
    {
      "epoch": 7.659923455440131,
      "grad_norm": 0.033323463052511215,
      "learning_rate": 1.2340076544559869e-05,
      "loss": 0.0003,
      "step": 28020
    },
    {
      "epoch": 7.662657189721159,
      "grad_norm": 5.304288387298584,
      "learning_rate": 1.2337342810278842e-05,
      "loss": 0.0459,
      "step": 28030
    },
    {
      "epoch": 7.665390924002187,
      "grad_norm": 0.5127935409545898,
      "learning_rate": 1.2334609075997814e-05,
      "loss": 0.0712,
      "step": 28040
    },
    {
      "epoch": 7.668124658283215,
      "grad_norm": 0.01730622537434101,
      "learning_rate": 1.2331875341716785e-05,
      "loss": 0.0007,
      "step": 28050
    },
    {
      "epoch": 7.670858392564242,
      "grad_norm": 0.01676095835864544,
      "learning_rate": 1.2329141607435757e-05,
      "loss": 0.0211,
      "step": 28060
    },
    {
      "epoch": 7.6735921268452705,
      "grad_norm": 0.03727766126394272,
      "learning_rate": 1.232640787315473e-05,
      "loss": 0.0006,
      "step": 28070
    },
    {
      "epoch": 7.6763258611262986,
      "grad_norm": 0.011097355745732784,
      "learning_rate": 1.2323674138873702e-05,
      "loss": 0.0075,
      "step": 28080
    },
    {
      "epoch": 7.679059595407327,
      "grad_norm": 0.0010692225769162178,
      "learning_rate": 1.2320940404592674e-05,
      "loss": 0.0088,
      "step": 28090
    },
    {
      "epoch": 7.681793329688354,
      "grad_norm": 0.0006868624477647245,
      "learning_rate": 1.2318206670311647e-05,
      "loss": 0.0014,
      "step": 28100
    },
    {
      "epoch": 7.684527063969382,
      "grad_norm": 0.012386051937937737,
      "learning_rate": 1.2315472936030619e-05,
      "loss": 0.0007,
      "step": 28110
    },
    {
      "epoch": 7.68726079825041,
      "grad_norm": 0.0021109553053975105,
      "learning_rate": 1.231273920174959e-05,
      "loss": 0.0068,
      "step": 28120
    },
    {
      "epoch": 7.689994532531438,
      "grad_norm": 0.005224925931543112,
      "learning_rate": 1.2310005467468562e-05,
      "loss": 0.0386,
      "step": 28130
    },
    {
      "epoch": 7.692728266812466,
      "grad_norm": 0.0007984336698427796,
      "learning_rate": 1.2307271733187535e-05,
      "loss": 0.0005,
      "step": 28140
    },
    {
      "epoch": 7.695462001093494,
      "grad_norm": 0.0010031552519649267,
      "learning_rate": 1.2304537998906507e-05,
      "loss": 0.0025,
      "step": 28150
    },
    {
      "epoch": 7.698195735374521,
      "grad_norm": 68.99948120117188,
      "learning_rate": 1.2301804264625479e-05,
      "loss": 0.0682,
      "step": 28160
    },
    {
      "epoch": 7.7009294696555495,
      "grad_norm": 0.0157134011387825,
      "learning_rate": 1.2299070530344452e-05,
      "loss": 0.0241,
      "step": 28170
    },
    {
      "epoch": 7.7036632039365776,
      "grad_norm": 0.014368659816682339,
      "learning_rate": 1.2296336796063424e-05,
      "loss": 0.0223,
      "step": 28180
    },
    {
      "epoch": 7.706396938217606,
      "grad_norm": 0.4505971670150757,
      "learning_rate": 1.2293603061782395e-05,
      "loss": 0.0071,
      "step": 28190
    },
    {
      "epoch": 7.709130672498633,
      "grad_norm": 0.0021066118497401476,
      "learning_rate": 1.2290869327501367e-05,
      "loss": 0.0009,
      "step": 28200
    },
    {
      "epoch": 7.711864406779661,
      "grad_norm": 0.024379612877964973,
      "learning_rate": 1.228813559322034e-05,
      "loss": 0.0377,
      "step": 28210
    },
    {
      "epoch": 7.714598141060689,
      "grad_norm": 0.0019726804457604885,
      "learning_rate": 1.2285401858939312e-05,
      "loss": 0.0004,
      "step": 28220
    },
    {
      "epoch": 7.717331875341717,
      "grad_norm": 0.02940325252711773,
      "learning_rate": 1.2282668124658284e-05,
      "loss": 0.0208,
      "step": 28230
    },
    {
      "epoch": 7.720065609622745,
      "grad_norm": 0.011211415752768517,
      "learning_rate": 1.2279934390377257e-05,
      "loss": 0.0195,
      "step": 28240
    },
    {
      "epoch": 7.722799343903772,
      "grad_norm": 0.011863014660775661,
      "learning_rate": 1.2277200656096229e-05,
      "loss": 0.0682,
      "step": 28250
    },
    {
      "epoch": 7.7255330781848,
      "grad_norm": 3.206233024597168,
      "learning_rate": 1.22744669218152e-05,
      "loss": 0.0215,
      "step": 28260
    },
    {
      "epoch": 7.7282668124658285,
      "grad_norm": 0.0005746990209445357,
      "learning_rate": 1.2271733187534172e-05,
      "loss": 0.0106,
      "step": 28270
    },
    {
      "epoch": 7.7310005467468565,
      "grad_norm": 2.478809118270874,
      "learning_rate": 1.2268999453253145e-05,
      "loss": 0.0556,
      "step": 28280
    },
    {
      "epoch": 7.733734281027884,
      "grad_norm": 0.012394965626299381,
      "learning_rate": 1.2266265718972117e-05,
      "loss": 0.0199,
      "step": 28290
    },
    {
      "epoch": 7.736468015308912,
      "grad_norm": 0.024056212976574898,
      "learning_rate": 1.2263531984691089e-05,
      "loss": 0.0342,
      "step": 28300
    },
    {
      "epoch": 7.73920174958994,
      "grad_norm": 0.10515125095844269,
      "learning_rate": 1.2260798250410062e-05,
      "loss": 0.0036,
      "step": 28310
    },
    {
      "epoch": 7.741935483870968,
      "grad_norm": 16.676786422729492,
      "learning_rate": 1.2258064516129034e-05,
      "loss": 0.0071,
      "step": 28320
    },
    {
      "epoch": 7.744669218151996,
      "grad_norm": 0.0029394954908639193,
      "learning_rate": 1.2255330781848005e-05,
      "loss": 0.034,
      "step": 28330
    },
    {
      "epoch": 7.747402952433023,
      "grad_norm": 0.017138101160526276,
      "learning_rate": 1.2252597047566977e-05,
      "loss": 0.0028,
      "step": 28340
    },
    {
      "epoch": 7.750136686714051,
      "grad_norm": 1.5203831195831299,
      "learning_rate": 1.224986331328595e-05,
      "loss": 0.0505,
      "step": 28350
    },
    {
      "epoch": 7.752870420995079,
      "grad_norm": 0.0035807304084300995,
      "learning_rate": 1.2247129579004922e-05,
      "loss": 0.001,
      "step": 28360
    },
    {
      "epoch": 7.7556041552761075,
      "grad_norm": 2.7026209831237793,
      "learning_rate": 1.2244395844723894e-05,
      "loss": 0.0114,
      "step": 28370
    },
    {
      "epoch": 7.758337889557135,
      "grad_norm": 0.09486883878707886,
      "learning_rate": 1.2241662110442867e-05,
      "loss": 0.0099,
      "step": 28380
    },
    {
      "epoch": 7.761071623838163,
      "grad_norm": 2.4056692123413086,
      "learning_rate": 1.2238928376161839e-05,
      "loss": 0.0089,
      "step": 28390
    },
    {
      "epoch": 7.763805358119191,
      "grad_norm": 0.0007347814389504492,
      "learning_rate": 1.223619464188081e-05,
      "loss": 0.0154,
      "step": 28400
    },
    {
      "epoch": 7.766539092400219,
      "grad_norm": 0.002336084144189954,
      "learning_rate": 1.2233460907599782e-05,
      "loss": 0.0175,
      "step": 28410
    },
    {
      "epoch": 7.769272826681247,
      "grad_norm": 0.041470084339380264,
      "learning_rate": 1.2230727173318755e-05,
      "loss": 0.0003,
      "step": 28420
    },
    {
      "epoch": 7.772006560962274,
      "grad_norm": 0.3419715464115143,
      "learning_rate": 1.2227993439037727e-05,
      "loss": 0.0013,
      "step": 28430
    },
    {
      "epoch": 7.774740295243302,
      "grad_norm": 0.019963368773460388,
      "learning_rate": 1.2225259704756699e-05,
      "loss": 0.0788,
      "step": 28440
    },
    {
      "epoch": 7.77747402952433,
      "grad_norm": 0.0007041498320177197,
      "learning_rate": 1.2222525970475672e-05,
      "loss": 0.0109,
      "step": 28450
    },
    {
      "epoch": 7.780207763805358,
      "grad_norm": 0.009583041071891785,
      "learning_rate": 1.2219792236194644e-05,
      "loss": 0.0059,
      "step": 28460
    },
    {
      "epoch": 7.782941498086386,
      "grad_norm": 27.71535301208496,
      "learning_rate": 1.2217058501913615e-05,
      "loss": 0.0312,
      "step": 28470
    },
    {
      "epoch": 7.785675232367414,
      "grad_norm": 0.16406431794166565,
      "learning_rate": 1.2214324767632585e-05,
      "loss": 0.0077,
      "step": 28480
    },
    {
      "epoch": 7.788408966648442,
      "grad_norm": 0.011373262852430344,
      "learning_rate": 1.221159103335156e-05,
      "loss": 0.0052,
      "step": 28490
    },
    {
      "epoch": 7.79114270092947,
      "grad_norm": 2.3449249267578125,
      "learning_rate": 1.2208857299070532e-05,
      "loss": 0.0505,
      "step": 28500
    },
    {
      "epoch": 7.793876435210498,
      "grad_norm": 0.0014865145785734057,
      "learning_rate": 1.2206123564789502e-05,
      "loss": 0.0081,
      "step": 28510
    },
    {
      "epoch": 7.796610169491525,
      "grad_norm": 0.0009815056109800935,
      "learning_rate": 1.2203389830508477e-05,
      "loss": 0.0171,
      "step": 28520
    },
    {
      "epoch": 7.799343903772553,
      "grad_norm": 0.016623718664050102,
      "learning_rate": 1.2200656096227449e-05,
      "loss": 0.0279,
      "step": 28530
    },
    {
      "epoch": 7.802077638053581,
      "grad_norm": 0.0021399485412985086,
      "learning_rate": 1.2197922361946419e-05,
      "loss": 0.0238,
      "step": 28540
    },
    {
      "epoch": 7.804811372334609,
      "grad_norm": 1.185562014579773,
      "learning_rate": 1.2195188627665394e-05,
      "loss": 0.0014,
      "step": 28550
    },
    {
      "epoch": 7.8075451066156365,
      "grad_norm": 0.0010333583923056722,
      "learning_rate": 1.2192454893384365e-05,
      "loss": 0.0002,
      "step": 28560
    },
    {
      "epoch": 7.810278840896665,
      "grad_norm": 0.0050223651342093945,
      "learning_rate": 1.2189721159103335e-05,
      "loss": 0.0067,
      "step": 28570
    },
    {
      "epoch": 7.813012575177693,
      "grad_norm": 0.005966649390757084,
      "learning_rate": 1.2186987424822307e-05,
      "loss": 0.0291,
      "step": 28580
    },
    {
      "epoch": 7.815746309458721,
      "grad_norm": 0.13386143743991852,
      "learning_rate": 1.2184253690541282e-05,
      "loss": 0.009,
      "step": 28590
    },
    {
      "epoch": 7.818480043739749,
      "grad_norm": 0.001733938930556178,
      "learning_rate": 1.2181519956260252e-05,
      "loss": 0.0305,
      "step": 28600
    },
    {
      "epoch": 7.821213778020776,
      "grad_norm": 0.09490707516670227,
      "learning_rate": 1.2178786221979224e-05,
      "loss": 0.0011,
      "step": 28610
    },
    {
      "epoch": 7.823947512301804,
      "grad_norm": 0.2245226502418518,
      "learning_rate": 1.2176052487698199e-05,
      "loss": 0.0029,
      "step": 28620
    },
    {
      "epoch": 7.826681246582832,
      "grad_norm": 0.010913185775279999,
      "learning_rate": 1.2173318753417169e-05,
      "loss": 0.0001,
      "step": 28630
    },
    {
      "epoch": 7.82941498086386,
      "grad_norm": 2.6017818450927734,
      "learning_rate": 1.217058501913614e-05,
      "loss": 0.0192,
      "step": 28640
    },
    {
      "epoch": 7.832148715144887,
      "grad_norm": 0.003642365336418152,
      "learning_rate": 1.2167851284855112e-05,
      "loss": 0.0003,
      "step": 28650
    },
    {
      "epoch": 7.8348824494259155,
      "grad_norm": 17.359315872192383,
      "learning_rate": 1.2165117550574085e-05,
      "loss": 0.0138,
      "step": 28660
    },
    {
      "epoch": 7.837616183706944,
      "grad_norm": 0.001067464123480022,
      "learning_rate": 1.2162383816293057e-05,
      "loss": 0.0546,
      "step": 28670
    },
    {
      "epoch": 7.840349917987972,
      "grad_norm": 0.002501119626685977,
      "learning_rate": 1.2159650082012028e-05,
      "loss": 0.0324,
      "step": 28680
    },
    {
      "epoch": 7.843083652269,
      "grad_norm": 0.13847796618938446,
      "learning_rate": 1.2156916347731002e-05,
      "loss": 0.0009,
      "step": 28690
    },
    {
      "epoch": 7.845817386550028,
      "grad_norm": 0.014971364289522171,
      "learning_rate": 1.2154182613449974e-05,
      "loss": 0.0103,
      "step": 28700
    },
    {
      "epoch": 7.848551120831055,
      "grad_norm": 0.0050088586285710335,
      "learning_rate": 1.2151448879168945e-05,
      "loss": 0.009,
      "step": 28710
    },
    {
      "epoch": 7.851284855112083,
      "grad_norm": 0.38181817531585693,
      "learning_rate": 1.2148715144887917e-05,
      "loss": 0.0076,
      "step": 28720
    },
    {
      "epoch": 7.854018589393111,
      "grad_norm": 0.008043071255087852,
      "learning_rate": 1.214598141060689e-05,
      "loss": 0.0012,
      "step": 28730
    },
    {
      "epoch": 7.856752323674139,
      "grad_norm": 0.0038813757710158825,
      "learning_rate": 1.2143247676325862e-05,
      "loss": 0.0068,
      "step": 28740
    },
    {
      "epoch": 7.859486057955166,
      "grad_norm": 0.0006475968984887004,
      "learning_rate": 1.2140513942044833e-05,
      "loss": 0.014,
      "step": 28750
    },
    {
      "epoch": 7.8622197922361945,
      "grad_norm": 0.000412234861869365,
      "learning_rate": 1.2137780207763807e-05,
      "loss": 0.011,
      "step": 28760
    },
    {
      "epoch": 7.864953526517223,
      "grad_norm": 0.0009620935306884348,
      "learning_rate": 1.2135046473482778e-05,
      "loss": 0.0012,
      "step": 28770
    },
    {
      "epoch": 7.867687260798251,
      "grad_norm": 0.001499788137152791,
      "learning_rate": 1.213231273920175e-05,
      "loss": 0.0004,
      "step": 28780
    },
    {
      "epoch": 7.870420995079279,
      "grad_norm": 1.8181661367416382,
      "learning_rate": 1.2129579004920722e-05,
      "loss": 0.0535,
      "step": 28790
    },
    {
      "epoch": 7.873154729360306,
      "grad_norm": 0.30117765069007874,
      "learning_rate": 1.2126845270639695e-05,
      "loss": 0.0007,
      "step": 28800
    },
    {
      "epoch": 7.875888463641334,
      "grad_norm": 0.011484156362712383,
      "learning_rate": 1.2124111536358667e-05,
      "loss": 0.0001,
      "step": 28810
    },
    {
      "epoch": 7.878622197922362,
      "grad_norm": 0.16714081168174744,
      "learning_rate": 1.2121377802077638e-05,
      "loss": 0.0146,
      "step": 28820
    },
    {
      "epoch": 7.88135593220339,
      "grad_norm": 0.0009938869625329971,
      "learning_rate": 1.2118644067796612e-05,
      "loss": 0.0123,
      "step": 28830
    },
    {
      "epoch": 7.884089666484417,
      "grad_norm": 0.0026534791104495525,
      "learning_rate": 1.2115910333515583e-05,
      "loss": 0.0003,
      "step": 28840
    },
    {
      "epoch": 7.886823400765445,
      "grad_norm": 1.6190928220748901,
      "learning_rate": 1.2113176599234555e-05,
      "loss": 0.0773,
      "step": 28850
    },
    {
      "epoch": 7.8895571350464735,
      "grad_norm": 0.0006819968111813068,
      "learning_rate": 1.2110442864953527e-05,
      "loss": 0.0008,
      "step": 28860
    },
    {
      "epoch": 7.892290869327502,
      "grad_norm": 0.0014461559476330876,
      "learning_rate": 1.21077091306725e-05,
      "loss": 0.0145,
      "step": 28870
    },
    {
      "epoch": 7.89502460360853,
      "grad_norm": 0.057715997099876404,
      "learning_rate": 1.2104975396391472e-05,
      "loss": 0.0002,
      "step": 28880
    },
    {
      "epoch": 7.897758337889557,
      "grad_norm": 0.13596592843532562,
      "learning_rate": 1.2102241662110443e-05,
      "loss": 0.0004,
      "step": 28890
    },
    {
      "epoch": 7.900492072170585,
      "grad_norm": 0.0009162373025901616,
      "learning_rate": 1.2099507927829417e-05,
      "loss": 0.001,
      "step": 28900
    },
    {
      "epoch": 7.903225806451613,
      "grad_norm": 0.0006715802592225373,
      "learning_rate": 1.2096774193548388e-05,
      "loss": 0.0113,
      "step": 28910
    },
    {
      "epoch": 7.905959540732641,
      "grad_norm": 0.12913109362125397,
      "learning_rate": 1.209404045926736e-05,
      "loss": 0.0023,
      "step": 28920
    },
    {
      "epoch": 7.908693275013668,
      "grad_norm": 0.002624110784381628,
      "learning_rate": 1.2091306724986332e-05,
      "loss": 0.0441,
      "step": 28930
    },
    {
      "epoch": 7.911427009294696,
      "grad_norm": 0.3969168961048126,
      "learning_rate": 1.2088572990705305e-05,
      "loss": 0.0026,
      "step": 28940
    },
    {
      "epoch": 7.914160743575724,
      "grad_norm": 0.04097750782966614,
      "learning_rate": 1.2085839256424277e-05,
      "loss": 0.0572,
      "step": 28950
    },
    {
      "epoch": 7.9168944778567525,
      "grad_norm": 0.00986388511955738,
      "learning_rate": 1.2083105522143248e-05,
      "loss": 0.0058,
      "step": 28960
    },
    {
      "epoch": 7.919628212137781,
      "grad_norm": 12.584002494812012,
      "learning_rate": 1.2080371787862222e-05,
      "loss": 0.0213,
      "step": 28970
    },
    {
      "epoch": 7.922361946418808,
      "grad_norm": 0.002255661180242896,
      "learning_rate": 1.2077638053581193e-05,
      "loss": 0.0143,
      "step": 28980
    },
    {
      "epoch": 7.925095680699836,
      "grad_norm": 0.0026655320543795824,
      "learning_rate": 1.2074904319300165e-05,
      "loss": 0.0011,
      "step": 28990
    },
    {
      "epoch": 7.927829414980864,
      "grad_norm": 0.0947866439819336,
      "learning_rate": 1.2072170585019137e-05,
      "loss": 0.0089,
      "step": 29000
    },
    {
      "epoch": 7.930563149261892,
      "grad_norm": 2.5562994480133057,
      "learning_rate": 1.206943685073811e-05,
      "loss": 0.0469,
      "step": 29010
    },
    {
      "epoch": 7.933296883542919,
      "grad_norm": 0.0031478514429181814,
      "learning_rate": 1.2066703116457082e-05,
      "loss": 0.0016,
      "step": 29020
    },
    {
      "epoch": 7.936030617823947,
      "grad_norm": 0.01183057576417923,
      "learning_rate": 1.2063969382176053e-05,
      "loss": 0.0016,
      "step": 29030
    },
    {
      "epoch": 7.938764352104975,
      "grad_norm": 0.3975723385810852,
      "learning_rate": 1.2061235647895027e-05,
      "loss": 0.001,
      "step": 29040
    },
    {
      "epoch": 7.941498086386003,
      "grad_norm": 0.02191011607646942,
      "learning_rate": 1.2058501913613998e-05,
      "loss": 0.031,
      "step": 29050
    },
    {
      "epoch": 7.9442318206670315,
      "grad_norm": 0.004793170839548111,
      "learning_rate": 1.205576817933297e-05,
      "loss": 0.0367,
      "step": 29060
    },
    {
      "epoch": 7.946965554948059,
      "grad_norm": 0.01780072972178459,
      "learning_rate": 1.2053034445051942e-05,
      "loss": 0.0205,
      "step": 29070
    },
    {
      "epoch": 7.949699289229087,
      "grad_norm": 0.006639433093369007,
      "learning_rate": 1.2050300710770915e-05,
      "loss": 0.0002,
      "step": 29080
    },
    {
      "epoch": 7.952433023510115,
      "grad_norm": 0.0067996555007994175,
      "learning_rate": 1.2047566976489887e-05,
      "loss": 0.0002,
      "step": 29090
    },
    {
      "epoch": 7.955166757791143,
      "grad_norm": 0.042065612971782684,
      "learning_rate": 1.2044833242208858e-05,
      "loss": 0.0298,
      "step": 29100
    },
    {
      "epoch": 7.95790049207217,
      "grad_norm": 0.005083781201392412,
      "learning_rate": 1.2042099507927832e-05,
      "loss": 0.0588,
      "step": 29110
    },
    {
      "epoch": 7.960634226353198,
      "grad_norm": 0.005432567559182644,
      "learning_rate": 1.2039365773646803e-05,
      "loss": 0.0088,
      "step": 29120
    },
    {
      "epoch": 7.963367960634226,
      "grad_norm": 0.006779857445508242,
      "learning_rate": 1.2036632039365775e-05,
      "loss": 0.0173,
      "step": 29130
    },
    {
      "epoch": 7.966101694915254,
      "grad_norm": 0.17171405255794525,
      "learning_rate": 1.2033898305084745e-05,
      "loss": 0.0016,
      "step": 29140
    },
    {
      "epoch": 7.968835429196282,
      "grad_norm": 15.233295440673828,
      "learning_rate": 1.203116457080372e-05,
      "loss": 0.0427,
      "step": 29150
    },
    {
      "epoch": 7.9715691634773105,
      "grad_norm": 0.006916944868862629,
      "learning_rate": 1.2028430836522692e-05,
      "loss": 0.0097,
      "step": 29160
    },
    {
      "epoch": 7.974302897758338,
      "grad_norm": 0.023424234241247177,
      "learning_rate": 1.2025697102241662e-05,
      "loss": 0.0468,
      "step": 29170
    },
    {
      "epoch": 7.977036632039366,
      "grad_norm": 0.07888346165418625,
      "learning_rate": 1.2022963367960637e-05,
      "loss": 0.0124,
      "step": 29180
    },
    {
      "epoch": 7.979770366320394,
      "grad_norm": 0.20532040297985077,
      "learning_rate": 1.2020229633679608e-05,
      "loss": 0.0016,
      "step": 29190
    },
    {
      "epoch": 7.982504100601422,
      "grad_norm": 0.005119371227920055,
      "learning_rate": 1.2017495899398578e-05,
      "loss": 0.0034,
      "step": 29200
    },
    {
      "epoch": 7.985237834882449,
      "grad_norm": 0.0023912880569696426,
      "learning_rate": 1.201476216511755e-05,
      "loss": 0.0269,
      "step": 29210
    },
    {
      "epoch": 7.987971569163477,
      "grad_norm": 0.006139128468930721,
      "learning_rate": 1.2012028430836525e-05,
      "loss": 0.0315,
      "step": 29220
    },
    {
      "epoch": 7.990705303444505,
      "grad_norm": 0.00311110308393836,
      "learning_rate": 1.2009294696555495e-05,
      "loss": 0.0358,
      "step": 29230
    },
    {
      "epoch": 7.993439037725533,
      "grad_norm": 0.5898845195770264,
      "learning_rate": 1.2006560962274467e-05,
      "loss": 0.0014,
      "step": 29240
    },
    {
      "epoch": 7.996172772006561,
      "grad_norm": 0.009141776710748672,
      "learning_rate": 1.2003827227993442e-05,
      "loss": 0.0085,
      "step": 29250
    },
    {
      "epoch": 7.998906506287589,
      "grad_norm": 0.006168750114738941,
      "learning_rate": 1.2001093493712412e-05,
      "loss": 0.0157,
      "step": 29260
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.991751809280545,
      "eval_f1": 0.9671261930010604,
      "eval_loss": 0.03350364789366722,
      "eval_precision": 0.9612141652613828,
      "eval_recall": 0.9731113956466069,
      "eval_runtime": 799.2295,
      "eval_samples_per_second": 23.54,
      "eval_steps_per_second": 0.981,
      "step": 29264
    },
    {
      "epoch": 8.001640240568618,
      "grad_norm": 0.09871096163988113,
      "learning_rate": 1.1998359759431383e-05,
      "loss": 0.0204,
      "step": 29270
    },
    {
      "epoch": 8.004373974849644,
      "grad_norm": 0.004058430902659893,
      "learning_rate": 1.1995626025150355e-05,
      "loss": 0.0001,
      "step": 29280
    },
    {
      "epoch": 8.007107709130672,
      "grad_norm": 0.002587050898000598,
      "learning_rate": 1.1992892290869328e-05,
      "loss": 0.0115,
      "step": 29290
    },
    {
      "epoch": 8.0098414434117,
      "grad_norm": 0.10371488332748413,
      "learning_rate": 1.19901585565883e-05,
      "loss": 0.0445,
      "step": 29300
    },
    {
      "epoch": 8.012575177692728,
      "grad_norm": 0.025668641552329063,
      "learning_rate": 1.1987424822307272e-05,
      "loss": 0.0028,
      "step": 29310
    },
    {
      "epoch": 8.015308911973756,
      "grad_norm": 0.0036142964381724596,
      "learning_rate": 1.1984691088026245e-05,
      "loss": 0.0003,
      "step": 29320
    },
    {
      "epoch": 8.018042646254784,
      "grad_norm": 0.0023594629019498825,
      "learning_rate": 1.1981957353745217e-05,
      "loss": 0.0532,
      "step": 29330
    },
    {
      "epoch": 8.020776380535812,
      "grad_norm": 0.006353374104946852,
      "learning_rate": 1.1979223619464188e-05,
      "loss": 0.0188,
      "step": 29340
    },
    {
      "epoch": 8.02351011481684,
      "grad_norm": 0.0056386673822999,
      "learning_rate": 1.197648988518316e-05,
      "loss": 0.006,
      "step": 29350
    },
    {
      "epoch": 8.026243849097868,
      "grad_norm": 0.017583824694156647,
      "learning_rate": 1.1973756150902133e-05,
      "loss": 0.0109,
      "step": 29360
    },
    {
      "epoch": 8.028977583378895,
      "grad_norm": 0.03716772422194481,
      "learning_rate": 1.1971022416621105e-05,
      "loss": 0.003,
      "step": 29370
    },
    {
      "epoch": 8.031711317659923,
      "grad_norm": 0.002378334291279316,
      "learning_rate": 1.1968288682340077e-05,
      "loss": 0.0011,
      "step": 29380
    },
    {
      "epoch": 8.034445051940951,
      "grad_norm": 0.46094754338264465,
      "learning_rate": 1.196555494805905e-05,
      "loss": 0.0013,
      "step": 29390
    },
    {
      "epoch": 8.037178786221979,
      "grad_norm": 0.06970980763435364,
      "learning_rate": 1.1962821213778022e-05,
      "loss": 0.0144,
      "step": 29400
    },
    {
      "epoch": 8.039912520503007,
      "grad_norm": 0.006371639668941498,
      "learning_rate": 1.1960087479496993e-05,
      "loss": 0.0069,
      "step": 29410
    },
    {
      "epoch": 8.042646254784035,
      "grad_norm": 1.6664451360702515,
      "learning_rate": 1.1957353745215965e-05,
      "loss": 0.0081,
      "step": 29420
    },
    {
      "epoch": 8.045379989065063,
      "grad_norm": 0.008732245303690434,
      "learning_rate": 1.1954620010934938e-05,
      "loss": 0.0166,
      "step": 29430
    },
    {
      "epoch": 8.048113723346091,
      "grad_norm": 0.0012237916234880686,
      "learning_rate": 1.195188627665391e-05,
      "loss": 0.0062,
      "step": 29440
    },
    {
      "epoch": 8.05084745762712,
      "grad_norm": 0.006234126165509224,
      "learning_rate": 1.1949152542372882e-05,
      "loss": 0.0096,
      "step": 29450
    },
    {
      "epoch": 8.053581191908146,
      "grad_norm": 1.883247971534729,
      "learning_rate": 1.1946418808091855e-05,
      "loss": 0.009,
      "step": 29460
    },
    {
      "epoch": 8.056314926189174,
      "grad_norm": 0.0010231859050691128,
      "learning_rate": 1.1943685073810827e-05,
      "loss": 0.0087,
      "step": 29470
    },
    {
      "epoch": 8.059048660470202,
      "grad_norm": 0.5661647319793701,
      "learning_rate": 1.1940951339529798e-05,
      "loss": 0.0144,
      "step": 29480
    },
    {
      "epoch": 8.06178239475123,
      "grad_norm": 19.175657272338867,
      "learning_rate": 1.193821760524877e-05,
      "loss": 0.0097,
      "step": 29490
    },
    {
      "epoch": 8.064516129032258,
      "grad_norm": 1.4210896492004395,
      "learning_rate": 1.1935483870967743e-05,
      "loss": 0.0334,
      "step": 29500
    },
    {
      "epoch": 8.067249863313286,
      "grad_norm": 0.003703541588038206,
      "learning_rate": 1.1932750136686715e-05,
      "loss": 0.0234,
      "step": 29510
    },
    {
      "epoch": 8.069983597594314,
      "grad_norm": 0.031020162627100945,
      "learning_rate": 1.1930016402405687e-05,
      "loss": 0.0298,
      "step": 29520
    },
    {
      "epoch": 8.072717331875342,
      "grad_norm": 0.033730268478393555,
      "learning_rate": 1.192728266812466e-05,
      "loss": 0.0051,
      "step": 29530
    },
    {
      "epoch": 8.07545106615637,
      "grad_norm": 0.2729298770427704,
      "learning_rate": 1.1924548933843632e-05,
      "loss": 0.035,
      "step": 29540
    },
    {
      "epoch": 8.078184800437397,
      "grad_norm": 0.9947219491004944,
      "learning_rate": 1.1921815199562603e-05,
      "loss": 0.0133,
      "step": 29550
    },
    {
      "epoch": 8.080918534718425,
      "grad_norm": 0.03662734478712082,
      "learning_rate": 1.1919081465281575e-05,
      "loss": 0.0086,
      "step": 29560
    },
    {
      "epoch": 8.083652268999453,
      "grad_norm": 2.429154396057129,
      "learning_rate": 1.1916347731000548e-05,
      "loss": 0.0241,
      "step": 29570
    },
    {
      "epoch": 8.08638600328048,
      "grad_norm": 0.0014076221268624067,
      "learning_rate": 1.191361399671952e-05,
      "loss": 0.0003,
      "step": 29580
    },
    {
      "epoch": 8.089119737561509,
      "grad_norm": 0.0008590357610955834,
      "learning_rate": 1.1910880262438492e-05,
      "loss": 0.0274,
      "step": 29590
    },
    {
      "epoch": 8.091853471842537,
      "grad_norm": 0.02114279568195343,
      "learning_rate": 1.1908146528157465e-05,
      "loss": 0.0001,
      "step": 29600
    },
    {
      "epoch": 8.094587206123565,
      "grad_norm": 0.001689481665380299,
      "learning_rate": 1.1905412793876437e-05,
      "loss": 0.02,
      "step": 29610
    },
    {
      "epoch": 8.097320940404593,
      "grad_norm": 1.911323070526123,
      "learning_rate": 1.1902679059595408e-05,
      "loss": 0.0036,
      "step": 29620
    },
    {
      "epoch": 8.100054674685621,
      "grad_norm": 0.001590666943229735,
      "learning_rate": 1.1899945325314382e-05,
      "loss": 0.0003,
      "step": 29630
    },
    {
      "epoch": 8.10278840896665,
      "grad_norm": 0.0025876376312226057,
      "learning_rate": 1.1897211591033353e-05,
      "loss": 0.0033,
      "step": 29640
    },
    {
      "epoch": 8.105522143247676,
      "grad_norm": 0.11887586861848831,
      "learning_rate": 1.1894477856752325e-05,
      "loss": 0.0042,
      "step": 29650
    },
    {
      "epoch": 8.108255877528704,
      "grad_norm": 2.05173659324646,
      "learning_rate": 1.1891744122471297e-05,
      "loss": 0.0524,
      "step": 29660
    },
    {
      "epoch": 8.110989611809732,
      "grad_norm": 0.002242892747744918,
      "learning_rate": 1.188901038819027e-05,
      "loss": 0.0135,
      "step": 29670
    },
    {
      "epoch": 8.11372334609076,
      "grad_norm": 1.7129020690917969,
      "learning_rate": 1.1886276653909242e-05,
      "loss": 0.0053,
      "step": 29680
    },
    {
      "epoch": 8.116457080371788,
      "grad_norm": 0.005437504034489393,
      "learning_rate": 1.1883542919628213e-05,
      "loss": 0.0001,
      "step": 29690
    },
    {
      "epoch": 8.119190814652816,
      "grad_norm": 0.002776192035526037,
      "learning_rate": 1.1880809185347187e-05,
      "loss": 0.0102,
      "step": 29700
    },
    {
      "epoch": 8.121924548933844,
      "grad_norm": 0.0050596329383552074,
      "learning_rate": 1.1878075451066158e-05,
      "loss": 0.003,
      "step": 29710
    },
    {
      "epoch": 8.124658283214872,
      "grad_norm": 5.055254936218262,
      "learning_rate": 1.187534171678513e-05,
      "loss": 0.0254,
      "step": 29720
    },
    {
      "epoch": 8.1273920174959,
      "grad_norm": 0.002391527872532606,
      "learning_rate": 1.1872607982504101e-05,
      "loss": 0.0197,
      "step": 29730
    },
    {
      "epoch": 8.130125751776927,
      "grad_norm": 0.0020964816212654114,
      "learning_rate": 1.1869874248223075e-05,
      "loss": 0.0224,
      "step": 29740
    },
    {
      "epoch": 8.132859486057955,
      "grad_norm": 0.0019614039920270443,
      "learning_rate": 1.1867140513942046e-05,
      "loss": 0.0601,
      "step": 29750
    },
    {
      "epoch": 8.135593220338983,
      "grad_norm": 0.47885212302207947,
      "learning_rate": 1.1864406779661018e-05,
      "loss": 0.0116,
      "step": 29760
    },
    {
      "epoch": 8.13832695462001,
      "grad_norm": 0.24019309878349304,
      "learning_rate": 1.1861673045379991e-05,
      "loss": 0.0193,
      "step": 29770
    },
    {
      "epoch": 8.141060688901039,
      "grad_norm": 0.04459505155682564,
      "learning_rate": 1.1858939311098963e-05,
      "loss": 0.0122,
      "step": 29780
    },
    {
      "epoch": 8.143794423182067,
      "grad_norm": 0.004740948788821697,
      "learning_rate": 1.1856205576817935e-05,
      "loss": 0.0026,
      "step": 29790
    },
    {
      "epoch": 8.146528157463095,
      "grad_norm": 0.003690678160637617,
      "learning_rate": 1.1853471842536905e-05,
      "loss": 0.0392,
      "step": 29800
    },
    {
      "epoch": 8.149261891744123,
      "grad_norm": 0.014195195399224758,
      "learning_rate": 1.185073810825588e-05,
      "loss": 0.0781,
      "step": 29810
    },
    {
      "epoch": 8.151995626025151,
      "grad_norm": 0.007948804646730423,
      "learning_rate": 1.1848004373974851e-05,
      "loss": 0.0099,
      "step": 29820
    },
    {
      "epoch": 8.154729360306177,
      "grad_norm": 0.0021752824541181326,
      "learning_rate": 1.1845270639693821e-05,
      "loss": 0.0245,
      "step": 29830
    },
    {
      "epoch": 8.157463094587206,
      "grad_norm": 0.0022394314873963594,
      "learning_rate": 1.1842536905412796e-05,
      "loss": 0.0002,
      "step": 29840
    },
    {
      "epoch": 8.160196828868234,
      "grad_norm": 0.0017902152612805367,
      "learning_rate": 1.1839803171131768e-05,
      "loss": 0.0001,
      "step": 29850
    },
    {
      "epoch": 8.162930563149262,
      "grad_norm": 0.9206694960594177,
      "learning_rate": 1.1837069436850738e-05,
      "loss": 0.0025,
      "step": 29860
    },
    {
      "epoch": 8.16566429743029,
      "grad_norm": 3.2792885303497314,
      "learning_rate": 1.183433570256971e-05,
      "loss": 0.0173,
      "step": 29870
    },
    {
      "epoch": 8.168398031711318,
      "grad_norm": 0.0014769877307116985,
      "learning_rate": 1.1831601968288685e-05,
      "loss": 0.0001,
      "step": 29880
    },
    {
      "epoch": 8.171131765992346,
      "grad_norm": 6.165602207183838,
      "learning_rate": 1.1828868234007655e-05,
      "loss": 0.0269,
      "step": 29890
    },
    {
      "epoch": 8.173865500273374,
      "grad_norm": 0.007730037439614534,
      "learning_rate": 1.1826134499726626e-05,
      "loss": 0.0107,
      "step": 29900
    },
    {
      "epoch": 8.176599234554402,
      "grad_norm": 0.8672841787338257,
      "learning_rate": 1.1823400765445601e-05,
      "loss": 0.0098,
      "step": 29910
    },
    {
      "epoch": 8.179332968835428,
      "grad_norm": 18.755033493041992,
      "learning_rate": 1.1820667031164571e-05,
      "loss": 0.003,
      "step": 29920
    },
    {
      "epoch": 8.182066703116456,
      "grad_norm": 0.0014136966783553362,
      "learning_rate": 1.1817933296883543e-05,
      "loss": 0.0002,
      "step": 29930
    },
    {
      "epoch": 8.184800437397485,
      "grad_norm": 0.035078078508377075,
      "learning_rate": 1.1815199562602515e-05,
      "loss": 0.0059,
      "step": 29940
    },
    {
      "epoch": 8.187534171678513,
      "grad_norm": 0.002189163351431489,
      "learning_rate": 1.1812465828321488e-05,
      "loss": 0.0003,
      "step": 29950
    },
    {
      "epoch": 8.19026790595954,
      "grad_norm": 0.0012278698850423098,
      "learning_rate": 1.180973209404046e-05,
      "loss": 0.014,
      "step": 29960
    },
    {
      "epoch": 8.193001640240569,
      "grad_norm": 0.012170201167464256,
      "learning_rate": 1.1806998359759431e-05,
      "loss": 0.0189,
      "step": 29970
    },
    {
      "epoch": 8.195735374521597,
      "grad_norm": 0.0008727583335712552,
      "learning_rate": 1.1804264625478405e-05,
      "loss": 0.0021,
      "step": 29980
    },
    {
      "epoch": 8.198469108802625,
      "grad_norm": 0.5881792306900024,
      "learning_rate": 1.1801530891197376e-05,
      "loss": 0.0094,
      "step": 29990
    },
    {
      "epoch": 8.201202843083653,
      "grad_norm": 0.002504725242033601,
      "learning_rate": 1.1798797156916348e-05,
      "loss": 0.0096,
      "step": 30000
    },
    {
      "epoch": 8.20393657736468,
      "grad_norm": 0.001595596899278462,
      "learning_rate": 1.179606342263532e-05,
      "loss": 0.0244,
      "step": 30010
    },
    {
      "epoch": 8.206670311645707,
      "grad_norm": 0.0011068952735513449,
      "learning_rate": 1.1793329688354293e-05,
      "loss": 0.0151,
      "step": 30020
    },
    {
      "epoch": 8.209404045926735,
      "grad_norm": 0.6517035961151123,
      "learning_rate": 1.1790595954073265e-05,
      "loss": 0.0129,
      "step": 30030
    },
    {
      "epoch": 8.212137780207764,
      "grad_norm": 0.03213105350732803,
      "learning_rate": 1.1787862219792236e-05,
      "loss": 0.0504,
      "step": 30040
    },
    {
      "epoch": 8.214871514488792,
      "grad_norm": 0.0014398301718756557,
      "learning_rate": 1.178512848551121e-05,
      "loss": 0.0193,
      "step": 30050
    },
    {
      "epoch": 8.21760524876982,
      "grad_norm": 0.03642747923731804,
      "learning_rate": 1.1782394751230181e-05,
      "loss": 0.0198,
      "step": 30060
    },
    {
      "epoch": 8.220338983050848,
      "grad_norm": 0.0033798832446336746,
      "learning_rate": 1.1779661016949153e-05,
      "loss": 0.0157,
      "step": 30070
    },
    {
      "epoch": 8.223072717331876,
      "grad_norm": 0.011873536743223667,
      "learning_rate": 1.1776927282668125e-05,
      "loss": 0.0024,
      "step": 30080
    },
    {
      "epoch": 8.225806451612904,
      "grad_norm": 0.0016556635964661837,
      "learning_rate": 1.1774193548387098e-05,
      "loss": 0.0046,
      "step": 30090
    },
    {
      "epoch": 8.22854018589393,
      "grad_norm": 1.430784821510315,
      "learning_rate": 1.177145981410607e-05,
      "loss": 0.0216,
      "step": 30100
    },
    {
      "epoch": 8.231273920174958,
      "grad_norm": 0.8130465149879456,
      "learning_rate": 1.1768726079825041e-05,
      "loss": 0.0119,
      "step": 30110
    },
    {
      "epoch": 8.234007654455986,
      "grad_norm": 91.35262298583984,
      "learning_rate": 1.1765992345544015e-05,
      "loss": 0.0466,
      "step": 30120
    },
    {
      "epoch": 8.236741388737014,
      "grad_norm": 0.002820885507389903,
      "learning_rate": 1.1763258611262986e-05,
      "loss": 0.0033,
      "step": 30130
    },
    {
      "epoch": 8.239475123018043,
      "grad_norm": 0.006949197966605425,
      "learning_rate": 1.1760524876981958e-05,
      "loss": 0.0005,
      "step": 30140
    },
    {
      "epoch": 8.24220885729907,
      "grad_norm": 0.0017037151847034693,
      "learning_rate": 1.175779114270093e-05,
      "loss": 0.0183,
      "step": 30150
    },
    {
      "epoch": 8.244942591580099,
      "grad_norm": 0.035550475120544434,
      "learning_rate": 1.1755057408419903e-05,
      "loss": 0.0057,
      "step": 30160
    },
    {
      "epoch": 8.247676325861127,
      "grad_norm": 0.6286559700965881,
      "learning_rate": 1.1752323674138875e-05,
      "loss": 0.0495,
      "step": 30170
    },
    {
      "epoch": 8.250410060142155,
      "grad_norm": 0.5531989336013794,
      "learning_rate": 1.1749589939857846e-05,
      "loss": 0.0996,
      "step": 30180
    },
    {
      "epoch": 8.253143794423183,
      "grad_norm": 0.010801787488162518,
      "learning_rate": 1.174685620557682e-05,
      "loss": 0.0005,
      "step": 30190
    },
    {
      "epoch": 8.25587752870421,
      "grad_norm": 0.018393229693174362,
      "learning_rate": 1.1744122471295791e-05,
      "loss": 0.0105,
      "step": 30200
    },
    {
      "epoch": 8.258611262985237,
      "grad_norm": 0.9762158989906311,
      "learning_rate": 1.1741388737014763e-05,
      "loss": 0.0277,
      "step": 30210
    },
    {
      "epoch": 8.261344997266265,
      "grad_norm": 0.17017564177513123,
      "learning_rate": 1.1738655002733735e-05,
      "loss": 0.0161,
      "step": 30220
    },
    {
      "epoch": 8.264078731547293,
      "grad_norm": 0.005895000416785479,
      "learning_rate": 1.1735921268452708e-05,
      "loss": 0.0314,
      "step": 30230
    },
    {
      "epoch": 8.266812465828322,
      "grad_norm": 0.008812815882265568,
      "learning_rate": 1.173318753417168e-05,
      "loss": 0.0178,
      "step": 30240
    },
    {
      "epoch": 8.26954620010935,
      "grad_norm": 0.006894158665090799,
      "learning_rate": 1.1730453799890651e-05,
      "loss": 0.008,
      "step": 30250
    },
    {
      "epoch": 8.272279934390378,
      "grad_norm": 0.5596563220024109,
      "learning_rate": 1.1727720065609625e-05,
      "loss": 0.0145,
      "step": 30260
    },
    {
      "epoch": 8.275013668671406,
      "grad_norm": 0.016496606171131134,
      "learning_rate": 1.1724986331328596e-05,
      "loss": 0.0208,
      "step": 30270
    },
    {
      "epoch": 8.277747402952434,
      "grad_norm": 0.0038487857673317194,
      "learning_rate": 1.1722252597047568e-05,
      "loss": 0.0055,
      "step": 30280
    },
    {
      "epoch": 8.28048113723346,
      "grad_norm": 0.02777712419629097,
      "learning_rate": 1.171951886276654e-05,
      "loss": 0.0085,
      "step": 30290
    },
    {
      "epoch": 8.283214871514488,
      "grad_norm": 0.06306979060173035,
      "learning_rate": 1.1716785128485513e-05,
      "loss": 0.0003,
      "step": 30300
    },
    {
      "epoch": 8.285948605795516,
      "grad_norm": 0.08034022152423859,
      "learning_rate": 1.1714051394204485e-05,
      "loss": 0.0016,
      "step": 30310
    },
    {
      "epoch": 8.288682340076544,
      "grad_norm": 0.002859006868675351,
      "learning_rate": 1.1711317659923456e-05,
      "loss": 0.0182,
      "step": 30320
    },
    {
      "epoch": 8.291416074357572,
      "grad_norm": 0.0052508399821817875,
      "learning_rate": 1.170858392564243e-05,
      "loss": 0.0461,
      "step": 30330
    },
    {
      "epoch": 8.2941498086386,
      "grad_norm": 13.355339050292969,
      "learning_rate": 1.1705850191361401e-05,
      "loss": 0.0656,
      "step": 30340
    },
    {
      "epoch": 8.296883542919629,
      "grad_norm": 0.025206254795193672,
      "learning_rate": 1.1703116457080373e-05,
      "loss": 0.001,
      "step": 30350
    },
    {
      "epoch": 8.299617277200657,
      "grad_norm": 0.10162276029586792,
      "learning_rate": 1.1700382722799345e-05,
      "loss": 0.0875,
      "step": 30360
    },
    {
      "epoch": 8.302351011481685,
      "grad_norm": 0.03569604456424713,
      "learning_rate": 1.1697648988518318e-05,
      "loss": 0.0022,
      "step": 30370
    },
    {
      "epoch": 8.305084745762711,
      "grad_norm": 0.029255911707878113,
      "learning_rate": 1.169491525423729e-05,
      "loss": 0.0416,
      "step": 30380
    },
    {
      "epoch": 8.30781848004374,
      "grad_norm": 0.03739549592137337,
      "learning_rate": 1.1692181519956261e-05,
      "loss": 0.0009,
      "step": 30390
    },
    {
      "epoch": 8.310552214324767,
      "grad_norm": 0.2088814377784729,
      "learning_rate": 1.1689447785675235e-05,
      "loss": 0.0038,
      "step": 30400
    },
    {
      "epoch": 8.313285948605795,
      "grad_norm": 0.2021428793668747,
      "learning_rate": 1.1686714051394206e-05,
      "loss": 0.0249,
      "step": 30410
    },
    {
      "epoch": 8.316019682886823,
      "grad_norm": 0.0042531914077699184,
      "learning_rate": 1.1683980317113178e-05,
      "loss": 0.0062,
      "step": 30420
    },
    {
      "epoch": 8.318753417167851,
      "grad_norm": 0.47356200218200684,
      "learning_rate": 1.1681246582832148e-05,
      "loss": 0.0134,
      "step": 30430
    },
    {
      "epoch": 8.32148715144888,
      "grad_norm": 0.013496441766619682,
      "learning_rate": 1.1678512848551123e-05,
      "loss": 0.001,
      "step": 30440
    },
    {
      "epoch": 8.324220885729908,
      "grad_norm": 0.002424567472189665,
      "learning_rate": 1.1675779114270095e-05,
      "loss": 0.0137,
      "step": 30450
    },
    {
      "epoch": 8.326954620010936,
      "grad_norm": 0.10962805896997452,
      "learning_rate": 1.1673045379989065e-05,
      "loss": 0.0464,
      "step": 30460
    },
    {
      "epoch": 8.329688354291962,
      "grad_norm": 0.005265838000923395,
      "learning_rate": 1.167031164570804e-05,
      "loss": 0.0012,
      "step": 30470
    },
    {
      "epoch": 8.33242208857299,
      "grad_norm": 0.0036191619001328945,
      "learning_rate": 1.1667577911427011e-05,
      "loss": 0.0003,
      "step": 30480
    },
    {
      "epoch": 8.335155822854018,
      "grad_norm": 0.003177525708451867,
      "learning_rate": 1.1664844177145981e-05,
      "loss": 0.0041,
      "step": 30490
    },
    {
      "epoch": 8.337889557135046,
      "grad_norm": 2.7225635051727295,
      "learning_rate": 1.1662110442864953e-05,
      "loss": 0.0246,
      "step": 30500
    },
    {
      "epoch": 8.340623291416074,
      "grad_norm": 0.006346490234136581,
      "learning_rate": 1.1659376708583928e-05,
      "loss": 0.0028,
      "step": 30510
    },
    {
      "epoch": 8.343357025697102,
      "grad_norm": 0.23025380074977875,
      "learning_rate": 1.1656642974302898e-05,
      "loss": 0.0026,
      "step": 30520
    },
    {
      "epoch": 8.34609075997813,
      "grad_norm": 0.07185555249452591,
      "learning_rate": 1.165390924002187e-05,
      "loss": 0.0358,
      "step": 30530
    },
    {
      "epoch": 8.348824494259159,
      "grad_norm": 0.002059255726635456,
      "learning_rate": 1.1651175505740845e-05,
      "loss": 0.0223,
      "step": 30540
    },
    {
      "epoch": 8.351558228540187,
      "grad_norm": 6.167842388153076,
      "learning_rate": 1.1648441771459815e-05,
      "loss": 0.0082,
      "step": 30550
    },
    {
      "epoch": 8.354291962821215,
      "grad_norm": 0.0024097950663417578,
      "learning_rate": 1.1645708037178786e-05,
      "loss": 0.0034,
      "step": 30560
    },
    {
      "epoch": 8.357025697102241,
      "grad_norm": 0.004458478186279535,
      "learning_rate": 1.1642974302897758e-05,
      "loss": 0.0493,
      "step": 30570
    },
    {
      "epoch": 8.359759431383269,
      "grad_norm": 0.04456020146608353,
      "learning_rate": 1.1640240568616731e-05,
      "loss": 0.0191,
      "step": 30580
    },
    {
      "epoch": 8.362493165664297,
      "grad_norm": 0.7038325071334839,
      "learning_rate": 1.1637506834335703e-05,
      "loss": 0.0047,
      "step": 30590
    },
    {
      "epoch": 8.365226899945325,
      "grad_norm": 0.0212368443608284,
      "learning_rate": 1.1634773100054675e-05,
      "loss": 0.0213,
      "step": 30600
    },
    {
      "epoch": 8.367960634226353,
      "grad_norm": 0.0076964059844613075,
      "learning_rate": 1.1632039365773648e-05,
      "loss": 0.0204,
      "step": 30610
    },
    {
      "epoch": 8.370694368507381,
      "grad_norm": 1.7751742601394653,
      "learning_rate": 1.162930563149262e-05,
      "loss": 0.0506,
      "step": 30620
    },
    {
      "epoch": 8.37342810278841,
      "grad_norm": 1.362044334411621,
      "learning_rate": 1.1626571897211591e-05,
      "loss": 0.0199,
      "step": 30630
    },
    {
      "epoch": 8.376161837069438,
      "grad_norm": 2.558009624481201,
      "learning_rate": 1.1623838162930563e-05,
      "loss": 0.0174,
      "step": 30640
    },
    {
      "epoch": 8.378895571350466,
      "grad_norm": 0.009286432527005672,
      "learning_rate": 1.1621104428649536e-05,
      "loss": 0.0141,
      "step": 30650
    },
    {
      "epoch": 8.381629305631492,
      "grad_norm": 1.2712948322296143,
      "learning_rate": 1.1618370694368508e-05,
      "loss": 0.0105,
      "step": 30660
    },
    {
      "epoch": 8.38436303991252,
      "grad_norm": 0.003564240410923958,
      "learning_rate": 1.161563696008748e-05,
      "loss": 0.0051,
      "step": 30670
    },
    {
      "epoch": 8.387096774193548,
      "grad_norm": 0.0030244719237089157,
      "learning_rate": 1.1612903225806453e-05,
      "loss": 0.0031,
      "step": 30680
    },
    {
      "epoch": 8.389830508474576,
      "grad_norm": 0.004326226655393839,
      "learning_rate": 1.1610169491525424e-05,
      "loss": 0.0255,
      "step": 30690
    },
    {
      "epoch": 8.392564242755604,
      "grad_norm": 0.004672128241509199,
      "learning_rate": 1.1607435757244396e-05,
      "loss": 0.0004,
      "step": 30700
    },
    {
      "epoch": 8.395297977036632,
      "grad_norm": 0.003871985711157322,
      "learning_rate": 1.160470202296337e-05,
      "loss": 0.0318,
      "step": 30710
    },
    {
      "epoch": 8.39803171131766,
      "grad_norm": 0.0032640343997627497,
      "learning_rate": 1.1601968288682341e-05,
      "loss": 0.0146,
      "step": 30720
    },
    {
      "epoch": 8.400765445598688,
      "grad_norm": 0.004333929158747196,
      "learning_rate": 1.1599234554401313e-05,
      "loss": 0.0178,
      "step": 30730
    },
    {
      "epoch": 8.403499179879717,
      "grad_norm": 0.004236631561070681,
      "learning_rate": 1.1596500820120284e-05,
      "loss": 0.0002,
      "step": 30740
    },
    {
      "epoch": 8.406232914160743,
      "grad_norm": 0.1692284643650055,
      "learning_rate": 1.1593767085839258e-05,
      "loss": 0.006,
      "step": 30750
    },
    {
      "epoch": 8.40896664844177,
      "grad_norm": 0.006532553117722273,
      "learning_rate": 1.159103335155823e-05,
      "loss": 0.0002,
      "step": 30760
    },
    {
      "epoch": 8.411700382722799,
      "grad_norm": 0.002765993820503354,
      "learning_rate": 1.1588299617277201e-05,
      "loss": 0.0001,
      "step": 30770
    },
    {
      "epoch": 8.414434117003827,
      "grad_norm": 0.002307693939656019,
      "learning_rate": 1.1585565882996174e-05,
      "loss": 0.0039,
      "step": 30780
    },
    {
      "epoch": 8.417167851284855,
      "grad_norm": 0.004064472392201424,
      "learning_rate": 1.1582832148715146e-05,
      "loss": 0.0026,
      "step": 30790
    },
    {
      "epoch": 8.419901585565883,
      "grad_norm": 0.0021682237274944782,
      "learning_rate": 1.1580098414434118e-05,
      "loss": 0.0394,
      "step": 30800
    },
    {
      "epoch": 8.422635319846911,
      "grad_norm": 0.0018611974082887173,
      "learning_rate": 1.157736468015309e-05,
      "loss": 0.0083,
      "step": 30810
    },
    {
      "epoch": 8.42536905412794,
      "grad_norm": 0.0029403851367533207,
      "learning_rate": 1.1574630945872063e-05,
      "loss": 0.0039,
      "step": 30820
    },
    {
      "epoch": 8.428102788408967,
      "grad_norm": 0.00182901113294065,
      "learning_rate": 1.1571897211591034e-05,
      "loss": 0.0384,
      "step": 30830
    },
    {
      "epoch": 8.430836522689994,
      "grad_norm": 0.0020828107371926308,
      "learning_rate": 1.1569163477310006e-05,
      "loss": 0.0002,
      "step": 30840
    },
    {
      "epoch": 8.433570256971022,
      "grad_norm": 0.0022120648063719273,
      "learning_rate": 1.156642974302898e-05,
      "loss": 0.002,
      "step": 30850
    },
    {
      "epoch": 8.43630399125205,
      "grad_norm": 0.0018418445251882076,
      "learning_rate": 1.1563696008747951e-05,
      "loss": 0.0292,
      "step": 30860
    },
    {
      "epoch": 8.439037725533078,
      "grad_norm": 0.018956411629915237,
      "learning_rate": 1.1560962274466923e-05,
      "loss": 0.0007,
      "step": 30870
    },
    {
      "epoch": 8.441771459814106,
      "grad_norm": 0.004646657034754753,
      "learning_rate": 1.1558228540185894e-05,
      "loss": 0.001,
      "step": 30880
    },
    {
      "epoch": 8.444505194095134,
      "grad_norm": 0.0023146725725382566,
      "learning_rate": 1.1555494805904868e-05,
      "loss": 0.0205,
      "step": 30890
    },
    {
      "epoch": 8.447238928376162,
      "grad_norm": 1.9286385774612427,
      "learning_rate": 1.155276107162384e-05,
      "loss": 0.0103,
      "step": 30900
    },
    {
      "epoch": 8.44997266265719,
      "grad_norm": 29.696414947509766,
      "learning_rate": 1.1550027337342811e-05,
      "loss": 0.0336,
      "step": 30910
    },
    {
      "epoch": 8.452706396938218,
      "grad_norm": 0.009458198212087154,
      "learning_rate": 1.1547293603061784e-05,
      "loss": 0.0002,
      "step": 30920
    },
    {
      "epoch": 8.455440131219245,
      "grad_norm": 0.001597339054569602,
      "learning_rate": 1.1544559868780756e-05,
      "loss": 0.0169,
      "step": 30930
    },
    {
      "epoch": 8.458173865500273,
      "grad_norm": 0.003216484561562538,
      "learning_rate": 1.1541826134499728e-05,
      "loss": 0.0452,
      "step": 30940
    },
    {
      "epoch": 8.4609075997813,
      "grad_norm": 0.0021321019157767296,
      "learning_rate": 1.15390924002187e-05,
      "loss": 0.002,
      "step": 30950
    },
    {
      "epoch": 8.463641334062329,
      "grad_norm": 0.004589509218931198,
      "learning_rate": 1.1536358665937673e-05,
      "loss": 0.0194,
      "step": 30960
    },
    {
      "epoch": 8.466375068343357,
      "grad_norm": 0.007954043336212635,
      "learning_rate": 1.1533624931656644e-05,
      "loss": 0.0004,
      "step": 30970
    },
    {
      "epoch": 8.469108802624385,
      "grad_norm": 0.010923025198280811,
      "learning_rate": 1.1530891197375616e-05,
      "loss": 0.0006,
      "step": 30980
    },
    {
      "epoch": 8.471842536905413,
      "grad_norm": 0.01528832595795393,
      "learning_rate": 1.152815746309459e-05,
      "loss": 0.0041,
      "step": 30990
    },
    {
      "epoch": 8.474576271186441,
      "grad_norm": 0.006072592921555042,
      "learning_rate": 1.1525423728813561e-05,
      "loss": 0.0338,
      "step": 31000
    },
    {
      "epoch": 8.47731000546747,
      "grad_norm": 0.36717489361763,
      "learning_rate": 1.1522689994532533e-05,
      "loss": 0.0019,
      "step": 31010
    },
    {
      "epoch": 8.480043739748496,
      "grad_norm": 0.03514929115772247,
      "learning_rate": 1.1519956260251504e-05,
      "loss": 0.0055,
      "step": 31020
    },
    {
      "epoch": 8.482777474029524,
      "grad_norm": 0.0026664696633815765,
      "learning_rate": 1.1517222525970478e-05,
      "loss": 0.0329,
      "step": 31030
    },
    {
      "epoch": 8.485511208310552,
      "grad_norm": 0.04555989429354668,
      "learning_rate": 1.151448879168945e-05,
      "loss": 0.0066,
      "step": 31040
    },
    {
      "epoch": 8.48824494259158,
      "grad_norm": 0.010947653092443943,
      "learning_rate": 1.1511755057408421e-05,
      "loss": 0.0513,
      "step": 31050
    },
    {
      "epoch": 8.490978676872608,
      "grad_norm": 0.019032040610909462,
      "learning_rate": 1.1509021323127394e-05,
      "loss": 0.0185,
      "step": 31060
    },
    {
      "epoch": 8.493712411153636,
      "grad_norm": 0.022750237956643105,
      "learning_rate": 1.1506287588846366e-05,
      "loss": 0.0206,
      "step": 31070
    },
    {
      "epoch": 8.496446145434664,
      "grad_norm": 0.01519028190523386,
      "learning_rate": 1.1503553854565338e-05,
      "loss": 0.0233,
      "step": 31080
    },
    {
      "epoch": 8.499179879715692,
      "grad_norm": 0.11369553208351135,
      "learning_rate": 1.1500820120284308e-05,
      "loss": 0.013,
      "step": 31090
    },
    {
      "epoch": 8.50191361399672,
      "grad_norm": 0.09019782394170761,
      "learning_rate": 1.1498086386003283e-05,
      "loss": 0.009,
      "step": 31100
    },
    {
      "epoch": 8.504647348277746,
      "grad_norm": 0.0031474970746785402,
      "learning_rate": 1.1495352651722254e-05,
      "loss": 0.0061,
      "step": 31110
    },
    {
      "epoch": 8.507381082558775,
      "grad_norm": 0.0049755387008190155,
      "learning_rate": 1.1492618917441224e-05,
      "loss": 0.0078,
      "step": 31120
    },
    {
      "epoch": 8.510114816839803,
      "grad_norm": 0.00210521649569273,
      "learning_rate": 1.14898851831602e-05,
      "loss": 0.0013,
      "step": 31130
    },
    {
      "epoch": 8.51284855112083,
      "grad_norm": 0.002097382443025708,
      "learning_rate": 1.1487151448879171e-05,
      "loss": 0.0,
      "step": 31140
    },
    {
      "epoch": 8.515582285401859,
      "grad_norm": 0.01969725638628006,
      "learning_rate": 1.1484417714598141e-05,
      "loss": 0.1018,
      "step": 31150
    },
    {
      "epoch": 8.518316019682887,
      "grad_norm": 0.039743680506944656,
      "learning_rate": 1.1481683980317113e-05,
      "loss": 0.0139,
      "step": 31160
    },
    {
      "epoch": 8.521049753963915,
      "grad_norm": 0.04714018851518631,
      "learning_rate": 1.1478950246036088e-05,
      "loss": 0.0074,
      "step": 31170
    },
    {
      "epoch": 8.523783488244943,
      "grad_norm": 0.012143346481025219,
      "learning_rate": 1.1476216511755058e-05,
      "loss": 0.0345,
      "step": 31180
    },
    {
      "epoch": 8.526517222525971,
      "grad_norm": 1.7906956672668457,
      "learning_rate": 1.147348277747403e-05,
      "loss": 0.0322,
      "step": 31190
    },
    {
      "epoch": 8.529250956807,
      "grad_norm": 0.053100984543561935,
      "learning_rate": 1.1470749043193004e-05,
      "loss": 0.0267,
      "step": 31200
    },
    {
      "epoch": 8.531984691088025,
      "grad_norm": 0.34172073006629944,
      "learning_rate": 1.1468015308911974e-05,
      "loss": 0.0027,
      "step": 31210
    },
    {
      "epoch": 8.534718425369054,
      "grad_norm": 0.011639359407126904,
      "learning_rate": 1.1465281574630946e-05,
      "loss": 0.0072,
      "step": 31220
    },
    {
      "epoch": 8.537452159650082,
      "grad_norm": 0.00763426860794425,
      "learning_rate": 1.1462547840349918e-05,
      "loss": 0.0051,
      "step": 31230
    },
    {
      "epoch": 8.54018589393111,
      "grad_norm": 0.006241465453058481,
      "learning_rate": 1.1459814106068891e-05,
      "loss": 0.0226,
      "step": 31240
    },
    {
      "epoch": 8.542919628212138,
      "grad_norm": 0.006662500556558371,
      "learning_rate": 1.1457080371787863e-05,
      "loss": 0.0006,
      "step": 31250
    },
    {
      "epoch": 8.545653362493166,
      "grad_norm": 0.004068135283887386,
      "learning_rate": 1.1454346637506834e-05,
      "loss": 0.0031,
      "step": 31260
    },
    {
      "epoch": 8.548387096774194,
      "grad_norm": 0.003991462290287018,
      "learning_rate": 1.1451612903225808e-05,
      "loss": 0.0004,
      "step": 31270
    },
    {
      "epoch": 8.551120831055222,
      "grad_norm": 0.004638977348804474,
      "learning_rate": 1.144887916894478e-05,
      "loss": 0.0387,
      "step": 31280
    },
    {
      "epoch": 8.55385456533625,
      "grad_norm": 0.004636368714272976,
      "learning_rate": 1.1446145434663751e-05,
      "loss": 0.0202,
      "step": 31290
    },
    {
      "epoch": 8.556588299617276,
      "grad_norm": 0.12227194011211395,
      "learning_rate": 1.1443411700382723e-05,
      "loss": 0.0386,
      "step": 31300
    },
    {
      "epoch": 8.559322033898304,
      "grad_norm": 0.021822543814778328,
      "learning_rate": 1.1440677966101696e-05,
      "loss": 0.0183,
      "step": 31310
    },
    {
      "epoch": 8.562055768179333,
      "grad_norm": 0.17042194306850433,
      "learning_rate": 1.1437944231820668e-05,
      "loss": 0.0007,
      "step": 31320
    },
    {
      "epoch": 8.56478950246036,
      "grad_norm": 0.010384229011833668,
      "learning_rate": 1.143521049753964e-05,
      "loss": 0.0004,
      "step": 31330
    },
    {
      "epoch": 8.567523236741389,
      "grad_norm": 0.01907271519303322,
      "learning_rate": 1.1432476763258613e-05,
      "loss": 0.0089,
      "step": 31340
    },
    {
      "epoch": 8.570256971022417,
      "grad_norm": 0.004324676003307104,
      "learning_rate": 1.1429743028977584e-05,
      "loss": 0.0092,
      "step": 31350
    },
    {
      "epoch": 8.572990705303445,
      "grad_norm": 0.007199278101325035,
      "learning_rate": 1.1427009294696556e-05,
      "loss": 0.0592,
      "step": 31360
    },
    {
      "epoch": 8.575724439584473,
      "grad_norm": 0.33085936307907104,
      "learning_rate": 1.1424275560415528e-05,
      "loss": 0.0073,
      "step": 31370
    },
    {
      "epoch": 8.578458173865501,
      "grad_norm": 0.03686036914587021,
      "learning_rate": 1.1421541826134501e-05,
      "loss": 0.0016,
      "step": 31380
    },
    {
      "epoch": 8.581191908146527,
      "grad_norm": 0.020000988617539406,
      "learning_rate": 1.1418808091853473e-05,
      "loss": 0.0067,
      "step": 31390
    },
    {
      "epoch": 8.583925642427555,
      "grad_norm": 0.004956032615154982,
      "learning_rate": 1.1416074357572444e-05,
      "loss": 0.0036,
      "step": 31400
    },
    {
      "epoch": 8.586659376708583,
      "grad_norm": 0.0031357239931821823,
      "learning_rate": 1.1413340623291418e-05,
      "loss": 0.0375,
      "step": 31410
    },
    {
      "epoch": 8.589393110989612,
      "grad_norm": 0.0017584717134013772,
      "learning_rate": 1.141060688901039e-05,
      "loss": 0.0013,
      "step": 31420
    },
    {
      "epoch": 8.59212684527064,
      "grad_norm": 0.12276598066091537,
      "learning_rate": 1.1407873154729361e-05,
      "loss": 0.0145,
      "step": 31430
    },
    {
      "epoch": 8.594860579551668,
      "grad_norm": 0.00416064728051424,
      "learning_rate": 1.1405139420448333e-05,
      "loss": 0.0067,
      "step": 31440
    },
    {
      "epoch": 8.597594313832696,
      "grad_norm": 0.010290821082890034,
      "learning_rate": 1.1402405686167306e-05,
      "loss": 0.0007,
      "step": 31450
    },
    {
      "epoch": 8.600328048113724,
      "grad_norm": 0.001959494547918439,
      "learning_rate": 1.1399671951886278e-05,
      "loss": 0.0024,
      "step": 31460
    },
    {
      "epoch": 8.603061782394752,
      "grad_norm": 1.4320234060287476,
      "learning_rate": 1.139693821760525e-05,
      "loss": 0.0412,
      "step": 31470
    },
    {
      "epoch": 8.60579551667578,
      "grad_norm": 0.11376190930604935,
      "learning_rate": 1.1394204483324223e-05,
      "loss": 0.0001,
      "step": 31480
    },
    {
      "epoch": 8.608529250956806,
      "grad_norm": 1.4771760702133179,
      "learning_rate": 1.1391470749043194e-05,
      "loss": 0.0188,
      "step": 31490
    },
    {
      "epoch": 8.611262985237834,
      "grad_norm": 0.0020880012307316065,
      "learning_rate": 1.1388737014762166e-05,
      "loss": 0.0191,
      "step": 31500
    },
    {
      "epoch": 8.613996719518862,
      "grad_norm": 1.5133607387542725,
      "learning_rate": 1.1386003280481138e-05,
      "loss": 0.0147,
      "step": 31510
    },
    {
      "epoch": 8.61673045379989,
      "grad_norm": 0.0024438865948468447,
      "learning_rate": 1.1383269546200111e-05,
      "loss": 0.0139,
      "step": 31520
    },
    {
      "epoch": 8.619464188080919,
      "grad_norm": 0.01926754228770733,
      "learning_rate": 1.1380535811919083e-05,
      "loss": 0.0101,
      "step": 31530
    },
    {
      "epoch": 8.622197922361947,
      "grad_norm": 0.05141779035329819,
      "learning_rate": 1.1377802077638054e-05,
      "loss": 0.0108,
      "step": 31540
    },
    {
      "epoch": 8.624931656642975,
      "grad_norm": 0.00603740056976676,
      "learning_rate": 1.1375068343357028e-05,
      "loss": 0.0326,
      "step": 31550
    },
    {
      "epoch": 8.627665390924003,
      "grad_norm": 0.0023403188679367304,
      "learning_rate": 1.1372334609076e-05,
      "loss": 0.0025,
      "step": 31560
    },
    {
      "epoch": 8.630399125205031,
      "grad_norm": 1.3779102563858032,
      "learning_rate": 1.1369600874794971e-05,
      "loss": 0.0055,
      "step": 31570
    },
    {
      "epoch": 8.633132859486057,
      "grad_norm": 0.004460358526557684,
      "learning_rate": 1.1366867140513943e-05,
      "loss": 0.0116,
      "step": 31580
    },
    {
      "epoch": 8.635866593767085,
      "grad_norm": 0.0021004744339734316,
      "learning_rate": 1.1364133406232916e-05,
      "loss": 0.0123,
      "step": 31590
    },
    {
      "epoch": 8.638600328048113,
      "grad_norm": 0.004599106032401323,
      "learning_rate": 1.1361399671951888e-05,
      "loss": 0.0266,
      "step": 31600
    },
    {
      "epoch": 8.641334062329141,
      "grad_norm": 0.04358089342713356,
      "learning_rate": 1.135866593767086e-05,
      "loss": 0.0007,
      "step": 31610
    },
    {
      "epoch": 8.64406779661017,
      "grad_norm": 0.8088576197624207,
      "learning_rate": 1.1355932203389833e-05,
      "loss": 0.0034,
      "step": 31620
    },
    {
      "epoch": 8.646801530891198,
      "grad_norm": 0.17368486523628235,
      "learning_rate": 1.1353198469108804e-05,
      "loss": 0.0061,
      "step": 31630
    },
    {
      "epoch": 8.649535265172226,
      "grad_norm": 6.930548191070557,
      "learning_rate": 1.1350464734827776e-05,
      "loss": 0.0019,
      "step": 31640
    },
    {
      "epoch": 8.652268999453254,
      "grad_norm": 0.8070058822631836,
      "learning_rate": 1.1347731000546747e-05,
      "loss": 0.0199,
      "step": 31650
    },
    {
      "epoch": 8.655002733734282,
      "grad_norm": 0.010624956339597702,
      "learning_rate": 1.134499726626572e-05,
      "loss": 0.0038,
      "step": 31660
    },
    {
      "epoch": 8.657736468015308,
      "grad_norm": 12.545906066894531,
      "learning_rate": 1.1342263531984693e-05,
      "loss": 0.0323,
      "step": 31670
    },
    {
      "epoch": 8.660470202296336,
      "grad_norm": 0.029357077553868294,
      "learning_rate": 1.1339529797703664e-05,
      "loss": 0.0413,
      "step": 31680
    },
    {
      "epoch": 8.663203936577364,
      "grad_norm": 0.046070199459791183,
      "learning_rate": 1.1336796063422638e-05,
      "loss": 0.0009,
      "step": 31690
    },
    {
      "epoch": 8.665937670858392,
      "grad_norm": 0.006329576019197702,
      "learning_rate": 1.133406232914161e-05,
      "loss": 0.0275,
      "step": 31700
    },
    {
      "epoch": 8.66867140513942,
      "grad_norm": 0.02260521799325943,
      "learning_rate": 1.133132859486058e-05,
      "loss": 0.0006,
      "step": 31710
    },
    {
      "epoch": 8.671405139420449,
      "grad_norm": 3.3414437770843506,
      "learning_rate": 1.132859486057955e-05,
      "loss": 0.0269,
      "step": 31720
    },
    {
      "epoch": 8.674138873701477,
      "grad_norm": 0.2253698855638504,
      "learning_rate": 1.1325861126298526e-05,
      "loss": 0.0031,
      "step": 31730
    },
    {
      "epoch": 8.676872607982505,
      "grad_norm": 0.0015951386885717511,
      "learning_rate": 1.1323127392017497e-05,
      "loss": 0.0071,
      "step": 31740
    },
    {
      "epoch": 8.679606342263533,
      "grad_norm": 0.0023980592377483845,
      "learning_rate": 1.1320393657736467e-05,
      "loss": 0.0392,
      "step": 31750
    },
    {
      "epoch": 8.682340076544559,
      "grad_norm": 0.0039976523257792,
      "learning_rate": 1.1317659923455442e-05,
      "loss": 0.0067,
      "step": 31760
    },
    {
      "epoch": 8.685073810825587,
      "grad_norm": 35.065853118896484,
      "learning_rate": 1.1314926189174414e-05,
      "loss": 0.0211,
      "step": 31770
    },
    {
      "epoch": 8.687807545106615,
      "grad_norm": 0.2781510651111603,
      "learning_rate": 1.1312192454893384e-05,
      "loss": 0.0107,
      "step": 31780
    },
    {
      "epoch": 8.690541279387643,
      "grad_norm": 0.10871096700429916,
      "learning_rate": 1.1309458720612359e-05,
      "loss": 0.0109,
      "step": 31790
    },
    {
      "epoch": 8.693275013668671,
      "grad_norm": 0.0013098377967253327,
      "learning_rate": 1.130672498633133e-05,
      "loss": 0.0044,
      "step": 31800
    },
    {
      "epoch": 8.6960087479497,
      "grad_norm": 0.0010680386330932379,
      "learning_rate": 1.13039912520503e-05,
      "loss": 0.006,
      "step": 31810
    },
    {
      "epoch": 8.698742482230728,
      "grad_norm": 0.01751423440873623,
      "learning_rate": 1.1301257517769272e-05,
      "loss": 0.0045,
      "step": 31820
    },
    {
      "epoch": 8.701476216511756,
      "grad_norm": 0.00092416099505499,
      "learning_rate": 1.1298523783488247e-05,
      "loss": 0.0241,
      "step": 31830
    },
    {
      "epoch": 8.704209950792784,
      "grad_norm": 0.6756513118743896,
      "learning_rate": 1.1295790049207217e-05,
      "loss": 0.0065,
      "step": 31840
    },
    {
      "epoch": 8.70694368507381,
      "grad_norm": 0.1596541702747345,
      "learning_rate": 1.1293056314926189e-05,
      "loss": 0.0318,
      "step": 31850
    },
    {
      "epoch": 8.709677419354838,
      "grad_norm": 3.0115089416503906,
      "learning_rate": 1.1290322580645164e-05,
      "loss": 0.0413,
      "step": 31860
    },
    {
      "epoch": 8.712411153635866,
      "grad_norm": 0.005596805829554796,
      "learning_rate": 1.1287588846364134e-05,
      "loss": 0.0003,
      "step": 31870
    },
    {
      "epoch": 8.715144887916894,
      "grad_norm": 0.003906619735062122,
      "learning_rate": 1.1284855112083106e-05,
      "loss": 0.0205,
      "step": 31880
    },
    {
      "epoch": 8.717878622197922,
      "grad_norm": 0.003947626333683729,
      "learning_rate": 1.1282121377802077e-05,
      "loss": 0.042,
      "step": 31890
    },
    {
      "epoch": 8.72061235647895,
      "grad_norm": 0.00497117405757308,
      "learning_rate": 1.127938764352105e-05,
      "loss": 0.0084,
      "step": 31900
    },
    {
      "epoch": 8.723346090759978,
      "grad_norm": 1.3845325708389282,
      "learning_rate": 1.1276653909240022e-05,
      "loss": 0.0043,
      "step": 31910
    },
    {
      "epoch": 8.726079825041007,
      "grad_norm": 0.15618963539600372,
      "learning_rate": 1.1273920174958994e-05,
      "loss": 0.0132,
      "step": 31920
    },
    {
      "epoch": 8.728813559322035,
      "grad_norm": 2.2228503227233887,
      "learning_rate": 1.1271186440677967e-05,
      "loss": 0.0671,
      "step": 31930
    },
    {
      "epoch": 8.731547293603061,
      "grad_norm": 0.003856668248772621,
      "learning_rate": 1.1268452706396939e-05,
      "loss": 0.0002,
      "step": 31940
    },
    {
      "epoch": 8.734281027884089,
      "grad_norm": 0.28186121582984924,
      "learning_rate": 1.126571897211591e-05,
      "loss": 0.0006,
      "step": 31950
    },
    {
      "epoch": 8.737014762165117,
      "grad_norm": 10.662039756774902,
      "learning_rate": 1.1262985237834882e-05,
      "loss": 0.0208,
      "step": 31960
    },
    {
      "epoch": 8.739748496446145,
      "grad_norm": 0.06072007492184639,
      "learning_rate": 1.1260251503553856e-05,
      "loss": 0.0014,
      "step": 31970
    },
    {
      "epoch": 8.742482230727173,
      "grad_norm": 0.0028348222840577364,
      "learning_rate": 1.1257517769272827e-05,
      "loss": 0.009,
      "step": 31980
    },
    {
      "epoch": 8.745215965008201,
      "grad_norm": 0.0024828496389091015,
      "learning_rate": 1.1254784034991799e-05,
      "loss": 0.0258,
      "step": 31990
    },
    {
      "epoch": 8.74794969928923,
      "grad_norm": 0.5833694934844971,
      "learning_rate": 1.1252050300710772e-05,
      "loss": 0.0557,
      "step": 32000
    },
    {
      "epoch": 8.750683433570257,
      "grad_norm": 0.01248702872544527,
      "learning_rate": 1.1249316566429744e-05,
      "loss": 0.0204,
      "step": 32010
    },
    {
      "epoch": 8.753417167851286,
      "grad_norm": 0.008808013051748276,
      "learning_rate": 1.1246582832148716e-05,
      "loss": 0.0039,
      "step": 32020
    },
    {
      "epoch": 8.756150902132312,
      "grad_norm": 0.011830093339085579,
      "learning_rate": 1.1243849097867687e-05,
      "loss": 0.0091,
      "step": 32030
    },
    {
      "epoch": 8.75888463641334,
      "grad_norm": 0.0157542135566473,
      "learning_rate": 1.124111536358666e-05,
      "loss": 0.0037,
      "step": 32040
    },
    {
      "epoch": 8.761618370694368,
      "grad_norm": 0.0043005864135921,
      "learning_rate": 1.1238381629305632e-05,
      "loss": 0.0051,
      "step": 32050
    },
    {
      "epoch": 8.764352104975396,
      "grad_norm": 1.112308382987976,
      "learning_rate": 1.1235647895024604e-05,
      "loss": 0.0045,
      "step": 32060
    },
    {
      "epoch": 8.767085839256424,
      "grad_norm": 0.03668712452054024,
      "learning_rate": 1.1232914160743577e-05,
      "loss": 0.0213,
      "step": 32070
    },
    {
      "epoch": 8.769819573537452,
      "grad_norm": 0.0028232771437615156,
      "learning_rate": 1.1230180426462549e-05,
      "loss": 0.0106,
      "step": 32080
    },
    {
      "epoch": 8.77255330781848,
      "grad_norm": 0.04980962723493576,
      "learning_rate": 1.122744669218152e-05,
      "loss": 0.0134,
      "step": 32090
    },
    {
      "epoch": 8.775287042099508,
      "grad_norm": 0.009507078677415848,
      "learning_rate": 1.1224712957900492e-05,
      "loss": 0.0008,
      "step": 32100
    },
    {
      "epoch": 8.778020776380536,
      "grad_norm": 0.01359547022730112,
      "learning_rate": 1.1221979223619466e-05,
      "loss": 0.0043,
      "step": 32110
    },
    {
      "epoch": 8.780754510661563,
      "grad_norm": 0.014629248529672623,
      "learning_rate": 1.1219245489338437e-05,
      "loss": 0.0415,
      "step": 32120
    },
    {
      "epoch": 8.78348824494259,
      "grad_norm": 0.00786570180207491,
      "learning_rate": 1.1216511755057409e-05,
      "loss": 0.0116,
      "step": 32130
    },
    {
      "epoch": 8.786221979223619,
      "grad_norm": 0.004510079976171255,
      "learning_rate": 1.1213778020776382e-05,
      "loss": 0.0074,
      "step": 32140
    },
    {
      "epoch": 8.788955713504647,
      "grad_norm": 0.005287844687700272,
      "learning_rate": 1.1211044286495354e-05,
      "loss": 0.0056,
      "step": 32150
    },
    {
      "epoch": 8.791689447785675,
      "grad_norm": 0.003558607306331396,
      "learning_rate": 1.1208310552214326e-05,
      "loss": 0.002,
      "step": 32160
    },
    {
      "epoch": 8.794423182066703,
      "grad_norm": 0.0026829803828150034,
      "learning_rate": 1.1205576817933297e-05,
      "loss": 0.0017,
      "step": 32170
    },
    {
      "epoch": 8.797156916347731,
      "grad_norm": 0.6110116839408875,
      "learning_rate": 1.120284308365227e-05,
      "loss": 0.0143,
      "step": 32180
    },
    {
      "epoch": 8.79989065062876,
      "grad_norm": 3.0735104084014893,
      "learning_rate": 1.1200109349371242e-05,
      "loss": 0.0478,
      "step": 32190
    },
    {
      "epoch": 8.802624384909787,
      "grad_norm": 0.42518579959869385,
      "learning_rate": 1.1197375615090214e-05,
      "loss": 0.0015,
      "step": 32200
    },
    {
      "epoch": 8.805358119190815,
      "grad_norm": 7.649274826049805,
      "learning_rate": 1.1194641880809187e-05,
      "loss": 0.0037,
      "step": 32210
    },
    {
      "epoch": 8.808091853471842,
      "grad_norm": 0.004943597596138716,
      "learning_rate": 1.1191908146528159e-05,
      "loss": 0.0054,
      "step": 32220
    },
    {
      "epoch": 8.81082558775287,
      "grad_norm": 0.006217511370778084,
      "learning_rate": 1.118917441224713e-05,
      "loss": 0.0004,
      "step": 32230
    },
    {
      "epoch": 8.813559322033898,
      "grad_norm": 0.008160336874425411,
      "learning_rate": 1.1186440677966102e-05,
      "loss": 0.0049,
      "step": 32240
    },
    {
      "epoch": 8.816293056314926,
      "grad_norm": 0.008153468370437622,
      "learning_rate": 1.1183706943685076e-05,
      "loss": 0.0001,
      "step": 32250
    },
    {
      "epoch": 8.819026790595954,
      "grad_norm": 37.59159469604492,
      "learning_rate": 1.1180973209404047e-05,
      "loss": 0.0437,
      "step": 32260
    },
    {
      "epoch": 8.821760524876982,
      "grad_norm": 0.003215695032849908,
      "learning_rate": 1.1178239475123019e-05,
      "loss": 0.0338,
      "step": 32270
    },
    {
      "epoch": 8.82449425915801,
      "grad_norm": 0.0075865923427045345,
      "learning_rate": 1.1175505740841992e-05,
      "loss": 0.0001,
      "step": 32280
    },
    {
      "epoch": 8.827227993439038,
      "grad_norm": 0.02286156453192234,
      "learning_rate": 1.1172772006560964e-05,
      "loss": 0.0198,
      "step": 32290
    },
    {
      "epoch": 8.829961727720066,
      "grad_norm": 0.006921761203557253,
      "learning_rate": 1.1170038272279936e-05,
      "loss": 0.0004,
      "step": 32300
    },
    {
      "epoch": 8.832695462001093,
      "grad_norm": 0.011219925247132778,
      "learning_rate": 1.1167304537998907e-05,
      "loss": 0.0272,
      "step": 32310
    },
    {
      "epoch": 8.83542919628212,
      "grad_norm": 0.00902546290308237,
      "learning_rate": 1.116457080371788e-05,
      "loss": 0.0177,
      "step": 32320
    },
    {
      "epoch": 8.838162930563149,
      "grad_norm": 0.007806756999343634,
      "learning_rate": 1.1161837069436852e-05,
      "loss": 0.0188,
      "step": 32330
    },
    {
      "epoch": 8.840896664844177,
      "grad_norm": 0.11649518460035324,
      "learning_rate": 1.1159103335155824e-05,
      "loss": 0.0004,
      "step": 32340
    },
    {
      "epoch": 8.843630399125205,
      "grad_norm": 0.014385150745511055,
      "learning_rate": 1.1156369600874797e-05,
      "loss": 0.0339,
      "step": 32350
    },
    {
      "epoch": 8.846364133406233,
      "grad_norm": 0.02957036718726158,
      "learning_rate": 1.1153635866593769e-05,
      "loss": 0.0038,
      "step": 32360
    },
    {
      "epoch": 8.849097867687261,
      "grad_norm": 0.014270593412220478,
      "learning_rate": 1.115090213231274e-05,
      "loss": 0.0138,
      "step": 32370
    },
    {
      "epoch": 8.85183160196829,
      "grad_norm": 0.011898962780833244,
      "learning_rate": 1.114816839803171e-05,
      "loss": 0.0288,
      "step": 32380
    },
    {
      "epoch": 8.854565336249317,
      "grad_norm": 0.013812331482768059,
      "learning_rate": 1.1145434663750686e-05,
      "loss": 0.004,
      "step": 32390
    },
    {
      "epoch": 8.857299070530345,
      "grad_norm": 1.4730517864227295,
      "learning_rate": 1.1142700929469657e-05,
      "loss": 0.0051,
      "step": 32400
    },
    {
      "epoch": 8.860032804811372,
      "grad_norm": 0.005519187077879906,
      "learning_rate": 1.1139967195188627e-05,
      "loss": 0.0187,
      "step": 32410
    },
    {
      "epoch": 8.8627665390924,
      "grad_norm": 0.02645358443260193,
      "learning_rate": 1.1137233460907602e-05,
      "loss": 0.0496,
      "step": 32420
    },
    {
      "epoch": 8.865500273373428,
      "grad_norm": 0.02707057259976864,
      "learning_rate": 1.1134499726626574e-05,
      "loss": 0.0013,
      "step": 32430
    },
    {
      "epoch": 8.868234007654456,
      "grad_norm": 0.02124149538576603,
      "learning_rate": 1.1131765992345544e-05,
      "loss": 0.006,
      "step": 32440
    },
    {
      "epoch": 8.870967741935484,
      "grad_norm": 0.014856577850878239,
      "learning_rate": 1.1129032258064516e-05,
      "loss": 0.0212,
      "step": 32450
    },
    {
      "epoch": 8.873701476216512,
      "grad_norm": 1.2192221879959106,
      "learning_rate": 1.112629852378349e-05,
      "loss": 0.0274,
      "step": 32460
    },
    {
      "epoch": 8.87643521049754,
      "grad_norm": 36.76214599609375,
      "learning_rate": 1.112356478950246e-05,
      "loss": 0.0156,
      "step": 32470
    },
    {
      "epoch": 8.879168944778568,
      "grad_norm": 2.0623018741607666,
      "learning_rate": 1.1120831055221432e-05,
      "loss": 0.0191,
      "step": 32480
    },
    {
      "epoch": 8.881902679059596,
      "grad_norm": 0.003900068113580346,
      "learning_rate": 1.1118097320940406e-05,
      "loss": 0.0008,
      "step": 32490
    },
    {
      "epoch": 8.884636413340623,
      "grad_norm": 0.006905202753841877,
      "learning_rate": 1.1115363586659377e-05,
      "loss": 0.0423,
      "step": 32500
    },
    {
      "epoch": 8.88737014762165,
      "grad_norm": 0.02845012955367565,
      "learning_rate": 1.1112629852378349e-05,
      "loss": 0.0007,
      "step": 32510
    },
    {
      "epoch": 8.890103881902679,
      "grad_norm": 11.038286209106445,
      "learning_rate": 1.110989611809732e-05,
      "loss": 0.019,
      "step": 32520
    },
    {
      "epoch": 8.892837616183707,
      "grad_norm": 38.97349548339844,
      "learning_rate": 1.1107162383816294e-05,
      "loss": 0.0051,
      "step": 32530
    },
    {
      "epoch": 8.895571350464735,
      "grad_norm": 0.004728458356112242,
      "learning_rate": 1.1104428649535266e-05,
      "loss": 0.0171,
      "step": 32540
    },
    {
      "epoch": 8.898305084745763,
      "grad_norm": 4.354969501495361,
      "learning_rate": 1.1101694915254237e-05,
      "loss": 0.0169,
      "step": 32550
    },
    {
      "epoch": 8.901038819026791,
      "grad_norm": 0.002899807645007968,
      "learning_rate": 1.109896118097321e-05,
      "loss": 0.0054,
      "step": 32560
    },
    {
      "epoch": 8.90377255330782,
      "grad_norm": 0.006719968281686306,
      "learning_rate": 1.1096227446692182e-05,
      "loss": 0.017,
      "step": 32570
    },
    {
      "epoch": 8.906506287588847,
      "grad_norm": 2.554574966430664,
      "learning_rate": 1.1093493712411154e-05,
      "loss": 0.0117,
      "step": 32580
    },
    {
      "epoch": 8.909240021869874,
      "grad_norm": 0.011443877592682838,
      "learning_rate": 1.1090759978130125e-05,
      "loss": 0.015,
      "step": 32590
    },
    {
      "epoch": 8.911973756150902,
      "grad_norm": 0.23997728526592255,
      "learning_rate": 1.1088026243849099e-05,
      "loss": 0.002,
      "step": 32600
    },
    {
      "epoch": 8.91470749043193,
      "grad_norm": 0.14321160316467285,
      "learning_rate": 1.108529250956807e-05,
      "loss": 0.0095,
      "step": 32610
    },
    {
      "epoch": 8.917441224712958,
      "grad_norm": 0.024264298379421234,
      "learning_rate": 1.1082558775287042e-05,
      "loss": 0.0264,
      "step": 32620
    },
    {
      "epoch": 8.920174958993986,
      "grad_norm": 0.008130071684718132,
      "learning_rate": 1.1079825041006016e-05,
      "loss": 0.0239,
      "step": 32630
    },
    {
      "epoch": 8.922908693275014,
      "grad_norm": 0.048682961612939835,
      "learning_rate": 1.1077091306724987e-05,
      "loss": 0.0298,
      "step": 32640
    },
    {
      "epoch": 8.925642427556042,
      "grad_norm": 1.5416830778121948,
      "learning_rate": 1.1074357572443959e-05,
      "loss": 0.0231,
      "step": 32650
    },
    {
      "epoch": 8.92837616183707,
      "grad_norm": 0.014272842556238174,
      "learning_rate": 1.107162383816293e-05,
      "loss": 0.0215,
      "step": 32660
    },
    {
      "epoch": 8.931109896118098,
      "grad_norm": 0.9461511969566345,
      "learning_rate": 1.1068890103881904e-05,
      "loss": 0.0192,
      "step": 32670
    },
    {
      "epoch": 8.933843630399124,
      "grad_norm": 0.004192546010017395,
      "learning_rate": 1.1066156369600875e-05,
      "loss": 0.01,
      "step": 32680
    },
    {
      "epoch": 8.936577364680153,
      "grad_norm": 0.00370988086797297,
      "learning_rate": 1.1063422635319847e-05,
      "loss": 0.0107,
      "step": 32690
    },
    {
      "epoch": 8.93931109896118,
      "grad_norm": 0.0014650617958977818,
      "learning_rate": 1.106068890103882e-05,
      "loss": 0.0208,
      "step": 32700
    },
    {
      "epoch": 8.942044833242209,
      "grad_norm": 0.0041875410825014114,
      "learning_rate": 1.1057955166757792e-05,
      "loss": 0.0084,
      "step": 32710
    },
    {
      "epoch": 8.944778567523237,
      "grad_norm": 0.0023259224835783243,
      "learning_rate": 1.1055221432476764e-05,
      "loss": 0.0144,
      "step": 32720
    },
    {
      "epoch": 8.947512301804265,
      "grad_norm": 0.0021044397726655006,
      "learning_rate": 1.1052487698195735e-05,
      "loss": 0.0001,
      "step": 32730
    },
    {
      "epoch": 8.950246036085293,
      "grad_norm": 0.004794553387910128,
      "learning_rate": 1.1049753963914709e-05,
      "loss": 0.0041,
      "step": 32740
    },
    {
      "epoch": 8.952979770366321,
      "grad_norm": 0.007628093007951975,
      "learning_rate": 1.104702022963368e-05,
      "loss": 0.0002,
      "step": 32750
    },
    {
      "epoch": 8.955713504647349,
      "grad_norm": 0.00495557626709342,
      "learning_rate": 1.1044286495352652e-05,
      "loss": 0.004,
      "step": 32760
    },
    {
      "epoch": 8.958447238928375,
      "grad_norm": 0.0009872568771243095,
      "learning_rate": 1.1041552761071625e-05,
      "loss": 0.0033,
      "step": 32770
    },
    {
      "epoch": 8.961180973209403,
      "grad_norm": 0.0015250890282914042,
      "learning_rate": 1.1038819026790597e-05,
      "loss": 0.0049,
      "step": 32780
    },
    {
      "epoch": 8.963914707490432,
      "grad_norm": 0.0011123870499432087,
      "learning_rate": 1.1036085292509569e-05,
      "loss": 0.0102,
      "step": 32790
    },
    {
      "epoch": 8.96664844177146,
      "grad_norm": 23.293996810913086,
      "learning_rate": 1.103335155822854e-05,
      "loss": 0.0089,
      "step": 32800
    },
    {
      "epoch": 8.969382176052488,
      "grad_norm": 0.0010653117205947638,
      "learning_rate": 1.1030617823947514e-05,
      "loss": 0.0015,
      "step": 32810
    },
    {
      "epoch": 8.972115910333516,
      "grad_norm": 0.0007877256139181554,
      "learning_rate": 1.1027884089666485e-05,
      "loss": 0.0455,
      "step": 32820
    },
    {
      "epoch": 8.974849644614544,
      "grad_norm": 0.0024569269735366106,
      "learning_rate": 1.1025150355385457e-05,
      "loss": 0.0222,
      "step": 32830
    },
    {
      "epoch": 8.977583378895572,
      "grad_norm": 0.0017405111575499177,
      "learning_rate": 1.102241662110443e-05,
      "loss": 0.0022,
      "step": 32840
    },
    {
      "epoch": 8.9803171131766,
      "grad_norm": 0.0010619318345561624,
      "learning_rate": 1.1019682886823402e-05,
      "loss": 0.0021,
      "step": 32850
    },
    {
      "epoch": 8.983050847457626,
      "grad_norm": 0.0008461204124614596,
      "learning_rate": 1.1016949152542374e-05,
      "loss": 0.0032,
      "step": 32860
    },
    {
      "epoch": 8.985784581738654,
      "grad_norm": 0.0012026902986690402,
      "learning_rate": 1.1014215418261347e-05,
      "loss": 0.0001,
      "step": 32870
    },
    {
      "epoch": 8.988518316019682,
      "grad_norm": 0.0010860037291422486,
      "learning_rate": 1.1011481683980319e-05,
      "loss": 0.0141,
      "step": 32880
    },
    {
      "epoch": 8.99125205030071,
      "grad_norm": 0.001708240364678204,
      "learning_rate": 1.100874794969929e-05,
      "loss": 0.0145,
      "step": 32890
    },
    {
      "epoch": 8.993985784581739,
      "grad_norm": 0.07384441792964935,
      "learning_rate": 1.1006014215418262e-05,
      "loss": 0.0012,
      "step": 32900
    },
    {
      "epoch": 8.996719518862767,
      "grad_norm": 0.0014424622058868408,
      "learning_rate": 1.1003280481137235e-05,
      "loss": 0.0322,
      "step": 32910
    },
    {
      "epoch": 8.999453253143795,
      "grad_norm": 0.02023826166987419,
      "learning_rate": 1.1000546746856207e-05,
      "loss": 0.0207,
      "step": 32920
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9921243082162622,
      "eval_f1": 0.9681993983669962,
      "eval_loss": 0.034045107662677765,
      "eval_precision": 0.9749026395499784,
      "eval_recall": 0.9615877080665813,
      "eval_runtime": 798.3615,
      "eval_samples_per_second": 23.566,
      "eval_steps_per_second": 0.982,
      "step": 32922
    },
    {
      "epoch": 9.002186987424823,
      "grad_norm": 0.0067505682818591595,
      "learning_rate": 1.0997813012575179e-05,
      "loss": 0.0132,
      "step": 32930
    },
    {
      "epoch": 9.004920721705851,
      "grad_norm": 0.0056650759652256966,
      "learning_rate": 1.0995079278294152e-05,
      "loss": 0.0025,
      "step": 32940
    },
    {
      "epoch": 9.007654455986877,
      "grad_norm": 0.0034854908008128405,
      "learning_rate": 1.0992345544013124e-05,
      "loss": 0.0037,
      "step": 32950
    },
    {
      "epoch": 9.010388190267905,
      "grad_norm": 0.019422469660639763,
      "learning_rate": 1.0989611809732095e-05,
      "loss": 0.0001,
      "step": 32960
    },
    {
      "epoch": 9.013121924548933,
      "grad_norm": 0.0015131046529859304,
      "learning_rate": 1.0986878075451067e-05,
      "loss": 0.0038,
      "step": 32970
    },
    {
      "epoch": 9.015855658829961,
      "grad_norm": 0.0015001361025497317,
      "learning_rate": 1.098414434117004e-05,
      "loss": 0.0127,
      "step": 32980
    },
    {
      "epoch": 9.01858939311099,
      "grad_norm": 0.013033540919423103,
      "learning_rate": 1.0981410606889012e-05,
      "loss": 0.0211,
      "step": 32990
    },
    {
      "epoch": 9.021323127392018,
      "grad_norm": 0.0038066389970481396,
      "learning_rate": 1.0978676872607984e-05,
      "loss": 0.028,
      "step": 33000
    },
    {
      "epoch": 9.024056861673046,
      "grad_norm": 0.006455929484218359,
      "learning_rate": 1.0975943138326957e-05,
      "loss": 0.0001,
      "step": 33010
    },
    {
      "epoch": 9.026790595954074,
      "grad_norm": 0.010480517521500587,
      "learning_rate": 1.0973209404045929e-05,
      "loss": 0.019,
      "step": 33020
    },
    {
      "epoch": 9.029524330235102,
      "grad_norm": 0.04198995232582092,
      "learning_rate": 1.09704756697649e-05,
      "loss": 0.0002,
      "step": 33030
    },
    {
      "epoch": 9.03225806451613,
      "grad_norm": 0.3260185122489929,
      "learning_rate": 1.096774193548387e-05,
      "loss": 0.0197,
      "step": 33040
    },
    {
      "epoch": 9.034991798797156,
      "grad_norm": 0.0018918297719210386,
      "learning_rate": 1.0965008201202845e-05,
      "loss": 0.0085,
      "step": 33050
    },
    {
      "epoch": 9.037725533078184,
      "grad_norm": 0.001342474133707583,
      "learning_rate": 1.0962274466921815e-05,
      "loss": 0.027,
      "step": 33060
    },
    {
      "epoch": 9.040459267359212,
      "grad_norm": 0.48728662729263306,
      "learning_rate": 1.0959540732640787e-05,
      "loss": 0.0151,
      "step": 33070
    },
    {
      "epoch": 9.04319300164024,
      "grad_norm": 0.0010270301718264818,
      "learning_rate": 1.0956806998359762e-05,
      "loss": 0.001,
      "step": 33080
    },
    {
      "epoch": 9.045926735921269,
      "grad_norm": 0.08708451688289642,
      "learning_rate": 1.0954073264078732e-05,
      "loss": 0.0012,
      "step": 33090
    },
    {
      "epoch": 9.048660470202297,
      "grad_norm": 0.0011960554402321577,
      "learning_rate": 1.0951339529797704e-05,
      "loss": 0.0035,
      "step": 33100
    },
    {
      "epoch": 9.051394204483325,
      "grad_norm": 0.0029549328610301018,
      "learning_rate": 1.0948605795516675e-05,
      "loss": 0.0,
      "step": 33110
    },
    {
      "epoch": 9.054127938764353,
      "grad_norm": 0.0009964127093553543,
      "learning_rate": 1.0945872061235649e-05,
      "loss": 0.0114,
      "step": 33120
    },
    {
      "epoch": 9.05686167304538,
      "grad_norm": 0.0009630350396037102,
      "learning_rate": 1.094313832695462e-05,
      "loss": 0.0134,
      "step": 33130
    },
    {
      "epoch": 9.059595407326407,
      "grad_norm": 0.001528876950033009,
      "learning_rate": 1.0940404592673592e-05,
      "loss": 0.0526,
      "step": 33140
    },
    {
      "epoch": 9.062329141607435,
      "grad_norm": 0.003100978210568428,
      "learning_rate": 1.0937670858392565e-05,
      "loss": 0.0149,
      "step": 33150
    },
    {
      "epoch": 9.065062875888463,
      "grad_norm": 0.5768566131591797,
      "learning_rate": 1.0934937124111537e-05,
      "loss": 0.0192,
      "step": 33160
    },
    {
      "epoch": 9.067796610169491,
      "grad_norm": 0.008071158081293106,
      "learning_rate": 1.0932203389830509e-05,
      "loss": 0.0029,
      "step": 33170
    },
    {
      "epoch": 9.07053034445052,
      "grad_norm": 2.252227544784546,
      "learning_rate": 1.092946965554948e-05,
      "loss": 0.0245,
      "step": 33180
    },
    {
      "epoch": 9.073264078731547,
      "grad_norm": 0.002597747603431344,
      "learning_rate": 1.0926735921268454e-05,
      "loss": 0.0058,
      "step": 33190
    },
    {
      "epoch": 9.075997813012576,
      "grad_norm": 0.0023385346867144108,
      "learning_rate": 1.0924002186987425e-05,
      "loss": 0.0001,
      "step": 33200
    },
    {
      "epoch": 9.078731547293604,
      "grad_norm": 0.0022583561949431896,
      "learning_rate": 1.0921268452706397e-05,
      "loss": 0.0025,
      "step": 33210
    },
    {
      "epoch": 9.081465281574632,
      "grad_norm": 0.004427652806043625,
      "learning_rate": 1.091853471842537e-05,
      "loss": 0.0139,
      "step": 33220
    },
    {
      "epoch": 9.084199015855658,
      "grad_norm": 0.00280744512565434,
      "learning_rate": 1.0915800984144342e-05,
      "loss": 0.0013,
      "step": 33230
    },
    {
      "epoch": 9.086932750136686,
      "grad_norm": 3.628042697906494,
      "learning_rate": 1.0913067249863314e-05,
      "loss": 0.0311,
      "step": 33240
    },
    {
      "epoch": 9.089666484417714,
      "grad_norm": 0.05211847648024559,
      "learning_rate": 1.0910333515582285e-05,
      "loss": 0.0006,
      "step": 33250
    },
    {
      "epoch": 9.092400218698742,
      "grad_norm": 0.0031088923569768667,
      "learning_rate": 1.0907599781301259e-05,
      "loss": 0.0006,
      "step": 33260
    },
    {
      "epoch": 9.09513395297977,
      "grad_norm": 0.5599538683891296,
      "learning_rate": 1.090486604702023e-05,
      "loss": 0.0193,
      "step": 33270
    },
    {
      "epoch": 9.097867687260798,
      "grad_norm": 22.776960372924805,
      "learning_rate": 1.0902132312739202e-05,
      "loss": 0.0122,
      "step": 33280
    },
    {
      "epoch": 9.100601421541826,
      "grad_norm": 0.004445722792297602,
      "learning_rate": 1.0899398578458175e-05,
      "loss": 0.006,
      "step": 33290
    },
    {
      "epoch": 9.103335155822855,
      "grad_norm": 1.5923352241516113,
      "learning_rate": 1.0896664844177147e-05,
      "loss": 0.035,
      "step": 33300
    },
    {
      "epoch": 9.106068890103883,
      "grad_norm": 0.001838851603679359,
      "learning_rate": 1.0893931109896119e-05,
      "loss": 0.0104,
      "step": 33310
    },
    {
      "epoch": 9.108802624384909,
      "grad_norm": 0.2928835451602936,
      "learning_rate": 1.089119737561509e-05,
      "loss": 0.0002,
      "step": 33320
    },
    {
      "epoch": 9.111536358665937,
      "grad_norm": 4.306521892547607,
      "learning_rate": 1.0888463641334064e-05,
      "loss": 0.0341,
      "step": 33330
    },
    {
      "epoch": 9.114270092946965,
      "grad_norm": 0.043681323528289795,
      "learning_rate": 1.0885729907053035e-05,
      "loss": 0.0097,
      "step": 33340
    },
    {
      "epoch": 9.117003827227993,
      "grad_norm": 8.71181583404541,
      "learning_rate": 1.0882996172772007e-05,
      "loss": 0.0212,
      "step": 33350
    },
    {
      "epoch": 9.119737561509021,
      "grad_norm": 0.0015108291991055012,
      "learning_rate": 1.088026243849098e-05,
      "loss": 0.0045,
      "step": 33360
    },
    {
      "epoch": 9.12247129579005,
      "grad_norm": 0.3867831826210022,
      "learning_rate": 1.0877528704209952e-05,
      "loss": 0.0062,
      "step": 33370
    },
    {
      "epoch": 9.125205030071077,
      "grad_norm": 2.8397207260131836,
      "learning_rate": 1.0874794969928924e-05,
      "loss": 0.0528,
      "step": 33380
    },
    {
      "epoch": 9.127938764352105,
      "grad_norm": 0.004102693870663643,
      "learning_rate": 1.0872061235647895e-05,
      "loss": 0.0119,
      "step": 33390
    },
    {
      "epoch": 9.130672498633134,
      "grad_norm": 0.002161473035812378,
      "learning_rate": 1.0869327501366869e-05,
      "loss": 0.007,
      "step": 33400
    },
    {
      "epoch": 9.13340623291416,
      "grad_norm": 1.389902949333191,
      "learning_rate": 1.086659376708584e-05,
      "loss": 0.0087,
      "step": 33410
    },
    {
      "epoch": 9.136139967195188,
      "grad_norm": 7.023256301879883,
      "learning_rate": 1.0863860032804812e-05,
      "loss": 0.008,
      "step": 33420
    },
    {
      "epoch": 9.138873701476216,
      "grad_norm": 0.0074425567872822285,
      "learning_rate": 1.0861126298523785e-05,
      "loss": 0.0382,
      "step": 33430
    },
    {
      "epoch": 9.141607435757244,
      "grad_norm": 0.010364762507379055,
      "learning_rate": 1.0858392564242757e-05,
      "loss": 0.0026,
      "step": 33440
    },
    {
      "epoch": 9.144341170038272,
      "grad_norm": 0.41111838817596436,
      "learning_rate": 1.0855658829961729e-05,
      "loss": 0.0221,
      "step": 33450
    },
    {
      "epoch": 9.1470749043193,
      "grad_norm": 0.005118636880069971,
      "learning_rate": 1.08529250956807e-05,
      "loss": 0.01,
      "step": 33460
    },
    {
      "epoch": 9.149808638600328,
      "grad_norm": 0.002262928057461977,
      "learning_rate": 1.0850191361399674e-05,
      "loss": 0.0083,
      "step": 33470
    },
    {
      "epoch": 9.152542372881356,
      "grad_norm": 0.6004416346549988,
      "learning_rate": 1.0847457627118645e-05,
      "loss": 0.0457,
      "step": 33480
    },
    {
      "epoch": 9.155276107162384,
      "grad_norm": 0.387380987405777,
      "learning_rate": 1.0844723892837617e-05,
      "loss": 0.0155,
      "step": 33490
    },
    {
      "epoch": 9.158009841443413,
      "grad_norm": 0.005736102815717459,
      "learning_rate": 1.084199015855659e-05,
      "loss": 0.0081,
      "step": 33500
    },
    {
      "epoch": 9.160743575724439,
      "grad_norm": 0.6464874148368835,
      "learning_rate": 1.0839256424275562e-05,
      "loss": 0.0092,
      "step": 33510
    },
    {
      "epoch": 9.163477310005467,
      "grad_norm": 0.0027470560744404793,
      "learning_rate": 1.0836522689994534e-05,
      "loss": 0.0248,
      "step": 33520
    },
    {
      "epoch": 9.166211044286495,
      "grad_norm": 0.24784311652183533,
      "learning_rate": 1.0833788955713505e-05,
      "loss": 0.0021,
      "step": 33530
    },
    {
      "epoch": 9.168944778567523,
      "grad_norm": 0.005326442886143923,
      "learning_rate": 1.0831055221432479e-05,
      "loss": 0.0071,
      "step": 33540
    },
    {
      "epoch": 9.171678512848551,
      "grad_norm": 0.024180874228477478,
      "learning_rate": 1.082832148715145e-05,
      "loss": 0.0094,
      "step": 33550
    },
    {
      "epoch": 9.17441224712958,
      "grad_norm": 0.025701357051730156,
      "learning_rate": 1.0825587752870422e-05,
      "loss": 0.0179,
      "step": 33560
    },
    {
      "epoch": 9.177145981410607,
      "grad_norm": 0.0008930825279094279,
      "learning_rate": 1.0822854018589395e-05,
      "loss": 0.0003,
      "step": 33570
    },
    {
      "epoch": 9.179879715691635,
      "grad_norm": 0.0062174368649721146,
      "learning_rate": 1.0820120284308367e-05,
      "loss": 0.0333,
      "step": 33580
    },
    {
      "epoch": 9.182613449972663,
      "grad_norm": 0.00532161071896553,
      "learning_rate": 1.0817386550027339e-05,
      "loss": 0.0077,
      "step": 33590
    },
    {
      "epoch": 9.18534718425369,
      "grad_norm": 0.0013300656573846936,
      "learning_rate": 1.081465281574631e-05,
      "loss": 0.0046,
      "step": 33600
    },
    {
      "epoch": 9.188080918534718,
      "grad_norm": 0.3914552927017212,
      "learning_rate": 1.0811919081465284e-05,
      "loss": 0.0514,
      "step": 33610
    },
    {
      "epoch": 9.190814652815746,
      "grad_norm": 0.0031079454347491264,
      "learning_rate": 1.0809185347184255e-05,
      "loss": 0.0443,
      "step": 33620
    },
    {
      "epoch": 9.193548387096774,
      "grad_norm": 0.0030181114561855793,
      "learning_rate": 1.0806451612903225e-05,
      "loss": 0.0006,
      "step": 33630
    },
    {
      "epoch": 9.196282121377802,
      "grad_norm": 0.011096909642219543,
      "learning_rate": 1.08037178786222e-05,
      "loss": 0.0019,
      "step": 33640
    },
    {
      "epoch": 9.19901585565883,
      "grad_norm": 0.0026094901841133833,
      "learning_rate": 1.0800984144341172e-05,
      "loss": 0.0012,
      "step": 33650
    },
    {
      "epoch": 9.201749589939858,
      "grad_norm": 0.0030420890543609858,
      "learning_rate": 1.0798250410060142e-05,
      "loss": 0.0001,
      "step": 33660
    },
    {
      "epoch": 9.204483324220886,
      "grad_norm": 0.002616357523947954,
      "learning_rate": 1.0795516675779113e-05,
      "loss": 0.0005,
      "step": 33670
    },
    {
      "epoch": 9.207217058501914,
      "grad_norm": 0.5769757628440857,
      "learning_rate": 1.0792782941498088e-05,
      "loss": 0.0082,
      "step": 33680
    },
    {
      "epoch": 9.20995079278294,
      "grad_norm": 0.004306484945118427,
      "learning_rate": 1.0790049207217058e-05,
      "loss": 0.0058,
      "step": 33690
    },
    {
      "epoch": 9.212684527063969,
      "grad_norm": 0.0028125550597906113,
      "learning_rate": 1.078731547293603e-05,
      "loss": 0.043,
      "step": 33700
    },
    {
      "epoch": 9.215418261344997,
      "grad_norm": 0.5920149683952332,
      "learning_rate": 1.0784581738655005e-05,
      "loss": 0.0082,
      "step": 33710
    },
    {
      "epoch": 9.218151995626025,
      "grad_norm": 0.0036817812360823154,
      "learning_rate": 1.0781848004373975e-05,
      "loss": 0.0021,
      "step": 33720
    },
    {
      "epoch": 9.220885729907053,
      "grad_norm": 0.004434505477547646,
      "learning_rate": 1.0779114270092947e-05,
      "loss": 0.0077,
      "step": 33730
    },
    {
      "epoch": 9.223619464188081,
      "grad_norm": 0.0064916047267615795,
      "learning_rate": 1.0776380535811918e-05,
      "loss": 0.003,
      "step": 33740
    },
    {
      "epoch": 9.22635319846911,
      "grad_norm": 0.008325203321874142,
      "learning_rate": 1.0773646801530892e-05,
      "loss": 0.0034,
      "step": 33750
    },
    {
      "epoch": 9.229086932750137,
      "grad_norm": 0.0030176432337611914,
      "learning_rate": 1.0770913067249863e-05,
      "loss": 0.0186,
      "step": 33760
    },
    {
      "epoch": 9.231820667031165,
      "grad_norm": 0.00516100786626339,
      "learning_rate": 1.0768179332968835e-05,
      "loss": 0.0001,
      "step": 33770
    },
    {
      "epoch": 9.234554401312192,
      "grad_norm": 0.0902511402964592,
      "learning_rate": 1.0765445598687808e-05,
      "loss": 0.0099,
      "step": 33780
    },
    {
      "epoch": 9.23728813559322,
      "grad_norm": 0.3405507802963257,
      "learning_rate": 1.076271186440678e-05,
      "loss": 0.0086,
      "step": 33790
    },
    {
      "epoch": 9.240021869874248,
      "grad_norm": 0.0031205250415951014,
      "learning_rate": 1.0759978130125752e-05,
      "loss": 0.0028,
      "step": 33800
    },
    {
      "epoch": 9.242755604155276,
      "grad_norm": 0.002490691374987364,
      "learning_rate": 1.0757244395844723e-05,
      "loss": 0.0514,
      "step": 33810
    },
    {
      "epoch": 9.245489338436304,
      "grad_norm": 0.03135298192501068,
      "learning_rate": 1.0754510661563697e-05,
      "loss": 0.0336,
      "step": 33820
    },
    {
      "epoch": 9.248223072717332,
      "grad_norm": 0.00641560647636652,
      "learning_rate": 1.0751776927282668e-05,
      "loss": 0.0127,
      "step": 33830
    },
    {
      "epoch": 9.25095680699836,
      "grad_norm": 0.005525206681340933,
      "learning_rate": 1.074904319300164e-05,
      "loss": 0.0052,
      "step": 33840
    },
    {
      "epoch": 9.253690541279388,
      "grad_norm": 0.0023433309979736805,
      "learning_rate": 1.0746309458720613e-05,
      "loss": 0.008,
      "step": 33850
    },
    {
      "epoch": 9.256424275560416,
      "grad_norm": 0.002518825698643923,
      "learning_rate": 1.0743575724439585e-05,
      "loss": 0.0034,
      "step": 33860
    },
    {
      "epoch": 9.259158009841443,
      "grad_norm": 1.5942190885543823,
      "learning_rate": 1.0740841990158557e-05,
      "loss": 0.0181,
      "step": 33870
    },
    {
      "epoch": 9.26189174412247,
      "grad_norm": 0.01106347981840372,
      "learning_rate": 1.0738108255877528e-05,
      "loss": 0.0194,
      "step": 33880
    },
    {
      "epoch": 9.264625478403499,
      "grad_norm": 0.0022597373463213444,
      "learning_rate": 1.0735374521596502e-05,
      "loss": 0.0001,
      "step": 33890
    },
    {
      "epoch": 9.267359212684527,
      "grad_norm": 1.0481061935424805,
      "learning_rate": 1.0732640787315473e-05,
      "loss": 0.0011,
      "step": 33900
    },
    {
      "epoch": 9.270092946965555,
      "grad_norm": 0.003501373576000333,
      "learning_rate": 1.0729907053034445e-05,
      "loss": 0.0116,
      "step": 33910
    },
    {
      "epoch": 9.272826681246583,
      "grad_norm": 0.002478261012583971,
      "learning_rate": 1.0727173318753418e-05,
      "loss": 0.0423,
      "step": 33920
    },
    {
      "epoch": 9.275560415527611,
      "grad_norm": 1.0554169416427612,
      "learning_rate": 1.072443958447239e-05,
      "loss": 0.0037,
      "step": 33930
    },
    {
      "epoch": 9.278294149808639,
      "grad_norm": 0.0026628675404936075,
      "learning_rate": 1.0721705850191362e-05,
      "loss": 0.0004,
      "step": 33940
    },
    {
      "epoch": 9.281027884089667,
      "grad_norm": 0.0025735844392329454,
      "learning_rate": 1.0718972115910335e-05,
      "loss": 0.0001,
      "step": 33950
    },
    {
      "epoch": 9.283761618370693,
      "grad_norm": 51.522300720214844,
      "learning_rate": 1.0716238381629307e-05,
      "loss": 0.0126,
      "step": 33960
    },
    {
      "epoch": 9.286495352651722,
      "grad_norm": 0.0018248987616971135,
      "learning_rate": 1.0713504647348278e-05,
      "loss": 0.0001,
      "step": 33970
    },
    {
      "epoch": 9.28922908693275,
      "grad_norm": 3.6237096786499023,
      "learning_rate": 1.071077091306725e-05,
      "loss": 0.0807,
      "step": 33980
    },
    {
      "epoch": 9.291962821213778,
      "grad_norm": 0.005263622384518385,
      "learning_rate": 1.0708037178786223e-05,
      "loss": 0.0002,
      "step": 33990
    },
    {
      "epoch": 9.294696555494806,
      "grad_norm": 0.007105361204594374,
      "learning_rate": 1.0705303444505195e-05,
      "loss": 0.0017,
      "step": 34000
    },
    {
      "epoch": 9.297430289775834,
      "grad_norm": 0.008415552787482738,
      "learning_rate": 1.0702569710224167e-05,
      "loss": 0.0011,
      "step": 34010
    },
    {
      "epoch": 9.300164024056862,
      "grad_norm": 0.0075270612724125385,
      "learning_rate": 1.069983597594314e-05,
      "loss": 0.0486,
      "step": 34020
    },
    {
      "epoch": 9.30289775833789,
      "grad_norm": 0.011059855110943317,
      "learning_rate": 1.0697102241662112e-05,
      "loss": 0.0354,
      "step": 34030
    },
    {
      "epoch": 9.305631492618918,
      "grad_norm": 0.03873026743531227,
      "learning_rate": 1.0694368507381083e-05,
      "loss": 0.0139,
      "step": 34040
    },
    {
      "epoch": 9.308365226899946,
      "grad_norm": 1.656620979309082,
      "learning_rate": 1.0691634773100055e-05,
      "loss": 0.0218,
      "step": 34050
    },
    {
      "epoch": 9.311098961180972,
      "grad_norm": 0.009532629512250423,
      "learning_rate": 1.0688901038819028e-05,
      "loss": 0.0068,
      "step": 34060
    },
    {
      "epoch": 9.313832695462,
      "grad_norm": 0.013950210995972157,
      "learning_rate": 1.0686167304538e-05,
      "loss": 0.0303,
      "step": 34070
    },
    {
      "epoch": 9.316566429743029,
      "grad_norm": 0.014281951822340488,
      "learning_rate": 1.0683433570256972e-05,
      "loss": 0.0051,
      "step": 34080
    },
    {
      "epoch": 9.319300164024057,
      "grad_norm": 0.1003878265619278,
      "learning_rate": 1.0680699835975945e-05,
      "loss": 0.0042,
      "step": 34090
    },
    {
      "epoch": 9.322033898305085,
      "grad_norm": 1.1621150970458984,
      "learning_rate": 1.0677966101694917e-05,
      "loss": 0.001,
      "step": 34100
    },
    {
      "epoch": 9.324767632586113,
      "grad_norm": 0.008395826444029808,
      "learning_rate": 1.0675232367413888e-05,
      "loss": 0.0385,
      "step": 34110
    },
    {
      "epoch": 9.327501366867141,
      "grad_norm": 7.175416946411133,
      "learning_rate": 1.067249863313286e-05,
      "loss": 0.0317,
      "step": 34120
    },
    {
      "epoch": 9.330235101148169,
      "grad_norm": 0.011979185976088047,
      "learning_rate": 1.0669764898851833e-05,
      "loss": 0.0059,
      "step": 34130
    },
    {
      "epoch": 9.332968835429197,
      "grad_norm": 3.8308022022247314,
      "learning_rate": 1.0667031164570805e-05,
      "loss": 0.0467,
      "step": 34140
    },
    {
      "epoch": 9.335702569710223,
      "grad_norm": 0.007837008684873581,
      "learning_rate": 1.0664297430289777e-05,
      "loss": 0.0082,
      "step": 34150
    },
    {
      "epoch": 9.338436303991251,
      "grad_norm": 0.007139555178582668,
      "learning_rate": 1.066156369600875e-05,
      "loss": 0.0075,
      "step": 34160
    },
    {
      "epoch": 9.34117003827228,
      "grad_norm": 0.005339254625141621,
      "learning_rate": 1.0658829961727722e-05,
      "loss": 0.0036,
      "step": 34170
    },
    {
      "epoch": 9.343903772553308,
      "grad_norm": 0.0042825923301279545,
      "learning_rate": 1.0656096227446693e-05,
      "loss": 0.017,
      "step": 34180
    },
    {
      "epoch": 9.346637506834336,
      "grad_norm": 0.009629933163523674,
      "learning_rate": 1.0653362493165665e-05,
      "loss": 0.0574,
      "step": 34190
    },
    {
      "epoch": 9.349371241115364,
      "grad_norm": 0.010933276265859604,
      "learning_rate": 1.0650628758884638e-05,
      "loss": 0.0024,
      "step": 34200
    },
    {
      "epoch": 9.352104975396392,
      "grad_norm": 0.018274156376719475,
      "learning_rate": 1.064789502460361e-05,
      "loss": 0.0038,
      "step": 34210
    },
    {
      "epoch": 9.35483870967742,
      "grad_norm": 0.050692204385995865,
      "learning_rate": 1.0645161290322582e-05,
      "loss": 0.0262,
      "step": 34220
    },
    {
      "epoch": 9.357572443958448,
      "grad_norm": 0.011928834952414036,
      "learning_rate": 1.0642427556041555e-05,
      "loss": 0.0031,
      "step": 34230
    },
    {
      "epoch": 9.360306178239474,
      "grad_norm": 0.01014561764895916,
      "learning_rate": 1.0639693821760527e-05,
      "loss": 0.0221,
      "step": 34240
    },
    {
      "epoch": 9.363039912520502,
      "grad_norm": 0.0077253710478544235,
      "learning_rate": 1.0636960087479498e-05,
      "loss": 0.0045,
      "step": 34250
    },
    {
      "epoch": 9.36577364680153,
      "grad_norm": 0.023751545697450638,
      "learning_rate": 1.0634226353198468e-05,
      "loss": 0.0364,
      "step": 34260
    },
    {
      "epoch": 9.368507381082559,
      "grad_norm": 0.04164998605847359,
      "learning_rate": 1.0631492618917443e-05,
      "loss": 0.0131,
      "step": 34270
    },
    {
      "epoch": 9.371241115363587,
      "grad_norm": 0.028865167871117592,
      "learning_rate": 1.0628758884636415e-05,
      "loss": 0.0239,
      "step": 34280
    },
    {
      "epoch": 9.373974849644615,
      "grad_norm": 0.8521692156791687,
      "learning_rate": 1.0626025150355385e-05,
      "loss": 0.0036,
      "step": 34290
    },
    {
      "epoch": 9.376708583925643,
      "grad_norm": 0.010259777307510376,
      "learning_rate": 1.062329141607436e-05,
      "loss": 0.0105,
      "step": 34300
    },
    {
      "epoch": 9.37944231820667,
      "grad_norm": 0.011641260236501694,
      "learning_rate": 1.0620557681793332e-05,
      "loss": 0.0191,
      "step": 34310
    },
    {
      "epoch": 9.382176052487699,
      "grad_norm": 0.017396731302142143,
      "learning_rate": 1.0617823947512302e-05,
      "loss": 0.0211,
      "step": 34320
    },
    {
      "epoch": 9.384909786768725,
      "grad_norm": 0.19724445044994354,
      "learning_rate": 1.0615090213231273e-05,
      "loss": 0.0016,
      "step": 34330
    },
    {
      "epoch": 9.387643521049753,
      "grad_norm": 0.05462676286697388,
      "learning_rate": 1.0612356478950248e-05,
      "loss": 0.0143,
      "step": 34340
    },
    {
      "epoch": 9.390377255330781,
      "grad_norm": 2.3300514221191406,
      "learning_rate": 1.0609622744669218e-05,
      "loss": 0.0126,
      "step": 34350
    },
    {
      "epoch": 9.39311098961181,
      "grad_norm": 0.005675355903804302,
      "learning_rate": 1.060688901038819e-05,
      "loss": 0.0042,
      "step": 34360
    },
    {
      "epoch": 9.395844723892838,
      "grad_norm": 0.5065522789955139,
      "learning_rate": 1.0604155276107165e-05,
      "loss": 0.0111,
      "step": 34370
    },
    {
      "epoch": 9.398578458173866,
      "grad_norm": 0.0576033741235733,
      "learning_rate": 1.0601421541826135e-05,
      "loss": 0.0034,
      "step": 34380
    },
    {
      "epoch": 9.401312192454894,
      "grad_norm": 0.028487803414463997,
      "learning_rate": 1.0598687807545107e-05,
      "loss": 0.0003,
      "step": 34390
    },
    {
      "epoch": 9.404045926735922,
      "grad_norm": 0.019405649974942207,
      "learning_rate": 1.0595954073264078e-05,
      "loss": 0.0275,
      "step": 34400
    },
    {
      "epoch": 9.40677966101695,
      "grad_norm": 0.028919542208313942,
      "learning_rate": 1.0593220338983052e-05,
      "loss": 0.0011,
      "step": 34410
    },
    {
      "epoch": 9.409513395297978,
      "grad_norm": 0.035803020000457764,
      "learning_rate": 1.0590486604702023e-05,
      "loss": 0.0008,
      "step": 34420
    },
    {
      "epoch": 9.412247129579004,
      "grad_norm": 0.007786348462104797,
      "learning_rate": 1.0587752870420995e-05,
      "loss": 0.0002,
      "step": 34430
    },
    {
      "epoch": 9.414980863860032,
      "grad_norm": 0.004341990686953068,
      "learning_rate": 1.0585019136139968e-05,
      "loss": 0.0352,
      "step": 34440
    },
    {
      "epoch": 9.41771459814106,
      "grad_norm": 2.8008928298950195,
      "learning_rate": 1.058228540185894e-05,
      "loss": 0.0388,
      "step": 34450
    },
    {
      "epoch": 9.420448332422088,
      "grad_norm": 47.74786376953125,
      "learning_rate": 1.0579551667577912e-05,
      "loss": 0.0297,
      "step": 34460
    },
    {
      "epoch": 9.423182066703117,
      "grad_norm": 0.5958502888679504,
      "learning_rate": 1.0576817933296883e-05,
      "loss": 0.0119,
      "step": 34470
    },
    {
      "epoch": 9.425915800984145,
      "grad_norm": 0.0062248255126178265,
      "learning_rate": 1.0574084199015857e-05,
      "loss": 0.001,
      "step": 34480
    },
    {
      "epoch": 9.428649535265173,
      "grad_norm": 0.0033215193543583155,
      "learning_rate": 1.0571350464734828e-05,
      "loss": 0.0059,
      "step": 34490
    },
    {
      "epoch": 9.4313832695462,
      "grad_norm": 0.007077768445014954,
      "learning_rate": 1.05686167304538e-05,
      "loss": 0.0145,
      "step": 34500
    },
    {
      "epoch": 9.434117003827229,
      "grad_norm": 1.6908948421478271,
      "learning_rate": 1.0565882996172773e-05,
      "loss": 0.0195,
      "step": 34510
    },
    {
      "epoch": 9.436850738108255,
      "grad_norm": 0.005838404875248671,
      "learning_rate": 1.0563149261891745e-05,
      "loss": 0.0008,
      "step": 34520
    },
    {
      "epoch": 9.439584472389283,
      "grad_norm": 0.0026453437749296427,
      "learning_rate": 1.0560415527610717e-05,
      "loss": 0.001,
      "step": 34530
    },
    {
      "epoch": 9.442318206670311,
      "grad_norm": 0.0028741341084241867,
      "learning_rate": 1.0557681793329688e-05,
      "loss": 0.0128,
      "step": 34540
    },
    {
      "epoch": 9.44505194095134,
      "grad_norm": 0.0025918406900018454,
      "learning_rate": 1.0554948059048662e-05,
      "loss": 0.0014,
      "step": 34550
    },
    {
      "epoch": 9.447785675232367,
      "grad_norm": 0.003247991669923067,
      "learning_rate": 1.0552214324767633e-05,
      "loss": 0.0134,
      "step": 34560
    },
    {
      "epoch": 9.450519409513396,
      "grad_norm": 0.0036699736956506968,
      "learning_rate": 1.0549480590486605e-05,
      "loss": 0.0002,
      "step": 34570
    },
    {
      "epoch": 9.453253143794424,
      "grad_norm": 0.003262588754296303,
      "learning_rate": 1.0546746856205578e-05,
      "loss": 0.0421,
      "step": 34580
    },
    {
      "epoch": 9.455986878075452,
      "grad_norm": 3.9182608127593994,
      "learning_rate": 1.054401312192455e-05,
      "loss": 0.0298,
      "step": 34590
    },
    {
      "epoch": 9.45872061235648,
      "grad_norm": 15.556852340698242,
      "learning_rate": 1.0541279387643521e-05,
      "loss": 0.0094,
      "step": 34600
    },
    {
      "epoch": 9.461454346637506,
      "grad_norm": 0.008037129417061806,
      "learning_rate": 1.0538545653362493e-05,
      "loss": 0.0006,
      "step": 34610
    },
    {
      "epoch": 9.464188080918534,
      "grad_norm": 0.01271273847669363,
      "learning_rate": 1.0535811919081466e-05,
      "loss": 0.0094,
      "step": 34620
    },
    {
      "epoch": 9.466921815199562,
      "grad_norm": 0.2230720967054367,
      "learning_rate": 1.0533078184800438e-05,
      "loss": 0.0006,
      "step": 34630
    },
    {
      "epoch": 9.46965554948059,
      "grad_norm": 0.06363639235496521,
      "learning_rate": 1.053034445051941e-05,
      "loss": 0.0066,
      "step": 34640
    },
    {
      "epoch": 9.472389283761618,
      "grad_norm": 0.0056637953966856,
      "learning_rate": 1.0527610716238383e-05,
      "loss": 0.0048,
      "step": 34650
    },
    {
      "epoch": 9.475123018042646,
      "grad_norm": 0.005031718406826258,
      "learning_rate": 1.0524876981957355e-05,
      "loss": 0.0003,
      "step": 34660
    },
    {
      "epoch": 9.477856752323675,
      "grad_norm": 0.005325015634298325,
      "learning_rate": 1.0522143247676326e-05,
      "loss": 0.0054,
      "step": 34670
    },
    {
      "epoch": 9.480590486604703,
      "grad_norm": 0.007697761990129948,
      "learning_rate": 1.0519409513395298e-05,
      "loss": 0.002,
      "step": 34680
    },
    {
      "epoch": 9.48332422088573,
      "grad_norm": 2.0550448894500732,
      "learning_rate": 1.0516675779114271e-05,
      "loss": 0.0288,
      "step": 34690
    },
    {
      "epoch": 9.486057955166757,
      "grad_norm": 0.0033608207013458014,
      "learning_rate": 1.0513942044833243e-05,
      "loss": 0.0086,
      "step": 34700
    },
    {
      "epoch": 9.488791689447785,
      "grad_norm": 0.003285670652985573,
      "learning_rate": 1.0511208310552215e-05,
      "loss": 0.032,
      "step": 34710
    },
    {
      "epoch": 9.491525423728813,
      "grad_norm": 0.0029884129762649536,
      "learning_rate": 1.0508474576271188e-05,
      "loss": 0.008,
      "step": 34720
    },
    {
      "epoch": 9.494259158009841,
      "grad_norm": 0.00333375483751297,
      "learning_rate": 1.050574084199016e-05,
      "loss": 0.0303,
      "step": 34730
    },
    {
      "epoch": 9.49699289229087,
      "grad_norm": 1.3194513320922852,
      "learning_rate": 1.0503007107709131e-05,
      "loss": 0.0646,
      "step": 34740
    },
    {
      "epoch": 9.499726626571897,
      "grad_norm": 0.0055652763694524765,
      "learning_rate": 1.0500273373428103e-05,
      "loss": 0.0081,
      "step": 34750
    },
    {
      "epoch": 9.502460360852925,
      "grad_norm": 0.004265656694769859,
      "learning_rate": 1.0497539639147076e-05,
      "loss": 0.0004,
      "step": 34760
    },
    {
      "epoch": 9.505194095133954,
      "grad_norm": 0.004114188719540834,
      "learning_rate": 1.0494805904866048e-05,
      "loss": 0.0265,
      "step": 34770
    },
    {
      "epoch": 9.507927829414982,
      "grad_norm": 0.004306816030293703,
      "learning_rate": 1.049207217058502e-05,
      "loss": 0.0082,
      "step": 34780
    },
    {
      "epoch": 9.510661563696008,
      "grad_norm": 0.004230791237205267,
      "learning_rate": 1.0489338436303993e-05,
      "loss": 0.0127,
      "step": 34790
    },
    {
      "epoch": 9.513395297977036,
      "grad_norm": 0.004379787482321262,
      "learning_rate": 1.0486604702022965e-05,
      "loss": 0.005,
      "step": 34800
    },
    {
      "epoch": 9.516129032258064,
      "grad_norm": 0.0039123366586863995,
      "learning_rate": 1.0483870967741936e-05,
      "loss": 0.0001,
      "step": 34810
    },
    {
      "epoch": 9.518862766539092,
      "grad_norm": 0.009565681219100952,
      "learning_rate": 1.0481137233460908e-05,
      "loss": 0.0172,
      "step": 34820
    },
    {
      "epoch": 9.52159650082012,
      "grad_norm": 0.10542299598455429,
      "learning_rate": 1.0478403499179881e-05,
      "loss": 0.0013,
      "step": 34830
    },
    {
      "epoch": 9.524330235101148,
      "grad_norm": 0.04445045068860054,
      "learning_rate": 1.0475669764898853e-05,
      "loss": 0.0404,
      "step": 34840
    },
    {
      "epoch": 9.527063969382176,
      "grad_norm": 0.02326032891869545,
      "learning_rate": 1.0472936030617825e-05,
      "loss": 0.0285,
      "step": 34850
    },
    {
      "epoch": 9.529797703663204,
      "grad_norm": 0.02635427750647068,
      "learning_rate": 1.0470202296336798e-05,
      "loss": 0.0011,
      "step": 34860
    },
    {
      "epoch": 9.532531437944233,
      "grad_norm": 0.014339677058160305,
      "learning_rate": 1.046746856205577e-05,
      "loss": 0.0096,
      "step": 34870
    },
    {
      "epoch": 9.535265172225259,
      "grad_norm": 0.010143796913325787,
      "learning_rate": 1.0464734827774741e-05,
      "loss": 0.042,
      "step": 34880
    },
    {
      "epoch": 9.537998906506287,
      "grad_norm": 0.01551138050854206,
      "learning_rate": 1.0462001093493711e-05,
      "loss": 0.0005,
      "step": 34890
    },
    {
      "epoch": 9.540732640787315,
      "grad_norm": 1.9579687118530273,
      "learning_rate": 1.0459267359212686e-05,
      "loss": 0.0216,
      "step": 34900
    },
    {
      "epoch": 9.543466375068343,
      "grad_norm": 0.07312198728322983,
      "learning_rate": 1.0456533624931658e-05,
      "loss": 0.0255,
      "step": 34910
    },
    {
      "epoch": 9.546200109349371,
      "grad_norm": 0.008157563395798206,
      "learning_rate": 1.0453799890650628e-05,
      "loss": 0.0093,
      "step": 34920
    },
    {
      "epoch": 9.5489338436304,
      "grad_norm": 0.004037320613861084,
      "learning_rate": 1.0451066156369603e-05,
      "loss": 0.0314,
      "step": 34930
    },
    {
      "epoch": 9.551667577911427,
      "grad_norm": 0.009830727241933346,
      "learning_rate": 1.0448332422088575e-05,
      "loss": 0.0046,
      "step": 34940
    },
    {
      "epoch": 9.554401312192455,
      "grad_norm": 0.021152174100279808,
      "learning_rate": 1.0445598687807545e-05,
      "loss": 0.0141,
      "step": 34950
    },
    {
      "epoch": 9.557135046473483,
      "grad_norm": 2.267726421356201,
      "learning_rate": 1.0442864953526516e-05,
      "loss": 0.0106,
      "step": 34960
    },
    {
      "epoch": 9.55986878075451,
      "grad_norm": 0.003627158235758543,
      "learning_rate": 1.0440131219245491e-05,
      "loss": 0.0305,
      "step": 34970
    },
    {
      "epoch": 9.562602515035538,
      "grad_norm": 1.6677972078323364,
      "learning_rate": 1.0437397484964461e-05,
      "loss": 0.0179,
      "step": 34980
    },
    {
      "epoch": 9.565336249316566,
      "grad_norm": 0.030657734721899033,
      "learning_rate": 1.0434663750683433e-05,
      "loss": 0.0044,
      "step": 34990
    },
    {
      "epoch": 9.568069983597594,
      "grad_norm": 0.002639051526784897,
      "learning_rate": 1.0431930016402408e-05,
      "loss": 0.0143,
      "step": 35000
    },
    {
      "epoch": 9.570803717878622,
      "grad_norm": 0.0025993874296545982,
      "learning_rate": 1.0429196282121378e-05,
      "loss": 0.0017,
      "step": 35010
    },
    {
      "epoch": 9.57353745215965,
      "grad_norm": 0.004685299936681986,
      "learning_rate": 1.042646254784035e-05,
      "loss": 0.0068,
      "step": 35020
    },
    {
      "epoch": 9.576271186440678,
      "grad_norm": 0.8302006721496582,
      "learning_rate": 1.0423728813559325e-05,
      "loss": 0.0032,
      "step": 35030
    },
    {
      "epoch": 9.579004920721706,
      "grad_norm": 0.009645890444517136,
      "learning_rate": 1.0420995079278295e-05,
      "loss": 0.007,
      "step": 35040
    },
    {
      "epoch": 9.581738655002734,
      "grad_norm": 0.0020817453041672707,
      "learning_rate": 1.0418261344997266e-05,
      "loss": 0.0228,
      "step": 35050
    },
    {
      "epoch": 9.584472389283762,
      "grad_norm": 7.012643814086914,
      "learning_rate": 1.0415527610716238e-05,
      "loss": 0.0196,
      "step": 35060
    },
    {
      "epoch": 9.587206123564789,
      "grad_norm": 0.0029991595074534416,
      "learning_rate": 1.0412793876435211e-05,
      "loss": 0.0122,
      "step": 35070
    },
    {
      "epoch": 9.589939857845817,
      "grad_norm": 1.2336844205856323,
      "learning_rate": 1.0410060142154183e-05,
      "loss": 0.0095,
      "step": 35080
    },
    {
      "epoch": 9.592673592126845,
      "grad_norm": 0.0026321851182729006,
      "learning_rate": 1.0407326407873155e-05,
      "loss": 0.0208,
      "step": 35090
    },
    {
      "epoch": 9.595407326407873,
      "grad_norm": 0.5934599041938782,
      "learning_rate": 1.0404592673592128e-05,
      "loss": 0.0176,
      "step": 35100
    },
    {
      "epoch": 9.598141060688901,
      "grad_norm": 0.010795559734106064,
      "learning_rate": 1.04018589393111e-05,
      "loss": 0.0169,
      "step": 35110
    },
    {
      "epoch": 9.60087479496993,
      "grad_norm": 0.003111225087195635,
      "learning_rate": 1.0399125205030071e-05,
      "loss": 0.0054,
      "step": 35120
    },
    {
      "epoch": 9.603608529250957,
      "grad_norm": 0.0034056897275149822,
      "learning_rate": 1.0396391470749043e-05,
      "loss": 0.0272,
      "step": 35130
    },
    {
      "epoch": 9.606342263531985,
      "grad_norm": 0.0028896513395011425,
      "learning_rate": 1.0393657736468016e-05,
      "loss": 0.0081,
      "step": 35140
    },
    {
      "epoch": 9.609075997813013,
      "grad_norm": 1.4213520288467407,
      "learning_rate": 1.0390924002186988e-05,
      "loss": 0.0127,
      "step": 35150
    },
    {
      "epoch": 9.61180973209404,
      "grad_norm": 0.002179633127525449,
      "learning_rate": 1.038819026790596e-05,
      "loss": 0.0061,
      "step": 35160
    },
    {
      "epoch": 9.614543466375068,
      "grad_norm": 0.0015836161328479648,
      "learning_rate": 1.0385456533624933e-05,
      "loss": 0.0004,
      "step": 35170
    },
    {
      "epoch": 9.617277200656096,
      "grad_norm": 0.03445759415626526,
      "learning_rate": 1.0382722799343905e-05,
      "loss": 0.0066,
      "step": 35180
    },
    {
      "epoch": 9.620010934937124,
      "grad_norm": 0.0014424278633669019,
      "learning_rate": 1.0379989065062876e-05,
      "loss": 0.0001,
      "step": 35190
    },
    {
      "epoch": 9.622744669218152,
      "grad_norm": 0.0014032069593667984,
      "learning_rate": 1.0377255330781848e-05,
      "loss": 0.0064,
      "step": 35200
    },
    {
      "epoch": 9.62547840349918,
      "grad_norm": 5.182602882385254,
      "learning_rate": 1.0374521596500821e-05,
      "loss": 0.0417,
      "step": 35210
    },
    {
      "epoch": 9.628212137780208,
      "grad_norm": 1.4996551275253296,
      "learning_rate": 1.0371787862219793e-05,
      "loss": 0.0112,
      "step": 35220
    },
    {
      "epoch": 9.630945872061236,
      "grad_norm": 1.7320497035980225,
      "learning_rate": 1.0369054127938765e-05,
      "loss": 0.0065,
      "step": 35230
    },
    {
      "epoch": 9.633679606342264,
      "grad_norm": 0.001830917433835566,
      "learning_rate": 1.0366320393657738e-05,
      "loss": 0.0065,
      "step": 35240
    },
    {
      "epoch": 9.636413340623292,
      "grad_norm": 0.0016854333225637674,
      "learning_rate": 1.036358665937671e-05,
      "loss": 0.0001,
      "step": 35250
    },
    {
      "epoch": 9.639147074904319,
      "grad_norm": 0.02307373471558094,
      "learning_rate": 1.0360852925095681e-05,
      "loss": 0.0002,
      "step": 35260
    },
    {
      "epoch": 9.641880809185347,
      "grad_norm": 0.0018710729200392962,
      "learning_rate": 1.0358119190814653e-05,
      "loss": 0.0161,
      "step": 35270
    },
    {
      "epoch": 9.644614543466375,
      "grad_norm": 0.0034874530974775553,
      "learning_rate": 1.0355385456533626e-05,
      "loss": 0.0205,
      "step": 35280
    },
    {
      "epoch": 9.647348277747403,
      "grad_norm": 0.013539960607886314,
      "learning_rate": 1.0352651722252598e-05,
      "loss": 0.0093,
      "step": 35290
    },
    {
      "epoch": 9.650082012028431,
      "grad_norm": 1.6574716567993164,
      "learning_rate": 1.034991798797157e-05,
      "loss": 0.0213,
      "step": 35300
    },
    {
      "epoch": 9.652815746309459,
      "grad_norm": 0.006329534575343132,
      "learning_rate": 1.0347184253690543e-05,
      "loss": 0.0307,
      "step": 35310
    },
    {
      "epoch": 9.655549480590487,
      "grad_norm": 0.0024954653345048428,
      "learning_rate": 1.0344450519409515e-05,
      "loss": 0.0079,
      "step": 35320
    },
    {
      "epoch": 9.658283214871515,
      "grad_norm": 0.0015418342081829906,
      "learning_rate": 1.0341716785128486e-05,
      "loss": 0.0023,
      "step": 35330
    },
    {
      "epoch": 9.661016949152543,
      "grad_norm": 0.0014712456613779068,
      "learning_rate": 1.0338983050847458e-05,
      "loss": 0.0005,
      "step": 35340
    },
    {
      "epoch": 9.66375068343357,
      "grad_norm": 0.001462149084545672,
      "learning_rate": 1.0336249316566431e-05,
      "loss": 0.0078,
      "step": 35350
    },
    {
      "epoch": 9.666484417714598,
      "grad_norm": 0.0011949858162552118,
      "learning_rate": 1.0333515582285403e-05,
      "loss": 0.0164,
      "step": 35360
    },
    {
      "epoch": 9.669218151995626,
      "grad_norm": 0.0037942323833703995,
      "learning_rate": 1.0330781848004375e-05,
      "loss": 0.0024,
      "step": 35370
    },
    {
      "epoch": 9.671951886276654,
      "grad_norm": 0.004566224757581949,
      "learning_rate": 1.0328048113723348e-05,
      "loss": 0.0158,
      "step": 35380
    },
    {
      "epoch": 9.674685620557682,
      "grad_norm": 11.090911865234375,
      "learning_rate": 1.032531437944232e-05,
      "loss": 0.0057,
      "step": 35390
    },
    {
      "epoch": 9.67741935483871,
      "grad_norm": 0.0009607371175661683,
      "learning_rate": 1.0322580645161291e-05,
      "loss": 0.0277,
      "step": 35400
    },
    {
      "epoch": 9.680153089119738,
      "grad_norm": 0.10676399618387222,
      "learning_rate": 1.0319846910880263e-05,
      "loss": 0.0269,
      "step": 35410
    },
    {
      "epoch": 9.682886823400766,
      "grad_norm": 0.0016196309588849545,
      "learning_rate": 1.0317113176599236e-05,
      "loss": 0.0033,
      "step": 35420
    },
    {
      "epoch": 9.685620557681794,
      "grad_norm": 0.001469783834181726,
      "learning_rate": 1.0314379442318208e-05,
      "loss": 0.0143,
      "step": 35430
    },
    {
      "epoch": 9.68835429196282,
      "grad_norm": 0.0013816248392686248,
      "learning_rate": 1.031164570803718e-05,
      "loss": 0.0172,
      "step": 35440
    },
    {
      "epoch": 9.691088026243849,
      "grad_norm": 0.01758304424583912,
      "learning_rate": 1.0308911973756153e-05,
      "loss": 0.0039,
      "step": 35450
    },
    {
      "epoch": 9.693821760524877,
      "grad_norm": 0.0056452578864991665,
      "learning_rate": 1.0306178239475125e-05,
      "loss": 0.0019,
      "step": 35460
    },
    {
      "epoch": 9.696555494805905,
      "grad_norm": 0.0033672070130705833,
      "learning_rate": 1.0303444505194096e-05,
      "loss": 0.0001,
      "step": 35470
    },
    {
      "epoch": 9.699289229086933,
      "grad_norm": 0.0018285728292539716,
      "learning_rate": 1.0300710770913068e-05,
      "loss": 0.0148,
      "step": 35480
    },
    {
      "epoch": 9.70202296336796,
      "grad_norm": 0.0008201008895412087,
      "learning_rate": 1.0297977036632041e-05,
      "loss": 0.009,
      "step": 35490
    },
    {
      "epoch": 9.704756697648989,
      "grad_norm": 2.1799063682556152,
      "learning_rate": 1.0295243302351013e-05,
      "loss": 0.019,
      "step": 35500
    },
    {
      "epoch": 9.707490431930017,
      "grad_norm": 0.11602264642715454,
      "learning_rate": 1.0292509568069985e-05,
      "loss": 0.0001,
      "step": 35510
    },
    {
      "epoch": 9.710224166211045,
      "grad_norm": 0.001594764064066112,
      "learning_rate": 1.0289775833788958e-05,
      "loss": 0.0099,
      "step": 35520
    },
    {
      "epoch": 9.712957900492071,
      "grad_norm": 0.029312631115317345,
      "learning_rate": 1.028704209950793e-05,
      "loss": 0.0003,
      "step": 35530
    },
    {
      "epoch": 9.7156916347731,
      "grad_norm": 19.518301010131836,
      "learning_rate": 1.0284308365226901e-05,
      "loss": 0.0189,
      "step": 35540
    },
    {
      "epoch": 9.718425369054128,
      "grad_norm": 0.002439945237711072,
      "learning_rate": 1.0281574630945871e-05,
      "loss": 0.0146,
      "step": 35550
    },
    {
      "epoch": 9.721159103335156,
      "grad_norm": 0.016076670959591866,
      "learning_rate": 1.0278840896664846e-05,
      "loss": 0.009,
      "step": 35560
    },
    {
      "epoch": 9.723892837616184,
      "grad_norm": 0.022680306807160378,
      "learning_rate": 1.0276107162383818e-05,
      "loss": 0.0173,
      "step": 35570
    },
    {
      "epoch": 9.726626571897212,
      "grad_norm": 0.1456809639930725,
      "learning_rate": 1.0273373428102788e-05,
      "loss": 0.0197,
      "step": 35580
    },
    {
      "epoch": 9.72936030617824,
      "grad_norm": 0.0009525673813186586,
      "learning_rate": 1.0270639693821763e-05,
      "loss": 0.0698,
      "step": 35590
    },
    {
      "epoch": 9.732094040459268,
      "grad_norm": 0.028645075857639313,
      "learning_rate": 1.0267905959540735e-05,
      "loss": 0.0002,
      "step": 35600
    },
    {
      "epoch": 9.734827774740296,
      "grad_norm": 0.0015959979500621557,
      "learning_rate": 1.0265172225259704e-05,
      "loss": 0.0145,
      "step": 35610
    },
    {
      "epoch": 9.737561509021322,
      "grad_norm": 0.0010807460639625788,
      "learning_rate": 1.0262438490978676e-05,
      "loss": 0.0042,
      "step": 35620
    },
    {
      "epoch": 9.74029524330235,
      "grad_norm": 1.02267587184906,
      "learning_rate": 1.0259704756697651e-05,
      "loss": 0.0108,
      "step": 35630
    },
    {
      "epoch": 9.743028977583378,
      "grad_norm": 0.0014060388784855604,
      "learning_rate": 1.0256971022416621e-05,
      "loss": 0.0001,
      "step": 35640
    },
    {
      "epoch": 9.745762711864407,
      "grad_norm": 0.0012295611668378115,
      "learning_rate": 1.0254237288135593e-05,
      "loss": 0.0005,
      "step": 35650
    },
    {
      "epoch": 9.748496446145435,
      "grad_norm": 0.0014678991865366697,
      "learning_rate": 1.0251503553854568e-05,
      "loss": 0.0124,
      "step": 35660
    },
    {
      "epoch": 9.751230180426463,
      "grad_norm": 0.001239150413312018,
      "learning_rate": 1.0248769819573538e-05,
      "loss": 0.0081,
      "step": 35670
    },
    {
      "epoch": 9.75396391470749,
      "grad_norm": 0.0012227175757288933,
      "learning_rate": 1.024603608529251e-05,
      "loss": 0.0069,
      "step": 35680
    },
    {
      "epoch": 9.756697648988519,
      "grad_norm": 0.0012314626947045326,
      "learning_rate": 1.0243302351011481e-05,
      "loss": 0.0445,
      "step": 35690
    },
    {
      "epoch": 9.759431383269547,
      "grad_norm": 0.0012945272028446198,
      "learning_rate": 1.0240568616730454e-05,
      "loss": 0.0005,
      "step": 35700
    },
    {
      "epoch": 9.762165117550573,
      "grad_norm": 0.0012642479268833995,
      "learning_rate": 1.0237834882449426e-05,
      "loss": 0.0162,
      "step": 35710
    },
    {
      "epoch": 9.764898851831601,
      "grad_norm": 0.0020012471359223127,
      "learning_rate": 1.0235101148168398e-05,
      "loss": 0.0056,
      "step": 35720
    },
    {
      "epoch": 9.76763258611263,
      "grad_norm": 0.001011366373859346,
      "learning_rate": 1.0232367413887371e-05,
      "loss": 0.0029,
      "step": 35730
    },
    {
      "epoch": 9.770366320393657,
      "grad_norm": 0.0056095728650689125,
      "learning_rate": 1.0229633679606343e-05,
      "loss": 0.0532,
      "step": 35740
    },
    {
      "epoch": 9.773100054674686,
      "grad_norm": 1.4578393697738647,
      "learning_rate": 1.0226899945325314e-05,
      "loss": 0.0017,
      "step": 35750
    },
    {
      "epoch": 9.775833788955714,
      "grad_norm": 0.0017974699148908257,
      "learning_rate": 1.0224166211044286e-05,
      "loss": 0.0153,
      "step": 35760
    },
    {
      "epoch": 9.778567523236742,
      "grad_norm": 0.11393458396196365,
      "learning_rate": 1.022143247676326e-05,
      "loss": 0.0161,
      "step": 35770
    },
    {
      "epoch": 9.78130125751777,
      "grad_norm": 0.003380096284672618,
      "learning_rate": 1.0218698742482231e-05,
      "loss": 0.0339,
      "step": 35780
    },
    {
      "epoch": 9.784034991798798,
      "grad_norm": 0.002342728665098548,
      "learning_rate": 1.0215965008201203e-05,
      "loss": 0.0001,
      "step": 35790
    },
    {
      "epoch": 9.786768726079824,
      "grad_norm": 0.001930111669935286,
      "learning_rate": 1.0213231273920176e-05,
      "loss": 0.0119,
      "step": 35800
    },
    {
      "epoch": 9.789502460360852,
      "grad_norm": 0.7847313284873962,
      "learning_rate": 1.0210497539639148e-05,
      "loss": 0.0313,
      "step": 35810
    },
    {
      "epoch": 9.79223619464188,
      "grad_norm": 2.1991186141967773,
      "learning_rate": 1.020776380535812e-05,
      "loss": 0.0435,
      "step": 35820
    },
    {
      "epoch": 9.794969928922908,
      "grad_norm": 0.01192464679479599,
      "learning_rate": 1.0205030071077091e-05,
      "loss": 0.0217,
      "step": 35830
    },
    {
      "epoch": 9.797703663203936,
      "grad_norm": 0.5899664163589478,
      "learning_rate": 1.0202296336796064e-05,
      "loss": 0.005,
      "step": 35840
    },
    {
      "epoch": 9.800437397484965,
      "grad_norm": 0.005368546117097139,
      "learning_rate": 1.0199562602515036e-05,
      "loss": 0.0177,
      "step": 35850
    },
    {
      "epoch": 9.803171131765993,
      "grad_norm": 0.005161665380001068,
      "learning_rate": 1.0196828868234008e-05,
      "loss": 0.0196,
      "step": 35860
    },
    {
      "epoch": 9.80590486604702,
      "grad_norm": 0.004839695990085602,
      "learning_rate": 1.0194095133952981e-05,
      "loss": 0.0089,
      "step": 35870
    },
    {
      "epoch": 9.808638600328049,
      "grad_norm": 142.76100158691406,
      "learning_rate": 1.0191361399671953e-05,
      "loss": 0.0228,
      "step": 35880
    },
    {
      "epoch": 9.811372334609075,
      "grad_norm": 0.0065721976570785046,
      "learning_rate": 1.0188627665390924e-05,
      "loss": 0.0007,
      "step": 35890
    },
    {
      "epoch": 9.814106068890103,
      "grad_norm": 4.479657173156738,
      "learning_rate": 1.0185893931109896e-05,
      "loss": 0.033,
      "step": 35900
    },
    {
      "epoch": 9.816839803171131,
      "grad_norm": 0.0043424260802567005,
      "learning_rate": 1.018316019682887e-05,
      "loss": 0.0059,
      "step": 35910
    },
    {
      "epoch": 9.81957353745216,
      "grad_norm": 0.026988953351974487,
      "learning_rate": 1.0180426462547841e-05,
      "loss": 0.0151,
      "step": 35920
    },
    {
      "epoch": 9.822307271733187,
      "grad_norm": 7.42017936706543,
      "learning_rate": 1.0177692728266813e-05,
      "loss": 0.0182,
      "step": 35930
    },
    {
      "epoch": 9.825041006014215,
      "grad_norm": 0.003583553247153759,
      "learning_rate": 1.0174958993985786e-05,
      "loss": 0.0031,
      "step": 35940
    },
    {
      "epoch": 9.827774740295244,
      "grad_norm": 0.005416875705122948,
      "learning_rate": 1.0172225259704758e-05,
      "loss": 0.0228,
      "step": 35950
    },
    {
      "epoch": 9.830508474576272,
      "grad_norm": 2.329284191131592,
      "learning_rate": 1.016949152542373e-05,
      "loss": 0.0114,
      "step": 35960
    },
    {
      "epoch": 9.8332422088573,
      "grad_norm": 0.0035443142987787724,
      "learning_rate": 1.0166757791142701e-05,
      "loss": 0.0111,
      "step": 35970
    },
    {
      "epoch": 9.835975943138326,
      "grad_norm": 0.0043556648306548595,
      "learning_rate": 1.0164024056861674e-05,
      "loss": 0.0205,
      "step": 35980
    },
    {
      "epoch": 9.838709677419354,
      "grad_norm": 0.0025987960398197174,
      "learning_rate": 1.0161290322580646e-05,
      "loss": 0.0014,
      "step": 35990
    },
    {
      "epoch": 9.841443411700382,
      "grad_norm": 0.0029534059576690197,
      "learning_rate": 1.0158556588299618e-05,
      "loss": 0.018,
      "step": 36000
    },
    {
      "epoch": 9.84417714598141,
      "grad_norm": 1.3110548257827759,
      "learning_rate": 1.0155822854018591e-05,
      "loss": 0.0148,
      "step": 36010
    },
    {
      "epoch": 9.846910880262438,
      "grad_norm": 0.07155776023864746,
      "learning_rate": 1.0153089119737563e-05,
      "loss": 0.0213,
      "step": 36020
    },
    {
      "epoch": 9.849644614543466,
      "grad_norm": 0.003951712977141142,
      "learning_rate": 1.0150355385456534e-05,
      "loss": 0.0115,
      "step": 36030
    },
    {
      "epoch": 9.852378348824494,
      "grad_norm": 0.0026564528234302998,
      "learning_rate": 1.0147621651175506e-05,
      "loss": 0.0048,
      "step": 36040
    },
    {
      "epoch": 9.855112083105523,
      "grad_norm": 1.4525187015533447,
      "learning_rate": 1.014488791689448e-05,
      "loss": 0.0642,
      "step": 36050
    },
    {
      "epoch": 9.85784581738655,
      "grad_norm": 7.747148036956787,
      "learning_rate": 1.0142154182613451e-05,
      "loss": 0.0169,
      "step": 36060
    },
    {
      "epoch": 9.860579551667579,
      "grad_norm": 1.995975375175476,
      "learning_rate": 1.0139420448332423e-05,
      "loss": 0.0125,
      "step": 36070
    },
    {
      "epoch": 9.863313285948605,
      "grad_norm": 0.003943575546145439,
      "learning_rate": 1.0136686714051396e-05,
      "loss": 0.0003,
      "step": 36080
    },
    {
      "epoch": 9.866047020229633,
      "grad_norm": 0.015620524063706398,
      "learning_rate": 1.0133952979770368e-05,
      "loss": 0.0042,
      "step": 36090
    },
    {
      "epoch": 9.868780754510661,
      "grad_norm": 0.015593874268233776,
      "learning_rate": 1.013121924548934e-05,
      "loss": 0.0098,
      "step": 36100
    },
    {
      "epoch": 9.87151448879169,
      "grad_norm": 0.004679497331380844,
      "learning_rate": 1.0128485511208313e-05,
      "loss": 0.0041,
      "step": 36110
    },
    {
      "epoch": 9.874248223072717,
      "grad_norm": 0.0023446555715054274,
      "learning_rate": 1.0125751776927284e-05,
      "loss": 0.0169,
      "step": 36120
    },
    {
      "epoch": 9.876981957353745,
      "grad_norm": 0.0020853793248534203,
      "learning_rate": 1.0123018042646256e-05,
      "loss": 0.0048,
      "step": 36130
    },
    {
      "epoch": 9.879715691634773,
      "grad_norm": 0.003940362483263016,
      "learning_rate": 1.0120284308365228e-05,
      "loss": 0.0176,
      "step": 36140
    },
    {
      "epoch": 9.882449425915802,
      "grad_norm": 0.0023913299664855003,
      "learning_rate": 1.0117550574084201e-05,
      "loss": 0.0001,
      "step": 36150
    },
    {
      "epoch": 9.88518316019683,
      "grad_norm": 0.0021006572060287,
      "learning_rate": 1.0114816839803173e-05,
      "loss": 0.0081,
      "step": 36160
    },
    {
      "epoch": 9.887916894477856,
      "grad_norm": 0.2040228545665741,
      "learning_rate": 1.0112083105522144e-05,
      "loss": 0.0046,
      "step": 36170
    },
    {
      "epoch": 9.890650628758884,
      "grad_norm": 0.002840867731720209,
      "learning_rate": 1.0109349371241118e-05,
      "loss": 0.0083,
      "step": 36180
    },
    {
      "epoch": 9.893384363039912,
      "grad_norm": 2.0046510696411133,
      "learning_rate": 1.010661563696009e-05,
      "loss": 0.0068,
      "step": 36190
    },
    {
      "epoch": 9.89611809732094,
      "grad_norm": 0.0017201248556375504,
      "learning_rate": 1.0103881902679061e-05,
      "loss": 0.0171,
      "step": 36200
    },
    {
      "epoch": 9.898851831601968,
      "grad_norm": 0.0041244602762162685,
      "learning_rate": 1.0101148168398031e-05,
      "loss": 0.0404,
      "step": 36210
    },
    {
      "epoch": 9.901585565882996,
      "grad_norm": 4.669682025909424,
      "learning_rate": 1.0098414434117006e-05,
      "loss": 0.0361,
      "step": 36220
    },
    {
      "epoch": 9.904319300164024,
      "grad_norm": 2.090101718902588,
      "learning_rate": 1.0095680699835978e-05,
      "loss": 0.0038,
      "step": 36230
    },
    {
      "epoch": 9.907053034445052,
      "grad_norm": 0.004773304797708988,
      "learning_rate": 1.0092946965554948e-05,
      "loss": 0.0049,
      "step": 36240
    },
    {
      "epoch": 9.90978676872608,
      "grad_norm": 0.018551219254732132,
      "learning_rate": 1.0090213231273923e-05,
      "loss": 0.0066,
      "step": 36250
    },
    {
      "epoch": 9.912520503007109,
      "grad_norm": 0.09780783206224442,
      "learning_rate": 1.0087479496992894e-05,
      "loss": 0.0008,
      "step": 36260
    },
    {
      "epoch": 9.915254237288135,
      "grad_norm": 0.0021205253433436155,
      "learning_rate": 1.0084745762711864e-05,
      "loss": 0.0098,
      "step": 36270
    },
    {
      "epoch": 9.917987971569163,
      "grad_norm": 2.974482297897339,
      "learning_rate": 1.0082012028430836e-05,
      "loss": 0.04,
      "step": 36280
    },
    {
      "epoch": 9.920721705850191,
      "grad_norm": 0.6071234941482544,
      "learning_rate": 1.0079278294149811e-05,
      "loss": 0.0029,
      "step": 36290
    },
    {
      "epoch": 9.92345544013122,
      "grad_norm": 0.005569152068346739,
      "learning_rate": 1.0076544559868781e-05,
      "loss": 0.002,
      "step": 36300
    },
    {
      "epoch": 9.926189174412247,
      "grad_norm": 0.013478641398251057,
      "learning_rate": 1.0073810825587753e-05,
      "loss": 0.0252,
      "step": 36310
    },
    {
      "epoch": 9.928922908693275,
      "grad_norm": 0.005673307925462723,
      "learning_rate": 1.0071077091306728e-05,
      "loss": 0.0191,
      "step": 36320
    },
    {
      "epoch": 9.931656642974303,
      "grad_norm": 0.011227520182728767,
      "learning_rate": 1.0068343357025698e-05,
      "loss": 0.0264,
      "step": 36330
    },
    {
      "epoch": 9.934390377255331,
      "grad_norm": 0.004418408498167992,
      "learning_rate": 1.006560962274467e-05,
      "loss": 0.0244,
      "step": 36340
    },
    {
      "epoch": 9.93712411153636,
      "grad_norm": 0.09346853941679001,
      "learning_rate": 1.0062875888463641e-05,
      "loss": 0.0565,
      "step": 36350
    },
    {
      "epoch": 9.939857845817386,
      "grad_norm": 0.014700149185955524,
      "learning_rate": 1.0060142154182614e-05,
      "loss": 0.0064,
      "step": 36360
    },
    {
      "epoch": 9.942591580098414,
      "grad_norm": 0.007438267581164837,
      "learning_rate": 1.0057408419901586e-05,
      "loss": 0.0007,
      "step": 36370
    },
    {
      "epoch": 9.945325314379442,
      "grad_norm": 1.228468894958496,
      "learning_rate": 1.0054674685620558e-05,
      "loss": 0.0088,
      "step": 36380
    },
    {
      "epoch": 9.94805904866047,
      "grad_norm": 0.008369904942810535,
      "learning_rate": 1.0051940951339531e-05,
      "loss": 0.0183,
      "step": 36390
    },
    {
      "epoch": 9.950792782941498,
      "grad_norm": 0.022105509415268898,
      "learning_rate": 1.0049207217058503e-05,
      "loss": 0.0213,
      "step": 36400
    },
    {
      "epoch": 9.953526517222526,
      "grad_norm": 0.0039725834503769875,
      "learning_rate": 1.0046473482777474e-05,
      "loss": 0.0003,
      "step": 36410
    },
    {
      "epoch": 9.956260251503554,
      "grad_norm": 0.10681354999542236,
      "learning_rate": 1.0043739748496446e-05,
      "loss": 0.0302,
      "step": 36420
    },
    {
      "epoch": 9.958993985784582,
      "grad_norm": 0.026981588453054428,
      "learning_rate": 1.004100601421542e-05,
      "loss": 0.0092,
      "step": 36430
    },
    {
      "epoch": 9.96172772006561,
      "grad_norm": 9.285923957824707,
      "learning_rate": 1.0038272279934391e-05,
      "loss": 0.0073,
      "step": 36440
    },
    {
      "epoch": 9.964461454346637,
      "grad_norm": 0.029494186863303185,
      "learning_rate": 1.0035538545653363e-05,
      "loss": 0.0257,
      "step": 36450
    },
    {
      "epoch": 9.967195188627665,
      "grad_norm": 0.0044202846474945545,
      "learning_rate": 1.0032804811372336e-05,
      "loss": 0.002,
      "step": 36460
    },
    {
      "epoch": 9.969928922908693,
      "grad_norm": 2.2954635620117188,
      "learning_rate": 1.0030071077091308e-05,
      "loss": 0.0074,
      "step": 36470
    },
    {
      "epoch": 9.972662657189721,
      "grad_norm": 0.001813196111470461,
      "learning_rate": 1.002733734281028e-05,
      "loss": 0.0002,
      "step": 36480
    },
    {
      "epoch": 9.975396391470749,
      "grad_norm": 0.008886602707207203,
      "learning_rate": 1.002460360852925e-05,
      "loss": 0.0166,
      "step": 36490
    },
    {
      "epoch": 9.978130125751777,
      "grad_norm": 2.9000017642974854,
      "learning_rate": 1.0021869874248224e-05,
      "loss": 0.0089,
      "step": 36500
    },
    {
      "epoch": 9.980863860032805,
      "grad_norm": 0.0076803406700491905,
      "learning_rate": 1.0019136139967196e-05,
      "loss": 0.0166,
      "step": 36510
    },
    {
      "epoch": 9.983597594313833,
      "grad_norm": 0.004346311558037996,
      "learning_rate": 1.0016402405686167e-05,
      "loss": 0.0018,
      "step": 36520
    },
    {
      "epoch": 9.986331328594861,
      "grad_norm": 0.0016607427969574928,
      "learning_rate": 1.001366867140514e-05,
      "loss": 0.0291,
      "step": 36530
    },
    {
      "epoch": 9.989065062875888,
      "grad_norm": 0.015561182051897049,
      "learning_rate": 1.0010934937124113e-05,
      "loss": 0.002,
      "step": 36540
    },
    {
      "epoch": 9.991798797156916,
      "grad_norm": 0.0038690809160470963,
      "learning_rate": 1.0008201202843084e-05,
      "loss": 0.0069,
      "step": 36550
    },
    {
      "epoch": 9.994532531437944,
      "grad_norm": 0.0022022752091288567,
      "learning_rate": 1.0005467468562056e-05,
      "loss": 0.0047,
      "step": 36560
    },
    {
      "epoch": 9.997266265718972,
      "grad_norm": 0.0035132088232785463,
      "learning_rate": 1.000273373428103e-05,
      "loss": 0.0041,
      "step": 36570
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.00429542688652873,
      "learning_rate": 1e-05,
      "loss": 0.002,
      "step": 36580
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9918050234142188,
      "eval_f1": 0.9669952850407201,
      "eval_loss": 0.037575241178274155,
      "eval_precision": 0.9711579853637538,
      "eval_recall": 0.9628681177976952,
      "eval_runtime": 794.0738,
      "eval_samples_per_second": 23.693,
      "eval_steps_per_second": 0.987,
      "step": 36580
    },
    {
      "epoch": 10.002733734281028,
      "grad_norm": 0.00226422818377614,
      "learning_rate": 9.997266265718974e-06,
      "loss": 0.0373,
      "step": 36590
    },
    {
      "epoch": 10.005467468562056,
      "grad_norm": 0.004181883297860622,
      "learning_rate": 9.994532531437944e-06,
      "loss": 0.0096,
      "step": 36600
    },
    {
      "epoch": 10.008201202843084,
      "grad_norm": 0.00405131233856082,
      "learning_rate": 9.991798797156917e-06,
      "loss": 0.0261,
      "step": 36610
    },
    {
      "epoch": 10.010934937124112,
      "grad_norm": 0.0392155759036541,
      "learning_rate": 9.989065062875889e-06,
      "loss": 0.0062,
      "step": 36620
    },
    {
      "epoch": 10.013668671405139,
      "grad_norm": 0.7992945313453674,
      "learning_rate": 9.98633132859486e-06,
      "loss": 0.0071,
      "step": 36630
    },
    {
      "epoch": 10.016402405686167,
      "grad_norm": 0.0009273384348489344,
      "learning_rate": 9.983597594313832e-06,
      "loss": 0.0133,
      "step": 36640
    },
    {
      "epoch": 10.019136139967195,
      "grad_norm": 0.006361159961670637,
      "learning_rate": 9.980863860032806e-06,
      "loss": 0.006,
      "step": 36650
    },
    {
      "epoch": 10.021869874248223,
      "grad_norm": 0.1889016479253769,
      "learning_rate": 9.978130125751777e-06,
      "loss": 0.0008,
      "step": 36660
    },
    {
      "epoch": 10.024603608529251,
      "grad_norm": 0.25381234288215637,
      "learning_rate": 9.975396391470749e-06,
      "loss": 0.0002,
      "step": 36670
    },
    {
      "epoch": 10.027337342810279,
      "grad_norm": 0.005490451585501432,
      "learning_rate": 9.972662657189722e-06,
      "loss": 0.0063,
      "step": 36680
    },
    {
      "epoch": 10.030071077091307,
      "grad_norm": 0.0014396773185580969,
      "learning_rate": 9.969928922908694e-06,
      "loss": 0.0021,
      "step": 36690
    },
    {
      "epoch": 10.032804811372335,
      "grad_norm": 0.0019765824545174837,
      "learning_rate": 9.967195188627666e-06,
      "loss": 0.003,
      "step": 36700
    },
    {
      "epoch": 10.035538545653363,
      "grad_norm": 0.0044031525030732155,
      "learning_rate": 9.964461454346637e-06,
      "loss": 0.0236,
      "step": 36710
    },
    {
      "epoch": 10.03827227993439,
      "grad_norm": 0.0027300151996314526,
      "learning_rate": 9.96172772006561e-06,
      "loss": 0.0177,
      "step": 36720
    },
    {
      "epoch": 10.041006014215418,
      "grad_norm": 0.0064991130493581295,
      "learning_rate": 9.958993985784582e-06,
      "loss": 0.0055,
      "step": 36730
    },
    {
      "epoch": 10.043739748496446,
      "grad_norm": 0.020562920719385147,
      "learning_rate": 9.956260251503554e-06,
      "loss": 0.0002,
      "step": 36740
    },
    {
      "epoch": 10.046473482777474,
      "grad_norm": 0.003013964043930173,
      "learning_rate": 9.953526517222527e-06,
      "loss": 0.013,
      "step": 36750
    },
    {
      "epoch": 10.049207217058502,
      "grad_norm": 0.0029140636324882507,
      "learning_rate": 9.950792782941499e-06,
      "loss": 0.0026,
      "step": 36760
    },
    {
      "epoch": 10.05194095133953,
      "grad_norm": 0.005828857887536287,
      "learning_rate": 9.94805904866047e-06,
      "loss": 0.0056,
      "step": 36770
    },
    {
      "epoch": 10.054674685620558,
      "grad_norm": 0.003281053388491273,
      "learning_rate": 9.945325314379442e-06,
      "loss": 0.0075,
      "step": 36780
    },
    {
      "epoch": 10.057408419901586,
      "grad_norm": 0.000820315966848284,
      "learning_rate": 9.942591580098416e-06,
      "loss": 0.0079,
      "step": 36790
    },
    {
      "epoch": 10.060142154182614,
      "grad_norm": 0.0074238162487745285,
      "learning_rate": 9.939857845817387e-06,
      "loss": 0.0126,
      "step": 36800
    },
    {
      "epoch": 10.06287588846364,
      "grad_norm": 0.0008649679948575795,
      "learning_rate": 9.937124111536359e-06,
      "loss": 0.0034,
      "step": 36810
    },
    {
      "epoch": 10.065609622744669,
      "grad_norm": 0.0013342384481802583,
      "learning_rate": 9.934390377255332e-06,
      "loss": 0.0,
      "step": 36820
    },
    {
      "epoch": 10.068343357025697,
      "grad_norm": 0.0011122897267341614,
      "learning_rate": 9.931656642974304e-06,
      "loss": 0.0,
      "step": 36830
    },
    {
      "epoch": 10.071077091306725,
      "grad_norm": 0.0009393091313540936,
      "learning_rate": 9.928922908693276e-06,
      "loss": 0.0065,
      "step": 36840
    },
    {
      "epoch": 10.073810825587753,
      "grad_norm": 0.28867900371551514,
      "learning_rate": 9.926189174412249e-06,
      "loss": 0.0251,
      "step": 36850
    },
    {
      "epoch": 10.07654455986878,
      "grad_norm": 0.0011107027530670166,
      "learning_rate": 9.92345544013122e-06,
      "loss": 0.0005,
      "step": 36860
    },
    {
      "epoch": 10.079278294149809,
      "grad_norm": 10.147496223449707,
      "learning_rate": 9.920721705850192e-06,
      "loss": 0.0093,
      "step": 36870
    },
    {
      "epoch": 10.082012028430837,
      "grad_norm": 0.06275076419115067,
      "learning_rate": 9.917987971569164e-06,
      "loss": 0.0193,
      "step": 36880
    },
    {
      "epoch": 10.084745762711865,
      "grad_norm": 0.0029620572458952665,
      "learning_rate": 9.915254237288137e-06,
      "loss": 0.0,
      "step": 36890
    },
    {
      "epoch": 10.087479496992893,
      "grad_norm": 0.0027259455528110266,
      "learning_rate": 9.912520503007107e-06,
      "loss": 0.0001,
      "step": 36900
    },
    {
      "epoch": 10.09021323127392,
      "grad_norm": 0.0013420700561255217,
      "learning_rate": 9.90978676872608e-06,
      "loss": 0.0158,
      "step": 36910
    },
    {
      "epoch": 10.092946965554948,
      "grad_norm": 0.006956464145332575,
      "learning_rate": 9.907053034445054e-06,
      "loss": 0.0058,
      "step": 36920
    },
    {
      "epoch": 10.095680699835976,
      "grad_norm": 1.2717657089233398,
      "learning_rate": 9.904319300164024e-06,
      "loss": 0.0061,
      "step": 36930
    },
    {
      "epoch": 10.098414434117004,
      "grad_norm": 0.06371597200632095,
      "learning_rate": 9.901585565882997e-06,
      "loss": 0.0467,
      "step": 36940
    },
    {
      "epoch": 10.101148168398032,
      "grad_norm": 0.09804022312164307,
      "learning_rate": 9.898851831601969e-06,
      "loss": 0.0151,
      "step": 36950
    },
    {
      "epoch": 10.10388190267906,
      "grad_norm": 0.01671765372157097,
      "learning_rate": 9.89611809732094e-06,
      "loss": 0.0098,
      "step": 36960
    },
    {
      "epoch": 10.106615636960088,
      "grad_norm": 0.12580668926239014,
      "learning_rate": 9.893384363039912e-06,
      "loss": 0.0074,
      "step": 36970
    },
    {
      "epoch": 10.109349371241116,
      "grad_norm": 1.0365252494812012,
      "learning_rate": 9.890650628758886e-06,
      "loss": 0.0072,
      "step": 36980
    },
    {
      "epoch": 10.112083105522144,
      "grad_norm": 0.0011717872694134712,
      "learning_rate": 9.887916894477857e-06,
      "loss": 0.006,
      "step": 36990
    },
    {
      "epoch": 10.11481683980317,
      "grad_norm": 0.1270517259836197,
      "learning_rate": 9.885183160196829e-06,
      "loss": 0.0045,
      "step": 37000
    },
    {
      "epoch": 10.117550574084198,
      "grad_norm": 0.03614320233464241,
      "learning_rate": 9.882449425915802e-06,
      "loss": 0.0036,
      "step": 37010
    },
    {
      "epoch": 10.120284308365227,
      "grad_norm": 1.604222059249878,
      "learning_rate": 9.879715691634774e-06,
      "loss": 0.0106,
      "step": 37020
    },
    {
      "epoch": 10.123018042646255,
      "grad_norm": 0.0010469343978911638,
      "learning_rate": 9.876981957353746e-06,
      "loss": 0.0282,
      "step": 37030
    },
    {
      "epoch": 10.125751776927283,
      "grad_norm": 1.070438027381897,
      "learning_rate": 9.874248223072717e-06,
      "loss": 0.0235,
      "step": 37040
    },
    {
      "epoch": 10.12848551120831,
      "grad_norm": 1.4794336557388306,
      "learning_rate": 9.87151448879169e-06,
      "loss": 0.0005,
      "step": 37050
    },
    {
      "epoch": 10.131219245489339,
      "grad_norm": 0.010188435204327106,
      "learning_rate": 9.868780754510662e-06,
      "loss": 0.0161,
      "step": 37060
    },
    {
      "epoch": 10.133952979770367,
      "grad_norm": 0.004150587599724531,
      "learning_rate": 9.866047020229634e-06,
      "loss": 0.0003,
      "step": 37070
    },
    {
      "epoch": 10.136686714051395,
      "grad_norm": 0.0012094080448150635,
      "learning_rate": 9.863313285948607e-06,
      "loss": 0.0056,
      "step": 37080
    },
    {
      "epoch": 10.139420448332421,
      "grad_norm": 0.0012677821796387434,
      "learning_rate": 9.860579551667579e-06,
      "loss": 0.005,
      "step": 37090
    },
    {
      "epoch": 10.14215418261345,
      "grad_norm": 0.0008582163718529046,
      "learning_rate": 9.85784581738655e-06,
      "loss": 0.0022,
      "step": 37100
    },
    {
      "epoch": 10.144887916894477,
      "grad_norm": 0.0014049923047423363,
      "learning_rate": 9.855112083105522e-06,
      "loss": 0.046,
      "step": 37110
    },
    {
      "epoch": 10.147621651175506,
      "grad_norm": 0.0018092357786372304,
      "learning_rate": 9.852378348824496e-06,
      "loss": 0.0486,
      "step": 37120
    },
    {
      "epoch": 10.150355385456534,
      "grad_norm": 0.6921581625938416,
      "learning_rate": 9.849644614543467e-06,
      "loss": 0.002,
      "step": 37130
    },
    {
      "epoch": 10.153089119737562,
      "grad_norm": 0.03398273140192032,
      "learning_rate": 9.846910880262439e-06,
      "loss": 0.0078,
      "step": 37140
    },
    {
      "epoch": 10.15582285401859,
      "grad_norm": 31.439952850341797,
      "learning_rate": 9.844177145981412e-06,
      "loss": 0.0253,
      "step": 37150
    },
    {
      "epoch": 10.158556588299618,
      "grad_norm": 0.005506542511284351,
      "learning_rate": 9.841443411700384e-06,
      "loss": 0.0065,
      "step": 37160
    },
    {
      "epoch": 10.161290322580646,
      "grad_norm": 0.03740330785512924,
      "learning_rate": 9.838709677419356e-06,
      "loss": 0.0334,
      "step": 37170
    },
    {
      "epoch": 10.164024056861672,
      "grad_norm": 0.015884295105934143,
      "learning_rate": 9.835975943138327e-06,
      "loss": 0.0003,
      "step": 37180
    },
    {
      "epoch": 10.1667577911427,
      "grad_norm": 0.008088091388344765,
      "learning_rate": 9.8332422088573e-06,
      "loss": 0.0205,
      "step": 37190
    },
    {
      "epoch": 10.169491525423728,
      "grad_norm": 0.018311290070414543,
      "learning_rate": 9.830508474576272e-06,
      "loss": 0.0079,
      "step": 37200
    },
    {
      "epoch": 10.172225259704756,
      "grad_norm": 0.005588528700172901,
      "learning_rate": 9.827774740295244e-06,
      "loss": 0.0005,
      "step": 37210
    },
    {
      "epoch": 10.174958993985785,
      "grad_norm": 0.19586004316806793,
      "learning_rate": 9.825041006014217e-06,
      "loss": 0.0074,
      "step": 37220
    },
    {
      "epoch": 10.177692728266813,
      "grad_norm": 0.0039490764029324055,
      "learning_rate": 9.822307271733187e-06,
      "loss": 0.0009,
      "step": 37230
    },
    {
      "epoch": 10.18042646254784,
      "grad_norm": 0.015500346198678017,
      "learning_rate": 9.81957353745216e-06,
      "loss": 0.0004,
      "step": 37240
    },
    {
      "epoch": 10.183160196828869,
      "grad_norm": 0.012108675204217434,
      "learning_rate": 9.816839803171132e-06,
      "loss": 0.0002,
      "step": 37250
    },
    {
      "epoch": 10.185893931109897,
      "grad_norm": 0.002578441286459565,
      "learning_rate": 9.814106068890104e-06,
      "loss": 0.0056,
      "step": 37260
    },
    {
      "epoch": 10.188627665390925,
      "grad_norm": 0.003977789543569088,
      "learning_rate": 9.811372334609077e-06,
      "loss": 0.004,
      "step": 37270
    },
    {
      "epoch": 10.191361399671951,
      "grad_norm": 0.006094939541071653,
      "learning_rate": 9.808638600328049e-06,
      "loss": 0.0001,
      "step": 37280
    },
    {
      "epoch": 10.19409513395298,
      "grad_norm": 0.0035045556724071503,
      "learning_rate": 9.80590486604702e-06,
      "loss": 0.0069,
      "step": 37290
    },
    {
      "epoch": 10.196828868234007,
      "grad_norm": 0.022753700613975525,
      "learning_rate": 9.803171131765992e-06,
      "loss": 0.007,
      "step": 37300
    },
    {
      "epoch": 10.199562602515035,
      "grad_norm": 0.0019653276540338993,
      "learning_rate": 9.800437397484966e-06,
      "loss": 0.0209,
      "step": 37310
    },
    {
      "epoch": 10.202296336796064,
      "grad_norm": 0.002591728698462248,
      "learning_rate": 9.797703663203937e-06,
      "loss": 0.0299,
      "step": 37320
    },
    {
      "epoch": 10.205030071077092,
      "grad_norm": 0.013837744481861591,
      "learning_rate": 9.794969928922909e-06,
      "loss": 0.0002,
      "step": 37330
    },
    {
      "epoch": 10.20776380535812,
      "grad_norm": 0.0035133843775838614,
      "learning_rate": 9.792236194641882e-06,
      "loss": 0.0001,
      "step": 37340
    },
    {
      "epoch": 10.210497539639148,
      "grad_norm": 0.005245812702924013,
      "learning_rate": 9.789502460360854e-06,
      "loss": 0.0002,
      "step": 37350
    },
    {
      "epoch": 10.213231273920176,
      "grad_norm": 0.008806339465081692,
      "learning_rate": 9.786768726079826e-06,
      "loss": 0.0037,
      "step": 37360
    },
    {
      "epoch": 10.215965008201202,
      "grad_norm": 0.0022621285170316696,
      "learning_rate": 9.784034991798797e-06,
      "loss": 0.0001,
      "step": 37370
    },
    {
      "epoch": 10.21869874248223,
      "grad_norm": 0.5476228594779968,
      "learning_rate": 9.78130125751777e-06,
      "loss": 0.0129,
      "step": 37380
    },
    {
      "epoch": 10.221432476763258,
      "grad_norm": 0.6784726977348328,
      "learning_rate": 9.778567523236742e-06,
      "loss": 0.0067,
      "step": 37390
    },
    {
      "epoch": 10.224166211044286,
      "grad_norm": 0.8207597136497498,
      "learning_rate": 9.775833788955714e-06,
      "loss": 0.0046,
      "step": 37400
    },
    {
      "epoch": 10.226899945325314,
      "grad_norm": 0.0016771715600043535,
      "learning_rate": 9.773100054674687e-06,
      "loss": 0.0033,
      "step": 37410
    },
    {
      "epoch": 10.229633679606343,
      "grad_norm": 0.0015177434543147683,
      "learning_rate": 9.770366320393659e-06,
      "loss": 0.0156,
      "step": 37420
    },
    {
      "epoch": 10.23236741388737,
      "grad_norm": 1.4093505144119263,
      "learning_rate": 9.76763258611263e-06,
      "loss": 0.0054,
      "step": 37430
    },
    {
      "epoch": 10.235101148168399,
      "grad_norm": 0.01961817778646946,
      "learning_rate": 9.764898851831602e-06,
      "loss": 0.0214,
      "step": 37440
    },
    {
      "epoch": 10.237834882449427,
      "grad_norm": 0.002884747227653861,
      "learning_rate": 9.762165117550576e-06,
      "loss": 0.0022,
      "step": 37450
    },
    {
      "epoch": 10.240568616730453,
      "grad_norm": 0.0012640119530260563,
      "learning_rate": 9.759431383269547e-06,
      "loss": 0.0058,
      "step": 37460
    },
    {
      "epoch": 10.243302351011481,
      "grad_norm": 0.0021731292363256216,
      "learning_rate": 9.756697648988519e-06,
      "loss": 0.0194,
      "step": 37470
    },
    {
      "epoch": 10.24603608529251,
      "grad_norm": 0.0034040079917758703,
      "learning_rate": 9.753963914707492e-06,
      "loss": 0.0281,
      "step": 37480
    },
    {
      "epoch": 10.248769819573537,
      "grad_norm": 0.16496427357196808,
      "learning_rate": 9.751230180426464e-06,
      "loss": 0.0026,
      "step": 37490
    },
    {
      "epoch": 10.251503553854565,
      "grad_norm": 0.768769383430481,
      "learning_rate": 9.748496446145436e-06,
      "loss": 0.0012,
      "step": 37500
    },
    {
      "epoch": 10.254237288135593,
      "grad_norm": 0.0019180550007149577,
      "learning_rate": 9.745762711864407e-06,
      "loss": 0.0002,
      "step": 37510
    },
    {
      "epoch": 10.256971022416622,
      "grad_norm": 0.0027427016757428646,
      "learning_rate": 9.74302897758338e-06,
      "loss": 0.0014,
      "step": 37520
    },
    {
      "epoch": 10.25970475669765,
      "grad_norm": 0.8336813449859619,
      "learning_rate": 9.740295243302352e-06,
      "loss": 0.0147,
      "step": 37530
    },
    {
      "epoch": 10.262438490978678,
      "grad_norm": 0.0018655575113371015,
      "learning_rate": 9.737561509021324e-06,
      "loss": 0.0001,
      "step": 37540
    },
    {
      "epoch": 10.265172225259704,
      "grad_norm": 0.5453859567642212,
      "learning_rate": 9.734827774740297e-06,
      "loss": 0.0021,
      "step": 37550
    },
    {
      "epoch": 10.267905959540732,
      "grad_norm": 0.0029278157744556665,
      "learning_rate": 9.732094040459267e-06,
      "loss": 0.0001,
      "step": 37560
    },
    {
      "epoch": 10.27063969382176,
      "grad_norm": 4.320791721343994,
      "learning_rate": 9.72936030617824e-06,
      "loss": 0.0238,
      "step": 37570
    },
    {
      "epoch": 10.273373428102788,
      "grad_norm": 0.0018677290063351393,
      "learning_rate": 9.726626571897212e-06,
      "loss": 0.0001,
      "step": 37580
    },
    {
      "epoch": 10.276107162383816,
      "grad_norm": 0.004127617459744215,
      "learning_rate": 9.723892837616184e-06,
      "loss": 0.0126,
      "step": 37590
    },
    {
      "epoch": 10.278840896664844,
      "grad_norm": 1.2265914678573608,
      "learning_rate": 9.721159103335157e-06,
      "loss": 0.0118,
      "step": 37600
    },
    {
      "epoch": 10.281574630945872,
      "grad_norm": 0.0017425474943593144,
      "learning_rate": 9.718425369054129e-06,
      "loss": 0.0316,
      "step": 37610
    },
    {
      "epoch": 10.2843083652269,
      "grad_norm": 0.0030001436825841665,
      "learning_rate": 9.7156916347731e-06,
      "loss": 0.0001,
      "step": 37620
    },
    {
      "epoch": 10.287042099507929,
      "grad_norm": 0.006096798460930586,
      "learning_rate": 9.712957900492072e-06,
      "loss": 0.0283,
      "step": 37630
    },
    {
      "epoch": 10.289775833788955,
      "grad_norm": 0.005910114385187626,
      "learning_rate": 9.710224166211045e-06,
      "loss": 0.0075,
      "step": 37640
    },
    {
      "epoch": 10.292509568069983,
      "grad_norm": 0.07148780673742294,
      "learning_rate": 9.707490431930017e-06,
      "loss": 0.0111,
      "step": 37650
    },
    {
      "epoch": 10.295243302351011,
      "grad_norm": 0.0832490399479866,
      "learning_rate": 9.704756697648989e-06,
      "loss": 0.0069,
      "step": 37660
    },
    {
      "epoch": 10.29797703663204,
      "grad_norm": 0.005191681906580925,
      "learning_rate": 9.702022963367962e-06,
      "loss": 0.0081,
      "step": 37670
    },
    {
      "epoch": 10.300710770913067,
      "grad_norm": 0.002696266397833824,
      "learning_rate": 9.699289229086934e-06,
      "loss": 0.0002,
      "step": 37680
    },
    {
      "epoch": 10.303444505194095,
      "grad_norm": 0.0037714869249612093,
      "learning_rate": 9.696555494805905e-06,
      "loss": 0.0043,
      "step": 37690
    },
    {
      "epoch": 10.306178239475123,
      "grad_norm": 0.0037826276384294033,
      "learning_rate": 9.693821760524877e-06,
      "loss": 0.0437,
      "step": 37700
    },
    {
      "epoch": 10.308911973756151,
      "grad_norm": 0.0197233185172081,
      "learning_rate": 9.69108802624385e-06,
      "loss": 0.0338,
      "step": 37710
    },
    {
      "epoch": 10.31164570803718,
      "grad_norm": 0.42167842388153076,
      "learning_rate": 9.688354291962822e-06,
      "loss": 0.0067,
      "step": 37720
    },
    {
      "epoch": 10.314379442318206,
      "grad_norm": 0.053321968764066696,
      "learning_rate": 9.685620557681794e-06,
      "loss": 0.0026,
      "step": 37730
    },
    {
      "epoch": 10.317113176599234,
      "grad_norm": 0.009124737232923508,
      "learning_rate": 9.682886823400767e-06,
      "loss": 0.0134,
      "step": 37740
    },
    {
      "epoch": 10.319846910880262,
      "grad_norm": 0.0032086060382425785,
      "learning_rate": 9.680153089119739e-06,
      "loss": 0.0046,
      "step": 37750
    },
    {
      "epoch": 10.32258064516129,
      "grad_norm": 0.0023594277445226908,
      "learning_rate": 9.67741935483871e-06,
      "loss": 0.0033,
      "step": 37760
    },
    {
      "epoch": 10.325314379442318,
      "grad_norm": 0.0036778245121240616,
      "learning_rate": 9.674685620557682e-06,
      "loss": 0.0052,
      "step": 37770
    },
    {
      "epoch": 10.328048113723346,
      "grad_norm": 0.0018710666336119175,
      "learning_rate": 9.671951886276655e-06,
      "loss": 0.0076,
      "step": 37780
    },
    {
      "epoch": 10.330781848004374,
      "grad_norm": 0.002784745069220662,
      "learning_rate": 9.669218151995627e-06,
      "loss": 0.0042,
      "step": 37790
    },
    {
      "epoch": 10.333515582285402,
      "grad_norm": 0.002592878183349967,
      "learning_rate": 9.666484417714599e-06,
      "loss": 0.0093,
      "step": 37800
    },
    {
      "epoch": 10.33624931656643,
      "grad_norm": 0.0038330296520143747,
      "learning_rate": 9.663750683433572e-06,
      "loss": 0.0217,
      "step": 37810
    },
    {
      "epoch": 10.338983050847457,
      "grad_norm": 2.530210018157959,
      "learning_rate": 9.661016949152544e-06,
      "loss": 0.0103,
      "step": 37820
    },
    {
      "epoch": 10.341716785128485,
      "grad_norm": 0.06437234580516815,
      "learning_rate": 9.658283214871515e-06,
      "loss": 0.0002,
      "step": 37830
    },
    {
      "epoch": 10.344450519409513,
      "grad_norm": 0.0018806206062436104,
      "learning_rate": 9.655549480590487e-06,
      "loss": 0.0189,
      "step": 37840
    },
    {
      "epoch": 10.347184253690541,
      "grad_norm": 0.5049130320549011,
      "learning_rate": 9.65281574630946e-06,
      "loss": 0.0174,
      "step": 37850
    },
    {
      "epoch": 10.349917987971569,
      "grad_norm": 1.2977442741394043,
      "learning_rate": 9.65008201202843e-06,
      "loss": 0.0077,
      "step": 37860
    },
    {
      "epoch": 10.352651722252597,
      "grad_norm": 0.5019329786300659,
      "learning_rate": 9.647348277747404e-06,
      "loss": 0.0049,
      "step": 37870
    },
    {
      "epoch": 10.355385456533625,
      "grad_norm": 0.013625514693558216,
      "learning_rate": 9.644614543466377e-06,
      "loss": 0.0062,
      "step": 37880
    },
    {
      "epoch": 10.358119190814653,
      "grad_norm": 0.001726078917272389,
      "learning_rate": 9.641880809185347e-06,
      "loss": 0.0029,
      "step": 37890
    },
    {
      "epoch": 10.360852925095681,
      "grad_norm": 0.0011730677215382457,
      "learning_rate": 9.63914707490432e-06,
      "loss": 0.0002,
      "step": 37900
    },
    {
      "epoch": 10.36358665937671,
      "grad_norm": 0.9500999450683594,
      "learning_rate": 9.636413340623292e-06,
      "loss": 0.0057,
      "step": 37910
    },
    {
      "epoch": 10.366320393657736,
      "grad_norm": 0.0034776353277266026,
      "learning_rate": 9.633679606342264e-06,
      "loss": 0.004,
      "step": 37920
    },
    {
      "epoch": 10.369054127938764,
      "grad_norm": 0.002777020214125514,
      "learning_rate": 9.630945872061237e-06,
      "loss": 0.0085,
      "step": 37930
    },
    {
      "epoch": 10.371787862219792,
      "grad_norm": 0.0012418710393831134,
      "learning_rate": 9.628212137780209e-06,
      "loss": 0.0076,
      "step": 37940
    },
    {
      "epoch": 10.37452159650082,
      "grad_norm": 0.0018065499607473612,
      "learning_rate": 9.62547840349918e-06,
      "loss": 0.0059,
      "step": 37950
    },
    {
      "epoch": 10.377255330781848,
      "grad_norm": 0.8900792598724365,
      "learning_rate": 9.622744669218152e-06,
      "loss": 0.0045,
      "step": 37960
    },
    {
      "epoch": 10.379989065062876,
      "grad_norm": 1.5072271823883057,
      "learning_rate": 9.620010934937125e-06,
      "loss": 0.0139,
      "step": 37970
    },
    {
      "epoch": 10.382722799343904,
      "grad_norm": 0.3729069232940674,
      "learning_rate": 9.617277200656097e-06,
      "loss": 0.0063,
      "step": 37980
    },
    {
      "epoch": 10.385456533624932,
      "grad_norm": 10.921281814575195,
      "learning_rate": 9.614543466375069e-06,
      "loss": 0.0363,
      "step": 37990
    },
    {
      "epoch": 10.38819026790596,
      "grad_norm": 0.0009505251655355096,
      "learning_rate": 9.611809732094042e-06,
      "loss": 0.0032,
      "step": 38000
    },
    {
      "epoch": 10.390924002186987,
      "grad_norm": 0.4243759214878082,
      "learning_rate": 9.609075997813014e-06,
      "loss": 0.0553,
      "step": 38010
    },
    {
      "epoch": 10.393657736468015,
      "grad_norm": 24.2849063873291,
      "learning_rate": 9.606342263531985e-06,
      "loss": 0.0271,
      "step": 38020
    },
    {
      "epoch": 10.396391470749043,
      "grad_norm": 0.013991538435220718,
      "learning_rate": 9.603608529250957e-06,
      "loss": 0.0204,
      "step": 38030
    },
    {
      "epoch": 10.39912520503007,
      "grad_norm": 7.93850564956665,
      "learning_rate": 9.60087479496993e-06,
      "loss": 0.0183,
      "step": 38040
    },
    {
      "epoch": 10.401858939311099,
      "grad_norm": 0.03150223195552826,
      "learning_rate": 9.598141060688902e-06,
      "loss": 0.0026,
      "step": 38050
    },
    {
      "epoch": 10.404592673592127,
      "grad_norm": 16.856382369995117,
      "learning_rate": 9.595407326407874e-06,
      "loss": 0.0107,
      "step": 38060
    },
    {
      "epoch": 10.407326407873155,
      "grad_norm": 0.9506456851959229,
      "learning_rate": 9.592673592126847e-06,
      "loss": 0.0242,
      "step": 38070
    },
    {
      "epoch": 10.410060142154183,
      "grad_norm": 0.007553657051175833,
      "learning_rate": 9.589939857845819e-06,
      "loss": 0.0058,
      "step": 38080
    },
    {
      "epoch": 10.412793876435211,
      "grad_norm": 0.07006347924470901,
      "learning_rate": 9.58720612356479e-06,
      "loss": 0.0246,
      "step": 38090
    },
    {
      "epoch": 10.415527610716238,
      "grad_norm": 3.5404109954833984,
      "learning_rate": 9.584472389283762e-06,
      "loss": 0.0127,
      "step": 38100
    },
    {
      "epoch": 10.418261344997266,
      "grad_norm": 0.0013617753284052014,
      "learning_rate": 9.581738655002735e-06,
      "loss": 0.0012,
      "step": 38110
    },
    {
      "epoch": 10.420995079278294,
      "grad_norm": 0.0011886253487318754,
      "learning_rate": 9.579004920721707e-06,
      "loss": 0.0001,
      "step": 38120
    },
    {
      "epoch": 10.423728813559322,
      "grad_norm": 0.0012115362333133817,
      "learning_rate": 9.576271186440679e-06,
      "loss": 0.0047,
      "step": 38130
    },
    {
      "epoch": 10.42646254784035,
      "grad_norm": 1.0293500423431396,
      "learning_rate": 9.573537452159652e-06,
      "loss": 0.0099,
      "step": 38140
    },
    {
      "epoch": 10.429196282121378,
      "grad_norm": 2.9884724617004395,
      "learning_rate": 9.570803717878624e-06,
      "loss": 0.0321,
      "step": 38150
    },
    {
      "epoch": 10.431930016402406,
      "grad_norm": 0.1884586215019226,
      "learning_rate": 9.568069983597595e-06,
      "loss": 0.0088,
      "step": 38160
    },
    {
      "epoch": 10.434663750683434,
      "grad_norm": 0.0009194135200232267,
      "learning_rate": 9.565336249316567e-06,
      "loss": 0.0057,
      "step": 38170
    },
    {
      "epoch": 10.437397484964462,
      "grad_norm": 0.001955254701897502,
      "learning_rate": 9.56260251503554e-06,
      "loss": 0.0272,
      "step": 38180
    },
    {
      "epoch": 10.440131219245488,
      "grad_norm": 0.0006384919979609549,
      "learning_rate": 9.55986878075451e-06,
      "loss": 0.0316,
      "step": 38190
    },
    {
      "epoch": 10.442864953526517,
      "grad_norm": 0.0012237651972100139,
      "learning_rate": 9.557135046473484e-06,
      "loss": 0.014,
      "step": 38200
    },
    {
      "epoch": 10.445598687807545,
      "grad_norm": 0.0009951243409886956,
      "learning_rate": 9.554401312192457e-06,
      "loss": 0.0,
      "step": 38210
    },
    {
      "epoch": 10.448332422088573,
      "grad_norm": 0.0014538888353854418,
      "learning_rate": 9.551667577911427e-06,
      "loss": 0.0008,
      "step": 38220
    },
    {
      "epoch": 10.4510661563696,
      "grad_norm": 0.0006771815242245793,
      "learning_rate": 9.5489338436304e-06,
      "loss": 0.0115,
      "step": 38230
    },
    {
      "epoch": 10.453799890650629,
      "grad_norm": 0.0006167899118736386,
      "learning_rate": 9.546200109349372e-06,
      "loss": 0.0147,
      "step": 38240
    },
    {
      "epoch": 10.456533624931657,
      "grad_norm": 0.0020464533008635044,
      "learning_rate": 9.543466375068344e-06,
      "loss": 0.0036,
      "step": 38250
    },
    {
      "epoch": 10.459267359212685,
      "grad_norm": 0.003704053582623601,
      "learning_rate": 9.540732640787315e-06,
      "loss": 0.001,
      "step": 38260
    },
    {
      "epoch": 10.462001093493713,
      "grad_norm": 0.0007318732095882297,
      "learning_rate": 9.537998906506289e-06,
      "loss": 0.0224,
      "step": 38270
    },
    {
      "epoch": 10.464734827774741,
      "grad_norm": 1.7852295637130737,
      "learning_rate": 9.53526517222526e-06,
      "loss": 0.0234,
      "step": 38280
    },
    {
      "epoch": 10.467468562055767,
      "grad_norm": 2.0725152492523193,
      "learning_rate": 9.532531437944232e-06,
      "loss": 0.0934,
      "step": 38290
    },
    {
      "epoch": 10.470202296336796,
      "grad_norm": 2.7240664958953857,
      "learning_rate": 9.529797703663205e-06,
      "loss": 0.0191,
      "step": 38300
    },
    {
      "epoch": 10.472936030617824,
      "grad_norm": 0.03404989466071129,
      "learning_rate": 9.527063969382177e-06,
      "loss": 0.0226,
      "step": 38310
    },
    {
      "epoch": 10.475669764898852,
      "grad_norm": 2.036069631576538,
      "learning_rate": 9.524330235101149e-06,
      "loss": 0.0115,
      "step": 38320
    },
    {
      "epoch": 10.47840349917988,
      "grad_norm": 0.004971875809133053,
      "learning_rate": 9.52159650082012e-06,
      "loss": 0.0048,
      "step": 38330
    },
    {
      "epoch": 10.481137233460908,
      "grad_norm": 0.022212473675608635,
      "learning_rate": 9.518862766539094e-06,
      "loss": 0.0008,
      "step": 38340
    },
    {
      "epoch": 10.483870967741936,
      "grad_norm": 0.0013588378205895424,
      "learning_rate": 9.516129032258065e-06,
      "loss": 0.0344,
      "step": 38350
    },
    {
      "epoch": 10.486604702022964,
      "grad_norm": 0.8132977485656738,
      "learning_rate": 9.513395297977037e-06,
      "loss": 0.0119,
      "step": 38360
    },
    {
      "epoch": 10.489338436303992,
      "grad_norm": 0.002413233043625951,
      "learning_rate": 9.51066156369601e-06,
      "loss": 0.0335,
      "step": 38370
    },
    {
      "epoch": 10.492072170585018,
      "grad_norm": 0.0013308677589520812,
      "learning_rate": 9.507927829414982e-06,
      "loss": 0.0024,
      "step": 38380
    },
    {
      "epoch": 10.494805904866046,
      "grad_norm": 0.00553631316870451,
      "learning_rate": 9.505194095133954e-06,
      "loss": 0.0069,
      "step": 38390
    },
    {
      "epoch": 10.497539639147075,
      "grad_norm": 0.0028735243249684572,
      "learning_rate": 9.502460360852925e-06,
      "loss": 0.0003,
      "step": 38400
    },
    {
      "epoch": 10.500273373428103,
      "grad_norm": 0.019326968118548393,
      "learning_rate": 9.499726626571899e-06,
      "loss": 0.0116,
      "step": 38410
    },
    {
      "epoch": 10.50300710770913,
      "grad_norm": 0.0009367403108626604,
      "learning_rate": 9.49699289229087e-06,
      "loss": 0.0104,
      "step": 38420
    },
    {
      "epoch": 10.505740841990159,
      "grad_norm": 0.006608438212424517,
      "learning_rate": 9.494259158009842e-06,
      "loss": 0.0288,
      "step": 38430
    },
    {
      "epoch": 10.508474576271187,
      "grad_norm": 0.004870720207691193,
      "learning_rate": 9.491525423728815e-06,
      "loss": 0.0126,
      "step": 38440
    },
    {
      "epoch": 10.511208310552215,
      "grad_norm": 0.0011558644473552704,
      "learning_rate": 9.488791689447787e-06,
      "loss": 0.0015,
      "step": 38450
    },
    {
      "epoch": 10.513942044833243,
      "grad_norm": 0.001158192753791809,
      "learning_rate": 9.486057955166759e-06,
      "loss": 0.0377,
      "step": 38460
    },
    {
      "epoch": 10.51667577911427,
      "grad_norm": 0.0015528377844020724,
      "learning_rate": 9.483324220885732e-06,
      "loss": 0.0059,
      "step": 38470
    },
    {
      "epoch": 10.519409513395297,
      "grad_norm": 0.004030842334032059,
      "learning_rate": 9.480590486604704e-06,
      "loss": 0.0094,
      "step": 38480
    },
    {
      "epoch": 10.522143247676325,
      "grad_norm": 2.54671049118042,
      "learning_rate": 9.477856752323675e-06,
      "loss": 0.045,
      "step": 38490
    },
    {
      "epoch": 10.524876981957354,
      "grad_norm": 0.0028368630446493626,
      "learning_rate": 9.475123018042647e-06,
      "loss": 0.0086,
      "step": 38500
    },
    {
      "epoch": 10.527610716238382,
      "grad_norm": 1.8164645433425903,
      "learning_rate": 9.47238928376162e-06,
      "loss": 0.0024,
      "step": 38510
    },
    {
      "epoch": 10.53034445051941,
      "grad_norm": 0.004205789417028427,
      "learning_rate": 9.46965554948059e-06,
      "loss": 0.0147,
      "step": 38520
    },
    {
      "epoch": 10.533078184800438,
      "grad_norm": 0.0034760611597448587,
      "learning_rate": 9.466921815199563e-06,
      "loss": 0.0007,
      "step": 38530
    },
    {
      "epoch": 10.535811919081466,
      "grad_norm": 0.0019159222720190883,
      "learning_rate": 9.464188080918537e-06,
      "loss": 0.0005,
      "step": 38540
    },
    {
      "epoch": 10.538545653362494,
      "grad_norm": 0.0025568592827767134,
      "learning_rate": 9.461454346637507e-06,
      "loss": 0.0062,
      "step": 38550
    },
    {
      "epoch": 10.54127938764352,
      "grad_norm": 0.2496645748615265,
      "learning_rate": 9.45872061235648e-06,
      "loss": 0.0107,
      "step": 38560
    },
    {
      "epoch": 10.544013121924548,
      "grad_norm": 0.037363119423389435,
      "learning_rate": 9.455986878075452e-06,
      "loss": 0.0059,
      "step": 38570
    },
    {
      "epoch": 10.546746856205576,
      "grad_norm": 0.0016448209062218666,
      "learning_rate": 9.453253143794423e-06,
      "loss": 0.0074,
      "step": 38580
    },
    {
      "epoch": 10.549480590486604,
      "grad_norm": 0.002059502759948373,
      "learning_rate": 9.450519409513395e-06,
      "loss": 0.0001,
      "step": 38590
    },
    {
      "epoch": 10.552214324767633,
      "grad_norm": 0.0040113311260938644,
      "learning_rate": 9.447785675232368e-06,
      "loss": 0.0335,
      "step": 38600
    },
    {
      "epoch": 10.55494805904866,
      "grad_norm": 4.064955234527588,
      "learning_rate": 9.44505194095134e-06,
      "loss": 0.0265,
      "step": 38610
    },
    {
      "epoch": 10.557681793329689,
      "grad_norm": 0.0032940595410764217,
      "learning_rate": 9.442318206670312e-06,
      "loss": 0.0033,
      "step": 38620
    },
    {
      "epoch": 10.560415527610717,
      "grad_norm": 0.003191627562046051,
      "learning_rate": 9.439584472389285e-06,
      "loss": 0.0028,
      "step": 38630
    },
    {
      "epoch": 10.563149261891745,
      "grad_norm": 0.006187546066939831,
      "learning_rate": 9.436850738108257e-06,
      "loss": 0.0085,
      "step": 38640
    },
    {
      "epoch": 10.565882996172771,
      "grad_norm": 0.0028345701284706593,
      "learning_rate": 9.434117003827228e-06,
      "loss": 0.0024,
      "step": 38650
    },
    {
      "epoch": 10.5686167304538,
      "grad_norm": 0.0015821498818695545,
      "learning_rate": 9.4313832695462e-06,
      "loss": 0.0044,
      "step": 38660
    },
    {
      "epoch": 10.571350464734827,
      "grad_norm": 0.0025119115598499775,
      "learning_rate": 9.428649535265173e-06,
      "loss": 0.0004,
      "step": 38670
    },
    {
      "epoch": 10.574084199015855,
      "grad_norm": 0.03027280978858471,
      "learning_rate": 9.425915800984145e-06,
      "loss": 0.0117,
      "step": 38680
    },
    {
      "epoch": 10.576817933296883,
      "grad_norm": 0.0022508101537823677,
      "learning_rate": 9.423182066703117e-06,
      "loss": 0.0056,
      "step": 38690
    },
    {
      "epoch": 10.579551667577912,
      "grad_norm": 0.03570796921849251,
      "learning_rate": 9.42044833242209e-06,
      "loss": 0.0062,
      "step": 38700
    },
    {
      "epoch": 10.58228540185894,
      "grad_norm": 0.0016707746544852853,
      "learning_rate": 9.417714598141062e-06,
      "loss": 0.0211,
      "step": 38710
    },
    {
      "epoch": 10.585019136139968,
      "grad_norm": 0.001959596760571003,
      "learning_rate": 9.414980863860033e-06,
      "loss": 0.0077,
      "step": 38720
    },
    {
      "epoch": 10.587752870420996,
      "grad_norm": 0.0017294769641011953,
      "learning_rate": 9.412247129579005e-06,
      "loss": 0.0057,
      "step": 38730
    },
    {
      "epoch": 10.590486604702022,
      "grad_norm": 1.0238486528396606,
      "learning_rate": 9.409513395297978e-06,
      "loss": 0.0102,
      "step": 38740
    },
    {
      "epoch": 10.59322033898305,
      "grad_norm": 0.0019061150960624218,
      "learning_rate": 9.40677966101695e-06,
      "loss": 0.0049,
      "step": 38750
    },
    {
      "epoch": 10.595954073264078,
      "grad_norm": 0.0008427913999184966,
      "learning_rate": 9.404045926735922e-06,
      "loss": 0.0001,
      "step": 38760
    },
    {
      "epoch": 10.598687807545106,
      "grad_norm": 0.0016659591346979141,
      "learning_rate": 9.401312192454895e-06,
      "loss": 0.013,
      "step": 38770
    },
    {
      "epoch": 10.601421541826134,
      "grad_norm": 0.001240515150129795,
      "learning_rate": 9.398578458173867e-06,
      "loss": 0.0047,
      "step": 38780
    },
    {
      "epoch": 10.604155276107162,
      "grad_norm": 0.0009644707897678018,
      "learning_rate": 9.395844723892838e-06,
      "loss": 0.0024,
      "step": 38790
    },
    {
      "epoch": 10.60688901038819,
      "grad_norm": 8.026263236999512,
      "learning_rate": 9.39311098961181e-06,
      "loss": 0.0337,
      "step": 38800
    },
    {
      "epoch": 10.609622744669219,
      "grad_norm": 0.0016782565508037806,
      "learning_rate": 9.390377255330783e-06,
      "loss": 0.0023,
      "step": 38810
    },
    {
      "epoch": 10.612356478950247,
      "grad_norm": 0.08280259370803833,
      "learning_rate": 9.387643521049755e-06,
      "loss": 0.0223,
      "step": 38820
    },
    {
      "epoch": 10.615090213231273,
      "grad_norm": 0.0012655530590564013,
      "learning_rate": 9.384909786768727e-06,
      "loss": 0.0288,
      "step": 38830
    },
    {
      "epoch": 10.617823947512301,
      "grad_norm": 0.018019285053014755,
      "learning_rate": 9.3821760524877e-06,
      "loss": 0.0059,
      "step": 38840
    },
    {
      "epoch": 10.62055768179333,
      "grad_norm": 0.7962774634361267,
      "learning_rate": 9.37944231820667e-06,
      "loss": 0.0095,
      "step": 38850
    },
    {
      "epoch": 10.623291416074357,
      "grad_norm": 0.0028480219189077616,
      "learning_rate": 9.376708583925643e-06,
      "loss": 0.0002,
      "step": 38860
    },
    {
      "epoch": 10.626025150355385,
      "grad_norm": 8.016914367675781,
      "learning_rate": 9.373974849644615e-06,
      "loss": 0.05,
      "step": 38870
    },
    {
      "epoch": 10.628758884636413,
      "grad_norm": 0.0015833548968657851,
      "learning_rate": 9.371241115363587e-06,
      "loss": 0.0072,
      "step": 38880
    },
    {
      "epoch": 10.631492618917441,
      "grad_norm": 0.002581527456641197,
      "learning_rate": 9.36850738108256e-06,
      "loss": 0.0162,
      "step": 38890
    },
    {
      "epoch": 10.63422635319847,
      "grad_norm": 0.00587071105837822,
      "learning_rate": 9.365773646801532e-06,
      "loss": 0.0223,
      "step": 38900
    },
    {
      "epoch": 10.636960087479498,
      "grad_norm": 0.0014785102102905512,
      "learning_rate": 9.363039912520503e-06,
      "loss": 0.0001,
      "step": 38910
    },
    {
      "epoch": 10.639693821760526,
      "grad_norm": 0.003765186294913292,
      "learning_rate": 9.360306178239475e-06,
      "loss": 0.0263,
      "step": 38920
    },
    {
      "epoch": 10.642427556041552,
      "grad_norm": 0.0018300089286640286,
      "learning_rate": 9.357572443958448e-06,
      "loss": 0.0074,
      "step": 38930
    },
    {
      "epoch": 10.64516129032258,
      "grad_norm": 0.002054037293419242,
      "learning_rate": 9.35483870967742e-06,
      "loss": 0.0046,
      "step": 38940
    },
    {
      "epoch": 10.647895024603608,
      "grad_norm": 0.0013388961087912321,
      "learning_rate": 9.352104975396392e-06,
      "loss": 0.0045,
      "step": 38950
    },
    {
      "epoch": 10.650628758884636,
      "grad_norm": 0.0014848726568743587,
      "learning_rate": 9.349371241115365e-06,
      "loss": 0.0129,
      "step": 38960
    },
    {
      "epoch": 10.653362493165664,
      "grad_norm": 2.0465598106384277,
      "learning_rate": 9.346637506834337e-06,
      "loss": 0.0029,
      "step": 38970
    },
    {
      "epoch": 10.656096227446692,
      "grad_norm": 0.0030933094676584005,
      "learning_rate": 9.343903772553308e-06,
      "loss": 0.0082,
      "step": 38980
    },
    {
      "epoch": 10.65882996172772,
      "grad_norm": 0.00265440228395164,
      "learning_rate": 9.34117003827228e-06,
      "loss": 0.0074,
      "step": 38990
    },
    {
      "epoch": 10.661563696008749,
      "grad_norm": 26.940805435180664,
      "learning_rate": 9.338436303991253e-06,
      "loss": 0.0184,
      "step": 39000
    },
    {
      "epoch": 10.664297430289777,
      "grad_norm": 0.0021408800967037678,
      "learning_rate": 9.335702569710225e-06,
      "loss": 0.0322,
      "step": 39010
    },
    {
      "epoch": 10.667031164570803,
      "grad_norm": 0.0015970418462529778,
      "learning_rate": 9.332968835429197e-06,
      "loss": 0.0493,
      "step": 39020
    },
    {
      "epoch": 10.669764898851831,
      "grad_norm": 0.0020336455199867487,
      "learning_rate": 9.33023510114817e-06,
      "loss": 0.0056,
      "step": 39030
    },
    {
      "epoch": 10.672498633132859,
      "grad_norm": 0.0017510438337922096,
      "learning_rate": 9.327501366867142e-06,
      "loss": 0.0001,
      "step": 39040
    },
    {
      "epoch": 10.675232367413887,
      "grad_norm": 0.002328724367544055,
      "learning_rate": 9.324767632586113e-06,
      "loss": 0.0085,
      "step": 39050
    },
    {
      "epoch": 10.677966101694915,
      "grad_norm": 0.0013772988459095359,
      "learning_rate": 9.322033898305085e-06,
      "loss": 0.0004,
      "step": 39060
    },
    {
      "epoch": 10.680699835975943,
      "grad_norm": 0.0029326025396585464,
      "learning_rate": 9.319300164024058e-06,
      "loss": 0.0082,
      "step": 39070
    },
    {
      "epoch": 10.683433570256971,
      "grad_norm": 0.045281678438186646,
      "learning_rate": 9.31656642974303e-06,
      "loss": 0.0095,
      "step": 39080
    },
    {
      "epoch": 10.686167304538,
      "grad_norm": 0.003639633534476161,
      "learning_rate": 9.313832695462002e-06,
      "loss": 0.0214,
      "step": 39090
    },
    {
      "epoch": 10.688901038819028,
      "grad_norm": 0.001701662433333695,
      "learning_rate": 9.311098961180975e-06,
      "loss": 0.0001,
      "step": 39100
    },
    {
      "epoch": 10.691634773100056,
      "grad_norm": 2.1840758323669434,
      "learning_rate": 9.308365226899947e-06,
      "loss": 0.0121,
      "step": 39110
    },
    {
      "epoch": 10.694368507381082,
      "grad_norm": 0.006187393330037594,
      "learning_rate": 9.305631492618918e-06,
      "loss": 0.0059,
      "step": 39120
    },
    {
      "epoch": 10.69710224166211,
      "grad_norm": 0.0058611659333109856,
      "learning_rate": 9.30289775833789e-06,
      "loss": 0.0027,
      "step": 39130
    },
    {
      "epoch": 10.699835975943138,
      "grad_norm": 0.00255591724999249,
      "learning_rate": 9.300164024056863e-06,
      "loss": 0.0017,
      "step": 39140
    },
    {
      "epoch": 10.702569710224166,
      "grad_norm": 0.002975902985781431,
      "learning_rate": 9.297430289775835e-06,
      "loss": 0.0262,
      "step": 39150
    },
    {
      "epoch": 10.705303444505194,
      "grad_norm": 0.06655053049325943,
      "learning_rate": 9.294696555494807e-06,
      "loss": 0.0243,
      "step": 39160
    },
    {
      "epoch": 10.708037178786222,
      "grad_norm": 0.8489425778388977,
      "learning_rate": 9.29196282121378e-06,
      "loss": 0.0407,
      "step": 39170
    },
    {
      "epoch": 10.71077091306725,
      "grad_norm": 0.0027715074829757214,
      "learning_rate": 9.28922908693275e-06,
      "loss": 0.0223,
      "step": 39180
    },
    {
      "epoch": 10.713504647348278,
      "grad_norm": 0.004202434327453375,
      "learning_rate": 9.286495352651723e-06,
      "loss": 0.0003,
      "step": 39190
    },
    {
      "epoch": 10.716238381629307,
      "grad_norm": 0.0026761353947222233,
      "learning_rate": 9.283761618370695e-06,
      "loss": 0.0001,
      "step": 39200
    },
    {
      "epoch": 10.718972115910333,
      "grad_norm": 0.0032908932771533728,
      "learning_rate": 9.281027884089667e-06,
      "loss": 0.0015,
      "step": 39210
    },
    {
      "epoch": 10.721705850191361,
      "grad_norm": 1.3324068784713745,
      "learning_rate": 9.27829414980864e-06,
      "loss": 0.0026,
      "step": 39220
    },
    {
      "epoch": 10.724439584472389,
      "grad_norm": 0.008659044280648232,
      "learning_rate": 9.275560415527612e-06,
      "loss": 0.0263,
      "step": 39230
    },
    {
      "epoch": 10.727173318753417,
      "grad_norm": 0.008909597061574459,
      "learning_rate": 9.272826681246583e-06,
      "loss": 0.0359,
      "step": 39240
    },
    {
      "epoch": 10.729907053034445,
      "grad_norm": 0.13714699447155,
      "learning_rate": 9.270092946965555e-06,
      "loss": 0.0062,
      "step": 39250
    },
    {
      "epoch": 10.732640787315473,
      "grad_norm": 0.004950910806655884,
      "learning_rate": 9.267359212684528e-06,
      "loss": 0.0001,
      "step": 39260
    },
    {
      "epoch": 10.735374521596501,
      "grad_norm": 0.0027722609229385853,
      "learning_rate": 9.2646254784035e-06,
      "loss": 0.0034,
      "step": 39270
    },
    {
      "epoch": 10.73810825587753,
      "grad_norm": 0.0026514094788581133,
      "learning_rate": 9.261891744122472e-06,
      "loss": 0.0103,
      "step": 39280
    },
    {
      "epoch": 10.740841990158557,
      "grad_norm": 0.005585240665823221,
      "learning_rate": 9.259158009841445e-06,
      "loss": 0.0113,
      "step": 39290
    },
    {
      "epoch": 10.743575724439584,
      "grad_norm": 0.003292458364740014,
      "learning_rate": 9.256424275560417e-06,
      "loss": 0.0014,
      "step": 39300
    },
    {
      "epoch": 10.746309458720612,
      "grad_norm": 0.010939178057014942,
      "learning_rate": 9.253690541279388e-06,
      "loss": 0.0168,
      "step": 39310
    },
    {
      "epoch": 10.74904319300164,
      "grad_norm": 0.011811326257884502,
      "learning_rate": 9.25095680699836e-06,
      "loss": 0.0012,
      "step": 39320
    },
    {
      "epoch": 10.751776927282668,
      "grad_norm": 0.0018391525372862816,
      "learning_rate": 9.248223072717333e-06,
      "loss": 0.0092,
      "step": 39330
    },
    {
      "epoch": 10.754510661563696,
      "grad_norm": 0.003944944124668837,
      "learning_rate": 9.245489338436305e-06,
      "loss": 0.0057,
      "step": 39340
    },
    {
      "epoch": 10.757244395844724,
      "grad_norm": 0.0021810138132423162,
      "learning_rate": 9.242755604155277e-06,
      "loss": 0.0219,
      "step": 39350
    },
    {
      "epoch": 10.759978130125752,
      "grad_norm": 0.0018967223586514592,
      "learning_rate": 9.24002186987425e-06,
      "loss": 0.0155,
      "step": 39360
    },
    {
      "epoch": 10.76271186440678,
      "grad_norm": 0.002222972922027111,
      "learning_rate": 9.237288135593222e-06,
      "loss": 0.0063,
      "step": 39370
    },
    {
      "epoch": 10.765445598687808,
      "grad_norm": 0.27720022201538086,
      "learning_rate": 9.234554401312193e-06,
      "loss": 0.0057,
      "step": 39380
    },
    {
      "epoch": 10.768179332968835,
      "grad_norm": 0.025462130084633827,
      "learning_rate": 9.231820667031165e-06,
      "loss": 0.0413,
      "step": 39390
    },
    {
      "epoch": 10.770913067249863,
      "grad_norm": 0.0017037857323884964,
      "learning_rate": 9.229086932750138e-06,
      "loss": 0.0067,
      "step": 39400
    },
    {
      "epoch": 10.77364680153089,
      "grad_norm": 0.002513723913580179,
      "learning_rate": 9.22635319846911e-06,
      "loss": 0.0016,
      "step": 39410
    },
    {
      "epoch": 10.776380535811919,
      "grad_norm": 0.0019482512725517154,
      "learning_rate": 9.223619464188082e-06,
      "loss": 0.0023,
      "step": 39420
    },
    {
      "epoch": 10.779114270092947,
      "grad_norm": 0.0030281366780400276,
      "learning_rate": 9.220885729907055e-06,
      "loss": 0.0024,
      "step": 39430
    },
    {
      "epoch": 10.781848004373975,
      "grad_norm": 0.00675145722925663,
      "learning_rate": 9.218151995626027e-06,
      "loss": 0.0154,
      "step": 39440
    },
    {
      "epoch": 10.784581738655003,
      "grad_norm": 0.748024582862854,
      "learning_rate": 9.215418261344998e-06,
      "loss": 0.0179,
      "step": 39450
    },
    {
      "epoch": 10.787315472936031,
      "grad_norm": 0.0024663363583385944,
      "learning_rate": 9.21268452706397e-06,
      "loss": 0.001,
      "step": 39460
    },
    {
      "epoch": 10.79004920721706,
      "grad_norm": 1.6826848983764648,
      "learning_rate": 9.209950792782943e-06,
      "loss": 0.0252,
      "step": 39470
    },
    {
      "epoch": 10.792782941498086,
      "grad_norm": 0.0017718638991937041,
      "learning_rate": 9.207217058501913e-06,
      "loss": 0.0234,
      "step": 39480
    },
    {
      "epoch": 10.795516675779114,
      "grad_norm": 0.001951767597347498,
      "learning_rate": 9.204483324220886e-06,
      "loss": 0.0019,
      "step": 39490
    },
    {
      "epoch": 10.798250410060142,
      "grad_norm": 0.0018452918156981468,
      "learning_rate": 9.20174958993986e-06,
      "loss": 0.0074,
      "step": 39500
    },
    {
      "epoch": 10.80098414434117,
      "grad_norm": 0.0017114676302298903,
      "learning_rate": 9.19901585565883e-06,
      "loss": 0.0219,
      "step": 39510
    },
    {
      "epoch": 10.803717878622198,
      "grad_norm": 0.002776209730654955,
      "learning_rate": 9.196282121377803e-06,
      "loss": 0.0226,
      "step": 39520
    },
    {
      "epoch": 10.806451612903226,
      "grad_norm": 2.5586905479431152,
      "learning_rate": 9.193548387096775e-06,
      "loss": 0.0881,
      "step": 39530
    },
    {
      "epoch": 10.809185347184254,
      "grad_norm": 0.0039502475410699844,
      "learning_rate": 9.190814652815746e-06,
      "loss": 0.0049,
      "step": 39540
    },
    {
      "epoch": 10.811919081465282,
      "grad_norm": 0.9321004152297974,
      "learning_rate": 9.18808091853472e-06,
      "loss": 0.0032,
      "step": 39550
    },
    {
      "epoch": 10.81465281574631,
      "grad_norm": 0.014825774356722832,
      "learning_rate": 9.185347184253691e-06,
      "loss": 0.001,
      "step": 39560
    },
    {
      "epoch": 10.817386550027337,
      "grad_norm": 0.026279453188180923,
      "learning_rate": 9.182613449972663e-06,
      "loss": 0.0091,
      "step": 39570
    },
    {
      "epoch": 10.820120284308365,
      "grad_norm": 2.2425880432128906,
      "learning_rate": 9.179879715691635e-06,
      "loss": 0.0091,
      "step": 39580
    },
    {
      "epoch": 10.822854018589393,
      "grad_norm": 0.0051693362183868885,
      "learning_rate": 9.177145981410608e-06,
      "loss": 0.0013,
      "step": 39590
    },
    {
      "epoch": 10.82558775287042,
      "grad_norm": 2.39255428314209,
      "learning_rate": 9.17441224712958e-06,
      "loss": 0.0121,
      "step": 39600
    },
    {
      "epoch": 10.828321487151449,
      "grad_norm": 0.004539106041193008,
      "learning_rate": 9.171678512848551e-06,
      "loss": 0.0001,
      "step": 39610
    },
    {
      "epoch": 10.831055221432477,
      "grad_norm": 0.002902681939303875,
      "learning_rate": 9.168944778567525e-06,
      "loss": 0.0213,
      "step": 39620
    },
    {
      "epoch": 10.833788955713505,
      "grad_norm": 0.004172709304839373,
      "learning_rate": 9.166211044286496e-06,
      "loss": 0.0016,
      "step": 39630
    },
    {
      "epoch": 10.836522689994533,
      "grad_norm": 0.0035394777078181505,
      "learning_rate": 9.163477310005468e-06,
      "loss": 0.0799,
      "step": 39640
    },
    {
      "epoch": 10.839256424275561,
      "grad_norm": 0.013096507638692856,
      "learning_rate": 9.16074357572444e-06,
      "loss": 0.0046,
      "step": 39650
    },
    {
      "epoch": 10.841990158556587,
      "grad_norm": 0.4684455394744873,
      "learning_rate": 9.158009841443413e-06,
      "loss": 0.0016,
      "step": 39660
    },
    {
      "epoch": 10.844723892837616,
      "grad_norm": 0.010204591788351536,
      "learning_rate": 9.155276107162385e-06,
      "loss": 0.0122,
      "step": 39670
    },
    {
      "epoch": 10.847457627118644,
      "grad_norm": 0.014485935680568218,
      "learning_rate": 9.152542372881356e-06,
      "loss": 0.0101,
      "step": 39680
    },
    {
      "epoch": 10.850191361399672,
      "grad_norm": 0.002913308097049594,
      "learning_rate": 9.14980863860033e-06,
      "loss": 0.0145,
      "step": 39690
    },
    {
      "epoch": 10.8529250956807,
      "grad_norm": 0.006872156634926796,
      "learning_rate": 9.147074904319301e-06,
      "loss": 0.0006,
      "step": 39700
    },
    {
      "epoch": 10.855658829961728,
      "grad_norm": 0.0027537615969777107,
      "learning_rate": 9.144341170038273e-06,
      "loss": 0.0005,
      "step": 39710
    },
    {
      "epoch": 10.858392564242756,
      "grad_norm": 4.097352027893066,
      "learning_rate": 9.141607435757245e-06,
      "loss": 0.0036,
      "step": 39720
    },
    {
      "epoch": 10.861126298523784,
      "grad_norm": 0.002791636623442173,
      "learning_rate": 9.138873701476218e-06,
      "loss": 0.0061,
      "step": 39730
    },
    {
      "epoch": 10.863860032804812,
      "grad_norm": 0.0025740796700119972,
      "learning_rate": 9.13613996719519e-06,
      "loss": 0.0014,
      "step": 39740
    },
    {
      "epoch": 10.866593767085838,
      "grad_norm": 0.0027674208395183086,
      "learning_rate": 9.133406232914161e-06,
      "loss": 0.0393,
      "step": 39750
    },
    {
      "epoch": 10.869327501366866,
      "grad_norm": 0.017509842291474342,
      "learning_rate": 9.130672498633135e-06,
      "loss": 0.0001,
      "step": 39760
    },
    {
      "epoch": 10.872061235647895,
      "grad_norm": 2.1456305980682373,
      "learning_rate": 9.127938764352106e-06,
      "loss": 0.0099,
      "step": 39770
    },
    {
      "epoch": 10.874794969928923,
      "grad_norm": 0.0026955697685480118,
      "learning_rate": 9.125205030071078e-06,
      "loss": 0.0001,
      "step": 39780
    },
    {
      "epoch": 10.87752870420995,
      "grad_norm": 0.0071526761166751385,
      "learning_rate": 9.12247129579005e-06,
      "loss": 0.006,
      "step": 39790
    },
    {
      "epoch": 10.880262438490979,
      "grad_norm": 0.0027740122750401497,
      "learning_rate": 9.119737561509023e-06,
      "loss": 0.0266,
      "step": 39800
    },
    {
      "epoch": 10.882996172772007,
      "grad_norm": 8.696142196655273,
      "learning_rate": 9.117003827227993e-06,
      "loss": 0.0221,
      "step": 39810
    },
    {
      "epoch": 10.885729907053035,
      "grad_norm": 0.003742659231647849,
      "learning_rate": 9.114270092946966e-06,
      "loss": 0.0541,
      "step": 39820
    },
    {
      "epoch": 10.888463641334063,
      "grad_norm": 0.004787234589457512,
      "learning_rate": 9.11153635866594e-06,
      "loss": 0.0003,
      "step": 39830
    },
    {
      "epoch": 10.89119737561509,
      "grad_norm": 0.00569169269874692,
      "learning_rate": 9.10880262438491e-06,
      "loss": 0.0038,
      "step": 39840
    },
    {
      "epoch": 10.893931109896117,
      "grad_norm": 0.0066595496609807014,
      "learning_rate": 9.106068890103883e-06,
      "loss": 0.0002,
      "step": 39850
    },
    {
      "epoch": 10.896664844177145,
      "grad_norm": 0.006828094366937876,
      "learning_rate": 9.103335155822855e-06,
      "loss": 0.0002,
      "step": 39860
    },
    {
      "epoch": 10.899398578458174,
      "grad_norm": 0.010466725565493107,
      "learning_rate": 9.100601421541826e-06,
      "loss": 0.0082,
      "step": 39870
    },
    {
      "epoch": 10.902132312739202,
      "grad_norm": 0.6700912117958069,
      "learning_rate": 9.097867687260798e-06,
      "loss": 0.0305,
      "step": 39880
    },
    {
      "epoch": 10.90486604702023,
      "grad_norm": 0.0035970474127680063,
      "learning_rate": 9.095133952979771e-06,
      "loss": 0.0007,
      "step": 39890
    },
    {
      "epoch": 10.907599781301258,
      "grad_norm": 1.4290306568145752,
      "learning_rate": 9.092400218698743e-06,
      "loss": 0.008,
      "step": 39900
    },
    {
      "epoch": 10.910333515582286,
      "grad_norm": 0.004530686419457197,
      "learning_rate": 9.089666484417715e-06,
      "loss": 0.0175,
      "step": 39910
    },
    {
      "epoch": 10.913067249863314,
      "grad_norm": 0.010998837649822235,
      "learning_rate": 9.086932750136688e-06,
      "loss": 0.0002,
      "step": 39920
    },
    {
      "epoch": 10.915800984144342,
      "grad_norm": 2.2509443759918213,
      "learning_rate": 9.08419901585566e-06,
      "loss": 0.0026,
      "step": 39930
    },
    {
      "epoch": 10.918534718425368,
      "grad_norm": 0.004585838411003351,
      "learning_rate": 9.081465281574631e-06,
      "loss": 0.0003,
      "step": 39940
    },
    {
      "epoch": 10.921268452706396,
      "grad_norm": 0.09897545725107193,
      "learning_rate": 9.078731547293603e-06,
      "loss": 0.0017,
      "step": 39950
    },
    {
      "epoch": 10.924002186987424,
      "grad_norm": 4.447155952453613,
      "learning_rate": 9.075997813012576e-06,
      "loss": 0.0106,
      "step": 39960
    },
    {
      "epoch": 10.926735921268453,
      "grad_norm": 0.002608159091323614,
      "learning_rate": 9.073264078731548e-06,
      "loss": 0.0008,
      "step": 39970
    },
    {
      "epoch": 10.92946965554948,
      "grad_norm": 1.86201810836792,
      "learning_rate": 9.07053034445052e-06,
      "loss": 0.0094,
      "step": 39980
    },
    {
      "epoch": 10.932203389830509,
      "grad_norm": 0.0030712566804140806,
      "learning_rate": 9.067796610169493e-06,
      "loss": 0.0069,
      "step": 39990
    },
    {
      "epoch": 10.934937124111537,
      "grad_norm": 0.0024418842513114214,
      "learning_rate": 9.065062875888465e-06,
      "loss": 0.0027,
      "step": 40000
    },
    {
      "epoch": 10.937670858392565,
      "grad_norm": 0.0029894905164837837,
      "learning_rate": 9.062329141607436e-06,
      "loss": 0.0385,
      "step": 40010
    },
    {
      "epoch": 10.940404592673593,
      "grad_norm": 0.036231089383363724,
      "learning_rate": 9.059595407326408e-06,
      "loss": 0.0002,
      "step": 40020
    },
    {
      "epoch": 10.94313832695462,
      "grad_norm": 0.0026726594660431147,
      "learning_rate": 9.056861673045381e-06,
      "loss": 0.0021,
      "step": 40030
    },
    {
      "epoch": 10.945872061235647,
      "grad_norm": 0.022280169650912285,
      "learning_rate": 9.054127938764353e-06,
      "loss": 0.0052,
      "step": 40040
    },
    {
      "epoch": 10.948605795516675,
      "grad_norm": 0.002503839321434498,
      "learning_rate": 9.051394204483325e-06,
      "loss": 0.0064,
      "step": 40050
    },
    {
      "epoch": 10.951339529797703,
      "grad_norm": 0.002495331224054098,
      "learning_rate": 9.048660470202298e-06,
      "loss": 0.0072,
      "step": 40060
    },
    {
      "epoch": 10.954073264078731,
      "grad_norm": 1.7751425504684448,
      "learning_rate": 9.04592673592127e-06,
      "loss": 0.0152,
      "step": 40070
    },
    {
      "epoch": 10.95680699835976,
      "grad_norm": 0.001790231908671558,
      "learning_rate": 9.043193001640241e-06,
      "loss": 0.0004,
      "step": 40080
    },
    {
      "epoch": 10.959540732640788,
      "grad_norm": 0.0026635571848601103,
      "learning_rate": 9.040459267359215e-06,
      "loss": 0.004,
      "step": 40090
    },
    {
      "epoch": 10.962274466921816,
      "grad_norm": 0.06253193318843842,
      "learning_rate": 9.037725533078186e-06,
      "loss": 0.0015,
      "step": 40100
    },
    {
      "epoch": 10.965008201202844,
      "grad_norm": 0.004157322458922863,
      "learning_rate": 9.034991798797158e-06,
      "loss": 0.006,
      "step": 40110
    },
    {
      "epoch": 10.967741935483872,
      "grad_norm": 0.3966902494430542,
      "learning_rate": 9.03225806451613e-06,
      "loss": 0.003,
      "step": 40120
    },
    {
      "epoch": 10.970475669764898,
      "grad_norm": 0.0018496991833671927,
      "learning_rate": 9.029524330235101e-06,
      "loss": 0.0011,
      "step": 40130
    },
    {
      "epoch": 10.973209404045926,
      "grad_norm": 0.00143400055821985,
      "learning_rate": 9.026790595954073e-06,
      "loss": 0.0031,
      "step": 40140
    },
    {
      "epoch": 10.975943138326954,
      "grad_norm": 0.002236229134723544,
      "learning_rate": 9.024056861673046e-06,
      "loss": 0.0162,
      "step": 40150
    },
    {
      "epoch": 10.978676872607982,
      "grad_norm": 5.934446811676025,
      "learning_rate": 9.021323127392018e-06,
      "loss": 0.0347,
      "step": 40160
    },
    {
      "epoch": 10.98141060688901,
      "grad_norm": 0.001894910354167223,
      "learning_rate": 9.01858939311099e-06,
      "loss": 0.0064,
      "step": 40170
    },
    {
      "epoch": 10.984144341170039,
      "grad_norm": 27.78564453125,
      "learning_rate": 9.015855658829963e-06,
      "loss": 0.0163,
      "step": 40180
    },
    {
      "epoch": 10.986878075451067,
      "grad_norm": 0.001420943415723741,
      "learning_rate": 9.013121924548935e-06,
      "loss": 0.027,
      "step": 40190
    },
    {
      "epoch": 10.989611809732095,
      "grad_norm": 1.2938562631607056,
      "learning_rate": 9.010388190267906e-06,
      "loss": 0.0065,
      "step": 40200
    },
    {
      "epoch": 10.992345544013123,
      "grad_norm": 0.001674831029959023,
      "learning_rate": 9.007654455986878e-06,
      "loss": 0.0222,
      "step": 40210
    },
    {
      "epoch": 10.995079278294149,
      "grad_norm": 0.003772466443479061,
      "learning_rate": 9.004920721705851e-06,
      "loss": 0.003,
      "step": 40220
    },
    {
      "epoch": 10.997813012575177,
      "grad_norm": 0.002070316346362233,
      "learning_rate": 9.002186987424823e-06,
      "loss": 0.0131,
      "step": 40230
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.9912728820774798,
      "eval_f1": 0.9652983495556496,
      "eval_loss": 0.03862287476658821,
      "eval_precision": 0.9571968107427612,
      "eval_recall": 0.9735381988903116,
      "eval_runtime": 793.666,
      "eval_samples_per_second": 23.705,
      "eval_steps_per_second": 0.988,
      "step": 40238
    },
    {
      "epoch": 11.000546746856205,
      "grad_norm": 0.004491062369197607,
      "learning_rate": 8.999453253143795e-06,
      "loss": 0.0274,
      "step": 40240
    },
    {
      "epoch": 11.003280481137233,
      "grad_norm": 0.0018883253214880824,
      "learning_rate": 8.996719518862768e-06,
      "loss": 0.0032,
      "step": 40250
    },
    {
      "epoch": 11.006014215418261,
      "grad_norm": 0.00443566357716918,
      "learning_rate": 8.99398578458174e-06,
      "loss": 0.0072,
      "step": 40260
    },
    {
      "epoch": 11.00874794969929,
      "grad_norm": 0.0022688566241413355,
      "learning_rate": 8.991252050300711e-06,
      "loss": 0.0067,
      "step": 40270
    },
    {
      "epoch": 11.011481683980318,
      "grad_norm": 0.6918574571609497,
      "learning_rate": 8.988518316019683e-06,
      "loss": 0.0061,
      "step": 40280
    },
    {
      "epoch": 11.014215418261346,
      "grad_norm": 0.054348502308130264,
      "learning_rate": 8.985784581738656e-06,
      "loss": 0.0001,
      "step": 40290
    },
    {
      "epoch": 11.016949152542374,
      "grad_norm": 0.0029492583125829697,
      "learning_rate": 8.983050847457628e-06,
      "loss": 0.001,
      "step": 40300
    },
    {
      "epoch": 11.0196828868234,
      "grad_norm": 0.0012412978103384376,
      "learning_rate": 8.9803171131766e-06,
      "loss": 0.0059,
      "step": 40310
    },
    {
      "epoch": 11.022416621104428,
      "grad_norm": 0.0016924405936151743,
      "learning_rate": 8.977583378895573e-06,
      "loss": 0.0001,
      "step": 40320
    },
    {
      "epoch": 11.025150355385456,
      "grad_norm": 0.003285215236246586,
      "learning_rate": 8.974849644614545e-06,
      "loss": 0.0001,
      "step": 40330
    },
    {
      "epoch": 11.027884089666484,
      "grad_norm": 0.0027915143873542547,
      "learning_rate": 8.972115910333516e-06,
      "loss": 0.0174,
      "step": 40340
    },
    {
      "epoch": 11.030617823947512,
      "grad_norm": 0.002193887485191226,
      "learning_rate": 8.969382176052488e-06,
      "loss": 0.0064,
      "step": 40350
    },
    {
      "epoch": 11.03335155822854,
      "grad_norm": 0.0018747333670035005,
      "learning_rate": 8.966648441771461e-06,
      "loss": 0.0001,
      "step": 40360
    },
    {
      "epoch": 11.036085292509568,
      "grad_norm": 6.603178977966309,
      "learning_rate": 8.963914707490433e-06,
      "loss": 0.0098,
      "step": 40370
    },
    {
      "epoch": 11.038819026790597,
      "grad_norm": 0.001356318243779242,
      "learning_rate": 8.961180973209405e-06,
      "loss": 0.018,
      "step": 40380
    },
    {
      "epoch": 11.041552761071625,
      "grad_norm": 0.0015836535021662712,
      "learning_rate": 8.958447238928378e-06,
      "loss": 0.0143,
      "step": 40390
    },
    {
      "epoch": 11.044286495352651,
      "grad_norm": 1.5047475099563599,
      "learning_rate": 8.95571350464735e-06,
      "loss": 0.0107,
      "step": 40400
    },
    {
      "epoch": 11.047020229633679,
      "grad_norm": 0.0013749779900535941,
      "learning_rate": 8.952979770366321e-06,
      "loss": 0.005,
      "step": 40410
    },
    {
      "epoch": 11.049753963914707,
      "grad_norm": 0.0018560641910880804,
      "learning_rate": 8.950246036085293e-06,
      "loss": 0.021,
      "step": 40420
    },
    {
      "epoch": 11.052487698195735,
      "grad_norm": 0.0016144088003784418,
      "learning_rate": 8.947512301804264e-06,
      "loss": 0.0083,
      "step": 40430
    },
    {
      "epoch": 11.055221432476763,
      "grad_norm": 0.6327041983604431,
      "learning_rate": 8.944778567523238e-06,
      "loss": 0.0035,
      "step": 40440
    },
    {
      "epoch": 11.057955166757791,
      "grad_norm": 11.266066551208496,
      "learning_rate": 8.94204483324221e-06,
      "loss": 0.0087,
      "step": 40450
    },
    {
      "epoch": 11.06068890103882,
      "grad_norm": 2.27587890625,
      "learning_rate": 8.939311098961181e-06,
      "loss": 0.0066,
      "step": 40460
    },
    {
      "epoch": 11.063422635319847,
      "grad_norm": 0.0017753526335582137,
      "learning_rate": 8.936577364680153e-06,
      "loss": 0.0116,
      "step": 40470
    },
    {
      "epoch": 11.066156369600876,
      "grad_norm": 0.015287380665540695,
      "learning_rate": 8.933843630399126e-06,
      "loss": 0.0006,
      "step": 40480
    },
    {
      "epoch": 11.068890103881902,
      "grad_norm": 0.002310671377927065,
      "learning_rate": 8.931109896118098e-06,
      "loss": 0.0061,
      "step": 40490
    },
    {
      "epoch": 11.07162383816293,
      "grad_norm": 0.0027802896220237017,
      "learning_rate": 8.92837616183707e-06,
      "loss": 0.0074,
      "step": 40500
    },
    {
      "epoch": 11.074357572443958,
      "grad_norm": 0.7557505965232849,
      "learning_rate": 8.925642427556043e-06,
      "loss": 0.014,
      "step": 40510
    },
    {
      "epoch": 11.077091306724986,
      "grad_norm": 0.0015919535653665662,
      "learning_rate": 8.922908693275014e-06,
      "loss": 0.0003,
      "step": 40520
    },
    {
      "epoch": 11.079825041006014,
      "grad_norm": 0.0013825275236740708,
      "learning_rate": 8.920174958993986e-06,
      "loss": 0.0132,
      "step": 40530
    },
    {
      "epoch": 11.082558775287042,
      "grad_norm": 0.0017799162305891514,
      "learning_rate": 8.917441224712958e-06,
      "loss": 0.0338,
      "step": 40540
    },
    {
      "epoch": 11.08529250956807,
      "grad_norm": 0.0009244619868695736,
      "learning_rate": 8.914707490431931e-06,
      "loss": 0.0,
      "step": 40550
    },
    {
      "epoch": 11.088026243849098,
      "grad_norm": 0.0014328759862110019,
      "learning_rate": 8.911973756150903e-06,
      "loss": 0.0377,
      "step": 40560
    },
    {
      "epoch": 11.090759978130126,
      "grad_norm": 0.0017237092833966017,
      "learning_rate": 8.909240021869874e-06,
      "loss": 0.0057,
      "step": 40570
    },
    {
      "epoch": 11.093493712411153,
      "grad_norm": 0.002886425470933318,
      "learning_rate": 8.906506287588848e-06,
      "loss": 0.0262,
      "step": 40580
    },
    {
      "epoch": 11.09622744669218,
      "grad_norm": 0.0013085767859593034,
      "learning_rate": 8.90377255330782e-06,
      "loss": 0.001,
      "step": 40590
    },
    {
      "epoch": 11.098961180973209,
      "grad_norm": 0.0014548090985044837,
      "learning_rate": 8.901038819026791e-06,
      "loss": 0.0254,
      "step": 40600
    },
    {
      "epoch": 11.101694915254237,
      "grad_norm": 0.001924707437865436,
      "learning_rate": 8.898305084745763e-06,
      "loss": 0.0001,
      "step": 40610
    },
    {
      "epoch": 11.104428649535265,
      "grad_norm": 1.1028971672058105,
      "learning_rate": 8.895571350464736e-06,
      "loss": 0.0547,
      "step": 40620
    },
    {
      "epoch": 11.107162383816293,
      "grad_norm": 0.03453313186764717,
      "learning_rate": 8.892837616183708e-06,
      "loss": 0.0024,
      "step": 40630
    },
    {
      "epoch": 11.109896118097321,
      "grad_norm": 13.992385864257812,
      "learning_rate": 8.89010388190268e-06,
      "loss": 0.0078,
      "step": 40640
    },
    {
      "epoch": 11.11262985237835,
      "grad_norm": 0.16819019615650177,
      "learning_rate": 8.887370147621653e-06,
      "loss": 0.0075,
      "step": 40650
    },
    {
      "epoch": 11.115363586659377,
      "grad_norm": 0.00222862814553082,
      "learning_rate": 8.884636413340624e-06,
      "loss": 0.0054,
      "step": 40660
    },
    {
      "epoch": 11.118097320940404,
      "grad_norm": 0.003762852167710662,
      "learning_rate": 8.881902679059596e-06,
      "loss": 0.035,
      "step": 40670
    },
    {
      "epoch": 11.120831055221432,
      "grad_norm": 0.008775942958891392,
      "learning_rate": 8.879168944778568e-06,
      "loss": 0.0002,
      "step": 40680
    },
    {
      "epoch": 11.12356478950246,
      "grad_norm": 0.010268505662679672,
      "learning_rate": 8.876435210497541e-06,
      "loss": 0.0019,
      "step": 40690
    },
    {
      "epoch": 11.126298523783488,
      "grad_norm": 0.005525397602468729,
      "learning_rate": 8.873701476216513e-06,
      "loss": 0.0003,
      "step": 40700
    },
    {
      "epoch": 11.129032258064516,
      "grad_norm": 1.0405195951461792,
      "learning_rate": 8.870967741935484e-06,
      "loss": 0.0199,
      "step": 40710
    },
    {
      "epoch": 11.131765992345544,
      "grad_norm": 3.266589641571045,
      "learning_rate": 8.868234007654458e-06,
      "loss": 0.0098,
      "step": 40720
    },
    {
      "epoch": 11.134499726626572,
      "grad_norm": 0.002940952545031905,
      "learning_rate": 8.865500273373428e-06,
      "loss": 0.0064,
      "step": 40730
    },
    {
      "epoch": 11.1372334609076,
      "grad_norm": 0.010572617873549461,
      "learning_rate": 8.862766539092401e-06,
      "loss": 0.0076,
      "step": 40740
    },
    {
      "epoch": 11.139967195188628,
      "grad_norm": 1.5147480964660645,
      "learning_rate": 8.860032804811373e-06,
      "loss": 0.0145,
      "step": 40750
    },
    {
      "epoch": 11.142700929469656,
      "grad_norm": 3.4259707927703857,
      "learning_rate": 8.857299070530344e-06,
      "loss": 0.0464,
      "step": 40760
    },
    {
      "epoch": 11.145434663750683,
      "grad_norm": 0.013205199502408504,
      "learning_rate": 8.854565336249318e-06,
      "loss": 0.0137,
      "step": 40770
    },
    {
      "epoch": 11.14816839803171,
      "grad_norm": 0.005467724986374378,
      "learning_rate": 8.85183160196829e-06,
      "loss": 0.0037,
      "step": 40780
    },
    {
      "epoch": 11.150902132312739,
      "grad_norm": 0.031444575637578964,
      "learning_rate": 8.849097867687261e-06,
      "loss": 0.0003,
      "step": 40790
    },
    {
      "epoch": 11.153635866593767,
      "grad_norm": 0.005532500799745321,
      "learning_rate": 8.846364133406233e-06,
      "loss": 0.0004,
      "step": 40800
    },
    {
      "epoch": 11.156369600874795,
      "grad_norm": 0.004339223261922598,
      "learning_rate": 8.843630399125206e-06,
      "loss": 0.0281,
      "step": 40810
    },
    {
      "epoch": 11.159103335155823,
      "grad_norm": 1.180822491645813,
      "learning_rate": 8.840896664844178e-06,
      "loss": 0.0042,
      "step": 40820
    },
    {
      "epoch": 11.161837069436851,
      "grad_norm": 0.0016422050539404154,
      "learning_rate": 8.83816293056315e-06,
      "loss": 0.0038,
      "step": 40830
    },
    {
      "epoch": 11.16457080371788,
      "grad_norm": 0.9513840079307556,
      "learning_rate": 8.835429196282123e-06,
      "loss": 0.0068,
      "step": 40840
    },
    {
      "epoch": 11.167304537998907,
      "grad_norm": 0.003925791941583157,
      "learning_rate": 8.832695462001094e-06,
      "loss": 0.0002,
      "step": 40850
    },
    {
      "epoch": 11.170038272279934,
      "grad_norm": 0.005113361403346062,
      "learning_rate": 8.829961727720066e-06,
      "loss": 0.0001,
      "step": 40860
    },
    {
      "epoch": 11.172772006560962,
      "grad_norm": 1.108870267868042,
      "learning_rate": 8.827227993439038e-06,
      "loss": 0.003,
      "step": 40870
    },
    {
      "epoch": 11.17550574084199,
      "grad_norm": 0.002423699712380767,
      "learning_rate": 8.824494259158011e-06,
      "loss": 0.0119,
      "step": 40880
    },
    {
      "epoch": 11.178239475123018,
      "grad_norm": 0.0032990046311169863,
      "learning_rate": 8.821760524876983e-06,
      "loss": 0.0003,
      "step": 40890
    },
    {
      "epoch": 11.180973209404046,
      "grad_norm": 0.0019778916612267494,
      "learning_rate": 8.819026790595954e-06,
      "loss": 0.005,
      "step": 40900
    },
    {
      "epoch": 11.183706943685074,
      "grad_norm": 0.0021893635857850313,
      "learning_rate": 8.816293056314928e-06,
      "loss": 0.0032,
      "step": 40910
    },
    {
      "epoch": 11.186440677966102,
      "grad_norm": 0.001915403874590993,
      "learning_rate": 8.8135593220339e-06,
      "loss": 0.0001,
      "step": 40920
    },
    {
      "epoch": 11.18917441224713,
      "grad_norm": 0.003392657730728388,
      "learning_rate": 8.810825587752871e-06,
      "loss": 0.0001,
      "step": 40930
    },
    {
      "epoch": 11.191908146528158,
      "grad_norm": 0.0026354412548244,
      "learning_rate": 8.808091853471843e-06,
      "loss": 0.0128,
      "step": 40940
    },
    {
      "epoch": 11.194641880809185,
      "grad_norm": 0.003070009872317314,
      "learning_rate": 8.805358119190816e-06,
      "loss": 0.0061,
      "step": 40950
    },
    {
      "epoch": 11.197375615090213,
      "grad_norm": 0.003448693547397852,
      "learning_rate": 8.802624384909788e-06,
      "loss": 0.0001,
      "step": 40960
    },
    {
      "epoch": 11.20010934937124,
      "grad_norm": 0.0025589836295694113,
      "learning_rate": 8.79989065062876e-06,
      "loss": 0.0028,
      "step": 40970
    },
    {
      "epoch": 11.202843083652269,
      "grad_norm": 0.0028931270353496075,
      "learning_rate": 8.797156916347733e-06,
      "loss": 0.0001,
      "step": 40980
    },
    {
      "epoch": 11.205576817933297,
      "grad_norm": 0.002203384879976511,
      "learning_rate": 8.794423182066704e-06,
      "loss": 0.0057,
      "step": 40990
    },
    {
      "epoch": 11.208310552214325,
      "grad_norm": 1.232079029083252,
      "learning_rate": 8.791689447785676e-06,
      "loss": 0.0082,
      "step": 41000
    },
    {
      "epoch": 11.211044286495353,
      "grad_norm": 0.0012366485316306353,
      "learning_rate": 8.788955713504648e-06,
      "loss": 0.0035,
      "step": 41010
    },
    {
      "epoch": 11.213778020776381,
      "grad_norm": 0.0018141890177503228,
      "learning_rate": 8.786221979223621e-06,
      "loss": 0.0001,
      "step": 41020
    },
    {
      "epoch": 11.21651175505741,
      "grad_norm": 2.911893129348755,
      "learning_rate": 8.783488244942591e-06,
      "loss": 0.0604,
      "step": 41030
    },
    {
      "epoch": 11.219245489338435,
      "grad_norm": 0.0029436855111271143,
      "learning_rate": 8.780754510661564e-06,
      "loss": 0.0253,
      "step": 41040
    },
    {
      "epoch": 11.221979223619464,
      "grad_norm": 3.317169666290283,
      "learning_rate": 8.778020776380538e-06,
      "loss": 0.0082,
      "step": 41050
    },
    {
      "epoch": 11.224712957900492,
      "grad_norm": 0.0018729136791080236,
      "learning_rate": 8.775287042099508e-06,
      "loss": 0.0001,
      "step": 41060
    },
    {
      "epoch": 11.22744669218152,
      "grad_norm": 1.2388944625854492,
      "learning_rate": 8.772553307818481e-06,
      "loss": 0.0194,
      "step": 41070
    },
    {
      "epoch": 11.230180426462548,
      "grad_norm": 0.17832326889038086,
      "learning_rate": 8.769819573537453e-06,
      "loss": 0.0026,
      "step": 41080
    },
    {
      "epoch": 11.232914160743576,
      "grad_norm": 0.0026454543694853783,
      "learning_rate": 8.767085839256424e-06,
      "loss": 0.0001,
      "step": 41090
    },
    {
      "epoch": 11.235647895024604,
      "grad_norm": 0.004282907582819462,
      "learning_rate": 8.764352104975396e-06,
      "loss": 0.0291,
      "step": 41100
    },
    {
      "epoch": 11.238381629305632,
      "grad_norm": 0.0020175992976874113,
      "learning_rate": 8.76161837069437e-06,
      "loss": 0.0022,
      "step": 41110
    },
    {
      "epoch": 11.24111536358666,
      "grad_norm": 0.002531887497752905,
      "learning_rate": 8.758884636413341e-06,
      "loss": 0.0192,
      "step": 41120
    },
    {
      "epoch": 11.243849097867688,
      "grad_norm": 0.002864512614905834,
      "learning_rate": 8.756150902132313e-06,
      "loss": 0.0214,
      "step": 41130
    },
    {
      "epoch": 11.246582832148714,
      "grad_norm": 0.003611780470237136,
      "learning_rate": 8.753417167851286e-06,
      "loss": 0.0001,
      "step": 41140
    },
    {
      "epoch": 11.249316566429743,
      "grad_norm": 0.02568669803440571,
      "learning_rate": 8.750683433570258e-06,
      "loss": 0.0104,
      "step": 41150
    },
    {
      "epoch": 11.25205030071077,
      "grad_norm": 0.004390370100736618,
      "learning_rate": 8.74794969928923e-06,
      "loss": 0.0362,
      "step": 41160
    },
    {
      "epoch": 11.254784034991799,
      "grad_norm": 0.007563950028270483,
      "learning_rate": 8.745215965008203e-06,
      "loss": 0.0329,
      "step": 41170
    },
    {
      "epoch": 11.257517769272827,
      "grad_norm": 0.005982343107461929,
      "learning_rate": 8.742482230727174e-06,
      "loss": 0.0077,
      "step": 41180
    },
    {
      "epoch": 11.260251503553855,
      "grad_norm": 0.04799564927816391,
      "learning_rate": 8.739748496446146e-06,
      "loss": 0.0052,
      "step": 41190
    },
    {
      "epoch": 11.262985237834883,
      "grad_norm": 0.0043835388496518135,
      "learning_rate": 8.737014762165118e-06,
      "loss": 0.0077,
      "step": 41200
    },
    {
      "epoch": 11.265718972115911,
      "grad_norm": 0.009632362052798271,
      "learning_rate": 8.734281027884091e-06,
      "loss": 0.0176,
      "step": 41210
    },
    {
      "epoch": 11.268452706396939,
      "grad_norm": 0.004421351011842489,
      "learning_rate": 8.731547293603063e-06,
      "loss": 0.0078,
      "step": 41220
    },
    {
      "epoch": 11.271186440677965,
      "grad_norm": 0.002553844591602683,
      "learning_rate": 8.728813559322034e-06,
      "loss": 0.0246,
      "step": 41230
    },
    {
      "epoch": 11.273920174958993,
      "grad_norm": 0.006617570295929909,
      "learning_rate": 8.726079825041008e-06,
      "loss": 0.0011,
      "step": 41240
    },
    {
      "epoch": 11.276653909240022,
      "grad_norm": 0.008328359574079514,
      "learning_rate": 8.72334609075998e-06,
      "loss": 0.0001,
      "step": 41250
    },
    {
      "epoch": 11.27938764352105,
      "grad_norm": 0.5570663809776306,
      "learning_rate": 8.720612356478951e-06,
      "loss": 0.0251,
      "step": 41260
    },
    {
      "epoch": 11.282121377802078,
      "grad_norm": 0.0025544720701873302,
      "learning_rate": 8.717878622197923e-06,
      "loss": 0.0161,
      "step": 41270
    },
    {
      "epoch": 11.284855112083106,
      "grad_norm": 0.02831900492310524,
      "learning_rate": 8.715144887916896e-06,
      "loss": 0.0347,
      "step": 41280
    },
    {
      "epoch": 11.287588846364134,
      "grad_norm": 0.005130149889737368,
      "learning_rate": 8.712411153635868e-06,
      "loss": 0.0342,
      "step": 41290
    },
    {
      "epoch": 11.290322580645162,
      "grad_norm": 0.0014697593869641423,
      "learning_rate": 8.70967741935484e-06,
      "loss": 0.0047,
      "step": 41300
    },
    {
      "epoch": 11.29305631492619,
      "grad_norm": 0.46742191910743713,
      "learning_rate": 8.706943685073813e-06,
      "loss": 0.0372,
      "step": 41310
    },
    {
      "epoch": 11.295790049207216,
      "grad_norm": 0.003170378739014268,
      "learning_rate": 8.704209950792784e-06,
      "loss": 0.0057,
      "step": 41320
    },
    {
      "epoch": 11.298523783488244,
      "grad_norm": 2.0615615844726562,
      "learning_rate": 8.701476216511756e-06,
      "loss": 0.005,
      "step": 41330
    },
    {
      "epoch": 11.301257517769272,
      "grad_norm": 0.0074788047932088375,
      "learning_rate": 8.698742482230728e-06,
      "loss": 0.0004,
      "step": 41340
    },
    {
      "epoch": 11.3039912520503,
      "grad_norm": 0.005527007859200239,
      "learning_rate": 8.696008747949701e-06,
      "loss": 0.0029,
      "step": 41350
    },
    {
      "epoch": 11.306724986331329,
      "grad_norm": 0.0055076866410672665,
      "learning_rate": 8.69327501366867e-06,
      "loss": 0.0007,
      "step": 41360
    },
    {
      "epoch": 11.309458720612357,
      "grad_norm": 0.0013977948110550642,
      "learning_rate": 8.690541279387644e-06,
      "loss": 0.0036,
      "step": 41370
    },
    {
      "epoch": 11.312192454893385,
      "grad_norm": 0.0021484687458723783,
      "learning_rate": 8.687807545106618e-06,
      "loss": 0.0,
      "step": 41380
    },
    {
      "epoch": 11.314926189174413,
      "grad_norm": 1.11388099193573,
      "learning_rate": 8.685073810825587e-06,
      "loss": 0.0291,
      "step": 41390
    },
    {
      "epoch": 11.317659923455441,
      "grad_norm": 0.0010840428294613957,
      "learning_rate": 8.68234007654456e-06,
      "loss": 0.0006,
      "step": 41400
    },
    {
      "epoch": 11.320393657736467,
      "grad_norm": 0.002008427632972598,
      "learning_rate": 8.679606342263532e-06,
      "loss": 0.0339,
      "step": 41410
    },
    {
      "epoch": 11.323127392017495,
      "grad_norm": 0.004324020352214575,
      "learning_rate": 8.676872607982504e-06,
      "loss": 0.0217,
      "step": 41420
    },
    {
      "epoch": 11.325861126298523,
      "grad_norm": 0.02609317936003208,
      "learning_rate": 8.674138873701476e-06,
      "loss": 0.0117,
      "step": 41430
    },
    {
      "epoch": 11.328594860579551,
      "grad_norm": 0.0005716116284020245,
      "learning_rate": 8.67140513942045e-06,
      "loss": 0.0054,
      "step": 41440
    },
    {
      "epoch": 11.33132859486058,
      "grad_norm": 24.358186721801758,
      "learning_rate": 8.66867140513942e-06,
      "loss": 0.04,
      "step": 41450
    },
    {
      "epoch": 11.334062329141608,
      "grad_norm": 0.00488637387752533,
      "learning_rate": 8.665937670858392e-06,
      "loss": 0.0112,
      "step": 41460
    },
    {
      "epoch": 11.336796063422636,
      "grad_norm": 0.005944386590272188,
      "learning_rate": 8.663203936577366e-06,
      "loss": 0.0034,
      "step": 41470
    },
    {
      "epoch": 11.339529797703664,
      "grad_norm": 0.007561898324638605,
      "learning_rate": 8.660470202296337e-06,
      "loss": 0.0009,
      "step": 41480
    },
    {
      "epoch": 11.342263531984692,
      "grad_norm": 0.00307636265642941,
      "learning_rate": 8.657736468015309e-06,
      "loss": 0.0001,
      "step": 41490
    },
    {
      "epoch": 11.344997266265718,
      "grad_norm": 0.002734948880970478,
      "learning_rate": 8.65500273373428e-06,
      "loss": 0.0086,
      "step": 41500
    },
    {
      "epoch": 11.347731000546746,
      "grad_norm": 0.002422134857624769,
      "learning_rate": 8.652268999453254e-06,
      "loss": 0.0044,
      "step": 41510
    },
    {
      "epoch": 11.350464734827774,
      "grad_norm": 0.007046493701636791,
      "learning_rate": 8.649535265172226e-06,
      "loss": 0.0001,
      "step": 41520
    },
    {
      "epoch": 11.353198469108802,
      "grad_norm": 0.0005492845666594803,
      "learning_rate": 8.646801530891197e-06,
      "loss": 0.0035,
      "step": 41530
    },
    {
      "epoch": 11.35593220338983,
      "grad_norm": 0.004858137108385563,
      "learning_rate": 8.64406779661017e-06,
      "loss": 0.014,
      "step": 41540
    },
    {
      "epoch": 11.358665937670859,
      "grad_norm": 0.008006153628230095,
      "learning_rate": 8.641334062329142e-06,
      "loss": 0.0214,
      "step": 41550
    },
    {
      "epoch": 11.361399671951887,
      "grad_norm": 0.003074631793424487,
      "learning_rate": 8.638600328048114e-06,
      "loss": 0.0209,
      "step": 41560
    },
    {
      "epoch": 11.364133406232915,
      "grad_norm": 0.7053031325340271,
      "learning_rate": 8.635866593767086e-06,
      "loss": 0.0136,
      "step": 41570
    },
    {
      "epoch": 11.366867140513943,
      "grad_norm": 0.008124158717691898,
      "learning_rate": 8.633132859486059e-06,
      "loss": 0.0119,
      "step": 41580
    },
    {
      "epoch": 11.369600874794969,
      "grad_norm": 0.006189871579408646,
      "learning_rate": 8.63039912520503e-06,
      "loss": 0.0328,
      "step": 41590
    },
    {
      "epoch": 11.372334609075997,
      "grad_norm": 0.0037301448173820972,
      "learning_rate": 8.627665390924002e-06,
      "loss": 0.0121,
      "step": 41600
    },
    {
      "epoch": 11.375068343357025,
      "grad_norm": 0.0016139565268531442,
      "learning_rate": 8.624931656642976e-06,
      "loss": 0.0321,
      "step": 41610
    },
    {
      "epoch": 11.377802077638053,
      "grad_norm": 1.4493712186813354,
      "learning_rate": 8.622197922361947e-06,
      "loss": 0.0051,
      "step": 41620
    },
    {
      "epoch": 11.380535811919081,
      "grad_norm": 0.01644454337656498,
      "learning_rate": 8.619464188080919e-06,
      "loss": 0.004,
      "step": 41630
    },
    {
      "epoch": 11.38326954620011,
      "grad_norm": 0.02253190614283085,
      "learning_rate": 8.61673045379989e-06,
      "loss": 0.0061,
      "step": 41640
    },
    {
      "epoch": 11.386003280481138,
      "grad_norm": 0.0022944342344999313,
      "learning_rate": 8.613996719518864e-06,
      "loss": 0.0022,
      "step": 41650
    },
    {
      "epoch": 11.388737014762166,
      "grad_norm": 0.01124212983995676,
      "learning_rate": 8.611262985237836e-06,
      "loss": 0.0211,
      "step": 41660
    },
    {
      "epoch": 11.391470749043194,
      "grad_norm": 0.002275436883792281,
      "learning_rate": 8.608529250956807e-06,
      "loss": 0.026,
      "step": 41670
    },
    {
      "epoch": 11.39420448332422,
      "grad_norm": 0.006691623479127884,
      "learning_rate": 8.60579551667578e-06,
      "loss": 0.02,
      "step": 41680
    },
    {
      "epoch": 11.396938217605248,
      "grad_norm": 0.002346237190067768,
      "learning_rate": 8.60306178239475e-06,
      "loss": 0.0046,
      "step": 41690
    },
    {
      "epoch": 11.399671951886276,
      "grad_norm": 0.003640740644186735,
      "learning_rate": 8.600328048113724e-06,
      "loss": 0.0004,
      "step": 41700
    },
    {
      "epoch": 11.402405686167304,
      "grad_norm": 0.002215519780293107,
      "learning_rate": 8.597594313832697e-06,
      "loss": 0.0021,
      "step": 41710
    },
    {
      "epoch": 11.405139420448332,
      "grad_norm": 3.2823216915130615,
      "learning_rate": 8.594860579551667e-06,
      "loss": 0.0427,
      "step": 41720
    },
    {
      "epoch": 11.40787315472936,
      "grad_norm": 0.23712566494941711,
      "learning_rate": 8.59212684527064e-06,
      "loss": 0.0432,
      "step": 41730
    },
    {
      "epoch": 11.410606889010388,
      "grad_norm": 0.0068990737199783325,
      "learning_rate": 8.589393110989612e-06,
      "loss": 0.0178,
      "step": 41740
    },
    {
      "epoch": 11.413340623291417,
      "grad_norm": 0.003640867304056883,
      "learning_rate": 8.586659376708584e-06,
      "loss": 0.0065,
      "step": 41750
    },
    {
      "epoch": 11.416074357572445,
      "grad_norm": 0.02765955962240696,
      "learning_rate": 8.583925642427556e-06,
      "loss": 0.0003,
      "step": 41760
    },
    {
      "epoch": 11.418808091853473,
      "grad_norm": 3.4635937213897705,
      "learning_rate": 8.581191908146529e-06,
      "loss": 0.0242,
      "step": 41770
    },
    {
      "epoch": 11.421541826134499,
      "grad_norm": 0.008561352267861366,
      "learning_rate": 8.5784581738655e-06,
      "loss": 0.0031,
      "step": 41780
    },
    {
      "epoch": 11.424275560415527,
      "grad_norm": 1.5864284038543701,
      "learning_rate": 8.575724439584472e-06,
      "loss": 0.0123,
      "step": 41790
    },
    {
      "epoch": 11.427009294696555,
      "grad_norm": 0.011423569172620773,
      "learning_rate": 8.572990705303446e-06,
      "loss": 0.0151,
      "step": 41800
    },
    {
      "epoch": 11.429743028977583,
      "grad_norm": 0.009528214111924171,
      "learning_rate": 8.570256971022417e-06,
      "loss": 0.0021,
      "step": 41810
    },
    {
      "epoch": 11.432476763258611,
      "grad_norm": 0.0029002453666180372,
      "learning_rate": 8.567523236741389e-06,
      "loss": 0.0069,
      "step": 41820
    },
    {
      "epoch": 11.43521049753964,
      "grad_norm": 0.009399021975696087,
      "learning_rate": 8.56478950246036e-06,
      "loss": 0.0002,
      "step": 41830
    },
    {
      "epoch": 11.437944231820667,
      "grad_norm": 0.8438092470169067,
      "learning_rate": 8.562055768179334e-06,
      "loss": 0.0043,
      "step": 41840
    },
    {
      "epoch": 11.440677966101696,
      "grad_norm": 0.00401017302647233,
      "learning_rate": 8.559322033898306e-06,
      "loss": 0.0058,
      "step": 41850
    },
    {
      "epoch": 11.443411700382724,
      "grad_norm": 0.008521023206412792,
      "learning_rate": 8.556588299617277e-06,
      "loss": 0.0091,
      "step": 41860
    },
    {
      "epoch": 11.44614543466375,
      "grad_norm": 0.00469236122444272,
      "learning_rate": 8.55385456533625e-06,
      "loss": 0.0135,
      "step": 41870
    },
    {
      "epoch": 11.448879168944778,
      "grad_norm": 0.018131958320736885,
      "learning_rate": 8.551120831055222e-06,
      "loss": 0.0177,
      "step": 41880
    },
    {
      "epoch": 11.451612903225806,
      "grad_norm": 0.003410240402445197,
      "learning_rate": 8.548387096774194e-06,
      "loss": 0.0001,
      "step": 41890
    },
    {
      "epoch": 11.454346637506834,
      "grad_norm": 0.46819233894348145,
      "learning_rate": 8.545653362493166e-06,
      "loss": 0.0019,
      "step": 41900
    },
    {
      "epoch": 11.457080371787862,
      "grad_norm": 5.2920966148376465,
      "learning_rate": 8.542919628212139e-06,
      "loss": 0.0114,
      "step": 41910
    },
    {
      "epoch": 11.45981410606889,
      "grad_norm": 0.01581796072423458,
      "learning_rate": 8.54018589393111e-06,
      "loss": 0.0006,
      "step": 41920
    },
    {
      "epoch": 11.462547840349918,
      "grad_norm": 1.9544398784637451,
      "learning_rate": 8.537452159650082e-06,
      "loss": 0.0201,
      "step": 41930
    },
    {
      "epoch": 11.465281574630946,
      "grad_norm": 64.65504455566406,
      "learning_rate": 8.534718425369056e-06,
      "loss": 0.005,
      "step": 41940
    },
    {
      "epoch": 11.468015308911975,
      "grad_norm": 0.003822530619800091,
      "learning_rate": 8.531984691088027e-06,
      "loss": 0.0056,
      "step": 41950
    },
    {
      "epoch": 11.470749043193,
      "grad_norm": 0.0016955275787040591,
      "learning_rate": 8.529250956806999e-06,
      "loss": 0.0216,
      "step": 41960
    },
    {
      "epoch": 11.473482777474029,
      "grad_norm": 0.001919949660077691,
      "learning_rate": 8.52651722252597e-06,
      "loss": 0.0044,
      "step": 41970
    },
    {
      "epoch": 11.476216511755057,
      "grad_norm": 0.002247361931949854,
      "learning_rate": 8.523783488244944e-06,
      "loss": 0.0079,
      "step": 41980
    },
    {
      "epoch": 11.478950246036085,
      "grad_norm": 0.0470220111310482,
      "learning_rate": 8.521049753963916e-06,
      "loss": 0.0035,
      "step": 41990
    },
    {
      "epoch": 11.481683980317113,
      "grad_norm": 0.8108561038970947,
      "learning_rate": 8.518316019682887e-06,
      "loss": 0.002,
      "step": 42000
    },
    {
      "epoch": 11.484417714598141,
      "grad_norm": 0.008581670001149178,
      "learning_rate": 8.51558228540186e-06,
      "loss": 0.0003,
      "step": 42010
    },
    {
      "epoch": 11.48715144887917,
      "grad_norm": 0.0011114864610135555,
      "learning_rate": 8.51284855112083e-06,
      "loss": 0.0024,
      "step": 42020
    },
    {
      "epoch": 11.489885183160197,
      "grad_norm": 1.5304107666015625,
      "learning_rate": 8.510114816839804e-06,
      "loss": 0.0183,
      "step": 42030
    },
    {
      "epoch": 11.492618917441225,
      "grad_norm": 0.0011112360516563058,
      "learning_rate": 8.507381082558776e-06,
      "loss": 0.0001,
      "step": 42040
    },
    {
      "epoch": 11.495352651722254,
      "grad_norm": 0.20993050932884216,
      "learning_rate": 8.504647348277747e-06,
      "loss": 0.0454,
      "step": 42050
    },
    {
      "epoch": 11.49808638600328,
      "grad_norm": 0.00964009203016758,
      "learning_rate": 8.50191361399672e-06,
      "loss": 0.0017,
      "step": 42060
    },
    {
      "epoch": 11.500820120284308,
      "grad_norm": 0.01157569419592619,
      "learning_rate": 8.499179879715692e-06,
      "loss": 0.0045,
      "step": 42070
    },
    {
      "epoch": 11.503553854565336,
      "grad_norm": 0.002357507823035121,
      "learning_rate": 8.496446145434664e-06,
      "loss": 0.0225,
      "step": 42080
    },
    {
      "epoch": 11.506287588846364,
      "grad_norm": 2.2005326747894287,
      "learning_rate": 8.493712411153636e-06,
      "loss": 0.0346,
      "step": 42090
    },
    {
      "epoch": 11.509021323127392,
      "grad_norm": 0.003031079890206456,
      "learning_rate": 8.490978676872609e-06,
      "loss": 0.0094,
      "step": 42100
    },
    {
      "epoch": 11.51175505740842,
      "grad_norm": 0.0020664779003709555,
      "learning_rate": 8.48824494259158e-06,
      "loss": 0.0059,
      "step": 42110
    },
    {
      "epoch": 11.514488791689448,
      "grad_norm": 0.0019567408598959446,
      "learning_rate": 8.485511208310552e-06,
      "loss": 0.0034,
      "step": 42120
    },
    {
      "epoch": 11.517222525970476,
      "grad_norm": 0.0025660679675638676,
      "learning_rate": 8.482777474029526e-06,
      "loss": 0.02,
      "step": 42130
    },
    {
      "epoch": 11.519956260251504,
      "grad_norm": 0.007722682319581509,
      "learning_rate": 8.480043739748497e-06,
      "loss": 0.0034,
      "step": 42140
    },
    {
      "epoch": 11.52268999453253,
      "grad_norm": 0.001233914983458817,
      "learning_rate": 8.477310005467469e-06,
      "loss": 0.0072,
      "step": 42150
    },
    {
      "epoch": 11.525423728813559,
      "grad_norm": 0.0019817096181213856,
      "learning_rate": 8.47457627118644e-06,
      "loss": 0.0001,
      "step": 42160
    },
    {
      "epoch": 11.528157463094587,
      "grad_norm": 0.006226665806025267,
      "learning_rate": 8.471842536905414e-06,
      "loss": 0.0064,
      "step": 42170
    },
    {
      "epoch": 11.530891197375615,
      "grad_norm": 1.6496590375900269,
      "learning_rate": 8.469108802624386e-06,
      "loss": 0.005,
      "step": 42180
    },
    {
      "epoch": 11.533624931656643,
      "grad_norm": 0.002437099115923047,
      "learning_rate": 8.466375068343357e-06,
      "loss": 0.009,
      "step": 42190
    },
    {
      "epoch": 11.536358665937671,
      "grad_norm": 0.34592175483703613,
      "learning_rate": 8.46364133406233e-06,
      "loss": 0.0162,
      "step": 42200
    },
    {
      "epoch": 11.5390924002187,
      "grad_norm": 0.0014299837639555335,
      "learning_rate": 8.460907599781302e-06,
      "loss": 0.0016,
      "step": 42210
    },
    {
      "epoch": 11.541826134499727,
      "grad_norm": 0.0012481189332902431,
      "learning_rate": 8.458173865500274e-06,
      "loss": 0.0003,
      "step": 42220
    },
    {
      "epoch": 11.544559868780755,
      "grad_norm": 0.0024177483282983303,
      "learning_rate": 8.455440131219246e-06,
      "loss": 0.0318,
      "step": 42230
    },
    {
      "epoch": 11.547293603061782,
      "grad_norm": 0.09846619516611099,
      "learning_rate": 8.452706396938219e-06,
      "loss": 0.0002,
      "step": 42240
    },
    {
      "epoch": 11.55002733734281,
      "grad_norm": 0.006054523400962353,
      "learning_rate": 8.44997266265719e-06,
      "loss": 0.0003,
      "step": 42250
    },
    {
      "epoch": 11.552761071623838,
      "grad_norm": 0.08596894890069962,
      "learning_rate": 8.447238928376162e-06,
      "loss": 0.0163,
      "step": 42260
    },
    {
      "epoch": 11.555494805904866,
      "grad_norm": 0.0016836640425026417,
      "learning_rate": 8.444505194095136e-06,
      "loss": 0.0166,
      "step": 42270
    },
    {
      "epoch": 11.558228540185894,
      "grad_norm": 0.0922766700387001,
      "learning_rate": 8.441771459814107e-06,
      "loss": 0.0527,
      "step": 42280
    },
    {
      "epoch": 11.560962274466922,
      "grad_norm": 0.9200520515441895,
      "learning_rate": 8.439037725533079e-06,
      "loss": 0.0113,
      "step": 42290
    },
    {
      "epoch": 11.56369600874795,
      "grad_norm": 0.014017081819474697,
      "learning_rate": 8.43630399125205e-06,
      "loss": 0.0025,
      "step": 42300
    },
    {
      "epoch": 11.566429743028978,
      "grad_norm": 0.0038737787399441004,
      "learning_rate": 8.433570256971024e-06,
      "loss": 0.01,
      "step": 42310
    },
    {
      "epoch": 11.569163477310006,
      "grad_norm": 0.5646434426307678,
      "learning_rate": 8.430836522689996e-06,
      "loss": 0.0099,
      "step": 42320
    },
    {
      "epoch": 11.571897211591033,
      "grad_norm": 0.0007946714176796377,
      "learning_rate": 8.428102788408967e-06,
      "loss": 0.0002,
      "step": 42330
    },
    {
      "epoch": 11.57463094587206,
      "grad_norm": 0.0018330843886360526,
      "learning_rate": 8.42536905412794e-06,
      "loss": 0.0002,
      "step": 42340
    },
    {
      "epoch": 11.577364680153089,
      "grad_norm": 11.934076309204102,
      "learning_rate": 8.42263531984691e-06,
      "loss": 0.0037,
      "step": 42350
    },
    {
      "epoch": 11.580098414434117,
      "grad_norm": 0.05779372900724411,
      "learning_rate": 8.419901585565884e-06,
      "loss": 0.0074,
      "step": 42360
    },
    {
      "epoch": 11.582832148715145,
      "grad_norm": 0.025068501010537148,
      "learning_rate": 8.417167851284856e-06,
      "loss": 0.0003,
      "step": 42370
    },
    {
      "epoch": 11.585565882996173,
      "grad_norm": 0.0011601168662309647,
      "learning_rate": 8.414434117003827e-06,
      "loss": 0.0027,
      "step": 42380
    },
    {
      "epoch": 11.588299617277201,
      "grad_norm": 0.0009491645032539964,
      "learning_rate": 8.4117003827228e-06,
      "loss": 0.001,
      "step": 42390
    },
    {
      "epoch": 11.59103335155823,
      "grad_norm": 0.006819041911512613,
      "learning_rate": 8.408966648441772e-06,
      "loss": 0.0272,
      "step": 42400
    },
    {
      "epoch": 11.593767085839257,
      "grad_norm": 0.0026291455142199993,
      "learning_rate": 8.406232914160744e-06,
      "loss": 0.0049,
      "step": 42410
    },
    {
      "epoch": 11.596500820120283,
      "grad_norm": 0.3368093967437744,
      "learning_rate": 8.403499179879715e-06,
      "loss": 0.0018,
      "step": 42420
    },
    {
      "epoch": 11.599234554401312,
      "grad_norm": 2.306044578552246,
      "learning_rate": 8.400765445598689e-06,
      "loss": 0.0068,
      "step": 42430
    },
    {
      "epoch": 11.60196828868234,
      "grad_norm": 0.0039551579393446445,
      "learning_rate": 8.39803171131766e-06,
      "loss": 0.0241,
      "step": 42440
    },
    {
      "epoch": 11.604702022963368,
      "grad_norm": 2.1542205810546875,
      "learning_rate": 8.395297977036632e-06,
      "loss": 0.0269,
      "step": 42450
    },
    {
      "epoch": 11.607435757244396,
      "grad_norm": 0.7986127734184265,
      "learning_rate": 8.392564242755605e-06,
      "loss": 0.0017,
      "step": 42460
    },
    {
      "epoch": 11.610169491525424,
      "grad_norm": 0.2140025645494461,
      "learning_rate": 8.389830508474577e-06,
      "loss": 0.0183,
      "step": 42470
    },
    {
      "epoch": 11.612903225806452,
      "grad_norm": 0.004824478644877672,
      "learning_rate": 8.387096774193549e-06,
      "loss": 0.0011,
      "step": 42480
    },
    {
      "epoch": 11.61563696008748,
      "grad_norm": 7.156399726867676,
      "learning_rate": 8.38436303991252e-06,
      "loss": 0.0156,
      "step": 42490
    },
    {
      "epoch": 11.618370694368508,
      "grad_norm": 0.02337043732404709,
      "learning_rate": 8.381629305631494e-06,
      "loss": 0.0008,
      "step": 42500
    },
    {
      "epoch": 11.621104428649534,
      "grad_norm": 0.0038961174432188272,
      "learning_rate": 8.378895571350465e-06,
      "loss": 0.0102,
      "step": 42510
    },
    {
      "epoch": 11.623838162930562,
      "grad_norm": 0.009691963903605938,
      "learning_rate": 8.376161837069437e-06,
      "loss": 0.0038,
      "step": 42520
    },
    {
      "epoch": 11.62657189721159,
      "grad_norm": 0.029239671304821968,
      "learning_rate": 8.37342810278841e-06,
      "loss": 0.0015,
      "step": 42530
    },
    {
      "epoch": 11.629305631492619,
      "grad_norm": 0.003533829003572464,
      "learning_rate": 8.370694368507382e-06,
      "loss": 0.0036,
      "step": 42540
    },
    {
      "epoch": 11.632039365773647,
      "grad_norm": 0.0026165065355598927,
      "learning_rate": 8.367960634226354e-06,
      "loss": 0.0151,
      "step": 42550
    },
    {
      "epoch": 11.634773100054675,
      "grad_norm": 2.744325876235962,
      "learning_rate": 8.365226899945325e-06,
      "loss": 0.0091,
      "step": 42560
    },
    {
      "epoch": 11.637506834335703,
      "grad_norm": 0.0014525203732773662,
      "learning_rate": 8.362493165664299e-06,
      "loss": 0.0119,
      "step": 42570
    },
    {
      "epoch": 11.640240568616731,
      "grad_norm": 0.001050001010298729,
      "learning_rate": 8.35975943138327e-06,
      "loss": 0.0025,
      "step": 42580
    },
    {
      "epoch": 11.642974302897759,
      "grad_norm": 0.09251020848751068,
      "learning_rate": 8.357025697102242e-06,
      "loss": 0.0023,
      "step": 42590
    },
    {
      "epoch": 11.645708037178785,
      "grad_norm": 0.0007738826679997146,
      "learning_rate": 8.354291962821215e-06,
      "loss": 0.0071,
      "step": 42600
    },
    {
      "epoch": 11.648441771459813,
      "grad_norm": 0.0011623329482972622,
      "learning_rate": 8.351558228540187e-06,
      "loss": 0.0241,
      "step": 42610
    },
    {
      "epoch": 11.651175505740841,
      "grad_norm": 27.40900993347168,
      "learning_rate": 8.348824494259159e-06,
      "loss": 0.0143,
      "step": 42620
    },
    {
      "epoch": 11.65390924002187,
      "grad_norm": 0.001125143957324326,
      "learning_rate": 8.34609075997813e-06,
      "loss": 0.0195,
      "step": 42630
    },
    {
      "epoch": 11.656642974302898,
      "grad_norm": 0.0013799234293401241,
      "learning_rate": 8.343357025697104e-06,
      "loss": 0.0002,
      "step": 42640
    },
    {
      "epoch": 11.659376708583926,
      "grad_norm": 0.0012282476527616382,
      "learning_rate": 8.340623291416074e-06,
      "loss": 0.0082,
      "step": 42650
    },
    {
      "epoch": 11.662110442864954,
      "grad_norm": 0.006461172830313444,
      "learning_rate": 8.337889557135047e-06,
      "loss": 0.0271,
      "step": 42660
    },
    {
      "epoch": 11.664844177145982,
      "grad_norm": 0.8038308620452881,
      "learning_rate": 8.33515582285402e-06,
      "loss": 0.0115,
      "step": 42670
    },
    {
      "epoch": 11.66757791142701,
      "grad_norm": 1.361506700515747,
      "learning_rate": 8.33242208857299e-06,
      "loss": 0.0115,
      "step": 42680
    },
    {
      "epoch": 11.670311645708036,
      "grad_norm": 0.025096070021390915,
      "learning_rate": 8.329688354291964e-06,
      "loss": 0.0001,
      "step": 42690
    },
    {
      "epoch": 11.673045379989064,
      "grad_norm": 0.0008912435150705278,
      "learning_rate": 8.326954620010935e-06,
      "loss": 0.0076,
      "step": 42700
    },
    {
      "epoch": 11.675779114270092,
      "grad_norm": 0.07642203569412231,
      "learning_rate": 8.324220885729907e-06,
      "loss": 0.0146,
      "step": 42710
    },
    {
      "epoch": 11.67851284855112,
      "grad_norm": 0.0013374300906434655,
      "learning_rate": 8.321487151448879e-06,
      "loss": 0.0023,
      "step": 42720
    },
    {
      "epoch": 11.681246582832149,
      "grad_norm": 0.001293298788368702,
      "learning_rate": 8.318753417167852e-06,
      "loss": 0.0359,
      "step": 42730
    },
    {
      "epoch": 11.683980317113177,
      "grad_norm": 1.255330204963684,
      "learning_rate": 8.316019682886824e-06,
      "loss": 0.0049,
      "step": 42740
    },
    {
      "epoch": 11.686714051394205,
      "grad_norm": 0.003643602132797241,
      "learning_rate": 8.313285948605795e-06,
      "loss": 0.0032,
      "step": 42750
    },
    {
      "epoch": 11.689447785675233,
      "grad_norm": 0.0011591456132009625,
      "learning_rate": 8.310552214324769e-06,
      "loss": 0.0027,
      "step": 42760
    },
    {
      "epoch": 11.69218151995626,
      "grad_norm": 0.0013165749842301011,
      "learning_rate": 8.30781848004374e-06,
      "loss": 0.0075,
      "step": 42770
    },
    {
      "epoch": 11.694915254237289,
      "grad_norm": 0.001900422852486372,
      "learning_rate": 8.305084745762712e-06,
      "loss": 0.0037,
      "step": 42780
    },
    {
      "epoch": 11.697648988518315,
      "grad_norm": 0.000773176085203886,
      "learning_rate": 8.302351011481685e-06,
      "loss": 0.0058,
      "step": 42790
    },
    {
      "epoch": 11.700382722799343,
      "grad_norm": 0.0005861229728907347,
      "learning_rate": 8.299617277200657e-06,
      "loss": 0.002,
      "step": 42800
    },
    {
      "epoch": 11.703116457080371,
      "grad_norm": 0.028944477438926697,
      "learning_rate": 8.296883542919629e-06,
      "loss": 0.0072,
      "step": 42810
    },
    {
      "epoch": 11.7058501913614,
      "grad_norm": 0.0016719428822398186,
      "learning_rate": 8.2941498086386e-06,
      "loss": 0.0001,
      "step": 42820
    },
    {
      "epoch": 11.708583925642428,
      "grad_norm": 0.033861856907606125,
      "learning_rate": 8.291416074357574e-06,
      "loss": 0.002,
      "step": 42830
    },
    {
      "epoch": 11.711317659923456,
      "grad_norm": 0.001315620495006442,
      "learning_rate": 8.288682340076545e-06,
      "loss": 0.0287,
      "step": 42840
    },
    {
      "epoch": 11.714051394204484,
      "grad_norm": 2.030984878540039,
      "learning_rate": 8.285948605795517e-06,
      "loss": 0.0473,
      "step": 42850
    },
    {
      "epoch": 11.716785128485512,
      "grad_norm": 0.01820824109017849,
      "learning_rate": 8.28321487151449e-06,
      "loss": 0.002,
      "step": 42860
    },
    {
      "epoch": 11.71951886276654,
      "grad_norm": 0.0063925799913704395,
      "learning_rate": 8.280481137233462e-06,
      "loss": 0.0034,
      "step": 42870
    },
    {
      "epoch": 11.722252597047566,
      "grad_norm": 0.46225881576538086,
      "learning_rate": 8.277747402952434e-06,
      "loss": 0.0175,
      "step": 42880
    },
    {
      "epoch": 11.724986331328594,
      "grad_norm": 0.0013973539462313056,
      "learning_rate": 8.275013668671405e-06,
      "loss": 0.0164,
      "step": 42890
    },
    {
      "epoch": 11.727720065609622,
      "grad_norm": 0.8279635310173035,
      "learning_rate": 8.272279934390379e-06,
      "loss": 0.0043,
      "step": 42900
    },
    {
      "epoch": 11.73045379989065,
      "grad_norm": 0.006574223283678293,
      "learning_rate": 8.26954620010935e-06,
      "loss": 0.013,
      "step": 42910
    },
    {
      "epoch": 11.733187534171678,
      "grad_norm": 0.44340577721595764,
      "learning_rate": 8.266812465828322e-06,
      "loss": 0.0073,
      "step": 42920
    },
    {
      "epoch": 11.735921268452707,
      "grad_norm": 0.0029827505350112915,
      "learning_rate": 8.264078731547295e-06,
      "loss": 0.0011,
      "step": 42930
    },
    {
      "epoch": 11.738655002733735,
      "grad_norm": 0.6934317350387573,
      "learning_rate": 8.261344997266267e-06,
      "loss": 0.0021,
      "step": 42940
    },
    {
      "epoch": 11.741388737014763,
      "grad_norm": 1.538267970085144,
      "learning_rate": 8.258611262985239e-06,
      "loss": 0.0018,
      "step": 42950
    },
    {
      "epoch": 11.74412247129579,
      "grad_norm": 0.0018988634692505002,
      "learning_rate": 8.25587752870421e-06,
      "loss": 0.0,
      "step": 42960
    },
    {
      "epoch": 11.746856205576819,
      "grad_norm": 1.4550570249557495,
      "learning_rate": 8.253143794423184e-06,
      "loss": 0.0206,
      "step": 42970
    },
    {
      "epoch": 11.749589939857845,
      "grad_norm": 0.0006788805476389825,
      "learning_rate": 8.250410060142154e-06,
      "loss": 0.0005,
      "step": 42980
    },
    {
      "epoch": 11.752323674138873,
      "grad_norm": 0.0012359832180663943,
      "learning_rate": 8.247676325861127e-06,
      "loss": 0.0321,
      "step": 42990
    },
    {
      "epoch": 11.755057408419901,
      "grad_norm": 14.516895294189453,
      "learning_rate": 8.2449425915801e-06,
      "loss": 0.0491,
      "step": 43000
    },
    {
      "epoch": 11.75779114270093,
      "grad_norm": 0.0008638395229354501,
      "learning_rate": 8.24220885729907e-06,
      "loss": 0.0165,
      "step": 43010
    },
    {
      "epoch": 11.760524876981957,
      "grad_norm": 1.9284932613372803,
      "learning_rate": 8.239475123018044e-06,
      "loss": 0.033,
      "step": 43020
    },
    {
      "epoch": 11.763258611262986,
      "grad_norm": 0.008420241996645927,
      "learning_rate": 8.236741388737015e-06,
      "loss": 0.0023,
      "step": 43030
    },
    {
      "epoch": 11.765992345544014,
      "grad_norm": 0.02146940492093563,
      "learning_rate": 8.234007654455987e-06,
      "loss": 0.0099,
      "step": 43040
    },
    {
      "epoch": 11.768726079825042,
      "grad_norm": 0.04010126739740372,
      "learning_rate": 8.231273920174959e-06,
      "loss": 0.0036,
      "step": 43050
    },
    {
      "epoch": 11.77145981410607,
      "grad_norm": 13.189054489135742,
      "learning_rate": 8.228540185893932e-06,
      "loss": 0.0275,
      "step": 43060
    },
    {
      "epoch": 11.774193548387096,
      "grad_norm": 0.008313961327075958,
      "learning_rate": 8.225806451612904e-06,
      "loss": 0.0155,
      "step": 43070
    },
    {
      "epoch": 11.776927282668124,
      "grad_norm": 8.406989097595215,
      "learning_rate": 8.223072717331875e-06,
      "loss": 0.0043,
      "step": 43080
    },
    {
      "epoch": 11.779661016949152,
      "grad_norm": 0.0033648202661424875,
      "learning_rate": 8.220338983050849e-06,
      "loss": 0.0026,
      "step": 43090
    },
    {
      "epoch": 11.78239475123018,
      "grad_norm": 0.003623905824497342,
      "learning_rate": 8.21760524876982e-06,
      "loss": 0.0154,
      "step": 43100
    },
    {
      "epoch": 11.785128485511208,
      "grad_norm": 0.01024491898715496,
      "learning_rate": 8.214871514488792e-06,
      "loss": 0.013,
      "step": 43110
    },
    {
      "epoch": 11.787862219792236,
      "grad_norm": 0.0015373009955510497,
      "learning_rate": 8.212137780207764e-06,
      "loss": 0.003,
      "step": 43120
    },
    {
      "epoch": 11.790595954073265,
      "grad_norm": 0.0014665245544165373,
      "learning_rate": 8.209404045926737e-06,
      "loss": 0.0002,
      "step": 43130
    },
    {
      "epoch": 11.793329688354293,
      "grad_norm": 0.00074060691986233,
      "learning_rate": 8.206670311645709e-06,
      "loss": 0.0048,
      "step": 43140
    },
    {
      "epoch": 11.79606342263532,
      "grad_norm": 0.00045985207543708384,
      "learning_rate": 8.20393657736468e-06,
      "loss": 0.0164,
      "step": 43150
    },
    {
      "epoch": 11.798797156916347,
      "grad_norm": 0.002598824445158243,
      "learning_rate": 8.201202843083654e-06,
      "loss": 0.0003,
      "step": 43160
    },
    {
      "epoch": 11.801530891197375,
      "grad_norm": 0.0020735354628413916,
      "learning_rate": 8.198469108802625e-06,
      "loss": 0.0112,
      "step": 43170
    },
    {
      "epoch": 11.804264625478403,
      "grad_norm": 0.0009707359131425619,
      "learning_rate": 8.195735374521597e-06,
      "loss": 0.017,
      "step": 43180
    },
    {
      "epoch": 11.806998359759431,
      "grad_norm": 0.001436924678273499,
      "learning_rate": 8.193001640240569e-06,
      "loss": 0.0109,
      "step": 43190
    },
    {
      "epoch": 11.80973209404046,
      "grad_norm": 2.2607083320617676,
      "learning_rate": 8.190267905959542e-06,
      "loss": 0.01,
      "step": 43200
    },
    {
      "epoch": 11.812465828321487,
      "grad_norm": 0.0009653226588852704,
      "learning_rate": 8.187534171678514e-06,
      "loss": 0.038,
      "step": 43210
    },
    {
      "epoch": 11.815199562602515,
      "grad_norm": 1.5993461608886719,
      "learning_rate": 8.184800437397485e-06,
      "loss": 0.0039,
      "step": 43220
    },
    {
      "epoch": 11.817933296883544,
      "grad_norm": 0.002349280519410968,
      "learning_rate": 8.182066703116459e-06,
      "loss": 0.0001,
      "step": 43230
    },
    {
      "epoch": 11.820667031164572,
      "grad_norm": 0.23590520024299622,
      "learning_rate": 8.17933296883543e-06,
      "loss": 0.0114,
      "step": 43240
    },
    {
      "epoch": 11.823400765445598,
      "grad_norm": 0.0036961447913199663,
      "learning_rate": 8.176599234554402e-06,
      "loss": 0.0032,
      "step": 43250
    },
    {
      "epoch": 11.826134499726626,
      "grad_norm": 0.0015449641505256295,
      "learning_rate": 8.173865500273374e-06,
      "loss": 0.0089,
      "step": 43260
    },
    {
      "epoch": 11.828868234007654,
      "grad_norm": 0.3716462254524231,
      "learning_rate": 8.171131765992347e-06,
      "loss": 0.0071,
      "step": 43270
    },
    {
      "epoch": 11.831601968288682,
      "grad_norm": 0.0011552131036296487,
      "learning_rate": 8.168398031711319e-06,
      "loss": 0.0079,
      "step": 43280
    },
    {
      "epoch": 11.83433570256971,
      "grad_norm": 0.000589416129514575,
      "learning_rate": 8.16566429743029e-06,
      "loss": 0.0041,
      "step": 43290
    },
    {
      "epoch": 11.837069436850738,
      "grad_norm": 0.04449339583516121,
      "learning_rate": 8.162930563149264e-06,
      "loss": 0.0458,
      "step": 43300
    },
    {
      "epoch": 11.839803171131766,
      "grad_norm": 0.006653165910393,
      "learning_rate": 8.160196828868234e-06,
      "loss": 0.0184,
      "step": 43310
    },
    {
      "epoch": 11.842536905412794,
      "grad_norm": 0.029115580022335052,
      "learning_rate": 8.157463094587207e-06,
      "loss": 0.0062,
      "step": 43320
    },
    {
      "epoch": 11.845270639693823,
      "grad_norm": 0.04236096143722534,
      "learning_rate": 8.15472936030618e-06,
      "loss": 0.0277,
      "step": 43330
    },
    {
      "epoch": 11.848004373974849,
      "grad_norm": 1.0886567831039429,
      "learning_rate": 8.15199562602515e-06,
      "loss": 0.0066,
      "step": 43340
    },
    {
      "epoch": 11.850738108255877,
      "grad_norm": 0.010426884517073631,
      "learning_rate": 8.149261891744124e-06,
      "loss": 0.0152,
      "step": 43350
    },
    {
      "epoch": 11.853471842536905,
      "grad_norm": 0.00662097567692399,
      "learning_rate": 8.146528157463095e-06,
      "loss": 0.0003,
      "step": 43360
    },
    {
      "epoch": 11.856205576817933,
      "grad_norm": 0.09709760546684265,
      "learning_rate": 8.143794423182067e-06,
      "loss": 0.0004,
      "step": 43370
    },
    {
      "epoch": 11.858939311098961,
      "grad_norm": 4.432482719421387,
      "learning_rate": 8.141060688901038e-06,
      "loss": 0.0194,
      "step": 43380
    },
    {
      "epoch": 11.86167304537999,
      "grad_norm": 0.010282148607075214,
      "learning_rate": 8.138326954620012e-06,
      "loss": 0.0068,
      "step": 43390
    },
    {
      "epoch": 11.864406779661017,
      "grad_norm": 0.004068915266543627,
      "learning_rate": 8.135593220338983e-06,
      "loss": 0.0001,
      "step": 43400
    },
    {
      "epoch": 11.867140513942045,
      "grad_norm": 0.0010827400255948305,
      "learning_rate": 8.132859486057955e-06,
      "loss": 0.0001,
      "step": 43410
    },
    {
      "epoch": 11.869874248223073,
      "grad_norm": 0.001583782723173499,
      "learning_rate": 8.130125751776928e-06,
      "loss": 0.0047,
      "step": 43420
    },
    {
      "epoch": 11.8726079825041,
      "grad_norm": 0.003161029191687703,
      "learning_rate": 8.1273920174959e-06,
      "loss": 0.0001,
      "step": 43430
    },
    {
      "epoch": 11.875341716785128,
      "grad_norm": 0.0007719755521975458,
      "learning_rate": 8.124658283214872e-06,
      "loss": 0.0001,
      "step": 43440
    },
    {
      "epoch": 11.878075451066156,
      "grad_norm": 1.0442508459091187,
      "learning_rate": 8.121924548933843e-06,
      "loss": 0.0113,
      "step": 43450
    },
    {
      "epoch": 11.880809185347184,
      "grad_norm": 0.0023947476875036955,
      "learning_rate": 8.119190814652817e-06,
      "loss": 0.0242,
      "step": 43460
    },
    {
      "epoch": 11.883542919628212,
      "grad_norm": 0.004466577898710966,
      "learning_rate": 8.116457080371788e-06,
      "loss": 0.0282,
      "step": 43470
    },
    {
      "epoch": 11.88627665390924,
      "grad_norm": 0.0008481976692564785,
      "learning_rate": 8.11372334609076e-06,
      "loss": 0.0047,
      "step": 43480
    },
    {
      "epoch": 11.889010388190268,
      "grad_norm": 0.002723226323723793,
      "learning_rate": 8.110989611809733e-06,
      "loss": 0.0456,
      "step": 43490
    },
    {
      "epoch": 11.891744122471296,
      "grad_norm": 0.9202954173088074,
      "learning_rate": 8.108255877528705e-06,
      "loss": 0.0049,
      "step": 43500
    },
    {
      "epoch": 11.894477856752324,
      "grad_norm": 0.05248395353555679,
      "learning_rate": 8.105522143247677e-06,
      "loss": 0.0012,
      "step": 43510
    },
    {
      "epoch": 11.89721159103335,
      "grad_norm": 15.932451248168945,
      "learning_rate": 8.102788408966648e-06,
      "loss": 0.0288,
      "step": 43520
    },
    {
      "epoch": 11.899945325314379,
      "grad_norm": 0.004923384636640549,
      "learning_rate": 8.100054674685622e-06,
      "loss": 0.0031,
      "step": 43530
    },
    {
      "epoch": 11.902679059595407,
      "grad_norm": 0.002472449792549014,
      "learning_rate": 8.097320940404593e-06,
      "loss": 0.0168,
      "step": 43540
    },
    {
      "epoch": 11.905412793876435,
      "grad_norm": 0.006948317866772413,
      "learning_rate": 8.094587206123565e-06,
      "loss": 0.0099,
      "step": 43550
    },
    {
      "epoch": 11.908146528157463,
      "grad_norm": 0.0009067856008186936,
      "learning_rate": 8.091853471842538e-06,
      "loss": 0.0069,
      "step": 43560
    },
    {
      "epoch": 11.910880262438491,
      "grad_norm": 0.0023151354398578405,
      "learning_rate": 8.08911973756151e-06,
      "loss": 0.0001,
      "step": 43570
    },
    {
      "epoch": 11.91361399671952,
      "grad_norm": 0.0019579282961785793,
      "learning_rate": 8.086386003280482e-06,
      "loss": 0.0187,
      "step": 43580
    },
    {
      "epoch": 11.916347731000547,
      "grad_norm": 0.0013754855608567595,
      "learning_rate": 8.083652268999453e-06,
      "loss": 0.0052,
      "step": 43590
    },
    {
      "epoch": 11.919081465281575,
      "grad_norm": 0.0004672126960940659,
      "learning_rate": 8.080918534718427e-06,
      "loss": 0.0039,
      "step": 43600
    },
    {
      "epoch": 11.921815199562602,
      "grad_norm": 0.5302703380584717,
      "learning_rate": 8.078184800437398e-06,
      "loss": 0.0028,
      "step": 43610
    },
    {
      "epoch": 11.92454893384363,
      "grad_norm": 0.0008626696071587503,
      "learning_rate": 8.07545106615637e-06,
      "loss": 0.0009,
      "step": 43620
    },
    {
      "epoch": 11.927282668124658,
      "grad_norm": 0.004993196576833725,
      "learning_rate": 8.072717331875343e-06,
      "loss": 0.023,
      "step": 43630
    },
    {
      "epoch": 11.930016402405686,
      "grad_norm": 0.016069775447249413,
      "learning_rate": 8.069983597594313e-06,
      "loss": 0.0091,
      "step": 43640
    },
    {
      "epoch": 11.932750136686714,
      "grad_norm": 0.0015870148781687021,
      "learning_rate": 8.067249863313287e-06,
      "loss": 0.0044,
      "step": 43650
    },
    {
      "epoch": 11.935483870967742,
      "grad_norm": 2.476167917251587,
      "learning_rate": 8.064516129032258e-06,
      "loss": 0.0091,
      "step": 43660
    },
    {
      "epoch": 11.93821760524877,
      "grad_norm": 0.0016252427594736218,
      "learning_rate": 8.06178239475123e-06,
      "loss": 0.0012,
      "step": 43670
    },
    {
      "epoch": 11.940951339529798,
      "grad_norm": 0.12125537544488907,
      "learning_rate": 8.059048660470203e-06,
      "loss": 0.0196,
      "step": 43680
    },
    {
      "epoch": 11.943685073810826,
      "grad_norm": 0.004532345104962587,
      "learning_rate": 8.056314926189175e-06,
      "loss": 0.0008,
      "step": 43690
    },
    {
      "epoch": 11.946418808091854,
      "grad_norm": 0.00416968297213316,
      "learning_rate": 8.053581191908147e-06,
      "loss": 0.023,
      "step": 43700
    },
    {
      "epoch": 11.94915254237288,
      "grad_norm": 0.04193892329931259,
      "learning_rate": 8.050847457627118e-06,
      "loss": 0.0319,
      "step": 43710
    },
    {
      "epoch": 11.951886276653909,
      "grad_norm": 16.774755477905273,
      "learning_rate": 8.048113723346092e-06,
      "loss": 0.0265,
      "step": 43720
    },
    {
      "epoch": 11.954620010934937,
      "grad_norm": 0.0011381246149539948,
      "learning_rate": 8.045379989065063e-06,
      "loss": 0.0022,
      "step": 43730
    },
    {
      "epoch": 11.957353745215965,
      "grad_norm": 0.0011200614972040057,
      "learning_rate": 8.042646254784035e-06,
      "loss": 0.0016,
      "step": 43740
    },
    {
      "epoch": 11.960087479496993,
      "grad_norm": 0.005847567226737738,
      "learning_rate": 8.039912520503008e-06,
      "loss": 0.0077,
      "step": 43750
    },
    {
      "epoch": 11.962821213778021,
      "grad_norm": 0.001848143874667585,
      "learning_rate": 8.03717878622198e-06,
      "loss": 0.0155,
      "step": 43760
    },
    {
      "epoch": 11.965554948059049,
      "grad_norm": 0.0008386891568079591,
      "learning_rate": 8.034445051940952e-06,
      "loss": 0.0001,
      "step": 43770
    },
    {
      "epoch": 11.968288682340077,
      "grad_norm": 0.0012198213953524828,
      "learning_rate": 8.031711317659923e-06,
      "loss": 0.0001,
      "step": 43780
    },
    {
      "epoch": 11.971022416621105,
      "grad_norm": 0.001295858295634389,
      "learning_rate": 8.028977583378897e-06,
      "loss": 0.0169,
      "step": 43790
    },
    {
      "epoch": 11.973756150902132,
      "grad_norm": 0.002350646536797285,
      "learning_rate": 8.026243849097868e-06,
      "loss": 0.0161,
      "step": 43800
    },
    {
      "epoch": 11.97648988518316,
      "grad_norm": 14.020196914672852,
      "learning_rate": 8.02351011481684e-06,
      "loss": 0.0384,
      "step": 43810
    },
    {
      "epoch": 11.979223619464188,
      "grad_norm": 0.0017324943328276277,
      "learning_rate": 8.020776380535813e-06,
      "loss": 0.0087,
      "step": 43820
    },
    {
      "epoch": 11.981957353745216,
      "grad_norm": 0.0017781027127057314,
      "learning_rate": 8.018042646254785e-06,
      "loss": 0.0018,
      "step": 43830
    },
    {
      "epoch": 11.984691088026244,
      "grad_norm": 0.006422810722142458,
      "learning_rate": 8.015308911973757e-06,
      "loss": 0.0031,
      "step": 43840
    },
    {
      "epoch": 11.987424822307272,
      "grad_norm": 0.0006907707429490983,
      "learning_rate": 8.012575177692728e-06,
      "loss": 0.0001,
      "step": 43850
    },
    {
      "epoch": 11.9901585565883,
      "grad_norm": 0.0012296965578570962,
      "learning_rate": 8.009841443411702e-06,
      "loss": 0.004,
      "step": 43860
    },
    {
      "epoch": 11.992892290869328,
      "grad_norm": 0.0016409605741500854,
      "learning_rate": 8.007107709130673e-06,
      "loss": 0.008,
      "step": 43870
    },
    {
      "epoch": 11.995626025150356,
      "grad_norm": 0.0014943304704502225,
      "learning_rate": 8.004373974849645e-06,
      "loss": 0.001,
      "step": 43880
    },
    {
      "epoch": 11.998359759431382,
      "grad_norm": 1.6261433362960815,
      "learning_rate": 8.001640240568618e-06,
      "loss": 0.0185,
      "step": 43890
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.9918582375478927,
      "eval_f1": 0.9673704414587333,
      "eval_loss": 0.038891345262527466,
      "eval_precision": 0.9667519181585678,
      "eval_recall": 0.967989756722151,
      "eval_runtime": 813.4724,
      "eval_samples_per_second": 23.128,
      "eval_steps_per_second": 0.964,
      "step": 43896
    },
    {
      "epoch": 12.00109349371241,
      "grad_norm": 0.0014582666335627437,
      "learning_rate": 7.99890650628759e-06,
      "loss": 0.0092,
      "step": 43900
    },
    {
      "epoch": 12.003827227993439,
      "grad_norm": 1.997613787651062,
      "learning_rate": 7.996172772006562e-06,
      "loss": 0.0118,
      "step": 43910
    },
    {
      "epoch": 12.006560962274467,
      "grad_norm": 0.9794974327087402,
      "learning_rate": 7.993439037725533e-06,
      "loss": 0.0033,
      "step": 43920
    },
    {
      "epoch": 12.009294696555495,
      "grad_norm": 0.0010322064626961946,
      "learning_rate": 7.990705303444507e-06,
      "loss": 0.0054,
      "step": 43930
    },
    {
      "epoch": 12.012028430836523,
      "grad_norm": 0.0009536925354041159,
      "learning_rate": 7.987971569163478e-06,
      "loss": 0.0166,
      "step": 43940
    },
    {
      "epoch": 12.014762165117551,
      "grad_norm": 0.00031039660098031163,
      "learning_rate": 7.98523783488245e-06,
      "loss": 0.0,
      "step": 43950
    },
    {
      "epoch": 12.017495899398579,
      "grad_norm": 0.0010939735220745206,
      "learning_rate": 7.982504100601423e-06,
      "loss": 0.007,
      "step": 43960
    },
    {
      "epoch": 12.020229633679607,
      "grad_norm": 0.0004015812010038644,
      "learning_rate": 7.979770366320393e-06,
      "loss": 0.0043,
      "step": 43970
    },
    {
      "epoch": 12.022963367960633,
      "grad_norm": 0.0007154031191021204,
      "learning_rate": 7.977036632039367e-06,
      "loss": 0.0119,
      "step": 43980
    },
    {
      "epoch": 12.025697102241661,
      "grad_norm": 3.374011754989624,
      "learning_rate": 7.974302897758338e-06,
      "loss": 0.0086,
      "step": 43990
    },
    {
      "epoch": 12.02843083652269,
      "grad_norm": 0.29819825291633606,
      "learning_rate": 7.97156916347731e-06,
      "loss": 0.0121,
      "step": 44000
    },
    {
      "epoch": 12.031164570803718,
      "grad_norm": 0.21443061530590057,
      "learning_rate": 7.968835429196283e-06,
      "loss": 0.0021,
      "step": 44010
    },
    {
      "epoch": 12.033898305084746,
      "grad_norm": 0.007173476275056601,
      "learning_rate": 7.966101694915255e-06,
      "loss": 0.0004,
      "step": 44020
    },
    {
      "epoch": 12.036632039365774,
      "grad_norm": 0.0280471108853817,
      "learning_rate": 7.963367960634227e-06,
      "loss": 0.0018,
      "step": 44030
    },
    {
      "epoch": 12.039365773646802,
      "grad_norm": 0.00906195305287838,
      "learning_rate": 7.960634226353198e-06,
      "loss": 0.0102,
      "step": 44040
    },
    {
      "epoch": 12.04209950792783,
      "grad_norm": 0.0007748163188807666,
      "learning_rate": 7.957900492072172e-06,
      "loss": 0.0078,
      "step": 44050
    },
    {
      "epoch": 12.044833242208858,
      "grad_norm": 0.0016179943922907114,
      "learning_rate": 7.955166757791143e-06,
      "loss": 0.0002,
      "step": 44060
    },
    {
      "epoch": 12.047566976489886,
      "grad_norm": 0.03215799480676651,
      "learning_rate": 7.952433023510115e-06,
      "loss": 0.0091,
      "step": 44070
    },
    {
      "epoch": 12.050300710770912,
      "grad_norm": 0.12412162870168686,
      "learning_rate": 7.949699289229088e-06,
      "loss": 0.0333,
      "step": 44080
    },
    {
      "epoch": 12.05303444505194,
      "grad_norm": 0.0018624092917889357,
      "learning_rate": 7.94696555494806e-06,
      "loss": 0.0072,
      "step": 44090
    },
    {
      "epoch": 12.055768179332969,
      "grad_norm": 0.0012125622015446424,
      "learning_rate": 7.944231820667032e-06,
      "loss": 0.0075,
      "step": 44100
    },
    {
      "epoch": 12.058501913613997,
      "grad_norm": 4.975534439086914,
      "learning_rate": 7.941498086386003e-06,
      "loss": 0.0578,
      "step": 44110
    },
    {
      "epoch": 12.061235647895025,
      "grad_norm": 0.001847251201979816,
      "learning_rate": 7.938764352104977e-06,
      "loss": 0.0,
      "step": 44120
    },
    {
      "epoch": 12.063969382176053,
      "grad_norm": 9.17606258392334,
      "learning_rate": 7.936030617823948e-06,
      "loss": 0.0156,
      "step": 44130
    },
    {
      "epoch": 12.06670311645708,
      "grad_norm": 0.0008911577751860023,
      "learning_rate": 7.93329688354292e-06,
      "loss": 0.0003,
      "step": 44140
    },
    {
      "epoch": 12.069436850738109,
      "grad_norm": 0.0018547330982983112,
      "learning_rate": 7.930563149261893e-06,
      "loss": 0.0025,
      "step": 44150
    },
    {
      "epoch": 12.072170585019137,
      "grad_norm": 0.009662291966378689,
      "learning_rate": 7.927829414980865e-06,
      "loss": 0.0023,
      "step": 44160
    },
    {
      "epoch": 12.074904319300163,
      "grad_norm": 0.0008838560897856951,
      "learning_rate": 7.925095680699837e-06,
      "loss": 0.0052,
      "step": 44170
    },
    {
      "epoch": 12.077638053581191,
      "grad_norm": 0.5235104560852051,
      "learning_rate": 7.922361946418808e-06,
      "loss": 0.044,
      "step": 44180
    },
    {
      "epoch": 12.08037178786222,
      "grad_norm": 0.003997757565230131,
      "learning_rate": 7.919628212137782e-06,
      "loss": 0.0074,
      "step": 44190
    },
    {
      "epoch": 12.083105522143248,
      "grad_norm": 0.06696531176567078,
      "learning_rate": 7.916894477856753e-06,
      "loss": 0.0045,
      "step": 44200
    },
    {
      "epoch": 12.085839256424276,
      "grad_norm": 0.9089212417602539,
      "learning_rate": 7.914160743575725e-06,
      "loss": 0.002,
      "step": 44210
    },
    {
      "epoch": 12.088572990705304,
      "grad_norm": 0.0020771839190274477,
      "learning_rate": 7.911427009294698e-06,
      "loss": 0.0024,
      "step": 44220
    },
    {
      "epoch": 12.091306724986332,
      "grad_norm": 0.866626501083374,
      "learning_rate": 7.90869327501367e-06,
      "loss": 0.0051,
      "step": 44230
    },
    {
      "epoch": 12.09404045926736,
      "grad_norm": 4.668503284454346,
      "learning_rate": 7.905959540732642e-06,
      "loss": 0.0305,
      "step": 44240
    },
    {
      "epoch": 12.096774193548388,
      "grad_norm": 0.0013941176002845168,
      "learning_rate": 7.903225806451613e-06,
      "loss": 0.0006,
      "step": 44250
    },
    {
      "epoch": 12.099507927829414,
      "grad_norm": 0.0020159080158919096,
      "learning_rate": 7.900492072170587e-06,
      "loss": 0.0015,
      "step": 44260
    },
    {
      "epoch": 12.102241662110442,
      "grad_norm": 0.0013442698400467634,
      "learning_rate": 7.897758337889557e-06,
      "loss": 0.0082,
      "step": 44270
    },
    {
      "epoch": 12.10497539639147,
      "grad_norm": 0.0018470734357833862,
      "learning_rate": 7.89502460360853e-06,
      "loss": 0.0417,
      "step": 44280
    },
    {
      "epoch": 12.107709130672498,
      "grad_norm": 0.02731376700103283,
      "learning_rate": 7.892290869327503e-06,
      "loss": 0.0017,
      "step": 44290
    },
    {
      "epoch": 12.110442864953527,
      "grad_norm": 0.001989962300285697,
      "learning_rate": 7.889557135046473e-06,
      "loss": 0.0128,
      "step": 44300
    },
    {
      "epoch": 12.113176599234555,
      "grad_norm": 0.001617640140466392,
      "learning_rate": 7.886823400765447e-06,
      "loss": 0.0022,
      "step": 44310
    },
    {
      "epoch": 12.115910333515583,
      "grad_norm": 0.002560148248448968,
      "learning_rate": 7.884089666484418e-06,
      "loss": 0.0349,
      "step": 44320
    },
    {
      "epoch": 12.11864406779661,
      "grad_norm": 5.283154487609863,
      "learning_rate": 7.88135593220339e-06,
      "loss": 0.0218,
      "step": 44330
    },
    {
      "epoch": 12.121377802077639,
      "grad_norm": 0.0016625776188448071,
      "learning_rate": 7.878622197922361e-06,
      "loss": 0.005,
      "step": 44340
    },
    {
      "epoch": 12.124111536358665,
      "grad_norm": 0.1871420294046402,
      "learning_rate": 7.875888463641335e-06,
      "loss": 0.0055,
      "step": 44350
    },
    {
      "epoch": 12.126845270639693,
      "grad_norm": 0.0012595707084983587,
      "learning_rate": 7.873154729360306e-06,
      "loss": 0.0002,
      "step": 44360
    },
    {
      "epoch": 12.129579004920721,
      "grad_norm": 0.005052679218351841,
      "learning_rate": 7.870420995079278e-06,
      "loss": 0.0073,
      "step": 44370
    },
    {
      "epoch": 12.13231273920175,
      "grad_norm": 0.0016633926425129175,
      "learning_rate": 7.867687260798251e-06,
      "loss": 0.0015,
      "step": 44380
    },
    {
      "epoch": 12.135046473482777,
      "grad_norm": 2.7910592555999756,
      "learning_rate": 7.864953526517223e-06,
      "loss": 0.0457,
      "step": 44390
    },
    {
      "epoch": 12.137780207763806,
      "grad_norm": 0.002318731974810362,
      "learning_rate": 7.862219792236195e-06,
      "loss": 0.0151,
      "step": 44400
    },
    {
      "epoch": 12.140513942044834,
      "grad_norm": 0.00991202611476183,
      "learning_rate": 7.859486057955168e-06,
      "loss": 0.0042,
      "step": 44410
    },
    {
      "epoch": 12.143247676325862,
      "grad_norm": 0.0069639962166547775,
      "learning_rate": 7.85675232367414e-06,
      "loss": 0.0059,
      "step": 44420
    },
    {
      "epoch": 12.14598141060689,
      "grad_norm": 0.00399397499859333,
      "learning_rate": 7.854018589393111e-06,
      "loss": 0.0001,
      "step": 44430
    },
    {
      "epoch": 12.148715144887916,
      "grad_norm": 0.0033680512569844723,
      "learning_rate": 7.851284855112083e-06,
      "loss": 0.0037,
      "step": 44440
    },
    {
      "epoch": 12.151448879168944,
      "grad_norm": 0.00986996665596962,
      "learning_rate": 7.848551120831056e-06,
      "loss": 0.0458,
      "step": 44450
    },
    {
      "epoch": 12.154182613449972,
      "grad_norm": 0.002132159424945712,
      "learning_rate": 7.845817386550028e-06,
      "loss": 0.0073,
      "step": 44460
    },
    {
      "epoch": 12.156916347731,
      "grad_norm": 0.0028734549414366484,
      "learning_rate": 7.843083652269e-06,
      "loss": 0.0001,
      "step": 44470
    },
    {
      "epoch": 12.159650082012028,
      "grad_norm": 0.7321459650993347,
      "learning_rate": 7.840349917987973e-06,
      "loss": 0.0354,
      "step": 44480
    },
    {
      "epoch": 12.162383816293056,
      "grad_norm": 1.4869095087051392,
      "learning_rate": 7.837616183706945e-06,
      "loss": 0.0145,
      "step": 44490
    },
    {
      "epoch": 12.165117550574085,
      "grad_norm": 0.005374891217797995,
      "learning_rate": 7.834882449425916e-06,
      "loss": 0.0473,
      "step": 44500
    },
    {
      "epoch": 12.167851284855113,
      "grad_norm": 2.1083688735961914,
      "learning_rate": 7.832148715144888e-06,
      "loss": 0.0389,
      "step": 44510
    },
    {
      "epoch": 12.17058501913614,
      "grad_norm": 0.012383896857500076,
      "learning_rate": 7.829414980863861e-06,
      "loss": 0.0038,
      "step": 44520
    },
    {
      "epoch": 12.173318753417167,
      "grad_norm": 0.009930312633514404,
      "learning_rate": 7.826681246582833e-06,
      "loss": 0.0028,
      "step": 44530
    },
    {
      "epoch": 12.176052487698195,
      "grad_norm": 0.009825089946389198,
      "learning_rate": 7.823947512301805e-06,
      "loss": 0.0558,
      "step": 44540
    },
    {
      "epoch": 12.178786221979223,
      "grad_norm": 0.03382374718785286,
      "learning_rate": 7.821213778020778e-06,
      "loss": 0.0002,
      "step": 44550
    },
    {
      "epoch": 12.181519956260251,
      "grad_norm": 3.4388267993927,
      "learning_rate": 7.81848004373975e-06,
      "loss": 0.0595,
      "step": 44560
    },
    {
      "epoch": 12.18425369054128,
      "grad_norm": 0.02119307778775692,
      "learning_rate": 7.815746309458721e-06,
      "loss": 0.0042,
      "step": 44570
    },
    {
      "epoch": 12.186987424822307,
      "grad_norm": 0.027708599343895912,
      "learning_rate": 7.813012575177693e-06,
      "loss": 0.0058,
      "step": 44580
    },
    {
      "epoch": 12.189721159103335,
      "grad_norm": 0.014932588674128056,
      "learning_rate": 7.810278840896666e-06,
      "loss": 0.0077,
      "step": 44590
    },
    {
      "epoch": 12.192454893384364,
      "grad_norm": 0.008182444609701633,
      "learning_rate": 7.807545106615636e-06,
      "loss": 0.0059,
      "step": 44600
    },
    {
      "epoch": 12.195188627665392,
      "grad_norm": 0.01118486188352108,
      "learning_rate": 7.80481137233461e-06,
      "loss": 0.0011,
      "step": 44610
    },
    {
      "epoch": 12.19792236194642,
      "grad_norm": 0.005973894614726305,
      "learning_rate": 7.802077638053583e-06,
      "loss": 0.0093,
      "step": 44620
    },
    {
      "epoch": 12.200656096227446,
      "grad_norm": 0.012195475399494171,
      "learning_rate": 7.799343903772553e-06,
      "loss": 0.0053,
      "step": 44630
    },
    {
      "epoch": 12.203389830508474,
      "grad_norm": 0.005261832382529974,
      "learning_rate": 7.796610169491526e-06,
      "loss": 0.0008,
      "step": 44640
    },
    {
      "epoch": 12.206123564789502,
      "grad_norm": 0.03703974932432175,
      "learning_rate": 7.793876435210498e-06,
      "loss": 0.0005,
      "step": 44650
    },
    {
      "epoch": 12.20885729907053,
      "grad_norm": 0.006135171744972467,
      "learning_rate": 7.79114270092947e-06,
      "loss": 0.022,
      "step": 44660
    },
    {
      "epoch": 12.211591033351558,
      "grad_norm": 0.014661671593785286,
      "learning_rate": 7.788408966648441e-06,
      "loss": 0.0047,
      "step": 44670
    },
    {
      "epoch": 12.214324767632586,
      "grad_norm": 0.009534991346299648,
      "learning_rate": 7.785675232367415e-06,
      "loss": 0.0249,
      "step": 44680
    },
    {
      "epoch": 12.217058501913614,
      "grad_norm": 0.01404919195920229,
      "learning_rate": 7.782941498086386e-06,
      "loss": 0.029,
      "step": 44690
    },
    {
      "epoch": 12.219792236194642,
      "grad_norm": 0.00898370798677206,
      "learning_rate": 7.780207763805358e-06,
      "loss": 0.004,
      "step": 44700
    },
    {
      "epoch": 12.22252597047567,
      "grad_norm": 0.011434986256062984,
      "learning_rate": 7.777474029524331e-06,
      "loss": 0.0065,
      "step": 44710
    },
    {
      "epoch": 12.225259704756697,
      "grad_norm": 0.010941660962998867,
      "learning_rate": 7.774740295243303e-06,
      "loss": 0.0002,
      "step": 44720
    },
    {
      "epoch": 12.227993439037725,
      "grad_norm": 0.005992239806801081,
      "learning_rate": 7.772006560962275e-06,
      "loss": 0.0003,
      "step": 44730
    },
    {
      "epoch": 12.230727173318753,
      "grad_norm": 0.01021726056933403,
      "learning_rate": 7.769272826681246e-06,
      "loss": 0.0003,
      "step": 44740
    },
    {
      "epoch": 12.233460907599781,
      "grad_norm": 0.006260219030082226,
      "learning_rate": 7.76653909240022e-06,
      "loss": 0.0218,
      "step": 44750
    },
    {
      "epoch": 12.23619464188081,
      "grad_norm": 0.006443584803491831,
      "learning_rate": 7.763805358119191e-06,
      "loss": 0.0002,
      "step": 44760
    },
    {
      "epoch": 12.238928376161837,
      "grad_norm": 0.008737043477594852,
      "learning_rate": 7.761071623838163e-06,
      "loss": 0.0067,
      "step": 44770
    },
    {
      "epoch": 12.241662110442865,
      "grad_norm": 0.0031032515689730644,
      "learning_rate": 7.758337889557136e-06,
      "loss": 0.0036,
      "step": 44780
    },
    {
      "epoch": 12.244395844723893,
      "grad_norm": 0.0054024867713451385,
      "learning_rate": 7.755604155276108e-06,
      "loss": 0.0115,
      "step": 44790
    },
    {
      "epoch": 12.247129579004921,
      "grad_norm": 0.011672332882881165,
      "learning_rate": 7.75287042099508e-06,
      "loss": 0.0019,
      "step": 44800
    },
    {
      "epoch": 12.249863313285948,
      "grad_norm": 0.002841730136424303,
      "learning_rate": 7.750136686714051e-06,
      "loss": 0.0107,
      "step": 44810
    },
    {
      "epoch": 12.252597047566976,
      "grad_norm": 0.004294205456972122,
      "learning_rate": 7.747402952433025e-06,
      "loss": 0.0033,
      "step": 44820
    },
    {
      "epoch": 12.255330781848004,
      "grad_norm": 2.433844566345215,
      "learning_rate": 7.744669218151996e-06,
      "loss": 0.0147,
      "step": 44830
    },
    {
      "epoch": 12.258064516129032,
      "grad_norm": 0.00397424167022109,
      "learning_rate": 7.741935483870968e-06,
      "loss": 0.0119,
      "step": 44840
    },
    {
      "epoch": 12.26079825041006,
      "grad_norm": 0.00731325801461935,
      "learning_rate": 7.739201749589941e-06,
      "loss": 0.004,
      "step": 44850
    },
    {
      "epoch": 12.263531984691088,
      "grad_norm": 0.002350413706153631,
      "learning_rate": 7.736468015308913e-06,
      "loss": 0.0003,
      "step": 44860
    },
    {
      "epoch": 12.266265718972116,
      "grad_norm": 0.0021021366119384766,
      "learning_rate": 7.733734281027885e-06,
      "loss": 0.012,
      "step": 44870
    },
    {
      "epoch": 12.268999453253144,
      "grad_norm": 0.004388392902910709,
      "learning_rate": 7.731000546746856e-06,
      "loss": 0.0071,
      "step": 44880
    },
    {
      "epoch": 12.271733187534172,
      "grad_norm": 0.0012382965069264174,
      "learning_rate": 7.72826681246583e-06,
      "loss": 0.0007,
      "step": 44890
    },
    {
      "epoch": 12.274466921815199,
      "grad_norm": 0.002502521499991417,
      "learning_rate": 7.725533078184801e-06,
      "loss": 0.0055,
      "step": 44900
    },
    {
      "epoch": 12.277200656096227,
      "grad_norm": 0.0029315254651010036,
      "learning_rate": 7.722799343903773e-06,
      "loss": 0.0008,
      "step": 44910
    },
    {
      "epoch": 12.279934390377255,
      "grad_norm": 0.0018742905231192708,
      "learning_rate": 7.720065609622746e-06,
      "loss": 0.0001,
      "step": 44920
    },
    {
      "epoch": 12.282668124658283,
      "grad_norm": 0.0023372035939246416,
      "learning_rate": 7.717331875341716e-06,
      "loss": 0.0001,
      "step": 44930
    },
    {
      "epoch": 12.285401858939311,
      "grad_norm": 2.6034586429595947,
      "learning_rate": 7.71459814106069e-06,
      "loss": 0.0093,
      "step": 44940
    },
    {
      "epoch": 12.288135593220339,
      "grad_norm": 1.0978916883468628,
      "learning_rate": 7.711864406779663e-06,
      "loss": 0.0189,
      "step": 44950
    },
    {
      "epoch": 12.290869327501367,
      "grad_norm": 0.25098878145217896,
      "learning_rate": 7.709130672498633e-06,
      "loss": 0.0076,
      "step": 44960
    },
    {
      "epoch": 12.293603061782395,
      "grad_norm": 0.003347376361489296,
      "learning_rate": 7.706396938217606e-06,
      "loss": 0.0064,
      "step": 44970
    },
    {
      "epoch": 12.296336796063423,
      "grad_norm": 0.004347501788288355,
      "learning_rate": 7.703663203936578e-06,
      "loss": 0.0016,
      "step": 44980
    },
    {
      "epoch": 12.299070530344451,
      "grad_norm": 0.13462689518928528,
      "learning_rate": 7.70092946965555e-06,
      "loss": 0.0002,
      "step": 44990
    },
    {
      "epoch": 12.301804264625478,
      "grad_norm": 0.4222485423088074,
      "learning_rate": 7.698195735374521e-06,
      "loss": 0.0077,
      "step": 45000
    },
    {
      "epoch": 12.304537998906506,
      "grad_norm": 0.002147363033145666,
      "learning_rate": 7.695462001093495e-06,
      "loss": 0.0071,
      "step": 45010
    },
    {
      "epoch": 12.307271733187534,
      "grad_norm": 0.0025997860357165337,
      "learning_rate": 7.692728266812466e-06,
      "loss": 0.0244,
      "step": 45020
    },
    {
      "epoch": 12.310005467468562,
      "grad_norm": 0.0020960383117198944,
      "learning_rate": 7.689994532531438e-06,
      "loss": 0.006,
      "step": 45030
    },
    {
      "epoch": 12.31273920174959,
      "grad_norm": 0.03310474380850792,
      "learning_rate": 7.687260798250411e-06,
      "loss": 0.0067,
      "step": 45040
    },
    {
      "epoch": 12.315472936030618,
      "grad_norm": 0.0013194277416914701,
      "learning_rate": 7.684527063969383e-06,
      "loss": 0.0018,
      "step": 45050
    },
    {
      "epoch": 12.318206670311646,
      "grad_norm": 0.3015589118003845,
      "learning_rate": 7.681793329688355e-06,
      "loss": 0.0081,
      "step": 45060
    },
    {
      "epoch": 12.320940404592674,
      "grad_norm": 0.001219303347170353,
      "learning_rate": 7.679059595407326e-06,
      "loss": 0.0016,
      "step": 45070
    },
    {
      "epoch": 12.323674138873702,
      "grad_norm": 0.6849876642227173,
      "learning_rate": 7.6763258611263e-06,
      "loss": 0.0038,
      "step": 45080
    },
    {
      "epoch": 12.326407873154729,
      "grad_norm": 0.0014157234691083431,
      "learning_rate": 7.673592126845271e-06,
      "loss": 0.008,
      "step": 45090
    },
    {
      "epoch": 12.329141607435757,
      "grad_norm": 0.0018845496233552694,
      "learning_rate": 7.670858392564243e-06,
      "loss": 0.0275,
      "step": 45100
    },
    {
      "epoch": 12.331875341716785,
      "grad_norm": 0.000600088678766042,
      "learning_rate": 7.668124658283216e-06,
      "loss": 0.0,
      "step": 45110
    },
    {
      "epoch": 12.334609075997813,
      "grad_norm": 0.08323034644126892,
      "learning_rate": 7.665390924002188e-06,
      "loss": 0.0078,
      "step": 45120
    },
    {
      "epoch": 12.337342810278841,
      "grad_norm": 1.7738819122314453,
      "learning_rate": 7.66265718972116e-06,
      "loss": 0.008,
      "step": 45130
    },
    {
      "epoch": 12.340076544559869,
      "grad_norm": 0.001968486001715064,
      "learning_rate": 7.659923455440131e-06,
      "loss": 0.0017,
      "step": 45140
    },
    {
      "epoch": 12.342810278840897,
      "grad_norm": 0.004527823068201542,
      "learning_rate": 7.657189721159105e-06,
      "loss": 0.0012,
      "step": 45150
    },
    {
      "epoch": 12.345544013121925,
      "grad_norm": 0.0006548302480950952,
      "learning_rate": 7.654455986878076e-06,
      "loss": 0.0067,
      "step": 45160
    },
    {
      "epoch": 12.348277747402953,
      "grad_norm": 2.9202401638031006,
      "learning_rate": 7.651722252597048e-06,
      "loss": 0.0197,
      "step": 45170
    },
    {
      "epoch": 12.35101148168398,
      "grad_norm": 0.0012402209686115384,
      "learning_rate": 7.648988518316021e-06,
      "loss": 0.0072,
      "step": 45180
    },
    {
      "epoch": 12.353745215965008,
      "grad_norm": 0.004790578503161669,
      "learning_rate": 7.646254784034993e-06,
      "loss": 0.0002,
      "step": 45190
    },
    {
      "epoch": 12.356478950246036,
      "grad_norm": 0.00651888269931078,
      "learning_rate": 7.643521049753965e-06,
      "loss": 0.0504,
      "step": 45200
    },
    {
      "epoch": 12.359212684527064,
      "grad_norm": 1.1203173398971558,
      "learning_rate": 7.640787315472936e-06,
      "loss": 0.0247,
      "step": 45210
    },
    {
      "epoch": 12.361946418808092,
      "grad_norm": 0.0020083419512957335,
      "learning_rate": 7.63805358119191e-06,
      "loss": 0.011,
      "step": 45220
    },
    {
      "epoch": 12.36468015308912,
      "grad_norm": 0.004391173832118511,
      "learning_rate": 7.635319846910881e-06,
      "loss": 0.0136,
      "step": 45230
    },
    {
      "epoch": 12.367413887370148,
      "grad_norm": 0.0021852487698197365,
      "learning_rate": 7.632586112629853e-06,
      "loss": 0.0119,
      "step": 45240
    },
    {
      "epoch": 12.370147621651176,
      "grad_norm": 1.1450133323669434,
      "learning_rate": 7.629852378348826e-06,
      "loss": 0.003,
      "step": 45250
    },
    {
      "epoch": 12.372881355932204,
      "grad_norm": 0.0014612595550715923,
      "learning_rate": 7.627118644067797e-06,
      "loss": 0.0001,
      "step": 45260
    },
    {
      "epoch": 12.37561509021323,
      "grad_norm": 0.7653868794441223,
      "learning_rate": 7.6243849097867695e-06,
      "loss": 0.0053,
      "step": 45270
    },
    {
      "epoch": 12.378348824494259,
      "grad_norm": 5.401845455169678,
      "learning_rate": 7.621651175505741e-06,
      "loss": 0.0095,
      "step": 45280
    },
    {
      "epoch": 12.381082558775287,
      "grad_norm": 0.001883242279291153,
      "learning_rate": 7.618917441224714e-06,
      "loss": 0.0122,
      "step": 45290
    },
    {
      "epoch": 12.383816293056315,
      "grad_norm": 0.0021867912728339434,
      "learning_rate": 7.616183706943686e-06,
      "loss": 0.0005,
      "step": 45300
    },
    {
      "epoch": 12.386550027337343,
      "grad_norm": 0.0009210626012645662,
      "learning_rate": 7.613449972662658e-06,
      "loss": 0.0057,
      "step": 45310
    },
    {
      "epoch": 12.38928376161837,
      "grad_norm": 1.4941675662994385,
      "learning_rate": 7.61071623838163e-06,
      "loss": 0.0105,
      "step": 45320
    },
    {
      "epoch": 12.392017495899399,
      "grad_norm": 0.0021603130735456944,
      "learning_rate": 7.607982504100602e-06,
      "loss": 0.0042,
      "step": 45330
    },
    {
      "epoch": 12.394751230180427,
      "grad_norm": 0.0006091417162679136,
      "learning_rate": 7.6052487698195745e-06,
      "loss": 0.0073,
      "step": 45340
    },
    {
      "epoch": 12.397484964461455,
      "grad_norm": 1.1006966829299927,
      "learning_rate": 7.602515035538546e-06,
      "loss": 0.0476,
      "step": 45350
    },
    {
      "epoch": 12.400218698742481,
      "grad_norm": 0.005253364332020283,
      "learning_rate": 7.599781301257519e-06,
      "loss": 0.0001,
      "step": 45360
    },
    {
      "epoch": 12.40295243302351,
      "grad_norm": 0.017078822478652,
      "learning_rate": 7.597047566976491e-06,
      "loss": 0.0029,
      "step": 45370
    },
    {
      "epoch": 12.405686167304538,
      "grad_norm": 0.009516855701804161,
      "learning_rate": 7.594313832695463e-06,
      "loss": 0.0191,
      "step": 45380
    },
    {
      "epoch": 12.408419901585566,
      "grad_norm": 2.0135555267333984,
      "learning_rate": 7.591580098414435e-06,
      "loss": 0.005,
      "step": 45390
    },
    {
      "epoch": 12.411153635866594,
      "grad_norm": 0.052348554134368896,
      "learning_rate": 7.588846364133406e-06,
      "loss": 0.0023,
      "step": 45400
    },
    {
      "epoch": 12.413887370147622,
      "grad_norm": 0.0019813692197203636,
      "learning_rate": 7.5861126298523795e-06,
      "loss": 0.0014,
      "step": 45410
    },
    {
      "epoch": 12.41662110442865,
      "grad_norm": 1.6224136352539062,
      "learning_rate": 7.58337889557135e-06,
      "loss": 0.0101,
      "step": 45420
    },
    {
      "epoch": 12.419354838709678,
      "grad_norm": 0.0028469678945839405,
      "learning_rate": 7.580645161290323e-06,
      "loss": 0.0001,
      "step": 45430
    },
    {
      "epoch": 12.422088572990706,
      "grad_norm": 0.0013460539048537612,
      "learning_rate": 7.577911427009296e-06,
      "loss": 0.0092,
      "step": 45440
    },
    {
      "epoch": 12.424822307271732,
      "grad_norm": 0.002168480772525072,
      "learning_rate": 7.575177692728267e-06,
      "loss": 0.0096,
      "step": 45450
    },
    {
      "epoch": 12.42755604155276,
      "grad_norm": 0.001003276207484305,
      "learning_rate": 7.5724439584472395e-06,
      "loss": 0.0169,
      "step": 45460
    },
    {
      "epoch": 12.430289775833788,
      "grad_norm": 0.0015448250342160463,
      "learning_rate": 7.569710224166211e-06,
      "loss": 0.0062,
      "step": 45470
    },
    {
      "epoch": 12.433023510114817,
      "grad_norm": 0.001672391314059496,
      "learning_rate": 7.566976489885184e-06,
      "loss": 0.016,
      "step": 45480
    },
    {
      "epoch": 12.435757244395845,
      "grad_norm": 0.0019389541121199727,
      "learning_rate": 7.564242755604156e-06,
      "loss": 0.0042,
      "step": 45490
    },
    {
      "epoch": 12.438490978676873,
      "grad_norm": 0.02504834719002247,
      "learning_rate": 7.561509021323128e-06,
      "loss": 0.0002,
      "step": 45500
    },
    {
      "epoch": 12.4412247129579,
      "grad_norm": 0.007131625898182392,
      "learning_rate": 7.5587752870421e-06,
      "loss": 0.0001,
      "step": 45510
    },
    {
      "epoch": 12.443958447238929,
      "grad_norm": 0.007470156066119671,
      "learning_rate": 7.556041552761072e-06,
      "loss": 0.0031,
      "step": 45520
    },
    {
      "epoch": 12.446692181519957,
      "grad_norm": 0.00251045566983521,
      "learning_rate": 7.5533078184800444e-06,
      "loss": 0.0001,
      "step": 45530
    },
    {
      "epoch": 12.449425915800983,
      "grad_norm": 0.0005440369131974876,
      "learning_rate": 7.550574084199016e-06,
      "loss": 0.0046,
      "step": 45540
    },
    {
      "epoch": 12.452159650082011,
      "grad_norm": 4.155651569366455,
      "learning_rate": 7.547840349917989e-06,
      "loss": 0.0345,
      "step": 45550
    },
    {
      "epoch": 12.45489338436304,
      "grad_norm": 0.003944642376154661,
      "learning_rate": 7.545106615636961e-06,
      "loss": 0.0083,
      "step": 45560
    },
    {
      "epoch": 12.457627118644067,
      "grad_norm": 0.0023614296223968267,
      "learning_rate": 7.542372881355933e-06,
      "loss": 0.006,
      "step": 45570
    },
    {
      "epoch": 12.460360852925096,
      "grad_norm": 0.00334832607768476,
      "learning_rate": 7.539639147074905e-06,
      "loss": 0.0278,
      "step": 45580
    },
    {
      "epoch": 12.463094587206124,
      "grad_norm": 0.011771957390010357,
      "learning_rate": 7.536905412793877e-06,
      "loss": 0.0073,
      "step": 45590
    },
    {
      "epoch": 12.465828321487152,
      "grad_norm": 13.102059364318848,
      "learning_rate": 7.534171678512849e-06,
      "loss": 0.0111,
      "step": 45600
    },
    {
      "epoch": 12.46856205576818,
      "grad_norm": 0.003088486148044467,
      "learning_rate": 7.531437944231821e-06,
      "loss": 0.0212,
      "step": 45610
    },
    {
      "epoch": 12.471295790049208,
      "grad_norm": 0.007316645234823227,
      "learning_rate": 7.5287042099507936e-06,
      "loss": 0.0064,
      "step": 45620
    },
    {
      "epoch": 12.474029524330236,
      "grad_norm": 0.02111593633890152,
      "learning_rate": 7.525970475669766e-06,
      "loss": 0.0052,
      "step": 45630
    },
    {
      "epoch": 12.476763258611262,
      "grad_norm": 0.010481634177267551,
      "learning_rate": 7.523236741388738e-06,
      "loss": 0.0036,
      "step": 45640
    },
    {
      "epoch": 12.47949699289229,
      "grad_norm": 2.4924776554107666,
      "learning_rate": 7.52050300710771e-06,
      "loss": 0.0039,
      "step": 45650
    },
    {
      "epoch": 12.482230727173318,
      "grad_norm": 0.24050219357013702,
      "learning_rate": 7.517769272826682e-06,
      "loss": 0.0109,
      "step": 45660
    },
    {
      "epoch": 12.484964461454346,
      "grad_norm": 0.0055844830349087715,
      "learning_rate": 7.515035538545654e-06,
      "loss": 0.0364,
      "step": 45670
    },
    {
      "epoch": 12.487698195735375,
      "grad_norm": 0.003480330342426896,
      "learning_rate": 7.512301804264626e-06,
      "loss": 0.0289,
      "step": 45680
    },
    {
      "epoch": 12.490431930016403,
      "grad_norm": 0.04312675818800926,
      "learning_rate": 7.5095680699835985e-06,
      "loss": 0.0066,
      "step": 45690
    },
    {
      "epoch": 12.49316566429743,
      "grad_norm": 0.003915898036211729,
      "learning_rate": 7.506834335702571e-06,
      "loss": 0.0218,
      "step": 45700
    },
    {
      "epoch": 12.495899398578459,
      "grad_norm": 0.006250352133065462,
      "learning_rate": 7.504100601421543e-06,
      "loss": 0.0064,
      "step": 45710
    },
    {
      "epoch": 12.498633132859487,
      "grad_norm": 0.1480032056570053,
      "learning_rate": 7.501366867140515e-06,
      "loss": 0.0202,
      "step": 45720
    },
    {
      "epoch": 12.501366867140513,
      "grad_norm": 0.008606672286987305,
      "learning_rate": 7.498633132859486e-06,
      "loss": 0.0095,
      "step": 45730
    },
    {
      "epoch": 12.504100601421541,
      "grad_norm": 0.770596981048584,
      "learning_rate": 7.4958993985784585e-06,
      "loss": 0.0055,
      "step": 45740
    },
    {
      "epoch": 12.50683433570257,
      "grad_norm": 0.01253486517816782,
      "learning_rate": 7.49316566429743e-06,
      "loss": 0.0002,
      "step": 45750
    },
    {
      "epoch": 12.509568069983597,
      "grad_norm": 3.970973014831543,
      "learning_rate": 7.490431930016403e-06,
      "loss": 0.0318,
      "step": 45760
    },
    {
      "epoch": 12.512301804264625,
      "grad_norm": 0.0026935965288430452,
      "learning_rate": 7.487698195735375e-06,
      "loss": 0.0023,
      "step": 45770
    },
    {
      "epoch": 12.515035538545654,
      "grad_norm": 0.7163968682289124,
      "learning_rate": 7.484964461454347e-06,
      "loss": 0.0079,
      "step": 45780
    },
    {
      "epoch": 12.517769272826682,
      "grad_norm": 0.004530180245637894,
      "learning_rate": 7.482230727173319e-06,
      "loss": 0.0066,
      "step": 45790
    },
    {
      "epoch": 12.52050300710771,
      "grad_norm": 0.007392569910734892,
      "learning_rate": 7.479496992892291e-06,
      "loss": 0.0002,
      "step": 45800
    },
    {
      "epoch": 12.523236741388738,
      "grad_norm": 0.0010479153133928776,
      "learning_rate": 7.4767632586112635e-06,
      "loss": 0.0011,
      "step": 45810
    },
    {
      "epoch": 12.525970475669764,
      "grad_norm": 0.004354691132903099,
      "learning_rate": 7.474029524330235e-06,
      "loss": 0.0152,
      "step": 45820
    },
    {
      "epoch": 12.528704209950792,
      "grad_norm": 0.0013465293450281024,
      "learning_rate": 7.471295790049208e-06,
      "loss": 0.0023,
      "step": 45830
    },
    {
      "epoch": 12.53143794423182,
      "grad_norm": 0.8853456974029541,
      "learning_rate": 7.46856205576818e-06,
      "loss": 0.0033,
      "step": 45840
    },
    {
      "epoch": 12.534171678512848,
      "grad_norm": 1.2018234729766846,
      "learning_rate": 7.465828321487152e-06,
      "loss": 0.0079,
      "step": 45850
    },
    {
      "epoch": 12.536905412793876,
      "grad_norm": 0.24090999364852905,
      "learning_rate": 7.463094587206124e-06,
      "loss": 0.0231,
      "step": 45860
    },
    {
      "epoch": 12.539639147074904,
      "grad_norm": 0.00226693507283926,
      "learning_rate": 7.460360852925096e-06,
      "loss": 0.0001,
      "step": 45870
    },
    {
      "epoch": 12.542372881355933,
      "grad_norm": 24.326555252075195,
      "learning_rate": 7.4576271186440685e-06,
      "loss": 0.0084,
      "step": 45880
    },
    {
      "epoch": 12.54510661563696,
      "grad_norm": 0.0024568538647145033,
      "learning_rate": 7.45489338436304e-06,
      "loss": 0.0237,
      "step": 45890
    },
    {
      "epoch": 12.547840349917989,
      "grad_norm": 1.2588846683502197,
      "learning_rate": 7.452159650082013e-06,
      "loss": 0.0079,
      "step": 45900
    },
    {
      "epoch": 12.550574084199017,
      "grad_norm": 0.001301089534536004,
      "learning_rate": 7.449425915800985e-06,
      "loss": 0.0037,
      "step": 45910
    },
    {
      "epoch": 12.553307818480043,
      "grad_norm": 0.0020256813149899244,
      "learning_rate": 7.446692181519957e-06,
      "loss": 0.0087,
      "step": 45920
    },
    {
      "epoch": 12.556041552761071,
      "grad_norm": 0.006035405211150646,
      "learning_rate": 7.443958447238929e-06,
      "loss": 0.0025,
      "step": 45930
    },
    {
      "epoch": 12.5587752870421,
      "grad_norm": 0.0014284776989370584,
      "learning_rate": 7.441224712957901e-06,
      "loss": 0.0003,
      "step": 45940
    },
    {
      "epoch": 12.561509021323127,
      "grad_norm": 0.003249793779104948,
      "learning_rate": 7.4384909786768735e-06,
      "loss": 0.0025,
      "step": 45950
    },
    {
      "epoch": 12.564242755604155,
      "grad_norm": 16.815677642822266,
      "learning_rate": 7.435757244395845e-06,
      "loss": 0.043,
      "step": 45960
    },
    {
      "epoch": 12.566976489885183,
      "grad_norm": 0.00781888235360384,
      "learning_rate": 7.433023510114818e-06,
      "loss": 0.0001,
      "step": 45970
    },
    {
      "epoch": 12.569710224166212,
      "grad_norm": 0.0020244368351995945,
      "learning_rate": 7.43028977583379e-06,
      "loss": 0.0016,
      "step": 45980
    },
    {
      "epoch": 12.57244395844724,
      "grad_norm": 0.004606070462614298,
      "learning_rate": 7.427556041552762e-06,
      "loss": 0.0101,
      "step": 45990
    },
    {
      "epoch": 12.575177692728268,
      "grad_norm": 3.378056764602661,
      "learning_rate": 7.424822307271734e-06,
      "loss": 0.0057,
      "step": 46000
    },
    {
      "epoch": 12.577911427009294,
      "grad_norm": 0.001181127387098968,
      "learning_rate": 7.422088572990705e-06,
      "loss": 0.0001,
      "step": 46010
    },
    {
      "epoch": 12.580645161290322,
      "grad_norm": 0.0008968552574515343,
      "learning_rate": 7.4193548387096784e-06,
      "loss": 0.0003,
      "step": 46020
    },
    {
      "epoch": 12.58337889557135,
      "grad_norm": 0.001979828579351306,
      "learning_rate": 7.416621104428651e-06,
      "loss": 0.0149,
      "step": 46030
    },
    {
      "epoch": 12.586112629852378,
      "grad_norm": 0.03507497161626816,
      "learning_rate": 7.413887370147622e-06,
      "loss": 0.0103,
      "step": 46040
    },
    {
      "epoch": 12.588846364133406,
      "grad_norm": 0.003603782271966338,
      "learning_rate": 7.411153635866595e-06,
      "loss": 0.0053,
      "step": 46050
    },
    {
      "epoch": 12.591580098414434,
      "grad_norm": 0.0010330617660656571,
      "learning_rate": 7.408419901585566e-06,
      "loss": 0.0091,
      "step": 46060
    },
    {
      "epoch": 12.594313832695462,
      "grad_norm": 3.1943001747131348,
      "learning_rate": 7.405686167304538e-06,
      "loss": 0.0179,
      "step": 46070
    },
    {
      "epoch": 12.59704756697649,
      "grad_norm": 0.0019184497650712729,
      "learning_rate": 7.40295243302351e-06,
      "loss": 0.0046,
      "step": 46080
    },
    {
      "epoch": 12.599781301257519,
      "grad_norm": 5.2528910636901855,
      "learning_rate": 7.4002186987424826e-06,
      "loss": 0.0253,
      "step": 46090
    },
    {
      "epoch": 12.602515035538545,
      "grad_norm": 0.6725584268569946,
      "learning_rate": 7.397484964461455e-06,
      "loss": 0.0038,
      "step": 46100
    },
    {
      "epoch": 12.605248769819573,
      "grad_norm": 0.0006941271130926907,
      "learning_rate": 7.394751230180427e-06,
      "loss": 0.0295,
      "step": 46110
    },
    {
      "epoch": 12.607982504100601,
      "grad_norm": 0.0004201172268949449,
      "learning_rate": 7.392017495899399e-06,
      "loss": 0.0002,
      "step": 46120
    },
    {
      "epoch": 12.61071623838163,
      "grad_norm": 0.4895555377006531,
      "learning_rate": 7.389283761618371e-06,
      "loss": 0.0106,
      "step": 46130
    },
    {
      "epoch": 12.613449972662657,
      "grad_norm": 0.0016924544470384717,
      "learning_rate": 7.386550027337343e-06,
      "loss": 0.0106,
      "step": 46140
    },
    {
      "epoch": 12.616183706943685,
      "grad_norm": 0.00870540365576744,
      "learning_rate": 7.383816293056315e-06,
      "loss": 0.0031,
      "step": 46150
    },
    {
      "epoch": 12.618917441224713,
      "grad_norm": 1.3193646669387817,
      "learning_rate": 7.3810825587752875e-06,
      "loss": 0.0491,
      "step": 46160
    },
    {
      "epoch": 12.621651175505741,
      "grad_norm": 0.8194648623466492,
      "learning_rate": 7.37834882449426e-06,
      "loss": 0.0022,
      "step": 46170
    },
    {
      "epoch": 12.62438490978677,
      "grad_norm": 0.003021000884473324,
      "learning_rate": 7.375615090213232e-06,
      "loss": 0.0396,
      "step": 46180
    },
    {
      "epoch": 12.627118644067796,
      "grad_norm": 0.009742247872054577,
      "learning_rate": 7.372881355932204e-06,
      "loss": 0.0002,
      "step": 46190
    },
    {
      "epoch": 12.629852378348824,
      "grad_norm": 0.010334777645766735,
      "learning_rate": 7.370147621651176e-06,
      "loss": 0.011,
      "step": 46200
    },
    {
      "epoch": 12.632586112629852,
      "grad_norm": 0.006878383457660675,
      "learning_rate": 7.367413887370148e-06,
      "loss": 0.0018,
      "step": 46210
    },
    {
      "epoch": 12.63531984691088,
      "grad_norm": 0.1441320776939392,
      "learning_rate": 7.36468015308912e-06,
      "loss": 0.0091,
      "step": 46220
    },
    {
      "epoch": 12.638053581191908,
      "grad_norm": 0.002385465195402503,
      "learning_rate": 7.3619464188080925e-06,
      "loss": 0.0002,
      "step": 46230
    },
    {
      "epoch": 12.640787315472936,
      "grad_norm": 0.0031781045254319906,
      "learning_rate": 7.359212684527065e-06,
      "loss": 0.0052,
      "step": 46240
    },
    {
      "epoch": 12.643521049753964,
      "grad_norm": 0.001877460046671331,
      "learning_rate": 7.356478950246037e-06,
      "loss": 0.0005,
      "step": 46250
    },
    {
      "epoch": 12.646254784034992,
      "grad_norm": 0.0021181590855121613,
      "learning_rate": 7.353745215965009e-06,
      "loss": 0.0001,
      "step": 46260
    },
    {
      "epoch": 12.64898851831602,
      "grad_norm": 0.0013503704685717821,
      "learning_rate": 7.351011481683981e-06,
      "loss": 0.0077,
      "step": 46270
    },
    {
      "epoch": 12.651722252597047,
      "grad_norm": 0.0008328661206178367,
      "learning_rate": 7.348277747402953e-06,
      "loss": 0.0001,
      "step": 46280
    },
    {
      "epoch": 12.654455986878075,
      "grad_norm": 0.0010725833708420396,
      "learning_rate": 7.345544013121925e-06,
      "loss": 0.003,
      "step": 46290
    },
    {
      "epoch": 12.657189721159103,
      "grad_norm": 0.0020912555046379566,
      "learning_rate": 7.3428102788408975e-06,
      "loss": 0.0083,
      "step": 46300
    },
    {
      "epoch": 12.659923455440131,
      "grad_norm": 0.0030941434670239687,
      "learning_rate": 7.34007654455987e-06,
      "loss": 0.0061,
      "step": 46310
    },
    {
      "epoch": 12.662657189721159,
      "grad_norm": 0.0016311975196003914,
      "learning_rate": 7.337342810278842e-06,
      "loss": 0.0056,
      "step": 46320
    },
    {
      "epoch": 12.665390924002187,
      "grad_norm": 1.9982446432113647,
      "learning_rate": 7.334609075997814e-06,
      "loss": 0.0126,
      "step": 46330
    },
    {
      "epoch": 12.668124658283215,
      "grad_norm": 0.0007603450212627649,
      "learning_rate": 7.331875341716785e-06,
      "loss": 0.0085,
      "step": 46340
    },
    {
      "epoch": 12.670858392564243,
      "grad_norm": 0.033857256174087524,
      "learning_rate": 7.329141607435758e-06,
      "loss": 0.0001,
      "step": 46350
    },
    {
      "epoch": 12.673592126845271,
      "grad_norm": 2.636800765991211,
      "learning_rate": 7.326407873154729e-06,
      "loss": 0.0129,
      "step": 46360
    },
    {
      "epoch": 12.676325861126298,
      "grad_norm": 0.7475759983062744,
      "learning_rate": 7.323674138873702e-06,
      "loss": 0.012,
      "step": 46370
    },
    {
      "epoch": 12.679059595407326,
      "grad_norm": 0.003641564166173339,
      "learning_rate": 7.320940404592675e-06,
      "loss": 0.0025,
      "step": 46380
    },
    {
      "epoch": 12.681793329688354,
      "grad_norm": 0.0020025931298732758,
      "learning_rate": 7.318206670311646e-06,
      "loss": 0.0038,
      "step": 46390
    },
    {
      "epoch": 12.684527063969382,
      "grad_norm": 0.001464368891902268,
      "learning_rate": 7.315472936030618e-06,
      "loss": 0.0058,
      "step": 46400
    },
    {
      "epoch": 12.68726079825041,
      "grad_norm": 0.0008939706021919847,
      "learning_rate": 7.31273920174959e-06,
      "loss": 0.0055,
      "step": 46410
    },
    {
      "epoch": 12.689994532531438,
      "grad_norm": 1.138939380645752,
      "learning_rate": 7.3100054674685625e-06,
      "loss": 0.0075,
      "step": 46420
    },
    {
      "epoch": 12.692728266812466,
      "grad_norm": 0.0008290280238725245,
      "learning_rate": 7.307271733187534e-06,
      "loss": 0.0037,
      "step": 46430
    },
    {
      "epoch": 12.695462001093494,
      "grad_norm": 1.1213979721069336,
      "learning_rate": 7.304537998906507e-06,
      "loss": 0.0256,
      "step": 46440
    },
    {
      "epoch": 12.698195735374522,
      "grad_norm": 0.01737467758357525,
      "learning_rate": 7.301804264625479e-06,
      "loss": 0.0035,
      "step": 46450
    },
    {
      "epoch": 12.700929469655549,
      "grad_norm": 0.006575297098606825,
      "learning_rate": 7.299070530344451e-06,
      "loss": 0.0083,
      "step": 46460
    },
    {
      "epoch": 12.703663203936577,
      "grad_norm": 0.0009708828874863684,
      "learning_rate": 7.296336796063423e-06,
      "loss": 0.0034,
      "step": 46470
    },
    {
      "epoch": 12.706396938217605,
      "grad_norm": 0.6666951179504395,
      "learning_rate": 7.293603061782395e-06,
      "loss": 0.0043,
      "step": 46480
    },
    {
      "epoch": 12.709130672498633,
      "grad_norm": 0.0030381488613784313,
      "learning_rate": 7.2908693275013674e-06,
      "loss": 0.0032,
      "step": 46490
    },
    {
      "epoch": 12.711864406779661,
      "grad_norm": 0.007422889117151499,
      "learning_rate": 7.288135593220339e-06,
      "loss": 0.002,
      "step": 46500
    },
    {
      "epoch": 12.714598141060689,
      "grad_norm": 0.0013469679979607463,
      "learning_rate": 7.285401858939312e-06,
      "loss": 0.0059,
      "step": 46510
    },
    {
      "epoch": 12.717331875341717,
      "grad_norm": 0.0013318270212039351,
      "learning_rate": 7.282668124658284e-06,
      "loss": 0.0034,
      "step": 46520
    },
    {
      "epoch": 12.720065609622745,
      "grad_norm": 0.012603876180946827,
      "learning_rate": 7.279934390377256e-06,
      "loss": 0.0001,
      "step": 46530
    },
    {
      "epoch": 12.722799343903773,
      "grad_norm": 0.0010317453416064382,
      "learning_rate": 7.277200656096228e-06,
      "loss": 0.0025,
      "step": 46540
    },
    {
      "epoch": 12.7255330781848,
      "grad_norm": 0.0039836992509663105,
      "learning_rate": 7.2744669218152e-06,
      "loss": 0.0083,
      "step": 46550
    },
    {
      "epoch": 12.728266812465828,
      "grad_norm": 0.0008506575250066817,
      "learning_rate": 7.271733187534172e-06,
      "loss": 0.0102,
      "step": 46560
    },
    {
      "epoch": 12.731000546746856,
      "grad_norm": 1.7406944036483765,
      "learning_rate": 7.268999453253145e-06,
      "loss": 0.0086,
      "step": 46570
    },
    {
      "epoch": 12.733734281027884,
      "grad_norm": 0.0007446493837051094,
      "learning_rate": 7.2662657189721166e-06,
      "loss": 0.0,
      "step": 46580
    },
    {
      "epoch": 12.736468015308912,
      "grad_norm": 0.0008399145444855094,
      "learning_rate": 7.263531984691089e-06,
      "loss": 0.0125,
      "step": 46590
    },
    {
      "epoch": 12.73920174958994,
      "grad_norm": 0.0005043814890086651,
      "learning_rate": 7.260798250410061e-06,
      "loss": 0.0015,
      "step": 46600
    },
    {
      "epoch": 12.741935483870968,
      "grad_norm": 0.6963528990745544,
      "learning_rate": 7.258064516129033e-06,
      "loss": 0.0019,
      "step": 46610
    },
    {
      "epoch": 12.744669218151996,
      "grad_norm": 1.3847140073776245,
      "learning_rate": 7.255330781848005e-06,
      "loss": 0.0075,
      "step": 46620
    },
    {
      "epoch": 12.747402952433024,
      "grad_norm": 0.0007485453970730305,
      "learning_rate": 7.252597047566977e-06,
      "loss": 0.001,
      "step": 46630
    },
    {
      "epoch": 12.750136686714052,
      "grad_norm": 0.0005219008307904005,
      "learning_rate": 7.24986331328595e-06,
      "loss": 0.0049,
      "step": 46640
    },
    {
      "epoch": 12.752870420995079,
      "grad_norm": 0.0559956356883049,
      "learning_rate": 7.2471295790049216e-06,
      "loss": 0.0018,
      "step": 46650
    },
    {
      "epoch": 12.755604155276107,
      "grad_norm": 0.7143034338951111,
      "learning_rate": 7.244395844723894e-06,
      "loss": 0.0056,
      "step": 46660
    },
    {
      "epoch": 12.758337889557135,
      "grad_norm": 1.3467997312545776,
      "learning_rate": 7.241662110442865e-06,
      "loss": 0.0045,
      "step": 46670
    },
    {
      "epoch": 12.761071623838163,
      "grad_norm": 0.0010978662176057696,
      "learning_rate": 7.238928376161838e-06,
      "loss": 0.0053,
      "step": 46680
    },
    {
      "epoch": 12.76380535811919,
      "grad_norm": 0.05168551951646805,
      "learning_rate": 7.236194641880809e-06,
      "loss": 0.0031,
      "step": 46690
    },
    {
      "epoch": 12.766539092400219,
      "grad_norm": 0.015063800849020481,
      "learning_rate": 7.2334609075997815e-06,
      "loss": 0.011,
      "step": 46700
    },
    {
      "epoch": 12.769272826681247,
      "grad_norm": 0.008319196291267872,
      "learning_rate": 7.230727173318755e-06,
      "loss": 0.001,
      "step": 46710
    },
    {
      "epoch": 12.772006560962275,
      "grad_norm": 0.7574219703674316,
      "learning_rate": 7.227993439037726e-06,
      "loss": 0.0074,
      "step": 46720
    },
    {
      "epoch": 12.774740295243303,
      "grad_norm": 0.0017594312084838748,
      "learning_rate": 7.225259704756698e-06,
      "loss": 0.0001,
      "step": 46730
    },
    {
      "epoch": 12.77747402952433,
      "grad_norm": 0.000849877658765763,
      "learning_rate": 7.22252597047567e-06,
      "loss": 0.0013,
      "step": 46740
    },
    {
      "epoch": 12.780207763805358,
      "grad_norm": 0.0006803781143389642,
      "learning_rate": 7.219792236194642e-06,
      "loss": 0.0458,
      "step": 46750
    },
    {
      "epoch": 12.782941498086386,
      "grad_norm": 0.002180033130571246,
      "learning_rate": 7.217058501913614e-06,
      "loss": 0.0002,
      "step": 46760
    },
    {
      "epoch": 12.785675232367414,
      "grad_norm": 0.025123542174696922,
      "learning_rate": 7.2143247676325865e-06,
      "loss": 0.0421,
      "step": 46770
    },
    {
      "epoch": 12.788408966648442,
      "grad_norm": 0.002173704095184803,
      "learning_rate": 7.211591033351559e-06,
      "loss": 0.0057,
      "step": 46780
    },
    {
      "epoch": 12.79114270092947,
      "grad_norm": 0.6529865860939026,
      "learning_rate": 7.208857299070531e-06,
      "loss": 0.0019,
      "step": 46790
    },
    {
      "epoch": 12.793876435210498,
      "grad_norm": 0.000955183815676719,
      "learning_rate": 7.206123564789503e-06,
      "loss": 0.003,
      "step": 46800
    },
    {
      "epoch": 12.796610169491526,
      "grad_norm": 0.0011564188171178102,
      "learning_rate": 7.203389830508475e-06,
      "loss": 0.0014,
      "step": 46810
    },
    {
      "epoch": 12.799343903772554,
      "grad_norm": 0.8111178874969482,
      "learning_rate": 7.200656096227447e-06,
      "loss": 0.0189,
      "step": 46820
    },
    {
      "epoch": 12.802077638053582,
      "grad_norm": 0.00040628708666190505,
      "learning_rate": 7.197922361946419e-06,
      "loss": 0.004,
      "step": 46830
    },
    {
      "epoch": 12.804811372334608,
      "grad_norm": 0.002457698807120323,
      "learning_rate": 7.1951886276653915e-06,
      "loss": 0.0361,
      "step": 46840
    },
    {
      "epoch": 12.807545106615636,
      "grad_norm": 2.5875182151794434,
      "learning_rate": 7.192454893384364e-06,
      "loss": 0.0194,
      "step": 46850
    },
    {
      "epoch": 12.810278840896665,
      "grad_norm": 0.004165688995271921,
      "learning_rate": 7.189721159103336e-06,
      "loss": 0.0146,
      "step": 46860
    },
    {
      "epoch": 12.813012575177693,
      "grad_norm": 0.0005779418279416859,
      "learning_rate": 7.186987424822308e-06,
      "loss": 0.0064,
      "step": 46870
    },
    {
      "epoch": 12.81574630945872,
      "grad_norm": 0.005991644226014614,
      "learning_rate": 7.18425369054128e-06,
      "loss": 0.0073,
      "step": 46880
    },
    {
      "epoch": 12.818480043739749,
      "grad_norm": 0.0039040425326675177,
      "learning_rate": 7.181519956260252e-06,
      "loss": 0.0132,
      "step": 46890
    },
    {
      "epoch": 12.821213778020777,
      "grad_norm": 0.00504891574382782,
      "learning_rate": 7.178786221979224e-06,
      "loss": 0.004,
      "step": 46900
    },
    {
      "epoch": 12.823947512301805,
      "grad_norm": 0.0013621988473460078,
      "learning_rate": 7.1760524876981965e-06,
      "loss": 0.0001,
      "step": 46910
    },
    {
      "epoch": 12.826681246582833,
      "grad_norm": 0.0023908757138997316,
      "learning_rate": 7.173318753417169e-06,
      "loss": 0.0094,
      "step": 46920
    },
    {
      "epoch": 12.82941498086386,
      "grad_norm": 0.0011461579706519842,
      "learning_rate": 7.170585019136141e-06,
      "loss": 0.0595,
      "step": 46930
    },
    {
      "epoch": 12.832148715144887,
      "grad_norm": 0.0026440361980348825,
      "learning_rate": 7.167851284855113e-06,
      "loss": 0.0038,
      "step": 46940
    },
    {
      "epoch": 12.834882449425915,
      "grad_norm": 1.1168135404586792,
      "learning_rate": 7.165117550574085e-06,
      "loss": 0.0068,
      "step": 46950
    },
    {
      "epoch": 12.837616183706944,
      "grad_norm": 0.002294593956321478,
      "learning_rate": 7.162383816293057e-06,
      "loss": 0.0063,
      "step": 46960
    },
    {
      "epoch": 12.840349917987972,
      "grad_norm": 0.008214329369366169,
      "learning_rate": 7.159650082012028e-06,
      "loss": 0.0055,
      "step": 46970
    },
    {
      "epoch": 12.843083652269,
      "grad_norm": 1.3888276815414429,
      "learning_rate": 7.1569163477310014e-06,
      "loss": 0.0077,
      "step": 46980
    },
    {
      "epoch": 12.845817386550028,
      "grad_norm": 0.0009173011058010161,
      "learning_rate": 7.154182613449974e-06,
      "loss": 0.0001,
      "step": 46990
    },
    {
      "epoch": 12.848551120831056,
      "grad_norm": 0.0010171140311285853,
      "learning_rate": 7.151448879168945e-06,
      "loss": 0.0003,
      "step": 47000
    },
    {
      "epoch": 12.851284855112084,
      "grad_norm": 0.004130074288696051,
      "learning_rate": 7.148715144887918e-06,
      "loss": 0.0043,
      "step": 47010
    },
    {
      "epoch": 12.85401858939311,
      "grad_norm": 0.007233935873955488,
      "learning_rate": 7.145981410606889e-06,
      "loss": 0.0119,
      "step": 47020
    },
    {
      "epoch": 12.856752323674138,
      "grad_norm": 0.002783701056614518,
      "learning_rate": 7.143247676325861e-06,
      "loss": 0.0092,
      "step": 47030
    },
    {
      "epoch": 12.859486057955166,
      "grad_norm": 0.002003795001655817,
      "learning_rate": 7.140513942044833e-06,
      "loss": 0.0242,
      "step": 47040
    },
    {
      "epoch": 12.862219792236194,
      "grad_norm": 0.0020762302447110415,
      "learning_rate": 7.1377802077638056e-06,
      "loss": 0.0031,
      "step": 47050
    },
    {
      "epoch": 12.864953526517223,
      "grad_norm": 0.002652282128110528,
      "learning_rate": 7.135046473482778e-06,
      "loss": 0.0049,
      "step": 47060
    },
    {
      "epoch": 12.86768726079825,
      "grad_norm": 0.0014460175298154354,
      "learning_rate": 7.13231273920175e-06,
      "loss": 0.0001,
      "step": 47070
    },
    {
      "epoch": 12.870420995079279,
      "grad_norm": 0.002225940814241767,
      "learning_rate": 7.129579004920722e-06,
      "loss": 0.0061,
      "step": 47080
    },
    {
      "epoch": 12.873154729360307,
      "grad_norm": 0.0017671792302280664,
      "learning_rate": 7.126845270639694e-06,
      "loss": 0.0014,
      "step": 47090
    },
    {
      "epoch": 12.875888463641335,
      "grad_norm": 0.0029086151625961065,
      "learning_rate": 7.124111536358666e-06,
      "loss": 0.0001,
      "step": 47100
    },
    {
      "epoch": 12.878622197922361,
      "grad_norm": 0.002510122489184141,
      "learning_rate": 7.121377802077639e-06,
      "loss": 0.0026,
      "step": 47110
    },
    {
      "epoch": 12.88135593220339,
      "grad_norm": 0.7877218723297119,
      "learning_rate": 7.1186440677966106e-06,
      "loss": 0.0111,
      "step": 47120
    },
    {
      "epoch": 12.884089666484417,
      "grad_norm": 0.0003925813070964068,
      "learning_rate": 7.115910333515583e-06,
      "loss": 0.0112,
      "step": 47130
    },
    {
      "epoch": 12.886823400765445,
      "grad_norm": 0.0012891277438029647,
      "learning_rate": 7.113176599234555e-06,
      "loss": 0.0027,
      "step": 47140
    },
    {
      "epoch": 12.889557135046473,
      "grad_norm": 0.0018515726551413536,
      "learning_rate": 7.110442864953527e-06,
      "loss": 0.0251,
      "step": 47150
    },
    {
      "epoch": 12.892290869327502,
      "grad_norm": 0.002316274680197239,
      "learning_rate": 7.107709130672499e-06,
      "loss": 0.0329,
      "step": 47160
    },
    {
      "epoch": 12.89502460360853,
      "grad_norm": 0.002555428072810173,
      "learning_rate": 7.104975396391471e-06,
      "loss": 0.0046,
      "step": 47170
    },
    {
      "epoch": 12.897758337889558,
      "grad_norm": 0.0015806359006091952,
      "learning_rate": 7.102241662110444e-06,
      "loss": 0.0109,
      "step": 47180
    },
    {
      "epoch": 12.900492072170586,
      "grad_norm": 0.9935543537139893,
      "learning_rate": 7.0995079278294155e-06,
      "loss": 0.0034,
      "step": 47190
    },
    {
      "epoch": 12.903225806451612,
      "grad_norm": 0.6122970581054688,
      "learning_rate": 7.096774193548388e-06,
      "loss": 0.0116,
      "step": 47200
    },
    {
      "epoch": 12.90595954073264,
      "grad_norm": 0.011002318933606148,
      "learning_rate": 7.09404045926736e-06,
      "loss": 0.0026,
      "step": 47210
    },
    {
      "epoch": 12.908693275013668,
      "grad_norm": 0.01317578461021185,
      "learning_rate": 7.091306724986332e-06,
      "loss": 0.0001,
      "step": 47220
    },
    {
      "epoch": 12.911427009294696,
      "grad_norm": 0.9380378723144531,
      "learning_rate": 7.088572990705304e-06,
      "loss": 0.0289,
      "step": 47230
    },
    {
      "epoch": 12.914160743575724,
      "grad_norm": 0.0025424384512007236,
      "learning_rate": 7.085839256424276e-06,
      "loss": 0.0108,
      "step": 47240
    },
    {
      "epoch": 12.916894477856752,
      "grad_norm": 0.0648527592420578,
      "learning_rate": 7.083105522143249e-06,
      "loss": 0.0023,
      "step": 47250
    },
    {
      "epoch": 12.91962821213778,
      "grad_norm": 0.018076740205287933,
      "learning_rate": 7.0803717878622205e-06,
      "loss": 0.0,
      "step": 47260
    },
    {
      "epoch": 12.922361946418809,
      "grad_norm": 0.0014835369074717164,
      "learning_rate": 7.077638053581193e-06,
      "loss": 0.0045,
      "step": 47270
    },
    {
      "epoch": 12.925095680699837,
      "grad_norm": 1.6301718950271606,
      "learning_rate": 7.074904319300165e-06,
      "loss": 0.0073,
      "step": 47280
    },
    {
      "epoch": 12.927829414980863,
      "grad_norm": 0.030796606093645096,
      "learning_rate": 7.072170585019137e-06,
      "loss": 0.0122,
      "step": 47290
    },
    {
      "epoch": 12.930563149261891,
      "grad_norm": 0.0645599365234375,
      "learning_rate": 7.069436850738108e-06,
      "loss": 0.0018,
      "step": 47300
    },
    {
      "epoch": 12.93329688354292,
      "grad_norm": 0.0034051844850182533,
      "learning_rate": 7.066703116457081e-06,
      "loss": 0.007,
      "step": 47310
    },
    {
      "epoch": 12.936030617823947,
      "grad_norm": 0.000824031129013747,
      "learning_rate": 7.063969382176054e-06,
      "loss": 0.0254,
      "step": 47320
    },
    {
      "epoch": 12.938764352104975,
      "grad_norm": 0.004397963173687458,
      "learning_rate": 7.061235647895025e-06,
      "loss": 0.0,
      "step": 47330
    },
    {
      "epoch": 12.941498086386003,
      "grad_norm": 0.0002775613684207201,
      "learning_rate": 7.058501913613998e-06,
      "loss": 0.0533,
      "step": 47340
    },
    {
      "epoch": 12.944231820667031,
      "grad_norm": 0.002254405990242958,
      "learning_rate": 7.055768179332969e-06,
      "loss": 0.0001,
      "step": 47350
    },
    {
      "epoch": 12.94696555494806,
      "grad_norm": 0.0006540034082718194,
      "learning_rate": 7.053034445051941e-06,
      "loss": 0.0002,
      "step": 47360
    },
    {
      "epoch": 12.949699289229088,
      "grad_norm": 0.00032899074722081423,
      "learning_rate": 7.050300710770913e-06,
      "loss": 0.0164,
      "step": 47370
    },
    {
      "epoch": 12.952433023510114,
      "grad_norm": 0.0016506639076396823,
      "learning_rate": 7.0475669764898855e-06,
      "loss": 0.0016,
      "step": 47380
    },
    {
      "epoch": 12.955166757791142,
      "grad_norm": 0.003073750762268901,
      "learning_rate": 7.044833242208858e-06,
      "loss": 0.0051,
      "step": 47390
    },
    {
      "epoch": 12.95790049207217,
      "grad_norm": 0.0052319602109491825,
      "learning_rate": 7.04209950792783e-06,
      "loss": 0.0015,
      "step": 47400
    },
    {
      "epoch": 12.960634226353198,
      "grad_norm": 1.1914182901382446,
      "learning_rate": 7.039365773646802e-06,
      "loss": 0.0131,
      "step": 47410
    },
    {
      "epoch": 12.963367960634226,
      "grad_norm": 0.008789836429059505,
      "learning_rate": 7.036632039365774e-06,
      "loss": 0.0001,
      "step": 47420
    },
    {
      "epoch": 12.966101694915254,
      "grad_norm": 0.48269495368003845,
      "learning_rate": 7.033898305084746e-06,
      "loss": 0.0041,
      "step": 47430
    },
    {
      "epoch": 12.968835429196282,
      "grad_norm": 0.0026061725802719593,
      "learning_rate": 7.031164570803718e-06,
      "loss": 0.0023,
      "step": 47440
    },
    {
      "epoch": 12.97156916347731,
      "grad_norm": 0.0005695532890968025,
      "learning_rate": 7.0284308365226904e-06,
      "loss": 0.0,
      "step": 47450
    },
    {
      "epoch": 12.974302897758339,
      "grad_norm": 0.0018302960088476539,
      "learning_rate": 7.025697102241663e-06,
      "loss": 0.0371,
      "step": 47460
    },
    {
      "epoch": 12.977036632039365,
      "grad_norm": 0.001722022076137364,
      "learning_rate": 7.022963367960635e-06,
      "loss": 0.009,
      "step": 47470
    },
    {
      "epoch": 12.979770366320393,
      "grad_norm": 0.02236931212246418,
      "learning_rate": 7.020229633679607e-06,
      "loss": 0.0232,
      "step": 47480
    },
    {
      "epoch": 12.982504100601421,
      "grad_norm": 0.004527564160525799,
      "learning_rate": 7.017495899398579e-06,
      "loss": 0.0018,
      "step": 47490
    },
    {
      "epoch": 12.985237834882449,
      "grad_norm": 0.004824106581509113,
      "learning_rate": 7.014762165117551e-06,
      "loss": 0.0051,
      "step": 47500
    },
    {
      "epoch": 12.987971569163477,
      "grad_norm": 0.0015498076099902391,
      "learning_rate": 7.012028430836523e-06,
      "loss": 0.0074,
      "step": 47510
    },
    {
      "epoch": 12.990705303444505,
      "grad_norm": 0.0034509743563830853,
      "learning_rate": 7.009294696555495e-06,
      "loss": 0.0081,
      "step": 47520
    },
    {
      "epoch": 12.993439037725533,
      "grad_norm": 0.001959775574505329,
      "learning_rate": 7.006560962274468e-06,
      "loss": 0.0069,
      "step": 47530
    },
    {
      "epoch": 12.996172772006561,
      "grad_norm": 0.0020930408500134945,
      "learning_rate": 7.00382722799344e-06,
      "loss": 0.0076,
      "step": 47540
    },
    {
      "epoch": 12.99890650628759,
      "grad_norm": 0.002709699794650078,
      "learning_rate": 7.001093493712412e-06,
      "loss": 0.0031,
      "step": 47550
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.9925500212856535,
      "eval_f1": 0.9701746910950149,
      "eval_loss": 0.03396385535597801,
      "eval_precision": 0.9685240323266695,
      "eval_recall": 0.971830985915493,
      "eval_runtime": 816.0299,
      "eval_samples_per_second": 23.056,
      "eval_steps_per_second": 0.961,
      "step": 47554
    },
    {
      "epoch": 13.001640240568618,
      "grad_norm": 0.0015019255224615335,
      "learning_rate": 6.998359759431384e-06,
      "loss": 0.0188,
      "step": 47560
    },
    {
      "epoch": 13.004373974849644,
      "grad_norm": 0.0014027009019628167,
      "learning_rate": 6.995626025150356e-06,
      "loss": 0.0007,
      "step": 47570
    },
    {
      "epoch": 13.007107709130672,
      "grad_norm": 0.0017032489413395524,
      "learning_rate": 6.992892290869328e-06,
      "loss": 0.0023,
      "step": 47580
    },
    {
      "epoch": 13.0098414434117,
      "grad_norm": 0.0008615536498837173,
      "learning_rate": 6.9901585565883e-06,
      "loss": 0.0016,
      "step": 47590
    },
    {
      "epoch": 13.012575177692728,
      "grad_norm": 0.001159821287728846,
      "learning_rate": 6.987424822307273e-06,
      "loss": 0.0013,
      "step": 47600
    },
    {
      "epoch": 13.015308911973756,
      "grad_norm": 0.0021748540457338095,
      "learning_rate": 6.9846910880262446e-06,
      "loss": 0.0036,
      "step": 47610
    },
    {
      "epoch": 13.018042646254784,
      "grad_norm": 0.0035506899002939463,
      "learning_rate": 6.981957353745217e-06,
      "loss": 0.0,
      "step": 47620
    },
    {
      "epoch": 13.020776380535812,
      "grad_norm": 0.000524476810824126,
      "learning_rate": 6.979223619464188e-06,
      "loss": 0.0,
      "step": 47630
    },
    {
      "epoch": 13.02351011481684,
      "grad_norm": 0.019168341532349586,
      "learning_rate": 6.976489885183161e-06,
      "loss": 0.0029,
      "step": 47640
    },
    {
      "epoch": 13.026243849097868,
      "grad_norm": 0.00046686214045621455,
      "learning_rate": 6.973756150902134e-06,
      "loss": 0.0,
      "step": 47650
    },
    {
      "epoch": 13.028977583378895,
      "grad_norm": 0.0035842990037053823,
      "learning_rate": 6.9710224166211045e-06,
      "loss": 0.0314,
      "step": 47660
    },
    {
      "epoch": 13.031711317659923,
      "grad_norm": 0.002936572302132845,
      "learning_rate": 6.968288682340078e-06,
      "loss": 0.0094,
      "step": 47670
    },
    {
      "epoch": 13.034445051940951,
      "grad_norm": 1.5882266759872437,
      "learning_rate": 6.965554948059049e-06,
      "loss": 0.0059,
      "step": 47680
    },
    {
      "epoch": 13.037178786221979,
      "grad_norm": 0.0031998518388718367,
      "learning_rate": 6.962821213778021e-06,
      "loss": 0.0082,
      "step": 47690
    },
    {
      "epoch": 13.039912520503007,
      "grad_norm": 0.001902436837553978,
      "learning_rate": 6.960087479496993e-06,
      "loss": 0.0034,
      "step": 47700
    },
    {
      "epoch": 13.042646254784035,
      "grad_norm": 0.004766182508319616,
      "learning_rate": 6.957353745215965e-06,
      "loss": 0.0211,
      "step": 47710
    },
    {
      "epoch": 13.045379989065063,
      "grad_norm": 0.0011396047193557024,
      "learning_rate": 6.954620010934938e-06,
      "loss": 0.0065,
      "step": 47720
    },
    {
      "epoch": 13.048113723346091,
      "grad_norm": 1.278655767440796,
      "learning_rate": 6.9518862766539095e-06,
      "loss": 0.0008,
      "step": 47730
    },
    {
      "epoch": 13.05084745762712,
      "grad_norm": 0.7523099184036255,
      "learning_rate": 6.949152542372882e-06,
      "loss": 0.0103,
      "step": 47740
    },
    {
      "epoch": 13.053581191908146,
      "grad_norm": 0.0016873566200956702,
      "learning_rate": 6.946418808091854e-06,
      "loss": 0.005,
      "step": 47750
    },
    {
      "epoch": 13.056314926189174,
      "grad_norm": 0.0030998128931969404,
      "learning_rate": 6.943685073810826e-06,
      "loss": 0.0151,
      "step": 47760
    },
    {
      "epoch": 13.059048660470202,
      "grad_norm": 0.001951763522811234,
      "learning_rate": 6.940951339529798e-06,
      "loss": 0.0033,
      "step": 47770
    },
    {
      "epoch": 13.06178239475123,
      "grad_norm": 0.00019124237587675452,
      "learning_rate": 6.93821760524877e-06,
      "loss": 0.0086,
      "step": 47780
    },
    {
      "epoch": 13.064516129032258,
      "grad_norm": 0.0006660203798674047,
      "learning_rate": 6.935483870967743e-06,
      "loss": 0.0005,
      "step": 47790
    },
    {
      "epoch": 13.067249863313286,
      "grad_norm": 0.4256005883216858,
      "learning_rate": 6.9327501366867145e-06,
      "loss": 0.002,
      "step": 47800
    },
    {
      "epoch": 13.069983597594314,
      "grad_norm": 0.003704802365973592,
      "learning_rate": 6.930016402405687e-06,
      "loss": 0.011,
      "step": 47810
    },
    {
      "epoch": 13.072717331875342,
      "grad_norm": 0.0016035990556702018,
      "learning_rate": 6.927282668124659e-06,
      "loss": 0.0,
      "step": 47820
    },
    {
      "epoch": 13.07545106615637,
      "grad_norm": 0.0012580498587340117,
      "learning_rate": 6.924548933843631e-06,
      "loss": 0.0056,
      "step": 47830
    },
    {
      "epoch": 13.078184800437397,
      "grad_norm": 0.0021121404133737087,
      "learning_rate": 6.921815199562603e-06,
      "loss": 0.0,
      "step": 47840
    },
    {
      "epoch": 13.080918534718425,
      "grad_norm": 0.003198235761374235,
      "learning_rate": 6.919081465281575e-06,
      "loss": 0.0079,
      "step": 47850
    },
    {
      "epoch": 13.083652268999453,
      "grad_norm": 0.16821523010730743,
      "learning_rate": 6.916347731000548e-06,
      "loss": 0.004,
      "step": 47860
    },
    {
      "epoch": 13.08638600328048,
      "grad_norm": 0.001493867370299995,
      "learning_rate": 6.9136139967195195e-06,
      "loss": 0.0034,
      "step": 47870
    },
    {
      "epoch": 13.089119737561509,
      "grad_norm": 20.135847091674805,
      "learning_rate": 6.910880262438492e-06,
      "loss": 0.0141,
      "step": 47880
    },
    {
      "epoch": 13.091853471842537,
      "grad_norm": 0.0011462719412520528,
      "learning_rate": 6.908146528157464e-06,
      "loss": 0.0,
      "step": 47890
    },
    {
      "epoch": 13.094587206123565,
      "grad_norm": 1.4255932569503784,
      "learning_rate": 6.905412793876436e-06,
      "loss": 0.0132,
      "step": 47900
    },
    {
      "epoch": 13.097320940404593,
      "grad_norm": 1.21937894821167,
      "learning_rate": 6.902679059595408e-06,
      "loss": 0.0084,
      "step": 47910
    },
    {
      "epoch": 13.100054674685621,
      "grad_norm": 0.0006770994514226913,
      "learning_rate": 6.89994532531438e-06,
      "loss": 0.0039,
      "step": 47920
    },
    {
      "epoch": 13.10278840896665,
      "grad_norm": 0.5987745523452759,
      "learning_rate": 6.897211591033353e-06,
      "loss": 0.0048,
      "step": 47930
    },
    {
      "epoch": 13.105522143247676,
      "grad_norm": 0.0004844200157094747,
      "learning_rate": 6.8944778567523244e-06,
      "loss": 0.0025,
      "step": 47940
    },
    {
      "epoch": 13.108255877528704,
      "grad_norm": 0.002400161698460579,
      "learning_rate": 6.891744122471297e-06,
      "loss": 0.0,
      "step": 47950
    },
    {
      "epoch": 13.110989611809732,
      "grad_norm": 0.0008942449931055307,
      "learning_rate": 6.889010388190268e-06,
      "loss": 0.0388,
      "step": 47960
    },
    {
      "epoch": 13.11372334609076,
      "grad_norm": 0.0022994433529675007,
      "learning_rate": 6.886276653909241e-06,
      "loss": 0.0,
      "step": 47970
    },
    {
      "epoch": 13.116457080371788,
      "grad_norm": 0.0010281541617587209,
      "learning_rate": 6.883542919628212e-06,
      "loss": 0.0211,
      "step": 47980
    },
    {
      "epoch": 13.119190814652816,
      "grad_norm": 0.0009956891881302,
      "learning_rate": 6.880809185347184e-06,
      "loss": 0.0004,
      "step": 47990
    },
    {
      "epoch": 13.121924548933844,
      "grad_norm": 0.0005696116131730378,
      "learning_rate": 6.878075451066158e-06,
      "loss": 0.0053,
      "step": 48000
    },
    {
      "epoch": 13.124658283214872,
      "grad_norm": 0.0013694880763068795,
      "learning_rate": 6.8753417167851286e-06,
      "loss": 0.0046,
      "step": 48010
    },
    {
      "epoch": 13.1273920174959,
      "grad_norm": 0.0003395918756723404,
      "learning_rate": 6.872607982504101e-06,
      "loss": 0.0153,
      "step": 48020
    },
    {
      "epoch": 13.130125751776927,
      "grad_norm": 0.0012210977729409933,
      "learning_rate": 6.869874248223073e-06,
      "loss": 0.0,
      "step": 48030
    },
    {
      "epoch": 13.132859486057955,
      "grad_norm": 0.06884502619504929,
      "learning_rate": 6.867140513942045e-06,
      "loss": 0.0038,
      "step": 48040
    },
    {
      "epoch": 13.135593220338983,
      "grad_norm": 0.007595502771437168,
      "learning_rate": 6.864406779661017e-06,
      "loss": 0.0022,
      "step": 48050
    },
    {
      "epoch": 13.13832695462001,
      "grad_norm": 0.0006996543379500508,
      "learning_rate": 6.861673045379989e-06,
      "loss": 0.0002,
      "step": 48060
    },
    {
      "epoch": 13.141060688901039,
      "grad_norm": 0.0002856710634659976,
      "learning_rate": 6.858939311098962e-06,
      "loss": 0.0,
      "step": 48070
    },
    {
      "epoch": 13.143794423182067,
      "grad_norm": 0.0005726044182665646,
      "learning_rate": 6.8562055768179336e-06,
      "loss": 0.0,
      "step": 48080
    },
    {
      "epoch": 13.146528157463095,
      "grad_norm": 0.00032047275453805923,
      "learning_rate": 6.853471842536906e-06,
      "loss": 0.0006,
      "step": 48090
    },
    {
      "epoch": 13.149261891744123,
      "grad_norm": 0.0038213918451219797,
      "learning_rate": 6.850738108255878e-06,
      "loss": 0.0234,
      "step": 48100
    },
    {
      "epoch": 13.151995626025151,
      "grad_norm": 0.04759557172656059,
      "learning_rate": 6.84800437397485e-06,
      "loss": 0.0399,
      "step": 48110
    },
    {
      "epoch": 13.154729360306177,
      "grad_norm": 0.0006964443600736558,
      "learning_rate": 6.845270639693822e-06,
      "loss": 0.0,
      "step": 48120
    },
    {
      "epoch": 13.157463094587206,
      "grad_norm": 0.9080147743225098,
      "learning_rate": 6.842536905412794e-06,
      "loss": 0.0142,
      "step": 48130
    },
    {
      "epoch": 13.160196828868234,
      "grad_norm": 0.0003617693728301674,
      "learning_rate": 6.839803171131767e-06,
      "loss": 0.0041,
      "step": 48140
    },
    {
      "epoch": 13.162930563149262,
      "grad_norm": 0.0006376895471476018,
      "learning_rate": 6.8370694368507385e-06,
      "loss": 0.0022,
      "step": 48150
    },
    {
      "epoch": 13.16566429743029,
      "grad_norm": 0.0006310610333457589,
      "learning_rate": 6.834335702569711e-06,
      "loss": 0.0001,
      "step": 48160
    },
    {
      "epoch": 13.168398031711318,
      "grad_norm": 0.0006676570628769696,
      "learning_rate": 6.831601968288683e-06,
      "loss": 0.025,
      "step": 48170
    },
    {
      "epoch": 13.171131765992346,
      "grad_norm": 0.0016222280682995915,
      "learning_rate": 6.828868234007655e-06,
      "loss": 0.0169,
      "step": 48180
    },
    {
      "epoch": 13.173865500273374,
      "grad_norm": 0.0009000112768262625,
      "learning_rate": 6.826134499726628e-06,
      "loss": 0.0098,
      "step": 48190
    },
    {
      "epoch": 13.176599234554402,
      "grad_norm": 0.0012526082573458552,
      "learning_rate": 6.823400765445599e-06,
      "loss": 0.0,
      "step": 48200
    },
    {
      "epoch": 13.179332968835428,
      "grad_norm": 0.002745670033618808,
      "learning_rate": 6.820667031164572e-06,
      "loss": 0.0028,
      "step": 48210
    },
    {
      "epoch": 13.182066703116456,
      "grad_norm": 0.0008900522952899337,
      "learning_rate": 6.8179332968835435e-06,
      "loss": 0.0062,
      "step": 48220
    },
    {
      "epoch": 13.184800437397485,
      "grad_norm": 0.002209280151873827,
      "learning_rate": 6.815199562602516e-06,
      "loss": 0.0,
      "step": 48230
    },
    {
      "epoch": 13.187534171678513,
      "grad_norm": 46.8647346496582,
      "learning_rate": 6.812465828321488e-06,
      "loss": 0.0221,
      "step": 48240
    },
    {
      "epoch": 13.19026790595954,
      "grad_norm": 0.0015183796640485525,
      "learning_rate": 6.80973209404046e-06,
      "loss": 0.0028,
      "step": 48250
    },
    {
      "epoch": 13.193001640240569,
      "grad_norm": 0.001112329657189548,
      "learning_rate": 6.806998359759433e-06,
      "loss": 0.0,
      "step": 48260
    },
    {
      "epoch": 13.195735374521597,
      "grad_norm": 0.002509502926841378,
      "learning_rate": 6.804264625478404e-06,
      "loss": 0.0047,
      "step": 48270
    },
    {
      "epoch": 13.198469108802625,
      "grad_norm": 0.00993114709854126,
      "learning_rate": 6.801530891197377e-06,
      "loss": 0.0005,
      "step": 48280
    },
    {
      "epoch": 13.201202843083653,
      "grad_norm": 0.0006283950060606003,
      "learning_rate": 6.798797156916348e-06,
      "loss": 0.0145,
      "step": 48290
    },
    {
      "epoch": 13.20393657736468,
      "grad_norm": 0.0003990523109678179,
      "learning_rate": 6.796063422635321e-06,
      "loss": 0.0006,
      "step": 48300
    },
    {
      "epoch": 13.206670311645707,
      "grad_norm": 0.0016487642424181104,
      "learning_rate": 6.793329688354292e-06,
      "loss": 0.0024,
      "step": 48310
    },
    {
      "epoch": 13.209404045926735,
      "grad_norm": 0.0023962731938809156,
      "learning_rate": 6.790595954073264e-06,
      "loss": 0.0116,
      "step": 48320
    },
    {
      "epoch": 13.212137780207764,
      "grad_norm": 0.001952729537151754,
      "learning_rate": 6.787862219792238e-06,
      "loss": 0.0,
      "step": 48330
    },
    {
      "epoch": 13.214871514488792,
      "grad_norm": 0.00031907676020637155,
      "learning_rate": 6.7851284855112085e-06,
      "loss": 0.0019,
      "step": 48340
    },
    {
      "epoch": 13.21760524876982,
      "grad_norm": 0.000891922740265727,
      "learning_rate": 6.782394751230181e-06,
      "loss": 0.003,
      "step": 48350
    },
    {
      "epoch": 13.220338983050848,
      "grad_norm": 0.0007596457144245505,
      "learning_rate": 6.779661016949153e-06,
      "loss": 0.0,
      "step": 48360
    },
    {
      "epoch": 13.223072717331876,
      "grad_norm": 0.0008919913088902831,
      "learning_rate": 6.776927282668125e-06,
      "loss": 0.0019,
      "step": 48370
    },
    {
      "epoch": 13.225806451612904,
      "grad_norm": 0.00029755415744148195,
      "learning_rate": 6.774193548387097e-06,
      "loss": 0.0031,
      "step": 48380
    },
    {
      "epoch": 13.22854018589393,
      "grad_norm": 1.5366400480270386,
      "learning_rate": 6.771459814106069e-06,
      "loss": 0.0227,
      "step": 48390
    },
    {
      "epoch": 13.231273920174958,
      "grad_norm": 0.00207536737434566,
      "learning_rate": 6.768726079825042e-06,
      "loss": 0.0,
      "step": 48400
    },
    {
      "epoch": 13.234007654455986,
      "grad_norm": 0.0007530698203481734,
      "learning_rate": 6.7659923455440134e-06,
      "loss": 0.012,
      "step": 48410
    },
    {
      "epoch": 13.236741388737014,
      "grad_norm": 0.0010341097367927432,
      "learning_rate": 6.763258611262986e-06,
      "loss": 0.0028,
      "step": 48420
    },
    {
      "epoch": 13.239475123018043,
      "grad_norm": 1.4061158895492554,
      "learning_rate": 6.760524876981958e-06,
      "loss": 0.0038,
      "step": 48430
    },
    {
      "epoch": 13.24220885729907,
      "grad_norm": 0.12014050036668777,
      "learning_rate": 6.75779114270093e-06,
      "loss": 0.008,
      "step": 48440
    },
    {
      "epoch": 13.244942591580099,
      "grad_norm": 0.0016370854573324323,
      "learning_rate": 6.755057408419902e-06,
      "loss": 0.0,
      "step": 48450
    },
    {
      "epoch": 13.247676325861127,
      "grad_norm": 0.0012302214745432138,
      "learning_rate": 6.752323674138874e-06,
      "loss": 0.0022,
      "step": 48460
    },
    {
      "epoch": 13.250410060142155,
      "grad_norm": 0.0012009544298052788,
      "learning_rate": 6.749589939857847e-06,
      "loss": 0.0076,
      "step": 48470
    },
    {
      "epoch": 13.253143794423183,
      "grad_norm": 0.0007601745892316103,
      "learning_rate": 6.746856205576818e-06,
      "loss": 0.0039,
      "step": 48480
    },
    {
      "epoch": 13.25587752870421,
      "grad_norm": 0.00034199844230897725,
      "learning_rate": 6.744122471295791e-06,
      "loss": 0.0039,
      "step": 48490
    },
    {
      "epoch": 13.258611262985237,
      "grad_norm": 0.00027185562066733837,
      "learning_rate": 6.741388737014763e-06,
      "loss": 0.0023,
      "step": 48500
    },
    {
      "epoch": 13.261344997266265,
      "grad_norm": 0.00034728774335235357,
      "learning_rate": 6.738655002733735e-06,
      "loss": 0.0105,
      "step": 48510
    },
    {
      "epoch": 13.264078731547293,
      "grad_norm": 0.0002641302708070725,
      "learning_rate": 6.735921268452707e-06,
      "loss": 0.0,
      "step": 48520
    },
    {
      "epoch": 13.266812465828322,
      "grad_norm": 0.0005504897562786937,
      "learning_rate": 6.733187534171679e-06,
      "loss": 0.0062,
      "step": 48530
    },
    {
      "epoch": 13.26954620010935,
      "grad_norm": 0.004360822029411793,
      "learning_rate": 6.730453799890652e-06,
      "loss": 0.0117,
      "step": 48540
    },
    {
      "epoch": 13.272279934390378,
      "grad_norm": 0.0005955669330433011,
      "learning_rate": 6.727720065609623e-06,
      "loss": 0.0,
      "step": 48550
    },
    {
      "epoch": 13.275013668671406,
      "grad_norm": 0.0005577295087277889,
      "learning_rate": 6.724986331328596e-06,
      "loss": 0.0,
      "step": 48560
    },
    {
      "epoch": 13.277747402952434,
      "grad_norm": 0.0008257924928329885,
      "learning_rate": 6.7222525970475676e-06,
      "loss": 0.0207,
      "step": 48570
    },
    {
      "epoch": 13.28048113723346,
      "grad_norm": 0.0002590272342786193,
      "learning_rate": 6.71951886276654e-06,
      "loss": 0.0003,
      "step": 48580
    },
    {
      "epoch": 13.283214871514488,
      "grad_norm": 0.00024733555619604886,
      "learning_rate": 6.716785128485511e-06,
      "loss": 0.0,
      "step": 48590
    },
    {
      "epoch": 13.285948605795516,
      "grad_norm": 0.0005084006697870791,
      "learning_rate": 6.714051394204484e-06,
      "loss": 0.0,
      "step": 48600
    },
    {
      "epoch": 13.288682340076544,
      "grad_norm": 0.0014727629022672772,
      "learning_rate": 6.711317659923457e-06,
      "loss": 0.0109,
      "step": 48610
    },
    {
      "epoch": 13.291416074357572,
      "grad_norm": 0.0008275783038698137,
      "learning_rate": 6.7085839256424275e-06,
      "loss": 0.0065,
      "step": 48620
    },
    {
      "epoch": 13.2941498086386,
      "grad_norm": 0.0004937232006341219,
      "learning_rate": 6.705850191361401e-06,
      "loss": 0.0035,
      "step": 48630
    },
    {
      "epoch": 13.296883542919629,
      "grad_norm": 0.0002035902434727177,
      "learning_rate": 6.703116457080372e-06,
      "loss": 0.0,
      "step": 48640
    },
    {
      "epoch": 13.299617277200657,
      "grad_norm": 0.00046751293120905757,
      "learning_rate": 6.700382722799344e-06,
      "loss": 0.0041,
      "step": 48650
    },
    {
      "epoch": 13.302351011481685,
      "grad_norm": 3.103595018386841,
      "learning_rate": 6.697648988518316e-06,
      "loss": 0.032,
      "step": 48660
    },
    {
      "epoch": 13.305084745762711,
      "grad_norm": 0.0007130269659683108,
      "learning_rate": 6.694915254237288e-06,
      "loss": 0.0,
      "step": 48670
    },
    {
      "epoch": 13.30781848004374,
      "grad_norm": 0.0004708950873464346,
      "learning_rate": 6.692181519956261e-06,
      "loss": 0.0002,
      "step": 48680
    },
    {
      "epoch": 13.310552214324767,
      "grad_norm": 0.0004194833163637668,
      "learning_rate": 6.6894477856752325e-06,
      "loss": 0.0043,
      "step": 48690
    },
    {
      "epoch": 13.313285948605795,
      "grad_norm": 0.0005637155845761299,
      "learning_rate": 6.686714051394205e-06,
      "loss": 0.0072,
      "step": 48700
    },
    {
      "epoch": 13.316019682886823,
      "grad_norm": 0.004883527755737305,
      "learning_rate": 6.683980317113177e-06,
      "loss": 0.0011,
      "step": 48710
    },
    {
      "epoch": 13.318753417167851,
      "grad_norm": 0.001389628159813583,
      "learning_rate": 6.681246582832149e-06,
      "loss": 0.0007,
      "step": 48720
    },
    {
      "epoch": 13.32148715144888,
      "grad_norm": 0.0007252676878124475,
      "learning_rate": 6.678512848551122e-06,
      "loss": 0.0325,
      "step": 48730
    },
    {
      "epoch": 13.324220885729908,
      "grad_norm": 0.005131876096129417,
      "learning_rate": 6.675779114270093e-06,
      "loss": 0.001,
      "step": 48740
    },
    {
      "epoch": 13.326954620010936,
      "grad_norm": 0.0007123750983737409,
      "learning_rate": 6.673045379989066e-06,
      "loss": 0.0023,
      "step": 48750
    },
    {
      "epoch": 13.329688354291962,
      "grad_norm": 0.007490671705454588,
      "learning_rate": 6.6703116457080375e-06,
      "loss": 0.0064,
      "step": 48760
    },
    {
      "epoch": 13.33242208857299,
      "grad_norm": 0.0004295822000131011,
      "learning_rate": 6.66757791142701e-06,
      "loss": 0.0153,
      "step": 48770
    },
    {
      "epoch": 13.335155822854018,
      "grad_norm": 0.0014168893685564399,
      "learning_rate": 6.664844177145982e-06,
      "loss": 0.0,
      "step": 48780
    },
    {
      "epoch": 13.337889557135046,
      "grad_norm": 0.002945631742477417,
      "learning_rate": 6.662110442864954e-06,
      "loss": 0.0276,
      "step": 48790
    },
    {
      "epoch": 13.340623291416074,
      "grad_norm": 0.001781201921403408,
      "learning_rate": 6.659376708583927e-06,
      "loss": 0.0266,
      "step": 48800
    },
    {
      "epoch": 13.343357025697102,
      "grad_norm": 0.01082603633403778,
      "learning_rate": 6.656642974302898e-06,
      "loss": 0.0017,
      "step": 48810
    },
    {
      "epoch": 13.34609075997813,
      "grad_norm": 0.052546463906764984,
      "learning_rate": 6.653909240021871e-06,
      "loss": 0.0048,
      "step": 48820
    },
    {
      "epoch": 13.348824494259159,
      "grad_norm": 6.9329118728637695,
      "learning_rate": 6.6511755057408425e-06,
      "loss": 0.0326,
      "step": 48830
    },
    {
      "epoch": 13.351558228540187,
      "grad_norm": 0.006675638724118471,
      "learning_rate": 6.648441771459815e-06,
      "loss": 0.0001,
      "step": 48840
    },
    {
      "epoch": 13.354291962821215,
      "grad_norm": 0.0035595756489783525,
      "learning_rate": 6.645708037178787e-06,
      "loss": 0.0017,
      "step": 48850
    },
    {
      "epoch": 13.357025697102241,
      "grad_norm": 2.0207560062408447,
      "learning_rate": 6.642974302897759e-06,
      "loss": 0.0139,
      "step": 48860
    },
    {
      "epoch": 13.359759431383269,
      "grad_norm": 0.010014929808676243,
      "learning_rate": 6.640240568616732e-06,
      "loss": 0.0002,
      "step": 48870
    },
    {
      "epoch": 13.362493165664297,
      "grad_norm": 0.003615312511101365,
      "learning_rate": 6.637506834335703e-06,
      "loss": 0.0003,
      "step": 48880
    },
    {
      "epoch": 13.365226899945325,
      "grad_norm": 0.002234054496511817,
      "learning_rate": 6.634773100054676e-06,
      "loss": 0.0001,
      "step": 48890
    },
    {
      "epoch": 13.367960634226353,
      "grad_norm": 0.0019281543791294098,
      "learning_rate": 6.6320393657736474e-06,
      "loss": 0.0093,
      "step": 48900
    },
    {
      "epoch": 13.370694368507381,
      "grad_norm": 1.4322919845581055,
      "learning_rate": 6.62930563149262e-06,
      "loss": 0.004,
      "step": 48910
    },
    {
      "epoch": 13.37342810278841,
      "grad_norm": 1.6188268661499023,
      "learning_rate": 6.626571897211591e-06,
      "loss": 0.0056,
      "step": 48920
    },
    {
      "epoch": 13.376161837069438,
      "grad_norm": 0.0009467445779591799,
      "learning_rate": 6.623838162930564e-06,
      "loss": 0.0001,
      "step": 48930
    },
    {
      "epoch": 13.378895571350466,
      "grad_norm": 4.48953914642334,
      "learning_rate": 6.621104428649537e-06,
      "loss": 0.0083,
      "step": 48940
    },
    {
      "epoch": 13.381629305631492,
      "grad_norm": 0.0008932249620556831,
      "learning_rate": 6.618370694368507e-06,
      "loss": 0.0049,
      "step": 48950
    },
    {
      "epoch": 13.38436303991252,
      "grad_norm": 1.8715900182724,
      "learning_rate": 6.615636960087481e-06,
      "loss": 0.0068,
      "step": 48960
    },
    {
      "epoch": 13.387096774193548,
      "grad_norm": 0.0006299160304479301,
      "learning_rate": 6.612903225806452e-06,
      "loss": 0.0035,
      "step": 48970
    },
    {
      "epoch": 13.389830508474576,
      "grad_norm": 0.18640272319316864,
      "learning_rate": 6.610169491525424e-06,
      "loss": 0.0312,
      "step": 48980
    },
    {
      "epoch": 13.392564242755604,
      "grad_norm": 0.0015338053926825523,
      "learning_rate": 6.607435757244396e-06,
      "loss": 0.0063,
      "step": 48990
    },
    {
      "epoch": 13.395297977036632,
      "grad_norm": 1.0909043550491333,
      "learning_rate": 6.604702022963368e-06,
      "loss": 0.0116,
      "step": 49000
    },
    {
      "epoch": 13.39803171131766,
      "grad_norm": 0.001401805318892002,
      "learning_rate": 6.601968288682341e-06,
      "loss": 0.0034,
      "step": 49010
    },
    {
      "epoch": 13.400765445598688,
      "grad_norm": 0.5978439450263977,
      "learning_rate": 6.599234554401312e-06,
      "loss": 0.0165,
      "step": 49020
    },
    {
      "epoch": 13.403499179879717,
      "grad_norm": 0.00029250929947011173,
      "learning_rate": 6.596500820120285e-06,
      "loss": 0.0001,
      "step": 49030
    },
    {
      "epoch": 13.406232914160743,
      "grad_norm": 0.027234990149736404,
      "learning_rate": 6.5937670858392566e-06,
      "loss": 0.0,
      "step": 49040
    },
    {
      "epoch": 13.40896664844177,
      "grad_norm": 0.0006024147151038051,
      "learning_rate": 6.591033351558229e-06,
      "loss": 0.0033,
      "step": 49050
    },
    {
      "epoch": 13.411700382722799,
      "grad_norm": 0.007923169061541557,
      "learning_rate": 6.588299617277201e-06,
      "loss": 0.0025,
      "step": 49060
    },
    {
      "epoch": 13.414434117003827,
      "grad_norm": 0.8819438219070435,
      "learning_rate": 6.585565882996173e-06,
      "loss": 0.0026,
      "step": 49070
    },
    {
      "epoch": 13.417167851284855,
      "grad_norm": 0.0016650193138048053,
      "learning_rate": 6.582832148715146e-06,
      "loss": 0.0057,
      "step": 49080
    },
    {
      "epoch": 13.419901585565883,
      "grad_norm": 0.003342744428664446,
      "learning_rate": 6.580098414434117e-06,
      "loss": 0.0033,
      "step": 49090
    },
    {
      "epoch": 13.422635319846911,
      "grad_norm": 0.000296479876851663,
      "learning_rate": 6.57736468015309e-06,
      "loss": 0.0134,
      "step": 49100
    },
    {
      "epoch": 13.42536905412794,
      "grad_norm": 0.0014744570944458246,
      "learning_rate": 6.5746309458720615e-06,
      "loss": 0.0329,
      "step": 49110
    },
    {
      "epoch": 13.428102788408967,
      "grad_norm": 0.001240259618498385,
      "learning_rate": 6.571897211591034e-06,
      "loss": 0.0103,
      "step": 49120
    },
    {
      "epoch": 13.430836522689994,
      "grad_norm": 1.1440441608428955,
      "learning_rate": 6.569163477310006e-06,
      "loss": 0.0075,
      "step": 49130
    },
    {
      "epoch": 13.433570256971022,
      "grad_norm": 0.0007177163497544825,
      "learning_rate": 6.566429743028978e-06,
      "loss": 0.0,
      "step": 49140
    },
    {
      "epoch": 13.43630399125205,
      "grad_norm": 0.003482766915112734,
      "learning_rate": 6.563696008747951e-06,
      "loss": 0.0221,
      "step": 49150
    },
    {
      "epoch": 13.439037725533078,
      "grad_norm": 0.0007914907764643431,
      "learning_rate": 6.560962274466922e-06,
      "loss": 0.0001,
      "step": 49160
    },
    {
      "epoch": 13.441771459814106,
      "grad_norm": 0.007706701289862394,
      "learning_rate": 6.558228540185895e-06,
      "loss": 0.0044,
      "step": 49170
    },
    {
      "epoch": 13.444505194095134,
      "grad_norm": 0.0007696617394685745,
      "learning_rate": 6.5554948059048665e-06,
      "loss": 0.0114,
      "step": 49180
    },
    {
      "epoch": 13.447238928376162,
      "grad_norm": 0.00043069542152807117,
      "learning_rate": 6.552761071623839e-06,
      "loss": 0.0,
      "step": 49190
    },
    {
      "epoch": 13.44997266265719,
      "grad_norm": 0.0027777862269431353,
      "learning_rate": 6.550027337342811e-06,
      "loss": 0.0034,
      "step": 49200
    },
    {
      "epoch": 13.452706396938218,
      "grad_norm": 1.4825294017791748,
      "learning_rate": 6.547293603061783e-06,
      "loss": 0.0075,
      "step": 49210
    },
    {
      "epoch": 13.455440131219245,
      "grad_norm": 0.0005204866756685078,
      "learning_rate": 6.544559868780756e-06,
      "loss": 0.0027,
      "step": 49220
    },
    {
      "epoch": 13.458173865500273,
      "grad_norm": 1.2812210321426392,
      "learning_rate": 6.541826134499727e-06,
      "loss": 0.0036,
      "step": 49230
    },
    {
      "epoch": 13.4609075997813,
      "grad_norm": 0.0009328758460469544,
      "learning_rate": 6.5390924002187e-06,
      "loss": 0.0,
      "step": 49240
    },
    {
      "epoch": 13.463641334062329,
      "grad_norm": 74.85596466064453,
      "learning_rate": 6.536358665937671e-06,
      "loss": 0.0304,
      "step": 49250
    },
    {
      "epoch": 13.466375068343357,
      "grad_norm": 0.00036697820178233087,
      "learning_rate": 6.533624931656644e-06,
      "loss": 0.0027,
      "step": 49260
    },
    {
      "epoch": 13.469108802624385,
      "grad_norm": 0.0007492683944292367,
      "learning_rate": 6.5308911973756165e-06,
      "loss": 0.0157,
      "step": 49270
    },
    {
      "epoch": 13.471842536905413,
      "grad_norm": 0.0027618983294814825,
      "learning_rate": 6.528157463094587e-06,
      "loss": 0.0021,
      "step": 49280
    },
    {
      "epoch": 13.474576271186441,
      "grad_norm": 0.004579632077366114,
      "learning_rate": 6.52542372881356e-06,
      "loss": 0.0067,
      "step": 49290
    },
    {
      "epoch": 13.47731000546747,
      "grad_norm": 0.0021368234883993864,
      "learning_rate": 6.5226899945325315e-06,
      "loss": 0.0012,
      "step": 49300
    },
    {
      "epoch": 13.480043739748496,
      "grad_norm": 0.8630154728889465,
      "learning_rate": 6.519956260251504e-06,
      "loss": 0.0035,
      "step": 49310
    },
    {
      "epoch": 13.482777474029524,
      "grad_norm": 0.0015540375607088208,
      "learning_rate": 6.517222525970476e-06,
      "loss": 0.0115,
      "step": 49320
    },
    {
      "epoch": 13.485511208310552,
      "grad_norm": 9.90817642211914,
      "learning_rate": 6.514488791689448e-06,
      "loss": 0.0147,
      "step": 49330
    },
    {
      "epoch": 13.48824494259158,
      "grad_norm": 0.000911498034838587,
      "learning_rate": 6.511755057408421e-06,
      "loss": 0.0054,
      "step": 49340
    },
    {
      "epoch": 13.490978676872608,
      "grad_norm": 1.1170388460159302,
      "learning_rate": 6.509021323127392e-06,
      "loss": 0.0457,
      "step": 49350
    },
    {
      "epoch": 13.493712411153636,
      "grad_norm": 0.013256801292300224,
      "learning_rate": 6.506287588846365e-06,
      "loss": 0.0077,
      "step": 49360
    },
    {
      "epoch": 13.496446145434664,
      "grad_norm": 0.0009672627202235162,
      "learning_rate": 6.5035538545653364e-06,
      "loss": 0.0003,
      "step": 49370
    },
    {
      "epoch": 13.499179879715692,
      "grad_norm": 0.0017619420541450381,
      "learning_rate": 6.500820120284309e-06,
      "loss": 0.0001,
      "step": 49380
    },
    {
      "epoch": 13.50191361399672,
      "grad_norm": 0.000769825535826385,
      "learning_rate": 6.498086386003281e-06,
      "loss": 0.0019,
      "step": 49390
    },
    {
      "epoch": 13.504647348277746,
      "grad_norm": 0.0005359493079595268,
      "learning_rate": 6.495352651722253e-06,
      "loss": 0.0074,
      "step": 49400
    },
    {
      "epoch": 13.507381082558775,
      "grad_norm": 0.0011459620436653495,
      "learning_rate": 6.492618917441226e-06,
      "loss": 0.0055,
      "step": 49410
    },
    {
      "epoch": 13.510114816839803,
      "grad_norm": 0.0012165640946477652,
      "learning_rate": 6.489885183160197e-06,
      "loss": 0.0029,
      "step": 49420
    },
    {
      "epoch": 13.51284855112083,
      "grad_norm": 0.06233731284737587,
      "learning_rate": 6.48715144887917e-06,
      "loss": 0.0157,
      "step": 49430
    },
    {
      "epoch": 13.515582285401859,
      "grad_norm": 0.001246524159796536,
      "learning_rate": 6.4844177145981414e-06,
      "loss": 0.0124,
      "step": 49440
    },
    {
      "epoch": 13.518316019682887,
      "grad_norm": 0.014497209340333939,
      "learning_rate": 6.481683980317114e-06,
      "loss": 0.0165,
      "step": 49450
    },
    {
      "epoch": 13.521049753963915,
      "grad_norm": 0.9352036714553833,
      "learning_rate": 6.478950246036086e-06,
      "loss": 0.016,
      "step": 49460
    },
    {
      "epoch": 13.523783488244943,
      "grad_norm": 0.015657849609851837,
      "learning_rate": 6.476216511755058e-06,
      "loss": 0.0019,
      "step": 49470
    },
    {
      "epoch": 13.526517222525971,
      "grad_norm": 0.8367874026298523,
      "learning_rate": 6.473482777474031e-06,
      "loss": 0.0123,
      "step": 49480
    },
    {
      "epoch": 13.529250956807,
      "grad_norm": 0.0024686839897185564,
      "learning_rate": 6.470749043193002e-06,
      "loss": 0.0019,
      "step": 49490
    },
    {
      "epoch": 13.531984691088025,
      "grad_norm": 0.0009301119716838002,
      "learning_rate": 6.468015308911975e-06,
      "loss": 0.0,
      "step": 49500
    },
    {
      "epoch": 13.534718425369054,
      "grad_norm": 0.0006194383022375405,
      "learning_rate": 6.465281574630946e-06,
      "loss": 0.0068,
      "step": 49510
    },
    {
      "epoch": 13.537452159650082,
      "grad_norm": 0.0015492071397602558,
      "learning_rate": 6.462547840349919e-06,
      "loss": 0.0116,
      "step": 49520
    },
    {
      "epoch": 13.54018589393111,
      "grad_norm": 2.822443962097168,
      "learning_rate": 6.4598141060688906e-06,
      "loss": 0.0146,
      "step": 49530
    },
    {
      "epoch": 13.542919628212138,
      "grad_norm": 0.00038470179424621165,
      "learning_rate": 6.457080371787863e-06,
      "loss": 0.0001,
      "step": 49540
    },
    {
      "epoch": 13.545653362493166,
      "grad_norm": 0.0052686347626149654,
      "learning_rate": 6.4543466375068356e-06,
      "loss": 0.0171,
      "step": 49550
    },
    {
      "epoch": 13.548387096774194,
      "grad_norm": 0.20008347928524017,
      "learning_rate": 6.451612903225806e-06,
      "loss": 0.0001,
      "step": 49560
    },
    {
      "epoch": 13.551120831055222,
      "grad_norm": 0.0005093775689601898,
      "learning_rate": 6.44887916894478e-06,
      "loss": 0.0052,
      "step": 49570
    },
    {
      "epoch": 13.55385456533625,
      "grad_norm": 0.049554161727428436,
      "learning_rate": 6.4461454346637505e-06,
      "loss": 0.0043,
      "step": 49580
    },
    {
      "epoch": 13.556588299617276,
      "grad_norm": 0.002598097315058112,
      "learning_rate": 6.443411700382723e-06,
      "loss": 0.0191,
      "step": 49590
    },
    {
      "epoch": 13.559322033898304,
      "grad_norm": 0.0003531394759193063,
      "learning_rate": 6.440677966101695e-06,
      "loss": 0.0102,
      "step": 49600
    },
    {
      "epoch": 13.562055768179333,
      "grad_norm": 0.0004879659099970013,
      "learning_rate": 6.437944231820667e-06,
      "loss": 0.0041,
      "step": 49610
    },
    {
      "epoch": 13.56478950246036,
      "grad_norm": 0.0007102527306415141,
      "learning_rate": 6.43521049753964e-06,
      "loss": 0.0155,
      "step": 49620
    },
    {
      "epoch": 13.567523236741389,
      "grad_norm": 0.0009808026952669024,
      "learning_rate": 6.432476763258611e-06,
      "loss": 0.0025,
      "step": 49630
    },
    {
      "epoch": 13.570256971022417,
      "grad_norm": 0.12379170209169388,
      "learning_rate": 6.429743028977584e-06,
      "loss": 0.0184,
      "step": 49640
    },
    {
      "epoch": 13.572990705303445,
      "grad_norm": 1.2865670919418335,
      "learning_rate": 6.4270092946965555e-06,
      "loss": 0.0083,
      "step": 49650
    },
    {
      "epoch": 13.575724439584473,
      "grad_norm": 0.0009304994018748403,
      "learning_rate": 6.424275560415528e-06,
      "loss": 0.0058,
      "step": 49660
    },
    {
      "epoch": 13.578458173865501,
      "grad_norm": 0.0004208686586935073,
      "learning_rate": 6.4215418261345e-06,
      "loss": 0.0069,
      "step": 49670
    },
    {
      "epoch": 13.581191908146527,
      "grad_norm": 0.000317576079396531,
      "learning_rate": 6.418808091853472e-06,
      "loss": 0.0051,
      "step": 49680
    },
    {
      "epoch": 13.583925642427555,
      "grad_norm": 0.0007584053091704845,
      "learning_rate": 6.416074357572445e-06,
      "loss": 0.0021,
      "step": 49690
    },
    {
      "epoch": 13.586659376708583,
      "grad_norm": 0.0003496099670883268,
      "learning_rate": 6.413340623291416e-06,
      "loss": 0.011,
      "step": 49700
    },
    {
      "epoch": 13.589393110989612,
      "grad_norm": 0.0004258057742845267,
      "learning_rate": 6.410606889010389e-06,
      "loss": 0.0079,
      "step": 49710
    },
    {
      "epoch": 13.59212684527064,
      "grad_norm": 0.0003318357630632818,
      "learning_rate": 6.4078731547293605e-06,
      "loss": 0.0001,
      "step": 49720
    },
    {
      "epoch": 13.594860579551668,
      "grad_norm": 1.0254024267196655,
      "learning_rate": 6.405139420448333e-06,
      "loss": 0.0547,
      "step": 49730
    },
    {
      "epoch": 13.597594313832696,
      "grad_norm": 0.001618073438294232,
      "learning_rate": 6.402405686167305e-06,
      "loss": 0.0,
      "step": 49740
    },
    {
      "epoch": 13.600328048113724,
      "grad_norm": 0.4345707893371582,
      "learning_rate": 6.399671951886277e-06,
      "loss": 0.0041,
      "step": 49750
    },
    {
      "epoch": 13.603061782394752,
      "grad_norm": 0.0017238033469766378,
      "learning_rate": 6.39693821760525e-06,
      "loss": 0.0016,
      "step": 49760
    },
    {
      "epoch": 13.60579551667578,
      "grad_norm": 0.0009537588921375573,
      "learning_rate": 6.394204483324221e-06,
      "loss": 0.0122,
      "step": 49770
    },
    {
      "epoch": 13.608529250956806,
      "grad_norm": 0.0006934101693332195,
      "learning_rate": 6.391470749043194e-06,
      "loss": 0.0066,
      "step": 49780
    },
    {
      "epoch": 13.611262985237834,
      "grad_norm": 0.0006322480621747673,
      "learning_rate": 6.3887370147621655e-06,
      "loss": 0.007,
      "step": 49790
    },
    {
      "epoch": 13.613996719518862,
      "grad_norm": 0.0006557549932040274,
      "learning_rate": 6.386003280481138e-06,
      "loss": 0.0038,
      "step": 49800
    },
    {
      "epoch": 13.61673045379989,
      "grad_norm": 0.0015025553293526173,
      "learning_rate": 6.3832695462001105e-06,
      "loss": 0.0089,
      "step": 49810
    },
    {
      "epoch": 13.619464188080919,
      "grad_norm": 0.0007992168539203703,
      "learning_rate": 6.380535811919082e-06,
      "loss": 0.0,
      "step": 49820
    },
    {
      "epoch": 13.622197922361947,
      "grad_norm": 1.163310170173645,
      "learning_rate": 6.377802077638055e-06,
      "loss": 0.0056,
      "step": 49830
    },
    {
      "epoch": 13.624931656642975,
      "grad_norm": 0.0003755933721549809,
      "learning_rate": 6.375068343357026e-06,
      "loss": 0.0026,
      "step": 49840
    },
    {
      "epoch": 13.627665390924003,
      "grad_norm": 0.0003883518511429429,
      "learning_rate": 6.372334609075999e-06,
      "loss": 0.0002,
      "step": 49850
    },
    {
      "epoch": 13.630399125205031,
      "grad_norm": 1.1088944673538208,
      "learning_rate": 6.36960087479497e-06,
      "loss": 0.004,
      "step": 49860
    },
    {
      "epoch": 13.633132859486057,
      "grad_norm": 1.2901854515075684,
      "learning_rate": 6.366867140513943e-06,
      "loss": 0.0043,
      "step": 49870
    },
    {
      "epoch": 13.635866593767085,
      "grad_norm": 0.0080653615295887,
      "learning_rate": 6.3641334062329155e-06,
      "loss": 0.0029,
      "step": 49880
    },
    {
      "epoch": 13.638600328048113,
      "grad_norm": 0.0002580903528723866,
      "learning_rate": 6.361399671951886e-06,
      "loss": 0.004,
      "step": 49890
    },
    {
      "epoch": 13.641334062329141,
      "grad_norm": 0.000567473703995347,
      "learning_rate": 6.35866593767086e-06,
      "loss": 0.0037,
      "step": 49900
    },
    {
      "epoch": 13.64406779661017,
      "grad_norm": 0.0005351338186301291,
      "learning_rate": 6.3559322033898304e-06,
      "loss": 0.0065,
      "step": 49910
    },
    {
      "epoch": 13.646801530891198,
      "grad_norm": 0.00024454237427562475,
      "learning_rate": 6.353198469108803e-06,
      "loss": 0.0026,
      "step": 49920
    },
    {
      "epoch": 13.649535265172226,
      "grad_norm": 0.0007225893787108362,
      "learning_rate": 6.350464734827775e-06,
      "loss": 0.0152,
      "step": 49930
    },
    {
      "epoch": 13.652268999453254,
      "grad_norm": 0.0007741434965282679,
      "learning_rate": 6.347731000546747e-06,
      "loss": 0.0046,
      "step": 49940
    },
    {
      "epoch": 13.655002733734282,
      "grad_norm": 0.0004588062292896211,
      "learning_rate": 6.34499726626572e-06,
      "loss": 0.0004,
      "step": 49950
    },
    {
      "epoch": 13.657736468015308,
      "grad_norm": 1.530464768409729,
      "learning_rate": 6.342263531984691e-06,
      "loss": 0.0113,
      "step": 49960
    },
    {
      "epoch": 13.660470202296336,
      "grad_norm": 0.0005882426048628986,
      "learning_rate": 6.339529797703664e-06,
      "loss": 0.0047,
      "step": 49970
    },
    {
      "epoch": 13.663203936577364,
      "grad_norm": 0.0014202450402081013,
      "learning_rate": 6.336796063422635e-06,
      "loss": 0.0195,
      "step": 49980
    },
    {
      "epoch": 13.665937670858392,
      "grad_norm": 0.0002562107692938298,
      "learning_rate": 6.334062329141608e-06,
      "loss": 0.0001,
      "step": 49990
    },
    {
      "epoch": 13.66867140513942,
      "grad_norm": 0.7299603223800659,
      "learning_rate": 6.3313285948605796e-06,
      "loss": 0.0091,
      "step": 50000
    },
    {
      "epoch": 13.671405139420449,
      "grad_norm": 0.0002476064255461097,
      "learning_rate": 6.328594860579552e-06,
      "loss": 0.0045,
      "step": 50010
    },
    {
      "epoch": 13.674138873701477,
      "grad_norm": 0.0001976871571969241,
      "learning_rate": 6.3258611262985246e-06,
      "loss": 0.0037,
      "step": 50020
    },
    {
      "epoch": 13.676872607982505,
      "grad_norm": 0.00031033853883855045,
      "learning_rate": 6.323127392017496e-06,
      "loss": 0.0018,
      "step": 50030
    },
    {
      "epoch": 13.679606342263533,
      "grad_norm": 0.0014796217437833548,
      "learning_rate": 6.320393657736469e-06,
      "loss": 0.0034,
      "step": 50040
    },
    {
      "epoch": 13.682340076544559,
      "grad_norm": 0.00026202277513220906,
      "learning_rate": 6.31765992345544e-06,
      "loss": 0.0198,
      "step": 50050
    },
    {
      "epoch": 13.685073810825587,
      "grad_norm": 0.0002711851557251066,
      "learning_rate": 6.314926189174413e-06,
      "loss": 0.0391,
      "step": 50060
    },
    {
      "epoch": 13.687807545106615,
      "grad_norm": 0.054392050951719284,
      "learning_rate": 6.3121924548933845e-06,
      "loss": 0.006,
      "step": 50070
    },
    {
      "epoch": 13.690541279387643,
      "grad_norm": 0.0005852155736647546,
      "learning_rate": 6.309458720612357e-06,
      "loss": 0.002,
      "step": 50080
    },
    {
      "epoch": 13.693275013668671,
      "grad_norm": 0.0004584995040204376,
      "learning_rate": 6.3067249863313295e-06,
      "loss": 0.0109,
      "step": 50090
    },
    {
      "epoch": 13.6960087479497,
      "grad_norm": 0.000675886170938611,
      "learning_rate": 6.303991252050301e-06,
      "loss": 0.0011,
      "step": 50100
    },
    {
      "epoch": 13.698742482230728,
      "grad_norm": 0.00039863947313278913,
      "learning_rate": 6.301257517769274e-06,
      "loss": 0.0009,
      "step": 50110
    },
    {
      "epoch": 13.701476216511756,
      "grad_norm": 0.0013947042170912027,
      "learning_rate": 6.298523783488245e-06,
      "loss": 0.0091,
      "step": 50120
    },
    {
      "epoch": 13.704209950792784,
      "grad_norm": 8.392127990722656,
      "learning_rate": 6.295790049207218e-06,
      "loss": 0.0317,
      "step": 50130
    },
    {
      "epoch": 13.70694368507381,
      "grad_norm": 2.304706573486328,
      "learning_rate": 6.2930563149261895e-06,
      "loss": 0.0103,
      "step": 50140
    },
    {
      "epoch": 13.709677419354838,
      "grad_norm": 0.0004673307412303984,
      "learning_rate": 6.290322580645162e-06,
      "loss": 0.0141,
      "step": 50150
    },
    {
      "epoch": 13.712411153635866,
      "grad_norm": 1.722610354423523,
      "learning_rate": 6.2875888463641345e-06,
      "loss": 0.0058,
      "step": 50160
    },
    {
      "epoch": 13.715144887916894,
      "grad_norm": 0.0013306009350344539,
      "learning_rate": 6.284855112083106e-06,
      "loss": 0.004,
      "step": 50170
    },
    {
      "epoch": 13.717878622197922,
      "grad_norm": 0.0022964368108659983,
      "learning_rate": 6.282121377802079e-06,
      "loss": 0.0079,
      "step": 50180
    },
    {
      "epoch": 13.72061235647895,
      "grad_norm": 0.00047549520968459547,
      "learning_rate": 6.2793876435210495e-06,
      "loss": 0.0306,
      "step": 50190
    },
    {
      "epoch": 13.723346090759978,
      "grad_norm": 0.0007215456571429968,
      "learning_rate": 6.276653909240023e-06,
      "loss": 0.0078,
      "step": 50200
    },
    {
      "epoch": 13.726079825041007,
      "grad_norm": 0.0006865207687951624,
      "learning_rate": 6.273920174958994e-06,
      "loss": 0.0029,
      "step": 50210
    },
    {
      "epoch": 13.728813559322035,
      "grad_norm": 0.0005310410051606596,
      "learning_rate": 6.271186440677966e-06,
      "loss": 0.0003,
      "step": 50220
    },
    {
      "epoch": 13.731547293603061,
      "grad_norm": 0.0005068100872449577,
      "learning_rate": 6.2684527063969395e-06,
      "loss": 0.0045,
      "step": 50230
    },
    {
      "epoch": 13.734281027884089,
      "grad_norm": 0.30903762578964233,
      "learning_rate": 6.26571897211591e-06,
      "loss": 0.0127,
      "step": 50240
    },
    {
      "epoch": 13.737014762165117,
      "grad_norm": 0.04075843468308449,
      "learning_rate": 6.262985237834883e-06,
      "loss": 0.0032,
      "step": 50250
    },
    {
      "epoch": 13.739748496446145,
      "grad_norm": 0.00023420709476340562,
      "learning_rate": 6.2602515035538545e-06,
      "loss": 0.012,
      "step": 50260
    },
    {
      "epoch": 13.742482230727173,
      "grad_norm": 0.21167348325252533,
      "learning_rate": 6.257517769272827e-06,
      "loss": 0.0366,
      "step": 50270
    },
    {
      "epoch": 13.745215965008201,
      "grad_norm": 0.00029526883736252785,
      "learning_rate": 6.254784034991799e-06,
      "loss": 0.0026,
      "step": 50280
    },
    {
      "epoch": 13.74794969928923,
      "grad_norm": 0.0006372519419528544,
      "learning_rate": 6.252050300710771e-06,
      "loss": 0.0044,
      "step": 50290
    },
    {
      "epoch": 13.750683433570257,
      "grad_norm": 0.00320838182233274,
      "learning_rate": 6.249316566429744e-06,
      "loss": 0.0011,
      "step": 50300
    },
    {
      "epoch": 13.753417167851286,
      "grad_norm": 0.0005769827985204756,
      "learning_rate": 6.246582832148715e-06,
      "loss": 0.0,
      "step": 50310
    },
    {
      "epoch": 13.756150902132312,
      "grad_norm": 0.0016267836326733232,
      "learning_rate": 6.243849097867688e-06,
      "loss": 0.0081,
      "step": 50320
    },
    {
      "epoch": 13.75888463641334,
      "grad_norm": 1.0794175863265991,
      "learning_rate": 6.2411153635866595e-06,
      "loss": 0.011,
      "step": 50330
    },
    {
      "epoch": 13.761618370694368,
      "grad_norm": 0.0006406751926988363,
      "learning_rate": 6.238381629305632e-06,
      "loss": 0.0,
      "step": 50340
    },
    {
      "epoch": 13.764352104975396,
      "grad_norm": 0.15942659974098206,
      "learning_rate": 6.2356478950246045e-06,
      "loss": 0.0005,
      "step": 50350
    },
    {
      "epoch": 13.767085839256424,
      "grad_norm": 0.0006393169751390815,
      "learning_rate": 6.232914160743576e-06,
      "loss": 0.0126,
      "step": 50360
    },
    {
      "epoch": 13.769819573537452,
      "grad_norm": 2.023099899291992,
      "learning_rate": 6.230180426462549e-06,
      "loss": 0.0119,
      "step": 50370
    },
    {
      "epoch": 13.77255330781848,
      "grad_norm": 0.023495163768529892,
      "learning_rate": 6.22744669218152e-06,
      "loss": 0.0031,
      "step": 50380
    },
    {
      "epoch": 13.775287042099508,
      "grad_norm": 0.0006770375766791403,
      "learning_rate": 6.224712957900493e-06,
      "loss": 0.0517,
      "step": 50390
    },
    {
      "epoch": 13.778020776380536,
      "grad_norm": 0.0006047651404514909,
      "learning_rate": 6.2219792236194644e-06,
      "loss": 0.0001,
      "step": 50400
    },
    {
      "epoch": 13.780754510661563,
      "grad_norm": 0.0049115438014268875,
      "learning_rate": 6.219245489338437e-06,
      "loss": 0.0027,
      "step": 50410
    },
    {
      "epoch": 13.78348824494259,
      "grad_norm": 0.0009386257734149694,
      "learning_rate": 6.2165117550574094e-06,
      "loss": 0.0033,
      "step": 50420
    },
    {
      "epoch": 13.786221979223619,
      "grad_norm": 0.0008175979601219296,
      "learning_rate": 6.213778020776381e-06,
      "loss": 0.0011,
      "step": 50430
    },
    {
      "epoch": 13.788955713504647,
      "grad_norm": 0.7724286913871765,
      "learning_rate": 6.211044286495354e-06,
      "loss": 0.0146,
      "step": 50440
    },
    {
      "epoch": 13.791689447785675,
      "grad_norm": 0.0005301549099385738,
      "learning_rate": 6.208310552214325e-06,
      "loss": 0.0,
      "step": 50450
    },
    {
      "epoch": 13.794423182066703,
      "grad_norm": 0.3194667100906372,
      "learning_rate": 6.205576817933298e-06,
      "loss": 0.0051,
      "step": 50460
    },
    {
      "epoch": 13.797156916347731,
      "grad_norm": 0.004001184832304716,
      "learning_rate": 6.202843083652269e-06,
      "loss": 0.0066,
      "step": 50470
    },
    {
      "epoch": 13.79989065062876,
      "grad_norm": 0.005237981677055359,
      "learning_rate": 6.200109349371242e-06,
      "loss": 0.0071,
      "step": 50480
    },
    {
      "epoch": 13.802624384909787,
      "grad_norm": 0.5999586582183838,
      "learning_rate": 6.197375615090214e-06,
      "loss": 0.0035,
      "step": 50490
    },
    {
      "epoch": 13.805358119190815,
      "grad_norm": 0.00016626388242002577,
      "learning_rate": 6.194641880809186e-06,
      "loss": 0.0093,
      "step": 50500
    },
    {
      "epoch": 13.808091853471842,
      "grad_norm": 0.00020627221965696663,
      "learning_rate": 6.1919081465281586e-06,
      "loss": 0.0,
      "step": 50510
    },
    {
      "epoch": 13.81082558775287,
      "grad_norm": 0.0004122629761695862,
      "learning_rate": 6.189174412247129e-06,
      "loss": 0.0005,
      "step": 50520
    },
    {
      "epoch": 13.813559322033898,
      "grad_norm": 0.01264116633683443,
      "learning_rate": 6.186440677966103e-06,
      "loss": 0.0167,
      "step": 50530
    },
    {
      "epoch": 13.816293056314926,
      "grad_norm": 0.0009015385876409709,
      "learning_rate": 6.1837069436850735e-06,
      "loss": 0.0094,
      "step": 50540
    },
    {
      "epoch": 13.819026790595954,
      "grad_norm": 0.002432560082525015,
      "learning_rate": 6.180973209404046e-06,
      "loss": 0.0082,
      "step": 50550
    },
    {
      "epoch": 13.821760524876982,
      "grad_norm": 0.0001943525276146829,
      "learning_rate": 6.178239475123019e-06,
      "loss": 0.0028,
      "step": 50560
    },
    {
      "epoch": 13.82449425915801,
      "grad_norm": 0.0003571530105546117,
      "learning_rate": 6.17550574084199e-06,
      "loss": 0.0628,
      "step": 50570
    },
    {
      "epoch": 13.827227993439038,
      "grad_norm": 0.006491242907941341,
      "learning_rate": 6.172772006560963e-06,
      "loss": 0.003,
      "step": 50580
    },
    {
      "epoch": 13.829961727720066,
      "grad_norm": 0.0004404548089951277,
      "learning_rate": 6.170038272279934e-06,
      "loss": 0.0017,
      "step": 50590
    },
    {
      "epoch": 13.832695462001093,
      "grad_norm": 0.0007625370053574443,
      "learning_rate": 6.167304537998907e-06,
      "loss": 0.0056,
      "step": 50600
    },
    {
      "epoch": 13.83542919628212,
      "grad_norm": 0.0027636901941150427,
      "learning_rate": 6.1645708037178785e-06,
      "loss": 0.0059,
      "step": 50610
    },
    {
      "epoch": 13.838162930563149,
      "grad_norm": 0.00020680471789091825,
      "learning_rate": 6.161837069436851e-06,
      "loss": 0.0117,
      "step": 50620
    },
    {
      "epoch": 13.840896664844177,
      "grad_norm": 0.0007837354787625372,
      "learning_rate": 6.1591033351558235e-06,
      "loss": 0.0214,
      "step": 50630
    },
    {
      "epoch": 13.843630399125205,
      "grad_norm": 0.0008342392975464463,
      "learning_rate": 6.156369600874795e-06,
      "loss": 0.0251,
      "step": 50640
    },
    {
      "epoch": 13.846364133406233,
      "grad_norm": 0.00039790591108612716,
      "learning_rate": 6.153635866593768e-06,
      "loss": 0.0022,
      "step": 50650
    },
    {
      "epoch": 13.849097867687261,
      "grad_norm": 0.005346926394850016,
      "learning_rate": 6.150902132312739e-06,
      "loss": 0.0001,
      "step": 50660
    },
    {
      "epoch": 13.85183160196829,
      "grad_norm": 0.0006281521054916084,
      "learning_rate": 6.148168398031712e-06,
      "loss": 0.0074,
      "step": 50670
    },
    {
      "epoch": 13.854565336249317,
      "grad_norm": 0.0017972186906263232,
      "learning_rate": 6.1454346637506835e-06,
      "loss": 0.0424,
      "step": 50680
    },
    {
      "epoch": 13.857299070530345,
      "grad_norm": 0.7872698903083801,
      "learning_rate": 6.142700929469656e-06,
      "loss": 0.0009,
      "step": 50690
    },
    {
      "epoch": 13.860032804811372,
      "grad_norm": 0.0005462051485665143,
      "learning_rate": 6.1399671951886285e-06,
      "loss": 0.0004,
      "step": 50700
    },
    {
      "epoch": 13.8627665390924,
      "grad_norm": 0.0032353370916098356,
      "learning_rate": 6.1372334609076e-06,
      "loss": 0.0001,
      "step": 50710
    },
    {
      "epoch": 13.865500273373428,
      "grad_norm": 0.0007151765748858452,
      "learning_rate": 6.134499726626573e-06,
      "loss": 0.0,
      "step": 50720
    },
    {
      "epoch": 13.868234007654456,
      "grad_norm": 0.0010433915304020047,
      "learning_rate": 6.131765992345544e-06,
      "loss": 0.0072,
      "step": 50730
    },
    {
      "epoch": 13.870967741935484,
      "grad_norm": 0.013934774324297905,
      "learning_rate": 6.129032258064517e-06,
      "loss": 0.0034,
      "step": 50740
    },
    {
      "epoch": 13.873701476216512,
      "grad_norm": 0.004103139974176884,
      "learning_rate": 6.1262985237834885e-06,
      "loss": 0.0107,
      "step": 50750
    },
    {
      "epoch": 13.87643521049754,
      "grad_norm": 0.002058843383565545,
      "learning_rate": 6.123564789502461e-06,
      "loss": 0.0081,
      "step": 50760
    },
    {
      "epoch": 13.879168944778568,
      "grad_norm": 0.011142340488731861,
      "learning_rate": 6.1208310552214335e-06,
      "loss": 0.0032,
      "step": 50770
    },
    {
      "epoch": 13.881902679059596,
      "grad_norm": 0.0002675858268048614,
      "learning_rate": 6.118097320940405e-06,
      "loss": 0.0115,
      "step": 50780
    },
    {
      "epoch": 13.884636413340623,
      "grad_norm": 0.00033031031489372253,
      "learning_rate": 6.115363586659378e-06,
      "loss": 0.0,
      "step": 50790
    },
    {
      "epoch": 13.88737014762165,
      "grad_norm": 0.0007204472785815597,
      "learning_rate": 6.112629852378349e-06,
      "loss": 0.0298,
      "step": 50800
    },
    {
      "epoch": 13.890103881902679,
      "grad_norm": 1.1713449954986572,
      "learning_rate": 6.109896118097322e-06,
      "loss": 0.0077,
      "step": 50810
    },
    {
      "epoch": 13.892837616183707,
      "grad_norm": 0.0005874630878679454,
      "learning_rate": 6.107162383816293e-06,
      "loss": 0.0061,
      "step": 50820
    },
    {
      "epoch": 13.895571350464735,
      "grad_norm": 0.0006470177322626114,
      "learning_rate": 6.104428649535266e-06,
      "loss": 0.0154,
      "step": 50830
    },
    {
      "epoch": 13.898305084745763,
      "grad_norm": 0.001303556258790195,
      "learning_rate": 6.1016949152542385e-06,
      "loss": 0.0037,
      "step": 50840
    },
    {
      "epoch": 13.901038819026791,
      "grad_norm": 0.0019494304433465004,
      "learning_rate": 6.098961180973209e-06,
      "loss": 0.0088,
      "step": 50850
    },
    {
      "epoch": 13.90377255330782,
      "grad_norm": 0.0042816330678761005,
      "learning_rate": 6.096227446692183e-06,
      "loss": 0.0001,
      "step": 50860
    },
    {
      "epoch": 13.906506287588847,
      "grad_norm": 0.0006668498390354216,
      "learning_rate": 6.0934937124111534e-06,
      "loss": 0.0064,
      "step": 50870
    },
    {
      "epoch": 13.909240021869874,
      "grad_norm": 0.0004907388938590884,
      "learning_rate": 6.090759978130126e-06,
      "loss": 0.0077,
      "step": 50880
    },
    {
      "epoch": 13.911973756150902,
      "grad_norm": 0.0002581016451586038,
      "learning_rate": 6.088026243849099e-06,
      "loss": 0.003,
      "step": 50890
    },
    {
      "epoch": 13.91470749043193,
      "grad_norm": 0.0005360205541364849,
      "learning_rate": 6.08529250956807e-06,
      "loss": 0.0002,
      "step": 50900
    },
    {
      "epoch": 13.917441224712958,
      "grad_norm": 0.000616049044765532,
      "learning_rate": 6.082558775287043e-06,
      "loss": 0.0043,
      "step": 50910
    },
    {
      "epoch": 13.920174958993986,
      "grad_norm": 0.0003275871858932078,
      "learning_rate": 6.079825041006014e-06,
      "loss": 0.0024,
      "step": 50920
    },
    {
      "epoch": 13.922908693275014,
      "grad_norm": 0.0004517339984886348,
      "learning_rate": 6.077091306724987e-06,
      "loss": 0.0007,
      "step": 50930
    },
    {
      "epoch": 13.925642427556042,
      "grad_norm": 0.0003101929323747754,
      "learning_rate": 6.074357572443958e-06,
      "loss": 0.0057,
      "step": 50940
    },
    {
      "epoch": 13.92837616183707,
      "grad_norm": 0.00041515828343108296,
      "learning_rate": 6.071623838162931e-06,
      "loss": 0.0039,
      "step": 50950
    },
    {
      "epoch": 13.931109896118098,
      "grad_norm": 0.00044593759230338037,
      "learning_rate": 6.068890103881903e-06,
      "loss": 0.0,
      "step": 50960
    },
    {
      "epoch": 13.933843630399124,
      "grad_norm": 0.0004260120040271431,
      "learning_rate": 6.066156369600875e-06,
      "loss": 0.0117,
      "step": 50970
    },
    {
      "epoch": 13.936577364680153,
      "grad_norm": 0.00033979478757828474,
      "learning_rate": 6.0634226353198476e-06,
      "loss": 0.0003,
      "step": 50980
    },
    {
      "epoch": 13.93931109896118,
      "grad_norm": 0.0004632148484233767,
      "learning_rate": 6.060688901038819e-06,
      "loss": 0.0,
      "step": 50990
    },
    {
      "epoch": 13.942044833242209,
      "grad_norm": 0.00031610135920345783,
      "learning_rate": 6.057955166757792e-06,
      "loss": 0.0003,
      "step": 51000
    },
    {
      "epoch": 13.944778567523237,
      "grad_norm": 0.0020517129451036453,
      "learning_rate": 6.055221432476763e-06,
      "loss": 0.0147,
      "step": 51010
    },
    {
      "epoch": 13.947512301804265,
      "grad_norm": 0.00021581302280537784,
      "learning_rate": 6.052487698195736e-06,
      "loss": 0.0051,
      "step": 51020
    },
    {
      "epoch": 13.950246036085293,
      "grad_norm": 0.048504412174224854,
      "learning_rate": 6.049753963914708e-06,
      "loss": 0.0007,
      "step": 51030
    },
    {
      "epoch": 13.952979770366321,
      "grad_norm": 0.000210872502066195,
      "learning_rate": 6.04702022963368e-06,
      "loss": 0.0039,
      "step": 51040
    },
    {
      "epoch": 13.955713504647349,
      "grad_norm": 0.0002491098712198436,
      "learning_rate": 6.0442864953526526e-06,
      "loss": 0.0,
      "step": 51050
    },
    {
      "epoch": 13.958447238928375,
      "grad_norm": 0.0010564707918092608,
      "learning_rate": 6.041552761071624e-06,
      "loss": 0.0037,
      "step": 51060
    },
    {
      "epoch": 13.961180973209403,
      "grad_norm": 0.0003275712369941175,
      "learning_rate": 6.038819026790597e-06,
      "loss": 0.0001,
      "step": 51070
    },
    {
      "epoch": 13.963914707490432,
      "grad_norm": 0.0002622932952363044,
      "learning_rate": 6.036085292509568e-06,
      "loss": 0.04,
      "step": 51080
    },
    {
      "epoch": 13.96664844177146,
      "grad_norm": 0.00032448902493342757,
      "learning_rate": 6.033351558228541e-06,
      "loss": 0.0197,
      "step": 51090
    },
    {
      "epoch": 13.969382176052488,
      "grad_norm": 0.004692617803812027,
      "learning_rate": 6.030617823947513e-06,
      "loss": 0.007,
      "step": 51100
    },
    {
      "epoch": 13.972115910333516,
      "grad_norm": 0.0006268298602662981,
      "learning_rate": 6.027884089666485e-06,
      "loss": 0.0,
      "step": 51110
    },
    {
      "epoch": 13.974849644614544,
      "grad_norm": 0.00026051612803712487,
      "learning_rate": 6.0251503553854575e-06,
      "loss": 0.0174,
      "step": 51120
    },
    {
      "epoch": 13.977583378895572,
      "grad_norm": 0.00034827529452741146,
      "learning_rate": 6.022416621104429e-06,
      "loss": 0.0047,
      "step": 51130
    },
    {
      "epoch": 13.9803171131766,
      "grad_norm": 0.01810816489160061,
      "learning_rate": 6.019682886823402e-06,
      "loss": 0.0089,
      "step": 51140
    },
    {
      "epoch": 13.983050847457626,
      "grad_norm": 0.000815092003904283,
      "learning_rate": 6.0169491525423725e-06,
      "loss": 0.0089,
      "step": 51150
    },
    {
      "epoch": 13.985784581738654,
      "grad_norm": 0.00027251752908341587,
      "learning_rate": 6.014215418261346e-06,
      "loss": 0.0072,
      "step": 51160
    },
    {
      "epoch": 13.988518316019682,
      "grad_norm": 0.0002974943781737238,
      "learning_rate": 6.011481683980318e-06,
      "loss": 0.0056,
      "step": 51170
    },
    {
      "epoch": 13.99125205030071,
      "grad_norm": 0.00026572670321911573,
      "learning_rate": 6.008747949699289e-06,
      "loss": 0.0067,
      "step": 51180
    },
    {
      "epoch": 13.993985784581739,
      "grad_norm": 0.00031251090695150197,
      "learning_rate": 6.0060142154182625e-06,
      "loss": 0.0181,
      "step": 51190
    },
    {
      "epoch": 13.996719518862767,
      "grad_norm": 1.0494515895843506,
      "learning_rate": 6.003280481137233e-06,
      "loss": 0.0007,
      "step": 51200
    },
    {
      "epoch": 13.999453253143795,
      "grad_norm": 0.0002471059560775757,
      "learning_rate": 6.000546746856206e-06,
      "loss": 0.0001,
      "step": 51210
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.9922839506172839,
      "eval_f1": 0.9689706826449818,
      "eval_loss": 0.04646284505724907,
      "eval_precision": 0.9716738197424892,
      "eval_recall": 0.9662825437473325,
      "eval_runtime": 797.6939,
      "eval_samples_per_second": 23.585,
      "eval_steps_per_second": 0.983,
      "step": 51212
    },
    {
      "epoch": 14.002186987424823,
      "grad_norm": 0.000588707800488919,
      "learning_rate": 5.9978130125751775e-06,
      "loss": 0.0157,
      "step": 51220
    },
    {
      "epoch": 14.004920721705851,
      "grad_norm": 14.9495267868042,
      "learning_rate": 5.99507927829415e-06,
      "loss": 0.0046,
      "step": 51230
    },
    {
      "epoch": 14.007654455986877,
      "grad_norm": 0.0017573205986991525,
      "learning_rate": 5.9923455440131225e-06,
      "loss": 0.0074,
      "step": 51240
    },
    {
      "epoch": 14.010388190267905,
      "grad_norm": 0.0010018961038440466,
      "learning_rate": 5.989611809732094e-06,
      "loss": 0.0354,
      "step": 51250
    },
    {
      "epoch": 14.013121924548933,
      "grad_norm": 0.6714721322059631,
      "learning_rate": 5.986878075451067e-06,
      "loss": 0.0013,
      "step": 51260
    },
    {
      "epoch": 14.015855658829961,
      "grad_norm": 0.0012833522632718086,
      "learning_rate": 5.984144341170038e-06,
      "loss": 0.0,
      "step": 51270
    },
    {
      "epoch": 14.01858939311099,
      "grad_norm": 0.0004332022799644619,
      "learning_rate": 5.981410606889011e-06,
      "loss": 0.0001,
      "step": 51280
    },
    {
      "epoch": 14.021323127392018,
      "grad_norm": 97.29825592041016,
      "learning_rate": 5.9786768726079825e-06,
      "loss": 0.009,
      "step": 51290
    },
    {
      "epoch": 14.024056861673046,
      "grad_norm": 0.0008600341971032321,
      "learning_rate": 5.975943138326955e-06,
      "loss": 0.0002,
      "step": 51300
    },
    {
      "epoch": 14.026790595954074,
      "grad_norm": 0.0004210560000501573,
      "learning_rate": 5.9732094040459275e-06,
      "loss": 0.0058,
      "step": 51310
    },
    {
      "epoch": 14.029524330235102,
      "grad_norm": 0.00035982660483568907,
      "learning_rate": 5.970475669764899e-06,
      "loss": 0.0,
      "step": 51320
    },
    {
      "epoch": 14.03225806451613,
      "grad_norm": 0.0009757358930073678,
      "learning_rate": 5.967741935483872e-06,
      "loss": 0.0029,
      "step": 51330
    },
    {
      "epoch": 14.034991798797156,
      "grad_norm": 1.8057756423950195,
      "learning_rate": 5.965008201202843e-06,
      "loss": 0.0052,
      "step": 51340
    },
    {
      "epoch": 14.037725533078184,
      "grad_norm": 0.0012043407186865807,
      "learning_rate": 5.962274466921816e-06,
      "loss": 0.0015,
      "step": 51350
    },
    {
      "epoch": 14.040459267359212,
      "grad_norm": 7.72881555557251,
      "learning_rate": 5.9595407326407874e-06,
      "loss": 0.029,
      "step": 51360
    },
    {
      "epoch": 14.04319300164024,
      "grad_norm": 0.0003670108562801033,
      "learning_rate": 5.95680699835976e-06,
      "loss": 0.0024,
      "step": 51370
    },
    {
      "epoch": 14.045926735921269,
      "grad_norm": 0.000812727608717978,
      "learning_rate": 5.9540732640787324e-06,
      "loss": 0.0004,
      "step": 51380
    },
    {
      "epoch": 14.048660470202297,
      "grad_norm": 0.0006709193112328649,
      "learning_rate": 5.951339529797704e-06,
      "loss": 0.0046,
      "step": 51390
    },
    {
      "epoch": 14.051394204483325,
      "grad_norm": 0.00027610460529103875,
      "learning_rate": 5.948605795516677e-06,
      "loss": 0.0018,
      "step": 51400
    },
    {
      "epoch": 14.054127938764353,
      "grad_norm": 0.00033405941212549806,
      "learning_rate": 5.945872061235648e-06,
      "loss": 0.0019,
      "step": 51410
    },
    {
      "epoch": 14.05686167304538,
      "grad_norm": 0.0003615528403315693,
      "learning_rate": 5.943138326954621e-06,
      "loss": 0.0104,
      "step": 51420
    },
    {
      "epoch": 14.059595407326407,
      "grad_norm": 0.0005941796116530895,
      "learning_rate": 5.940404592673593e-06,
      "loss": 0.0034,
      "step": 51430
    },
    {
      "epoch": 14.062329141607435,
      "grad_norm": 0.0003099842870142311,
      "learning_rate": 5.937670858392565e-06,
      "loss": 0.0483,
      "step": 51440
    },
    {
      "epoch": 14.065062875888463,
      "grad_norm": 0.0005236039287410676,
      "learning_rate": 5.934937124111537e-06,
      "loss": 0.0,
      "step": 51450
    },
    {
      "epoch": 14.067796610169491,
      "grad_norm": 0.0018818225944414735,
      "learning_rate": 5.932203389830509e-06,
      "loss": 0.0461,
      "step": 51460
    },
    {
      "epoch": 14.07053034445052,
      "grad_norm": 0.0019242027774453163,
      "learning_rate": 5.929469655549482e-06,
      "loss": 0.0128,
      "step": 51470
    },
    {
      "epoch": 14.073264078731547,
      "grad_norm": 0.0009411264327354729,
      "learning_rate": 5.926735921268452e-06,
      "loss": 0.0,
      "step": 51480
    },
    {
      "epoch": 14.075997813012576,
      "grad_norm": 0.02060556598007679,
      "learning_rate": 5.924002186987426e-06,
      "loss": 0.0002,
      "step": 51490
    },
    {
      "epoch": 14.078731547293604,
      "grad_norm": 0.0021646698005497456,
      "learning_rate": 5.921268452706398e-06,
      "loss": 0.0066,
      "step": 51500
    },
    {
      "epoch": 14.081465281574632,
      "grad_norm": 0.0003132495330646634,
      "learning_rate": 5.918534718425369e-06,
      "loss": 0.0077,
      "step": 51510
    },
    {
      "epoch": 14.084199015855658,
      "grad_norm": 0.0022524853702634573,
      "learning_rate": 5.915800984144342e-06,
      "loss": 0.1471,
      "step": 51520
    },
    {
      "epoch": 14.086932750136686,
      "grad_norm": 0.00927640125155449,
      "learning_rate": 5.913067249863313e-06,
      "loss": 0.0119,
      "step": 51530
    },
    {
      "epoch": 14.089666484417714,
      "grad_norm": 0.0017801413778215647,
      "learning_rate": 5.910333515582286e-06,
      "loss": 0.0185,
      "step": 51540
    },
    {
      "epoch": 14.092400218698742,
      "grad_norm": 0.9006448984146118,
      "learning_rate": 5.907599781301257e-06,
      "loss": 0.0061,
      "step": 51550
    },
    {
      "epoch": 14.09513395297977,
      "grad_norm": 0.5201708674430847,
      "learning_rate": 5.90486604702023e-06,
      "loss": 0.0033,
      "step": 51560
    },
    {
      "epoch": 14.097867687260798,
      "grad_norm": 0.013536498881876469,
      "learning_rate": 5.902132312739202e-06,
      "loss": 0.0018,
      "step": 51570
    },
    {
      "epoch": 14.100601421541826,
      "grad_norm": 1.1338311433792114,
      "learning_rate": 5.899398578458174e-06,
      "loss": 0.0084,
      "step": 51580
    },
    {
      "epoch": 14.103335155822855,
      "grad_norm": 0.0061312392354011536,
      "learning_rate": 5.8966648441771465e-06,
      "loss": 0.0077,
      "step": 51590
    },
    {
      "epoch": 14.106068890103883,
      "grad_norm": 0.003258153097704053,
      "learning_rate": 5.893931109896118e-06,
      "loss": 0.0101,
      "step": 51600
    },
    {
      "epoch": 14.108802624384909,
      "grad_norm": 0.003041241317987442,
      "learning_rate": 5.891197375615091e-06,
      "loss": 0.0016,
      "step": 51610
    },
    {
      "epoch": 14.111536358665937,
      "grad_norm": 0.0037283676210790873,
      "learning_rate": 5.888463641334062e-06,
      "loss": 0.0001,
      "step": 51620
    },
    {
      "epoch": 14.114270092946965,
      "grad_norm": 0.0017127596074715257,
      "learning_rate": 5.885729907053035e-06,
      "loss": 0.0093,
      "step": 51630
    },
    {
      "epoch": 14.117003827227993,
      "grad_norm": 0.0011349321575835347,
      "learning_rate": 5.882996172772007e-06,
      "loss": 0.0042,
      "step": 51640
    },
    {
      "epoch": 14.119737561509021,
      "grad_norm": 0.9749302268028259,
      "learning_rate": 5.880262438490979e-06,
      "loss": 0.0016,
      "step": 51650
    },
    {
      "epoch": 14.12247129579005,
      "grad_norm": 0.0020892240572720766,
      "learning_rate": 5.8775287042099515e-06,
      "loss": 0.0148,
      "step": 51660
    },
    {
      "epoch": 14.125205030071077,
      "grad_norm": 0.00145647709723562,
      "learning_rate": 5.874794969928923e-06,
      "loss": 0.0043,
      "step": 51670
    },
    {
      "epoch": 14.127938764352105,
      "grad_norm": 0.0006296554347500205,
      "learning_rate": 5.872061235647896e-06,
      "loss": 0.0214,
      "step": 51680
    },
    {
      "epoch": 14.130672498633134,
      "grad_norm": 0.001349725527688861,
      "learning_rate": 5.869327501366867e-06,
      "loss": 0.0006,
      "step": 51690
    },
    {
      "epoch": 14.13340623291416,
      "grad_norm": 0.0010594269260764122,
      "learning_rate": 5.86659376708584e-06,
      "loss": 0.0157,
      "step": 51700
    },
    {
      "epoch": 14.136139967195188,
      "grad_norm": 0.0122256800532341,
      "learning_rate": 5.863860032804812e-06,
      "loss": 0.0023,
      "step": 51710
    },
    {
      "epoch": 14.138873701476216,
      "grad_norm": 0.0022541568614542484,
      "learning_rate": 5.861126298523784e-06,
      "loss": 0.0026,
      "step": 51720
    },
    {
      "epoch": 14.141607435757244,
      "grad_norm": 0.018107423558831215,
      "learning_rate": 5.8583925642427565e-06,
      "loss": 0.0017,
      "step": 51730
    },
    {
      "epoch": 14.144341170038272,
      "grad_norm": 0.0018164549255743623,
      "learning_rate": 5.855658829961728e-06,
      "loss": 0.0231,
      "step": 51740
    },
    {
      "epoch": 14.1470749043193,
      "grad_norm": 0.0009296397911384702,
      "learning_rate": 5.852925095680701e-06,
      "loss": 0.0023,
      "step": 51750
    },
    {
      "epoch": 14.149808638600328,
      "grad_norm": 0.0025528103578835726,
      "learning_rate": 5.850191361399672e-06,
      "loss": 0.0265,
      "step": 51760
    },
    {
      "epoch": 14.152542372881356,
      "grad_norm": 1.864119529724121,
      "learning_rate": 5.847457627118645e-06,
      "loss": 0.0118,
      "step": 51770
    },
    {
      "epoch": 14.155276107162384,
      "grad_norm": 7.378799915313721,
      "learning_rate": 5.844723892837617e-06,
      "loss": 0.0364,
      "step": 51780
    },
    {
      "epoch": 14.158009841443413,
      "grad_norm": 1.2581236362457275,
      "learning_rate": 5.841990158556589e-06,
      "loss": 0.0034,
      "step": 51790
    },
    {
      "epoch": 14.160743575724439,
      "grad_norm": 0.0013328766217455268,
      "learning_rate": 5.8392564242755615e-06,
      "loss": 0.0068,
      "step": 51800
    },
    {
      "epoch": 14.163477310005467,
      "grad_norm": 0.000993760651908815,
      "learning_rate": 5.836522689994532e-06,
      "loss": 0.0,
      "step": 51810
    },
    {
      "epoch": 14.166211044286495,
      "grad_norm": 0.006152028683573008,
      "learning_rate": 5.833788955713506e-06,
      "loss": 0.006,
      "step": 51820
    },
    {
      "epoch": 14.168944778567523,
      "grad_norm": 0.000964032718911767,
      "learning_rate": 5.8310552214324764e-06,
      "loss": 0.0001,
      "step": 51830
    },
    {
      "epoch": 14.171678512848551,
      "grad_norm": 0.3107573091983795,
      "learning_rate": 5.828321487151449e-06,
      "loss": 0.0265,
      "step": 51840
    },
    {
      "epoch": 14.17441224712958,
      "grad_norm": 0.8801026940345764,
      "learning_rate": 5.825587752870422e-06,
      "loss": 0.0017,
      "step": 51850
    },
    {
      "epoch": 14.177145981410607,
      "grad_norm": 0.003395375795662403,
      "learning_rate": 5.822854018589393e-06,
      "loss": 0.0003,
      "step": 51860
    },
    {
      "epoch": 14.179879715691635,
      "grad_norm": 0.0012624346418306231,
      "learning_rate": 5.820120284308366e-06,
      "loss": 0.0003,
      "step": 51870
    },
    {
      "epoch": 14.182613449972663,
      "grad_norm": 0.014522136189043522,
      "learning_rate": 5.817386550027337e-06,
      "loss": 0.002,
      "step": 51880
    },
    {
      "epoch": 14.18534718425369,
      "grad_norm": 0.0013967660488560796,
      "learning_rate": 5.81465281574631e-06,
      "loss": 0.0,
      "step": 51890
    },
    {
      "epoch": 14.188080918534718,
      "grad_norm": 0.0013789191143587232,
      "learning_rate": 5.811919081465281e-06,
      "loss": 0.0051,
      "step": 51900
    },
    {
      "epoch": 14.190814652815746,
      "grad_norm": 0.0013560032239183784,
      "learning_rate": 5.809185347184254e-06,
      "loss": 0.0,
      "step": 51910
    },
    {
      "epoch": 14.193548387096774,
      "grad_norm": 0.0026337038725614548,
      "learning_rate": 5.806451612903226e-06,
      "loss": 0.0001,
      "step": 51920
    },
    {
      "epoch": 14.196282121377802,
      "grad_norm": 0.0013040867634117603,
      "learning_rate": 5.803717878622198e-06,
      "loss": 0.0093,
      "step": 51930
    },
    {
      "epoch": 14.19901585565883,
      "grad_norm": 0.0009970883838832378,
      "learning_rate": 5.800984144341171e-06,
      "loss": 0.0002,
      "step": 51940
    },
    {
      "epoch": 14.201749589939858,
      "grad_norm": 0.0009689672733657062,
      "learning_rate": 5.798250410060142e-06,
      "loss": 0.0009,
      "step": 51950
    },
    {
      "epoch": 14.204483324220886,
      "grad_norm": 0.0016298330156132579,
      "learning_rate": 5.795516675779115e-06,
      "loss": 0.0,
      "step": 51960
    },
    {
      "epoch": 14.207217058501914,
      "grad_norm": 0.09184035658836365,
      "learning_rate": 5.792782941498087e-06,
      "loss": 0.005,
      "step": 51970
    },
    {
      "epoch": 14.20995079278294,
      "grad_norm": 0.0008451634203083813,
      "learning_rate": 5.790049207217059e-06,
      "loss": 0.0012,
      "step": 51980
    },
    {
      "epoch": 14.212684527063969,
      "grad_norm": 0.0007492016302421689,
      "learning_rate": 5.787315472936031e-06,
      "loss": 0.0056,
      "step": 51990
    },
    {
      "epoch": 14.215418261344997,
      "grad_norm": 0.0004981891252100468,
      "learning_rate": 5.784581738655003e-06,
      "loss": 0.0,
      "step": 52000
    },
    {
      "epoch": 14.218151995626025,
      "grad_norm": 0.0006020787404850125,
      "learning_rate": 5.7818480043739756e-06,
      "loss": 0.0154,
      "step": 52010
    },
    {
      "epoch": 14.220885729907053,
      "grad_norm": 0.0010989278089255095,
      "learning_rate": 5.779114270092947e-06,
      "loss": 0.0,
      "step": 52020
    },
    {
      "epoch": 14.223619464188081,
      "grad_norm": 0.002639793325215578,
      "learning_rate": 5.77638053581192e-06,
      "loss": 0.0147,
      "step": 52030
    },
    {
      "epoch": 14.22635319846911,
      "grad_norm": 0.0012537080328911543,
      "learning_rate": 5.773646801530892e-06,
      "loss": 0.0391,
      "step": 52040
    },
    {
      "epoch": 14.229086932750137,
      "grad_norm": 0.0010646861046552658,
      "learning_rate": 5.770913067249864e-06,
      "loss": 0.0003,
      "step": 52050
    },
    {
      "epoch": 14.231820667031165,
      "grad_norm": 0.0016392945544794202,
      "learning_rate": 5.768179332968836e-06,
      "loss": 0.0167,
      "step": 52060
    },
    {
      "epoch": 14.234554401312192,
      "grad_norm": 0.0011504426365718246,
      "learning_rate": 5.765445598687808e-06,
      "loss": 0.0284,
      "step": 52070
    },
    {
      "epoch": 14.23728813559322,
      "grad_norm": 0.394241064786911,
      "learning_rate": 5.7627118644067805e-06,
      "loss": 0.0543,
      "step": 52080
    },
    {
      "epoch": 14.240021869874248,
      "grad_norm": 0.03281466290354729,
      "learning_rate": 5.759978130125752e-06,
      "loss": 0.0374,
      "step": 52090
    },
    {
      "epoch": 14.242755604155276,
      "grad_norm": 0.008925451897084713,
      "learning_rate": 5.757244395844725e-06,
      "loss": 0.0106,
      "step": 52100
    },
    {
      "epoch": 14.245489338436304,
      "grad_norm": 0.007434643805027008,
      "learning_rate": 5.754510661563697e-06,
      "loss": 0.0049,
      "step": 52110
    },
    {
      "epoch": 14.248223072717332,
      "grad_norm": 0.0036623519845306873,
      "learning_rate": 5.751776927282669e-06,
      "loss": 0.0052,
      "step": 52120
    },
    {
      "epoch": 14.25095680699836,
      "grad_norm": 0.00426819734275341,
      "learning_rate": 5.749043193001641e-06,
      "loss": 0.0206,
      "step": 52130
    },
    {
      "epoch": 14.253690541279388,
      "grad_norm": 0.00737746199592948,
      "learning_rate": 5.746309458720612e-06,
      "loss": 0.0089,
      "step": 52140
    },
    {
      "epoch": 14.256424275560416,
      "grad_norm": 0.00968972872942686,
      "learning_rate": 5.7435757244395855e-06,
      "loss": 0.0038,
      "step": 52150
    },
    {
      "epoch": 14.259158009841443,
      "grad_norm": 0.010946007445454597,
      "learning_rate": 5.740841990158556e-06,
      "loss": 0.013,
      "step": 52160
    },
    {
      "epoch": 14.26189174412247,
      "grad_norm": 0.006357172038406134,
      "learning_rate": 5.738108255877529e-06,
      "loss": 0.0002,
      "step": 52170
    },
    {
      "epoch": 14.264625478403499,
      "grad_norm": 0.007091904524713755,
      "learning_rate": 5.735374521596502e-06,
      "loss": 0.0111,
      "step": 52180
    },
    {
      "epoch": 14.267359212684527,
      "grad_norm": 8.995569229125977,
      "learning_rate": 5.732640787315473e-06,
      "loss": 0.0164,
      "step": 52190
    },
    {
      "epoch": 14.270092946965555,
      "grad_norm": 0.0018087435746565461,
      "learning_rate": 5.7299070530344455e-06,
      "loss": 0.0094,
      "step": 52200
    },
    {
      "epoch": 14.272826681246583,
      "grad_norm": 5.170491695404053,
      "learning_rate": 5.727173318753417e-06,
      "loss": 0.0179,
      "step": 52210
    },
    {
      "epoch": 14.275560415527611,
      "grad_norm": 0.0025182354729622602,
      "learning_rate": 5.72443958447239e-06,
      "loss": 0.0068,
      "step": 52220
    },
    {
      "epoch": 14.278294149808639,
      "grad_norm": 0.4954874515533447,
      "learning_rate": 5.721705850191361e-06,
      "loss": 0.0009,
      "step": 52230
    },
    {
      "epoch": 14.281027884089667,
      "grad_norm": 0.011417866684496403,
      "learning_rate": 5.718972115910334e-06,
      "loss": 0.0077,
      "step": 52240
    },
    {
      "epoch": 14.283761618370693,
      "grad_norm": 1.8466695547103882,
      "learning_rate": 5.716238381629306e-06,
      "loss": 0.0028,
      "step": 52250
    },
    {
      "epoch": 14.286495352651722,
      "grad_norm": 0.00055857835104689,
      "learning_rate": 5.713504647348278e-06,
      "loss": 0.0081,
      "step": 52260
    },
    {
      "epoch": 14.28922908693275,
      "grad_norm": 0.001193778240121901,
      "learning_rate": 5.7107709130672505e-06,
      "loss": 0.0045,
      "step": 52270
    },
    {
      "epoch": 14.291962821213778,
      "grad_norm": 0.001093982602469623,
      "learning_rate": 5.708037178786222e-06,
      "loss": 0.0106,
      "step": 52280
    },
    {
      "epoch": 14.294696555494806,
      "grad_norm": 1.8764374256134033,
      "learning_rate": 5.705303444505195e-06,
      "loss": 0.011,
      "step": 52290
    },
    {
      "epoch": 14.297430289775834,
      "grad_norm": 2.0144217014312744,
      "learning_rate": 5.702569710224166e-06,
      "loss": 0.0048,
      "step": 52300
    },
    {
      "epoch": 14.300164024056862,
      "grad_norm": 0.0006505237543024123,
      "learning_rate": 5.699835975943139e-06,
      "loss": 0.0047,
      "step": 52310
    },
    {
      "epoch": 14.30289775833789,
      "grad_norm": 0.0006993758725002408,
      "learning_rate": 5.697102241662111e-06,
      "loss": 0.0049,
      "step": 52320
    },
    {
      "epoch": 14.305631492618918,
      "grad_norm": 0.0012769642053171992,
      "learning_rate": 5.694368507381083e-06,
      "loss": 0.0004,
      "step": 52330
    },
    {
      "epoch": 14.308365226899946,
      "grad_norm": 2.911055564880371,
      "learning_rate": 5.6916347731000554e-06,
      "loss": 0.008,
      "step": 52340
    },
    {
      "epoch": 14.311098961180972,
      "grad_norm": 0.0003728052834048867,
      "learning_rate": 5.688901038819027e-06,
      "loss": 0.0203,
      "step": 52350
    },
    {
      "epoch": 14.313832695462,
      "grad_norm": 0.0014932826161384583,
      "learning_rate": 5.686167304538e-06,
      "loss": 0.0004,
      "step": 52360
    },
    {
      "epoch": 14.316566429743029,
      "grad_norm": 1.5478864908218384,
      "learning_rate": 5.683433570256971e-06,
      "loss": 0.0184,
      "step": 52370
    },
    {
      "epoch": 14.319300164024057,
      "grad_norm": 0.00031597918132320046,
      "learning_rate": 5.680699835975944e-06,
      "loss": 0.0016,
      "step": 52380
    },
    {
      "epoch": 14.322033898305085,
      "grad_norm": 0.0008487198501825333,
      "learning_rate": 5.677966101694916e-06,
      "loss": 0.0022,
      "step": 52390
    },
    {
      "epoch": 14.324767632586113,
      "grad_norm": 2.4369332790374756,
      "learning_rate": 5.675232367413888e-06,
      "loss": 0.0182,
      "step": 52400
    },
    {
      "epoch": 14.327501366867141,
      "grad_norm": 0.9000225067138672,
      "learning_rate": 5.67249863313286e-06,
      "loss": 0.0213,
      "step": 52410
    },
    {
      "epoch": 14.330235101148169,
      "grad_norm": 0.00045736352331005037,
      "learning_rate": 5.669764898851832e-06,
      "loss": 0.0001,
      "step": 52420
    },
    {
      "epoch": 14.332968835429197,
      "grad_norm": 0.002746997633948922,
      "learning_rate": 5.667031164570805e-06,
      "loss": 0.0041,
      "step": 52430
    },
    {
      "epoch": 14.335702569710223,
      "grad_norm": 0.0032549018505960703,
      "learning_rate": 5.664297430289775e-06,
      "loss": 0.0137,
      "step": 52440
    },
    {
      "epoch": 14.338436303991251,
      "grad_norm": 1.8657852411270142,
      "learning_rate": 5.661563696008749e-06,
      "loss": 0.0108,
      "step": 52450
    },
    {
      "epoch": 14.34117003827228,
      "grad_norm": 0.8073842525482178,
      "learning_rate": 5.658829961727721e-06,
      "loss": 0.0145,
      "step": 52460
    },
    {
      "epoch": 14.343903772553308,
      "grad_norm": 0.3399713337421417,
      "learning_rate": 5.656096227446692e-06,
      "loss": 0.0193,
      "step": 52470
    },
    {
      "epoch": 14.346637506834336,
      "grad_norm": 0.03276519104838371,
      "learning_rate": 5.653362493165665e-06,
      "loss": 0.0,
      "step": 52480
    },
    {
      "epoch": 14.349371241115364,
      "grad_norm": 0.040667176246643066,
      "learning_rate": 5.650628758884636e-06,
      "loss": 0.003,
      "step": 52490
    },
    {
      "epoch": 14.352104975396392,
      "grad_norm": 0.00048221921315416694,
      "learning_rate": 5.647895024603609e-06,
      "loss": 0.0035,
      "step": 52500
    },
    {
      "epoch": 14.35483870967742,
      "grad_norm": 0.0008624345646239817,
      "learning_rate": 5.645161290322582e-06,
      "loss": 0.0,
      "step": 52510
    },
    {
      "epoch": 14.357572443958448,
      "grad_norm": 0.0030713428277522326,
      "learning_rate": 5.642427556041553e-06,
      "loss": 0.0028,
      "step": 52520
    },
    {
      "epoch": 14.360306178239474,
      "grad_norm": 0.0007920606294646859,
      "learning_rate": 5.639693821760525e-06,
      "loss": 0.0001,
      "step": 52530
    },
    {
      "epoch": 14.363039912520502,
      "grad_norm": 1.4454492330551147,
      "learning_rate": 5.636960087479497e-06,
      "loss": 0.0256,
      "step": 52540
    },
    {
      "epoch": 14.36577364680153,
      "grad_norm": 0.00556885777041316,
      "learning_rate": 5.6342263531984695e-06,
      "loss": 0.0096,
      "step": 52550
    },
    {
      "epoch": 14.368507381082559,
      "grad_norm": 0.000814957485999912,
      "learning_rate": 5.631492618917441e-06,
      "loss": 0.0035,
      "step": 52560
    },
    {
      "epoch": 14.371241115363587,
      "grad_norm": 0.0006168599356897175,
      "learning_rate": 5.628758884636414e-06,
      "loss": 0.0054,
      "step": 52570
    },
    {
      "epoch": 14.373974849644615,
      "grad_norm": 0.0010261250426992774,
      "learning_rate": 5.626025150355386e-06,
      "loss": 0.0152,
      "step": 52580
    },
    {
      "epoch": 14.376708583925643,
      "grad_norm": 0.009738867171108723,
      "learning_rate": 5.623291416074358e-06,
      "loss": 0.0061,
      "step": 52590
    },
    {
      "epoch": 14.37944231820667,
      "grad_norm": 0.0005833717295899987,
      "learning_rate": 5.62055768179333e-06,
      "loss": 0.0075,
      "step": 52600
    },
    {
      "epoch": 14.382176052487699,
      "grad_norm": 0.0002859971427824348,
      "learning_rate": 5.617823947512302e-06,
      "loss": 0.0,
      "step": 52610
    },
    {
      "epoch": 14.384909786768725,
      "grad_norm": 0.007793402764946222,
      "learning_rate": 5.6150902132312745e-06,
      "loss": 0.0009,
      "step": 52620
    },
    {
      "epoch": 14.387643521049753,
      "grad_norm": 0.0005686069489456713,
      "learning_rate": 5.612356478950246e-06,
      "loss": 0.0075,
      "step": 52630
    },
    {
      "epoch": 14.390377255330781,
      "grad_norm": 0.0002975683310069144,
      "learning_rate": 5.609622744669219e-06,
      "loss": 0.0076,
      "step": 52640
    },
    {
      "epoch": 14.39311098961181,
      "grad_norm": 0.0009980748873203993,
      "learning_rate": 5.606889010388191e-06,
      "loss": 0.0036,
      "step": 52650
    },
    {
      "epoch": 14.395844723892838,
      "grad_norm": 0.00022680277470499277,
      "learning_rate": 5.604155276107163e-06,
      "loss": 0.0094,
      "step": 52660
    },
    {
      "epoch": 14.398578458173866,
      "grad_norm": 0.0005996773252263665,
      "learning_rate": 5.601421541826135e-06,
      "loss": 0.0015,
      "step": 52670
    },
    {
      "epoch": 14.401312192454894,
      "grad_norm": 0.0005785429384559393,
      "learning_rate": 5.598687807545107e-06,
      "loss": 0.0136,
      "step": 52680
    },
    {
      "epoch": 14.404045926735922,
      "grad_norm": 0.0005054433713667095,
      "learning_rate": 5.5959540732640795e-06,
      "loss": 0.0,
      "step": 52690
    },
    {
      "epoch": 14.40677966101695,
      "grad_norm": 0.0005648431251756847,
      "learning_rate": 5.593220338983051e-06,
      "loss": 0.0,
      "step": 52700
    },
    {
      "epoch": 14.409513395297978,
      "grad_norm": 0.0020731871481984854,
      "learning_rate": 5.590486604702024e-06,
      "loss": 0.0024,
      "step": 52710
    },
    {
      "epoch": 14.412247129579004,
      "grad_norm": 0.0001697511615930125,
      "learning_rate": 5.587752870420996e-06,
      "loss": 0.0066,
      "step": 52720
    },
    {
      "epoch": 14.414980863860032,
      "grad_norm": 0.6395847201347351,
      "learning_rate": 5.585019136139968e-06,
      "loss": 0.0011,
      "step": 52730
    },
    {
      "epoch": 14.41771459814106,
      "grad_norm": 0.0006454457761719823,
      "learning_rate": 5.58228540185894e-06,
      "loss": 0.0,
      "step": 52740
    },
    {
      "epoch": 14.420448332422088,
      "grad_norm": 0.0003547531960066408,
      "learning_rate": 5.579551667577912e-06,
      "loss": 0.0,
      "step": 52750
    },
    {
      "epoch": 14.423182066703117,
      "grad_norm": 0.00022115914907772094,
      "learning_rate": 5.5768179332968845e-06,
      "loss": 0.0012,
      "step": 52760
    },
    {
      "epoch": 14.425915800984145,
      "grad_norm": 0.0004714859533123672,
      "learning_rate": 5.574084199015855e-06,
      "loss": 0.0,
      "step": 52770
    },
    {
      "epoch": 14.428649535265173,
      "grad_norm": 0.0007444981602020562,
      "learning_rate": 5.571350464734829e-06,
      "loss": 0.0607,
      "step": 52780
    },
    {
      "epoch": 14.4313832695462,
      "grad_norm": 0.00023816987231839448,
      "learning_rate": 5.568616730453801e-06,
      "loss": 0.0007,
      "step": 52790
    },
    {
      "epoch": 14.434117003827229,
      "grad_norm": 0.0008442960097454488,
      "learning_rate": 5.565882996172772e-06,
      "loss": 0.0018,
      "step": 52800
    },
    {
      "epoch": 14.436850738108255,
      "grad_norm": 0.0009110388346016407,
      "learning_rate": 5.563149261891745e-06,
      "loss": 0.0,
      "step": 52810
    },
    {
      "epoch": 14.439584472389283,
      "grad_norm": 0.001024486031383276,
      "learning_rate": 5.560415527610716e-06,
      "loss": 0.0123,
      "step": 52820
    },
    {
      "epoch": 14.442318206670311,
      "grad_norm": 1.9403178691864014,
      "learning_rate": 5.557681793329689e-06,
      "loss": 0.0094,
      "step": 52830
    },
    {
      "epoch": 14.44505194095134,
      "grad_norm": 0.0011680558091029525,
      "learning_rate": 5.55494805904866e-06,
      "loss": 0.0064,
      "step": 52840
    },
    {
      "epoch": 14.447785675232367,
      "grad_norm": 0.0006653215386904776,
      "learning_rate": 5.552214324767633e-06,
      "loss": 0.0037,
      "step": 52850
    },
    {
      "epoch": 14.450519409513396,
      "grad_norm": 0.0004969065194018185,
      "learning_rate": 5.549480590486605e-06,
      "loss": 0.004,
      "step": 52860
    },
    {
      "epoch": 14.453253143794424,
      "grad_norm": 0.0006324943387880921,
      "learning_rate": 5.546746856205577e-06,
      "loss": 0.0091,
      "step": 52870
    },
    {
      "epoch": 14.455986878075452,
      "grad_norm": 0.00043131591519340873,
      "learning_rate": 5.544013121924549e-06,
      "loss": 0.0,
      "step": 52880
    },
    {
      "epoch": 14.45872061235648,
      "grad_norm": 0.0006850256468169391,
      "learning_rate": 5.541279387643521e-06,
      "loss": 0.0045,
      "step": 52890
    },
    {
      "epoch": 14.461454346637506,
      "grad_norm": 0.006689145229756832,
      "learning_rate": 5.538545653362494e-06,
      "loss": 0.0129,
      "step": 52900
    },
    {
      "epoch": 14.464188080918534,
      "grad_norm": 0.0005661458126269281,
      "learning_rate": 5.535811919081465e-06,
      "loss": 0.0,
      "step": 52910
    },
    {
      "epoch": 14.466921815199562,
      "grad_norm": 0.0023040594533085823,
      "learning_rate": 5.533078184800438e-06,
      "loss": 0.0001,
      "step": 52920
    },
    {
      "epoch": 14.46965554948059,
      "grad_norm": 0.006574433296918869,
      "learning_rate": 5.53034445051941e-06,
      "loss": 0.006,
      "step": 52930
    },
    {
      "epoch": 14.472389283761618,
      "grad_norm": 0.00864850077778101,
      "learning_rate": 5.527610716238382e-06,
      "loss": 0.004,
      "step": 52940
    },
    {
      "epoch": 14.475123018042646,
      "grad_norm": 0.0005244851927272975,
      "learning_rate": 5.524876981957354e-06,
      "loss": 0.0042,
      "step": 52950
    },
    {
      "epoch": 14.477856752323675,
      "grad_norm": 0.00018047055345959961,
      "learning_rate": 5.522143247676326e-06,
      "loss": 0.0001,
      "step": 52960
    },
    {
      "epoch": 14.480590486604703,
      "grad_norm": 0.0008289393153972924,
      "learning_rate": 5.5194095133952986e-06,
      "loss": 0.0,
      "step": 52970
    },
    {
      "epoch": 14.48332422088573,
      "grad_norm": 0.0004970591980963945,
      "learning_rate": 5.51667577911427e-06,
      "loss": 0.0447,
      "step": 52980
    },
    {
      "epoch": 14.486057955166757,
      "grad_norm": 0.0010041166096925735,
      "learning_rate": 5.513942044833243e-06,
      "loss": 0.0085,
      "step": 52990
    },
    {
      "epoch": 14.488791689447785,
      "grad_norm": 0.0017616166733205318,
      "learning_rate": 5.511208310552215e-06,
      "loss": 0.003,
      "step": 53000
    },
    {
      "epoch": 14.491525423728813,
      "grad_norm": 0.4726128578186035,
      "learning_rate": 5.508474576271187e-06,
      "loss": 0.0009,
      "step": 53010
    },
    {
      "epoch": 14.494259158009841,
      "grad_norm": 0.0008506859885528684,
      "learning_rate": 5.505740841990159e-06,
      "loss": 0.0003,
      "step": 53020
    },
    {
      "epoch": 14.49699289229087,
      "grad_norm": 0.0014783149817958474,
      "learning_rate": 5.503007107709131e-06,
      "loss": 0.0041,
      "step": 53030
    },
    {
      "epoch": 14.499726626571897,
      "grad_norm": 0.2629426121711731,
      "learning_rate": 5.5002733734281035e-06,
      "loss": 0.0005,
      "step": 53040
    },
    {
      "epoch": 14.502460360852925,
      "grad_norm": 0.9515926837921143,
      "learning_rate": 5.497539639147076e-06,
      "loss": 0.0041,
      "step": 53050
    },
    {
      "epoch": 14.505194095133954,
      "grad_norm": 0.0005659274174831808,
      "learning_rate": 5.494805904866048e-06,
      "loss": 0.0034,
      "step": 53060
    },
    {
      "epoch": 14.507927829414982,
      "grad_norm": 0.0004043607332278043,
      "learning_rate": 5.49207217058502e-06,
      "loss": 0.0121,
      "step": 53070
    },
    {
      "epoch": 14.510661563696008,
      "grad_norm": 2.476013422012329,
      "learning_rate": 5.489338436303992e-06,
      "loss": 0.0146,
      "step": 53080
    },
    {
      "epoch": 14.513395297977036,
      "grad_norm": 0.0006812333595007658,
      "learning_rate": 5.486604702022964e-06,
      "loss": 0.0001,
      "step": 53090
    },
    {
      "epoch": 14.516129032258064,
      "grad_norm": 0.006814110092818737,
      "learning_rate": 5.483870967741935e-06,
      "loss": 0.0,
      "step": 53100
    },
    {
      "epoch": 14.518862766539092,
      "grad_norm": 0.0026441304944455624,
      "learning_rate": 5.481137233460908e-06,
      "loss": 0.0001,
      "step": 53110
    },
    {
      "epoch": 14.52159650082012,
      "grad_norm": 0.005365596152842045,
      "learning_rate": 5.478403499179881e-06,
      "loss": 0.004,
      "step": 53120
    },
    {
      "epoch": 14.524330235101148,
      "grad_norm": 0.0009034404647536576,
      "learning_rate": 5.475669764898852e-06,
      "loss": 0.0212,
      "step": 53130
    },
    {
      "epoch": 14.527063969382176,
      "grad_norm": 0.0010887521784752607,
      "learning_rate": 5.472936030617824e-06,
      "loss": 0.0075,
      "step": 53140
    },
    {
      "epoch": 14.529797703663204,
      "grad_norm": 0.0003154840669594705,
      "learning_rate": 5.470202296336796e-06,
      "loss": 0.0077,
      "step": 53150
    },
    {
      "epoch": 14.532531437944233,
      "grad_norm": 0.0007121313828974962,
      "learning_rate": 5.4674685620557685e-06,
      "loss": 0.0289,
      "step": 53160
    },
    {
      "epoch": 14.535265172225259,
      "grad_norm": 0.6786808371543884,
      "learning_rate": 5.46473482777474e-06,
      "loss": 0.0332,
      "step": 53170
    },
    {
      "epoch": 14.537998906506287,
      "grad_norm": 0.0010649291798472404,
      "learning_rate": 5.462001093493713e-06,
      "loss": 0.0016,
      "step": 53180
    },
    {
      "epoch": 14.540732640787315,
      "grad_norm": 0.00526441540569067,
      "learning_rate": 5.459267359212685e-06,
      "loss": 0.0023,
      "step": 53190
    },
    {
      "epoch": 14.543466375068343,
      "grad_norm": 0.003375316970050335,
      "learning_rate": 5.456533624931657e-06,
      "loss": 0.0,
      "step": 53200
    },
    {
      "epoch": 14.546200109349371,
      "grad_norm": 1.336315631866455,
      "learning_rate": 5.453799890650629e-06,
      "loss": 0.0132,
      "step": 53210
    },
    {
      "epoch": 14.5489338436304,
      "grad_norm": 0.004297803621739149,
      "learning_rate": 5.451066156369601e-06,
      "loss": 0.0455,
      "step": 53220
    },
    {
      "epoch": 14.551667577911427,
      "grad_norm": 0.0005289202090352774,
      "learning_rate": 5.4483324220885735e-06,
      "loss": 0.0212,
      "step": 53230
    },
    {
      "epoch": 14.554401312192455,
      "grad_norm": 0.062336504459381104,
      "learning_rate": 5.445598687807545e-06,
      "loss": 0.0173,
      "step": 53240
    },
    {
      "epoch": 14.557135046473483,
      "grad_norm": 0.0010422334307804704,
      "learning_rate": 5.442864953526518e-06,
      "loss": 0.0162,
      "step": 53250
    },
    {
      "epoch": 14.55986878075451,
      "grad_norm": 0.002109594875946641,
      "learning_rate": 5.44013121924549e-06,
      "loss": 0.0153,
      "step": 53260
    },
    {
      "epoch": 14.562602515035538,
      "grad_norm": 0.0004554003244265914,
      "learning_rate": 5.437397484964462e-06,
      "loss": 0.0049,
      "step": 53270
    },
    {
      "epoch": 14.565336249316566,
      "grad_norm": 0.0008202983881346881,
      "learning_rate": 5.434663750683434e-06,
      "loss": 0.0009,
      "step": 53280
    },
    {
      "epoch": 14.568069983597594,
      "grad_norm": 0.0011737633030861616,
      "learning_rate": 5.431930016402406e-06,
      "loss": 0.0036,
      "step": 53290
    },
    {
      "epoch": 14.570803717878622,
      "grad_norm": 0.0016519707860425115,
      "learning_rate": 5.4291962821213784e-06,
      "loss": 0.0127,
      "step": 53300
    },
    {
      "epoch": 14.57353745215965,
      "grad_norm": 0.0008472564513795078,
      "learning_rate": 5.42646254784035e-06,
      "loss": 0.0,
      "step": 53310
    },
    {
      "epoch": 14.576271186440678,
      "grad_norm": 0.0007453038124367595,
      "learning_rate": 5.423728813559323e-06,
      "loss": 0.0411,
      "step": 53320
    },
    {
      "epoch": 14.579004920721706,
      "grad_norm": 0.5374210476875305,
      "learning_rate": 5.420995079278295e-06,
      "loss": 0.0053,
      "step": 53330
    },
    {
      "epoch": 14.581738655002734,
      "grad_norm": 0.01252097450196743,
      "learning_rate": 5.418261344997267e-06,
      "loss": 0.0002,
      "step": 53340
    },
    {
      "epoch": 14.584472389283762,
      "grad_norm": 0.0023246980272233486,
      "learning_rate": 5.415527610716239e-06,
      "loss": 0.0001,
      "step": 53350
    },
    {
      "epoch": 14.587206123564789,
      "grad_norm": 0.8908898234367371,
      "learning_rate": 5.412793876435211e-06,
      "loss": 0.0063,
      "step": 53360
    },
    {
      "epoch": 14.589939857845817,
      "grad_norm": 0.7662628889083862,
      "learning_rate": 5.4100601421541834e-06,
      "loss": 0.0445,
      "step": 53370
    },
    {
      "epoch": 14.592673592126845,
      "grad_norm": 0.001799152116291225,
      "learning_rate": 5.407326407873155e-06,
      "loss": 0.0292,
      "step": 53380
    },
    {
      "epoch": 14.595407326407873,
      "grad_norm": 0.002789622638374567,
      "learning_rate": 5.404592673592128e-06,
      "loss": 0.0018,
      "step": 53390
    },
    {
      "epoch": 14.598141060688901,
      "grad_norm": 0.002913515781983733,
      "learning_rate": 5.4018589393111e-06,
      "loss": 0.0373,
      "step": 53400
    },
    {
      "epoch": 14.60087479496993,
      "grad_norm": 1.4640146493911743,
      "learning_rate": 5.399125205030071e-06,
      "loss": 0.0054,
      "step": 53410
    },
    {
      "epoch": 14.603608529250957,
      "grad_norm": 0.004147234372794628,
      "learning_rate": 5.396391470749044e-06,
      "loss": 0.0122,
      "step": 53420
    },
    {
      "epoch": 14.606342263531985,
      "grad_norm": 0.0012457058764994144,
      "learning_rate": 5.393657736468015e-06,
      "loss": 0.0288,
      "step": 53430
    },
    {
      "epoch": 14.609075997813013,
      "grad_norm": 0.00320371612906456,
      "learning_rate": 5.3909240021869876e-06,
      "loss": 0.0001,
      "step": 53440
    },
    {
      "epoch": 14.61180973209404,
      "grad_norm": 0.031739793717861176,
      "learning_rate": 5.388190267905959e-06,
      "loss": 0.0121,
      "step": 53450
    },
    {
      "epoch": 14.614543466375068,
      "grad_norm": 0.4636547565460205,
      "learning_rate": 5.385456533624932e-06,
      "loss": 0.0092,
      "step": 53460
    },
    {
      "epoch": 14.617277200656096,
      "grad_norm": 0.006179815158247948,
      "learning_rate": 5.382722799343904e-06,
      "loss": 0.0058,
      "step": 53470
    },
    {
      "epoch": 14.620010934937124,
      "grad_norm": 0.0017389535205438733,
      "learning_rate": 5.379989065062876e-06,
      "loss": 0.0001,
      "step": 53480
    },
    {
      "epoch": 14.622744669218152,
      "grad_norm": 0.0033547619823366404,
      "learning_rate": 5.377255330781848e-06,
      "loss": 0.0006,
      "step": 53490
    },
    {
      "epoch": 14.62547840349918,
      "grad_norm": 0.030767401680350304,
      "learning_rate": 5.37452159650082e-06,
      "loss": 0.0012,
      "step": 53500
    },
    {
      "epoch": 14.628212137780208,
      "grad_norm": 0.0013448146637529135,
      "learning_rate": 5.3717878622197925e-06,
      "loss": 0.0134,
      "step": 53510
    },
    {
      "epoch": 14.630945872061236,
      "grad_norm": 0.0005760710337199271,
      "learning_rate": 5.369054127938764e-06,
      "loss": 0.0014,
      "step": 53520
    },
    {
      "epoch": 14.633679606342264,
      "grad_norm": 0.001594823901541531,
      "learning_rate": 5.366320393657737e-06,
      "loss": 0.0013,
      "step": 53530
    },
    {
      "epoch": 14.636413340623292,
      "grad_norm": 0.9521352052688599,
      "learning_rate": 5.363586659376709e-06,
      "loss": 0.0248,
      "step": 53540
    },
    {
      "epoch": 14.639147074904319,
      "grad_norm": 0.0012756678042933345,
      "learning_rate": 5.360852925095681e-06,
      "loss": 0.0076,
      "step": 53550
    },
    {
      "epoch": 14.641880809185347,
      "grad_norm": 0.026430942118167877,
      "learning_rate": 5.358119190814653e-06,
      "loss": 0.0033,
      "step": 53560
    },
    {
      "epoch": 14.644614543466375,
      "grad_norm": 0.002987670013681054,
      "learning_rate": 5.355385456533625e-06,
      "loss": 0.0001,
      "step": 53570
    },
    {
      "epoch": 14.647348277747403,
      "grad_norm": 0.0012374419020488858,
      "learning_rate": 5.3526517222525975e-06,
      "loss": 0.0001,
      "step": 53580
    },
    {
      "epoch": 14.650082012028431,
      "grad_norm": 0.0023053681943565607,
      "learning_rate": 5.34991798797157e-06,
      "loss": 0.0115,
      "step": 53590
    },
    {
      "epoch": 14.652815746309459,
      "grad_norm": 0.002017960185185075,
      "learning_rate": 5.347184253690542e-06,
      "loss": 0.008,
      "step": 53600
    },
    {
      "epoch": 14.655549480590487,
      "grad_norm": 0.001713292789645493,
      "learning_rate": 5.344450519409514e-06,
      "loss": 0.0125,
      "step": 53610
    },
    {
      "epoch": 14.658283214871515,
      "grad_norm": 0.0065575153566896915,
      "learning_rate": 5.341716785128486e-06,
      "loss": 0.004,
      "step": 53620
    },
    {
      "epoch": 14.661016949152543,
      "grad_norm": 0.0010410503018647432,
      "learning_rate": 5.338983050847458e-06,
      "loss": 0.0062,
      "step": 53630
    },
    {
      "epoch": 14.66375068343357,
      "grad_norm": 0.008784762583673,
      "learning_rate": 5.33624931656643e-06,
      "loss": 0.0027,
      "step": 53640
    },
    {
      "epoch": 14.666484417714598,
      "grad_norm": 0.001129940152168274,
      "learning_rate": 5.3335155822854025e-06,
      "loss": 0.0051,
      "step": 53650
    },
    {
      "epoch": 14.669218151995626,
      "grad_norm": 0.006749443709850311,
      "learning_rate": 5.330781848004375e-06,
      "loss": 0.0046,
      "step": 53660
    },
    {
      "epoch": 14.671951886276654,
      "grad_norm": 0.02713545225560665,
      "learning_rate": 5.328048113723347e-06,
      "loss": 0.0072,
      "step": 53670
    },
    {
      "epoch": 14.674685620557682,
      "grad_norm": 1.8960670232772827,
      "learning_rate": 5.325314379442319e-06,
      "loss": 0.0198,
      "step": 53680
    },
    {
      "epoch": 14.67741935483871,
      "grad_norm": 0.0006683381507173181,
      "learning_rate": 5.322580645161291e-06,
      "loss": 0.0087,
      "step": 53690
    },
    {
      "epoch": 14.680153089119738,
      "grad_norm": 0.0027725324034690857,
      "learning_rate": 5.319846910880263e-06,
      "loss": 0.0052,
      "step": 53700
    },
    {
      "epoch": 14.682886823400766,
      "grad_norm": 0.0013065803796052933,
      "learning_rate": 5.317113176599234e-06,
      "loss": 0.0112,
      "step": 53710
    },
    {
      "epoch": 14.685620557681794,
      "grad_norm": 0.309343159198761,
      "learning_rate": 5.3143794423182075e-06,
      "loss": 0.0009,
      "step": 53720
    },
    {
      "epoch": 14.68835429196282,
      "grad_norm": 0.0012339269742369652,
      "learning_rate": 5.31164570803718e-06,
      "loss": 0.0045,
      "step": 53730
    },
    {
      "epoch": 14.691088026243849,
      "grad_norm": 0.1932523250579834,
      "learning_rate": 5.308911973756151e-06,
      "loss": 0.003,
      "step": 53740
    },
    {
      "epoch": 14.693821760524877,
      "grad_norm": 0.0006611424614675343,
      "learning_rate": 5.306178239475124e-06,
      "loss": 0.0019,
      "step": 53750
    },
    {
      "epoch": 14.696555494805905,
      "grad_norm": 0.00022072023421060294,
      "learning_rate": 5.303444505194095e-06,
      "loss": 0.0,
      "step": 53760
    },
    {
      "epoch": 14.699289229086933,
      "grad_norm": 0.0006660001236014068,
      "learning_rate": 5.3007107709130674e-06,
      "loss": 0.004,
      "step": 53770
    },
    {
      "epoch": 14.70202296336796,
      "grad_norm": 0.0019233908969908953,
      "learning_rate": 5.297977036632039e-06,
      "loss": 0.012,
      "step": 53780
    },
    {
      "epoch": 14.704756697648989,
      "grad_norm": 0.0006988914683461189,
      "learning_rate": 5.295243302351012e-06,
      "loss": 0.0001,
      "step": 53790
    },
    {
      "epoch": 14.707490431930017,
      "grad_norm": 1.0678913593292236,
      "learning_rate": 5.292509568069984e-06,
      "loss": 0.0422,
      "step": 53800
    },
    {
      "epoch": 14.710224166211045,
      "grad_norm": 1.5401338338851929,
      "learning_rate": 5.289775833788956e-06,
      "loss": 0.0031,
      "step": 53810
    },
    {
      "epoch": 14.712957900492071,
      "grad_norm": 0.013962112367153168,
      "learning_rate": 5.287042099507928e-06,
      "loss": 0.0112,
      "step": 53820
    },
    {
      "epoch": 14.7156916347731,
      "grad_norm": 0.4493432939052582,
      "learning_rate": 5.2843083652269e-06,
      "loss": 0.0105,
      "step": 53830
    },
    {
      "epoch": 14.718425369054128,
      "grad_norm": 0.0021756088826805353,
      "learning_rate": 5.2815746309458724e-06,
      "loss": 0.0048,
      "step": 53840
    },
    {
      "epoch": 14.721159103335156,
      "grad_norm": 0.279187947511673,
      "learning_rate": 5.278840896664844e-06,
      "loss": 0.0049,
      "step": 53850
    },
    {
      "epoch": 14.723892837616184,
      "grad_norm": 1.8023909330368042,
      "learning_rate": 5.276107162383817e-06,
      "loss": 0.0087,
      "step": 53860
    },
    {
      "epoch": 14.726626571897212,
      "grad_norm": 0.0004996221396140754,
      "learning_rate": 5.273373428102789e-06,
      "loss": 0.0008,
      "step": 53870
    },
    {
      "epoch": 14.72936030617824,
      "grad_norm": 0.006852572783827782,
      "learning_rate": 5.270639693821761e-06,
      "loss": 0.0123,
      "step": 53880
    },
    {
      "epoch": 14.732094040459268,
      "grad_norm": 0.01009769644588232,
      "learning_rate": 5.267905959540733e-06,
      "loss": 0.0053,
      "step": 53890
    },
    {
      "epoch": 14.734827774740296,
      "grad_norm": 0.003925994038581848,
      "learning_rate": 5.265172225259705e-06,
      "loss": 0.0018,
      "step": 53900
    },
    {
      "epoch": 14.737561509021322,
      "grad_norm": 0.08455472439527512,
      "learning_rate": 5.262438490978677e-06,
      "loss": 0.0005,
      "step": 53910
    },
    {
      "epoch": 14.74029524330235,
      "grad_norm": 0.888455331325531,
      "learning_rate": 5.259704756697649e-06,
      "loss": 0.0054,
      "step": 53920
    },
    {
      "epoch": 14.743028977583378,
      "grad_norm": 0.0009237310732714832,
      "learning_rate": 5.2569710224166216e-06,
      "loss": 0.0113,
      "step": 53930
    },
    {
      "epoch": 14.745762711864407,
      "grad_norm": 0.01855899952352047,
      "learning_rate": 5.254237288135594e-06,
      "loss": 0.0066,
      "step": 53940
    },
    {
      "epoch": 14.748496446145435,
      "grad_norm": 0.00198771758005023,
      "learning_rate": 5.251503553854566e-06,
      "loss": 0.0129,
      "step": 53950
    },
    {
      "epoch": 14.751230180426463,
      "grad_norm": 0.002951613161712885,
      "learning_rate": 5.248769819573538e-06,
      "loss": 0.0001,
      "step": 53960
    },
    {
      "epoch": 14.75396391470749,
      "grad_norm": 0.0027672683354467154,
      "learning_rate": 5.24603608529251e-06,
      "loss": 0.0,
      "step": 53970
    },
    {
      "epoch": 14.756697648988519,
      "grad_norm": 0.0031555292662233114,
      "learning_rate": 5.243302351011482e-06,
      "loss": 0.0001,
      "step": 53980
    },
    {
      "epoch": 14.759431383269547,
      "grad_norm": 0.07612846046686172,
      "learning_rate": 5.240568616730454e-06,
      "loss": 0.0038,
      "step": 53990
    },
    {
      "epoch": 14.762165117550573,
      "grad_norm": 0.0001822615449782461,
      "learning_rate": 5.2378348824494265e-06,
      "loss": 0.0021,
      "step": 54000
    },
    {
      "epoch": 14.764898851831601,
      "grad_norm": 0.0009061213932000101,
      "learning_rate": 5.235101148168399e-06,
      "loss": 0.005,
      "step": 54010
    },
    {
      "epoch": 14.76763258611263,
      "grad_norm": 0.3391561806201935,
      "learning_rate": 5.232367413887371e-06,
      "loss": 0.0137,
      "step": 54020
    },
    {
      "epoch": 14.770366320393657,
      "grad_norm": 0.0009201630018651485,
      "learning_rate": 5.229633679606343e-06,
      "loss": 0.0,
      "step": 54030
    },
    {
      "epoch": 14.773100054674686,
      "grad_norm": 0.0014251784887164831,
      "learning_rate": 5.226899945325314e-06,
      "loss": 0.0052,
      "step": 54040
    },
    {
      "epoch": 14.775833788955714,
      "grad_norm": 0.00040353057556785643,
      "learning_rate": 5.224166211044287e-06,
      "loss": 0.0,
      "step": 54050
    },
    {
      "epoch": 14.778567523236742,
      "grad_norm": 0.0005606155027635396,
      "learning_rate": 5.221432476763258e-06,
      "loss": 0.0108,
      "step": 54060
    },
    {
      "epoch": 14.78130125751777,
      "grad_norm": 0.00047660744166933,
      "learning_rate": 5.218698742482231e-06,
      "loss": 0.0002,
      "step": 54070
    },
    {
      "epoch": 14.784034991798798,
      "grad_norm": 0.0005338419578038156,
      "learning_rate": 5.215965008201204e-06,
      "loss": 0.0049,
      "step": 54080
    },
    {
      "epoch": 14.786768726079824,
      "grad_norm": 0.00042914890218526125,
      "learning_rate": 5.213231273920175e-06,
      "loss": 0.0029,
      "step": 54090
    },
    {
      "epoch": 14.789502460360852,
      "grad_norm": 0.0004338403232395649,
      "learning_rate": 5.210497539639147e-06,
      "loss": 0.0021,
      "step": 54100
    },
    {
      "epoch": 14.79223619464188,
      "grad_norm": 0.0001968715660041198,
      "learning_rate": 5.207763805358119e-06,
      "loss": 0.0102,
      "step": 54110
    },
    {
      "epoch": 14.794969928922908,
      "grad_norm": 0.0001709251810098067,
      "learning_rate": 5.2050300710770915e-06,
      "loss": 0.0096,
      "step": 54120
    },
    {
      "epoch": 14.797703663203936,
      "grad_norm": 0.0005330637795850635,
      "learning_rate": 5.202296336796064e-06,
      "loss": 0.0182,
      "step": 54130
    },
    {
      "epoch": 14.800437397484965,
      "grad_norm": 0.009098361246287823,
      "learning_rate": 5.199562602515036e-06,
      "loss": 0.0074,
      "step": 54140
    },
    {
      "epoch": 14.803171131765993,
      "grad_norm": 1.2348922491073608,
      "learning_rate": 5.196828868234008e-06,
      "loss": 0.0117,
      "step": 54150
    },
    {
      "epoch": 14.80590486604702,
      "grad_norm": 1.2024027109146118,
      "learning_rate": 5.19409513395298e-06,
      "loss": 0.008,
      "step": 54160
    },
    {
      "epoch": 14.808638600328049,
      "grad_norm": 0.0003867640916723758,
      "learning_rate": 5.191361399671952e-06,
      "loss": 0.0017,
      "step": 54170
    },
    {
      "epoch": 14.811372334609075,
      "grad_norm": 0.00022545309911947697,
      "learning_rate": 5.188627665390924e-06,
      "loss": 0.0001,
      "step": 54180
    },
    {
      "epoch": 14.814106068890103,
      "grad_norm": 1.0982520580291748,
      "learning_rate": 5.1858939311098965e-06,
      "loss": 0.0086,
      "step": 54190
    },
    {
      "epoch": 14.816839803171131,
      "grad_norm": 0.005393031518906355,
      "learning_rate": 5.183160196828869e-06,
      "loss": 0.0093,
      "step": 54200
    },
    {
      "epoch": 14.81957353745216,
      "grad_norm": 0.00025865170755423605,
      "learning_rate": 5.180426462547841e-06,
      "loss": 0.0077,
      "step": 54210
    },
    {
      "epoch": 14.822307271733187,
      "grad_norm": 0.000981239601969719,
      "learning_rate": 5.177692728266813e-06,
      "loss": 0.0072,
      "step": 54220
    },
    {
      "epoch": 14.825041006014215,
      "grad_norm": 0.0004968055873177946,
      "learning_rate": 5.174958993985785e-06,
      "loss": 0.0099,
      "step": 54230
    },
    {
      "epoch": 14.827774740295244,
      "grad_norm": 0.0003710820456035435,
      "learning_rate": 5.172225259704757e-06,
      "loss": 0.0051,
      "step": 54240
    },
    {
      "epoch": 14.830508474576272,
      "grad_norm": 0.94162917137146,
      "learning_rate": 5.169491525423729e-06,
      "loss": 0.0079,
      "step": 54250
    },
    {
      "epoch": 14.8332422088573,
      "grad_norm": 0.00013478667824529111,
      "learning_rate": 5.1667577911427015e-06,
      "loss": 0.0025,
      "step": 54260
    },
    {
      "epoch": 14.835975943138326,
      "grad_norm": 0.00021522847237065434,
      "learning_rate": 5.164024056861674e-06,
      "loss": 0.002,
      "step": 54270
    },
    {
      "epoch": 14.838709677419354,
      "grad_norm": 0.0010287617333233356,
      "learning_rate": 5.161290322580646e-06,
      "loss": 0.0002,
      "step": 54280
    },
    {
      "epoch": 14.841443411700382,
      "grad_norm": 0.004037850070744753,
      "learning_rate": 5.158556588299618e-06,
      "loss": 0.0026,
      "step": 54290
    },
    {
      "epoch": 14.84417714598141,
      "grad_norm": 1.4704562425613403,
      "learning_rate": 5.15582285401859e-06,
      "loss": 0.0065,
      "step": 54300
    },
    {
      "epoch": 14.846910880262438,
      "grad_norm": 0.00040286887087859213,
      "learning_rate": 5.153089119737562e-06,
      "loss": 0.0096,
      "step": 54310
    },
    {
      "epoch": 14.849644614543466,
      "grad_norm": 0.00025730018387548625,
      "learning_rate": 5.150355385456534e-06,
      "loss": 0.003,
      "step": 54320
    },
    {
      "epoch": 14.852378348824494,
      "grad_norm": 0.00051583704771474,
      "learning_rate": 5.1476216511755064e-06,
      "loss": 0.0022,
      "step": 54330
    },
    {
      "epoch": 14.855112083105523,
      "grad_norm": 0.0003155201848130673,
      "learning_rate": 5.144887916894479e-06,
      "loss": 0.0058,
      "step": 54340
    },
    {
      "epoch": 14.85784581738655,
      "grad_norm": 0.8470001220703125,
      "learning_rate": 5.142154182613451e-06,
      "loss": 0.0057,
      "step": 54350
    },
    {
      "epoch": 14.860579551667579,
      "grad_norm": 0.0006082514300942421,
      "learning_rate": 5.139420448332423e-06,
      "loss": 0.0003,
      "step": 54360
    },
    {
      "epoch": 14.863313285948605,
      "grad_norm": 0.000488912221044302,
      "learning_rate": 5.136686714051394e-06,
      "loss": 0.0059,
      "step": 54370
    },
    {
      "epoch": 14.866047020229633,
      "grad_norm": 0.00040625210385769606,
      "learning_rate": 5.133952979770367e-06,
      "loss": 0.0,
      "step": 54380
    },
    {
      "epoch": 14.868780754510661,
      "grad_norm": 7.55848503112793,
      "learning_rate": 5.131219245489338e-06,
      "loss": 0.0059,
      "step": 54390
    },
    {
      "epoch": 14.87151448879169,
      "grad_norm": 0.00033819425152614713,
      "learning_rate": 5.1284855112083106e-06,
      "loss": 0.0,
      "step": 54400
    },
    {
      "epoch": 14.874248223072717,
      "grad_norm": 0.022141296416521072,
      "learning_rate": 5.125751776927284e-06,
      "loss": 0.0001,
      "step": 54410
    },
    {
      "epoch": 14.876981957353745,
      "grad_norm": 0.0003734122437890619,
      "learning_rate": 5.123018042646255e-06,
      "loss": 0.0046,
      "step": 54420
    },
    {
      "epoch": 14.879715691634773,
      "grad_norm": 0.000302426255075261,
      "learning_rate": 5.120284308365227e-06,
      "loss": 0.018,
      "step": 54430
    },
    {
      "epoch": 14.882449425915802,
      "grad_norm": 1.1292897462844849,
      "learning_rate": 5.117550574084199e-06,
      "loss": 0.0029,
      "step": 54440
    },
    {
      "epoch": 14.88518316019683,
      "grad_norm": 4.972896575927734,
      "learning_rate": 5.114816839803171e-06,
      "loss": 0.0142,
      "step": 54450
    },
    {
      "epoch": 14.887916894477856,
      "grad_norm": 0.005776324775069952,
      "learning_rate": 5.112083105522143e-06,
      "loss": 0.0122,
      "step": 54460
    },
    {
      "epoch": 14.890650628758884,
      "grad_norm": 0.00047429234837181866,
      "learning_rate": 5.1093493712411155e-06,
      "loss": 0.0023,
      "step": 54470
    },
    {
      "epoch": 14.893384363039912,
      "grad_norm": 0.0002119871787726879,
      "learning_rate": 5.106615636960088e-06,
      "loss": 0.0025,
      "step": 54480
    },
    {
      "epoch": 14.89611809732094,
      "grad_norm": 0.009182860143482685,
      "learning_rate": 5.10388190267906e-06,
      "loss": 0.0037,
      "step": 54490
    },
    {
      "epoch": 14.898851831601968,
      "grad_norm": 0.16619908809661865,
      "learning_rate": 5.101148168398032e-06,
      "loss": 0.001,
      "step": 54500
    },
    {
      "epoch": 14.901585565882996,
      "grad_norm": 0.0001440941559849307,
      "learning_rate": 5.098414434117004e-06,
      "loss": 0.0,
      "step": 54510
    },
    {
      "epoch": 14.904319300164024,
      "grad_norm": 0.003264917293563485,
      "learning_rate": 5.095680699835976e-06,
      "loss": 0.0039,
      "step": 54520
    },
    {
      "epoch": 14.907053034445052,
      "grad_norm": 0.0006323671550489962,
      "learning_rate": 5.092946965554948e-06,
      "loss": 0.0269,
      "step": 54530
    },
    {
      "epoch": 14.90978676872608,
      "grad_norm": 0.004397530108690262,
      "learning_rate": 5.0902132312739205e-06,
      "loss": 0.0021,
      "step": 54540
    },
    {
      "epoch": 14.912520503007109,
      "grad_norm": 0.0006445439648814499,
      "learning_rate": 5.087479496992893e-06,
      "loss": 0.0088,
      "step": 54550
    },
    {
      "epoch": 14.915254237288135,
      "grad_norm": 0.00041288009379059076,
      "learning_rate": 5.084745762711865e-06,
      "loss": 0.009,
      "step": 54560
    },
    {
      "epoch": 14.917987971569163,
      "grad_norm": 0.0002663498744368553,
      "learning_rate": 5.082012028430837e-06,
      "loss": 0.0022,
      "step": 54570
    },
    {
      "epoch": 14.920721705850191,
      "grad_norm": 0.0004940790240652859,
      "learning_rate": 5.079278294149809e-06,
      "loss": 0.0036,
      "step": 54580
    },
    {
      "epoch": 14.92345544013122,
      "grad_norm": 0.0011892899638041854,
      "learning_rate": 5.076544559868781e-06,
      "loss": 0.0177,
      "step": 54590
    },
    {
      "epoch": 14.926189174412247,
      "grad_norm": 0.0002102285361615941,
      "learning_rate": 5.073810825587753e-06,
      "loss": 0.0053,
      "step": 54600
    },
    {
      "epoch": 14.928922908693275,
      "grad_norm": 0.0003821527352556586,
      "learning_rate": 5.0710770913067255e-06,
      "loss": 0.0004,
      "step": 54610
    },
    {
      "epoch": 14.931656642974303,
      "grad_norm": 0.00040393922245129943,
      "learning_rate": 5.068343357025698e-06,
      "loss": 0.0,
      "step": 54620
    },
    {
      "epoch": 14.934390377255331,
      "grad_norm": 0.9121244549751282,
      "learning_rate": 5.06560962274467e-06,
      "loss": 0.0069,
      "step": 54630
    },
    {
      "epoch": 14.93712411153636,
      "grad_norm": 0.0003683684626594186,
      "learning_rate": 5.062875888463642e-06,
      "loss": 0.0038,
      "step": 54640
    },
    {
      "epoch": 14.939857845817386,
      "grad_norm": 0.00045385039993561804,
      "learning_rate": 5.060142154182614e-06,
      "loss": 0.0001,
      "step": 54650
    },
    {
      "epoch": 14.942591580098414,
      "grad_norm": 0.022845396772027016,
      "learning_rate": 5.057408419901586e-06,
      "loss": 0.0012,
      "step": 54660
    },
    {
      "epoch": 14.945325314379442,
      "grad_norm": 0.008249528706073761,
      "learning_rate": 5.054674685620559e-06,
      "loss": 0.0023,
      "step": 54670
    },
    {
      "epoch": 14.94805904866047,
      "grad_norm": 0.8407655358314514,
      "learning_rate": 5.0519409513395305e-06,
      "loss": 0.0058,
      "step": 54680
    },
    {
      "epoch": 14.950792782941498,
      "grad_norm": 0.00805326271802187,
      "learning_rate": 5.049207217058503e-06,
      "loss": 0.0035,
      "step": 54690
    },
    {
      "epoch": 14.953526517222526,
      "grad_norm": 0.49008896946907043,
      "learning_rate": 5.046473482777474e-06,
      "loss": 0.0009,
      "step": 54700
    },
    {
      "epoch": 14.956260251503554,
      "grad_norm": 0.0004329768125899136,
      "learning_rate": 5.043739748496447e-06,
      "loss": 0.0036,
      "step": 54710
    },
    {
      "epoch": 14.958993985784582,
      "grad_norm": 0.002845518756657839,
      "learning_rate": 5.041006014215418e-06,
      "loss": 0.0044,
      "step": 54720
    },
    {
      "epoch": 14.96172772006561,
      "grad_norm": 0.0005592304514721036,
      "learning_rate": 5.0382722799343905e-06,
      "loss": 0.0081,
      "step": 54730
    },
    {
      "epoch": 14.964461454346637,
      "grad_norm": 8.895673818187788e-05,
      "learning_rate": 5.035538545653364e-06,
      "loss": 0.0038,
      "step": 54740
    },
    {
      "epoch": 14.967195188627665,
      "grad_norm": 0.00024269366986118257,
      "learning_rate": 5.032804811372335e-06,
      "loss": 0.0098,
      "step": 54750
    },
    {
      "epoch": 14.969928922908693,
      "grad_norm": 0.0003234331961721182,
      "learning_rate": 5.030071077091307e-06,
      "loss": 0.0007,
      "step": 54760
    },
    {
      "epoch": 14.972662657189721,
      "grad_norm": 0.0004609449242707342,
      "learning_rate": 5.027337342810279e-06,
      "loss": 0.0136,
      "step": 54770
    },
    {
      "epoch": 14.975396391470749,
      "grad_norm": 0.00023608087212778628,
      "learning_rate": 5.024603608529251e-06,
      "loss": 0.0,
      "step": 54780
    },
    {
      "epoch": 14.978130125751777,
      "grad_norm": 0.0002298220933880657,
      "learning_rate": 5.021869874248223e-06,
      "loss": 0.001,
      "step": 54790
    },
    {
      "epoch": 14.980863860032805,
      "grad_norm": 0.0004642912244889885,
      "learning_rate": 5.0191361399671954e-06,
      "loss": 0.0002,
      "step": 54800
    },
    {
      "epoch": 14.983597594313833,
      "grad_norm": 0.00019670814799610525,
      "learning_rate": 5.016402405686168e-06,
      "loss": 0.0056,
      "step": 54810
    },
    {
      "epoch": 14.986331328594861,
      "grad_norm": 0.00021856164676137269,
      "learning_rate": 5.01366867140514e-06,
      "loss": 0.0026,
      "step": 54820
    },
    {
      "epoch": 14.989065062875888,
      "grad_norm": 0.00048283158685080707,
      "learning_rate": 5.010934937124112e-06,
      "loss": 0.0004,
      "step": 54830
    },
    {
      "epoch": 14.991798797156916,
      "grad_norm": 0.00018489478679839522,
      "learning_rate": 5.008201202843084e-06,
      "loss": 0.0034,
      "step": 54840
    },
    {
      "epoch": 14.994532531437944,
      "grad_norm": 0.0008796441252343357,
      "learning_rate": 5.005467468562056e-06,
      "loss": 0.0195,
      "step": 54850
    },
    {
      "epoch": 14.997266265718972,
      "grad_norm": 0.00015312270261347294,
      "learning_rate": 5.002733734281028e-06,
      "loss": 0.0216,
      "step": 54860
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.0004764562763739377,
      "learning_rate": 5e-06,
      "loss": 0.0048,
      "step": 54870
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.9930821626223925,
      "eval_f1": 0.9721508140531278,
      "eval_loss": 0.04052331671118736,
      "eval_precision": 0.9759139784946237,
      "eval_recall": 0.9684165599658557,
      "eval_runtime": 798.5738,
      "eval_samples_per_second": 23.56,
      "eval_steps_per_second": 0.982,
      "step": 54870
    }
  ],
  "logging_steps": 10,
  "max_steps": 73160,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.043199024029696e+17,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
