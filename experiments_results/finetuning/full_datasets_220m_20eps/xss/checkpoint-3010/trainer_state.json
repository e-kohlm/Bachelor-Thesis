{
  "best_metric": 0.9635135135135136,
  "best_model_checkpoint": "../saved_models/xss_20ep/checkpoint-3010",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3010,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0033222591362126247,
      "grad_norm": 44.39754867553711,
      "learning_rate": 1.999667774086379e-05,
      "loss": 1.1104,
      "step": 1
    },
    {
      "epoch": 0.03322259136212625,
      "grad_norm": 9.23383903503418,
      "learning_rate": 1.9966777408637876e-05,
      "loss": 0.4059,
      "step": 10
    },
    {
      "epoch": 0.0664451827242525,
      "grad_norm": 10.352192878723145,
      "learning_rate": 1.9933554817275747e-05,
      "loss": 0.3206,
      "step": 20
    },
    {
      "epoch": 0.09966777408637874,
      "grad_norm": 11.791571617126465,
      "learning_rate": 1.9900332225913622e-05,
      "loss": 0.3043,
      "step": 30
    },
    {
      "epoch": 0.132890365448505,
      "grad_norm": 32.227203369140625,
      "learning_rate": 1.9867109634551496e-05,
      "loss": 0.283,
      "step": 40
    },
    {
      "epoch": 0.16611295681063123,
      "grad_norm": 6.7855939865112305,
      "learning_rate": 1.983388704318937e-05,
      "loss": 0.2862,
      "step": 50
    },
    {
      "epoch": 0.19933554817275748,
      "grad_norm": 34.01808547973633,
      "learning_rate": 1.9800664451827245e-05,
      "loss": 0.2708,
      "step": 60
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 28.15500259399414,
      "learning_rate": 1.9767441860465116e-05,
      "loss": 0.2699,
      "step": 70
    },
    {
      "epoch": 0.26578073089701,
      "grad_norm": 11.802778244018555,
      "learning_rate": 1.973421926910299e-05,
      "loss": 0.2491,
      "step": 80
    },
    {
      "epoch": 0.29900332225913623,
      "grad_norm": 11.091046333312988,
      "learning_rate": 1.9700996677740865e-05,
      "loss": 0.2531,
      "step": 90
    },
    {
      "epoch": 0.33222591362126247,
      "grad_norm": 6.916159152984619,
      "learning_rate": 1.966777408637874e-05,
      "loss": 0.2444,
      "step": 100
    },
    {
      "epoch": 0.3654485049833887,
      "grad_norm": 18.281700134277344,
      "learning_rate": 1.9634551495016614e-05,
      "loss": 0.2278,
      "step": 110
    },
    {
      "epoch": 0.39867109634551495,
      "grad_norm": 6.849381446838379,
      "learning_rate": 1.9601328903654486e-05,
      "loss": 0.219,
      "step": 120
    },
    {
      "epoch": 0.4318936877076412,
      "grad_norm": 6.115015029907227,
      "learning_rate": 1.956810631229236e-05,
      "loss": 0.2146,
      "step": 130
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 5.793162822723389,
      "learning_rate": 1.9534883720930235e-05,
      "loss": 0.1947,
      "step": 140
    },
    {
      "epoch": 0.4983388704318937,
      "grad_norm": 4.248793125152588,
      "learning_rate": 1.950166112956811e-05,
      "loss": 0.1719,
      "step": 150
    },
    {
      "epoch": 0.53156146179402,
      "grad_norm": 4.594729900360107,
      "learning_rate": 1.9468438538205984e-05,
      "loss": 0.1792,
      "step": 160
    },
    {
      "epoch": 0.5647840531561462,
      "grad_norm": 9.822047233581543,
      "learning_rate": 1.9435215946843855e-05,
      "loss": 0.1502,
      "step": 170
    },
    {
      "epoch": 0.5980066445182725,
      "grad_norm": 5.638448715209961,
      "learning_rate": 1.940199335548173e-05,
      "loss": 0.1802,
      "step": 180
    },
    {
      "epoch": 0.6312292358803987,
      "grad_norm": 3.334688186645508,
      "learning_rate": 1.9368770764119604e-05,
      "loss": 0.1678,
      "step": 190
    },
    {
      "epoch": 0.6644518272425249,
      "grad_norm": 4.11352014541626,
      "learning_rate": 1.933554817275748e-05,
      "loss": 0.154,
      "step": 200
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 3.388350486755371,
      "learning_rate": 1.9302325581395353e-05,
      "loss": 0.1478,
      "step": 210
    },
    {
      "epoch": 0.7308970099667774,
      "grad_norm": 4.7933244705200195,
      "learning_rate": 1.9269102990033224e-05,
      "loss": 0.1407,
      "step": 220
    },
    {
      "epoch": 0.7641196013289037,
      "grad_norm": 2.752861738204956,
      "learning_rate": 1.92358803986711e-05,
      "loss": 0.1409,
      "step": 230
    },
    {
      "epoch": 0.7973421926910299,
      "grad_norm": 4.045764446258545,
      "learning_rate": 1.920265780730897e-05,
      "loss": 0.1303,
      "step": 240
    },
    {
      "epoch": 0.8305647840531561,
      "grad_norm": 2.671950578689575,
      "learning_rate": 1.9169435215946844e-05,
      "loss": 0.1173,
      "step": 250
    },
    {
      "epoch": 0.8637873754152824,
      "grad_norm": 3.5111498832702637,
      "learning_rate": 1.913621262458472e-05,
      "loss": 0.1198,
      "step": 260
    },
    {
      "epoch": 0.8970099667774086,
      "grad_norm": 3.217388391494751,
      "learning_rate": 1.9102990033222593e-05,
      "loss": 0.1483,
      "step": 270
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 2.668053150177002,
      "learning_rate": 1.9069767441860468e-05,
      "loss": 0.0925,
      "step": 280
    },
    {
      "epoch": 0.9634551495016611,
      "grad_norm": 4.480010032653809,
      "learning_rate": 1.903654485049834e-05,
      "loss": 0.089,
      "step": 290
    },
    {
      "epoch": 0.9966777408637874,
      "grad_norm": 3.7541167736053467,
      "learning_rate": 1.9003322259136213e-05,
      "loss": 0.1248,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9653585271317829,
      "eval_f1": 0.7762128325508607,
      "eval_loss": 0.10282622277736664,
      "eval_precision": 0.9483747609942639,
      "eval_recall": 0.6569536423841059,
      "eval_runtime": 84.6613,
      "eval_samples_per_second": 97.766,
      "eval_steps_per_second": 3.059,
      "step": 301
    },
    {
      "epoch": 1.0299003322259137,
      "grad_norm": 2.550774097442627,
      "learning_rate": 1.8970099667774088e-05,
      "loss": 0.0824,
      "step": 310
    },
    {
      "epoch": 1.06312292358804,
      "grad_norm": 2.1292240619659424,
      "learning_rate": 1.8936877076411962e-05,
      "loss": 0.0637,
      "step": 320
    },
    {
      "epoch": 1.0963455149501662,
      "grad_norm": 9.100499153137207,
      "learning_rate": 1.8903654485049837e-05,
      "loss": 0.0783,
      "step": 330
    },
    {
      "epoch": 1.1295681063122924,
      "grad_norm": 2.6297712326049805,
      "learning_rate": 1.8870431893687708e-05,
      "loss": 0.0939,
      "step": 340
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 2.59175181388855,
      "learning_rate": 1.8837209302325582e-05,
      "loss": 0.0486,
      "step": 350
    },
    {
      "epoch": 1.196013289036545,
      "grad_norm": 4.050595283508301,
      "learning_rate": 1.8803986710963457e-05,
      "loss": 0.0615,
      "step": 360
    },
    {
      "epoch": 1.2292358803986712,
      "grad_norm": 3.3647663593292236,
      "learning_rate": 1.877076411960133e-05,
      "loss": 0.0933,
      "step": 370
    },
    {
      "epoch": 1.2624584717607974,
      "grad_norm": 3.1329121589660645,
      "learning_rate": 1.8737541528239206e-05,
      "loss": 0.0601,
      "step": 380
    },
    {
      "epoch": 1.2956810631229236,
      "grad_norm": 4.748514652252197,
      "learning_rate": 1.8704318936877077e-05,
      "loss": 0.0739,
      "step": 390
    },
    {
      "epoch": 1.3289036544850499,
      "grad_norm": 2.9580605030059814,
      "learning_rate": 1.867109634551495e-05,
      "loss": 0.0829,
      "step": 400
    },
    {
      "epoch": 1.3621262458471761,
      "grad_norm": 3.0529959201812744,
      "learning_rate": 1.8637873754152826e-05,
      "loss": 0.0531,
      "step": 410
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 3.069347858428955,
      "learning_rate": 1.86046511627907e-05,
      "loss": 0.0578,
      "step": 420
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 2.0986547470092773,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 0.0591,
      "step": 430
    },
    {
      "epoch": 1.4617940199335548,
      "grad_norm": 5.327538013458252,
      "learning_rate": 1.8538205980066446e-05,
      "loss": 0.0576,
      "step": 440
    },
    {
      "epoch": 1.495016611295681,
      "grad_norm": 6.082798480987549,
      "learning_rate": 1.850498338870432e-05,
      "loss": 0.0699,
      "step": 450
    },
    {
      "epoch": 1.5282392026578073,
      "grad_norm": 2.715406894683838,
      "learning_rate": 1.8471760797342195e-05,
      "loss": 0.0704,
      "step": 460
    },
    {
      "epoch": 1.5614617940199336,
      "grad_norm": 2.898453950881958,
      "learning_rate": 1.8438538205980066e-05,
      "loss": 0.0668,
      "step": 470
    },
    {
      "epoch": 1.5946843853820598,
      "grad_norm": 2.499232769012451,
      "learning_rate": 1.840531561461794e-05,
      "loss": 0.045,
      "step": 480
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 3.2453625202178955,
      "learning_rate": 1.8372093023255815e-05,
      "loss": 0.0299,
      "step": 490
    },
    {
      "epoch": 1.6611295681063123,
      "grad_norm": 4.335212707519531,
      "learning_rate": 1.833887043189369e-05,
      "loss": 0.0522,
      "step": 500
    },
    {
      "epoch": 1.6943521594684385,
      "grad_norm": 2.7034389972686768,
      "learning_rate": 1.830564784053156e-05,
      "loss": 0.076,
      "step": 510
    },
    {
      "epoch": 1.7275747508305648,
      "grad_norm": 4.520760536193848,
      "learning_rate": 1.8272425249169436e-05,
      "loss": 0.0672,
      "step": 520
    },
    {
      "epoch": 1.760797342192691,
      "grad_norm": 1.1132994890213013,
      "learning_rate": 1.823920265780731e-05,
      "loss": 0.044,
      "step": 530
    },
    {
      "epoch": 1.7940199335548173,
      "grad_norm": 1.740047812461853,
      "learning_rate": 1.8205980066445185e-05,
      "loss": 0.0539,
      "step": 540
    },
    {
      "epoch": 1.8272425249169435,
      "grad_norm": 3.189119338989258,
      "learning_rate": 1.817275747508306e-05,
      "loss": 0.0508,
      "step": 550
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 1.4634145498275757,
      "learning_rate": 1.813953488372093e-05,
      "loss": 0.0653,
      "step": 560
    },
    {
      "epoch": 1.893687707641196,
      "grad_norm": 2.035447359085083,
      "learning_rate": 1.8106312292358805e-05,
      "loss": 0.0388,
      "step": 570
    },
    {
      "epoch": 1.9269102990033222,
      "grad_norm": 1.3262698650360107,
      "learning_rate": 1.807308970099668e-05,
      "loss": 0.0373,
      "step": 580
    },
    {
      "epoch": 1.9601328903654485,
      "grad_norm": 3.439122200012207,
      "learning_rate": 1.8039867109634554e-05,
      "loss": 0.0493,
      "step": 590
    },
    {
      "epoch": 1.9933554817275747,
      "grad_norm": 0.9279912114143372,
      "learning_rate": 1.8006644518272428e-05,
      "loss": 0.0453,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9877664728682171,
      "eval_f1": 0.9302967563837129,
      "eval_loss": 0.035434477031230927,
      "eval_precision": 0.9711815561959655,
      "eval_recall": 0.8927152317880794,
      "eval_runtime": 84.2077,
      "eval_samples_per_second": 98.293,
      "eval_steps_per_second": 3.076,
      "step": 602
    },
    {
      "epoch": 2.026578073089701,
      "grad_norm": 4.594461441040039,
      "learning_rate": 1.79734219269103e-05,
      "loss": 0.0477,
      "step": 610
    },
    {
      "epoch": 2.0598006644518274,
      "grad_norm": 1.4940834045410156,
      "learning_rate": 1.7940199335548174e-05,
      "loss": 0.0385,
      "step": 620
    },
    {
      "epoch": 2.0930232558139537,
      "grad_norm": 2.9375643730163574,
      "learning_rate": 1.790697674418605e-05,
      "loss": 0.0335,
      "step": 630
    },
    {
      "epoch": 2.12624584717608,
      "grad_norm": 3.3596954345703125,
      "learning_rate": 1.787375415282392e-05,
      "loss": 0.0292,
      "step": 640
    },
    {
      "epoch": 2.159468438538206,
      "grad_norm": 3.3619799613952637,
      "learning_rate": 1.7840531561461797e-05,
      "loss": 0.0387,
      "step": 650
    },
    {
      "epoch": 2.1926910299003324,
      "grad_norm": 1.8763177394866943,
      "learning_rate": 1.780730897009967e-05,
      "loss": 0.0271,
      "step": 660
    },
    {
      "epoch": 2.2259136212624586,
      "grad_norm": 3.101024866104126,
      "learning_rate": 1.7774086378737543e-05,
      "loss": 0.0347,
      "step": 670
    },
    {
      "epoch": 2.259136212624585,
      "grad_norm": 2.1670124530792236,
      "learning_rate": 1.7740863787375418e-05,
      "loss": 0.0351,
      "step": 680
    },
    {
      "epoch": 2.292358803986711,
      "grad_norm": 1.536972999572754,
      "learning_rate": 1.770764119601329e-05,
      "loss": 0.0353,
      "step": 690
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 2.062349796295166,
      "learning_rate": 1.7674418604651163e-05,
      "loss": 0.039,
      "step": 700
    },
    {
      "epoch": 2.3588039867109636,
      "grad_norm": 1.6653985977172852,
      "learning_rate": 1.7641196013289038e-05,
      "loss": 0.0382,
      "step": 710
    },
    {
      "epoch": 2.39202657807309,
      "grad_norm": 2.0308079719543457,
      "learning_rate": 1.7607973421926912e-05,
      "loss": 0.0413,
      "step": 720
    },
    {
      "epoch": 2.425249169435216,
      "grad_norm": 2.129491090774536,
      "learning_rate": 1.7574750830564787e-05,
      "loss": 0.0262,
      "step": 730
    },
    {
      "epoch": 2.4584717607973423,
      "grad_norm": 0.34002605080604553,
      "learning_rate": 1.7541528239202658e-05,
      "loss": 0.0242,
      "step": 740
    },
    {
      "epoch": 2.4916943521594686,
      "grad_norm": 1.8061800003051758,
      "learning_rate": 1.7508305647840532e-05,
      "loss": 0.0278,
      "step": 750
    },
    {
      "epoch": 2.524916943521595,
      "grad_norm": 9.843789100646973,
      "learning_rate": 1.7475083056478407e-05,
      "loss": 0.0383,
      "step": 760
    },
    {
      "epoch": 2.558139534883721,
      "grad_norm": 2.597626209259033,
      "learning_rate": 1.744186046511628e-05,
      "loss": 0.0487,
      "step": 770
    },
    {
      "epoch": 2.5913621262458473,
      "grad_norm": 0.3146683871746063,
      "learning_rate": 1.7408637873754156e-05,
      "loss": 0.0137,
      "step": 780
    },
    {
      "epoch": 2.6245847176079735,
      "grad_norm": 1.6193499565124512,
      "learning_rate": 1.7375415282392027e-05,
      "loss": 0.0323,
      "step": 790
    },
    {
      "epoch": 2.6578073089700998,
      "grad_norm": 0.5591172575950623,
      "learning_rate": 1.73421926910299e-05,
      "loss": 0.0237,
      "step": 800
    },
    {
      "epoch": 2.691029900332226,
      "grad_norm": 1.0794963836669922,
      "learning_rate": 1.7308970099667776e-05,
      "loss": 0.0303,
      "step": 810
    },
    {
      "epoch": 2.7242524916943522,
      "grad_norm": 0.37689757347106934,
      "learning_rate": 1.727574750830565e-05,
      "loss": 0.0388,
      "step": 820
    },
    {
      "epoch": 2.7574750830564785,
      "grad_norm": 0.07242928445339203,
      "learning_rate": 1.7242524916943525e-05,
      "loss": 0.0428,
      "step": 830
    },
    {
      "epoch": 2.7906976744186047,
      "grad_norm": 0.3230346143245697,
      "learning_rate": 1.7209302325581396e-05,
      "loss": 0.0375,
      "step": 840
    },
    {
      "epoch": 2.823920265780731,
      "grad_norm": 0.9461673498153687,
      "learning_rate": 1.717607973421927e-05,
      "loss": 0.0364,
      "step": 850
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 2.1956777572631836,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.0299,
      "step": 860
    },
    {
      "epoch": 2.8903654485049834,
      "grad_norm": 2.691678524017334,
      "learning_rate": 1.7109634551495016e-05,
      "loss": 0.0359,
      "step": 870
    },
    {
      "epoch": 2.9235880398671097,
      "grad_norm": 2.3103396892547607,
      "learning_rate": 1.7076411960132894e-05,
      "loss": 0.0209,
      "step": 880
    },
    {
      "epoch": 2.956810631229236,
      "grad_norm": 1.2109124660491943,
      "learning_rate": 1.7043189368770765e-05,
      "loss": 0.0174,
      "step": 890
    },
    {
      "epoch": 2.990033222591362,
      "grad_norm": 0.24555523693561554,
      "learning_rate": 1.700996677740864e-05,
      "loss": 0.018,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9895833333333334,
      "eval_f1": 0.9418132611637349,
      "eval_loss": 0.0373070053756237,
      "eval_precision": 0.9626556016597511,
      "eval_recall": 0.9218543046357616,
      "eval_runtime": 84.8705,
      "eval_samples_per_second": 97.525,
      "eval_steps_per_second": 3.052,
      "step": 903
    },
    {
      "epoch": 3.0232558139534884,
      "grad_norm": 0.16962890326976776,
      "learning_rate": 1.697674418604651e-05,
      "loss": 0.0154,
      "step": 910
    },
    {
      "epoch": 3.0564784053156147,
      "grad_norm": 1.984256386756897,
      "learning_rate": 1.6943521594684386e-05,
      "loss": 0.0271,
      "step": 920
    },
    {
      "epoch": 3.089700996677741,
      "grad_norm": 0.8300415277481079,
      "learning_rate": 1.691029900332226e-05,
      "loss": 0.0257,
      "step": 930
    },
    {
      "epoch": 3.122923588039867,
      "grad_norm": 1.886565089225769,
      "learning_rate": 1.6877076411960135e-05,
      "loss": 0.0093,
      "step": 940
    },
    {
      "epoch": 3.1561461794019934,
      "grad_norm": 2.100414991378784,
      "learning_rate": 1.684385382059801e-05,
      "loss": 0.0333,
      "step": 950
    },
    {
      "epoch": 3.1893687707641196,
      "grad_norm": 0.36039331555366516,
      "learning_rate": 1.681063122923588e-05,
      "loss": 0.0217,
      "step": 960
    },
    {
      "epoch": 3.222591362126246,
      "grad_norm": 3.9640326499938965,
      "learning_rate": 1.6777408637873755e-05,
      "loss": 0.0222,
      "step": 970
    },
    {
      "epoch": 3.255813953488372,
      "grad_norm": 1.2355740070343018,
      "learning_rate": 1.674418604651163e-05,
      "loss": 0.0278,
      "step": 980
    },
    {
      "epoch": 3.2890365448504983,
      "grad_norm": 0.5801128149032593,
      "learning_rate": 1.6710963455149504e-05,
      "loss": 0.0288,
      "step": 990
    },
    {
      "epoch": 3.3222591362126246,
      "grad_norm": 2.363190174102783,
      "learning_rate": 1.6677740863787378e-05,
      "loss": 0.0245,
      "step": 1000
    },
    {
      "epoch": 3.355481727574751,
      "grad_norm": 3.4761505126953125,
      "learning_rate": 1.664451827242525e-05,
      "loss": 0.0253,
      "step": 1010
    },
    {
      "epoch": 3.388704318936877,
      "grad_norm": 1.1658077239990234,
      "learning_rate": 1.6611295681063124e-05,
      "loss": 0.0214,
      "step": 1020
    },
    {
      "epoch": 3.4219269102990033,
      "grad_norm": 1.020362377166748,
      "learning_rate": 1.6578073089701e-05,
      "loss": 0.0235,
      "step": 1030
    },
    {
      "epoch": 3.4551495016611296,
      "grad_norm": 0.6145236492156982,
      "learning_rate": 1.6544850498338873e-05,
      "loss": 0.0156,
      "step": 1040
    },
    {
      "epoch": 3.488372093023256,
      "grad_norm": 1.0572673082351685,
      "learning_rate": 1.6511627906976747e-05,
      "loss": 0.0283,
      "step": 1050
    },
    {
      "epoch": 3.521594684385382,
      "grad_norm": 3.755472183227539,
      "learning_rate": 1.647840531561462e-05,
      "loss": 0.037,
      "step": 1060
    },
    {
      "epoch": 3.5548172757475083,
      "grad_norm": 2.130730628967285,
      "learning_rate": 1.6445182724252493e-05,
      "loss": 0.0291,
      "step": 1070
    },
    {
      "epoch": 3.5880398671096345,
      "grad_norm": 1.6154762506484985,
      "learning_rate": 1.6411960132890368e-05,
      "loss": 0.0216,
      "step": 1080
    },
    {
      "epoch": 3.6212624584717608,
      "grad_norm": 3.1191701889038086,
      "learning_rate": 1.637873754152824e-05,
      "loss": 0.0241,
      "step": 1090
    },
    {
      "epoch": 3.654485049833887,
      "grad_norm": 1.182180643081665,
      "learning_rate": 1.6345514950166113e-05,
      "loss": 0.0128,
      "step": 1100
    },
    {
      "epoch": 3.6877076411960132,
      "grad_norm": 0.12793003022670746,
      "learning_rate": 1.6312292358803988e-05,
      "loss": 0.0183,
      "step": 1110
    },
    {
      "epoch": 3.7209302325581395,
      "grad_norm": 1.092620849609375,
      "learning_rate": 1.6279069767441862e-05,
      "loss": 0.0154,
      "step": 1120
    },
    {
      "epoch": 3.7541528239202657,
      "grad_norm": 3.8502063751220703,
      "learning_rate": 1.6245847176079737e-05,
      "loss": 0.024,
      "step": 1130
    },
    {
      "epoch": 3.787375415282392,
      "grad_norm": 2.9644052982330322,
      "learning_rate": 1.6212624584717608e-05,
      "loss": 0.0359,
      "step": 1140
    },
    {
      "epoch": 3.820598006644518,
      "grad_norm": 2.423844575881958,
      "learning_rate": 1.6179401993355482e-05,
      "loss": 0.015,
      "step": 1150
    },
    {
      "epoch": 3.8538205980066444,
      "grad_norm": 0.18154868483543396,
      "learning_rate": 1.6146179401993357e-05,
      "loss": 0.0179,
      "step": 1160
    },
    {
      "epoch": 3.8870431893687707,
      "grad_norm": 0.3346935510635376,
      "learning_rate": 1.611295681063123e-05,
      "loss": 0.0224,
      "step": 1170
    },
    {
      "epoch": 3.920265780730897,
      "grad_norm": 3.35581374168396,
      "learning_rate": 1.6079734219269106e-05,
      "loss": 0.018,
      "step": 1180
    },
    {
      "epoch": 3.953488372093023,
      "grad_norm": 1.4648557901382446,
      "learning_rate": 1.6046511627906977e-05,
      "loss": 0.0205,
      "step": 1190
    },
    {
      "epoch": 3.9867109634551494,
      "grad_norm": 1.2740346193313599,
      "learning_rate": 1.601328903654485e-05,
      "loss": 0.0304,
      "step": 1200
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9910368217054264,
      "eval_f1": 0.9505347593582888,
      "eval_loss": 0.027836402878165245,
      "eval_precision": 0.9595141700404858,
      "eval_recall": 0.9417218543046357,
      "eval_runtime": 83.9221,
      "eval_samples_per_second": 98.627,
      "eval_steps_per_second": 3.086,
      "step": 1204
    },
    {
      "epoch": 4.019933554817276,
      "grad_norm": 0.1530281901359558,
      "learning_rate": 1.5980066445182726e-05,
      "loss": 0.01,
      "step": 1210
    },
    {
      "epoch": 4.053156146179402,
      "grad_norm": 1.6452770233154297,
      "learning_rate": 1.59468438538206e-05,
      "loss": 0.0135,
      "step": 1220
    },
    {
      "epoch": 4.086378737541528,
      "grad_norm": 1.8756686449050903,
      "learning_rate": 1.5913621262458475e-05,
      "loss": 0.007,
      "step": 1230
    },
    {
      "epoch": 4.119601328903655,
      "grad_norm": 0.8235382437705994,
      "learning_rate": 1.5880398671096346e-05,
      "loss": 0.0202,
      "step": 1240
    },
    {
      "epoch": 4.152823920265781,
      "grad_norm": 1.2029430866241455,
      "learning_rate": 1.584717607973422e-05,
      "loss": 0.0183,
      "step": 1250
    },
    {
      "epoch": 4.186046511627907,
      "grad_norm": 1.820225477218628,
      "learning_rate": 1.5813953488372095e-05,
      "loss": 0.0205,
      "step": 1260
    },
    {
      "epoch": 4.219269102990033,
      "grad_norm": 2.721649169921875,
      "learning_rate": 1.578073089700997e-05,
      "loss": 0.0187,
      "step": 1270
    },
    {
      "epoch": 4.25249169435216,
      "grad_norm": 1.0367807149887085,
      "learning_rate": 1.5747508305647844e-05,
      "loss": 0.0175,
      "step": 1280
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 2.4674065113067627,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.0265,
      "step": 1290
    },
    {
      "epoch": 4.318936877076412,
      "grad_norm": 4.042780876159668,
      "learning_rate": 1.568106312292359e-05,
      "loss": 0.028,
      "step": 1300
    },
    {
      "epoch": 4.352159468438538,
      "grad_norm": 2.087501049041748,
      "learning_rate": 1.564784053156146e-05,
      "loss": 0.0213,
      "step": 1310
    },
    {
      "epoch": 4.385382059800665,
      "grad_norm": 0.8250452876091003,
      "learning_rate": 1.5614617940199335e-05,
      "loss": 0.017,
      "step": 1320
    },
    {
      "epoch": 4.4186046511627906,
      "grad_norm": 2.0600697994232178,
      "learning_rate": 1.558139534883721e-05,
      "loss": 0.0135,
      "step": 1330
    },
    {
      "epoch": 4.451827242524917,
      "grad_norm": 0.9345377683639526,
      "learning_rate": 1.5548172757475084e-05,
      "loss": 0.0139,
      "step": 1340
    },
    {
      "epoch": 4.485049833887043,
      "grad_norm": 0.8461543321609497,
      "learning_rate": 1.551495016611296e-05,
      "loss": 0.0242,
      "step": 1350
    },
    {
      "epoch": 4.51827242524917,
      "grad_norm": 0.1294320821762085,
      "learning_rate": 1.548172757475083e-05,
      "loss": 0.0078,
      "step": 1360
    },
    {
      "epoch": 4.5514950166112955,
      "grad_norm": 1.3665858507156372,
      "learning_rate": 1.5448504983388705e-05,
      "loss": 0.0105,
      "step": 1370
    },
    {
      "epoch": 4.584717607973422,
      "grad_norm": 0.031933560967445374,
      "learning_rate": 1.541528239202658e-05,
      "loss": 0.0138,
      "step": 1380
    },
    {
      "epoch": 4.617940199335548,
      "grad_norm": 0.9548654556274414,
      "learning_rate": 1.5382059800664454e-05,
      "loss": 0.0202,
      "step": 1390
    },
    {
      "epoch": 4.651162790697675,
      "grad_norm": 1.0889174938201904,
      "learning_rate": 1.5348837209302328e-05,
      "loss": 0.0135,
      "step": 1400
    },
    {
      "epoch": 4.6843853820598005,
      "grad_norm": 4.732766151428223,
      "learning_rate": 1.53156146179402e-05,
      "loss": 0.0142,
      "step": 1410
    },
    {
      "epoch": 4.717607973421927,
      "grad_norm": 1.83326256275177,
      "learning_rate": 1.5282392026578074e-05,
      "loss": 0.016,
      "step": 1420
    },
    {
      "epoch": 4.750830564784053,
      "grad_norm": 0.8521615266799927,
      "learning_rate": 1.5249169435215948e-05,
      "loss": 0.019,
      "step": 1430
    },
    {
      "epoch": 4.78405315614618,
      "grad_norm": 0.06356995552778244,
      "learning_rate": 1.5215946843853821e-05,
      "loss": 0.0141,
      "step": 1440
    },
    {
      "epoch": 4.8172757475083055,
      "grad_norm": 0.40593522787094116,
      "learning_rate": 1.5182724252491696e-05,
      "loss": 0.0276,
      "step": 1450
    },
    {
      "epoch": 4.850498338870432,
      "grad_norm": 1.282955288887024,
      "learning_rate": 1.5149501661129568e-05,
      "loss": 0.0144,
      "step": 1460
    },
    {
      "epoch": 4.883720930232558,
      "grad_norm": 1.8890674114227295,
      "learning_rate": 1.5116279069767443e-05,
      "loss": 0.0174,
      "step": 1470
    },
    {
      "epoch": 4.916943521594685,
      "grad_norm": 0.344806045293808,
      "learning_rate": 1.5083056478405317e-05,
      "loss": 0.0074,
      "step": 1480
    },
    {
      "epoch": 4.95016611295681,
      "grad_norm": 3.461365222930908,
      "learning_rate": 1.504983388704319e-05,
      "loss": 0.0172,
      "step": 1490
    },
    {
      "epoch": 4.983388704318937,
      "grad_norm": 3.471752882003784,
      "learning_rate": 1.5016611295681065e-05,
      "loss": 0.0149,
      "step": 1500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9916424418604651,
      "eval_f1": 0.9544554455445544,
      "eval_loss": 0.02471923828125,
      "eval_precision": 0.9513157894736842,
      "eval_recall": 0.9576158940397351,
      "eval_runtime": 83.8051,
      "eval_samples_per_second": 98.765,
      "eval_steps_per_second": 3.091,
      "step": 1505
    },
    {
      "epoch": 5.016611295681063,
      "grad_norm": 0.14463123679161072,
      "learning_rate": 1.4983388704318938e-05,
      "loss": 0.0171,
      "step": 1510
    },
    {
      "epoch": 5.04983388704319,
      "grad_norm": 1.2552090883255005,
      "learning_rate": 1.4950166112956812e-05,
      "loss": 0.0116,
      "step": 1520
    },
    {
      "epoch": 5.083056478405315,
      "grad_norm": 0.9108374118804932,
      "learning_rate": 1.4916943521594685e-05,
      "loss": 0.0085,
      "step": 1530
    },
    {
      "epoch": 5.116279069767442,
      "grad_norm": 0.5526604056358337,
      "learning_rate": 1.488372093023256e-05,
      "loss": 0.0205,
      "step": 1540
    },
    {
      "epoch": 5.149501661129568,
      "grad_norm": 0.5583625435829163,
      "learning_rate": 1.4850498338870434e-05,
      "loss": 0.006,
      "step": 1550
    },
    {
      "epoch": 5.1827242524916945,
      "grad_norm": 1.6864845752716064,
      "learning_rate": 1.4817275747508307e-05,
      "loss": 0.0055,
      "step": 1560
    },
    {
      "epoch": 5.21594684385382,
      "grad_norm": 4.093278884887695,
      "learning_rate": 1.4784053156146181e-05,
      "loss": 0.0164,
      "step": 1570
    },
    {
      "epoch": 5.249169435215947,
      "grad_norm": 2.4143900871276855,
      "learning_rate": 1.4750830564784054e-05,
      "loss": 0.0189,
      "step": 1580
    },
    {
      "epoch": 5.282392026578073,
      "grad_norm": 2.6196305751800537,
      "learning_rate": 1.4717607973421929e-05,
      "loss": 0.0098,
      "step": 1590
    },
    {
      "epoch": 5.3156146179401995,
      "grad_norm": 1.1170477867126465,
      "learning_rate": 1.4684385382059803e-05,
      "loss": 0.0119,
      "step": 1600
    },
    {
      "epoch": 5.348837209302325,
      "grad_norm": 0.3319152295589447,
      "learning_rate": 1.4651162790697674e-05,
      "loss": 0.0052,
      "step": 1610
    },
    {
      "epoch": 5.382059800664452,
      "grad_norm": 0.20783647894859314,
      "learning_rate": 1.461794019933555e-05,
      "loss": 0.014,
      "step": 1620
    },
    {
      "epoch": 5.415282392026578,
      "grad_norm": 0.9426910281181335,
      "learning_rate": 1.4584717607973422e-05,
      "loss": 0.0107,
      "step": 1630
    },
    {
      "epoch": 5.4485049833887045,
      "grad_norm": 1.8518681526184082,
      "learning_rate": 1.4551495016611296e-05,
      "loss": 0.022,
      "step": 1640
    },
    {
      "epoch": 5.48172757475083,
      "grad_norm": 0.0878225788474083,
      "learning_rate": 1.451827242524917e-05,
      "loss": 0.0072,
      "step": 1650
    },
    {
      "epoch": 5.514950166112957,
      "grad_norm": 0.3707195520401001,
      "learning_rate": 1.4485049833887043e-05,
      "loss": 0.0266,
      "step": 1660
    },
    {
      "epoch": 5.548172757475083,
      "grad_norm": 0.03600263223052025,
      "learning_rate": 1.4451827242524918e-05,
      "loss": 0.0097,
      "step": 1670
    },
    {
      "epoch": 5.5813953488372094,
      "grad_norm": 2.7519803047180176,
      "learning_rate": 1.441860465116279e-05,
      "loss": 0.0141,
      "step": 1680
    },
    {
      "epoch": 5.614617940199335,
      "grad_norm": 1.2589030265808105,
      "learning_rate": 1.4385382059800665e-05,
      "loss": 0.0155,
      "step": 1690
    },
    {
      "epoch": 5.647840531561462,
      "grad_norm": 0.6859275698661804,
      "learning_rate": 1.435215946843854e-05,
      "loss": 0.0125,
      "step": 1700
    },
    {
      "epoch": 5.681063122923588,
      "grad_norm": 1.1154987812042236,
      "learning_rate": 1.4318936877076413e-05,
      "loss": 0.0127,
      "step": 1710
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.1938273012638092,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.0132,
      "step": 1720
    },
    {
      "epoch": 5.74750830564784,
      "grad_norm": 1.001784086227417,
      "learning_rate": 1.425249169435216e-05,
      "loss": 0.0266,
      "step": 1730
    },
    {
      "epoch": 5.780730897009967,
      "grad_norm": 1.5512802600860596,
      "learning_rate": 1.4219269102990034e-05,
      "loss": 0.0274,
      "step": 1740
    },
    {
      "epoch": 5.813953488372093,
      "grad_norm": 1.5424656867980957,
      "learning_rate": 1.4186046511627909e-05,
      "loss": 0.0161,
      "step": 1750
    },
    {
      "epoch": 5.847176079734219,
      "grad_norm": 1.2274688482284546,
      "learning_rate": 1.4152823920265782e-05,
      "loss": 0.0237,
      "step": 1760
    },
    {
      "epoch": 5.880398671096345,
      "grad_norm": 0.5962274074554443,
      "learning_rate": 1.4119601328903656e-05,
      "loss": 0.0185,
      "step": 1770
    },
    {
      "epoch": 5.913621262458472,
      "grad_norm": 0.5215022563934326,
      "learning_rate": 1.4086378737541529e-05,
      "loss": 0.0135,
      "step": 1780
    },
    {
      "epoch": 5.946843853820598,
      "grad_norm": 0.9628691077232361,
      "learning_rate": 1.4053156146179404e-05,
      "loss": 0.0072,
      "step": 1790
    },
    {
      "epoch": 5.980066445182724,
      "grad_norm": 0.0153054753318429,
      "learning_rate": 1.4019933554817278e-05,
      "loss": 0.0043,
      "step": 1800
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9929748062015504,
      "eval_f1": 0.9612299465240642,
      "eval_loss": 0.027218321338295937,
      "eval_precision": 0.970310391363023,
      "eval_recall": 0.952317880794702,
      "eval_runtime": 83.3267,
      "eval_samples_per_second": 99.332,
      "eval_steps_per_second": 3.108,
      "step": 1806
    },
    {
      "epoch": 6.01328903654485,
      "grad_norm": 1.3757848739624023,
      "learning_rate": 1.3986710963455151e-05,
      "loss": 0.0105,
      "step": 1810
    },
    {
      "epoch": 6.046511627906977,
      "grad_norm": 0.8206711411476135,
      "learning_rate": 1.3953488372093025e-05,
      "loss": 0.0149,
      "step": 1820
    },
    {
      "epoch": 6.079734219269103,
      "grad_norm": 6.393817901611328,
      "learning_rate": 1.3920265780730897e-05,
      "loss": 0.015,
      "step": 1830
    },
    {
      "epoch": 6.112956810631229,
      "grad_norm": 0.09795506298542023,
      "learning_rate": 1.3887043189368771e-05,
      "loss": 0.0111,
      "step": 1840
    },
    {
      "epoch": 6.146179401993355,
      "grad_norm": 1.1023365259170532,
      "learning_rate": 1.3853820598006647e-05,
      "loss": 0.0058,
      "step": 1850
    },
    {
      "epoch": 6.179401993355482,
      "grad_norm": 0.5895736217498779,
      "learning_rate": 1.3820598006644518e-05,
      "loss": 0.0089,
      "step": 1860
    },
    {
      "epoch": 6.212624584717608,
      "grad_norm": 1.5314093828201294,
      "learning_rate": 1.3787375415282393e-05,
      "loss": 0.0084,
      "step": 1870
    },
    {
      "epoch": 6.245847176079734,
      "grad_norm": 0.17350740730762482,
      "learning_rate": 1.3754152823920266e-05,
      "loss": 0.0042,
      "step": 1880
    },
    {
      "epoch": 6.27906976744186,
      "grad_norm": 0.042579639703035355,
      "learning_rate": 1.372093023255814e-05,
      "loss": 0.0041,
      "step": 1890
    },
    {
      "epoch": 6.312292358803987,
      "grad_norm": 1.3171594142913818,
      "learning_rate": 1.3687707641196015e-05,
      "loss": 0.0053,
      "step": 1900
    },
    {
      "epoch": 6.3455149501661126,
      "grad_norm": 1.6877079010009766,
      "learning_rate": 1.3654485049833888e-05,
      "loss": 0.0188,
      "step": 1910
    },
    {
      "epoch": 6.378737541528239,
      "grad_norm": 1.0550501346588135,
      "learning_rate": 1.3621262458471762e-05,
      "loss": 0.0177,
      "step": 1920
    },
    {
      "epoch": 6.411960132890365,
      "grad_norm": 0.740364134311676,
      "learning_rate": 1.3588039867109635e-05,
      "loss": 0.012,
      "step": 1930
    },
    {
      "epoch": 6.445182724252492,
      "grad_norm": 0.048178479075431824,
      "learning_rate": 1.355481727574751e-05,
      "loss": 0.0107,
      "step": 1940
    },
    {
      "epoch": 6.4784053156146175,
      "grad_norm": 0.8968067169189453,
      "learning_rate": 1.3521594684385384e-05,
      "loss": 0.0106,
      "step": 1950
    },
    {
      "epoch": 6.511627906976744,
      "grad_norm": 1.5680538415908813,
      "learning_rate": 1.3488372093023257e-05,
      "loss": 0.0112,
      "step": 1960
    },
    {
      "epoch": 6.544850498338871,
      "grad_norm": 0.3547361493110657,
      "learning_rate": 1.3455149501661131e-05,
      "loss": 0.0095,
      "step": 1970
    },
    {
      "epoch": 6.578073089700997,
      "grad_norm": 1.3153493404388428,
      "learning_rate": 1.3421926910299004e-05,
      "loss": 0.006,
      "step": 1980
    },
    {
      "epoch": 6.6112956810631225,
      "grad_norm": 0.04558348283171654,
      "learning_rate": 1.3388704318936879e-05,
      "loss": 0.0148,
      "step": 1990
    },
    {
      "epoch": 6.644518272425249,
      "grad_norm": 0.6136278510093689,
      "learning_rate": 1.3355481727574753e-05,
      "loss": 0.0079,
      "step": 2000
    },
    {
      "epoch": 6.677740863787376,
      "grad_norm": 0.4343338906764984,
      "learning_rate": 1.3322259136212626e-05,
      "loss": 0.0103,
      "step": 2010
    },
    {
      "epoch": 6.710963455149502,
      "grad_norm": 0.4323892891407013,
      "learning_rate": 1.32890365448505e-05,
      "loss": 0.0081,
      "step": 2020
    },
    {
      "epoch": 6.7441860465116275,
      "grad_norm": 0.8861204385757446,
      "learning_rate": 1.3255813953488372e-05,
      "loss": 0.0109,
      "step": 2030
    },
    {
      "epoch": 6.777408637873754,
      "grad_norm": 1.6673917770385742,
      "learning_rate": 1.3222591362126248e-05,
      "loss": 0.0241,
      "step": 2040
    },
    {
      "epoch": 6.810631229235881,
      "grad_norm": 0.4834687113761902,
      "learning_rate": 1.3189368770764122e-05,
      "loss": 0.0082,
      "step": 2050
    },
    {
      "epoch": 6.843853820598007,
      "grad_norm": 0.14272692799568176,
      "learning_rate": 1.3156146179401993e-05,
      "loss": 0.0136,
      "step": 2060
    },
    {
      "epoch": 6.877076411960132,
      "grad_norm": 0.6091904044151306,
      "learning_rate": 1.3122923588039868e-05,
      "loss": 0.0076,
      "step": 2070
    },
    {
      "epoch": 6.910299003322259,
      "grad_norm": 0.020160231739282608,
      "learning_rate": 1.308970099667774e-05,
      "loss": 0.0037,
      "step": 2080
    },
    {
      "epoch": 6.943521594684386,
      "grad_norm": 0.8403865098953247,
      "learning_rate": 1.3056478405315615e-05,
      "loss": 0.0074,
      "step": 2090
    },
    {
      "epoch": 6.976744186046512,
      "grad_norm": 1.315066933631897,
      "learning_rate": 1.302325581395349e-05,
      "loss": 0.0114,
      "step": 2100
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9921269379844961,
      "eval_f1": 0.9555707450444293,
      "eval_loss": 0.032267142087221146,
      "eval_precision": 0.9872881355932204,
      "eval_recall": 0.9258278145695364,
      "eval_runtime": 83.3214,
      "eval_samples_per_second": 99.338,
      "eval_steps_per_second": 3.108,
      "step": 2107
    },
    {
      "epoch": 7.009966777408638,
      "grad_norm": 0.758869469165802,
      "learning_rate": 1.2990033222591363e-05,
      "loss": 0.006,
      "step": 2110
    },
    {
      "epoch": 7.043189368770764,
      "grad_norm": 0.014491397887468338,
      "learning_rate": 1.2956810631229237e-05,
      "loss": 0.0168,
      "step": 2120
    },
    {
      "epoch": 7.076411960132891,
      "grad_norm": 1.3904083967208862,
      "learning_rate": 1.292358803986711e-05,
      "loss": 0.0145,
      "step": 2130
    },
    {
      "epoch": 7.1096345514950166,
      "grad_norm": 0.4485633969306946,
      "learning_rate": 1.2890365448504984e-05,
      "loss": 0.0054,
      "step": 2140
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 1.6260156631469727,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 0.0071,
      "step": 2150
    },
    {
      "epoch": 7.176079734219269,
      "grad_norm": 0.5993172526359558,
      "learning_rate": 1.2823920265780732e-05,
      "loss": 0.0026,
      "step": 2160
    },
    {
      "epoch": 7.209302325581396,
      "grad_norm": 0.01941542886197567,
      "learning_rate": 1.2790697674418606e-05,
      "loss": 0.0077,
      "step": 2170
    },
    {
      "epoch": 7.2425249169435215,
      "grad_norm": 0.06174425780773163,
      "learning_rate": 1.2757475083056479e-05,
      "loss": 0.0082,
      "step": 2180
    },
    {
      "epoch": 7.275747508305648,
      "grad_norm": 2.8957114219665527,
      "learning_rate": 1.2724252491694354e-05,
      "loss": 0.0171,
      "step": 2190
    },
    {
      "epoch": 7.308970099667774,
      "grad_norm": 0.4836293160915375,
      "learning_rate": 1.2691029900332228e-05,
      "loss": 0.0066,
      "step": 2200
    },
    {
      "epoch": 7.342192691029901,
      "grad_norm": 1.6244003772735596,
      "learning_rate": 1.2657807308970101e-05,
      "loss": 0.0192,
      "step": 2210
    },
    {
      "epoch": 7.3754152823920265,
      "grad_norm": 0.041414495557546616,
      "learning_rate": 1.2624584717607975e-05,
      "loss": 0.0117,
      "step": 2220
    },
    {
      "epoch": 7.408637873754153,
      "grad_norm": 0.3978729844093323,
      "learning_rate": 1.2591362126245848e-05,
      "loss": 0.0066,
      "step": 2230
    },
    {
      "epoch": 7.441860465116279,
      "grad_norm": 1.6162246465682983,
      "learning_rate": 1.2558139534883723e-05,
      "loss": 0.0081,
      "step": 2240
    },
    {
      "epoch": 7.475083056478406,
      "grad_norm": 0.013669186271727085,
      "learning_rate": 1.2524916943521597e-05,
      "loss": 0.0102,
      "step": 2250
    },
    {
      "epoch": 7.5083056478405314,
      "grad_norm": 0.700053870677948,
      "learning_rate": 1.2491694352159468e-05,
      "loss": 0.0052,
      "step": 2260
    },
    {
      "epoch": 7.541528239202658,
      "grad_norm": 1.5414226055145264,
      "learning_rate": 1.2458471760797345e-05,
      "loss": 0.0104,
      "step": 2270
    },
    {
      "epoch": 7.574750830564784,
      "grad_norm": 0.009972866624593735,
      "learning_rate": 1.2425249169435216e-05,
      "loss": 0.016,
      "step": 2280
    },
    {
      "epoch": 7.607973421926911,
      "grad_norm": 0.48365798592567444,
      "learning_rate": 1.239202657807309e-05,
      "loss": 0.0037,
      "step": 2290
    },
    {
      "epoch": 7.641196013289036,
      "grad_norm": 1.2045234441757202,
      "learning_rate": 1.2358803986710965e-05,
      "loss": 0.008,
      "step": 2300
    },
    {
      "epoch": 7.674418604651163,
      "grad_norm": 1.1870553493499756,
      "learning_rate": 1.2325581395348838e-05,
      "loss": 0.0099,
      "step": 2310
    },
    {
      "epoch": 7.707641196013289,
      "grad_norm": 1.465055227279663,
      "learning_rate": 1.2292358803986712e-05,
      "loss": 0.0139,
      "step": 2320
    },
    {
      "epoch": 7.740863787375416,
      "grad_norm": 0.0362810455262661,
      "learning_rate": 1.2259136212624585e-05,
      "loss": 0.0108,
      "step": 2330
    },
    {
      "epoch": 7.774086378737541,
      "grad_norm": 0.10691708326339722,
      "learning_rate": 1.222591362126246e-05,
      "loss": 0.009,
      "step": 2340
    },
    {
      "epoch": 7.807308970099668,
      "grad_norm": 0.42387324571609497,
      "learning_rate": 1.2192691029900334e-05,
      "loss": 0.0119,
      "step": 2350
    },
    {
      "epoch": 7.840531561461794,
      "grad_norm": 0.03570859506726265,
      "learning_rate": 1.2159468438538207e-05,
      "loss": 0.0096,
      "step": 2360
    },
    {
      "epoch": 7.8737541528239205,
      "grad_norm": 0.26820528507232666,
      "learning_rate": 1.2126245847176081e-05,
      "loss": 0.0088,
      "step": 2370
    },
    {
      "epoch": 7.906976744186046,
      "grad_norm": 0.23597921431064606,
      "learning_rate": 1.2093023255813954e-05,
      "loss": 0.0069,
      "step": 2380
    },
    {
      "epoch": 7.940199335548173,
      "grad_norm": 2.7059550285339355,
      "learning_rate": 1.2059800664451829e-05,
      "loss": 0.0114,
      "step": 2390
    },
    {
      "epoch": 7.973421926910299,
      "grad_norm": 1.4429572820663452,
      "learning_rate": 1.2026578073089703e-05,
      "loss": 0.0126,
      "step": 2400
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9927325581395349,
      "eval_f1": 0.959349593495935,
      "eval_loss": 0.027805518358945847,
      "eval_precision": 0.9819694868238558,
      "eval_recall": 0.937748344370861,
      "eval_runtime": 85.1222,
      "eval_samples_per_second": 97.237,
      "eval_steps_per_second": 3.043,
      "step": 2408
    },
    {
      "epoch": 8.006644518272426,
      "grad_norm": 0.5650367736816406,
      "learning_rate": 1.1993355481727576e-05,
      "loss": 0.0107,
      "step": 2410
    },
    {
      "epoch": 8.039867109634551,
      "grad_norm": 0.16978222131729126,
      "learning_rate": 1.196013289036545e-05,
      "loss": 0.0024,
      "step": 2420
    },
    {
      "epoch": 8.073089700996677,
      "grad_norm": 0.9291473627090454,
      "learning_rate": 1.1926910299003323e-05,
      "loss": 0.0037,
      "step": 2430
    },
    {
      "epoch": 8.106312292358805,
      "grad_norm": 0.008273348212242126,
      "learning_rate": 1.1893687707641198e-05,
      "loss": 0.0092,
      "step": 2440
    },
    {
      "epoch": 8.13953488372093,
      "grad_norm": 21.81199836730957,
      "learning_rate": 1.1860465116279072e-05,
      "loss": 0.0076,
      "step": 2450
    },
    {
      "epoch": 8.172757475083056,
      "grad_norm": 0.5512803792953491,
      "learning_rate": 1.1827242524916945e-05,
      "loss": 0.0101,
      "step": 2460
    },
    {
      "epoch": 8.205980066445182,
      "grad_norm": 0.9297382831573486,
      "learning_rate": 1.179401993355482e-05,
      "loss": 0.0117,
      "step": 2470
    },
    {
      "epoch": 8.23920265780731,
      "grad_norm": 1.4895929098129272,
      "learning_rate": 1.176079734219269e-05,
      "loss": 0.0066,
      "step": 2480
    },
    {
      "epoch": 8.272425249169435,
      "grad_norm": 0.2832752466201782,
      "learning_rate": 1.1727574750830565e-05,
      "loss": 0.0071,
      "step": 2490
    },
    {
      "epoch": 8.305647840531561,
      "grad_norm": 1.783756136894226,
      "learning_rate": 1.1694352159468441e-05,
      "loss": 0.0133,
      "step": 2500
    },
    {
      "epoch": 8.338870431893687,
      "grad_norm": 0.026710549369454384,
      "learning_rate": 1.1661129568106313e-05,
      "loss": 0.0101,
      "step": 2510
    },
    {
      "epoch": 8.372093023255815,
      "grad_norm": 0.15701134502887726,
      "learning_rate": 1.1627906976744187e-05,
      "loss": 0.0054,
      "step": 2520
    },
    {
      "epoch": 8.40531561461794,
      "grad_norm": 3.612957239151001,
      "learning_rate": 1.159468438538206e-05,
      "loss": 0.0152,
      "step": 2530
    },
    {
      "epoch": 8.438538205980066,
      "grad_norm": 0.37087222933769226,
      "learning_rate": 1.1561461794019934e-05,
      "loss": 0.0049,
      "step": 2540
    },
    {
      "epoch": 8.471760797342192,
      "grad_norm": 1.0414769649505615,
      "learning_rate": 1.1528239202657807e-05,
      "loss": 0.0079,
      "step": 2550
    },
    {
      "epoch": 8.50498338870432,
      "grad_norm": 0.022524109110236168,
      "learning_rate": 1.1495016611295682e-05,
      "loss": 0.0028,
      "step": 2560
    },
    {
      "epoch": 8.538205980066445,
      "grad_norm": 0.21084216237068176,
      "learning_rate": 1.1461794019933556e-05,
      "loss": 0.0164,
      "step": 2570
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.3384452164173126,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0117,
      "step": 2580
    },
    {
      "epoch": 8.604651162790697,
      "grad_norm": 0.2019573152065277,
      "learning_rate": 1.1395348837209304e-05,
      "loss": 0.006,
      "step": 2590
    },
    {
      "epoch": 8.637873754152825,
      "grad_norm": 1.038809061050415,
      "learning_rate": 1.1362126245847176e-05,
      "loss": 0.0065,
      "step": 2600
    },
    {
      "epoch": 8.67109634551495,
      "grad_norm": 0.1254422664642334,
      "learning_rate": 1.1328903654485051e-05,
      "loss": 0.0055,
      "step": 2610
    },
    {
      "epoch": 8.704318936877076,
      "grad_norm": 0.731951892375946,
      "learning_rate": 1.1295681063122925e-05,
      "loss": 0.0082,
      "step": 2620
    },
    {
      "epoch": 8.737541528239202,
      "grad_norm": 0.46643486618995667,
      "learning_rate": 1.1262458471760798e-05,
      "loss": 0.0116,
      "step": 2630
    },
    {
      "epoch": 8.77076411960133,
      "grad_norm": 0.009150414727628231,
      "learning_rate": 1.1229235880398673e-05,
      "loss": 0.0035,
      "step": 2640
    },
    {
      "epoch": 8.803986710963455,
      "grad_norm": 0.18676847219467163,
      "learning_rate": 1.1196013289036546e-05,
      "loss": 0.0069,
      "step": 2650
    },
    {
      "epoch": 8.837209302325581,
      "grad_norm": 0.11686041951179504,
      "learning_rate": 1.116279069767442e-05,
      "loss": 0.0055,
      "step": 2660
    },
    {
      "epoch": 8.870431893687707,
      "grad_norm": 0.06080611050128937,
      "learning_rate": 1.1129568106312295e-05,
      "loss": 0.0085,
      "step": 2670
    },
    {
      "epoch": 8.903654485049834,
      "grad_norm": 0.07728844881057739,
      "learning_rate": 1.1096345514950166e-05,
      "loss": 0.0113,
      "step": 2680
    },
    {
      "epoch": 8.93687707641196,
      "grad_norm": 0.4755582809448242,
      "learning_rate": 1.1063122923588042e-05,
      "loss": 0.0056,
      "step": 2690
    },
    {
      "epoch": 8.970099667774086,
      "grad_norm": 0.03917160630226135,
      "learning_rate": 1.1029900332225913e-05,
      "loss": 0.0087,
      "step": 2700
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9927325581395349,
      "eval_f1": 0.9597855227882037,
      "eval_loss": 0.0285101979970932,
      "eval_precision": 0.9715061058344641,
      "eval_recall": 0.9483443708609272,
      "eval_runtime": 83.3196,
      "eval_samples_per_second": 99.34,
      "eval_steps_per_second": 3.109,
      "step": 2709
    },
    {
      "epoch": 9.003322259136212,
      "grad_norm": 0.5550941228866577,
      "learning_rate": 1.0996677740863788e-05,
      "loss": 0.0103,
      "step": 2710
    },
    {
      "epoch": 9.03654485049834,
      "grad_norm": 0.061923690140247345,
      "learning_rate": 1.0963455149501662e-05,
      "loss": 0.0117,
      "step": 2720
    },
    {
      "epoch": 9.069767441860465,
      "grad_norm": 3.263967514038086,
      "learning_rate": 1.0930232558139535e-05,
      "loss": 0.0085,
      "step": 2730
    },
    {
      "epoch": 9.102990033222591,
      "grad_norm": 0.19100360572338104,
      "learning_rate": 1.089700996677741e-05,
      "loss": 0.0087,
      "step": 2740
    },
    {
      "epoch": 9.136212624584717,
      "grad_norm": 0.7601972222328186,
      "learning_rate": 1.0863787375415282e-05,
      "loss": 0.008,
      "step": 2750
    },
    {
      "epoch": 9.169435215946844,
      "grad_norm": 0.5851608514785767,
      "learning_rate": 1.0830564784053157e-05,
      "loss": 0.0053,
      "step": 2760
    },
    {
      "epoch": 9.20265780730897,
      "grad_norm": 0.43931522965431213,
      "learning_rate": 1.0797342192691031e-05,
      "loss": 0.0049,
      "step": 2770
    },
    {
      "epoch": 9.235880398671096,
      "grad_norm": 0.28073087334632874,
      "learning_rate": 1.0764119601328904e-05,
      "loss": 0.008,
      "step": 2780
    },
    {
      "epoch": 9.269102990033222,
      "grad_norm": 0.5114348530769348,
      "learning_rate": 1.0730897009966779e-05,
      "loss": 0.0103,
      "step": 2790
    },
    {
      "epoch": 9.30232558139535,
      "grad_norm": 1.0606322288513184,
      "learning_rate": 1.0697674418604651e-05,
      "loss": 0.0086,
      "step": 2800
    },
    {
      "epoch": 9.335548172757475,
      "grad_norm": 0.6786002516746521,
      "learning_rate": 1.0664451827242526e-05,
      "loss": 0.0047,
      "step": 2810
    },
    {
      "epoch": 9.368770764119601,
      "grad_norm": 0.16500206291675568,
      "learning_rate": 1.06312292358804e-05,
      "loss": 0.0171,
      "step": 2820
    },
    {
      "epoch": 9.401993355481727,
      "grad_norm": 5.386471748352051,
      "learning_rate": 1.0598006644518273e-05,
      "loss": 0.0106,
      "step": 2830
    },
    {
      "epoch": 9.435215946843854,
      "grad_norm": 0.02609185315668583,
      "learning_rate": 1.0564784053156148e-05,
      "loss": 0.0093,
      "step": 2840
    },
    {
      "epoch": 9.46843853820598,
      "grad_norm": 0.6473484635353088,
      "learning_rate": 1.053156146179402e-05,
      "loss": 0.004,
      "step": 2850
    },
    {
      "epoch": 9.501661129568106,
      "grad_norm": 0.7002193331718445,
      "learning_rate": 1.0498338870431895e-05,
      "loss": 0.0071,
      "step": 2860
    },
    {
      "epoch": 9.534883720930232,
      "grad_norm": 0.8408043384552002,
      "learning_rate": 1.046511627906977e-05,
      "loss": 0.0099,
      "step": 2870
    },
    {
      "epoch": 9.56810631229236,
      "grad_norm": 0.5508329272270203,
      "learning_rate": 1.0431893687707642e-05,
      "loss": 0.0049,
      "step": 2880
    },
    {
      "epoch": 9.601328903654485,
      "grad_norm": 0.0038111750036478043,
      "learning_rate": 1.0398671096345517e-05,
      "loss": 0.0036,
      "step": 2890
    },
    {
      "epoch": 9.634551495016611,
      "grad_norm": 0.050734199583530426,
      "learning_rate": 1.0365448504983388e-05,
      "loss": 0.0072,
      "step": 2900
    },
    {
      "epoch": 9.667774086378738,
      "grad_norm": 0.3334473967552185,
      "learning_rate": 1.0332225913621262e-05,
      "loss": 0.0104,
      "step": 2910
    },
    {
      "epoch": 9.700996677740864,
      "grad_norm": 0.015441438183188438,
      "learning_rate": 1.0299003322259139e-05,
      "loss": 0.0061,
      "step": 2920
    },
    {
      "epoch": 9.73421926910299,
      "grad_norm": 0.0339469388127327,
      "learning_rate": 1.026578073089701e-05,
      "loss": 0.0039,
      "step": 2930
    },
    {
      "epoch": 9.767441860465116,
      "grad_norm": 0.003558764699846506,
      "learning_rate": 1.0232558139534884e-05,
      "loss": 0.0057,
      "step": 2940
    },
    {
      "epoch": 9.800664451827242,
      "grad_norm": 0.027196332812309265,
      "learning_rate": 1.0199335548172757e-05,
      "loss": 0.0021,
      "step": 2950
    },
    {
      "epoch": 9.83388704318937,
      "grad_norm": 0.49550682306289673,
      "learning_rate": 1.0166112956810632e-05,
      "loss": 0.0068,
      "step": 2960
    },
    {
      "epoch": 9.867109634551495,
      "grad_norm": 1.2882909774780273,
      "learning_rate": 1.0132890365448506e-05,
      "loss": 0.0121,
      "step": 2970
    },
    {
      "epoch": 9.90033222591362,
      "grad_norm": 0.7940506339073181,
      "learning_rate": 1.0099667774086379e-05,
      "loss": 0.0116,
      "step": 2980
    },
    {
      "epoch": 9.933554817275748,
      "grad_norm": 5.215190887451172,
      "learning_rate": 1.0066445182724253e-05,
      "loss": 0.008,
      "step": 2990
    },
    {
      "epoch": 9.966777408637874,
      "grad_norm": 0.020974913612008095,
      "learning_rate": 1.0033222591362126e-05,
      "loss": 0.0097,
      "step": 3000
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.16742627322673798,
      "learning_rate": 1e-05,
      "loss": 0.0025,
      "step": 3010
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9934593023255814,
      "eval_f1": 0.9635135135135136,
      "eval_loss": 0.028055476024746895,
      "eval_precision": 0.983448275862069,
      "eval_recall": 0.9443708609271523,
      "eval_runtime": 84.7411,
      "eval_samples_per_second": 97.674,
      "eval_steps_per_second": 3.056,
      "step": 3010
    }
  ],
  "logging_steps": 10,
  "max_steps": 6020,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.685064482868224e+16,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
