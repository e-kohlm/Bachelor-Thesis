{
  "best_metric": 0.9678824847504046,
  "best_model_checkpoint": "../saved_models/sql_220_ep20/checkpoint-157700",
  "epoch": 19.0,
  "eval_steps": 500,
  "global_step": 157700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00012048192771084337,
      "grad_norm": 209.3475799560547,
      "learning_rate": 1.999987951807229e-05,
      "loss": 0.8377,
      "step": 1
    },
    {
      "epoch": 0.0012048192771084338,
      "grad_norm": 36.65922546386719,
      "learning_rate": 1.9998795180722894e-05,
      "loss": 0.614,
      "step": 10
    },
    {
      "epoch": 0.0024096385542168677,
      "grad_norm": 27.97088623046875,
      "learning_rate": 1.9997590361445783e-05,
      "loss": 0.6255,
      "step": 20
    },
    {
      "epoch": 0.0036144578313253013,
      "grad_norm": 41.3354377746582,
      "learning_rate": 1.9996385542168676e-05,
      "loss": 0.5763,
      "step": 30
    },
    {
      "epoch": 0.004819277108433735,
      "grad_norm": 23.224933624267578,
      "learning_rate": 1.9995180722891568e-05,
      "loss": 0.4921,
      "step": 40
    },
    {
      "epoch": 0.006024096385542169,
      "grad_norm": 23.462873458862305,
      "learning_rate": 1.999397590361446e-05,
      "loss": 0.4938,
      "step": 50
    },
    {
      "epoch": 0.007228915662650603,
      "grad_norm": 28.192291259765625,
      "learning_rate": 1.999277108433735e-05,
      "loss": 0.5259,
      "step": 60
    },
    {
      "epoch": 0.008433734939759036,
      "grad_norm": 32.73404312133789,
      "learning_rate": 1.9991566265060242e-05,
      "loss": 0.3933,
      "step": 70
    },
    {
      "epoch": 0.00963855421686747,
      "grad_norm": 22.4926815032959,
      "learning_rate": 1.9990361445783134e-05,
      "loss": 0.5375,
      "step": 80
    },
    {
      "epoch": 0.010843373493975903,
      "grad_norm": 12.588542938232422,
      "learning_rate": 1.9989156626506027e-05,
      "loss": 0.4397,
      "step": 90
    },
    {
      "epoch": 0.012048192771084338,
      "grad_norm": 11.67897891998291,
      "learning_rate": 1.998795180722892e-05,
      "loss": 0.4124,
      "step": 100
    },
    {
      "epoch": 0.01325301204819277,
      "grad_norm": 13.662474632263184,
      "learning_rate": 1.9986746987951808e-05,
      "loss": 0.4375,
      "step": 110
    },
    {
      "epoch": 0.014457831325301205,
      "grad_norm": 11.536123275756836,
      "learning_rate": 1.99855421686747e-05,
      "loss": 0.514,
      "step": 120
    },
    {
      "epoch": 0.01566265060240964,
      "grad_norm": 12.675392150878906,
      "learning_rate": 1.998433734939759e-05,
      "loss": 0.3245,
      "step": 130
    },
    {
      "epoch": 0.016867469879518072,
      "grad_norm": 12.282200813293457,
      "learning_rate": 1.9983132530120482e-05,
      "loss": 0.44,
      "step": 140
    },
    {
      "epoch": 0.018072289156626505,
      "grad_norm": 10.934731483459473,
      "learning_rate": 1.9981927710843375e-05,
      "loss": 0.4177,
      "step": 150
    },
    {
      "epoch": 0.01927710843373494,
      "grad_norm": 11.319072723388672,
      "learning_rate": 1.9980722891566267e-05,
      "loss": 0.4854,
      "step": 160
    },
    {
      "epoch": 0.020481927710843374,
      "grad_norm": 8.834329605102539,
      "learning_rate": 1.997951807228916e-05,
      "loss": 0.4632,
      "step": 170
    },
    {
      "epoch": 0.021686746987951807,
      "grad_norm": 14.924257278442383,
      "learning_rate": 1.997831325301205e-05,
      "loss": 0.3793,
      "step": 180
    },
    {
      "epoch": 0.02289156626506024,
      "grad_norm": 13.325133323669434,
      "learning_rate": 1.997710843373494e-05,
      "loss": 0.3904,
      "step": 190
    },
    {
      "epoch": 0.024096385542168676,
      "grad_norm": 12.957111358642578,
      "learning_rate": 1.9975903614457833e-05,
      "loss": 0.5235,
      "step": 200
    },
    {
      "epoch": 0.02530120481927711,
      "grad_norm": 9.620450019836426,
      "learning_rate": 1.9974698795180726e-05,
      "loss": 0.4141,
      "step": 210
    },
    {
      "epoch": 0.02650602409638554,
      "grad_norm": 16.339563369750977,
      "learning_rate": 1.9973493975903615e-05,
      "loss": 0.4093,
      "step": 220
    },
    {
      "epoch": 0.027710843373493974,
      "grad_norm": 11.433694839477539,
      "learning_rate": 1.9972289156626507e-05,
      "loss": 0.4847,
      "step": 230
    },
    {
      "epoch": 0.02891566265060241,
      "grad_norm": 9.676135063171387,
      "learning_rate": 1.99710843373494e-05,
      "loss": 0.462,
      "step": 240
    },
    {
      "epoch": 0.030120481927710843,
      "grad_norm": 11.604212760925293,
      "learning_rate": 1.996987951807229e-05,
      "loss": 0.4389,
      "step": 250
    },
    {
      "epoch": 0.03132530120481928,
      "grad_norm": 7.3964080810546875,
      "learning_rate": 1.9968674698795185e-05,
      "loss": 0.3705,
      "step": 260
    },
    {
      "epoch": 0.03253012048192771,
      "grad_norm": 9.647323608398438,
      "learning_rate": 1.9967469879518074e-05,
      "loss": 0.3975,
      "step": 270
    },
    {
      "epoch": 0.033734939759036145,
      "grad_norm": 7.552210807800293,
      "learning_rate": 1.9966265060240966e-05,
      "loss": 0.4187,
      "step": 280
    },
    {
      "epoch": 0.03493975903614458,
      "grad_norm": 39.82370376586914,
      "learning_rate": 1.9965060240963855e-05,
      "loss": 0.3909,
      "step": 290
    },
    {
      "epoch": 0.03614457831325301,
      "grad_norm": 10.857307434082031,
      "learning_rate": 1.9963855421686748e-05,
      "loss": 0.492,
      "step": 300
    },
    {
      "epoch": 0.03734939759036145,
      "grad_norm": 10.299595832824707,
      "learning_rate": 1.996265060240964e-05,
      "loss": 0.3757,
      "step": 310
    },
    {
      "epoch": 0.03855421686746988,
      "grad_norm": 18.938549041748047,
      "learning_rate": 1.9961445783132532e-05,
      "loss": 0.333,
      "step": 320
    },
    {
      "epoch": 0.03975903614457831,
      "grad_norm": 24.51485252380371,
      "learning_rate": 1.9960240963855425e-05,
      "loss": 0.3842,
      "step": 330
    },
    {
      "epoch": 0.04096385542168675,
      "grad_norm": 10.726198196411133,
      "learning_rate": 1.9959036144578314e-05,
      "loss": 0.3751,
      "step": 340
    },
    {
      "epoch": 0.04216867469879518,
      "grad_norm": 9.778447151184082,
      "learning_rate": 1.9957831325301206e-05,
      "loss": 0.4554,
      "step": 350
    },
    {
      "epoch": 0.043373493975903614,
      "grad_norm": 6.194700717926025,
      "learning_rate": 1.99566265060241e-05,
      "loss": 0.4255,
      "step": 360
    },
    {
      "epoch": 0.04457831325301205,
      "grad_norm": 8.109296798706055,
      "learning_rate": 1.995542168674699e-05,
      "loss": 0.4475,
      "step": 370
    },
    {
      "epoch": 0.04578313253012048,
      "grad_norm": 17.475536346435547,
      "learning_rate": 1.9954216867469884e-05,
      "loss": 0.4073,
      "step": 380
    },
    {
      "epoch": 0.046987951807228916,
      "grad_norm": 7.559347629547119,
      "learning_rate": 1.9953012048192773e-05,
      "loss": 0.3849,
      "step": 390
    },
    {
      "epoch": 0.04819277108433735,
      "grad_norm": 7.5281524658203125,
      "learning_rate": 1.9951807228915665e-05,
      "loss": 0.4065,
      "step": 400
    },
    {
      "epoch": 0.04939759036144578,
      "grad_norm": 9.222676277160645,
      "learning_rate": 1.9950602409638554e-05,
      "loss": 0.4692,
      "step": 410
    },
    {
      "epoch": 0.05060240963855422,
      "grad_norm": 10.036189079284668,
      "learning_rate": 1.9949397590361447e-05,
      "loss": 0.4301,
      "step": 420
    },
    {
      "epoch": 0.051807228915662654,
      "grad_norm": 6.1654181480407715,
      "learning_rate": 1.994819277108434e-05,
      "loss": 0.3254,
      "step": 430
    },
    {
      "epoch": 0.05301204819277108,
      "grad_norm": 6.703424453735352,
      "learning_rate": 1.994698795180723e-05,
      "loss": 0.3598,
      "step": 440
    },
    {
      "epoch": 0.05421686746987952,
      "grad_norm": 8.566176414489746,
      "learning_rate": 1.9945783132530124e-05,
      "loss": 0.3913,
      "step": 450
    },
    {
      "epoch": 0.05542168674698795,
      "grad_norm": 5.047896385192871,
      "learning_rate": 1.9944578313253013e-05,
      "loss": 0.3282,
      "step": 460
    },
    {
      "epoch": 0.056626506024096385,
      "grad_norm": 6.294164657592773,
      "learning_rate": 1.9943373493975905e-05,
      "loss": 0.3843,
      "step": 470
    },
    {
      "epoch": 0.05783132530120482,
      "grad_norm": 5.9642462730407715,
      "learning_rate": 1.9942168674698798e-05,
      "loss": 0.3474,
      "step": 480
    },
    {
      "epoch": 0.05903614457831325,
      "grad_norm": 5.40649938583374,
      "learning_rate": 1.994096385542169e-05,
      "loss": 0.4027,
      "step": 490
    },
    {
      "epoch": 0.060240963855421686,
      "grad_norm": 12.929044723510742,
      "learning_rate": 1.993975903614458e-05,
      "loss": 0.2648,
      "step": 500
    },
    {
      "epoch": 0.06144578313253012,
      "grad_norm": 6.803095817565918,
      "learning_rate": 1.9938554216867472e-05,
      "loss": 0.3742,
      "step": 510
    },
    {
      "epoch": 0.06265060240963856,
      "grad_norm": 5.044974327087402,
      "learning_rate": 1.993734939759036e-05,
      "loss": 0.3952,
      "step": 520
    },
    {
      "epoch": 0.06385542168674699,
      "grad_norm": 5.442347049713135,
      "learning_rate": 1.9936144578313253e-05,
      "loss": 0.327,
      "step": 530
    },
    {
      "epoch": 0.06506024096385542,
      "grad_norm": 6.232551097869873,
      "learning_rate": 1.9934939759036146e-05,
      "loss": 0.3713,
      "step": 540
    },
    {
      "epoch": 0.06626506024096386,
      "grad_norm": 11.219928741455078,
      "learning_rate": 1.9933734939759038e-05,
      "loss": 0.3595,
      "step": 550
    },
    {
      "epoch": 0.06746987951807229,
      "grad_norm": 5.111512184143066,
      "learning_rate": 1.993253012048193e-05,
      "loss": 0.3784,
      "step": 560
    },
    {
      "epoch": 0.06867469879518072,
      "grad_norm": 5.723125457763672,
      "learning_rate": 1.993132530120482e-05,
      "loss": 0.3335,
      "step": 570
    },
    {
      "epoch": 0.06987951807228916,
      "grad_norm": 5.574950218200684,
      "learning_rate": 1.9930120481927712e-05,
      "loss": 0.3878,
      "step": 580
    },
    {
      "epoch": 0.07108433734939759,
      "grad_norm": 6.186993598937988,
      "learning_rate": 1.9928915662650604e-05,
      "loss": 0.4003,
      "step": 590
    },
    {
      "epoch": 0.07228915662650602,
      "grad_norm": 6.427992343902588,
      "learning_rate": 1.9927710843373497e-05,
      "loss": 0.3842,
      "step": 600
    },
    {
      "epoch": 0.07349397590361446,
      "grad_norm": 7.0360612869262695,
      "learning_rate": 1.992650602409639e-05,
      "loss": 0.3749,
      "step": 610
    },
    {
      "epoch": 0.0746987951807229,
      "grad_norm": 7.749406337738037,
      "learning_rate": 1.992530120481928e-05,
      "loss": 0.4262,
      "step": 620
    },
    {
      "epoch": 0.07590361445783132,
      "grad_norm": 6.725709915161133,
      "learning_rate": 1.992409638554217e-05,
      "loss": 0.3914,
      "step": 630
    },
    {
      "epoch": 0.07710843373493977,
      "grad_norm": 9.429703712463379,
      "learning_rate": 1.992289156626506e-05,
      "loss": 0.35,
      "step": 640
    },
    {
      "epoch": 0.0783132530120482,
      "grad_norm": 4.877102375030518,
      "learning_rate": 1.9921686746987952e-05,
      "loss": 0.3472,
      "step": 650
    },
    {
      "epoch": 0.07951807228915662,
      "grad_norm": 5.968548774719238,
      "learning_rate": 1.9920481927710845e-05,
      "loss": 0.3415,
      "step": 660
    },
    {
      "epoch": 0.08072289156626505,
      "grad_norm": 9.552096366882324,
      "learning_rate": 1.9919277108433737e-05,
      "loss": 0.416,
      "step": 670
    },
    {
      "epoch": 0.0819277108433735,
      "grad_norm": 57.881134033203125,
      "learning_rate": 1.991807228915663e-05,
      "loss": 0.3366,
      "step": 680
    },
    {
      "epoch": 0.08313253012048193,
      "grad_norm": 5.989663124084473,
      "learning_rate": 1.991686746987952e-05,
      "loss": 0.3502,
      "step": 690
    },
    {
      "epoch": 0.08433734939759036,
      "grad_norm": 9.381383895874023,
      "learning_rate": 1.991566265060241e-05,
      "loss": 0.3567,
      "step": 700
    },
    {
      "epoch": 0.0855421686746988,
      "grad_norm": 7.534895896911621,
      "learning_rate": 1.9914457831325304e-05,
      "loss": 0.3368,
      "step": 710
    },
    {
      "epoch": 0.08674698795180723,
      "grad_norm": 8.780378341674805,
      "learning_rate": 1.9913253012048196e-05,
      "loss": 0.3809,
      "step": 720
    },
    {
      "epoch": 0.08795180722891566,
      "grad_norm": 6.563659191131592,
      "learning_rate": 1.9912048192771085e-05,
      "loss": 0.35,
      "step": 730
    },
    {
      "epoch": 0.0891566265060241,
      "grad_norm": 9.467942237854004,
      "learning_rate": 1.9910843373493977e-05,
      "loss": 0.3406,
      "step": 740
    },
    {
      "epoch": 0.09036144578313253,
      "grad_norm": 6.066725254058838,
      "learning_rate": 1.990963855421687e-05,
      "loss": 0.284,
      "step": 750
    },
    {
      "epoch": 0.09156626506024096,
      "grad_norm": 8.402745246887207,
      "learning_rate": 1.990843373493976e-05,
      "loss": 0.3122,
      "step": 760
    },
    {
      "epoch": 0.0927710843373494,
      "grad_norm": 3.7653870582580566,
      "learning_rate": 1.990722891566265e-05,
      "loss": 0.3667,
      "step": 770
    },
    {
      "epoch": 0.09397590361445783,
      "grad_norm": 5.537988185882568,
      "learning_rate": 1.9906024096385544e-05,
      "loss": 0.2838,
      "step": 780
    },
    {
      "epoch": 0.09518072289156626,
      "grad_norm": 10.715914726257324,
      "learning_rate": 1.9904819277108436e-05,
      "loss": 0.3007,
      "step": 790
    },
    {
      "epoch": 0.0963855421686747,
      "grad_norm": 24.200693130493164,
      "learning_rate": 1.9903614457831325e-05,
      "loss": 0.4152,
      "step": 800
    },
    {
      "epoch": 0.09759036144578313,
      "grad_norm": 9.190744400024414,
      "learning_rate": 1.9902409638554218e-05,
      "loss": 0.3859,
      "step": 810
    },
    {
      "epoch": 0.09879518072289156,
      "grad_norm": 6.042938232421875,
      "learning_rate": 1.990120481927711e-05,
      "loss": 0.3381,
      "step": 820
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.6051480770111084,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.2894,
      "step": 830
    },
    {
      "epoch": 0.10120481927710843,
      "grad_norm": 9.541036605834961,
      "learning_rate": 1.9898795180722895e-05,
      "loss": 0.4184,
      "step": 840
    },
    {
      "epoch": 0.10240963855421686,
      "grad_norm": 7.248474597930908,
      "learning_rate": 1.9897590361445784e-05,
      "loss": 0.3932,
      "step": 850
    },
    {
      "epoch": 0.10361445783132531,
      "grad_norm": 10.700417518615723,
      "learning_rate": 1.9896385542168677e-05,
      "loss": 0.3242,
      "step": 860
    },
    {
      "epoch": 0.10481927710843374,
      "grad_norm": 9.239469528198242,
      "learning_rate": 1.9895180722891566e-05,
      "loss": 0.3259,
      "step": 870
    },
    {
      "epoch": 0.10602409638554217,
      "grad_norm": 11.060022354125977,
      "learning_rate": 1.989397590361446e-05,
      "loss": 0.2966,
      "step": 880
    },
    {
      "epoch": 0.10722891566265061,
      "grad_norm": 8.818878173828125,
      "learning_rate": 1.989277108433735e-05,
      "loss": 0.3972,
      "step": 890
    },
    {
      "epoch": 0.10843373493975904,
      "grad_norm": 9.244625091552734,
      "learning_rate": 1.9891566265060243e-05,
      "loss": 0.3438,
      "step": 900
    },
    {
      "epoch": 0.10963855421686747,
      "grad_norm": 4.7718586921691895,
      "learning_rate": 1.9890361445783135e-05,
      "loss": 0.3775,
      "step": 910
    },
    {
      "epoch": 0.1108433734939759,
      "grad_norm": 5.210428714752197,
      "learning_rate": 1.9889156626506024e-05,
      "loss": 0.2976,
      "step": 920
    },
    {
      "epoch": 0.11204819277108434,
      "grad_norm": 8.211617469787598,
      "learning_rate": 1.9887951807228917e-05,
      "loss": 0.3915,
      "step": 930
    },
    {
      "epoch": 0.11325301204819277,
      "grad_norm": 9.972460746765137,
      "learning_rate": 1.988674698795181e-05,
      "loss": 0.3653,
      "step": 940
    },
    {
      "epoch": 0.1144578313253012,
      "grad_norm": 4.473834037780762,
      "learning_rate": 1.98855421686747e-05,
      "loss": 0.3429,
      "step": 950
    },
    {
      "epoch": 0.11566265060240964,
      "grad_norm": 4.156335353851318,
      "learning_rate": 1.988433734939759e-05,
      "loss": 0.2824,
      "step": 960
    },
    {
      "epoch": 0.11686746987951807,
      "grad_norm": 5.051581382751465,
      "learning_rate": 1.9883132530120483e-05,
      "loss": 0.3756,
      "step": 970
    },
    {
      "epoch": 0.1180722891566265,
      "grad_norm": 8.92639446258545,
      "learning_rate": 1.9881927710843376e-05,
      "loss": 0.3057,
      "step": 980
    },
    {
      "epoch": 0.11927710843373494,
      "grad_norm": 9.271384239196777,
      "learning_rate": 1.9880722891566268e-05,
      "loss": 0.3785,
      "step": 990
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 9.6682767868042,
      "learning_rate": 1.987951807228916e-05,
      "loss": 0.3284,
      "step": 1000
    },
    {
      "epoch": 0.1216867469879518,
      "grad_norm": 5.388803005218506,
      "learning_rate": 1.987831325301205e-05,
      "loss": 0.341,
      "step": 1010
    },
    {
      "epoch": 0.12289156626506025,
      "grad_norm": 4.612754821777344,
      "learning_rate": 1.9877108433734942e-05,
      "loss": 0.2761,
      "step": 1020
    },
    {
      "epoch": 0.12409638554216867,
      "grad_norm": 5.3525872230529785,
      "learning_rate": 1.987590361445783e-05,
      "loss": 0.3323,
      "step": 1030
    },
    {
      "epoch": 0.12530120481927712,
      "grad_norm": 3.6840057373046875,
      "learning_rate": 1.9874698795180723e-05,
      "loss": 0.2738,
      "step": 1040
    },
    {
      "epoch": 0.12650602409638553,
      "grad_norm": 6.333548545837402,
      "learning_rate": 1.9873493975903616e-05,
      "loss": 0.3841,
      "step": 1050
    },
    {
      "epoch": 0.12771084337349398,
      "grad_norm": 4.706873416900635,
      "learning_rate": 1.9872289156626508e-05,
      "loss": 0.3355,
      "step": 1060
    },
    {
      "epoch": 0.12891566265060242,
      "grad_norm": 5.184473991394043,
      "learning_rate": 1.98710843373494e-05,
      "loss": 0.3231,
      "step": 1070
    },
    {
      "epoch": 0.13012048192771083,
      "grad_norm": 5.5266313552856445,
      "learning_rate": 1.986987951807229e-05,
      "loss": 0.262,
      "step": 1080
    },
    {
      "epoch": 0.13132530120481928,
      "grad_norm": 4.749505043029785,
      "learning_rate": 1.9868674698795182e-05,
      "loss": 0.3602,
      "step": 1090
    },
    {
      "epoch": 0.13253012048192772,
      "grad_norm": 5.586100101470947,
      "learning_rate": 1.9867469879518075e-05,
      "loss": 0.2428,
      "step": 1100
    },
    {
      "epoch": 0.13373493975903614,
      "grad_norm": 2.7581441402435303,
      "learning_rate": 1.9866265060240967e-05,
      "loss": 0.3304,
      "step": 1110
    },
    {
      "epoch": 0.13493975903614458,
      "grad_norm": 3.93198299407959,
      "learning_rate": 1.9865060240963856e-05,
      "loss": 0.3282,
      "step": 1120
    },
    {
      "epoch": 0.13614457831325302,
      "grad_norm": 5.708624362945557,
      "learning_rate": 1.986385542168675e-05,
      "loss": 0.294,
      "step": 1130
    },
    {
      "epoch": 0.13734939759036144,
      "grad_norm": 5.967503547668457,
      "learning_rate": 1.986265060240964e-05,
      "loss": 0.3106,
      "step": 1140
    },
    {
      "epoch": 0.13855421686746988,
      "grad_norm": 1.692975401878357,
      "learning_rate": 1.986144578313253e-05,
      "loss": 0.2858,
      "step": 1150
    },
    {
      "epoch": 0.13975903614457832,
      "grad_norm": 5.0606794357299805,
      "learning_rate": 1.9860240963855422e-05,
      "loss": 0.3386,
      "step": 1160
    },
    {
      "epoch": 0.14096385542168674,
      "grad_norm": 6.57637357711792,
      "learning_rate": 1.9859036144578315e-05,
      "loss": 0.3018,
      "step": 1170
    },
    {
      "epoch": 0.14216867469879518,
      "grad_norm": 6.785553455352783,
      "learning_rate": 1.9857831325301207e-05,
      "loss": 0.3083,
      "step": 1180
    },
    {
      "epoch": 0.14337349397590363,
      "grad_norm": 6.976491451263428,
      "learning_rate": 1.9856626506024096e-05,
      "loss": 0.3748,
      "step": 1190
    },
    {
      "epoch": 0.14457831325301204,
      "grad_norm": 6.958546161651611,
      "learning_rate": 1.985542168674699e-05,
      "loss": 0.2577,
      "step": 1200
    },
    {
      "epoch": 0.14578313253012049,
      "grad_norm": 9.06004810333252,
      "learning_rate": 1.985421686746988e-05,
      "loss": 0.3332,
      "step": 1210
    },
    {
      "epoch": 0.14698795180722893,
      "grad_norm": 3.9863600730895996,
      "learning_rate": 1.9853012048192774e-05,
      "loss": 0.2845,
      "step": 1220
    },
    {
      "epoch": 0.14819277108433734,
      "grad_norm": 12.513943672180176,
      "learning_rate": 1.9851807228915666e-05,
      "loss": 0.2932,
      "step": 1230
    },
    {
      "epoch": 0.1493975903614458,
      "grad_norm": 4.752933025360107,
      "learning_rate": 1.9850602409638555e-05,
      "loss": 0.263,
      "step": 1240
    },
    {
      "epoch": 0.15060240963855423,
      "grad_norm": 5.903966426849365,
      "learning_rate": 1.9849397590361448e-05,
      "loss": 0.3,
      "step": 1250
    },
    {
      "epoch": 0.15180722891566265,
      "grad_norm": 7.361249923706055,
      "learning_rate": 1.9848192771084337e-05,
      "loss": 0.3606,
      "step": 1260
    },
    {
      "epoch": 0.1530120481927711,
      "grad_norm": 4.823094367980957,
      "learning_rate": 1.984698795180723e-05,
      "loss": 0.287,
      "step": 1270
    },
    {
      "epoch": 0.15421686746987953,
      "grad_norm": 4.548890590667725,
      "learning_rate": 1.984578313253012e-05,
      "loss": 0.2927,
      "step": 1280
    },
    {
      "epoch": 0.15542168674698795,
      "grad_norm": 3.8933942317962646,
      "learning_rate": 1.9844578313253014e-05,
      "loss": 0.3143,
      "step": 1290
    },
    {
      "epoch": 0.1566265060240964,
      "grad_norm": 6.434521198272705,
      "learning_rate": 1.9843373493975906e-05,
      "loss": 0.3798,
      "step": 1300
    },
    {
      "epoch": 0.1578313253012048,
      "grad_norm": 5.730830192565918,
      "learning_rate": 1.9842168674698795e-05,
      "loss": 0.2642,
      "step": 1310
    },
    {
      "epoch": 0.15903614457831325,
      "grad_norm": 5.682042598724365,
      "learning_rate": 1.9840963855421688e-05,
      "loss": 0.2922,
      "step": 1320
    },
    {
      "epoch": 0.1602409638554217,
      "grad_norm": 6.436285018920898,
      "learning_rate": 1.983975903614458e-05,
      "loss": 0.3478,
      "step": 1330
    },
    {
      "epoch": 0.1614457831325301,
      "grad_norm": 3.5028510093688965,
      "learning_rate": 1.9838554216867473e-05,
      "loss": 0.275,
      "step": 1340
    },
    {
      "epoch": 0.16265060240963855,
      "grad_norm": 5.601451873779297,
      "learning_rate": 1.9837349397590365e-05,
      "loss": 0.281,
      "step": 1350
    },
    {
      "epoch": 0.163855421686747,
      "grad_norm": 8.378414154052734,
      "learning_rate": 1.9836144578313254e-05,
      "loss": 0.2993,
      "step": 1360
    },
    {
      "epoch": 0.1650602409638554,
      "grad_norm": 10.417424201965332,
      "learning_rate": 1.9834939759036147e-05,
      "loss": 0.3424,
      "step": 1370
    },
    {
      "epoch": 0.16626506024096385,
      "grad_norm": 6.707812309265137,
      "learning_rate": 1.9833734939759036e-05,
      "loss": 0.3226,
      "step": 1380
    },
    {
      "epoch": 0.1674698795180723,
      "grad_norm": 4.92775821685791,
      "learning_rate": 1.9832530120481928e-05,
      "loss": 0.229,
      "step": 1390
    },
    {
      "epoch": 0.1686746987951807,
      "grad_norm": 4.783202171325684,
      "learning_rate": 1.983132530120482e-05,
      "loss": 0.2016,
      "step": 1400
    },
    {
      "epoch": 0.16987951807228915,
      "grad_norm": 4.650494575500488,
      "learning_rate": 1.9830120481927713e-05,
      "loss": 0.3124,
      "step": 1410
    },
    {
      "epoch": 0.1710843373493976,
      "grad_norm": 5.524905204772949,
      "learning_rate": 1.9828915662650602e-05,
      "loss": 0.322,
      "step": 1420
    },
    {
      "epoch": 0.172289156626506,
      "grad_norm": 4.615020275115967,
      "learning_rate": 1.9827710843373494e-05,
      "loss": 0.2951,
      "step": 1430
    },
    {
      "epoch": 0.17349397590361446,
      "grad_norm": 3.8789868354797363,
      "learning_rate": 1.9826506024096387e-05,
      "loss": 0.2902,
      "step": 1440
    },
    {
      "epoch": 0.1746987951807229,
      "grad_norm": 7.477490425109863,
      "learning_rate": 1.982530120481928e-05,
      "loss": 0.2882,
      "step": 1450
    },
    {
      "epoch": 0.17590361445783131,
      "grad_norm": 6.169371128082275,
      "learning_rate": 1.9824096385542172e-05,
      "loss": 0.2586,
      "step": 1460
    },
    {
      "epoch": 0.17710843373493976,
      "grad_norm": 6.820685386657715,
      "learning_rate": 1.982289156626506e-05,
      "loss": 0.3346,
      "step": 1470
    },
    {
      "epoch": 0.1783132530120482,
      "grad_norm": 3.979588270187378,
      "learning_rate": 1.9821686746987953e-05,
      "loss": 0.2335,
      "step": 1480
    },
    {
      "epoch": 0.17951807228915662,
      "grad_norm": 7.407918930053711,
      "learning_rate": 1.9820481927710842e-05,
      "loss": 0.2713,
      "step": 1490
    },
    {
      "epoch": 0.18072289156626506,
      "grad_norm": 3.3751022815704346,
      "learning_rate": 1.9819277108433738e-05,
      "loss": 0.3944,
      "step": 1500
    },
    {
      "epoch": 0.1819277108433735,
      "grad_norm": 4.163174152374268,
      "learning_rate": 1.981807228915663e-05,
      "loss": 0.26,
      "step": 1510
    },
    {
      "epoch": 0.18313253012048192,
      "grad_norm": 4.896415710449219,
      "learning_rate": 1.981686746987952e-05,
      "loss": 0.293,
      "step": 1520
    },
    {
      "epoch": 0.18433734939759036,
      "grad_norm": 4.84314489364624,
      "learning_rate": 1.9815662650602412e-05,
      "loss": 0.2624,
      "step": 1530
    },
    {
      "epoch": 0.1855421686746988,
      "grad_norm": 6.185014724731445,
      "learning_rate": 1.98144578313253e-05,
      "loss": 0.2664,
      "step": 1540
    },
    {
      "epoch": 0.18674698795180722,
      "grad_norm": 2.1936657428741455,
      "learning_rate": 1.9813253012048194e-05,
      "loss": 0.2247,
      "step": 1550
    },
    {
      "epoch": 0.18795180722891566,
      "grad_norm": 5.378252983093262,
      "learning_rate": 1.9812048192771086e-05,
      "loss": 0.2724,
      "step": 1560
    },
    {
      "epoch": 0.1891566265060241,
      "grad_norm": 8.600713729858398,
      "learning_rate": 1.981084337349398e-05,
      "loss": 0.3284,
      "step": 1570
    },
    {
      "epoch": 0.19036144578313252,
      "grad_norm": 8.17628002166748,
      "learning_rate": 1.980963855421687e-05,
      "loss": 0.3247,
      "step": 1580
    },
    {
      "epoch": 0.19156626506024096,
      "grad_norm": 6.984397888183594,
      "learning_rate": 1.980843373493976e-05,
      "loss": 0.3526,
      "step": 1590
    },
    {
      "epoch": 0.1927710843373494,
      "grad_norm": 5.503075122833252,
      "learning_rate": 1.9807228915662652e-05,
      "loss": 0.2693,
      "step": 1600
    },
    {
      "epoch": 0.19397590361445782,
      "grad_norm": 3.707395076751709,
      "learning_rate": 1.9806024096385545e-05,
      "loss": 0.2459,
      "step": 1610
    },
    {
      "epoch": 0.19518072289156627,
      "grad_norm": 6.680890083312988,
      "learning_rate": 1.9804819277108437e-05,
      "loss": 0.2352,
      "step": 1620
    },
    {
      "epoch": 0.1963855421686747,
      "grad_norm": 5.948465347290039,
      "learning_rate": 1.9803614457831326e-05,
      "loss": 0.2145,
      "step": 1630
    },
    {
      "epoch": 0.19759036144578312,
      "grad_norm": 12.956674575805664,
      "learning_rate": 1.980240963855422e-05,
      "loss": 0.2261,
      "step": 1640
    },
    {
      "epoch": 0.19879518072289157,
      "grad_norm": 7.314193248748779,
      "learning_rate": 1.980120481927711e-05,
      "loss": 0.3079,
      "step": 1650
    },
    {
      "epoch": 0.2,
      "grad_norm": 5.037179470062256,
      "learning_rate": 1.98e-05,
      "loss": 0.2021,
      "step": 1660
    },
    {
      "epoch": 0.20120481927710843,
      "grad_norm": 8.394803047180176,
      "learning_rate": 1.9798795180722893e-05,
      "loss": 0.2433,
      "step": 1670
    },
    {
      "epoch": 0.20240963855421687,
      "grad_norm": 4.009634494781494,
      "learning_rate": 1.9797590361445785e-05,
      "loss": 0.2301,
      "step": 1680
    },
    {
      "epoch": 0.2036144578313253,
      "grad_norm": 8.078652381896973,
      "learning_rate": 1.9796385542168677e-05,
      "loss": 0.3041,
      "step": 1690
    },
    {
      "epoch": 0.20481927710843373,
      "grad_norm": 5.681157112121582,
      "learning_rate": 1.9795180722891567e-05,
      "loss": 0.3024,
      "step": 1700
    },
    {
      "epoch": 0.20602409638554217,
      "grad_norm": 2.7607486248016357,
      "learning_rate": 1.979397590361446e-05,
      "loss": 0.2692,
      "step": 1710
    },
    {
      "epoch": 0.20722891566265061,
      "grad_norm": 4.668206691741943,
      "learning_rate": 1.979277108433735e-05,
      "loss": 0.2958,
      "step": 1720
    },
    {
      "epoch": 0.20843373493975903,
      "grad_norm": 3.9810597896575928,
      "learning_rate": 1.9791566265060244e-05,
      "loss": 0.2256,
      "step": 1730
    },
    {
      "epoch": 0.20963855421686747,
      "grad_norm": 7.8509840965271,
      "learning_rate": 1.9790361445783136e-05,
      "loss": 0.243,
      "step": 1740
    },
    {
      "epoch": 0.21084337349397592,
      "grad_norm": 6.532614707946777,
      "learning_rate": 1.9789156626506025e-05,
      "loss": 0.2752,
      "step": 1750
    },
    {
      "epoch": 0.21204819277108433,
      "grad_norm": 3.5350215435028076,
      "learning_rate": 1.9787951807228918e-05,
      "loss": 0.2733,
      "step": 1760
    },
    {
      "epoch": 0.21325301204819277,
      "grad_norm": 6.752880096435547,
      "learning_rate": 1.9786746987951807e-05,
      "loss": 0.2802,
      "step": 1770
    },
    {
      "epoch": 0.21445783132530122,
      "grad_norm": 7.294417858123779,
      "learning_rate": 1.97855421686747e-05,
      "loss": 0.2856,
      "step": 1780
    },
    {
      "epoch": 0.21566265060240963,
      "grad_norm": 4.327044486999512,
      "learning_rate": 1.978433734939759e-05,
      "loss": 0.207,
      "step": 1790
    },
    {
      "epoch": 0.21686746987951808,
      "grad_norm": 6.893344402313232,
      "learning_rate": 1.9783132530120484e-05,
      "loss": 0.2272,
      "step": 1800
    },
    {
      "epoch": 0.21807228915662652,
      "grad_norm": 5.426517963409424,
      "learning_rate": 1.9781927710843377e-05,
      "loss": 0.2257,
      "step": 1810
    },
    {
      "epoch": 0.21927710843373494,
      "grad_norm": 4.517172813415527,
      "learning_rate": 1.9780722891566266e-05,
      "loss": 0.2752,
      "step": 1820
    },
    {
      "epoch": 0.22048192771084338,
      "grad_norm": 3.7492494583129883,
      "learning_rate": 1.9779518072289158e-05,
      "loss": 0.193,
      "step": 1830
    },
    {
      "epoch": 0.2216867469879518,
      "grad_norm": 5.418063163757324,
      "learning_rate": 1.977831325301205e-05,
      "loss": 0.3092,
      "step": 1840
    },
    {
      "epoch": 0.22289156626506024,
      "grad_norm": 4.578001976013184,
      "learning_rate": 1.9777108433734943e-05,
      "loss": 0.2356,
      "step": 1850
    },
    {
      "epoch": 0.22409638554216868,
      "grad_norm": 7.898558616638184,
      "learning_rate": 1.9775903614457832e-05,
      "loss": 0.3124,
      "step": 1860
    },
    {
      "epoch": 0.2253012048192771,
      "grad_norm": 2.056591749191284,
      "learning_rate": 1.9774698795180724e-05,
      "loss": 0.25,
      "step": 1870
    },
    {
      "epoch": 0.22650602409638554,
      "grad_norm": 2.5206263065338135,
      "learning_rate": 1.9773493975903617e-05,
      "loss": 0.2236,
      "step": 1880
    },
    {
      "epoch": 0.22771084337349398,
      "grad_norm": 4.519252300262451,
      "learning_rate": 1.9772289156626506e-05,
      "loss": 0.1916,
      "step": 1890
    },
    {
      "epoch": 0.2289156626506024,
      "grad_norm": 2.8288919925689697,
      "learning_rate": 1.9771084337349398e-05,
      "loss": 0.2543,
      "step": 1900
    },
    {
      "epoch": 0.23012048192771084,
      "grad_norm": 9.883304595947266,
      "learning_rate": 1.976987951807229e-05,
      "loss": 0.1986,
      "step": 1910
    },
    {
      "epoch": 0.23132530120481928,
      "grad_norm": 10.017342567443848,
      "learning_rate": 1.9768674698795183e-05,
      "loss": 0.3207,
      "step": 1920
    },
    {
      "epoch": 0.2325301204819277,
      "grad_norm": 4.503760814666748,
      "learning_rate": 1.9767469879518072e-05,
      "loss": 0.2115,
      "step": 1930
    },
    {
      "epoch": 0.23373493975903614,
      "grad_norm": 4.4425506591796875,
      "learning_rate": 1.9766265060240965e-05,
      "loss": 0.204,
      "step": 1940
    },
    {
      "epoch": 0.23493975903614459,
      "grad_norm": 4.090939521789551,
      "learning_rate": 1.9765060240963857e-05,
      "loss": 0.205,
      "step": 1950
    },
    {
      "epoch": 0.236144578313253,
      "grad_norm": 13.590270042419434,
      "learning_rate": 1.976385542168675e-05,
      "loss": 0.3481,
      "step": 1960
    },
    {
      "epoch": 0.23734939759036144,
      "grad_norm": 10.587804794311523,
      "learning_rate": 1.9762650602409642e-05,
      "loss": 0.2649,
      "step": 1970
    },
    {
      "epoch": 0.2385542168674699,
      "grad_norm": 5.537717342376709,
      "learning_rate": 1.976144578313253e-05,
      "loss": 0.2189,
      "step": 1980
    },
    {
      "epoch": 0.2397590361445783,
      "grad_norm": 7.190089225769043,
      "learning_rate": 1.9760240963855423e-05,
      "loss": 0.2881,
      "step": 1990
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 4.416627407073975,
      "learning_rate": 1.9759036144578312e-05,
      "loss": 0.2849,
      "step": 2000
    },
    {
      "epoch": 0.2421686746987952,
      "grad_norm": 5.103978633880615,
      "learning_rate": 1.9757831325301208e-05,
      "loss": 0.26,
      "step": 2010
    },
    {
      "epoch": 0.2433734939759036,
      "grad_norm": 4.838071346282959,
      "learning_rate": 1.9756626506024097e-05,
      "loss": 0.2435,
      "step": 2020
    },
    {
      "epoch": 0.24457831325301205,
      "grad_norm": 4.913070201873779,
      "learning_rate": 1.975542168674699e-05,
      "loss": 0.2481,
      "step": 2030
    },
    {
      "epoch": 0.2457831325301205,
      "grad_norm": 2.3702392578125,
      "learning_rate": 1.9754216867469882e-05,
      "loss": 0.1671,
      "step": 2040
    },
    {
      "epoch": 0.2469879518072289,
      "grad_norm": 7.820551872253418,
      "learning_rate": 1.975301204819277e-05,
      "loss": 0.2372,
      "step": 2050
    },
    {
      "epoch": 0.24819277108433735,
      "grad_norm": 4.288348197937012,
      "learning_rate": 1.9751807228915664e-05,
      "loss": 0.2539,
      "step": 2060
    },
    {
      "epoch": 0.2493975903614458,
      "grad_norm": 5.6101579666137695,
      "learning_rate": 1.9750602409638556e-05,
      "loss": 0.2355,
      "step": 2070
    },
    {
      "epoch": 0.25060240963855424,
      "grad_norm": 10.473999977111816,
      "learning_rate": 1.974939759036145e-05,
      "loss": 0.2612,
      "step": 2080
    },
    {
      "epoch": 0.25180722891566265,
      "grad_norm": 3.9856507778167725,
      "learning_rate": 1.9748192771084338e-05,
      "loss": 0.2276,
      "step": 2090
    },
    {
      "epoch": 0.25301204819277107,
      "grad_norm": 7.354068756103516,
      "learning_rate": 1.974698795180723e-05,
      "loss": 0.2726,
      "step": 2100
    },
    {
      "epoch": 0.25421686746987954,
      "grad_norm": 3.5366814136505127,
      "learning_rate": 1.9745783132530122e-05,
      "loss": 0.2178,
      "step": 2110
    },
    {
      "epoch": 0.25542168674698795,
      "grad_norm": 7.394397258758545,
      "learning_rate": 1.9744578313253015e-05,
      "loss": 0.2952,
      "step": 2120
    },
    {
      "epoch": 0.25662650602409637,
      "grad_norm": 6.97020959854126,
      "learning_rate": 1.9743373493975907e-05,
      "loss": 0.3192,
      "step": 2130
    },
    {
      "epoch": 0.25783132530120484,
      "grad_norm": 5.525989055633545,
      "learning_rate": 1.9742168674698796e-05,
      "loss": 0.1991,
      "step": 2140
    },
    {
      "epoch": 0.25903614457831325,
      "grad_norm": 1.7170592546463013,
      "learning_rate": 1.974096385542169e-05,
      "loss": 0.1977,
      "step": 2150
    },
    {
      "epoch": 0.26024096385542167,
      "grad_norm": 7.149861812591553,
      "learning_rate": 1.9739759036144578e-05,
      "loss": 0.2507,
      "step": 2160
    },
    {
      "epoch": 0.26144578313253014,
      "grad_norm": 2.7266457080841064,
      "learning_rate": 1.973855421686747e-05,
      "loss": 0.1885,
      "step": 2170
    },
    {
      "epoch": 0.26265060240963856,
      "grad_norm": 3.3303141593933105,
      "learning_rate": 1.9737349397590363e-05,
      "loss": 0.3014,
      "step": 2180
    },
    {
      "epoch": 0.26385542168674697,
      "grad_norm": 9.815354347229004,
      "learning_rate": 1.9736144578313255e-05,
      "loss": 0.2446,
      "step": 2190
    },
    {
      "epoch": 0.26506024096385544,
      "grad_norm": 6.407270431518555,
      "learning_rate": 1.9734939759036148e-05,
      "loss": 0.2425,
      "step": 2200
    },
    {
      "epoch": 0.26626506024096386,
      "grad_norm": 9.429924011230469,
      "learning_rate": 1.9733734939759037e-05,
      "loss": 0.2598,
      "step": 2210
    },
    {
      "epoch": 0.2674698795180723,
      "grad_norm": 5.438996315002441,
      "learning_rate": 1.973253012048193e-05,
      "loss": 0.2336,
      "step": 2220
    },
    {
      "epoch": 0.26867469879518074,
      "grad_norm": 6.805614471435547,
      "learning_rate": 1.973132530120482e-05,
      "loss": 0.1801,
      "step": 2230
    },
    {
      "epoch": 0.26987951807228916,
      "grad_norm": 4.446132183074951,
      "learning_rate": 1.9730120481927714e-05,
      "loss": 0.2096,
      "step": 2240
    },
    {
      "epoch": 0.2710843373493976,
      "grad_norm": 8.383830070495605,
      "learning_rate": 1.9728915662650606e-05,
      "loss": 0.2313,
      "step": 2250
    },
    {
      "epoch": 0.27228915662650605,
      "grad_norm": 5.82224178314209,
      "learning_rate": 1.9727710843373495e-05,
      "loss": 0.2434,
      "step": 2260
    },
    {
      "epoch": 0.27349397590361446,
      "grad_norm": 8.058565139770508,
      "learning_rate": 1.9726506024096388e-05,
      "loss": 0.2441,
      "step": 2270
    },
    {
      "epoch": 0.2746987951807229,
      "grad_norm": 5.722517013549805,
      "learning_rate": 1.9725301204819277e-05,
      "loss": 0.2435,
      "step": 2280
    },
    {
      "epoch": 0.27590361445783135,
      "grad_norm": 2.1558523178100586,
      "learning_rate": 1.972409638554217e-05,
      "loss": 0.2696,
      "step": 2290
    },
    {
      "epoch": 0.27710843373493976,
      "grad_norm": 8.021764755249023,
      "learning_rate": 1.9722891566265062e-05,
      "loss": 0.2095,
      "step": 2300
    },
    {
      "epoch": 0.2783132530120482,
      "grad_norm": 7.583634376525879,
      "learning_rate": 1.9721686746987954e-05,
      "loss": 0.2858,
      "step": 2310
    },
    {
      "epoch": 0.27951807228915665,
      "grad_norm": 16.271467208862305,
      "learning_rate": 1.9720481927710843e-05,
      "loss": 0.2681,
      "step": 2320
    },
    {
      "epoch": 0.28072289156626506,
      "grad_norm": 5.737725734710693,
      "learning_rate": 1.9719277108433736e-05,
      "loss": 0.2561,
      "step": 2330
    },
    {
      "epoch": 0.2819277108433735,
      "grad_norm": 4.526088237762451,
      "learning_rate": 1.9718072289156628e-05,
      "loss": 0.2195,
      "step": 2340
    },
    {
      "epoch": 0.28313253012048195,
      "grad_norm": 8.647102355957031,
      "learning_rate": 1.971686746987952e-05,
      "loss": 0.3896,
      "step": 2350
    },
    {
      "epoch": 0.28433734939759037,
      "grad_norm": 5.6413960456848145,
      "learning_rate": 1.9715662650602413e-05,
      "loss": 0.2645,
      "step": 2360
    },
    {
      "epoch": 0.2855421686746988,
      "grad_norm": 4.120798110961914,
      "learning_rate": 1.9714457831325302e-05,
      "loss": 0.3207,
      "step": 2370
    },
    {
      "epoch": 0.28674698795180725,
      "grad_norm": 8.353277206420898,
      "learning_rate": 1.9713253012048194e-05,
      "loss": 0.1487,
      "step": 2380
    },
    {
      "epoch": 0.28795180722891567,
      "grad_norm": 4.648031234741211,
      "learning_rate": 1.9712048192771084e-05,
      "loss": 0.1646,
      "step": 2390
    },
    {
      "epoch": 0.2891566265060241,
      "grad_norm": 7.590013027191162,
      "learning_rate": 1.9710843373493976e-05,
      "loss": 0.2918,
      "step": 2400
    },
    {
      "epoch": 0.29036144578313255,
      "grad_norm": 0.8634942173957825,
      "learning_rate": 1.970963855421687e-05,
      "loss": 0.1759,
      "step": 2410
    },
    {
      "epoch": 0.29156626506024097,
      "grad_norm": 6.390968322753906,
      "learning_rate": 1.970843373493976e-05,
      "loss": 0.3141,
      "step": 2420
    },
    {
      "epoch": 0.2927710843373494,
      "grad_norm": 5.997228145599365,
      "learning_rate": 1.9707228915662653e-05,
      "loss": 0.2639,
      "step": 2430
    },
    {
      "epoch": 0.29397590361445786,
      "grad_norm": 3.3914661407470703,
      "learning_rate": 1.9706024096385542e-05,
      "loss": 0.1484,
      "step": 2440
    },
    {
      "epoch": 0.29518072289156627,
      "grad_norm": 5.518786907196045,
      "learning_rate": 1.9704819277108435e-05,
      "loss": 0.1943,
      "step": 2450
    },
    {
      "epoch": 0.2963855421686747,
      "grad_norm": 6.094580173492432,
      "learning_rate": 1.9703614457831327e-05,
      "loss": 0.2959,
      "step": 2460
    },
    {
      "epoch": 0.29759036144578316,
      "grad_norm": 7.675774574279785,
      "learning_rate": 1.970240963855422e-05,
      "loss": 0.1279,
      "step": 2470
    },
    {
      "epoch": 0.2987951807228916,
      "grad_norm": 5.916298866271973,
      "learning_rate": 1.9701204819277112e-05,
      "loss": 0.1972,
      "step": 2480
    },
    {
      "epoch": 0.3,
      "grad_norm": 9.48336410522461,
      "learning_rate": 1.97e-05,
      "loss": 0.1926,
      "step": 2490
    },
    {
      "epoch": 0.30120481927710846,
      "grad_norm": 9.758838653564453,
      "learning_rate": 1.9698795180722894e-05,
      "loss": 0.2475,
      "step": 2500
    },
    {
      "epoch": 0.3024096385542169,
      "grad_norm": 4.924459934234619,
      "learning_rate": 1.9697590361445783e-05,
      "loss": 0.2049,
      "step": 2510
    },
    {
      "epoch": 0.3036144578313253,
      "grad_norm": 6.5713701248168945,
      "learning_rate": 1.9696385542168675e-05,
      "loss": 0.1604,
      "step": 2520
    },
    {
      "epoch": 0.30481927710843376,
      "grad_norm": 5.396618843078613,
      "learning_rate": 1.9695180722891567e-05,
      "loss": 0.2269,
      "step": 2530
    },
    {
      "epoch": 0.3060240963855422,
      "grad_norm": 2.1558291912078857,
      "learning_rate": 1.969397590361446e-05,
      "loss": 0.1896,
      "step": 2540
    },
    {
      "epoch": 0.3072289156626506,
      "grad_norm": 7.135453224182129,
      "learning_rate": 1.9692771084337352e-05,
      "loss": 0.1686,
      "step": 2550
    },
    {
      "epoch": 0.30843373493975906,
      "grad_norm": 6.231138706207275,
      "learning_rate": 1.969156626506024e-05,
      "loss": 0.1953,
      "step": 2560
    },
    {
      "epoch": 0.3096385542168675,
      "grad_norm": 2.339733839035034,
      "learning_rate": 1.9690361445783134e-05,
      "loss": 0.2205,
      "step": 2570
    },
    {
      "epoch": 0.3108433734939759,
      "grad_norm": 5.448953151702881,
      "learning_rate": 1.9689156626506026e-05,
      "loss": 0.1796,
      "step": 2580
    },
    {
      "epoch": 0.31204819277108437,
      "grad_norm": 2.7454609870910645,
      "learning_rate": 1.968795180722892e-05,
      "loss": 0.2543,
      "step": 2590
    },
    {
      "epoch": 0.3132530120481928,
      "grad_norm": 2.921215534210205,
      "learning_rate": 1.9686746987951808e-05,
      "loss": 0.2105,
      "step": 2600
    },
    {
      "epoch": 0.3144578313253012,
      "grad_norm": 6.322086811065674,
      "learning_rate": 1.96855421686747e-05,
      "loss": 0.2196,
      "step": 2610
    },
    {
      "epoch": 0.3156626506024096,
      "grad_norm": 7.986087799072266,
      "learning_rate": 1.968433734939759e-05,
      "loss": 0.1918,
      "step": 2620
    },
    {
      "epoch": 0.3168674698795181,
      "grad_norm": 4.402784824371338,
      "learning_rate": 1.9683132530120485e-05,
      "loss": 0.1704,
      "step": 2630
    },
    {
      "epoch": 0.3180722891566265,
      "grad_norm": 4.830630779266357,
      "learning_rate": 1.9681927710843377e-05,
      "loss": 0.1886,
      "step": 2640
    },
    {
      "epoch": 0.3192771084337349,
      "grad_norm": 6.192324638366699,
      "learning_rate": 1.9680722891566267e-05,
      "loss": 0.339,
      "step": 2650
    },
    {
      "epoch": 0.3204819277108434,
      "grad_norm": 9.064906120300293,
      "learning_rate": 1.967951807228916e-05,
      "loss": 0.2175,
      "step": 2660
    },
    {
      "epoch": 0.3216867469879518,
      "grad_norm": 4.633318901062012,
      "learning_rate": 1.9678313253012048e-05,
      "loss": 0.2582,
      "step": 2670
    },
    {
      "epoch": 0.3228915662650602,
      "grad_norm": 8.747060775756836,
      "learning_rate": 1.967710843373494e-05,
      "loss": 0.1716,
      "step": 2680
    },
    {
      "epoch": 0.3240963855421687,
      "grad_norm": 6.680285930633545,
      "learning_rate": 1.9675903614457833e-05,
      "loss": 0.2042,
      "step": 2690
    },
    {
      "epoch": 0.3253012048192771,
      "grad_norm": 4.6252875328063965,
      "learning_rate": 1.9674698795180725e-05,
      "loss": 0.2376,
      "step": 2700
    },
    {
      "epoch": 0.3265060240963855,
      "grad_norm": 4.407909393310547,
      "learning_rate": 1.9673493975903618e-05,
      "loss": 0.2002,
      "step": 2710
    },
    {
      "epoch": 0.327710843373494,
      "grad_norm": 6.577251434326172,
      "learning_rate": 1.9672289156626507e-05,
      "loss": 0.233,
      "step": 2720
    },
    {
      "epoch": 0.3289156626506024,
      "grad_norm": 4.676155090332031,
      "learning_rate": 1.96710843373494e-05,
      "loss": 0.198,
      "step": 2730
    },
    {
      "epoch": 0.3301204819277108,
      "grad_norm": 3.3640317916870117,
      "learning_rate": 1.966987951807229e-05,
      "loss": 0.1432,
      "step": 2740
    },
    {
      "epoch": 0.3313253012048193,
      "grad_norm": 7.826514720916748,
      "learning_rate": 1.9668674698795184e-05,
      "loss": 0.2329,
      "step": 2750
    },
    {
      "epoch": 0.3325301204819277,
      "grad_norm": 4.03766393661499,
      "learning_rate": 1.9667469879518073e-05,
      "loss": 0.1806,
      "step": 2760
    },
    {
      "epoch": 0.3337349397590361,
      "grad_norm": 2.0377449989318848,
      "learning_rate": 1.9666265060240966e-05,
      "loss": 0.1314,
      "step": 2770
    },
    {
      "epoch": 0.3349397590361446,
      "grad_norm": 6.8860931396484375,
      "learning_rate": 1.9665060240963858e-05,
      "loss": 0.2262,
      "step": 2780
    },
    {
      "epoch": 0.336144578313253,
      "grad_norm": 8.189950942993164,
      "learning_rate": 1.9663855421686747e-05,
      "loss": 0.2156,
      "step": 2790
    },
    {
      "epoch": 0.3373493975903614,
      "grad_norm": 1.206676721572876,
      "learning_rate": 1.966265060240964e-05,
      "loss": 0.1724,
      "step": 2800
    },
    {
      "epoch": 0.3385542168674699,
      "grad_norm": 6.3315510749816895,
      "learning_rate": 1.9661445783132532e-05,
      "loss": 0.2424,
      "step": 2810
    },
    {
      "epoch": 0.3397590361445783,
      "grad_norm": 5.162638187408447,
      "learning_rate": 1.9660240963855424e-05,
      "loss": 0.1847,
      "step": 2820
    },
    {
      "epoch": 0.3409638554216867,
      "grad_norm": 4.301449775695801,
      "learning_rate": 1.9659036144578313e-05,
      "loss": 0.2874,
      "step": 2830
    },
    {
      "epoch": 0.3421686746987952,
      "grad_norm": 4.451272964477539,
      "learning_rate": 1.9657831325301206e-05,
      "loss": 0.1738,
      "step": 2840
    },
    {
      "epoch": 0.3433734939759036,
      "grad_norm": 6.379962921142578,
      "learning_rate": 1.9656626506024098e-05,
      "loss": 0.2488,
      "step": 2850
    },
    {
      "epoch": 0.344578313253012,
      "grad_norm": 4.554980754852295,
      "learning_rate": 1.965542168674699e-05,
      "loss": 0.1587,
      "step": 2860
    },
    {
      "epoch": 0.3457831325301205,
      "grad_norm": 13.636862754821777,
      "learning_rate": 1.9654216867469883e-05,
      "loss": 0.249,
      "step": 2870
    },
    {
      "epoch": 0.3469879518072289,
      "grad_norm": 4.606515407562256,
      "learning_rate": 1.9653012048192772e-05,
      "loss": 0.1444,
      "step": 2880
    },
    {
      "epoch": 0.3481927710843373,
      "grad_norm": 7.640784740447998,
      "learning_rate": 1.9651807228915665e-05,
      "loss": 0.1985,
      "step": 2890
    },
    {
      "epoch": 0.3493975903614458,
      "grad_norm": 8.479676246643066,
      "learning_rate": 1.9650602409638554e-05,
      "loss": 0.2296,
      "step": 2900
    },
    {
      "epoch": 0.3506024096385542,
      "grad_norm": 6.856158256530762,
      "learning_rate": 1.9649397590361446e-05,
      "loss": 0.151,
      "step": 2910
    },
    {
      "epoch": 0.35180722891566263,
      "grad_norm": 6.4296345710754395,
      "learning_rate": 1.964819277108434e-05,
      "loss": 0.1548,
      "step": 2920
    },
    {
      "epoch": 0.3530120481927711,
      "grad_norm": 9.952505111694336,
      "learning_rate": 1.964698795180723e-05,
      "loss": 0.168,
      "step": 2930
    },
    {
      "epoch": 0.3542168674698795,
      "grad_norm": 8.601162910461426,
      "learning_rate": 1.9645783132530123e-05,
      "loss": 0.1706,
      "step": 2940
    },
    {
      "epoch": 0.35542168674698793,
      "grad_norm": 4.628542423248291,
      "learning_rate": 1.9644578313253012e-05,
      "loss": 0.2426,
      "step": 2950
    },
    {
      "epoch": 0.3566265060240964,
      "grad_norm": 7.287530899047852,
      "learning_rate": 1.9643373493975905e-05,
      "loss": 0.1686,
      "step": 2960
    },
    {
      "epoch": 0.3578313253012048,
      "grad_norm": 13.239800453186035,
      "learning_rate": 1.9642168674698797e-05,
      "loss": 0.1662,
      "step": 2970
    },
    {
      "epoch": 0.35903614457831323,
      "grad_norm": 17.567773818969727,
      "learning_rate": 1.964096385542169e-05,
      "loss": 0.3125,
      "step": 2980
    },
    {
      "epoch": 0.3602409638554217,
      "grad_norm": 4.852194786071777,
      "learning_rate": 1.963975903614458e-05,
      "loss": 0.2071,
      "step": 2990
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 16.87782096862793,
      "learning_rate": 1.963855421686747e-05,
      "loss": 0.2354,
      "step": 3000
    },
    {
      "epoch": 0.36265060240963853,
      "grad_norm": 8.02447509765625,
      "learning_rate": 1.9637349397590364e-05,
      "loss": 0.2155,
      "step": 3010
    },
    {
      "epoch": 0.363855421686747,
      "grad_norm": 3.3899147510528564,
      "learning_rate": 1.9636144578313253e-05,
      "loss": 0.1644,
      "step": 3020
    },
    {
      "epoch": 0.3650602409638554,
      "grad_norm": 5.666131973266602,
      "learning_rate": 1.9634939759036145e-05,
      "loss": 0.1918,
      "step": 3030
    },
    {
      "epoch": 0.36626506024096384,
      "grad_norm": 6.675487041473389,
      "learning_rate": 1.9633734939759038e-05,
      "loss": 0.1485,
      "step": 3040
    },
    {
      "epoch": 0.3674698795180723,
      "grad_norm": 6.779360771179199,
      "learning_rate": 1.963253012048193e-05,
      "loss": 0.1909,
      "step": 3050
    },
    {
      "epoch": 0.3686746987951807,
      "grad_norm": 6.114617824554443,
      "learning_rate": 1.963132530120482e-05,
      "loss": 0.2425,
      "step": 3060
    },
    {
      "epoch": 0.36987951807228914,
      "grad_norm": 3.927216053009033,
      "learning_rate": 1.963012048192771e-05,
      "loss": 0.1928,
      "step": 3070
    },
    {
      "epoch": 0.3710843373493976,
      "grad_norm": 3.847665548324585,
      "learning_rate": 1.9628915662650604e-05,
      "loss": 0.2173,
      "step": 3080
    },
    {
      "epoch": 0.372289156626506,
      "grad_norm": 2.3367960453033447,
      "learning_rate": 1.9627710843373496e-05,
      "loss": 0.1296,
      "step": 3090
    },
    {
      "epoch": 0.37349397590361444,
      "grad_norm": 9.355798721313477,
      "learning_rate": 1.962650602409639e-05,
      "loss": 0.2496,
      "step": 3100
    },
    {
      "epoch": 0.3746987951807229,
      "grad_norm": 1.461919903755188,
      "learning_rate": 1.9625301204819278e-05,
      "loss": 0.1827,
      "step": 3110
    },
    {
      "epoch": 0.3759036144578313,
      "grad_norm": 2.5319759845733643,
      "learning_rate": 1.962409638554217e-05,
      "loss": 0.1606,
      "step": 3120
    },
    {
      "epoch": 0.37710843373493974,
      "grad_norm": 3.811074733734131,
      "learning_rate": 1.962289156626506e-05,
      "loss": 0.1407,
      "step": 3130
    },
    {
      "epoch": 0.3783132530120482,
      "grad_norm": 10.679401397705078,
      "learning_rate": 1.9621686746987955e-05,
      "loss": 0.2501,
      "step": 3140
    },
    {
      "epoch": 0.3795180722891566,
      "grad_norm": 1.242680311203003,
      "learning_rate": 1.9620481927710848e-05,
      "loss": 0.2,
      "step": 3150
    },
    {
      "epoch": 0.38072289156626504,
      "grad_norm": 7.646875381469727,
      "learning_rate": 1.9619277108433737e-05,
      "loss": 0.1698,
      "step": 3160
    },
    {
      "epoch": 0.3819277108433735,
      "grad_norm": 4.191728115081787,
      "learning_rate": 1.961807228915663e-05,
      "loss": 0.1664,
      "step": 3170
    },
    {
      "epoch": 0.38313253012048193,
      "grad_norm": 4.822400093078613,
      "learning_rate": 1.9616867469879518e-05,
      "loss": 0.1769,
      "step": 3180
    },
    {
      "epoch": 0.38433734939759034,
      "grad_norm": 4.6483683586120605,
      "learning_rate": 1.961566265060241e-05,
      "loss": 0.1254,
      "step": 3190
    },
    {
      "epoch": 0.3855421686746988,
      "grad_norm": 6.102412700653076,
      "learning_rate": 1.9614457831325303e-05,
      "loss": 0.2215,
      "step": 3200
    },
    {
      "epoch": 0.38674698795180723,
      "grad_norm": 5.284730911254883,
      "learning_rate": 1.9613253012048195e-05,
      "loss": 0.177,
      "step": 3210
    },
    {
      "epoch": 0.38795180722891565,
      "grad_norm": 4.622721195220947,
      "learning_rate": 1.9612048192771085e-05,
      "loss": 0.1921,
      "step": 3220
    },
    {
      "epoch": 0.3891566265060241,
      "grad_norm": 6.08381462097168,
      "learning_rate": 1.9610843373493977e-05,
      "loss": 0.1777,
      "step": 3230
    },
    {
      "epoch": 0.39036144578313253,
      "grad_norm": 6.532538414001465,
      "learning_rate": 1.960963855421687e-05,
      "loss": 0.1823,
      "step": 3240
    },
    {
      "epoch": 0.39156626506024095,
      "grad_norm": 4.910064697265625,
      "learning_rate": 1.9608433734939762e-05,
      "loss": 0.158,
      "step": 3250
    },
    {
      "epoch": 0.3927710843373494,
      "grad_norm": 3.701158046722412,
      "learning_rate": 1.9607228915662654e-05,
      "loss": 0.1789,
      "step": 3260
    },
    {
      "epoch": 0.39397590361445783,
      "grad_norm": 7.850135803222656,
      "learning_rate": 1.9606024096385543e-05,
      "loss": 0.2057,
      "step": 3270
    },
    {
      "epoch": 0.39518072289156625,
      "grad_norm": 2.0051043033599854,
      "learning_rate": 1.9604819277108436e-05,
      "loss": 0.1687,
      "step": 3280
    },
    {
      "epoch": 0.3963855421686747,
      "grad_norm": 3.577333688735962,
      "learning_rate": 1.9603614457831325e-05,
      "loss": 0.1731,
      "step": 3290
    },
    {
      "epoch": 0.39759036144578314,
      "grad_norm": 2.124788284301758,
      "learning_rate": 1.9602409638554217e-05,
      "loss": 0.1705,
      "step": 3300
    },
    {
      "epoch": 0.39879518072289155,
      "grad_norm": 2.48362398147583,
      "learning_rate": 1.960120481927711e-05,
      "loss": 0.1204,
      "step": 3310
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.552556037902832,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.2326,
      "step": 3320
    },
    {
      "epoch": 0.40120481927710844,
      "grad_norm": 3.7874085903167725,
      "learning_rate": 1.9598795180722895e-05,
      "loss": 0.2083,
      "step": 3330
    },
    {
      "epoch": 0.40240963855421685,
      "grad_norm": 4.364932060241699,
      "learning_rate": 1.9597590361445784e-05,
      "loss": 0.1282,
      "step": 3340
    },
    {
      "epoch": 0.4036144578313253,
      "grad_norm": 12.638575553894043,
      "learning_rate": 1.9596385542168676e-05,
      "loss": 0.1961,
      "step": 3350
    },
    {
      "epoch": 0.40481927710843374,
      "grad_norm": 5.661779403686523,
      "learning_rate": 1.959518072289157e-05,
      "loss": 0.2279,
      "step": 3360
    },
    {
      "epoch": 0.40602409638554215,
      "grad_norm": 5.726842880249023,
      "learning_rate": 1.959397590361446e-05,
      "loss": 0.145,
      "step": 3370
    },
    {
      "epoch": 0.4072289156626506,
      "grad_norm": 2.7206854820251465,
      "learning_rate": 1.9592771084337353e-05,
      "loss": 0.1245,
      "step": 3380
    },
    {
      "epoch": 0.40843373493975904,
      "grad_norm": 5.363507270812988,
      "learning_rate": 1.9591566265060242e-05,
      "loss": 0.1898,
      "step": 3390
    },
    {
      "epoch": 0.40963855421686746,
      "grad_norm": 6.229284286499023,
      "learning_rate": 1.9590361445783135e-05,
      "loss": 0.217,
      "step": 3400
    },
    {
      "epoch": 0.4108433734939759,
      "grad_norm": 6.787223815917969,
      "learning_rate": 1.9589156626506024e-05,
      "loss": 0.2434,
      "step": 3410
    },
    {
      "epoch": 0.41204819277108434,
      "grad_norm": 1.9536277055740356,
      "learning_rate": 1.9587951807228916e-05,
      "loss": 0.1232,
      "step": 3420
    },
    {
      "epoch": 0.41325301204819276,
      "grad_norm": 7.74945068359375,
      "learning_rate": 1.958674698795181e-05,
      "loss": 0.2088,
      "step": 3430
    },
    {
      "epoch": 0.41445783132530123,
      "grad_norm": 9.296302795410156,
      "learning_rate": 1.95855421686747e-05,
      "loss": 0.1688,
      "step": 3440
    },
    {
      "epoch": 0.41566265060240964,
      "grad_norm": 5.689276695251465,
      "learning_rate": 1.9584337349397594e-05,
      "loss": 0.169,
      "step": 3450
    },
    {
      "epoch": 0.41686746987951806,
      "grad_norm": 3.545854330062866,
      "learning_rate": 1.9583132530120483e-05,
      "loss": 0.1565,
      "step": 3460
    },
    {
      "epoch": 0.41807228915662653,
      "grad_norm": 10.147520065307617,
      "learning_rate": 1.9581927710843375e-05,
      "loss": 0.2033,
      "step": 3470
    },
    {
      "epoch": 0.41927710843373495,
      "grad_norm": 3.403691530227661,
      "learning_rate": 1.9580722891566267e-05,
      "loss": 0.1668,
      "step": 3480
    },
    {
      "epoch": 0.42048192771084336,
      "grad_norm": 9.856075286865234,
      "learning_rate": 1.957951807228916e-05,
      "loss": 0.1578,
      "step": 3490
    },
    {
      "epoch": 0.42168674698795183,
      "grad_norm": 7.735556125640869,
      "learning_rate": 1.957831325301205e-05,
      "loss": 0.1591,
      "step": 3500
    },
    {
      "epoch": 0.42289156626506025,
      "grad_norm": 6.411710739135742,
      "learning_rate": 1.957710843373494e-05,
      "loss": 0.2026,
      "step": 3510
    },
    {
      "epoch": 0.42409638554216866,
      "grad_norm": 7.564389228820801,
      "learning_rate": 1.957590361445783e-05,
      "loss": 0.1491,
      "step": 3520
    },
    {
      "epoch": 0.42530120481927713,
      "grad_norm": 8.281396865844727,
      "learning_rate": 1.9574698795180723e-05,
      "loss": 0.1826,
      "step": 3530
    },
    {
      "epoch": 0.42650602409638555,
      "grad_norm": 4.701836585998535,
      "learning_rate": 1.9573493975903615e-05,
      "loss": 0.2132,
      "step": 3540
    },
    {
      "epoch": 0.42771084337349397,
      "grad_norm": 8.823370933532715,
      "learning_rate": 1.9572289156626508e-05,
      "loss": 0.1679,
      "step": 3550
    },
    {
      "epoch": 0.42891566265060244,
      "grad_norm": 3.6513185501098633,
      "learning_rate": 1.95710843373494e-05,
      "loss": 0.1462,
      "step": 3560
    },
    {
      "epoch": 0.43012048192771085,
      "grad_norm": 4.972492694854736,
      "learning_rate": 1.956987951807229e-05,
      "loss": 0.1309,
      "step": 3570
    },
    {
      "epoch": 0.43132530120481927,
      "grad_norm": 4.270527362823486,
      "learning_rate": 1.956867469879518e-05,
      "loss": 0.1864,
      "step": 3580
    },
    {
      "epoch": 0.43253012048192774,
      "grad_norm": 8.799943923950195,
      "learning_rate": 1.9567469879518074e-05,
      "loss": 0.2622,
      "step": 3590
    },
    {
      "epoch": 0.43373493975903615,
      "grad_norm": 1.6883469820022583,
      "learning_rate": 1.9566265060240967e-05,
      "loss": 0.1612,
      "step": 3600
    },
    {
      "epoch": 0.43493975903614457,
      "grad_norm": 8.976516723632812,
      "learning_rate": 1.956506024096386e-05,
      "loss": 0.1934,
      "step": 3610
    },
    {
      "epoch": 0.43614457831325304,
      "grad_norm": 4.09304666519165,
      "learning_rate": 1.9563855421686748e-05,
      "loss": 0.158,
      "step": 3620
    },
    {
      "epoch": 0.43734939759036146,
      "grad_norm": 4.05919885635376,
      "learning_rate": 1.956265060240964e-05,
      "loss": 0.1352,
      "step": 3630
    },
    {
      "epoch": 0.43855421686746987,
      "grad_norm": 4.883019924163818,
      "learning_rate": 1.956144578313253e-05,
      "loss": 0.251,
      "step": 3640
    },
    {
      "epoch": 0.4397590361445783,
      "grad_norm": 6.725109577178955,
      "learning_rate": 1.9560240963855422e-05,
      "loss": 0.2131,
      "step": 3650
    },
    {
      "epoch": 0.44096385542168676,
      "grad_norm": 4.189682960510254,
      "learning_rate": 1.9559036144578314e-05,
      "loss": 0.1844,
      "step": 3660
    },
    {
      "epoch": 0.44216867469879517,
      "grad_norm": 8.594695091247559,
      "learning_rate": 1.9557831325301207e-05,
      "loss": 0.2115,
      "step": 3670
    },
    {
      "epoch": 0.4433734939759036,
      "grad_norm": 4.468864440917969,
      "learning_rate": 1.95566265060241e-05,
      "loss": 0.1704,
      "step": 3680
    },
    {
      "epoch": 0.44457831325301206,
      "grad_norm": 2.6765990257263184,
      "learning_rate": 1.9555421686746988e-05,
      "loss": 0.2321,
      "step": 3690
    },
    {
      "epoch": 0.4457831325301205,
      "grad_norm": 6.127477645874023,
      "learning_rate": 1.955421686746988e-05,
      "loss": 0.1454,
      "step": 3700
    },
    {
      "epoch": 0.4469879518072289,
      "grad_norm": 6.372844696044922,
      "learning_rate": 1.9553012048192773e-05,
      "loss": 0.1985,
      "step": 3710
    },
    {
      "epoch": 0.44819277108433736,
      "grad_norm": 0.46135058999061584,
      "learning_rate": 1.9551807228915666e-05,
      "loss": 0.1827,
      "step": 3720
    },
    {
      "epoch": 0.4493975903614458,
      "grad_norm": 10.00780200958252,
      "learning_rate": 1.9550602409638555e-05,
      "loss": 0.1914,
      "step": 3730
    },
    {
      "epoch": 0.4506024096385542,
      "grad_norm": 8.156390190124512,
      "learning_rate": 1.9549397590361447e-05,
      "loss": 0.2813,
      "step": 3740
    },
    {
      "epoch": 0.45180722891566266,
      "grad_norm": 2.2378594875335693,
      "learning_rate": 1.954819277108434e-05,
      "loss": 0.1481,
      "step": 3750
    },
    {
      "epoch": 0.4530120481927711,
      "grad_norm": 5.085168838500977,
      "learning_rate": 1.9546987951807232e-05,
      "loss": 0.1346,
      "step": 3760
    },
    {
      "epoch": 0.4542168674698795,
      "grad_norm": 5.688279151916504,
      "learning_rate": 1.9545783132530124e-05,
      "loss": 0.1724,
      "step": 3770
    },
    {
      "epoch": 0.45542168674698796,
      "grad_norm": 4.463139057159424,
      "learning_rate": 1.9544578313253013e-05,
      "loss": 0.168,
      "step": 3780
    },
    {
      "epoch": 0.4566265060240964,
      "grad_norm": 3.5847983360290527,
      "learning_rate": 1.9543373493975906e-05,
      "loss": 0.2023,
      "step": 3790
    },
    {
      "epoch": 0.4578313253012048,
      "grad_norm": 4.076661109924316,
      "learning_rate": 1.9542168674698795e-05,
      "loss": 0.1138,
      "step": 3800
    },
    {
      "epoch": 0.45903614457831327,
      "grad_norm": 5.8142499923706055,
      "learning_rate": 1.9540963855421687e-05,
      "loss": 0.1981,
      "step": 3810
    },
    {
      "epoch": 0.4602409638554217,
      "grad_norm": 6.931551933288574,
      "learning_rate": 1.953975903614458e-05,
      "loss": 0.2401,
      "step": 3820
    },
    {
      "epoch": 0.4614457831325301,
      "grad_norm": 3.4542808532714844,
      "learning_rate": 1.9538554216867472e-05,
      "loss": 0.1748,
      "step": 3830
    },
    {
      "epoch": 0.46265060240963857,
      "grad_norm": 5.8541460037231445,
      "learning_rate": 1.9537349397590365e-05,
      "loss": 0.199,
      "step": 3840
    },
    {
      "epoch": 0.463855421686747,
      "grad_norm": 1.1763379573822021,
      "learning_rate": 1.9536144578313254e-05,
      "loss": 0.1824,
      "step": 3850
    },
    {
      "epoch": 0.4650602409638554,
      "grad_norm": 10.680917739868164,
      "learning_rate": 1.9534939759036146e-05,
      "loss": 0.1102,
      "step": 3860
    },
    {
      "epoch": 0.46626506024096387,
      "grad_norm": 16.316293716430664,
      "learning_rate": 1.953373493975904e-05,
      "loss": 0.1598,
      "step": 3870
    },
    {
      "epoch": 0.4674698795180723,
      "grad_norm": 6.272592544555664,
      "learning_rate": 1.953253012048193e-05,
      "loss": 0.1778,
      "step": 3880
    },
    {
      "epoch": 0.4686746987951807,
      "grad_norm": 3.3570075035095215,
      "learning_rate": 1.953132530120482e-05,
      "loss": 0.2207,
      "step": 3890
    },
    {
      "epoch": 0.46987951807228917,
      "grad_norm": 0.6534222960472107,
      "learning_rate": 1.9530120481927712e-05,
      "loss": 0.1774,
      "step": 3900
    },
    {
      "epoch": 0.4710843373493976,
      "grad_norm": 7.29557991027832,
      "learning_rate": 1.9528915662650605e-05,
      "loss": 0.2048,
      "step": 3910
    },
    {
      "epoch": 0.472289156626506,
      "grad_norm": 1.9540971517562866,
      "learning_rate": 1.9527710843373494e-05,
      "loss": 0.1832,
      "step": 3920
    },
    {
      "epoch": 0.4734939759036145,
      "grad_norm": 3.3188085556030273,
      "learning_rate": 1.9526506024096386e-05,
      "loss": 0.1464,
      "step": 3930
    },
    {
      "epoch": 0.4746987951807229,
      "grad_norm": 5.83656644821167,
      "learning_rate": 1.952530120481928e-05,
      "loss": 0.1336,
      "step": 3940
    },
    {
      "epoch": 0.4759036144578313,
      "grad_norm": 4.659779071807861,
      "learning_rate": 1.952409638554217e-05,
      "loss": 0.1814,
      "step": 3950
    },
    {
      "epoch": 0.4771084337349398,
      "grad_norm": 7.089157581329346,
      "learning_rate": 1.952289156626506e-05,
      "loss": 0.1049,
      "step": 3960
    },
    {
      "epoch": 0.4783132530120482,
      "grad_norm": 10.637186050415039,
      "learning_rate": 1.9521686746987953e-05,
      "loss": 0.1741,
      "step": 3970
    },
    {
      "epoch": 0.4795180722891566,
      "grad_norm": 5.121634006500244,
      "learning_rate": 1.9520481927710845e-05,
      "loss": 0.2016,
      "step": 3980
    },
    {
      "epoch": 0.4807228915662651,
      "grad_norm": 3.120711088180542,
      "learning_rate": 1.9519277108433738e-05,
      "loss": 0.2139,
      "step": 3990
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 12.075000762939453,
      "learning_rate": 1.951807228915663e-05,
      "loss": 0.1822,
      "step": 4000
    },
    {
      "epoch": 0.4831325301204819,
      "grad_norm": 10.92212200164795,
      "learning_rate": 1.951686746987952e-05,
      "loss": 0.1435,
      "step": 4010
    },
    {
      "epoch": 0.4843373493975904,
      "grad_norm": 4.381875991821289,
      "learning_rate": 1.951566265060241e-05,
      "loss": 0.1017,
      "step": 4020
    },
    {
      "epoch": 0.4855421686746988,
      "grad_norm": 7.605460166931152,
      "learning_rate": 1.95144578313253e-05,
      "loss": 0.1742,
      "step": 4030
    },
    {
      "epoch": 0.4867469879518072,
      "grad_norm": 6.892362117767334,
      "learning_rate": 1.9513253012048193e-05,
      "loss": 0.2138,
      "step": 4040
    },
    {
      "epoch": 0.4879518072289157,
      "grad_norm": 5.28743314743042,
      "learning_rate": 1.9512048192771085e-05,
      "loss": 0.2134,
      "step": 4050
    },
    {
      "epoch": 0.4891566265060241,
      "grad_norm": 7.855250835418701,
      "learning_rate": 1.9510843373493978e-05,
      "loss": 0.1246,
      "step": 4060
    },
    {
      "epoch": 0.4903614457831325,
      "grad_norm": 4.516967296600342,
      "learning_rate": 1.950963855421687e-05,
      "loss": 0.1464,
      "step": 4070
    },
    {
      "epoch": 0.491566265060241,
      "grad_norm": 2.6128695011138916,
      "learning_rate": 1.950843373493976e-05,
      "loss": 0.1291,
      "step": 4080
    },
    {
      "epoch": 0.4927710843373494,
      "grad_norm": 1.2666290998458862,
      "learning_rate": 1.9507228915662652e-05,
      "loss": 0.1454,
      "step": 4090
    },
    {
      "epoch": 0.4939759036144578,
      "grad_norm": 11.626212120056152,
      "learning_rate": 1.9506024096385544e-05,
      "loss": 0.141,
      "step": 4100
    },
    {
      "epoch": 0.4951807228915663,
      "grad_norm": 7.548562049865723,
      "learning_rate": 1.9504819277108437e-05,
      "loss": 0.1951,
      "step": 4110
    },
    {
      "epoch": 0.4963855421686747,
      "grad_norm": 6.521340370178223,
      "learning_rate": 1.9503614457831326e-05,
      "loss": 0.2453,
      "step": 4120
    },
    {
      "epoch": 0.4975903614457831,
      "grad_norm": 6.953557968139648,
      "learning_rate": 1.9502409638554218e-05,
      "loss": 0.1904,
      "step": 4130
    },
    {
      "epoch": 0.4987951807228916,
      "grad_norm": 4.610267162322998,
      "learning_rate": 1.950120481927711e-05,
      "loss": 0.196,
      "step": 4140
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.157376289367676,
      "learning_rate": 1.95e-05,
      "loss": 0.1707,
      "step": 4150
    },
    {
      "epoch": 0.5012048192771085,
      "grad_norm": 7.218172550201416,
      "learning_rate": 1.9498795180722892e-05,
      "loss": 0.0913,
      "step": 4160
    },
    {
      "epoch": 0.5024096385542168,
      "grad_norm": 6.621463298797607,
      "learning_rate": 1.9497590361445785e-05,
      "loss": 0.1309,
      "step": 4170
    },
    {
      "epoch": 0.5036144578313253,
      "grad_norm": 6.663377285003662,
      "learning_rate": 1.9496385542168677e-05,
      "loss": 0.2229,
      "step": 4180
    },
    {
      "epoch": 0.5048192771084338,
      "grad_norm": 6.8246870040893555,
      "learning_rate": 1.9495180722891566e-05,
      "loss": 0.1633,
      "step": 4190
    },
    {
      "epoch": 0.5060240963855421,
      "grad_norm": 4.920630931854248,
      "learning_rate": 1.949397590361446e-05,
      "loss": 0.1835,
      "step": 4200
    },
    {
      "epoch": 0.5072289156626506,
      "grad_norm": 6.107293605804443,
      "learning_rate": 1.949277108433735e-05,
      "loss": 0.2251,
      "step": 4210
    },
    {
      "epoch": 0.5084337349397591,
      "grad_norm": 2.1833484172821045,
      "learning_rate": 1.9491566265060243e-05,
      "loss": 0.1363,
      "step": 4220
    },
    {
      "epoch": 0.5096385542168674,
      "grad_norm": 3.3824498653411865,
      "learning_rate": 1.9490361445783136e-05,
      "loss": 0.169,
      "step": 4230
    },
    {
      "epoch": 0.5108433734939759,
      "grad_norm": 7.581230640411377,
      "learning_rate": 1.9489156626506025e-05,
      "loss": 0.1562,
      "step": 4240
    },
    {
      "epoch": 0.5120481927710844,
      "grad_norm": 4.45789909362793,
      "learning_rate": 1.9487951807228917e-05,
      "loss": 0.1793,
      "step": 4250
    },
    {
      "epoch": 0.5132530120481927,
      "grad_norm": 0.7965855598449707,
      "learning_rate": 1.9486746987951806e-05,
      "loss": 0.1294,
      "step": 4260
    },
    {
      "epoch": 0.5144578313253012,
      "grad_norm": 4.321624279022217,
      "learning_rate": 1.94855421686747e-05,
      "loss": 0.3134,
      "step": 4270
    },
    {
      "epoch": 0.5156626506024097,
      "grad_norm": 4.514021396636963,
      "learning_rate": 1.9484337349397595e-05,
      "loss": 0.1927,
      "step": 4280
    },
    {
      "epoch": 0.516867469879518,
      "grad_norm": 4.608246803283691,
      "learning_rate": 1.9483132530120484e-05,
      "loss": 0.1599,
      "step": 4290
    },
    {
      "epoch": 0.5180722891566265,
      "grad_norm": 6.119877338409424,
      "learning_rate": 1.9481927710843376e-05,
      "loss": 0.2076,
      "step": 4300
    },
    {
      "epoch": 0.519277108433735,
      "grad_norm": 3.814579486846924,
      "learning_rate": 1.9480722891566265e-05,
      "loss": 0.1218,
      "step": 4310
    },
    {
      "epoch": 0.5204819277108433,
      "grad_norm": 8.579560279846191,
      "learning_rate": 1.9479518072289157e-05,
      "loss": 0.1661,
      "step": 4320
    },
    {
      "epoch": 0.5216867469879518,
      "grad_norm": 9.363751411437988,
      "learning_rate": 1.947831325301205e-05,
      "loss": 0.2769,
      "step": 4330
    },
    {
      "epoch": 0.5228915662650603,
      "grad_norm": 7.468043327331543,
      "learning_rate": 1.9477108433734942e-05,
      "loss": 0.1411,
      "step": 4340
    },
    {
      "epoch": 0.5240963855421686,
      "grad_norm": 5.797800064086914,
      "learning_rate": 1.9475903614457835e-05,
      "loss": 0.2192,
      "step": 4350
    },
    {
      "epoch": 0.5253012048192771,
      "grad_norm": 6.3435378074646,
      "learning_rate": 1.9474698795180724e-05,
      "loss": 0.1754,
      "step": 4360
    },
    {
      "epoch": 0.5265060240963856,
      "grad_norm": 5.392271995544434,
      "learning_rate": 1.9473493975903616e-05,
      "loss": 0.1655,
      "step": 4370
    },
    {
      "epoch": 0.5277108433734939,
      "grad_norm": 4.79223108291626,
      "learning_rate": 1.947228915662651e-05,
      "loss": 0.129,
      "step": 4380
    },
    {
      "epoch": 0.5289156626506024,
      "grad_norm": 6.858213901519775,
      "learning_rate": 1.94710843373494e-05,
      "loss": 0.1977,
      "step": 4390
    },
    {
      "epoch": 0.5301204819277109,
      "grad_norm": 5.4798712730407715,
      "learning_rate": 1.946987951807229e-05,
      "loss": 0.1619,
      "step": 4400
    },
    {
      "epoch": 0.5313253012048192,
      "grad_norm": 6.16205358505249,
      "learning_rate": 1.9468674698795183e-05,
      "loss": 0.1502,
      "step": 4410
    },
    {
      "epoch": 0.5325301204819277,
      "grad_norm": 9.740007400512695,
      "learning_rate": 1.9467469879518075e-05,
      "loss": 0.1315,
      "step": 4420
    },
    {
      "epoch": 0.5337349397590362,
      "grad_norm": 4.8728532791137695,
      "learning_rate": 1.9466265060240964e-05,
      "loss": 0.2107,
      "step": 4430
    },
    {
      "epoch": 0.5349397590361445,
      "grad_norm": 6.361910820007324,
      "learning_rate": 1.9465060240963857e-05,
      "loss": 0.1073,
      "step": 4440
    },
    {
      "epoch": 0.536144578313253,
      "grad_norm": 1.9509817361831665,
      "learning_rate": 1.946385542168675e-05,
      "loss": 0.173,
      "step": 4450
    },
    {
      "epoch": 0.5373493975903615,
      "grad_norm": 3.5538108348846436,
      "learning_rate": 1.946265060240964e-05,
      "loss": 0.1982,
      "step": 4460
    },
    {
      "epoch": 0.5385542168674698,
      "grad_norm": 5.351633548736572,
      "learning_rate": 1.946144578313253e-05,
      "loss": 0.1037,
      "step": 4470
    },
    {
      "epoch": 0.5397590361445783,
      "grad_norm": 6.898097991943359,
      "learning_rate": 1.9460240963855423e-05,
      "loss": 0.1745,
      "step": 4480
    },
    {
      "epoch": 0.5409638554216868,
      "grad_norm": 7.11887264251709,
      "learning_rate": 1.9459036144578315e-05,
      "loss": 0.1375,
      "step": 4490
    },
    {
      "epoch": 0.5421686746987951,
      "grad_norm": 6.744221210479736,
      "learning_rate": 1.9457831325301208e-05,
      "loss": 0.2115,
      "step": 4500
    },
    {
      "epoch": 0.5433734939759036,
      "grad_norm": 4.2066969871521,
      "learning_rate": 1.94566265060241e-05,
      "loss": 0.1974,
      "step": 4510
    },
    {
      "epoch": 0.5445783132530121,
      "grad_norm": 8.856725692749023,
      "learning_rate": 1.945542168674699e-05,
      "loss": 0.2055,
      "step": 4520
    },
    {
      "epoch": 0.5457831325301205,
      "grad_norm": 9.236030578613281,
      "learning_rate": 1.945421686746988e-05,
      "loss": 0.1561,
      "step": 4530
    },
    {
      "epoch": 0.5469879518072289,
      "grad_norm": 10.255292892456055,
      "learning_rate": 1.945301204819277e-05,
      "loss": 0.0989,
      "step": 4540
    },
    {
      "epoch": 0.5481927710843374,
      "grad_norm": 15.918651580810547,
      "learning_rate": 1.9451807228915663e-05,
      "loss": 0.2108,
      "step": 4550
    },
    {
      "epoch": 0.5493975903614458,
      "grad_norm": 10.748452186584473,
      "learning_rate": 1.9450602409638556e-05,
      "loss": 0.2425,
      "step": 4560
    },
    {
      "epoch": 0.5506024096385542,
      "grad_norm": 8.113410949707031,
      "learning_rate": 1.9449397590361448e-05,
      "loss": 0.2119,
      "step": 4570
    },
    {
      "epoch": 0.5518072289156627,
      "grad_norm": 9.747288703918457,
      "learning_rate": 1.944819277108434e-05,
      "loss": 0.146,
      "step": 4580
    },
    {
      "epoch": 0.553012048192771,
      "grad_norm": 1.6818923950195312,
      "learning_rate": 1.944698795180723e-05,
      "loss": 0.1629,
      "step": 4590
    },
    {
      "epoch": 0.5542168674698795,
      "grad_norm": 1.8813350200653076,
      "learning_rate": 1.9445783132530122e-05,
      "loss": 0.1246,
      "step": 4600
    },
    {
      "epoch": 0.555421686746988,
      "grad_norm": 8.580669403076172,
      "learning_rate": 1.9444578313253014e-05,
      "loss": 0.2016,
      "step": 4610
    },
    {
      "epoch": 0.5566265060240964,
      "grad_norm": 4.568905353546143,
      "learning_rate": 1.9443373493975907e-05,
      "loss": 0.1773,
      "step": 4620
    },
    {
      "epoch": 0.5578313253012048,
      "grad_norm": 0.39719676971435547,
      "learning_rate": 1.9442168674698796e-05,
      "loss": 0.1357,
      "step": 4630
    },
    {
      "epoch": 0.5590361445783133,
      "grad_norm": 4.456592082977295,
      "learning_rate": 1.944096385542169e-05,
      "loss": 0.1557,
      "step": 4640
    },
    {
      "epoch": 0.5602409638554217,
      "grad_norm": 6.4691853523254395,
      "learning_rate": 1.943975903614458e-05,
      "loss": 0.1614,
      "step": 4650
    },
    {
      "epoch": 0.5614457831325301,
      "grad_norm": 5.5503830909729,
      "learning_rate": 1.943855421686747e-05,
      "loss": 0.1184,
      "step": 4660
    },
    {
      "epoch": 0.5626506024096386,
      "grad_norm": 7.8248467445373535,
      "learning_rate": 1.9437349397590362e-05,
      "loss": 0.1868,
      "step": 4670
    },
    {
      "epoch": 0.563855421686747,
      "grad_norm": 3.8455069065093994,
      "learning_rate": 1.9436144578313255e-05,
      "loss": 0.1936,
      "step": 4680
    },
    {
      "epoch": 0.5650602409638554,
      "grad_norm": 4.566669464111328,
      "learning_rate": 1.9434939759036147e-05,
      "loss": 0.1619,
      "step": 4690
    },
    {
      "epoch": 0.5662650602409639,
      "grad_norm": 4.527639865875244,
      "learning_rate": 1.9433734939759036e-05,
      "loss": 0.1979,
      "step": 4700
    },
    {
      "epoch": 0.5674698795180723,
      "grad_norm": 6.905407428741455,
      "learning_rate": 1.943253012048193e-05,
      "loss": 0.119,
      "step": 4710
    },
    {
      "epoch": 0.5686746987951807,
      "grad_norm": 4.98099946975708,
      "learning_rate": 1.943132530120482e-05,
      "loss": 0.1154,
      "step": 4720
    },
    {
      "epoch": 0.5698795180722892,
      "grad_norm": 7.931012153625488,
      "learning_rate": 1.9430120481927713e-05,
      "loss": 0.1862,
      "step": 4730
    },
    {
      "epoch": 0.5710843373493976,
      "grad_norm": 7.538109302520752,
      "learning_rate": 1.9428915662650606e-05,
      "loss": 0.1557,
      "step": 4740
    },
    {
      "epoch": 0.572289156626506,
      "grad_norm": 4.617554664611816,
      "learning_rate": 1.9427710843373495e-05,
      "loss": 0.1391,
      "step": 4750
    },
    {
      "epoch": 0.5734939759036145,
      "grad_norm": 20.232173919677734,
      "learning_rate": 1.9426506024096387e-05,
      "loss": 0.1133,
      "step": 4760
    },
    {
      "epoch": 0.5746987951807229,
      "grad_norm": 6.399504661560059,
      "learning_rate": 1.9425301204819276e-05,
      "loss": 0.1906,
      "step": 4770
    },
    {
      "epoch": 0.5759036144578313,
      "grad_norm": 3.9855639934539795,
      "learning_rate": 1.942409638554217e-05,
      "loss": 0.1725,
      "step": 4780
    },
    {
      "epoch": 0.5771084337349398,
      "grad_norm": 4.918360233306885,
      "learning_rate": 1.942289156626506e-05,
      "loss": 0.1727,
      "step": 4790
    },
    {
      "epoch": 0.5783132530120482,
      "grad_norm": 6.76909065246582,
      "learning_rate": 1.9421686746987954e-05,
      "loss": 0.1136,
      "step": 4800
    },
    {
      "epoch": 0.5795180722891566,
      "grad_norm": 6.596453666687012,
      "learning_rate": 1.9420481927710846e-05,
      "loss": 0.1623,
      "step": 4810
    },
    {
      "epoch": 0.5807228915662651,
      "grad_norm": 9.863823890686035,
      "learning_rate": 1.9419277108433735e-05,
      "loss": 0.1221,
      "step": 4820
    },
    {
      "epoch": 0.5819277108433735,
      "grad_norm": 6.742912292480469,
      "learning_rate": 1.9418072289156628e-05,
      "loss": 0.1873,
      "step": 4830
    },
    {
      "epoch": 0.5831325301204819,
      "grad_norm": 5.466497898101807,
      "learning_rate": 1.941686746987952e-05,
      "loss": 0.1364,
      "step": 4840
    },
    {
      "epoch": 0.5843373493975904,
      "grad_norm": 7.464195728302002,
      "learning_rate": 1.9415662650602413e-05,
      "loss": 0.1376,
      "step": 4850
    },
    {
      "epoch": 0.5855421686746988,
      "grad_norm": 8.647309303283691,
      "learning_rate": 1.94144578313253e-05,
      "loss": 0.146,
      "step": 4860
    },
    {
      "epoch": 0.5867469879518072,
      "grad_norm": 1.4113792181015015,
      "learning_rate": 1.9413253012048194e-05,
      "loss": 0.1273,
      "step": 4870
    },
    {
      "epoch": 0.5879518072289157,
      "grad_norm": 5.681794166564941,
      "learning_rate": 1.9412048192771086e-05,
      "loss": 0.1906,
      "step": 4880
    },
    {
      "epoch": 0.5891566265060241,
      "grad_norm": 0.3845272958278656,
      "learning_rate": 1.941084337349398e-05,
      "loss": 0.0748,
      "step": 4890
    },
    {
      "epoch": 0.5903614457831325,
      "grad_norm": 3.0894222259521484,
      "learning_rate": 1.940963855421687e-05,
      "loss": 0.1547,
      "step": 4900
    },
    {
      "epoch": 0.591566265060241,
      "grad_norm": 3.679534912109375,
      "learning_rate": 1.940843373493976e-05,
      "loss": 0.1853,
      "step": 4910
    },
    {
      "epoch": 0.5927710843373494,
      "grad_norm": 6.426093578338623,
      "learning_rate": 1.9407228915662653e-05,
      "loss": 0.178,
      "step": 4920
    },
    {
      "epoch": 0.5939759036144578,
      "grad_norm": 3.368177890777588,
      "learning_rate": 1.9406024096385542e-05,
      "loss": 0.1581,
      "step": 4930
    },
    {
      "epoch": 0.5951807228915663,
      "grad_norm": 1.8768935203552246,
      "learning_rate": 1.9404819277108434e-05,
      "loss": 0.1828,
      "step": 4940
    },
    {
      "epoch": 0.5963855421686747,
      "grad_norm": 3.7573742866516113,
      "learning_rate": 1.9403614457831327e-05,
      "loss": 0.1631,
      "step": 4950
    },
    {
      "epoch": 0.5975903614457831,
      "grad_norm": 3.8618147373199463,
      "learning_rate": 1.940240963855422e-05,
      "loss": 0.1781,
      "step": 4960
    },
    {
      "epoch": 0.5987951807228916,
      "grad_norm": 3.8299338817596436,
      "learning_rate": 1.940120481927711e-05,
      "loss": 0.1305,
      "step": 4970
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.024237155914307,
      "learning_rate": 1.94e-05,
      "loss": 0.1186,
      "step": 4980
    },
    {
      "epoch": 0.6012048192771084,
      "grad_norm": 6.1261749267578125,
      "learning_rate": 1.9398795180722893e-05,
      "loss": 0.1277,
      "step": 4990
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 10.671565055847168,
      "learning_rate": 1.9397590361445785e-05,
      "loss": 0.1001,
      "step": 5000
    },
    {
      "epoch": 0.6036144578313253,
      "grad_norm": 0.8050594925880432,
      "learning_rate": 1.9396385542168678e-05,
      "loss": 0.182,
      "step": 5010
    },
    {
      "epoch": 0.6048192771084338,
      "grad_norm": 8.344988822937012,
      "learning_rate": 1.939518072289157e-05,
      "loss": 0.1315,
      "step": 5020
    },
    {
      "epoch": 0.6060240963855422,
      "grad_norm": 2.884645700454712,
      "learning_rate": 1.939397590361446e-05,
      "loss": 0.1427,
      "step": 5030
    },
    {
      "epoch": 0.6072289156626506,
      "grad_norm": 6.706043243408203,
      "learning_rate": 1.9392771084337352e-05,
      "loss": 0.124,
      "step": 5040
    },
    {
      "epoch": 0.608433734939759,
      "grad_norm": 4.884363174438477,
      "learning_rate": 1.939156626506024e-05,
      "loss": 0.1627,
      "step": 5050
    },
    {
      "epoch": 0.6096385542168675,
      "grad_norm": 6.250925540924072,
      "learning_rate": 1.9390361445783133e-05,
      "loss": 0.0938,
      "step": 5060
    },
    {
      "epoch": 0.6108433734939759,
      "grad_norm": 1.280989646911621,
      "learning_rate": 1.9389156626506026e-05,
      "loss": 0.1207,
      "step": 5070
    },
    {
      "epoch": 0.6120481927710844,
      "grad_norm": 33.059810638427734,
      "learning_rate": 1.9387951807228918e-05,
      "loss": 0.1722,
      "step": 5080
    },
    {
      "epoch": 0.6132530120481928,
      "grad_norm": 4.039045333862305,
      "learning_rate": 1.9386746987951807e-05,
      "loss": 0.1191,
      "step": 5090
    },
    {
      "epoch": 0.6144578313253012,
      "grad_norm": 6.435790061950684,
      "learning_rate": 1.93855421686747e-05,
      "loss": 0.2369,
      "step": 5100
    },
    {
      "epoch": 0.6156626506024097,
      "grad_norm": 5.102571487426758,
      "learning_rate": 1.9384337349397592e-05,
      "loss": 0.1705,
      "step": 5110
    },
    {
      "epoch": 0.6168674698795181,
      "grad_norm": 10.336877822875977,
      "learning_rate": 1.9383132530120485e-05,
      "loss": 0.1665,
      "step": 5120
    },
    {
      "epoch": 0.6180722891566265,
      "grad_norm": 4.3195061683654785,
      "learning_rate": 1.9381927710843377e-05,
      "loss": 0.1598,
      "step": 5130
    },
    {
      "epoch": 0.619277108433735,
      "grad_norm": 16.8527889251709,
      "learning_rate": 1.9380722891566266e-05,
      "loss": 0.145,
      "step": 5140
    },
    {
      "epoch": 0.6204819277108434,
      "grad_norm": 15.906359672546387,
      "learning_rate": 1.937951807228916e-05,
      "loss": 0.2029,
      "step": 5150
    },
    {
      "epoch": 0.6216867469879518,
      "grad_norm": 4.794151306152344,
      "learning_rate": 1.9378313253012047e-05,
      "loss": 0.1729,
      "step": 5160
    },
    {
      "epoch": 0.6228915662650603,
      "grad_norm": 2.1889655590057373,
      "learning_rate": 1.937710843373494e-05,
      "loss": 0.1933,
      "step": 5170
    },
    {
      "epoch": 0.6240963855421687,
      "grad_norm": 4.464681148529053,
      "learning_rate": 1.9375903614457832e-05,
      "loss": 0.1518,
      "step": 5180
    },
    {
      "epoch": 0.6253012048192771,
      "grad_norm": 1.6918858289718628,
      "learning_rate": 1.9374698795180725e-05,
      "loss": 0.128,
      "step": 5190
    },
    {
      "epoch": 0.6265060240963856,
      "grad_norm": 0.9953466653823853,
      "learning_rate": 1.9373493975903617e-05,
      "loss": 0.136,
      "step": 5200
    },
    {
      "epoch": 0.6277108433734939,
      "grad_norm": 8.33002758026123,
      "learning_rate": 1.9372289156626506e-05,
      "loss": 0.1972,
      "step": 5210
    },
    {
      "epoch": 0.6289156626506024,
      "grad_norm": 13.437187194824219,
      "learning_rate": 1.93710843373494e-05,
      "loss": 0.1871,
      "step": 5220
    },
    {
      "epoch": 0.6301204819277109,
      "grad_norm": 2.0768675804138184,
      "learning_rate": 1.936987951807229e-05,
      "loss": 0.1391,
      "step": 5230
    },
    {
      "epoch": 0.6313253012048192,
      "grad_norm": 6.893123149871826,
      "learning_rate": 1.9368674698795184e-05,
      "loss": 0.1419,
      "step": 5240
    },
    {
      "epoch": 0.6325301204819277,
      "grad_norm": 1.8054567575454712,
      "learning_rate": 1.9367469879518076e-05,
      "loss": 0.1269,
      "step": 5250
    },
    {
      "epoch": 0.6337349397590362,
      "grad_norm": 16.00343132019043,
      "learning_rate": 1.9366265060240965e-05,
      "loss": 0.1219,
      "step": 5260
    },
    {
      "epoch": 0.6349397590361445,
      "grad_norm": 4.266785621643066,
      "learning_rate": 1.9365060240963858e-05,
      "loss": 0.1276,
      "step": 5270
    },
    {
      "epoch": 0.636144578313253,
      "grad_norm": 9.66152286529541,
      "learning_rate": 1.9363855421686747e-05,
      "loss": 0.1103,
      "step": 5280
    },
    {
      "epoch": 0.6373493975903615,
      "grad_norm": 0.5506874918937683,
      "learning_rate": 1.936265060240964e-05,
      "loss": 0.1695,
      "step": 5290
    },
    {
      "epoch": 0.6385542168674698,
      "grad_norm": 2.346686363220215,
      "learning_rate": 1.936144578313253e-05,
      "loss": 0.1116,
      "step": 5300
    },
    {
      "epoch": 0.6397590361445783,
      "grad_norm": 4.057427883148193,
      "learning_rate": 1.9360240963855424e-05,
      "loss": 0.1662,
      "step": 5310
    },
    {
      "epoch": 0.6409638554216868,
      "grad_norm": 3.162531852722168,
      "learning_rate": 1.9359036144578316e-05,
      "loss": 0.1807,
      "step": 5320
    },
    {
      "epoch": 0.6421686746987951,
      "grad_norm": 6.224760055541992,
      "learning_rate": 1.9357831325301205e-05,
      "loss": 0.1749,
      "step": 5330
    },
    {
      "epoch": 0.6433734939759036,
      "grad_norm": 3.257432460784912,
      "learning_rate": 1.9356626506024098e-05,
      "loss": 0.1192,
      "step": 5340
    },
    {
      "epoch": 0.6445783132530121,
      "grad_norm": 9.046768188476562,
      "learning_rate": 1.935542168674699e-05,
      "loss": 0.225,
      "step": 5350
    },
    {
      "epoch": 0.6457831325301204,
      "grad_norm": 8.615628242492676,
      "learning_rate": 1.9354216867469883e-05,
      "loss": 0.1503,
      "step": 5360
    },
    {
      "epoch": 0.6469879518072289,
      "grad_norm": 11.437174797058105,
      "learning_rate": 1.935301204819277e-05,
      "loss": 0.1386,
      "step": 5370
    },
    {
      "epoch": 0.6481927710843374,
      "grad_norm": 12.842663764953613,
      "learning_rate": 1.9351807228915664e-05,
      "loss": 0.1233,
      "step": 5380
    },
    {
      "epoch": 0.6493975903614457,
      "grad_norm": 6.986889362335205,
      "learning_rate": 1.9350602409638553e-05,
      "loss": 0.1595,
      "step": 5390
    },
    {
      "epoch": 0.6506024096385542,
      "grad_norm": 3.995281457901001,
      "learning_rate": 1.9349397590361446e-05,
      "loss": 0.125,
      "step": 5400
    },
    {
      "epoch": 0.6518072289156627,
      "grad_norm": 4.3987531661987305,
      "learning_rate": 1.934819277108434e-05,
      "loss": 0.179,
      "step": 5410
    },
    {
      "epoch": 0.653012048192771,
      "grad_norm": 8.845865249633789,
      "learning_rate": 1.934698795180723e-05,
      "loss": 0.16,
      "step": 5420
    },
    {
      "epoch": 0.6542168674698795,
      "grad_norm": 12.792041778564453,
      "learning_rate": 1.9345783132530123e-05,
      "loss": 0.149,
      "step": 5430
    },
    {
      "epoch": 0.655421686746988,
      "grad_norm": 7.772871017456055,
      "learning_rate": 1.9344578313253012e-05,
      "loss": 0.1848,
      "step": 5440
    },
    {
      "epoch": 0.6566265060240963,
      "grad_norm": 9.391505241394043,
      "learning_rate": 1.9343373493975904e-05,
      "loss": 0.1272,
      "step": 5450
    },
    {
      "epoch": 0.6578313253012048,
      "grad_norm": 3.232196569442749,
      "learning_rate": 1.9342168674698797e-05,
      "loss": 0.1696,
      "step": 5460
    },
    {
      "epoch": 0.6590361445783133,
      "grad_norm": 6.254822731018066,
      "learning_rate": 1.934096385542169e-05,
      "loss": 0.2123,
      "step": 5470
    },
    {
      "epoch": 0.6602409638554216,
      "grad_norm": 3.226149797439575,
      "learning_rate": 1.9339759036144582e-05,
      "loss": 0.1653,
      "step": 5480
    },
    {
      "epoch": 0.6614457831325301,
      "grad_norm": 0.5182437300682068,
      "learning_rate": 1.933855421686747e-05,
      "loss": 0.1165,
      "step": 5490
    },
    {
      "epoch": 0.6626506024096386,
      "grad_norm": 6.322141170501709,
      "learning_rate": 1.9337349397590363e-05,
      "loss": 0.125,
      "step": 5500
    },
    {
      "epoch": 0.6638554216867469,
      "grad_norm": 5.058326721191406,
      "learning_rate": 1.9336144578313256e-05,
      "loss": 0.1283,
      "step": 5510
    },
    {
      "epoch": 0.6650602409638554,
      "grad_norm": 0.8621018528938293,
      "learning_rate": 1.9334939759036148e-05,
      "loss": 0.2439,
      "step": 5520
    },
    {
      "epoch": 0.6662650602409639,
      "grad_norm": 11.8020601272583,
      "learning_rate": 1.9333734939759037e-05,
      "loss": 0.1491,
      "step": 5530
    },
    {
      "epoch": 0.6674698795180722,
      "grad_norm": 7.6051859855651855,
      "learning_rate": 1.933253012048193e-05,
      "loss": 0.1581,
      "step": 5540
    },
    {
      "epoch": 0.6686746987951807,
      "grad_norm": 1.1820687055587769,
      "learning_rate": 1.9331325301204822e-05,
      "loss": 0.0858,
      "step": 5550
    },
    {
      "epoch": 0.6698795180722892,
      "grad_norm": 11.00537109375,
      "learning_rate": 1.933012048192771e-05,
      "loss": 0.2792,
      "step": 5560
    },
    {
      "epoch": 0.6710843373493975,
      "grad_norm": 0.5775253176689148,
      "learning_rate": 1.9328915662650603e-05,
      "loss": 0.0659,
      "step": 5570
    },
    {
      "epoch": 0.672289156626506,
      "grad_norm": 9.705564498901367,
      "learning_rate": 1.9327710843373496e-05,
      "loss": 0.1365,
      "step": 5580
    },
    {
      "epoch": 0.6734939759036145,
      "grad_norm": 0.8145530819892883,
      "learning_rate": 1.932650602409639e-05,
      "loss": 0.2397,
      "step": 5590
    },
    {
      "epoch": 0.6746987951807228,
      "grad_norm": 4.95365571975708,
      "learning_rate": 1.9325301204819277e-05,
      "loss": 0.2009,
      "step": 5600
    },
    {
      "epoch": 0.6759036144578313,
      "grad_norm": 5.431923866271973,
      "learning_rate": 1.932409638554217e-05,
      "loss": 0.2052,
      "step": 5610
    },
    {
      "epoch": 0.6771084337349398,
      "grad_norm": 3.3570055961608887,
      "learning_rate": 1.9322891566265062e-05,
      "loss": 0.1378,
      "step": 5620
    },
    {
      "epoch": 0.6783132530120481,
      "grad_norm": 5.053638935089111,
      "learning_rate": 1.9321686746987955e-05,
      "loss": 0.1123,
      "step": 5630
    },
    {
      "epoch": 0.6795180722891566,
      "grad_norm": 11.711750984191895,
      "learning_rate": 1.9320481927710847e-05,
      "loss": 0.1338,
      "step": 5640
    },
    {
      "epoch": 0.6807228915662651,
      "grad_norm": 3.2813568115234375,
      "learning_rate": 1.9319277108433736e-05,
      "loss": 0.1292,
      "step": 5650
    },
    {
      "epoch": 0.6819277108433734,
      "grad_norm": 9.758867263793945,
      "learning_rate": 1.931807228915663e-05,
      "loss": 0.206,
      "step": 5660
    },
    {
      "epoch": 0.6831325301204819,
      "grad_norm": 5.596731185913086,
      "learning_rate": 1.9316867469879518e-05,
      "loss": 0.1192,
      "step": 5670
    },
    {
      "epoch": 0.6843373493975904,
      "grad_norm": 7.051000595092773,
      "learning_rate": 1.931566265060241e-05,
      "loss": 0.1437,
      "step": 5680
    },
    {
      "epoch": 0.6855421686746987,
      "grad_norm": 5.241541862487793,
      "learning_rate": 1.9314457831325303e-05,
      "loss": 0.1273,
      "step": 5690
    },
    {
      "epoch": 0.6867469879518072,
      "grad_norm": 9.177921295166016,
      "learning_rate": 1.9313253012048195e-05,
      "loss": 0.1563,
      "step": 5700
    },
    {
      "epoch": 0.6879518072289157,
      "grad_norm": 5.310173988342285,
      "learning_rate": 1.9312048192771087e-05,
      "loss": 0.1603,
      "step": 5710
    },
    {
      "epoch": 0.689156626506024,
      "grad_norm": 3.6452910900115967,
      "learning_rate": 1.9310843373493976e-05,
      "loss": 0.2698,
      "step": 5720
    },
    {
      "epoch": 0.6903614457831325,
      "grad_norm": 3.593001127243042,
      "learning_rate": 1.930963855421687e-05,
      "loss": 0.1708,
      "step": 5730
    },
    {
      "epoch": 0.691566265060241,
      "grad_norm": 5.730554580688477,
      "learning_rate": 1.930843373493976e-05,
      "loss": 0.0937,
      "step": 5740
    },
    {
      "epoch": 0.6927710843373494,
      "grad_norm": 9.27896785736084,
      "learning_rate": 1.9307228915662654e-05,
      "loss": 0.1356,
      "step": 5750
    },
    {
      "epoch": 0.6939759036144578,
      "grad_norm": 10.93605899810791,
      "learning_rate": 1.9306024096385543e-05,
      "loss": 0.156,
      "step": 5760
    },
    {
      "epoch": 0.6951807228915663,
      "grad_norm": 9.658341407775879,
      "learning_rate": 1.9304819277108435e-05,
      "loss": 0.1251,
      "step": 5770
    },
    {
      "epoch": 0.6963855421686747,
      "grad_norm": 8.262742042541504,
      "learning_rate": 1.9303614457831328e-05,
      "loss": 0.1966,
      "step": 5780
    },
    {
      "epoch": 0.6975903614457831,
      "grad_norm": 3.761281967163086,
      "learning_rate": 1.9302409638554217e-05,
      "loss": 0.166,
      "step": 5790
    },
    {
      "epoch": 0.6987951807228916,
      "grad_norm": 4.000730514526367,
      "learning_rate": 1.930120481927711e-05,
      "loss": 0.1824,
      "step": 5800
    },
    {
      "epoch": 0.7,
      "grad_norm": 7.583612442016602,
      "learning_rate": 1.93e-05,
      "loss": 0.1267,
      "step": 5810
    },
    {
      "epoch": 0.7012048192771084,
      "grad_norm": 0.388191819190979,
      "learning_rate": 1.9298795180722894e-05,
      "loss": 0.0942,
      "step": 5820
    },
    {
      "epoch": 0.7024096385542169,
      "grad_norm": 7.562785625457764,
      "learning_rate": 1.9297590361445783e-05,
      "loss": 0.1918,
      "step": 5830
    },
    {
      "epoch": 0.7036144578313253,
      "grad_norm": 10.664834022521973,
      "learning_rate": 1.9296385542168675e-05,
      "loss": 0.1202,
      "step": 5840
    },
    {
      "epoch": 0.7048192771084337,
      "grad_norm": 2.9493565559387207,
      "learning_rate": 1.9295180722891568e-05,
      "loss": 0.149,
      "step": 5850
    },
    {
      "epoch": 0.7060240963855422,
      "grad_norm": 5.392096042633057,
      "learning_rate": 1.929397590361446e-05,
      "loss": 0.128,
      "step": 5860
    },
    {
      "epoch": 0.7072289156626506,
      "grad_norm": 3.1245291233062744,
      "learning_rate": 1.9292771084337353e-05,
      "loss": 0.1846,
      "step": 5870
    },
    {
      "epoch": 0.708433734939759,
      "grad_norm": 0.9211437702178955,
      "learning_rate": 1.9291566265060242e-05,
      "loss": 0.1175,
      "step": 5880
    },
    {
      "epoch": 0.7096385542168675,
      "grad_norm": 4.417148590087891,
      "learning_rate": 1.9290361445783134e-05,
      "loss": 0.1358,
      "step": 5890
    },
    {
      "epoch": 0.7108433734939759,
      "grad_norm": 4.998398303985596,
      "learning_rate": 1.9289156626506023e-05,
      "loss": 0.2273,
      "step": 5900
    },
    {
      "epoch": 0.7120481927710843,
      "grad_norm": 12.00574016571045,
      "learning_rate": 1.9287951807228916e-05,
      "loss": 0.1067,
      "step": 5910
    },
    {
      "epoch": 0.7132530120481928,
      "grad_norm": 8.264538764953613,
      "learning_rate": 1.928674698795181e-05,
      "loss": 0.1356,
      "step": 5920
    },
    {
      "epoch": 0.7144578313253012,
      "grad_norm": 10.29572868347168,
      "learning_rate": 1.92855421686747e-05,
      "loss": 0.1616,
      "step": 5930
    },
    {
      "epoch": 0.7156626506024096,
      "grad_norm": 13.429143905639648,
      "learning_rate": 1.9284337349397593e-05,
      "loss": 0.0838,
      "step": 5940
    },
    {
      "epoch": 0.7168674698795181,
      "grad_norm": 5.06330680847168,
      "learning_rate": 1.9283132530120482e-05,
      "loss": 0.1706,
      "step": 5950
    },
    {
      "epoch": 0.7180722891566265,
      "grad_norm": 3.7516205310821533,
      "learning_rate": 1.9281927710843375e-05,
      "loss": 0.1706,
      "step": 5960
    },
    {
      "epoch": 0.7192771084337349,
      "grad_norm": 0.6567031741142273,
      "learning_rate": 1.9280722891566267e-05,
      "loss": 0.1898,
      "step": 5970
    },
    {
      "epoch": 0.7204819277108434,
      "grad_norm": 3.3414394855499268,
      "learning_rate": 1.927951807228916e-05,
      "loss": 0.1467,
      "step": 5980
    },
    {
      "epoch": 0.7216867469879518,
      "grad_norm": 4.29252290725708,
      "learning_rate": 1.927831325301205e-05,
      "loss": 0.0865,
      "step": 5990
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 9.00324535369873,
      "learning_rate": 1.927710843373494e-05,
      "loss": 0.129,
      "step": 6000
    },
    {
      "epoch": 0.7240963855421687,
      "grad_norm": 5.479097843170166,
      "learning_rate": 1.9275903614457833e-05,
      "loss": 0.1779,
      "step": 6010
    },
    {
      "epoch": 0.7253012048192771,
      "grad_norm": 5.5210280418396,
      "learning_rate": 1.9274698795180726e-05,
      "loss": 0.1669,
      "step": 6020
    },
    {
      "epoch": 0.7265060240963855,
      "grad_norm": 1.7723720073699951,
      "learning_rate": 1.9273493975903618e-05,
      "loss": 0.1458,
      "step": 6030
    },
    {
      "epoch": 0.727710843373494,
      "grad_norm": 13.585110664367676,
      "learning_rate": 1.9272289156626507e-05,
      "loss": 0.1278,
      "step": 6040
    },
    {
      "epoch": 0.7289156626506024,
      "grad_norm": 15.675464630126953,
      "learning_rate": 1.92710843373494e-05,
      "loss": 0.2044,
      "step": 6050
    },
    {
      "epoch": 0.7301204819277108,
      "grad_norm": 6.5961079597473145,
      "learning_rate": 1.926987951807229e-05,
      "loss": 0.1526,
      "step": 6060
    },
    {
      "epoch": 0.7313253012048193,
      "grad_norm": 1.656314730644226,
      "learning_rate": 1.926867469879518e-05,
      "loss": 0.1198,
      "step": 6070
    },
    {
      "epoch": 0.7325301204819277,
      "grad_norm": 13.787653923034668,
      "learning_rate": 1.9267469879518074e-05,
      "loss": 0.1666,
      "step": 6080
    },
    {
      "epoch": 0.7337349397590361,
      "grad_norm": 5.3241286277771,
      "learning_rate": 1.9266265060240966e-05,
      "loss": 0.1399,
      "step": 6090
    },
    {
      "epoch": 0.7349397590361446,
      "grad_norm": 0.8580806851387024,
      "learning_rate": 1.926506024096386e-05,
      "loss": 0.085,
      "step": 6100
    },
    {
      "epoch": 0.736144578313253,
      "grad_norm": 0.08737669885158539,
      "learning_rate": 1.9263855421686748e-05,
      "loss": 0.1555,
      "step": 6110
    },
    {
      "epoch": 0.7373493975903614,
      "grad_norm": 3.7230775356292725,
      "learning_rate": 1.926265060240964e-05,
      "loss": 0.1672,
      "step": 6120
    },
    {
      "epoch": 0.7385542168674699,
      "grad_norm": 1.591897964477539,
      "learning_rate": 1.9261445783132532e-05,
      "loss": 0.1475,
      "step": 6130
    },
    {
      "epoch": 0.7397590361445783,
      "grad_norm": 7.600736141204834,
      "learning_rate": 1.9260240963855425e-05,
      "loss": 0.107,
      "step": 6140
    },
    {
      "epoch": 0.7409638554216867,
      "grad_norm": 4.701797008514404,
      "learning_rate": 1.9259036144578317e-05,
      "loss": 0.1593,
      "step": 6150
    },
    {
      "epoch": 0.7421686746987952,
      "grad_norm": 2.241278886795044,
      "learning_rate": 1.9257831325301206e-05,
      "loss": 0.1973,
      "step": 6160
    },
    {
      "epoch": 0.7433734939759036,
      "grad_norm": 2.518533229827881,
      "learning_rate": 1.92566265060241e-05,
      "loss": 0.1065,
      "step": 6170
    },
    {
      "epoch": 0.744578313253012,
      "grad_norm": 6.611241340637207,
      "learning_rate": 1.9255421686746988e-05,
      "loss": 0.1101,
      "step": 6180
    },
    {
      "epoch": 0.7457831325301205,
      "grad_norm": 5.411843776702881,
      "learning_rate": 1.925421686746988e-05,
      "loss": 0.1253,
      "step": 6190
    },
    {
      "epoch": 0.7469879518072289,
      "grad_norm": 12.295232772827148,
      "learning_rate": 1.9253012048192773e-05,
      "loss": 0.124,
      "step": 6200
    },
    {
      "epoch": 0.7481927710843373,
      "grad_norm": 2.6899333000183105,
      "learning_rate": 1.9251807228915665e-05,
      "loss": 0.2366,
      "step": 6210
    },
    {
      "epoch": 0.7493975903614458,
      "grad_norm": 3.9690375328063965,
      "learning_rate": 1.9250602409638558e-05,
      "loss": 0.1853,
      "step": 6220
    },
    {
      "epoch": 0.7506024096385542,
      "grad_norm": 3.28546142578125,
      "learning_rate": 1.9249397590361447e-05,
      "loss": 0.1635,
      "step": 6230
    },
    {
      "epoch": 0.7518072289156627,
      "grad_norm": 5.4921956062316895,
      "learning_rate": 1.924819277108434e-05,
      "loss": 0.1238,
      "step": 6240
    },
    {
      "epoch": 0.7530120481927711,
      "grad_norm": 6.187727451324463,
      "learning_rate": 1.924698795180723e-05,
      "loss": 0.121,
      "step": 6250
    },
    {
      "epoch": 0.7542168674698795,
      "grad_norm": 2.8208823204040527,
      "learning_rate": 1.9245783132530124e-05,
      "loss": 0.0889,
      "step": 6260
    },
    {
      "epoch": 0.755421686746988,
      "grad_norm": 3.2052061557769775,
      "learning_rate": 1.9244578313253013e-05,
      "loss": 0.1474,
      "step": 6270
    },
    {
      "epoch": 0.7566265060240964,
      "grad_norm": 4.300586700439453,
      "learning_rate": 1.9243373493975905e-05,
      "loss": 0.1669,
      "step": 6280
    },
    {
      "epoch": 0.7578313253012048,
      "grad_norm": 6.981145858764648,
      "learning_rate": 1.9242168674698794e-05,
      "loss": 0.1439,
      "step": 6290
    },
    {
      "epoch": 0.7590361445783133,
      "grad_norm": 1.4983667135238647,
      "learning_rate": 1.9240963855421687e-05,
      "loss": 0.1671,
      "step": 6300
    },
    {
      "epoch": 0.7602409638554217,
      "grad_norm": 10.495603561401367,
      "learning_rate": 1.923975903614458e-05,
      "loss": 0.1433,
      "step": 6310
    },
    {
      "epoch": 0.7614457831325301,
      "grad_norm": 0.7020681500434875,
      "learning_rate": 1.9238554216867472e-05,
      "loss": 0.1773,
      "step": 6320
    },
    {
      "epoch": 0.7626506024096386,
      "grad_norm": 6.4011030197143555,
      "learning_rate": 1.9237349397590364e-05,
      "loss": 0.1415,
      "step": 6330
    },
    {
      "epoch": 0.763855421686747,
      "grad_norm": 1.2402268648147583,
      "learning_rate": 1.9236144578313253e-05,
      "loss": 0.0996,
      "step": 6340
    },
    {
      "epoch": 0.7650602409638554,
      "grad_norm": 8.805359840393066,
      "learning_rate": 1.9234939759036146e-05,
      "loss": 0.1441,
      "step": 6350
    },
    {
      "epoch": 0.7662650602409639,
      "grad_norm": 8.53828239440918,
      "learning_rate": 1.9233734939759038e-05,
      "loss": 0.1224,
      "step": 6360
    },
    {
      "epoch": 0.7674698795180723,
      "grad_norm": 3.5058984756469727,
      "learning_rate": 1.923253012048193e-05,
      "loss": 0.2186,
      "step": 6370
    },
    {
      "epoch": 0.7686746987951807,
      "grad_norm": 7.021337032318115,
      "learning_rate": 1.9231325301204823e-05,
      "loss": 0.1015,
      "step": 6380
    },
    {
      "epoch": 0.7698795180722892,
      "grad_norm": 12.600963592529297,
      "learning_rate": 1.9230120481927712e-05,
      "loss": 0.1352,
      "step": 6390
    },
    {
      "epoch": 0.7710843373493976,
      "grad_norm": 2.438880205154419,
      "learning_rate": 1.9228915662650604e-05,
      "loss": 0.1871,
      "step": 6400
    },
    {
      "epoch": 0.772289156626506,
      "grad_norm": 3.0021750926971436,
      "learning_rate": 1.9227710843373493e-05,
      "loss": 0.1972,
      "step": 6410
    },
    {
      "epoch": 0.7734939759036145,
      "grad_norm": 5.089186191558838,
      "learning_rate": 1.9226506024096386e-05,
      "loss": 0.1692,
      "step": 6420
    },
    {
      "epoch": 0.7746987951807229,
      "grad_norm": 1.6508936882019043,
      "learning_rate": 1.922530120481928e-05,
      "loss": 0.1295,
      "step": 6430
    },
    {
      "epoch": 0.7759036144578313,
      "grad_norm": 7.9405694007873535,
      "learning_rate": 1.922409638554217e-05,
      "loss": 0.1909,
      "step": 6440
    },
    {
      "epoch": 0.7771084337349398,
      "grad_norm": 5.786319732666016,
      "learning_rate": 1.9222891566265063e-05,
      "loss": 0.1265,
      "step": 6450
    },
    {
      "epoch": 0.7783132530120482,
      "grad_norm": 5.469359397888184,
      "learning_rate": 1.9221686746987952e-05,
      "loss": 0.0895,
      "step": 6460
    },
    {
      "epoch": 0.7795180722891566,
      "grad_norm": 7.36496114730835,
      "learning_rate": 1.9220481927710845e-05,
      "loss": 0.129,
      "step": 6470
    },
    {
      "epoch": 0.7807228915662651,
      "grad_norm": 24.76846694946289,
      "learning_rate": 1.9219277108433737e-05,
      "loss": 0.1631,
      "step": 6480
    },
    {
      "epoch": 0.7819277108433735,
      "grad_norm": 1.0180963277816772,
      "learning_rate": 1.921807228915663e-05,
      "loss": 0.1005,
      "step": 6490
    },
    {
      "epoch": 0.7831325301204819,
      "grad_norm": 12.525565147399902,
      "learning_rate": 1.921686746987952e-05,
      "loss": 0.172,
      "step": 6500
    },
    {
      "epoch": 0.7843373493975904,
      "grad_norm": 2.930542469024658,
      "learning_rate": 1.921566265060241e-05,
      "loss": 0.1203,
      "step": 6510
    },
    {
      "epoch": 0.7855421686746988,
      "grad_norm": 0.47943195700645447,
      "learning_rate": 1.9214457831325303e-05,
      "loss": 0.0962,
      "step": 6520
    },
    {
      "epoch": 0.7867469879518072,
      "grad_norm": 3.076934576034546,
      "learning_rate": 1.9213253012048193e-05,
      "loss": 0.1497,
      "step": 6530
    },
    {
      "epoch": 0.7879518072289157,
      "grad_norm": 10.879239082336426,
      "learning_rate": 1.921204819277109e-05,
      "loss": 0.1391,
      "step": 6540
    },
    {
      "epoch": 0.7891566265060241,
      "grad_norm": 13.083039283752441,
      "learning_rate": 1.9210843373493977e-05,
      "loss": 0.1386,
      "step": 6550
    },
    {
      "epoch": 0.7903614457831325,
      "grad_norm": 6.822357177734375,
      "learning_rate": 1.920963855421687e-05,
      "loss": 0.1035,
      "step": 6560
    },
    {
      "epoch": 0.791566265060241,
      "grad_norm": 0.5976637601852417,
      "learning_rate": 1.920843373493976e-05,
      "loss": 0.115,
      "step": 6570
    },
    {
      "epoch": 0.7927710843373494,
      "grad_norm": 18.018545150756836,
      "learning_rate": 1.920722891566265e-05,
      "loss": 0.1276,
      "step": 6580
    },
    {
      "epoch": 0.7939759036144578,
      "grad_norm": 8.562076568603516,
      "learning_rate": 1.9206024096385544e-05,
      "loss": 0.1756,
      "step": 6590
    },
    {
      "epoch": 0.7951807228915663,
      "grad_norm": 1.175184965133667,
      "learning_rate": 1.9204819277108436e-05,
      "loss": 0.148,
      "step": 6600
    },
    {
      "epoch": 0.7963855421686747,
      "grad_norm": 4.409256458282471,
      "learning_rate": 1.920361445783133e-05,
      "loss": 0.1425,
      "step": 6610
    },
    {
      "epoch": 0.7975903614457831,
      "grad_norm": 11.374248504638672,
      "learning_rate": 1.9202409638554218e-05,
      "loss": 0.1812,
      "step": 6620
    },
    {
      "epoch": 0.7987951807228916,
      "grad_norm": 3.0345265865325928,
      "learning_rate": 1.920120481927711e-05,
      "loss": 0.1304,
      "step": 6630
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.005056858062744,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.1778,
      "step": 6640
    },
    {
      "epoch": 0.8012048192771084,
      "grad_norm": 4.097514629364014,
      "learning_rate": 1.9198795180722895e-05,
      "loss": 0.1484,
      "step": 6650
    },
    {
      "epoch": 0.8024096385542169,
      "grad_norm": 1.6414917707443237,
      "learning_rate": 1.9197590361445784e-05,
      "loss": 0.1476,
      "step": 6660
    },
    {
      "epoch": 0.8036144578313253,
      "grad_norm": 1.6644537448883057,
      "learning_rate": 1.9196385542168676e-05,
      "loss": 0.1607,
      "step": 6670
    },
    {
      "epoch": 0.8048192771084337,
      "grad_norm": 3.1886682510375977,
      "learning_rate": 1.919518072289157e-05,
      "loss": 0.0978,
      "step": 6680
    },
    {
      "epoch": 0.8060240963855422,
      "grad_norm": 12.315463066101074,
      "learning_rate": 1.9193975903614458e-05,
      "loss": 0.1055,
      "step": 6690
    },
    {
      "epoch": 0.8072289156626506,
      "grad_norm": 2.3669724464416504,
      "learning_rate": 1.919277108433735e-05,
      "loss": 0.0974,
      "step": 6700
    },
    {
      "epoch": 0.808433734939759,
      "grad_norm": 4.87614631652832,
      "learning_rate": 1.9191566265060243e-05,
      "loss": 0.1362,
      "step": 6710
    },
    {
      "epoch": 0.8096385542168675,
      "grad_norm": 3.1855671405792236,
      "learning_rate": 1.9190361445783135e-05,
      "loss": 0.2578,
      "step": 6720
    },
    {
      "epoch": 0.810843373493976,
      "grad_norm": 3.953279972076416,
      "learning_rate": 1.9189156626506024e-05,
      "loss": 0.0758,
      "step": 6730
    },
    {
      "epoch": 0.8120481927710843,
      "grad_norm": 0.3690357804298401,
      "learning_rate": 1.9187951807228917e-05,
      "loss": 0.117,
      "step": 6740
    },
    {
      "epoch": 0.8132530120481928,
      "grad_norm": 2.341278553009033,
      "learning_rate": 1.918674698795181e-05,
      "loss": 0.225,
      "step": 6750
    },
    {
      "epoch": 0.8144578313253013,
      "grad_norm": 7.633081912994385,
      "learning_rate": 1.91855421686747e-05,
      "loss": 0.1775,
      "step": 6760
    },
    {
      "epoch": 0.8156626506024096,
      "grad_norm": 19.229280471801758,
      "learning_rate": 1.9184337349397594e-05,
      "loss": 0.1604,
      "step": 6770
    },
    {
      "epoch": 0.8168674698795181,
      "grad_norm": 7.340471267700195,
      "learning_rate": 1.9183132530120483e-05,
      "loss": 0.1409,
      "step": 6780
    },
    {
      "epoch": 0.8180722891566266,
      "grad_norm": 5.8485026359558105,
      "learning_rate": 1.9181927710843375e-05,
      "loss": 0.1714,
      "step": 6790
    },
    {
      "epoch": 0.8192771084337349,
      "grad_norm": 7.5975189208984375,
      "learning_rate": 1.9180722891566265e-05,
      "loss": 0.1838,
      "step": 6800
    },
    {
      "epoch": 0.8204819277108434,
      "grad_norm": 1.74968421459198,
      "learning_rate": 1.9179518072289157e-05,
      "loss": 0.0995,
      "step": 6810
    },
    {
      "epoch": 0.8216867469879519,
      "grad_norm": 0.68149733543396,
      "learning_rate": 1.917831325301205e-05,
      "loss": 0.1466,
      "step": 6820
    },
    {
      "epoch": 0.8228915662650602,
      "grad_norm": 13.525727272033691,
      "learning_rate": 1.9177108433734942e-05,
      "loss": 0.0655,
      "step": 6830
    },
    {
      "epoch": 0.8240963855421687,
      "grad_norm": 0.17985227704048157,
      "learning_rate": 1.9175903614457834e-05,
      "loss": 0.1079,
      "step": 6840
    },
    {
      "epoch": 0.8253012048192772,
      "grad_norm": 0.3615516722202301,
      "learning_rate": 1.9174698795180723e-05,
      "loss": 0.0723,
      "step": 6850
    },
    {
      "epoch": 0.8265060240963855,
      "grad_norm": 3.9456095695495605,
      "learning_rate": 1.9173493975903616e-05,
      "loss": 0.1536,
      "step": 6860
    },
    {
      "epoch": 0.827710843373494,
      "grad_norm": 7.490786552429199,
      "learning_rate": 1.9172289156626508e-05,
      "loss": 0.1436,
      "step": 6870
    },
    {
      "epoch": 0.8289156626506025,
      "grad_norm": 1.0725089311599731,
      "learning_rate": 1.91710843373494e-05,
      "loss": 0.1496,
      "step": 6880
    },
    {
      "epoch": 0.8301204819277108,
      "grad_norm": 9.215475082397461,
      "learning_rate": 1.916987951807229e-05,
      "loss": 0.1087,
      "step": 6890
    },
    {
      "epoch": 0.8313253012048193,
      "grad_norm": 13.858357429504395,
      "learning_rate": 1.9168674698795182e-05,
      "loss": 0.2007,
      "step": 6900
    },
    {
      "epoch": 0.8325301204819278,
      "grad_norm": 0.861771285533905,
      "learning_rate": 1.9167469879518075e-05,
      "loss": 0.2898,
      "step": 6910
    },
    {
      "epoch": 0.8337349397590361,
      "grad_norm": 13.414508819580078,
      "learning_rate": 1.9166265060240964e-05,
      "loss": 0.1068,
      "step": 6920
    },
    {
      "epoch": 0.8349397590361446,
      "grad_norm": 2.736231803894043,
      "learning_rate": 1.9165060240963856e-05,
      "loss": 0.1039,
      "step": 6930
    },
    {
      "epoch": 0.8361445783132531,
      "grad_norm": 3.696901798248291,
      "learning_rate": 1.916385542168675e-05,
      "loss": 0.0975,
      "step": 6940
    },
    {
      "epoch": 0.8373493975903614,
      "grad_norm": 12.1973295211792,
      "learning_rate": 1.916265060240964e-05,
      "loss": 0.1179,
      "step": 6950
    },
    {
      "epoch": 0.8385542168674699,
      "grad_norm": 6.148894309997559,
      "learning_rate": 1.916144578313253e-05,
      "loss": 0.1688,
      "step": 6960
    },
    {
      "epoch": 0.8397590361445784,
      "grad_norm": 6.183839797973633,
      "learning_rate": 1.9160240963855422e-05,
      "loss": 0.2119,
      "step": 6970
    },
    {
      "epoch": 0.8409638554216867,
      "grad_norm": 4.496895790100098,
      "learning_rate": 1.9159036144578315e-05,
      "loss": 0.0802,
      "step": 6980
    },
    {
      "epoch": 0.8421686746987952,
      "grad_norm": 6.350569725036621,
      "learning_rate": 1.9157831325301207e-05,
      "loss": 0.1204,
      "step": 6990
    },
    {
      "epoch": 0.8433734939759037,
      "grad_norm": 1.905516505241394,
      "learning_rate": 1.91566265060241e-05,
      "loss": 0.1718,
      "step": 7000
    },
    {
      "epoch": 0.844578313253012,
      "grad_norm": 4.690359592437744,
      "learning_rate": 1.915542168674699e-05,
      "loss": 0.1705,
      "step": 7010
    },
    {
      "epoch": 0.8457831325301205,
      "grad_norm": 0.4158436059951782,
      "learning_rate": 1.915421686746988e-05,
      "loss": 0.0603,
      "step": 7020
    },
    {
      "epoch": 0.846987951807229,
      "grad_norm": 1.7640336751937866,
      "learning_rate": 1.915301204819277e-05,
      "loss": 0.1352,
      "step": 7030
    },
    {
      "epoch": 0.8481927710843373,
      "grad_norm": 3.408196210861206,
      "learning_rate": 1.9151807228915663e-05,
      "loss": 0.1642,
      "step": 7040
    },
    {
      "epoch": 0.8493975903614458,
      "grad_norm": 12.77517318725586,
      "learning_rate": 1.9150602409638555e-05,
      "loss": 0.1011,
      "step": 7050
    },
    {
      "epoch": 0.8506024096385543,
      "grad_norm": 5.300127983093262,
      "learning_rate": 1.9149397590361448e-05,
      "loss": 0.0811,
      "step": 7060
    },
    {
      "epoch": 0.8518072289156626,
      "grad_norm": 6.991878032684326,
      "learning_rate": 1.914819277108434e-05,
      "loss": 0.1379,
      "step": 7070
    },
    {
      "epoch": 0.8530120481927711,
      "grad_norm": 0.3634975254535675,
      "learning_rate": 1.914698795180723e-05,
      "loss": 0.1085,
      "step": 7080
    },
    {
      "epoch": 0.8542168674698796,
      "grad_norm": 6.280744552612305,
      "learning_rate": 1.914578313253012e-05,
      "loss": 0.1061,
      "step": 7090
    },
    {
      "epoch": 0.8554216867469879,
      "grad_norm": 23.572120666503906,
      "learning_rate": 1.9144578313253014e-05,
      "loss": 0.1926,
      "step": 7100
    },
    {
      "epoch": 0.8566265060240964,
      "grad_norm": 11.683313369750977,
      "learning_rate": 1.9143373493975906e-05,
      "loss": 0.1637,
      "step": 7110
    },
    {
      "epoch": 0.8578313253012049,
      "grad_norm": 8.960514068603516,
      "learning_rate": 1.91421686746988e-05,
      "loss": 0.1664,
      "step": 7120
    },
    {
      "epoch": 0.8590361445783132,
      "grad_norm": 6.403578758239746,
      "learning_rate": 1.9140963855421688e-05,
      "loss": 0.1281,
      "step": 7130
    },
    {
      "epoch": 0.8602409638554217,
      "grad_norm": 7.657562732696533,
      "learning_rate": 1.913975903614458e-05,
      "loss": 0.1137,
      "step": 7140
    },
    {
      "epoch": 0.8614457831325302,
      "grad_norm": 7.7305755615234375,
      "learning_rate": 1.913855421686747e-05,
      "loss": 0.1505,
      "step": 7150
    },
    {
      "epoch": 0.8626506024096385,
      "grad_norm": 33.25403594970703,
      "learning_rate": 1.9137349397590365e-05,
      "loss": 0.1282,
      "step": 7160
    },
    {
      "epoch": 0.863855421686747,
      "grad_norm": 2.179835796356201,
      "learning_rate": 1.9136144578313254e-05,
      "loss": 0.1169,
      "step": 7170
    },
    {
      "epoch": 0.8650602409638555,
      "grad_norm": 2.8547725677490234,
      "learning_rate": 1.9134939759036147e-05,
      "loss": 0.176,
      "step": 7180
    },
    {
      "epoch": 0.8662650602409638,
      "grad_norm": 5.260756969451904,
      "learning_rate": 1.9133734939759036e-05,
      "loss": 0.1092,
      "step": 7190
    },
    {
      "epoch": 0.8674698795180723,
      "grad_norm": 1.4323443174362183,
      "learning_rate": 1.9132530120481928e-05,
      "loss": 0.0874,
      "step": 7200
    },
    {
      "epoch": 0.8686746987951808,
      "grad_norm": 1.0930134057998657,
      "learning_rate": 1.913132530120482e-05,
      "loss": 0.1447,
      "step": 7210
    },
    {
      "epoch": 0.8698795180722891,
      "grad_norm": 6.455761432647705,
      "learning_rate": 1.9130120481927713e-05,
      "loss": 0.1706,
      "step": 7220
    },
    {
      "epoch": 0.8710843373493976,
      "grad_norm": 14.7593412399292,
      "learning_rate": 1.9128915662650605e-05,
      "loss": 0.1288,
      "step": 7230
    },
    {
      "epoch": 0.8722891566265061,
      "grad_norm": 12.1329984664917,
      "learning_rate": 1.9127710843373494e-05,
      "loss": 0.1596,
      "step": 7240
    },
    {
      "epoch": 0.8734939759036144,
      "grad_norm": 4.547363758087158,
      "learning_rate": 1.9126506024096387e-05,
      "loss": 0.0762,
      "step": 7250
    },
    {
      "epoch": 0.8746987951807229,
      "grad_norm": 3.5254812240600586,
      "learning_rate": 1.912530120481928e-05,
      "loss": 0.1055,
      "step": 7260
    },
    {
      "epoch": 0.8759036144578313,
      "grad_norm": 0.6492607593536377,
      "learning_rate": 1.9124096385542172e-05,
      "loss": 0.121,
      "step": 7270
    },
    {
      "epoch": 0.8771084337349397,
      "grad_norm": 9.087776184082031,
      "learning_rate": 1.9122891566265064e-05,
      "loss": 0.0896,
      "step": 7280
    },
    {
      "epoch": 0.8783132530120482,
      "grad_norm": 3.165776491165161,
      "learning_rate": 1.9121686746987953e-05,
      "loss": 0.1681,
      "step": 7290
    },
    {
      "epoch": 0.8795180722891566,
      "grad_norm": 5.852673053741455,
      "learning_rate": 1.9120481927710846e-05,
      "loss": 0.1543,
      "step": 7300
    },
    {
      "epoch": 0.880722891566265,
      "grad_norm": 4.601993083953857,
      "learning_rate": 1.9119277108433735e-05,
      "loss": 0.1653,
      "step": 7310
    },
    {
      "epoch": 0.8819277108433735,
      "grad_norm": 0.6399827599525452,
      "learning_rate": 1.9118072289156627e-05,
      "loss": 0.145,
      "step": 7320
    },
    {
      "epoch": 0.8831325301204819,
      "grad_norm": 14.610925674438477,
      "learning_rate": 1.911686746987952e-05,
      "loss": 0.1884,
      "step": 7330
    },
    {
      "epoch": 0.8843373493975903,
      "grad_norm": 5.515504837036133,
      "learning_rate": 1.9115662650602412e-05,
      "loss": 0.1223,
      "step": 7340
    },
    {
      "epoch": 0.8855421686746988,
      "grad_norm": 7.313483238220215,
      "learning_rate": 1.9114457831325304e-05,
      "loss": 0.1001,
      "step": 7350
    },
    {
      "epoch": 0.8867469879518072,
      "grad_norm": 28.369470596313477,
      "learning_rate": 1.9113253012048193e-05,
      "loss": 0.1883,
      "step": 7360
    },
    {
      "epoch": 0.8879518072289156,
      "grad_norm": 1.9681880474090576,
      "learning_rate": 1.9112048192771086e-05,
      "loss": 0.1333,
      "step": 7370
    },
    {
      "epoch": 0.8891566265060241,
      "grad_norm": 1.490565538406372,
      "learning_rate": 1.911084337349398e-05,
      "loss": 0.0976,
      "step": 7380
    },
    {
      "epoch": 0.8903614457831325,
      "grad_norm": 7.942065715789795,
      "learning_rate": 1.910963855421687e-05,
      "loss": 0.1016,
      "step": 7390
    },
    {
      "epoch": 0.891566265060241,
      "grad_norm": 0.24973346292972565,
      "learning_rate": 1.910843373493976e-05,
      "loss": 0.1404,
      "step": 7400
    },
    {
      "epoch": 0.8927710843373494,
      "grad_norm": 6.537899494171143,
      "learning_rate": 1.9107228915662652e-05,
      "loss": 0.1618,
      "step": 7410
    },
    {
      "epoch": 0.8939759036144578,
      "grad_norm": 5.9430952072143555,
      "learning_rate": 1.9106024096385545e-05,
      "loss": 0.1084,
      "step": 7420
    },
    {
      "epoch": 0.8951807228915662,
      "grad_norm": 4.651486873626709,
      "learning_rate": 1.9104819277108434e-05,
      "loss": 0.1818,
      "step": 7430
    },
    {
      "epoch": 0.8963855421686747,
      "grad_norm": 4.601818561553955,
      "learning_rate": 1.9103614457831326e-05,
      "loss": 0.1225,
      "step": 7440
    },
    {
      "epoch": 0.8975903614457831,
      "grad_norm": 12.287641525268555,
      "learning_rate": 1.910240963855422e-05,
      "loss": 0.1215,
      "step": 7450
    },
    {
      "epoch": 0.8987951807228916,
      "grad_norm": 0.3497784733772278,
      "learning_rate": 1.910120481927711e-05,
      "loss": 0.111,
      "step": 7460
    },
    {
      "epoch": 0.9,
      "grad_norm": 7.2411274909973145,
      "learning_rate": 1.91e-05,
      "loss": 0.102,
      "step": 7470
    },
    {
      "epoch": 0.9012048192771084,
      "grad_norm": 4.862903118133545,
      "learning_rate": 1.9098795180722893e-05,
      "loss": 0.1569,
      "step": 7480
    },
    {
      "epoch": 0.9024096385542169,
      "grad_norm": 7.67415189743042,
      "learning_rate": 1.9097590361445785e-05,
      "loss": 0.1427,
      "step": 7490
    },
    {
      "epoch": 0.9036144578313253,
      "grad_norm": 2.6273927688598633,
      "learning_rate": 1.9096385542168677e-05,
      "loss": 0.1213,
      "step": 7500
    },
    {
      "epoch": 0.9048192771084337,
      "grad_norm": 0.5780089497566223,
      "learning_rate": 1.909518072289157e-05,
      "loss": 0.1318,
      "step": 7510
    },
    {
      "epoch": 0.9060240963855422,
      "grad_norm": 4.190696716308594,
      "learning_rate": 1.909397590361446e-05,
      "loss": 0.1437,
      "step": 7520
    },
    {
      "epoch": 0.9072289156626506,
      "grad_norm": 10.37695598602295,
      "learning_rate": 1.909277108433735e-05,
      "loss": 0.142,
      "step": 7530
    },
    {
      "epoch": 0.908433734939759,
      "grad_norm": 8.859354972839355,
      "learning_rate": 1.909156626506024e-05,
      "loss": 0.127,
      "step": 7540
    },
    {
      "epoch": 0.9096385542168675,
      "grad_norm": 6.055468559265137,
      "learning_rate": 1.9090361445783133e-05,
      "loss": 0.1757,
      "step": 7550
    },
    {
      "epoch": 0.9108433734939759,
      "grad_norm": 5.261435508728027,
      "learning_rate": 1.9089156626506025e-05,
      "loss": 0.1893,
      "step": 7560
    },
    {
      "epoch": 0.9120481927710843,
      "grad_norm": 6.283318996429443,
      "learning_rate": 1.9087951807228918e-05,
      "loss": 0.1423,
      "step": 7570
    },
    {
      "epoch": 0.9132530120481928,
      "grad_norm": 4.610183238983154,
      "learning_rate": 1.908674698795181e-05,
      "loss": 0.1286,
      "step": 7580
    },
    {
      "epoch": 0.9144578313253012,
      "grad_norm": 11.650784492492676,
      "learning_rate": 1.90855421686747e-05,
      "loss": 0.1355,
      "step": 7590
    },
    {
      "epoch": 0.9156626506024096,
      "grad_norm": 0.6434968709945679,
      "learning_rate": 1.908433734939759e-05,
      "loss": 0.1589,
      "step": 7600
    },
    {
      "epoch": 0.9168674698795181,
      "grad_norm": 2.5610859394073486,
      "learning_rate": 1.9083132530120484e-05,
      "loss": 0.2169,
      "step": 7610
    },
    {
      "epoch": 0.9180722891566265,
      "grad_norm": 0.7698946595191956,
      "learning_rate": 1.9081927710843376e-05,
      "loss": 0.1115,
      "step": 7620
    },
    {
      "epoch": 0.9192771084337349,
      "grad_norm": 16.122501373291016,
      "learning_rate": 1.9080722891566265e-05,
      "loss": 0.0804,
      "step": 7630
    },
    {
      "epoch": 0.9204819277108434,
      "grad_norm": 1.5521639585494995,
      "learning_rate": 1.9079518072289158e-05,
      "loss": 0.132,
      "step": 7640
    },
    {
      "epoch": 0.9216867469879518,
      "grad_norm": 13.955252647399902,
      "learning_rate": 1.907831325301205e-05,
      "loss": 0.0992,
      "step": 7650
    },
    {
      "epoch": 0.9228915662650602,
      "grad_norm": 0.022153807803988457,
      "learning_rate": 1.907710843373494e-05,
      "loss": 0.1095,
      "step": 7660
    },
    {
      "epoch": 0.9240963855421687,
      "grad_norm": 6.736134052276611,
      "learning_rate": 1.9075903614457835e-05,
      "loss": 0.0792,
      "step": 7670
    },
    {
      "epoch": 0.9253012048192771,
      "grad_norm": 1.0847166776657104,
      "learning_rate": 1.9074698795180724e-05,
      "loss": 0.161,
      "step": 7680
    },
    {
      "epoch": 0.9265060240963855,
      "grad_norm": 3.6224796772003174,
      "learning_rate": 1.9073493975903617e-05,
      "loss": 0.1739,
      "step": 7690
    },
    {
      "epoch": 0.927710843373494,
      "grad_norm": 4.854403018951416,
      "learning_rate": 1.9072289156626506e-05,
      "loss": 0.0927,
      "step": 7700
    },
    {
      "epoch": 0.9289156626506024,
      "grad_norm": 6.322175979614258,
      "learning_rate": 1.9071084337349398e-05,
      "loss": 0.085,
      "step": 7710
    },
    {
      "epoch": 0.9301204819277108,
      "grad_norm": 2.200737714767456,
      "learning_rate": 1.906987951807229e-05,
      "loss": 0.1475,
      "step": 7720
    },
    {
      "epoch": 0.9313253012048193,
      "grad_norm": 8.76975154876709,
      "learning_rate": 1.9068674698795183e-05,
      "loss": 0.088,
      "step": 7730
    },
    {
      "epoch": 0.9325301204819277,
      "grad_norm": 17.57145118713379,
      "learning_rate": 1.9067469879518076e-05,
      "loss": 0.1799,
      "step": 7740
    },
    {
      "epoch": 0.9337349397590361,
      "grad_norm": 7.02876615524292,
      "learning_rate": 1.9066265060240965e-05,
      "loss": 0.1255,
      "step": 7750
    },
    {
      "epoch": 0.9349397590361446,
      "grad_norm": 5.34642219543457,
      "learning_rate": 1.9065060240963857e-05,
      "loss": 0.1402,
      "step": 7760
    },
    {
      "epoch": 0.936144578313253,
      "grad_norm": 2.74117112159729,
      "learning_rate": 1.906385542168675e-05,
      "loss": 0.0483,
      "step": 7770
    },
    {
      "epoch": 0.9373493975903614,
      "grad_norm": 11.67861270904541,
      "learning_rate": 1.9062650602409642e-05,
      "loss": 0.1067,
      "step": 7780
    },
    {
      "epoch": 0.9385542168674699,
      "grad_norm": 6.951568603515625,
      "learning_rate": 1.906144578313253e-05,
      "loss": 0.1068,
      "step": 7790
    },
    {
      "epoch": 0.9397590361445783,
      "grad_norm": 0.2529253661632538,
      "learning_rate": 1.9060240963855423e-05,
      "loss": 0.0887,
      "step": 7800
    },
    {
      "epoch": 0.9409638554216867,
      "grad_norm": 2.356112241744995,
      "learning_rate": 1.9059036144578316e-05,
      "loss": 0.1469,
      "step": 7810
    },
    {
      "epoch": 0.9421686746987952,
      "grad_norm": 9.462899208068848,
      "learning_rate": 1.9057831325301205e-05,
      "loss": 0.1562,
      "step": 7820
    },
    {
      "epoch": 0.9433734939759036,
      "grad_norm": 7.6008453369140625,
      "learning_rate": 1.9056626506024097e-05,
      "loss": 0.096,
      "step": 7830
    },
    {
      "epoch": 0.944578313253012,
      "grad_norm": 9.80964183807373,
      "learning_rate": 1.905542168674699e-05,
      "loss": 0.1442,
      "step": 7840
    },
    {
      "epoch": 0.9457831325301205,
      "grad_norm": 2.0080618858337402,
      "learning_rate": 1.9054216867469882e-05,
      "loss": 0.0726,
      "step": 7850
    },
    {
      "epoch": 0.946987951807229,
      "grad_norm": 8.085689544677734,
      "learning_rate": 1.905301204819277e-05,
      "loss": 0.1007,
      "step": 7860
    },
    {
      "epoch": 0.9481927710843373,
      "grad_norm": 3.126376152038574,
      "learning_rate": 1.9051807228915664e-05,
      "loss": 0.1663,
      "step": 7870
    },
    {
      "epoch": 0.9493975903614458,
      "grad_norm": 6.45121431350708,
      "learning_rate": 1.9050602409638556e-05,
      "loss": 0.1376,
      "step": 7880
    },
    {
      "epoch": 0.9506024096385542,
      "grad_norm": 1.4170054197311401,
      "learning_rate": 1.904939759036145e-05,
      "loss": 0.1741,
      "step": 7890
    },
    {
      "epoch": 0.9518072289156626,
      "grad_norm": 6.969135284423828,
      "learning_rate": 1.904819277108434e-05,
      "loss": 0.2252,
      "step": 7900
    },
    {
      "epoch": 0.9530120481927711,
      "grad_norm": 5.124544620513916,
      "learning_rate": 1.904698795180723e-05,
      "loss": 0.1278,
      "step": 7910
    },
    {
      "epoch": 0.9542168674698795,
      "grad_norm": 3.744462013244629,
      "learning_rate": 1.9045783132530122e-05,
      "loss": 0.0787,
      "step": 7920
    },
    {
      "epoch": 0.9554216867469879,
      "grad_norm": 1.6982767581939697,
      "learning_rate": 1.904457831325301e-05,
      "loss": 0.0949,
      "step": 7930
    },
    {
      "epoch": 0.9566265060240964,
      "grad_norm": 7.605827331542969,
      "learning_rate": 1.9043373493975904e-05,
      "loss": 0.1418,
      "step": 7940
    },
    {
      "epoch": 0.9578313253012049,
      "grad_norm": 10.770238876342773,
      "learning_rate": 1.9042168674698796e-05,
      "loss": 0.2614,
      "step": 7950
    },
    {
      "epoch": 0.9590361445783132,
      "grad_norm": 1.7643592357635498,
      "learning_rate": 1.904096385542169e-05,
      "loss": 0.0712,
      "step": 7960
    },
    {
      "epoch": 0.9602409638554217,
      "grad_norm": 1.7386986017227173,
      "learning_rate": 1.903975903614458e-05,
      "loss": 0.1308,
      "step": 7970
    },
    {
      "epoch": 0.9614457831325302,
      "grad_norm": 2.347132921218872,
      "learning_rate": 1.903855421686747e-05,
      "loss": 0.1416,
      "step": 7980
    },
    {
      "epoch": 0.9626506024096385,
      "grad_norm": 5.473455905914307,
      "learning_rate": 1.9037349397590363e-05,
      "loss": 0.1345,
      "step": 7990
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 2.782407760620117,
      "learning_rate": 1.9036144578313255e-05,
      "loss": 0.1204,
      "step": 8000
    },
    {
      "epoch": 0.9650602409638555,
      "grad_norm": 10.150954246520996,
      "learning_rate": 1.9034939759036148e-05,
      "loss": 0.1231,
      "step": 8010
    },
    {
      "epoch": 0.9662650602409638,
      "grad_norm": 3.929348945617676,
      "learning_rate": 1.903373493975904e-05,
      "loss": 0.1706,
      "step": 8020
    },
    {
      "epoch": 0.9674698795180723,
      "grad_norm": 7.204498767852783,
      "learning_rate": 1.903253012048193e-05,
      "loss": 0.0974,
      "step": 8030
    },
    {
      "epoch": 0.9686746987951808,
      "grad_norm": 3.6507270336151123,
      "learning_rate": 1.903132530120482e-05,
      "loss": 0.1496,
      "step": 8040
    },
    {
      "epoch": 0.9698795180722891,
      "grad_norm": 4.546549320220947,
      "learning_rate": 1.903012048192771e-05,
      "loss": 0.0849,
      "step": 8050
    },
    {
      "epoch": 0.9710843373493976,
      "grad_norm": 3.4798359870910645,
      "learning_rate": 1.9028915662650603e-05,
      "loss": 0.1292,
      "step": 8060
    },
    {
      "epoch": 0.9722891566265061,
      "grad_norm": 3.122567653656006,
      "learning_rate": 1.9027710843373495e-05,
      "loss": 0.2548,
      "step": 8070
    },
    {
      "epoch": 0.9734939759036144,
      "grad_norm": 5.8077311515808105,
      "learning_rate": 1.9026506024096388e-05,
      "loss": 0.163,
      "step": 8080
    },
    {
      "epoch": 0.9746987951807229,
      "grad_norm": 3.752939224243164,
      "learning_rate": 1.9025301204819277e-05,
      "loss": 0.1056,
      "step": 8090
    },
    {
      "epoch": 0.9759036144578314,
      "grad_norm": 1.6235448122024536,
      "learning_rate": 1.902409638554217e-05,
      "loss": 0.1413,
      "step": 8100
    },
    {
      "epoch": 0.9771084337349397,
      "grad_norm": 12.344551086425781,
      "learning_rate": 1.9022891566265062e-05,
      "loss": 0.1544,
      "step": 8110
    },
    {
      "epoch": 0.9783132530120482,
      "grad_norm": 2.7616424560546875,
      "learning_rate": 1.9021686746987954e-05,
      "loss": 0.1188,
      "step": 8120
    },
    {
      "epoch": 0.9795180722891567,
      "grad_norm": 4.193707466125488,
      "learning_rate": 1.9020481927710847e-05,
      "loss": 0.1473,
      "step": 8130
    },
    {
      "epoch": 0.980722891566265,
      "grad_norm": 9.242531776428223,
      "learning_rate": 1.9019277108433736e-05,
      "loss": 0.1839,
      "step": 8140
    },
    {
      "epoch": 0.9819277108433735,
      "grad_norm": 3.2403385639190674,
      "learning_rate": 1.9018072289156628e-05,
      "loss": 0.1538,
      "step": 8150
    },
    {
      "epoch": 0.983132530120482,
      "grad_norm": 9.674422264099121,
      "learning_rate": 1.9016867469879517e-05,
      "loss": 0.1764,
      "step": 8160
    },
    {
      "epoch": 0.9843373493975903,
      "grad_norm": 14.110088348388672,
      "learning_rate": 1.901566265060241e-05,
      "loss": 0.1506,
      "step": 8170
    },
    {
      "epoch": 0.9855421686746988,
      "grad_norm": 3.5563666820526123,
      "learning_rate": 1.9014457831325302e-05,
      "loss": 0.196,
      "step": 8180
    },
    {
      "epoch": 0.9867469879518073,
      "grad_norm": 4.4801411628723145,
      "learning_rate": 1.9013253012048194e-05,
      "loss": 0.1557,
      "step": 8190
    },
    {
      "epoch": 0.9879518072289156,
      "grad_norm": 3.5100598335266113,
      "learning_rate": 1.9012048192771087e-05,
      "loss": 0.0737,
      "step": 8200
    },
    {
      "epoch": 0.9891566265060241,
      "grad_norm": 0.28790849447250366,
      "learning_rate": 1.9010843373493976e-05,
      "loss": 0.1189,
      "step": 8210
    },
    {
      "epoch": 0.9903614457831326,
      "grad_norm": 2.680454969406128,
      "learning_rate": 1.900963855421687e-05,
      "loss": 0.2667,
      "step": 8220
    },
    {
      "epoch": 0.9915662650602409,
      "grad_norm": 47.30215835571289,
      "learning_rate": 1.900843373493976e-05,
      "loss": 0.1594,
      "step": 8230
    },
    {
      "epoch": 0.9927710843373494,
      "grad_norm": 7.5052571296691895,
      "learning_rate": 1.9007228915662653e-05,
      "loss": 0.1733,
      "step": 8240
    },
    {
      "epoch": 0.9939759036144579,
      "grad_norm": 7.58150053024292,
      "learning_rate": 1.9006024096385546e-05,
      "loss": 0.1703,
      "step": 8250
    },
    {
      "epoch": 0.9951807228915662,
      "grad_norm": 9.067438125610352,
      "learning_rate": 1.9004819277108435e-05,
      "loss": 0.1569,
      "step": 8260
    },
    {
      "epoch": 0.9963855421686747,
      "grad_norm": 5.001882553100586,
      "learning_rate": 1.9003614457831327e-05,
      "loss": 0.0878,
      "step": 8270
    },
    {
      "epoch": 0.9975903614457832,
      "grad_norm": 12.65656852722168,
      "learning_rate": 1.9002409638554216e-05,
      "loss": 0.123,
      "step": 8280
    },
    {
      "epoch": 0.9987951807228915,
      "grad_norm": 6.725470542907715,
      "learning_rate": 1.9001204819277112e-05,
      "loss": 0.1835,
      "step": 8290
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.343153953552246,
      "learning_rate": 1.9e-05,
      "loss": 0.1517,
      "step": 8300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.95751312335958,
      "eval_f1": 0.8830699774266366,
      "eval_loss": 0.11360882967710495,
      "eval_precision": 0.923388184515781,
      "eval_recall": 0.8461253244345569,
      "eval_runtime": 3391.7252,
      "eval_samples_per_second": 12.587,
      "eval_steps_per_second": 0.525,
      "step": 8300
    },
    {
      "epoch": 1.0012048192771084,
      "grad_norm": 29.338186264038086,
      "learning_rate": 1.8998795180722893e-05,
      "loss": 0.1399,
      "step": 8310
    },
    {
      "epoch": 1.002409638554217,
      "grad_norm": 4.188158988952637,
      "learning_rate": 1.8997590361445786e-05,
      "loss": 0.1104,
      "step": 8320
    },
    {
      "epoch": 1.0036144578313253,
      "grad_norm": 1.2457722425460815,
      "learning_rate": 1.8996385542168675e-05,
      "loss": 0.1397,
      "step": 8330
    },
    {
      "epoch": 1.0048192771084337,
      "grad_norm": 4.026923179626465,
      "learning_rate": 1.8995180722891567e-05,
      "loss": 0.1164,
      "step": 8340
    },
    {
      "epoch": 1.0060240963855422,
      "grad_norm": 13.738385200500488,
      "learning_rate": 1.899397590361446e-05,
      "loss": 0.207,
      "step": 8350
    },
    {
      "epoch": 1.0072289156626506,
      "grad_norm": 11.804631233215332,
      "learning_rate": 1.8992771084337352e-05,
      "loss": 0.1404,
      "step": 8360
    },
    {
      "epoch": 1.008433734939759,
      "grad_norm": 5.978418350219727,
      "learning_rate": 1.899156626506024e-05,
      "loss": 0.126,
      "step": 8370
    },
    {
      "epoch": 1.0096385542168675,
      "grad_norm": 3.11037015914917,
      "learning_rate": 1.8990361445783134e-05,
      "loss": 0.0525,
      "step": 8380
    },
    {
      "epoch": 1.010843373493976,
      "grad_norm": 6.060598373413086,
      "learning_rate": 1.8989156626506026e-05,
      "loss": 0.1379,
      "step": 8390
    },
    {
      "epoch": 1.0120481927710843,
      "grad_norm": 9.028279304504395,
      "learning_rate": 1.898795180722892e-05,
      "loss": 0.0509,
      "step": 8400
    },
    {
      "epoch": 1.0132530120481928,
      "grad_norm": 12.665384292602539,
      "learning_rate": 1.898674698795181e-05,
      "loss": 0.1637,
      "step": 8410
    },
    {
      "epoch": 1.0144578313253012,
      "grad_norm": 19.589153289794922,
      "learning_rate": 1.89855421686747e-05,
      "loss": 0.1216,
      "step": 8420
    },
    {
      "epoch": 1.0156626506024096,
      "grad_norm": 1.1149811744689941,
      "learning_rate": 1.8984337349397593e-05,
      "loss": 0.111,
      "step": 8430
    },
    {
      "epoch": 1.0168674698795181,
      "grad_norm": 0.13572224974632263,
      "learning_rate": 1.898313253012048e-05,
      "loss": 0.1143,
      "step": 8440
    },
    {
      "epoch": 1.0180722891566265,
      "grad_norm": 0.36883071064949036,
      "learning_rate": 1.8981927710843374e-05,
      "loss": 0.1075,
      "step": 8450
    },
    {
      "epoch": 1.0192771084337349,
      "grad_norm": 6.09022855758667,
      "learning_rate": 1.8980722891566266e-05,
      "loss": 0.0851,
      "step": 8460
    },
    {
      "epoch": 1.0204819277108435,
      "grad_norm": 0.1432768702507019,
      "learning_rate": 1.897951807228916e-05,
      "loss": 0.0936,
      "step": 8470
    },
    {
      "epoch": 1.0216867469879518,
      "grad_norm": 27.268892288208008,
      "learning_rate": 1.897831325301205e-05,
      "loss": 0.1714,
      "step": 8480
    },
    {
      "epoch": 1.0228915662650602,
      "grad_norm": 2.654381036758423,
      "learning_rate": 1.897710843373494e-05,
      "loss": 0.0908,
      "step": 8490
    },
    {
      "epoch": 1.0240963855421688,
      "grad_norm": 0.13368570804595947,
      "learning_rate": 1.8975903614457833e-05,
      "loss": 0.0769,
      "step": 8500
    },
    {
      "epoch": 1.0253012048192771,
      "grad_norm": 0.5176703929901123,
      "learning_rate": 1.8974698795180725e-05,
      "loss": 0.1429,
      "step": 8510
    },
    {
      "epoch": 1.0265060240963855,
      "grad_norm": 3.2604563236236572,
      "learning_rate": 1.8973493975903618e-05,
      "loss": 0.1316,
      "step": 8520
    },
    {
      "epoch": 1.027710843373494,
      "grad_norm": 9.786009788513184,
      "learning_rate": 1.8972289156626507e-05,
      "loss": 0.103,
      "step": 8530
    },
    {
      "epoch": 1.0289156626506024,
      "grad_norm": 18.698951721191406,
      "learning_rate": 1.89710843373494e-05,
      "loss": 0.0997,
      "step": 8540
    },
    {
      "epoch": 1.0301204819277108,
      "grad_norm": 11.817174911499023,
      "learning_rate": 1.896987951807229e-05,
      "loss": 0.1303,
      "step": 8550
    },
    {
      "epoch": 1.0313253012048194,
      "grad_norm": 4.2321858406066895,
      "learning_rate": 1.896867469879518e-05,
      "loss": 0.1084,
      "step": 8560
    },
    {
      "epoch": 1.0325301204819277,
      "grad_norm": 3.2218713760375977,
      "learning_rate": 1.8967469879518073e-05,
      "loss": 0.1059,
      "step": 8570
    },
    {
      "epoch": 1.033734939759036,
      "grad_norm": 0.11986243724822998,
      "learning_rate": 1.8966265060240966e-05,
      "loss": 0.1338,
      "step": 8580
    },
    {
      "epoch": 1.0349397590361447,
      "grad_norm": 0.3503952622413635,
      "learning_rate": 1.8965060240963858e-05,
      "loss": 0.1173,
      "step": 8590
    },
    {
      "epoch": 1.036144578313253,
      "grad_norm": 3.3985023498535156,
      "learning_rate": 1.8963855421686747e-05,
      "loss": 0.1225,
      "step": 8600
    },
    {
      "epoch": 1.0373493975903614,
      "grad_norm": 0.30751487612724304,
      "learning_rate": 1.896265060240964e-05,
      "loss": 0.0692,
      "step": 8610
    },
    {
      "epoch": 1.03855421686747,
      "grad_norm": 5.75641393661499,
      "learning_rate": 1.8961445783132532e-05,
      "loss": 0.1666,
      "step": 8620
    },
    {
      "epoch": 1.0397590361445783,
      "grad_norm": 1.7595432996749878,
      "learning_rate": 1.8960240963855424e-05,
      "loss": 0.0585,
      "step": 8630
    },
    {
      "epoch": 1.0409638554216867,
      "grad_norm": 11.733830451965332,
      "learning_rate": 1.8959036144578317e-05,
      "loss": 0.147,
      "step": 8640
    },
    {
      "epoch": 1.0421686746987953,
      "grad_norm": 10.023777961730957,
      "learning_rate": 1.8957831325301206e-05,
      "loss": 0.097,
      "step": 8650
    },
    {
      "epoch": 1.0433734939759036,
      "grad_norm": 4.296696662902832,
      "learning_rate": 1.8956626506024098e-05,
      "loss": 0.0953,
      "step": 8660
    },
    {
      "epoch": 1.044578313253012,
      "grad_norm": 2.790269374847412,
      "learning_rate": 1.8955421686746987e-05,
      "loss": 0.104,
      "step": 8670
    },
    {
      "epoch": 1.0457831325301206,
      "grad_norm": 8.357778549194336,
      "learning_rate": 1.895421686746988e-05,
      "loss": 0.0859,
      "step": 8680
    },
    {
      "epoch": 1.046987951807229,
      "grad_norm": 5.0226664543151855,
      "learning_rate": 1.8953012048192772e-05,
      "loss": 0.1225,
      "step": 8690
    },
    {
      "epoch": 1.0481927710843373,
      "grad_norm": 18.019723892211914,
      "learning_rate": 1.8951807228915665e-05,
      "loss": 0.1682,
      "step": 8700
    },
    {
      "epoch": 1.0493975903614459,
      "grad_norm": 16.254430770874023,
      "learning_rate": 1.8950602409638557e-05,
      "loss": 0.0861,
      "step": 8710
    },
    {
      "epoch": 1.0506024096385542,
      "grad_norm": 5.764893054962158,
      "learning_rate": 1.8949397590361446e-05,
      "loss": 0.1687,
      "step": 8720
    },
    {
      "epoch": 1.0518072289156626,
      "grad_norm": 12.592286109924316,
      "learning_rate": 1.894819277108434e-05,
      "loss": 0.2663,
      "step": 8730
    },
    {
      "epoch": 1.0530120481927712,
      "grad_norm": 25.37216567993164,
      "learning_rate": 1.894698795180723e-05,
      "loss": 0.1306,
      "step": 8740
    },
    {
      "epoch": 1.0542168674698795,
      "grad_norm": 3.984419345855713,
      "learning_rate": 1.8945783132530123e-05,
      "loss": 0.1032,
      "step": 8750
    },
    {
      "epoch": 1.0554216867469879,
      "grad_norm": 2.6387619972229004,
      "learning_rate": 1.8944578313253012e-05,
      "loss": 0.1709,
      "step": 8760
    },
    {
      "epoch": 1.0566265060240965,
      "grad_norm": 5.597728252410889,
      "learning_rate": 1.8943373493975905e-05,
      "loss": 0.1769,
      "step": 8770
    },
    {
      "epoch": 1.0578313253012048,
      "grad_norm": 6.165042877197266,
      "learning_rate": 1.8942168674698797e-05,
      "loss": 0.1139,
      "step": 8780
    },
    {
      "epoch": 1.0590361445783132,
      "grad_norm": 49.7091064453125,
      "learning_rate": 1.8940963855421686e-05,
      "loss": 0.1117,
      "step": 8790
    },
    {
      "epoch": 1.0602409638554218,
      "grad_norm": 36.50204849243164,
      "learning_rate": 1.893975903614458e-05,
      "loss": 0.1097,
      "step": 8800
    },
    {
      "epoch": 1.0614457831325301,
      "grad_norm": 5.328469753265381,
      "learning_rate": 1.893855421686747e-05,
      "loss": 0.0977,
      "step": 8810
    },
    {
      "epoch": 1.0626506024096385,
      "grad_norm": 15.302009582519531,
      "learning_rate": 1.8937349397590364e-05,
      "loss": 0.1286,
      "step": 8820
    },
    {
      "epoch": 1.063855421686747,
      "grad_norm": 2.843571662902832,
      "learning_rate": 1.8936144578313253e-05,
      "loss": 0.1201,
      "step": 8830
    },
    {
      "epoch": 1.0650602409638554,
      "grad_norm": 2.8861730098724365,
      "learning_rate": 1.8934939759036145e-05,
      "loss": 0.1277,
      "step": 8840
    },
    {
      "epoch": 1.0662650602409638,
      "grad_norm": 6.159087181091309,
      "learning_rate": 1.8933734939759038e-05,
      "loss": 0.1692,
      "step": 8850
    },
    {
      "epoch": 1.0674698795180724,
      "grad_norm": 6.219813346862793,
      "learning_rate": 1.893253012048193e-05,
      "loss": 0.0847,
      "step": 8860
    },
    {
      "epoch": 1.0686746987951807,
      "grad_norm": 4.4707818031311035,
      "learning_rate": 1.8931325301204822e-05,
      "loss": 0.1337,
      "step": 8870
    },
    {
      "epoch": 1.069879518072289,
      "grad_norm": 0.8652918338775635,
      "learning_rate": 1.893012048192771e-05,
      "loss": 0.1359,
      "step": 8880
    },
    {
      "epoch": 1.0710843373493977,
      "grad_norm": 5.014257431030273,
      "learning_rate": 1.8928915662650604e-05,
      "loss": 0.1827,
      "step": 8890
    },
    {
      "epoch": 1.072289156626506,
      "grad_norm": 3.109956979751587,
      "learning_rate": 1.8927710843373493e-05,
      "loss": 0.1029,
      "step": 8900
    },
    {
      "epoch": 1.0734939759036144,
      "grad_norm": 1.4964863061904907,
      "learning_rate": 1.892650602409639e-05,
      "loss": 0.0843,
      "step": 8910
    },
    {
      "epoch": 1.074698795180723,
      "grad_norm": 9.797298431396484,
      "learning_rate": 1.892530120481928e-05,
      "loss": 0.1027,
      "step": 8920
    },
    {
      "epoch": 1.0759036144578313,
      "grad_norm": 0.14570747315883636,
      "learning_rate": 1.892409638554217e-05,
      "loss": 0.0683,
      "step": 8930
    },
    {
      "epoch": 1.0771084337349397,
      "grad_norm": 0.45187559723854065,
      "learning_rate": 1.8922891566265063e-05,
      "loss": 0.11,
      "step": 8940
    },
    {
      "epoch": 1.0783132530120483,
      "grad_norm": 8.148178100585938,
      "learning_rate": 1.8921686746987952e-05,
      "loss": 0.1561,
      "step": 8950
    },
    {
      "epoch": 1.0795180722891566,
      "grad_norm": 5.103445529937744,
      "learning_rate": 1.8920481927710844e-05,
      "loss": 0.1733,
      "step": 8960
    },
    {
      "epoch": 1.080722891566265,
      "grad_norm": 0.5098662376403809,
      "learning_rate": 1.8919277108433737e-05,
      "loss": 0.1426,
      "step": 8970
    },
    {
      "epoch": 1.0819277108433736,
      "grad_norm": 7.120963096618652,
      "learning_rate": 1.891807228915663e-05,
      "loss": 0.0868,
      "step": 8980
    },
    {
      "epoch": 1.083132530120482,
      "grad_norm": 1.2103772163391113,
      "learning_rate": 1.891686746987952e-05,
      "loss": 0.1324,
      "step": 8990
    },
    {
      "epoch": 1.0843373493975903,
      "grad_norm": 9.410207748413086,
      "learning_rate": 1.891566265060241e-05,
      "loss": 0.1536,
      "step": 9000
    },
    {
      "epoch": 1.0855421686746989,
      "grad_norm": 2.4218382835388184,
      "learning_rate": 1.8914457831325303e-05,
      "loss": 0.0783,
      "step": 9010
    },
    {
      "epoch": 1.0867469879518072,
      "grad_norm": 6.984931945800781,
      "learning_rate": 1.8913253012048195e-05,
      "loss": 0.0693,
      "step": 9020
    },
    {
      "epoch": 1.0879518072289156,
      "grad_norm": 4.942361831665039,
      "learning_rate": 1.8912048192771088e-05,
      "loss": 0.1089,
      "step": 9030
    },
    {
      "epoch": 1.0891566265060242,
      "grad_norm": 0.9897343516349792,
      "learning_rate": 1.8910843373493977e-05,
      "loss": 0.0566,
      "step": 9040
    },
    {
      "epoch": 1.0903614457831325,
      "grad_norm": 0.8707150816917419,
      "learning_rate": 1.890963855421687e-05,
      "loss": 0.0972,
      "step": 9050
    },
    {
      "epoch": 1.091566265060241,
      "grad_norm": 5.453499794006348,
      "learning_rate": 1.890843373493976e-05,
      "loss": 0.2105,
      "step": 9060
    },
    {
      "epoch": 1.0927710843373495,
      "grad_norm": 5.0374298095703125,
      "learning_rate": 1.890722891566265e-05,
      "loss": 0.1614,
      "step": 9070
    },
    {
      "epoch": 1.0939759036144578,
      "grad_norm": 7.302107334136963,
      "learning_rate": 1.8906024096385543e-05,
      "loss": 0.1202,
      "step": 9080
    },
    {
      "epoch": 1.0951807228915662,
      "grad_norm": 7.432504177093506,
      "learning_rate": 1.8904819277108436e-05,
      "loss": 0.1375,
      "step": 9090
    },
    {
      "epoch": 1.0963855421686748,
      "grad_norm": 7.529428958892822,
      "learning_rate": 1.8903614457831328e-05,
      "loss": 0.1481,
      "step": 9100
    },
    {
      "epoch": 1.0975903614457831,
      "grad_norm": 0.670801043510437,
      "learning_rate": 1.8902409638554217e-05,
      "loss": 0.1114,
      "step": 9110
    },
    {
      "epoch": 1.0987951807228915,
      "grad_norm": 4.629739284515381,
      "learning_rate": 1.890120481927711e-05,
      "loss": 0.0928,
      "step": 9120
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.5981926918029785,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0712,
      "step": 9130
    },
    {
      "epoch": 1.1012048192771084,
      "grad_norm": 1.0326787233352661,
      "learning_rate": 1.8898795180722894e-05,
      "loss": 0.1253,
      "step": 9140
    },
    {
      "epoch": 1.1024096385542168,
      "grad_norm": 10.716147422790527,
      "learning_rate": 1.8897590361445787e-05,
      "loss": 0.1042,
      "step": 9150
    },
    {
      "epoch": 1.1036144578313254,
      "grad_norm": 5.74704647064209,
      "learning_rate": 1.8896385542168676e-05,
      "loss": 0.0976,
      "step": 9160
    },
    {
      "epoch": 1.1048192771084338,
      "grad_norm": 5.751653671264648,
      "learning_rate": 1.889518072289157e-05,
      "loss": 0.137,
      "step": 9170
    },
    {
      "epoch": 1.106024096385542,
      "grad_norm": 3.81194806098938,
      "learning_rate": 1.8893975903614457e-05,
      "loss": 0.0908,
      "step": 9180
    },
    {
      "epoch": 1.1072289156626507,
      "grad_norm": 10.580780029296875,
      "learning_rate": 1.889277108433735e-05,
      "loss": 0.1246,
      "step": 9190
    },
    {
      "epoch": 1.108433734939759,
      "grad_norm": 51.79623031616211,
      "learning_rate": 1.8891566265060242e-05,
      "loss": 0.182,
      "step": 9200
    },
    {
      "epoch": 1.1096385542168674,
      "grad_norm": 4.000154972076416,
      "learning_rate": 1.8890361445783135e-05,
      "loss": 0.0824,
      "step": 9210
    },
    {
      "epoch": 1.110843373493976,
      "grad_norm": 9.155112266540527,
      "learning_rate": 1.8889156626506027e-05,
      "loss": 0.1493,
      "step": 9220
    },
    {
      "epoch": 1.1120481927710844,
      "grad_norm": 23.69849395751953,
      "learning_rate": 1.8887951807228916e-05,
      "loss": 0.1921,
      "step": 9230
    },
    {
      "epoch": 1.1132530120481927,
      "grad_norm": 6.6020731925964355,
      "learning_rate": 1.888674698795181e-05,
      "loss": 0.1617,
      "step": 9240
    },
    {
      "epoch": 1.1144578313253013,
      "grad_norm": 0.808535635471344,
      "learning_rate": 1.88855421686747e-05,
      "loss": 0.1388,
      "step": 9250
    },
    {
      "epoch": 1.1156626506024097,
      "grad_norm": 6.227928638458252,
      "learning_rate": 1.8884337349397593e-05,
      "loss": 0.107,
      "step": 9260
    },
    {
      "epoch": 1.116867469879518,
      "grad_norm": 4.828413963317871,
      "learning_rate": 1.8883132530120483e-05,
      "loss": 0.0656,
      "step": 9270
    },
    {
      "epoch": 1.1180722891566266,
      "grad_norm": 1.3986785411834717,
      "learning_rate": 1.8881927710843375e-05,
      "loss": 0.1097,
      "step": 9280
    },
    {
      "epoch": 1.119277108433735,
      "grad_norm": 0.41755416989326477,
      "learning_rate": 1.8880722891566267e-05,
      "loss": 0.1906,
      "step": 9290
    },
    {
      "epoch": 1.1204819277108433,
      "grad_norm": 8.568617820739746,
      "learning_rate": 1.8879518072289156e-05,
      "loss": 0.0833,
      "step": 9300
    },
    {
      "epoch": 1.121686746987952,
      "grad_norm": 0.36226895451545715,
      "learning_rate": 1.887831325301205e-05,
      "loss": 0.1715,
      "step": 9310
    },
    {
      "epoch": 1.1228915662650603,
      "grad_norm": 4.6909308433532715,
      "learning_rate": 1.887710843373494e-05,
      "loss": 0.129,
      "step": 9320
    },
    {
      "epoch": 1.1240963855421686,
      "grad_norm": 10.69211483001709,
      "learning_rate": 1.8875903614457834e-05,
      "loss": 0.0941,
      "step": 9330
    },
    {
      "epoch": 1.1253012048192772,
      "grad_norm": 9.46218204498291,
      "learning_rate": 1.8874698795180723e-05,
      "loss": 0.1192,
      "step": 9340
    },
    {
      "epoch": 1.1265060240963856,
      "grad_norm": 9.929840087890625,
      "learning_rate": 1.8873493975903615e-05,
      "loss": 0.0458,
      "step": 9350
    },
    {
      "epoch": 1.127710843373494,
      "grad_norm": 25.904935836791992,
      "learning_rate": 1.8872289156626508e-05,
      "loss": 0.1452,
      "step": 9360
    },
    {
      "epoch": 1.1289156626506025,
      "grad_norm": 11.241101264953613,
      "learning_rate": 1.88710843373494e-05,
      "loss": 0.2072,
      "step": 9370
    },
    {
      "epoch": 1.1301204819277109,
      "grad_norm": 20.334087371826172,
      "learning_rate": 1.8869879518072293e-05,
      "loss": 0.1058,
      "step": 9380
    },
    {
      "epoch": 1.1313253012048192,
      "grad_norm": 1.2680753469467163,
      "learning_rate": 1.886867469879518e-05,
      "loss": 0.1518,
      "step": 9390
    },
    {
      "epoch": 1.1325301204819278,
      "grad_norm": 5.469579219818115,
      "learning_rate": 1.8867469879518074e-05,
      "loss": 0.1304,
      "step": 9400
    },
    {
      "epoch": 1.1337349397590362,
      "grad_norm": 0.6068403720855713,
      "learning_rate": 1.8866265060240963e-05,
      "loss": 0.0625,
      "step": 9410
    },
    {
      "epoch": 1.1349397590361445,
      "grad_norm": 0.18465395271778107,
      "learning_rate": 1.886506024096386e-05,
      "loss": 0.0927,
      "step": 9420
    },
    {
      "epoch": 1.136144578313253,
      "grad_norm": 6.099328994750977,
      "learning_rate": 1.8863855421686748e-05,
      "loss": 0.2065,
      "step": 9430
    },
    {
      "epoch": 1.1373493975903615,
      "grad_norm": 0.3352581560611725,
      "learning_rate": 1.886265060240964e-05,
      "loss": 0.0742,
      "step": 9440
    },
    {
      "epoch": 1.1385542168674698,
      "grad_norm": 3.4053046703338623,
      "learning_rate": 1.8861445783132533e-05,
      "loss": 0.133,
      "step": 9450
    },
    {
      "epoch": 1.1397590361445784,
      "grad_norm": 4.399635314941406,
      "learning_rate": 1.8860240963855422e-05,
      "loss": 0.128,
      "step": 9460
    },
    {
      "epoch": 1.1409638554216868,
      "grad_norm": 4.266578197479248,
      "learning_rate": 1.8859036144578314e-05,
      "loss": 0.069,
      "step": 9470
    },
    {
      "epoch": 1.1421686746987951,
      "grad_norm": 3.4964542388916016,
      "learning_rate": 1.8857831325301207e-05,
      "loss": 0.0935,
      "step": 9480
    },
    {
      "epoch": 1.1433734939759037,
      "grad_norm": 0.021363666281104088,
      "learning_rate": 1.88566265060241e-05,
      "loss": 0.0659,
      "step": 9490
    },
    {
      "epoch": 1.144578313253012,
      "grad_norm": 0.1997777372598648,
      "learning_rate": 1.8855421686746988e-05,
      "loss": 0.1333,
      "step": 9500
    },
    {
      "epoch": 1.1457831325301204,
      "grad_norm": 3.022709846496582,
      "learning_rate": 1.885421686746988e-05,
      "loss": 0.1394,
      "step": 9510
    },
    {
      "epoch": 1.146987951807229,
      "grad_norm": 4.524020195007324,
      "learning_rate": 1.8853012048192773e-05,
      "loss": 0.1511,
      "step": 9520
    },
    {
      "epoch": 1.1481927710843374,
      "grad_norm": 0.6276871562004089,
      "learning_rate": 1.8851807228915666e-05,
      "loss": 0.1035,
      "step": 9530
    },
    {
      "epoch": 1.1493975903614457,
      "grad_norm": 2.536532402038574,
      "learning_rate": 1.8850602409638558e-05,
      "loss": 0.1453,
      "step": 9540
    },
    {
      "epoch": 1.1506024096385543,
      "grad_norm": 1.4728951454162598,
      "learning_rate": 1.8849397590361447e-05,
      "loss": 0.1544,
      "step": 9550
    },
    {
      "epoch": 1.1518072289156627,
      "grad_norm": 3.3619279861450195,
      "learning_rate": 1.884819277108434e-05,
      "loss": 0.0735,
      "step": 9560
    },
    {
      "epoch": 1.153012048192771,
      "grad_norm": 4.6502766609191895,
      "learning_rate": 1.884698795180723e-05,
      "loss": 0.1024,
      "step": 9570
    },
    {
      "epoch": 1.1542168674698796,
      "grad_norm": 3.044739007949829,
      "learning_rate": 1.884578313253012e-05,
      "loss": 0.1284,
      "step": 9580
    },
    {
      "epoch": 1.155421686746988,
      "grad_norm": 14.828577041625977,
      "learning_rate": 1.8844578313253013e-05,
      "loss": 0.1055,
      "step": 9590
    },
    {
      "epoch": 1.1566265060240963,
      "grad_norm": 0.08933626115322113,
      "learning_rate": 1.8843373493975906e-05,
      "loss": 0.0534,
      "step": 9600
    },
    {
      "epoch": 1.157831325301205,
      "grad_norm": 8.036260604858398,
      "learning_rate": 1.8842168674698798e-05,
      "loss": 0.0829,
      "step": 9610
    },
    {
      "epoch": 1.1590361445783133,
      "grad_norm": 0.042575206607580185,
      "learning_rate": 1.8840963855421687e-05,
      "loss": 0.0615,
      "step": 9620
    },
    {
      "epoch": 1.1602409638554216,
      "grad_norm": 0.8577762842178345,
      "learning_rate": 1.883975903614458e-05,
      "loss": 0.1324,
      "step": 9630
    },
    {
      "epoch": 1.16144578313253,
      "grad_norm": 3.1424458026885986,
      "learning_rate": 1.8838554216867472e-05,
      "loss": 0.1291,
      "step": 9640
    },
    {
      "epoch": 1.1626506024096386,
      "grad_norm": 7.8798112869262695,
      "learning_rate": 1.8837349397590365e-05,
      "loss": 0.0983,
      "step": 9650
    },
    {
      "epoch": 1.163855421686747,
      "grad_norm": 1.348100185394287,
      "learning_rate": 1.8836144578313254e-05,
      "loss": 0.0933,
      "step": 9660
    },
    {
      "epoch": 1.1650602409638555,
      "grad_norm": 6.263021469116211,
      "learning_rate": 1.8834939759036146e-05,
      "loss": 0.0974,
      "step": 9670
    },
    {
      "epoch": 1.1662650602409639,
      "grad_norm": 1.51878023147583,
      "learning_rate": 1.883373493975904e-05,
      "loss": 0.104,
      "step": 9680
    },
    {
      "epoch": 1.1674698795180722,
      "grad_norm": 6.678329944610596,
      "learning_rate": 1.8832530120481928e-05,
      "loss": 0.1204,
      "step": 9690
    },
    {
      "epoch": 1.1686746987951806,
      "grad_norm": 0.30339545011520386,
      "learning_rate": 1.883132530120482e-05,
      "loss": 0.139,
      "step": 9700
    },
    {
      "epoch": 1.1698795180722892,
      "grad_norm": 23.260894775390625,
      "learning_rate": 1.8830120481927712e-05,
      "loss": 0.0944,
      "step": 9710
    },
    {
      "epoch": 1.1710843373493975,
      "grad_norm": 3.1895503997802734,
      "learning_rate": 1.8828915662650605e-05,
      "loss": 0.0954,
      "step": 9720
    },
    {
      "epoch": 1.1722891566265061,
      "grad_norm": 5.343540191650391,
      "learning_rate": 1.8827710843373494e-05,
      "loss": 0.0379,
      "step": 9730
    },
    {
      "epoch": 1.1734939759036145,
      "grad_norm": 3.5223662853240967,
      "learning_rate": 1.8826506024096386e-05,
      "loss": 0.086,
      "step": 9740
    },
    {
      "epoch": 1.1746987951807228,
      "grad_norm": 0.2334267646074295,
      "learning_rate": 1.882530120481928e-05,
      "loss": 0.1386,
      "step": 9750
    },
    {
      "epoch": 1.1759036144578312,
      "grad_norm": 0.23364819586277008,
      "learning_rate": 1.882409638554217e-05,
      "loss": 0.1104,
      "step": 9760
    },
    {
      "epoch": 1.1771084337349398,
      "grad_norm": 9.58029842376709,
      "learning_rate": 1.8822891566265064e-05,
      "loss": 0.1389,
      "step": 9770
    },
    {
      "epoch": 1.1783132530120481,
      "grad_norm": 9.009129524230957,
      "learning_rate": 1.8821686746987953e-05,
      "loss": 0.0924,
      "step": 9780
    },
    {
      "epoch": 1.1795180722891567,
      "grad_norm": 0.10785012692213058,
      "learning_rate": 1.8820481927710845e-05,
      "loss": 0.1127,
      "step": 9790
    },
    {
      "epoch": 1.180722891566265,
      "grad_norm": 3.3319509029388428,
      "learning_rate": 1.8819277108433734e-05,
      "loss": 0.0687,
      "step": 9800
    },
    {
      "epoch": 1.1819277108433734,
      "grad_norm": 3.864811897277832,
      "learning_rate": 1.8818072289156627e-05,
      "loss": 0.1568,
      "step": 9810
    },
    {
      "epoch": 1.1831325301204818,
      "grad_norm": 6.4757585525512695,
      "learning_rate": 1.881686746987952e-05,
      "loss": 0.1404,
      "step": 9820
    },
    {
      "epoch": 1.1843373493975904,
      "grad_norm": 4.660233497619629,
      "learning_rate": 1.881566265060241e-05,
      "loss": 0.0952,
      "step": 9830
    },
    {
      "epoch": 1.1855421686746987,
      "grad_norm": 8.530694961547852,
      "learning_rate": 1.8814457831325304e-05,
      "loss": 0.0696,
      "step": 9840
    },
    {
      "epoch": 1.1867469879518073,
      "grad_norm": 2.5775580406188965,
      "learning_rate": 1.8813253012048193e-05,
      "loss": 0.1206,
      "step": 9850
    },
    {
      "epoch": 1.1879518072289157,
      "grad_norm": 7.908321857452393,
      "learning_rate": 1.8812048192771085e-05,
      "loss": 0.1843,
      "step": 9860
    },
    {
      "epoch": 1.189156626506024,
      "grad_norm": 0.2795177102088928,
      "learning_rate": 1.8810843373493978e-05,
      "loss": 0.1261,
      "step": 9870
    },
    {
      "epoch": 1.1903614457831324,
      "grad_norm": 10.074963569641113,
      "learning_rate": 1.880963855421687e-05,
      "loss": 0.1073,
      "step": 9880
    },
    {
      "epoch": 1.191566265060241,
      "grad_norm": 1.6690956354141235,
      "learning_rate": 1.8808433734939763e-05,
      "loss": 0.0991,
      "step": 9890
    },
    {
      "epoch": 1.1927710843373494,
      "grad_norm": 0.1696661412715912,
      "learning_rate": 1.8807228915662652e-05,
      "loss": 0.0833,
      "step": 9900
    },
    {
      "epoch": 1.193975903614458,
      "grad_norm": 0.8192403316497803,
      "learning_rate": 1.8806024096385544e-05,
      "loss": 0.0741,
      "step": 9910
    },
    {
      "epoch": 1.1951807228915663,
      "grad_norm": 25.15546417236328,
      "learning_rate": 1.8804819277108433e-05,
      "loss": 0.1503,
      "step": 9920
    },
    {
      "epoch": 1.1963855421686747,
      "grad_norm": 0.8731607794761658,
      "learning_rate": 1.8803614457831326e-05,
      "loss": 0.1285,
      "step": 9930
    },
    {
      "epoch": 1.197590361445783,
      "grad_norm": 4.233292102813721,
      "learning_rate": 1.8802409638554218e-05,
      "loss": 0.077,
      "step": 9940
    },
    {
      "epoch": 1.1987951807228916,
      "grad_norm": 0.462738037109375,
      "learning_rate": 1.880120481927711e-05,
      "loss": 0.1471,
      "step": 9950
    },
    {
      "epoch": 1.2,
      "grad_norm": 5.26223087310791,
      "learning_rate": 1.88e-05,
      "loss": 0.1154,
      "step": 9960
    },
    {
      "epoch": 1.2012048192771085,
      "grad_norm": 10.254213333129883,
      "learning_rate": 1.8798795180722892e-05,
      "loss": 0.1068,
      "step": 9970
    },
    {
      "epoch": 1.202409638554217,
      "grad_norm": 1.1159554719924927,
      "learning_rate": 1.8797590361445784e-05,
      "loss": 0.088,
      "step": 9980
    },
    {
      "epoch": 1.2036144578313253,
      "grad_norm": 23.745765686035156,
      "learning_rate": 1.8796385542168677e-05,
      "loss": 0.1086,
      "step": 9990
    },
    {
      "epoch": 1.2048192771084336,
      "grad_norm": 5.798732280731201,
      "learning_rate": 1.879518072289157e-05,
      "loss": 0.1426,
      "step": 10000
    },
    {
      "epoch": 1.2060240963855422,
      "grad_norm": 0.4346736967563629,
      "learning_rate": 1.879397590361446e-05,
      "loss": 0.0573,
      "step": 10010
    },
    {
      "epoch": 1.2072289156626506,
      "grad_norm": 4.05691385269165,
      "learning_rate": 1.879277108433735e-05,
      "loss": 0.1376,
      "step": 10020
    },
    {
      "epoch": 1.2084337349397591,
      "grad_norm": 12.560583114624023,
      "learning_rate": 1.879156626506024e-05,
      "loss": 0.1031,
      "step": 10030
    },
    {
      "epoch": 1.2096385542168675,
      "grad_norm": 26.290523529052734,
      "learning_rate": 1.8790361445783136e-05,
      "loss": 0.1614,
      "step": 10040
    },
    {
      "epoch": 1.2108433734939759,
      "grad_norm": 2.0903728008270264,
      "learning_rate": 1.8789156626506028e-05,
      "loss": 0.1115,
      "step": 10050
    },
    {
      "epoch": 1.2120481927710842,
      "grad_norm": 0.11635414510965347,
      "learning_rate": 1.8787951807228917e-05,
      "loss": 0.0466,
      "step": 10060
    },
    {
      "epoch": 1.2132530120481928,
      "grad_norm": 6.799263000488281,
      "learning_rate": 1.878674698795181e-05,
      "loss": 0.0958,
      "step": 10070
    },
    {
      "epoch": 1.2144578313253012,
      "grad_norm": 9.592815399169922,
      "learning_rate": 1.87855421686747e-05,
      "loss": 0.0826,
      "step": 10080
    },
    {
      "epoch": 1.2156626506024097,
      "grad_norm": 0.5503074526786804,
      "learning_rate": 1.878433734939759e-05,
      "loss": 0.1069,
      "step": 10090
    },
    {
      "epoch": 1.216867469879518,
      "grad_norm": 3.602024555206299,
      "learning_rate": 1.8783132530120483e-05,
      "loss": 0.1553,
      "step": 10100
    },
    {
      "epoch": 1.2180722891566265,
      "grad_norm": 3.418139696121216,
      "learning_rate": 1.8781927710843376e-05,
      "loss": 0.0791,
      "step": 10110
    },
    {
      "epoch": 1.2192771084337348,
      "grad_norm": 4.053879737854004,
      "learning_rate": 1.878072289156627e-05,
      "loss": 0.1134,
      "step": 10120
    },
    {
      "epoch": 1.2204819277108434,
      "grad_norm": 23.409339904785156,
      "learning_rate": 1.8779518072289157e-05,
      "loss": 0.0987,
      "step": 10130
    },
    {
      "epoch": 1.2216867469879518,
      "grad_norm": 0.9377682209014893,
      "learning_rate": 1.877831325301205e-05,
      "loss": 0.1302,
      "step": 10140
    },
    {
      "epoch": 1.2228915662650603,
      "grad_norm": 7.850785732269287,
      "learning_rate": 1.8777108433734942e-05,
      "loss": 0.0824,
      "step": 10150
    },
    {
      "epoch": 1.2240963855421687,
      "grad_norm": 3.4340977668762207,
      "learning_rate": 1.8775903614457835e-05,
      "loss": 0.1287,
      "step": 10160
    },
    {
      "epoch": 1.225301204819277,
      "grad_norm": 2.163721799850464,
      "learning_rate": 1.8774698795180724e-05,
      "loss": 0.1551,
      "step": 10170
    },
    {
      "epoch": 1.2265060240963854,
      "grad_norm": 21.39927864074707,
      "learning_rate": 1.8773493975903616e-05,
      "loss": 0.111,
      "step": 10180
    },
    {
      "epoch": 1.227710843373494,
      "grad_norm": 2.1662328243255615,
      "learning_rate": 1.877228915662651e-05,
      "loss": 0.1177,
      "step": 10190
    },
    {
      "epoch": 1.2289156626506024,
      "grad_norm": 3.741987705230713,
      "learning_rate": 1.8771084337349398e-05,
      "loss": 0.1127,
      "step": 10200
    },
    {
      "epoch": 1.230120481927711,
      "grad_norm": 8.530864715576172,
      "learning_rate": 1.876987951807229e-05,
      "loss": 0.23,
      "step": 10210
    },
    {
      "epoch": 1.2313253012048193,
      "grad_norm": 5.8447675704956055,
      "learning_rate": 1.8768674698795183e-05,
      "loss": 0.1643,
      "step": 10220
    },
    {
      "epoch": 1.2325301204819277,
      "grad_norm": 7.478916168212891,
      "learning_rate": 1.8767469879518075e-05,
      "loss": 0.1071,
      "step": 10230
    },
    {
      "epoch": 1.233734939759036,
      "grad_norm": 2.4081709384918213,
      "learning_rate": 1.8766265060240964e-05,
      "loss": 0.0734,
      "step": 10240
    },
    {
      "epoch": 1.2349397590361446,
      "grad_norm": 2.565232753753662,
      "learning_rate": 1.8765060240963856e-05,
      "loss": 0.0461,
      "step": 10250
    },
    {
      "epoch": 1.236144578313253,
      "grad_norm": 0.16017863154411316,
      "learning_rate": 1.876385542168675e-05,
      "loss": 0.1148,
      "step": 10260
    },
    {
      "epoch": 1.2373493975903616,
      "grad_norm": 3.663480043411255,
      "learning_rate": 1.876265060240964e-05,
      "loss": 0.1987,
      "step": 10270
    },
    {
      "epoch": 1.23855421686747,
      "grad_norm": 3.445136070251465,
      "learning_rate": 1.8761445783132534e-05,
      "loss": 0.0755,
      "step": 10280
    },
    {
      "epoch": 1.2397590361445783,
      "grad_norm": 3.105130672454834,
      "learning_rate": 1.8760240963855423e-05,
      "loss": 0.049,
      "step": 10290
    },
    {
      "epoch": 1.2409638554216866,
      "grad_norm": 19.22031021118164,
      "learning_rate": 1.8759036144578315e-05,
      "loss": 0.044,
      "step": 10300
    },
    {
      "epoch": 1.2421686746987952,
      "grad_norm": 3.777503252029419,
      "learning_rate": 1.8757831325301204e-05,
      "loss": 0.1572,
      "step": 10310
    },
    {
      "epoch": 1.2433734939759036,
      "grad_norm": 14.724203109741211,
      "learning_rate": 1.8756626506024097e-05,
      "loss": 0.1079,
      "step": 10320
    },
    {
      "epoch": 1.2445783132530122,
      "grad_norm": 0.20058293640613556,
      "learning_rate": 1.875542168674699e-05,
      "loss": 0.0859,
      "step": 10330
    },
    {
      "epoch": 1.2457831325301205,
      "grad_norm": 5.557095050811768,
      "learning_rate": 1.875421686746988e-05,
      "loss": 0.1089,
      "step": 10340
    },
    {
      "epoch": 1.2469879518072289,
      "grad_norm": 19.37464141845703,
      "learning_rate": 1.8753012048192774e-05,
      "loss": 0.1327,
      "step": 10350
    },
    {
      "epoch": 1.2481927710843372,
      "grad_norm": 1.1383455991744995,
      "learning_rate": 1.8751807228915663e-05,
      "loss": 0.185,
      "step": 10360
    },
    {
      "epoch": 1.2493975903614458,
      "grad_norm": 13.562819480895996,
      "learning_rate": 1.8750602409638556e-05,
      "loss": 0.1078,
      "step": 10370
    },
    {
      "epoch": 1.2506024096385542,
      "grad_norm": 1.4103052616119385,
      "learning_rate": 1.8749397590361448e-05,
      "loss": 0.0543,
      "step": 10380
    },
    {
      "epoch": 1.2518072289156628,
      "grad_norm": 2.728973627090454,
      "learning_rate": 1.874819277108434e-05,
      "loss": 0.108,
      "step": 10390
    },
    {
      "epoch": 1.2530120481927711,
      "grad_norm": 6.441890239715576,
      "learning_rate": 1.874698795180723e-05,
      "loss": 0.1166,
      "step": 10400
    },
    {
      "epoch": 1.2542168674698795,
      "grad_norm": 17.186580657958984,
      "learning_rate": 1.8745783132530122e-05,
      "loss": 0.0715,
      "step": 10410
    },
    {
      "epoch": 1.2554216867469878,
      "grad_norm": 10.501654624938965,
      "learning_rate": 1.8744578313253014e-05,
      "loss": 0.103,
      "step": 10420
    },
    {
      "epoch": 1.2566265060240964,
      "grad_norm": 6.218704700469971,
      "learning_rate": 1.8743373493975903e-05,
      "loss": 0.1528,
      "step": 10430
    },
    {
      "epoch": 1.2578313253012048,
      "grad_norm": 0.4921533763408661,
      "learning_rate": 1.8742168674698796e-05,
      "loss": 0.0738,
      "step": 10440
    },
    {
      "epoch": 1.2590361445783134,
      "grad_norm": 9.338797569274902,
      "learning_rate": 1.8740963855421688e-05,
      "loss": 0.1173,
      "step": 10450
    },
    {
      "epoch": 1.2602409638554217,
      "grad_norm": 0.6488804817199707,
      "learning_rate": 1.873975903614458e-05,
      "loss": 0.0719,
      "step": 10460
    },
    {
      "epoch": 1.26144578313253,
      "grad_norm": 3.289987802505493,
      "learning_rate": 1.873855421686747e-05,
      "loss": 0.111,
      "step": 10470
    },
    {
      "epoch": 1.2626506024096384,
      "grad_norm": 0.07542852312326431,
      "learning_rate": 1.8737349397590362e-05,
      "loss": 0.0828,
      "step": 10480
    },
    {
      "epoch": 1.263855421686747,
      "grad_norm": 0.9227683544158936,
      "learning_rate": 1.8736144578313255e-05,
      "loss": 0.0808,
      "step": 10490
    },
    {
      "epoch": 1.2650602409638554,
      "grad_norm": 4.922861576080322,
      "learning_rate": 1.8734939759036147e-05,
      "loss": 0.1067,
      "step": 10500
    },
    {
      "epoch": 1.266265060240964,
      "grad_norm": 12.230504989624023,
      "learning_rate": 1.873373493975904e-05,
      "loss": 0.0975,
      "step": 10510
    },
    {
      "epoch": 1.2674698795180723,
      "grad_norm": 20.910799026489258,
      "learning_rate": 1.873253012048193e-05,
      "loss": 0.0972,
      "step": 10520
    },
    {
      "epoch": 1.2686746987951807,
      "grad_norm": 2.90291690826416,
      "learning_rate": 1.873132530120482e-05,
      "loss": 0.1347,
      "step": 10530
    },
    {
      "epoch": 1.269879518072289,
      "grad_norm": 8.475592613220215,
      "learning_rate": 1.873012048192771e-05,
      "loss": 0.109,
      "step": 10540
    },
    {
      "epoch": 1.2710843373493976,
      "grad_norm": 0.313718318939209,
      "learning_rate": 1.8728915662650606e-05,
      "loss": 0.0858,
      "step": 10550
    },
    {
      "epoch": 1.272289156626506,
      "grad_norm": 10.990724563598633,
      "learning_rate": 1.8727710843373495e-05,
      "loss": 0.1263,
      "step": 10560
    },
    {
      "epoch": 1.2734939759036146,
      "grad_norm": 4.507179260253906,
      "learning_rate": 1.8726506024096387e-05,
      "loss": 0.1664,
      "step": 10570
    },
    {
      "epoch": 1.274698795180723,
      "grad_norm": 30.985454559326172,
      "learning_rate": 1.872530120481928e-05,
      "loss": 0.181,
      "step": 10580
    },
    {
      "epoch": 1.2759036144578313,
      "grad_norm": 5.214357852935791,
      "learning_rate": 1.872409638554217e-05,
      "loss": 0.076,
      "step": 10590
    },
    {
      "epoch": 1.2771084337349397,
      "grad_norm": 0.3050834536552429,
      "learning_rate": 1.872289156626506e-05,
      "loss": 0.0781,
      "step": 10600
    },
    {
      "epoch": 1.2783132530120482,
      "grad_norm": 5.2686662673950195,
      "learning_rate": 1.8721686746987954e-05,
      "loss": 0.0992,
      "step": 10610
    },
    {
      "epoch": 1.2795180722891566,
      "grad_norm": 0.30125024914741516,
      "learning_rate": 1.8720481927710846e-05,
      "loss": 0.1291,
      "step": 10620
    },
    {
      "epoch": 1.2807228915662652,
      "grad_norm": 6.350060939788818,
      "learning_rate": 1.8719277108433735e-05,
      "loss": 0.1168,
      "step": 10630
    },
    {
      "epoch": 1.2819277108433735,
      "grad_norm": 3.4925713539123535,
      "learning_rate": 1.8718072289156628e-05,
      "loss": 0.0838,
      "step": 10640
    },
    {
      "epoch": 1.283132530120482,
      "grad_norm": 2.2394778728485107,
      "learning_rate": 1.871686746987952e-05,
      "loss": 0.069,
      "step": 10650
    },
    {
      "epoch": 1.2843373493975903,
      "grad_norm": 18.827733993530273,
      "learning_rate": 1.8715662650602412e-05,
      "loss": 0.1417,
      "step": 10660
    },
    {
      "epoch": 1.2855421686746988,
      "grad_norm": 6.5082926750183105,
      "learning_rate": 1.8714457831325305e-05,
      "loss": 0.0957,
      "step": 10670
    },
    {
      "epoch": 1.2867469879518072,
      "grad_norm": 8.25619125366211,
      "learning_rate": 1.8713253012048194e-05,
      "loss": 0.1311,
      "step": 10680
    },
    {
      "epoch": 1.2879518072289158,
      "grad_norm": 5.838106155395508,
      "learning_rate": 1.8712048192771086e-05,
      "loss": 0.0798,
      "step": 10690
    },
    {
      "epoch": 1.2891566265060241,
      "grad_norm": 2.6921286582946777,
      "learning_rate": 1.8710843373493975e-05,
      "loss": 0.1994,
      "step": 10700
    },
    {
      "epoch": 1.2903614457831325,
      "grad_norm": 3.3343276977539062,
      "learning_rate": 1.8709638554216868e-05,
      "loss": 0.1593,
      "step": 10710
    },
    {
      "epoch": 1.2915662650602409,
      "grad_norm": 2.7217581272125244,
      "learning_rate": 1.870843373493976e-05,
      "loss": 0.0653,
      "step": 10720
    },
    {
      "epoch": 1.2927710843373494,
      "grad_norm": 0.750404953956604,
      "learning_rate": 1.8707228915662653e-05,
      "loss": 0.0973,
      "step": 10730
    },
    {
      "epoch": 1.2939759036144578,
      "grad_norm": 11.248058319091797,
      "learning_rate": 1.8706024096385545e-05,
      "loss": 0.1328,
      "step": 10740
    },
    {
      "epoch": 1.2951807228915664,
      "grad_norm": 3.9377706050872803,
      "learning_rate": 1.8704819277108434e-05,
      "loss": 0.0646,
      "step": 10750
    },
    {
      "epoch": 1.2963855421686747,
      "grad_norm": 0.12220386415719986,
      "learning_rate": 1.8703614457831327e-05,
      "loss": 0.1336,
      "step": 10760
    },
    {
      "epoch": 1.297590361445783,
      "grad_norm": 9.961372375488281,
      "learning_rate": 1.870240963855422e-05,
      "loss": 0.1203,
      "step": 10770
    },
    {
      "epoch": 1.2987951807228915,
      "grad_norm": 7.563751220703125,
      "learning_rate": 1.870120481927711e-05,
      "loss": 0.1537,
      "step": 10780
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.168248176574707,
      "learning_rate": 1.8700000000000004e-05,
      "loss": 0.1491,
      "step": 10790
    },
    {
      "epoch": 1.3012048192771084,
      "grad_norm": 1.3137781620025635,
      "learning_rate": 1.8698795180722893e-05,
      "loss": 0.0755,
      "step": 10800
    },
    {
      "epoch": 1.302409638554217,
      "grad_norm": 19.8043270111084,
      "learning_rate": 1.8697590361445785e-05,
      "loss": 0.0933,
      "step": 10810
    },
    {
      "epoch": 1.3036144578313253,
      "grad_norm": 3.2667267322540283,
      "learning_rate": 1.8696385542168674e-05,
      "loss": 0.1115,
      "step": 10820
    },
    {
      "epoch": 1.3048192771084337,
      "grad_norm": 3.0782759189605713,
      "learning_rate": 1.8695180722891567e-05,
      "loss": 0.1229,
      "step": 10830
    },
    {
      "epoch": 1.306024096385542,
      "grad_norm": 1.3513129949569702,
      "learning_rate": 1.869397590361446e-05,
      "loss": 0.145,
      "step": 10840
    },
    {
      "epoch": 1.3072289156626506,
      "grad_norm": 1.588748574256897,
      "learning_rate": 1.8692771084337352e-05,
      "loss": 0.0992,
      "step": 10850
    },
    {
      "epoch": 1.308433734939759,
      "grad_norm": 0.41853055357933044,
      "learning_rate": 1.869156626506024e-05,
      "loss": 0.0721,
      "step": 10860
    },
    {
      "epoch": 1.3096385542168676,
      "grad_norm": 2.4281158447265625,
      "learning_rate": 1.8690361445783133e-05,
      "loss": 0.0849,
      "step": 10870
    },
    {
      "epoch": 1.310843373493976,
      "grad_norm": 4.501922607421875,
      "learning_rate": 1.8689156626506026e-05,
      "loss": 0.0781,
      "step": 10880
    },
    {
      "epoch": 1.3120481927710843,
      "grad_norm": 10.327510833740234,
      "learning_rate": 1.8687951807228918e-05,
      "loss": 0.0997,
      "step": 10890
    },
    {
      "epoch": 1.3132530120481927,
      "grad_norm": 0.6866709589958191,
      "learning_rate": 1.868674698795181e-05,
      "loss": 0.1317,
      "step": 10900
    },
    {
      "epoch": 1.3144578313253013,
      "grad_norm": 10.090137481689453,
      "learning_rate": 1.86855421686747e-05,
      "loss": 0.0777,
      "step": 10910
    },
    {
      "epoch": 1.3156626506024096,
      "grad_norm": 0.1535213142633438,
      "learning_rate": 1.8684337349397592e-05,
      "loss": 0.0695,
      "step": 10920
    },
    {
      "epoch": 1.3168674698795182,
      "grad_norm": 27.60997772216797,
      "learning_rate": 1.868313253012048e-05,
      "loss": 0.1356,
      "step": 10930
    },
    {
      "epoch": 1.3180722891566266,
      "grad_norm": 7.886401176452637,
      "learning_rate": 1.8681927710843374e-05,
      "loss": 0.1388,
      "step": 10940
    },
    {
      "epoch": 1.319277108433735,
      "grad_norm": 2.8923938274383545,
      "learning_rate": 1.8680722891566266e-05,
      "loss": 0.0896,
      "step": 10950
    },
    {
      "epoch": 1.3204819277108433,
      "grad_norm": 1.4039037227630615,
      "learning_rate": 1.867951807228916e-05,
      "loss": 0.0632,
      "step": 10960
    },
    {
      "epoch": 1.3216867469879519,
      "grad_norm": 8.502936363220215,
      "learning_rate": 1.867831325301205e-05,
      "loss": 0.1356,
      "step": 10970
    },
    {
      "epoch": 1.3228915662650602,
      "grad_norm": 10.571165084838867,
      "learning_rate": 1.867710843373494e-05,
      "loss": 0.1431,
      "step": 10980
    },
    {
      "epoch": 1.3240963855421688,
      "grad_norm": 13.482316017150879,
      "learning_rate": 1.8675903614457832e-05,
      "loss": 0.0684,
      "step": 10990
    },
    {
      "epoch": 1.3253012048192772,
      "grad_norm": 12.732049942016602,
      "learning_rate": 1.8674698795180725e-05,
      "loss": 0.0612,
      "step": 11000
    },
    {
      "epoch": 1.3265060240963855,
      "grad_norm": 2.5548295974731445,
      "learning_rate": 1.8673493975903617e-05,
      "loss": 0.1086,
      "step": 11010
    },
    {
      "epoch": 1.3277108433734939,
      "grad_norm": 4.5102081298828125,
      "learning_rate": 1.867228915662651e-05,
      "loss": 0.126,
      "step": 11020
    },
    {
      "epoch": 1.3289156626506025,
      "grad_norm": 6.202391624450684,
      "learning_rate": 1.86710843373494e-05,
      "loss": 0.1599,
      "step": 11030
    },
    {
      "epoch": 1.3301204819277108,
      "grad_norm": 4.058419227600098,
      "learning_rate": 1.866987951807229e-05,
      "loss": 0.1478,
      "step": 11040
    },
    {
      "epoch": 1.3313253012048194,
      "grad_norm": 2.5185770988464355,
      "learning_rate": 1.866867469879518e-05,
      "loss": 0.1115,
      "step": 11050
    },
    {
      "epoch": 1.3325301204819278,
      "grad_norm": 3.823204755783081,
      "learning_rate": 1.8667469879518073e-05,
      "loss": 0.1398,
      "step": 11060
    },
    {
      "epoch": 1.3337349397590361,
      "grad_norm": 18.309234619140625,
      "learning_rate": 1.8666265060240965e-05,
      "loss": 0.1569,
      "step": 11070
    },
    {
      "epoch": 1.3349397590361445,
      "grad_norm": 3.964264392852783,
      "learning_rate": 1.8665060240963857e-05,
      "loss": 0.0953,
      "step": 11080
    },
    {
      "epoch": 1.336144578313253,
      "grad_norm": 7.655491828918457,
      "learning_rate": 1.866385542168675e-05,
      "loss": 0.1011,
      "step": 11090
    },
    {
      "epoch": 1.3373493975903614,
      "grad_norm": 1.4015231132507324,
      "learning_rate": 1.866265060240964e-05,
      "loss": 0.1039,
      "step": 11100
    },
    {
      "epoch": 1.33855421686747,
      "grad_norm": 0.25348493456840515,
      "learning_rate": 1.866144578313253e-05,
      "loss": 0.0757,
      "step": 11110
    },
    {
      "epoch": 1.3397590361445784,
      "grad_norm": 3.8335320949554443,
      "learning_rate": 1.8660240963855424e-05,
      "loss": 0.0559,
      "step": 11120
    },
    {
      "epoch": 1.3409638554216867,
      "grad_norm": 8.086492538452148,
      "learning_rate": 1.8659036144578316e-05,
      "loss": 0.2021,
      "step": 11130
    },
    {
      "epoch": 1.342168674698795,
      "grad_norm": 11.92487621307373,
      "learning_rate": 1.8657831325301205e-05,
      "loss": 0.1211,
      "step": 11140
    },
    {
      "epoch": 1.3433734939759037,
      "grad_norm": 11.432699203491211,
      "learning_rate": 1.8656626506024098e-05,
      "loss": 0.1165,
      "step": 11150
    },
    {
      "epoch": 1.344578313253012,
      "grad_norm": 0.8542118668556213,
      "learning_rate": 1.8655421686746987e-05,
      "loss": 0.1067,
      "step": 11160
    },
    {
      "epoch": 1.3457831325301206,
      "grad_norm": 0.39910149574279785,
      "learning_rate": 1.8654216867469883e-05,
      "loss": 0.0743,
      "step": 11170
    },
    {
      "epoch": 1.346987951807229,
      "grad_norm": 3.3494272232055664,
      "learning_rate": 1.8653012048192775e-05,
      "loss": 0.0693,
      "step": 11180
    },
    {
      "epoch": 1.3481927710843373,
      "grad_norm": 1.6785684823989868,
      "learning_rate": 1.8651807228915664e-05,
      "loss": 0.1301,
      "step": 11190
    },
    {
      "epoch": 1.3493975903614457,
      "grad_norm": 8.429951667785645,
      "learning_rate": 1.8650602409638556e-05,
      "loss": 0.0533,
      "step": 11200
    },
    {
      "epoch": 1.3506024096385543,
      "grad_norm": 10.819314956665039,
      "learning_rate": 1.8649397590361446e-05,
      "loss": 0.1306,
      "step": 11210
    },
    {
      "epoch": 1.3518072289156626,
      "grad_norm": 0.33969172835350037,
      "learning_rate": 1.8648192771084338e-05,
      "loss": 0.0936,
      "step": 11220
    },
    {
      "epoch": 1.3530120481927712,
      "grad_norm": 18.580280303955078,
      "learning_rate": 1.864698795180723e-05,
      "loss": 0.1689,
      "step": 11230
    },
    {
      "epoch": 1.3542168674698796,
      "grad_norm": 1.9381166696548462,
      "learning_rate": 1.8645783132530123e-05,
      "loss": 0.102,
      "step": 11240
    },
    {
      "epoch": 1.355421686746988,
      "grad_norm": 12.148603439331055,
      "learning_rate": 1.8644578313253015e-05,
      "loss": 0.1145,
      "step": 11250
    },
    {
      "epoch": 1.3566265060240963,
      "grad_norm": 6.636092185974121,
      "learning_rate": 1.8643373493975904e-05,
      "loss": 0.1525,
      "step": 11260
    },
    {
      "epoch": 1.3578313253012049,
      "grad_norm": 9.498241424560547,
      "learning_rate": 1.8642168674698797e-05,
      "loss": 0.1828,
      "step": 11270
    },
    {
      "epoch": 1.3590361445783132,
      "grad_norm": 2.2471108436584473,
      "learning_rate": 1.864096385542169e-05,
      "loss": 0.063,
      "step": 11280
    },
    {
      "epoch": 1.3602409638554218,
      "grad_norm": 0.38927972316741943,
      "learning_rate": 1.863975903614458e-05,
      "loss": 0.0462,
      "step": 11290
    },
    {
      "epoch": 1.3614457831325302,
      "grad_norm": 1.0286487340927124,
      "learning_rate": 1.863855421686747e-05,
      "loss": 0.0747,
      "step": 11300
    },
    {
      "epoch": 1.3626506024096385,
      "grad_norm": 0.2261742353439331,
      "learning_rate": 1.8637349397590363e-05,
      "loss": 0.0852,
      "step": 11310
    },
    {
      "epoch": 1.363855421686747,
      "grad_norm": 0.1696891486644745,
      "learning_rate": 1.8636144578313256e-05,
      "loss": 0.0867,
      "step": 11320
    },
    {
      "epoch": 1.3650602409638555,
      "grad_norm": 0.45884236693382263,
      "learning_rate": 1.8634939759036145e-05,
      "loss": 0.1044,
      "step": 11330
    },
    {
      "epoch": 1.3662650602409638,
      "grad_norm": 3.5284368991851807,
      "learning_rate": 1.8633734939759037e-05,
      "loss": 0.1649,
      "step": 11340
    },
    {
      "epoch": 1.3674698795180724,
      "grad_norm": 16.18229866027832,
      "learning_rate": 1.863253012048193e-05,
      "loss": 0.1102,
      "step": 11350
    },
    {
      "epoch": 1.3686746987951808,
      "grad_norm": 22.62792205810547,
      "learning_rate": 1.8631325301204822e-05,
      "loss": 0.1116,
      "step": 11360
    },
    {
      "epoch": 1.3698795180722891,
      "grad_norm": 7.391974925994873,
      "learning_rate": 1.863012048192771e-05,
      "loss": 0.1294,
      "step": 11370
    },
    {
      "epoch": 1.3710843373493975,
      "grad_norm": 7.394947052001953,
      "learning_rate": 1.8628915662650603e-05,
      "loss": 0.0816,
      "step": 11380
    },
    {
      "epoch": 1.372289156626506,
      "grad_norm": 10.523452758789062,
      "learning_rate": 1.8627710843373496e-05,
      "loss": 0.0303,
      "step": 11390
    },
    {
      "epoch": 1.3734939759036144,
      "grad_norm": 27.294530868530273,
      "learning_rate": 1.8626506024096388e-05,
      "loss": 0.1575,
      "step": 11400
    },
    {
      "epoch": 1.374698795180723,
      "grad_norm": 6.509481906890869,
      "learning_rate": 1.862530120481928e-05,
      "loss": 0.1801,
      "step": 11410
    },
    {
      "epoch": 1.3759036144578314,
      "grad_norm": 10.686749458312988,
      "learning_rate": 1.862409638554217e-05,
      "loss": 0.1206,
      "step": 11420
    },
    {
      "epoch": 1.3771084337349397,
      "grad_norm": 0.515468418598175,
      "learning_rate": 1.8622891566265062e-05,
      "loss": 0.1506,
      "step": 11430
    },
    {
      "epoch": 1.378313253012048,
      "grad_norm": 4.594615459442139,
      "learning_rate": 1.862168674698795e-05,
      "loss": 0.1223,
      "step": 11440
    },
    {
      "epoch": 1.3795180722891567,
      "grad_norm": 1.9212759733200073,
      "learning_rate": 1.8620481927710844e-05,
      "loss": 0.0986,
      "step": 11450
    },
    {
      "epoch": 1.380722891566265,
      "grad_norm": 1.6576331853866577,
      "learning_rate": 1.8619277108433736e-05,
      "loss": 0.0796,
      "step": 11460
    },
    {
      "epoch": 1.3819277108433736,
      "grad_norm": 2.809277057647705,
      "learning_rate": 1.861807228915663e-05,
      "loss": 0.1345,
      "step": 11470
    },
    {
      "epoch": 1.383132530120482,
      "grad_norm": 1.7273029088974,
      "learning_rate": 1.861686746987952e-05,
      "loss": 0.085,
      "step": 11480
    },
    {
      "epoch": 1.3843373493975903,
      "grad_norm": 0.9237968921661377,
      "learning_rate": 1.861566265060241e-05,
      "loss": 0.116,
      "step": 11490
    },
    {
      "epoch": 1.3855421686746987,
      "grad_norm": 4.586104393005371,
      "learning_rate": 1.8614457831325302e-05,
      "loss": 0.0905,
      "step": 11500
    },
    {
      "epoch": 1.3867469879518073,
      "grad_norm": 0.2115687131881714,
      "learning_rate": 1.8613253012048195e-05,
      "loss": 0.0954,
      "step": 11510
    },
    {
      "epoch": 1.3879518072289156,
      "grad_norm": 4.4910993576049805,
      "learning_rate": 1.8612048192771087e-05,
      "loss": 0.1104,
      "step": 11520
    },
    {
      "epoch": 1.3891566265060242,
      "grad_norm": 3.686138391494751,
      "learning_rate": 1.8610843373493976e-05,
      "loss": 0.1352,
      "step": 11530
    },
    {
      "epoch": 1.3903614457831326,
      "grad_norm": 5.8840179443359375,
      "learning_rate": 1.860963855421687e-05,
      "loss": 0.1549,
      "step": 11540
    },
    {
      "epoch": 1.391566265060241,
      "grad_norm": 2.400326728820801,
      "learning_rate": 1.860843373493976e-05,
      "loss": 0.0813,
      "step": 11550
    },
    {
      "epoch": 1.3927710843373493,
      "grad_norm": 0.5160061120986938,
      "learning_rate": 1.860722891566265e-05,
      "loss": 0.095,
      "step": 11560
    },
    {
      "epoch": 1.393975903614458,
      "grad_norm": 10.2254056930542,
      "learning_rate": 1.8606024096385543e-05,
      "loss": 0.084,
      "step": 11570
    },
    {
      "epoch": 1.3951807228915662,
      "grad_norm": 3.3491976261138916,
      "learning_rate": 1.8604819277108435e-05,
      "loss": 0.043,
      "step": 11580
    },
    {
      "epoch": 1.3963855421686748,
      "grad_norm": 0.8336037397384644,
      "learning_rate": 1.8603614457831328e-05,
      "loss": 0.1236,
      "step": 11590
    },
    {
      "epoch": 1.3975903614457832,
      "grad_norm": 0.7543354034423828,
      "learning_rate": 1.8602409638554217e-05,
      "loss": 0.1431,
      "step": 11600
    },
    {
      "epoch": 1.3987951807228916,
      "grad_norm": 2.9766101837158203,
      "learning_rate": 1.860120481927711e-05,
      "loss": 0.1077,
      "step": 11610
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.1328680515289307,
      "learning_rate": 1.86e-05,
      "loss": 0.0676,
      "step": 11620
    },
    {
      "epoch": 1.4012048192771085,
      "grad_norm": 19.94228744506836,
      "learning_rate": 1.8598795180722894e-05,
      "loss": 0.0823,
      "step": 11630
    },
    {
      "epoch": 1.4024096385542169,
      "grad_norm": 7.6899027824401855,
      "learning_rate": 1.8597590361445786e-05,
      "loss": 0.0907,
      "step": 11640
    },
    {
      "epoch": 1.4036144578313254,
      "grad_norm": 11.84903621673584,
      "learning_rate": 1.8596385542168675e-05,
      "loss": 0.1493,
      "step": 11650
    },
    {
      "epoch": 1.4048192771084338,
      "grad_norm": 5.541121006011963,
      "learning_rate": 1.8595180722891568e-05,
      "loss": 0.1052,
      "step": 11660
    },
    {
      "epoch": 1.4060240963855422,
      "grad_norm": 4.015266418457031,
      "learning_rate": 1.8593975903614457e-05,
      "loss": 0.0782,
      "step": 11670
    },
    {
      "epoch": 1.4072289156626505,
      "grad_norm": 0.9265027046203613,
      "learning_rate": 1.859277108433735e-05,
      "loss": 0.1272,
      "step": 11680
    },
    {
      "epoch": 1.408433734939759,
      "grad_norm": 4.471354007720947,
      "learning_rate": 1.8591566265060245e-05,
      "loss": 0.0783,
      "step": 11690
    },
    {
      "epoch": 1.4096385542168675,
      "grad_norm": 4.717647552490234,
      "learning_rate": 1.8590361445783134e-05,
      "loss": 0.1119,
      "step": 11700
    },
    {
      "epoch": 1.410843373493976,
      "grad_norm": 7.756652355194092,
      "learning_rate": 1.8589156626506027e-05,
      "loss": 0.1741,
      "step": 11710
    },
    {
      "epoch": 1.4120481927710844,
      "grad_norm": 0.14869675040245056,
      "learning_rate": 1.8587951807228916e-05,
      "loss": 0.1024,
      "step": 11720
    },
    {
      "epoch": 1.4132530120481928,
      "grad_norm": 2.796980142593384,
      "learning_rate": 1.8586746987951808e-05,
      "loss": 0.0334,
      "step": 11730
    },
    {
      "epoch": 1.4144578313253011,
      "grad_norm": 3.449538469314575,
      "learning_rate": 1.85855421686747e-05,
      "loss": 0.1056,
      "step": 11740
    },
    {
      "epoch": 1.4156626506024097,
      "grad_norm": 14.38769817352295,
      "learning_rate": 1.8584337349397593e-05,
      "loss": 0.156,
      "step": 11750
    },
    {
      "epoch": 1.416867469879518,
      "grad_norm": 27.57636070251465,
      "learning_rate": 1.8583132530120482e-05,
      "loss": 0.114,
      "step": 11760
    },
    {
      "epoch": 1.4180722891566266,
      "grad_norm": 18.994443893432617,
      "learning_rate": 1.8581927710843374e-05,
      "loss": 0.1646,
      "step": 11770
    },
    {
      "epoch": 1.419277108433735,
      "grad_norm": 0.3210538923740387,
      "learning_rate": 1.8580722891566267e-05,
      "loss": 0.1122,
      "step": 11780
    },
    {
      "epoch": 1.4204819277108434,
      "grad_norm": 27.49195098876953,
      "learning_rate": 1.857951807228916e-05,
      "loss": 0.1769,
      "step": 11790
    },
    {
      "epoch": 1.4216867469879517,
      "grad_norm": 3.4241721630096436,
      "learning_rate": 1.8578313253012052e-05,
      "loss": 0.0741,
      "step": 11800
    },
    {
      "epoch": 1.4228915662650603,
      "grad_norm": 43.344879150390625,
      "learning_rate": 1.857710843373494e-05,
      "loss": 0.1683,
      "step": 11810
    },
    {
      "epoch": 1.4240963855421687,
      "grad_norm": 1.588751196861267,
      "learning_rate": 1.8575903614457833e-05,
      "loss": 0.1598,
      "step": 11820
    },
    {
      "epoch": 1.4253012048192772,
      "grad_norm": 1.2370895147323608,
      "learning_rate": 1.8574698795180722e-05,
      "loss": 0.0609,
      "step": 11830
    },
    {
      "epoch": 1.4265060240963856,
      "grad_norm": 63.10447311401367,
      "learning_rate": 1.8573493975903615e-05,
      "loss": 0.189,
      "step": 11840
    },
    {
      "epoch": 1.427710843373494,
      "grad_norm": 0.43101024627685547,
      "learning_rate": 1.8572289156626507e-05,
      "loss": 0.0467,
      "step": 11850
    },
    {
      "epoch": 1.4289156626506023,
      "grad_norm": 7.000817775726318,
      "learning_rate": 1.85710843373494e-05,
      "loss": 0.1664,
      "step": 11860
    },
    {
      "epoch": 1.430120481927711,
      "grad_norm": 1.5593234300613403,
      "learning_rate": 1.8569879518072292e-05,
      "loss": 0.1653,
      "step": 11870
    },
    {
      "epoch": 1.4313253012048193,
      "grad_norm": 10.243531227111816,
      "learning_rate": 1.856867469879518e-05,
      "loss": 0.0952,
      "step": 11880
    },
    {
      "epoch": 1.4325301204819278,
      "grad_norm": 0.1046605110168457,
      "learning_rate": 1.8567469879518074e-05,
      "loss": 0.063,
      "step": 11890
    },
    {
      "epoch": 1.4337349397590362,
      "grad_norm": 1.271028757095337,
      "learning_rate": 1.8566265060240966e-05,
      "loss": 0.067,
      "step": 11900
    },
    {
      "epoch": 1.4349397590361446,
      "grad_norm": 11.183107376098633,
      "learning_rate": 1.856506024096386e-05,
      "loss": 0.0981,
      "step": 11910
    },
    {
      "epoch": 1.436144578313253,
      "grad_norm": 0.7259826064109802,
      "learning_rate": 1.856385542168675e-05,
      "loss": 0.0892,
      "step": 11920
    },
    {
      "epoch": 1.4373493975903615,
      "grad_norm": 10.292869567871094,
      "learning_rate": 1.856265060240964e-05,
      "loss": 0.0927,
      "step": 11930
    },
    {
      "epoch": 1.4385542168674699,
      "grad_norm": 5.624309062957764,
      "learning_rate": 1.8561445783132532e-05,
      "loss": 0.1368,
      "step": 11940
    },
    {
      "epoch": 1.4397590361445782,
      "grad_norm": 8.350696563720703,
      "learning_rate": 1.856024096385542e-05,
      "loss": 0.1092,
      "step": 11950
    },
    {
      "epoch": 1.4409638554216868,
      "grad_norm": 3.405082941055298,
      "learning_rate": 1.8559036144578314e-05,
      "loss": 0.1187,
      "step": 11960
    },
    {
      "epoch": 1.4421686746987952,
      "grad_norm": 7.5313920974731445,
      "learning_rate": 1.8557831325301206e-05,
      "loss": 0.0742,
      "step": 11970
    },
    {
      "epoch": 1.4433734939759035,
      "grad_norm": 22.913583755493164,
      "learning_rate": 1.85566265060241e-05,
      "loss": 0.1116,
      "step": 11980
    },
    {
      "epoch": 1.4445783132530121,
      "grad_norm": 0.6946887969970703,
      "learning_rate": 1.855542168674699e-05,
      "loss": 0.1287,
      "step": 11990
    },
    {
      "epoch": 1.4457831325301205,
      "grad_norm": 7.728485107421875,
      "learning_rate": 1.855421686746988e-05,
      "loss": 0.0733,
      "step": 12000
    },
    {
      "epoch": 1.4469879518072288,
      "grad_norm": 8.641180992126465,
      "learning_rate": 1.8553012048192773e-05,
      "loss": 0.08,
      "step": 12010
    },
    {
      "epoch": 1.4481927710843374,
      "grad_norm": 3.1651597023010254,
      "learning_rate": 1.8551807228915665e-05,
      "loss": 0.2587,
      "step": 12020
    },
    {
      "epoch": 1.4493975903614458,
      "grad_norm": 6.121955394744873,
      "learning_rate": 1.8550602409638557e-05,
      "loss": 0.1301,
      "step": 12030
    },
    {
      "epoch": 1.4506024096385541,
      "grad_norm": 8.553174018859863,
      "learning_rate": 1.8549397590361446e-05,
      "loss": 0.1447,
      "step": 12040
    },
    {
      "epoch": 1.4518072289156627,
      "grad_norm": 2.992356061935425,
      "learning_rate": 1.854819277108434e-05,
      "loss": 0.1262,
      "step": 12050
    },
    {
      "epoch": 1.453012048192771,
      "grad_norm": 2.5331571102142334,
      "learning_rate": 1.8546987951807228e-05,
      "loss": 0.1106,
      "step": 12060
    },
    {
      "epoch": 1.4542168674698794,
      "grad_norm": 0.8740794658660889,
      "learning_rate": 1.854578313253012e-05,
      "loss": 0.0975,
      "step": 12070
    },
    {
      "epoch": 1.455421686746988,
      "grad_norm": 40.60914611816406,
      "learning_rate": 1.8544578313253013e-05,
      "loss": 0.1388,
      "step": 12080
    },
    {
      "epoch": 1.4566265060240964,
      "grad_norm": 0.7338202595710754,
      "learning_rate": 1.8543373493975905e-05,
      "loss": 0.0627,
      "step": 12090
    },
    {
      "epoch": 1.4578313253012047,
      "grad_norm": 7.8305158615112305,
      "learning_rate": 1.8542168674698798e-05,
      "loss": 0.1203,
      "step": 12100
    },
    {
      "epoch": 1.4590361445783133,
      "grad_norm": 50.46051025390625,
      "learning_rate": 1.8540963855421687e-05,
      "loss": 0.0903,
      "step": 12110
    },
    {
      "epoch": 1.4602409638554217,
      "grad_norm": 4.184701442718506,
      "learning_rate": 1.853975903614458e-05,
      "loss": 0.0515,
      "step": 12120
    },
    {
      "epoch": 1.46144578313253,
      "grad_norm": 4.439119338989258,
      "learning_rate": 1.853855421686747e-05,
      "loss": 0.1038,
      "step": 12130
    },
    {
      "epoch": 1.4626506024096386,
      "grad_norm": 0.3747214078903198,
      "learning_rate": 1.8537349397590364e-05,
      "loss": 0.0744,
      "step": 12140
    },
    {
      "epoch": 1.463855421686747,
      "grad_norm": 9.038651466369629,
      "learning_rate": 1.8536144578313256e-05,
      "loss": 0.143,
      "step": 12150
    },
    {
      "epoch": 1.4650602409638553,
      "grad_norm": 2.813889503479004,
      "learning_rate": 1.8534939759036146e-05,
      "loss": 0.0892,
      "step": 12160
    },
    {
      "epoch": 1.466265060240964,
      "grad_norm": 7.092909812927246,
      "learning_rate": 1.8533734939759038e-05,
      "loss": 0.1501,
      "step": 12170
    },
    {
      "epoch": 1.4674698795180723,
      "grad_norm": 0.6992167830467224,
      "learning_rate": 1.8532530120481927e-05,
      "loss": 0.166,
      "step": 12180
    },
    {
      "epoch": 1.4686746987951806,
      "grad_norm": 15.132469177246094,
      "learning_rate": 1.853132530120482e-05,
      "loss": 0.1667,
      "step": 12190
    },
    {
      "epoch": 1.4698795180722892,
      "grad_norm": 5.124320983886719,
      "learning_rate": 1.8530120481927712e-05,
      "loss": 0.1775,
      "step": 12200
    },
    {
      "epoch": 1.4710843373493976,
      "grad_norm": 7.848906517028809,
      "learning_rate": 1.8528915662650604e-05,
      "loss": 0.144,
      "step": 12210
    },
    {
      "epoch": 1.472289156626506,
      "grad_norm": 10.446053504943848,
      "learning_rate": 1.8527710843373497e-05,
      "loss": 0.0681,
      "step": 12220
    },
    {
      "epoch": 1.4734939759036145,
      "grad_norm": 4.102422714233398,
      "learning_rate": 1.8526506024096386e-05,
      "loss": 0.1127,
      "step": 12230
    },
    {
      "epoch": 1.4746987951807229,
      "grad_norm": 2.475264549255371,
      "learning_rate": 1.8525301204819278e-05,
      "loss": 0.1144,
      "step": 12240
    },
    {
      "epoch": 1.4759036144578312,
      "grad_norm": 5.159016132354736,
      "learning_rate": 1.852409638554217e-05,
      "loss": 0.1273,
      "step": 12250
    },
    {
      "epoch": 1.4771084337349398,
      "grad_norm": 43.11123275756836,
      "learning_rate": 1.8522891566265063e-05,
      "loss": 0.0625,
      "step": 12260
    },
    {
      "epoch": 1.4783132530120482,
      "grad_norm": 1.4242033958435059,
      "learning_rate": 1.8521686746987952e-05,
      "loss": 0.1081,
      "step": 12270
    },
    {
      "epoch": 1.4795180722891565,
      "grad_norm": 6.730716705322266,
      "learning_rate": 1.8520481927710845e-05,
      "loss": 0.1669,
      "step": 12280
    },
    {
      "epoch": 1.4807228915662651,
      "grad_norm": 0.20080962777137756,
      "learning_rate": 1.8519277108433737e-05,
      "loss": 0.0356,
      "step": 12290
    },
    {
      "epoch": 1.4819277108433735,
      "grad_norm": 5.388803958892822,
      "learning_rate": 1.851807228915663e-05,
      "loss": 0.1571,
      "step": 12300
    },
    {
      "epoch": 1.4831325301204819,
      "grad_norm": 1.9685125350952148,
      "learning_rate": 1.8516867469879522e-05,
      "loss": 0.1182,
      "step": 12310
    },
    {
      "epoch": 1.4843373493975904,
      "grad_norm": 10.694392204284668,
      "learning_rate": 1.851566265060241e-05,
      "loss": 0.0721,
      "step": 12320
    },
    {
      "epoch": 1.4855421686746988,
      "grad_norm": 3.350593090057373,
      "learning_rate": 1.8514457831325303e-05,
      "loss": 0.147,
      "step": 12330
    },
    {
      "epoch": 1.4867469879518072,
      "grad_norm": 7.024587154388428,
      "learning_rate": 1.8513253012048192e-05,
      "loss": 0.0893,
      "step": 12340
    },
    {
      "epoch": 1.4879518072289157,
      "grad_norm": 7.32370662689209,
      "learning_rate": 1.8512048192771085e-05,
      "loss": 0.1342,
      "step": 12350
    },
    {
      "epoch": 1.489156626506024,
      "grad_norm": 6.13431978225708,
      "learning_rate": 1.8510843373493977e-05,
      "loss": 0.1525,
      "step": 12360
    },
    {
      "epoch": 1.4903614457831325,
      "grad_norm": 1.8160654306411743,
      "learning_rate": 1.850963855421687e-05,
      "loss": 0.1354,
      "step": 12370
    },
    {
      "epoch": 1.491566265060241,
      "grad_norm": 8.491083145141602,
      "learning_rate": 1.8508433734939762e-05,
      "loss": 0.1052,
      "step": 12380
    },
    {
      "epoch": 1.4927710843373494,
      "grad_norm": 3.3608970642089844,
      "learning_rate": 1.850722891566265e-05,
      "loss": 0.0968,
      "step": 12390
    },
    {
      "epoch": 1.4939759036144578,
      "grad_norm": 1.0016335248947144,
      "learning_rate": 1.8506024096385544e-05,
      "loss": 0.0847,
      "step": 12400
    },
    {
      "epoch": 1.4951807228915663,
      "grad_norm": 0.08715832233428955,
      "learning_rate": 1.8504819277108436e-05,
      "loss": 0.1134,
      "step": 12410
    },
    {
      "epoch": 1.4963855421686747,
      "grad_norm": 7.5116777420043945,
      "learning_rate": 1.850361445783133e-05,
      "loss": 0.1114,
      "step": 12420
    },
    {
      "epoch": 1.497590361445783,
      "grad_norm": 5.131557464599609,
      "learning_rate": 1.8502409638554218e-05,
      "loss": 0.121,
      "step": 12430
    },
    {
      "epoch": 1.4987951807228916,
      "grad_norm": 4.7439188957214355,
      "learning_rate": 1.850120481927711e-05,
      "loss": 0.1041,
      "step": 12440
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.334611177444458,
      "learning_rate": 1.8500000000000002e-05,
      "loss": 0.0905,
      "step": 12450
    },
    {
      "epoch": 1.5012048192771084,
      "grad_norm": 4.500097751617432,
      "learning_rate": 1.849879518072289e-05,
      "loss": 0.1143,
      "step": 12460
    },
    {
      "epoch": 1.5024096385542167,
      "grad_norm": 8.251758575439453,
      "learning_rate": 1.8497590361445784e-05,
      "loss": 0.128,
      "step": 12470
    },
    {
      "epoch": 1.5036144578313253,
      "grad_norm": 0.14593888819217682,
      "learning_rate": 1.8496385542168676e-05,
      "loss": 0.0516,
      "step": 12480
    },
    {
      "epoch": 1.5048192771084339,
      "grad_norm": 14.372760772705078,
      "learning_rate": 1.849518072289157e-05,
      "loss": 0.1522,
      "step": 12490
    },
    {
      "epoch": 1.5060240963855422,
      "grad_norm": 42.23238754272461,
      "learning_rate": 1.8493975903614458e-05,
      "loss": 0.1344,
      "step": 12500
    },
    {
      "epoch": 1.5072289156626506,
      "grad_norm": 0.44934898614883423,
      "learning_rate": 1.849277108433735e-05,
      "loss": 0.1736,
      "step": 12510
    },
    {
      "epoch": 1.508433734939759,
      "grad_norm": 22.32583236694336,
      "learning_rate": 1.8491566265060243e-05,
      "loss": 0.1249,
      "step": 12520
    },
    {
      "epoch": 1.5096385542168673,
      "grad_norm": 8.623826026916504,
      "learning_rate": 1.8490361445783135e-05,
      "loss": 0.0972,
      "step": 12530
    },
    {
      "epoch": 1.510843373493976,
      "grad_norm": 17.26752471923828,
      "learning_rate": 1.8489156626506028e-05,
      "loss": 0.1412,
      "step": 12540
    },
    {
      "epoch": 1.5120481927710845,
      "grad_norm": 10.105419158935547,
      "learning_rate": 1.8487951807228917e-05,
      "loss": 0.1011,
      "step": 12550
    },
    {
      "epoch": 1.5132530120481928,
      "grad_norm": 2.4103972911834717,
      "learning_rate": 1.848674698795181e-05,
      "loss": 0.1383,
      "step": 12560
    },
    {
      "epoch": 1.5144578313253012,
      "grad_norm": 2.1992127895355225,
      "learning_rate": 1.8485542168674698e-05,
      "loss": 0.0667,
      "step": 12570
    },
    {
      "epoch": 1.5156626506024096,
      "grad_norm": 4.608117580413818,
      "learning_rate": 1.848433734939759e-05,
      "loss": 0.0729,
      "step": 12580
    },
    {
      "epoch": 1.516867469879518,
      "grad_norm": 4.691622257232666,
      "learning_rate": 1.8483132530120483e-05,
      "loss": 0.203,
      "step": 12590
    },
    {
      "epoch": 1.5180722891566265,
      "grad_norm": 4.34376335144043,
      "learning_rate": 1.8481927710843375e-05,
      "loss": 0.064,
      "step": 12600
    },
    {
      "epoch": 1.519277108433735,
      "grad_norm": 49.65750503540039,
      "learning_rate": 1.8480722891566268e-05,
      "loss": 0.1333,
      "step": 12610
    },
    {
      "epoch": 1.5204819277108435,
      "grad_norm": 2.6832289695739746,
      "learning_rate": 1.8479518072289157e-05,
      "loss": 0.1176,
      "step": 12620
    },
    {
      "epoch": 1.5216867469879518,
      "grad_norm": 17.05937957763672,
      "learning_rate": 1.847831325301205e-05,
      "loss": 0.1114,
      "step": 12630
    },
    {
      "epoch": 1.5228915662650602,
      "grad_norm": 0.28482121229171753,
      "learning_rate": 1.8477108433734942e-05,
      "loss": 0.0676,
      "step": 12640
    },
    {
      "epoch": 1.5240963855421685,
      "grad_norm": 2.70428466796875,
      "learning_rate": 1.8475903614457834e-05,
      "loss": 0.1617,
      "step": 12650
    },
    {
      "epoch": 1.5253012048192771,
      "grad_norm": 0.21939724683761597,
      "learning_rate": 1.8474698795180727e-05,
      "loss": 0.1241,
      "step": 12660
    },
    {
      "epoch": 1.5265060240963857,
      "grad_norm": 0.10979592055082321,
      "learning_rate": 1.8473493975903616e-05,
      "loss": 0.0551,
      "step": 12670
    },
    {
      "epoch": 1.527710843373494,
      "grad_norm": 0.28058913350105286,
      "learning_rate": 1.8472289156626508e-05,
      "loss": 0.1205,
      "step": 12680
    },
    {
      "epoch": 1.5289156626506024,
      "grad_norm": 8.41987133026123,
      "learning_rate": 1.8471084337349397e-05,
      "loss": 0.0879,
      "step": 12690
    },
    {
      "epoch": 1.5301204819277108,
      "grad_norm": 0.12916548550128937,
      "learning_rate": 1.846987951807229e-05,
      "loss": 0.1518,
      "step": 12700
    },
    {
      "epoch": 1.5313253012048191,
      "grad_norm": 1.977874755859375,
      "learning_rate": 1.8468674698795182e-05,
      "loss": 0.0657,
      "step": 12710
    },
    {
      "epoch": 1.5325301204819277,
      "grad_norm": 1.6102243661880493,
      "learning_rate": 1.8467469879518074e-05,
      "loss": 0.0911,
      "step": 12720
    },
    {
      "epoch": 1.5337349397590363,
      "grad_norm": 9.802628517150879,
      "learning_rate": 1.8466265060240964e-05,
      "loss": 0.1057,
      "step": 12730
    },
    {
      "epoch": 1.5349397590361447,
      "grad_norm": 5.903270244598389,
      "learning_rate": 1.8465060240963856e-05,
      "loss": 0.0775,
      "step": 12740
    },
    {
      "epoch": 1.536144578313253,
      "grad_norm": 8.21106243133545,
      "learning_rate": 1.846385542168675e-05,
      "loss": 0.1358,
      "step": 12750
    },
    {
      "epoch": 1.5373493975903614,
      "grad_norm": 9.152726173400879,
      "learning_rate": 1.846265060240964e-05,
      "loss": 0.0915,
      "step": 12760
    },
    {
      "epoch": 1.5385542168674697,
      "grad_norm": 12.612475395202637,
      "learning_rate": 1.8461445783132533e-05,
      "loss": 0.1302,
      "step": 12770
    },
    {
      "epoch": 1.5397590361445783,
      "grad_norm": 4.424704551696777,
      "learning_rate": 1.8460240963855422e-05,
      "loss": 0.0896,
      "step": 12780
    },
    {
      "epoch": 1.540963855421687,
      "grad_norm": 8.704686164855957,
      "learning_rate": 1.8459036144578315e-05,
      "loss": 0.102,
      "step": 12790
    },
    {
      "epoch": 1.5421686746987953,
      "grad_norm": 8.549704551696777,
      "learning_rate": 1.8457831325301204e-05,
      "loss": 0.1417,
      "step": 12800
    },
    {
      "epoch": 1.5433734939759036,
      "grad_norm": 6.034101963043213,
      "learning_rate": 1.8456626506024096e-05,
      "loss": 0.124,
      "step": 12810
    },
    {
      "epoch": 1.544578313253012,
      "grad_norm": 5.733388900756836,
      "learning_rate": 1.8455421686746992e-05,
      "loss": 0.0957,
      "step": 12820
    },
    {
      "epoch": 1.5457831325301203,
      "grad_norm": 3.7968382835388184,
      "learning_rate": 1.845421686746988e-05,
      "loss": 0.1541,
      "step": 12830
    },
    {
      "epoch": 1.546987951807229,
      "grad_norm": 0.9658313989639282,
      "learning_rate": 1.8453012048192774e-05,
      "loss": 0.0957,
      "step": 12840
    },
    {
      "epoch": 1.5481927710843375,
      "grad_norm": 0.2989720404148102,
      "learning_rate": 1.8451807228915663e-05,
      "loss": 0.0931,
      "step": 12850
    },
    {
      "epoch": 1.5493975903614459,
      "grad_norm": 5.132467269897461,
      "learning_rate": 1.8450602409638555e-05,
      "loss": 0.1116,
      "step": 12860
    },
    {
      "epoch": 1.5506024096385542,
      "grad_norm": 6.231212615966797,
      "learning_rate": 1.8449397590361447e-05,
      "loss": 0.1097,
      "step": 12870
    },
    {
      "epoch": 1.5518072289156626,
      "grad_norm": 0.5050276517868042,
      "learning_rate": 1.844819277108434e-05,
      "loss": 0.1024,
      "step": 12880
    },
    {
      "epoch": 1.553012048192771,
      "grad_norm": 0.10467547178268433,
      "learning_rate": 1.8446987951807232e-05,
      "loss": 0.0956,
      "step": 12890
    },
    {
      "epoch": 1.5542168674698795,
      "grad_norm": 15.313050270080566,
      "learning_rate": 1.844578313253012e-05,
      "loss": 0.0816,
      "step": 12900
    },
    {
      "epoch": 1.555421686746988,
      "grad_norm": 47.48891830444336,
      "learning_rate": 1.8444578313253014e-05,
      "loss": 0.1106,
      "step": 12910
    },
    {
      "epoch": 1.5566265060240965,
      "grad_norm": 5.398524761199951,
      "learning_rate": 1.8443373493975906e-05,
      "loss": 0.1767,
      "step": 12920
    },
    {
      "epoch": 1.5578313253012048,
      "grad_norm": 33.66814041137695,
      "learning_rate": 1.84421686746988e-05,
      "loss": 0.0672,
      "step": 12930
    },
    {
      "epoch": 1.5590361445783132,
      "grad_norm": 12.6471529006958,
      "learning_rate": 1.8440963855421688e-05,
      "loss": 0.0438,
      "step": 12940
    },
    {
      "epoch": 1.5602409638554215,
      "grad_norm": 0.06754869967699051,
      "learning_rate": 1.843975903614458e-05,
      "loss": 0.0788,
      "step": 12950
    },
    {
      "epoch": 1.5614457831325301,
      "grad_norm": 7.122594833374023,
      "learning_rate": 1.8438554216867473e-05,
      "loss": 0.1481,
      "step": 12960
    },
    {
      "epoch": 1.5626506024096387,
      "grad_norm": 5.223371505737305,
      "learning_rate": 1.843734939759036e-05,
      "loss": 0.1472,
      "step": 12970
    },
    {
      "epoch": 1.563855421686747,
      "grad_norm": 2.5442774295806885,
      "learning_rate": 1.8436144578313254e-05,
      "loss": 0.0661,
      "step": 12980
    },
    {
      "epoch": 1.5650602409638554,
      "grad_norm": 2.8270998001098633,
      "learning_rate": 1.8434939759036147e-05,
      "loss": 0.05,
      "step": 12990
    },
    {
      "epoch": 1.5662650602409638,
      "grad_norm": 3.3992233276367188,
      "learning_rate": 1.843373493975904e-05,
      "loss": 0.1164,
      "step": 13000
    },
    {
      "epoch": 1.5674698795180722,
      "grad_norm": 4.87639856338501,
      "learning_rate": 1.8432530120481928e-05,
      "loss": 0.1376,
      "step": 13010
    },
    {
      "epoch": 1.5686746987951807,
      "grad_norm": 1.1747311353683472,
      "learning_rate": 1.843132530120482e-05,
      "loss": 0.0846,
      "step": 13020
    },
    {
      "epoch": 1.5698795180722893,
      "grad_norm": 5.49565315246582,
      "learning_rate": 1.8430120481927713e-05,
      "loss": 0.1212,
      "step": 13030
    },
    {
      "epoch": 1.5710843373493977,
      "grad_norm": 11.999444961547852,
      "learning_rate": 1.8428915662650605e-05,
      "loss": 0.1705,
      "step": 13040
    },
    {
      "epoch": 1.572289156626506,
      "grad_norm": 4.074263572692871,
      "learning_rate": 1.8427710843373498e-05,
      "loss": 0.0714,
      "step": 13050
    },
    {
      "epoch": 1.5734939759036144,
      "grad_norm": 14.79017162322998,
      "learning_rate": 1.8426506024096387e-05,
      "loss": 0.0961,
      "step": 13060
    },
    {
      "epoch": 1.5746987951807228,
      "grad_norm": 7.011730194091797,
      "learning_rate": 1.842530120481928e-05,
      "loss": 0.1182,
      "step": 13070
    },
    {
      "epoch": 1.5759036144578313,
      "grad_norm": 1.069608449935913,
      "learning_rate": 1.8424096385542168e-05,
      "loss": 0.0976,
      "step": 13080
    },
    {
      "epoch": 1.57710843373494,
      "grad_norm": 1.8703107833862305,
      "learning_rate": 1.842289156626506e-05,
      "loss": 0.0783,
      "step": 13090
    },
    {
      "epoch": 1.5783132530120483,
      "grad_norm": 75.56066131591797,
      "learning_rate": 1.8421686746987953e-05,
      "loss": 0.0867,
      "step": 13100
    },
    {
      "epoch": 1.5795180722891566,
      "grad_norm": 2.7320477962493896,
      "learning_rate": 1.8420481927710846e-05,
      "loss": 0.0942,
      "step": 13110
    },
    {
      "epoch": 1.580722891566265,
      "grad_norm": 7.049693584442139,
      "learning_rate": 1.8419277108433738e-05,
      "loss": 0.0954,
      "step": 13120
    },
    {
      "epoch": 1.5819277108433734,
      "grad_norm": 157.75262451171875,
      "learning_rate": 1.8418072289156627e-05,
      "loss": 0.1081,
      "step": 13130
    },
    {
      "epoch": 1.583132530120482,
      "grad_norm": 0.8358228802680969,
      "learning_rate": 1.841686746987952e-05,
      "loss": 0.0873,
      "step": 13140
    },
    {
      "epoch": 1.5843373493975905,
      "grad_norm": 0.6035904884338379,
      "learning_rate": 1.8415662650602412e-05,
      "loss": 0.0853,
      "step": 13150
    },
    {
      "epoch": 1.5855421686746989,
      "grad_norm": 0.19514216482639313,
      "learning_rate": 1.8414457831325304e-05,
      "loss": 0.0942,
      "step": 13160
    },
    {
      "epoch": 1.5867469879518072,
      "grad_norm": 1.5992881059646606,
      "learning_rate": 1.8413253012048193e-05,
      "loss": 0.0878,
      "step": 13170
    },
    {
      "epoch": 1.5879518072289156,
      "grad_norm": 10.505162239074707,
      "learning_rate": 1.8412048192771086e-05,
      "loss": 0.0865,
      "step": 13180
    },
    {
      "epoch": 1.589156626506024,
      "grad_norm": 6.832979202270508,
      "learning_rate": 1.8410843373493978e-05,
      "loss": 0.156,
      "step": 13190
    },
    {
      "epoch": 1.5903614457831325,
      "grad_norm": 26.140426635742188,
      "learning_rate": 1.8409638554216867e-05,
      "loss": 0.0668,
      "step": 13200
    },
    {
      "epoch": 1.5915662650602411,
      "grad_norm": 62.30703353881836,
      "learning_rate": 1.840843373493976e-05,
      "loss": 0.0765,
      "step": 13210
    },
    {
      "epoch": 1.5927710843373495,
      "grad_norm": 0.22639942169189453,
      "learning_rate": 1.8407228915662652e-05,
      "loss": 0.105,
      "step": 13220
    },
    {
      "epoch": 1.5939759036144578,
      "grad_norm": 0.8862190246582031,
      "learning_rate": 1.8406024096385545e-05,
      "loss": 0.0767,
      "step": 13230
    },
    {
      "epoch": 1.5951807228915662,
      "grad_norm": 2.6412606239318848,
      "learning_rate": 1.8404819277108434e-05,
      "loss": 0.1174,
      "step": 13240
    },
    {
      "epoch": 1.5963855421686746,
      "grad_norm": 0.1843220740556717,
      "learning_rate": 1.8403614457831326e-05,
      "loss": 0.1542,
      "step": 13250
    },
    {
      "epoch": 1.5975903614457831,
      "grad_norm": 2.3874576091766357,
      "learning_rate": 1.840240963855422e-05,
      "loss": 0.1293,
      "step": 13260
    },
    {
      "epoch": 1.5987951807228917,
      "grad_norm": 1.5097558498382568,
      "learning_rate": 1.840120481927711e-05,
      "loss": 0.1022,
      "step": 13270
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6844509840011597,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.0953,
      "step": 13280
    },
    {
      "epoch": 1.6012048192771084,
      "grad_norm": 8.207077026367188,
      "learning_rate": 1.8398795180722892e-05,
      "loss": 0.0962,
      "step": 13290
    },
    {
      "epoch": 1.6024096385542168,
      "grad_norm": 2.8477702140808105,
      "learning_rate": 1.8397590361445785e-05,
      "loss": 0.1021,
      "step": 13300
    },
    {
      "epoch": 1.6036144578313252,
      "grad_norm": 13.742477416992188,
      "learning_rate": 1.8396385542168674e-05,
      "loss": 0.1163,
      "step": 13310
    },
    {
      "epoch": 1.6048192771084338,
      "grad_norm": 9.66370677947998,
      "learning_rate": 1.8395180722891566e-05,
      "loss": 0.1344,
      "step": 13320
    },
    {
      "epoch": 1.6060240963855423,
      "grad_norm": 3.382143497467041,
      "learning_rate": 1.839397590361446e-05,
      "loss": 0.0742,
      "step": 13330
    },
    {
      "epoch": 1.6072289156626507,
      "grad_norm": 2.608771800994873,
      "learning_rate": 1.839277108433735e-05,
      "loss": 0.0931,
      "step": 13340
    },
    {
      "epoch": 1.608433734939759,
      "grad_norm": 4.806471347808838,
      "learning_rate": 1.8391566265060244e-05,
      "loss": 0.079,
      "step": 13350
    },
    {
      "epoch": 1.6096385542168674,
      "grad_norm": 6.581852912902832,
      "learning_rate": 1.8390361445783133e-05,
      "loss": 0.0738,
      "step": 13360
    },
    {
      "epoch": 1.6108433734939758,
      "grad_norm": 2.3161070346832275,
      "learning_rate": 1.8389156626506025e-05,
      "loss": 0.1083,
      "step": 13370
    },
    {
      "epoch": 1.6120481927710844,
      "grad_norm": 0.6818710565567017,
      "learning_rate": 1.8387951807228918e-05,
      "loss": 0.0902,
      "step": 13380
    },
    {
      "epoch": 1.613253012048193,
      "grad_norm": 8.268086433410645,
      "learning_rate": 1.838674698795181e-05,
      "loss": 0.1534,
      "step": 13390
    },
    {
      "epoch": 1.6144578313253013,
      "grad_norm": 0.26724785566329956,
      "learning_rate": 1.83855421686747e-05,
      "loss": 0.0793,
      "step": 13400
    },
    {
      "epoch": 1.6156626506024097,
      "grad_norm": 4.100496292114258,
      "learning_rate": 1.838433734939759e-05,
      "loss": 0.1317,
      "step": 13410
    },
    {
      "epoch": 1.616867469879518,
      "grad_norm": 0.6568769812583923,
      "learning_rate": 1.8383132530120484e-05,
      "loss": 0.1513,
      "step": 13420
    },
    {
      "epoch": 1.6180722891566264,
      "grad_norm": 0.24391743540763855,
      "learning_rate": 1.8381927710843376e-05,
      "loss": 0.1062,
      "step": 13430
    },
    {
      "epoch": 1.619277108433735,
      "grad_norm": 6.968954563140869,
      "learning_rate": 1.838072289156627e-05,
      "loss": 0.1501,
      "step": 13440
    },
    {
      "epoch": 1.6204819277108435,
      "grad_norm": 0.5855382680892944,
      "learning_rate": 1.8379518072289158e-05,
      "loss": 0.0658,
      "step": 13450
    },
    {
      "epoch": 1.621686746987952,
      "grad_norm": 0.41795220971107483,
      "learning_rate": 1.837831325301205e-05,
      "loss": 0.0599,
      "step": 13460
    },
    {
      "epoch": 1.6228915662650603,
      "grad_norm": 0.08546386659145355,
      "learning_rate": 1.837710843373494e-05,
      "loss": 0.1004,
      "step": 13470
    },
    {
      "epoch": 1.6240963855421686,
      "grad_norm": 0.5721861720085144,
      "learning_rate": 1.8375903614457832e-05,
      "loss": 0.1204,
      "step": 13480
    },
    {
      "epoch": 1.625301204819277,
      "grad_norm": 0.15441866219043732,
      "learning_rate": 1.8374698795180724e-05,
      "loss": 0.0833,
      "step": 13490
    },
    {
      "epoch": 1.6265060240963856,
      "grad_norm": 8.106261253356934,
      "learning_rate": 1.8373493975903617e-05,
      "loss": 0.0746,
      "step": 13500
    },
    {
      "epoch": 1.627710843373494,
      "grad_norm": 0.13069558143615723,
      "learning_rate": 1.837228915662651e-05,
      "loss": 0.0532,
      "step": 13510
    },
    {
      "epoch": 1.6289156626506025,
      "grad_norm": 1.0280095338821411,
      "learning_rate": 1.8371084337349398e-05,
      "loss": 0.0453,
      "step": 13520
    },
    {
      "epoch": 1.6301204819277109,
      "grad_norm": 3.841073989868164,
      "learning_rate": 1.836987951807229e-05,
      "loss": 0.1212,
      "step": 13530
    },
    {
      "epoch": 1.6313253012048192,
      "grad_norm": 16.489315032958984,
      "learning_rate": 1.8368674698795183e-05,
      "loss": 0.1028,
      "step": 13540
    },
    {
      "epoch": 1.6325301204819276,
      "grad_norm": 39.68014907836914,
      "learning_rate": 1.8367469879518075e-05,
      "loss": 0.1189,
      "step": 13550
    },
    {
      "epoch": 1.6337349397590362,
      "grad_norm": 0.3820432424545288,
      "learning_rate": 1.8366265060240968e-05,
      "loss": 0.1442,
      "step": 13560
    },
    {
      "epoch": 1.6349397590361445,
      "grad_norm": 7.455450534820557,
      "learning_rate": 1.8365060240963857e-05,
      "loss": 0.0667,
      "step": 13570
    },
    {
      "epoch": 1.636144578313253,
      "grad_norm": 13.651468276977539,
      "learning_rate": 1.836385542168675e-05,
      "loss": 0.0971,
      "step": 13580
    },
    {
      "epoch": 1.6373493975903615,
      "grad_norm": 4.854175090789795,
      "learning_rate": 1.836265060240964e-05,
      "loss": 0.118,
      "step": 13590
    },
    {
      "epoch": 1.6385542168674698,
      "grad_norm": 13.36584186553955,
      "learning_rate": 1.836144578313253e-05,
      "loss": 0.1168,
      "step": 13600
    },
    {
      "epoch": 1.6397590361445782,
      "grad_norm": 1.0834776163101196,
      "learning_rate": 1.8360240963855423e-05,
      "loss": 0.1099,
      "step": 13610
    },
    {
      "epoch": 1.6409638554216868,
      "grad_norm": 0.7895107865333557,
      "learning_rate": 1.8359036144578316e-05,
      "loss": 0.174,
      "step": 13620
    },
    {
      "epoch": 1.6421686746987951,
      "grad_norm": 2.124189853668213,
      "learning_rate": 1.8357831325301205e-05,
      "loss": 0.1333,
      "step": 13630
    },
    {
      "epoch": 1.6433734939759037,
      "grad_norm": 32.688480377197266,
      "learning_rate": 1.8356626506024097e-05,
      "loss": 0.1006,
      "step": 13640
    },
    {
      "epoch": 1.644578313253012,
      "grad_norm": 2.0116543769836426,
      "learning_rate": 1.835542168674699e-05,
      "loss": 0.1038,
      "step": 13650
    },
    {
      "epoch": 1.6457831325301204,
      "grad_norm": 29.521198272705078,
      "learning_rate": 1.8354216867469882e-05,
      "loss": 0.2056,
      "step": 13660
    },
    {
      "epoch": 1.6469879518072288,
      "grad_norm": 44.97339630126953,
      "learning_rate": 1.8353012048192774e-05,
      "loss": 0.0801,
      "step": 13670
    },
    {
      "epoch": 1.6481927710843374,
      "grad_norm": 1.7603532075881958,
      "learning_rate": 1.8351807228915664e-05,
      "loss": 0.1108,
      "step": 13680
    },
    {
      "epoch": 1.6493975903614457,
      "grad_norm": 0.42621931433677673,
      "learning_rate": 1.8350602409638556e-05,
      "loss": 0.1254,
      "step": 13690
    },
    {
      "epoch": 1.6506024096385543,
      "grad_norm": 1.843024730682373,
      "learning_rate": 1.8349397590361445e-05,
      "loss": 0.0656,
      "step": 13700
    },
    {
      "epoch": 1.6518072289156627,
      "grad_norm": 0.1792176216840744,
      "learning_rate": 1.8348192771084337e-05,
      "loss": 0.0898,
      "step": 13710
    },
    {
      "epoch": 1.653012048192771,
      "grad_norm": 0.10204015672206879,
      "learning_rate": 1.834698795180723e-05,
      "loss": 0.1109,
      "step": 13720
    },
    {
      "epoch": 1.6542168674698794,
      "grad_norm": 0.7661343812942505,
      "learning_rate": 1.8345783132530122e-05,
      "loss": 0.1735,
      "step": 13730
    },
    {
      "epoch": 1.655421686746988,
      "grad_norm": 5.427826881408691,
      "learning_rate": 1.8344578313253015e-05,
      "loss": 0.1452,
      "step": 13740
    },
    {
      "epoch": 1.6566265060240963,
      "grad_norm": 3.033498525619507,
      "learning_rate": 1.8343373493975904e-05,
      "loss": 0.1118,
      "step": 13750
    },
    {
      "epoch": 1.657831325301205,
      "grad_norm": 2.5758163928985596,
      "learning_rate": 1.8342168674698796e-05,
      "loss": 0.0726,
      "step": 13760
    },
    {
      "epoch": 1.6590361445783133,
      "grad_norm": 5.276985168457031,
      "learning_rate": 1.834096385542169e-05,
      "loss": 0.1658,
      "step": 13770
    },
    {
      "epoch": 1.6602409638554216,
      "grad_norm": 0.269992470741272,
      "learning_rate": 1.833975903614458e-05,
      "loss": 0.0896,
      "step": 13780
    },
    {
      "epoch": 1.66144578313253,
      "grad_norm": 5.088990211486816,
      "learning_rate": 1.8338554216867474e-05,
      "loss": 0.067,
      "step": 13790
    },
    {
      "epoch": 1.6626506024096386,
      "grad_norm": 0.2558915913105011,
      "learning_rate": 1.8337349397590363e-05,
      "loss": 0.0587,
      "step": 13800
    },
    {
      "epoch": 1.663855421686747,
      "grad_norm": 28.698829650878906,
      "learning_rate": 1.8336144578313255e-05,
      "loss": 0.188,
      "step": 13810
    },
    {
      "epoch": 1.6650602409638555,
      "grad_norm": 0.7209569215774536,
      "learning_rate": 1.8334939759036144e-05,
      "loss": 0.0626,
      "step": 13820
    },
    {
      "epoch": 1.6662650602409639,
      "grad_norm": 12.30109691619873,
      "learning_rate": 1.8333734939759037e-05,
      "loss": 0.097,
      "step": 13830
    },
    {
      "epoch": 1.6674698795180722,
      "grad_norm": 2.3109521865844727,
      "learning_rate": 1.833253012048193e-05,
      "loss": 0.1049,
      "step": 13840
    },
    {
      "epoch": 1.6686746987951806,
      "grad_norm": 3.7536284923553467,
      "learning_rate": 1.833132530120482e-05,
      "loss": 0.0692,
      "step": 13850
    },
    {
      "epoch": 1.6698795180722892,
      "grad_norm": 1.759569525718689,
      "learning_rate": 1.8330120481927714e-05,
      "loss": 0.1141,
      "step": 13860
    },
    {
      "epoch": 1.6710843373493975,
      "grad_norm": 5.698672771453857,
      "learning_rate": 1.8328915662650603e-05,
      "loss": 0.0986,
      "step": 13870
    },
    {
      "epoch": 1.6722891566265061,
      "grad_norm": 3.666829824447632,
      "learning_rate": 1.8327710843373495e-05,
      "loss": 0.0704,
      "step": 13880
    },
    {
      "epoch": 1.6734939759036145,
      "grad_norm": 6.358283042907715,
      "learning_rate": 1.8326506024096388e-05,
      "loss": 0.1647,
      "step": 13890
    },
    {
      "epoch": 1.6746987951807228,
      "grad_norm": 7.308747291564941,
      "learning_rate": 1.832530120481928e-05,
      "loss": 0.0243,
      "step": 13900
    },
    {
      "epoch": 1.6759036144578312,
      "grad_norm": 0.14157161116600037,
      "learning_rate": 1.832409638554217e-05,
      "loss": 0.0815,
      "step": 13910
    },
    {
      "epoch": 1.6771084337349398,
      "grad_norm": 0.4340560734272003,
      "learning_rate": 1.832289156626506e-05,
      "loss": 0.0843,
      "step": 13920
    },
    {
      "epoch": 1.6783132530120481,
      "grad_norm": 3.4368886947631836,
      "learning_rate": 1.832168674698795e-05,
      "loss": 0.0702,
      "step": 13930
    },
    {
      "epoch": 1.6795180722891567,
      "grad_norm": 0.6828294992446899,
      "learning_rate": 1.8320481927710843e-05,
      "loss": 0.1018,
      "step": 13940
    },
    {
      "epoch": 1.680722891566265,
      "grad_norm": 10.278426170349121,
      "learning_rate": 1.831927710843374e-05,
      "loss": 0.0839,
      "step": 13950
    },
    {
      "epoch": 1.6819277108433734,
      "grad_norm": 10.253213882446289,
      "learning_rate": 1.8318072289156628e-05,
      "loss": 0.133,
      "step": 13960
    },
    {
      "epoch": 1.6831325301204818,
      "grad_norm": 8.548567771911621,
      "learning_rate": 1.831686746987952e-05,
      "loss": 0.0799,
      "step": 13970
    },
    {
      "epoch": 1.6843373493975904,
      "grad_norm": 0.16070936620235443,
      "learning_rate": 1.831566265060241e-05,
      "loss": 0.0847,
      "step": 13980
    },
    {
      "epoch": 1.6855421686746987,
      "grad_norm": 7.912570476531982,
      "learning_rate": 1.8314457831325302e-05,
      "loss": 0.0779,
      "step": 13990
    },
    {
      "epoch": 1.6867469879518073,
      "grad_norm": 66.63256072998047,
      "learning_rate": 1.8313253012048194e-05,
      "loss": 0.0787,
      "step": 14000
    },
    {
      "epoch": 1.6879518072289157,
      "grad_norm": 6.16985559463501,
      "learning_rate": 1.8312048192771087e-05,
      "loss": 0.1508,
      "step": 14010
    },
    {
      "epoch": 1.689156626506024,
      "grad_norm": 0.16822920739650726,
      "learning_rate": 1.831084337349398e-05,
      "loss": 0.0546,
      "step": 14020
    },
    {
      "epoch": 1.6903614457831324,
      "grad_norm": 4.869410514831543,
      "learning_rate": 1.8309638554216868e-05,
      "loss": 0.1637,
      "step": 14030
    },
    {
      "epoch": 1.691566265060241,
      "grad_norm": 13.022712707519531,
      "learning_rate": 1.830843373493976e-05,
      "loss": 0.1047,
      "step": 14040
    },
    {
      "epoch": 1.6927710843373494,
      "grad_norm": 3.305509090423584,
      "learning_rate": 1.8307228915662653e-05,
      "loss": 0.1279,
      "step": 14050
    },
    {
      "epoch": 1.693975903614458,
      "grad_norm": 16.814546585083008,
      "learning_rate": 1.8306024096385546e-05,
      "loss": 0.0488,
      "step": 14060
    },
    {
      "epoch": 1.6951807228915663,
      "grad_norm": 0.6153489351272583,
      "learning_rate": 1.8304819277108435e-05,
      "loss": 0.0891,
      "step": 14070
    },
    {
      "epoch": 1.6963855421686747,
      "grad_norm": 19.480236053466797,
      "learning_rate": 1.8303614457831327e-05,
      "loss": 0.1135,
      "step": 14080
    },
    {
      "epoch": 1.697590361445783,
      "grad_norm": 2.735395669937134,
      "learning_rate": 1.830240963855422e-05,
      "loss": 0.1202,
      "step": 14090
    },
    {
      "epoch": 1.6987951807228916,
      "grad_norm": 7.214197635650635,
      "learning_rate": 1.830120481927711e-05,
      "loss": 0.1331,
      "step": 14100
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.741790771484375,
      "learning_rate": 1.83e-05,
      "loss": 0.0336,
      "step": 14110
    },
    {
      "epoch": 1.7012048192771085,
      "grad_norm": 0.49967488646507263,
      "learning_rate": 1.8298795180722893e-05,
      "loss": 0.0507,
      "step": 14120
    },
    {
      "epoch": 1.702409638554217,
      "grad_norm": 3.7885847091674805,
      "learning_rate": 1.8297590361445786e-05,
      "loss": 0.1296,
      "step": 14130
    },
    {
      "epoch": 1.7036144578313253,
      "grad_norm": 2.3964924812316895,
      "learning_rate": 1.8296385542168675e-05,
      "loss": 0.109,
      "step": 14140
    },
    {
      "epoch": 1.7048192771084336,
      "grad_norm": 5.386559009552002,
      "learning_rate": 1.8295180722891567e-05,
      "loss": 0.1233,
      "step": 14150
    },
    {
      "epoch": 1.7060240963855422,
      "grad_norm": 17.79326057434082,
      "learning_rate": 1.829397590361446e-05,
      "loss": 0.1088,
      "step": 14160
    },
    {
      "epoch": 1.7072289156626506,
      "grad_norm": 6.973828315734863,
      "learning_rate": 1.8292771084337352e-05,
      "loss": 0.1205,
      "step": 14170
    },
    {
      "epoch": 1.7084337349397591,
      "grad_norm": 0.46381598711013794,
      "learning_rate": 1.8291566265060245e-05,
      "loss": 0.0298,
      "step": 14180
    },
    {
      "epoch": 1.7096385542168675,
      "grad_norm": 4.140013217926025,
      "learning_rate": 1.8290361445783134e-05,
      "loss": 0.1408,
      "step": 14190
    },
    {
      "epoch": 1.7108433734939759,
      "grad_norm": 5.349621772766113,
      "learning_rate": 1.8289156626506026e-05,
      "loss": 0.0972,
      "step": 14200
    },
    {
      "epoch": 1.7120481927710842,
      "grad_norm": 4.945189476013184,
      "learning_rate": 1.8287951807228915e-05,
      "loss": 0.1847,
      "step": 14210
    },
    {
      "epoch": 1.7132530120481928,
      "grad_norm": 0.3837958872318268,
      "learning_rate": 1.8286746987951808e-05,
      "loss": 0.0766,
      "step": 14220
    },
    {
      "epoch": 1.7144578313253012,
      "grad_norm": 2.7070345878601074,
      "learning_rate": 1.82855421686747e-05,
      "loss": 0.119,
      "step": 14230
    },
    {
      "epoch": 1.7156626506024097,
      "grad_norm": 4.141637325286865,
      "learning_rate": 1.8284337349397592e-05,
      "loss": 0.1252,
      "step": 14240
    },
    {
      "epoch": 1.716867469879518,
      "grad_norm": 0.8135336637496948,
      "learning_rate": 1.8283132530120485e-05,
      "loss": 0.032,
      "step": 14250
    },
    {
      "epoch": 1.7180722891566265,
      "grad_norm": 0.8446136713027954,
      "learning_rate": 1.8281927710843374e-05,
      "loss": 0.0647,
      "step": 14260
    },
    {
      "epoch": 1.7192771084337348,
      "grad_norm": 4.460457801818848,
      "learning_rate": 1.8280722891566266e-05,
      "loss": 0.1639,
      "step": 14270
    },
    {
      "epoch": 1.7204819277108434,
      "grad_norm": 1.9921218156814575,
      "learning_rate": 1.827951807228916e-05,
      "loss": 0.0774,
      "step": 14280
    },
    {
      "epoch": 1.7216867469879518,
      "grad_norm": 4.845345973968506,
      "learning_rate": 1.827831325301205e-05,
      "loss": 0.1342,
      "step": 14290
    },
    {
      "epoch": 1.7228915662650603,
      "grad_norm": 5.662594318389893,
      "learning_rate": 1.827710843373494e-05,
      "loss": 0.1357,
      "step": 14300
    },
    {
      "epoch": 1.7240963855421687,
      "grad_norm": 0.6833056211471558,
      "learning_rate": 1.8275903614457833e-05,
      "loss": 0.0938,
      "step": 14310
    },
    {
      "epoch": 1.725301204819277,
      "grad_norm": 38.33092498779297,
      "learning_rate": 1.8274698795180725e-05,
      "loss": 0.0671,
      "step": 14320
    },
    {
      "epoch": 1.7265060240963854,
      "grad_norm": 1.0470294952392578,
      "learning_rate": 1.8273493975903614e-05,
      "loss": 0.1426,
      "step": 14330
    },
    {
      "epoch": 1.727710843373494,
      "grad_norm": 0.1609915792942047,
      "learning_rate": 1.8272289156626507e-05,
      "loss": 0.0591,
      "step": 14340
    },
    {
      "epoch": 1.7289156626506024,
      "grad_norm": 0.6641528010368347,
      "learning_rate": 1.82710843373494e-05,
      "loss": 0.0984,
      "step": 14350
    },
    {
      "epoch": 1.730120481927711,
      "grad_norm": 1.5424435138702393,
      "learning_rate": 1.826987951807229e-05,
      "loss": 0.0924,
      "step": 14360
    },
    {
      "epoch": 1.7313253012048193,
      "grad_norm": 9.173260688781738,
      "learning_rate": 1.826867469879518e-05,
      "loss": 0.0754,
      "step": 14370
    },
    {
      "epoch": 1.7325301204819277,
      "grad_norm": 0.23407526314258575,
      "learning_rate": 1.8267469879518073e-05,
      "loss": 0.1293,
      "step": 14380
    },
    {
      "epoch": 1.733734939759036,
      "grad_norm": 4.770268440246582,
      "learning_rate": 1.8266265060240965e-05,
      "loss": 0.1017,
      "step": 14390
    },
    {
      "epoch": 1.7349397590361446,
      "grad_norm": 0.2142411172389984,
      "learning_rate": 1.8265060240963858e-05,
      "loss": 0.0744,
      "step": 14400
    },
    {
      "epoch": 1.736144578313253,
      "grad_norm": 1.3422163724899292,
      "learning_rate": 1.826385542168675e-05,
      "loss": 0.1212,
      "step": 14410
    },
    {
      "epoch": 1.7373493975903616,
      "grad_norm": 3.3556711673736572,
      "learning_rate": 1.826265060240964e-05,
      "loss": 0.1313,
      "step": 14420
    },
    {
      "epoch": 1.73855421686747,
      "grad_norm": 1.2290035486221313,
      "learning_rate": 1.8261445783132532e-05,
      "loss": 0.1434,
      "step": 14430
    },
    {
      "epoch": 1.7397590361445783,
      "grad_norm": 13.122435569763184,
      "learning_rate": 1.826024096385542e-05,
      "loss": 0.1031,
      "step": 14440
    },
    {
      "epoch": 1.7409638554216866,
      "grad_norm": 0.6244156360626221,
      "learning_rate": 1.8259036144578313e-05,
      "loss": 0.0942,
      "step": 14450
    },
    {
      "epoch": 1.7421686746987952,
      "grad_norm": 7.924389839172363,
      "learning_rate": 1.8257831325301206e-05,
      "loss": 0.1461,
      "step": 14460
    },
    {
      "epoch": 1.7433734939759036,
      "grad_norm": 2.232593297958374,
      "learning_rate": 1.8256626506024098e-05,
      "loss": 0.1014,
      "step": 14470
    },
    {
      "epoch": 1.7445783132530122,
      "grad_norm": 5.787333965301514,
      "learning_rate": 1.825542168674699e-05,
      "loss": 0.0744,
      "step": 14480
    },
    {
      "epoch": 1.7457831325301205,
      "grad_norm": 7.18071985244751,
      "learning_rate": 1.825421686746988e-05,
      "loss": 0.1511,
      "step": 14490
    },
    {
      "epoch": 1.7469879518072289,
      "grad_norm": 3.6903765201568604,
      "learning_rate": 1.8253012048192772e-05,
      "loss": 0.1764,
      "step": 14500
    },
    {
      "epoch": 1.7481927710843372,
      "grad_norm": 4.482128620147705,
      "learning_rate": 1.8251807228915664e-05,
      "loss": 0.1007,
      "step": 14510
    },
    {
      "epoch": 1.7493975903614458,
      "grad_norm": 0.6797564625740051,
      "learning_rate": 1.8250602409638557e-05,
      "loss": 0.0384,
      "step": 14520
    },
    {
      "epoch": 1.7506024096385542,
      "grad_norm": 19.938947677612305,
      "learning_rate": 1.8249397590361446e-05,
      "loss": 0.1202,
      "step": 14530
    },
    {
      "epoch": 1.7518072289156628,
      "grad_norm": 11.696186065673828,
      "learning_rate": 1.824819277108434e-05,
      "loss": 0.1321,
      "step": 14540
    },
    {
      "epoch": 1.7530120481927711,
      "grad_norm": 6.862154960632324,
      "learning_rate": 1.824698795180723e-05,
      "loss": 0.0924,
      "step": 14550
    },
    {
      "epoch": 1.7542168674698795,
      "grad_norm": 4.4916205406188965,
      "learning_rate": 1.824578313253012e-05,
      "loss": 0.0938,
      "step": 14560
    },
    {
      "epoch": 1.7554216867469878,
      "grad_norm": 4.453547477722168,
      "learning_rate": 1.8244578313253016e-05,
      "loss": 0.0374,
      "step": 14570
    },
    {
      "epoch": 1.7566265060240964,
      "grad_norm": 7.242303848266602,
      "learning_rate": 1.8243373493975905e-05,
      "loss": 0.1197,
      "step": 14580
    },
    {
      "epoch": 1.7578313253012048,
      "grad_norm": 0.26593950390815735,
      "learning_rate": 1.8242168674698797e-05,
      "loss": 0.0657,
      "step": 14590
    },
    {
      "epoch": 1.7590361445783134,
      "grad_norm": 18.589969635009766,
      "learning_rate": 1.8240963855421686e-05,
      "loss": 0.2467,
      "step": 14600
    },
    {
      "epoch": 1.7602409638554217,
      "grad_norm": 3.7247164249420166,
      "learning_rate": 1.823975903614458e-05,
      "loss": 0.1002,
      "step": 14610
    },
    {
      "epoch": 1.76144578313253,
      "grad_norm": 2.599534511566162,
      "learning_rate": 1.823855421686747e-05,
      "loss": 0.0416,
      "step": 14620
    },
    {
      "epoch": 1.7626506024096384,
      "grad_norm": 2.786595582962036,
      "learning_rate": 1.8237349397590364e-05,
      "loss": 0.0722,
      "step": 14630
    },
    {
      "epoch": 1.763855421686747,
      "grad_norm": 1.6685842275619507,
      "learning_rate": 1.8236144578313256e-05,
      "loss": 0.117,
      "step": 14640
    },
    {
      "epoch": 1.7650602409638554,
      "grad_norm": 3.857354164123535,
      "learning_rate": 1.8234939759036145e-05,
      "loss": 0.1183,
      "step": 14650
    },
    {
      "epoch": 1.766265060240964,
      "grad_norm": 2.209989309310913,
      "learning_rate": 1.8233734939759037e-05,
      "loss": 0.19,
      "step": 14660
    },
    {
      "epoch": 1.7674698795180723,
      "grad_norm": 15.15729808807373,
      "learning_rate": 1.823253012048193e-05,
      "loss": 0.0913,
      "step": 14670
    },
    {
      "epoch": 1.7686746987951807,
      "grad_norm": 8.906991004943848,
      "learning_rate": 1.8231325301204822e-05,
      "loss": 0.1074,
      "step": 14680
    },
    {
      "epoch": 1.769879518072289,
      "grad_norm": 10.831257820129395,
      "learning_rate": 1.8230120481927715e-05,
      "loss": 0.0647,
      "step": 14690
    },
    {
      "epoch": 1.7710843373493976,
      "grad_norm": 0.43172067403793335,
      "learning_rate": 1.8228915662650604e-05,
      "loss": 0.0742,
      "step": 14700
    },
    {
      "epoch": 1.772289156626506,
      "grad_norm": 4.1055216789245605,
      "learning_rate": 1.8227710843373496e-05,
      "loss": 0.1455,
      "step": 14710
    },
    {
      "epoch": 1.7734939759036146,
      "grad_norm": 0.8846912980079651,
      "learning_rate": 1.8226506024096385e-05,
      "loss": 0.0955,
      "step": 14720
    },
    {
      "epoch": 1.774698795180723,
      "grad_norm": 5.625892162322998,
      "learning_rate": 1.8225301204819278e-05,
      "loss": 0.0902,
      "step": 14730
    },
    {
      "epoch": 1.7759036144578313,
      "grad_norm": 49.94709014892578,
      "learning_rate": 1.822409638554217e-05,
      "loss": 0.0533,
      "step": 14740
    },
    {
      "epoch": 1.7771084337349397,
      "grad_norm": 2.756977081298828,
      "learning_rate": 1.8222891566265063e-05,
      "loss": 0.0843,
      "step": 14750
    },
    {
      "epoch": 1.7783132530120482,
      "grad_norm": 2.557426929473877,
      "learning_rate": 1.8221686746987955e-05,
      "loss": 0.0871,
      "step": 14760
    },
    {
      "epoch": 1.7795180722891566,
      "grad_norm": 0.2571449875831604,
      "learning_rate": 1.8220481927710844e-05,
      "loss": 0.1027,
      "step": 14770
    },
    {
      "epoch": 1.7807228915662652,
      "grad_norm": 0.36434462666511536,
      "learning_rate": 1.8219277108433737e-05,
      "loss": 0.1135,
      "step": 14780
    },
    {
      "epoch": 1.7819277108433735,
      "grad_norm": 13.467941284179688,
      "learning_rate": 1.821807228915663e-05,
      "loss": 0.1333,
      "step": 14790
    },
    {
      "epoch": 1.783132530120482,
      "grad_norm": 0.24593180418014526,
      "learning_rate": 1.821686746987952e-05,
      "loss": 0.0459,
      "step": 14800
    },
    {
      "epoch": 1.7843373493975903,
      "grad_norm": 11.74129581451416,
      "learning_rate": 1.821566265060241e-05,
      "loss": 0.1262,
      "step": 14810
    },
    {
      "epoch": 1.7855421686746988,
      "grad_norm": 25.325090408325195,
      "learning_rate": 1.8214457831325303e-05,
      "loss": 0.1222,
      "step": 14820
    },
    {
      "epoch": 1.7867469879518072,
      "grad_norm": 0.19818885624408722,
      "learning_rate": 1.8213253012048192e-05,
      "loss": 0.1636,
      "step": 14830
    },
    {
      "epoch": 1.7879518072289158,
      "grad_norm": 7.710348606109619,
      "learning_rate": 1.8212048192771084e-05,
      "loss": 0.08,
      "step": 14840
    },
    {
      "epoch": 1.7891566265060241,
      "grad_norm": 13.55329704284668,
      "learning_rate": 1.8210843373493977e-05,
      "loss": 0.1909,
      "step": 14850
    },
    {
      "epoch": 1.7903614457831325,
      "grad_norm": 5.2108378410339355,
      "learning_rate": 1.820963855421687e-05,
      "loss": 0.1433,
      "step": 14860
    },
    {
      "epoch": 1.7915662650602409,
      "grad_norm": 1.1090179681777954,
      "learning_rate": 1.820843373493976e-05,
      "loss": 0.0714,
      "step": 14870
    },
    {
      "epoch": 1.7927710843373494,
      "grad_norm": 4.6673712730407715,
      "learning_rate": 1.820722891566265e-05,
      "loss": 0.0664,
      "step": 14880
    },
    {
      "epoch": 1.7939759036144578,
      "grad_norm": 12.464719772338867,
      "learning_rate": 1.8206024096385543e-05,
      "loss": 0.1295,
      "step": 14890
    },
    {
      "epoch": 1.7951807228915664,
      "grad_norm": 0.27996379137039185,
      "learning_rate": 1.8204819277108436e-05,
      "loss": 0.1606,
      "step": 14900
    },
    {
      "epoch": 1.7963855421686747,
      "grad_norm": 1.444027304649353,
      "learning_rate": 1.8203614457831328e-05,
      "loss": 0.0415,
      "step": 14910
    },
    {
      "epoch": 1.797590361445783,
      "grad_norm": 5.152594089508057,
      "learning_rate": 1.820240963855422e-05,
      "loss": 0.1642,
      "step": 14920
    },
    {
      "epoch": 1.7987951807228915,
      "grad_norm": 4.508677005767822,
      "learning_rate": 1.820120481927711e-05,
      "loss": 0.0755,
      "step": 14930
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.680659770965576,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0994,
      "step": 14940
    },
    {
      "epoch": 1.8012048192771084,
      "grad_norm": 63.71782302856445,
      "learning_rate": 1.819879518072289e-05,
      "loss": 0.0704,
      "step": 14950
    },
    {
      "epoch": 1.802409638554217,
      "grad_norm": 122.36249542236328,
      "learning_rate": 1.8197590361445783e-05,
      "loss": 0.0979,
      "step": 14960
    },
    {
      "epoch": 1.8036144578313253,
      "grad_norm": 150.28382873535156,
      "learning_rate": 1.8196385542168676e-05,
      "loss": 0.1318,
      "step": 14970
    },
    {
      "epoch": 1.8048192771084337,
      "grad_norm": 2.5611414909362793,
      "learning_rate": 1.8195180722891568e-05,
      "loss": 0.1146,
      "step": 14980
    },
    {
      "epoch": 1.806024096385542,
      "grad_norm": 12.039679527282715,
      "learning_rate": 1.819397590361446e-05,
      "loss": 0.1417,
      "step": 14990
    },
    {
      "epoch": 1.8072289156626506,
      "grad_norm": 8.637462615966797,
      "learning_rate": 1.819277108433735e-05,
      "loss": 0.0854,
      "step": 15000
    },
    {
      "epoch": 1.808433734939759,
      "grad_norm": 2.0224053859710693,
      "learning_rate": 1.8191566265060242e-05,
      "loss": 0.0921,
      "step": 15010
    },
    {
      "epoch": 1.8096385542168676,
      "grad_norm": 0.1399410218000412,
      "learning_rate": 1.8190361445783135e-05,
      "loss": 0.0648,
      "step": 15020
    },
    {
      "epoch": 1.810843373493976,
      "grad_norm": 0.8113179802894592,
      "learning_rate": 1.8189156626506027e-05,
      "loss": 0.0963,
      "step": 15030
    },
    {
      "epoch": 1.8120481927710843,
      "grad_norm": 4.150089740753174,
      "learning_rate": 1.8187951807228916e-05,
      "loss": 0.088,
      "step": 15040
    },
    {
      "epoch": 1.8132530120481927,
      "grad_norm": 0.5949491262435913,
      "learning_rate": 1.818674698795181e-05,
      "loss": 0.0401,
      "step": 15050
    },
    {
      "epoch": 1.8144578313253013,
      "grad_norm": 5.111311435699463,
      "learning_rate": 1.81855421686747e-05,
      "loss": 0.1751,
      "step": 15060
    },
    {
      "epoch": 1.8156626506024096,
      "grad_norm": 0.18812786042690277,
      "learning_rate": 1.818433734939759e-05,
      "loss": 0.1026,
      "step": 15070
    },
    {
      "epoch": 1.8168674698795182,
      "grad_norm": 0.22619658708572388,
      "learning_rate": 1.8183132530120486e-05,
      "loss": 0.0627,
      "step": 15080
    },
    {
      "epoch": 1.8180722891566266,
      "grad_norm": 4.500542640686035,
      "learning_rate": 1.8181927710843375e-05,
      "loss": 0.1118,
      "step": 15090
    },
    {
      "epoch": 1.819277108433735,
      "grad_norm": 0.2115405797958374,
      "learning_rate": 1.8180722891566267e-05,
      "loss": 0.077,
      "step": 15100
    },
    {
      "epoch": 1.8204819277108433,
      "grad_norm": 3.2468552589416504,
      "learning_rate": 1.8179518072289156e-05,
      "loss": 0.0945,
      "step": 15110
    },
    {
      "epoch": 1.8216867469879519,
      "grad_norm": 1.0640063285827637,
      "learning_rate": 1.817831325301205e-05,
      "loss": 0.06,
      "step": 15120
    },
    {
      "epoch": 1.8228915662650602,
      "grad_norm": 4.532142162322998,
      "learning_rate": 1.817710843373494e-05,
      "loss": 0.0656,
      "step": 15130
    },
    {
      "epoch": 1.8240963855421688,
      "grad_norm": 2.991832971572876,
      "learning_rate": 1.8175903614457834e-05,
      "loss": 0.1261,
      "step": 15140
    },
    {
      "epoch": 1.8253012048192772,
      "grad_norm": 1.8037596940994263,
      "learning_rate": 1.8174698795180726e-05,
      "loss": 0.1453,
      "step": 15150
    },
    {
      "epoch": 1.8265060240963855,
      "grad_norm": 12.55574893951416,
      "learning_rate": 1.8173493975903615e-05,
      "loss": 0.1044,
      "step": 15160
    },
    {
      "epoch": 1.8277108433734939,
      "grad_norm": 15.378332138061523,
      "learning_rate": 1.8172289156626508e-05,
      "loss": 0.1071,
      "step": 15170
    },
    {
      "epoch": 1.8289156626506025,
      "grad_norm": 2.1248273849487305,
      "learning_rate": 1.81710843373494e-05,
      "loss": 0.1428,
      "step": 15180
    },
    {
      "epoch": 1.8301204819277108,
      "grad_norm": 7.975318431854248,
      "learning_rate": 1.8169879518072292e-05,
      "loss": 0.0854,
      "step": 15190
    },
    {
      "epoch": 1.8313253012048194,
      "grad_norm": 2.041807174682617,
      "learning_rate": 1.816867469879518e-05,
      "loss": 0.117,
      "step": 15200
    },
    {
      "epoch": 1.8325301204819278,
      "grad_norm": 0.6598010063171387,
      "learning_rate": 1.8167469879518074e-05,
      "loss": 0.1215,
      "step": 15210
    },
    {
      "epoch": 1.8337349397590361,
      "grad_norm": 25.899051666259766,
      "learning_rate": 1.8166265060240966e-05,
      "loss": 0.1316,
      "step": 15220
    },
    {
      "epoch": 1.8349397590361445,
      "grad_norm": 0.15492397546768188,
      "learning_rate": 1.8165060240963855e-05,
      "loss": 0.104,
      "step": 15230
    },
    {
      "epoch": 1.836144578313253,
      "grad_norm": 2.539318323135376,
      "learning_rate": 1.8163855421686748e-05,
      "loss": 0.0949,
      "step": 15240
    },
    {
      "epoch": 1.8373493975903614,
      "grad_norm": 0.7433066368103027,
      "learning_rate": 1.816265060240964e-05,
      "loss": 0.1057,
      "step": 15250
    },
    {
      "epoch": 1.83855421686747,
      "grad_norm": 0.6246018409729004,
      "learning_rate": 1.8161445783132533e-05,
      "loss": 0.1013,
      "step": 15260
    },
    {
      "epoch": 1.8397590361445784,
      "grad_norm": 0.39167335629463196,
      "learning_rate": 1.8160240963855422e-05,
      "loss": 0.0648,
      "step": 15270
    },
    {
      "epoch": 1.8409638554216867,
      "grad_norm": 56.08433532714844,
      "learning_rate": 1.8159036144578314e-05,
      "loss": 0.1052,
      "step": 15280
    },
    {
      "epoch": 1.842168674698795,
      "grad_norm": 11.99886417388916,
      "learning_rate": 1.8157831325301207e-05,
      "loss": 0.1198,
      "step": 15290
    },
    {
      "epoch": 1.8433734939759037,
      "grad_norm": 6.1131768226623535,
      "learning_rate": 1.81566265060241e-05,
      "loss": 0.0873,
      "step": 15300
    },
    {
      "epoch": 1.844578313253012,
      "grad_norm": 0.097945936024189,
      "learning_rate": 1.815542168674699e-05,
      "loss": 0.0826,
      "step": 15310
    },
    {
      "epoch": 1.8457831325301206,
      "grad_norm": 36.5197639465332,
      "learning_rate": 1.815421686746988e-05,
      "loss": 0.1025,
      "step": 15320
    },
    {
      "epoch": 1.846987951807229,
      "grad_norm": 1.037522315979004,
      "learning_rate": 1.8153012048192773e-05,
      "loss": 0.0739,
      "step": 15330
    },
    {
      "epoch": 1.8481927710843373,
      "grad_norm": 9.896994590759277,
      "learning_rate": 1.8151807228915662e-05,
      "loss": 0.113,
      "step": 15340
    },
    {
      "epoch": 1.8493975903614457,
      "grad_norm": 7.222940444946289,
      "learning_rate": 1.8150602409638554e-05,
      "loss": 0.114,
      "step": 15350
    },
    {
      "epoch": 1.8506024096385543,
      "grad_norm": 0.2478155791759491,
      "learning_rate": 1.8149397590361447e-05,
      "loss": 0.0932,
      "step": 15360
    },
    {
      "epoch": 1.8518072289156626,
      "grad_norm": 3.6453118324279785,
      "learning_rate": 1.814819277108434e-05,
      "loss": 0.0924,
      "step": 15370
    },
    {
      "epoch": 1.8530120481927712,
      "grad_norm": 1.6398100852966309,
      "learning_rate": 1.8146987951807232e-05,
      "loss": 0.1003,
      "step": 15380
    },
    {
      "epoch": 1.8542168674698796,
      "grad_norm": 6.779353618621826,
      "learning_rate": 1.814578313253012e-05,
      "loss": 0.0617,
      "step": 15390
    },
    {
      "epoch": 1.855421686746988,
      "grad_norm": 7.083611488342285,
      "learning_rate": 1.8144578313253013e-05,
      "loss": 0.103,
      "step": 15400
    },
    {
      "epoch": 1.8566265060240963,
      "grad_norm": 24.007843017578125,
      "learning_rate": 1.8143373493975906e-05,
      "loss": 0.1907,
      "step": 15410
    },
    {
      "epoch": 1.8578313253012049,
      "grad_norm": 0.5936844348907471,
      "learning_rate": 1.8142168674698798e-05,
      "loss": 0.1297,
      "step": 15420
    },
    {
      "epoch": 1.8590361445783132,
      "grad_norm": 10.660004615783691,
      "learning_rate": 1.8140963855421687e-05,
      "loss": 0.1055,
      "step": 15430
    },
    {
      "epoch": 1.8602409638554218,
      "grad_norm": 3.104832649230957,
      "learning_rate": 1.813975903614458e-05,
      "loss": 0.049,
      "step": 15440
    },
    {
      "epoch": 1.8614457831325302,
      "grad_norm": 4.212258338928223,
      "learning_rate": 1.8138554216867472e-05,
      "loss": 0.0941,
      "step": 15450
    },
    {
      "epoch": 1.8626506024096385,
      "grad_norm": 2.5431509017944336,
      "learning_rate": 1.813734939759036e-05,
      "loss": 0.0776,
      "step": 15460
    },
    {
      "epoch": 1.863855421686747,
      "grad_norm": 5.590658664703369,
      "learning_rate": 1.8136144578313254e-05,
      "loss": 0.1136,
      "step": 15470
    },
    {
      "epoch": 1.8650602409638555,
      "grad_norm": 4.926867485046387,
      "learning_rate": 1.8134939759036146e-05,
      "loss": 0.0903,
      "step": 15480
    },
    {
      "epoch": 1.8662650602409638,
      "grad_norm": 6.230039119720459,
      "learning_rate": 1.813373493975904e-05,
      "loss": 0.0905,
      "step": 15490
    },
    {
      "epoch": 1.8674698795180724,
      "grad_norm": 0.9186131954193115,
      "learning_rate": 1.8132530120481927e-05,
      "loss": 0.0856,
      "step": 15500
    },
    {
      "epoch": 1.8686746987951808,
      "grad_norm": 24.684173583984375,
      "learning_rate": 1.813132530120482e-05,
      "loss": 0.1189,
      "step": 15510
    },
    {
      "epoch": 1.8698795180722891,
      "grad_norm": 0.6998231410980225,
      "learning_rate": 1.8130120481927712e-05,
      "loss": 0.0844,
      "step": 15520
    },
    {
      "epoch": 1.8710843373493975,
      "grad_norm": 0.8026202917098999,
      "learning_rate": 1.8128915662650605e-05,
      "loss": 0.1479,
      "step": 15530
    },
    {
      "epoch": 1.872289156626506,
      "grad_norm": 12.967580795288086,
      "learning_rate": 1.8127710843373497e-05,
      "loss": 0.1258,
      "step": 15540
    },
    {
      "epoch": 1.8734939759036144,
      "grad_norm": 13.761563301086426,
      "learning_rate": 1.8126506024096386e-05,
      "loss": 0.1174,
      "step": 15550
    },
    {
      "epoch": 1.874698795180723,
      "grad_norm": 0.15743157267570496,
      "learning_rate": 1.812530120481928e-05,
      "loss": 0.1114,
      "step": 15560
    },
    {
      "epoch": 1.8759036144578314,
      "grad_norm": 7.303805828094482,
      "learning_rate": 1.8124096385542168e-05,
      "loss": 0.1263,
      "step": 15570
    },
    {
      "epoch": 1.8771084337349397,
      "grad_norm": 7.557924747467041,
      "learning_rate": 1.812289156626506e-05,
      "loss": 0.0533,
      "step": 15580
    },
    {
      "epoch": 1.878313253012048,
      "grad_norm": 0.09536909312009811,
      "learning_rate": 1.8121686746987953e-05,
      "loss": 0.1189,
      "step": 15590
    },
    {
      "epoch": 1.8795180722891565,
      "grad_norm": 0.11718753725290298,
      "learning_rate": 1.8120481927710845e-05,
      "loss": 0.0915,
      "step": 15600
    },
    {
      "epoch": 1.880722891566265,
      "grad_norm": 1.2308405637741089,
      "learning_rate": 1.8119277108433737e-05,
      "loss": 0.0719,
      "step": 15610
    },
    {
      "epoch": 1.8819277108433736,
      "grad_norm": 1.6335837841033936,
      "learning_rate": 1.8118072289156627e-05,
      "loss": 0.1014,
      "step": 15620
    },
    {
      "epoch": 1.883132530120482,
      "grad_norm": 9.546074867248535,
      "learning_rate": 1.811686746987952e-05,
      "loss": 0.134,
      "step": 15630
    },
    {
      "epoch": 1.8843373493975903,
      "grad_norm": 5.438851833343506,
      "learning_rate": 1.811566265060241e-05,
      "loss": 0.0946,
      "step": 15640
    },
    {
      "epoch": 1.8855421686746987,
      "grad_norm": 0.2768016457557678,
      "learning_rate": 1.8114457831325304e-05,
      "loss": 0.0444,
      "step": 15650
    },
    {
      "epoch": 1.886746987951807,
      "grad_norm": 5.319363594055176,
      "learning_rate": 1.8113253012048196e-05,
      "loss": 0.0512,
      "step": 15660
    },
    {
      "epoch": 1.8879518072289156,
      "grad_norm": 0.04645039886236191,
      "learning_rate": 1.8112048192771085e-05,
      "loss": 0.083,
      "step": 15670
    },
    {
      "epoch": 1.8891566265060242,
      "grad_norm": 3.8594775199890137,
      "learning_rate": 1.8110843373493978e-05,
      "loss": 0.1547,
      "step": 15680
    },
    {
      "epoch": 1.8903614457831326,
      "grad_norm": 14.060953140258789,
      "learning_rate": 1.8109638554216867e-05,
      "loss": 0.1113,
      "step": 15690
    },
    {
      "epoch": 1.891566265060241,
      "grad_norm": 0.514781653881073,
      "learning_rate": 1.8108433734939763e-05,
      "loss": 0.1015,
      "step": 15700
    },
    {
      "epoch": 1.8927710843373493,
      "grad_norm": 10.907236099243164,
      "learning_rate": 1.810722891566265e-05,
      "loss": 0.0664,
      "step": 15710
    },
    {
      "epoch": 1.8939759036144577,
      "grad_norm": 2.2825984954833984,
      "learning_rate": 1.8106024096385544e-05,
      "loss": 0.1218,
      "step": 15720
    },
    {
      "epoch": 1.8951807228915662,
      "grad_norm": 5.624215126037598,
      "learning_rate": 1.8104819277108433e-05,
      "loss": 0.1243,
      "step": 15730
    },
    {
      "epoch": 1.8963855421686748,
      "grad_norm": 1.7618345022201538,
      "learning_rate": 1.8103614457831326e-05,
      "loss": 0.1327,
      "step": 15740
    },
    {
      "epoch": 1.8975903614457832,
      "grad_norm": 3.4788479804992676,
      "learning_rate": 1.8102409638554218e-05,
      "loss": 0.0759,
      "step": 15750
    },
    {
      "epoch": 1.8987951807228916,
      "grad_norm": 4.022866725921631,
      "learning_rate": 1.810120481927711e-05,
      "loss": 0.0698,
      "step": 15760
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.494744300842285,
      "learning_rate": 1.8100000000000003e-05,
      "loss": 0.1156,
      "step": 15770
    },
    {
      "epoch": 1.9012048192771083,
      "grad_norm": 0.09610459953546524,
      "learning_rate": 1.8098795180722892e-05,
      "loss": 0.0921,
      "step": 15780
    },
    {
      "epoch": 1.9024096385542169,
      "grad_norm": 0.9895079135894775,
      "learning_rate": 1.8097590361445784e-05,
      "loss": 0.0978,
      "step": 15790
    },
    {
      "epoch": 1.9036144578313254,
      "grad_norm": 0.8840957880020142,
      "learning_rate": 1.8096385542168677e-05,
      "loss": 0.0555,
      "step": 15800
    },
    {
      "epoch": 1.9048192771084338,
      "grad_norm": 23.74289894104004,
      "learning_rate": 1.809518072289157e-05,
      "loss": 0.108,
      "step": 15810
    },
    {
      "epoch": 1.9060240963855422,
      "grad_norm": 4.02683687210083,
      "learning_rate": 1.809397590361446e-05,
      "loss": 0.1266,
      "step": 15820
    },
    {
      "epoch": 1.9072289156626505,
      "grad_norm": 4.0418877601623535,
      "learning_rate": 1.809277108433735e-05,
      "loss": 0.1133,
      "step": 15830
    },
    {
      "epoch": 1.9084337349397589,
      "grad_norm": 0.14395646750926971,
      "learning_rate": 1.8091566265060243e-05,
      "loss": 0.1058,
      "step": 15840
    },
    {
      "epoch": 1.9096385542168675,
      "grad_norm": 1.3011362552642822,
      "learning_rate": 1.8090361445783132e-05,
      "loss": 0.0848,
      "step": 15850
    },
    {
      "epoch": 1.910843373493976,
      "grad_norm": 1.3961929082870483,
      "learning_rate": 1.8089156626506025e-05,
      "loss": 0.0795,
      "step": 15860
    },
    {
      "epoch": 1.9120481927710844,
      "grad_norm": 2.222679853439331,
      "learning_rate": 1.8087951807228917e-05,
      "loss": 0.0149,
      "step": 15870
    },
    {
      "epoch": 1.9132530120481928,
      "grad_norm": 98.19783782958984,
      "learning_rate": 1.808674698795181e-05,
      "loss": 0.1515,
      "step": 15880
    },
    {
      "epoch": 1.9144578313253011,
      "grad_norm": 3.5453667640686035,
      "learning_rate": 1.8085542168674702e-05,
      "loss": 0.1101,
      "step": 15890
    },
    {
      "epoch": 1.9156626506024095,
      "grad_norm": 7.166289806365967,
      "learning_rate": 1.808433734939759e-05,
      "loss": 0.1499,
      "step": 15900
    },
    {
      "epoch": 1.916867469879518,
      "grad_norm": 4.087247848510742,
      "learning_rate": 1.8083132530120483e-05,
      "loss": 0.089,
      "step": 15910
    },
    {
      "epoch": 1.9180722891566266,
      "grad_norm": 11.417040824890137,
      "learning_rate": 1.8081927710843376e-05,
      "loss": 0.1298,
      "step": 15920
    },
    {
      "epoch": 1.919277108433735,
      "grad_norm": 3.840639352798462,
      "learning_rate": 1.8080722891566268e-05,
      "loss": 0.1345,
      "step": 15930
    },
    {
      "epoch": 1.9204819277108434,
      "grad_norm": 11.926990509033203,
      "learning_rate": 1.8079518072289157e-05,
      "loss": 0.051,
      "step": 15940
    },
    {
      "epoch": 1.9216867469879517,
      "grad_norm": 3.659743070602417,
      "learning_rate": 1.807831325301205e-05,
      "loss": 0.1443,
      "step": 15950
    },
    {
      "epoch": 1.92289156626506,
      "grad_norm": 0.5052201151847839,
      "learning_rate": 1.8077108433734942e-05,
      "loss": 0.1116,
      "step": 15960
    },
    {
      "epoch": 1.9240963855421687,
      "grad_norm": 5.143180847167969,
      "learning_rate": 1.807590361445783e-05,
      "loss": 0.0898,
      "step": 15970
    },
    {
      "epoch": 1.9253012048192772,
      "grad_norm": 0.31687453389167786,
      "learning_rate": 1.8074698795180724e-05,
      "loss": 0.1021,
      "step": 15980
    },
    {
      "epoch": 1.9265060240963856,
      "grad_norm": 2.473785638809204,
      "learning_rate": 1.8073493975903616e-05,
      "loss": 0.1059,
      "step": 15990
    },
    {
      "epoch": 1.927710843373494,
      "grad_norm": 5.41085958480835,
      "learning_rate": 1.807228915662651e-05,
      "loss": 0.0793,
      "step": 16000
    },
    {
      "epoch": 1.9289156626506023,
      "grad_norm": 2.0865092277526855,
      "learning_rate": 1.8071084337349398e-05,
      "loss": 0.0932,
      "step": 16010
    },
    {
      "epoch": 1.9301204819277107,
      "grad_norm": 0.6654870510101318,
      "learning_rate": 1.806987951807229e-05,
      "loss": 0.066,
      "step": 16020
    },
    {
      "epoch": 1.9313253012048193,
      "grad_norm": 0.7287476658821106,
      "learning_rate": 1.8068674698795182e-05,
      "loss": 0.0628,
      "step": 16030
    },
    {
      "epoch": 1.9325301204819278,
      "grad_norm": 12.660272598266602,
      "learning_rate": 1.8067469879518075e-05,
      "loss": 0.1107,
      "step": 16040
    },
    {
      "epoch": 1.9337349397590362,
      "grad_norm": 6.239190101623535,
      "learning_rate": 1.8066265060240967e-05,
      "loss": 0.1008,
      "step": 16050
    },
    {
      "epoch": 1.9349397590361446,
      "grad_norm": 3.061591863632202,
      "learning_rate": 1.8065060240963856e-05,
      "loss": 0.103,
      "step": 16060
    },
    {
      "epoch": 1.936144578313253,
      "grad_norm": 1.154624104499817,
      "learning_rate": 1.806385542168675e-05,
      "loss": 0.0584,
      "step": 16070
    },
    {
      "epoch": 1.9373493975903613,
      "grad_norm": 8.344401359558105,
      "learning_rate": 1.8062650602409638e-05,
      "loss": 0.1667,
      "step": 16080
    },
    {
      "epoch": 1.9385542168674699,
      "grad_norm": 3.589029312133789,
      "learning_rate": 1.806144578313253e-05,
      "loss": 0.069,
      "step": 16090
    },
    {
      "epoch": 1.9397590361445785,
      "grad_norm": 0.7570269107818604,
      "learning_rate": 1.8060240963855423e-05,
      "loss": 0.0425,
      "step": 16100
    },
    {
      "epoch": 1.9409638554216868,
      "grad_norm": 0.2995665669441223,
      "learning_rate": 1.8059036144578315e-05,
      "loss": 0.0938,
      "step": 16110
    },
    {
      "epoch": 1.9421686746987952,
      "grad_norm": 3.688154697418213,
      "learning_rate": 1.8057831325301208e-05,
      "loss": 0.0344,
      "step": 16120
    },
    {
      "epoch": 1.9433734939759035,
      "grad_norm": 13.246235847473145,
      "learning_rate": 1.8056626506024097e-05,
      "loss": 0.2184,
      "step": 16130
    },
    {
      "epoch": 1.944578313253012,
      "grad_norm": 0.16566070914268494,
      "learning_rate": 1.805542168674699e-05,
      "loss": 0.1029,
      "step": 16140
    },
    {
      "epoch": 1.9457831325301205,
      "grad_norm": 2.340623617172241,
      "learning_rate": 1.805421686746988e-05,
      "loss": 0.0648,
      "step": 16150
    },
    {
      "epoch": 1.946987951807229,
      "grad_norm": 7.196425437927246,
      "learning_rate": 1.8053012048192774e-05,
      "loss": 0.0463,
      "step": 16160
    },
    {
      "epoch": 1.9481927710843374,
      "grad_norm": 0.08765855431556702,
      "learning_rate": 1.8051807228915663e-05,
      "loss": 0.1112,
      "step": 16170
    },
    {
      "epoch": 1.9493975903614458,
      "grad_norm": 4.4891767501831055,
      "learning_rate": 1.8050602409638555e-05,
      "loss": 0.1227,
      "step": 16180
    },
    {
      "epoch": 1.9506024096385541,
      "grad_norm": 19.589797973632812,
      "learning_rate": 1.8049397590361448e-05,
      "loss": 0.1351,
      "step": 16190
    },
    {
      "epoch": 1.9518072289156625,
      "grad_norm": 2.564676523208618,
      "learning_rate": 1.8048192771084337e-05,
      "loss": 0.0637,
      "step": 16200
    },
    {
      "epoch": 1.953012048192771,
      "grad_norm": 2.1183598041534424,
      "learning_rate": 1.8046987951807233e-05,
      "loss": 0.081,
      "step": 16210
    },
    {
      "epoch": 1.9542168674698797,
      "grad_norm": 6.41074275970459,
      "learning_rate": 1.8045783132530122e-05,
      "loss": 0.0291,
      "step": 16220
    },
    {
      "epoch": 1.955421686746988,
      "grad_norm": 2.7715797424316406,
      "learning_rate": 1.8044578313253014e-05,
      "loss": 0.1299,
      "step": 16230
    },
    {
      "epoch": 1.9566265060240964,
      "grad_norm": 27.69695472717285,
      "learning_rate": 1.8043373493975903e-05,
      "loss": 0.083,
      "step": 16240
    },
    {
      "epoch": 1.9578313253012047,
      "grad_norm": 19.285953521728516,
      "learning_rate": 1.8042168674698796e-05,
      "loss": 0.1133,
      "step": 16250
    },
    {
      "epoch": 1.959036144578313,
      "grad_norm": 8.354049682617188,
      "learning_rate": 1.8040963855421688e-05,
      "loss": 0.0995,
      "step": 16260
    },
    {
      "epoch": 1.9602409638554217,
      "grad_norm": 7.302252292633057,
      "learning_rate": 1.803975903614458e-05,
      "loss": 0.1014,
      "step": 16270
    },
    {
      "epoch": 1.9614457831325303,
      "grad_norm": 9.571803092956543,
      "learning_rate": 1.8038554216867473e-05,
      "loss": 0.0959,
      "step": 16280
    },
    {
      "epoch": 1.9626506024096386,
      "grad_norm": 0.737055778503418,
      "learning_rate": 1.8037349397590362e-05,
      "loss": 0.0912,
      "step": 16290
    },
    {
      "epoch": 1.963855421686747,
      "grad_norm": 13.062049865722656,
      "learning_rate": 1.8036144578313255e-05,
      "loss": 0.1034,
      "step": 16300
    },
    {
      "epoch": 1.9650602409638553,
      "grad_norm": 1.7769440412521362,
      "learning_rate": 1.8034939759036144e-05,
      "loss": 0.0496,
      "step": 16310
    },
    {
      "epoch": 1.9662650602409637,
      "grad_norm": 2.756296157836914,
      "learning_rate": 1.803373493975904e-05,
      "loss": 0.1181,
      "step": 16320
    },
    {
      "epoch": 1.9674698795180723,
      "grad_norm": 1.8170050382614136,
      "learning_rate": 1.803253012048193e-05,
      "loss": 0.1274,
      "step": 16330
    },
    {
      "epoch": 1.9686746987951809,
      "grad_norm": 2.475752115249634,
      "learning_rate": 1.803132530120482e-05,
      "loss": 0.0832,
      "step": 16340
    },
    {
      "epoch": 1.9698795180722892,
      "grad_norm": 0.31169986724853516,
      "learning_rate": 1.8030120481927713e-05,
      "loss": 0.0848,
      "step": 16350
    },
    {
      "epoch": 1.9710843373493976,
      "grad_norm": 3.2749342918395996,
      "learning_rate": 1.8028915662650602e-05,
      "loss": 0.0646,
      "step": 16360
    },
    {
      "epoch": 1.972289156626506,
      "grad_norm": 0.3726300895214081,
      "learning_rate": 1.8027710843373495e-05,
      "loss": 0.0614,
      "step": 16370
    },
    {
      "epoch": 1.9734939759036143,
      "grad_norm": 10.08068561553955,
      "learning_rate": 1.8026506024096387e-05,
      "loss": 0.1446,
      "step": 16380
    },
    {
      "epoch": 1.9746987951807229,
      "grad_norm": 3.5576963424682617,
      "learning_rate": 1.802530120481928e-05,
      "loss": 0.057,
      "step": 16390
    },
    {
      "epoch": 1.9759036144578315,
      "grad_norm": 5.262248992919922,
      "learning_rate": 1.802409638554217e-05,
      "loss": 0.0735,
      "step": 16400
    },
    {
      "epoch": 1.9771084337349398,
      "grad_norm": 0.11981935799121857,
      "learning_rate": 1.802289156626506e-05,
      "loss": 0.0928,
      "step": 16410
    },
    {
      "epoch": 1.9783132530120482,
      "grad_norm": 2.5434553623199463,
      "learning_rate": 1.8021686746987954e-05,
      "loss": 0.0899,
      "step": 16420
    },
    {
      "epoch": 1.9795180722891565,
      "grad_norm": 5.506950855255127,
      "learning_rate": 1.8020481927710846e-05,
      "loss": 0.0759,
      "step": 16430
    },
    {
      "epoch": 1.980722891566265,
      "grad_norm": 18.46780776977539,
      "learning_rate": 1.801927710843374e-05,
      "loss": 0.0405,
      "step": 16440
    },
    {
      "epoch": 1.9819277108433735,
      "grad_norm": 2.8630926609039307,
      "learning_rate": 1.8018072289156627e-05,
      "loss": 0.1295,
      "step": 16450
    },
    {
      "epoch": 1.983132530120482,
      "grad_norm": 2.1676549911499023,
      "learning_rate": 1.801686746987952e-05,
      "loss": 0.1233,
      "step": 16460
    },
    {
      "epoch": 1.9843373493975904,
      "grad_norm": 1.2704867124557495,
      "learning_rate": 1.801566265060241e-05,
      "loss": 0.0959,
      "step": 16470
    },
    {
      "epoch": 1.9855421686746988,
      "grad_norm": 2.6162619590759277,
      "learning_rate": 1.80144578313253e-05,
      "loss": 0.0949,
      "step": 16480
    },
    {
      "epoch": 1.9867469879518072,
      "grad_norm": 36.44994354248047,
      "learning_rate": 1.8013253012048194e-05,
      "loss": 0.0829,
      "step": 16490
    },
    {
      "epoch": 1.9879518072289155,
      "grad_norm": 1.8320828676223755,
      "learning_rate": 1.8012048192771086e-05,
      "loss": 0.1098,
      "step": 16500
    },
    {
      "epoch": 1.989156626506024,
      "grad_norm": 0.7152143716812134,
      "learning_rate": 1.801084337349398e-05,
      "loss": 0.0679,
      "step": 16510
    },
    {
      "epoch": 1.9903614457831327,
      "grad_norm": 3.3135619163513184,
      "learning_rate": 1.8009638554216868e-05,
      "loss": 0.152,
      "step": 16520
    },
    {
      "epoch": 1.991566265060241,
      "grad_norm": 1.0020442008972168,
      "learning_rate": 1.800843373493976e-05,
      "loss": 0.0531,
      "step": 16530
    },
    {
      "epoch": 1.9927710843373494,
      "grad_norm": 3.882540702819824,
      "learning_rate": 1.8007228915662653e-05,
      "loss": 0.081,
      "step": 16540
    },
    {
      "epoch": 1.9939759036144578,
      "grad_norm": 0.3185551166534424,
      "learning_rate": 1.8006024096385545e-05,
      "loss": 0.0763,
      "step": 16550
    },
    {
      "epoch": 1.9951807228915661,
      "grad_norm": 5.844545841217041,
      "learning_rate": 1.8004819277108437e-05,
      "loss": 0.1171,
      "step": 16560
    },
    {
      "epoch": 1.9963855421686747,
      "grad_norm": 0.10170132666826248,
      "learning_rate": 1.8003614457831327e-05,
      "loss": 0.075,
      "step": 16570
    },
    {
      "epoch": 1.9975903614457833,
      "grad_norm": 2.377143621444702,
      "learning_rate": 1.800240963855422e-05,
      "loss": 0.0552,
      "step": 16580
    },
    {
      "epoch": 1.9987951807228916,
      "grad_norm": 0.35686084628105164,
      "learning_rate": 1.8001204819277108e-05,
      "loss": 0.1089,
      "step": 16590
    },
    {
      "epoch": 2.0,
      "grad_norm": 22.099201202392578,
      "learning_rate": 1.8e-05,
      "loss": 0.1305,
      "step": 16600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9700740532433446,
      "eval_f1": 0.9229562594268477,
      "eval_loss": 0.08561776578426361,
      "eval_precision": 0.9015794436586516,
      "eval_recall": 0.9453714003213447,
      "eval_runtime": 3377.7182,
      "eval_samples_per_second": 12.639,
      "eval_steps_per_second": 0.527,
      "step": 16600
    },
    {
      "epoch": 2.0012048192771084,
      "grad_norm": 3.63601016998291,
      "learning_rate": 1.7998795180722893e-05,
      "loss": 0.0808,
      "step": 16610
    },
    {
      "epoch": 2.0024096385542167,
      "grad_norm": 3.0425870418548584,
      "learning_rate": 1.7997590361445785e-05,
      "loss": 0.0687,
      "step": 16620
    },
    {
      "epoch": 2.003614457831325,
      "grad_norm": 0.85695481300354,
      "learning_rate": 1.7996385542168678e-05,
      "loss": 0.0952,
      "step": 16630
    },
    {
      "epoch": 2.004819277108434,
      "grad_norm": 11.275116920471191,
      "learning_rate": 1.7995180722891567e-05,
      "loss": 0.0774,
      "step": 16640
    },
    {
      "epoch": 2.0060240963855422,
      "grad_norm": 1.1802083253860474,
      "learning_rate": 1.799397590361446e-05,
      "loss": 0.1207,
      "step": 16650
    },
    {
      "epoch": 2.0072289156626506,
      "grad_norm": 0.4275592565536499,
      "learning_rate": 1.799277108433735e-05,
      "loss": 0.1017,
      "step": 16660
    },
    {
      "epoch": 2.008433734939759,
      "grad_norm": 0.7555020451545715,
      "learning_rate": 1.7991566265060244e-05,
      "loss": 0.0838,
      "step": 16670
    },
    {
      "epoch": 2.0096385542168673,
      "grad_norm": 0.1974964290857315,
      "learning_rate": 1.7990361445783133e-05,
      "loss": 0.0666,
      "step": 16680
    },
    {
      "epoch": 2.0108433734939757,
      "grad_norm": 11.978911399841309,
      "learning_rate": 1.7989156626506026e-05,
      "loss": 0.0296,
      "step": 16690
    },
    {
      "epoch": 2.0120481927710845,
      "grad_norm": 1.2834280729293823,
      "learning_rate": 1.7987951807228915e-05,
      "loss": 0.0422,
      "step": 16700
    },
    {
      "epoch": 2.013253012048193,
      "grad_norm": 1.4620435237884521,
      "learning_rate": 1.7986746987951807e-05,
      "loss": 0.1098,
      "step": 16710
    },
    {
      "epoch": 2.014457831325301,
      "grad_norm": 2.99450945854187,
      "learning_rate": 1.79855421686747e-05,
      "loss": 0.1436,
      "step": 16720
    },
    {
      "epoch": 2.0156626506024096,
      "grad_norm": 0.5383396744728088,
      "learning_rate": 1.7984337349397592e-05,
      "loss": 0.0558,
      "step": 16730
    },
    {
      "epoch": 2.016867469879518,
      "grad_norm": 0.05861003324389458,
      "learning_rate": 1.7983132530120484e-05,
      "loss": 0.0693,
      "step": 16740
    },
    {
      "epoch": 2.0180722891566263,
      "grad_norm": 0.056082095950841904,
      "learning_rate": 1.7981927710843373e-05,
      "loss": 0.0307,
      "step": 16750
    },
    {
      "epoch": 2.019277108433735,
      "grad_norm": 0.03591616451740265,
      "learning_rate": 1.7980722891566266e-05,
      "loss": 0.0606,
      "step": 16760
    },
    {
      "epoch": 2.0204819277108435,
      "grad_norm": 0.3560522198677063,
      "learning_rate": 1.7979518072289158e-05,
      "loss": 0.0649,
      "step": 16770
    },
    {
      "epoch": 2.021686746987952,
      "grad_norm": 0.013508837670087814,
      "learning_rate": 1.797831325301205e-05,
      "loss": 0.0602,
      "step": 16780
    },
    {
      "epoch": 2.02289156626506,
      "grad_norm": 0.37206804752349854,
      "learning_rate": 1.7977108433734943e-05,
      "loss": 0.1361,
      "step": 16790
    },
    {
      "epoch": 2.0240963855421685,
      "grad_norm": 27.127593994140625,
      "learning_rate": 1.7975903614457832e-05,
      "loss": 0.1068,
      "step": 16800
    },
    {
      "epoch": 2.025301204819277,
      "grad_norm": 6.3154096603393555,
      "learning_rate": 1.7974698795180725e-05,
      "loss": 0.0663,
      "step": 16810
    },
    {
      "epoch": 2.0265060240963857,
      "grad_norm": 0.3494730293750763,
      "learning_rate": 1.7973493975903614e-05,
      "loss": 0.0874,
      "step": 16820
    },
    {
      "epoch": 2.027710843373494,
      "grad_norm": 8.413496971130371,
      "learning_rate": 1.797228915662651e-05,
      "loss": 0.1369,
      "step": 16830
    },
    {
      "epoch": 2.0289156626506024,
      "grad_norm": 0.36757421493530273,
      "learning_rate": 1.79710843373494e-05,
      "loss": 0.0765,
      "step": 16840
    },
    {
      "epoch": 2.0301204819277108,
      "grad_norm": 3.5231568813323975,
      "learning_rate": 1.796987951807229e-05,
      "loss": 0.1159,
      "step": 16850
    },
    {
      "epoch": 2.031325301204819,
      "grad_norm": 0.9932051301002502,
      "learning_rate": 1.7968674698795183e-05,
      "loss": 0.0761,
      "step": 16860
    },
    {
      "epoch": 2.0325301204819275,
      "grad_norm": 1.17439603805542,
      "learning_rate": 1.7967469879518072e-05,
      "loss": 0.1173,
      "step": 16870
    },
    {
      "epoch": 2.0337349397590363,
      "grad_norm": 26.06807518005371,
      "learning_rate": 1.7966265060240965e-05,
      "loss": 0.0493,
      "step": 16880
    },
    {
      "epoch": 2.0349397590361447,
      "grad_norm": 5.861244201660156,
      "learning_rate": 1.7965060240963857e-05,
      "loss": 0.1161,
      "step": 16890
    },
    {
      "epoch": 2.036144578313253,
      "grad_norm": 0.1246429830789566,
      "learning_rate": 1.796385542168675e-05,
      "loss": 0.0618,
      "step": 16900
    },
    {
      "epoch": 2.0373493975903614,
      "grad_norm": 0.4757869839668274,
      "learning_rate": 1.796265060240964e-05,
      "loss": 0.078,
      "step": 16910
    },
    {
      "epoch": 2.0385542168674697,
      "grad_norm": 2.6246182918548584,
      "learning_rate": 1.796144578313253e-05,
      "loss": 0.0771,
      "step": 16920
    },
    {
      "epoch": 2.039759036144578,
      "grad_norm": 1.8377718925476074,
      "learning_rate": 1.7960240963855424e-05,
      "loss": 0.0883,
      "step": 16930
    },
    {
      "epoch": 2.040963855421687,
      "grad_norm": 8.599954605102539,
      "learning_rate": 1.7959036144578316e-05,
      "loss": 0.1192,
      "step": 16940
    },
    {
      "epoch": 2.0421686746987953,
      "grad_norm": 5.126506805419922,
      "learning_rate": 1.795783132530121e-05,
      "loss": 0.0707,
      "step": 16950
    },
    {
      "epoch": 2.0433734939759036,
      "grad_norm": 0.10854053497314453,
      "learning_rate": 1.7956626506024098e-05,
      "loss": 0.057,
      "step": 16960
    },
    {
      "epoch": 2.044578313253012,
      "grad_norm": 0.13970690965652466,
      "learning_rate": 1.795542168674699e-05,
      "loss": 0.079,
      "step": 16970
    },
    {
      "epoch": 2.0457831325301203,
      "grad_norm": 1.2659586668014526,
      "learning_rate": 1.795421686746988e-05,
      "loss": 0.0241,
      "step": 16980
    },
    {
      "epoch": 2.0469879518072287,
      "grad_norm": 21.72582244873047,
      "learning_rate": 1.795301204819277e-05,
      "loss": 0.0774,
      "step": 16990
    },
    {
      "epoch": 2.0481927710843375,
      "grad_norm": 10.433507919311523,
      "learning_rate": 1.7951807228915664e-05,
      "loss": 0.1827,
      "step": 17000
    },
    {
      "epoch": 2.049397590361446,
      "grad_norm": 0.10532618314027786,
      "learning_rate": 1.7950602409638556e-05,
      "loss": 0.0828,
      "step": 17010
    },
    {
      "epoch": 2.0506024096385542,
      "grad_norm": 5.621153831481934,
      "learning_rate": 1.794939759036145e-05,
      "loss": 0.1118,
      "step": 17020
    },
    {
      "epoch": 2.0518072289156626,
      "grad_norm": 1.7538546323776245,
      "learning_rate": 1.7948192771084338e-05,
      "loss": 0.0305,
      "step": 17030
    },
    {
      "epoch": 2.053012048192771,
      "grad_norm": 0.20523947477340698,
      "learning_rate": 1.794698795180723e-05,
      "loss": 0.1063,
      "step": 17040
    },
    {
      "epoch": 2.0542168674698793,
      "grad_norm": 0.7897822260856628,
      "learning_rate": 1.7945783132530123e-05,
      "loss": 0.0623,
      "step": 17050
    },
    {
      "epoch": 2.055421686746988,
      "grad_norm": 2.5366926193237305,
      "learning_rate": 1.7944578313253015e-05,
      "loss": 0.1129,
      "step": 17060
    },
    {
      "epoch": 2.0566265060240965,
      "grad_norm": 12.259976387023926,
      "learning_rate": 1.7943373493975904e-05,
      "loss": 0.0894,
      "step": 17070
    },
    {
      "epoch": 2.057831325301205,
      "grad_norm": 6.655364990234375,
      "learning_rate": 1.7942168674698797e-05,
      "loss": 0.1317,
      "step": 17080
    },
    {
      "epoch": 2.059036144578313,
      "grad_norm": 2.802640438079834,
      "learning_rate": 1.794096385542169e-05,
      "loss": 0.1028,
      "step": 17090
    },
    {
      "epoch": 2.0602409638554215,
      "grad_norm": 0.20036105811595917,
      "learning_rate": 1.7939759036144578e-05,
      "loss": 0.0617,
      "step": 17100
    },
    {
      "epoch": 2.06144578313253,
      "grad_norm": 9.345589637756348,
      "learning_rate": 1.793855421686747e-05,
      "loss": 0.056,
      "step": 17110
    },
    {
      "epoch": 2.0626506024096387,
      "grad_norm": 33.80887985229492,
      "learning_rate": 1.7937349397590363e-05,
      "loss": 0.0296,
      "step": 17120
    },
    {
      "epoch": 2.063855421686747,
      "grad_norm": 9.15772819519043,
      "learning_rate": 1.7936144578313255e-05,
      "loss": 0.083,
      "step": 17130
    },
    {
      "epoch": 2.0650602409638554,
      "grad_norm": 2.639315128326416,
      "learning_rate": 1.7934939759036145e-05,
      "loss": 0.0526,
      "step": 17140
    },
    {
      "epoch": 2.066265060240964,
      "grad_norm": 13.439059257507324,
      "learning_rate": 1.7933734939759037e-05,
      "loss": 0.073,
      "step": 17150
    },
    {
      "epoch": 2.067469879518072,
      "grad_norm": 3.4675893783569336,
      "learning_rate": 1.793253012048193e-05,
      "loss": 0.1011,
      "step": 17160
    },
    {
      "epoch": 2.0686746987951805,
      "grad_norm": 0.12402693927288055,
      "learning_rate": 1.7931325301204822e-05,
      "loss": 0.0242,
      "step": 17170
    },
    {
      "epoch": 2.0698795180722893,
      "grad_norm": 1.8738524913787842,
      "learning_rate": 1.7930120481927714e-05,
      "loss": 0.0901,
      "step": 17180
    },
    {
      "epoch": 2.0710843373493977,
      "grad_norm": 1.4512743949890137,
      "learning_rate": 1.7928915662650603e-05,
      "loss": 0.0987,
      "step": 17190
    },
    {
      "epoch": 2.072289156626506,
      "grad_norm": 0.1989029198884964,
      "learning_rate": 1.7927710843373496e-05,
      "loss": 0.0777,
      "step": 17200
    },
    {
      "epoch": 2.0734939759036144,
      "grad_norm": 0.7513971328735352,
      "learning_rate": 1.7926506024096385e-05,
      "loss": 0.0977,
      "step": 17210
    },
    {
      "epoch": 2.0746987951807228,
      "grad_norm": 0.6287543773651123,
      "learning_rate": 1.7925301204819277e-05,
      "loss": 0.0751,
      "step": 17220
    },
    {
      "epoch": 2.075903614457831,
      "grad_norm": 10.581132888793945,
      "learning_rate": 1.792409638554217e-05,
      "loss": 0.0513,
      "step": 17230
    },
    {
      "epoch": 2.07710843373494,
      "grad_norm": 2.588738203048706,
      "learning_rate": 1.7922891566265062e-05,
      "loss": 0.1124,
      "step": 17240
    },
    {
      "epoch": 2.0783132530120483,
      "grad_norm": 0.9855639934539795,
      "learning_rate": 1.7921686746987955e-05,
      "loss": 0.0521,
      "step": 17250
    },
    {
      "epoch": 2.0795180722891566,
      "grad_norm": 2.5094783306121826,
      "learning_rate": 1.7920481927710844e-05,
      "loss": 0.0647,
      "step": 17260
    },
    {
      "epoch": 2.080722891566265,
      "grad_norm": 1.7222156524658203,
      "learning_rate": 1.7919277108433736e-05,
      "loss": 0.1616,
      "step": 17270
    },
    {
      "epoch": 2.0819277108433734,
      "grad_norm": 0.63498854637146,
      "learning_rate": 1.791807228915663e-05,
      "loss": 0.1038,
      "step": 17280
    },
    {
      "epoch": 2.0831325301204817,
      "grad_norm": 2.100733995437622,
      "learning_rate": 1.791686746987952e-05,
      "loss": 0.0803,
      "step": 17290
    },
    {
      "epoch": 2.0843373493975905,
      "grad_norm": 3.523120164871216,
      "learning_rate": 1.791566265060241e-05,
      "loss": 0.0858,
      "step": 17300
    },
    {
      "epoch": 2.085542168674699,
      "grad_norm": 1.0366727113723755,
      "learning_rate": 1.7914457831325302e-05,
      "loss": 0.0755,
      "step": 17310
    },
    {
      "epoch": 2.0867469879518072,
      "grad_norm": 1.4637564420700073,
      "learning_rate": 1.7913253012048195e-05,
      "loss": 0.0817,
      "step": 17320
    },
    {
      "epoch": 2.0879518072289156,
      "grad_norm": 1.9262142181396484,
      "learning_rate": 1.7912048192771084e-05,
      "loss": 0.0545,
      "step": 17330
    },
    {
      "epoch": 2.089156626506024,
      "grad_norm": 4.2642741203308105,
      "learning_rate": 1.7910843373493976e-05,
      "loss": 0.1176,
      "step": 17340
    },
    {
      "epoch": 2.0903614457831323,
      "grad_norm": 1.3193632364273071,
      "learning_rate": 1.790963855421687e-05,
      "loss": 0.0827,
      "step": 17350
    },
    {
      "epoch": 2.091566265060241,
      "grad_norm": 3.322953939437866,
      "learning_rate": 1.790843373493976e-05,
      "loss": 0.0568,
      "step": 17360
    },
    {
      "epoch": 2.0927710843373495,
      "grad_norm": 1.307220220565796,
      "learning_rate": 1.790722891566265e-05,
      "loss": 0.049,
      "step": 17370
    },
    {
      "epoch": 2.093975903614458,
      "grad_norm": 0.1932002454996109,
      "learning_rate": 1.7906024096385543e-05,
      "loss": 0.0395,
      "step": 17380
    },
    {
      "epoch": 2.095180722891566,
      "grad_norm": 9.38378620147705,
      "learning_rate": 1.7904819277108435e-05,
      "loss": 0.1216,
      "step": 17390
    },
    {
      "epoch": 2.0963855421686746,
      "grad_norm": 3.0588934421539307,
      "learning_rate": 1.7903614457831327e-05,
      "loss": 0.0854,
      "step": 17400
    },
    {
      "epoch": 2.097590361445783,
      "grad_norm": 9.726292610168457,
      "learning_rate": 1.790240963855422e-05,
      "loss": 0.0797,
      "step": 17410
    },
    {
      "epoch": 2.0987951807228917,
      "grad_norm": 0.2269737273454666,
      "learning_rate": 1.790120481927711e-05,
      "loss": 0.0519,
      "step": 17420
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.13580317795276642,
      "learning_rate": 1.79e-05,
      "loss": 0.0442,
      "step": 17430
    },
    {
      "epoch": 2.1012048192771084,
      "grad_norm": 1.5772792100906372,
      "learning_rate": 1.789879518072289e-05,
      "loss": 0.0422,
      "step": 17440
    },
    {
      "epoch": 2.102409638554217,
      "grad_norm": 0.016698287799954414,
      "learning_rate": 1.7897590361445786e-05,
      "loss": 0.0784,
      "step": 17450
    },
    {
      "epoch": 2.103614457831325,
      "grad_norm": 0.17496494948863983,
      "learning_rate": 1.789638554216868e-05,
      "loss": 0.0369,
      "step": 17460
    },
    {
      "epoch": 2.1048192771084335,
      "grad_norm": 0.3763584494590759,
      "learning_rate": 1.7895180722891568e-05,
      "loss": 0.024,
      "step": 17470
    },
    {
      "epoch": 2.1060240963855423,
      "grad_norm": 3.862508773803711,
      "learning_rate": 1.789397590361446e-05,
      "loss": 0.087,
      "step": 17480
    },
    {
      "epoch": 2.1072289156626507,
      "grad_norm": 49.02592086791992,
      "learning_rate": 1.789277108433735e-05,
      "loss": 0.0525,
      "step": 17490
    },
    {
      "epoch": 2.108433734939759,
      "grad_norm": 43.06519317626953,
      "learning_rate": 1.789156626506024e-05,
      "loss": 0.1713,
      "step": 17500
    },
    {
      "epoch": 2.1096385542168674,
      "grad_norm": 8.825433731079102,
      "learning_rate": 1.7890361445783134e-05,
      "loss": 0.1223,
      "step": 17510
    },
    {
      "epoch": 2.1108433734939758,
      "grad_norm": 1.3225274085998535,
      "learning_rate": 1.7889156626506027e-05,
      "loss": 0.0454,
      "step": 17520
    },
    {
      "epoch": 2.112048192771084,
      "grad_norm": 8.74427604675293,
      "learning_rate": 1.788795180722892e-05,
      "loss": 0.0715,
      "step": 17530
    },
    {
      "epoch": 2.113253012048193,
      "grad_norm": 2.405191659927368,
      "learning_rate": 1.7886746987951808e-05,
      "loss": 0.1153,
      "step": 17540
    },
    {
      "epoch": 2.1144578313253013,
      "grad_norm": 38.77629089355469,
      "learning_rate": 1.78855421686747e-05,
      "loss": 0.1256,
      "step": 17550
    },
    {
      "epoch": 2.1156626506024097,
      "grad_norm": 7.3256707191467285,
      "learning_rate": 1.7884337349397593e-05,
      "loss": 0.102,
      "step": 17560
    },
    {
      "epoch": 2.116867469879518,
      "grad_norm": 0.22605645656585693,
      "learning_rate": 1.7883132530120485e-05,
      "loss": 0.0432,
      "step": 17570
    },
    {
      "epoch": 2.1180722891566264,
      "grad_norm": 3.0994534492492676,
      "learning_rate": 1.7881927710843374e-05,
      "loss": 0.1354,
      "step": 17580
    },
    {
      "epoch": 2.1192771084337347,
      "grad_norm": 1.160335659980774,
      "learning_rate": 1.7880722891566267e-05,
      "loss": 0.1017,
      "step": 17590
    },
    {
      "epoch": 2.1204819277108435,
      "grad_norm": 1.5977096557617188,
      "learning_rate": 1.7879518072289156e-05,
      "loss": 0.0512,
      "step": 17600
    },
    {
      "epoch": 2.121686746987952,
      "grad_norm": 1.3889100551605225,
      "learning_rate": 1.7878313253012048e-05,
      "loss": 0.029,
      "step": 17610
    },
    {
      "epoch": 2.1228915662650603,
      "grad_norm": 4.75192928314209,
      "learning_rate": 1.787710843373494e-05,
      "loss": 0.0483,
      "step": 17620
    },
    {
      "epoch": 2.1240963855421686,
      "grad_norm": 4.770944118499756,
      "learning_rate": 1.7875903614457833e-05,
      "loss": 0.0871,
      "step": 17630
    },
    {
      "epoch": 2.125301204819277,
      "grad_norm": 27.178234100341797,
      "learning_rate": 1.7874698795180726e-05,
      "loss": 0.0987,
      "step": 17640
    },
    {
      "epoch": 2.1265060240963853,
      "grad_norm": 0.779273509979248,
      "learning_rate": 1.7873493975903615e-05,
      "loss": 0.0562,
      "step": 17650
    },
    {
      "epoch": 2.127710843373494,
      "grad_norm": 1.6808942556381226,
      "learning_rate": 1.7872289156626507e-05,
      "loss": 0.1098,
      "step": 17660
    },
    {
      "epoch": 2.1289156626506025,
      "grad_norm": 7.5657057762146,
      "learning_rate": 1.78710843373494e-05,
      "loss": 0.0543,
      "step": 17670
    },
    {
      "epoch": 2.130120481927711,
      "grad_norm": 9.428820610046387,
      "learning_rate": 1.7869879518072292e-05,
      "loss": 0.0776,
      "step": 17680
    },
    {
      "epoch": 2.1313253012048192,
      "grad_norm": 9.265170097351074,
      "learning_rate": 1.7868674698795184e-05,
      "loss": 0.0945,
      "step": 17690
    },
    {
      "epoch": 2.1325301204819276,
      "grad_norm": 1.7868566513061523,
      "learning_rate": 1.7867469879518073e-05,
      "loss": 0.0798,
      "step": 17700
    },
    {
      "epoch": 2.133734939759036,
      "grad_norm": 0.24173283576965332,
      "learning_rate": 1.7866265060240966e-05,
      "loss": 0.0476,
      "step": 17710
    },
    {
      "epoch": 2.1349397590361447,
      "grad_norm": 3.825995922088623,
      "learning_rate": 1.7865060240963855e-05,
      "loss": 0.1381,
      "step": 17720
    },
    {
      "epoch": 2.136144578313253,
      "grad_norm": 2.5449917316436768,
      "learning_rate": 1.7863855421686747e-05,
      "loss": 0.0707,
      "step": 17730
    },
    {
      "epoch": 2.1373493975903615,
      "grad_norm": 9.650477409362793,
      "learning_rate": 1.786265060240964e-05,
      "loss": 0.1468,
      "step": 17740
    },
    {
      "epoch": 2.13855421686747,
      "grad_norm": 7.898255348205566,
      "learning_rate": 1.7861445783132532e-05,
      "loss": 0.0819,
      "step": 17750
    },
    {
      "epoch": 2.139759036144578,
      "grad_norm": 1.8197270631790161,
      "learning_rate": 1.7860240963855425e-05,
      "loss": 0.1082,
      "step": 17760
    },
    {
      "epoch": 2.1409638554216865,
      "grad_norm": 0.13223925232887268,
      "learning_rate": 1.7859036144578314e-05,
      "loss": 0.0515,
      "step": 17770
    },
    {
      "epoch": 2.1421686746987953,
      "grad_norm": 0.06290232390165329,
      "learning_rate": 1.7857831325301206e-05,
      "loss": 0.0858,
      "step": 17780
    },
    {
      "epoch": 2.1433734939759037,
      "grad_norm": 0.2534405589103699,
      "learning_rate": 1.78566265060241e-05,
      "loss": 0.1735,
      "step": 17790
    },
    {
      "epoch": 2.144578313253012,
      "grad_norm": 4.001912593841553,
      "learning_rate": 1.785542168674699e-05,
      "loss": 0.207,
      "step": 17800
    },
    {
      "epoch": 2.1457831325301204,
      "grad_norm": 1.0020391941070557,
      "learning_rate": 1.785421686746988e-05,
      "loss": 0.1218,
      "step": 17810
    },
    {
      "epoch": 2.146987951807229,
      "grad_norm": 3.913148880004883,
      "learning_rate": 1.7853012048192772e-05,
      "loss": 0.1076,
      "step": 17820
    },
    {
      "epoch": 2.148192771084337,
      "grad_norm": 3.58042049407959,
      "learning_rate": 1.7851807228915665e-05,
      "loss": 0.0697,
      "step": 17830
    },
    {
      "epoch": 2.149397590361446,
      "grad_norm": 4.670560836791992,
      "learning_rate": 1.7850602409638554e-05,
      "loss": 0.1024,
      "step": 17840
    },
    {
      "epoch": 2.1506024096385543,
      "grad_norm": 8.703003883361816,
      "learning_rate": 1.7849397590361446e-05,
      "loss": 0.0999,
      "step": 17850
    },
    {
      "epoch": 2.1518072289156627,
      "grad_norm": 2.815387725830078,
      "learning_rate": 1.784819277108434e-05,
      "loss": 0.05,
      "step": 17860
    },
    {
      "epoch": 2.153012048192771,
      "grad_norm": 2.2298824787139893,
      "learning_rate": 1.784698795180723e-05,
      "loss": 0.0512,
      "step": 17870
    },
    {
      "epoch": 2.1542168674698794,
      "grad_norm": 1.1197882890701294,
      "learning_rate": 1.784578313253012e-05,
      "loss": 0.0221,
      "step": 17880
    },
    {
      "epoch": 2.1554216867469878,
      "grad_norm": 0.046827711164951324,
      "learning_rate": 1.7844578313253013e-05,
      "loss": 0.0802,
      "step": 17890
    },
    {
      "epoch": 2.1566265060240966,
      "grad_norm": 1.3431841135025024,
      "learning_rate": 1.7843373493975905e-05,
      "loss": 0.0687,
      "step": 17900
    },
    {
      "epoch": 2.157831325301205,
      "grad_norm": 3.0142102241516113,
      "learning_rate": 1.7842168674698798e-05,
      "loss": 0.0738,
      "step": 17910
    },
    {
      "epoch": 2.1590361445783133,
      "grad_norm": 0.7693154811859131,
      "learning_rate": 1.784096385542169e-05,
      "loss": 0.1016,
      "step": 17920
    },
    {
      "epoch": 2.1602409638554216,
      "grad_norm": 4.871264934539795,
      "learning_rate": 1.783975903614458e-05,
      "loss": 0.0518,
      "step": 17930
    },
    {
      "epoch": 2.16144578313253,
      "grad_norm": 0.6673979759216309,
      "learning_rate": 1.783855421686747e-05,
      "loss": 0.0455,
      "step": 17940
    },
    {
      "epoch": 2.1626506024096384,
      "grad_norm": 0.4455918073654175,
      "learning_rate": 1.783734939759036e-05,
      "loss": 0.0845,
      "step": 17950
    },
    {
      "epoch": 2.163855421686747,
      "grad_norm": 1.2312572002410889,
      "learning_rate": 1.7836144578313256e-05,
      "loss": 0.1055,
      "step": 17960
    },
    {
      "epoch": 2.1650602409638555,
      "grad_norm": 4.701480388641357,
      "learning_rate": 1.7834939759036145e-05,
      "loss": 0.0791,
      "step": 17970
    },
    {
      "epoch": 2.166265060240964,
      "grad_norm": 5.853181838989258,
      "learning_rate": 1.7833734939759038e-05,
      "loss": 0.1034,
      "step": 17980
    },
    {
      "epoch": 2.1674698795180722,
      "grad_norm": 7.499696254730225,
      "learning_rate": 1.783253012048193e-05,
      "loss": 0.0948,
      "step": 17990
    },
    {
      "epoch": 2.1686746987951806,
      "grad_norm": 0.6961369514465332,
      "learning_rate": 1.783132530120482e-05,
      "loss": 0.1055,
      "step": 18000
    },
    {
      "epoch": 2.169879518072289,
      "grad_norm": 13.293413162231445,
      "learning_rate": 1.7830120481927712e-05,
      "loss": 0.0766,
      "step": 18010
    },
    {
      "epoch": 2.1710843373493978,
      "grad_norm": 1.4080100059509277,
      "learning_rate": 1.7828915662650604e-05,
      "loss": 0.0927,
      "step": 18020
    },
    {
      "epoch": 2.172289156626506,
      "grad_norm": 0.30789101123809814,
      "learning_rate": 1.7827710843373497e-05,
      "loss": 0.0403,
      "step": 18030
    },
    {
      "epoch": 2.1734939759036145,
      "grad_norm": 3.126681327819824,
      "learning_rate": 1.7826506024096386e-05,
      "loss": 0.0886,
      "step": 18040
    },
    {
      "epoch": 2.174698795180723,
      "grad_norm": 26.29521942138672,
      "learning_rate": 1.7825301204819278e-05,
      "loss": 0.034,
      "step": 18050
    },
    {
      "epoch": 2.175903614457831,
      "grad_norm": 0.06659682840108871,
      "learning_rate": 1.782409638554217e-05,
      "loss": 0.1047,
      "step": 18060
    },
    {
      "epoch": 2.1771084337349396,
      "grad_norm": 2.0889625549316406,
      "learning_rate": 1.7822891566265063e-05,
      "loss": 0.1286,
      "step": 18070
    },
    {
      "epoch": 2.1783132530120484,
      "grad_norm": 2.4100241661071777,
      "learning_rate": 1.7821686746987955e-05,
      "loss": 0.1141,
      "step": 18080
    },
    {
      "epoch": 2.1795180722891567,
      "grad_norm": 0.23932486772537231,
      "learning_rate": 1.7820481927710845e-05,
      "loss": 0.0778,
      "step": 18090
    },
    {
      "epoch": 2.180722891566265,
      "grad_norm": 15.922786712646484,
      "learning_rate": 1.7819277108433737e-05,
      "loss": 0.0445,
      "step": 18100
    },
    {
      "epoch": 2.1819277108433734,
      "grad_norm": 1.7607046365737915,
      "learning_rate": 1.7818072289156626e-05,
      "loss": 0.0417,
      "step": 18110
    },
    {
      "epoch": 2.183132530120482,
      "grad_norm": 22.9510440826416,
      "learning_rate": 1.781686746987952e-05,
      "loss": 0.1179,
      "step": 18120
    },
    {
      "epoch": 2.18433734939759,
      "grad_norm": 16.025922775268555,
      "learning_rate": 1.781566265060241e-05,
      "loss": 0.1281,
      "step": 18130
    },
    {
      "epoch": 2.185542168674699,
      "grad_norm": 0.4806285500526428,
      "learning_rate": 1.7814457831325303e-05,
      "loss": 0.1296,
      "step": 18140
    },
    {
      "epoch": 2.1867469879518073,
      "grad_norm": 14.786893844604492,
      "learning_rate": 1.7813253012048196e-05,
      "loss": 0.0981,
      "step": 18150
    },
    {
      "epoch": 2.1879518072289157,
      "grad_norm": 2.3884453773498535,
      "learning_rate": 1.7812048192771085e-05,
      "loss": 0.1551,
      "step": 18160
    },
    {
      "epoch": 2.189156626506024,
      "grad_norm": 10.303533554077148,
      "learning_rate": 1.7810843373493977e-05,
      "loss": 0.0836,
      "step": 18170
    },
    {
      "epoch": 2.1903614457831324,
      "grad_norm": 7.014832496643066,
      "learning_rate": 1.780963855421687e-05,
      "loss": 0.1128,
      "step": 18180
    },
    {
      "epoch": 2.1915662650602408,
      "grad_norm": 16.20166778564453,
      "learning_rate": 1.7808433734939762e-05,
      "loss": 0.0552,
      "step": 18190
    },
    {
      "epoch": 2.1927710843373496,
      "grad_norm": 0.5716014504432678,
      "learning_rate": 1.780722891566265e-05,
      "loss": 0.0822,
      "step": 18200
    },
    {
      "epoch": 2.193975903614458,
      "grad_norm": 3.397068738937378,
      "learning_rate": 1.7806024096385544e-05,
      "loss": 0.1186,
      "step": 18210
    },
    {
      "epoch": 2.1951807228915663,
      "grad_norm": 34.89501953125,
      "learning_rate": 1.7804819277108436e-05,
      "loss": 0.0882,
      "step": 18220
    },
    {
      "epoch": 2.1963855421686747,
      "grad_norm": 22.35015296936035,
      "learning_rate": 1.7803614457831325e-05,
      "loss": 0.0818,
      "step": 18230
    },
    {
      "epoch": 2.197590361445783,
      "grad_norm": 8.870926856994629,
      "learning_rate": 1.7802409638554218e-05,
      "loss": 0.1552,
      "step": 18240
    },
    {
      "epoch": 2.1987951807228914,
      "grad_norm": 4.1132988929748535,
      "learning_rate": 1.780120481927711e-05,
      "loss": 0.139,
      "step": 18250
    },
    {
      "epoch": 2.2,
      "grad_norm": 8.126118659973145,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 0.0814,
      "step": 18260
    },
    {
      "epoch": 2.2012048192771085,
      "grad_norm": 0.7547520995140076,
      "learning_rate": 1.779879518072289e-05,
      "loss": 0.043,
      "step": 18270
    },
    {
      "epoch": 2.202409638554217,
      "grad_norm": 0.28150027990341187,
      "learning_rate": 1.7797590361445784e-05,
      "loss": 0.1128,
      "step": 18280
    },
    {
      "epoch": 2.2036144578313253,
      "grad_norm": 18.49207878112793,
      "learning_rate": 1.7796385542168676e-05,
      "loss": 0.093,
      "step": 18290
    },
    {
      "epoch": 2.2048192771084336,
      "grad_norm": 4.3575592041015625,
      "learning_rate": 1.779518072289157e-05,
      "loss": 0.1266,
      "step": 18300
    },
    {
      "epoch": 2.206024096385542,
      "grad_norm": 2.8520681858062744,
      "learning_rate": 1.779397590361446e-05,
      "loss": 0.1257,
      "step": 18310
    },
    {
      "epoch": 2.207228915662651,
      "grad_norm": 2.251617908477783,
      "learning_rate": 1.779277108433735e-05,
      "loss": 0.1049,
      "step": 18320
    },
    {
      "epoch": 2.208433734939759,
      "grad_norm": 0.9574268460273743,
      "learning_rate": 1.7791566265060243e-05,
      "loss": 0.0808,
      "step": 18330
    },
    {
      "epoch": 2.2096385542168675,
      "grad_norm": 6.965824127197266,
      "learning_rate": 1.779036144578313e-05,
      "loss": 0.1231,
      "step": 18340
    },
    {
      "epoch": 2.210843373493976,
      "grad_norm": 9.612231254577637,
      "learning_rate": 1.7789156626506024e-05,
      "loss": 0.0809,
      "step": 18350
    },
    {
      "epoch": 2.212048192771084,
      "grad_norm": 10.024706840515137,
      "learning_rate": 1.7787951807228917e-05,
      "loss": 0.0772,
      "step": 18360
    },
    {
      "epoch": 2.2132530120481926,
      "grad_norm": 0.9244265556335449,
      "learning_rate": 1.778674698795181e-05,
      "loss": 0.0871,
      "step": 18370
    },
    {
      "epoch": 2.2144578313253014,
      "grad_norm": 2.2720389366149902,
      "learning_rate": 1.77855421686747e-05,
      "loss": 0.1397,
      "step": 18380
    },
    {
      "epoch": 2.2156626506024097,
      "grad_norm": 5.74235725402832,
      "learning_rate": 1.778433734939759e-05,
      "loss": 0.057,
      "step": 18390
    },
    {
      "epoch": 2.216867469879518,
      "grad_norm": 3.0455057621002197,
      "learning_rate": 1.7783132530120483e-05,
      "loss": 0.0486,
      "step": 18400
    },
    {
      "epoch": 2.2180722891566265,
      "grad_norm": 0.8524251580238342,
      "learning_rate": 1.7781927710843375e-05,
      "loss": 0.0534,
      "step": 18410
    },
    {
      "epoch": 2.219277108433735,
      "grad_norm": 6.957838535308838,
      "learning_rate": 1.7780722891566268e-05,
      "loss": 0.1974,
      "step": 18420
    },
    {
      "epoch": 2.220481927710843,
      "grad_norm": 0.9985048770904541,
      "learning_rate": 1.777951807228916e-05,
      "loss": 0.0548,
      "step": 18430
    },
    {
      "epoch": 2.221686746987952,
      "grad_norm": 0.18744497001171112,
      "learning_rate": 1.777831325301205e-05,
      "loss": 0.1267,
      "step": 18440
    },
    {
      "epoch": 2.2228915662650603,
      "grad_norm": 12.368810653686523,
      "learning_rate": 1.7777108433734942e-05,
      "loss": 0.0633,
      "step": 18450
    },
    {
      "epoch": 2.2240963855421687,
      "grad_norm": 2.264528512954712,
      "learning_rate": 1.777590361445783e-05,
      "loss": 0.0661,
      "step": 18460
    },
    {
      "epoch": 2.225301204819277,
      "grad_norm": 13.882952690124512,
      "learning_rate": 1.7774698795180723e-05,
      "loss": 0.0924,
      "step": 18470
    },
    {
      "epoch": 2.2265060240963854,
      "grad_norm": 0.25862303376197815,
      "learning_rate": 1.7773493975903616e-05,
      "loss": 0.0587,
      "step": 18480
    },
    {
      "epoch": 2.227710843373494,
      "grad_norm": 5.967716693878174,
      "learning_rate": 1.7772289156626508e-05,
      "loss": 0.0838,
      "step": 18490
    },
    {
      "epoch": 2.2289156626506026,
      "grad_norm": 0.22679923474788666,
      "learning_rate": 1.7771084337349397e-05,
      "loss": 0.0832,
      "step": 18500
    },
    {
      "epoch": 2.230120481927711,
      "grad_norm": 0.0705607458949089,
      "learning_rate": 1.776987951807229e-05,
      "loss": 0.0322,
      "step": 18510
    },
    {
      "epoch": 2.2313253012048193,
      "grad_norm": 0.12578937411308289,
      "learning_rate": 1.7768674698795182e-05,
      "loss": 0.047,
      "step": 18520
    },
    {
      "epoch": 2.2325301204819277,
      "grad_norm": 5.386999607086182,
      "learning_rate": 1.7767469879518074e-05,
      "loss": 0.1583,
      "step": 18530
    },
    {
      "epoch": 2.233734939759036,
      "grad_norm": 1.1418588161468506,
      "learning_rate": 1.7766265060240967e-05,
      "loss": 0.0665,
      "step": 18540
    },
    {
      "epoch": 2.2349397590361444,
      "grad_norm": 1.672445297241211,
      "learning_rate": 1.7765060240963856e-05,
      "loss": 0.0795,
      "step": 18550
    },
    {
      "epoch": 2.236144578313253,
      "grad_norm": 22.84695053100586,
      "learning_rate": 1.776385542168675e-05,
      "loss": 0.0804,
      "step": 18560
    },
    {
      "epoch": 2.2373493975903616,
      "grad_norm": 5.584354400634766,
      "learning_rate": 1.7762650602409637e-05,
      "loss": 0.0562,
      "step": 18570
    },
    {
      "epoch": 2.23855421686747,
      "grad_norm": 3.033360004425049,
      "learning_rate": 1.7761445783132533e-05,
      "loss": 0.098,
      "step": 18580
    },
    {
      "epoch": 2.2397590361445783,
      "grad_norm": 1.0701897144317627,
      "learning_rate": 1.7760240963855426e-05,
      "loss": 0.105,
      "step": 18590
    },
    {
      "epoch": 2.2409638554216866,
      "grad_norm": 2.135493040084839,
      "learning_rate": 1.7759036144578315e-05,
      "loss": 0.1345,
      "step": 18600
    },
    {
      "epoch": 2.242168674698795,
      "grad_norm": 0.11919177323579788,
      "learning_rate": 1.7757831325301207e-05,
      "loss": 0.084,
      "step": 18610
    },
    {
      "epoch": 2.243373493975904,
      "grad_norm": 0.7419434785842896,
      "learning_rate": 1.7756626506024096e-05,
      "loss": 0.0522,
      "step": 18620
    },
    {
      "epoch": 2.244578313253012,
      "grad_norm": 7.572150230407715,
      "learning_rate": 1.775542168674699e-05,
      "loss": 0.1101,
      "step": 18630
    },
    {
      "epoch": 2.2457831325301205,
      "grad_norm": 7.292864799499512,
      "learning_rate": 1.775421686746988e-05,
      "loss": 0.0444,
      "step": 18640
    },
    {
      "epoch": 2.246987951807229,
      "grad_norm": 0.03092428483068943,
      "learning_rate": 1.7753012048192773e-05,
      "loss": 0.0853,
      "step": 18650
    },
    {
      "epoch": 2.2481927710843372,
      "grad_norm": 2.218296766281128,
      "learning_rate": 1.7751807228915666e-05,
      "loss": 0.0689,
      "step": 18660
    },
    {
      "epoch": 2.2493975903614456,
      "grad_norm": 0.5565522909164429,
      "learning_rate": 1.7750602409638555e-05,
      "loss": 0.0576,
      "step": 18670
    },
    {
      "epoch": 2.2506024096385544,
      "grad_norm": 0.10838137567043304,
      "learning_rate": 1.7749397590361447e-05,
      "loss": 0.0967,
      "step": 18680
    },
    {
      "epoch": 2.2518072289156628,
      "grad_norm": 3.6487784385681152,
      "learning_rate": 1.774819277108434e-05,
      "loss": 0.1067,
      "step": 18690
    },
    {
      "epoch": 2.253012048192771,
      "grad_norm": 5.525334358215332,
      "learning_rate": 1.7746987951807232e-05,
      "loss": 0.0462,
      "step": 18700
    },
    {
      "epoch": 2.2542168674698795,
      "grad_norm": 2.290072441101074,
      "learning_rate": 1.774578313253012e-05,
      "loss": 0.0563,
      "step": 18710
    },
    {
      "epoch": 2.255421686746988,
      "grad_norm": 0.4215644598007202,
      "learning_rate": 1.7744578313253014e-05,
      "loss": 0.0792,
      "step": 18720
    },
    {
      "epoch": 2.256626506024096,
      "grad_norm": 5.768730640411377,
      "learning_rate": 1.7743373493975906e-05,
      "loss": 0.1893,
      "step": 18730
    },
    {
      "epoch": 2.257831325301205,
      "grad_norm": 0.46115073561668396,
      "learning_rate": 1.7742168674698795e-05,
      "loss": 0.0596,
      "step": 18740
    },
    {
      "epoch": 2.2590361445783134,
      "grad_norm": 7.215086936950684,
      "learning_rate": 1.7740963855421688e-05,
      "loss": 0.0909,
      "step": 18750
    },
    {
      "epoch": 2.2602409638554217,
      "grad_norm": 1.7336478233337402,
      "learning_rate": 1.773975903614458e-05,
      "loss": 0.0619,
      "step": 18760
    },
    {
      "epoch": 2.26144578313253,
      "grad_norm": 0.3326503336429596,
      "learning_rate": 1.7738554216867473e-05,
      "loss": 0.1058,
      "step": 18770
    },
    {
      "epoch": 2.2626506024096384,
      "grad_norm": 9.335291862487793,
      "learning_rate": 1.773734939759036e-05,
      "loss": 0.0622,
      "step": 18780
    },
    {
      "epoch": 2.263855421686747,
      "grad_norm": 1.746952772140503,
      "learning_rate": 1.7736144578313254e-05,
      "loss": 0.0827,
      "step": 18790
    },
    {
      "epoch": 2.2650602409638556,
      "grad_norm": 0.3626905381679535,
      "learning_rate": 1.7734939759036146e-05,
      "loss": 0.1251,
      "step": 18800
    },
    {
      "epoch": 2.266265060240964,
      "grad_norm": 0.09924212098121643,
      "learning_rate": 1.773373493975904e-05,
      "loss": 0.0825,
      "step": 18810
    },
    {
      "epoch": 2.2674698795180723,
      "grad_norm": 1.9202313423156738,
      "learning_rate": 1.773253012048193e-05,
      "loss": 0.1447,
      "step": 18820
    },
    {
      "epoch": 2.2686746987951807,
      "grad_norm": 5.934916973114014,
      "learning_rate": 1.773132530120482e-05,
      "loss": 0.0654,
      "step": 18830
    },
    {
      "epoch": 2.269879518072289,
      "grad_norm": 2.8048644065856934,
      "learning_rate": 1.7730120481927713e-05,
      "loss": 0.1234,
      "step": 18840
    },
    {
      "epoch": 2.2710843373493974,
      "grad_norm": 3.760606288909912,
      "learning_rate": 1.7728915662650602e-05,
      "loss": 0.0751,
      "step": 18850
    },
    {
      "epoch": 2.272289156626506,
      "grad_norm": 2.6291697025299072,
      "learning_rate": 1.7727710843373494e-05,
      "loss": 0.0961,
      "step": 18860
    },
    {
      "epoch": 2.2734939759036146,
      "grad_norm": 2.73891282081604,
      "learning_rate": 1.7726506024096387e-05,
      "loss": 0.0673,
      "step": 18870
    },
    {
      "epoch": 2.274698795180723,
      "grad_norm": 0.33367452025413513,
      "learning_rate": 1.772530120481928e-05,
      "loss": 0.0851,
      "step": 18880
    },
    {
      "epoch": 2.2759036144578313,
      "grad_norm": 3.286928653717041,
      "learning_rate": 1.772409638554217e-05,
      "loss": 0.081,
      "step": 18890
    },
    {
      "epoch": 2.2771084337349397,
      "grad_norm": 4.062604904174805,
      "learning_rate": 1.772289156626506e-05,
      "loss": 0.0822,
      "step": 18900
    },
    {
      "epoch": 2.278313253012048,
      "grad_norm": 1.2293682098388672,
      "learning_rate": 1.7721686746987953e-05,
      "loss": 0.0526,
      "step": 18910
    },
    {
      "epoch": 2.279518072289157,
      "grad_norm": 1.5127384662628174,
      "learning_rate": 1.7720481927710845e-05,
      "loss": 0.0804,
      "step": 18920
    },
    {
      "epoch": 2.280722891566265,
      "grad_norm": 3.787632942199707,
      "learning_rate": 1.7719277108433738e-05,
      "loss": 0.0813,
      "step": 18930
    },
    {
      "epoch": 2.2819277108433735,
      "grad_norm": 0.15798908472061157,
      "learning_rate": 1.7718072289156627e-05,
      "loss": 0.075,
      "step": 18940
    },
    {
      "epoch": 2.283132530120482,
      "grad_norm": 20.148935317993164,
      "learning_rate": 1.771686746987952e-05,
      "loss": 0.1003,
      "step": 18950
    },
    {
      "epoch": 2.2843373493975903,
      "grad_norm": 0.20724591612815857,
      "learning_rate": 1.7715662650602412e-05,
      "loss": 0.0674,
      "step": 18960
    },
    {
      "epoch": 2.2855421686746986,
      "grad_norm": 0.11125489324331284,
      "learning_rate": 1.77144578313253e-05,
      "loss": 0.0461,
      "step": 18970
    },
    {
      "epoch": 2.2867469879518074,
      "grad_norm": 0.04459396377205849,
      "learning_rate": 1.7713253012048193e-05,
      "loss": 0.1034,
      "step": 18980
    },
    {
      "epoch": 2.287951807228916,
      "grad_norm": 1.7594449520111084,
      "learning_rate": 1.7712048192771086e-05,
      "loss": 0.1052,
      "step": 18990
    },
    {
      "epoch": 2.289156626506024,
      "grad_norm": 1.2692722082138062,
      "learning_rate": 1.7710843373493978e-05,
      "loss": 0.0429,
      "step": 19000
    },
    {
      "epoch": 2.2903614457831325,
      "grad_norm": 2.7597360610961914,
      "learning_rate": 1.7709638554216867e-05,
      "loss": 0.1309,
      "step": 19010
    },
    {
      "epoch": 2.291566265060241,
      "grad_norm": 0.4707508087158203,
      "learning_rate": 1.770843373493976e-05,
      "loss": 0.0443,
      "step": 19020
    },
    {
      "epoch": 2.292771084337349,
      "grad_norm": 0.3617638647556305,
      "learning_rate": 1.7707228915662652e-05,
      "loss": 0.1112,
      "step": 19030
    },
    {
      "epoch": 2.293975903614458,
      "grad_norm": 5.806638240814209,
      "learning_rate": 1.7706024096385545e-05,
      "loss": 0.1974,
      "step": 19040
    },
    {
      "epoch": 2.2951807228915664,
      "grad_norm": 13.505582809448242,
      "learning_rate": 1.7704819277108437e-05,
      "loss": 0.0745,
      "step": 19050
    },
    {
      "epoch": 2.2963855421686747,
      "grad_norm": 5.717599391937256,
      "learning_rate": 1.7703614457831326e-05,
      "loss": 0.0644,
      "step": 19060
    },
    {
      "epoch": 2.297590361445783,
      "grad_norm": 2.1980419158935547,
      "learning_rate": 1.770240963855422e-05,
      "loss": 0.119,
      "step": 19070
    },
    {
      "epoch": 2.2987951807228915,
      "grad_norm": 10.011716842651367,
      "learning_rate": 1.7701204819277108e-05,
      "loss": 0.1923,
      "step": 19080
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.4104456901550293,
      "learning_rate": 1.77e-05,
      "loss": 0.0504,
      "step": 19090
    },
    {
      "epoch": 2.3012048192771086,
      "grad_norm": 3.7796030044555664,
      "learning_rate": 1.7698795180722892e-05,
      "loss": 0.0694,
      "step": 19100
    },
    {
      "epoch": 2.302409638554217,
      "grad_norm": 5.762124061584473,
      "learning_rate": 1.7697590361445785e-05,
      "loss": 0.1304,
      "step": 19110
    },
    {
      "epoch": 2.3036144578313253,
      "grad_norm": 0.3217824697494507,
      "learning_rate": 1.7696385542168677e-05,
      "loss": 0.0691,
      "step": 19120
    },
    {
      "epoch": 2.3048192771084337,
      "grad_norm": 0.15817609429359436,
      "learning_rate": 1.7695180722891566e-05,
      "loss": 0.1079,
      "step": 19130
    },
    {
      "epoch": 2.306024096385542,
      "grad_norm": 0.3708055913448334,
      "learning_rate": 1.769397590361446e-05,
      "loss": 0.0955,
      "step": 19140
    },
    {
      "epoch": 2.3072289156626504,
      "grad_norm": 3.982921600341797,
      "learning_rate": 1.769277108433735e-05,
      "loss": 0.028,
      "step": 19150
    },
    {
      "epoch": 2.3084337349397592,
      "grad_norm": 1.3058017492294312,
      "learning_rate": 1.7691566265060244e-05,
      "loss": 0.1454,
      "step": 19160
    },
    {
      "epoch": 2.3096385542168676,
      "grad_norm": 0.48910319805145264,
      "learning_rate": 1.7690361445783133e-05,
      "loss": 0.0335,
      "step": 19170
    },
    {
      "epoch": 2.310843373493976,
      "grad_norm": 3.0389397144317627,
      "learning_rate": 1.7689156626506025e-05,
      "loss": 0.0814,
      "step": 19180
    },
    {
      "epoch": 2.3120481927710843,
      "grad_norm": 9.885126113891602,
      "learning_rate": 1.7687951807228918e-05,
      "loss": 0.0336,
      "step": 19190
    },
    {
      "epoch": 2.3132530120481927,
      "grad_norm": 9.124763488769531,
      "learning_rate": 1.768674698795181e-05,
      "loss": 0.0604,
      "step": 19200
    },
    {
      "epoch": 2.314457831325301,
      "grad_norm": 9.6083984375,
      "learning_rate": 1.7685542168674702e-05,
      "loss": 0.0622,
      "step": 19210
    },
    {
      "epoch": 2.31566265060241,
      "grad_norm": 1.590027928352356,
      "learning_rate": 1.768433734939759e-05,
      "loss": 0.0643,
      "step": 19220
    },
    {
      "epoch": 2.316867469879518,
      "grad_norm": 1.8938606977462769,
      "learning_rate": 1.7683132530120484e-05,
      "loss": 0.101,
      "step": 19230
    },
    {
      "epoch": 2.3180722891566266,
      "grad_norm": 0.6348351240158081,
      "learning_rate": 1.7681927710843373e-05,
      "loss": 0.078,
      "step": 19240
    },
    {
      "epoch": 2.319277108433735,
      "grad_norm": 0.24478697776794434,
      "learning_rate": 1.7680722891566265e-05,
      "loss": 0.0656,
      "step": 19250
    },
    {
      "epoch": 2.3204819277108433,
      "grad_norm": 0.07030081003904343,
      "learning_rate": 1.7679518072289158e-05,
      "loss": 0.1079,
      "step": 19260
    },
    {
      "epoch": 2.3216867469879516,
      "grad_norm": 6.108033180236816,
      "learning_rate": 1.767831325301205e-05,
      "loss": 0.0845,
      "step": 19270
    },
    {
      "epoch": 2.32289156626506,
      "grad_norm": 4.096609115600586,
      "learning_rate": 1.7677108433734943e-05,
      "loss": 0.0818,
      "step": 19280
    },
    {
      "epoch": 2.324096385542169,
      "grad_norm": 5.3010783195495605,
      "learning_rate": 1.7675903614457832e-05,
      "loss": 0.1777,
      "step": 19290
    },
    {
      "epoch": 2.325301204819277,
      "grad_norm": 7.357713222503662,
      "learning_rate": 1.7674698795180724e-05,
      "loss": 0.1259,
      "step": 19300
    },
    {
      "epoch": 2.3265060240963855,
      "grad_norm": 1.2367582321166992,
      "learning_rate": 1.7673493975903617e-05,
      "loss": 0.075,
      "step": 19310
    },
    {
      "epoch": 2.327710843373494,
      "grad_norm": 0.231829434633255,
      "learning_rate": 1.767228915662651e-05,
      "loss": 0.043,
      "step": 19320
    },
    {
      "epoch": 2.3289156626506022,
      "grad_norm": 0.21201136708259583,
      "learning_rate": 1.76710843373494e-05,
      "loss": 0.0354,
      "step": 19330
    },
    {
      "epoch": 2.330120481927711,
      "grad_norm": 0.06619171798229218,
      "learning_rate": 1.766987951807229e-05,
      "loss": 0.0339,
      "step": 19340
    },
    {
      "epoch": 2.3313253012048194,
      "grad_norm": 7.03990364074707,
      "learning_rate": 1.7668674698795183e-05,
      "loss": 0.0808,
      "step": 19350
    },
    {
      "epoch": 2.3325301204819278,
      "grad_norm": 7.640591144561768,
      "learning_rate": 1.7667469879518072e-05,
      "loss": 0.073,
      "step": 19360
    },
    {
      "epoch": 2.333734939759036,
      "grad_norm": 7.794499397277832,
      "learning_rate": 1.7666265060240964e-05,
      "loss": 0.1158,
      "step": 19370
    },
    {
      "epoch": 2.3349397590361445,
      "grad_norm": 0.5841966271400452,
      "learning_rate": 1.7665060240963857e-05,
      "loss": 0.1753,
      "step": 19380
    },
    {
      "epoch": 2.336144578313253,
      "grad_norm": 0.9373102784156799,
      "learning_rate": 1.766385542168675e-05,
      "loss": 0.0532,
      "step": 19390
    },
    {
      "epoch": 2.337349397590361,
      "grad_norm": 0.12095824629068375,
      "learning_rate": 1.766265060240964e-05,
      "loss": 0.0859,
      "step": 19400
    },
    {
      "epoch": 2.33855421686747,
      "grad_norm": 0.06662456691265106,
      "learning_rate": 1.766144578313253e-05,
      "loss": 0.0554,
      "step": 19410
    },
    {
      "epoch": 2.3397590361445784,
      "grad_norm": 9.889269828796387,
      "learning_rate": 1.7660240963855423e-05,
      "loss": 0.1206,
      "step": 19420
    },
    {
      "epoch": 2.3409638554216867,
      "grad_norm": 0.11881350725889206,
      "learning_rate": 1.7659036144578316e-05,
      "loss": 0.1088,
      "step": 19430
    },
    {
      "epoch": 2.342168674698795,
      "grad_norm": 0.2848065495491028,
      "learning_rate": 1.7657831325301208e-05,
      "loss": 0.1087,
      "step": 19440
    },
    {
      "epoch": 2.3433734939759034,
      "grad_norm": 5.761688232421875,
      "learning_rate": 1.7656626506024097e-05,
      "loss": 0.0212,
      "step": 19450
    },
    {
      "epoch": 2.3445783132530122,
      "grad_norm": 1.9794743061065674,
      "learning_rate": 1.765542168674699e-05,
      "loss": 0.0426,
      "step": 19460
    },
    {
      "epoch": 2.3457831325301206,
      "grad_norm": 3.00846266746521,
      "learning_rate": 1.765421686746988e-05,
      "loss": 0.1166,
      "step": 19470
    },
    {
      "epoch": 2.346987951807229,
      "grad_norm": 5.886647701263428,
      "learning_rate": 1.765301204819277e-05,
      "loss": 0.1175,
      "step": 19480
    },
    {
      "epoch": 2.3481927710843373,
      "grad_norm": 0.4483567178249359,
      "learning_rate": 1.7651807228915663e-05,
      "loss": 0.1256,
      "step": 19490
    },
    {
      "epoch": 2.3493975903614457,
      "grad_norm": 2.2319397926330566,
      "learning_rate": 1.7650602409638556e-05,
      "loss": 0.0485,
      "step": 19500
    },
    {
      "epoch": 2.350602409638554,
      "grad_norm": 17.40777587890625,
      "learning_rate": 1.764939759036145e-05,
      "loss": 0.0495,
      "step": 19510
    },
    {
      "epoch": 2.3518072289156624,
      "grad_norm": 0.19591663777828217,
      "learning_rate": 1.7648192771084337e-05,
      "loss": 0.1291,
      "step": 19520
    },
    {
      "epoch": 2.353012048192771,
      "grad_norm": 1.1386981010437012,
      "learning_rate": 1.764698795180723e-05,
      "loss": 0.0672,
      "step": 19530
    },
    {
      "epoch": 2.3542168674698796,
      "grad_norm": 0.5504099726676941,
      "learning_rate": 1.7645783132530122e-05,
      "loss": 0.1021,
      "step": 19540
    },
    {
      "epoch": 2.355421686746988,
      "grad_norm": 168.40040588378906,
      "learning_rate": 1.7644578313253015e-05,
      "loss": 0.0886,
      "step": 19550
    },
    {
      "epoch": 2.3566265060240963,
      "grad_norm": 11.609979629516602,
      "learning_rate": 1.7643373493975907e-05,
      "loss": 0.0818,
      "step": 19560
    },
    {
      "epoch": 2.3578313253012047,
      "grad_norm": 2.8536386489868164,
      "learning_rate": 1.7642168674698796e-05,
      "loss": 0.0985,
      "step": 19570
    },
    {
      "epoch": 2.3590361445783135,
      "grad_norm": 39.76865768432617,
      "learning_rate": 1.764096385542169e-05,
      "loss": 0.0907,
      "step": 19580
    },
    {
      "epoch": 2.360240963855422,
      "grad_norm": 0.5167977213859558,
      "learning_rate": 1.7639759036144578e-05,
      "loss": 0.095,
      "step": 19590
    },
    {
      "epoch": 2.36144578313253,
      "grad_norm": 3.773406505584717,
      "learning_rate": 1.763855421686747e-05,
      "loss": 0.0804,
      "step": 19600
    },
    {
      "epoch": 2.3626506024096385,
      "grad_norm": 11.77176570892334,
      "learning_rate": 1.7637349397590363e-05,
      "loss": 0.1353,
      "step": 19610
    },
    {
      "epoch": 2.363855421686747,
      "grad_norm": 0.16449257731437683,
      "learning_rate": 1.7636144578313255e-05,
      "loss": 0.0818,
      "step": 19620
    },
    {
      "epoch": 2.3650602409638553,
      "grad_norm": 0.6649820804595947,
      "learning_rate": 1.7634939759036147e-05,
      "loss": 0.0568,
      "step": 19630
    },
    {
      "epoch": 2.3662650602409636,
      "grad_norm": 0.7475444674491882,
      "learning_rate": 1.7633734939759036e-05,
      "loss": 0.0615,
      "step": 19640
    },
    {
      "epoch": 2.3674698795180724,
      "grad_norm": 2.8570361137390137,
      "learning_rate": 1.763253012048193e-05,
      "loss": 0.0791,
      "step": 19650
    },
    {
      "epoch": 2.3686746987951808,
      "grad_norm": 0.7428674697875977,
      "learning_rate": 1.763132530120482e-05,
      "loss": 0.0151,
      "step": 19660
    },
    {
      "epoch": 2.369879518072289,
      "grad_norm": 0.41864168643951416,
      "learning_rate": 1.7630120481927714e-05,
      "loss": 0.0529,
      "step": 19670
    },
    {
      "epoch": 2.3710843373493975,
      "grad_norm": 9.141302108764648,
      "learning_rate": 1.7628915662650603e-05,
      "loss": 0.0514,
      "step": 19680
    },
    {
      "epoch": 2.372289156626506,
      "grad_norm": 0.14826977252960205,
      "learning_rate": 1.7627710843373495e-05,
      "loss": 0.0928,
      "step": 19690
    },
    {
      "epoch": 2.3734939759036147,
      "grad_norm": 7.651271343231201,
      "learning_rate": 1.7626506024096384e-05,
      "loss": 0.0608,
      "step": 19700
    },
    {
      "epoch": 2.374698795180723,
      "grad_norm": 17.65435028076172,
      "learning_rate": 1.762530120481928e-05,
      "loss": 0.1548,
      "step": 19710
    },
    {
      "epoch": 2.3759036144578314,
      "grad_norm": 1.2110660076141357,
      "learning_rate": 1.7624096385542173e-05,
      "loss": 0.0764,
      "step": 19720
    },
    {
      "epoch": 2.3771084337349397,
      "grad_norm": 4.3278584480285645,
      "learning_rate": 1.762289156626506e-05,
      "loss": 0.1052,
      "step": 19730
    },
    {
      "epoch": 2.378313253012048,
      "grad_norm": 5.306339740753174,
      "learning_rate": 1.7621686746987954e-05,
      "loss": 0.1011,
      "step": 19740
    },
    {
      "epoch": 2.3795180722891565,
      "grad_norm": 28.76544952392578,
      "learning_rate": 1.7620481927710843e-05,
      "loss": 0.0223,
      "step": 19750
    },
    {
      "epoch": 2.380722891566265,
      "grad_norm": 22.298288345336914,
      "learning_rate": 1.7619277108433735e-05,
      "loss": 0.0963,
      "step": 19760
    },
    {
      "epoch": 2.3819277108433736,
      "grad_norm": 0.40886327624320984,
      "learning_rate": 1.7618072289156628e-05,
      "loss": 0.0804,
      "step": 19770
    },
    {
      "epoch": 2.383132530120482,
      "grad_norm": 0.35619932413101196,
      "learning_rate": 1.761686746987952e-05,
      "loss": 0.0675,
      "step": 19780
    },
    {
      "epoch": 2.3843373493975903,
      "grad_norm": 0.44480153918266296,
      "learning_rate": 1.7615662650602413e-05,
      "loss": 0.0398,
      "step": 19790
    },
    {
      "epoch": 2.3855421686746987,
      "grad_norm": 0.24230726063251495,
      "learning_rate": 1.7614457831325302e-05,
      "loss": 0.0622,
      "step": 19800
    },
    {
      "epoch": 2.386746987951807,
      "grad_norm": 2.6835408210754395,
      "learning_rate": 1.7613253012048194e-05,
      "loss": 0.0815,
      "step": 19810
    },
    {
      "epoch": 2.387951807228916,
      "grad_norm": 51.24311447143555,
      "learning_rate": 1.7612048192771087e-05,
      "loss": 0.0614,
      "step": 19820
    },
    {
      "epoch": 2.3891566265060242,
      "grad_norm": 0.15712803602218628,
      "learning_rate": 1.761084337349398e-05,
      "loss": 0.052,
      "step": 19830
    },
    {
      "epoch": 2.3903614457831326,
      "grad_norm": 43.422279357910156,
      "learning_rate": 1.7609638554216868e-05,
      "loss": 0.1119,
      "step": 19840
    },
    {
      "epoch": 2.391566265060241,
      "grad_norm": 0.21574844419956207,
      "learning_rate": 1.760843373493976e-05,
      "loss": 0.063,
      "step": 19850
    },
    {
      "epoch": 2.3927710843373493,
      "grad_norm": 3.0633456707000732,
      "learning_rate": 1.7607228915662653e-05,
      "loss": 0.1012,
      "step": 19860
    },
    {
      "epoch": 2.3939759036144577,
      "grad_norm": 3.0352299213409424,
      "learning_rate": 1.7606024096385542e-05,
      "loss": 0.0835,
      "step": 19870
    },
    {
      "epoch": 2.395180722891566,
      "grad_norm": 0.16626064479351044,
      "learning_rate": 1.7604819277108435e-05,
      "loss": 0.0914,
      "step": 19880
    },
    {
      "epoch": 2.396385542168675,
      "grad_norm": 0.8450342416763306,
      "learning_rate": 1.7603614457831327e-05,
      "loss": 0.0691,
      "step": 19890
    },
    {
      "epoch": 2.397590361445783,
      "grad_norm": 10.614155769348145,
      "learning_rate": 1.760240963855422e-05,
      "loss": 0.0781,
      "step": 19900
    },
    {
      "epoch": 2.3987951807228916,
      "grad_norm": 19.581995010375977,
      "learning_rate": 1.760120481927711e-05,
      "loss": 0.0797,
      "step": 19910
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.12793438136577606,
      "learning_rate": 1.76e-05,
      "loss": 0.1023,
      "step": 19920
    },
    {
      "epoch": 2.4012048192771083,
      "grad_norm": 2.0570831298828125,
      "learning_rate": 1.7598795180722893e-05,
      "loss": 0.087,
      "step": 19930
    },
    {
      "epoch": 2.402409638554217,
      "grad_norm": 0.13190233707427979,
      "learning_rate": 1.7597590361445786e-05,
      "loss": 0.0486,
      "step": 19940
    },
    {
      "epoch": 2.4036144578313254,
      "grad_norm": 0.24674955010414124,
      "learning_rate": 1.7596385542168678e-05,
      "loss": 0.0604,
      "step": 19950
    },
    {
      "epoch": 2.404819277108434,
      "grad_norm": 2.4209210872650146,
      "learning_rate": 1.7595180722891567e-05,
      "loss": 0.098,
      "step": 19960
    },
    {
      "epoch": 2.406024096385542,
      "grad_norm": 3.435859203338623,
      "learning_rate": 1.759397590361446e-05,
      "loss": 0.0984,
      "step": 19970
    },
    {
      "epoch": 2.4072289156626505,
      "grad_norm": 2.4664509296417236,
      "learning_rate": 1.759277108433735e-05,
      "loss": 0.0645,
      "step": 19980
    },
    {
      "epoch": 2.408433734939759,
      "grad_norm": 1.0640666484832764,
      "learning_rate": 1.759156626506024e-05,
      "loss": 0.0848,
      "step": 19990
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 1.011200189590454,
      "learning_rate": 1.7590361445783134e-05,
      "loss": 0.0636,
      "step": 20000
    },
    {
      "epoch": 2.410843373493976,
      "grad_norm": 1.8607503175735474,
      "learning_rate": 1.7589156626506026e-05,
      "loss": 0.0384,
      "step": 20010
    },
    {
      "epoch": 2.4120481927710844,
      "grad_norm": 3.7635135650634766,
      "learning_rate": 1.758795180722892e-05,
      "loss": 0.0775,
      "step": 20020
    },
    {
      "epoch": 2.4132530120481928,
      "grad_norm": 0.1803007274866104,
      "learning_rate": 1.7586746987951808e-05,
      "loss": 0.1123,
      "step": 20030
    },
    {
      "epoch": 2.414457831325301,
      "grad_norm": 8.747979164123535,
      "learning_rate": 1.75855421686747e-05,
      "loss": 0.0391,
      "step": 20040
    },
    {
      "epoch": 2.4156626506024095,
      "grad_norm": 20.189517974853516,
      "learning_rate": 1.7584337349397592e-05,
      "loss": 0.0435,
      "step": 20050
    },
    {
      "epoch": 2.4168674698795183,
      "grad_norm": 15.289850234985352,
      "learning_rate": 1.7583132530120485e-05,
      "loss": 0.1074,
      "step": 20060
    },
    {
      "epoch": 2.4180722891566266,
      "grad_norm": 29.94789695739746,
      "learning_rate": 1.7581927710843374e-05,
      "loss": 0.0709,
      "step": 20070
    },
    {
      "epoch": 2.419277108433735,
      "grad_norm": 0.18901413679122925,
      "learning_rate": 1.7580722891566266e-05,
      "loss": 0.09,
      "step": 20080
    },
    {
      "epoch": 2.4204819277108434,
      "grad_norm": 0.07458680123090744,
      "learning_rate": 1.757951807228916e-05,
      "loss": 0.0434,
      "step": 20090
    },
    {
      "epoch": 2.4216867469879517,
      "grad_norm": 0.11971332877874374,
      "learning_rate": 1.7578313253012048e-05,
      "loss": 0.0905,
      "step": 20100
    },
    {
      "epoch": 2.42289156626506,
      "grad_norm": 5.04230260848999,
      "learning_rate": 1.757710843373494e-05,
      "loss": 0.0688,
      "step": 20110
    },
    {
      "epoch": 2.4240963855421684,
      "grad_norm": 0.8513117432594299,
      "learning_rate": 1.7575903614457833e-05,
      "loss": 0.0909,
      "step": 20120
    },
    {
      "epoch": 2.4253012048192772,
      "grad_norm": 5.489832878112793,
      "learning_rate": 1.7574698795180725e-05,
      "loss": 0.0699,
      "step": 20130
    },
    {
      "epoch": 2.4265060240963856,
      "grad_norm": 13.508243560791016,
      "learning_rate": 1.7573493975903614e-05,
      "loss": 0.1204,
      "step": 20140
    },
    {
      "epoch": 2.427710843373494,
      "grad_norm": 5.078591346740723,
      "learning_rate": 1.7572289156626507e-05,
      "loss": 0.1182,
      "step": 20150
    },
    {
      "epoch": 2.4289156626506023,
      "grad_norm": 1.2820231914520264,
      "learning_rate": 1.75710843373494e-05,
      "loss": 0.0219,
      "step": 20160
    },
    {
      "epoch": 2.4301204819277107,
      "grad_norm": 0.2414761632680893,
      "learning_rate": 1.756987951807229e-05,
      "loss": 0.0356,
      "step": 20170
    },
    {
      "epoch": 2.4313253012048195,
      "grad_norm": 0.06724958121776581,
      "learning_rate": 1.7568674698795184e-05,
      "loss": 0.0438,
      "step": 20180
    },
    {
      "epoch": 2.432530120481928,
      "grad_norm": 0.12629909813404083,
      "learning_rate": 1.7567469879518073e-05,
      "loss": 0.0943,
      "step": 20190
    },
    {
      "epoch": 2.433734939759036,
      "grad_norm": 0.18883489072322845,
      "learning_rate": 1.7566265060240965e-05,
      "loss": 0.0925,
      "step": 20200
    },
    {
      "epoch": 2.4349397590361446,
      "grad_norm": 3.246212959289551,
      "learning_rate": 1.7565060240963854e-05,
      "loss": 0.1017,
      "step": 20210
    },
    {
      "epoch": 2.436144578313253,
      "grad_norm": 9.316834449768066,
      "learning_rate": 1.7563855421686747e-05,
      "loss": 0.0871,
      "step": 20220
    },
    {
      "epoch": 2.4373493975903613,
      "grad_norm": 1.9018598794937134,
      "learning_rate": 1.7562650602409643e-05,
      "loss": 0.0698,
      "step": 20230
    },
    {
      "epoch": 2.4385542168674696,
      "grad_norm": 0.49577662348747253,
      "learning_rate": 1.7561445783132532e-05,
      "loss": 0.0693,
      "step": 20240
    },
    {
      "epoch": 2.4397590361445785,
      "grad_norm": 2.3140032291412354,
      "learning_rate": 1.7560240963855424e-05,
      "loss": 0.0613,
      "step": 20250
    },
    {
      "epoch": 2.440963855421687,
      "grad_norm": 2.0841000080108643,
      "learning_rate": 1.7559036144578313e-05,
      "loss": 0.0491,
      "step": 20260
    },
    {
      "epoch": 2.442168674698795,
      "grad_norm": 42.734405517578125,
      "learning_rate": 1.7557831325301206e-05,
      "loss": 0.0945,
      "step": 20270
    },
    {
      "epoch": 2.4433734939759035,
      "grad_norm": 0.39773494005203247,
      "learning_rate": 1.7556626506024098e-05,
      "loss": 0.058,
      "step": 20280
    },
    {
      "epoch": 2.444578313253012,
      "grad_norm": 60.41020965576172,
      "learning_rate": 1.755542168674699e-05,
      "loss": 0.0941,
      "step": 20290
    },
    {
      "epoch": 2.4457831325301207,
      "grad_norm": 6.3583984375,
      "learning_rate": 1.755421686746988e-05,
      "loss": 0.0741,
      "step": 20300
    },
    {
      "epoch": 2.446987951807229,
      "grad_norm": 0.540295422077179,
      "learning_rate": 1.7553012048192772e-05,
      "loss": 0.0538,
      "step": 20310
    },
    {
      "epoch": 2.4481927710843374,
      "grad_norm": 3.556093215942383,
      "learning_rate": 1.7551807228915664e-05,
      "loss": 0.089,
      "step": 20320
    },
    {
      "epoch": 2.4493975903614458,
      "grad_norm": 5.633772373199463,
      "learning_rate": 1.7550602409638557e-05,
      "loss": 0.0472,
      "step": 20330
    },
    {
      "epoch": 2.450602409638554,
      "grad_norm": 3.2163619995117188,
      "learning_rate": 1.754939759036145e-05,
      "loss": 0.0845,
      "step": 20340
    },
    {
      "epoch": 2.4518072289156625,
      "grad_norm": 1.2137616872787476,
      "learning_rate": 1.754819277108434e-05,
      "loss": 0.1191,
      "step": 20350
    },
    {
      "epoch": 2.453012048192771,
      "grad_norm": 3.0953454971313477,
      "learning_rate": 1.754698795180723e-05,
      "loss": 0.0505,
      "step": 20360
    },
    {
      "epoch": 2.4542168674698797,
      "grad_norm": 35.130821228027344,
      "learning_rate": 1.754578313253012e-05,
      "loss": 0.0978,
      "step": 20370
    },
    {
      "epoch": 2.455421686746988,
      "grad_norm": 1.4068715572357178,
      "learning_rate": 1.7544578313253012e-05,
      "loss": 0.097,
      "step": 20380
    },
    {
      "epoch": 2.4566265060240964,
      "grad_norm": 0.7868665456771851,
      "learning_rate": 1.7543373493975905e-05,
      "loss": 0.1693,
      "step": 20390
    },
    {
      "epoch": 2.4578313253012047,
      "grad_norm": 1.9232897758483887,
      "learning_rate": 1.7542168674698797e-05,
      "loss": 0.0912,
      "step": 20400
    },
    {
      "epoch": 2.459036144578313,
      "grad_norm": 0.17624562978744507,
      "learning_rate": 1.754096385542169e-05,
      "loss": 0.0514,
      "step": 20410
    },
    {
      "epoch": 2.460240963855422,
      "grad_norm": 12.888272285461426,
      "learning_rate": 1.753975903614458e-05,
      "loss": 0.0539,
      "step": 20420
    },
    {
      "epoch": 2.4614457831325303,
      "grad_norm": 23.694766998291016,
      "learning_rate": 1.753855421686747e-05,
      "loss": 0.0662,
      "step": 20430
    },
    {
      "epoch": 2.4626506024096386,
      "grad_norm": 0.45113667845726013,
      "learning_rate": 1.7537349397590363e-05,
      "loss": 0.0302,
      "step": 20440
    },
    {
      "epoch": 2.463855421686747,
      "grad_norm": 1.0141661167144775,
      "learning_rate": 1.7536144578313256e-05,
      "loss": 0.0743,
      "step": 20450
    },
    {
      "epoch": 2.4650602409638553,
      "grad_norm": 6.320250034332275,
      "learning_rate": 1.753493975903615e-05,
      "loss": 0.0637,
      "step": 20460
    },
    {
      "epoch": 2.4662650602409637,
      "grad_norm": 8.874048233032227,
      "learning_rate": 1.7533734939759037e-05,
      "loss": 0.0823,
      "step": 20470
    },
    {
      "epoch": 2.467469879518072,
      "grad_norm": 0.09682928025722504,
      "learning_rate": 1.753253012048193e-05,
      "loss": 0.0599,
      "step": 20480
    },
    {
      "epoch": 2.468674698795181,
      "grad_norm": 8.805607795715332,
      "learning_rate": 1.753132530120482e-05,
      "loss": 0.067,
      "step": 20490
    },
    {
      "epoch": 2.4698795180722892,
      "grad_norm": 0.6853663921356201,
      "learning_rate": 1.753012048192771e-05,
      "loss": 0.0218,
      "step": 20500
    },
    {
      "epoch": 2.4710843373493976,
      "grad_norm": 0.5849428772926331,
      "learning_rate": 1.7528915662650604e-05,
      "loss": 0.1078,
      "step": 20510
    },
    {
      "epoch": 2.472289156626506,
      "grad_norm": 37.67079162597656,
      "learning_rate": 1.7527710843373496e-05,
      "loss": 0.0557,
      "step": 20520
    },
    {
      "epoch": 2.4734939759036143,
      "grad_norm": 1.1685601472854614,
      "learning_rate": 1.752650602409639e-05,
      "loss": 0.0991,
      "step": 20530
    },
    {
      "epoch": 2.474698795180723,
      "grad_norm": 3.5840184688568115,
      "learning_rate": 1.7525301204819278e-05,
      "loss": 0.1273,
      "step": 20540
    },
    {
      "epoch": 2.4759036144578315,
      "grad_norm": 0.4675085246562958,
      "learning_rate": 1.752409638554217e-05,
      "loss": 0.0545,
      "step": 20550
    },
    {
      "epoch": 2.47710843373494,
      "grad_norm": 3.9055070877075195,
      "learning_rate": 1.7522891566265063e-05,
      "loss": 0.0528,
      "step": 20560
    },
    {
      "epoch": 2.478313253012048,
      "grad_norm": 0.1914413869380951,
      "learning_rate": 1.7521686746987955e-05,
      "loss": 0.0434,
      "step": 20570
    },
    {
      "epoch": 2.4795180722891565,
      "grad_norm": 0.6635885834693909,
      "learning_rate": 1.7520481927710844e-05,
      "loss": 0.1022,
      "step": 20580
    },
    {
      "epoch": 2.480722891566265,
      "grad_norm": 0.07942796498537064,
      "learning_rate": 1.7519277108433736e-05,
      "loss": 0.0875,
      "step": 20590
    },
    {
      "epoch": 2.4819277108433733,
      "grad_norm": 1.706091046333313,
      "learning_rate": 1.7518072289156625e-05,
      "loss": 0.0413,
      "step": 20600
    },
    {
      "epoch": 2.483132530120482,
      "grad_norm": 0.3218514323234558,
      "learning_rate": 1.7516867469879518e-05,
      "loss": 0.0729,
      "step": 20610
    },
    {
      "epoch": 2.4843373493975904,
      "grad_norm": 0.11652018129825592,
      "learning_rate": 1.751566265060241e-05,
      "loss": 0.0939,
      "step": 20620
    },
    {
      "epoch": 2.485542168674699,
      "grad_norm": 6.027439117431641,
      "learning_rate": 1.7514457831325303e-05,
      "loss": 0.0872,
      "step": 20630
    },
    {
      "epoch": 2.486746987951807,
      "grad_norm": 3.462108850479126,
      "learning_rate": 1.7513253012048195e-05,
      "loss": 0.0476,
      "step": 20640
    },
    {
      "epoch": 2.4879518072289155,
      "grad_norm": 1.8267613649368286,
      "learning_rate": 1.7512048192771084e-05,
      "loss": 0.0724,
      "step": 20650
    },
    {
      "epoch": 2.4891566265060243,
      "grad_norm": 12.848139762878418,
      "learning_rate": 1.7510843373493977e-05,
      "loss": 0.1243,
      "step": 20660
    },
    {
      "epoch": 2.4903614457831327,
      "grad_norm": 0.44319358468055725,
      "learning_rate": 1.750963855421687e-05,
      "loss": 0.0993,
      "step": 20670
    },
    {
      "epoch": 2.491566265060241,
      "grad_norm": 8.01343822479248,
      "learning_rate": 1.750843373493976e-05,
      "loss": 0.0571,
      "step": 20680
    },
    {
      "epoch": 2.4927710843373494,
      "grad_norm": 0.46542176604270935,
      "learning_rate": 1.7507228915662654e-05,
      "loss": 0.063,
      "step": 20690
    },
    {
      "epoch": 2.4939759036144578,
      "grad_norm": 3.8423404693603516,
      "learning_rate": 1.7506024096385543e-05,
      "loss": 0.1147,
      "step": 20700
    },
    {
      "epoch": 2.495180722891566,
      "grad_norm": 0.23990803956985474,
      "learning_rate": 1.7504819277108436e-05,
      "loss": 0.0328,
      "step": 20710
    },
    {
      "epoch": 2.4963855421686745,
      "grad_norm": 2.4072418212890625,
      "learning_rate": 1.7503614457831325e-05,
      "loss": 0.05,
      "step": 20720
    },
    {
      "epoch": 2.4975903614457833,
      "grad_norm": 3.713050365447998,
      "learning_rate": 1.7502409638554217e-05,
      "loss": 0.0963,
      "step": 20730
    },
    {
      "epoch": 2.4987951807228916,
      "grad_norm": 27.064680099487305,
      "learning_rate": 1.750120481927711e-05,
      "loss": 0.143,
      "step": 20740
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.062701225280762,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.1238,
      "step": 20750
    },
    {
      "epoch": 2.5012048192771084,
      "grad_norm": 0.12298603355884552,
      "learning_rate": 1.7498795180722894e-05,
      "loss": 0.0186,
      "step": 20760
    },
    {
      "epoch": 2.5024096385542167,
      "grad_norm": 4.4466423988342285,
      "learning_rate": 1.7497590361445783e-05,
      "loss": 0.0878,
      "step": 20770
    },
    {
      "epoch": 2.5036144578313255,
      "grad_norm": 0.26161155104637146,
      "learning_rate": 1.7496385542168676e-05,
      "loss": 0.0576,
      "step": 20780
    },
    {
      "epoch": 2.504819277108434,
      "grad_norm": 4.276094913482666,
      "learning_rate": 1.7495180722891568e-05,
      "loss": 0.1163,
      "step": 20790
    },
    {
      "epoch": 2.5060240963855422,
      "grad_norm": 7.970991134643555,
      "learning_rate": 1.749397590361446e-05,
      "loss": 0.1569,
      "step": 20800
    },
    {
      "epoch": 2.5072289156626506,
      "grad_norm": 2.50054669380188,
      "learning_rate": 1.749277108433735e-05,
      "loss": 0.0418,
      "step": 20810
    },
    {
      "epoch": 2.508433734939759,
      "grad_norm": 0.3512216806411743,
      "learning_rate": 1.7491566265060242e-05,
      "loss": 0.0488,
      "step": 20820
    },
    {
      "epoch": 2.5096385542168673,
      "grad_norm": 0.2996939420700073,
      "learning_rate": 1.7490361445783135e-05,
      "loss": 0.076,
      "step": 20830
    },
    {
      "epoch": 2.5108433734939757,
      "grad_norm": 3.5075511932373047,
      "learning_rate": 1.7489156626506027e-05,
      "loss": 0.0731,
      "step": 20840
    },
    {
      "epoch": 2.5120481927710845,
      "grad_norm": 0.09929677098989487,
      "learning_rate": 1.748795180722892e-05,
      "loss": 0.0535,
      "step": 20850
    },
    {
      "epoch": 2.513253012048193,
      "grad_norm": 0.05227244645357132,
      "learning_rate": 1.748674698795181e-05,
      "loss": 0.1597,
      "step": 20860
    },
    {
      "epoch": 2.514457831325301,
      "grad_norm": 0.6523224115371704,
      "learning_rate": 1.74855421686747e-05,
      "loss": 0.1007,
      "step": 20870
    },
    {
      "epoch": 2.5156626506024096,
      "grad_norm": 0.6665319204330444,
      "learning_rate": 1.748433734939759e-05,
      "loss": 0.0614,
      "step": 20880
    },
    {
      "epoch": 2.516867469879518,
      "grad_norm": 2.719688892364502,
      "learning_rate": 1.7483132530120482e-05,
      "loss": 0.0831,
      "step": 20890
    },
    {
      "epoch": 2.5180722891566267,
      "grad_norm": 6.3962931632995605,
      "learning_rate": 1.7481927710843375e-05,
      "loss": 0.139,
      "step": 20900
    },
    {
      "epoch": 2.519277108433735,
      "grad_norm": 4.489538669586182,
      "learning_rate": 1.7480722891566267e-05,
      "loss": 0.1277,
      "step": 20910
    },
    {
      "epoch": 2.5204819277108435,
      "grad_norm": 0.03830520808696747,
      "learning_rate": 1.747951807228916e-05,
      "loss": 0.0469,
      "step": 20920
    },
    {
      "epoch": 2.521686746987952,
      "grad_norm": 0.03022323176264763,
      "learning_rate": 1.747831325301205e-05,
      "loss": 0.087,
      "step": 20930
    },
    {
      "epoch": 2.52289156626506,
      "grad_norm": 0.34484875202178955,
      "learning_rate": 1.747710843373494e-05,
      "loss": 0.0688,
      "step": 20940
    },
    {
      "epoch": 2.5240963855421685,
      "grad_norm": 0.24952703714370728,
      "learning_rate": 1.7475903614457834e-05,
      "loss": 0.1266,
      "step": 20950
    },
    {
      "epoch": 2.525301204819277,
      "grad_norm": 0.04554203897714615,
      "learning_rate": 1.7474698795180726e-05,
      "loss": 0.0551,
      "step": 20960
    },
    {
      "epoch": 2.5265060240963857,
      "grad_norm": 0.07973650097846985,
      "learning_rate": 1.7473493975903615e-05,
      "loss": 0.0585,
      "step": 20970
    },
    {
      "epoch": 2.527710843373494,
      "grad_norm": 0.7765303254127502,
      "learning_rate": 1.7472289156626508e-05,
      "loss": 0.0687,
      "step": 20980
    },
    {
      "epoch": 2.5289156626506024,
      "grad_norm": 2.843907356262207,
      "learning_rate": 1.74710843373494e-05,
      "loss": 0.121,
      "step": 20990
    },
    {
      "epoch": 2.5301204819277108,
      "grad_norm": 4.241520881652832,
      "learning_rate": 1.746987951807229e-05,
      "loss": 0.0572,
      "step": 21000
    },
    {
      "epoch": 2.531325301204819,
      "grad_norm": 1.6650880575180054,
      "learning_rate": 1.746867469879518e-05,
      "loss": 0.0843,
      "step": 21010
    },
    {
      "epoch": 2.532530120481928,
      "grad_norm": 7.299192905426025,
      "learning_rate": 1.7467469879518074e-05,
      "loss": 0.1258,
      "step": 21020
    },
    {
      "epoch": 2.5337349397590363,
      "grad_norm": 0.2053264081478119,
      "learning_rate": 1.7466265060240966e-05,
      "loss": 0.0416,
      "step": 21030
    },
    {
      "epoch": 2.5349397590361447,
      "grad_norm": 0.4148877263069153,
      "learning_rate": 1.7465060240963855e-05,
      "loss": 0.0289,
      "step": 21040
    },
    {
      "epoch": 2.536144578313253,
      "grad_norm": 0.7257764339447021,
      "learning_rate": 1.7463855421686748e-05,
      "loss": 0.0394,
      "step": 21050
    },
    {
      "epoch": 2.5373493975903614,
      "grad_norm": 0.3631211817264557,
      "learning_rate": 1.746265060240964e-05,
      "loss": 0.1579,
      "step": 21060
    },
    {
      "epoch": 2.5385542168674697,
      "grad_norm": 1.0394304990768433,
      "learning_rate": 1.7461445783132533e-05,
      "loss": 0.0264,
      "step": 21070
    },
    {
      "epoch": 2.539759036144578,
      "grad_norm": 0.6633281111717224,
      "learning_rate": 1.7460240963855425e-05,
      "loss": 0.0919,
      "step": 21080
    },
    {
      "epoch": 2.540963855421687,
      "grad_norm": 2.3380937576293945,
      "learning_rate": 1.7459036144578314e-05,
      "loss": 0.0421,
      "step": 21090
    },
    {
      "epoch": 2.5421686746987953,
      "grad_norm": 5.336252689361572,
      "learning_rate": 1.7457831325301207e-05,
      "loss": 0.0941,
      "step": 21100
    },
    {
      "epoch": 2.5433734939759036,
      "grad_norm": 3.3953583240509033,
      "learning_rate": 1.7456626506024096e-05,
      "loss": 0.0793,
      "step": 21110
    },
    {
      "epoch": 2.544578313253012,
      "grad_norm": 1.7645573616027832,
      "learning_rate": 1.7455421686746988e-05,
      "loss": 0.118,
      "step": 21120
    },
    {
      "epoch": 2.5457831325301203,
      "grad_norm": 3.3690121173858643,
      "learning_rate": 1.745421686746988e-05,
      "loss": 0.0712,
      "step": 21130
    },
    {
      "epoch": 2.546987951807229,
      "grad_norm": 2.7640221118927,
      "learning_rate": 1.7453012048192773e-05,
      "loss": 0.0625,
      "step": 21140
    },
    {
      "epoch": 2.5481927710843375,
      "grad_norm": 2.716418981552124,
      "learning_rate": 1.7451807228915665e-05,
      "loss": 0.0947,
      "step": 21150
    },
    {
      "epoch": 2.549397590361446,
      "grad_norm": 8.65353775024414,
      "learning_rate": 1.7450602409638554e-05,
      "loss": 0.1425,
      "step": 21160
    },
    {
      "epoch": 2.5506024096385542,
      "grad_norm": 2.177377939224243,
      "learning_rate": 1.7449397590361447e-05,
      "loss": 0.1092,
      "step": 21170
    },
    {
      "epoch": 2.5518072289156626,
      "grad_norm": 1.3537389039993286,
      "learning_rate": 1.744819277108434e-05,
      "loss": 0.0765,
      "step": 21180
    },
    {
      "epoch": 2.553012048192771,
      "grad_norm": 4.153270244598389,
      "learning_rate": 1.7446987951807232e-05,
      "loss": 0.0765,
      "step": 21190
    },
    {
      "epoch": 2.5542168674698793,
      "grad_norm": 0.31948840618133545,
      "learning_rate": 1.7445783132530124e-05,
      "loss": 0.0599,
      "step": 21200
    },
    {
      "epoch": 2.555421686746988,
      "grad_norm": 17.33539581298828,
      "learning_rate": 1.7444578313253013e-05,
      "loss": 0.0433,
      "step": 21210
    },
    {
      "epoch": 2.5566265060240965,
      "grad_norm": 1.9332064390182495,
      "learning_rate": 1.7443373493975906e-05,
      "loss": 0.0605,
      "step": 21220
    },
    {
      "epoch": 2.557831325301205,
      "grad_norm": 8.633004188537598,
      "learning_rate": 1.7442168674698795e-05,
      "loss": 0.017,
      "step": 21230
    },
    {
      "epoch": 2.559036144578313,
      "grad_norm": 4.897599220275879,
      "learning_rate": 1.7440963855421687e-05,
      "loss": 0.0958,
      "step": 21240
    },
    {
      "epoch": 2.5602409638554215,
      "grad_norm": 0.1304256021976471,
      "learning_rate": 1.743975903614458e-05,
      "loss": 0.1354,
      "step": 21250
    },
    {
      "epoch": 2.5614457831325304,
      "grad_norm": 1.2750080823898315,
      "learning_rate": 1.7438554216867472e-05,
      "loss": 0.0739,
      "step": 21260
    },
    {
      "epoch": 2.5626506024096387,
      "grad_norm": 5.265219688415527,
      "learning_rate": 1.743734939759036e-05,
      "loss": 0.0669,
      "step": 21270
    },
    {
      "epoch": 2.563855421686747,
      "grad_norm": 0.27961382269859314,
      "learning_rate": 1.7436144578313253e-05,
      "loss": 0.0824,
      "step": 21280
    },
    {
      "epoch": 2.5650602409638554,
      "grad_norm": 1.6857672929763794,
      "learning_rate": 1.7434939759036146e-05,
      "loss": 0.0782,
      "step": 21290
    },
    {
      "epoch": 2.566265060240964,
      "grad_norm": 30.810644149780273,
      "learning_rate": 1.743373493975904e-05,
      "loss": 0.0841,
      "step": 21300
    },
    {
      "epoch": 2.567469879518072,
      "grad_norm": 0.22588682174682617,
      "learning_rate": 1.743253012048193e-05,
      "loss": 0.0958,
      "step": 21310
    },
    {
      "epoch": 2.5686746987951805,
      "grad_norm": 10.578898429870605,
      "learning_rate": 1.743132530120482e-05,
      "loss": 0.0829,
      "step": 21320
    },
    {
      "epoch": 2.5698795180722893,
      "grad_norm": 0.31818312406539917,
      "learning_rate": 1.7430120481927712e-05,
      "loss": 0.0404,
      "step": 21330
    },
    {
      "epoch": 2.5710843373493977,
      "grad_norm": 0.10903244465589523,
      "learning_rate": 1.74289156626506e-05,
      "loss": 0.1106,
      "step": 21340
    },
    {
      "epoch": 2.572289156626506,
      "grad_norm": 0.5517018437385559,
      "learning_rate": 1.7427710843373494e-05,
      "loss": 0.1009,
      "step": 21350
    },
    {
      "epoch": 2.5734939759036144,
      "grad_norm": 0.08813679963350296,
      "learning_rate": 1.742650602409639e-05,
      "loss": 0.0657,
      "step": 21360
    },
    {
      "epoch": 2.5746987951807228,
      "grad_norm": 0.21173302829265594,
      "learning_rate": 1.742530120481928e-05,
      "loss": 0.031,
      "step": 21370
    },
    {
      "epoch": 2.5759036144578316,
      "grad_norm": 12.972511291503906,
      "learning_rate": 1.742409638554217e-05,
      "loss": 0.0758,
      "step": 21380
    },
    {
      "epoch": 2.57710843373494,
      "grad_norm": 1.5908676385879517,
      "learning_rate": 1.742289156626506e-05,
      "loss": 0.0771,
      "step": 21390
    },
    {
      "epoch": 2.5783132530120483,
      "grad_norm": 20.5214786529541,
      "learning_rate": 1.7421686746987953e-05,
      "loss": 0.0606,
      "step": 21400
    },
    {
      "epoch": 2.5795180722891566,
      "grad_norm": 1.5544911623001099,
      "learning_rate": 1.7420481927710845e-05,
      "loss": 0.0783,
      "step": 21410
    },
    {
      "epoch": 2.580722891566265,
      "grad_norm": 0.7381583452224731,
      "learning_rate": 1.7419277108433737e-05,
      "loss": 0.0451,
      "step": 21420
    },
    {
      "epoch": 2.5819277108433734,
      "grad_norm": 0.17105945944786072,
      "learning_rate": 1.741807228915663e-05,
      "loss": 0.1007,
      "step": 21430
    },
    {
      "epoch": 2.5831325301204817,
      "grad_norm": 0.14641399681568146,
      "learning_rate": 1.741686746987952e-05,
      "loss": 0.1118,
      "step": 21440
    },
    {
      "epoch": 2.5843373493975905,
      "grad_norm": 8.138688087463379,
      "learning_rate": 1.741566265060241e-05,
      "loss": 0.0656,
      "step": 21450
    },
    {
      "epoch": 2.585542168674699,
      "grad_norm": 13.386530876159668,
      "learning_rate": 1.7414457831325304e-05,
      "loss": 0.0968,
      "step": 21460
    },
    {
      "epoch": 2.5867469879518072,
      "grad_norm": 5.802254676818848,
      "learning_rate": 1.7413253012048196e-05,
      "loss": 0.0732,
      "step": 21470
    },
    {
      "epoch": 2.5879518072289156,
      "grad_norm": 0.7579696178436279,
      "learning_rate": 1.7412048192771085e-05,
      "loss": 0.0804,
      "step": 21480
    },
    {
      "epoch": 2.589156626506024,
      "grad_norm": 27.540624618530273,
      "learning_rate": 1.7410843373493978e-05,
      "loss": 0.0392,
      "step": 21490
    },
    {
      "epoch": 2.5903614457831328,
      "grad_norm": 1.7386138439178467,
      "learning_rate": 1.740963855421687e-05,
      "loss": 0.14,
      "step": 21500
    },
    {
      "epoch": 2.591566265060241,
      "grad_norm": 0.1810954064130783,
      "learning_rate": 1.740843373493976e-05,
      "loss": 0.0687,
      "step": 21510
    },
    {
      "epoch": 2.5927710843373495,
      "grad_norm": 3.5796773433685303,
      "learning_rate": 1.740722891566265e-05,
      "loss": 0.0712,
      "step": 21520
    },
    {
      "epoch": 2.593975903614458,
      "grad_norm": 6.317977428436279,
      "learning_rate": 1.7406024096385544e-05,
      "loss": 0.058,
      "step": 21530
    },
    {
      "epoch": 2.595180722891566,
      "grad_norm": 0.1587931215763092,
      "learning_rate": 1.7404819277108436e-05,
      "loss": 0.0933,
      "step": 21540
    },
    {
      "epoch": 2.5963855421686746,
      "grad_norm": 9.210755348205566,
      "learning_rate": 1.7403614457831326e-05,
      "loss": 0.0648,
      "step": 21550
    },
    {
      "epoch": 2.597590361445783,
      "grad_norm": 0.4204114079475403,
      "learning_rate": 1.7402409638554218e-05,
      "loss": 0.0807,
      "step": 21560
    },
    {
      "epoch": 2.5987951807228917,
      "grad_norm": 4.741505146026611,
      "learning_rate": 1.740120481927711e-05,
      "loss": 0.0354,
      "step": 21570
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.5177218914031982,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 0.04,
      "step": 21580
    },
    {
      "epoch": 2.6012048192771084,
      "grad_norm": 0.1949155330657959,
      "learning_rate": 1.7398795180722895e-05,
      "loss": 0.0998,
      "step": 21590
    },
    {
      "epoch": 2.602409638554217,
      "grad_norm": 0.1718238890171051,
      "learning_rate": 1.7397590361445784e-05,
      "loss": 0.0888,
      "step": 21600
    },
    {
      "epoch": 2.603614457831325,
      "grad_norm": 0.23739704489707947,
      "learning_rate": 1.7396385542168677e-05,
      "loss": 0.0452,
      "step": 21610
    },
    {
      "epoch": 2.604819277108434,
      "grad_norm": 0.47734373807907104,
      "learning_rate": 1.7395180722891566e-05,
      "loss": 0.0363,
      "step": 21620
    },
    {
      "epoch": 2.6060240963855423,
      "grad_norm": 4.261348247528076,
      "learning_rate": 1.7393975903614458e-05,
      "loss": 0.1267,
      "step": 21630
    },
    {
      "epoch": 2.6072289156626507,
      "grad_norm": 1.0228458642959595,
      "learning_rate": 1.739277108433735e-05,
      "loss": 0.0185,
      "step": 21640
    },
    {
      "epoch": 2.608433734939759,
      "grad_norm": 10.069099426269531,
      "learning_rate": 1.7391566265060243e-05,
      "loss": 0.0907,
      "step": 21650
    },
    {
      "epoch": 2.6096385542168674,
      "grad_norm": 0.3940807580947876,
      "learning_rate": 1.7390361445783136e-05,
      "loss": 0.1117,
      "step": 21660
    },
    {
      "epoch": 2.6108433734939758,
      "grad_norm": 2.4025940895080566,
      "learning_rate": 1.7389156626506025e-05,
      "loss": 0.1142,
      "step": 21670
    },
    {
      "epoch": 2.612048192771084,
      "grad_norm": 0.4857499599456787,
      "learning_rate": 1.7387951807228917e-05,
      "loss": 0.0552,
      "step": 21680
    },
    {
      "epoch": 2.613253012048193,
      "grad_norm": 4.05600643157959,
      "learning_rate": 1.738674698795181e-05,
      "loss": 0.1426,
      "step": 21690
    },
    {
      "epoch": 2.6144578313253013,
      "grad_norm": 1.016554355621338,
      "learning_rate": 1.7385542168674702e-05,
      "loss": 0.0473,
      "step": 21700
    },
    {
      "epoch": 2.6156626506024097,
      "grad_norm": 12.917986869812012,
      "learning_rate": 1.738433734939759e-05,
      "loss": 0.0624,
      "step": 21710
    },
    {
      "epoch": 2.616867469879518,
      "grad_norm": 0.27424558997154236,
      "learning_rate": 1.7383132530120483e-05,
      "loss": 0.0685,
      "step": 21720
    },
    {
      "epoch": 2.6180722891566264,
      "grad_norm": 3.6386187076568604,
      "learning_rate": 1.7381927710843376e-05,
      "loss": 0.0757,
      "step": 21730
    },
    {
      "epoch": 2.619277108433735,
      "grad_norm": 2.6693990230560303,
      "learning_rate": 1.7380722891566265e-05,
      "loss": 0.13,
      "step": 21740
    },
    {
      "epoch": 2.6204819277108435,
      "grad_norm": 0.047369685024023056,
      "learning_rate": 1.7379518072289157e-05,
      "loss": 0.0574,
      "step": 21750
    },
    {
      "epoch": 2.621686746987952,
      "grad_norm": 0.19383350014686584,
      "learning_rate": 1.737831325301205e-05,
      "loss": 0.0422,
      "step": 21760
    },
    {
      "epoch": 2.6228915662650603,
      "grad_norm": 1.4898382425308228,
      "learning_rate": 1.7377108433734942e-05,
      "loss": 0.0282,
      "step": 21770
    },
    {
      "epoch": 2.6240963855421686,
      "grad_norm": 5.249551773071289,
      "learning_rate": 1.737590361445783e-05,
      "loss": 0.1234,
      "step": 21780
    },
    {
      "epoch": 2.625301204819277,
      "grad_norm": 1.9023579359054565,
      "learning_rate": 1.7374698795180724e-05,
      "loss": 0.0823,
      "step": 21790
    },
    {
      "epoch": 2.6265060240963853,
      "grad_norm": 7.366772174835205,
      "learning_rate": 1.7373493975903616e-05,
      "loss": 0.0721,
      "step": 21800
    },
    {
      "epoch": 2.627710843373494,
      "grad_norm": 0.44577813148498535,
      "learning_rate": 1.737228915662651e-05,
      "loss": 0.0889,
      "step": 21810
    },
    {
      "epoch": 2.6289156626506025,
      "grad_norm": 4.835604190826416,
      "learning_rate": 1.73710843373494e-05,
      "loss": 0.1055,
      "step": 21820
    },
    {
      "epoch": 2.630120481927711,
      "grad_norm": 0.1506754606962204,
      "learning_rate": 1.736987951807229e-05,
      "loss": 0.0223,
      "step": 21830
    },
    {
      "epoch": 2.6313253012048192,
      "grad_norm": 1.2575701475143433,
      "learning_rate": 1.7368674698795182e-05,
      "loss": 0.0864,
      "step": 21840
    },
    {
      "epoch": 2.6325301204819276,
      "grad_norm": 5.445217132568359,
      "learning_rate": 1.736746987951807e-05,
      "loss": 0.1132,
      "step": 21850
    },
    {
      "epoch": 2.6337349397590364,
      "grad_norm": 2.696319580078125,
      "learning_rate": 1.7366265060240964e-05,
      "loss": 0.0729,
      "step": 21860
    },
    {
      "epoch": 2.6349397590361443,
      "grad_norm": 0.4004194736480713,
      "learning_rate": 1.7365060240963856e-05,
      "loss": 0.0628,
      "step": 21870
    },
    {
      "epoch": 2.636144578313253,
      "grad_norm": 5.166575908660889,
      "learning_rate": 1.736385542168675e-05,
      "loss": 0.0739,
      "step": 21880
    },
    {
      "epoch": 2.6373493975903615,
      "grad_norm": 1.8413121700286865,
      "learning_rate": 1.736265060240964e-05,
      "loss": 0.1007,
      "step": 21890
    },
    {
      "epoch": 2.63855421686747,
      "grad_norm": 0.8596748113632202,
      "learning_rate": 1.736144578313253e-05,
      "loss": 0.1004,
      "step": 21900
    },
    {
      "epoch": 2.639759036144578,
      "grad_norm": 5.96461820602417,
      "learning_rate": 1.7360240963855423e-05,
      "loss": 0.1067,
      "step": 21910
    },
    {
      "epoch": 2.6409638554216865,
      "grad_norm": 14.514246940612793,
      "learning_rate": 1.7359036144578315e-05,
      "loss": 0.1464,
      "step": 21920
    },
    {
      "epoch": 2.6421686746987953,
      "grad_norm": 1.6898066997528076,
      "learning_rate": 1.7357831325301208e-05,
      "loss": 0.0738,
      "step": 21930
    },
    {
      "epoch": 2.6433734939759037,
      "grad_norm": 4.53476619720459,
      "learning_rate": 1.7356626506024097e-05,
      "loss": 0.0952,
      "step": 21940
    },
    {
      "epoch": 2.644578313253012,
      "grad_norm": 6.581787109375,
      "learning_rate": 1.735542168674699e-05,
      "loss": 0.1003,
      "step": 21950
    },
    {
      "epoch": 2.6457831325301204,
      "grad_norm": 2.2210533618927,
      "learning_rate": 1.735421686746988e-05,
      "loss": 0.0834,
      "step": 21960
    },
    {
      "epoch": 2.646987951807229,
      "grad_norm": 8.625442504882812,
      "learning_rate": 1.735301204819277e-05,
      "loss": 0.0513,
      "step": 21970
    },
    {
      "epoch": 2.6481927710843376,
      "grad_norm": 0.27554336190223694,
      "learning_rate": 1.7351807228915666e-05,
      "loss": 0.1001,
      "step": 21980
    },
    {
      "epoch": 2.6493975903614455,
      "grad_norm": 2.7271766662597656,
      "learning_rate": 1.7350602409638555e-05,
      "loss": 0.0569,
      "step": 21990
    },
    {
      "epoch": 2.6506024096385543,
      "grad_norm": 4.131907939910889,
      "learning_rate": 1.7349397590361448e-05,
      "loss": 0.1487,
      "step": 22000
    },
    {
      "epoch": 2.6518072289156627,
      "grad_norm": 0.3188936412334442,
      "learning_rate": 1.7348192771084337e-05,
      "loss": 0.0725,
      "step": 22010
    },
    {
      "epoch": 2.653012048192771,
      "grad_norm": 3.3088250160217285,
      "learning_rate": 1.734698795180723e-05,
      "loss": 0.1014,
      "step": 22020
    },
    {
      "epoch": 2.6542168674698794,
      "grad_norm": 2.2766618728637695,
      "learning_rate": 1.7345783132530122e-05,
      "loss": 0.0771,
      "step": 22030
    },
    {
      "epoch": 2.6554216867469878,
      "grad_norm": 1.3178095817565918,
      "learning_rate": 1.7344578313253014e-05,
      "loss": 0.0622,
      "step": 22040
    },
    {
      "epoch": 2.6566265060240966,
      "grad_norm": 3.715498924255371,
      "learning_rate": 1.7343373493975907e-05,
      "loss": 0.0485,
      "step": 22050
    },
    {
      "epoch": 2.657831325301205,
      "grad_norm": 0.5074520707130432,
      "learning_rate": 1.7342168674698796e-05,
      "loss": 0.0619,
      "step": 22060
    },
    {
      "epoch": 2.6590361445783133,
      "grad_norm": 4.127864360809326,
      "learning_rate": 1.7340963855421688e-05,
      "loss": 0.0482,
      "step": 22070
    },
    {
      "epoch": 2.6602409638554216,
      "grad_norm": 0.2597266435623169,
      "learning_rate": 1.733975903614458e-05,
      "loss": 0.0435,
      "step": 22080
    },
    {
      "epoch": 2.66144578313253,
      "grad_norm": 0.23278066515922546,
      "learning_rate": 1.7338554216867473e-05,
      "loss": 0.044,
      "step": 22090
    },
    {
      "epoch": 2.662650602409639,
      "grad_norm": 11.670223236083984,
      "learning_rate": 1.7337349397590365e-05,
      "loss": 0.0612,
      "step": 22100
    },
    {
      "epoch": 2.6638554216867467,
      "grad_norm": 0.06469285488128662,
      "learning_rate": 1.7336144578313254e-05,
      "loss": 0.1319,
      "step": 22110
    },
    {
      "epoch": 2.6650602409638555,
      "grad_norm": 11.453166007995605,
      "learning_rate": 1.7334939759036147e-05,
      "loss": 0.1421,
      "step": 22120
    },
    {
      "epoch": 2.666265060240964,
      "grad_norm": 0.1529865860939026,
      "learning_rate": 1.7333734939759036e-05,
      "loss": 0.1247,
      "step": 22130
    },
    {
      "epoch": 2.6674698795180722,
      "grad_norm": 7.102628707885742,
      "learning_rate": 1.733253012048193e-05,
      "loss": 0.0808,
      "step": 22140
    },
    {
      "epoch": 2.6686746987951806,
      "grad_norm": 5.645833969116211,
      "learning_rate": 1.733132530120482e-05,
      "loss": 0.1454,
      "step": 22150
    },
    {
      "epoch": 2.669879518072289,
      "grad_norm": 6.725122928619385,
      "learning_rate": 1.7330120481927713e-05,
      "loss": 0.1579,
      "step": 22160
    },
    {
      "epoch": 2.6710843373493978,
      "grad_norm": 6.360311985015869,
      "learning_rate": 1.7328915662650602e-05,
      "loss": 0.0553,
      "step": 22170
    },
    {
      "epoch": 2.672289156626506,
      "grad_norm": 19.325763702392578,
      "learning_rate": 1.7327710843373495e-05,
      "loss": 0.0935,
      "step": 22180
    },
    {
      "epoch": 2.6734939759036145,
      "grad_norm": 6.83111572265625,
      "learning_rate": 1.7326506024096387e-05,
      "loss": 0.097,
      "step": 22190
    },
    {
      "epoch": 2.674698795180723,
      "grad_norm": 0.20132607221603394,
      "learning_rate": 1.732530120481928e-05,
      "loss": 0.1169,
      "step": 22200
    },
    {
      "epoch": 2.675903614457831,
      "grad_norm": 9.25717544555664,
      "learning_rate": 1.7324096385542172e-05,
      "loss": 0.0795,
      "step": 22210
    },
    {
      "epoch": 2.67710843373494,
      "grad_norm": 2.493659257888794,
      "learning_rate": 1.732289156626506e-05,
      "loss": 0.0789,
      "step": 22220
    },
    {
      "epoch": 2.678313253012048,
      "grad_norm": 0.46469300985336304,
      "learning_rate": 1.7321686746987953e-05,
      "loss": 0.0814,
      "step": 22230
    },
    {
      "epoch": 2.6795180722891567,
      "grad_norm": 0.22680379450321198,
      "learning_rate": 1.7320481927710843e-05,
      "loss": 0.0677,
      "step": 22240
    },
    {
      "epoch": 2.680722891566265,
      "grad_norm": 3.147857189178467,
      "learning_rate": 1.7319277108433735e-05,
      "loss": 0.0482,
      "step": 22250
    },
    {
      "epoch": 2.6819277108433734,
      "grad_norm": 10.501409530639648,
      "learning_rate": 1.7318072289156627e-05,
      "loss": 0.1147,
      "step": 22260
    },
    {
      "epoch": 2.683132530120482,
      "grad_norm": 1.8000996112823486,
      "learning_rate": 1.731686746987952e-05,
      "loss": 0.0788,
      "step": 22270
    },
    {
      "epoch": 2.68433734939759,
      "grad_norm": 0.119029201567173,
      "learning_rate": 1.7315662650602412e-05,
      "loss": 0.0406,
      "step": 22280
    },
    {
      "epoch": 2.685542168674699,
      "grad_norm": 0.05141002684831619,
      "learning_rate": 1.73144578313253e-05,
      "loss": 0.0763,
      "step": 22290
    },
    {
      "epoch": 2.6867469879518073,
      "grad_norm": 5.326103687286377,
      "learning_rate": 1.7313253012048194e-05,
      "loss": 0.1294,
      "step": 22300
    },
    {
      "epoch": 2.6879518072289157,
      "grad_norm": 0.4273416996002197,
      "learning_rate": 1.7312048192771086e-05,
      "loss": 0.1086,
      "step": 22310
    },
    {
      "epoch": 2.689156626506024,
      "grad_norm": 0.318403959274292,
      "learning_rate": 1.731084337349398e-05,
      "loss": 0.0241,
      "step": 22320
    },
    {
      "epoch": 2.6903614457831324,
      "grad_norm": 13.994393348693848,
      "learning_rate": 1.730963855421687e-05,
      "loss": 0.0804,
      "step": 22330
    },
    {
      "epoch": 2.691566265060241,
      "grad_norm": 0.9059938788414001,
      "learning_rate": 1.730843373493976e-05,
      "loss": 0.0504,
      "step": 22340
    },
    {
      "epoch": 2.692771084337349,
      "grad_norm": 0.13761858642101288,
      "learning_rate": 1.7307228915662653e-05,
      "loss": 0.0607,
      "step": 22350
    },
    {
      "epoch": 2.693975903614458,
      "grad_norm": 3.1039648056030273,
      "learning_rate": 1.730602409638554e-05,
      "loss": 0.0724,
      "step": 22360
    },
    {
      "epoch": 2.6951807228915663,
      "grad_norm": 1.147085189819336,
      "learning_rate": 1.7304819277108434e-05,
      "loss": 0.1066,
      "step": 22370
    },
    {
      "epoch": 2.6963855421686747,
      "grad_norm": 0.026478854939341545,
      "learning_rate": 1.7303614457831326e-05,
      "loss": 0.099,
      "step": 22380
    },
    {
      "epoch": 2.697590361445783,
      "grad_norm": 11.023249626159668,
      "learning_rate": 1.730240963855422e-05,
      "loss": 0.08,
      "step": 22390
    },
    {
      "epoch": 2.6987951807228914,
      "grad_norm": 12.649519920349121,
      "learning_rate": 1.730120481927711e-05,
      "loss": 0.0434,
      "step": 22400
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.4352509081363678,
      "learning_rate": 1.73e-05,
      "loss": 0.0333,
      "step": 22410
    },
    {
      "epoch": 2.7012048192771085,
      "grad_norm": 3.8473470211029053,
      "learning_rate": 1.7298795180722893e-05,
      "loss": 0.1593,
      "step": 22420
    },
    {
      "epoch": 2.702409638554217,
      "grad_norm": 5.2806901931762695,
      "learning_rate": 1.7297590361445785e-05,
      "loss": 0.0928,
      "step": 22430
    },
    {
      "epoch": 2.7036144578313253,
      "grad_norm": 2.3110175132751465,
      "learning_rate": 1.7296385542168678e-05,
      "loss": 0.0566,
      "step": 22440
    },
    {
      "epoch": 2.7048192771084336,
      "grad_norm": 8.553186416625977,
      "learning_rate": 1.7295180722891567e-05,
      "loss": 0.1089,
      "step": 22450
    },
    {
      "epoch": 2.7060240963855424,
      "grad_norm": 0.199051171541214,
      "learning_rate": 1.729397590361446e-05,
      "loss": 0.0508,
      "step": 22460
    },
    {
      "epoch": 2.7072289156626503,
      "grad_norm": 8.007877349853516,
      "learning_rate": 1.7292771084337348e-05,
      "loss": 0.0741,
      "step": 22470
    },
    {
      "epoch": 2.708433734939759,
      "grad_norm": 1.3400921821594238,
      "learning_rate": 1.729156626506024e-05,
      "loss": 0.0781,
      "step": 22480
    },
    {
      "epoch": 2.7096385542168675,
      "grad_norm": 1.8071955442428589,
      "learning_rate": 1.7290361445783136e-05,
      "loss": 0.0239,
      "step": 22490
    },
    {
      "epoch": 2.710843373493976,
      "grad_norm": 3.893415927886963,
      "learning_rate": 1.7289156626506026e-05,
      "loss": 0.1299,
      "step": 22500
    },
    {
      "epoch": 2.712048192771084,
      "grad_norm": 1.9930698871612549,
      "learning_rate": 1.7287951807228918e-05,
      "loss": 0.093,
      "step": 22510
    },
    {
      "epoch": 2.7132530120481926,
      "grad_norm": 1.5258774757385254,
      "learning_rate": 1.7286746987951807e-05,
      "loss": 0.1103,
      "step": 22520
    },
    {
      "epoch": 2.7144578313253014,
      "grad_norm": 5.882627487182617,
      "learning_rate": 1.72855421686747e-05,
      "loss": 0.0981,
      "step": 22530
    },
    {
      "epoch": 2.7156626506024097,
      "grad_norm": 0.2527659833431244,
      "learning_rate": 1.7284337349397592e-05,
      "loss": 0.0597,
      "step": 22540
    },
    {
      "epoch": 2.716867469879518,
      "grad_norm": 2.8588707447052,
      "learning_rate": 1.7283132530120484e-05,
      "loss": 0.0775,
      "step": 22550
    },
    {
      "epoch": 2.7180722891566265,
      "grad_norm": 2.4635024070739746,
      "learning_rate": 1.7281927710843377e-05,
      "loss": 0.1056,
      "step": 22560
    },
    {
      "epoch": 2.719277108433735,
      "grad_norm": 0.7267590165138245,
      "learning_rate": 1.7280722891566266e-05,
      "loss": 0.0501,
      "step": 22570
    },
    {
      "epoch": 2.7204819277108436,
      "grad_norm": 1.5527571439743042,
      "learning_rate": 1.7279518072289158e-05,
      "loss": 0.0617,
      "step": 22580
    },
    {
      "epoch": 2.7216867469879515,
      "grad_norm": 4.5123701095581055,
      "learning_rate": 1.727831325301205e-05,
      "loss": 0.0942,
      "step": 22590
    },
    {
      "epoch": 2.7228915662650603,
      "grad_norm": 4.127221584320068,
      "learning_rate": 1.7277108433734943e-05,
      "loss": 0.0942,
      "step": 22600
    },
    {
      "epoch": 2.7240963855421687,
      "grad_norm": 0.7874809503555298,
      "learning_rate": 1.7275903614457832e-05,
      "loss": 0.0368,
      "step": 22610
    },
    {
      "epoch": 2.725301204819277,
      "grad_norm": 0.554940402507782,
      "learning_rate": 1.7274698795180725e-05,
      "loss": 0.0486,
      "step": 22620
    },
    {
      "epoch": 2.7265060240963854,
      "grad_norm": 18.849349975585938,
      "learning_rate": 1.7273493975903617e-05,
      "loss": 0.1918,
      "step": 22630
    },
    {
      "epoch": 2.727710843373494,
      "grad_norm": 3.4147260189056396,
      "learning_rate": 1.7272289156626506e-05,
      "loss": 0.0653,
      "step": 22640
    },
    {
      "epoch": 2.7289156626506026,
      "grad_norm": 1.1805059909820557,
      "learning_rate": 1.72710843373494e-05,
      "loss": 0.0182,
      "step": 22650
    },
    {
      "epoch": 2.730120481927711,
      "grad_norm": 5.529083251953125,
      "learning_rate": 1.726987951807229e-05,
      "loss": 0.0997,
      "step": 22660
    },
    {
      "epoch": 2.7313253012048193,
      "grad_norm": 1.997890830039978,
      "learning_rate": 1.7268674698795183e-05,
      "loss": 0.0412,
      "step": 22670
    },
    {
      "epoch": 2.7325301204819277,
      "grad_norm": 9.143847465515137,
      "learning_rate": 1.7267469879518072e-05,
      "loss": 0.1244,
      "step": 22680
    },
    {
      "epoch": 2.733734939759036,
      "grad_norm": 10.36669921875,
      "learning_rate": 1.7266265060240965e-05,
      "loss": 0.1004,
      "step": 22690
    },
    {
      "epoch": 2.734939759036145,
      "grad_norm": 1.2314473390579224,
      "learning_rate": 1.7265060240963857e-05,
      "loss": 0.0467,
      "step": 22700
    },
    {
      "epoch": 2.7361445783132528,
      "grad_norm": 0.39103490114212036,
      "learning_rate": 1.726385542168675e-05,
      "loss": 0.1112,
      "step": 22710
    },
    {
      "epoch": 2.7373493975903616,
      "grad_norm": 0.29529327154159546,
      "learning_rate": 1.7262650602409642e-05,
      "loss": 0.094,
      "step": 22720
    },
    {
      "epoch": 2.73855421686747,
      "grad_norm": 0.9960039258003235,
      "learning_rate": 1.726144578313253e-05,
      "loss": 0.0978,
      "step": 22730
    },
    {
      "epoch": 2.7397590361445783,
      "grad_norm": 1.87412691116333,
      "learning_rate": 1.7260240963855424e-05,
      "loss": 0.0546,
      "step": 22740
    },
    {
      "epoch": 2.7409638554216866,
      "grad_norm": 3.489497423171997,
      "learning_rate": 1.7259036144578313e-05,
      "loss": 0.0597,
      "step": 22750
    },
    {
      "epoch": 2.742168674698795,
      "grad_norm": 0.33978721499443054,
      "learning_rate": 1.7257831325301205e-05,
      "loss": 0.0572,
      "step": 22760
    },
    {
      "epoch": 2.743373493975904,
      "grad_norm": 4.494582176208496,
      "learning_rate": 1.7256626506024098e-05,
      "loss": 0.1242,
      "step": 22770
    },
    {
      "epoch": 2.744578313253012,
      "grad_norm": 4.498171329498291,
      "learning_rate": 1.725542168674699e-05,
      "loss": 0.0681,
      "step": 22780
    },
    {
      "epoch": 2.7457831325301205,
      "grad_norm": 0.10911992192268372,
      "learning_rate": 1.7254216867469882e-05,
      "loss": 0.0606,
      "step": 22790
    },
    {
      "epoch": 2.746987951807229,
      "grad_norm": 15.055853843688965,
      "learning_rate": 1.725301204819277e-05,
      "loss": 0.1113,
      "step": 22800
    },
    {
      "epoch": 2.7481927710843372,
      "grad_norm": 4.824296951293945,
      "learning_rate": 1.7251807228915664e-05,
      "loss": 0.0754,
      "step": 22810
    },
    {
      "epoch": 2.749397590361446,
      "grad_norm": 1.4805303812026978,
      "learning_rate": 1.7250602409638556e-05,
      "loss": 0.0639,
      "step": 22820
    },
    {
      "epoch": 2.750602409638554,
      "grad_norm": 0.2999277412891388,
      "learning_rate": 1.724939759036145e-05,
      "loss": 0.1472,
      "step": 22830
    },
    {
      "epoch": 2.7518072289156628,
      "grad_norm": 2.6237707138061523,
      "learning_rate": 1.7248192771084338e-05,
      "loss": 0.1434,
      "step": 22840
    },
    {
      "epoch": 2.753012048192771,
      "grad_norm": 0.30268213152885437,
      "learning_rate": 1.724698795180723e-05,
      "loss": 0.0317,
      "step": 22850
    },
    {
      "epoch": 2.7542168674698795,
      "grad_norm": 0.09048369526863098,
      "learning_rate": 1.7245783132530123e-05,
      "loss": 0.0468,
      "step": 22860
    },
    {
      "epoch": 2.755421686746988,
      "grad_norm": 0.12530885636806488,
      "learning_rate": 1.7244578313253012e-05,
      "loss": 0.0685,
      "step": 22870
    },
    {
      "epoch": 2.756626506024096,
      "grad_norm": 11.61197566986084,
      "learning_rate": 1.7243373493975904e-05,
      "loss": 0.151,
      "step": 22880
    },
    {
      "epoch": 2.757831325301205,
      "grad_norm": 0.41759055852890015,
      "learning_rate": 1.7242168674698797e-05,
      "loss": 0.0605,
      "step": 22890
    },
    {
      "epoch": 2.7590361445783134,
      "grad_norm": 9.64426040649414,
      "learning_rate": 1.724096385542169e-05,
      "loss": 0.0724,
      "step": 22900
    },
    {
      "epoch": 2.7602409638554217,
      "grad_norm": 2.3304388523101807,
      "learning_rate": 1.7239759036144578e-05,
      "loss": 0.0692,
      "step": 22910
    },
    {
      "epoch": 2.76144578313253,
      "grad_norm": 0.3106367886066437,
      "learning_rate": 1.723855421686747e-05,
      "loss": 0.1258,
      "step": 22920
    },
    {
      "epoch": 2.7626506024096384,
      "grad_norm": 18.720308303833008,
      "learning_rate": 1.7237349397590363e-05,
      "loss": 0.0574,
      "step": 22930
    },
    {
      "epoch": 2.7638554216867472,
      "grad_norm": 4.7580790519714355,
      "learning_rate": 1.7236144578313255e-05,
      "loss": 0.0434,
      "step": 22940
    },
    {
      "epoch": 2.765060240963855,
      "grad_norm": 2.0658152103424072,
      "learning_rate": 1.7234939759036148e-05,
      "loss": 0.0718,
      "step": 22950
    },
    {
      "epoch": 2.766265060240964,
      "grad_norm": 6.064984321594238,
      "learning_rate": 1.7233734939759037e-05,
      "loss": 0.0826,
      "step": 22960
    },
    {
      "epoch": 2.7674698795180723,
      "grad_norm": 0.4298236668109894,
      "learning_rate": 1.723253012048193e-05,
      "loss": 0.0539,
      "step": 22970
    },
    {
      "epoch": 2.7686746987951807,
      "grad_norm": 6.071131706237793,
      "learning_rate": 1.723132530120482e-05,
      "loss": 0.0854,
      "step": 22980
    },
    {
      "epoch": 2.769879518072289,
      "grad_norm": 1.3670847415924072,
      "learning_rate": 1.723012048192771e-05,
      "loss": 0.0345,
      "step": 22990
    },
    {
      "epoch": 2.7710843373493974,
      "grad_norm": 3.6647753715515137,
      "learning_rate": 1.7228915662650603e-05,
      "loss": 0.0764,
      "step": 23000
    },
    {
      "epoch": 2.772289156626506,
      "grad_norm": 2.729356527328491,
      "learning_rate": 1.7227710843373496e-05,
      "loss": 0.1021,
      "step": 23010
    },
    {
      "epoch": 2.7734939759036146,
      "grad_norm": 0.5438537001609802,
      "learning_rate": 1.7226506024096388e-05,
      "loss": 0.0511,
      "step": 23020
    },
    {
      "epoch": 2.774698795180723,
      "grad_norm": 8.248576164245605,
      "learning_rate": 1.7225301204819277e-05,
      "loss": 0.0773,
      "step": 23030
    },
    {
      "epoch": 2.7759036144578313,
      "grad_norm": 0.12484376132488251,
      "learning_rate": 1.722409638554217e-05,
      "loss": 0.1201,
      "step": 23040
    },
    {
      "epoch": 2.7771084337349397,
      "grad_norm": 3.2742931842803955,
      "learning_rate": 1.7222891566265062e-05,
      "loss": 0.1205,
      "step": 23050
    },
    {
      "epoch": 2.7783132530120485,
      "grad_norm": 41.707420349121094,
      "learning_rate": 1.7221686746987954e-05,
      "loss": 0.0545,
      "step": 23060
    },
    {
      "epoch": 2.7795180722891564,
      "grad_norm": 3.101616859436035,
      "learning_rate": 1.7220481927710843e-05,
      "loss": 0.0515,
      "step": 23070
    },
    {
      "epoch": 2.780722891566265,
      "grad_norm": 3.1542327404022217,
      "learning_rate": 1.7219277108433736e-05,
      "loss": 0.092,
      "step": 23080
    },
    {
      "epoch": 2.7819277108433735,
      "grad_norm": 3.7632575035095215,
      "learning_rate": 1.721807228915663e-05,
      "loss": 0.1092,
      "step": 23090
    },
    {
      "epoch": 2.783132530120482,
      "grad_norm": 20.601179122924805,
      "learning_rate": 1.7216867469879517e-05,
      "loss": 0.0884,
      "step": 23100
    },
    {
      "epoch": 2.7843373493975903,
      "grad_norm": 0.7908666729927063,
      "learning_rate": 1.7215662650602413e-05,
      "loss": 0.0673,
      "step": 23110
    },
    {
      "epoch": 2.7855421686746986,
      "grad_norm": 6.536197662353516,
      "learning_rate": 1.7214457831325302e-05,
      "loss": 0.1462,
      "step": 23120
    },
    {
      "epoch": 2.7867469879518074,
      "grad_norm": 7.612046718597412,
      "learning_rate": 1.7213253012048195e-05,
      "loss": 0.0618,
      "step": 23130
    },
    {
      "epoch": 2.787951807228916,
      "grad_norm": 1.2585422992706299,
      "learning_rate": 1.7212048192771084e-05,
      "loss": 0.092,
      "step": 23140
    },
    {
      "epoch": 2.789156626506024,
      "grad_norm": 0.4246314764022827,
      "learning_rate": 1.7210843373493976e-05,
      "loss": 0.0941,
      "step": 23150
    },
    {
      "epoch": 2.7903614457831325,
      "grad_norm": 3.082425355911255,
      "learning_rate": 1.720963855421687e-05,
      "loss": 0.0601,
      "step": 23160
    },
    {
      "epoch": 2.791566265060241,
      "grad_norm": 8.417622566223145,
      "learning_rate": 1.720843373493976e-05,
      "loss": 0.1149,
      "step": 23170
    },
    {
      "epoch": 2.7927710843373497,
      "grad_norm": 0.256542444229126,
      "learning_rate": 1.7207228915662654e-05,
      "loss": 0.0282,
      "step": 23180
    },
    {
      "epoch": 2.7939759036144576,
      "grad_norm": 0.11170682311058044,
      "learning_rate": 1.7206024096385543e-05,
      "loss": 0.0407,
      "step": 23190
    },
    {
      "epoch": 2.7951807228915664,
      "grad_norm": 5.835474491119385,
      "learning_rate": 1.7204819277108435e-05,
      "loss": 0.0825,
      "step": 23200
    },
    {
      "epoch": 2.7963855421686747,
      "grad_norm": 0.09647784382104874,
      "learning_rate": 1.7203614457831327e-05,
      "loss": 0.0671,
      "step": 23210
    },
    {
      "epoch": 2.797590361445783,
      "grad_norm": 7.210955619812012,
      "learning_rate": 1.720240963855422e-05,
      "loss": 0.0571,
      "step": 23220
    },
    {
      "epoch": 2.7987951807228915,
      "grad_norm": 0.2081020623445511,
      "learning_rate": 1.7201204819277112e-05,
      "loss": 0.1697,
      "step": 23230
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.09364453703165054,
      "learning_rate": 1.72e-05,
      "loss": 0.0441,
      "step": 23240
    },
    {
      "epoch": 2.8012048192771086,
      "grad_norm": 2.4753592014312744,
      "learning_rate": 1.7198795180722894e-05,
      "loss": 0.0542,
      "step": 23250
    },
    {
      "epoch": 2.802409638554217,
      "grad_norm": 5.327836990356445,
      "learning_rate": 1.7197590361445783e-05,
      "loss": 0.1474,
      "step": 23260
    },
    {
      "epoch": 2.8036144578313253,
      "grad_norm": 12.35399055480957,
      "learning_rate": 1.7196385542168675e-05,
      "loss": 0.0887,
      "step": 23270
    },
    {
      "epoch": 2.8048192771084337,
      "grad_norm": 4.967146396636963,
      "learning_rate": 1.7195180722891568e-05,
      "loss": 0.0695,
      "step": 23280
    },
    {
      "epoch": 2.806024096385542,
      "grad_norm": 2.468510866165161,
      "learning_rate": 1.719397590361446e-05,
      "loss": 0.1068,
      "step": 23290
    },
    {
      "epoch": 2.807228915662651,
      "grad_norm": 6.775613784790039,
      "learning_rate": 1.7192771084337353e-05,
      "loss": 0.079,
      "step": 23300
    },
    {
      "epoch": 2.808433734939759,
      "grad_norm": 0.3569176197052002,
      "learning_rate": 1.719156626506024e-05,
      "loss": 0.0524,
      "step": 23310
    },
    {
      "epoch": 2.8096385542168676,
      "grad_norm": 0.22371672093868256,
      "learning_rate": 1.7190361445783134e-05,
      "loss": 0.0412,
      "step": 23320
    },
    {
      "epoch": 2.810843373493976,
      "grad_norm": 5.819157123565674,
      "learning_rate": 1.7189156626506026e-05,
      "loss": 0.0365,
      "step": 23330
    },
    {
      "epoch": 2.8120481927710843,
      "grad_norm": 0.04465436190366745,
      "learning_rate": 1.718795180722892e-05,
      "loss": 0.047,
      "step": 23340
    },
    {
      "epoch": 2.8132530120481927,
      "grad_norm": 4.024510860443115,
      "learning_rate": 1.7186746987951808e-05,
      "loss": 0.1113,
      "step": 23350
    },
    {
      "epoch": 2.814457831325301,
      "grad_norm": 5.863964557647705,
      "learning_rate": 1.71855421686747e-05,
      "loss": 0.1114,
      "step": 23360
    },
    {
      "epoch": 2.81566265060241,
      "grad_norm": 6.876823425292969,
      "learning_rate": 1.718433734939759e-05,
      "loss": 0.0721,
      "step": 23370
    },
    {
      "epoch": 2.816867469879518,
      "grad_norm": 8.12418270111084,
      "learning_rate": 1.7183132530120482e-05,
      "loss": 0.0938,
      "step": 23380
    },
    {
      "epoch": 2.8180722891566266,
      "grad_norm": 0.9269471764564514,
      "learning_rate": 1.7181927710843374e-05,
      "loss": 0.0487,
      "step": 23390
    },
    {
      "epoch": 2.819277108433735,
      "grad_norm": 7.837636470794678,
      "learning_rate": 1.7180722891566267e-05,
      "loss": 0.0828,
      "step": 23400
    },
    {
      "epoch": 2.8204819277108433,
      "grad_norm": 4.746688365936279,
      "learning_rate": 1.717951807228916e-05,
      "loss": 0.1067,
      "step": 23410
    },
    {
      "epoch": 2.821686746987952,
      "grad_norm": 0.2703823149204254,
      "learning_rate": 1.7178313253012048e-05,
      "loss": 0.0846,
      "step": 23420
    },
    {
      "epoch": 2.82289156626506,
      "grad_norm": 3.14402174949646,
      "learning_rate": 1.717710843373494e-05,
      "loss": 0.0807,
      "step": 23430
    },
    {
      "epoch": 2.824096385542169,
      "grad_norm": 66.49047088623047,
      "learning_rate": 1.7175903614457833e-05,
      "loss": 0.0371,
      "step": 23440
    },
    {
      "epoch": 2.825301204819277,
      "grad_norm": 8.42310619354248,
      "learning_rate": 1.7174698795180726e-05,
      "loss": 0.0607,
      "step": 23450
    },
    {
      "epoch": 2.8265060240963855,
      "grad_norm": 0.07265017181634903,
      "learning_rate": 1.7173493975903618e-05,
      "loss": 0.0478,
      "step": 23460
    },
    {
      "epoch": 2.827710843373494,
      "grad_norm": 2.6103591918945312,
      "learning_rate": 1.7172289156626507e-05,
      "loss": 0.1222,
      "step": 23470
    },
    {
      "epoch": 2.8289156626506022,
      "grad_norm": 9.151280403137207,
      "learning_rate": 1.71710843373494e-05,
      "loss": 0.0762,
      "step": 23480
    },
    {
      "epoch": 2.830120481927711,
      "grad_norm": 4.003072738647461,
      "learning_rate": 1.716987951807229e-05,
      "loss": 0.0739,
      "step": 23490
    },
    {
      "epoch": 2.8313253012048194,
      "grad_norm": 0.3662113547325134,
      "learning_rate": 1.716867469879518e-05,
      "loss": 0.0399,
      "step": 23500
    },
    {
      "epoch": 2.8325301204819278,
      "grad_norm": 3.5731239318847656,
      "learning_rate": 1.7167469879518073e-05,
      "loss": 0.0851,
      "step": 23510
    },
    {
      "epoch": 2.833734939759036,
      "grad_norm": 6.198467254638672,
      "learning_rate": 1.7166265060240966e-05,
      "loss": 0.1076,
      "step": 23520
    },
    {
      "epoch": 2.8349397590361445,
      "grad_norm": 6.699820518493652,
      "learning_rate": 1.7165060240963858e-05,
      "loss": 0.163,
      "step": 23530
    },
    {
      "epoch": 2.8361445783132533,
      "grad_norm": 8.645689964294434,
      "learning_rate": 1.7163855421686747e-05,
      "loss": 0.0967,
      "step": 23540
    },
    {
      "epoch": 2.837349397590361,
      "grad_norm": 0.15208445489406586,
      "learning_rate": 1.716265060240964e-05,
      "loss": 0.1001,
      "step": 23550
    },
    {
      "epoch": 2.83855421686747,
      "grad_norm": 5.841885566711426,
      "learning_rate": 1.7161445783132532e-05,
      "loss": 0.0606,
      "step": 23560
    },
    {
      "epoch": 2.8397590361445784,
      "grad_norm": 0.31389036774635315,
      "learning_rate": 1.7160240963855425e-05,
      "loss": 0.0905,
      "step": 23570
    },
    {
      "epoch": 2.8409638554216867,
      "grad_norm": 0.13215944170951843,
      "learning_rate": 1.7159036144578314e-05,
      "loss": 0.1035,
      "step": 23580
    },
    {
      "epoch": 2.842168674698795,
      "grad_norm": 0.06606455147266388,
      "learning_rate": 1.7157831325301206e-05,
      "loss": 0.1087,
      "step": 23590
    },
    {
      "epoch": 2.8433734939759034,
      "grad_norm": 0.1955094188451767,
      "learning_rate": 1.71566265060241e-05,
      "loss": 0.0506,
      "step": 23600
    },
    {
      "epoch": 2.8445783132530122,
      "grad_norm": 0.05836262181401253,
      "learning_rate": 1.7155421686746988e-05,
      "loss": 0.0739,
      "step": 23610
    },
    {
      "epoch": 2.8457831325301206,
      "grad_norm": 3.2815310955047607,
      "learning_rate": 1.7154216867469883e-05,
      "loss": 0.0679,
      "step": 23620
    },
    {
      "epoch": 2.846987951807229,
      "grad_norm": 6.244670391082764,
      "learning_rate": 1.7153012048192772e-05,
      "loss": 0.0678,
      "step": 23630
    },
    {
      "epoch": 2.8481927710843373,
      "grad_norm": 9.721837997436523,
      "learning_rate": 1.7151807228915665e-05,
      "loss": 0.0946,
      "step": 23640
    },
    {
      "epoch": 2.8493975903614457,
      "grad_norm": 0.2665950059890747,
      "learning_rate": 1.7150602409638554e-05,
      "loss": 0.0887,
      "step": 23650
    },
    {
      "epoch": 2.8506024096385545,
      "grad_norm": 4.347006797790527,
      "learning_rate": 1.7149397590361446e-05,
      "loss": 0.0906,
      "step": 23660
    },
    {
      "epoch": 2.8518072289156624,
      "grad_norm": 7.2328925132751465,
      "learning_rate": 1.714819277108434e-05,
      "loss": 0.0761,
      "step": 23670
    },
    {
      "epoch": 2.853012048192771,
      "grad_norm": 7.725250244140625,
      "learning_rate": 1.714698795180723e-05,
      "loss": 0.1108,
      "step": 23680
    },
    {
      "epoch": 2.8542168674698796,
      "grad_norm": 0.1330481916666031,
      "learning_rate": 1.7145783132530124e-05,
      "loss": 0.0617,
      "step": 23690
    },
    {
      "epoch": 2.855421686746988,
      "grad_norm": 0.10565736144781113,
      "learning_rate": 1.7144578313253013e-05,
      "loss": 0.163,
      "step": 23700
    },
    {
      "epoch": 2.8566265060240963,
      "grad_norm": 0.8124568462371826,
      "learning_rate": 1.7143373493975905e-05,
      "loss": 0.0763,
      "step": 23710
    },
    {
      "epoch": 2.8578313253012047,
      "grad_norm": 1.5934444665908813,
      "learning_rate": 1.7142168674698794e-05,
      "loss": 0.1362,
      "step": 23720
    },
    {
      "epoch": 2.8590361445783135,
      "grad_norm": 1.6560962200164795,
      "learning_rate": 1.714096385542169e-05,
      "loss": 0.0539,
      "step": 23730
    },
    {
      "epoch": 2.860240963855422,
      "grad_norm": 0.3944703936576843,
      "learning_rate": 1.713975903614458e-05,
      "loss": 0.0238,
      "step": 23740
    },
    {
      "epoch": 2.86144578313253,
      "grad_norm": 0.08769404888153076,
      "learning_rate": 1.713855421686747e-05,
      "loss": 0.1453,
      "step": 23750
    },
    {
      "epoch": 2.8626506024096385,
      "grad_norm": 3.7677223682403564,
      "learning_rate": 1.7137349397590364e-05,
      "loss": 0.0853,
      "step": 23760
    },
    {
      "epoch": 2.863855421686747,
      "grad_norm": 2.3359434604644775,
      "learning_rate": 1.7136144578313253e-05,
      "loss": 0.0653,
      "step": 23770
    },
    {
      "epoch": 2.8650602409638557,
      "grad_norm": 0.5860331654548645,
      "learning_rate": 1.7134939759036145e-05,
      "loss": 0.0893,
      "step": 23780
    },
    {
      "epoch": 2.8662650602409636,
      "grad_norm": 11.023945808410645,
      "learning_rate": 1.7133734939759038e-05,
      "loss": 0.0617,
      "step": 23790
    },
    {
      "epoch": 2.8674698795180724,
      "grad_norm": 1.730249047279358,
      "learning_rate": 1.713253012048193e-05,
      "loss": 0.0746,
      "step": 23800
    },
    {
      "epoch": 2.8686746987951808,
      "grad_norm": 2.8882994651794434,
      "learning_rate": 1.713132530120482e-05,
      "loss": 0.0793,
      "step": 23810
    },
    {
      "epoch": 2.869879518072289,
      "grad_norm": 7.066068649291992,
      "learning_rate": 1.7130120481927712e-05,
      "loss": 0.0715,
      "step": 23820
    },
    {
      "epoch": 2.8710843373493975,
      "grad_norm": 10.234838485717773,
      "learning_rate": 1.7128915662650604e-05,
      "loss": 0.116,
      "step": 23830
    },
    {
      "epoch": 2.872289156626506,
      "grad_norm": 0.8850728869438171,
      "learning_rate": 1.7127710843373497e-05,
      "loss": 0.0564,
      "step": 23840
    },
    {
      "epoch": 2.8734939759036147,
      "grad_norm": 1.995485782623291,
      "learning_rate": 1.712650602409639e-05,
      "loss": 0.0397,
      "step": 23850
    },
    {
      "epoch": 2.874698795180723,
      "grad_norm": 38.16647720336914,
      "learning_rate": 1.7125301204819278e-05,
      "loss": 0.0575,
      "step": 23860
    },
    {
      "epoch": 2.8759036144578314,
      "grad_norm": 0.11957526952028275,
      "learning_rate": 1.712409638554217e-05,
      "loss": 0.0792,
      "step": 23870
    },
    {
      "epoch": 2.8771084337349397,
      "grad_norm": 7.946218967437744,
      "learning_rate": 1.712289156626506e-05,
      "loss": 0.1369,
      "step": 23880
    },
    {
      "epoch": 2.878313253012048,
      "grad_norm": 2.0794835090637207,
      "learning_rate": 1.7121686746987952e-05,
      "loss": 0.12,
      "step": 23890
    },
    {
      "epoch": 2.8795180722891565,
      "grad_norm": 0.530569851398468,
      "learning_rate": 1.7120481927710844e-05,
      "loss": 0.1177,
      "step": 23900
    },
    {
      "epoch": 2.880722891566265,
      "grad_norm": 1.2533930540084839,
      "learning_rate": 1.7119277108433737e-05,
      "loss": 0.0444,
      "step": 23910
    },
    {
      "epoch": 2.8819277108433736,
      "grad_norm": 3.338395357131958,
      "learning_rate": 1.711807228915663e-05,
      "loss": 0.0634,
      "step": 23920
    },
    {
      "epoch": 2.883132530120482,
      "grad_norm": 12.534910202026367,
      "learning_rate": 1.711686746987952e-05,
      "loss": 0.0682,
      "step": 23930
    },
    {
      "epoch": 2.8843373493975903,
      "grad_norm": 2.9561948776245117,
      "learning_rate": 1.711566265060241e-05,
      "loss": 0.0812,
      "step": 23940
    },
    {
      "epoch": 2.8855421686746987,
      "grad_norm": 4.585231781005859,
      "learning_rate": 1.7114457831325303e-05,
      "loss": 0.1009,
      "step": 23950
    },
    {
      "epoch": 2.886746987951807,
      "grad_norm": 2.2811777591705322,
      "learning_rate": 1.7113253012048196e-05,
      "loss": 0.0616,
      "step": 23960
    },
    {
      "epoch": 2.887951807228916,
      "grad_norm": 0.06613228470087051,
      "learning_rate": 1.7112048192771085e-05,
      "loss": 0.0523,
      "step": 23970
    },
    {
      "epoch": 2.8891566265060242,
      "grad_norm": 19.153553009033203,
      "learning_rate": 1.7110843373493977e-05,
      "loss": 0.0879,
      "step": 23980
    },
    {
      "epoch": 2.8903614457831326,
      "grad_norm": 7.5004987716674805,
      "learning_rate": 1.710963855421687e-05,
      "loss": 0.0947,
      "step": 23990
    },
    {
      "epoch": 2.891566265060241,
      "grad_norm": 0.080354243516922,
      "learning_rate": 1.710843373493976e-05,
      "loss": 0.0418,
      "step": 24000
    },
    {
      "epoch": 2.8927710843373493,
      "grad_norm": 4.616190433502197,
      "learning_rate": 1.710722891566265e-05,
      "loss": 0.1044,
      "step": 24010
    },
    {
      "epoch": 2.8939759036144577,
      "grad_norm": 7.694141387939453,
      "learning_rate": 1.7106024096385544e-05,
      "loss": 0.1926,
      "step": 24020
    },
    {
      "epoch": 2.895180722891566,
      "grad_norm": 5.589909076690674,
      "learning_rate": 1.7104819277108436e-05,
      "loss": 0.2189,
      "step": 24030
    },
    {
      "epoch": 2.896385542168675,
      "grad_norm": 2.2454538345336914,
      "learning_rate": 1.7103614457831325e-05,
      "loss": 0.1076,
      "step": 24040
    },
    {
      "epoch": 2.897590361445783,
      "grad_norm": 0.5682858228683472,
      "learning_rate": 1.7102409638554217e-05,
      "loss": 0.0876,
      "step": 24050
    },
    {
      "epoch": 2.8987951807228916,
      "grad_norm": 0.35470202565193176,
      "learning_rate": 1.710120481927711e-05,
      "loss": 0.1364,
      "step": 24060
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.6014270782470703,
      "learning_rate": 1.7100000000000002e-05,
      "loss": 0.0614,
      "step": 24070
    },
    {
      "epoch": 2.9012048192771083,
      "grad_norm": 5.530418872833252,
      "learning_rate": 1.7098795180722895e-05,
      "loss": 0.0768,
      "step": 24080
    },
    {
      "epoch": 2.902409638554217,
      "grad_norm": 4.065949440002441,
      "learning_rate": 1.7097590361445784e-05,
      "loss": 0.1053,
      "step": 24090
    },
    {
      "epoch": 2.9036144578313254,
      "grad_norm": 0.29909762740135193,
      "learning_rate": 1.7096385542168676e-05,
      "loss": 0.0581,
      "step": 24100
    },
    {
      "epoch": 2.904819277108434,
      "grad_norm": 7.259001731872559,
      "learning_rate": 1.7095180722891565e-05,
      "loss": 0.1413,
      "step": 24110
    },
    {
      "epoch": 2.906024096385542,
      "grad_norm": 1.1154276132583618,
      "learning_rate": 1.7093975903614458e-05,
      "loss": 0.0772,
      "step": 24120
    },
    {
      "epoch": 2.9072289156626505,
      "grad_norm": 1.1022627353668213,
      "learning_rate": 1.709277108433735e-05,
      "loss": 0.1103,
      "step": 24130
    },
    {
      "epoch": 2.908433734939759,
      "grad_norm": 13.78179931640625,
      "learning_rate": 1.7091566265060243e-05,
      "loss": 0.0242,
      "step": 24140
    },
    {
      "epoch": 2.9096385542168672,
      "grad_norm": 8.675520896911621,
      "learning_rate": 1.7090361445783135e-05,
      "loss": 0.0754,
      "step": 24150
    },
    {
      "epoch": 2.910843373493976,
      "grad_norm": 0.48783305287361145,
      "learning_rate": 1.7089156626506024e-05,
      "loss": 0.0751,
      "step": 24160
    },
    {
      "epoch": 2.9120481927710844,
      "grad_norm": 0.2590487003326416,
      "learning_rate": 1.7087951807228916e-05,
      "loss": 0.0479,
      "step": 24170
    },
    {
      "epoch": 2.9132530120481928,
      "grad_norm": 0.6952983736991882,
      "learning_rate": 1.708674698795181e-05,
      "loss": 0.0844,
      "step": 24180
    },
    {
      "epoch": 2.914457831325301,
      "grad_norm": 10.13435173034668,
      "learning_rate": 1.70855421686747e-05,
      "loss": 0.1266,
      "step": 24190
    },
    {
      "epoch": 2.9156626506024095,
      "grad_norm": 5.605111122131348,
      "learning_rate": 1.7084337349397594e-05,
      "loss": 0.1104,
      "step": 24200
    },
    {
      "epoch": 2.9168674698795183,
      "grad_norm": 1.6379598379135132,
      "learning_rate": 1.7083132530120483e-05,
      "loss": 0.0543,
      "step": 24210
    },
    {
      "epoch": 2.9180722891566266,
      "grad_norm": 0.8418600559234619,
      "learning_rate": 1.7081927710843375e-05,
      "loss": 0.0595,
      "step": 24220
    },
    {
      "epoch": 2.919277108433735,
      "grad_norm": 4.070945739746094,
      "learning_rate": 1.7080722891566264e-05,
      "loss": 0.0657,
      "step": 24230
    },
    {
      "epoch": 2.9204819277108434,
      "grad_norm": 2.291910171508789,
      "learning_rate": 1.707951807228916e-05,
      "loss": 0.0581,
      "step": 24240
    },
    {
      "epoch": 2.9216867469879517,
      "grad_norm": 0.6519025564193726,
      "learning_rate": 1.707831325301205e-05,
      "loss": 0.066,
      "step": 24250
    },
    {
      "epoch": 2.92289156626506,
      "grad_norm": 0.6811968088150024,
      "learning_rate": 1.707710843373494e-05,
      "loss": 0.041,
      "step": 24260
    },
    {
      "epoch": 2.9240963855421684,
      "grad_norm": 1.9398508071899414,
      "learning_rate": 1.707590361445783e-05,
      "loss": 0.0523,
      "step": 24270
    },
    {
      "epoch": 2.9253012048192772,
      "grad_norm": 0.1933799684047699,
      "learning_rate": 1.7074698795180723e-05,
      "loss": 0.0345,
      "step": 24280
    },
    {
      "epoch": 2.9265060240963856,
      "grad_norm": 0.03929934278130531,
      "learning_rate": 1.7073493975903616e-05,
      "loss": 0.1187,
      "step": 24290
    },
    {
      "epoch": 2.927710843373494,
      "grad_norm": 16.886953353881836,
      "learning_rate": 1.7072289156626508e-05,
      "loss": 0.0553,
      "step": 24300
    },
    {
      "epoch": 2.9289156626506023,
      "grad_norm": 0.46906960010528564,
      "learning_rate": 1.70710843373494e-05,
      "loss": 0.0384,
      "step": 24310
    },
    {
      "epoch": 2.9301204819277107,
      "grad_norm": 10.683395385742188,
      "learning_rate": 1.706987951807229e-05,
      "loss": 0.0621,
      "step": 24320
    },
    {
      "epoch": 2.9313253012048195,
      "grad_norm": 2.613511800765991,
      "learning_rate": 1.7068674698795182e-05,
      "loss": 0.1634,
      "step": 24330
    },
    {
      "epoch": 2.932530120481928,
      "grad_norm": 7.219575881958008,
      "learning_rate": 1.7067469879518074e-05,
      "loss": 0.0781,
      "step": 24340
    },
    {
      "epoch": 2.933734939759036,
      "grad_norm": 9.110837936401367,
      "learning_rate": 1.7066265060240967e-05,
      "loss": 0.0875,
      "step": 24350
    },
    {
      "epoch": 2.9349397590361446,
      "grad_norm": 3.5023233890533447,
      "learning_rate": 1.706506024096386e-05,
      "loss": 0.0664,
      "step": 24360
    },
    {
      "epoch": 2.936144578313253,
      "grad_norm": 0.7284088730812073,
      "learning_rate": 1.7063855421686748e-05,
      "loss": 0.1251,
      "step": 24370
    },
    {
      "epoch": 2.9373493975903613,
      "grad_norm": 1.2193589210510254,
      "learning_rate": 1.706265060240964e-05,
      "loss": 0.0766,
      "step": 24380
    },
    {
      "epoch": 2.9385542168674696,
      "grad_norm": 3.5504682064056396,
      "learning_rate": 1.706144578313253e-05,
      "loss": 0.0477,
      "step": 24390
    },
    {
      "epoch": 2.9397590361445785,
      "grad_norm": 13.455425262451172,
      "learning_rate": 1.7060240963855422e-05,
      "loss": 0.1098,
      "step": 24400
    },
    {
      "epoch": 2.940963855421687,
      "grad_norm": 0.39442020654678345,
      "learning_rate": 1.7059036144578315e-05,
      "loss": 0.0812,
      "step": 24410
    },
    {
      "epoch": 2.942168674698795,
      "grad_norm": 1.2531218528747559,
      "learning_rate": 1.7057831325301207e-05,
      "loss": 0.0817,
      "step": 24420
    },
    {
      "epoch": 2.9433734939759035,
      "grad_norm": 0.2016095519065857,
      "learning_rate": 1.70566265060241e-05,
      "loss": 0.0963,
      "step": 24430
    },
    {
      "epoch": 2.944578313253012,
      "grad_norm": 0.9168893098831177,
      "learning_rate": 1.705542168674699e-05,
      "loss": 0.0672,
      "step": 24440
    },
    {
      "epoch": 2.9457831325301207,
      "grad_norm": 1.914004921913147,
      "learning_rate": 1.705421686746988e-05,
      "loss": 0.1053,
      "step": 24450
    },
    {
      "epoch": 2.946987951807229,
      "grad_norm": 0.28619471192359924,
      "learning_rate": 1.7053012048192773e-05,
      "loss": 0.0903,
      "step": 24460
    },
    {
      "epoch": 2.9481927710843374,
      "grad_norm": 13.444095611572266,
      "learning_rate": 1.7051807228915666e-05,
      "loss": 0.1026,
      "step": 24470
    },
    {
      "epoch": 2.9493975903614458,
      "grad_norm": 29.35394859313965,
      "learning_rate": 1.7050602409638555e-05,
      "loss": 0.068,
      "step": 24480
    },
    {
      "epoch": 2.950602409638554,
      "grad_norm": 2.985642910003662,
      "learning_rate": 1.7049397590361447e-05,
      "loss": 0.0768,
      "step": 24490
    },
    {
      "epoch": 2.9518072289156625,
      "grad_norm": 2.1720898151397705,
      "learning_rate": 1.704819277108434e-05,
      "loss": 0.0468,
      "step": 24500
    },
    {
      "epoch": 2.953012048192771,
      "grad_norm": 2.9443089962005615,
      "learning_rate": 1.704698795180723e-05,
      "loss": 0.0947,
      "step": 24510
    },
    {
      "epoch": 2.9542168674698797,
      "grad_norm": 4.784847736358643,
      "learning_rate": 1.704578313253012e-05,
      "loss": 0.0747,
      "step": 24520
    },
    {
      "epoch": 2.955421686746988,
      "grad_norm": 0.12553007900714874,
      "learning_rate": 1.7044578313253014e-05,
      "loss": 0.0733,
      "step": 24530
    },
    {
      "epoch": 2.9566265060240964,
      "grad_norm": 2.9808828830718994,
      "learning_rate": 1.7043373493975906e-05,
      "loss": 0.0597,
      "step": 24540
    },
    {
      "epoch": 2.9578313253012047,
      "grad_norm": 0.22252300381660461,
      "learning_rate": 1.7042168674698795e-05,
      "loss": 0.0269,
      "step": 24550
    },
    {
      "epoch": 2.959036144578313,
      "grad_norm": 3.054316997528076,
      "learning_rate": 1.7040963855421688e-05,
      "loss": 0.1056,
      "step": 24560
    },
    {
      "epoch": 2.960240963855422,
      "grad_norm": 1.076340913772583,
      "learning_rate": 1.703975903614458e-05,
      "loss": 0.081,
      "step": 24570
    },
    {
      "epoch": 2.9614457831325303,
      "grad_norm": 0.08051089197397232,
      "learning_rate": 1.7038554216867472e-05,
      "loss": 0.078,
      "step": 24580
    },
    {
      "epoch": 2.9626506024096386,
      "grad_norm": 2.1312129497528076,
      "learning_rate": 1.7037349397590365e-05,
      "loss": 0.0611,
      "step": 24590
    },
    {
      "epoch": 2.963855421686747,
      "grad_norm": 0.6260464787483215,
      "learning_rate": 1.7036144578313254e-05,
      "loss": 0.0969,
      "step": 24600
    },
    {
      "epoch": 2.9650602409638553,
      "grad_norm": 2.8200759887695312,
      "learning_rate": 1.7034939759036146e-05,
      "loss": 0.0619,
      "step": 24610
    },
    {
      "epoch": 2.9662650602409637,
      "grad_norm": 1.2665513753890991,
      "learning_rate": 1.7033734939759035e-05,
      "loss": 0.0792,
      "step": 24620
    },
    {
      "epoch": 2.967469879518072,
      "grad_norm": 1.8842447996139526,
      "learning_rate": 1.7032530120481928e-05,
      "loss": 0.0859,
      "step": 24630
    },
    {
      "epoch": 2.968674698795181,
      "grad_norm": 2.3203117847442627,
      "learning_rate": 1.703132530120482e-05,
      "loss": 0.062,
      "step": 24640
    },
    {
      "epoch": 2.9698795180722892,
      "grad_norm": 8.069111824035645,
      "learning_rate": 1.7030120481927713e-05,
      "loss": 0.0987,
      "step": 24650
    },
    {
      "epoch": 2.9710843373493976,
      "grad_norm": 0.13850334286689758,
      "learning_rate": 1.7028915662650605e-05,
      "loss": 0.0612,
      "step": 24660
    },
    {
      "epoch": 2.972289156626506,
      "grad_norm": 4.435942649841309,
      "learning_rate": 1.7027710843373494e-05,
      "loss": 0.0649,
      "step": 24670
    },
    {
      "epoch": 2.9734939759036143,
      "grad_norm": 2.774355411529541,
      "learning_rate": 1.7026506024096387e-05,
      "loss": 0.0961,
      "step": 24680
    },
    {
      "epoch": 2.974698795180723,
      "grad_norm": 6.966097354888916,
      "learning_rate": 1.702530120481928e-05,
      "loss": 0.0819,
      "step": 24690
    },
    {
      "epoch": 2.9759036144578315,
      "grad_norm": 0.10463069379329681,
      "learning_rate": 1.702409638554217e-05,
      "loss": 0.0871,
      "step": 24700
    },
    {
      "epoch": 2.97710843373494,
      "grad_norm": 0.4660145044326782,
      "learning_rate": 1.702289156626506e-05,
      "loss": 0.0508,
      "step": 24710
    },
    {
      "epoch": 2.978313253012048,
      "grad_norm": 0.08747763931751251,
      "learning_rate": 1.7021686746987953e-05,
      "loss": 0.0543,
      "step": 24720
    },
    {
      "epoch": 2.9795180722891565,
      "grad_norm": 2.9472765922546387,
      "learning_rate": 1.7020481927710845e-05,
      "loss": 0.0853,
      "step": 24730
    },
    {
      "epoch": 2.980722891566265,
      "grad_norm": 2.1828773021698,
      "learning_rate": 1.7019277108433734e-05,
      "loss": 0.1134,
      "step": 24740
    },
    {
      "epoch": 2.9819277108433733,
      "grad_norm": 4.650660514831543,
      "learning_rate": 1.7018072289156627e-05,
      "loss": 0.079,
      "step": 24750
    },
    {
      "epoch": 2.983132530120482,
      "grad_norm": 5.0996551513671875,
      "learning_rate": 1.701686746987952e-05,
      "loss": 0.0969,
      "step": 24760
    },
    {
      "epoch": 2.9843373493975904,
      "grad_norm": 36.23675537109375,
      "learning_rate": 1.7015662650602412e-05,
      "loss": 0.0977,
      "step": 24770
    },
    {
      "epoch": 2.985542168674699,
      "grad_norm": 0.09061502665281296,
      "learning_rate": 1.70144578313253e-05,
      "loss": 0.0377,
      "step": 24780
    },
    {
      "epoch": 2.986746987951807,
      "grad_norm": 0.7273723483085632,
      "learning_rate": 1.7013253012048193e-05,
      "loss": 0.0692,
      "step": 24790
    },
    {
      "epoch": 2.9879518072289155,
      "grad_norm": 3.8742265701293945,
      "learning_rate": 1.7012048192771086e-05,
      "loss": 0.1573,
      "step": 24800
    },
    {
      "epoch": 2.9891566265060243,
      "grad_norm": 0.13911579549312592,
      "learning_rate": 1.7010843373493978e-05,
      "loss": 0.0622,
      "step": 24810
    },
    {
      "epoch": 2.9903614457831327,
      "grad_norm": 0.06825052201747894,
      "learning_rate": 1.700963855421687e-05,
      "loss": 0.0492,
      "step": 24820
    },
    {
      "epoch": 2.991566265060241,
      "grad_norm": 0.16861726343631744,
      "learning_rate": 1.700843373493976e-05,
      "loss": 0.0256,
      "step": 24830
    },
    {
      "epoch": 2.9927710843373494,
      "grad_norm": 0.09393893927335739,
      "learning_rate": 1.7007228915662652e-05,
      "loss": 0.1617,
      "step": 24840
    },
    {
      "epoch": 2.9939759036144578,
      "grad_norm": 28.71964454650879,
      "learning_rate": 1.700602409638554e-05,
      "loss": 0.1189,
      "step": 24850
    },
    {
      "epoch": 2.995180722891566,
      "grad_norm": 0.6475785970687866,
      "learning_rate": 1.7004819277108437e-05,
      "loss": 0.128,
      "step": 24860
    },
    {
      "epoch": 2.9963855421686745,
      "grad_norm": 0.8995348811149597,
      "learning_rate": 1.7003614457831326e-05,
      "loss": 0.1556,
      "step": 24870
    },
    {
      "epoch": 2.9975903614457833,
      "grad_norm": 8.053971290588379,
      "learning_rate": 1.700240963855422e-05,
      "loss": 0.1283,
      "step": 24880
    },
    {
      "epoch": 2.9987951807228916,
      "grad_norm": 0.16220085322856903,
      "learning_rate": 1.700120481927711e-05,
      "loss": 0.0317,
      "step": 24890
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6785534024238586,
      "learning_rate": 1.7e-05,
      "loss": 0.1302,
      "step": 24900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9725346831646045,
      "eval_f1": 0.9287278034541474,
      "eval_loss": 0.08141212910413742,
      "eval_precision": 0.9141625763198851,
      "eval_recall": 0.9437646768013842,
      "eval_runtime": 3384.106,
      "eval_samples_per_second": 12.615,
      "eval_steps_per_second": 0.526,
      "step": 24900
    },
    {
      "epoch": 3.0012048192771084,
      "grad_norm": 2.4304099082946777,
      "learning_rate": 1.6998795180722892e-05,
      "loss": 0.0793,
      "step": 24910
    },
    {
      "epoch": 3.0024096385542167,
      "grad_norm": 0.03624741733074188,
      "learning_rate": 1.6997590361445785e-05,
      "loss": 0.0272,
      "step": 24920
    },
    {
      "epoch": 3.003614457831325,
      "grad_norm": 1.3383427858352661,
      "learning_rate": 1.6996385542168677e-05,
      "loss": 0.0867,
      "step": 24930
    },
    {
      "epoch": 3.004819277108434,
      "grad_norm": 0.5510725975036621,
      "learning_rate": 1.6995180722891566e-05,
      "loss": 0.0508,
      "step": 24940
    },
    {
      "epoch": 3.0060240963855422,
      "grad_norm": 0.3666130602359772,
      "learning_rate": 1.699397590361446e-05,
      "loss": 0.0898,
      "step": 24950
    },
    {
      "epoch": 3.0072289156626506,
      "grad_norm": 0.4211019277572632,
      "learning_rate": 1.699277108433735e-05,
      "loss": 0.0582,
      "step": 24960
    },
    {
      "epoch": 3.008433734939759,
      "grad_norm": 10.228185653686523,
      "learning_rate": 1.6991566265060244e-05,
      "loss": 0.0571,
      "step": 24970
    },
    {
      "epoch": 3.0096385542168673,
      "grad_norm": 0.471503347158432,
      "learning_rate": 1.6990361445783136e-05,
      "loss": 0.0171,
      "step": 24980
    },
    {
      "epoch": 3.0108433734939757,
      "grad_norm": 0.5381041765213013,
      "learning_rate": 1.6989156626506025e-05,
      "loss": 0.0174,
      "step": 24990
    },
    {
      "epoch": 3.0120481927710845,
      "grad_norm": 3.176314115524292,
      "learning_rate": 1.6987951807228917e-05,
      "loss": 0.0842,
      "step": 25000
    },
    {
      "epoch": 3.013253012048193,
      "grad_norm": 0.22568516433238983,
      "learning_rate": 1.6986746987951806e-05,
      "loss": 0.0472,
      "step": 25010
    },
    {
      "epoch": 3.014457831325301,
      "grad_norm": 51.33846664428711,
      "learning_rate": 1.69855421686747e-05,
      "loss": 0.0686,
      "step": 25020
    },
    {
      "epoch": 3.0156626506024096,
      "grad_norm": 0.43363553285598755,
      "learning_rate": 1.698433734939759e-05,
      "loss": 0.0368,
      "step": 25030
    },
    {
      "epoch": 3.016867469879518,
      "grad_norm": 0.6956917643547058,
      "learning_rate": 1.6983132530120484e-05,
      "loss": 0.1057,
      "step": 25040
    },
    {
      "epoch": 3.0180722891566263,
      "grad_norm": 0.38611817359924316,
      "learning_rate": 1.6981927710843376e-05,
      "loss": 0.0725,
      "step": 25050
    },
    {
      "epoch": 3.019277108433735,
      "grad_norm": 9.51264476776123,
      "learning_rate": 1.6980722891566265e-05,
      "loss": 0.0667,
      "step": 25060
    },
    {
      "epoch": 3.0204819277108435,
      "grad_norm": 8.615707397460938,
      "learning_rate": 1.6979518072289158e-05,
      "loss": 0.1165,
      "step": 25070
    },
    {
      "epoch": 3.021686746987952,
      "grad_norm": 2.6760761737823486,
      "learning_rate": 1.697831325301205e-05,
      "loss": 0.0328,
      "step": 25080
    },
    {
      "epoch": 3.02289156626506,
      "grad_norm": 0.1322176605463028,
      "learning_rate": 1.6977108433734943e-05,
      "loss": 0.048,
      "step": 25090
    },
    {
      "epoch": 3.0240963855421685,
      "grad_norm": 0.8976318836212158,
      "learning_rate": 1.6975903614457835e-05,
      "loss": 0.1384,
      "step": 25100
    },
    {
      "epoch": 3.025301204819277,
      "grad_norm": 1.887345790863037,
      "learning_rate": 1.6974698795180724e-05,
      "loss": 0.0499,
      "step": 25110
    },
    {
      "epoch": 3.0265060240963857,
      "grad_norm": 2.610219717025757,
      "learning_rate": 1.6973493975903616e-05,
      "loss": 0.0624,
      "step": 25120
    },
    {
      "epoch": 3.027710843373494,
      "grad_norm": 0.4516180753707886,
      "learning_rate": 1.6972289156626506e-05,
      "loss": 0.0365,
      "step": 25130
    },
    {
      "epoch": 3.0289156626506024,
      "grad_norm": 11.192957878112793,
      "learning_rate": 1.6971084337349398e-05,
      "loss": 0.0959,
      "step": 25140
    },
    {
      "epoch": 3.0301204819277108,
      "grad_norm": 0.14288848638534546,
      "learning_rate": 1.696987951807229e-05,
      "loss": 0.065,
      "step": 25150
    },
    {
      "epoch": 3.031325301204819,
      "grad_norm": 0.15026803314685822,
      "learning_rate": 1.6968674698795183e-05,
      "loss": 0.0298,
      "step": 25160
    },
    {
      "epoch": 3.0325301204819275,
      "grad_norm": 10.095438003540039,
      "learning_rate": 1.6967469879518075e-05,
      "loss": 0.0548,
      "step": 25170
    },
    {
      "epoch": 3.0337349397590363,
      "grad_norm": 0.16888085007667542,
      "learning_rate": 1.6966265060240964e-05,
      "loss": 0.0558,
      "step": 25180
    },
    {
      "epoch": 3.0349397590361447,
      "grad_norm": 1.8774999380111694,
      "learning_rate": 1.6965060240963857e-05,
      "loss": 0.0795,
      "step": 25190
    },
    {
      "epoch": 3.036144578313253,
      "grad_norm": 0.9404363632202148,
      "learning_rate": 1.696385542168675e-05,
      "loss": 0.0905,
      "step": 25200
    },
    {
      "epoch": 3.0373493975903614,
      "grad_norm": 0.8127645254135132,
      "learning_rate": 1.696265060240964e-05,
      "loss": 0.0858,
      "step": 25210
    },
    {
      "epoch": 3.0385542168674697,
      "grad_norm": 0.03646562620997429,
      "learning_rate": 1.696144578313253e-05,
      "loss": 0.0174,
      "step": 25220
    },
    {
      "epoch": 3.039759036144578,
      "grad_norm": 0.04564135521650314,
      "learning_rate": 1.6960240963855423e-05,
      "loss": 0.0548,
      "step": 25230
    },
    {
      "epoch": 3.040963855421687,
      "grad_norm": 4.462850570678711,
      "learning_rate": 1.6959036144578312e-05,
      "loss": 0.0335,
      "step": 25240
    },
    {
      "epoch": 3.0421686746987953,
      "grad_norm": 0.3072064220905304,
      "learning_rate": 1.6957831325301205e-05,
      "loss": 0.0509,
      "step": 25250
    },
    {
      "epoch": 3.0433734939759036,
      "grad_norm": 0.0355733297765255,
      "learning_rate": 1.6956626506024097e-05,
      "loss": 0.0196,
      "step": 25260
    },
    {
      "epoch": 3.044578313253012,
      "grad_norm": 4.6734724044799805,
      "learning_rate": 1.695542168674699e-05,
      "loss": 0.0543,
      "step": 25270
    },
    {
      "epoch": 3.0457831325301203,
      "grad_norm": 1.9315805435180664,
      "learning_rate": 1.6954216867469882e-05,
      "loss": 0.0174,
      "step": 25280
    },
    {
      "epoch": 3.0469879518072287,
      "grad_norm": 1.0515413284301758,
      "learning_rate": 1.695301204819277e-05,
      "loss": 0.0722,
      "step": 25290
    },
    {
      "epoch": 3.0481927710843375,
      "grad_norm": 21.70365333557129,
      "learning_rate": 1.6951807228915663e-05,
      "loss": 0.1093,
      "step": 25300
    },
    {
      "epoch": 3.049397590361446,
      "grad_norm": 7.412184715270996,
      "learning_rate": 1.6950602409638556e-05,
      "loss": 0.0887,
      "step": 25310
    },
    {
      "epoch": 3.0506024096385542,
      "grad_norm": 0.6567618250846863,
      "learning_rate": 1.6949397590361448e-05,
      "loss": 0.0716,
      "step": 25320
    },
    {
      "epoch": 3.0518072289156626,
      "grad_norm": 2.499176025390625,
      "learning_rate": 1.694819277108434e-05,
      "loss": 0.0493,
      "step": 25330
    },
    {
      "epoch": 3.053012048192771,
      "grad_norm": 0.3454431891441345,
      "learning_rate": 1.694698795180723e-05,
      "loss": 0.0669,
      "step": 25340
    },
    {
      "epoch": 3.0542168674698793,
      "grad_norm": 5.247974395751953,
      "learning_rate": 1.6945783132530122e-05,
      "loss": 0.0735,
      "step": 25350
    },
    {
      "epoch": 3.055421686746988,
      "grad_norm": 2.995832681655884,
      "learning_rate": 1.694457831325301e-05,
      "loss": 0.0367,
      "step": 25360
    },
    {
      "epoch": 3.0566265060240965,
      "grad_norm": 0.6726611256599426,
      "learning_rate": 1.6943373493975907e-05,
      "loss": 0.0555,
      "step": 25370
    },
    {
      "epoch": 3.057831325301205,
      "grad_norm": 44.52445602416992,
      "learning_rate": 1.6942168674698796e-05,
      "loss": 0.0499,
      "step": 25380
    },
    {
      "epoch": 3.059036144578313,
      "grad_norm": 3.1108498573303223,
      "learning_rate": 1.694096385542169e-05,
      "loss": 0.1678,
      "step": 25390
    },
    {
      "epoch": 3.0602409638554215,
      "grad_norm": 7.216498851776123,
      "learning_rate": 1.693975903614458e-05,
      "loss": 0.1109,
      "step": 25400
    },
    {
      "epoch": 3.06144578313253,
      "grad_norm": 3.309115171432495,
      "learning_rate": 1.693855421686747e-05,
      "loss": 0.0662,
      "step": 25410
    },
    {
      "epoch": 3.0626506024096387,
      "grad_norm": 5.374570846557617,
      "learning_rate": 1.6937349397590362e-05,
      "loss": 0.1032,
      "step": 25420
    },
    {
      "epoch": 3.063855421686747,
      "grad_norm": 27.222984313964844,
      "learning_rate": 1.6936144578313255e-05,
      "loss": 0.0381,
      "step": 25430
    },
    {
      "epoch": 3.0650602409638554,
      "grad_norm": 0.10647351294755936,
      "learning_rate": 1.6934939759036147e-05,
      "loss": 0.047,
      "step": 25440
    },
    {
      "epoch": 3.066265060240964,
      "grad_norm": 4.85795783996582,
      "learning_rate": 1.6933734939759036e-05,
      "loss": 0.0618,
      "step": 25450
    },
    {
      "epoch": 3.067469879518072,
      "grad_norm": 0.2360479235649109,
      "learning_rate": 1.693253012048193e-05,
      "loss": 0.0379,
      "step": 25460
    },
    {
      "epoch": 3.0686746987951805,
      "grad_norm": 1.3372066020965576,
      "learning_rate": 1.693132530120482e-05,
      "loss": 0.0323,
      "step": 25470
    },
    {
      "epoch": 3.0698795180722893,
      "grad_norm": 0.41832563281059265,
      "learning_rate": 1.6930120481927714e-05,
      "loss": 0.0825,
      "step": 25480
    },
    {
      "epoch": 3.0710843373493977,
      "grad_norm": 4.403922080993652,
      "learning_rate": 1.6928915662650606e-05,
      "loss": 0.0988,
      "step": 25490
    },
    {
      "epoch": 3.072289156626506,
      "grad_norm": 8.387153625488281,
      "learning_rate": 1.6927710843373495e-05,
      "loss": 0.0528,
      "step": 25500
    },
    {
      "epoch": 3.0734939759036144,
      "grad_norm": 3.03525710105896,
      "learning_rate": 1.6926506024096388e-05,
      "loss": 0.027,
      "step": 25510
    },
    {
      "epoch": 3.0746987951807228,
      "grad_norm": 3.354562997817993,
      "learning_rate": 1.6925301204819277e-05,
      "loss": 0.0711,
      "step": 25520
    },
    {
      "epoch": 3.075903614457831,
      "grad_norm": 0.6368874907493591,
      "learning_rate": 1.692409638554217e-05,
      "loss": 0.0535,
      "step": 25530
    },
    {
      "epoch": 3.07710843373494,
      "grad_norm": 0.1567530483007431,
      "learning_rate": 1.692289156626506e-05,
      "loss": 0.0419,
      "step": 25540
    },
    {
      "epoch": 3.0783132530120483,
      "grad_norm": 30.621044158935547,
      "learning_rate": 1.6921686746987954e-05,
      "loss": 0.0467,
      "step": 25550
    },
    {
      "epoch": 3.0795180722891566,
      "grad_norm": 0.40632039308547974,
      "learning_rate": 1.6920481927710846e-05,
      "loss": 0.0461,
      "step": 25560
    },
    {
      "epoch": 3.080722891566265,
      "grad_norm": 11.382928848266602,
      "learning_rate": 1.6919277108433735e-05,
      "loss": 0.0983,
      "step": 25570
    },
    {
      "epoch": 3.0819277108433734,
      "grad_norm": 13.122811317443848,
      "learning_rate": 1.6918072289156628e-05,
      "loss": 0.0866,
      "step": 25580
    },
    {
      "epoch": 3.0831325301204817,
      "grad_norm": 14.135125160217285,
      "learning_rate": 1.691686746987952e-05,
      "loss": 0.0837,
      "step": 25590
    },
    {
      "epoch": 3.0843373493975905,
      "grad_norm": 0.07893872261047363,
      "learning_rate": 1.6915662650602413e-05,
      "loss": 0.0307,
      "step": 25600
    },
    {
      "epoch": 3.085542168674699,
      "grad_norm": 0.16496102511882782,
      "learning_rate": 1.6914457831325302e-05,
      "loss": 0.0325,
      "step": 25610
    },
    {
      "epoch": 3.0867469879518072,
      "grad_norm": 2.434671640396118,
      "learning_rate": 1.6913253012048194e-05,
      "loss": 0.0496,
      "step": 25620
    },
    {
      "epoch": 3.0879518072289156,
      "grad_norm": 0.0845930278301239,
      "learning_rate": 1.6912048192771087e-05,
      "loss": 0.0163,
      "step": 25630
    },
    {
      "epoch": 3.089156626506024,
      "grad_norm": 0.1764116883277893,
      "learning_rate": 1.6910843373493976e-05,
      "loss": 0.1476,
      "step": 25640
    },
    {
      "epoch": 3.0903614457831323,
      "grad_norm": 2.334674119949341,
      "learning_rate": 1.6909638554216868e-05,
      "loss": 0.0342,
      "step": 25650
    },
    {
      "epoch": 3.091566265060241,
      "grad_norm": 8.168604850769043,
      "learning_rate": 1.690843373493976e-05,
      "loss": 0.0332,
      "step": 25660
    },
    {
      "epoch": 3.0927710843373495,
      "grad_norm": 0.039613738656044006,
      "learning_rate": 1.6907228915662653e-05,
      "loss": 0.1076,
      "step": 25670
    },
    {
      "epoch": 3.093975903614458,
      "grad_norm": 0.041930604726076126,
      "learning_rate": 1.6906024096385542e-05,
      "loss": 0.0871,
      "step": 25680
    },
    {
      "epoch": 3.095180722891566,
      "grad_norm": 3.0779659748077393,
      "learning_rate": 1.6904819277108434e-05,
      "loss": 0.1095,
      "step": 25690
    },
    {
      "epoch": 3.0963855421686746,
      "grad_norm": 8.746243476867676,
      "learning_rate": 1.6903614457831327e-05,
      "loss": 0.0525,
      "step": 25700
    },
    {
      "epoch": 3.097590361445783,
      "grad_norm": 0.6415839791297913,
      "learning_rate": 1.690240963855422e-05,
      "loss": 0.0463,
      "step": 25710
    },
    {
      "epoch": 3.0987951807228917,
      "grad_norm": 14.529682159423828,
      "learning_rate": 1.6901204819277112e-05,
      "loss": 0.0476,
      "step": 25720
    },
    {
      "epoch": 3.1,
      "grad_norm": 1.1583919525146484,
      "learning_rate": 1.69e-05,
      "loss": 0.0616,
      "step": 25730
    },
    {
      "epoch": 3.1012048192771084,
      "grad_norm": 0.22396260499954224,
      "learning_rate": 1.6898795180722893e-05,
      "loss": 0.0805,
      "step": 25740
    },
    {
      "epoch": 3.102409638554217,
      "grad_norm": 7.871969223022461,
      "learning_rate": 1.6897590361445782e-05,
      "loss": 0.1113,
      "step": 25750
    },
    {
      "epoch": 3.103614457831325,
      "grad_norm": 0.20708441734313965,
      "learning_rate": 1.6896385542168675e-05,
      "loss": 0.0557,
      "step": 25760
    },
    {
      "epoch": 3.1048192771084335,
      "grad_norm": 12.685872077941895,
      "learning_rate": 1.6895180722891567e-05,
      "loss": 0.0869,
      "step": 25770
    },
    {
      "epoch": 3.1060240963855423,
      "grad_norm": 0.3448854684829712,
      "learning_rate": 1.689397590361446e-05,
      "loss": 0.0776,
      "step": 25780
    },
    {
      "epoch": 3.1072289156626507,
      "grad_norm": 0.303743451833725,
      "learning_rate": 1.6892771084337352e-05,
      "loss": 0.0949,
      "step": 25790
    },
    {
      "epoch": 3.108433734939759,
      "grad_norm": 0.05809903144836426,
      "learning_rate": 1.689156626506024e-05,
      "loss": 0.0676,
      "step": 25800
    },
    {
      "epoch": 3.1096385542168674,
      "grad_norm": 6.349732875823975,
      "learning_rate": 1.6890361445783134e-05,
      "loss": 0.0668,
      "step": 25810
    },
    {
      "epoch": 3.1108433734939758,
      "grad_norm": 0.4365343451499939,
      "learning_rate": 1.6889156626506026e-05,
      "loss": 0.1055,
      "step": 25820
    },
    {
      "epoch": 3.112048192771084,
      "grad_norm": 0.9432787299156189,
      "learning_rate": 1.688795180722892e-05,
      "loss": 0.071,
      "step": 25830
    },
    {
      "epoch": 3.113253012048193,
      "grad_norm": 0.08495219051837921,
      "learning_rate": 1.6886746987951807e-05,
      "loss": 0.0465,
      "step": 25840
    },
    {
      "epoch": 3.1144578313253013,
      "grad_norm": 0.8767963647842407,
      "learning_rate": 1.68855421686747e-05,
      "loss": 0.0608,
      "step": 25850
    },
    {
      "epoch": 3.1156626506024097,
      "grad_norm": 19.451202392578125,
      "learning_rate": 1.6884337349397592e-05,
      "loss": 0.1041,
      "step": 25860
    },
    {
      "epoch": 3.116867469879518,
      "grad_norm": 16.793489456176758,
      "learning_rate": 1.688313253012048e-05,
      "loss": 0.0786,
      "step": 25870
    },
    {
      "epoch": 3.1180722891566264,
      "grad_norm": 3.298405647277832,
      "learning_rate": 1.6881927710843374e-05,
      "loss": 0.0543,
      "step": 25880
    },
    {
      "epoch": 3.1192771084337347,
      "grad_norm": 0.18387550115585327,
      "learning_rate": 1.6880722891566266e-05,
      "loss": 0.0769,
      "step": 25890
    },
    {
      "epoch": 3.1204819277108435,
      "grad_norm": 1.8464025259017944,
      "learning_rate": 1.687951807228916e-05,
      "loss": 0.1124,
      "step": 25900
    },
    {
      "epoch": 3.121686746987952,
      "grad_norm": 1.1267430782318115,
      "learning_rate": 1.6878313253012048e-05,
      "loss": 0.0821,
      "step": 25910
    },
    {
      "epoch": 3.1228915662650603,
      "grad_norm": 0.18176427483558655,
      "learning_rate": 1.687710843373494e-05,
      "loss": 0.0976,
      "step": 25920
    },
    {
      "epoch": 3.1240963855421686,
      "grad_norm": 0.05536215007305145,
      "learning_rate": 1.6875903614457833e-05,
      "loss": 0.0586,
      "step": 25930
    },
    {
      "epoch": 3.125301204819277,
      "grad_norm": 0.7859703898429871,
      "learning_rate": 1.6874698795180725e-05,
      "loss": 0.0478,
      "step": 25940
    },
    {
      "epoch": 3.1265060240963853,
      "grad_norm": 3.8488543033599854,
      "learning_rate": 1.6873493975903617e-05,
      "loss": 0.0458,
      "step": 25950
    },
    {
      "epoch": 3.127710843373494,
      "grad_norm": 0.08266708254814148,
      "learning_rate": 1.6872289156626507e-05,
      "loss": 0.1293,
      "step": 25960
    },
    {
      "epoch": 3.1289156626506025,
      "grad_norm": 0.09261792153120041,
      "learning_rate": 1.68710843373494e-05,
      "loss": 0.0376,
      "step": 25970
    },
    {
      "epoch": 3.130120481927711,
      "grad_norm": 8.889521598815918,
      "learning_rate": 1.6869879518072288e-05,
      "loss": 0.0753,
      "step": 25980
    },
    {
      "epoch": 3.1313253012048192,
      "grad_norm": 3.2584214210510254,
      "learning_rate": 1.6868674698795184e-05,
      "loss": 0.0229,
      "step": 25990
    },
    {
      "epoch": 3.1325301204819276,
      "grad_norm": 5.605503082275391,
      "learning_rate": 1.6867469879518076e-05,
      "loss": 0.0569,
      "step": 26000
    },
    {
      "epoch": 3.133734939759036,
      "grad_norm": 9.834375381469727,
      "learning_rate": 1.6866265060240965e-05,
      "loss": 0.1245,
      "step": 26010
    },
    {
      "epoch": 3.1349397590361447,
      "grad_norm": 0.93794184923172,
      "learning_rate": 1.6865060240963858e-05,
      "loss": 0.0667,
      "step": 26020
    },
    {
      "epoch": 3.136144578313253,
      "grad_norm": 0.2288997918367386,
      "learning_rate": 1.6863855421686747e-05,
      "loss": 0.0725,
      "step": 26030
    },
    {
      "epoch": 3.1373493975903615,
      "grad_norm": 0.2972485423088074,
      "learning_rate": 1.686265060240964e-05,
      "loss": 0.0929,
      "step": 26040
    },
    {
      "epoch": 3.13855421686747,
      "grad_norm": 1.9175256490707397,
      "learning_rate": 1.686144578313253e-05,
      "loss": 0.0167,
      "step": 26050
    },
    {
      "epoch": 3.139759036144578,
      "grad_norm": 32.169036865234375,
      "learning_rate": 1.6860240963855424e-05,
      "loss": 0.0762,
      "step": 26060
    },
    {
      "epoch": 3.1409638554216865,
      "grad_norm": 0.8169445991516113,
      "learning_rate": 1.6859036144578317e-05,
      "loss": 0.0235,
      "step": 26070
    },
    {
      "epoch": 3.1421686746987953,
      "grad_norm": 0.2376757562160492,
      "learning_rate": 1.6857831325301206e-05,
      "loss": 0.0607,
      "step": 26080
    },
    {
      "epoch": 3.1433734939759037,
      "grad_norm": 0.14052288234233856,
      "learning_rate": 1.6856626506024098e-05,
      "loss": 0.0163,
      "step": 26090
    },
    {
      "epoch": 3.144578313253012,
      "grad_norm": 1.7419928312301636,
      "learning_rate": 1.685542168674699e-05,
      "loss": 0.0681,
      "step": 26100
    },
    {
      "epoch": 3.1457831325301204,
      "grad_norm": 0.09817593544721603,
      "learning_rate": 1.6854216867469883e-05,
      "loss": 0.052,
      "step": 26110
    },
    {
      "epoch": 3.146987951807229,
      "grad_norm": 0.878078818321228,
      "learning_rate": 1.6853012048192772e-05,
      "loss": 0.0149,
      "step": 26120
    },
    {
      "epoch": 3.148192771084337,
      "grad_norm": 8.070270538330078,
      "learning_rate": 1.6851807228915664e-05,
      "loss": 0.1109,
      "step": 26130
    },
    {
      "epoch": 3.149397590361446,
      "grad_norm": 0.05910024791955948,
      "learning_rate": 1.6850602409638553e-05,
      "loss": 0.0216,
      "step": 26140
    },
    {
      "epoch": 3.1506024096385543,
      "grad_norm": 4.452776908874512,
      "learning_rate": 1.6849397590361446e-05,
      "loss": 0.0914,
      "step": 26150
    },
    {
      "epoch": 3.1518072289156627,
      "grad_norm": 4.576009273529053,
      "learning_rate": 1.6848192771084338e-05,
      "loss": 0.0873,
      "step": 26160
    },
    {
      "epoch": 3.153012048192771,
      "grad_norm": 0.0800064206123352,
      "learning_rate": 1.684698795180723e-05,
      "loss": 0.0101,
      "step": 26170
    },
    {
      "epoch": 3.1542168674698794,
      "grad_norm": 0.48798656463623047,
      "learning_rate": 1.6845783132530123e-05,
      "loss": 0.0615,
      "step": 26180
    },
    {
      "epoch": 3.1554216867469878,
      "grad_norm": 30.84395408630371,
      "learning_rate": 1.6844578313253012e-05,
      "loss": 0.046,
      "step": 26190
    },
    {
      "epoch": 3.1566265060240966,
      "grad_norm": 0.15044832229614258,
      "learning_rate": 1.6843373493975905e-05,
      "loss": 0.0456,
      "step": 26200
    },
    {
      "epoch": 3.157831325301205,
      "grad_norm": 3.884406566619873,
      "learning_rate": 1.6842168674698797e-05,
      "loss": 0.1349,
      "step": 26210
    },
    {
      "epoch": 3.1590361445783133,
      "grad_norm": 0.06481903046369553,
      "learning_rate": 1.684096385542169e-05,
      "loss": 0.0584,
      "step": 26220
    },
    {
      "epoch": 3.1602409638554216,
      "grad_norm": 3.1064701080322266,
      "learning_rate": 1.6839759036144582e-05,
      "loss": 0.1142,
      "step": 26230
    },
    {
      "epoch": 3.16144578313253,
      "grad_norm": 7.3680100440979,
      "learning_rate": 1.683855421686747e-05,
      "loss": 0.0659,
      "step": 26240
    },
    {
      "epoch": 3.1626506024096384,
      "grad_norm": 5.156304836273193,
      "learning_rate": 1.6837349397590363e-05,
      "loss": 0.0847,
      "step": 26250
    },
    {
      "epoch": 3.163855421686747,
      "grad_norm": 0.17517346143722534,
      "learning_rate": 1.6836144578313252e-05,
      "loss": 0.0317,
      "step": 26260
    },
    {
      "epoch": 3.1650602409638555,
      "grad_norm": 0.2617555856704712,
      "learning_rate": 1.6834939759036145e-05,
      "loss": 0.059,
      "step": 26270
    },
    {
      "epoch": 3.166265060240964,
      "grad_norm": 0.08920858055353165,
      "learning_rate": 1.6833734939759037e-05,
      "loss": 0.0753,
      "step": 26280
    },
    {
      "epoch": 3.1674698795180722,
      "grad_norm": 1.203094244003296,
      "learning_rate": 1.683253012048193e-05,
      "loss": 0.0202,
      "step": 26290
    },
    {
      "epoch": 3.1686746987951806,
      "grad_norm": 6.004008769989014,
      "learning_rate": 1.6831325301204822e-05,
      "loss": 0.1487,
      "step": 26300
    },
    {
      "epoch": 3.169879518072289,
      "grad_norm": 0.3282317817211151,
      "learning_rate": 1.683012048192771e-05,
      "loss": 0.054,
      "step": 26310
    },
    {
      "epoch": 3.1710843373493978,
      "grad_norm": 7.994946479797363,
      "learning_rate": 1.6828915662650604e-05,
      "loss": 0.114,
      "step": 26320
    },
    {
      "epoch": 3.172289156626506,
      "grad_norm": 0.1751353144645691,
      "learning_rate": 1.6827710843373496e-05,
      "loss": 0.0644,
      "step": 26330
    },
    {
      "epoch": 3.1734939759036145,
      "grad_norm": 0.19138644635677338,
      "learning_rate": 1.682650602409639e-05,
      "loss": 0.0793,
      "step": 26340
    },
    {
      "epoch": 3.174698795180723,
      "grad_norm": 6.072001934051514,
      "learning_rate": 1.6825301204819278e-05,
      "loss": 0.0902,
      "step": 26350
    },
    {
      "epoch": 3.175903614457831,
      "grad_norm": 12.983019828796387,
      "learning_rate": 1.682409638554217e-05,
      "loss": 0.0371,
      "step": 26360
    },
    {
      "epoch": 3.1771084337349396,
      "grad_norm": 0.4078042805194855,
      "learning_rate": 1.6822891566265062e-05,
      "loss": 0.0731,
      "step": 26370
    },
    {
      "epoch": 3.1783132530120484,
      "grad_norm": 0.057945024222135544,
      "learning_rate": 1.682168674698795e-05,
      "loss": 0.0342,
      "step": 26380
    },
    {
      "epoch": 3.1795180722891567,
      "grad_norm": 0.11347431689500809,
      "learning_rate": 1.6820481927710844e-05,
      "loss": 0.05,
      "step": 26390
    },
    {
      "epoch": 3.180722891566265,
      "grad_norm": 0.16104423999786377,
      "learning_rate": 1.6819277108433736e-05,
      "loss": 0.0286,
      "step": 26400
    },
    {
      "epoch": 3.1819277108433734,
      "grad_norm": 0.10562007874250412,
      "learning_rate": 1.681807228915663e-05,
      "loss": 0.0364,
      "step": 26410
    },
    {
      "epoch": 3.183132530120482,
      "grad_norm": 1.027530312538147,
      "learning_rate": 1.6816867469879518e-05,
      "loss": 0.0996,
      "step": 26420
    },
    {
      "epoch": 3.18433734939759,
      "grad_norm": 0.21920964121818542,
      "learning_rate": 1.681566265060241e-05,
      "loss": 0.0782,
      "step": 26430
    },
    {
      "epoch": 3.185542168674699,
      "grad_norm": 0.07091505080461502,
      "learning_rate": 1.6814457831325303e-05,
      "loss": 0.0638,
      "step": 26440
    },
    {
      "epoch": 3.1867469879518073,
      "grad_norm": 0.09488457441329956,
      "learning_rate": 1.6813253012048195e-05,
      "loss": 0.0669,
      "step": 26450
    },
    {
      "epoch": 3.1879518072289157,
      "grad_norm": 4.9313063621521,
      "learning_rate": 1.6812048192771088e-05,
      "loss": 0.0199,
      "step": 26460
    },
    {
      "epoch": 3.189156626506024,
      "grad_norm": 0.03541585057973862,
      "learning_rate": 1.6810843373493977e-05,
      "loss": 0.0721,
      "step": 26470
    },
    {
      "epoch": 3.1903614457831324,
      "grad_norm": 2.7213025093078613,
      "learning_rate": 1.680963855421687e-05,
      "loss": 0.0806,
      "step": 26480
    },
    {
      "epoch": 3.1915662650602408,
      "grad_norm": 11.054094314575195,
      "learning_rate": 1.6808433734939758e-05,
      "loss": 0.0465,
      "step": 26490
    },
    {
      "epoch": 3.1927710843373496,
      "grad_norm": 2.8837890625,
      "learning_rate": 1.680722891566265e-05,
      "loss": 0.0464,
      "step": 26500
    },
    {
      "epoch": 3.193975903614458,
      "grad_norm": 1.93407142162323,
      "learning_rate": 1.6806024096385543e-05,
      "loss": 0.0824,
      "step": 26510
    },
    {
      "epoch": 3.1951807228915663,
      "grad_norm": 11.155102729797363,
      "learning_rate": 1.6804819277108435e-05,
      "loss": 0.1184,
      "step": 26520
    },
    {
      "epoch": 3.1963855421686747,
      "grad_norm": 3.4218454360961914,
      "learning_rate": 1.6803614457831328e-05,
      "loss": 0.0774,
      "step": 26530
    },
    {
      "epoch": 3.197590361445783,
      "grad_norm": 3.093200445175171,
      "learning_rate": 1.6802409638554217e-05,
      "loss": 0.1006,
      "step": 26540
    },
    {
      "epoch": 3.1987951807228914,
      "grad_norm": 3.256248712539673,
      "learning_rate": 1.680120481927711e-05,
      "loss": 0.0748,
      "step": 26550
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.09572318196296692,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0422,
      "step": 26560
    },
    {
      "epoch": 3.2012048192771085,
      "grad_norm": 4.604417324066162,
      "learning_rate": 1.6798795180722894e-05,
      "loss": 0.0512,
      "step": 26570
    },
    {
      "epoch": 3.202409638554217,
      "grad_norm": 0.34045425057411194,
      "learning_rate": 1.6797590361445783e-05,
      "loss": 0.0672,
      "step": 26580
    },
    {
      "epoch": 3.2036144578313253,
      "grad_norm": 0.8815582990646362,
      "learning_rate": 1.6796385542168676e-05,
      "loss": 0.0811,
      "step": 26590
    },
    {
      "epoch": 3.2048192771084336,
      "grad_norm": 0.6092846989631653,
      "learning_rate": 1.6795180722891568e-05,
      "loss": 0.069,
      "step": 26600
    },
    {
      "epoch": 3.206024096385542,
      "grad_norm": 2.183805227279663,
      "learning_rate": 1.679397590361446e-05,
      "loss": 0.0702,
      "step": 26610
    },
    {
      "epoch": 3.207228915662651,
      "grad_norm": 29.468746185302734,
      "learning_rate": 1.6792771084337353e-05,
      "loss": 0.0798,
      "step": 26620
    },
    {
      "epoch": 3.208433734939759,
      "grad_norm": 0.03591011092066765,
      "learning_rate": 1.6791566265060242e-05,
      "loss": 0.0542,
      "step": 26630
    },
    {
      "epoch": 3.2096385542168675,
      "grad_norm": 2.16982364654541,
      "learning_rate": 1.6790361445783134e-05,
      "loss": 0.0404,
      "step": 26640
    },
    {
      "epoch": 3.210843373493976,
      "grad_norm": 0.11500905454158783,
      "learning_rate": 1.6789156626506024e-05,
      "loss": 0.0555,
      "step": 26650
    },
    {
      "epoch": 3.212048192771084,
      "grad_norm": 0.03458219766616821,
      "learning_rate": 1.6787951807228916e-05,
      "loss": 0.0598,
      "step": 26660
    },
    {
      "epoch": 3.2132530120481926,
      "grad_norm": 1.0305193662643433,
      "learning_rate": 1.678674698795181e-05,
      "loss": 0.087,
      "step": 26670
    },
    {
      "epoch": 3.2144578313253014,
      "grad_norm": 6.024100303649902,
      "learning_rate": 1.67855421686747e-05,
      "loss": 0.0515,
      "step": 26680
    },
    {
      "epoch": 3.2156626506024097,
      "grad_norm": 0.07609761506319046,
      "learning_rate": 1.6784337349397593e-05,
      "loss": 0.0629,
      "step": 26690
    },
    {
      "epoch": 3.216867469879518,
      "grad_norm": 0.1056930348277092,
      "learning_rate": 1.6783132530120482e-05,
      "loss": 0.0216,
      "step": 26700
    },
    {
      "epoch": 3.2180722891566265,
      "grad_norm": 0.05177391320466995,
      "learning_rate": 1.6781927710843375e-05,
      "loss": 0.052,
      "step": 26710
    },
    {
      "epoch": 3.219277108433735,
      "grad_norm": 0.5241652131080627,
      "learning_rate": 1.6780722891566267e-05,
      "loss": 0.0596,
      "step": 26720
    },
    {
      "epoch": 3.220481927710843,
      "grad_norm": 0.03315462917089462,
      "learning_rate": 1.677951807228916e-05,
      "loss": 0.0424,
      "step": 26730
    },
    {
      "epoch": 3.221686746987952,
      "grad_norm": 3.431530237197876,
      "learning_rate": 1.677831325301205e-05,
      "loss": 0.0609,
      "step": 26740
    },
    {
      "epoch": 3.2228915662650603,
      "grad_norm": 29.721054077148438,
      "learning_rate": 1.677710843373494e-05,
      "loss": 0.0774,
      "step": 26750
    },
    {
      "epoch": 3.2240963855421687,
      "grad_norm": 1.9155800342559814,
      "learning_rate": 1.6775903614457834e-05,
      "loss": 0.1134,
      "step": 26760
    },
    {
      "epoch": 3.225301204819277,
      "grad_norm": 0.29992324113845825,
      "learning_rate": 1.6774698795180723e-05,
      "loss": 0.0909,
      "step": 26770
    },
    {
      "epoch": 3.2265060240963854,
      "grad_norm": 2.1543965339660645,
      "learning_rate": 1.6773493975903615e-05,
      "loss": 0.0746,
      "step": 26780
    },
    {
      "epoch": 3.227710843373494,
      "grad_norm": 4.518555164337158,
      "learning_rate": 1.6772289156626507e-05,
      "loss": 0.0347,
      "step": 26790
    },
    {
      "epoch": 3.2289156626506026,
      "grad_norm": 8.521016120910645,
      "learning_rate": 1.67710843373494e-05,
      "loss": 0.0472,
      "step": 26800
    },
    {
      "epoch": 3.230120481927711,
      "grad_norm": 8.654586791992188,
      "learning_rate": 1.676987951807229e-05,
      "loss": 0.0351,
      "step": 26810
    },
    {
      "epoch": 3.2313253012048193,
      "grad_norm": 1.8603919744491577,
      "learning_rate": 1.676867469879518e-05,
      "loss": 0.1113,
      "step": 26820
    },
    {
      "epoch": 3.2325301204819277,
      "grad_norm": 46.339786529541016,
      "learning_rate": 1.6767469879518074e-05,
      "loss": 0.0647,
      "step": 26830
    },
    {
      "epoch": 3.233734939759036,
      "grad_norm": 1.8170804977416992,
      "learning_rate": 1.6766265060240966e-05,
      "loss": 0.0388,
      "step": 26840
    },
    {
      "epoch": 3.2349397590361444,
      "grad_norm": 0.13533321022987366,
      "learning_rate": 1.676506024096386e-05,
      "loss": 0.0481,
      "step": 26850
    },
    {
      "epoch": 3.236144578313253,
      "grad_norm": 2.147639751434326,
      "learning_rate": 1.6763855421686748e-05,
      "loss": 0.0602,
      "step": 26860
    },
    {
      "epoch": 3.2373493975903616,
      "grad_norm": 0.07540425658226013,
      "learning_rate": 1.676265060240964e-05,
      "loss": 0.0797,
      "step": 26870
    },
    {
      "epoch": 3.23855421686747,
      "grad_norm": 1.8043736219406128,
      "learning_rate": 1.676144578313253e-05,
      "loss": 0.0343,
      "step": 26880
    },
    {
      "epoch": 3.2397590361445783,
      "grad_norm": 0.13325108587741852,
      "learning_rate": 1.676024096385542e-05,
      "loss": 0.1029,
      "step": 26890
    },
    {
      "epoch": 3.2409638554216866,
      "grad_norm": 0.5252453684806824,
      "learning_rate": 1.6759036144578314e-05,
      "loss": 0.0467,
      "step": 26900
    },
    {
      "epoch": 3.242168674698795,
      "grad_norm": 3.725343942642212,
      "learning_rate": 1.6757831325301207e-05,
      "loss": 0.086,
      "step": 26910
    },
    {
      "epoch": 3.243373493975904,
      "grad_norm": 0.5330333113670349,
      "learning_rate": 1.67566265060241e-05,
      "loss": 0.1252,
      "step": 26920
    },
    {
      "epoch": 3.244578313253012,
      "grad_norm": 2.2018349170684814,
      "learning_rate": 1.6755421686746988e-05,
      "loss": 0.0887,
      "step": 26930
    },
    {
      "epoch": 3.2457831325301205,
      "grad_norm": 1.890535593032837,
      "learning_rate": 1.675421686746988e-05,
      "loss": 0.0542,
      "step": 26940
    },
    {
      "epoch": 3.246987951807229,
      "grad_norm": 26.869281768798828,
      "learning_rate": 1.6753012048192773e-05,
      "loss": 0.0302,
      "step": 26950
    },
    {
      "epoch": 3.2481927710843372,
      "grad_norm": 0.013795916922390461,
      "learning_rate": 1.6751807228915665e-05,
      "loss": 0.0396,
      "step": 26960
    },
    {
      "epoch": 3.2493975903614456,
      "grad_norm": 0.04685601592063904,
      "learning_rate": 1.6750602409638558e-05,
      "loss": 0.0729,
      "step": 26970
    },
    {
      "epoch": 3.2506024096385544,
      "grad_norm": 3.0077052116394043,
      "learning_rate": 1.6749397590361447e-05,
      "loss": 0.1074,
      "step": 26980
    },
    {
      "epoch": 3.2518072289156628,
      "grad_norm": 2.198719024658203,
      "learning_rate": 1.674819277108434e-05,
      "loss": 0.0771,
      "step": 26990
    },
    {
      "epoch": 3.253012048192771,
      "grad_norm": 14.49349308013916,
      "learning_rate": 1.6746987951807228e-05,
      "loss": 0.0958,
      "step": 27000
    },
    {
      "epoch": 3.2542168674698795,
      "grad_norm": 4.667550086975098,
      "learning_rate": 1.674578313253012e-05,
      "loss": 0.1204,
      "step": 27010
    },
    {
      "epoch": 3.255421686746988,
      "grad_norm": 0.7611319422721863,
      "learning_rate": 1.6744578313253013e-05,
      "loss": 0.0279,
      "step": 27020
    },
    {
      "epoch": 3.256626506024096,
      "grad_norm": 1.4760061502456665,
      "learning_rate": 1.6743373493975906e-05,
      "loss": 0.0426,
      "step": 27030
    },
    {
      "epoch": 3.257831325301205,
      "grad_norm": 18.78403091430664,
      "learning_rate": 1.6742168674698795e-05,
      "loss": 0.0817,
      "step": 27040
    },
    {
      "epoch": 3.2590361445783134,
      "grad_norm": 3.454662322998047,
      "learning_rate": 1.6740963855421687e-05,
      "loss": 0.0318,
      "step": 27050
    },
    {
      "epoch": 3.2602409638554217,
      "grad_norm": 0.6224161982536316,
      "learning_rate": 1.673975903614458e-05,
      "loss": 0.0615,
      "step": 27060
    },
    {
      "epoch": 3.26144578313253,
      "grad_norm": 0.10394388437271118,
      "learning_rate": 1.6738554216867472e-05,
      "loss": 0.0531,
      "step": 27070
    },
    {
      "epoch": 3.2626506024096384,
      "grad_norm": 0.47540083527565,
      "learning_rate": 1.6737349397590364e-05,
      "loss": 0.1052,
      "step": 27080
    },
    {
      "epoch": 3.263855421686747,
      "grad_norm": 5.5564045906066895,
      "learning_rate": 1.6736144578313253e-05,
      "loss": 0.136,
      "step": 27090
    },
    {
      "epoch": 3.2650602409638556,
      "grad_norm": 3.9517929553985596,
      "learning_rate": 1.6734939759036146e-05,
      "loss": 0.0611,
      "step": 27100
    },
    {
      "epoch": 3.266265060240964,
      "grad_norm": 0.5871978998184204,
      "learning_rate": 1.6733734939759035e-05,
      "loss": 0.0363,
      "step": 27110
    },
    {
      "epoch": 3.2674698795180723,
      "grad_norm": 0.3836040794849396,
      "learning_rate": 1.673253012048193e-05,
      "loss": 0.0228,
      "step": 27120
    },
    {
      "epoch": 3.2686746987951807,
      "grad_norm": 0.7250939011573792,
      "learning_rate": 1.6731325301204823e-05,
      "loss": 0.1023,
      "step": 27130
    },
    {
      "epoch": 3.269879518072289,
      "grad_norm": 9.097030639648438,
      "learning_rate": 1.6730120481927712e-05,
      "loss": 0.0504,
      "step": 27140
    },
    {
      "epoch": 3.2710843373493974,
      "grad_norm": 3.7175188064575195,
      "learning_rate": 1.6728915662650605e-05,
      "loss": 0.0904,
      "step": 27150
    },
    {
      "epoch": 3.272289156626506,
      "grad_norm": 0.8150573372840881,
      "learning_rate": 1.6727710843373494e-05,
      "loss": 0.0753,
      "step": 27160
    },
    {
      "epoch": 3.2734939759036146,
      "grad_norm": 3.9711270332336426,
      "learning_rate": 1.6726506024096386e-05,
      "loss": 0.0693,
      "step": 27170
    },
    {
      "epoch": 3.274698795180723,
      "grad_norm": 1.9097397327423096,
      "learning_rate": 1.672530120481928e-05,
      "loss": 0.0378,
      "step": 27180
    },
    {
      "epoch": 3.2759036144578313,
      "grad_norm": 0.4498533010482788,
      "learning_rate": 1.672409638554217e-05,
      "loss": 0.0441,
      "step": 27190
    },
    {
      "epoch": 3.2771084337349397,
      "grad_norm": 6.291377067565918,
      "learning_rate": 1.6722891566265063e-05,
      "loss": 0.1124,
      "step": 27200
    },
    {
      "epoch": 3.278313253012048,
      "grad_norm": 2.2646782398223877,
      "learning_rate": 1.6721686746987952e-05,
      "loss": 0.0791,
      "step": 27210
    },
    {
      "epoch": 3.279518072289157,
      "grad_norm": 0.5469788908958435,
      "learning_rate": 1.6720481927710845e-05,
      "loss": 0.1067,
      "step": 27220
    },
    {
      "epoch": 3.280722891566265,
      "grad_norm": 3.3256900310516357,
      "learning_rate": 1.6719277108433737e-05,
      "loss": 0.0639,
      "step": 27230
    },
    {
      "epoch": 3.2819277108433735,
      "grad_norm": 4.534427165985107,
      "learning_rate": 1.671807228915663e-05,
      "loss": 0.1408,
      "step": 27240
    },
    {
      "epoch": 3.283132530120482,
      "grad_norm": 0.10616862028837204,
      "learning_rate": 1.671686746987952e-05,
      "loss": 0.0105,
      "step": 27250
    },
    {
      "epoch": 3.2843373493975903,
      "grad_norm": 0.8914650678634644,
      "learning_rate": 1.671566265060241e-05,
      "loss": 0.0898,
      "step": 27260
    },
    {
      "epoch": 3.2855421686746986,
      "grad_norm": 0.08794144541025162,
      "learning_rate": 1.6714457831325304e-05,
      "loss": 0.0508,
      "step": 27270
    },
    {
      "epoch": 3.2867469879518074,
      "grad_norm": 0.5228912234306335,
      "learning_rate": 1.6713253012048193e-05,
      "loss": 0.0682,
      "step": 27280
    },
    {
      "epoch": 3.287951807228916,
      "grad_norm": 1.8214054107666016,
      "learning_rate": 1.6712048192771085e-05,
      "loss": 0.0768,
      "step": 27290
    },
    {
      "epoch": 3.289156626506024,
      "grad_norm": 2.1843068599700928,
      "learning_rate": 1.6710843373493978e-05,
      "loss": 0.0506,
      "step": 27300
    },
    {
      "epoch": 3.2903614457831325,
      "grad_norm": 0.5939213037490845,
      "learning_rate": 1.670963855421687e-05,
      "loss": 0.0144,
      "step": 27310
    },
    {
      "epoch": 3.291566265060241,
      "grad_norm": 0.25938475131988525,
      "learning_rate": 1.670843373493976e-05,
      "loss": 0.0474,
      "step": 27320
    },
    {
      "epoch": 3.292771084337349,
      "grad_norm": 5.104830265045166,
      "learning_rate": 1.670722891566265e-05,
      "loss": 0.0787,
      "step": 27330
    },
    {
      "epoch": 3.293975903614458,
      "grad_norm": 3.6693620681762695,
      "learning_rate": 1.6706024096385544e-05,
      "loss": 0.0684,
      "step": 27340
    },
    {
      "epoch": 3.2951807228915664,
      "grad_norm": 1.9662514925003052,
      "learning_rate": 1.6704819277108436e-05,
      "loss": 0.1069,
      "step": 27350
    },
    {
      "epoch": 3.2963855421686747,
      "grad_norm": 7.378446578979492,
      "learning_rate": 1.670361445783133e-05,
      "loss": 0.1113,
      "step": 27360
    },
    {
      "epoch": 3.297590361445783,
      "grad_norm": 3.3514535427093506,
      "learning_rate": 1.6702409638554218e-05,
      "loss": 0.0879,
      "step": 27370
    },
    {
      "epoch": 3.2987951807228915,
      "grad_norm": 4.092611312866211,
      "learning_rate": 1.670120481927711e-05,
      "loss": 0.0804,
      "step": 27380
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.11408103257417679,
      "learning_rate": 1.67e-05,
      "loss": 0.0353,
      "step": 27390
    },
    {
      "epoch": 3.3012048192771086,
      "grad_norm": 13.949662208557129,
      "learning_rate": 1.6698795180722892e-05,
      "loss": 0.0495,
      "step": 27400
    },
    {
      "epoch": 3.302409638554217,
      "grad_norm": 0.14192593097686768,
      "learning_rate": 1.6697590361445784e-05,
      "loss": 0.0838,
      "step": 27410
    },
    {
      "epoch": 3.3036144578313253,
      "grad_norm": 5.291695594787598,
      "learning_rate": 1.6696385542168677e-05,
      "loss": 0.0636,
      "step": 27420
    },
    {
      "epoch": 3.3048192771084337,
      "grad_norm": 4.508517742156982,
      "learning_rate": 1.669518072289157e-05,
      "loss": 0.0953,
      "step": 27430
    },
    {
      "epoch": 3.306024096385542,
      "grad_norm": 2.758342981338501,
      "learning_rate": 1.6693975903614458e-05,
      "loss": 0.0747,
      "step": 27440
    },
    {
      "epoch": 3.3072289156626504,
      "grad_norm": 0.20182618498802185,
      "learning_rate": 1.669277108433735e-05,
      "loss": 0.0684,
      "step": 27450
    },
    {
      "epoch": 3.3084337349397592,
      "grad_norm": 0.5231675505638123,
      "learning_rate": 1.6691566265060243e-05,
      "loss": 0.0623,
      "step": 27460
    },
    {
      "epoch": 3.3096385542168676,
      "grad_norm": 34.3823356628418,
      "learning_rate": 1.6690361445783135e-05,
      "loss": 0.1014,
      "step": 27470
    },
    {
      "epoch": 3.310843373493976,
      "grad_norm": 1.3765956163406372,
      "learning_rate": 1.6689156626506024e-05,
      "loss": 0.1212,
      "step": 27480
    },
    {
      "epoch": 3.3120481927710843,
      "grad_norm": 9.701821327209473,
      "learning_rate": 1.6687951807228917e-05,
      "loss": 0.0455,
      "step": 27490
    },
    {
      "epoch": 3.3132530120481927,
      "grad_norm": 4.616878509521484,
      "learning_rate": 1.668674698795181e-05,
      "loss": 0.0536,
      "step": 27500
    },
    {
      "epoch": 3.314457831325301,
      "grad_norm": 0.050315406173467636,
      "learning_rate": 1.66855421686747e-05,
      "loss": 0.0798,
      "step": 27510
    },
    {
      "epoch": 3.31566265060241,
      "grad_norm": 7.848692893981934,
      "learning_rate": 1.668433734939759e-05,
      "loss": 0.0691,
      "step": 27520
    },
    {
      "epoch": 3.316867469879518,
      "grad_norm": 2.289454460144043,
      "learning_rate": 1.6683132530120483e-05,
      "loss": 0.0632,
      "step": 27530
    },
    {
      "epoch": 3.3180722891566266,
      "grad_norm": 4.11361026763916,
      "learning_rate": 1.6681927710843376e-05,
      "loss": 0.0642,
      "step": 27540
    },
    {
      "epoch": 3.319277108433735,
      "grad_norm": 5.824213981628418,
      "learning_rate": 1.6680722891566265e-05,
      "loss": 0.0798,
      "step": 27550
    },
    {
      "epoch": 3.3204819277108433,
      "grad_norm": 0.056690990924835205,
      "learning_rate": 1.6679518072289157e-05,
      "loss": 0.0261,
      "step": 27560
    },
    {
      "epoch": 3.3216867469879516,
      "grad_norm": 2.440331220626831,
      "learning_rate": 1.667831325301205e-05,
      "loss": 0.111,
      "step": 27570
    },
    {
      "epoch": 3.32289156626506,
      "grad_norm": 0.06535816192626953,
      "learning_rate": 1.6677108433734942e-05,
      "loss": 0.0525,
      "step": 27580
    },
    {
      "epoch": 3.324096385542169,
      "grad_norm": 9.141136169433594,
      "learning_rate": 1.6675903614457834e-05,
      "loss": 0.1117,
      "step": 27590
    },
    {
      "epoch": 3.325301204819277,
      "grad_norm": 2.925405502319336,
      "learning_rate": 1.6674698795180724e-05,
      "loss": 0.0875,
      "step": 27600
    },
    {
      "epoch": 3.3265060240963855,
      "grad_norm": 0.5565310120582581,
      "learning_rate": 1.6673493975903616e-05,
      "loss": 0.1008,
      "step": 27610
    },
    {
      "epoch": 3.327710843373494,
      "grad_norm": 2.0491204261779785,
      "learning_rate": 1.6672289156626505e-05,
      "loss": 0.0841,
      "step": 27620
    },
    {
      "epoch": 3.3289156626506022,
      "grad_norm": 9.166755676269531,
      "learning_rate": 1.6671084337349397e-05,
      "loss": 0.1166,
      "step": 27630
    },
    {
      "epoch": 3.330120481927711,
      "grad_norm": 13.084972381591797,
      "learning_rate": 1.666987951807229e-05,
      "loss": 0.0737,
      "step": 27640
    },
    {
      "epoch": 3.3313253012048194,
      "grad_norm": 1.4796898365020752,
      "learning_rate": 1.6668674698795182e-05,
      "loss": 0.0916,
      "step": 27650
    },
    {
      "epoch": 3.3325301204819278,
      "grad_norm": 0.282308429479599,
      "learning_rate": 1.6667469879518075e-05,
      "loss": 0.0306,
      "step": 27660
    },
    {
      "epoch": 3.333734939759036,
      "grad_norm": 9.012731552124023,
      "learning_rate": 1.6666265060240964e-05,
      "loss": 0.0365,
      "step": 27670
    },
    {
      "epoch": 3.3349397590361445,
      "grad_norm": 0.2655320167541504,
      "learning_rate": 1.6665060240963856e-05,
      "loss": 0.0712,
      "step": 27680
    },
    {
      "epoch": 3.336144578313253,
      "grad_norm": 5.032983779907227,
      "learning_rate": 1.666385542168675e-05,
      "loss": 0.1879,
      "step": 27690
    },
    {
      "epoch": 3.337349397590361,
      "grad_norm": 4.658780574798584,
      "learning_rate": 1.666265060240964e-05,
      "loss": 0.0591,
      "step": 27700
    },
    {
      "epoch": 3.33855421686747,
      "grad_norm": 0.4050604999065399,
      "learning_rate": 1.666144578313253e-05,
      "loss": 0.0754,
      "step": 27710
    },
    {
      "epoch": 3.3397590361445784,
      "grad_norm": 1.6646056175231934,
      "learning_rate": 1.6660240963855423e-05,
      "loss": 0.1073,
      "step": 27720
    },
    {
      "epoch": 3.3409638554216867,
      "grad_norm": 9.897492408752441,
      "learning_rate": 1.6659036144578315e-05,
      "loss": 0.0576,
      "step": 27730
    },
    {
      "epoch": 3.342168674698795,
      "grad_norm": 2.289375066757202,
      "learning_rate": 1.6657831325301207e-05,
      "loss": 0.063,
      "step": 27740
    },
    {
      "epoch": 3.3433734939759034,
      "grad_norm": 4.35339879989624,
      "learning_rate": 1.66566265060241e-05,
      "loss": 0.0401,
      "step": 27750
    },
    {
      "epoch": 3.3445783132530122,
      "grad_norm": 3.100318670272827,
      "learning_rate": 1.665542168674699e-05,
      "loss": 0.1116,
      "step": 27760
    },
    {
      "epoch": 3.3457831325301206,
      "grad_norm": 0.04470933601260185,
      "learning_rate": 1.665421686746988e-05,
      "loss": 0.1007,
      "step": 27770
    },
    {
      "epoch": 3.346987951807229,
      "grad_norm": 0.47288310527801514,
      "learning_rate": 1.665301204819277e-05,
      "loss": 0.0525,
      "step": 27780
    },
    {
      "epoch": 3.3481927710843373,
      "grad_norm": 5.459960460662842,
      "learning_rate": 1.6651807228915663e-05,
      "loss": 0.107,
      "step": 27790
    },
    {
      "epoch": 3.3493975903614457,
      "grad_norm": 5.043856620788574,
      "learning_rate": 1.6650602409638555e-05,
      "loss": 0.1015,
      "step": 27800
    },
    {
      "epoch": 3.350602409638554,
      "grad_norm": 3.535763740539551,
      "learning_rate": 1.6649397590361448e-05,
      "loss": 0.0517,
      "step": 27810
    },
    {
      "epoch": 3.3518072289156624,
      "grad_norm": 0.4081851840019226,
      "learning_rate": 1.664819277108434e-05,
      "loss": 0.0123,
      "step": 27820
    },
    {
      "epoch": 3.353012048192771,
      "grad_norm": 0.8460297584533691,
      "learning_rate": 1.664698795180723e-05,
      "loss": 0.072,
      "step": 27830
    },
    {
      "epoch": 3.3542168674698796,
      "grad_norm": 0.3655186593532562,
      "learning_rate": 1.664578313253012e-05,
      "loss": 0.0662,
      "step": 27840
    },
    {
      "epoch": 3.355421686746988,
      "grad_norm": 5.960210800170898,
      "learning_rate": 1.6644578313253014e-05,
      "loss": 0.0537,
      "step": 27850
    },
    {
      "epoch": 3.3566265060240963,
      "grad_norm": 3.232088088989258,
      "learning_rate": 1.6643373493975907e-05,
      "loss": 0.0817,
      "step": 27860
    },
    {
      "epoch": 3.3578313253012047,
      "grad_norm": 0.6818039417266846,
      "learning_rate": 1.66421686746988e-05,
      "loss": 0.0264,
      "step": 27870
    },
    {
      "epoch": 3.3590361445783135,
      "grad_norm": 5.138138294219971,
      "learning_rate": 1.6640963855421688e-05,
      "loss": 0.0741,
      "step": 27880
    },
    {
      "epoch": 3.360240963855422,
      "grad_norm": 0.06772740185260773,
      "learning_rate": 1.663975903614458e-05,
      "loss": 0.044,
      "step": 27890
    },
    {
      "epoch": 3.36144578313253,
      "grad_norm": 2.9462785720825195,
      "learning_rate": 1.663855421686747e-05,
      "loss": 0.0689,
      "step": 27900
    },
    {
      "epoch": 3.3626506024096385,
      "grad_norm": 0.20093540847301483,
      "learning_rate": 1.6637349397590362e-05,
      "loss": 0.0514,
      "step": 27910
    },
    {
      "epoch": 3.363855421686747,
      "grad_norm": 8.133833885192871,
      "learning_rate": 1.6636144578313254e-05,
      "loss": 0.1186,
      "step": 27920
    },
    {
      "epoch": 3.3650602409638553,
      "grad_norm": 0.058916885405778885,
      "learning_rate": 1.6634939759036147e-05,
      "loss": 0.0734,
      "step": 27930
    },
    {
      "epoch": 3.3662650602409636,
      "grad_norm": 0.6913279294967651,
      "learning_rate": 1.6633734939759036e-05,
      "loss": 0.1067,
      "step": 27940
    },
    {
      "epoch": 3.3674698795180724,
      "grad_norm": 0.05566032603383064,
      "learning_rate": 1.6632530120481928e-05,
      "loss": 0.0925,
      "step": 27950
    },
    {
      "epoch": 3.3686746987951808,
      "grad_norm": 3.6596994400024414,
      "learning_rate": 1.663132530120482e-05,
      "loss": 0.0816,
      "step": 27960
    },
    {
      "epoch": 3.369879518072289,
      "grad_norm": 0.03666534647345543,
      "learning_rate": 1.6630120481927713e-05,
      "loss": 0.0717,
      "step": 27970
    },
    {
      "epoch": 3.3710843373493975,
      "grad_norm": 3.5050976276397705,
      "learning_rate": 1.6628915662650606e-05,
      "loss": 0.1137,
      "step": 27980
    },
    {
      "epoch": 3.372289156626506,
      "grad_norm": 0.5617831349372864,
      "learning_rate": 1.6627710843373495e-05,
      "loss": 0.0503,
      "step": 27990
    },
    {
      "epoch": 3.3734939759036147,
      "grad_norm": 0.21974928677082062,
      "learning_rate": 1.6626506024096387e-05,
      "loss": 0.033,
      "step": 28000
    },
    {
      "epoch": 3.374698795180723,
      "grad_norm": 2.472929000854492,
      "learning_rate": 1.6625301204819276e-05,
      "loss": 0.0642,
      "step": 28010
    },
    {
      "epoch": 3.3759036144578314,
      "grad_norm": 0.049432236701250076,
      "learning_rate": 1.662409638554217e-05,
      "loss": 0.0484,
      "step": 28020
    },
    {
      "epoch": 3.3771084337349397,
      "grad_norm": 3.927672863006592,
      "learning_rate": 1.662289156626506e-05,
      "loss": 0.1115,
      "step": 28030
    },
    {
      "epoch": 3.378313253012048,
      "grad_norm": 3.227896213531494,
      "learning_rate": 1.6621686746987953e-05,
      "loss": 0.0697,
      "step": 28040
    },
    {
      "epoch": 3.3795180722891565,
      "grad_norm": 4.156235218048096,
      "learning_rate": 1.6620481927710846e-05,
      "loss": 0.0435,
      "step": 28050
    },
    {
      "epoch": 3.380722891566265,
      "grad_norm": 0.5050932765007019,
      "learning_rate": 1.6619277108433735e-05,
      "loss": 0.0371,
      "step": 28060
    },
    {
      "epoch": 3.3819277108433736,
      "grad_norm": 3.080878973007202,
      "learning_rate": 1.6618072289156627e-05,
      "loss": 0.05,
      "step": 28070
    },
    {
      "epoch": 3.383132530120482,
      "grad_norm": 1.520767092704773,
      "learning_rate": 1.661686746987952e-05,
      "loss": 0.0581,
      "step": 28080
    },
    {
      "epoch": 3.3843373493975903,
      "grad_norm": 0.09094154089689255,
      "learning_rate": 1.6615662650602412e-05,
      "loss": 0.0636,
      "step": 28090
    },
    {
      "epoch": 3.3855421686746987,
      "grad_norm": 9.869294166564941,
      "learning_rate": 1.6614457831325305e-05,
      "loss": 0.1865,
      "step": 28100
    },
    {
      "epoch": 3.386746987951807,
      "grad_norm": 4.210869312286377,
      "learning_rate": 1.6613253012048194e-05,
      "loss": 0.0175,
      "step": 28110
    },
    {
      "epoch": 3.387951807228916,
      "grad_norm": 2.4549479484558105,
      "learning_rate": 1.6612048192771086e-05,
      "loss": 0.0516,
      "step": 28120
    },
    {
      "epoch": 3.3891566265060242,
      "grad_norm": 0.5575266480445862,
      "learning_rate": 1.6610843373493975e-05,
      "loss": 0.0154,
      "step": 28130
    },
    {
      "epoch": 3.3903614457831326,
      "grad_norm": 93.76697540283203,
      "learning_rate": 1.6609638554216868e-05,
      "loss": 0.046,
      "step": 28140
    },
    {
      "epoch": 3.391566265060241,
      "grad_norm": 11.45612621307373,
      "learning_rate": 1.660843373493976e-05,
      "loss": 0.0884,
      "step": 28150
    },
    {
      "epoch": 3.3927710843373493,
      "grad_norm": 0.035982608795166016,
      "learning_rate": 1.6607228915662652e-05,
      "loss": 0.043,
      "step": 28160
    },
    {
      "epoch": 3.3939759036144577,
      "grad_norm": 0.11558803915977478,
      "learning_rate": 1.6606024096385545e-05,
      "loss": 0.0572,
      "step": 28170
    },
    {
      "epoch": 3.395180722891566,
      "grad_norm": 0.02992662601172924,
      "learning_rate": 1.6604819277108434e-05,
      "loss": 0.0466,
      "step": 28180
    },
    {
      "epoch": 3.396385542168675,
      "grad_norm": 0.31496578454971313,
      "learning_rate": 1.6603614457831326e-05,
      "loss": 0.0663,
      "step": 28190
    },
    {
      "epoch": 3.397590361445783,
      "grad_norm": 0.056435924023389816,
      "learning_rate": 1.660240963855422e-05,
      "loss": 0.0675,
      "step": 28200
    },
    {
      "epoch": 3.3987951807228916,
      "grad_norm": 11.538069725036621,
      "learning_rate": 1.660120481927711e-05,
      "loss": 0.0645,
      "step": 28210
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.057901382446289,
      "learning_rate": 1.66e-05,
      "loss": 0.0701,
      "step": 28220
    },
    {
      "epoch": 3.4012048192771083,
      "grad_norm": 2.648752212524414,
      "learning_rate": 1.6598795180722893e-05,
      "loss": 0.1014,
      "step": 28230
    },
    {
      "epoch": 3.402409638554217,
      "grad_norm": 1.0812947750091553,
      "learning_rate": 1.6597590361445782e-05,
      "loss": 0.0941,
      "step": 28240
    },
    {
      "epoch": 3.4036144578313254,
      "grad_norm": 0.4721759557723999,
      "learning_rate": 1.6596385542168678e-05,
      "loss": 0.0554,
      "step": 28250
    },
    {
      "epoch": 3.404819277108434,
      "grad_norm": 0.5150995254516602,
      "learning_rate": 1.659518072289157e-05,
      "loss": 0.0683,
      "step": 28260
    },
    {
      "epoch": 3.406024096385542,
      "grad_norm": 5.087803363800049,
      "learning_rate": 1.659397590361446e-05,
      "loss": 0.1102,
      "step": 28270
    },
    {
      "epoch": 3.4072289156626505,
      "grad_norm": 0.9109878540039062,
      "learning_rate": 1.659277108433735e-05,
      "loss": 0.0481,
      "step": 28280
    },
    {
      "epoch": 3.408433734939759,
      "grad_norm": 8.895696640014648,
      "learning_rate": 1.659156626506024e-05,
      "loss": 0.0464,
      "step": 28290
    },
    {
      "epoch": 3.4096385542168672,
      "grad_norm": 285.7054138183594,
      "learning_rate": 1.6590361445783133e-05,
      "loss": 0.1025,
      "step": 28300
    },
    {
      "epoch": 3.410843373493976,
      "grad_norm": 0.5090513229370117,
      "learning_rate": 1.6589156626506025e-05,
      "loss": 0.0713,
      "step": 28310
    },
    {
      "epoch": 3.4120481927710844,
      "grad_norm": 4.613924503326416,
      "learning_rate": 1.6587951807228918e-05,
      "loss": 0.1443,
      "step": 28320
    },
    {
      "epoch": 3.4132530120481928,
      "grad_norm": 8.255899429321289,
      "learning_rate": 1.658674698795181e-05,
      "loss": 0.0613,
      "step": 28330
    },
    {
      "epoch": 3.414457831325301,
      "grad_norm": 0.25919270515441895,
      "learning_rate": 1.65855421686747e-05,
      "loss": 0.1158,
      "step": 28340
    },
    {
      "epoch": 3.4156626506024095,
      "grad_norm": 4.189389228820801,
      "learning_rate": 1.6584337349397592e-05,
      "loss": 0.0306,
      "step": 28350
    },
    {
      "epoch": 3.4168674698795183,
      "grad_norm": 0.07981662452220917,
      "learning_rate": 1.6583132530120484e-05,
      "loss": 0.0404,
      "step": 28360
    },
    {
      "epoch": 3.4180722891566266,
      "grad_norm": 7.512853145599365,
      "learning_rate": 1.6581927710843377e-05,
      "loss": 0.1258,
      "step": 28370
    },
    {
      "epoch": 3.419277108433735,
      "grad_norm": 4.275465965270996,
      "learning_rate": 1.6580722891566266e-05,
      "loss": 0.0874,
      "step": 28380
    },
    {
      "epoch": 3.4204819277108434,
      "grad_norm": 2.536520004272461,
      "learning_rate": 1.6579518072289158e-05,
      "loss": 0.0335,
      "step": 28390
    },
    {
      "epoch": 3.4216867469879517,
      "grad_norm": 1.1139652729034424,
      "learning_rate": 1.657831325301205e-05,
      "loss": 0.0712,
      "step": 28400
    },
    {
      "epoch": 3.42289156626506,
      "grad_norm": 0.18187305331230164,
      "learning_rate": 1.657710843373494e-05,
      "loss": 0.1044,
      "step": 28410
    },
    {
      "epoch": 3.4240963855421684,
      "grad_norm": 3.144366502761841,
      "learning_rate": 1.6575903614457832e-05,
      "loss": 0.0675,
      "step": 28420
    },
    {
      "epoch": 3.4253012048192772,
      "grad_norm": 0.14358606934547424,
      "learning_rate": 1.6574698795180725e-05,
      "loss": 0.0404,
      "step": 28430
    },
    {
      "epoch": 3.4265060240963856,
      "grad_norm": 6.145718574523926,
      "learning_rate": 1.6573493975903617e-05,
      "loss": 0.0703,
      "step": 28440
    },
    {
      "epoch": 3.427710843373494,
      "grad_norm": 1.2059369087219238,
      "learning_rate": 1.6572289156626506e-05,
      "loss": 0.0918,
      "step": 28450
    },
    {
      "epoch": 3.4289156626506023,
      "grad_norm": 0.21679677069187164,
      "learning_rate": 1.65710843373494e-05,
      "loss": 0.0689,
      "step": 28460
    },
    {
      "epoch": 3.4301204819277107,
      "grad_norm": 0.6948105096817017,
      "learning_rate": 1.656987951807229e-05,
      "loss": 0.0795,
      "step": 28470
    },
    {
      "epoch": 3.4313253012048195,
      "grad_norm": 35.54526138305664,
      "learning_rate": 1.6568674698795183e-05,
      "loss": 0.1105,
      "step": 28480
    },
    {
      "epoch": 3.432530120481928,
      "grad_norm": 0.37163424491882324,
      "learning_rate": 1.6567469879518076e-05,
      "loss": 0.0355,
      "step": 28490
    },
    {
      "epoch": 3.433734939759036,
      "grad_norm": 0.10887306183576584,
      "learning_rate": 1.6566265060240965e-05,
      "loss": 0.0693,
      "step": 28500
    },
    {
      "epoch": 3.4349397590361446,
      "grad_norm": 0.041971903294324875,
      "learning_rate": 1.6565060240963857e-05,
      "loss": 0.0665,
      "step": 28510
    },
    {
      "epoch": 3.436144578313253,
      "grad_norm": 2.920664072036743,
      "learning_rate": 1.6563855421686746e-05,
      "loss": 0.0618,
      "step": 28520
    },
    {
      "epoch": 3.4373493975903613,
      "grad_norm": 9.794906616210938,
      "learning_rate": 1.656265060240964e-05,
      "loss": 0.1378,
      "step": 28530
    },
    {
      "epoch": 3.4385542168674696,
      "grad_norm": 0.17982153594493866,
      "learning_rate": 1.656144578313253e-05,
      "loss": 0.0444,
      "step": 28540
    },
    {
      "epoch": 3.4397590361445785,
      "grad_norm": 8.666274070739746,
      "learning_rate": 1.6560240963855424e-05,
      "loss": 0.0376,
      "step": 28550
    },
    {
      "epoch": 3.440963855421687,
      "grad_norm": 2.33363938331604,
      "learning_rate": 1.6559036144578316e-05,
      "loss": 0.0371,
      "step": 28560
    },
    {
      "epoch": 3.442168674698795,
      "grad_norm": 2.8582024574279785,
      "learning_rate": 1.6557831325301205e-05,
      "loss": 0.0415,
      "step": 28570
    },
    {
      "epoch": 3.4433734939759035,
      "grad_norm": 15.088441848754883,
      "learning_rate": 1.6556626506024097e-05,
      "loss": 0.1341,
      "step": 28580
    },
    {
      "epoch": 3.444578313253012,
      "grad_norm": 4.439570426940918,
      "learning_rate": 1.655542168674699e-05,
      "loss": 0.071,
      "step": 28590
    },
    {
      "epoch": 3.4457831325301207,
      "grad_norm": 1.1330245733261108,
      "learning_rate": 1.6554216867469882e-05,
      "loss": 0.0336,
      "step": 28600
    },
    {
      "epoch": 3.446987951807229,
      "grad_norm": 15.470048904418945,
      "learning_rate": 1.655301204819277e-05,
      "loss": 0.1177,
      "step": 28610
    },
    {
      "epoch": 3.4481927710843374,
      "grad_norm": 5.703914165496826,
      "learning_rate": 1.6551807228915664e-05,
      "loss": 0.0495,
      "step": 28620
    },
    {
      "epoch": 3.4493975903614458,
      "grad_norm": 1.6190434694290161,
      "learning_rate": 1.6550602409638556e-05,
      "loss": 0.1029,
      "step": 28630
    },
    {
      "epoch": 3.450602409638554,
      "grad_norm": 1.0928305387496948,
      "learning_rate": 1.6549397590361445e-05,
      "loss": 0.0745,
      "step": 28640
    },
    {
      "epoch": 3.4518072289156625,
      "grad_norm": 0.13902394473552704,
      "learning_rate": 1.6548192771084338e-05,
      "loss": 0.0556,
      "step": 28650
    },
    {
      "epoch": 3.453012048192771,
      "grad_norm": 2.3352484703063965,
      "learning_rate": 1.654698795180723e-05,
      "loss": 0.0353,
      "step": 28660
    },
    {
      "epoch": 3.4542168674698797,
      "grad_norm": 0.233582004904747,
      "learning_rate": 1.6545783132530123e-05,
      "loss": 0.0585,
      "step": 28670
    },
    {
      "epoch": 3.455421686746988,
      "grad_norm": 3.1565091609954834,
      "learning_rate": 1.654457831325301e-05,
      "loss": 0.0651,
      "step": 28680
    },
    {
      "epoch": 3.4566265060240964,
      "grad_norm": 0.1698964685201645,
      "learning_rate": 1.6543373493975904e-05,
      "loss": 0.0984,
      "step": 28690
    },
    {
      "epoch": 3.4578313253012047,
      "grad_norm": 0.7295335531234741,
      "learning_rate": 1.6542168674698797e-05,
      "loss": 0.0535,
      "step": 28700
    },
    {
      "epoch": 3.459036144578313,
      "grad_norm": 1.264926791191101,
      "learning_rate": 1.654096385542169e-05,
      "loss": 0.0326,
      "step": 28710
    },
    {
      "epoch": 3.460240963855422,
      "grad_norm": 11.202779769897461,
      "learning_rate": 1.653975903614458e-05,
      "loss": 0.0518,
      "step": 28720
    },
    {
      "epoch": 3.4614457831325303,
      "grad_norm": 0.1684335172176361,
      "learning_rate": 1.653855421686747e-05,
      "loss": 0.0468,
      "step": 28730
    },
    {
      "epoch": 3.4626506024096386,
      "grad_norm": 0.8449482321739197,
      "learning_rate": 1.6537349397590363e-05,
      "loss": 0.0602,
      "step": 28740
    },
    {
      "epoch": 3.463855421686747,
      "grad_norm": 0.3881760835647583,
      "learning_rate": 1.6536144578313252e-05,
      "loss": 0.1044,
      "step": 28750
    },
    {
      "epoch": 3.4650602409638553,
      "grad_norm": 1.3146560192108154,
      "learning_rate": 1.6534939759036144e-05,
      "loss": 0.0493,
      "step": 28760
    },
    {
      "epoch": 3.4662650602409637,
      "grad_norm": 2.2225899696350098,
      "learning_rate": 1.653373493975904e-05,
      "loss": 0.071,
      "step": 28770
    },
    {
      "epoch": 3.467469879518072,
      "grad_norm": 0.0384853258728981,
      "learning_rate": 1.653253012048193e-05,
      "loss": 0.0427,
      "step": 28780
    },
    {
      "epoch": 3.468674698795181,
      "grad_norm": 1.3266172409057617,
      "learning_rate": 1.653132530120482e-05,
      "loss": 0.0598,
      "step": 28790
    },
    {
      "epoch": 3.4698795180722892,
      "grad_norm": 5.160793781280518,
      "learning_rate": 1.653012048192771e-05,
      "loss": 0.0731,
      "step": 28800
    },
    {
      "epoch": 3.4710843373493976,
      "grad_norm": 6.562557220458984,
      "learning_rate": 1.6528915662650603e-05,
      "loss": 0.0485,
      "step": 28810
    },
    {
      "epoch": 3.472289156626506,
      "grad_norm": 6.998154640197754,
      "learning_rate": 1.6527710843373496e-05,
      "loss": 0.1251,
      "step": 28820
    },
    {
      "epoch": 3.4734939759036143,
      "grad_norm": 0.5230711102485657,
      "learning_rate": 1.6526506024096388e-05,
      "loss": 0.0281,
      "step": 28830
    },
    {
      "epoch": 3.474698795180723,
      "grad_norm": 16.248266220092773,
      "learning_rate": 1.6525301204819277e-05,
      "loss": 0.0957,
      "step": 28840
    },
    {
      "epoch": 3.4759036144578315,
      "grad_norm": 1.7789357900619507,
      "learning_rate": 1.652409638554217e-05,
      "loss": 0.1199,
      "step": 28850
    },
    {
      "epoch": 3.47710843373494,
      "grad_norm": 14.694721221923828,
      "learning_rate": 1.6522891566265062e-05,
      "loss": 0.0919,
      "step": 28860
    },
    {
      "epoch": 3.478313253012048,
      "grad_norm": 0.2994018495082855,
      "learning_rate": 1.6521686746987954e-05,
      "loss": 0.0552,
      "step": 28870
    },
    {
      "epoch": 3.4795180722891565,
      "grad_norm": 0.08908776193857193,
      "learning_rate": 1.6520481927710847e-05,
      "loss": 0.0611,
      "step": 28880
    },
    {
      "epoch": 3.480722891566265,
      "grad_norm": 25.561769485473633,
      "learning_rate": 1.6519277108433736e-05,
      "loss": 0.0761,
      "step": 28890
    },
    {
      "epoch": 3.4819277108433733,
      "grad_norm": 1.188668966293335,
      "learning_rate": 1.6518072289156628e-05,
      "loss": 0.0816,
      "step": 28900
    },
    {
      "epoch": 3.483132530120482,
      "grad_norm": 3.6142947673797607,
      "learning_rate": 1.6516867469879517e-05,
      "loss": 0.0627,
      "step": 28910
    },
    {
      "epoch": 3.4843373493975904,
      "grad_norm": 6.029285430908203,
      "learning_rate": 1.651566265060241e-05,
      "loss": 0.062,
      "step": 28920
    },
    {
      "epoch": 3.485542168674699,
      "grad_norm": 11.14476490020752,
      "learning_rate": 1.6514457831325302e-05,
      "loss": 0.0556,
      "step": 28930
    },
    {
      "epoch": 3.486746987951807,
      "grad_norm": 2.2109546661376953,
      "learning_rate": 1.6513253012048195e-05,
      "loss": 0.0621,
      "step": 28940
    },
    {
      "epoch": 3.4879518072289155,
      "grad_norm": 3.9108917713165283,
      "learning_rate": 1.6512048192771087e-05,
      "loss": 0.1149,
      "step": 28950
    },
    {
      "epoch": 3.4891566265060243,
      "grad_norm": 2.371847629547119,
      "learning_rate": 1.6510843373493976e-05,
      "loss": 0.0978,
      "step": 28960
    },
    {
      "epoch": 3.4903614457831327,
      "grad_norm": 4.843067169189453,
      "learning_rate": 1.650963855421687e-05,
      "loss": 0.0503,
      "step": 28970
    },
    {
      "epoch": 3.491566265060241,
      "grad_norm": 10.130696296691895,
      "learning_rate": 1.650843373493976e-05,
      "loss": 0.0649,
      "step": 28980
    },
    {
      "epoch": 3.4927710843373494,
      "grad_norm": 4.295697212219238,
      "learning_rate": 1.6507228915662653e-05,
      "loss": 0.1431,
      "step": 28990
    },
    {
      "epoch": 3.4939759036144578,
      "grad_norm": 0.34467774629592896,
      "learning_rate": 1.6506024096385546e-05,
      "loss": 0.0519,
      "step": 29000
    },
    {
      "epoch": 3.495180722891566,
      "grad_norm": 1.93345308303833,
      "learning_rate": 1.6504819277108435e-05,
      "loss": 0.0828,
      "step": 29010
    },
    {
      "epoch": 3.4963855421686745,
      "grad_norm": 1.1002851724624634,
      "learning_rate": 1.6503614457831327e-05,
      "loss": 0.0559,
      "step": 29020
    },
    {
      "epoch": 3.4975903614457833,
      "grad_norm": 2.2575604915618896,
      "learning_rate": 1.6502409638554216e-05,
      "loss": 0.0311,
      "step": 29030
    },
    {
      "epoch": 3.4987951807228916,
      "grad_norm": 1.0557564496994019,
      "learning_rate": 1.650120481927711e-05,
      "loss": 0.0625,
      "step": 29040
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.298994302749634,
      "learning_rate": 1.65e-05,
      "loss": 0.0382,
      "step": 29050
    },
    {
      "epoch": 3.5012048192771084,
      "grad_norm": 0.4673475921154022,
      "learning_rate": 1.6498795180722894e-05,
      "loss": 0.076,
      "step": 29060
    },
    {
      "epoch": 3.5024096385542167,
      "grad_norm": 1.885562777519226,
      "learning_rate": 1.6497590361445786e-05,
      "loss": 0.0407,
      "step": 29070
    },
    {
      "epoch": 3.5036144578313255,
      "grad_norm": 12.066434860229492,
      "learning_rate": 1.6496385542168675e-05,
      "loss": 0.1707,
      "step": 29080
    },
    {
      "epoch": 3.504819277108434,
      "grad_norm": 9.881409645080566,
      "learning_rate": 1.6495180722891568e-05,
      "loss": 0.0866,
      "step": 29090
    },
    {
      "epoch": 3.5060240963855422,
      "grad_norm": 3.1614203453063965,
      "learning_rate": 1.649397590361446e-05,
      "loss": 0.1066,
      "step": 29100
    },
    {
      "epoch": 3.5072289156626506,
      "grad_norm": 2.643174648284912,
      "learning_rate": 1.6492771084337352e-05,
      "loss": 0.0744,
      "step": 29110
    },
    {
      "epoch": 3.508433734939759,
      "grad_norm": 14.684094429016113,
      "learning_rate": 1.649156626506024e-05,
      "loss": 0.1091,
      "step": 29120
    },
    {
      "epoch": 3.5096385542168673,
      "grad_norm": 16.53411865234375,
      "learning_rate": 1.6490361445783134e-05,
      "loss": 0.1065,
      "step": 29130
    },
    {
      "epoch": 3.5108433734939757,
      "grad_norm": 8.708229064941406,
      "learning_rate": 1.6489156626506026e-05,
      "loss": 0.0209,
      "step": 29140
    },
    {
      "epoch": 3.5120481927710845,
      "grad_norm": 0.631342351436615,
      "learning_rate": 1.6487951807228915e-05,
      "loss": 0.046,
      "step": 29150
    },
    {
      "epoch": 3.513253012048193,
      "grad_norm": 6.973851680755615,
      "learning_rate": 1.6486746987951808e-05,
      "loss": 0.048,
      "step": 29160
    },
    {
      "epoch": 3.514457831325301,
      "grad_norm": 10.247248649597168,
      "learning_rate": 1.64855421686747e-05,
      "loss": 0.1248,
      "step": 29170
    },
    {
      "epoch": 3.5156626506024096,
      "grad_norm": 0.39747482538223267,
      "learning_rate": 1.6484337349397593e-05,
      "loss": 0.0631,
      "step": 29180
    },
    {
      "epoch": 3.516867469879518,
      "grad_norm": 1.436899185180664,
      "learning_rate": 1.6483132530120482e-05,
      "loss": 0.1192,
      "step": 29190
    },
    {
      "epoch": 3.5180722891566267,
      "grad_norm": 0.7175518274307251,
      "learning_rate": 1.6481927710843374e-05,
      "loss": 0.0591,
      "step": 29200
    },
    {
      "epoch": 3.519277108433735,
      "grad_norm": 4.831859111785889,
      "learning_rate": 1.6480722891566267e-05,
      "loss": 0.0882,
      "step": 29210
    },
    {
      "epoch": 3.5204819277108435,
      "grad_norm": 4.143465042114258,
      "learning_rate": 1.647951807228916e-05,
      "loss": 0.0638,
      "step": 29220
    },
    {
      "epoch": 3.521686746987952,
      "grad_norm": 1.2171823978424072,
      "learning_rate": 1.647831325301205e-05,
      "loss": 0.0421,
      "step": 29230
    },
    {
      "epoch": 3.52289156626506,
      "grad_norm": 60.57237243652344,
      "learning_rate": 1.647710843373494e-05,
      "loss": 0.0502,
      "step": 29240
    },
    {
      "epoch": 3.5240963855421685,
      "grad_norm": 0.07127854228019714,
      "learning_rate": 1.6475903614457833e-05,
      "loss": 0.0533,
      "step": 29250
    },
    {
      "epoch": 3.525301204819277,
      "grad_norm": 5.491479396820068,
      "learning_rate": 1.6474698795180722e-05,
      "loss": 0.0373,
      "step": 29260
    },
    {
      "epoch": 3.5265060240963857,
      "grad_norm": 0.22519971430301666,
      "learning_rate": 1.6473493975903615e-05,
      "loss": 0.0797,
      "step": 29270
    },
    {
      "epoch": 3.527710843373494,
      "grad_norm": 1.9882595539093018,
      "learning_rate": 1.6472289156626507e-05,
      "loss": 0.0507,
      "step": 29280
    },
    {
      "epoch": 3.5289156626506024,
      "grad_norm": 7.645766258239746,
      "learning_rate": 1.64710843373494e-05,
      "loss": 0.0987,
      "step": 29290
    },
    {
      "epoch": 3.5301204819277108,
      "grad_norm": 3.47708797454834,
      "learning_rate": 1.6469879518072292e-05,
      "loss": 0.078,
      "step": 29300
    },
    {
      "epoch": 3.531325301204819,
      "grad_norm": 1.5829216241836548,
      "learning_rate": 1.646867469879518e-05,
      "loss": 0.0789,
      "step": 29310
    },
    {
      "epoch": 3.532530120481928,
      "grad_norm": 0.18173453211784363,
      "learning_rate": 1.6467469879518073e-05,
      "loss": 0.0385,
      "step": 29320
    },
    {
      "epoch": 3.5337349397590363,
      "grad_norm": 2.9462192058563232,
      "learning_rate": 1.6466265060240966e-05,
      "loss": 0.0903,
      "step": 29330
    },
    {
      "epoch": 3.5349397590361447,
      "grad_norm": 0.13497638702392578,
      "learning_rate": 1.6465060240963858e-05,
      "loss": 0.0367,
      "step": 29340
    },
    {
      "epoch": 3.536144578313253,
      "grad_norm": 2.70444917678833,
      "learning_rate": 1.6463855421686747e-05,
      "loss": 0.0585,
      "step": 29350
    },
    {
      "epoch": 3.5373493975903614,
      "grad_norm": 52.22235107421875,
      "learning_rate": 1.646265060240964e-05,
      "loss": 0.1573,
      "step": 29360
    },
    {
      "epoch": 3.5385542168674697,
      "grad_norm": 7.870243549346924,
      "learning_rate": 1.6461445783132532e-05,
      "loss": 0.1252,
      "step": 29370
    },
    {
      "epoch": 3.539759036144578,
      "grad_norm": 3.8127524852752686,
      "learning_rate": 1.646024096385542e-05,
      "loss": 0.0504,
      "step": 29380
    },
    {
      "epoch": 3.540963855421687,
      "grad_norm": 0.23632432520389557,
      "learning_rate": 1.6459036144578317e-05,
      "loss": 0.0709,
      "step": 29390
    },
    {
      "epoch": 3.5421686746987953,
      "grad_norm": 5.0837507247924805,
      "learning_rate": 1.6457831325301206e-05,
      "loss": 0.0884,
      "step": 29400
    },
    {
      "epoch": 3.5433734939759036,
      "grad_norm": 4.557967662811279,
      "learning_rate": 1.64566265060241e-05,
      "loss": 0.0812,
      "step": 29410
    },
    {
      "epoch": 3.544578313253012,
      "grad_norm": 63.28343200683594,
      "learning_rate": 1.6455421686746987e-05,
      "loss": 0.0879,
      "step": 29420
    },
    {
      "epoch": 3.5457831325301203,
      "grad_norm": 7.044811248779297,
      "learning_rate": 1.645421686746988e-05,
      "loss": 0.0311,
      "step": 29430
    },
    {
      "epoch": 3.546987951807229,
      "grad_norm": 0.2363113909959793,
      "learning_rate": 1.6453012048192772e-05,
      "loss": 0.0224,
      "step": 29440
    },
    {
      "epoch": 3.5481927710843375,
      "grad_norm": 0.03996085748076439,
      "learning_rate": 1.6451807228915665e-05,
      "loss": 0.0664,
      "step": 29450
    },
    {
      "epoch": 3.549397590361446,
      "grad_norm": 0.9785535931587219,
      "learning_rate": 1.6450602409638557e-05,
      "loss": 0.0707,
      "step": 29460
    },
    {
      "epoch": 3.5506024096385542,
      "grad_norm": 0.026972142979502678,
      "learning_rate": 1.6449397590361446e-05,
      "loss": 0.0352,
      "step": 29470
    },
    {
      "epoch": 3.5518072289156626,
      "grad_norm": 0.018979858607053757,
      "learning_rate": 1.644819277108434e-05,
      "loss": 0.0641,
      "step": 29480
    },
    {
      "epoch": 3.553012048192771,
      "grad_norm": 0.05981255695223808,
      "learning_rate": 1.644698795180723e-05,
      "loss": 0.0671,
      "step": 29490
    },
    {
      "epoch": 3.5542168674698793,
      "grad_norm": 3.787665843963623,
      "learning_rate": 1.6445783132530124e-05,
      "loss": 0.1458,
      "step": 29500
    },
    {
      "epoch": 3.555421686746988,
      "grad_norm": 0.09072708338499069,
      "learning_rate": 1.6444578313253013e-05,
      "loss": 0.0461,
      "step": 29510
    },
    {
      "epoch": 3.5566265060240965,
      "grad_norm": 31.608299255371094,
      "learning_rate": 1.6443373493975905e-05,
      "loss": 0.1158,
      "step": 29520
    },
    {
      "epoch": 3.557831325301205,
      "grad_norm": 8.499691009521484,
      "learning_rate": 1.6442168674698797e-05,
      "loss": 0.0685,
      "step": 29530
    },
    {
      "epoch": 3.559036144578313,
      "grad_norm": 0.08705303072929382,
      "learning_rate": 1.6440963855421687e-05,
      "loss": 0.0723,
      "step": 29540
    },
    {
      "epoch": 3.5602409638554215,
      "grad_norm": 7.44955587387085,
      "learning_rate": 1.643975903614458e-05,
      "loss": 0.0264,
      "step": 29550
    },
    {
      "epoch": 3.5614457831325304,
      "grad_norm": 2.036285877227783,
      "learning_rate": 1.643855421686747e-05,
      "loss": 0.0447,
      "step": 29560
    },
    {
      "epoch": 3.5626506024096387,
      "grad_norm": 0.34479251503944397,
      "learning_rate": 1.6437349397590364e-05,
      "loss": 0.0731,
      "step": 29570
    },
    {
      "epoch": 3.563855421686747,
      "grad_norm": 3.6241300106048584,
      "learning_rate": 1.6436144578313253e-05,
      "loss": 0.0857,
      "step": 29580
    },
    {
      "epoch": 3.5650602409638554,
      "grad_norm": 4.495842456817627,
      "learning_rate": 1.6434939759036145e-05,
      "loss": 0.0776,
      "step": 29590
    },
    {
      "epoch": 3.566265060240964,
      "grad_norm": 0.11421778798103333,
      "learning_rate": 1.6433734939759038e-05,
      "loss": 0.0209,
      "step": 29600
    },
    {
      "epoch": 3.567469879518072,
      "grad_norm": 0.6795980334281921,
      "learning_rate": 1.643253012048193e-05,
      "loss": 0.0494,
      "step": 29610
    },
    {
      "epoch": 3.5686746987951805,
      "grad_norm": 0.16619861125946045,
      "learning_rate": 1.6431325301204823e-05,
      "loss": 0.0892,
      "step": 29620
    },
    {
      "epoch": 3.5698795180722893,
      "grad_norm": 8.140278816223145,
      "learning_rate": 1.643012048192771e-05,
      "loss": 0.1027,
      "step": 29630
    },
    {
      "epoch": 3.5710843373493977,
      "grad_norm": 0.10103074461221695,
      "learning_rate": 1.6428915662650604e-05,
      "loss": 0.0142,
      "step": 29640
    },
    {
      "epoch": 3.572289156626506,
      "grad_norm": 0.04998794198036194,
      "learning_rate": 1.6427710843373493e-05,
      "loss": 0.0296,
      "step": 29650
    },
    {
      "epoch": 3.5734939759036144,
      "grad_norm": 0.09519195556640625,
      "learning_rate": 1.6426506024096386e-05,
      "loss": 0.04,
      "step": 29660
    },
    {
      "epoch": 3.5746987951807228,
      "grad_norm": 0.14817966520786285,
      "learning_rate": 1.6425301204819278e-05,
      "loss": 0.0725,
      "step": 29670
    },
    {
      "epoch": 3.5759036144578316,
      "grad_norm": 0.2634754776954651,
      "learning_rate": 1.642409638554217e-05,
      "loss": 0.0744,
      "step": 29680
    },
    {
      "epoch": 3.57710843373494,
      "grad_norm": 2.5446674823760986,
      "learning_rate": 1.6422891566265063e-05,
      "loss": 0.05,
      "step": 29690
    },
    {
      "epoch": 3.5783132530120483,
      "grad_norm": 0.27127134799957275,
      "learning_rate": 1.6421686746987952e-05,
      "loss": 0.0135,
      "step": 29700
    },
    {
      "epoch": 3.5795180722891566,
      "grad_norm": 4.554290294647217,
      "learning_rate": 1.6420481927710844e-05,
      "loss": 0.0461,
      "step": 29710
    },
    {
      "epoch": 3.580722891566265,
      "grad_norm": 1.830647587776184,
      "learning_rate": 1.6419277108433737e-05,
      "loss": 0.1219,
      "step": 29720
    },
    {
      "epoch": 3.5819277108433734,
      "grad_norm": 11.119424819946289,
      "learning_rate": 1.641807228915663e-05,
      "loss": 0.0611,
      "step": 29730
    },
    {
      "epoch": 3.5831325301204817,
      "grad_norm": 0.013176016509532928,
      "learning_rate": 1.641686746987952e-05,
      "loss": 0.0503,
      "step": 29740
    },
    {
      "epoch": 3.5843373493975905,
      "grad_norm": 0.024627286940813065,
      "learning_rate": 1.641566265060241e-05,
      "loss": 0.0447,
      "step": 29750
    },
    {
      "epoch": 3.585542168674699,
      "grad_norm": 0.8658360838890076,
      "learning_rate": 1.6414457831325303e-05,
      "loss": 0.1168,
      "step": 29760
    },
    {
      "epoch": 3.5867469879518072,
      "grad_norm": 1.3400285243988037,
      "learning_rate": 1.6413253012048192e-05,
      "loss": 0.0384,
      "step": 29770
    },
    {
      "epoch": 3.5879518072289156,
      "grad_norm": 0.018768828362226486,
      "learning_rate": 1.6412048192771085e-05,
      "loss": 0.0405,
      "step": 29780
    },
    {
      "epoch": 3.589156626506024,
      "grad_norm": 0.18944016098976135,
      "learning_rate": 1.6410843373493977e-05,
      "loss": 0.0346,
      "step": 29790
    },
    {
      "epoch": 3.5903614457831328,
      "grad_norm": 3.944831371307373,
      "learning_rate": 1.640963855421687e-05,
      "loss": 0.0846,
      "step": 29800
    },
    {
      "epoch": 3.591566265060241,
      "grad_norm": 0.04888944700360298,
      "learning_rate": 1.640843373493976e-05,
      "loss": 0.0883,
      "step": 29810
    },
    {
      "epoch": 3.5927710843373495,
      "grad_norm": 0.03983737900853157,
      "learning_rate": 1.640722891566265e-05,
      "loss": 0.0383,
      "step": 29820
    },
    {
      "epoch": 3.593975903614458,
      "grad_norm": 0.10892235487699509,
      "learning_rate": 1.6406024096385543e-05,
      "loss": 0.0681,
      "step": 29830
    },
    {
      "epoch": 3.595180722891566,
      "grad_norm": 3.881578207015991,
      "learning_rate": 1.6404819277108436e-05,
      "loss": 0.0439,
      "step": 29840
    },
    {
      "epoch": 3.5963855421686746,
      "grad_norm": 2.8957691192626953,
      "learning_rate": 1.6403614457831328e-05,
      "loss": 0.0604,
      "step": 29850
    },
    {
      "epoch": 3.597590361445783,
      "grad_norm": 2.101972818374634,
      "learning_rate": 1.6402409638554217e-05,
      "loss": 0.0894,
      "step": 29860
    },
    {
      "epoch": 3.5987951807228917,
      "grad_norm": 0.04572011157870293,
      "learning_rate": 1.640120481927711e-05,
      "loss": 0.0182,
      "step": 29870
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.0532795786857605,
      "learning_rate": 1.64e-05,
      "loss": 0.044,
      "step": 29880
    },
    {
      "epoch": 3.6012048192771084,
      "grad_norm": 0.31414666771888733,
      "learning_rate": 1.639879518072289e-05,
      "loss": 0.0746,
      "step": 29890
    },
    {
      "epoch": 3.602409638554217,
      "grad_norm": 3.686345338821411,
      "learning_rate": 1.6397590361445787e-05,
      "loss": 0.0912,
      "step": 29900
    },
    {
      "epoch": 3.603614457831325,
      "grad_norm": 3.5521862506866455,
      "learning_rate": 1.6396385542168676e-05,
      "loss": 0.0592,
      "step": 29910
    },
    {
      "epoch": 3.604819277108434,
      "grad_norm": 0.5553306937217712,
      "learning_rate": 1.639518072289157e-05,
      "loss": 0.058,
      "step": 29920
    },
    {
      "epoch": 3.6060240963855423,
      "grad_norm": 2.3390424251556396,
      "learning_rate": 1.6393975903614458e-05,
      "loss": 0.1148,
      "step": 29930
    },
    {
      "epoch": 3.6072289156626507,
      "grad_norm": 5.564435958862305,
      "learning_rate": 1.639277108433735e-05,
      "loss": 0.0354,
      "step": 29940
    },
    {
      "epoch": 3.608433734939759,
      "grad_norm": 0.021391797810792923,
      "learning_rate": 1.6391566265060242e-05,
      "loss": 0.0111,
      "step": 29950
    },
    {
      "epoch": 3.6096385542168674,
      "grad_norm": 0.07640440762042999,
      "learning_rate": 1.6390361445783135e-05,
      "loss": 0.1036,
      "step": 29960
    },
    {
      "epoch": 3.6108433734939758,
      "grad_norm": 0.5432169437408447,
      "learning_rate": 1.6389156626506027e-05,
      "loss": 0.0435,
      "step": 29970
    },
    {
      "epoch": 3.612048192771084,
      "grad_norm": 0.17508579790592194,
      "learning_rate": 1.6387951807228916e-05,
      "loss": 0.0894,
      "step": 29980
    },
    {
      "epoch": 3.613253012048193,
      "grad_norm": 0.23961955308914185,
      "learning_rate": 1.638674698795181e-05,
      "loss": 0.1759,
      "step": 29990
    },
    {
      "epoch": 3.6144578313253013,
      "grad_norm": 0.6271026730537415,
      "learning_rate": 1.63855421686747e-05,
      "loss": 0.0335,
      "step": 30000
    },
    {
      "epoch": 3.6156626506024097,
      "grad_norm": 2.305154323577881,
      "learning_rate": 1.6384337349397594e-05,
      "loss": 0.0916,
      "step": 30010
    },
    {
      "epoch": 3.616867469879518,
      "grad_norm": 16.22994041442871,
      "learning_rate": 1.6383132530120483e-05,
      "loss": 0.0614,
      "step": 30020
    },
    {
      "epoch": 3.6180722891566264,
      "grad_norm": 6.99080753326416,
      "learning_rate": 1.6381927710843375e-05,
      "loss": 0.0743,
      "step": 30030
    },
    {
      "epoch": 3.619277108433735,
      "grad_norm": 1.58367919921875,
      "learning_rate": 1.6380722891566268e-05,
      "loss": 0.0433,
      "step": 30040
    },
    {
      "epoch": 3.6204819277108435,
      "grad_norm": 0.1323566436767578,
      "learning_rate": 1.6379518072289157e-05,
      "loss": 0.0197,
      "step": 30050
    },
    {
      "epoch": 3.621686746987952,
      "grad_norm": 0.3232460916042328,
      "learning_rate": 1.637831325301205e-05,
      "loss": 0.0187,
      "step": 30060
    },
    {
      "epoch": 3.6228915662650603,
      "grad_norm": 1.9663184881210327,
      "learning_rate": 1.637710843373494e-05,
      "loss": 0.1118,
      "step": 30070
    },
    {
      "epoch": 3.6240963855421686,
      "grad_norm": 0.3029560148715973,
      "learning_rate": 1.6375903614457834e-05,
      "loss": 0.0779,
      "step": 30080
    },
    {
      "epoch": 3.625301204819277,
      "grad_norm": 5.190894603729248,
      "learning_rate": 1.6374698795180723e-05,
      "loss": 0.0606,
      "step": 30090
    },
    {
      "epoch": 3.6265060240963853,
      "grad_norm": 1.8337935209274292,
      "learning_rate": 1.6373493975903615e-05,
      "loss": 0.066,
      "step": 30100
    },
    {
      "epoch": 3.627710843373494,
      "grad_norm": 1.9625701904296875,
      "learning_rate": 1.6372289156626508e-05,
      "loss": 0.0368,
      "step": 30110
    },
    {
      "epoch": 3.6289156626506025,
      "grad_norm": 0.48652103543281555,
      "learning_rate": 1.63710843373494e-05,
      "loss": 0.1021,
      "step": 30120
    },
    {
      "epoch": 3.630120481927711,
      "grad_norm": 4.373330116271973,
      "learning_rate": 1.6369879518072293e-05,
      "loss": 0.0871,
      "step": 30130
    },
    {
      "epoch": 3.6313253012048192,
      "grad_norm": 33.518123626708984,
      "learning_rate": 1.6368674698795182e-05,
      "loss": 0.1141,
      "step": 30140
    },
    {
      "epoch": 3.6325301204819276,
      "grad_norm": 0.24532948434352875,
      "learning_rate": 1.6367469879518074e-05,
      "loss": 0.0159,
      "step": 30150
    },
    {
      "epoch": 3.6337349397590364,
      "grad_norm": 2.454197406768799,
      "learning_rate": 1.6366265060240963e-05,
      "loss": 0.084,
      "step": 30160
    },
    {
      "epoch": 3.6349397590361443,
      "grad_norm": 5.864934921264648,
      "learning_rate": 1.6365060240963856e-05,
      "loss": 0.0965,
      "step": 30170
    },
    {
      "epoch": 3.636144578313253,
      "grad_norm": 3.2730753421783447,
      "learning_rate": 1.6363855421686748e-05,
      "loss": 0.0561,
      "step": 30180
    },
    {
      "epoch": 3.6373493975903615,
      "grad_norm": 0.5312891006469727,
      "learning_rate": 1.636265060240964e-05,
      "loss": 0.0712,
      "step": 30190
    },
    {
      "epoch": 3.63855421686747,
      "grad_norm": 0.5352979898452759,
      "learning_rate": 1.6361445783132533e-05,
      "loss": 0.0447,
      "step": 30200
    },
    {
      "epoch": 3.639759036144578,
      "grad_norm": 0.05552074685692787,
      "learning_rate": 1.6360240963855422e-05,
      "loss": 0.021,
      "step": 30210
    },
    {
      "epoch": 3.6409638554216865,
      "grad_norm": 0.3488418757915497,
      "learning_rate": 1.6359036144578315e-05,
      "loss": 0.0443,
      "step": 30220
    },
    {
      "epoch": 3.6421686746987953,
      "grad_norm": 0.21997329592704773,
      "learning_rate": 1.6357831325301207e-05,
      "loss": 0.0798,
      "step": 30230
    },
    {
      "epoch": 3.6433734939759037,
      "grad_norm": 1.057584524154663,
      "learning_rate": 1.63566265060241e-05,
      "loss": 0.1237,
      "step": 30240
    },
    {
      "epoch": 3.644578313253012,
      "grad_norm": 1.9787273406982422,
      "learning_rate": 1.635542168674699e-05,
      "loss": 0.087,
      "step": 30250
    },
    {
      "epoch": 3.6457831325301204,
      "grad_norm": 0.8413269519805908,
      "learning_rate": 1.635421686746988e-05,
      "loss": 0.0687,
      "step": 30260
    },
    {
      "epoch": 3.646987951807229,
      "grad_norm": 8.445930480957031,
      "learning_rate": 1.6353012048192773e-05,
      "loss": 0.0445,
      "step": 30270
    },
    {
      "epoch": 3.6481927710843376,
      "grad_norm": 0.055952027440071106,
      "learning_rate": 1.6351807228915662e-05,
      "loss": 0.0337,
      "step": 30280
    },
    {
      "epoch": 3.6493975903614455,
      "grad_norm": 0.15503062307834625,
      "learning_rate": 1.6350602409638555e-05,
      "loss": 0.0373,
      "step": 30290
    },
    {
      "epoch": 3.6506024096385543,
      "grad_norm": 0.054790984839200974,
      "learning_rate": 1.6349397590361447e-05,
      "loss": 0.0889,
      "step": 30300
    },
    {
      "epoch": 3.6518072289156627,
      "grad_norm": 0.06690852344036102,
      "learning_rate": 1.634819277108434e-05,
      "loss": 0.0417,
      "step": 30310
    },
    {
      "epoch": 3.653012048192771,
      "grad_norm": 14.21523666381836,
      "learning_rate": 1.634698795180723e-05,
      "loss": 0.1097,
      "step": 30320
    },
    {
      "epoch": 3.6542168674698794,
      "grad_norm": 0.2014441341161728,
      "learning_rate": 1.634578313253012e-05,
      "loss": 0.0385,
      "step": 30330
    },
    {
      "epoch": 3.6554216867469878,
      "grad_norm": 24.75295066833496,
      "learning_rate": 1.6344578313253014e-05,
      "loss": 0.0492,
      "step": 30340
    },
    {
      "epoch": 3.6566265060240966,
      "grad_norm": 7.020045280456543,
      "learning_rate": 1.6343373493975906e-05,
      "loss": 0.108,
      "step": 30350
    },
    {
      "epoch": 3.657831325301205,
      "grad_norm": 2.184267520904541,
      "learning_rate": 1.63421686746988e-05,
      "loss": 0.0283,
      "step": 30360
    },
    {
      "epoch": 3.6590361445783133,
      "grad_norm": 1.3143973350524902,
      "learning_rate": 1.6340963855421687e-05,
      "loss": 0.0738,
      "step": 30370
    },
    {
      "epoch": 3.6602409638554216,
      "grad_norm": 0.12576866149902344,
      "learning_rate": 1.633975903614458e-05,
      "loss": 0.0531,
      "step": 30380
    },
    {
      "epoch": 3.66144578313253,
      "grad_norm": 1.1269375085830688,
      "learning_rate": 1.633855421686747e-05,
      "loss": 0.0556,
      "step": 30390
    },
    {
      "epoch": 3.662650602409639,
      "grad_norm": 5.49226713180542,
      "learning_rate": 1.633734939759036e-05,
      "loss": 0.1427,
      "step": 30400
    },
    {
      "epoch": 3.6638554216867467,
      "grad_norm": 0.2738238275051117,
      "learning_rate": 1.6336144578313254e-05,
      "loss": 0.0247,
      "step": 30410
    },
    {
      "epoch": 3.6650602409638555,
      "grad_norm": 0.9265837669372559,
      "learning_rate": 1.6334939759036146e-05,
      "loss": 0.0885,
      "step": 30420
    },
    {
      "epoch": 3.666265060240964,
      "grad_norm": 0.16740696132183075,
      "learning_rate": 1.633373493975904e-05,
      "loss": 0.0264,
      "step": 30430
    },
    {
      "epoch": 3.6674698795180722,
      "grad_norm": 0.1251801997423172,
      "learning_rate": 1.6332530120481928e-05,
      "loss": 0.0238,
      "step": 30440
    },
    {
      "epoch": 3.6686746987951806,
      "grad_norm": 0.7610846757888794,
      "learning_rate": 1.633132530120482e-05,
      "loss": 0.0752,
      "step": 30450
    },
    {
      "epoch": 3.669879518072289,
      "grad_norm": 0.04511471465229988,
      "learning_rate": 1.6330120481927713e-05,
      "loss": 0.0464,
      "step": 30460
    },
    {
      "epoch": 3.6710843373493978,
      "grad_norm": 4.120901107788086,
      "learning_rate": 1.6328915662650605e-05,
      "loss": 0.049,
      "step": 30470
    },
    {
      "epoch": 3.672289156626506,
      "grad_norm": 3.146441698074341,
      "learning_rate": 1.6327710843373494e-05,
      "loss": 0.0308,
      "step": 30480
    },
    {
      "epoch": 3.6734939759036145,
      "grad_norm": 0.01946890540421009,
      "learning_rate": 1.6326506024096387e-05,
      "loss": 0.0657,
      "step": 30490
    },
    {
      "epoch": 3.674698795180723,
      "grad_norm": 0.044370926916599274,
      "learning_rate": 1.632530120481928e-05,
      "loss": 0.0426,
      "step": 30500
    },
    {
      "epoch": 3.675903614457831,
      "grad_norm": 1.986666202545166,
      "learning_rate": 1.6324096385542168e-05,
      "loss": 0.0281,
      "step": 30510
    },
    {
      "epoch": 3.67710843373494,
      "grad_norm": 4.601450443267822,
      "learning_rate": 1.6322891566265064e-05,
      "loss": 0.1007,
      "step": 30520
    },
    {
      "epoch": 3.678313253012048,
      "grad_norm": 0.2490576207637787,
      "learning_rate": 1.6321686746987953e-05,
      "loss": 0.067,
      "step": 30530
    },
    {
      "epoch": 3.6795180722891567,
      "grad_norm": 1.0992324352264404,
      "learning_rate": 1.6320481927710845e-05,
      "loss": 0.0383,
      "step": 30540
    },
    {
      "epoch": 3.680722891566265,
      "grad_norm": 0.023785974830389023,
      "learning_rate": 1.6319277108433734e-05,
      "loss": 0.0522,
      "step": 30550
    },
    {
      "epoch": 3.6819277108433734,
      "grad_norm": 10.447096824645996,
      "learning_rate": 1.6318072289156627e-05,
      "loss": 0.0652,
      "step": 30560
    },
    {
      "epoch": 3.683132530120482,
      "grad_norm": 9.541464805603027,
      "learning_rate": 1.631686746987952e-05,
      "loss": 0.066,
      "step": 30570
    },
    {
      "epoch": 3.68433734939759,
      "grad_norm": 4.804542064666748,
      "learning_rate": 1.631566265060241e-05,
      "loss": 0.0373,
      "step": 30580
    },
    {
      "epoch": 3.685542168674699,
      "grad_norm": 0.020639803260564804,
      "learning_rate": 1.6314457831325304e-05,
      "loss": 0.0545,
      "step": 30590
    },
    {
      "epoch": 3.6867469879518073,
      "grad_norm": 7.703486919403076,
      "learning_rate": 1.6313253012048193e-05,
      "loss": 0.0568,
      "step": 30600
    },
    {
      "epoch": 3.6879518072289157,
      "grad_norm": 2.8310458660125732,
      "learning_rate": 1.6312048192771086e-05,
      "loss": 0.0628,
      "step": 30610
    },
    {
      "epoch": 3.689156626506024,
      "grad_norm": 0.056772381067276,
      "learning_rate": 1.6310843373493978e-05,
      "loss": 0.0134,
      "step": 30620
    },
    {
      "epoch": 3.6903614457831324,
      "grad_norm": 1.1794140338897705,
      "learning_rate": 1.630963855421687e-05,
      "loss": 0.1147,
      "step": 30630
    },
    {
      "epoch": 3.691566265060241,
      "grad_norm": 0.3273998200893402,
      "learning_rate": 1.6308433734939763e-05,
      "loss": 0.1247,
      "step": 30640
    },
    {
      "epoch": 3.692771084337349,
      "grad_norm": 2.090789318084717,
      "learning_rate": 1.6307228915662652e-05,
      "loss": 0.0615,
      "step": 30650
    },
    {
      "epoch": 3.693975903614458,
      "grad_norm": 3.9911749362945557,
      "learning_rate": 1.6306024096385544e-05,
      "loss": 0.0496,
      "step": 30660
    },
    {
      "epoch": 3.6951807228915663,
      "grad_norm": 2.0946078300476074,
      "learning_rate": 1.6304819277108433e-05,
      "loss": 0.0334,
      "step": 30670
    },
    {
      "epoch": 3.6963855421686747,
      "grad_norm": 6.418437480926514,
      "learning_rate": 1.6303614457831326e-05,
      "loss": 0.0526,
      "step": 30680
    },
    {
      "epoch": 3.697590361445783,
      "grad_norm": 4.654331207275391,
      "learning_rate": 1.630240963855422e-05,
      "loss": 0.0438,
      "step": 30690
    },
    {
      "epoch": 3.6987951807228914,
      "grad_norm": 0.01637968234717846,
      "learning_rate": 1.630120481927711e-05,
      "loss": 0.0242,
      "step": 30700
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.07890794426202774,
      "learning_rate": 1.63e-05,
      "loss": 0.0845,
      "step": 30710
    },
    {
      "epoch": 3.7012048192771085,
      "grad_norm": 8.257691383361816,
      "learning_rate": 1.6298795180722892e-05,
      "loss": 0.0888,
      "step": 30720
    },
    {
      "epoch": 3.702409638554217,
      "grad_norm": 0.10424231737852097,
      "learning_rate": 1.6297590361445785e-05,
      "loss": 0.0426,
      "step": 30730
    },
    {
      "epoch": 3.7036144578313253,
      "grad_norm": 4.981168746948242,
      "learning_rate": 1.6296385542168677e-05,
      "loss": 0.0714,
      "step": 30740
    },
    {
      "epoch": 3.7048192771084336,
      "grad_norm": 0.35887375473976135,
      "learning_rate": 1.629518072289157e-05,
      "loss": 0.0424,
      "step": 30750
    },
    {
      "epoch": 3.7060240963855424,
      "grad_norm": 11.609871864318848,
      "learning_rate": 1.629397590361446e-05,
      "loss": 0.0932,
      "step": 30760
    },
    {
      "epoch": 3.7072289156626503,
      "grad_norm": 0.48611825704574585,
      "learning_rate": 1.629277108433735e-05,
      "loss": 0.0839,
      "step": 30770
    },
    {
      "epoch": 3.708433734939759,
      "grad_norm": 1.1089802980422974,
      "learning_rate": 1.629156626506024e-05,
      "loss": 0.042,
      "step": 30780
    },
    {
      "epoch": 3.7096385542168675,
      "grad_norm": 14.324577331542969,
      "learning_rate": 1.6290361445783132e-05,
      "loss": 0.1186,
      "step": 30790
    },
    {
      "epoch": 3.710843373493976,
      "grad_norm": 1.4048441648483276,
      "learning_rate": 1.6289156626506025e-05,
      "loss": 0.0325,
      "step": 30800
    },
    {
      "epoch": 3.712048192771084,
      "grad_norm": 0.6517361998558044,
      "learning_rate": 1.6287951807228917e-05,
      "loss": 0.0697,
      "step": 30810
    },
    {
      "epoch": 3.7132530120481926,
      "grad_norm": 0.4540899693965912,
      "learning_rate": 1.628674698795181e-05,
      "loss": 0.0709,
      "step": 30820
    },
    {
      "epoch": 3.7144578313253014,
      "grad_norm": 0.10383713245391846,
      "learning_rate": 1.62855421686747e-05,
      "loss": 0.046,
      "step": 30830
    },
    {
      "epoch": 3.7156626506024097,
      "grad_norm": 0.20620059967041016,
      "learning_rate": 1.628433734939759e-05,
      "loss": 0.0807,
      "step": 30840
    },
    {
      "epoch": 3.716867469879518,
      "grad_norm": 1.6948659420013428,
      "learning_rate": 1.6283132530120484e-05,
      "loss": 0.032,
      "step": 30850
    },
    {
      "epoch": 3.7180722891566265,
      "grad_norm": 0.6756315231323242,
      "learning_rate": 1.6281927710843376e-05,
      "loss": 0.0884,
      "step": 30860
    },
    {
      "epoch": 3.719277108433735,
      "grad_norm": 2.417710065841675,
      "learning_rate": 1.628072289156627e-05,
      "loss": 0.0712,
      "step": 30870
    },
    {
      "epoch": 3.7204819277108436,
      "grad_norm": 0.12929852306842804,
      "learning_rate": 1.6279518072289158e-05,
      "loss": 0.0624,
      "step": 30880
    },
    {
      "epoch": 3.7216867469879515,
      "grad_norm": 0.10674889385700226,
      "learning_rate": 1.627831325301205e-05,
      "loss": 0.0143,
      "step": 30890
    },
    {
      "epoch": 3.7228915662650603,
      "grad_norm": 9.374650001525879,
      "learning_rate": 1.627710843373494e-05,
      "loss": 0.1331,
      "step": 30900
    },
    {
      "epoch": 3.7240963855421687,
      "grad_norm": 0.2918849587440491,
      "learning_rate": 1.627590361445783e-05,
      "loss": 0.0577,
      "step": 30910
    },
    {
      "epoch": 3.725301204819277,
      "grad_norm": 0.5171006321907043,
      "learning_rate": 1.6274698795180724e-05,
      "loss": 0.0692,
      "step": 30920
    },
    {
      "epoch": 3.7265060240963854,
      "grad_norm": 0.1620587557554245,
      "learning_rate": 1.6273493975903616e-05,
      "loss": 0.0498,
      "step": 30930
    },
    {
      "epoch": 3.727710843373494,
      "grad_norm": 0.24458461999893188,
      "learning_rate": 1.627228915662651e-05,
      "loss": 0.0307,
      "step": 30940
    },
    {
      "epoch": 3.7289156626506026,
      "grad_norm": 13.245699882507324,
      "learning_rate": 1.6271084337349398e-05,
      "loss": 0.1252,
      "step": 30950
    },
    {
      "epoch": 3.730120481927711,
      "grad_norm": 71.33834075927734,
      "learning_rate": 1.626987951807229e-05,
      "loss": 0.0682,
      "step": 30960
    },
    {
      "epoch": 3.7313253012048193,
      "grad_norm": 2.649991035461426,
      "learning_rate": 1.6268674698795183e-05,
      "loss": 0.0874,
      "step": 30970
    },
    {
      "epoch": 3.7325301204819277,
      "grad_norm": 0.4582021236419678,
      "learning_rate": 1.6267469879518075e-05,
      "loss": 0.0294,
      "step": 30980
    },
    {
      "epoch": 3.733734939759036,
      "grad_norm": 0.014974657446146011,
      "learning_rate": 1.6266265060240964e-05,
      "loss": 0.0585,
      "step": 30990
    },
    {
      "epoch": 3.734939759036145,
      "grad_norm": 7.15224027633667,
      "learning_rate": 1.6265060240963857e-05,
      "loss": 0.0922,
      "step": 31000
    },
    {
      "epoch": 3.7361445783132528,
      "grad_norm": 0.17744068801403046,
      "learning_rate": 1.6263855421686746e-05,
      "loss": 0.0304,
      "step": 31010
    },
    {
      "epoch": 3.7373493975903616,
      "grad_norm": 0.27450838685035706,
      "learning_rate": 1.6262650602409638e-05,
      "loss": 0.0736,
      "step": 31020
    },
    {
      "epoch": 3.73855421686747,
      "grad_norm": 1.0170081853866577,
      "learning_rate": 1.6261445783132534e-05,
      "loss": 0.11,
      "step": 31030
    },
    {
      "epoch": 3.7397590361445783,
      "grad_norm": 12.185324668884277,
      "learning_rate": 1.6260240963855423e-05,
      "loss": 0.0595,
      "step": 31040
    },
    {
      "epoch": 3.7409638554216866,
      "grad_norm": 2.2069900035858154,
      "learning_rate": 1.6259036144578315e-05,
      "loss": 0.0598,
      "step": 31050
    },
    {
      "epoch": 3.742168674698795,
      "grad_norm": 0.4066014289855957,
      "learning_rate": 1.6257831325301205e-05,
      "loss": 0.0374,
      "step": 31060
    },
    {
      "epoch": 3.743373493975904,
      "grad_norm": 0.02479989267885685,
      "learning_rate": 1.6256626506024097e-05,
      "loss": 0.0253,
      "step": 31070
    },
    {
      "epoch": 3.744578313253012,
      "grad_norm": 0.7399506568908691,
      "learning_rate": 1.625542168674699e-05,
      "loss": 0.0438,
      "step": 31080
    },
    {
      "epoch": 3.7457831325301205,
      "grad_norm": 1.6813665628433228,
      "learning_rate": 1.6254216867469882e-05,
      "loss": 0.0893,
      "step": 31090
    },
    {
      "epoch": 3.746987951807229,
      "grad_norm": 0.05798586457967758,
      "learning_rate": 1.6253012048192774e-05,
      "loss": 0.04,
      "step": 31100
    },
    {
      "epoch": 3.7481927710843372,
      "grad_norm": 0.34036219120025635,
      "learning_rate": 1.6251807228915663e-05,
      "loss": 0.1328,
      "step": 31110
    },
    {
      "epoch": 3.749397590361446,
      "grad_norm": 0.07563295215368271,
      "learning_rate": 1.6250602409638556e-05,
      "loss": 0.0368,
      "step": 31120
    },
    {
      "epoch": 3.750602409638554,
      "grad_norm": 3.142895460128784,
      "learning_rate": 1.6249397590361445e-05,
      "loss": 0.0433,
      "step": 31130
    },
    {
      "epoch": 3.7518072289156628,
      "grad_norm": 0.6766719222068787,
      "learning_rate": 1.624819277108434e-05,
      "loss": 0.0378,
      "step": 31140
    },
    {
      "epoch": 3.753012048192771,
      "grad_norm": 7.0193867683410645,
      "learning_rate": 1.624698795180723e-05,
      "loss": 0.0288,
      "step": 31150
    },
    {
      "epoch": 3.7542168674698795,
      "grad_norm": 30.94122886657715,
      "learning_rate": 1.6245783132530122e-05,
      "loss": 0.0415,
      "step": 31160
    },
    {
      "epoch": 3.755421686746988,
      "grad_norm": 0.3311099112033844,
      "learning_rate": 1.6244578313253015e-05,
      "loss": 0.0581,
      "step": 31170
    },
    {
      "epoch": 3.756626506024096,
      "grad_norm": 0.19347107410430908,
      "learning_rate": 1.6243373493975904e-05,
      "loss": 0.0435,
      "step": 31180
    },
    {
      "epoch": 3.757831325301205,
      "grad_norm": 6.9344658851623535,
      "learning_rate": 1.6242168674698796e-05,
      "loss": 0.1075,
      "step": 31190
    },
    {
      "epoch": 3.7590361445783134,
      "grad_norm": 0.5614132881164551,
      "learning_rate": 1.624096385542169e-05,
      "loss": 0.0254,
      "step": 31200
    },
    {
      "epoch": 3.7602409638554217,
      "grad_norm": 5.025177478790283,
      "learning_rate": 1.623975903614458e-05,
      "loss": 0.1342,
      "step": 31210
    },
    {
      "epoch": 3.76144578313253,
      "grad_norm": 0.4395608603954315,
      "learning_rate": 1.623855421686747e-05,
      "loss": 0.047,
      "step": 31220
    },
    {
      "epoch": 3.7626506024096384,
      "grad_norm": 0.7563072443008423,
      "learning_rate": 1.6237349397590362e-05,
      "loss": 0.0278,
      "step": 31230
    },
    {
      "epoch": 3.7638554216867472,
      "grad_norm": 5.417100429534912,
      "learning_rate": 1.6236144578313255e-05,
      "loss": 0.0407,
      "step": 31240
    },
    {
      "epoch": 3.765060240963855,
      "grad_norm": 1.2523852586746216,
      "learning_rate": 1.6234939759036147e-05,
      "loss": 0.0255,
      "step": 31250
    },
    {
      "epoch": 3.766265060240964,
      "grad_norm": 0.03725433722138405,
      "learning_rate": 1.623373493975904e-05,
      "loss": 0.0809,
      "step": 31260
    },
    {
      "epoch": 3.7674698795180723,
      "grad_norm": 0.08345986157655716,
      "learning_rate": 1.623253012048193e-05,
      "loss": 0.1047,
      "step": 31270
    },
    {
      "epoch": 3.7686746987951807,
      "grad_norm": 0.29362061619758606,
      "learning_rate": 1.623132530120482e-05,
      "loss": 0.0339,
      "step": 31280
    },
    {
      "epoch": 3.769879518072289,
      "grad_norm": 0.15325887501239777,
      "learning_rate": 1.623012048192771e-05,
      "loss": 0.0367,
      "step": 31290
    },
    {
      "epoch": 3.7710843373493974,
      "grad_norm": 11.34970760345459,
      "learning_rate": 1.6228915662650603e-05,
      "loss": 0.0493,
      "step": 31300
    },
    {
      "epoch": 3.772289156626506,
      "grad_norm": 0.03185164928436279,
      "learning_rate": 1.6227710843373495e-05,
      "loss": 0.0611,
      "step": 31310
    },
    {
      "epoch": 3.7734939759036146,
      "grad_norm": 1.4236338138580322,
      "learning_rate": 1.6226506024096388e-05,
      "loss": 0.1109,
      "step": 31320
    },
    {
      "epoch": 3.774698795180723,
      "grad_norm": 0.0559912845492363,
      "learning_rate": 1.622530120481928e-05,
      "loss": 0.1265,
      "step": 31330
    },
    {
      "epoch": 3.7759036144578313,
      "grad_norm": 3.9523630142211914,
      "learning_rate": 1.622409638554217e-05,
      "loss": 0.0462,
      "step": 31340
    },
    {
      "epoch": 3.7771084337349397,
      "grad_norm": 3.72659969329834,
      "learning_rate": 1.622289156626506e-05,
      "loss": 0.0836,
      "step": 31350
    },
    {
      "epoch": 3.7783132530120485,
      "grad_norm": 1.855400800704956,
      "learning_rate": 1.6221686746987954e-05,
      "loss": 0.0524,
      "step": 31360
    },
    {
      "epoch": 3.7795180722891564,
      "grad_norm": 6.170168399810791,
      "learning_rate": 1.6220481927710846e-05,
      "loss": 0.1164,
      "step": 31370
    },
    {
      "epoch": 3.780722891566265,
      "grad_norm": 23.308673858642578,
      "learning_rate": 1.6219277108433735e-05,
      "loss": 0.0592,
      "step": 31380
    },
    {
      "epoch": 3.7819277108433735,
      "grad_norm": 0.06915117800235748,
      "learning_rate": 1.6218072289156628e-05,
      "loss": 0.0655,
      "step": 31390
    },
    {
      "epoch": 3.783132530120482,
      "grad_norm": 8.174774169921875,
      "learning_rate": 1.621686746987952e-05,
      "loss": 0.0829,
      "step": 31400
    },
    {
      "epoch": 3.7843373493975903,
      "grad_norm": 0.5766366720199585,
      "learning_rate": 1.621566265060241e-05,
      "loss": 0.0454,
      "step": 31410
    },
    {
      "epoch": 3.7855421686746986,
      "grad_norm": 12.884888648986816,
      "learning_rate": 1.62144578313253e-05,
      "loss": 0.0252,
      "step": 31420
    },
    {
      "epoch": 3.7867469879518074,
      "grad_norm": 13.159451484680176,
      "learning_rate": 1.6213253012048194e-05,
      "loss": 0.0781,
      "step": 31430
    },
    {
      "epoch": 3.787951807228916,
      "grad_norm": 2.133394479751587,
      "learning_rate": 1.6212048192771087e-05,
      "loss": 0.1018,
      "step": 31440
    },
    {
      "epoch": 3.789156626506024,
      "grad_norm": 0.0897185355424881,
      "learning_rate": 1.6210843373493976e-05,
      "loss": 0.0776,
      "step": 31450
    },
    {
      "epoch": 3.7903614457831325,
      "grad_norm": 0.06432735919952393,
      "learning_rate": 1.6209638554216868e-05,
      "loss": 0.0473,
      "step": 31460
    },
    {
      "epoch": 3.791566265060241,
      "grad_norm": 14.23031997680664,
      "learning_rate": 1.620843373493976e-05,
      "loss": 0.1047,
      "step": 31470
    },
    {
      "epoch": 3.7927710843373497,
      "grad_norm": 6.738197326660156,
      "learning_rate": 1.6207228915662653e-05,
      "loss": 0.0551,
      "step": 31480
    },
    {
      "epoch": 3.7939759036144576,
      "grad_norm": 1.042973518371582,
      "learning_rate": 1.6206024096385545e-05,
      "loss": 0.049,
      "step": 31490
    },
    {
      "epoch": 3.7951807228915664,
      "grad_norm": 2.4012551307678223,
      "learning_rate": 1.6204819277108434e-05,
      "loss": 0.0697,
      "step": 31500
    },
    {
      "epoch": 3.7963855421686747,
      "grad_norm": 0.17594049870967865,
      "learning_rate": 1.6203614457831327e-05,
      "loss": 0.0614,
      "step": 31510
    },
    {
      "epoch": 3.797590361445783,
      "grad_norm": 0.7755613327026367,
      "learning_rate": 1.6202409638554216e-05,
      "loss": 0.0701,
      "step": 31520
    },
    {
      "epoch": 3.7987951807228915,
      "grad_norm": 3.5270345211029053,
      "learning_rate": 1.620120481927711e-05,
      "loss": 0.0411,
      "step": 31530
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.06383728235960007,
      "learning_rate": 1.62e-05,
      "loss": 0.0883,
      "step": 31540
    },
    {
      "epoch": 3.8012048192771086,
      "grad_norm": 6.141544818878174,
      "learning_rate": 1.6198795180722893e-05,
      "loss": 0.07,
      "step": 31550
    },
    {
      "epoch": 3.802409638554217,
      "grad_norm": 1.2857637405395508,
      "learning_rate": 1.6197590361445786e-05,
      "loss": 0.0857,
      "step": 31560
    },
    {
      "epoch": 3.8036144578313253,
      "grad_norm": 2.072615623474121,
      "learning_rate": 1.6196385542168675e-05,
      "loss": 0.0493,
      "step": 31570
    },
    {
      "epoch": 3.8048192771084337,
      "grad_norm": 0.4914223551750183,
      "learning_rate": 1.6195180722891567e-05,
      "loss": 0.0422,
      "step": 31580
    },
    {
      "epoch": 3.806024096385542,
      "grad_norm": 0.1683141440153122,
      "learning_rate": 1.619397590361446e-05,
      "loss": 0.0505,
      "step": 31590
    },
    {
      "epoch": 3.807228915662651,
      "grad_norm": 5.1536359786987305,
      "learning_rate": 1.6192771084337352e-05,
      "loss": 0.0958,
      "step": 31600
    },
    {
      "epoch": 3.808433734939759,
      "grad_norm": 1.2331725358963013,
      "learning_rate": 1.619156626506024e-05,
      "loss": 0.0346,
      "step": 31610
    },
    {
      "epoch": 3.8096385542168676,
      "grad_norm": 0.036908894777297974,
      "learning_rate": 1.6190361445783133e-05,
      "loss": 0.061,
      "step": 31620
    },
    {
      "epoch": 3.810843373493976,
      "grad_norm": 1.6123796701431274,
      "learning_rate": 1.6189156626506026e-05,
      "loss": 0.0502,
      "step": 31630
    },
    {
      "epoch": 3.8120481927710843,
      "grad_norm": 4.737345218658447,
      "learning_rate": 1.6187951807228915e-05,
      "loss": 0.0521,
      "step": 31640
    },
    {
      "epoch": 3.8132530120481927,
      "grad_norm": 1.804441213607788,
      "learning_rate": 1.618674698795181e-05,
      "loss": 0.044,
      "step": 31650
    },
    {
      "epoch": 3.814457831325301,
      "grad_norm": 0.22280246019363403,
      "learning_rate": 1.61855421686747e-05,
      "loss": 0.046,
      "step": 31660
    },
    {
      "epoch": 3.81566265060241,
      "grad_norm": 4.495815753936768,
      "learning_rate": 1.6184337349397592e-05,
      "loss": 0.0614,
      "step": 31670
    },
    {
      "epoch": 3.816867469879518,
      "grad_norm": 0.4822898507118225,
      "learning_rate": 1.618313253012048e-05,
      "loss": 0.0545,
      "step": 31680
    },
    {
      "epoch": 3.8180722891566266,
      "grad_norm": 0.3355468809604645,
      "learning_rate": 1.6181927710843374e-05,
      "loss": 0.0953,
      "step": 31690
    },
    {
      "epoch": 3.819277108433735,
      "grad_norm": 0.34252864122390747,
      "learning_rate": 1.6180722891566266e-05,
      "loss": 0.0997,
      "step": 31700
    },
    {
      "epoch": 3.8204819277108433,
      "grad_norm": 0.10512884706258774,
      "learning_rate": 1.617951807228916e-05,
      "loss": 0.1419,
      "step": 31710
    },
    {
      "epoch": 3.821686746987952,
      "grad_norm": 2.48028302192688,
      "learning_rate": 1.617831325301205e-05,
      "loss": 0.0551,
      "step": 31720
    },
    {
      "epoch": 3.82289156626506,
      "grad_norm": 0.0865127295255661,
      "learning_rate": 1.617710843373494e-05,
      "loss": 0.0567,
      "step": 31730
    },
    {
      "epoch": 3.824096385542169,
      "grad_norm": 2.2780723571777344,
      "learning_rate": 1.6175903614457833e-05,
      "loss": 0.082,
      "step": 31740
    },
    {
      "epoch": 3.825301204819277,
      "grad_norm": 0.5382506847381592,
      "learning_rate": 1.6174698795180725e-05,
      "loss": 0.0413,
      "step": 31750
    },
    {
      "epoch": 3.8265060240963855,
      "grad_norm": 0.14179104566574097,
      "learning_rate": 1.6173493975903617e-05,
      "loss": 0.0719,
      "step": 31760
    },
    {
      "epoch": 3.827710843373494,
      "grad_norm": 0.5906664133071899,
      "learning_rate": 1.617228915662651e-05,
      "loss": 0.0914,
      "step": 31770
    },
    {
      "epoch": 3.8289156626506022,
      "grad_norm": 6.836513519287109,
      "learning_rate": 1.61710843373494e-05,
      "loss": 0.0582,
      "step": 31780
    },
    {
      "epoch": 3.830120481927711,
      "grad_norm": 0.3727991282939911,
      "learning_rate": 1.616987951807229e-05,
      "loss": 0.0635,
      "step": 31790
    },
    {
      "epoch": 3.8313253012048194,
      "grad_norm": 2.9383456707000732,
      "learning_rate": 1.616867469879518e-05,
      "loss": 0.0771,
      "step": 31800
    },
    {
      "epoch": 3.8325301204819278,
      "grad_norm": 0.4586329460144043,
      "learning_rate": 1.6167469879518073e-05,
      "loss": 0.0592,
      "step": 31810
    },
    {
      "epoch": 3.833734939759036,
      "grad_norm": 0.43728747963905334,
      "learning_rate": 1.6166265060240965e-05,
      "loss": 0.0121,
      "step": 31820
    },
    {
      "epoch": 3.8349397590361445,
      "grad_norm": 0.2109234631061554,
      "learning_rate": 1.6165060240963858e-05,
      "loss": 0.0846,
      "step": 31830
    },
    {
      "epoch": 3.8361445783132533,
      "grad_norm": 0.11690892279148102,
      "learning_rate": 1.616385542168675e-05,
      "loss": 0.047,
      "step": 31840
    },
    {
      "epoch": 3.837349397590361,
      "grad_norm": 8.863883972167969,
      "learning_rate": 1.616265060240964e-05,
      "loss": 0.1011,
      "step": 31850
    },
    {
      "epoch": 3.83855421686747,
      "grad_norm": 2.668592691421509,
      "learning_rate": 1.616144578313253e-05,
      "loss": 0.1529,
      "step": 31860
    },
    {
      "epoch": 3.8397590361445784,
      "grad_norm": 0.6958367824554443,
      "learning_rate": 1.6160240963855424e-05,
      "loss": 0.0933,
      "step": 31870
    },
    {
      "epoch": 3.8409638554216867,
      "grad_norm": 5.117384433746338,
      "learning_rate": 1.6159036144578316e-05,
      "loss": 0.1315,
      "step": 31880
    },
    {
      "epoch": 3.842168674698795,
      "grad_norm": 1.9126348495483398,
      "learning_rate": 1.6157831325301205e-05,
      "loss": 0.0347,
      "step": 31890
    },
    {
      "epoch": 3.8433734939759034,
      "grad_norm": 0.06501782685518265,
      "learning_rate": 1.6156626506024098e-05,
      "loss": 0.0595,
      "step": 31900
    },
    {
      "epoch": 3.8445783132530122,
      "grad_norm": 0.4455604553222656,
      "learning_rate": 1.6155421686746987e-05,
      "loss": 0.0351,
      "step": 31910
    },
    {
      "epoch": 3.8457831325301206,
      "grad_norm": 4.880772590637207,
      "learning_rate": 1.615421686746988e-05,
      "loss": 0.0477,
      "step": 31920
    },
    {
      "epoch": 3.846987951807229,
      "grad_norm": 0.06096378713846207,
      "learning_rate": 1.6153012048192772e-05,
      "loss": 0.0639,
      "step": 31930
    },
    {
      "epoch": 3.8481927710843373,
      "grad_norm": 0.04076780378818512,
      "learning_rate": 1.6151807228915664e-05,
      "loss": 0.0904,
      "step": 31940
    },
    {
      "epoch": 3.8493975903614457,
      "grad_norm": 0.8260222673416138,
      "learning_rate": 1.6150602409638557e-05,
      "loss": 0.1518,
      "step": 31950
    },
    {
      "epoch": 3.8506024096385545,
      "grad_norm": 1.0511741638183594,
      "learning_rate": 1.6149397590361446e-05,
      "loss": 0.0746,
      "step": 31960
    },
    {
      "epoch": 3.8518072289156624,
      "grad_norm": 8.093866348266602,
      "learning_rate": 1.6148192771084338e-05,
      "loss": 0.0754,
      "step": 31970
    },
    {
      "epoch": 3.853012048192771,
      "grad_norm": 2.3216440677642822,
      "learning_rate": 1.614698795180723e-05,
      "loss": 0.1036,
      "step": 31980
    },
    {
      "epoch": 3.8542168674698796,
      "grad_norm": 0.28577864170074463,
      "learning_rate": 1.6145783132530123e-05,
      "loss": 0.0476,
      "step": 31990
    },
    {
      "epoch": 3.855421686746988,
      "grad_norm": 18.729488372802734,
      "learning_rate": 1.6144578313253015e-05,
      "loss": 0.1192,
      "step": 32000
    },
    {
      "epoch": 3.8566265060240963,
      "grad_norm": 0.02951980195939541,
      "learning_rate": 1.6143373493975905e-05,
      "loss": 0.0538,
      "step": 32010
    },
    {
      "epoch": 3.8578313253012047,
      "grad_norm": 0.40933212637901306,
      "learning_rate": 1.6142168674698797e-05,
      "loss": 0.0434,
      "step": 32020
    },
    {
      "epoch": 3.8590361445783135,
      "grad_norm": 0.6277286410331726,
      "learning_rate": 1.6140963855421686e-05,
      "loss": 0.0585,
      "step": 32030
    },
    {
      "epoch": 3.860240963855422,
      "grad_norm": 0.10418284684419632,
      "learning_rate": 1.613975903614458e-05,
      "loss": 0.0448,
      "step": 32040
    },
    {
      "epoch": 3.86144578313253,
      "grad_norm": 0.1598036140203476,
      "learning_rate": 1.613855421686747e-05,
      "loss": 0.0711,
      "step": 32050
    },
    {
      "epoch": 3.8626506024096385,
      "grad_norm": 0.0626014992594719,
      "learning_rate": 1.6137349397590363e-05,
      "loss": 0.1174,
      "step": 32060
    },
    {
      "epoch": 3.863855421686747,
      "grad_norm": 3.0147440433502197,
      "learning_rate": 1.6136144578313256e-05,
      "loss": 0.0973,
      "step": 32070
    },
    {
      "epoch": 3.8650602409638557,
      "grad_norm": 0.3661283552646637,
      "learning_rate": 1.6134939759036145e-05,
      "loss": 0.0495,
      "step": 32080
    },
    {
      "epoch": 3.8662650602409636,
      "grad_norm": 0.12320619076490402,
      "learning_rate": 1.6133734939759037e-05,
      "loss": 0.0414,
      "step": 32090
    },
    {
      "epoch": 3.8674698795180724,
      "grad_norm": 2.2385408878326416,
      "learning_rate": 1.613253012048193e-05,
      "loss": 0.0581,
      "step": 32100
    },
    {
      "epoch": 3.8686746987951808,
      "grad_norm": 0.9649425148963928,
      "learning_rate": 1.6131325301204822e-05,
      "loss": 0.0527,
      "step": 32110
    },
    {
      "epoch": 3.869879518072289,
      "grad_norm": 3.8101491928100586,
      "learning_rate": 1.613012048192771e-05,
      "loss": 0.0863,
      "step": 32120
    },
    {
      "epoch": 3.8710843373493975,
      "grad_norm": 0.07248421758413315,
      "learning_rate": 1.6128915662650604e-05,
      "loss": 0.101,
      "step": 32130
    },
    {
      "epoch": 3.872289156626506,
      "grad_norm": 0.3941006660461426,
      "learning_rate": 1.6127710843373496e-05,
      "loss": 0.0419,
      "step": 32140
    },
    {
      "epoch": 3.8734939759036147,
      "grad_norm": 0.6690731644630432,
      "learning_rate": 1.6126506024096385e-05,
      "loss": 0.0336,
      "step": 32150
    },
    {
      "epoch": 3.874698795180723,
      "grad_norm": 0.026756102219223976,
      "learning_rate": 1.6125301204819278e-05,
      "loss": 0.0639,
      "step": 32160
    },
    {
      "epoch": 3.8759036144578314,
      "grad_norm": 4.114717483520508,
      "learning_rate": 1.612409638554217e-05,
      "loss": 0.0529,
      "step": 32170
    },
    {
      "epoch": 3.8771084337349397,
      "grad_norm": 1.494540810585022,
      "learning_rate": 1.6122891566265062e-05,
      "loss": 0.0437,
      "step": 32180
    },
    {
      "epoch": 3.878313253012048,
      "grad_norm": 0.5420886874198914,
      "learning_rate": 1.612168674698795e-05,
      "loss": 0.0544,
      "step": 32190
    },
    {
      "epoch": 3.8795180722891565,
      "grad_norm": 0.44819873571395874,
      "learning_rate": 1.6120481927710844e-05,
      "loss": 0.0227,
      "step": 32200
    },
    {
      "epoch": 3.880722891566265,
      "grad_norm": 0.3462452292442322,
      "learning_rate": 1.6119277108433736e-05,
      "loss": 0.0261,
      "step": 32210
    },
    {
      "epoch": 3.8819277108433736,
      "grad_norm": 0.8383684754371643,
      "learning_rate": 1.611807228915663e-05,
      "loss": 0.0698,
      "step": 32220
    },
    {
      "epoch": 3.883132530120482,
      "grad_norm": 13.404438018798828,
      "learning_rate": 1.611686746987952e-05,
      "loss": 0.0831,
      "step": 32230
    },
    {
      "epoch": 3.8843373493975903,
      "grad_norm": 5.202821254730225,
      "learning_rate": 1.611566265060241e-05,
      "loss": 0.0821,
      "step": 32240
    },
    {
      "epoch": 3.8855421686746987,
      "grad_norm": 0.17602770030498505,
      "learning_rate": 1.6114457831325303e-05,
      "loss": 0.0446,
      "step": 32250
    },
    {
      "epoch": 3.886746987951807,
      "grad_norm": 0.04792439937591553,
      "learning_rate": 1.6113253012048192e-05,
      "loss": 0.0302,
      "step": 32260
    },
    {
      "epoch": 3.887951807228916,
      "grad_norm": 55.603702545166016,
      "learning_rate": 1.6112048192771088e-05,
      "loss": 0.0497,
      "step": 32270
    },
    {
      "epoch": 3.8891566265060242,
      "grad_norm": 10.631569862365723,
      "learning_rate": 1.6110843373493977e-05,
      "loss": 0.1431,
      "step": 32280
    },
    {
      "epoch": 3.8903614457831326,
      "grad_norm": 1.5317949056625366,
      "learning_rate": 1.610963855421687e-05,
      "loss": 0.0561,
      "step": 32290
    },
    {
      "epoch": 3.891566265060241,
      "grad_norm": 0.9582651853561401,
      "learning_rate": 1.610843373493976e-05,
      "loss": 0.0894,
      "step": 32300
    },
    {
      "epoch": 3.8927710843373493,
      "grad_norm": 0.5167095065116882,
      "learning_rate": 1.610722891566265e-05,
      "loss": 0.0469,
      "step": 32310
    },
    {
      "epoch": 3.8939759036144577,
      "grad_norm": 7.011835098266602,
      "learning_rate": 1.6106024096385543e-05,
      "loss": 0.0614,
      "step": 32320
    },
    {
      "epoch": 3.895180722891566,
      "grad_norm": 0.7914678454399109,
      "learning_rate": 1.6104819277108435e-05,
      "loss": 0.0139,
      "step": 32330
    },
    {
      "epoch": 3.896385542168675,
      "grad_norm": 5.629205703735352,
      "learning_rate": 1.6103614457831328e-05,
      "loss": 0.0668,
      "step": 32340
    },
    {
      "epoch": 3.897590361445783,
      "grad_norm": 0.0698414072394371,
      "learning_rate": 1.6102409638554217e-05,
      "loss": 0.0422,
      "step": 32350
    },
    {
      "epoch": 3.8987951807228916,
      "grad_norm": 0.34555795788764954,
      "learning_rate": 1.610120481927711e-05,
      "loss": 0.0594,
      "step": 32360
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.04112148657441139,
      "learning_rate": 1.6100000000000002e-05,
      "loss": 0.0707,
      "step": 32370
    },
    {
      "epoch": 3.9012048192771083,
      "grad_norm": 0.2736515998840332,
      "learning_rate": 1.6098795180722894e-05,
      "loss": 0.0386,
      "step": 32380
    },
    {
      "epoch": 3.902409638554217,
      "grad_norm": 4.96168851852417,
      "learning_rate": 1.6097590361445787e-05,
      "loss": 0.054,
      "step": 32390
    },
    {
      "epoch": 3.9036144578313254,
      "grad_norm": 0.23684881627559662,
      "learning_rate": 1.6096385542168676e-05,
      "loss": 0.0641,
      "step": 32400
    },
    {
      "epoch": 3.904819277108434,
      "grad_norm": 13.110878944396973,
      "learning_rate": 1.6095180722891568e-05,
      "loss": 0.0649,
      "step": 32410
    },
    {
      "epoch": 3.906024096385542,
      "grad_norm": 2.2622158527374268,
      "learning_rate": 1.6093975903614457e-05,
      "loss": 0.1038,
      "step": 32420
    },
    {
      "epoch": 3.9072289156626505,
      "grad_norm": 5.869284629821777,
      "learning_rate": 1.609277108433735e-05,
      "loss": 0.0498,
      "step": 32430
    },
    {
      "epoch": 3.908433734939759,
      "grad_norm": 10.182994842529297,
      "learning_rate": 1.6091566265060242e-05,
      "loss": 0.0862,
      "step": 32440
    },
    {
      "epoch": 3.9096385542168672,
      "grad_norm": 1.0239019393920898,
      "learning_rate": 1.6090361445783134e-05,
      "loss": 0.0398,
      "step": 32450
    },
    {
      "epoch": 3.910843373493976,
      "grad_norm": 0.15746542811393738,
      "learning_rate": 1.6089156626506027e-05,
      "loss": 0.066,
      "step": 32460
    },
    {
      "epoch": 3.9120481927710844,
      "grad_norm": 1.8610193729400635,
      "learning_rate": 1.6087951807228916e-05,
      "loss": 0.0588,
      "step": 32470
    },
    {
      "epoch": 3.9132530120481928,
      "grad_norm": 0.24892239272594452,
      "learning_rate": 1.608674698795181e-05,
      "loss": 0.0405,
      "step": 32480
    },
    {
      "epoch": 3.914457831325301,
      "grad_norm": 13.10919189453125,
      "learning_rate": 1.60855421686747e-05,
      "loss": 0.0801,
      "step": 32490
    },
    {
      "epoch": 3.9156626506024095,
      "grad_norm": 0.23969747126102448,
      "learning_rate": 1.6084337349397593e-05,
      "loss": 0.0742,
      "step": 32500
    },
    {
      "epoch": 3.9168674698795183,
      "grad_norm": 10.14235782623291,
      "learning_rate": 1.6083132530120482e-05,
      "loss": 0.0536,
      "step": 32510
    },
    {
      "epoch": 3.9180722891566266,
      "grad_norm": 4.752527236938477,
      "learning_rate": 1.6081927710843375e-05,
      "loss": 0.0686,
      "step": 32520
    },
    {
      "epoch": 3.919277108433735,
      "grad_norm": 55.40552520751953,
      "learning_rate": 1.6080722891566267e-05,
      "loss": 0.0608,
      "step": 32530
    },
    {
      "epoch": 3.9204819277108434,
      "grad_norm": 60.683353424072266,
      "learning_rate": 1.6079518072289156e-05,
      "loss": 0.0593,
      "step": 32540
    },
    {
      "epoch": 3.9216867469879517,
      "grad_norm": 19.529420852661133,
      "learning_rate": 1.607831325301205e-05,
      "loss": 0.084,
      "step": 32550
    },
    {
      "epoch": 3.92289156626506,
      "grad_norm": 8.866355895996094,
      "learning_rate": 1.607710843373494e-05,
      "loss": 0.0973,
      "step": 32560
    },
    {
      "epoch": 3.9240963855421684,
      "grad_norm": 3.34273624420166,
      "learning_rate": 1.6075903614457833e-05,
      "loss": 0.0393,
      "step": 32570
    },
    {
      "epoch": 3.9253012048192772,
      "grad_norm": 4.644097328186035,
      "learning_rate": 1.6074698795180723e-05,
      "loss": 0.0547,
      "step": 32580
    },
    {
      "epoch": 3.9265060240963856,
      "grad_norm": 0.09052899479866028,
      "learning_rate": 1.6073493975903615e-05,
      "loss": 0.0348,
      "step": 32590
    },
    {
      "epoch": 3.927710843373494,
      "grad_norm": 0.8559308052062988,
      "learning_rate": 1.6072289156626507e-05,
      "loss": 0.1398,
      "step": 32600
    },
    {
      "epoch": 3.9289156626506023,
      "grad_norm": 0.8104263544082642,
      "learning_rate": 1.60710843373494e-05,
      "loss": 0.0584,
      "step": 32610
    },
    {
      "epoch": 3.9301204819277107,
      "grad_norm": 0.7158435583114624,
      "learning_rate": 1.6069879518072292e-05,
      "loss": 0.0537,
      "step": 32620
    },
    {
      "epoch": 3.9313253012048195,
      "grad_norm": 0.02158627286553383,
      "learning_rate": 1.606867469879518e-05,
      "loss": 0.0417,
      "step": 32630
    },
    {
      "epoch": 3.932530120481928,
      "grad_norm": 5.9500017166137695,
      "learning_rate": 1.6067469879518074e-05,
      "loss": 0.0272,
      "step": 32640
    },
    {
      "epoch": 3.933734939759036,
      "grad_norm": 0.4273475110530853,
      "learning_rate": 1.6066265060240963e-05,
      "loss": 0.0704,
      "step": 32650
    },
    {
      "epoch": 3.9349397590361446,
      "grad_norm": 0.0708911195397377,
      "learning_rate": 1.6065060240963855e-05,
      "loss": 0.1068,
      "step": 32660
    },
    {
      "epoch": 3.936144578313253,
      "grad_norm": 0.1840667426586151,
      "learning_rate": 1.6063855421686748e-05,
      "loss": 0.1152,
      "step": 32670
    },
    {
      "epoch": 3.9373493975903613,
      "grad_norm": 4.71335506439209,
      "learning_rate": 1.606265060240964e-05,
      "loss": 0.0346,
      "step": 32680
    },
    {
      "epoch": 3.9385542168674696,
      "grad_norm": 0.44300147891044617,
      "learning_rate": 1.6061445783132533e-05,
      "loss": 0.0636,
      "step": 32690
    },
    {
      "epoch": 3.9397590361445785,
      "grad_norm": 2.234370708465576,
      "learning_rate": 1.606024096385542e-05,
      "loss": 0.0885,
      "step": 32700
    },
    {
      "epoch": 3.940963855421687,
      "grad_norm": 0.2041381299495697,
      "learning_rate": 1.6059036144578314e-05,
      "loss": 0.0739,
      "step": 32710
    },
    {
      "epoch": 3.942168674698795,
      "grad_norm": 0.0742153525352478,
      "learning_rate": 1.6057831325301206e-05,
      "loss": 0.0352,
      "step": 32720
    },
    {
      "epoch": 3.9433734939759035,
      "grad_norm": 0.2976531386375427,
      "learning_rate": 1.60566265060241e-05,
      "loss": 0.0387,
      "step": 32730
    },
    {
      "epoch": 3.944578313253012,
      "grad_norm": 8.634031295776367,
      "learning_rate": 1.605542168674699e-05,
      "loss": 0.0637,
      "step": 32740
    },
    {
      "epoch": 3.9457831325301207,
      "grad_norm": 0.6057106256484985,
      "learning_rate": 1.605421686746988e-05,
      "loss": 0.0553,
      "step": 32750
    },
    {
      "epoch": 3.946987951807229,
      "grad_norm": 5.678911209106445,
      "learning_rate": 1.6053012048192773e-05,
      "loss": 0.0688,
      "step": 32760
    },
    {
      "epoch": 3.9481927710843374,
      "grad_norm": 1.7444915771484375,
      "learning_rate": 1.6051807228915662e-05,
      "loss": 0.0627,
      "step": 32770
    },
    {
      "epoch": 3.9493975903614458,
      "grad_norm": 0.8569410443305969,
      "learning_rate": 1.6050602409638558e-05,
      "loss": 0.0579,
      "step": 32780
    },
    {
      "epoch": 3.950602409638554,
      "grad_norm": 6.047285556793213,
      "learning_rate": 1.6049397590361447e-05,
      "loss": 0.0821,
      "step": 32790
    },
    {
      "epoch": 3.9518072289156625,
      "grad_norm": 0.6853947639465332,
      "learning_rate": 1.604819277108434e-05,
      "loss": 0.0739,
      "step": 32800
    },
    {
      "epoch": 3.953012048192771,
      "grad_norm": 0.24934951961040497,
      "learning_rate": 1.6046987951807228e-05,
      "loss": 0.0972,
      "step": 32810
    },
    {
      "epoch": 3.9542168674698797,
      "grad_norm": 0.9456605911254883,
      "learning_rate": 1.604578313253012e-05,
      "loss": 0.0886,
      "step": 32820
    },
    {
      "epoch": 3.955421686746988,
      "grad_norm": 1.5727453231811523,
      "learning_rate": 1.6044578313253013e-05,
      "loss": 0.0913,
      "step": 32830
    },
    {
      "epoch": 3.9566265060240964,
      "grad_norm": 0.2837606966495514,
      "learning_rate": 1.6043373493975905e-05,
      "loss": 0.0576,
      "step": 32840
    },
    {
      "epoch": 3.9578313253012047,
      "grad_norm": 0.12954241037368774,
      "learning_rate": 1.6042168674698798e-05,
      "loss": 0.0507,
      "step": 32850
    },
    {
      "epoch": 3.959036144578313,
      "grad_norm": 17.945886611938477,
      "learning_rate": 1.6040963855421687e-05,
      "loss": 0.0347,
      "step": 32860
    },
    {
      "epoch": 3.960240963855422,
      "grad_norm": 1.2661175727844238,
      "learning_rate": 1.603975903614458e-05,
      "loss": 0.039,
      "step": 32870
    },
    {
      "epoch": 3.9614457831325303,
      "grad_norm": 0.6907174587249756,
      "learning_rate": 1.6038554216867472e-05,
      "loss": 0.0349,
      "step": 32880
    },
    {
      "epoch": 3.9626506024096386,
      "grad_norm": 10.632761001586914,
      "learning_rate": 1.6037349397590364e-05,
      "loss": 0.0558,
      "step": 32890
    },
    {
      "epoch": 3.963855421686747,
      "grad_norm": 0.08403722941875458,
      "learning_rate": 1.6036144578313257e-05,
      "loss": 0.0237,
      "step": 32900
    },
    {
      "epoch": 3.9650602409638553,
      "grad_norm": 4.034692287445068,
      "learning_rate": 1.6034939759036146e-05,
      "loss": 0.0528,
      "step": 32910
    },
    {
      "epoch": 3.9662650602409637,
      "grad_norm": 2.3139638900756836,
      "learning_rate": 1.6033734939759038e-05,
      "loss": 0.043,
      "step": 32920
    },
    {
      "epoch": 3.967469879518072,
      "grad_norm": 0.2734734117984772,
      "learning_rate": 1.6032530120481927e-05,
      "loss": 0.0212,
      "step": 32930
    },
    {
      "epoch": 3.968674698795181,
      "grad_norm": 0.022574622184038162,
      "learning_rate": 1.603132530120482e-05,
      "loss": 0.107,
      "step": 32940
    },
    {
      "epoch": 3.9698795180722892,
      "grad_norm": 8.649139404296875,
      "learning_rate": 1.6030120481927712e-05,
      "loss": 0.0909,
      "step": 32950
    },
    {
      "epoch": 3.9710843373493976,
      "grad_norm": 16.56130027770996,
      "learning_rate": 1.6028915662650605e-05,
      "loss": 0.0874,
      "step": 32960
    },
    {
      "epoch": 3.972289156626506,
      "grad_norm": 3.691439151763916,
      "learning_rate": 1.6027710843373497e-05,
      "loss": 0.0626,
      "step": 32970
    },
    {
      "epoch": 3.9734939759036143,
      "grad_norm": 3.9235312938690186,
      "learning_rate": 1.6026506024096386e-05,
      "loss": 0.0448,
      "step": 32980
    },
    {
      "epoch": 3.974698795180723,
      "grad_norm": 2.0047683715820312,
      "learning_rate": 1.602530120481928e-05,
      "loss": 0.1406,
      "step": 32990
    },
    {
      "epoch": 3.9759036144578315,
      "grad_norm": 43.25828170776367,
      "learning_rate": 1.602409638554217e-05,
      "loss": 0.0389,
      "step": 33000
    },
    {
      "epoch": 3.97710843373494,
      "grad_norm": 0.6027385592460632,
      "learning_rate": 1.6022891566265063e-05,
      "loss": 0.0667,
      "step": 33010
    },
    {
      "epoch": 3.978313253012048,
      "grad_norm": 8.552085876464844,
      "learning_rate": 1.6021686746987952e-05,
      "loss": 0.0848,
      "step": 33020
    },
    {
      "epoch": 3.9795180722891565,
      "grad_norm": 0.1730732023715973,
      "learning_rate": 1.6020481927710845e-05,
      "loss": 0.0485,
      "step": 33030
    },
    {
      "epoch": 3.980722891566265,
      "grad_norm": 2.124113082885742,
      "learning_rate": 1.6019277108433737e-05,
      "loss": 0.043,
      "step": 33040
    },
    {
      "epoch": 3.9819277108433733,
      "grad_norm": 0.09810885041952133,
      "learning_rate": 1.6018072289156626e-05,
      "loss": 0.0582,
      "step": 33050
    },
    {
      "epoch": 3.983132530120482,
      "grad_norm": 5.45848274230957,
      "learning_rate": 1.601686746987952e-05,
      "loss": 0.0831,
      "step": 33060
    },
    {
      "epoch": 3.9843373493975904,
      "grad_norm": 0.0206602755934,
      "learning_rate": 1.601566265060241e-05,
      "loss": 0.0534,
      "step": 33070
    },
    {
      "epoch": 3.985542168674699,
      "grad_norm": 1.6721558570861816,
      "learning_rate": 1.6014457831325304e-05,
      "loss": 0.092,
      "step": 33080
    },
    {
      "epoch": 3.986746987951807,
      "grad_norm": 0.1928354799747467,
      "learning_rate": 1.6013253012048193e-05,
      "loss": 0.0122,
      "step": 33090
    },
    {
      "epoch": 3.9879518072289155,
      "grad_norm": 0.03419143334031105,
      "learning_rate": 1.6012048192771085e-05,
      "loss": 0.0831,
      "step": 33100
    },
    {
      "epoch": 3.9891566265060243,
      "grad_norm": 0.05177447199821472,
      "learning_rate": 1.6010843373493978e-05,
      "loss": 0.0519,
      "step": 33110
    },
    {
      "epoch": 3.9903614457831327,
      "grad_norm": 0.017179038375616074,
      "learning_rate": 1.600963855421687e-05,
      "loss": 0.0517,
      "step": 33120
    },
    {
      "epoch": 3.991566265060241,
      "grad_norm": 7.5188188552856445,
      "learning_rate": 1.6008433734939762e-05,
      "loss": 0.0556,
      "step": 33130
    },
    {
      "epoch": 3.9927710843373494,
      "grad_norm": 0.491422176361084,
      "learning_rate": 1.600722891566265e-05,
      "loss": 0.0552,
      "step": 33140
    },
    {
      "epoch": 3.9939759036144578,
      "grad_norm": 0.6613186001777649,
      "learning_rate": 1.6006024096385544e-05,
      "loss": 0.0614,
      "step": 33150
    },
    {
      "epoch": 3.995180722891566,
      "grad_norm": 0.019411275163292885,
      "learning_rate": 1.6004819277108433e-05,
      "loss": 0.0404,
      "step": 33160
    },
    {
      "epoch": 3.9963855421686745,
      "grad_norm": 1.8357821702957153,
      "learning_rate": 1.6003614457831325e-05,
      "loss": 0.0155,
      "step": 33170
    },
    {
      "epoch": 3.9975903614457833,
      "grad_norm": 18.47409439086914,
      "learning_rate": 1.6002409638554218e-05,
      "loss": 0.0899,
      "step": 33180
    },
    {
      "epoch": 3.9987951807228916,
      "grad_norm": 5.861011981964111,
      "learning_rate": 1.600120481927711e-05,
      "loss": 0.1268,
      "step": 33190
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3880791664123535,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0611,
      "step": 33200
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9775965504311961,
      "eval_f1": 0.9403320434402695,
      "eval_loss": 0.0659787505865097,
      "eval_precision": 0.949817173118144,
      "eval_recall": 0.9310344827586207,
      "eval_runtime": 3388.7984,
      "eval_samples_per_second": 12.597,
      "eval_steps_per_second": 0.525,
      "step": 33200
    },
    {
      "epoch": 4.001204819277109,
      "grad_norm": 2.410072088241577,
      "learning_rate": 1.5998795180722892e-05,
      "loss": 0.0492,
      "step": 33210
    },
    {
      "epoch": 4.002409638554217,
      "grad_norm": 3.580237865447998,
      "learning_rate": 1.5997590361445784e-05,
      "loss": 0.0957,
      "step": 33220
    },
    {
      "epoch": 4.0036144578313255,
      "grad_norm": 4.462005138397217,
      "learning_rate": 1.5996385542168677e-05,
      "loss": 0.0376,
      "step": 33230
    },
    {
      "epoch": 4.004819277108433,
      "grad_norm": 3.4368247985839844,
      "learning_rate": 1.599518072289157e-05,
      "loss": 0.035,
      "step": 33240
    },
    {
      "epoch": 4.006024096385542,
      "grad_norm": 0.28418734669685364,
      "learning_rate": 1.5993975903614458e-05,
      "loss": 0.0943,
      "step": 33250
    },
    {
      "epoch": 4.00722891566265,
      "grad_norm": 0.039845891296863556,
      "learning_rate": 1.599277108433735e-05,
      "loss": 0.0628,
      "step": 33260
    },
    {
      "epoch": 4.008433734939759,
      "grad_norm": 0.4259862005710602,
      "learning_rate": 1.5991566265060243e-05,
      "loss": 0.0307,
      "step": 33270
    },
    {
      "epoch": 4.009638554216868,
      "grad_norm": 0.04574393481016159,
      "learning_rate": 1.5990361445783132e-05,
      "loss": 0.0245,
      "step": 33280
    },
    {
      "epoch": 4.010843373493976,
      "grad_norm": 12.377408027648926,
      "learning_rate": 1.5989156626506024e-05,
      "loss": 0.1455,
      "step": 33290
    },
    {
      "epoch": 4.0120481927710845,
      "grad_norm": 2.966959238052368,
      "learning_rate": 1.5987951807228917e-05,
      "loss": 0.0545,
      "step": 33300
    },
    {
      "epoch": 4.013253012048192,
      "grad_norm": 0.08566300570964813,
      "learning_rate": 1.598674698795181e-05,
      "loss": 0.0485,
      "step": 33310
    },
    {
      "epoch": 4.014457831325301,
      "grad_norm": 0.4849635064601898,
      "learning_rate": 1.59855421686747e-05,
      "loss": 0.051,
      "step": 33320
    },
    {
      "epoch": 4.01566265060241,
      "grad_norm": 0.9524651765823364,
      "learning_rate": 1.598433734939759e-05,
      "loss": 0.0678,
      "step": 33330
    },
    {
      "epoch": 4.016867469879518,
      "grad_norm": 0.05831971764564514,
      "learning_rate": 1.5983132530120483e-05,
      "loss": 0.0266,
      "step": 33340
    },
    {
      "epoch": 4.018072289156627,
      "grad_norm": 4.928552150726318,
      "learning_rate": 1.5981927710843376e-05,
      "loss": 0.0581,
      "step": 33350
    },
    {
      "epoch": 4.019277108433735,
      "grad_norm": 0.02339821681380272,
      "learning_rate": 1.5980722891566268e-05,
      "loss": 0.0188,
      "step": 33360
    },
    {
      "epoch": 4.0204819277108435,
      "grad_norm": 3.437136650085449,
      "learning_rate": 1.5979518072289157e-05,
      "loss": 0.0889,
      "step": 33370
    },
    {
      "epoch": 4.021686746987951,
      "grad_norm": 0.8336079120635986,
      "learning_rate": 1.597831325301205e-05,
      "loss": 0.0431,
      "step": 33380
    },
    {
      "epoch": 4.02289156626506,
      "grad_norm": 0.09938962757587433,
      "learning_rate": 1.597710843373494e-05,
      "loss": 0.0552,
      "step": 33390
    },
    {
      "epoch": 4.024096385542169,
      "grad_norm": 0.0674315094947815,
      "learning_rate": 1.5975903614457834e-05,
      "loss": 0.0986,
      "step": 33400
    },
    {
      "epoch": 4.025301204819277,
      "grad_norm": 1.0429424047470093,
      "learning_rate": 1.5974698795180727e-05,
      "loss": 0.0426,
      "step": 33410
    },
    {
      "epoch": 4.026506024096386,
      "grad_norm": 1.090478777885437,
      "learning_rate": 1.5973493975903616e-05,
      "loss": 0.0649,
      "step": 33420
    },
    {
      "epoch": 4.027710843373494,
      "grad_norm": 5.64985466003418,
      "learning_rate": 1.597228915662651e-05,
      "loss": 0.1351,
      "step": 33430
    },
    {
      "epoch": 4.028915662650602,
      "grad_norm": 2.2989752292633057,
      "learning_rate": 1.5971084337349397e-05,
      "loss": 0.0583,
      "step": 33440
    },
    {
      "epoch": 4.030120481927711,
      "grad_norm": 1.782906174659729,
      "learning_rate": 1.596987951807229e-05,
      "loss": 0.0718,
      "step": 33450
    },
    {
      "epoch": 4.031325301204819,
      "grad_norm": 0.6085088849067688,
      "learning_rate": 1.5968674698795182e-05,
      "loss": 0.039,
      "step": 33460
    },
    {
      "epoch": 4.032530120481928,
      "grad_norm": 3.496981143951416,
      "learning_rate": 1.5967469879518075e-05,
      "loss": 0.0516,
      "step": 33470
    },
    {
      "epoch": 4.033734939759036,
      "grad_norm": 0.17196796834468842,
      "learning_rate": 1.5966265060240964e-05,
      "loss": 0.0756,
      "step": 33480
    },
    {
      "epoch": 4.034939759036145,
      "grad_norm": 1.4104793071746826,
      "learning_rate": 1.5965060240963856e-05,
      "loss": 0.0353,
      "step": 33490
    },
    {
      "epoch": 4.036144578313253,
      "grad_norm": 0.3325929045677185,
      "learning_rate": 1.596385542168675e-05,
      "loss": 0.0519,
      "step": 33500
    },
    {
      "epoch": 4.037349397590361,
      "grad_norm": 1.1231160163879395,
      "learning_rate": 1.596265060240964e-05,
      "loss": 0.0226,
      "step": 33510
    },
    {
      "epoch": 4.03855421686747,
      "grad_norm": 14.513633728027344,
      "learning_rate": 1.5961445783132533e-05,
      "loss": 0.0285,
      "step": 33520
    },
    {
      "epoch": 4.039759036144578,
      "grad_norm": 0.016179997473955154,
      "learning_rate": 1.5960240963855423e-05,
      "loss": 0.0376,
      "step": 33530
    },
    {
      "epoch": 4.040963855421687,
      "grad_norm": 0.04751545935869217,
      "learning_rate": 1.5959036144578315e-05,
      "loss": 0.0382,
      "step": 33540
    },
    {
      "epoch": 4.042168674698795,
      "grad_norm": 0.11226217448711395,
      "learning_rate": 1.5957831325301204e-05,
      "loss": 0.0726,
      "step": 33550
    },
    {
      "epoch": 4.043373493975904,
      "grad_norm": 4.0745530128479,
      "learning_rate": 1.5956626506024096e-05,
      "loss": 0.0333,
      "step": 33560
    },
    {
      "epoch": 4.044578313253012,
      "grad_norm": 3.359793186187744,
      "learning_rate": 1.595542168674699e-05,
      "loss": 0.0503,
      "step": 33570
    },
    {
      "epoch": 4.04578313253012,
      "grad_norm": 0.09441765397787094,
      "learning_rate": 1.595421686746988e-05,
      "loss": 0.0406,
      "step": 33580
    },
    {
      "epoch": 4.046987951807229,
      "grad_norm": 0.5464387536048889,
      "learning_rate": 1.5953012048192774e-05,
      "loss": 0.0303,
      "step": 33590
    },
    {
      "epoch": 4.048192771084337,
      "grad_norm": 23.853809356689453,
      "learning_rate": 1.5951807228915663e-05,
      "loss": 0.0044,
      "step": 33600
    },
    {
      "epoch": 4.049397590361446,
      "grad_norm": 5.51497220993042,
      "learning_rate": 1.5950602409638555e-05,
      "loss": 0.102,
      "step": 33610
    },
    {
      "epoch": 4.050602409638554,
      "grad_norm": 28.9471435546875,
      "learning_rate": 1.5949397590361448e-05,
      "loss": 0.0696,
      "step": 33620
    },
    {
      "epoch": 4.051807228915663,
      "grad_norm": 0.030345739796757698,
      "learning_rate": 1.594819277108434e-05,
      "loss": 0.064,
      "step": 33630
    },
    {
      "epoch": 4.053012048192771,
      "grad_norm": 2.42637038230896,
      "learning_rate": 1.5946987951807233e-05,
      "loss": 0.0785,
      "step": 33640
    },
    {
      "epoch": 4.054216867469879,
      "grad_norm": 1.046002984046936,
      "learning_rate": 1.594578313253012e-05,
      "loss": 0.019,
      "step": 33650
    },
    {
      "epoch": 4.055421686746988,
      "grad_norm": 0.058684807270765305,
      "learning_rate": 1.5944578313253014e-05,
      "loss": 0.0341,
      "step": 33660
    },
    {
      "epoch": 4.056626506024096,
      "grad_norm": 1.382146954536438,
      "learning_rate": 1.5943373493975903e-05,
      "loss": 0.0279,
      "step": 33670
    },
    {
      "epoch": 4.057831325301205,
      "grad_norm": 0.01637119986116886,
      "learning_rate": 1.5942168674698796e-05,
      "loss": 0.0171,
      "step": 33680
    },
    {
      "epoch": 4.059036144578314,
      "grad_norm": 4.438302516937256,
      "learning_rate": 1.5940963855421688e-05,
      "loss": 0.0836,
      "step": 33690
    },
    {
      "epoch": 4.0602409638554215,
      "grad_norm": 1.061279058456421,
      "learning_rate": 1.593975903614458e-05,
      "loss": 0.0319,
      "step": 33700
    },
    {
      "epoch": 4.06144578313253,
      "grad_norm": 4.735666275024414,
      "learning_rate": 1.5938554216867473e-05,
      "loss": 0.0742,
      "step": 33710
    },
    {
      "epoch": 4.062650602409638,
      "grad_norm": 0.49943917989730835,
      "learning_rate": 1.5937349397590362e-05,
      "loss": 0.0128,
      "step": 33720
    },
    {
      "epoch": 4.063855421686747,
      "grad_norm": 0.21548740565776825,
      "learning_rate": 1.5936144578313254e-05,
      "loss": 0.0306,
      "step": 33730
    },
    {
      "epoch": 4.065060240963855,
      "grad_norm": 0.014938953332602978,
      "learning_rate": 1.5934939759036147e-05,
      "loss": 0.1317,
      "step": 33740
    },
    {
      "epoch": 4.066265060240964,
      "grad_norm": 2.2002501487731934,
      "learning_rate": 1.593373493975904e-05,
      "loss": 0.0399,
      "step": 33750
    },
    {
      "epoch": 4.067469879518073,
      "grad_norm": 0.09056758880615234,
      "learning_rate": 1.5932530120481928e-05,
      "loss": 0.053,
      "step": 33760
    },
    {
      "epoch": 4.0686746987951805,
      "grad_norm": 1.921759843826294,
      "learning_rate": 1.593132530120482e-05,
      "loss": 0.0761,
      "step": 33770
    },
    {
      "epoch": 4.069879518072289,
      "grad_norm": 1.6208956241607666,
      "learning_rate": 1.593012048192771e-05,
      "loss": 0.0305,
      "step": 33780
    },
    {
      "epoch": 4.071084337349397,
      "grad_norm": 0.13666671514511108,
      "learning_rate": 1.5928915662650602e-05,
      "loss": 0.0518,
      "step": 33790
    },
    {
      "epoch": 4.072289156626506,
      "grad_norm": 2.057927131652832,
      "learning_rate": 1.5927710843373495e-05,
      "loss": 0.086,
      "step": 33800
    },
    {
      "epoch": 4.073493975903615,
      "grad_norm": 0.27052634954452515,
      "learning_rate": 1.5926506024096387e-05,
      "loss": 0.0715,
      "step": 33810
    },
    {
      "epoch": 4.074698795180723,
      "grad_norm": 0.9073522090911865,
      "learning_rate": 1.592530120481928e-05,
      "loss": 0.0649,
      "step": 33820
    },
    {
      "epoch": 4.075903614457832,
      "grad_norm": 2.123366355895996,
      "learning_rate": 1.592409638554217e-05,
      "loss": 0.0053,
      "step": 33830
    },
    {
      "epoch": 4.0771084337349395,
      "grad_norm": 3.9875330924987793,
      "learning_rate": 1.592289156626506e-05,
      "loss": 0.1066,
      "step": 33840
    },
    {
      "epoch": 4.078313253012048,
      "grad_norm": 0.057891588658094406,
      "learning_rate": 1.5921686746987953e-05,
      "loss": 0.0987,
      "step": 33850
    },
    {
      "epoch": 4.079518072289156,
      "grad_norm": 1.1140618324279785,
      "learning_rate": 1.5920481927710846e-05,
      "loss": 0.0628,
      "step": 33860
    },
    {
      "epoch": 4.080722891566265,
      "grad_norm": 0.04799976199865341,
      "learning_rate": 1.5919277108433738e-05,
      "loss": 0.0065,
      "step": 33870
    },
    {
      "epoch": 4.081927710843374,
      "grad_norm": 0.03778005391359329,
      "learning_rate": 1.5918072289156627e-05,
      "loss": 0.0438,
      "step": 33880
    },
    {
      "epoch": 4.083132530120482,
      "grad_norm": 15.098274230957031,
      "learning_rate": 1.591686746987952e-05,
      "loss": 0.0943,
      "step": 33890
    },
    {
      "epoch": 4.0843373493975905,
      "grad_norm": 11.311434745788574,
      "learning_rate": 1.591566265060241e-05,
      "loss": 0.0417,
      "step": 33900
    },
    {
      "epoch": 4.085542168674698,
      "grad_norm": 5.315834045410156,
      "learning_rate": 1.59144578313253e-05,
      "loss": 0.0605,
      "step": 33910
    },
    {
      "epoch": 4.086746987951807,
      "grad_norm": 0.04250379279255867,
      "learning_rate": 1.5913253012048194e-05,
      "loss": 0.0277,
      "step": 33920
    },
    {
      "epoch": 4.087951807228916,
      "grad_norm": 2.143381118774414,
      "learning_rate": 1.5912048192771086e-05,
      "loss": 0.0204,
      "step": 33930
    },
    {
      "epoch": 4.089156626506024,
      "grad_norm": 1.5996453762054443,
      "learning_rate": 1.591084337349398e-05,
      "loss": 0.0581,
      "step": 33940
    },
    {
      "epoch": 4.090361445783133,
      "grad_norm": 5.139344692230225,
      "learning_rate": 1.5909638554216868e-05,
      "loss": 0.0442,
      "step": 33950
    },
    {
      "epoch": 4.091566265060241,
      "grad_norm": 0.024634502828121185,
      "learning_rate": 1.590843373493976e-05,
      "loss": 0.0684,
      "step": 33960
    },
    {
      "epoch": 4.0927710843373495,
      "grad_norm": 2.2054646015167236,
      "learning_rate": 1.5907228915662652e-05,
      "loss": 0.1281,
      "step": 33970
    },
    {
      "epoch": 4.093975903614457,
      "grad_norm": 2.1259608268737793,
      "learning_rate": 1.5906024096385545e-05,
      "loss": 0.044,
      "step": 33980
    },
    {
      "epoch": 4.095180722891566,
      "grad_norm": 0.27682214975357056,
      "learning_rate": 1.5904819277108434e-05,
      "loss": 0.0269,
      "step": 33990
    },
    {
      "epoch": 4.096385542168675,
      "grad_norm": 0.24138379096984863,
      "learning_rate": 1.5903614457831326e-05,
      "loss": 0.0305,
      "step": 34000
    },
    {
      "epoch": 4.097590361445783,
      "grad_norm": 0.03456636145710945,
      "learning_rate": 1.590240963855422e-05,
      "loss": 0.1173,
      "step": 34010
    },
    {
      "epoch": 4.098795180722892,
      "grad_norm": 3.1744508743286133,
      "learning_rate": 1.590120481927711e-05,
      "loss": 0.0403,
      "step": 34020
    },
    {
      "epoch": 4.1,
      "grad_norm": 4.977872848510742,
      "learning_rate": 1.5900000000000004e-05,
      "loss": 0.0845,
      "step": 34030
    },
    {
      "epoch": 4.1012048192771084,
      "grad_norm": 10.127029418945312,
      "learning_rate": 1.5898795180722893e-05,
      "loss": 0.0709,
      "step": 34040
    },
    {
      "epoch": 4.102409638554217,
      "grad_norm": 1.3199609518051147,
      "learning_rate": 1.5897590361445785e-05,
      "loss": 0.0224,
      "step": 34050
    },
    {
      "epoch": 4.103614457831325,
      "grad_norm": 3.7072839736938477,
      "learning_rate": 1.5896385542168674e-05,
      "loss": 0.034,
      "step": 34060
    },
    {
      "epoch": 4.104819277108434,
      "grad_norm": 36.68638610839844,
      "learning_rate": 1.5895180722891567e-05,
      "loss": 0.0606,
      "step": 34070
    },
    {
      "epoch": 4.106024096385542,
      "grad_norm": 0.03607285022735596,
      "learning_rate": 1.589397590361446e-05,
      "loss": 0.0665,
      "step": 34080
    },
    {
      "epoch": 4.107228915662651,
      "grad_norm": 0.30325496196746826,
      "learning_rate": 1.589277108433735e-05,
      "loss": 0.0226,
      "step": 34090
    },
    {
      "epoch": 4.108433734939759,
      "grad_norm": 11.044207572937012,
      "learning_rate": 1.5891566265060244e-05,
      "loss": 0.0163,
      "step": 34100
    },
    {
      "epoch": 4.109638554216867,
      "grad_norm": 42.663875579833984,
      "learning_rate": 1.5890361445783133e-05,
      "loss": 0.0747,
      "step": 34110
    },
    {
      "epoch": 4.110843373493976,
      "grad_norm": 5.427242755889893,
      "learning_rate": 1.5889156626506025e-05,
      "loss": 0.0498,
      "step": 34120
    },
    {
      "epoch": 4.112048192771084,
      "grad_norm": 0.11769383400678635,
      "learning_rate": 1.5887951807228918e-05,
      "loss": 0.0661,
      "step": 34130
    },
    {
      "epoch": 4.113253012048193,
      "grad_norm": 7.9821648597717285,
      "learning_rate": 1.588674698795181e-05,
      "loss": 0.1014,
      "step": 34140
    },
    {
      "epoch": 4.114457831325301,
      "grad_norm": 4.383194446563721,
      "learning_rate": 1.58855421686747e-05,
      "loss": 0.0561,
      "step": 34150
    },
    {
      "epoch": 4.11566265060241,
      "grad_norm": 1.6910077333450317,
      "learning_rate": 1.5884337349397592e-05,
      "loss": 0.0816,
      "step": 34160
    },
    {
      "epoch": 4.1168674698795185,
      "grad_norm": 21.35257911682129,
      "learning_rate": 1.5883132530120484e-05,
      "loss": 0.0398,
      "step": 34170
    },
    {
      "epoch": 4.118072289156626,
      "grad_norm": 0.024441124871373177,
      "learning_rate": 1.5881927710843373e-05,
      "loss": 0.0328,
      "step": 34180
    },
    {
      "epoch": 4.119277108433735,
      "grad_norm": 0.8679229021072388,
      "learning_rate": 1.5880722891566266e-05,
      "loss": 0.0216,
      "step": 34190
    },
    {
      "epoch": 4.120481927710843,
      "grad_norm": 3.0176148414611816,
      "learning_rate": 1.5879518072289158e-05,
      "loss": 0.0775,
      "step": 34200
    },
    {
      "epoch": 4.121686746987952,
      "grad_norm": 34.13753128051758,
      "learning_rate": 1.587831325301205e-05,
      "loss": 0.0157,
      "step": 34210
    },
    {
      "epoch": 4.12289156626506,
      "grad_norm": 2.2427473068237305,
      "learning_rate": 1.587710843373494e-05,
      "loss": 0.0975,
      "step": 34220
    },
    {
      "epoch": 4.124096385542169,
      "grad_norm": 0.02607663907110691,
      "learning_rate": 1.5875903614457832e-05,
      "loss": 0.0523,
      "step": 34230
    },
    {
      "epoch": 4.125301204819277,
      "grad_norm": 0.04792111739516258,
      "learning_rate": 1.5874698795180724e-05,
      "loss": 0.0645,
      "step": 34240
    },
    {
      "epoch": 4.126506024096385,
      "grad_norm": 12.876246452331543,
      "learning_rate": 1.5873493975903617e-05,
      "loss": 0.0406,
      "step": 34250
    },
    {
      "epoch": 4.127710843373494,
      "grad_norm": 2.7604990005493164,
      "learning_rate": 1.587228915662651e-05,
      "loss": 0.0345,
      "step": 34260
    },
    {
      "epoch": 4.128915662650602,
      "grad_norm": 1.021329641342163,
      "learning_rate": 1.58710843373494e-05,
      "loss": 0.0579,
      "step": 34270
    },
    {
      "epoch": 4.130120481927711,
      "grad_norm": 8.486831665039062,
      "learning_rate": 1.586987951807229e-05,
      "loss": 0.1045,
      "step": 34280
    },
    {
      "epoch": 4.13132530120482,
      "grad_norm": 0.20865024626255035,
      "learning_rate": 1.586867469879518e-05,
      "loss": 0.0603,
      "step": 34290
    },
    {
      "epoch": 4.132530120481928,
      "grad_norm": 9.694293975830078,
      "learning_rate": 1.5867469879518072e-05,
      "loss": 0.0333,
      "step": 34300
    },
    {
      "epoch": 4.133734939759036,
      "grad_norm": 6.82390022277832,
      "learning_rate": 1.5866265060240965e-05,
      "loss": 0.034,
      "step": 34310
    },
    {
      "epoch": 4.134939759036144,
      "grad_norm": 2.514657735824585,
      "learning_rate": 1.5865060240963857e-05,
      "loss": 0.0191,
      "step": 34320
    },
    {
      "epoch": 4.136144578313253,
      "grad_norm": 0.023041758686304092,
      "learning_rate": 1.586385542168675e-05,
      "loss": 0.0127,
      "step": 34330
    },
    {
      "epoch": 4.137349397590361,
      "grad_norm": 0.2649230659008026,
      "learning_rate": 1.586265060240964e-05,
      "loss": 0.1095,
      "step": 34340
    },
    {
      "epoch": 4.13855421686747,
      "grad_norm": 5.761012077331543,
      "learning_rate": 1.586144578313253e-05,
      "loss": 0.1014,
      "step": 34350
    },
    {
      "epoch": 4.139759036144579,
      "grad_norm": 0.18077890574932098,
      "learning_rate": 1.5860240963855423e-05,
      "loss": 0.0485,
      "step": 34360
    },
    {
      "epoch": 4.1409638554216865,
      "grad_norm": 0.7313691973686218,
      "learning_rate": 1.5859036144578316e-05,
      "loss": 0.0317,
      "step": 34370
    },
    {
      "epoch": 4.142168674698795,
      "grad_norm": 2.1262803077697754,
      "learning_rate": 1.5857831325301205e-05,
      "loss": 0.0563,
      "step": 34380
    },
    {
      "epoch": 4.143373493975903,
      "grad_norm": 0.4369472563266754,
      "learning_rate": 1.5856626506024097e-05,
      "loss": 0.0715,
      "step": 34390
    },
    {
      "epoch": 4.144578313253012,
      "grad_norm": 0.4204052686691284,
      "learning_rate": 1.585542168674699e-05,
      "loss": 0.0532,
      "step": 34400
    },
    {
      "epoch": 4.145783132530121,
      "grad_norm": 4.583132266998291,
      "learning_rate": 1.585421686746988e-05,
      "loss": 0.042,
      "step": 34410
    },
    {
      "epoch": 4.146987951807229,
      "grad_norm": 1.9007747173309326,
      "learning_rate": 1.585301204819277e-05,
      "loss": 0.047,
      "step": 34420
    },
    {
      "epoch": 4.148192771084338,
      "grad_norm": 0.9728876948356628,
      "learning_rate": 1.5851807228915664e-05,
      "loss": 0.0379,
      "step": 34430
    },
    {
      "epoch": 4.1493975903614455,
      "grad_norm": 2.023390293121338,
      "learning_rate": 1.5850602409638556e-05,
      "loss": 0.0497,
      "step": 34440
    },
    {
      "epoch": 4.150602409638554,
      "grad_norm": 0.24143509566783905,
      "learning_rate": 1.5849397590361445e-05,
      "loss": 0.0411,
      "step": 34450
    },
    {
      "epoch": 4.151807228915662,
      "grad_norm": 1.9752981662750244,
      "learning_rate": 1.5848192771084338e-05,
      "loss": 0.0855,
      "step": 34460
    },
    {
      "epoch": 4.153012048192771,
      "grad_norm": 0.7278178334236145,
      "learning_rate": 1.584698795180723e-05,
      "loss": 0.0126,
      "step": 34470
    },
    {
      "epoch": 4.15421686746988,
      "grad_norm": 3.0271458625793457,
      "learning_rate": 1.5845783132530123e-05,
      "loss": 0.0273,
      "step": 34480
    },
    {
      "epoch": 4.155421686746988,
      "grad_norm": 0.05742306634783745,
      "learning_rate": 1.5844578313253015e-05,
      "loss": 0.0742,
      "step": 34490
    },
    {
      "epoch": 4.156626506024097,
      "grad_norm": 5.517597675323486,
      "learning_rate": 1.5843373493975904e-05,
      "loss": 0.0089,
      "step": 34500
    },
    {
      "epoch": 4.1578313253012045,
      "grad_norm": 19.361644744873047,
      "learning_rate": 1.5842168674698796e-05,
      "loss": 0.146,
      "step": 34510
    },
    {
      "epoch": 4.159036144578313,
      "grad_norm": 0.08421214669942856,
      "learning_rate": 1.5840963855421686e-05,
      "loss": 0.0799,
      "step": 34520
    },
    {
      "epoch": 4.160240963855422,
      "grad_norm": 0.014573114924132824,
      "learning_rate": 1.583975903614458e-05,
      "loss": 0.0539,
      "step": 34530
    },
    {
      "epoch": 4.16144578313253,
      "grad_norm": 7.9291672706604,
      "learning_rate": 1.5838554216867474e-05,
      "loss": 0.0712,
      "step": 34540
    },
    {
      "epoch": 4.162650602409639,
      "grad_norm": 0.3075363337993622,
      "learning_rate": 1.5837349397590363e-05,
      "loss": 0.0148,
      "step": 34550
    },
    {
      "epoch": 4.163855421686747,
      "grad_norm": 1.2641490697860718,
      "learning_rate": 1.5836144578313255e-05,
      "loss": 0.0378,
      "step": 34560
    },
    {
      "epoch": 4.1650602409638555,
      "grad_norm": 13.212048530578613,
      "learning_rate": 1.5834939759036144e-05,
      "loss": 0.0723,
      "step": 34570
    },
    {
      "epoch": 4.166265060240963,
      "grad_norm": 0.3952210545539856,
      "learning_rate": 1.5833734939759037e-05,
      "loss": 0.073,
      "step": 34580
    },
    {
      "epoch": 4.167469879518072,
      "grad_norm": 5.390224456787109,
      "learning_rate": 1.583253012048193e-05,
      "loss": 0.0882,
      "step": 34590
    },
    {
      "epoch": 4.168674698795181,
      "grad_norm": 14.586380958557129,
      "learning_rate": 1.583132530120482e-05,
      "loss": 0.1157,
      "step": 34600
    },
    {
      "epoch": 4.169879518072289,
      "grad_norm": 107.61431884765625,
      "learning_rate": 1.5830120481927714e-05,
      "loss": 0.0349,
      "step": 34610
    },
    {
      "epoch": 4.171084337349398,
      "grad_norm": 0.29273417592048645,
      "learning_rate": 1.5828915662650603e-05,
      "loss": 0.0285,
      "step": 34620
    },
    {
      "epoch": 4.172289156626506,
      "grad_norm": 7.520256996154785,
      "learning_rate": 1.5827710843373496e-05,
      "loss": 0.064,
      "step": 34630
    },
    {
      "epoch": 4.1734939759036145,
      "grad_norm": 0.13244585692882538,
      "learning_rate": 1.5826506024096388e-05,
      "loss": 0.041,
      "step": 34640
    },
    {
      "epoch": 4.174698795180723,
      "grad_norm": 0.0264772679656744,
      "learning_rate": 1.582530120481928e-05,
      "loss": 0.0628,
      "step": 34650
    },
    {
      "epoch": 4.175903614457831,
      "grad_norm": 1.3179517984390259,
      "learning_rate": 1.582409638554217e-05,
      "loss": 0.0496,
      "step": 34660
    },
    {
      "epoch": 4.17710843373494,
      "grad_norm": 14.168957710266113,
      "learning_rate": 1.5822891566265062e-05,
      "loss": 0.0851,
      "step": 34670
    },
    {
      "epoch": 4.178313253012048,
      "grad_norm": 1.5096242427825928,
      "learning_rate": 1.582168674698795e-05,
      "loss": 0.0807,
      "step": 34680
    },
    {
      "epoch": 4.179518072289157,
      "grad_norm": 1.284570336341858,
      "learning_rate": 1.5820481927710843e-05,
      "loss": 0.0272,
      "step": 34690
    },
    {
      "epoch": 4.180722891566265,
      "grad_norm": 0.6378433704376221,
      "learning_rate": 1.5819277108433736e-05,
      "loss": 0.052,
      "step": 34700
    },
    {
      "epoch": 4.1819277108433734,
      "grad_norm": 3.276533603668213,
      "learning_rate": 1.5818072289156628e-05,
      "loss": 0.0902,
      "step": 34710
    },
    {
      "epoch": 4.183132530120482,
      "grad_norm": 24.762609481811523,
      "learning_rate": 1.581686746987952e-05,
      "loss": 0.063,
      "step": 34720
    },
    {
      "epoch": 4.18433734939759,
      "grad_norm": 0.04365842789411545,
      "learning_rate": 1.581566265060241e-05,
      "loss": 0.0425,
      "step": 34730
    },
    {
      "epoch": 4.185542168674699,
      "grad_norm": 0.05335404351353645,
      "learning_rate": 1.5814457831325302e-05,
      "loss": 0.0743,
      "step": 34740
    },
    {
      "epoch": 4.186746987951807,
      "grad_norm": 3.914015531539917,
      "learning_rate": 1.5813253012048195e-05,
      "loss": 0.0597,
      "step": 34750
    },
    {
      "epoch": 4.187951807228916,
      "grad_norm": 0.25270000100135803,
      "learning_rate": 1.5812048192771087e-05,
      "loss": 0.0294,
      "step": 34760
    },
    {
      "epoch": 4.1891566265060245,
      "grad_norm": 0.5749717354774475,
      "learning_rate": 1.581084337349398e-05,
      "loss": 0.0366,
      "step": 34770
    },
    {
      "epoch": 4.190361445783132,
      "grad_norm": 0.5954855680465698,
      "learning_rate": 1.580963855421687e-05,
      "loss": 0.0583,
      "step": 34780
    },
    {
      "epoch": 4.191566265060241,
      "grad_norm": 1.084972620010376,
      "learning_rate": 1.580843373493976e-05,
      "loss": 0.0343,
      "step": 34790
    },
    {
      "epoch": 4.192771084337349,
      "grad_norm": 2.1118791103363037,
      "learning_rate": 1.580722891566265e-05,
      "loss": 0.0896,
      "step": 34800
    },
    {
      "epoch": 4.193975903614458,
      "grad_norm": 2.440316915512085,
      "learning_rate": 1.5806024096385542e-05,
      "loss": 0.0172,
      "step": 34810
    },
    {
      "epoch": 4.195180722891566,
      "grad_norm": 4.971869945526123,
      "learning_rate": 1.5804819277108435e-05,
      "loss": 0.0418,
      "step": 34820
    },
    {
      "epoch": 4.196385542168675,
      "grad_norm": 12.46146297454834,
      "learning_rate": 1.5803614457831327e-05,
      "loss": 0.0219,
      "step": 34830
    },
    {
      "epoch": 4.1975903614457835,
      "grad_norm": 0.022096944972872734,
      "learning_rate": 1.580240963855422e-05,
      "loss": 0.0508,
      "step": 34840
    },
    {
      "epoch": 4.198795180722891,
      "grad_norm": 0.7785362005233765,
      "learning_rate": 1.580120481927711e-05,
      "loss": 0.0538,
      "step": 34850
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.07828602939844131,
      "learning_rate": 1.58e-05,
      "loss": 0.0722,
      "step": 34860
    },
    {
      "epoch": 4.201204819277108,
      "grad_norm": 0.3658052384853363,
      "learning_rate": 1.5798795180722894e-05,
      "loss": 0.0296,
      "step": 34870
    },
    {
      "epoch": 4.202409638554217,
      "grad_norm": 6.598363399505615,
      "learning_rate": 1.5797590361445786e-05,
      "loss": 0.0905,
      "step": 34880
    },
    {
      "epoch": 4.203614457831326,
      "grad_norm": 2.4057977199554443,
      "learning_rate": 1.5796385542168675e-05,
      "loss": 0.0704,
      "step": 34890
    },
    {
      "epoch": 4.204819277108434,
      "grad_norm": 1.7344650030136108,
      "learning_rate": 1.5795180722891568e-05,
      "loss": 0.0682,
      "step": 34900
    },
    {
      "epoch": 4.206024096385542,
      "grad_norm": 0.8680914640426636,
      "learning_rate": 1.579397590361446e-05,
      "loss": 0.0131,
      "step": 34910
    },
    {
      "epoch": 4.20722891566265,
      "grad_norm": 2.756012439727783,
      "learning_rate": 1.579277108433735e-05,
      "loss": 0.0528,
      "step": 34920
    },
    {
      "epoch": 4.208433734939759,
      "grad_norm": 2.318070888519287,
      "learning_rate": 1.579156626506024e-05,
      "loss": 0.0258,
      "step": 34930
    },
    {
      "epoch": 4.209638554216867,
      "grad_norm": 5.541548252105713,
      "learning_rate": 1.5790361445783134e-05,
      "loss": 0.0689,
      "step": 34940
    },
    {
      "epoch": 4.210843373493976,
      "grad_norm": 0.916215181350708,
      "learning_rate": 1.5789156626506026e-05,
      "loss": 0.0257,
      "step": 34950
    },
    {
      "epoch": 4.212048192771085,
      "grad_norm": 0.023402856662869453,
      "learning_rate": 1.5787951807228915e-05,
      "loss": 0.048,
      "step": 34960
    },
    {
      "epoch": 4.213253012048193,
      "grad_norm": 4.300132751464844,
      "learning_rate": 1.5786746987951808e-05,
      "loss": 0.0559,
      "step": 34970
    },
    {
      "epoch": 4.214457831325301,
      "grad_norm": 7.23480224609375,
      "learning_rate": 1.57855421686747e-05,
      "loss": 0.0782,
      "step": 34980
    },
    {
      "epoch": 4.215662650602409,
      "grad_norm": 0.0187806636095047,
      "learning_rate": 1.5784337349397593e-05,
      "loss": 0.0403,
      "step": 34990
    },
    {
      "epoch": 4.216867469879518,
      "grad_norm": 0.38268375396728516,
      "learning_rate": 1.5783132530120485e-05,
      "loss": 0.0459,
      "step": 35000
    },
    {
      "epoch": 4.218072289156627,
      "grad_norm": 12.14968204498291,
      "learning_rate": 1.5781927710843374e-05,
      "loss": 0.0885,
      "step": 35010
    },
    {
      "epoch": 4.219277108433735,
      "grad_norm": 0.17327190935611725,
      "learning_rate": 1.5780722891566267e-05,
      "loss": 0.0796,
      "step": 35020
    },
    {
      "epoch": 4.220481927710844,
      "grad_norm": 0.1324281394481659,
      "learning_rate": 1.5779518072289156e-05,
      "loss": 0.0339,
      "step": 35030
    },
    {
      "epoch": 4.2216867469879515,
      "grad_norm": 2.5978844165802,
      "learning_rate": 1.5778313253012048e-05,
      "loss": 0.0267,
      "step": 35040
    },
    {
      "epoch": 4.22289156626506,
      "grad_norm": 0.6199555397033691,
      "learning_rate": 1.577710843373494e-05,
      "loss": 0.0429,
      "step": 35050
    },
    {
      "epoch": 4.224096385542168,
      "grad_norm": 2.172142744064331,
      "learning_rate": 1.5775903614457833e-05,
      "loss": 0.0541,
      "step": 35060
    },
    {
      "epoch": 4.225301204819277,
      "grad_norm": 6.655354022979736,
      "learning_rate": 1.5774698795180725e-05,
      "loss": 0.0586,
      "step": 35070
    },
    {
      "epoch": 4.226506024096386,
      "grad_norm": 0.4326906204223633,
      "learning_rate": 1.5773493975903614e-05,
      "loss": 0.0971,
      "step": 35080
    },
    {
      "epoch": 4.227710843373494,
      "grad_norm": 0.988683819770813,
      "learning_rate": 1.5772289156626507e-05,
      "loss": 0.0924,
      "step": 35090
    },
    {
      "epoch": 4.228915662650603,
      "grad_norm": 11.438474655151367,
      "learning_rate": 1.57710843373494e-05,
      "loss": 0.0918,
      "step": 35100
    },
    {
      "epoch": 4.2301204819277105,
      "grad_norm": 10.49417781829834,
      "learning_rate": 1.5769879518072292e-05,
      "loss": 0.0323,
      "step": 35110
    },
    {
      "epoch": 4.231325301204819,
      "grad_norm": 3.658799886703491,
      "learning_rate": 1.576867469879518e-05,
      "loss": 0.0498,
      "step": 35120
    },
    {
      "epoch": 4.232530120481928,
      "grad_norm": 0.9962216019630432,
      "learning_rate": 1.5767469879518073e-05,
      "loss": 0.102,
      "step": 35130
    },
    {
      "epoch": 4.233734939759036,
      "grad_norm": 0.8572017550468445,
      "learning_rate": 1.5766265060240966e-05,
      "loss": 0.0647,
      "step": 35140
    },
    {
      "epoch": 4.234939759036145,
      "grad_norm": 11.22762680053711,
      "learning_rate": 1.5765060240963858e-05,
      "loss": 0.042,
      "step": 35150
    },
    {
      "epoch": 4.236144578313253,
      "grad_norm": 0.07180460542440414,
      "learning_rate": 1.576385542168675e-05,
      "loss": 0.0669,
      "step": 35160
    },
    {
      "epoch": 4.2373493975903616,
      "grad_norm": 0.6913943290710449,
      "learning_rate": 1.576265060240964e-05,
      "loss": 0.0414,
      "step": 35170
    },
    {
      "epoch": 4.2385542168674695,
      "grad_norm": 0.3273603022098541,
      "learning_rate": 1.5761445783132532e-05,
      "loss": 0.045,
      "step": 35180
    },
    {
      "epoch": 4.239759036144578,
      "grad_norm": 0.016791105270385742,
      "learning_rate": 1.576024096385542e-05,
      "loss": 0.0572,
      "step": 35190
    },
    {
      "epoch": 4.240963855421687,
      "grad_norm": 0.9939525723457336,
      "learning_rate": 1.5759036144578313e-05,
      "loss": 0.0425,
      "step": 35200
    },
    {
      "epoch": 4.242168674698795,
      "grad_norm": 0.10909755527973175,
      "learning_rate": 1.5757831325301206e-05,
      "loss": 0.046,
      "step": 35210
    },
    {
      "epoch": 4.243373493975904,
      "grad_norm": 1.2950302362442017,
      "learning_rate": 1.57566265060241e-05,
      "loss": 0.0167,
      "step": 35220
    },
    {
      "epoch": 4.244578313253012,
      "grad_norm": 0.037291161715984344,
      "learning_rate": 1.575542168674699e-05,
      "loss": 0.1044,
      "step": 35230
    },
    {
      "epoch": 4.2457831325301205,
      "grad_norm": 0.8360388278961182,
      "learning_rate": 1.575421686746988e-05,
      "loss": 0.0828,
      "step": 35240
    },
    {
      "epoch": 4.246987951807229,
      "grad_norm": 1.226141095161438,
      "learning_rate": 1.5753012048192772e-05,
      "loss": 0.0646,
      "step": 35250
    },
    {
      "epoch": 4.248192771084337,
      "grad_norm": 16.537399291992188,
      "learning_rate": 1.5751807228915665e-05,
      "loss": 0.0438,
      "step": 35260
    },
    {
      "epoch": 4.249397590361446,
      "grad_norm": 0.20001792907714844,
      "learning_rate": 1.5750602409638557e-05,
      "loss": 0.01,
      "step": 35270
    },
    {
      "epoch": 4.250602409638554,
      "grad_norm": 0.9366664886474609,
      "learning_rate": 1.5749397590361446e-05,
      "loss": 0.0355,
      "step": 35280
    },
    {
      "epoch": 4.251807228915663,
      "grad_norm": 0.011402617208659649,
      "learning_rate": 1.574819277108434e-05,
      "loss": 0.0293,
      "step": 35290
    },
    {
      "epoch": 4.253012048192771,
      "grad_norm": 3.24835467338562,
      "learning_rate": 1.574698795180723e-05,
      "loss": 0.0499,
      "step": 35300
    },
    {
      "epoch": 4.2542168674698795,
      "grad_norm": 1.9042487144470215,
      "learning_rate": 1.574578313253012e-05,
      "loss": 0.095,
      "step": 35310
    },
    {
      "epoch": 4.255421686746988,
      "grad_norm": 0.12173064053058624,
      "learning_rate": 1.5744578313253013e-05,
      "loss": 0.0602,
      "step": 35320
    },
    {
      "epoch": 4.256626506024096,
      "grad_norm": 0.011405841447412968,
      "learning_rate": 1.5743373493975905e-05,
      "loss": 0.0211,
      "step": 35330
    },
    {
      "epoch": 4.257831325301205,
      "grad_norm": 1.859806776046753,
      "learning_rate": 1.5742168674698797e-05,
      "loss": 0.1035,
      "step": 35340
    },
    {
      "epoch": 4.259036144578313,
      "grad_norm": 0.20672743022441864,
      "learning_rate": 1.5740963855421686e-05,
      "loss": 0.039,
      "step": 35350
    },
    {
      "epoch": 4.260240963855422,
      "grad_norm": 2.999837875366211,
      "learning_rate": 1.573975903614458e-05,
      "loss": 0.062,
      "step": 35360
    },
    {
      "epoch": 4.2614457831325305,
      "grad_norm": 1.8405625820159912,
      "learning_rate": 1.573855421686747e-05,
      "loss": 0.0397,
      "step": 35370
    },
    {
      "epoch": 4.2626506024096384,
      "grad_norm": 1.051964282989502,
      "learning_rate": 1.5737349397590364e-05,
      "loss": 0.0593,
      "step": 35380
    },
    {
      "epoch": 4.263855421686747,
      "grad_norm": 4.543039798736572,
      "learning_rate": 1.5736144578313256e-05,
      "loss": 0.0566,
      "step": 35390
    },
    {
      "epoch": 4.265060240963855,
      "grad_norm": 7.560832500457764,
      "learning_rate": 1.5734939759036145e-05,
      "loss": 0.0556,
      "step": 35400
    },
    {
      "epoch": 4.266265060240964,
      "grad_norm": 0.014766800217330456,
      "learning_rate": 1.5733734939759038e-05,
      "loss": 0.0662,
      "step": 35410
    },
    {
      "epoch": 4.267469879518072,
      "grad_norm": 4.089423179626465,
      "learning_rate": 1.5732530120481927e-05,
      "loss": 0.0674,
      "step": 35420
    },
    {
      "epoch": 4.268674698795181,
      "grad_norm": 0.061932630836963654,
      "learning_rate": 1.573132530120482e-05,
      "loss": 0.0487,
      "step": 35430
    },
    {
      "epoch": 4.2698795180722895,
      "grad_norm": 1.347229242324829,
      "learning_rate": 1.573012048192771e-05,
      "loss": 0.0157,
      "step": 35440
    },
    {
      "epoch": 4.271084337349397,
      "grad_norm": 0.007334241643548012,
      "learning_rate": 1.5728915662650604e-05,
      "loss": 0.1614,
      "step": 35450
    },
    {
      "epoch": 4.272289156626506,
      "grad_norm": 1.1621887683868408,
      "learning_rate": 1.5727710843373496e-05,
      "loss": 0.0771,
      "step": 35460
    },
    {
      "epoch": 4.273493975903614,
      "grad_norm": 0.1382688581943512,
      "learning_rate": 1.5726506024096386e-05,
      "loss": 0.0192,
      "step": 35470
    },
    {
      "epoch": 4.274698795180723,
      "grad_norm": 0.11964298039674759,
      "learning_rate": 1.5725301204819278e-05,
      "loss": 0.0418,
      "step": 35480
    },
    {
      "epoch": 4.275903614457832,
      "grad_norm": 0.07115344703197479,
      "learning_rate": 1.572409638554217e-05,
      "loss": 0.0254,
      "step": 35490
    },
    {
      "epoch": 4.27710843373494,
      "grad_norm": 0.00991551112383604,
      "learning_rate": 1.5722891566265063e-05,
      "loss": 0.0302,
      "step": 35500
    },
    {
      "epoch": 4.2783132530120485,
      "grad_norm": 0.7776281237602234,
      "learning_rate": 1.5721686746987955e-05,
      "loss": 0.0325,
      "step": 35510
    },
    {
      "epoch": 4.279518072289156,
      "grad_norm": 0.009140154346823692,
      "learning_rate": 1.5720481927710844e-05,
      "loss": 0.0333,
      "step": 35520
    },
    {
      "epoch": 4.280722891566265,
      "grad_norm": 6.586560249328613,
      "learning_rate": 1.5719277108433737e-05,
      "loss": 0.0571,
      "step": 35530
    },
    {
      "epoch": 4.281927710843373,
      "grad_norm": 2.716911554336548,
      "learning_rate": 1.5718072289156626e-05,
      "loss": 0.0625,
      "step": 35540
    },
    {
      "epoch": 4.283132530120482,
      "grad_norm": 2.154048204421997,
      "learning_rate": 1.5716867469879518e-05,
      "loss": 0.0308,
      "step": 35550
    },
    {
      "epoch": 4.284337349397591,
      "grad_norm": 0.12490485608577728,
      "learning_rate": 1.571566265060241e-05,
      "loss": 0.0213,
      "step": 35560
    },
    {
      "epoch": 4.285542168674699,
      "grad_norm": 0.06672027707099915,
      "learning_rate": 1.5714457831325303e-05,
      "loss": 0.1312,
      "step": 35570
    },
    {
      "epoch": 4.286746987951807,
      "grad_norm": 3.9391496181488037,
      "learning_rate": 1.5713253012048192e-05,
      "loss": 0.1074,
      "step": 35580
    },
    {
      "epoch": 4.287951807228915,
      "grad_norm": 0.25624194741249084,
      "learning_rate": 1.5712048192771085e-05,
      "loss": 0.0321,
      "step": 35590
    },
    {
      "epoch": 4.289156626506024,
      "grad_norm": 1.7060586214065552,
      "learning_rate": 1.5710843373493977e-05,
      "loss": 0.0414,
      "step": 35600
    },
    {
      "epoch": 4.290361445783133,
      "grad_norm": 5.11525821685791,
      "learning_rate": 1.570963855421687e-05,
      "loss": 0.0884,
      "step": 35610
    },
    {
      "epoch": 4.291566265060241,
      "grad_norm": 0.09305672347545624,
      "learning_rate": 1.5708433734939762e-05,
      "loss": 0.0372,
      "step": 35620
    },
    {
      "epoch": 4.29277108433735,
      "grad_norm": 0.3367399275302887,
      "learning_rate": 1.570722891566265e-05,
      "loss": 0.0742,
      "step": 35630
    },
    {
      "epoch": 4.293975903614458,
      "grad_norm": 0.030349595472216606,
      "learning_rate": 1.5706024096385543e-05,
      "loss": 0.0529,
      "step": 35640
    },
    {
      "epoch": 4.295180722891566,
      "grad_norm": 0.04161353036761284,
      "learning_rate": 1.5704819277108432e-05,
      "loss": 0.083,
      "step": 35650
    },
    {
      "epoch": 4.296385542168674,
      "grad_norm": 5.788625717163086,
      "learning_rate": 1.5703614457831328e-05,
      "loss": 0.1509,
      "step": 35660
    },
    {
      "epoch": 4.297590361445783,
      "grad_norm": 0.06035277247428894,
      "learning_rate": 1.570240963855422e-05,
      "loss": 0.0475,
      "step": 35670
    },
    {
      "epoch": 4.298795180722892,
      "grad_norm": 0.5371009707450867,
      "learning_rate": 1.570120481927711e-05,
      "loss": 0.0188,
      "step": 35680
    },
    {
      "epoch": 4.3,
      "grad_norm": 1.6436680555343628,
      "learning_rate": 1.5700000000000002e-05,
      "loss": 0.0573,
      "step": 35690
    },
    {
      "epoch": 4.301204819277109,
      "grad_norm": 11.23072624206543,
      "learning_rate": 1.569879518072289e-05,
      "loss": 0.0329,
      "step": 35700
    },
    {
      "epoch": 4.3024096385542165,
      "grad_norm": 2.0713987350463867,
      "learning_rate": 1.5697590361445784e-05,
      "loss": 0.0616,
      "step": 35710
    },
    {
      "epoch": 4.303614457831325,
      "grad_norm": 1.5267895460128784,
      "learning_rate": 1.5696385542168676e-05,
      "loss": 0.0374,
      "step": 35720
    },
    {
      "epoch": 4.304819277108434,
      "grad_norm": 4.258053302764893,
      "learning_rate": 1.569518072289157e-05,
      "loss": 0.0682,
      "step": 35730
    },
    {
      "epoch": 4.306024096385542,
      "grad_norm": 2.7183749675750732,
      "learning_rate": 1.569397590361446e-05,
      "loss": 0.036,
      "step": 35740
    },
    {
      "epoch": 4.307228915662651,
      "grad_norm": 0.17588362097740173,
      "learning_rate": 1.569277108433735e-05,
      "loss": 0.0536,
      "step": 35750
    },
    {
      "epoch": 4.308433734939759,
      "grad_norm": 0.02676485665142536,
      "learning_rate": 1.5691566265060242e-05,
      "loss": 0.0798,
      "step": 35760
    },
    {
      "epoch": 4.309638554216868,
      "grad_norm": 6.85556173324585,
      "learning_rate": 1.5690361445783135e-05,
      "loss": 0.0581,
      "step": 35770
    },
    {
      "epoch": 4.3108433734939755,
      "grad_norm": 4.4467010498046875,
      "learning_rate": 1.5689156626506027e-05,
      "loss": 0.0313,
      "step": 35780
    },
    {
      "epoch": 4.312048192771084,
      "grad_norm": 0.8295316696166992,
      "learning_rate": 1.5687951807228916e-05,
      "loss": 0.0308,
      "step": 35790
    },
    {
      "epoch": 4.313253012048193,
      "grad_norm": 0.14623162150382996,
      "learning_rate": 1.568674698795181e-05,
      "loss": 0.0484,
      "step": 35800
    },
    {
      "epoch": 4.314457831325301,
      "grad_norm": 0.028687473386526108,
      "learning_rate": 1.56855421686747e-05,
      "loss": 0.0447,
      "step": 35810
    },
    {
      "epoch": 4.31566265060241,
      "grad_norm": 0.26262107491493225,
      "learning_rate": 1.568433734939759e-05,
      "loss": 0.0268,
      "step": 35820
    },
    {
      "epoch": 4.316867469879518,
      "grad_norm": 0.029670555144548416,
      "learning_rate": 1.5683132530120483e-05,
      "loss": 0.0501,
      "step": 35830
    },
    {
      "epoch": 4.3180722891566266,
      "grad_norm": 11.16187572479248,
      "learning_rate": 1.5681927710843375e-05,
      "loss": 0.1153,
      "step": 35840
    },
    {
      "epoch": 4.3192771084337345,
      "grad_norm": 0.02884104661643505,
      "learning_rate": 1.5680722891566268e-05,
      "loss": 0.0983,
      "step": 35850
    },
    {
      "epoch": 4.320481927710843,
      "grad_norm": 0.3658215403556824,
      "learning_rate": 1.5679518072289157e-05,
      "loss": 0.0586,
      "step": 35860
    },
    {
      "epoch": 4.321686746987952,
      "grad_norm": 9.622528076171875,
      "learning_rate": 1.567831325301205e-05,
      "loss": 0.1416,
      "step": 35870
    },
    {
      "epoch": 4.32289156626506,
      "grad_norm": 3.413888454437256,
      "learning_rate": 1.567710843373494e-05,
      "loss": 0.0592,
      "step": 35880
    },
    {
      "epoch": 4.324096385542169,
      "grad_norm": 0.2892577350139618,
      "learning_rate": 1.5675903614457834e-05,
      "loss": 0.0293,
      "step": 35890
    },
    {
      "epoch": 4.325301204819277,
      "grad_norm": 0.14262132346630096,
      "learning_rate": 1.5674698795180726e-05,
      "loss": 0.0703,
      "step": 35900
    },
    {
      "epoch": 4.3265060240963855,
      "grad_norm": 0.5632718801498413,
      "learning_rate": 1.5673493975903615e-05,
      "loss": 0.1598,
      "step": 35910
    },
    {
      "epoch": 4.327710843373494,
      "grad_norm": 0.10858409851789474,
      "learning_rate": 1.5672289156626508e-05,
      "loss": 0.0394,
      "step": 35920
    },
    {
      "epoch": 4.328915662650602,
      "grad_norm": 15.474905967712402,
      "learning_rate": 1.5671084337349397e-05,
      "loss": 0.0503,
      "step": 35930
    },
    {
      "epoch": 4.330120481927711,
      "grad_norm": 1.3846365213394165,
      "learning_rate": 1.566987951807229e-05,
      "loss": 0.0271,
      "step": 35940
    },
    {
      "epoch": 4.331325301204819,
      "grad_norm": 2.161632776260376,
      "learning_rate": 1.5668674698795182e-05,
      "loss": 0.1373,
      "step": 35950
    },
    {
      "epoch": 4.332530120481928,
      "grad_norm": 0.3394801914691925,
      "learning_rate": 1.5667469879518074e-05,
      "loss": 0.0347,
      "step": 35960
    },
    {
      "epoch": 4.333734939759037,
      "grad_norm": 0.06682197004556656,
      "learning_rate": 1.5666265060240967e-05,
      "loss": 0.0347,
      "step": 35970
    },
    {
      "epoch": 4.3349397590361445,
      "grad_norm": 0.4942722022533417,
      "learning_rate": 1.5665060240963856e-05,
      "loss": 0.0254,
      "step": 35980
    },
    {
      "epoch": 4.336144578313253,
      "grad_norm": 1.7852253913879395,
      "learning_rate": 1.5663855421686748e-05,
      "loss": 0.0566,
      "step": 35990
    },
    {
      "epoch": 4.337349397590361,
      "grad_norm": 1.9797531366348267,
      "learning_rate": 1.566265060240964e-05,
      "loss": 0.1417,
      "step": 36000
    },
    {
      "epoch": 4.33855421686747,
      "grad_norm": 0.09408783912658691,
      "learning_rate": 1.5661445783132533e-05,
      "loss": 0.053,
      "step": 36010
    },
    {
      "epoch": 4.339759036144578,
      "grad_norm": 0.3035893142223358,
      "learning_rate": 1.5660240963855422e-05,
      "loss": 0.0662,
      "step": 36020
    },
    {
      "epoch": 4.340963855421687,
      "grad_norm": 21.804567337036133,
      "learning_rate": 1.5659036144578314e-05,
      "loss": 0.0302,
      "step": 36030
    },
    {
      "epoch": 4.3421686746987955,
      "grad_norm": 5.3482818603515625,
      "learning_rate": 1.5657831325301207e-05,
      "loss": 0.125,
      "step": 36040
    },
    {
      "epoch": 4.343373493975903,
      "grad_norm": 0.3596544563770294,
      "learning_rate": 1.5656626506024096e-05,
      "loss": 0.0088,
      "step": 36050
    },
    {
      "epoch": 4.344578313253012,
      "grad_norm": 0.244143545627594,
      "learning_rate": 1.565542168674699e-05,
      "loss": 0.0597,
      "step": 36060
    },
    {
      "epoch": 4.34578313253012,
      "grad_norm": 4.4807820320129395,
      "learning_rate": 1.565421686746988e-05,
      "loss": 0.0381,
      "step": 36070
    },
    {
      "epoch": 4.346987951807229,
      "grad_norm": 9.686911582946777,
      "learning_rate": 1.5653012048192773e-05,
      "loss": 0.0899,
      "step": 36080
    },
    {
      "epoch": 4.348192771084337,
      "grad_norm": 0.14514563977718353,
      "learning_rate": 1.5651807228915662e-05,
      "loss": 0.0211,
      "step": 36090
    },
    {
      "epoch": 4.349397590361446,
      "grad_norm": 0.07619978487491608,
      "learning_rate": 1.5650602409638555e-05,
      "loss": 0.0106,
      "step": 36100
    },
    {
      "epoch": 4.3506024096385545,
      "grad_norm": 0.09051145613193512,
      "learning_rate": 1.5649397590361447e-05,
      "loss": 0.0451,
      "step": 36110
    },
    {
      "epoch": 4.351807228915662,
      "grad_norm": 0.15144291520118713,
      "learning_rate": 1.564819277108434e-05,
      "loss": 0.0913,
      "step": 36120
    },
    {
      "epoch": 4.353012048192771,
      "grad_norm": 1.9834842681884766,
      "learning_rate": 1.5646987951807232e-05,
      "loss": 0.1356,
      "step": 36130
    },
    {
      "epoch": 4.354216867469879,
      "grad_norm": 0.3217841684818268,
      "learning_rate": 1.564578313253012e-05,
      "loss": 0.0375,
      "step": 36140
    },
    {
      "epoch": 4.355421686746988,
      "grad_norm": 4.21496057510376,
      "learning_rate": 1.5644578313253014e-05,
      "loss": 0.0659,
      "step": 36150
    },
    {
      "epoch": 4.356626506024097,
      "grad_norm": 0.08030202239751816,
      "learning_rate": 1.5643373493975903e-05,
      "loss": 0.0303,
      "step": 36160
    },
    {
      "epoch": 4.357831325301205,
      "grad_norm": 1.2943460941314697,
      "learning_rate": 1.5642168674698795e-05,
      "loss": 0.0559,
      "step": 36170
    },
    {
      "epoch": 4.3590361445783135,
      "grad_norm": 0.046182140707969666,
      "learning_rate": 1.5640963855421687e-05,
      "loss": 0.0781,
      "step": 36180
    },
    {
      "epoch": 4.360240963855421,
      "grad_norm": 0.6918011903762817,
      "learning_rate": 1.563975903614458e-05,
      "loss": 0.0079,
      "step": 36190
    },
    {
      "epoch": 4.36144578313253,
      "grad_norm": 1.1418814659118652,
      "learning_rate": 1.5638554216867472e-05,
      "loss": 0.0838,
      "step": 36200
    },
    {
      "epoch": 4.362650602409639,
      "grad_norm": 0.07844085246324539,
      "learning_rate": 1.563734939759036e-05,
      "loss": 0.0655,
      "step": 36210
    },
    {
      "epoch": 4.363855421686747,
      "grad_norm": 0.04385804757475853,
      "learning_rate": 1.5636144578313254e-05,
      "loss": 0.0344,
      "step": 36220
    },
    {
      "epoch": 4.365060240963856,
      "grad_norm": 0.02944171242415905,
      "learning_rate": 1.5634939759036146e-05,
      "loss": 0.0714,
      "step": 36230
    },
    {
      "epoch": 4.366265060240964,
      "grad_norm": 1.1468985080718994,
      "learning_rate": 1.563373493975904e-05,
      "loss": 0.0247,
      "step": 36240
    },
    {
      "epoch": 4.367469879518072,
      "grad_norm": 5.749820232391357,
      "learning_rate": 1.5632530120481928e-05,
      "loss": 0.0437,
      "step": 36250
    },
    {
      "epoch": 4.36867469879518,
      "grad_norm": 12.389525413513184,
      "learning_rate": 1.563132530120482e-05,
      "loss": 0.0495,
      "step": 36260
    },
    {
      "epoch": 4.369879518072289,
      "grad_norm": 1.9499589204788208,
      "learning_rate": 1.5630120481927713e-05,
      "loss": 0.1117,
      "step": 36270
    },
    {
      "epoch": 4.371084337349398,
      "grad_norm": 1.204922080039978,
      "learning_rate": 1.5628915662650605e-05,
      "loss": 0.1113,
      "step": 36280
    },
    {
      "epoch": 4.372289156626506,
      "grad_norm": 0.7921997904777527,
      "learning_rate": 1.5627710843373497e-05,
      "loss": 0.0794,
      "step": 36290
    },
    {
      "epoch": 4.373493975903615,
      "grad_norm": 5.595151424407959,
      "learning_rate": 1.5626506024096386e-05,
      "loss": 0.0638,
      "step": 36300
    },
    {
      "epoch": 4.374698795180723,
      "grad_norm": 4.272253036499023,
      "learning_rate": 1.562530120481928e-05,
      "loss": 0.034,
      "step": 36310
    },
    {
      "epoch": 4.375903614457831,
      "grad_norm": 0.43611398339271545,
      "learning_rate": 1.5624096385542168e-05,
      "loss": 0.0446,
      "step": 36320
    },
    {
      "epoch": 4.377108433734939,
      "grad_norm": 21.47898292541504,
      "learning_rate": 1.562289156626506e-05,
      "loss": 0.095,
      "step": 36330
    },
    {
      "epoch": 4.378313253012048,
      "grad_norm": 0.10981951653957367,
      "learning_rate": 1.5621686746987953e-05,
      "loss": 0.0377,
      "step": 36340
    },
    {
      "epoch": 4.379518072289157,
      "grad_norm": 2.690319776535034,
      "learning_rate": 1.5620481927710845e-05,
      "loss": 0.076,
      "step": 36350
    },
    {
      "epoch": 4.380722891566265,
      "grad_norm": 3.8832485675811768,
      "learning_rate": 1.5619277108433738e-05,
      "loss": 0.0631,
      "step": 36360
    },
    {
      "epoch": 4.381927710843374,
      "grad_norm": 2.0866525173187256,
      "learning_rate": 1.5618072289156627e-05,
      "loss": 0.0421,
      "step": 36370
    },
    {
      "epoch": 4.3831325301204815,
      "grad_norm": 5.636566638946533,
      "learning_rate": 1.561686746987952e-05,
      "loss": 0.1176,
      "step": 36380
    },
    {
      "epoch": 4.38433734939759,
      "grad_norm": 0.09625271707773209,
      "learning_rate": 1.561566265060241e-05,
      "loss": 0.0563,
      "step": 36390
    },
    {
      "epoch": 4.385542168674699,
      "grad_norm": 6.861870288848877,
      "learning_rate": 1.5614457831325304e-05,
      "loss": 0.0509,
      "step": 36400
    },
    {
      "epoch": 4.386746987951807,
      "grad_norm": 0.0748380795121193,
      "learning_rate": 1.5613253012048196e-05,
      "loss": 0.0442,
      "step": 36410
    },
    {
      "epoch": 4.387951807228916,
      "grad_norm": 9.98300552368164,
      "learning_rate": 1.5612048192771086e-05,
      "loss": 0.0671,
      "step": 36420
    },
    {
      "epoch": 4.389156626506024,
      "grad_norm": 2.759310007095337,
      "learning_rate": 1.5610843373493978e-05,
      "loss": 0.0547,
      "step": 36430
    },
    {
      "epoch": 4.390361445783133,
      "grad_norm": 4.296724796295166,
      "learning_rate": 1.5609638554216867e-05,
      "loss": 0.0822,
      "step": 36440
    },
    {
      "epoch": 4.391566265060241,
      "grad_norm": 0.42824894189834595,
      "learning_rate": 1.560843373493976e-05,
      "loss": 0.0339,
      "step": 36450
    },
    {
      "epoch": 4.392771084337349,
      "grad_norm": 0.3149334490299225,
      "learning_rate": 1.5607228915662652e-05,
      "loss": 0.021,
      "step": 36460
    },
    {
      "epoch": 4.393975903614458,
      "grad_norm": 0.07816153764724731,
      "learning_rate": 1.5606024096385544e-05,
      "loss": 0.0487,
      "step": 36470
    },
    {
      "epoch": 4.395180722891566,
      "grad_norm": 5.948054313659668,
      "learning_rate": 1.5604819277108433e-05,
      "loss": 0.0479,
      "step": 36480
    },
    {
      "epoch": 4.396385542168675,
      "grad_norm": 1.321909785270691,
      "learning_rate": 1.5603614457831326e-05,
      "loss": 0.06,
      "step": 36490
    },
    {
      "epoch": 4.397590361445783,
      "grad_norm": 2.0448873043060303,
      "learning_rate": 1.5602409638554218e-05,
      "loss": 0.076,
      "step": 36500
    },
    {
      "epoch": 4.3987951807228916,
      "grad_norm": 8.404557228088379,
      "learning_rate": 1.560120481927711e-05,
      "loss": 0.0629,
      "step": 36510
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.07170112431049347,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.0385,
      "step": 36520
    },
    {
      "epoch": 4.401204819277108,
      "grad_norm": 1.235903263092041,
      "learning_rate": 1.5598795180722892e-05,
      "loss": 0.0586,
      "step": 36530
    },
    {
      "epoch": 4.402409638554217,
      "grad_norm": 0.028469152748584747,
      "learning_rate": 1.5597590361445785e-05,
      "loss": 0.1144,
      "step": 36540
    },
    {
      "epoch": 4.403614457831325,
      "grad_norm": 3.238022565841675,
      "learning_rate": 1.5596385542168674e-05,
      "loss": 0.1083,
      "step": 36550
    },
    {
      "epoch": 4.404819277108434,
      "grad_norm": 1.7355810403823853,
      "learning_rate": 1.5595180722891566e-05,
      "loss": 0.0489,
      "step": 36560
    },
    {
      "epoch": 4.406024096385542,
      "grad_norm": 0.691705584526062,
      "learning_rate": 1.559397590361446e-05,
      "loss": 0.0164,
      "step": 36570
    },
    {
      "epoch": 4.4072289156626505,
      "grad_norm": 0.1264084279537201,
      "learning_rate": 1.559277108433735e-05,
      "loss": 0.0744,
      "step": 36580
    },
    {
      "epoch": 4.408433734939759,
      "grad_norm": 17.723831176757812,
      "learning_rate": 1.5591566265060243e-05,
      "loss": 0.0416,
      "step": 36590
    },
    {
      "epoch": 4.409638554216867,
      "grad_norm": 0.03472047299146652,
      "learning_rate": 1.5590361445783132e-05,
      "loss": 0.045,
      "step": 36600
    },
    {
      "epoch": 4.410843373493976,
      "grad_norm": 23.009042739868164,
      "learning_rate": 1.5589156626506025e-05,
      "loss": 0.1066,
      "step": 36610
    },
    {
      "epoch": 4.412048192771084,
      "grad_norm": 1.950135350227356,
      "learning_rate": 1.5587951807228917e-05,
      "loss": 0.0632,
      "step": 36620
    },
    {
      "epoch": 4.413253012048193,
      "grad_norm": 0.2514457702636719,
      "learning_rate": 1.558674698795181e-05,
      "loss": 0.0962,
      "step": 36630
    },
    {
      "epoch": 4.414457831325302,
      "grad_norm": 0.06813038140535355,
      "learning_rate": 1.5585542168674702e-05,
      "loss": 0.0486,
      "step": 36640
    },
    {
      "epoch": 4.4156626506024095,
      "grad_norm": 0.22548681497573853,
      "learning_rate": 1.558433734939759e-05,
      "loss": 0.0778,
      "step": 36650
    },
    {
      "epoch": 4.416867469879518,
      "grad_norm": 2.381639003753662,
      "learning_rate": 1.5583132530120484e-05,
      "loss": 0.0233,
      "step": 36660
    },
    {
      "epoch": 4.418072289156626,
      "grad_norm": 0.7905309796333313,
      "learning_rate": 1.5581927710843373e-05,
      "loss": 0.0486,
      "step": 36670
    },
    {
      "epoch": 4.419277108433735,
      "grad_norm": 2.6083779335021973,
      "learning_rate": 1.5580722891566265e-05,
      "loss": 0.0985,
      "step": 36680
    },
    {
      "epoch": 4.420481927710844,
      "grad_norm": 3.262694835662842,
      "learning_rate": 1.5579518072289158e-05,
      "loss": 0.079,
      "step": 36690
    },
    {
      "epoch": 4.421686746987952,
      "grad_norm": 28.076168060302734,
      "learning_rate": 1.557831325301205e-05,
      "loss": 0.0129,
      "step": 36700
    },
    {
      "epoch": 4.4228915662650605,
      "grad_norm": 3.707411050796509,
      "learning_rate": 1.5577108433734942e-05,
      "loss": 0.019,
      "step": 36710
    },
    {
      "epoch": 4.424096385542168,
      "grad_norm": 0.7938193082809448,
      "learning_rate": 1.557590361445783e-05,
      "loss": 0.1478,
      "step": 36720
    },
    {
      "epoch": 4.425301204819277,
      "grad_norm": 1.7065225839614868,
      "learning_rate": 1.5574698795180724e-05,
      "loss": 0.0445,
      "step": 36730
    },
    {
      "epoch": 4.426506024096385,
      "grad_norm": 0.12136339396238327,
      "learning_rate": 1.5573493975903616e-05,
      "loss": 0.1065,
      "step": 36740
    },
    {
      "epoch": 4.427710843373494,
      "grad_norm": 0.682567834854126,
      "learning_rate": 1.557228915662651e-05,
      "loss": 0.0156,
      "step": 36750
    },
    {
      "epoch": 4.428915662650603,
      "grad_norm": 0.08002571016550064,
      "learning_rate": 1.5571084337349398e-05,
      "loss": 0.1004,
      "step": 36760
    },
    {
      "epoch": 4.430120481927711,
      "grad_norm": 50.404747009277344,
      "learning_rate": 1.556987951807229e-05,
      "loss": 0.0291,
      "step": 36770
    },
    {
      "epoch": 4.4313253012048195,
      "grad_norm": 17.482948303222656,
      "learning_rate": 1.556867469879518e-05,
      "loss": 0.0815,
      "step": 36780
    },
    {
      "epoch": 4.432530120481927,
      "grad_norm": 1.1561580896377563,
      "learning_rate": 1.5567469879518072e-05,
      "loss": 0.0673,
      "step": 36790
    },
    {
      "epoch": 4.433734939759036,
      "grad_norm": 8.229114532470703,
      "learning_rate": 1.5566265060240968e-05,
      "loss": 0.0753,
      "step": 36800
    },
    {
      "epoch": 4.434939759036144,
      "grad_norm": 2.3944616317749023,
      "learning_rate": 1.5565060240963857e-05,
      "loss": 0.0403,
      "step": 36810
    },
    {
      "epoch": 4.436144578313253,
      "grad_norm": 0.6673468947410583,
      "learning_rate": 1.556385542168675e-05,
      "loss": 0.015,
      "step": 36820
    },
    {
      "epoch": 4.437349397590362,
      "grad_norm": 0.04478275403380394,
      "learning_rate": 1.5562650602409638e-05,
      "loss": 0.0246,
      "step": 36830
    },
    {
      "epoch": 4.43855421686747,
      "grad_norm": 67.52345275878906,
      "learning_rate": 1.556144578313253e-05,
      "loss": 0.0457,
      "step": 36840
    },
    {
      "epoch": 4.4397590361445785,
      "grad_norm": 0.0323541983962059,
      "learning_rate": 1.5560240963855423e-05,
      "loss": 0.0505,
      "step": 36850
    },
    {
      "epoch": 4.440963855421686,
      "grad_norm": 4.03014612197876,
      "learning_rate": 1.5559036144578315e-05,
      "loss": 0.104,
      "step": 36860
    },
    {
      "epoch": 4.442168674698795,
      "grad_norm": 11.76347827911377,
      "learning_rate": 1.5557831325301208e-05,
      "loss": 0.106,
      "step": 36870
    },
    {
      "epoch": 4.443373493975904,
      "grad_norm": 23.16756820678711,
      "learning_rate": 1.5556626506024097e-05,
      "loss": 0.0307,
      "step": 36880
    },
    {
      "epoch": 4.444578313253012,
      "grad_norm": 0.08527874946594238,
      "learning_rate": 1.555542168674699e-05,
      "loss": 0.0221,
      "step": 36890
    },
    {
      "epoch": 4.445783132530121,
      "grad_norm": 6.438256740570068,
      "learning_rate": 1.5554216867469882e-05,
      "loss": 0.0391,
      "step": 36900
    },
    {
      "epoch": 4.446987951807229,
      "grad_norm": 0.02591875195503235,
      "learning_rate": 1.5553012048192774e-05,
      "loss": 0.0661,
      "step": 36910
    },
    {
      "epoch": 4.448192771084337,
      "grad_norm": 2.232095718383789,
      "learning_rate": 1.5551807228915663e-05,
      "loss": 0.0356,
      "step": 36920
    },
    {
      "epoch": 4.449397590361446,
      "grad_norm": 0.01664533093571663,
      "learning_rate": 1.5550602409638556e-05,
      "loss": 0.0389,
      "step": 36930
    },
    {
      "epoch": 4.450602409638554,
      "grad_norm": 0.027186010032892227,
      "learning_rate": 1.5549397590361448e-05,
      "loss": 0.0349,
      "step": 36940
    },
    {
      "epoch": 4.451807228915663,
      "grad_norm": 0.25988656282424927,
      "learning_rate": 1.5548192771084337e-05,
      "loss": 0.0117,
      "step": 36950
    },
    {
      "epoch": 4.453012048192771,
      "grad_norm": 0.03811315819621086,
      "learning_rate": 1.554698795180723e-05,
      "loss": 0.0325,
      "step": 36960
    },
    {
      "epoch": 4.45421686746988,
      "grad_norm": 2.558366298675537,
      "learning_rate": 1.5545783132530122e-05,
      "loss": 0.116,
      "step": 36970
    },
    {
      "epoch": 4.455421686746988,
      "grad_norm": 0.03195404261350632,
      "learning_rate": 1.5544578313253014e-05,
      "loss": 0.0758,
      "step": 36980
    },
    {
      "epoch": 4.456626506024096,
      "grad_norm": 0.3408832848072052,
      "learning_rate": 1.5543373493975904e-05,
      "loss": 0.007,
      "step": 36990
    },
    {
      "epoch": 4.457831325301205,
      "grad_norm": 0.019703051075339317,
      "learning_rate": 1.5542168674698796e-05,
      "loss": 0.0286,
      "step": 37000
    },
    {
      "epoch": 4.459036144578313,
      "grad_norm": 15.353768348693848,
      "learning_rate": 1.554096385542169e-05,
      "loss": 0.099,
      "step": 37010
    },
    {
      "epoch": 4.460240963855422,
      "grad_norm": 7.368679046630859,
      "learning_rate": 1.553975903614458e-05,
      "loss": 0.0566,
      "step": 37020
    },
    {
      "epoch": 4.46144578313253,
      "grad_norm": 0.022161360830068588,
      "learning_rate": 1.5538554216867473e-05,
      "loss": 0.0385,
      "step": 37030
    },
    {
      "epoch": 4.462650602409639,
      "grad_norm": 0.040227390825748444,
      "learning_rate": 1.5537349397590362e-05,
      "loss": 0.0786,
      "step": 37040
    },
    {
      "epoch": 4.4638554216867465,
      "grad_norm": 0.045663051307201385,
      "learning_rate": 1.5536144578313255e-05,
      "loss": 0.0628,
      "step": 37050
    },
    {
      "epoch": 4.465060240963855,
      "grad_norm": 14.287442207336426,
      "learning_rate": 1.5534939759036144e-05,
      "loss": 0.0328,
      "step": 37060
    },
    {
      "epoch": 4.466265060240964,
      "grad_norm": 7.231505393981934,
      "learning_rate": 1.5533734939759036e-05,
      "loss": 0.0567,
      "step": 37070
    },
    {
      "epoch": 4.467469879518072,
      "grad_norm": 3.4779231548309326,
      "learning_rate": 1.553253012048193e-05,
      "loss": 0.076,
      "step": 37080
    },
    {
      "epoch": 4.468674698795181,
      "grad_norm": 7.403808116912842,
      "learning_rate": 1.553132530120482e-05,
      "loss": 0.0872,
      "step": 37090
    },
    {
      "epoch": 4.469879518072289,
      "grad_norm": 0.12823446094989777,
      "learning_rate": 1.5530120481927714e-05,
      "loss": 0.0723,
      "step": 37100
    },
    {
      "epoch": 4.471084337349398,
      "grad_norm": 0.32623806595802307,
      "learning_rate": 1.5528915662650603e-05,
      "loss": 0.0325,
      "step": 37110
    },
    {
      "epoch": 4.472289156626506,
      "grad_norm": 4.149834156036377,
      "learning_rate": 1.5527710843373495e-05,
      "loss": 0.0449,
      "step": 37120
    },
    {
      "epoch": 4.473493975903614,
      "grad_norm": 0.044392555952072144,
      "learning_rate": 1.5526506024096387e-05,
      "loss": 0.0451,
      "step": 37130
    },
    {
      "epoch": 4.474698795180723,
      "grad_norm": 0.07915832102298737,
      "learning_rate": 1.552530120481928e-05,
      "loss": 0.0579,
      "step": 37140
    },
    {
      "epoch": 4.475903614457831,
      "grad_norm": 0.2200157642364502,
      "learning_rate": 1.552409638554217e-05,
      "loss": 0.0865,
      "step": 37150
    },
    {
      "epoch": 4.47710843373494,
      "grad_norm": 0.7827713489532471,
      "learning_rate": 1.552289156626506e-05,
      "loss": 0.0538,
      "step": 37160
    },
    {
      "epoch": 4.478313253012049,
      "grad_norm": 0.6968510150909424,
      "learning_rate": 1.5521686746987954e-05,
      "loss": 0.0466,
      "step": 37170
    },
    {
      "epoch": 4.4795180722891565,
      "grad_norm": 0.3675864636898041,
      "learning_rate": 1.5520481927710843e-05,
      "loss": 0.0438,
      "step": 37180
    },
    {
      "epoch": 4.480722891566265,
      "grad_norm": 0.06435465067625046,
      "learning_rate": 1.5519277108433735e-05,
      "loss": 0.0703,
      "step": 37190
    },
    {
      "epoch": 4.481927710843373,
      "grad_norm": 0.11098021268844604,
      "learning_rate": 1.5518072289156628e-05,
      "loss": 0.0395,
      "step": 37200
    },
    {
      "epoch": 4.483132530120482,
      "grad_norm": 0.024967020377516747,
      "learning_rate": 1.551686746987952e-05,
      "loss": 0.0714,
      "step": 37210
    },
    {
      "epoch": 4.48433734939759,
      "grad_norm": 0.15261246263980865,
      "learning_rate": 1.551566265060241e-05,
      "loss": 0.0485,
      "step": 37220
    },
    {
      "epoch": 4.485542168674699,
      "grad_norm": 1.563860297203064,
      "learning_rate": 1.55144578313253e-05,
      "loss": 0.0347,
      "step": 37230
    },
    {
      "epoch": 4.486746987951808,
      "grad_norm": 0.23267348110675812,
      "learning_rate": 1.5513253012048194e-05,
      "loss": 0.0581,
      "step": 37240
    },
    {
      "epoch": 4.4879518072289155,
      "grad_norm": 0.1009574756026268,
      "learning_rate": 1.5512048192771086e-05,
      "loss": 0.0482,
      "step": 37250
    },
    {
      "epoch": 4.489156626506024,
      "grad_norm": 2.1376123428344727,
      "learning_rate": 1.551084337349398e-05,
      "loss": 0.0702,
      "step": 37260
    },
    {
      "epoch": 4.490361445783132,
      "grad_norm": 1.5380545854568481,
      "learning_rate": 1.5509638554216868e-05,
      "loss": 0.0346,
      "step": 37270
    },
    {
      "epoch": 4.491566265060241,
      "grad_norm": 2.2457971572875977,
      "learning_rate": 1.550843373493976e-05,
      "loss": 0.0295,
      "step": 37280
    },
    {
      "epoch": 4.492771084337349,
      "grad_norm": 3.7951369285583496,
      "learning_rate": 1.550722891566265e-05,
      "loss": 0.0425,
      "step": 37290
    },
    {
      "epoch": 4.493975903614458,
      "grad_norm": 4.38128137588501,
      "learning_rate": 1.5506024096385542e-05,
      "loss": 0.0952,
      "step": 37300
    },
    {
      "epoch": 4.495180722891567,
      "grad_norm": 3.027580499649048,
      "learning_rate": 1.5504819277108438e-05,
      "loss": 0.0783,
      "step": 37310
    },
    {
      "epoch": 4.4963855421686745,
      "grad_norm": 21.16642189025879,
      "learning_rate": 1.5503614457831327e-05,
      "loss": 0.0294,
      "step": 37320
    },
    {
      "epoch": 4.497590361445783,
      "grad_norm": 3.007830858230591,
      "learning_rate": 1.550240963855422e-05,
      "loss": 0.0765,
      "step": 37330
    },
    {
      "epoch": 4.498795180722891,
      "grad_norm": 18.333629608154297,
      "learning_rate": 1.5501204819277108e-05,
      "loss": 0.1366,
      "step": 37340
    },
    {
      "epoch": 4.5,
      "grad_norm": 1.0602940320968628,
      "learning_rate": 1.55e-05,
      "loss": 0.0955,
      "step": 37350
    },
    {
      "epoch": 4.501204819277109,
      "grad_norm": 0.09219786524772644,
      "learning_rate": 1.5498795180722893e-05,
      "loss": 0.0399,
      "step": 37360
    },
    {
      "epoch": 4.502409638554217,
      "grad_norm": 3.7990267276763916,
      "learning_rate": 1.5497590361445786e-05,
      "loss": 0.0177,
      "step": 37370
    },
    {
      "epoch": 4.5036144578313255,
      "grad_norm": 0.1777665615081787,
      "learning_rate": 1.5496385542168678e-05,
      "loss": 0.055,
      "step": 37380
    },
    {
      "epoch": 4.504819277108433,
      "grad_norm": 7.965851306915283,
      "learning_rate": 1.5495180722891567e-05,
      "loss": 0.0577,
      "step": 37390
    },
    {
      "epoch": 4.506024096385542,
      "grad_norm": 0.031564861536026,
      "learning_rate": 1.549397590361446e-05,
      "loss": 0.0151,
      "step": 37400
    },
    {
      "epoch": 4.507228915662651,
      "grad_norm": 11.206069946289062,
      "learning_rate": 1.5492771084337352e-05,
      "loss": 0.0748,
      "step": 37410
    },
    {
      "epoch": 4.508433734939759,
      "grad_norm": 1.5599297285079956,
      "learning_rate": 1.5491566265060244e-05,
      "loss": 0.0496,
      "step": 37420
    },
    {
      "epoch": 4.509638554216868,
      "grad_norm": 1.3515300750732422,
      "learning_rate": 1.5490361445783133e-05,
      "loss": 0.0615,
      "step": 37430
    },
    {
      "epoch": 4.510843373493976,
      "grad_norm": 0.03681648150086403,
      "learning_rate": 1.5489156626506026e-05,
      "loss": 0.0684,
      "step": 37440
    },
    {
      "epoch": 4.5120481927710845,
      "grad_norm": 0.02905595675110817,
      "learning_rate": 1.5487951807228915e-05,
      "loss": 0.0126,
      "step": 37450
    },
    {
      "epoch": 4.513253012048192,
      "grad_norm": 0.04318540170788765,
      "learning_rate": 1.5486746987951807e-05,
      "loss": 0.0859,
      "step": 37460
    },
    {
      "epoch": 4.514457831325301,
      "grad_norm": 0.03591059148311615,
      "learning_rate": 1.54855421686747e-05,
      "loss": 0.0185,
      "step": 37470
    },
    {
      "epoch": 4.51566265060241,
      "grad_norm": 0.03182049095630646,
      "learning_rate": 1.5484337349397592e-05,
      "loss": 0.0841,
      "step": 37480
    },
    {
      "epoch": 4.516867469879518,
      "grad_norm": 0.5583383440971375,
      "learning_rate": 1.5483132530120485e-05,
      "loss": 0.1049,
      "step": 37490
    },
    {
      "epoch": 4.518072289156627,
      "grad_norm": 0.11818032711744308,
      "learning_rate": 1.5481927710843374e-05,
      "loss": 0.0129,
      "step": 37500
    },
    {
      "epoch": 4.519277108433735,
      "grad_norm": 0.032676391303539276,
      "learning_rate": 1.5480722891566266e-05,
      "loss": 0.0508,
      "step": 37510
    },
    {
      "epoch": 4.5204819277108435,
      "grad_norm": 0.04076342284679413,
      "learning_rate": 1.547951807228916e-05,
      "loss": 0.0505,
      "step": 37520
    },
    {
      "epoch": 4.521686746987951,
      "grad_norm": 4.39872407913208,
      "learning_rate": 1.547831325301205e-05,
      "loss": 0.0895,
      "step": 37530
    },
    {
      "epoch": 4.52289156626506,
      "grad_norm": 0.09066668152809143,
      "learning_rate": 1.5477108433734943e-05,
      "loss": 0.0026,
      "step": 37540
    },
    {
      "epoch": 4.524096385542169,
      "grad_norm": 4.169796466827393,
      "learning_rate": 1.5475903614457832e-05,
      "loss": 0.0789,
      "step": 37550
    },
    {
      "epoch": 4.525301204819277,
      "grad_norm": 0.05327196046710014,
      "learning_rate": 1.5474698795180725e-05,
      "loss": 0.0413,
      "step": 37560
    },
    {
      "epoch": 4.526506024096386,
      "grad_norm": 4.8817338943481445,
      "learning_rate": 1.5473493975903614e-05,
      "loss": 0.0794,
      "step": 37570
    },
    {
      "epoch": 4.527710843373494,
      "grad_norm": 0.10388994961977005,
      "learning_rate": 1.5472289156626506e-05,
      "loss": 0.0774,
      "step": 37580
    },
    {
      "epoch": 4.528915662650602,
      "grad_norm": 0.2818099558353424,
      "learning_rate": 1.54710843373494e-05,
      "loss": 0.0254,
      "step": 37590
    },
    {
      "epoch": 4.530120481927711,
      "grad_norm": 2.076183795928955,
      "learning_rate": 1.546987951807229e-05,
      "loss": 0.041,
      "step": 37600
    },
    {
      "epoch": 4.531325301204819,
      "grad_norm": 8.348567008972168,
      "learning_rate": 1.5468674698795184e-05,
      "loss": 0.0361,
      "step": 37610
    },
    {
      "epoch": 4.532530120481928,
      "grad_norm": 0.21258994936943054,
      "learning_rate": 1.5467469879518073e-05,
      "loss": 0.0547,
      "step": 37620
    },
    {
      "epoch": 4.533734939759036,
      "grad_norm": 0.1282867193222046,
      "learning_rate": 1.5466265060240965e-05,
      "loss": 0.0199,
      "step": 37630
    },
    {
      "epoch": 4.534939759036145,
      "grad_norm": 0.39645177125930786,
      "learning_rate": 1.5465060240963858e-05,
      "loss": 0.0255,
      "step": 37640
    },
    {
      "epoch": 4.5361445783132535,
      "grad_norm": 0.368757039308548,
      "learning_rate": 1.546385542168675e-05,
      "loss": 0.0305,
      "step": 37650
    },
    {
      "epoch": 4.537349397590361,
      "grad_norm": 0.03571078181266785,
      "learning_rate": 1.546265060240964e-05,
      "loss": 0.0199,
      "step": 37660
    },
    {
      "epoch": 4.53855421686747,
      "grad_norm": 0.008277771063148975,
      "learning_rate": 1.546144578313253e-05,
      "loss": 0.1004,
      "step": 37670
    },
    {
      "epoch": 4.539759036144578,
      "grad_norm": 9.03356647491455,
      "learning_rate": 1.5460240963855424e-05,
      "loss": 0.1868,
      "step": 37680
    },
    {
      "epoch": 4.540963855421687,
      "grad_norm": 0.19635681807994843,
      "learning_rate": 1.5459036144578313e-05,
      "loss": 0.0122,
      "step": 37690
    },
    {
      "epoch": 4.542168674698795,
      "grad_norm": 25.999326705932617,
      "learning_rate": 1.5457831325301205e-05,
      "loss": 0.0563,
      "step": 37700
    },
    {
      "epoch": 4.543373493975904,
      "grad_norm": 0.3885376751422882,
      "learning_rate": 1.5456626506024098e-05,
      "loss": 0.0332,
      "step": 37710
    },
    {
      "epoch": 4.544578313253012,
      "grad_norm": 0.4486444294452667,
      "learning_rate": 1.545542168674699e-05,
      "loss": 0.032,
      "step": 37720
    },
    {
      "epoch": 4.54578313253012,
      "grad_norm": 0.030572684481739998,
      "learning_rate": 1.545421686746988e-05,
      "loss": 0.0734,
      "step": 37730
    },
    {
      "epoch": 4.546987951807229,
      "grad_norm": 0.037433452904224396,
      "learning_rate": 1.5453012048192772e-05,
      "loss": 0.102,
      "step": 37740
    },
    {
      "epoch": 4.548192771084337,
      "grad_norm": 0.389794260263443,
      "learning_rate": 1.5451807228915664e-05,
      "loss": 0.015,
      "step": 37750
    },
    {
      "epoch": 4.549397590361446,
      "grad_norm": 0.11631681770086288,
      "learning_rate": 1.5450602409638557e-05,
      "loss": 0.0643,
      "step": 37760
    },
    {
      "epoch": 4.550602409638554,
      "grad_norm": 0.02874528430402279,
      "learning_rate": 1.544939759036145e-05,
      "loss": 0.0269,
      "step": 37770
    },
    {
      "epoch": 4.551807228915663,
      "grad_norm": 0.13417193293571472,
      "learning_rate": 1.5448192771084338e-05,
      "loss": 0.0983,
      "step": 37780
    },
    {
      "epoch": 4.553012048192771,
      "grad_norm": 0.10804665833711624,
      "learning_rate": 1.544698795180723e-05,
      "loss": 0.0438,
      "step": 37790
    },
    {
      "epoch": 4.554216867469879,
      "grad_norm": 0.44797876477241516,
      "learning_rate": 1.544578313253012e-05,
      "loss": 0.1002,
      "step": 37800
    },
    {
      "epoch": 4.555421686746988,
      "grad_norm": 0.10762285441160202,
      "learning_rate": 1.5444578313253012e-05,
      "loss": 0.0289,
      "step": 37810
    },
    {
      "epoch": 4.556626506024096,
      "grad_norm": 0.37617141008377075,
      "learning_rate": 1.5443373493975904e-05,
      "loss": 0.0314,
      "step": 37820
    },
    {
      "epoch": 4.557831325301205,
      "grad_norm": 0.09152507036924362,
      "learning_rate": 1.5442168674698797e-05,
      "loss": 0.0967,
      "step": 37830
    },
    {
      "epoch": 4.559036144578314,
      "grad_norm": 0.07372366636991501,
      "learning_rate": 1.544096385542169e-05,
      "loss": 0.0304,
      "step": 37840
    },
    {
      "epoch": 4.5602409638554215,
      "grad_norm": 1.373355746269226,
      "learning_rate": 1.543975903614458e-05,
      "loss": 0.052,
      "step": 37850
    },
    {
      "epoch": 4.56144578313253,
      "grad_norm": 0.08272602409124374,
      "learning_rate": 1.543855421686747e-05,
      "loss": 0.0613,
      "step": 37860
    },
    {
      "epoch": 4.562650602409638,
      "grad_norm": 0.06226407736539841,
      "learning_rate": 1.5437349397590363e-05,
      "loss": 0.0682,
      "step": 37870
    },
    {
      "epoch": 4.563855421686747,
      "grad_norm": 0.03914986923336983,
      "learning_rate": 1.5436144578313256e-05,
      "loss": 0.0709,
      "step": 37880
    },
    {
      "epoch": 4.565060240963856,
      "grad_norm": 7.238283634185791,
      "learning_rate": 1.5434939759036145e-05,
      "loss": 0.1122,
      "step": 37890
    },
    {
      "epoch": 4.566265060240964,
      "grad_norm": 2.194945812225342,
      "learning_rate": 1.5433734939759037e-05,
      "loss": 0.0401,
      "step": 37900
    },
    {
      "epoch": 4.567469879518073,
      "grad_norm": 3.7790489196777344,
      "learning_rate": 1.543253012048193e-05,
      "loss": 0.0669,
      "step": 37910
    },
    {
      "epoch": 4.5686746987951805,
      "grad_norm": 3.5572094917297363,
      "learning_rate": 1.543132530120482e-05,
      "loss": 0.0393,
      "step": 37920
    },
    {
      "epoch": 4.569879518072289,
      "grad_norm": 1.3729984760284424,
      "learning_rate": 1.5430120481927714e-05,
      "loss": 0.0487,
      "step": 37930
    },
    {
      "epoch": 4.571084337349397,
      "grad_norm": 5.866179943084717,
      "learning_rate": 1.5428915662650604e-05,
      "loss": 0.1046,
      "step": 37940
    },
    {
      "epoch": 4.572289156626506,
      "grad_norm": 11.628629684448242,
      "learning_rate": 1.5427710843373496e-05,
      "loss": 0.0416,
      "step": 37950
    },
    {
      "epoch": 4.573493975903615,
      "grad_norm": 0.48590677976608276,
      "learning_rate": 1.5426506024096385e-05,
      "loss": 0.0394,
      "step": 37960
    },
    {
      "epoch": 4.574698795180723,
      "grad_norm": 2.623861789703369,
      "learning_rate": 1.5425301204819277e-05,
      "loss": 0.0918,
      "step": 37970
    },
    {
      "epoch": 4.575903614457832,
      "grad_norm": 4.62286901473999,
      "learning_rate": 1.542409638554217e-05,
      "loss": 0.1229,
      "step": 37980
    },
    {
      "epoch": 4.5771084337349395,
      "grad_norm": 29.40553092956543,
      "learning_rate": 1.5422891566265062e-05,
      "loss": 0.0722,
      "step": 37990
    },
    {
      "epoch": 4.578313253012048,
      "grad_norm": 10.509866714477539,
      "learning_rate": 1.5421686746987955e-05,
      "loss": 0.0888,
      "step": 38000
    },
    {
      "epoch": 4.579518072289156,
      "grad_norm": 4.4296674728393555,
      "learning_rate": 1.5420481927710844e-05,
      "loss": 0.0378,
      "step": 38010
    },
    {
      "epoch": 4.580722891566265,
      "grad_norm": 4.899650573730469,
      "learning_rate": 1.5419277108433736e-05,
      "loss": 0.02,
      "step": 38020
    },
    {
      "epoch": 4.581927710843374,
      "grad_norm": 3.0716538429260254,
      "learning_rate": 1.541807228915663e-05,
      "loss": 0.1102,
      "step": 38030
    },
    {
      "epoch": 4.583132530120482,
      "grad_norm": 0.2604055404663086,
      "learning_rate": 1.541686746987952e-05,
      "loss": 0.0127,
      "step": 38040
    },
    {
      "epoch": 4.5843373493975905,
      "grad_norm": 14.174549102783203,
      "learning_rate": 1.541566265060241e-05,
      "loss": 0.02,
      "step": 38050
    },
    {
      "epoch": 4.585542168674698,
      "grad_norm": 0.0883917510509491,
      "learning_rate": 1.5414457831325303e-05,
      "loss": 0.0696,
      "step": 38060
    },
    {
      "epoch": 4.586746987951807,
      "grad_norm": 0.008791422471404076,
      "learning_rate": 1.5413253012048195e-05,
      "loss": 0.0943,
      "step": 38070
    },
    {
      "epoch": 4.587951807228916,
      "grad_norm": 3.7431869506835938,
      "learning_rate": 1.5412048192771084e-05,
      "loss": 0.1077,
      "step": 38080
    },
    {
      "epoch": 4.589156626506024,
      "grad_norm": 3.017850160598755,
      "learning_rate": 1.5410843373493976e-05,
      "loss": 0.0925,
      "step": 38090
    },
    {
      "epoch": 4.590361445783133,
      "grad_norm": 2.6800129413604736,
      "learning_rate": 1.540963855421687e-05,
      "loss": 0.0661,
      "step": 38100
    },
    {
      "epoch": 4.591566265060241,
      "grad_norm": 0.263713538646698,
      "learning_rate": 1.540843373493976e-05,
      "loss": 0.0342,
      "step": 38110
    },
    {
      "epoch": 4.5927710843373495,
      "grad_norm": 0.480295330286026,
      "learning_rate": 1.540722891566265e-05,
      "loss": 0.0332,
      "step": 38120
    },
    {
      "epoch": 4.593975903614458,
      "grad_norm": 1.2255990505218506,
      "learning_rate": 1.5406024096385543e-05,
      "loss": 0.1254,
      "step": 38130
    },
    {
      "epoch": 4.595180722891566,
      "grad_norm": 1.4465999603271484,
      "learning_rate": 1.5404819277108435e-05,
      "loss": 0.0279,
      "step": 38140
    },
    {
      "epoch": 4.596385542168675,
      "grad_norm": 3.7082364559173584,
      "learning_rate": 1.5403614457831328e-05,
      "loss": 0.1129,
      "step": 38150
    },
    {
      "epoch": 4.597590361445783,
      "grad_norm": 0.3595225214958191,
      "learning_rate": 1.540240963855422e-05,
      "loss": 0.0538,
      "step": 38160
    },
    {
      "epoch": 4.598795180722892,
      "grad_norm": 0.18418599665164948,
      "learning_rate": 1.540120481927711e-05,
      "loss": 0.0534,
      "step": 38170
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.324299156665802,
      "learning_rate": 1.54e-05,
      "loss": 0.0348,
      "step": 38180
    },
    {
      "epoch": 4.6012048192771084,
      "grad_norm": 1.9288653135299683,
      "learning_rate": 1.539879518072289e-05,
      "loss": 0.0774,
      "step": 38190
    },
    {
      "epoch": 4.602409638554217,
      "grad_norm": 0.41397976875305176,
      "learning_rate": 1.5397590361445783e-05,
      "loss": 0.012,
      "step": 38200
    },
    {
      "epoch": 4.603614457831325,
      "grad_norm": 1.0400665998458862,
      "learning_rate": 1.5396385542168676e-05,
      "loss": 0.0432,
      "step": 38210
    },
    {
      "epoch": 4.604819277108434,
      "grad_norm": 0.021278949454426765,
      "learning_rate": 1.5395180722891568e-05,
      "loss": 0.0606,
      "step": 38220
    },
    {
      "epoch": 4.606024096385542,
      "grad_norm": 1.8080453872680664,
      "learning_rate": 1.539397590361446e-05,
      "loss": 0.0575,
      "step": 38230
    },
    {
      "epoch": 4.607228915662651,
      "grad_norm": 0.49450281262397766,
      "learning_rate": 1.539277108433735e-05,
      "loss": 0.0424,
      "step": 38240
    },
    {
      "epoch": 4.608433734939759,
      "grad_norm": 13.416845321655273,
      "learning_rate": 1.5391566265060242e-05,
      "loss": 0.0673,
      "step": 38250
    },
    {
      "epoch": 4.609638554216867,
      "grad_norm": 0.056214589625597,
      "learning_rate": 1.5390361445783134e-05,
      "loss": 0.054,
      "step": 38260
    },
    {
      "epoch": 4.610843373493976,
      "grad_norm": 0.03239644691348076,
      "learning_rate": 1.5389156626506027e-05,
      "loss": 0.0964,
      "step": 38270
    },
    {
      "epoch": 4.612048192771084,
      "grad_norm": 11.515847206115723,
      "learning_rate": 1.538795180722892e-05,
      "loss": 0.0704,
      "step": 38280
    },
    {
      "epoch": 4.613253012048193,
      "grad_norm": 1.2215629816055298,
      "learning_rate": 1.5386746987951808e-05,
      "loss": 0.0641,
      "step": 38290
    },
    {
      "epoch": 4.614457831325301,
      "grad_norm": 0.5457243323326111,
      "learning_rate": 1.53855421686747e-05,
      "loss": 0.0595,
      "step": 38300
    },
    {
      "epoch": 4.61566265060241,
      "grad_norm": 1.2280480861663818,
      "learning_rate": 1.538433734939759e-05,
      "loss": 0.0711,
      "step": 38310
    },
    {
      "epoch": 4.6168674698795185,
      "grad_norm": 0.24247674643993378,
      "learning_rate": 1.5383132530120482e-05,
      "loss": 0.0087,
      "step": 38320
    },
    {
      "epoch": 4.618072289156626,
      "grad_norm": 0.1480574607849121,
      "learning_rate": 1.5381927710843375e-05,
      "loss": 0.0609,
      "step": 38330
    },
    {
      "epoch": 4.619277108433735,
      "grad_norm": 0.10971908271312714,
      "learning_rate": 1.5380722891566267e-05,
      "loss": 0.0301,
      "step": 38340
    },
    {
      "epoch": 4.620481927710843,
      "grad_norm": 9.355137825012207,
      "learning_rate": 1.5379518072289156e-05,
      "loss": 0.0498,
      "step": 38350
    },
    {
      "epoch": 4.621686746987952,
      "grad_norm": 0.3606451153755188,
      "learning_rate": 1.537831325301205e-05,
      "loss": 0.1104,
      "step": 38360
    },
    {
      "epoch": 4.622891566265061,
      "grad_norm": 2.6674435138702393,
      "learning_rate": 1.537710843373494e-05,
      "loss": 0.0624,
      "step": 38370
    },
    {
      "epoch": 4.624096385542169,
      "grad_norm": 2.7227563858032227,
      "learning_rate": 1.5375903614457833e-05,
      "loss": 0.0812,
      "step": 38380
    },
    {
      "epoch": 4.625301204819277,
      "grad_norm": 0.1813657581806183,
      "learning_rate": 1.5374698795180726e-05,
      "loss": 0.0543,
      "step": 38390
    },
    {
      "epoch": 4.626506024096385,
      "grad_norm": 1.2480446100234985,
      "learning_rate": 1.5373493975903615e-05,
      "loss": 0.0759,
      "step": 38400
    },
    {
      "epoch": 4.627710843373494,
      "grad_norm": 0.28770527243614197,
      "learning_rate": 1.5372289156626507e-05,
      "loss": 0.0269,
      "step": 38410
    },
    {
      "epoch": 4.628915662650602,
      "grad_norm": 0.9951235055923462,
      "learning_rate": 1.5371084337349396e-05,
      "loss": 0.0765,
      "step": 38420
    },
    {
      "epoch": 4.630120481927711,
      "grad_norm": 2.7631397247314453,
      "learning_rate": 1.536987951807229e-05,
      "loss": 0.0834,
      "step": 38430
    },
    {
      "epoch": 4.63132530120482,
      "grad_norm": 0.05164631828665733,
      "learning_rate": 1.5368674698795185e-05,
      "loss": 0.09,
      "step": 38440
    },
    {
      "epoch": 4.632530120481928,
      "grad_norm": 2.5042331218719482,
      "learning_rate": 1.5367469879518074e-05,
      "loss": 0.0204,
      "step": 38450
    },
    {
      "epoch": 4.633734939759036,
      "grad_norm": 2.910054922103882,
      "learning_rate": 1.5366265060240966e-05,
      "loss": 0.0447,
      "step": 38460
    },
    {
      "epoch": 4.634939759036144,
      "grad_norm": 5.9215850830078125,
      "learning_rate": 1.5365060240963855e-05,
      "loss": 0.0392,
      "step": 38470
    },
    {
      "epoch": 4.636144578313253,
      "grad_norm": 0.035125598311424255,
      "learning_rate": 1.5363855421686748e-05,
      "loss": 0.0367,
      "step": 38480
    },
    {
      "epoch": 4.637349397590361,
      "grad_norm": 0.2634883522987366,
      "learning_rate": 1.536265060240964e-05,
      "loss": 0.0248,
      "step": 38490
    },
    {
      "epoch": 4.63855421686747,
      "grad_norm": 0.009955777786672115,
      "learning_rate": 1.5361445783132532e-05,
      "loss": 0.0416,
      "step": 38500
    },
    {
      "epoch": 4.639759036144579,
      "grad_norm": 0.07361119240522385,
      "learning_rate": 1.5360240963855425e-05,
      "loss": 0.0859,
      "step": 38510
    },
    {
      "epoch": 4.6409638554216865,
      "grad_norm": 1.171919345855713,
      "learning_rate": 1.5359036144578314e-05,
      "loss": 0.0236,
      "step": 38520
    },
    {
      "epoch": 4.642168674698795,
      "grad_norm": 0.007574844639748335,
      "learning_rate": 1.5357831325301206e-05,
      "loss": 0.0583,
      "step": 38530
    },
    {
      "epoch": 4.643373493975903,
      "grad_norm": 2.1442863941192627,
      "learning_rate": 1.5356626506024095e-05,
      "loss": 0.0773,
      "step": 38540
    },
    {
      "epoch": 4.644578313253012,
      "grad_norm": 0.04064140468835831,
      "learning_rate": 1.535542168674699e-05,
      "loss": 0.0838,
      "step": 38550
    },
    {
      "epoch": 4.64578313253012,
      "grad_norm": 0.08198969066143036,
      "learning_rate": 1.535421686746988e-05,
      "loss": 0.0627,
      "step": 38560
    },
    {
      "epoch": 4.646987951807229,
      "grad_norm": 0.6846223473548889,
      "learning_rate": 1.5353012048192773e-05,
      "loss": 0.0661,
      "step": 38570
    },
    {
      "epoch": 4.648192771084338,
      "grad_norm": 4.389018535614014,
      "learning_rate": 1.5351807228915665e-05,
      "loss": 0.0539,
      "step": 38580
    },
    {
      "epoch": 4.6493975903614455,
      "grad_norm": 0.38312506675720215,
      "learning_rate": 1.5350602409638554e-05,
      "loss": 0.0514,
      "step": 38590
    },
    {
      "epoch": 4.650602409638554,
      "grad_norm": 2.023081064224243,
      "learning_rate": 1.5349397590361447e-05,
      "loss": 0.069,
      "step": 38600
    },
    {
      "epoch": 4.651807228915663,
      "grad_norm": 0.1446031779050827,
      "learning_rate": 1.534819277108434e-05,
      "loss": 0.0633,
      "step": 38610
    },
    {
      "epoch": 4.653012048192771,
      "grad_norm": 0.11739269644021988,
      "learning_rate": 1.534698795180723e-05,
      "loss": 0.0931,
      "step": 38620
    },
    {
      "epoch": 4.65421686746988,
      "grad_norm": 0.26231440901756287,
      "learning_rate": 1.534578313253012e-05,
      "loss": 0.0436,
      "step": 38630
    },
    {
      "epoch": 4.655421686746988,
      "grad_norm": 0.3799440264701843,
      "learning_rate": 1.5344578313253013e-05,
      "loss": 0.0146,
      "step": 38640
    },
    {
      "epoch": 4.656626506024097,
      "grad_norm": 0.010541039519011974,
      "learning_rate": 1.5343373493975905e-05,
      "loss": 0.0889,
      "step": 38650
    },
    {
      "epoch": 4.6578313253012045,
      "grad_norm": 3.553307056427002,
      "learning_rate": 1.5342168674698798e-05,
      "loss": 0.0878,
      "step": 38660
    },
    {
      "epoch": 4.659036144578313,
      "grad_norm": 10.072885513305664,
      "learning_rate": 1.534096385542169e-05,
      "loss": 0.028,
      "step": 38670
    },
    {
      "epoch": 4.660240963855422,
      "grad_norm": 5.243360996246338,
      "learning_rate": 1.533975903614458e-05,
      "loss": 0.0645,
      "step": 38680
    },
    {
      "epoch": 4.66144578313253,
      "grad_norm": 3.2484936714172363,
      "learning_rate": 1.5338554216867472e-05,
      "loss": 0.0196,
      "step": 38690
    },
    {
      "epoch": 4.662650602409639,
      "grad_norm": 0.01796662248671055,
      "learning_rate": 1.533734939759036e-05,
      "loss": 0.0344,
      "step": 38700
    },
    {
      "epoch": 4.663855421686747,
      "grad_norm": 0.49466776847839355,
      "learning_rate": 1.5336144578313253e-05,
      "loss": 0.0279,
      "step": 38710
    },
    {
      "epoch": 4.6650602409638555,
      "grad_norm": 0.06749912351369858,
      "learning_rate": 1.5334939759036146e-05,
      "loss": 0.0412,
      "step": 38720
    },
    {
      "epoch": 4.666265060240963,
      "grad_norm": 13.728946685791016,
      "learning_rate": 1.5333734939759038e-05,
      "loss": 0.0937,
      "step": 38730
    },
    {
      "epoch": 4.667469879518072,
      "grad_norm": 0.2479598969221115,
      "learning_rate": 1.533253012048193e-05,
      "loss": 0.0579,
      "step": 38740
    },
    {
      "epoch": 4.668674698795181,
      "grad_norm": 0.140554279088974,
      "learning_rate": 1.533132530120482e-05,
      "loss": 0.0211,
      "step": 38750
    },
    {
      "epoch": 4.669879518072289,
      "grad_norm": 0.02171037159860134,
      "learning_rate": 1.5330120481927712e-05,
      "loss": 0.0795,
      "step": 38760
    },
    {
      "epoch": 4.671084337349398,
      "grad_norm": 10.00374698638916,
      "learning_rate": 1.5328915662650604e-05,
      "loss": 0.0358,
      "step": 38770
    },
    {
      "epoch": 4.672289156626506,
      "grad_norm": 2.871014356613159,
      "learning_rate": 1.5327710843373497e-05,
      "loss": 0.0995,
      "step": 38780
    },
    {
      "epoch": 4.6734939759036145,
      "grad_norm": 3.066740036010742,
      "learning_rate": 1.5326506024096386e-05,
      "loss": 0.0708,
      "step": 38790
    },
    {
      "epoch": 4.674698795180722,
      "grad_norm": 1.7461227178573608,
      "learning_rate": 1.532530120481928e-05,
      "loss": 0.0585,
      "step": 38800
    },
    {
      "epoch": 4.675903614457831,
      "grad_norm": 14.277990341186523,
      "learning_rate": 1.532409638554217e-05,
      "loss": 0.0117,
      "step": 38810
    },
    {
      "epoch": 4.67710843373494,
      "grad_norm": 0.0048267110250890255,
      "learning_rate": 1.532289156626506e-05,
      "loss": 0.1065,
      "step": 38820
    },
    {
      "epoch": 4.678313253012048,
      "grad_norm": 0.10620453208684921,
      "learning_rate": 1.5321686746987952e-05,
      "loss": 0.009,
      "step": 38830
    },
    {
      "epoch": 4.679518072289157,
      "grad_norm": 0.994500994682312,
      "learning_rate": 1.5320481927710845e-05,
      "loss": 0.1214,
      "step": 38840
    },
    {
      "epoch": 4.6807228915662655,
      "grad_norm": 1.9934370517730713,
      "learning_rate": 1.5319277108433737e-05,
      "loss": 0.1269,
      "step": 38850
    },
    {
      "epoch": 4.6819277108433734,
      "grad_norm": 0.3458876609802246,
      "learning_rate": 1.5318072289156626e-05,
      "loss": 0.0563,
      "step": 38860
    },
    {
      "epoch": 4.683132530120482,
      "grad_norm": 3.4713099002838135,
      "learning_rate": 1.531686746987952e-05,
      "loss": 0.0581,
      "step": 38870
    },
    {
      "epoch": 4.68433734939759,
      "grad_norm": 0.17874008417129517,
      "learning_rate": 1.531566265060241e-05,
      "loss": 0.0624,
      "step": 38880
    },
    {
      "epoch": 4.685542168674699,
      "grad_norm": 0.14888150990009308,
      "learning_rate": 1.5314457831325304e-05,
      "loss": 0.0552,
      "step": 38890
    },
    {
      "epoch": 4.686746987951807,
      "grad_norm": 0.2769857943058014,
      "learning_rate": 1.5313253012048196e-05,
      "loss": 0.0391,
      "step": 38900
    },
    {
      "epoch": 4.687951807228916,
      "grad_norm": 0.0842275470495224,
      "learning_rate": 1.5312048192771085e-05,
      "loss": 0.0478,
      "step": 38910
    },
    {
      "epoch": 4.6891566265060245,
      "grad_norm": 4.1269450187683105,
      "learning_rate": 1.5310843373493977e-05,
      "loss": 0.0607,
      "step": 38920
    },
    {
      "epoch": 4.690361445783132,
      "grad_norm": 1.1241179704666138,
      "learning_rate": 1.5309638554216866e-05,
      "loss": 0.039,
      "step": 38930
    },
    {
      "epoch": 4.691566265060241,
      "grad_norm": 0.020001156255602837,
      "learning_rate": 1.530843373493976e-05,
      "loss": 0.0443,
      "step": 38940
    },
    {
      "epoch": 4.692771084337349,
      "grad_norm": 5.245398044586182,
      "learning_rate": 1.530722891566265e-05,
      "loss": 0.1151,
      "step": 38950
    },
    {
      "epoch": 4.693975903614458,
      "grad_norm": 5.248901844024658,
      "learning_rate": 1.5306024096385544e-05,
      "loss": 0.0811,
      "step": 38960
    },
    {
      "epoch": 4.695180722891566,
      "grad_norm": 0.35971349477767944,
      "learning_rate": 1.5304819277108436e-05,
      "loss": 0.0112,
      "step": 38970
    },
    {
      "epoch": 4.696385542168675,
      "grad_norm": 2.091540813446045,
      "learning_rate": 1.5303614457831325e-05,
      "loss": 0.037,
      "step": 38980
    },
    {
      "epoch": 4.6975903614457835,
      "grad_norm": 0.05627455189824104,
      "learning_rate": 1.5302409638554218e-05,
      "loss": 0.0454,
      "step": 38990
    },
    {
      "epoch": 4.698795180722891,
      "grad_norm": 9.296825408935547,
      "learning_rate": 1.530120481927711e-05,
      "loss": 0.0763,
      "step": 39000
    },
    {
      "epoch": 4.7,
      "grad_norm": 13.174038887023926,
      "learning_rate": 1.5300000000000003e-05,
      "loss": 0.0918,
      "step": 39010
    },
    {
      "epoch": 4.701204819277108,
      "grad_norm": 11.80639362335205,
      "learning_rate": 1.529879518072289e-05,
      "loss": 0.1035,
      "step": 39020
    },
    {
      "epoch": 4.702409638554217,
      "grad_norm": 7.5327253341674805,
      "learning_rate": 1.5297590361445784e-05,
      "loss": 0.0734,
      "step": 39030
    },
    {
      "epoch": 4.703614457831325,
      "grad_norm": 14.42311954498291,
      "learning_rate": 1.5296385542168677e-05,
      "loss": 0.0821,
      "step": 39040
    },
    {
      "epoch": 4.704819277108434,
      "grad_norm": 0.9363083243370056,
      "learning_rate": 1.5295180722891566e-05,
      "loss": 0.0776,
      "step": 39050
    },
    {
      "epoch": 4.706024096385542,
      "grad_norm": 0.08343224227428436,
      "learning_rate": 1.529397590361446e-05,
      "loss": 0.0529,
      "step": 39060
    },
    {
      "epoch": 4.70722891566265,
      "grad_norm": 0.15397971868515015,
      "learning_rate": 1.529277108433735e-05,
      "loss": 0.0606,
      "step": 39070
    },
    {
      "epoch": 4.708433734939759,
      "grad_norm": 1.329526662826538,
      "learning_rate": 1.5291566265060243e-05,
      "loss": 0.0202,
      "step": 39080
    },
    {
      "epoch": 4.709638554216868,
      "grad_norm": 0.012562635354697704,
      "learning_rate": 1.5290361445783132e-05,
      "loss": 0.0311,
      "step": 39090
    },
    {
      "epoch": 4.710843373493976,
      "grad_norm": 16.23141860961914,
      "learning_rate": 1.5289156626506024e-05,
      "loss": 0.0647,
      "step": 39100
    },
    {
      "epoch": 4.712048192771085,
      "grad_norm": 0.3568844795227051,
      "learning_rate": 1.5287951807228917e-05,
      "loss": 0.0512,
      "step": 39110
    },
    {
      "epoch": 4.713253012048193,
      "grad_norm": 2.483389139175415,
      "learning_rate": 1.528674698795181e-05,
      "loss": 0.0703,
      "step": 39120
    },
    {
      "epoch": 4.714457831325301,
      "grad_norm": 0.7581948041915894,
      "learning_rate": 1.52855421686747e-05,
      "loss": 0.0624,
      "step": 39130
    },
    {
      "epoch": 4.715662650602409,
      "grad_norm": 0.48862317204475403,
      "learning_rate": 1.528433734939759e-05,
      "loss": 0.0468,
      "step": 39140
    },
    {
      "epoch": 4.716867469879518,
      "grad_norm": 0.11861125379800797,
      "learning_rate": 1.5283132530120483e-05,
      "loss": 0.0566,
      "step": 39150
    },
    {
      "epoch": 4.718072289156627,
      "grad_norm": 7.663078784942627,
      "learning_rate": 1.5281927710843376e-05,
      "loss": 0.0693,
      "step": 39160
    },
    {
      "epoch": 4.719277108433735,
      "grad_norm": 2.9688327312469482,
      "learning_rate": 1.5280722891566268e-05,
      "loss": 0.0451,
      "step": 39170
    },
    {
      "epoch": 4.720481927710844,
      "grad_norm": 3.9333138465881348,
      "learning_rate": 1.527951807228916e-05,
      "loss": 0.0496,
      "step": 39180
    },
    {
      "epoch": 4.7216867469879515,
      "grad_norm": 0.716925323009491,
      "learning_rate": 1.527831325301205e-05,
      "loss": 0.035,
      "step": 39190
    },
    {
      "epoch": 4.72289156626506,
      "grad_norm": 0.7441391944885254,
      "learning_rate": 1.5277108433734942e-05,
      "loss": 0.0542,
      "step": 39200
    },
    {
      "epoch": 4.724096385542168,
      "grad_norm": 23.962936401367188,
      "learning_rate": 1.527590361445783e-05,
      "loss": 0.0466,
      "step": 39210
    },
    {
      "epoch": 4.725301204819277,
      "grad_norm": 0.26624736189842224,
      "learning_rate": 1.5274698795180723e-05,
      "loss": 0.0981,
      "step": 39220
    },
    {
      "epoch": 4.726506024096386,
      "grad_norm": 1.2262303829193115,
      "learning_rate": 1.5273493975903616e-05,
      "loss": 0.0416,
      "step": 39230
    },
    {
      "epoch": 4.727710843373494,
      "grad_norm": 0.014631032943725586,
      "learning_rate": 1.5272289156626508e-05,
      "loss": 0.082,
      "step": 39240
    },
    {
      "epoch": 4.728915662650603,
      "grad_norm": 1.9990826845169067,
      "learning_rate": 1.5271084337349397e-05,
      "loss": 0.0691,
      "step": 39250
    },
    {
      "epoch": 4.7301204819277105,
      "grad_norm": 0.7241969704627991,
      "learning_rate": 1.526987951807229e-05,
      "loss": 0.0674,
      "step": 39260
    },
    {
      "epoch": 4.731325301204819,
      "grad_norm": 4.2836594581604,
      "learning_rate": 1.5268674698795182e-05,
      "loss": 0.0792,
      "step": 39270
    },
    {
      "epoch": 4.732530120481927,
      "grad_norm": 0.018763376399874687,
      "learning_rate": 1.5267469879518075e-05,
      "loss": 0.0091,
      "step": 39280
    },
    {
      "epoch": 4.733734939759036,
      "grad_norm": 4.392466068267822,
      "learning_rate": 1.5266265060240967e-05,
      "loss": 0.0846,
      "step": 39290
    },
    {
      "epoch": 4.734939759036145,
      "grad_norm": 0.03257470205426216,
      "learning_rate": 1.5265060240963856e-05,
      "loss": 0.0921,
      "step": 39300
    },
    {
      "epoch": 4.736144578313253,
      "grad_norm": 6.059953689575195,
      "learning_rate": 1.526385542168675e-05,
      "loss": 0.0351,
      "step": 39310
    },
    {
      "epoch": 4.7373493975903616,
      "grad_norm": 3.6076622009277344,
      "learning_rate": 1.5262650602409638e-05,
      "loss": 0.0334,
      "step": 39320
    },
    {
      "epoch": 4.73855421686747,
      "grad_norm": 0.12429540604352951,
      "learning_rate": 1.526144578313253e-05,
      "loss": 0.0425,
      "step": 39330
    },
    {
      "epoch": 4.739759036144578,
      "grad_norm": 0.23845922946929932,
      "learning_rate": 1.5260240963855422e-05,
      "loss": 0.0611,
      "step": 39340
    },
    {
      "epoch": 4.740963855421687,
      "grad_norm": 9.540803909301758,
      "learning_rate": 1.5259036144578315e-05,
      "loss": 0.0778,
      "step": 39350
    },
    {
      "epoch": 4.742168674698795,
      "grad_norm": 4.097837924957275,
      "learning_rate": 1.5257831325301207e-05,
      "loss": 0.0269,
      "step": 39360
    },
    {
      "epoch": 4.743373493975904,
      "grad_norm": 0.13678079843521118,
      "learning_rate": 1.5256626506024096e-05,
      "loss": 0.0383,
      "step": 39370
    },
    {
      "epoch": 4.744578313253012,
      "grad_norm": 8.768678665161133,
      "learning_rate": 1.5255421686746989e-05,
      "loss": 0.0348,
      "step": 39380
    },
    {
      "epoch": 4.7457831325301205,
      "grad_norm": 1.4609355926513672,
      "learning_rate": 1.525421686746988e-05,
      "loss": 0.0574,
      "step": 39390
    },
    {
      "epoch": 4.746987951807229,
      "grad_norm": 0.676033079624176,
      "learning_rate": 1.5253012048192772e-05,
      "loss": 0.0475,
      "step": 39400
    },
    {
      "epoch": 4.748192771084337,
      "grad_norm": 0.12737025320529938,
      "learning_rate": 1.5251807228915664e-05,
      "loss": 0.0937,
      "step": 39410
    },
    {
      "epoch": 4.749397590361446,
      "grad_norm": 0.5554962158203125,
      "learning_rate": 1.5250602409638555e-05,
      "loss": 0.0786,
      "step": 39420
    },
    {
      "epoch": 4.750602409638554,
      "grad_norm": 19.149629592895508,
      "learning_rate": 1.5249397590361448e-05,
      "loss": 0.0315,
      "step": 39430
    },
    {
      "epoch": 4.751807228915663,
      "grad_norm": 4.803319454193115,
      "learning_rate": 1.5248192771084338e-05,
      "loss": 0.05,
      "step": 39440
    },
    {
      "epoch": 4.753012048192771,
      "grad_norm": 0.0832672119140625,
      "learning_rate": 1.524698795180723e-05,
      "loss": 0.0323,
      "step": 39450
    },
    {
      "epoch": 4.7542168674698795,
      "grad_norm": 0.12193227559328079,
      "learning_rate": 1.5245783132530122e-05,
      "loss": 0.0797,
      "step": 39460
    },
    {
      "epoch": 4.755421686746988,
      "grad_norm": 1.9157382249832153,
      "learning_rate": 1.5244578313253014e-05,
      "loss": 0.0372,
      "step": 39470
    },
    {
      "epoch": 4.756626506024096,
      "grad_norm": 0.1780933439731598,
      "learning_rate": 1.5243373493975906e-05,
      "loss": 0.0326,
      "step": 39480
    },
    {
      "epoch": 4.757831325301205,
      "grad_norm": 0.39541199803352356,
      "learning_rate": 1.5242168674698795e-05,
      "loss": 0.0509,
      "step": 39490
    },
    {
      "epoch": 4.759036144578313,
      "grad_norm": 0.3043809235095978,
      "learning_rate": 1.524096385542169e-05,
      "loss": 0.0812,
      "step": 39500
    },
    {
      "epoch": 4.760240963855422,
      "grad_norm": 18.1778621673584,
      "learning_rate": 1.5239759036144579e-05,
      "loss": 0.029,
      "step": 39510
    },
    {
      "epoch": 4.76144578313253,
      "grad_norm": 0.03606129810214043,
      "learning_rate": 1.5238554216867471e-05,
      "loss": 0.0128,
      "step": 39520
    },
    {
      "epoch": 4.7626506024096384,
      "grad_norm": 11.107478141784668,
      "learning_rate": 1.5237349397590362e-05,
      "loss": 0.0465,
      "step": 39530
    },
    {
      "epoch": 4.763855421686747,
      "grad_norm": 2.2348358631134033,
      "learning_rate": 1.5236144578313254e-05,
      "loss": 0.0285,
      "step": 39540
    },
    {
      "epoch": 4.765060240963855,
      "grad_norm": 0.036597590893507004,
      "learning_rate": 1.5234939759036145e-05,
      "loss": 0.0554,
      "step": 39550
    },
    {
      "epoch": 4.766265060240964,
      "grad_norm": 1.5533740520477295,
      "learning_rate": 1.5233734939759037e-05,
      "loss": 0.0291,
      "step": 39560
    },
    {
      "epoch": 4.767469879518073,
      "grad_norm": 0.02328559197485447,
      "learning_rate": 1.523253012048193e-05,
      "loss": 0.0724,
      "step": 39570
    },
    {
      "epoch": 4.768674698795181,
      "grad_norm": 9.828251838684082,
      "learning_rate": 1.523132530120482e-05,
      "loss": 0.052,
      "step": 39580
    },
    {
      "epoch": 4.7698795180722895,
      "grad_norm": 0.31957346200942993,
      "learning_rate": 1.5230120481927713e-05,
      "loss": 0.0688,
      "step": 39590
    },
    {
      "epoch": 4.771084337349397,
      "grad_norm": 0.9647842645645142,
      "learning_rate": 1.5228915662650604e-05,
      "loss": 0.0929,
      "step": 39600
    },
    {
      "epoch": 4.772289156626506,
      "grad_norm": 3.7180936336517334,
      "learning_rate": 1.5227710843373496e-05,
      "loss": 0.0966,
      "step": 39610
    },
    {
      "epoch": 4.773493975903614,
      "grad_norm": 8.60409164428711,
      "learning_rate": 1.5226506024096385e-05,
      "loss": 0.0741,
      "step": 39620
    },
    {
      "epoch": 4.774698795180723,
      "grad_norm": 0.03442206606268883,
      "learning_rate": 1.5225301204819278e-05,
      "loss": 0.0803,
      "step": 39630
    },
    {
      "epoch": 4.775903614457832,
      "grad_norm": 4.4607391357421875,
      "learning_rate": 1.522409638554217e-05,
      "loss": 0.1207,
      "step": 39640
    },
    {
      "epoch": 4.77710843373494,
      "grad_norm": 31.080581665039062,
      "learning_rate": 1.522289156626506e-05,
      "loss": 0.057,
      "step": 39650
    },
    {
      "epoch": 4.7783132530120485,
      "grad_norm": 0.9841230511665344,
      "learning_rate": 1.5221686746987953e-05,
      "loss": 0.0709,
      "step": 39660
    },
    {
      "epoch": 4.779518072289156,
      "grad_norm": 0.29372891783714294,
      "learning_rate": 1.5220481927710844e-05,
      "loss": 0.0686,
      "step": 39670
    },
    {
      "epoch": 4.780722891566265,
      "grad_norm": 6.386068820953369,
      "learning_rate": 1.5219277108433736e-05,
      "loss": 0.1224,
      "step": 39680
    },
    {
      "epoch": 4.781927710843373,
      "grad_norm": 10.663565635681152,
      "learning_rate": 1.5218072289156627e-05,
      "loss": 0.0416,
      "step": 39690
    },
    {
      "epoch": 4.783132530120482,
      "grad_norm": 1.5118842124938965,
      "learning_rate": 1.521686746987952e-05,
      "loss": 0.0298,
      "step": 39700
    },
    {
      "epoch": 4.784337349397591,
      "grad_norm": 0.04020301252603531,
      "learning_rate": 1.5215662650602412e-05,
      "loss": 0.0189,
      "step": 39710
    },
    {
      "epoch": 4.785542168674699,
      "grad_norm": 0.10155034065246582,
      "learning_rate": 1.5214457831325303e-05,
      "loss": 0.0306,
      "step": 39720
    },
    {
      "epoch": 4.786746987951807,
      "grad_norm": 4.219091892242432,
      "learning_rate": 1.5213253012048195e-05,
      "loss": 0.0876,
      "step": 39730
    },
    {
      "epoch": 4.787951807228915,
      "grad_norm": 1.969527006149292,
      "learning_rate": 1.5212048192771084e-05,
      "loss": 0.07,
      "step": 39740
    },
    {
      "epoch": 4.789156626506024,
      "grad_norm": 0.13417087495326996,
      "learning_rate": 1.5210843373493977e-05,
      "loss": 0.087,
      "step": 39750
    },
    {
      "epoch": 4.790361445783132,
      "grad_norm": 0.46092602610588074,
      "learning_rate": 1.5209638554216867e-05,
      "loss": 0.0682,
      "step": 39760
    },
    {
      "epoch": 4.791566265060241,
      "grad_norm": 5.470114231109619,
      "learning_rate": 1.520843373493976e-05,
      "loss": 0.0569,
      "step": 39770
    },
    {
      "epoch": 4.79277108433735,
      "grad_norm": 0.12327507138252258,
      "learning_rate": 1.5207228915662652e-05,
      "loss": 0.0121,
      "step": 39780
    },
    {
      "epoch": 4.793975903614458,
      "grad_norm": 6.984430313110352,
      "learning_rate": 1.5206024096385543e-05,
      "loss": 0.05,
      "step": 39790
    },
    {
      "epoch": 4.795180722891566,
      "grad_norm": 0.07979831099510193,
      "learning_rate": 1.5204819277108436e-05,
      "loss": 0.0186,
      "step": 39800
    },
    {
      "epoch": 4.796385542168675,
      "grad_norm": 0.43196481466293335,
      "learning_rate": 1.5203614457831326e-05,
      "loss": 0.0503,
      "step": 39810
    },
    {
      "epoch": 4.797590361445783,
      "grad_norm": 1.6340527534484863,
      "learning_rate": 1.5202409638554219e-05,
      "loss": 0.0712,
      "step": 39820
    },
    {
      "epoch": 4.798795180722892,
      "grad_norm": 9.753671646118164,
      "learning_rate": 1.520120481927711e-05,
      "loss": 0.0277,
      "step": 39830
    },
    {
      "epoch": 4.8,
      "grad_norm": 18.150110244750977,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.0394,
      "step": 39840
    },
    {
      "epoch": 4.801204819277109,
      "grad_norm": 2.70943284034729,
      "learning_rate": 1.5198795180722891e-05,
      "loss": 0.036,
      "step": 39850
    },
    {
      "epoch": 4.8024096385542165,
      "grad_norm": 1.8308353424072266,
      "learning_rate": 1.5197590361445785e-05,
      "loss": 0.052,
      "step": 39860
    },
    {
      "epoch": 4.803614457831325,
      "grad_norm": 7.212255001068115,
      "learning_rate": 1.5196385542168677e-05,
      "loss": 0.1179,
      "step": 39870
    },
    {
      "epoch": 4.804819277108434,
      "grad_norm": 0.8767324090003967,
      "learning_rate": 1.5195180722891567e-05,
      "loss": 0.0822,
      "step": 39880
    },
    {
      "epoch": 4.806024096385542,
      "grad_norm": 0.056261688470840454,
      "learning_rate": 1.5193975903614459e-05,
      "loss": 0.0495,
      "step": 39890
    },
    {
      "epoch": 4.807228915662651,
      "grad_norm": 4.766208648681641,
      "learning_rate": 1.519277108433735e-05,
      "loss": 0.1117,
      "step": 39900
    },
    {
      "epoch": 4.808433734939759,
      "grad_norm": 7.930700302124023,
      "learning_rate": 1.5191566265060242e-05,
      "loss": 0.0416,
      "step": 39910
    },
    {
      "epoch": 4.809638554216868,
      "grad_norm": 3.1289515495300293,
      "learning_rate": 1.5190361445783133e-05,
      "loss": 0.088,
      "step": 39920
    },
    {
      "epoch": 4.8108433734939755,
      "grad_norm": 0.3697732090950012,
      "learning_rate": 1.5189156626506025e-05,
      "loss": 0.1608,
      "step": 39930
    },
    {
      "epoch": 4.812048192771084,
      "grad_norm": 6.981701374053955,
      "learning_rate": 1.5187951807228918e-05,
      "loss": 0.0284,
      "step": 39940
    },
    {
      "epoch": 4.813253012048193,
      "grad_norm": 6.992684841156006,
      "learning_rate": 1.5186746987951808e-05,
      "loss": 0.0812,
      "step": 39950
    },
    {
      "epoch": 4.814457831325301,
      "grad_norm": 0.01180932205170393,
      "learning_rate": 1.5185542168674701e-05,
      "loss": 0.0637,
      "step": 39960
    },
    {
      "epoch": 4.81566265060241,
      "grad_norm": 12.347853660583496,
      "learning_rate": 1.5184337349397592e-05,
      "loss": 0.0365,
      "step": 39970
    },
    {
      "epoch": 4.816867469879518,
      "grad_norm": 0.37367552518844604,
      "learning_rate": 1.5183132530120484e-05,
      "loss": 0.0745,
      "step": 39980
    },
    {
      "epoch": 4.8180722891566266,
      "grad_norm": 3.2589802742004395,
      "learning_rate": 1.5181927710843373e-05,
      "loss": 0.0545,
      "step": 39990
    },
    {
      "epoch": 4.8192771084337345,
      "grad_norm": 0.010337669402360916,
      "learning_rate": 1.5180722891566266e-05,
      "loss": 0.0457,
      "step": 40000
    },
    {
      "epoch": 4.820481927710843,
      "grad_norm": 1.6892051696777344,
      "learning_rate": 1.517951807228916e-05,
      "loss": 0.0926,
      "step": 40010
    },
    {
      "epoch": 4.821686746987952,
      "grad_norm": 0.022058632224798203,
      "learning_rate": 1.5178313253012049e-05,
      "loss": 0.0538,
      "step": 40020
    },
    {
      "epoch": 4.82289156626506,
      "grad_norm": 5.733506202697754,
      "learning_rate": 1.5177108433734941e-05,
      "loss": 0.0652,
      "step": 40030
    },
    {
      "epoch": 4.824096385542169,
      "grad_norm": 1.3203864097595215,
      "learning_rate": 1.5175903614457832e-05,
      "loss": 0.088,
      "step": 40040
    },
    {
      "epoch": 4.825301204819278,
      "grad_norm": 0.21229667961597443,
      "learning_rate": 1.5174698795180724e-05,
      "loss": 0.0558,
      "step": 40050
    },
    {
      "epoch": 4.8265060240963855,
      "grad_norm": 0.4781470000743866,
      "learning_rate": 1.5173493975903615e-05,
      "loss": 0.042,
      "step": 40060
    },
    {
      "epoch": 4.827710843373494,
      "grad_norm": 1.932541012763977,
      "learning_rate": 1.5172289156626508e-05,
      "loss": 0.0273,
      "step": 40070
    },
    {
      "epoch": 4.828915662650602,
      "grad_norm": 6.735400199890137,
      "learning_rate": 1.51710843373494e-05,
      "loss": 0.1076,
      "step": 40080
    },
    {
      "epoch": 4.830120481927711,
      "grad_norm": 5.0014801025390625,
      "learning_rate": 1.516987951807229e-05,
      "loss": 0.0403,
      "step": 40090
    },
    {
      "epoch": 4.831325301204819,
      "grad_norm": 7.442420959472656,
      "learning_rate": 1.5168674698795183e-05,
      "loss": 0.0854,
      "step": 40100
    },
    {
      "epoch": 4.832530120481928,
      "grad_norm": 0.1605839878320694,
      "learning_rate": 1.5167469879518074e-05,
      "loss": 0.0309,
      "step": 40110
    },
    {
      "epoch": 4.833734939759037,
      "grad_norm": 0.2879777252674103,
      "learning_rate": 1.5166265060240966e-05,
      "loss": 0.0289,
      "step": 40120
    },
    {
      "epoch": 4.8349397590361445,
      "grad_norm": 0.5155170559883118,
      "learning_rate": 1.5165060240963855e-05,
      "loss": 0.0324,
      "step": 40130
    },
    {
      "epoch": 4.836144578313253,
      "grad_norm": 1.777053952217102,
      "learning_rate": 1.5163855421686748e-05,
      "loss": 0.0436,
      "step": 40140
    },
    {
      "epoch": 4.837349397590361,
      "grad_norm": 0.05826171115040779,
      "learning_rate": 1.5162650602409639e-05,
      "loss": 0.0436,
      "step": 40150
    },
    {
      "epoch": 4.83855421686747,
      "grad_norm": 0.15866729617118835,
      "learning_rate": 1.5161445783132531e-05,
      "loss": 0.0542,
      "step": 40160
    },
    {
      "epoch": 4.839759036144578,
      "grad_norm": 0.011125171557068825,
      "learning_rate": 1.5160240963855423e-05,
      "loss": 0.071,
      "step": 40170
    },
    {
      "epoch": 4.840963855421687,
      "grad_norm": 1.763877034187317,
      "learning_rate": 1.5159036144578314e-05,
      "loss": 0.0431,
      "step": 40180
    },
    {
      "epoch": 4.8421686746987955,
      "grad_norm": 0.1509874016046524,
      "learning_rate": 1.5157831325301207e-05,
      "loss": 0.0715,
      "step": 40190
    },
    {
      "epoch": 4.843373493975903,
      "grad_norm": 3.915865421295166,
      "learning_rate": 1.5156626506024097e-05,
      "loss": 0.0677,
      "step": 40200
    },
    {
      "epoch": 4.844578313253012,
      "grad_norm": 0.008860954083502293,
      "learning_rate": 1.515542168674699e-05,
      "loss": 0.0354,
      "step": 40210
    },
    {
      "epoch": 4.84578313253012,
      "grad_norm": 0.22177845239639282,
      "learning_rate": 1.515421686746988e-05,
      "loss": 0.0416,
      "step": 40220
    },
    {
      "epoch": 4.846987951807229,
      "grad_norm": 0.07778694480657578,
      "learning_rate": 1.5153012048192773e-05,
      "loss": 0.0539,
      "step": 40230
    },
    {
      "epoch": 4.848192771084337,
      "grad_norm": 0.10396993905305862,
      "learning_rate": 1.5151807228915665e-05,
      "loss": 0.0161,
      "step": 40240
    },
    {
      "epoch": 4.849397590361446,
      "grad_norm": 0.45318013429641724,
      "learning_rate": 1.5150602409638554e-05,
      "loss": 0.0662,
      "step": 40250
    },
    {
      "epoch": 4.8506024096385545,
      "grad_norm": 5.465000152587891,
      "learning_rate": 1.5149397590361447e-05,
      "loss": 0.0376,
      "step": 40260
    },
    {
      "epoch": 4.851807228915662,
      "grad_norm": 0.10874470323324203,
      "learning_rate": 1.5148192771084338e-05,
      "loss": 0.0213,
      "step": 40270
    },
    {
      "epoch": 4.853012048192771,
      "grad_norm": 0.023148655891418457,
      "learning_rate": 1.514698795180723e-05,
      "loss": 0.0586,
      "step": 40280
    },
    {
      "epoch": 4.85421686746988,
      "grad_norm": 0.4884796440601349,
      "learning_rate": 1.514578313253012e-05,
      "loss": 0.0801,
      "step": 40290
    },
    {
      "epoch": 4.855421686746988,
      "grad_norm": 0.4346286654472351,
      "learning_rate": 1.5144578313253013e-05,
      "loss": 0.0258,
      "step": 40300
    },
    {
      "epoch": 4.856626506024097,
      "grad_norm": 0.6773169040679932,
      "learning_rate": 1.5143373493975906e-05,
      "loss": 0.0376,
      "step": 40310
    },
    {
      "epoch": 4.857831325301205,
      "grad_norm": 0.007452786434441805,
      "learning_rate": 1.5142168674698796e-05,
      "loss": 0.0593,
      "step": 40320
    },
    {
      "epoch": 4.8590361445783135,
      "grad_norm": 0.15252402424812317,
      "learning_rate": 1.5140963855421689e-05,
      "loss": 0.0471,
      "step": 40330
    },
    {
      "epoch": 4.860240963855421,
      "grad_norm": 0.062012214213609695,
      "learning_rate": 1.513975903614458e-05,
      "loss": 0.0343,
      "step": 40340
    },
    {
      "epoch": 4.86144578313253,
      "grad_norm": 8.756580352783203,
      "learning_rate": 1.5138554216867472e-05,
      "loss": 0.1084,
      "step": 40350
    },
    {
      "epoch": 4.862650602409639,
      "grad_norm": 3.928253412246704,
      "learning_rate": 1.5137349397590361e-05,
      "loss": 0.029,
      "step": 40360
    },
    {
      "epoch": 4.863855421686747,
      "grad_norm": 2.0393714904785156,
      "learning_rate": 1.5136144578313255e-05,
      "loss": 0.0255,
      "step": 40370
    },
    {
      "epoch": 4.865060240963856,
      "grad_norm": 0.9108903408050537,
      "learning_rate": 1.5134939759036148e-05,
      "loss": 0.0493,
      "step": 40380
    },
    {
      "epoch": 4.866265060240964,
      "grad_norm": 2.8409829139709473,
      "learning_rate": 1.5133734939759037e-05,
      "loss": 0.0806,
      "step": 40390
    },
    {
      "epoch": 4.867469879518072,
      "grad_norm": 0.15525400638580322,
      "learning_rate": 1.5132530120481929e-05,
      "loss": 0.0269,
      "step": 40400
    },
    {
      "epoch": 4.86867469879518,
      "grad_norm": 2.2607650756835938,
      "learning_rate": 1.513132530120482e-05,
      "loss": 0.0472,
      "step": 40410
    },
    {
      "epoch": 4.869879518072289,
      "grad_norm": 0.04096044600009918,
      "learning_rate": 1.5130120481927712e-05,
      "loss": 0.0701,
      "step": 40420
    },
    {
      "epoch": 4.871084337349398,
      "grad_norm": 2.3465070724487305,
      "learning_rate": 1.5128915662650603e-05,
      "loss": 0.0455,
      "step": 40430
    },
    {
      "epoch": 4.872289156626506,
      "grad_norm": 3.3258659839630127,
      "learning_rate": 1.5127710843373495e-05,
      "loss": 0.0453,
      "step": 40440
    },
    {
      "epoch": 4.873493975903615,
      "grad_norm": 4.241806983947754,
      "learning_rate": 1.5126506024096386e-05,
      "loss": 0.051,
      "step": 40450
    },
    {
      "epoch": 4.874698795180723,
      "grad_norm": 0.49295365810394287,
      "learning_rate": 1.5125301204819279e-05,
      "loss": 0.0436,
      "step": 40460
    },
    {
      "epoch": 4.875903614457831,
      "grad_norm": 2.5825610160827637,
      "learning_rate": 1.5124096385542171e-05,
      "loss": 0.0893,
      "step": 40470
    },
    {
      "epoch": 4.877108433734939,
      "grad_norm": 0.16574949026107788,
      "learning_rate": 1.5122891566265062e-05,
      "loss": 0.0488,
      "step": 40480
    },
    {
      "epoch": 4.878313253012048,
      "grad_norm": 5.501836776733398,
      "learning_rate": 1.5121686746987954e-05,
      "loss": 0.0556,
      "step": 40490
    },
    {
      "epoch": 4.879518072289157,
      "grad_norm": 2.5078465938568115,
      "learning_rate": 1.5120481927710843e-05,
      "loss": 0.0546,
      "step": 40500
    },
    {
      "epoch": 4.880722891566265,
      "grad_norm": 0.07100893557071686,
      "learning_rate": 1.5119277108433736e-05,
      "loss": 0.0416,
      "step": 40510
    },
    {
      "epoch": 4.881927710843374,
      "grad_norm": 0.30356404185295105,
      "learning_rate": 1.5118072289156626e-05,
      "loss": 0.0255,
      "step": 40520
    },
    {
      "epoch": 4.8831325301204815,
      "grad_norm": 0.10777385532855988,
      "learning_rate": 1.5116867469879519e-05,
      "loss": 0.001,
      "step": 40530
    },
    {
      "epoch": 4.88433734939759,
      "grad_norm": 3.1558218002319336,
      "learning_rate": 1.5115662650602411e-05,
      "loss": 0.033,
      "step": 40540
    },
    {
      "epoch": 4.885542168674699,
      "grad_norm": 1.4168621301651,
      "learning_rate": 1.5114457831325302e-05,
      "loss": 0.06,
      "step": 40550
    },
    {
      "epoch": 4.886746987951807,
      "grad_norm": 0.08430314809083939,
      "learning_rate": 1.5113253012048194e-05,
      "loss": 0.1311,
      "step": 40560
    },
    {
      "epoch": 4.887951807228916,
      "grad_norm": 0.273165225982666,
      "learning_rate": 1.5112048192771085e-05,
      "loss": 0.0558,
      "step": 40570
    },
    {
      "epoch": 4.889156626506024,
      "grad_norm": 0.015840159729123116,
      "learning_rate": 1.5110843373493978e-05,
      "loss": 0.1071,
      "step": 40580
    },
    {
      "epoch": 4.890361445783133,
      "grad_norm": 0.08143980801105499,
      "learning_rate": 1.5109638554216868e-05,
      "loss": 0.1183,
      "step": 40590
    },
    {
      "epoch": 4.891566265060241,
      "grad_norm": 1.6168580055236816,
      "learning_rate": 1.5108433734939761e-05,
      "loss": 0.0785,
      "step": 40600
    },
    {
      "epoch": 4.892771084337349,
      "grad_norm": 0.2989581227302551,
      "learning_rate": 1.5107228915662653e-05,
      "loss": 0.047,
      "step": 40610
    },
    {
      "epoch": 4.893975903614458,
      "grad_norm": 3.060711145401001,
      "learning_rate": 1.5106024096385542e-05,
      "loss": 0.0617,
      "step": 40620
    },
    {
      "epoch": 4.895180722891566,
      "grad_norm": 0.2863297760486603,
      "learning_rate": 1.5104819277108436e-05,
      "loss": 0.0492,
      "step": 40630
    },
    {
      "epoch": 4.896385542168675,
      "grad_norm": 2.8007829189300537,
      "learning_rate": 1.5103614457831326e-05,
      "loss": 0.0572,
      "step": 40640
    },
    {
      "epoch": 4.897590361445783,
      "grad_norm": 0.2747766971588135,
      "learning_rate": 1.5102409638554218e-05,
      "loss": 0.0736,
      "step": 40650
    },
    {
      "epoch": 4.8987951807228916,
      "grad_norm": 2.3886897563934326,
      "learning_rate": 1.5101204819277109e-05,
      "loss": 0.0242,
      "step": 40660
    },
    {
      "epoch": 4.9,
      "grad_norm": 5.026007652282715,
      "learning_rate": 1.5100000000000001e-05,
      "loss": 0.0339,
      "step": 40670
    },
    {
      "epoch": 4.901204819277108,
      "grad_norm": 4.5621819496154785,
      "learning_rate": 1.5098795180722894e-05,
      "loss": 0.0169,
      "step": 40680
    },
    {
      "epoch": 4.902409638554217,
      "grad_norm": 13.326610565185547,
      "learning_rate": 1.5097590361445784e-05,
      "loss": 0.0715,
      "step": 40690
    },
    {
      "epoch": 4.903614457831325,
      "grad_norm": 7.261092185974121,
      "learning_rate": 1.5096385542168677e-05,
      "loss": 0.0711,
      "step": 40700
    },
    {
      "epoch": 4.904819277108434,
      "grad_norm": 0.045226141810417175,
      "learning_rate": 1.5095180722891567e-05,
      "loss": 0.0895,
      "step": 40710
    },
    {
      "epoch": 4.906024096385542,
      "grad_norm": 3.786529779434204,
      "learning_rate": 1.509397590361446e-05,
      "loss": 0.0969,
      "step": 40720
    },
    {
      "epoch": 4.9072289156626505,
      "grad_norm": 6.215459823608398,
      "learning_rate": 1.509277108433735e-05,
      "loss": 0.0333,
      "step": 40730
    },
    {
      "epoch": 4.908433734939759,
      "grad_norm": 3.7665352821350098,
      "learning_rate": 1.5091566265060243e-05,
      "loss": 0.0439,
      "step": 40740
    },
    {
      "epoch": 4.909638554216867,
      "grad_norm": 22.73358917236328,
      "learning_rate": 1.5090361445783132e-05,
      "loss": 0.0846,
      "step": 40750
    },
    {
      "epoch": 4.910843373493976,
      "grad_norm": 0.01840772107243538,
      "learning_rate": 1.5089156626506025e-05,
      "loss": 0.0211,
      "step": 40760
    },
    {
      "epoch": 4.912048192771084,
      "grad_norm": 2.40982723236084,
      "learning_rate": 1.5087951807228917e-05,
      "loss": 0.0628,
      "step": 40770
    },
    {
      "epoch": 4.913253012048193,
      "grad_norm": 0.2775469422340393,
      "learning_rate": 1.5086746987951808e-05,
      "loss": 0.008,
      "step": 40780
    },
    {
      "epoch": 4.914457831325302,
      "grad_norm": 0.21978645026683807,
      "learning_rate": 1.50855421686747e-05,
      "loss": 0.0144,
      "step": 40790
    },
    {
      "epoch": 4.9156626506024095,
      "grad_norm": 0.12133198231458664,
      "learning_rate": 1.5084337349397591e-05,
      "loss": 0.0848,
      "step": 40800
    },
    {
      "epoch": 4.916867469879518,
      "grad_norm": 4.194094657897949,
      "learning_rate": 1.5083132530120483e-05,
      "loss": 0.0402,
      "step": 40810
    },
    {
      "epoch": 4.918072289156626,
      "grad_norm": 16.23726463317871,
      "learning_rate": 1.5081927710843374e-05,
      "loss": 0.0795,
      "step": 40820
    },
    {
      "epoch": 4.919277108433735,
      "grad_norm": 3.828714609146118,
      "learning_rate": 1.5080722891566267e-05,
      "loss": 0.0783,
      "step": 40830
    },
    {
      "epoch": 4.920481927710844,
      "grad_norm": 0.16090135276317596,
      "learning_rate": 1.5079518072289159e-05,
      "loss": 0.054,
      "step": 40840
    },
    {
      "epoch": 4.921686746987952,
      "grad_norm": 0.4528653919696808,
      "learning_rate": 1.507831325301205e-05,
      "loss": 0.0368,
      "step": 40850
    },
    {
      "epoch": 4.9228915662650605,
      "grad_norm": 4.919771194458008,
      "learning_rate": 1.5077108433734942e-05,
      "loss": 0.0307,
      "step": 40860
    },
    {
      "epoch": 4.924096385542168,
      "grad_norm": 0.8607102036476135,
      "learning_rate": 1.5075903614457831e-05,
      "loss": 0.0276,
      "step": 40870
    },
    {
      "epoch": 4.925301204819277,
      "grad_norm": 0.20348785817623138,
      "learning_rate": 1.5074698795180724e-05,
      "loss": 0.05,
      "step": 40880
    },
    {
      "epoch": 4.926506024096385,
      "grad_norm": 4.141417026519775,
      "learning_rate": 1.5073493975903614e-05,
      "loss": 0.0859,
      "step": 40890
    },
    {
      "epoch": 4.927710843373494,
      "grad_norm": 13.784387588500977,
      "learning_rate": 1.5072289156626507e-05,
      "loss": 0.0893,
      "step": 40900
    },
    {
      "epoch": 4.928915662650603,
      "grad_norm": 0.23346945643424988,
      "learning_rate": 1.50710843373494e-05,
      "loss": 0.0145,
      "step": 40910
    },
    {
      "epoch": 4.930120481927711,
      "grad_norm": 0.09187924116849899,
      "learning_rate": 1.506987951807229e-05,
      "loss": 0.0861,
      "step": 40920
    },
    {
      "epoch": 4.9313253012048195,
      "grad_norm": 0.05060823634266853,
      "learning_rate": 1.5068674698795182e-05,
      "loss": 0.0318,
      "step": 40930
    },
    {
      "epoch": 4.932530120481927,
      "grad_norm": 3.242597818374634,
      "learning_rate": 1.5067469879518073e-05,
      "loss": 0.0715,
      "step": 40940
    },
    {
      "epoch": 4.933734939759036,
      "grad_norm": 1.3803147077560425,
      "learning_rate": 1.5066265060240966e-05,
      "loss": 0.0569,
      "step": 40950
    },
    {
      "epoch": 4.934939759036144,
      "grad_norm": 50.915611267089844,
      "learning_rate": 1.5065060240963856e-05,
      "loss": 0.0955,
      "step": 40960
    },
    {
      "epoch": 4.936144578313253,
      "grad_norm": 0.05004652589559555,
      "learning_rate": 1.5063855421686749e-05,
      "loss": 0.0564,
      "step": 40970
    },
    {
      "epoch": 4.937349397590362,
      "grad_norm": 0.25077030062675476,
      "learning_rate": 1.5062650602409641e-05,
      "loss": 0.0127,
      "step": 40980
    },
    {
      "epoch": 4.93855421686747,
      "grad_norm": 0.6201502084732056,
      "learning_rate": 1.5061445783132532e-05,
      "loss": 0.034,
      "step": 40990
    },
    {
      "epoch": 4.9397590361445785,
      "grad_norm": 28.017179489135742,
      "learning_rate": 1.5060240963855424e-05,
      "loss": 0.0863,
      "step": 41000
    },
    {
      "epoch": 4.940963855421686,
      "grad_norm": 2.238041639328003,
      "learning_rate": 1.5059036144578313e-05,
      "loss": 0.0507,
      "step": 41010
    },
    {
      "epoch": 4.942168674698795,
      "grad_norm": 0.8435044884681702,
      "learning_rate": 1.5057831325301206e-05,
      "loss": 0.0698,
      "step": 41020
    },
    {
      "epoch": 4.943373493975904,
      "grad_norm": 2.009545087814331,
      "learning_rate": 1.5056626506024097e-05,
      "loss": 0.0396,
      "step": 41030
    },
    {
      "epoch": 4.944578313253012,
      "grad_norm": 2.1814823150634766,
      "learning_rate": 1.5055421686746989e-05,
      "loss": 0.0499,
      "step": 41040
    },
    {
      "epoch": 4.945783132530121,
      "grad_norm": 0.12243203818798065,
      "learning_rate": 1.505421686746988e-05,
      "loss": 0.0181,
      "step": 41050
    },
    {
      "epoch": 4.946987951807229,
      "grad_norm": 0.05652523413300514,
      "learning_rate": 1.5053012048192772e-05,
      "loss": 0.0478,
      "step": 41060
    },
    {
      "epoch": 4.948192771084337,
      "grad_norm": 1.8075180053710938,
      "learning_rate": 1.5051807228915665e-05,
      "loss": 0.0169,
      "step": 41070
    },
    {
      "epoch": 4.949397590361446,
      "grad_norm": 0.5535696148872375,
      "learning_rate": 1.5050602409638555e-05,
      "loss": 0.0331,
      "step": 41080
    },
    {
      "epoch": 4.950602409638554,
      "grad_norm": 8.011548042297363,
      "learning_rate": 1.5049397590361448e-05,
      "loss": 0.0941,
      "step": 41090
    },
    {
      "epoch": 4.951807228915663,
      "grad_norm": 8.258533477783203,
      "learning_rate": 1.5048192771084339e-05,
      "loss": 0.0929,
      "step": 41100
    },
    {
      "epoch": 4.953012048192771,
      "grad_norm": 0.028613613918423653,
      "learning_rate": 1.5046987951807231e-05,
      "loss": 0.007,
      "step": 41110
    },
    {
      "epoch": 4.95421686746988,
      "grad_norm": 0.07033154368400574,
      "learning_rate": 1.504578313253012e-05,
      "loss": 0.0852,
      "step": 41120
    },
    {
      "epoch": 4.955421686746988,
      "grad_norm": 0.08505894243717194,
      "learning_rate": 1.5044578313253012e-05,
      "loss": 0.0615,
      "step": 41130
    },
    {
      "epoch": 4.956626506024096,
      "grad_norm": 2.3751866817474365,
      "learning_rate": 1.5043373493975905e-05,
      "loss": 0.0584,
      "step": 41140
    },
    {
      "epoch": 4.957831325301205,
      "grad_norm": 0.019703848287463188,
      "learning_rate": 1.5042168674698796e-05,
      "loss": 0.0475,
      "step": 41150
    },
    {
      "epoch": 4.959036144578313,
      "grad_norm": 1.5245287418365479,
      "learning_rate": 1.5040963855421688e-05,
      "loss": 0.0432,
      "step": 41160
    },
    {
      "epoch": 4.960240963855422,
      "grad_norm": 0.8489441871643066,
      "learning_rate": 1.5039759036144579e-05,
      "loss": 0.0509,
      "step": 41170
    },
    {
      "epoch": 4.96144578313253,
      "grad_norm": 5.284667491912842,
      "learning_rate": 1.5038554216867471e-05,
      "loss": 0.0942,
      "step": 41180
    },
    {
      "epoch": 4.962650602409639,
      "grad_norm": 0.8352515697479248,
      "learning_rate": 1.5037349397590362e-05,
      "loss": 0.0777,
      "step": 41190
    },
    {
      "epoch": 4.9638554216867465,
      "grad_norm": 0.13924720883369446,
      "learning_rate": 1.5036144578313254e-05,
      "loss": 0.0328,
      "step": 41200
    },
    {
      "epoch": 4.965060240963855,
      "grad_norm": 15.071229934692383,
      "learning_rate": 1.5034939759036147e-05,
      "loss": 0.0985,
      "step": 41210
    },
    {
      "epoch": 4.966265060240964,
      "grad_norm": 0.2070295810699463,
      "learning_rate": 1.5033734939759038e-05,
      "loss": 0.005,
      "step": 41220
    },
    {
      "epoch": 4.967469879518072,
      "grad_norm": 1.8488290309906006,
      "learning_rate": 1.503253012048193e-05,
      "loss": 0.0328,
      "step": 41230
    },
    {
      "epoch": 4.968674698795181,
      "grad_norm": 0.017306743189692497,
      "learning_rate": 1.5031325301204819e-05,
      "loss": 0.0506,
      "step": 41240
    },
    {
      "epoch": 4.969879518072289,
      "grad_norm": 1.415848970413208,
      "learning_rate": 1.5030120481927713e-05,
      "loss": 0.0293,
      "step": 41250
    },
    {
      "epoch": 4.971084337349398,
      "grad_norm": 1.0472840070724487,
      "learning_rate": 1.5028915662650602e-05,
      "loss": 0.0235,
      "step": 41260
    },
    {
      "epoch": 4.972289156626506,
      "grad_norm": 2.523682117462158,
      "learning_rate": 1.5027710843373495e-05,
      "loss": 0.0835,
      "step": 41270
    },
    {
      "epoch": 4.973493975903614,
      "grad_norm": 0.07592137157917023,
      "learning_rate": 1.5026506024096387e-05,
      "loss": 0.0467,
      "step": 41280
    },
    {
      "epoch": 4.974698795180723,
      "grad_norm": 0.41428741812705994,
      "learning_rate": 1.5025301204819278e-05,
      "loss": 0.0294,
      "step": 41290
    },
    {
      "epoch": 4.975903614457831,
      "grad_norm": 4.274835109710693,
      "learning_rate": 1.502409638554217e-05,
      "loss": 0.0488,
      "step": 41300
    },
    {
      "epoch": 4.97710843373494,
      "grad_norm": 0.38271528482437134,
      "learning_rate": 1.5022891566265061e-05,
      "loss": 0.0716,
      "step": 41310
    },
    {
      "epoch": 4.978313253012049,
      "grad_norm": 2.998774290084839,
      "learning_rate": 1.5021686746987953e-05,
      "loss": 0.1223,
      "step": 41320
    },
    {
      "epoch": 4.9795180722891565,
      "grad_norm": 0.35563015937805176,
      "learning_rate": 1.5020481927710844e-05,
      "loss": 0.0519,
      "step": 41330
    },
    {
      "epoch": 4.980722891566265,
      "grad_norm": 2.183500289916992,
      "learning_rate": 1.5019277108433737e-05,
      "loss": 0.0254,
      "step": 41340
    },
    {
      "epoch": 4.981927710843373,
      "grad_norm": 8.940367698669434,
      "learning_rate": 1.5018072289156627e-05,
      "loss": 0.0711,
      "step": 41350
    },
    {
      "epoch": 4.983132530120482,
      "grad_norm": 0.811493456363678,
      "learning_rate": 1.501686746987952e-05,
      "loss": 0.0111,
      "step": 41360
    },
    {
      "epoch": 4.98433734939759,
      "grad_norm": 8.930355072021484,
      "learning_rate": 1.5015662650602412e-05,
      "loss": 0.0928,
      "step": 41370
    },
    {
      "epoch": 4.985542168674699,
      "grad_norm": 0.022604433819651604,
      "learning_rate": 1.5014457831325301e-05,
      "loss": 0.0608,
      "step": 41380
    },
    {
      "epoch": 4.986746987951808,
      "grad_norm": 4.579582691192627,
      "learning_rate": 1.5013253012048194e-05,
      "loss": 0.1182,
      "step": 41390
    },
    {
      "epoch": 4.9879518072289155,
      "grad_norm": 0.2356874644756317,
      "learning_rate": 1.5012048192771084e-05,
      "loss": 0.0259,
      "step": 41400
    },
    {
      "epoch": 4.989156626506024,
      "grad_norm": 0.03153722733259201,
      "learning_rate": 1.5010843373493977e-05,
      "loss": 0.0355,
      "step": 41410
    },
    {
      "epoch": 4.990361445783132,
      "grad_norm": 0.17260611057281494,
      "learning_rate": 1.5009638554216868e-05,
      "loss": 0.0922,
      "step": 41420
    },
    {
      "epoch": 4.991566265060241,
      "grad_norm": 1.485661506652832,
      "learning_rate": 1.500843373493976e-05,
      "loss": 0.071,
      "step": 41430
    },
    {
      "epoch": 4.992771084337349,
      "grad_norm": 0.0239102840423584,
      "learning_rate": 1.5007228915662653e-05,
      "loss": 0.0111,
      "step": 41440
    },
    {
      "epoch": 4.993975903614458,
      "grad_norm": 0.3080008029937744,
      "learning_rate": 1.5006024096385543e-05,
      "loss": 0.0673,
      "step": 41450
    },
    {
      "epoch": 4.995180722891567,
      "grad_norm": 0.7564777135848999,
      "learning_rate": 1.5004819277108436e-05,
      "loss": 0.062,
      "step": 41460
    },
    {
      "epoch": 4.9963855421686745,
      "grad_norm": 0.04828933626413345,
      "learning_rate": 1.5003614457831326e-05,
      "loss": 0.0221,
      "step": 41470
    },
    {
      "epoch": 4.997590361445783,
      "grad_norm": 0.03009747341275215,
      "learning_rate": 1.5002409638554219e-05,
      "loss": 0.0218,
      "step": 41480
    },
    {
      "epoch": 4.998795180722891,
      "grad_norm": 2.7899892330169678,
      "learning_rate": 1.5001204819277108e-05,
      "loss": 0.0535,
      "step": 41490
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.881906986236572,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.0801,
      "step": 41500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.979916572928384,
      "eval_f1": 0.9461107967050243,
      "eval_loss": 0.07586752623319626,
      "eval_precision": 0.9630056323604711,
      "eval_recall": 0.9297985415894203,
      "eval_runtime": 3369.7697,
      "eval_samples_per_second": 12.669,
      "eval_steps_per_second": 0.528,
      "step": 41500
    },
    {
      "epoch": 5.001204819277109,
      "grad_norm": 1.9575477838516235,
      "learning_rate": 1.4998795180722895e-05,
      "loss": 0.046,
      "step": 41510
    },
    {
      "epoch": 5.002409638554217,
      "grad_norm": 0.06665671616792679,
      "learning_rate": 1.4997590361445784e-05,
      "loss": 0.0317,
      "step": 41520
    },
    {
      "epoch": 5.0036144578313255,
      "grad_norm": 1.7334692478179932,
      "learning_rate": 1.4996385542168676e-05,
      "loss": 0.0421,
      "step": 41530
    },
    {
      "epoch": 5.004819277108433,
      "grad_norm": 0.06508203595876694,
      "learning_rate": 1.4995180722891567e-05,
      "loss": 0.009,
      "step": 41540
    },
    {
      "epoch": 5.006024096385542,
      "grad_norm": 3.135361909866333,
      "learning_rate": 1.499397590361446e-05,
      "loss": 0.0878,
      "step": 41550
    },
    {
      "epoch": 5.00722891566265,
      "grad_norm": 0.20788748562335968,
      "learning_rate": 1.499277108433735e-05,
      "loss": 0.0532,
      "step": 41560
    },
    {
      "epoch": 5.008433734939759,
      "grad_norm": 0.26128116250038147,
      "learning_rate": 1.4991566265060242e-05,
      "loss": 0.0431,
      "step": 41570
    },
    {
      "epoch": 5.009638554216868,
      "grad_norm": 0.4812332093715668,
      "learning_rate": 1.4990361445783135e-05,
      "loss": 0.021,
      "step": 41580
    },
    {
      "epoch": 5.010843373493976,
      "grad_norm": 0.015750011429190636,
      "learning_rate": 1.4989156626506026e-05,
      "loss": 0.039,
      "step": 41590
    },
    {
      "epoch": 5.0120481927710845,
      "grad_norm": 0.34951266646385193,
      "learning_rate": 1.4987951807228918e-05,
      "loss": 0.0225,
      "step": 41600
    },
    {
      "epoch": 5.013253012048192,
      "grad_norm": 29.08565902709961,
      "learning_rate": 1.4986746987951809e-05,
      "loss": 0.0949,
      "step": 41610
    },
    {
      "epoch": 5.014457831325301,
      "grad_norm": 4.569239616394043,
      "learning_rate": 1.4985542168674701e-05,
      "loss": 0.0551,
      "step": 41620
    },
    {
      "epoch": 5.01566265060241,
      "grad_norm": 1.1720829010009766,
      "learning_rate": 1.498433734939759e-05,
      "loss": 0.0249,
      "step": 41630
    },
    {
      "epoch": 5.016867469879518,
      "grad_norm": 3.9619877338409424,
      "learning_rate": 1.4983132530120483e-05,
      "loss": 0.037,
      "step": 41640
    },
    {
      "epoch": 5.018072289156627,
      "grad_norm": 6.4006733894348145,
      "learning_rate": 1.4981927710843375e-05,
      "loss": 0.0243,
      "step": 41650
    },
    {
      "epoch": 5.019277108433735,
      "grad_norm": 0.6650269627571106,
      "learning_rate": 1.4980722891566266e-05,
      "loss": 0.0463,
      "step": 41660
    },
    {
      "epoch": 5.0204819277108435,
      "grad_norm": 0.06946805119514465,
      "learning_rate": 1.4979518072289158e-05,
      "loss": 0.0798,
      "step": 41670
    },
    {
      "epoch": 5.021686746987951,
      "grad_norm": 1.3292067050933838,
      "learning_rate": 1.4978313253012049e-05,
      "loss": 0.0245,
      "step": 41680
    },
    {
      "epoch": 5.02289156626506,
      "grad_norm": 13.296120643615723,
      "learning_rate": 1.4977108433734941e-05,
      "loss": 0.0989,
      "step": 41690
    },
    {
      "epoch": 5.024096385542169,
      "grad_norm": 0.31544265151023865,
      "learning_rate": 1.4975903614457832e-05,
      "loss": 0.0552,
      "step": 41700
    },
    {
      "epoch": 5.025301204819277,
      "grad_norm": 0.3158462345600128,
      "learning_rate": 1.4974698795180725e-05,
      "loss": 0.064,
      "step": 41710
    },
    {
      "epoch": 5.026506024096386,
      "grad_norm": 0.28508231043815613,
      "learning_rate": 1.4973493975903615e-05,
      "loss": 0.0706,
      "step": 41720
    },
    {
      "epoch": 5.027710843373494,
      "grad_norm": 5.238302707672119,
      "learning_rate": 1.4972289156626508e-05,
      "loss": 0.0768,
      "step": 41730
    },
    {
      "epoch": 5.028915662650602,
      "grad_norm": 0.1827104538679123,
      "learning_rate": 1.49710843373494e-05,
      "loss": 0.0144,
      "step": 41740
    },
    {
      "epoch": 5.030120481927711,
      "grad_norm": 0.8208122849464417,
      "learning_rate": 1.496987951807229e-05,
      "loss": 0.0392,
      "step": 41750
    },
    {
      "epoch": 5.031325301204819,
      "grad_norm": 0.0851391926407814,
      "learning_rate": 1.4968674698795183e-05,
      "loss": 0.0283,
      "step": 41760
    },
    {
      "epoch": 5.032530120481928,
      "grad_norm": 0.05812133103609085,
      "learning_rate": 1.4967469879518072e-05,
      "loss": 0.0477,
      "step": 41770
    },
    {
      "epoch": 5.033734939759036,
      "grad_norm": 0.08617442101240158,
      "learning_rate": 1.4966265060240965e-05,
      "loss": 0.0262,
      "step": 41780
    },
    {
      "epoch": 5.034939759036145,
      "grad_norm": 0.28995102643966675,
      "learning_rate": 1.4965060240963856e-05,
      "loss": 0.0232,
      "step": 41790
    },
    {
      "epoch": 5.036144578313253,
      "grad_norm": 0.16028465330600739,
      "learning_rate": 1.4963855421686748e-05,
      "loss": 0.0273,
      "step": 41800
    },
    {
      "epoch": 5.037349397590361,
      "grad_norm": 0.007957929745316505,
      "learning_rate": 1.496265060240964e-05,
      "loss": 0.0485,
      "step": 41810
    },
    {
      "epoch": 5.03855421686747,
      "grad_norm": 2.052152156829834,
      "learning_rate": 1.4961445783132531e-05,
      "loss": 0.0234,
      "step": 41820
    },
    {
      "epoch": 5.039759036144578,
      "grad_norm": 55.76008224487305,
      "learning_rate": 1.4960240963855424e-05,
      "loss": 0.0572,
      "step": 41830
    },
    {
      "epoch": 5.040963855421687,
      "grad_norm": 0.09176164120435715,
      "learning_rate": 1.4959036144578314e-05,
      "loss": 0.0376,
      "step": 41840
    },
    {
      "epoch": 5.042168674698795,
      "grad_norm": 0.203142911195755,
      "learning_rate": 1.4957831325301207e-05,
      "loss": 0.0074,
      "step": 41850
    },
    {
      "epoch": 5.043373493975904,
      "grad_norm": 11.322488784790039,
      "learning_rate": 1.4956626506024098e-05,
      "loss": 0.0798,
      "step": 41860
    },
    {
      "epoch": 5.044578313253012,
      "grad_norm": 7.719987392425537,
      "learning_rate": 1.495542168674699e-05,
      "loss": 0.0408,
      "step": 41870
    },
    {
      "epoch": 5.04578313253012,
      "grad_norm": 10.24019718170166,
      "learning_rate": 1.4954216867469882e-05,
      "loss": 0.0458,
      "step": 41880
    },
    {
      "epoch": 5.046987951807229,
      "grad_norm": 0.3150583803653717,
      "learning_rate": 1.4953012048192771e-05,
      "loss": 0.0438,
      "step": 41890
    },
    {
      "epoch": 5.048192771084337,
      "grad_norm": 1.436361312866211,
      "learning_rate": 1.4951807228915664e-05,
      "loss": 0.0276,
      "step": 41900
    },
    {
      "epoch": 5.049397590361446,
      "grad_norm": 0.1052226722240448,
      "learning_rate": 1.4950602409638555e-05,
      "loss": 0.0514,
      "step": 41910
    },
    {
      "epoch": 5.050602409638554,
      "grad_norm": 0.32903024554252625,
      "learning_rate": 1.4949397590361447e-05,
      "loss": 0.0256,
      "step": 41920
    },
    {
      "epoch": 5.051807228915663,
      "grad_norm": 0.16492757201194763,
      "learning_rate": 1.4948192771084338e-05,
      "loss": 0.0855,
      "step": 41930
    },
    {
      "epoch": 5.053012048192771,
      "grad_norm": 0.04143104702234268,
      "learning_rate": 1.494698795180723e-05,
      "loss": 0.0018,
      "step": 41940
    },
    {
      "epoch": 5.054216867469879,
      "grad_norm": 49.088035583496094,
      "learning_rate": 1.4945783132530123e-05,
      "loss": 0.0502,
      "step": 41950
    },
    {
      "epoch": 5.055421686746988,
      "grad_norm": 2.416175603866577,
      "learning_rate": 1.4944578313253013e-05,
      "loss": 0.038,
      "step": 41960
    },
    {
      "epoch": 5.056626506024096,
      "grad_norm": 0.1413012444972992,
      "learning_rate": 1.4943373493975906e-05,
      "loss": 0.009,
      "step": 41970
    },
    {
      "epoch": 5.057831325301205,
      "grad_norm": 0.012176822870969772,
      "learning_rate": 1.4942168674698797e-05,
      "loss": 0.0177,
      "step": 41980
    },
    {
      "epoch": 5.059036144578314,
      "grad_norm": 0.0526595376431942,
      "learning_rate": 1.4940963855421689e-05,
      "loss": 0.0321,
      "step": 41990
    },
    {
      "epoch": 5.0602409638554215,
      "grad_norm": 2.1421146392822266,
      "learning_rate": 1.4939759036144578e-05,
      "loss": 0.0692,
      "step": 42000
    },
    {
      "epoch": 5.06144578313253,
      "grad_norm": 0.03532994166016579,
      "learning_rate": 1.493855421686747e-05,
      "loss": 0.0495,
      "step": 42010
    },
    {
      "epoch": 5.062650602409638,
      "grad_norm": 12.244985580444336,
      "learning_rate": 1.4937349397590361e-05,
      "loss": 0.0313,
      "step": 42020
    },
    {
      "epoch": 5.063855421686747,
      "grad_norm": 1.1432751417160034,
      "learning_rate": 1.4936144578313254e-05,
      "loss": 0.0615,
      "step": 42030
    },
    {
      "epoch": 5.065060240963855,
      "grad_norm": 0.06046753376722336,
      "learning_rate": 1.4934939759036146e-05,
      "loss": 0.0346,
      "step": 42040
    },
    {
      "epoch": 5.066265060240964,
      "grad_norm": 0.24242863059043884,
      "learning_rate": 1.4933734939759037e-05,
      "loss": 0.0572,
      "step": 42050
    },
    {
      "epoch": 5.067469879518073,
      "grad_norm": 0.07713963836431503,
      "learning_rate": 1.493253012048193e-05,
      "loss": 0.0271,
      "step": 42060
    },
    {
      "epoch": 5.0686746987951805,
      "grad_norm": 0.971445620059967,
      "learning_rate": 1.493132530120482e-05,
      "loss": 0.0552,
      "step": 42070
    },
    {
      "epoch": 5.069879518072289,
      "grad_norm": 0.11956590414047241,
      "learning_rate": 1.4930120481927712e-05,
      "loss": 0.0477,
      "step": 42080
    },
    {
      "epoch": 5.071084337349397,
      "grad_norm": 9.633277893066406,
      "learning_rate": 1.4928915662650603e-05,
      "loss": 0.0469,
      "step": 42090
    },
    {
      "epoch": 5.072289156626506,
      "grad_norm": 0.06194619461894035,
      "learning_rate": 1.4927710843373496e-05,
      "loss": 0.023,
      "step": 42100
    },
    {
      "epoch": 5.073493975903615,
      "grad_norm": 3.8542959690093994,
      "learning_rate": 1.4926506024096388e-05,
      "loss": 0.1227,
      "step": 42110
    },
    {
      "epoch": 5.074698795180723,
      "grad_norm": 0.013441377319395542,
      "learning_rate": 1.4925301204819279e-05,
      "loss": 0.0416,
      "step": 42120
    },
    {
      "epoch": 5.075903614457832,
      "grad_norm": 0.08396393805742264,
      "learning_rate": 1.4924096385542171e-05,
      "loss": 0.0283,
      "step": 42130
    },
    {
      "epoch": 5.0771084337349395,
      "grad_norm": 0.264960378408432,
      "learning_rate": 1.492289156626506e-05,
      "loss": 0.0166,
      "step": 42140
    },
    {
      "epoch": 5.078313253012048,
      "grad_norm": 0.03554124757647514,
      "learning_rate": 1.4921686746987953e-05,
      "loss": 0.0603,
      "step": 42150
    },
    {
      "epoch": 5.079518072289156,
      "grad_norm": 12.492307662963867,
      "learning_rate": 1.4920481927710843e-05,
      "loss": 0.061,
      "step": 42160
    },
    {
      "epoch": 5.080722891566265,
      "grad_norm": 0.43622615933418274,
      "learning_rate": 1.4919277108433736e-05,
      "loss": 0.0765,
      "step": 42170
    },
    {
      "epoch": 5.081927710843374,
      "grad_norm": 11.027762413024902,
      "learning_rate": 1.4918072289156628e-05,
      "loss": 0.032,
      "step": 42180
    },
    {
      "epoch": 5.083132530120482,
      "grad_norm": 0.3788880705833435,
      "learning_rate": 1.4916867469879519e-05,
      "loss": 0.0475,
      "step": 42190
    },
    {
      "epoch": 5.0843373493975905,
      "grad_norm": 1.7278212308883667,
      "learning_rate": 1.4915662650602412e-05,
      "loss": 0.0233,
      "step": 42200
    },
    {
      "epoch": 5.085542168674698,
      "grad_norm": 0.008830713108181953,
      "learning_rate": 1.4914457831325302e-05,
      "loss": 0.0393,
      "step": 42210
    },
    {
      "epoch": 5.086746987951807,
      "grad_norm": 4.755378723144531,
      "learning_rate": 1.4913253012048195e-05,
      "loss": 0.0575,
      "step": 42220
    },
    {
      "epoch": 5.087951807228916,
      "grad_norm": 0.10767795890569687,
      "learning_rate": 1.4912048192771085e-05,
      "loss": 0.0596,
      "step": 42230
    },
    {
      "epoch": 5.089156626506024,
      "grad_norm": 0.08974479883909225,
      "learning_rate": 1.4910843373493978e-05,
      "loss": 0.0213,
      "step": 42240
    },
    {
      "epoch": 5.090361445783133,
      "grad_norm": 3.9030141830444336,
      "learning_rate": 1.490963855421687e-05,
      "loss": 0.0669,
      "step": 42250
    },
    {
      "epoch": 5.091566265060241,
      "grad_norm": 0.965924084186554,
      "learning_rate": 1.490843373493976e-05,
      "loss": 0.0404,
      "step": 42260
    },
    {
      "epoch": 5.0927710843373495,
      "grad_norm": 0.18210919201374054,
      "learning_rate": 1.4907228915662652e-05,
      "loss": 0.0568,
      "step": 42270
    },
    {
      "epoch": 5.093975903614457,
      "grad_norm": 2.2784807682037354,
      "learning_rate": 1.4906024096385543e-05,
      "loss": 0.0832,
      "step": 42280
    },
    {
      "epoch": 5.095180722891566,
      "grad_norm": 0.3265796899795532,
      "learning_rate": 1.4904819277108435e-05,
      "loss": 0.0898,
      "step": 42290
    },
    {
      "epoch": 5.096385542168675,
      "grad_norm": 0.3008500039577484,
      "learning_rate": 1.4903614457831326e-05,
      "loss": 0.0347,
      "step": 42300
    },
    {
      "epoch": 5.097590361445783,
      "grad_norm": 0.026566559448838234,
      "learning_rate": 1.4902409638554218e-05,
      "loss": 0.0462,
      "step": 42310
    },
    {
      "epoch": 5.098795180722892,
      "grad_norm": 0.07843668013811111,
      "learning_rate": 1.4901204819277109e-05,
      "loss": 0.0348,
      "step": 42320
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.07243165373802185,
      "learning_rate": 1.4900000000000001e-05,
      "loss": 0.0219,
      "step": 42330
    },
    {
      "epoch": 5.1012048192771084,
      "grad_norm": 0.056616783142089844,
      "learning_rate": 1.4898795180722894e-05,
      "loss": 0.0454,
      "step": 42340
    },
    {
      "epoch": 5.102409638554217,
      "grad_norm": 3.0389091968536377,
      "learning_rate": 1.4897590361445785e-05,
      "loss": 0.0302,
      "step": 42350
    },
    {
      "epoch": 5.103614457831325,
      "grad_norm": 0.02489539422094822,
      "learning_rate": 1.4896385542168677e-05,
      "loss": 0.0403,
      "step": 42360
    },
    {
      "epoch": 5.104819277108434,
      "grad_norm": 0.7125369310379028,
      "learning_rate": 1.4895180722891566e-05,
      "loss": 0.0821,
      "step": 42370
    },
    {
      "epoch": 5.106024096385542,
      "grad_norm": 0.0252001341432333,
      "learning_rate": 1.489397590361446e-05,
      "loss": 0.0116,
      "step": 42380
    },
    {
      "epoch": 5.107228915662651,
      "grad_norm": 0.7408537864685059,
      "learning_rate": 1.489277108433735e-05,
      "loss": 0.0297,
      "step": 42390
    },
    {
      "epoch": 5.108433734939759,
      "grad_norm": 5.872019290924072,
      "learning_rate": 1.4891566265060242e-05,
      "loss": 0.0705,
      "step": 42400
    },
    {
      "epoch": 5.109638554216867,
      "grad_norm": 1.222402572631836,
      "learning_rate": 1.4890361445783134e-05,
      "loss": 0.074,
      "step": 42410
    },
    {
      "epoch": 5.110843373493976,
      "grad_norm": 0.18927286565303802,
      "learning_rate": 1.4889156626506025e-05,
      "loss": 0.0275,
      "step": 42420
    },
    {
      "epoch": 5.112048192771084,
      "grad_norm": 0.36134764552116394,
      "learning_rate": 1.4887951807228917e-05,
      "loss": 0.0644,
      "step": 42430
    },
    {
      "epoch": 5.113253012048193,
      "grad_norm": 0.32979723811149597,
      "learning_rate": 1.4886746987951808e-05,
      "loss": 0.0739,
      "step": 42440
    },
    {
      "epoch": 5.114457831325301,
      "grad_norm": 0.589197039604187,
      "learning_rate": 1.48855421686747e-05,
      "loss": 0.0617,
      "step": 42450
    },
    {
      "epoch": 5.11566265060241,
      "grad_norm": 0.6700313687324524,
      "learning_rate": 1.4884337349397591e-05,
      "loss": 0.0386,
      "step": 42460
    },
    {
      "epoch": 5.1168674698795185,
      "grad_norm": 0.7610962390899658,
      "learning_rate": 1.4883132530120484e-05,
      "loss": 0.0312,
      "step": 42470
    },
    {
      "epoch": 5.118072289156626,
      "grad_norm": 2.509781837463379,
      "learning_rate": 1.4881927710843376e-05,
      "loss": 0.1004,
      "step": 42480
    },
    {
      "epoch": 5.119277108433735,
      "grad_norm": 0.4111575484275818,
      "learning_rate": 1.4880722891566267e-05,
      "loss": 0.0587,
      "step": 42490
    },
    {
      "epoch": 5.120481927710843,
      "grad_norm": 0.22123076021671295,
      "learning_rate": 1.487951807228916e-05,
      "loss": 0.0308,
      "step": 42500
    },
    {
      "epoch": 5.121686746987952,
      "grad_norm": 0.2733604907989502,
      "learning_rate": 1.4878313253012048e-05,
      "loss": 0.0278,
      "step": 42510
    },
    {
      "epoch": 5.12289156626506,
      "grad_norm": 26.611331939697266,
      "learning_rate": 1.487710843373494e-05,
      "loss": 0.0584,
      "step": 42520
    },
    {
      "epoch": 5.124096385542169,
      "grad_norm": 1.0220637321472168,
      "learning_rate": 1.4875903614457831e-05,
      "loss": 0.0184,
      "step": 42530
    },
    {
      "epoch": 5.125301204819277,
      "grad_norm": 4.344132900238037,
      "learning_rate": 1.4874698795180724e-05,
      "loss": 0.1419,
      "step": 42540
    },
    {
      "epoch": 5.126506024096385,
      "grad_norm": 5.201584815979004,
      "learning_rate": 1.4873493975903616e-05,
      "loss": 0.0703,
      "step": 42550
    },
    {
      "epoch": 5.127710843373494,
      "grad_norm": 2.484049081802368,
      "learning_rate": 1.4872289156626507e-05,
      "loss": 0.0496,
      "step": 42560
    },
    {
      "epoch": 5.128915662650602,
      "grad_norm": 0.22286811470985413,
      "learning_rate": 1.48710843373494e-05,
      "loss": 0.0263,
      "step": 42570
    },
    {
      "epoch": 5.130120481927711,
      "grad_norm": 0.030980350449681282,
      "learning_rate": 1.486987951807229e-05,
      "loss": 0.0717,
      "step": 42580
    },
    {
      "epoch": 5.13132530120482,
      "grad_norm": 2.0414376258850098,
      "learning_rate": 1.4868674698795183e-05,
      "loss": 0.1362,
      "step": 42590
    },
    {
      "epoch": 5.132530120481928,
      "grad_norm": 0.03142469748854637,
      "learning_rate": 1.4867469879518073e-05,
      "loss": 0.0077,
      "step": 42600
    },
    {
      "epoch": 5.133734939759036,
      "grad_norm": 1.3515151739120483,
      "learning_rate": 1.4866265060240966e-05,
      "loss": 0.0245,
      "step": 42610
    },
    {
      "epoch": 5.134939759036144,
      "grad_norm": 2.065326452255249,
      "learning_rate": 1.4865060240963855e-05,
      "loss": 0.0243,
      "step": 42620
    },
    {
      "epoch": 5.136144578313253,
      "grad_norm": 0.0133842583745718,
      "learning_rate": 1.4863855421686747e-05,
      "loss": 0.0523,
      "step": 42630
    },
    {
      "epoch": 5.137349397590361,
      "grad_norm": 0.872795581817627,
      "learning_rate": 1.4862650602409641e-05,
      "loss": 0.0464,
      "step": 42640
    },
    {
      "epoch": 5.13855421686747,
      "grad_norm": 5.634056091308594,
      "learning_rate": 1.486144578313253e-05,
      "loss": 0.0513,
      "step": 42650
    },
    {
      "epoch": 5.139759036144579,
      "grad_norm": 0.06093394756317139,
      "learning_rate": 1.4860240963855423e-05,
      "loss": 0.0373,
      "step": 42660
    },
    {
      "epoch": 5.1409638554216865,
      "grad_norm": 0.20606425404548645,
      "learning_rate": 1.4859036144578314e-05,
      "loss": 0.0475,
      "step": 42670
    },
    {
      "epoch": 5.142168674698795,
      "grad_norm": 0.3036421835422516,
      "learning_rate": 1.4857831325301206e-05,
      "loss": 0.0377,
      "step": 42680
    },
    {
      "epoch": 5.143373493975903,
      "grad_norm": 0.06920761615037918,
      "learning_rate": 1.4856626506024097e-05,
      "loss": 0.0188,
      "step": 42690
    },
    {
      "epoch": 5.144578313253012,
      "grad_norm": 0.011474466882646084,
      "learning_rate": 1.485542168674699e-05,
      "loss": 0.097,
      "step": 42700
    },
    {
      "epoch": 5.145783132530121,
      "grad_norm": 69.94776153564453,
      "learning_rate": 1.4854216867469882e-05,
      "loss": 0.0575,
      "step": 42710
    },
    {
      "epoch": 5.146987951807229,
      "grad_norm": 0.4613095223903656,
      "learning_rate": 1.4853012048192772e-05,
      "loss": 0.0812,
      "step": 42720
    },
    {
      "epoch": 5.148192771084338,
      "grad_norm": 0.6539859175682068,
      "learning_rate": 1.4851807228915665e-05,
      "loss": 0.022,
      "step": 42730
    },
    {
      "epoch": 5.1493975903614455,
      "grad_norm": 22.358781814575195,
      "learning_rate": 1.4850602409638556e-05,
      "loss": 0.0696,
      "step": 42740
    },
    {
      "epoch": 5.150602409638554,
      "grad_norm": 1.066163420677185,
      "learning_rate": 1.4849397590361448e-05,
      "loss": 0.0306,
      "step": 42750
    },
    {
      "epoch": 5.151807228915662,
      "grad_norm": 0.08962419629096985,
      "learning_rate": 1.4848192771084337e-05,
      "loss": 0.0494,
      "step": 42760
    },
    {
      "epoch": 5.153012048192771,
      "grad_norm": 0.6820690631866455,
      "learning_rate": 1.484698795180723e-05,
      "loss": 0.0658,
      "step": 42770
    },
    {
      "epoch": 5.15421686746988,
      "grad_norm": 0.06677991151809692,
      "learning_rate": 1.4845783132530122e-05,
      "loss": 0.0446,
      "step": 42780
    },
    {
      "epoch": 5.155421686746988,
      "grad_norm": 5.978094577789307,
      "learning_rate": 1.4844578313253013e-05,
      "loss": 0.0615,
      "step": 42790
    },
    {
      "epoch": 5.156626506024097,
      "grad_norm": 0.06960152089595795,
      "learning_rate": 1.4843373493975905e-05,
      "loss": 0.0376,
      "step": 42800
    },
    {
      "epoch": 5.1578313253012045,
      "grad_norm": 0.048335812985897064,
      "learning_rate": 1.4842168674698796e-05,
      "loss": 0.0501,
      "step": 42810
    },
    {
      "epoch": 5.159036144578313,
      "grad_norm": 0.045567285269498825,
      "learning_rate": 1.4840963855421688e-05,
      "loss": 0.0224,
      "step": 42820
    },
    {
      "epoch": 5.160240963855422,
      "grad_norm": 0.4583398997783661,
      "learning_rate": 1.4839759036144579e-05,
      "loss": 0.042,
      "step": 42830
    },
    {
      "epoch": 5.16144578313253,
      "grad_norm": 2.134348154067993,
      "learning_rate": 1.4838554216867471e-05,
      "loss": 0.0477,
      "step": 42840
    },
    {
      "epoch": 5.162650602409639,
      "grad_norm": 2.397979974746704,
      "learning_rate": 1.4837349397590364e-05,
      "loss": 0.0628,
      "step": 42850
    },
    {
      "epoch": 5.163855421686747,
      "grad_norm": 1.0280098915100098,
      "learning_rate": 1.4836144578313255e-05,
      "loss": 0.0765,
      "step": 42860
    },
    {
      "epoch": 5.1650602409638555,
      "grad_norm": 2.341836929321289,
      "learning_rate": 1.4834939759036147e-05,
      "loss": 0.036,
      "step": 42870
    },
    {
      "epoch": 5.166265060240963,
      "grad_norm": 13.551359176635742,
      "learning_rate": 1.4833734939759036e-05,
      "loss": 0.0323,
      "step": 42880
    },
    {
      "epoch": 5.167469879518072,
      "grad_norm": 0.3065067231655121,
      "learning_rate": 1.4832530120481929e-05,
      "loss": 0.0256,
      "step": 42890
    },
    {
      "epoch": 5.168674698795181,
      "grad_norm": 1.006041407585144,
      "learning_rate": 1.483132530120482e-05,
      "loss": 0.0654,
      "step": 42900
    },
    {
      "epoch": 5.169879518072289,
      "grad_norm": 1.0158926248550415,
      "learning_rate": 1.4830120481927712e-05,
      "loss": 0.0315,
      "step": 42910
    },
    {
      "epoch": 5.171084337349398,
      "grad_norm": 4.3173723220825195,
      "learning_rate": 1.4828915662650602e-05,
      "loss": 0.0451,
      "step": 42920
    },
    {
      "epoch": 5.172289156626506,
      "grad_norm": 0.02483009733259678,
      "learning_rate": 1.4827710843373495e-05,
      "loss": 0.0928,
      "step": 42930
    },
    {
      "epoch": 5.1734939759036145,
      "grad_norm": 0.3428284525871277,
      "learning_rate": 1.4826506024096387e-05,
      "loss": 0.0338,
      "step": 42940
    },
    {
      "epoch": 5.174698795180723,
      "grad_norm": 0.18853923678398132,
      "learning_rate": 1.4825301204819278e-05,
      "loss": 0.0243,
      "step": 42950
    },
    {
      "epoch": 5.175903614457831,
      "grad_norm": 1.9260836839675903,
      "learning_rate": 1.482409638554217e-05,
      "loss": 0.0716,
      "step": 42960
    },
    {
      "epoch": 5.17710843373494,
      "grad_norm": 0.007898960262537003,
      "learning_rate": 1.4822891566265061e-05,
      "loss": 0.0084,
      "step": 42970
    },
    {
      "epoch": 5.178313253012048,
      "grad_norm": 0.653835117816925,
      "learning_rate": 1.4821686746987954e-05,
      "loss": 0.0845,
      "step": 42980
    },
    {
      "epoch": 5.179518072289157,
      "grad_norm": 2.965398073196411,
      "learning_rate": 1.4820481927710843e-05,
      "loss": 0.0666,
      "step": 42990
    },
    {
      "epoch": 5.180722891566265,
      "grad_norm": 0.011814003810286522,
      "learning_rate": 1.4819277108433737e-05,
      "loss": 0.0095,
      "step": 43000
    },
    {
      "epoch": 5.1819277108433734,
      "grad_norm": 1.32295560836792,
      "learning_rate": 1.481807228915663e-05,
      "loss": 0.0894,
      "step": 43010
    },
    {
      "epoch": 5.183132530120482,
      "grad_norm": 4.166160583496094,
      "learning_rate": 1.4816867469879518e-05,
      "loss": 0.0536,
      "step": 43020
    },
    {
      "epoch": 5.18433734939759,
      "grad_norm": 6.016754627227783,
      "learning_rate": 1.481566265060241e-05,
      "loss": 0.0429,
      "step": 43030
    },
    {
      "epoch": 5.185542168674699,
      "grad_norm": 0.11110736429691315,
      "learning_rate": 1.4814457831325302e-05,
      "loss": 0.034,
      "step": 43040
    },
    {
      "epoch": 5.186746987951807,
      "grad_norm": 0.26686492562294006,
      "learning_rate": 1.4813253012048194e-05,
      "loss": 0.0523,
      "step": 43050
    },
    {
      "epoch": 5.187951807228916,
      "grad_norm": 3.3635342121124268,
      "learning_rate": 1.4812048192771085e-05,
      "loss": 0.0431,
      "step": 43060
    },
    {
      "epoch": 5.1891566265060245,
      "grad_norm": 0.03461584448814392,
      "learning_rate": 1.4810843373493977e-05,
      "loss": 0.0531,
      "step": 43070
    },
    {
      "epoch": 5.190361445783132,
      "grad_norm": 0.03055286779999733,
      "learning_rate": 1.480963855421687e-05,
      "loss": 0.0393,
      "step": 43080
    },
    {
      "epoch": 5.191566265060241,
      "grad_norm": 1.7855231761932373,
      "learning_rate": 1.480843373493976e-05,
      "loss": 0.0527,
      "step": 43090
    },
    {
      "epoch": 5.192771084337349,
      "grad_norm": 0.3823334872722626,
      "learning_rate": 1.4807228915662653e-05,
      "loss": 0.0507,
      "step": 43100
    },
    {
      "epoch": 5.193975903614458,
      "grad_norm": 50.15321350097656,
      "learning_rate": 1.4806024096385544e-05,
      "loss": 0.0808,
      "step": 43110
    },
    {
      "epoch": 5.195180722891566,
      "grad_norm": 0.1003619059920311,
      "learning_rate": 1.4804819277108436e-05,
      "loss": 0.0107,
      "step": 43120
    },
    {
      "epoch": 5.196385542168675,
      "grad_norm": 0.018183182924985886,
      "learning_rate": 1.4803614457831325e-05,
      "loss": 0.0498,
      "step": 43130
    },
    {
      "epoch": 5.1975903614457835,
      "grad_norm": 0.27955421805381775,
      "learning_rate": 1.4802409638554217e-05,
      "loss": 0.0062,
      "step": 43140
    },
    {
      "epoch": 5.198795180722891,
      "grad_norm": 0.1148378923535347,
      "learning_rate": 1.4801204819277112e-05,
      "loss": 0.0679,
      "step": 43150
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.05279015749692917,
      "learning_rate": 1.48e-05,
      "loss": 0.0441,
      "step": 43160
    },
    {
      "epoch": 5.201204819277108,
      "grad_norm": 60.1826171875,
      "learning_rate": 1.4798795180722893e-05,
      "loss": 0.0275,
      "step": 43170
    },
    {
      "epoch": 5.202409638554217,
      "grad_norm": 34.961761474609375,
      "learning_rate": 1.4797590361445784e-05,
      "loss": 0.0549,
      "step": 43180
    },
    {
      "epoch": 5.203614457831326,
      "grad_norm": 0.016490159556269646,
      "learning_rate": 1.4796385542168676e-05,
      "loss": 0.0137,
      "step": 43190
    },
    {
      "epoch": 5.204819277108434,
      "grad_norm": 7.377558708190918,
      "learning_rate": 1.4795180722891567e-05,
      "loss": 0.0194,
      "step": 43200
    },
    {
      "epoch": 5.206024096385542,
      "grad_norm": 0.008365367539227009,
      "learning_rate": 1.479397590361446e-05,
      "loss": 0.0927,
      "step": 43210
    },
    {
      "epoch": 5.20722891566265,
      "grad_norm": 4.6598615646362305,
      "learning_rate": 1.479277108433735e-05,
      "loss": 0.08,
      "step": 43220
    },
    {
      "epoch": 5.208433734939759,
      "grad_norm": 0.06333627551794052,
      "learning_rate": 1.4791566265060243e-05,
      "loss": 0.04,
      "step": 43230
    },
    {
      "epoch": 5.209638554216867,
      "grad_norm": 0.06446981430053711,
      "learning_rate": 1.4790361445783135e-05,
      "loss": 0.0531,
      "step": 43240
    },
    {
      "epoch": 5.210843373493976,
      "grad_norm": 0.7585690021514893,
      "learning_rate": 1.4789156626506026e-05,
      "loss": 0.0073,
      "step": 43250
    },
    {
      "epoch": 5.212048192771085,
      "grad_norm": 0.2552628815174103,
      "learning_rate": 1.4787951807228918e-05,
      "loss": 0.0457,
      "step": 43260
    },
    {
      "epoch": 5.213253012048193,
      "grad_norm": 1.8590314388275146,
      "learning_rate": 1.4786746987951807e-05,
      "loss": 0.0919,
      "step": 43270
    },
    {
      "epoch": 5.214457831325301,
      "grad_norm": 0.01978428289294243,
      "learning_rate": 1.47855421686747e-05,
      "loss": 0.0926,
      "step": 43280
    },
    {
      "epoch": 5.215662650602409,
      "grad_norm": 1.5413784980773926,
      "learning_rate": 1.478433734939759e-05,
      "loss": 0.0326,
      "step": 43290
    },
    {
      "epoch": 5.216867469879518,
      "grad_norm": 21.37132453918457,
      "learning_rate": 1.4783132530120483e-05,
      "loss": 0.0431,
      "step": 43300
    },
    {
      "epoch": 5.218072289156627,
      "grad_norm": 0.6241633296012878,
      "learning_rate": 1.4781927710843375e-05,
      "loss": 0.0165,
      "step": 43310
    },
    {
      "epoch": 5.219277108433735,
      "grad_norm": 1.253190517425537,
      "learning_rate": 1.4780722891566266e-05,
      "loss": 0.027,
      "step": 43320
    },
    {
      "epoch": 5.220481927710844,
      "grad_norm": 0.01614149659872055,
      "learning_rate": 1.4779518072289158e-05,
      "loss": 0.0204,
      "step": 43330
    },
    {
      "epoch": 5.2216867469879515,
      "grad_norm": 0.03348566219210625,
      "learning_rate": 1.477831325301205e-05,
      "loss": 0.0473,
      "step": 43340
    },
    {
      "epoch": 5.22289156626506,
      "grad_norm": 0.011506679467856884,
      "learning_rate": 1.4777108433734942e-05,
      "loss": 0.0325,
      "step": 43350
    },
    {
      "epoch": 5.224096385542168,
      "grad_norm": 0.012955758720636368,
      "learning_rate": 1.4775903614457832e-05,
      "loss": 0.0142,
      "step": 43360
    },
    {
      "epoch": 5.225301204819277,
      "grad_norm": 0.01665494404733181,
      "learning_rate": 1.4774698795180725e-05,
      "loss": 0.0742,
      "step": 43370
    },
    {
      "epoch": 5.226506024096386,
      "grad_norm": 2.6591601371765137,
      "learning_rate": 1.4773493975903617e-05,
      "loss": 0.0481,
      "step": 43380
    },
    {
      "epoch": 5.227710843373494,
      "grad_norm": 0.2754878103733063,
      "learning_rate": 1.4772289156626506e-05,
      "loss": 0.0294,
      "step": 43390
    },
    {
      "epoch": 5.228915662650603,
      "grad_norm": 0.18170155584812164,
      "learning_rate": 1.4771084337349399e-05,
      "loss": 0.0407,
      "step": 43400
    },
    {
      "epoch": 5.2301204819277105,
      "grad_norm": 24.379810333251953,
      "learning_rate": 1.476987951807229e-05,
      "loss": 0.0389,
      "step": 43410
    },
    {
      "epoch": 5.231325301204819,
      "grad_norm": 2.108708143234253,
      "learning_rate": 1.4768674698795182e-05,
      "loss": 0.019,
      "step": 43420
    },
    {
      "epoch": 5.232530120481928,
      "grad_norm": 0.01426526065915823,
      "learning_rate": 1.4767469879518073e-05,
      "loss": 0.0497,
      "step": 43430
    },
    {
      "epoch": 5.233734939759036,
      "grad_norm": 0.07097245752811432,
      "learning_rate": 1.4766265060240965e-05,
      "loss": 0.077,
      "step": 43440
    },
    {
      "epoch": 5.234939759036145,
      "grad_norm": 3.2324583530426025,
      "learning_rate": 1.4765060240963858e-05,
      "loss": 0.0582,
      "step": 43450
    },
    {
      "epoch": 5.236144578313253,
      "grad_norm": 3.4833927154541016,
      "learning_rate": 1.4763855421686748e-05,
      "loss": 0.0978,
      "step": 43460
    },
    {
      "epoch": 5.2373493975903616,
      "grad_norm": 0.0883248820900917,
      "learning_rate": 1.476265060240964e-05,
      "loss": 0.0128,
      "step": 43470
    },
    {
      "epoch": 5.2385542168674695,
      "grad_norm": 6.300846576690674,
      "learning_rate": 1.4761445783132531e-05,
      "loss": 0.0528,
      "step": 43480
    },
    {
      "epoch": 5.239759036144578,
      "grad_norm": 5.2599406242370605,
      "learning_rate": 1.4760240963855424e-05,
      "loss": 0.0493,
      "step": 43490
    },
    {
      "epoch": 5.240963855421687,
      "grad_norm": 0.04230204597115517,
      "learning_rate": 1.4759036144578313e-05,
      "loss": 0.0304,
      "step": 43500
    },
    {
      "epoch": 5.242168674698795,
      "grad_norm": 0.0143129276111722,
      "learning_rate": 1.4757831325301207e-05,
      "loss": 0.0266,
      "step": 43510
    },
    {
      "epoch": 5.243373493975904,
      "grad_norm": 6.354344367980957,
      "learning_rate": 1.4756626506024096e-05,
      "loss": 0.0709,
      "step": 43520
    },
    {
      "epoch": 5.244578313253012,
      "grad_norm": 15.513633728027344,
      "learning_rate": 1.4755421686746989e-05,
      "loss": 0.0263,
      "step": 43530
    },
    {
      "epoch": 5.2457831325301205,
      "grad_norm": 0.2678247392177582,
      "learning_rate": 1.4754216867469881e-05,
      "loss": 0.0605,
      "step": 43540
    },
    {
      "epoch": 5.246987951807229,
      "grad_norm": 0.017165567725896835,
      "learning_rate": 1.4753012048192772e-05,
      "loss": 0.0418,
      "step": 43550
    },
    {
      "epoch": 5.248192771084337,
      "grad_norm": 2.6702418327331543,
      "learning_rate": 1.4751807228915664e-05,
      "loss": 0.0637,
      "step": 43560
    },
    {
      "epoch": 5.249397590361446,
      "grad_norm": 0.8736267685890198,
      "learning_rate": 1.4750602409638555e-05,
      "loss": 0.0566,
      "step": 43570
    },
    {
      "epoch": 5.250602409638554,
      "grad_norm": 0.1455073356628418,
      "learning_rate": 1.4749397590361447e-05,
      "loss": 0.0399,
      "step": 43580
    },
    {
      "epoch": 5.251807228915663,
      "grad_norm": 0.10194800049066544,
      "learning_rate": 1.4748192771084338e-05,
      "loss": 0.0366,
      "step": 43590
    },
    {
      "epoch": 5.253012048192771,
      "grad_norm": 6.536916255950928,
      "learning_rate": 1.474698795180723e-05,
      "loss": 0.0285,
      "step": 43600
    },
    {
      "epoch": 5.2542168674698795,
      "grad_norm": 0.04614555835723877,
      "learning_rate": 1.4745783132530123e-05,
      "loss": 0.0156,
      "step": 43610
    },
    {
      "epoch": 5.255421686746988,
      "grad_norm": 1.6075820922851562,
      "learning_rate": 1.4744578313253014e-05,
      "loss": 0.147,
      "step": 43620
    },
    {
      "epoch": 5.256626506024096,
      "grad_norm": 0.4529890716075897,
      "learning_rate": 1.4743373493975906e-05,
      "loss": 0.0762,
      "step": 43630
    },
    {
      "epoch": 5.257831325301205,
      "grad_norm": 0.22331443428993225,
      "learning_rate": 1.4742168674698795e-05,
      "loss": 0.0448,
      "step": 43640
    },
    {
      "epoch": 5.259036144578313,
      "grad_norm": 0.05440939590334892,
      "learning_rate": 1.4740963855421688e-05,
      "loss": 0.0294,
      "step": 43650
    },
    {
      "epoch": 5.260240963855422,
      "grad_norm": 9.324624061584473,
      "learning_rate": 1.4739759036144578e-05,
      "loss": 0.1114,
      "step": 43660
    },
    {
      "epoch": 5.2614457831325305,
      "grad_norm": 0.14097581803798676,
      "learning_rate": 1.473855421686747e-05,
      "loss": 0.0385,
      "step": 43670
    },
    {
      "epoch": 5.2626506024096384,
      "grad_norm": 1.9719916582107544,
      "learning_rate": 1.4737349397590363e-05,
      "loss": 0.0462,
      "step": 43680
    },
    {
      "epoch": 5.263855421686747,
      "grad_norm": 0.676056981086731,
      "learning_rate": 1.4736144578313254e-05,
      "loss": 0.0217,
      "step": 43690
    },
    {
      "epoch": 5.265060240963855,
      "grad_norm": 3.9238786697387695,
      "learning_rate": 1.4734939759036146e-05,
      "loss": 0.0554,
      "step": 43700
    },
    {
      "epoch": 5.266265060240964,
      "grad_norm": 0.4574429392814636,
      "learning_rate": 1.4733734939759037e-05,
      "loss": 0.0099,
      "step": 43710
    },
    {
      "epoch": 5.267469879518072,
      "grad_norm": 0.43692269921302795,
      "learning_rate": 1.473253012048193e-05,
      "loss": 0.0085,
      "step": 43720
    },
    {
      "epoch": 5.268674698795181,
      "grad_norm": 6.882184028625488,
      "learning_rate": 1.473132530120482e-05,
      "loss": 0.0905,
      "step": 43730
    },
    {
      "epoch": 5.2698795180722895,
      "grad_norm": 0.037458278238773346,
      "learning_rate": 1.4730120481927713e-05,
      "loss": 0.0843,
      "step": 43740
    },
    {
      "epoch": 5.271084337349397,
      "grad_norm": 0.23956845700740814,
      "learning_rate": 1.4728915662650605e-05,
      "loss": 0.0556,
      "step": 43750
    },
    {
      "epoch": 5.272289156626506,
      "grad_norm": 0.1992868334054947,
      "learning_rate": 1.4727710843373494e-05,
      "loss": 0.0296,
      "step": 43760
    },
    {
      "epoch": 5.273493975903614,
      "grad_norm": 1.9925882816314697,
      "learning_rate": 1.4726506024096388e-05,
      "loss": 0.0258,
      "step": 43770
    },
    {
      "epoch": 5.274698795180723,
      "grad_norm": 0.03628223389387131,
      "learning_rate": 1.4725301204819277e-05,
      "loss": 0.0191,
      "step": 43780
    },
    {
      "epoch": 5.275903614457832,
      "grad_norm": 0.1197793111205101,
      "learning_rate": 1.472409638554217e-05,
      "loss": 0.035,
      "step": 43790
    },
    {
      "epoch": 5.27710843373494,
      "grad_norm": 2.7340199947357178,
      "learning_rate": 1.472289156626506e-05,
      "loss": 0.0689,
      "step": 43800
    },
    {
      "epoch": 5.2783132530120485,
      "grad_norm": 0.05540262162685394,
      "learning_rate": 1.4721686746987953e-05,
      "loss": 0.0495,
      "step": 43810
    },
    {
      "epoch": 5.279518072289156,
      "grad_norm": 1.3673243522644043,
      "learning_rate": 1.4720481927710844e-05,
      "loss": 0.0249,
      "step": 43820
    },
    {
      "epoch": 5.280722891566265,
      "grad_norm": 0.13011083006858826,
      "learning_rate": 1.4719277108433736e-05,
      "loss": 0.027,
      "step": 43830
    },
    {
      "epoch": 5.281927710843373,
      "grad_norm": 0.011332283727824688,
      "learning_rate": 1.4718072289156629e-05,
      "loss": 0.0361,
      "step": 43840
    },
    {
      "epoch": 5.283132530120482,
      "grad_norm": 1.4379901885986328,
      "learning_rate": 1.471686746987952e-05,
      "loss": 0.0116,
      "step": 43850
    },
    {
      "epoch": 5.284337349397591,
      "grad_norm": 0.13270063698291779,
      "learning_rate": 1.4715662650602412e-05,
      "loss": 0.0165,
      "step": 43860
    },
    {
      "epoch": 5.285542168674699,
      "grad_norm": 0.09499311447143555,
      "learning_rate": 1.4714457831325303e-05,
      "loss": 0.0903,
      "step": 43870
    },
    {
      "epoch": 5.286746987951807,
      "grad_norm": 0.027332782745361328,
      "learning_rate": 1.4713253012048195e-05,
      "loss": 0.0352,
      "step": 43880
    },
    {
      "epoch": 5.287951807228915,
      "grad_norm": 0.18177668750286102,
      "learning_rate": 1.4712048192771084e-05,
      "loss": 0.0107,
      "step": 43890
    },
    {
      "epoch": 5.289156626506024,
      "grad_norm": 1.8454110622406006,
      "learning_rate": 1.4710843373493976e-05,
      "loss": 0.0256,
      "step": 43900
    },
    {
      "epoch": 5.290361445783133,
      "grad_norm": 10.283255577087402,
      "learning_rate": 1.4709638554216869e-05,
      "loss": 0.0375,
      "step": 43910
    },
    {
      "epoch": 5.291566265060241,
      "grad_norm": 2.4969890117645264,
      "learning_rate": 1.470843373493976e-05,
      "loss": 0.0508,
      "step": 43920
    },
    {
      "epoch": 5.29277108433735,
      "grad_norm": 3.010525703430176,
      "learning_rate": 1.4707228915662652e-05,
      "loss": 0.0654,
      "step": 43930
    },
    {
      "epoch": 5.293975903614458,
      "grad_norm": 0.7579575181007385,
      "learning_rate": 1.4706024096385543e-05,
      "loss": 0.0498,
      "step": 43940
    },
    {
      "epoch": 5.295180722891566,
      "grad_norm": 0.29688888788223267,
      "learning_rate": 1.4704819277108435e-05,
      "loss": 0.032,
      "step": 43950
    },
    {
      "epoch": 5.296385542168674,
      "grad_norm": 6.791123390197754,
      "learning_rate": 1.4703614457831326e-05,
      "loss": 0.0337,
      "step": 43960
    },
    {
      "epoch": 5.297590361445783,
      "grad_norm": 1.4427694082260132,
      "learning_rate": 1.4702409638554218e-05,
      "loss": 0.0318,
      "step": 43970
    },
    {
      "epoch": 5.298795180722892,
      "grad_norm": 11.592912673950195,
      "learning_rate": 1.470120481927711e-05,
      "loss": 0.0513,
      "step": 43980
    },
    {
      "epoch": 5.3,
      "grad_norm": 1.8304028511047363,
      "learning_rate": 1.4700000000000002e-05,
      "loss": 0.018,
      "step": 43990
    },
    {
      "epoch": 5.301204819277109,
      "grad_norm": 0.040467459708452225,
      "learning_rate": 1.4698795180722894e-05,
      "loss": 0.0257,
      "step": 44000
    },
    {
      "epoch": 5.3024096385542165,
      "grad_norm": 2.4903900623321533,
      "learning_rate": 1.4697590361445783e-05,
      "loss": 0.0825,
      "step": 44010
    },
    {
      "epoch": 5.303614457831325,
      "grad_norm": 0.13592712581157684,
      "learning_rate": 1.4696385542168675e-05,
      "loss": 0.05,
      "step": 44020
    },
    {
      "epoch": 5.304819277108434,
      "grad_norm": 27.414138793945312,
      "learning_rate": 1.4695180722891566e-05,
      "loss": 0.0836,
      "step": 44030
    },
    {
      "epoch": 5.306024096385542,
      "grad_norm": 0.0780477523803711,
      "learning_rate": 1.4693975903614459e-05,
      "loss": 0.0246,
      "step": 44040
    },
    {
      "epoch": 5.307228915662651,
      "grad_norm": 1.4515018463134766,
      "learning_rate": 1.4692771084337351e-05,
      "loss": 0.1015,
      "step": 44050
    },
    {
      "epoch": 5.308433734939759,
      "grad_norm": 0.018561968579888344,
      "learning_rate": 1.4691566265060242e-05,
      "loss": 0.026,
      "step": 44060
    },
    {
      "epoch": 5.309638554216868,
      "grad_norm": 0.3467254042625427,
      "learning_rate": 1.4690361445783134e-05,
      "loss": 0.0184,
      "step": 44070
    },
    {
      "epoch": 5.3108433734939755,
      "grad_norm": 0.8502821326255798,
      "learning_rate": 1.4689156626506025e-05,
      "loss": 0.0518,
      "step": 44080
    },
    {
      "epoch": 5.312048192771084,
      "grad_norm": 0.33693599700927734,
      "learning_rate": 1.4687951807228917e-05,
      "loss": 0.0553,
      "step": 44090
    },
    {
      "epoch": 5.313253012048193,
      "grad_norm": 0.8122751712799072,
      "learning_rate": 1.4686746987951808e-05,
      "loss": 0.0585,
      "step": 44100
    },
    {
      "epoch": 5.314457831325301,
      "grad_norm": 2.695284366607666,
      "learning_rate": 1.46855421686747e-05,
      "loss": 0.0762,
      "step": 44110
    },
    {
      "epoch": 5.31566265060241,
      "grad_norm": 2.1862401962280273,
      "learning_rate": 1.468433734939759e-05,
      "loss": 0.0291,
      "step": 44120
    },
    {
      "epoch": 5.316867469879518,
      "grad_norm": 0.21003520488739014,
      "learning_rate": 1.4683132530120484e-05,
      "loss": 0.0216,
      "step": 44130
    },
    {
      "epoch": 5.3180722891566266,
      "grad_norm": 5.815417766571045,
      "learning_rate": 1.4681927710843376e-05,
      "loss": 0.092,
      "step": 44140
    },
    {
      "epoch": 5.3192771084337345,
      "grad_norm": 0.30554628372192383,
      "learning_rate": 1.4680722891566265e-05,
      "loss": 0.0616,
      "step": 44150
    },
    {
      "epoch": 5.320481927710843,
      "grad_norm": 2.80277681350708,
      "learning_rate": 1.4679518072289158e-05,
      "loss": 0.026,
      "step": 44160
    },
    {
      "epoch": 5.321686746987952,
      "grad_norm": 0.03757211193442345,
      "learning_rate": 1.4678313253012048e-05,
      "loss": 0.0507,
      "step": 44170
    },
    {
      "epoch": 5.32289156626506,
      "grad_norm": 1.023724913597107,
      "learning_rate": 1.4677108433734941e-05,
      "loss": 0.027,
      "step": 44180
    },
    {
      "epoch": 5.324096385542169,
      "grad_norm": 4.522324085235596,
      "learning_rate": 1.4675903614457832e-05,
      "loss": 0.0266,
      "step": 44190
    },
    {
      "epoch": 5.325301204819277,
      "grad_norm": 1.23798406124115,
      "learning_rate": 1.4674698795180724e-05,
      "loss": 0.0344,
      "step": 44200
    },
    {
      "epoch": 5.3265060240963855,
      "grad_norm": 0.039455052465200424,
      "learning_rate": 1.4673493975903616e-05,
      "loss": 0.049,
      "step": 44210
    },
    {
      "epoch": 5.327710843373494,
      "grad_norm": 0.0023116811644285917,
      "learning_rate": 1.4672289156626507e-05,
      "loss": 0.0212,
      "step": 44220
    },
    {
      "epoch": 5.328915662650602,
      "grad_norm": 9.035893440246582,
      "learning_rate": 1.46710843373494e-05,
      "loss": 0.1329,
      "step": 44230
    },
    {
      "epoch": 5.330120481927711,
      "grad_norm": 1.1299465894699097,
      "learning_rate": 1.466987951807229e-05,
      "loss": 0.0246,
      "step": 44240
    },
    {
      "epoch": 5.331325301204819,
      "grad_norm": 6.057157516479492,
      "learning_rate": 1.4668674698795183e-05,
      "loss": 0.0147,
      "step": 44250
    },
    {
      "epoch": 5.332530120481928,
      "grad_norm": 0.2488158643245697,
      "learning_rate": 1.4667469879518072e-05,
      "loss": 0.0412,
      "step": 44260
    },
    {
      "epoch": 5.333734939759037,
      "grad_norm": 0.0551014170050621,
      "learning_rate": 1.4666265060240964e-05,
      "loss": 0.0241,
      "step": 44270
    },
    {
      "epoch": 5.3349397590361445,
      "grad_norm": 15.641587257385254,
      "learning_rate": 1.4665060240963857e-05,
      "loss": 0.0496,
      "step": 44280
    },
    {
      "epoch": 5.336144578313253,
      "grad_norm": 0.05202174559235573,
      "learning_rate": 1.4663855421686748e-05,
      "loss": 0.0535,
      "step": 44290
    },
    {
      "epoch": 5.337349397590361,
      "grad_norm": 0.4848441481590271,
      "learning_rate": 1.466265060240964e-05,
      "loss": 0.0389,
      "step": 44300
    },
    {
      "epoch": 5.33855421686747,
      "grad_norm": 2.196579694747925,
      "learning_rate": 1.466144578313253e-05,
      "loss": 0.0338,
      "step": 44310
    },
    {
      "epoch": 5.339759036144578,
      "grad_norm": 0.02222343720495701,
      "learning_rate": 1.4660240963855423e-05,
      "loss": 0.0534,
      "step": 44320
    },
    {
      "epoch": 5.340963855421687,
      "grad_norm": 1.1494358777999878,
      "learning_rate": 1.4659036144578314e-05,
      "loss": 0.0462,
      "step": 44330
    },
    {
      "epoch": 5.3421686746987955,
      "grad_norm": 0.07261087745428085,
      "learning_rate": 1.4657831325301206e-05,
      "loss": 0.0531,
      "step": 44340
    },
    {
      "epoch": 5.343373493975903,
      "grad_norm": 0.021091602742671967,
      "learning_rate": 1.4656626506024099e-05,
      "loss": 0.0209,
      "step": 44350
    },
    {
      "epoch": 5.344578313253012,
      "grad_norm": 4.652217864990234,
      "learning_rate": 1.465542168674699e-05,
      "loss": 0.0329,
      "step": 44360
    },
    {
      "epoch": 5.34578313253012,
      "grad_norm": 4.205556392669678,
      "learning_rate": 1.4654216867469882e-05,
      "loss": 0.0639,
      "step": 44370
    },
    {
      "epoch": 5.346987951807229,
      "grad_norm": 16.809206008911133,
      "learning_rate": 1.4653012048192771e-05,
      "loss": 0.0196,
      "step": 44380
    },
    {
      "epoch": 5.348192771084337,
      "grad_norm": 3.3871665000915527,
      "learning_rate": 1.4651807228915665e-05,
      "loss": 0.0376,
      "step": 44390
    },
    {
      "epoch": 5.349397590361446,
      "grad_norm": 3.116816520690918,
      "learning_rate": 1.4650602409638554e-05,
      "loss": 0.074,
      "step": 44400
    },
    {
      "epoch": 5.3506024096385545,
      "grad_norm": 0.04175390303134918,
      "learning_rate": 1.4649397590361447e-05,
      "loss": 0.0664,
      "step": 44410
    },
    {
      "epoch": 5.351807228915662,
      "grad_norm": 0.25380149483680725,
      "learning_rate": 1.4648192771084337e-05,
      "loss": 0.0383,
      "step": 44420
    },
    {
      "epoch": 5.353012048192771,
      "grad_norm": 0.23038740456104279,
      "learning_rate": 1.464698795180723e-05,
      "loss": 0.0296,
      "step": 44430
    },
    {
      "epoch": 5.354216867469879,
      "grad_norm": 0.28751155734062195,
      "learning_rate": 1.4645783132530122e-05,
      "loss": 0.0308,
      "step": 44440
    },
    {
      "epoch": 5.355421686746988,
      "grad_norm": 0.968396008014679,
      "learning_rate": 1.4644578313253013e-05,
      "loss": 0.0096,
      "step": 44450
    },
    {
      "epoch": 5.356626506024097,
      "grad_norm": 0.0333016961812973,
      "learning_rate": 1.4643373493975905e-05,
      "loss": 0.1334,
      "step": 44460
    },
    {
      "epoch": 5.357831325301205,
      "grad_norm": 0.07052632421255112,
      "learning_rate": 1.4642168674698796e-05,
      "loss": 0.0225,
      "step": 44470
    },
    {
      "epoch": 5.3590361445783135,
      "grad_norm": 0.02678256668150425,
      "learning_rate": 1.4640963855421689e-05,
      "loss": 0.0693,
      "step": 44480
    },
    {
      "epoch": 5.360240963855421,
      "grad_norm": 0.06282538175582886,
      "learning_rate": 1.463975903614458e-05,
      "loss": 0.0342,
      "step": 44490
    },
    {
      "epoch": 5.36144578313253,
      "grad_norm": 0.054673872888088226,
      "learning_rate": 1.4638554216867472e-05,
      "loss": 0.0739,
      "step": 44500
    },
    {
      "epoch": 5.362650602409639,
      "grad_norm": 0.17081111669540405,
      "learning_rate": 1.4637349397590364e-05,
      "loss": 0.0188,
      "step": 44510
    },
    {
      "epoch": 5.363855421686747,
      "grad_norm": 6.9167094230651855,
      "learning_rate": 1.4636144578313253e-05,
      "loss": 0.05,
      "step": 44520
    },
    {
      "epoch": 5.365060240963856,
      "grad_norm": 2.530597448348999,
      "learning_rate": 1.4634939759036146e-05,
      "loss": 0.0506,
      "step": 44530
    },
    {
      "epoch": 5.366265060240964,
      "grad_norm": 0.0677233636379242,
      "learning_rate": 1.4633734939759036e-05,
      "loss": 0.0478,
      "step": 44540
    },
    {
      "epoch": 5.367469879518072,
      "grad_norm": 18.178977966308594,
      "learning_rate": 1.4632530120481929e-05,
      "loss": 0.0472,
      "step": 44550
    },
    {
      "epoch": 5.36867469879518,
      "grad_norm": 0.352706640958786,
      "learning_rate": 1.463132530120482e-05,
      "loss": 0.043,
      "step": 44560
    },
    {
      "epoch": 5.369879518072289,
      "grad_norm": 0.1495307832956314,
      "learning_rate": 1.4630120481927712e-05,
      "loss": 0.0389,
      "step": 44570
    },
    {
      "epoch": 5.371084337349398,
      "grad_norm": 1.9068857431411743,
      "learning_rate": 1.4628915662650604e-05,
      "loss": 0.0279,
      "step": 44580
    },
    {
      "epoch": 5.372289156626506,
      "grad_norm": 0.5275295376777649,
      "learning_rate": 1.4627710843373495e-05,
      "loss": 0.0586,
      "step": 44590
    },
    {
      "epoch": 5.373493975903615,
      "grad_norm": 0.1832498461008072,
      "learning_rate": 1.4626506024096388e-05,
      "loss": 0.0315,
      "step": 44600
    },
    {
      "epoch": 5.374698795180723,
      "grad_norm": 0.0451347753405571,
      "learning_rate": 1.4625301204819278e-05,
      "loss": 0.0504,
      "step": 44610
    },
    {
      "epoch": 5.375903614457831,
      "grad_norm": 0.03506570681929588,
      "learning_rate": 1.462409638554217e-05,
      "loss": 0.0509,
      "step": 44620
    },
    {
      "epoch": 5.377108433734939,
      "grad_norm": 1.0439525842666626,
      "learning_rate": 1.462289156626506e-05,
      "loss": 0.0246,
      "step": 44630
    },
    {
      "epoch": 5.378313253012048,
      "grad_norm": 2.522427797317505,
      "learning_rate": 1.4621686746987954e-05,
      "loss": 0.0301,
      "step": 44640
    },
    {
      "epoch": 5.379518072289157,
      "grad_norm": 0.2559782564640045,
      "learning_rate": 1.4620481927710846e-05,
      "loss": 0.0168,
      "step": 44650
    },
    {
      "epoch": 5.380722891566265,
      "grad_norm": 4.4878010749816895,
      "learning_rate": 1.4619277108433735e-05,
      "loss": 0.0269,
      "step": 44660
    },
    {
      "epoch": 5.381927710843374,
      "grad_norm": 0.3472517132759094,
      "learning_rate": 1.4618072289156628e-05,
      "loss": 0.0213,
      "step": 44670
    },
    {
      "epoch": 5.3831325301204815,
      "grad_norm": 6.692553520202637,
      "learning_rate": 1.4616867469879519e-05,
      "loss": 0.0863,
      "step": 44680
    },
    {
      "epoch": 5.38433734939759,
      "grad_norm": 1.1665592193603516,
      "learning_rate": 1.4615662650602411e-05,
      "loss": 0.0271,
      "step": 44690
    },
    {
      "epoch": 5.385542168674699,
      "grad_norm": 0.019863048568367958,
      "learning_rate": 1.4614457831325302e-05,
      "loss": 0.0145,
      "step": 44700
    },
    {
      "epoch": 5.386746987951807,
      "grad_norm": 1.643900752067566,
      "learning_rate": 1.4613253012048194e-05,
      "loss": 0.0461,
      "step": 44710
    },
    {
      "epoch": 5.387951807228916,
      "grad_norm": 5.748080730438232,
      "learning_rate": 1.4612048192771085e-05,
      "loss": 0.0683,
      "step": 44720
    },
    {
      "epoch": 5.389156626506024,
      "grad_norm": 2.1998021602630615,
      "learning_rate": 1.4610843373493977e-05,
      "loss": 0.0844,
      "step": 44730
    },
    {
      "epoch": 5.390361445783133,
      "grad_norm": 0.5727730393409729,
      "learning_rate": 1.460963855421687e-05,
      "loss": 0.0177,
      "step": 44740
    },
    {
      "epoch": 5.391566265060241,
      "grad_norm": 0.3781861662864685,
      "learning_rate": 1.460843373493976e-05,
      "loss": 0.0626,
      "step": 44750
    },
    {
      "epoch": 5.392771084337349,
      "grad_norm": 3.8486125469207764,
      "learning_rate": 1.4607228915662653e-05,
      "loss": 0.028,
      "step": 44760
    },
    {
      "epoch": 5.393975903614458,
      "grad_norm": 0.037788234651088715,
      "learning_rate": 1.4606024096385542e-05,
      "loss": 0.0613,
      "step": 44770
    },
    {
      "epoch": 5.395180722891566,
      "grad_norm": 0.13854248821735382,
      "learning_rate": 1.4604819277108434e-05,
      "loss": 0.044,
      "step": 44780
    },
    {
      "epoch": 5.396385542168675,
      "grad_norm": 1.1216238737106323,
      "learning_rate": 1.4603614457831325e-05,
      "loss": 0.0713,
      "step": 44790
    },
    {
      "epoch": 5.397590361445783,
      "grad_norm": 0.07953052967786789,
      "learning_rate": 1.4602409638554218e-05,
      "loss": 0.0528,
      "step": 44800
    },
    {
      "epoch": 5.3987951807228916,
      "grad_norm": 0.5842847228050232,
      "learning_rate": 1.460120481927711e-05,
      "loss": 0.0262,
      "step": 44810
    },
    {
      "epoch": 5.4,
      "grad_norm": 4.507314205169678,
      "learning_rate": 1.46e-05,
      "loss": 0.0739,
      "step": 44820
    },
    {
      "epoch": 5.401204819277108,
      "grad_norm": 0.2855628430843353,
      "learning_rate": 1.4598795180722893e-05,
      "loss": 0.0099,
      "step": 44830
    },
    {
      "epoch": 5.402409638554217,
      "grad_norm": 1.0134696960449219,
      "learning_rate": 1.4597590361445784e-05,
      "loss": 0.0501,
      "step": 44840
    },
    {
      "epoch": 5.403614457831325,
      "grad_norm": 0.017529679462313652,
      "learning_rate": 1.4596385542168676e-05,
      "loss": 0.0716,
      "step": 44850
    },
    {
      "epoch": 5.404819277108434,
      "grad_norm": 0.018633762374520302,
      "learning_rate": 1.4595180722891567e-05,
      "loss": 0.0369,
      "step": 44860
    },
    {
      "epoch": 5.406024096385542,
      "grad_norm": 0.025294573977589607,
      "learning_rate": 1.459397590361446e-05,
      "loss": 0.0993,
      "step": 44870
    },
    {
      "epoch": 5.4072289156626505,
      "grad_norm": 2.546125650405884,
      "learning_rate": 1.4592771084337352e-05,
      "loss": 0.065,
      "step": 44880
    },
    {
      "epoch": 5.408433734939759,
      "grad_norm": 3.5554370880126953,
      "learning_rate": 1.4591566265060241e-05,
      "loss": 0.0699,
      "step": 44890
    },
    {
      "epoch": 5.409638554216867,
      "grad_norm": 2.1738157272338867,
      "learning_rate": 1.4590361445783135e-05,
      "loss": 0.046,
      "step": 44900
    },
    {
      "epoch": 5.410843373493976,
      "grad_norm": 0.30049651861190796,
      "learning_rate": 1.4589156626506024e-05,
      "loss": 0.04,
      "step": 44910
    },
    {
      "epoch": 5.412048192771084,
      "grad_norm": 4.4902496337890625,
      "learning_rate": 1.4587951807228917e-05,
      "loss": 0.0637,
      "step": 44920
    },
    {
      "epoch": 5.413253012048193,
      "grad_norm": 0.11800925433635712,
      "learning_rate": 1.4586746987951807e-05,
      "loss": 0.0371,
      "step": 44930
    },
    {
      "epoch": 5.414457831325302,
      "grad_norm": 4.319725036621094,
      "learning_rate": 1.45855421686747e-05,
      "loss": 0.0187,
      "step": 44940
    },
    {
      "epoch": 5.4156626506024095,
      "grad_norm": 0.02663918398320675,
      "learning_rate": 1.4584337349397592e-05,
      "loss": 0.0874,
      "step": 44950
    },
    {
      "epoch": 5.416867469879518,
      "grad_norm": 0.08341321349143982,
      "learning_rate": 1.4583132530120483e-05,
      "loss": 0.0355,
      "step": 44960
    },
    {
      "epoch": 5.418072289156626,
      "grad_norm": 1.5920757055282593,
      "learning_rate": 1.4581927710843375e-05,
      "loss": 0.0494,
      "step": 44970
    },
    {
      "epoch": 5.419277108433735,
      "grad_norm": 2.2499091625213623,
      "learning_rate": 1.4580722891566266e-05,
      "loss": 0.0862,
      "step": 44980
    },
    {
      "epoch": 5.420481927710844,
      "grad_norm": 3.683161973953247,
      "learning_rate": 1.4579518072289159e-05,
      "loss": 0.0425,
      "step": 44990
    },
    {
      "epoch": 5.421686746987952,
      "grad_norm": 3.307633876800537,
      "learning_rate": 1.457831325301205e-05,
      "loss": 0.0168,
      "step": 45000
    },
    {
      "epoch": 5.4228915662650605,
      "grad_norm": 0.04493638128042221,
      "learning_rate": 1.4577108433734942e-05,
      "loss": 0.0591,
      "step": 45010
    },
    {
      "epoch": 5.424096385542168,
      "grad_norm": 0.02600947953760624,
      "learning_rate": 1.4575903614457831e-05,
      "loss": 0.0664,
      "step": 45020
    },
    {
      "epoch": 5.425301204819277,
      "grad_norm": 3.593366861343384,
      "learning_rate": 1.4574698795180723e-05,
      "loss": 0.0513,
      "step": 45030
    },
    {
      "epoch": 5.426506024096385,
      "grad_norm": 0.4711872339248657,
      "learning_rate": 1.4573493975903616e-05,
      "loss": 0.0441,
      "step": 45040
    },
    {
      "epoch": 5.427710843373494,
      "grad_norm": 0.07701893895864487,
      "learning_rate": 1.4572289156626506e-05,
      "loss": 0.0406,
      "step": 45050
    },
    {
      "epoch": 5.428915662650603,
      "grad_norm": 1.9268549680709839,
      "learning_rate": 1.4571084337349399e-05,
      "loss": 0.0528,
      "step": 45060
    },
    {
      "epoch": 5.430120481927711,
      "grad_norm": 0.3375949263572693,
      "learning_rate": 1.456987951807229e-05,
      "loss": 0.0234,
      "step": 45070
    },
    {
      "epoch": 5.4313253012048195,
      "grad_norm": 1.5622328519821167,
      "learning_rate": 1.4568674698795182e-05,
      "loss": 0.0695,
      "step": 45080
    },
    {
      "epoch": 5.432530120481927,
      "grad_norm": 1.2970378398895264,
      "learning_rate": 1.4567469879518073e-05,
      "loss": 0.0431,
      "step": 45090
    },
    {
      "epoch": 5.433734939759036,
      "grad_norm": 0.49332937598228455,
      "learning_rate": 1.4566265060240965e-05,
      "loss": 0.0411,
      "step": 45100
    },
    {
      "epoch": 5.434939759036144,
      "grad_norm": 0.10417366772890091,
      "learning_rate": 1.4565060240963858e-05,
      "loss": 0.0628,
      "step": 45110
    },
    {
      "epoch": 5.436144578313253,
      "grad_norm": 1.5661906003952026,
      "learning_rate": 1.4563855421686748e-05,
      "loss": 0.017,
      "step": 45120
    },
    {
      "epoch": 5.437349397590362,
      "grad_norm": 1.6121304035186768,
      "learning_rate": 1.4562650602409641e-05,
      "loss": 0.0315,
      "step": 45130
    },
    {
      "epoch": 5.43855421686747,
      "grad_norm": 0.020656345412135124,
      "learning_rate": 1.456144578313253e-05,
      "loss": 0.0276,
      "step": 45140
    },
    {
      "epoch": 5.4397590361445785,
      "grad_norm": 6.46078634262085,
      "learning_rate": 1.4560240963855422e-05,
      "loss": 0.0172,
      "step": 45150
    },
    {
      "epoch": 5.440963855421686,
      "grad_norm": 11.52521800994873,
      "learning_rate": 1.4559036144578313e-05,
      "loss": 0.0755,
      "step": 45160
    },
    {
      "epoch": 5.442168674698795,
      "grad_norm": 7.396840572357178,
      "learning_rate": 1.4557831325301206e-05,
      "loss": 0.0407,
      "step": 45170
    },
    {
      "epoch": 5.443373493975904,
      "grad_norm": 0.21515454351902008,
      "learning_rate": 1.4556626506024098e-05,
      "loss": 0.0037,
      "step": 45180
    },
    {
      "epoch": 5.444578313253012,
      "grad_norm": 0.16436322033405304,
      "learning_rate": 1.4555421686746989e-05,
      "loss": 0.0569,
      "step": 45190
    },
    {
      "epoch": 5.445783132530121,
      "grad_norm": 1.8709555864334106,
      "learning_rate": 1.4554216867469881e-05,
      "loss": 0.044,
      "step": 45200
    },
    {
      "epoch": 5.446987951807229,
      "grad_norm": 0.0644335150718689,
      "learning_rate": 1.4553012048192772e-05,
      "loss": 0.0464,
      "step": 45210
    },
    {
      "epoch": 5.448192771084337,
      "grad_norm": 0.3522705137729645,
      "learning_rate": 1.4551807228915664e-05,
      "loss": 0.0653,
      "step": 45220
    },
    {
      "epoch": 5.449397590361446,
      "grad_norm": 0.5035572052001953,
      "learning_rate": 1.4550602409638555e-05,
      "loss": 0.0508,
      "step": 45230
    },
    {
      "epoch": 5.450602409638554,
      "grad_norm": 0.006273312959820032,
      "learning_rate": 1.4549397590361448e-05,
      "loss": 0.0628,
      "step": 45240
    },
    {
      "epoch": 5.451807228915663,
      "grad_norm": 3.2768075466156006,
      "learning_rate": 1.454819277108434e-05,
      "loss": 0.0387,
      "step": 45250
    },
    {
      "epoch": 5.453012048192771,
      "grad_norm": 0.0052947611548006535,
      "learning_rate": 1.454698795180723e-05,
      "loss": 0.014,
      "step": 45260
    },
    {
      "epoch": 5.45421686746988,
      "grad_norm": 0.3954281508922577,
      "learning_rate": 1.4545783132530123e-05,
      "loss": 0.0512,
      "step": 45270
    },
    {
      "epoch": 5.455421686746988,
      "grad_norm": 0.6814039349555969,
      "learning_rate": 1.4544578313253012e-05,
      "loss": 0.0752,
      "step": 45280
    },
    {
      "epoch": 5.456626506024096,
      "grad_norm": 1.2054299116134644,
      "learning_rate": 1.4543373493975905e-05,
      "loss": 0.0405,
      "step": 45290
    },
    {
      "epoch": 5.457831325301205,
      "grad_norm": 0.011536464095115662,
      "learning_rate": 1.4542168674698795e-05,
      "loss": 0.027,
      "step": 45300
    },
    {
      "epoch": 5.459036144578313,
      "grad_norm": 2.742007255554199,
      "learning_rate": 1.4540963855421688e-05,
      "loss": 0.0482,
      "step": 45310
    },
    {
      "epoch": 5.460240963855422,
      "grad_norm": 0.05612983927130699,
      "learning_rate": 1.4539759036144579e-05,
      "loss": 0.0255,
      "step": 45320
    },
    {
      "epoch": 5.46144578313253,
      "grad_norm": 0.3604790270328522,
      "learning_rate": 1.4538554216867471e-05,
      "loss": 0.012,
      "step": 45330
    },
    {
      "epoch": 5.462650602409639,
      "grad_norm": 0.0033350775483995676,
      "learning_rate": 1.4537349397590363e-05,
      "loss": 0.1194,
      "step": 45340
    },
    {
      "epoch": 5.4638554216867465,
      "grad_norm": 1.1932704448699951,
      "learning_rate": 1.4536144578313254e-05,
      "loss": 0.0128,
      "step": 45350
    },
    {
      "epoch": 5.465060240963855,
      "grad_norm": 13.722262382507324,
      "learning_rate": 1.4534939759036147e-05,
      "loss": 0.0442,
      "step": 45360
    },
    {
      "epoch": 5.466265060240964,
      "grad_norm": 0.21465535461902618,
      "learning_rate": 1.4533734939759037e-05,
      "loss": 0.0183,
      "step": 45370
    },
    {
      "epoch": 5.467469879518072,
      "grad_norm": 0.004383106250315905,
      "learning_rate": 1.453253012048193e-05,
      "loss": 0.0626,
      "step": 45380
    },
    {
      "epoch": 5.468674698795181,
      "grad_norm": 0.008216360583901405,
      "learning_rate": 1.4531325301204819e-05,
      "loss": 0.0206,
      "step": 45390
    },
    {
      "epoch": 5.469879518072289,
      "grad_norm": 1.0586893558502197,
      "learning_rate": 1.4530120481927711e-05,
      "loss": 0.0633,
      "step": 45400
    },
    {
      "epoch": 5.471084337349398,
      "grad_norm": 0.9883835315704346,
      "learning_rate": 1.4528915662650604e-05,
      "loss": 0.0516,
      "step": 45410
    },
    {
      "epoch": 5.472289156626506,
      "grad_norm": 0.005441057961434126,
      "learning_rate": 1.4527710843373494e-05,
      "loss": 0.0707,
      "step": 45420
    },
    {
      "epoch": 5.473493975903614,
      "grad_norm": 0.27821072936058044,
      "learning_rate": 1.4526506024096387e-05,
      "loss": 0.0285,
      "step": 45430
    },
    {
      "epoch": 5.474698795180723,
      "grad_norm": 0.8683229088783264,
      "learning_rate": 1.4525301204819278e-05,
      "loss": 0.0505,
      "step": 45440
    },
    {
      "epoch": 5.475903614457831,
      "grad_norm": 4.076203346252441,
      "learning_rate": 1.452409638554217e-05,
      "loss": 0.042,
      "step": 45450
    },
    {
      "epoch": 5.47710843373494,
      "grad_norm": 1.052250623703003,
      "learning_rate": 1.452289156626506e-05,
      "loss": 0.0338,
      "step": 45460
    },
    {
      "epoch": 5.478313253012049,
      "grad_norm": 0.13792784512043,
      "learning_rate": 1.4521686746987953e-05,
      "loss": 0.0241,
      "step": 45470
    },
    {
      "epoch": 5.4795180722891565,
      "grad_norm": 0.6297174096107483,
      "learning_rate": 1.4520481927710846e-05,
      "loss": 0.0256,
      "step": 45480
    },
    {
      "epoch": 5.480722891566265,
      "grad_norm": 0.14221197366714478,
      "learning_rate": 1.4519277108433736e-05,
      "loss": 0.0574,
      "step": 45490
    },
    {
      "epoch": 5.481927710843373,
      "grad_norm": 0.00911535881459713,
      "learning_rate": 1.4518072289156629e-05,
      "loss": 0.0294,
      "step": 45500
    },
    {
      "epoch": 5.483132530120482,
      "grad_norm": 0.008484452031552792,
      "learning_rate": 1.4516867469879518e-05,
      "loss": 0.0201,
      "step": 45510
    },
    {
      "epoch": 5.48433734939759,
      "grad_norm": 0.005467952694743872,
      "learning_rate": 1.4515662650602412e-05,
      "loss": 0.0149,
      "step": 45520
    },
    {
      "epoch": 5.485542168674699,
      "grad_norm": 0.05883920192718506,
      "learning_rate": 1.4514457831325301e-05,
      "loss": 0.02,
      "step": 45530
    },
    {
      "epoch": 5.486746987951808,
      "grad_norm": 0.005496529396623373,
      "learning_rate": 1.4513253012048193e-05,
      "loss": 0.0211,
      "step": 45540
    },
    {
      "epoch": 5.4879518072289155,
      "grad_norm": 0.006109995301812887,
      "learning_rate": 1.4512048192771086e-05,
      "loss": 0.034,
      "step": 45550
    },
    {
      "epoch": 5.489156626506024,
      "grad_norm": 0.03341806307435036,
      "learning_rate": 1.4510843373493977e-05,
      "loss": 0.0396,
      "step": 45560
    },
    {
      "epoch": 5.490361445783132,
      "grad_norm": 0.21535027027130127,
      "learning_rate": 1.4509638554216869e-05,
      "loss": 0.0655,
      "step": 45570
    },
    {
      "epoch": 5.491566265060241,
      "grad_norm": 12.902837753295898,
      "learning_rate": 1.450843373493976e-05,
      "loss": 0.1259,
      "step": 45580
    },
    {
      "epoch": 5.492771084337349,
      "grad_norm": 0.06045201048254967,
      "learning_rate": 1.4507228915662652e-05,
      "loss": 0.0097,
      "step": 45590
    },
    {
      "epoch": 5.493975903614458,
      "grad_norm": 2.284515857696533,
      "learning_rate": 1.4506024096385543e-05,
      "loss": 0.0467,
      "step": 45600
    },
    {
      "epoch": 5.495180722891567,
      "grad_norm": 0.04508298635482788,
      "learning_rate": 1.4504819277108435e-05,
      "loss": 0.0385,
      "step": 45610
    },
    {
      "epoch": 5.4963855421686745,
      "grad_norm": 0.16586291790008545,
      "learning_rate": 1.4503614457831326e-05,
      "loss": 0.0121,
      "step": 45620
    },
    {
      "epoch": 5.497590361445783,
      "grad_norm": 1.3580453395843506,
      "learning_rate": 1.4502409638554219e-05,
      "loss": 0.0482,
      "step": 45630
    },
    {
      "epoch": 5.498795180722891,
      "grad_norm": 0.09647584706544876,
      "learning_rate": 1.4501204819277111e-05,
      "loss": 0.0254,
      "step": 45640
    },
    {
      "epoch": 5.5,
      "grad_norm": 5.36904239654541,
      "learning_rate": 1.45e-05,
      "loss": 0.0551,
      "step": 45650
    },
    {
      "epoch": 5.501204819277109,
      "grad_norm": 0.1785300225019455,
      "learning_rate": 1.4498795180722893e-05,
      "loss": 0.0336,
      "step": 45660
    },
    {
      "epoch": 5.502409638554217,
      "grad_norm": 2.706904411315918,
      "learning_rate": 1.4497590361445783e-05,
      "loss": 0.0919,
      "step": 45670
    },
    {
      "epoch": 5.5036144578313255,
      "grad_norm": 0.25793197751045227,
      "learning_rate": 1.4496385542168676e-05,
      "loss": 0.0696,
      "step": 45680
    },
    {
      "epoch": 5.504819277108433,
      "grad_norm": 0.15574760735034943,
      "learning_rate": 1.4495180722891566e-05,
      "loss": 0.0095,
      "step": 45690
    },
    {
      "epoch": 5.506024096385542,
      "grad_norm": 0.018866125494241714,
      "learning_rate": 1.4493975903614459e-05,
      "loss": 0.0141,
      "step": 45700
    },
    {
      "epoch": 5.507228915662651,
      "grad_norm": 8.23272705078125,
      "learning_rate": 1.4492771084337351e-05,
      "loss": 0.0753,
      "step": 45710
    },
    {
      "epoch": 5.508433734939759,
      "grad_norm": 0.07541849464178085,
      "learning_rate": 1.4491566265060242e-05,
      "loss": 0.0704,
      "step": 45720
    },
    {
      "epoch": 5.509638554216868,
      "grad_norm": 0.2961575984954834,
      "learning_rate": 1.4490361445783134e-05,
      "loss": 0.0566,
      "step": 45730
    },
    {
      "epoch": 5.510843373493976,
      "grad_norm": 1.9081755876541138,
      "learning_rate": 1.4489156626506025e-05,
      "loss": 0.0727,
      "step": 45740
    },
    {
      "epoch": 5.5120481927710845,
      "grad_norm": 32.442359924316406,
      "learning_rate": 1.4487951807228918e-05,
      "loss": 0.0322,
      "step": 45750
    },
    {
      "epoch": 5.513253012048192,
      "grad_norm": 7.749317646026611,
      "learning_rate": 1.4486746987951807e-05,
      "loss": 0.0329,
      "step": 45760
    },
    {
      "epoch": 5.514457831325301,
      "grad_norm": 10.00147533416748,
      "learning_rate": 1.4485542168674699e-05,
      "loss": 0.0578,
      "step": 45770
    },
    {
      "epoch": 5.51566265060241,
      "grad_norm": 0.7953932881355286,
      "learning_rate": 1.4484337349397593e-05,
      "loss": 0.0204,
      "step": 45780
    },
    {
      "epoch": 5.516867469879518,
      "grad_norm": 0.005143546033650637,
      "learning_rate": 1.4483132530120482e-05,
      "loss": 0.0233,
      "step": 45790
    },
    {
      "epoch": 5.518072289156627,
      "grad_norm": 0.10047511011362076,
      "learning_rate": 1.4481927710843375e-05,
      "loss": 0.0106,
      "step": 45800
    },
    {
      "epoch": 5.519277108433735,
      "grad_norm": 6.588116645812988,
      "learning_rate": 1.4480722891566265e-05,
      "loss": 0.0725,
      "step": 45810
    },
    {
      "epoch": 5.5204819277108435,
      "grad_norm": 2.223883628845215,
      "learning_rate": 1.4479518072289158e-05,
      "loss": 0.0726,
      "step": 45820
    },
    {
      "epoch": 5.521686746987951,
      "grad_norm": 4.491575241088867,
      "learning_rate": 1.4478313253012049e-05,
      "loss": 0.0359,
      "step": 45830
    },
    {
      "epoch": 5.52289156626506,
      "grad_norm": 9.88464069366455,
      "learning_rate": 1.4477108433734941e-05,
      "loss": 0.0713,
      "step": 45840
    },
    {
      "epoch": 5.524096385542169,
      "grad_norm": 0.402596652507782,
      "learning_rate": 1.4475903614457834e-05,
      "loss": 0.0736,
      "step": 45850
    },
    {
      "epoch": 5.525301204819277,
      "grad_norm": 0.3861977756023407,
      "learning_rate": 1.4474698795180724e-05,
      "loss": 0.0362,
      "step": 45860
    },
    {
      "epoch": 5.526506024096386,
      "grad_norm": 14.532723426818848,
      "learning_rate": 1.4473493975903617e-05,
      "loss": 0.0907,
      "step": 45870
    },
    {
      "epoch": 5.527710843373494,
      "grad_norm": 0.10415083914995193,
      "learning_rate": 1.4472289156626507e-05,
      "loss": 0.0185,
      "step": 45880
    },
    {
      "epoch": 5.528915662650602,
      "grad_norm": 0.4151499271392822,
      "learning_rate": 1.44710843373494e-05,
      "loss": 0.085,
      "step": 45890
    },
    {
      "epoch": 5.530120481927711,
      "grad_norm": 0.13550497591495514,
      "learning_rate": 1.4469879518072289e-05,
      "loss": 0.0313,
      "step": 45900
    },
    {
      "epoch": 5.531325301204819,
      "grad_norm": 0.965694010257721,
      "learning_rate": 1.4468674698795181e-05,
      "loss": 0.0472,
      "step": 45910
    },
    {
      "epoch": 5.532530120481928,
      "grad_norm": 0.04726136103272438,
      "learning_rate": 1.4467469879518074e-05,
      "loss": 0.0207,
      "step": 45920
    },
    {
      "epoch": 5.533734939759036,
      "grad_norm": 0.5218355655670166,
      "learning_rate": 1.4466265060240965e-05,
      "loss": 0.0209,
      "step": 45930
    },
    {
      "epoch": 5.534939759036145,
      "grad_norm": 0.06636536121368408,
      "learning_rate": 1.4465060240963857e-05,
      "loss": 0.0233,
      "step": 45940
    },
    {
      "epoch": 5.5361445783132535,
      "grad_norm": 8.513976097106934,
      "learning_rate": 1.4463855421686748e-05,
      "loss": 0.0429,
      "step": 45950
    },
    {
      "epoch": 5.537349397590361,
      "grad_norm": 0.12800730764865875,
      "learning_rate": 1.446265060240964e-05,
      "loss": 0.0266,
      "step": 45960
    },
    {
      "epoch": 5.53855421686747,
      "grad_norm": 4.786098480224609,
      "learning_rate": 1.4461445783132531e-05,
      "loss": 0.1033,
      "step": 45970
    },
    {
      "epoch": 5.539759036144578,
      "grad_norm": 1.3101661205291748,
      "learning_rate": 1.4460240963855423e-05,
      "loss": 0.0161,
      "step": 45980
    },
    {
      "epoch": 5.540963855421687,
      "grad_norm": 0.07222606241703033,
      "learning_rate": 1.4459036144578314e-05,
      "loss": 0.0645,
      "step": 45990
    },
    {
      "epoch": 5.542168674698795,
      "grad_norm": 0.11174754798412323,
      "learning_rate": 1.4457831325301207e-05,
      "loss": 0.0584,
      "step": 46000
    },
    {
      "epoch": 5.543373493975904,
      "grad_norm": 0.6134305000305176,
      "learning_rate": 1.4456626506024099e-05,
      "loss": 0.0144,
      "step": 46010
    },
    {
      "epoch": 5.544578313253012,
      "grad_norm": 11.307615280151367,
      "learning_rate": 1.4455421686746988e-05,
      "loss": 0.0287,
      "step": 46020
    },
    {
      "epoch": 5.54578313253012,
      "grad_norm": 8.684660911560059,
      "learning_rate": 1.4454216867469882e-05,
      "loss": 0.0965,
      "step": 46030
    },
    {
      "epoch": 5.546987951807229,
      "grad_norm": 0.09063196182250977,
      "learning_rate": 1.4453012048192771e-05,
      "loss": 0.073,
      "step": 46040
    },
    {
      "epoch": 5.548192771084337,
      "grad_norm": 0.1159743145108223,
      "learning_rate": 1.4451807228915664e-05,
      "loss": 0.057,
      "step": 46050
    },
    {
      "epoch": 5.549397590361446,
      "grad_norm": 2.2054555416107178,
      "learning_rate": 1.4450602409638554e-05,
      "loss": 0.0608,
      "step": 46060
    },
    {
      "epoch": 5.550602409638554,
      "grad_norm": 0.07827452570199966,
      "learning_rate": 1.4449397590361447e-05,
      "loss": 0.0953,
      "step": 46070
    },
    {
      "epoch": 5.551807228915663,
      "grad_norm": 8.440387725830078,
      "learning_rate": 1.444819277108434e-05,
      "loss": 0.0409,
      "step": 46080
    },
    {
      "epoch": 5.553012048192771,
      "grad_norm": 16.424407958984375,
      "learning_rate": 1.444698795180723e-05,
      "loss": 0.0481,
      "step": 46090
    },
    {
      "epoch": 5.554216867469879,
      "grad_norm": 5.7582831382751465,
      "learning_rate": 1.4445783132530122e-05,
      "loss": 0.0223,
      "step": 46100
    },
    {
      "epoch": 5.555421686746988,
      "grad_norm": 0.20485644042491913,
      "learning_rate": 1.4444578313253013e-05,
      "loss": 0.0816,
      "step": 46110
    },
    {
      "epoch": 5.556626506024096,
      "grad_norm": 19.546537399291992,
      "learning_rate": 1.4443373493975906e-05,
      "loss": 0.0412,
      "step": 46120
    },
    {
      "epoch": 5.557831325301205,
      "grad_norm": 3.8256595134735107,
      "learning_rate": 1.4442168674698796e-05,
      "loss": 0.0233,
      "step": 46130
    },
    {
      "epoch": 5.559036144578314,
      "grad_norm": 0.08408324420452118,
      "learning_rate": 1.4440963855421689e-05,
      "loss": 0.0844,
      "step": 46140
    },
    {
      "epoch": 5.5602409638554215,
      "grad_norm": 0.22954677045345306,
      "learning_rate": 1.4439759036144581e-05,
      "loss": 0.0273,
      "step": 46150
    },
    {
      "epoch": 5.56144578313253,
      "grad_norm": 7.037965774536133,
      "learning_rate": 1.443855421686747e-05,
      "loss": 0.0676,
      "step": 46160
    },
    {
      "epoch": 5.562650602409638,
      "grad_norm": 5.086587429046631,
      "learning_rate": 1.4437349397590363e-05,
      "loss": 0.0245,
      "step": 46170
    },
    {
      "epoch": 5.563855421686747,
      "grad_norm": 6.255030632019043,
      "learning_rate": 1.4436144578313253e-05,
      "loss": 0.0768,
      "step": 46180
    },
    {
      "epoch": 5.565060240963856,
      "grad_norm": 0.12042733281850815,
      "learning_rate": 1.4434939759036146e-05,
      "loss": 0.0471,
      "step": 46190
    },
    {
      "epoch": 5.566265060240964,
      "grad_norm": 0.2302308827638626,
      "learning_rate": 1.4433734939759037e-05,
      "loss": 0.0246,
      "step": 46200
    },
    {
      "epoch": 5.567469879518073,
      "grad_norm": 5.636494159698486,
      "learning_rate": 1.4432530120481929e-05,
      "loss": 0.0658,
      "step": 46210
    },
    {
      "epoch": 5.5686746987951805,
      "grad_norm": 2.569167375564575,
      "learning_rate": 1.4431325301204821e-05,
      "loss": 0.0259,
      "step": 46220
    },
    {
      "epoch": 5.569879518072289,
      "grad_norm": 0.14478783309459686,
      "learning_rate": 1.4430120481927712e-05,
      "loss": 0.0312,
      "step": 46230
    },
    {
      "epoch": 5.571084337349397,
      "grad_norm": 0.2660558819770813,
      "learning_rate": 1.4428915662650605e-05,
      "loss": 0.0633,
      "step": 46240
    },
    {
      "epoch": 5.572289156626506,
      "grad_norm": 0.7865092754364014,
      "learning_rate": 1.4427710843373495e-05,
      "loss": 0.0157,
      "step": 46250
    },
    {
      "epoch": 5.573493975903615,
      "grad_norm": 0.005194378085434437,
      "learning_rate": 1.4426506024096388e-05,
      "loss": 0.0203,
      "step": 46260
    },
    {
      "epoch": 5.574698795180723,
      "grad_norm": 0.11451643705368042,
      "learning_rate": 1.4425301204819277e-05,
      "loss": 0.0558,
      "step": 46270
    },
    {
      "epoch": 5.575903614457832,
      "grad_norm": 0.05584383383393288,
      "learning_rate": 1.442409638554217e-05,
      "loss": 0.0537,
      "step": 46280
    },
    {
      "epoch": 5.5771084337349395,
      "grad_norm": 2.0382652282714844,
      "learning_rate": 1.442289156626506e-05,
      "loss": 0.0468,
      "step": 46290
    },
    {
      "epoch": 5.578313253012048,
      "grad_norm": 1.2443289756774902,
      "learning_rate": 1.4421686746987952e-05,
      "loss": 0.0466,
      "step": 46300
    },
    {
      "epoch": 5.579518072289156,
      "grad_norm": 0.008007415570318699,
      "learning_rate": 1.4420481927710845e-05,
      "loss": 0.0432,
      "step": 46310
    },
    {
      "epoch": 5.580722891566265,
      "grad_norm": 0.5780906677246094,
      "learning_rate": 1.4419277108433736e-05,
      "loss": 0.0872,
      "step": 46320
    },
    {
      "epoch": 5.581927710843374,
      "grad_norm": 0.07097097486257553,
      "learning_rate": 1.4418072289156628e-05,
      "loss": 0.0544,
      "step": 46330
    },
    {
      "epoch": 5.583132530120482,
      "grad_norm": 0.049294330179691315,
      "learning_rate": 1.4416867469879519e-05,
      "loss": 0.0392,
      "step": 46340
    },
    {
      "epoch": 5.5843373493975905,
      "grad_norm": 0.05464315414428711,
      "learning_rate": 1.4415662650602411e-05,
      "loss": 0.0546,
      "step": 46350
    },
    {
      "epoch": 5.585542168674698,
      "grad_norm": 2.010246515274048,
      "learning_rate": 1.4414457831325302e-05,
      "loss": 0.0489,
      "step": 46360
    },
    {
      "epoch": 5.586746987951807,
      "grad_norm": 0.0155748650431633,
      "learning_rate": 1.4413253012048194e-05,
      "loss": 0.0217,
      "step": 46370
    },
    {
      "epoch": 5.587951807228916,
      "grad_norm": 0.29078835248947144,
      "learning_rate": 1.4412048192771087e-05,
      "loss": 0.0642,
      "step": 46380
    },
    {
      "epoch": 5.589156626506024,
      "grad_norm": 0.00896124541759491,
      "learning_rate": 1.4410843373493978e-05,
      "loss": 0.0176,
      "step": 46390
    },
    {
      "epoch": 5.590361445783133,
      "grad_norm": 0.3144010901451111,
      "learning_rate": 1.440963855421687e-05,
      "loss": 0.023,
      "step": 46400
    },
    {
      "epoch": 5.591566265060241,
      "grad_norm": 0.02614552527666092,
      "learning_rate": 1.4408433734939759e-05,
      "loss": 0.0807,
      "step": 46410
    },
    {
      "epoch": 5.5927710843373495,
      "grad_norm": 0.423317551612854,
      "learning_rate": 1.4407228915662652e-05,
      "loss": 0.0099,
      "step": 46420
    },
    {
      "epoch": 5.593975903614458,
      "grad_norm": 0.012505068443715572,
      "learning_rate": 1.4406024096385542e-05,
      "loss": 0.0666,
      "step": 46430
    },
    {
      "epoch": 5.595180722891566,
      "grad_norm": 7.064083576202393,
      "learning_rate": 1.4404819277108435e-05,
      "loss": 0.1003,
      "step": 46440
    },
    {
      "epoch": 5.596385542168675,
      "grad_norm": 1.8503493070602417,
      "learning_rate": 1.4403614457831327e-05,
      "loss": 0.0873,
      "step": 46450
    },
    {
      "epoch": 5.597590361445783,
      "grad_norm": 1.863913655281067,
      "learning_rate": 1.4402409638554218e-05,
      "loss": 0.0725,
      "step": 46460
    },
    {
      "epoch": 5.598795180722892,
      "grad_norm": 4.280461311340332,
      "learning_rate": 1.440120481927711e-05,
      "loss": 0.0547,
      "step": 46470
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.20023499429225922,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.0301,
      "step": 46480
    },
    {
      "epoch": 5.6012048192771084,
      "grad_norm": 0.7047355771064758,
      "learning_rate": 1.4398795180722893e-05,
      "loss": 0.0502,
      "step": 46490
    },
    {
      "epoch": 5.602409638554217,
      "grad_norm": 0.07362109422683716,
      "learning_rate": 1.4397590361445784e-05,
      "loss": 0.0617,
      "step": 46500
    },
    {
      "epoch": 5.603614457831325,
      "grad_norm": 1.3461352586746216,
      "learning_rate": 1.4396385542168677e-05,
      "loss": 0.0215,
      "step": 46510
    },
    {
      "epoch": 5.604819277108434,
      "grad_norm": 6.153625011444092,
      "learning_rate": 1.4395180722891569e-05,
      "loss": 0.0462,
      "step": 46520
    },
    {
      "epoch": 5.606024096385542,
      "grad_norm": 0.3945268392562866,
      "learning_rate": 1.4393975903614458e-05,
      "loss": 0.0507,
      "step": 46530
    },
    {
      "epoch": 5.607228915662651,
      "grad_norm": 3.9020237922668457,
      "learning_rate": 1.439277108433735e-05,
      "loss": 0.0706,
      "step": 46540
    },
    {
      "epoch": 5.608433734939759,
      "grad_norm": 0.03008856065571308,
      "learning_rate": 1.4391566265060241e-05,
      "loss": 0.0135,
      "step": 46550
    },
    {
      "epoch": 5.609638554216867,
      "grad_norm": 1.238249659538269,
      "learning_rate": 1.4390361445783134e-05,
      "loss": 0.0788,
      "step": 46560
    },
    {
      "epoch": 5.610843373493976,
      "grad_norm": 0.6858855485916138,
      "learning_rate": 1.4389156626506024e-05,
      "loss": 0.0296,
      "step": 46570
    },
    {
      "epoch": 5.612048192771084,
      "grad_norm": 22.008209228515625,
      "learning_rate": 1.4387951807228917e-05,
      "loss": 0.1284,
      "step": 46580
    },
    {
      "epoch": 5.613253012048193,
      "grad_norm": 3.629795551300049,
      "learning_rate": 1.4386746987951808e-05,
      "loss": 0.0418,
      "step": 46590
    },
    {
      "epoch": 5.614457831325301,
      "grad_norm": 2.074028730392456,
      "learning_rate": 1.43855421686747e-05,
      "loss": 0.0328,
      "step": 46600
    },
    {
      "epoch": 5.61566265060241,
      "grad_norm": 0.22350694239139557,
      "learning_rate": 1.4384337349397593e-05,
      "loss": 0.0297,
      "step": 46610
    },
    {
      "epoch": 5.6168674698795185,
      "grad_norm": 2.142806053161621,
      "learning_rate": 1.4383132530120483e-05,
      "loss": 0.0263,
      "step": 46620
    },
    {
      "epoch": 5.618072289156626,
      "grad_norm": 0.4525637626647949,
      "learning_rate": 1.4381927710843376e-05,
      "loss": 0.0256,
      "step": 46630
    },
    {
      "epoch": 5.619277108433735,
      "grad_norm": 2.7714521884918213,
      "learning_rate": 1.4380722891566265e-05,
      "loss": 0.0935,
      "step": 46640
    },
    {
      "epoch": 5.620481927710843,
      "grad_norm": 1.6477949619293213,
      "learning_rate": 1.4379518072289159e-05,
      "loss": 0.015,
      "step": 46650
    },
    {
      "epoch": 5.621686746987952,
      "grad_norm": 1.5642173290252686,
      "learning_rate": 1.4378313253012048e-05,
      "loss": 0.0551,
      "step": 46660
    },
    {
      "epoch": 5.622891566265061,
      "grad_norm": 0.23451422154903412,
      "learning_rate": 1.437710843373494e-05,
      "loss": 0.0576,
      "step": 46670
    },
    {
      "epoch": 5.624096385542169,
      "grad_norm": 1.3925256729125977,
      "learning_rate": 1.4375903614457833e-05,
      "loss": 0.0918,
      "step": 46680
    },
    {
      "epoch": 5.625301204819277,
      "grad_norm": 0.07209029793739319,
      "learning_rate": 1.4374698795180724e-05,
      "loss": 0.0372,
      "step": 46690
    },
    {
      "epoch": 5.626506024096385,
      "grad_norm": 0.5493795275688171,
      "learning_rate": 1.4373493975903616e-05,
      "loss": 0.0256,
      "step": 46700
    },
    {
      "epoch": 5.627710843373494,
      "grad_norm": 0.02963637188076973,
      "learning_rate": 1.4372289156626507e-05,
      "loss": 0.0374,
      "step": 46710
    },
    {
      "epoch": 5.628915662650602,
      "grad_norm": 0.015097849071025848,
      "learning_rate": 1.43710843373494e-05,
      "loss": 0.0458,
      "step": 46720
    },
    {
      "epoch": 5.630120481927711,
      "grad_norm": 0.10369082540273666,
      "learning_rate": 1.436987951807229e-05,
      "loss": 0.0438,
      "step": 46730
    },
    {
      "epoch": 5.63132530120482,
      "grad_norm": 0.06578067690134048,
      "learning_rate": 1.4368674698795182e-05,
      "loss": 0.0324,
      "step": 46740
    },
    {
      "epoch": 5.632530120481928,
      "grad_norm": 0.11357913166284561,
      "learning_rate": 1.4367469879518075e-05,
      "loss": 0.0644,
      "step": 46750
    },
    {
      "epoch": 5.633734939759036,
      "grad_norm": 0.444713830947876,
      "learning_rate": 1.4366265060240966e-05,
      "loss": 0.024,
      "step": 46760
    },
    {
      "epoch": 5.634939759036144,
      "grad_norm": 0.013141797855496407,
      "learning_rate": 1.4365060240963858e-05,
      "loss": 0.0431,
      "step": 46770
    },
    {
      "epoch": 5.636144578313253,
      "grad_norm": 0.02209043875336647,
      "learning_rate": 1.4363855421686747e-05,
      "loss": 0.0255,
      "step": 46780
    },
    {
      "epoch": 5.637349397590361,
      "grad_norm": 0.03114808164536953,
      "learning_rate": 1.436265060240964e-05,
      "loss": 0.0201,
      "step": 46790
    },
    {
      "epoch": 5.63855421686747,
      "grad_norm": 0.20030391216278076,
      "learning_rate": 1.436144578313253e-05,
      "loss": 0.0589,
      "step": 46800
    },
    {
      "epoch": 5.639759036144579,
      "grad_norm": 0.02881588228046894,
      "learning_rate": 1.4360240963855423e-05,
      "loss": 0.0543,
      "step": 46810
    },
    {
      "epoch": 5.6409638554216865,
      "grad_norm": 3.271543025970459,
      "learning_rate": 1.4359036144578315e-05,
      "loss": 0.0382,
      "step": 46820
    },
    {
      "epoch": 5.642168674698795,
      "grad_norm": 4.105895042419434,
      "learning_rate": 1.4357831325301206e-05,
      "loss": 0.0654,
      "step": 46830
    },
    {
      "epoch": 5.643373493975903,
      "grad_norm": 1.7550204992294312,
      "learning_rate": 1.4356626506024098e-05,
      "loss": 0.0551,
      "step": 46840
    },
    {
      "epoch": 5.644578313253012,
      "grad_norm": 9.74010181427002,
      "learning_rate": 1.4355421686746989e-05,
      "loss": 0.0507,
      "step": 46850
    },
    {
      "epoch": 5.64578313253012,
      "grad_norm": 1.4324026107788086,
      "learning_rate": 1.4354216867469881e-05,
      "loss": 0.0124,
      "step": 46860
    },
    {
      "epoch": 5.646987951807229,
      "grad_norm": 3.547208547592163,
      "learning_rate": 1.4353012048192772e-05,
      "loss": 0.0699,
      "step": 46870
    },
    {
      "epoch": 5.648192771084338,
      "grad_norm": 0.936625599861145,
      "learning_rate": 1.4351807228915665e-05,
      "loss": 0.0284,
      "step": 46880
    },
    {
      "epoch": 5.6493975903614455,
      "grad_norm": 0.48197752237319946,
      "learning_rate": 1.4350602409638554e-05,
      "loss": 0.0038,
      "step": 46890
    },
    {
      "epoch": 5.650602409638554,
      "grad_norm": 0.006049636285752058,
      "learning_rate": 1.4349397590361446e-05,
      "loss": 0.0533,
      "step": 46900
    },
    {
      "epoch": 5.651807228915663,
      "grad_norm": 0.006256795953959227,
      "learning_rate": 1.434819277108434e-05,
      "loss": 0.0308,
      "step": 46910
    },
    {
      "epoch": 5.653012048192771,
      "grad_norm": 0.19021449983119965,
      "learning_rate": 1.434698795180723e-05,
      "loss": 0.022,
      "step": 46920
    },
    {
      "epoch": 5.65421686746988,
      "grad_norm": 0.0053818002343177795,
      "learning_rate": 1.4345783132530122e-05,
      "loss": 0.0596,
      "step": 46930
    },
    {
      "epoch": 5.655421686746988,
      "grad_norm": 0.07256076484918594,
      "learning_rate": 1.4344578313253012e-05,
      "loss": 0.1349,
      "step": 46940
    },
    {
      "epoch": 5.656626506024097,
      "grad_norm": 0.016659129410982132,
      "learning_rate": 1.4343373493975905e-05,
      "loss": 0.0274,
      "step": 46950
    },
    {
      "epoch": 5.6578313253012045,
      "grad_norm": 0.07002940773963928,
      "learning_rate": 1.4342168674698796e-05,
      "loss": 0.0046,
      "step": 46960
    },
    {
      "epoch": 5.659036144578313,
      "grad_norm": 7.387669563293457,
      "learning_rate": 1.4340963855421688e-05,
      "loss": 0.0559,
      "step": 46970
    },
    {
      "epoch": 5.660240963855422,
      "grad_norm": 0.23359408974647522,
      "learning_rate": 1.433975903614458e-05,
      "loss": 0.0724,
      "step": 46980
    },
    {
      "epoch": 5.66144578313253,
      "grad_norm": 0.09725726395845413,
      "learning_rate": 1.4338554216867471e-05,
      "loss": 0.0298,
      "step": 46990
    },
    {
      "epoch": 5.662650602409639,
      "grad_norm": 2.683410882949829,
      "learning_rate": 1.4337349397590364e-05,
      "loss": 0.071,
      "step": 47000
    },
    {
      "epoch": 5.663855421686747,
      "grad_norm": 2.618736982345581,
      "learning_rate": 1.4336144578313254e-05,
      "loss": 0.0334,
      "step": 47010
    },
    {
      "epoch": 5.6650602409638555,
      "grad_norm": 0.2088892012834549,
      "learning_rate": 1.4334939759036147e-05,
      "loss": 0.0724,
      "step": 47020
    },
    {
      "epoch": 5.666265060240963,
      "grad_norm": 1.629404902458191,
      "learning_rate": 1.4333734939759036e-05,
      "loss": 0.0282,
      "step": 47030
    },
    {
      "epoch": 5.667469879518072,
      "grad_norm": 0.026912862434983253,
      "learning_rate": 1.4332530120481928e-05,
      "loss": 0.0364,
      "step": 47040
    },
    {
      "epoch": 5.668674698795181,
      "grad_norm": 0.5926398634910583,
      "learning_rate": 1.433132530120482e-05,
      "loss": 0.0099,
      "step": 47050
    },
    {
      "epoch": 5.669879518072289,
      "grad_norm": 4.593282222747803,
      "learning_rate": 1.4330120481927711e-05,
      "loss": 0.0893,
      "step": 47060
    },
    {
      "epoch": 5.671084337349398,
      "grad_norm": 0.03998292237520218,
      "learning_rate": 1.4328915662650604e-05,
      "loss": 0.0549,
      "step": 47070
    },
    {
      "epoch": 5.672289156626506,
      "grad_norm": 0.3689033091068268,
      "learning_rate": 1.4327710843373495e-05,
      "loss": 0.0145,
      "step": 47080
    },
    {
      "epoch": 5.6734939759036145,
      "grad_norm": 6.022726058959961,
      "learning_rate": 1.4326506024096387e-05,
      "loss": 0.0344,
      "step": 47090
    },
    {
      "epoch": 5.674698795180722,
      "grad_norm": 0.22174891829490662,
      "learning_rate": 1.4325301204819278e-05,
      "loss": 0.0132,
      "step": 47100
    },
    {
      "epoch": 5.675903614457831,
      "grad_norm": 0.05352650582790375,
      "learning_rate": 1.432409638554217e-05,
      "loss": 0.0131,
      "step": 47110
    },
    {
      "epoch": 5.67710843373494,
      "grad_norm": 1.1138534545898438,
      "learning_rate": 1.4322891566265063e-05,
      "loss": 0.0289,
      "step": 47120
    },
    {
      "epoch": 5.678313253012048,
      "grad_norm": 0.13540445268154144,
      "learning_rate": 1.4321686746987953e-05,
      "loss": 0.0698,
      "step": 47130
    },
    {
      "epoch": 5.679518072289157,
      "grad_norm": 0.11940793693065643,
      "learning_rate": 1.4320481927710846e-05,
      "loss": 0.0257,
      "step": 47140
    },
    {
      "epoch": 5.6807228915662655,
      "grad_norm": 0.409625768661499,
      "learning_rate": 1.4319277108433735e-05,
      "loss": 0.0191,
      "step": 47150
    },
    {
      "epoch": 5.6819277108433734,
      "grad_norm": 0.016595885157585144,
      "learning_rate": 1.4318072289156627e-05,
      "loss": 0.0504,
      "step": 47160
    },
    {
      "epoch": 5.683132530120482,
      "grad_norm": 13.302750587463379,
      "learning_rate": 1.4316867469879518e-05,
      "loss": 0.059,
      "step": 47170
    },
    {
      "epoch": 5.68433734939759,
      "grad_norm": 1.5209208726882935,
      "learning_rate": 1.431566265060241e-05,
      "loss": 0.0897,
      "step": 47180
    },
    {
      "epoch": 5.685542168674699,
      "grad_norm": 1.0433995723724365,
      "learning_rate": 1.4314457831325301e-05,
      "loss": 0.0269,
      "step": 47190
    },
    {
      "epoch": 5.686746987951807,
      "grad_norm": 0.16228929162025452,
      "learning_rate": 1.4313253012048194e-05,
      "loss": 0.0443,
      "step": 47200
    },
    {
      "epoch": 5.687951807228916,
      "grad_norm": 0.9374737739562988,
      "learning_rate": 1.4312048192771086e-05,
      "loss": 0.032,
      "step": 47210
    },
    {
      "epoch": 5.6891566265060245,
      "grad_norm": 1.1519263982772827,
      "learning_rate": 1.4310843373493977e-05,
      "loss": 0.0301,
      "step": 47220
    },
    {
      "epoch": 5.690361445783132,
      "grad_norm": 7.692883014678955,
      "learning_rate": 1.430963855421687e-05,
      "loss": 0.0864,
      "step": 47230
    },
    {
      "epoch": 5.691566265060241,
      "grad_norm": 0.4109978675842285,
      "learning_rate": 1.430843373493976e-05,
      "loss": 0.0725,
      "step": 47240
    },
    {
      "epoch": 5.692771084337349,
      "grad_norm": 1.07700777053833,
      "learning_rate": 1.4307228915662652e-05,
      "loss": 0.0447,
      "step": 47250
    },
    {
      "epoch": 5.693975903614458,
      "grad_norm": 2.9941487312316895,
      "learning_rate": 1.4306024096385542e-05,
      "loss": 0.0113,
      "step": 47260
    },
    {
      "epoch": 5.695180722891566,
      "grad_norm": 0.03531217575073242,
      "learning_rate": 1.4304819277108436e-05,
      "loss": 0.0556,
      "step": 47270
    },
    {
      "epoch": 5.696385542168675,
      "grad_norm": 2.0036282539367676,
      "learning_rate": 1.4303614457831328e-05,
      "loss": 0.0514,
      "step": 47280
    },
    {
      "epoch": 5.6975903614457835,
      "grad_norm": 7.655682563781738,
      "learning_rate": 1.4302409638554217e-05,
      "loss": 0.0274,
      "step": 47290
    },
    {
      "epoch": 5.698795180722891,
      "grad_norm": 0.016358209773898125,
      "learning_rate": 1.430120481927711e-05,
      "loss": 0.0455,
      "step": 47300
    },
    {
      "epoch": 5.7,
      "grad_norm": 23.578338623046875,
      "learning_rate": 1.43e-05,
      "loss": 0.0976,
      "step": 47310
    },
    {
      "epoch": 5.701204819277108,
      "grad_norm": 0.2860700190067291,
      "learning_rate": 1.4298795180722893e-05,
      "loss": 0.0181,
      "step": 47320
    },
    {
      "epoch": 5.702409638554217,
      "grad_norm": 68.59149169921875,
      "learning_rate": 1.4297590361445783e-05,
      "loss": 0.0661,
      "step": 47330
    },
    {
      "epoch": 5.703614457831325,
      "grad_norm": 1.6503489017486572,
      "learning_rate": 1.4296385542168676e-05,
      "loss": 0.0319,
      "step": 47340
    },
    {
      "epoch": 5.704819277108434,
      "grad_norm": 0.9839407205581665,
      "learning_rate": 1.4295180722891568e-05,
      "loss": 0.0315,
      "step": 47350
    },
    {
      "epoch": 5.706024096385542,
      "grad_norm": 0.35722577571868896,
      "learning_rate": 1.4293975903614459e-05,
      "loss": 0.0097,
      "step": 47360
    },
    {
      "epoch": 5.70722891566265,
      "grad_norm": 12.370797157287598,
      "learning_rate": 1.4292771084337352e-05,
      "loss": 0.0565,
      "step": 47370
    },
    {
      "epoch": 5.708433734939759,
      "grad_norm": 0.1543159782886505,
      "learning_rate": 1.4291566265060242e-05,
      "loss": 0.079,
      "step": 47380
    },
    {
      "epoch": 5.709638554216868,
      "grad_norm": 0.05687146633863449,
      "learning_rate": 1.4290361445783135e-05,
      "loss": 0.0417,
      "step": 47390
    },
    {
      "epoch": 5.710843373493976,
      "grad_norm": 0.45050737261772156,
      "learning_rate": 1.4289156626506024e-05,
      "loss": 0.04,
      "step": 47400
    },
    {
      "epoch": 5.712048192771085,
      "grad_norm": 1.8245680332183838,
      "learning_rate": 1.4287951807228916e-05,
      "loss": 0.052,
      "step": 47410
    },
    {
      "epoch": 5.713253012048193,
      "grad_norm": 0.022595878690481186,
      "learning_rate": 1.428674698795181e-05,
      "loss": 0.0283,
      "step": 47420
    },
    {
      "epoch": 5.714457831325301,
      "grad_norm": 9.759675979614258,
      "learning_rate": 1.42855421686747e-05,
      "loss": 0.0287,
      "step": 47430
    },
    {
      "epoch": 5.715662650602409,
      "grad_norm": 1.2496721744537354,
      "learning_rate": 1.4284337349397592e-05,
      "loss": 0.1386,
      "step": 47440
    },
    {
      "epoch": 5.716867469879518,
      "grad_norm": 9.168049812316895,
      "learning_rate": 1.4283132530120483e-05,
      "loss": 0.0504,
      "step": 47450
    },
    {
      "epoch": 5.718072289156627,
      "grad_norm": 0.5973721146583557,
      "learning_rate": 1.4281927710843375e-05,
      "loss": 0.0948,
      "step": 47460
    },
    {
      "epoch": 5.719277108433735,
      "grad_norm": 0.20097596943378448,
      "learning_rate": 1.4280722891566266e-05,
      "loss": 0.027,
      "step": 47470
    },
    {
      "epoch": 5.720481927710844,
      "grad_norm": 0.060557425022125244,
      "learning_rate": 1.4279518072289158e-05,
      "loss": 0.076,
      "step": 47480
    },
    {
      "epoch": 5.7216867469879515,
      "grad_norm": 5.876057147979736,
      "learning_rate": 1.4278313253012049e-05,
      "loss": 0.032,
      "step": 47490
    },
    {
      "epoch": 5.72289156626506,
      "grad_norm": 0.26735636591911316,
      "learning_rate": 1.4277108433734941e-05,
      "loss": 0.0959,
      "step": 47500
    },
    {
      "epoch": 5.724096385542168,
      "grad_norm": 4.331145763397217,
      "learning_rate": 1.4275903614457834e-05,
      "loss": 0.0142,
      "step": 47510
    },
    {
      "epoch": 5.725301204819277,
      "grad_norm": 0.48413750529289246,
      "learning_rate": 1.4274698795180725e-05,
      "loss": 0.0521,
      "step": 47520
    },
    {
      "epoch": 5.726506024096386,
      "grad_norm": 2.961935043334961,
      "learning_rate": 1.4273493975903617e-05,
      "loss": 0.0586,
      "step": 47530
    },
    {
      "epoch": 5.727710843373494,
      "grad_norm": 0.2273360639810562,
      "learning_rate": 1.4272289156626506e-05,
      "loss": 0.0128,
      "step": 47540
    },
    {
      "epoch": 5.728915662650603,
      "grad_norm": 0.06900078803300858,
      "learning_rate": 1.4271084337349398e-05,
      "loss": 0.0525,
      "step": 47550
    },
    {
      "epoch": 5.7301204819277105,
      "grad_norm": 0.4169404208660126,
      "learning_rate": 1.426987951807229e-05,
      "loss": 0.0129,
      "step": 47560
    },
    {
      "epoch": 5.731325301204819,
      "grad_norm": 0.49054887890815735,
      "learning_rate": 1.4268674698795182e-05,
      "loss": 0.0736,
      "step": 47570
    },
    {
      "epoch": 5.732530120481927,
      "grad_norm": 0.11214390397071838,
      "learning_rate": 1.4267469879518074e-05,
      "loss": 0.0828,
      "step": 47580
    },
    {
      "epoch": 5.733734939759036,
      "grad_norm": 7.646174907684326,
      "learning_rate": 1.4266265060240965e-05,
      "loss": 0.0945,
      "step": 47590
    },
    {
      "epoch": 5.734939759036145,
      "grad_norm": 8.36631965637207,
      "learning_rate": 1.4265060240963857e-05,
      "loss": 0.0474,
      "step": 47600
    },
    {
      "epoch": 5.736144578313253,
      "grad_norm": 2.8320982456207275,
      "learning_rate": 1.4263855421686748e-05,
      "loss": 0.0048,
      "step": 47610
    },
    {
      "epoch": 5.7373493975903616,
      "grad_norm": 0.018549256026744843,
      "learning_rate": 1.426265060240964e-05,
      "loss": 0.0221,
      "step": 47620
    },
    {
      "epoch": 5.73855421686747,
      "grad_norm": 0.37551966309547424,
      "learning_rate": 1.4261445783132531e-05,
      "loss": 0.033,
      "step": 47630
    },
    {
      "epoch": 5.739759036144578,
      "grad_norm": 0.009105535224080086,
      "learning_rate": 1.4260240963855424e-05,
      "loss": 0.0836,
      "step": 47640
    },
    {
      "epoch": 5.740963855421687,
      "grad_norm": 0.15433742105960846,
      "learning_rate": 1.4259036144578316e-05,
      "loss": 0.0562,
      "step": 47650
    },
    {
      "epoch": 5.742168674698795,
      "grad_norm": 3.6042633056640625,
      "learning_rate": 1.4257831325301205e-05,
      "loss": 0.0742,
      "step": 47660
    },
    {
      "epoch": 5.743373493975904,
      "grad_norm": 0.09341371059417725,
      "learning_rate": 1.4256626506024097e-05,
      "loss": 0.0282,
      "step": 47670
    },
    {
      "epoch": 5.744578313253012,
      "grad_norm": 0.11314348876476288,
      "learning_rate": 1.4255421686746988e-05,
      "loss": 0.055,
      "step": 47680
    },
    {
      "epoch": 5.7457831325301205,
      "grad_norm": 1.661597728729248,
      "learning_rate": 1.425421686746988e-05,
      "loss": 0.0446,
      "step": 47690
    },
    {
      "epoch": 5.746987951807229,
      "grad_norm": 0.11386708170175552,
      "learning_rate": 1.4253012048192771e-05,
      "loss": 0.0643,
      "step": 47700
    },
    {
      "epoch": 5.748192771084337,
      "grad_norm": 0.4616719186306,
      "learning_rate": 1.4251807228915664e-05,
      "loss": 0.0653,
      "step": 47710
    },
    {
      "epoch": 5.749397590361446,
      "grad_norm": 1.6427624225616455,
      "learning_rate": 1.4250602409638556e-05,
      "loss": 0.0414,
      "step": 47720
    },
    {
      "epoch": 5.750602409638554,
      "grad_norm": 0.058833424001932144,
      "learning_rate": 1.4249397590361447e-05,
      "loss": 0.0361,
      "step": 47730
    },
    {
      "epoch": 5.751807228915663,
      "grad_norm": 0.21891796588897705,
      "learning_rate": 1.424819277108434e-05,
      "loss": 0.0593,
      "step": 47740
    },
    {
      "epoch": 5.753012048192771,
      "grad_norm": 0.15804749727249146,
      "learning_rate": 1.424698795180723e-05,
      "loss": 0.0587,
      "step": 47750
    },
    {
      "epoch": 5.7542168674698795,
      "grad_norm": 2.6147429943084717,
      "learning_rate": 1.4245783132530123e-05,
      "loss": 0.0841,
      "step": 47760
    },
    {
      "epoch": 5.755421686746988,
      "grad_norm": 2.744964361190796,
      "learning_rate": 1.4244578313253012e-05,
      "loss": 0.0497,
      "step": 47770
    },
    {
      "epoch": 5.756626506024096,
      "grad_norm": 0.16085435450077057,
      "learning_rate": 1.4243373493975906e-05,
      "loss": 0.021,
      "step": 47780
    },
    {
      "epoch": 5.757831325301205,
      "grad_norm": 0.14804987609386444,
      "learning_rate": 1.4242168674698795e-05,
      "loss": 0.0797,
      "step": 47790
    },
    {
      "epoch": 5.759036144578313,
      "grad_norm": 0.046144090592861176,
      "learning_rate": 1.4240963855421687e-05,
      "loss": 0.0047,
      "step": 47800
    },
    {
      "epoch": 5.760240963855422,
      "grad_norm": 0.06911692023277283,
      "learning_rate": 1.423975903614458e-05,
      "loss": 0.0125,
      "step": 47810
    },
    {
      "epoch": 5.76144578313253,
      "grad_norm": 0.06338465213775635,
      "learning_rate": 1.423855421686747e-05,
      "loss": 0.0427,
      "step": 47820
    },
    {
      "epoch": 5.7626506024096384,
      "grad_norm": 0.7449181079864502,
      "learning_rate": 1.4237349397590363e-05,
      "loss": 0.0564,
      "step": 47830
    },
    {
      "epoch": 5.763855421686747,
      "grad_norm": 2.923938274383545,
      "learning_rate": 1.4236144578313254e-05,
      "loss": 0.0069,
      "step": 47840
    },
    {
      "epoch": 5.765060240963855,
      "grad_norm": 0.07631740719079971,
      "learning_rate": 1.4234939759036146e-05,
      "loss": 0.0297,
      "step": 47850
    },
    {
      "epoch": 5.766265060240964,
      "grad_norm": 8.592386245727539,
      "learning_rate": 1.4233734939759037e-05,
      "loss": 0.0354,
      "step": 47860
    },
    {
      "epoch": 5.767469879518073,
      "grad_norm": 0.047917190939188004,
      "learning_rate": 1.423253012048193e-05,
      "loss": 0.0313,
      "step": 47870
    },
    {
      "epoch": 5.768674698795181,
      "grad_norm": 2.7045304775238037,
      "learning_rate": 1.4231325301204822e-05,
      "loss": 0.0167,
      "step": 47880
    },
    {
      "epoch": 5.7698795180722895,
      "grad_norm": 2.439633369445801,
      "learning_rate": 1.4230120481927712e-05,
      "loss": 0.0291,
      "step": 47890
    },
    {
      "epoch": 5.771084337349397,
      "grad_norm": 1.873937726020813,
      "learning_rate": 1.4228915662650605e-05,
      "loss": 0.0153,
      "step": 47900
    },
    {
      "epoch": 5.772289156626506,
      "grad_norm": 0.02626432292163372,
      "learning_rate": 1.4227710843373494e-05,
      "loss": 0.0539,
      "step": 47910
    },
    {
      "epoch": 5.773493975903614,
      "grad_norm": 2.3225905895233154,
      "learning_rate": 1.4226506024096386e-05,
      "loss": 0.0558,
      "step": 47920
    },
    {
      "epoch": 5.774698795180723,
      "grad_norm": 15.300625801086426,
      "learning_rate": 1.4225301204819277e-05,
      "loss": 0.0462,
      "step": 47930
    },
    {
      "epoch": 5.775903614457832,
      "grad_norm": 1.8395487070083618,
      "learning_rate": 1.422409638554217e-05,
      "loss": 0.0299,
      "step": 47940
    },
    {
      "epoch": 5.77710843373494,
      "grad_norm": 0.6231826543807983,
      "learning_rate": 1.4222891566265062e-05,
      "loss": 0.046,
      "step": 47950
    },
    {
      "epoch": 5.7783132530120485,
      "grad_norm": 1.2752680778503418,
      "learning_rate": 1.4221686746987953e-05,
      "loss": 0.055,
      "step": 47960
    },
    {
      "epoch": 5.779518072289156,
      "grad_norm": 3.8047235012054443,
      "learning_rate": 1.4220481927710845e-05,
      "loss": 0.0546,
      "step": 47970
    },
    {
      "epoch": 5.780722891566265,
      "grad_norm": 0.06758132576942444,
      "learning_rate": 1.4219277108433736e-05,
      "loss": 0.0118,
      "step": 47980
    },
    {
      "epoch": 5.781927710843373,
      "grad_norm": 2.631692409515381,
      "learning_rate": 1.4218072289156628e-05,
      "loss": 0.0288,
      "step": 47990
    },
    {
      "epoch": 5.783132530120482,
      "grad_norm": 3.4009385108947754,
      "learning_rate": 1.4216867469879519e-05,
      "loss": 0.0726,
      "step": 48000
    },
    {
      "epoch": 5.784337349397591,
      "grad_norm": 0.2702691853046417,
      "learning_rate": 1.4215662650602411e-05,
      "loss": 0.0483,
      "step": 48010
    },
    {
      "epoch": 5.785542168674699,
      "grad_norm": 31.25713539123535,
      "learning_rate": 1.4214457831325304e-05,
      "loss": 0.0117,
      "step": 48020
    },
    {
      "epoch": 5.786746987951807,
      "grad_norm": 1.0436193943023682,
      "learning_rate": 1.4213253012048193e-05,
      "loss": 0.0376,
      "step": 48030
    },
    {
      "epoch": 5.787951807228915,
      "grad_norm": 2.111598014831543,
      "learning_rate": 1.4212048192771087e-05,
      "loss": 0.1027,
      "step": 48040
    },
    {
      "epoch": 5.789156626506024,
      "grad_norm": 0.5373353362083435,
      "learning_rate": 1.4210843373493976e-05,
      "loss": 0.0265,
      "step": 48050
    },
    {
      "epoch": 5.790361445783132,
      "grad_norm": 0.02277534082531929,
      "learning_rate": 1.4209638554216869e-05,
      "loss": 0.043,
      "step": 48060
    },
    {
      "epoch": 5.791566265060241,
      "grad_norm": 0.12846632301807404,
      "learning_rate": 1.420843373493976e-05,
      "loss": 0.0422,
      "step": 48070
    },
    {
      "epoch": 5.79277108433735,
      "grad_norm": 0.0345427542924881,
      "learning_rate": 1.4207228915662652e-05,
      "loss": 0.0646,
      "step": 48080
    },
    {
      "epoch": 5.793975903614458,
      "grad_norm": 9.268519401550293,
      "learning_rate": 1.4206024096385542e-05,
      "loss": 0.0649,
      "step": 48090
    },
    {
      "epoch": 5.795180722891566,
      "grad_norm": 0.11263366043567657,
      "learning_rate": 1.4204819277108435e-05,
      "loss": 0.0252,
      "step": 48100
    },
    {
      "epoch": 5.796385542168675,
      "grad_norm": 1.5546705722808838,
      "learning_rate": 1.4203614457831327e-05,
      "loss": 0.0353,
      "step": 48110
    },
    {
      "epoch": 5.797590361445783,
      "grad_norm": 0.02431083470582962,
      "learning_rate": 1.4202409638554218e-05,
      "loss": 0.0391,
      "step": 48120
    },
    {
      "epoch": 5.798795180722892,
      "grad_norm": 4.187270641326904,
      "learning_rate": 1.420120481927711e-05,
      "loss": 0.0665,
      "step": 48130
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.014137299731373787,
      "learning_rate": 1.4200000000000001e-05,
      "loss": 0.0533,
      "step": 48140
    },
    {
      "epoch": 5.801204819277109,
      "grad_norm": 7.033761978149414,
      "learning_rate": 1.4198795180722894e-05,
      "loss": 0.0496,
      "step": 48150
    },
    {
      "epoch": 5.8024096385542165,
      "grad_norm": 0.03732612729072571,
      "learning_rate": 1.4197590361445783e-05,
      "loss": 0.0401,
      "step": 48160
    },
    {
      "epoch": 5.803614457831325,
      "grad_norm": 0.22494544088840485,
      "learning_rate": 1.4196385542168675e-05,
      "loss": 0.0264,
      "step": 48170
    },
    {
      "epoch": 5.804819277108434,
      "grad_norm": 2.0125231742858887,
      "learning_rate": 1.4195180722891568e-05,
      "loss": 0.0321,
      "step": 48180
    },
    {
      "epoch": 5.806024096385542,
      "grad_norm": 2.783989667892456,
      "learning_rate": 1.4193975903614458e-05,
      "loss": 0.02,
      "step": 48190
    },
    {
      "epoch": 5.807228915662651,
      "grad_norm": 0.007569711189717054,
      "learning_rate": 1.419277108433735e-05,
      "loss": 0.0473,
      "step": 48200
    },
    {
      "epoch": 5.808433734939759,
      "grad_norm": 0.10305774956941605,
      "learning_rate": 1.4191566265060242e-05,
      "loss": 0.044,
      "step": 48210
    },
    {
      "epoch": 5.809638554216868,
      "grad_norm": 6.747074127197266,
      "learning_rate": 1.4190361445783134e-05,
      "loss": 0.0111,
      "step": 48220
    },
    {
      "epoch": 5.8108433734939755,
      "grad_norm": 0.2121259570121765,
      "learning_rate": 1.4189156626506025e-05,
      "loss": 0.0468,
      "step": 48230
    },
    {
      "epoch": 5.812048192771084,
      "grad_norm": 0.06750160455703735,
      "learning_rate": 1.4187951807228917e-05,
      "loss": 0.0605,
      "step": 48240
    },
    {
      "epoch": 5.813253012048193,
      "grad_norm": 0.2604921758174896,
      "learning_rate": 1.418674698795181e-05,
      "loss": 0.0347,
      "step": 48250
    },
    {
      "epoch": 5.814457831325301,
      "grad_norm": 0.15371136367321014,
      "learning_rate": 1.41855421686747e-05,
      "loss": 0.0035,
      "step": 48260
    },
    {
      "epoch": 5.81566265060241,
      "grad_norm": 0.01412831712514162,
      "learning_rate": 1.4184337349397593e-05,
      "loss": 0.0648,
      "step": 48270
    },
    {
      "epoch": 5.816867469879518,
      "grad_norm": 0.036852117627859116,
      "learning_rate": 1.4183132530120482e-05,
      "loss": 0.0558,
      "step": 48280
    },
    {
      "epoch": 5.8180722891566266,
      "grad_norm": 0.6050316095352173,
      "learning_rate": 1.4181927710843374e-05,
      "loss": 0.0631,
      "step": 48290
    },
    {
      "epoch": 5.8192771084337345,
      "grad_norm": 3.495603561401367,
      "learning_rate": 1.4180722891566265e-05,
      "loss": 0.0579,
      "step": 48300
    },
    {
      "epoch": 5.820481927710843,
      "grad_norm": 8.613558769226074,
      "learning_rate": 1.4179518072289157e-05,
      "loss": 0.0605,
      "step": 48310
    },
    {
      "epoch": 5.821686746987952,
      "grad_norm": 0.1550453156232834,
      "learning_rate": 1.417831325301205e-05,
      "loss": 0.0502,
      "step": 48320
    },
    {
      "epoch": 5.82289156626506,
      "grad_norm": 0.2718583941459656,
      "learning_rate": 1.417710843373494e-05,
      "loss": 0.0178,
      "step": 48330
    },
    {
      "epoch": 5.824096385542169,
      "grad_norm": 0.007341692689806223,
      "learning_rate": 1.4175903614457833e-05,
      "loss": 0.0192,
      "step": 48340
    },
    {
      "epoch": 5.825301204819278,
      "grad_norm": 1.28693425655365,
      "learning_rate": 1.4174698795180724e-05,
      "loss": 0.0565,
      "step": 48350
    },
    {
      "epoch": 5.8265060240963855,
      "grad_norm": 0.5910757184028625,
      "learning_rate": 1.4173493975903616e-05,
      "loss": 0.0081,
      "step": 48360
    },
    {
      "epoch": 5.827710843373494,
      "grad_norm": 0.03650827333331108,
      "learning_rate": 1.4172289156626507e-05,
      "loss": 0.0162,
      "step": 48370
    },
    {
      "epoch": 5.828915662650602,
      "grad_norm": 3.666151523590088,
      "learning_rate": 1.41710843373494e-05,
      "loss": 0.0128,
      "step": 48380
    },
    {
      "epoch": 5.830120481927711,
      "grad_norm": 0.003735890844836831,
      "learning_rate": 1.4169879518072288e-05,
      "loss": 0.0136,
      "step": 48390
    },
    {
      "epoch": 5.831325301204819,
      "grad_norm": 0.09184423834085464,
      "learning_rate": 1.4168674698795183e-05,
      "loss": 0.0908,
      "step": 48400
    },
    {
      "epoch": 5.832530120481928,
      "grad_norm": 0.09574529528617859,
      "learning_rate": 1.4167469879518075e-05,
      "loss": 0.0177,
      "step": 48410
    },
    {
      "epoch": 5.833734939759037,
      "grad_norm": 0.004801989533007145,
      "learning_rate": 1.4166265060240964e-05,
      "loss": 0.0738,
      "step": 48420
    },
    {
      "epoch": 5.8349397590361445,
      "grad_norm": 0.007737281266599894,
      "learning_rate": 1.4165060240963856e-05,
      "loss": 0.0477,
      "step": 48430
    },
    {
      "epoch": 5.836144578313253,
      "grad_norm": 0.025038981810212135,
      "learning_rate": 1.4163855421686747e-05,
      "loss": 0.1035,
      "step": 48440
    },
    {
      "epoch": 5.837349397590361,
      "grad_norm": 1.745869755744934,
      "learning_rate": 1.416265060240964e-05,
      "loss": 0.0395,
      "step": 48450
    },
    {
      "epoch": 5.83855421686747,
      "grad_norm": 0.8745272755622864,
      "learning_rate": 1.416144578313253e-05,
      "loss": 0.048,
      "step": 48460
    },
    {
      "epoch": 5.839759036144578,
      "grad_norm": 0.09310105443000793,
      "learning_rate": 1.4160240963855423e-05,
      "loss": 0.0707,
      "step": 48470
    },
    {
      "epoch": 5.840963855421687,
      "grad_norm": 0.42167043685913086,
      "learning_rate": 1.4159036144578315e-05,
      "loss": 0.0365,
      "step": 48480
    },
    {
      "epoch": 5.8421686746987955,
      "grad_norm": 0.04632224142551422,
      "learning_rate": 1.4157831325301206e-05,
      "loss": 0.0618,
      "step": 48490
    },
    {
      "epoch": 5.843373493975903,
      "grad_norm": 1.138927698135376,
      "learning_rate": 1.4156626506024098e-05,
      "loss": 0.0364,
      "step": 48500
    },
    {
      "epoch": 5.844578313253012,
      "grad_norm": 0.03637009859085083,
      "learning_rate": 1.415542168674699e-05,
      "loss": 0.0777,
      "step": 48510
    },
    {
      "epoch": 5.84578313253012,
      "grad_norm": 0.05758637189865112,
      "learning_rate": 1.4154216867469882e-05,
      "loss": 0.0179,
      "step": 48520
    },
    {
      "epoch": 5.846987951807229,
      "grad_norm": 5.6395792961120605,
      "learning_rate": 1.415301204819277e-05,
      "loss": 0.0387,
      "step": 48530
    },
    {
      "epoch": 5.848192771084337,
      "grad_norm": 0.04813025891780853,
      "learning_rate": 1.4151807228915663e-05,
      "loss": 0.0358,
      "step": 48540
    },
    {
      "epoch": 5.849397590361446,
      "grad_norm": 0.9957958459854126,
      "learning_rate": 1.4150602409638556e-05,
      "loss": 0.0377,
      "step": 48550
    },
    {
      "epoch": 5.8506024096385545,
      "grad_norm": 0.6053647398948669,
      "learning_rate": 1.4149397590361446e-05,
      "loss": 0.0594,
      "step": 48560
    },
    {
      "epoch": 5.851807228915662,
      "grad_norm": 0.8725269436836243,
      "learning_rate": 1.4148192771084339e-05,
      "loss": 0.0463,
      "step": 48570
    },
    {
      "epoch": 5.853012048192771,
      "grad_norm": 3.280587911605835,
      "learning_rate": 1.414698795180723e-05,
      "loss": 0.0657,
      "step": 48580
    },
    {
      "epoch": 5.85421686746988,
      "grad_norm": 1.0078836679458618,
      "learning_rate": 1.4145783132530122e-05,
      "loss": 0.0358,
      "step": 48590
    },
    {
      "epoch": 5.855421686746988,
      "grad_norm": 1.567358136177063,
      "learning_rate": 1.4144578313253013e-05,
      "loss": 0.0334,
      "step": 48600
    },
    {
      "epoch": 5.856626506024097,
      "grad_norm": 0.06437920778989792,
      "learning_rate": 1.4143373493975905e-05,
      "loss": 0.0468,
      "step": 48610
    },
    {
      "epoch": 5.857831325301205,
      "grad_norm": 0.019882215186953545,
      "learning_rate": 1.4142168674698797e-05,
      "loss": 0.0299,
      "step": 48620
    },
    {
      "epoch": 5.8590361445783135,
      "grad_norm": 0.04121595621109009,
      "learning_rate": 1.4140963855421688e-05,
      "loss": 0.058,
      "step": 48630
    },
    {
      "epoch": 5.860240963855421,
      "grad_norm": 17.966882705688477,
      "learning_rate": 1.413975903614458e-05,
      "loss": 0.0291,
      "step": 48640
    },
    {
      "epoch": 5.86144578313253,
      "grad_norm": 1.9107266664505005,
      "learning_rate": 1.413855421686747e-05,
      "loss": 0.058,
      "step": 48650
    },
    {
      "epoch": 5.862650602409639,
      "grad_norm": 0.5140027403831482,
      "learning_rate": 1.4137349397590364e-05,
      "loss": 0.0428,
      "step": 48660
    },
    {
      "epoch": 5.863855421686747,
      "grad_norm": 0.0773652121424675,
      "learning_rate": 1.4136144578313253e-05,
      "loss": 0.0248,
      "step": 48670
    },
    {
      "epoch": 5.865060240963856,
      "grad_norm": 2.2855782508850098,
      "learning_rate": 1.4134939759036145e-05,
      "loss": 0.0782,
      "step": 48680
    },
    {
      "epoch": 5.866265060240964,
      "grad_norm": 0.048033714294433594,
      "learning_rate": 1.4133734939759036e-05,
      "loss": 0.0135,
      "step": 48690
    },
    {
      "epoch": 5.867469879518072,
      "grad_norm": 0.011413528583943844,
      "learning_rate": 1.4132530120481928e-05,
      "loss": 0.0428,
      "step": 48700
    },
    {
      "epoch": 5.86867469879518,
      "grad_norm": 0.026239806786179543,
      "learning_rate": 1.4131325301204821e-05,
      "loss": 0.0202,
      "step": 48710
    },
    {
      "epoch": 5.869879518072289,
      "grad_norm": 0.025736622512340546,
      "learning_rate": 1.4130120481927712e-05,
      "loss": 0.0877,
      "step": 48720
    },
    {
      "epoch": 5.871084337349398,
      "grad_norm": 0.015290712006390095,
      "learning_rate": 1.4128915662650604e-05,
      "loss": 0.0416,
      "step": 48730
    },
    {
      "epoch": 5.872289156626506,
      "grad_norm": 0.8699985146522522,
      "learning_rate": 1.4127710843373495e-05,
      "loss": 0.0195,
      "step": 48740
    },
    {
      "epoch": 5.873493975903615,
      "grad_norm": 0.6349957585334778,
      "learning_rate": 1.4126506024096387e-05,
      "loss": 0.0753,
      "step": 48750
    },
    {
      "epoch": 5.874698795180723,
      "grad_norm": 1.4090765714645386,
      "learning_rate": 1.4125301204819278e-05,
      "loss": 0.0606,
      "step": 48760
    },
    {
      "epoch": 5.875903614457831,
      "grad_norm": 9.509023666381836,
      "learning_rate": 1.412409638554217e-05,
      "loss": 0.0476,
      "step": 48770
    },
    {
      "epoch": 5.877108433734939,
      "grad_norm": 0.1795995831489563,
      "learning_rate": 1.4122891566265063e-05,
      "loss": 0.0341,
      "step": 48780
    },
    {
      "epoch": 5.878313253012048,
      "grad_norm": 0.10687658190727234,
      "learning_rate": 1.4121686746987952e-05,
      "loss": 0.1294,
      "step": 48790
    },
    {
      "epoch": 5.879518072289157,
      "grad_norm": 23.065595626831055,
      "learning_rate": 1.4120481927710844e-05,
      "loss": 0.0202,
      "step": 48800
    },
    {
      "epoch": 5.880722891566265,
      "grad_norm": 4.275728225708008,
      "learning_rate": 1.4119277108433735e-05,
      "loss": 0.0858,
      "step": 48810
    },
    {
      "epoch": 5.881927710843374,
      "grad_norm": 0.23238223791122437,
      "learning_rate": 1.4118072289156628e-05,
      "loss": 0.0189,
      "step": 48820
    },
    {
      "epoch": 5.8831325301204815,
      "grad_norm": 1.2505855560302734,
      "learning_rate": 1.4116867469879518e-05,
      "loss": 0.0528,
      "step": 48830
    },
    {
      "epoch": 5.88433734939759,
      "grad_norm": 0.7732520699501038,
      "learning_rate": 1.411566265060241e-05,
      "loss": 0.0449,
      "step": 48840
    },
    {
      "epoch": 5.885542168674699,
      "grad_norm": 12.467768669128418,
      "learning_rate": 1.4114457831325303e-05,
      "loss": 0.0578,
      "step": 48850
    },
    {
      "epoch": 5.886746987951807,
      "grad_norm": 6.337390422821045,
      "learning_rate": 1.4113253012048194e-05,
      "loss": 0.0772,
      "step": 48860
    },
    {
      "epoch": 5.887951807228916,
      "grad_norm": 3.8360767364501953,
      "learning_rate": 1.4112048192771086e-05,
      "loss": 0.0706,
      "step": 48870
    },
    {
      "epoch": 5.889156626506024,
      "grad_norm": 2.4803123474121094,
      "learning_rate": 1.4110843373493977e-05,
      "loss": 0.048,
      "step": 48880
    },
    {
      "epoch": 5.890361445783133,
      "grad_norm": 0.017740117385983467,
      "learning_rate": 1.410963855421687e-05,
      "loss": 0.0285,
      "step": 48890
    },
    {
      "epoch": 5.891566265060241,
      "grad_norm": 0.06667036563158035,
      "learning_rate": 1.4108433734939759e-05,
      "loss": 0.0108,
      "step": 48900
    },
    {
      "epoch": 5.892771084337349,
      "grad_norm": 3.197357416152954,
      "learning_rate": 1.4107228915662653e-05,
      "loss": 0.0606,
      "step": 48910
    },
    {
      "epoch": 5.893975903614458,
      "grad_norm": 0.005383459851145744,
      "learning_rate": 1.4106024096385545e-05,
      "loss": 0.0401,
      "step": 48920
    },
    {
      "epoch": 5.895180722891566,
      "grad_norm": 0.0571129210293293,
      "learning_rate": 1.4104819277108434e-05,
      "loss": 0.0376,
      "step": 48930
    },
    {
      "epoch": 5.896385542168675,
      "grad_norm": 0.004100691992789507,
      "learning_rate": 1.4103614457831327e-05,
      "loss": 0.0547,
      "step": 48940
    },
    {
      "epoch": 5.897590361445783,
      "grad_norm": 0.0111419428139925,
      "learning_rate": 1.4102409638554217e-05,
      "loss": 0.0207,
      "step": 48950
    },
    {
      "epoch": 5.8987951807228916,
      "grad_norm": 10.134557723999023,
      "learning_rate": 1.410120481927711e-05,
      "loss": 0.0731,
      "step": 48960
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.47840747237205505,
      "learning_rate": 1.41e-05,
      "loss": 0.0188,
      "step": 48970
    },
    {
      "epoch": 5.901204819277108,
      "grad_norm": 7.551464557647705,
      "learning_rate": 1.4098795180722893e-05,
      "loss": 0.0366,
      "step": 48980
    },
    {
      "epoch": 5.902409638554217,
      "grad_norm": 0.005677209235727787,
      "learning_rate": 1.4097590361445784e-05,
      "loss": 0.0189,
      "step": 48990
    },
    {
      "epoch": 5.903614457831325,
      "grad_norm": 0.05261708423495293,
      "learning_rate": 1.4096385542168676e-05,
      "loss": 0.033,
      "step": 49000
    },
    {
      "epoch": 5.904819277108434,
      "grad_norm": 2.0870912075042725,
      "learning_rate": 1.4095180722891569e-05,
      "loss": 0.0449,
      "step": 49010
    },
    {
      "epoch": 5.906024096385542,
      "grad_norm": 0.09357800334692001,
      "learning_rate": 1.409397590361446e-05,
      "loss": 0.0444,
      "step": 49020
    },
    {
      "epoch": 5.9072289156626505,
      "grad_norm": 6.022912979125977,
      "learning_rate": 1.4092771084337352e-05,
      "loss": 0.0735,
      "step": 49030
    },
    {
      "epoch": 5.908433734939759,
      "grad_norm": 0.14662198722362518,
      "learning_rate": 1.409156626506024e-05,
      "loss": 0.0564,
      "step": 49040
    },
    {
      "epoch": 5.909638554216867,
      "grad_norm": 0.3441583514213562,
      "learning_rate": 1.4090361445783133e-05,
      "loss": 0.0451,
      "step": 49050
    },
    {
      "epoch": 5.910843373493976,
      "grad_norm": 3.0443129539489746,
      "learning_rate": 1.4089156626506024e-05,
      "loss": 0.0559,
      "step": 49060
    },
    {
      "epoch": 5.912048192771084,
      "grad_norm": 4.333470344543457,
      "learning_rate": 1.4087951807228916e-05,
      "loss": 0.0503,
      "step": 49070
    },
    {
      "epoch": 5.913253012048193,
      "grad_norm": 0.19008833169937134,
      "learning_rate": 1.4086746987951809e-05,
      "loss": 0.055,
      "step": 49080
    },
    {
      "epoch": 5.914457831325302,
      "grad_norm": 3.7328147888183594,
      "learning_rate": 1.40855421686747e-05,
      "loss": 0.0739,
      "step": 49090
    },
    {
      "epoch": 5.9156626506024095,
      "grad_norm": 3.4472076892852783,
      "learning_rate": 1.4084337349397592e-05,
      "loss": 0.1063,
      "step": 49100
    },
    {
      "epoch": 5.916867469879518,
      "grad_norm": 0.9522566199302673,
      "learning_rate": 1.4083132530120483e-05,
      "loss": 0.0236,
      "step": 49110
    },
    {
      "epoch": 5.918072289156626,
      "grad_norm": 2.1160385608673096,
      "learning_rate": 1.4081927710843375e-05,
      "loss": 0.0295,
      "step": 49120
    },
    {
      "epoch": 5.919277108433735,
      "grad_norm": 2.6755971908569336,
      "learning_rate": 1.4080722891566266e-05,
      "loss": 0.0467,
      "step": 49130
    },
    {
      "epoch": 5.920481927710844,
      "grad_norm": 0.008553396910429,
      "learning_rate": 1.4079518072289158e-05,
      "loss": 0.0215,
      "step": 49140
    },
    {
      "epoch": 5.921686746987952,
      "grad_norm": 0.017376840114593506,
      "learning_rate": 1.407831325301205e-05,
      "loss": 0.0098,
      "step": 49150
    },
    {
      "epoch": 5.9228915662650605,
      "grad_norm": 28.804153442382812,
      "learning_rate": 1.407710843373494e-05,
      "loss": 0.1339,
      "step": 49160
    },
    {
      "epoch": 5.924096385542168,
      "grad_norm": 0.31941723823547363,
      "learning_rate": 1.4075903614457834e-05,
      "loss": 0.0335,
      "step": 49170
    },
    {
      "epoch": 5.925301204819277,
      "grad_norm": 5.45015811920166,
      "learning_rate": 1.4074698795180723e-05,
      "loss": 0.0839,
      "step": 49180
    },
    {
      "epoch": 5.926506024096385,
      "grad_norm": 1.4658756256103516,
      "learning_rate": 1.4073493975903615e-05,
      "loss": 0.0259,
      "step": 49190
    },
    {
      "epoch": 5.927710843373494,
      "grad_norm": 0.03633873164653778,
      "learning_rate": 1.4072289156626506e-05,
      "loss": 0.0056,
      "step": 49200
    },
    {
      "epoch": 5.928915662650603,
      "grad_norm": 0.011511671356856823,
      "learning_rate": 1.4071084337349399e-05,
      "loss": 0.0236,
      "step": 49210
    },
    {
      "epoch": 5.930120481927711,
      "grad_norm": 7.903541088104248,
      "learning_rate": 1.4069879518072291e-05,
      "loss": 0.0461,
      "step": 49220
    },
    {
      "epoch": 5.9313253012048195,
      "grad_norm": 0.3889499306678772,
      "learning_rate": 1.4068674698795182e-05,
      "loss": 0.041,
      "step": 49230
    },
    {
      "epoch": 5.932530120481927,
      "grad_norm": 1.501907467842102,
      "learning_rate": 1.4067469879518074e-05,
      "loss": 0.0527,
      "step": 49240
    },
    {
      "epoch": 5.933734939759036,
      "grad_norm": 13.230167388916016,
      "learning_rate": 1.4066265060240965e-05,
      "loss": 0.0568,
      "step": 49250
    },
    {
      "epoch": 5.934939759036144,
      "grad_norm": 12.490877151489258,
      "learning_rate": 1.4065060240963857e-05,
      "loss": 0.0584,
      "step": 49260
    },
    {
      "epoch": 5.936144578313253,
      "grad_norm": 1.0400933027267456,
      "learning_rate": 1.4063855421686748e-05,
      "loss": 0.0559,
      "step": 49270
    },
    {
      "epoch": 5.937349397590362,
      "grad_norm": 0.09490393102169037,
      "learning_rate": 1.406265060240964e-05,
      "loss": 0.0234,
      "step": 49280
    },
    {
      "epoch": 5.93855421686747,
      "grad_norm": 1.5686489343643188,
      "learning_rate": 1.406144578313253e-05,
      "loss": 0.0174,
      "step": 49290
    },
    {
      "epoch": 5.9397590361445785,
      "grad_norm": 0.2807525098323822,
      "learning_rate": 1.4060240963855422e-05,
      "loss": 0.0186,
      "step": 49300
    },
    {
      "epoch": 5.940963855421686,
      "grad_norm": 0.0017501246184110641,
      "learning_rate": 1.4059036144578315e-05,
      "loss": 0.0121,
      "step": 49310
    },
    {
      "epoch": 5.942168674698795,
      "grad_norm": 2.696027994155884,
      "learning_rate": 1.4057831325301205e-05,
      "loss": 0.0697,
      "step": 49320
    },
    {
      "epoch": 5.943373493975904,
      "grad_norm": 0.0409940667450428,
      "learning_rate": 1.4056626506024098e-05,
      "loss": 0.0815,
      "step": 49330
    },
    {
      "epoch": 5.944578313253012,
      "grad_norm": 1.8169000148773193,
      "learning_rate": 1.4055421686746988e-05,
      "loss": 0.0171,
      "step": 49340
    },
    {
      "epoch": 5.945783132530121,
      "grad_norm": 6.707622051239014,
      "learning_rate": 1.4054216867469881e-05,
      "loss": 0.0508,
      "step": 49350
    },
    {
      "epoch": 5.946987951807229,
      "grad_norm": 0.5665237307548523,
      "learning_rate": 1.4053012048192772e-05,
      "loss": 0.0192,
      "step": 49360
    },
    {
      "epoch": 5.948192771084337,
      "grad_norm": 0.670988142490387,
      "learning_rate": 1.4051807228915664e-05,
      "loss": 0.0361,
      "step": 49370
    },
    {
      "epoch": 5.949397590361446,
      "grad_norm": 0.3267000615596771,
      "learning_rate": 1.4050602409638556e-05,
      "loss": 0.0706,
      "step": 49380
    },
    {
      "epoch": 5.950602409638554,
      "grad_norm": 0.03563004359602928,
      "learning_rate": 1.4049397590361447e-05,
      "loss": 0.0662,
      "step": 49390
    },
    {
      "epoch": 5.951807228915663,
      "grad_norm": 0.2111739218235016,
      "learning_rate": 1.404819277108434e-05,
      "loss": 0.0403,
      "step": 49400
    },
    {
      "epoch": 5.953012048192771,
      "grad_norm": 1.9577205181121826,
      "learning_rate": 1.4046987951807229e-05,
      "loss": 0.0547,
      "step": 49410
    },
    {
      "epoch": 5.95421686746988,
      "grad_norm": 0.456828773021698,
      "learning_rate": 1.4045783132530121e-05,
      "loss": 0.022,
      "step": 49420
    },
    {
      "epoch": 5.955421686746988,
      "grad_norm": 0.023367449641227722,
      "learning_rate": 1.4044578313253012e-05,
      "loss": 0.0236,
      "step": 49430
    },
    {
      "epoch": 5.956626506024096,
      "grad_norm": 0.019807197153568268,
      "learning_rate": 1.4043373493975904e-05,
      "loss": 0.0456,
      "step": 49440
    },
    {
      "epoch": 5.957831325301205,
      "grad_norm": 0.690348207950592,
      "learning_rate": 1.4042168674698797e-05,
      "loss": 0.0081,
      "step": 49450
    },
    {
      "epoch": 5.959036144578313,
      "grad_norm": 0.27656570076942444,
      "learning_rate": 1.4040963855421687e-05,
      "loss": 0.0278,
      "step": 49460
    },
    {
      "epoch": 5.960240963855422,
      "grad_norm": 1.404637098312378,
      "learning_rate": 1.403975903614458e-05,
      "loss": 0.0522,
      "step": 49470
    },
    {
      "epoch": 5.96144578313253,
      "grad_norm": 3.8151557445526123,
      "learning_rate": 1.403855421686747e-05,
      "loss": 0.0322,
      "step": 49480
    },
    {
      "epoch": 5.962650602409639,
      "grad_norm": 0.008394519798457623,
      "learning_rate": 1.4037349397590363e-05,
      "loss": 0.0617,
      "step": 49490
    },
    {
      "epoch": 5.9638554216867465,
      "grad_norm": 0.014755787327885628,
      "learning_rate": 1.4036144578313254e-05,
      "loss": 0.0352,
      "step": 49500
    },
    {
      "epoch": 5.965060240963855,
      "grad_norm": 0.02776969224214554,
      "learning_rate": 1.4034939759036146e-05,
      "loss": 0.0293,
      "step": 49510
    },
    {
      "epoch": 5.966265060240964,
      "grad_norm": 0.04945558309555054,
      "learning_rate": 1.4033734939759039e-05,
      "loss": 0.0084,
      "step": 49520
    },
    {
      "epoch": 5.967469879518072,
      "grad_norm": 0.006782772019505501,
      "learning_rate": 1.403253012048193e-05,
      "loss": 0.0413,
      "step": 49530
    },
    {
      "epoch": 5.968674698795181,
      "grad_norm": 0.8496273756027222,
      "learning_rate": 1.4031325301204822e-05,
      "loss": 0.0837,
      "step": 49540
    },
    {
      "epoch": 5.969879518072289,
      "grad_norm": 1.7425576448440552,
      "learning_rate": 1.4030120481927711e-05,
      "loss": 0.0127,
      "step": 49550
    },
    {
      "epoch": 5.971084337349398,
      "grad_norm": 75.89069366455078,
      "learning_rate": 1.4028915662650603e-05,
      "loss": 0.0317,
      "step": 49560
    },
    {
      "epoch": 5.972289156626506,
      "grad_norm": 0.008560637943446636,
      "learning_rate": 1.4027710843373494e-05,
      "loss": 0.0649,
      "step": 49570
    },
    {
      "epoch": 5.973493975903614,
      "grad_norm": 0.030204035341739655,
      "learning_rate": 1.4026506024096387e-05,
      "loss": 0.0421,
      "step": 49580
    },
    {
      "epoch": 5.974698795180723,
      "grad_norm": 3.254707098007202,
      "learning_rate": 1.4025301204819277e-05,
      "loss": 0.038,
      "step": 49590
    },
    {
      "epoch": 5.975903614457831,
      "grad_norm": 0.03495430573821068,
      "learning_rate": 1.402409638554217e-05,
      "loss": 0.0163,
      "step": 49600
    },
    {
      "epoch": 5.97710843373494,
      "grad_norm": 0.015488265082240105,
      "learning_rate": 1.4022891566265062e-05,
      "loss": 0.0304,
      "step": 49610
    },
    {
      "epoch": 5.978313253012049,
      "grad_norm": 2.0560615062713623,
      "learning_rate": 1.4021686746987953e-05,
      "loss": 0.0762,
      "step": 49620
    },
    {
      "epoch": 5.9795180722891565,
      "grad_norm": 0.017660774290561676,
      "learning_rate": 1.4020481927710845e-05,
      "loss": 0.0497,
      "step": 49630
    },
    {
      "epoch": 5.980722891566265,
      "grad_norm": 0.11879301071166992,
      "learning_rate": 1.4019277108433736e-05,
      "loss": 0.0327,
      "step": 49640
    },
    {
      "epoch": 5.981927710843373,
      "grad_norm": 0.08051459491252899,
      "learning_rate": 1.4018072289156629e-05,
      "loss": 0.0243,
      "step": 49650
    },
    {
      "epoch": 5.983132530120482,
      "grad_norm": 3.525297164916992,
      "learning_rate": 1.4016867469879518e-05,
      "loss": 0.0969,
      "step": 49660
    },
    {
      "epoch": 5.98433734939759,
      "grad_norm": 0.03381941094994545,
      "learning_rate": 1.401566265060241e-05,
      "loss": 0.0634,
      "step": 49670
    },
    {
      "epoch": 5.985542168674699,
      "grad_norm": 0.07486168295145035,
      "learning_rate": 1.4014457831325302e-05,
      "loss": 0.0141,
      "step": 49680
    },
    {
      "epoch": 5.986746987951808,
      "grad_norm": 0.01912054978311062,
      "learning_rate": 1.4013253012048193e-05,
      "loss": 0.0051,
      "step": 49690
    },
    {
      "epoch": 5.9879518072289155,
      "grad_norm": 1.9604201316833496,
      "learning_rate": 1.4012048192771086e-05,
      "loss": 0.1231,
      "step": 49700
    },
    {
      "epoch": 5.989156626506024,
      "grad_norm": 2.7591562271118164,
      "learning_rate": 1.4010843373493976e-05,
      "loss": 0.0819,
      "step": 49710
    },
    {
      "epoch": 5.990361445783132,
      "grad_norm": 2.690490245819092,
      "learning_rate": 1.4009638554216869e-05,
      "loss": 0.056,
      "step": 49720
    },
    {
      "epoch": 5.991566265060241,
      "grad_norm": 9.419083595275879,
      "learning_rate": 1.400843373493976e-05,
      "loss": 0.0485,
      "step": 49730
    },
    {
      "epoch": 5.992771084337349,
      "grad_norm": 1.6634349822998047,
      "learning_rate": 1.4007228915662652e-05,
      "loss": 0.0571,
      "step": 49740
    },
    {
      "epoch": 5.993975903614458,
      "grad_norm": 1.1446279287338257,
      "learning_rate": 1.4006024096385544e-05,
      "loss": 0.0836,
      "step": 49750
    },
    {
      "epoch": 5.995180722891567,
      "grad_norm": 12.797292709350586,
      "learning_rate": 1.4004819277108435e-05,
      "loss": 0.0214,
      "step": 49760
    },
    {
      "epoch": 5.9963855421686745,
      "grad_norm": 2.2515363693237305,
      "learning_rate": 1.4003614457831328e-05,
      "loss": 0.0525,
      "step": 49770
    },
    {
      "epoch": 5.997590361445783,
      "grad_norm": 0.2814505398273468,
      "learning_rate": 1.4002409638554217e-05,
      "loss": 0.0194,
      "step": 49780
    },
    {
      "epoch": 5.998795180722891,
      "grad_norm": 2.715615749359131,
      "learning_rate": 1.400120481927711e-05,
      "loss": 0.0342,
      "step": 49790
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.3926138877868652,
      "learning_rate": 1.4e-05,
      "loss": 0.0177,
      "step": 49800
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9825178102737158,
      "eval_f1": 0.953087661929317,
      "eval_loss": 0.07043495774269104,
      "eval_precision": 0.9701702726923569,
      "eval_recall": 0.9365962180200222,
      "eval_runtime": 3378.1805,
      "eval_samples_per_second": 12.637,
      "eval_steps_per_second": 0.527,
      "step": 49800
    },
    {
      "epoch": 6.001204819277109,
      "grad_norm": 0.03806810826063156,
      "learning_rate": 1.3998795180722892e-05,
      "loss": 0.0474,
      "step": 49810
    },
    {
      "epoch": 6.002409638554217,
      "grad_norm": 0.42832618951797485,
      "learning_rate": 1.3997590361445785e-05,
      "loss": 0.054,
      "step": 49820
    },
    {
      "epoch": 6.0036144578313255,
      "grad_norm": 0.005854060407727957,
      "learning_rate": 1.3996385542168675e-05,
      "loss": 0.0129,
      "step": 49830
    },
    {
      "epoch": 6.004819277108433,
      "grad_norm": 0.007637971080839634,
      "learning_rate": 1.3995180722891568e-05,
      "loss": 0.0278,
      "step": 49840
    },
    {
      "epoch": 6.006024096385542,
      "grad_norm": 0.47626253962516785,
      "learning_rate": 1.3993975903614459e-05,
      "loss": 0.0958,
      "step": 49850
    },
    {
      "epoch": 6.00722891566265,
      "grad_norm": 5.35095739364624,
      "learning_rate": 1.3992771084337351e-05,
      "loss": 0.0276,
      "step": 49860
    },
    {
      "epoch": 6.008433734939759,
      "grad_norm": 0.01462580543011427,
      "learning_rate": 1.3991566265060242e-05,
      "loss": 0.0518,
      "step": 49870
    },
    {
      "epoch": 6.009638554216868,
      "grad_norm": 0.5430395603179932,
      "learning_rate": 1.3990361445783134e-05,
      "loss": 0.0147,
      "step": 49880
    },
    {
      "epoch": 6.010843373493976,
      "grad_norm": 0.01838482730090618,
      "learning_rate": 1.3989156626506027e-05,
      "loss": 0.0366,
      "step": 49890
    },
    {
      "epoch": 6.0120481927710845,
      "grad_norm": 0.98921138048172,
      "learning_rate": 1.3987951807228917e-05,
      "loss": 0.1214,
      "step": 49900
    },
    {
      "epoch": 6.013253012048192,
      "grad_norm": 0.393298476934433,
      "learning_rate": 1.398674698795181e-05,
      "loss": 0.0493,
      "step": 49910
    },
    {
      "epoch": 6.014457831325301,
      "grad_norm": 1.6108568906784058,
      "learning_rate": 1.3985542168674699e-05,
      "loss": 0.0565,
      "step": 49920
    },
    {
      "epoch": 6.01566265060241,
      "grad_norm": 0.06217173486948013,
      "learning_rate": 1.3984337349397591e-05,
      "loss": 0.0698,
      "step": 49930
    },
    {
      "epoch": 6.016867469879518,
      "grad_norm": 0.04056493192911148,
      "learning_rate": 1.3983132530120482e-05,
      "loss": 0.0678,
      "step": 49940
    },
    {
      "epoch": 6.018072289156627,
      "grad_norm": 0.07228747755289078,
      "learning_rate": 1.3981927710843374e-05,
      "loss": 0.0799,
      "step": 49950
    },
    {
      "epoch": 6.019277108433735,
      "grad_norm": 0.08876989781856537,
      "learning_rate": 1.3980722891566265e-05,
      "loss": 0.0309,
      "step": 49960
    },
    {
      "epoch": 6.0204819277108435,
      "grad_norm": 0.01839485391974449,
      "learning_rate": 1.3979518072289158e-05,
      "loss": 0.0181,
      "step": 49970
    },
    {
      "epoch": 6.021686746987951,
      "grad_norm": 9.745888710021973,
      "learning_rate": 1.397831325301205e-05,
      "loss": 0.0409,
      "step": 49980
    },
    {
      "epoch": 6.02289156626506,
      "grad_norm": 2.2274603843688965,
      "learning_rate": 1.397710843373494e-05,
      "loss": 0.0516,
      "step": 49990
    },
    {
      "epoch": 6.024096385542169,
      "grad_norm": 0.2707101106643677,
      "learning_rate": 1.3975903614457833e-05,
      "loss": 0.0281,
      "step": 50000
    },
    {
      "epoch": 6.025301204819277,
      "grad_norm": 1.0923058986663818,
      "learning_rate": 1.3974698795180724e-05,
      "loss": 0.0311,
      "step": 50010
    },
    {
      "epoch": 6.026506024096386,
      "grad_norm": 0.7573414444923401,
      "learning_rate": 1.3973493975903616e-05,
      "loss": 0.0154,
      "step": 50020
    },
    {
      "epoch": 6.027710843373494,
      "grad_norm": 0.5027919411659241,
      "learning_rate": 1.3972289156626505e-05,
      "loss": 0.0361,
      "step": 50030
    },
    {
      "epoch": 6.028915662650602,
      "grad_norm": 0.02320082113146782,
      "learning_rate": 1.3971084337349398e-05,
      "loss": 0.0396,
      "step": 50040
    },
    {
      "epoch": 6.030120481927711,
      "grad_norm": 1.6131821870803833,
      "learning_rate": 1.3969879518072292e-05,
      "loss": 0.017,
      "step": 50050
    },
    {
      "epoch": 6.031325301204819,
      "grad_norm": 0.5604584217071533,
      "learning_rate": 1.3968674698795181e-05,
      "loss": 0.0306,
      "step": 50060
    },
    {
      "epoch": 6.032530120481928,
      "grad_norm": 0.06585907936096191,
      "learning_rate": 1.3967469879518074e-05,
      "loss": 0.0211,
      "step": 50070
    },
    {
      "epoch": 6.033734939759036,
      "grad_norm": 0.06087345629930496,
      "learning_rate": 1.3966265060240964e-05,
      "loss": 0.0764,
      "step": 50080
    },
    {
      "epoch": 6.034939759036145,
      "grad_norm": 0.0684310719370842,
      "learning_rate": 1.3965060240963857e-05,
      "loss": 0.0193,
      "step": 50090
    },
    {
      "epoch": 6.036144578313253,
      "grad_norm": 0.008949263952672482,
      "learning_rate": 1.3963855421686747e-05,
      "loss": 0.0379,
      "step": 50100
    },
    {
      "epoch": 6.037349397590361,
      "grad_norm": 7.480624675750732,
      "learning_rate": 1.396265060240964e-05,
      "loss": 0.0732,
      "step": 50110
    },
    {
      "epoch": 6.03855421686747,
      "grad_norm": 1.1915802955627441,
      "learning_rate": 1.3961445783132532e-05,
      "loss": 0.05,
      "step": 50120
    },
    {
      "epoch": 6.039759036144578,
      "grad_norm": 1.1428576707839966,
      "learning_rate": 1.3960240963855423e-05,
      "loss": 0.0313,
      "step": 50130
    },
    {
      "epoch": 6.040963855421687,
      "grad_norm": 3.2306604385375977,
      "learning_rate": 1.3959036144578315e-05,
      "loss": 0.0341,
      "step": 50140
    },
    {
      "epoch": 6.042168674698795,
      "grad_norm": 0.21655680239200592,
      "learning_rate": 1.3957831325301206e-05,
      "loss": 0.0783,
      "step": 50150
    },
    {
      "epoch": 6.043373493975904,
      "grad_norm": 4.775881767272949,
      "learning_rate": 1.3956626506024099e-05,
      "loss": 0.1114,
      "step": 50160
    },
    {
      "epoch": 6.044578313253012,
      "grad_norm": 2.965723991394043,
      "learning_rate": 1.3955421686746988e-05,
      "loss": 0.0227,
      "step": 50170
    },
    {
      "epoch": 6.04578313253012,
      "grad_norm": 0.9865719079971313,
      "learning_rate": 1.395421686746988e-05,
      "loss": 0.0141,
      "step": 50180
    },
    {
      "epoch": 6.046987951807229,
      "grad_norm": 1.867883563041687,
      "learning_rate": 1.3953012048192773e-05,
      "loss": 0.0389,
      "step": 50190
    },
    {
      "epoch": 6.048192771084337,
      "grad_norm": 0.18497949838638306,
      "learning_rate": 1.3951807228915663e-05,
      "loss": 0.0575,
      "step": 50200
    },
    {
      "epoch": 6.049397590361446,
      "grad_norm": 0.24321402609348297,
      "learning_rate": 1.3950602409638556e-05,
      "loss": 0.0072,
      "step": 50210
    },
    {
      "epoch": 6.050602409638554,
      "grad_norm": 7.752309799194336,
      "learning_rate": 1.3949397590361446e-05,
      "loss": 0.0591,
      "step": 50220
    },
    {
      "epoch": 6.051807228915663,
      "grad_norm": 0.025514302775263786,
      "learning_rate": 1.3948192771084339e-05,
      "loss": 0.028,
      "step": 50230
    },
    {
      "epoch": 6.053012048192771,
      "grad_norm": 1.2235337495803833,
      "learning_rate": 1.394698795180723e-05,
      "loss": 0.0128,
      "step": 50240
    },
    {
      "epoch": 6.054216867469879,
      "grad_norm": 0.05384273827075958,
      "learning_rate": 1.3945783132530122e-05,
      "loss": 0.0327,
      "step": 50250
    },
    {
      "epoch": 6.055421686746988,
      "grad_norm": 0.028597332537174225,
      "learning_rate": 1.3944578313253013e-05,
      "loss": 0.0221,
      "step": 50260
    },
    {
      "epoch": 6.056626506024096,
      "grad_norm": 4.880908966064453,
      "learning_rate": 1.3943373493975905e-05,
      "loss": 0.0249,
      "step": 50270
    },
    {
      "epoch": 6.057831325301205,
      "grad_norm": 0.4044693410396576,
      "learning_rate": 1.3942168674698798e-05,
      "loss": 0.0105,
      "step": 50280
    },
    {
      "epoch": 6.059036144578314,
      "grad_norm": 8.560811996459961,
      "learning_rate": 1.3940963855421687e-05,
      "loss": 0.0862,
      "step": 50290
    },
    {
      "epoch": 6.0602409638554215,
      "grad_norm": 0.14777684211730957,
      "learning_rate": 1.393975903614458e-05,
      "loss": 0.0503,
      "step": 50300
    },
    {
      "epoch": 6.06144578313253,
      "grad_norm": 0.029837297275662422,
      "learning_rate": 1.393855421686747e-05,
      "loss": 0.0179,
      "step": 50310
    },
    {
      "epoch": 6.062650602409638,
      "grad_norm": 3.900804281234741,
      "learning_rate": 1.3937349397590362e-05,
      "loss": 0.0147,
      "step": 50320
    },
    {
      "epoch": 6.063855421686747,
      "grad_norm": 4.1440510749816895,
      "learning_rate": 1.3936144578313253e-05,
      "loss": 0.0451,
      "step": 50330
    },
    {
      "epoch": 6.065060240963855,
      "grad_norm": 5.456520080566406,
      "learning_rate": 1.3934939759036146e-05,
      "loss": 0.0581,
      "step": 50340
    },
    {
      "epoch": 6.066265060240964,
      "grad_norm": 0.13947391510009766,
      "learning_rate": 1.3933734939759038e-05,
      "loss": 0.0491,
      "step": 50350
    },
    {
      "epoch": 6.067469879518073,
      "grad_norm": 0.057250767946243286,
      "learning_rate": 1.3932530120481929e-05,
      "loss": 0.0215,
      "step": 50360
    },
    {
      "epoch": 6.0686746987951805,
      "grad_norm": 0.33914071321487427,
      "learning_rate": 1.3931325301204821e-05,
      "loss": 0.0613,
      "step": 50370
    },
    {
      "epoch": 6.069879518072289,
      "grad_norm": 3.7929880619049072,
      "learning_rate": 1.3930120481927712e-05,
      "loss": 0.0274,
      "step": 50380
    },
    {
      "epoch": 6.071084337349397,
      "grad_norm": 0.4054735600948334,
      "learning_rate": 1.3928915662650604e-05,
      "loss": 0.0345,
      "step": 50390
    },
    {
      "epoch": 6.072289156626506,
      "grad_norm": 0.39090847969055176,
      "learning_rate": 1.3927710843373493e-05,
      "loss": 0.029,
      "step": 50400
    },
    {
      "epoch": 6.073493975903615,
      "grad_norm": 5.988058090209961,
      "learning_rate": 1.3926506024096388e-05,
      "loss": 0.0476,
      "step": 50410
    },
    {
      "epoch": 6.074698795180723,
      "grad_norm": 0.17064182460308075,
      "learning_rate": 1.392530120481928e-05,
      "loss": 0.0605,
      "step": 50420
    },
    {
      "epoch": 6.075903614457832,
      "grad_norm": 2.079639196395874,
      "learning_rate": 1.3924096385542169e-05,
      "loss": 0.0245,
      "step": 50430
    },
    {
      "epoch": 6.0771084337349395,
      "grad_norm": 0.023599158972501755,
      "learning_rate": 1.3922891566265061e-05,
      "loss": 0.0461,
      "step": 50440
    },
    {
      "epoch": 6.078313253012048,
      "grad_norm": 0.547944188117981,
      "learning_rate": 1.3921686746987952e-05,
      "loss": 0.0228,
      "step": 50450
    },
    {
      "epoch": 6.079518072289156,
      "grad_norm": 0.5873026847839355,
      "learning_rate": 1.3920481927710845e-05,
      "loss": 0.0329,
      "step": 50460
    },
    {
      "epoch": 6.080722891566265,
      "grad_norm": 0.5371589660644531,
      "learning_rate": 1.3919277108433735e-05,
      "loss": 0.0072,
      "step": 50470
    },
    {
      "epoch": 6.081927710843374,
      "grad_norm": 0.7980461120605469,
      "learning_rate": 1.3918072289156628e-05,
      "loss": 0.0226,
      "step": 50480
    },
    {
      "epoch": 6.083132530120482,
      "grad_norm": 0.01763210818171501,
      "learning_rate": 1.391686746987952e-05,
      "loss": 0.0765,
      "step": 50490
    },
    {
      "epoch": 6.0843373493975905,
      "grad_norm": 0.007931377738714218,
      "learning_rate": 1.3915662650602411e-05,
      "loss": 0.065,
      "step": 50500
    },
    {
      "epoch": 6.085542168674698,
      "grad_norm": 0.004856177140027285,
      "learning_rate": 1.3914457831325303e-05,
      "loss": 0.016,
      "step": 50510
    },
    {
      "epoch": 6.086746987951807,
      "grad_norm": 0.09240303933620453,
      "learning_rate": 1.3913253012048194e-05,
      "loss": 0.0362,
      "step": 50520
    },
    {
      "epoch": 6.087951807228916,
      "grad_norm": 0.029768764972686768,
      "learning_rate": 1.3912048192771087e-05,
      "loss": 0.0188,
      "step": 50530
    },
    {
      "epoch": 6.089156626506024,
      "grad_norm": 28.021038055419922,
      "learning_rate": 1.3910843373493976e-05,
      "loss": 0.0483,
      "step": 50540
    },
    {
      "epoch": 6.090361445783133,
      "grad_norm": 1.1788934469223022,
      "learning_rate": 1.3909638554216868e-05,
      "loss": 0.0121,
      "step": 50550
    },
    {
      "epoch": 6.091566265060241,
      "grad_norm": 0.006557720713317394,
      "learning_rate": 1.3908433734939759e-05,
      "loss": 0.0169,
      "step": 50560
    },
    {
      "epoch": 6.0927710843373495,
      "grad_norm": 0.16163380444049835,
      "learning_rate": 1.3907228915662651e-05,
      "loss": 0.0787,
      "step": 50570
    },
    {
      "epoch": 6.093975903614457,
      "grad_norm": 5.167879104614258,
      "learning_rate": 1.3906024096385544e-05,
      "loss": 0.0502,
      "step": 50580
    },
    {
      "epoch": 6.095180722891566,
      "grad_norm": 2.3098466396331787,
      "learning_rate": 1.3904819277108434e-05,
      "loss": 0.0656,
      "step": 50590
    },
    {
      "epoch": 6.096385542168675,
      "grad_norm": 0.0969800353050232,
      "learning_rate": 1.3903614457831327e-05,
      "loss": 0.0252,
      "step": 50600
    },
    {
      "epoch": 6.097590361445783,
      "grad_norm": 0.7038874626159668,
      "learning_rate": 1.3902409638554218e-05,
      "loss": 0.0166,
      "step": 50610
    },
    {
      "epoch": 6.098795180722892,
      "grad_norm": 0.014497662894427776,
      "learning_rate": 1.390120481927711e-05,
      "loss": 0.0276,
      "step": 50620
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.010867700912058353,
      "learning_rate": 1.39e-05,
      "loss": 0.0323,
      "step": 50630
    },
    {
      "epoch": 6.1012048192771084,
      "grad_norm": 0.8722196221351624,
      "learning_rate": 1.3898795180722893e-05,
      "loss": 0.0769,
      "step": 50640
    },
    {
      "epoch": 6.102409638554217,
      "grad_norm": 0.04924604669213295,
      "learning_rate": 1.3897590361445786e-05,
      "loss": 0.0295,
      "step": 50650
    },
    {
      "epoch": 6.103614457831325,
      "grad_norm": 0.012659315019845963,
      "learning_rate": 1.3896385542168676e-05,
      "loss": 0.0203,
      "step": 50660
    },
    {
      "epoch": 6.104819277108434,
      "grad_norm": 0.006753886118531227,
      "learning_rate": 1.3895180722891569e-05,
      "loss": 0.0113,
      "step": 50670
    },
    {
      "epoch": 6.106024096385542,
      "grad_norm": 0.007106372620910406,
      "learning_rate": 1.3893975903614458e-05,
      "loss": 0.0094,
      "step": 50680
    },
    {
      "epoch": 6.107228915662651,
      "grad_norm": 2.1671273708343506,
      "learning_rate": 1.389277108433735e-05,
      "loss": 0.0575,
      "step": 50690
    },
    {
      "epoch": 6.108433734939759,
      "grad_norm": 8.43122386932373,
      "learning_rate": 1.3891566265060241e-05,
      "loss": 0.0652,
      "step": 50700
    },
    {
      "epoch": 6.109638554216867,
      "grad_norm": 0.5532135963439941,
      "learning_rate": 1.3890361445783133e-05,
      "loss": 0.0288,
      "step": 50710
    },
    {
      "epoch": 6.110843373493976,
      "grad_norm": 0.007929644547402859,
      "learning_rate": 1.3889156626506026e-05,
      "loss": 0.0128,
      "step": 50720
    },
    {
      "epoch": 6.112048192771084,
      "grad_norm": 0.003625866025686264,
      "learning_rate": 1.3887951807228917e-05,
      "loss": 0.0337,
      "step": 50730
    },
    {
      "epoch": 6.113253012048193,
      "grad_norm": 0.3558605909347534,
      "learning_rate": 1.3886746987951809e-05,
      "loss": 0.0684,
      "step": 50740
    },
    {
      "epoch": 6.114457831325301,
      "grad_norm": 0.006777448579668999,
      "learning_rate": 1.38855421686747e-05,
      "loss": 0.0472,
      "step": 50750
    },
    {
      "epoch": 6.11566265060241,
      "grad_norm": 0.03502560406923294,
      "learning_rate": 1.3884337349397592e-05,
      "loss": 0.0281,
      "step": 50760
    },
    {
      "epoch": 6.1168674698795185,
      "grad_norm": 0.24528539180755615,
      "learning_rate": 1.3883132530120483e-05,
      "loss": 0.0274,
      "step": 50770
    },
    {
      "epoch": 6.118072289156626,
      "grad_norm": 5.643462181091309,
      "learning_rate": 1.3881927710843375e-05,
      "loss": 0.0619,
      "step": 50780
    },
    {
      "epoch": 6.119277108433735,
      "grad_norm": 0.014888457953929901,
      "learning_rate": 1.3880722891566268e-05,
      "loss": 0.0224,
      "step": 50790
    },
    {
      "epoch": 6.120481927710843,
      "grad_norm": 0.013119618408381939,
      "learning_rate": 1.3879518072289157e-05,
      "loss": 0.0563,
      "step": 50800
    },
    {
      "epoch": 6.121686746987952,
      "grad_norm": 4.782576560974121,
      "learning_rate": 1.387831325301205e-05,
      "loss": 0.0785,
      "step": 50810
    },
    {
      "epoch": 6.12289156626506,
      "grad_norm": 0.015506603755056858,
      "learning_rate": 1.387710843373494e-05,
      "loss": 0.0502,
      "step": 50820
    },
    {
      "epoch": 6.124096385542169,
      "grad_norm": 0.03832021728157997,
      "learning_rate": 1.3875903614457833e-05,
      "loss": 0.0473,
      "step": 50830
    },
    {
      "epoch": 6.125301204819277,
      "grad_norm": 0.7853325605392456,
      "learning_rate": 1.3874698795180723e-05,
      "loss": 0.024,
      "step": 50840
    },
    {
      "epoch": 6.126506024096385,
      "grad_norm": 0.00810493715107441,
      "learning_rate": 1.3873493975903616e-05,
      "loss": 0.043,
      "step": 50850
    },
    {
      "epoch": 6.127710843373494,
      "grad_norm": 0.5948012471199036,
      "learning_rate": 1.3872289156626506e-05,
      "loss": 0.0712,
      "step": 50860
    },
    {
      "epoch": 6.128915662650602,
      "grad_norm": 2.253443717956543,
      "learning_rate": 1.3871084337349399e-05,
      "loss": 0.0696,
      "step": 50870
    },
    {
      "epoch": 6.130120481927711,
      "grad_norm": 0.015475987456738949,
      "learning_rate": 1.3869879518072291e-05,
      "loss": 0.0028,
      "step": 50880
    },
    {
      "epoch": 6.13132530120482,
      "grad_norm": 6.987908840179443,
      "learning_rate": 1.3868674698795182e-05,
      "loss": 0.0667,
      "step": 50890
    },
    {
      "epoch": 6.132530120481928,
      "grad_norm": 10.23036003112793,
      "learning_rate": 1.3867469879518074e-05,
      "loss": 0.0909,
      "step": 50900
    },
    {
      "epoch": 6.133734939759036,
      "grad_norm": 1.5729992389678955,
      "learning_rate": 1.3866265060240964e-05,
      "loss": 0.0368,
      "step": 50910
    },
    {
      "epoch": 6.134939759036144,
      "grad_norm": 4.7382378578186035,
      "learning_rate": 1.3865060240963858e-05,
      "loss": 0.0156,
      "step": 50920
    },
    {
      "epoch": 6.136144578313253,
      "grad_norm": 0.4895557761192322,
      "learning_rate": 1.3863855421686747e-05,
      "loss": 0.0424,
      "step": 50930
    },
    {
      "epoch": 6.137349397590361,
      "grad_norm": 0.007500364910811186,
      "learning_rate": 1.3862650602409639e-05,
      "loss": 0.0653,
      "step": 50940
    },
    {
      "epoch": 6.13855421686747,
      "grad_norm": 0.010772747918963432,
      "learning_rate": 1.3861445783132532e-05,
      "loss": 0.0073,
      "step": 50950
    },
    {
      "epoch": 6.139759036144579,
      "grad_norm": 2.048701047897339,
      "learning_rate": 1.3860240963855422e-05,
      "loss": 0.0492,
      "step": 50960
    },
    {
      "epoch": 6.1409638554216865,
      "grad_norm": 0.08990602195262909,
      "learning_rate": 1.3859036144578315e-05,
      "loss": 0.0163,
      "step": 50970
    },
    {
      "epoch": 6.142168674698795,
      "grad_norm": 0.10040634870529175,
      "learning_rate": 1.3857831325301205e-05,
      "loss": 0.0451,
      "step": 50980
    },
    {
      "epoch": 6.143373493975903,
      "grad_norm": 0.2090904861688614,
      "learning_rate": 1.3856626506024098e-05,
      "loss": 0.0101,
      "step": 50990
    },
    {
      "epoch": 6.144578313253012,
      "grad_norm": 0.7829410433769226,
      "learning_rate": 1.3855421686746989e-05,
      "loss": 0.0681,
      "step": 51000
    },
    {
      "epoch": 6.145783132530121,
      "grad_norm": 0.14469927549362183,
      "learning_rate": 1.3854216867469881e-05,
      "loss": 0.015,
      "step": 51010
    },
    {
      "epoch": 6.146987951807229,
      "grad_norm": 8.903294563293457,
      "learning_rate": 1.3853012048192774e-05,
      "loss": 0.0304,
      "step": 51020
    },
    {
      "epoch": 6.148192771084338,
      "grad_norm": 7.4288787841796875,
      "learning_rate": 1.3851807228915664e-05,
      "loss": 0.0748,
      "step": 51030
    },
    {
      "epoch": 6.1493975903614455,
      "grad_norm": 1.4699336290359497,
      "learning_rate": 1.3850602409638557e-05,
      "loss": 0.0275,
      "step": 51040
    },
    {
      "epoch": 6.150602409638554,
      "grad_norm": 0.2758926451206207,
      "learning_rate": 1.3849397590361446e-05,
      "loss": 0.0415,
      "step": 51050
    },
    {
      "epoch": 6.151807228915662,
      "grad_norm": 0.00839855894446373,
      "learning_rate": 1.3848192771084338e-05,
      "loss": 0.0373,
      "step": 51060
    },
    {
      "epoch": 6.153012048192771,
      "grad_norm": 0.9224371910095215,
      "learning_rate": 1.3846987951807229e-05,
      "loss": 0.0473,
      "step": 51070
    },
    {
      "epoch": 6.15421686746988,
      "grad_norm": 5.140231132507324,
      "learning_rate": 1.3845783132530121e-05,
      "loss": 0.0158,
      "step": 51080
    },
    {
      "epoch": 6.155421686746988,
      "grad_norm": 0.004237959161400795,
      "learning_rate": 1.3844578313253014e-05,
      "loss": 0.0471,
      "step": 51090
    },
    {
      "epoch": 6.156626506024097,
      "grad_norm": 10.370670318603516,
      "learning_rate": 1.3843373493975905e-05,
      "loss": 0.0775,
      "step": 51100
    },
    {
      "epoch": 6.1578313253012045,
      "grad_norm": 0.5790802240371704,
      "learning_rate": 1.3842168674698797e-05,
      "loss": 0.0117,
      "step": 51110
    },
    {
      "epoch": 6.159036144578313,
      "grad_norm": 0.0799507275223732,
      "learning_rate": 1.3840963855421688e-05,
      "loss": 0.0565,
      "step": 51120
    },
    {
      "epoch": 6.160240963855422,
      "grad_norm": 1.759124755859375,
      "learning_rate": 1.383975903614458e-05,
      "loss": 0.0428,
      "step": 51130
    },
    {
      "epoch": 6.16144578313253,
      "grad_norm": 0.22965404391288757,
      "learning_rate": 1.3838554216867471e-05,
      "loss": 0.0224,
      "step": 51140
    },
    {
      "epoch": 6.162650602409639,
      "grad_norm": 0.06594925373792648,
      "learning_rate": 1.3837349397590363e-05,
      "loss": 0.0234,
      "step": 51150
    },
    {
      "epoch": 6.163855421686747,
      "grad_norm": 0.07867652177810669,
      "learning_rate": 1.3836144578313252e-05,
      "loss": 0.0129,
      "step": 51160
    },
    {
      "epoch": 6.1650602409638555,
      "grad_norm": 0.27817651629447937,
      "learning_rate": 1.3834939759036145e-05,
      "loss": 0.0456,
      "step": 51170
    },
    {
      "epoch": 6.166265060240963,
      "grad_norm": 0.009188038296997547,
      "learning_rate": 1.3833734939759039e-05,
      "loss": 0.0182,
      "step": 51180
    },
    {
      "epoch": 6.167469879518072,
      "grad_norm": 23.413049697875977,
      "learning_rate": 1.3832530120481928e-05,
      "loss": 0.0568,
      "step": 51190
    },
    {
      "epoch": 6.168674698795181,
      "grad_norm": 0.007638947106897831,
      "learning_rate": 1.383132530120482e-05,
      "loss": 0.0162,
      "step": 51200
    },
    {
      "epoch": 6.169879518072289,
      "grad_norm": 0.019535178318619728,
      "learning_rate": 1.3830120481927711e-05,
      "loss": 0.0787,
      "step": 51210
    },
    {
      "epoch": 6.171084337349398,
      "grad_norm": 0.40371236205101013,
      "learning_rate": 1.3828915662650604e-05,
      "loss": 0.0273,
      "step": 51220
    },
    {
      "epoch": 6.172289156626506,
      "grad_norm": 2.664975643157959,
      "learning_rate": 1.3827710843373494e-05,
      "loss": 0.0752,
      "step": 51230
    },
    {
      "epoch": 6.1734939759036145,
      "grad_norm": 2.7319235801696777,
      "learning_rate": 1.3826506024096387e-05,
      "loss": 0.0764,
      "step": 51240
    },
    {
      "epoch": 6.174698795180723,
      "grad_norm": 2.708678722381592,
      "learning_rate": 1.382530120481928e-05,
      "loss": 0.0259,
      "step": 51250
    },
    {
      "epoch": 6.175903614457831,
      "grad_norm": 0.04165143147110939,
      "learning_rate": 1.382409638554217e-05,
      "loss": 0.0276,
      "step": 51260
    },
    {
      "epoch": 6.17710843373494,
      "grad_norm": 4.819253444671631,
      "learning_rate": 1.3822891566265062e-05,
      "loss": 0.0256,
      "step": 51270
    },
    {
      "epoch": 6.178313253012048,
      "grad_norm": 1.7982019186019897,
      "learning_rate": 1.3821686746987953e-05,
      "loss": 0.0275,
      "step": 51280
    },
    {
      "epoch": 6.179518072289157,
      "grad_norm": 0.14629121124744415,
      "learning_rate": 1.3820481927710846e-05,
      "loss": 0.0159,
      "step": 51290
    },
    {
      "epoch": 6.180722891566265,
      "grad_norm": 2.5370938777923584,
      "learning_rate": 1.3819277108433735e-05,
      "loss": 0.0564,
      "step": 51300
    },
    {
      "epoch": 6.1819277108433734,
      "grad_norm": 24.08011245727539,
      "learning_rate": 1.3818072289156627e-05,
      "loss": 0.0341,
      "step": 51310
    },
    {
      "epoch": 6.183132530120482,
      "grad_norm": 0.9060848355293274,
      "learning_rate": 1.381686746987952e-05,
      "loss": 0.0271,
      "step": 51320
    },
    {
      "epoch": 6.18433734939759,
      "grad_norm": 0.8787774443626404,
      "learning_rate": 1.381566265060241e-05,
      "loss": 0.0365,
      "step": 51330
    },
    {
      "epoch": 6.185542168674699,
      "grad_norm": 17.855012893676758,
      "learning_rate": 1.3814457831325303e-05,
      "loss": 0.0384,
      "step": 51340
    },
    {
      "epoch": 6.186746987951807,
      "grad_norm": 0.018553107976913452,
      "learning_rate": 1.3813253012048193e-05,
      "loss": 0.0663,
      "step": 51350
    },
    {
      "epoch": 6.187951807228916,
      "grad_norm": 0.018093077465891838,
      "learning_rate": 1.3812048192771086e-05,
      "loss": 0.008,
      "step": 51360
    },
    {
      "epoch": 6.1891566265060245,
      "grad_norm": 0.08189573138952255,
      "learning_rate": 1.3810843373493977e-05,
      "loss": 0.0223,
      "step": 51370
    },
    {
      "epoch": 6.190361445783132,
      "grad_norm": 0.008446014486253262,
      "learning_rate": 1.3809638554216869e-05,
      "loss": 0.0458,
      "step": 51380
    },
    {
      "epoch": 6.191566265060241,
      "grad_norm": 0.1373968869447708,
      "learning_rate": 1.3808433734939761e-05,
      "loss": 0.0228,
      "step": 51390
    },
    {
      "epoch": 6.192771084337349,
      "grad_norm": 0.11805422604084015,
      "learning_rate": 1.3807228915662652e-05,
      "loss": 0.0187,
      "step": 51400
    },
    {
      "epoch": 6.193975903614458,
      "grad_norm": 15.867871284484863,
      "learning_rate": 1.3806024096385545e-05,
      "loss": 0.0562,
      "step": 51410
    },
    {
      "epoch": 6.195180722891566,
      "grad_norm": 1.6790094375610352,
      "learning_rate": 1.3804819277108434e-05,
      "loss": 0.0699,
      "step": 51420
    },
    {
      "epoch": 6.196385542168675,
      "grad_norm": 0.0708954855799675,
      "learning_rate": 1.3803614457831326e-05,
      "loss": 0.0484,
      "step": 51430
    },
    {
      "epoch": 6.1975903614457835,
      "grad_norm": 2.0752861499786377,
      "learning_rate": 1.3802409638554217e-05,
      "loss": 0.0368,
      "step": 51440
    },
    {
      "epoch": 6.198795180722891,
      "grad_norm": 2.9836018085479736,
      "learning_rate": 1.380120481927711e-05,
      "loss": 0.057,
      "step": 51450
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.17401425540447235,
      "learning_rate": 1.38e-05,
      "loss": 0.0705,
      "step": 51460
    },
    {
      "epoch": 6.201204819277108,
      "grad_norm": 0.1606024205684662,
      "learning_rate": 1.3798795180722892e-05,
      "loss": 0.0107,
      "step": 51470
    },
    {
      "epoch": 6.202409638554217,
      "grad_norm": 0.27812308073043823,
      "learning_rate": 1.3797590361445785e-05,
      "loss": 0.048,
      "step": 51480
    },
    {
      "epoch": 6.203614457831326,
      "grad_norm": 59.36274337768555,
      "learning_rate": 1.3796385542168676e-05,
      "loss": 0.0485,
      "step": 51490
    },
    {
      "epoch": 6.204819277108434,
      "grad_norm": 1.8991787433624268,
      "learning_rate": 1.3795180722891568e-05,
      "loss": 0.025,
      "step": 51500
    },
    {
      "epoch": 6.206024096385542,
      "grad_norm": 0.008461851626634598,
      "learning_rate": 1.3793975903614459e-05,
      "loss": 0.0663,
      "step": 51510
    },
    {
      "epoch": 6.20722891566265,
      "grad_norm": 5.444415092468262,
      "learning_rate": 1.3792771084337351e-05,
      "loss": 0.0537,
      "step": 51520
    },
    {
      "epoch": 6.208433734939759,
      "grad_norm": 13.437149047851562,
      "learning_rate": 1.379156626506024e-05,
      "loss": 0.0747,
      "step": 51530
    },
    {
      "epoch": 6.209638554216867,
      "grad_norm": 2.0914602279663086,
      "learning_rate": 1.3790361445783134e-05,
      "loss": 0.0876,
      "step": 51540
    },
    {
      "epoch": 6.210843373493976,
      "grad_norm": 3.722072124481201,
      "learning_rate": 1.3789156626506027e-05,
      "loss": 0.0801,
      "step": 51550
    },
    {
      "epoch": 6.212048192771085,
      "grad_norm": 0.03025011718273163,
      "learning_rate": 1.3787951807228916e-05,
      "loss": 0.0064,
      "step": 51560
    },
    {
      "epoch": 6.213253012048193,
      "grad_norm": 0.03495427221059799,
      "learning_rate": 1.3786746987951808e-05,
      "loss": 0.0272,
      "step": 51570
    },
    {
      "epoch": 6.214457831325301,
      "grad_norm": 0.029160151258111,
      "learning_rate": 1.3785542168674699e-05,
      "loss": 0.0412,
      "step": 51580
    },
    {
      "epoch": 6.215662650602409,
      "grad_norm": 3.145362615585327,
      "learning_rate": 1.3784337349397592e-05,
      "loss": 0.1178,
      "step": 51590
    },
    {
      "epoch": 6.216867469879518,
      "grad_norm": 1.0882047414779663,
      "learning_rate": 1.3783132530120482e-05,
      "loss": 0.0549,
      "step": 51600
    },
    {
      "epoch": 6.218072289156627,
      "grad_norm": 2.6671998500823975,
      "learning_rate": 1.3781927710843375e-05,
      "loss": 0.0441,
      "step": 51610
    },
    {
      "epoch": 6.219277108433735,
      "grad_norm": 0.1516142636537552,
      "learning_rate": 1.3780722891566267e-05,
      "loss": 0.022,
      "step": 51620
    },
    {
      "epoch": 6.220481927710844,
      "grad_norm": 1.043000340461731,
      "learning_rate": 1.3779518072289158e-05,
      "loss": 0.0207,
      "step": 51630
    },
    {
      "epoch": 6.2216867469879515,
      "grad_norm": 0.22213396430015564,
      "learning_rate": 1.377831325301205e-05,
      "loss": 0.0148,
      "step": 51640
    },
    {
      "epoch": 6.22289156626506,
      "grad_norm": 2.4426729679107666,
      "learning_rate": 1.3777108433734941e-05,
      "loss": 0.0756,
      "step": 51650
    },
    {
      "epoch": 6.224096385542168,
      "grad_norm": 0.14265067875385284,
      "learning_rate": 1.3775903614457833e-05,
      "loss": 0.0334,
      "step": 51660
    },
    {
      "epoch": 6.225301204819277,
      "grad_norm": 2.016371726989746,
      "learning_rate": 1.3774698795180723e-05,
      "loss": 0.0845,
      "step": 51670
    },
    {
      "epoch": 6.226506024096386,
      "grad_norm": 0.8712462782859802,
      "learning_rate": 1.3773493975903615e-05,
      "loss": 0.0855,
      "step": 51680
    },
    {
      "epoch": 6.227710843373494,
      "grad_norm": 1.6295264959335327,
      "learning_rate": 1.3772289156626507e-05,
      "loss": 0.0653,
      "step": 51690
    },
    {
      "epoch": 6.228915662650603,
      "grad_norm": 1.78326416015625,
      "learning_rate": 1.3771084337349398e-05,
      "loss": 0.015,
      "step": 51700
    },
    {
      "epoch": 6.2301204819277105,
      "grad_norm": 1.8860194683074951,
      "learning_rate": 1.376987951807229e-05,
      "loss": 0.0208,
      "step": 51710
    },
    {
      "epoch": 6.231325301204819,
      "grad_norm": 0.028431719169020653,
      "learning_rate": 1.3768674698795181e-05,
      "loss": 0.0582,
      "step": 51720
    },
    {
      "epoch": 6.232530120481928,
      "grad_norm": 0.4594292938709259,
      "learning_rate": 1.3767469879518074e-05,
      "loss": 0.022,
      "step": 51730
    },
    {
      "epoch": 6.233734939759036,
      "grad_norm": 1.4788398742675781,
      "learning_rate": 1.3766265060240964e-05,
      "loss": 0.0181,
      "step": 51740
    },
    {
      "epoch": 6.234939759036145,
      "grad_norm": 5.442503929138184,
      "learning_rate": 1.3765060240963857e-05,
      "loss": 0.0742,
      "step": 51750
    },
    {
      "epoch": 6.236144578313253,
      "grad_norm": 8.008365631103516,
      "learning_rate": 1.3763855421686748e-05,
      "loss": 0.0298,
      "step": 51760
    },
    {
      "epoch": 6.2373493975903616,
      "grad_norm": 5.859031677246094,
      "learning_rate": 1.376265060240964e-05,
      "loss": 0.1114,
      "step": 51770
    },
    {
      "epoch": 6.2385542168674695,
      "grad_norm": 0.07105956226587296,
      "learning_rate": 1.3761445783132533e-05,
      "loss": 0.0549,
      "step": 51780
    },
    {
      "epoch": 6.239759036144578,
      "grad_norm": 0.019149646162986755,
      "learning_rate": 1.3760240963855422e-05,
      "loss": 0.0265,
      "step": 51790
    },
    {
      "epoch": 6.240963855421687,
      "grad_norm": 2.4208667278289795,
      "learning_rate": 1.3759036144578316e-05,
      "loss": 0.0242,
      "step": 51800
    },
    {
      "epoch": 6.242168674698795,
      "grad_norm": 0.4771404564380646,
      "learning_rate": 1.3757831325301205e-05,
      "loss": 0.0281,
      "step": 51810
    },
    {
      "epoch": 6.243373493975904,
      "grad_norm": 0.6749580502510071,
      "learning_rate": 1.3756626506024097e-05,
      "loss": 0.0215,
      "step": 51820
    },
    {
      "epoch": 6.244578313253012,
      "grad_norm": 0.8966636657714844,
      "learning_rate": 1.3755421686746988e-05,
      "loss": 0.0207,
      "step": 51830
    },
    {
      "epoch": 6.2457831325301205,
      "grad_norm": 0.006233810447156429,
      "learning_rate": 1.375421686746988e-05,
      "loss": 0.0204,
      "step": 51840
    },
    {
      "epoch": 6.246987951807229,
      "grad_norm": 3.0109541416168213,
      "learning_rate": 1.3753012048192773e-05,
      "loss": 0.018,
      "step": 51850
    },
    {
      "epoch": 6.248192771084337,
      "grad_norm": 0.00860095676034689,
      "learning_rate": 1.3751807228915664e-05,
      "loss": 0.0224,
      "step": 51860
    },
    {
      "epoch": 6.249397590361446,
      "grad_norm": 0.007124009076505899,
      "learning_rate": 1.3750602409638556e-05,
      "loss": 0.061,
      "step": 51870
    },
    {
      "epoch": 6.250602409638554,
      "grad_norm": 5.421331882476807,
      "learning_rate": 1.3749397590361447e-05,
      "loss": 0.0336,
      "step": 51880
    },
    {
      "epoch": 6.251807228915663,
      "grad_norm": 0.0052564735524356365,
      "learning_rate": 1.3748192771084339e-05,
      "loss": 0.0232,
      "step": 51890
    },
    {
      "epoch": 6.253012048192771,
      "grad_norm": 0.7036604881286621,
      "learning_rate": 1.374698795180723e-05,
      "loss": 0.0617,
      "step": 51900
    },
    {
      "epoch": 6.2542168674698795,
      "grad_norm": 0.008509009145200253,
      "learning_rate": 1.3745783132530122e-05,
      "loss": 0.0208,
      "step": 51910
    },
    {
      "epoch": 6.255421686746988,
      "grad_norm": 17.6346492767334,
      "learning_rate": 1.3744578313253015e-05,
      "loss": 0.0452,
      "step": 51920
    },
    {
      "epoch": 6.256626506024096,
      "grad_norm": 0.18116283416748047,
      "learning_rate": 1.3743373493975904e-05,
      "loss": 0.0442,
      "step": 51930
    },
    {
      "epoch": 6.257831325301205,
      "grad_norm": 2.6568875312805176,
      "learning_rate": 1.3742168674698796e-05,
      "loss": 0.0321,
      "step": 51940
    },
    {
      "epoch": 6.259036144578313,
      "grad_norm": 0.06826679408550262,
      "learning_rate": 1.3740963855421687e-05,
      "loss": 0.0131,
      "step": 51950
    },
    {
      "epoch": 6.260240963855422,
      "grad_norm": 0.03089749813079834,
      "learning_rate": 1.373975903614458e-05,
      "loss": 0.1102,
      "step": 51960
    },
    {
      "epoch": 6.2614457831325305,
      "grad_norm": 3.8542542457580566,
      "learning_rate": 1.373855421686747e-05,
      "loss": 0.0156,
      "step": 51970
    },
    {
      "epoch": 6.2626506024096384,
      "grad_norm": 0.019076919183135033,
      "learning_rate": 1.3737349397590363e-05,
      "loss": 0.0057,
      "step": 51980
    },
    {
      "epoch": 6.263855421686747,
      "grad_norm": 2.382863998413086,
      "learning_rate": 1.3736144578313255e-05,
      "loss": 0.0771,
      "step": 51990
    },
    {
      "epoch": 6.265060240963855,
      "grad_norm": 2.2116148471832275,
      "learning_rate": 1.3734939759036146e-05,
      "loss": 0.0654,
      "step": 52000
    },
    {
      "epoch": 6.266265060240964,
      "grad_norm": 0.26305705308914185,
      "learning_rate": 1.3733734939759038e-05,
      "loss": 0.0235,
      "step": 52010
    },
    {
      "epoch": 6.267469879518072,
      "grad_norm": 0.039989128708839417,
      "learning_rate": 1.3732530120481929e-05,
      "loss": 0.0394,
      "step": 52020
    },
    {
      "epoch": 6.268674698795181,
      "grad_norm": 12.701820373535156,
      "learning_rate": 1.3731325301204821e-05,
      "loss": 0.043,
      "step": 52030
    },
    {
      "epoch": 6.2698795180722895,
      "grad_norm": 3.223313331604004,
      "learning_rate": 1.373012048192771e-05,
      "loss": 0.0476,
      "step": 52040
    },
    {
      "epoch": 6.271084337349397,
      "grad_norm": 0.06774325668811798,
      "learning_rate": 1.3728915662650605e-05,
      "loss": 0.0304,
      "step": 52050
    },
    {
      "epoch": 6.272289156626506,
      "grad_norm": 7.82443904876709,
      "learning_rate": 1.3727710843373494e-05,
      "loss": 0.0172,
      "step": 52060
    },
    {
      "epoch": 6.273493975903614,
      "grad_norm": 0.012352327816188335,
      "learning_rate": 1.3726506024096386e-05,
      "loss": 0.0144,
      "step": 52070
    },
    {
      "epoch": 6.274698795180723,
      "grad_norm": 0.06564325094223022,
      "learning_rate": 1.3725301204819278e-05,
      "loss": 0.0372,
      "step": 52080
    },
    {
      "epoch": 6.275903614457832,
      "grad_norm": 0.9860842227935791,
      "learning_rate": 1.372409638554217e-05,
      "loss": 0.0357,
      "step": 52090
    },
    {
      "epoch": 6.27710843373494,
      "grad_norm": 0.010375415906310081,
      "learning_rate": 1.3722891566265062e-05,
      "loss": 0.0104,
      "step": 52100
    },
    {
      "epoch": 6.2783132530120485,
      "grad_norm": 14.183006286621094,
      "learning_rate": 1.3721686746987952e-05,
      "loss": 0.0524,
      "step": 52110
    },
    {
      "epoch": 6.279518072289156,
      "grad_norm": 0.012210732325911522,
      "learning_rate": 1.3720481927710845e-05,
      "loss": 0.0041,
      "step": 52120
    },
    {
      "epoch": 6.280722891566265,
      "grad_norm": 0.04683523252606392,
      "learning_rate": 1.3719277108433736e-05,
      "loss": 0.0164,
      "step": 52130
    },
    {
      "epoch": 6.281927710843373,
      "grad_norm": 0.012269675731658936,
      "learning_rate": 1.3718072289156628e-05,
      "loss": 0.0089,
      "step": 52140
    },
    {
      "epoch": 6.283132530120482,
      "grad_norm": 0.006325846537947655,
      "learning_rate": 1.371686746987952e-05,
      "loss": 0.0726,
      "step": 52150
    },
    {
      "epoch": 6.284337349397591,
      "grad_norm": 1.103725552558899,
      "learning_rate": 1.3715662650602411e-05,
      "loss": 0.019,
      "step": 52160
    },
    {
      "epoch": 6.285542168674699,
      "grad_norm": 0.22266416251659393,
      "learning_rate": 1.3714457831325304e-05,
      "loss": 0.052,
      "step": 52170
    },
    {
      "epoch": 6.286746987951807,
      "grad_norm": 0.33536624908447266,
      "learning_rate": 1.3713253012048193e-05,
      "loss": 0.0582,
      "step": 52180
    },
    {
      "epoch": 6.287951807228915,
      "grad_norm": 0.39615052938461304,
      "learning_rate": 1.3712048192771085e-05,
      "loss": 0.0485,
      "step": 52190
    },
    {
      "epoch": 6.289156626506024,
      "grad_norm": 0.044696930795907974,
      "learning_rate": 1.3710843373493976e-05,
      "loss": 0.0589,
      "step": 52200
    },
    {
      "epoch": 6.290361445783133,
      "grad_norm": 0.019265176728367805,
      "learning_rate": 1.3709638554216868e-05,
      "loss": 0.0196,
      "step": 52210
    },
    {
      "epoch": 6.291566265060241,
      "grad_norm": 1.4152828454971313,
      "learning_rate": 1.370843373493976e-05,
      "loss": 0.0537,
      "step": 52220
    },
    {
      "epoch": 6.29277108433735,
      "grad_norm": 1.0265891551971436,
      "learning_rate": 1.3707228915662651e-05,
      "loss": 0.0166,
      "step": 52230
    },
    {
      "epoch": 6.293975903614458,
      "grad_norm": 1.1185178756713867,
      "learning_rate": 1.3706024096385544e-05,
      "loss": 0.0324,
      "step": 52240
    },
    {
      "epoch": 6.295180722891566,
      "grad_norm": 2.093939781188965,
      "learning_rate": 1.3704819277108435e-05,
      "loss": 0.0376,
      "step": 52250
    },
    {
      "epoch": 6.296385542168674,
      "grad_norm": 0.021931972354650497,
      "learning_rate": 1.3703614457831327e-05,
      "loss": 0.0204,
      "step": 52260
    },
    {
      "epoch": 6.297590361445783,
      "grad_norm": 0.02819330245256424,
      "learning_rate": 1.3702409638554218e-05,
      "loss": 0.056,
      "step": 52270
    },
    {
      "epoch": 6.298795180722892,
      "grad_norm": 0.9628338813781738,
      "learning_rate": 1.370120481927711e-05,
      "loss": 0.0648,
      "step": 52280
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.07782547175884247,
      "learning_rate": 1.3700000000000003e-05,
      "loss": 0.0588,
      "step": 52290
    },
    {
      "epoch": 6.301204819277109,
      "grad_norm": 0.43888428807258606,
      "learning_rate": 1.3698795180722892e-05,
      "loss": 0.0196,
      "step": 52300
    },
    {
      "epoch": 6.3024096385542165,
      "grad_norm": 4.315052509307861,
      "learning_rate": 1.3697590361445786e-05,
      "loss": 0.0328,
      "step": 52310
    },
    {
      "epoch": 6.303614457831325,
      "grad_norm": 0.6512976288795471,
      "learning_rate": 1.3696385542168675e-05,
      "loss": 0.0116,
      "step": 52320
    },
    {
      "epoch": 6.304819277108434,
      "grad_norm": 0.0867350846529007,
      "learning_rate": 1.3695180722891567e-05,
      "loss": 0.055,
      "step": 52330
    },
    {
      "epoch": 6.306024096385542,
      "grad_norm": 0.024998553097248077,
      "learning_rate": 1.3693975903614458e-05,
      "loss": 0.0127,
      "step": 52340
    },
    {
      "epoch": 6.307228915662651,
      "grad_norm": 8.206613540649414,
      "learning_rate": 1.369277108433735e-05,
      "loss": 0.0579,
      "step": 52350
    },
    {
      "epoch": 6.308433734939759,
      "grad_norm": 4.269313335418701,
      "learning_rate": 1.3691566265060241e-05,
      "loss": 0.05,
      "step": 52360
    },
    {
      "epoch": 6.309638554216868,
      "grad_norm": 2.2028086185455322,
      "learning_rate": 1.3690361445783134e-05,
      "loss": 0.0155,
      "step": 52370
    },
    {
      "epoch": 6.3108433734939755,
      "grad_norm": 0.06834015250205994,
      "learning_rate": 1.3689156626506026e-05,
      "loss": 0.0419,
      "step": 52380
    },
    {
      "epoch": 6.312048192771084,
      "grad_norm": 0.2426978051662445,
      "learning_rate": 1.3687951807228917e-05,
      "loss": 0.0464,
      "step": 52390
    },
    {
      "epoch": 6.313253012048193,
      "grad_norm": 0.4969548285007477,
      "learning_rate": 1.368674698795181e-05,
      "loss": 0.0377,
      "step": 52400
    },
    {
      "epoch": 6.314457831325301,
      "grad_norm": 7.3941144943237305,
      "learning_rate": 1.36855421686747e-05,
      "loss": 0.0724,
      "step": 52410
    },
    {
      "epoch": 6.31566265060241,
      "grad_norm": 2.9938747882843018,
      "learning_rate": 1.3684337349397592e-05,
      "loss": 0.0708,
      "step": 52420
    },
    {
      "epoch": 6.316867469879518,
      "grad_norm": 0.012618848122656345,
      "learning_rate": 1.3683132530120482e-05,
      "loss": 0.0099,
      "step": 52430
    },
    {
      "epoch": 6.3180722891566266,
      "grad_norm": 0.02087901160120964,
      "learning_rate": 1.3681927710843374e-05,
      "loss": 0.0796,
      "step": 52440
    },
    {
      "epoch": 6.3192771084337345,
      "grad_norm": 42.82891845703125,
      "learning_rate": 1.3680722891566266e-05,
      "loss": 0.0316,
      "step": 52450
    },
    {
      "epoch": 6.320481927710843,
      "grad_norm": 0.030914515256881714,
      "learning_rate": 1.3679518072289157e-05,
      "loss": 0.0284,
      "step": 52460
    },
    {
      "epoch": 6.321686746987952,
      "grad_norm": 0.01932935044169426,
      "learning_rate": 1.367831325301205e-05,
      "loss": 0.0544,
      "step": 52470
    },
    {
      "epoch": 6.32289156626506,
      "grad_norm": 0.6112653613090515,
      "learning_rate": 1.367710843373494e-05,
      "loss": 0.0814,
      "step": 52480
    },
    {
      "epoch": 6.324096385542169,
      "grad_norm": 0.1802223026752472,
      "learning_rate": 1.3675903614457833e-05,
      "loss": 0.0649,
      "step": 52490
    },
    {
      "epoch": 6.325301204819277,
      "grad_norm": 1.015878438949585,
      "learning_rate": 1.3674698795180723e-05,
      "loss": 0.0123,
      "step": 52500
    },
    {
      "epoch": 6.3265060240963855,
      "grad_norm": 0.008460866287350655,
      "learning_rate": 1.3673493975903616e-05,
      "loss": 0.0176,
      "step": 52510
    },
    {
      "epoch": 6.327710843373494,
      "grad_norm": 0.023857414722442627,
      "learning_rate": 1.3672289156626508e-05,
      "loss": 0.0046,
      "step": 52520
    },
    {
      "epoch": 6.328915662650602,
      "grad_norm": 0.2167334109544754,
      "learning_rate": 1.3671084337349399e-05,
      "loss": 0.021,
      "step": 52530
    },
    {
      "epoch": 6.330120481927711,
      "grad_norm": 0.17191757261753082,
      "learning_rate": 1.3669879518072292e-05,
      "loss": 0.0522,
      "step": 52540
    },
    {
      "epoch": 6.331325301204819,
      "grad_norm": 1.2807339429855347,
      "learning_rate": 1.366867469879518e-05,
      "loss": 0.0699,
      "step": 52550
    },
    {
      "epoch": 6.332530120481928,
      "grad_norm": 0.01108135748654604,
      "learning_rate": 1.3667469879518073e-05,
      "loss": 0.0768,
      "step": 52560
    },
    {
      "epoch": 6.333734939759037,
      "grad_norm": 0.23805183172225952,
      "learning_rate": 1.3666265060240964e-05,
      "loss": 0.0345,
      "step": 52570
    },
    {
      "epoch": 6.3349397590361445,
      "grad_norm": 0.01987546496093273,
      "learning_rate": 1.3665060240963856e-05,
      "loss": 0.0564,
      "step": 52580
    },
    {
      "epoch": 6.336144578313253,
      "grad_norm": 2.8614354133605957,
      "learning_rate": 1.3663855421686749e-05,
      "loss": 0.0381,
      "step": 52590
    },
    {
      "epoch": 6.337349397590361,
      "grad_norm": 1.619443655014038,
      "learning_rate": 1.366265060240964e-05,
      "loss": 0.0236,
      "step": 52600
    },
    {
      "epoch": 6.33855421686747,
      "grad_norm": 0.20606039464473724,
      "learning_rate": 1.3661445783132532e-05,
      "loss": 0.0156,
      "step": 52610
    },
    {
      "epoch": 6.339759036144578,
      "grad_norm": 0.026173241436481476,
      "learning_rate": 1.3660240963855423e-05,
      "loss": 0.0254,
      "step": 52620
    },
    {
      "epoch": 6.340963855421687,
      "grad_norm": 0.07132532447576523,
      "learning_rate": 1.3659036144578315e-05,
      "loss": 0.0636,
      "step": 52630
    },
    {
      "epoch": 6.3421686746987955,
      "grad_norm": 0.20225460827350616,
      "learning_rate": 1.3657831325301206e-05,
      "loss": 0.045,
      "step": 52640
    },
    {
      "epoch": 6.343373493975903,
      "grad_norm": 0.025097839534282684,
      "learning_rate": 1.3656626506024098e-05,
      "loss": 0.01,
      "step": 52650
    },
    {
      "epoch": 6.344578313253012,
      "grad_norm": 0.007639781571924686,
      "learning_rate": 1.3655421686746987e-05,
      "loss": 0.0184,
      "step": 52660
    },
    {
      "epoch": 6.34578313253012,
      "grad_norm": 0.06205516681075096,
      "learning_rate": 1.3654216867469881e-05,
      "loss": 0.0409,
      "step": 52670
    },
    {
      "epoch": 6.346987951807229,
      "grad_norm": 0.016162224113941193,
      "learning_rate": 1.3653012048192774e-05,
      "loss": 0.0368,
      "step": 52680
    },
    {
      "epoch": 6.348192771084337,
      "grad_norm": 0.01320694014430046,
      "learning_rate": 1.3651807228915663e-05,
      "loss": 0.0487,
      "step": 52690
    },
    {
      "epoch": 6.349397590361446,
      "grad_norm": 5.82891845703125,
      "learning_rate": 1.3650602409638555e-05,
      "loss": 0.0515,
      "step": 52700
    },
    {
      "epoch": 6.3506024096385545,
      "grad_norm": 2.3375489711761475,
      "learning_rate": 1.3649397590361446e-05,
      "loss": 0.0376,
      "step": 52710
    },
    {
      "epoch": 6.351807228915662,
      "grad_norm": 2.082378387451172,
      "learning_rate": 1.3648192771084338e-05,
      "loss": 0.0913,
      "step": 52720
    },
    {
      "epoch": 6.353012048192771,
      "grad_norm": 0.8966354131698608,
      "learning_rate": 1.3646987951807229e-05,
      "loss": 0.0671,
      "step": 52730
    },
    {
      "epoch": 6.354216867469879,
      "grad_norm": 1.034214973449707,
      "learning_rate": 1.3645783132530122e-05,
      "loss": 0.0215,
      "step": 52740
    },
    {
      "epoch": 6.355421686746988,
      "grad_norm": 3.462445020675659,
      "learning_rate": 1.3644578313253014e-05,
      "loss": 0.0242,
      "step": 52750
    },
    {
      "epoch": 6.356626506024097,
      "grad_norm": 0.028767237439751625,
      "learning_rate": 1.3643373493975905e-05,
      "loss": 0.0321,
      "step": 52760
    },
    {
      "epoch": 6.357831325301205,
      "grad_norm": 1.9918725490570068,
      "learning_rate": 1.3642168674698797e-05,
      "loss": 0.0564,
      "step": 52770
    },
    {
      "epoch": 6.3590361445783135,
      "grad_norm": 1.6236454248428345,
      "learning_rate": 1.3640963855421688e-05,
      "loss": 0.012,
      "step": 52780
    },
    {
      "epoch": 6.360240963855421,
      "grad_norm": 1.3436272144317627,
      "learning_rate": 1.363975903614458e-05,
      "loss": 0.0555,
      "step": 52790
    },
    {
      "epoch": 6.36144578313253,
      "grad_norm": 0.07557540386915207,
      "learning_rate": 1.363855421686747e-05,
      "loss": 0.0725,
      "step": 52800
    },
    {
      "epoch": 6.362650602409639,
      "grad_norm": 0.9489858150482178,
      "learning_rate": 1.3637349397590362e-05,
      "loss": 0.0641,
      "step": 52810
    },
    {
      "epoch": 6.363855421686747,
      "grad_norm": 3.551483631134033,
      "learning_rate": 1.3636144578313254e-05,
      "loss": 0.0822,
      "step": 52820
    },
    {
      "epoch": 6.365060240963856,
      "grad_norm": 0.23987352848052979,
      "learning_rate": 1.3634939759036145e-05,
      "loss": 0.0533,
      "step": 52830
    },
    {
      "epoch": 6.366265060240964,
      "grad_norm": 3.6371395587921143,
      "learning_rate": 1.3633734939759037e-05,
      "loss": 0.0138,
      "step": 52840
    },
    {
      "epoch": 6.367469879518072,
      "grad_norm": 0.15330535173416138,
      "learning_rate": 1.3632530120481928e-05,
      "loss": 0.012,
      "step": 52850
    },
    {
      "epoch": 6.36867469879518,
      "grad_norm": 0.6885237097740173,
      "learning_rate": 1.363132530120482e-05,
      "loss": 0.0692,
      "step": 52860
    },
    {
      "epoch": 6.369879518072289,
      "grad_norm": 0.022653287276625633,
      "learning_rate": 1.3630120481927711e-05,
      "loss": 0.095,
      "step": 52870
    },
    {
      "epoch": 6.371084337349398,
      "grad_norm": 1.8208955526351929,
      "learning_rate": 1.3628915662650604e-05,
      "loss": 0.0611,
      "step": 52880
    },
    {
      "epoch": 6.372289156626506,
      "grad_norm": 0.13248710334300995,
      "learning_rate": 1.3627710843373496e-05,
      "loss": 0.0281,
      "step": 52890
    },
    {
      "epoch": 6.373493975903615,
      "grad_norm": 0.18237754702568054,
      "learning_rate": 1.3626506024096387e-05,
      "loss": 0.0771,
      "step": 52900
    },
    {
      "epoch": 6.374698795180723,
      "grad_norm": 0.18285351991653442,
      "learning_rate": 1.362530120481928e-05,
      "loss": 0.0262,
      "step": 52910
    },
    {
      "epoch": 6.375903614457831,
      "grad_norm": 0.0196551401168108,
      "learning_rate": 1.3624096385542168e-05,
      "loss": 0.0574,
      "step": 52920
    },
    {
      "epoch": 6.377108433734939,
      "grad_norm": 1.9563175439834595,
      "learning_rate": 1.3622891566265063e-05,
      "loss": 0.0823,
      "step": 52930
    },
    {
      "epoch": 6.378313253012048,
      "grad_norm": 0.14530719816684723,
      "learning_rate": 1.3621686746987952e-05,
      "loss": 0.0276,
      "step": 52940
    },
    {
      "epoch": 6.379518072289157,
      "grad_norm": 0.11548138409852982,
      "learning_rate": 1.3620481927710844e-05,
      "loss": 0.0684,
      "step": 52950
    },
    {
      "epoch": 6.380722891566265,
      "grad_norm": 0.06421475857496262,
      "learning_rate": 1.3619277108433735e-05,
      "loss": 0.0337,
      "step": 52960
    },
    {
      "epoch": 6.381927710843374,
      "grad_norm": 7.476552963256836,
      "learning_rate": 1.3618072289156627e-05,
      "loss": 0.0278,
      "step": 52970
    },
    {
      "epoch": 6.3831325301204815,
      "grad_norm": 0.11405619233846664,
      "learning_rate": 1.361686746987952e-05,
      "loss": 0.036,
      "step": 52980
    },
    {
      "epoch": 6.38433734939759,
      "grad_norm": 3.4968042373657227,
      "learning_rate": 1.361566265060241e-05,
      "loss": 0.025,
      "step": 52990
    },
    {
      "epoch": 6.385542168674699,
      "grad_norm": 0.3018585741519928,
      "learning_rate": 1.3614457831325303e-05,
      "loss": 0.0376,
      "step": 53000
    },
    {
      "epoch": 6.386746987951807,
      "grad_norm": 0.14337627589702606,
      "learning_rate": 1.3613253012048194e-05,
      "loss": 0.0323,
      "step": 53010
    },
    {
      "epoch": 6.387951807228916,
      "grad_norm": 4.603032112121582,
      "learning_rate": 1.3612048192771086e-05,
      "loss": 0.048,
      "step": 53020
    },
    {
      "epoch": 6.389156626506024,
      "grad_norm": 0.18632648885250092,
      "learning_rate": 1.3610843373493977e-05,
      "loss": 0.0386,
      "step": 53030
    },
    {
      "epoch": 6.390361445783133,
      "grad_norm": 0.5020110607147217,
      "learning_rate": 1.360963855421687e-05,
      "loss": 0.0261,
      "step": 53040
    },
    {
      "epoch": 6.391566265060241,
      "grad_norm": 0.659517228603363,
      "learning_rate": 1.3608433734939762e-05,
      "loss": 0.0302,
      "step": 53050
    },
    {
      "epoch": 6.392771084337349,
      "grad_norm": 0.18998168408870697,
      "learning_rate": 1.360722891566265e-05,
      "loss": 0.048,
      "step": 53060
    },
    {
      "epoch": 6.393975903614458,
      "grad_norm": 0.0635988786816597,
      "learning_rate": 1.3606024096385543e-05,
      "loss": 0.016,
      "step": 53070
    },
    {
      "epoch": 6.395180722891566,
      "grad_norm": 1.2545015811920166,
      "learning_rate": 1.3604819277108434e-05,
      "loss": 0.0584,
      "step": 53080
    },
    {
      "epoch": 6.396385542168675,
      "grad_norm": 0.025405241176486015,
      "learning_rate": 1.3603614457831326e-05,
      "loss": 0.0317,
      "step": 53090
    },
    {
      "epoch": 6.397590361445783,
      "grad_norm": 1.5804578065872192,
      "learning_rate": 1.3602409638554217e-05,
      "loss": 0.0832,
      "step": 53100
    },
    {
      "epoch": 6.3987951807228916,
      "grad_norm": 0.13719618320465088,
      "learning_rate": 1.360120481927711e-05,
      "loss": 0.0681,
      "step": 53110
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.4767677783966064,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0656,
      "step": 53120
    },
    {
      "epoch": 6.401204819277108,
      "grad_norm": 0.19983462989330292,
      "learning_rate": 1.3598795180722893e-05,
      "loss": 0.0094,
      "step": 53130
    },
    {
      "epoch": 6.402409638554217,
      "grad_norm": 0.06016844883561134,
      "learning_rate": 1.3597590361445785e-05,
      "loss": 0.0244,
      "step": 53140
    },
    {
      "epoch": 6.403614457831325,
      "grad_norm": 0.06390263885259628,
      "learning_rate": 1.3596385542168676e-05,
      "loss": 0.0277,
      "step": 53150
    },
    {
      "epoch": 6.404819277108434,
      "grad_norm": 0.04580140858888626,
      "learning_rate": 1.3595180722891568e-05,
      "loss": 0.044,
      "step": 53160
    },
    {
      "epoch": 6.406024096385542,
      "grad_norm": 0.2561829090118408,
      "learning_rate": 1.3593975903614457e-05,
      "loss": 0.0902,
      "step": 53170
    },
    {
      "epoch": 6.4072289156626505,
      "grad_norm": 1.5302650928497314,
      "learning_rate": 1.359277108433735e-05,
      "loss": 0.028,
      "step": 53180
    },
    {
      "epoch": 6.408433734939759,
      "grad_norm": 0.7815589904785156,
      "learning_rate": 1.3591566265060244e-05,
      "loss": 0.0267,
      "step": 53190
    },
    {
      "epoch": 6.409638554216867,
      "grad_norm": 0.06665941327810287,
      "learning_rate": 1.3590361445783133e-05,
      "loss": 0.0243,
      "step": 53200
    },
    {
      "epoch": 6.410843373493976,
      "grad_norm": 1.8058024644851685,
      "learning_rate": 1.3589156626506025e-05,
      "loss": 0.0118,
      "step": 53210
    },
    {
      "epoch": 6.412048192771084,
      "grad_norm": 0.004524369724094868,
      "learning_rate": 1.3587951807228916e-05,
      "loss": 0.0401,
      "step": 53220
    },
    {
      "epoch": 6.413253012048193,
      "grad_norm": 1.2798877954483032,
      "learning_rate": 1.3586746987951809e-05,
      "loss": 0.0309,
      "step": 53230
    },
    {
      "epoch": 6.414457831325302,
      "grad_norm": 0.010410086251795292,
      "learning_rate": 1.35855421686747e-05,
      "loss": 0.0004,
      "step": 53240
    },
    {
      "epoch": 6.4156626506024095,
      "grad_norm": 0.18023908138275146,
      "learning_rate": 1.3584337349397592e-05,
      "loss": 0.0888,
      "step": 53250
    },
    {
      "epoch": 6.416867469879518,
      "grad_norm": 0.01234185229986906,
      "learning_rate": 1.3583132530120482e-05,
      "loss": 0.066,
      "step": 53260
    },
    {
      "epoch": 6.418072289156626,
      "grad_norm": 0.029788589105010033,
      "learning_rate": 1.3581927710843375e-05,
      "loss": 0.0306,
      "step": 53270
    },
    {
      "epoch": 6.419277108433735,
      "grad_norm": 0.06874194741249084,
      "learning_rate": 1.3580722891566267e-05,
      "loss": 0.053,
      "step": 53280
    },
    {
      "epoch": 6.420481927710844,
      "grad_norm": 1.8166639804840088,
      "learning_rate": 1.3579518072289158e-05,
      "loss": 0.0122,
      "step": 53290
    },
    {
      "epoch": 6.421686746987952,
      "grad_norm": 0.015014656819403172,
      "learning_rate": 1.357831325301205e-05,
      "loss": 0.051,
      "step": 53300
    },
    {
      "epoch": 6.4228915662650605,
      "grad_norm": 1.42574143409729,
      "learning_rate": 1.357710843373494e-05,
      "loss": 0.0148,
      "step": 53310
    },
    {
      "epoch": 6.424096385542168,
      "grad_norm": 0.7449402809143066,
      "learning_rate": 1.3575903614457832e-05,
      "loss": 0.029,
      "step": 53320
    },
    {
      "epoch": 6.425301204819277,
      "grad_norm": 4.498558044433594,
      "learning_rate": 1.3574698795180723e-05,
      "loss": 0.0543,
      "step": 53330
    },
    {
      "epoch": 6.426506024096385,
      "grad_norm": 4.860233783721924,
      "learning_rate": 1.3573493975903615e-05,
      "loss": 0.0712,
      "step": 53340
    },
    {
      "epoch": 6.427710843373494,
      "grad_norm": 0.04504725709557533,
      "learning_rate": 1.3572289156626508e-05,
      "loss": 0.0313,
      "step": 53350
    },
    {
      "epoch": 6.428915662650603,
      "grad_norm": 2.678668975830078,
      "learning_rate": 1.3571084337349398e-05,
      "loss": 0.0732,
      "step": 53360
    },
    {
      "epoch": 6.430120481927711,
      "grad_norm": 3.8695244789123535,
      "learning_rate": 1.356987951807229e-05,
      "loss": 0.0313,
      "step": 53370
    },
    {
      "epoch": 6.4313253012048195,
      "grad_norm": 0.05244164168834686,
      "learning_rate": 1.3568674698795182e-05,
      "loss": 0.0136,
      "step": 53380
    },
    {
      "epoch": 6.432530120481927,
      "grad_norm": 0.34579452872276306,
      "learning_rate": 1.3567469879518074e-05,
      "loss": 0.0357,
      "step": 53390
    },
    {
      "epoch": 6.433734939759036,
      "grad_norm": 0.07806843519210815,
      "learning_rate": 1.3566265060240965e-05,
      "loss": 0.0698,
      "step": 53400
    },
    {
      "epoch": 6.434939759036144,
      "grad_norm": 0.17271561920642853,
      "learning_rate": 1.3565060240963857e-05,
      "loss": 0.0124,
      "step": 53410
    },
    {
      "epoch": 6.436144578313253,
      "grad_norm": 0.015137330628931522,
      "learning_rate": 1.356385542168675e-05,
      "loss": 0.0215,
      "step": 53420
    },
    {
      "epoch": 6.437349397590362,
      "grad_norm": 0.03029506281018257,
      "learning_rate": 1.3562650602409639e-05,
      "loss": 0.0734,
      "step": 53430
    },
    {
      "epoch": 6.43855421686747,
      "grad_norm": 0.4263558089733124,
      "learning_rate": 1.3561445783132533e-05,
      "loss": 0.0043,
      "step": 53440
    },
    {
      "epoch": 6.4397590361445785,
      "grad_norm": 0.014527803286910057,
      "learning_rate": 1.3560240963855422e-05,
      "loss": 0.022,
      "step": 53450
    },
    {
      "epoch": 6.440963855421686,
      "grad_norm": 0.020519772544503212,
      "learning_rate": 1.3559036144578314e-05,
      "loss": 0.0457,
      "step": 53460
    },
    {
      "epoch": 6.442168674698795,
      "grad_norm": 1.520072340965271,
      "learning_rate": 1.3557831325301205e-05,
      "loss": 0.0672,
      "step": 53470
    },
    {
      "epoch": 6.443373493975904,
      "grad_norm": 0.6551018953323364,
      "learning_rate": 1.3556626506024097e-05,
      "loss": 0.0055,
      "step": 53480
    },
    {
      "epoch": 6.444578313253012,
      "grad_norm": 0.01567063294351101,
      "learning_rate": 1.355542168674699e-05,
      "loss": 0.0469,
      "step": 53490
    },
    {
      "epoch": 6.445783132530121,
      "grad_norm": 0.06023247912526131,
      "learning_rate": 1.355421686746988e-05,
      "loss": 0.0755,
      "step": 53500
    },
    {
      "epoch": 6.446987951807229,
      "grad_norm": 12.554969787597656,
      "learning_rate": 1.3553012048192773e-05,
      "loss": 0.1016,
      "step": 53510
    },
    {
      "epoch": 6.448192771084337,
      "grad_norm": 0.09517768025398254,
      "learning_rate": 1.3551807228915664e-05,
      "loss": 0.0468,
      "step": 53520
    },
    {
      "epoch": 6.449397590361446,
      "grad_norm": 0.01910249888896942,
      "learning_rate": 1.3550602409638556e-05,
      "loss": 0.02,
      "step": 53530
    },
    {
      "epoch": 6.450602409638554,
      "grad_norm": 6.6545491218566895,
      "learning_rate": 1.3549397590361447e-05,
      "loss": 0.0202,
      "step": 53540
    },
    {
      "epoch": 6.451807228915663,
      "grad_norm": 0.028975538909435272,
      "learning_rate": 1.354819277108434e-05,
      "loss": 0.0435,
      "step": 53550
    },
    {
      "epoch": 6.453012048192771,
      "grad_norm": 0.5728076696395874,
      "learning_rate": 1.3546987951807228e-05,
      "loss": 0.0116,
      "step": 53560
    },
    {
      "epoch": 6.45421686746988,
      "grad_norm": 0.021846769377589226,
      "learning_rate": 1.354578313253012e-05,
      "loss": 0.062,
      "step": 53570
    },
    {
      "epoch": 6.455421686746988,
      "grad_norm": 0.7901938557624817,
      "learning_rate": 1.3544578313253013e-05,
      "loss": 0.0294,
      "step": 53580
    },
    {
      "epoch": 6.456626506024096,
      "grad_norm": 0.19752758741378784,
      "learning_rate": 1.3543373493975904e-05,
      "loss": 0.0113,
      "step": 53590
    },
    {
      "epoch": 6.457831325301205,
      "grad_norm": 0.07761669158935547,
      "learning_rate": 1.3542168674698796e-05,
      "loss": 0.0167,
      "step": 53600
    },
    {
      "epoch": 6.459036144578313,
      "grad_norm": 0.006165713537484407,
      "learning_rate": 1.3540963855421687e-05,
      "loss": 0.0275,
      "step": 53610
    },
    {
      "epoch": 6.460240963855422,
      "grad_norm": 0.033784396946430206,
      "learning_rate": 1.353975903614458e-05,
      "loss": 0.0371,
      "step": 53620
    },
    {
      "epoch": 6.46144578313253,
      "grad_norm": 3.4092979431152344,
      "learning_rate": 1.353855421686747e-05,
      "loss": 0.0568,
      "step": 53630
    },
    {
      "epoch": 6.462650602409639,
      "grad_norm": 0.016650011762976646,
      "learning_rate": 1.3537349397590363e-05,
      "loss": 0.0037,
      "step": 53640
    },
    {
      "epoch": 6.4638554216867465,
      "grad_norm": 0.03828352317214012,
      "learning_rate": 1.3536144578313255e-05,
      "loss": 0.0372,
      "step": 53650
    },
    {
      "epoch": 6.465060240963855,
      "grad_norm": 4.135827541351318,
      "learning_rate": 1.3534939759036146e-05,
      "loss": 0.0127,
      "step": 53660
    },
    {
      "epoch": 6.466265060240964,
      "grad_norm": 0.04294257238507271,
      "learning_rate": 1.3533734939759038e-05,
      "loss": 0.02,
      "step": 53670
    },
    {
      "epoch": 6.467469879518072,
      "grad_norm": 1.6853922605514526,
      "learning_rate": 1.3532530120481927e-05,
      "loss": 0.063,
      "step": 53680
    },
    {
      "epoch": 6.468674698795181,
      "grad_norm": 5.012300491333008,
      "learning_rate": 1.353132530120482e-05,
      "loss": 0.0313,
      "step": 53690
    },
    {
      "epoch": 6.469879518072289,
      "grad_norm": 1.8907431364059448,
      "learning_rate": 1.353012048192771e-05,
      "loss": 0.0566,
      "step": 53700
    },
    {
      "epoch": 6.471084337349398,
      "grad_norm": 0.006665248889476061,
      "learning_rate": 1.3528915662650603e-05,
      "loss": 0.0207,
      "step": 53710
    },
    {
      "epoch": 6.472289156626506,
      "grad_norm": 0.08614630252122879,
      "learning_rate": 1.3527710843373496e-05,
      "loss": 0.0118,
      "step": 53720
    },
    {
      "epoch": 6.473493975903614,
      "grad_norm": 3.2633204460144043,
      "learning_rate": 1.3526506024096386e-05,
      "loss": 0.0566,
      "step": 53730
    },
    {
      "epoch": 6.474698795180723,
      "grad_norm": 1.2650262117385864,
      "learning_rate": 1.3525301204819279e-05,
      "loss": 0.0566,
      "step": 53740
    },
    {
      "epoch": 6.475903614457831,
      "grad_norm": 0.16902531683444977,
      "learning_rate": 1.352409638554217e-05,
      "loss": 0.0405,
      "step": 53750
    },
    {
      "epoch": 6.47710843373494,
      "grad_norm": 0.44841083884239197,
      "learning_rate": 1.3522891566265062e-05,
      "loss": 0.0225,
      "step": 53760
    },
    {
      "epoch": 6.478313253012049,
      "grad_norm": 0.42346927523612976,
      "learning_rate": 1.3521686746987953e-05,
      "loss": 0.0408,
      "step": 53770
    },
    {
      "epoch": 6.4795180722891565,
      "grad_norm": 0.11552289873361588,
      "learning_rate": 1.3520481927710845e-05,
      "loss": 0.0329,
      "step": 53780
    },
    {
      "epoch": 6.480722891566265,
      "grad_norm": 20.521743774414062,
      "learning_rate": 1.3519277108433737e-05,
      "loss": 0.0191,
      "step": 53790
    },
    {
      "epoch": 6.481927710843373,
      "grad_norm": 0.2742895185947418,
      "learning_rate": 1.3518072289156628e-05,
      "loss": 0.0502,
      "step": 53800
    },
    {
      "epoch": 6.483132530120482,
      "grad_norm": 1.7467854022979736,
      "learning_rate": 1.351686746987952e-05,
      "loss": 0.0527,
      "step": 53810
    },
    {
      "epoch": 6.48433734939759,
      "grad_norm": 1.5782777070999146,
      "learning_rate": 1.351566265060241e-05,
      "loss": 0.0502,
      "step": 53820
    },
    {
      "epoch": 6.485542168674699,
      "grad_norm": 0.19109810888767242,
      "learning_rate": 1.3514457831325302e-05,
      "loss": 0.014,
      "step": 53830
    },
    {
      "epoch": 6.486746987951808,
      "grad_norm": 6.233851909637451,
      "learning_rate": 1.3513253012048193e-05,
      "loss": 0.0504,
      "step": 53840
    },
    {
      "epoch": 6.4879518072289155,
      "grad_norm": 1.318172812461853,
      "learning_rate": 1.3512048192771085e-05,
      "loss": 0.0163,
      "step": 53850
    },
    {
      "epoch": 6.489156626506024,
      "grad_norm": 0.013235986232757568,
      "learning_rate": 1.3510843373493976e-05,
      "loss": 0.0138,
      "step": 53860
    },
    {
      "epoch": 6.490361445783132,
      "grad_norm": 0.29396191239356995,
      "learning_rate": 1.3509638554216868e-05,
      "loss": 0.0194,
      "step": 53870
    },
    {
      "epoch": 6.491566265060241,
      "grad_norm": 0.746577799320221,
      "learning_rate": 1.3508433734939761e-05,
      "loss": 0.0303,
      "step": 53880
    },
    {
      "epoch": 6.492771084337349,
      "grad_norm": 0.7893328070640564,
      "learning_rate": 1.3507228915662652e-05,
      "loss": 0.0271,
      "step": 53890
    },
    {
      "epoch": 6.493975903614458,
      "grad_norm": 0.4591406285762787,
      "learning_rate": 1.3506024096385544e-05,
      "loss": 0.0548,
      "step": 53900
    },
    {
      "epoch": 6.495180722891567,
      "grad_norm": 0.006514632608741522,
      "learning_rate": 1.3504819277108435e-05,
      "loss": 0.0167,
      "step": 53910
    },
    {
      "epoch": 6.4963855421686745,
      "grad_norm": 0.48270124197006226,
      "learning_rate": 1.3503614457831327e-05,
      "loss": 0.0473,
      "step": 53920
    },
    {
      "epoch": 6.497590361445783,
      "grad_norm": 0.04657275974750519,
      "learning_rate": 1.3502409638554216e-05,
      "loss": 0.0186,
      "step": 53930
    },
    {
      "epoch": 6.498795180722891,
      "grad_norm": 1.2741445302963257,
      "learning_rate": 1.3501204819277109e-05,
      "loss": 0.0195,
      "step": 53940
    },
    {
      "epoch": 6.5,
      "grad_norm": 21.591886520385742,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0443,
      "step": 53950
    },
    {
      "epoch": 6.501204819277109,
      "grad_norm": 0.8684560656547546,
      "learning_rate": 1.3498795180722892e-05,
      "loss": 0.0053,
      "step": 53960
    },
    {
      "epoch": 6.502409638554217,
      "grad_norm": 0.025299200788140297,
      "learning_rate": 1.3497590361445784e-05,
      "loss": 0.0588,
      "step": 53970
    },
    {
      "epoch": 6.5036144578313255,
      "grad_norm": 0.047886718064546585,
      "learning_rate": 1.3496385542168675e-05,
      "loss": 0.0506,
      "step": 53980
    },
    {
      "epoch": 6.504819277108433,
      "grad_norm": 0.022760014981031418,
      "learning_rate": 1.3495180722891568e-05,
      "loss": 0.065,
      "step": 53990
    },
    {
      "epoch": 6.506024096385542,
      "grad_norm": 0.06520740687847137,
      "learning_rate": 1.3493975903614458e-05,
      "loss": 0.0264,
      "step": 54000
    },
    {
      "epoch": 6.507228915662651,
      "grad_norm": 0.4904472231864929,
      "learning_rate": 1.349277108433735e-05,
      "loss": 0.0787,
      "step": 54010
    },
    {
      "epoch": 6.508433734939759,
      "grad_norm": 0.19189265370368958,
      "learning_rate": 1.3491566265060243e-05,
      "loss": 0.0181,
      "step": 54020
    },
    {
      "epoch": 6.509638554216868,
      "grad_norm": 1.696574330329895,
      "learning_rate": 1.3490361445783134e-05,
      "loss": 0.0582,
      "step": 54030
    },
    {
      "epoch": 6.510843373493976,
      "grad_norm": 0.14779995381832123,
      "learning_rate": 1.3489156626506026e-05,
      "loss": 0.0468,
      "step": 54040
    },
    {
      "epoch": 6.5120481927710845,
      "grad_norm": 0.36101463437080383,
      "learning_rate": 1.3487951807228915e-05,
      "loss": 0.024,
      "step": 54050
    },
    {
      "epoch": 6.513253012048192,
      "grad_norm": 0.007684207055717707,
      "learning_rate": 1.348674698795181e-05,
      "loss": 0.0582,
      "step": 54060
    },
    {
      "epoch": 6.514457831325301,
      "grad_norm": 0.5902805924415588,
      "learning_rate": 1.3485542168674699e-05,
      "loss": 0.0322,
      "step": 54070
    },
    {
      "epoch": 6.51566265060241,
      "grad_norm": 12.606216430664062,
      "learning_rate": 1.3484337349397591e-05,
      "loss": 0.0899,
      "step": 54080
    },
    {
      "epoch": 6.516867469879518,
      "grad_norm": 1.9965221881866455,
      "learning_rate": 1.3483132530120483e-05,
      "loss": 0.0323,
      "step": 54090
    },
    {
      "epoch": 6.518072289156627,
      "grad_norm": 0.01014647725969553,
      "learning_rate": 1.3481927710843374e-05,
      "loss": 0.0012,
      "step": 54100
    },
    {
      "epoch": 6.519277108433735,
      "grad_norm": 0.10952223092317581,
      "learning_rate": 1.3480722891566267e-05,
      "loss": 0.055,
      "step": 54110
    },
    {
      "epoch": 6.5204819277108435,
      "grad_norm": 0.018105175346136093,
      "learning_rate": 1.3479518072289157e-05,
      "loss": 0.0294,
      "step": 54120
    },
    {
      "epoch": 6.521686746987951,
      "grad_norm": 0.4440429210662842,
      "learning_rate": 1.347831325301205e-05,
      "loss": 0.0392,
      "step": 54130
    },
    {
      "epoch": 6.52289156626506,
      "grad_norm": 3.6723086833953857,
      "learning_rate": 1.347710843373494e-05,
      "loss": 0.0655,
      "step": 54140
    },
    {
      "epoch": 6.524096385542169,
      "grad_norm": 78.0615234375,
      "learning_rate": 1.3475903614457833e-05,
      "loss": 0.0554,
      "step": 54150
    },
    {
      "epoch": 6.525301204819277,
      "grad_norm": 5.026379585266113,
      "learning_rate": 1.3474698795180725e-05,
      "loss": 0.0482,
      "step": 54160
    },
    {
      "epoch": 6.526506024096386,
      "grad_norm": 0.10717243701219559,
      "learning_rate": 1.3473493975903616e-05,
      "loss": 0.0342,
      "step": 54170
    },
    {
      "epoch": 6.527710843373494,
      "grad_norm": 3.0588533878326416,
      "learning_rate": 1.3472289156626509e-05,
      "loss": 0.0917,
      "step": 54180
    },
    {
      "epoch": 6.528915662650602,
      "grad_norm": 1.9857749938964844,
      "learning_rate": 1.3471084337349398e-05,
      "loss": 0.0313,
      "step": 54190
    },
    {
      "epoch": 6.530120481927711,
      "grad_norm": 0.8279203772544861,
      "learning_rate": 1.346987951807229e-05,
      "loss": 0.015,
      "step": 54200
    },
    {
      "epoch": 6.531325301204819,
      "grad_norm": 0.015995968133211136,
      "learning_rate": 1.346867469879518e-05,
      "loss": 0.0427,
      "step": 54210
    },
    {
      "epoch": 6.532530120481928,
      "grad_norm": 0.9294509291648865,
      "learning_rate": 1.3467469879518073e-05,
      "loss": 0.0354,
      "step": 54220
    },
    {
      "epoch": 6.533734939759036,
      "grad_norm": 0.011753629893064499,
      "learning_rate": 1.3466265060240964e-05,
      "loss": 0.0371,
      "step": 54230
    },
    {
      "epoch": 6.534939759036145,
      "grad_norm": 0.01910187117755413,
      "learning_rate": 1.3465060240963856e-05,
      "loss": 0.0218,
      "step": 54240
    },
    {
      "epoch": 6.5361445783132535,
      "grad_norm": 1.203354835510254,
      "learning_rate": 1.3463855421686749e-05,
      "loss": 0.0331,
      "step": 54250
    },
    {
      "epoch": 6.537349397590361,
      "grad_norm": 0.3727430999279022,
      "learning_rate": 1.346265060240964e-05,
      "loss": 0.0726,
      "step": 54260
    },
    {
      "epoch": 6.53855421686747,
      "grad_norm": 0.0636080801486969,
      "learning_rate": 1.3461445783132532e-05,
      "loss": 0.069,
      "step": 54270
    },
    {
      "epoch": 6.539759036144578,
      "grad_norm": 0.10868772864341736,
      "learning_rate": 1.3460240963855423e-05,
      "loss": 0.0374,
      "step": 54280
    },
    {
      "epoch": 6.540963855421687,
      "grad_norm": 0.38081488013267517,
      "learning_rate": 1.3459036144578315e-05,
      "loss": 0.0234,
      "step": 54290
    },
    {
      "epoch": 6.542168674698795,
      "grad_norm": 0.06781467795372009,
      "learning_rate": 1.3457831325301204e-05,
      "loss": 0.0714,
      "step": 54300
    },
    {
      "epoch": 6.543373493975904,
      "grad_norm": 0.030170800164341927,
      "learning_rate": 1.3456626506024097e-05,
      "loss": 0.0161,
      "step": 54310
    },
    {
      "epoch": 6.544578313253012,
      "grad_norm": 0.01900072954595089,
      "learning_rate": 1.345542168674699e-05,
      "loss": 0.0375,
      "step": 54320
    },
    {
      "epoch": 6.54578313253012,
      "grad_norm": 0.010374384932219982,
      "learning_rate": 1.345421686746988e-05,
      "loss": 0.0091,
      "step": 54330
    },
    {
      "epoch": 6.546987951807229,
      "grad_norm": 1.888532042503357,
      "learning_rate": 1.3453012048192772e-05,
      "loss": 0.005,
      "step": 54340
    },
    {
      "epoch": 6.548192771084337,
      "grad_norm": 4.48237943649292,
      "learning_rate": 1.3451807228915663e-05,
      "loss": 0.0393,
      "step": 54350
    },
    {
      "epoch": 6.549397590361446,
      "grad_norm": 0.055466048419475555,
      "learning_rate": 1.3450602409638555e-05,
      "loss": 0.0733,
      "step": 54360
    },
    {
      "epoch": 6.550602409638554,
      "grad_norm": 5.059256553649902,
      "learning_rate": 1.3449397590361446e-05,
      "loss": 0.0441,
      "step": 54370
    },
    {
      "epoch": 6.551807228915663,
      "grad_norm": 0.033113475888967514,
      "learning_rate": 1.3448192771084339e-05,
      "loss": 0.0431,
      "step": 54380
    },
    {
      "epoch": 6.553012048192771,
      "grad_norm": 0.5928160548210144,
      "learning_rate": 1.3446987951807231e-05,
      "loss": 0.0261,
      "step": 54390
    },
    {
      "epoch": 6.554216867469879,
      "grad_norm": 0.463255375623703,
      "learning_rate": 1.3445783132530122e-05,
      "loss": 0.0042,
      "step": 54400
    },
    {
      "epoch": 6.555421686746988,
      "grad_norm": 0.007388238795101643,
      "learning_rate": 1.3444578313253014e-05,
      "loss": 0.0167,
      "step": 54410
    },
    {
      "epoch": 6.556626506024096,
      "grad_norm": 4.711589813232422,
      "learning_rate": 1.3443373493975905e-05,
      "loss": 0.063,
      "step": 54420
    },
    {
      "epoch": 6.557831325301205,
      "grad_norm": 0.4106498658657074,
      "learning_rate": 1.3442168674698797e-05,
      "loss": 0.0332,
      "step": 54430
    },
    {
      "epoch": 6.559036144578314,
      "grad_norm": 0.05376935005187988,
      "learning_rate": 1.3440963855421686e-05,
      "loss": 0.0347,
      "step": 54440
    },
    {
      "epoch": 6.5602409638554215,
      "grad_norm": 5.757789134979248,
      "learning_rate": 1.3439759036144579e-05,
      "loss": 0.0555,
      "step": 54450
    },
    {
      "epoch": 6.56144578313253,
      "grad_norm": 0.042251795530319214,
      "learning_rate": 1.3438554216867471e-05,
      "loss": 0.0119,
      "step": 54460
    },
    {
      "epoch": 6.562650602409638,
      "grad_norm": 7.633467197418213,
      "learning_rate": 1.3437349397590362e-05,
      "loss": 0.0971,
      "step": 54470
    },
    {
      "epoch": 6.563855421686747,
      "grad_norm": 1.4931308031082153,
      "learning_rate": 1.3436144578313255e-05,
      "loss": 0.0107,
      "step": 54480
    },
    {
      "epoch": 6.565060240963856,
      "grad_norm": 0.14997966587543488,
      "learning_rate": 1.3434939759036145e-05,
      "loss": 0.0184,
      "step": 54490
    },
    {
      "epoch": 6.566265060240964,
      "grad_norm": 0.05863136798143387,
      "learning_rate": 1.3433734939759038e-05,
      "loss": 0.0233,
      "step": 54500
    },
    {
      "epoch": 6.567469879518073,
      "grad_norm": 0.04724041745066643,
      "learning_rate": 1.3432530120481928e-05,
      "loss": 0.0189,
      "step": 54510
    },
    {
      "epoch": 6.5686746987951805,
      "grad_norm": 1.5218828916549683,
      "learning_rate": 1.3431325301204821e-05,
      "loss": 0.0521,
      "step": 54520
    },
    {
      "epoch": 6.569879518072289,
      "grad_norm": 0.8859556317329407,
      "learning_rate": 1.3430120481927712e-05,
      "loss": 0.0584,
      "step": 54530
    },
    {
      "epoch": 6.571084337349397,
      "grad_norm": 3.11006236076355,
      "learning_rate": 1.3428915662650604e-05,
      "loss": 0.0743,
      "step": 54540
    },
    {
      "epoch": 6.572289156626506,
      "grad_norm": 0.03139543905854225,
      "learning_rate": 1.3427710843373496e-05,
      "loss": 0.0428,
      "step": 54550
    },
    {
      "epoch": 6.573493975903615,
      "grad_norm": 0.02111539989709854,
      "learning_rate": 1.3426506024096386e-05,
      "loss": 0.06,
      "step": 54560
    },
    {
      "epoch": 6.574698795180723,
      "grad_norm": 0.2179121971130371,
      "learning_rate": 1.3425301204819278e-05,
      "loss": 0.0182,
      "step": 54570
    },
    {
      "epoch": 6.575903614457832,
      "grad_norm": 23.789508819580078,
      "learning_rate": 1.3424096385542169e-05,
      "loss": 0.0615,
      "step": 54580
    },
    {
      "epoch": 6.5771084337349395,
      "grad_norm": 0.008151589892804623,
      "learning_rate": 1.3422891566265061e-05,
      "loss": 0.0118,
      "step": 54590
    },
    {
      "epoch": 6.578313253012048,
      "grad_norm": 1.593308448791504,
      "learning_rate": 1.3421686746987952e-05,
      "loss": 0.0703,
      "step": 54600
    },
    {
      "epoch": 6.579518072289156,
      "grad_norm": 0.3899240493774414,
      "learning_rate": 1.3420481927710844e-05,
      "loss": 0.0602,
      "step": 54610
    },
    {
      "epoch": 6.580722891566265,
      "grad_norm": 0.054900214076042175,
      "learning_rate": 1.3419277108433737e-05,
      "loss": 0.0937,
      "step": 54620
    },
    {
      "epoch": 6.581927710843374,
      "grad_norm": 9.169499397277832,
      "learning_rate": 1.3418072289156627e-05,
      "loss": 0.0368,
      "step": 54630
    },
    {
      "epoch": 6.583132530120482,
      "grad_norm": 73.3342056274414,
      "learning_rate": 1.341686746987952e-05,
      "loss": 0.038,
      "step": 54640
    },
    {
      "epoch": 6.5843373493975905,
      "grad_norm": 0.21661078929901123,
      "learning_rate": 1.341566265060241e-05,
      "loss": 0.0315,
      "step": 54650
    },
    {
      "epoch": 6.585542168674698,
      "grad_norm": 15.86652946472168,
      "learning_rate": 1.3414457831325303e-05,
      "loss": 0.0424,
      "step": 54660
    },
    {
      "epoch": 6.586746987951807,
      "grad_norm": 0.09791933745145798,
      "learning_rate": 1.3413253012048192e-05,
      "loss": 0.0794,
      "step": 54670
    },
    {
      "epoch": 6.587951807228916,
      "grad_norm": 0.038360610604286194,
      "learning_rate": 1.3412048192771086e-05,
      "loss": 0.0805,
      "step": 54680
    },
    {
      "epoch": 6.589156626506024,
      "grad_norm": 0.07409295439720154,
      "learning_rate": 1.3410843373493979e-05,
      "loss": 0.0184,
      "step": 54690
    },
    {
      "epoch": 6.590361445783133,
      "grad_norm": 0.4039231538772583,
      "learning_rate": 1.3409638554216868e-05,
      "loss": 0.0104,
      "step": 54700
    },
    {
      "epoch": 6.591566265060241,
      "grad_norm": 0.23251958191394806,
      "learning_rate": 1.340843373493976e-05,
      "loss": 0.0467,
      "step": 54710
    },
    {
      "epoch": 6.5927710843373495,
      "grad_norm": 1.6005159616470337,
      "learning_rate": 1.3407228915662651e-05,
      "loss": 0.0156,
      "step": 54720
    },
    {
      "epoch": 6.593975903614458,
      "grad_norm": 2.599806308746338,
      "learning_rate": 1.3406024096385543e-05,
      "loss": 0.108,
      "step": 54730
    },
    {
      "epoch": 6.595180722891566,
      "grad_norm": 0.0876195877790451,
      "learning_rate": 1.3404819277108434e-05,
      "loss": 0.025,
      "step": 54740
    },
    {
      "epoch": 6.596385542168675,
      "grad_norm": 0.1597120463848114,
      "learning_rate": 1.3403614457831327e-05,
      "loss": 0.0303,
      "step": 54750
    },
    {
      "epoch": 6.597590361445783,
      "grad_norm": 0.040861159563064575,
      "learning_rate": 1.3402409638554219e-05,
      "loss": 0.0673,
      "step": 54760
    },
    {
      "epoch": 6.598795180722892,
      "grad_norm": 0.16476763784885406,
      "learning_rate": 1.340120481927711e-05,
      "loss": 0.0203,
      "step": 54770
    },
    {
      "epoch": 6.6,
      "grad_norm": 1.7368892431259155,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0678,
      "step": 54780
    },
    {
      "epoch": 6.6012048192771084,
      "grad_norm": 1.4654816389083862,
      "learning_rate": 1.3398795180722893e-05,
      "loss": 0.0337,
      "step": 54790
    },
    {
      "epoch": 6.602409638554217,
      "grad_norm": 1.981600046157837,
      "learning_rate": 1.3397590361445785e-05,
      "loss": 0.0683,
      "step": 54800
    },
    {
      "epoch": 6.603614457831325,
      "grad_norm": 0.4426287114620209,
      "learning_rate": 1.3396385542168674e-05,
      "loss": 0.0363,
      "step": 54810
    },
    {
      "epoch": 6.604819277108434,
      "grad_norm": 0.1344285011291504,
      "learning_rate": 1.3395180722891567e-05,
      "loss": 0.0384,
      "step": 54820
    },
    {
      "epoch": 6.606024096385542,
      "grad_norm": 1.4106335639953613,
      "learning_rate": 1.3393975903614458e-05,
      "loss": 0.0755,
      "step": 54830
    },
    {
      "epoch": 6.607228915662651,
      "grad_norm": 0.007857316173613071,
      "learning_rate": 1.339277108433735e-05,
      "loss": 0.0223,
      "step": 54840
    },
    {
      "epoch": 6.608433734939759,
      "grad_norm": 0.0717899277806282,
      "learning_rate": 1.3391566265060242e-05,
      "loss": 0.04,
      "step": 54850
    },
    {
      "epoch": 6.609638554216867,
      "grad_norm": 0.009203732945024967,
      "learning_rate": 1.3390361445783133e-05,
      "loss": 0.0395,
      "step": 54860
    },
    {
      "epoch": 6.610843373493976,
      "grad_norm": 0.044183723628520966,
      "learning_rate": 1.3389156626506026e-05,
      "loss": 0.038,
      "step": 54870
    },
    {
      "epoch": 6.612048192771084,
      "grad_norm": 8.294288635253906,
      "learning_rate": 1.3387951807228916e-05,
      "loss": 0.0386,
      "step": 54880
    },
    {
      "epoch": 6.613253012048193,
      "grad_norm": 0.40887391567230225,
      "learning_rate": 1.3386746987951809e-05,
      "loss": 0.0075,
      "step": 54890
    },
    {
      "epoch": 6.614457831325301,
      "grad_norm": 2.30983567237854,
      "learning_rate": 1.33855421686747e-05,
      "loss": 0.0835,
      "step": 54900
    },
    {
      "epoch": 6.61566265060241,
      "grad_norm": 0.007238547783344984,
      "learning_rate": 1.3384337349397592e-05,
      "loss": 0.0336,
      "step": 54910
    },
    {
      "epoch": 6.6168674698795185,
      "grad_norm": 0.00588695565238595,
      "learning_rate": 1.3383132530120484e-05,
      "loss": 0.046,
      "step": 54920
    },
    {
      "epoch": 6.618072289156626,
      "grad_norm": 0.6660089492797852,
      "learning_rate": 1.3381927710843375e-05,
      "loss": 0.0654,
      "step": 54930
    },
    {
      "epoch": 6.619277108433735,
      "grad_norm": 0.02126343734562397,
      "learning_rate": 1.3380722891566268e-05,
      "loss": 0.0188,
      "step": 54940
    },
    {
      "epoch": 6.620481927710843,
      "grad_norm": 0.13235758244991302,
      "learning_rate": 1.3379518072289157e-05,
      "loss": 0.0226,
      "step": 54950
    },
    {
      "epoch": 6.621686746987952,
      "grad_norm": 0.012549181468784809,
      "learning_rate": 1.3378313253012049e-05,
      "loss": 0.003,
      "step": 54960
    },
    {
      "epoch": 6.622891566265061,
      "grad_norm": 0.05186081677675247,
      "learning_rate": 1.337710843373494e-05,
      "loss": 0.0443,
      "step": 54970
    },
    {
      "epoch": 6.624096385542169,
      "grad_norm": 0.014890709891915321,
      "learning_rate": 1.3375903614457832e-05,
      "loss": 0.0118,
      "step": 54980
    },
    {
      "epoch": 6.625301204819277,
      "grad_norm": 0.01678883656859398,
      "learning_rate": 1.3374698795180725e-05,
      "loss": 0.037,
      "step": 54990
    },
    {
      "epoch": 6.626506024096385,
      "grad_norm": 0.04709649458527565,
      "learning_rate": 1.3373493975903615e-05,
      "loss": 0.0346,
      "step": 55000
    },
    {
      "epoch": 6.627710843373494,
      "grad_norm": 0.024951433762907982,
      "learning_rate": 1.3372289156626508e-05,
      "loss": 0.0246,
      "step": 55010
    },
    {
      "epoch": 6.628915662650602,
      "grad_norm": 8.604348182678223,
      "learning_rate": 1.3371084337349399e-05,
      "loss": 0.0778,
      "step": 55020
    },
    {
      "epoch": 6.630120481927711,
      "grad_norm": 0.05712271109223366,
      "learning_rate": 1.3369879518072291e-05,
      "loss": 0.0164,
      "step": 55030
    },
    {
      "epoch": 6.63132530120482,
      "grad_norm": 0.02294132299721241,
      "learning_rate": 1.3368674698795182e-05,
      "loss": 0.0653,
      "step": 55040
    },
    {
      "epoch": 6.632530120481928,
      "grad_norm": 0.09842813014984131,
      "learning_rate": 1.3367469879518074e-05,
      "loss": 0.0328,
      "step": 55050
    },
    {
      "epoch": 6.633734939759036,
      "grad_norm": 0.616030752658844,
      "learning_rate": 1.3366265060240967e-05,
      "loss": 0.0505,
      "step": 55060
    },
    {
      "epoch": 6.634939759036144,
      "grad_norm": 0.11028842628002167,
      "learning_rate": 1.3365060240963856e-05,
      "loss": 0.0433,
      "step": 55070
    },
    {
      "epoch": 6.636144578313253,
      "grad_norm": 0.07339221984148026,
      "learning_rate": 1.3363855421686748e-05,
      "loss": 0.0199,
      "step": 55080
    },
    {
      "epoch": 6.637349397590361,
      "grad_norm": 1.263394832611084,
      "learning_rate": 1.3362650602409639e-05,
      "loss": 0.0517,
      "step": 55090
    },
    {
      "epoch": 6.63855421686747,
      "grad_norm": 0.05602247267961502,
      "learning_rate": 1.3361445783132531e-05,
      "loss": 0.0594,
      "step": 55100
    },
    {
      "epoch": 6.639759036144579,
      "grad_norm": 0.4846249222755432,
      "learning_rate": 1.3360240963855422e-05,
      "loss": 0.0219,
      "step": 55110
    },
    {
      "epoch": 6.6409638554216865,
      "grad_norm": 0.3712797164916992,
      "learning_rate": 1.3359036144578314e-05,
      "loss": 0.0292,
      "step": 55120
    },
    {
      "epoch": 6.642168674698795,
      "grad_norm": 0.006195858586579561,
      "learning_rate": 1.3357831325301205e-05,
      "loss": 0.0337,
      "step": 55130
    },
    {
      "epoch": 6.643373493975903,
      "grad_norm": 0.1744212806224823,
      "learning_rate": 1.3356626506024098e-05,
      "loss": 0.0491,
      "step": 55140
    },
    {
      "epoch": 6.644578313253012,
      "grad_norm": 2.6433842182159424,
      "learning_rate": 1.335542168674699e-05,
      "loss": 0.0519,
      "step": 55150
    },
    {
      "epoch": 6.64578313253012,
      "grad_norm": 0.09809171408414841,
      "learning_rate": 1.335421686746988e-05,
      "loss": 0.013,
      "step": 55160
    },
    {
      "epoch": 6.646987951807229,
      "grad_norm": 1.8742021322250366,
      "learning_rate": 1.3353012048192773e-05,
      "loss": 0.04,
      "step": 55170
    },
    {
      "epoch": 6.648192771084338,
      "grad_norm": 0.004962061066180468,
      "learning_rate": 1.3351807228915662e-05,
      "loss": 0.0337,
      "step": 55180
    },
    {
      "epoch": 6.6493975903614455,
      "grad_norm": 5.4383745193481445,
      "learning_rate": 1.3350602409638556e-05,
      "loss": 0.0465,
      "step": 55190
    },
    {
      "epoch": 6.650602409638554,
      "grad_norm": 0.21753031015396118,
      "learning_rate": 1.3349397590361445e-05,
      "loss": 0.0198,
      "step": 55200
    },
    {
      "epoch": 6.651807228915663,
      "grad_norm": 0.025946704670786858,
      "learning_rate": 1.3348192771084338e-05,
      "loss": 0.0558,
      "step": 55210
    },
    {
      "epoch": 6.653012048192771,
      "grad_norm": 0.8822694420814514,
      "learning_rate": 1.334698795180723e-05,
      "loss": 0.0696,
      "step": 55220
    },
    {
      "epoch": 6.65421686746988,
      "grad_norm": 2.0754902362823486,
      "learning_rate": 1.3345783132530121e-05,
      "loss": 0.0342,
      "step": 55230
    },
    {
      "epoch": 6.655421686746988,
      "grad_norm": 0.5541996955871582,
      "learning_rate": 1.3344578313253014e-05,
      "loss": 0.0283,
      "step": 55240
    },
    {
      "epoch": 6.656626506024097,
      "grad_norm": 1.50166654586792,
      "learning_rate": 1.3343373493975904e-05,
      "loss": 0.0045,
      "step": 55250
    },
    {
      "epoch": 6.6578313253012045,
      "grad_norm": 0.07065002620220184,
      "learning_rate": 1.3342168674698797e-05,
      "loss": 0.0663,
      "step": 55260
    },
    {
      "epoch": 6.659036144578313,
      "grad_norm": 2.5297348499298096,
      "learning_rate": 1.3340963855421687e-05,
      "loss": 0.018,
      "step": 55270
    },
    {
      "epoch": 6.660240963855422,
      "grad_norm": 15.489716529846191,
      "learning_rate": 1.333975903614458e-05,
      "loss": 0.032,
      "step": 55280
    },
    {
      "epoch": 6.66144578313253,
      "grad_norm": 6.375595569610596,
      "learning_rate": 1.3338554216867472e-05,
      "loss": 0.0557,
      "step": 55290
    },
    {
      "epoch": 6.662650602409639,
      "grad_norm": 0.03230717405676842,
      "learning_rate": 1.3337349397590363e-05,
      "loss": 0.021,
      "step": 55300
    },
    {
      "epoch": 6.663855421686747,
      "grad_norm": 30.54993438720703,
      "learning_rate": 1.3336144578313255e-05,
      "loss": 0.032,
      "step": 55310
    },
    {
      "epoch": 6.6650602409638555,
      "grad_norm": 0.0325394906103611,
      "learning_rate": 1.3334939759036145e-05,
      "loss": 0.0115,
      "step": 55320
    },
    {
      "epoch": 6.666265060240963,
      "grad_norm": 0.15582041442394257,
      "learning_rate": 1.3333734939759037e-05,
      "loss": 0.0859,
      "step": 55330
    },
    {
      "epoch": 6.667469879518072,
      "grad_norm": 0.8200296759605408,
      "learning_rate": 1.3332530120481928e-05,
      "loss": 0.0413,
      "step": 55340
    },
    {
      "epoch": 6.668674698795181,
      "grad_norm": 41.190521240234375,
      "learning_rate": 1.333132530120482e-05,
      "loss": 0.0125,
      "step": 55350
    },
    {
      "epoch": 6.669879518072289,
      "grad_norm": 1.2314122915267944,
      "learning_rate": 1.3330120481927713e-05,
      "loss": 0.0242,
      "step": 55360
    },
    {
      "epoch": 6.671084337349398,
      "grad_norm": 5.782665252685547,
      "learning_rate": 1.3328915662650603e-05,
      "loss": 0.041,
      "step": 55370
    },
    {
      "epoch": 6.672289156626506,
      "grad_norm": 1.6908353567123413,
      "learning_rate": 1.3327710843373496e-05,
      "loss": 0.0434,
      "step": 55380
    },
    {
      "epoch": 6.6734939759036145,
      "grad_norm": 0.013625022955238819,
      "learning_rate": 1.3326506024096386e-05,
      "loss": 0.0689,
      "step": 55390
    },
    {
      "epoch": 6.674698795180722,
      "grad_norm": 0.013864087872207165,
      "learning_rate": 1.3325301204819279e-05,
      "loss": 0.0471,
      "step": 55400
    },
    {
      "epoch": 6.675903614457831,
      "grad_norm": 0.8388024568557739,
      "learning_rate": 1.332409638554217e-05,
      "loss": 0.047,
      "step": 55410
    },
    {
      "epoch": 6.67710843373494,
      "grad_norm": 0.0636383667588234,
      "learning_rate": 1.3322891566265062e-05,
      "loss": 0.0074,
      "step": 55420
    },
    {
      "epoch": 6.678313253012048,
      "grad_norm": 0.01216049399226904,
      "learning_rate": 1.3321686746987951e-05,
      "loss": 0.0074,
      "step": 55430
    },
    {
      "epoch": 6.679518072289157,
      "grad_norm": 13.527884483337402,
      "learning_rate": 1.3320481927710844e-05,
      "loss": 0.0364,
      "step": 55440
    },
    {
      "epoch": 6.6807228915662655,
      "grad_norm": 7.059811592102051,
      "learning_rate": 1.3319277108433738e-05,
      "loss": 0.0755,
      "step": 55450
    },
    {
      "epoch": 6.6819277108433734,
      "grad_norm": 5.484699249267578,
      "learning_rate": 1.3318072289156627e-05,
      "loss": 0.0521,
      "step": 55460
    },
    {
      "epoch": 6.683132530120482,
      "grad_norm": 0.009495961479842663,
      "learning_rate": 1.331686746987952e-05,
      "loss": 0.013,
      "step": 55470
    },
    {
      "epoch": 6.68433734939759,
      "grad_norm": 0.02322441153228283,
      "learning_rate": 1.331566265060241e-05,
      "loss": 0.0332,
      "step": 55480
    },
    {
      "epoch": 6.685542168674699,
      "grad_norm": 2.862518310546875,
      "learning_rate": 1.3314457831325302e-05,
      "loss": 0.0276,
      "step": 55490
    },
    {
      "epoch": 6.686746987951807,
      "grad_norm": 0.2113768756389618,
      "learning_rate": 1.3313253012048193e-05,
      "loss": 0.0274,
      "step": 55500
    },
    {
      "epoch": 6.687951807228916,
      "grad_norm": 18.410327911376953,
      "learning_rate": 1.3312048192771086e-05,
      "loss": 0.0293,
      "step": 55510
    },
    {
      "epoch": 6.6891566265060245,
      "grad_norm": 0.006561253219842911,
      "learning_rate": 1.3310843373493978e-05,
      "loss": 0.0274,
      "step": 55520
    },
    {
      "epoch": 6.690361445783132,
      "grad_norm": 2.9568190574645996,
      "learning_rate": 1.3309638554216869e-05,
      "loss": 0.0627,
      "step": 55530
    },
    {
      "epoch": 6.691566265060241,
      "grad_norm": 0.012752429582178593,
      "learning_rate": 1.3308433734939761e-05,
      "loss": 0.0472,
      "step": 55540
    },
    {
      "epoch": 6.692771084337349,
      "grad_norm": 0.07574360072612762,
      "learning_rate": 1.3307228915662652e-05,
      "loss": 0.0423,
      "step": 55550
    },
    {
      "epoch": 6.693975903614458,
      "grad_norm": 0.09962747246026993,
      "learning_rate": 1.3306024096385544e-05,
      "loss": 0.0306,
      "step": 55560
    },
    {
      "epoch": 6.695180722891566,
      "grad_norm": 0.2206323742866516,
      "learning_rate": 1.3304819277108433e-05,
      "loss": 0.0405,
      "step": 55570
    },
    {
      "epoch": 6.696385542168675,
      "grad_norm": 0.04242628067731857,
      "learning_rate": 1.3303614457831326e-05,
      "loss": 0.0273,
      "step": 55580
    },
    {
      "epoch": 6.6975903614457835,
      "grad_norm": 0.019219698384404182,
      "learning_rate": 1.3302409638554218e-05,
      "loss": 0.0586,
      "step": 55590
    },
    {
      "epoch": 6.698795180722891,
      "grad_norm": 0.29049983620643616,
      "learning_rate": 1.3301204819277109e-05,
      "loss": 0.0091,
      "step": 55600
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.04617207124829292,
      "learning_rate": 1.3300000000000001e-05,
      "loss": 0.014,
      "step": 55610
    },
    {
      "epoch": 6.701204819277108,
      "grad_norm": 0.29559192061424255,
      "learning_rate": 1.3298795180722892e-05,
      "loss": 0.0271,
      "step": 55620
    },
    {
      "epoch": 6.702409638554217,
      "grad_norm": 0.06894984841346741,
      "learning_rate": 1.3297590361445785e-05,
      "loss": 0.0378,
      "step": 55630
    },
    {
      "epoch": 6.703614457831325,
      "grad_norm": 8.740262985229492,
      "learning_rate": 1.3296385542168675e-05,
      "loss": 0.0743,
      "step": 55640
    },
    {
      "epoch": 6.704819277108434,
      "grad_norm": 5.084400653839111,
      "learning_rate": 1.3295180722891568e-05,
      "loss": 0.0688,
      "step": 55650
    },
    {
      "epoch": 6.706024096385542,
      "grad_norm": 2.091994524002075,
      "learning_rate": 1.329397590361446e-05,
      "loss": 0.0871,
      "step": 55660
    },
    {
      "epoch": 6.70722891566265,
      "grad_norm": 0.2204180359840393,
      "learning_rate": 1.3292771084337351e-05,
      "loss": 0.0618,
      "step": 55670
    },
    {
      "epoch": 6.708433734939759,
      "grad_norm": 0.15816111862659454,
      "learning_rate": 1.3291566265060243e-05,
      "loss": 0.0457,
      "step": 55680
    },
    {
      "epoch": 6.709638554216868,
      "grad_norm": 0.5449537634849548,
      "learning_rate": 1.3290361445783132e-05,
      "loss": 0.0622,
      "step": 55690
    },
    {
      "epoch": 6.710843373493976,
      "grad_norm": 0.3321278989315033,
      "learning_rate": 1.3289156626506025e-05,
      "loss": 0.0203,
      "step": 55700
    },
    {
      "epoch": 6.712048192771085,
      "grad_norm": 6.001646995544434,
      "learning_rate": 1.3287951807228916e-05,
      "loss": 0.0543,
      "step": 55710
    },
    {
      "epoch": 6.713253012048193,
      "grad_norm": 3.8451554775238037,
      "learning_rate": 1.3286746987951808e-05,
      "loss": 0.0311,
      "step": 55720
    },
    {
      "epoch": 6.714457831325301,
      "grad_norm": 0.0608467236161232,
      "learning_rate": 1.3285542168674699e-05,
      "loss": 0.0144,
      "step": 55730
    },
    {
      "epoch": 6.715662650602409,
      "grad_norm": 12.53772258758545,
      "learning_rate": 1.3284337349397591e-05,
      "loss": 0.0703,
      "step": 55740
    },
    {
      "epoch": 6.716867469879518,
      "grad_norm": 28.936267852783203,
      "learning_rate": 1.3283132530120484e-05,
      "loss": 0.0709,
      "step": 55750
    },
    {
      "epoch": 6.718072289156627,
      "grad_norm": 20.57632827758789,
      "learning_rate": 1.3281927710843374e-05,
      "loss": 0.0423,
      "step": 55760
    },
    {
      "epoch": 6.719277108433735,
      "grad_norm": 0.009134121239185333,
      "learning_rate": 1.3280722891566267e-05,
      "loss": 0.0006,
      "step": 55770
    },
    {
      "epoch": 6.720481927710844,
      "grad_norm": 0.012582390569150448,
      "learning_rate": 1.3279518072289158e-05,
      "loss": 0.0356,
      "step": 55780
    },
    {
      "epoch": 6.7216867469879515,
      "grad_norm": 0.028245631605386734,
      "learning_rate": 1.327831325301205e-05,
      "loss": 0.0271,
      "step": 55790
    },
    {
      "epoch": 6.72289156626506,
      "grad_norm": 0.031907446682453156,
      "learning_rate": 1.3277108433734939e-05,
      "loss": 0.0329,
      "step": 55800
    },
    {
      "epoch": 6.724096385542168,
      "grad_norm": 0.23628683388233185,
      "learning_rate": 1.3275903614457833e-05,
      "loss": 0.0408,
      "step": 55810
    },
    {
      "epoch": 6.725301204819277,
      "grad_norm": 0.22325198352336884,
      "learning_rate": 1.3274698795180726e-05,
      "loss": 0.0527,
      "step": 55820
    },
    {
      "epoch": 6.726506024096386,
      "grad_norm": 0.2202204316854477,
      "learning_rate": 1.3273493975903615e-05,
      "loss": 0.0593,
      "step": 55830
    },
    {
      "epoch": 6.727710843373494,
      "grad_norm": 8.648971557617188,
      "learning_rate": 1.3272289156626507e-05,
      "loss": 0.0277,
      "step": 55840
    },
    {
      "epoch": 6.728915662650603,
      "grad_norm": 2.4998040199279785,
      "learning_rate": 1.3271084337349398e-05,
      "loss": 0.0213,
      "step": 55850
    },
    {
      "epoch": 6.7301204819277105,
      "grad_norm": 0.21698416769504547,
      "learning_rate": 1.326987951807229e-05,
      "loss": 0.0371,
      "step": 55860
    },
    {
      "epoch": 6.731325301204819,
      "grad_norm": 0.03360466659069061,
      "learning_rate": 1.3268674698795181e-05,
      "loss": 0.0653,
      "step": 55870
    },
    {
      "epoch": 6.732530120481927,
      "grad_norm": 18.04088592529297,
      "learning_rate": 1.3267469879518073e-05,
      "loss": 0.0274,
      "step": 55880
    },
    {
      "epoch": 6.733734939759036,
      "grad_norm": 0.03207532316446304,
      "learning_rate": 1.3266265060240966e-05,
      "loss": 0.0041,
      "step": 55890
    },
    {
      "epoch": 6.734939759036145,
      "grad_norm": 0.00804519560188055,
      "learning_rate": 1.3265060240963857e-05,
      "loss": 0.0215,
      "step": 55900
    },
    {
      "epoch": 6.736144578313253,
      "grad_norm": 0.7347077131271362,
      "learning_rate": 1.3263855421686749e-05,
      "loss": 0.0944,
      "step": 55910
    },
    {
      "epoch": 6.7373493975903616,
      "grad_norm": 21.481569290161133,
      "learning_rate": 1.326265060240964e-05,
      "loss": 0.0745,
      "step": 55920
    },
    {
      "epoch": 6.73855421686747,
      "grad_norm": 5.99097204208374,
      "learning_rate": 1.3261445783132532e-05,
      "loss": 0.0389,
      "step": 55930
    },
    {
      "epoch": 6.739759036144578,
      "grad_norm": 17.01901626586914,
      "learning_rate": 1.3260240963855421e-05,
      "loss": 0.0294,
      "step": 55940
    },
    {
      "epoch": 6.740963855421687,
      "grad_norm": 2.300666570663452,
      "learning_rate": 1.3259036144578314e-05,
      "loss": 0.0742,
      "step": 55950
    },
    {
      "epoch": 6.742168674698795,
      "grad_norm": 0.28421980142593384,
      "learning_rate": 1.3257831325301206e-05,
      "loss": 0.0094,
      "step": 55960
    },
    {
      "epoch": 6.743373493975904,
      "grad_norm": 6.044569492340088,
      "learning_rate": 1.3256626506024097e-05,
      "loss": 0.0452,
      "step": 55970
    },
    {
      "epoch": 6.744578313253012,
      "grad_norm": 0.9648950695991516,
      "learning_rate": 1.325542168674699e-05,
      "loss": 0.0844,
      "step": 55980
    },
    {
      "epoch": 6.7457831325301205,
      "grad_norm": 1.4326646327972412,
      "learning_rate": 1.325421686746988e-05,
      "loss": 0.0629,
      "step": 55990
    },
    {
      "epoch": 6.746987951807229,
      "grad_norm": 1.5884565114974976,
      "learning_rate": 1.3253012048192772e-05,
      "loss": 0.0072,
      "step": 56000
    },
    {
      "epoch": 6.748192771084337,
      "grad_norm": 0.004434971138834953,
      "learning_rate": 1.3251807228915663e-05,
      "loss": 0.0192,
      "step": 56010
    },
    {
      "epoch": 6.749397590361446,
      "grad_norm": 0.003919681068509817,
      "learning_rate": 1.3250602409638556e-05,
      "loss": 0.0365,
      "step": 56020
    },
    {
      "epoch": 6.750602409638554,
      "grad_norm": 0.10471240431070328,
      "learning_rate": 1.3249397590361446e-05,
      "loss": 0.0512,
      "step": 56030
    },
    {
      "epoch": 6.751807228915663,
      "grad_norm": 2.2001376152038574,
      "learning_rate": 1.3248192771084339e-05,
      "loss": 0.0126,
      "step": 56040
    },
    {
      "epoch": 6.753012048192771,
      "grad_norm": 0.13427139818668365,
      "learning_rate": 1.3246987951807231e-05,
      "loss": 0.0034,
      "step": 56050
    },
    {
      "epoch": 6.7542168674698795,
      "grad_norm": 0.05936041101813316,
      "learning_rate": 1.324578313253012e-05,
      "loss": 0.0529,
      "step": 56060
    },
    {
      "epoch": 6.755421686746988,
      "grad_norm": 10.572159767150879,
      "learning_rate": 1.3244578313253014e-05,
      "loss": 0.0621,
      "step": 56070
    },
    {
      "epoch": 6.756626506024096,
      "grad_norm": 1.741516351699829,
      "learning_rate": 1.3243373493975904e-05,
      "loss": 0.0864,
      "step": 56080
    },
    {
      "epoch": 6.757831325301205,
      "grad_norm": 0.005815116222947836,
      "learning_rate": 1.3242168674698796e-05,
      "loss": 0.0111,
      "step": 56090
    },
    {
      "epoch": 6.759036144578313,
      "grad_norm": 2.819890260696411,
      "learning_rate": 1.3240963855421687e-05,
      "loss": 0.0107,
      "step": 56100
    },
    {
      "epoch": 6.760240963855422,
      "grad_norm": 1.4865010976791382,
      "learning_rate": 1.3239759036144579e-05,
      "loss": 0.0457,
      "step": 56110
    },
    {
      "epoch": 6.76144578313253,
      "grad_norm": 1.595719575881958,
      "learning_rate": 1.3238554216867472e-05,
      "loss": 0.0282,
      "step": 56120
    },
    {
      "epoch": 6.7626506024096384,
      "grad_norm": 0.0024876368697732687,
      "learning_rate": 1.3237349397590362e-05,
      "loss": 0.0445,
      "step": 56130
    },
    {
      "epoch": 6.763855421686747,
      "grad_norm": 0.002432406647130847,
      "learning_rate": 1.3236144578313255e-05,
      "loss": 0.0611,
      "step": 56140
    },
    {
      "epoch": 6.765060240963855,
      "grad_norm": 0.1593470424413681,
      "learning_rate": 1.3234939759036145e-05,
      "loss": 0.0692,
      "step": 56150
    },
    {
      "epoch": 6.766265060240964,
      "grad_norm": 0.9885284900665283,
      "learning_rate": 1.3233734939759038e-05,
      "loss": 0.0704,
      "step": 56160
    },
    {
      "epoch": 6.767469879518073,
      "grad_norm": 0.4916565716266632,
      "learning_rate": 1.3232530120481929e-05,
      "loss": 0.0102,
      "step": 56170
    },
    {
      "epoch": 6.768674698795181,
      "grad_norm": 2.013701915740967,
      "learning_rate": 1.3231325301204821e-05,
      "loss": 0.0532,
      "step": 56180
    },
    {
      "epoch": 6.7698795180722895,
      "grad_norm": 3.245326042175293,
      "learning_rate": 1.3230120481927714e-05,
      "loss": 0.0722,
      "step": 56190
    },
    {
      "epoch": 6.771084337349397,
      "grad_norm": 0.0037487053778022528,
      "learning_rate": 1.3228915662650603e-05,
      "loss": 0.0175,
      "step": 56200
    },
    {
      "epoch": 6.772289156626506,
      "grad_norm": 0.12189514189958572,
      "learning_rate": 1.3227710843373495e-05,
      "loss": 0.0705,
      "step": 56210
    },
    {
      "epoch": 6.773493975903614,
      "grad_norm": 0.04234332591295242,
      "learning_rate": 1.3226506024096386e-05,
      "loss": 0.0602,
      "step": 56220
    },
    {
      "epoch": 6.774698795180723,
      "grad_norm": 0.012882540933787823,
      "learning_rate": 1.3225301204819278e-05,
      "loss": 0.0489,
      "step": 56230
    },
    {
      "epoch": 6.775903614457832,
      "grad_norm": 1.2841275930404663,
      "learning_rate": 1.3224096385542169e-05,
      "loss": 0.0484,
      "step": 56240
    },
    {
      "epoch": 6.77710843373494,
      "grad_norm": 4.5796709060668945,
      "learning_rate": 1.3222891566265061e-05,
      "loss": 0.0272,
      "step": 56250
    },
    {
      "epoch": 6.7783132530120485,
      "grad_norm": 0.7413495182991028,
      "learning_rate": 1.3221686746987954e-05,
      "loss": 0.0556,
      "step": 56260
    },
    {
      "epoch": 6.779518072289156,
      "grad_norm": 0.008512057363986969,
      "learning_rate": 1.3220481927710845e-05,
      "loss": 0.0452,
      "step": 56270
    },
    {
      "epoch": 6.780722891566265,
      "grad_norm": 7.472576141357422,
      "learning_rate": 1.3219277108433737e-05,
      "loss": 0.0154,
      "step": 56280
    },
    {
      "epoch": 6.781927710843373,
      "grad_norm": 5.245774745941162,
      "learning_rate": 1.3218072289156628e-05,
      "loss": 0.0213,
      "step": 56290
    },
    {
      "epoch": 6.783132530120482,
      "grad_norm": 0.009681026451289654,
      "learning_rate": 1.321686746987952e-05,
      "loss": 0.032,
      "step": 56300
    },
    {
      "epoch": 6.784337349397591,
      "grad_norm": 0.005778683349490166,
      "learning_rate": 1.321566265060241e-05,
      "loss": 0.0469,
      "step": 56310
    },
    {
      "epoch": 6.785542168674699,
      "grad_norm": 0.35841724276542664,
      "learning_rate": 1.3214457831325303e-05,
      "loss": 0.0497,
      "step": 56320
    },
    {
      "epoch": 6.786746987951807,
      "grad_norm": 10.409238815307617,
      "learning_rate": 1.3213253012048192e-05,
      "loss": 0.0372,
      "step": 56330
    },
    {
      "epoch": 6.787951807228915,
      "grad_norm": 1.2528283596038818,
      "learning_rate": 1.3212048192771085e-05,
      "loss": 0.0927,
      "step": 56340
    },
    {
      "epoch": 6.789156626506024,
      "grad_norm": 0.12000468373298645,
      "learning_rate": 1.3210843373493977e-05,
      "loss": 0.0268,
      "step": 56350
    },
    {
      "epoch": 6.790361445783132,
      "grad_norm": 0.6852560639381409,
      "learning_rate": 1.3209638554216868e-05,
      "loss": 0.0646,
      "step": 56360
    },
    {
      "epoch": 6.791566265060241,
      "grad_norm": 0.8244704604148865,
      "learning_rate": 1.320843373493976e-05,
      "loss": 0.0398,
      "step": 56370
    },
    {
      "epoch": 6.79277108433735,
      "grad_norm": 5.315762042999268,
      "learning_rate": 1.3207228915662651e-05,
      "loss": 0.0375,
      "step": 56380
    },
    {
      "epoch": 6.793975903614458,
      "grad_norm": 3.3767740726470947,
      "learning_rate": 1.3206024096385544e-05,
      "loss": 0.0213,
      "step": 56390
    },
    {
      "epoch": 6.795180722891566,
      "grad_norm": 0.333326518535614,
      "learning_rate": 1.3204819277108434e-05,
      "loss": 0.0262,
      "step": 56400
    },
    {
      "epoch": 6.796385542168675,
      "grad_norm": 0.13898156583309174,
      "learning_rate": 1.3203614457831327e-05,
      "loss": 0.0377,
      "step": 56410
    },
    {
      "epoch": 6.797590361445783,
      "grad_norm": 0.011874556541442871,
      "learning_rate": 1.320240963855422e-05,
      "loss": 0.0234,
      "step": 56420
    },
    {
      "epoch": 6.798795180722892,
      "grad_norm": 0.16466304659843445,
      "learning_rate": 1.320120481927711e-05,
      "loss": 0.0341,
      "step": 56430
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.0452575646340847,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.0393,
      "step": 56440
    },
    {
      "epoch": 6.801204819277109,
      "grad_norm": 20.97768211364746,
      "learning_rate": 1.3198795180722891e-05,
      "loss": 0.1022,
      "step": 56450
    },
    {
      "epoch": 6.8024096385542165,
      "grad_norm": 0.38260841369628906,
      "learning_rate": 1.3197590361445784e-05,
      "loss": 0.0049,
      "step": 56460
    },
    {
      "epoch": 6.803614457831325,
      "grad_norm": 0.008709303103387356,
      "learning_rate": 1.3196385542168675e-05,
      "loss": 0.0225,
      "step": 56470
    },
    {
      "epoch": 6.804819277108434,
      "grad_norm": 0.3842901885509491,
      "learning_rate": 1.3195180722891567e-05,
      "loss": 0.0283,
      "step": 56480
    },
    {
      "epoch": 6.806024096385542,
      "grad_norm": 0.009138595312833786,
      "learning_rate": 1.319397590361446e-05,
      "loss": 0.0482,
      "step": 56490
    },
    {
      "epoch": 6.807228915662651,
      "grad_norm": 6.362055778503418,
      "learning_rate": 1.319277108433735e-05,
      "loss": 0.1186,
      "step": 56500
    },
    {
      "epoch": 6.808433734939759,
      "grad_norm": 3.7634503841400146,
      "learning_rate": 1.3191566265060243e-05,
      "loss": 0.0137,
      "step": 56510
    },
    {
      "epoch": 6.809638554216868,
      "grad_norm": 1.7793563604354858,
      "learning_rate": 1.3190361445783133e-05,
      "loss": 0.0226,
      "step": 56520
    },
    {
      "epoch": 6.8108433734939755,
      "grad_norm": 0.24001319706439972,
      "learning_rate": 1.3189156626506026e-05,
      "loss": 0.0288,
      "step": 56530
    },
    {
      "epoch": 6.812048192771084,
      "grad_norm": 0.0682368278503418,
      "learning_rate": 1.3187951807228917e-05,
      "loss": 0.0474,
      "step": 56540
    },
    {
      "epoch": 6.813253012048193,
      "grad_norm": 0.08809439837932587,
      "learning_rate": 1.3186746987951809e-05,
      "loss": 0.0096,
      "step": 56550
    },
    {
      "epoch": 6.814457831325301,
      "grad_norm": 0.32330936193466187,
      "learning_rate": 1.3185542168674701e-05,
      "loss": 0.0025,
      "step": 56560
    },
    {
      "epoch": 6.81566265060241,
      "grad_norm": 0.06832462549209595,
      "learning_rate": 1.318433734939759e-05,
      "loss": 0.0369,
      "step": 56570
    },
    {
      "epoch": 6.816867469879518,
      "grad_norm": 0.009108101949095726,
      "learning_rate": 1.3183132530120485e-05,
      "loss": 0.0443,
      "step": 56580
    },
    {
      "epoch": 6.8180722891566266,
      "grad_norm": 2.8520922660827637,
      "learning_rate": 1.3181927710843374e-05,
      "loss": 0.0779,
      "step": 56590
    },
    {
      "epoch": 6.8192771084337345,
      "grad_norm": 2.2922842502593994,
      "learning_rate": 1.3180722891566266e-05,
      "loss": 0.0095,
      "step": 56600
    },
    {
      "epoch": 6.820481927710843,
      "grad_norm": 0.05753214284777641,
      "learning_rate": 1.3179518072289157e-05,
      "loss": 0.0477,
      "step": 56610
    },
    {
      "epoch": 6.821686746987952,
      "grad_norm": 5.628236293792725,
      "learning_rate": 1.317831325301205e-05,
      "loss": 0.0274,
      "step": 56620
    },
    {
      "epoch": 6.82289156626506,
      "grad_norm": 0.29902413487434387,
      "learning_rate": 1.317710843373494e-05,
      "loss": 0.0223,
      "step": 56630
    },
    {
      "epoch": 6.824096385542169,
      "grad_norm": 0.026705648750066757,
      "learning_rate": 1.3175903614457832e-05,
      "loss": 0.0326,
      "step": 56640
    },
    {
      "epoch": 6.825301204819278,
      "grad_norm": 19.975811004638672,
      "learning_rate": 1.3174698795180725e-05,
      "loss": 0.0475,
      "step": 56650
    },
    {
      "epoch": 6.8265060240963855,
      "grad_norm": 0.36916154623031616,
      "learning_rate": 1.3173493975903616e-05,
      "loss": 0.0338,
      "step": 56660
    },
    {
      "epoch": 6.827710843373494,
      "grad_norm": 0.1627330332994461,
      "learning_rate": 1.3172289156626508e-05,
      "loss": 0.0603,
      "step": 56670
    },
    {
      "epoch": 6.828915662650602,
      "grad_norm": 0.6419175863265991,
      "learning_rate": 1.3171084337349399e-05,
      "loss": 0.0593,
      "step": 56680
    },
    {
      "epoch": 6.830120481927711,
      "grad_norm": 0.042921632528305054,
      "learning_rate": 1.3169879518072291e-05,
      "loss": 0.04,
      "step": 56690
    },
    {
      "epoch": 6.831325301204819,
      "grad_norm": 0.04009706526994705,
      "learning_rate": 1.316867469879518e-05,
      "loss": 0.0256,
      "step": 56700
    },
    {
      "epoch": 6.832530120481928,
      "grad_norm": 0.4631659984588623,
      "learning_rate": 1.3167469879518073e-05,
      "loss": 0.009,
      "step": 56710
    },
    {
      "epoch": 6.833734939759037,
      "grad_norm": 0.00828878115862608,
      "learning_rate": 1.3166265060240965e-05,
      "loss": 0.003,
      "step": 56720
    },
    {
      "epoch": 6.8349397590361445,
      "grad_norm": 0.24273158609867096,
      "learning_rate": 1.3165060240963856e-05,
      "loss": 0.0022,
      "step": 56730
    },
    {
      "epoch": 6.836144578313253,
      "grad_norm": 2.35380482673645,
      "learning_rate": 1.3163855421686748e-05,
      "loss": 0.0442,
      "step": 56740
    },
    {
      "epoch": 6.837349397590361,
      "grad_norm": 0.01887163333594799,
      "learning_rate": 1.3162650602409639e-05,
      "loss": 0.1575,
      "step": 56750
    },
    {
      "epoch": 6.83855421686747,
      "grad_norm": 0.13563397526741028,
      "learning_rate": 1.3161445783132531e-05,
      "loss": 0.0271,
      "step": 56760
    },
    {
      "epoch": 6.839759036144578,
      "grad_norm": 1.164657473564148,
      "learning_rate": 1.3160240963855422e-05,
      "loss": 0.0491,
      "step": 56770
    },
    {
      "epoch": 6.840963855421687,
      "grad_norm": 0.11446446180343628,
      "learning_rate": 1.3159036144578315e-05,
      "loss": 0.0217,
      "step": 56780
    },
    {
      "epoch": 6.8421686746987955,
      "grad_norm": 0.0359584242105484,
      "learning_rate": 1.3157831325301207e-05,
      "loss": 0.0341,
      "step": 56790
    },
    {
      "epoch": 6.843373493975903,
      "grad_norm": 1.3095722198486328,
      "learning_rate": 1.3156626506024098e-05,
      "loss": 0.0811,
      "step": 56800
    },
    {
      "epoch": 6.844578313253012,
      "grad_norm": 0.3488655090332031,
      "learning_rate": 1.315542168674699e-05,
      "loss": 0.0043,
      "step": 56810
    },
    {
      "epoch": 6.84578313253012,
      "grad_norm": 0.03898390009999275,
      "learning_rate": 1.315421686746988e-05,
      "loss": 0.0712,
      "step": 56820
    },
    {
      "epoch": 6.846987951807229,
      "grad_norm": 1.7333176136016846,
      "learning_rate": 1.3153012048192772e-05,
      "loss": 0.0282,
      "step": 56830
    },
    {
      "epoch": 6.848192771084337,
      "grad_norm": 0.017545582726597786,
      "learning_rate": 1.3151807228915662e-05,
      "loss": 0.011,
      "step": 56840
    },
    {
      "epoch": 6.849397590361446,
      "grad_norm": 14.200366020202637,
      "learning_rate": 1.3150602409638555e-05,
      "loss": 0.0553,
      "step": 56850
    },
    {
      "epoch": 6.8506024096385545,
      "grad_norm": 4.459060192108154,
      "learning_rate": 1.3149397590361447e-05,
      "loss": 0.0716,
      "step": 56860
    },
    {
      "epoch": 6.851807228915662,
      "grad_norm": 0.9446021318435669,
      "learning_rate": 1.3148192771084338e-05,
      "loss": 0.0343,
      "step": 56870
    },
    {
      "epoch": 6.853012048192771,
      "grad_norm": 0.22647923231124878,
      "learning_rate": 1.314698795180723e-05,
      "loss": 0.0349,
      "step": 56880
    },
    {
      "epoch": 6.85421686746988,
      "grad_norm": 0.04264749959111214,
      "learning_rate": 1.3145783132530121e-05,
      "loss": 0.0456,
      "step": 56890
    },
    {
      "epoch": 6.855421686746988,
      "grad_norm": 0.004211109131574631,
      "learning_rate": 1.3144578313253014e-05,
      "loss": 0.0647,
      "step": 56900
    },
    {
      "epoch": 6.856626506024097,
      "grad_norm": 0.3168564438819885,
      "learning_rate": 1.3143373493975904e-05,
      "loss": 0.0382,
      "step": 56910
    },
    {
      "epoch": 6.857831325301205,
      "grad_norm": 0.075006864964962,
      "learning_rate": 1.3142168674698797e-05,
      "loss": 0.0237,
      "step": 56920
    },
    {
      "epoch": 6.8590361445783135,
      "grad_norm": 0.11367630213499069,
      "learning_rate": 1.3140963855421686e-05,
      "loss": 0.0138,
      "step": 56930
    },
    {
      "epoch": 6.860240963855421,
      "grad_norm": 0.01705474592745304,
      "learning_rate": 1.313975903614458e-05,
      "loss": 0.0706,
      "step": 56940
    },
    {
      "epoch": 6.86144578313253,
      "grad_norm": 3.6621270179748535,
      "learning_rate": 1.3138554216867473e-05,
      "loss": 0.0297,
      "step": 56950
    },
    {
      "epoch": 6.862650602409639,
      "grad_norm": 0.0058735753409564495,
      "learning_rate": 1.3137349397590362e-05,
      "loss": 0.0424,
      "step": 56960
    },
    {
      "epoch": 6.863855421686747,
      "grad_norm": 2.76058030128479,
      "learning_rate": 1.3136144578313254e-05,
      "loss": 0.0437,
      "step": 56970
    },
    {
      "epoch": 6.865060240963856,
      "grad_norm": 1.7369948625564575,
      "learning_rate": 1.3134939759036145e-05,
      "loss": 0.0204,
      "step": 56980
    },
    {
      "epoch": 6.866265060240964,
      "grad_norm": 0.3093777596950531,
      "learning_rate": 1.3133734939759037e-05,
      "loss": 0.0711,
      "step": 56990
    },
    {
      "epoch": 6.867469879518072,
      "grad_norm": 3.3947110176086426,
      "learning_rate": 1.3132530120481928e-05,
      "loss": 0.0087,
      "step": 57000
    },
    {
      "epoch": 6.86867469879518,
      "grad_norm": 0.005149495787918568,
      "learning_rate": 1.313132530120482e-05,
      "loss": 0.0066,
      "step": 57010
    },
    {
      "epoch": 6.869879518072289,
      "grad_norm": 0.013348285108804703,
      "learning_rate": 1.3130120481927713e-05,
      "loss": 0.093,
      "step": 57020
    },
    {
      "epoch": 6.871084337349398,
      "grad_norm": 0.07116376608610153,
      "learning_rate": 1.3128915662650604e-05,
      "loss": 0.0059,
      "step": 57030
    },
    {
      "epoch": 6.872289156626506,
      "grad_norm": 0.9542070031166077,
      "learning_rate": 1.3127710843373496e-05,
      "loss": 0.0306,
      "step": 57040
    },
    {
      "epoch": 6.873493975903615,
      "grad_norm": 7.756524085998535,
      "learning_rate": 1.3126506024096387e-05,
      "loss": 0.0688,
      "step": 57050
    },
    {
      "epoch": 6.874698795180723,
      "grad_norm": 13.941875457763672,
      "learning_rate": 1.3125301204819279e-05,
      "loss": 0.0059,
      "step": 57060
    },
    {
      "epoch": 6.875903614457831,
      "grad_norm": 0.01740381121635437,
      "learning_rate": 1.3124096385542168e-05,
      "loss": 0.0428,
      "step": 57070
    },
    {
      "epoch": 6.877108433734939,
      "grad_norm": 5.984297275543213,
      "learning_rate": 1.312289156626506e-05,
      "loss": 0.0282,
      "step": 57080
    },
    {
      "epoch": 6.878313253012048,
      "grad_norm": 3.4039292335510254,
      "learning_rate": 1.3121686746987953e-05,
      "loss": 0.0709,
      "step": 57090
    },
    {
      "epoch": 6.879518072289157,
      "grad_norm": 0.02760930173099041,
      "learning_rate": 1.3120481927710844e-05,
      "loss": 0.0592,
      "step": 57100
    },
    {
      "epoch": 6.880722891566265,
      "grad_norm": 1.1710927486419678,
      "learning_rate": 1.3119277108433736e-05,
      "loss": 0.0462,
      "step": 57110
    },
    {
      "epoch": 6.881927710843374,
      "grad_norm": 0.35033079981803894,
      "learning_rate": 1.3118072289156627e-05,
      "loss": 0.0364,
      "step": 57120
    },
    {
      "epoch": 6.8831325301204815,
      "grad_norm": 7.589746475219727,
      "learning_rate": 1.311686746987952e-05,
      "loss": 0.066,
      "step": 57130
    },
    {
      "epoch": 6.88433734939759,
      "grad_norm": 2.438094139099121,
      "learning_rate": 1.311566265060241e-05,
      "loss": 0.0331,
      "step": 57140
    },
    {
      "epoch": 6.885542168674699,
      "grad_norm": 0.05006260424852371,
      "learning_rate": 1.3114457831325303e-05,
      "loss": 0.0192,
      "step": 57150
    },
    {
      "epoch": 6.886746987951807,
      "grad_norm": 2.9265782833099365,
      "learning_rate": 1.3113253012048195e-05,
      "loss": 0.0372,
      "step": 57160
    },
    {
      "epoch": 6.887951807228916,
      "grad_norm": 0.004640161991119385,
      "learning_rate": 1.3112048192771086e-05,
      "loss": 0.0422,
      "step": 57170
    },
    {
      "epoch": 6.889156626506024,
      "grad_norm": 0.011821248568594456,
      "learning_rate": 1.3110843373493978e-05,
      "loss": 0.0094,
      "step": 57180
    },
    {
      "epoch": 6.890361445783133,
      "grad_norm": 0.30763891339302063,
      "learning_rate": 1.3109638554216867e-05,
      "loss": 0.0415,
      "step": 57190
    },
    {
      "epoch": 6.891566265060241,
      "grad_norm": 3.606144666671753,
      "learning_rate": 1.3108433734939761e-05,
      "loss": 0.0434,
      "step": 57200
    },
    {
      "epoch": 6.892771084337349,
      "grad_norm": 0.593841016292572,
      "learning_rate": 1.310722891566265e-05,
      "loss": 0.0194,
      "step": 57210
    },
    {
      "epoch": 6.893975903614458,
      "grad_norm": 1.5051534175872803,
      "learning_rate": 1.3106024096385543e-05,
      "loss": 0.0586,
      "step": 57220
    },
    {
      "epoch": 6.895180722891566,
      "grad_norm": 0.014071423560380936,
      "learning_rate": 1.3104819277108434e-05,
      "loss": 0.0321,
      "step": 57230
    },
    {
      "epoch": 6.896385542168675,
      "grad_norm": 0.17441776394844055,
      "learning_rate": 1.3103614457831326e-05,
      "loss": 0.0291,
      "step": 57240
    },
    {
      "epoch": 6.897590361445783,
      "grad_norm": 44.80516815185547,
      "learning_rate": 1.3102409638554218e-05,
      "loss": 0.0306,
      "step": 57250
    },
    {
      "epoch": 6.8987951807228916,
      "grad_norm": 3.6554317474365234,
      "learning_rate": 1.310120481927711e-05,
      "loss": 0.053,
      "step": 57260
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.06303072720766068,
      "learning_rate": 1.3100000000000002e-05,
      "loss": 0.0431,
      "step": 57270
    },
    {
      "epoch": 6.901204819277108,
      "grad_norm": 0.056995827704668045,
      "learning_rate": 1.3098795180722892e-05,
      "loss": 0.0039,
      "step": 57280
    },
    {
      "epoch": 6.902409638554217,
      "grad_norm": 0.01988273486495018,
      "learning_rate": 1.3097590361445785e-05,
      "loss": 0.0281,
      "step": 57290
    },
    {
      "epoch": 6.903614457831325,
      "grad_norm": 0.005433450452983379,
      "learning_rate": 1.3096385542168676e-05,
      "loss": 0.0035,
      "step": 57300
    },
    {
      "epoch": 6.904819277108434,
      "grad_norm": 0.0738895833492279,
      "learning_rate": 1.3095180722891568e-05,
      "loss": 0.0333,
      "step": 57310
    },
    {
      "epoch": 6.906024096385542,
      "grad_norm": 0.009571801871061325,
      "learning_rate": 1.309397590361446e-05,
      "loss": 0.041,
      "step": 57320
    },
    {
      "epoch": 6.9072289156626505,
      "grad_norm": 0.20408573746681213,
      "learning_rate": 1.309277108433735e-05,
      "loss": 0.0473,
      "step": 57330
    },
    {
      "epoch": 6.908433734939759,
      "grad_norm": 0.009736192412674427,
      "learning_rate": 1.3091566265060242e-05,
      "loss": 0.008,
      "step": 57340
    },
    {
      "epoch": 6.909638554216867,
      "grad_norm": 0.030097952112555504,
      "learning_rate": 1.3090361445783133e-05,
      "loss": 0.0142,
      "step": 57350
    },
    {
      "epoch": 6.910843373493976,
      "grad_norm": 15.631192207336426,
      "learning_rate": 1.3089156626506025e-05,
      "loss": 0.0577,
      "step": 57360
    },
    {
      "epoch": 6.912048192771084,
      "grad_norm": 0.008622216992080212,
      "learning_rate": 1.3087951807228916e-05,
      "loss": 0.0505,
      "step": 57370
    },
    {
      "epoch": 6.913253012048193,
      "grad_norm": 20.347204208374023,
      "learning_rate": 1.3086746987951808e-05,
      "loss": 0.0256,
      "step": 57380
    },
    {
      "epoch": 6.914457831325302,
      "grad_norm": 0.7636420130729675,
      "learning_rate": 1.30855421686747e-05,
      "loss": 0.0213,
      "step": 57390
    },
    {
      "epoch": 6.9156626506024095,
      "grad_norm": 0.2997134327888489,
      "learning_rate": 1.3084337349397591e-05,
      "loss": 0.0311,
      "step": 57400
    },
    {
      "epoch": 6.916867469879518,
      "grad_norm": 0.004841833841055632,
      "learning_rate": 1.3083132530120484e-05,
      "loss": 0.0156,
      "step": 57410
    },
    {
      "epoch": 6.918072289156626,
      "grad_norm": 0.009048606269061565,
      "learning_rate": 1.3081927710843375e-05,
      "loss": 0.0361,
      "step": 57420
    },
    {
      "epoch": 6.919277108433735,
      "grad_norm": 0.003928727935999632,
      "learning_rate": 1.3080722891566267e-05,
      "loss": 0.0338,
      "step": 57430
    },
    {
      "epoch": 6.920481927710844,
      "grad_norm": 1.464300513267517,
      "learning_rate": 1.3079518072289156e-05,
      "loss": 0.0187,
      "step": 57440
    },
    {
      "epoch": 6.921686746987952,
      "grad_norm": 1.255578637123108,
      "learning_rate": 1.3078313253012049e-05,
      "loss": 0.0241,
      "step": 57450
    },
    {
      "epoch": 6.9228915662650605,
      "grad_norm": 0.043136145919561386,
      "learning_rate": 1.3077108433734943e-05,
      "loss": 0.0474,
      "step": 57460
    },
    {
      "epoch": 6.924096385542168,
      "grad_norm": 0.0038476414047181606,
      "learning_rate": 1.3075903614457832e-05,
      "loss": 0.0351,
      "step": 57470
    },
    {
      "epoch": 6.925301204819277,
      "grad_norm": 0.22332122921943665,
      "learning_rate": 1.3074698795180724e-05,
      "loss": 0.0258,
      "step": 57480
    },
    {
      "epoch": 6.926506024096385,
      "grad_norm": 19.68100357055664,
      "learning_rate": 1.3073493975903615e-05,
      "loss": 0.0158,
      "step": 57490
    },
    {
      "epoch": 6.927710843373494,
      "grad_norm": 0.003041759831830859,
      "learning_rate": 1.3072289156626507e-05,
      "loss": 0.0131,
      "step": 57500
    },
    {
      "epoch": 6.928915662650603,
      "grad_norm": 0.896628201007843,
      "learning_rate": 1.3071084337349398e-05,
      "loss": 0.0113,
      "step": 57510
    },
    {
      "epoch": 6.930120481927711,
      "grad_norm": 0.002415441907942295,
      "learning_rate": 1.306987951807229e-05,
      "loss": 0.0461,
      "step": 57520
    },
    {
      "epoch": 6.9313253012048195,
      "grad_norm": 0.752807080745697,
      "learning_rate": 1.3068674698795181e-05,
      "loss": 0.0443,
      "step": 57530
    },
    {
      "epoch": 6.932530120481927,
      "grad_norm": 1.1616380214691162,
      "learning_rate": 1.3067469879518074e-05,
      "loss": 0.0666,
      "step": 57540
    },
    {
      "epoch": 6.933734939759036,
      "grad_norm": 0.5503596663475037,
      "learning_rate": 1.3066265060240966e-05,
      "loss": 0.0466,
      "step": 57550
    },
    {
      "epoch": 6.934939759036144,
      "grad_norm": 2.7174057960510254,
      "learning_rate": 1.3065060240963857e-05,
      "loss": 0.0311,
      "step": 57560
    },
    {
      "epoch": 6.936144578313253,
      "grad_norm": 3.14704966545105,
      "learning_rate": 1.306385542168675e-05,
      "loss": 0.0728,
      "step": 57570
    },
    {
      "epoch": 6.937349397590362,
      "grad_norm": 0.13899089395999908,
      "learning_rate": 1.3062650602409638e-05,
      "loss": 0.018,
      "step": 57580
    },
    {
      "epoch": 6.93855421686747,
      "grad_norm": 0.029292773455381393,
      "learning_rate": 1.306144578313253e-05,
      "loss": 0.0842,
      "step": 57590
    },
    {
      "epoch": 6.9397590361445785,
      "grad_norm": 2.1710703372955322,
      "learning_rate": 1.3060240963855421e-05,
      "loss": 0.0381,
      "step": 57600
    },
    {
      "epoch": 6.940963855421686,
      "grad_norm": 0.45769718289375305,
      "learning_rate": 1.3059036144578314e-05,
      "loss": 0.0325,
      "step": 57610
    },
    {
      "epoch": 6.942168674698795,
      "grad_norm": 1.2370457649230957,
      "learning_rate": 1.3057831325301206e-05,
      "loss": 0.0584,
      "step": 57620
    },
    {
      "epoch": 6.943373493975904,
      "grad_norm": 0.03153137117624283,
      "learning_rate": 1.3056626506024097e-05,
      "loss": 0.0329,
      "step": 57630
    },
    {
      "epoch": 6.944578313253012,
      "grad_norm": 0.042812444269657135,
      "learning_rate": 1.305542168674699e-05,
      "loss": 0.0317,
      "step": 57640
    },
    {
      "epoch": 6.945783132530121,
      "grad_norm": 0.08710025995969772,
      "learning_rate": 1.305421686746988e-05,
      "loss": 0.093,
      "step": 57650
    },
    {
      "epoch": 6.946987951807229,
      "grad_norm": 0.1562233567237854,
      "learning_rate": 1.3053012048192773e-05,
      "loss": 0.0283,
      "step": 57660
    },
    {
      "epoch": 6.948192771084337,
      "grad_norm": 0.0697188749909401,
      "learning_rate": 1.3051807228915663e-05,
      "loss": 0.0527,
      "step": 57670
    },
    {
      "epoch": 6.949397590361446,
      "grad_norm": 0.4094623625278473,
      "learning_rate": 1.3050602409638556e-05,
      "loss": 0.0057,
      "step": 57680
    },
    {
      "epoch": 6.950602409638554,
      "grad_norm": 0.0026747803203761578,
      "learning_rate": 1.3049397590361448e-05,
      "loss": 0.0184,
      "step": 57690
    },
    {
      "epoch": 6.951807228915663,
      "grad_norm": 0.3624269664287567,
      "learning_rate": 1.3048192771084337e-05,
      "loss": 0.0396,
      "step": 57700
    },
    {
      "epoch": 6.953012048192771,
      "grad_norm": 0.2418300360441208,
      "learning_rate": 1.3046987951807232e-05,
      "loss": 0.0427,
      "step": 57710
    },
    {
      "epoch": 6.95421686746988,
      "grad_norm": 5.9580607414245605,
      "learning_rate": 1.304578313253012e-05,
      "loss": 0.1296,
      "step": 57720
    },
    {
      "epoch": 6.955421686746988,
      "grad_norm": 2.1955244541168213,
      "learning_rate": 1.3044578313253013e-05,
      "loss": 0.0183,
      "step": 57730
    },
    {
      "epoch": 6.956626506024096,
      "grad_norm": 3.7248167991638184,
      "learning_rate": 1.3043373493975904e-05,
      "loss": 0.0506,
      "step": 57740
    },
    {
      "epoch": 6.957831325301205,
      "grad_norm": 45.13003921508789,
      "learning_rate": 1.3042168674698796e-05,
      "loss": 0.0614,
      "step": 57750
    },
    {
      "epoch": 6.959036144578313,
      "grad_norm": 0.1399838924407959,
      "learning_rate": 1.3040963855421689e-05,
      "loss": 0.0043,
      "step": 57760
    },
    {
      "epoch": 6.960240963855422,
      "grad_norm": 0.11464593559503555,
      "learning_rate": 1.303975903614458e-05,
      "loss": 0.01,
      "step": 57770
    },
    {
      "epoch": 6.96144578313253,
      "grad_norm": 0.14613443613052368,
      "learning_rate": 1.3038554216867472e-05,
      "loss": 0.0398,
      "step": 57780
    },
    {
      "epoch": 6.962650602409639,
      "grad_norm": 0.008212974295020103,
      "learning_rate": 1.3037349397590363e-05,
      "loss": 0.0872,
      "step": 57790
    },
    {
      "epoch": 6.9638554216867465,
      "grad_norm": 4.244421005249023,
      "learning_rate": 1.3036144578313255e-05,
      "loss": 0.0607,
      "step": 57800
    },
    {
      "epoch": 6.965060240963855,
      "grad_norm": 0.22787794470787048,
      "learning_rate": 1.3034939759036144e-05,
      "loss": 0.0132,
      "step": 57810
    },
    {
      "epoch": 6.966265060240964,
      "grad_norm": 0.5371257066726685,
      "learning_rate": 1.3033734939759038e-05,
      "loss": 0.03,
      "step": 57820
    },
    {
      "epoch": 6.967469879518072,
      "grad_norm": 0.3625715672969818,
      "learning_rate": 1.3032530120481927e-05,
      "loss": 0.0858,
      "step": 57830
    },
    {
      "epoch": 6.968674698795181,
      "grad_norm": 0.02391301840543747,
      "learning_rate": 1.303132530120482e-05,
      "loss": 0.0739,
      "step": 57840
    },
    {
      "epoch": 6.969879518072289,
      "grad_norm": 0.4286925494670868,
      "learning_rate": 1.3030120481927712e-05,
      "loss": 0.0325,
      "step": 57850
    },
    {
      "epoch": 6.971084337349398,
      "grad_norm": 4.186958312988281,
      "learning_rate": 1.3028915662650603e-05,
      "loss": 0.0435,
      "step": 57860
    },
    {
      "epoch": 6.972289156626506,
      "grad_norm": 8.695504188537598,
      "learning_rate": 1.3027710843373495e-05,
      "loss": 0.0499,
      "step": 57870
    },
    {
      "epoch": 6.973493975903614,
      "grad_norm": 0.021408556029200554,
      "learning_rate": 1.3026506024096386e-05,
      "loss": 0.0113,
      "step": 57880
    },
    {
      "epoch": 6.974698795180723,
      "grad_norm": 2.043837308883667,
      "learning_rate": 1.3025301204819278e-05,
      "loss": 0.0251,
      "step": 57890
    },
    {
      "epoch": 6.975903614457831,
      "grad_norm": 0.03069809079170227,
      "learning_rate": 1.3024096385542169e-05,
      "loss": 0.018,
      "step": 57900
    },
    {
      "epoch": 6.97710843373494,
      "grad_norm": 0.01899336278438568,
      "learning_rate": 1.3022891566265062e-05,
      "loss": 0.0393,
      "step": 57910
    },
    {
      "epoch": 6.978313253012049,
      "grad_norm": 1.3312500715255737,
      "learning_rate": 1.3021686746987954e-05,
      "loss": 0.1014,
      "step": 57920
    },
    {
      "epoch": 6.9795180722891565,
      "grad_norm": 22.323604583740234,
      "learning_rate": 1.3020481927710845e-05,
      "loss": 0.0917,
      "step": 57930
    },
    {
      "epoch": 6.980722891566265,
      "grad_norm": 4.56736946105957,
      "learning_rate": 1.3019277108433737e-05,
      "loss": 0.0387,
      "step": 57940
    },
    {
      "epoch": 6.981927710843373,
      "grad_norm": 67.8087158203125,
      "learning_rate": 1.3018072289156626e-05,
      "loss": 0.0904,
      "step": 57950
    },
    {
      "epoch": 6.983132530120482,
      "grad_norm": 0.08597172796726227,
      "learning_rate": 1.3016867469879519e-05,
      "loss": 0.0584,
      "step": 57960
    },
    {
      "epoch": 6.98433734939759,
      "grad_norm": 0.2795430123806,
      "learning_rate": 1.301566265060241e-05,
      "loss": 0.0068,
      "step": 57970
    },
    {
      "epoch": 6.985542168674699,
      "grad_norm": 3.6636922359466553,
      "learning_rate": 1.3014457831325302e-05,
      "loss": 0.0612,
      "step": 57980
    },
    {
      "epoch": 6.986746987951808,
      "grad_norm": 0.37376853823661804,
      "learning_rate": 1.3013253012048194e-05,
      "loss": 0.0101,
      "step": 57990
    },
    {
      "epoch": 6.9879518072289155,
      "grad_norm": 1.4648675918579102,
      "learning_rate": 1.3012048192771085e-05,
      "loss": 0.0787,
      "step": 58000
    },
    {
      "epoch": 6.989156626506024,
      "grad_norm": 0.24874775111675262,
      "learning_rate": 1.3010843373493977e-05,
      "loss": 0.0231,
      "step": 58010
    },
    {
      "epoch": 6.990361445783132,
      "grad_norm": 0.03721647337079048,
      "learning_rate": 1.3009638554216868e-05,
      "loss": 0.0585,
      "step": 58020
    },
    {
      "epoch": 6.991566265060241,
      "grad_norm": 1.0040167570114136,
      "learning_rate": 1.300843373493976e-05,
      "loss": 0.0304,
      "step": 58030
    },
    {
      "epoch": 6.992771084337349,
      "grad_norm": 0.016099192202091217,
      "learning_rate": 1.3007228915662651e-05,
      "loss": 0.0205,
      "step": 58040
    },
    {
      "epoch": 6.993975903614458,
      "grad_norm": 7.28893518447876,
      "learning_rate": 1.3006024096385544e-05,
      "loss": 0.0187,
      "step": 58050
    },
    {
      "epoch": 6.995180722891567,
      "grad_norm": 1.154929280281067,
      "learning_rate": 1.3004819277108436e-05,
      "loss": 0.0334,
      "step": 58060
    },
    {
      "epoch": 6.9963855421686745,
      "grad_norm": 1.0257701873779297,
      "learning_rate": 1.3003614457831327e-05,
      "loss": 0.0607,
      "step": 58070
    },
    {
      "epoch": 6.997590361445783,
      "grad_norm": 0.012762478552758694,
      "learning_rate": 1.300240963855422e-05,
      "loss": 0.0695,
      "step": 58080
    },
    {
      "epoch": 6.998795180722891,
      "grad_norm": 2.864968776702881,
      "learning_rate": 1.3001204819277108e-05,
      "loss": 0.0603,
      "step": 58090
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.008300110697746277,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.036,
      "step": 58100
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9825412448443944,
      "eval_f1": 0.9540718821281055,
      "eval_loss": 0.05347960814833641,
      "eval_precision": 0.9517835178351783,
      "eval_recall": 0.9563712767272278,
      "eval_runtime": 3397.0366,
      "eval_samples_per_second": 12.567,
      "eval_steps_per_second": 0.524,
      "step": 58100
    },
    {
      "epoch": 7.001204819277109,
      "grad_norm": 0.2710624635219574,
      "learning_rate": 1.2998795180722892e-05,
      "loss": 0.0208,
      "step": 58110
    },
    {
      "epoch": 7.002409638554217,
      "grad_norm": 2.3252549171447754,
      "learning_rate": 1.2997590361445784e-05,
      "loss": 0.0709,
      "step": 58120
    },
    {
      "epoch": 7.0036144578313255,
      "grad_norm": 0.4029863774776459,
      "learning_rate": 1.2996385542168677e-05,
      "loss": 0.0173,
      "step": 58130
    },
    {
      "epoch": 7.004819277108433,
      "grad_norm": 0.007641978096216917,
      "learning_rate": 1.2995180722891567e-05,
      "loss": 0.0308,
      "step": 58140
    },
    {
      "epoch": 7.006024096385542,
      "grad_norm": 0.06239940598607063,
      "learning_rate": 1.299397590361446e-05,
      "loss": 0.0611,
      "step": 58150
    },
    {
      "epoch": 7.00722891566265,
      "grad_norm": 0.08124258369207382,
      "learning_rate": 1.299277108433735e-05,
      "loss": 0.0371,
      "step": 58160
    },
    {
      "epoch": 7.008433734939759,
      "grad_norm": 0.018196526914834976,
      "learning_rate": 1.2991566265060243e-05,
      "loss": 0.0478,
      "step": 58170
    },
    {
      "epoch": 7.009638554216868,
      "grad_norm": 3.20967698097229,
      "learning_rate": 1.2990361445783134e-05,
      "loss": 0.0518,
      "step": 58180
    },
    {
      "epoch": 7.010843373493976,
      "grad_norm": 1.7243914604187012,
      "learning_rate": 1.2989156626506026e-05,
      "loss": 0.0306,
      "step": 58190
    },
    {
      "epoch": 7.0120481927710845,
      "grad_norm": 0.01908998005092144,
      "learning_rate": 1.2987951807228915e-05,
      "loss": 0.0692,
      "step": 58200
    },
    {
      "epoch": 7.013253012048192,
      "grad_norm": 1.1114054918289185,
      "learning_rate": 1.2986746987951808e-05,
      "loss": 0.0268,
      "step": 58210
    },
    {
      "epoch": 7.014457831325301,
      "grad_norm": 9.359797477722168,
      "learning_rate": 1.29855421686747e-05,
      "loss": 0.038,
      "step": 58220
    },
    {
      "epoch": 7.01566265060241,
      "grad_norm": 0.03136308863759041,
      "learning_rate": 1.298433734939759e-05,
      "loss": 0.0012,
      "step": 58230
    },
    {
      "epoch": 7.016867469879518,
      "grad_norm": 0.0070284102112054825,
      "learning_rate": 1.2983132530120483e-05,
      "loss": 0.0091,
      "step": 58240
    },
    {
      "epoch": 7.018072289156627,
      "grad_norm": 0.0066118487156927586,
      "learning_rate": 1.2981927710843374e-05,
      "loss": 0.0033,
      "step": 58250
    },
    {
      "epoch": 7.019277108433735,
      "grad_norm": 0.8809119462966919,
      "learning_rate": 1.2980722891566266e-05,
      "loss": 0.0104,
      "step": 58260
    },
    {
      "epoch": 7.0204819277108435,
      "grad_norm": 2.151543140411377,
      "learning_rate": 1.2979518072289157e-05,
      "loss": 0.0783,
      "step": 58270
    },
    {
      "epoch": 7.021686746987951,
      "grad_norm": 0.019881971180438995,
      "learning_rate": 1.297831325301205e-05,
      "loss": 0.0596,
      "step": 58280
    },
    {
      "epoch": 7.02289156626506,
      "grad_norm": 0.08247224986553192,
      "learning_rate": 1.2977108433734942e-05,
      "loss": 0.067,
      "step": 58290
    },
    {
      "epoch": 7.024096385542169,
      "grad_norm": 0.09413403272628784,
      "learning_rate": 1.2975903614457833e-05,
      "loss": 0.0158,
      "step": 58300
    },
    {
      "epoch": 7.025301204819277,
      "grad_norm": 0.1067347601056099,
      "learning_rate": 1.2974698795180725e-05,
      "loss": 0.0225,
      "step": 58310
    },
    {
      "epoch": 7.026506024096386,
      "grad_norm": 2.525953769683838,
      "learning_rate": 1.2973493975903614e-05,
      "loss": 0.0149,
      "step": 58320
    },
    {
      "epoch": 7.027710843373494,
      "grad_norm": 0.014188905246555805,
      "learning_rate": 1.2972289156626508e-05,
      "loss": 0.0232,
      "step": 58330
    },
    {
      "epoch": 7.028915662650602,
      "grad_norm": 0.09299633651971817,
      "learning_rate": 1.2971084337349397e-05,
      "loss": 0.06,
      "step": 58340
    },
    {
      "epoch": 7.030120481927711,
      "grad_norm": 0.13758578896522522,
      "learning_rate": 1.296987951807229e-05,
      "loss": 0.0268,
      "step": 58350
    },
    {
      "epoch": 7.031325301204819,
      "grad_norm": 0.17172273993492126,
      "learning_rate": 1.2968674698795182e-05,
      "loss": 0.0163,
      "step": 58360
    },
    {
      "epoch": 7.032530120481928,
      "grad_norm": 0.008757837116718292,
      "learning_rate": 1.2967469879518073e-05,
      "loss": 0.0419,
      "step": 58370
    },
    {
      "epoch": 7.033734939759036,
      "grad_norm": 3.6865718364715576,
      "learning_rate": 1.2966265060240965e-05,
      "loss": 0.0216,
      "step": 58380
    },
    {
      "epoch": 7.034939759036145,
      "grad_norm": 0.018295468762516975,
      "learning_rate": 1.2965060240963856e-05,
      "loss": 0.0487,
      "step": 58390
    },
    {
      "epoch": 7.036144578313253,
      "grad_norm": 38.134033203125,
      "learning_rate": 1.2963855421686749e-05,
      "loss": 0.0867,
      "step": 58400
    },
    {
      "epoch": 7.037349397590361,
      "grad_norm": 0.010256634093821049,
      "learning_rate": 1.296265060240964e-05,
      "loss": 0.0112,
      "step": 58410
    },
    {
      "epoch": 7.03855421686747,
      "grad_norm": 0.25148430466651917,
      "learning_rate": 1.2961445783132532e-05,
      "loss": 0.0112,
      "step": 58420
    },
    {
      "epoch": 7.039759036144578,
      "grad_norm": 0.015992548316717148,
      "learning_rate": 1.2960240963855424e-05,
      "loss": 0.0016,
      "step": 58430
    },
    {
      "epoch": 7.040963855421687,
      "grad_norm": 2.0106751918792725,
      "learning_rate": 1.2959036144578315e-05,
      "loss": 0.0332,
      "step": 58440
    },
    {
      "epoch": 7.042168674698795,
      "grad_norm": 0.15140406787395477,
      "learning_rate": 1.2957831325301207e-05,
      "loss": 0.0382,
      "step": 58450
    },
    {
      "epoch": 7.043373493975904,
      "grad_norm": 4.708261966705322,
      "learning_rate": 1.2956626506024096e-05,
      "loss": 0.0592,
      "step": 58460
    },
    {
      "epoch": 7.044578313253012,
      "grad_norm": 0.26632121205329895,
      "learning_rate": 1.2955421686746989e-05,
      "loss": 0.0463,
      "step": 58470
    },
    {
      "epoch": 7.04578313253012,
      "grad_norm": 0.25526612997055054,
      "learning_rate": 1.295421686746988e-05,
      "loss": 0.0405,
      "step": 58480
    },
    {
      "epoch": 7.046987951807229,
      "grad_norm": 1.0638731718063354,
      "learning_rate": 1.2953012048192772e-05,
      "loss": 0.0117,
      "step": 58490
    },
    {
      "epoch": 7.048192771084337,
      "grad_norm": 0.2841118574142456,
      "learning_rate": 1.2951807228915663e-05,
      "loss": 0.0113,
      "step": 58500
    },
    {
      "epoch": 7.049397590361446,
      "grad_norm": 18.888813018798828,
      "learning_rate": 1.2950602409638555e-05,
      "loss": 0.0499,
      "step": 58510
    },
    {
      "epoch": 7.050602409638554,
      "grad_norm": 0.015735387802124023,
      "learning_rate": 1.2949397590361448e-05,
      "loss": 0.0626,
      "step": 58520
    },
    {
      "epoch": 7.051807228915663,
      "grad_norm": 0.012756788171827793,
      "learning_rate": 1.2948192771084338e-05,
      "loss": 0.0017,
      "step": 58530
    },
    {
      "epoch": 7.053012048192771,
      "grad_norm": 0.0325908400118351,
      "learning_rate": 1.294698795180723e-05,
      "loss": 0.0393,
      "step": 58540
    },
    {
      "epoch": 7.054216867469879,
      "grad_norm": 0.016582226380705833,
      "learning_rate": 1.2945783132530122e-05,
      "loss": 0.056,
      "step": 58550
    },
    {
      "epoch": 7.055421686746988,
      "grad_norm": 0.023264609277248383,
      "learning_rate": 1.2944578313253014e-05,
      "loss": 0.0242,
      "step": 58560
    },
    {
      "epoch": 7.056626506024096,
      "grad_norm": 0.34512558579444885,
      "learning_rate": 1.2943373493975903e-05,
      "loss": 0.0053,
      "step": 58570
    },
    {
      "epoch": 7.057831325301205,
      "grad_norm": 0.1382925659418106,
      "learning_rate": 1.2942168674698795e-05,
      "loss": 0.032,
      "step": 58580
    },
    {
      "epoch": 7.059036144578314,
      "grad_norm": 5.920442581176758,
      "learning_rate": 1.294096385542169e-05,
      "loss": 0.0293,
      "step": 58590
    },
    {
      "epoch": 7.0602409638554215,
      "grad_norm": 0.03130263090133667,
      "learning_rate": 1.2939759036144579e-05,
      "loss": 0.016,
      "step": 58600
    },
    {
      "epoch": 7.06144578313253,
      "grad_norm": 0.0074917469173669815,
      "learning_rate": 1.2938554216867471e-05,
      "loss": 0.0117,
      "step": 58610
    },
    {
      "epoch": 7.062650602409638,
      "grad_norm": 0.005050521809607744,
      "learning_rate": 1.2937349397590362e-05,
      "loss": 0.0223,
      "step": 58620
    },
    {
      "epoch": 7.063855421686747,
      "grad_norm": 1.3248785734176636,
      "learning_rate": 1.2936144578313254e-05,
      "loss": 0.0247,
      "step": 58630
    },
    {
      "epoch": 7.065060240963855,
      "grad_norm": 0.005510963033884764,
      "learning_rate": 1.2934939759036145e-05,
      "loss": 0.135,
      "step": 58640
    },
    {
      "epoch": 7.066265060240964,
      "grad_norm": 5.797407627105713,
      "learning_rate": 1.2933734939759037e-05,
      "loss": 0.0548,
      "step": 58650
    },
    {
      "epoch": 7.067469879518073,
      "grad_norm": 2.875323534011841,
      "learning_rate": 1.293253012048193e-05,
      "loss": 0.0331,
      "step": 58660
    },
    {
      "epoch": 7.0686746987951805,
      "grad_norm": 0.03623032942414284,
      "learning_rate": 1.293132530120482e-05,
      "loss": 0.0175,
      "step": 58670
    },
    {
      "epoch": 7.069879518072289,
      "grad_norm": 0.008823282085359097,
      "learning_rate": 1.2930120481927713e-05,
      "loss": 0.0187,
      "step": 58680
    },
    {
      "epoch": 7.071084337349397,
      "grad_norm": 3.5978031158447266,
      "learning_rate": 1.2928915662650604e-05,
      "loss": 0.0397,
      "step": 58690
    },
    {
      "epoch": 7.072289156626506,
      "grad_norm": 0.1635979264974594,
      "learning_rate": 1.2927710843373496e-05,
      "loss": 0.0222,
      "step": 58700
    },
    {
      "epoch": 7.073493975903615,
      "grad_norm": 1.3149563074111938,
      "learning_rate": 1.2926506024096385e-05,
      "loss": 0.0075,
      "step": 58710
    },
    {
      "epoch": 7.074698795180723,
      "grad_norm": 0.34409549832344055,
      "learning_rate": 1.2925301204819278e-05,
      "loss": 0.047,
      "step": 58720
    },
    {
      "epoch": 7.075903614457832,
      "grad_norm": 0.0026860542129725218,
      "learning_rate": 1.292409638554217e-05,
      "loss": 0.0063,
      "step": 58730
    },
    {
      "epoch": 7.0771084337349395,
      "grad_norm": 6.912778377532959,
      "learning_rate": 1.292289156626506e-05,
      "loss": 0.0453,
      "step": 58740
    },
    {
      "epoch": 7.078313253012048,
      "grad_norm": 0.8380282521247864,
      "learning_rate": 1.2921686746987953e-05,
      "loss": 0.0173,
      "step": 58750
    },
    {
      "epoch": 7.079518072289156,
      "grad_norm": 1.6031413078308105,
      "learning_rate": 1.2920481927710844e-05,
      "loss": 0.0236,
      "step": 58760
    },
    {
      "epoch": 7.080722891566265,
      "grad_norm": 0.018799053505063057,
      "learning_rate": 1.2919277108433736e-05,
      "loss": 0.0255,
      "step": 58770
    },
    {
      "epoch": 7.081927710843374,
      "grad_norm": 0.04354855790734291,
      "learning_rate": 1.2918072289156627e-05,
      "loss": 0.034,
      "step": 58780
    },
    {
      "epoch": 7.083132530120482,
      "grad_norm": 0.009108158759772778,
      "learning_rate": 1.291686746987952e-05,
      "loss": 0.0181,
      "step": 58790
    },
    {
      "epoch": 7.0843373493975905,
      "grad_norm": 0.4961329698562622,
      "learning_rate": 1.291566265060241e-05,
      "loss": 0.0307,
      "step": 58800
    },
    {
      "epoch": 7.085542168674698,
      "grad_norm": 0.008976220153272152,
      "learning_rate": 1.2914457831325303e-05,
      "loss": 0.0281,
      "step": 58810
    },
    {
      "epoch": 7.086746987951807,
      "grad_norm": 0.2346406877040863,
      "learning_rate": 1.2913253012048195e-05,
      "loss": 0.0353,
      "step": 58820
    },
    {
      "epoch": 7.087951807228916,
      "grad_norm": 0.7898785471916199,
      "learning_rate": 1.2912048192771084e-05,
      "loss": 0.0514,
      "step": 58830
    },
    {
      "epoch": 7.089156626506024,
      "grad_norm": 0.04463285207748413,
      "learning_rate": 1.2910843373493977e-05,
      "loss": 0.0479,
      "step": 58840
    },
    {
      "epoch": 7.090361445783133,
      "grad_norm": 0.11174508184194565,
      "learning_rate": 1.2909638554216867e-05,
      "loss": 0.0278,
      "step": 58850
    },
    {
      "epoch": 7.091566265060241,
      "grad_norm": 3.5884530544281006,
      "learning_rate": 1.290843373493976e-05,
      "loss": 0.0343,
      "step": 58860
    },
    {
      "epoch": 7.0927710843373495,
      "grad_norm": 0.004221149254590273,
      "learning_rate": 1.290722891566265e-05,
      "loss": 0.0224,
      "step": 58870
    },
    {
      "epoch": 7.093975903614457,
      "grad_norm": 0.003629704937338829,
      "learning_rate": 1.2906024096385543e-05,
      "loss": 0.0263,
      "step": 58880
    },
    {
      "epoch": 7.095180722891566,
      "grad_norm": 0.004202862735837698,
      "learning_rate": 1.2904819277108435e-05,
      "loss": 0.0054,
      "step": 58890
    },
    {
      "epoch": 7.096385542168675,
      "grad_norm": 0.0054937684908509254,
      "learning_rate": 1.2903614457831326e-05,
      "loss": 0.0351,
      "step": 58900
    },
    {
      "epoch": 7.097590361445783,
      "grad_norm": 0.009653833694756031,
      "learning_rate": 1.2902409638554219e-05,
      "loss": 0.0398,
      "step": 58910
    },
    {
      "epoch": 7.098795180722892,
      "grad_norm": 0.0029756019357591867,
      "learning_rate": 1.290120481927711e-05,
      "loss": 0.012,
      "step": 58920
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.06902112811803818,
      "learning_rate": 1.2900000000000002e-05,
      "loss": 0.0215,
      "step": 58930
    },
    {
      "epoch": 7.1012048192771084,
      "grad_norm": 0.5075589418411255,
      "learning_rate": 1.2898795180722891e-05,
      "loss": 0.0495,
      "step": 58940
    },
    {
      "epoch": 7.102409638554217,
      "grad_norm": 0.7971881628036499,
      "learning_rate": 1.2897590361445785e-05,
      "loss": 0.0166,
      "step": 58950
    },
    {
      "epoch": 7.103614457831325,
      "grad_norm": 11.327779769897461,
      "learning_rate": 1.2896385542168677e-05,
      "loss": 0.0346,
      "step": 58960
    },
    {
      "epoch": 7.104819277108434,
      "grad_norm": 0.013852941803634167,
      "learning_rate": 1.2895180722891567e-05,
      "loss": 0.0054,
      "step": 58970
    },
    {
      "epoch": 7.106024096385542,
      "grad_norm": 0.0039210389368236065,
      "learning_rate": 1.2893975903614459e-05,
      "loss": 0.0024,
      "step": 58980
    },
    {
      "epoch": 7.107228915662651,
      "grad_norm": 0.7387517690658569,
      "learning_rate": 1.289277108433735e-05,
      "loss": 0.0986,
      "step": 58990
    },
    {
      "epoch": 7.108433734939759,
      "grad_norm": 0.00465979753062129,
      "learning_rate": 1.2891566265060242e-05,
      "loss": 0.0131,
      "step": 59000
    },
    {
      "epoch": 7.109638554216867,
      "grad_norm": 0.008483887650072575,
      "learning_rate": 1.2890361445783133e-05,
      "loss": 0.0983,
      "step": 59010
    },
    {
      "epoch": 7.110843373493976,
      "grad_norm": 0.6403743624687195,
      "learning_rate": 1.2889156626506025e-05,
      "loss": 0.0145,
      "step": 59020
    },
    {
      "epoch": 7.112048192771084,
      "grad_norm": 0.007467424962669611,
      "learning_rate": 1.2887951807228918e-05,
      "loss": 0.0082,
      "step": 59030
    },
    {
      "epoch": 7.113253012048193,
      "grad_norm": 2.119389772415161,
      "learning_rate": 1.2886746987951808e-05,
      "loss": 0.0171,
      "step": 59040
    },
    {
      "epoch": 7.114457831325301,
      "grad_norm": 5.032591819763184,
      "learning_rate": 1.2885542168674701e-05,
      "loss": 0.0666,
      "step": 59050
    },
    {
      "epoch": 7.11566265060241,
      "grad_norm": 1.2568608522415161,
      "learning_rate": 1.2884337349397592e-05,
      "loss": 0.0374,
      "step": 59060
    },
    {
      "epoch": 7.1168674698795185,
      "grad_norm": 0.016517961397767067,
      "learning_rate": 1.2883132530120484e-05,
      "loss": 0.0288,
      "step": 59070
    },
    {
      "epoch": 7.118072289156626,
      "grad_norm": 0.17993220686912537,
      "learning_rate": 1.2881927710843373e-05,
      "loss": 0.0639,
      "step": 59080
    },
    {
      "epoch": 7.119277108433735,
      "grad_norm": 2.195781946182251,
      "learning_rate": 1.2880722891566266e-05,
      "loss": 0.0188,
      "step": 59090
    },
    {
      "epoch": 7.120481927710843,
      "grad_norm": 0.6364485025405884,
      "learning_rate": 1.2879518072289156e-05,
      "loss": 0.0707,
      "step": 59100
    },
    {
      "epoch": 7.121686746987952,
      "grad_norm": 23.45953941345215,
      "learning_rate": 1.2878313253012049e-05,
      "loss": 0.0249,
      "step": 59110
    },
    {
      "epoch": 7.12289156626506,
      "grad_norm": 0.11519087105989456,
      "learning_rate": 1.2877108433734941e-05,
      "loss": 0.0269,
      "step": 59120
    },
    {
      "epoch": 7.124096385542169,
      "grad_norm": 1.9036082029342651,
      "learning_rate": 1.2875903614457832e-05,
      "loss": 0.0171,
      "step": 59130
    },
    {
      "epoch": 7.125301204819277,
      "grad_norm": 0.047241367399692535,
      "learning_rate": 1.2874698795180724e-05,
      "loss": 0.0531,
      "step": 59140
    },
    {
      "epoch": 7.126506024096385,
      "grad_norm": 2.034069299697876,
      "learning_rate": 1.2873493975903615e-05,
      "loss": 0.0477,
      "step": 59150
    },
    {
      "epoch": 7.127710843373494,
      "grad_norm": 5.6028618812561035,
      "learning_rate": 1.2872289156626508e-05,
      "loss": 0.0171,
      "step": 59160
    },
    {
      "epoch": 7.128915662650602,
      "grad_norm": 7.010952472686768,
      "learning_rate": 1.2871084337349398e-05,
      "loss": 0.0683,
      "step": 59170
    },
    {
      "epoch": 7.130120481927711,
      "grad_norm": 0.5491054654121399,
      "learning_rate": 1.286987951807229e-05,
      "loss": 0.0257,
      "step": 59180
    },
    {
      "epoch": 7.13132530120482,
      "grad_norm": 0.01634940877556801,
      "learning_rate": 1.2868674698795183e-05,
      "loss": 0.0202,
      "step": 59190
    },
    {
      "epoch": 7.132530120481928,
      "grad_norm": 0.21575157344341278,
      "learning_rate": 1.2867469879518072e-05,
      "loss": 0.0654,
      "step": 59200
    },
    {
      "epoch": 7.133734939759036,
      "grad_norm": 0.6143568754196167,
      "learning_rate": 1.2866265060240966e-05,
      "loss": 0.0142,
      "step": 59210
    },
    {
      "epoch": 7.134939759036144,
      "grad_norm": 0.006963517516851425,
      "learning_rate": 1.2865060240963855e-05,
      "loss": 0.0391,
      "step": 59220
    },
    {
      "epoch": 7.136144578313253,
      "grad_norm": 0.008899034932255745,
      "learning_rate": 1.2863855421686748e-05,
      "loss": 0.0149,
      "step": 59230
    },
    {
      "epoch": 7.137349397590361,
      "grad_norm": 0.3276626169681549,
      "learning_rate": 1.2862650602409639e-05,
      "loss": 0.0099,
      "step": 59240
    },
    {
      "epoch": 7.13855421686747,
      "grad_norm": 3.928518772125244,
      "learning_rate": 1.2861445783132531e-05,
      "loss": 0.0272,
      "step": 59250
    },
    {
      "epoch": 7.139759036144579,
      "grad_norm": 1.6330738067626953,
      "learning_rate": 1.2860240963855423e-05,
      "loss": 0.0929,
      "step": 59260
    },
    {
      "epoch": 7.1409638554216865,
      "grad_norm": 1.5285183191299438,
      "learning_rate": 1.2859036144578314e-05,
      "loss": 0.0139,
      "step": 59270
    },
    {
      "epoch": 7.142168674698795,
      "grad_norm": 0.05339399725198746,
      "learning_rate": 1.2857831325301207e-05,
      "loss": 0.0143,
      "step": 59280
    },
    {
      "epoch": 7.143373493975903,
      "grad_norm": 0.4838119447231293,
      "learning_rate": 1.2856626506024097e-05,
      "loss": 0.0295,
      "step": 59290
    },
    {
      "epoch": 7.144578313253012,
      "grad_norm": 0.05876467004418373,
      "learning_rate": 1.285542168674699e-05,
      "loss": 0.0499,
      "step": 59300
    },
    {
      "epoch": 7.145783132530121,
      "grad_norm": 0.007672126404941082,
      "learning_rate": 1.285421686746988e-05,
      "loss": 0.0221,
      "step": 59310
    },
    {
      "epoch": 7.146987951807229,
      "grad_norm": 1.0501257181167603,
      "learning_rate": 1.2853012048192773e-05,
      "loss": 0.055,
      "step": 59320
    },
    {
      "epoch": 7.148192771084338,
      "grad_norm": 0.007937617599964142,
      "learning_rate": 1.2851807228915665e-05,
      "loss": 0.0363,
      "step": 59330
    },
    {
      "epoch": 7.1493975903614455,
      "grad_norm": 0.00994113553315401,
      "learning_rate": 1.2850602409638554e-05,
      "loss": 0.0294,
      "step": 59340
    },
    {
      "epoch": 7.150602409638554,
      "grad_norm": 0.805361270904541,
      "learning_rate": 1.2849397590361447e-05,
      "loss": 0.0345,
      "step": 59350
    },
    {
      "epoch": 7.151807228915662,
      "grad_norm": 0.006639696657657623,
      "learning_rate": 1.2848192771084338e-05,
      "loss": 0.0381,
      "step": 59360
    },
    {
      "epoch": 7.153012048192771,
      "grad_norm": 0.009000124409794807,
      "learning_rate": 1.284698795180723e-05,
      "loss": 0.0634,
      "step": 59370
    },
    {
      "epoch": 7.15421686746988,
      "grad_norm": 0.354662150144577,
      "learning_rate": 1.284578313253012e-05,
      "loss": 0.0068,
      "step": 59380
    },
    {
      "epoch": 7.155421686746988,
      "grad_norm": 0.019293082877993584,
      "learning_rate": 1.2844578313253013e-05,
      "loss": 0.0331,
      "step": 59390
    },
    {
      "epoch": 7.156626506024097,
      "grad_norm": 0.0401650071144104,
      "learning_rate": 1.2843373493975904e-05,
      "loss": 0.0259,
      "step": 59400
    },
    {
      "epoch": 7.1578313253012045,
      "grad_norm": 0.4397730827331543,
      "learning_rate": 1.2842168674698796e-05,
      "loss": 0.0141,
      "step": 59410
    },
    {
      "epoch": 7.159036144578313,
      "grad_norm": 0.3681127727031708,
      "learning_rate": 1.2840963855421689e-05,
      "loss": 0.0565,
      "step": 59420
    },
    {
      "epoch": 7.160240963855422,
      "grad_norm": 0.006634563207626343,
      "learning_rate": 1.283975903614458e-05,
      "loss": 0.0223,
      "step": 59430
    },
    {
      "epoch": 7.16144578313253,
      "grad_norm": 0.009354366920888424,
      "learning_rate": 1.2838554216867472e-05,
      "loss": 0.0359,
      "step": 59440
    },
    {
      "epoch": 7.162650602409639,
      "grad_norm": 0.4310929775238037,
      "learning_rate": 1.2837349397590361e-05,
      "loss": 0.0382,
      "step": 59450
    },
    {
      "epoch": 7.163855421686747,
      "grad_norm": 0.20988503098487854,
      "learning_rate": 1.2836144578313255e-05,
      "loss": 0.0453,
      "step": 59460
    },
    {
      "epoch": 7.1650602409638555,
      "grad_norm": 1.2413737773895264,
      "learning_rate": 1.2834939759036144e-05,
      "loss": 0.0402,
      "step": 59470
    },
    {
      "epoch": 7.166265060240963,
      "grad_norm": 0.24460972845554352,
      "learning_rate": 1.2833734939759037e-05,
      "loss": 0.0038,
      "step": 59480
    },
    {
      "epoch": 7.167469879518072,
      "grad_norm": 0.126260906457901,
      "learning_rate": 1.2832530120481929e-05,
      "loss": 0.0034,
      "step": 59490
    },
    {
      "epoch": 7.168674698795181,
      "grad_norm": 1.9663689136505127,
      "learning_rate": 1.283132530120482e-05,
      "loss": 0.0544,
      "step": 59500
    },
    {
      "epoch": 7.169879518072289,
      "grad_norm": 0.006181764882057905,
      "learning_rate": 1.2830120481927712e-05,
      "loss": 0.0303,
      "step": 59510
    },
    {
      "epoch": 7.171084337349398,
      "grad_norm": 0.23913346230983734,
      "learning_rate": 1.2828915662650603e-05,
      "loss": 0.0664,
      "step": 59520
    },
    {
      "epoch": 7.172289156626506,
      "grad_norm": 1.2969709634780884,
      "learning_rate": 1.2827710843373495e-05,
      "loss": 0.0575,
      "step": 59530
    },
    {
      "epoch": 7.1734939759036145,
      "grad_norm": 0.8565375804901123,
      "learning_rate": 1.2826506024096386e-05,
      "loss": 0.0301,
      "step": 59540
    },
    {
      "epoch": 7.174698795180723,
      "grad_norm": 0.16427691280841827,
      "learning_rate": 1.2825301204819279e-05,
      "loss": 0.0195,
      "step": 59550
    },
    {
      "epoch": 7.175903614457831,
      "grad_norm": 0.26783129572868347,
      "learning_rate": 1.2824096385542171e-05,
      "loss": 0.0155,
      "step": 59560
    },
    {
      "epoch": 7.17710843373494,
      "grad_norm": 0.03833121061325073,
      "learning_rate": 1.2822891566265062e-05,
      "loss": 0.0311,
      "step": 59570
    },
    {
      "epoch": 7.178313253012048,
      "grad_norm": 0.010459902696311474,
      "learning_rate": 1.2821686746987954e-05,
      "loss": 0.0326,
      "step": 59580
    },
    {
      "epoch": 7.179518072289157,
      "grad_norm": 0.0359642393887043,
      "learning_rate": 1.2820481927710843e-05,
      "loss": 0.0392,
      "step": 59590
    },
    {
      "epoch": 7.180722891566265,
      "grad_norm": 0.012560595758259296,
      "learning_rate": 1.2819277108433736e-05,
      "loss": 0.0057,
      "step": 59600
    },
    {
      "epoch": 7.1819277108433734,
      "grad_norm": 0.01294197328388691,
      "learning_rate": 1.2818072289156626e-05,
      "loss": 0.0259,
      "step": 59610
    },
    {
      "epoch": 7.183132530120482,
      "grad_norm": 0.005897394381463528,
      "learning_rate": 1.2816867469879519e-05,
      "loss": 0.0189,
      "step": 59620
    },
    {
      "epoch": 7.18433734939759,
      "grad_norm": 0.4337764084339142,
      "learning_rate": 1.2815662650602411e-05,
      "loss": 0.0532,
      "step": 59630
    },
    {
      "epoch": 7.185542168674699,
      "grad_norm": 2.438262462615967,
      "learning_rate": 1.2814457831325302e-05,
      "loss": 0.0035,
      "step": 59640
    },
    {
      "epoch": 7.186746987951807,
      "grad_norm": 0.01952194608747959,
      "learning_rate": 1.2813253012048194e-05,
      "loss": 0.0767,
      "step": 59650
    },
    {
      "epoch": 7.187951807228916,
      "grad_norm": 0.006812826730310917,
      "learning_rate": 1.2812048192771085e-05,
      "loss": 0.0907,
      "step": 59660
    },
    {
      "epoch": 7.1891566265060245,
      "grad_norm": 0.07800047844648361,
      "learning_rate": 1.2810843373493978e-05,
      "loss": 0.0177,
      "step": 59670
    },
    {
      "epoch": 7.190361445783132,
      "grad_norm": 0.3575141727924347,
      "learning_rate": 1.2809638554216868e-05,
      "loss": 0.0651,
      "step": 59680
    },
    {
      "epoch": 7.191566265060241,
      "grad_norm": 0.016697462648153305,
      "learning_rate": 1.280843373493976e-05,
      "loss": 0.0319,
      "step": 59690
    },
    {
      "epoch": 7.192771084337349,
      "grad_norm": 0.9935458302497864,
      "learning_rate": 1.280722891566265e-05,
      "loss": 0.0186,
      "step": 59700
    },
    {
      "epoch": 7.193975903614458,
      "grad_norm": 17.361156463623047,
      "learning_rate": 1.2806024096385542e-05,
      "loss": 0.0382,
      "step": 59710
    },
    {
      "epoch": 7.195180722891566,
      "grad_norm": 0.03320835158228874,
      "learning_rate": 1.2804819277108436e-05,
      "loss": 0.056,
      "step": 59720
    },
    {
      "epoch": 7.196385542168675,
      "grad_norm": 4.074280261993408,
      "learning_rate": 1.2803614457831326e-05,
      "loss": 0.0237,
      "step": 59730
    },
    {
      "epoch": 7.1975903614457835,
      "grad_norm": 0.09246629476547241,
      "learning_rate": 1.2802409638554218e-05,
      "loss": 0.0308,
      "step": 59740
    },
    {
      "epoch": 7.198795180722891,
      "grad_norm": 0.011081076227128506,
      "learning_rate": 1.2801204819277109e-05,
      "loss": 0.0216,
      "step": 59750
    },
    {
      "epoch": 7.2,
      "grad_norm": 2.09580397605896,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0513,
      "step": 59760
    },
    {
      "epoch": 7.201204819277108,
      "grad_norm": 0.012851695530116558,
      "learning_rate": 1.2798795180722892e-05,
      "loss": 0.0598,
      "step": 59770
    },
    {
      "epoch": 7.202409638554217,
      "grad_norm": 1.693845272064209,
      "learning_rate": 1.2797590361445784e-05,
      "loss": 0.0399,
      "step": 59780
    },
    {
      "epoch": 7.203614457831326,
      "grad_norm": 0.833073079586029,
      "learning_rate": 1.2796385542168677e-05,
      "loss": 0.0288,
      "step": 59790
    },
    {
      "epoch": 7.204819277108434,
      "grad_norm": 6.936428546905518,
      "learning_rate": 1.2795180722891567e-05,
      "loss": 0.0492,
      "step": 59800
    },
    {
      "epoch": 7.206024096385542,
      "grad_norm": 1.8233869075775146,
      "learning_rate": 1.279397590361446e-05,
      "loss": 0.0386,
      "step": 59810
    },
    {
      "epoch": 7.20722891566265,
      "grad_norm": 0.0056917364709079266,
      "learning_rate": 1.279277108433735e-05,
      "loss": 0.0945,
      "step": 59820
    },
    {
      "epoch": 7.208433734939759,
      "grad_norm": 0.2200445830821991,
      "learning_rate": 1.2791566265060243e-05,
      "loss": 0.034,
      "step": 59830
    },
    {
      "epoch": 7.209638554216867,
      "grad_norm": 0.007566893473267555,
      "learning_rate": 1.2790361445783132e-05,
      "loss": 0.0113,
      "step": 59840
    },
    {
      "epoch": 7.210843373493976,
      "grad_norm": 0.02859911322593689,
      "learning_rate": 1.2789156626506025e-05,
      "loss": 0.0313,
      "step": 59850
    },
    {
      "epoch": 7.212048192771085,
      "grad_norm": 2.5827419757843018,
      "learning_rate": 1.2787951807228917e-05,
      "loss": 0.028,
      "step": 59860
    },
    {
      "epoch": 7.213253012048193,
      "grad_norm": 1.4268802404403687,
      "learning_rate": 1.2786746987951808e-05,
      "loss": 0.0405,
      "step": 59870
    },
    {
      "epoch": 7.214457831325301,
      "grad_norm": 0.02814611978828907,
      "learning_rate": 1.27855421686747e-05,
      "loss": 0.0089,
      "step": 59880
    },
    {
      "epoch": 7.215662650602409,
      "grad_norm": 0.11315487325191498,
      "learning_rate": 1.2784337349397591e-05,
      "loss": 0.0031,
      "step": 59890
    },
    {
      "epoch": 7.216867469879518,
      "grad_norm": 0.01605958119034767,
      "learning_rate": 1.2783132530120483e-05,
      "loss": 0.0233,
      "step": 59900
    },
    {
      "epoch": 7.218072289156627,
      "grad_norm": 0.3024613857269287,
      "learning_rate": 1.2781927710843374e-05,
      "loss": 0.0207,
      "step": 59910
    },
    {
      "epoch": 7.219277108433735,
      "grad_norm": 1.70705246925354,
      "learning_rate": 1.2780722891566267e-05,
      "loss": 0.046,
      "step": 59920
    },
    {
      "epoch": 7.220481927710844,
      "grad_norm": 0.028440650552511215,
      "learning_rate": 1.2779518072289159e-05,
      "loss": 0.0439,
      "step": 59930
    },
    {
      "epoch": 7.2216867469879515,
      "grad_norm": 0.012910122983157635,
      "learning_rate": 1.277831325301205e-05,
      "loss": 0.068,
      "step": 59940
    },
    {
      "epoch": 7.22289156626506,
      "grad_norm": 0.055386364459991455,
      "learning_rate": 1.2777108433734942e-05,
      "loss": 0.0074,
      "step": 59950
    },
    {
      "epoch": 7.224096385542168,
      "grad_norm": 0.007124321535229683,
      "learning_rate": 1.2775903614457831e-05,
      "loss": 0.0695,
      "step": 59960
    },
    {
      "epoch": 7.225301204819277,
      "grad_norm": 0.013434875756502151,
      "learning_rate": 1.2774698795180724e-05,
      "loss": 0.0074,
      "step": 59970
    },
    {
      "epoch": 7.226506024096386,
      "grad_norm": 4.603446960449219,
      "learning_rate": 1.2773493975903614e-05,
      "loss": 0.0989,
      "step": 59980
    },
    {
      "epoch": 7.227710843373494,
      "grad_norm": 0.6734297871589661,
      "learning_rate": 1.2772289156626507e-05,
      "loss": 0.0161,
      "step": 59990
    },
    {
      "epoch": 7.228915662650603,
      "grad_norm": 0.011750931851565838,
      "learning_rate": 1.2771084337349398e-05,
      "loss": 0.0219,
      "step": 60000
    },
    {
      "epoch": 7.2301204819277105,
      "grad_norm": 0.23004302382469177,
      "learning_rate": 1.276987951807229e-05,
      "loss": 0.0042,
      "step": 60010
    },
    {
      "epoch": 7.231325301204819,
      "grad_norm": 0.052573274821043015,
      "learning_rate": 1.2768674698795182e-05,
      "loss": 0.0314,
      "step": 60020
    },
    {
      "epoch": 7.232530120481928,
      "grad_norm": 48.67540740966797,
      "learning_rate": 1.2767469879518073e-05,
      "loss": 0.0429,
      "step": 60030
    },
    {
      "epoch": 7.233734939759036,
      "grad_norm": 0.007162314839661121,
      "learning_rate": 1.2766265060240966e-05,
      "loss": 0.0384,
      "step": 60040
    },
    {
      "epoch": 7.234939759036145,
      "grad_norm": 0.003904622048139572,
      "learning_rate": 1.2765060240963856e-05,
      "loss": 0.0083,
      "step": 60050
    },
    {
      "epoch": 7.236144578313253,
      "grad_norm": 1.5355805158615112,
      "learning_rate": 1.2763855421686749e-05,
      "loss": 0.0258,
      "step": 60060
    },
    {
      "epoch": 7.2373493975903616,
      "grad_norm": 0.7209028005599976,
      "learning_rate": 1.2762650602409638e-05,
      "loss": 0.0396,
      "step": 60070
    },
    {
      "epoch": 7.2385542168674695,
      "grad_norm": 9.29379940032959,
      "learning_rate": 1.2761445783132532e-05,
      "loss": 0.0609,
      "step": 60080
    },
    {
      "epoch": 7.239759036144578,
      "grad_norm": 1.2593450546264648,
      "learning_rate": 1.2760240963855424e-05,
      "loss": 0.0256,
      "step": 60090
    },
    {
      "epoch": 7.240963855421687,
      "grad_norm": 0.015578709542751312,
      "learning_rate": 1.2759036144578313e-05,
      "loss": 0.0386,
      "step": 60100
    },
    {
      "epoch": 7.242168674698795,
      "grad_norm": 0.11674600094556808,
      "learning_rate": 1.2757831325301206e-05,
      "loss": 0.053,
      "step": 60110
    },
    {
      "epoch": 7.243373493975904,
      "grad_norm": 8.830695152282715,
      "learning_rate": 1.2756626506024097e-05,
      "loss": 0.0552,
      "step": 60120
    },
    {
      "epoch": 7.244578313253012,
      "grad_norm": 1.1821578741073608,
      "learning_rate": 1.2755421686746989e-05,
      "loss": 0.0474,
      "step": 60130
    },
    {
      "epoch": 7.2457831325301205,
      "grad_norm": 0.011691423133015633,
      "learning_rate": 1.275421686746988e-05,
      "loss": 0.0116,
      "step": 60140
    },
    {
      "epoch": 7.246987951807229,
      "grad_norm": 0.01890343800187111,
      "learning_rate": 1.2753012048192772e-05,
      "loss": 0.024,
      "step": 60150
    },
    {
      "epoch": 7.248192771084337,
      "grad_norm": 2.6908843517303467,
      "learning_rate": 1.2751807228915665e-05,
      "loss": 0.0853,
      "step": 60160
    },
    {
      "epoch": 7.249397590361446,
      "grad_norm": 2.631831169128418,
      "learning_rate": 1.2750602409638555e-05,
      "loss": 0.0187,
      "step": 60170
    },
    {
      "epoch": 7.250602409638554,
      "grad_norm": 0.02108800783753395,
      "learning_rate": 1.2749397590361448e-05,
      "loss": 0.0396,
      "step": 60180
    },
    {
      "epoch": 7.251807228915663,
      "grad_norm": 1.124182939529419,
      "learning_rate": 1.2748192771084339e-05,
      "loss": 0.0145,
      "step": 60190
    },
    {
      "epoch": 7.253012048192771,
      "grad_norm": 2.844738721847534,
      "learning_rate": 1.2746987951807231e-05,
      "loss": 0.0263,
      "step": 60200
    },
    {
      "epoch": 7.2542168674698795,
      "grad_norm": 1.1522632837295532,
      "learning_rate": 1.274578313253012e-05,
      "loss": 0.0381,
      "step": 60210
    },
    {
      "epoch": 7.255421686746988,
      "grad_norm": 0.0911552831530571,
      "learning_rate": 1.2744578313253012e-05,
      "loss": 0.025,
      "step": 60220
    },
    {
      "epoch": 7.256626506024096,
      "grad_norm": 0.012988856993615627,
      "learning_rate": 1.2743373493975905e-05,
      "loss": 0.0378,
      "step": 60230
    },
    {
      "epoch": 7.257831325301205,
      "grad_norm": 0.023968033492565155,
      "learning_rate": 1.2742168674698796e-05,
      "loss": 0.0477,
      "step": 60240
    },
    {
      "epoch": 7.259036144578313,
      "grad_norm": 0.4307844638824463,
      "learning_rate": 1.2740963855421688e-05,
      "loss": 0.044,
      "step": 60250
    },
    {
      "epoch": 7.260240963855422,
      "grad_norm": 0.0024757091887295246,
      "learning_rate": 1.2739759036144579e-05,
      "loss": 0.0254,
      "step": 60260
    },
    {
      "epoch": 7.2614457831325305,
      "grad_norm": 2.4168519973754883,
      "learning_rate": 1.2738554216867471e-05,
      "loss": 0.0528,
      "step": 60270
    },
    {
      "epoch": 7.2626506024096384,
      "grad_norm": 0.009383578784763813,
      "learning_rate": 1.2737349397590362e-05,
      "loss": 0.0009,
      "step": 60280
    },
    {
      "epoch": 7.263855421686747,
      "grad_norm": 4.309227466583252,
      "learning_rate": 1.2736144578313254e-05,
      "loss": 0.0521,
      "step": 60290
    },
    {
      "epoch": 7.265060240963855,
      "grad_norm": 0.005210711155086756,
      "learning_rate": 1.2734939759036145e-05,
      "loss": 0.0016,
      "step": 60300
    },
    {
      "epoch": 7.266265060240964,
      "grad_norm": 2.9451236724853516,
      "learning_rate": 1.2733734939759038e-05,
      "loss": 0.0482,
      "step": 60310
    },
    {
      "epoch": 7.267469879518072,
      "grad_norm": 0.06774431467056274,
      "learning_rate": 1.273253012048193e-05,
      "loss": 0.0335,
      "step": 60320
    },
    {
      "epoch": 7.268674698795181,
      "grad_norm": 0.13058967888355255,
      "learning_rate": 1.2731325301204819e-05,
      "loss": 0.0434,
      "step": 60330
    },
    {
      "epoch": 7.2698795180722895,
      "grad_norm": 0.2366533875465393,
      "learning_rate": 1.2730120481927713e-05,
      "loss": 0.0303,
      "step": 60340
    },
    {
      "epoch": 7.271084337349397,
      "grad_norm": 0.03246791288256645,
      "learning_rate": 1.2728915662650602e-05,
      "loss": 0.0134,
      "step": 60350
    },
    {
      "epoch": 7.272289156626506,
      "grad_norm": 3.2520763874053955,
      "learning_rate": 1.2727710843373495e-05,
      "loss": 0.0342,
      "step": 60360
    },
    {
      "epoch": 7.273493975903614,
      "grad_norm": 0.00480575580149889,
      "learning_rate": 1.2726506024096385e-05,
      "loss": 0.0249,
      "step": 60370
    },
    {
      "epoch": 7.274698795180723,
      "grad_norm": 0.059159912168979645,
      "learning_rate": 1.2725301204819278e-05,
      "loss": 0.0445,
      "step": 60380
    },
    {
      "epoch": 7.275903614457832,
      "grad_norm": 0.47898343205451965,
      "learning_rate": 1.272409638554217e-05,
      "loss": 0.0466,
      "step": 60390
    },
    {
      "epoch": 7.27710843373494,
      "grad_norm": 0.14969435334205627,
      "learning_rate": 1.2722891566265061e-05,
      "loss": 0.0435,
      "step": 60400
    },
    {
      "epoch": 7.2783132530120485,
      "grad_norm": 0.2105448693037033,
      "learning_rate": 1.2721686746987953e-05,
      "loss": 0.0406,
      "step": 60410
    },
    {
      "epoch": 7.279518072289156,
      "grad_norm": 1.7166343927383423,
      "learning_rate": 1.2720481927710844e-05,
      "loss": 0.027,
      "step": 60420
    },
    {
      "epoch": 7.280722891566265,
      "grad_norm": 9.23382568359375,
      "learning_rate": 1.2719277108433737e-05,
      "loss": 0.0834,
      "step": 60430
    },
    {
      "epoch": 7.281927710843373,
      "grad_norm": 1.2212939262390137,
      "learning_rate": 1.2718072289156627e-05,
      "loss": 0.0175,
      "step": 60440
    },
    {
      "epoch": 7.283132530120482,
      "grad_norm": 0.11582658439874649,
      "learning_rate": 1.271686746987952e-05,
      "loss": 0.0506,
      "step": 60450
    },
    {
      "epoch": 7.284337349397591,
      "grad_norm": 0.2547021210193634,
      "learning_rate": 1.2715662650602412e-05,
      "loss": 0.0408,
      "step": 60460
    },
    {
      "epoch": 7.285542168674699,
      "grad_norm": 0.9944968223571777,
      "learning_rate": 1.2714457831325301e-05,
      "loss": 0.0324,
      "step": 60470
    },
    {
      "epoch": 7.286746987951807,
      "grad_norm": 0.9509879350662231,
      "learning_rate": 1.2713253012048194e-05,
      "loss": 0.0429,
      "step": 60480
    },
    {
      "epoch": 7.287951807228915,
      "grad_norm": 1.5043660402297974,
      "learning_rate": 1.2712048192771084e-05,
      "loss": 0.0168,
      "step": 60490
    },
    {
      "epoch": 7.289156626506024,
      "grad_norm": 0.881156325340271,
      "learning_rate": 1.2710843373493977e-05,
      "loss": 0.0071,
      "step": 60500
    },
    {
      "epoch": 7.290361445783133,
      "grad_norm": 0.011696713045239449,
      "learning_rate": 1.2709638554216868e-05,
      "loss": 0.0117,
      "step": 60510
    },
    {
      "epoch": 7.291566265060241,
      "grad_norm": 0.22809480130672455,
      "learning_rate": 1.270843373493976e-05,
      "loss": 0.0407,
      "step": 60520
    },
    {
      "epoch": 7.29277108433735,
      "grad_norm": 0.014466937631368637,
      "learning_rate": 1.2707228915662653e-05,
      "loss": 0.0261,
      "step": 60530
    },
    {
      "epoch": 7.293975903614458,
      "grad_norm": 0.9673734307289124,
      "learning_rate": 1.2706024096385543e-05,
      "loss": 0.0042,
      "step": 60540
    },
    {
      "epoch": 7.295180722891566,
      "grad_norm": 0.11913382261991501,
      "learning_rate": 1.2704819277108436e-05,
      "loss": 0.0744,
      "step": 60550
    },
    {
      "epoch": 7.296385542168674,
      "grad_norm": 1.6669880151748657,
      "learning_rate": 1.2703614457831326e-05,
      "loss": 0.016,
      "step": 60560
    },
    {
      "epoch": 7.297590361445783,
      "grad_norm": 0.02990465611219406,
      "learning_rate": 1.2702409638554219e-05,
      "loss": 0.0293,
      "step": 60570
    },
    {
      "epoch": 7.298795180722892,
      "grad_norm": 0.4675697684288025,
      "learning_rate": 1.2701204819277108e-05,
      "loss": 0.0211,
      "step": 60580
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.09811335802078247,
      "learning_rate": 1.27e-05,
      "loss": 0.0451,
      "step": 60590
    },
    {
      "epoch": 7.301204819277109,
      "grad_norm": 1.2356404066085815,
      "learning_rate": 1.2698795180722891e-05,
      "loss": 0.0259,
      "step": 60600
    },
    {
      "epoch": 7.3024096385542165,
      "grad_norm": 0.22345072031021118,
      "learning_rate": 1.2697590361445784e-05,
      "loss": 0.0308,
      "step": 60610
    },
    {
      "epoch": 7.303614457831325,
      "grad_norm": 0.0035805157385766506,
      "learning_rate": 1.2696385542168676e-05,
      "loss": 0.0337,
      "step": 60620
    },
    {
      "epoch": 7.304819277108434,
      "grad_norm": 0.2162664830684662,
      "learning_rate": 1.2695180722891567e-05,
      "loss": 0.0315,
      "step": 60630
    },
    {
      "epoch": 7.306024096385542,
      "grad_norm": 1.2658711671829224,
      "learning_rate": 1.269397590361446e-05,
      "loss": 0.0198,
      "step": 60640
    },
    {
      "epoch": 7.307228915662651,
      "grad_norm": 0.0025862473994493484,
      "learning_rate": 1.269277108433735e-05,
      "loss": 0.0556,
      "step": 60650
    },
    {
      "epoch": 7.308433734939759,
      "grad_norm": 0.9512344598770142,
      "learning_rate": 1.2691566265060242e-05,
      "loss": 0.0247,
      "step": 60660
    },
    {
      "epoch": 7.309638554216868,
      "grad_norm": 1.1095051765441895,
      "learning_rate": 1.2690361445783133e-05,
      "loss": 0.004,
      "step": 60670
    },
    {
      "epoch": 7.3108433734939755,
      "grad_norm": 2.2537059783935547,
      "learning_rate": 1.2689156626506026e-05,
      "loss": 0.0946,
      "step": 60680
    },
    {
      "epoch": 7.312048192771084,
      "grad_norm": 1.5687761306762695,
      "learning_rate": 1.2687951807228918e-05,
      "loss": 0.0317,
      "step": 60690
    },
    {
      "epoch": 7.313253012048193,
      "grad_norm": 0.06889202445745468,
      "learning_rate": 1.2686746987951809e-05,
      "loss": 0.0388,
      "step": 60700
    },
    {
      "epoch": 7.314457831325301,
      "grad_norm": 0.9067549705505371,
      "learning_rate": 1.2685542168674701e-05,
      "loss": 0.0178,
      "step": 60710
    },
    {
      "epoch": 7.31566265060241,
      "grad_norm": 0.06427087634801865,
      "learning_rate": 1.268433734939759e-05,
      "loss": 0.0282,
      "step": 60720
    },
    {
      "epoch": 7.316867469879518,
      "grad_norm": 0.011437776498496532,
      "learning_rate": 1.2683132530120483e-05,
      "loss": 0.0107,
      "step": 60730
    },
    {
      "epoch": 7.3180722891566266,
      "grad_norm": 0.7241823077201843,
      "learning_rate": 1.2681927710843373e-05,
      "loss": 0.0332,
      "step": 60740
    },
    {
      "epoch": 7.3192771084337345,
      "grad_norm": 0.39145249128341675,
      "learning_rate": 1.2680722891566266e-05,
      "loss": 0.006,
      "step": 60750
    },
    {
      "epoch": 7.320481927710843,
      "grad_norm": 0.002284775022417307,
      "learning_rate": 1.2679518072289158e-05,
      "loss": 0.0069,
      "step": 60760
    },
    {
      "epoch": 7.321686746987952,
      "grad_norm": 0.0013714913511648774,
      "learning_rate": 1.2678313253012049e-05,
      "loss": 0.0133,
      "step": 60770
    },
    {
      "epoch": 7.32289156626506,
      "grad_norm": 5.017638206481934,
      "learning_rate": 1.2677108433734941e-05,
      "loss": 0.0478,
      "step": 60780
    },
    {
      "epoch": 7.324096385542169,
      "grad_norm": 1.454397439956665,
      "learning_rate": 1.2675903614457832e-05,
      "loss": 0.0261,
      "step": 60790
    },
    {
      "epoch": 7.325301204819277,
      "grad_norm": 0.053959738463163376,
      "learning_rate": 1.2674698795180725e-05,
      "loss": 0.0127,
      "step": 60800
    },
    {
      "epoch": 7.3265060240963855,
      "grad_norm": 28.620840072631836,
      "learning_rate": 1.2673493975903615e-05,
      "loss": 0.0427,
      "step": 60810
    },
    {
      "epoch": 7.327710843373494,
      "grad_norm": 0.0031426395289599895,
      "learning_rate": 1.2672289156626508e-05,
      "loss": 0.0071,
      "step": 60820
    },
    {
      "epoch": 7.328915662650602,
      "grad_norm": 0.013861080631613731,
      "learning_rate": 1.26710843373494e-05,
      "loss": 0.0465,
      "step": 60830
    },
    {
      "epoch": 7.330120481927711,
      "grad_norm": 0.0017444570548832417,
      "learning_rate": 1.266987951807229e-05,
      "loss": 0.0271,
      "step": 60840
    },
    {
      "epoch": 7.331325301204819,
      "grad_norm": 0.0020198929123580456,
      "learning_rate": 1.2668674698795183e-05,
      "loss": 0.0293,
      "step": 60850
    },
    {
      "epoch": 7.332530120481928,
      "grad_norm": 22.602989196777344,
      "learning_rate": 1.2667469879518072e-05,
      "loss": 0.0922,
      "step": 60860
    },
    {
      "epoch": 7.333734939759037,
      "grad_norm": 1.0196092128753662,
      "learning_rate": 1.2666265060240965e-05,
      "loss": 0.0085,
      "step": 60870
    },
    {
      "epoch": 7.3349397590361445,
      "grad_norm": 0.04194281995296478,
      "learning_rate": 1.2665060240963856e-05,
      "loss": 0.0109,
      "step": 60880
    },
    {
      "epoch": 7.336144578313253,
      "grad_norm": 0.001971455290913582,
      "learning_rate": 1.2663855421686748e-05,
      "loss": 0.029,
      "step": 60890
    },
    {
      "epoch": 7.337349397590361,
      "grad_norm": 1.77228844165802,
      "learning_rate": 1.2662650602409639e-05,
      "loss": 0.0841,
      "step": 60900
    },
    {
      "epoch": 7.33855421686747,
      "grad_norm": 1.3812289237976074,
      "learning_rate": 1.2661445783132531e-05,
      "loss": 0.0717,
      "step": 60910
    },
    {
      "epoch": 7.339759036144578,
      "grad_norm": 0.7083632349967957,
      "learning_rate": 1.2660240963855424e-05,
      "loss": 0.0701,
      "step": 60920
    },
    {
      "epoch": 7.340963855421687,
      "grad_norm": 2.530099630355835,
      "learning_rate": 1.2659036144578314e-05,
      "loss": 0.0376,
      "step": 60930
    },
    {
      "epoch": 7.3421686746987955,
      "grad_norm": 6.034915924072266,
      "learning_rate": 1.2657831325301207e-05,
      "loss": 0.0533,
      "step": 60940
    },
    {
      "epoch": 7.343373493975903,
      "grad_norm": 0.02244294434785843,
      "learning_rate": 1.2656626506024098e-05,
      "loss": 0.0252,
      "step": 60950
    },
    {
      "epoch": 7.344578313253012,
      "grad_norm": 0.008713741786777973,
      "learning_rate": 1.265542168674699e-05,
      "loss": 0.0524,
      "step": 60960
    },
    {
      "epoch": 7.34578313253012,
      "grad_norm": 1.392812967300415,
      "learning_rate": 1.2654216867469879e-05,
      "loss": 0.0421,
      "step": 60970
    },
    {
      "epoch": 7.346987951807229,
      "grad_norm": 0.004116444382816553,
      "learning_rate": 1.2653012048192771e-05,
      "loss": 0.017,
      "step": 60980
    },
    {
      "epoch": 7.348192771084337,
      "grad_norm": 0.05682188645005226,
      "learning_rate": 1.2651807228915664e-05,
      "loss": 0.0273,
      "step": 60990
    },
    {
      "epoch": 7.349397590361446,
      "grad_norm": 0.38084283471107483,
      "learning_rate": 1.2650602409638555e-05,
      "loss": 0.0246,
      "step": 61000
    },
    {
      "epoch": 7.3506024096385545,
      "grad_norm": 2.801203966140747,
      "learning_rate": 1.2649397590361447e-05,
      "loss": 0.05,
      "step": 61010
    },
    {
      "epoch": 7.351807228915662,
      "grad_norm": 0.009642778895795345,
      "learning_rate": 1.2648192771084338e-05,
      "loss": 0.0076,
      "step": 61020
    },
    {
      "epoch": 7.353012048192771,
      "grad_norm": 0.11842996627092361,
      "learning_rate": 1.264698795180723e-05,
      "loss": 0.0048,
      "step": 61030
    },
    {
      "epoch": 7.354216867469879,
      "grad_norm": 0.18499885499477386,
      "learning_rate": 1.2645783132530121e-05,
      "loss": 0.0773,
      "step": 61040
    },
    {
      "epoch": 7.355421686746988,
      "grad_norm": 0.007279477547854185,
      "learning_rate": 1.2644578313253013e-05,
      "loss": 0.0513,
      "step": 61050
    },
    {
      "epoch": 7.356626506024097,
      "grad_norm": 12.305767059326172,
      "learning_rate": 1.2643373493975906e-05,
      "loss": 0.0735,
      "step": 61060
    },
    {
      "epoch": 7.357831325301205,
      "grad_norm": 7.643435478210449,
      "learning_rate": 1.2642168674698797e-05,
      "loss": 0.0355,
      "step": 61070
    },
    {
      "epoch": 7.3590361445783135,
      "grad_norm": 3.9113657474517822,
      "learning_rate": 1.2640963855421689e-05,
      "loss": 0.0328,
      "step": 61080
    },
    {
      "epoch": 7.360240963855421,
      "grad_norm": 1.0630395412445068,
      "learning_rate": 1.2639759036144578e-05,
      "loss": 0.0252,
      "step": 61090
    },
    {
      "epoch": 7.36144578313253,
      "grad_norm": 0.27412092685699463,
      "learning_rate": 1.263855421686747e-05,
      "loss": 0.04,
      "step": 61100
    },
    {
      "epoch": 7.362650602409639,
      "grad_norm": 3.224320888519287,
      "learning_rate": 1.2637349397590361e-05,
      "loss": 0.0329,
      "step": 61110
    },
    {
      "epoch": 7.363855421686747,
      "grad_norm": 1.9271655082702637,
      "learning_rate": 1.2636144578313254e-05,
      "loss": 0.0552,
      "step": 61120
    },
    {
      "epoch": 7.365060240963856,
      "grad_norm": 0.6452322006225586,
      "learning_rate": 1.2634939759036146e-05,
      "loss": 0.021,
      "step": 61130
    },
    {
      "epoch": 7.366265060240964,
      "grad_norm": 0.7005323171615601,
      "learning_rate": 1.2633734939759037e-05,
      "loss": 0.1079,
      "step": 61140
    },
    {
      "epoch": 7.367469879518072,
      "grad_norm": 3.810011148452759,
      "learning_rate": 1.263253012048193e-05,
      "loss": 0.0444,
      "step": 61150
    },
    {
      "epoch": 7.36867469879518,
      "grad_norm": 0.15820001065731049,
      "learning_rate": 1.263132530120482e-05,
      "loss": 0.048,
      "step": 61160
    },
    {
      "epoch": 7.369879518072289,
      "grad_norm": 0.07480745017528534,
      "learning_rate": 1.2630120481927712e-05,
      "loss": 0.0091,
      "step": 61170
    },
    {
      "epoch": 7.371084337349398,
      "grad_norm": 0.018458489328622818,
      "learning_rate": 1.2628915662650603e-05,
      "loss": 0.0373,
      "step": 61180
    },
    {
      "epoch": 7.372289156626506,
      "grad_norm": 0.4045737683773041,
      "learning_rate": 1.2627710843373496e-05,
      "loss": 0.0264,
      "step": 61190
    },
    {
      "epoch": 7.373493975903615,
      "grad_norm": 0.021077528595924377,
      "learning_rate": 1.2626506024096385e-05,
      "loss": 0.0238,
      "step": 61200
    },
    {
      "epoch": 7.374698795180723,
      "grad_norm": 0.39826738834381104,
      "learning_rate": 1.2625301204819279e-05,
      "loss": 0.0258,
      "step": 61210
    },
    {
      "epoch": 7.375903614457831,
      "grad_norm": 0.010315322317183018,
      "learning_rate": 1.2624096385542171e-05,
      "loss": 0.0159,
      "step": 61220
    },
    {
      "epoch": 7.377108433734939,
      "grad_norm": 6.754802703857422,
      "learning_rate": 1.262289156626506e-05,
      "loss": 0.0327,
      "step": 61230
    },
    {
      "epoch": 7.378313253012048,
      "grad_norm": 1.8629310131072998,
      "learning_rate": 1.2621686746987953e-05,
      "loss": 0.042,
      "step": 61240
    },
    {
      "epoch": 7.379518072289157,
      "grad_norm": 0.004552745725959539,
      "learning_rate": 1.2620481927710843e-05,
      "loss": 0.0124,
      "step": 61250
    },
    {
      "epoch": 7.380722891566265,
      "grad_norm": 0.001159489038400352,
      "learning_rate": 1.2619277108433736e-05,
      "loss": 0.0238,
      "step": 61260
    },
    {
      "epoch": 7.381927710843374,
      "grad_norm": 0.01777283474802971,
      "learning_rate": 1.2618072289156627e-05,
      "loss": 0.0032,
      "step": 61270
    },
    {
      "epoch": 7.3831325301204815,
      "grad_norm": 0.9556159377098083,
      "learning_rate": 1.2616867469879519e-05,
      "loss": 0.0742,
      "step": 61280
    },
    {
      "epoch": 7.38433734939759,
      "grad_norm": 0.19152416288852692,
      "learning_rate": 1.2615662650602412e-05,
      "loss": 0.042,
      "step": 61290
    },
    {
      "epoch": 7.385542168674699,
      "grad_norm": 0.014132210984826088,
      "learning_rate": 1.2614457831325302e-05,
      "loss": 0.0143,
      "step": 61300
    },
    {
      "epoch": 7.386746987951807,
      "grad_norm": 0.8674830794334412,
      "learning_rate": 1.2613253012048195e-05,
      "loss": 0.043,
      "step": 61310
    },
    {
      "epoch": 7.387951807228916,
      "grad_norm": 0.3921523690223694,
      "learning_rate": 1.2612048192771085e-05,
      "loss": 0.021,
      "step": 61320
    },
    {
      "epoch": 7.389156626506024,
      "grad_norm": 2.099665403366089,
      "learning_rate": 1.2610843373493978e-05,
      "loss": 0.0341,
      "step": 61330
    },
    {
      "epoch": 7.390361445783133,
      "grad_norm": 0.006145874038338661,
      "learning_rate": 1.2609638554216867e-05,
      "loss": 0.0346,
      "step": 61340
    },
    {
      "epoch": 7.391566265060241,
      "grad_norm": 0.0027937323320657015,
      "learning_rate": 1.260843373493976e-05,
      "loss": 0.0398,
      "step": 61350
    },
    {
      "epoch": 7.392771084337349,
      "grad_norm": 0.004687197040766478,
      "learning_rate": 1.2607228915662652e-05,
      "loss": 0.0493,
      "step": 61360
    },
    {
      "epoch": 7.393975903614458,
      "grad_norm": 0.004471159540116787,
      "learning_rate": 1.2606024096385543e-05,
      "loss": 0.0383,
      "step": 61370
    },
    {
      "epoch": 7.395180722891566,
      "grad_norm": 0.013142379932105541,
      "learning_rate": 1.2604819277108435e-05,
      "loss": 0.0358,
      "step": 61380
    },
    {
      "epoch": 7.396385542168675,
      "grad_norm": 11.88115119934082,
      "learning_rate": 1.2603614457831326e-05,
      "loss": 0.0702,
      "step": 61390
    },
    {
      "epoch": 7.397590361445783,
      "grad_norm": 0.21319694817066193,
      "learning_rate": 1.2602409638554218e-05,
      "loss": 0.0265,
      "step": 61400
    },
    {
      "epoch": 7.3987951807228916,
      "grad_norm": 8.83803653717041,
      "learning_rate": 1.2601204819277109e-05,
      "loss": 0.0981,
      "step": 61410
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.03447682410478592,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.0881,
      "step": 61420
    },
    {
      "epoch": 7.401204819277108,
      "grad_norm": 60.6384391784668,
      "learning_rate": 1.2598795180722894e-05,
      "loss": 0.0135,
      "step": 61430
    },
    {
      "epoch": 7.402409638554217,
      "grad_norm": 3.9761173725128174,
      "learning_rate": 1.2597590361445785e-05,
      "loss": 0.0698,
      "step": 61440
    },
    {
      "epoch": 7.403614457831325,
      "grad_norm": 0.5291115641593933,
      "learning_rate": 1.2596385542168677e-05,
      "loss": 0.0176,
      "step": 61450
    },
    {
      "epoch": 7.404819277108434,
      "grad_norm": 0.05969134345650673,
      "learning_rate": 1.2595180722891566e-05,
      "loss": 0.0347,
      "step": 61460
    },
    {
      "epoch": 7.406024096385542,
      "grad_norm": 0.2554093301296234,
      "learning_rate": 1.259397590361446e-05,
      "loss": 0.0057,
      "step": 61470
    },
    {
      "epoch": 7.4072289156626505,
      "grad_norm": 15.19473648071289,
      "learning_rate": 1.259277108433735e-05,
      "loss": 0.0587,
      "step": 61480
    },
    {
      "epoch": 7.408433734939759,
      "grad_norm": 0.861972451210022,
      "learning_rate": 1.2591566265060242e-05,
      "loss": 0.0297,
      "step": 61490
    },
    {
      "epoch": 7.409638554216867,
      "grad_norm": 0.13498470187187195,
      "learning_rate": 1.2590361445783132e-05,
      "loss": 0.0439,
      "step": 61500
    },
    {
      "epoch": 7.410843373493976,
      "grad_norm": 0.005240546073764563,
      "learning_rate": 1.2589156626506025e-05,
      "loss": 0.0014,
      "step": 61510
    },
    {
      "epoch": 7.412048192771084,
      "grad_norm": 0.02814071998000145,
      "learning_rate": 1.2587951807228917e-05,
      "loss": 0.0106,
      "step": 61520
    },
    {
      "epoch": 7.413253012048193,
      "grad_norm": 226.84063720703125,
      "learning_rate": 1.2586746987951808e-05,
      "loss": 0.0292,
      "step": 61530
    },
    {
      "epoch": 7.414457831325302,
      "grad_norm": 0.02931012585759163,
      "learning_rate": 1.25855421686747e-05,
      "loss": 0.0398,
      "step": 61540
    },
    {
      "epoch": 7.4156626506024095,
      "grad_norm": 1.2168998718261719,
      "learning_rate": 1.2584337349397591e-05,
      "loss": 0.0671,
      "step": 61550
    },
    {
      "epoch": 7.416867469879518,
      "grad_norm": 0.003389398567378521,
      "learning_rate": 1.2583132530120484e-05,
      "loss": 0.0673,
      "step": 61560
    },
    {
      "epoch": 7.418072289156626,
      "grad_norm": 0.03256167843937874,
      "learning_rate": 1.2581927710843374e-05,
      "loss": 0.0093,
      "step": 61570
    },
    {
      "epoch": 7.419277108433735,
      "grad_norm": 0.026442527770996094,
      "learning_rate": 1.2580722891566267e-05,
      "loss": 0.0304,
      "step": 61580
    },
    {
      "epoch": 7.420481927710844,
      "grad_norm": 0.18951302766799927,
      "learning_rate": 1.257951807228916e-05,
      "loss": 0.0158,
      "step": 61590
    },
    {
      "epoch": 7.421686746987952,
      "grad_norm": 0.9505917429924011,
      "learning_rate": 1.2578313253012048e-05,
      "loss": 0.0215,
      "step": 61600
    },
    {
      "epoch": 7.4228915662650605,
      "grad_norm": 0.023081762716174126,
      "learning_rate": 1.257710843373494e-05,
      "loss": 0.0211,
      "step": 61610
    },
    {
      "epoch": 7.424096385542168,
      "grad_norm": 8.677464485168457,
      "learning_rate": 1.2575903614457831e-05,
      "loss": 0.0492,
      "step": 61620
    },
    {
      "epoch": 7.425301204819277,
      "grad_norm": 7.799039840698242,
      "learning_rate": 1.2574698795180724e-05,
      "loss": 0.0232,
      "step": 61630
    },
    {
      "epoch": 7.426506024096385,
      "grad_norm": 0.0308582354336977,
      "learning_rate": 1.2573493975903615e-05,
      "loss": 0.0297,
      "step": 61640
    },
    {
      "epoch": 7.427710843373494,
      "grad_norm": 0.2815662622451782,
      "learning_rate": 1.2572289156626507e-05,
      "loss": 0.0397,
      "step": 61650
    },
    {
      "epoch": 7.428915662650603,
      "grad_norm": 0.3087315559387207,
      "learning_rate": 1.25710843373494e-05,
      "loss": 0.0617,
      "step": 61660
    },
    {
      "epoch": 7.430120481927711,
      "grad_norm": 0.08495458215475082,
      "learning_rate": 1.256987951807229e-05,
      "loss": 0.047,
      "step": 61670
    },
    {
      "epoch": 7.4313253012048195,
      "grad_norm": 0.07457166165113449,
      "learning_rate": 1.2568674698795183e-05,
      "loss": 0.0325,
      "step": 61680
    },
    {
      "epoch": 7.432530120481927,
      "grad_norm": 0.06078965216875076,
      "learning_rate": 1.2567469879518073e-05,
      "loss": 0.019,
      "step": 61690
    },
    {
      "epoch": 7.433734939759036,
      "grad_norm": 0.5336316227912903,
      "learning_rate": 1.2566265060240966e-05,
      "loss": 0.032,
      "step": 61700
    },
    {
      "epoch": 7.434939759036144,
      "grad_norm": 0.06734738498926163,
      "learning_rate": 1.2565060240963855e-05,
      "loss": 0.0254,
      "step": 61710
    },
    {
      "epoch": 7.436144578313253,
      "grad_norm": 1.8231598138809204,
      "learning_rate": 1.2563855421686747e-05,
      "loss": 0.0145,
      "step": 61720
    },
    {
      "epoch": 7.437349397590362,
      "grad_norm": 0.009234648197889328,
      "learning_rate": 1.2562650602409641e-05,
      "loss": 0.057,
      "step": 61730
    },
    {
      "epoch": 7.43855421686747,
      "grad_norm": 1.47882080078125,
      "learning_rate": 1.256144578313253e-05,
      "loss": 0.0261,
      "step": 61740
    },
    {
      "epoch": 7.4397590361445785,
      "grad_norm": 1.2760335206985474,
      "learning_rate": 1.2560240963855423e-05,
      "loss": 0.0687,
      "step": 61750
    },
    {
      "epoch": 7.440963855421686,
      "grad_norm": 6.935988426208496,
      "learning_rate": 1.2559036144578314e-05,
      "loss": 0.0239,
      "step": 61760
    },
    {
      "epoch": 7.442168674698795,
      "grad_norm": 5.248815536499023,
      "learning_rate": 1.2557831325301206e-05,
      "loss": 0.0758,
      "step": 61770
    },
    {
      "epoch": 7.443373493975904,
      "grad_norm": 0.1361396461725235,
      "learning_rate": 1.2556626506024097e-05,
      "loss": 0.0133,
      "step": 61780
    },
    {
      "epoch": 7.444578313253012,
      "grad_norm": 0.28524166345596313,
      "learning_rate": 1.255542168674699e-05,
      "loss": 0.0274,
      "step": 61790
    },
    {
      "epoch": 7.445783132530121,
      "grad_norm": 0.024145890027284622,
      "learning_rate": 1.255421686746988e-05,
      "loss": 0.016,
      "step": 61800
    },
    {
      "epoch": 7.446987951807229,
      "grad_norm": 0.05741426348686218,
      "learning_rate": 1.2553012048192772e-05,
      "loss": 0.0515,
      "step": 61810
    },
    {
      "epoch": 7.448192771084337,
      "grad_norm": 0.04106709733605385,
      "learning_rate": 1.2551807228915665e-05,
      "loss": 0.0149,
      "step": 61820
    },
    {
      "epoch": 7.449397590361446,
      "grad_norm": 0.0853252187371254,
      "learning_rate": 1.2550602409638556e-05,
      "loss": 0.0265,
      "step": 61830
    },
    {
      "epoch": 7.450602409638554,
      "grad_norm": 0.8876725435256958,
      "learning_rate": 1.2549397590361448e-05,
      "loss": 0.0176,
      "step": 61840
    },
    {
      "epoch": 7.451807228915663,
      "grad_norm": 0.12477241456508636,
      "learning_rate": 1.2548192771084337e-05,
      "loss": 0.0232,
      "step": 61850
    },
    {
      "epoch": 7.453012048192771,
      "grad_norm": 0.012367693707346916,
      "learning_rate": 1.254698795180723e-05,
      "loss": 0.0955,
      "step": 61860
    },
    {
      "epoch": 7.45421686746988,
      "grad_norm": 0.8113926649093628,
      "learning_rate": 1.254578313253012e-05,
      "loss": 0.0127,
      "step": 61870
    },
    {
      "epoch": 7.455421686746988,
      "grad_norm": 0.9179154634475708,
      "learning_rate": 1.2544578313253013e-05,
      "loss": 0.0183,
      "step": 61880
    },
    {
      "epoch": 7.456626506024096,
      "grad_norm": 0.8474695086479187,
      "learning_rate": 1.2543373493975905e-05,
      "loss": 0.0427,
      "step": 61890
    },
    {
      "epoch": 7.457831325301205,
      "grad_norm": 0.013103671371936798,
      "learning_rate": 1.2542168674698796e-05,
      "loss": 0.0644,
      "step": 61900
    },
    {
      "epoch": 7.459036144578313,
      "grad_norm": 0.6831070780754089,
      "learning_rate": 1.2540963855421688e-05,
      "loss": 0.0089,
      "step": 61910
    },
    {
      "epoch": 7.460240963855422,
      "grad_norm": 1.0697455406188965,
      "learning_rate": 1.2539759036144579e-05,
      "loss": 0.0443,
      "step": 61920
    },
    {
      "epoch": 7.46144578313253,
      "grad_norm": 0.18088336288928986,
      "learning_rate": 1.2538554216867471e-05,
      "loss": 0.0437,
      "step": 61930
    },
    {
      "epoch": 7.462650602409639,
      "grad_norm": 0.43724316358566284,
      "learning_rate": 1.2537349397590362e-05,
      "loss": 0.0136,
      "step": 61940
    },
    {
      "epoch": 7.4638554216867465,
      "grad_norm": 0.007078014314174652,
      "learning_rate": 1.2536144578313255e-05,
      "loss": 0.0237,
      "step": 61950
    },
    {
      "epoch": 7.465060240963855,
      "grad_norm": 4.025842189788818,
      "learning_rate": 1.2534939759036147e-05,
      "loss": 0.0525,
      "step": 61960
    },
    {
      "epoch": 7.466265060240964,
      "grad_norm": 23.54584312438965,
      "learning_rate": 1.2533734939759036e-05,
      "loss": 0.1122,
      "step": 61970
    },
    {
      "epoch": 7.467469879518072,
      "grad_norm": 0.005604588892310858,
      "learning_rate": 1.2532530120481929e-05,
      "loss": 0.0058,
      "step": 61980
    },
    {
      "epoch": 7.468674698795181,
      "grad_norm": 1.0620200634002686,
      "learning_rate": 1.253132530120482e-05,
      "loss": 0.0413,
      "step": 61990
    },
    {
      "epoch": 7.469879518072289,
      "grad_norm": 0.963854968547821,
      "learning_rate": 1.2530120481927712e-05,
      "loss": 0.0144,
      "step": 62000
    },
    {
      "epoch": 7.471084337349398,
      "grad_norm": 0.007089960388839245,
      "learning_rate": 1.2528915662650602e-05,
      "loss": 0.0876,
      "step": 62010
    },
    {
      "epoch": 7.472289156626506,
      "grad_norm": 0.030751993879675865,
      "learning_rate": 1.2527710843373495e-05,
      "loss": 0.012,
      "step": 62020
    },
    {
      "epoch": 7.473493975903614,
      "grad_norm": 0.02736232988536358,
      "learning_rate": 1.2526506024096387e-05,
      "loss": 0.0606,
      "step": 62030
    },
    {
      "epoch": 7.474698795180723,
      "grad_norm": 0.016375277191400528,
      "learning_rate": 1.2525301204819278e-05,
      "loss": 0.0542,
      "step": 62040
    },
    {
      "epoch": 7.475903614457831,
      "grad_norm": 0.02728848345577717,
      "learning_rate": 1.252409638554217e-05,
      "loss": 0.0181,
      "step": 62050
    },
    {
      "epoch": 7.47710843373494,
      "grad_norm": 1.11234450340271,
      "learning_rate": 1.2522891566265061e-05,
      "loss": 0.0489,
      "step": 62060
    },
    {
      "epoch": 7.478313253012049,
      "grad_norm": 0.009237604215741158,
      "learning_rate": 1.2521686746987954e-05,
      "loss": 0.012,
      "step": 62070
    },
    {
      "epoch": 7.4795180722891565,
      "grad_norm": 1.1997567415237427,
      "learning_rate": 1.2520481927710843e-05,
      "loss": 0.0129,
      "step": 62080
    },
    {
      "epoch": 7.480722891566265,
      "grad_norm": 0.015568718314170837,
      "learning_rate": 1.2519277108433737e-05,
      "loss": 0.0103,
      "step": 62090
    },
    {
      "epoch": 7.481927710843373,
      "grad_norm": 0.026799988001585007,
      "learning_rate": 1.2518072289156626e-05,
      "loss": 0.0445,
      "step": 62100
    },
    {
      "epoch": 7.483132530120482,
      "grad_norm": 0.04394572973251343,
      "learning_rate": 1.2516867469879518e-05,
      "loss": 0.0297,
      "step": 62110
    },
    {
      "epoch": 7.48433734939759,
      "grad_norm": 7.084383964538574,
      "learning_rate": 1.251566265060241e-05,
      "loss": 0.0361,
      "step": 62120
    },
    {
      "epoch": 7.485542168674699,
      "grad_norm": 0.01852010190486908,
      "learning_rate": 1.2514457831325302e-05,
      "loss": 0.059,
      "step": 62130
    },
    {
      "epoch": 7.486746987951808,
      "grad_norm": 0.05580323562026024,
      "learning_rate": 1.2513253012048194e-05,
      "loss": 0.0522,
      "step": 62140
    },
    {
      "epoch": 7.4879518072289155,
      "grad_norm": 0.02641288936138153,
      "learning_rate": 1.2512048192771085e-05,
      "loss": 0.0071,
      "step": 62150
    },
    {
      "epoch": 7.489156626506024,
      "grad_norm": 0.12471993267536163,
      "learning_rate": 1.2510843373493977e-05,
      "loss": 0.007,
      "step": 62160
    },
    {
      "epoch": 7.490361445783132,
      "grad_norm": 2.2140324115753174,
      "learning_rate": 1.2509638554216868e-05,
      "loss": 0.0569,
      "step": 62170
    },
    {
      "epoch": 7.491566265060241,
      "grad_norm": 0.024235110729932785,
      "learning_rate": 1.250843373493976e-05,
      "loss": 0.0336,
      "step": 62180
    },
    {
      "epoch": 7.492771084337349,
      "grad_norm": 0.013229957781732082,
      "learning_rate": 1.2507228915662653e-05,
      "loss": 0.0238,
      "step": 62190
    },
    {
      "epoch": 7.493975903614458,
      "grad_norm": 0.006681348197162151,
      "learning_rate": 1.2506024096385544e-05,
      "loss": 0.051,
      "step": 62200
    },
    {
      "epoch": 7.495180722891567,
      "grad_norm": 0.9215381145477295,
      "learning_rate": 1.2504819277108436e-05,
      "loss": 0.01,
      "step": 62210
    },
    {
      "epoch": 7.4963855421686745,
      "grad_norm": 0.2316662222146988,
      "learning_rate": 1.2503614457831325e-05,
      "loss": 0.0629,
      "step": 62220
    },
    {
      "epoch": 7.497590361445783,
      "grad_norm": 2.7019717693328857,
      "learning_rate": 1.2502409638554217e-05,
      "loss": 0.0117,
      "step": 62230
    },
    {
      "epoch": 7.498795180722891,
      "grad_norm": 0.06694366037845612,
      "learning_rate": 1.2501204819277108e-05,
      "loss": 0.0421,
      "step": 62240
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.1373586505651474,
      "learning_rate": 1.25e-05,
      "loss": 0.0379,
      "step": 62250
    },
    {
      "epoch": 7.501204819277109,
      "grad_norm": 0.06120898574590683,
      "learning_rate": 1.2498795180722893e-05,
      "loss": 0.0709,
      "step": 62260
    },
    {
      "epoch": 7.502409638554217,
      "grad_norm": 0.010605509392917156,
      "learning_rate": 1.2497590361445784e-05,
      "loss": 0.0184,
      "step": 62270
    },
    {
      "epoch": 7.5036144578313255,
      "grad_norm": 10.857813835144043,
      "learning_rate": 1.2496385542168676e-05,
      "loss": 0.0576,
      "step": 62280
    },
    {
      "epoch": 7.504819277108433,
      "grad_norm": 0.16383425891399384,
      "learning_rate": 1.2495180722891567e-05,
      "loss": 0.0345,
      "step": 62290
    },
    {
      "epoch": 7.506024096385542,
      "grad_norm": 0.18651901185512543,
      "learning_rate": 1.249397590361446e-05,
      "loss": 0.0052,
      "step": 62300
    },
    {
      "epoch": 7.507228915662651,
      "grad_norm": 0.029158126562833786,
      "learning_rate": 1.249277108433735e-05,
      "loss": 0.0473,
      "step": 62310
    },
    {
      "epoch": 7.508433734939759,
      "grad_norm": 7.412993907928467,
      "learning_rate": 1.2491566265060243e-05,
      "loss": 0.0386,
      "step": 62320
    },
    {
      "epoch": 7.509638554216868,
      "grad_norm": 0.031131086871027946,
      "learning_rate": 1.2490361445783135e-05,
      "loss": 0.0142,
      "step": 62330
    },
    {
      "epoch": 7.510843373493976,
      "grad_norm": 0.019362470135092735,
      "learning_rate": 1.2489156626506026e-05,
      "loss": 0.0075,
      "step": 62340
    },
    {
      "epoch": 7.5120481927710845,
      "grad_norm": 0.023010993376374245,
      "learning_rate": 1.2487951807228918e-05,
      "loss": 0.0102,
      "step": 62350
    },
    {
      "epoch": 7.513253012048192,
      "grad_norm": 0.8847601413726807,
      "learning_rate": 1.2486746987951807e-05,
      "loss": 0.0375,
      "step": 62360
    },
    {
      "epoch": 7.514457831325301,
      "grad_norm": 5.254034996032715,
      "learning_rate": 1.24855421686747e-05,
      "loss": 0.0187,
      "step": 62370
    },
    {
      "epoch": 7.51566265060241,
      "grad_norm": 0.8381602168083191,
      "learning_rate": 1.248433734939759e-05,
      "loss": 0.0333,
      "step": 62380
    },
    {
      "epoch": 7.516867469879518,
      "grad_norm": 0.9694700837135315,
      "learning_rate": 1.2483132530120483e-05,
      "loss": 0.0302,
      "step": 62390
    },
    {
      "epoch": 7.518072289156627,
      "grad_norm": 0.13344812393188477,
      "learning_rate": 1.2481927710843375e-05,
      "loss": 0.0064,
      "step": 62400
    },
    {
      "epoch": 7.519277108433735,
      "grad_norm": 0.3615671694278717,
      "learning_rate": 1.2480722891566266e-05,
      "loss": 0.0456,
      "step": 62410
    },
    {
      "epoch": 7.5204819277108435,
      "grad_norm": 0.025510229170322418,
      "learning_rate": 1.2479518072289158e-05,
      "loss": 0.0244,
      "step": 62420
    },
    {
      "epoch": 7.521686746987951,
      "grad_norm": 0.016530629247426987,
      "learning_rate": 1.247831325301205e-05,
      "loss": 0.0118,
      "step": 62430
    },
    {
      "epoch": 7.52289156626506,
      "grad_norm": 0.01990690641105175,
      "learning_rate": 1.2477108433734942e-05,
      "loss": 0.0337,
      "step": 62440
    },
    {
      "epoch": 7.524096385542169,
      "grad_norm": 0.010580507107079029,
      "learning_rate": 1.2475903614457832e-05,
      "loss": 0.0435,
      "step": 62450
    },
    {
      "epoch": 7.525301204819277,
      "grad_norm": 1.0291908979415894,
      "learning_rate": 1.2474698795180725e-05,
      "loss": 0.0126,
      "step": 62460
    },
    {
      "epoch": 7.526506024096386,
      "grad_norm": 0.03443389758467674,
      "learning_rate": 1.2473493975903614e-05,
      "loss": 0.052,
      "step": 62470
    },
    {
      "epoch": 7.527710843373494,
      "grad_norm": 0.07491210103034973,
      "learning_rate": 1.2472289156626506e-05,
      "loss": 0.0353,
      "step": 62480
    },
    {
      "epoch": 7.528915662650602,
      "grad_norm": 0.33158180117607117,
      "learning_rate": 1.2471084337349399e-05,
      "loss": 0.0955,
      "step": 62490
    },
    {
      "epoch": 7.530120481927711,
      "grad_norm": 0.09622999280691147,
      "learning_rate": 1.246987951807229e-05,
      "loss": 0.0507,
      "step": 62500
    },
    {
      "epoch": 7.531325301204819,
      "grad_norm": 0.2123289257287979,
      "learning_rate": 1.2468674698795182e-05,
      "loss": 0.0603,
      "step": 62510
    },
    {
      "epoch": 7.532530120481928,
      "grad_norm": 0.3373517394065857,
      "learning_rate": 1.2467469879518073e-05,
      "loss": 0.0052,
      "step": 62520
    },
    {
      "epoch": 7.533734939759036,
      "grad_norm": 0.15958896279335022,
      "learning_rate": 1.2466265060240965e-05,
      "loss": 0.0164,
      "step": 62530
    },
    {
      "epoch": 7.534939759036145,
      "grad_norm": 2.084524631500244,
      "learning_rate": 1.2465060240963856e-05,
      "loss": 0.0323,
      "step": 62540
    },
    {
      "epoch": 7.5361445783132535,
      "grad_norm": 0.16337384283542633,
      "learning_rate": 1.2463855421686748e-05,
      "loss": 0.0093,
      "step": 62550
    },
    {
      "epoch": 7.537349397590361,
      "grad_norm": 7.598755836486816,
      "learning_rate": 1.246265060240964e-05,
      "loss": 0.0234,
      "step": 62560
    },
    {
      "epoch": 7.53855421686747,
      "grad_norm": 0.007142623420804739,
      "learning_rate": 1.2461445783132531e-05,
      "loss": 0.0265,
      "step": 62570
    },
    {
      "epoch": 7.539759036144578,
      "grad_norm": 0.13655243813991547,
      "learning_rate": 1.2460240963855424e-05,
      "loss": 0.0371,
      "step": 62580
    },
    {
      "epoch": 7.540963855421687,
      "grad_norm": 110.77276611328125,
      "learning_rate": 1.2459036144578313e-05,
      "loss": 0.0388,
      "step": 62590
    },
    {
      "epoch": 7.542168674698795,
      "grad_norm": 0.8225536942481995,
      "learning_rate": 1.2457831325301207e-05,
      "loss": 0.0653,
      "step": 62600
    },
    {
      "epoch": 7.543373493975904,
      "grad_norm": 0.08064812421798706,
      "learning_rate": 1.2456626506024096e-05,
      "loss": 0.023,
      "step": 62610
    },
    {
      "epoch": 7.544578313253012,
      "grad_norm": 0.06952884048223495,
      "learning_rate": 1.2455421686746989e-05,
      "loss": 0.0311,
      "step": 62620
    },
    {
      "epoch": 7.54578313253012,
      "grad_norm": 0.08981820195913315,
      "learning_rate": 1.2454216867469881e-05,
      "loss": 0.0498,
      "step": 62630
    },
    {
      "epoch": 7.546987951807229,
      "grad_norm": 0.050760965794324875,
      "learning_rate": 1.2453012048192772e-05,
      "loss": 0.0125,
      "step": 62640
    },
    {
      "epoch": 7.548192771084337,
      "grad_norm": 3.914987087249756,
      "learning_rate": 1.2451807228915664e-05,
      "loss": 0.0253,
      "step": 62650
    },
    {
      "epoch": 7.549397590361446,
      "grad_norm": 0.016084011644124985,
      "learning_rate": 1.2450602409638555e-05,
      "loss": 0.0189,
      "step": 62660
    },
    {
      "epoch": 7.550602409638554,
      "grad_norm": 1.664324402809143,
      "learning_rate": 1.2449397590361447e-05,
      "loss": 0.0093,
      "step": 62670
    },
    {
      "epoch": 7.551807228915663,
      "grad_norm": 1.111124038696289,
      "learning_rate": 1.2448192771084338e-05,
      "loss": 0.0315,
      "step": 62680
    },
    {
      "epoch": 7.553012048192771,
      "grad_norm": 0.026483044028282166,
      "learning_rate": 1.244698795180723e-05,
      "loss": 0.0324,
      "step": 62690
    },
    {
      "epoch": 7.554216867469879,
      "grad_norm": 1.3221391439437866,
      "learning_rate": 1.2445783132530123e-05,
      "loss": 0.007,
      "step": 62700
    },
    {
      "epoch": 7.555421686746988,
      "grad_norm": 1.621659517288208,
      "learning_rate": 1.2444578313253014e-05,
      "loss": 0.0709,
      "step": 62710
    },
    {
      "epoch": 7.556626506024096,
      "grad_norm": 0.015245922841131687,
      "learning_rate": 1.2443373493975906e-05,
      "loss": 0.0272,
      "step": 62720
    },
    {
      "epoch": 7.557831325301205,
      "grad_norm": 13.00269889831543,
      "learning_rate": 1.2442168674698795e-05,
      "loss": 0.0784,
      "step": 62730
    },
    {
      "epoch": 7.559036144578314,
      "grad_norm": 11.682355880737305,
      "learning_rate": 1.2440963855421688e-05,
      "loss": 0.0525,
      "step": 62740
    },
    {
      "epoch": 7.5602409638554215,
      "grad_norm": 2.5706961154937744,
      "learning_rate": 1.2439759036144578e-05,
      "loss": 0.0503,
      "step": 62750
    },
    {
      "epoch": 7.56144578313253,
      "grad_norm": 0.42356714606285095,
      "learning_rate": 1.243855421686747e-05,
      "loss": 0.0428,
      "step": 62760
    },
    {
      "epoch": 7.562650602409638,
      "grad_norm": 0.1611304134130478,
      "learning_rate": 1.2437349397590361e-05,
      "loss": 0.0118,
      "step": 62770
    },
    {
      "epoch": 7.563855421686747,
      "grad_norm": 0.0990261435508728,
      "learning_rate": 1.2436144578313254e-05,
      "loss": 0.0121,
      "step": 62780
    },
    {
      "epoch": 7.565060240963856,
      "grad_norm": 0.08364561200141907,
      "learning_rate": 1.2434939759036146e-05,
      "loss": 0.0252,
      "step": 62790
    },
    {
      "epoch": 7.566265060240964,
      "grad_norm": 0.09630925208330154,
      "learning_rate": 1.2433734939759037e-05,
      "loss": 0.052,
      "step": 62800
    },
    {
      "epoch": 7.567469879518073,
      "grad_norm": 0.03606536239385605,
      "learning_rate": 1.243253012048193e-05,
      "loss": 0.0172,
      "step": 62810
    },
    {
      "epoch": 7.5686746987951805,
      "grad_norm": 0.023408545181155205,
      "learning_rate": 1.243132530120482e-05,
      "loss": 0.0009,
      "step": 62820
    },
    {
      "epoch": 7.569879518072289,
      "grad_norm": 0.014243348501622677,
      "learning_rate": 1.2430120481927713e-05,
      "loss": 0.0189,
      "step": 62830
    },
    {
      "epoch": 7.571084337349397,
      "grad_norm": 1.6877214908599854,
      "learning_rate": 1.2428915662650602e-05,
      "loss": 0.0248,
      "step": 62840
    },
    {
      "epoch": 7.572289156626506,
      "grad_norm": 0.011026876047253609,
      "learning_rate": 1.2427710843373494e-05,
      "loss": 0.0195,
      "step": 62850
    },
    {
      "epoch": 7.573493975903615,
      "grad_norm": 0.016778497025370598,
      "learning_rate": 1.2426506024096388e-05,
      "loss": 0.006,
      "step": 62860
    },
    {
      "epoch": 7.574698795180723,
      "grad_norm": 7.1292195320129395,
      "learning_rate": 1.2425301204819277e-05,
      "loss": 0.0535,
      "step": 62870
    },
    {
      "epoch": 7.575903614457832,
      "grad_norm": 0.0052969143725931644,
      "learning_rate": 1.242409638554217e-05,
      "loss": 0.0448,
      "step": 62880
    },
    {
      "epoch": 7.5771084337349395,
      "grad_norm": 0.05920187011361122,
      "learning_rate": 1.242289156626506e-05,
      "loss": 0.0592,
      "step": 62890
    },
    {
      "epoch": 7.578313253012048,
      "grad_norm": 0.045928847044706345,
      "learning_rate": 1.2421686746987953e-05,
      "loss": 0.0319,
      "step": 62900
    },
    {
      "epoch": 7.579518072289156,
      "grad_norm": 0.046139415353536606,
      "learning_rate": 1.2420481927710844e-05,
      "loss": 0.0265,
      "step": 62910
    },
    {
      "epoch": 7.580722891566265,
      "grad_norm": 1.192837119102478,
      "learning_rate": 1.2419277108433736e-05,
      "loss": 0.0669,
      "step": 62920
    },
    {
      "epoch": 7.581927710843374,
      "grad_norm": 0.042600736021995544,
      "learning_rate": 1.2418072289156629e-05,
      "loss": 0.0379,
      "step": 62930
    },
    {
      "epoch": 7.583132530120482,
      "grad_norm": 0.009617378935217857,
      "learning_rate": 1.241686746987952e-05,
      "loss": 0.0329,
      "step": 62940
    },
    {
      "epoch": 7.5843373493975905,
      "grad_norm": 0.7111466526985168,
      "learning_rate": 1.2415662650602412e-05,
      "loss": 0.0252,
      "step": 62950
    },
    {
      "epoch": 7.585542168674698,
      "grad_norm": 1.8344905376434326,
      "learning_rate": 1.2414457831325303e-05,
      "loss": 0.0535,
      "step": 62960
    },
    {
      "epoch": 7.586746987951807,
      "grad_norm": 0.33544686436653137,
      "learning_rate": 1.2413253012048195e-05,
      "loss": 0.0495,
      "step": 62970
    },
    {
      "epoch": 7.587951807228916,
      "grad_norm": 0.03536011278629303,
      "learning_rate": 1.2412048192771084e-05,
      "loss": 0.0235,
      "step": 62980
    },
    {
      "epoch": 7.589156626506024,
      "grad_norm": 2.8938984870910645,
      "learning_rate": 1.2410843373493976e-05,
      "loss": 0.072,
      "step": 62990
    },
    {
      "epoch": 7.590361445783133,
      "grad_norm": 0.020266519859433174,
      "learning_rate": 1.2409638554216869e-05,
      "loss": 0.0085,
      "step": 63000
    },
    {
      "epoch": 7.591566265060241,
      "grad_norm": 1.1784698963165283,
      "learning_rate": 1.240843373493976e-05,
      "loss": 0.0562,
      "step": 63010
    },
    {
      "epoch": 7.5927710843373495,
      "grad_norm": 4.857503890991211,
      "learning_rate": 1.2407228915662652e-05,
      "loss": 0.0338,
      "step": 63020
    },
    {
      "epoch": 7.593975903614458,
      "grad_norm": 0.0673937201499939,
      "learning_rate": 1.2406024096385543e-05,
      "loss": 0.0229,
      "step": 63030
    },
    {
      "epoch": 7.595180722891566,
      "grad_norm": 0.40286698937416077,
      "learning_rate": 1.2404819277108435e-05,
      "loss": 0.0545,
      "step": 63040
    },
    {
      "epoch": 7.596385542168675,
      "grad_norm": 0.012559196911752224,
      "learning_rate": 1.2403614457831326e-05,
      "loss": 0.0307,
      "step": 63050
    },
    {
      "epoch": 7.597590361445783,
      "grad_norm": 1.6425141096115112,
      "learning_rate": 1.2402409638554218e-05,
      "loss": 0.0097,
      "step": 63060
    },
    {
      "epoch": 7.598795180722892,
      "grad_norm": 3.9312002658843994,
      "learning_rate": 1.2401204819277109e-05,
      "loss": 0.0257,
      "step": 63070
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.017224140465259552,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.0355,
      "step": 63080
    },
    {
      "epoch": 7.6012048192771084,
      "grad_norm": 1.0089712142944336,
      "learning_rate": 1.2398795180722894e-05,
      "loss": 0.0273,
      "step": 63090
    },
    {
      "epoch": 7.602409638554217,
      "grad_norm": 1.053682565689087,
      "learning_rate": 1.2397590361445783e-05,
      "loss": 0.0473,
      "step": 63100
    },
    {
      "epoch": 7.603614457831325,
      "grad_norm": 0.004847118631005287,
      "learning_rate": 1.2396385542168675e-05,
      "loss": 0.0251,
      "step": 63110
    },
    {
      "epoch": 7.604819277108434,
      "grad_norm": 0.8614433407783508,
      "learning_rate": 1.2395180722891566e-05,
      "loss": 0.0443,
      "step": 63120
    },
    {
      "epoch": 7.606024096385542,
      "grad_norm": 0.020663127303123474,
      "learning_rate": 1.2393975903614459e-05,
      "loss": 0.0417,
      "step": 63130
    },
    {
      "epoch": 7.607228915662651,
      "grad_norm": 0.003068507183343172,
      "learning_rate": 1.239277108433735e-05,
      "loss": 0.0089,
      "step": 63140
    },
    {
      "epoch": 7.608433734939759,
      "grad_norm": 2.2136926651000977,
      "learning_rate": 1.2391566265060242e-05,
      "loss": 0.0678,
      "step": 63150
    },
    {
      "epoch": 7.609638554216867,
      "grad_norm": 4.938931941986084,
      "learning_rate": 1.2390361445783134e-05,
      "loss": 0.0285,
      "step": 63160
    },
    {
      "epoch": 7.610843373493976,
      "grad_norm": 5.695446968078613,
      "learning_rate": 1.2389156626506025e-05,
      "loss": 0.0579,
      "step": 63170
    },
    {
      "epoch": 7.612048192771084,
      "grad_norm": 0.22386518120765686,
      "learning_rate": 1.2387951807228917e-05,
      "loss": 0.0214,
      "step": 63180
    },
    {
      "epoch": 7.613253012048193,
      "grad_norm": 0.9975510835647583,
      "learning_rate": 1.2386746987951808e-05,
      "loss": 0.0809,
      "step": 63190
    },
    {
      "epoch": 7.614457831325301,
      "grad_norm": 1.2796097993850708,
      "learning_rate": 1.23855421686747e-05,
      "loss": 0.0294,
      "step": 63200
    },
    {
      "epoch": 7.61566265060241,
      "grad_norm": 0.019053753465414047,
      "learning_rate": 1.238433734939759e-05,
      "loss": 0.0127,
      "step": 63210
    },
    {
      "epoch": 7.6168674698795185,
      "grad_norm": 1.0454202890396118,
      "learning_rate": 1.2383132530120484e-05,
      "loss": 0.0349,
      "step": 63220
    },
    {
      "epoch": 7.618072289156626,
      "grad_norm": 0.1486627161502838,
      "learning_rate": 1.2381927710843376e-05,
      "loss": 0.0156,
      "step": 63230
    },
    {
      "epoch": 7.619277108433735,
      "grad_norm": 0.024026945233345032,
      "learning_rate": 1.2380722891566265e-05,
      "loss": 0.029,
      "step": 63240
    },
    {
      "epoch": 7.620481927710843,
      "grad_norm": 0.0044001624919474125,
      "learning_rate": 1.2379518072289158e-05,
      "loss": 0.0086,
      "step": 63250
    },
    {
      "epoch": 7.621686746987952,
      "grad_norm": 0.005321030039340258,
      "learning_rate": 1.2378313253012048e-05,
      "loss": 0.0105,
      "step": 63260
    },
    {
      "epoch": 7.622891566265061,
      "grad_norm": 0.06469383090734482,
      "learning_rate": 1.2377108433734941e-05,
      "loss": 0.0322,
      "step": 63270
    },
    {
      "epoch": 7.624096385542169,
      "grad_norm": 0.3609447777271271,
      "learning_rate": 1.2375903614457832e-05,
      "loss": 0.0678,
      "step": 63280
    },
    {
      "epoch": 7.625301204819277,
      "grad_norm": 0.00567640271037817,
      "learning_rate": 1.2374698795180724e-05,
      "loss": 0.0104,
      "step": 63290
    },
    {
      "epoch": 7.626506024096385,
      "grad_norm": 0.006502109579741955,
      "learning_rate": 1.2373493975903616e-05,
      "loss": 0.0164,
      "step": 63300
    },
    {
      "epoch": 7.627710843373494,
      "grad_norm": 0.41087228059768677,
      "learning_rate": 1.2372289156626507e-05,
      "loss": 0.0147,
      "step": 63310
    },
    {
      "epoch": 7.628915662650602,
      "grad_norm": 0.006290770135819912,
      "learning_rate": 1.23710843373494e-05,
      "loss": 0.0428,
      "step": 63320
    },
    {
      "epoch": 7.630120481927711,
      "grad_norm": 1.5829740762710571,
      "learning_rate": 1.236987951807229e-05,
      "loss": 0.0118,
      "step": 63330
    },
    {
      "epoch": 7.63132530120482,
      "grad_norm": 11.289366722106934,
      "learning_rate": 1.2368674698795183e-05,
      "loss": 0.0279,
      "step": 63340
    },
    {
      "epoch": 7.632530120481928,
      "grad_norm": 0.008760535158216953,
      "learning_rate": 1.2367469879518072e-05,
      "loss": 0.0024,
      "step": 63350
    },
    {
      "epoch": 7.633734939759036,
      "grad_norm": 6.973159313201904,
      "learning_rate": 1.2366265060240964e-05,
      "loss": 0.0459,
      "step": 63360
    },
    {
      "epoch": 7.634939759036144,
      "grad_norm": 3.6989030838012695,
      "learning_rate": 1.2365060240963855e-05,
      "loss": 0.0505,
      "step": 63370
    },
    {
      "epoch": 7.636144578313253,
      "grad_norm": 1.5311628580093384,
      "learning_rate": 1.2363855421686748e-05,
      "loss": 0.0429,
      "step": 63380
    },
    {
      "epoch": 7.637349397590361,
      "grad_norm": 4.890451431274414,
      "learning_rate": 1.236265060240964e-05,
      "loss": 0.0318,
      "step": 63390
    },
    {
      "epoch": 7.63855421686747,
      "grad_norm": 0.00838726107031107,
      "learning_rate": 1.236144578313253e-05,
      "loss": 0.0271,
      "step": 63400
    },
    {
      "epoch": 7.639759036144579,
      "grad_norm": 0.4898471534252167,
      "learning_rate": 1.2360240963855423e-05,
      "loss": 0.0447,
      "step": 63410
    },
    {
      "epoch": 7.6409638554216865,
      "grad_norm": 0.20564359426498413,
      "learning_rate": 1.2359036144578314e-05,
      "loss": 0.0092,
      "step": 63420
    },
    {
      "epoch": 7.642168674698795,
      "grad_norm": 0.002717257710173726,
      "learning_rate": 1.2357831325301206e-05,
      "loss": 0.0328,
      "step": 63430
    },
    {
      "epoch": 7.643373493975903,
      "grad_norm": 2.304077625274658,
      "learning_rate": 1.2356626506024097e-05,
      "loss": 0.0226,
      "step": 63440
    },
    {
      "epoch": 7.644578313253012,
      "grad_norm": 0.002327428897842765,
      "learning_rate": 1.235542168674699e-05,
      "loss": 0.0339,
      "step": 63450
    },
    {
      "epoch": 7.64578313253012,
      "grad_norm": 0.31900015473365784,
      "learning_rate": 1.2354216867469882e-05,
      "loss": 0.0444,
      "step": 63460
    },
    {
      "epoch": 7.646987951807229,
      "grad_norm": 0.006356342695653439,
      "learning_rate": 1.2353012048192771e-05,
      "loss": 0.0128,
      "step": 63470
    },
    {
      "epoch": 7.648192771084338,
      "grad_norm": 0.012959199026226997,
      "learning_rate": 1.2351807228915665e-05,
      "loss": 0.0302,
      "step": 63480
    },
    {
      "epoch": 7.6493975903614455,
      "grad_norm": 0.006588812451809645,
      "learning_rate": 1.2350602409638554e-05,
      "loss": 0.0783,
      "step": 63490
    },
    {
      "epoch": 7.650602409638554,
      "grad_norm": 0.007076198235154152,
      "learning_rate": 1.2349397590361447e-05,
      "loss": 0.0406,
      "step": 63500
    },
    {
      "epoch": 7.651807228915663,
      "grad_norm": 0.13794274628162384,
      "learning_rate": 1.2348192771084337e-05,
      "loss": 0.0939,
      "step": 63510
    },
    {
      "epoch": 7.653012048192771,
      "grad_norm": 1.2486826181411743,
      "learning_rate": 1.234698795180723e-05,
      "loss": 0.0416,
      "step": 63520
    },
    {
      "epoch": 7.65421686746988,
      "grad_norm": 0.09708156436681747,
      "learning_rate": 1.2345783132530122e-05,
      "loss": 0.0243,
      "step": 63530
    },
    {
      "epoch": 7.655421686746988,
      "grad_norm": 0.4597897529602051,
      "learning_rate": 1.2344578313253013e-05,
      "loss": 0.0397,
      "step": 63540
    },
    {
      "epoch": 7.656626506024097,
      "grad_norm": 4.332276821136475,
      "learning_rate": 1.2343373493975905e-05,
      "loss": 0.0208,
      "step": 63550
    },
    {
      "epoch": 7.6578313253012045,
      "grad_norm": 1.2231231927871704,
      "learning_rate": 1.2342168674698796e-05,
      "loss": 0.0447,
      "step": 63560
    },
    {
      "epoch": 7.659036144578313,
      "grad_norm": 0.019965488463640213,
      "learning_rate": 1.2340963855421689e-05,
      "loss": 0.0316,
      "step": 63570
    },
    {
      "epoch": 7.660240963855422,
      "grad_norm": 15.557948112487793,
      "learning_rate": 1.233975903614458e-05,
      "loss": 0.0521,
      "step": 63580
    },
    {
      "epoch": 7.66144578313253,
      "grad_norm": 0.013600176200270653,
      "learning_rate": 1.2338554216867472e-05,
      "loss": 0.0472,
      "step": 63590
    },
    {
      "epoch": 7.662650602409639,
      "grad_norm": 0.05141141265630722,
      "learning_rate": 1.2337349397590364e-05,
      "loss": 0.0297,
      "step": 63600
    },
    {
      "epoch": 7.663855421686747,
      "grad_norm": 0.12272569537162781,
      "learning_rate": 1.2336144578313253e-05,
      "loss": 0.0664,
      "step": 63610
    },
    {
      "epoch": 7.6650602409638555,
      "grad_norm": 0.07475772500038147,
      "learning_rate": 1.2334939759036146e-05,
      "loss": 0.0079,
      "step": 63620
    },
    {
      "epoch": 7.666265060240963,
      "grad_norm": 0.2699948251247406,
      "learning_rate": 1.2333734939759036e-05,
      "loss": 0.1167,
      "step": 63630
    },
    {
      "epoch": 7.667469879518072,
      "grad_norm": 1.1413785219192505,
      "learning_rate": 1.2332530120481929e-05,
      "loss": 0.0252,
      "step": 63640
    },
    {
      "epoch": 7.668674698795181,
      "grad_norm": 0.11735252290964127,
      "learning_rate": 1.233132530120482e-05,
      "loss": 0.0734,
      "step": 63650
    },
    {
      "epoch": 7.669879518072289,
      "grad_norm": 1.3424073457717896,
      "learning_rate": 1.2330120481927712e-05,
      "loss": 0.0112,
      "step": 63660
    },
    {
      "epoch": 7.671084337349398,
      "grad_norm": 0.08126872032880783,
      "learning_rate": 1.2328915662650603e-05,
      "loss": 0.054,
      "step": 63670
    },
    {
      "epoch": 7.672289156626506,
      "grad_norm": 2.757066249847412,
      "learning_rate": 1.2327710843373495e-05,
      "loss": 0.0405,
      "step": 63680
    },
    {
      "epoch": 7.6734939759036145,
      "grad_norm": 0.5180022716522217,
      "learning_rate": 1.2326506024096388e-05,
      "loss": 0.004,
      "step": 63690
    },
    {
      "epoch": 7.674698795180722,
      "grad_norm": 0.10972317308187485,
      "learning_rate": 1.2325301204819278e-05,
      "loss": 0.0467,
      "step": 63700
    },
    {
      "epoch": 7.675903614457831,
      "grad_norm": 1.0735313892364502,
      "learning_rate": 1.232409638554217e-05,
      "loss": 0.0121,
      "step": 63710
    },
    {
      "epoch": 7.67710843373494,
      "grad_norm": 0.015524324029684067,
      "learning_rate": 1.232289156626506e-05,
      "loss": 0.0562,
      "step": 63720
    },
    {
      "epoch": 7.678313253012048,
      "grad_norm": 0.038188640028238297,
      "learning_rate": 1.2321686746987954e-05,
      "loss": 0.0104,
      "step": 63730
    },
    {
      "epoch": 7.679518072289157,
      "grad_norm": 0.08145228028297424,
      "learning_rate": 1.2320481927710843e-05,
      "loss": 0.0019,
      "step": 63740
    },
    {
      "epoch": 7.6807228915662655,
      "grad_norm": 0.002346830675378442,
      "learning_rate": 1.2319277108433735e-05,
      "loss": 0.0048,
      "step": 63750
    },
    {
      "epoch": 7.6819277108433734,
      "grad_norm": 6.769583225250244,
      "learning_rate": 1.2318072289156628e-05,
      "loss": 0.0283,
      "step": 63760
    },
    {
      "epoch": 7.683132530120482,
      "grad_norm": 0.043301213532686234,
      "learning_rate": 1.2316867469879519e-05,
      "loss": 0.0291,
      "step": 63770
    },
    {
      "epoch": 7.68433734939759,
      "grad_norm": 0.021155690774321556,
      "learning_rate": 1.2315662650602411e-05,
      "loss": 0.018,
      "step": 63780
    },
    {
      "epoch": 7.685542168674699,
      "grad_norm": 0.018804065883159637,
      "learning_rate": 1.2314457831325302e-05,
      "loss": 0.0373,
      "step": 63790
    },
    {
      "epoch": 7.686746987951807,
      "grad_norm": 0.0815458595752716,
      "learning_rate": 1.2313253012048194e-05,
      "loss": 0.0328,
      "step": 63800
    },
    {
      "epoch": 7.687951807228916,
      "grad_norm": 0.6282902359962463,
      "learning_rate": 1.2312048192771085e-05,
      "loss": 0.0123,
      "step": 63810
    },
    {
      "epoch": 7.6891566265060245,
      "grad_norm": 0.7802112698554993,
      "learning_rate": 1.2310843373493977e-05,
      "loss": 0.021,
      "step": 63820
    },
    {
      "epoch": 7.690361445783132,
      "grad_norm": 0.521603524684906,
      "learning_rate": 1.230963855421687e-05,
      "loss": 0.0177,
      "step": 63830
    },
    {
      "epoch": 7.691566265060241,
      "grad_norm": 6.508819580078125,
      "learning_rate": 1.230843373493976e-05,
      "loss": 0.0906,
      "step": 63840
    },
    {
      "epoch": 7.692771084337349,
      "grad_norm": 0.9180169105529785,
      "learning_rate": 1.2307228915662653e-05,
      "loss": 0.0352,
      "step": 63850
    },
    {
      "epoch": 7.693975903614458,
      "grad_norm": 0.9528678059577942,
      "learning_rate": 1.2306024096385542e-05,
      "loss": 0.0208,
      "step": 63860
    },
    {
      "epoch": 7.695180722891566,
      "grad_norm": 0.04023167863488197,
      "learning_rate": 1.2304819277108434e-05,
      "loss": 0.027,
      "step": 63870
    },
    {
      "epoch": 7.696385542168675,
      "grad_norm": 0.0837821513414383,
      "learning_rate": 1.2303614457831325e-05,
      "loss": 0.0143,
      "step": 63880
    },
    {
      "epoch": 7.6975903614457835,
      "grad_norm": 0.09499208629131317,
      "learning_rate": 1.2302409638554218e-05,
      "loss": 0.0092,
      "step": 63890
    },
    {
      "epoch": 7.698795180722891,
      "grad_norm": 0.9165909290313721,
      "learning_rate": 1.230120481927711e-05,
      "loss": 0.0486,
      "step": 63900
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.002929055830463767,
      "learning_rate": 1.23e-05,
      "loss": 0.0652,
      "step": 63910
    },
    {
      "epoch": 7.701204819277108,
      "grad_norm": 0.675586462020874,
      "learning_rate": 1.2298795180722893e-05,
      "loss": 0.0041,
      "step": 63920
    },
    {
      "epoch": 7.702409638554217,
      "grad_norm": 0.056983575224876404,
      "learning_rate": 1.2297590361445784e-05,
      "loss": 0.0789,
      "step": 63930
    },
    {
      "epoch": 7.703614457831325,
      "grad_norm": 0.024009553715586662,
      "learning_rate": 1.2296385542168676e-05,
      "loss": 0.0135,
      "step": 63940
    },
    {
      "epoch": 7.704819277108434,
      "grad_norm": 0.007099292241036892,
      "learning_rate": 1.2295180722891567e-05,
      "loss": 0.0335,
      "step": 63950
    },
    {
      "epoch": 7.706024096385542,
      "grad_norm": 0.019430361688137054,
      "learning_rate": 1.229397590361446e-05,
      "loss": 0.0357,
      "step": 63960
    },
    {
      "epoch": 7.70722891566265,
      "grad_norm": 0.022377008572220802,
      "learning_rate": 1.2292771084337349e-05,
      "loss": 0.0153,
      "step": 63970
    },
    {
      "epoch": 7.708433734939759,
      "grad_norm": 0.23232220113277435,
      "learning_rate": 1.2291566265060241e-05,
      "loss": 0.0324,
      "step": 63980
    },
    {
      "epoch": 7.709638554216868,
      "grad_norm": 0.0019810341764241457,
      "learning_rate": 1.2290361445783135e-05,
      "loss": 0.0273,
      "step": 63990
    },
    {
      "epoch": 7.710843373493976,
      "grad_norm": 0.3729483187198639,
      "learning_rate": 1.2289156626506024e-05,
      "loss": 0.0232,
      "step": 64000
    },
    {
      "epoch": 7.712048192771085,
      "grad_norm": 0.003909362014383078,
      "learning_rate": 1.2287951807228917e-05,
      "loss": 0.0022,
      "step": 64010
    },
    {
      "epoch": 7.713253012048193,
      "grad_norm": 0.03452463820576668,
      "learning_rate": 1.2286746987951807e-05,
      "loss": 0.0556,
      "step": 64020
    },
    {
      "epoch": 7.714457831325301,
      "grad_norm": 0.01504529919475317,
      "learning_rate": 1.22855421686747e-05,
      "loss": 0.0122,
      "step": 64030
    },
    {
      "epoch": 7.715662650602409,
      "grad_norm": 0.035513486713171005,
      "learning_rate": 1.228433734939759e-05,
      "loss": 0.0278,
      "step": 64040
    },
    {
      "epoch": 7.716867469879518,
      "grad_norm": 2.865110158920288,
      "learning_rate": 1.2283132530120483e-05,
      "loss": 0.0474,
      "step": 64050
    },
    {
      "epoch": 7.718072289156627,
      "grad_norm": 12.788650512695312,
      "learning_rate": 1.2281927710843375e-05,
      "loss": 0.0393,
      "step": 64060
    },
    {
      "epoch": 7.719277108433735,
      "grad_norm": 0.028965188190340996,
      "learning_rate": 1.2280722891566266e-05,
      "loss": 0.0031,
      "step": 64070
    },
    {
      "epoch": 7.720481927710844,
      "grad_norm": 0.8053047060966492,
      "learning_rate": 1.2279518072289159e-05,
      "loss": 0.0629,
      "step": 64080
    },
    {
      "epoch": 7.7216867469879515,
      "grad_norm": 1.2521628141403198,
      "learning_rate": 1.227831325301205e-05,
      "loss": 0.0513,
      "step": 64090
    },
    {
      "epoch": 7.72289156626506,
      "grad_norm": 0.005960662849247456,
      "learning_rate": 1.2277108433734942e-05,
      "loss": 0.067,
      "step": 64100
    },
    {
      "epoch": 7.724096385542168,
      "grad_norm": 0.08792702108621597,
      "learning_rate": 1.2275903614457831e-05,
      "loss": 0.0182,
      "step": 64110
    },
    {
      "epoch": 7.725301204819277,
      "grad_norm": 0.22206175327301025,
      "learning_rate": 1.2274698795180723e-05,
      "loss": 0.0269,
      "step": 64120
    },
    {
      "epoch": 7.726506024096386,
      "grad_norm": 0.02864890731871128,
      "learning_rate": 1.2273493975903616e-05,
      "loss": 0.0147,
      "step": 64130
    },
    {
      "epoch": 7.727710843373494,
      "grad_norm": 0.4021884799003601,
      "learning_rate": 1.2272289156626506e-05,
      "loss": 0.0894,
      "step": 64140
    },
    {
      "epoch": 7.728915662650603,
      "grad_norm": 2.7572364807128906,
      "learning_rate": 1.2271084337349399e-05,
      "loss": 0.0362,
      "step": 64150
    },
    {
      "epoch": 7.7301204819277105,
      "grad_norm": 0.18856346607208252,
      "learning_rate": 1.226987951807229e-05,
      "loss": 0.0306,
      "step": 64160
    },
    {
      "epoch": 7.731325301204819,
      "grad_norm": 11.579678535461426,
      "learning_rate": 1.2268674698795182e-05,
      "loss": 0.0374,
      "step": 64170
    },
    {
      "epoch": 7.732530120481927,
      "grad_norm": 0.005437253043055534,
      "learning_rate": 1.2267469879518073e-05,
      "loss": 0.0192,
      "step": 64180
    },
    {
      "epoch": 7.733734939759036,
      "grad_norm": 0.013034173287451267,
      "learning_rate": 1.2266265060240965e-05,
      "loss": 0.0123,
      "step": 64190
    },
    {
      "epoch": 7.734939759036145,
      "grad_norm": 0.2647658884525299,
      "learning_rate": 1.2265060240963858e-05,
      "loss": 0.0406,
      "step": 64200
    },
    {
      "epoch": 7.736144578313253,
      "grad_norm": 11.127211570739746,
      "learning_rate": 1.2263855421686748e-05,
      "loss": 0.029,
      "step": 64210
    },
    {
      "epoch": 7.7373493975903616,
      "grad_norm": 0.004421363119035959,
      "learning_rate": 1.2262650602409641e-05,
      "loss": 0.0123,
      "step": 64220
    },
    {
      "epoch": 7.73855421686747,
      "grad_norm": 0.8930715322494507,
      "learning_rate": 1.226144578313253e-05,
      "loss": 0.0408,
      "step": 64230
    },
    {
      "epoch": 7.739759036144578,
      "grad_norm": 0.10033611953258514,
      "learning_rate": 1.2260240963855422e-05,
      "loss": 0.053,
      "step": 64240
    },
    {
      "epoch": 7.740963855421687,
      "grad_norm": 1.9138699769973755,
      "learning_rate": 1.2259036144578313e-05,
      "loss": 0.0405,
      "step": 64250
    },
    {
      "epoch": 7.742168674698795,
      "grad_norm": 0.028809625655412674,
      "learning_rate": 1.2257831325301206e-05,
      "loss": 0.0387,
      "step": 64260
    },
    {
      "epoch": 7.743373493975904,
      "grad_norm": 10.41880989074707,
      "learning_rate": 1.2256626506024096e-05,
      "loss": 0.039,
      "step": 64270
    },
    {
      "epoch": 7.744578313253012,
      "grad_norm": 0.8060286641120911,
      "learning_rate": 1.2255421686746989e-05,
      "loss": 0.022,
      "step": 64280
    },
    {
      "epoch": 7.7457831325301205,
      "grad_norm": 5.423434257507324,
      "learning_rate": 1.2254216867469881e-05,
      "loss": 0.0277,
      "step": 64290
    },
    {
      "epoch": 7.746987951807229,
      "grad_norm": 0.2041929066181183,
      "learning_rate": 1.2253012048192772e-05,
      "loss": 0.0135,
      "step": 64300
    },
    {
      "epoch": 7.748192771084337,
      "grad_norm": 0.0036654409486800432,
      "learning_rate": 1.2251807228915664e-05,
      "loss": 0.0434,
      "step": 64310
    },
    {
      "epoch": 7.749397590361446,
      "grad_norm": 0.0008839433430694044,
      "learning_rate": 1.2250602409638555e-05,
      "loss": 0.0168,
      "step": 64320
    },
    {
      "epoch": 7.750602409638554,
      "grad_norm": 0.002559409011155367,
      "learning_rate": 1.2249397590361448e-05,
      "loss": 0.0262,
      "step": 64330
    },
    {
      "epoch": 7.751807228915663,
      "grad_norm": 0.0007538814097642899,
      "learning_rate": 1.2248192771084337e-05,
      "loss": 0.0175,
      "step": 64340
    },
    {
      "epoch": 7.753012048192771,
      "grad_norm": 0.0017306746449321508,
      "learning_rate": 1.224698795180723e-05,
      "loss": 0.0154,
      "step": 64350
    },
    {
      "epoch": 7.7542168674698795,
      "grad_norm": 0.0011728012468665838,
      "learning_rate": 1.2245783132530123e-05,
      "loss": 0.0193,
      "step": 64360
    },
    {
      "epoch": 7.755421686746988,
      "grad_norm": 0.007528039161115885,
      "learning_rate": 1.2244578313253012e-05,
      "loss": 0.0498,
      "step": 64370
    },
    {
      "epoch": 7.756626506024096,
      "grad_norm": 0.008606217801570892,
      "learning_rate": 1.2243373493975905e-05,
      "loss": 0.02,
      "step": 64380
    },
    {
      "epoch": 7.757831325301205,
      "grad_norm": 0.009156887419521809,
      "learning_rate": 1.2242168674698795e-05,
      "loss": 0.0329,
      "step": 64390
    },
    {
      "epoch": 7.759036144578313,
      "grad_norm": 1.8222429752349854,
      "learning_rate": 1.2240963855421688e-05,
      "loss": 0.0638,
      "step": 64400
    },
    {
      "epoch": 7.760240963855422,
      "grad_norm": 1.2903205156326294,
      "learning_rate": 1.2239759036144579e-05,
      "loss": 0.0115,
      "step": 64410
    },
    {
      "epoch": 7.76144578313253,
      "grad_norm": 0.04061916470527649,
      "learning_rate": 1.2238554216867471e-05,
      "loss": 0.02,
      "step": 64420
    },
    {
      "epoch": 7.7626506024096384,
      "grad_norm": 1.0893529653549194,
      "learning_rate": 1.2237349397590363e-05,
      "loss": 0.0423,
      "step": 64430
    },
    {
      "epoch": 7.763855421686747,
      "grad_norm": 2.6724960803985596,
      "learning_rate": 1.2236144578313254e-05,
      "loss": 0.0574,
      "step": 64440
    },
    {
      "epoch": 7.765060240963855,
      "grad_norm": 0.060940422117710114,
      "learning_rate": 1.2234939759036147e-05,
      "loss": 0.0314,
      "step": 64450
    },
    {
      "epoch": 7.766265060240964,
      "grad_norm": 3.516989231109619,
      "learning_rate": 1.2233734939759037e-05,
      "loss": 0.048,
      "step": 64460
    },
    {
      "epoch": 7.767469879518073,
      "grad_norm": 0.08107935637235641,
      "learning_rate": 1.223253012048193e-05,
      "loss": 0.0368,
      "step": 64470
    },
    {
      "epoch": 7.768674698795181,
      "grad_norm": 0.10029835253953934,
      "learning_rate": 1.2231325301204819e-05,
      "loss": 0.0235,
      "step": 64480
    },
    {
      "epoch": 7.7698795180722895,
      "grad_norm": 2.0808048248291016,
      "learning_rate": 1.2230120481927711e-05,
      "loss": 0.1134,
      "step": 64490
    },
    {
      "epoch": 7.771084337349397,
      "grad_norm": 0.14982181787490845,
      "learning_rate": 1.2228915662650604e-05,
      "loss": 0.0263,
      "step": 64500
    },
    {
      "epoch": 7.772289156626506,
      "grad_norm": 3.825161933898926,
      "learning_rate": 1.2227710843373494e-05,
      "loss": 0.0372,
      "step": 64510
    },
    {
      "epoch": 7.773493975903614,
      "grad_norm": 0.010255079716444016,
      "learning_rate": 1.2226506024096387e-05,
      "loss": 0.0489,
      "step": 64520
    },
    {
      "epoch": 7.774698795180723,
      "grad_norm": 0.1245260089635849,
      "learning_rate": 1.2225301204819278e-05,
      "loss": 0.0146,
      "step": 64530
    },
    {
      "epoch": 7.775903614457832,
      "grad_norm": 0.0042418865486979485,
      "learning_rate": 1.222409638554217e-05,
      "loss": 0.0619,
      "step": 64540
    },
    {
      "epoch": 7.77710843373494,
      "grad_norm": 3.8943228721618652,
      "learning_rate": 1.222289156626506e-05,
      "loss": 0.0386,
      "step": 64550
    },
    {
      "epoch": 7.7783132530120485,
      "grad_norm": 0.057406410574913025,
      "learning_rate": 1.2221686746987953e-05,
      "loss": 0.0379,
      "step": 64560
    },
    {
      "epoch": 7.779518072289156,
      "grad_norm": 0.0730632096529007,
      "learning_rate": 1.2220481927710844e-05,
      "loss": 0.0091,
      "step": 64570
    },
    {
      "epoch": 7.780722891566265,
      "grad_norm": 4.240745544433594,
      "learning_rate": 1.2219277108433736e-05,
      "loss": 0.0221,
      "step": 64580
    },
    {
      "epoch": 7.781927710843373,
      "grad_norm": 4.383991241455078,
      "learning_rate": 1.2218072289156629e-05,
      "loss": 0.0479,
      "step": 64590
    },
    {
      "epoch": 7.783132530120482,
      "grad_norm": 0.1500537395477295,
      "learning_rate": 1.2216867469879518e-05,
      "loss": 0.0487,
      "step": 64600
    },
    {
      "epoch": 7.784337349397591,
      "grad_norm": 0.04862596467137337,
      "learning_rate": 1.2215662650602412e-05,
      "loss": 0.005,
      "step": 64610
    },
    {
      "epoch": 7.785542168674699,
      "grad_norm": 0.024411004036664963,
      "learning_rate": 1.2214457831325301e-05,
      "loss": 0.0069,
      "step": 64620
    },
    {
      "epoch": 7.786746987951807,
      "grad_norm": 0.01693800464272499,
      "learning_rate": 1.2213253012048193e-05,
      "loss": 0.0038,
      "step": 64630
    },
    {
      "epoch": 7.787951807228915,
      "grad_norm": 13.33732795715332,
      "learning_rate": 1.2212048192771084e-05,
      "loss": 0.0201,
      "step": 64640
    },
    {
      "epoch": 7.789156626506024,
      "grad_norm": 0.04867757484316826,
      "learning_rate": 1.2210843373493977e-05,
      "loss": 0.0163,
      "step": 64650
    },
    {
      "epoch": 7.790361445783132,
      "grad_norm": 8.206185340881348,
      "learning_rate": 1.2209638554216869e-05,
      "loss": 0.0478,
      "step": 64660
    },
    {
      "epoch": 7.791566265060241,
      "grad_norm": 19.162952423095703,
      "learning_rate": 1.220843373493976e-05,
      "loss": 0.0507,
      "step": 64670
    },
    {
      "epoch": 7.79277108433735,
      "grad_norm": 0.04048814997076988,
      "learning_rate": 1.2207228915662652e-05,
      "loss": 0.0786,
      "step": 64680
    },
    {
      "epoch": 7.793975903614458,
      "grad_norm": 0.024654295295476913,
      "learning_rate": 1.2206024096385543e-05,
      "loss": 0.0116,
      "step": 64690
    },
    {
      "epoch": 7.795180722891566,
      "grad_norm": 0.02056306041777134,
      "learning_rate": 1.2204819277108435e-05,
      "loss": 0.0064,
      "step": 64700
    },
    {
      "epoch": 7.796385542168675,
      "grad_norm": 13.50999927520752,
      "learning_rate": 1.2203614457831326e-05,
      "loss": 0.0708,
      "step": 64710
    },
    {
      "epoch": 7.797590361445783,
      "grad_norm": 1.7784239053726196,
      "learning_rate": 1.2202409638554219e-05,
      "loss": 0.0405,
      "step": 64720
    },
    {
      "epoch": 7.798795180722892,
      "grad_norm": 1.4770721197128296,
      "learning_rate": 1.2201204819277111e-05,
      "loss": 0.059,
      "step": 64730
    },
    {
      "epoch": 7.8,
      "grad_norm": 3.2733852863311768,
      "learning_rate": 1.22e-05,
      "loss": 0.0284,
      "step": 64740
    },
    {
      "epoch": 7.801204819277109,
      "grad_norm": 18.223665237426758,
      "learning_rate": 1.2198795180722893e-05,
      "loss": 0.0611,
      "step": 64750
    },
    {
      "epoch": 7.8024096385542165,
      "grad_norm": 2.0526046752929688,
      "learning_rate": 1.2197590361445783e-05,
      "loss": 0.015,
      "step": 64760
    },
    {
      "epoch": 7.803614457831325,
      "grad_norm": 0.29275232553482056,
      "learning_rate": 1.2196385542168676e-05,
      "loss": 0.1025,
      "step": 64770
    },
    {
      "epoch": 7.804819277108434,
      "grad_norm": 7.41022253036499,
      "learning_rate": 1.2195180722891566e-05,
      "loss": 0.0282,
      "step": 64780
    },
    {
      "epoch": 7.806024096385542,
      "grad_norm": 0.1512988805770874,
      "learning_rate": 1.2193975903614459e-05,
      "loss": 0.0459,
      "step": 64790
    },
    {
      "epoch": 7.807228915662651,
      "grad_norm": 1.9389100074768066,
      "learning_rate": 1.2192771084337351e-05,
      "loss": 0.0147,
      "step": 64800
    },
    {
      "epoch": 7.808433734939759,
      "grad_norm": 2.8546361923217773,
      "learning_rate": 1.2191566265060242e-05,
      "loss": 0.0196,
      "step": 64810
    },
    {
      "epoch": 7.809638554216868,
      "grad_norm": 0.015497650019824505,
      "learning_rate": 1.2190361445783134e-05,
      "loss": 0.0225,
      "step": 64820
    },
    {
      "epoch": 7.8108433734939755,
      "grad_norm": 0.7684488296508789,
      "learning_rate": 1.2189156626506025e-05,
      "loss": 0.0216,
      "step": 64830
    },
    {
      "epoch": 7.812048192771084,
      "grad_norm": 0.45039692521095276,
      "learning_rate": 1.2187951807228918e-05,
      "loss": 0.0278,
      "step": 64840
    },
    {
      "epoch": 7.813253012048193,
      "grad_norm": 0.026669079437851906,
      "learning_rate": 1.2186746987951807e-05,
      "loss": 0.0195,
      "step": 64850
    },
    {
      "epoch": 7.814457831325301,
      "grad_norm": 1.0325775146484375,
      "learning_rate": 1.2185542168674699e-05,
      "loss": 0.0087,
      "step": 64860
    },
    {
      "epoch": 7.81566265060241,
      "grad_norm": 1.0017430782318115,
      "learning_rate": 1.218433734939759e-05,
      "loss": 0.012,
      "step": 64870
    },
    {
      "epoch": 7.816867469879518,
      "grad_norm": 0.0150804677978158,
      "learning_rate": 1.2183132530120482e-05,
      "loss": 0.0289,
      "step": 64880
    },
    {
      "epoch": 7.8180722891566266,
      "grad_norm": 0.3362336754798889,
      "learning_rate": 1.2181927710843375e-05,
      "loss": 0.0276,
      "step": 64890
    },
    {
      "epoch": 7.8192771084337345,
      "grad_norm": 1.2476921081542969,
      "learning_rate": 1.2180722891566265e-05,
      "loss": 0.0171,
      "step": 64900
    },
    {
      "epoch": 7.820481927710843,
      "grad_norm": 1.882994532585144,
      "learning_rate": 1.2179518072289158e-05,
      "loss": 0.0407,
      "step": 64910
    },
    {
      "epoch": 7.821686746987952,
      "grad_norm": 0.0038875590544193983,
      "learning_rate": 1.2178313253012049e-05,
      "loss": 0.0545,
      "step": 64920
    },
    {
      "epoch": 7.82289156626506,
      "grad_norm": 0.040844086557626724,
      "learning_rate": 1.2177108433734941e-05,
      "loss": 0.0655,
      "step": 64930
    },
    {
      "epoch": 7.824096385542169,
      "grad_norm": 1.4328453540802002,
      "learning_rate": 1.2175903614457832e-05,
      "loss": 0.0819,
      "step": 64940
    },
    {
      "epoch": 7.825301204819278,
      "grad_norm": 1.08065664768219,
      "learning_rate": 1.2174698795180724e-05,
      "loss": 0.0249,
      "step": 64950
    },
    {
      "epoch": 7.8265060240963855,
      "grad_norm": 0.020497560501098633,
      "learning_rate": 1.2173493975903617e-05,
      "loss": 0.0363,
      "step": 64960
    },
    {
      "epoch": 7.827710843373494,
      "grad_norm": 1.3040574789047241,
      "learning_rate": 1.2172289156626507e-05,
      "loss": 0.022,
      "step": 64970
    },
    {
      "epoch": 7.828915662650602,
      "grad_norm": 0.008700322359800339,
      "learning_rate": 1.21710843373494e-05,
      "loss": 0.0121,
      "step": 64980
    },
    {
      "epoch": 7.830120481927711,
      "grad_norm": 0.02174992859363556,
      "learning_rate": 1.2169879518072289e-05,
      "loss": 0.015,
      "step": 64990
    },
    {
      "epoch": 7.831325301204819,
      "grad_norm": 0.8772424459457397,
      "learning_rate": 1.2168674698795181e-05,
      "loss": 0.0843,
      "step": 65000
    },
    {
      "epoch": 7.832530120481928,
      "grad_norm": 0.037097711116075516,
      "learning_rate": 1.2167469879518072e-05,
      "loss": 0.0067,
      "step": 65010
    },
    {
      "epoch": 7.833734939759037,
      "grad_norm": 0.8748690485954285,
      "learning_rate": 1.2166265060240965e-05,
      "loss": 0.0091,
      "step": 65020
    },
    {
      "epoch": 7.8349397590361445,
      "grad_norm": 0.6004455089569092,
      "learning_rate": 1.2165060240963857e-05,
      "loss": 0.0134,
      "step": 65030
    },
    {
      "epoch": 7.836144578313253,
      "grad_norm": 0.00491097429767251,
      "learning_rate": 1.2163855421686748e-05,
      "loss": 0.0125,
      "step": 65040
    },
    {
      "epoch": 7.837349397590361,
      "grad_norm": 2.8492119312286377,
      "learning_rate": 1.216265060240964e-05,
      "loss": 0.0851,
      "step": 65050
    },
    {
      "epoch": 7.83855421686747,
      "grad_norm": 0.009189336560666561,
      "learning_rate": 1.2161445783132531e-05,
      "loss": 0.0261,
      "step": 65060
    },
    {
      "epoch": 7.839759036144578,
      "grad_norm": 1.8379312753677368,
      "learning_rate": 1.2160240963855423e-05,
      "loss": 0.0206,
      "step": 65070
    },
    {
      "epoch": 7.840963855421687,
      "grad_norm": 0.015978770330548286,
      "learning_rate": 1.2159036144578314e-05,
      "loss": 0.1099,
      "step": 65080
    },
    {
      "epoch": 7.8421686746987955,
      "grad_norm": 0.05281088128685951,
      "learning_rate": 1.2157831325301207e-05,
      "loss": 0.0501,
      "step": 65090
    },
    {
      "epoch": 7.843373493975903,
      "grad_norm": 4.763654708862305,
      "learning_rate": 1.2156626506024099e-05,
      "loss": 0.082,
      "step": 65100
    },
    {
      "epoch": 7.844578313253012,
      "grad_norm": 5.721970558166504,
      "learning_rate": 1.2155421686746988e-05,
      "loss": 0.0284,
      "step": 65110
    },
    {
      "epoch": 7.84578313253012,
      "grad_norm": 0.018859265372157097,
      "learning_rate": 1.2154216867469882e-05,
      "loss": 0.0103,
      "step": 65120
    },
    {
      "epoch": 7.846987951807229,
      "grad_norm": 8.130648612976074,
      "learning_rate": 1.2153012048192771e-05,
      "loss": 0.0288,
      "step": 65130
    },
    {
      "epoch": 7.848192771084337,
      "grad_norm": 0.12871703505516052,
      "learning_rate": 1.2151807228915664e-05,
      "loss": 0.0073,
      "step": 65140
    },
    {
      "epoch": 7.849397590361446,
      "grad_norm": 1.1426726579666138,
      "learning_rate": 1.2150602409638554e-05,
      "loss": 0.0291,
      "step": 65150
    },
    {
      "epoch": 7.8506024096385545,
      "grad_norm": 1.141571044921875,
      "learning_rate": 1.2149397590361447e-05,
      "loss": 0.0242,
      "step": 65160
    },
    {
      "epoch": 7.851807228915662,
      "grad_norm": 0.007978081703186035,
      "learning_rate": 1.2148192771084338e-05,
      "loss": 0.0177,
      "step": 65170
    },
    {
      "epoch": 7.853012048192771,
      "grad_norm": 7.5296101570129395,
      "learning_rate": 1.214698795180723e-05,
      "loss": 0.0303,
      "step": 65180
    },
    {
      "epoch": 7.85421686746988,
      "grad_norm": 1.0654797554016113,
      "learning_rate": 1.2145783132530122e-05,
      "loss": 0.0407,
      "step": 65190
    },
    {
      "epoch": 7.855421686746988,
      "grad_norm": 1.496641755104065,
      "learning_rate": 1.2144578313253013e-05,
      "loss": 0.0562,
      "step": 65200
    },
    {
      "epoch": 7.856626506024097,
      "grad_norm": 7.813507556915283,
      "learning_rate": 1.2143373493975906e-05,
      "loss": 0.0548,
      "step": 65210
    },
    {
      "epoch": 7.857831325301205,
      "grad_norm": 0.14155571162700653,
      "learning_rate": 1.2142168674698795e-05,
      "loss": 0.0264,
      "step": 65220
    },
    {
      "epoch": 7.8590361445783135,
      "grad_norm": 12.068288803100586,
      "learning_rate": 1.2140963855421689e-05,
      "loss": 0.034,
      "step": 65230
    },
    {
      "epoch": 7.860240963855421,
      "grad_norm": 0.06265971809625626,
      "learning_rate": 1.2139759036144578e-05,
      "loss": 0.0242,
      "step": 65240
    },
    {
      "epoch": 7.86144578313253,
      "grad_norm": 3.3555378913879395,
      "learning_rate": 1.213855421686747e-05,
      "loss": 0.0399,
      "step": 65250
    },
    {
      "epoch": 7.862650602409639,
      "grad_norm": 2.338303327560425,
      "learning_rate": 1.2137349397590363e-05,
      "loss": 0.0587,
      "step": 65260
    },
    {
      "epoch": 7.863855421686747,
      "grad_norm": 1.2874526977539062,
      "learning_rate": 1.2136144578313253e-05,
      "loss": 0.0121,
      "step": 65270
    },
    {
      "epoch": 7.865060240963856,
      "grad_norm": 0.22672340273857117,
      "learning_rate": 1.2134939759036146e-05,
      "loss": 0.0404,
      "step": 65280
    },
    {
      "epoch": 7.866265060240964,
      "grad_norm": 0.24116110801696777,
      "learning_rate": 1.2133734939759037e-05,
      "loss": 0.0469,
      "step": 65290
    },
    {
      "epoch": 7.867469879518072,
      "grad_norm": 4.253676891326904,
      "learning_rate": 1.2132530120481929e-05,
      "loss": 0.0237,
      "step": 65300
    },
    {
      "epoch": 7.86867469879518,
      "grad_norm": 0.008890841156244278,
      "learning_rate": 1.213132530120482e-05,
      "loss": 0.0081,
      "step": 65310
    },
    {
      "epoch": 7.869879518072289,
      "grad_norm": 0.04534422233700752,
      "learning_rate": 1.2130120481927712e-05,
      "loss": 0.0659,
      "step": 65320
    },
    {
      "epoch": 7.871084337349398,
      "grad_norm": 0.007581989746540785,
      "learning_rate": 1.2128915662650605e-05,
      "loss": 0.0249,
      "step": 65330
    },
    {
      "epoch": 7.872289156626506,
      "grad_norm": 1.4963704347610474,
      "learning_rate": 1.2127710843373495e-05,
      "loss": 0.0514,
      "step": 65340
    },
    {
      "epoch": 7.873493975903615,
      "grad_norm": 3.875837802886963,
      "learning_rate": 1.2126506024096388e-05,
      "loss": 0.0563,
      "step": 65350
    },
    {
      "epoch": 7.874698795180723,
      "grad_norm": 0.31163957715034485,
      "learning_rate": 1.2125301204819277e-05,
      "loss": 0.0294,
      "step": 65360
    },
    {
      "epoch": 7.875903614457831,
      "grad_norm": 0.1076558455824852,
      "learning_rate": 1.212409638554217e-05,
      "loss": 0.0201,
      "step": 65370
    },
    {
      "epoch": 7.877108433734939,
      "grad_norm": 27.442750930786133,
      "learning_rate": 1.212289156626506e-05,
      "loss": 0.0722,
      "step": 65380
    },
    {
      "epoch": 7.878313253012048,
      "grad_norm": 0.29723402857780457,
      "learning_rate": 1.2121686746987952e-05,
      "loss": 0.0261,
      "step": 65390
    },
    {
      "epoch": 7.879518072289157,
      "grad_norm": 9.26192855834961,
      "learning_rate": 1.2120481927710845e-05,
      "loss": 0.0303,
      "step": 65400
    },
    {
      "epoch": 7.880722891566265,
      "grad_norm": 0.006337177008390427,
      "learning_rate": 1.2119277108433736e-05,
      "loss": 0.0121,
      "step": 65410
    },
    {
      "epoch": 7.881927710843374,
      "grad_norm": 4.735546112060547,
      "learning_rate": 1.2118072289156628e-05,
      "loss": 0.041,
      "step": 65420
    },
    {
      "epoch": 7.8831325301204815,
      "grad_norm": 0.555722713470459,
      "learning_rate": 1.2116867469879519e-05,
      "loss": 0.0095,
      "step": 65430
    },
    {
      "epoch": 7.88433734939759,
      "grad_norm": 0.22713270783424377,
      "learning_rate": 1.2115662650602411e-05,
      "loss": 0.0219,
      "step": 65440
    },
    {
      "epoch": 7.885542168674699,
      "grad_norm": 0.2715654671192169,
      "learning_rate": 1.2114457831325302e-05,
      "loss": 0.0707,
      "step": 65450
    },
    {
      "epoch": 7.886746987951807,
      "grad_norm": 0.6059147715568542,
      "learning_rate": 1.2113253012048194e-05,
      "loss": 0.0273,
      "step": 65460
    },
    {
      "epoch": 7.887951807228916,
      "grad_norm": 0.05141988769173622,
      "learning_rate": 1.2112048192771083e-05,
      "loss": 0.0616,
      "step": 65470
    },
    {
      "epoch": 7.889156626506024,
      "grad_norm": 1.3415937423706055,
      "learning_rate": 1.2110843373493978e-05,
      "loss": 0.0164,
      "step": 65480
    },
    {
      "epoch": 7.890361445783133,
      "grad_norm": 0.32560980319976807,
      "learning_rate": 1.210963855421687e-05,
      "loss": 0.0237,
      "step": 65490
    },
    {
      "epoch": 7.891566265060241,
      "grad_norm": 0.5307100415229797,
      "learning_rate": 1.2108433734939759e-05,
      "loss": 0.0324,
      "step": 65500
    },
    {
      "epoch": 7.892771084337349,
      "grad_norm": 0.25951364636421204,
      "learning_rate": 1.2107228915662652e-05,
      "loss": 0.0559,
      "step": 65510
    },
    {
      "epoch": 7.893975903614458,
      "grad_norm": 0.41292238235473633,
      "learning_rate": 1.2106024096385542e-05,
      "loss": 0.0085,
      "step": 65520
    },
    {
      "epoch": 7.895180722891566,
      "grad_norm": 0.0213677566498518,
      "learning_rate": 1.2104819277108435e-05,
      "loss": 0.0357,
      "step": 65530
    },
    {
      "epoch": 7.896385542168675,
      "grad_norm": 1.418884038925171,
      "learning_rate": 1.2103614457831325e-05,
      "loss": 0.0277,
      "step": 65540
    },
    {
      "epoch": 7.897590361445783,
      "grad_norm": 12.436530113220215,
      "learning_rate": 1.2102409638554218e-05,
      "loss": 0.0735,
      "step": 65550
    },
    {
      "epoch": 7.8987951807228916,
      "grad_norm": 5.316122531890869,
      "learning_rate": 1.210120481927711e-05,
      "loss": 0.0401,
      "step": 65560
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.16787993907928467,
      "learning_rate": 1.2100000000000001e-05,
      "loss": 0.0215,
      "step": 65570
    },
    {
      "epoch": 7.901204819277108,
      "grad_norm": 0.1666565090417862,
      "learning_rate": 1.2098795180722893e-05,
      "loss": 0.0609,
      "step": 65580
    },
    {
      "epoch": 7.902409638554217,
      "grad_norm": 1.7954026460647583,
      "learning_rate": 1.2097590361445784e-05,
      "loss": 0.08,
      "step": 65590
    },
    {
      "epoch": 7.903614457831325,
      "grad_norm": 0.06454174220561981,
      "learning_rate": 1.2096385542168677e-05,
      "loss": 0.0535,
      "step": 65600
    },
    {
      "epoch": 7.904819277108434,
      "grad_norm": 0.4849850833415985,
      "learning_rate": 1.2095180722891566e-05,
      "loss": 0.0038,
      "step": 65610
    },
    {
      "epoch": 7.906024096385542,
      "grad_norm": 1.9254257678985596,
      "learning_rate": 1.2093975903614458e-05,
      "loss": 0.058,
      "step": 65620
    },
    {
      "epoch": 7.9072289156626505,
      "grad_norm": 0.021689407527446747,
      "learning_rate": 1.209277108433735e-05,
      "loss": 0.0494,
      "step": 65630
    },
    {
      "epoch": 7.908433734939759,
      "grad_norm": 0.2053976207971573,
      "learning_rate": 1.2091566265060241e-05,
      "loss": 0.0562,
      "step": 65640
    },
    {
      "epoch": 7.909638554216867,
      "grad_norm": 0.1156248152256012,
      "learning_rate": 1.2090361445783134e-05,
      "loss": 0.0015,
      "step": 65650
    },
    {
      "epoch": 7.910843373493976,
      "grad_norm": 0.016666851937770844,
      "learning_rate": 1.2089156626506024e-05,
      "loss": 0.027,
      "step": 65660
    },
    {
      "epoch": 7.912048192771084,
      "grad_norm": 3.964752674102783,
      "learning_rate": 1.2087951807228917e-05,
      "loss": 0.0849,
      "step": 65670
    },
    {
      "epoch": 7.913253012048193,
      "grad_norm": 0.037659648805856705,
      "learning_rate": 1.2086746987951808e-05,
      "loss": 0.0212,
      "step": 65680
    },
    {
      "epoch": 7.914457831325302,
      "grad_norm": 0.1279466301202774,
      "learning_rate": 1.20855421686747e-05,
      "loss": 0.0058,
      "step": 65690
    },
    {
      "epoch": 7.9156626506024095,
      "grad_norm": 1.033136010169983,
      "learning_rate": 1.2084337349397593e-05,
      "loss": 0.0154,
      "step": 65700
    },
    {
      "epoch": 7.916867469879518,
      "grad_norm": 1.3831114768981934,
      "learning_rate": 1.2083132530120483e-05,
      "loss": 0.0396,
      "step": 65710
    },
    {
      "epoch": 7.918072289156626,
      "grad_norm": 0.13014373183250427,
      "learning_rate": 1.2081927710843376e-05,
      "loss": 0.0257,
      "step": 65720
    },
    {
      "epoch": 7.919277108433735,
      "grad_norm": 4.643141746520996,
      "learning_rate": 1.2080722891566265e-05,
      "loss": 0.071,
      "step": 65730
    },
    {
      "epoch": 7.920481927710844,
      "grad_norm": 2.840597152709961,
      "learning_rate": 1.2079518072289159e-05,
      "loss": 0.0711,
      "step": 65740
    },
    {
      "epoch": 7.921686746987952,
      "grad_norm": 0.07500933110713959,
      "learning_rate": 1.2078313253012048e-05,
      "loss": 0.0081,
      "step": 65750
    },
    {
      "epoch": 7.9228915662650605,
      "grad_norm": 4.906157493591309,
      "learning_rate": 1.207710843373494e-05,
      "loss": 0.0766,
      "step": 65760
    },
    {
      "epoch": 7.924096385542168,
      "grad_norm": 0.18450677394866943,
      "learning_rate": 1.2075903614457831e-05,
      "loss": 0.0385,
      "step": 65770
    },
    {
      "epoch": 7.925301204819277,
      "grad_norm": 0.050327420234680176,
      "learning_rate": 1.2074698795180724e-05,
      "loss": 0.0188,
      "step": 65780
    },
    {
      "epoch": 7.926506024096385,
      "grad_norm": 1.0475770235061646,
      "learning_rate": 1.2073493975903616e-05,
      "loss": 0.0074,
      "step": 65790
    },
    {
      "epoch": 7.927710843373494,
      "grad_norm": 1.8652764558792114,
      "learning_rate": 1.2072289156626507e-05,
      "loss": 0.0447,
      "step": 65800
    },
    {
      "epoch": 7.928915662650603,
      "grad_norm": 0.2898784577846527,
      "learning_rate": 1.2071084337349399e-05,
      "loss": 0.0138,
      "step": 65810
    },
    {
      "epoch": 7.930120481927711,
      "grad_norm": 0.20903398096561432,
      "learning_rate": 1.206987951807229e-05,
      "loss": 0.0012,
      "step": 65820
    },
    {
      "epoch": 7.9313253012048195,
      "grad_norm": 0.006728302221745253,
      "learning_rate": 1.2068674698795182e-05,
      "loss": 0.0355,
      "step": 65830
    },
    {
      "epoch": 7.932530120481927,
      "grad_norm": 4.431326866149902,
      "learning_rate": 1.2067469879518073e-05,
      "loss": 0.0491,
      "step": 65840
    },
    {
      "epoch": 7.933734939759036,
      "grad_norm": 0.014956177212297916,
      "learning_rate": 1.2066265060240966e-05,
      "loss": 0.033,
      "step": 65850
    },
    {
      "epoch": 7.934939759036144,
      "grad_norm": 15.700439453125,
      "learning_rate": 1.2065060240963858e-05,
      "loss": 0.0725,
      "step": 65860
    },
    {
      "epoch": 7.936144578313253,
      "grad_norm": 0.8686810731887817,
      "learning_rate": 1.2063855421686747e-05,
      "loss": 0.0148,
      "step": 65870
    },
    {
      "epoch": 7.937349397590362,
      "grad_norm": 0.13138337433338165,
      "learning_rate": 1.206265060240964e-05,
      "loss": 0.0092,
      "step": 65880
    },
    {
      "epoch": 7.93855421686747,
      "grad_norm": 4.540464878082275,
      "learning_rate": 1.206144578313253e-05,
      "loss": 0.0672,
      "step": 65890
    },
    {
      "epoch": 7.9397590361445785,
      "grad_norm": 14.599584579467773,
      "learning_rate": 1.2060240963855423e-05,
      "loss": 0.0481,
      "step": 65900
    },
    {
      "epoch": 7.940963855421686,
      "grad_norm": 0.010190462693572044,
      "learning_rate": 1.2059036144578313e-05,
      "loss": 0.1028,
      "step": 65910
    },
    {
      "epoch": 7.942168674698795,
      "grad_norm": 0.04972516745328903,
      "learning_rate": 1.2057831325301206e-05,
      "loss": 0.0275,
      "step": 65920
    },
    {
      "epoch": 7.943373493975904,
      "grad_norm": 0.022128736600279808,
      "learning_rate": 1.2056626506024098e-05,
      "loss": 0.008,
      "step": 65930
    },
    {
      "epoch": 7.944578313253012,
      "grad_norm": 3.457939386367798,
      "learning_rate": 1.2055421686746989e-05,
      "loss": 0.0227,
      "step": 65940
    },
    {
      "epoch": 7.945783132530121,
      "grad_norm": 0.036171380430459976,
      "learning_rate": 1.2054216867469881e-05,
      "loss": 0.0037,
      "step": 65950
    },
    {
      "epoch": 7.946987951807229,
      "grad_norm": 0.026685282588005066,
      "learning_rate": 1.2053012048192772e-05,
      "loss": 0.0648,
      "step": 65960
    },
    {
      "epoch": 7.948192771084337,
      "grad_norm": 0.11296089738607407,
      "learning_rate": 1.2051807228915665e-05,
      "loss": 0.0232,
      "step": 65970
    },
    {
      "epoch": 7.949397590361446,
      "grad_norm": 0.7238183617591858,
      "learning_rate": 1.2050602409638554e-05,
      "loss": 0.0172,
      "step": 65980
    },
    {
      "epoch": 7.950602409638554,
      "grad_norm": 4.0715460777282715,
      "learning_rate": 1.2049397590361446e-05,
      "loss": 0.028,
      "step": 65990
    },
    {
      "epoch": 7.951807228915663,
      "grad_norm": 0.5764952301979065,
      "learning_rate": 1.204819277108434e-05,
      "loss": 0.0376,
      "step": 66000
    },
    {
      "epoch": 7.953012048192771,
      "grad_norm": 0.5016156435012817,
      "learning_rate": 1.204698795180723e-05,
      "loss": 0.0056,
      "step": 66010
    },
    {
      "epoch": 7.95421686746988,
      "grad_norm": 1.1944310665130615,
      "learning_rate": 1.2045783132530122e-05,
      "loss": 0.0253,
      "step": 66020
    },
    {
      "epoch": 7.955421686746988,
      "grad_norm": 0.051366545259952545,
      "learning_rate": 1.2044578313253012e-05,
      "loss": 0.0455,
      "step": 66030
    },
    {
      "epoch": 7.956626506024096,
      "grad_norm": 0.015923280268907547,
      "learning_rate": 1.2043373493975905e-05,
      "loss": 0.0492,
      "step": 66040
    },
    {
      "epoch": 7.957831325301205,
      "grad_norm": 0.01209512073546648,
      "learning_rate": 1.2042168674698796e-05,
      "loss": 0.0151,
      "step": 66050
    },
    {
      "epoch": 7.959036144578313,
      "grad_norm": 0.00990881584584713,
      "learning_rate": 1.2040963855421688e-05,
      "loss": 0.029,
      "step": 66060
    },
    {
      "epoch": 7.960240963855422,
      "grad_norm": 0.994030773639679,
      "learning_rate": 1.2039759036144579e-05,
      "loss": 0.0335,
      "step": 66070
    },
    {
      "epoch": 7.96144578313253,
      "grad_norm": 1.4623498916625977,
      "learning_rate": 1.2038554216867471e-05,
      "loss": 0.0441,
      "step": 66080
    },
    {
      "epoch": 7.962650602409639,
      "grad_norm": 16.13709259033203,
      "learning_rate": 1.2037349397590364e-05,
      "loss": 0.0268,
      "step": 66090
    },
    {
      "epoch": 7.9638554216867465,
      "grad_norm": 0.04761500656604767,
      "learning_rate": 1.2036144578313254e-05,
      "loss": 0.0077,
      "step": 66100
    },
    {
      "epoch": 7.965060240963855,
      "grad_norm": 0.013710534200072289,
      "learning_rate": 1.2034939759036147e-05,
      "loss": 0.0116,
      "step": 66110
    },
    {
      "epoch": 7.966265060240964,
      "grad_norm": 2.7669999599456787,
      "learning_rate": 1.2033734939759036e-05,
      "loss": 0.0297,
      "step": 66120
    },
    {
      "epoch": 7.967469879518072,
      "grad_norm": 0.014024066738784313,
      "learning_rate": 1.2032530120481928e-05,
      "loss": 0.0126,
      "step": 66130
    },
    {
      "epoch": 7.968674698795181,
      "grad_norm": 0.0022173470351845026,
      "learning_rate": 1.2031325301204819e-05,
      "loss": 0.0072,
      "step": 66140
    },
    {
      "epoch": 7.969879518072289,
      "grad_norm": 0.7346063852310181,
      "learning_rate": 1.2030120481927711e-05,
      "loss": 0.0421,
      "step": 66150
    },
    {
      "epoch": 7.971084337349398,
      "grad_norm": 0.0038612638600170612,
      "learning_rate": 1.2028915662650604e-05,
      "loss": 0.0465,
      "step": 66160
    },
    {
      "epoch": 7.972289156626506,
      "grad_norm": 0.009073165245354176,
      "learning_rate": 1.2027710843373495e-05,
      "loss": 0.0224,
      "step": 66170
    },
    {
      "epoch": 7.973493975903614,
      "grad_norm": 0.048776037991046906,
      "learning_rate": 1.2026506024096387e-05,
      "loss": 0.0104,
      "step": 66180
    },
    {
      "epoch": 7.974698795180723,
      "grad_norm": 0.007694953121244907,
      "learning_rate": 1.2025301204819278e-05,
      "loss": 0.019,
      "step": 66190
    },
    {
      "epoch": 7.975903614457831,
      "grad_norm": 0.009845335967838764,
      "learning_rate": 1.202409638554217e-05,
      "loss": 0.01,
      "step": 66200
    },
    {
      "epoch": 7.97710843373494,
      "grad_norm": 0.014368592761456966,
      "learning_rate": 1.2022891566265061e-05,
      "loss": 0.059,
      "step": 66210
    },
    {
      "epoch": 7.978313253012049,
      "grad_norm": 0.020635118708014488,
      "learning_rate": 1.2021686746987953e-05,
      "loss": 0.0582,
      "step": 66220
    },
    {
      "epoch": 7.9795180722891565,
      "grad_norm": 11.78724479675293,
      "learning_rate": 1.2020481927710846e-05,
      "loss": 0.0572,
      "step": 66230
    },
    {
      "epoch": 7.980722891566265,
      "grad_norm": 0.020374873653054237,
      "learning_rate": 1.2019277108433735e-05,
      "loss": 0.0223,
      "step": 66240
    },
    {
      "epoch": 7.981927710843373,
      "grad_norm": 2.9576327800750732,
      "learning_rate": 1.2018072289156627e-05,
      "loss": 0.0385,
      "step": 66250
    },
    {
      "epoch": 7.983132530120482,
      "grad_norm": 0.00622576056048274,
      "learning_rate": 1.2016867469879518e-05,
      "loss": 0.0012,
      "step": 66260
    },
    {
      "epoch": 7.98433734939759,
      "grad_norm": 1.6876568794250488,
      "learning_rate": 1.201566265060241e-05,
      "loss": 0.0528,
      "step": 66270
    },
    {
      "epoch": 7.985542168674699,
      "grad_norm": 0.5264726281166077,
      "learning_rate": 1.2014457831325301e-05,
      "loss": 0.0369,
      "step": 66280
    },
    {
      "epoch": 7.986746987951808,
      "grad_norm": 0.01092175766825676,
      "learning_rate": 1.2013253012048194e-05,
      "loss": 0.0172,
      "step": 66290
    },
    {
      "epoch": 7.9879518072289155,
      "grad_norm": 2.878411293029785,
      "learning_rate": 1.2012048192771086e-05,
      "loss": 0.0421,
      "step": 66300
    },
    {
      "epoch": 7.989156626506024,
      "grad_norm": 0.9148038029670715,
      "learning_rate": 1.2010843373493977e-05,
      "loss": 0.0255,
      "step": 66310
    },
    {
      "epoch": 7.990361445783132,
      "grad_norm": 0.022896312177181244,
      "learning_rate": 1.200963855421687e-05,
      "loss": 0.0048,
      "step": 66320
    },
    {
      "epoch": 7.991566265060241,
      "grad_norm": 0.02272733300924301,
      "learning_rate": 1.200843373493976e-05,
      "loss": 0.0032,
      "step": 66330
    },
    {
      "epoch": 7.992771084337349,
      "grad_norm": 0.034475646913051605,
      "learning_rate": 1.2007228915662652e-05,
      "loss": 0.0311,
      "step": 66340
    },
    {
      "epoch": 7.993975903614458,
      "grad_norm": 5.368890285491943,
      "learning_rate": 1.2006024096385542e-05,
      "loss": 0.0171,
      "step": 66350
    },
    {
      "epoch": 7.995180722891567,
      "grad_norm": 0.0065013873390853405,
      "learning_rate": 1.2004819277108436e-05,
      "loss": 0.0297,
      "step": 66360
    },
    {
      "epoch": 7.9963855421686745,
      "grad_norm": 0.008956342935562134,
      "learning_rate": 1.2003614457831325e-05,
      "loss": 0.0215,
      "step": 66370
    },
    {
      "epoch": 7.997590361445783,
      "grad_norm": 0.7893214225769043,
      "learning_rate": 1.2002409638554217e-05,
      "loss": 0.017,
      "step": 66380
    },
    {
      "epoch": 7.998795180722891,
      "grad_norm": 0.006046630442142487,
      "learning_rate": 1.200120481927711e-05,
      "loss": 0.048,
      "step": 66390
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.49898743629455566,
      "learning_rate": 1.2e-05,
      "loss": 0.0541,
      "step": 66400
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9846034870641169,
      "eval_f1": 0.9593264409088095,
      "eval_loss": 0.05476868525147438,
      "eval_precision": 0.9610518481766311,
      "eval_recall": 0.9576072178964281,
      "eval_runtime": 3384.4844,
      "eval_samples_per_second": 12.613,
      "eval_steps_per_second": 0.526,
      "step": 66400
    },
    {
      "epoch": 8.001204819277108,
      "grad_norm": 0.20613102614879608,
      "learning_rate": 1.1998795180722893e-05,
      "loss": 0.0532,
      "step": 66410
    },
    {
      "epoch": 8.002409638554218,
      "grad_norm": 0.0723753273487091,
      "learning_rate": 1.1997590361445783e-05,
      "loss": 0.0654,
      "step": 66420
    },
    {
      "epoch": 8.003614457831326,
      "grad_norm": 0.08347529917955399,
      "learning_rate": 1.1996385542168676e-05,
      "loss": 0.0106,
      "step": 66430
    },
    {
      "epoch": 8.004819277108433,
      "grad_norm": 0.07782476395368576,
      "learning_rate": 1.1995180722891567e-05,
      "loss": 0.0091,
      "step": 66440
    },
    {
      "epoch": 8.006024096385541,
      "grad_norm": 4.537776470184326,
      "learning_rate": 1.1993975903614459e-05,
      "loss": 0.0264,
      "step": 66450
    },
    {
      "epoch": 8.007228915662651,
      "grad_norm": 1.2144334316253662,
      "learning_rate": 1.1992771084337352e-05,
      "loss": 0.0576,
      "step": 66460
    },
    {
      "epoch": 8.008433734939759,
      "grad_norm": 1.9725292921066284,
      "learning_rate": 1.1991566265060242e-05,
      "loss": 0.0443,
      "step": 66470
    },
    {
      "epoch": 8.009638554216867,
      "grad_norm": 0.031225105747580528,
      "learning_rate": 1.1990361445783135e-05,
      "loss": 0.025,
      "step": 66480
    },
    {
      "epoch": 8.010843373493977,
      "grad_norm": 0.004151948727667332,
      "learning_rate": 1.1989156626506024e-05,
      "loss": 0.0304,
      "step": 66490
    },
    {
      "epoch": 8.012048192771084,
      "grad_norm": 0.015008334070444107,
      "learning_rate": 1.1987951807228916e-05,
      "loss": 0.0247,
      "step": 66500
    },
    {
      "epoch": 8.013253012048192,
      "grad_norm": 0.06644584238529205,
      "learning_rate": 1.1986746987951807e-05,
      "loss": 0.0168,
      "step": 66510
    },
    {
      "epoch": 8.0144578313253,
      "grad_norm": 2.5661606788635254,
      "learning_rate": 1.19855421686747e-05,
      "loss": 0.0212,
      "step": 66520
    },
    {
      "epoch": 8.01566265060241,
      "grad_norm": 0.2904212176799774,
      "learning_rate": 1.1984337349397592e-05,
      "loss": 0.01,
      "step": 66530
    },
    {
      "epoch": 8.016867469879518,
      "grad_norm": 11.83236026763916,
      "learning_rate": 1.1983132530120483e-05,
      "loss": 0.0609,
      "step": 66540
    },
    {
      "epoch": 8.018072289156626,
      "grad_norm": 0.12378337234258652,
      "learning_rate": 1.1981927710843375e-05,
      "loss": 0.0119,
      "step": 66550
    },
    {
      "epoch": 8.019277108433736,
      "grad_norm": 0.004391726106405258,
      "learning_rate": 1.1980722891566266e-05,
      "loss": 0.0069,
      "step": 66560
    },
    {
      "epoch": 8.020481927710843,
      "grad_norm": 0.42095106840133667,
      "learning_rate": 1.1979518072289158e-05,
      "loss": 0.004,
      "step": 66570
    },
    {
      "epoch": 8.021686746987951,
      "grad_norm": 0.020014185458421707,
      "learning_rate": 1.1978313253012049e-05,
      "loss": 0.0084,
      "step": 66580
    },
    {
      "epoch": 8.022891566265061,
      "grad_norm": 0.24021592736244202,
      "learning_rate": 1.1977108433734941e-05,
      "loss": 0.0007,
      "step": 66590
    },
    {
      "epoch": 8.024096385542169,
      "grad_norm": 0.0024242186918854713,
      "learning_rate": 1.1975903614457834e-05,
      "loss": 0.0587,
      "step": 66600
    },
    {
      "epoch": 8.025301204819277,
      "grad_norm": 0.20699873566627502,
      "learning_rate": 1.1974698795180723e-05,
      "loss": 0.0893,
      "step": 66610
    },
    {
      "epoch": 8.026506024096385,
      "grad_norm": 0.20999886095523834,
      "learning_rate": 1.1973493975903617e-05,
      "loss": 0.0288,
      "step": 66620
    },
    {
      "epoch": 8.027710843373494,
      "grad_norm": 0.11757606267929077,
      "learning_rate": 1.1972289156626506e-05,
      "loss": 0.0202,
      "step": 66630
    },
    {
      "epoch": 8.028915662650602,
      "grad_norm": 0.15570491552352905,
      "learning_rate": 1.1971084337349398e-05,
      "loss": 0.0559,
      "step": 66640
    },
    {
      "epoch": 8.03012048192771,
      "grad_norm": 0.03812160715460777,
      "learning_rate": 1.196987951807229e-05,
      "loss": 0.0087,
      "step": 66650
    },
    {
      "epoch": 8.03132530120482,
      "grad_norm": 0.009889288805425167,
      "learning_rate": 1.1968674698795182e-05,
      "loss": 0.0533,
      "step": 66660
    },
    {
      "epoch": 8.032530120481928,
      "grad_norm": 2.301900863647461,
      "learning_rate": 1.1967469879518074e-05,
      "loss": 0.0209,
      "step": 66670
    },
    {
      "epoch": 8.033734939759036,
      "grad_norm": 0.37090665102005005,
      "learning_rate": 1.1966265060240965e-05,
      "loss": 0.0411,
      "step": 66680
    },
    {
      "epoch": 8.034939759036144,
      "grad_norm": 0.9799081683158875,
      "learning_rate": 1.1965060240963857e-05,
      "loss": 0.0164,
      "step": 66690
    },
    {
      "epoch": 8.036144578313253,
      "grad_norm": 0.03963296860456467,
      "learning_rate": 1.1963855421686748e-05,
      "loss": 0.0094,
      "step": 66700
    },
    {
      "epoch": 8.037349397590361,
      "grad_norm": 1.0066667795181274,
      "learning_rate": 1.196265060240964e-05,
      "loss": 0.0473,
      "step": 66710
    },
    {
      "epoch": 8.03855421686747,
      "grad_norm": 0.004923632834106684,
      "learning_rate": 1.1961445783132531e-05,
      "loss": 0.0081,
      "step": 66720
    },
    {
      "epoch": 8.039759036144579,
      "grad_norm": 0.49207326769828796,
      "learning_rate": 1.1960240963855424e-05,
      "loss": 0.0562,
      "step": 66730
    },
    {
      "epoch": 8.040963855421687,
      "grad_norm": 0.019004054367542267,
      "learning_rate": 1.1959036144578313e-05,
      "loss": 0.0173,
      "step": 66740
    },
    {
      "epoch": 8.042168674698795,
      "grad_norm": 5.101664066314697,
      "learning_rate": 1.1957831325301205e-05,
      "loss": 0.0324,
      "step": 66750
    },
    {
      "epoch": 8.043373493975903,
      "grad_norm": 5.294960975646973,
      "learning_rate": 1.1956626506024097e-05,
      "loss": 0.0527,
      "step": 66760
    },
    {
      "epoch": 8.044578313253012,
      "grad_norm": 0.008951447904109955,
      "learning_rate": 1.1955421686746988e-05,
      "loss": 0.0134,
      "step": 66770
    },
    {
      "epoch": 8.04578313253012,
      "grad_norm": 0.005638068541884422,
      "learning_rate": 1.195421686746988e-05,
      "loss": 0.0186,
      "step": 66780
    },
    {
      "epoch": 8.046987951807228,
      "grad_norm": 2.237358570098877,
      "learning_rate": 1.1953012048192771e-05,
      "loss": 0.0211,
      "step": 66790
    },
    {
      "epoch": 8.048192771084338,
      "grad_norm": 1.2714812755584717,
      "learning_rate": 1.1951807228915664e-05,
      "loss": 0.0277,
      "step": 66800
    },
    {
      "epoch": 8.049397590361446,
      "grad_norm": 0.15121333301067352,
      "learning_rate": 1.1950602409638555e-05,
      "loss": 0.0277,
      "step": 66810
    },
    {
      "epoch": 8.050602409638554,
      "grad_norm": 0.14503419399261475,
      "learning_rate": 1.1949397590361447e-05,
      "loss": 0.017,
      "step": 66820
    },
    {
      "epoch": 8.051807228915663,
      "grad_norm": 1.0280182361602783,
      "learning_rate": 1.194819277108434e-05,
      "loss": 0.0387,
      "step": 66830
    },
    {
      "epoch": 8.053012048192771,
      "grad_norm": 0.989399790763855,
      "learning_rate": 1.194698795180723e-05,
      "loss": 0.0141,
      "step": 66840
    },
    {
      "epoch": 8.05421686746988,
      "grad_norm": 1.1796163320541382,
      "learning_rate": 1.1945783132530123e-05,
      "loss": 0.0051,
      "step": 66850
    },
    {
      "epoch": 8.055421686746987,
      "grad_norm": 0.5394876599311829,
      "learning_rate": 1.1944578313253012e-05,
      "loss": 0.035,
      "step": 66860
    },
    {
      "epoch": 8.056626506024097,
      "grad_norm": 0.015836263075470924,
      "learning_rate": 1.1943373493975906e-05,
      "loss": 0.0169,
      "step": 66870
    },
    {
      "epoch": 8.057831325301205,
      "grad_norm": 0.4085869789123535,
      "learning_rate": 1.1942168674698795e-05,
      "loss": 0.0199,
      "step": 66880
    },
    {
      "epoch": 8.059036144578313,
      "grad_norm": 3.8734045028686523,
      "learning_rate": 1.1940963855421687e-05,
      "loss": 0.0189,
      "step": 66890
    },
    {
      "epoch": 8.060240963855422,
      "grad_norm": 0.004799084737896919,
      "learning_rate": 1.193975903614458e-05,
      "loss": 0.0157,
      "step": 66900
    },
    {
      "epoch": 8.06144578313253,
      "grad_norm": 1.0700088739395142,
      "learning_rate": 1.193855421686747e-05,
      "loss": 0.0251,
      "step": 66910
    },
    {
      "epoch": 8.062650602409638,
      "grad_norm": 1.5726566314697266,
      "learning_rate": 1.1937349397590363e-05,
      "loss": 0.0563,
      "step": 66920
    },
    {
      "epoch": 8.063855421686746,
      "grad_norm": 1.500612735748291,
      "learning_rate": 1.1936144578313254e-05,
      "loss": 0.0235,
      "step": 66930
    },
    {
      "epoch": 8.065060240963856,
      "grad_norm": 1.1825861930847168,
      "learning_rate": 1.1934939759036146e-05,
      "loss": 0.0243,
      "step": 66940
    },
    {
      "epoch": 8.066265060240964,
      "grad_norm": 0.049742188304662704,
      "learning_rate": 1.1933734939759037e-05,
      "loss": 0.061,
      "step": 66950
    },
    {
      "epoch": 8.067469879518072,
      "grad_norm": 0.011110179126262665,
      "learning_rate": 1.193253012048193e-05,
      "loss": 0.0112,
      "step": 66960
    },
    {
      "epoch": 8.068674698795181,
      "grad_norm": 0.003779076738283038,
      "learning_rate": 1.1931325301204822e-05,
      "loss": 0.0153,
      "step": 66970
    },
    {
      "epoch": 8.06987951807229,
      "grad_norm": 0.3403007984161377,
      "learning_rate": 1.1930120481927712e-05,
      "loss": 0.0311,
      "step": 66980
    },
    {
      "epoch": 8.071084337349397,
      "grad_norm": 0.00929758045822382,
      "learning_rate": 1.1928915662650605e-05,
      "loss": 0.0176,
      "step": 66990
    },
    {
      "epoch": 8.072289156626505,
      "grad_norm": 0.00931511353701353,
      "learning_rate": 1.1927710843373494e-05,
      "loss": 0.0133,
      "step": 67000
    },
    {
      "epoch": 8.073493975903615,
      "grad_norm": 0.08355282992124557,
      "learning_rate": 1.1926506024096386e-05,
      "loss": 0.003,
      "step": 67010
    },
    {
      "epoch": 8.074698795180723,
      "grad_norm": 0.03588612750172615,
      "learning_rate": 1.1925301204819277e-05,
      "loss": 0.0515,
      "step": 67020
    },
    {
      "epoch": 8.07590361445783,
      "grad_norm": 5.173795700073242,
      "learning_rate": 1.192409638554217e-05,
      "loss": 0.0242,
      "step": 67030
    },
    {
      "epoch": 8.07710843373494,
      "grad_norm": 0.6023038029670715,
      "learning_rate": 1.192289156626506e-05,
      "loss": 0.0256,
      "step": 67040
    },
    {
      "epoch": 8.078313253012048,
      "grad_norm": 1.2124781608581543,
      "learning_rate": 1.1921686746987953e-05,
      "loss": 0.0189,
      "step": 67050
    },
    {
      "epoch": 8.079518072289156,
      "grad_norm": 0.004231659695506096,
      "learning_rate": 1.1920481927710845e-05,
      "loss": 0.0002,
      "step": 67060
    },
    {
      "epoch": 8.080722891566266,
      "grad_norm": 0.19313979148864746,
      "learning_rate": 1.1919277108433736e-05,
      "loss": 0.0026,
      "step": 67070
    },
    {
      "epoch": 8.081927710843374,
      "grad_norm": 0.020827146247029305,
      "learning_rate": 1.1918072289156628e-05,
      "loss": 0.0591,
      "step": 67080
    },
    {
      "epoch": 8.083132530120482,
      "grad_norm": 0.03693244606256485,
      "learning_rate": 1.1916867469879519e-05,
      "loss": 0.0242,
      "step": 67090
    },
    {
      "epoch": 8.08433734939759,
      "grad_norm": 0.08481617271900177,
      "learning_rate": 1.1915662650602411e-05,
      "loss": 0.0296,
      "step": 67100
    },
    {
      "epoch": 8.0855421686747,
      "grad_norm": 0.2446940541267395,
      "learning_rate": 1.19144578313253e-05,
      "loss": 0.0114,
      "step": 67110
    },
    {
      "epoch": 8.086746987951807,
      "grad_norm": 0.10956846177577972,
      "learning_rate": 1.1913253012048193e-05,
      "loss": 0.0009,
      "step": 67120
    },
    {
      "epoch": 8.087951807228915,
      "grad_norm": 24.492218017578125,
      "learning_rate": 1.1912048192771087e-05,
      "loss": 0.0462,
      "step": 67130
    },
    {
      "epoch": 8.089156626506025,
      "grad_norm": 2.536783218383789,
      "learning_rate": 1.1910843373493976e-05,
      "loss": 0.0386,
      "step": 67140
    },
    {
      "epoch": 8.090361445783133,
      "grad_norm": 0.26507237553596497,
      "learning_rate": 1.1909638554216869e-05,
      "loss": 0.0073,
      "step": 67150
    },
    {
      "epoch": 8.09156626506024,
      "grad_norm": 0.00251515069976449,
      "learning_rate": 1.190843373493976e-05,
      "loss": 0.0064,
      "step": 67160
    },
    {
      "epoch": 8.092771084337349,
      "grad_norm": 0.013091068714857101,
      "learning_rate": 1.1907228915662652e-05,
      "loss": 0.0458,
      "step": 67170
    },
    {
      "epoch": 8.093975903614458,
      "grad_norm": 0.1510881632566452,
      "learning_rate": 1.1906024096385542e-05,
      "loss": 0.0011,
      "step": 67180
    },
    {
      "epoch": 8.095180722891566,
      "grad_norm": 0.5585517287254333,
      "learning_rate": 1.1904819277108435e-05,
      "loss": 0.0216,
      "step": 67190
    },
    {
      "epoch": 8.096385542168674,
      "grad_norm": 0.0059766159392893314,
      "learning_rate": 1.1903614457831327e-05,
      "loss": 0.0583,
      "step": 67200
    },
    {
      "epoch": 8.097590361445784,
      "grad_norm": 0.036053773015737534,
      "learning_rate": 1.1902409638554218e-05,
      "loss": 0.0647,
      "step": 67210
    },
    {
      "epoch": 8.098795180722892,
      "grad_norm": 1.7647238969802856,
      "learning_rate": 1.190120481927711e-05,
      "loss": 0.018,
      "step": 67220
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.06528844684362411,
      "learning_rate": 1.1900000000000001e-05,
      "loss": 0.0082,
      "step": 67230
    },
    {
      "epoch": 8.101204819277108,
      "grad_norm": 0.8176572918891907,
      "learning_rate": 1.1898795180722894e-05,
      "loss": 0.0722,
      "step": 67240
    },
    {
      "epoch": 8.102409638554217,
      "grad_norm": 0.012635611928999424,
      "learning_rate": 1.1897590361445783e-05,
      "loss": 0.0419,
      "step": 67250
    },
    {
      "epoch": 8.103614457831325,
      "grad_norm": 0.08023592829704285,
      "learning_rate": 1.1896385542168675e-05,
      "loss": 0.0277,
      "step": 67260
    },
    {
      "epoch": 8.104819277108433,
      "grad_norm": 10.325555801391602,
      "learning_rate": 1.1895180722891568e-05,
      "loss": 0.0104,
      "step": 67270
    },
    {
      "epoch": 8.106024096385543,
      "grad_norm": 0.1392698585987091,
      "learning_rate": 1.1893975903614458e-05,
      "loss": 0.0127,
      "step": 67280
    },
    {
      "epoch": 8.10722891566265,
      "grad_norm": 0.033918749541044235,
      "learning_rate": 1.189277108433735e-05,
      "loss": 0.0198,
      "step": 67290
    },
    {
      "epoch": 8.108433734939759,
      "grad_norm": 0.20553721487522125,
      "learning_rate": 1.1891566265060242e-05,
      "loss": 0.0169,
      "step": 67300
    },
    {
      "epoch": 8.109638554216868,
      "grad_norm": 3.421170473098755,
      "learning_rate": 1.1890361445783134e-05,
      "loss": 0.0152,
      "step": 67310
    },
    {
      "epoch": 8.110843373493976,
      "grad_norm": 2.449486255645752,
      "learning_rate": 1.1889156626506025e-05,
      "loss": 0.0327,
      "step": 67320
    },
    {
      "epoch": 8.112048192771084,
      "grad_norm": 0.041740257292985916,
      "learning_rate": 1.1887951807228917e-05,
      "loss": 0.0764,
      "step": 67330
    },
    {
      "epoch": 8.113253012048192,
      "grad_norm": 0.037503525614738464,
      "learning_rate": 1.1886746987951808e-05,
      "loss": 0.023,
      "step": 67340
    },
    {
      "epoch": 8.114457831325302,
      "grad_norm": 0.13577494025230408,
      "learning_rate": 1.18855421686747e-05,
      "loss": 0.0207,
      "step": 67350
    },
    {
      "epoch": 8.11566265060241,
      "grad_norm": 0.03737054765224457,
      "learning_rate": 1.1884337349397593e-05,
      "loss": 0.0051,
      "step": 67360
    },
    {
      "epoch": 8.116867469879518,
      "grad_norm": 1.3183481693267822,
      "learning_rate": 1.1883132530120482e-05,
      "loss": 0.0633,
      "step": 67370
    },
    {
      "epoch": 8.118072289156627,
      "grad_norm": 0.01391384843736887,
      "learning_rate": 1.1881927710843374e-05,
      "loss": 0.0104,
      "step": 67380
    },
    {
      "epoch": 8.119277108433735,
      "grad_norm": 0.01175481267273426,
      "learning_rate": 1.1880722891566265e-05,
      "loss": 0.0207,
      "step": 67390
    },
    {
      "epoch": 8.120481927710843,
      "grad_norm": 0.00896872952580452,
      "learning_rate": 1.1879518072289157e-05,
      "loss": 0.0126,
      "step": 67400
    },
    {
      "epoch": 8.121686746987951,
      "grad_norm": 3.14158034324646,
      "learning_rate": 1.1878313253012048e-05,
      "loss": 0.0548,
      "step": 67410
    },
    {
      "epoch": 8.12289156626506,
      "grad_norm": 0.021049315109848976,
      "learning_rate": 1.187710843373494e-05,
      "loss": 0.0906,
      "step": 67420
    },
    {
      "epoch": 8.124096385542169,
      "grad_norm": 1.7865391969680786,
      "learning_rate": 1.1875903614457833e-05,
      "loss": 0.0333,
      "step": 67430
    },
    {
      "epoch": 8.125301204819277,
      "grad_norm": 0.7109334468841553,
      "learning_rate": 1.1874698795180724e-05,
      "loss": 0.0554,
      "step": 67440
    },
    {
      "epoch": 8.126506024096386,
      "grad_norm": 0.15600575506687164,
      "learning_rate": 1.1873493975903616e-05,
      "loss": 0.0863,
      "step": 67450
    },
    {
      "epoch": 8.127710843373494,
      "grad_norm": 0.024262767285108566,
      "learning_rate": 1.1872289156626507e-05,
      "loss": 0.0287,
      "step": 67460
    },
    {
      "epoch": 8.128915662650602,
      "grad_norm": 1.150923252105713,
      "learning_rate": 1.18710843373494e-05,
      "loss": 0.0092,
      "step": 67470
    },
    {
      "epoch": 8.13012048192771,
      "grad_norm": 0.06460867822170258,
      "learning_rate": 1.1869879518072288e-05,
      "loss": 0.0485,
      "step": 67480
    },
    {
      "epoch": 8.13132530120482,
      "grad_norm": 0.024209419265389442,
      "learning_rate": 1.1868674698795183e-05,
      "loss": 0.0387,
      "step": 67490
    },
    {
      "epoch": 8.132530120481928,
      "grad_norm": 0.07770009338855743,
      "learning_rate": 1.1867469879518075e-05,
      "loss": 0.0062,
      "step": 67500
    },
    {
      "epoch": 8.133734939759035,
      "grad_norm": 0.248147115111351,
      "learning_rate": 1.1866265060240964e-05,
      "loss": 0.0085,
      "step": 67510
    },
    {
      "epoch": 8.134939759036145,
      "grad_norm": 0.7150710225105286,
      "learning_rate": 1.1865060240963856e-05,
      "loss": 0.0578,
      "step": 67520
    },
    {
      "epoch": 8.136144578313253,
      "grad_norm": 3.6953351497650146,
      "learning_rate": 1.1863855421686747e-05,
      "loss": 0.0347,
      "step": 67530
    },
    {
      "epoch": 8.137349397590361,
      "grad_norm": 0.009494312107563019,
      "learning_rate": 1.186265060240964e-05,
      "loss": 0.0171,
      "step": 67540
    },
    {
      "epoch": 8.13855421686747,
      "grad_norm": 0.04728059470653534,
      "learning_rate": 1.186144578313253e-05,
      "loss": 0.0248,
      "step": 67550
    },
    {
      "epoch": 8.139759036144579,
      "grad_norm": 0.004841076675802469,
      "learning_rate": 1.1860240963855423e-05,
      "loss": 0.01,
      "step": 67560
    },
    {
      "epoch": 8.140963855421687,
      "grad_norm": 0.06981486827135086,
      "learning_rate": 1.1859036144578315e-05,
      "loss": 0.0468,
      "step": 67570
    },
    {
      "epoch": 8.142168674698794,
      "grad_norm": 0.014318139292299747,
      "learning_rate": 1.1857831325301206e-05,
      "loss": 0.0657,
      "step": 67580
    },
    {
      "epoch": 8.143373493975904,
      "grad_norm": 1.0853521823883057,
      "learning_rate": 1.1856626506024098e-05,
      "loss": 0.017,
      "step": 67590
    },
    {
      "epoch": 8.144578313253012,
      "grad_norm": 1.437333106994629,
      "learning_rate": 1.185542168674699e-05,
      "loss": 0.0277,
      "step": 67600
    },
    {
      "epoch": 8.14578313253012,
      "grad_norm": 0.3210587203502655,
      "learning_rate": 1.1854216867469882e-05,
      "loss": 0.0539,
      "step": 67610
    },
    {
      "epoch": 8.14698795180723,
      "grad_norm": 0.08672022074460983,
      "learning_rate": 1.185301204819277e-05,
      "loss": 0.0341,
      "step": 67620
    },
    {
      "epoch": 8.148192771084338,
      "grad_norm": 1.3793821334838867,
      "learning_rate": 1.1851807228915663e-05,
      "loss": 0.0136,
      "step": 67630
    },
    {
      "epoch": 8.149397590361446,
      "grad_norm": 0.03728674724698067,
      "learning_rate": 1.1850602409638554e-05,
      "loss": 0.0144,
      "step": 67640
    },
    {
      "epoch": 8.150602409638553,
      "grad_norm": 0.004260564688593149,
      "learning_rate": 1.1849397590361446e-05,
      "loss": 0.0365,
      "step": 67650
    },
    {
      "epoch": 8.151807228915663,
      "grad_norm": 7.817083358764648,
      "learning_rate": 1.1848192771084339e-05,
      "loss": 0.0565,
      "step": 67660
    },
    {
      "epoch": 8.153012048192771,
      "grad_norm": 44.203895568847656,
      "learning_rate": 1.184698795180723e-05,
      "loss": 0.033,
      "step": 67670
    },
    {
      "epoch": 8.154216867469879,
      "grad_norm": 0.20814034342765808,
      "learning_rate": 1.1845783132530122e-05,
      "loss": 0.0384,
      "step": 67680
    },
    {
      "epoch": 8.155421686746989,
      "grad_norm": 0.009623322635889053,
      "learning_rate": 1.1844578313253013e-05,
      "loss": 0.0241,
      "step": 67690
    },
    {
      "epoch": 8.156626506024097,
      "grad_norm": 7.540441513061523,
      "learning_rate": 1.1843373493975905e-05,
      "loss": 0.0407,
      "step": 67700
    },
    {
      "epoch": 8.157831325301204,
      "grad_norm": 2.2673561573028564,
      "learning_rate": 1.1842168674698796e-05,
      "loss": 0.0355,
      "step": 67710
    },
    {
      "epoch": 8.159036144578312,
      "grad_norm": 1.782486081123352,
      "learning_rate": 1.1840963855421688e-05,
      "loss": 0.0291,
      "step": 67720
    },
    {
      "epoch": 8.160240963855422,
      "grad_norm": 0.1289624720811844,
      "learning_rate": 1.183975903614458e-05,
      "loss": 0.0241,
      "step": 67730
    },
    {
      "epoch": 8.16144578313253,
      "grad_norm": 0.05858692526817322,
      "learning_rate": 1.183855421686747e-05,
      "loss": 0.0358,
      "step": 67740
    },
    {
      "epoch": 8.162650602409638,
      "grad_norm": 0.00585048645734787,
      "learning_rate": 1.1837349397590364e-05,
      "loss": 0.0145,
      "step": 67750
    },
    {
      "epoch": 8.163855421686748,
      "grad_norm": 0.008407322689890862,
      "learning_rate": 1.1836144578313253e-05,
      "loss": 0.0314,
      "step": 67760
    },
    {
      "epoch": 8.165060240963856,
      "grad_norm": 0.2282041311264038,
      "learning_rate": 1.1834939759036145e-05,
      "loss": 0.0083,
      "step": 67770
    },
    {
      "epoch": 8.166265060240963,
      "grad_norm": 0.5854398608207703,
      "learning_rate": 1.1833734939759036e-05,
      "loss": 0.0251,
      "step": 67780
    },
    {
      "epoch": 8.167469879518073,
      "grad_norm": 0.1130179837346077,
      "learning_rate": 1.1832530120481928e-05,
      "loss": 0.0487,
      "step": 67790
    },
    {
      "epoch": 8.168674698795181,
      "grad_norm": 4.0021443367004395,
      "learning_rate": 1.1831325301204821e-05,
      "loss": 0.0097,
      "step": 67800
    },
    {
      "epoch": 8.169879518072289,
      "grad_norm": 0.011338496580719948,
      "learning_rate": 1.1830120481927712e-05,
      "loss": 0.068,
      "step": 67810
    },
    {
      "epoch": 8.171084337349397,
      "grad_norm": 0.17286302149295807,
      "learning_rate": 1.1828915662650604e-05,
      "loss": 0.0361,
      "step": 67820
    },
    {
      "epoch": 8.172289156626507,
      "grad_norm": 0.07103723287582397,
      "learning_rate": 1.1827710843373495e-05,
      "loss": 0.0218,
      "step": 67830
    },
    {
      "epoch": 8.173493975903614,
      "grad_norm": 2.913381338119507,
      "learning_rate": 1.1826506024096387e-05,
      "loss": 0.0598,
      "step": 67840
    },
    {
      "epoch": 8.174698795180722,
      "grad_norm": 0.19189412891864777,
      "learning_rate": 1.1825301204819278e-05,
      "loss": 0.0082,
      "step": 67850
    },
    {
      "epoch": 8.175903614457832,
      "grad_norm": 0.23368805646896362,
      "learning_rate": 1.182409638554217e-05,
      "loss": 0.0304,
      "step": 67860
    },
    {
      "epoch": 8.17710843373494,
      "grad_norm": 0.005155619699507952,
      "learning_rate": 1.1822891566265063e-05,
      "loss": 0.0697,
      "step": 67870
    },
    {
      "epoch": 8.178313253012048,
      "grad_norm": 0.005851877853274345,
      "learning_rate": 1.1821686746987952e-05,
      "loss": 0.0095,
      "step": 67880
    },
    {
      "epoch": 8.179518072289156,
      "grad_norm": 1.7048001289367676,
      "learning_rate": 1.1820481927710844e-05,
      "loss": 0.0281,
      "step": 67890
    },
    {
      "epoch": 8.180722891566266,
      "grad_norm": 0.007142172660678625,
      "learning_rate": 1.1819277108433735e-05,
      "loss": 0.0096,
      "step": 67900
    },
    {
      "epoch": 8.181927710843373,
      "grad_norm": 9.861152648925781,
      "learning_rate": 1.1818072289156628e-05,
      "loss": 0.0148,
      "step": 67910
    },
    {
      "epoch": 8.183132530120481,
      "grad_norm": 0.007478812709450722,
      "learning_rate": 1.1816867469879518e-05,
      "loss": 0.0005,
      "step": 67920
    },
    {
      "epoch": 8.184337349397591,
      "grad_norm": 0.00897821132093668,
      "learning_rate": 1.181566265060241e-05,
      "loss": 0.0143,
      "step": 67930
    },
    {
      "epoch": 8.185542168674699,
      "grad_norm": 0.029924970120191574,
      "learning_rate": 1.1814457831325301e-05,
      "loss": 0.0187,
      "step": 67940
    },
    {
      "epoch": 8.186746987951807,
      "grad_norm": 0.01015501283109188,
      "learning_rate": 1.1813253012048194e-05,
      "loss": 0.0283,
      "step": 67950
    },
    {
      "epoch": 8.187951807228915,
      "grad_norm": 0.0033151705283671618,
      "learning_rate": 1.1812048192771086e-05,
      "loss": 0.037,
      "step": 67960
    },
    {
      "epoch": 8.189156626506024,
      "grad_norm": 0.012464870698750019,
      "learning_rate": 1.1810843373493977e-05,
      "loss": 0.0031,
      "step": 67970
    },
    {
      "epoch": 8.190361445783132,
      "grad_norm": 0.0035994346253573895,
      "learning_rate": 1.180963855421687e-05,
      "loss": 0.0144,
      "step": 67980
    },
    {
      "epoch": 8.19156626506024,
      "grad_norm": 2.1444363594055176,
      "learning_rate": 1.1808433734939759e-05,
      "loss": 0.012,
      "step": 67990
    },
    {
      "epoch": 8.19277108433735,
      "grad_norm": 2.361685037612915,
      "learning_rate": 1.1807228915662651e-05,
      "loss": 0.0195,
      "step": 68000
    },
    {
      "epoch": 8.193975903614458,
      "grad_norm": 0.07111591845750809,
      "learning_rate": 1.1806024096385542e-05,
      "loss": 0.0132,
      "step": 68010
    },
    {
      "epoch": 8.195180722891566,
      "grad_norm": 0.0023365039378404617,
      "learning_rate": 1.1804819277108434e-05,
      "loss": 0.0818,
      "step": 68020
    },
    {
      "epoch": 8.196385542168676,
      "grad_norm": 0.002360361395403743,
      "learning_rate": 1.1803614457831327e-05,
      "loss": 0.0778,
      "step": 68030
    },
    {
      "epoch": 8.197590361445783,
      "grad_norm": 1.5050487518310547,
      "learning_rate": 1.1802409638554217e-05,
      "loss": 0.0486,
      "step": 68040
    },
    {
      "epoch": 8.198795180722891,
      "grad_norm": 0.44041985273361206,
      "learning_rate": 1.180120481927711e-05,
      "loss": 0.0864,
      "step": 68050
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.1692347526550293,
      "learning_rate": 1.18e-05,
      "loss": 0.0198,
      "step": 68060
    },
    {
      "epoch": 8.201204819277109,
      "grad_norm": 16.68849754333496,
      "learning_rate": 1.1798795180722893e-05,
      "loss": 0.0259,
      "step": 68070
    },
    {
      "epoch": 8.202409638554217,
      "grad_norm": 1.036838412284851,
      "learning_rate": 1.1797590361445784e-05,
      "loss": 0.0397,
      "step": 68080
    },
    {
      "epoch": 8.203614457831325,
      "grad_norm": 0.01969868876039982,
      "learning_rate": 1.1796385542168676e-05,
      "loss": 0.0152,
      "step": 68090
    },
    {
      "epoch": 8.204819277108435,
      "grad_norm": 2.5204741954803467,
      "learning_rate": 1.1795180722891569e-05,
      "loss": 0.019,
      "step": 68100
    },
    {
      "epoch": 8.206024096385542,
      "grad_norm": 9.116714477539062,
      "learning_rate": 1.179397590361446e-05,
      "loss": 0.0385,
      "step": 68110
    },
    {
      "epoch": 8.20722891566265,
      "grad_norm": 0.035787828266620636,
      "learning_rate": 1.1792771084337352e-05,
      "loss": 0.0212,
      "step": 68120
    },
    {
      "epoch": 8.208433734939758,
      "grad_norm": 0.7115464806556702,
      "learning_rate": 1.179156626506024e-05,
      "loss": 0.0342,
      "step": 68130
    },
    {
      "epoch": 8.209638554216868,
      "grad_norm": 0.5968571901321411,
      "learning_rate": 1.1790361445783133e-05,
      "loss": 0.0184,
      "step": 68140
    },
    {
      "epoch": 8.210843373493976,
      "grad_norm": 0.35081300139427185,
      "learning_rate": 1.1789156626506024e-05,
      "loss": 0.027,
      "step": 68150
    },
    {
      "epoch": 8.212048192771084,
      "grad_norm": 2.18383526802063,
      "learning_rate": 1.1787951807228916e-05,
      "loss": 0.0207,
      "step": 68160
    },
    {
      "epoch": 8.213253012048193,
      "grad_norm": 1.2527365684509277,
      "learning_rate": 1.1786746987951809e-05,
      "loss": 0.0462,
      "step": 68170
    },
    {
      "epoch": 8.214457831325301,
      "grad_norm": 6.274114608764648,
      "learning_rate": 1.17855421686747e-05,
      "loss": 0.0388,
      "step": 68180
    },
    {
      "epoch": 8.21566265060241,
      "grad_norm": 8.917671203613281,
      "learning_rate": 1.1784337349397592e-05,
      "loss": 0.0452,
      "step": 68190
    },
    {
      "epoch": 8.216867469879517,
      "grad_norm": 1.0158404111862183,
      "learning_rate": 1.1783132530120483e-05,
      "loss": 0.0639,
      "step": 68200
    },
    {
      "epoch": 8.218072289156627,
      "grad_norm": 5.978514671325684,
      "learning_rate": 1.1781927710843375e-05,
      "loss": 0.0736,
      "step": 68210
    },
    {
      "epoch": 8.219277108433735,
      "grad_norm": 3.985978364944458,
      "learning_rate": 1.1780722891566266e-05,
      "loss": 0.0322,
      "step": 68220
    },
    {
      "epoch": 8.220481927710843,
      "grad_norm": 0.10174762457609177,
      "learning_rate": 1.1779518072289158e-05,
      "loss": 0.0087,
      "step": 68230
    },
    {
      "epoch": 8.221686746987952,
      "grad_norm": 207.8151397705078,
      "learning_rate": 1.1778313253012047e-05,
      "loss": 0.0412,
      "step": 68240
    },
    {
      "epoch": 8.22289156626506,
      "grad_norm": 0.7380134463310242,
      "learning_rate": 1.177710843373494e-05,
      "loss": 0.0442,
      "step": 68250
    },
    {
      "epoch": 8.224096385542168,
      "grad_norm": 0.061576198786497116,
      "learning_rate": 1.1775903614457834e-05,
      "loss": 0.0255,
      "step": 68260
    },
    {
      "epoch": 8.225301204819278,
      "grad_norm": 0.771561324596405,
      "learning_rate": 1.1774698795180723e-05,
      "loss": 0.0173,
      "step": 68270
    },
    {
      "epoch": 8.226506024096386,
      "grad_norm": 1.3526127338409424,
      "learning_rate": 1.1773493975903615e-05,
      "loss": 0.0556,
      "step": 68280
    },
    {
      "epoch": 8.227710843373494,
      "grad_norm": 0.45575621724128723,
      "learning_rate": 1.1772289156626506e-05,
      "loss": 0.0412,
      "step": 68290
    },
    {
      "epoch": 8.228915662650602,
      "grad_norm": 2.021646738052368,
      "learning_rate": 1.1771084337349399e-05,
      "loss": 0.0472,
      "step": 68300
    },
    {
      "epoch": 8.230120481927711,
      "grad_norm": 0.40364870429039,
      "learning_rate": 1.176987951807229e-05,
      "loss": 0.0199,
      "step": 68310
    },
    {
      "epoch": 8.23132530120482,
      "grad_norm": 1.9723604917526245,
      "learning_rate": 1.1768674698795182e-05,
      "loss": 0.0398,
      "step": 68320
    },
    {
      "epoch": 8.232530120481927,
      "grad_norm": 0.04646223410964012,
      "learning_rate": 1.1767469879518074e-05,
      "loss": 0.0371,
      "step": 68330
    },
    {
      "epoch": 8.233734939759037,
      "grad_norm": 0.3393378257751465,
      "learning_rate": 1.1766265060240965e-05,
      "loss": 0.0314,
      "step": 68340
    },
    {
      "epoch": 8.234939759036145,
      "grad_norm": 14.172700881958008,
      "learning_rate": 1.1765060240963857e-05,
      "loss": 0.0846,
      "step": 68350
    },
    {
      "epoch": 8.236144578313253,
      "grad_norm": 2.3236145973205566,
      "learning_rate": 1.1763855421686748e-05,
      "loss": 0.0162,
      "step": 68360
    },
    {
      "epoch": 8.23734939759036,
      "grad_norm": 1.5749093294143677,
      "learning_rate": 1.176265060240964e-05,
      "loss": 0.0104,
      "step": 68370
    },
    {
      "epoch": 8.23855421686747,
      "grad_norm": 2.538738250732422,
      "learning_rate": 1.176144578313253e-05,
      "loss": 0.0196,
      "step": 68380
    },
    {
      "epoch": 8.239759036144578,
      "grad_norm": 0.003980052191764116,
      "learning_rate": 1.1760240963855422e-05,
      "loss": 0.0144,
      "step": 68390
    },
    {
      "epoch": 8.240963855421686,
      "grad_norm": 3.22697114944458,
      "learning_rate": 1.1759036144578315e-05,
      "loss": 0.0278,
      "step": 68400
    },
    {
      "epoch": 8.242168674698796,
      "grad_norm": 0.0495859831571579,
      "learning_rate": 1.1757831325301205e-05,
      "loss": 0.0314,
      "step": 68410
    },
    {
      "epoch": 8.243373493975904,
      "grad_norm": 1.111102819442749,
      "learning_rate": 1.1756626506024098e-05,
      "loss": 0.0401,
      "step": 68420
    },
    {
      "epoch": 8.244578313253012,
      "grad_norm": 1.3272069692611694,
      "learning_rate": 1.1755421686746988e-05,
      "loss": 0.0355,
      "step": 68430
    },
    {
      "epoch": 8.24578313253012,
      "grad_norm": 0.8231682181358337,
      "learning_rate": 1.1754216867469881e-05,
      "loss": 0.0388,
      "step": 68440
    },
    {
      "epoch": 8.24698795180723,
      "grad_norm": 0.0703798308968544,
      "learning_rate": 1.1753012048192772e-05,
      "loss": 0.0519,
      "step": 68450
    },
    {
      "epoch": 8.248192771084337,
      "grad_norm": 0.42856428027153015,
      "learning_rate": 1.1751807228915664e-05,
      "loss": 0.037,
      "step": 68460
    },
    {
      "epoch": 8.249397590361445,
      "grad_norm": 0.0033622407354414463,
      "learning_rate": 1.1750602409638556e-05,
      "loss": 0.0309,
      "step": 68470
    },
    {
      "epoch": 8.250602409638555,
      "grad_norm": 0.002887140028178692,
      "learning_rate": 1.1749397590361447e-05,
      "loss": 0.009,
      "step": 68480
    },
    {
      "epoch": 8.251807228915663,
      "grad_norm": 0.00095715670613572,
      "learning_rate": 1.174819277108434e-05,
      "loss": 0.0125,
      "step": 68490
    },
    {
      "epoch": 8.25301204819277,
      "grad_norm": 0.01110073085874319,
      "learning_rate": 1.1746987951807229e-05,
      "loss": 0.0387,
      "step": 68500
    },
    {
      "epoch": 8.25421686746988,
      "grad_norm": 0.03617048263549805,
      "learning_rate": 1.1745783132530121e-05,
      "loss": 0.0053,
      "step": 68510
    },
    {
      "epoch": 8.255421686746988,
      "grad_norm": 11.847960472106934,
      "learning_rate": 1.1744578313253012e-05,
      "loss": 0.0164,
      "step": 68520
    },
    {
      "epoch": 8.256626506024096,
      "grad_norm": 0.020513370633125305,
      "learning_rate": 1.1743373493975904e-05,
      "loss": 0.0086,
      "step": 68530
    },
    {
      "epoch": 8.257831325301204,
      "grad_norm": 4.571863651275635,
      "learning_rate": 1.1742168674698795e-05,
      "loss": 0.0405,
      "step": 68540
    },
    {
      "epoch": 8.259036144578314,
      "grad_norm": 0.0018563865451142192,
      "learning_rate": 1.1740963855421687e-05,
      "loss": 0.0556,
      "step": 68550
    },
    {
      "epoch": 8.260240963855422,
      "grad_norm": 0.014454326592385769,
      "learning_rate": 1.173975903614458e-05,
      "loss": 0.0065,
      "step": 68560
    },
    {
      "epoch": 8.26144578313253,
      "grad_norm": 0.9863781929016113,
      "learning_rate": 1.173855421686747e-05,
      "loss": 0.0305,
      "step": 68570
    },
    {
      "epoch": 8.26265060240964,
      "grad_norm": 0.09450877457857132,
      "learning_rate": 1.1737349397590363e-05,
      "loss": 0.0486,
      "step": 68580
    },
    {
      "epoch": 8.263855421686747,
      "grad_norm": 0.012923701666295528,
      "learning_rate": 1.1736144578313254e-05,
      "loss": 0.0292,
      "step": 68590
    },
    {
      "epoch": 8.265060240963855,
      "grad_norm": 0.008909950032830238,
      "learning_rate": 1.1734939759036146e-05,
      "loss": 0.0135,
      "step": 68600
    },
    {
      "epoch": 8.266265060240963,
      "grad_norm": 0.01424235850572586,
      "learning_rate": 1.1733734939759035e-05,
      "loss": 0.0019,
      "step": 68610
    },
    {
      "epoch": 8.267469879518073,
      "grad_norm": 0.004552055150270462,
      "learning_rate": 1.173253012048193e-05,
      "loss": 0.0703,
      "step": 68620
    },
    {
      "epoch": 8.26867469879518,
      "grad_norm": 0.4487634301185608,
      "learning_rate": 1.1731325301204822e-05,
      "loss": 0.0365,
      "step": 68630
    },
    {
      "epoch": 8.269879518072289,
      "grad_norm": 0.23739518225193024,
      "learning_rate": 1.1730120481927711e-05,
      "loss": 0.0219,
      "step": 68640
    },
    {
      "epoch": 8.271084337349398,
      "grad_norm": 4.883528232574463,
      "learning_rate": 1.1728915662650603e-05,
      "loss": 0.0171,
      "step": 68650
    },
    {
      "epoch": 8.272289156626506,
      "grad_norm": 0.40191444754600525,
      "learning_rate": 1.1727710843373494e-05,
      "loss": 0.0196,
      "step": 68660
    },
    {
      "epoch": 8.273493975903614,
      "grad_norm": 4.440547466278076,
      "learning_rate": 1.1726506024096387e-05,
      "loss": 0.0358,
      "step": 68670
    },
    {
      "epoch": 8.274698795180722,
      "grad_norm": 0.03680291771888733,
      "learning_rate": 1.1725301204819277e-05,
      "loss": 0.0226,
      "step": 68680
    },
    {
      "epoch": 8.275903614457832,
      "grad_norm": 0.005302815232425928,
      "learning_rate": 1.172409638554217e-05,
      "loss": 0.0387,
      "step": 68690
    },
    {
      "epoch": 8.27710843373494,
      "grad_norm": 0.05900706350803375,
      "learning_rate": 1.1722891566265062e-05,
      "loss": 0.0242,
      "step": 68700
    },
    {
      "epoch": 8.278313253012048,
      "grad_norm": 0.0036762745585292578,
      "learning_rate": 1.1721686746987953e-05,
      "loss": 0.044,
      "step": 68710
    },
    {
      "epoch": 8.279518072289157,
      "grad_norm": 0.010405382141470909,
      "learning_rate": 1.1720481927710845e-05,
      "loss": 0.0207,
      "step": 68720
    },
    {
      "epoch": 8.280722891566265,
      "grad_norm": 0.0075087943114340305,
      "learning_rate": 1.1719277108433736e-05,
      "loss": 0.0405,
      "step": 68730
    },
    {
      "epoch": 8.281927710843373,
      "grad_norm": 1.1173648834228516,
      "learning_rate": 1.1718072289156629e-05,
      "loss": 0.0233,
      "step": 68740
    },
    {
      "epoch": 8.283132530120483,
      "grad_norm": 0.09201672673225403,
      "learning_rate": 1.1716867469879518e-05,
      "loss": 0.0511,
      "step": 68750
    },
    {
      "epoch": 8.28433734939759,
      "grad_norm": 0.4509243965148926,
      "learning_rate": 1.171566265060241e-05,
      "loss": 0.0353,
      "step": 68760
    },
    {
      "epoch": 8.285542168674699,
      "grad_norm": 2.015033483505249,
      "learning_rate": 1.1714457831325302e-05,
      "loss": 0.0533,
      "step": 68770
    },
    {
      "epoch": 8.286746987951807,
      "grad_norm": 0.10415522754192352,
      "learning_rate": 1.1713253012048193e-05,
      "loss": 0.0322,
      "step": 68780
    },
    {
      "epoch": 8.287951807228916,
      "grad_norm": 1.5382472276687622,
      "learning_rate": 1.1712048192771086e-05,
      "loss": 0.0337,
      "step": 68790
    },
    {
      "epoch": 8.289156626506024,
      "grad_norm": 0.0719524547457695,
      "learning_rate": 1.1710843373493976e-05,
      "loss": 0.068,
      "step": 68800
    },
    {
      "epoch": 8.290361445783132,
      "grad_norm": 0.0023233562242239714,
      "learning_rate": 1.1709638554216869e-05,
      "loss": 0.0031,
      "step": 68810
    },
    {
      "epoch": 8.291566265060242,
      "grad_norm": 5.536072254180908,
      "learning_rate": 1.170843373493976e-05,
      "loss": 0.0121,
      "step": 68820
    },
    {
      "epoch": 8.29277108433735,
      "grad_norm": 0.005180625710636377,
      "learning_rate": 1.1707228915662652e-05,
      "loss": 0.0111,
      "step": 68830
    },
    {
      "epoch": 8.293975903614458,
      "grad_norm": 1.7533867359161377,
      "learning_rate": 1.1706024096385543e-05,
      "loss": 0.0488,
      "step": 68840
    },
    {
      "epoch": 8.295180722891565,
      "grad_norm": 11.34242057800293,
      "learning_rate": 1.1704819277108435e-05,
      "loss": 0.0599,
      "step": 68850
    },
    {
      "epoch": 8.296385542168675,
      "grad_norm": 0.005324061028659344,
      "learning_rate": 1.1703614457831328e-05,
      "loss": 0.0828,
      "step": 68860
    },
    {
      "epoch": 8.297590361445783,
      "grad_norm": 0.7765076160430908,
      "learning_rate": 1.1702409638554217e-05,
      "loss": 0.0177,
      "step": 68870
    },
    {
      "epoch": 8.298795180722891,
      "grad_norm": 0.31952986121177673,
      "learning_rate": 1.170120481927711e-05,
      "loss": 0.0244,
      "step": 68880
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.0681343749165535,
      "learning_rate": 1.17e-05,
      "loss": 0.0276,
      "step": 68890
    },
    {
      "epoch": 8.301204819277109,
      "grad_norm": 0.027506502345204353,
      "learning_rate": 1.1698795180722892e-05,
      "loss": 0.042,
      "step": 68900
    },
    {
      "epoch": 8.302409638554217,
      "grad_norm": 0.006182192824780941,
      "learning_rate": 1.1697590361445783e-05,
      "loss": 0.0253,
      "step": 68910
    },
    {
      "epoch": 8.303614457831324,
      "grad_norm": 1.3854502439498901,
      "learning_rate": 1.1696385542168675e-05,
      "loss": 0.0445,
      "step": 68920
    },
    {
      "epoch": 8.304819277108434,
      "grad_norm": 0.006672176998108625,
      "learning_rate": 1.1695180722891568e-05,
      "loss": 0.0114,
      "step": 68930
    },
    {
      "epoch": 8.306024096385542,
      "grad_norm": 0.04837649315595627,
      "learning_rate": 1.1693975903614459e-05,
      "loss": 0.0545,
      "step": 68940
    },
    {
      "epoch": 8.30722891566265,
      "grad_norm": 0.007726646959781647,
      "learning_rate": 1.1692771084337351e-05,
      "loss": 0.0182,
      "step": 68950
    },
    {
      "epoch": 8.30843373493976,
      "grad_norm": 0.2497517168521881,
      "learning_rate": 1.1691566265060242e-05,
      "loss": 0.0046,
      "step": 68960
    },
    {
      "epoch": 8.309638554216868,
      "grad_norm": 0.003132561920210719,
      "learning_rate": 1.1690361445783134e-05,
      "loss": 0.0091,
      "step": 68970
    },
    {
      "epoch": 8.310843373493976,
      "grad_norm": 6.128277778625488,
      "learning_rate": 1.1689156626506025e-05,
      "loss": 0.0454,
      "step": 68980
    },
    {
      "epoch": 8.312048192771085,
      "grad_norm": 0.08316376805305481,
      "learning_rate": 1.1687951807228917e-05,
      "loss": 0.0064,
      "step": 68990
    },
    {
      "epoch": 8.313253012048193,
      "grad_norm": 0.695809543132782,
      "learning_rate": 1.168674698795181e-05,
      "loss": 0.0839,
      "step": 69000
    },
    {
      "epoch": 8.314457831325301,
      "grad_norm": 0.0072293151170015335,
      "learning_rate": 1.1685542168674699e-05,
      "loss": 0.0266,
      "step": 69010
    },
    {
      "epoch": 8.315662650602409,
      "grad_norm": 0.003516589291393757,
      "learning_rate": 1.1684337349397591e-05,
      "loss": 0.0075,
      "step": 69020
    },
    {
      "epoch": 8.316867469879519,
      "grad_norm": 0.013301179744303226,
      "learning_rate": 1.1683132530120482e-05,
      "loss": 0.0292,
      "step": 69030
    },
    {
      "epoch": 8.318072289156627,
      "grad_norm": 0.003542375285178423,
      "learning_rate": 1.1681927710843374e-05,
      "loss": 0.0202,
      "step": 69040
    },
    {
      "epoch": 8.319277108433734,
      "grad_norm": 0.004596234764903784,
      "learning_rate": 1.1680722891566265e-05,
      "loss": 0.0221,
      "step": 69050
    },
    {
      "epoch": 8.320481927710844,
      "grad_norm": 0.1541326493024826,
      "learning_rate": 1.1679518072289158e-05,
      "loss": 0.0307,
      "step": 69060
    },
    {
      "epoch": 8.321686746987952,
      "grad_norm": 1.570971965789795,
      "learning_rate": 1.167831325301205e-05,
      "loss": 0.0723,
      "step": 69070
    },
    {
      "epoch": 8.32289156626506,
      "grad_norm": 0.21853883564472198,
      "learning_rate": 1.167710843373494e-05,
      "loss": 0.0437,
      "step": 69080
    },
    {
      "epoch": 8.324096385542168,
      "grad_norm": 0.9891891479492188,
      "learning_rate": 1.1675903614457833e-05,
      "loss": 0.0113,
      "step": 69090
    },
    {
      "epoch": 8.325301204819278,
      "grad_norm": 0.05488446727395058,
      "learning_rate": 1.1674698795180724e-05,
      "loss": 0.0055,
      "step": 69100
    },
    {
      "epoch": 8.326506024096386,
      "grad_norm": 0.1159968301653862,
      "learning_rate": 1.1673493975903616e-05,
      "loss": 0.0481,
      "step": 69110
    },
    {
      "epoch": 8.327710843373493,
      "grad_norm": 1.3092421293258667,
      "learning_rate": 1.1672289156626505e-05,
      "loss": 0.0602,
      "step": 69120
    },
    {
      "epoch": 8.328915662650603,
      "grad_norm": 0.03935929015278816,
      "learning_rate": 1.1671084337349398e-05,
      "loss": 0.0116,
      "step": 69130
    },
    {
      "epoch": 8.330120481927711,
      "grad_norm": 1.2406104803085327,
      "learning_rate": 1.1669879518072289e-05,
      "loss": 0.0123,
      "step": 69140
    },
    {
      "epoch": 8.331325301204819,
      "grad_norm": 0.09227253496646881,
      "learning_rate": 1.1668674698795181e-05,
      "loss": 0.0145,
      "step": 69150
    },
    {
      "epoch": 8.332530120481927,
      "grad_norm": 0.055957525968551636,
      "learning_rate": 1.1667469879518074e-05,
      "loss": 0.0465,
      "step": 69160
    },
    {
      "epoch": 8.333734939759037,
      "grad_norm": 0.13516853749752045,
      "learning_rate": 1.1666265060240964e-05,
      "loss": 0.0118,
      "step": 69170
    },
    {
      "epoch": 8.334939759036144,
      "grad_norm": 0.004272830206900835,
      "learning_rate": 1.1665060240963857e-05,
      "loss": 0.0077,
      "step": 69180
    },
    {
      "epoch": 8.336144578313252,
      "grad_norm": 0.02681651897728443,
      "learning_rate": 1.1663855421686747e-05,
      "loss": 0.0016,
      "step": 69190
    },
    {
      "epoch": 8.337349397590362,
      "grad_norm": 0.7466697096824646,
      "learning_rate": 1.166265060240964e-05,
      "loss": 0.0576,
      "step": 69200
    },
    {
      "epoch": 8.33855421686747,
      "grad_norm": 0.004349720198661089,
      "learning_rate": 1.166144578313253e-05,
      "loss": 0.0207,
      "step": 69210
    },
    {
      "epoch": 8.339759036144578,
      "grad_norm": 1.0572197437286377,
      "learning_rate": 1.1660240963855423e-05,
      "loss": 0.0225,
      "step": 69220
    },
    {
      "epoch": 8.340963855421688,
      "grad_norm": 0.0528704971075058,
      "learning_rate": 1.1659036144578315e-05,
      "loss": 0.0692,
      "step": 69230
    },
    {
      "epoch": 8.342168674698796,
      "grad_norm": 0.010158861987292767,
      "learning_rate": 1.1657831325301206e-05,
      "loss": 0.0445,
      "step": 69240
    },
    {
      "epoch": 8.343373493975903,
      "grad_norm": 0.652485191822052,
      "learning_rate": 1.1656626506024099e-05,
      "loss": 0.0253,
      "step": 69250
    },
    {
      "epoch": 8.344578313253011,
      "grad_norm": 0.02394811622798443,
      "learning_rate": 1.1655421686746988e-05,
      "loss": 0.0255,
      "step": 69260
    },
    {
      "epoch": 8.345783132530121,
      "grad_norm": 1.7060222625732422,
      "learning_rate": 1.165421686746988e-05,
      "loss": 0.0261,
      "step": 69270
    },
    {
      "epoch": 8.346987951807229,
      "grad_norm": 0.007041731849312782,
      "learning_rate": 1.1653012048192771e-05,
      "loss": 0.0253,
      "step": 69280
    },
    {
      "epoch": 8.348192771084337,
      "grad_norm": 0.029596863314509392,
      "learning_rate": 1.1651807228915663e-05,
      "loss": 0.0155,
      "step": 69290
    },
    {
      "epoch": 8.349397590361447,
      "grad_norm": 1.3082540035247803,
      "learning_rate": 1.1650602409638556e-05,
      "loss": 0.0198,
      "step": 69300
    },
    {
      "epoch": 8.350602409638554,
      "grad_norm": 0.002989170141518116,
      "learning_rate": 1.1649397590361446e-05,
      "loss": 0.0187,
      "step": 69310
    },
    {
      "epoch": 8.351807228915662,
      "grad_norm": 1.1200518608093262,
      "learning_rate": 1.1648192771084339e-05,
      "loss": 0.0331,
      "step": 69320
    },
    {
      "epoch": 8.35301204819277,
      "grad_norm": 0.2161894142627716,
      "learning_rate": 1.164698795180723e-05,
      "loss": 0.0206,
      "step": 69330
    },
    {
      "epoch": 8.35421686746988,
      "grad_norm": 1.3708181381225586,
      "learning_rate": 1.1645783132530122e-05,
      "loss": 0.0163,
      "step": 69340
    },
    {
      "epoch": 8.355421686746988,
      "grad_norm": 0.029000235721468925,
      "learning_rate": 1.1644578313253013e-05,
      "loss": 0.06,
      "step": 69350
    },
    {
      "epoch": 8.356626506024096,
      "grad_norm": 0.3101564645767212,
      "learning_rate": 1.1643373493975905e-05,
      "loss": 0.0349,
      "step": 69360
    },
    {
      "epoch": 8.357831325301206,
      "grad_norm": 0.02204855903983116,
      "learning_rate": 1.1642168674698798e-05,
      "loss": 0.0093,
      "step": 69370
    },
    {
      "epoch": 8.359036144578313,
      "grad_norm": 0.14534175395965576,
      "learning_rate": 1.1640963855421687e-05,
      "loss": 0.0134,
      "step": 69380
    },
    {
      "epoch": 8.360240963855421,
      "grad_norm": 0.0047927359119057655,
      "learning_rate": 1.163975903614458e-05,
      "loss": 0.0039,
      "step": 69390
    },
    {
      "epoch": 8.36144578313253,
      "grad_norm": 0.0017263242043554783,
      "learning_rate": 1.163855421686747e-05,
      "loss": 0.0423,
      "step": 69400
    },
    {
      "epoch": 8.362650602409639,
      "grad_norm": 0.02500215731561184,
      "learning_rate": 1.1637349397590362e-05,
      "loss": 0.0515,
      "step": 69410
    },
    {
      "epoch": 8.363855421686747,
      "grad_norm": 0.001528242602944374,
      "learning_rate": 1.1636144578313253e-05,
      "loss": 0.0002,
      "step": 69420
    },
    {
      "epoch": 8.365060240963855,
      "grad_norm": 1.634265422821045,
      "learning_rate": 1.1634939759036146e-05,
      "loss": 0.0125,
      "step": 69430
    },
    {
      "epoch": 8.366265060240965,
      "grad_norm": 0.4851531386375427,
      "learning_rate": 1.1633734939759036e-05,
      "loss": 0.0219,
      "step": 69440
    },
    {
      "epoch": 8.367469879518072,
      "grad_norm": 0.003947235178202391,
      "learning_rate": 1.1632530120481929e-05,
      "loss": 0.0156,
      "step": 69450
    },
    {
      "epoch": 8.36867469879518,
      "grad_norm": 0.6218518018722534,
      "learning_rate": 1.1631325301204821e-05,
      "loss": 0.0079,
      "step": 69460
    },
    {
      "epoch": 8.369879518072288,
      "grad_norm": 0.0021940036676824093,
      "learning_rate": 1.1630120481927712e-05,
      "loss": 0.1063,
      "step": 69470
    },
    {
      "epoch": 8.371084337349398,
      "grad_norm": 0.003057233989238739,
      "learning_rate": 1.1628915662650604e-05,
      "loss": 0.063,
      "step": 69480
    },
    {
      "epoch": 8.372289156626506,
      "grad_norm": 0.008868299424648285,
      "learning_rate": 1.1627710843373493e-05,
      "loss": 0.049,
      "step": 69490
    },
    {
      "epoch": 8.373493975903614,
      "grad_norm": 0.019946837797760963,
      "learning_rate": 1.1626506024096388e-05,
      "loss": 0.0175,
      "step": 69500
    },
    {
      "epoch": 8.374698795180723,
      "grad_norm": 0.007247959263622761,
      "learning_rate": 1.1625301204819277e-05,
      "loss": 0.035,
      "step": 69510
    },
    {
      "epoch": 8.375903614457831,
      "grad_norm": 3.1816112995147705,
      "learning_rate": 1.1624096385542169e-05,
      "loss": 0.0431,
      "step": 69520
    },
    {
      "epoch": 8.37710843373494,
      "grad_norm": 0.01652953401207924,
      "learning_rate": 1.1622891566265061e-05,
      "loss": 0.0197,
      "step": 69530
    },
    {
      "epoch": 8.378313253012049,
      "grad_norm": 0.7784609198570251,
      "learning_rate": 1.1621686746987952e-05,
      "loss": 0.0263,
      "step": 69540
    },
    {
      "epoch": 8.379518072289157,
      "grad_norm": 0.0036998370196670294,
      "learning_rate": 1.1620481927710845e-05,
      "loss": 0.0036,
      "step": 69550
    },
    {
      "epoch": 8.380722891566265,
      "grad_norm": 4.852262496948242,
      "learning_rate": 1.1619277108433735e-05,
      "loss": 0.0497,
      "step": 69560
    },
    {
      "epoch": 8.381927710843373,
      "grad_norm": 0.5578179955482483,
      "learning_rate": 1.1618072289156628e-05,
      "loss": 0.0221,
      "step": 69570
    },
    {
      "epoch": 8.383132530120482,
      "grad_norm": 0.31557199358940125,
      "learning_rate": 1.1616867469879519e-05,
      "loss": 0.0204,
      "step": 69580
    },
    {
      "epoch": 8.38433734939759,
      "grad_norm": 0.3459087908267975,
      "learning_rate": 1.1615662650602411e-05,
      "loss": 0.0448,
      "step": 69590
    },
    {
      "epoch": 8.385542168674698,
      "grad_norm": 6.178816318511963,
      "learning_rate": 1.1614457831325303e-05,
      "loss": 0.0274,
      "step": 69600
    },
    {
      "epoch": 8.386746987951808,
      "grad_norm": 0.0992114394903183,
      "learning_rate": 1.1613253012048194e-05,
      "loss": 0.0403,
      "step": 69610
    },
    {
      "epoch": 8.387951807228916,
      "grad_norm": 2.957890748977661,
      "learning_rate": 1.1612048192771087e-05,
      "loss": 0.059,
      "step": 69620
    },
    {
      "epoch": 8.389156626506024,
      "grad_norm": 3.43768572807312,
      "learning_rate": 1.1610843373493976e-05,
      "loss": 0.0321,
      "step": 69630
    },
    {
      "epoch": 8.390361445783132,
      "grad_norm": 0.07331816107034683,
      "learning_rate": 1.1609638554216868e-05,
      "loss": 0.0212,
      "step": 69640
    },
    {
      "epoch": 8.391566265060241,
      "grad_norm": 0.4174543619155884,
      "learning_rate": 1.1608433734939759e-05,
      "loss": 0.0145,
      "step": 69650
    },
    {
      "epoch": 8.39277108433735,
      "grad_norm": 0.002858651801943779,
      "learning_rate": 1.1607228915662651e-05,
      "loss": 0.0378,
      "step": 69660
    },
    {
      "epoch": 8.393975903614457,
      "grad_norm": 0.147843137383461,
      "learning_rate": 1.1606024096385544e-05,
      "loss": 0.0064,
      "step": 69670
    },
    {
      "epoch": 8.395180722891567,
      "grad_norm": 0.11976342648267746,
      "learning_rate": 1.1604819277108434e-05,
      "loss": 0.0307,
      "step": 69680
    },
    {
      "epoch": 8.396385542168675,
      "grad_norm": 0.2634778618812561,
      "learning_rate": 1.1603614457831327e-05,
      "loss": 0.0071,
      "step": 69690
    },
    {
      "epoch": 8.397590361445783,
      "grad_norm": 6.418639183044434,
      "learning_rate": 1.1602409638554218e-05,
      "loss": 0.0553,
      "step": 69700
    },
    {
      "epoch": 8.398795180722892,
      "grad_norm": 0.005656038876622915,
      "learning_rate": 1.160120481927711e-05,
      "loss": 0.0155,
      "step": 69710
    },
    {
      "epoch": 8.4,
      "grad_norm": 6.291464328765869,
      "learning_rate": 1.16e-05,
      "loss": 0.0223,
      "step": 69720
    },
    {
      "epoch": 8.401204819277108,
      "grad_norm": 0.007720937952399254,
      "learning_rate": 1.1598795180722893e-05,
      "loss": 0.0197,
      "step": 69730
    },
    {
      "epoch": 8.402409638554216,
      "grad_norm": 0.8653767108917236,
      "learning_rate": 1.1597590361445782e-05,
      "loss": 0.0303,
      "step": 69740
    },
    {
      "epoch": 8.403614457831326,
      "grad_norm": 0.016154028475284576,
      "learning_rate": 1.1596385542168676e-05,
      "loss": 0.0203,
      "step": 69750
    },
    {
      "epoch": 8.404819277108434,
      "grad_norm": 3.630551815032959,
      "learning_rate": 1.1595180722891569e-05,
      "loss": 0.0664,
      "step": 69760
    },
    {
      "epoch": 8.406024096385542,
      "grad_norm": 0.032387349754571915,
      "learning_rate": 1.1593975903614458e-05,
      "loss": 0.0508,
      "step": 69770
    },
    {
      "epoch": 8.407228915662651,
      "grad_norm": 3.7558882236480713,
      "learning_rate": 1.159277108433735e-05,
      "loss": 0.0159,
      "step": 69780
    },
    {
      "epoch": 8.40843373493976,
      "grad_norm": 0.1245102807879448,
      "learning_rate": 1.1591566265060241e-05,
      "loss": 0.0209,
      "step": 69790
    },
    {
      "epoch": 8.409638554216867,
      "grad_norm": 0.05158943682909012,
      "learning_rate": 1.1590361445783133e-05,
      "loss": 0.0244,
      "step": 69800
    },
    {
      "epoch": 8.410843373493975,
      "grad_norm": 1.8537918329238892,
      "learning_rate": 1.1589156626506024e-05,
      "loss": 0.0275,
      "step": 69810
    },
    {
      "epoch": 8.412048192771085,
      "grad_norm": 1.4873144626617432,
      "learning_rate": 1.1587951807228917e-05,
      "loss": 0.0431,
      "step": 69820
    },
    {
      "epoch": 8.413253012048193,
      "grad_norm": 0.010288846679031849,
      "learning_rate": 1.1586746987951809e-05,
      "loss": 0.0296,
      "step": 69830
    },
    {
      "epoch": 8.4144578313253,
      "grad_norm": 0.08761124312877655,
      "learning_rate": 1.15855421686747e-05,
      "loss": 0.0158,
      "step": 69840
    },
    {
      "epoch": 8.41566265060241,
      "grad_norm": 0.8012869954109192,
      "learning_rate": 1.1584337349397592e-05,
      "loss": 0.0376,
      "step": 69850
    },
    {
      "epoch": 8.416867469879518,
      "grad_norm": 4.64827299118042,
      "learning_rate": 1.1583132530120483e-05,
      "loss": 0.0476,
      "step": 69860
    },
    {
      "epoch": 8.418072289156626,
      "grad_norm": 0.002518757712095976,
      "learning_rate": 1.1581927710843375e-05,
      "loss": 0.0315,
      "step": 69870
    },
    {
      "epoch": 8.419277108433734,
      "grad_norm": 0.0075958166271448135,
      "learning_rate": 1.1580722891566264e-05,
      "loss": 0.0104,
      "step": 69880
    },
    {
      "epoch": 8.420481927710844,
      "grad_norm": 0.002671566791832447,
      "learning_rate": 1.1579518072289157e-05,
      "loss": 0.0403,
      "step": 69890
    },
    {
      "epoch": 8.421686746987952,
      "grad_norm": 0.021114768460392952,
      "learning_rate": 1.157831325301205e-05,
      "loss": 0.0083,
      "step": 69900
    },
    {
      "epoch": 8.42289156626506,
      "grad_norm": 0.04458564892411232,
      "learning_rate": 1.157710843373494e-05,
      "loss": 0.0408,
      "step": 69910
    },
    {
      "epoch": 8.42409638554217,
      "grad_norm": 0.7623799443244934,
      "learning_rate": 1.1575903614457833e-05,
      "loss": 0.016,
      "step": 69920
    },
    {
      "epoch": 8.425301204819277,
      "grad_norm": 0.09361688792705536,
      "learning_rate": 1.1574698795180723e-05,
      "loss": 0.0402,
      "step": 69930
    },
    {
      "epoch": 8.426506024096385,
      "grad_norm": 0.03737827390432358,
      "learning_rate": 1.1573493975903616e-05,
      "loss": 0.0093,
      "step": 69940
    },
    {
      "epoch": 8.427710843373493,
      "grad_norm": 0.5448396801948547,
      "learning_rate": 1.1572289156626506e-05,
      "loss": 0.0361,
      "step": 69950
    },
    {
      "epoch": 8.428915662650603,
      "grad_norm": 12.420360565185547,
      "learning_rate": 1.1571084337349399e-05,
      "loss": 0.0456,
      "step": 69960
    },
    {
      "epoch": 8.43012048192771,
      "grad_norm": 6.801479816436768,
      "learning_rate": 1.1569879518072291e-05,
      "loss": 0.0139,
      "step": 69970
    },
    {
      "epoch": 8.431325301204819,
      "grad_norm": 77.58354949951172,
      "learning_rate": 1.1568674698795182e-05,
      "loss": 0.0078,
      "step": 69980
    },
    {
      "epoch": 8.432530120481928,
      "grad_norm": 7.4544477462768555,
      "learning_rate": 1.1567469879518074e-05,
      "loss": 0.0424,
      "step": 69990
    },
    {
      "epoch": 8.433734939759036,
      "grad_norm": 3.630126714706421,
      "learning_rate": 1.1566265060240964e-05,
      "loss": 0.0175,
      "step": 70000
    },
    {
      "epoch": 8.434939759036144,
      "grad_norm": 4.615455627441406,
      "learning_rate": 1.1565060240963858e-05,
      "loss": 0.0486,
      "step": 70010
    },
    {
      "epoch": 8.436144578313254,
      "grad_norm": 8.718018531799316,
      "learning_rate": 1.1563855421686747e-05,
      "loss": 0.0463,
      "step": 70020
    },
    {
      "epoch": 8.437349397590362,
      "grad_norm": 0.025270801037549973,
      "learning_rate": 1.1562650602409639e-05,
      "loss": 0.0209,
      "step": 70030
    },
    {
      "epoch": 8.43855421686747,
      "grad_norm": 18.730133056640625,
      "learning_rate": 1.156144578313253e-05,
      "loss": 0.0797,
      "step": 70040
    },
    {
      "epoch": 8.439759036144578,
      "grad_norm": 0.042355284094810486,
      "learning_rate": 1.1560240963855422e-05,
      "loss": 0.0413,
      "step": 70050
    },
    {
      "epoch": 8.440963855421687,
      "grad_norm": 0.18661150336265564,
      "learning_rate": 1.1559036144578315e-05,
      "loss": 0.0485,
      "step": 70060
    },
    {
      "epoch": 8.442168674698795,
      "grad_norm": 20.807361602783203,
      "learning_rate": 1.1557831325301205e-05,
      "loss": 0.0292,
      "step": 70070
    },
    {
      "epoch": 8.443373493975903,
      "grad_norm": 6.639698505401611,
      "learning_rate": 1.1556626506024098e-05,
      "loss": 0.0422,
      "step": 70080
    },
    {
      "epoch": 8.444578313253013,
      "grad_norm": 0.6782058477401733,
      "learning_rate": 1.1555421686746989e-05,
      "loss": 0.0182,
      "step": 70090
    },
    {
      "epoch": 8.44578313253012,
      "grad_norm": 5.326298713684082,
      "learning_rate": 1.1554216867469881e-05,
      "loss": 0.0271,
      "step": 70100
    },
    {
      "epoch": 8.446987951807229,
      "grad_norm": 0.5035808682441711,
      "learning_rate": 1.1553012048192772e-05,
      "loss": 0.0283,
      "step": 70110
    },
    {
      "epoch": 8.448192771084337,
      "grad_norm": 0.6999939680099487,
      "learning_rate": 1.1551807228915664e-05,
      "loss": 0.0055,
      "step": 70120
    },
    {
      "epoch": 8.449397590361446,
      "grad_norm": 0.19564171135425568,
      "learning_rate": 1.1550602409638557e-05,
      "loss": 0.0142,
      "step": 70130
    },
    {
      "epoch": 8.450602409638554,
      "grad_norm": 0.005850815214216709,
      "learning_rate": 1.1549397590361446e-05,
      "loss": 0.009,
      "step": 70140
    },
    {
      "epoch": 8.451807228915662,
      "grad_norm": 4.000382423400879,
      "learning_rate": 1.1548192771084338e-05,
      "loss": 0.0588,
      "step": 70150
    },
    {
      "epoch": 8.453012048192772,
      "grad_norm": 0.01948096603155136,
      "learning_rate": 1.1546987951807229e-05,
      "loss": 0.0142,
      "step": 70160
    },
    {
      "epoch": 8.45421686746988,
      "grad_norm": 5.996795654296875,
      "learning_rate": 1.1545783132530121e-05,
      "loss": 0.05,
      "step": 70170
    },
    {
      "epoch": 8.455421686746988,
      "grad_norm": 0.20702658593654633,
      "learning_rate": 1.1544578313253012e-05,
      "loss": 0.0173,
      "step": 70180
    },
    {
      "epoch": 8.456626506024097,
      "grad_norm": 0.009168879128992558,
      "learning_rate": 1.1543373493975905e-05,
      "loss": 0.0074,
      "step": 70190
    },
    {
      "epoch": 8.457831325301205,
      "grad_norm": 4.339284896850586,
      "learning_rate": 1.1542168674698797e-05,
      "loss": 0.0396,
      "step": 70200
    },
    {
      "epoch": 8.459036144578313,
      "grad_norm": 0.08097605407238007,
      "learning_rate": 1.1540963855421688e-05,
      "loss": 0.0609,
      "step": 70210
    },
    {
      "epoch": 8.460240963855421,
      "grad_norm": 0.058174822479486465,
      "learning_rate": 1.153975903614458e-05,
      "loss": 0.0136,
      "step": 70220
    },
    {
      "epoch": 8.46144578313253,
      "grad_norm": 0.3070904314517975,
      "learning_rate": 1.1538554216867471e-05,
      "loss": 0.0229,
      "step": 70230
    },
    {
      "epoch": 8.462650602409639,
      "grad_norm": 0.17523589730262756,
      "learning_rate": 1.1537349397590363e-05,
      "loss": 0.0047,
      "step": 70240
    },
    {
      "epoch": 8.463855421686747,
      "grad_norm": 0.7676347494125366,
      "learning_rate": 1.1536144578313252e-05,
      "loss": 0.0146,
      "step": 70250
    },
    {
      "epoch": 8.465060240963856,
      "grad_norm": 0.001676736050285399,
      "learning_rate": 1.1534939759036145e-05,
      "loss": 0.0229,
      "step": 70260
    },
    {
      "epoch": 8.466265060240964,
      "grad_norm": 0.001625279663130641,
      "learning_rate": 1.1533734939759039e-05,
      "loss": 0.0011,
      "step": 70270
    },
    {
      "epoch": 8.467469879518072,
      "grad_norm": 0.02035232074558735,
      "learning_rate": 1.1532530120481928e-05,
      "loss": 0.0108,
      "step": 70280
    },
    {
      "epoch": 8.46867469879518,
      "grad_norm": 1.2828433513641357,
      "learning_rate": 1.153132530120482e-05,
      "loss": 0.0217,
      "step": 70290
    },
    {
      "epoch": 8.46987951807229,
      "grad_norm": 0.6512530446052551,
      "learning_rate": 1.1530120481927711e-05,
      "loss": 0.0337,
      "step": 70300
    },
    {
      "epoch": 8.471084337349398,
      "grad_norm": 0.5848375558853149,
      "learning_rate": 1.1528915662650604e-05,
      "loss": 0.0168,
      "step": 70310
    },
    {
      "epoch": 8.472289156626506,
      "grad_norm": 1.6439733505249023,
      "learning_rate": 1.1527710843373494e-05,
      "loss": 0.0649,
      "step": 70320
    },
    {
      "epoch": 8.473493975903615,
      "grad_norm": 0.08057957142591476,
      "learning_rate": 1.1526506024096387e-05,
      "loss": 0.0054,
      "step": 70330
    },
    {
      "epoch": 8.474698795180723,
      "grad_norm": 0.001166781410574913,
      "learning_rate": 1.1525301204819278e-05,
      "loss": 0.0199,
      "step": 70340
    },
    {
      "epoch": 8.475903614457831,
      "grad_norm": 3.242511749267578,
      "learning_rate": 1.152409638554217e-05,
      "loss": 0.0716,
      "step": 70350
    },
    {
      "epoch": 8.477108433734939,
      "grad_norm": 1.330033302307129,
      "learning_rate": 1.1522891566265062e-05,
      "loss": 0.0148,
      "step": 70360
    },
    {
      "epoch": 8.478313253012049,
      "grad_norm": 0.009135915897786617,
      "learning_rate": 1.1521686746987953e-05,
      "loss": 0.0378,
      "step": 70370
    },
    {
      "epoch": 8.479518072289157,
      "grad_norm": 1.6113969087600708,
      "learning_rate": 1.1520481927710846e-05,
      "loss": 0.0542,
      "step": 70380
    },
    {
      "epoch": 8.480722891566264,
      "grad_norm": 0.0036366276908665895,
      "learning_rate": 1.1519277108433735e-05,
      "loss": 0.028,
      "step": 70390
    },
    {
      "epoch": 8.481927710843374,
      "grad_norm": 0.004927622154355049,
      "learning_rate": 1.1518072289156627e-05,
      "loss": 0.0136,
      "step": 70400
    },
    {
      "epoch": 8.483132530120482,
      "grad_norm": 6.936905860900879,
      "learning_rate": 1.1516867469879518e-05,
      "loss": 0.0237,
      "step": 70410
    },
    {
      "epoch": 8.48433734939759,
      "grad_norm": 1.5599364042282104,
      "learning_rate": 1.151566265060241e-05,
      "loss": 0.0356,
      "step": 70420
    },
    {
      "epoch": 8.485542168674698,
      "grad_norm": 0.6359187960624695,
      "learning_rate": 1.1514457831325303e-05,
      "loss": 0.0412,
      "step": 70430
    },
    {
      "epoch": 8.486746987951808,
      "grad_norm": 0.9724015593528748,
      "learning_rate": 1.1513253012048193e-05,
      "loss": 0.0216,
      "step": 70440
    },
    {
      "epoch": 8.487951807228916,
      "grad_norm": 2.0715863704681396,
      "learning_rate": 1.1512048192771086e-05,
      "loss": 0.0916,
      "step": 70450
    },
    {
      "epoch": 8.489156626506023,
      "grad_norm": 1.2759793996810913,
      "learning_rate": 1.1510843373493977e-05,
      "loss": 0.0367,
      "step": 70460
    },
    {
      "epoch": 8.490361445783133,
      "grad_norm": 2.7873873710632324,
      "learning_rate": 1.1509638554216869e-05,
      "loss": 0.0305,
      "step": 70470
    },
    {
      "epoch": 8.491566265060241,
      "grad_norm": 0.1797645390033722,
      "learning_rate": 1.150843373493976e-05,
      "loss": 0.0476,
      "step": 70480
    },
    {
      "epoch": 8.492771084337349,
      "grad_norm": 0.0061499932780861855,
      "learning_rate": 1.1507228915662652e-05,
      "loss": 0.0092,
      "step": 70490
    },
    {
      "epoch": 8.493975903614459,
      "grad_norm": 5.8090128898620605,
      "learning_rate": 1.1506024096385545e-05,
      "loss": 0.044,
      "step": 70500
    },
    {
      "epoch": 8.495180722891567,
      "grad_norm": 0.008573975414037704,
      "learning_rate": 1.1504819277108434e-05,
      "loss": 0.0455,
      "step": 70510
    },
    {
      "epoch": 8.496385542168674,
      "grad_norm": 0.9548667073249817,
      "learning_rate": 1.1503614457831326e-05,
      "loss": 0.0118,
      "step": 70520
    },
    {
      "epoch": 8.497590361445782,
      "grad_norm": 0.9182428121566772,
      "learning_rate": 1.1502409638554217e-05,
      "loss": 0.0247,
      "step": 70530
    },
    {
      "epoch": 8.498795180722892,
      "grad_norm": 0.017599906772375107,
      "learning_rate": 1.150120481927711e-05,
      "loss": 0.0087,
      "step": 70540
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.0022614493500441313,
      "learning_rate": 1.15e-05,
      "loss": 0.0016,
      "step": 70550
    },
    {
      "epoch": 8.501204819277108,
      "grad_norm": 0.8562279939651489,
      "learning_rate": 1.1498795180722892e-05,
      "loss": 0.0321,
      "step": 70560
    },
    {
      "epoch": 8.502409638554218,
      "grad_norm": 0.37846580147743225,
      "learning_rate": 1.1497590361445785e-05,
      "loss": 0.0514,
      "step": 70570
    },
    {
      "epoch": 8.503614457831326,
      "grad_norm": 1.369986891746521,
      "learning_rate": 1.1496385542168676e-05,
      "loss": 0.051,
      "step": 70580
    },
    {
      "epoch": 8.504819277108433,
      "grad_norm": 0.01724810153245926,
      "learning_rate": 1.1495180722891568e-05,
      "loss": 0.0029,
      "step": 70590
    },
    {
      "epoch": 8.506024096385541,
      "grad_norm": 0.0021996675059199333,
      "learning_rate": 1.1493975903614459e-05,
      "loss": 0.0635,
      "step": 70600
    },
    {
      "epoch": 8.507228915662651,
      "grad_norm": 0.006000948138535023,
      "learning_rate": 1.1492771084337351e-05,
      "loss": 0.0178,
      "step": 70610
    },
    {
      "epoch": 8.508433734939759,
      "grad_norm": 0.17139340937137604,
      "learning_rate": 1.149156626506024e-05,
      "loss": 0.0063,
      "step": 70620
    },
    {
      "epoch": 8.509638554216867,
      "grad_norm": 0.6430929899215698,
      "learning_rate": 1.1490361445783134e-05,
      "loss": 0.0942,
      "step": 70630
    },
    {
      "epoch": 8.510843373493977,
      "grad_norm": 0.20953798294067383,
      "learning_rate": 1.1489156626506027e-05,
      "loss": 0.0313,
      "step": 70640
    },
    {
      "epoch": 8.512048192771084,
      "grad_norm": 0.317787230014801,
      "learning_rate": 1.1487951807228916e-05,
      "loss": 0.038,
      "step": 70650
    },
    {
      "epoch": 8.513253012048192,
      "grad_norm": 0.14922361075878143,
      "learning_rate": 1.1486746987951808e-05,
      "loss": 0.0193,
      "step": 70660
    },
    {
      "epoch": 8.514457831325302,
      "grad_norm": 0.038119811564683914,
      "learning_rate": 1.1485542168674699e-05,
      "loss": 0.0421,
      "step": 70670
    },
    {
      "epoch": 8.51566265060241,
      "grad_norm": 2.9654946327209473,
      "learning_rate": 1.1484337349397592e-05,
      "loss": 0.0153,
      "step": 70680
    },
    {
      "epoch": 8.516867469879518,
      "grad_norm": 0.07183316349983215,
      "learning_rate": 1.1483132530120482e-05,
      "loss": 0.0524,
      "step": 70690
    },
    {
      "epoch": 8.518072289156626,
      "grad_norm": 0.06788218021392822,
      "learning_rate": 1.1481927710843375e-05,
      "loss": 0.0268,
      "step": 70700
    },
    {
      "epoch": 8.519277108433736,
      "grad_norm": 0.005883217789232731,
      "learning_rate": 1.1480722891566265e-05,
      "loss": 0.0246,
      "step": 70710
    },
    {
      "epoch": 8.520481927710843,
      "grad_norm": 0.04064080864191055,
      "learning_rate": 1.1479518072289158e-05,
      "loss": 0.0499,
      "step": 70720
    },
    {
      "epoch": 8.521686746987951,
      "grad_norm": 0.13206328451633453,
      "learning_rate": 1.147831325301205e-05,
      "loss": 0.0055,
      "step": 70730
    },
    {
      "epoch": 8.522891566265061,
      "grad_norm": 0.04619145765900612,
      "learning_rate": 1.1477108433734941e-05,
      "loss": 0.0159,
      "step": 70740
    },
    {
      "epoch": 8.524096385542169,
      "grad_norm": 0.0021370614413172007,
      "learning_rate": 1.1475903614457833e-05,
      "loss": 0.0381,
      "step": 70750
    },
    {
      "epoch": 8.525301204819277,
      "grad_norm": 1.1109962463378906,
      "learning_rate": 1.1474698795180723e-05,
      "loss": 0.0357,
      "step": 70760
    },
    {
      "epoch": 8.526506024096385,
      "grad_norm": 0.11482121795415878,
      "learning_rate": 1.1473493975903615e-05,
      "loss": 0.0277,
      "step": 70770
    },
    {
      "epoch": 8.527710843373494,
      "grad_norm": 0.10455776751041412,
      "learning_rate": 1.1472289156626506e-05,
      "loss": 0.0466,
      "step": 70780
    },
    {
      "epoch": 8.528915662650602,
      "grad_norm": 0.07867125421762466,
      "learning_rate": 1.1471084337349398e-05,
      "loss": 0.0183,
      "step": 70790
    },
    {
      "epoch": 8.53012048192771,
      "grad_norm": 0.0164833702147007,
      "learning_rate": 1.146987951807229e-05,
      "loss": 0.0106,
      "step": 70800
    },
    {
      "epoch": 8.53132530120482,
      "grad_norm": 0.004507941659539938,
      "learning_rate": 1.1468674698795181e-05,
      "loss": 0.0264,
      "step": 70810
    },
    {
      "epoch": 8.532530120481928,
      "grad_norm": 0.007730808574706316,
      "learning_rate": 1.1467469879518074e-05,
      "loss": 0.0259,
      "step": 70820
    },
    {
      "epoch": 8.533734939759036,
      "grad_norm": 4.844654560089111,
      "learning_rate": 1.1466265060240964e-05,
      "loss": 0.0305,
      "step": 70830
    },
    {
      "epoch": 8.534939759036144,
      "grad_norm": 0.006533396430313587,
      "learning_rate": 1.1465060240963857e-05,
      "loss": 0.0065,
      "step": 70840
    },
    {
      "epoch": 8.536144578313253,
      "grad_norm": 0.005322833079844713,
      "learning_rate": 1.1463855421686748e-05,
      "loss": 0.0517,
      "step": 70850
    },
    {
      "epoch": 8.537349397590361,
      "grad_norm": 2.544316530227661,
      "learning_rate": 1.146265060240964e-05,
      "loss": 0.0151,
      "step": 70860
    },
    {
      "epoch": 8.53855421686747,
      "grad_norm": 5.865475177764893,
      "learning_rate": 1.1461445783132533e-05,
      "loss": 0.0163,
      "step": 70870
    },
    {
      "epoch": 8.539759036144579,
      "grad_norm": 0.18955236673355103,
      "learning_rate": 1.1460240963855422e-05,
      "loss": 0.032,
      "step": 70880
    },
    {
      "epoch": 8.540963855421687,
      "grad_norm": 0.003049209015443921,
      "learning_rate": 1.1459036144578316e-05,
      "loss": 0.0268,
      "step": 70890
    },
    {
      "epoch": 8.542168674698795,
      "grad_norm": 6.1930155754089355,
      "learning_rate": 1.1457831325301205e-05,
      "loss": 0.0389,
      "step": 70900
    },
    {
      "epoch": 8.543373493975903,
      "grad_norm": 1.800724744796753,
      "learning_rate": 1.1456626506024097e-05,
      "loss": 0.0356,
      "step": 70910
    },
    {
      "epoch": 8.544578313253012,
      "grad_norm": 1.1720255613327026,
      "learning_rate": 1.1455421686746988e-05,
      "loss": 0.0247,
      "step": 70920
    },
    {
      "epoch": 8.54578313253012,
      "grad_norm": 4.008119583129883,
      "learning_rate": 1.145421686746988e-05,
      "loss": 0.0445,
      "step": 70930
    },
    {
      "epoch": 8.546987951807228,
      "grad_norm": 5.909693717956543,
      "learning_rate": 1.1453012048192773e-05,
      "loss": 0.0473,
      "step": 70940
    },
    {
      "epoch": 8.548192771084338,
      "grad_norm": 0.004905866924673319,
      "learning_rate": 1.1451807228915664e-05,
      "loss": 0.0128,
      "step": 70950
    },
    {
      "epoch": 8.549397590361446,
      "grad_norm": 0.5579575896263123,
      "learning_rate": 1.1450602409638556e-05,
      "loss": 0.0228,
      "step": 70960
    },
    {
      "epoch": 8.550602409638554,
      "grad_norm": 0.20675556361675262,
      "learning_rate": 1.1449397590361447e-05,
      "loss": 0.0514,
      "step": 70970
    },
    {
      "epoch": 8.551807228915663,
      "grad_norm": 0.9283624887466431,
      "learning_rate": 1.1448192771084339e-05,
      "loss": 0.0648,
      "step": 70980
    },
    {
      "epoch": 8.553012048192771,
      "grad_norm": 0.8204610347747803,
      "learning_rate": 1.144698795180723e-05,
      "loss": 0.0567,
      "step": 70990
    },
    {
      "epoch": 8.55421686746988,
      "grad_norm": 1.3465549945831299,
      "learning_rate": 1.1445783132530122e-05,
      "loss": 0.0393,
      "step": 71000
    },
    {
      "epoch": 8.555421686746987,
      "grad_norm": 1.6743600368499756,
      "learning_rate": 1.1444578313253011e-05,
      "loss": 0.0514,
      "step": 71010
    },
    {
      "epoch": 8.556626506024097,
      "grad_norm": 16.666088104248047,
      "learning_rate": 1.1443373493975904e-05,
      "loss": 0.0466,
      "step": 71020
    },
    {
      "epoch": 8.557831325301205,
      "grad_norm": 0.7318567633628845,
      "learning_rate": 1.1442168674698796e-05,
      "loss": 0.0113,
      "step": 71030
    },
    {
      "epoch": 8.559036144578313,
      "grad_norm": 0.0718073695898056,
      "learning_rate": 1.1440963855421687e-05,
      "loss": 0.0189,
      "step": 71040
    },
    {
      "epoch": 8.560240963855422,
      "grad_norm": 0.10655279457569122,
      "learning_rate": 1.143975903614458e-05,
      "loss": 0.0195,
      "step": 71050
    },
    {
      "epoch": 8.56144578313253,
      "grad_norm": 0.03412185609340668,
      "learning_rate": 1.143855421686747e-05,
      "loss": 0.0051,
      "step": 71060
    },
    {
      "epoch": 8.562650602409638,
      "grad_norm": 0.09911876916885376,
      "learning_rate": 1.1437349397590363e-05,
      "loss": 0.0026,
      "step": 71070
    },
    {
      "epoch": 8.563855421686746,
      "grad_norm": 1.1093435287475586,
      "learning_rate": 1.1436144578313253e-05,
      "loss": 0.0181,
      "step": 71080
    },
    {
      "epoch": 8.565060240963856,
      "grad_norm": 0.0067351884208619595,
      "learning_rate": 1.1434939759036146e-05,
      "loss": 0.0449,
      "step": 71090
    },
    {
      "epoch": 8.566265060240964,
      "grad_norm": 0.0019280295819044113,
      "learning_rate": 1.1433734939759038e-05,
      "loss": 0.0495,
      "step": 71100
    },
    {
      "epoch": 8.567469879518072,
      "grad_norm": 1.3723766803741455,
      "learning_rate": 1.1432530120481929e-05,
      "loss": 0.0098,
      "step": 71110
    },
    {
      "epoch": 8.568674698795181,
      "grad_norm": 0.005351357627660036,
      "learning_rate": 1.1431325301204821e-05,
      "loss": 0.0418,
      "step": 71120
    },
    {
      "epoch": 8.56987951807229,
      "grad_norm": 0.011548463255167007,
      "learning_rate": 1.143012048192771e-05,
      "loss": 0.0377,
      "step": 71130
    },
    {
      "epoch": 8.571084337349397,
      "grad_norm": 0.07821875810623169,
      "learning_rate": 1.1428915662650605e-05,
      "loss": 0.0503,
      "step": 71140
    },
    {
      "epoch": 8.572289156626507,
      "grad_norm": 3.5476841926574707,
      "learning_rate": 1.1427710843373494e-05,
      "loss": 0.0596,
      "step": 71150
    },
    {
      "epoch": 8.573493975903615,
      "grad_norm": 0.18599383533000946,
      "learning_rate": 1.1426506024096386e-05,
      "loss": 0.0307,
      "step": 71160
    },
    {
      "epoch": 8.574698795180723,
      "grad_norm": 0.07086411863565445,
      "learning_rate": 1.1425301204819278e-05,
      "loss": 0.025,
      "step": 71170
    },
    {
      "epoch": 8.57590361445783,
      "grad_norm": 5.091534614562988,
      "learning_rate": 1.142409638554217e-05,
      "loss": 0.0382,
      "step": 71180
    },
    {
      "epoch": 8.57710843373494,
      "grad_norm": 0.055121298879384995,
      "learning_rate": 1.1422891566265062e-05,
      "loss": 0.0223,
      "step": 71190
    },
    {
      "epoch": 8.578313253012048,
      "grad_norm": 0.0031181597150862217,
      "learning_rate": 1.1421686746987952e-05,
      "loss": 0.0228,
      "step": 71200
    },
    {
      "epoch": 8.579518072289156,
      "grad_norm": 0.027254579588770866,
      "learning_rate": 1.1420481927710845e-05,
      "loss": 0.0205,
      "step": 71210
    },
    {
      "epoch": 8.580722891566266,
      "grad_norm": 14.337937355041504,
      "learning_rate": 1.1419277108433736e-05,
      "loss": 0.0516,
      "step": 71220
    },
    {
      "epoch": 8.581927710843374,
      "grad_norm": 0.16502557694911957,
      "learning_rate": 1.1418072289156628e-05,
      "loss": 0.0104,
      "step": 71230
    },
    {
      "epoch": 8.583132530120482,
      "grad_norm": 1.0904338359832764,
      "learning_rate": 1.141686746987952e-05,
      "loss": 0.0307,
      "step": 71240
    },
    {
      "epoch": 8.58433734939759,
      "grad_norm": 0.008128272369503975,
      "learning_rate": 1.1415662650602411e-05,
      "loss": 0.0309,
      "step": 71250
    },
    {
      "epoch": 8.5855421686747,
      "grad_norm": 0.09710093587636948,
      "learning_rate": 1.1414457831325304e-05,
      "loss": 0.0191,
      "step": 71260
    },
    {
      "epoch": 8.586746987951807,
      "grad_norm": 0.5874230861663818,
      "learning_rate": 1.1413253012048193e-05,
      "loss": 0.0198,
      "step": 71270
    },
    {
      "epoch": 8.587951807228915,
      "grad_norm": 0.0026120624970644712,
      "learning_rate": 1.1412048192771085e-05,
      "loss": 0.0047,
      "step": 71280
    },
    {
      "epoch": 8.589156626506025,
      "grad_norm": 7.77374267578125,
      "learning_rate": 1.1410843373493976e-05,
      "loss": 0.109,
      "step": 71290
    },
    {
      "epoch": 8.590361445783133,
      "grad_norm": 0.0040802424773573875,
      "learning_rate": 1.1409638554216868e-05,
      "loss": 0.0108,
      "step": 71300
    },
    {
      "epoch": 8.59156626506024,
      "grad_norm": 0.157301664352417,
      "learning_rate": 1.1408433734939759e-05,
      "loss": 0.0471,
      "step": 71310
    },
    {
      "epoch": 8.592771084337349,
      "grad_norm": 2.7450907230377197,
      "learning_rate": 1.1407228915662651e-05,
      "loss": 0.0111,
      "step": 71320
    },
    {
      "epoch": 8.593975903614458,
      "grad_norm": 0.9716367125511169,
      "learning_rate": 1.1406024096385544e-05,
      "loss": 0.0143,
      "step": 71330
    },
    {
      "epoch": 8.595180722891566,
      "grad_norm": 1.3599467277526855,
      "learning_rate": 1.1404819277108435e-05,
      "loss": 0.04,
      "step": 71340
    },
    {
      "epoch": 8.596385542168674,
      "grad_norm": 0.005938406568020582,
      "learning_rate": 1.1403614457831327e-05,
      "loss": 0.0085,
      "step": 71350
    },
    {
      "epoch": 8.597590361445784,
      "grad_norm": 0.0029497751966118813,
      "learning_rate": 1.1402409638554218e-05,
      "loss": 0.0302,
      "step": 71360
    },
    {
      "epoch": 8.598795180722892,
      "grad_norm": 0.0048996577970683575,
      "learning_rate": 1.140120481927711e-05,
      "loss": 0.0273,
      "step": 71370
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.019562754780054092,
      "learning_rate": 1.14e-05,
      "loss": 0.0199,
      "step": 71380
    },
    {
      "epoch": 8.601204819277108,
      "grad_norm": 0.0030204064678400755,
      "learning_rate": 1.1398795180722892e-05,
      "loss": 0.0331,
      "step": 71390
    },
    {
      "epoch": 8.602409638554217,
      "grad_norm": 0.012544394470751286,
      "learning_rate": 1.1397590361445786e-05,
      "loss": 0.0004,
      "step": 71400
    },
    {
      "epoch": 8.603614457831325,
      "grad_norm": 2.803314447402954,
      "learning_rate": 1.1396385542168675e-05,
      "loss": 0.0611,
      "step": 71410
    },
    {
      "epoch": 8.604819277108433,
      "grad_norm": 2.5259552001953125,
      "learning_rate": 1.1395180722891567e-05,
      "loss": 0.0211,
      "step": 71420
    },
    {
      "epoch": 8.606024096385543,
      "grad_norm": 1.4525610208511353,
      "learning_rate": 1.1393975903614458e-05,
      "loss": 0.052,
      "step": 71430
    },
    {
      "epoch": 8.60722891566265,
      "grad_norm": 0.03209572657942772,
      "learning_rate": 1.139277108433735e-05,
      "loss": 0.042,
      "step": 71440
    },
    {
      "epoch": 8.608433734939759,
      "grad_norm": 1.4950520992279053,
      "learning_rate": 1.1391566265060241e-05,
      "loss": 0.0292,
      "step": 71450
    },
    {
      "epoch": 8.609638554216868,
      "grad_norm": 0.012981954962015152,
      "learning_rate": 1.1390361445783134e-05,
      "loss": 0.0357,
      "step": 71460
    },
    {
      "epoch": 8.610843373493976,
      "grad_norm": 0.07450031489133835,
      "learning_rate": 1.1389156626506026e-05,
      "loss": 0.0224,
      "step": 71470
    },
    {
      "epoch": 8.612048192771084,
      "grad_norm": 17.464550018310547,
      "learning_rate": 1.1387951807228917e-05,
      "loss": 0.0243,
      "step": 71480
    },
    {
      "epoch": 8.613253012048192,
      "grad_norm": 0.034420546144247055,
      "learning_rate": 1.138674698795181e-05,
      "loss": 0.0174,
      "step": 71490
    },
    {
      "epoch": 8.614457831325302,
      "grad_norm": 13.514863014221191,
      "learning_rate": 1.13855421686747e-05,
      "loss": 0.0146,
      "step": 71500
    },
    {
      "epoch": 8.61566265060241,
      "grad_norm": 4.066445350646973,
      "learning_rate": 1.1384337349397592e-05,
      "loss": 0.0441,
      "step": 71510
    },
    {
      "epoch": 8.616867469879518,
      "grad_norm": 0.030859971418976784,
      "learning_rate": 1.1383132530120482e-05,
      "loss": 0.0386,
      "step": 71520
    },
    {
      "epoch": 8.618072289156627,
      "grad_norm": 0.008814460597932339,
      "learning_rate": 1.1381927710843374e-05,
      "loss": 0.0021,
      "step": 71530
    },
    {
      "epoch": 8.619277108433735,
      "grad_norm": 0.009596064686775208,
      "learning_rate": 1.1380722891566266e-05,
      "loss": 0.008,
      "step": 71540
    },
    {
      "epoch": 8.620481927710843,
      "grad_norm": 0.007862144149839878,
      "learning_rate": 1.1379518072289157e-05,
      "loss": 0.0298,
      "step": 71550
    },
    {
      "epoch": 8.621686746987951,
      "grad_norm": 3.5620038509368896,
      "learning_rate": 1.137831325301205e-05,
      "loss": 0.0283,
      "step": 71560
    },
    {
      "epoch": 8.62289156626506,
      "grad_norm": 0.9538530111312866,
      "learning_rate": 1.137710843373494e-05,
      "loss": 0.0272,
      "step": 71570
    },
    {
      "epoch": 8.624096385542169,
      "grad_norm": 0.7755846381187439,
      "learning_rate": 1.1375903614457833e-05,
      "loss": 0.0087,
      "step": 71580
    },
    {
      "epoch": 8.625301204819277,
      "grad_norm": 0.03793655335903168,
      "learning_rate": 1.1374698795180723e-05,
      "loss": 0.0018,
      "step": 71590
    },
    {
      "epoch": 8.626506024096386,
      "grad_norm": 0.007681481074541807,
      "learning_rate": 1.1373493975903616e-05,
      "loss": 0.0007,
      "step": 71600
    },
    {
      "epoch": 8.627710843373494,
      "grad_norm": 0.004017586819827557,
      "learning_rate": 1.1372289156626507e-05,
      "loss": 0.0515,
      "step": 71610
    },
    {
      "epoch": 8.628915662650602,
      "grad_norm": 0.0861566811800003,
      "learning_rate": 1.1371084337349399e-05,
      "loss": 0.0148,
      "step": 71620
    },
    {
      "epoch": 8.630120481927712,
      "grad_norm": 0.005015668459236622,
      "learning_rate": 1.1369879518072292e-05,
      "loss": 0.0462,
      "step": 71630
    },
    {
      "epoch": 8.63132530120482,
      "grad_norm": 6.938891887664795,
      "learning_rate": 1.136867469879518e-05,
      "loss": 0.0373,
      "step": 71640
    },
    {
      "epoch": 8.632530120481928,
      "grad_norm": 0.004798402078449726,
      "learning_rate": 1.1367469879518073e-05,
      "loss": 0.0008,
      "step": 71650
    },
    {
      "epoch": 8.633734939759035,
      "grad_norm": 0.5468066334724426,
      "learning_rate": 1.1366265060240964e-05,
      "loss": 0.0219,
      "step": 71660
    },
    {
      "epoch": 8.634939759036145,
      "grad_norm": 0.00861791055649519,
      "learning_rate": 1.1365060240963856e-05,
      "loss": 0.0175,
      "step": 71670
    },
    {
      "epoch": 8.636144578313253,
      "grad_norm": 0.03440037742257118,
      "learning_rate": 1.1363855421686747e-05,
      "loss": 0.0044,
      "step": 71680
    },
    {
      "epoch": 8.637349397590361,
      "grad_norm": 0.29007160663604736,
      "learning_rate": 1.136265060240964e-05,
      "loss": 0.0035,
      "step": 71690
    },
    {
      "epoch": 8.638554216867469,
      "grad_norm": 0.07426118850708008,
      "learning_rate": 1.1361445783132532e-05,
      "loss": 0.0342,
      "step": 71700
    },
    {
      "epoch": 8.639759036144579,
      "grad_norm": 0.004049020819365978,
      "learning_rate": 1.1360240963855423e-05,
      "loss": 0.0267,
      "step": 71710
    },
    {
      "epoch": 8.640963855421687,
      "grad_norm": 0.004350181203335524,
      "learning_rate": 1.1359036144578315e-05,
      "loss": 0.0269,
      "step": 71720
    },
    {
      "epoch": 8.642168674698794,
      "grad_norm": 7.111536026000977,
      "learning_rate": 1.1357831325301206e-05,
      "loss": 0.0367,
      "step": 71730
    },
    {
      "epoch": 8.643373493975904,
      "grad_norm": 2.3086140155792236,
      "learning_rate": 1.1356626506024098e-05,
      "loss": 0.0515,
      "step": 71740
    },
    {
      "epoch": 8.644578313253012,
      "grad_norm": 3.9962427616119385,
      "learning_rate": 1.1355421686746987e-05,
      "loss": 0.0336,
      "step": 71750
    },
    {
      "epoch": 8.64578313253012,
      "grad_norm": 2.5954272747039795,
      "learning_rate": 1.1354216867469881e-05,
      "loss": 0.0342,
      "step": 71760
    },
    {
      "epoch": 8.64698795180723,
      "grad_norm": 0.2556149661540985,
      "learning_rate": 1.1353012048192774e-05,
      "loss": 0.0138,
      "step": 71770
    },
    {
      "epoch": 8.648192771084338,
      "grad_norm": 0.1751534789800644,
      "learning_rate": 1.1351807228915663e-05,
      "loss": 0.0541,
      "step": 71780
    },
    {
      "epoch": 8.649397590361446,
      "grad_norm": 0.41993269324302673,
      "learning_rate": 1.1350602409638555e-05,
      "loss": 0.0134,
      "step": 71790
    },
    {
      "epoch": 8.650602409638553,
      "grad_norm": 0.5075104236602783,
      "learning_rate": 1.1349397590361446e-05,
      "loss": 0.0385,
      "step": 71800
    },
    {
      "epoch": 8.651807228915663,
      "grad_norm": 0.11738679558038712,
      "learning_rate": 1.1348192771084338e-05,
      "loss": 0.0159,
      "step": 71810
    },
    {
      "epoch": 8.653012048192771,
      "grad_norm": 0.002501403447240591,
      "learning_rate": 1.1346987951807229e-05,
      "loss": 0.029,
      "step": 71820
    },
    {
      "epoch": 8.654216867469879,
      "grad_norm": 1.5801173448562622,
      "learning_rate": 1.1345783132530122e-05,
      "loss": 0.0153,
      "step": 71830
    },
    {
      "epoch": 8.655421686746989,
      "grad_norm": 3.4107003211975098,
      "learning_rate": 1.1344578313253014e-05,
      "loss": 0.0648,
      "step": 71840
    },
    {
      "epoch": 8.656626506024097,
      "grad_norm": 0.16962069272994995,
      "learning_rate": 1.1343373493975905e-05,
      "loss": 0.0106,
      "step": 71850
    },
    {
      "epoch": 8.657831325301204,
      "grad_norm": 0.6060150861740112,
      "learning_rate": 1.1342168674698797e-05,
      "loss": 0.0199,
      "step": 71860
    },
    {
      "epoch": 8.659036144578312,
      "grad_norm": 0.016312915831804276,
      "learning_rate": 1.1340963855421688e-05,
      "loss": 0.0216,
      "step": 71870
    },
    {
      "epoch": 8.660240963855422,
      "grad_norm": 0.11499031633138657,
      "learning_rate": 1.133975903614458e-05,
      "loss": 0.0339,
      "step": 71880
    },
    {
      "epoch": 8.66144578313253,
      "grad_norm": 0.8525956273078918,
      "learning_rate": 1.133855421686747e-05,
      "loss": 0.025,
      "step": 71890
    },
    {
      "epoch": 8.662650602409638,
      "grad_norm": 0.0013436570297926664,
      "learning_rate": 1.1337349397590362e-05,
      "loss": 0.0161,
      "step": 71900
    },
    {
      "epoch": 8.663855421686748,
      "grad_norm": 0.0024519332218915224,
      "learning_rate": 1.1336144578313253e-05,
      "loss": 0.0094,
      "step": 71910
    },
    {
      "epoch": 8.665060240963856,
      "grad_norm": 0.9108899831771851,
      "learning_rate": 1.1334939759036145e-05,
      "loss": 0.0383,
      "step": 71920
    },
    {
      "epoch": 8.666265060240963,
      "grad_norm": 1.8954064846038818,
      "learning_rate": 1.1333734939759037e-05,
      "loss": 0.0466,
      "step": 71930
    },
    {
      "epoch": 8.667469879518073,
      "grad_norm": 0.001916574197821319,
      "learning_rate": 1.1332530120481928e-05,
      "loss": 0.0007,
      "step": 71940
    },
    {
      "epoch": 8.668674698795181,
      "grad_norm": 0.03455318883061409,
      "learning_rate": 1.133132530120482e-05,
      "loss": 0.0006,
      "step": 71950
    },
    {
      "epoch": 8.669879518072289,
      "grad_norm": 36.01874542236328,
      "learning_rate": 1.1330120481927711e-05,
      "loss": 0.0105,
      "step": 71960
    },
    {
      "epoch": 8.671084337349397,
      "grad_norm": 0.21847717463970184,
      "learning_rate": 1.1328915662650604e-05,
      "loss": 0.0131,
      "step": 71970
    },
    {
      "epoch": 8.672289156626507,
      "grad_norm": 0.002513977000489831,
      "learning_rate": 1.1327710843373495e-05,
      "loss": 0.0053,
      "step": 71980
    },
    {
      "epoch": 8.673493975903614,
      "grad_norm": 0.0013204040005803108,
      "learning_rate": 1.1326506024096387e-05,
      "loss": 0.0039,
      "step": 71990
    },
    {
      "epoch": 8.674698795180722,
      "grad_norm": 1.9703607559204102,
      "learning_rate": 1.132530120481928e-05,
      "loss": 0.0506,
      "step": 72000
    },
    {
      "epoch": 8.675903614457832,
      "grad_norm": 0.0017002065433189273,
      "learning_rate": 1.1324096385542168e-05,
      "loss": 0.0032,
      "step": 72010
    },
    {
      "epoch": 8.67710843373494,
      "grad_norm": 0.0025358533021062613,
      "learning_rate": 1.1322891566265063e-05,
      "loss": 0.0649,
      "step": 72020
    },
    {
      "epoch": 8.678313253012048,
      "grad_norm": 3.1987860202789307,
      "learning_rate": 1.1321686746987952e-05,
      "loss": 0.0226,
      "step": 72030
    },
    {
      "epoch": 8.679518072289156,
      "grad_norm": 0.7062419056892395,
      "learning_rate": 1.1320481927710844e-05,
      "loss": 0.0415,
      "step": 72040
    },
    {
      "epoch": 8.680722891566266,
      "grad_norm": 0.012601925991475582,
      "learning_rate": 1.1319277108433735e-05,
      "loss": 0.0043,
      "step": 72050
    },
    {
      "epoch": 8.681927710843373,
      "grad_norm": 0.16614718735218048,
      "learning_rate": 1.1318072289156627e-05,
      "loss": 0.0215,
      "step": 72060
    },
    {
      "epoch": 8.683132530120481,
      "grad_norm": 0.00574026582762599,
      "learning_rate": 1.131686746987952e-05,
      "loss": 0.0297,
      "step": 72070
    },
    {
      "epoch": 8.684337349397591,
      "grad_norm": 0.12537142634391785,
      "learning_rate": 1.131566265060241e-05,
      "loss": 0.0323,
      "step": 72080
    },
    {
      "epoch": 8.685542168674699,
      "grad_norm": 0.15628324449062347,
      "learning_rate": 1.1314457831325303e-05,
      "loss": 0.0257,
      "step": 72090
    },
    {
      "epoch": 8.686746987951807,
      "grad_norm": 0.012533926405012608,
      "learning_rate": 1.1313253012048194e-05,
      "loss": 0.024,
      "step": 72100
    },
    {
      "epoch": 8.687951807228917,
      "grad_norm": 0.0014497060328722,
      "learning_rate": 1.1312048192771086e-05,
      "loss": 0.0578,
      "step": 72110
    },
    {
      "epoch": 8.689156626506024,
      "grad_norm": 0.03803623095154762,
      "learning_rate": 1.1310843373493977e-05,
      "loss": 0.0272,
      "step": 72120
    },
    {
      "epoch": 8.690361445783132,
      "grad_norm": 0.0037415216211229563,
      "learning_rate": 1.130963855421687e-05,
      "loss": 0.0172,
      "step": 72130
    },
    {
      "epoch": 8.69156626506024,
      "grad_norm": 1.5590910911560059,
      "learning_rate": 1.1308433734939762e-05,
      "loss": 0.0285,
      "step": 72140
    },
    {
      "epoch": 8.69277108433735,
      "grad_norm": 0.0022476601880043745,
      "learning_rate": 1.130722891566265e-05,
      "loss": 0.0365,
      "step": 72150
    },
    {
      "epoch": 8.693975903614458,
      "grad_norm": 0.005086265504360199,
      "learning_rate": 1.1306024096385543e-05,
      "loss": 0.0382,
      "step": 72160
    },
    {
      "epoch": 8.695180722891566,
      "grad_norm": 1.0498031377792358,
      "learning_rate": 1.1304819277108434e-05,
      "loss": 0.0185,
      "step": 72170
    },
    {
      "epoch": 8.696385542168674,
      "grad_norm": 0.08149437606334686,
      "learning_rate": 1.1303614457831326e-05,
      "loss": 0.0024,
      "step": 72180
    },
    {
      "epoch": 8.697590361445783,
      "grad_norm": 0.027492891997098923,
      "learning_rate": 1.1302409638554217e-05,
      "loss": 0.0148,
      "step": 72190
    },
    {
      "epoch": 8.698795180722891,
      "grad_norm": 0.00965030025690794,
      "learning_rate": 1.130120481927711e-05,
      "loss": 0.0299,
      "step": 72200
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.024540871381759644,
      "learning_rate": 1.13e-05,
      "loss": 0.0172,
      "step": 72210
    },
    {
      "epoch": 8.701204819277109,
      "grad_norm": 0.0025792301166802645,
      "learning_rate": 1.1298795180722893e-05,
      "loss": 0.0457,
      "step": 72220
    },
    {
      "epoch": 8.702409638554217,
      "grad_norm": 0.24009093642234802,
      "learning_rate": 1.1297590361445785e-05,
      "loss": 0.0138,
      "step": 72230
    },
    {
      "epoch": 8.703614457831325,
      "grad_norm": 0.0021052099764347076,
      "learning_rate": 1.1296385542168676e-05,
      "loss": 0.0193,
      "step": 72240
    },
    {
      "epoch": 8.704819277108435,
      "grad_norm": 0.0046721515245735645,
      "learning_rate": 1.1295180722891568e-05,
      "loss": 0.0072,
      "step": 72250
    },
    {
      "epoch": 8.706024096385542,
      "grad_norm": 2.2982420921325684,
      "learning_rate": 1.1293975903614457e-05,
      "loss": 0.071,
      "step": 72260
    },
    {
      "epoch": 8.70722891566265,
      "grad_norm": 0.6882203817367554,
      "learning_rate": 1.129277108433735e-05,
      "loss": 0.0576,
      "step": 72270
    },
    {
      "epoch": 8.708433734939758,
      "grad_norm": 1.5167787075042725,
      "learning_rate": 1.129156626506024e-05,
      "loss": 0.0123,
      "step": 72280
    },
    {
      "epoch": 8.709638554216868,
      "grad_norm": 0.6254824995994568,
      "learning_rate": 1.1290361445783133e-05,
      "loss": 0.0062,
      "step": 72290
    },
    {
      "epoch": 8.710843373493976,
      "grad_norm": 0.00833720900118351,
      "learning_rate": 1.1289156626506025e-05,
      "loss": 0.0531,
      "step": 72300
    },
    {
      "epoch": 8.712048192771084,
      "grad_norm": 0.003395998850464821,
      "learning_rate": 1.1287951807228916e-05,
      "loss": 0.0091,
      "step": 72310
    },
    {
      "epoch": 8.713253012048193,
      "grad_norm": 0.0077166203409433365,
      "learning_rate": 1.1286746987951809e-05,
      "loss": 0.0004,
      "step": 72320
    },
    {
      "epoch": 8.714457831325301,
      "grad_norm": 0.020073385909199715,
      "learning_rate": 1.12855421686747e-05,
      "loss": 0.0228,
      "step": 72330
    },
    {
      "epoch": 8.71566265060241,
      "grad_norm": 0.0046733408235013485,
      "learning_rate": 1.1284337349397592e-05,
      "loss": 0.0019,
      "step": 72340
    },
    {
      "epoch": 8.716867469879517,
      "grad_norm": 0.005991111043840647,
      "learning_rate": 1.1283132530120482e-05,
      "loss": 0.0251,
      "step": 72350
    },
    {
      "epoch": 8.718072289156627,
      "grad_norm": 0.006190252024680376,
      "learning_rate": 1.1281927710843375e-05,
      "loss": 0.0094,
      "step": 72360
    },
    {
      "epoch": 8.719277108433735,
      "grad_norm": 0.6346500515937805,
      "learning_rate": 1.1280722891566267e-05,
      "loss": 0.0248,
      "step": 72370
    },
    {
      "epoch": 8.720481927710843,
      "grad_norm": 0.004382960498332977,
      "learning_rate": 1.1279518072289158e-05,
      "loss": 0.0073,
      "step": 72380
    },
    {
      "epoch": 8.721686746987952,
      "grad_norm": 0.002407958498224616,
      "learning_rate": 1.127831325301205e-05,
      "loss": 0.0034,
      "step": 72390
    },
    {
      "epoch": 8.72289156626506,
      "grad_norm": 0.028190404176712036,
      "learning_rate": 1.127710843373494e-05,
      "loss": 0.031,
      "step": 72400
    },
    {
      "epoch": 8.724096385542168,
      "grad_norm": 0.008702559396624565,
      "learning_rate": 1.1275903614457832e-05,
      "loss": 0.0312,
      "step": 72410
    },
    {
      "epoch": 8.725301204819278,
      "grad_norm": 2.429201126098633,
      "learning_rate": 1.1274698795180723e-05,
      "loss": 0.0588,
      "step": 72420
    },
    {
      "epoch": 8.726506024096386,
      "grad_norm": 0.008428935892879963,
      "learning_rate": 1.1273493975903615e-05,
      "loss": 0.0668,
      "step": 72430
    },
    {
      "epoch": 8.727710843373494,
      "grad_norm": 0.39028170704841614,
      "learning_rate": 1.1272289156626508e-05,
      "loss": 0.0014,
      "step": 72440
    },
    {
      "epoch": 8.728915662650602,
      "grad_norm": 0.0070874751545488834,
      "learning_rate": 1.1271084337349398e-05,
      "loss": 0.0084,
      "step": 72450
    },
    {
      "epoch": 8.730120481927711,
      "grad_norm": 0.5506028532981873,
      "learning_rate": 1.126987951807229e-05,
      "loss": 0.0327,
      "step": 72460
    },
    {
      "epoch": 8.73132530120482,
      "grad_norm": 0.005721775349229574,
      "learning_rate": 1.1268674698795182e-05,
      "loss": 0.0334,
      "step": 72470
    },
    {
      "epoch": 8.732530120481927,
      "grad_norm": 0.7160552740097046,
      "learning_rate": 1.1267469879518074e-05,
      "loss": 0.0119,
      "step": 72480
    },
    {
      "epoch": 8.733734939759037,
      "grad_norm": 0.028088636696338654,
      "learning_rate": 1.1266265060240965e-05,
      "loss": 0.0195,
      "step": 72490
    },
    {
      "epoch": 8.734939759036145,
      "grad_norm": 0.002697375137358904,
      "learning_rate": 1.1265060240963857e-05,
      "loss": 0.0315,
      "step": 72500
    },
    {
      "epoch": 8.736144578313253,
      "grad_norm": 0.0051306928507983685,
      "learning_rate": 1.1263855421686746e-05,
      "loss": 0.0113,
      "step": 72510
    },
    {
      "epoch": 8.73734939759036,
      "grad_norm": 0.15599177777767181,
      "learning_rate": 1.1262650602409639e-05,
      "loss": 0.0167,
      "step": 72520
    },
    {
      "epoch": 8.73855421686747,
      "grad_norm": 0.08446566015481949,
      "learning_rate": 1.1261445783132533e-05,
      "loss": 0.0245,
      "step": 72530
    },
    {
      "epoch": 8.739759036144578,
      "grad_norm": 0.006010740529745817,
      "learning_rate": 1.1260240963855422e-05,
      "loss": 0.0113,
      "step": 72540
    },
    {
      "epoch": 8.740963855421686,
      "grad_norm": 1.1969767808914185,
      "learning_rate": 1.1259036144578314e-05,
      "loss": 0.0181,
      "step": 72550
    },
    {
      "epoch": 8.742168674698796,
      "grad_norm": 0.007661673706024885,
      "learning_rate": 1.1257831325301205e-05,
      "loss": 0.0112,
      "step": 72560
    },
    {
      "epoch": 8.743373493975904,
      "grad_norm": 0.627469003200531,
      "learning_rate": 1.1256626506024097e-05,
      "loss": 0.0538,
      "step": 72570
    },
    {
      "epoch": 8.744578313253012,
      "grad_norm": 3.169926643371582,
      "learning_rate": 1.1255421686746988e-05,
      "loss": 0.0121,
      "step": 72580
    },
    {
      "epoch": 8.745783132530121,
      "grad_norm": 0.001973917940631509,
      "learning_rate": 1.125421686746988e-05,
      "loss": 0.0436,
      "step": 72590
    },
    {
      "epoch": 8.74698795180723,
      "grad_norm": 0.003349894192069769,
      "learning_rate": 1.1253012048192773e-05,
      "loss": 0.022,
      "step": 72600
    },
    {
      "epoch": 8.748192771084337,
      "grad_norm": 0.2178070843219757,
      "learning_rate": 1.1251807228915664e-05,
      "loss": 0.1418,
      "step": 72610
    },
    {
      "epoch": 8.749397590361445,
      "grad_norm": 9.551491737365723,
      "learning_rate": 1.1250602409638556e-05,
      "loss": 0.0073,
      "step": 72620
    },
    {
      "epoch": 8.750602409638555,
      "grad_norm": 0.009492612443864346,
      "learning_rate": 1.1249397590361445e-05,
      "loss": 0.0268,
      "step": 72630
    },
    {
      "epoch": 8.751807228915663,
      "grad_norm": 0.017400305718183517,
      "learning_rate": 1.124819277108434e-05,
      "loss": 0.0221,
      "step": 72640
    },
    {
      "epoch": 8.75301204819277,
      "grad_norm": 0.010643701069056988,
      "learning_rate": 1.1246987951807228e-05,
      "loss": 0.0075,
      "step": 72650
    },
    {
      "epoch": 8.754216867469879,
      "grad_norm": 0.0498315803706646,
      "learning_rate": 1.124578313253012e-05,
      "loss": 0.0504,
      "step": 72660
    },
    {
      "epoch": 8.755421686746988,
      "grad_norm": 4.405694961547852,
      "learning_rate": 1.1244578313253013e-05,
      "loss": 0.0466,
      "step": 72670
    },
    {
      "epoch": 8.756626506024096,
      "grad_norm": 0.18491223454475403,
      "learning_rate": 1.1243373493975904e-05,
      "loss": 0.0069,
      "step": 72680
    },
    {
      "epoch": 8.757831325301204,
      "grad_norm": 0.007197589613497257,
      "learning_rate": 1.1242168674698796e-05,
      "loss": 0.0383,
      "step": 72690
    },
    {
      "epoch": 8.759036144578314,
      "grad_norm": 1.742569088935852,
      "learning_rate": 1.1240963855421687e-05,
      "loss": 0.0656,
      "step": 72700
    },
    {
      "epoch": 8.760240963855422,
      "grad_norm": 1.2033185958862305,
      "learning_rate": 1.123975903614458e-05,
      "loss": 0.0255,
      "step": 72710
    },
    {
      "epoch": 8.76144578313253,
      "grad_norm": 0.004049698822200298,
      "learning_rate": 1.123855421686747e-05,
      "loss": 0.0352,
      "step": 72720
    },
    {
      "epoch": 8.76265060240964,
      "grad_norm": 1.4553909301757812,
      "learning_rate": 1.1237349397590363e-05,
      "loss": 0.0299,
      "step": 72730
    },
    {
      "epoch": 8.763855421686747,
      "grad_norm": 0.5468524098396301,
      "learning_rate": 1.1236144578313255e-05,
      "loss": 0.0167,
      "step": 72740
    },
    {
      "epoch": 8.765060240963855,
      "grad_norm": 0.0038927209097892046,
      "learning_rate": 1.1234939759036146e-05,
      "loss": 0.0248,
      "step": 72750
    },
    {
      "epoch": 8.766265060240963,
      "grad_norm": 0.003145070979371667,
      "learning_rate": 1.1233734939759038e-05,
      "loss": 0.0063,
      "step": 72760
    },
    {
      "epoch": 8.767469879518073,
      "grad_norm": 0.034159447997808456,
      "learning_rate": 1.1232530120481927e-05,
      "loss": 0.0652,
      "step": 72770
    },
    {
      "epoch": 8.76867469879518,
      "grad_norm": 0.02326401136815548,
      "learning_rate": 1.123132530120482e-05,
      "loss": 0.0082,
      "step": 72780
    },
    {
      "epoch": 8.769879518072289,
      "grad_norm": 0.01402810774743557,
      "learning_rate": 1.123012048192771e-05,
      "loss": 0.0148,
      "step": 72790
    },
    {
      "epoch": 8.771084337349398,
      "grad_norm": 4.5682501792907715,
      "learning_rate": 1.1228915662650603e-05,
      "loss": 0.0551,
      "step": 72800
    },
    {
      "epoch": 8.772289156626506,
      "grad_norm": 0.005667410790920258,
      "learning_rate": 1.1227710843373494e-05,
      "loss": 0.0319,
      "step": 72810
    },
    {
      "epoch": 8.773493975903614,
      "grad_norm": 1.307440996170044,
      "learning_rate": 1.1226506024096386e-05,
      "loss": 0.0481,
      "step": 72820
    },
    {
      "epoch": 8.774698795180722,
      "grad_norm": 1.1629506349563599,
      "learning_rate": 1.1225301204819279e-05,
      "loss": 0.0638,
      "step": 72830
    },
    {
      "epoch": 8.775903614457832,
      "grad_norm": 1.5922712087631226,
      "learning_rate": 1.122409638554217e-05,
      "loss": 0.0572,
      "step": 72840
    },
    {
      "epoch": 8.77710843373494,
      "grad_norm": 2.4076344966888428,
      "learning_rate": 1.1222891566265062e-05,
      "loss": 0.072,
      "step": 72850
    },
    {
      "epoch": 8.778313253012048,
      "grad_norm": 0.017707321792840958,
      "learning_rate": 1.1221686746987953e-05,
      "loss": 0.0291,
      "step": 72860
    },
    {
      "epoch": 8.779518072289157,
      "grad_norm": 0.16328449547290802,
      "learning_rate": 1.1220481927710845e-05,
      "loss": 0.0249,
      "step": 72870
    },
    {
      "epoch": 8.780722891566265,
      "grad_norm": 0.70377117395401,
      "learning_rate": 1.1219277108433734e-05,
      "loss": 0.0547,
      "step": 72880
    },
    {
      "epoch": 8.781927710843373,
      "grad_norm": 0.003383298171684146,
      "learning_rate": 1.1218072289156628e-05,
      "loss": 0.0655,
      "step": 72890
    },
    {
      "epoch": 8.783132530120483,
      "grad_norm": 0.07531668990850449,
      "learning_rate": 1.121686746987952e-05,
      "loss": 0.0232,
      "step": 72900
    },
    {
      "epoch": 8.78433734939759,
      "grad_norm": 0.04988102987408638,
      "learning_rate": 1.121566265060241e-05,
      "loss": 0.0464,
      "step": 72910
    },
    {
      "epoch": 8.785542168674699,
      "grad_norm": 0.01242943573743105,
      "learning_rate": 1.1214457831325302e-05,
      "loss": 0.031,
      "step": 72920
    },
    {
      "epoch": 8.786746987951807,
      "grad_norm": 1.1666165590286255,
      "learning_rate": 1.1213253012048193e-05,
      "loss": 0.0172,
      "step": 72930
    },
    {
      "epoch": 8.787951807228916,
      "grad_norm": 0.007109665311872959,
      "learning_rate": 1.1212048192771085e-05,
      "loss": 0.0144,
      "step": 72940
    },
    {
      "epoch": 8.789156626506024,
      "grad_norm": 0.5937183499336243,
      "learning_rate": 1.1210843373493976e-05,
      "loss": 0.0743,
      "step": 72950
    },
    {
      "epoch": 8.790361445783132,
      "grad_norm": 0.009169219993054867,
      "learning_rate": 1.1209638554216868e-05,
      "loss": 0.0129,
      "step": 72960
    },
    {
      "epoch": 8.791566265060242,
      "grad_norm": 0.00623983284458518,
      "learning_rate": 1.1208433734939761e-05,
      "loss": 0.0267,
      "step": 72970
    },
    {
      "epoch": 8.79277108433735,
      "grad_norm": 0.00483666080981493,
      "learning_rate": 1.1207228915662652e-05,
      "loss": 0.0131,
      "step": 72980
    },
    {
      "epoch": 8.793975903614458,
      "grad_norm": 9.549530982971191,
      "learning_rate": 1.1206024096385544e-05,
      "loss": 0.0645,
      "step": 72990
    },
    {
      "epoch": 8.795180722891565,
      "grad_norm": 0.020911984145641327,
      "learning_rate": 1.1204819277108435e-05,
      "loss": 0.0591,
      "step": 73000
    },
    {
      "epoch": 8.796385542168675,
      "grad_norm": 3.744476079940796,
      "learning_rate": 1.1203614457831327e-05,
      "loss": 0.0297,
      "step": 73010
    },
    {
      "epoch": 8.797590361445783,
      "grad_norm": 0.0516149140894413,
      "learning_rate": 1.1202409638554216e-05,
      "loss": 0.0055,
      "step": 73020
    },
    {
      "epoch": 8.798795180722891,
      "grad_norm": 0.07316935062408447,
      "learning_rate": 1.1201204819277109e-05,
      "loss": 0.0237,
      "step": 73030
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.6173819303512573,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.013,
      "step": 73040
    },
    {
      "epoch": 8.801204819277109,
      "grad_norm": 47.71211624145508,
      "learning_rate": 1.1198795180722892e-05,
      "loss": 0.0096,
      "step": 73050
    },
    {
      "epoch": 8.802409638554217,
      "grad_norm": 1.206661581993103,
      "learning_rate": 1.1197590361445784e-05,
      "loss": 0.0302,
      "step": 73060
    },
    {
      "epoch": 8.803614457831326,
      "grad_norm": 0.0013391056563705206,
      "learning_rate": 1.1196385542168675e-05,
      "loss": 0.0149,
      "step": 73070
    },
    {
      "epoch": 8.804819277108434,
      "grad_norm": 0.6045482158660889,
      "learning_rate": 1.1195180722891568e-05,
      "loss": 0.0687,
      "step": 73080
    },
    {
      "epoch": 8.806024096385542,
      "grad_norm": 0.726990282535553,
      "learning_rate": 1.1193975903614458e-05,
      "loss": 0.0234,
      "step": 73090
    },
    {
      "epoch": 8.80722891566265,
      "grad_norm": 1.0930308103561401,
      "learning_rate": 1.119277108433735e-05,
      "loss": 0.0528,
      "step": 73100
    },
    {
      "epoch": 8.80843373493976,
      "grad_norm": 0.018470091745257378,
      "learning_rate": 1.1191566265060241e-05,
      "loss": 0.0229,
      "step": 73110
    },
    {
      "epoch": 8.809638554216868,
      "grad_norm": 0.33054694533348083,
      "learning_rate": 1.1190361445783134e-05,
      "loss": 0.032,
      "step": 73120
    },
    {
      "epoch": 8.810843373493976,
      "grad_norm": 0.21455255150794983,
      "learning_rate": 1.1189156626506026e-05,
      "loss": 0.0252,
      "step": 73130
    },
    {
      "epoch": 8.812048192771083,
      "grad_norm": 0.025106457993388176,
      "learning_rate": 1.1187951807228915e-05,
      "loss": 0.0419,
      "step": 73140
    },
    {
      "epoch": 8.813253012048193,
      "grad_norm": 0.026514137163758278,
      "learning_rate": 1.118674698795181e-05,
      "loss": 0.009,
      "step": 73150
    },
    {
      "epoch": 8.814457831325301,
      "grad_norm": 0.01680082455277443,
      "learning_rate": 1.1185542168674699e-05,
      "loss": 0.015,
      "step": 73160
    },
    {
      "epoch": 8.815662650602409,
      "grad_norm": 5.500860691070557,
      "learning_rate": 1.1184337349397591e-05,
      "loss": 0.0176,
      "step": 73170
    },
    {
      "epoch": 8.816867469879519,
      "grad_norm": 1.5257257223129272,
      "learning_rate": 1.1183132530120482e-05,
      "loss": 0.0233,
      "step": 73180
    },
    {
      "epoch": 8.818072289156627,
      "grad_norm": 0.1448400318622589,
      "learning_rate": 1.1181927710843374e-05,
      "loss": 0.0131,
      "step": 73190
    },
    {
      "epoch": 8.819277108433734,
      "grad_norm": 0.07416073232889175,
      "learning_rate": 1.1180722891566267e-05,
      "loss": 0.0148,
      "step": 73200
    },
    {
      "epoch": 8.820481927710844,
      "grad_norm": 0.7716382741928101,
      "learning_rate": 1.1179518072289157e-05,
      "loss": 0.0113,
      "step": 73210
    },
    {
      "epoch": 8.821686746987952,
      "grad_norm": 2.353508234024048,
      "learning_rate": 1.117831325301205e-05,
      "loss": 0.0394,
      "step": 73220
    },
    {
      "epoch": 8.82289156626506,
      "grad_norm": 0.5807902812957764,
      "learning_rate": 1.117710843373494e-05,
      "loss": 0.023,
      "step": 73230
    },
    {
      "epoch": 8.824096385542168,
      "grad_norm": 0.007647574879229069,
      "learning_rate": 1.1175903614457833e-05,
      "loss": 0.0026,
      "step": 73240
    },
    {
      "epoch": 8.825301204819278,
      "grad_norm": 0.009815230965614319,
      "learning_rate": 1.1174698795180724e-05,
      "loss": 0.0179,
      "step": 73250
    },
    {
      "epoch": 8.826506024096386,
      "grad_norm": 0.04534110799431801,
      "learning_rate": 1.1173493975903616e-05,
      "loss": 0.0208,
      "step": 73260
    },
    {
      "epoch": 8.827710843373493,
      "grad_norm": 0.2009229063987732,
      "learning_rate": 1.1172289156626509e-05,
      "loss": 0.002,
      "step": 73270
    },
    {
      "epoch": 8.828915662650603,
      "grad_norm": 0.004874749109148979,
      "learning_rate": 1.1171084337349398e-05,
      "loss": 0.012,
      "step": 73280
    },
    {
      "epoch": 8.830120481927711,
      "grad_norm": 3.3707854747772217,
      "learning_rate": 1.116987951807229e-05,
      "loss": 0.1172,
      "step": 73290
    },
    {
      "epoch": 8.831325301204819,
      "grad_norm": 0.0052934871055185795,
      "learning_rate": 1.116867469879518e-05,
      "loss": 0.0124,
      "step": 73300
    },
    {
      "epoch": 8.832530120481927,
      "grad_norm": 0.006462913937866688,
      "learning_rate": 1.1167469879518073e-05,
      "loss": 0.058,
      "step": 73310
    },
    {
      "epoch": 8.833734939759037,
      "grad_norm": 5.3391804695129395,
      "learning_rate": 1.1166265060240964e-05,
      "loss": 0.0999,
      "step": 73320
    },
    {
      "epoch": 8.834939759036144,
      "grad_norm": 0.01480876374989748,
      "learning_rate": 1.1165060240963856e-05,
      "loss": 0.0356,
      "step": 73330
    },
    {
      "epoch": 8.836144578313252,
      "grad_norm": 1.6309034824371338,
      "learning_rate": 1.1163855421686749e-05,
      "loss": 0.0418,
      "step": 73340
    },
    {
      "epoch": 8.837349397590362,
      "grad_norm": 0.04834011197090149,
      "learning_rate": 1.116265060240964e-05,
      "loss": 0.0575,
      "step": 73350
    },
    {
      "epoch": 8.83855421686747,
      "grad_norm": 0.6068279147148132,
      "learning_rate": 1.1161445783132532e-05,
      "loss": 0.0216,
      "step": 73360
    },
    {
      "epoch": 8.839759036144578,
      "grad_norm": 0.056940242648124695,
      "learning_rate": 1.1160240963855423e-05,
      "loss": 0.0325,
      "step": 73370
    },
    {
      "epoch": 8.840963855421688,
      "grad_norm": 0.007218953687697649,
      "learning_rate": 1.1159036144578315e-05,
      "loss": 0.0065,
      "step": 73380
    },
    {
      "epoch": 8.842168674698796,
      "grad_norm": 0.009718296118080616,
      "learning_rate": 1.1157831325301204e-05,
      "loss": 0.03,
      "step": 73390
    },
    {
      "epoch": 8.843373493975903,
      "grad_norm": 4.343705177307129,
      "learning_rate": 1.1156626506024097e-05,
      "loss": 0.0139,
      "step": 73400
    },
    {
      "epoch": 8.844578313253011,
      "grad_norm": 1.9902645349502563,
      "learning_rate": 1.1155421686746987e-05,
      "loss": 0.0104,
      "step": 73410
    },
    {
      "epoch": 8.845783132530121,
      "grad_norm": 0.005131545942276716,
      "learning_rate": 1.115421686746988e-05,
      "loss": 0.0077,
      "step": 73420
    },
    {
      "epoch": 8.846987951807229,
      "grad_norm": 0.0929257720708847,
      "learning_rate": 1.1153012048192772e-05,
      "loss": 0.0339,
      "step": 73430
    },
    {
      "epoch": 8.848192771084337,
      "grad_norm": 0.003651896957308054,
      "learning_rate": 1.1151807228915663e-05,
      "loss": 0.0309,
      "step": 73440
    },
    {
      "epoch": 8.849397590361447,
      "grad_norm": 0.01419298816472292,
      "learning_rate": 1.1150602409638555e-05,
      "loss": 0.0562,
      "step": 73450
    },
    {
      "epoch": 8.850602409638554,
      "grad_norm": 0.010842560790479183,
      "learning_rate": 1.1149397590361446e-05,
      "loss": 0.0354,
      "step": 73460
    },
    {
      "epoch": 8.851807228915662,
      "grad_norm": 0.004087734501808882,
      "learning_rate": 1.1148192771084339e-05,
      "loss": 0.0341,
      "step": 73470
    },
    {
      "epoch": 8.85301204819277,
      "grad_norm": 0.2594431936740875,
      "learning_rate": 1.114698795180723e-05,
      "loss": 0.0248,
      "step": 73480
    },
    {
      "epoch": 8.85421686746988,
      "grad_norm": 0.35834839940071106,
      "learning_rate": 1.1145783132530122e-05,
      "loss": 0.013,
      "step": 73490
    },
    {
      "epoch": 8.855421686746988,
      "grad_norm": 0.4635818898677826,
      "learning_rate": 1.1144578313253014e-05,
      "loss": 0.063,
      "step": 73500
    },
    {
      "epoch": 8.856626506024096,
      "grad_norm": 1.1305599212646484,
      "learning_rate": 1.1143373493975905e-05,
      "loss": 0.0328,
      "step": 73510
    },
    {
      "epoch": 8.857831325301206,
      "grad_norm": 0.048628393560647964,
      "learning_rate": 1.1142168674698797e-05,
      "loss": 0.0246,
      "step": 73520
    },
    {
      "epoch": 8.859036144578313,
      "grad_norm": 0.050961051136255264,
      "learning_rate": 1.1140963855421686e-05,
      "loss": 0.0271,
      "step": 73530
    },
    {
      "epoch": 8.860240963855421,
      "grad_norm": 0.007305837236344814,
      "learning_rate": 1.1139759036144579e-05,
      "loss": 0.021,
      "step": 73540
    },
    {
      "epoch": 8.861445783132531,
      "grad_norm": 1.3545136451721191,
      "learning_rate": 1.113855421686747e-05,
      "loss": 0.0384,
      "step": 73550
    },
    {
      "epoch": 8.862650602409639,
      "grad_norm": 0.01943618431687355,
      "learning_rate": 1.1137349397590362e-05,
      "loss": 0.0298,
      "step": 73560
    },
    {
      "epoch": 8.863855421686747,
      "grad_norm": 0.014323383569717407,
      "learning_rate": 1.1136144578313255e-05,
      "loss": 0.0068,
      "step": 73570
    },
    {
      "epoch": 8.865060240963855,
      "grad_norm": 1.238709807395935,
      "learning_rate": 1.1134939759036145e-05,
      "loss": 0.0125,
      "step": 73580
    },
    {
      "epoch": 8.866265060240965,
      "grad_norm": 0.06479625403881073,
      "learning_rate": 1.1133734939759038e-05,
      "loss": 0.0346,
      "step": 73590
    },
    {
      "epoch": 8.867469879518072,
      "grad_norm": 1.4585087299346924,
      "learning_rate": 1.1132530120481928e-05,
      "loss": 0.022,
      "step": 73600
    },
    {
      "epoch": 8.86867469879518,
      "grad_norm": 0.29433223605155945,
      "learning_rate": 1.1131325301204821e-05,
      "loss": 0.0219,
      "step": 73610
    },
    {
      "epoch": 8.869879518072288,
      "grad_norm": 3.053509473800659,
      "learning_rate": 1.1130120481927712e-05,
      "loss": 0.022,
      "step": 73620
    },
    {
      "epoch": 8.871084337349398,
      "grad_norm": 0.22175249457359314,
      "learning_rate": 1.1128915662650604e-05,
      "loss": 0.0615,
      "step": 73630
    },
    {
      "epoch": 8.872289156626506,
      "grad_norm": 1.3824907541275024,
      "learning_rate": 1.1127710843373496e-05,
      "loss": 0.0562,
      "step": 73640
    },
    {
      "epoch": 8.873493975903614,
      "grad_norm": 0.005596055183559656,
      "learning_rate": 1.1126506024096386e-05,
      "loss": 0.0586,
      "step": 73650
    },
    {
      "epoch": 8.874698795180723,
      "grad_norm": 0.39674362540245056,
      "learning_rate": 1.1125301204819278e-05,
      "loss": 0.0195,
      "step": 73660
    },
    {
      "epoch": 8.875903614457831,
      "grad_norm": 0.007249655667692423,
      "learning_rate": 1.1124096385542169e-05,
      "loss": 0.0296,
      "step": 73670
    },
    {
      "epoch": 8.87710843373494,
      "grad_norm": 0.05734092742204666,
      "learning_rate": 1.1122891566265061e-05,
      "loss": 0.048,
      "step": 73680
    },
    {
      "epoch": 8.878313253012049,
      "grad_norm": 1.525500774383545,
      "learning_rate": 1.1121686746987952e-05,
      "loss": 0.0307,
      "step": 73690
    },
    {
      "epoch": 8.879518072289157,
      "grad_norm": 1.1072134971618652,
      "learning_rate": 1.1120481927710844e-05,
      "loss": 0.0374,
      "step": 73700
    },
    {
      "epoch": 8.880722891566265,
      "grad_norm": 6.681790351867676,
      "learning_rate": 1.1119277108433735e-05,
      "loss": 0.0306,
      "step": 73710
    },
    {
      "epoch": 8.881927710843373,
      "grad_norm": 3.3779358863830566,
      "learning_rate": 1.1118072289156627e-05,
      "loss": 0.0587,
      "step": 73720
    },
    {
      "epoch": 8.883132530120482,
      "grad_norm": 0.004935238976031542,
      "learning_rate": 1.111686746987952e-05,
      "loss": 0.0097,
      "step": 73730
    },
    {
      "epoch": 8.88433734939759,
      "grad_norm": 0.30034294724464417,
      "learning_rate": 1.111566265060241e-05,
      "loss": 0.013,
      "step": 73740
    },
    {
      "epoch": 8.885542168674698,
      "grad_norm": 0.6315522789955139,
      "learning_rate": 1.1114457831325303e-05,
      "loss": 0.0298,
      "step": 73750
    },
    {
      "epoch": 8.886746987951808,
      "grad_norm": 0.4631602168083191,
      "learning_rate": 1.1113253012048192e-05,
      "loss": 0.0263,
      "step": 73760
    },
    {
      "epoch": 8.887951807228916,
      "grad_norm": 0.09545520693063736,
      "learning_rate": 1.1112048192771086e-05,
      "loss": 0.0468,
      "step": 73770
    },
    {
      "epoch": 8.889156626506024,
      "grad_norm": 4.431366443634033,
      "learning_rate": 1.1110843373493975e-05,
      "loss": 0.0398,
      "step": 73780
    },
    {
      "epoch": 8.890361445783132,
      "grad_norm": 0.0023978541139513254,
      "learning_rate": 1.1109638554216868e-05,
      "loss": 0.0018,
      "step": 73790
    },
    {
      "epoch": 8.891566265060241,
      "grad_norm": 0.032782066613435745,
      "learning_rate": 1.110843373493976e-05,
      "loss": 0.0144,
      "step": 73800
    },
    {
      "epoch": 8.89277108433735,
      "grad_norm": 0.0032760202884674072,
      "learning_rate": 1.1107228915662651e-05,
      "loss": 0.0213,
      "step": 73810
    },
    {
      "epoch": 8.893975903614457,
      "grad_norm": 0.0017945498693734407,
      "learning_rate": 1.1106024096385543e-05,
      "loss": 0.0472,
      "step": 73820
    },
    {
      "epoch": 8.895180722891567,
      "grad_norm": 0.9483346343040466,
      "learning_rate": 1.1104819277108434e-05,
      "loss": 0.0429,
      "step": 73830
    },
    {
      "epoch": 8.896385542168675,
      "grad_norm": 7.178430080413818,
      "learning_rate": 1.1103614457831327e-05,
      "loss": 0.0455,
      "step": 73840
    },
    {
      "epoch": 8.897590361445783,
      "grad_norm": 0.07420727610588074,
      "learning_rate": 1.1102409638554217e-05,
      "loss": 0.0439,
      "step": 73850
    },
    {
      "epoch": 8.898795180722892,
      "grad_norm": 2.118851900100708,
      "learning_rate": 1.110120481927711e-05,
      "loss": 0.0389,
      "step": 73860
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.0033321408554911613,
      "learning_rate": 1.1100000000000002e-05,
      "loss": 0.0187,
      "step": 73870
    },
    {
      "epoch": 8.901204819277108,
      "grad_norm": 0.019027549773454666,
      "learning_rate": 1.1098795180722893e-05,
      "loss": 0.0092,
      "step": 73880
    },
    {
      "epoch": 8.902409638554216,
      "grad_norm": 0.0023031849414110184,
      "learning_rate": 1.1097590361445785e-05,
      "loss": 0.007,
      "step": 73890
    },
    {
      "epoch": 8.903614457831326,
      "grad_norm": 0.06287974864244461,
      "learning_rate": 1.1096385542168674e-05,
      "loss": 0.1031,
      "step": 73900
    },
    {
      "epoch": 8.904819277108434,
      "grad_norm": 1.6834074258804321,
      "learning_rate": 1.1095180722891567e-05,
      "loss": 0.0217,
      "step": 73910
    },
    {
      "epoch": 8.906024096385542,
      "grad_norm": 0.09219557046890259,
      "learning_rate": 1.1093975903614458e-05,
      "loss": 0.0276,
      "step": 73920
    },
    {
      "epoch": 8.907228915662651,
      "grad_norm": 0.0959668830037117,
      "learning_rate": 1.109277108433735e-05,
      "loss": 0.0239,
      "step": 73930
    },
    {
      "epoch": 8.90843373493976,
      "grad_norm": 0.006715614814311266,
      "learning_rate": 1.1091566265060242e-05,
      "loss": 0.0185,
      "step": 73940
    },
    {
      "epoch": 8.909638554216867,
      "grad_norm": 3.6875410079956055,
      "learning_rate": 1.1090361445783133e-05,
      "loss": 0.0709,
      "step": 73950
    },
    {
      "epoch": 8.910843373493975,
      "grad_norm": 0.028398247435688972,
      "learning_rate": 1.1089156626506026e-05,
      "loss": 0.0397,
      "step": 73960
    },
    {
      "epoch": 8.912048192771085,
      "grad_norm": 0.06314077228307724,
      "learning_rate": 1.1087951807228916e-05,
      "loss": 0.0512,
      "step": 73970
    },
    {
      "epoch": 8.913253012048193,
      "grad_norm": 4.972898960113525,
      "learning_rate": 1.1086746987951809e-05,
      "loss": 0.0372,
      "step": 73980
    },
    {
      "epoch": 8.9144578313253,
      "grad_norm": 0.03311467543244362,
      "learning_rate": 1.10855421686747e-05,
      "loss": 0.0044,
      "step": 73990
    },
    {
      "epoch": 8.91566265060241,
      "grad_norm": 0.55925452709198,
      "learning_rate": 1.1084337349397592e-05,
      "loss": 0.0312,
      "step": 74000
    },
    {
      "epoch": 8.916867469879518,
      "grad_norm": 1.0435272455215454,
      "learning_rate": 1.1083132530120481e-05,
      "loss": 0.0335,
      "step": 74010
    },
    {
      "epoch": 8.918072289156626,
      "grad_norm": 0.9147468209266663,
      "learning_rate": 1.1081927710843373e-05,
      "loss": 0.0332,
      "step": 74020
    },
    {
      "epoch": 8.919277108433734,
      "grad_norm": 0.011350033804774284,
      "learning_rate": 1.1080722891566268e-05,
      "loss": 0.0521,
      "step": 74030
    },
    {
      "epoch": 8.920481927710844,
      "grad_norm": 0.017851468175649643,
      "learning_rate": 1.1079518072289157e-05,
      "loss": 0.0124,
      "step": 74040
    },
    {
      "epoch": 8.921686746987952,
      "grad_norm": 0.5239746570587158,
      "learning_rate": 1.1078313253012049e-05,
      "loss": 0.0099,
      "step": 74050
    },
    {
      "epoch": 8.92289156626506,
      "grad_norm": 0.03731749579310417,
      "learning_rate": 1.107710843373494e-05,
      "loss": 0.0066,
      "step": 74060
    },
    {
      "epoch": 8.92409638554217,
      "grad_norm": 0.13556790351867676,
      "learning_rate": 1.1075903614457832e-05,
      "loss": 0.0214,
      "step": 74070
    },
    {
      "epoch": 8.925301204819277,
      "grad_norm": 1.198362112045288,
      "learning_rate": 1.1074698795180723e-05,
      "loss": 0.0351,
      "step": 74080
    },
    {
      "epoch": 8.926506024096385,
      "grad_norm": 0.004720648750662804,
      "learning_rate": 1.1073493975903615e-05,
      "loss": 0.0478,
      "step": 74090
    },
    {
      "epoch": 8.927710843373493,
      "grad_norm": 0.31600233912467957,
      "learning_rate": 1.1072289156626508e-05,
      "loss": 0.0139,
      "step": 74100
    },
    {
      "epoch": 8.928915662650603,
      "grad_norm": 0.005077227484434843,
      "learning_rate": 1.1071084337349399e-05,
      "loss": 0.0274,
      "step": 74110
    },
    {
      "epoch": 8.93012048192771,
      "grad_norm": 0.002322545973584056,
      "learning_rate": 1.1069879518072291e-05,
      "loss": 0.0098,
      "step": 74120
    },
    {
      "epoch": 8.931325301204819,
      "grad_norm": 0.018594246357679367,
      "learning_rate": 1.1068674698795182e-05,
      "loss": 0.042,
      "step": 74130
    },
    {
      "epoch": 8.932530120481928,
      "grad_norm": 0.23370276391506195,
      "learning_rate": 1.1067469879518074e-05,
      "loss": 0.0279,
      "step": 74140
    },
    {
      "epoch": 8.933734939759036,
      "grad_norm": 0.0022769831120967865,
      "learning_rate": 1.1066265060240963e-05,
      "loss": 0.0424,
      "step": 74150
    },
    {
      "epoch": 8.934939759036144,
      "grad_norm": 3.798609733581543,
      "learning_rate": 1.1065060240963856e-05,
      "loss": 0.0461,
      "step": 74160
    },
    {
      "epoch": 8.936144578313254,
      "grad_norm": 0.018245328217744827,
      "learning_rate": 1.1063855421686748e-05,
      "loss": 0.005,
      "step": 74170
    },
    {
      "epoch": 8.937349397590362,
      "grad_norm": 0.39015471935272217,
      "learning_rate": 1.1062650602409639e-05,
      "loss": 0.0318,
      "step": 74180
    },
    {
      "epoch": 8.93855421686747,
      "grad_norm": 0.7989048957824707,
      "learning_rate": 1.1061445783132531e-05,
      "loss": 0.0077,
      "step": 74190
    },
    {
      "epoch": 8.939759036144578,
      "grad_norm": 0.0032635421957820654,
      "learning_rate": 1.1060240963855422e-05,
      "loss": 0.0223,
      "step": 74200
    },
    {
      "epoch": 8.940963855421687,
      "grad_norm": 0.22194191813468933,
      "learning_rate": 1.1059036144578314e-05,
      "loss": 0.001,
      "step": 74210
    },
    {
      "epoch": 8.942168674698795,
      "grad_norm": 0.0025366111658513546,
      "learning_rate": 1.1057831325301205e-05,
      "loss": 0.0041,
      "step": 74220
    },
    {
      "epoch": 8.943373493975903,
      "grad_norm": 0.9088259339332581,
      "learning_rate": 1.1056626506024098e-05,
      "loss": 0.0202,
      "step": 74230
    },
    {
      "epoch": 8.944578313253013,
      "grad_norm": 0.020840171724557877,
      "learning_rate": 1.105542168674699e-05,
      "loss": 0.0539,
      "step": 74240
    },
    {
      "epoch": 8.94578313253012,
      "grad_norm": 0.5829392671585083,
      "learning_rate": 1.105421686746988e-05,
      "loss": 0.071,
      "step": 74250
    },
    {
      "epoch": 8.946987951807229,
      "grad_norm": 0.03981463238596916,
      "learning_rate": 1.1053012048192773e-05,
      "loss": 0.0487,
      "step": 74260
    },
    {
      "epoch": 8.948192771084337,
      "grad_norm": 0.3823774456977844,
      "learning_rate": 1.1051807228915662e-05,
      "loss": 0.0454,
      "step": 74270
    },
    {
      "epoch": 8.949397590361446,
      "grad_norm": 0.00580235430970788,
      "learning_rate": 1.1050602409638556e-05,
      "loss": 0.0109,
      "step": 74280
    },
    {
      "epoch": 8.950602409638554,
      "grad_norm": 0.39193397760391235,
      "learning_rate": 1.1049397590361445e-05,
      "loss": 0.0059,
      "step": 74290
    },
    {
      "epoch": 8.951807228915662,
      "grad_norm": 0.9596139788627625,
      "learning_rate": 1.1048192771084338e-05,
      "loss": 0.0339,
      "step": 74300
    },
    {
      "epoch": 8.953012048192772,
      "grad_norm": 0.21202604472637177,
      "learning_rate": 1.1046987951807229e-05,
      "loss": 0.0317,
      "step": 74310
    },
    {
      "epoch": 8.95421686746988,
      "grad_norm": 6.18251371383667,
      "learning_rate": 1.1045783132530121e-05,
      "loss": 0.0176,
      "step": 74320
    },
    {
      "epoch": 8.955421686746988,
      "grad_norm": 1.0079277753829956,
      "learning_rate": 1.1044578313253013e-05,
      "loss": 0.0325,
      "step": 74330
    },
    {
      "epoch": 8.956626506024097,
      "grad_norm": 0.008362239226698875,
      "learning_rate": 1.1043373493975904e-05,
      "loss": 0.0122,
      "step": 74340
    },
    {
      "epoch": 8.957831325301205,
      "grad_norm": 0.003828003304079175,
      "learning_rate": 1.1042168674698797e-05,
      "loss": 0.0121,
      "step": 74350
    },
    {
      "epoch": 8.959036144578313,
      "grad_norm": 0.29556363821029663,
      "learning_rate": 1.1040963855421687e-05,
      "loss": 0.0237,
      "step": 74360
    },
    {
      "epoch": 8.960240963855421,
      "grad_norm": 1.9371086359024048,
      "learning_rate": 1.103975903614458e-05,
      "loss": 0.0145,
      "step": 74370
    },
    {
      "epoch": 8.96144578313253,
      "grad_norm": 0.0040934584103524685,
      "learning_rate": 1.103855421686747e-05,
      "loss": 0.0033,
      "step": 74380
    },
    {
      "epoch": 8.962650602409639,
      "grad_norm": 0.004178580828011036,
      "learning_rate": 1.1037349397590363e-05,
      "loss": 0.0599,
      "step": 74390
    },
    {
      "epoch": 8.963855421686747,
      "grad_norm": 7.431552886962891,
      "learning_rate": 1.1036144578313255e-05,
      "loss": 0.0877,
      "step": 74400
    },
    {
      "epoch": 8.965060240963856,
      "grad_norm": 0.011829049326479435,
      "learning_rate": 1.1034939759036145e-05,
      "loss": 0.0327,
      "step": 74410
    },
    {
      "epoch": 8.966265060240964,
      "grad_norm": 0.0059966640546917915,
      "learning_rate": 1.1033734939759037e-05,
      "loss": 0.0461,
      "step": 74420
    },
    {
      "epoch": 8.967469879518072,
      "grad_norm": 2.2873144149780273,
      "learning_rate": 1.1032530120481928e-05,
      "loss": 0.031,
      "step": 74430
    },
    {
      "epoch": 8.96867469879518,
      "grad_norm": 7.695131778717041,
      "learning_rate": 1.103132530120482e-05,
      "loss": 0.0323,
      "step": 74440
    },
    {
      "epoch": 8.96987951807229,
      "grad_norm": 0.003939181100577116,
      "learning_rate": 1.1030120481927711e-05,
      "loss": 0.0144,
      "step": 74450
    },
    {
      "epoch": 8.971084337349398,
      "grad_norm": 0.009347392246127129,
      "learning_rate": 1.1028915662650603e-05,
      "loss": 0.003,
      "step": 74460
    },
    {
      "epoch": 8.972289156626506,
      "grad_norm": 3.516535997390747,
      "learning_rate": 1.1027710843373496e-05,
      "loss": 0.03,
      "step": 74470
    },
    {
      "epoch": 8.973493975903615,
      "grad_norm": 1.8552409410476685,
      "learning_rate": 1.1026506024096386e-05,
      "loss": 0.0652,
      "step": 74480
    },
    {
      "epoch": 8.974698795180723,
      "grad_norm": 0.8804898858070374,
      "learning_rate": 1.1025301204819279e-05,
      "loss": 0.0131,
      "step": 74490
    },
    {
      "epoch": 8.975903614457831,
      "grad_norm": 0.009916872717440128,
      "learning_rate": 1.102409638554217e-05,
      "loss": 0.01,
      "step": 74500
    },
    {
      "epoch": 8.977108433734939,
      "grad_norm": 3.4447593688964844,
      "learning_rate": 1.1022891566265062e-05,
      "loss": 0.0202,
      "step": 74510
    },
    {
      "epoch": 8.978313253012049,
      "grad_norm": 0.04133832827210426,
      "learning_rate": 1.1021686746987951e-05,
      "loss": 0.0207,
      "step": 74520
    },
    {
      "epoch": 8.979518072289157,
      "grad_norm": 0.47993767261505127,
      "learning_rate": 1.1020481927710844e-05,
      "loss": 0.0051,
      "step": 74530
    },
    {
      "epoch": 8.980722891566264,
      "grad_norm": 1.4330835342407227,
      "learning_rate": 1.1019277108433738e-05,
      "loss": 0.0292,
      "step": 74540
    },
    {
      "epoch": 8.981927710843374,
      "grad_norm": 11.906010627746582,
      "learning_rate": 1.1018072289156627e-05,
      "loss": 0.0277,
      "step": 74550
    },
    {
      "epoch": 8.983132530120482,
      "grad_norm": 0.0019790728110820055,
      "learning_rate": 1.101686746987952e-05,
      "loss": 0.0349,
      "step": 74560
    },
    {
      "epoch": 8.98433734939759,
      "grad_norm": 1.1752756834030151,
      "learning_rate": 1.101566265060241e-05,
      "loss": 0.022,
      "step": 74570
    },
    {
      "epoch": 8.985542168674698,
      "grad_norm": 3.055047035217285,
      "learning_rate": 1.1014457831325302e-05,
      "loss": 0.0463,
      "step": 74580
    },
    {
      "epoch": 8.986746987951808,
      "grad_norm": 0.007864230312407017,
      "learning_rate": 1.1013253012048193e-05,
      "loss": 0.0418,
      "step": 74590
    },
    {
      "epoch": 8.987951807228916,
      "grad_norm": 0.00824837014079094,
      "learning_rate": 1.1012048192771086e-05,
      "loss": 0.0449,
      "step": 74600
    },
    {
      "epoch": 8.989156626506023,
      "grad_norm": 0.06106887757778168,
      "learning_rate": 1.1010843373493976e-05,
      "loss": 0.0542,
      "step": 74610
    },
    {
      "epoch": 8.990361445783133,
      "grad_norm": 0.11267798393964767,
      "learning_rate": 1.1009638554216869e-05,
      "loss": 0.0126,
      "step": 74620
    },
    {
      "epoch": 8.991566265060241,
      "grad_norm": 0.014935187064111233,
      "learning_rate": 1.1008433734939761e-05,
      "loss": 0.014,
      "step": 74630
    },
    {
      "epoch": 8.992771084337349,
      "grad_norm": 0.003394507570192218,
      "learning_rate": 1.1007228915662652e-05,
      "loss": 0.0138,
      "step": 74640
    },
    {
      "epoch": 8.993975903614459,
      "grad_norm": 0.0028634562622755766,
      "learning_rate": 1.1006024096385544e-05,
      "loss": 0.0031,
      "step": 74650
    },
    {
      "epoch": 8.995180722891567,
      "grad_norm": 0.9002321362495422,
      "learning_rate": 1.1004819277108433e-05,
      "loss": 0.0413,
      "step": 74660
    },
    {
      "epoch": 8.996385542168674,
      "grad_norm": 0.5372881889343262,
      "learning_rate": 1.1003614457831326e-05,
      "loss": 0.0241,
      "step": 74670
    },
    {
      "epoch": 8.997590361445782,
      "grad_norm": 0.12561750411987305,
      "learning_rate": 1.1002409638554217e-05,
      "loss": 0.0213,
      "step": 74680
    },
    {
      "epoch": 8.998795180722892,
      "grad_norm": 0.017851529642939568,
      "learning_rate": 1.1001204819277109e-05,
      "loss": 0.0695,
      "step": 74690
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.01451412495225668,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0218,
      "step": 74700
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9858689538807649,
      "eval_f1": 0.9626185605356146,
      "eval_loss": 0.051954660564661026,
      "eval_precision": 0.9656716417910448,
      "eval_recall": 0.9595847237671487,
      "eval_runtime": 3395.3602,
      "eval_samples_per_second": 12.573,
      "eval_steps_per_second": 0.524,
      "step": 74700
    },
    {
      "epoch": 9.001204819277108,
      "grad_norm": 0.012420405633747578,
      "learning_rate": 1.0998795180722892e-05,
      "loss": 0.0329,
      "step": 74710
    },
    {
      "epoch": 9.002409638554218,
      "grad_norm": 0.015275765210390091,
      "learning_rate": 1.0997590361445785e-05,
      "loss": 0.0227,
      "step": 74720
    },
    {
      "epoch": 9.003614457831326,
      "grad_norm": 0.10225459188222885,
      "learning_rate": 1.0996385542168675e-05,
      "loss": 0.0238,
      "step": 74730
    },
    {
      "epoch": 9.004819277108433,
      "grad_norm": 0.020430753007531166,
      "learning_rate": 1.0995180722891568e-05,
      "loss": 0.009,
      "step": 74740
    },
    {
      "epoch": 9.006024096385541,
      "grad_norm": 0.20723780989646912,
      "learning_rate": 1.0993975903614459e-05,
      "loss": 0.0127,
      "step": 74750
    },
    {
      "epoch": 9.007228915662651,
      "grad_norm": 1.431318998336792,
      "learning_rate": 1.0992771084337351e-05,
      "loss": 0.0436,
      "step": 74760
    },
    {
      "epoch": 9.008433734939759,
      "grad_norm": 0.026771187782287598,
      "learning_rate": 1.0991566265060243e-05,
      "loss": 0.0174,
      "step": 74770
    },
    {
      "epoch": 9.009638554216867,
      "grad_norm": 0.11651913076639175,
      "learning_rate": 1.0990361445783132e-05,
      "loss": 0.0252,
      "step": 74780
    },
    {
      "epoch": 9.010843373493977,
      "grad_norm": 0.003401004010811448,
      "learning_rate": 1.0989156626506025e-05,
      "loss": 0.032,
      "step": 74790
    },
    {
      "epoch": 9.012048192771084,
      "grad_norm": 2.8824000358581543,
      "learning_rate": 1.0987951807228916e-05,
      "loss": 0.0223,
      "step": 74800
    },
    {
      "epoch": 9.013253012048192,
      "grad_norm": 0.0024951433297246695,
      "learning_rate": 1.0986746987951808e-05,
      "loss": 0.0219,
      "step": 74810
    },
    {
      "epoch": 9.0144578313253,
      "grad_norm": 0.4060341417789459,
      "learning_rate": 1.0985542168674699e-05,
      "loss": 0.0292,
      "step": 74820
    },
    {
      "epoch": 9.01566265060241,
      "grad_norm": 0.0038956794887781143,
      "learning_rate": 1.0984337349397591e-05,
      "loss": 0.0191,
      "step": 74830
    },
    {
      "epoch": 9.016867469879518,
      "grad_norm": 0.38563764095306396,
      "learning_rate": 1.0983132530120484e-05,
      "loss": 0.0076,
      "step": 74840
    },
    {
      "epoch": 9.018072289156626,
      "grad_norm": 22.873836517333984,
      "learning_rate": 1.0981927710843374e-05,
      "loss": 0.0407,
      "step": 74850
    },
    {
      "epoch": 9.019277108433736,
      "grad_norm": 0.22041751444339752,
      "learning_rate": 1.0980722891566267e-05,
      "loss": 0.0057,
      "step": 74860
    },
    {
      "epoch": 9.020481927710843,
      "grad_norm": 0.0032591703347861767,
      "learning_rate": 1.0979518072289158e-05,
      "loss": 0.0038,
      "step": 74870
    },
    {
      "epoch": 9.021686746987951,
      "grad_norm": 0.0018123359186574817,
      "learning_rate": 1.097831325301205e-05,
      "loss": 0.0596,
      "step": 74880
    },
    {
      "epoch": 9.022891566265061,
      "grad_norm": 0.0020050466991961002,
      "learning_rate": 1.0977108433734939e-05,
      "loss": 0.0433,
      "step": 74890
    },
    {
      "epoch": 9.024096385542169,
      "grad_norm": 0.04152677580714226,
      "learning_rate": 1.0975903614457833e-05,
      "loss": 0.0181,
      "step": 74900
    },
    {
      "epoch": 9.025301204819277,
      "grad_norm": 3.109797954559326,
      "learning_rate": 1.0974698795180726e-05,
      "loss": 0.0227,
      "step": 74910
    },
    {
      "epoch": 9.026506024096385,
      "grad_norm": 0.004580517299473286,
      "learning_rate": 1.0973493975903615e-05,
      "loss": 0.0212,
      "step": 74920
    },
    {
      "epoch": 9.027710843373494,
      "grad_norm": 0.06838125735521317,
      "learning_rate": 1.0972289156626507e-05,
      "loss": 0.0438,
      "step": 74930
    },
    {
      "epoch": 9.028915662650602,
      "grad_norm": 0.016896603628993034,
      "learning_rate": 1.0971084337349398e-05,
      "loss": 0.0474,
      "step": 74940
    },
    {
      "epoch": 9.03012048192771,
      "grad_norm": 0.18370041251182556,
      "learning_rate": 1.096987951807229e-05,
      "loss": 0.0309,
      "step": 74950
    },
    {
      "epoch": 9.03132530120482,
      "grad_norm": 0.8856304883956909,
      "learning_rate": 1.0968674698795181e-05,
      "loss": 0.0204,
      "step": 74960
    },
    {
      "epoch": 9.032530120481928,
      "grad_norm": 0.006192934699356556,
      "learning_rate": 1.0967469879518073e-05,
      "loss": 0.0197,
      "step": 74970
    },
    {
      "epoch": 9.033734939759036,
      "grad_norm": 0.21862664818763733,
      "learning_rate": 1.0966265060240964e-05,
      "loss": 0.053,
      "step": 74980
    },
    {
      "epoch": 9.034939759036144,
      "grad_norm": 0.2763979136943817,
      "learning_rate": 1.0965060240963857e-05,
      "loss": 0.0148,
      "step": 74990
    },
    {
      "epoch": 9.036144578313253,
      "grad_norm": 0.1706501841545105,
      "learning_rate": 1.0963855421686749e-05,
      "loss": 0.001,
      "step": 75000
    },
    {
      "epoch": 9.037349397590361,
      "grad_norm": 0.007432860322296619,
      "learning_rate": 1.096265060240964e-05,
      "loss": 0.0186,
      "step": 75010
    },
    {
      "epoch": 9.03855421686747,
      "grad_norm": 0.13903622329235077,
      "learning_rate": 1.0961445783132532e-05,
      "loss": 0.0168,
      "step": 75020
    },
    {
      "epoch": 9.039759036144579,
      "grad_norm": 1.4923038482666016,
      "learning_rate": 1.0960240963855421e-05,
      "loss": 0.0601,
      "step": 75030
    },
    {
      "epoch": 9.040963855421687,
      "grad_norm": 0.008441196754574776,
      "learning_rate": 1.0959036144578314e-05,
      "loss": 0.003,
      "step": 75040
    },
    {
      "epoch": 9.042168674698795,
      "grad_norm": 0.7619799375534058,
      "learning_rate": 1.0957831325301204e-05,
      "loss": 0.0144,
      "step": 75050
    },
    {
      "epoch": 9.043373493975903,
      "grad_norm": 0.004994034767150879,
      "learning_rate": 1.0956626506024097e-05,
      "loss": 0.0095,
      "step": 75060
    },
    {
      "epoch": 9.044578313253012,
      "grad_norm": 0.5451416373252869,
      "learning_rate": 1.095542168674699e-05,
      "loss": 0.0213,
      "step": 75070
    },
    {
      "epoch": 9.04578313253012,
      "grad_norm": 0.0651465505361557,
      "learning_rate": 1.095421686746988e-05,
      "loss": 0.0119,
      "step": 75080
    },
    {
      "epoch": 9.046987951807228,
      "grad_norm": 3.6086015701293945,
      "learning_rate": 1.0953012048192772e-05,
      "loss": 0.0118,
      "step": 75090
    },
    {
      "epoch": 9.048192771084338,
      "grad_norm": 0.49799829721450806,
      "learning_rate": 1.0951807228915663e-05,
      "loss": 0.0178,
      "step": 75100
    },
    {
      "epoch": 9.049397590361446,
      "grad_norm": 0.015680670738220215,
      "learning_rate": 1.0950602409638556e-05,
      "loss": 0.0256,
      "step": 75110
    },
    {
      "epoch": 9.050602409638554,
      "grad_norm": 0.006135407369583845,
      "learning_rate": 1.0949397590361446e-05,
      "loss": 0.008,
      "step": 75120
    },
    {
      "epoch": 9.051807228915663,
      "grad_norm": 0.0010948675917461514,
      "learning_rate": 1.0948192771084339e-05,
      "loss": 0.0111,
      "step": 75130
    },
    {
      "epoch": 9.053012048192771,
      "grad_norm": 0.006290154065936804,
      "learning_rate": 1.0946987951807231e-05,
      "loss": 0.0464,
      "step": 75140
    },
    {
      "epoch": 9.05421686746988,
      "grad_norm": 0.02845216542482376,
      "learning_rate": 1.094578313253012e-05,
      "loss": 0.0104,
      "step": 75150
    },
    {
      "epoch": 9.055421686746987,
      "grad_norm": 0.010771618224680424,
      "learning_rate": 1.0944578313253014e-05,
      "loss": 0.0349,
      "step": 75160
    },
    {
      "epoch": 9.056626506024097,
      "grad_norm": 0.0016590928426012397,
      "learning_rate": 1.0943373493975904e-05,
      "loss": 0.0198,
      "step": 75170
    },
    {
      "epoch": 9.057831325301205,
      "grad_norm": 0.003021989483386278,
      "learning_rate": 1.0942168674698796e-05,
      "loss": 0.0051,
      "step": 75180
    },
    {
      "epoch": 9.059036144578313,
      "grad_norm": 2.4292259216308594,
      "learning_rate": 1.0940963855421687e-05,
      "loss": 0.0304,
      "step": 75190
    },
    {
      "epoch": 9.060240963855422,
      "grad_norm": 0.9479840993881226,
      "learning_rate": 1.0939759036144579e-05,
      "loss": 0.0279,
      "step": 75200
    },
    {
      "epoch": 9.06144578313253,
      "grad_norm": 0.06904903054237366,
      "learning_rate": 1.0938554216867472e-05,
      "loss": 0.0114,
      "step": 75210
    },
    {
      "epoch": 9.062650602409638,
      "grad_norm": 0.100618377327919,
      "learning_rate": 1.0937349397590362e-05,
      "loss": 0.0295,
      "step": 75220
    },
    {
      "epoch": 9.063855421686746,
      "grad_norm": 0.0483502596616745,
      "learning_rate": 1.0936144578313255e-05,
      "loss": 0.0125,
      "step": 75230
    },
    {
      "epoch": 9.065060240963856,
      "grad_norm": 2.166463613510132,
      "learning_rate": 1.0934939759036145e-05,
      "loss": 0.0281,
      "step": 75240
    },
    {
      "epoch": 9.066265060240964,
      "grad_norm": 0.001089391764253378,
      "learning_rate": 1.0933734939759038e-05,
      "loss": 0.0081,
      "step": 75250
    },
    {
      "epoch": 9.067469879518072,
      "grad_norm": 0.3067939281463623,
      "learning_rate": 1.0932530120481929e-05,
      "loss": 0.0225,
      "step": 75260
    },
    {
      "epoch": 9.068674698795181,
      "grad_norm": 0.91144198179245,
      "learning_rate": 1.0931325301204821e-05,
      "loss": 0.0181,
      "step": 75270
    },
    {
      "epoch": 9.06987951807229,
      "grad_norm": 0.23179134726524353,
      "learning_rate": 1.093012048192771e-05,
      "loss": 0.0079,
      "step": 75280
    },
    {
      "epoch": 9.071084337349397,
      "grad_norm": 4.313777923583984,
      "learning_rate": 1.0928915662650603e-05,
      "loss": 0.0308,
      "step": 75290
    },
    {
      "epoch": 9.072289156626505,
      "grad_norm": 0.0017904697451740503,
      "learning_rate": 1.0927710843373495e-05,
      "loss": 0.012,
      "step": 75300
    },
    {
      "epoch": 9.073493975903615,
      "grad_norm": 0.0007685531745664775,
      "learning_rate": 1.0926506024096386e-05,
      "loss": 0.0263,
      "step": 75310
    },
    {
      "epoch": 9.074698795180723,
      "grad_norm": 1.0050904750823975,
      "learning_rate": 1.0925301204819278e-05,
      "loss": 0.0247,
      "step": 75320
    },
    {
      "epoch": 9.07590361445783,
      "grad_norm": 1.157563328742981,
      "learning_rate": 1.0924096385542169e-05,
      "loss": 0.0059,
      "step": 75330
    },
    {
      "epoch": 9.07710843373494,
      "grad_norm": 0.6763142347335815,
      "learning_rate": 1.0922891566265061e-05,
      "loss": 0.0932,
      "step": 75340
    },
    {
      "epoch": 9.078313253012048,
      "grad_norm": 0.0008065855363383889,
      "learning_rate": 1.0921686746987952e-05,
      "loss": 0.0183,
      "step": 75350
    },
    {
      "epoch": 9.079518072289156,
      "grad_norm": 0.008436374366283417,
      "learning_rate": 1.0920481927710845e-05,
      "loss": 0.0421,
      "step": 75360
    },
    {
      "epoch": 9.080722891566266,
      "grad_norm": 0.0008279348840005696,
      "learning_rate": 1.0919277108433737e-05,
      "loss": 0.002,
      "step": 75370
    },
    {
      "epoch": 9.081927710843374,
      "grad_norm": 2.344787836074829,
      "learning_rate": 1.0918072289156628e-05,
      "loss": 0.0593,
      "step": 75380
    },
    {
      "epoch": 9.083132530120482,
      "grad_norm": 0.988639235496521,
      "learning_rate": 1.091686746987952e-05,
      "loss": 0.0266,
      "step": 75390
    },
    {
      "epoch": 9.08433734939759,
      "grad_norm": 0.0013471896527335048,
      "learning_rate": 1.091566265060241e-05,
      "loss": 0.0058,
      "step": 75400
    },
    {
      "epoch": 9.0855421686747,
      "grad_norm": 0.0014693503035232425,
      "learning_rate": 1.0914457831325302e-05,
      "loss": 0.0302,
      "step": 75410
    },
    {
      "epoch": 9.086746987951807,
      "grad_norm": 0.0017851238371804357,
      "learning_rate": 1.0913253012048192e-05,
      "loss": 0.0165,
      "step": 75420
    },
    {
      "epoch": 9.087951807228915,
      "grad_norm": 0.0014960560947656631,
      "learning_rate": 1.0912048192771085e-05,
      "loss": 0.0049,
      "step": 75430
    },
    {
      "epoch": 9.089156626506025,
      "grad_norm": 19.79329490661621,
      "learning_rate": 1.0910843373493977e-05,
      "loss": 0.0282,
      "step": 75440
    },
    {
      "epoch": 9.090361445783133,
      "grad_norm": 2.1251049041748047,
      "learning_rate": 1.0909638554216868e-05,
      "loss": 0.0605,
      "step": 75450
    },
    {
      "epoch": 9.09156626506024,
      "grad_norm": 0.9894993305206299,
      "learning_rate": 1.090843373493976e-05,
      "loss": 0.0119,
      "step": 75460
    },
    {
      "epoch": 9.092771084337349,
      "grad_norm": 0.0025577552150934935,
      "learning_rate": 1.0907228915662651e-05,
      "loss": 0.0383,
      "step": 75470
    },
    {
      "epoch": 9.093975903614458,
      "grad_norm": 0.0031889802776277065,
      "learning_rate": 1.0906024096385544e-05,
      "loss": 0.0235,
      "step": 75480
    },
    {
      "epoch": 9.095180722891566,
      "grad_norm": 1.0255835056304932,
      "learning_rate": 1.0904819277108434e-05,
      "loss": 0.0257,
      "step": 75490
    },
    {
      "epoch": 9.096385542168674,
      "grad_norm": 0.5523786544799805,
      "learning_rate": 1.0903614457831327e-05,
      "loss": 0.0225,
      "step": 75500
    },
    {
      "epoch": 9.097590361445784,
      "grad_norm": 0.00184361741412431,
      "learning_rate": 1.090240963855422e-05,
      "loss": 0.0089,
      "step": 75510
    },
    {
      "epoch": 9.098795180722892,
      "grad_norm": 0.0011542646680027246,
      "learning_rate": 1.090120481927711e-05,
      "loss": 0.0086,
      "step": 75520
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.3011820316314697,
      "learning_rate": 1.0900000000000002e-05,
      "loss": 0.0096,
      "step": 75530
    },
    {
      "epoch": 9.101204819277108,
      "grad_norm": 0.5093593597412109,
      "learning_rate": 1.0898795180722891e-05,
      "loss": 0.021,
      "step": 75540
    },
    {
      "epoch": 9.102409638554217,
      "grad_norm": 0.0013242573477327824,
      "learning_rate": 1.0897590361445784e-05,
      "loss": 0.0484,
      "step": 75550
    },
    {
      "epoch": 9.103614457831325,
      "grad_norm": 0.0041799722239375114,
      "learning_rate": 1.0896385542168675e-05,
      "loss": 0.0352,
      "step": 75560
    },
    {
      "epoch": 9.104819277108433,
      "grad_norm": 0.0013908393448218703,
      "learning_rate": 1.0895180722891567e-05,
      "loss": 0.0329,
      "step": 75570
    },
    {
      "epoch": 9.106024096385543,
      "grad_norm": 0.054969459772109985,
      "learning_rate": 1.0893975903614458e-05,
      "loss": 0.044,
      "step": 75580
    },
    {
      "epoch": 9.10722891566265,
      "grad_norm": 1.3351038694381714,
      "learning_rate": 1.089277108433735e-05,
      "loss": 0.0452,
      "step": 75590
    },
    {
      "epoch": 9.108433734939759,
      "grad_norm": 0.19010835886001587,
      "learning_rate": 1.0891566265060243e-05,
      "loss": 0.0221,
      "step": 75600
    },
    {
      "epoch": 9.109638554216868,
      "grad_norm": 0.0026131102349609137,
      "learning_rate": 1.0890361445783133e-05,
      "loss": 0.01,
      "step": 75610
    },
    {
      "epoch": 9.110843373493976,
      "grad_norm": 0.023813409730792046,
      "learning_rate": 1.0889156626506026e-05,
      "loss": 0.0855,
      "step": 75620
    },
    {
      "epoch": 9.112048192771084,
      "grad_norm": 0.06769820302724838,
      "learning_rate": 1.0887951807228917e-05,
      "loss": 0.0607,
      "step": 75630
    },
    {
      "epoch": 9.113253012048192,
      "grad_norm": 0.02932753600180149,
      "learning_rate": 1.0886746987951809e-05,
      "loss": 0.0043,
      "step": 75640
    },
    {
      "epoch": 9.114457831325302,
      "grad_norm": 0.011811356991529465,
      "learning_rate": 1.0885542168674698e-05,
      "loss": 0.0027,
      "step": 75650
    },
    {
      "epoch": 9.11566265060241,
      "grad_norm": 0.010538196191191673,
      "learning_rate": 1.088433734939759e-05,
      "loss": 0.0112,
      "step": 75660
    },
    {
      "epoch": 9.116867469879518,
      "grad_norm": 0.09465508162975311,
      "learning_rate": 1.0883132530120485e-05,
      "loss": 0.0258,
      "step": 75670
    },
    {
      "epoch": 9.118072289156627,
      "grad_norm": 0.3284513056278229,
      "learning_rate": 1.0881927710843374e-05,
      "loss": 0.0028,
      "step": 75680
    },
    {
      "epoch": 9.119277108433735,
      "grad_norm": 3.596925973892212,
      "learning_rate": 1.0880722891566266e-05,
      "loss": 0.0315,
      "step": 75690
    },
    {
      "epoch": 9.120481927710843,
      "grad_norm": 0.020884521305561066,
      "learning_rate": 1.0879518072289157e-05,
      "loss": 0.068,
      "step": 75700
    },
    {
      "epoch": 9.121686746987951,
      "grad_norm": 0.9810687303543091,
      "learning_rate": 1.087831325301205e-05,
      "loss": 0.0214,
      "step": 75710
    },
    {
      "epoch": 9.12289156626506,
      "grad_norm": 2.1879537105560303,
      "learning_rate": 1.087710843373494e-05,
      "loss": 0.0728,
      "step": 75720
    },
    {
      "epoch": 9.124096385542169,
      "grad_norm": 0.05560874938964844,
      "learning_rate": 1.0875903614457832e-05,
      "loss": 0.0371,
      "step": 75730
    },
    {
      "epoch": 9.125301204819277,
      "grad_norm": 0.07317749410867691,
      "learning_rate": 1.0874698795180725e-05,
      "loss": 0.0165,
      "step": 75740
    },
    {
      "epoch": 9.126506024096386,
      "grad_norm": 5.433016777038574,
      "learning_rate": 1.0873493975903616e-05,
      "loss": 0.0083,
      "step": 75750
    },
    {
      "epoch": 9.127710843373494,
      "grad_norm": 0.020238058641552925,
      "learning_rate": 1.0872289156626508e-05,
      "loss": 0.0266,
      "step": 75760
    },
    {
      "epoch": 9.128915662650602,
      "grad_norm": 2.765846014022827,
      "learning_rate": 1.0871084337349399e-05,
      "loss": 0.0298,
      "step": 75770
    },
    {
      "epoch": 9.13012048192771,
      "grad_norm": 0.013919363729655743,
      "learning_rate": 1.0869879518072291e-05,
      "loss": 0.0775,
      "step": 75780
    },
    {
      "epoch": 9.13132530120482,
      "grad_norm": 0.01347700972110033,
      "learning_rate": 1.086867469879518e-05,
      "loss": 0.0063,
      "step": 75790
    },
    {
      "epoch": 9.132530120481928,
      "grad_norm": 1.652733325958252,
      "learning_rate": 1.0867469879518073e-05,
      "loss": 0.0182,
      "step": 75800
    },
    {
      "epoch": 9.133734939759035,
      "grad_norm": 4.060873508453369,
      "learning_rate": 1.0866265060240965e-05,
      "loss": 0.0961,
      "step": 75810
    },
    {
      "epoch": 9.134939759036145,
      "grad_norm": 1.151868224143982,
      "learning_rate": 1.0865060240963856e-05,
      "loss": 0.0037,
      "step": 75820
    },
    {
      "epoch": 9.136144578313253,
      "grad_norm": 1.5192184448242188,
      "learning_rate": 1.0863855421686748e-05,
      "loss": 0.0616,
      "step": 75830
    },
    {
      "epoch": 9.137349397590361,
      "grad_norm": 0.014748829416930676,
      "learning_rate": 1.0862650602409639e-05,
      "loss": 0.0153,
      "step": 75840
    },
    {
      "epoch": 9.13855421686747,
      "grad_norm": 1.9915168285369873,
      "learning_rate": 1.0861445783132531e-05,
      "loss": 0.0294,
      "step": 75850
    },
    {
      "epoch": 9.139759036144579,
      "grad_norm": 0.20213110744953156,
      "learning_rate": 1.0860240963855422e-05,
      "loss": 0.0268,
      "step": 75860
    },
    {
      "epoch": 9.140963855421687,
      "grad_norm": 1.0353140830993652,
      "learning_rate": 1.0859036144578315e-05,
      "loss": 0.061,
      "step": 75870
    },
    {
      "epoch": 9.142168674698794,
      "grad_norm": 8.738276481628418,
      "learning_rate": 1.0857831325301205e-05,
      "loss": 0.0206,
      "step": 75880
    },
    {
      "epoch": 9.143373493975904,
      "grad_norm": 0.0077339280396699905,
      "learning_rate": 1.0856626506024098e-05,
      "loss": 0.0194,
      "step": 75890
    },
    {
      "epoch": 9.144578313253012,
      "grad_norm": 0.1680828183889389,
      "learning_rate": 1.085542168674699e-05,
      "loss": 0.0188,
      "step": 75900
    },
    {
      "epoch": 9.14578313253012,
      "grad_norm": 4.165250778198242,
      "learning_rate": 1.085421686746988e-05,
      "loss": 0.0819,
      "step": 75910
    },
    {
      "epoch": 9.14698795180723,
      "grad_norm": 0.47658026218414307,
      "learning_rate": 1.0853012048192772e-05,
      "loss": 0.0509,
      "step": 75920
    },
    {
      "epoch": 9.148192771084338,
      "grad_norm": 4.055749893188477,
      "learning_rate": 1.0851807228915662e-05,
      "loss": 0.0267,
      "step": 75930
    },
    {
      "epoch": 9.149397590361446,
      "grad_norm": 0.024383045732975006,
      "learning_rate": 1.0850602409638555e-05,
      "loss": 0.008,
      "step": 75940
    },
    {
      "epoch": 9.150602409638553,
      "grad_norm": 3.219089984893799,
      "learning_rate": 1.0849397590361446e-05,
      "loss": 0.0391,
      "step": 75950
    },
    {
      "epoch": 9.151807228915663,
      "grad_norm": 0.17134760320186615,
      "learning_rate": 1.0848192771084338e-05,
      "loss": 0.0504,
      "step": 75960
    },
    {
      "epoch": 9.153012048192771,
      "grad_norm": 0.03987080603837967,
      "learning_rate": 1.084698795180723e-05,
      "loss": 0.0181,
      "step": 75970
    },
    {
      "epoch": 9.154216867469879,
      "grad_norm": 0.049321334809064865,
      "learning_rate": 1.0845783132530121e-05,
      "loss": 0.0039,
      "step": 75980
    },
    {
      "epoch": 9.155421686746989,
      "grad_norm": 0.007716392632573843,
      "learning_rate": 1.0844578313253014e-05,
      "loss": 0.014,
      "step": 75990
    },
    {
      "epoch": 9.156626506024097,
      "grad_norm": 0.7201724052429199,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 0.0358,
      "step": 76000
    },
    {
      "epoch": 9.157831325301204,
      "grad_norm": 3.1190717220306396,
      "learning_rate": 1.0842168674698797e-05,
      "loss": 0.0478,
      "step": 76010
    },
    {
      "epoch": 9.159036144578312,
      "grad_norm": 0.725653350353241,
      "learning_rate": 1.0840963855421686e-05,
      "loss": 0.0127,
      "step": 76020
    },
    {
      "epoch": 9.160240963855422,
      "grad_norm": 5.597095012664795,
      "learning_rate": 1.083975903614458e-05,
      "loss": 0.0253,
      "step": 76030
    },
    {
      "epoch": 9.16144578313253,
      "grad_norm": 1.5847216844558716,
      "learning_rate": 1.0838554216867473e-05,
      "loss": 0.0268,
      "step": 76040
    },
    {
      "epoch": 9.162650602409638,
      "grad_norm": 0.017568303272128105,
      "learning_rate": 1.0837349397590362e-05,
      "loss": 0.0373,
      "step": 76050
    },
    {
      "epoch": 9.163855421686748,
      "grad_norm": 0.5021761655807495,
      "learning_rate": 1.0836144578313254e-05,
      "loss": 0.0197,
      "step": 76060
    },
    {
      "epoch": 9.165060240963856,
      "grad_norm": 2.293483257293701,
      "learning_rate": 1.0834939759036145e-05,
      "loss": 0.0494,
      "step": 76070
    },
    {
      "epoch": 9.166265060240963,
      "grad_norm": 0.02316347323358059,
      "learning_rate": 1.0833734939759037e-05,
      "loss": 0.0144,
      "step": 76080
    },
    {
      "epoch": 9.167469879518073,
      "grad_norm": 0.1160978153347969,
      "learning_rate": 1.0832530120481928e-05,
      "loss": 0.0454,
      "step": 76090
    },
    {
      "epoch": 9.168674698795181,
      "grad_norm": 3.3891489505767822,
      "learning_rate": 1.083132530120482e-05,
      "loss": 0.0181,
      "step": 76100
    },
    {
      "epoch": 9.169879518072289,
      "grad_norm": 0.12360935658216476,
      "learning_rate": 1.0830120481927713e-05,
      "loss": 0.0547,
      "step": 76110
    },
    {
      "epoch": 9.171084337349397,
      "grad_norm": 0.5319573879241943,
      "learning_rate": 1.0828915662650604e-05,
      "loss": 0.0445,
      "step": 76120
    },
    {
      "epoch": 9.172289156626507,
      "grad_norm": 0.5094854831695557,
      "learning_rate": 1.0827710843373496e-05,
      "loss": 0.0129,
      "step": 76130
    },
    {
      "epoch": 9.173493975903614,
      "grad_norm": 0.0013466236414387822,
      "learning_rate": 1.0826506024096387e-05,
      "loss": 0.0149,
      "step": 76140
    },
    {
      "epoch": 9.174698795180722,
      "grad_norm": 0.02966923825442791,
      "learning_rate": 1.0825301204819279e-05,
      "loss": 0.0108,
      "step": 76150
    },
    {
      "epoch": 9.175903614457832,
      "grad_norm": 0.6904242038726807,
      "learning_rate": 1.0824096385542168e-05,
      "loss": 0.0081,
      "step": 76160
    },
    {
      "epoch": 9.17710843373494,
      "grad_norm": 0.0014391522854566574,
      "learning_rate": 1.082289156626506e-05,
      "loss": 0.0043,
      "step": 76170
    },
    {
      "epoch": 9.178313253012048,
      "grad_norm": 1.1787710189819336,
      "learning_rate": 1.0821686746987951e-05,
      "loss": 0.0239,
      "step": 76180
    },
    {
      "epoch": 9.179518072289156,
      "grad_norm": 0.0013756538974121213,
      "learning_rate": 1.0820481927710844e-05,
      "loss": 0.0022,
      "step": 76190
    },
    {
      "epoch": 9.180722891566266,
      "grad_norm": 0.9631059765815735,
      "learning_rate": 1.0819277108433736e-05,
      "loss": 0.1497,
      "step": 76200
    },
    {
      "epoch": 9.181927710843373,
      "grad_norm": 0.08184084296226501,
      "learning_rate": 1.0818072289156627e-05,
      "loss": 0.0604,
      "step": 76210
    },
    {
      "epoch": 9.183132530120481,
      "grad_norm": 0.23930615186691284,
      "learning_rate": 1.081686746987952e-05,
      "loss": 0.0017,
      "step": 76220
    },
    {
      "epoch": 9.184337349397591,
      "grad_norm": 0.5451862215995789,
      "learning_rate": 1.081566265060241e-05,
      "loss": 0.0293,
      "step": 76230
    },
    {
      "epoch": 9.185542168674699,
      "grad_norm": 3.1604490280151367,
      "learning_rate": 1.0814457831325303e-05,
      "loss": 0.015,
      "step": 76240
    },
    {
      "epoch": 9.186746987951807,
      "grad_norm": 0.019011978060007095,
      "learning_rate": 1.0813253012048193e-05,
      "loss": 0.0287,
      "step": 76250
    },
    {
      "epoch": 9.187951807228915,
      "grad_norm": 0.6286044716835022,
      "learning_rate": 1.0812048192771086e-05,
      "loss": 0.004,
      "step": 76260
    },
    {
      "epoch": 9.189156626506024,
      "grad_norm": 0.12668661773204803,
      "learning_rate": 1.0810843373493978e-05,
      "loss": 0.0662,
      "step": 76270
    },
    {
      "epoch": 9.190361445783132,
      "grad_norm": 0.02309115044772625,
      "learning_rate": 1.0809638554216867e-05,
      "loss": 0.0144,
      "step": 76280
    },
    {
      "epoch": 9.19156626506024,
      "grad_norm": 0.03930255025625229,
      "learning_rate": 1.0808433734939761e-05,
      "loss": 0.0185,
      "step": 76290
    },
    {
      "epoch": 9.19277108433735,
      "grad_norm": 0.018836719915270805,
      "learning_rate": 1.080722891566265e-05,
      "loss": 0.019,
      "step": 76300
    },
    {
      "epoch": 9.193975903614458,
      "grad_norm": 0.22312115132808685,
      "learning_rate": 1.0806024096385543e-05,
      "loss": 0.0118,
      "step": 76310
    },
    {
      "epoch": 9.195180722891566,
      "grad_norm": 0.05414561182260513,
      "learning_rate": 1.0804819277108434e-05,
      "loss": 0.0224,
      "step": 76320
    },
    {
      "epoch": 9.196385542168676,
      "grad_norm": 0.6030319333076477,
      "learning_rate": 1.0803614457831326e-05,
      "loss": 0.0401,
      "step": 76330
    },
    {
      "epoch": 9.197590361445783,
      "grad_norm": 1.0822361707687378,
      "learning_rate": 1.0802409638554218e-05,
      "loss": 0.0054,
      "step": 76340
    },
    {
      "epoch": 9.198795180722891,
      "grad_norm": 0.27582427859306335,
      "learning_rate": 1.080120481927711e-05,
      "loss": 0.0023,
      "step": 76350
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.10777952522039413,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.0737,
      "step": 76360
    },
    {
      "epoch": 9.201204819277109,
      "grad_norm": 12.907868385314941,
      "learning_rate": 1.0798795180722892e-05,
      "loss": 0.0227,
      "step": 76370
    },
    {
      "epoch": 9.202409638554217,
      "grad_norm": 9.654050827026367,
      "learning_rate": 1.0797590361445785e-05,
      "loss": 0.0365,
      "step": 76380
    },
    {
      "epoch": 9.203614457831325,
      "grad_norm": 0.020515887066721916,
      "learning_rate": 1.0796385542168676e-05,
      "loss": 0.0076,
      "step": 76390
    },
    {
      "epoch": 9.204819277108435,
      "grad_norm": 1.3849947452545166,
      "learning_rate": 1.0795180722891568e-05,
      "loss": 0.0492,
      "step": 76400
    },
    {
      "epoch": 9.206024096385542,
      "grad_norm": 0.040126800537109375,
      "learning_rate": 1.079397590361446e-05,
      "loss": 0.0278,
      "step": 76410
    },
    {
      "epoch": 9.20722891566265,
      "grad_norm": 8.194124221801758,
      "learning_rate": 1.079277108433735e-05,
      "loss": 0.0192,
      "step": 76420
    },
    {
      "epoch": 9.208433734939758,
      "grad_norm": 0.05633336305618286,
      "learning_rate": 1.0791566265060242e-05,
      "loss": 0.0468,
      "step": 76430
    },
    {
      "epoch": 9.209638554216868,
      "grad_norm": 2.321105718612671,
      "learning_rate": 1.0790361445783133e-05,
      "loss": 0.0272,
      "step": 76440
    },
    {
      "epoch": 9.210843373493976,
      "grad_norm": 0.2885255813598633,
      "learning_rate": 1.0789156626506025e-05,
      "loss": 0.022,
      "step": 76450
    },
    {
      "epoch": 9.212048192771084,
      "grad_norm": 12.22909927368164,
      "learning_rate": 1.0787951807228916e-05,
      "loss": 0.0844,
      "step": 76460
    },
    {
      "epoch": 9.213253012048193,
      "grad_norm": 0.3471025228500366,
      "learning_rate": 1.0786746987951808e-05,
      "loss": 0.0341,
      "step": 76470
    },
    {
      "epoch": 9.214457831325301,
      "grad_norm": 0.586617648601532,
      "learning_rate": 1.0785542168674699e-05,
      "loss": 0.0297,
      "step": 76480
    },
    {
      "epoch": 9.21566265060241,
      "grad_norm": 1.4012612104415894,
      "learning_rate": 1.0784337349397591e-05,
      "loss": 0.03,
      "step": 76490
    },
    {
      "epoch": 9.216867469879517,
      "grad_norm": 1.2613824605941772,
      "learning_rate": 1.0783132530120484e-05,
      "loss": 0.0191,
      "step": 76500
    },
    {
      "epoch": 9.218072289156627,
      "grad_norm": 1.5016759634017944,
      "learning_rate": 1.0781927710843375e-05,
      "loss": 0.0133,
      "step": 76510
    },
    {
      "epoch": 9.219277108433735,
      "grad_norm": 9.062501907348633,
      "learning_rate": 1.0780722891566267e-05,
      "loss": 0.0582,
      "step": 76520
    },
    {
      "epoch": 9.220481927710843,
      "grad_norm": 0.0031321498099714518,
      "learning_rate": 1.0779518072289156e-05,
      "loss": 0.0168,
      "step": 76530
    },
    {
      "epoch": 9.221686746987952,
      "grad_norm": 2.8513267040252686,
      "learning_rate": 1.0778313253012049e-05,
      "loss": 0.0096,
      "step": 76540
    },
    {
      "epoch": 9.22289156626506,
      "grad_norm": 0.4327116012573242,
      "learning_rate": 1.077710843373494e-05,
      "loss": 0.0079,
      "step": 76550
    },
    {
      "epoch": 9.224096385542168,
      "grad_norm": 0.028302419930696487,
      "learning_rate": 1.0775903614457832e-05,
      "loss": 0.0075,
      "step": 76560
    },
    {
      "epoch": 9.225301204819278,
      "grad_norm": 0.0024026338942348957,
      "learning_rate": 1.0774698795180724e-05,
      "loss": 0.0121,
      "step": 76570
    },
    {
      "epoch": 9.226506024096386,
      "grad_norm": 0.004240833222866058,
      "learning_rate": 1.0773493975903615e-05,
      "loss": 0.0728,
      "step": 76580
    },
    {
      "epoch": 9.227710843373494,
      "grad_norm": 0.38263535499572754,
      "learning_rate": 1.0772289156626507e-05,
      "loss": 0.0103,
      "step": 76590
    },
    {
      "epoch": 9.228915662650602,
      "grad_norm": 0.6223940849304199,
      "learning_rate": 1.0771084337349398e-05,
      "loss": 0.0298,
      "step": 76600
    },
    {
      "epoch": 9.230120481927711,
      "grad_norm": 0.40634438395500183,
      "learning_rate": 1.076987951807229e-05,
      "loss": 0.0092,
      "step": 76610
    },
    {
      "epoch": 9.23132530120482,
      "grad_norm": 3.488611936569214,
      "learning_rate": 1.0768674698795181e-05,
      "loss": 0.0206,
      "step": 76620
    },
    {
      "epoch": 9.232530120481927,
      "grad_norm": 0.002020779065787792,
      "learning_rate": 1.0767469879518074e-05,
      "loss": 0.0297,
      "step": 76630
    },
    {
      "epoch": 9.233734939759037,
      "grad_norm": 1.0270955562591553,
      "learning_rate": 1.0766265060240966e-05,
      "loss": 0.0099,
      "step": 76640
    },
    {
      "epoch": 9.234939759036145,
      "grad_norm": 0.0038797492161393166,
      "learning_rate": 1.0765060240963857e-05,
      "loss": 0.0379,
      "step": 76650
    },
    {
      "epoch": 9.236144578313253,
      "grad_norm": 0.8311274647712708,
      "learning_rate": 1.076385542168675e-05,
      "loss": 0.0217,
      "step": 76660
    },
    {
      "epoch": 9.23734939759036,
      "grad_norm": 0.004133010748773813,
      "learning_rate": 1.0762650602409638e-05,
      "loss": 0.0116,
      "step": 76670
    },
    {
      "epoch": 9.23855421686747,
      "grad_norm": 0.02611628733575344,
      "learning_rate": 1.076144578313253e-05,
      "loss": 0.0255,
      "step": 76680
    },
    {
      "epoch": 9.239759036144578,
      "grad_norm": 0.0020421140361577272,
      "learning_rate": 1.0760240963855421e-05,
      "loss": 0.0643,
      "step": 76690
    },
    {
      "epoch": 9.240963855421686,
      "grad_norm": 3.6377618312835693,
      "learning_rate": 1.0759036144578314e-05,
      "loss": 0.0388,
      "step": 76700
    },
    {
      "epoch": 9.242168674698796,
      "grad_norm": 0.04190724715590477,
      "learning_rate": 1.0757831325301206e-05,
      "loss": 0.0063,
      "step": 76710
    },
    {
      "epoch": 9.243373493975904,
      "grad_norm": 7.46232795715332,
      "learning_rate": 1.0756626506024097e-05,
      "loss": 0.0108,
      "step": 76720
    },
    {
      "epoch": 9.244578313253012,
      "grad_norm": 1.3304314613342285,
      "learning_rate": 1.075542168674699e-05,
      "loss": 0.0464,
      "step": 76730
    },
    {
      "epoch": 9.24578313253012,
      "grad_norm": 0.0112112145870924,
      "learning_rate": 1.075421686746988e-05,
      "loss": 0.0338,
      "step": 76740
    },
    {
      "epoch": 9.24698795180723,
      "grad_norm": 11.286270141601562,
      "learning_rate": 1.0753012048192773e-05,
      "loss": 0.0619,
      "step": 76750
    },
    {
      "epoch": 9.248192771084337,
      "grad_norm": 3.3758697509765625,
      "learning_rate": 1.0751807228915663e-05,
      "loss": 0.015,
      "step": 76760
    },
    {
      "epoch": 9.249397590361445,
      "grad_norm": 0.08614101260900497,
      "learning_rate": 1.0750602409638556e-05,
      "loss": 0.0266,
      "step": 76770
    },
    {
      "epoch": 9.250602409638555,
      "grad_norm": 0.6053487062454224,
      "learning_rate": 1.0749397590361445e-05,
      "loss": 0.0096,
      "step": 76780
    },
    {
      "epoch": 9.251807228915663,
      "grad_norm": 0.005510574206709862,
      "learning_rate": 1.0748192771084337e-05,
      "loss": 0.0095,
      "step": 76790
    },
    {
      "epoch": 9.25301204819277,
      "grad_norm": 0.8671292066574097,
      "learning_rate": 1.074698795180723e-05,
      "loss": 0.0153,
      "step": 76800
    },
    {
      "epoch": 9.25421686746988,
      "grad_norm": 1.245962142944336,
      "learning_rate": 1.074578313253012e-05,
      "loss": 0.0262,
      "step": 76810
    },
    {
      "epoch": 9.255421686746988,
      "grad_norm": 1.7065197229385376,
      "learning_rate": 1.0744578313253013e-05,
      "loss": 0.015,
      "step": 76820
    },
    {
      "epoch": 9.256626506024096,
      "grad_norm": 4.769428730010986,
      "learning_rate": 1.0743373493975904e-05,
      "loss": 0.0437,
      "step": 76830
    },
    {
      "epoch": 9.257831325301204,
      "grad_norm": 0.0017094302456825972,
      "learning_rate": 1.0742168674698796e-05,
      "loss": 0.0079,
      "step": 76840
    },
    {
      "epoch": 9.259036144578314,
      "grad_norm": 0.4051629900932312,
      "learning_rate": 1.0740963855421687e-05,
      "loss": 0.0341,
      "step": 76850
    },
    {
      "epoch": 9.260240963855422,
      "grad_norm": 1.828324317932129,
      "learning_rate": 1.073975903614458e-05,
      "loss": 0.0615,
      "step": 76860
    },
    {
      "epoch": 9.26144578313253,
      "grad_norm": 1.507232427597046,
      "learning_rate": 1.0738554216867472e-05,
      "loss": 0.0091,
      "step": 76870
    },
    {
      "epoch": 9.26265060240964,
      "grad_norm": 0.003670454490929842,
      "learning_rate": 1.0737349397590363e-05,
      "loss": 0.047,
      "step": 76880
    },
    {
      "epoch": 9.263855421686747,
      "grad_norm": 0.5062891840934753,
      "learning_rate": 1.0736144578313255e-05,
      "loss": 0.0064,
      "step": 76890
    },
    {
      "epoch": 9.265060240963855,
      "grad_norm": 9.556741714477539,
      "learning_rate": 1.0734939759036144e-05,
      "loss": 0.0406,
      "step": 76900
    },
    {
      "epoch": 9.266265060240963,
      "grad_norm": 0.2420666664838791,
      "learning_rate": 1.0733734939759038e-05,
      "loss": 0.0244,
      "step": 76910
    },
    {
      "epoch": 9.267469879518073,
      "grad_norm": 0.0019283179426565766,
      "learning_rate": 1.0732530120481927e-05,
      "loss": 0.0268,
      "step": 76920
    },
    {
      "epoch": 9.26867469879518,
      "grad_norm": 0.25515154004096985,
      "learning_rate": 1.073132530120482e-05,
      "loss": 0.0095,
      "step": 76930
    },
    {
      "epoch": 9.269879518072289,
      "grad_norm": 0.265796035528183,
      "learning_rate": 1.0730120481927712e-05,
      "loss": 0.0187,
      "step": 76940
    },
    {
      "epoch": 9.271084337349398,
      "grad_norm": 0.41628599166870117,
      "learning_rate": 1.0728915662650603e-05,
      "loss": 0.0031,
      "step": 76950
    },
    {
      "epoch": 9.272289156626506,
      "grad_norm": 0.003951475024223328,
      "learning_rate": 1.0727710843373495e-05,
      "loss": 0.0174,
      "step": 76960
    },
    {
      "epoch": 9.273493975903614,
      "grad_norm": 0.0016699207480996847,
      "learning_rate": 1.0726506024096386e-05,
      "loss": 0.0422,
      "step": 76970
    },
    {
      "epoch": 9.274698795180722,
      "grad_norm": 0.0031606433913111687,
      "learning_rate": 1.0725301204819278e-05,
      "loss": 0.0277,
      "step": 76980
    },
    {
      "epoch": 9.275903614457832,
      "grad_norm": 0.3109699487686157,
      "learning_rate": 1.0724096385542169e-05,
      "loss": 0.0669,
      "step": 76990
    },
    {
      "epoch": 9.27710843373494,
      "grad_norm": 0.6787911057472229,
      "learning_rate": 1.0722891566265062e-05,
      "loss": 0.0291,
      "step": 77000
    },
    {
      "epoch": 9.278313253012048,
      "grad_norm": 0.28078076243400574,
      "learning_rate": 1.0721686746987954e-05,
      "loss": 0.0186,
      "step": 77010
    },
    {
      "epoch": 9.279518072289157,
      "grad_norm": 1.781251311302185,
      "learning_rate": 1.0720481927710845e-05,
      "loss": 0.0426,
      "step": 77020
    },
    {
      "epoch": 9.280722891566265,
      "grad_norm": 0.6452106237411499,
      "learning_rate": 1.0719277108433737e-05,
      "loss": 0.0081,
      "step": 77030
    },
    {
      "epoch": 9.281927710843373,
      "grad_norm": 0.18525783717632294,
      "learning_rate": 1.0718072289156626e-05,
      "loss": 0.005,
      "step": 77040
    },
    {
      "epoch": 9.283132530120483,
      "grad_norm": 0.012184619903564453,
      "learning_rate": 1.0716867469879519e-05,
      "loss": 0.0043,
      "step": 77050
    },
    {
      "epoch": 9.28433734939759,
      "grad_norm": 0.00418689614161849,
      "learning_rate": 1.071566265060241e-05,
      "loss": 0.0066,
      "step": 77060
    },
    {
      "epoch": 9.285542168674699,
      "grad_norm": 4.455988883972168,
      "learning_rate": 1.0714457831325302e-05,
      "loss": 0.0346,
      "step": 77070
    },
    {
      "epoch": 9.286746987951807,
      "grad_norm": 0.11916578561067581,
      "learning_rate": 1.0713253012048193e-05,
      "loss": 0.0127,
      "step": 77080
    },
    {
      "epoch": 9.287951807228916,
      "grad_norm": 0.015641553327441216,
      "learning_rate": 1.0712048192771085e-05,
      "loss": 0.0074,
      "step": 77090
    },
    {
      "epoch": 9.289156626506024,
      "grad_norm": 0.3690586984157562,
      "learning_rate": 1.0710843373493977e-05,
      "loss": 0.0357,
      "step": 77100
    },
    {
      "epoch": 9.290361445783132,
      "grad_norm": 3.5264463424682617,
      "learning_rate": 1.0709638554216868e-05,
      "loss": 0.051,
      "step": 77110
    },
    {
      "epoch": 9.291566265060242,
      "grad_norm": 0.002373993396759033,
      "learning_rate": 1.070843373493976e-05,
      "loss": 0.0102,
      "step": 77120
    },
    {
      "epoch": 9.29277108433735,
      "grad_norm": 0.00451735220849514,
      "learning_rate": 1.0707228915662651e-05,
      "loss": 0.0425,
      "step": 77130
    },
    {
      "epoch": 9.293975903614458,
      "grad_norm": 0.0018580922624096274,
      "learning_rate": 1.0706024096385544e-05,
      "loss": 0.016,
      "step": 77140
    },
    {
      "epoch": 9.295180722891565,
      "grad_norm": 0.015840549021959305,
      "learning_rate": 1.0704819277108433e-05,
      "loss": 0.058,
      "step": 77150
    },
    {
      "epoch": 9.296385542168675,
      "grad_norm": 6.582268714904785,
      "learning_rate": 1.0703614457831327e-05,
      "loss": 0.0182,
      "step": 77160
    },
    {
      "epoch": 9.297590361445783,
      "grad_norm": 0.003287916537374258,
      "learning_rate": 1.070240963855422e-05,
      "loss": 0.0134,
      "step": 77170
    },
    {
      "epoch": 9.298795180722891,
      "grad_norm": 0.00893466267734766,
      "learning_rate": 1.0701204819277108e-05,
      "loss": 0.0419,
      "step": 77180
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.7250319719314575,
      "learning_rate": 1.0700000000000001e-05,
      "loss": 0.0502,
      "step": 77190
    },
    {
      "epoch": 9.301204819277109,
      "grad_norm": 1.125103235244751,
      "learning_rate": 1.0698795180722892e-05,
      "loss": 0.0443,
      "step": 77200
    },
    {
      "epoch": 9.302409638554217,
      "grad_norm": 0.13819973170757294,
      "learning_rate": 1.0697590361445784e-05,
      "loss": 0.0079,
      "step": 77210
    },
    {
      "epoch": 9.303614457831324,
      "grad_norm": 0.005635259672999382,
      "learning_rate": 1.0696385542168675e-05,
      "loss": 0.0186,
      "step": 77220
    },
    {
      "epoch": 9.304819277108434,
      "grad_norm": 1.0201218128204346,
      "learning_rate": 1.0695180722891567e-05,
      "loss": 0.0225,
      "step": 77230
    },
    {
      "epoch": 9.306024096385542,
      "grad_norm": 0.09163045883178711,
      "learning_rate": 1.069397590361446e-05,
      "loss": 0.0444,
      "step": 77240
    },
    {
      "epoch": 9.30722891566265,
      "grad_norm": 0.3110792934894562,
      "learning_rate": 1.069277108433735e-05,
      "loss": 0.0176,
      "step": 77250
    },
    {
      "epoch": 9.30843373493976,
      "grad_norm": 0.0015787879237905145,
      "learning_rate": 1.0691566265060243e-05,
      "loss": 0.0155,
      "step": 77260
    },
    {
      "epoch": 9.309638554216868,
      "grad_norm": 0.12267489731311798,
      "learning_rate": 1.0690361445783134e-05,
      "loss": 0.0124,
      "step": 77270
    },
    {
      "epoch": 9.310843373493976,
      "grad_norm": 3.552689552307129,
      "learning_rate": 1.0689156626506026e-05,
      "loss": 0.0446,
      "step": 77280
    },
    {
      "epoch": 9.312048192771085,
      "grad_norm": 0.005010894499719143,
      "learning_rate": 1.0687951807228915e-05,
      "loss": 0.0091,
      "step": 77290
    },
    {
      "epoch": 9.313253012048193,
      "grad_norm": 0.008485847152769566,
      "learning_rate": 1.0686746987951808e-05,
      "loss": 0.0234,
      "step": 77300
    },
    {
      "epoch": 9.314457831325301,
      "grad_norm": 0.0022109108977019787,
      "learning_rate": 1.06855421686747e-05,
      "loss": 0.0025,
      "step": 77310
    },
    {
      "epoch": 9.315662650602409,
      "grad_norm": 0.03044956550002098,
      "learning_rate": 1.068433734939759e-05,
      "loss": 0.0098,
      "step": 77320
    },
    {
      "epoch": 9.316867469879519,
      "grad_norm": 0.1430380940437317,
      "learning_rate": 1.0683132530120483e-05,
      "loss": 0.0327,
      "step": 77330
    },
    {
      "epoch": 9.318072289156627,
      "grad_norm": 0.0009103409829549491,
      "learning_rate": 1.0681927710843374e-05,
      "loss": 0.0026,
      "step": 77340
    },
    {
      "epoch": 9.319277108433734,
      "grad_norm": 0.0012710451846942306,
      "learning_rate": 1.0680722891566266e-05,
      "loss": 0.0259,
      "step": 77350
    },
    {
      "epoch": 9.320481927710844,
      "grad_norm": 0.004679275676608086,
      "learning_rate": 1.0679518072289157e-05,
      "loss": 0.0345,
      "step": 77360
    },
    {
      "epoch": 9.321686746987952,
      "grad_norm": 0.15780019760131836,
      "learning_rate": 1.067831325301205e-05,
      "loss": 0.0373,
      "step": 77370
    },
    {
      "epoch": 9.32289156626506,
      "grad_norm": 0.19867946207523346,
      "learning_rate": 1.067710843373494e-05,
      "loss": 0.0095,
      "step": 77380
    },
    {
      "epoch": 9.324096385542168,
      "grad_norm": 0.002490663668140769,
      "learning_rate": 1.0675903614457833e-05,
      "loss": 0.0388,
      "step": 77390
    },
    {
      "epoch": 9.325301204819278,
      "grad_norm": 0.0012720973463729024,
      "learning_rate": 1.0674698795180725e-05,
      "loss": 0.0488,
      "step": 77400
    },
    {
      "epoch": 9.326506024096386,
      "grad_norm": 0.005071183200925589,
      "learning_rate": 1.0673493975903614e-05,
      "loss": 0.0083,
      "step": 77410
    },
    {
      "epoch": 9.327710843373493,
      "grad_norm": 1.9337905645370483,
      "learning_rate": 1.0672289156626508e-05,
      "loss": 0.021,
      "step": 77420
    },
    {
      "epoch": 9.328915662650603,
      "grad_norm": 0.0032655042596161366,
      "learning_rate": 1.0671084337349397e-05,
      "loss": 0.0436,
      "step": 77430
    },
    {
      "epoch": 9.330120481927711,
      "grad_norm": 0.004553510341793299,
      "learning_rate": 1.066987951807229e-05,
      "loss": 0.011,
      "step": 77440
    },
    {
      "epoch": 9.331325301204819,
      "grad_norm": 0.0036552101373672485,
      "learning_rate": 1.066867469879518e-05,
      "loss": 0.0465,
      "step": 77450
    },
    {
      "epoch": 9.332530120481927,
      "grad_norm": 0.09654363989830017,
      "learning_rate": 1.0667469879518073e-05,
      "loss": 0.0262,
      "step": 77460
    },
    {
      "epoch": 9.333734939759037,
      "grad_norm": 0.05392812192440033,
      "learning_rate": 1.0666265060240965e-05,
      "loss": 0.0195,
      "step": 77470
    },
    {
      "epoch": 9.334939759036144,
      "grad_norm": 0.006224602460861206,
      "learning_rate": 1.0665060240963856e-05,
      "loss": 0.0304,
      "step": 77480
    },
    {
      "epoch": 9.336144578313252,
      "grad_norm": 0.8430317640304565,
      "learning_rate": 1.0663855421686749e-05,
      "loss": 0.0104,
      "step": 77490
    },
    {
      "epoch": 9.337349397590362,
      "grad_norm": 0.004942690022289753,
      "learning_rate": 1.066265060240964e-05,
      "loss": 0.0359,
      "step": 77500
    },
    {
      "epoch": 9.33855421686747,
      "grad_norm": 0.6203234195709229,
      "learning_rate": 1.0661445783132532e-05,
      "loss": 0.034,
      "step": 77510
    },
    {
      "epoch": 9.339759036144578,
      "grad_norm": 0.021755816414952278,
      "learning_rate": 1.0660240963855422e-05,
      "loss": 0.0249,
      "step": 77520
    },
    {
      "epoch": 9.340963855421688,
      "grad_norm": 3.426724910736084,
      "learning_rate": 1.0659036144578315e-05,
      "loss": 0.0425,
      "step": 77530
    },
    {
      "epoch": 9.342168674698796,
      "grad_norm": 0.009994096122682095,
      "learning_rate": 1.0657831325301207e-05,
      "loss": 0.0068,
      "step": 77540
    },
    {
      "epoch": 9.343373493975903,
      "grad_norm": 0.20745699107646942,
      "learning_rate": 1.0656626506024096e-05,
      "loss": 0.0125,
      "step": 77550
    },
    {
      "epoch": 9.344578313253011,
      "grad_norm": 0.002684981096535921,
      "learning_rate": 1.0655421686746989e-05,
      "loss": 0.0457,
      "step": 77560
    },
    {
      "epoch": 9.345783132530121,
      "grad_norm": 0.029534583911299706,
      "learning_rate": 1.065421686746988e-05,
      "loss": 0.0165,
      "step": 77570
    },
    {
      "epoch": 9.346987951807229,
      "grad_norm": 0.003913037944585085,
      "learning_rate": 1.0653012048192772e-05,
      "loss": 0.0103,
      "step": 77580
    },
    {
      "epoch": 9.348192771084337,
      "grad_norm": 0.4514021873474121,
      "learning_rate": 1.0651807228915663e-05,
      "loss": 0.0146,
      "step": 77590
    },
    {
      "epoch": 9.349397590361447,
      "grad_norm": 0.052087392657995224,
      "learning_rate": 1.0650602409638555e-05,
      "loss": 0.0683,
      "step": 77600
    },
    {
      "epoch": 9.350602409638554,
      "grad_norm": 0.0038490556180477142,
      "learning_rate": 1.0649397590361448e-05,
      "loss": 0.0887,
      "step": 77610
    },
    {
      "epoch": 9.351807228915662,
      "grad_norm": 0.22076113522052765,
      "learning_rate": 1.0648192771084338e-05,
      "loss": 0.0044,
      "step": 77620
    },
    {
      "epoch": 9.35301204819277,
      "grad_norm": 3.7657523155212402,
      "learning_rate": 1.064698795180723e-05,
      "loss": 0.05,
      "step": 77630
    },
    {
      "epoch": 9.35421686746988,
      "grad_norm": 1.382163166999817,
      "learning_rate": 1.0645783132530122e-05,
      "loss": 0.0296,
      "step": 77640
    },
    {
      "epoch": 9.355421686746988,
      "grad_norm": 0.013744017109274864,
      "learning_rate": 1.0644578313253014e-05,
      "loss": 0.057,
      "step": 77650
    },
    {
      "epoch": 9.356626506024096,
      "grad_norm": 0.4615011215209961,
      "learning_rate": 1.0643373493975903e-05,
      "loss": 0.0247,
      "step": 77660
    },
    {
      "epoch": 9.357831325301206,
      "grad_norm": 0.16487839818000793,
      "learning_rate": 1.0642168674698795e-05,
      "loss": 0.0376,
      "step": 77670
    },
    {
      "epoch": 9.359036144578313,
      "grad_norm": 0.17009852826595306,
      "learning_rate": 1.0640963855421686e-05,
      "loss": 0.0092,
      "step": 77680
    },
    {
      "epoch": 9.360240963855421,
      "grad_norm": 0.0032394712325185537,
      "learning_rate": 1.0639759036144579e-05,
      "loss": 0.0262,
      "step": 77690
    },
    {
      "epoch": 9.36144578313253,
      "grad_norm": 0.003713954472914338,
      "learning_rate": 1.0638554216867471e-05,
      "loss": 0.0274,
      "step": 77700
    },
    {
      "epoch": 9.362650602409639,
      "grad_norm": 0.003178503829985857,
      "learning_rate": 1.0637349397590362e-05,
      "loss": 0.015,
      "step": 77710
    },
    {
      "epoch": 9.363855421686747,
      "grad_norm": 0.004562215879559517,
      "learning_rate": 1.0636144578313254e-05,
      "loss": 0.0247,
      "step": 77720
    },
    {
      "epoch": 9.365060240963855,
      "grad_norm": 0.5096554756164551,
      "learning_rate": 1.0634939759036145e-05,
      "loss": 0.016,
      "step": 77730
    },
    {
      "epoch": 9.366265060240965,
      "grad_norm": 0.15171897411346436,
      "learning_rate": 1.0633734939759037e-05,
      "loss": 0.0066,
      "step": 77740
    },
    {
      "epoch": 9.367469879518072,
      "grad_norm": 0.6909124851226807,
      "learning_rate": 1.0632530120481928e-05,
      "loss": 0.0416,
      "step": 77750
    },
    {
      "epoch": 9.36867469879518,
      "grad_norm": 0.43805208802223206,
      "learning_rate": 1.063132530120482e-05,
      "loss": 0.0308,
      "step": 77760
    },
    {
      "epoch": 9.369879518072288,
      "grad_norm": 0.1081598624587059,
      "learning_rate": 1.0630120481927713e-05,
      "loss": 0.0322,
      "step": 77770
    },
    {
      "epoch": 9.371084337349398,
      "grad_norm": 1.2332990169525146,
      "learning_rate": 1.0628915662650604e-05,
      "loss": 0.0051,
      "step": 77780
    },
    {
      "epoch": 9.372289156626506,
      "grad_norm": 0.012861925177276134,
      "learning_rate": 1.0627710843373496e-05,
      "loss": 0.0639,
      "step": 77790
    },
    {
      "epoch": 9.373493975903614,
      "grad_norm": 1.9393671751022339,
      "learning_rate": 1.0626506024096385e-05,
      "loss": 0.0564,
      "step": 77800
    },
    {
      "epoch": 9.374698795180723,
      "grad_norm": 0.399015337228775,
      "learning_rate": 1.0625301204819278e-05,
      "loss": 0.0436,
      "step": 77810
    },
    {
      "epoch": 9.375903614457831,
      "grad_norm": 1.2838178873062134,
      "learning_rate": 1.0624096385542168e-05,
      "loss": 0.0209,
      "step": 77820
    },
    {
      "epoch": 9.37710843373494,
      "grad_norm": 0.34276875853538513,
      "learning_rate": 1.062289156626506e-05,
      "loss": 0.0159,
      "step": 77830
    },
    {
      "epoch": 9.378313253012049,
      "grad_norm": 1.1459380388259888,
      "learning_rate": 1.0621686746987953e-05,
      "loss": 0.032,
      "step": 77840
    },
    {
      "epoch": 9.379518072289157,
      "grad_norm": 0.0023949171882122755,
      "learning_rate": 1.0620481927710844e-05,
      "loss": 0.0039,
      "step": 77850
    },
    {
      "epoch": 9.380722891566265,
      "grad_norm": 0.27582642436027527,
      "learning_rate": 1.0619277108433736e-05,
      "loss": 0.011,
      "step": 77860
    },
    {
      "epoch": 9.381927710843373,
      "grad_norm": 1.4952571392059326,
      "learning_rate": 1.0618072289156627e-05,
      "loss": 0.0194,
      "step": 77870
    },
    {
      "epoch": 9.383132530120482,
      "grad_norm": 0.21394206583499908,
      "learning_rate": 1.061686746987952e-05,
      "loss": 0.0027,
      "step": 77880
    },
    {
      "epoch": 9.38433734939759,
      "grad_norm": 0.74488765001297,
      "learning_rate": 1.061566265060241e-05,
      "loss": 0.0084,
      "step": 77890
    },
    {
      "epoch": 9.385542168674698,
      "grad_norm": 0.005040031857788563,
      "learning_rate": 1.0614457831325303e-05,
      "loss": 0.0081,
      "step": 77900
    },
    {
      "epoch": 9.386746987951808,
      "grad_norm": 0.0025384589098393917,
      "learning_rate": 1.0613253012048195e-05,
      "loss": 0.0074,
      "step": 77910
    },
    {
      "epoch": 9.387951807228916,
      "grad_norm": 0.4941733777523041,
      "learning_rate": 1.0612048192771084e-05,
      "loss": 0.041,
      "step": 77920
    },
    {
      "epoch": 9.389156626506024,
      "grad_norm": 0.12395773828029633,
      "learning_rate": 1.0610843373493977e-05,
      "loss": 0.0019,
      "step": 77930
    },
    {
      "epoch": 9.390361445783132,
      "grad_norm": 0.0013069408014416695,
      "learning_rate": 1.0609638554216867e-05,
      "loss": 0.0043,
      "step": 77940
    },
    {
      "epoch": 9.391566265060241,
      "grad_norm": 0.0014410315779969096,
      "learning_rate": 1.060843373493976e-05,
      "loss": 0.0119,
      "step": 77950
    },
    {
      "epoch": 9.39277108433735,
      "grad_norm": 0.13387931883335114,
      "learning_rate": 1.060722891566265e-05,
      "loss": 0.0131,
      "step": 77960
    },
    {
      "epoch": 9.393975903614457,
      "grad_norm": 1.5390011072158813,
      "learning_rate": 1.0606024096385543e-05,
      "loss": 0.0098,
      "step": 77970
    },
    {
      "epoch": 9.395180722891567,
      "grad_norm": 0.7568029165267944,
      "learning_rate": 1.0604819277108434e-05,
      "loss": 0.012,
      "step": 77980
    },
    {
      "epoch": 9.396385542168675,
      "grad_norm": 1.9749597311019897,
      "learning_rate": 1.0603614457831326e-05,
      "loss": 0.0462,
      "step": 77990
    },
    {
      "epoch": 9.397590361445783,
      "grad_norm": 0.003115356434136629,
      "learning_rate": 1.0602409638554219e-05,
      "loss": 0.0404,
      "step": 78000
    },
    {
      "epoch": 9.398795180722892,
      "grad_norm": 0.11037547141313553,
      "learning_rate": 1.060120481927711e-05,
      "loss": 0.0126,
      "step": 78010
    },
    {
      "epoch": 9.4,
      "grad_norm": 9.775227546691895,
      "learning_rate": 1.0600000000000002e-05,
      "loss": 0.0882,
      "step": 78020
    },
    {
      "epoch": 9.401204819277108,
      "grad_norm": 0.3594096302986145,
      "learning_rate": 1.0598795180722891e-05,
      "loss": 0.0189,
      "step": 78030
    },
    {
      "epoch": 9.402409638554216,
      "grad_norm": 0.004084727261215448,
      "learning_rate": 1.0597590361445785e-05,
      "loss": 0.0298,
      "step": 78040
    },
    {
      "epoch": 9.403614457831326,
      "grad_norm": 0.8971741199493408,
      "learning_rate": 1.0596385542168674e-05,
      "loss": 0.018,
      "step": 78050
    },
    {
      "epoch": 9.404819277108434,
      "grad_norm": 0.007140408270061016,
      "learning_rate": 1.0595180722891567e-05,
      "loss": 0.0144,
      "step": 78060
    },
    {
      "epoch": 9.406024096385542,
      "grad_norm": 0.3388673663139343,
      "learning_rate": 1.0593975903614459e-05,
      "loss": 0.0019,
      "step": 78070
    },
    {
      "epoch": 9.407228915662651,
      "grad_norm": 2.3970022201538086,
      "learning_rate": 1.059277108433735e-05,
      "loss": 0.0118,
      "step": 78080
    },
    {
      "epoch": 9.40843373493976,
      "grad_norm": 0.0007539590005762875,
      "learning_rate": 1.0591566265060242e-05,
      "loss": 0.0257,
      "step": 78090
    },
    {
      "epoch": 9.409638554216867,
      "grad_norm": 0.5086503028869629,
      "learning_rate": 1.0590361445783133e-05,
      "loss": 0.0341,
      "step": 78100
    },
    {
      "epoch": 9.410843373493975,
      "grad_norm": 0.09489573538303375,
      "learning_rate": 1.0589156626506025e-05,
      "loss": 0.0522,
      "step": 78110
    },
    {
      "epoch": 9.412048192771085,
      "grad_norm": 0.33697080612182617,
      "learning_rate": 1.0587951807228916e-05,
      "loss": 0.0044,
      "step": 78120
    },
    {
      "epoch": 9.413253012048193,
      "grad_norm": 5.093035697937012,
      "learning_rate": 1.0586746987951808e-05,
      "loss": 0.0398,
      "step": 78130
    },
    {
      "epoch": 9.4144578313253,
      "grad_norm": 0.19276756048202515,
      "learning_rate": 1.0585542168674701e-05,
      "loss": 0.0161,
      "step": 78140
    },
    {
      "epoch": 9.41566265060241,
      "grad_norm": 0.004489151295274496,
      "learning_rate": 1.0584337349397592e-05,
      "loss": 0.0175,
      "step": 78150
    },
    {
      "epoch": 9.416867469879518,
      "grad_norm": 0.006774517707526684,
      "learning_rate": 1.0583132530120484e-05,
      "loss": 0.0383,
      "step": 78160
    },
    {
      "epoch": 9.418072289156626,
      "grad_norm": 0.11109700798988342,
      "learning_rate": 1.0581927710843373e-05,
      "loss": 0.0627,
      "step": 78170
    },
    {
      "epoch": 9.419277108433734,
      "grad_norm": 0.04394780471920967,
      "learning_rate": 1.0580722891566266e-05,
      "loss": 0.0686,
      "step": 78180
    },
    {
      "epoch": 9.420481927710844,
      "grad_norm": 0.051504988223314285,
      "learning_rate": 1.0579518072289156e-05,
      "loss": 0.0172,
      "step": 78190
    },
    {
      "epoch": 9.421686746987952,
      "grad_norm": 2.424316644668579,
      "learning_rate": 1.0578313253012049e-05,
      "loss": 0.021,
      "step": 78200
    },
    {
      "epoch": 9.42289156626506,
      "grad_norm": 0.16511709988117218,
      "learning_rate": 1.0577108433734941e-05,
      "loss": 0.0403,
      "step": 78210
    },
    {
      "epoch": 9.42409638554217,
      "grad_norm": 0.006527951452881098,
      "learning_rate": 1.0575903614457832e-05,
      "loss": 0.0174,
      "step": 78220
    },
    {
      "epoch": 9.425301204819277,
      "grad_norm": 0.024128248915076256,
      "learning_rate": 1.0574698795180724e-05,
      "loss": 0.0241,
      "step": 78230
    },
    {
      "epoch": 9.426506024096385,
      "grad_norm": 0.02768673375248909,
      "learning_rate": 1.0573493975903615e-05,
      "loss": 0.0079,
      "step": 78240
    },
    {
      "epoch": 9.427710843373493,
      "grad_norm": 0.46425536274909973,
      "learning_rate": 1.0572289156626508e-05,
      "loss": 0.05,
      "step": 78250
    },
    {
      "epoch": 9.428915662650603,
      "grad_norm": 0.01763288304209709,
      "learning_rate": 1.0571084337349398e-05,
      "loss": 0.0079,
      "step": 78260
    },
    {
      "epoch": 9.43012048192771,
      "grad_norm": 1.6393041610717773,
      "learning_rate": 1.056987951807229e-05,
      "loss": 0.0267,
      "step": 78270
    },
    {
      "epoch": 9.431325301204819,
      "grad_norm": 0.6838074922561646,
      "learning_rate": 1.056867469879518e-05,
      "loss": 0.019,
      "step": 78280
    },
    {
      "epoch": 9.432530120481928,
      "grad_norm": 0.1393827497959137,
      "learning_rate": 1.0567469879518072e-05,
      "loss": 0.0471,
      "step": 78290
    },
    {
      "epoch": 9.433734939759036,
      "grad_norm": 0.08386225253343582,
      "learning_rate": 1.0566265060240966e-05,
      "loss": 0.0399,
      "step": 78300
    },
    {
      "epoch": 9.434939759036144,
      "grad_norm": 11.769025802612305,
      "learning_rate": 1.0565060240963855e-05,
      "loss": 0.0151,
      "step": 78310
    },
    {
      "epoch": 9.436144578313254,
      "grad_norm": 0.0011228483635932207,
      "learning_rate": 1.0563855421686748e-05,
      "loss": 0.0102,
      "step": 78320
    },
    {
      "epoch": 9.437349397590362,
      "grad_norm": 0.07155013829469681,
      "learning_rate": 1.0562650602409639e-05,
      "loss": 0.023,
      "step": 78330
    },
    {
      "epoch": 9.43855421686747,
      "grad_norm": 0.27688169479370117,
      "learning_rate": 1.0561445783132531e-05,
      "loss": 0.0038,
      "step": 78340
    },
    {
      "epoch": 9.439759036144578,
      "grad_norm": 1.9384742975234985,
      "learning_rate": 1.0560240963855422e-05,
      "loss": 0.0403,
      "step": 78350
    },
    {
      "epoch": 9.440963855421687,
      "grad_norm": 0.006568065844476223,
      "learning_rate": 1.0559036144578314e-05,
      "loss": 0.023,
      "step": 78360
    },
    {
      "epoch": 9.442168674698795,
      "grad_norm": 0.015950476750731468,
      "learning_rate": 1.0557831325301207e-05,
      "loss": 0.0433,
      "step": 78370
    },
    {
      "epoch": 9.443373493975903,
      "grad_norm": 1.4912387132644653,
      "learning_rate": 1.0556626506024097e-05,
      "loss": 0.0296,
      "step": 78380
    },
    {
      "epoch": 9.444578313253013,
      "grad_norm": 0.01802901364862919,
      "learning_rate": 1.055542168674699e-05,
      "loss": 0.0481,
      "step": 78390
    },
    {
      "epoch": 9.44578313253012,
      "grad_norm": 0.4675976634025574,
      "learning_rate": 1.055421686746988e-05,
      "loss": 0.0271,
      "step": 78400
    },
    {
      "epoch": 9.446987951807229,
      "grad_norm": 0.011174261569976807,
      "learning_rate": 1.0553012048192773e-05,
      "loss": 0.0164,
      "step": 78410
    },
    {
      "epoch": 9.448192771084337,
      "grad_norm": 1.2941548824310303,
      "learning_rate": 1.0551807228915662e-05,
      "loss": 0.0428,
      "step": 78420
    },
    {
      "epoch": 9.449397590361446,
      "grad_norm": 1.0173768997192383,
      "learning_rate": 1.0550602409638554e-05,
      "loss": 0.0564,
      "step": 78430
    },
    {
      "epoch": 9.450602409638554,
      "grad_norm": 0.0018843206344172359,
      "learning_rate": 1.0549397590361447e-05,
      "loss": 0.0131,
      "step": 78440
    },
    {
      "epoch": 9.451807228915662,
      "grad_norm": 0.9513024687767029,
      "learning_rate": 1.0548192771084338e-05,
      "loss": 0.0259,
      "step": 78450
    },
    {
      "epoch": 9.453012048192772,
      "grad_norm": 0.0043984949588775635,
      "learning_rate": 1.054698795180723e-05,
      "loss": 0.0116,
      "step": 78460
    },
    {
      "epoch": 9.45421686746988,
      "grad_norm": 0.00426020473241806,
      "learning_rate": 1.054578313253012e-05,
      "loss": 0.0088,
      "step": 78470
    },
    {
      "epoch": 9.455421686746988,
      "grad_norm": 0.0326971635222435,
      "learning_rate": 1.0544578313253013e-05,
      "loss": 0.0009,
      "step": 78480
    },
    {
      "epoch": 9.456626506024097,
      "grad_norm": 0.0023565643932670355,
      "learning_rate": 1.0543373493975904e-05,
      "loss": 0.011,
      "step": 78490
    },
    {
      "epoch": 9.457831325301205,
      "grad_norm": 0.19034212827682495,
      "learning_rate": 1.0542168674698796e-05,
      "loss": 0.0047,
      "step": 78500
    },
    {
      "epoch": 9.459036144578313,
      "grad_norm": 0.0038163724821060896,
      "learning_rate": 1.0540963855421689e-05,
      "loss": 0.0112,
      "step": 78510
    },
    {
      "epoch": 9.460240963855421,
      "grad_norm": 1.5832229852676392,
      "learning_rate": 1.053975903614458e-05,
      "loss": 0.0081,
      "step": 78520
    },
    {
      "epoch": 9.46144578313253,
      "grad_norm": 3.296142816543579,
      "learning_rate": 1.0538554216867472e-05,
      "loss": 0.0381,
      "step": 78530
    },
    {
      "epoch": 9.462650602409639,
      "grad_norm": 0.016899116337299347,
      "learning_rate": 1.0537349397590361e-05,
      "loss": 0.0256,
      "step": 78540
    },
    {
      "epoch": 9.463855421686747,
      "grad_norm": 0.4255591630935669,
      "learning_rate": 1.0536144578313255e-05,
      "loss": 0.0427,
      "step": 78550
    },
    {
      "epoch": 9.465060240963856,
      "grad_norm": 0.10682116448879242,
      "learning_rate": 1.0534939759036144e-05,
      "loss": 0.012,
      "step": 78560
    },
    {
      "epoch": 9.466265060240964,
      "grad_norm": 0.007538679055869579,
      "learning_rate": 1.0533734939759037e-05,
      "loss": 0.0659,
      "step": 78570
    },
    {
      "epoch": 9.467469879518072,
      "grad_norm": 2.2615935802459717,
      "learning_rate": 1.0532530120481927e-05,
      "loss": 0.0224,
      "step": 78580
    },
    {
      "epoch": 9.46867469879518,
      "grad_norm": 4.3252058029174805,
      "learning_rate": 1.053132530120482e-05,
      "loss": 0.0746,
      "step": 78590
    },
    {
      "epoch": 9.46987951807229,
      "grad_norm": 0.41303524374961853,
      "learning_rate": 1.0530120481927712e-05,
      "loss": 0.026,
      "step": 78600
    },
    {
      "epoch": 9.471084337349398,
      "grad_norm": 0.022584231570363045,
      "learning_rate": 1.0528915662650603e-05,
      "loss": 0.0349,
      "step": 78610
    },
    {
      "epoch": 9.472289156626506,
      "grad_norm": 0.0889153853058815,
      "learning_rate": 1.0527710843373495e-05,
      "loss": 0.0052,
      "step": 78620
    },
    {
      "epoch": 9.473493975903615,
      "grad_norm": 0.007550738286226988,
      "learning_rate": 1.0526506024096386e-05,
      "loss": 0.0386,
      "step": 78630
    },
    {
      "epoch": 9.474698795180723,
      "grad_norm": 0.016898412257432938,
      "learning_rate": 1.0525301204819279e-05,
      "loss": 0.0087,
      "step": 78640
    },
    {
      "epoch": 9.475903614457831,
      "grad_norm": 0.013521024957299232,
      "learning_rate": 1.0524096385542168e-05,
      "loss": 0.0536,
      "step": 78650
    },
    {
      "epoch": 9.477108433734939,
      "grad_norm": 11.113753318786621,
      "learning_rate": 1.0522891566265062e-05,
      "loss": 0.0605,
      "step": 78660
    },
    {
      "epoch": 9.478313253012049,
      "grad_norm": 0.0497857965528965,
      "learning_rate": 1.0521686746987954e-05,
      "loss": 0.0371,
      "step": 78670
    },
    {
      "epoch": 9.479518072289157,
      "grad_norm": 0.01703094132244587,
      "learning_rate": 1.0520481927710843e-05,
      "loss": 0.0151,
      "step": 78680
    },
    {
      "epoch": 9.480722891566264,
      "grad_norm": 0.4622173607349396,
      "learning_rate": 1.0519277108433736e-05,
      "loss": 0.0031,
      "step": 78690
    },
    {
      "epoch": 9.481927710843374,
      "grad_norm": 1.6500582695007324,
      "learning_rate": 1.0518072289156626e-05,
      "loss": 0.0402,
      "step": 78700
    },
    {
      "epoch": 9.483132530120482,
      "grad_norm": 0.07194769382476807,
      "learning_rate": 1.0516867469879519e-05,
      "loss": 0.025,
      "step": 78710
    },
    {
      "epoch": 9.48433734939759,
      "grad_norm": 1.4526766538619995,
      "learning_rate": 1.051566265060241e-05,
      "loss": 0.0163,
      "step": 78720
    },
    {
      "epoch": 9.485542168674698,
      "grad_norm": 2.0952117443084717,
      "learning_rate": 1.0514457831325302e-05,
      "loss": 0.0558,
      "step": 78730
    },
    {
      "epoch": 9.486746987951808,
      "grad_norm": 0.0044281561858952045,
      "learning_rate": 1.0513253012048194e-05,
      "loss": 0.0147,
      "step": 78740
    },
    {
      "epoch": 9.487951807228916,
      "grad_norm": 0.005620313808321953,
      "learning_rate": 1.0512048192771085e-05,
      "loss": 0.0372,
      "step": 78750
    },
    {
      "epoch": 9.489156626506023,
      "grad_norm": 0.004575000144541264,
      "learning_rate": 1.0510843373493978e-05,
      "loss": 0.0052,
      "step": 78760
    },
    {
      "epoch": 9.490361445783133,
      "grad_norm": 26.097593307495117,
      "learning_rate": 1.0509638554216868e-05,
      "loss": 0.0325,
      "step": 78770
    },
    {
      "epoch": 9.491566265060241,
      "grad_norm": 3.1827661991119385,
      "learning_rate": 1.050843373493976e-05,
      "loss": 0.037,
      "step": 78780
    },
    {
      "epoch": 9.492771084337349,
      "grad_norm": 0.15126240253448486,
      "learning_rate": 1.050722891566265e-05,
      "loss": 0.0123,
      "step": 78790
    },
    {
      "epoch": 9.493975903614459,
      "grad_norm": 0.03833401948213577,
      "learning_rate": 1.0506024096385542e-05,
      "loss": 0.0029,
      "step": 78800
    },
    {
      "epoch": 9.495180722891567,
      "grad_norm": 0.0021758689545094967,
      "learning_rate": 1.0504819277108436e-05,
      "loss": 0.0169,
      "step": 78810
    },
    {
      "epoch": 9.496385542168674,
      "grad_norm": 0.004319649655371904,
      "learning_rate": 1.0503614457831326e-05,
      "loss": 0.0334,
      "step": 78820
    },
    {
      "epoch": 9.497590361445782,
      "grad_norm": 2.733241081237793,
      "learning_rate": 1.0502409638554218e-05,
      "loss": 0.0402,
      "step": 78830
    },
    {
      "epoch": 9.498795180722892,
      "grad_norm": 0.007841997779905796,
      "learning_rate": 1.0501204819277109e-05,
      "loss": 0.0107,
      "step": 78840
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.0697630643844604,
      "learning_rate": 1.0500000000000001e-05,
      "loss": 0.0093,
      "step": 78850
    },
    {
      "epoch": 9.501204819277108,
      "grad_norm": 5.560839653015137,
      "learning_rate": 1.0498795180722892e-05,
      "loss": 0.0319,
      "step": 78860
    },
    {
      "epoch": 9.502409638554218,
      "grad_norm": 0.4459054172039032,
      "learning_rate": 1.0497590361445784e-05,
      "loss": 0.0062,
      "step": 78870
    },
    {
      "epoch": 9.503614457831326,
      "grad_norm": 0.8977750539779663,
      "learning_rate": 1.0496385542168677e-05,
      "loss": 0.0281,
      "step": 78880
    },
    {
      "epoch": 9.504819277108433,
      "grad_norm": 0.0021095438860356808,
      "learning_rate": 1.0495180722891567e-05,
      "loss": 0.0126,
      "step": 78890
    },
    {
      "epoch": 9.506024096385541,
      "grad_norm": 0.008074283599853516,
      "learning_rate": 1.049397590361446e-05,
      "loss": 0.0551,
      "step": 78900
    },
    {
      "epoch": 9.507228915662651,
      "grad_norm": 0.0050542354583740234,
      "learning_rate": 1.049277108433735e-05,
      "loss": 0.0167,
      "step": 78910
    },
    {
      "epoch": 9.508433734939759,
      "grad_norm": 0.010289152152836323,
      "learning_rate": 1.0491566265060243e-05,
      "loss": 0.0238,
      "step": 78920
    },
    {
      "epoch": 9.509638554216867,
      "grad_norm": 1.1837894916534424,
      "learning_rate": 1.0490361445783132e-05,
      "loss": 0.0111,
      "step": 78930
    },
    {
      "epoch": 9.510843373493977,
      "grad_norm": 0.0333990752696991,
      "learning_rate": 1.0489156626506025e-05,
      "loss": 0.0134,
      "step": 78940
    },
    {
      "epoch": 9.512048192771084,
      "grad_norm": 0.0026410690043121576,
      "learning_rate": 1.0487951807228915e-05,
      "loss": 0.0309,
      "step": 78950
    },
    {
      "epoch": 9.513253012048192,
      "grad_norm": 0.29909375309944153,
      "learning_rate": 1.0486746987951808e-05,
      "loss": 0.0137,
      "step": 78960
    },
    {
      "epoch": 9.514457831325302,
      "grad_norm": 7.2326340675354,
      "learning_rate": 1.04855421686747e-05,
      "loss": 0.0258,
      "step": 78970
    },
    {
      "epoch": 9.51566265060241,
      "grad_norm": 0.6607974767684937,
      "learning_rate": 1.0484337349397591e-05,
      "loss": 0.0096,
      "step": 78980
    },
    {
      "epoch": 9.516867469879518,
      "grad_norm": 1.3175371885299683,
      "learning_rate": 1.0483132530120483e-05,
      "loss": 0.0271,
      "step": 78990
    },
    {
      "epoch": 9.518072289156626,
      "grad_norm": 0.011508775874972343,
      "learning_rate": 1.0481927710843374e-05,
      "loss": 0.0503,
      "step": 79000
    },
    {
      "epoch": 9.519277108433736,
      "grad_norm": 0.0007931375876069069,
      "learning_rate": 1.0480722891566267e-05,
      "loss": 0.0311,
      "step": 79010
    },
    {
      "epoch": 9.520481927710843,
      "grad_norm": 0.008300925604999065,
      "learning_rate": 1.0479518072289157e-05,
      "loss": 0.0015,
      "step": 79020
    },
    {
      "epoch": 9.521686746987951,
      "grad_norm": 3.928971767425537,
      "learning_rate": 1.047831325301205e-05,
      "loss": 0.0242,
      "step": 79030
    },
    {
      "epoch": 9.522891566265061,
      "grad_norm": 0.40543392300605774,
      "learning_rate": 1.0477108433734942e-05,
      "loss": 0.0281,
      "step": 79040
    },
    {
      "epoch": 9.524096385542169,
      "grad_norm": 0.0023453279864042997,
      "learning_rate": 1.0475903614457831e-05,
      "loss": 0.0314,
      "step": 79050
    },
    {
      "epoch": 9.525301204819277,
      "grad_norm": 0.0595550611615181,
      "learning_rate": 1.0474698795180724e-05,
      "loss": 0.028,
      "step": 79060
    },
    {
      "epoch": 9.526506024096385,
      "grad_norm": 0.12113821506500244,
      "learning_rate": 1.0473493975903614e-05,
      "loss": 0.02,
      "step": 79070
    },
    {
      "epoch": 9.527710843373494,
      "grad_norm": 0.05881620571017265,
      "learning_rate": 1.0472289156626507e-05,
      "loss": 0.0291,
      "step": 79080
    },
    {
      "epoch": 9.528915662650602,
      "grad_norm": 1.7774425745010376,
      "learning_rate": 1.0471084337349398e-05,
      "loss": 0.0442,
      "step": 79090
    },
    {
      "epoch": 9.53012048192771,
      "grad_norm": 3.104356527328491,
      "learning_rate": 1.046987951807229e-05,
      "loss": 0.0419,
      "step": 79100
    },
    {
      "epoch": 9.53132530120482,
      "grad_norm": 0.22057126462459564,
      "learning_rate": 1.0468674698795182e-05,
      "loss": 0.0238,
      "step": 79110
    },
    {
      "epoch": 9.532530120481928,
      "grad_norm": 2.8562207221984863,
      "learning_rate": 1.0467469879518073e-05,
      "loss": 0.0214,
      "step": 79120
    },
    {
      "epoch": 9.533734939759036,
      "grad_norm": 2.591348171234131,
      "learning_rate": 1.0466265060240966e-05,
      "loss": 0.042,
      "step": 79130
    },
    {
      "epoch": 9.534939759036144,
      "grad_norm": 0.1856306940317154,
      "learning_rate": 1.0465060240963856e-05,
      "loss": 0.0092,
      "step": 79140
    },
    {
      "epoch": 9.536144578313253,
      "grad_norm": 0.031382616609334946,
      "learning_rate": 1.0463855421686749e-05,
      "loss": 0.0058,
      "step": 79150
    },
    {
      "epoch": 9.537349397590361,
      "grad_norm": 0.0038745419587939978,
      "learning_rate": 1.0462650602409638e-05,
      "loss": 0.0071,
      "step": 79160
    },
    {
      "epoch": 9.53855421686747,
      "grad_norm": 0.0025388922076672316,
      "learning_rate": 1.0461445783132532e-05,
      "loss": 0.0212,
      "step": 79170
    },
    {
      "epoch": 9.539759036144579,
      "grad_norm": 0.5755723118782043,
      "learning_rate": 1.0460240963855424e-05,
      "loss": 0.0536,
      "step": 79180
    },
    {
      "epoch": 9.540963855421687,
      "grad_norm": 0.12745803594589233,
      "learning_rate": 1.0459036144578313e-05,
      "loss": 0.014,
      "step": 79190
    },
    {
      "epoch": 9.542168674698795,
      "grad_norm": 0.006075267679989338,
      "learning_rate": 1.0457831325301206e-05,
      "loss": 0.0192,
      "step": 79200
    },
    {
      "epoch": 9.543373493975903,
      "grad_norm": 0.06967923790216446,
      "learning_rate": 1.0456626506024097e-05,
      "loss": 0.0161,
      "step": 79210
    },
    {
      "epoch": 9.544578313253012,
      "grad_norm": 0.43047842383384705,
      "learning_rate": 1.0455421686746989e-05,
      "loss": 0.0113,
      "step": 79220
    },
    {
      "epoch": 9.54578313253012,
      "grad_norm": 1.0237643718719482,
      "learning_rate": 1.045421686746988e-05,
      "loss": 0.0095,
      "step": 79230
    },
    {
      "epoch": 9.546987951807228,
      "grad_norm": 94.34439849853516,
      "learning_rate": 1.0453012048192772e-05,
      "loss": 0.0147,
      "step": 79240
    },
    {
      "epoch": 9.548192771084338,
      "grad_norm": 0.08434562385082245,
      "learning_rate": 1.0451807228915663e-05,
      "loss": 0.0179,
      "step": 79250
    },
    {
      "epoch": 9.549397590361446,
      "grad_norm": 0.0015785208670422435,
      "learning_rate": 1.0450602409638555e-05,
      "loss": 0.0044,
      "step": 79260
    },
    {
      "epoch": 9.550602409638554,
      "grad_norm": 1.9559800624847412,
      "learning_rate": 1.0449397590361448e-05,
      "loss": 0.0219,
      "step": 79270
    },
    {
      "epoch": 9.551807228915663,
      "grad_norm": 5.603930473327637,
      "learning_rate": 1.0448192771084339e-05,
      "loss": 0.0254,
      "step": 79280
    },
    {
      "epoch": 9.553012048192771,
      "grad_norm": 61.52464294433594,
      "learning_rate": 1.0446987951807231e-05,
      "loss": 0.0286,
      "step": 79290
    },
    {
      "epoch": 9.55421686746988,
      "grad_norm": 0.00787289533764124,
      "learning_rate": 1.044578313253012e-05,
      "loss": 0.0537,
      "step": 79300
    },
    {
      "epoch": 9.555421686746987,
      "grad_norm": 4.350341796875,
      "learning_rate": 1.0444578313253012e-05,
      "loss": 0.0697,
      "step": 79310
    },
    {
      "epoch": 9.556626506024097,
      "grad_norm": 0.028742309659719467,
      "learning_rate": 1.0443373493975903e-05,
      "loss": 0.0055,
      "step": 79320
    },
    {
      "epoch": 9.557831325301205,
      "grad_norm": 0.23381473124027252,
      "learning_rate": 1.0442168674698796e-05,
      "loss": 0.0106,
      "step": 79330
    },
    {
      "epoch": 9.559036144578313,
      "grad_norm": 1.1207506656646729,
      "learning_rate": 1.0440963855421688e-05,
      "loss": 0.0089,
      "step": 79340
    },
    {
      "epoch": 9.560240963855422,
      "grad_norm": 7.584458827972412,
      "learning_rate": 1.0439759036144579e-05,
      "loss": 0.0295,
      "step": 79350
    },
    {
      "epoch": 9.56144578313253,
      "grad_norm": 0.09147918224334717,
      "learning_rate": 1.0438554216867471e-05,
      "loss": 0.0063,
      "step": 79360
    },
    {
      "epoch": 9.562650602409638,
      "grad_norm": 2.719942331314087,
      "learning_rate": 1.0437349397590362e-05,
      "loss": 0.0252,
      "step": 79370
    },
    {
      "epoch": 9.563855421686746,
      "grad_norm": 5.096983909606934,
      "learning_rate": 1.0436144578313254e-05,
      "loss": 0.0233,
      "step": 79380
    },
    {
      "epoch": 9.565060240963856,
      "grad_norm": 0.08252736926078796,
      "learning_rate": 1.0434939759036145e-05,
      "loss": 0.0111,
      "step": 79390
    },
    {
      "epoch": 9.566265060240964,
      "grad_norm": 0.5094053745269775,
      "learning_rate": 1.0433734939759038e-05,
      "loss": 0.0488,
      "step": 79400
    },
    {
      "epoch": 9.567469879518072,
      "grad_norm": 0.0030528204515576363,
      "learning_rate": 1.043253012048193e-05,
      "loss": 0.0235,
      "step": 79410
    },
    {
      "epoch": 9.568674698795181,
      "grad_norm": 5.092089653015137,
      "learning_rate": 1.0431325301204819e-05,
      "loss": 0.0119,
      "step": 79420
    },
    {
      "epoch": 9.56987951807229,
      "grad_norm": 0.04518408328294754,
      "learning_rate": 1.0430120481927713e-05,
      "loss": 0.008,
      "step": 79430
    },
    {
      "epoch": 9.571084337349397,
      "grad_norm": 0.008060039952397346,
      "learning_rate": 1.0428915662650602e-05,
      "loss": 0.0295,
      "step": 79440
    },
    {
      "epoch": 9.572289156626507,
      "grad_norm": 0.012635260820388794,
      "learning_rate": 1.0427710843373495e-05,
      "loss": 0.0543,
      "step": 79450
    },
    {
      "epoch": 9.573493975903615,
      "grad_norm": 3.8131184577941895,
      "learning_rate": 1.0426506024096385e-05,
      "loss": 0.0267,
      "step": 79460
    },
    {
      "epoch": 9.574698795180723,
      "grad_norm": 1.3063534498214722,
      "learning_rate": 1.0425301204819278e-05,
      "loss": 0.0208,
      "step": 79470
    },
    {
      "epoch": 9.57590361445783,
      "grad_norm": 0.0637393668293953,
      "learning_rate": 1.042409638554217e-05,
      "loss": 0.026,
      "step": 79480
    },
    {
      "epoch": 9.57710843373494,
      "grad_norm": 3.021763563156128,
      "learning_rate": 1.0422891566265061e-05,
      "loss": 0.0382,
      "step": 79490
    },
    {
      "epoch": 9.578313253012048,
      "grad_norm": 0.046671196818351746,
      "learning_rate": 1.0421686746987953e-05,
      "loss": 0.0109,
      "step": 79500
    },
    {
      "epoch": 9.579518072289156,
      "grad_norm": 0.4813554286956787,
      "learning_rate": 1.0420481927710844e-05,
      "loss": 0.0012,
      "step": 79510
    },
    {
      "epoch": 9.580722891566266,
      "grad_norm": 0.07161607593297958,
      "learning_rate": 1.0419277108433737e-05,
      "loss": 0.0296,
      "step": 79520
    },
    {
      "epoch": 9.581927710843374,
      "grad_norm": 0.01609424315392971,
      "learning_rate": 1.0418072289156627e-05,
      "loss": 0.0469,
      "step": 79530
    },
    {
      "epoch": 9.583132530120482,
      "grad_norm": 0.30560606718063354,
      "learning_rate": 1.041686746987952e-05,
      "loss": 0.0413,
      "step": 79540
    },
    {
      "epoch": 9.58433734939759,
      "grad_norm": 0.010286220349371433,
      "learning_rate": 1.0415662650602409e-05,
      "loss": 0.0444,
      "step": 79550
    },
    {
      "epoch": 9.5855421686747,
      "grad_norm": 0.8221284747123718,
      "learning_rate": 1.0414457831325301e-05,
      "loss": 0.0165,
      "step": 79560
    },
    {
      "epoch": 9.586746987951807,
      "grad_norm": 0.04442036524415016,
      "learning_rate": 1.0413253012048194e-05,
      "loss": 0.0156,
      "step": 79570
    },
    {
      "epoch": 9.587951807228915,
      "grad_norm": 0.015010983683168888,
      "learning_rate": 1.0412048192771084e-05,
      "loss": 0.006,
      "step": 79580
    },
    {
      "epoch": 9.589156626506025,
      "grad_norm": 0.7008035182952881,
      "learning_rate": 1.0410843373493977e-05,
      "loss": 0.0072,
      "step": 79590
    },
    {
      "epoch": 9.590361445783133,
      "grad_norm": 1.0843864679336548,
      "learning_rate": 1.0409638554216868e-05,
      "loss": 0.07,
      "step": 79600
    },
    {
      "epoch": 9.59156626506024,
      "grad_norm": 0.17151057720184326,
      "learning_rate": 1.040843373493976e-05,
      "loss": 0.0327,
      "step": 79610
    },
    {
      "epoch": 9.592771084337349,
      "grad_norm": 0.005717189516872168,
      "learning_rate": 1.0407228915662651e-05,
      "loss": 0.0099,
      "step": 79620
    },
    {
      "epoch": 9.593975903614458,
      "grad_norm": 1.6999701261520386,
      "learning_rate": 1.0406024096385543e-05,
      "loss": 0.0093,
      "step": 79630
    },
    {
      "epoch": 9.595180722891566,
      "grad_norm": 0.0013957337941974401,
      "learning_rate": 1.0404819277108436e-05,
      "loss": 0.0161,
      "step": 79640
    },
    {
      "epoch": 9.596385542168674,
      "grad_norm": 1.0466978549957275,
      "learning_rate": 1.0403614457831326e-05,
      "loss": 0.0321,
      "step": 79650
    },
    {
      "epoch": 9.597590361445784,
      "grad_norm": 0.007910330779850483,
      "learning_rate": 1.0402409638554219e-05,
      "loss": 0.0108,
      "step": 79660
    },
    {
      "epoch": 9.598795180722892,
      "grad_norm": 0.002213340951129794,
      "learning_rate": 1.0401204819277108e-05,
      "loss": 0.0069,
      "step": 79670
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.161643385887146,
      "learning_rate": 1.04e-05,
      "loss": 0.0468,
      "step": 79680
    },
    {
      "epoch": 9.601204819277108,
      "grad_norm": 0.011359152384102345,
      "learning_rate": 1.0398795180722891e-05,
      "loss": 0.0054,
      "step": 79690
    },
    {
      "epoch": 9.602409638554217,
      "grad_norm": 0.005753315519541502,
      "learning_rate": 1.0397590361445784e-05,
      "loss": 0.0553,
      "step": 79700
    },
    {
      "epoch": 9.603614457831325,
      "grad_norm": 4.055914878845215,
      "learning_rate": 1.0396385542168676e-05,
      "loss": 0.0279,
      "step": 79710
    },
    {
      "epoch": 9.604819277108433,
      "grad_norm": 21.564584732055664,
      "learning_rate": 1.0395180722891567e-05,
      "loss": 0.0191,
      "step": 79720
    },
    {
      "epoch": 9.606024096385543,
      "grad_norm": 0.026978429406881332,
      "learning_rate": 1.039397590361446e-05,
      "loss": 0.0111,
      "step": 79730
    },
    {
      "epoch": 9.60722891566265,
      "grad_norm": 1.1127550601959229,
      "learning_rate": 1.039277108433735e-05,
      "loss": 0.0379,
      "step": 79740
    },
    {
      "epoch": 9.608433734939759,
      "grad_norm": 0.004311234224587679,
      "learning_rate": 1.0391566265060242e-05,
      "loss": 0.0395,
      "step": 79750
    },
    {
      "epoch": 9.609638554216868,
      "grad_norm": 0.37837573885917664,
      "learning_rate": 1.0390361445783133e-05,
      "loss": 0.0074,
      "step": 79760
    },
    {
      "epoch": 9.610843373493976,
      "grad_norm": 0.004198581911623478,
      "learning_rate": 1.0389156626506026e-05,
      "loss": 0.0009,
      "step": 79770
    },
    {
      "epoch": 9.612048192771084,
      "grad_norm": 0.003184971632435918,
      "learning_rate": 1.0387951807228918e-05,
      "loss": 0.0282,
      "step": 79780
    },
    {
      "epoch": 9.613253012048192,
      "grad_norm": 0.010749786160886288,
      "learning_rate": 1.0386746987951809e-05,
      "loss": 0.0199,
      "step": 79790
    },
    {
      "epoch": 9.614457831325302,
      "grad_norm": 2.678314208984375,
      "learning_rate": 1.0385542168674701e-05,
      "loss": 0.0295,
      "step": 79800
    },
    {
      "epoch": 9.61566265060241,
      "grad_norm": 0.6235533952713013,
      "learning_rate": 1.038433734939759e-05,
      "loss": 0.0283,
      "step": 79810
    },
    {
      "epoch": 9.616867469879518,
      "grad_norm": 1.533045768737793,
      "learning_rate": 1.0383132530120483e-05,
      "loss": 0.0401,
      "step": 79820
    },
    {
      "epoch": 9.618072289156627,
      "grad_norm": 18.178646087646484,
      "learning_rate": 1.0381927710843373e-05,
      "loss": 0.0311,
      "step": 79830
    },
    {
      "epoch": 9.619277108433735,
      "grad_norm": 1.5853999853134155,
      "learning_rate": 1.0380722891566266e-05,
      "loss": 0.0255,
      "step": 79840
    },
    {
      "epoch": 9.620481927710843,
      "grad_norm": 0.006028574891388416,
      "learning_rate": 1.0379518072289157e-05,
      "loss": 0.0116,
      "step": 79850
    },
    {
      "epoch": 9.621686746987951,
      "grad_norm": 0.003110333578661084,
      "learning_rate": 1.0378313253012049e-05,
      "loss": 0.027,
      "step": 79860
    },
    {
      "epoch": 9.62289156626506,
      "grad_norm": 0.0007775892736390233,
      "learning_rate": 1.0377108433734941e-05,
      "loss": 0.0317,
      "step": 79870
    },
    {
      "epoch": 9.624096385542169,
      "grad_norm": 0.006915233097970486,
      "learning_rate": 1.0375903614457832e-05,
      "loss": 0.016,
      "step": 79880
    },
    {
      "epoch": 9.625301204819277,
      "grad_norm": 0.0028033931739628315,
      "learning_rate": 1.0374698795180725e-05,
      "loss": 0.0181,
      "step": 79890
    },
    {
      "epoch": 9.626506024096386,
      "grad_norm": 0.002480115508660674,
      "learning_rate": 1.0373493975903615e-05,
      "loss": 0.0175,
      "step": 79900
    },
    {
      "epoch": 9.627710843373494,
      "grad_norm": 0.028606628999114037,
      "learning_rate": 1.0372289156626508e-05,
      "loss": 0.0205,
      "step": 79910
    },
    {
      "epoch": 9.628915662650602,
      "grad_norm": 0.040367040783166885,
      "learning_rate": 1.0371084337349397e-05,
      "loss": 0.0244,
      "step": 79920
    },
    {
      "epoch": 9.630120481927712,
      "grad_norm": 6.814724922180176,
      "learning_rate": 1.036987951807229e-05,
      "loss": 0.0418,
      "step": 79930
    },
    {
      "epoch": 9.63132530120482,
      "grad_norm": 0.008892965503036976,
      "learning_rate": 1.0368674698795183e-05,
      "loss": 0.0181,
      "step": 79940
    },
    {
      "epoch": 9.632530120481928,
      "grad_norm": 0.4002491533756256,
      "learning_rate": 1.0367469879518072e-05,
      "loss": 0.0346,
      "step": 79950
    },
    {
      "epoch": 9.633734939759035,
      "grad_norm": 0.0315004363656044,
      "learning_rate": 1.0366265060240965e-05,
      "loss": 0.0259,
      "step": 79960
    },
    {
      "epoch": 9.634939759036145,
      "grad_norm": 0.6788328886032104,
      "learning_rate": 1.0365060240963856e-05,
      "loss": 0.0206,
      "step": 79970
    },
    {
      "epoch": 9.636144578313253,
      "grad_norm": 0.013514605350792408,
      "learning_rate": 1.0363855421686748e-05,
      "loss": 0.0279,
      "step": 79980
    },
    {
      "epoch": 9.637349397590361,
      "grad_norm": 0.08004124462604523,
      "learning_rate": 1.0362650602409639e-05,
      "loss": 0.0107,
      "step": 79990
    },
    {
      "epoch": 9.638554216867469,
      "grad_norm": 0.0008362508960999548,
      "learning_rate": 1.0361445783132531e-05,
      "loss": 0.0142,
      "step": 80000
    },
    {
      "epoch": 9.639759036144579,
      "grad_norm": 0.0007076430483721197,
      "learning_rate": 1.0360240963855424e-05,
      "loss": 0.045,
      "step": 80010
    },
    {
      "epoch": 9.640963855421687,
      "grad_norm": 1.036453127861023,
      "learning_rate": 1.0359036144578314e-05,
      "loss": 0.0214,
      "step": 80020
    },
    {
      "epoch": 9.642168674698794,
      "grad_norm": 0.028377724811434746,
      "learning_rate": 1.0357831325301207e-05,
      "loss": 0.0454,
      "step": 80030
    },
    {
      "epoch": 9.643373493975904,
      "grad_norm": 0.004383381921797991,
      "learning_rate": 1.0356626506024096e-05,
      "loss": 0.0062,
      "step": 80040
    },
    {
      "epoch": 9.644578313253012,
      "grad_norm": 0.002791930455714464,
      "learning_rate": 1.035542168674699e-05,
      "loss": 0.0243,
      "step": 80050
    },
    {
      "epoch": 9.64578313253012,
      "grad_norm": 0.0006919897277839482,
      "learning_rate": 1.0354216867469879e-05,
      "loss": 0.0084,
      "step": 80060
    },
    {
      "epoch": 9.64698795180723,
      "grad_norm": 0.001596021349541843,
      "learning_rate": 1.0353012048192771e-05,
      "loss": 0.0643,
      "step": 80070
    },
    {
      "epoch": 9.648192771084338,
      "grad_norm": 0.008109635673463345,
      "learning_rate": 1.0351807228915664e-05,
      "loss": 0.0229,
      "step": 80080
    },
    {
      "epoch": 9.649397590361446,
      "grad_norm": 0.08995044976472855,
      "learning_rate": 1.0350602409638555e-05,
      "loss": 0.058,
      "step": 80090
    },
    {
      "epoch": 9.650602409638553,
      "grad_norm": 0.023426862433552742,
      "learning_rate": 1.0349397590361447e-05,
      "loss": 0.0006,
      "step": 80100
    },
    {
      "epoch": 9.651807228915663,
      "grad_norm": 0.017110157757997513,
      "learning_rate": 1.0348192771084338e-05,
      "loss": 0.0477,
      "step": 80110
    },
    {
      "epoch": 9.653012048192771,
      "grad_norm": 2.9689953327178955,
      "learning_rate": 1.034698795180723e-05,
      "loss": 0.0305,
      "step": 80120
    },
    {
      "epoch": 9.654216867469879,
      "grad_norm": 0.04766886308789253,
      "learning_rate": 1.0345783132530121e-05,
      "loss": 0.037,
      "step": 80130
    },
    {
      "epoch": 9.655421686746989,
      "grad_norm": 0.024319851770997047,
      "learning_rate": 1.0344578313253013e-05,
      "loss": 0.0189,
      "step": 80140
    },
    {
      "epoch": 9.656626506024097,
      "grad_norm": 0.06971339136362076,
      "learning_rate": 1.0343373493975904e-05,
      "loss": 0.0148,
      "step": 80150
    },
    {
      "epoch": 9.657831325301204,
      "grad_norm": 0.002306238515302539,
      "learning_rate": 1.0342168674698797e-05,
      "loss": 0.0129,
      "step": 80160
    },
    {
      "epoch": 9.659036144578312,
      "grad_norm": 0.010444799438118935,
      "learning_rate": 1.0340963855421689e-05,
      "loss": 0.0367,
      "step": 80170
    },
    {
      "epoch": 9.660240963855422,
      "grad_norm": 0.014470024965703487,
      "learning_rate": 1.0339759036144578e-05,
      "loss": 0.0234,
      "step": 80180
    },
    {
      "epoch": 9.66144578313253,
      "grad_norm": 5.325029373168945,
      "learning_rate": 1.033855421686747e-05,
      "loss": 0.0301,
      "step": 80190
    },
    {
      "epoch": 9.662650602409638,
      "grad_norm": 0.49217522144317627,
      "learning_rate": 1.0337349397590361e-05,
      "loss": 0.0373,
      "step": 80200
    },
    {
      "epoch": 9.663855421686748,
      "grad_norm": 0.33871278166770935,
      "learning_rate": 1.0336144578313254e-05,
      "loss": 0.0078,
      "step": 80210
    },
    {
      "epoch": 9.665060240963856,
      "grad_norm": 0.24726325273513794,
      "learning_rate": 1.0334939759036144e-05,
      "loss": 0.0153,
      "step": 80220
    },
    {
      "epoch": 9.666265060240963,
      "grad_norm": 1.16019606590271,
      "learning_rate": 1.0333734939759037e-05,
      "loss": 0.0634,
      "step": 80230
    },
    {
      "epoch": 9.667469879518073,
      "grad_norm": 0.7721271514892578,
      "learning_rate": 1.033253012048193e-05,
      "loss": 0.0464,
      "step": 80240
    },
    {
      "epoch": 9.668674698795181,
      "grad_norm": 23.17855453491211,
      "learning_rate": 1.033132530120482e-05,
      "loss": 0.0137,
      "step": 80250
    },
    {
      "epoch": 9.669879518072289,
      "grad_norm": 0.013521052896976471,
      "learning_rate": 1.0330120481927712e-05,
      "loss": 0.0537,
      "step": 80260
    },
    {
      "epoch": 9.671084337349397,
      "grad_norm": 0.0018294347682967782,
      "learning_rate": 1.0328915662650603e-05,
      "loss": 0.0414,
      "step": 80270
    },
    {
      "epoch": 9.672289156626507,
      "grad_norm": 0.00900384783744812,
      "learning_rate": 1.0327710843373496e-05,
      "loss": 0.0457,
      "step": 80280
    },
    {
      "epoch": 9.673493975903614,
      "grad_norm": 0.005992197431623936,
      "learning_rate": 1.0326506024096385e-05,
      "loss": 0.011,
      "step": 80290
    },
    {
      "epoch": 9.674698795180722,
      "grad_norm": 0.004726020619273186,
      "learning_rate": 1.0325301204819279e-05,
      "loss": 0.0078,
      "step": 80300
    },
    {
      "epoch": 9.675903614457832,
      "grad_norm": 0.005405074916779995,
      "learning_rate": 1.0324096385542171e-05,
      "loss": 0.0108,
      "step": 80310
    },
    {
      "epoch": 9.67710843373494,
      "grad_norm": 0.24121713638305664,
      "learning_rate": 1.032289156626506e-05,
      "loss": 0.0038,
      "step": 80320
    },
    {
      "epoch": 9.678313253012048,
      "grad_norm": 0.011158348992466927,
      "learning_rate": 1.0321686746987953e-05,
      "loss": 0.0164,
      "step": 80330
    },
    {
      "epoch": 9.679518072289156,
      "grad_norm": 0.002219226909801364,
      "learning_rate": 1.0320481927710843e-05,
      "loss": 0.021,
      "step": 80340
    },
    {
      "epoch": 9.680722891566266,
      "grad_norm": 0.00584688363596797,
      "learning_rate": 1.0319277108433736e-05,
      "loss": 0.0413,
      "step": 80350
    },
    {
      "epoch": 9.681927710843373,
      "grad_norm": 0.1922430843114853,
      "learning_rate": 1.0318072289156627e-05,
      "loss": 0.0144,
      "step": 80360
    },
    {
      "epoch": 9.683132530120481,
      "grad_norm": 0.6984136700630188,
      "learning_rate": 1.0316867469879519e-05,
      "loss": 0.0251,
      "step": 80370
    },
    {
      "epoch": 9.684337349397591,
      "grad_norm": 8.729218482971191,
      "learning_rate": 1.0315662650602412e-05,
      "loss": 0.0155,
      "step": 80380
    },
    {
      "epoch": 9.685542168674699,
      "grad_norm": 0.004182519856840372,
      "learning_rate": 1.0314457831325302e-05,
      "loss": 0.0472,
      "step": 80390
    },
    {
      "epoch": 9.686746987951807,
      "grad_norm": 0.042854346334934235,
      "learning_rate": 1.0313253012048195e-05,
      "loss": 0.0485,
      "step": 80400
    },
    {
      "epoch": 9.687951807228917,
      "grad_norm": 0.48707589507102966,
      "learning_rate": 1.0312048192771085e-05,
      "loss": 0.0272,
      "step": 80410
    },
    {
      "epoch": 9.689156626506024,
      "grad_norm": 1.6329796314239502,
      "learning_rate": 1.0310843373493978e-05,
      "loss": 0.0361,
      "step": 80420
    },
    {
      "epoch": 9.690361445783132,
      "grad_norm": 3.8711631298065186,
      "learning_rate": 1.0309638554216867e-05,
      "loss": 0.0386,
      "step": 80430
    },
    {
      "epoch": 9.69156626506024,
      "grad_norm": 1.0553510189056396,
      "learning_rate": 1.030843373493976e-05,
      "loss": 0.0331,
      "step": 80440
    },
    {
      "epoch": 9.69277108433735,
      "grad_norm": 0.01663811504840851,
      "learning_rate": 1.030722891566265e-05,
      "loss": 0.0062,
      "step": 80450
    },
    {
      "epoch": 9.693975903614458,
      "grad_norm": 0.05434457212686539,
      "learning_rate": 1.0306024096385543e-05,
      "loss": 0.0042,
      "step": 80460
    },
    {
      "epoch": 9.695180722891566,
      "grad_norm": 0.04087693616747856,
      "learning_rate": 1.0304819277108435e-05,
      "loss": 0.0163,
      "step": 80470
    },
    {
      "epoch": 9.696385542168674,
      "grad_norm": 0.7458989024162292,
      "learning_rate": 1.0303614457831326e-05,
      "loss": 0.0215,
      "step": 80480
    },
    {
      "epoch": 9.697590361445783,
      "grad_norm": 1.051613211631775,
      "learning_rate": 1.0302409638554218e-05,
      "loss": 0.0117,
      "step": 80490
    },
    {
      "epoch": 9.698795180722891,
      "grad_norm": 0.9717082977294922,
      "learning_rate": 1.0301204819277109e-05,
      "loss": 0.0123,
      "step": 80500
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.00485637690871954,
      "learning_rate": 1.0300000000000001e-05,
      "loss": 0.0346,
      "step": 80510
    },
    {
      "epoch": 9.701204819277109,
      "grad_norm": 1.0865401029586792,
      "learning_rate": 1.0298795180722892e-05,
      "loss": 0.0086,
      "step": 80520
    },
    {
      "epoch": 9.702409638554217,
      "grad_norm": 0.0022764585446566343,
      "learning_rate": 1.0297590361445785e-05,
      "loss": 0.0355,
      "step": 80530
    },
    {
      "epoch": 9.703614457831325,
      "grad_norm": 8.415128707885742,
      "learning_rate": 1.0296385542168677e-05,
      "loss": 0.0361,
      "step": 80540
    },
    {
      "epoch": 9.704819277108435,
      "grad_norm": 6.866734981536865,
      "learning_rate": 1.0295180722891566e-05,
      "loss": 0.0579,
      "step": 80550
    },
    {
      "epoch": 9.706024096385542,
      "grad_norm": 0.012248823419213295,
      "learning_rate": 1.029397590361446e-05,
      "loss": 0.0033,
      "step": 80560
    },
    {
      "epoch": 9.70722891566265,
      "grad_norm": 0.02157258428633213,
      "learning_rate": 1.029277108433735e-05,
      "loss": 0.0196,
      "step": 80570
    },
    {
      "epoch": 9.708433734939758,
      "grad_norm": 4.125543117523193,
      "learning_rate": 1.0291566265060242e-05,
      "loss": 0.0372,
      "step": 80580
    },
    {
      "epoch": 9.709638554216868,
      "grad_norm": 0.5466492176055908,
      "learning_rate": 1.0290361445783132e-05,
      "loss": 0.0203,
      "step": 80590
    },
    {
      "epoch": 9.710843373493976,
      "grad_norm": 0.03116440400481224,
      "learning_rate": 1.0289156626506025e-05,
      "loss": 0.0336,
      "step": 80600
    },
    {
      "epoch": 9.712048192771084,
      "grad_norm": 1.4694782495498657,
      "learning_rate": 1.0287951807228917e-05,
      "loss": 0.044,
      "step": 80610
    },
    {
      "epoch": 9.713253012048193,
      "grad_norm": 0.7092648148536682,
      "learning_rate": 1.0286746987951808e-05,
      "loss": 0.0115,
      "step": 80620
    },
    {
      "epoch": 9.714457831325301,
      "grad_norm": 0.018050966784358025,
      "learning_rate": 1.02855421686747e-05,
      "loss": 0.0417,
      "step": 80630
    },
    {
      "epoch": 9.71566265060241,
      "grad_norm": 0.0013996574562042952,
      "learning_rate": 1.0284337349397591e-05,
      "loss": 0.038,
      "step": 80640
    },
    {
      "epoch": 9.716867469879517,
      "grad_norm": 0.0008431969326920807,
      "learning_rate": 1.0283132530120484e-05,
      "loss": 0.0103,
      "step": 80650
    },
    {
      "epoch": 9.718072289156627,
      "grad_norm": 0.011980078183114529,
      "learning_rate": 1.0281927710843374e-05,
      "loss": 0.0014,
      "step": 80660
    },
    {
      "epoch": 9.719277108433735,
      "grad_norm": 0.6868060231208801,
      "learning_rate": 1.0280722891566267e-05,
      "loss": 0.0067,
      "step": 80670
    },
    {
      "epoch": 9.720481927710843,
      "grad_norm": 0.001425479305908084,
      "learning_rate": 1.027951807228916e-05,
      "loss": 0.0099,
      "step": 80680
    },
    {
      "epoch": 9.721686746987952,
      "grad_norm": 0.011457296088337898,
      "learning_rate": 1.0278313253012048e-05,
      "loss": 0.0426,
      "step": 80690
    },
    {
      "epoch": 9.72289156626506,
      "grad_norm": 5.592257022857666,
      "learning_rate": 1.027710843373494e-05,
      "loss": 0.0754,
      "step": 80700
    },
    {
      "epoch": 9.724096385542168,
      "grad_norm": 0.004278160165995359,
      "learning_rate": 1.0275903614457831e-05,
      "loss": 0.0072,
      "step": 80710
    },
    {
      "epoch": 9.725301204819278,
      "grad_norm": 0.0034964908845722675,
      "learning_rate": 1.0274698795180724e-05,
      "loss": 0.0218,
      "step": 80720
    },
    {
      "epoch": 9.726506024096386,
      "grad_norm": 0.01520374696701765,
      "learning_rate": 1.0273493975903615e-05,
      "loss": 0.0121,
      "step": 80730
    },
    {
      "epoch": 9.727710843373494,
      "grad_norm": 0.3950065076351166,
      "learning_rate": 1.0272289156626507e-05,
      "loss": 0.0403,
      "step": 80740
    },
    {
      "epoch": 9.728915662650602,
      "grad_norm": 2.066948652267456,
      "learning_rate": 1.0271084337349398e-05,
      "loss": 0.0138,
      "step": 80750
    },
    {
      "epoch": 9.730120481927711,
      "grad_norm": 0.017560802400112152,
      "learning_rate": 1.026987951807229e-05,
      "loss": 0.0446,
      "step": 80760
    },
    {
      "epoch": 9.73132530120482,
      "grad_norm": 3.757097005844116,
      "learning_rate": 1.0268674698795183e-05,
      "loss": 0.053,
      "step": 80770
    },
    {
      "epoch": 9.732530120481927,
      "grad_norm": 0.013488998636603355,
      "learning_rate": 1.0267469879518073e-05,
      "loss": 0.0273,
      "step": 80780
    },
    {
      "epoch": 9.733734939759037,
      "grad_norm": 0.2824755012989044,
      "learning_rate": 1.0266265060240966e-05,
      "loss": 0.0033,
      "step": 80790
    },
    {
      "epoch": 9.734939759036145,
      "grad_norm": 3.7734463214874268,
      "learning_rate": 1.0265060240963855e-05,
      "loss": 0.0778,
      "step": 80800
    },
    {
      "epoch": 9.736144578313253,
      "grad_norm": 0.7876701951026917,
      "learning_rate": 1.0263855421686747e-05,
      "loss": 0.0407,
      "step": 80810
    },
    {
      "epoch": 9.73734939759036,
      "grad_norm": 2.2026314735412598,
      "learning_rate": 1.0262650602409638e-05,
      "loss": 0.0132,
      "step": 80820
    },
    {
      "epoch": 9.73855421686747,
      "grad_norm": 0.1559877097606659,
      "learning_rate": 1.026144578313253e-05,
      "loss": 0.0092,
      "step": 80830
    },
    {
      "epoch": 9.739759036144578,
      "grad_norm": 1.1564710140228271,
      "learning_rate": 1.0260240963855423e-05,
      "loss": 0.0653,
      "step": 80840
    },
    {
      "epoch": 9.740963855421686,
      "grad_norm": 0.0027008650358766317,
      "learning_rate": 1.0259036144578314e-05,
      "loss": 0.0243,
      "step": 80850
    },
    {
      "epoch": 9.742168674698796,
      "grad_norm": 6.816894054412842,
      "learning_rate": 1.0257831325301206e-05,
      "loss": 0.0103,
      "step": 80860
    },
    {
      "epoch": 9.743373493975904,
      "grad_norm": 0.0051002600230276585,
      "learning_rate": 1.0256626506024097e-05,
      "loss": 0.0058,
      "step": 80870
    },
    {
      "epoch": 9.744578313253012,
      "grad_norm": 3.7222256660461426,
      "learning_rate": 1.025542168674699e-05,
      "loss": 0.127,
      "step": 80880
    },
    {
      "epoch": 9.745783132530121,
      "grad_norm": 0.038102440536022186,
      "learning_rate": 1.025421686746988e-05,
      "loss": 0.0032,
      "step": 80890
    },
    {
      "epoch": 9.74698795180723,
      "grad_norm": 0.8100659251213074,
      "learning_rate": 1.0253012048192772e-05,
      "loss": 0.0069,
      "step": 80900
    },
    {
      "epoch": 9.748192771084337,
      "grad_norm": 0.002712846267968416,
      "learning_rate": 1.0251807228915665e-05,
      "loss": 0.0105,
      "step": 80910
    },
    {
      "epoch": 9.749397590361445,
      "grad_norm": 0.6597804427146912,
      "learning_rate": 1.0250602409638556e-05,
      "loss": 0.0289,
      "step": 80920
    },
    {
      "epoch": 9.750602409638555,
      "grad_norm": 0.5353356003761292,
      "learning_rate": 1.0249397590361448e-05,
      "loss": 0.0211,
      "step": 80930
    },
    {
      "epoch": 9.751807228915663,
      "grad_norm": 0.03300685063004494,
      "learning_rate": 1.0248192771084337e-05,
      "loss": 0.0268,
      "step": 80940
    },
    {
      "epoch": 9.75301204819277,
      "grad_norm": 0.07475568354129791,
      "learning_rate": 1.024698795180723e-05,
      "loss": 0.0295,
      "step": 80950
    },
    {
      "epoch": 9.754216867469879,
      "grad_norm": 17.516889572143555,
      "learning_rate": 1.024578313253012e-05,
      "loss": 0.0581,
      "step": 80960
    },
    {
      "epoch": 9.755421686746988,
      "grad_norm": 5.260900497436523,
      "learning_rate": 1.0244578313253013e-05,
      "loss": 0.0368,
      "step": 80970
    },
    {
      "epoch": 9.756626506024096,
      "grad_norm": 0.030543211847543716,
      "learning_rate": 1.0243373493975905e-05,
      "loss": 0.0146,
      "step": 80980
    },
    {
      "epoch": 9.757831325301204,
      "grad_norm": 0.2841172218322754,
      "learning_rate": 1.0242168674698796e-05,
      "loss": 0.0276,
      "step": 80990
    },
    {
      "epoch": 9.759036144578314,
      "grad_norm": 0.008257545530796051,
      "learning_rate": 1.0240963855421688e-05,
      "loss": 0.0255,
      "step": 81000
    },
    {
      "epoch": 9.760240963855422,
      "grad_norm": 0.003365256590768695,
      "learning_rate": 1.0239759036144579e-05,
      "loss": 0.0004,
      "step": 81010
    },
    {
      "epoch": 9.76144578313253,
      "grad_norm": 0.13849395513534546,
      "learning_rate": 1.0238554216867471e-05,
      "loss": 0.0216,
      "step": 81020
    },
    {
      "epoch": 9.76265060240964,
      "grad_norm": 0.0274119321256876,
      "learning_rate": 1.0237349397590362e-05,
      "loss": 0.0444,
      "step": 81030
    },
    {
      "epoch": 9.763855421686747,
      "grad_norm": 0.0377434603869915,
      "learning_rate": 1.0236144578313255e-05,
      "loss": 0.0579,
      "step": 81040
    },
    {
      "epoch": 9.765060240963855,
      "grad_norm": 0.3274935483932495,
      "learning_rate": 1.0234939759036144e-05,
      "loss": 0.0147,
      "step": 81050
    },
    {
      "epoch": 9.766265060240963,
      "grad_norm": 0.007546506822109222,
      "learning_rate": 1.0233734939759036e-05,
      "loss": 0.0273,
      "step": 81060
    },
    {
      "epoch": 9.767469879518073,
      "grad_norm": 0.12891149520874023,
      "learning_rate": 1.0232530120481929e-05,
      "loss": 0.02,
      "step": 81070
    },
    {
      "epoch": 9.76867469879518,
      "grad_norm": 0.005428878124803305,
      "learning_rate": 1.023132530120482e-05,
      "loss": 0.042,
      "step": 81080
    },
    {
      "epoch": 9.769879518072289,
      "grad_norm": 0.0017512323101982474,
      "learning_rate": 1.0230120481927712e-05,
      "loss": 0.0193,
      "step": 81090
    },
    {
      "epoch": 9.771084337349398,
      "grad_norm": 0.3186745345592499,
      "learning_rate": 1.0228915662650602e-05,
      "loss": 0.0191,
      "step": 81100
    },
    {
      "epoch": 9.772289156626506,
      "grad_norm": 0.02430391125380993,
      "learning_rate": 1.0227710843373495e-05,
      "loss": 0.0257,
      "step": 81110
    },
    {
      "epoch": 9.773493975903614,
      "grad_norm": 0.8196136951446533,
      "learning_rate": 1.0226506024096386e-05,
      "loss": 0.0316,
      "step": 81120
    },
    {
      "epoch": 9.774698795180722,
      "grad_norm": 0.0038806626107543707,
      "learning_rate": 1.0225301204819278e-05,
      "loss": 0.0081,
      "step": 81130
    },
    {
      "epoch": 9.775903614457832,
      "grad_norm": 1.6680500507354736,
      "learning_rate": 1.022409638554217e-05,
      "loss": 0.0268,
      "step": 81140
    },
    {
      "epoch": 9.77710843373494,
      "grad_norm": 1.8807936906814575,
      "learning_rate": 1.0222891566265061e-05,
      "loss": 0.0379,
      "step": 81150
    },
    {
      "epoch": 9.778313253012048,
      "grad_norm": 7.622833251953125,
      "learning_rate": 1.0221686746987954e-05,
      "loss": 0.029,
      "step": 81160
    },
    {
      "epoch": 9.779518072289157,
      "grad_norm": 0.005007496103644371,
      "learning_rate": 1.0220481927710843e-05,
      "loss": 0.014,
      "step": 81170
    },
    {
      "epoch": 9.780722891566265,
      "grad_norm": 0.029828470200300217,
      "learning_rate": 1.0219277108433737e-05,
      "loss": 0.0929,
      "step": 81180
    },
    {
      "epoch": 9.781927710843373,
      "grad_norm": 0.11239603161811829,
      "learning_rate": 1.0218072289156626e-05,
      "loss": 0.0343,
      "step": 81190
    },
    {
      "epoch": 9.783132530120483,
      "grad_norm": 2.1401138305664062,
      "learning_rate": 1.0216867469879518e-05,
      "loss": 0.0439,
      "step": 81200
    },
    {
      "epoch": 9.78433734939759,
      "grad_norm": 0.10252482444047928,
      "learning_rate": 1.021566265060241e-05,
      "loss": 0.0205,
      "step": 81210
    },
    {
      "epoch": 9.785542168674699,
      "grad_norm": 0.07502079010009766,
      "learning_rate": 1.0214457831325302e-05,
      "loss": 0.0058,
      "step": 81220
    },
    {
      "epoch": 9.786746987951807,
      "grad_norm": 0.02778269164264202,
      "learning_rate": 1.0213253012048194e-05,
      "loss": 0.0382,
      "step": 81230
    },
    {
      "epoch": 9.787951807228916,
      "grad_norm": 0.016324101015925407,
      "learning_rate": 1.0212048192771085e-05,
      "loss": 0.0091,
      "step": 81240
    },
    {
      "epoch": 9.789156626506024,
      "grad_norm": 0.2489352524280548,
      "learning_rate": 1.0210843373493977e-05,
      "loss": 0.0305,
      "step": 81250
    },
    {
      "epoch": 9.790361445783132,
      "grad_norm": 0.9697248339653015,
      "learning_rate": 1.0209638554216868e-05,
      "loss": 0.0143,
      "step": 81260
    },
    {
      "epoch": 9.791566265060242,
      "grad_norm": 0.03174476698040962,
      "learning_rate": 1.020843373493976e-05,
      "loss": 0.027,
      "step": 81270
    },
    {
      "epoch": 9.79277108433735,
      "grad_norm": 0.03509606420993805,
      "learning_rate": 1.0207228915662653e-05,
      "loss": 0.0163,
      "step": 81280
    },
    {
      "epoch": 9.793975903614458,
      "grad_norm": 0.0031128968112170696,
      "learning_rate": 1.0206024096385544e-05,
      "loss": 0.0067,
      "step": 81290
    },
    {
      "epoch": 9.795180722891565,
      "grad_norm": 0.04832865670323372,
      "learning_rate": 1.0204819277108436e-05,
      "loss": 0.0031,
      "step": 81300
    },
    {
      "epoch": 9.796385542168675,
      "grad_norm": 0.011484072543680668,
      "learning_rate": 1.0203614457831325e-05,
      "loss": 0.0392,
      "step": 81310
    },
    {
      "epoch": 9.797590361445783,
      "grad_norm": 5.471024036407471,
      "learning_rate": 1.0202409638554217e-05,
      "loss": 0.0767,
      "step": 81320
    },
    {
      "epoch": 9.798795180722891,
      "grad_norm": 0.17239098250865936,
      "learning_rate": 1.0201204819277108e-05,
      "loss": 0.0431,
      "step": 81330
    },
    {
      "epoch": 9.8,
      "grad_norm": 1.432132601737976,
      "learning_rate": 1.02e-05,
      "loss": 0.0314,
      "step": 81340
    },
    {
      "epoch": 9.801204819277109,
      "grad_norm": 4.1493096351623535,
      "learning_rate": 1.0198795180722891e-05,
      "loss": 0.0421,
      "step": 81350
    },
    {
      "epoch": 9.802409638554217,
      "grad_norm": 0.02058061584830284,
      "learning_rate": 1.0197590361445784e-05,
      "loss": 0.0262,
      "step": 81360
    },
    {
      "epoch": 9.803614457831326,
      "grad_norm": 0.02977507933974266,
      "learning_rate": 1.0196385542168676e-05,
      "loss": 0.0285,
      "step": 81370
    },
    {
      "epoch": 9.804819277108434,
      "grad_norm": 0.29280632734298706,
      "learning_rate": 1.0195180722891567e-05,
      "loss": 0.0513,
      "step": 81380
    },
    {
      "epoch": 9.806024096385542,
      "grad_norm": 0.03695705160498619,
      "learning_rate": 1.019397590361446e-05,
      "loss": 0.0123,
      "step": 81390
    },
    {
      "epoch": 9.80722891566265,
      "grad_norm": 1.0133146047592163,
      "learning_rate": 1.019277108433735e-05,
      "loss": 0.0283,
      "step": 81400
    },
    {
      "epoch": 9.80843373493976,
      "grad_norm": 0.08927131444215775,
      "learning_rate": 1.0191566265060243e-05,
      "loss": 0.0492,
      "step": 81410
    },
    {
      "epoch": 9.809638554216868,
      "grad_norm": 0.004051043186336756,
      "learning_rate": 1.0190361445783132e-05,
      "loss": 0.0161,
      "step": 81420
    },
    {
      "epoch": 9.810843373493976,
      "grad_norm": 7.385066032409668,
      "learning_rate": 1.0189156626506024e-05,
      "loss": 0.0286,
      "step": 81430
    },
    {
      "epoch": 9.812048192771083,
      "grad_norm": 0.056196700781583786,
      "learning_rate": 1.0187951807228918e-05,
      "loss": 0.0051,
      "step": 81440
    },
    {
      "epoch": 9.813253012048193,
      "grad_norm": 0.07372117787599564,
      "learning_rate": 1.0186746987951807e-05,
      "loss": 0.0188,
      "step": 81450
    },
    {
      "epoch": 9.814457831325301,
      "grad_norm": 0.0062551493756473064,
      "learning_rate": 1.01855421686747e-05,
      "loss": 0.0139,
      "step": 81460
    },
    {
      "epoch": 9.815662650602409,
      "grad_norm": 0.007880432531237602,
      "learning_rate": 1.018433734939759e-05,
      "loss": 0.0304,
      "step": 81470
    },
    {
      "epoch": 9.816867469879519,
      "grad_norm": 0.005511063616722822,
      "learning_rate": 1.0183132530120483e-05,
      "loss": 0.0387,
      "step": 81480
    },
    {
      "epoch": 9.818072289156627,
      "grad_norm": 0.003497829893603921,
      "learning_rate": 1.0181927710843374e-05,
      "loss": 0.0273,
      "step": 81490
    },
    {
      "epoch": 9.819277108433734,
      "grad_norm": 3.1943814754486084,
      "learning_rate": 1.0180722891566266e-05,
      "loss": 0.0191,
      "step": 81500
    },
    {
      "epoch": 9.820481927710844,
      "grad_norm": 0.14778706431388855,
      "learning_rate": 1.0179518072289158e-05,
      "loss": 0.034,
      "step": 81510
    },
    {
      "epoch": 9.821686746987952,
      "grad_norm": 0.004153114277869463,
      "learning_rate": 1.017831325301205e-05,
      "loss": 0.0158,
      "step": 81520
    },
    {
      "epoch": 9.82289156626506,
      "grad_norm": 0.013445574790239334,
      "learning_rate": 1.0177108433734942e-05,
      "loss": 0.0366,
      "step": 81530
    },
    {
      "epoch": 9.824096385542168,
      "grad_norm": 0.005734746344387531,
      "learning_rate": 1.0175903614457832e-05,
      "loss": 0.0094,
      "step": 81540
    },
    {
      "epoch": 9.825301204819278,
      "grad_norm": 0.015837453305721283,
      "learning_rate": 1.0174698795180725e-05,
      "loss": 0.0147,
      "step": 81550
    },
    {
      "epoch": 9.826506024096386,
      "grad_norm": 1.9026840925216675,
      "learning_rate": 1.0173493975903614e-05,
      "loss": 0.02,
      "step": 81560
    },
    {
      "epoch": 9.827710843373493,
      "grad_norm": 0.005374759901314974,
      "learning_rate": 1.0172289156626506e-05,
      "loss": 0.0212,
      "step": 81570
    },
    {
      "epoch": 9.828915662650603,
      "grad_norm": 15.611834526062012,
      "learning_rate": 1.0171084337349399e-05,
      "loss": 0.0288,
      "step": 81580
    },
    {
      "epoch": 9.830120481927711,
      "grad_norm": 0.7957897782325745,
      "learning_rate": 1.016987951807229e-05,
      "loss": 0.0799,
      "step": 81590
    },
    {
      "epoch": 9.831325301204819,
      "grad_norm": 1.8781852722167969,
      "learning_rate": 1.0168674698795182e-05,
      "loss": 0.0301,
      "step": 81600
    },
    {
      "epoch": 9.832530120481927,
      "grad_norm": 0.3772285580635071,
      "learning_rate": 1.0167469879518073e-05,
      "loss": 0.0067,
      "step": 81610
    },
    {
      "epoch": 9.833734939759037,
      "grad_norm": 0.0054552629590034485,
      "learning_rate": 1.0166265060240965e-05,
      "loss": 0.0137,
      "step": 81620
    },
    {
      "epoch": 9.834939759036144,
      "grad_norm": 0.1935933530330658,
      "learning_rate": 1.0165060240963856e-05,
      "loss": 0.0314,
      "step": 81630
    },
    {
      "epoch": 9.836144578313252,
      "grad_norm": 0.0003722168621607125,
      "learning_rate": 1.0163855421686748e-05,
      "loss": 0.017,
      "step": 81640
    },
    {
      "epoch": 9.837349397590362,
      "grad_norm": 0.0022707462776452303,
      "learning_rate": 1.0162650602409639e-05,
      "loss": 0.0186,
      "step": 81650
    },
    {
      "epoch": 9.83855421686747,
      "grad_norm": 0.005596308037638664,
      "learning_rate": 1.0161445783132531e-05,
      "loss": 0.0211,
      "step": 81660
    },
    {
      "epoch": 9.839759036144578,
      "grad_norm": 1.8271466493606567,
      "learning_rate": 1.0160240963855424e-05,
      "loss": 0.0551,
      "step": 81670
    },
    {
      "epoch": 9.840963855421688,
      "grad_norm": 5.508415699005127,
      "learning_rate": 1.0159036144578313e-05,
      "loss": 0.0362,
      "step": 81680
    },
    {
      "epoch": 9.842168674698796,
      "grad_norm": 0.003783053020015359,
      "learning_rate": 1.0157831325301207e-05,
      "loss": 0.0422,
      "step": 81690
    },
    {
      "epoch": 9.843373493975903,
      "grad_norm": 0.05882769078016281,
      "learning_rate": 1.0156626506024096e-05,
      "loss": 0.0375,
      "step": 81700
    },
    {
      "epoch": 9.844578313253011,
      "grad_norm": 0.14661343395709991,
      "learning_rate": 1.0155421686746989e-05,
      "loss": 0.0809,
      "step": 81710
    },
    {
      "epoch": 9.845783132530121,
      "grad_norm": 0.8489518761634827,
      "learning_rate": 1.015421686746988e-05,
      "loss": 0.0163,
      "step": 81720
    },
    {
      "epoch": 9.846987951807229,
      "grad_norm": 0.16620175540447235,
      "learning_rate": 1.0153012048192772e-05,
      "loss": 0.0023,
      "step": 81730
    },
    {
      "epoch": 9.848192771084337,
      "grad_norm": 0.02664538100361824,
      "learning_rate": 1.0151807228915664e-05,
      "loss": 0.0211,
      "step": 81740
    },
    {
      "epoch": 9.849397590361447,
      "grad_norm": 0.011841864325106144,
      "learning_rate": 1.0150602409638555e-05,
      "loss": 0.0059,
      "step": 81750
    },
    {
      "epoch": 9.850602409638554,
      "grad_norm": 0.060240913182497025,
      "learning_rate": 1.0149397590361447e-05,
      "loss": 0.0559,
      "step": 81760
    },
    {
      "epoch": 9.851807228915662,
      "grad_norm": 0.6736116409301758,
      "learning_rate": 1.0148192771084338e-05,
      "loss": 0.0375,
      "step": 81770
    },
    {
      "epoch": 9.85301204819277,
      "grad_norm": 0.003702197689563036,
      "learning_rate": 1.014698795180723e-05,
      "loss": 0.0268,
      "step": 81780
    },
    {
      "epoch": 9.85421686746988,
      "grad_norm": 0.22440241277217865,
      "learning_rate": 1.0145783132530121e-05,
      "loss": 0.013,
      "step": 81790
    },
    {
      "epoch": 9.855421686746988,
      "grad_norm": 0.03356212005019188,
      "learning_rate": 1.0144578313253014e-05,
      "loss": 0.009,
      "step": 81800
    },
    {
      "epoch": 9.856626506024096,
      "grad_norm": 0.0008892518235370517,
      "learning_rate": 1.0143373493975906e-05,
      "loss": 0.0052,
      "step": 81810
    },
    {
      "epoch": 9.857831325301206,
      "grad_norm": 0.7952755689620972,
      "learning_rate": 1.0142168674698795e-05,
      "loss": 0.0543,
      "step": 81820
    },
    {
      "epoch": 9.859036144578313,
      "grad_norm": 0.024426942691206932,
      "learning_rate": 1.0140963855421688e-05,
      "loss": 0.0139,
      "step": 81830
    },
    {
      "epoch": 9.860240963855421,
      "grad_norm": 0.00817134790122509,
      "learning_rate": 1.0139759036144578e-05,
      "loss": 0.037,
      "step": 81840
    },
    {
      "epoch": 9.861445783132531,
      "grad_norm": 3.2911839485168457,
      "learning_rate": 1.013855421686747e-05,
      "loss": 0.0547,
      "step": 81850
    },
    {
      "epoch": 9.862650602409639,
      "grad_norm": 0.09525145590305328,
      "learning_rate": 1.0137349397590361e-05,
      "loss": 0.035,
      "step": 81860
    },
    {
      "epoch": 9.863855421686747,
      "grad_norm": 0.02405768819153309,
      "learning_rate": 1.0136144578313254e-05,
      "loss": 0.0228,
      "step": 81870
    },
    {
      "epoch": 9.865060240963855,
      "grad_norm": 14.92558479309082,
      "learning_rate": 1.0134939759036146e-05,
      "loss": 0.0072,
      "step": 81880
    },
    {
      "epoch": 9.866265060240965,
      "grad_norm": 0.008287234231829643,
      "learning_rate": 1.0133734939759037e-05,
      "loss": 0.0036,
      "step": 81890
    },
    {
      "epoch": 9.867469879518072,
      "grad_norm": 0.7903580069541931,
      "learning_rate": 1.013253012048193e-05,
      "loss": 0.0117,
      "step": 81900
    },
    {
      "epoch": 9.86867469879518,
      "grad_norm": 6.122595310211182,
      "learning_rate": 1.013132530120482e-05,
      "loss": 0.089,
      "step": 81910
    },
    {
      "epoch": 9.869879518072288,
      "grad_norm": 0.06193070858716965,
      "learning_rate": 1.0130120481927713e-05,
      "loss": 0.0046,
      "step": 81920
    },
    {
      "epoch": 9.871084337349398,
      "grad_norm": 0.35157716274261475,
      "learning_rate": 1.0128915662650602e-05,
      "loss": 0.0179,
      "step": 81930
    },
    {
      "epoch": 9.872289156626506,
      "grad_norm": 0.022400330752134323,
      "learning_rate": 1.0127710843373494e-05,
      "loss": 0.0015,
      "step": 81940
    },
    {
      "epoch": 9.873493975903614,
      "grad_norm": 0.014859650284051895,
      "learning_rate": 1.0126506024096385e-05,
      "loss": 0.0334,
      "step": 81950
    },
    {
      "epoch": 9.874698795180723,
      "grad_norm": 0.014192377217113972,
      "learning_rate": 1.0125301204819277e-05,
      "loss": 0.0084,
      "step": 81960
    },
    {
      "epoch": 9.875903614457831,
      "grad_norm": 0.16722433269023895,
      "learning_rate": 1.012409638554217e-05,
      "loss": 0.0068,
      "step": 81970
    },
    {
      "epoch": 9.87710843373494,
      "grad_norm": 7.452653884887695,
      "learning_rate": 1.012289156626506e-05,
      "loss": 0.041,
      "step": 81980
    },
    {
      "epoch": 9.878313253012049,
      "grad_norm": 1.8532474040985107,
      "learning_rate": 1.0121686746987953e-05,
      "loss": 0.0581,
      "step": 81990
    },
    {
      "epoch": 9.879518072289157,
      "grad_norm": 1.7358781099319458,
      "learning_rate": 1.0120481927710844e-05,
      "loss": 0.0614,
      "step": 82000
    },
    {
      "epoch": 9.880722891566265,
      "grad_norm": 0.008170553483068943,
      "learning_rate": 1.0119277108433736e-05,
      "loss": 0.0449,
      "step": 82010
    },
    {
      "epoch": 9.881927710843373,
      "grad_norm": 0.5106310844421387,
      "learning_rate": 1.0118072289156627e-05,
      "loss": 0.0297,
      "step": 82020
    },
    {
      "epoch": 9.883132530120482,
      "grad_norm": 2.007822036743164,
      "learning_rate": 1.011686746987952e-05,
      "loss": 0.0363,
      "step": 82030
    },
    {
      "epoch": 9.88433734939759,
      "grad_norm": 0.37772825360298157,
      "learning_rate": 1.0115662650602412e-05,
      "loss": 0.0259,
      "step": 82040
    },
    {
      "epoch": 9.885542168674698,
      "grad_norm": 0.03879552334547043,
      "learning_rate": 1.0114457831325302e-05,
      "loss": 0.0304,
      "step": 82050
    },
    {
      "epoch": 9.886746987951808,
      "grad_norm": 1.7164723873138428,
      "learning_rate": 1.0113253012048195e-05,
      "loss": 0.0228,
      "step": 82060
    },
    {
      "epoch": 9.887951807228916,
      "grad_norm": 1.142319917678833,
      "learning_rate": 1.0112048192771084e-05,
      "loss": 0.0436,
      "step": 82070
    },
    {
      "epoch": 9.889156626506024,
      "grad_norm": 0.006533917970955372,
      "learning_rate": 1.0110843373493976e-05,
      "loss": 0.0203,
      "step": 82080
    },
    {
      "epoch": 9.890361445783132,
      "grad_norm": 0.32536131143569946,
      "learning_rate": 1.0109638554216867e-05,
      "loss": 0.0459,
      "step": 82090
    },
    {
      "epoch": 9.891566265060241,
      "grad_norm": 0.004737350158393383,
      "learning_rate": 1.010843373493976e-05,
      "loss": 0.0174,
      "step": 82100
    },
    {
      "epoch": 9.89277108433735,
      "grad_norm": 0.014218149706721306,
      "learning_rate": 1.0107228915662652e-05,
      "loss": 0.0203,
      "step": 82110
    },
    {
      "epoch": 9.893975903614457,
      "grad_norm": 0.0028321403078734875,
      "learning_rate": 1.0106024096385543e-05,
      "loss": 0.0325,
      "step": 82120
    },
    {
      "epoch": 9.895180722891567,
      "grad_norm": 0.0025701764971017838,
      "learning_rate": 1.0104819277108435e-05,
      "loss": 0.0659,
      "step": 82130
    },
    {
      "epoch": 9.896385542168675,
      "grad_norm": 26.569499969482422,
      "learning_rate": 1.0103614457831326e-05,
      "loss": 0.0205,
      "step": 82140
    },
    {
      "epoch": 9.897590361445783,
      "grad_norm": 0.2773013412952423,
      "learning_rate": 1.0102409638554218e-05,
      "loss": 0.006,
      "step": 82150
    },
    {
      "epoch": 9.898795180722892,
      "grad_norm": 0.025551756843924522,
      "learning_rate": 1.0101204819277109e-05,
      "loss": 0.0309,
      "step": 82160
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.004124575760215521,
      "learning_rate": 1.0100000000000002e-05,
      "loss": 0.0111,
      "step": 82170
    },
    {
      "epoch": 9.901204819277108,
      "grad_norm": 34.23810958862305,
      "learning_rate": 1.0098795180722894e-05,
      "loss": 0.0679,
      "step": 82180
    },
    {
      "epoch": 9.902409638554216,
      "grad_norm": 0.3410321772098541,
      "learning_rate": 1.0097590361445783e-05,
      "loss": 0.0178,
      "step": 82190
    },
    {
      "epoch": 9.903614457831326,
      "grad_norm": 0.006785353645682335,
      "learning_rate": 1.0096385542168675e-05,
      "loss": 0.0137,
      "step": 82200
    },
    {
      "epoch": 9.904819277108434,
      "grad_norm": 0.12022752314805984,
      "learning_rate": 1.0095180722891566e-05,
      "loss": 0.0128,
      "step": 82210
    },
    {
      "epoch": 9.906024096385542,
      "grad_norm": 0.0307460930198431,
      "learning_rate": 1.0093975903614459e-05,
      "loss": 0.069,
      "step": 82220
    },
    {
      "epoch": 9.907228915662651,
      "grad_norm": 0.0027270696591585875,
      "learning_rate": 1.009277108433735e-05,
      "loss": 0.0124,
      "step": 82230
    },
    {
      "epoch": 9.90843373493976,
      "grad_norm": 0.004864411428570747,
      "learning_rate": 1.0091566265060242e-05,
      "loss": 0.0069,
      "step": 82240
    },
    {
      "epoch": 9.909638554216867,
      "grad_norm": 0.005932582542300224,
      "learning_rate": 1.0090361445783133e-05,
      "loss": 0.0102,
      "step": 82250
    },
    {
      "epoch": 9.910843373493975,
      "grad_norm": 0.768077552318573,
      "learning_rate": 1.0089156626506025e-05,
      "loss": 0.0235,
      "step": 82260
    },
    {
      "epoch": 9.912048192771085,
      "grad_norm": 0.008444532752037048,
      "learning_rate": 1.0087951807228917e-05,
      "loss": 0.016,
      "step": 82270
    },
    {
      "epoch": 9.913253012048193,
      "grad_norm": 8.1473970413208,
      "learning_rate": 1.0086746987951808e-05,
      "loss": 0.0625,
      "step": 82280
    },
    {
      "epoch": 9.9144578313253,
      "grad_norm": 6.298933982849121,
      "learning_rate": 1.00855421686747e-05,
      "loss": 0.0137,
      "step": 82290
    },
    {
      "epoch": 9.91566265060241,
      "grad_norm": 1.6062138080596924,
      "learning_rate": 1.008433734939759e-05,
      "loss": 0.0116,
      "step": 82300
    },
    {
      "epoch": 9.916867469879518,
      "grad_norm": 0.12973621487617493,
      "learning_rate": 1.0083132530120484e-05,
      "loss": 0.0152,
      "step": 82310
    },
    {
      "epoch": 9.918072289156626,
      "grad_norm": 0.03259514644742012,
      "learning_rate": 1.0081927710843373e-05,
      "loss": 0.0029,
      "step": 82320
    },
    {
      "epoch": 9.919277108433734,
      "grad_norm": 1.1888432502746582,
      "learning_rate": 1.0080722891566265e-05,
      "loss": 0.0288,
      "step": 82330
    },
    {
      "epoch": 9.920481927710844,
      "grad_norm": 0.7899660468101501,
      "learning_rate": 1.0079518072289158e-05,
      "loss": 0.025,
      "step": 82340
    },
    {
      "epoch": 9.921686746987952,
      "grad_norm": 0.03925512358546257,
      "learning_rate": 1.0078313253012048e-05,
      "loss": 0.0365,
      "step": 82350
    },
    {
      "epoch": 9.92289156626506,
      "grad_norm": 0.10744357109069824,
      "learning_rate": 1.0077108433734941e-05,
      "loss": 0.0065,
      "step": 82360
    },
    {
      "epoch": 9.92409638554217,
      "grad_norm": 0.007780428975820541,
      "learning_rate": 1.0075903614457832e-05,
      "loss": 0.0561,
      "step": 82370
    },
    {
      "epoch": 9.925301204819277,
      "grad_norm": 0.02645459584891796,
      "learning_rate": 1.0074698795180724e-05,
      "loss": 0.0635,
      "step": 82380
    },
    {
      "epoch": 9.926506024096385,
      "grad_norm": 0.006487461272627115,
      "learning_rate": 1.0073493975903615e-05,
      "loss": 0.015,
      "step": 82390
    },
    {
      "epoch": 9.927710843373493,
      "grad_norm": 0.015498453751206398,
      "learning_rate": 1.0072289156626507e-05,
      "loss": 0.0494,
      "step": 82400
    },
    {
      "epoch": 9.928915662650603,
      "grad_norm": 0.05613090097904205,
      "learning_rate": 1.00710843373494e-05,
      "loss": 0.0327,
      "step": 82410
    },
    {
      "epoch": 9.93012048192771,
      "grad_norm": 1.4534980058670044,
      "learning_rate": 1.006987951807229e-05,
      "loss": 0.0356,
      "step": 82420
    },
    {
      "epoch": 9.931325301204819,
      "grad_norm": 0.026102958247065544,
      "learning_rate": 1.0068674698795183e-05,
      "loss": 0.0498,
      "step": 82430
    },
    {
      "epoch": 9.932530120481928,
      "grad_norm": 2.870063304901123,
      "learning_rate": 1.0067469879518072e-05,
      "loss": 0.0314,
      "step": 82440
    },
    {
      "epoch": 9.933734939759036,
      "grad_norm": 1.3373126983642578,
      "learning_rate": 1.0066265060240964e-05,
      "loss": 0.0172,
      "step": 82450
    },
    {
      "epoch": 9.934939759036144,
      "grad_norm": 0.014056340791285038,
      "learning_rate": 1.0065060240963855e-05,
      "loss": 0.0087,
      "step": 82460
    },
    {
      "epoch": 9.936144578313254,
      "grad_norm": 0.8505769968032837,
      "learning_rate": 1.0063855421686748e-05,
      "loss": 0.0152,
      "step": 82470
    },
    {
      "epoch": 9.937349397590362,
      "grad_norm": 4.045742511749268,
      "learning_rate": 1.006265060240964e-05,
      "loss": 0.0326,
      "step": 82480
    },
    {
      "epoch": 9.93855421686747,
      "grad_norm": 0.8864503502845764,
      "learning_rate": 1.006144578313253e-05,
      "loss": 0.0468,
      "step": 82490
    },
    {
      "epoch": 9.939759036144578,
      "grad_norm": 0.07101728767156601,
      "learning_rate": 1.0060240963855423e-05,
      "loss": 0.0514,
      "step": 82500
    },
    {
      "epoch": 9.940963855421687,
      "grad_norm": 0.02255220152437687,
      "learning_rate": 1.0059036144578314e-05,
      "loss": 0.0009,
      "step": 82510
    },
    {
      "epoch": 9.942168674698795,
      "grad_norm": 0.021102679893374443,
      "learning_rate": 1.0057831325301206e-05,
      "loss": 0.0065,
      "step": 82520
    },
    {
      "epoch": 9.943373493975903,
      "grad_norm": 0.3581809103488922,
      "learning_rate": 1.0056626506024097e-05,
      "loss": 0.0367,
      "step": 82530
    },
    {
      "epoch": 9.944578313253013,
      "grad_norm": 0.009671433828771114,
      "learning_rate": 1.005542168674699e-05,
      "loss": 0.0026,
      "step": 82540
    },
    {
      "epoch": 9.94578313253012,
      "grad_norm": 6.665035724639893,
      "learning_rate": 1.0054216867469879e-05,
      "loss": 0.085,
      "step": 82550
    },
    {
      "epoch": 9.946987951807229,
      "grad_norm": 0.08304249495267868,
      "learning_rate": 1.0053012048192771e-05,
      "loss": 0.0246,
      "step": 82560
    },
    {
      "epoch": 9.948192771084337,
      "grad_norm": 3.1767215728759766,
      "learning_rate": 1.0051807228915665e-05,
      "loss": 0.0553,
      "step": 82570
    },
    {
      "epoch": 9.949397590361446,
      "grad_norm": 0.010424003936350346,
      "learning_rate": 1.0050602409638554e-05,
      "loss": 0.0364,
      "step": 82580
    },
    {
      "epoch": 9.950602409638554,
      "grad_norm": 1.8857707977294922,
      "learning_rate": 1.0049397590361447e-05,
      "loss": 0.0306,
      "step": 82590
    },
    {
      "epoch": 9.951807228915662,
      "grad_norm": 0.06976833939552307,
      "learning_rate": 1.0048192771084337e-05,
      "loss": 0.0159,
      "step": 82600
    },
    {
      "epoch": 9.953012048192772,
      "grad_norm": 0.05922553688287735,
      "learning_rate": 1.004698795180723e-05,
      "loss": 0.0226,
      "step": 82610
    },
    {
      "epoch": 9.95421686746988,
      "grad_norm": 0.04781883955001831,
      "learning_rate": 1.004578313253012e-05,
      "loss": 0.0335,
      "step": 82620
    },
    {
      "epoch": 9.955421686746988,
      "grad_norm": 0.020841117948293686,
      "learning_rate": 1.0044578313253013e-05,
      "loss": 0.0078,
      "step": 82630
    },
    {
      "epoch": 9.956626506024097,
      "grad_norm": 18.670642852783203,
      "learning_rate": 1.0043373493975905e-05,
      "loss": 0.0134,
      "step": 82640
    },
    {
      "epoch": 9.957831325301205,
      "grad_norm": 0.23715628683567047,
      "learning_rate": 1.0042168674698796e-05,
      "loss": 0.023,
      "step": 82650
    },
    {
      "epoch": 9.959036144578313,
      "grad_norm": 0.002065281616523862,
      "learning_rate": 1.0040963855421689e-05,
      "loss": 0.0064,
      "step": 82660
    },
    {
      "epoch": 9.960240963855421,
      "grad_norm": 0.967406690120697,
      "learning_rate": 1.003975903614458e-05,
      "loss": 0.0714,
      "step": 82670
    },
    {
      "epoch": 9.96144578313253,
      "grad_norm": 0.011501409113407135,
      "learning_rate": 1.0038554216867472e-05,
      "loss": 0.0114,
      "step": 82680
    },
    {
      "epoch": 9.962650602409639,
      "grad_norm": 0.013262179680168629,
      "learning_rate": 1.003734939759036e-05,
      "loss": 0.0209,
      "step": 82690
    },
    {
      "epoch": 9.963855421686747,
      "grad_norm": 0.7758440375328064,
      "learning_rate": 1.0036144578313253e-05,
      "loss": 0.023,
      "step": 82700
    },
    {
      "epoch": 9.965060240963856,
      "grad_norm": 0.003995921928435564,
      "learning_rate": 1.0034939759036146e-05,
      "loss": 0.0049,
      "step": 82710
    },
    {
      "epoch": 9.966265060240964,
      "grad_norm": 2.71112322807312,
      "learning_rate": 1.0033734939759036e-05,
      "loss": 0.0369,
      "step": 82720
    },
    {
      "epoch": 9.967469879518072,
      "grad_norm": 0.004351573996245861,
      "learning_rate": 1.0032530120481929e-05,
      "loss": 0.0109,
      "step": 82730
    },
    {
      "epoch": 9.96867469879518,
      "grad_norm": 0.007253848947584629,
      "learning_rate": 1.003132530120482e-05,
      "loss": 0.0209,
      "step": 82740
    },
    {
      "epoch": 9.96987951807229,
      "grad_norm": 1.832503080368042,
      "learning_rate": 1.0030120481927712e-05,
      "loss": 0.0449,
      "step": 82750
    },
    {
      "epoch": 9.971084337349398,
      "grad_norm": 0.001092136837542057,
      "learning_rate": 1.0028915662650603e-05,
      "loss": 0.0244,
      "step": 82760
    },
    {
      "epoch": 9.972289156626506,
      "grad_norm": 0.055072247982025146,
      "learning_rate": 1.0027710843373495e-05,
      "loss": 0.0077,
      "step": 82770
    },
    {
      "epoch": 9.973493975903615,
      "grad_norm": 1.5432000160217285,
      "learning_rate": 1.0026506024096388e-05,
      "loss": 0.0563,
      "step": 82780
    },
    {
      "epoch": 9.974698795180723,
      "grad_norm": 0.9152930974960327,
      "learning_rate": 1.0025301204819278e-05,
      "loss": 0.0276,
      "step": 82790
    },
    {
      "epoch": 9.975903614457831,
      "grad_norm": 0.0014184418832883239,
      "learning_rate": 1.002409638554217e-05,
      "loss": 0.0063,
      "step": 82800
    },
    {
      "epoch": 9.977108433734939,
      "grad_norm": 0.9723716378211975,
      "learning_rate": 1.002289156626506e-05,
      "loss": 0.0147,
      "step": 82810
    },
    {
      "epoch": 9.978313253012049,
      "grad_norm": 0.0035056944470852613,
      "learning_rate": 1.0021686746987952e-05,
      "loss": 0.0144,
      "step": 82820
    },
    {
      "epoch": 9.979518072289157,
      "grad_norm": 0.008483702316880226,
      "learning_rate": 1.0020481927710843e-05,
      "loss": 0.0002,
      "step": 82830
    },
    {
      "epoch": 9.980722891566264,
      "grad_norm": 0.5670039057731628,
      "learning_rate": 1.0019277108433735e-05,
      "loss": 0.0359,
      "step": 82840
    },
    {
      "epoch": 9.981927710843374,
      "grad_norm": 0.9627991318702698,
      "learning_rate": 1.0018072289156626e-05,
      "loss": 0.0379,
      "step": 82850
    },
    {
      "epoch": 9.983132530120482,
      "grad_norm": 10.068633079528809,
      "learning_rate": 1.0016867469879519e-05,
      "loss": 0.0299,
      "step": 82860
    },
    {
      "epoch": 9.98433734939759,
      "grad_norm": 1.6781160831451416,
      "learning_rate": 1.0015662650602411e-05,
      "loss": 0.0239,
      "step": 82870
    },
    {
      "epoch": 9.985542168674698,
      "grad_norm": 1.7180869579315186,
      "learning_rate": 1.0014457831325302e-05,
      "loss": 0.0689,
      "step": 82880
    },
    {
      "epoch": 9.986746987951808,
      "grad_norm": 3.9743597507476807,
      "learning_rate": 1.0013253012048194e-05,
      "loss": 0.0518,
      "step": 82890
    },
    {
      "epoch": 9.987951807228916,
      "grad_norm": 0.0061418283730745316,
      "learning_rate": 1.0012048192771085e-05,
      "loss": 0.063,
      "step": 82900
    },
    {
      "epoch": 9.989156626506023,
      "grad_norm": 6.274116516113281,
      "learning_rate": 1.0010843373493977e-05,
      "loss": 0.0389,
      "step": 82910
    },
    {
      "epoch": 9.990361445783133,
      "grad_norm": 0.7795713543891907,
      "learning_rate": 1.0009638554216866e-05,
      "loss": 0.0057,
      "step": 82920
    },
    {
      "epoch": 9.991566265060241,
      "grad_norm": 0.8269497752189636,
      "learning_rate": 1.000843373493976e-05,
      "loss": 0.0276,
      "step": 82930
    },
    {
      "epoch": 9.992771084337349,
      "grad_norm": 0.0101259620860219,
      "learning_rate": 1.0007228915662653e-05,
      "loss": 0.0251,
      "step": 82940
    },
    {
      "epoch": 9.993975903614459,
      "grad_norm": 0.2805593013763428,
      "learning_rate": 1.0006024096385542e-05,
      "loss": 0.0312,
      "step": 82950
    },
    {
      "epoch": 9.995180722891567,
      "grad_norm": 0.006519916467368603,
      "learning_rate": 1.0004819277108434e-05,
      "loss": 0.0051,
      "step": 82960
    },
    {
      "epoch": 9.996385542168674,
      "grad_norm": 1.5576694011688232,
      "learning_rate": 1.0003614457831325e-05,
      "loss": 0.0158,
      "step": 82970
    },
    {
      "epoch": 9.997590361445782,
      "grad_norm": 0.0013919335324317217,
      "learning_rate": 1.0002409638554218e-05,
      "loss": 0.0066,
      "step": 82980
    },
    {
      "epoch": 9.998795180722892,
      "grad_norm": 3.059450387954712,
      "learning_rate": 1.0001204819277108e-05,
      "loss": 0.0422,
      "step": 82990
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.018572527915239334,
      "learning_rate": 1e-05,
      "loss": 0.0058,
      "step": 83000
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9856346081739783,
      "eval_f1": 0.9623764806972319,
      "eval_loss": 0.0487857460975647,
      "eval_precision": 0.9558644233113874,
      "eval_recall": 0.9689778766530713,
      "eval_runtime": 3384.2507,
      "eval_samples_per_second": 12.614,
      "eval_steps_per_second": 0.526,
      "step": 83000
    },
    {
      "epoch": 10.001204819277108,
      "grad_norm": 0.010321613401174545,
      "learning_rate": 9.998795180722892e-06,
      "loss": 0.0026,
      "step": 83010
    },
    {
      "epoch": 10.002409638554218,
      "grad_norm": 7.282094478607178,
      "learning_rate": 9.997590361445784e-06,
      "loss": 0.0232,
      "step": 83020
    },
    {
      "epoch": 10.003614457831326,
      "grad_norm": 0.0772043988108635,
      "learning_rate": 9.996385542168675e-06,
      "loss": 0.0205,
      "step": 83030
    },
    {
      "epoch": 10.004819277108433,
      "grad_norm": 0.6665075421333313,
      "learning_rate": 9.995180722891567e-06,
      "loss": 0.039,
      "step": 83040
    },
    {
      "epoch": 10.006024096385541,
      "grad_norm": 0.5651642680168152,
      "learning_rate": 9.99397590361446e-06,
      "loss": 0.0399,
      "step": 83050
    },
    {
      "epoch": 10.007228915662651,
      "grad_norm": 1.312275767326355,
      "learning_rate": 9.99277108433735e-06,
      "loss": 0.0076,
      "step": 83060
    },
    {
      "epoch": 10.008433734939759,
      "grad_norm": 0.00893464032560587,
      "learning_rate": 9.991566265060241e-06,
      "loss": 0.0216,
      "step": 83070
    },
    {
      "epoch": 10.009638554216867,
      "grad_norm": 0.7073466181755066,
      "learning_rate": 9.990361445783134e-06,
      "loss": 0.0363,
      "step": 83080
    },
    {
      "epoch": 10.010843373493977,
      "grad_norm": 0.004536566324532032,
      "learning_rate": 9.989156626506024e-06,
      "loss": 0.0156,
      "step": 83090
    },
    {
      "epoch": 10.012048192771084,
      "grad_norm": 0.019799942150712013,
      "learning_rate": 9.987951807228917e-06,
      "loss": 0.0264,
      "step": 83100
    },
    {
      "epoch": 10.013253012048192,
      "grad_norm": 6.967564582824707,
      "learning_rate": 9.986746987951807e-06,
      "loss": 0.0247,
      "step": 83110
    },
    {
      "epoch": 10.0144578313253,
      "grad_norm": 1.6330844163894653,
      "learning_rate": 9.9855421686747e-06,
      "loss": 0.0141,
      "step": 83120
    },
    {
      "epoch": 10.01566265060241,
      "grad_norm": 0.010421505197882652,
      "learning_rate": 9.984337349397592e-06,
      "loss": 0.0021,
      "step": 83130
    },
    {
      "epoch": 10.016867469879518,
      "grad_norm": 0.019198007881641388,
      "learning_rate": 9.983132530120483e-06,
      "loss": 0.0546,
      "step": 83140
    },
    {
      "epoch": 10.018072289156626,
      "grad_norm": 1.854006052017212,
      "learning_rate": 9.981927710843374e-06,
      "loss": 0.0211,
      "step": 83150
    },
    {
      "epoch": 10.019277108433736,
      "grad_norm": 0.00414178567007184,
      "learning_rate": 9.980722891566266e-06,
      "loss": 0.0207,
      "step": 83160
    },
    {
      "epoch": 10.020481927710843,
      "grad_norm": 0.7756750583648682,
      "learning_rate": 9.979518072289157e-06,
      "loss": 0.0212,
      "step": 83170
    },
    {
      "epoch": 10.021686746987951,
      "grad_norm": 0.02507711574435234,
      "learning_rate": 9.97831325301205e-06,
      "loss": 0.0135,
      "step": 83180
    },
    {
      "epoch": 10.022891566265061,
      "grad_norm": 0.006819958332926035,
      "learning_rate": 9.977108433734942e-06,
      "loss": 0.0145,
      "step": 83190
    },
    {
      "epoch": 10.024096385542169,
      "grad_norm": 0.9546442031860352,
      "learning_rate": 9.975903614457833e-06,
      "loss": 0.0123,
      "step": 83200
    },
    {
      "epoch": 10.025301204819277,
      "grad_norm": 1.2607052326202393,
      "learning_rate": 9.974698795180723e-06,
      "loss": 0.0153,
      "step": 83210
    },
    {
      "epoch": 10.026506024096385,
      "grad_norm": 0.0008671505493111908,
      "learning_rate": 9.973493975903616e-06,
      "loss": 0.0049,
      "step": 83220
    },
    {
      "epoch": 10.027710843373494,
      "grad_norm": 0.0016644721617922187,
      "learning_rate": 9.972289156626506e-06,
      "loss": 0.0369,
      "step": 83230
    },
    {
      "epoch": 10.028915662650602,
      "grad_norm": 0.0009827730245888233,
      "learning_rate": 9.971084337349399e-06,
      "loss": 0.0045,
      "step": 83240
    },
    {
      "epoch": 10.03012048192771,
      "grad_norm": 0.004605067893862724,
      "learning_rate": 9.96987951807229e-06,
      "loss": 0.0132,
      "step": 83250
    },
    {
      "epoch": 10.03132530120482,
      "grad_norm": 0.0011663736077025533,
      "learning_rate": 9.96867469879518e-06,
      "loss": 0.0286,
      "step": 83260
    },
    {
      "epoch": 10.032530120481928,
      "grad_norm": 1.9176785945892334,
      "learning_rate": 9.967469879518073e-06,
      "loss": 0.0353,
      "step": 83270
    },
    {
      "epoch": 10.033734939759036,
      "grad_norm": 0.002795697655528784,
      "learning_rate": 9.966265060240965e-06,
      "loss": 0.0547,
      "step": 83280
    },
    {
      "epoch": 10.034939759036144,
      "grad_norm": 11.463053703308105,
      "learning_rate": 9.965060240963856e-06,
      "loss": 0.0603,
      "step": 83290
    },
    {
      "epoch": 10.036144578313253,
      "grad_norm": 0.008878450840711594,
      "learning_rate": 9.963855421686748e-06,
      "loss": 0.0106,
      "step": 83300
    },
    {
      "epoch": 10.037349397590361,
      "grad_norm": 1.4225900173187256,
      "learning_rate": 9.96265060240964e-06,
      "loss": 0.0121,
      "step": 83310
    },
    {
      "epoch": 10.03855421686747,
      "grad_norm": 0.0026277881115674973,
      "learning_rate": 9.96144578313253e-06,
      "loss": 0.0036,
      "step": 83320
    },
    {
      "epoch": 10.039759036144579,
      "grad_norm": 0.020820651203393936,
      "learning_rate": 9.960240963855422e-06,
      "loss": 0.0072,
      "step": 83330
    },
    {
      "epoch": 10.040963855421687,
      "grad_norm": 0.14196018874645233,
      "learning_rate": 9.959036144578315e-06,
      "loss": 0.019,
      "step": 83340
    },
    {
      "epoch": 10.042168674698795,
      "grad_norm": 0.21042288839817047,
      "learning_rate": 9.957831325301206e-06,
      "loss": 0.0152,
      "step": 83350
    },
    {
      "epoch": 10.043373493975903,
      "grad_norm": 2.87201189994812,
      "learning_rate": 9.956626506024098e-06,
      "loss": 0.0339,
      "step": 83360
    },
    {
      "epoch": 10.044578313253012,
      "grad_norm": 0.7005617618560791,
      "learning_rate": 9.955421686746989e-06,
      "loss": 0.0035,
      "step": 83370
    },
    {
      "epoch": 10.04578313253012,
      "grad_norm": 0.32117050886154175,
      "learning_rate": 9.95421686746988e-06,
      "loss": 0.0056,
      "step": 83380
    },
    {
      "epoch": 10.046987951807228,
      "grad_norm": 0.0004980664816685021,
      "learning_rate": 9.953012048192772e-06,
      "loss": 0.0123,
      "step": 83390
    },
    {
      "epoch": 10.048192771084338,
      "grad_norm": 0.002624038839712739,
      "learning_rate": 9.951807228915663e-06,
      "loss": 0.009,
      "step": 83400
    },
    {
      "epoch": 10.049397590361446,
      "grad_norm": 0.0013656140072271228,
      "learning_rate": 9.950602409638555e-06,
      "loss": 0.0125,
      "step": 83410
    },
    {
      "epoch": 10.050602409638554,
      "grad_norm": 0.00682870065793395,
      "learning_rate": 9.949397590361448e-06,
      "loss": 0.0331,
      "step": 83420
    },
    {
      "epoch": 10.051807228915663,
      "grad_norm": 0.0019297853577882051,
      "learning_rate": 9.948192771084338e-06,
      "loss": 0.0064,
      "step": 83430
    },
    {
      "epoch": 10.053012048192771,
      "grad_norm": 1.6112467050552368,
      "learning_rate": 9.94698795180723e-06,
      "loss": 0.0108,
      "step": 83440
    },
    {
      "epoch": 10.05421686746988,
      "grad_norm": 0.0025071788113564253,
      "learning_rate": 9.945783132530121e-06,
      "loss": 0.0019,
      "step": 83450
    },
    {
      "epoch": 10.055421686746987,
      "grad_norm": 1.9461417198181152,
      "learning_rate": 9.944578313253012e-06,
      "loss": 0.029,
      "step": 83460
    },
    {
      "epoch": 10.056626506024097,
      "grad_norm": 0.0005734608857892454,
      "learning_rate": 9.943373493975905e-06,
      "loss": 0.0022,
      "step": 83470
    },
    {
      "epoch": 10.057831325301205,
      "grad_norm": 5.634352684020996,
      "learning_rate": 9.942168674698795e-06,
      "loss": 0.0312,
      "step": 83480
    },
    {
      "epoch": 10.059036144578313,
      "grad_norm": 0.003397625405341387,
      "learning_rate": 9.940963855421688e-06,
      "loss": 0.0,
      "step": 83490
    },
    {
      "epoch": 10.060240963855422,
      "grad_norm": 0.0008716903976164758,
      "learning_rate": 9.93975903614458e-06,
      "loss": 0.0345,
      "step": 83500
    },
    {
      "epoch": 10.06144578313253,
      "grad_norm": 0.0017248347867280245,
      "learning_rate": 9.938554216867471e-06,
      "loss": 0.0239,
      "step": 83510
    },
    {
      "epoch": 10.062650602409638,
      "grad_norm": 0.762869656085968,
      "learning_rate": 9.937349397590362e-06,
      "loss": 0.0163,
      "step": 83520
    },
    {
      "epoch": 10.063855421686746,
      "grad_norm": 0.011359252035617828,
      "learning_rate": 9.936144578313254e-06,
      "loss": 0.0222,
      "step": 83530
    },
    {
      "epoch": 10.065060240963856,
      "grad_norm": 0.001059893285855651,
      "learning_rate": 9.934939759036145e-06,
      "loss": 0.0078,
      "step": 83540
    },
    {
      "epoch": 10.066265060240964,
      "grad_norm": 3.4832236766815186,
      "learning_rate": 9.933734939759037e-06,
      "loss": 0.0162,
      "step": 83550
    },
    {
      "epoch": 10.067469879518072,
      "grad_norm": 0.0002335327008040622,
      "learning_rate": 9.932530120481928e-06,
      "loss": 0.0153,
      "step": 83560
    },
    {
      "epoch": 10.068674698795181,
      "grad_norm": 0.0011625464539974928,
      "learning_rate": 9.93132530120482e-06,
      "loss": 0.0075,
      "step": 83570
    },
    {
      "epoch": 10.06987951807229,
      "grad_norm": 1.131486415863037,
      "learning_rate": 9.930120481927711e-06,
      "loss": 0.0107,
      "step": 83580
    },
    {
      "epoch": 10.071084337349397,
      "grad_norm": 1.0583056211471558,
      "learning_rate": 9.928915662650604e-06,
      "loss": 0.0391,
      "step": 83590
    },
    {
      "epoch": 10.072289156626505,
      "grad_norm": 0.004569018725305796,
      "learning_rate": 9.927710843373494e-06,
      "loss": 0.0054,
      "step": 83600
    },
    {
      "epoch": 10.073493975903615,
      "grad_norm": 0.6137930750846863,
      "learning_rate": 9.926506024096387e-06,
      "loss": 0.0057,
      "step": 83610
    },
    {
      "epoch": 10.074698795180723,
      "grad_norm": 0.5049257874488831,
      "learning_rate": 9.925301204819278e-06,
      "loss": 0.0125,
      "step": 83620
    },
    {
      "epoch": 10.07590361445783,
      "grad_norm": 0.010247945785522461,
      "learning_rate": 9.924096385542168e-06,
      "loss": 0.0246,
      "step": 83630
    },
    {
      "epoch": 10.07710843373494,
      "grad_norm": 0.00011734026338672265,
      "learning_rate": 9.92289156626506e-06,
      "loss": 0.0009,
      "step": 83640
    },
    {
      "epoch": 10.078313253012048,
      "grad_norm": 0.2778400182723999,
      "learning_rate": 9.921686746987953e-06,
      "loss": 0.0244,
      "step": 83650
    },
    {
      "epoch": 10.079518072289156,
      "grad_norm": 13.835756301879883,
      "learning_rate": 9.920481927710844e-06,
      "loss": 0.0096,
      "step": 83660
    },
    {
      "epoch": 10.080722891566266,
      "grad_norm": 0.0008144990424625576,
      "learning_rate": 9.919277108433736e-06,
      "loss": 0.0182,
      "step": 83670
    },
    {
      "epoch": 10.081927710843374,
      "grad_norm": 1.9036716222763062,
      "learning_rate": 9.918072289156627e-06,
      "loss": 0.0139,
      "step": 83680
    },
    {
      "epoch": 10.083132530120482,
      "grad_norm": 1.151987075805664,
      "learning_rate": 9.916867469879518e-06,
      "loss": 0.0248,
      "step": 83690
    },
    {
      "epoch": 10.08433734939759,
      "grad_norm": 0.015497480519115925,
      "learning_rate": 9.91566265060241e-06,
      "loss": 0.0159,
      "step": 83700
    },
    {
      "epoch": 10.0855421686747,
      "grad_norm": 9.574549674987793,
      "learning_rate": 9.914457831325301e-06,
      "loss": 0.0738,
      "step": 83710
    },
    {
      "epoch": 10.086746987951807,
      "grad_norm": 2.152632474899292,
      "learning_rate": 9.913253012048193e-06,
      "loss": 0.0187,
      "step": 83720
    },
    {
      "epoch": 10.087951807228915,
      "grad_norm": 0.014774901792407036,
      "learning_rate": 9.912048192771086e-06,
      "loss": 0.0205,
      "step": 83730
    },
    {
      "epoch": 10.089156626506025,
      "grad_norm": 0.38436949253082275,
      "learning_rate": 9.910843373493977e-06,
      "loss": 0.0039,
      "step": 83740
    },
    {
      "epoch": 10.090361445783133,
      "grad_norm": 3.614957571029663,
      "learning_rate": 9.909638554216869e-06,
      "loss": 0.0206,
      "step": 83750
    },
    {
      "epoch": 10.09156626506024,
      "grad_norm": 1.2788763046264648,
      "learning_rate": 9.90843373493976e-06,
      "loss": 0.0141,
      "step": 83760
    },
    {
      "epoch": 10.092771084337349,
      "grad_norm": 0.0023017083294689655,
      "learning_rate": 9.90722891566265e-06,
      "loss": 0.0432,
      "step": 83770
    },
    {
      "epoch": 10.093975903614458,
      "grad_norm": 0.00039799633668735623,
      "learning_rate": 9.906024096385543e-06,
      "loss": 0.0031,
      "step": 83780
    },
    {
      "epoch": 10.095180722891566,
      "grad_norm": 0.008792887441813946,
      "learning_rate": 9.904819277108435e-06,
      "loss": 0.0038,
      "step": 83790
    },
    {
      "epoch": 10.096385542168674,
      "grad_norm": 25.23935317993164,
      "learning_rate": 9.903614457831326e-06,
      "loss": 0.0167,
      "step": 83800
    },
    {
      "epoch": 10.097590361445784,
      "grad_norm": 0.017173541709780693,
      "learning_rate": 9.902409638554219e-06,
      "loss": 0.0123,
      "step": 83810
    },
    {
      "epoch": 10.098795180722892,
      "grad_norm": 0.024520404636859894,
      "learning_rate": 9.90120481927711e-06,
      "loss": 0.0532,
      "step": 83820
    },
    {
      "epoch": 10.1,
      "grad_norm": 0.004668074194341898,
      "learning_rate": 9.9e-06,
      "loss": 0.0208,
      "step": 83830
    },
    {
      "epoch": 10.101204819277108,
      "grad_norm": 3.0907135009765625,
      "learning_rate": 9.898795180722893e-06,
      "loss": 0.0969,
      "step": 83840
    },
    {
      "epoch": 10.102409638554217,
      "grad_norm": 3.983680486679077,
      "learning_rate": 9.897590361445783e-06,
      "loss": 0.0138,
      "step": 83850
    },
    {
      "epoch": 10.103614457831325,
      "grad_norm": 0.0044821444898843765,
      "learning_rate": 9.896385542168676e-06,
      "loss": 0.0186,
      "step": 83860
    },
    {
      "epoch": 10.104819277108433,
      "grad_norm": 0.15902724862098694,
      "learning_rate": 9.895180722891568e-06,
      "loss": 0.0211,
      "step": 83870
    },
    {
      "epoch": 10.106024096385543,
      "grad_norm": 0.013386842794716358,
      "learning_rate": 9.893975903614459e-06,
      "loss": 0.0222,
      "step": 83880
    },
    {
      "epoch": 10.10722891566265,
      "grad_norm": 0.3886122405529022,
      "learning_rate": 9.89277108433735e-06,
      "loss": 0.0167,
      "step": 83890
    },
    {
      "epoch": 10.108433734939759,
      "grad_norm": 0.4190270006656647,
      "learning_rate": 9.891566265060242e-06,
      "loss": 0.0206,
      "step": 83900
    },
    {
      "epoch": 10.109638554216868,
      "grad_norm": 0.0008820654475130141,
      "learning_rate": 9.890361445783133e-06,
      "loss": 0.0207,
      "step": 83910
    },
    {
      "epoch": 10.110843373493976,
      "grad_norm": 0.00037741183768957853,
      "learning_rate": 9.889156626506025e-06,
      "loss": 0.0011,
      "step": 83920
    },
    {
      "epoch": 10.112048192771084,
      "grad_norm": 0.7335991859436035,
      "learning_rate": 9.887951807228916e-06,
      "loss": 0.0295,
      "step": 83930
    },
    {
      "epoch": 10.113253012048192,
      "grad_norm": 0.000594957557041198,
      "learning_rate": 9.886746987951808e-06,
      "loss": 0.0056,
      "step": 83940
    },
    {
      "epoch": 10.114457831325302,
      "grad_norm": 0.0009677799534983933,
      "learning_rate": 9.885542168674699e-06,
      "loss": 0.0062,
      "step": 83950
    },
    {
      "epoch": 10.11566265060241,
      "grad_norm": 0.0008288110257126391,
      "learning_rate": 9.884337349397592e-06,
      "loss": 0.0035,
      "step": 83960
    },
    {
      "epoch": 10.116867469879518,
      "grad_norm": 0.0021916476543992758,
      "learning_rate": 9.883132530120482e-06,
      "loss": 0.0346,
      "step": 83970
    },
    {
      "epoch": 10.118072289156627,
      "grad_norm": 0.15025493502616882,
      "learning_rate": 9.881927710843375e-06,
      "loss": 0.0068,
      "step": 83980
    },
    {
      "epoch": 10.119277108433735,
      "grad_norm": 0.0006518912850879133,
      "learning_rate": 9.880722891566265e-06,
      "loss": 0.0319,
      "step": 83990
    },
    {
      "epoch": 10.120481927710843,
      "grad_norm": 1.04045569896698,
      "learning_rate": 9.879518072289156e-06,
      "loss": 0.0252,
      "step": 84000
    },
    {
      "epoch": 10.121686746987951,
      "grad_norm": 0.9943864345550537,
      "learning_rate": 9.878313253012049e-06,
      "loss": 0.0541,
      "step": 84010
    },
    {
      "epoch": 10.12289156626506,
      "grad_norm": 0.7777275443077087,
      "learning_rate": 9.877108433734941e-06,
      "loss": 0.0137,
      "step": 84020
    },
    {
      "epoch": 10.124096385542169,
      "grad_norm": 0.3278108537197113,
      "learning_rate": 9.875903614457832e-06,
      "loss": 0.0087,
      "step": 84030
    },
    {
      "epoch": 10.125301204819277,
      "grad_norm": 0.0006587315001524985,
      "learning_rate": 9.874698795180724e-06,
      "loss": 0.0435,
      "step": 84040
    },
    {
      "epoch": 10.126506024096386,
      "grad_norm": 0.0027171275578439236,
      "learning_rate": 9.873493975903615e-06,
      "loss": 0.0194,
      "step": 84050
    },
    {
      "epoch": 10.127710843373494,
      "grad_norm": 0.04182052984833717,
      "learning_rate": 9.872289156626507e-06,
      "loss": 0.0027,
      "step": 84060
    },
    {
      "epoch": 10.128915662650602,
      "grad_norm": 0.11024285852909088,
      "learning_rate": 9.871084337349398e-06,
      "loss": 0.0176,
      "step": 84070
    },
    {
      "epoch": 10.13012048192771,
      "grad_norm": 0.009831972420215607,
      "learning_rate": 9.869879518072289e-06,
      "loss": 0.039,
      "step": 84080
    },
    {
      "epoch": 10.13132530120482,
      "grad_norm": 0.06834378838539124,
      "learning_rate": 9.868674698795181e-06,
      "loss": 0.0594,
      "step": 84090
    },
    {
      "epoch": 10.132530120481928,
      "grad_norm": 1.6292152404785156,
      "learning_rate": 9.867469879518074e-06,
      "loss": 0.0277,
      "step": 84100
    },
    {
      "epoch": 10.133734939759035,
      "grad_norm": 0.02157522737979889,
      "learning_rate": 9.866265060240965e-06,
      "loss": 0.0113,
      "step": 84110
    },
    {
      "epoch": 10.134939759036145,
      "grad_norm": 1.0789333581924438,
      "learning_rate": 9.865060240963857e-06,
      "loss": 0.0124,
      "step": 84120
    },
    {
      "epoch": 10.136144578313253,
      "grad_norm": 0.4111369848251343,
      "learning_rate": 9.863855421686748e-06,
      "loss": 0.0024,
      "step": 84130
    },
    {
      "epoch": 10.137349397590361,
      "grad_norm": 0.01206351350992918,
      "learning_rate": 9.862650602409638e-06,
      "loss": 0.0048,
      "step": 84140
    },
    {
      "epoch": 10.13855421686747,
      "grad_norm": 0.01406144630163908,
      "learning_rate": 9.861445783132531e-06,
      "loss": 0.0069,
      "step": 84150
    },
    {
      "epoch": 10.139759036144579,
      "grad_norm": 0.0038933679461479187,
      "learning_rate": 9.860240963855422e-06,
      "loss": 0.001,
      "step": 84160
    },
    {
      "epoch": 10.140963855421687,
      "grad_norm": 6.963947296142578,
      "learning_rate": 9.859036144578314e-06,
      "loss": 0.031,
      "step": 84170
    },
    {
      "epoch": 10.142168674698794,
      "grad_norm": 0.012172669172286987,
      "learning_rate": 9.857831325301207e-06,
      "loss": 0.0107,
      "step": 84180
    },
    {
      "epoch": 10.143373493975904,
      "grad_norm": 0.2875337600708008,
      "learning_rate": 9.856626506024097e-06,
      "loss": 0.0436,
      "step": 84190
    },
    {
      "epoch": 10.144578313253012,
      "grad_norm": 0.21358370780944824,
      "learning_rate": 9.855421686746988e-06,
      "loss": 0.0042,
      "step": 84200
    },
    {
      "epoch": 10.14578313253012,
      "grad_norm": 0.3004221022129059,
      "learning_rate": 9.85421686746988e-06,
      "loss": 0.0013,
      "step": 84210
    },
    {
      "epoch": 10.14698795180723,
      "grad_norm": 1.3548387289047241,
      "learning_rate": 9.853012048192771e-06,
      "loss": 0.0171,
      "step": 84220
    },
    {
      "epoch": 10.148192771084338,
      "grad_norm": 0.004549988079816103,
      "learning_rate": 9.851807228915664e-06,
      "loss": 0.0323,
      "step": 84230
    },
    {
      "epoch": 10.149397590361446,
      "grad_norm": 0.003494822420179844,
      "learning_rate": 9.850602409638556e-06,
      "loss": 0.0111,
      "step": 84240
    },
    {
      "epoch": 10.150602409638553,
      "grad_norm": 0.0010058839106932282,
      "learning_rate": 9.849397590361447e-06,
      "loss": 0.0005,
      "step": 84250
    },
    {
      "epoch": 10.151807228915663,
      "grad_norm": 0.03592963516712189,
      "learning_rate": 9.848192771084338e-06,
      "loss": 0.0083,
      "step": 84260
    },
    {
      "epoch": 10.153012048192771,
      "grad_norm": 0.33537694811820984,
      "learning_rate": 9.84698795180723e-06,
      "loss": 0.007,
      "step": 84270
    },
    {
      "epoch": 10.154216867469879,
      "grad_norm": 1.9050769805908203,
      "learning_rate": 9.84578313253012e-06,
      "loss": 0.0322,
      "step": 84280
    },
    {
      "epoch": 10.155421686746989,
      "grad_norm": 0.003101261332631111,
      "learning_rate": 9.844578313253013e-06,
      "loss": 0.0047,
      "step": 84290
    },
    {
      "epoch": 10.156626506024097,
      "grad_norm": 0.002265535295009613,
      "learning_rate": 9.843373493975904e-06,
      "loss": 0.0352,
      "step": 84300
    },
    {
      "epoch": 10.157831325301204,
      "grad_norm": 0.005683175288140774,
      "learning_rate": 9.842168674698795e-06,
      "loss": 0.0146,
      "step": 84310
    },
    {
      "epoch": 10.159036144578312,
      "grad_norm": 0.001909460755996406,
      "learning_rate": 9.840963855421689e-06,
      "loss": 0.0076,
      "step": 84320
    },
    {
      "epoch": 10.160240963855422,
      "grad_norm": 0.001008750987239182,
      "learning_rate": 9.83975903614458e-06,
      "loss": 0.0342,
      "step": 84330
    },
    {
      "epoch": 10.16144578313253,
      "grad_norm": 0.0020500358659774065,
      "learning_rate": 9.83855421686747e-06,
      "loss": 0.0359,
      "step": 84340
    },
    {
      "epoch": 10.162650602409638,
      "grad_norm": 0.0016128885326907039,
      "learning_rate": 9.837349397590363e-06,
      "loss": 0.0189,
      "step": 84350
    },
    {
      "epoch": 10.163855421686748,
      "grad_norm": 0.14146864414215088,
      "learning_rate": 9.836144578313253e-06,
      "loss": 0.037,
      "step": 84360
    },
    {
      "epoch": 10.165060240963856,
      "grad_norm": 4.639579772949219,
      "learning_rate": 9.834939759036146e-06,
      "loss": 0.0205,
      "step": 84370
    },
    {
      "epoch": 10.166265060240963,
      "grad_norm": 1.2417134046554565,
      "learning_rate": 9.833734939759037e-06,
      "loss": 0.0479,
      "step": 84380
    },
    {
      "epoch": 10.167469879518073,
      "grad_norm": 0.003039328381419182,
      "learning_rate": 9.832530120481929e-06,
      "loss": 0.0002,
      "step": 84390
    },
    {
      "epoch": 10.168674698795181,
      "grad_norm": 0.002286602044478059,
      "learning_rate": 9.83132530120482e-06,
      "loss": 0.0142,
      "step": 84400
    },
    {
      "epoch": 10.169879518072289,
      "grad_norm": 0.21594378352165222,
      "learning_rate": 9.830120481927712e-06,
      "loss": 0.0386,
      "step": 84410
    },
    {
      "epoch": 10.171084337349397,
      "grad_norm": 0.4105108678340912,
      "learning_rate": 9.828915662650603e-06,
      "loss": 0.0137,
      "step": 84420
    },
    {
      "epoch": 10.172289156626507,
      "grad_norm": 0.004815726540982723,
      "learning_rate": 9.827710843373495e-06,
      "loss": 0.0164,
      "step": 84430
    },
    {
      "epoch": 10.173493975903614,
      "grad_norm": 0.03995561972260475,
      "learning_rate": 9.826506024096386e-06,
      "loss": 0.0118,
      "step": 84440
    },
    {
      "epoch": 10.174698795180722,
      "grad_norm": 0.003568573622033,
      "learning_rate": 9.825301204819277e-06,
      "loss": 0.0385,
      "step": 84450
    },
    {
      "epoch": 10.175903614457832,
      "grad_norm": 0.4542650580406189,
      "learning_rate": 9.82409638554217e-06,
      "loss": 0.0471,
      "step": 84460
    },
    {
      "epoch": 10.17710843373494,
      "grad_norm": 0.9303590655326843,
      "learning_rate": 9.822891566265062e-06,
      "loss": 0.0511,
      "step": 84470
    },
    {
      "epoch": 10.178313253012048,
      "grad_norm": 0.7161978483200073,
      "learning_rate": 9.821686746987952e-06,
      "loss": 0.0078,
      "step": 84480
    },
    {
      "epoch": 10.179518072289156,
      "grad_norm": 0.3540208041667938,
      "learning_rate": 9.820481927710845e-06,
      "loss": 0.0133,
      "step": 84490
    },
    {
      "epoch": 10.180722891566266,
      "grad_norm": 0.12276075780391693,
      "learning_rate": 9.819277108433736e-06,
      "loss": 0.0189,
      "step": 84500
    },
    {
      "epoch": 10.181927710843373,
      "grad_norm": 0.002781536430120468,
      "learning_rate": 9.818072289156626e-06,
      "loss": 0.0211,
      "step": 84510
    },
    {
      "epoch": 10.183132530120481,
      "grad_norm": 0.003356932196766138,
      "learning_rate": 9.816867469879519e-06,
      "loss": 0.0384,
      "step": 84520
    },
    {
      "epoch": 10.184337349397591,
      "grad_norm": 1.2513370513916016,
      "learning_rate": 9.81566265060241e-06,
      "loss": 0.0112,
      "step": 84530
    },
    {
      "epoch": 10.185542168674699,
      "grad_norm": 0.004202742129564285,
      "learning_rate": 9.814457831325302e-06,
      "loss": 0.0418,
      "step": 84540
    },
    {
      "epoch": 10.186746987951807,
      "grad_norm": 2.5197560787200928,
      "learning_rate": 9.813253012048194e-06,
      "loss": 0.0226,
      "step": 84550
    },
    {
      "epoch": 10.187951807228915,
      "grad_norm": 0.3768749237060547,
      "learning_rate": 9.812048192771085e-06,
      "loss": 0.0129,
      "step": 84560
    },
    {
      "epoch": 10.189156626506024,
      "grad_norm": 3.3127801418304443,
      "learning_rate": 9.810843373493978e-06,
      "loss": 0.0148,
      "step": 84570
    },
    {
      "epoch": 10.190361445783132,
      "grad_norm": 0.013315473683178425,
      "learning_rate": 9.809638554216868e-06,
      "loss": 0.0022,
      "step": 84580
    },
    {
      "epoch": 10.19156626506024,
      "grad_norm": 0.41209009289741516,
      "learning_rate": 9.808433734939759e-06,
      "loss": 0.0266,
      "step": 84590
    },
    {
      "epoch": 10.19277108433735,
      "grad_norm": 1.8680366277694702,
      "learning_rate": 9.807228915662652e-06,
      "loss": 0.0292,
      "step": 84600
    },
    {
      "epoch": 10.193975903614458,
      "grad_norm": 0.00504492549225688,
      "learning_rate": 9.806024096385542e-06,
      "loss": 0.0009,
      "step": 84610
    },
    {
      "epoch": 10.195180722891566,
      "grad_norm": 0.9526188969612122,
      "learning_rate": 9.804819277108435e-06,
      "loss": 0.0054,
      "step": 84620
    },
    {
      "epoch": 10.196385542168676,
      "grad_norm": 0.2927094101905823,
      "learning_rate": 9.803614457831327e-06,
      "loss": 0.0383,
      "step": 84630
    },
    {
      "epoch": 10.197590361445783,
      "grad_norm": 1.9559166431427002,
      "learning_rate": 9.802409638554218e-06,
      "loss": 0.0272,
      "step": 84640
    },
    {
      "epoch": 10.198795180722891,
      "grad_norm": 0.003800053847953677,
      "learning_rate": 9.801204819277109e-06,
      "loss": 0.0028,
      "step": 84650
    },
    {
      "epoch": 10.2,
      "grad_norm": 0.5688155889511108,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.0173,
      "step": 84660
    },
    {
      "epoch": 10.201204819277109,
      "grad_norm": 0.000805073359515518,
      "learning_rate": 9.798795180722892e-06,
      "loss": 0.0189,
      "step": 84670
    },
    {
      "epoch": 10.202409638554217,
      "grad_norm": 5.48486852645874,
      "learning_rate": 9.797590361445784e-06,
      "loss": 0.0386,
      "step": 84680
    },
    {
      "epoch": 10.203614457831325,
      "grad_norm": 0.003705994924530387,
      "learning_rate": 9.796385542168677e-06,
      "loss": 0.006,
      "step": 84690
    },
    {
      "epoch": 10.204819277108435,
      "grad_norm": 2.1620917320251465,
      "learning_rate": 9.795180722891567e-06,
      "loss": 0.0437,
      "step": 84700
    },
    {
      "epoch": 10.206024096385542,
      "grad_norm": 0.5757750868797302,
      "learning_rate": 9.793975903614458e-06,
      "loss": 0.0123,
      "step": 84710
    },
    {
      "epoch": 10.20722891566265,
      "grad_norm": 0.05148258060216904,
      "learning_rate": 9.79277108433735e-06,
      "loss": 0.0318,
      "step": 84720
    },
    {
      "epoch": 10.208433734939758,
      "grad_norm": 1.180214524269104,
      "learning_rate": 9.791566265060241e-06,
      "loss": 0.0054,
      "step": 84730
    },
    {
      "epoch": 10.209638554216868,
      "grad_norm": 0.002275843871757388,
      "learning_rate": 9.790361445783134e-06,
      "loss": 0.0095,
      "step": 84740
    },
    {
      "epoch": 10.210843373493976,
      "grad_norm": 0.0016729874769225717,
      "learning_rate": 9.789156626506024e-06,
      "loss": 0.007,
      "step": 84750
    },
    {
      "epoch": 10.212048192771084,
      "grad_norm": 0.014110398478806019,
      "learning_rate": 9.787951807228915e-06,
      "loss": 0.0033,
      "step": 84760
    },
    {
      "epoch": 10.213253012048193,
      "grad_norm": 0.005481180734932423,
      "learning_rate": 9.786746987951808e-06,
      "loss": 0.0021,
      "step": 84770
    },
    {
      "epoch": 10.214457831325301,
      "grad_norm": 2.038189172744751,
      "learning_rate": 9.7855421686747e-06,
      "loss": 0.0621,
      "step": 84780
    },
    {
      "epoch": 10.21566265060241,
      "grad_norm": 10.351130485534668,
      "learning_rate": 9.78433734939759e-06,
      "loss": 0.0261,
      "step": 84790
    },
    {
      "epoch": 10.216867469879517,
      "grad_norm": 1.7730555534362793,
      "learning_rate": 9.783132530120483e-06,
      "loss": 0.0167,
      "step": 84800
    },
    {
      "epoch": 10.218072289156627,
      "grad_norm": 0.006417408585548401,
      "learning_rate": 9.781927710843374e-06,
      "loss": 0.0139,
      "step": 84810
    },
    {
      "epoch": 10.219277108433735,
      "grad_norm": 0.0024339400697499514,
      "learning_rate": 9.780722891566265e-06,
      "loss": 0.0422,
      "step": 84820
    },
    {
      "epoch": 10.220481927710843,
      "grad_norm": 1.1242812871932983,
      "learning_rate": 9.779518072289157e-06,
      "loss": 0.0274,
      "step": 84830
    },
    {
      "epoch": 10.221686746987952,
      "grad_norm": 0.1014184057712555,
      "learning_rate": 9.77831325301205e-06,
      "loss": 0.0134,
      "step": 84840
    },
    {
      "epoch": 10.22289156626506,
      "grad_norm": 0.015162807889282703,
      "learning_rate": 9.77710843373494e-06,
      "loss": 0.025,
      "step": 84850
    },
    {
      "epoch": 10.224096385542168,
      "grad_norm": 0.006750783883035183,
      "learning_rate": 9.775903614457833e-06,
      "loss": 0.0166,
      "step": 84860
    },
    {
      "epoch": 10.225301204819278,
      "grad_norm": 0.03809387981891632,
      "learning_rate": 9.774698795180724e-06,
      "loss": 0.0212,
      "step": 84870
    },
    {
      "epoch": 10.226506024096386,
      "grad_norm": 0.6109771132469177,
      "learning_rate": 9.773493975903616e-06,
      "loss": 0.0092,
      "step": 84880
    },
    {
      "epoch": 10.227710843373494,
      "grad_norm": 1.9016761779785156,
      "learning_rate": 9.772289156626507e-06,
      "loss": 0.0561,
      "step": 84890
    },
    {
      "epoch": 10.228915662650602,
      "grad_norm": 0.010653630830347538,
      "learning_rate": 9.771084337349397e-06,
      "loss": 0.0636,
      "step": 84900
    },
    {
      "epoch": 10.230120481927711,
      "grad_norm": 1.1775848865509033,
      "learning_rate": 9.76987951807229e-06,
      "loss": 0.042,
      "step": 84910
    },
    {
      "epoch": 10.23132530120482,
      "grad_norm": 1.5337258577346802,
      "learning_rate": 9.768674698795182e-06,
      "loss": 0.0116,
      "step": 84920
    },
    {
      "epoch": 10.232530120481927,
      "grad_norm": 2.774423360824585,
      "learning_rate": 9.767469879518073e-06,
      "loss": 0.0298,
      "step": 84930
    },
    {
      "epoch": 10.233734939759037,
      "grad_norm": 0.5575920343399048,
      "learning_rate": 9.766265060240966e-06,
      "loss": 0.0103,
      "step": 84940
    },
    {
      "epoch": 10.234939759036145,
      "grad_norm": 0.0049179052002727985,
      "learning_rate": 9.765060240963856e-06,
      "loss": 0.039,
      "step": 84950
    },
    {
      "epoch": 10.236144578313253,
      "grad_norm": 0.5237593650817871,
      "learning_rate": 9.763855421686747e-06,
      "loss": 0.0194,
      "step": 84960
    },
    {
      "epoch": 10.23734939759036,
      "grad_norm": 1.1835001707077026,
      "learning_rate": 9.76265060240964e-06,
      "loss": 0.0531,
      "step": 84970
    },
    {
      "epoch": 10.23855421686747,
      "grad_norm": 0.9609976410865784,
      "learning_rate": 9.76144578313253e-06,
      "loss": 0.0137,
      "step": 84980
    },
    {
      "epoch": 10.239759036144578,
      "grad_norm": 1.0128405094146729,
      "learning_rate": 9.760240963855423e-06,
      "loss": 0.0129,
      "step": 84990
    },
    {
      "epoch": 10.240963855421686,
      "grad_norm": 4.333500862121582,
      "learning_rate": 9.759036144578315e-06,
      "loss": 0.0267,
      "step": 85000
    },
    {
      "epoch": 10.242168674698796,
      "grad_norm": 1.0002596378326416,
      "learning_rate": 9.757831325301206e-06,
      "loss": 0.0121,
      "step": 85010
    },
    {
      "epoch": 10.243373493975904,
      "grad_norm": 1.4158458709716797,
      "learning_rate": 9.756626506024097e-06,
      "loss": 0.0139,
      "step": 85020
    },
    {
      "epoch": 10.244578313253012,
      "grad_norm": 0.0025593640748411417,
      "learning_rate": 9.755421686746989e-06,
      "loss": 0.0261,
      "step": 85030
    },
    {
      "epoch": 10.24578313253012,
      "grad_norm": 0.015955422073602676,
      "learning_rate": 9.75421686746988e-06,
      "loss": 0.0614,
      "step": 85040
    },
    {
      "epoch": 10.24698795180723,
      "grad_norm": 0.0074832201935350895,
      "learning_rate": 9.753012048192772e-06,
      "loss": 0.0187,
      "step": 85050
    },
    {
      "epoch": 10.248192771084337,
      "grad_norm": 0.3994573652744293,
      "learning_rate": 9.751807228915663e-06,
      "loss": 0.0064,
      "step": 85060
    },
    {
      "epoch": 10.249397590361445,
      "grad_norm": 0.0076841507107019424,
      "learning_rate": 9.750602409638555e-06,
      "loss": 0.0135,
      "step": 85070
    },
    {
      "epoch": 10.250602409638555,
      "grad_norm": 0.1523286998271942,
      "learning_rate": 9.749397590361446e-06,
      "loss": 0.0038,
      "step": 85080
    },
    {
      "epoch": 10.251807228915663,
      "grad_norm": 0.005138581618666649,
      "learning_rate": 9.748192771084338e-06,
      "loss": 0.0079,
      "step": 85090
    },
    {
      "epoch": 10.25301204819277,
      "grad_norm": 0.0075690858066082,
      "learning_rate": 9.74698795180723e-06,
      "loss": 0.0076,
      "step": 85100
    },
    {
      "epoch": 10.25421686746988,
      "grad_norm": 0.5904204249382019,
      "learning_rate": 9.745783132530122e-06,
      "loss": 0.0558,
      "step": 85110
    },
    {
      "epoch": 10.255421686746988,
      "grad_norm": 0.011406945064663887,
      "learning_rate": 9.744578313253012e-06,
      "loss": 0.0253,
      "step": 85120
    },
    {
      "epoch": 10.256626506024096,
      "grad_norm": 0.033842138946056366,
      "learning_rate": 9.743373493975903e-06,
      "loss": 0.0265,
      "step": 85130
    },
    {
      "epoch": 10.257831325301204,
      "grad_norm": 0.24840882420539856,
      "learning_rate": 9.742168674698797e-06,
      "loss": 0.035,
      "step": 85140
    },
    {
      "epoch": 10.259036144578314,
      "grad_norm": 0.13596154749393463,
      "learning_rate": 9.740963855421688e-06,
      "loss": 0.0073,
      "step": 85150
    },
    {
      "epoch": 10.260240963855422,
      "grad_norm": 0.03366571292281151,
      "learning_rate": 9.739759036144579e-06,
      "loss": 0.0208,
      "step": 85160
    },
    {
      "epoch": 10.26144578313253,
      "grad_norm": 2.4760313034057617,
      "learning_rate": 9.738554216867471e-06,
      "loss": 0.0201,
      "step": 85170
    },
    {
      "epoch": 10.26265060240964,
      "grad_norm": 0.5181925296783447,
      "learning_rate": 9.737349397590362e-06,
      "loss": 0.0171,
      "step": 85180
    },
    {
      "epoch": 10.263855421686747,
      "grad_norm": 0.010166074149310589,
      "learning_rate": 9.736144578313254e-06,
      "loss": 0.0002,
      "step": 85190
    },
    {
      "epoch": 10.265060240963855,
      "grad_norm": 0.0023067709989845753,
      "learning_rate": 9.734939759036145e-06,
      "loss": 0.009,
      "step": 85200
    },
    {
      "epoch": 10.266265060240963,
      "grad_norm": 1.0785218477249146,
      "learning_rate": 9.733734939759038e-06,
      "loss": 0.0047,
      "step": 85210
    },
    {
      "epoch": 10.267469879518073,
      "grad_norm": 0.00748229306191206,
      "learning_rate": 9.732530120481928e-06,
      "loss": 0.0432,
      "step": 85220
    },
    {
      "epoch": 10.26867469879518,
      "grad_norm": 0.0013930798741057515,
      "learning_rate": 9.73132530120482e-06,
      "loss": 0.017,
      "step": 85230
    },
    {
      "epoch": 10.269879518072289,
      "grad_norm": 0.008624098263680935,
      "learning_rate": 9.730120481927711e-06,
      "loss": 0.031,
      "step": 85240
    },
    {
      "epoch": 10.271084337349398,
      "grad_norm": 0.009402376599609852,
      "learning_rate": 9.728915662650604e-06,
      "loss": 0.0424,
      "step": 85250
    },
    {
      "epoch": 10.272289156626506,
      "grad_norm": 0.01744270697236061,
      "learning_rate": 9.727710843373495e-06,
      "loss": 0.0098,
      "step": 85260
    },
    {
      "epoch": 10.273493975903614,
      "grad_norm": 0.020858043804764748,
      "learning_rate": 9.726506024096385e-06,
      "loss": 0.0105,
      "step": 85270
    },
    {
      "epoch": 10.274698795180722,
      "grad_norm": 2.001283884048462,
      "learning_rate": 9.725301204819278e-06,
      "loss": 0.0227,
      "step": 85280
    },
    {
      "epoch": 10.275903614457832,
      "grad_norm": 0.2707532048225403,
      "learning_rate": 9.72409638554217e-06,
      "loss": 0.0023,
      "step": 85290
    },
    {
      "epoch": 10.27710843373494,
      "grad_norm": 0.0046975030563771725,
      "learning_rate": 9.722891566265061e-06,
      "loss": 0.0055,
      "step": 85300
    },
    {
      "epoch": 10.278313253012048,
      "grad_norm": 0.08832649141550064,
      "learning_rate": 9.721686746987953e-06,
      "loss": 0.0186,
      "step": 85310
    },
    {
      "epoch": 10.279518072289157,
      "grad_norm": 0.1125609278678894,
      "learning_rate": 9.720481927710844e-06,
      "loss": 0.0102,
      "step": 85320
    },
    {
      "epoch": 10.280722891566265,
      "grad_norm": 0.002112288260832429,
      "learning_rate": 9.719277108433735e-06,
      "loss": 0.0222,
      "step": 85330
    },
    {
      "epoch": 10.281927710843373,
      "grad_norm": 0.04125549644231796,
      "learning_rate": 9.718072289156627e-06,
      "loss": 0.0263,
      "step": 85340
    },
    {
      "epoch": 10.283132530120483,
      "grad_norm": 0.004312735516577959,
      "learning_rate": 9.716867469879518e-06,
      "loss": 0.0167,
      "step": 85350
    },
    {
      "epoch": 10.28433734939759,
      "grad_norm": 0.0011251091491430998,
      "learning_rate": 9.71566265060241e-06,
      "loss": 0.0428,
      "step": 85360
    },
    {
      "epoch": 10.285542168674699,
      "grad_norm": 0.02700318954885006,
      "learning_rate": 9.714457831325303e-06,
      "loss": 0.046,
      "step": 85370
    },
    {
      "epoch": 10.286746987951807,
      "grad_norm": 0.005301994737237692,
      "learning_rate": 9.713253012048194e-06,
      "loss": 0.0372,
      "step": 85380
    },
    {
      "epoch": 10.287951807228916,
      "grad_norm": 0.01746024377644062,
      "learning_rate": 9.712048192771084e-06,
      "loss": 0.0251,
      "step": 85390
    },
    {
      "epoch": 10.289156626506024,
      "grad_norm": 1.0749017000198364,
      "learning_rate": 9.710843373493977e-06,
      "loss": 0.006,
      "step": 85400
    },
    {
      "epoch": 10.290361445783132,
      "grad_norm": 0.5460429787635803,
      "learning_rate": 9.709638554216868e-06,
      "loss": 0.0358,
      "step": 85410
    },
    {
      "epoch": 10.291566265060242,
      "grad_norm": 0.8800433278083801,
      "learning_rate": 9.70843373493976e-06,
      "loss": 0.0276,
      "step": 85420
    },
    {
      "epoch": 10.29277108433735,
      "grad_norm": 0.49917706847190857,
      "learning_rate": 9.70722891566265e-06,
      "loss": 0.0029,
      "step": 85430
    },
    {
      "epoch": 10.293975903614458,
      "grad_norm": 1.7386908531188965,
      "learning_rate": 9.706024096385543e-06,
      "loss": 0.0327,
      "step": 85440
    },
    {
      "epoch": 10.295180722891565,
      "grad_norm": 0.003318231785669923,
      "learning_rate": 9.704819277108436e-06,
      "loss": 0.0264,
      "step": 85450
    },
    {
      "epoch": 10.296385542168675,
      "grad_norm": 0.018795816227793694,
      "learning_rate": 9.703614457831326e-06,
      "loss": 0.012,
      "step": 85460
    },
    {
      "epoch": 10.297590361445783,
      "grad_norm": 0.04733547940850258,
      "learning_rate": 9.702409638554217e-06,
      "loss": 0.0196,
      "step": 85470
    },
    {
      "epoch": 10.298795180722891,
      "grad_norm": 0.031201060861349106,
      "learning_rate": 9.70120481927711e-06,
      "loss": 0.0373,
      "step": 85480
    },
    {
      "epoch": 10.3,
      "grad_norm": 0.890819251537323,
      "learning_rate": 9.7e-06,
      "loss": 0.006,
      "step": 85490
    },
    {
      "epoch": 10.301204819277109,
      "grad_norm": 0.009329679422080517,
      "learning_rate": 9.698795180722893e-06,
      "loss": 0.0188,
      "step": 85500
    },
    {
      "epoch": 10.302409638554217,
      "grad_norm": 0.03336415812373161,
      "learning_rate": 9.697590361445785e-06,
      "loss": 0.0231,
      "step": 85510
    },
    {
      "epoch": 10.303614457831324,
      "grad_norm": 0.055092792958021164,
      "learning_rate": 9.696385542168676e-06,
      "loss": 0.0409,
      "step": 85520
    },
    {
      "epoch": 10.304819277108434,
      "grad_norm": 0.1431574523448944,
      "learning_rate": 9.695180722891567e-06,
      "loss": 0.0068,
      "step": 85530
    },
    {
      "epoch": 10.306024096385542,
      "grad_norm": 0.017521394416689873,
      "learning_rate": 9.693975903614459e-06,
      "loss": 0.0086,
      "step": 85540
    },
    {
      "epoch": 10.30722891566265,
      "grad_norm": 0.0602831095457077,
      "learning_rate": 9.69277108433735e-06,
      "loss": 0.0133,
      "step": 85550
    },
    {
      "epoch": 10.30843373493976,
      "grad_norm": 0.07553839683532715,
      "learning_rate": 9.691566265060242e-06,
      "loss": 0.015,
      "step": 85560
    },
    {
      "epoch": 10.309638554216868,
      "grad_norm": 0.0012634432641789317,
      "learning_rate": 9.690361445783133e-06,
      "loss": 0.0182,
      "step": 85570
    },
    {
      "epoch": 10.310843373493976,
      "grad_norm": 0.1006186231970787,
      "learning_rate": 9.689156626506024e-06,
      "loss": 0.0276,
      "step": 85580
    },
    {
      "epoch": 10.312048192771085,
      "grad_norm": 0.05964924767613411,
      "learning_rate": 9.687951807228916e-06,
      "loss": 0.0031,
      "step": 85590
    },
    {
      "epoch": 10.313253012048193,
      "grad_norm": 0.022872982546687126,
      "learning_rate": 9.686746987951809e-06,
      "loss": 0.009,
      "step": 85600
    },
    {
      "epoch": 10.314457831325301,
      "grad_norm": 0.004437084775418043,
      "learning_rate": 9.6855421686747e-06,
      "loss": 0.0668,
      "step": 85610
    },
    {
      "epoch": 10.315662650602409,
      "grad_norm": 1.1231558322906494,
      "learning_rate": 9.684337349397592e-06,
      "loss": 0.0116,
      "step": 85620
    },
    {
      "epoch": 10.316867469879519,
      "grad_norm": 0.001826401217840612,
      "learning_rate": 9.683132530120483e-06,
      "loss": 0.0275,
      "step": 85630
    },
    {
      "epoch": 10.318072289156627,
      "grad_norm": 0.11145854741334915,
      "learning_rate": 9.681927710843373e-06,
      "loss": 0.0295,
      "step": 85640
    },
    {
      "epoch": 10.319277108433734,
      "grad_norm": 0.015342390164732933,
      "learning_rate": 9.680722891566266e-06,
      "loss": 0.0047,
      "step": 85650
    },
    {
      "epoch": 10.320481927710844,
      "grad_norm": 0.002187052508816123,
      "learning_rate": 9.679518072289158e-06,
      "loss": 0.0261,
      "step": 85660
    },
    {
      "epoch": 10.321686746987952,
      "grad_norm": 0.02315519191324711,
      "learning_rate": 9.678313253012049e-06,
      "loss": 0.066,
      "step": 85670
    },
    {
      "epoch": 10.32289156626506,
      "grad_norm": 0.07110831141471863,
      "learning_rate": 9.677108433734941e-06,
      "loss": 0.0039,
      "step": 85680
    },
    {
      "epoch": 10.324096385542168,
      "grad_norm": 0.008601677604019642,
      "learning_rate": 9.675903614457832e-06,
      "loss": 0.0209,
      "step": 85690
    },
    {
      "epoch": 10.325301204819278,
      "grad_norm": 0.006361560896039009,
      "learning_rate": 9.674698795180723e-06,
      "loss": 0.0097,
      "step": 85700
    },
    {
      "epoch": 10.326506024096386,
      "grad_norm": 0.004920065402984619,
      "learning_rate": 9.673493975903615e-06,
      "loss": 0.0325,
      "step": 85710
    },
    {
      "epoch": 10.327710843373493,
      "grad_norm": 0.01367919985204935,
      "learning_rate": 9.672289156626506e-06,
      "loss": 0.0097,
      "step": 85720
    },
    {
      "epoch": 10.328915662650603,
      "grad_norm": 0.2718702256679535,
      "learning_rate": 9.671084337349398e-06,
      "loss": 0.0368,
      "step": 85730
    },
    {
      "epoch": 10.330120481927711,
      "grad_norm": 4.041736125946045,
      "learning_rate": 9.669879518072291e-06,
      "loss": 0.0345,
      "step": 85740
    },
    {
      "epoch": 10.331325301204819,
      "grad_norm": 0.002874275902286172,
      "learning_rate": 9.668674698795182e-06,
      "loss": 0.0033,
      "step": 85750
    },
    {
      "epoch": 10.332530120481927,
      "grad_norm": 0.013535493053495884,
      "learning_rate": 9.667469879518074e-06,
      "loss": 0.026,
      "step": 85760
    },
    {
      "epoch": 10.333734939759037,
      "grad_norm": 0.37424609065055847,
      "learning_rate": 9.666265060240965e-06,
      "loss": 0.0066,
      "step": 85770
    },
    {
      "epoch": 10.334939759036144,
      "grad_norm": 0.004586644005030394,
      "learning_rate": 9.665060240963856e-06,
      "loss": 0.0029,
      "step": 85780
    },
    {
      "epoch": 10.336144578313252,
      "grad_norm": 0.005917864385992289,
      "learning_rate": 9.663855421686748e-06,
      "loss": 0.0086,
      "step": 85790
    },
    {
      "epoch": 10.337349397590362,
      "grad_norm": 0.0008172172238118947,
      "learning_rate": 9.662650602409639e-06,
      "loss": 0.0282,
      "step": 85800
    },
    {
      "epoch": 10.33855421686747,
      "grad_norm": 0.0017414730973541737,
      "learning_rate": 9.661445783132531e-06,
      "loss": 0.042,
      "step": 85810
    },
    {
      "epoch": 10.339759036144578,
      "grad_norm": 0.0015682416269555688,
      "learning_rate": 9.660240963855424e-06,
      "loss": 0.0259,
      "step": 85820
    },
    {
      "epoch": 10.340963855421688,
      "grad_norm": 16.663389205932617,
      "learning_rate": 9.659036144578314e-06,
      "loss": 0.0378,
      "step": 85830
    },
    {
      "epoch": 10.342168674698796,
      "grad_norm": 9.420661926269531,
      "learning_rate": 9.657831325301205e-06,
      "loss": 0.0178,
      "step": 85840
    },
    {
      "epoch": 10.343373493975903,
      "grad_norm": 2.876929521560669,
      "learning_rate": 9.656626506024097e-06,
      "loss": 0.0301,
      "step": 85850
    },
    {
      "epoch": 10.344578313253011,
      "grad_norm": 1.2913464307785034,
      "learning_rate": 9.655421686746988e-06,
      "loss": 0.021,
      "step": 85860
    },
    {
      "epoch": 10.345783132530121,
      "grad_norm": 1.2766931056976318,
      "learning_rate": 9.65421686746988e-06,
      "loss": 0.0049,
      "step": 85870
    },
    {
      "epoch": 10.346987951807229,
      "grad_norm": 7.080212593078613,
      "learning_rate": 9.653012048192771e-06,
      "loss": 0.0295,
      "step": 85880
    },
    {
      "epoch": 10.348192771084337,
      "grad_norm": 0.0012702436652034521,
      "learning_rate": 9.651807228915664e-06,
      "loss": 0.0049,
      "step": 85890
    },
    {
      "epoch": 10.349397590361447,
      "grad_norm": 0.0129964305087924,
      "learning_rate": 9.650602409638555e-06,
      "loss": 0.0163,
      "step": 85900
    },
    {
      "epoch": 10.350602409638554,
      "grad_norm": 0.001328076352365315,
      "learning_rate": 9.649397590361447e-06,
      "loss": 0.0072,
      "step": 85910
    },
    {
      "epoch": 10.351807228915662,
      "grad_norm": 1.1101796627044678,
      "learning_rate": 9.648192771084338e-06,
      "loss": 0.0107,
      "step": 85920
    },
    {
      "epoch": 10.35301204819277,
      "grad_norm": 1.885309100151062,
      "learning_rate": 9.64698795180723e-06,
      "loss": 0.026,
      "step": 85930
    },
    {
      "epoch": 10.35421686746988,
      "grad_norm": 0.00035837345058098435,
      "learning_rate": 9.645783132530121e-06,
      "loss": 0.0057,
      "step": 85940
    },
    {
      "epoch": 10.355421686746988,
      "grad_norm": 0.11368530988693237,
      "learning_rate": 9.644578313253012e-06,
      "loss": 0.0732,
      "step": 85950
    },
    {
      "epoch": 10.356626506024096,
      "grad_norm": 2.1592063903808594,
      "learning_rate": 9.643373493975906e-06,
      "loss": 0.0216,
      "step": 85960
    },
    {
      "epoch": 10.357831325301206,
      "grad_norm": 0.0707973763346672,
      "learning_rate": 9.642168674698797e-06,
      "loss": 0.0342,
      "step": 85970
    },
    {
      "epoch": 10.359036144578313,
      "grad_norm": 8.611666679382324,
      "learning_rate": 9.640963855421687e-06,
      "loss": 0.0604,
      "step": 85980
    },
    {
      "epoch": 10.360240963855421,
      "grad_norm": 0.4916113615036011,
      "learning_rate": 9.63975903614458e-06,
      "loss": 0.0118,
      "step": 85990
    },
    {
      "epoch": 10.36144578313253,
      "grad_norm": 0.04414442181587219,
      "learning_rate": 9.63855421686747e-06,
      "loss": 0.03,
      "step": 86000
    },
    {
      "epoch": 10.362650602409639,
      "grad_norm": 0.005779193248599768,
      "learning_rate": 9.637349397590363e-06,
      "loss": 0.0156,
      "step": 86010
    },
    {
      "epoch": 10.363855421686747,
      "grad_norm": 35.6937255859375,
      "learning_rate": 9.636144578313254e-06,
      "loss": 0.0143,
      "step": 86020
    },
    {
      "epoch": 10.365060240963855,
      "grad_norm": 0.06679745763540268,
      "learning_rate": 9.634939759036144e-06,
      "loss": 0.0262,
      "step": 86030
    },
    {
      "epoch": 10.366265060240965,
      "grad_norm": 0.001918284804560244,
      "learning_rate": 9.633734939759037e-06,
      "loss": 0.0043,
      "step": 86040
    },
    {
      "epoch": 10.367469879518072,
      "grad_norm": 0.001639666617847979,
      "learning_rate": 9.63253012048193e-06,
      "loss": 0.013,
      "step": 86050
    },
    {
      "epoch": 10.36867469879518,
      "grad_norm": 0.004934858996421099,
      "learning_rate": 9.63132530120482e-06,
      "loss": 0.0423,
      "step": 86060
    },
    {
      "epoch": 10.369879518072288,
      "grad_norm": 0.0014921638648957014,
      "learning_rate": 9.630120481927712e-06,
      "loss": 0.0028,
      "step": 86070
    },
    {
      "epoch": 10.371084337349398,
      "grad_norm": 0.0008051540935412049,
      "learning_rate": 9.628915662650603e-06,
      "loss": 0.0077,
      "step": 86080
    },
    {
      "epoch": 10.372289156626506,
      "grad_norm": 0.00039672237471677363,
      "learning_rate": 9.627710843373494e-06,
      "loss": 0.0502,
      "step": 86090
    },
    {
      "epoch": 10.373493975903614,
      "grad_norm": 0.06362978368997574,
      "learning_rate": 9.626506024096386e-06,
      "loss": 0.004,
      "step": 86100
    },
    {
      "epoch": 10.374698795180723,
      "grad_norm": 0.0049583143554627895,
      "learning_rate": 9.625301204819279e-06,
      "loss": 0.0183,
      "step": 86110
    },
    {
      "epoch": 10.375903614457831,
      "grad_norm": 0.820796012878418,
      "learning_rate": 9.62409638554217e-06,
      "loss": 0.0178,
      "step": 86120
    },
    {
      "epoch": 10.37710843373494,
      "grad_norm": 0.3356260061264038,
      "learning_rate": 9.622891566265062e-06,
      "loss": 0.0439,
      "step": 86130
    },
    {
      "epoch": 10.378313253012049,
      "grad_norm": 0.3105660080909729,
      "learning_rate": 9.621686746987953e-06,
      "loss": 0.0556,
      "step": 86140
    },
    {
      "epoch": 10.379518072289157,
      "grad_norm": 0.004864921793341637,
      "learning_rate": 9.620481927710843e-06,
      "loss": 0.0067,
      "step": 86150
    },
    {
      "epoch": 10.380722891566265,
      "grad_norm": 0.69500732421875,
      "learning_rate": 9.619277108433736e-06,
      "loss": 0.0283,
      "step": 86160
    },
    {
      "epoch": 10.381927710843373,
      "grad_norm": 0.6186456680297852,
      "learning_rate": 9.618072289156627e-06,
      "loss": 0.0066,
      "step": 86170
    },
    {
      "epoch": 10.383132530120482,
      "grad_norm": 0.027366286143660545,
      "learning_rate": 9.616867469879519e-06,
      "loss": 0.0048,
      "step": 86180
    },
    {
      "epoch": 10.38433734939759,
      "grad_norm": 0.00292622740380466,
      "learning_rate": 9.615662650602411e-06,
      "loss": 0.0056,
      "step": 86190
    },
    {
      "epoch": 10.385542168674698,
      "grad_norm": 18.197250366210938,
      "learning_rate": 9.614457831325302e-06,
      "loss": 0.0117,
      "step": 86200
    },
    {
      "epoch": 10.386746987951808,
      "grad_norm": 0.001355149201117456,
      "learning_rate": 9.613253012048193e-06,
      "loss": 0.0205,
      "step": 86210
    },
    {
      "epoch": 10.387951807228916,
      "grad_norm": 0.7098075151443481,
      "learning_rate": 9.612048192771085e-06,
      "loss": 0.0624,
      "step": 86220
    },
    {
      "epoch": 10.389156626506024,
      "grad_norm": 0.02931893616914749,
      "learning_rate": 9.610843373493976e-06,
      "loss": 0.0111,
      "step": 86230
    },
    {
      "epoch": 10.390361445783132,
      "grad_norm": 2.3863165378570557,
      "learning_rate": 9.609638554216869e-06,
      "loss": 0.0324,
      "step": 86240
    },
    {
      "epoch": 10.391566265060241,
      "grad_norm": 0.3788842260837555,
      "learning_rate": 9.60843373493976e-06,
      "loss": 0.038,
      "step": 86250
    },
    {
      "epoch": 10.39277108433735,
      "grad_norm": 0.2566596269607544,
      "learning_rate": 9.607228915662652e-06,
      "loss": 0.0029,
      "step": 86260
    },
    {
      "epoch": 10.393975903614457,
      "grad_norm": 0.009724674746394157,
      "learning_rate": 9.606024096385544e-06,
      "loss": 0.0321,
      "step": 86270
    },
    {
      "epoch": 10.395180722891567,
      "grad_norm": 0.0031686085276305676,
      "learning_rate": 9.604819277108435e-06,
      "loss": 0.0101,
      "step": 86280
    },
    {
      "epoch": 10.396385542168675,
      "grad_norm": 1.7794533967971802,
      "learning_rate": 9.603614457831326e-06,
      "loss": 0.0226,
      "step": 86290
    },
    {
      "epoch": 10.397590361445783,
      "grad_norm": 11.63701057434082,
      "learning_rate": 9.602409638554218e-06,
      "loss": 0.0151,
      "step": 86300
    },
    {
      "epoch": 10.398795180722892,
      "grad_norm": 0.0013737601693719625,
      "learning_rate": 9.601204819277109e-06,
      "loss": 0.0202,
      "step": 86310
    },
    {
      "epoch": 10.4,
      "grad_norm": 0.002688868436962366,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0052,
      "step": 86320
    },
    {
      "epoch": 10.401204819277108,
      "grad_norm": 0.0019196482608094811,
      "learning_rate": 9.598795180722892e-06,
      "loss": 0.0073,
      "step": 86330
    },
    {
      "epoch": 10.402409638554216,
      "grad_norm": 0.011846189387142658,
      "learning_rate": 9.597590361445784e-06,
      "loss": 0.0011,
      "step": 86340
    },
    {
      "epoch": 10.403614457831326,
      "grad_norm": 0.001783397514373064,
      "learning_rate": 9.596385542168675e-06,
      "loss": 0.036,
      "step": 86350
    },
    {
      "epoch": 10.404819277108434,
      "grad_norm": 11.192086219787598,
      "learning_rate": 9.595180722891568e-06,
      "loss": 0.0272,
      "step": 86360
    },
    {
      "epoch": 10.406024096385542,
      "grad_norm": 0.002654328476637602,
      "learning_rate": 9.593975903614458e-06,
      "loss": 0.0016,
      "step": 86370
    },
    {
      "epoch": 10.407228915662651,
      "grad_norm": 0.0019194954074919224,
      "learning_rate": 9.59277108433735e-06,
      "loss": 0.0345,
      "step": 86380
    },
    {
      "epoch": 10.40843373493976,
      "grad_norm": 0.004266576375812292,
      "learning_rate": 9.591566265060242e-06,
      "loss": 0.0266,
      "step": 86390
    },
    {
      "epoch": 10.409638554216867,
      "grad_norm": 2.581000566482544,
      "learning_rate": 9.590361445783132e-06,
      "loss": 0.0452,
      "step": 86400
    },
    {
      "epoch": 10.410843373493975,
      "grad_norm": 1.4153720140457153,
      "learning_rate": 9.589156626506025e-06,
      "loss": 0.0484,
      "step": 86410
    },
    {
      "epoch": 10.412048192771085,
      "grad_norm": 0.06813770532608032,
      "learning_rate": 9.587951807228917e-06,
      "loss": 0.0068,
      "step": 86420
    },
    {
      "epoch": 10.413253012048193,
      "grad_norm": 1.5733948945999146,
      "learning_rate": 9.586746987951808e-06,
      "loss": 0.0367,
      "step": 86430
    },
    {
      "epoch": 10.4144578313253,
      "grad_norm": 0.0029358065221458673,
      "learning_rate": 9.5855421686747e-06,
      "loss": 0.0197,
      "step": 86440
    },
    {
      "epoch": 10.41566265060241,
      "grad_norm": 0.020237715914845467,
      "learning_rate": 9.584337349397591e-06,
      "loss": 0.0098,
      "step": 86450
    },
    {
      "epoch": 10.416867469879518,
      "grad_norm": 5.614987850189209,
      "learning_rate": 9.583132530120482e-06,
      "loss": 0.0397,
      "step": 86460
    },
    {
      "epoch": 10.418072289156626,
      "grad_norm": 2.4537153244018555,
      "learning_rate": 9.581927710843374e-06,
      "loss": 0.0391,
      "step": 86470
    },
    {
      "epoch": 10.419277108433734,
      "grad_norm": 0.02005939744412899,
      "learning_rate": 9.580722891566265e-06,
      "loss": 0.01,
      "step": 86480
    },
    {
      "epoch": 10.420481927710844,
      "grad_norm": 0.0579368956387043,
      "learning_rate": 9.579518072289157e-06,
      "loss": 0.0518,
      "step": 86490
    },
    {
      "epoch": 10.421686746987952,
      "grad_norm": 6.504387855529785,
      "learning_rate": 9.57831325301205e-06,
      "loss": 0.0374,
      "step": 86500
    },
    {
      "epoch": 10.42289156626506,
      "grad_norm": 0.40155351161956787,
      "learning_rate": 9.57710843373494e-06,
      "loss": 0.0257,
      "step": 86510
    },
    {
      "epoch": 10.42409638554217,
      "grad_norm": 3.8713643550872803,
      "learning_rate": 9.575903614457831e-06,
      "loss": 0.0156,
      "step": 86520
    },
    {
      "epoch": 10.425301204819277,
      "grad_norm": 0.0034249317832291126,
      "learning_rate": 9.574698795180724e-06,
      "loss": 0.0285,
      "step": 86530
    },
    {
      "epoch": 10.426506024096385,
      "grad_norm": 0.11467017233371735,
      "learning_rate": 9.573493975903615e-06,
      "loss": 0.032,
      "step": 86540
    },
    {
      "epoch": 10.427710843373493,
      "grad_norm": 0.5324746370315552,
      "learning_rate": 9.572289156626507e-06,
      "loss": 0.0093,
      "step": 86550
    },
    {
      "epoch": 10.428915662650603,
      "grad_norm": 0.31750527024269104,
      "learning_rate": 9.5710843373494e-06,
      "loss": 0.0222,
      "step": 86560
    },
    {
      "epoch": 10.43012048192771,
      "grad_norm": 0.007783323060721159,
      "learning_rate": 9.56987951807229e-06,
      "loss": 0.0306,
      "step": 86570
    },
    {
      "epoch": 10.431325301204819,
      "grad_norm": 0.07169552147388458,
      "learning_rate": 9.568674698795183e-06,
      "loss": 0.0382,
      "step": 86580
    },
    {
      "epoch": 10.432530120481928,
      "grad_norm": 0.005399090703576803,
      "learning_rate": 9.567469879518073e-06,
      "loss": 0.0495,
      "step": 86590
    },
    {
      "epoch": 10.433734939759036,
      "grad_norm": 0.015452387742698193,
      "learning_rate": 9.566265060240964e-06,
      "loss": 0.0139,
      "step": 86600
    },
    {
      "epoch": 10.434939759036144,
      "grad_norm": 0.006554110441356897,
      "learning_rate": 9.565060240963856e-06,
      "loss": 0.0454,
      "step": 86610
    },
    {
      "epoch": 10.436144578313254,
      "grad_norm": 0.0017657168209552765,
      "learning_rate": 9.563855421686747e-06,
      "loss": 0.0213,
      "step": 86620
    },
    {
      "epoch": 10.437349397590362,
      "grad_norm": 0.8083165884017944,
      "learning_rate": 9.56265060240964e-06,
      "loss": 0.0218,
      "step": 86630
    },
    {
      "epoch": 10.43855421686747,
      "grad_norm": 0.1767626404762268,
      "learning_rate": 9.561445783132532e-06,
      "loss": 0.0341,
      "step": 86640
    },
    {
      "epoch": 10.439759036144578,
      "grad_norm": 1.5949993133544922,
      "learning_rate": 9.560240963855423e-06,
      "loss": 0.0526,
      "step": 86650
    },
    {
      "epoch": 10.440963855421687,
      "grad_norm": 0.01062089204788208,
      "learning_rate": 9.559036144578314e-06,
      "loss": 0.0517,
      "step": 86660
    },
    {
      "epoch": 10.442168674698795,
      "grad_norm": 0.012100967578589916,
      "learning_rate": 9.557831325301206e-06,
      "loss": 0.0034,
      "step": 86670
    },
    {
      "epoch": 10.443373493975903,
      "grad_norm": 0.010382218286395073,
      "learning_rate": 9.556626506024097e-06,
      "loss": 0.0464,
      "step": 86680
    },
    {
      "epoch": 10.444578313253013,
      "grad_norm": 0.07010269910097122,
      "learning_rate": 9.55542168674699e-06,
      "loss": 0.0239,
      "step": 86690
    },
    {
      "epoch": 10.44578313253012,
      "grad_norm": 0.429595023393631,
      "learning_rate": 9.55421686746988e-06,
      "loss": 0.0135,
      "step": 86700
    },
    {
      "epoch": 10.446987951807229,
      "grad_norm": 0.0015620727790519595,
      "learning_rate": 9.553012048192772e-06,
      "loss": 0.0071,
      "step": 86710
    },
    {
      "epoch": 10.448192771084337,
      "grad_norm": 0.002291246550157666,
      "learning_rate": 9.551807228915663e-06,
      "loss": 0.0217,
      "step": 86720
    },
    {
      "epoch": 10.449397590361446,
      "grad_norm": 0.016656890511512756,
      "learning_rate": 9.550602409638556e-06,
      "loss": 0.002,
      "step": 86730
    },
    {
      "epoch": 10.450602409638554,
      "grad_norm": 0.0068575977347791195,
      "learning_rate": 9.549397590361446e-06,
      "loss": 0.0141,
      "step": 86740
    },
    {
      "epoch": 10.451807228915662,
      "grad_norm": 2.0010929107666016,
      "learning_rate": 9.548192771084339e-06,
      "loss": 0.0253,
      "step": 86750
    },
    {
      "epoch": 10.453012048192772,
      "grad_norm": 0.0018842091085389256,
      "learning_rate": 9.54698795180723e-06,
      "loss": 0.0444,
      "step": 86760
    },
    {
      "epoch": 10.45421686746988,
      "grad_norm": 0.02230796590447426,
      "learning_rate": 9.54578313253012e-06,
      "loss": 0.0054,
      "step": 86770
    },
    {
      "epoch": 10.455421686746988,
      "grad_norm": 0.0020989670883864164,
      "learning_rate": 9.544578313253013e-06,
      "loss": 0.0532,
      "step": 86780
    },
    {
      "epoch": 10.456626506024097,
      "grad_norm": 0.004754186142235994,
      "learning_rate": 9.543373493975905e-06,
      "loss": 0.0081,
      "step": 86790
    },
    {
      "epoch": 10.457831325301205,
      "grad_norm": 0.0019561555236577988,
      "learning_rate": 9.542168674698796e-06,
      "loss": 0.0253,
      "step": 86800
    },
    {
      "epoch": 10.459036144578313,
      "grad_norm": 3.793950319290161,
      "learning_rate": 9.540963855421688e-06,
      "loss": 0.0333,
      "step": 86810
    },
    {
      "epoch": 10.460240963855421,
      "grad_norm": 0.0013843257911503315,
      "learning_rate": 9.539759036144579e-06,
      "loss": 0.0034,
      "step": 86820
    },
    {
      "epoch": 10.46144578313253,
      "grad_norm": 0.5906461477279663,
      "learning_rate": 9.53855421686747e-06,
      "loss": 0.025,
      "step": 86830
    },
    {
      "epoch": 10.462650602409639,
      "grad_norm": 4.022793292999268,
      "learning_rate": 9.537349397590362e-06,
      "loss": 0.023,
      "step": 86840
    },
    {
      "epoch": 10.463855421686747,
      "grad_norm": 0.002655024640262127,
      "learning_rate": 9.536144578313253e-06,
      "loss": 0.024,
      "step": 86850
    },
    {
      "epoch": 10.465060240963856,
      "grad_norm": 0.5783864855766296,
      "learning_rate": 9.534939759036145e-06,
      "loss": 0.0462,
      "step": 86860
    },
    {
      "epoch": 10.466265060240964,
      "grad_norm": 0.010601971298456192,
      "learning_rate": 9.533734939759038e-06,
      "loss": 0.065,
      "step": 86870
    },
    {
      "epoch": 10.467469879518072,
      "grad_norm": 1.0896025896072388,
      "learning_rate": 9.532530120481928e-06,
      "loss": 0.0086,
      "step": 86880
    },
    {
      "epoch": 10.46867469879518,
      "grad_norm": 2.2366292476654053,
      "learning_rate": 9.531325301204821e-06,
      "loss": 0.0193,
      "step": 86890
    },
    {
      "epoch": 10.46987951807229,
      "grad_norm": 1.960014820098877,
      "learning_rate": 9.530120481927712e-06,
      "loss": 0.0251,
      "step": 86900
    },
    {
      "epoch": 10.471084337349398,
      "grad_norm": 0.002732999389991164,
      "learning_rate": 9.528915662650602e-06,
      "loss": 0.0421,
      "step": 86910
    },
    {
      "epoch": 10.472289156626506,
      "grad_norm": 0.0015405963640660048,
      "learning_rate": 9.527710843373495e-06,
      "loss": 0.0612,
      "step": 86920
    },
    {
      "epoch": 10.473493975903615,
      "grad_norm": 0.14824378490447998,
      "learning_rate": 9.526506024096386e-06,
      "loss": 0.0192,
      "step": 86930
    },
    {
      "epoch": 10.474698795180723,
      "grad_norm": 0.8695618510246277,
      "learning_rate": 9.525301204819278e-06,
      "loss": 0.0369,
      "step": 86940
    },
    {
      "epoch": 10.475903614457831,
      "grad_norm": 0.4083552658557892,
      "learning_rate": 9.52409638554217e-06,
      "loss": 0.0503,
      "step": 86950
    },
    {
      "epoch": 10.477108433734939,
      "grad_norm": 0.03929360210895538,
      "learning_rate": 9.522891566265061e-06,
      "loss": 0.0127,
      "step": 86960
    },
    {
      "epoch": 10.478313253012049,
      "grad_norm": 8.387214660644531,
      "learning_rate": 9.521686746987952e-06,
      "loss": 0.038,
      "step": 86970
    },
    {
      "epoch": 10.479518072289157,
      "grad_norm": 0.006446709856390953,
      "learning_rate": 9.520481927710844e-06,
      "loss": 0.0281,
      "step": 86980
    },
    {
      "epoch": 10.480722891566264,
      "grad_norm": 0.7540394067764282,
      "learning_rate": 9.519277108433735e-06,
      "loss": 0.0088,
      "step": 86990
    },
    {
      "epoch": 10.481927710843374,
      "grad_norm": 0.39210155606269836,
      "learning_rate": 9.518072289156628e-06,
      "loss": 0.0501,
      "step": 87000
    },
    {
      "epoch": 10.483132530120482,
      "grad_norm": 0.004033342935144901,
      "learning_rate": 9.51686746987952e-06,
      "loss": 0.0336,
      "step": 87010
    },
    {
      "epoch": 10.48433734939759,
      "grad_norm": 0.09257707744836807,
      "learning_rate": 9.51566265060241e-06,
      "loss": 0.0014,
      "step": 87020
    },
    {
      "epoch": 10.485542168674698,
      "grad_norm": 9.860058784484863,
      "learning_rate": 9.514457831325301e-06,
      "loss": 0.0256,
      "step": 87030
    },
    {
      "epoch": 10.486746987951808,
      "grad_norm": 0.04686485230922699,
      "learning_rate": 9.513253012048194e-06,
      "loss": 0.0314,
      "step": 87040
    },
    {
      "epoch": 10.487951807228916,
      "grad_norm": 0.006910606287419796,
      "learning_rate": 9.512048192771085e-06,
      "loss": 0.0498,
      "step": 87050
    },
    {
      "epoch": 10.489156626506023,
      "grad_norm": 0.04402906820178032,
      "learning_rate": 9.510843373493977e-06,
      "loss": 0.073,
      "step": 87060
    },
    {
      "epoch": 10.490361445783133,
      "grad_norm": 0.05497687682509422,
      "learning_rate": 9.509638554216868e-06,
      "loss": 0.0048,
      "step": 87070
    },
    {
      "epoch": 10.491566265060241,
      "grad_norm": 1.939989686012268,
      "learning_rate": 9.508433734939759e-06,
      "loss": 0.0917,
      "step": 87080
    },
    {
      "epoch": 10.492771084337349,
      "grad_norm": 217.34075927734375,
      "learning_rate": 9.507228915662651e-06,
      "loss": 0.0239,
      "step": 87090
    },
    {
      "epoch": 10.493975903614459,
      "grad_norm": 0.348267138004303,
      "learning_rate": 9.506024096385543e-06,
      "loss": 0.0033,
      "step": 87100
    },
    {
      "epoch": 10.495180722891567,
      "grad_norm": 0.023101408034563065,
      "learning_rate": 9.504819277108434e-06,
      "loss": 0.0059,
      "step": 87110
    },
    {
      "epoch": 10.496385542168674,
      "grad_norm": 4.096534252166748,
      "learning_rate": 9.503614457831327e-06,
      "loss": 0.0142,
      "step": 87120
    },
    {
      "epoch": 10.497590361445782,
      "grad_norm": 0.02980826608836651,
      "learning_rate": 9.502409638554217e-06,
      "loss": 0.0144,
      "step": 87130
    },
    {
      "epoch": 10.498795180722892,
      "grad_norm": 0.0033512236550450325,
      "learning_rate": 9.501204819277108e-06,
      "loss": 0.0162,
      "step": 87140
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.007301124278455973,
      "learning_rate": 9.5e-06,
      "loss": 0.0293,
      "step": 87150
    },
    {
      "epoch": 10.501204819277108,
      "grad_norm": 1.5830326080322266,
      "learning_rate": 9.498795180722893e-06,
      "loss": 0.0076,
      "step": 87160
    },
    {
      "epoch": 10.502409638554218,
      "grad_norm": 0.0010736010735854506,
      "learning_rate": 9.497590361445784e-06,
      "loss": 0.0176,
      "step": 87170
    },
    {
      "epoch": 10.503614457831326,
      "grad_norm": 0.02022140473127365,
      "learning_rate": 9.496385542168676e-06,
      "loss": 0.059,
      "step": 87180
    },
    {
      "epoch": 10.504819277108433,
      "grad_norm": 0.005447862669825554,
      "learning_rate": 9.495180722891567e-06,
      "loss": 0.0225,
      "step": 87190
    },
    {
      "epoch": 10.506024096385541,
      "grad_norm": 0.028786268085241318,
      "learning_rate": 9.49397590361446e-06,
      "loss": 0.0493,
      "step": 87200
    },
    {
      "epoch": 10.507228915662651,
      "grad_norm": 0.0172873642295599,
      "learning_rate": 9.49277108433735e-06,
      "loss": 0.0022,
      "step": 87210
    },
    {
      "epoch": 10.508433734939759,
      "grad_norm": 0.1909211426973343,
      "learning_rate": 9.49156626506024e-06,
      "loss": 0.0467,
      "step": 87220
    },
    {
      "epoch": 10.509638554216867,
      "grad_norm": 0.02624015510082245,
      "learning_rate": 9.490361445783133e-06,
      "loss": 0.0104,
      "step": 87230
    },
    {
      "epoch": 10.510843373493977,
      "grad_norm": 4.296246528625488,
      "learning_rate": 9.489156626506026e-06,
      "loss": 0.0102,
      "step": 87240
    },
    {
      "epoch": 10.512048192771084,
      "grad_norm": 2.3204643726348877,
      "learning_rate": 9.487951807228916e-06,
      "loss": 0.0658,
      "step": 87250
    },
    {
      "epoch": 10.513253012048192,
      "grad_norm": 1.9368239641189575,
      "learning_rate": 9.486746987951809e-06,
      "loss": 0.0288,
      "step": 87260
    },
    {
      "epoch": 10.514457831325302,
      "grad_norm": 2.6698806285858154,
      "learning_rate": 9.4855421686747e-06,
      "loss": 0.0721,
      "step": 87270
    },
    {
      "epoch": 10.51566265060241,
      "grad_norm": 1.914448618888855,
      "learning_rate": 9.48433734939759e-06,
      "loss": 0.0101,
      "step": 87280
    },
    {
      "epoch": 10.516867469879518,
      "grad_norm": 0.003605692181736231,
      "learning_rate": 9.483132530120483e-06,
      "loss": 0.0048,
      "step": 87290
    },
    {
      "epoch": 10.518072289156626,
      "grad_norm": 1.858147382736206,
      "learning_rate": 9.481927710843373e-06,
      "loss": 0.0082,
      "step": 87300
    },
    {
      "epoch": 10.519277108433736,
      "grad_norm": 0.6018839478492737,
      "learning_rate": 9.480722891566266e-06,
      "loss": 0.011,
      "step": 87310
    },
    {
      "epoch": 10.520481927710843,
      "grad_norm": 0.0126809636130929,
      "learning_rate": 9.479518072289158e-06,
      "loss": 0.0059,
      "step": 87320
    },
    {
      "epoch": 10.521686746987951,
      "grad_norm": 0.3512287139892578,
      "learning_rate": 9.478313253012049e-06,
      "loss": 0.0132,
      "step": 87330
    },
    {
      "epoch": 10.522891566265061,
      "grad_norm": 0.010223818011581898,
      "learning_rate": 9.47710843373494e-06,
      "loss": 0.0167,
      "step": 87340
    },
    {
      "epoch": 10.524096385542169,
      "grad_norm": 1.9804787635803223,
      "learning_rate": 9.475903614457832e-06,
      "loss": 0.0604,
      "step": 87350
    },
    {
      "epoch": 10.525301204819277,
      "grad_norm": 0.1035650447010994,
      "learning_rate": 9.474698795180723e-06,
      "loss": 0.0066,
      "step": 87360
    },
    {
      "epoch": 10.526506024096385,
      "grad_norm": 0.5020130276679993,
      "learning_rate": 9.473493975903615e-06,
      "loss": 0.0328,
      "step": 87370
    },
    {
      "epoch": 10.527710843373494,
      "grad_norm": 0.004945544525980949,
      "learning_rate": 9.472289156626506e-06,
      "loss": 0.0101,
      "step": 87380
    },
    {
      "epoch": 10.528915662650602,
      "grad_norm": 0.005335275083780289,
      "learning_rate": 9.471084337349399e-06,
      "loss": 0.0207,
      "step": 87390
    },
    {
      "epoch": 10.53012048192771,
      "grad_norm": 0.005672863218933344,
      "learning_rate": 9.46987951807229e-06,
      "loss": 0.0114,
      "step": 87400
    },
    {
      "epoch": 10.53132530120482,
      "grad_norm": 0.1844194233417511,
      "learning_rate": 9.468674698795182e-06,
      "loss": 0.0405,
      "step": 87410
    },
    {
      "epoch": 10.532530120481928,
      "grad_norm": 0.5456899404525757,
      "learning_rate": 9.467469879518073e-06,
      "loss": 0.0134,
      "step": 87420
    },
    {
      "epoch": 10.533734939759036,
      "grad_norm": 0.0615791492164135,
      "learning_rate": 9.466265060240965e-06,
      "loss": 0.0101,
      "step": 87430
    },
    {
      "epoch": 10.534939759036144,
      "grad_norm": 0.03691026195883751,
      "learning_rate": 9.465060240963856e-06,
      "loss": 0.013,
      "step": 87440
    },
    {
      "epoch": 10.536144578313253,
      "grad_norm": 0.7091021537780762,
      "learning_rate": 9.463855421686746e-06,
      "loss": 0.0268,
      "step": 87450
    },
    {
      "epoch": 10.537349397590361,
      "grad_norm": 1.5057287216186523,
      "learning_rate": 9.46265060240964e-06,
      "loss": 0.0422,
      "step": 87460
    },
    {
      "epoch": 10.53855421686747,
      "grad_norm": 0.005730289034545422,
      "learning_rate": 9.461445783132531e-06,
      "loss": 0.0058,
      "step": 87470
    },
    {
      "epoch": 10.539759036144579,
      "grad_norm": 0.006892395671457052,
      "learning_rate": 9.460240963855422e-06,
      "loss": 0.0162,
      "step": 87480
    },
    {
      "epoch": 10.540963855421687,
      "grad_norm": 0.045727990567684174,
      "learning_rate": 9.459036144578315e-06,
      "loss": 0.0086,
      "step": 87490
    },
    {
      "epoch": 10.542168674698795,
      "grad_norm": 3.926711082458496,
      "learning_rate": 9.457831325301205e-06,
      "loss": 0.0316,
      "step": 87500
    },
    {
      "epoch": 10.543373493975903,
      "grad_norm": 1.5291274785995483,
      "learning_rate": 9.456626506024098e-06,
      "loss": 0.0396,
      "step": 87510
    },
    {
      "epoch": 10.544578313253012,
      "grad_norm": 0.0038996150251477957,
      "learning_rate": 9.455421686746988e-06,
      "loss": 0.017,
      "step": 87520
    },
    {
      "epoch": 10.54578313253012,
      "grad_norm": 0.14915692806243896,
      "learning_rate": 9.45421686746988e-06,
      "loss": 0.0031,
      "step": 87530
    },
    {
      "epoch": 10.546987951807228,
      "grad_norm": 1.5331523418426514,
      "learning_rate": 9.453012048192772e-06,
      "loss": 0.0364,
      "step": 87540
    },
    {
      "epoch": 10.548192771084338,
      "grad_norm": 0.0043001314625144005,
      "learning_rate": 9.451807228915664e-06,
      "loss": 0.0032,
      "step": 87550
    },
    {
      "epoch": 10.549397590361446,
      "grad_norm": 0.01250354666262865,
      "learning_rate": 9.450602409638555e-06,
      "loss": 0.0159,
      "step": 87560
    },
    {
      "epoch": 10.550602409638554,
      "grad_norm": 1.7880258560180664,
      "learning_rate": 9.449397590361447e-06,
      "loss": 0.0232,
      "step": 87570
    },
    {
      "epoch": 10.551807228915663,
      "grad_norm": 0.004092154558748007,
      "learning_rate": 9.448192771084338e-06,
      "loss": 0.0689,
      "step": 87580
    },
    {
      "epoch": 10.553012048192771,
      "grad_norm": 19.37241554260254,
      "learning_rate": 9.446987951807229e-06,
      "loss": 0.0331,
      "step": 87590
    },
    {
      "epoch": 10.55421686746988,
      "grad_norm": 0.03982391580939293,
      "learning_rate": 9.445783132530121e-06,
      "loss": 0.0029,
      "step": 87600
    },
    {
      "epoch": 10.555421686746987,
      "grad_norm": 0.6715909838676453,
      "learning_rate": 9.444578313253014e-06,
      "loss": 0.0295,
      "step": 87610
    },
    {
      "epoch": 10.556626506024097,
      "grad_norm": 1.4939069747924805,
      "learning_rate": 9.443373493975904e-06,
      "loss": 0.0225,
      "step": 87620
    },
    {
      "epoch": 10.557831325301205,
      "grad_norm": 12.654644966125488,
      "learning_rate": 9.442168674698797e-06,
      "loss": 0.043,
      "step": 87630
    },
    {
      "epoch": 10.559036144578313,
      "grad_norm": 0.08602413535118103,
      "learning_rate": 9.440963855421687e-06,
      "loss": 0.0261,
      "step": 87640
    },
    {
      "epoch": 10.560240963855422,
      "grad_norm": 0.010438482277095318,
      "learning_rate": 9.439759036144578e-06,
      "loss": 0.0512,
      "step": 87650
    },
    {
      "epoch": 10.56144578313253,
      "grad_norm": 0.07036268711090088,
      "learning_rate": 9.43855421686747e-06,
      "loss": 0.0421,
      "step": 87660
    },
    {
      "epoch": 10.562650602409638,
      "grad_norm": 0.00475241057574749,
      "learning_rate": 9.437349397590361e-06,
      "loss": 0.0034,
      "step": 87670
    },
    {
      "epoch": 10.563855421686746,
      "grad_norm": 0.003981384914368391,
      "learning_rate": 9.436144578313254e-06,
      "loss": 0.0029,
      "step": 87680
    },
    {
      "epoch": 10.565060240963856,
      "grad_norm": 1.6051299571990967,
      "learning_rate": 9.434939759036146e-06,
      "loss": 0.0047,
      "step": 87690
    },
    {
      "epoch": 10.566265060240964,
      "grad_norm": 0.49295058846473694,
      "learning_rate": 9.433734939759037e-06,
      "loss": 0.003,
      "step": 87700
    },
    {
      "epoch": 10.567469879518072,
      "grad_norm": 1.599967122077942,
      "learning_rate": 9.43253012048193e-06,
      "loss": 0.035,
      "step": 87710
    },
    {
      "epoch": 10.568674698795181,
      "grad_norm": 0.0017752029234543443,
      "learning_rate": 9.43132530120482e-06,
      "loss": 0.0025,
      "step": 87720
    },
    {
      "epoch": 10.56987951807229,
      "grad_norm": 0.47928586602211,
      "learning_rate": 9.430120481927711e-06,
      "loss": 0.0097,
      "step": 87730
    },
    {
      "epoch": 10.571084337349397,
      "grad_norm": 0.0029496580827981234,
      "learning_rate": 9.428915662650603e-06,
      "loss": 0.0157,
      "step": 87740
    },
    {
      "epoch": 10.572289156626507,
      "grad_norm": 6.214792251586914,
      "learning_rate": 9.427710843373494e-06,
      "loss": 0.0707,
      "step": 87750
    },
    {
      "epoch": 10.573493975903615,
      "grad_norm": 0.7809600234031677,
      "learning_rate": 9.426506024096387e-06,
      "loss": 0.0043,
      "step": 87760
    },
    {
      "epoch": 10.574698795180723,
      "grad_norm": 0.002562983427196741,
      "learning_rate": 9.425301204819279e-06,
      "loss": 0.0121,
      "step": 87770
    },
    {
      "epoch": 10.57590361445783,
      "grad_norm": 0.002952106297016144,
      "learning_rate": 9.42409638554217e-06,
      "loss": 0.0259,
      "step": 87780
    },
    {
      "epoch": 10.57710843373494,
      "grad_norm": 0.4481534957885742,
      "learning_rate": 9.42289156626506e-06,
      "loss": 0.0097,
      "step": 87790
    },
    {
      "epoch": 10.578313253012048,
      "grad_norm": 0.45391035079956055,
      "learning_rate": 9.421686746987953e-06,
      "loss": 0.0066,
      "step": 87800
    },
    {
      "epoch": 10.579518072289156,
      "grad_norm": 0.0017226533964276314,
      "learning_rate": 9.420481927710844e-06,
      "loss": 0.0205,
      "step": 87810
    },
    {
      "epoch": 10.580722891566266,
      "grad_norm": 0.0019685544539242983,
      "learning_rate": 9.419277108433736e-06,
      "loss": 0.0526,
      "step": 87820
    },
    {
      "epoch": 10.581927710843374,
      "grad_norm": 0.04179491102695465,
      "learning_rate": 9.418072289156627e-06,
      "loss": 0.0015,
      "step": 87830
    },
    {
      "epoch": 10.583132530120482,
      "grad_norm": 4.576136112213135,
      "learning_rate": 9.41686746987952e-06,
      "loss": 0.0322,
      "step": 87840
    },
    {
      "epoch": 10.58433734939759,
      "grad_norm": 1.033192753791809,
      "learning_rate": 9.41566265060241e-06,
      "loss": 0.0158,
      "step": 87850
    },
    {
      "epoch": 10.5855421686747,
      "grad_norm": 0.0033581675961613655,
      "learning_rate": 9.414457831325302e-06,
      "loss": 0.02,
      "step": 87860
    },
    {
      "epoch": 10.586746987951807,
      "grad_norm": 9.622135162353516,
      "learning_rate": 9.413253012048193e-06,
      "loss": 0.0582,
      "step": 87870
    },
    {
      "epoch": 10.587951807228915,
      "grad_norm": 0.26647624373435974,
      "learning_rate": 9.412048192771086e-06,
      "loss": 0.0274,
      "step": 87880
    },
    {
      "epoch": 10.589156626506025,
      "grad_norm": 0.010200847871601582,
      "learning_rate": 9.410843373493976e-06,
      "loss": 0.0106,
      "step": 87890
    },
    {
      "epoch": 10.590361445783133,
      "grad_norm": 0.16365787386894226,
      "learning_rate": 9.409638554216867e-06,
      "loss": 0.0602,
      "step": 87900
    },
    {
      "epoch": 10.59156626506024,
      "grad_norm": 0.06612970679998398,
      "learning_rate": 9.40843373493976e-06,
      "loss": 0.0218,
      "step": 87910
    },
    {
      "epoch": 10.592771084337349,
      "grad_norm": 2.521495819091797,
      "learning_rate": 9.407228915662652e-06,
      "loss": 0.0195,
      "step": 87920
    },
    {
      "epoch": 10.593975903614458,
      "grad_norm": 0.2295684516429901,
      "learning_rate": 9.406024096385543e-06,
      "loss": 0.0546,
      "step": 87930
    },
    {
      "epoch": 10.595180722891566,
      "grad_norm": 0.32188650965690613,
      "learning_rate": 9.404819277108435e-06,
      "loss": 0.0253,
      "step": 87940
    },
    {
      "epoch": 10.596385542168674,
      "grad_norm": 1.788040041923523,
      "learning_rate": 9.403614457831326e-06,
      "loss": 0.007,
      "step": 87950
    },
    {
      "epoch": 10.597590361445784,
      "grad_norm": 0.2983960807323456,
      "learning_rate": 9.402409638554217e-06,
      "loss": 0.0228,
      "step": 87960
    },
    {
      "epoch": 10.598795180722892,
      "grad_norm": 1.685470461845398,
      "learning_rate": 9.401204819277109e-06,
      "loss": 0.0211,
      "step": 87970
    },
    {
      "epoch": 10.6,
      "grad_norm": 0.013632412068545818,
      "learning_rate": 9.4e-06,
      "loss": 0.0489,
      "step": 87980
    },
    {
      "epoch": 10.601204819277108,
      "grad_norm": 0.38149601221084595,
      "learning_rate": 9.398795180722892e-06,
      "loss": 0.0108,
      "step": 87990
    },
    {
      "epoch": 10.602409638554217,
      "grad_norm": 35.75411605834961,
      "learning_rate": 9.397590361445785e-06,
      "loss": 0.0268,
      "step": 88000
    },
    {
      "epoch": 10.603614457831325,
      "grad_norm": 0.7623441219329834,
      "learning_rate": 9.396385542168675e-06,
      "loss": 0.0237,
      "step": 88010
    },
    {
      "epoch": 10.604819277108433,
      "grad_norm": 0.08081167191267014,
      "learning_rate": 9.395180722891568e-06,
      "loss": 0.0067,
      "step": 88020
    },
    {
      "epoch": 10.606024096385543,
      "grad_norm": 2.5907561779022217,
      "learning_rate": 9.393975903614459e-06,
      "loss": 0.019,
      "step": 88030
    },
    {
      "epoch": 10.60722891566265,
      "grad_norm": 0.006970713380724192,
      "learning_rate": 9.39277108433735e-06,
      "loss": 0.0184,
      "step": 88040
    },
    {
      "epoch": 10.608433734939759,
      "grad_norm": 0.001813586801290512,
      "learning_rate": 9.391566265060242e-06,
      "loss": 0.006,
      "step": 88050
    },
    {
      "epoch": 10.609638554216868,
      "grad_norm": 0.0018735480261966586,
      "learning_rate": 9.390361445783134e-06,
      "loss": 0.0181,
      "step": 88060
    },
    {
      "epoch": 10.610843373493976,
      "grad_norm": 0.0036993969697505236,
      "learning_rate": 9.389156626506025e-06,
      "loss": 0.003,
      "step": 88070
    },
    {
      "epoch": 10.612048192771084,
      "grad_norm": 0.002366785891354084,
      "learning_rate": 9.387951807228917e-06,
      "loss": 0.0584,
      "step": 88080
    },
    {
      "epoch": 10.613253012048192,
      "grad_norm": 2.2755956649780273,
      "learning_rate": 9.386746987951808e-06,
      "loss": 0.0529,
      "step": 88090
    },
    {
      "epoch": 10.614457831325302,
      "grad_norm": 3.973489284515381,
      "learning_rate": 9.385542168674699e-06,
      "loss": 0.0182,
      "step": 88100
    },
    {
      "epoch": 10.61566265060241,
      "grad_norm": 0.007730201818048954,
      "learning_rate": 9.384337349397591e-06,
      "loss": 0.0083,
      "step": 88110
    },
    {
      "epoch": 10.616867469879518,
      "grad_norm": 0.0013143153628334403,
      "learning_rate": 9.383132530120482e-06,
      "loss": 0.0281,
      "step": 88120
    },
    {
      "epoch": 10.618072289156627,
      "grad_norm": 1.8029470443725586,
      "learning_rate": 9.381927710843374e-06,
      "loss": 0.0099,
      "step": 88130
    },
    {
      "epoch": 10.619277108433735,
      "grad_norm": 0.06526273488998413,
      "learning_rate": 9.380722891566267e-06,
      "loss": 0.0246,
      "step": 88140
    },
    {
      "epoch": 10.620481927710843,
      "grad_norm": 5.236423492431641,
      "learning_rate": 9.379518072289158e-06,
      "loss": 0.0096,
      "step": 88150
    },
    {
      "epoch": 10.621686746987951,
      "grad_norm": 0.010841780342161655,
      "learning_rate": 9.378313253012048e-06,
      "loss": 0.0167,
      "step": 88160
    },
    {
      "epoch": 10.62289156626506,
      "grad_norm": 0.001824479317292571,
      "learning_rate": 9.37710843373494e-06,
      "loss": 0.0182,
      "step": 88170
    },
    {
      "epoch": 10.624096385542169,
      "grad_norm": 0.8367753028869629,
      "learning_rate": 9.375903614457832e-06,
      "loss": 0.0763,
      "step": 88180
    },
    {
      "epoch": 10.625301204819277,
      "grad_norm": 0.045508090406656265,
      "learning_rate": 9.374698795180724e-06,
      "loss": 0.0149,
      "step": 88190
    },
    {
      "epoch": 10.626506024096386,
      "grad_norm": 0.13708075881004333,
      "learning_rate": 9.373493975903615e-06,
      "loss": 0.0112,
      "step": 88200
    },
    {
      "epoch": 10.627710843373494,
      "grad_norm": 0.7712725400924683,
      "learning_rate": 9.372289156626507e-06,
      "loss": 0.0253,
      "step": 88210
    },
    {
      "epoch": 10.628915662650602,
      "grad_norm": 5.908411979675293,
      "learning_rate": 9.371084337349398e-06,
      "loss": 0.1,
      "step": 88220
    },
    {
      "epoch": 10.630120481927712,
      "grad_norm": 0.0019411674002185464,
      "learning_rate": 9.36987951807229e-06,
      "loss": 0.0106,
      "step": 88230
    },
    {
      "epoch": 10.63132530120482,
      "grad_norm": 0.004893001634627581,
      "learning_rate": 9.368674698795181e-06,
      "loss": 0.0162,
      "step": 88240
    },
    {
      "epoch": 10.632530120481928,
      "grad_norm": 0.0030529049690812826,
      "learning_rate": 9.367469879518074e-06,
      "loss": 0.0284,
      "step": 88250
    },
    {
      "epoch": 10.633734939759035,
      "grad_norm": 0.0012927339412271976,
      "learning_rate": 9.366265060240964e-06,
      "loss": 0.0275,
      "step": 88260
    },
    {
      "epoch": 10.634939759036145,
      "grad_norm": 0.012088575400412083,
      "learning_rate": 9.365060240963855e-06,
      "loss": 0.0402,
      "step": 88270
    },
    {
      "epoch": 10.636144578313253,
      "grad_norm": 0.0010070662247017026,
      "learning_rate": 9.363855421686747e-06,
      "loss": 0.0382,
      "step": 88280
    },
    {
      "epoch": 10.637349397590361,
      "grad_norm": 0.8517886996269226,
      "learning_rate": 9.36265060240964e-06,
      "loss": 0.049,
      "step": 88290
    },
    {
      "epoch": 10.638554216867469,
      "grad_norm": 9.081379890441895,
      "learning_rate": 9.36144578313253e-06,
      "loss": 0.0651,
      "step": 88300
    },
    {
      "epoch": 10.639759036144579,
      "grad_norm": 0.010465715080499649,
      "learning_rate": 9.360240963855423e-06,
      "loss": 0.0036,
      "step": 88310
    },
    {
      "epoch": 10.640963855421687,
      "grad_norm": 0.1090301126241684,
      "learning_rate": 9.359036144578314e-06,
      "loss": 0.013,
      "step": 88320
    },
    {
      "epoch": 10.642168674698794,
      "grad_norm": 1.739237666130066,
      "learning_rate": 9.357831325301206e-06,
      "loss": 0.0719,
      "step": 88330
    },
    {
      "epoch": 10.643373493975904,
      "grad_norm": 0.007028849329799414,
      "learning_rate": 9.356626506024097e-06,
      "loss": 0.0248,
      "step": 88340
    },
    {
      "epoch": 10.644578313253012,
      "grad_norm": 1.2643595933914185,
      "learning_rate": 9.355421686746988e-06,
      "loss": 0.0331,
      "step": 88350
    },
    {
      "epoch": 10.64578313253012,
      "grad_norm": 0.011755451560020447,
      "learning_rate": 9.35421686746988e-06,
      "loss": 0.0204,
      "step": 88360
    },
    {
      "epoch": 10.64698795180723,
      "grad_norm": 1.2663182020187378,
      "learning_rate": 9.353012048192773e-06,
      "loss": 0.0065,
      "step": 88370
    },
    {
      "epoch": 10.648192771084338,
      "grad_norm": 1.1091744899749756,
      "learning_rate": 9.351807228915663e-06,
      "loss": 0.0534,
      "step": 88380
    },
    {
      "epoch": 10.649397590361446,
      "grad_norm": 2.7478647232055664,
      "learning_rate": 9.350602409638556e-06,
      "loss": 0.0259,
      "step": 88390
    },
    {
      "epoch": 10.650602409638553,
      "grad_norm": 0.0036329396534711123,
      "learning_rate": 9.349397590361446e-06,
      "loss": 0.0116,
      "step": 88400
    },
    {
      "epoch": 10.651807228915663,
      "grad_norm": 0.3844093680381775,
      "learning_rate": 9.348192771084337e-06,
      "loss": 0.0094,
      "step": 88410
    },
    {
      "epoch": 10.653012048192771,
      "grad_norm": 0.0061618490144610405,
      "learning_rate": 9.34698795180723e-06,
      "loss": 0.0081,
      "step": 88420
    },
    {
      "epoch": 10.654216867469879,
      "grad_norm": 2.6874029636383057,
      "learning_rate": 9.34578313253012e-06,
      "loss": 0.0292,
      "step": 88430
    },
    {
      "epoch": 10.655421686746989,
      "grad_norm": 0.007359195034950972,
      "learning_rate": 9.344578313253013e-06,
      "loss": 0.0098,
      "step": 88440
    },
    {
      "epoch": 10.656626506024097,
      "grad_norm": 0.3285294473171234,
      "learning_rate": 9.343373493975905e-06,
      "loss": 0.0265,
      "step": 88450
    },
    {
      "epoch": 10.657831325301204,
      "grad_norm": 0.07420933991670609,
      "learning_rate": 9.342168674698796e-06,
      "loss": 0.0114,
      "step": 88460
    },
    {
      "epoch": 10.659036144578312,
      "grad_norm": 0.003441155655309558,
      "learning_rate": 9.340963855421687e-06,
      "loss": 0.0245,
      "step": 88470
    },
    {
      "epoch": 10.660240963855422,
      "grad_norm": 0.0017128163017332554,
      "learning_rate": 9.33975903614458e-06,
      "loss": 0.0155,
      "step": 88480
    },
    {
      "epoch": 10.66144578313253,
      "grad_norm": 0.35588711500167847,
      "learning_rate": 9.33855421686747e-06,
      "loss": 0.0319,
      "step": 88490
    },
    {
      "epoch": 10.662650602409638,
      "grad_norm": 0.004033596720546484,
      "learning_rate": 9.337349397590362e-06,
      "loss": 0.0447,
      "step": 88500
    },
    {
      "epoch": 10.663855421686748,
      "grad_norm": 1.0119527578353882,
      "learning_rate": 9.336144578313255e-06,
      "loss": 0.033,
      "step": 88510
    },
    {
      "epoch": 10.665060240963856,
      "grad_norm": 0.001315025961957872,
      "learning_rate": 9.334939759036146e-06,
      "loss": 0.014,
      "step": 88520
    },
    {
      "epoch": 10.666265060240963,
      "grad_norm": 0.7902596592903137,
      "learning_rate": 9.333734939759036e-06,
      "loss": 0.0111,
      "step": 88530
    },
    {
      "epoch": 10.667469879518073,
      "grad_norm": 0.001067392178811133,
      "learning_rate": 9.332530120481929e-06,
      "loss": 0.0116,
      "step": 88540
    },
    {
      "epoch": 10.668674698795181,
      "grad_norm": 0.014650175347924232,
      "learning_rate": 9.33132530120482e-06,
      "loss": 0.0127,
      "step": 88550
    },
    {
      "epoch": 10.669879518072289,
      "grad_norm": 4.572880744934082,
      "learning_rate": 9.330120481927712e-06,
      "loss": 0.0226,
      "step": 88560
    },
    {
      "epoch": 10.671084337349397,
      "grad_norm": 0.012019462883472443,
      "learning_rate": 9.328915662650603e-06,
      "loss": 0.0029,
      "step": 88570
    },
    {
      "epoch": 10.672289156626507,
      "grad_norm": 0.011760955676436424,
      "learning_rate": 9.327710843373493e-06,
      "loss": 0.0423,
      "step": 88580
    },
    {
      "epoch": 10.673493975903614,
      "grad_norm": 0.15976983308792114,
      "learning_rate": 9.326506024096388e-06,
      "loss": 0.0054,
      "step": 88590
    },
    {
      "epoch": 10.674698795180722,
      "grad_norm": 2.073361873626709,
      "learning_rate": 9.325301204819278e-06,
      "loss": 0.0403,
      "step": 88600
    },
    {
      "epoch": 10.675903614457832,
      "grad_norm": 0.00136181537527591,
      "learning_rate": 9.324096385542169e-06,
      "loss": 0.0212,
      "step": 88610
    },
    {
      "epoch": 10.67710843373494,
      "grad_norm": 0.00281718373298645,
      "learning_rate": 9.322891566265061e-06,
      "loss": 0.0592,
      "step": 88620
    },
    {
      "epoch": 10.678313253012048,
      "grad_norm": 0.23069176077842712,
      "learning_rate": 9.321686746987952e-06,
      "loss": 0.0163,
      "step": 88630
    },
    {
      "epoch": 10.679518072289156,
      "grad_norm": 11.140181541442871,
      "learning_rate": 9.320481927710845e-06,
      "loss": 0.0265,
      "step": 88640
    },
    {
      "epoch": 10.680722891566266,
      "grad_norm": 0.32437995076179504,
      "learning_rate": 9.319277108433735e-06,
      "loss": 0.0137,
      "step": 88650
    },
    {
      "epoch": 10.681927710843373,
      "grad_norm": 2.682241678237915,
      "learning_rate": 9.318072289156628e-06,
      "loss": 0.0115,
      "step": 88660
    },
    {
      "epoch": 10.683132530120481,
      "grad_norm": 0.13596510887145996,
      "learning_rate": 9.316867469879519e-06,
      "loss": 0.0362,
      "step": 88670
    },
    {
      "epoch": 10.684337349397591,
      "grad_norm": 0.009596755728125572,
      "learning_rate": 9.315662650602411e-06,
      "loss": 0.0112,
      "step": 88680
    },
    {
      "epoch": 10.685542168674699,
      "grad_norm": 0.009840676560997963,
      "learning_rate": 9.314457831325302e-06,
      "loss": 0.018,
      "step": 88690
    },
    {
      "epoch": 10.686746987951807,
      "grad_norm": 0.020402172580361366,
      "learning_rate": 9.313253012048194e-06,
      "loss": 0.0112,
      "step": 88700
    },
    {
      "epoch": 10.687951807228917,
      "grad_norm": 0.813149631023407,
      "learning_rate": 9.312048192771085e-06,
      "loss": 0.0156,
      "step": 88710
    },
    {
      "epoch": 10.689156626506024,
      "grad_norm": 0.818658173084259,
      "learning_rate": 9.310843373493976e-06,
      "loss": 0.0033,
      "step": 88720
    },
    {
      "epoch": 10.690361445783132,
      "grad_norm": 0.006335707847028971,
      "learning_rate": 9.309638554216868e-06,
      "loss": 0.0477,
      "step": 88730
    },
    {
      "epoch": 10.69156626506024,
      "grad_norm": 4.21405029296875,
      "learning_rate": 9.30843373493976e-06,
      "loss": 0.0192,
      "step": 88740
    },
    {
      "epoch": 10.69277108433735,
      "grad_norm": 0.26223692297935486,
      "learning_rate": 9.307228915662651e-06,
      "loss": 0.0143,
      "step": 88750
    },
    {
      "epoch": 10.693975903614458,
      "grad_norm": 0.7817199230194092,
      "learning_rate": 9.306024096385544e-06,
      "loss": 0.0123,
      "step": 88760
    },
    {
      "epoch": 10.695180722891566,
      "grad_norm": 0.005676225293427706,
      "learning_rate": 9.304819277108434e-06,
      "loss": 0.0221,
      "step": 88770
    },
    {
      "epoch": 10.696385542168674,
      "grad_norm": 1.4451239109039307,
      "learning_rate": 9.303614457831325e-06,
      "loss": 0.0164,
      "step": 88780
    },
    {
      "epoch": 10.697590361445783,
      "grad_norm": 0.005855787545442581,
      "learning_rate": 9.302409638554218e-06,
      "loss": 0.0098,
      "step": 88790
    },
    {
      "epoch": 10.698795180722891,
      "grad_norm": 0.011231440119445324,
      "learning_rate": 9.301204819277108e-06,
      "loss": 0.0387,
      "step": 88800
    },
    {
      "epoch": 10.7,
      "grad_norm": 0.051446735858917236,
      "learning_rate": 9.3e-06,
      "loss": 0.014,
      "step": 88810
    },
    {
      "epoch": 10.701204819277109,
      "grad_norm": 0.0061784605495631695,
      "learning_rate": 9.298795180722893e-06,
      "loss": 0.0874,
      "step": 88820
    },
    {
      "epoch": 10.702409638554217,
      "grad_norm": 0.203802689909935,
      "learning_rate": 9.297590361445784e-06,
      "loss": 0.0221,
      "step": 88830
    },
    {
      "epoch": 10.703614457831325,
      "grad_norm": 0.013627479784190655,
      "learning_rate": 9.296385542168675e-06,
      "loss": 0.0212,
      "step": 88840
    },
    {
      "epoch": 10.704819277108435,
      "grad_norm": 1.9025124311447144,
      "learning_rate": 9.295180722891567e-06,
      "loss": 0.0413,
      "step": 88850
    },
    {
      "epoch": 10.706024096385542,
      "grad_norm": 0.7125162482261658,
      "learning_rate": 9.293975903614458e-06,
      "loss": 0.0158,
      "step": 88860
    },
    {
      "epoch": 10.70722891566265,
      "grad_norm": 0.0045876153744757175,
      "learning_rate": 9.29277108433735e-06,
      "loss": 0.0131,
      "step": 88870
    },
    {
      "epoch": 10.708433734939758,
      "grad_norm": 0.6302847266197205,
      "learning_rate": 9.291566265060241e-06,
      "loss": 0.0214,
      "step": 88880
    },
    {
      "epoch": 10.709638554216868,
      "grad_norm": 0.2677948772907257,
      "learning_rate": 9.290361445783133e-06,
      "loss": 0.0109,
      "step": 88890
    },
    {
      "epoch": 10.710843373493976,
      "grad_norm": 0.003868698375299573,
      "learning_rate": 9.289156626506026e-06,
      "loss": 0.0521,
      "step": 88900
    },
    {
      "epoch": 10.712048192771084,
      "grad_norm": 0.2551371157169342,
      "learning_rate": 9.287951807228917e-06,
      "loss": 0.0103,
      "step": 88910
    },
    {
      "epoch": 10.713253012048193,
      "grad_norm": 0.38862115144729614,
      "learning_rate": 9.286746987951807e-06,
      "loss": 0.0104,
      "step": 88920
    },
    {
      "epoch": 10.714457831325301,
      "grad_norm": 0.06164885684847832,
      "learning_rate": 9.2855421686747e-06,
      "loss": 0.0228,
      "step": 88930
    },
    {
      "epoch": 10.71566265060241,
      "grad_norm": 0.3371511399745941,
      "learning_rate": 9.28433734939759e-06,
      "loss": 0.0366,
      "step": 88940
    },
    {
      "epoch": 10.716867469879517,
      "grad_norm": 0.8296675086021423,
      "learning_rate": 9.283132530120483e-06,
      "loss": 0.0085,
      "step": 88950
    },
    {
      "epoch": 10.718072289156627,
      "grad_norm": 1.2410547733306885,
      "learning_rate": 9.281927710843375e-06,
      "loss": 0.0271,
      "step": 88960
    },
    {
      "epoch": 10.719277108433735,
      "grad_norm": 0.0032347296364605427,
      "learning_rate": 9.280722891566266e-06,
      "loss": 0.007,
      "step": 88970
    },
    {
      "epoch": 10.720481927710843,
      "grad_norm": 0.003881132462993264,
      "learning_rate": 9.279518072289157e-06,
      "loss": 0.032,
      "step": 88980
    },
    {
      "epoch": 10.721686746987952,
      "grad_norm": 0.026313241571187973,
      "learning_rate": 9.27831325301205e-06,
      "loss": 0.0297,
      "step": 88990
    },
    {
      "epoch": 10.72289156626506,
      "grad_norm": 0.0037730259355157614,
      "learning_rate": 9.27710843373494e-06,
      "loss": 0.0127,
      "step": 89000
    },
    {
      "epoch": 10.724096385542168,
      "grad_norm": 0.8580578565597534,
      "learning_rate": 9.275903614457833e-06,
      "loss": 0.018,
      "step": 89010
    },
    {
      "epoch": 10.725301204819278,
      "grad_norm": 0.48303085565567017,
      "learning_rate": 9.274698795180723e-06,
      "loss": 0.0159,
      "step": 89020
    },
    {
      "epoch": 10.726506024096386,
      "grad_norm": 0.46073117852211,
      "learning_rate": 9.273493975903614e-06,
      "loss": 0.0082,
      "step": 89030
    },
    {
      "epoch": 10.727710843373494,
      "grad_norm": 0.005673746112734079,
      "learning_rate": 9.272289156626506e-06,
      "loss": 0.0211,
      "step": 89040
    },
    {
      "epoch": 10.728915662650602,
      "grad_norm": 1.43674898147583,
      "learning_rate": 9.271084337349399e-06,
      "loss": 0.0234,
      "step": 89050
    },
    {
      "epoch": 10.730120481927711,
      "grad_norm": 0.0012040305882692337,
      "learning_rate": 9.26987951807229e-06,
      "loss": 0.0298,
      "step": 89060
    },
    {
      "epoch": 10.73132530120482,
      "grad_norm": 0.001635763910599053,
      "learning_rate": 9.268674698795182e-06,
      "loss": 0.0508,
      "step": 89070
    },
    {
      "epoch": 10.732530120481927,
      "grad_norm": 0.009885692968964577,
      "learning_rate": 9.267469879518073e-06,
      "loss": 0.0291,
      "step": 89080
    },
    {
      "epoch": 10.733734939759037,
      "grad_norm": 0.005210378207266331,
      "learning_rate": 9.266265060240964e-06,
      "loss": 0.0505,
      "step": 89090
    },
    {
      "epoch": 10.734939759036145,
      "grad_norm": 1.911465048789978,
      "learning_rate": 9.265060240963856e-06,
      "loss": 0.0114,
      "step": 89100
    },
    {
      "epoch": 10.736144578313253,
      "grad_norm": 3.052168369293213,
      "learning_rate": 9.263855421686748e-06,
      "loss": 0.0199,
      "step": 89110
    },
    {
      "epoch": 10.73734939759036,
      "grad_norm": 1.2458223104476929,
      "learning_rate": 9.262650602409639e-06,
      "loss": 0.024,
      "step": 89120
    },
    {
      "epoch": 10.73855421686747,
      "grad_norm": 0.9826155304908752,
      "learning_rate": 9.261445783132532e-06,
      "loss": 0.0128,
      "step": 89130
    },
    {
      "epoch": 10.739759036144578,
      "grad_norm": 1.1155470609664917,
      "learning_rate": 9.260240963855422e-06,
      "loss": 0.0256,
      "step": 89140
    },
    {
      "epoch": 10.740963855421686,
      "grad_norm": 0.7673108577728271,
      "learning_rate": 9.259036144578315e-06,
      "loss": 0.0282,
      "step": 89150
    },
    {
      "epoch": 10.742168674698796,
      "grad_norm": 0.007148899137973785,
      "learning_rate": 9.257831325301205e-06,
      "loss": 0.035,
      "step": 89160
    },
    {
      "epoch": 10.743373493975904,
      "grad_norm": 0.023703865706920624,
      "learning_rate": 9.256626506024096e-06,
      "loss": 0.04,
      "step": 89170
    },
    {
      "epoch": 10.744578313253012,
      "grad_norm": 0.8318907618522644,
      "learning_rate": 9.255421686746989e-06,
      "loss": 0.0513,
      "step": 89180
    },
    {
      "epoch": 10.745783132530121,
      "grad_norm": 0.01197909191250801,
      "learning_rate": 9.254216867469881e-06,
      "loss": 0.0166,
      "step": 89190
    },
    {
      "epoch": 10.74698795180723,
      "grad_norm": 0.04943045973777771,
      "learning_rate": 9.253012048192772e-06,
      "loss": 0.0157,
      "step": 89200
    },
    {
      "epoch": 10.748192771084337,
      "grad_norm": 2.066506862640381,
      "learning_rate": 9.251807228915664e-06,
      "loss": 0.0189,
      "step": 89210
    },
    {
      "epoch": 10.749397590361445,
      "grad_norm": 7.370255470275879,
      "learning_rate": 9.250602409638555e-06,
      "loss": 0.0259,
      "step": 89220
    },
    {
      "epoch": 10.750602409638555,
      "grad_norm": 0.003251732559874654,
      "learning_rate": 9.249397590361446e-06,
      "loss": 0.0234,
      "step": 89230
    },
    {
      "epoch": 10.751807228915663,
      "grad_norm": 0.3705301582813263,
      "learning_rate": 9.248192771084338e-06,
      "loss": 0.0164,
      "step": 89240
    },
    {
      "epoch": 10.75301204819277,
      "grad_norm": 2.5261332988739014,
      "learning_rate": 9.246987951807229e-06,
      "loss": 0.0309,
      "step": 89250
    },
    {
      "epoch": 10.754216867469879,
      "grad_norm": 0.001779588172212243,
      "learning_rate": 9.245783132530121e-06,
      "loss": 0.0134,
      "step": 89260
    },
    {
      "epoch": 10.755421686746988,
      "grad_norm": 0.00158396502956748,
      "learning_rate": 9.244578313253014e-06,
      "loss": 0.0657,
      "step": 89270
    },
    {
      "epoch": 10.756626506024096,
      "grad_norm": 6.234491348266602,
      "learning_rate": 9.243373493975905e-06,
      "loss": 0.0445,
      "step": 89280
    },
    {
      "epoch": 10.757831325301204,
      "grad_norm": 1.0535492897033691,
      "learning_rate": 9.242168674698795e-06,
      "loss": 0.014,
      "step": 89290
    },
    {
      "epoch": 10.759036144578314,
      "grad_norm": 0.001456908299587667,
      "learning_rate": 9.240963855421688e-06,
      "loss": 0.015,
      "step": 89300
    },
    {
      "epoch": 10.760240963855422,
      "grad_norm": 0.0025642672553658485,
      "learning_rate": 9.239759036144578e-06,
      "loss": 0.0207,
      "step": 89310
    },
    {
      "epoch": 10.76144578313253,
      "grad_norm": 1.026329755783081,
      "learning_rate": 9.238554216867471e-06,
      "loss": 0.0166,
      "step": 89320
    },
    {
      "epoch": 10.76265060240964,
      "grad_norm": 0.002170001622289419,
      "learning_rate": 9.237349397590363e-06,
      "loss": 0.0192,
      "step": 89330
    },
    {
      "epoch": 10.763855421686747,
      "grad_norm": 1.1542487144470215,
      "learning_rate": 9.236144578313254e-06,
      "loss": 0.03,
      "step": 89340
    },
    {
      "epoch": 10.765060240963855,
      "grad_norm": 0.1654006987810135,
      "learning_rate": 9.234939759036145e-06,
      "loss": 0.0206,
      "step": 89350
    },
    {
      "epoch": 10.766265060240963,
      "grad_norm": 0.0009255005279555917,
      "learning_rate": 9.233734939759037e-06,
      "loss": 0.0029,
      "step": 89360
    },
    {
      "epoch": 10.767469879518073,
      "grad_norm": 0.009051994420588017,
      "learning_rate": 9.232530120481928e-06,
      "loss": 0.0026,
      "step": 89370
    },
    {
      "epoch": 10.76867469879518,
      "grad_norm": 0.0021051408257335424,
      "learning_rate": 9.23132530120482e-06,
      "loss": 0.0085,
      "step": 89380
    },
    {
      "epoch": 10.769879518072289,
      "grad_norm": 0.00454447278752923,
      "learning_rate": 9.230120481927711e-06,
      "loss": 0.0114,
      "step": 89390
    },
    {
      "epoch": 10.771084337349398,
      "grad_norm": 0.977173388004303,
      "learning_rate": 9.228915662650602e-06,
      "loss": 0.0146,
      "step": 89400
    },
    {
      "epoch": 10.772289156626506,
      "grad_norm": 3.6817941665649414,
      "learning_rate": 9.227710843373496e-06,
      "loss": 0.0577,
      "step": 89410
    },
    {
      "epoch": 10.773493975903614,
      "grad_norm": 0.01934860832989216,
      "learning_rate": 9.226506024096387e-06,
      "loss": 0.0066,
      "step": 89420
    },
    {
      "epoch": 10.774698795180722,
      "grad_norm": 0.0136078130453825,
      "learning_rate": 9.225301204819278e-06,
      "loss": 0.0305,
      "step": 89430
    },
    {
      "epoch": 10.775903614457832,
      "grad_norm": 3.7427022457122803,
      "learning_rate": 9.22409638554217e-06,
      "loss": 0.064,
      "step": 89440
    },
    {
      "epoch": 10.77710843373494,
      "grad_norm": 4.4590654373168945,
      "learning_rate": 9.22289156626506e-06,
      "loss": 0.0469,
      "step": 89450
    },
    {
      "epoch": 10.778313253012048,
      "grad_norm": 0.9605194330215454,
      "learning_rate": 9.221686746987953e-06,
      "loss": 0.0349,
      "step": 89460
    },
    {
      "epoch": 10.779518072289157,
      "grad_norm": 1.0444645881652832,
      "learning_rate": 9.220481927710844e-06,
      "loss": 0.0107,
      "step": 89470
    },
    {
      "epoch": 10.780722891566265,
      "grad_norm": 7.276084899902344,
      "learning_rate": 9.219277108433736e-06,
      "loss": 0.028,
      "step": 89480
    },
    {
      "epoch": 10.781927710843373,
      "grad_norm": 0.2407771795988083,
      "learning_rate": 9.218072289156627e-06,
      "loss": 0.0268,
      "step": 89490
    },
    {
      "epoch": 10.783132530120483,
      "grad_norm": 0.05113689973950386,
      "learning_rate": 9.21686746987952e-06,
      "loss": 0.0099,
      "step": 89500
    },
    {
      "epoch": 10.78433734939759,
      "grad_norm": 0.0032928730361163616,
      "learning_rate": 9.21566265060241e-06,
      "loss": 0.0163,
      "step": 89510
    },
    {
      "epoch": 10.785542168674699,
      "grad_norm": 0.013476762920618057,
      "learning_rate": 9.214457831325303e-06,
      "loss": 0.0587,
      "step": 89520
    },
    {
      "epoch": 10.786746987951807,
      "grad_norm": 0.020533086732029915,
      "learning_rate": 9.213253012048193e-06,
      "loss": 0.0333,
      "step": 89530
    },
    {
      "epoch": 10.787951807228916,
      "grad_norm": 0.0853516012430191,
      "learning_rate": 9.212048192771084e-06,
      "loss": 0.0169,
      "step": 89540
    },
    {
      "epoch": 10.789156626506024,
      "grad_norm": 5.359842300415039,
      "learning_rate": 9.210843373493977e-06,
      "loss": 0.0092,
      "step": 89550
    },
    {
      "epoch": 10.790361445783132,
      "grad_norm": 0.48120567202568054,
      "learning_rate": 9.209638554216869e-06,
      "loss": 0.0444,
      "step": 89560
    },
    {
      "epoch": 10.791566265060242,
      "grad_norm": 1.342819333076477,
      "learning_rate": 9.20843373493976e-06,
      "loss": 0.0366,
      "step": 89570
    },
    {
      "epoch": 10.79277108433735,
      "grad_norm": 0.018764721229672432,
      "learning_rate": 9.207228915662652e-06,
      "loss": 0.0008,
      "step": 89580
    },
    {
      "epoch": 10.793975903614458,
      "grad_norm": 0.12592951953411102,
      "learning_rate": 9.206024096385543e-06,
      "loss": 0.0308,
      "step": 89590
    },
    {
      "epoch": 10.795180722891565,
      "grad_norm": 0.9640488624572754,
      "learning_rate": 9.204819277108434e-06,
      "loss": 0.0239,
      "step": 89600
    },
    {
      "epoch": 10.796385542168675,
      "grad_norm": 6.781364917755127,
      "learning_rate": 9.203614457831326e-06,
      "loss": 0.0389,
      "step": 89610
    },
    {
      "epoch": 10.797590361445783,
      "grad_norm": 3.3943214416503906,
      "learning_rate": 9.202409638554217e-06,
      "loss": 0.0276,
      "step": 89620
    },
    {
      "epoch": 10.798795180722891,
      "grad_norm": 1.2351248264312744,
      "learning_rate": 9.20120481927711e-06,
      "loss": 0.0439,
      "step": 89630
    },
    {
      "epoch": 10.8,
      "grad_norm": 0.826411247253418,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0223,
      "step": 89640
    },
    {
      "epoch": 10.801204819277109,
      "grad_norm": 0.47177448868751526,
      "learning_rate": 9.198795180722892e-06,
      "loss": 0.0167,
      "step": 89650
    },
    {
      "epoch": 10.802409638554217,
      "grad_norm": 2.3576738834381104,
      "learning_rate": 9.197590361445783e-06,
      "loss": 0.045,
      "step": 89660
    },
    {
      "epoch": 10.803614457831326,
      "grad_norm": 0.0055619473569095135,
      "learning_rate": 9.196385542168676e-06,
      "loss": 0.0229,
      "step": 89670
    },
    {
      "epoch": 10.804819277108434,
      "grad_norm": 0.2780553698539734,
      "learning_rate": 9.195180722891566e-06,
      "loss": 0.0079,
      "step": 89680
    },
    {
      "epoch": 10.806024096385542,
      "grad_norm": 0.015474021434783936,
      "learning_rate": 9.193975903614459e-06,
      "loss": 0.0448,
      "step": 89690
    },
    {
      "epoch": 10.80722891566265,
      "grad_norm": 0.017312077805399895,
      "learning_rate": 9.19277108433735e-06,
      "loss": 0.0558,
      "step": 89700
    },
    {
      "epoch": 10.80843373493976,
      "grad_norm": 1.4393024444580078,
      "learning_rate": 9.191566265060242e-06,
      "loss": 0.0221,
      "step": 89710
    },
    {
      "epoch": 10.809638554216868,
      "grad_norm": 0.016466716304421425,
      "learning_rate": 9.190361445783134e-06,
      "loss": 0.0528,
      "step": 89720
    },
    {
      "epoch": 10.810843373493976,
      "grad_norm": 0.9038629531860352,
      "learning_rate": 9.189156626506025e-06,
      "loss": 0.0163,
      "step": 89730
    },
    {
      "epoch": 10.812048192771083,
      "grad_norm": 1.2173818349838257,
      "learning_rate": 9.187951807228916e-06,
      "loss": 0.0245,
      "step": 89740
    },
    {
      "epoch": 10.813253012048193,
      "grad_norm": 0.48697206377983093,
      "learning_rate": 9.186746987951808e-06,
      "loss": 0.0278,
      "step": 89750
    },
    {
      "epoch": 10.814457831325301,
      "grad_norm": 0.014831624925136566,
      "learning_rate": 9.185542168674699e-06,
      "loss": 0.0069,
      "step": 89760
    },
    {
      "epoch": 10.815662650602409,
      "grad_norm": 1.0803461074829102,
      "learning_rate": 9.184337349397591e-06,
      "loss": 0.0141,
      "step": 89770
    },
    {
      "epoch": 10.816867469879519,
      "grad_norm": 0.30010440945625305,
      "learning_rate": 9.183132530120484e-06,
      "loss": 0.0339,
      "step": 89780
    },
    {
      "epoch": 10.818072289156627,
      "grad_norm": 0.47090470790863037,
      "learning_rate": 9.181927710843375e-06,
      "loss": 0.0096,
      "step": 89790
    },
    {
      "epoch": 10.819277108433734,
      "grad_norm": 0.0006628375267609954,
      "learning_rate": 9.180722891566265e-06,
      "loss": 0.0085,
      "step": 89800
    },
    {
      "epoch": 10.820481927710844,
      "grad_norm": 0.0027912503574043512,
      "learning_rate": 9.179518072289158e-06,
      "loss": 0.0595,
      "step": 89810
    },
    {
      "epoch": 10.821686746987952,
      "grad_norm": 0.00422273576259613,
      "learning_rate": 9.178313253012049e-06,
      "loss": 0.0233,
      "step": 89820
    },
    {
      "epoch": 10.82289156626506,
      "grad_norm": 0.014185290783643723,
      "learning_rate": 9.177108433734941e-06,
      "loss": 0.0051,
      "step": 89830
    },
    {
      "epoch": 10.824096385542168,
      "grad_norm": 0.25685352087020874,
      "learning_rate": 9.175903614457832e-06,
      "loss": 0.0494,
      "step": 89840
    },
    {
      "epoch": 10.825301204819278,
      "grad_norm": 0.004233398009091616,
      "learning_rate": 9.174698795180723e-06,
      "loss": 0.0129,
      "step": 89850
    },
    {
      "epoch": 10.826506024096386,
      "grad_norm": 0.0012864646269008517,
      "learning_rate": 9.173493975903615e-06,
      "loss": 0.0042,
      "step": 89860
    },
    {
      "epoch": 10.827710843373493,
      "grad_norm": 1.4963855743408203,
      "learning_rate": 9.172289156626507e-06,
      "loss": 0.032,
      "step": 89870
    },
    {
      "epoch": 10.828915662650603,
      "grad_norm": 8.722603797912598,
      "learning_rate": 9.171084337349398e-06,
      "loss": 0.0355,
      "step": 89880
    },
    {
      "epoch": 10.830120481927711,
      "grad_norm": 0.5617849230766296,
      "learning_rate": 9.16987951807229e-06,
      "loss": 0.0223,
      "step": 89890
    },
    {
      "epoch": 10.831325301204819,
      "grad_norm": 1.7123668193817139,
      "learning_rate": 9.168674698795181e-06,
      "loss": 0.0122,
      "step": 89900
    },
    {
      "epoch": 10.832530120481927,
      "grad_norm": 10.23994255065918,
      "learning_rate": 9.167469879518072e-06,
      "loss": 0.0287,
      "step": 89910
    },
    {
      "epoch": 10.833734939759037,
      "grad_norm": 0.0041035753674805164,
      "learning_rate": 9.166265060240964e-06,
      "loss": 0.0289,
      "step": 89920
    },
    {
      "epoch": 10.834939759036144,
      "grad_norm": 0.0012296936474740505,
      "learning_rate": 9.165060240963857e-06,
      "loss": 0.029,
      "step": 89930
    },
    {
      "epoch": 10.836144578313252,
      "grad_norm": 1.9937382936477661,
      "learning_rate": 9.163855421686748e-06,
      "loss": 0.0304,
      "step": 89940
    },
    {
      "epoch": 10.837349397590362,
      "grad_norm": 1.8937573432922363,
      "learning_rate": 9.16265060240964e-06,
      "loss": 0.0068,
      "step": 89950
    },
    {
      "epoch": 10.83855421686747,
      "grad_norm": 2.649207353591919,
      "learning_rate": 9.16144578313253e-06,
      "loss": 0.0267,
      "step": 89960
    },
    {
      "epoch": 10.839759036144578,
      "grad_norm": 0.0023155801463872194,
      "learning_rate": 9.160240963855422e-06,
      "loss": 0.0423,
      "step": 89970
    },
    {
      "epoch": 10.840963855421688,
      "grad_norm": 0.009446417912840843,
      "learning_rate": 9.159036144578314e-06,
      "loss": 0.0253,
      "step": 89980
    },
    {
      "epoch": 10.842168674698796,
      "grad_norm": 0.6204063892364502,
      "learning_rate": 9.157831325301205e-06,
      "loss": 0.0259,
      "step": 89990
    },
    {
      "epoch": 10.843373493975903,
      "grad_norm": 0.9395096302032471,
      "learning_rate": 9.156626506024097e-06,
      "loss": 0.0133,
      "step": 90000
    },
    {
      "epoch": 10.844578313253011,
      "grad_norm": 0.002481696894392371,
      "learning_rate": 9.15542168674699e-06,
      "loss": 0.036,
      "step": 90010
    },
    {
      "epoch": 10.845783132530121,
      "grad_norm": 0.5513846278190613,
      "learning_rate": 9.15421686746988e-06,
      "loss": 0.0159,
      "step": 90020
    },
    {
      "epoch": 10.846987951807229,
      "grad_norm": 0.19519533216953278,
      "learning_rate": 9.153012048192773e-06,
      "loss": 0.0127,
      "step": 90030
    },
    {
      "epoch": 10.848192771084337,
      "grad_norm": 0.0011443312978371978,
      "learning_rate": 9.151807228915664e-06,
      "loss": 0.0416,
      "step": 90040
    },
    {
      "epoch": 10.849397590361447,
      "grad_norm": 0.46564456820487976,
      "learning_rate": 9.150602409638554e-06,
      "loss": 0.0139,
      "step": 90050
    },
    {
      "epoch": 10.850602409638554,
      "grad_norm": 0.7307519912719727,
      "learning_rate": 9.149397590361447e-06,
      "loss": 0.0695,
      "step": 90060
    },
    {
      "epoch": 10.851807228915662,
      "grad_norm": 0.04735061153769493,
      "learning_rate": 9.148192771084337e-06,
      "loss": 0.0178,
      "step": 90070
    },
    {
      "epoch": 10.85301204819277,
      "grad_norm": 0.004193732514977455,
      "learning_rate": 9.14698795180723e-06,
      "loss": 0.0236,
      "step": 90080
    },
    {
      "epoch": 10.85421686746988,
      "grad_norm": 3.778129816055298,
      "learning_rate": 9.145783132530122e-06,
      "loss": 0.0581,
      "step": 90090
    },
    {
      "epoch": 10.855421686746988,
      "grad_norm": 0.06282683461904526,
      "learning_rate": 9.144578313253013e-06,
      "loss": 0.0226,
      "step": 90100
    },
    {
      "epoch": 10.856626506024096,
      "grad_norm": 0.000806749623734504,
      "learning_rate": 9.143373493975904e-06,
      "loss": 0.0056,
      "step": 90110
    },
    {
      "epoch": 10.857831325301206,
      "grad_norm": 23.560998916625977,
      "learning_rate": 9.142168674698796e-06,
      "loss": 0.047,
      "step": 90120
    },
    {
      "epoch": 10.859036144578313,
      "grad_norm": 0.34023022651672363,
      "learning_rate": 9.140963855421687e-06,
      "loss": 0.0417,
      "step": 90130
    },
    {
      "epoch": 10.860240963855421,
      "grad_norm": 1.3242120742797852,
      "learning_rate": 9.13975903614458e-06,
      "loss": 0.0056,
      "step": 90140
    },
    {
      "epoch": 10.861445783132531,
      "grad_norm": 0.005428996402770281,
      "learning_rate": 9.13855421686747e-06,
      "loss": 0.0414,
      "step": 90150
    },
    {
      "epoch": 10.862650602409639,
      "grad_norm": 4.797403812408447,
      "learning_rate": 9.137349397590363e-06,
      "loss": 0.0377,
      "step": 90160
    },
    {
      "epoch": 10.863855421686747,
      "grad_norm": 0.013572527095675468,
      "learning_rate": 9.136144578313253e-06,
      "loss": 0.0178,
      "step": 90170
    },
    {
      "epoch": 10.865060240963855,
      "grad_norm": 1.6263675689697266,
      "learning_rate": 9.134939759036146e-06,
      "loss": 0.0204,
      "step": 90180
    },
    {
      "epoch": 10.866265060240965,
      "grad_norm": 1.0337005853652954,
      "learning_rate": 9.133734939759037e-06,
      "loss": 0.0252,
      "step": 90190
    },
    {
      "epoch": 10.867469879518072,
      "grad_norm": 0.002141278702765703,
      "learning_rate": 9.132530120481929e-06,
      "loss": 0.0097,
      "step": 90200
    },
    {
      "epoch": 10.86867469879518,
      "grad_norm": 0.9923718571662903,
      "learning_rate": 9.13132530120482e-06,
      "loss": 0.0421,
      "step": 90210
    },
    {
      "epoch": 10.869879518072288,
      "grad_norm": 0.002909152302891016,
      "learning_rate": 9.13012048192771e-06,
      "loss": 0.014,
      "step": 90220
    },
    {
      "epoch": 10.871084337349398,
      "grad_norm": 0.4621809720993042,
      "learning_rate": 9.128915662650603e-06,
      "loss": 0.0052,
      "step": 90230
    },
    {
      "epoch": 10.872289156626506,
      "grad_norm": 0.4293806552886963,
      "learning_rate": 9.127710843373495e-06,
      "loss": 0.0079,
      "step": 90240
    },
    {
      "epoch": 10.873493975903614,
      "grad_norm": 0.3972163200378418,
      "learning_rate": 9.126506024096386e-06,
      "loss": 0.0147,
      "step": 90250
    },
    {
      "epoch": 10.874698795180723,
      "grad_norm": 5.980468273162842,
      "learning_rate": 9.125301204819278e-06,
      "loss": 0.0349,
      "step": 90260
    },
    {
      "epoch": 10.875903614457831,
      "grad_norm": 0.33667340874671936,
      "learning_rate": 9.12409638554217e-06,
      "loss": 0.0093,
      "step": 90270
    },
    {
      "epoch": 10.87710843373494,
      "grad_norm": 0.0033107527997344732,
      "learning_rate": 9.12289156626506e-06,
      "loss": 0.0246,
      "step": 90280
    },
    {
      "epoch": 10.878313253012049,
      "grad_norm": 0.0007451941492035985,
      "learning_rate": 9.121686746987952e-06,
      "loss": 0.0215,
      "step": 90290
    },
    {
      "epoch": 10.879518072289157,
      "grad_norm": 0.1443791687488556,
      "learning_rate": 9.120481927710843e-06,
      "loss": 0.008,
      "step": 90300
    },
    {
      "epoch": 10.880722891566265,
      "grad_norm": 1.4640939235687256,
      "learning_rate": 9.119277108433736e-06,
      "loss": 0.0637,
      "step": 90310
    },
    {
      "epoch": 10.881927710843373,
      "grad_norm": 0.5397162437438965,
      "learning_rate": 9.118072289156628e-06,
      "loss": 0.0314,
      "step": 90320
    },
    {
      "epoch": 10.883132530120482,
      "grad_norm": 0.0020800617057830095,
      "learning_rate": 9.116867469879519e-06,
      "loss": 0.0077,
      "step": 90330
    },
    {
      "epoch": 10.88433734939759,
      "grad_norm": 0.034913014620542526,
      "learning_rate": 9.115662650602411e-06,
      "loss": 0.0267,
      "step": 90340
    },
    {
      "epoch": 10.885542168674698,
      "grad_norm": 2.5812718868255615,
      "learning_rate": 9.114457831325302e-06,
      "loss": 0.0773,
      "step": 90350
    },
    {
      "epoch": 10.886746987951808,
      "grad_norm": 10.321459770202637,
      "learning_rate": 9.113253012048193e-06,
      "loss": 0.0202,
      "step": 90360
    },
    {
      "epoch": 10.887951807228916,
      "grad_norm": 1.214523434638977,
      "learning_rate": 9.112048192771085e-06,
      "loss": 0.0114,
      "step": 90370
    },
    {
      "epoch": 10.889156626506024,
      "grad_norm": 0.012754482217133045,
      "learning_rate": 9.110843373493978e-06,
      "loss": 0.0269,
      "step": 90380
    },
    {
      "epoch": 10.890361445783132,
      "grad_norm": 0.003312565153464675,
      "learning_rate": 9.109638554216868e-06,
      "loss": 0.014,
      "step": 90390
    },
    {
      "epoch": 10.891566265060241,
      "grad_norm": 0.03127598389983177,
      "learning_rate": 9.10843373493976e-06,
      "loss": 0.0045,
      "step": 90400
    },
    {
      "epoch": 10.89277108433735,
      "grad_norm": 0.005830956157296896,
      "learning_rate": 9.107228915662651e-06,
      "loss": 0.0206,
      "step": 90410
    },
    {
      "epoch": 10.893975903614457,
      "grad_norm": 0.002701143966987729,
      "learning_rate": 9.106024096385542e-06,
      "loss": 0.0079,
      "step": 90420
    },
    {
      "epoch": 10.895180722891567,
      "grad_norm": 0.0032158363610506058,
      "learning_rate": 9.104819277108435e-06,
      "loss": 0.0203,
      "step": 90430
    },
    {
      "epoch": 10.896385542168675,
      "grad_norm": 0.024953089654445648,
      "learning_rate": 9.103614457831325e-06,
      "loss": 0.0138,
      "step": 90440
    },
    {
      "epoch": 10.897590361445783,
      "grad_norm": 3.832186222076416,
      "learning_rate": 9.102409638554218e-06,
      "loss": 0.0247,
      "step": 90450
    },
    {
      "epoch": 10.898795180722892,
      "grad_norm": 0.20850026607513428,
      "learning_rate": 9.10120481927711e-06,
      "loss": 0.0192,
      "step": 90460
    },
    {
      "epoch": 10.9,
      "grad_norm": 0.031404562294483185,
      "learning_rate": 9.100000000000001e-06,
      "loss": 0.0329,
      "step": 90470
    },
    {
      "epoch": 10.901204819277108,
      "grad_norm": 0.0014413610333576798,
      "learning_rate": 9.098795180722892e-06,
      "loss": 0.0118,
      "step": 90480
    },
    {
      "epoch": 10.902409638554216,
      "grad_norm": 0.1438933163881302,
      "learning_rate": 9.097590361445784e-06,
      "loss": 0.0182,
      "step": 90490
    },
    {
      "epoch": 10.903614457831326,
      "grad_norm": 0.001350895268842578,
      "learning_rate": 9.096385542168675e-06,
      "loss": 0.0112,
      "step": 90500
    },
    {
      "epoch": 10.904819277108434,
      "grad_norm": 0.2783564627170563,
      "learning_rate": 9.095180722891567e-06,
      "loss": 0.0437,
      "step": 90510
    },
    {
      "epoch": 10.906024096385542,
      "grad_norm": 0.004913631826639175,
      "learning_rate": 9.093975903614458e-06,
      "loss": 0.0009,
      "step": 90520
    },
    {
      "epoch": 10.907228915662651,
      "grad_norm": 0.0013177493819966912,
      "learning_rate": 9.09277108433735e-06,
      "loss": 0.0047,
      "step": 90530
    },
    {
      "epoch": 10.90843373493976,
      "grad_norm": 5.318357467651367,
      "learning_rate": 9.091566265060243e-06,
      "loss": 0.0287,
      "step": 90540
    },
    {
      "epoch": 10.909638554216867,
      "grad_norm": 0.007502824533730745,
      "learning_rate": 9.090361445783134e-06,
      "loss": 0.0399,
      "step": 90550
    },
    {
      "epoch": 10.910843373493975,
      "grad_norm": 0.03521230071783066,
      "learning_rate": 9.089156626506024e-06,
      "loss": 0.005,
      "step": 90560
    },
    {
      "epoch": 10.912048192771085,
      "grad_norm": 3.577883720397949,
      "learning_rate": 9.087951807228917e-06,
      "loss": 0.0589,
      "step": 90570
    },
    {
      "epoch": 10.913253012048193,
      "grad_norm": 0.5983902812004089,
      "learning_rate": 9.086746987951808e-06,
      "loss": 0.0315,
      "step": 90580
    },
    {
      "epoch": 10.9144578313253,
      "grad_norm": 0.013748817145824432,
      "learning_rate": 9.0855421686747e-06,
      "loss": 0.0169,
      "step": 90590
    },
    {
      "epoch": 10.91566265060241,
      "grad_norm": 0.09633522480726242,
      "learning_rate": 9.08433734939759e-06,
      "loss": 0.0344,
      "step": 90600
    },
    {
      "epoch": 10.916867469879518,
      "grad_norm": 0.0015919762663543224,
      "learning_rate": 9.083132530120483e-06,
      "loss": 0.0368,
      "step": 90610
    },
    {
      "epoch": 10.918072289156626,
      "grad_norm": 0.003665127092972398,
      "learning_rate": 9.081927710843374e-06,
      "loss": 0.0112,
      "step": 90620
    },
    {
      "epoch": 10.919277108433734,
      "grad_norm": 0.1150977835059166,
      "learning_rate": 9.080722891566266e-06,
      "loss": 0.0093,
      "step": 90630
    },
    {
      "epoch": 10.920481927710844,
      "grad_norm": 1.1192492246627808,
      "learning_rate": 9.079518072289157e-06,
      "loss": 0.0761,
      "step": 90640
    },
    {
      "epoch": 10.921686746987952,
      "grad_norm": 0.8290081024169922,
      "learning_rate": 9.07831325301205e-06,
      "loss": 0.0138,
      "step": 90650
    },
    {
      "epoch": 10.92289156626506,
      "grad_norm": 0.0025951790157705545,
      "learning_rate": 9.07710843373494e-06,
      "loss": 0.0036,
      "step": 90660
    },
    {
      "epoch": 10.92409638554217,
      "grad_norm": 1.8431483507156372,
      "learning_rate": 9.075903614457831e-06,
      "loss": 0.0104,
      "step": 90670
    },
    {
      "epoch": 10.925301204819277,
      "grad_norm": 2.964766502380371,
      "learning_rate": 9.074698795180723e-06,
      "loss": 0.0354,
      "step": 90680
    },
    {
      "epoch": 10.926506024096385,
      "grad_norm": 0.7523197531700134,
      "learning_rate": 9.073493975903616e-06,
      "loss": 0.0286,
      "step": 90690
    },
    {
      "epoch": 10.927710843373493,
      "grad_norm": 0.00376073713414371,
      "learning_rate": 9.072289156626507e-06,
      "loss": 0.0487,
      "step": 90700
    },
    {
      "epoch": 10.928915662650603,
      "grad_norm": 1.628214716911316,
      "learning_rate": 9.071084337349399e-06,
      "loss": 0.0205,
      "step": 90710
    },
    {
      "epoch": 10.93012048192771,
      "grad_norm": 0.18352840840816498,
      "learning_rate": 9.06987951807229e-06,
      "loss": 0.0269,
      "step": 90720
    },
    {
      "epoch": 10.931325301204819,
      "grad_norm": 0.03916030749678612,
      "learning_rate": 9.06867469879518e-06,
      "loss": 0.0067,
      "step": 90730
    },
    {
      "epoch": 10.932530120481928,
      "grad_norm": 0.009053432382643223,
      "learning_rate": 9.067469879518073e-06,
      "loss": 0.0026,
      "step": 90740
    },
    {
      "epoch": 10.933734939759036,
      "grad_norm": 0.5097886919975281,
      "learning_rate": 9.066265060240964e-06,
      "loss": 0.0352,
      "step": 90750
    },
    {
      "epoch": 10.934939759036144,
      "grad_norm": 0.06355507671833038,
      "learning_rate": 9.065060240963856e-06,
      "loss": 0.0226,
      "step": 90760
    },
    {
      "epoch": 10.936144578313254,
      "grad_norm": 0.007742846850305796,
      "learning_rate": 9.063855421686749e-06,
      "loss": 0.0073,
      "step": 90770
    },
    {
      "epoch": 10.937349397590362,
      "grad_norm": 0.04718479886651039,
      "learning_rate": 9.06265060240964e-06,
      "loss": 0.0184,
      "step": 90780
    },
    {
      "epoch": 10.93855421686747,
      "grad_norm": 0.007796695455908775,
      "learning_rate": 9.06144578313253e-06,
      "loss": 0.0104,
      "step": 90790
    },
    {
      "epoch": 10.939759036144578,
      "grad_norm": 0.012362880632281303,
      "learning_rate": 9.060240963855423e-06,
      "loss": 0.0203,
      "step": 90800
    },
    {
      "epoch": 10.940963855421687,
      "grad_norm": 0.11020399630069733,
      "learning_rate": 9.059036144578313e-06,
      "loss": 0.0172,
      "step": 90810
    },
    {
      "epoch": 10.942168674698795,
      "grad_norm": 0.013306592591106892,
      "learning_rate": 9.057831325301206e-06,
      "loss": 0.0061,
      "step": 90820
    },
    {
      "epoch": 10.943373493975903,
      "grad_norm": 1.1633944511413574,
      "learning_rate": 9.056626506024098e-06,
      "loss": 0.0629,
      "step": 90830
    },
    {
      "epoch": 10.944578313253013,
      "grad_norm": 1.2209398746490479,
      "learning_rate": 9.055421686746989e-06,
      "loss": 0.0511,
      "step": 90840
    },
    {
      "epoch": 10.94578313253012,
      "grad_norm": 0.28944164514541626,
      "learning_rate": 9.054216867469881e-06,
      "loss": 0.0216,
      "step": 90850
    },
    {
      "epoch": 10.946987951807229,
      "grad_norm": 13.50133991241455,
      "learning_rate": 9.053012048192772e-06,
      "loss": 0.0469,
      "step": 90860
    },
    {
      "epoch": 10.948192771084337,
      "grad_norm": 0.035741809755563736,
      "learning_rate": 9.051807228915663e-06,
      "loss": 0.0202,
      "step": 90870
    },
    {
      "epoch": 10.949397590361446,
      "grad_norm": 1.831087589263916,
      "learning_rate": 9.050602409638555e-06,
      "loss": 0.0134,
      "step": 90880
    },
    {
      "epoch": 10.950602409638554,
      "grad_norm": 0.24483846127986908,
      "learning_rate": 9.049397590361446e-06,
      "loss": 0.0036,
      "step": 90890
    },
    {
      "epoch": 10.951807228915662,
      "grad_norm": 4.091172218322754,
      "learning_rate": 9.048192771084338e-06,
      "loss": 0.0426,
      "step": 90900
    },
    {
      "epoch": 10.953012048192772,
      "grad_norm": 4.065433502197266,
      "learning_rate": 9.04698795180723e-06,
      "loss": 0.0406,
      "step": 90910
    },
    {
      "epoch": 10.95421686746988,
      "grad_norm": 0.004071942996233702,
      "learning_rate": 9.045783132530122e-06,
      "loss": 0.0372,
      "step": 90920
    },
    {
      "epoch": 10.955421686746988,
      "grad_norm": 0.006628841161727905,
      "learning_rate": 9.044578313253012e-06,
      "loss": 0.0171,
      "step": 90930
    },
    {
      "epoch": 10.956626506024097,
      "grad_norm": 0.02304646000266075,
      "learning_rate": 9.043373493975905e-06,
      "loss": 0.0109,
      "step": 90940
    },
    {
      "epoch": 10.957831325301205,
      "grad_norm": 0.005304011050611734,
      "learning_rate": 9.042168674698795e-06,
      "loss": 0.0174,
      "step": 90950
    },
    {
      "epoch": 10.959036144578313,
      "grad_norm": 0.037455733865499496,
      "learning_rate": 9.040963855421688e-06,
      "loss": 0.0527,
      "step": 90960
    },
    {
      "epoch": 10.960240963855421,
      "grad_norm": 0.5726522207260132,
      "learning_rate": 9.039759036144579e-06,
      "loss": 0.0199,
      "step": 90970
    },
    {
      "epoch": 10.96144578313253,
      "grad_norm": 0.017012571915984154,
      "learning_rate": 9.038554216867471e-06,
      "loss": 0.0284,
      "step": 90980
    },
    {
      "epoch": 10.962650602409639,
      "grad_norm": 4.572547435760498,
      "learning_rate": 9.037349397590362e-06,
      "loss": 0.0274,
      "step": 90990
    },
    {
      "epoch": 10.963855421686747,
      "grad_norm": 1.043812870979309,
      "learning_rate": 9.036144578313254e-06,
      "loss": 0.0419,
      "step": 91000
    },
    {
      "epoch": 10.965060240963856,
      "grad_norm": 0.07254385203123093,
      "learning_rate": 9.034939759036145e-06,
      "loss": 0.0239,
      "step": 91010
    },
    {
      "epoch": 10.966265060240964,
      "grad_norm": 2.3259072303771973,
      "learning_rate": 9.033734939759037e-06,
      "loss": 0.0346,
      "step": 91020
    },
    {
      "epoch": 10.967469879518072,
      "grad_norm": 0.11952786892652512,
      "learning_rate": 9.032530120481928e-06,
      "loss": 0.0222,
      "step": 91030
    },
    {
      "epoch": 10.96867469879518,
      "grad_norm": 0.009364564903080463,
      "learning_rate": 9.031325301204819e-06,
      "loss": 0.0151,
      "step": 91040
    },
    {
      "epoch": 10.96987951807229,
      "grad_norm": 0.009228603914380074,
      "learning_rate": 9.030120481927711e-06,
      "loss": 0.0181,
      "step": 91050
    },
    {
      "epoch": 10.971084337349398,
      "grad_norm": 1.957476019859314,
      "learning_rate": 9.028915662650604e-06,
      "loss": 0.019,
      "step": 91060
    },
    {
      "epoch": 10.972289156626506,
      "grad_norm": 2.0067789554595947,
      "learning_rate": 9.027710843373495e-06,
      "loss": 0.0219,
      "step": 91070
    },
    {
      "epoch": 10.973493975903615,
      "grad_norm": 3.799182891845703,
      "learning_rate": 9.026506024096387e-06,
      "loss": 0.0306,
      "step": 91080
    },
    {
      "epoch": 10.974698795180723,
      "grad_norm": 0.09944802522659302,
      "learning_rate": 9.025301204819278e-06,
      "loss": 0.0544,
      "step": 91090
    },
    {
      "epoch": 10.975903614457831,
      "grad_norm": 2.1494767665863037,
      "learning_rate": 9.024096385542168e-06,
      "loss": 0.0157,
      "step": 91100
    },
    {
      "epoch": 10.977108433734939,
      "grad_norm": 0.04865657538175583,
      "learning_rate": 9.022891566265061e-06,
      "loss": 0.0087,
      "step": 91110
    },
    {
      "epoch": 10.978313253012049,
      "grad_norm": 6.223278522491455,
      "learning_rate": 9.021686746987952e-06,
      "loss": 0.032,
      "step": 91120
    },
    {
      "epoch": 10.979518072289157,
      "grad_norm": 0.42858630418777466,
      "learning_rate": 9.020481927710844e-06,
      "loss": 0.0163,
      "step": 91130
    },
    {
      "epoch": 10.980722891566264,
      "grad_norm": 7.1251420974731445,
      "learning_rate": 9.019277108433737e-06,
      "loss": 0.0058,
      "step": 91140
    },
    {
      "epoch": 10.981927710843374,
      "grad_norm": 6.09068489074707,
      "learning_rate": 9.018072289156627e-06,
      "loss": 0.028,
      "step": 91150
    },
    {
      "epoch": 10.983132530120482,
      "grad_norm": 0.0030887399334460497,
      "learning_rate": 9.01686746987952e-06,
      "loss": 0.0346,
      "step": 91160
    },
    {
      "epoch": 10.98433734939759,
      "grad_norm": 0.0013231539633125067,
      "learning_rate": 9.01566265060241e-06,
      "loss": 0.002,
      "step": 91170
    },
    {
      "epoch": 10.985542168674698,
      "grad_norm": 0.0029075555503368378,
      "learning_rate": 9.014457831325301e-06,
      "loss": 0.0301,
      "step": 91180
    },
    {
      "epoch": 10.986746987951808,
      "grad_norm": 0.00632240017876029,
      "learning_rate": 9.013253012048194e-06,
      "loss": 0.0148,
      "step": 91190
    },
    {
      "epoch": 10.987951807228916,
      "grad_norm": 0.0016036274610087276,
      "learning_rate": 9.012048192771084e-06,
      "loss": 0.0172,
      "step": 91200
    },
    {
      "epoch": 10.989156626506023,
      "grad_norm": 0.6874479651451111,
      "learning_rate": 9.010843373493977e-06,
      "loss": 0.0444,
      "step": 91210
    },
    {
      "epoch": 10.990361445783133,
      "grad_norm": 8.792633056640625,
      "learning_rate": 9.00963855421687e-06,
      "loss": 0.0495,
      "step": 91220
    },
    {
      "epoch": 10.991566265060241,
      "grad_norm": 0.8648591041564941,
      "learning_rate": 9.00843373493976e-06,
      "loss": 0.0308,
      "step": 91230
    },
    {
      "epoch": 10.992771084337349,
      "grad_norm": 0.19891570508480072,
      "learning_rate": 9.00722891566265e-06,
      "loss": 0.0353,
      "step": 91240
    },
    {
      "epoch": 10.993975903614459,
      "grad_norm": 0.007294744253158569,
      "learning_rate": 9.006024096385543e-06,
      "loss": 0.0329,
      "step": 91250
    },
    {
      "epoch": 10.995180722891567,
      "grad_norm": 0.1488974392414093,
      "learning_rate": 9.004819277108434e-06,
      "loss": 0.0323,
      "step": 91260
    },
    {
      "epoch": 10.996385542168674,
      "grad_norm": 0.06968574225902557,
      "learning_rate": 9.003614457831326e-06,
      "loss": 0.0125,
      "step": 91270
    },
    {
      "epoch": 10.997590361445782,
      "grad_norm": 0.23987022042274475,
      "learning_rate": 9.002409638554219e-06,
      "loss": 0.027,
      "step": 91280
    },
    {
      "epoch": 10.998795180722892,
      "grad_norm": 0.21911218762397766,
      "learning_rate": 9.00120481927711e-06,
      "loss": 0.0451,
      "step": 91290
    },
    {
      "epoch": 11.0,
      "grad_norm": 4.3233208656311035,
      "learning_rate": 9e-06,
      "loss": 0.0102,
      "step": 91300
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.9857049118860143,
      "eval_f1": 0.9619510978043911,
      "eval_loss": 0.04849320277571678,
      "eval_precision": 0.9710363934013349,
      "eval_recall": 0.9530342355703868,
      "eval_runtime": 3379.1947,
      "eval_samples_per_second": 12.633,
      "eval_steps_per_second": 0.526,
      "step": 91300
    },
    {
      "epoch": 11.001204819277108,
      "grad_norm": 0.0040752156637609005,
      "learning_rate": 8.998795180722893e-06,
      "loss": 0.0341,
      "step": 91310
    },
    {
      "epoch": 11.002409638554218,
      "grad_norm": 0.04714900255203247,
      "learning_rate": 8.997590361445783e-06,
      "loss": 0.0143,
      "step": 91320
    },
    {
      "epoch": 11.003614457831326,
      "grad_norm": 0.222889244556427,
      "learning_rate": 8.996385542168676e-06,
      "loss": 0.0201,
      "step": 91330
    },
    {
      "epoch": 11.004819277108433,
      "grad_norm": 0.42339828610420227,
      "learning_rate": 8.995180722891567e-06,
      "loss": 0.0179,
      "step": 91340
    },
    {
      "epoch": 11.006024096385541,
      "grad_norm": 3.1107430458068848,
      "learning_rate": 8.993975903614457e-06,
      "loss": 0.0147,
      "step": 91350
    },
    {
      "epoch": 11.007228915662651,
      "grad_norm": 2.2907111644744873,
      "learning_rate": 8.99277108433735e-06,
      "loss": 0.0167,
      "step": 91360
    },
    {
      "epoch": 11.008433734939759,
      "grad_norm": 0.014144530519843102,
      "learning_rate": 8.991566265060242e-06,
      "loss": 0.0216,
      "step": 91370
    },
    {
      "epoch": 11.009638554216867,
      "grad_norm": 1.407121181488037,
      "learning_rate": 8.990361445783133e-06,
      "loss": 0.0291,
      "step": 91380
    },
    {
      "epoch": 11.010843373493977,
      "grad_norm": 1.2984747886657715,
      "learning_rate": 8.989156626506025e-06,
      "loss": 0.0094,
      "step": 91390
    },
    {
      "epoch": 11.012048192771084,
      "grad_norm": 0.12318019568920135,
      "learning_rate": 8.987951807228916e-06,
      "loss": 0.0228,
      "step": 91400
    },
    {
      "epoch": 11.013253012048192,
      "grad_norm": 0.4318196475505829,
      "learning_rate": 8.986746987951807e-06,
      "loss": 0.0175,
      "step": 91410
    },
    {
      "epoch": 11.0144578313253,
      "grad_norm": 1.3216502666473389,
      "learning_rate": 8.9855421686747e-06,
      "loss": 0.0169,
      "step": 91420
    },
    {
      "epoch": 11.01566265060241,
      "grad_norm": 0.002455801237374544,
      "learning_rate": 8.984337349397592e-06,
      "loss": 0.007,
      "step": 91430
    },
    {
      "epoch": 11.016867469879518,
      "grad_norm": 0.0029657636769115925,
      "learning_rate": 8.983132530120482e-06,
      "loss": 0.0033,
      "step": 91440
    },
    {
      "epoch": 11.018072289156626,
      "grad_norm": 0.9663538336753845,
      "learning_rate": 8.981927710843375e-06,
      "loss": 0.0084,
      "step": 91450
    },
    {
      "epoch": 11.019277108433736,
      "grad_norm": 3.868267774581909,
      "learning_rate": 8.980722891566266e-06,
      "loss": 0.039,
      "step": 91460
    },
    {
      "epoch": 11.020481927710843,
      "grad_norm": 0.002724313409999013,
      "learning_rate": 8.979518072289158e-06,
      "loss": 0.0054,
      "step": 91470
    },
    {
      "epoch": 11.021686746987951,
      "grad_norm": 0.0023480623494833708,
      "learning_rate": 8.978313253012049e-06,
      "loss": 0.0237,
      "step": 91480
    },
    {
      "epoch": 11.022891566265061,
      "grad_norm": 0.002073401352390647,
      "learning_rate": 8.97710843373494e-06,
      "loss": 0.0483,
      "step": 91490
    },
    {
      "epoch": 11.024096385542169,
      "grad_norm": 0.013979632407426834,
      "learning_rate": 8.975903614457832e-06,
      "loss": 0.0168,
      "step": 91500
    },
    {
      "epoch": 11.025301204819277,
      "grad_norm": 0.023706093430519104,
      "learning_rate": 8.974698795180724e-06,
      "loss": 0.0296,
      "step": 91510
    },
    {
      "epoch": 11.026506024096385,
      "grad_norm": 0.09236327558755875,
      "learning_rate": 8.973493975903615e-06,
      "loss": 0.005,
      "step": 91520
    },
    {
      "epoch": 11.027710843373494,
      "grad_norm": 0.012066036462783813,
      "learning_rate": 8.972289156626508e-06,
      "loss": 0.0075,
      "step": 91530
    },
    {
      "epoch": 11.028915662650602,
      "grad_norm": 1.3887872695922852,
      "learning_rate": 8.971084337349398e-06,
      "loss": 0.02,
      "step": 91540
    },
    {
      "epoch": 11.03012048192771,
      "grad_norm": 0.003334632609039545,
      "learning_rate": 8.969879518072289e-06,
      "loss": 0.0372,
      "step": 91550
    },
    {
      "epoch": 11.03132530120482,
      "grad_norm": 0.004455137066543102,
      "learning_rate": 8.968674698795182e-06,
      "loss": 0.0266,
      "step": 91560
    },
    {
      "epoch": 11.032530120481928,
      "grad_norm": 0.4895933270454407,
      "learning_rate": 8.967469879518072e-06,
      "loss": 0.0057,
      "step": 91570
    },
    {
      "epoch": 11.033734939759036,
      "grad_norm": 0.015001124702394009,
      "learning_rate": 8.966265060240965e-06,
      "loss": 0.0053,
      "step": 91580
    },
    {
      "epoch": 11.034939759036144,
      "grad_norm": 8.510618209838867,
      "learning_rate": 8.965060240963857e-06,
      "loss": 0.0186,
      "step": 91590
    },
    {
      "epoch": 11.036144578313253,
      "grad_norm": 0.48246970772743225,
      "learning_rate": 8.963855421686748e-06,
      "loss": 0.0318,
      "step": 91600
    },
    {
      "epoch": 11.037349397590361,
      "grad_norm": 0.10061990469694138,
      "learning_rate": 8.962650602409639e-06,
      "loss": 0.0567,
      "step": 91610
    },
    {
      "epoch": 11.03855421686747,
      "grad_norm": 1.6613085269927979,
      "learning_rate": 8.961445783132531e-06,
      "loss": 0.0227,
      "step": 91620
    },
    {
      "epoch": 11.039759036144579,
      "grad_norm": 0.005462449509650469,
      "learning_rate": 8.960240963855422e-06,
      "loss": 0.0221,
      "step": 91630
    },
    {
      "epoch": 11.040963855421687,
      "grad_norm": 0.014737457036972046,
      "learning_rate": 8.959036144578314e-06,
      "loss": 0.0237,
      "step": 91640
    },
    {
      "epoch": 11.042168674698795,
      "grad_norm": 0.01667793281376362,
      "learning_rate": 8.957831325301205e-06,
      "loss": 0.0065,
      "step": 91650
    },
    {
      "epoch": 11.043373493975903,
      "grad_norm": 0.004796184599399567,
      "learning_rate": 8.956626506024097e-06,
      "loss": 0.0028,
      "step": 91660
    },
    {
      "epoch": 11.044578313253012,
      "grad_norm": 2.834287643432617,
      "learning_rate": 8.955421686746988e-06,
      "loss": 0.0328,
      "step": 91670
    },
    {
      "epoch": 11.04578313253012,
      "grad_norm": 1.450104832649231,
      "learning_rate": 8.95421686746988e-06,
      "loss": 0.017,
      "step": 91680
    },
    {
      "epoch": 11.046987951807228,
      "grad_norm": 1.096826434135437,
      "learning_rate": 8.953012048192771e-06,
      "loss": 0.0086,
      "step": 91690
    },
    {
      "epoch": 11.048192771084338,
      "grad_norm": 0.0012907733907923102,
      "learning_rate": 8.951807228915664e-06,
      "loss": 0.0142,
      "step": 91700
    },
    {
      "epoch": 11.049397590361446,
      "grad_norm": 1.5604970455169678,
      "learning_rate": 8.950602409638554e-06,
      "loss": 0.0048,
      "step": 91710
    },
    {
      "epoch": 11.050602409638554,
      "grad_norm": 0.8762385845184326,
      "learning_rate": 8.949397590361445e-06,
      "loss": 0.0176,
      "step": 91720
    },
    {
      "epoch": 11.051807228915663,
      "grad_norm": 2.108898401260376,
      "learning_rate": 8.94819277108434e-06,
      "loss": 0.0147,
      "step": 91730
    },
    {
      "epoch": 11.053012048192771,
      "grad_norm": 1.4078937768936157,
      "learning_rate": 8.94698795180723e-06,
      "loss": 0.0175,
      "step": 91740
    },
    {
      "epoch": 11.05421686746988,
      "grad_norm": 0.3232501149177551,
      "learning_rate": 8.94578313253012e-06,
      "loss": 0.0782,
      "step": 91750
    },
    {
      "epoch": 11.055421686746987,
      "grad_norm": 0.0067110126838088036,
      "learning_rate": 8.944578313253013e-06,
      "loss": 0.0095,
      "step": 91760
    },
    {
      "epoch": 11.056626506024097,
      "grad_norm": 0.022535540163517,
      "learning_rate": 8.943373493975904e-06,
      "loss": 0.0051,
      "step": 91770
    },
    {
      "epoch": 11.057831325301205,
      "grad_norm": 4.100361347198486,
      "learning_rate": 8.942168674698796e-06,
      "loss": 0.0393,
      "step": 91780
    },
    {
      "epoch": 11.059036144578313,
      "grad_norm": 0.06428544223308563,
      "learning_rate": 8.940963855421687e-06,
      "loss": 0.0079,
      "step": 91790
    },
    {
      "epoch": 11.060240963855422,
      "grad_norm": 0.003466509049758315,
      "learning_rate": 8.939759036144578e-06,
      "loss": 0.0001,
      "step": 91800
    },
    {
      "epoch": 11.06144578313253,
      "grad_norm": 2.661761522293091,
      "learning_rate": 8.93855421686747e-06,
      "loss": 0.051,
      "step": 91810
    },
    {
      "epoch": 11.062650602409638,
      "grad_norm": 0.005234664771705866,
      "learning_rate": 8.937349397590363e-06,
      "loss": 0.0216,
      "step": 91820
    },
    {
      "epoch": 11.063855421686746,
      "grad_norm": 0.04759255424141884,
      "learning_rate": 8.936144578313254e-06,
      "loss": 0.0246,
      "step": 91830
    },
    {
      "epoch": 11.065060240963856,
      "grad_norm": 0.026592154055833817,
      "learning_rate": 8.934939759036146e-06,
      "loss": 0.0237,
      "step": 91840
    },
    {
      "epoch": 11.066265060240964,
      "grad_norm": 0.002548666438087821,
      "learning_rate": 8.933734939759037e-06,
      "loss": 0.0322,
      "step": 91850
    },
    {
      "epoch": 11.067469879518072,
      "grad_norm": 1.3227708339691162,
      "learning_rate": 8.932530120481927e-06,
      "loss": 0.0299,
      "step": 91860
    },
    {
      "epoch": 11.068674698795181,
      "grad_norm": 0.907962441444397,
      "learning_rate": 8.93132530120482e-06,
      "loss": 0.0118,
      "step": 91870
    },
    {
      "epoch": 11.06987951807229,
      "grad_norm": 0.0042725796811282635,
      "learning_rate": 8.930120481927712e-06,
      "loss": 0.0084,
      "step": 91880
    },
    {
      "epoch": 11.071084337349397,
      "grad_norm": 0.01610618084669113,
      "learning_rate": 8.928915662650603e-06,
      "loss": 0.0005,
      "step": 91890
    },
    {
      "epoch": 11.072289156626505,
      "grad_norm": 1.029762864112854,
      "learning_rate": 8.927710843373496e-06,
      "loss": 0.0262,
      "step": 91900
    },
    {
      "epoch": 11.073493975903615,
      "grad_norm": 0.18598781526088715,
      "learning_rate": 8.926506024096386e-06,
      "loss": 0.0208,
      "step": 91910
    },
    {
      "epoch": 11.074698795180723,
      "grad_norm": 0.029664484784007072,
      "learning_rate": 8.925301204819277e-06,
      "loss": 0.0007,
      "step": 91920
    },
    {
      "epoch": 11.07590361445783,
      "grad_norm": 0.0021187441889196634,
      "learning_rate": 8.92409638554217e-06,
      "loss": 0.0066,
      "step": 91930
    },
    {
      "epoch": 11.07710843373494,
      "grad_norm": 4.342395305633545,
      "learning_rate": 8.92289156626506e-06,
      "loss": 0.0497,
      "step": 91940
    },
    {
      "epoch": 11.078313253012048,
      "grad_norm": 1.6138492822647095,
      "learning_rate": 8.921686746987953e-06,
      "loss": 0.0083,
      "step": 91950
    },
    {
      "epoch": 11.079518072289156,
      "grad_norm": 0.0035544836428016424,
      "learning_rate": 8.920481927710845e-06,
      "loss": 0.0094,
      "step": 91960
    },
    {
      "epoch": 11.080722891566266,
      "grad_norm": 0.0027520591393113136,
      "learning_rate": 8.919277108433736e-06,
      "loss": 0.015,
      "step": 91970
    },
    {
      "epoch": 11.081927710843374,
      "grad_norm": 0.3842564523220062,
      "learning_rate": 8.918072289156628e-06,
      "loss": 0.0152,
      "step": 91980
    },
    {
      "epoch": 11.083132530120482,
      "grad_norm": 0.0032822489738464355,
      "learning_rate": 8.916867469879519e-06,
      "loss": 0.0037,
      "step": 91990
    },
    {
      "epoch": 11.08433734939759,
      "grad_norm": 0.03614973649382591,
      "learning_rate": 8.91566265060241e-06,
      "loss": 0.0088,
      "step": 92000
    },
    {
      "epoch": 11.0855421686747,
      "grad_norm": 0.09092775732278824,
      "learning_rate": 8.914457831325302e-06,
      "loss": 0.0265,
      "step": 92010
    },
    {
      "epoch": 11.086746987951807,
      "grad_norm": 0.0031078828033059835,
      "learning_rate": 8.913253012048193e-06,
      "loss": 0.0082,
      "step": 92020
    },
    {
      "epoch": 11.087951807228915,
      "grad_norm": 1.6739882230758667,
      "learning_rate": 8.912048192771085e-06,
      "loss": 0.026,
      "step": 92030
    },
    {
      "epoch": 11.089156626506025,
      "grad_norm": 0.0006524032214656472,
      "learning_rate": 8.910843373493978e-06,
      "loss": 0.042,
      "step": 92040
    },
    {
      "epoch": 11.090361445783133,
      "grad_norm": 0.0024561737664043903,
      "learning_rate": 8.909638554216868e-06,
      "loss": 0.0043,
      "step": 92050
    },
    {
      "epoch": 11.09156626506024,
      "grad_norm": 0.06853269785642624,
      "learning_rate": 8.90843373493976e-06,
      "loss": 0.0112,
      "step": 92060
    },
    {
      "epoch": 11.092771084337349,
      "grad_norm": 0.006012288387864828,
      "learning_rate": 8.907228915662652e-06,
      "loss": 0.0156,
      "step": 92070
    },
    {
      "epoch": 11.093975903614458,
      "grad_norm": 0.04807284474372864,
      "learning_rate": 8.906024096385542e-06,
      "loss": 0.0366,
      "step": 92080
    },
    {
      "epoch": 11.095180722891566,
      "grad_norm": 5.5249810218811035,
      "learning_rate": 8.904819277108435e-06,
      "loss": 0.0174,
      "step": 92090
    },
    {
      "epoch": 11.096385542168674,
      "grad_norm": 0.002394150011241436,
      "learning_rate": 8.903614457831326e-06,
      "loss": 0.0247,
      "step": 92100
    },
    {
      "epoch": 11.097590361445784,
      "grad_norm": 0.4411696493625641,
      "learning_rate": 8.902409638554218e-06,
      "loss": 0.0069,
      "step": 92110
    },
    {
      "epoch": 11.098795180722892,
      "grad_norm": 0.19427655637264252,
      "learning_rate": 8.901204819277109e-06,
      "loss": 0.0019,
      "step": 92120
    },
    {
      "epoch": 11.1,
      "grad_norm": 5.7296037673950195,
      "learning_rate": 8.900000000000001e-06,
      "loss": 0.0337,
      "step": 92130
    },
    {
      "epoch": 11.101204819277108,
      "grad_norm": 0.012918426655232906,
      "learning_rate": 8.898795180722892e-06,
      "loss": 0.0026,
      "step": 92140
    },
    {
      "epoch": 11.102409638554217,
      "grad_norm": 0.005192408338189125,
      "learning_rate": 8.897590361445784e-06,
      "loss": 0.0426,
      "step": 92150
    },
    {
      "epoch": 11.103614457831325,
      "grad_norm": 0.3310387134552002,
      "learning_rate": 8.896385542168675e-06,
      "loss": 0.0441,
      "step": 92160
    },
    {
      "epoch": 11.104819277108433,
      "grad_norm": 0.019549962133169174,
      "learning_rate": 8.895180722891566e-06,
      "loss": 0.0056,
      "step": 92170
    },
    {
      "epoch": 11.106024096385543,
      "grad_norm": 0.0036738549824804068,
      "learning_rate": 8.893975903614458e-06,
      "loss": 0.0137,
      "step": 92180
    },
    {
      "epoch": 11.10722891566265,
      "grad_norm": 0.024172423407435417,
      "learning_rate": 8.89277108433735e-06,
      "loss": 0.0273,
      "step": 92190
    },
    {
      "epoch": 11.108433734939759,
      "grad_norm": 0.00146766216494143,
      "learning_rate": 8.891566265060241e-06,
      "loss": 0.0074,
      "step": 92200
    },
    {
      "epoch": 11.109638554216868,
      "grad_norm": 0.002856550505384803,
      "learning_rate": 8.890361445783134e-06,
      "loss": 0.0044,
      "step": 92210
    },
    {
      "epoch": 11.110843373493976,
      "grad_norm": 2.09590220451355,
      "learning_rate": 8.889156626506025e-06,
      "loss": 0.0331,
      "step": 92220
    },
    {
      "epoch": 11.112048192771084,
      "grad_norm": 0.1389034241437912,
      "learning_rate": 8.887951807228915e-06,
      "loss": 0.0283,
      "step": 92230
    },
    {
      "epoch": 11.113253012048192,
      "grad_norm": 3.0467770099639893,
      "learning_rate": 8.886746987951808e-06,
      "loss": 0.0247,
      "step": 92240
    },
    {
      "epoch": 11.114457831325302,
      "grad_norm": 0.007943428121507168,
      "learning_rate": 8.885542168674699e-06,
      "loss": 0.0136,
      "step": 92250
    },
    {
      "epoch": 11.11566265060241,
      "grad_norm": 0.2639405429363251,
      "learning_rate": 8.884337349397591e-06,
      "loss": 0.0046,
      "step": 92260
    },
    {
      "epoch": 11.116867469879518,
      "grad_norm": 0.08345600962638855,
      "learning_rate": 8.883132530120483e-06,
      "loss": 0.011,
      "step": 92270
    },
    {
      "epoch": 11.118072289156627,
      "grad_norm": 0.0017705028876662254,
      "learning_rate": 8.881927710843374e-06,
      "loss": 0.0127,
      "step": 92280
    },
    {
      "epoch": 11.119277108433735,
      "grad_norm": 0.008847815915942192,
      "learning_rate": 8.880722891566267e-06,
      "loss": 0.0035,
      "step": 92290
    },
    {
      "epoch": 11.120481927710843,
      "grad_norm": 0.0016534208552911878,
      "learning_rate": 8.879518072289157e-06,
      "loss": 0.0003,
      "step": 92300
    },
    {
      "epoch": 11.121686746987951,
      "grad_norm": 0.001033052452839911,
      "learning_rate": 8.878313253012048e-06,
      "loss": 0.0006,
      "step": 92310
    },
    {
      "epoch": 11.12289156626506,
      "grad_norm": 0.0011102092685177922,
      "learning_rate": 8.87710843373494e-06,
      "loss": 0.0207,
      "step": 92320
    },
    {
      "epoch": 11.124096385542169,
      "grad_norm": 2.139922618865967,
      "learning_rate": 8.875903614457833e-06,
      "loss": 0.0564,
      "step": 92330
    },
    {
      "epoch": 11.125301204819277,
      "grad_norm": 1.3697519302368164,
      "learning_rate": 8.874698795180724e-06,
      "loss": 0.0162,
      "step": 92340
    },
    {
      "epoch": 11.126506024096386,
      "grad_norm": 0.26468831300735474,
      "learning_rate": 8.873493975903616e-06,
      "loss": 0.0587,
      "step": 92350
    },
    {
      "epoch": 11.127710843373494,
      "grad_norm": 0.277812123298645,
      "learning_rate": 8.872289156626507e-06,
      "loss": 0.0011,
      "step": 92360
    },
    {
      "epoch": 11.128915662650602,
      "grad_norm": 0.21268701553344727,
      "learning_rate": 8.871084337349398e-06,
      "loss": 0.0403,
      "step": 92370
    },
    {
      "epoch": 11.13012048192771,
      "grad_norm": 0.003302785800769925,
      "learning_rate": 8.86987951807229e-06,
      "loss": 0.0086,
      "step": 92380
    },
    {
      "epoch": 11.13132530120482,
      "grad_norm": 0.0232712309807539,
      "learning_rate": 8.86867469879518e-06,
      "loss": 0.0013,
      "step": 92390
    },
    {
      "epoch": 11.132530120481928,
      "grad_norm": 0.8578318357467651,
      "learning_rate": 8.867469879518073e-06,
      "loss": 0.0288,
      "step": 92400
    },
    {
      "epoch": 11.133734939759035,
      "grad_norm": 0.01663115620613098,
      "learning_rate": 8.866265060240966e-06,
      "loss": 0.0217,
      "step": 92410
    },
    {
      "epoch": 11.134939759036145,
      "grad_norm": 1.1246496438980103,
      "learning_rate": 8.865060240963856e-06,
      "loss": 0.0129,
      "step": 92420
    },
    {
      "epoch": 11.136144578313253,
      "grad_norm": 0.4849456250667572,
      "learning_rate": 8.863855421686747e-06,
      "loss": 0.0352,
      "step": 92430
    },
    {
      "epoch": 11.137349397590361,
      "grad_norm": 0.0021208233665674925,
      "learning_rate": 8.86265060240964e-06,
      "loss": 0.0168,
      "step": 92440
    },
    {
      "epoch": 11.13855421686747,
      "grad_norm": 0.0011130156926810741,
      "learning_rate": 8.86144578313253e-06,
      "loss": 0.0166,
      "step": 92450
    },
    {
      "epoch": 11.139759036144579,
      "grad_norm": 0.11380893737077713,
      "learning_rate": 8.860240963855423e-06,
      "loss": 0.0229,
      "step": 92460
    },
    {
      "epoch": 11.140963855421687,
      "grad_norm": 0.03148738294839859,
      "learning_rate": 8.859036144578313e-06,
      "loss": 0.0021,
      "step": 92470
    },
    {
      "epoch": 11.142168674698794,
      "grad_norm": 0.0031497275922447443,
      "learning_rate": 8.857831325301206e-06,
      "loss": 0.0169,
      "step": 92480
    },
    {
      "epoch": 11.143373493975904,
      "grad_norm": 0.7584143280982971,
      "learning_rate": 8.856626506024097e-06,
      "loss": 0.0034,
      "step": 92490
    },
    {
      "epoch": 11.144578313253012,
      "grad_norm": 0.009994878433644772,
      "learning_rate": 8.855421686746989e-06,
      "loss": 0.011,
      "step": 92500
    },
    {
      "epoch": 11.14578313253012,
      "grad_norm": 0.001232675975188613,
      "learning_rate": 8.85421686746988e-06,
      "loss": 0.009,
      "step": 92510
    },
    {
      "epoch": 11.14698795180723,
      "grad_norm": 0.0007048897095955908,
      "learning_rate": 8.853012048192772e-06,
      "loss": 0.005,
      "step": 92520
    },
    {
      "epoch": 11.148192771084338,
      "grad_norm": 1.144111156463623,
      "learning_rate": 8.851807228915663e-06,
      "loss": 0.0082,
      "step": 92530
    },
    {
      "epoch": 11.149397590361446,
      "grad_norm": 0.0018392633646726608,
      "learning_rate": 8.850602409638554e-06,
      "loss": 0.0108,
      "step": 92540
    },
    {
      "epoch": 11.150602409638553,
      "grad_norm": 0.16620874404907227,
      "learning_rate": 8.849397590361446e-06,
      "loss": 0.0035,
      "step": 92550
    },
    {
      "epoch": 11.151807228915663,
      "grad_norm": 0.0008480218821205199,
      "learning_rate": 8.848192771084339e-06,
      "loss": 0.0299,
      "step": 92560
    },
    {
      "epoch": 11.153012048192771,
      "grad_norm": 0.5908093452453613,
      "learning_rate": 8.84698795180723e-06,
      "loss": 0.0134,
      "step": 92570
    },
    {
      "epoch": 11.154216867469879,
      "grad_norm": 0.0012728600995615125,
      "learning_rate": 8.845783132530122e-06,
      "loss": 0.0179,
      "step": 92580
    },
    {
      "epoch": 11.155421686746989,
      "grad_norm": 0.0012922128662467003,
      "learning_rate": 8.844578313253013e-06,
      "loss": 0.0237,
      "step": 92590
    },
    {
      "epoch": 11.156626506024097,
      "grad_norm": 0.016314709559082985,
      "learning_rate": 8.843373493975905e-06,
      "loss": 0.0467,
      "step": 92600
    },
    {
      "epoch": 11.157831325301204,
      "grad_norm": 0.004115436691790819,
      "learning_rate": 8.842168674698796e-06,
      "loss": 0.0388,
      "step": 92610
    },
    {
      "epoch": 11.159036144578312,
      "grad_norm": 0.13309356570243835,
      "learning_rate": 8.840963855421686e-06,
      "loss": 0.0154,
      "step": 92620
    },
    {
      "epoch": 11.160240963855422,
      "grad_norm": 1.8471693992614746,
      "learning_rate": 8.839759036144579e-06,
      "loss": 0.0116,
      "step": 92630
    },
    {
      "epoch": 11.16144578313253,
      "grad_norm": 0.07597868889570236,
      "learning_rate": 8.838554216867471e-06,
      "loss": 0.0067,
      "step": 92640
    },
    {
      "epoch": 11.162650602409638,
      "grad_norm": 0.05145531892776489,
      "learning_rate": 8.837349397590362e-06,
      "loss": 0.0115,
      "step": 92650
    },
    {
      "epoch": 11.163855421686748,
      "grad_norm": 0.17747803032398224,
      "learning_rate": 8.836144578313255e-06,
      "loss": 0.0215,
      "step": 92660
    },
    {
      "epoch": 11.165060240963856,
      "grad_norm": 0.003835363080725074,
      "learning_rate": 8.834939759036145e-06,
      "loss": 0.0103,
      "step": 92670
    },
    {
      "epoch": 11.166265060240963,
      "grad_norm": 0.001837637391872704,
      "learning_rate": 8.833734939759036e-06,
      "loss": 0.0142,
      "step": 92680
    },
    {
      "epoch": 11.167469879518073,
      "grad_norm": 0.5152791142463684,
      "learning_rate": 8.832530120481928e-06,
      "loss": 0.0087,
      "step": 92690
    },
    {
      "epoch": 11.168674698795181,
      "grad_norm": 0.0013374510454013944,
      "learning_rate": 8.83132530120482e-06,
      "loss": 0.0228,
      "step": 92700
    },
    {
      "epoch": 11.169879518072289,
      "grad_norm": 83.25591278076172,
      "learning_rate": 8.830120481927712e-06,
      "loss": 0.046,
      "step": 92710
    },
    {
      "epoch": 11.171084337349397,
      "grad_norm": 0.003209393471479416,
      "learning_rate": 8.828915662650604e-06,
      "loss": 0.0504,
      "step": 92720
    },
    {
      "epoch": 11.172289156626507,
      "grad_norm": 0.018448881804943085,
      "learning_rate": 8.827710843373495e-06,
      "loss": 0.0003,
      "step": 92730
    },
    {
      "epoch": 11.173493975903614,
      "grad_norm": 10.640778541564941,
      "learning_rate": 8.826506024096386e-06,
      "loss": 0.0281,
      "step": 92740
    },
    {
      "epoch": 11.174698795180722,
      "grad_norm": 1.951927900314331,
      "learning_rate": 8.825301204819278e-06,
      "loss": 0.0168,
      "step": 92750
    },
    {
      "epoch": 11.175903614457832,
      "grad_norm": 0.0015847962349653244,
      "learning_rate": 8.824096385542169e-06,
      "loss": 0.0196,
      "step": 92760
    },
    {
      "epoch": 11.17710843373494,
      "grad_norm": 0.2833849787712097,
      "learning_rate": 8.822891566265061e-06,
      "loss": 0.0356,
      "step": 92770
    },
    {
      "epoch": 11.178313253012048,
      "grad_norm": 1.2584943771362305,
      "learning_rate": 8.821686746987954e-06,
      "loss": 0.0498,
      "step": 92780
    },
    {
      "epoch": 11.179518072289156,
      "grad_norm": 7.2053141593933105,
      "learning_rate": 8.820481927710844e-06,
      "loss": 0.0233,
      "step": 92790
    },
    {
      "epoch": 11.180722891566266,
      "grad_norm": 0.003100563772022724,
      "learning_rate": 8.819277108433735e-06,
      "loss": 0.002,
      "step": 92800
    },
    {
      "epoch": 11.181927710843373,
      "grad_norm": 0.147223562002182,
      "learning_rate": 8.818072289156627e-06,
      "loss": 0.0008,
      "step": 92810
    },
    {
      "epoch": 11.183132530120481,
      "grad_norm": 0.0022551249712705612,
      "learning_rate": 8.816867469879518e-06,
      "loss": 0.0231,
      "step": 92820
    },
    {
      "epoch": 11.184337349397591,
      "grad_norm": 1.4984972476959229,
      "learning_rate": 8.81566265060241e-06,
      "loss": 0.0085,
      "step": 92830
    },
    {
      "epoch": 11.185542168674699,
      "grad_norm": 0.0014109071344137192,
      "learning_rate": 8.814457831325301e-06,
      "loss": 0.0196,
      "step": 92840
    },
    {
      "epoch": 11.186746987951807,
      "grad_norm": 0.0022696787491440773,
      "learning_rate": 8.813253012048192e-06,
      "loss": 0.02,
      "step": 92850
    },
    {
      "epoch": 11.187951807228915,
      "grad_norm": 0.31561997532844543,
      "learning_rate": 8.812048192771086e-06,
      "loss": 0.0438,
      "step": 92860
    },
    {
      "epoch": 11.189156626506024,
      "grad_norm": 0.20520973205566406,
      "learning_rate": 8.810843373493977e-06,
      "loss": 0.0085,
      "step": 92870
    },
    {
      "epoch": 11.190361445783132,
      "grad_norm": 0.4343312084674835,
      "learning_rate": 8.809638554216868e-06,
      "loss": 0.0074,
      "step": 92880
    },
    {
      "epoch": 11.19156626506024,
      "grad_norm": 0.0037497335579246283,
      "learning_rate": 8.80843373493976e-06,
      "loss": 0.0162,
      "step": 92890
    },
    {
      "epoch": 11.19277108433735,
      "grad_norm": 0.02684556320309639,
      "learning_rate": 8.807228915662651e-06,
      "loss": 0.0062,
      "step": 92900
    },
    {
      "epoch": 11.193975903614458,
      "grad_norm": 1.2293435335159302,
      "learning_rate": 8.806024096385543e-06,
      "loss": 0.0268,
      "step": 92910
    },
    {
      "epoch": 11.195180722891566,
      "grad_norm": 2.022346258163452,
      "learning_rate": 8.804819277108434e-06,
      "loss": 0.0164,
      "step": 92920
    },
    {
      "epoch": 11.196385542168676,
      "grad_norm": 12.923029899597168,
      "learning_rate": 8.803614457831327e-06,
      "loss": 0.0432,
      "step": 92930
    },
    {
      "epoch": 11.197590361445783,
      "grad_norm": 0.0022718075197190046,
      "learning_rate": 8.802409638554217e-06,
      "loss": 0.0107,
      "step": 92940
    },
    {
      "epoch": 11.198795180722891,
      "grad_norm": 0.01446243841201067,
      "learning_rate": 8.80120481927711e-06,
      "loss": 0.0169,
      "step": 92950
    },
    {
      "epoch": 11.2,
      "grad_norm": 0.004102073144167662,
      "learning_rate": 8.8e-06,
      "loss": 0.0063,
      "step": 92960
    },
    {
      "epoch": 11.201204819277109,
      "grad_norm": 0.04661416634917259,
      "learning_rate": 8.798795180722893e-06,
      "loss": 0.0096,
      "step": 92970
    },
    {
      "epoch": 11.202409638554217,
      "grad_norm": 1.4048718214035034,
      "learning_rate": 8.797590361445784e-06,
      "loss": 0.0366,
      "step": 92980
    },
    {
      "epoch": 11.203614457831325,
      "grad_norm": 3.950456142425537,
      "learning_rate": 8.796385542168674e-06,
      "loss": 0.0101,
      "step": 92990
    },
    {
      "epoch": 11.204819277108435,
      "grad_norm": 0.0037202811799943447,
      "learning_rate": 8.795180722891567e-06,
      "loss": 0.0623,
      "step": 93000
    },
    {
      "epoch": 11.206024096385542,
      "grad_norm": 0.3405706286430359,
      "learning_rate": 8.79397590361446e-06,
      "loss": 0.0153,
      "step": 93010
    },
    {
      "epoch": 11.20722891566265,
      "grad_norm": 0.16400660574436188,
      "learning_rate": 8.79277108433735e-06,
      "loss": 0.0104,
      "step": 93020
    },
    {
      "epoch": 11.208433734939758,
      "grad_norm": 0.0021383787970989943,
      "learning_rate": 8.791566265060242e-06,
      "loss": 0.0245,
      "step": 93030
    },
    {
      "epoch": 11.209638554216868,
      "grad_norm": 1.2752678394317627,
      "learning_rate": 8.790361445783133e-06,
      "loss": 0.0514,
      "step": 93040
    },
    {
      "epoch": 11.210843373493976,
      "grad_norm": 0.0015761678805574775,
      "learning_rate": 8.789156626506024e-06,
      "loss": 0.0091,
      "step": 93050
    },
    {
      "epoch": 11.212048192771084,
      "grad_norm": 0.004804751370102167,
      "learning_rate": 8.787951807228916e-06,
      "loss": 0.0504,
      "step": 93060
    },
    {
      "epoch": 11.213253012048193,
      "grad_norm": 2.1585426330566406,
      "learning_rate": 8.786746987951807e-06,
      "loss": 0.0683,
      "step": 93070
    },
    {
      "epoch": 11.214457831325301,
      "grad_norm": 0.0047958181239664555,
      "learning_rate": 8.7855421686747e-06,
      "loss": 0.0167,
      "step": 93080
    },
    {
      "epoch": 11.21566265060241,
      "grad_norm": 0.9990764856338501,
      "learning_rate": 8.784337349397592e-06,
      "loss": 0.007,
      "step": 93090
    },
    {
      "epoch": 11.216867469879517,
      "grad_norm": 0.030944548547267914,
      "learning_rate": 8.783132530120483e-06,
      "loss": 0.0403,
      "step": 93100
    },
    {
      "epoch": 11.218072289156627,
      "grad_norm": 0.03457058221101761,
      "learning_rate": 8.781927710843373e-06,
      "loss": 0.0106,
      "step": 93110
    },
    {
      "epoch": 11.219277108433735,
      "grad_norm": 0.6050025820732117,
      "learning_rate": 8.780722891566266e-06,
      "loss": 0.0122,
      "step": 93120
    },
    {
      "epoch": 11.220481927710843,
      "grad_norm": 0.0028045736253261566,
      "learning_rate": 8.779518072289157e-06,
      "loss": 0.0321,
      "step": 93130
    },
    {
      "epoch": 11.221686746987952,
      "grad_norm": 0.0013192357728257775,
      "learning_rate": 8.778313253012049e-06,
      "loss": 0.0103,
      "step": 93140
    },
    {
      "epoch": 11.22289156626506,
      "grad_norm": 1.4878126382827759,
      "learning_rate": 8.77710843373494e-06,
      "loss": 0.0114,
      "step": 93150
    },
    {
      "epoch": 11.224096385542168,
      "grad_norm": 1.3447293043136597,
      "learning_rate": 8.775903614457832e-06,
      "loss": 0.0133,
      "step": 93160
    },
    {
      "epoch": 11.225301204819278,
      "grad_norm": 0.3067164421081543,
      "learning_rate": 8.774698795180725e-06,
      "loss": 0.0358,
      "step": 93170
    },
    {
      "epoch": 11.226506024096386,
      "grad_norm": 0.18726418912410736,
      "learning_rate": 8.773493975903615e-06,
      "loss": 0.0261,
      "step": 93180
    },
    {
      "epoch": 11.227710843373494,
      "grad_norm": 0.701024055480957,
      "learning_rate": 8.772289156626506e-06,
      "loss": 0.0184,
      "step": 93190
    },
    {
      "epoch": 11.228915662650602,
      "grad_norm": 0.5155506730079651,
      "learning_rate": 8.771084337349399e-06,
      "loss": 0.0197,
      "step": 93200
    },
    {
      "epoch": 11.230120481927711,
      "grad_norm": 0.0022134114988148212,
      "learning_rate": 8.76987951807229e-06,
      "loss": 0.0238,
      "step": 93210
    },
    {
      "epoch": 11.23132530120482,
      "grad_norm": 0.002903259126469493,
      "learning_rate": 8.768674698795182e-06,
      "loss": 0.0493,
      "step": 93220
    },
    {
      "epoch": 11.232530120481927,
      "grad_norm": 0.0029679483268409967,
      "learning_rate": 8.767469879518074e-06,
      "loss": 0.0136,
      "step": 93230
    },
    {
      "epoch": 11.233734939759037,
      "grad_norm": 0.1731320470571518,
      "learning_rate": 8.766265060240965e-06,
      "loss": 0.0228,
      "step": 93240
    },
    {
      "epoch": 11.234939759036145,
      "grad_norm": 0.0021775541827082634,
      "learning_rate": 8.765060240963856e-06,
      "loss": 0.0165,
      "step": 93250
    },
    {
      "epoch": 11.236144578313253,
      "grad_norm": 0.09722712635993958,
      "learning_rate": 8.763855421686748e-06,
      "loss": 0.0077,
      "step": 93260
    },
    {
      "epoch": 11.23734939759036,
      "grad_norm": 0.0037122750654816628,
      "learning_rate": 8.762650602409639e-06,
      "loss": 0.0147,
      "step": 93270
    },
    {
      "epoch": 11.23855421686747,
      "grad_norm": 0.711579442024231,
      "learning_rate": 8.761445783132531e-06,
      "loss": 0.0169,
      "step": 93280
    },
    {
      "epoch": 11.239759036144578,
      "grad_norm": 0.029526999220252037,
      "learning_rate": 8.760240963855422e-06,
      "loss": 0.015,
      "step": 93290
    },
    {
      "epoch": 11.240963855421686,
      "grad_norm": 0.0016263652360066772,
      "learning_rate": 8.759036144578313e-06,
      "loss": 0.0055,
      "step": 93300
    },
    {
      "epoch": 11.242168674698796,
      "grad_norm": 0.3404550850391388,
      "learning_rate": 8.757831325301205e-06,
      "loss": 0.012,
      "step": 93310
    },
    {
      "epoch": 11.243373493975904,
      "grad_norm": 0.5583277344703674,
      "learning_rate": 8.756626506024098e-06,
      "loss": 0.0025,
      "step": 93320
    },
    {
      "epoch": 11.244578313253012,
      "grad_norm": 0.0007489339914172888,
      "learning_rate": 8.755421686746988e-06,
      "loss": 0.0068,
      "step": 93330
    },
    {
      "epoch": 11.24578313253012,
      "grad_norm": 0.04460367560386658,
      "learning_rate": 8.75421686746988e-06,
      "loss": 0.0301,
      "step": 93340
    },
    {
      "epoch": 11.24698795180723,
      "grad_norm": 0.00304857874289155,
      "learning_rate": 8.753012048192772e-06,
      "loss": 0.0206,
      "step": 93350
    },
    {
      "epoch": 11.248192771084337,
      "grad_norm": 0.002309008501470089,
      "learning_rate": 8.751807228915662e-06,
      "loss": 0.0054,
      "step": 93360
    },
    {
      "epoch": 11.249397590361445,
      "grad_norm": 0.0019755938556045294,
      "learning_rate": 8.750602409638555e-06,
      "loss": 0.0159,
      "step": 93370
    },
    {
      "epoch": 11.250602409638555,
      "grad_norm": 0.0032264709006994963,
      "learning_rate": 8.749397590361447e-06,
      "loss": 0.0039,
      "step": 93380
    },
    {
      "epoch": 11.251807228915663,
      "grad_norm": 0.47807934880256653,
      "learning_rate": 8.748192771084338e-06,
      "loss": 0.0189,
      "step": 93390
    },
    {
      "epoch": 11.25301204819277,
      "grad_norm": 0.0026018107309937477,
      "learning_rate": 8.74698795180723e-06,
      "loss": 0.0116,
      "step": 93400
    },
    {
      "epoch": 11.25421686746988,
      "grad_norm": 0.016492530703544617,
      "learning_rate": 8.745783132530121e-06,
      "loss": 0.0069,
      "step": 93410
    },
    {
      "epoch": 11.255421686746988,
      "grad_norm": 0.008208361454308033,
      "learning_rate": 8.744578313253013e-06,
      "loss": 0.0096,
      "step": 93420
    },
    {
      "epoch": 11.256626506024096,
      "grad_norm": 0.0010880378540605307,
      "learning_rate": 8.743373493975904e-06,
      "loss": 0.0053,
      "step": 93430
    },
    {
      "epoch": 11.257831325301204,
      "grad_norm": 0.0015767121221870184,
      "learning_rate": 8.742168674698795e-06,
      "loss": 0.0109,
      "step": 93440
    },
    {
      "epoch": 11.259036144578314,
      "grad_norm": 0.0023768253158777952,
      "learning_rate": 8.740963855421687e-06,
      "loss": 0.0104,
      "step": 93450
    },
    {
      "epoch": 11.260240963855422,
      "grad_norm": 0.14271371066570282,
      "learning_rate": 8.73975903614458e-06,
      "loss": 0.0211,
      "step": 93460
    },
    {
      "epoch": 11.26144578313253,
      "grad_norm": 0.0014950466575101018,
      "learning_rate": 8.73855421686747e-06,
      "loss": 0.002,
      "step": 93470
    },
    {
      "epoch": 11.26265060240964,
      "grad_norm": 0.6491562128067017,
      "learning_rate": 8.737349397590363e-06,
      "loss": 0.0495,
      "step": 93480
    },
    {
      "epoch": 11.263855421686747,
      "grad_norm": 0.0013202560367062688,
      "learning_rate": 8.736144578313254e-06,
      "loss": 0.0082,
      "step": 93490
    },
    {
      "epoch": 11.265060240963855,
      "grad_norm": 0.0018383453134447336,
      "learning_rate": 8.734939759036145e-06,
      "loss": 0.0212,
      "step": 93500
    },
    {
      "epoch": 11.266265060240963,
      "grad_norm": 0.0023829014971852303,
      "learning_rate": 8.733734939759037e-06,
      "loss": 0.0163,
      "step": 93510
    },
    {
      "epoch": 11.267469879518073,
      "grad_norm": 0.04020826518535614,
      "learning_rate": 8.732530120481928e-06,
      "loss": 0.0131,
      "step": 93520
    },
    {
      "epoch": 11.26867469879518,
      "grad_norm": 0.45966848731040955,
      "learning_rate": 8.73132530120482e-06,
      "loss": 0.0083,
      "step": 93530
    },
    {
      "epoch": 11.269879518072289,
      "grad_norm": 0.226485475897789,
      "learning_rate": 8.730120481927713e-06,
      "loss": 0.0476,
      "step": 93540
    },
    {
      "epoch": 11.271084337349398,
      "grad_norm": 0.21082527935504913,
      "learning_rate": 8.728915662650603e-06,
      "loss": 0.0449,
      "step": 93550
    },
    {
      "epoch": 11.272289156626506,
      "grad_norm": 0.811536967754364,
      "learning_rate": 8.727710843373494e-06,
      "loss": 0.0095,
      "step": 93560
    },
    {
      "epoch": 11.273493975903614,
      "grad_norm": 1.1955009698867798,
      "learning_rate": 8.726506024096386e-06,
      "loss": 0.0061,
      "step": 93570
    },
    {
      "epoch": 11.274698795180722,
      "grad_norm": 0.06239110231399536,
      "learning_rate": 8.725301204819277e-06,
      "loss": 0.0135,
      "step": 93580
    },
    {
      "epoch": 11.275903614457832,
      "grad_norm": 0.003845976432785392,
      "learning_rate": 8.72409638554217e-06,
      "loss": 0.0001,
      "step": 93590
    },
    {
      "epoch": 11.27710843373494,
      "grad_norm": 1.5020328760147095,
      "learning_rate": 8.722891566265062e-06,
      "loss": 0.0284,
      "step": 93600
    },
    {
      "epoch": 11.278313253012048,
      "grad_norm": 7.854223728179932,
      "learning_rate": 8.721686746987953e-06,
      "loss": 0.0433,
      "step": 93610
    },
    {
      "epoch": 11.279518072289157,
      "grad_norm": 0.0022783137392252684,
      "learning_rate": 8.720481927710844e-06,
      "loss": 0.0223,
      "step": 93620
    },
    {
      "epoch": 11.280722891566265,
      "grad_norm": 0.0021669575944542885,
      "learning_rate": 8.719277108433736e-06,
      "loss": 0.0142,
      "step": 93630
    },
    {
      "epoch": 11.281927710843373,
      "grad_norm": 0.004323393106460571,
      "learning_rate": 8.718072289156627e-06,
      "loss": 0.0001,
      "step": 93640
    },
    {
      "epoch": 11.283132530120483,
      "grad_norm": 0.752056360244751,
      "learning_rate": 8.71686746987952e-06,
      "loss": 0.0225,
      "step": 93650
    },
    {
      "epoch": 11.28433734939759,
      "grad_norm": 3.664746046066284,
      "learning_rate": 8.71566265060241e-06,
      "loss": 0.0165,
      "step": 93660
    },
    {
      "epoch": 11.285542168674699,
      "grad_norm": 0.006239423993974924,
      "learning_rate": 8.7144578313253e-06,
      "loss": 0.0057,
      "step": 93670
    },
    {
      "epoch": 11.286746987951807,
      "grad_norm": 0.0011694984277710319,
      "learning_rate": 8.713253012048195e-06,
      "loss": 0.0139,
      "step": 93680
    },
    {
      "epoch": 11.287951807228916,
      "grad_norm": 0.0027664087247103453,
      "learning_rate": 8.712048192771086e-06,
      "loss": 0.0429,
      "step": 93690
    },
    {
      "epoch": 11.289156626506024,
      "grad_norm": 0.002174539025872946,
      "learning_rate": 8.710843373493976e-06,
      "loss": 0.0117,
      "step": 93700
    },
    {
      "epoch": 11.290361445783132,
      "grad_norm": 2.698071241378784,
      "learning_rate": 8.709638554216869e-06,
      "loss": 0.0294,
      "step": 93710
    },
    {
      "epoch": 11.291566265060242,
      "grad_norm": 0.624859631061554,
      "learning_rate": 8.70843373493976e-06,
      "loss": 0.0005,
      "step": 93720
    },
    {
      "epoch": 11.29277108433735,
      "grad_norm": 0.0024143813643604517,
      "learning_rate": 8.707228915662652e-06,
      "loss": 0.0141,
      "step": 93730
    },
    {
      "epoch": 11.293975903614458,
      "grad_norm": 1.4653408527374268,
      "learning_rate": 8.706024096385543e-06,
      "loss": 0.0407,
      "step": 93740
    },
    {
      "epoch": 11.295180722891565,
      "grad_norm": 0.002097473479807377,
      "learning_rate": 8.704819277108435e-06,
      "loss": 0.0014,
      "step": 93750
    },
    {
      "epoch": 11.296385542168675,
      "grad_norm": 0.30420807003974915,
      "learning_rate": 8.703614457831326e-06,
      "loss": 0.0152,
      "step": 93760
    },
    {
      "epoch": 11.297590361445783,
      "grad_norm": 0.0019660943653434515,
      "learning_rate": 8.702409638554218e-06,
      "loss": 0.0001,
      "step": 93770
    },
    {
      "epoch": 11.298795180722891,
      "grad_norm": 6.542891979217529,
      "learning_rate": 8.701204819277109e-06,
      "loss": 0.0302,
      "step": 93780
    },
    {
      "epoch": 11.3,
      "grad_norm": 0.0018966810312122107,
      "learning_rate": 8.700000000000001e-06,
      "loss": 0.009,
      "step": 93790
    },
    {
      "epoch": 11.301204819277109,
      "grad_norm": 2.1341700553894043,
      "learning_rate": 8.698795180722892e-06,
      "loss": 0.0044,
      "step": 93800
    },
    {
      "epoch": 11.302409638554217,
      "grad_norm": 0.002070769900456071,
      "learning_rate": 8.697590361445783e-06,
      "loss": 0.0007,
      "step": 93810
    },
    {
      "epoch": 11.303614457831324,
      "grad_norm": 0.004954710602760315,
      "learning_rate": 8.696385542168675e-06,
      "loss": 0.0281,
      "step": 93820
    },
    {
      "epoch": 11.304819277108434,
      "grad_norm": 0.004394382704049349,
      "learning_rate": 8.695180722891568e-06,
      "loss": 0.0115,
      "step": 93830
    },
    {
      "epoch": 11.306024096385542,
      "grad_norm": 0.19837184250354767,
      "learning_rate": 8.693975903614458e-06,
      "loss": 0.0274,
      "step": 93840
    },
    {
      "epoch": 11.30722891566265,
      "grad_norm": 0.004308641422539949,
      "learning_rate": 8.692771084337351e-06,
      "loss": 0.0018,
      "step": 93850
    },
    {
      "epoch": 11.30843373493976,
      "grad_norm": 0.12698769569396973,
      "learning_rate": 8.691566265060242e-06,
      "loss": 0.0284,
      "step": 93860
    },
    {
      "epoch": 11.309638554216868,
      "grad_norm": 0.3168146014213562,
      "learning_rate": 8.690361445783132e-06,
      "loss": 0.0178,
      "step": 93870
    },
    {
      "epoch": 11.310843373493976,
      "grad_norm": 0.0036130198277533054,
      "learning_rate": 8.689156626506025e-06,
      "loss": 0.0211,
      "step": 93880
    },
    {
      "epoch": 11.312048192771085,
      "grad_norm": 0.0022708154283463955,
      "learning_rate": 8.687951807228916e-06,
      "loss": 0.0158,
      "step": 93890
    },
    {
      "epoch": 11.313253012048193,
      "grad_norm": 8.595223426818848,
      "learning_rate": 8.686746987951808e-06,
      "loss": 0.019,
      "step": 93900
    },
    {
      "epoch": 11.314457831325301,
      "grad_norm": 0.025509128347039223,
      "learning_rate": 8.6855421686747e-06,
      "loss": 0.0213,
      "step": 93910
    },
    {
      "epoch": 11.315662650602409,
      "grad_norm": 0.0034399721771478653,
      "learning_rate": 8.684337349397591e-06,
      "loss": 0.011,
      "step": 93920
    },
    {
      "epoch": 11.316867469879519,
      "grad_norm": 2.098458766937256,
      "learning_rate": 8.683132530120482e-06,
      "loss": 0.0196,
      "step": 93930
    },
    {
      "epoch": 11.318072289156627,
      "grad_norm": 0.007608586456626654,
      "learning_rate": 8.681927710843374e-06,
      "loss": 0.0723,
      "step": 93940
    },
    {
      "epoch": 11.319277108433734,
      "grad_norm": 0.06497035175561905,
      "learning_rate": 8.680722891566265e-06,
      "loss": 0.0122,
      "step": 93950
    },
    {
      "epoch": 11.320481927710844,
      "grad_norm": 0.006693718023598194,
      "learning_rate": 8.679518072289158e-06,
      "loss": 0.0235,
      "step": 93960
    },
    {
      "epoch": 11.321686746987952,
      "grad_norm": 0.005530507303774357,
      "learning_rate": 8.678313253012048e-06,
      "loss": 0.0079,
      "step": 93970
    },
    {
      "epoch": 11.32289156626506,
      "grad_norm": 0.007063784636557102,
      "learning_rate": 8.67710843373494e-06,
      "loss": 0.0304,
      "step": 93980
    },
    {
      "epoch": 11.324096385542168,
      "grad_norm": 1.9927737712860107,
      "learning_rate": 8.675903614457833e-06,
      "loss": 0.0446,
      "step": 93990
    },
    {
      "epoch": 11.325301204819278,
      "grad_norm": 0.004105847794562578,
      "learning_rate": 8.674698795180724e-06,
      "loss": 0.0563,
      "step": 94000
    },
    {
      "epoch": 11.326506024096386,
      "grad_norm": 0.05140363425016403,
      "learning_rate": 8.673493975903615e-06,
      "loss": 0.0035,
      "step": 94010
    },
    {
      "epoch": 11.327710843373493,
      "grad_norm": 0.0011706579243764281,
      "learning_rate": 8.672289156626507e-06,
      "loss": 0.0018,
      "step": 94020
    },
    {
      "epoch": 11.328915662650603,
      "grad_norm": 0.0412752628326416,
      "learning_rate": 8.671084337349398e-06,
      "loss": 0.0044,
      "step": 94030
    },
    {
      "epoch": 11.330120481927711,
      "grad_norm": 0.005034747067838907,
      "learning_rate": 8.66987951807229e-06,
      "loss": 0.0125,
      "step": 94040
    },
    {
      "epoch": 11.331325301204819,
      "grad_norm": 3.110341787338257,
      "learning_rate": 8.668674698795183e-06,
      "loss": 0.0144,
      "step": 94050
    },
    {
      "epoch": 11.332530120481927,
      "grad_norm": 0.0016050611156970263,
      "learning_rate": 8.667469879518073e-06,
      "loss": 0.0171,
      "step": 94060
    },
    {
      "epoch": 11.333734939759037,
      "grad_norm": 1.5342289209365845,
      "learning_rate": 8.666265060240964e-06,
      "loss": 0.0061,
      "step": 94070
    },
    {
      "epoch": 11.334939759036144,
      "grad_norm": 0.8634335398674011,
      "learning_rate": 8.665060240963857e-06,
      "loss": 0.037,
      "step": 94080
    },
    {
      "epoch": 11.336144578313252,
      "grad_norm": 3.042664051055908,
      "learning_rate": 8.663855421686747e-06,
      "loss": 0.0344,
      "step": 94090
    },
    {
      "epoch": 11.337349397590362,
      "grad_norm": 0.17224206030368805,
      "learning_rate": 8.66265060240964e-06,
      "loss": 0.0062,
      "step": 94100
    },
    {
      "epoch": 11.33855421686747,
      "grad_norm": 6.286049842834473,
      "learning_rate": 8.66144578313253e-06,
      "loss": 0.034,
      "step": 94110
    },
    {
      "epoch": 11.339759036144578,
      "grad_norm": 0.020027147606015205,
      "learning_rate": 8.660240963855421e-06,
      "loss": 0.0021,
      "step": 94120
    },
    {
      "epoch": 11.340963855421688,
      "grad_norm": 4.924674987792969,
      "learning_rate": 8.659036144578314e-06,
      "loss": 0.0067,
      "step": 94130
    },
    {
      "epoch": 11.342168674698796,
      "grad_norm": 0.026979219168424606,
      "learning_rate": 8.657831325301206e-06,
      "loss": 0.0235,
      "step": 94140
    },
    {
      "epoch": 11.343373493975903,
      "grad_norm": 0.016166096553206444,
      "learning_rate": 8.656626506024097e-06,
      "loss": 0.0024,
      "step": 94150
    },
    {
      "epoch": 11.344578313253011,
      "grad_norm": 0.0008250817190855742,
      "learning_rate": 8.65542168674699e-06,
      "loss": 0.0084,
      "step": 94160
    },
    {
      "epoch": 11.345783132530121,
      "grad_norm": 2.490595817565918,
      "learning_rate": 8.65421686746988e-06,
      "loss": 0.0209,
      "step": 94170
    },
    {
      "epoch": 11.346987951807229,
      "grad_norm": 0.49577799439430237,
      "learning_rate": 8.65301204819277e-06,
      "loss": 0.0141,
      "step": 94180
    },
    {
      "epoch": 11.348192771084337,
      "grad_norm": 11.300312995910645,
      "learning_rate": 8.651807228915663e-06,
      "loss": 0.0288,
      "step": 94190
    },
    {
      "epoch": 11.349397590361447,
      "grad_norm": 0.0035559965763241053,
      "learning_rate": 8.650602409638556e-06,
      "loss": 0.0239,
      "step": 94200
    },
    {
      "epoch": 11.350602409638554,
      "grad_norm": 1.3908010721206665,
      "learning_rate": 8.649397590361446e-06,
      "loss": 0.0238,
      "step": 94210
    },
    {
      "epoch": 11.351807228915662,
      "grad_norm": 0.4474624991416931,
      "learning_rate": 8.648192771084339e-06,
      "loss": 0.0434,
      "step": 94220
    },
    {
      "epoch": 11.35301204819277,
      "grad_norm": 0.16855834424495697,
      "learning_rate": 8.64698795180723e-06,
      "loss": 0.008,
      "step": 94230
    },
    {
      "epoch": 11.35421686746988,
      "grad_norm": 0.06584570556879044,
      "learning_rate": 8.64578313253012e-06,
      "loss": 0.0177,
      "step": 94240
    },
    {
      "epoch": 11.355421686746988,
      "grad_norm": 0.024985792115330696,
      "learning_rate": 8.644578313253013e-06,
      "loss": 0.0182,
      "step": 94250
    },
    {
      "epoch": 11.356626506024096,
      "grad_norm": 12.487537384033203,
      "learning_rate": 8.643373493975904e-06,
      "loss": 0.0524,
      "step": 94260
    },
    {
      "epoch": 11.357831325301206,
      "grad_norm": 0.7800722122192383,
      "learning_rate": 8.642168674698796e-06,
      "loss": 0.0167,
      "step": 94270
    },
    {
      "epoch": 11.359036144578313,
      "grad_norm": 0.0024778819642961025,
      "learning_rate": 8.640963855421688e-06,
      "loss": 0.0142,
      "step": 94280
    },
    {
      "epoch": 11.360240963855421,
      "grad_norm": 3.6508705615997314,
      "learning_rate": 8.639759036144579e-06,
      "loss": 0.0461,
      "step": 94290
    },
    {
      "epoch": 11.36144578313253,
      "grad_norm": 1.3351466655731201,
      "learning_rate": 8.638554216867472e-06,
      "loss": 0.0259,
      "step": 94300
    },
    {
      "epoch": 11.362650602409639,
      "grad_norm": 0.0010661216219887137,
      "learning_rate": 8.637349397590362e-06,
      "loss": 0.0298,
      "step": 94310
    },
    {
      "epoch": 11.363855421686747,
      "grad_norm": 0.0019924461375921965,
      "learning_rate": 8.636144578313253e-06,
      "loss": 0.0126,
      "step": 94320
    },
    {
      "epoch": 11.365060240963855,
      "grad_norm": 2.3337550163269043,
      "learning_rate": 8.634939759036145e-06,
      "loss": 0.0329,
      "step": 94330
    },
    {
      "epoch": 11.366265060240965,
      "grad_norm": 0.34462210536003113,
      "learning_rate": 8.633734939759036e-06,
      "loss": 0.0368,
      "step": 94340
    },
    {
      "epoch": 11.367469879518072,
      "grad_norm": 0.028640052303671837,
      "learning_rate": 8.632530120481929e-06,
      "loss": 0.0109,
      "step": 94350
    },
    {
      "epoch": 11.36867469879518,
      "grad_norm": 3.2802765369415283,
      "learning_rate": 8.631325301204821e-06,
      "loss": 0.0373,
      "step": 94360
    },
    {
      "epoch": 11.369879518072288,
      "grad_norm": 0.006370525807142258,
      "learning_rate": 8.630120481927712e-06,
      "loss": 0.0073,
      "step": 94370
    },
    {
      "epoch": 11.371084337349398,
      "grad_norm": 0.023877965286374092,
      "learning_rate": 8.628915662650603e-06,
      "loss": 0.0167,
      "step": 94380
    },
    {
      "epoch": 11.372289156626506,
      "grad_norm": 3.015192747116089,
      "learning_rate": 8.627710843373495e-06,
      "loss": 0.0216,
      "step": 94390
    },
    {
      "epoch": 11.373493975903614,
      "grad_norm": 0.08321132510900497,
      "learning_rate": 8.626506024096386e-06,
      "loss": 0.0103,
      "step": 94400
    },
    {
      "epoch": 11.374698795180723,
      "grad_norm": 0.06247679889202118,
      "learning_rate": 8.625301204819278e-06,
      "loss": 0.0064,
      "step": 94410
    },
    {
      "epoch": 11.375903614457831,
      "grad_norm": 1.8908393383026123,
      "learning_rate": 8.624096385542169e-06,
      "loss": 0.0368,
      "step": 94420
    },
    {
      "epoch": 11.37710843373494,
      "grad_norm": 0.001832289039157331,
      "learning_rate": 8.622891566265061e-06,
      "loss": 0.0691,
      "step": 94430
    },
    {
      "epoch": 11.378313253012049,
      "grad_norm": 0.056539904326200485,
      "learning_rate": 8.621686746987952e-06,
      "loss": 0.0427,
      "step": 94440
    },
    {
      "epoch": 11.379518072289157,
      "grad_norm": 0.03843170404434204,
      "learning_rate": 8.620481927710845e-06,
      "loss": 0.0458,
      "step": 94450
    },
    {
      "epoch": 11.380722891566265,
      "grad_norm": 8.429657936096191,
      "learning_rate": 8.619277108433735e-06,
      "loss": 0.0471,
      "step": 94460
    },
    {
      "epoch": 11.381927710843373,
      "grad_norm": 0.2335488498210907,
      "learning_rate": 8.618072289156628e-06,
      "loss": 0.0281,
      "step": 94470
    },
    {
      "epoch": 11.383132530120482,
      "grad_norm": 0.0037994433660060167,
      "learning_rate": 8.616867469879518e-06,
      "loss": 0.0384,
      "step": 94480
    },
    {
      "epoch": 11.38433734939759,
      "grad_norm": 0.03798114135861397,
      "learning_rate": 8.61566265060241e-06,
      "loss": 0.0478,
      "step": 94490
    },
    {
      "epoch": 11.385542168674698,
      "grad_norm": 0.5449817776679993,
      "learning_rate": 8.614457831325302e-06,
      "loss": 0.0056,
      "step": 94500
    },
    {
      "epoch": 11.386746987951808,
      "grad_norm": 3.4497666358947754,
      "learning_rate": 8.613253012048194e-06,
      "loss": 0.0147,
      "step": 94510
    },
    {
      "epoch": 11.387951807228916,
      "grad_norm": 4.135205268859863,
      "learning_rate": 8.612048192771085e-06,
      "loss": 0.0664,
      "step": 94520
    },
    {
      "epoch": 11.389156626506024,
      "grad_norm": 0.0025301219429820776,
      "learning_rate": 8.610843373493977e-06,
      "loss": 0.0321,
      "step": 94530
    },
    {
      "epoch": 11.390361445783132,
      "grad_norm": 1.4335153102874756,
      "learning_rate": 8.609638554216868e-06,
      "loss": 0.0183,
      "step": 94540
    },
    {
      "epoch": 11.391566265060241,
      "grad_norm": 0.5634040832519531,
      "learning_rate": 8.608433734939759e-06,
      "loss": 0.0133,
      "step": 94550
    },
    {
      "epoch": 11.39277108433735,
      "grad_norm": 0.0010626830626279116,
      "learning_rate": 8.607228915662651e-06,
      "loss": 0.0106,
      "step": 94560
    },
    {
      "epoch": 11.393975903614457,
      "grad_norm": 0.006609960924834013,
      "learning_rate": 8.606024096385542e-06,
      "loss": 0.0199,
      "step": 94570
    },
    {
      "epoch": 11.395180722891567,
      "grad_norm": 0.0008484258432872593,
      "learning_rate": 8.604819277108434e-06,
      "loss": 0.0094,
      "step": 94580
    },
    {
      "epoch": 11.396385542168675,
      "grad_norm": 0.00354379671625793,
      "learning_rate": 8.603614457831327e-06,
      "loss": 0.0142,
      "step": 94590
    },
    {
      "epoch": 11.397590361445783,
      "grad_norm": 1.3926411867141724,
      "learning_rate": 8.602409638554217e-06,
      "loss": 0.006,
      "step": 94600
    },
    {
      "epoch": 11.398795180722892,
      "grad_norm": 7.893967628479004,
      "learning_rate": 8.60120481927711e-06,
      "loss": 0.0268,
      "step": 94610
    },
    {
      "epoch": 11.4,
      "grad_norm": 1.928209662437439,
      "learning_rate": 8.6e-06,
      "loss": 0.0269,
      "step": 94620
    },
    {
      "epoch": 11.401204819277108,
      "grad_norm": 0.021463265642523766,
      "learning_rate": 8.598795180722891e-06,
      "loss": 0.0001,
      "step": 94630
    },
    {
      "epoch": 11.402409638554216,
      "grad_norm": 0.0031188034918159246,
      "learning_rate": 8.597590361445784e-06,
      "loss": 0.0302,
      "step": 94640
    },
    {
      "epoch": 11.403614457831326,
      "grad_norm": 0.3777763247489929,
      "learning_rate": 8.596385542168676e-06,
      "loss": 0.0212,
      "step": 94650
    },
    {
      "epoch": 11.404819277108434,
      "grad_norm": 0.0883612409234047,
      "learning_rate": 8.595180722891567e-06,
      "loss": 0.0146,
      "step": 94660
    },
    {
      "epoch": 11.406024096385542,
      "grad_norm": 0.003788330126553774,
      "learning_rate": 8.59397590361446e-06,
      "loss": 0.0374,
      "step": 94670
    },
    {
      "epoch": 11.407228915662651,
      "grad_norm": 0.05054119974374771,
      "learning_rate": 8.59277108433735e-06,
      "loss": 0.0153,
      "step": 94680
    },
    {
      "epoch": 11.40843373493976,
      "grad_norm": 0.01880946010351181,
      "learning_rate": 8.591566265060241e-06,
      "loss": 0.0138,
      "step": 94690
    },
    {
      "epoch": 11.409638554216867,
      "grad_norm": 1.2336513996124268,
      "learning_rate": 8.590361445783133e-06,
      "loss": 0.0398,
      "step": 94700
    },
    {
      "epoch": 11.410843373493975,
      "grad_norm": 0.0024901495780795813,
      "learning_rate": 8.589156626506024e-06,
      "loss": 0.0104,
      "step": 94710
    },
    {
      "epoch": 11.412048192771085,
      "grad_norm": 0.0016904358053579926,
      "learning_rate": 8.587951807228917e-06,
      "loss": 0.0041,
      "step": 94720
    },
    {
      "epoch": 11.413253012048193,
      "grad_norm": 0.027763009071350098,
      "learning_rate": 8.586746987951809e-06,
      "loss": 0.0072,
      "step": 94730
    },
    {
      "epoch": 11.4144578313253,
      "grad_norm": 0.001824759179726243,
      "learning_rate": 8.5855421686747e-06,
      "loss": 0.0054,
      "step": 94740
    },
    {
      "epoch": 11.41566265060241,
      "grad_norm": 0.0008218616130761802,
      "learning_rate": 8.58433734939759e-06,
      "loss": 0.0127,
      "step": 94750
    },
    {
      "epoch": 11.416867469879518,
      "grad_norm": 0.01165353786200285,
      "learning_rate": 8.583132530120483e-06,
      "loss": 0.0099,
      "step": 94760
    },
    {
      "epoch": 11.418072289156626,
      "grad_norm": 0.0380510650575161,
      "learning_rate": 8.581927710843374e-06,
      "loss": 0.0185,
      "step": 94770
    },
    {
      "epoch": 11.419277108433734,
      "grad_norm": 0.001190681243315339,
      "learning_rate": 8.580722891566266e-06,
      "loss": 0.0101,
      "step": 94780
    },
    {
      "epoch": 11.420481927710844,
      "grad_norm": 0.0008823158568702638,
      "learning_rate": 8.579518072289157e-06,
      "loss": 0.0193,
      "step": 94790
    },
    {
      "epoch": 11.421686746987952,
      "grad_norm": 20.041488647460938,
      "learning_rate": 8.57831325301205e-06,
      "loss": 0.0449,
      "step": 94800
    },
    {
      "epoch": 11.42289156626506,
      "grad_norm": 0.9970197677612305,
      "learning_rate": 8.577108433734942e-06,
      "loss": 0.0055,
      "step": 94810
    },
    {
      "epoch": 11.42409638554217,
      "grad_norm": 0.00292542134411633,
      "learning_rate": 8.575903614457832e-06,
      "loss": 0.0248,
      "step": 94820
    },
    {
      "epoch": 11.425301204819277,
      "grad_norm": 0.0011319430777803063,
      "learning_rate": 8.574698795180723e-06,
      "loss": 0.0096,
      "step": 94830
    },
    {
      "epoch": 11.426506024096385,
      "grad_norm": 0.0015934325056150556,
      "learning_rate": 8.573493975903616e-06,
      "loss": 0.0207,
      "step": 94840
    },
    {
      "epoch": 11.427710843373493,
      "grad_norm": 1.016810655593872,
      "learning_rate": 8.572289156626506e-06,
      "loss": 0.0125,
      "step": 94850
    },
    {
      "epoch": 11.428915662650603,
      "grad_norm": 0.018735740333795547,
      "learning_rate": 8.571084337349397e-06,
      "loss": 0.0712,
      "step": 94860
    },
    {
      "epoch": 11.43012048192771,
      "grad_norm": 0.011403331533074379,
      "learning_rate": 8.56987951807229e-06,
      "loss": 0.0072,
      "step": 94870
    },
    {
      "epoch": 11.431325301204819,
      "grad_norm": 1.5692403316497803,
      "learning_rate": 8.568674698795182e-06,
      "loss": 0.0159,
      "step": 94880
    },
    {
      "epoch": 11.432530120481928,
      "grad_norm": 0.8375247120857239,
      "learning_rate": 8.567469879518073e-06,
      "loss": 0.0157,
      "step": 94890
    },
    {
      "epoch": 11.433734939759036,
      "grad_norm": 7.895542621612549,
      "learning_rate": 8.566265060240965e-06,
      "loss": 0.0882,
      "step": 94900
    },
    {
      "epoch": 11.434939759036144,
      "grad_norm": 0.008490289561450481,
      "learning_rate": 8.565060240963856e-06,
      "loss": 0.0313,
      "step": 94910
    },
    {
      "epoch": 11.436144578313254,
      "grad_norm": 1.3109537363052368,
      "learning_rate": 8.563855421686748e-06,
      "loss": 0.0082,
      "step": 94920
    },
    {
      "epoch": 11.437349397590362,
      "grad_norm": 0.011991139501333237,
      "learning_rate": 8.562650602409639e-06,
      "loss": 0.0047,
      "step": 94930
    },
    {
      "epoch": 11.43855421686747,
      "grad_norm": 1.107010841369629,
      "learning_rate": 8.56144578313253e-06,
      "loss": 0.0112,
      "step": 94940
    },
    {
      "epoch": 11.439759036144578,
      "grad_norm": 0.007322781253606081,
      "learning_rate": 8.560240963855422e-06,
      "loss": 0.0813,
      "step": 94950
    },
    {
      "epoch": 11.440963855421687,
      "grad_norm": 0.007512880023568869,
      "learning_rate": 8.559036144578315e-06,
      "loss": 0.0067,
      "step": 94960
    },
    {
      "epoch": 11.442168674698795,
      "grad_norm": 0.003249522764235735,
      "learning_rate": 8.557831325301205e-06,
      "loss": 0.0166,
      "step": 94970
    },
    {
      "epoch": 11.443373493975903,
      "grad_norm": 0.004569340031594038,
      "learning_rate": 8.556626506024098e-06,
      "loss": 0.0075,
      "step": 94980
    },
    {
      "epoch": 11.444578313253013,
      "grad_norm": 0.006099827587604523,
      "learning_rate": 8.555421686746989e-06,
      "loss": 0.0069,
      "step": 94990
    },
    {
      "epoch": 11.44578313253012,
      "grad_norm": 0.0026816760655492544,
      "learning_rate": 8.55421686746988e-06,
      "loss": 0.0318,
      "step": 95000
    },
    {
      "epoch": 11.446987951807229,
      "grad_norm": 0.2888098359107971,
      "learning_rate": 8.553012048192772e-06,
      "loss": 0.0292,
      "step": 95010
    },
    {
      "epoch": 11.448192771084337,
      "grad_norm": 0.026975393295288086,
      "learning_rate": 8.551807228915662e-06,
      "loss": 0.0034,
      "step": 95020
    },
    {
      "epoch": 11.449397590361446,
      "grad_norm": 0.0032041294034570456,
      "learning_rate": 8.550602409638555e-06,
      "loss": 0.0072,
      "step": 95030
    },
    {
      "epoch": 11.450602409638554,
      "grad_norm": 0.0035480500664561987,
      "learning_rate": 8.549397590361447e-06,
      "loss": 0.0574,
      "step": 95040
    },
    {
      "epoch": 11.451807228915662,
      "grad_norm": 0.004636102356016636,
      "learning_rate": 8.548192771084338e-06,
      "loss": 0.0076,
      "step": 95050
    },
    {
      "epoch": 11.453012048192772,
      "grad_norm": 0.010686495341360569,
      "learning_rate": 8.546987951807229e-06,
      "loss": 0.0075,
      "step": 95060
    },
    {
      "epoch": 11.45421686746988,
      "grad_norm": 0.024462979286909103,
      "learning_rate": 8.545783132530121e-06,
      "loss": 0.0182,
      "step": 95070
    },
    {
      "epoch": 11.455421686746988,
      "grad_norm": 0.009212075732648373,
      "learning_rate": 8.544578313253012e-06,
      "loss": 0.008,
      "step": 95080
    },
    {
      "epoch": 11.456626506024097,
      "grad_norm": 0.0092544574290514,
      "learning_rate": 8.543373493975904e-06,
      "loss": 0.0112,
      "step": 95090
    },
    {
      "epoch": 11.457831325301205,
      "grad_norm": 0.05896768718957901,
      "learning_rate": 8.542168674698797e-06,
      "loss": 0.0282,
      "step": 95100
    },
    {
      "epoch": 11.459036144578313,
      "grad_norm": 0.004259212873876095,
      "learning_rate": 8.540963855421688e-06,
      "loss": 0.0646,
      "step": 95110
    },
    {
      "epoch": 11.460240963855421,
      "grad_norm": 0.020551834255456924,
      "learning_rate": 8.53975903614458e-06,
      "loss": 0.0091,
      "step": 95120
    },
    {
      "epoch": 11.46144578313253,
      "grad_norm": 1.2558194398880005,
      "learning_rate": 8.53855421686747e-06,
      "loss": 0.005,
      "step": 95130
    },
    {
      "epoch": 11.462650602409639,
      "grad_norm": 1.2423696517944336,
      "learning_rate": 8.537349397590362e-06,
      "loss": 0.0127,
      "step": 95140
    },
    {
      "epoch": 11.463855421686747,
      "grad_norm": 0.002162975026294589,
      "learning_rate": 8.536144578313254e-06,
      "loss": 0.027,
      "step": 95150
    },
    {
      "epoch": 11.465060240963856,
      "grad_norm": 6.32047700881958,
      "learning_rate": 8.534939759036145e-06,
      "loss": 0.0324,
      "step": 95160
    },
    {
      "epoch": 11.466265060240964,
      "grad_norm": 0.0692916214466095,
      "learning_rate": 8.533734939759037e-06,
      "loss": 0.024,
      "step": 95170
    },
    {
      "epoch": 11.467469879518072,
      "grad_norm": 0.04250723123550415,
      "learning_rate": 8.53253012048193e-06,
      "loss": 0.0048,
      "step": 95180
    },
    {
      "epoch": 11.46867469879518,
      "grad_norm": 0.00764826126396656,
      "learning_rate": 8.53132530120482e-06,
      "loss": 0.0142,
      "step": 95190
    },
    {
      "epoch": 11.46987951807229,
      "grad_norm": 0.009740585461258888,
      "learning_rate": 8.530120481927711e-06,
      "loss": 0.0363,
      "step": 95200
    },
    {
      "epoch": 11.471084337349398,
      "grad_norm": 2.1201632022857666,
      "learning_rate": 8.528915662650604e-06,
      "loss": 0.0111,
      "step": 95210
    },
    {
      "epoch": 11.472289156626506,
      "grad_norm": 1.3981903791427612,
      "learning_rate": 8.527710843373494e-06,
      "loss": 0.0349,
      "step": 95220
    },
    {
      "epoch": 11.473493975903615,
      "grad_norm": 0.0025811903178691864,
      "learning_rate": 8.526506024096387e-06,
      "loss": 0.0099,
      "step": 95230
    },
    {
      "epoch": 11.474698795180723,
      "grad_norm": 0.004354854114353657,
      "learning_rate": 8.525301204819277e-06,
      "loss": 0.004,
      "step": 95240
    },
    {
      "epoch": 11.475903614457831,
      "grad_norm": 0.0021192131098359823,
      "learning_rate": 8.52409638554217e-06,
      "loss": 0.0294,
      "step": 95250
    },
    {
      "epoch": 11.477108433734939,
      "grad_norm": 0.14631588757038116,
      "learning_rate": 8.52289156626506e-06,
      "loss": 0.0095,
      "step": 95260
    },
    {
      "epoch": 11.478313253012049,
      "grad_norm": 1.0953205823898315,
      "learning_rate": 8.521686746987953e-06,
      "loss": 0.0184,
      "step": 95270
    },
    {
      "epoch": 11.479518072289157,
      "grad_norm": 0.16592895984649658,
      "learning_rate": 8.520481927710844e-06,
      "loss": 0.0031,
      "step": 95280
    },
    {
      "epoch": 11.480722891566264,
      "grad_norm": 0.0025737357791513205,
      "learning_rate": 8.519277108433736e-06,
      "loss": 0.009,
      "step": 95290
    },
    {
      "epoch": 11.481927710843374,
      "grad_norm": 0.0008202352910302579,
      "learning_rate": 8.518072289156627e-06,
      "loss": 0.0184,
      "step": 95300
    },
    {
      "epoch": 11.483132530120482,
      "grad_norm": 0.0014024673728272319,
      "learning_rate": 8.516867469879518e-06,
      "loss": 0.0153,
      "step": 95310
    },
    {
      "epoch": 11.48433734939759,
      "grad_norm": 0.8712357878684998,
      "learning_rate": 8.51566265060241e-06,
      "loss": 0.0108,
      "step": 95320
    },
    {
      "epoch": 11.485542168674698,
      "grad_norm": 2.4573347568511963,
      "learning_rate": 8.514457831325303e-06,
      "loss": 0.0701,
      "step": 95330
    },
    {
      "epoch": 11.486746987951808,
      "grad_norm": 0.03552154079079628,
      "learning_rate": 8.513253012048193e-06,
      "loss": 0.004,
      "step": 95340
    },
    {
      "epoch": 11.487951807228916,
      "grad_norm": 0.13852493464946747,
      "learning_rate": 8.512048192771086e-06,
      "loss": 0.0121,
      "step": 95350
    },
    {
      "epoch": 11.489156626506023,
      "grad_norm": 0.00144680286757648,
      "learning_rate": 8.510843373493976e-06,
      "loss": 0.0241,
      "step": 95360
    },
    {
      "epoch": 11.490361445783133,
      "grad_norm": 0.011768849566578865,
      "learning_rate": 8.509638554216867e-06,
      "loss": 0.0709,
      "step": 95370
    },
    {
      "epoch": 11.491566265060241,
      "grad_norm": 3.7837603092193604,
      "learning_rate": 8.50843373493976e-06,
      "loss": 0.0398,
      "step": 95380
    },
    {
      "epoch": 11.492771084337349,
      "grad_norm": 0.010967915877699852,
      "learning_rate": 8.50722891566265e-06,
      "loss": 0.0116,
      "step": 95390
    },
    {
      "epoch": 11.493975903614459,
      "grad_norm": 1.9321701526641846,
      "learning_rate": 8.506024096385543e-06,
      "loss": 0.0321,
      "step": 95400
    },
    {
      "epoch": 11.495180722891567,
      "grad_norm": 0.009874345734715462,
      "learning_rate": 8.504819277108435e-06,
      "loss": 0.0048,
      "step": 95410
    },
    {
      "epoch": 11.496385542168674,
      "grad_norm": 0.005574946291744709,
      "learning_rate": 8.503614457831326e-06,
      "loss": 0.0501,
      "step": 95420
    },
    {
      "epoch": 11.497590361445782,
      "grad_norm": 0.22016648948192596,
      "learning_rate": 8.502409638554218e-06,
      "loss": 0.0101,
      "step": 95430
    },
    {
      "epoch": 11.498795180722892,
      "grad_norm": 0.0051187677308917046,
      "learning_rate": 8.50120481927711e-06,
      "loss": 0.0095,
      "step": 95440
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.00545013602823019,
      "learning_rate": 8.5e-06,
      "loss": 0.0038,
      "step": 95450
    },
    {
      "epoch": 11.501204819277108,
      "grad_norm": 0.0026221205480396748,
      "learning_rate": 8.498795180722892e-06,
      "loss": 0.0433,
      "step": 95460
    },
    {
      "epoch": 11.502409638554218,
      "grad_norm": 0.043277762830257416,
      "learning_rate": 8.497590361445783e-06,
      "loss": 0.0072,
      "step": 95470
    },
    {
      "epoch": 11.503614457831326,
      "grad_norm": 0.001554393325932324,
      "learning_rate": 8.496385542168676e-06,
      "loss": 0.0282,
      "step": 95480
    },
    {
      "epoch": 11.504819277108433,
      "grad_norm": 0.008174174465239048,
      "learning_rate": 8.495180722891568e-06,
      "loss": 0.0105,
      "step": 95490
    },
    {
      "epoch": 11.506024096385541,
      "grad_norm": 0.003286142135038972,
      "learning_rate": 8.493975903614459e-06,
      "loss": 0.0236,
      "step": 95500
    },
    {
      "epoch": 11.507228915662651,
      "grad_norm": 0.9699862003326416,
      "learning_rate": 8.49277108433735e-06,
      "loss": 0.0034,
      "step": 95510
    },
    {
      "epoch": 11.508433734939759,
      "grad_norm": 0.001994941383600235,
      "learning_rate": 8.491566265060242e-06,
      "loss": 0.0287,
      "step": 95520
    },
    {
      "epoch": 11.509638554216867,
      "grad_norm": 0.0366324707865715,
      "learning_rate": 8.490361445783133e-06,
      "loss": 0.0097,
      "step": 95530
    },
    {
      "epoch": 11.510843373493977,
      "grad_norm": 0.0006249208236113191,
      "learning_rate": 8.489156626506025e-06,
      "loss": 0.0258,
      "step": 95540
    },
    {
      "epoch": 11.512048192771084,
      "grad_norm": 0.6380181908607483,
      "learning_rate": 8.487951807228918e-06,
      "loss": 0.0067,
      "step": 95550
    },
    {
      "epoch": 11.513253012048192,
      "grad_norm": 0.03869209066033363,
      "learning_rate": 8.486746987951808e-06,
      "loss": 0.0068,
      "step": 95560
    },
    {
      "epoch": 11.514457831325302,
      "grad_norm": 0.025907306000590324,
      "learning_rate": 8.485542168674699e-06,
      "loss": 0.0081,
      "step": 95570
    },
    {
      "epoch": 11.51566265060241,
      "grad_norm": 2.7706427574157715,
      "learning_rate": 8.484337349397591e-06,
      "loss": 0.016,
      "step": 95580
    },
    {
      "epoch": 11.516867469879518,
      "grad_norm": 0.38069918751716614,
      "learning_rate": 8.483132530120482e-06,
      "loss": 0.0199,
      "step": 95590
    },
    {
      "epoch": 11.518072289156626,
      "grad_norm": 0.026344913989305496,
      "learning_rate": 8.481927710843375e-06,
      "loss": 0.0164,
      "step": 95600
    },
    {
      "epoch": 11.519277108433736,
      "grad_norm": 0.0007809606613591313,
      "learning_rate": 8.480722891566265e-06,
      "loss": 0.0314,
      "step": 95610
    },
    {
      "epoch": 11.520481927710843,
      "grad_norm": 0.004003423266112804,
      "learning_rate": 8.479518072289156e-06,
      "loss": 0.0551,
      "step": 95620
    },
    {
      "epoch": 11.521686746987951,
      "grad_norm": 0.003696966450661421,
      "learning_rate": 8.478313253012049e-06,
      "loss": 0.0117,
      "step": 95630
    },
    {
      "epoch": 11.522891566265061,
      "grad_norm": 0.0037887333892285824,
      "learning_rate": 8.477108433734941e-06,
      "loss": 0.0051,
      "step": 95640
    },
    {
      "epoch": 11.524096385542169,
      "grad_norm": 0.6127136945724487,
      "learning_rate": 8.475903614457832e-06,
      "loss": 0.0319,
      "step": 95650
    },
    {
      "epoch": 11.525301204819277,
      "grad_norm": 0.00875594187527895,
      "learning_rate": 8.474698795180724e-06,
      "loss": 0.0055,
      "step": 95660
    },
    {
      "epoch": 11.526506024096385,
      "grad_norm": 0.010223419405519962,
      "learning_rate": 8.473493975903615e-06,
      "loss": 0.0309,
      "step": 95670
    },
    {
      "epoch": 11.527710843373494,
      "grad_norm": 0.0015508816577494144,
      "learning_rate": 8.472289156626506e-06,
      "loss": 0.0059,
      "step": 95680
    },
    {
      "epoch": 11.528915662650602,
      "grad_norm": 0.0014845725381746888,
      "learning_rate": 8.471084337349398e-06,
      "loss": 0.0169,
      "step": 95690
    },
    {
      "epoch": 11.53012048192771,
      "grad_norm": 0.011699286289513111,
      "learning_rate": 8.46987951807229e-06,
      "loss": 0.0383,
      "step": 95700
    },
    {
      "epoch": 11.53132530120482,
      "grad_norm": 0.04076331853866577,
      "learning_rate": 8.468674698795181e-06,
      "loss": 0.0294,
      "step": 95710
    },
    {
      "epoch": 11.532530120481928,
      "grad_norm": 3.7023956775665283,
      "learning_rate": 8.467469879518074e-06,
      "loss": 0.0332,
      "step": 95720
    },
    {
      "epoch": 11.533734939759036,
      "grad_norm": 0.15625646710395813,
      "learning_rate": 8.466265060240964e-06,
      "loss": 0.0087,
      "step": 95730
    },
    {
      "epoch": 11.534939759036144,
      "grad_norm": 0.0041228244081139565,
      "learning_rate": 8.465060240963857e-06,
      "loss": 0.0372,
      "step": 95740
    },
    {
      "epoch": 11.536144578313253,
      "grad_norm": 0.006675407290458679,
      "learning_rate": 8.463855421686748e-06,
      "loss": 0.0425,
      "step": 95750
    },
    {
      "epoch": 11.537349397590361,
      "grad_norm": 0.07145186513662338,
      "learning_rate": 8.462650602409638e-06,
      "loss": 0.0006,
      "step": 95760
    },
    {
      "epoch": 11.53855421686747,
      "grad_norm": 0.004215702880173922,
      "learning_rate": 8.46144578313253e-06,
      "loss": 0.0052,
      "step": 95770
    },
    {
      "epoch": 11.539759036144579,
      "grad_norm": 1.3902301788330078,
      "learning_rate": 8.460240963855423e-06,
      "loss": 0.0047,
      "step": 95780
    },
    {
      "epoch": 11.540963855421687,
      "grad_norm": 0.025459563359618187,
      "learning_rate": 8.459036144578314e-06,
      "loss": 0.0138,
      "step": 95790
    },
    {
      "epoch": 11.542168674698795,
      "grad_norm": 3.2151498794555664,
      "learning_rate": 8.457831325301206e-06,
      "loss": 0.0251,
      "step": 95800
    },
    {
      "epoch": 11.543373493975903,
      "grad_norm": 0.005754866171628237,
      "learning_rate": 8.456626506024097e-06,
      "loss": 0.0038,
      "step": 95810
    },
    {
      "epoch": 11.544578313253012,
      "grad_norm": 0.08563890308141708,
      "learning_rate": 8.455421686746988e-06,
      "loss": 0.0196,
      "step": 95820
    },
    {
      "epoch": 11.54578313253012,
      "grad_norm": 2.422065258026123,
      "learning_rate": 8.45421686746988e-06,
      "loss": 0.0171,
      "step": 95830
    },
    {
      "epoch": 11.546987951807228,
      "grad_norm": 0.0015506992349401116,
      "learning_rate": 8.453012048192771e-06,
      "loss": 0.0563,
      "step": 95840
    },
    {
      "epoch": 11.548192771084338,
      "grad_norm": 0.7564984560012817,
      "learning_rate": 8.451807228915663e-06,
      "loss": 0.0121,
      "step": 95850
    },
    {
      "epoch": 11.549397590361446,
      "grad_norm": 1.619901418685913,
      "learning_rate": 8.450602409638556e-06,
      "loss": 0.0338,
      "step": 95860
    },
    {
      "epoch": 11.550602409638554,
      "grad_norm": 0.0348070003092289,
      "learning_rate": 8.449397590361447e-06,
      "loss": 0.0126,
      "step": 95870
    },
    {
      "epoch": 11.551807228915663,
      "grad_norm": 0.7268355488777161,
      "learning_rate": 8.448192771084337e-06,
      "loss": 0.0035,
      "step": 95880
    },
    {
      "epoch": 11.553012048192771,
      "grad_norm": 0.018783725798130035,
      "learning_rate": 8.44698795180723e-06,
      "loss": 0.0159,
      "step": 95890
    },
    {
      "epoch": 11.55421686746988,
      "grad_norm": 0.002164107747375965,
      "learning_rate": 8.44578313253012e-06,
      "loss": 0.0531,
      "step": 95900
    },
    {
      "epoch": 11.555421686746987,
      "grad_norm": 0.0265947338193655,
      "learning_rate": 8.444578313253013e-06,
      "loss": 0.015,
      "step": 95910
    },
    {
      "epoch": 11.556626506024097,
      "grad_norm": 0.4659450352191925,
      "learning_rate": 8.443373493975904e-06,
      "loss": 0.0338,
      "step": 95920
    },
    {
      "epoch": 11.557831325301205,
      "grad_norm": 1.8965696096420288,
      "learning_rate": 8.442168674698796e-06,
      "loss": 0.0275,
      "step": 95930
    },
    {
      "epoch": 11.559036144578313,
      "grad_norm": 0.0009319050004705787,
      "learning_rate": 8.440963855421687e-06,
      "loss": 0.025,
      "step": 95940
    },
    {
      "epoch": 11.560240963855422,
      "grad_norm": 1.3026145696640015,
      "learning_rate": 8.43975903614458e-06,
      "loss": 0.0098,
      "step": 95950
    },
    {
      "epoch": 11.56144578313253,
      "grad_norm": 0.012702659703791142,
      "learning_rate": 8.43855421686747e-06,
      "loss": 0.0162,
      "step": 95960
    },
    {
      "epoch": 11.562650602409638,
      "grad_norm": 3.9943037033081055,
      "learning_rate": 8.437349397590363e-06,
      "loss": 0.0188,
      "step": 95970
    },
    {
      "epoch": 11.563855421686746,
      "grad_norm": 0.4054509401321411,
      "learning_rate": 8.436144578313253e-06,
      "loss": 0.0183,
      "step": 95980
    },
    {
      "epoch": 11.565060240963856,
      "grad_norm": 0.0020360422786325216,
      "learning_rate": 8.434939759036144e-06,
      "loss": 0.0238,
      "step": 95990
    },
    {
      "epoch": 11.566265060240964,
      "grad_norm": 0.5545036196708679,
      "learning_rate": 8.433734939759038e-06,
      "loss": 0.0093,
      "step": 96000
    },
    {
      "epoch": 11.567469879518072,
      "grad_norm": 0.0005544826271943748,
      "learning_rate": 8.432530120481929e-06,
      "loss": 0.0467,
      "step": 96010
    },
    {
      "epoch": 11.568674698795181,
      "grad_norm": 7.009034633636475,
      "learning_rate": 8.43132530120482e-06,
      "loss": 0.0242,
      "step": 96020
    },
    {
      "epoch": 11.56987951807229,
      "grad_norm": 0.6630199551582336,
      "learning_rate": 8.430120481927712e-06,
      "loss": 0.0088,
      "step": 96030
    },
    {
      "epoch": 11.571084337349397,
      "grad_norm": 0.0008464275742881,
      "learning_rate": 8.428915662650603e-06,
      "loss": 0.0244,
      "step": 96040
    },
    {
      "epoch": 11.572289156626507,
      "grad_norm": 0.008712009526789188,
      "learning_rate": 8.427710843373495e-06,
      "loss": 0.0059,
      "step": 96050
    },
    {
      "epoch": 11.573493975903615,
      "grad_norm": 2.8165130615234375,
      "learning_rate": 8.426506024096386e-06,
      "loss": 0.0666,
      "step": 96060
    },
    {
      "epoch": 11.574698795180723,
      "grad_norm": 0.06058516725897789,
      "learning_rate": 8.425301204819277e-06,
      "loss": 0.0479,
      "step": 96070
    },
    {
      "epoch": 11.57590361445783,
      "grad_norm": 0.04320216178894043,
      "learning_rate": 8.424096385542169e-06,
      "loss": 0.0226,
      "step": 96080
    },
    {
      "epoch": 11.57710843373494,
      "grad_norm": 0.7360831499099731,
      "learning_rate": 8.422891566265062e-06,
      "loss": 0.0078,
      "step": 96090
    },
    {
      "epoch": 11.578313253012048,
      "grad_norm": 0.004780590068548918,
      "learning_rate": 8.421686746987952e-06,
      "loss": 0.0122,
      "step": 96100
    },
    {
      "epoch": 11.579518072289156,
      "grad_norm": 0.0028829022776335478,
      "learning_rate": 8.420481927710845e-06,
      "loss": 0.0082,
      "step": 96110
    },
    {
      "epoch": 11.580722891566266,
      "grad_norm": 0.008103929460048676,
      "learning_rate": 8.419277108433735e-06,
      "loss": 0.0359,
      "step": 96120
    },
    {
      "epoch": 11.581927710843374,
      "grad_norm": 0.03668531775474548,
      "learning_rate": 8.418072289156626e-06,
      "loss": 0.0163,
      "step": 96130
    },
    {
      "epoch": 11.583132530120482,
      "grad_norm": 0.002056264551356435,
      "learning_rate": 8.416867469879519e-06,
      "loss": 0.0343,
      "step": 96140
    },
    {
      "epoch": 11.58433734939759,
      "grad_norm": 0.0007322249002754688,
      "learning_rate": 8.415662650602411e-06,
      "loss": 0.0121,
      "step": 96150
    },
    {
      "epoch": 11.5855421686747,
      "grad_norm": 0.02470557577908039,
      "learning_rate": 8.414457831325302e-06,
      "loss": 0.0058,
      "step": 96160
    },
    {
      "epoch": 11.586746987951807,
      "grad_norm": 0.0006218256312422454,
      "learning_rate": 8.413253012048194e-06,
      "loss": 0.0171,
      "step": 96170
    },
    {
      "epoch": 11.587951807228915,
      "grad_norm": 0.26491639018058777,
      "learning_rate": 8.412048192771085e-06,
      "loss": 0.016,
      "step": 96180
    },
    {
      "epoch": 11.589156626506025,
      "grad_norm": 0.7631374597549438,
      "learning_rate": 8.410843373493976e-06,
      "loss": 0.0065,
      "step": 96190
    },
    {
      "epoch": 11.590361445783133,
      "grad_norm": 1.6247005462646484,
      "learning_rate": 8.409638554216868e-06,
      "loss": 0.0237,
      "step": 96200
    },
    {
      "epoch": 11.59156626506024,
      "grad_norm": 0.0005650746752507985,
      "learning_rate": 8.408433734939759e-06,
      "loss": 0.0597,
      "step": 96210
    },
    {
      "epoch": 11.592771084337349,
      "grad_norm": 0.0008713847491890192,
      "learning_rate": 8.407228915662651e-06,
      "loss": 0.0106,
      "step": 96220
    },
    {
      "epoch": 11.593975903614458,
      "grad_norm": 0.000937833683565259,
      "learning_rate": 8.406024096385544e-06,
      "loss": 0.0298,
      "step": 96230
    },
    {
      "epoch": 11.595180722891566,
      "grad_norm": 0.0025268630124628544,
      "learning_rate": 8.404819277108435e-06,
      "loss": 0.0136,
      "step": 96240
    },
    {
      "epoch": 11.596385542168674,
      "grad_norm": 0.0006487078499048948,
      "learning_rate": 8.403614457831325e-06,
      "loss": 0.0286,
      "step": 96250
    },
    {
      "epoch": 11.597590361445784,
      "grad_norm": 1.3161509037017822,
      "learning_rate": 8.402409638554218e-06,
      "loss": 0.0255,
      "step": 96260
    },
    {
      "epoch": 11.598795180722892,
      "grad_norm": 0.0021428060717880726,
      "learning_rate": 8.401204819277108e-06,
      "loss": 0.0122,
      "step": 96270
    },
    {
      "epoch": 11.6,
      "grad_norm": 0.29393234848976135,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0095,
      "step": 96280
    },
    {
      "epoch": 11.601204819277108,
      "grad_norm": 0.018274635076522827,
      "learning_rate": 8.398795180722892e-06,
      "loss": 0.0211,
      "step": 96290
    },
    {
      "epoch": 11.602409638554217,
      "grad_norm": 0.0022809579968452454,
      "learning_rate": 8.397590361445784e-06,
      "loss": 0.0124,
      "step": 96300
    },
    {
      "epoch": 11.603614457831325,
      "grad_norm": 0.0006896306294947863,
      "learning_rate": 8.396385542168677e-06,
      "loss": 0.0418,
      "step": 96310
    },
    {
      "epoch": 11.604819277108433,
      "grad_norm": 0.001603498007170856,
      "learning_rate": 8.395180722891567e-06,
      "loss": 0.0108,
      "step": 96320
    },
    {
      "epoch": 11.606024096385543,
      "grad_norm": 1.259581208229065,
      "learning_rate": 8.393975903614458e-06,
      "loss": 0.0162,
      "step": 96330
    },
    {
      "epoch": 11.60722891566265,
      "grad_norm": 5.211101531982422,
      "learning_rate": 8.39277108433735e-06,
      "loss": 0.0318,
      "step": 96340
    },
    {
      "epoch": 11.608433734939759,
      "grad_norm": 1.3339686393737793,
      "learning_rate": 8.391566265060241e-06,
      "loss": 0.032,
      "step": 96350
    },
    {
      "epoch": 11.609638554216868,
      "grad_norm": 0.3175795078277588,
      "learning_rate": 8.390361445783134e-06,
      "loss": 0.0163,
      "step": 96360
    },
    {
      "epoch": 11.610843373493976,
      "grad_norm": 0.05095817893743515,
      "learning_rate": 8.389156626506024e-06,
      "loss": 0.0024,
      "step": 96370
    },
    {
      "epoch": 11.612048192771084,
      "grad_norm": 0.026316704228520393,
      "learning_rate": 8.387951807228917e-06,
      "loss": 0.0182,
      "step": 96380
    },
    {
      "epoch": 11.613253012048192,
      "grad_norm": 0.0010269692866131663,
      "learning_rate": 8.386746987951808e-06,
      "loss": 0.012,
      "step": 96390
    },
    {
      "epoch": 11.614457831325302,
      "grad_norm": 0.11784983426332474,
      "learning_rate": 8.3855421686747e-06,
      "loss": 0.0155,
      "step": 96400
    },
    {
      "epoch": 11.61566265060241,
      "grad_norm": 0.004579703323543072,
      "learning_rate": 8.38433734939759e-06,
      "loss": 0.001,
      "step": 96410
    },
    {
      "epoch": 11.616867469879518,
      "grad_norm": 0.12870892882347107,
      "learning_rate": 8.383132530120483e-06,
      "loss": 0.0013,
      "step": 96420
    },
    {
      "epoch": 11.618072289156627,
      "grad_norm": 0.0008596276165917516,
      "learning_rate": 8.381927710843374e-06,
      "loss": 0.0403,
      "step": 96430
    },
    {
      "epoch": 11.619277108433735,
      "grad_norm": 0.055314354598522186,
      "learning_rate": 8.380722891566265e-06,
      "loss": 0.012,
      "step": 96440
    },
    {
      "epoch": 11.620481927710843,
      "grad_norm": 0.021379996091127396,
      "learning_rate": 8.379518072289157e-06,
      "loss": 0.0005,
      "step": 96450
    },
    {
      "epoch": 11.621686746987951,
      "grad_norm": 1.1159590482711792,
      "learning_rate": 8.37831325301205e-06,
      "loss": 0.0087,
      "step": 96460
    },
    {
      "epoch": 11.62289156626506,
      "grad_norm": 0.0005654693231917918,
      "learning_rate": 8.37710843373494e-06,
      "loss": 0.0195,
      "step": 96470
    },
    {
      "epoch": 11.624096385542169,
      "grad_norm": 12.427576065063477,
      "learning_rate": 8.375903614457833e-06,
      "loss": 0.0198,
      "step": 96480
    },
    {
      "epoch": 11.625301204819277,
      "grad_norm": 0.1087268739938736,
      "learning_rate": 8.374698795180723e-06,
      "loss": 0.0127,
      "step": 96490
    },
    {
      "epoch": 11.626506024096386,
      "grad_norm": 0.0005740787019021809,
      "learning_rate": 8.373493975903614e-06,
      "loss": 0.0294,
      "step": 96500
    },
    {
      "epoch": 11.627710843373494,
      "grad_norm": 0.002720798598602414,
      "learning_rate": 8.372289156626507e-06,
      "loss": 0.0663,
      "step": 96510
    },
    {
      "epoch": 11.628915662650602,
      "grad_norm": 0.048917870968580246,
      "learning_rate": 8.371084337349397e-06,
      "loss": 0.0335,
      "step": 96520
    },
    {
      "epoch": 11.630120481927712,
      "grad_norm": 0.22785766422748566,
      "learning_rate": 8.36987951807229e-06,
      "loss": 0.0165,
      "step": 96530
    },
    {
      "epoch": 11.63132530120482,
      "grad_norm": 0.01571504771709442,
      "learning_rate": 8.368674698795182e-06,
      "loss": 0.0195,
      "step": 96540
    },
    {
      "epoch": 11.632530120481928,
      "grad_norm": 0.025711659342050552,
      "learning_rate": 8.367469879518073e-06,
      "loss": 0.006,
      "step": 96550
    },
    {
      "epoch": 11.633734939759035,
      "grad_norm": 0.31391021609306335,
      "learning_rate": 8.366265060240965e-06,
      "loss": 0.01,
      "step": 96560
    },
    {
      "epoch": 11.634939759036145,
      "grad_norm": 0.006501022260636091,
      "learning_rate": 8.365060240963856e-06,
      "loss": 0.029,
      "step": 96570
    },
    {
      "epoch": 11.636144578313253,
      "grad_norm": 0.016565745696425438,
      "learning_rate": 8.363855421686747e-06,
      "loss": 0.0367,
      "step": 96580
    },
    {
      "epoch": 11.637349397590361,
      "grad_norm": 8.134812355041504,
      "learning_rate": 8.36265060240964e-06,
      "loss": 0.0225,
      "step": 96590
    },
    {
      "epoch": 11.638554216867469,
      "grad_norm": 0.01952318847179413,
      "learning_rate": 8.361445783132532e-06,
      "loss": 0.0247,
      "step": 96600
    },
    {
      "epoch": 11.639759036144579,
      "grad_norm": 4.707365036010742,
      "learning_rate": 8.360240963855422e-06,
      "loss": 0.0204,
      "step": 96610
    },
    {
      "epoch": 11.640963855421687,
      "grad_norm": 0.5256909132003784,
      "learning_rate": 8.359036144578315e-06,
      "loss": 0.0338,
      "step": 96620
    },
    {
      "epoch": 11.642168674698794,
      "grad_norm": 0.018009766936302185,
      "learning_rate": 8.357831325301206e-06,
      "loss": 0.0018,
      "step": 96630
    },
    {
      "epoch": 11.643373493975904,
      "grad_norm": 0.0647471696138382,
      "learning_rate": 8.356626506024096e-06,
      "loss": 0.0079,
      "step": 96640
    },
    {
      "epoch": 11.644578313253012,
      "grad_norm": 0.01110918540507555,
      "learning_rate": 8.355421686746989e-06,
      "loss": 0.0511,
      "step": 96650
    },
    {
      "epoch": 11.64578313253012,
      "grad_norm": 0.006511028856039047,
      "learning_rate": 8.35421686746988e-06,
      "loss": 0.0257,
      "step": 96660
    },
    {
      "epoch": 11.64698795180723,
      "grad_norm": 0.1189669668674469,
      "learning_rate": 8.353012048192772e-06,
      "loss": 0.0431,
      "step": 96670
    },
    {
      "epoch": 11.648192771084338,
      "grad_norm": 0.026447659358382225,
      "learning_rate": 8.351807228915664e-06,
      "loss": 0.0164,
      "step": 96680
    },
    {
      "epoch": 11.649397590361446,
      "grad_norm": 0.0008192136301659048,
      "learning_rate": 8.350602409638555e-06,
      "loss": 0.0258,
      "step": 96690
    },
    {
      "epoch": 11.650602409638553,
      "grad_norm": 0.09380651265382767,
      "learning_rate": 8.349397590361446e-06,
      "loss": 0.015,
      "step": 96700
    },
    {
      "epoch": 11.651807228915663,
      "grad_norm": 0.0025938372127711773,
      "learning_rate": 8.348192771084338e-06,
      "loss": 0.0057,
      "step": 96710
    },
    {
      "epoch": 11.653012048192771,
      "grad_norm": 0.0007360903546214104,
      "learning_rate": 8.346987951807229e-06,
      "loss": 0.0077,
      "step": 96720
    },
    {
      "epoch": 11.654216867469879,
      "grad_norm": 0.0037512383423745632,
      "learning_rate": 8.345783132530122e-06,
      "loss": 0.002,
      "step": 96730
    },
    {
      "epoch": 11.655421686746989,
      "grad_norm": 23.595829010009766,
      "learning_rate": 8.344578313253012e-06,
      "loss": 0.0305,
      "step": 96740
    },
    {
      "epoch": 11.656626506024097,
      "grad_norm": 0.0019025130895897746,
      "learning_rate": 8.343373493975905e-06,
      "loss": 0.0155,
      "step": 96750
    },
    {
      "epoch": 11.657831325301204,
      "grad_norm": 0.02110123448073864,
      "learning_rate": 8.342168674698795e-06,
      "loss": 0.0304,
      "step": 96760
    },
    {
      "epoch": 11.659036144578312,
      "grad_norm": 3.013808250427246,
      "learning_rate": 8.340963855421688e-06,
      "loss": 0.0305,
      "step": 96770
    },
    {
      "epoch": 11.660240963855422,
      "grad_norm": 0.24421332776546478,
      "learning_rate": 8.339759036144579e-06,
      "loss": 0.0398,
      "step": 96780
    },
    {
      "epoch": 11.66144578313253,
      "grad_norm": 0.29302266240119934,
      "learning_rate": 8.338554216867471e-06,
      "loss": 0.0217,
      "step": 96790
    },
    {
      "epoch": 11.662650602409638,
      "grad_norm": 1.3035515546798706,
      "learning_rate": 8.337349397590362e-06,
      "loss": 0.0109,
      "step": 96800
    },
    {
      "epoch": 11.663855421686748,
      "grad_norm": 0.03182263299822807,
      "learning_rate": 8.336144578313253e-06,
      "loss": 0.0098,
      "step": 96810
    },
    {
      "epoch": 11.665060240963856,
      "grad_norm": 0.039332594722509384,
      "learning_rate": 8.334939759036145e-06,
      "loss": 0.0208,
      "step": 96820
    },
    {
      "epoch": 11.666265060240963,
      "grad_norm": 0.0014566717436537147,
      "learning_rate": 8.333734939759037e-06,
      "loss": 0.0295,
      "step": 96830
    },
    {
      "epoch": 11.667469879518073,
      "grad_norm": 0.0003985474759247154,
      "learning_rate": 8.332530120481928e-06,
      "loss": 0.0021,
      "step": 96840
    },
    {
      "epoch": 11.668674698795181,
      "grad_norm": 1.33332097530365,
      "learning_rate": 8.33132530120482e-06,
      "loss": 0.0715,
      "step": 96850
    },
    {
      "epoch": 11.669879518072289,
      "grad_norm": 0.001301558455452323,
      "learning_rate": 8.330120481927711e-06,
      "loss": 0.0293,
      "step": 96860
    },
    {
      "epoch": 11.671084337349397,
      "grad_norm": 0.013151410967111588,
      "learning_rate": 8.328915662650604e-06,
      "loss": 0.0217,
      "step": 96870
    },
    {
      "epoch": 11.672289156626507,
      "grad_norm": 0.02419785037636757,
      "learning_rate": 8.327710843373494e-06,
      "loss": 0.0019,
      "step": 96880
    },
    {
      "epoch": 11.673493975903614,
      "grad_norm": 0.0006744763813912868,
      "learning_rate": 8.326506024096385e-06,
      "loss": 0.0077,
      "step": 96890
    },
    {
      "epoch": 11.674698795180722,
      "grad_norm": 1.2370765209197998,
      "learning_rate": 8.325301204819278e-06,
      "loss": 0.0043,
      "step": 96900
    },
    {
      "epoch": 11.675903614457832,
      "grad_norm": 0.0009384388104081154,
      "learning_rate": 8.32409638554217e-06,
      "loss": 0.0099,
      "step": 96910
    },
    {
      "epoch": 11.67710843373494,
      "grad_norm": 0.3123425543308258,
      "learning_rate": 8.32289156626506e-06,
      "loss": 0.018,
      "step": 96920
    },
    {
      "epoch": 11.678313253012048,
      "grad_norm": 0.27357155084609985,
      "learning_rate": 8.321686746987953e-06,
      "loss": 0.0098,
      "step": 96930
    },
    {
      "epoch": 11.679518072289156,
      "grad_norm": 0.002410181798040867,
      "learning_rate": 8.320481927710844e-06,
      "loss": 0.0742,
      "step": 96940
    },
    {
      "epoch": 11.680722891566266,
      "grad_norm": 0.0005728774704039097,
      "learning_rate": 8.319277108433735e-06,
      "loss": 0.0609,
      "step": 96950
    },
    {
      "epoch": 11.681927710843373,
      "grad_norm": 1.7375397682189941,
      "learning_rate": 8.318072289156627e-06,
      "loss": 0.0582,
      "step": 96960
    },
    {
      "epoch": 11.683132530120481,
      "grad_norm": 6.456789970397949,
      "learning_rate": 8.316867469879518e-06,
      "loss": 0.0189,
      "step": 96970
    },
    {
      "epoch": 11.684337349397591,
      "grad_norm": 1.6708731651306152,
      "learning_rate": 8.31566265060241e-06,
      "loss": 0.0125,
      "step": 96980
    },
    {
      "epoch": 11.685542168674699,
      "grad_norm": 0.01963687129318714,
      "learning_rate": 8.314457831325303e-06,
      "loss": 0.0426,
      "step": 96990
    },
    {
      "epoch": 11.686746987951807,
      "grad_norm": 0.0034867445938289165,
      "learning_rate": 8.313253012048194e-06,
      "loss": 0.0066,
      "step": 97000
    },
    {
      "epoch": 11.687951807228917,
      "grad_norm": 0.015126967802643776,
      "learning_rate": 8.312048192771084e-06,
      "loss": 0.013,
      "step": 97010
    },
    {
      "epoch": 11.689156626506024,
      "grad_norm": 1.6184269189834595,
      "learning_rate": 8.310843373493977e-06,
      "loss": 0.0063,
      "step": 97020
    },
    {
      "epoch": 11.690361445783132,
      "grad_norm": 0.06927473843097687,
      "learning_rate": 8.309638554216867e-06,
      "loss": 0.0108,
      "step": 97030
    },
    {
      "epoch": 11.69156626506024,
      "grad_norm": 0.8368151783943176,
      "learning_rate": 8.30843373493976e-06,
      "loss": 0.0348,
      "step": 97040
    },
    {
      "epoch": 11.69277108433735,
      "grad_norm": 0.001806124346330762,
      "learning_rate": 8.307228915662652e-06,
      "loss": 0.0161,
      "step": 97050
    },
    {
      "epoch": 11.693975903614458,
      "grad_norm": 0.877618134021759,
      "learning_rate": 8.306024096385543e-06,
      "loss": 0.0252,
      "step": 97060
    },
    {
      "epoch": 11.695180722891566,
      "grad_norm": 0.6852787733078003,
      "learning_rate": 8.304819277108434e-06,
      "loss": 0.0139,
      "step": 97070
    },
    {
      "epoch": 11.696385542168674,
      "grad_norm": 0.02866967022418976,
      "learning_rate": 8.303614457831326e-06,
      "loss": 0.0135,
      "step": 97080
    },
    {
      "epoch": 11.697590361445783,
      "grad_norm": 0.006666076835244894,
      "learning_rate": 8.302409638554217e-06,
      "loss": 0.0281,
      "step": 97090
    },
    {
      "epoch": 11.698795180722891,
      "grad_norm": 0.2659410238265991,
      "learning_rate": 8.30120481927711e-06,
      "loss": 0.0378,
      "step": 97100
    },
    {
      "epoch": 11.7,
      "grad_norm": 0.0167576614767313,
      "learning_rate": 8.3e-06,
      "loss": 0.0098,
      "step": 97110
    },
    {
      "epoch": 11.701204819277109,
      "grad_norm": 737.8845825195312,
      "learning_rate": 8.298795180722891e-06,
      "loss": 0.0399,
      "step": 97120
    },
    {
      "epoch": 11.702409638554217,
      "grad_norm": 0.10259588807821274,
      "learning_rate": 8.297590361445785e-06,
      "loss": 0.0073,
      "step": 97130
    },
    {
      "epoch": 11.703614457831325,
      "grad_norm": 0.8842630386352539,
      "learning_rate": 8.296385542168676e-06,
      "loss": 0.0299,
      "step": 97140
    },
    {
      "epoch": 11.704819277108435,
      "grad_norm": 0.6652495265007019,
      "learning_rate": 8.295180722891567e-06,
      "loss": 0.0096,
      "step": 97150
    },
    {
      "epoch": 11.706024096385542,
      "grad_norm": 0.021626954898238182,
      "learning_rate": 8.293975903614459e-06,
      "loss": 0.0057,
      "step": 97160
    },
    {
      "epoch": 11.70722891566265,
      "grad_norm": 0.002483615418896079,
      "learning_rate": 8.29277108433735e-06,
      "loss": 0.018,
      "step": 97170
    },
    {
      "epoch": 11.708433734939758,
      "grad_norm": 1.7572197914123535,
      "learning_rate": 8.291566265060242e-06,
      "loss": 0.0271,
      "step": 97180
    },
    {
      "epoch": 11.709638554216868,
      "grad_norm": 0.001329520484432578,
      "learning_rate": 8.290361445783133e-06,
      "loss": 0.05,
      "step": 97190
    },
    {
      "epoch": 11.710843373493976,
      "grad_norm": 0.0026343856006860733,
      "learning_rate": 8.289156626506025e-06,
      "loss": 0.0369,
      "step": 97200
    },
    {
      "epoch": 11.712048192771084,
      "grad_norm": 0.020683735609054565,
      "learning_rate": 8.287951807228916e-06,
      "loss": 0.0029,
      "step": 97210
    },
    {
      "epoch": 11.713253012048193,
      "grad_norm": 1.2947208881378174,
      "learning_rate": 8.286746987951808e-06,
      "loss": 0.0089,
      "step": 97220
    },
    {
      "epoch": 11.714457831325301,
      "grad_norm": 0.001190572278574109,
      "learning_rate": 8.2855421686747e-06,
      "loss": 0.0076,
      "step": 97230
    },
    {
      "epoch": 11.71566265060241,
      "grad_norm": 0.0010308788623660803,
      "learning_rate": 8.284337349397592e-06,
      "loss": 0.0069,
      "step": 97240
    },
    {
      "epoch": 11.716867469879517,
      "grad_norm": 0.22282081842422485,
      "learning_rate": 8.283132530120482e-06,
      "loss": 0.028,
      "step": 97250
    },
    {
      "epoch": 11.718072289156627,
      "grad_norm": 0.24271532893180847,
      "learning_rate": 8.281927710843373e-06,
      "loss": 0.0141,
      "step": 97260
    },
    {
      "epoch": 11.719277108433735,
      "grad_norm": 1.3544386625289917,
      "learning_rate": 8.280722891566266e-06,
      "loss": 0.0524,
      "step": 97270
    },
    {
      "epoch": 11.720481927710843,
      "grad_norm": 2.174152374267578,
      "learning_rate": 8.279518072289158e-06,
      "loss": 0.0149,
      "step": 97280
    },
    {
      "epoch": 11.721686746987952,
      "grad_norm": 0.5723897814750671,
      "learning_rate": 8.278313253012049e-06,
      "loss": 0.0194,
      "step": 97290
    },
    {
      "epoch": 11.72289156626506,
      "grad_norm": 0.000797385408077389,
      "learning_rate": 8.277108433734941e-06,
      "loss": 0.0031,
      "step": 97300
    },
    {
      "epoch": 11.724096385542168,
      "grad_norm": 0.0007983589312061667,
      "learning_rate": 8.275903614457832e-06,
      "loss": 0.0146,
      "step": 97310
    },
    {
      "epoch": 11.725301204819278,
      "grad_norm": 0.006677525583654642,
      "learning_rate": 8.274698795180723e-06,
      "loss": 0.0247,
      "step": 97320
    },
    {
      "epoch": 11.726506024096386,
      "grad_norm": 1.6808602809906006,
      "learning_rate": 8.273493975903615e-06,
      "loss": 0.0377,
      "step": 97330
    },
    {
      "epoch": 11.727710843373494,
      "grad_norm": 1.343954086303711,
      "learning_rate": 8.272289156626506e-06,
      "loss": 0.0156,
      "step": 97340
    },
    {
      "epoch": 11.728915662650602,
      "grad_norm": 1.8615798950195312,
      "learning_rate": 8.271084337349398e-06,
      "loss": 0.0271,
      "step": 97350
    },
    {
      "epoch": 11.730120481927711,
      "grad_norm": 0.011387261562049389,
      "learning_rate": 8.26987951807229e-06,
      "loss": 0.0007,
      "step": 97360
    },
    {
      "epoch": 11.73132530120482,
      "grad_norm": 0.0892627015709877,
      "learning_rate": 8.268674698795181e-06,
      "loss": 0.0169,
      "step": 97370
    },
    {
      "epoch": 11.732530120481927,
      "grad_norm": 0.7547904849052429,
      "learning_rate": 8.267469879518072e-06,
      "loss": 0.0199,
      "step": 97380
    },
    {
      "epoch": 11.733734939759037,
      "grad_norm": 0.026853738352656364,
      "learning_rate": 8.266265060240965e-06,
      "loss": 0.0118,
      "step": 97390
    },
    {
      "epoch": 11.734939759036145,
      "grad_norm": 0.6725752353668213,
      "learning_rate": 8.265060240963855e-06,
      "loss": 0.0232,
      "step": 97400
    },
    {
      "epoch": 11.736144578313253,
      "grad_norm": 0.0036198024172335863,
      "learning_rate": 8.263855421686748e-06,
      "loss": 0.0184,
      "step": 97410
    },
    {
      "epoch": 11.73734939759036,
      "grad_norm": 0.000437536888057366,
      "learning_rate": 8.262650602409639e-06,
      "loss": 0.0167,
      "step": 97420
    },
    {
      "epoch": 11.73855421686747,
      "grad_norm": 1.8072303533554077,
      "learning_rate": 8.261445783132531e-06,
      "loss": 0.0116,
      "step": 97430
    },
    {
      "epoch": 11.739759036144578,
      "grad_norm": 0.002136518247425556,
      "learning_rate": 8.260240963855423e-06,
      "loss": 0.0046,
      "step": 97440
    },
    {
      "epoch": 11.740963855421686,
      "grad_norm": 0.0005032641929574311,
      "learning_rate": 8.259036144578314e-06,
      "loss": 0.0321,
      "step": 97450
    },
    {
      "epoch": 11.742168674698796,
      "grad_norm": 0.0044510760344564915,
      "learning_rate": 8.257831325301205e-06,
      "loss": 0.0084,
      "step": 97460
    },
    {
      "epoch": 11.743373493975904,
      "grad_norm": 18.80219268798828,
      "learning_rate": 8.256626506024097e-06,
      "loss": 0.0286,
      "step": 97470
    },
    {
      "epoch": 11.744578313253012,
      "grad_norm": 0.05864711478352547,
      "learning_rate": 8.255421686746988e-06,
      "loss": 0.0442,
      "step": 97480
    },
    {
      "epoch": 11.745783132530121,
      "grad_norm": 0.0010606711730360985,
      "learning_rate": 8.25421686746988e-06,
      "loss": 0.0245,
      "step": 97490
    },
    {
      "epoch": 11.74698795180723,
      "grad_norm": 1.2694891691207886,
      "learning_rate": 8.253012048192773e-06,
      "loss": 0.0132,
      "step": 97500
    },
    {
      "epoch": 11.748192771084337,
      "grad_norm": 0.020353028550744057,
      "learning_rate": 8.251807228915664e-06,
      "loss": 0.0132,
      "step": 97510
    },
    {
      "epoch": 11.749397590361445,
      "grad_norm": 1.6367461681365967,
      "learning_rate": 8.250602409638554e-06,
      "loss": 0.019,
      "step": 97520
    },
    {
      "epoch": 11.750602409638555,
      "grad_norm": 0.0005361037910915911,
      "learning_rate": 8.249397590361447e-06,
      "loss": 0.012,
      "step": 97530
    },
    {
      "epoch": 11.751807228915663,
      "grad_norm": 0.0007027166429907084,
      "learning_rate": 8.248192771084338e-06,
      "loss": 0.0261,
      "step": 97540
    },
    {
      "epoch": 11.75301204819277,
      "grad_norm": 0.651046872138977,
      "learning_rate": 8.24698795180723e-06,
      "loss": 0.025,
      "step": 97550
    },
    {
      "epoch": 11.754216867469879,
      "grad_norm": 2.4143283367156982,
      "learning_rate": 8.24578313253012e-06,
      "loss": 0.0155,
      "step": 97560
    },
    {
      "epoch": 11.755421686746988,
      "grad_norm": 0.9721203446388245,
      "learning_rate": 8.244578313253013e-06,
      "loss": 0.0146,
      "step": 97570
    },
    {
      "epoch": 11.756626506024096,
      "grad_norm": 0.000477693451102823,
      "learning_rate": 8.243373493975904e-06,
      "loss": 0.0042,
      "step": 97580
    },
    {
      "epoch": 11.757831325301204,
      "grad_norm": 0.2972096800804138,
      "learning_rate": 8.242168674698796e-06,
      "loss": 0.0296,
      "step": 97590
    },
    {
      "epoch": 11.759036144578314,
      "grad_norm": 0.0007855019648559391,
      "learning_rate": 8.240963855421687e-06,
      "loss": 0.0217,
      "step": 97600
    },
    {
      "epoch": 11.760240963855422,
      "grad_norm": 9.688311576843262,
      "learning_rate": 8.23975903614458e-06,
      "loss": 0.0414,
      "step": 97610
    },
    {
      "epoch": 11.76144578313253,
      "grad_norm": 0.0010065410751849413,
      "learning_rate": 8.23855421686747e-06,
      "loss": 0.02,
      "step": 97620
    },
    {
      "epoch": 11.76265060240964,
      "grad_norm": 0.041242972016334534,
      "learning_rate": 8.237349397590361e-06,
      "loss": 0.0175,
      "step": 97630
    },
    {
      "epoch": 11.763855421686747,
      "grad_norm": 0.0017289456445723772,
      "learning_rate": 8.236144578313253e-06,
      "loss": 0.0096,
      "step": 97640
    },
    {
      "epoch": 11.765060240963855,
      "grad_norm": 0.010678095743060112,
      "learning_rate": 8.234939759036146e-06,
      "loss": 0.0057,
      "step": 97650
    },
    {
      "epoch": 11.766265060240963,
      "grad_norm": 0.3531320095062256,
      "learning_rate": 8.233734939759037e-06,
      "loss": 0.0175,
      "step": 97660
    },
    {
      "epoch": 11.767469879518073,
      "grad_norm": 0.4613930284976959,
      "learning_rate": 8.232530120481929e-06,
      "loss": 0.0495,
      "step": 97670
    },
    {
      "epoch": 11.76867469879518,
      "grad_norm": 0.0012028361670672894,
      "learning_rate": 8.23132530120482e-06,
      "loss": 0.0072,
      "step": 97680
    },
    {
      "epoch": 11.769879518072289,
      "grad_norm": 0.22446055710315704,
      "learning_rate": 8.23012048192771e-06,
      "loss": 0.0407,
      "step": 97690
    },
    {
      "epoch": 11.771084337349398,
      "grad_norm": 0.0019199394155293703,
      "learning_rate": 8.228915662650603e-06,
      "loss": 0.0195,
      "step": 97700
    },
    {
      "epoch": 11.772289156626506,
      "grad_norm": 0.00060720753390342,
      "learning_rate": 8.227710843373494e-06,
      "loss": 0.0214,
      "step": 97710
    },
    {
      "epoch": 11.773493975903614,
      "grad_norm": 1.0801376104354858,
      "learning_rate": 8.226506024096386e-06,
      "loss": 0.0137,
      "step": 97720
    },
    {
      "epoch": 11.774698795180722,
      "grad_norm": 0.0011894427007064223,
      "learning_rate": 8.225301204819279e-06,
      "loss": 0.0333,
      "step": 97730
    },
    {
      "epoch": 11.775903614457832,
      "grad_norm": 0.0006356899393722415,
      "learning_rate": 8.22409638554217e-06,
      "loss": 0.0207,
      "step": 97740
    },
    {
      "epoch": 11.77710843373494,
      "grad_norm": 1.5434776544570923,
      "learning_rate": 8.222891566265062e-06,
      "loss": 0.0164,
      "step": 97750
    },
    {
      "epoch": 11.778313253012048,
      "grad_norm": 0.9273248314857483,
      "learning_rate": 8.221686746987953e-06,
      "loss": 0.0265,
      "step": 97760
    },
    {
      "epoch": 11.779518072289157,
      "grad_norm": 0.0005996439140290022,
      "learning_rate": 8.220481927710843e-06,
      "loss": 0.0127,
      "step": 97770
    },
    {
      "epoch": 11.780722891566265,
      "grad_norm": 0.0008142946171574295,
      "learning_rate": 8.219277108433736e-06,
      "loss": 0.0206,
      "step": 97780
    },
    {
      "epoch": 11.781927710843373,
      "grad_norm": 1.1232547760009766,
      "learning_rate": 8.218072289156626e-06,
      "loss": 0.0356,
      "step": 97790
    },
    {
      "epoch": 11.783132530120483,
      "grad_norm": 3.8950414657592773,
      "learning_rate": 8.216867469879519e-06,
      "loss": 0.0197,
      "step": 97800
    },
    {
      "epoch": 11.78433734939759,
      "grad_norm": 0.000754206848796457,
      "learning_rate": 8.215662650602411e-06,
      "loss": 0.0169,
      "step": 97810
    },
    {
      "epoch": 11.785542168674699,
      "grad_norm": 0.0005094308871775866,
      "learning_rate": 8.214457831325302e-06,
      "loss": 0.0172,
      "step": 97820
    },
    {
      "epoch": 11.786746987951807,
      "grad_norm": 0.00048247375525534153,
      "learning_rate": 8.213253012048193e-06,
      "loss": 0.0105,
      "step": 97830
    },
    {
      "epoch": 11.787951807228916,
      "grad_norm": 0.802447497844696,
      "learning_rate": 8.212048192771085e-06,
      "loss": 0.0581,
      "step": 97840
    },
    {
      "epoch": 11.789156626506024,
      "grad_norm": 0.001907083671540022,
      "learning_rate": 8.210843373493976e-06,
      "loss": 0.0079,
      "step": 97850
    },
    {
      "epoch": 11.790361445783132,
      "grad_norm": 0.19762082397937775,
      "learning_rate": 8.209638554216868e-06,
      "loss": 0.0433,
      "step": 97860
    },
    {
      "epoch": 11.791566265060242,
      "grad_norm": 0.0017130030319094658,
      "learning_rate": 8.20843373493976e-06,
      "loss": 0.0613,
      "step": 97870
    },
    {
      "epoch": 11.79277108433735,
      "grad_norm": 0.005923568271100521,
      "learning_rate": 8.207228915662652e-06,
      "loss": 0.0084,
      "step": 97880
    },
    {
      "epoch": 11.793975903614458,
      "grad_norm": 0.00370188825763762,
      "learning_rate": 8.206024096385542e-06,
      "loss": 0.0188,
      "step": 97890
    },
    {
      "epoch": 11.795180722891565,
      "grad_norm": 0.004369872622191906,
      "learning_rate": 8.204819277108435e-06,
      "loss": 0.0088,
      "step": 97900
    },
    {
      "epoch": 11.796385542168675,
      "grad_norm": 0.022493915632367134,
      "learning_rate": 8.203614457831326e-06,
      "loss": 0.0286,
      "step": 97910
    },
    {
      "epoch": 11.797590361445783,
      "grad_norm": 0.0023857452906668186,
      "learning_rate": 8.202409638554218e-06,
      "loss": 0.0413,
      "step": 97920
    },
    {
      "epoch": 11.798795180722891,
      "grad_norm": 0.4750406742095947,
      "learning_rate": 8.201204819277109e-06,
      "loss": 0.0114,
      "step": 97930
    },
    {
      "epoch": 11.8,
      "grad_norm": 0.002128592226654291,
      "learning_rate": 8.2e-06,
      "loss": 0.0083,
      "step": 97940
    },
    {
      "epoch": 11.801204819277109,
      "grad_norm": 1.395860195159912,
      "learning_rate": 8.198795180722894e-06,
      "loss": 0.006,
      "step": 97950
    },
    {
      "epoch": 11.802409638554217,
      "grad_norm": 0.004733541514724493,
      "learning_rate": 8.197590361445784e-06,
      "loss": 0.0022,
      "step": 97960
    },
    {
      "epoch": 11.803614457831326,
      "grad_norm": 0.0017595969839021564,
      "learning_rate": 8.196385542168675e-06,
      "loss": 0.0026,
      "step": 97970
    },
    {
      "epoch": 11.804819277108434,
      "grad_norm": 0.010022218339145184,
      "learning_rate": 8.195180722891567e-06,
      "loss": 0.0132,
      "step": 97980
    },
    {
      "epoch": 11.806024096385542,
      "grad_norm": 0.132613867521286,
      "learning_rate": 8.193975903614458e-06,
      "loss": 0.0062,
      "step": 97990
    },
    {
      "epoch": 11.80722891566265,
      "grad_norm": 0.4079195261001587,
      "learning_rate": 8.19277108433735e-06,
      "loss": 0.0138,
      "step": 98000
    },
    {
      "epoch": 11.80843373493976,
      "grad_norm": 0.025968428701162338,
      "learning_rate": 8.191566265060241e-06,
      "loss": 0.0142,
      "step": 98010
    },
    {
      "epoch": 11.809638554216868,
      "grad_norm": 1.7234158515930176,
      "learning_rate": 8.190361445783134e-06,
      "loss": 0.0282,
      "step": 98020
    },
    {
      "epoch": 11.810843373493976,
      "grad_norm": 10.674748420715332,
      "learning_rate": 8.189156626506025e-06,
      "loss": 0.0535,
      "step": 98030
    },
    {
      "epoch": 11.812048192771083,
      "grad_norm": 0.0016873949207365513,
      "learning_rate": 8.187951807228917e-06,
      "loss": 0.0022,
      "step": 98040
    },
    {
      "epoch": 11.813253012048193,
      "grad_norm": 0.0015077959978953004,
      "learning_rate": 8.186746987951808e-06,
      "loss": 0.0079,
      "step": 98050
    },
    {
      "epoch": 11.814457831325301,
      "grad_norm": 0.013331150636076927,
      "learning_rate": 8.1855421686747e-06,
      "loss": 0.015,
      "step": 98060
    },
    {
      "epoch": 11.815662650602409,
      "grad_norm": 0.03470456600189209,
      "learning_rate": 8.184337349397591e-06,
      "loss": 0.01,
      "step": 98070
    },
    {
      "epoch": 11.816867469879519,
      "grad_norm": 0.028653547167778015,
      "learning_rate": 8.183132530120482e-06,
      "loss": 0.0132,
      "step": 98080
    },
    {
      "epoch": 11.818072289156627,
      "grad_norm": 3.4653148651123047,
      "learning_rate": 8.181927710843374e-06,
      "loss": 0.0412,
      "step": 98090
    },
    {
      "epoch": 11.819277108433734,
      "grad_norm": 0.001068579382263124,
      "learning_rate": 8.180722891566267e-06,
      "loss": 0.0146,
      "step": 98100
    },
    {
      "epoch": 11.820481927710844,
      "grad_norm": 0.004041692707687616,
      "learning_rate": 8.179518072289157e-06,
      "loss": 0.0071,
      "step": 98110
    },
    {
      "epoch": 11.821686746987952,
      "grad_norm": 0.004396542906761169,
      "learning_rate": 8.17831325301205e-06,
      "loss": 0.0093,
      "step": 98120
    },
    {
      "epoch": 11.82289156626506,
      "grad_norm": 0.10929994285106659,
      "learning_rate": 8.17710843373494e-06,
      "loss": 0.0463,
      "step": 98130
    },
    {
      "epoch": 11.824096385542168,
      "grad_norm": 0.0014152310322970152,
      "learning_rate": 8.175903614457831e-06,
      "loss": 0.0351,
      "step": 98140
    },
    {
      "epoch": 11.825301204819278,
      "grad_norm": 0.4657255709171295,
      "learning_rate": 8.174698795180724e-06,
      "loss": 0.051,
      "step": 98150
    },
    {
      "epoch": 11.826506024096386,
      "grad_norm": 0.5142295956611633,
      "learning_rate": 8.173493975903614e-06,
      "loss": 0.0182,
      "step": 98160
    },
    {
      "epoch": 11.827710843373493,
      "grad_norm": 1.2946727275848389,
      "learning_rate": 8.172289156626507e-06,
      "loss": 0.022,
      "step": 98170
    },
    {
      "epoch": 11.828915662650603,
      "grad_norm": 0.024583054706454277,
      "learning_rate": 8.1710843373494e-06,
      "loss": 0.0049,
      "step": 98180
    },
    {
      "epoch": 11.830120481927711,
      "grad_norm": 1.3950210809707642,
      "learning_rate": 8.16987951807229e-06,
      "loss": 0.0134,
      "step": 98190
    },
    {
      "epoch": 11.831325301204819,
      "grad_norm": 0.009992195293307304,
      "learning_rate": 8.16867469879518e-06,
      "loss": 0.0167,
      "step": 98200
    },
    {
      "epoch": 11.832530120481927,
      "grad_norm": 0.046248555183410645,
      "learning_rate": 8.167469879518073e-06,
      "loss": 0.0587,
      "step": 98210
    },
    {
      "epoch": 11.833734939759037,
      "grad_norm": 0.29824963212013245,
      "learning_rate": 8.166265060240964e-06,
      "loss": 0.0037,
      "step": 98220
    },
    {
      "epoch": 11.834939759036144,
      "grad_norm": 0.3080352246761322,
      "learning_rate": 8.165060240963856e-06,
      "loss": 0.0078,
      "step": 98230
    },
    {
      "epoch": 11.836144578313252,
      "grad_norm": 0.02336149848997593,
      "learning_rate": 8.163855421686747e-06,
      "loss": 0.0017,
      "step": 98240
    },
    {
      "epoch": 11.837349397590362,
      "grad_norm": 0.006211662199348211,
      "learning_rate": 8.16265060240964e-06,
      "loss": 0.015,
      "step": 98250
    },
    {
      "epoch": 11.83855421686747,
      "grad_norm": 0.12494075298309326,
      "learning_rate": 8.161445783132532e-06,
      "loss": 0.0062,
      "step": 98260
    },
    {
      "epoch": 11.839759036144578,
      "grad_norm": 2.7866570949554443,
      "learning_rate": 8.160240963855423e-06,
      "loss": 0.0464,
      "step": 98270
    },
    {
      "epoch": 11.840963855421688,
      "grad_norm": 0.004464202560484409,
      "learning_rate": 8.159036144578313e-06,
      "loss": 0.0048,
      "step": 98280
    },
    {
      "epoch": 11.842168674698796,
      "grad_norm": 0.00212066899985075,
      "learning_rate": 8.157831325301206e-06,
      "loss": 0.0013,
      "step": 98290
    },
    {
      "epoch": 11.843373493975903,
      "grad_norm": 0.003038067603483796,
      "learning_rate": 8.156626506024097e-06,
      "loss": 0.0079,
      "step": 98300
    },
    {
      "epoch": 11.844578313253011,
      "grad_norm": 0.22193844616413116,
      "learning_rate": 8.155421686746989e-06,
      "loss": 0.0249,
      "step": 98310
    },
    {
      "epoch": 11.845783132530121,
      "grad_norm": 0.05434207245707512,
      "learning_rate": 8.154216867469881e-06,
      "loss": 0.0035,
      "step": 98320
    },
    {
      "epoch": 11.846987951807229,
      "grad_norm": 0.1896093338727951,
      "learning_rate": 8.153012048192772e-06,
      "loss": 0.0256,
      "step": 98330
    },
    {
      "epoch": 11.848192771084337,
      "grad_norm": 0.002539628418162465,
      "learning_rate": 8.151807228915663e-06,
      "loss": 0.0219,
      "step": 98340
    },
    {
      "epoch": 11.849397590361447,
      "grad_norm": 0.0810987576842308,
      "learning_rate": 8.150602409638555e-06,
      "loss": 0.0153,
      "step": 98350
    },
    {
      "epoch": 11.850602409638554,
      "grad_norm": 0.19449694454669952,
      "learning_rate": 8.149397590361446e-06,
      "loss": 0.0139,
      "step": 98360
    },
    {
      "epoch": 11.851807228915662,
      "grad_norm": 0.06380695104598999,
      "learning_rate": 8.148192771084339e-06,
      "loss": 0.0313,
      "step": 98370
    },
    {
      "epoch": 11.85301204819277,
      "grad_norm": 0.47162944078445435,
      "learning_rate": 8.14698795180723e-06,
      "loss": 0.0097,
      "step": 98380
    },
    {
      "epoch": 11.85421686746988,
      "grad_norm": 0.22120432555675507,
      "learning_rate": 8.14578313253012e-06,
      "loss": 0.0091,
      "step": 98390
    },
    {
      "epoch": 11.855421686746988,
      "grad_norm": 0.0010108412243425846,
      "learning_rate": 8.144578313253012e-06,
      "loss": 0.0056,
      "step": 98400
    },
    {
      "epoch": 11.856626506024096,
      "grad_norm": 2.4436919689178467,
      "learning_rate": 8.143373493975905e-06,
      "loss": 0.0093,
      "step": 98410
    },
    {
      "epoch": 11.857831325301206,
      "grad_norm": 0.007734025828540325,
      "learning_rate": 8.142168674698796e-06,
      "loss": 0.0253,
      "step": 98420
    },
    {
      "epoch": 11.859036144578313,
      "grad_norm": 4.728343486785889,
      "learning_rate": 8.140963855421688e-06,
      "loss": 0.058,
      "step": 98430
    },
    {
      "epoch": 11.860240963855421,
      "grad_norm": 0.004700935911387205,
      "learning_rate": 8.139759036144579e-06,
      "loss": 0.0088,
      "step": 98440
    },
    {
      "epoch": 11.861445783132531,
      "grad_norm": 31.813396453857422,
      "learning_rate": 8.13855421686747e-06,
      "loss": 0.0476,
      "step": 98450
    },
    {
      "epoch": 11.862650602409639,
      "grad_norm": 0.013891436159610748,
      "learning_rate": 8.137349397590362e-06,
      "loss": 0.0198,
      "step": 98460
    },
    {
      "epoch": 11.863855421686747,
      "grad_norm": 0.003003477118909359,
      "learning_rate": 8.136144578313254e-06,
      "loss": 0.0009,
      "step": 98470
    },
    {
      "epoch": 11.865060240963855,
      "grad_norm": 0.07019969075918198,
      "learning_rate": 8.134939759036145e-06,
      "loss": 0.0232,
      "step": 98480
    },
    {
      "epoch": 11.866265060240965,
      "grad_norm": 0.0023364813532680273,
      "learning_rate": 8.133734939759038e-06,
      "loss": 0.0329,
      "step": 98490
    },
    {
      "epoch": 11.867469879518072,
      "grad_norm": 0.2599441707134247,
      "learning_rate": 8.132530120481928e-06,
      "loss": 0.0117,
      "step": 98500
    },
    {
      "epoch": 11.86867469879518,
      "grad_norm": 0.8989774584770203,
      "learning_rate": 8.131325301204819e-06,
      "loss": 0.0079,
      "step": 98510
    },
    {
      "epoch": 11.869879518072288,
      "grad_norm": 0.0030147326178848743,
      "learning_rate": 8.130120481927712e-06,
      "loss": 0.0073,
      "step": 98520
    },
    {
      "epoch": 11.871084337349398,
      "grad_norm": 0.7030392289161682,
      "learning_rate": 8.128915662650602e-06,
      "loss": 0.0144,
      "step": 98530
    },
    {
      "epoch": 11.872289156626506,
      "grad_norm": 0.2130553424358368,
      "learning_rate": 8.127710843373495e-06,
      "loss": 0.0143,
      "step": 98540
    },
    {
      "epoch": 11.873493975903614,
      "grad_norm": 5.982311725616455,
      "learning_rate": 8.126506024096387e-06,
      "loss": 0.0411,
      "step": 98550
    },
    {
      "epoch": 11.874698795180723,
      "grad_norm": 0.002209685044363141,
      "learning_rate": 8.125301204819278e-06,
      "loss": 0.0167,
      "step": 98560
    },
    {
      "epoch": 11.875903614457831,
      "grad_norm": 0.007584304083138704,
      "learning_rate": 8.12409638554217e-06,
      "loss": 0.0066,
      "step": 98570
    },
    {
      "epoch": 11.87710843373494,
      "grad_norm": 0.028688810765743256,
      "learning_rate": 8.122891566265061e-06,
      "loss": 0.044,
      "step": 98580
    },
    {
      "epoch": 11.878313253012049,
      "grad_norm": 0.04172847792506218,
      "learning_rate": 8.121686746987952e-06,
      "loss": 0.0023,
      "step": 98590
    },
    {
      "epoch": 11.879518072289157,
      "grad_norm": 0.31201687455177307,
      "learning_rate": 8.120481927710844e-06,
      "loss": 0.0112,
      "step": 98600
    },
    {
      "epoch": 11.880722891566265,
      "grad_norm": 0.0032855411991477013,
      "learning_rate": 8.119277108433735e-06,
      "loss": 0.0501,
      "step": 98610
    },
    {
      "epoch": 11.881927710843373,
      "grad_norm": 0.013868473470211029,
      "learning_rate": 8.118072289156627e-06,
      "loss": 0.0063,
      "step": 98620
    },
    {
      "epoch": 11.883132530120482,
      "grad_norm": 1.0904414653778076,
      "learning_rate": 8.11686746987952e-06,
      "loss": 0.0177,
      "step": 98630
    },
    {
      "epoch": 11.88433734939759,
      "grad_norm": 0.003532792441546917,
      "learning_rate": 8.11566265060241e-06,
      "loss": 0.0332,
      "step": 98640
    },
    {
      "epoch": 11.885542168674698,
      "grad_norm": 0.013847610913217068,
      "learning_rate": 8.114457831325301e-06,
      "loss": 0.0109,
      "step": 98650
    },
    {
      "epoch": 11.886746987951808,
      "grad_norm": 0.0021304485853761435,
      "learning_rate": 8.113253012048194e-06,
      "loss": 0.0069,
      "step": 98660
    },
    {
      "epoch": 11.887951807228916,
      "grad_norm": 0.006324532441794872,
      "learning_rate": 8.112048192771084e-06,
      "loss": 0.0412,
      "step": 98670
    },
    {
      "epoch": 11.889156626506024,
      "grad_norm": 0.2371257096529007,
      "learning_rate": 8.110843373493977e-06,
      "loss": 0.0148,
      "step": 98680
    },
    {
      "epoch": 11.890361445783132,
      "grad_norm": 0.36825624108314514,
      "learning_rate": 8.109638554216868e-06,
      "loss": 0.0644,
      "step": 98690
    },
    {
      "epoch": 11.891566265060241,
      "grad_norm": 0.11244070529937744,
      "learning_rate": 8.10843373493976e-06,
      "loss": 0.0166,
      "step": 98700
    },
    {
      "epoch": 11.89277108433735,
      "grad_norm": 0.000963028403930366,
      "learning_rate": 8.10722891566265e-06,
      "loss": 0.0217,
      "step": 98710
    },
    {
      "epoch": 11.893975903614457,
      "grad_norm": 0.007711491081863642,
      "learning_rate": 8.106024096385543e-06,
      "loss": 0.0056,
      "step": 98720
    },
    {
      "epoch": 11.895180722891567,
      "grad_norm": 0.19722895324230194,
      "learning_rate": 8.104819277108434e-06,
      "loss": 0.0055,
      "step": 98730
    },
    {
      "epoch": 11.896385542168675,
      "grad_norm": 3.785477638244629,
      "learning_rate": 8.103614457831326e-06,
      "loss": 0.0273,
      "step": 98740
    },
    {
      "epoch": 11.897590361445783,
      "grad_norm": 0.0027410162147134542,
      "learning_rate": 8.102409638554217e-06,
      "loss": 0.0184,
      "step": 98750
    },
    {
      "epoch": 11.898795180722892,
      "grad_norm": 0.0040610856376588345,
      "learning_rate": 8.101204819277108e-06,
      "loss": 0.03,
      "step": 98760
    },
    {
      "epoch": 11.9,
      "grad_norm": 0.0014796413015574217,
      "learning_rate": 8.1e-06,
      "loss": 0.0551,
      "step": 98770
    },
    {
      "epoch": 11.901204819277108,
      "grad_norm": 0.005996077321469784,
      "learning_rate": 8.098795180722893e-06,
      "loss": 0.0163,
      "step": 98780
    },
    {
      "epoch": 11.902409638554216,
      "grad_norm": 0.007702031172811985,
      "learning_rate": 8.097590361445784e-06,
      "loss": 0.0157,
      "step": 98790
    },
    {
      "epoch": 11.903614457831326,
      "grad_norm": 0.3296782672405243,
      "learning_rate": 8.096385542168676e-06,
      "loss": 0.0213,
      "step": 98800
    },
    {
      "epoch": 11.904819277108434,
      "grad_norm": 1.192848801612854,
      "learning_rate": 8.095180722891567e-06,
      "loss": 0.0181,
      "step": 98810
    },
    {
      "epoch": 11.906024096385542,
      "grad_norm": 1.2132991552352905,
      "learning_rate": 8.093975903614457e-06,
      "loss": 0.0295,
      "step": 98820
    },
    {
      "epoch": 11.907228915662651,
      "grad_norm": 0.005301299504935741,
      "learning_rate": 8.09277108433735e-06,
      "loss": 0.0114,
      "step": 98830
    },
    {
      "epoch": 11.90843373493976,
      "grad_norm": 0.7836551070213318,
      "learning_rate": 8.09156626506024e-06,
      "loss": 0.0051,
      "step": 98840
    },
    {
      "epoch": 11.909638554216867,
      "grad_norm": 7.276195049285889,
      "learning_rate": 8.090361445783133e-06,
      "loss": 0.0415,
      "step": 98850
    },
    {
      "epoch": 11.910843373493975,
      "grad_norm": 0.4812764525413513,
      "learning_rate": 8.089156626506026e-06,
      "loss": 0.0044,
      "step": 98860
    },
    {
      "epoch": 11.912048192771085,
      "grad_norm": 0.002433264860883355,
      "learning_rate": 8.087951807228916e-06,
      "loss": 0.0157,
      "step": 98870
    },
    {
      "epoch": 11.913253012048193,
      "grad_norm": 0.0012272530002519488,
      "learning_rate": 8.086746987951809e-06,
      "loss": 0.0194,
      "step": 98880
    },
    {
      "epoch": 11.9144578313253,
      "grad_norm": 0.6580694913864136,
      "learning_rate": 8.0855421686747e-06,
      "loss": 0.0153,
      "step": 98890
    },
    {
      "epoch": 11.91566265060241,
      "grad_norm": 2.1568267345428467,
      "learning_rate": 8.08433734939759e-06,
      "loss": 0.0332,
      "step": 98900
    },
    {
      "epoch": 11.916867469879518,
      "grad_norm": 0.7290714979171753,
      "learning_rate": 8.083132530120483e-06,
      "loss": 0.0171,
      "step": 98910
    },
    {
      "epoch": 11.918072289156626,
      "grad_norm": 1.119853138923645,
      "learning_rate": 8.081927710843375e-06,
      "loss": 0.0217,
      "step": 98920
    },
    {
      "epoch": 11.919277108433734,
      "grad_norm": 0.03953393176198006,
      "learning_rate": 8.080722891566266e-06,
      "loss": 0.044,
      "step": 98930
    },
    {
      "epoch": 11.920481927710844,
      "grad_norm": 0.01619531214237213,
      "learning_rate": 8.079518072289158e-06,
      "loss": 0.0145,
      "step": 98940
    },
    {
      "epoch": 11.921686746987952,
      "grad_norm": 0.002607526956126094,
      "learning_rate": 8.078313253012049e-06,
      "loss": 0.0093,
      "step": 98950
    },
    {
      "epoch": 11.92289156626506,
      "grad_norm": 1.3740123510360718,
      "learning_rate": 8.07710843373494e-06,
      "loss": 0.0066,
      "step": 98960
    },
    {
      "epoch": 11.92409638554217,
      "grad_norm": 0.002839890541508794,
      "learning_rate": 8.075903614457832e-06,
      "loss": 0.0219,
      "step": 98970
    },
    {
      "epoch": 11.925301204819277,
      "grad_norm": 1.0935462713241577,
      "learning_rate": 8.074698795180723e-06,
      "loss": 0.0137,
      "step": 98980
    },
    {
      "epoch": 11.926506024096385,
      "grad_norm": 0.46075552701950073,
      "learning_rate": 8.073493975903615e-06,
      "loss": 0.0151,
      "step": 98990
    },
    {
      "epoch": 11.927710843373493,
      "grad_norm": 0.0024075142573565245,
      "learning_rate": 8.072289156626508e-06,
      "loss": 0.0188,
      "step": 99000
    },
    {
      "epoch": 11.928915662650603,
      "grad_norm": 1.1011251211166382,
      "learning_rate": 8.071084337349398e-06,
      "loss": 0.0223,
      "step": 99010
    },
    {
      "epoch": 11.93012048192771,
      "grad_norm": 0.7138030529022217,
      "learning_rate": 8.06987951807229e-06,
      "loss": 0.0253,
      "step": 99020
    },
    {
      "epoch": 11.931325301204819,
      "grad_norm": 0.001428730203770101,
      "learning_rate": 8.068674698795182e-06,
      "loss": 0.0017,
      "step": 99030
    },
    {
      "epoch": 11.932530120481928,
      "grad_norm": 0.31964805722236633,
      "learning_rate": 8.067469879518072e-06,
      "loss": 0.0257,
      "step": 99040
    },
    {
      "epoch": 11.933734939759036,
      "grad_norm": 0.004015602637082338,
      "learning_rate": 8.066265060240965e-06,
      "loss": 0.0282,
      "step": 99050
    },
    {
      "epoch": 11.934939759036144,
      "grad_norm": 0.001973645528778434,
      "learning_rate": 8.065060240963856e-06,
      "loss": 0.0353,
      "step": 99060
    },
    {
      "epoch": 11.936144578313254,
      "grad_norm": 0.07651905715465546,
      "learning_rate": 8.063855421686748e-06,
      "loss": 0.02,
      "step": 99070
    },
    {
      "epoch": 11.937349397590362,
      "grad_norm": 0.002681507496163249,
      "learning_rate": 8.062650602409639e-06,
      "loss": 0.0226,
      "step": 99080
    },
    {
      "epoch": 11.93855421686747,
      "grad_norm": 0.021622927859425545,
      "learning_rate": 8.061445783132531e-06,
      "loss": 0.0083,
      "step": 99090
    },
    {
      "epoch": 11.939759036144578,
      "grad_norm": 0.6539397239685059,
      "learning_rate": 8.060240963855422e-06,
      "loss": 0.018,
      "step": 99100
    },
    {
      "epoch": 11.940963855421687,
      "grad_norm": 0.04505256935954094,
      "learning_rate": 8.059036144578314e-06,
      "loss": 0.0075,
      "step": 99110
    },
    {
      "epoch": 11.942168674698795,
      "grad_norm": 0.003960863221436739,
      "learning_rate": 8.057831325301205e-06,
      "loss": 0.0384,
      "step": 99120
    },
    {
      "epoch": 11.943373493975903,
      "grad_norm": 0.0015139037277549505,
      "learning_rate": 8.056626506024096e-06,
      "loss": 0.013,
      "step": 99130
    },
    {
      "epoch": 11.944578313253013,
      "grad_norm": 0.2620793879032135,
      "learning_rate": 8.055421686746988e-06,
      "loss": 0.0183,
      "step": 99140
    },
    {
      "epoch": 11.94578313253012,
      "grad_norm": 0.0013899037148803473,
      "learning_rate": 8.05421686746988e-06,
      "loss": 0.0268,
      "step": 99150
    },
    {
      "epoch": 11.946987951807229,
      "grad_norm": 0.002679632743820548,
      "learning_rate": 8.053012048192771e-06,
      "loss": 0.0506,
      "step": 99160
    },
    {
      "epoch": 11.948192771084337,
      "grad_norm": 1.517997145652771,
      "learning_rate": 8.051807228915664e-06,
      "loss": 0.0094,
      "step": 99170
    },
    {
      "epoch": 11.949397590361446,
      "grad_norm": 0.0022729875054210424,
      "learning_rate": 8.050602409638555e-06,
      "loss": 0.0152,
      "step": 99180
    },
    {
      "epoch": 11.950602409638554,
      "grad_norm": 0.01098687294870615,
      "learning_rate": 8.049397590361447e-06,
      "loss": 0.0236,
      "step": 99190
    },
    {
      "epoch": 11.951807228915662,
      "grad_norm": 0.016237230971455574,
      "learning_rate": 8.048192771084338e-06,
      "loss": 0.0037,
      "step": 99200
    },
    {
      "epoch": 11.953012048192772,
      "grad_norm": 1.4770722389221191,
      "learning_rate": 8.046987951807229e-06,
      "loss": 0.0203,
      "step": 99210
    },
    {
      "epoch": 11.95421686746988,
      "grad_norm": 0.0034529902040958405,
      "learning_rate": 8.045783132530121e-06,
      "loss": 0.0094,
      "step": 99220
    },
    {
      "epoch": 11.955421686746988,
      "grad_norm": 6.731395721435547,
      "learning_rate": 8.044578313253013e-06,
      "loss": 0.0287,
      "step": 99230
    },
    {
      "epoch": 11.956626506024097,
      "grad_norm": 1.742643117904663,
      "learning_rate": 8.043373493975904e-06,
      "loss": 0.0241,
      "step": 99240
    },
    {
      "epoch": 11.957831325301205,
      "grad_norm": 0.012150843627750874,
      "learning_rate": 8.042168674698797e-06,
      "loss": 0.0953,
      "step": 99250
    },
    {
      "epoch": 11.959036144578313,
      "grad_norm": 0.02772418223321438,
      "learning_rate": 8.040963855421687e-06,
      "loss": 0.0065,
      "step": 99260
    },
    {
      "epoch": 11.960240963855421,
      "grad_norm": 0.013691688887774944,
      "learning_rate": 8.039759036144578e-06,
      "loss": 0.0243,
      "step": 99270
    },
    {
      "epoch": 11.96144578313253,
      "grad_norm": 3.9857914447784424,
      "learning_rate": 8.03855421686747e-06,
      "loss": 0.0525,
      "step": 99280
    },
    {
      "epoch": 11.962650602409639,
      "grad_norm": 1.6143510341644287,
      "learning_rate": 8.037349397590361e-06,
      "loss": 0.0441,
      "step": 99290
    },
    {
      "epoch": 11.963855421686747,
      "grad_norm": 0.0009831850184127688,
      "learning_rate": 8.036144578313254e-06,
      "loss": 0.0233,
      "step": 99300
    },
    {
      "epoch": 11.965060240963856,
      "grad_norm": 0.0029728247318416834,
      "learning_rate": 8.034939759036146e-06,
      "loss": 0.0399,
      "step": 99310
    },
    {
      "epoch": 11.966265060240964,
      "grad_norm": 0.3180924355983734,
      "learning_rate": 8.033734939759037e-06,
      "loss": 0.0113,
      "step": 99320
    },
    {
      "epoch": 11.967469879518072,
      "grad_norm": 0.020566096529364586,
      "learning_rate": 8.032530120481928e-06,
      "loss": 0.0515,
      "step": 99330
    },
    {
      "epoch": 11.96867469879518,
      "grad_norm": 0.0015077852876856923,
      "learning_rate": 8.03132530120482e-06,
      "loss": 0.0144,
      "step": 99340
    },
    {
      "epoch": 11.96987951807229,
      "grad_norm": 0.5134448409080505,
      "learning_rate": 8.03012048192771e-06,
      "loss": 0.03,
      "step": 99350
    },
    {
      "epoch": 11.971084337349398,
      "grad_norm": 0.2397460788488388,
      "learning_rate": 8.028915662650603e-06,
      "loss": 0.0092,
      "step": 99360
    },
    {
      "epoch": 11.972289156626506,
      "grad_norm": 0.0013575152261182666,
      "learning_rate": 8.027710843373496e-06,
      "loss": 0.0357,
      "step": 99370
    },
    {
      "epoch": 11.973493975903615,
      "grad_norm": 1.8304589986801147,
      "learning_rate": 8.026506024096386e-06,
      "loss": 0.01,
      "step": 99380
    },
    {
      "epoch": 11.974698795180723,
      "grad_norm": 0.07717419415712357,
      "learning_rate": 8.025301204819279e-06,
      "loss": 0.019,
      "step": 99390
    },
    {
      "epoch": 11.975903614457831,
      "grad_norm": 0.09412449598312378,
      "learning_rate": 8.02409638554217e-06,
      "loss": 0.0543,
      "step": 99400
    },
    {
      "epoch": 11.977108433734939,
      "grad_norm": 0.0012469397624954581,
      "learning_rate": 8.02289156626506e-06,
      "loss": 0.0104,
      "step": 99410
    },
    {
      "epoch": 11.978313253012049,
      "grad_norm": 0.08529259264469147,
      "learning_rate": 8.021686746987953e-06,
      "loss": 0.0084,
      "step": 99420
    },
    {
      "epoch": 11.979518072289157,
      "grad_norm": 0.023347433656454086,
      "learning_rate": 8.020481927710843e-06,
      "loss": 0.0209,
      "step": 99430
    },
    {
      "epoch": 11.980722891566264,
      "grad_norm": 0.4829218089580536,
      "learning_rate": 8.019277108433736e-06,
      "loss": 0.008,
      "step": 99440
    },
    {
      "epoch": 11.981927710843374,
      "grad_norm": 0.0010213264031335711,
      "learning_rate": 8.018072289156628e-06,
      "loss": 0.0316,
      "step": 99450
    },
    {
      "epoch": 11.983132530120482,
      "grad_norm": 0.03740430995821953,
      "learning_rate": 8.016867469879519e-06,
      "loss": 0.021,
      "step": 99460
    },
    {
      "epoch": 11.98433734939759,
      "grad_norm": 3.3516790866851807,
      "learning_rate": 8.01566265060241e-06,
      "loss": 0.0248,
      "step": 99470
    },
    {
      "epoch": 11.985542168674698,
      "grad_norm": 0.05536097288131714,
      "learning_rate": 8.014457831325302e-06,
      "loss": 0.0209,
      "step": 99480
    },
    {
      "epoch": 11.986746987951808,
      "grad_norm": 1.0618168115615845,
      "learning_rate": 8.013253012048193e-06,
      "loss": 0.0202,
      "step": 99490
    },
    {
      "epoch": 11.987951807228916,
      "grad_norm": 0.408023476600647,
      "learning_rate": 8.012048192771085e-06,
      "loss": 0.0179,
      "step": 99500
    },
    {
      "epoch": 11.989156626506023,
      "grad_norm": 0.957436740398407,
      "learning_rate": 8.010843373493976e-06,
      "loss": 0.0186,
      "step": 99510
    },
    {
      "epoch": 11.990361445783133,
      "grad_norm": 1.222143292427063,
      "learning_rate": 8.009638554216869e-06,
      "loss": 0.0256,
      "step": 99520
    },
    {
      "epoch": 11.991566265060241,
      "grad_norm": 0.002955835312604904,
      "learning_rate": 8.00843373493976e-06,
      "loss": 0.0074,
      "step": 99530
    },
    {
      "epoch": 11.992771084337349,
      "grad_norm": 0.014066457748413086,
      "learning_rate": 8.007228915662652e-06,
      "loss": 0.0147,
      "step": 99540
    },
    {
      "epoch": 11.993975903614459,
      "grad_norm": 1.0402069091796875,
      "learning_rate": 8.006024096385543e-06,
      "loss": 0.0203,
      "step": 99550
    },
    {
      "epoch": 11.995180722891567,
      "grad_norm": 0.2683090567588806,
      "learning_rate": 8.004819277108435e-06,
      "loss": 0.0088,
      "step": 99560
    },
    {
      "epoch": 11.996385542168674,
      "grad_norm": 0.063763827085495,
      "learning_rate": 8.003614457831326e-06,
      "loss": 0.0622,
      "step": 99570
    },
    {
      "epoch": 11.997590361445782,
      "grad_norm": 0.0013204795541241765,
      "learning_rate": 8.002409638554216e-06,
      "loss": 0.0046,
      "step": 99580
    },
    {
      "epoch": 11.998795180722892,
      "grad_norm": 0.000992635847069323,
      "learning_rate": 8.001204819277109e-06,
      "loss": 0.0072,
      "step": 99590
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.482879877090454,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0574,
      "step": 99600
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.9874625046869141,
      "eval_f1": 0.9665227457605907,
      "eval_loss": 0.04510572552680969,
      "eval_precision": 0.9788339670468948,
      "eval_recall": 0.9545173649734273,
      "eval_runtime": 3342.2514,
      "eval_samples_per_second": 12.773,
      "eval_steps_per_second": 0.532,
      "step": 99600
    },
    {
      "epoch": 12.001204819277108,
      "grad_norm": 0.01778615079820156,
      "learning_rate": 7.998795180722892e-06,
      "loss": 0.0094,
      "step": 99610
    },
    {
      "epoch": 12.002409638554218,
      "grad_norm": 1.4631540775299072,
      "learning_rate": 7.997590361445785e-06,
      "loss": 0.016,
      "step": 99620
    },
    {
      "epoch": 12.003614457831326,
      "grad_norm": 0.03914450854063034,
      "learning_rate": 7.996385542168675e-06,
      "loss": 0.0109,
      "step": 99630
    },
    {
      "epoch": 12.004819277108433,
      "grad_norm": 0.6365963220596313,
      "learning_rate": 7.995180722891566e-06,
      "loss": 0.005,
      "step": 99640
    },
    {
      "epoch": 12.006024096385541,
      "grad_norm": 0.01685689203441143,
      "learning_rate": 7.993975903614458e-06,
      "loss": 0.0099,
      "step": 99650
    },
    {
      "epoch": 12.007228915662651,
      "grad_norm": 1.4871355295181274,
      "learning_rate": 7.99277108433735e-06,
      "loss": 0.0399,
      "step": 99660
    },
    {
      "epoch": 12.008433734939759,
      "grad_norm": 0.004942410159856081,
      "learning_rate": 7.991566265060242e-06,
      "loss": 0.0241,
      "step": 99670
    },
    {
      "epoch": 12.009638554216867,
      "grad_norm": 0.0018431252101436257,
      "learning_rate": 7.990361445783134e-06,
      "loss": 0.0026,
      "step": 99680
    },
    {
      "epoch": 12.010843373493977,
      "grad_norm": 0.0009102056501433253,
      "learning_rate": 7.989156626506025e-06,
      "loss": 0.0149,
      "step": 99690
    },
    {
      "epoch": 12.012048192771084,
      "grad_norm": 0.0007555678021162748,
      "learning_rate": 7.987951807228917e-06,
      "loss": 0.0256,
      "step": 99700
    },
    {
      "epoch": 12.013253012048192,
      "grad_norm": 0.2544032633304596,
      "learning_rate": 7.986746987951808e-06,
      "loss": 0.0112,
      "step": 99710
    },
    {
      "epoch": 12.0144578313253,
      "grad_norm": 0.0016242738347500563,
      "learning_rate": 7.985542168674699e-06,
      "loss": 0.0096,
      "step": 99720
    },
    {
      "epoch": 12.01566265060241,
      "grad_norm": 0.010411896742880344,
      "learning_rate": 7.984337349397591e-06,
      "loss": 0.0158,
      "step": 99730
    },
    {
      "epoch": 12.016867469879518,
      "grad_norm": 0.005708022974431515,
      "learning_rate": 7.983132530120482e-06,
      "loss": 0.0239,
      "step": 99740
    },
    {
      "epoch": 12.018072289156626,
      "grad_norm": 0.0004943374078720808,
      "learning_rate": 7.981927710843374e-06,
      "loss": 0.0062,
      "step": 99750
    },
    {
      "epoch": 12.019277108433736,
      "grad_norm": 0.00422952463850379,
      "learning_rate": 7.980722891566267e-06,
      "loss": 0.0498,
      "step": 99760
    },
    {
      "epoch": 12.020481927710843,
      "grad_norm": 0.22579413652420044,
      "learning_rate": 7.979518072289157e-06,
      "loss": 0.0053,
      "step": 99770
    },
    {
      "epoch": 12.021686746987951,
      "grad_norm": 0.010846794582903385,
      "learning_rate": 7.978313253012048e-06,
      "loss": 0.003,
      "step": 99780
    },
    {
      "epoch": 12.022891566265061,
      "grad_norm": 0.14591072499752045,
      "learning_rate": 7.97710843373494e-06,
      "loss": 0.0068,
      "step": 99790
    },
    {
      "epoch": 12.024096385542169,
      "grad_norm": 0.0019108111737295985,
      "learning_rate": 7.975903614457831e-06,
      "loss": 0.0264,
      "step": 99800
    },
    {
      "epoch": 12.025301204819277,
      "grad_norm": 0.000591339310631156,
      "learning_rate": 7.974698795180724e-06,
      "loss": 0.0079,
      "step": 99810
    },
    {
      "epoch": 12.026506024096385,
      "grad_norm": 0.3329337537288666,
      "learning_rate": 7.973493975903616e-06,
      "loss": 0.0143,
      "step": 99820
    },
    {
      "epoch": 12.027710843373494,
      "grad_norm": 1.26478111743927,
      "learning_rate": 7.972289156626507e-06,
      "loss": 0.0202,
      "step": 99830
    },
    {
      "epoch": 12.028915662650602,
      "grad_norm": 0.3503464460372925,
      "learning_rate": 7.971084337349398e-06,
      "loss": 0.0159,
      "step": 99840
    },
    {
      "epoch": 12.03012048192771,
      "grad_norm": 0.0009184738737531006,
      "learning_rate": 7.96987951807229e-06,
      "loss": 0.0,
      "step": 99850
    },
    {
      "epoch": 12.03132530120482,
      "grad_norm": 0.0013333242386579514,
      "learning_rate": 7.968674698795181e-06,
      "loss": 0.0149,
      "step": 99860
    },
    {
      "epoch": 12.032530120481928,
      "grad_norm": 0.009160925634205341,
      "learning_rate": 7.967469879518073e-06,
      "loss": 0.0131,
      "step": 99870
    },
    {
      "epoch": 12.033734939759036,
      "grad_norm": 0.0004911604919470847,
      "learning_rate": 7.966265060240964e-06,
      "loss": 0.0268,
      "step": 99880
    },
    {
      "epoch": 12.034939759036144,
      "grad_norm": 0.0022168627474457026,
      "learning_rate": 7.965060240963855e-06,
      "loss": 0.0356,
      "step": 99890
    },
    {
      "epoch": 12.036144578313253,
      "grad_norm": 0.32961469888687134,
      "learning_rate": 7.963855421686747e-06,
      "loss": 0.009,
      "step": 99900
    },
    {
      "epoch": 12.037349397590361,
      "grad_norm": 0.019968494772911072,
      "learning_rate": 7.96265060240964e-06,
      "loss": 0.0082,
      "step": 99910
    },
    {
      "epoch": 12.03855421686747,
      "grad_norm": 0.13568764925003052,
      "learning_rate": 7.96144578313253e-06,
      "loss": 0.0035,
      "step": 99920
    },
    {
      "epoch": 12.039759036144579,
      "grad_norm": 0.0006637887563556433,
      "learning_rate": 7.960240963855423e-06,
      "loss": 0.0214,
      "step": 99930
    },
    {
      "epoch": 12.040963855421687,
      "grad_norm": 0.0009593311115168035,
      "learning_rate": 7.959036144578314e-06,
      "loss": 0.0056,
      "step": 99940
    },
    {
      "epoch": 12.042168674698795,
      "grad_norm": 9.230217933654785,
      "learning_rate": 7.957831325301204e-06,
      "loss": 0.0335,
      "step": 99950
    },
    {
      "epoch": 12.043373493975903,
      "grad_norm": 0.004279577173292637,
      "learning_rate": 7.956626506024097e-06,
      "loss": 0.0099,
      "step": 99960
    },
    {
      "epoch": 12.044578313253012,
      "grad_norm": 1.1664339303970337,
      "learning_rate": 7.95542168674699e-06,
      "loss": 0.022,
      "step": 99970
    },
    {
      "epoch": 12.04578313253012,
      "grad_norm": 8.68840217590332,
      "learning_rate": 7.95421686746988e-06,
      "loss": 0.0443,
      "step": 99980
    },
    {
      "epoch": 12.046987951807228,
      "grad_norm": 0.006772802211344242,
      "learning_rate": 7.953012048192772e-06,
      "loss": 0.0053,
      "step": 99990
    },
    {
      "epoch": 12.048192771084338,
      "grad_norm": 0.0011072845663875341,
      "learning_rate": 7.951807228915663e-06,
      "loss": 0.0004,
      "step": 100000
    },
    {
      "epoch": 12.049397590361446,
      "grad_norm": 2.7378695011138916,
      "learning_rate": 7.950602409638556e-06,
      "loss": 0.0256,
      "step": 100010
    },
    {
      "epoch": 12.050602409638554,
      "grad_norm": 0.027571139857172966,
      "learning_rate": 7.949397590361446e-06,
      "loss": 0.0294,
      "step": 100020
    },
    {
      "epoch": 12.051807228915663,
      "grad_norm": 0.001563822035677731,
      "learning_rate": 7.948192771084337e-06,
      "loss": 0.05,
      "step": 100030
    },
    {
      "epoch": 12.053012048192771,
      "grad_norm": 0.34139323234558105,
      "learning_rate": 7.94698795180723e-06,
      "loss": 0.0336,
      "step": 100040
    },
    {
      "epoch": 12.05421686746988,
      "grad_norm": 0.6229894161224365,
      "learning_rate": 7.945783132530122e-06,
      "loss": 0.0159,
      "step": 100050
    },
    {
      "epoch": 12.055421686746987,
      "grad_norm": 0.6066902875900269,
      "learning_rate": 7.944578313253013e-06,
      "loss": 0.0218,
      "step": 100060
    },
    {
      "epoch": 12.056626506024097,
      "grad_norm": 0.004289048723876476,
      "learning_rate": 7.943373493975905e-06,
      "loss": 0.0068,
      "step": 100070
    },
    {
      "epoch": 12.057831325301205,
      "grad_norm": 0.0020643663592636585,
      "learning_rate": 7.942168674698796e-06,
      "loss": 0.0493,
      "step": 100080
    },
    {
      "epoch": 12.059036144578313,
      "grad_norm": 0.0021990223322063684,
      "learning_rate": 7.940963855421687e-06,
      "loss": 0.0112,
      "step": 100090
    },
    {
      "epoch": 12.060240963855422,
      "grad_norm": 0.004258573055267334,
      "learning_rate": 7.939759036144579e-06,
      "loss": 0.0084,
      "step": 100100
    },
    {
      "epoch": 12.06144578313253,
      "grad_norm": 0.0017113825306296349,
      "learning_rate": 7.93855421686747e-06,
      "loss": 0.025,
      "step": 100110
    },
    {
      "epoch": 12.062650602409638,
      "grad_norm": 0.0012972647091373801,
      "learning_rate": 7.937349397590362e-06,
      "loss": 0.0017,
      "step": 100120
    },
    {
      "epoch": 12.063855421686746,
      "grad_norm": 0.7780989408493042,
      "learning_rate": 7.936144578313255e-06,
      "loss": 0.0128,
      "step": 100130
    },
    {
      "epoch": 12.065060240963856,
      "grad_norm": 0.004371982999145985,
      "learning_rate": 7.934939759036145e-06,
      "loss": 0.0136,
      "step": 100140
    },
    {
      "epoch": 12.066265060240964,
      "grad_norm": 0.0013764059403911233,
      "learning_rate": 7.933734939759036e-06,
      "loss": 0.0298,
      "step": 100150
    },
    {
      "epoch": 12.067469879518072,
      "grad_norm": 0.011445725336670876,
      "learning_rate": 7.932530120481929e-06,
      "loss": 0.0163,
      "step": 100160
    },
    {
      "epoch": 12.068674698795181,
      "grad_norm": 0.02298218011856079,
      "learning_rate": 7.93132530120482e-06,
      "loss": 0.0538,
      "step": 100170
    },
    {
      "epoch": 12.06987951807229,
      "grad_norm": 1.6821638345718384,
      "learning_rate": 7.930120481927712e-06,
      "loss": 0.0111,
      "step": 100180
    },
    {
      "epoch": 12.071084337349397,
      "grad_norm": 0.0013967890990898013,
      "learning_rate": 7.928915662650602e-06,
      "loss": 0.0399,
      "step": 100190
    },
    {
      "epoch": 12.072289156626505,
      "grad_norm": 0.006534664425998926,
      "learning_rate": 7.927710843373495e-06,
      "loss": 0.0196,
      "step": 100200
    },
    {
      "epoch": 12.073493975903615,
      "grad_norm": 1.7363003492355347,
      "learning_rate": 7.926506024096386e-06,
      "loss": 0.0206,
      "step": 100210
    },
    {
      "epoch": 12.074698795180723,
      "grad_norm": 0.010414499789476395,
      "learning_rate": 7.925301204819278e-06,
      "loss": 0.012,
      "step": 100220
    },
    {
      "epoch": 12.07590361445783,
      "grad_norm": 0.888836145401001,
      "learning_rate": 7.924096385542169e-06,
      "loss": 0.0326,
      "step": 100230
    },
    {
      "epoch": 12.07710843373494,
      "grad_norm": 0.034970443695783615,
      "learning_rate": 7.922891566265061e-06,
      "loss": 0.0571,
      "step": 100240
    },
    {
      "epoch": 12.078313253012048,
      "grad_norm": 0.007855040021240711,
      "learning_rate": 7.921686746987952e-06,
      "loss": 0.0131,
      "step": 100250
    },
    {
      "epoch": 12.079518072289156,
      "grad_norm": 0.07418279349803925,
      "learning_rate": 7.920481927710843e-06,
      "loss": 0.0062,
      "step": 100260
    },
    {
      "epoch": 12.080722891566266,
      "grad_norm": 0.02788470685482025,
      "learning_rate": 7.919277108433737e-06,
      "loss": 0.0064,
      "step": 100270
    },
    {
      "epoch": 12.081927710843374,
      "grad_norm": 0.46458497643470764,
      "learning_rate": 7.918072289156628e-06,
      "loss": 0.0177,
      "step": 100280
    },
    {
      "epoch": 12.083132530120482,
      "grad_norm": 1.7180863618850708,
      "learning_rate": 7.916867469879518e-06,
      "loss": 0.0181,
      "step": 100290
    },
    {
      "epoch": 12.08433734939759,
      "grad_norm": 0.040138669312000275,
      "learning_rate": 7.91566265060241e-06,
      "loss": 0.0236,
      "step": 100300
    },
    {
      "epoch": 12.0855421686747,
      "grad_norm": 0.001895361696369946,
      "learning_rate": 7.914457831325302e-06,
      "loss": 0.0151,
      "step": 100310
    },
    {
      "epoch": 12.086746987951807,
      "grad_norm": 0.015187239274382591,
      "learning_rate": 7.913253012048194e-06,
      "loss": 0.0479,
      "step": 100320
    },
    {
      "epoch": 12.087951807228915,
      "grad_norm": 0.006999065168201923,
      "learning_rate": 7.912048192771085e-06,
      "loss": 0.0009,
      "step": 100330
    },
    {
      "epoch": 12.089156626506025,
      "grad_norm": 0.00048306488315574825,
      "learning_rate": 7.910843373493975e-06,
      "loss": 0.0274,
      "step": 100340
    },
    {
      "epoch": 12.090361445783133,
      "grad_norm": 1.8729417324066162,
      "learning_rate": 7.909638554216868e-06,
      "loss": 0.0178,
      "step": 100350
    },
    {
      "epoch": 12.09156626506024,
      "grad_norm": 0.0010933867888525128,
      "learning_rate": 7.90843373493976e-06,
      "loss": 0.0212,
      "step": 100360
    },
    {
      "epoch": 12.092771084337349,
      "grad_norm": 0.011926423758268356,
      "learning_rate": 7.907228915662651e-06,
      "loss": 0.0193,
      "step": 100370
    },
    {
      "epoch": 12.093975903614458,
      "grad_norm": 0.02000853791832924,
      "learning_rate": 7.906024096385544e-06,
      "loss": 0.0178,
      "step": 100380
    },
    {
      "epoch": 12.095180722891566,
      "grad_norm": 0.0014721695333719254,
      "learning_rate": 7.904819277108434e-06,
      "loss": 0.0231,
      "step": 100390
    },
    {
      "epoch": 12.096385542168674,
      "grad_norm": 0.0037987325340509415,
      "learning_rate": 7.903614457831325e-06,
      "loss": 0.0037,
      "step": 100400
    },
    {
      "epoch": 12.097590361445784,
      "grad_norm": 0.0012173173017799854,
      "learning_rate": 7.902409638554217e-06,
      "loss": 0.0095,
      "step": 100410
    },
    {
      "epoch": 12.098795180722892,
      "grad_norm": 10.174932479858398,
      "learning_rate": 7.90120481927711e-06,
      "loss": 0.0675,
      "step": 100420
    },
    {
      "epoch": 12.1,
      "grad_norm": 0.0006768289604224265,
      "learning_rate": 7.9e-06,
      "loss": 0.0168,
      "step": 100430
    },
    {
      "epoch": 12.101204819277108,
      "grad_norm": 4.366401195526123,
      "learning_rate": 7.898795180722893e-06,
      "loss": 0.0231,
      "step": 100440
    },
    {
      "epoch": 12.102409638554217,
      "grad_norm": 0.20918136835098267,
      "learning_rate": 7.897590361445784e-06,
      "loss": 0.0085,
      "step": 100450
    },
    {
      "epoch": 12.103614457831325,
      "grad_norm": 1.3404370546340942,
      "learning_rate": 7.896385542168675e-06,
      "loss": 0.0572,
      "step": 100460
    },
    {
      "epoch": 12.104819277108433,
      "grad_norm": 0.003224326530471444,
      "learning_rate": 7.895180722891567e-06,
      "loss": 0.0156,
      "step": 100470
    },
    {
      "epoch": 12.106024096385543,
      "grad_norm": 0.002546687377616763,
      "learning_rate": 7.893975903614458e-06,
      "loss": 0.0125,
      "step": 100480
    },
    {
      "epoch": 12.10722891566265,
      "grad_norm": 0.0023464371915906668,
      "learning_rate": 7.89277108433735e-06,
      "loss": 0.0243,
      "step": 100490
    },
    {
      "epoch": 12.108433734939759,
      "grad_norm": 0.008280702866613865,
      "learning_rate": 7.891566265060243e-06,
      "loss": 0.0166,
      "step": 100500
    },
    {
      "epoch": 12.109638554216868,
      "grad_norm": 3.057811975479126,
      "learning_rate": 7.890361445783133e-06,
      "loss": 0.0312,
      "step": 100510
    },
    {
      "epoch": 12.110843373493976,
      "grad_norm": 1.2157150506973267,
      "learning_rate": 7.889156626506024e-06,
      "loss": 0.0171,
      "step": 100520
    },
    {
      "epoch": 12.112048192771084,
      "grad_norm": 0.010440252721309662,
      "learning_rate": 7.887951807228916e-06,
      "loss": 0.0318,
      "step": 100530
    },
    {
      "epoch": 12.113253012048192,
      "grad_norm": 0.0009776338702067733,
      "learning_rate": 7.886746987951807e-06,
      "loss": 0.0121,
      "step": 100540
    },
    {
      "epoch": 12.114457831325302,
      "grad_norm": 0.0014277765294536948,
      "learning_rate": 7.8855421686747e-06,
      "loss": 0.0026,
      "step": 100550
    },
    {
      "epoch": 12.11566265060241,
      "grad_norm": 0.0005492435884661973,
      "learning_rate": 7.88433734939759e-06,
      "loss": 0.0148,
      "step": 100560
    },
    {
      "epoch": 12.116867469879518,
      "grad_norm": 0.005802176892757416,
      "learning_rate": 7.883132530120483e-06,
      "loss": 0.0388,
      "step": 100570
    },
    {
      "epoch": 12.118072289156627,
      "grad_norm": 1.2516121864318848,
      "learning_rate": 7.881927710843375e-06,
      "loss": 0.0216,
      "step": 100580
    },
    {
      "epoch": 12.119277108433735,
      "grad_norm": 0.004150778520852327,
      "learning_rate": 7.880722891566266e-06,
      "loss": 0.0074,
      "step": 100590
    },
    {
      "epoch": 12.120481927710843,
      "grad_norm": 0.007970967330038548,
      "learning_rate": 7.879518072289157e-06,
      "loss": 0.0308,
      "step": 100600
    },
    {
      "epoch": 12.121686746987951,
      "grad_norm": 2.0264480113983154,
      "learning_rate": 7.87831325301205e-06,
      "loss": 0.018,
      "step": 100610
    },
    {
      "epoch": 12.12289156626506,
      "grad_norm": 0.005493778269737959,
      "learning_rate": 7.87710843373494e-06,
      "loss": 0.0269,
      "step": 100620
    },
    {
      "epoch": 12.124096385542169,
      "grad_norm": 0.01658320240676403,
      "learning_rate": 7.875903614457832e-06,
      "loss": 0.0133,
      "step": 100630
    },
    {
      "epoch": 12.125301204819277,
      "grad_norm": 0.0040321447886526585,
      "learning_rate": 7.874698795180723e-06,
      "loss": 0.0071,
      "step": 100640
    },
    {
      "epoch": 12.126506024096386,
      "grad_norm": 0.005974532105028629,
      "learning_rate": 7.873493975903616e-06,
      "loss": 0.0154,
      "step": 100650
    },
    {
      "epoch": 12.127710843373494,
      "grad_norm": 1.1184321641921997,
      "learning_rate": 7.872289156626506e-06,
      "loss": 0.0478,
      "step": 100660
    },
    {
      "epoch": 12.128915662650602,
      "grad_norm": 0.6480970978736877,
      "learning_rate": 7.871084337349399e-06,
      "loss": 0.0103,
      "step": 100670
    },
    {
      "epoch": 12.13012048192771,
      "grad_norm": 0.020533086732029915,
      "learning_rate": 7.86987951807229e-06,
      "loss": 0.0277,
      "step": 100680
    },
    {
      "epoch": 12.13132530120482,
      "grad_norm": 0.00200852588750422,
      "learning_rate": 7.868674698795182e-06,
      "loss": 0.0201,
      "step": 100690
    },
    {
      "epoch": 12.132530120481928,
      "grad_norm": 0.4973199665546417,
      "learning_rate": 7.867469879518073e-06,
      "loss": 0.0118,
      "step": 100700
    },
    {
      "epoch": 12.133734939759035,
      "grad_norm": 0.6716442108154297,
      "learning_rate": 7.866265060240963e-06,
      "loss": 0.0179,
      "step": 100710
    },
    {
      "epoch": 12.134939759036145,
      "grad_norm": 0.0046415855176746845,
      "learning_rate": 7.865060240963856e-06,
      "loss": 0.0034,
      "step": 100720
    },
    {
      "epoch": 12.136144578313253,
      "grad_norm": 0.0032334320712834597,
      "learning_rate": 7.863855421686748e-06,
      "loss": 0.0048,
      "step": 100730
    },
    {
      "epoch": 12.137349397590361,
      "grad_norm": 0.0015535530401393771,
      "learning_rate": 7.862650602409639e-06,
      "loss": 0.0045,
      "step": 100740
    },
    {
      "epoch": 12.13855421686747,
      "grad_norm": 3.475318431854248,
      "learning_rate": 7.861445783132531e-06,
      "loss": 0.074,
      "step": 100750
    },
    {
      "epoch": 12.139759036144579,
      "grad_norm": 0.04501868411898613,
      "learning_rate": 7.860240963855422e-06,
      "loss": 0.011,
      "step": 100760
    },
    {
      "epoch": 12.140963855421687,
      "grad_norm": 0.006772210821509361,
      "learning_rate": 7.859036144578313e-06,
      "loss": 0.0153,
      "step": 100770
    },
    {
      "epoch": 12.142168674698794,
      "grad_norm": 0.2269015610218048,
      "learning_rate": 7.857831325301205e-06,
      "loss": 0.017,
      "step": 100780
    },
    {
      "epoch": 12.143373493975904,
      "grad_norm": 0.005698209162801504,
      "learning_rate": 7.856626506024096e-06,
      "loss": 0.0358,
      "step": 100790
    },
    {
      "epoch": 12.144578313253012,
      "grad_norm": 0.001962685026228428,
      "learning_rate": 7.855421686746989e-06,
      "loss": 0.0096,
      "step": 100800
    },
    {
      "epoch": 12.14578313253012,
      "grad_norm": 0.0028414418920874596,
      "learning_rate": 7.854216867469881e-06,
      "loss": 0.0323,
      "step": 100810
    },
    {
      "epoch": 12.14698795180723,
      "grad_norm": 0.7753381729125977,
      "learning_rate": 7.853012048192772e-06,
      "loss": 0.0139,
      "step": 100820
    },
    {
      "epoch": 12.148192771084338,
      "grad_norm": 0.003153149737045169,
      "learning_rate": 7.851807228915664e-06,
      "loss": 0.0043,
      "step": 100830
    },
    {
      "epoch": 12.149397590361446,
      "grad_norm": 0.06149837002158165,
      "learning_rate": 7.850602409638555e-06,
      "loss": 0.0203,
      "step": 100840
    },
    {
      "epoch": 12.150602409638553,
      "grad_norm": 10.568840980529785,
      "learning_rate": 7.849397590361446e-06,
      "loss": 0.0094,
      "step": 100850
    },
    {
      "epoch": 12.151807228915663,
      "grad_norm": 0.8622618913650513,
      "learning_rate": 7.848192771084338e-06,
      "loss": 0.0306,
      "step": 100860
    },
    {
      "epoch": 12.153012048192771,
      "grad_norm": 0.6462293863296509,
      "learning_rate": 7.84698795180723e-06,
      "loss": 0.0092,
      "step": 100870
    },
    {
      "epoch": 12.154216867469879,
      "grad_norm": 0.014436325989663601,
      "learning_rate": 7.845783132530121e-06,
      "loss": 0.0065,
      "step": 100880
    },
    {
      "epoch": 12.155421686746989,
      "grad_norm": 0.000912635528948158,
      "learning_rate": 7.844578313253014e-06,
      "loss": 0.0201,
      "step": 100890
    },
    {
      "epoch": 12.156626506024097,
      "grad_norm": 0.39874958992004395,
      "learning_rate": 7.843373493975904e-06,
      "loss": 0.0297,
      "step": 100900
    },
    {
      "epoch": 12.157831325301204,
      "grad_norm": 3.4294018745422363,
      "learning_rate": 7.842168674698795e-06,
      "loss": 0.0119,
      "step": 100910
    },
    {
      "epoch": 12.159036144578312,
      "grad_norm": 0.002401605248451233,
      "learning_rate": 7.840963855421688e-06,
      "loss": 0.0137,
      "step": 100920
    },
    {
      "epoch": 12.160240963855422,
      "grad_norm": 0.8203754425048828,
      "learning_rate": 7.839759036144578e-06,
      "loss": 0.0164,
      "step": 100930
    },
    {
      "epoch": 12.16144578313253,
      "grad_norm": 0.8457609415054321,
      "learning_rate": 7.83855421686747e-06,
      "loss": 0.011,
      "step": 100940
    },
    {
      "epoch": 12.162650602409638,
      "grad_norm": 1.0281758308410645,
      "learning_rate": 7.837349397590363e-06,
      "loss": 0.0232,
      "step": 100950
    },
    {
      "epoch": 12.163855421686748,
      "grad_norm": 0.0022256714291870594,
      "learning_rate": 7.836144578313254e-06,
      "loss": 0.0019,
      "step": 100960
    },
    {
      "epoch": 12.165060240963856,
      "grad_norm": 0.008652852848172188,
      "learning_rate": 7.834939759036145e-06,
      "loss": 0.0234,
      "step": 100970
    },
    {
      "epoch": 12.166265060240963,
      "grad_norm": 0.0008935352088883519,
      "learning_rate": 7.833734939759037e-06,
      "loss": 0.0079,
      "step": 100980
    },
    {
      "epoch": 12.167469879518073,
      "grad_norm": 0.0017709406092762947,
      "learning_rate": 7.832530120481928e-06,
      "loss": 0.0523,
      "step": 100990
    },
    {
      "epoch": 12.168674698795181,
      "grad_norm": 0.6010473966598511,
      "learning_rate": 7.83132530120482e-06,
      "loss": 0.0075,
      "step": 101000
    },
    {
      "epoch": 12.169879518072289,
      "grad_norm": 0.01638144440948963,
      "learning_rate": 7.830120481927711e-06,
      "loss": 0.0064,
      "step": 101010
    },
    {
      "epoch": 12.171084337349397,
      "grad_norm": 0.001276082475669682,
      "learning_rate": 7.828915662650603e-06,
      "loss": 0.0098,
      "step": 101020
    },
    {
      "epoch": 12.172289156626507,
      "grad_norm": 1.2363412380218506,
      "learning_rate": 7.827710843373494e-06,
      "loss": 0.005,
      "step": 101030
    },
    {
      "epoch": 12.173493975903614,
      "grad_norm": 0.001721389009617269,
      "learning_rate": 7.826506024096387e-06,
      "loss": 0.0043,
      "step": 101040
    },
    {
      "epoch": 12.174698795180722,
      "grad_norm": 0.23139990866184235,
      "learning_rate": 7.825301204819277e-06,
      "loss": 0.0141,
      "step": 101050
    },
    {
      "epoch": 12.175903614457832,
      "grad_norm": 1.1501646041870117,
      "learning_rate": 7.82409638554217e-06,
      "loss": 0.0089,
      "step": 101060
    },
    {
      "epoch": 12.17710843373494,
      "grad_norm": 0.004538529086858034,
      "learning_rate": 7.82289156626506e-06,
      "loss": 0.0134,
      "step": 101070
    },
    {
      "epoch": 12.178313253012048,
      "grad_norm": 0.0037700433749705553,
      "learning_rate": 7.821686746987951e-06,
      "loss": 0.0032,
      "step": 101080
    },
    {
      "epoch": 12.179518072289156,
      "grad_norm": 0.1909317821264267,
      "learning_rate": 7.820481927710844e-06,
      "loss": 0.0483,
      "step": 101090
    },
    {
      "epoch": 12.180722891566266,
      "grad_norm": 0.004539475776255131,
      "learning_rate": 7.819277108433736e-06,
      "loss": 0.0058,
      "step": 101100
    },
    {
      "epoch": 12.181927710843373,
      "grad_norm": 0.02828751690685749,
      "learning_rate": 7.818072289156627e-06,
      "loss": 0.0011,
      "step": 101110
    },
    {
      "epoch": 12.183132530120481,
      "grad_norm": 0.0011878595687448978,
      "learning_rate": 7.81686746987952e-06,
      "loss": 0.0038,
      "step": 101120
    },
    {
      "epoch": 12.184337349397591,
      "grad_norm": 0.002219516783952713,
      "learning_rate": 7.81566265060241e-06,
      "loss": 0.0528,
      "step": 101130
    },
    {
      "epoch": 12.185542168674699,
      "grad_norm": 0.0018825636943802238,
      "learning_rate": 7.814457831325302e-06,
      "loss": 0.0298,
      "step": 101140
    },
    {
      "epoch": 12.186746987951807,
      "grad_norm": 0.03286609426140785,
      "learning_rate": 7.813253012048193e-06,
      "loss": 0.009,
      "step": 101150
    },
    {
      "epoch": 12.187951807228915,
      "grad_norm": 0.0012051524827256799,
      "learning_rate": 7.812048192771084e-06,
      "loss": 0.0265,
      "step": 101160
    },
    {
      "epoch": 12.189156626506024,
      "grad_norm": 0.01771717332303524,
      "learning_rate": 7.810843373493976e-06,
      "loss": 0.0153,
      "step": 101170
    },
    {
      "epoch": 12.190361445783132,
      "grad_norm": 0.0008594825048930943,
      "learning_rate": 7.809638554216869e-06,
      "loss": 0.025,
      "step": 101180
    },
    {
      "epoch": 12.19156626506024,
      "grad_norm": 2.4925427436828613,
      "learning_rate": 7.80843373493976e-06,
      "loss": 0.0446,
      "step": 101190
    },
    {
      "epoch": 12.19277108433735,
      "grad_norm": 0.0009033906389959157,
      "learning_rate": 7.807228915662652e-06,
      "loss": 0.0054,
      "step": 101200
    },
    {
      "epoch": 12.193975903614458,
      "grad_norm": 0.1112445816397667,
      "learning_rate": 7.806024096385543e-06,
      "loss": 0.0108,
      "step": 101210
    },
    {
      "epoch": 12.195180722891566,
      "grad_norm": 0.003553323447704315,
      "learning_rate": 7.804819277108434e-06,
      "loss": 0.0062,
      "step": 101220
    },
    {
      "epoch": 12.196385542168676,
      "grad_norm": 0.002062354702502489,
      "learning_rate": 7.803614457831326e-06,
      "loss": 0.0217,
      "step": 101230
    },
    {
      "epoch": 12.197590361445783,
      "grad_norm": 0.008369372226297855,
      "learning_rate": 7.802409638554217e-06,
      "loss": 0.0048,
      "step": 101240
    },
    {
      "epoch": 12.198795180722891,
      "grad_norm": 1.3607218265533447,
      "learning_rate": 7.801204819277109e-06,
      "loss": 0.0075,
      "step": 101250
    },
    {
      "epoch": 12.2,
      "grad_norm": 0.9587050676345825,
      "learning_rate": 7.800000000000002e-06,
      "loss": 0.0135,
      "step": 101260
    },
    {
      "epoch": 12.201204819277109,
      "grad_norm": 0.0028512333519756794,
      "learning_rate": 7.798795180722892e-06,
      "loss": 0.0198,
      "step": 101270
    },
    {
      "epoch": 12.202409638554217,
      "grad_norm": 1.2142716646194458,
      "learning_rate": 7.797590361445783e-06,
      "loss": 0.0193,
      "step": 101280
    },
    {
      "epoch": 12.203614457831325,
      "grad_norm": 0.23331928253173828,
      "learning_rate": 7.796385542168675e-06,
      "loss": 0.0052,
      "step": 101290
    },
    {
      "epoch": 12.204819277108435,
      "grad_norm": 0.00041597141535021365,
      "learning_rate": 7.795180722891566e-06,
      "loss": 0.0427,
      "step": 101300
    },
    {
      "epoch": 12.206024096385542,
      "grad_norm": 0.005156437400728464,
      "learning_rate": 7.793975903614459e-06,
      "loss": 0.0118,
      "step": 101310
    },
    {
      "epoch": 12.20722891566265,
      "grad_norm": 0.03597142547369003,
      "learning_rate": 7.792771084337351e-06,
      "loss": 0.0558,
      "step": 101320
    },
    {
      "epoch": 12.208433734939758,
      "grad_norm": 0.5945643186569214,
      "learning_rate": 7.791566265060242e-06,
      "loss": 0.0146,
      "step": 101330
    },
    {
      "epoch": 12.209638554216868,
      "grad_norm": 0.5425509214401245,
      "learning_rate": 7.790361445783133e-06,
      "loss": 0.0164,
      "step": 101340
    },
    {
      "epoch": 12.210843373493976,
      "grad_norm": 0.0006283839466050267,
      "learning_rate": 7.789156626506025e-06,
      "loss": 0.0117,
      "step": 101350
    },
    {
      "epoch": 12.212048192771084,
      "grad_norm": 0.006533140316605568,
      "learning_rate": 7.787951807228916e-06,
      "loss": 0.0225,
      "step": 101360
    },
    {
      "epoch": 12.213253012048193,
      "grad_norm": 0.008732261136174202,
      "learning_rate": 7.786746987951808e-06,
      "loss": 0.0377,
      "step": 101370
    },
    {
      "epoch": 12.214457831325301,
      "grad_norm": 0.0006941387546248734,
      "learning_rate": 7.785542168674699e-06,
      "loss": 0.0049,
      "step": 101380
    },
    {
      "epoch": 12.21566265060241,
      "grad_norm": 1.6406010389328003,
      "learning_rate": 7.78433734939759e-06,
      "loss": 0.0116,
      "step": 101390
    },
    {
      "epoch": 12.216867469879517,
      "grad_norm": 0.000511032179929316,
      "learning_rate": 7.783132530120484e-06,
      "loss": 0.0041,
      "step": 101400
    },
    {
      "epoch": 12.218072289156627,
      "grad_norm": 0.0014812060398980975,
      "learning_rate": 7.781927710843375e-06,
      "loss": 0.0043,
      "step": 101410
    },
    {
      "epoch": 12.219277108433735,
      "grad_norm": 0.01827145554125309,
      "learning_rate": 7.780722891566265e-06,
      "loss": 0.0234,
      "step": 101420
    },
    {
      "epoch": 12.220481927710843,
      "grad_norm": 1.3020100593566895,
      "learning_rate": 7.779518072289158e-06,
      "loss": 0.0092,
      "step": 101430
    },
    {
      "epoch": 12.221686746987952,
      "grad_norm": 0.0010475496528670192,
      "learning_rate": 7.778313253012048e-06,
      "loss": 0.0052,
      "step": 101440
    },
    {
      "epoch": 12.22289156626506,
      "grad_norm": 0.00134730723220855,
      "learning_rate": 7.777108433734941e-06,
      "loss": 0.0034,
      "step": 101450
    },
    {
      "epoch": 12.224096385542168,
      "grad_norm": 0.0011090198531746864,
      "learning_rate": 7.775903614457832e-06,
      "loss": 0.0084,
      "step": 101460
    },
    {
      "epoch": 12.225301204819278,
      "grad_norm": 0.0019748585764318705,
      "learning_rate": 7.774698795180724e-06,
      "loss": 0.0026,
      "step": 101470
    },
    {
      "epoch": 12.226506024096386,
      "grad_norm": 0.0017564315348863602,
      "learning_rate": 7.773493975903615e-06,
      "loss": 0.0039,
      "step": 101480
    },
    {
      "epoch": 12.227710843373494,
      "grad_norm": 1.1692012548446655,
      "learning_rate": 7.772289156626507e-06,
      "loss": 0.0045,
      "step": 101490
    },
    {
      "epoch": 12.228915662650602,
      "grad_norm": 1.481799840927124,
      "learning_rate": 7.771084337349398e-06,
      "loss": 0.0146,
      "step": 101500
    },
    {
      "epoch": 12.230120481927711,
      "grad_norm": 0.009070073254406452,
      "learning_rate": 7.76987951807229e-06,
      "loss": 0.0038,
      "step": 101510
    },
    {
      "epoch": 12.23132530120482,
      "grad_norm": 0.0012152508134022355,
      "learning_rate": 7.768674698795181e-06,
      "loss": 0.0025,
      "step": 101520
    },
    {
      "epoch": 12.232530120481927,
      "grad_norm": 0.0011041732504963875,
      "learning_rate": 7.767469879518072e-06,
      "loss": 0.0154,
      "step": 101530
    },
    {
      "epoch": 12.233734939759037,
      "grad_norm": 1.7991600036621094,
      "learning_rate": 7.766265060240964e-06,
      "loss": 0.0528,
      "step": 101540
    },
    {
      "epoch": 12.234939759036145,
      "grad_norm": 0.0008567825425416231,
      "learning_rate": 7.765060240963857e-06,
      "loss": 0.0278,
      "step": 101550
    },
    {
      "epoch": 12.236144578313253,
      "grad_norm": 0.24680684506893158,
      "learning_rate": 7.763855421686747e-06,
      "loss": 0.0014,
      "step": 101560
    },
    {
      "epoch": 12.23734939759036,
      "grad_norm": 0.004689368885010481,
      "learning_rate": 7.76265060240964e-06,
      "loss": 0.0273,
      "step": 101570
    },
    {
      "epoch": 12.23855421686747,
      "grad_norm": 6.275530815124512,
      "learning_rate": 7.76144578313253e-06,
      "loss": 0.016,
      "step": 101580
    },
    {
      "epoch": 12.239759036144578,
      "grad_norm": 9.137518882751465,
      "learning_rate": 7.760240963855421e-06,
      "loss": 0.048,
      "step": 101590
    },
    {
      "epoch": 12.240963855421686,
      "grad_norm": 0.009770264849066734,
      "learning_rate": 7.759036144578314e-06,
      "loss": 0.0317,
      "step": 101600
    },
    {
      "epoch": 12.242168674698796,
      "grad_norm": 0.007255553733557463,
      "learning_rate": 7.757831325301205e-06,
      "loss": 0.0202,
      "step": 101610
    },
    {
      "epoch": 12.243373493975904,
      "grad_norm": 0.008336283266544342,
      "learning_rate": 7.756626506024097e-06,
      "loss": 0.0262,
      "step": 101620
    },
    {
      "epoch": 12.244578313253012,
      "grad_norm": 0.0423683300614357,
      "learning_rate": 7.75542168674699e-06,
      "loss": 0.0213,
      "step": 101630
    },
    {
      "epoch": 12.24578313253012,
      "grad_norm": 1.1371561288833618,
      "learning_rate": 7.75421686746988e-06,
      "loss": 0.0242,
      "step": 101640
    },
    {
      "epoch": 12.24698795180723,
      "grad_norm": 0.005234735552221537,
      "learning_rate": 7.753012048192771e-06,
      "loss": 0.0046,
      "step": 101650
    },
    {
      "epoch": 12.248192771084337,
      "grad_norm": 1.2157801389694214,
      "learning_rate": 7.751807228915663e-06,
      "loss": 0.0142,
      "step": 101660
    },
    {
      "epoch": 12.249397590361445,
      "grad_norm": 0.0028946103993803263,
      "learning_rate": 7.750602409638554e-06,
      "loss": 0.0132,
      "step": 101670
    },
    {
      "epoch": 12.250602409638555,
      "grad_norm": 0.7061922550201416,
      "learning_rate": 7.749397590361447e-06,
      "loss": 0.0123,
      "step": 101680
    },
    {
      "epoch": 12.251807228915663,
      "grad_norm": 0.0004667289031203836,
      "learning_rate": 7.748192771084339e-06,
      "loss": 0.0027,
      "step": 101690
    },
    {
      "epoch": 12.25301204819277,
      "grad_norm": 1.0773762464523315,
      "learning_rate": 7.74698795180723e-06,
      "loss": 0.0165,
      "step": 101700
    },
    {
      "epoch": 12.25421686746988,
      "grad_norm": 0.006378697231411934,
      "learning_rate": 7.745783132530122e-06,
      "loss": 0.0125,
      "step": 101710
    },
    {
      "epoch": 12.255421686746988,
      "grad_norm": 1.9442524909973145,
      "learning_rate": 7.744578313253013e-06,
      "loss": 0.0128,
      "step": 101720
    },
    {
      "epoch": 12.256626506024096,
      "grad_norm": 1.6871861219406128,
      "learning_rate": 7.743373493975904e-06,
      "loss": 0.0133,
      "step": 101730
    },
    {
      "epoch": 12.257831325301204,
      "grad_norm": 0.0011273721465840936,
      "learning_rate": 7.742168674698796e-06,
      "loss": 0.002,
      "step": 101740
    },
    {
      "epoch": 12.259036144578314,
      "grad_norm": 0.009308123029768467,
      "learning_rate": 7.740963855421687e-06,
      "loss": 0.0044,
      "step": 101750
    },
    {
      "epoch": 12.260240963855422,
      "grad_norm": 0.0008017210057005286,
      "learning_rate": 7.73975903614458e-06,
      "loss": 0.0041,
      "step": 101760
    },
    {
      "epoch": 12.26144578313253,
      "grad_norm": 0.00047284713946282864,
      "learning_rate": 7.738554216867472e-06,
      "loss": 0.0073,
      "step": 101770
    },
    {
      "epoch": 12.26265060240964,
      "grad_norm": 0.16316798329353333,
      "learning_rate": 7.737349397590362e-06,
      "loss": 0.0295,
      "step": 101780
    },
    {
      "epoch": 12.263855421686747,
      "grad_norm": 0.00495024211704731,
      "learning_rate": 7.736144578313253e-06,
      "loss": 0.0081,
      "step": 101790
    },
    {
      "epoch": 12.265060240963855,
      "grad_norm": 1.6659300327301025,
      "learning_rate": 7.734939759036146e-06,
      "loss": 0.0153,
      "step": 101800
    },
    {
      "epoch": 12.266265060240963,
      "grad_norm": 0.5228603482246399,
      "learning_rate": 7.733734939759036e-06,
      "loss": 0.0234,
      "step": 101810
    },
    {
      "epoch": 12.267469879518073,
      "grad_norm": 0.04961599409580231,
      "learning_rate": 7.732530120481929e-06,
      "loss": 0.0285,
      "step": 101820
    },
    {
      "epoch": 12.26867469879518,
      "grad_norm": 0.03555256128311157,
      "learning_rate": 7.73132530120482e-06,
      "loss": 0.0261,
      "step": 101830
    },
    {
      "epoch": 12.269879518072289,
      "grad_norm": 0.18029621243476868,
      "learning_rate": 7.730120481927712e-06,
      "loss": 0.0345,
      "step": 101840
    },
    {
      "epoch": 12.271084337349398,
      "grad_norm": 0.8024317622184753,
      "learning_rate": 7.728915662650603e-06,
      "loss": 0.0199,
      "step": 101850
    },
    {
      "epoch": 12.272289156626506,
      "grad_norm": 77.18621826171875,
      "learning_rate": 7.727710843373495e-06,
      "loss": 0.0514,
      "step": 101860
    },
    {
      "epoch": 12.273493975903614,
      "grad_norm": 0.03734986484050751,
      "learning_rate": 7.726506024096386e-06,
      "loss": 0.02,
      "step": 101870
    },
    {
      "epoch": 12.274698795180722,
      "grad_norm": 0.00481813121587038,
      "learning_rate": 7.725301204819278e-06,
      "loss": 0.0076,
      "step": 101880
    },
    {
      "epoch": 12.275903614457832,
      "grad_norm": 0.41111016273498535,
      "learning_rate": 7.724096385542169e-06,
      "loss": 0.0199,
      "step": 101890
    },
    {
      "epoch": 12.27710843373494,
      "grad_norm": 0.001102327718399465,
      "learning_rate": 7.72289156626506e-06,
      "loss": 0.0306,
      "step": 101900
    },
    {
      "epoch": 12.278313253012048,
      "grad_norm": 0.8766257166862488,
      "learning_rate": 7.721686746987952e-06,
      "loss": 0.0197,
      "step": 101910
    },
    {
      "epoch": 12.279518072289157,
      "grad_norm": 0.001002877950668335,
      "learning_rate": 7.720481927710845e-06,
      "loss": 0.0059,
      "step": 101920
    },
    {
      "epoch": 12.280722891566265,
      "grad_norm": 1.1527260541915894,
      "learning_rate": 7.719277108433735e-06,
      "loss": 0.0065,
      "step": 101930
    },
    {
      "epoch": 12.281927710843373,
      "grad_norm": 0.001926014432683587,
      "learning_rate": 7.718072289156628e-06,
      "loss": 0.0018,
      "step": 101940
    },
    {
      "epoch": 12.283132530120483,
      "grad_norm": 0.002965085208415985,
      "learning_rate": 7.716867469879519e-06,
      "loss": 0.0056,
      "step": 101950
    },
    {
      "epoch": 12.28433734939759,
      "grad_norm": 0.00042493370710872114,
      "learning_rate": 7.71566265060241e-06,
      "loss": 0.0169,
      "step": 101960
    },
    {
      "epoch": 12.285542168674699,
      "grad_norm": 0.4424270987510681,
      "learning_rate": 7.714457831325302e-06,
      "loss": 0.0319,
      "step": 101970
    },
    {
      "epoch": 12.286746987951807,
      "grad_norm": 1.8482674360275269,
      "learning_rate": 7.713253012048193e-06,
      "loss": 0.0191,
      "step": 101980
    },
    {
      "epoch": 12.287951807228916,
      "grad_norm": 0.7473701238632202,
      "learning_rate": 7.712048192771085e-06,
      "loss": 0.016,
      "step": 101990
    },
    {
      "epoch": 12.289156626506024,
      "grad_norm": 0.00016717262042220682,
      "learning_rate": 7.710843373493977e-06,
      "loss": 0.0091,
      "step": 102000
    },
    {
      "epoch": 12.290361445783132,
      "grad_norm": 0.0008069153991527855,
      "learning_rate": 7.709638554216868e-06,
      "loss": 0.015,
      "step": 102010
    },
    {
      "epoch": 12.291566265060242,
      "grad_norm": 0.00043296729563735425,
      "learning_rate": 7.70843373493976e-06,
      "loss": 0.0039,
      "step": 102020
    },
    {
      "epoch": 12.29277108433735,
      "grad_norm": 0.0007401250768452883,
      "learning_rate": 7.707228915662651e-06,
      "loss": 0.0161,
      "step": 102030
    },
    {
      "epoch": 12.293975903614458,
      "grad_norm": 3.3179056644439697,
      "learning_rate": 7.706024096385542e-06,
      "loss": 0.036,
      "step": 102040
    },
    {
      "epoch": 12.295180722891565,
      "grad_norm": 1.3599252700805664,
      "learning_rate": 7.704819277108434e-06,
      "loss": 0.0201,
      "step": 102050
    },
    {
      "epoch": 12.296385542168675,
      "grad_norm": 0.00848804134875536,
      "learning_rate": 7.703614457831325e-06,
      "loss": 0.0045,
      "step": 102060
    },
    {
      "epoch": 12.297590361445783,
      "grad_norm": 0.000435702211689204,
      "learning_rate": 7.702409638554218e-06,
      "loss": 0.031,
      "step": 102070
    },
    {
      "epoch": 12.298795180722891,
      "grad_norm": 0.007406166289001703,
      "learning_rate": 7.70120481927711e-06,
      "loss": 0.0073,
      "step": 102080
    },
    {
      "epoch": 12.3,
      "grad_norm": 0.06458871066570282,
      "learning_rate": 7.7e-06,
      "loss": 0.0378,
      "step": 102090
    },
    {
      "epoch": 12.301204819277109,
      "grad_norm": 1.412721037864685,
      "learning_rate": 7.698795180722892e-06,
      "loss": 0.0338,
      "step": 102100
    },
    {
      "epoch": 12.302409638554217,
      "grad_norm": 0.019266117364168167,
      "learning_rate": 7.697590361445784e-06,
      "loss": 0.0158,
      "step": 102110
    },
    {
      "epoch": 12.303614457831324,
      "grad_norm": 0.01604035310447216,
      "learning_rate": 7.696385542168675e-06,
      "loss": 0.0132,
      "step": 102120
    },
    {
      "epoch": 12.304819277108434,
      "grad_norm": 3.9025111198425293,
      "learning_rate": 7.695180722891567e-06,
      "loss": 0.0146,
      "step": 102130
    },
    {
      "epoch": 12.306024096385542,
      "grad_norm": 0.3932662606239319,
      "learning_rate": 7.69397590361446e-06,
      "loss": 0.0314,
      "step": 102140
    },
    {
      "epoch": 12.30722891566265,
      "grad_norm": 0.3657056987285614,
      "learning_rate": 7.69277108433735e-06,
      "loss": 0.0283,
      "step": 102150
    },
    {
      "epoch": 12.30843373493976,
      "grad_norm": 0.0014165403554216027,
      "learning_rate": 7.691566265060241e-06,
      "loss": 0.0124,
      "step": 102160
    },
    {
      "epoch": 12.309638554216868,
      "grad_norm": 0.008670738898217678,
      "learning_rate": 7.690361445783134e-06,
      "loss": 0.0018,
      "step": 102170
    },
    {
      "epoch": 12.310843373493976,
      "grad_norm": 0.9769489169120789,
      "learning_rate": 7.689156626506024e-06,
      "loss": 0.031,
      "step": 102180
    },
    {
      "epoch": 12.312048192771085,
      "grad_norm": 0.0009996142471209168,
      "learning_rate": 7.687951807228917e-06,
      "loss": 0.0094,
      "step": 102190
    },
    {
      "epoch": 12.313253012048193,
      "grad_norm": 0.24626483023166656,
      "learning_rate": 7.686746987951807e-06,
      "loss": 0.0408,
      "step": 102200
    },
    {
      "epoch": 12.314457831325301,
      "grad_norm": 0.001479623606428504,
      "learning_rate": 7.685542168674698e-06,
      "loss": 0.002,
      "step": 102210
    },
    {
      "epoch": 12.315662650602409,
      "grad_norm": 0.5650970935821533,
      "learning_rate": 7.684337349397592e-06,
      "loss": 0.0094,
      "step": 102220
    },
    {
      "epoch": 12.316867469879519,
      "grad_norm": 2.1205899715423584,
      "learning_rate": 7.683132530120483e-06,
      "loss": 0.0182,
      "step": 102230
    },
    {
      "epoch": 12.318072289156627,
      "grad_norm": 0.003526031970977783,
      "learning_rate": 7.681927710843374e-06,
      "loss": 0.0096,
      "step": 102240
    },
    {
      "epoch": 12.319277108433734,
      "grad_norm": 0.022673843428492546,
      "learning_rate": 7.680722891566266e-06,
      "loss": 0.0013,
      "step": 102250
    },
    {
      "epoch": 12.320481927710844,
      "grad_norm": 0.12152877449989319,
      "learning_rate": 7.679518072289157e-06,
      "loss": 0.0034,
      "step": 102260
    },
    {
      "epoch": 12.321686746987952,
      "grad_norm": 0.28109049797058105,
      "learning_rate": 7.678313253012048e-06,
      "loss": 0.0104,
      "step": 102270
    },
    {
      "epoch": 12.32289156626506,
      "grad_norm": 0.019909026101231575,
      "learning_rate": 7.67710843373494e-06,
      "loss": 0.0004,
      "step": 102280
    },
    {
      "epoch": 12.324096385542168,
      "grad_norm": 1.740531325340271,
      "learning_rate": 7.675903614457833e-06,
      "loss": 0.0165,
      "step": 102290
    },
    {
      "epoch": 12.325301204819278,
      "grad_norm": 0.004338744096457958,
      "learning_rate": 7.674698795180723e-06,
      "loss": 0.0011,
      "step": 102300
    },
    {
      "epoch": 12.326506024096386,
      "grad_norm": 0.0011232857359573245,
      "learning_rate": 7.673493975903616e-06,
      "loss": 0.0099,
      "step": 102310
    },
    {
      "epoch": 12.327710843373493,
      "grad_norm": 0.44567400217056274,
      "learning_rate": 7.672289156626506e-06,
      "loss": 0.0633,
      "step": 102320
    },
    {
      "epoch": 12.328915662650603,
      "grad_norm": 0.01441473700106144,
      "learning_rate": 7.671084337349399e-06,
      "loss": 0.0111,
      "step": 102330
    },
    {
      "epoch": 12.330120481927711,
      "grad_norm": 0.5661299824714661,
      "learning_rate": 7.66987951807229e-06,
      "loss": 0.0438,
      "step": 102340
    },
    {
      "epoch": 12.331325301204819,
      "grad_norm": 0.0035487257409840822,
      "learning_rate": 7.66867469879518e-06,
      "loss": 0.0002,
      "step": 102350
    },
    {
      "epoch": 12.332530120481927,
      "grad_norm": 0.0031696674413979053,
      "learning_rate": 7.667469879518073e-06,
      "loss": 0.012,
      "step": 102360
    },
    {
      "epoch": 12.333734939759037,
      "grad_norm": 0.0021772522013634443,
      "learning_rate": 7.666265060240965e-06,
      "loss": 0.0105,
      "step": 102370
    },
    {
      "epoch": 12.334939759036144,
      "grad_norm": 0.0013379057636484504,
      "learning_rate": 7.665060240963856e-06,
      "loss": 0.0135,
      "step": 102380
    },
    {
      "epoch": 12.336144578313252,
      "grad_norm": 1.423148512840271,
      "learning_rate": 7.663855421686748e-06,
      "loss": 0.014,
      "step": 102390
    },
    {
      "epoch": 12.337349397590362,
      "grad_norm": 0.3016371726989746,
      "learning_rate": 7.66265060240964e-06,
      "loss": 0.011,
      "step": 102400
    },
    {
      "epoch": 12.33855421686747,
      "grad_norm": 1.79450261592865,
      "learning_rate": 7.66144578313253e-06,
      "loss": 0.0199,
      "step": 102410
    },
    {
      "epoch": 12.339759036144578,
      "grad_norm": 0.16627918183803558,
      "learning_rate": 7.660240963855422e-06,
      "loss": 0.0222,
      "step": 102420
    },
    {
      "epoch": 12.340963855421688,
      "grad_norm": 0.0018518827855587006,
      "learning_rate": 7.659036144578313e-06,
      "loss": 0.0481,
      "step": 102430
    },
    {
      "epoch": 12.342168674698796,
      "grad_norm": 1.3827884197235107,
      "learning_rate": 7.657831325301206e-06,
      "loss": 0.0214,
      "step": 102440
    },
    {
      "epoch": 12.343373493975903,
      "grad_norm": 0.0014900201931595802,
      "learning_rate": 7.656626506024098e-06,
      "loss": 0.0036,
      "step": 102450
    },
    {
      "epoch": 12.344578313253011,
      "grad_norm": 0.0019427008228376508,
      "learning_rate": 7.655421686746989e-06,
      "loss": 0.0251,
      "step": 102460
    },
    {
      "epoch": 12.345783132530121,
      "grad_norm": 0.003304780460894108,
      "learning_rate": 7.65421686746988e-06,
      "loss": 0.0282,
      "step": 102470
    },
    {
      "epoch": 12.346987951807229,
      "grad_norm": 1.7259999513626099,
      "learning_rate": 7.653012048192772e-06,
      "loss": 0.0167,
      "step": 102480
    },
    {
      "epoch": 12.348192771084337,
      "grad_norm": 3.841916799545288,
      "learning_rate": 7.651807228915663e-06,
      "loss": 0.0235,
      "step": 102490
    },
    {
      "epoch": 12.349397590361447,
      "grad_norm": 0.2986011505126953,
      "learning_rate": 7.650602409638555e-06,
      "loss": 0.0045,
      "step": 102500
    },
    {
      "epoch": 12.350602409638554,
      "grad_norm": 0.6775743961334229,
      "learning_rate": 7.649397590361446e-06,
      "loss": 0.0051,
      "step": 102510
    },
    {
      "epoch": 12.351807228915662,
      "grad_norm": 0.0999947339296341,
      "learning_rate": 7.648192771084338e-06,
      "loss": 0.0285,
      "step": 102520
    },
    {
      "epoch": 12.35301204819277,
      "grad_norm": 1.617269515991211,
      "learning_rate": 7.64698795180723e-06,
      "loss": 0.0118,
      "step": 102530
    },
    {
      "epoch": 12.35421686746988,
      "grad_norm": 0.0026457516942173243,
      "learning_rate": 7.645783132530121e-06,
      "loss": 0.0035,
      "step": 102540
    },
    {
      "epoch": 12.355421686746988,
      "grad_norm": 1.373479962348938,
      "learning_rate": 7.644578313253012e-06,
      "loss": 0.033,
      "step": 102550
    },
    {
      "epoch": 12.356626506024096,
      "grad_norm": 0.0023395090829581022,
      "learning_rate": 7.643373493975905e-06,
      "loss": 0.0138,
      "step": 102560
    },
    {
      "epoch": 12.357831325301206,
      "grad_norm": 0.1411105841398239,
      "learning_rate": 7.642168674698795e-06,
      "loss": 0.0064,
      "step": 102570
    },
    {
      "epoch": 12.359036144578313,
      "grad_norm": 0.001992706209421158,
      "learning_rate": 7.640963855421688e-06,
      "loss": 0.0088,
      "step": 102580
    },
    {
      "epoch": 12.360240963855421,
      "grad_norm": 0.002353540388867259,
      "learning_rate": 7.63975903614458e-06,
      "loss": 0.0022,
      "step": 102590
    },
    {
      "epoch": 12.36144578313253,
      "grad_norm": 0.033402737230062485,
      "learning_rate": 7.638554216867471e-06,
      "loss": 0.0024,
      "step": 102600
    },
    {
      "epoch": 12.362650602409639,
      "grad_norm": 0.004777534864842892,
      "learning_rate": 7.637349397590362e-06,
      "loss": 0.0526,
      "step": 102610
    },
    {
      "epoch": 12.363855421686747,
      "grad_norm": 0.001340130576863885,
      "learning_rate": 7.636144578313254e-06,
      "loss": 0.0043,
      "step": 102620
    },
    {
      "epoch": 12.365060240963855,
      "grad_norm": 0.0012204323429614305,
      "learning_rate": 7.634939759036145e-06,
      "loss": 0.0127,
      "step": 102630
    },
    {
      "epoch": 12.366265060240965,
      "grad_norm": 0.0037279129028320312,
      "learning_rate": 7.633734939759037e-06,
      "loss": 0.018,
      "step": 102640
    },
    {
      "epoch": 12.367469879518072,
      "grad_norm": 1.5204726457595825,
      "learning_rate": 7.632530120481928e-06,
      "loss": 0.0146,
      "step": 102650
    },
    {
      "epoch": 12.36867469879518,
      "grad_norm": 0.3005390763282776,
      "learning_rate": 7.631325301204819e-06,
      "loss": 0.0121,
      "step": 102660
    },
    {
      "epoch": 12.369879518072288,
      "grad_norm": 14.656594276428223,
      "learning_rate": 7.630120481927711e-06,
      "loss": 0.0681,
      "step": 102670
    },
    {
      "epoch": 12.371084337349398,
      "grad_norm": 0.05459665134549141,
      "learning_rate": 7.628915662650604e-06,
      "loss": 0.0357,
      "step": 102680
    },
    {
      "epoch": 12.372289156626506,
      "grad_norm": 0.002923442982137203,
      "learning_rate": 7.627710843373494e-06,
      "loss": 0.0072,
      "step": 102690
    },
    {
      "epoch": 12.373493975903614,
      "grad_norm": 0.006378192454576492,
      "learning_rate": 7.626506024096386e-06,
      "loss": 0.0189,
      "step": 102700
    },
    {
      "epoch": 12.374698795180723,
      "grad_norm": 0.005596482194960117,
      "learning_rate": 7.625301204819278e-06,
      "loss": 0.0123,
      "step": 102710
    },
    {
      "epoch": 12.375903614457831,
      "grad_norm": 0.014187676832079887,
      "learning_rate": 7.624096385542169e-06,
      "loss": 0.0115,
      "step": 102720
    },
    {
      "epoch": 12.37710843373494,
      "grad_norm": 0.003049873746931553,
      "learning_rate": 7.622891566265061e-06,
      "loss": 0.0084,
      "step": 102730
    },
    {
      "epoch": 12.378313253012049,
      "grad_norm": 0.006029306910932064,
      "learning_rate": 7.621686746987953e-06,
      "loss": 0.046,
      "step": 102740
    },
    {
      "epoch": 12.379518072289157,
      "grad_norm": 0.03140401840209961,
      "learning_rate": 7.620481927710845e-06,
      "loss": 0.0073,
      "step": 102750
    },
    {
      "epoch": 12.380722891566265,
      "grad_norm": 0.01748618856072426,
      "learning_rate": 7.6192771084337355e-06,
      "loss": 0.0281,
      "step": 102760
    },
    {
      "epoch": 12.381927710843373,
      "grad_norm": 0.0049751512706279755,
      "learning_rate": 7.618072289156627e-06,
      "loss": 0.011,
      "step": 102770
    },
    {
      "epoch": 12.383132530120482,
      "grad_norm": 0.35874149203300476,
      "learning_rate": 7.616867469879519e-06,
      "loss": 0.0076,
      "step": 102780
    },
    {
      "epoch": 12.38433734939759,
      "grad_norm": 0.05009274184703827,
      "learning_rate": 7.61566265060241e-06,
      "loss": 0.0147,
      "step": 102790
    },
    {
      "epoch": 12.385542168674698,
      "grad_norm": 0.4515259265899658,
      "learning_rate": 7.614457831325302e-06,
      "loss": 0.0128,
      "step": 102800
    },
    {
      "epoch": 12.386746987951808,
      "grad_norm": 0.006529893726110458,
      "learning_rate": 7.613253012048193e-06,
      "loss": 0.003,
      "step": 102810
    },
    {
      "epoch": 12.387951807228916,
      "grad_norm": 0.5100698471069336,
      "learning_rate": 7.612048192771085e-06,
      "loss": 0.0252,
      "step": 102820
    },
    {
      "epoch": 12.389156626506024,
      "grad_norm": 0.1893828809261322,
      "learning_rate": 7.610843373493977e-06,
      "loss": 0.0096,
      "step": 102830
    },
    {
      "epoch": 12.390361445783132,
      "grad_norm": 0.003090919926762581,
      "learning_rate": 7.609638554216868e-06,
      "loss": 0.0239,
      "step": 102840
    },
    {
      "epoch": 12.391566265060241,
      "grad_norm": 0.762046754360199,
      "learning_rate": 7.60843373493976e-06,
      "loss": 0.0039,
      "step": 102850
    },
    {
      "epoch": 12.39277108433735,
      "grad_norm": 0.06297606974840164,
      "learning_rate": 7.607228915662651e-06,
      "loss": 0.0006,
      "step": 102860
    },
    {
      "epoch": 12.393975903614457,
      "grad_norm": 0.24764575064182281,
      "learning_rate": 7.606024096385542e-06,
      "loss": 0.0134,
      "step": 102870
    },
    {
      "epoch": 12.395180722891567,
      "grad_norm": 2.578766107559204,
      "learning_rate": 7.604819277108434e-06,
      "loss": 0.0097,
      "step": 102880
    },
    {
      "epoch": 12.396385542168675,
      "grad_norm": 0.3607361316680908,
      "learning_rate": 7.603614457831326e-06,
      "loss": 0.006,
      "step": 102890
    },
    {
      "epoch": 12.397590361445783,
      "grad_norm": 7.77384090423584,
      "learning_rate": 7.602409638554218e-06,
      "loss": 0.0234,
      "step": 102900
    },
    {
      "epoch": 12.398795180722892,
      "grad_norm": 1.1424204111099243,
      "learning_rate": 7.601204819277109e-06,
      "loss": 0.0347,
      "step": 102910
    },
    {
      "epoch": 12.4,
      "grad_norm": 0.002874786965548992,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0124,
      "step": 102920
    },
    {
      "epoch": 12.401204819277108,
      "grad_norm": 0.0015632548602297902,
      "learning_rate": 7.5987951807228925e-06,
      "loss": 0.0172,
      "step": 102930
    },
    {
      "epoch": 12.402409638554216,
      "grad_norm": 0.008131954818964005,
      "learning_rate": 7.597590361445783e-06,
      "loss": 0.0193,
      "step": 102940
    },
    {
      "epoch": 12.403614457831326,
      "grad_norm": 0.020111743360757828,
      "learning_rate": 7.596385542168675e-06,
      "loss": 0.0022,
      "step": 102950
    },
    {
      "epoch": 12.404819277108434,
      "grad_norm": 0.055712394416332245,
      "learning_rate": 7.5951807228915664e-06,
      "loss": 0.0271,
      "step": 102960
    },
    {
      "epoch": 12.406024096385542,
      "grad_norm": 1.606089472770691,
      "learning_rate": 7.593975903614459e-06,
      "loss": 0.0424,
      "step": 102970
    },
    {
      "epoch": 12.407228915662651,
      "grad_norm": 3.595268964767456,
      "learning_rate": 7.5927710843373505e-06,
      "loss": 0.016,
      "step": 102980
    },
    {
      "epoch": 12.40843373493976,
      "grad_norm": 0.0013622789410874248,
      "learning_rate": 7.591566265060242e-06,
      "loss": 0.0277,
      "step": 102990
    },
    {
      "epoch": 12.409638554216867,
      "grad_norm": 0.0017211950616911054,
      "learning_rate": 7.590361445783133e-06,
      "loss": 0.0248,
      "step": 103000
    },
    {
      "epoch": 12.410843373493975,
      "grad_norm": 0.28702306747436523,
      "learning_rate": 7.589156626506024e-06,
      "loss": 0.0262,
      "step": 103010
    },
    {
      "epoch": 12.412048192771085,
      "grad_norm": 0.011565878055989742,
      "learning_rate": 7.587951807228916e-06,
      "loss": 0.002,
      "step": 103020
    },
    {
      "epoch": 12.413253012048193,
      "grad_norm": 0.24676577746868134,
      "learning_rate": 7.5867469879518075e-06,
      "loss": 0.0082,
      "step": 103030
    },
    {
      "epoch": 12.4144578313253,
      "grad_norm": 0.0012041121954098344,
      "learning_rate": 7.5855421686747e-06,
      "loss": 0.0179,
      "step": 103040
    },
    {
      "epoch": 12.41566265060241,
      "grad_norm": 0.0025924129877239466,
      "learning_rate": 7.5843373493975916e-06,
      "loss": 0.0156,
      "step": 103050
    },
    {
      "epoch": 12.416867469879518,
      "grad_norm": 1.7681838274002075,
      "learning_rate": 7.583132530120483e-06,
      "loss": 0.0468,
      "step": 103060
    },
    {
      "epoch": 12.418072289156626,
      "grad_norm": 0.005325572099536657,
      "learning_rate": 7.581927710843374e-06,
      "loss": 0.0193,
      "step": 103070
    },
    {
      "epoch": 12.419277108433734,
      "grad_norm": 0.13340437412261963,
      "learning_rate": 7.5807228915662655e-06,
      "loss": 0.0174,
      "step": 103080
    },
    {
      "epoch": 12.420481927710844,
      "grad_norm": 0.02625773288309574,
      "learning_rate": 7.579518072289157e-06,
      "loss": 0.0033,
      "step": 103090
    },
    {
      "epoch": 12.421686746987952,
      "grad_norm": 0.0006788103491999209,
      "learning_rate": 7.578313253012049e-06,
      "loss": 0.0073,
      "step": 103100
    },
    {
      "epoch": 12.42289156626506,
      "grad_norm": 0.006548732053488493,
      "learning_rate": 7.57710843373494e-06,
      "loss": 0.0225,
      "step": 103110
    },
    {
      "epoch": 12.42409638554217,
      "grad_norm": 0.031670983880758286,
      "learning_rate": 7.575903614457833e-06,
      "loss": 0.0091,
      "step": 103120
    },
    {
      "epoch": 12.425301204819277,
      "grad_norm": 0.01018503401428461,
      "learning_rate": 7.5746987951807234e-06,
      "loss": 0.0781,
      "step": 103130
    },
    {
      "epoch": 12.426506024096385,
      "grad_norm": 0.4845430254936218,
      "learning_rate": 7.573493975903615e-06,
      "loss": 0.0489,
      "step": 103140
    },
    {
      "epoch": 12.427710843373493,
      "grad_norm": 0.0010444471845403314,
      "learning_rate": 7.572289156626507e-06,
      "loss": 0.0101,
      "step": 103150
    },
    {
      "epoch": 12.428915662650603,
      "grad_norm": 0.0063840183429419994,
      "learning_rate": 7.571084337349398e-06,
      "loss": 0.0158,
      "step": 103160
    },
    {
      "epoch": 12.43012048192771,
      "grad_norm": 0.12109558284282684,
      "learning_rate": 7.56987951807229e-06,
      "loss": 0.0002,
      "step": 103170
    },
    {
      "epoch": 12.431325301204819,
      "grad_norm": 0.22825562953948975,
      "learning_rate": 7.5686746987951805e-06,
      "loss": 0.012,
      "step": 103180
    },
    {
      "epoch": 12.432530120481928,
      "grad_norm": 0.006318368017673492,
      "learning_rate": 7.567469879518074e-06,
      "loss": 0.0247,
      "step": 103190
    },
    {
      "epoch": 12.433734939759036,
      "grad_norm": 0.0011079589603468776,
      "learning_rate": 7.5662650602409645e-06,
      "loss": 0.0116,
      "step": 103200
    },
    {
      "epoch": 12.434939759036144,
      "grad_norm": 0.002686399733647704,
      "learning_rate": 7.565060240963856e-06,
      "loss": 0.0174,
      "step": 103210
    },
    {
      "epoch": 12.436144578313254,
      "grad_norm": 0.8024065494537354,
      "learning_rate": 7.563855421686748e-06,
      "loss": 0.0708,
      "step": 103220
    },
    {
      "epoch": 12.437349397590362,
      "grad_norm": 0.0005338294431567192,
      "learning_rate": 7.562650602409639e-06,
      "loss": 0.0516,
      "step": 103230
    },
    {
      "epoch": 12.43855421686747,
      "grad_norm": 0.0020925879944115877,
      "learning_rate": 7.561445783132531e-06,
      "loss": 0.0133,
      "step": 103240
    },
    {
      "epoch": 12.439759036144578,
      "grad_norm": 0.004375227261334658,
      "learning_rate": 7.560240963855422e-06,
      "loss": 0.0049,
      "step": 103250
    },
    {
      "epoch": 12.440963855421687,
      "grad_norm": 0.19185222685337067,
      "learning_rate": 7.559036144578313e-06,
      "loss": 0.0053,
      "step": 103260
    },
    {
      "epoch": 12.442168674698795,
      "grad_norm": 0.002309411996975541,
      "learning_rate": 7.557831325301206e-06,
      "loss": 0.0424,
      "step": 103270
    },
    {
      "epoch": 12.443373493975903,
      "grad_norm": 1.0387606620788574,
      "learning_rate": 7.556626506024097e-06,
      "loss": 0.0112,
      "step": 103280
    },
    {
      "epoch": 12.444578313253013,
      "grad_norm": 6.8882527351379395,
      "learning_rate": 7.555421686746989e-06,
      "loss": 0.028,
      "step": 103290
    },
    {
      "epoch": 12.44578313253012,
      "grad_norm": 1.6630295515060425,
      "learning_rate": 7.5542168674698804e-06,
      "loss": 0.0102,
      "step": 103300
    },
    {
      "epoch": 12.446987951807229,
      "grad_norm": 0.5714166164398193,
      "learning_rate": 7.553012048192771e-06,
      "loss": 0.0038,
      "step": 103310
    },
    {
      "epoch": 12.448192771084337,
      "grad_norm": 0.0014376953477039933,
      "learning_rate": 7.551807228915663e-06,
      "loss": 0.0011,
      "step": 103320
    },
    {
      "epoch": 12.449397590361446,
      "grad_norm": 0.0187988318502903,
      "learning_rate": 7.550602409638554e-06,
      "loss": 0.0101,
      "step": 103330
    },
    {
      "epoch": 12.450602409638554,
      "grad_norm": 1.211565613746643,
      "learning_rate": 7.549397590361447e-06,
      "loss": 0.0214,
      "step": 103340
    },
    {
      "epoch": 12.451807228915662,
      "grad_norm": 1.7696129083633423,
      "learning_rate": 7.548192771084338e-06,
      "loss": 0.0299,
      "step": 103350
    },
    {
      "epoch": 12.453012048192772,
      "grad_norm": 1.559074878692627,
      "learning_rate": 7.54698795180723e-06,
      "loss": 0.0268,
      "step": 103360
    },
    {
      "epoch": 12.45421686746988,
      "grad_norm": 0.0005477853119373322,
      "learning_rate": 7.5457831325301215e-06,
      "loss": 0.0228,
      "step": 103370
    },
    {
      "epoch": 12.455421686746988,
      "grad_norm": 0.0012604973744601011,
      "learning_rate": 7.544578313253012e-06,
      "loss": 0.0146,
      "step": 103380
    },
    {
      "epoch": 12.456626506024097,
      "grad_norm": 0.008580957539379597,
      "learning_rate": 7.543373493975904e-06,
      "loss": 0.0167,
      "step": 103390
    },
    {
      "epoch": 12.457831325301205,
      "grad_norm": 0.0009021255536936224,
      "learning_rate": 7.5421686746987955e-06,
      "loss": 0.0062,
      "step": 103400
    },
    {
      "epoch": 12.459036144578313,
      "grad_norm": 0.014442806132137775,
      "learning_rate": 7.540963855421687e-06,
      "loss": 0.0256,
      "step": 103410
    },
    {
      "epoch": 12.460240963855421,
      "grad_norm": 1.1302156448364258,
      "learning_rate": 7.5397590361445795e-06,
      "loss": 0.013,
      "step": 103420
    },
    {
      "epoch": 12.46144578313253,
      "grad_norm": 0.0025726393796503544,
      "learning_rate": 7.538554216867471e-06,
      "loss": 0.0087,
      "step": 103430
    },
    {
      "epoch": 12.462650602409639,
      "grad_norm": 0.0027440388221293688,
      "learning_rate": 7.537349397590362e-06,
      "loss": 0.0063,
      "step": 103440
    },
    {
      "epoch": 12.463855421686747,
      "grad_norm": 0.0024405852891504765,
      "learning_rate": 7.536144578313253e-06,
      "loss": 0.0292,
      "step": 103450
    },
    {
      "epoch": 12.465060240963856,
      "grad_norm": 0.0004985039704479277,
      "learning_rate": 7.534939759036145e-06,
      "loss": 0.0259,
      "step": 103460
    },
    {
      "epoch": 12.466265060240964,
      "grad_norm": 27.557390213012695,
      "learning_rate": 7.5337349397590366e-06,
      "loss": 0.0803,
      "step": 103470
    },
    {
      "epoch": 12.467469879518072,
      "grad_norm": 0.015383647754788399,
      "learning_rate": 7.532530120481928e-06,
      "loss": 0.0232,
      "step": 103480
    },
    {
      "epoch": 12.46867469879518,
      "grad_norm": 2.457366466522217,
      "learning_rate": 7.531325301204821e-06,
      "loss": 0.0232,
      "step": 103490
    },
    {
      "epoch": 12.46987951807229,
      "grad_norm": 0.0011821240186691284,
      "learning_rate": 7.530120481927712e-06,
      "loss": 0.004,
      "step": 103500
    },
    {
      "epoch": 12.471084337349398,
      "grad_norm": 0.300808310508728,
      "learning_rate": 7.528915662650603e-06,
      "loss": 0.0111,
      "step": 103510
    },
    {
      "epoch": 12.472289156626506,
      "grad_norm": 0.008663754910230637,
      "learning_rate": 7.5277108433734945e-06,
      "loss": 0.022,
      "step": 103520
    },
    {
      "epoch": 12.473493975903615,
      "grad_norm": 16.63567352294922,
      "learning_rate": 7.526506024096386e-06,
      "loss": 0.0377,
      "step": 103530
    },
    {
      "epoch": 12.474698795180723,
      "grad_norm": 0.002104454440996051,
      "learning_rate": 7.525301204819278e-06,
      "loss": 0.006,
      "step": 103540
    },
    {
      "epoch": 12.475903614457831,
      "grad_norm": 0.8219175934791565,
      "learning_rate": 7.524096385542169e-06,
      "loss": 0.0183,
      "step": 103550
    },
    {
      "epoch": 12.477108433734939,
      "grad_norm": 0.11553292721509933,
      "learning_rate": 7.52289156626506e-06,
      "loss": 0.015,
      "step": 103560
    },
    {
      "epoch": 12.478313253012049,
      "grad_norm": 0.0006352945929393172,
      "learning_rate": 7.5216867469879525e-06,
      "loss": 0.0019,
      "step": 103570
    },
    {
      "epoch": 12.479518072289157,
      "grad_norm": 0.0032881794031709433,
      "learning_rate": 7.520481927710844e-06,
      "loss": 0.0238,
      "step": 103580
    },
    {
      "epoch": 12.480722891566264,
      "grad_norm": 0.3671182692050934,
      "learning_rate": 7.519277108433736e-06,
      "loss": 0.0046,
      "step": 103590
    },
    {
      "epoch": 12.481927710843374,
      "grad_norm": 1.61208975315094,
      "learning_rate": 7.518072289156627e-06,
      "loss": 0.0169,
      "step": 103600
    },
    {
      "epoch": 12.483132530120482,
      "grad_norm": 0.0009639177587814629,
      "learning_rate": 7.516867469879519e-06,
      "loss": 0.0033,
      "step": 103610
    },
    {
      "epoch": 12.48433734939759,
      "grad_norm": 0.6241171956062317,
      "learning_rate": 7.5156626506024095e-06,
      "loss": 0.0124,
      "step": 103620
    },
    {
      "epoch": 12.485542168674698,
      "grad_norm": 0.0061591495759785175,
      "learning_rate": 7.514457831325301e-06,
      "loss": 0.0127,
      "step": 103630
    },
    {
      "epoch": 12.486746987951808,
      "grad_norm": 0.0009792795171961188,
      "learning_rate": 7.5132530120481936e-06,
      "loss": 0.0395,
      "step": 103640
    },
    {
      "epoch": 12.487951807228916,
      "grad_norm": 0.0007033708388917148,
      "learning_rate": 7.512048192771085e-06,
      "loss": 0.0138,
      "step": 103650
    },
    {
      "epoch": 12.489156626506023,
      "grad_norm": 0.2505950629711151,
      "learning_rate": 7.510843373493977e-06,
      "loss": 0.1055,
      "step": 103660
    },
    {
      "epoch": 12.490361445783133,
      "grad_norm": 0.004219097550958395,
      "learning_rate": 7.509638554216868e-06,
      "loss": 0.0472,
      "step": 103670
    },
    {
      "epoch": 12.491566265060241,
      "grad_norm": 1.3519505262374878,
      "learning_rate": 7.50843373493976e-06,
      "loss": 0.0437,
      "step": 103680
    },
    {
      "epoch": 12.492771084337349,
      "grad_norm": 1.751232385635376,
      "learning_rate": 7.507228915662651e-06,
      "loss": 0.0111,
      "step": 103690
    },
    {
      "epoch": 12.493975903614459,
      "grad_norm": 0.022814912721514702,
      "learning_rate": 7.506024096385542e-06,
      "loss": 0.0067,
      "step": 103700
    },
    {
      "epoch": 12.495180722891567,
      "grad_norm": 0.005031603388488293,
      "learning_rate": 7.504819277108434e-06,
      "loss": 0.0214,
      "step": 103710
    },
    {
      "epoch": 12.496385542168674,
      "grad_norm": 0.02395249903202057,
      "learning_rate": 7.503614457831326e-06,
      "loss": 0.0074,
      "step": 103720
    },
    {
      "epoch": 12.497590361445782,
      "grad_norm": 1.1254355907440186,
      "learning_rate": 7.502409638554218e-06,
      "loss": 0.007,
      "step": 103730
    },
    {
      "epoch": 12.498795180722892,
      "grad_norm": 0.22046427428722382,
      "learning_rate": 7.5012048192771094e-06,
      "loss": 0.0129,
      "step": 103740
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.007144027855247259,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0173,
      "step": 103750
    },
    {
      "epoch": 12.501204819277108,
      "grad_norm": 0.0014832529705017805,
      "learning_rate": 7.498795180722892e-06,
      "loss": 0.0161,
      "step": 103760
    },
    {
      "epoch": 12.502409638554218,
      "grad_norm": 0.6821032166481018,
      "learning_rate": 7.497590361445783e-06,
      "loss": 0.0058,
      "step": 103770
    },
    {
      "epoch": 12.503614457831326,
      "grad_norm": 1.917062759399414,
      "learning_rate": 7.496385542168675e-06,
      "loss": 0.0807,
      "step": 103780
    },
    {
      "epoch": 12.504819277108433,
      "grad_norm": 1.1738766431808472,
      "learning_rate": 7.495180722891567e-06,
      "loss": 0.0098,
      "step": 103790
    },
    {
      "epoch": 12.506024096385541,
      "grad_norm": 1.4815683364868164,
      "learning_rate": 7.493975903614459e-06,
      "loss": 0.008,
      "step": 103800
    },
    {
      "epoch": 12.507228915662651,
      "grad_norm": 1.522153377532959,
      "learning_rate": 7.4927710843373506e-06,
      "loss": 0.0493,
      "step": 103810
    },
    {
      "epoch": 12.508433734939759,
      "grad_norm": 0.0069253467954695225,
      "learning_rate": 7.491566265060241e-06,
      "loss": 0.002,
      "step": 103820
    },
    {
      "epoch": 12.509638554216867,
      "grad_norm": 0.11428343504667282,
      "learning_rate": 7.490361445783133e-06,
      "loss": 0.0154,
      "step": 103830
    },
    {
      "epoch": 12.510843373493977,
      "grad_norm": 0.0026485808193683624,
      "learning_rate": 7.4891566265060245e-06,
      "loss": 0.0068,
      "step": 103840
    },
    {
      "epoch": 12.512048192771084,
      "grad_norm": 0.001501047401688993,
      "learning_rate": 7.487951807228916e-06,
      "loss": 0.0243,
      "step": 103850
    },
    {
      "epoch": 12.513253012048192,
      "grad_norm": 0.33488085865974426,
      "learning_rate": 7.486746987951808e-06,
      "loss": 0.0104,
      "step": 103860
    },
    {
      "epoch": 12.514457831325302,
      "grad_norm": 0.001326081808656454,
      "learning_rate": 7.4855421686747e-06,
      "loss": 0.0153,
      "step": 103870
    },
    {
      "epoch": 12.51566265060241,
      "grad_norm": 0.4241589903831482,
      "learning_rate": 7.484337349397592e-06,
      "loss": 0.0282,
      "step": 103880
    },
    {
      "epoch": 12.516867469879518,
      "grad_norm": 0.002323032356798649,
      "learning_rate": 7.483132530120482e-06,
      "loss": 0.0127,
      "step": 103890
    },
    {
      "epoch": 12.518072289156626,
      "grad_norm": 6.419840335845947,
      "learning_rate": 7.481927710843374e-06,
      "loss": 0.0549,
      "step": 103900
    },
    {
      "epoch": 12.519277108433736,
      "grad_norm": 0.005161370150744915,
      "learning_rate": 7.480722891566266e-06,
      "loss": 0.0099,
      "step": 103910
    },
    {
      "epoch": 12.520481927710843,
      "grad_norm": 0.007318344432860613,
      "learning_rate": 7.479518072289157e-06,
      "loss": 0.0133,
      "step": 103920
    },
    {
      "epoch": 12.521686746987951,
      "grad_norm": 0.0013526618713513017,
      "learning_rate": 7.478313253012049e-06,
      "loss": 0.0265,
      "step": 103930
    },
    {
      "epoch": 12.522891566265061,
      "grad_norm": 1.716472864151001,
      "learning_rate": 7.477108433734941e-06,
      "loss": 0.0324,
      "step": 103940
    },
    {
      "epoch": 12.524096385542169,
      "grad_norm": 0.0024735976476222277,
      "learning_rate": 7.475903614457832e-06,
      "loss": 0.0113,
      "step": 103950
    },
    {
      "epoch": 12.525301204819277,
      "grad_norm": 0.0751541331410408,
      "learning_rate": 7.4746987951807235e-06,
      "loss": 0.0147,
      "step": 103960
    },
    {
      "epoch": 12.526506024096385,
      "grad_norm": 0.001445295405574143,
      "learning_rate": 7.473493975903615e-06,
      "loss": 0.0081,
      "step": 103970
    },
    {
      "epoch": 12.527710843373494,
      "grad_norm": 0.007238303776830435,
      "learning_rate": 7.472289156626507e-06,
      "loss": 0.0332,
      "step": 103980
    },
    {
      "epoch": 12.528915662650602,
      "grad_norm": 1.873435139656067,
      "learning_rate": 7.471084337349398e-06,
      "loss": 0.0225,
      "step": 103990
    },
    {
      "epoch": 12.53012048192771,
      "grad_norm": 0.001932961749844253,
      "learning_rate": 7.469879518072289e-06,
      "loss": 0.005,
      "step": 104000
    },
    {
      "epoch": 12.53132530120482,
      "grad_norm": 0.001715415739454329,
      "learning_rate": 7.468674698795181e-06,
      "loss": 0.0596,
      "step": 104010
    },
    {
      "epoch": 12.532530120481928,
      "grad_norm": 10.914386749267578,
      "learning_rate": 7.467469879518073e-06,
      "loss": 0.043,
      "step": 104020
    },
    {
      "epoch": 12.533734939759036,
      "grad_norm": 28.948617935180664,
      "learning_rate": 7.466265060240965e-06,
      "loss": 0.0192,
      "step": 104030
    },
    {
      "epoch": 12.534939759036144,
      "grad_norm": 1.0344527959823608,
      "learning_rate": 7.465060240963856e-06,
      "loss": 0.0319,
      "step": 104040
    },
    {
      "epoch": 12.536144578313253,
      "grad_norm": 0.0017394943861290812,
      "learning_rate": 7.463855421686748e-06,
      "loss": 0.0122,
      "step": 104050
    },
    {
      "epoch": 12.537349397590361,
      "grad_norm": 0.0015452696243301034,
      "learning_rate": 7.462650602409639e-06,
      "loss": 0.0104,
      "step": 104060
    },
    {
      "epoch": 12.53855421686747,
      "grad_norm": 0.0396159291267395,
      "learning_rate": 7.46144578313253e-06,
      "loss": 0.0183,
      "step": 104070
    },
    {
      "epoch": 12.539759036144579,
      "grad_norm": 0.32359880208969116,
      "learning_rate": 7.460240963855422e-06,
      "loss": 0.0343,
      "step": 104080
    },
    {
      "epoch": 12.540963855421687,
      "grad_norm": 0.0012969307135790586,
      "learning_rate": 7.459036144578314e-06,
      "loss": 0.0087,
      "step": 104090
    },
    {
      "epoch": 12.542168674698795,
      "grad_norm": 0.10966740548610687,
      "learning_rate": 7.457831325301206e-06,
      "loss": 0.034,
      "step": 104100
    },
    {
      "epoch": 12.543373493975903,
      "grad_norm": 0.00139656662940979,
      "learning_rate": 7.456626506024097e-06,
      "loss": 0.0143,
      "step": 104110
    },
    {
      "epoch": 12.544578313253012,
      "grad_norm": 0.0016795806586742401,
      "learning_rate": 7.455421686746989e-06,
      "loss": 0.0165,
      "step": 104120
    },
    {
      "epoch": 12.54578313253012,
      "grad_norm": 0.0015717094065621495,
      "learning_rate": 7.45421686746988e-06,
      "loss": 0.0089,
      "step": 104130
    },
    {
      "epoch": 12.546987951807228,
      "grad_norm": 8.035008430480957,
      "learning_rate": 7.453012048192771e-06,
      "loss": 0.0069,
      "step": 104140
    },
    {
      "epoch": 12.548192771084338,
      "grad_norm": 1.558623194694519,
      "learning_rate": 7.451807228915663e-06,
      "loss": 0.0259,
      "step": 104150
    },
    {
      "epoch": 12.549397590361446,
      "grad_norm": 1.5945279598236084,
      "learning_rate": 7.4506024096385545e-06,
      "loss": 0.0085,
      "step": 104160
    },
    {
      "epoch": 12.550602409638554,
      "grad_norm": 0.045883338898420334,
      "learning_rate": 7.449397590361447e-06,
      "loss": 0.0105,
      "step": 104170
    },
    {
      "epoch": 12.551807228915663,
      "grad_norm": 0.0010535299079492688,
      "learning_rate": 7.4481927710843385e-06,
      "loss": 0.0531,
      "step": 104180
    },
    {
      "epoch": 12.553012048192771,
      "grad_norm": 0.0020185145549476147,
      "learning_rate": 7.44698795180723e-06,
      "loss": 0.0111,
      "step": 104190
    },
    {
      "epoch": 12.55421686746988,
      "grad_norm": 0.002297127153724432,
      "learning_rate": 7.445783132530121e-06,
      "loss": 0.0126,
      "step": 104200
    },
    {
      "epoch": 12.555421686746987,
      "grad_norm": 0.0013491008430719376,
      "learning_rate": 7.444578313253012e-06,
      "loss": 0.0258,
      "step": 104210
    },
    {
      "epoch": 12.556626506024097,
      "grad_norm": 1.1553748846054077,
      "learning_rate": 7.443373493975904e-06,
      "loss": 0.0309,
      "step": 104220
    },
    {
      "epoch": 12.557831325301205,
      "grad_norm": 12.506718635559082,
      "learning_rate": 7.4421686746987956e-06,
      "loss": 0.0502,
      "step": 104230
    },
    {
      "epoch": 12.559036144578313,
      "grad_norm": 0.0009735064231790602,
      "learning_rate": 7.440963855421688e-06,
      "loss": 0.0134,
      "step": 104240
    },
    {
      "epoch": 12.560240963855422,
      "grad_norm": 2.858293056488037,
      "learning_rate": 7.43975903614458e-06,
      "loss": 0.0209,
      "step": 104250
    },
    {
      "epoch": 12.56144578313253,
      "grad_norm": 0.0017976859817281365,
      "learning_rate": 7.43855421686747e-06,
      "loss": 0.0172,
      "step": 104260
    },
    {
      "epoch": 12.562650602409638,
      "grad_norm": 0.010764412581920624,
      "learning_rate": 7.437349397590362e-06,
      "loss": 0.0335,
      "step": 104270
    },
    {
      "epoch": 12.563855421686746,
      "grad_norm": 0.5000705718994141,
      "learning_rate": 7.4361445783132535e-06,
      "loss": 0.0094,
      "step": 104280
    },
    {
      "epoch": 12.565060240963856,
      "grad_norm": 0.0024348965380340815,
      "learning_rate": 7.434939759036145e-06,
      "loss": 0.0016,
      "step": 104290
    },
    {
      "epoch": 12.566265060240964,
      "grad_norm": 0.35409674048423767,
      "learning_rate": 7.433734939759037e-06,
      "loss": 0.0045,
      "step": 104300
    },
    {
      "epoch": 12.567469879518072,
      "grad_norm": 0.0023570843040943146,
      "learning_rate": 7.4325301204819274e-06,
      "loss": 0.0041,
      "step": 104310
    },
    {
      "epoch": 12.568674698795181,
      "grad_norm": 0.0011451086029410362,
      "learning_rate": 7.431325301204821e-06,
      "loss": 0.006,
      "step": 104320
    },
    {
      "epoch": 12.56987951807229,
      "grad_norm": 0.001671560457907617,
      "learning_rate": 7.4301204819277114e-06,
      "loss": 0.0222,
      "step": 104330
    },
    {
      "epoch": 12.571084337349397,
      "grad_norm": 0.000967843399848789,
      "learning_rate": 7.428915662650603e-06,
      "loss": 0.0078,
      "step": 104340
    },
    {
      "epoch": 12.572289156626507,
      "grad_norm": 0.7267308831214905,
      "learning_rate": 7.427710843373495e-06,
      "loss": 0.0185,
      "step": 104350
    },
    {
      "epoch": 12.573493975903615,
      "grad_norm": 0.7852394580841064,
      "learning_rate": 7.426506024096386e-06,
      "loss": 0.0495,
      "step": 104360
    },
    {
      "epoch": 12.574698795180723,
      "grad_norm": 0.0034529638942331076,
      "learning_rate": 7.425301204819278e-06,
      "loss": 0.0463,
      "step": 104370
    },
    {
      "epoch": 12.57590361445783,
      "grad_norm": 0.5496186017990112,
      "learning_rate": 7.4240963855421685e-06,
      "loss": 0.0497,
      "step": 104380
    },
    {
      "epoch": 12.57710843373494,
      "grad_norm": 0.008834210224449635,
      "learning_rate": 7.422891566265061e-06,
      "loss": 0.0069,
      "step": 104390
    },
    {
      "epoch": 12.578313253012048,
      "grad_norm": 1.5355865955352783,
      "learning_rate": 7.4216867469879526e-06,
      "loss": 0.0127,
      "step": 104400
    },
    {
      "epoch": 12.579518072289156,
      "grad_norm": 0.7278198003768921,
      "learning_rate": 7.420481927710844e-06,
      "loss": 0.0027,
      "step": 104410
    },
    {
      "epoch": 12.580722891566266,
      "grad_norm": 0.002255681436508894,
      "learning_rate": 7.419277108433736e-06,
      "loss": 0.0032,
      "step": 104420
    },
    {
      "epoch": 12.581927710843374,
      "grad_norm": 3.8066794872283936,
      "learning_rate": 7.418072289156627e-06,
      "loss": 0.0333,
      "step": 104430
    },
    {
      "epoch": 12.583132530120482,
      "grad_norm": 0.002018420724198222,
      "learning_rate": 7.416867469879518e-06,
      "loss": 0.0161,
      "step": 104440
    },
    {
      "epoch": 12.58433734939759,
      "grad_norm": 1.9935766458511353,
      "learning_rate": 7.41566265060241e-06,
      "loss": 0.0157,
      "step": 104450
    },
    {
      "epoch": 12.5855421686747,
      "grad_norm": 0.007232154253870249,
      "learning_rate": 7.414457831325301e-06,
      "loss": 0.0456,
      "step": 104460
    },
    {
      "epoch": 12.586746987951807,
      "grad_norm": 0.13650256395339966,
      "learning_rate": 7.413253012048194e-06,
      "loss": 0.0103,
      "step": 104470
    },
    {
      "epoch": 12.587951807228915,
      "grad_norm": 0.002370610600337386,
      "learning_rate": 7.412048192771085e-06,
      "loss": 0.0107,
      "step": 104480
    },
    {
      "epoch": 12.589156626506025,
      "grad_norm": 0.004298481624573469,
      "learning_rate": 7.410843373493977e-06,
      "loss": 0.0423,
      "step": 104490
    },
    {
      "epoch": 12.590361445783133,
      "grad_norm": 0.7755754590034485,
      "learning_rate": 7.4096385542168684e-06,
      "loss": 0.0087,
      "step": 104500
    },
    {
      "epoch": 12.59156626506024,
      "grad_norm": 2.4537672996520996,
      "learning_rate": 7.408433734939759e-06,
      "loss": 0.0413,
      "step": 104510
    },
    {
      "epoch": 12.592771084337349,
      "grad_norm": 0.0025391208473592997,
      "learning_rate": 7.407228915662651e-06,
      "loss": 0.0022,
      "step": 104520
    },
    {
      "epoch": 12.593975903614458,
      "grad_norm": 1.7135283946990967,
      "learning_rate": 7.406024096385542e-06,
      "loss": 0.0258,
      "step": 104530
    },
    {
      "epoch": 12.595180722891566,
      "grad_norm": 0.002532899146899581,
      "learning_rate": 7.404819277108435e-06,
      "loss": 0.0231,
      "step": 104540
    },
    {
      "epoch": 12.596385542168674,
      "grad_norm": 0.0014735400909557939,
      "learning_rate": 7.403614457831326e-06,
      "loss": 0.0085,
      "step": 104550
    },
    {
      "epoch": 12.597590361445784,
      "grad_norm": 0.003765795612707734,
      "learning_rate": 7.402409638554218e-06,
      "loss": 0.0078,
      "step": 104560
    },
    {
      "epoch": 12.598795180722892,
      "grad_norm": 0.7352771162986755,
      "learning_rate": 7.401204819277109e-06,
      "loss": 0.0187,
      "step": 104570
    },
    {
      "epoch": 12.6,
      "grad_norm": 0.0065552350133657455,
      "learning_rate": 7.4e-06,
      "loss": 0.0105,
      "step": 104580
    },
    {
      "epoch": 12.601204819277108,
      "grad_norm": 1.6483532190322876,
      "learning_rate": 7.398795180722892e-06,
      "loss": 0.0248,
      "step": 104590
    },
    {
      "epoch": 12.602409638554217,
      "grad_norm": 0.0010245232842862606,
      "learning_rate": 7.3975903614457835e-06,
      "loss": 0.0049,
      "step": 104600
    },
    {
      "epoch": 12.603614457831325,
      "grad_norm": 1.578009843826294,
      "learning_rate": 7.396385542168675e-06,
      "loss": 0.0484,
      "step": 104610
    },
    {
      "epoch": 12.604819277108433,
      "grad_norm": 0.0738682970404625,
      "learning_rate": 7.3951807228915675e-06,
      "loss": 0.0097,
      "step": 104620
    },
    {
      "epoch": 12.606024096385543,
      "grad_norm": 0.0012697272468358278,
      "learning_rate": 7.393975903614459e-06,
      "loss": 0.0028,
      "step": 104630
    },
    {
      "epoch": 12.60722891566265,
      "grad_norm": 0.0011829562718048692,
      "learning_rate": 7.39277108433735e-06,
      "loss": 0.0065,
      "step": 104640
    },
    {
      "epoch": 12.608433734939759,
      "grad_norm": 0.9153314828872681,
      "learning_rate": 7.391566265060241e-06,
      "loss": 0.0222,
      "step": 104650
    },
    {
      "epoch": 12.609638554216868,
      "grad_norm": 0.8977043628692627,
      "learning_rate": 7.390361445783133e-06,
      "loss": 0.0301,
      "step": 104660
    },
    {
      "epoch": 12.610843373493976,
      "grad_norm": 0.9464049935340881,
      "learning_rate": 7.389156626506025e-06,
      "loss": 0.0308,
      "step": 104670
    },
    {
      "epoch": 12.612048192771084,
      "grad_norm": 0.0020820319186896086,
      "learning_rate": 7.387951807228916e-06,
      "loss": 0.0116,
      "step": 104680
    },
    {
      "epoch": 12.613253012048192,
      "grad_norm": 0.7725303173065186,
      "learning_rate": 7.386746987951809e-06,
      "loss": 0.0079,
      "step": 104690
    },
    {
      "epoch": 12.614457831325302,
      "grad_norm": 0.11173336207866669,
      "learning_rate": 7.385542168674699e-06,
      "loss": 0.0524,
      "step": 104700
    },
    {
      "epoch": 12.61566265060241,
      "grad_norm": 0.018109185621142387,
      "learning_rate": 7.384337349397591e-06,
      "loss": 0.0174,
      "step": 104710
    },
    {
      "epoch": 12.616867469879518,
      "grad_norm": 3.417637825012207,
      "learning_rate": 7.3831325301204825e-06,
      "loss": 0.0199,
      "step": 104720
    },
    {
      "epoch": 12.618072289156627,
      "grad_norm": 13.607638359069824,
      "learning_rate": 7.381927710843374e-06,
      "loss": 0.0551,
      "step": 104730
    },
    {
      "epoch": 12.619277108433735,
      "grad_norm": 8.2409086227417,
      "learning_rate": 7.380722891566266e-06,
      "loss": 0.0411,
      "step": 104740
    },
    {
      "epoch": 12.620481927710843,
      "grad_norm": 0.04236190766096115,
      "learning_rate": 7.3795180722891564e-06,
      "loss": 0.003,
      "step": 104750
    },
    {
      "epoch": 12.621686746987951,
      "grad_norm": 3.8975884914398193,
      "learning_rate": 7.378313253012048e-06,
      "loss": 0.0218,
      "step": 104760
    },
    {
      "epoch": 12.62289156626506,
      "grad_norm": 0.30177634954452515,
      "learning_rate": 7.3771084337349405e-06,
      "loss": 0.0126,
      "step": 104770
    },
    {
      "epoch": 12.624096385542169,
      "grad_norm": 0.9167988300323486,
      "learning_rate": 7.375903614457832e-06,
      "loss": 0.0054,
      "step": 104780
    },
    {
      "epoch": 12.625301204819277,
      "grad_norm": 0.0018903493182733655,
      "learning_rate": 7.374698795180724e-06,
      "loss": 0.0109,
      "step": 104790
    },
    {
      "epoch": 12.626506024096386,
      "grad_norm": 1.2146912813186646,
      "learning_rate": 7.373493975903615e-06,
      "loss": 0.0163,
      "step": 104800
    },
    {
      "epoch": 12.627710843373494,
      "grad_norm": 0.007909896783530712,
      "learning_rate": 7.372289156626507e-06,
      "loss": 0.012,
      "step": 104810
    },
    {
      "epoch": 12.628915662650602,
      "grad_norm": 1.5611623525619507,
      "learning_rate": 7.3710843373493976e-06,
      "loss": 0.0192,
      "step": 104820
    },
    {
      "epoch": 12.630120481927712,
      "grad_norm": 0.5173760056495667,
      "learning_rate": 7.369879518072289e-06,
      "loss": 0.0173,
      "step": 104830
    },
    {
      "epoch": 12.63132530120482,
      "grad_norm": 1.1092332601547241,
      "learning_rate": 7.368674698795182e-06,
      "loss": 0.0206,
      "step": 104840
    },
    {
      "epoch": 12.632530120481928,
      "grad_norm": 0.0010118010686710477,
      "learning_rate": 7.367469879518073e-06,
      "loss": 0.0458,
      "step": 104850
    },
    {
      "epoch": 12.633734939759035,
      "grad_norm": 0.00109588960185647,
      "learning_rate": 7.366265060240965e-06,
      "loss": 0.0143,
      "step": 104860
    },
    {
      "epoch": 12.634939759036145,
      "grad_norm": 0.0008290393161587417,
      "learning_rate": 7.365060240963856e-06,
      "loss": 0.0085,
      "step": 104870
    },
    {
      "epoch": 12.636144578313253,
      "grad_norm": 0.004307896830141544,
      "learning_rate": 7.363855421686747e-06,
      "loss": 0.0204,
      "step": 104880
    },
    {
      "epoch": 12.637349397590361,
      "grad_norm": 0.0009368504397571087,
      "learning_rate": 7.362650602409639e-06,
      "loss": 0.0037,
      "step": 104890
    },
    {
      "epoch": 12.638554216867469,
      "grad_norm": 1.5624313354492188,
      "learning_rate": 7.36144578313253e-06,
      "loss": 0.0176,
      "step": 104900
    },
    {
      "epoch": 12.639759036144579,
      "grad_norm": 0.012907047756016254,
      "learning_rate": 7.360240963855422e-06,
      "loss": 0.0511,
      "step": 104910
    },
    {
      "epoch": 12.640963855421687,
      "grad_norm": 4.385263442993164,
      "learning_rate": 7.359036144578314e-06,
      "loss": 0.0525,
      "step": 104920
    },
    {
      "epoch": 12.642168674698794,
      "grad_norm": 0.02236240543425083,
      "learning_rate": 7.357831325301206e-06,
      "loss": 0.0094,
      "step": 104930
    },
    {
      "epoch": 12.643373493975904,
      "grad_norm": 3.1467442512512207,
      "learning_rate": 7.3566265060240975e-06,
      "loss": 0.0411,
      "step": 104940
    },
    {
      "epoch": 12.644578313253012,
      "grad_norm": 0.005183347966521978,
      "learning_rate": 7.355421686746988e-06,
      "loss": 0.004,
      "step": 104950
    },
    {
      "epoch": 12.64578313253012,
      "grad_norm": 0.0030778427608311176,
      "learning_rate": 7.35421686746988e-06,
      "loss": 0.0048,
      "step": 104960
    },
    {
      "epoch": 12.64698795180723,
      "grad_norm": 2.5546875,
      "learning_rate": 7.353012048192771e-06,
      "loss": 0.024,
      "step": 104970
    },
    {
      "epoch": 12.648192771084338,
      "grad_norm": 0.002469803672283888,
      "learning_rate": 7.351807228915663e-06,
      "loss": 0.0109,
      "step": 104980
    },
    {
      "epoch": 12.649397590361446,
      "grad_norm": 0.034789230674505234,
      "learning_rate": 7.350602409638555e-06,
      "loss": 0.0057,
      "step": 104990
    },
    {
      "epoch": 12.650602409638553,
      "grad_norm": 1.544533133506775,
      "learning_rate": 7.349397590361447e-06,
      "loss": 0.0184,
      "step": 105000
    },
    {
      "epoch": 12.651807228915663,
      "grad_norm": 2.616779088973999,
      "learning_rate": 7.348192771084338e-06,
      "loss": 0.0595,
      "step": 105010
    },
    {
      "epoch": 12.653012048192771,
      "grad_norm": 0.0009321685647591949,
      "learning_rate": 7.346987951807229e-06,
      "loss": 0.0247,
      "step": 105020
    },
    {
      "epoch": 12.654216867469879,
      "grad_norm": 0.0010655599180608988,
      "learning_rate": 7.345783132530121e-06,
      "loss": 0.0606,
      "step": 105030
    },
    {
      "epoch": 12.655421686746989,
      "grad_norm": 0.0011219894513487816,
      "learning_rate": 7.3445783132530125e-06,
      "loss": 0.0235,
      "step": 105040
    },
    {
      "epoch": 12.656626506024097,
      "grad_norm": 0.3531315326690674,
      "learning_rate": 7.343373493975904e-06,
      "loss": 0.029,
      "step": 105050
    },
    {
      "epoch": 12.657831325301204,
      "grad_norm": 0.006792299449443817,
      "learning_rate": 7.342168674698795e-06,
      "loss": 0.0054,
      "step": 105060
    },
    {
      "epoch": 12.659036144578312,
      "grad_norm": 0.0480198971927166,
      "learning_rate": 7.340963855421688e-06,
      "loss": 0.0128,
      "step": 105070
    },
    {
      "epoch": 12.660240963855422,
      "grad_norm": 0.00450151739642024,
      "learning_rate": 7.339759036144579e-06,
      "loss": 0.0024,
      "step": 105080
    },
    {
      "epoch": 12.66144578313253,
      "grad_norm": 13.410255432128906,
      "learning_rate": 7.3385542168674704e-06,
      "loss": 0.0568,
      "step": 105090
    },
    {
      "epoch": 12.662650602409638,
      "grad_norm": 0.1191520020365715,
      "learning_rate": 7.337349397590362e-06,
      "loss": 0.0073,
      "step": 105100
    },
    {
      "epoch": 12.663855421686748,
      "grad_norm": 0.00179314857814461,
      "learning_rate": 7.336144578313254e-06,
      "loss": 0.0039,
      "step": 105110
    },
    {
      "epoch": 12.665060240963856,
      "grad_norm": 0.001128978212364018,
      "learning_rate": 7.334939759036145e-06,
      "loss": 0.011,
      "step": 105120
    },
    {
      "epoch": 12.666265060240963,
      "grad_norm": 0.006410303991287947,
      "learning_rate": 7.333734939759036e-06,
      "loss": 0.0061,
      "step": 105130
    },
    {
      "epoch": 12.667469879518073,
      "grad_norm": 0.9643663763999939,
      "learning_rate": 7.332530120481928e-06,
      "loss": 0.0214,
      "step": 105140
    },
    {
      "epoch": 12.668674698795181,
      "grad_norm": 0.0015815927181392908,
      "learning_rate": 7.33132530120482e-06,
      "loss": 0.0108,
      "step": 105150
    },
    {
      "epoch": 12.669879518072289,
      "grad_norm": 0.0016446295194327831,
      "learning_rate": 7.3301204819277116e-06,
      "loss": 0.0112,
      "step": 105160
    },
    {
      "epoch": 12.671084337349397,
      "grad_norm": 0.0013607805594801903,
      "learning_rate": 7.328915662650603e-06,
      "loss": 0.021,
      "step": 105170
    },
    {
      "epoch": 12.672289156626507,
      "grad_norm": 0.0015012199291959405,
      "learning_rate": 7.327710843373495e-06,
      "loss": 0.0143,
      "step": 105180
    },
    {
      "epoch": 12.673493975903614,
      "grad_norm": 0.8208624124526978,
      "learning_rate": 7.3265060240963855e-06,
      "loss": 0.02,
      "step": 105190
    },
    {
      "epoch": 12.674698795180722,
      "grad_norm": 0.0005476169171743095,
      "learning_rate": 7.325301204819277e-06,
      "loss": 0.0008,
      "step": 105200
    },
    {
      "epoch": 12.675903614457832,
      "grad_norm": 0.4565989375114441,
      "learning_rate": 7.324096385542169e-06,
      "loss": 0.007,
      "step": 105210
    },
    {
      "epoch": 12.67710843373494,
      "grad_norm": 0.0009510027011856437,
      "learning_rate": 7.322891566265061e-06,
      "loss": 0.0197,
      "step": 105220
    },
    {
      "epoch": 12.678313253012048,
      "grad_norm": 28.597347259521484,
      "learning_rate": 7.321686746987953e-06,
      "loss": 0.0224,
      "step": 105230
    },
    {
      "epoch": 12.679518072289156,
      "grad_norm": 0.03371178358793259,
      "learning_rate": 7.320481927710844e-06,
      "loss": 0.001,
      "step": 105240
    },
    {
      "epoch": 12.680722891566266,
      "grad_norm": 0.0007020494667813182,
      "learning_rate": 7.319277108433736e-06,
      "loss": 0.031,
      "step": 105250
    },
    {
      "epoch": 12.681927710843373,
      "grad_norm": 0.0010902737267315388,
      "learning_rate": 7.318072289156627e-06,
      "loss": 0.0084,
      "step": 105260
    },
    {
      "epoch": 12.683132530120481,
      "grad_norm": 0.00206559244543314,
      "learning_rate": 7.316867469879518e-06,
      "loss": 0.027,
      "step": 105270
    },
    {
      "epoch": 12.684337349397591,
      "grad_norm": 0.000828999443911016,
      "learning_rate": 7.31566265060241e-06,
      "loss": 0.004,
      "step": 105280
    },
    {
      "epoch": 12.685542168674699,
      "grad_norm": 0.010636314749717712,
      "learning_rate": 7.314457831325302e-06,
      "loss": 0.0108,
      "step": 105290
    },
    {
      "epoch": 12.686746987951807,
      "grad_norm": 4.931898593902588,
      "learning_rate": 7.313253012048194e-06,
      "loss": 0.0514,
      "step": 105300
    },
    {
      "epoch": 12.687951807228917,
      "grad_norm": 0.27594947814941406,
      "learning_rate": 7.312048192771085e-06,
      "loss": 0.0008,
      "step": 105310
    },
    {
      "epoch": 12.689156626506024,
      "grad_norm": 0.0006803268333896995,
      "learning_rate": 7.310843373493977e-06,
      "loss": 0.0041,
      "step": 105320
    },
    {
      "epoch": 12.690361445783132,
      "grad_norm": 0.0006602568319067359,
      "learning_rate": 7.309638554216868e-06,
      "loss": 0.035,
      "step": 105330
    },
    {
      "epoch": 12.69156626506024,
      "grad_norm": 1.5166387557983398,
      "learning_rate": 7.308433734939759e-06,
      "loss": 0.0184,
      "step": 105340
    },
    {
      "epoch": 12.69277108433735,
      "grad_norm": 1.6146150827407837,
      "learning_rate": 7.307228915662651e-06,
      "loss": 0.0085,
      "step": 105350
    },
    {
      "epoch": 12.693975903614458,
      "grad_norm": 0.010188467800617218,
      "learning_rate": 7.3060240963855425e-06,
      "loss": 0.0342,
      "step": 105360
    },
    {
      "epoch": 12.695180722891566,
      "grad_norm": 0.28574272990226746,
      "learning_rate": 7.304819277108435e-06,
      "loss": 0.0131,
      "step": 105370
    },
    {
      "epoch": 12.696385542168674,
      "grad_norm": 14.3837251663208,
      "learning_rate": 7.3036144578313265e-06,
      "loss": 0.0433,
      "step": 105380
    },
    {
      "epoch": 12.697590361445783,
      "grad_norm": 0.03724011778831482,
      "learning_rate": 7.302409638554217e-06,
      "loss": 0.0232,
      "step": 105390
    },
    {
      "epoch": 12.698795180722891,
      "grad_norm": 0.39323970675468445,
      "learning_rate": 7.301204819277109e-06,
      "loss": 0.001,
      "step": 105400
    },
    {
      "epoch": 12.7,
      "grad_norm": 0.0024054814130067825,
      "learning_rate": 7.3e-06,
      "loss": 0.0159,
      "step": 105410
    },
    {
      "epoch": 12.701204819277109,
      "grad_norm": 0.344374418258667,
      "learning_rate": 7.298795180722892e-06,
      "loss": 0.0176,
      "step": 105420
    },
    {
      "epoch": 12.702409638554217,
      "grad_norm": 0.472003310918808,
      "learning_rate": 7.297590361445784e-06,
      "loss": 0.0202,
      "step": 105430
    },
    {
      "epoch": 12.703614457831325,
      "grad_norm": 0.0027265942189842463,
      "learning_rate": 7.296385542168676e-06,
      "loss": 0.0085,
      "step": 105440
    },
    {
      "epoch": 12.704819277108435,
      "grad_norm": 7.102704048156738,
      "learning_rate": 7.295180722891568e-06,
      "loss": 0.0596,
      "step": 105450
    },
    {
      "epoch": 12.706024096385542,
      "grad_norm": 0.016514504328370094,
      "learning_rate": 7.293975903614458e-06,
      "loss": 0.0163,
      "step": 105460
    },
    {
      "epoch": 12.70722891566265,
      "grad_norm": 0.32537898421287537,
      "learning_rate": 7.29277108433735e-06,
      "loss": 0.0028,
      "step": 105470
    },
    {
      "epoch": 12.708433734939758,
      "grad_norm": 0.002766745164990425,
      "learning_rate": 7.2915662650602415e-06,
      "loss": 0.0214,
      "step": 105480
    },
    {
      "epoch": 12.709638554216868,
      "grad_norm": 0.03260311856865883,
      "learning_rate": 7.290361445783133e-06,
      "loss": 0.0021,
      "step": 105490
    },
    {
      "epoch": 12.710843373493976,
      "grad_norm": 0.0018351096659898758,
      "learning_rate": 7.289156626506025e-06,
      "loss": 0.0559,
      "step": 105500
    },
    {
      "epoch": 12.712048192771084,
      "grad_norm": 0.26395851373672485,
      "learning_rate": 7.2879518072289154e-06,
      "loss": 0.0232,
      "step": 105510
    },
    {
      "epoch": 12.713253012048193,
      "grad_norm": 0.15086862444877625,
      "learning_rate": 7.286746987951808e-06,
      "loss": 0.0045,
      "step": 105520
    },
    {
      "epoch": 12.714457831325301,
      "grad_norm": 0.5322823524475098,
      "learning_rate": 7.2855421686746995e-06,
      "loss": 0.002,
      "step": 105530
    },
    {
      "epoch": 12.71566265060241,
      "grad_norm": 0.4079751670360565,
      "learning_rate": 7.284337349397591e-06,
      "loss": 0.0139,
      "step": 105540
    },
    {
      "epoch": 12.716867469879517,
      "grad_norm": 0.0012419576523825526,
      "learning_rate": 7.283132530120483e-06,
      "loss": 0.0086,
      "step": 105550
    },
    {
      "epoch": 12.718072289156627,
      "grad_norm": 0.26386088132858276,
      "learning_rate": 7.281927710843374e-06,
      "loss": 0.002,
      "step": 105560
    },
    {
      "epoch": 12.719277108433735,
      "grad_norm": 0.0015556085854768753,
      "learning_rate": 7.280722891566265e-06,
      "loss": 0.0324,
      "step": 105570
    },
    {
      "epoch": 12.720481927710843,
      "grad_norm": 45.52397155761719,
      "learning_rate": 7.2795180722891566e-06,
      "loss": 0.0115,
      "step": 105580
    },
    {
      "epoch": 12.721686746987952,
      "grad_norm": 4.991907119750977,
      "learning_rate": 7.278313253012049e-06,
      "loss": 0.0431,
      "step": 105590
    },
    {
      "epoch": 12.72289156626506,
      "grad_norm": 2.5339903831481934,
      "learning_rate": 7.277108433734941e-06,
      "loss": 0.0142,
      "step": 105600
    },
    {
      "epoch": 12.724096385542168,
      "grad_norm": 0.0011803132947534323,
      "learning_rate": 7.275903614457832e-06,
      "loss": 0.0021,
      "step": 105610
    },
    {
      "epoch": 12.725301204819278,
      "grad_norm": 0.007780176587402821,
      "learning_rate": 7.274698795180724e-06,
      "loss": 0.0069,
      "step": 105620
    },
    {
      "epoch": 12.726506024096386,
      "grad_norm": 0.005231990944594145,
      "learning_rate": 7.273493975903615e-06,
      "loss": 0.0011,
      "step": 105630
    },
    {
      "epoch": 12.727710843373494,
      "grad_norm": 1.6763209104537964,
      "learning_rate": 7.272289156626506e-06,
      "loss": 0.0232,
      "step": 105640
    },
    {
      "epoch": 12.728915662650602,
      "grad_norm": 0.0015135189751163125,
      "learning_rate": 7.271084337349398e-06,
      "loss": 0.018,
      "step": 105650
    },
    {
      "epoch": 12.730120481927711,
      "grad_norm": 3.7088048458099365,
      "learning_rate": 7.269879518072289e-06,
      "loss": 0.0231,
      "step": 105660
    },
    {
      "epoch": 12.73132530120482,
      "grad_norm": 0.001454134238883853,
      "learning_rate": 7.268674698795182e-06,
      "loss": 0.0092,
      "step": 105670
    },
    {
      "epoch": 12.732530120481927,
      "grad_norm": 2.5793306827545166,
      "learning_rate": 7.267469879518073e-06,
      "loss": 0.0188,
      "step": 105680
    },
    {
      "epoch": 12.733734939759037,
      "grad_norm": 0.006778862327337265,
      "learning_rate": 7.266265060240965e-06,
      "loss": 0.0012,
      "step": 105690
    },
    {
      "epoch": 12.734939759036145,
      "grad_norm": 0.0010704247979447246,
      "learning_rate": 7.265060240963856e-06,
      "loss": 0.0013,
      "step": 105700
    },
    {
      "epoch": 12.736144578313253,
      "grad_norm": 7.274753093719482,
      "learning_rate": 7.263855421686747e-06,
      "loss": 0.0556,
      "step": 105710
    },
    {
      "epoch": 12.73734939759036,
      "grad_norm": 0.5266440510749817,
      "learning_rate": 7.262650602409639e-06,
      "loss": 0.0236,
      "step": 105720
    },
    {
      "epoch": 12.73855421686747,
      "grad_norm": 0.01281232014298439,
      "learning_rate": 7.26144578313253e-06,
      "loss": 0.0192,
      "step": 105730
    },
    {
      "epoch": 12.739759036144578,
      "grad_norm": 0.8588248491287231,
      "learning_rate": 7.260240963855423e-06,
      "loss": 0.0095,
      "step": 105740
    },
    {
      "epoch": 12.740963855421686,
      "grad_norm": 5.465642929077148,
      "learning_rate": 7.259036144578314e-06,
      "loss": 0.0308,
      "step": 105750
    },
    {
      "epoch": 12.742168674698796,
      "grad_norm": 1.134798526763916,
      "learning_rate": 7.257831325301206e-06,
      "loss": 0.0214,
      "step": 105760
    },
    {
      "epoch": 12.743373493975904,
      "grad_norm": 0.0027194174472242594,
      "learning_rate": 7.256626506024097e-06,
      "loss": 0.0002,
      "step": 105770
    },
    {
      "epoch": 12.744578313253012,
      "grad_norm": 0.0019239094108343124,
      "learning_rate": 7.255421686746988e-06,
      "loss": 0.0051,
      "step": 105780
    },
    {
      "epoch": 12.745783132530121,
      "grad_norm": 0.01976907067000866,
      "learning_rate": 7.25421686746988e-06,
      "loss": 0.0073,
      "step": 105790
    },
    {
      "epoch": 12.74698795180723,
      "grad_norm": 31.268199920654297,
      "learning_rate": 7.2530120481927715e-06,
      "loss": 0.0529,
      "step": 105800
    },
    {
      "epoch": 12.748192771084337,
      "grad_norm": 1.597743272781372,
      "learning_rate": 7.251807228915663e-06,
      "loss": 0.0131,
      "step": 105810
    },
    {
      "epoch": 12.749397590361445,
      "grad_norm": 0.005459345877170563,
      "learning_rate": 7.2506024096385555e-06,
      "loss": 0.0129,
      "step": 105820
    },
    {
      "epoch": 12.750602409638555,
      "grad_norm": 0.0027181156910955906,
      "learning_rate": 7.249397590361446e-06,
      "loss": 0.0217,
      "step": 105830
    },
    {
      "epoch": 12.751807228915663,
      "grad_norm": 0.006702289916574955,
      "learning_rate": 7.248192771084338e-06,
      "loss": 0.0045,
      "step": 105840
    },
    {
      "epoch": 12.75301204819277,
      "grad_norm": 0.014393698424100876,
      "learning_rate": 7.2469879518072294e-06,
      "loss": 0.0074,
      "step": 105850
    },
    {
      "epoch": 12.754216867469879,
      "grad_norm": 0.0007172239129431546,
      "learning_rate": 7.245783132530121e-06,
      "loss": 0.0156,
      "step": 105860
    },
    {
      "epoch": 12.755421686746988,
      "grad_norm": 1.620269536972046,
      "learning_rate": 7.244578313253013e-06,
      "loss": 0.0099,
      "step": 105870
    },
    {
      "epoch": 12.756626506024096,
      "grad_norm": 1.2588045597076416,
      "learning_rate": 7.243373493975903e-06,
      "loss": 0.0229,
      "step": 105880
    },
    {
      "epoch": 12.757831325301204,
      "grad_norm": 0.35433927178382874,
      "learning_rate": 7.242168674698797e-06,
      "loss": 0.0576,
      "step": 105890
    },
    {
      "epoch": 12.759036144578314,
      "grad_norm": 0.0007787325885146856,
      "learning_rate": 7.240963855421687e-06,
      "loss": 0.0206,
      "step": 105900
    },
    {
      "epoch": 12.760240963855422,
      "grad_norm": 1.15460205078125,
      "learning_rate": 7.239759036144579e-06,
      "loss": 0.0097,
      "step": 105910
    },
    {
      "epoch": 12.76144578313253,
      "grad_norm": 2.3346498012542725,
      "learning_rate": 7.2385542168674706e-06,
      "loss": 0.0277,
      "step": 105920
    },
    {
      "epoch": 12.76265060240964,
      "grad_norm": 0.015888214111328125,
      "learning_rate": 7.237349397590362e-06,
      "loss": 0.0253,
      "step": 105930
    },
    {
      "epoch": 12.763855421686747,
      "grad_norm": 0.0034299269318580627,
      "learning_rate": 7.236144578313254e-06,
      "loss": 0.0056,
      "step": 105940
    },
    {
      "epoch": 12.765060240963855,
      "grad_norm": 0.07681345194578171,
      "learning_rate": 7.2349397590361445e-06,
      "loss": 0.0116,
      "step": 105950
    },
    {
      "epoch": 12.766265060240963,
      "grad_norm": 10.041169166564941,
      "learning_rate": 7.233734939759037e-06,
      "loss": 0.0254,
      "step": 105960
    },
    {
      "epoch": 12.767469879518073,
      "grad_norm": 0.0008713266579434276,
      "learning_rate": 7.2325301204819285e-06,
      "loss": 0.0056,
      "step": 105970
    },
    {
      "epoch": 12.76867469879518,
      "grad_norm": 0.0011324990773573518,
      "learning_rate": 7.23132530120482e-06,
      "loss": 0.0044,
      "step": 105980
    },
    {
      "epoch": 12.769879518072289,
      "grad_norm": 1.3363896608352661,
      "learning_rate": 7.230120481927712e-06,
      "loss": 0.0234,
      "step": 105990
    },
    {
      "epoch": 12.771084337349398,
      "grad_norm": 0.0003006770566571504,
      "learning_rate": 7.228915662650603e-06,
      "loss": 0.009,
      "step": 106000
    },
    {
      "epoch": 12.772289156626506,
      "grad_norm": 0.03247459605336189,
      "learning_rate": 7.227710843373494e-06,
      "loss": 0.0123,
      "step": 106010
    },
    {
      "epoch": 12.773493975903614,
      "grad_norm": 0.0011761332862079144,
      "learning_rate": 7.226506024096386e-06,
      "loss": 0.057,
      "step": 106020
    },
    {
      "epoch": 12.774698795180722,
      "grad_norm": 0.01612776331603527,
      "learning_rate": 7.225301204819277e-06,
      "loss": 0.0038,
      "step": 106030
    },
    {
      "epoch": 12.775903614457832,
      "grad_norm": 2.2968976497650146,
      "learning_rate": 7.22409638554217e-06,
      "loss": 0.0252,
      "step": 106040
    },
    {
      "epoch": 12.77710843373494,
      "grad_norm": 0.008394614793360233,
      "learning_rate": 7.222891566265061e-06,
      "loss": 0.0085,
      "step": 106050
    },
    {
      "epoch": 12.778313253012048,
      "grad_norm": 0.0033082719892263412,
      "learning_rate": 7.221686746987953e-06,
      "loss": 0.0147,
      "step": 106060
    },
    {
      "epoch": 12.779518072289157,
      "grad_norm": 0.0021489597856998444,
      "learning_rate": 7.220481927710844e-06,
      "loss": 0.013,
      "step": 106070
    },
    {
      "epoch": 12.780722891566265,
      "grad_norm": 0.0063476478680968285,
      "learning_rate": 7.219277108433735e-06,
      "loss": 0.011,
      "step": 106080
    },
    {
      "epoch": 12.781927710843373,
      "grad_norm": 0.0021206254605203867,
      "learning_rate": 7.218072289156627e-06,
      "loss": 0.0032,
      "step": 106090
    },
    {
      "epoch": 12.783132530120483,
      "grad_norm": 0.20516344904899597,
      "learning_rate": 7.216867469879518e-06,
      "loss": 0.0151,
      "step": 106100
    },
    {
      "epoch": 12.78433734939759,
      "grad_norm": 0.4345678985118866,
      "learning_rate": 7.215662650602411e-06,
      "loss": 0.0267,
      "step": 106110
    },
    {
      "epoch": 12.785542168674699,
      "grad_norm": 0.42495372891426086,
      "learning_rate": 7.214457831325302e-06,
      "loss": 0.0113,
      "step": 106120
    },
    {
      "epoch": 12.786746987951807,
      "grad_norm": 2.3587703704833984,
      "learning_rate": 7.213253012048194e-06,
      "loss": 0.0035,
      "step": 106130
    },
    {
      "epoch": 12.787951807228916,
      "grad_norm": 0.0013746804324910045,
      "learning_rate": 7.212048192771085e-06,
      "loss": 0.0276,
      "step": 106140
    },
    {
      "epoch": 12.789156626506024,
      "grad_norm": 0.004362407606095076,
      "learning_rate": 7.210843373493976e-06,
      "loss": 0.1002,
      "step": 106150
    },
    {
      "epoch": 12.790361445783132,
      "grad_norm": 0.019792303442955017,
      "learning_rate": 7.209638554216868e-06,
      "loss": 0.0091,
      "step": 106160
    },
    {
      "epoch": 12.791566265060242,
      "grad_norm": 0.5980244874954224,
      "learning_rate": 7.208433734939759e-06,
      "loss": 0.0183,
      "step": 106170
    },
    {
      "epoch": 12.79277108433735,
      "grad_norm": 1.3551989793777466,
      "learning_rate": 7.207228915662651e-06,
      "loss": 0.0115,
      "step": 106180
    },
    {
      "epoch": 12.793975903614458,
      "grad_norm": 0.0011681064497679472,
      "learning_rate": 7.2060240963855434e-06,
      "loss": 0.0068,
      "step": 106190
    },
    {
      "epoch": 12.795180722891565,
      "grad_norm": 0.006648901384323835,
      "learning_rate": 7.204819277108435e-06,
      "loss": 0.0525,
      "step": 106200
    },
    {
      "epoch": 12.796385542168675,
      "grad_norm": 0.0017359013436362147,
      "learning_rate": 7.203614457831326e-06,
      "loss": 0.0082,
      "step": 106210
    },
    {
      "epoch": 12.797590361445783,
      "grad_norm": 0.9371304512023926,
      "learning_rate": 7.202409638554217e-06,
      "loss": 0.0063,
      "step": 106220
    },
    {
      "epoch": 12.798795180722891,
      "grad_norm": 0.0023894370533525944,
      "learning_rate": 7.201204819277109e-06,
      "loss": 0.026,
      "step": 106230
    },
    {
      "epoch": 12.8,
      "grad_norm": 0.35705652832984924,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.0828,
      "step": 106240
    },
    {
      "epoch": 12.801204819277109,
      "grad_norm": 0.022797344252467155,
      "learning_rate": 7.198795180722892e-06,
      "loss": 0.0111,
      "step": 106250
    },
    {
      "epoch": 12.802409638554217,
      "grad_norm": 1.6392676830291748,
      "learning_rate": 7.1975903614457845e-06,
      "loss": 0.0145,
      "step": 106260
    },
    {
      "epoch": 12.803614457831326,
      "grad_norm": 0.0040925247594714165,
      "learning_rate": 7.196385542168675e-06,
      "loss": 0.0288,
      "step": 106270
    },
    {
      "epoch": 12.804819277108434,
      "grad_norm": 0.0035183581057935953,
      "learning_rate": 7.195180722891567e-06,
      "loss": 0.0046,
      "step": 106280
    },
    {
      "epoch": 12.806024096385542,
      "grad_norm": 0.01296128798276186,
      "learning_rate": 7.1939759036144585e-06,
      "loss": 0.0373,
      "step": 106290
    },
    {
      "epoch": 12.80722891566265,
      "grad_norm": 0.04366142302751541,
      "learning_rate": 7.19277108433735e-06,
      "loss": 0.0123,
      "step": 106300
    },
    {
      "epoch": 12.80843373493976,
      "grad_norm": 0.5838757753372192,
      "learning_rate": 7.191566265060242e-06,
      "loss": 0.0101,
      "step": 106310
    },
    {
      "epoch": 12.809638554216868,
      "grad_norm": 14.089082717895508,
      "learning_rate": 7.190361445783132e-06,
      "loss": 0.0336,
      "step": 106320
    },
    {
      "epoch": 12.810843373493976,
      "grad_norm": 0.020550867542624474,
      "learning_rate": 7.189156626506024e-06,
      "loss": 0.0103,
      "step": 106330
    },
    {
      "epoch": 12.812048192771083,
      "grad_norm": 0.8761329054832458,
      "learning_rate": 7.187951807228916e-06,
      "loss": 0.0242,
      "step": 106340
    },
    {
      "epoch": 12.813253012048193,
      "grad_norm": 0.020558001473546028,
      "learning_rate": 7.186746987951808e-06,
      "loss": 0.0113,
      "step": 106350
    },
    {
      "epoch": 12.814457831325301,
      "grad_norm": 3.333090305328369,
      "learning_rate": 7.1855421686747e-06,
      "loss": 0.0077,
      "step": 106360
    },
    {
      "epoch": 12.815662650602409,
      "grad_norm": 0.003161468543112278,
      "learning_rate": 7.184337349397591e-06,
      "loss": 0.0189,
      "step": 106370
    },
    {
      "epoch": 12.816867469879519,
      "grad_norm": 0.23647473752498627,
      "learning_rate": 7.183132530120483e-06,
      "loss": 0.0669,
      "step": 106380
    },
    {
      "epoch": 12.818072289156627,
      "grad_norm": 1.812025785446167,
      "learning_rate": 7.1819277108433735e-06,
      "loss": 0.04,
      "step": 106390
    },
    {
      "epoch": 12.819277108433734,
      "grad_norm": 0.03443874046206474,
      "learning_rate": 7.180722891566265e-06,
      "loss": 0.0204,
      "step": 106400
    },
    {
      "epoch": 12.820481927710844,
      "grad_norm": 0.11090300232172012,
      "learning_rate": 7.1795180722891575e-06,
      "loss": 0.0221,
      "step": 106410
    },
    {
      "epoch": 12.821686746987952,
      "grad_norm": 0.975651741027832,
      "learning_rate": 7.178313253012049e-06,
      "loss": 0.0301,
      "step": 106420
    },
    {
      "epoch": 12.82289156626506,
      "grad_norm": 0.6917445063591003,
      "learning_rate": 7.177108433734941e-06,
      "loss": 0.0189,
      "step": 106430
    },
    {
      "epoch": 12.824096385542168,
      "grad_norm": 0.012568837963044643,
      "learning_rate": 7.175903614457832e-06,
      "loss": 0.0209,
      "step": 106440
    },
    {
      "epoch": 12.825301204819278,
      "grad_norm": 0.001026569283567369,
      "learning_rate": 7.174698795180723e-06,
      "loss": 0.0131,
      "step": 106450
    },
    {
      "epoch": 12.826506024096386,
      "grad_norm": 0.00154158566147089,
      "learning_rate": 7.173493975903615e-06,
      "loss": 0.0178,
      "step": 106460
    },
    {
      "epoch": 12.827710843373493,
      "grad_norm": 0.581298291683197,
      "learning_rate": 7.172289156626506e-06,
      "loss": 0.0115,
      "step": 106470
    },
    {
      "epoch": 12.828915662650603,
      "grad_norm": 1.4429110288619995,
      "learning_rate": 7.171084337349398e-06,
      "loss": 0.0502,
      "step": 106480
    },
    {
      "epoch": 12.830120481927711,
      "grad_norm": 0.017078794538974762,
      "learning_rate": 7.16987951807229e-06,
      "loss": 0.0069,
      "step": 106490
    },
    {
      "epoch": 12.831325301204819,
      "grad_norm": 0.01141261775046587,
      "learning_rate": 7.168674698795182e-06,
      "loss": 0.0145,
      "step": 106500
    },
    {
      "epoch": 12.832530120481927,
      "grad_norm": 0.0023152909707278013,
      "learning_rate": 7.167469879518073e-06,
      "loss": 0.0317,
      "step": 106510
    },
    {
      "epoch": 12.833734939759037,
      "grad_norm": 0.004404203500598669,
      "learning_rate": 7.166265060240964e-06,
      "loss": 0.0051,
      "step": 106520
    },
    {
      "epoch": 12.834939759036144,
      "grad_norm": 0.021645763888955116,
      "learning_rate": 7.165060240963856e-06,
      "loss": 0.0413,
      "step": 106530
    },
    {
      "epoch": 12.836144578313252,
      "grad_norm": 0.10625865310430527,
      "learning_rate": 7.163855421686747e-06,
      "loss": 0.0069,
      "step": 106540
    },
    {
      "epoch": 12.837349397590362,
      "grad_norm": 18.265830993652344,
      "learning_rate": 7.162650602409639e-06,
      "loss": 0.0297,
      "step": 106550
    },
    {
      "epoch": 12.83855421686747,
      "grad_norm": 1.1924757957458496,
      "learning_rate": 7.161445783132531e-06,
      "loss": 0.0112,
      "step": 106560
    },
    {
      "epoch": 12.839759036144578,
      "grad_norm": 0.18502283096313477,
      "learning_rate": 7.160240963855423e-06,
      "loss": 0.034,
      "step": 106570
    },
    {
      "epoch": 12.840963855421688,
      "grad_norm": 0.0024248247500509024,
      "learning_rate": 7.159036144578314e-06,
      "loss": 0.009,
      "step": 106580
    },
    {
      "epoch": 12.842168674698796,
      "grad_norm": 0.6435739398002625,
      "learning_rate": 7.157831325301205e-06,
      "loss": 0.0201,
      "step": 106590
    },
    {
      "epoch": 12.843373493975903,
      "grad_norm": 0.0021805493161082268,
      "learning_rate": 7.156626506024097e-06,
      "loss": 0.0445,
      "step": 106600
    },
    {
      "epoch": 12.844578313253011,
      "grad_norm": 0.2011931836605072,
      "learning_rate": 7.1554216867469884e-06,
      "loss": 0.0102,
      "step": 106610
    },
    {
      "epoch": 12.845783132530121,
      "grad_norm": 0.0042608859948813915,
      "learning_rate": 7.15421686746988e-06,
      "loss": 0.0143,
      "step": 106620
    },
    {
      "epoch": 12.846987951807229,
      "grad_norm": 0.011667031794786453,
      "learning_rate": 7.153012048192771e-06,
      "loss": 0.0121,
      "step": 106630
    },
    {
      "epoch": 12.848192771084337,
      "grad_norm": 0.002245513955131173,
      "learning_rate": 7.151807228915664e-06,
      "loss": 0.0157,
      "step": 106640
    },
    {
      "epoch": 12.849397590361447,
      "grad_norm": 0.004140217322856188,
      "learning_rate": 7.150602409638555e-06,
      "loss": 0.0446,
      "step": 106650
    },
    {
      "epoch": 12.850602409638554,
      "grad_norm": 0.38577279448509216,
      "learning_rate": 7.149397590361446e-06,
      "loss": 0.0108,
      "step": 106660
    },
    {
      "epoch": 12.851807228915662,
      "grad_norm": 0.9456075429916382,
      "learning_rate": 7.148192771084338e-06,
      "loss": 0.0252,
      "step": 106670
    },
    {
      "epoch": 12.85301204819277,
      "grad_norm": 0.7408868670463562,
      "learning_rate": 7.1469879518072295e-06,
      "loss": 0.0227,
      "step": 106680
    },
    {
      "epoch": 12.85421686746988,
      "grad_norm": 0.971384584903717,
      "learning_rate": 7.145783132530121e-06,
      "loss": 0.0202,
      "step": 106690
    },
    {
      "epoch": 12.855421686746988,
      "grad_norm": 0.00029288040241226554,
      "learning_rate": 7.144578313253012e-06,
      "loss": 0.0053,
      "step": 106700
    },
    {
      "epoch": 12.856626506024096,
      "grad_norm": 0.00917720515280962,
      "learning_rate": 7.143373493975905e-06,
      "loss": 0.001,
      "step": 106710
    },
    {
      "epoch": 12.857831325301206,
      "grad_norm": 2.142744541168213,
      "learning_rate": 7.142168674698796e-06,
      "loss": 0.0205,
      "step": 106720
    },
    {
      "epoch": 12.859036144578313,
      "grad_norm": 0.0008487499435432255,
      "learning_rate": 7.1409638554216875e-06,
      "loss": 0.0051,
      "step": 106730
    },
    {
      "epoch": 12.860240963855421,
      "grad_norm": 1.0928215980529785,
      "learning_rate": 7.139759036144579e-06,
      "loss": 0.014,
      "step": 106740
    },
    {
      "epoch": 12.861445783132531,
      "grad_norm": 0.0006638204213231802,
      "learning_rate": 7.138554216867471e-06,
      "loss": 0.0141,
      "step": 106750
    },
    {
      "epoch": 12.862650602409639,
      "grad_norm": 0.04728741943836212,
      "learning_rate": 7.137349397590362e-06,
      "loss": 0.0155,
      "step": 106760
    },
    {
      "epoch": 12.863855421686747,
      "grad_norm": 1.0671662092208862,
      "learning_rate": 7.136144578313253e-06,
      "loss": 0.0162,
      "step": 106770
    },
    {
      "epoch": 12.865060240963855,
      "grad_norm": 0.0007234482909552753,
      "learning_rate": 7.134939759036145e-06,
      "loss": 0.0175,
      "step": 106780
    },
    {
      "epoch": 12.866265060240965,
      "grad_norm": 0.0006054771365597844,
      "learning_rate": 7.133734939759037e-06,
      "loss": 0.0125,
      "step": 106790
    },
    {
      "epoch": 12.867469879518072,
      "grad_norm": 0.2606739401817322,
      "learning_rate": 7.132530120481929e-06,
      "loss": 0.0037,
      "step": 106800
    },
    {
      "epoch": 12.86867469879518,
      "grad_norm": 1.6818974018096924,
      "learning_rate": 7.13132530120482e-06,
      "loss": 0.0606,
      "step": 106810
    },
    {
      "epoch": 12.869879518072288,
      "grad_norm": 0.023465147241950035,
      "learning_rate": 7.130120481927712e-06,
      "loss": 0.0083,
      "step": 106820
    },
    {
      "epoch": 12.871084337349398,
      "grad_norm": 1.5181816816329956,
      "learning_rate": 7.1289156626506025e-06,
      "loss": 0.034,
      "step": 106830
    },
    {
      "epoch": 12.872289156626506,
      "grad_norm": 0.0010501205688342452,
      "learning_rate": 7.127710843373494e-06,
      "loss": 0.0189,
      "step": 106840
    },
    {
      "epoch": 12.873493975903614,
      "grad_norm": 16.786609649658203,
      "learning_rate": 7.126506024096386e-06,
      "loss": 0.0193,
      "step": 106850
    },
    {
      "epoch": 12.874698795180723,
      "grad_norm": 0.0017163018928840756,
      "learning_rate": 7.125301204819278e-06,
      "loss": 0.0114,
      "step": 106860
    },
    {
      "epoch": 12.875903614457831,
      "grad_norm": 1.0063221454620361,
      "learning_rate": 7.12409638554217e-06,
      "loss": 0.0194,
      "step": 106870
    },
    {
      "epoch": 12.87710843373494,
      "grad_norm": 0.0013445308431982994,
      "learning_rate": 7.122891566265061e-06,
      "loss": 0.0073,
      "step": 106880
    },
    {
      "epoch": 12.878313253012049,
      "grad_norm": 0.6706210970878601,
      "learning_rate": 7.121686746987953e-06,
      "loss": 0.0107,
      "step": 106890
    },
    {
      "epoch": 12.879518072289157,
      "grad_norm": 0.04556083306670189,
      "learning_rate": 7.120481927710844e-06,
      "loss": 0.0048,
      "step": 106900
    },
    {
      "epoch": 12.880722891566265,
      "grad_norm": 1.1455833911895752,
      "learning_rate": 7.119277108433735e-06,
      "loss": 0.0317,
      "step": 106910
    },
    {
      "epoch": 12.881927710843373,
      "grad_norm": 0.861694872379303,
      "learning_rate": 7.118072289156627e-06,
      "loss": 0.0195,
      "step": 106920
    },
    {
      "epoch": 12.883132530120482,
      "grad_norm": 0.004262624774128199,
      "learning_rate": 7.116867469879518e-06,
      "loss": 0.0542,
      "step": 106930
    },
    {
      "epoch": 12.88433734939759,
      "grad_norm": 0.0030472981743514538,
      "learning_rate": 7.115662650602411e-06,
      "loss": 0.0198,
      "step": 106940
    },
    {
      "epoch": 12.885542168674698,
      "grad_norm": 0.3231767416000366,
      "learning_rate": 7.114457831325302e-06,
      "loss": 0.0238,
      "step": 106950
    },
    {
      "epoch": 12.886746987951808,
      "grad_norm": 0.0017307810485363007,
      "learning_rate": 7.113253012048193e-06,
      "loss": 0.0275,
      "step": 106960
    },
    {
      "epoch": 12.887951807228916,
      "grad_norm": 1.3637630939483643,
      "learning_rate": 7.112048192771085e-06,
      "loss": 0.023,
      "step": 106970
    },
    {
      "epoch": 12.889156626506024,
      "grad_norm": 1.6928025484085083,
      "learning_rate": 7.110843373493976e-06,
      "loss": 0.0126,
      "step": 106980
    },
    {
      "epoch": 12.890361445783132,
      "grad_norm": 0.007670294027775526,
      "learning_rate": 7.109638554216868e-06,
      "loss": 0.002,
      "step": 106990
    },
    {
      "epoch": 12.891566265060241,
      "grad_norm": 0.012986382469534874,
      "learning_rate": 7.1084337349397595e-06,
      "loss": 0.0065,
      "step": 107000
    },
    {
      "epoch": 12.89277108433735,
      "grad_norm": 0.016751321032643318,
      "learning_rate": 7.107228915662652e-06,
      "loss": 0.057,
      "step": 107010
    },
    {
      "epoch": 12.893975903614457,
      "grad_norm": 0.08108919858932495,
      "learning_rate": 7.1060240963855435e-06,
      "loss": 0.0298,
      "step": 107020
    },
    {
      "epoch": 12.895180722891567,
      "grad_norm": 0.02143506146967411,
      "learning_rate": 7.104819277108434e-06,
      "loss": 0.0143,
      "step": 107030
    },
    {
      "epoch": 12.896385542168675,
      "grad_norm": 0.0030119922012090683,
      "learning_rate": 7.103614457831326e-06,
      "loss": 0.018,
      "step": 107040
    },
    {
      "epoch": 12.897590361445783,
      "grad_norm": 0.003864097176119685,
      "learning_rate": 7.1024096385542175e-06,
      "loss": 0.0068,
      "step": 107050
    },
    {
      "epoch": 12.898795180722892,
      "grad_norm": 0.008748797699809074,
      "learning_rate": 7.101204819277109e-06,
      "loss": 0.0097,
      "step": 107060
    },
    {
      "epoch": 12.9,
      "grad_norm": 0.003272044938057661,
      "learning_rate": 7.100000000000001e-06,
      "loss": 0.0106,
      "step": 107070
    },
    {
      "epoch": 12.901204819277108,
      "grad_norm": 0.0031255350913852453,
      "learning_rate": 7.098795180722891e-06,
      "loss": 0.0243,
      "step": 107080
    },
    {
      "epoch": 12.902409638554216,
      "grad_norm": 0.22715753316879272,
      "learning_rate": 7.097590361445784e-06,
      "loss": 0.0159,
      "step": 107090
    },
    {
      "epoch": 12.903614457831326,
      "grad_norm": 0.08168405294418335,
      "learning_rate": 7.096385542168675e-06,
      "loss": 0.0233,
      "step": 107100
    },
    {
      "epoch": 12.904819277108434,
      "grad_norm": 0.23550288379192352,
      "learning_rate": 7.095180722891567e-06,
      "loss": 0.0141,
      "step": 107110
    },
    {
      "epoch": 12.906024096385542,
      "grad_norm": 0.7728965282440186,
      "learning_rate": 7.0939759036144586e-06,
      "loss": 0.0185,
      "step": 107120
    },
    {
      "epoch": 12.907228915662651,
      "grad_norm": 0.0011110046179965138,
      "learning_rate": 7.09277108433735e-06,
      "loss": 0.0125,
      "step": 107130
    },
    {
      "epoch": 12.90843373493976,
      "grad_norm": 0.0036266131792217493,
      "learning_rate": 7.091566265060241e-06,
      "loss": 0.0358,
      "step": 107140
    },
    {
      "epoch": 12.909638554216867,
      "grad_norm": 0.9653533101081848,
      "learning_rate": 7.0903614457831325e-06,
      "loss": 0.0507,
      "step": 107150
    },
    {
      "epoch": 12.910843373493975,
      "grad_norm": 0.004686959553509951,
      "learning_rate": 7.089156626506025e-06,
      "loss": 0.0196,
      "step": 107160
    },
    {
      "epoch": 12.912048192771085,
      "grad_norm": 0.0103122154250741,
      "learning_rate": 7.0879518072289165e-06,
      "loss": 0.0104,
      "step": 107170
    },
    {
      "epoch": 12.913253012048193,
      "grad_norm": 0.01079259067773819,
      "learning_rate": 7.086746987951808e-06,
      "loss": 0.0402,
      "step": 107180
    },
    {
      "epoch": 12.9144578313253,
      "grad_norm": 0.09931129217147827,
      "learning_rate": 7.0855421686747e-06,
      "loss": 0.0074,
      "step": 107190
    },
    {
      "epoch": 12.91566265060241,
      "grad_norm": 1.8894425630569458,
      "learning_rate": 7.084337349397591e-06,
      "loss": 0.0106,
      "step": 107200
    },
    {
      "epoch": 12.916867469879518,
      "grad_norm": 0.20190194249153137,
      "learning_rate": 7.083132530120482e-06,
      "loss": 0.0012,
      "step": 107210
    },
    {
      "epoch": 12.918072289156626,
      "grad_norm": 0.014352666214108467,
      "learning_rate": 7.081927710843374e-06,
      "loss": 0.0212,
      "step": 107220
    },
    {
      "epoch": 12.919277108433734,
      "grad_norm": 0.007417486980557442,
      "learning_rate": 7.080722891566265e-06,
      "loss": 0.0037,
      "step": 107230
    },
    {
      "epoch": 12.920481927710844,
      "grad_norm": 0.004003074951469898,
      "learning_rate": 7.079518072289158e-06,
      "loss": 0.0471,
      "step": 107240
    },
    {
      "epoch": 12.921686746987952,
      "grad_norm": 0.0027708583511412144,
      "learning_rate": 7.078313253012049e-06,
      "loss": 0.0036,
      "step": 107250
    },
    {
      "epoch": 12.92289156626506,
      "grad_norm": 0.5633723735809326,
      "learning_rate": 7.077108433734941e-06,
      "loss": 0.0502,
      "step": 107260
    },
    {
      "epoch": 12.92409638554217,
      "grad_norm": 0.020845109596848488,
      "learning_rate": 7.0759036144578315e-06,
      "loss": 0.0094,
      "step": 107270
    },
    {
      "epoch": 12.925301204819277,
      "grad_norm": 13.467528343200684,
      "learning_rate": 7.074698795180723e-06,
      "loss": 0.0663,
      "step": 107280
    },
    {
      "epoch": 12.926506024096385,
      "grad_norm": 0.007941978052258492,
      "learning_rate": 7.073493975903615e-06,
      "loss": 0.0134,
      "step": 107290
    },
    {
      "epoch": 12.927710843373493,
      "grad_norm": 0.15935905277729034,
      "learning_rate": 7.072289156626506e-06,
      "loss": 0.0009,
      "step": 107300
    },
    {
      "epoch": 12.928915662650603,
      "grad_norm": 0.035319551825523376,
      "learning_rate": 7.071084337349399e-06,
      "loss": 0.0056,
      "step": 107310
    },
    {
      "epoch": 12.93012048192771,
      "grad_norm": 0.0007663823198527098,
      "learning_rate": 7.06987951807229e-06,
      "loss": 0.0275,
      "step": 107320
    },
    {
      "epoch": 12.931325301204819,
      "grad_norm": 1.086168885231018,
      "learning_rate": 7.068674698795182e-06,
      "loss": 0.0446,
      "step": 107330
    },
    {
      "epoch": 12.932530120481928,
      "grad_norm": 1.3060476779937744,
      "learning_rate": 7.067469879518073e-06,
      "loss": 0.0058,
      "step": 107340
    },
    {
      "epoch": 12.933734939759036,
      "grad_norm": 0.07347890734672546,
      "learning_rate": 7.066265060240964e-06,
      "loss": 0.0275,
      "step": 107350
    },
    {
      "epoch": 12.934939759036144,
      "grad_norm": 2.611184597015381,
      "learning_rate": 7.065060240963856e-06,
      "loss": 0.0256,
      "step": 107360
    },
    {
      "epoch": 12.936144578313254,
      "grad_norm": 0.002743485849350691,
      "learning_rate": 7.0638554216867474e-06,
      "loss": 0.0101,
      "step": 107370
    },
    {
      "epoch": 12.937349397590362,
      "grad_norm": 0.005225487984716892,
      "learning_rate": 7.062650602409639e-06,
      "loss": 0.0129,
      "step": 107380
    },
    {
      "epoch": 12.93855421686747,
      "grad_norm": 0.5601999163627625,
      "learning_rate": 7.0614457831325314e-06,
      "loss": 0.0307,
      "step": 107390
    },
    {
      "epoch": 12.939759036144578,
      "grad_norm": 0.003840849967673421,
      "learning_rate": 7.060240963855422e-06,
      "loss": 0.0192,
      "step": 107400
    },
    {
      "epoch": 12.940963855421687,
      "grad_norm": 0.018704049289226532,
      "learning_rate": 7.059036144578314e-06,
      "loss": 0.0059,
      "step": 107410
    },
    {
      "epoch": 12.942168674698795,
      "grad_norm": 0.004412709269672632,
      "learning_rate": 7.057831325301205e-06,
      "loss": 0.0153,
      "step": 107420
    },
    {
      "epoch": 12.943373493975903,
      "grad_norm": 0.025711247697472572,
      "learning_rate": 7.056626506024097e-06,
      "loss": 0.0162,
      "step": 107430
    },
    {
      "epoch": 12.944578313253013,
      "grad_norm": 1.9719089269638062,
      "learning_rate": 7.0554216867469885e-06,
      "loss": 0.0171,
      "step": 107440
    },
    {
      "epoch": 12.94578313253012,
      "grad_norm": 0.40047213435173035,
      "learning_rate": 7.054216867469879e-06,
      "loss": 0.024,
      "step": 107450
    },
    {
      "epoch": 12.946987951807229,
      "grad_norm": 1.5880204439163208,
      "learning_rate": 7.0530120481927726e-06,
      "loss": 0.0123,
      "step": 107460
    },
    {
      "epoch": 12.948192771084337,
      "grad_norm": 0.31048348546028137,
      "learning_rate": 7.051807228915663e-06,
      "loss": 0.0188,
      "step": 107470
    },
    {
      "epoch": 12.949397590361446,
      "grad_norm": 0.3696184754371643,
      "learning_rate": 7.050602409638555e-06,
      "loss": 0.0185,
      "step": 107480
    },
    {
      "epoch": 12.950602409638554,
      "grad_norm": 1.4335658550262451,
      "learning_rate": 7.0493975903614465e-06,
      "loss": 0.0334,
      "step": 107490
    },
    {
      "epoch": 12.951807228915662,
      "grad_norm": 0.0022723160218447447,
      "learning_rate": 7.048192771084338e-06,
      "loss": 0.0378,
      "step": 107500
    },
    {
      "epoch": 12.953012048192772,
      "grad_norm": 0.004869584925472736,
      "learning_rate": 7.04698795180723e-06,
      "loss": 0.0184,
      "step": 107510
    },
    {
      "epoch": 12.95421686746988,
      "grad_norm": 1.1455687284469604,
      "learning_rate": 7.04578313253012e-06,
      "loss": 0.0187,
      "step": 107520
    },
    {
      "epoch": 12.955421686746988,
      "grad_norm": 1.7467268705368042,
      "learning_rate": 7.044578313253012e-06,
      "loss": 0.0224,
      "step": 107530
    },
    {
      "epoch": 12.956626506024097,
      "grad_norm": 0.0034928000532090664,
      "learning_rate": 7.043373493975904e-06,
      "loss": 0.0289,
      "step": 107540
    },
    {
      "epoch": 12.957831325301205,
      "grad_norm": 1.0101717710494995,
      "learning_rate": 7.042168674698796e-06,
      "loss": 0.02,
      "step": 107550
    },
    {
      "epoch": 12.959036144578313,
      "grad_norm": 0.001235781703144312,
      "learning_rate": 7.040963855421688e-06,
      "loss": 0.0085,
      "step": 107560
    },
    {
      "epoch": 12.960240963855421,
      "grad_norm": 0.9998273849487305,
      "learning_rate": 7.039759036144579e-06,
      "loss": 0.0283,
      "step": 107570
    },
    {
      "epoch": 12.96144578313253,
      "grad_norm": 1.1088868379592896,
      "learning_rate": 7.03855421686747e-06,
      "loss": 0.0091,
      "step": 107580
    },
    {
      "epoch": 12.962650602409639,
      "grad_norm": 0.0027616985607892275,
      "learning_rate": 7.0373493975903615e-06,
      "loss": 0.015,
      "step": 107590
    },
    {
      "epoch": 12.963855421686747,
      "grad_norm": 0.0030321108642965555,
      "learning_rate": 7.036144578313253e-06,
      "loss": 0.0147,
      "step": 107600
    },
    {
      "epoch": 12.965060240963856,
      "grad_norm": 0.0021519495639950037,
      "learning_rate": 7.0349397590361455e-06,
      "loss": 0.004,
      "step": 107610
    },
    {
      "epoch": 12.966265060240964,
      "grad_norm": 0.001837339485064149,
      "learning_rate": 7.033734939759037e-06,
      "loss": 0.0064,
      "step": 107620
    },
    {
      "epoch": 12.967469879518072,
      "grad_norm": 1.6422396898269653,
      "learning_rate": 7.032530120481929e-06,
      "loss": 0.0379,
      "step": 107630
    },
    {
      "epoch": 12.96867469879518,
      "grad_norm": 0.002479486633092165,
      "learning_rate": 7.03132530120482e-06,
      "loss": 0.0063,
      "step": 107640
    },
    {
      "epoch": 12.96987951807229,
      "grad_norm": 0.8218631148338318,
      "learning_rate": 7.030120481927711e-06,
      "loss": 0.0156,
      "step": 107650
    },
    {
      "epoch": 12.971084337349398,
      "grad_norm": 0.0004516400513239205,
      "learning_rate": 7.028915662650603e-06,
      "loss": 0.0047,
      "step": 107660
    },
    {
      "epoch": 12.972289156626506,
      "grad_norm": 0.4687522351741791,
      "learning_rate": 7.027710843373494e-06,
      "loss": 0.0133,
      "step": 107670
    },
    {
      "epoch": 12.973493975903615,
      "grad_norm": 0.12930354475975037,
      "learning_rate": 7.026506024096386e-06,
      "loss": 0.0062,
      "step": 107680
    },
    {
      "epoch": 12.974698795180723,
      "grad_norm": 0.7202584147453308,
      "learning_rate": 7.025301204819278e-06,
      "loss": 0.0127,
      "step": 107690
    },
    {
      "epoch": 12.975903614457831,
      "grad_norm": 0.050400495529174805,
      "learning_rate": 7.02409638554217e-06,
      "loss": 0.0357,
      "step": 107700
    },
    {
      "epoch": 12.977108433734939,
      "grad_norm": 0.007890165783464909,
      "learning_rate": 7.0228915662650606e-06,
      "loss": 0.0139,
      "step": 107710
    },
    {
      "epoch": 12.978313253012049,
      "grad_norm": 0.7200612425804138,
      "learning_rate": 7.021686746987952e-06,
      "loss": 0.0214,
      "step": 107720
    },
    {
      "epoch": 12.979518072289157,
      "grad_norm": 0.0017500871326774359,
      "learning_rate": 7.020481927710844e-06,
      "loss": 0.012,
      "step": 107730
    },
    {
      "epoch": 12.980722891566264,
      "grad_norm": 0.0009896280243992805,
      "learning_rate": 7.019277108433735e-06,
      "loss": 0.0161,
      "step": 107740
    },
    {
      "epoch": 12.981927710843374,
      "grad_norm": 0.002177117159590125,
      "learning_rate": 7.018072289156627e-06,
      "loss": 0.0144,
      "step": 107750
    },
    {
      "epoch": 12.983132530120482,
      "grad_norm": 17.624961853027344,
      "learning_rate": 7.016867469879519e-06,
      "loss": 0.0306,
      "step": 107760
    },
    {
      "epoch": 12.98433734939759,
      "grad_norm": 0.3009960651397705,
      "learning_rate": 7.015662650602411e-06,
      "loss": 0.0244,
      "step": 107770
    },
    {
      "epoch": 12.985542168674698,
      "grad_norm": 0.4394557476043701,
      "learning_rate": 7.014457831325302e-06,
      "loss": 0.0334,
      "step": 107780
    },
    {
      "epoch": 12.986746987951808,
      "grad_norm": 0.9752489328384399,
      "learning_rate": 7.013253012048193e-06,
      "loss": 0.0118,
      "step": 107790
    },
    {
      "epoch": 12.987951807228916,
      "grad_norm": 0.44633907079696655,
      "learning_rate": 7.012048192771085e-06,
      "loss": 0.0308,
      "step": 107800
    },
    {
      "epoch": 12.989156626506023,
      "grad_norm": 0.34912776947021484,
      "learning_rate": 7.0108433734939764e-06,
      "loss": 0.0184,
      "step": 107810
    },
    {
      "epoch": 12.990361445783133,
      "grad_norm": 1.9121354818344116,
      "learning_rate": 7.009638554216868e-06,
      "loss": 0.0065,
      "step": 107820
    },
    {
      "epoch": 12.991566265060241,
      "grad_norm": 0.0013422243064269423,
      "learning_rate": 7.008433734939759e-06,
      "loss": 0.0115,
      "step": 107830
    },
    {
      "epoch": 12.992771084337349,
      "grad_norm": 0.37275421619415283,
      "learning_rate": 7.007228915662651e-06,
      "loss": 0.022,
      "step": 107840
    },
    {
      "epoch": 12.993975903614459,
      "grad_norm": 0.0007703343289904296,
      "learning_rate": 7.006024096385543e-06,
      "loss": 0.0366,
      "step": 107850
    },
    {
      "epoch": 12.995180722891567,
      "grad_norm": 0.788348376750946,
      "learning_rate": 7.004819277108434e-06,
      "loss": 0.0037,
      "step": 107860
    },
    {
      "epoch": 12.996385542168674,
      "grad_norm": 1.0897783041000366,
      "learning_rate": 7.003614457831326e-06,
      "loss": 0.0097,
      "step": 107870
    },
    {
      "epoch": 12.997590361445782,
      "grad_norm": 0.4956793785095215,
      "learning_rate": 7.0024096385542176e-06,
      "loss": 0.0137,
      "step": 107880
    },
    {
      "epoch": 12.998795180722892,
      "grad_norm": 0.08936721086502075,
      "learning_rate": 7.001204819277108e-06,
      "loss": 0.0412,
      "step": 107890
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.3346700072288513,
      "learning_rate": 7e-06,
      "loss": 0.0205,
      "step": 107900
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.9866657292838396,
      "eval_f1": 0.9642655278527916,
      "eval_loss": 0.04954909160733223,
      "eval_precision": 0.9802093973442288,
      "eval_recall": 0.9488320355951056,
      "eval_runtime": 3379.8764,
      "eval_samples_per_second": 12.631,
      "eval_steps_per_second": 0.526,
      "step": 107900
    },
    {
      "epoch": 13.001204819277108,
      "grad_norm": 0.007268117740750313,
      "learning_rate": 6.998795180722892e-06,
      "loss": 0.0244,
      "step": 107910
    },
    {
      "epoch": 13.002409638554218,
      "grad_norm": 0.0023541187401860952,
      "learning_rate": 6.997590361445784e-06,
      "loss": 0.0105,
      "step": 107920
    },
    {
      "epoch": 13.003614457831326,
      "grad_norm": 0.5615073442459106,
      "learning_rate": 6.9963855421686755e-06,
      "loss": 0.0197,
      "step": 107930
    },
    {
      "epoch": 13.004819277108433,
      "grad_norm": 0.7151022553443909,
      "learning_rate": 6.995180722891567e-06,
      "loss": 0.0168,
      "step": 107940
    },
    {
      "epoch": 13.006024096385541,
      "grad_norm": 0.001111676567234099,
      "learning_rate": 6.993975903614459e-06,
      "loss": 0.0243,
      "step": 107950
    },
    {
      "epoch": 13.007228915662651,
      "grad_norm": 0.6150564551353455,
      "learning_rate": 6.992771084337349e-06,
      "loss": 0.0041,
      "step": 107960
    },
    {
      "epoch": 13.008433734939759,
      "grad_norm": 0.3289582133293152,
      "learning_rate": 6.991566265060241e-06,
      "loss": 0.0374,
      "step": 107970
    },
    {
      "epoch": 13.009638554216867,
      "grad_norm": 0.0192997008562088,
      "learning_rate": 6.990361445783133e-06,
      "loss": 0.0163,
      "step": 107980
    },
    {
      "epoch": 13.010843373493977,
      "grad_norm": 1.219773292541504,
      "learning_rate": 6.989156626506025e-06,
      "loss": 0.0132,
      "step": 107990
    },
    {
      "epoch": 13.012048192771084,
      "grad_norm": 1.406978964805603,
      "learning_rate": 6.987951807228917e-06,
      "loss": 0.0057,
      "step": 108000
    },
    {
      "epoch": 13.013253012048192,
      "grad_norm": 0.25824403762817383,
      "learning_rate": 6.986746987951808e-06,
      "loss": 0.0136,
      "step": 108010
    },
    {
      "epoch": 13.0144578313253,
      "grad_norm": 0.00046905825729481876,
      "learning_rate": 6.985542168674699e-06,
      "loss": 0.0024,
      "step": 108020
    },
    {
      "epoch": 13.01566265060241,
      "grad_norm": 0.0003671035810839385,
      "learning_rate": 6.9843373493975905e-06,
      "loss": 0.0208,
      "step": 108030
    },
    {
      "epoch": 13.016867469879518,
      "grad_norm": 0.0013276453828439116,
      "learning_rate": 6.983132530120482e-06,
      "loss": 0.0279,
      "step": 108040
    },
    {
      "epoch": 13.018072289156626,
      "grad_norm": 0.0003889885265380144,
      "learning_rate": 6.981927710843374e-06,
      "loss": 0.0032,
      "step": 108050
    },
    {
      "epoch": 13.019277108433736,
      "grad_norm": 0.000371587579138577,
      "learning_rate": 6.980722891566266e-06,
      "loss": 0.0043,
      "step": 108060
    },
    {
      "epoch": 13.020481927710843,
      "grad_norm": 0.01052760612219572,
      "learning_rate": 6.979518072289158e-06,
      "loss": 0.002,
      "step": 108070
    },
    {
      "epoch": 13.021686746987951,
      "grad_norm": 0.021886663511395454,
      "learning_rate": 6.978313253012049e-06,
      "loss": 0.0189,
      "step": 108080
    },
    {
      "epoch": 13.022891566265061,
      "grad_norm": 0.019521092996001244,
      "learning_rate": 6.97710843373494e-06,
      "loss": 0.0274,
      "step": 108090
    },
    {
      "epoch": 13.024096385542169,
      "grad_norm": 0.011107619851827621,
      "learning_rate": 6.975903614457832e-06,
      "loss": 0.0659,
      "step": 108100
    },
    {
      "epoch": 13.025301204819277,
      "grad_norm": 1.0868549346923828,
      "learning_rate": 6.974698795180723e-06,
      "loss": 0.0208,
      "step": 108110
    },
    {
      "epoch": 13.026506024096385,
      "grad_norm": 0.016043422743678093,
      "learning_rate": 6.973493975903615e-06,
      "loss": 0.0163,
      "step": 108120
    },
    {
      "epoch": 13.027710843373494,
      "grad_norm": 0.8243834376335144,
      "learning_rate": 6.972289156626506e-06,
      "loss": 0.0192,
      "step": 108130
    },
    {
      "epoch": 13.028915662650602,
      "grad_norm": 0.0009774145437404513,
      "learning_rate": 6.971084337349399e-06,
      "loss": 0.0052,
      "step": 108140
    },
    {
      "epoch": 13.03012048192771,
      "grad_norm": 0.0012075643753632903,
      "learning_rate": 6.96987951807229e-06,
      "loss": 0.0291,
      "step": 108150
    },
    {
      "epoch": 13.03132530120482,
      "grad_norm": 0.2551768124103546,
      "learning_rate": 6.968674698795181e-06,
      "loss": 0.0172,
      "step": 108160
    },
    {
      "epoch": 13.032530120481928,
      "grad_norm": 0.28118011355400085,
      "learning_rate": 6.967469879518073e-06,
      "loss": 0.0157,
      "step": 108170
    },
    {
      "epoch": 13.033734939759036,
      "grad_norm": 0.008853727020323277,
      "learning_rate": 6.966265060240964e-06,
      "loss": 0.045,
      "step": 108180
    },
    {
      "epoch": 13.034939759036144,
      "grad_norm": 0.976337194442749,
      "learning_rate": 6.965060240963856e-06,
      "loss": 0.0369,
      "step": 108190
    },
    {
      "epoch": 13.036144578313253,
      "grad_norm": 32.448150634765625,
      "learning_rate": 6.963855421686747e-06,
      "loss": 0.0095,
      "step": 108200
    },
    {
      "epoch": 13.037349397590361,
      "grad_norm": 0.019586561247706413,
      "learning_rate": 6.96265060240964e-06,
      "loss": 0.0188,
      "step": 108210
    },
    {
      "epoch": 13.03855421686747,
      "grad_norm": 1.7196009159088135,
      "learning_rate": 6.961445783132531e-06,
      "loss": 0.0217,
      "step": 108220
    },
    {
      "epoch": 13.039759036144579,
      "grad_norm": 10.80474853515625,
      "learning_rate": 6.960240963855422e-06,
      "loss": 0.0253,
      "step": 108230
    },
    {
      "epoch": 13.040963855421687,
      "grad_norm": 0.0007893944857642055,
      "learning_rate": 6.959036144578314e-06,
      "loss": 0.0027,
      "step": 108240
    },
    {
      "epoch": 13.042168674698795,
      "grad_norm": 2.740151882171631,
      "learning_rate": 6.9578313253012055e-06,
      "loss": 0.0232,
      "step": 108250
    },
    {
      "epoch": 13.043373493975903,
      "grad_norm": 0.011650430038571358,
      "learning_rate": 6.956626506024097e-06,
      "loss": 0.02,
      "step": 108260
    },
    {
      "epoch": 13.044578313253012,
      "grad_norm": 1.0851361751556396,
      "learning_rate": 6.955421686746988e-06,
      "loss": 0.0259,
      "step": 108270
    },
    {
      "epoch": 13.04578313253012,
      "grad_norm": 0.08246373385190964,
      "learning_rate": 6.954216867469879e-06,
      "loss": 0.0017,
      "step": 108280
    },
    {
      "epoch": 13.046987951807228,
      "grad_norm": 0.8058298230171204,
      "learning_rate": 6.953012048192772e-06,
      "loss": 0.0096,
      "step": 108290
    },
    {
      "epoch": 13.048192771084338,
      "grad_norm": 0.20788973569869995,
      "learning_rate": 6.951807228915663e-06,
      "loss": 0.0111,
      "step": 108300
    },
    {
      "epoch": 13.049397590361446,
      "grad_norm": 0.0009267423884011805,
      "learning_rate": 6.950602409638555e-06,
      "loss": 0.004,
      "step": 108310
    },
    {
      "epoch": 13.050602409638554,
      "grad_norm": 0.004475126508623362,
      "learning_rate": 6.949397590361447e-06,
      "loss": 0.0053,
      "step": 108320
    },
    {
      "epoch": 13.051807228915663,
      "grad_norm": 1.6881968975067139,
      "learning_rate": 6.948192771084338e-06,
      "loss": 0.0131,
      "step": 108330
    },
    {
      "epoch": 13.053012048192771,
      "grad_norm": 0.3493417501449585,
      "learning_rate": 6.946987951807229e-06,
      "loss": 0.0126,
      "step": 108340
    },
    {
      "epoch": 13.05421686746988,
      "grad_norm": 0.012379107996821404,
      "learning_rate": 6.9457831325301205e-06,
      "loss": 0.0097,
      "step": 108350
    },
    {
      "epoch": 13.055421686746987,
      "grad_norm": 1.4023319482803345,
      "learning_rate": 6.944578313253013e-06,
      "loss": 0.0188,
      "step": 108360
    },
    {
      "epoch": 13.056626506024097,
      "grad_norm": 0.0015488234348595142,
      "learning_rate": 6.9433734939759045e-06,
      "loss": 0.0296,
      "step": 108370
    },
    {
      "epoch": 13.057831325301205,
      "grad_norm": 0.0003691917227115482,
      "learning_rate": 6.942168674698796e-06,
      "loss": 0.0155,
      "step": 108380
    },
    {
      "epoch": 13.059036144578313,
      "grad_norm": 0.3432612121105194,
      "learning_rate": 6.940963855421688e-06,
      "loss": 0.0071,
      "step": 108390
    },
    {
      "epoch": 13.060240963855422,
      "grad_norm": 0.0007900818018242717,
      "learning_rate": 6.9397590361445784e-06,
      "loss": 0.0253,
      "step": 108400
    },
    {
      "epoch": 13.06144578313253,
      "grad_norm": 0.0004262318543624133,
      "learning_rate": 6.93855421686747e-06,
      "loss": 0.0053,
      "step": 108410
    },
    {
      "epoch": 13.062650602409638,
      "grad_norm": 0.8089367747306824,
      "learning_rate": 6.937349397590362e-06,
      "loss": 0.025,
      "step": 108420
    },
    {
      "epoch": 13.063855421686746,
      "grad_norm": 1.1098318099975586,
      "learning_rate": 6.936144578313253e-06,
      "loss": 0.0602,
      "step": 108430
    },
    {
      "epoch": 13.065060240963856,
      "grad_norm": 0.011888290755450726,
      "learning_rate": 6.934939759036146e-06,
      "loss": 0.0171,
      "step": 108440
    },
    {
      "epoch": 13.066265060240964,
      "grad_norm": 2.381117820739746,
      "learning_rate": 6.933734939759037e-06,
      "loss": 0.0157,
      "step": 108450
    },
    {
      "epoch": 13.067469879518072,
      "grad_norm": 0.0026522993575781584,
      "learning_rate": 6.932530120481929e-06,
      "loss": 0.0382,
      "step": 108460
    },
    {
      "epoch": 13.068674698795181,
      "grad_norm": 0.007824649102985859,
      "learning_rate": 6.9313253012048196e-06,
      "loss": 0.0066,
      "step": 108470
    },
    {
      "epoch": 13.06987951807229,
      "grad_norm": 0.002173217013478279,
      "learning_rate": 6.930120481927711e-06,
      "loss": 0.0178,
      "step": 108480
    },
    {
      "epoch": 13.071084337349397,
      "grad_norm": 0.00024034632951952517,
      "learning_rate": 6.928915662650603e-06,
      "loss": 0.0206,
      "step": 108490
    },
    {
      "epoch": 13.072289156626505,
      "grad_norm": 1.4443840980529785,
      "learning_rate": 6.927710843373494e-06,
      "loss": 0.0144,
      "step": 108500
    },
    {
      "epoch": 13.073493975903615,
      "grad_norm": 0.0021958283614367247,
      "learning_rate": 6.926506024096387e-06,
      "loss": 0.0069,
      "step": 108510
    },
    {
      "epoch": 13.074698795180723,
      "grad_norm": 0.0016888167010620236,
      "learning_rate": 6.925301204819278e-06,
      "loss": 0.0316,
      "step": 108520
    },
    {
      "epoch": 13.07590361445783,
      "grad_norm": 0.733086884021759,
      "learning_rate": 6.924096385542169e-06,
      "loss": 0.0123,
      "step": 108530
    },
    {
      "epoch": 13.07710843373494,
      "grad_norm": 1.7861989736557007,
      "learning_rate": 6.922891566265061e-06,
      "loss": 0.0101,
      "step": 108540
    },
    {
      "epoch": 13.078313253012048,
      "grad_norm": 0.0018704560352489352,
      "learning_rate": 6.921686746987952e-06,
      "loss": 0.0209,
      "step": 108550
    },
    {
      "epoch": 13.079518072289156,
      "grad_norm": 0.3462190628051758,
      "learning_rate": 6.920481927710844e-06,
      "loss": 0.0218,
      "step": 108560
    },
    {
      "epoch": 13.080722891566266,
      "grad_norm": 0.00375851197168231,
      "learning_rate": 6.9192771084337354e-06,
      "loss": 0.0056,
      "step": 108570
    },
    {
      "epoch": 13.081927710843374,
      "grad_norm": 0.9701127409934998,
      "learning_rate": 6.918072289156626e-06,
      "loss": 0.0255,
      "step": 108580
    },
    {
      "epoch": 13.083132530120482,
      "grad_norm": 1.0989081859588623,
      "learning_rate": 6.9168674698795195e-06,
      "loss": 0.0327,
      "step": 108590
    },
    {
      "epoch": 13.08433734939759,
      "grad_norm": 1.615173101425171,
      "learning_rate": 6.91566265060241e-06,
      "loss": 0.0153,
      "step": 108600
    },
    {
      "epoch": 13.0855421686747,
      "grad_norm": 0.00196369388140738,
      "learning_rate": 6.914457831325302e-06,
      "loss": 0.0174,
      "step": 108610
    },
    {
      "epoch": 13.086746987951807,
      "grad_norm": 0.6845600008964539,
      "learning_rate": 6.913253012048193e-06,
      "loss": 0.0038,
      "step": 108620
    },
    {
      "epoch": 13.087951807228915,
      "grad_norm": 0.3071417808532715,
      "learning_rate": 6.912048192771085e-06,
      "loss": 0.04,
      "step": 108630
    },
    {
      "epoch": 13.089156626506025,
      "grad_norm": 0.4843757748603821,
      "learning_rate": 6.9108433734939766e-06,
      "loss": 0.0042,
      "step": 108640
    },
    {
      "epoch": 13.090361445783133,
      "grad_norm": 0.0032688931096345186,
      "learning_rate": 6.909638554216867e-06,
      "loss": 0.0092,
      "step": 108650
    },
    {
      "epoch": 13.09156626506024,
      "grad_norm": 0.47292304039001465,
      "learning_rate": 6.90843373493976e-06,
      "loss": 0.0253,
      "step": 108660
    },
    {
      "epoch": 13.092771084337349,
      "grad_norm": 0.006830899976193905,
      "learning_rate": 6.907228915662651e-06,
      "loss": 0.0092,
      "step": 108670
    },
    {
      "epoch": 13.093975903614458,
      "grad_norm": 0.0028127345722168684,
      "learning_rate": 6.906024096385543e-06,
      "loss": 0.0073,
      "step": 108680
    },
    {
      "epoch": 13.095180722891566,
      "grad_norm": 1.1801918745040894,
      "learning_rate": 6.9048192771084345e-06,
      "loss": 0.0393,
      "step": 108690
    },
    {
      "epoch": 13.096385542168674,
      "grad_norm": 1.8330098390579224,
      "learning_rate": 6.903614457831326e-06,
      "loss": 0.0094,
      "step": 108700
    },
    {
      "epoch": 13.097590361445784,
      "grad_norm": 1.3575698137283325,
      "learning_rate": 6.902409638554217e-06,
      "loss": 0.0665,
      "step": 108710
    },
    {
      "epoch": 13.098795180722892,
      "grad_norm": 0.0014520237455144525,
      "learning_rate": 6.901204819277108e-06,
      "loss": 0.0149,
      "step": 108720
    },
    {
      "epoch": 13.1,
      "grad_norm": 0.1721746027469635,
      "learning_rate": 6.9e-06,
      "loss": 0.0131,
      "step": 108730
    },
    {
      "epoch": 13.101204819277108,
      "grad_norm": 0.0024209506809711456,
      "learning_rate": 6.8987951807228924e-06,
      "loss": 0.029,
      "step": 108740
    },
    {
      "epoch": 13.102409638554217,
      "grad_norm": 0.0023109724279493093,
      "learning_rate": 6.897590361445784e-06,
      "loss": 0.0092,
      "step": 108750
    },
    {
      "epoch": 13.103614457831325,
      "grad_norm": 0.19225619733333588,
      "learning_rate": 6.896385542168676e-06,
      "loss": 0.0025,
      "step": 108760
    },
    {
      "epoch": 13.104819277108433,
      "grad_norm": 0.0013920250348746777,
      "learning_rate": 6.895180722891567e-06,
      "loss": 0.0086,
      "step": 108770
    },
    {
      "epoch": 13.106024096385543,
      "grad_norm": 1.7974282503128052,
      "learning_rate": 6.893975903614458e-06,
      "loss": 0.0357,
      "step": 108780
    },
    {
      "epoch": 13.10722891566265,
      "grad_norm": 0.002234268467873335,
      "learning_rate": 6.8927710843373495e-06,
      "loss": 0.0085,
      "step": 108790
    },
    {
      "epoch": 13.108433734939759,
      "grad_norm": 0.0192734282463789,
      "learning_rate": 6.891566265060241e-06,
      "loss": 0.015,
      "step": 108800
    },
    {
      "epoch": 13.109638554216868,
      "grad_norm": 0.005283663980662823,
      "learning_rate": 6.8903614457831336e-06,
      "loss": 0.0013,
      "step": 108810
    },
    {
      "epoch": 13.110843373493976,
      "grad_norm": 0.0008710020920261741,
      "learning_rate": 6.889156626506025e-06,
      "loss": 0.0084,
      "step": 108820
    },
    {
      "epoch": 13.112048192771084,
      "grad_norm": 0.0010108145652338862,
      "learning_rate": 6.887951807228917e-06,
      "loss": 0.0117,
      "step": 108830
    },
    {
      "epoch": 13.113253012048192,
      "grad_norm": 0.27859845757484436,
      "learning_rate": 6.8867469879518075e-06,
      "loss": 0.0057,
      "step": 108840
    },
    {
      "epoch": 13.114457831325302,
      "grad_norm": 0.0008328699041157961,
      "learning_rate": 6.885542168674699e-06,
      "loss": 0.0138,
      "step": 108850
    },
    {
      "epoch": 13.11566265060241,
      "grad_norm": 0.22573037445545197,
      "learning_rate": 6.884337349397591e-06,
      "loss": 0.009,
      "step": 108860
    },
    {
      "epoch": 13.116867469879518,
      "grad_norm": 0.0010448538232594728,
      "learning_rate": 6.883132530120482e-06,
      "loss": 0.0124,
      "step": 108870
    },
    {
      "epoch": 13.118072289156627,
      "grad_norm": 0.9844527244567871,
      "learning_rate": 6.881927710843374e-06,
      "loss": 0.0087,
      "step": 108880
    },
    {
      "epoch": 13.119277108433735,
      "grad_norm": 0.0033106065820902586,
      "learning_rate": 6.880722891566266e-06,
      "loss": 0.0082,
      "step": 108890
    },
    {
      "epoch": 13.120481927710843,
      "grad_norm": 2.846320629119873,
      "learning_rate": 6.879518072289158e-06,
      "loss": 0.0367,
      "step": 108900
    },
    {
      "epoch": 13.121686746987951,
      "grad_norm": 1.3395261764526367,
      "learning_rate": 6.878313253012049e-06,
      "loss": 0.0461,
      "step": 108910
    },
    {
      "epoch": 13.12289156626506,
      "grad_norm": 0.004714333917945623,
      "learning_rate": 6.87710843373494e-06,
      "loss": 0.0086,
      "step": 108920
    },
    {
      "epoch": 13.124096385542169,
      "grad_norm": 0.628781259059906,
      "learning_rate": 6.875903614457832e-06,
      "loss": 0.0241,
      "step": 108930
    },
    {
      "epoch": 13.125301204819277,
      "grad_norm": 0.0024079750292003155,
      "learning_rate": 6.874698795180723e-06,
      "loss": 0.0019,
      "step": 108940
    },
    {
      "epoch": 13.126506024096386,
      "grad_norm": 1.3608341217041016,
      "learning_rate": 6.873493975903615e-06,
      "loss": 0.0131,
      "step": 108950
    },
    {
      "epoch": 13.127710843373494,
      "grad_norm": 0.3131957948207855,
      "learning_rate": 6.872289156626507e-06,
      "loss": 0.012,
      "step": 108960
    },
    {
      "epoch": 13.128915662650602,
      "grad_norm": 0.020128149539232254,
      "learning_rate": 6.871084337349398e-06,
      "loss": 0.0311,
      "step": 108970
    },
    {
      "epoch": 13.13012048192771,
      "grad_norm": 0.6866195797920227,
      "learning_rate": 6.86987951807229e-06,
      "loss": 0.0104,
      "step": 108980
    },
    {
      "epoch": 13.13132530120482,
      "grad_norm": 1.048224687576294,
      "learning_rate": 6.868674698795181e-06,
      "loss": 0.0157,
      "step": 108990
    },
    {
      "epoch": 13.132530120481928,
      "grad_norm": 0.0031755503732711077,
      "learning_rate": 6.867469879518073e-06,
      "loss": 0.0009,
      "step": 109000
    },
    {
      "epoch": 13.133734939759035,
      "grad_norm": 0.0010218162788078189,
      "learning_rate": 6.8662650602409645e-06,
      "loss": 0.0025,
      "step": 109010
    },
    {
      "epoch": 13.134939759036145,
      "grad_norm": 0.013088668696582317,
      "learning_rate": 6.865060240963855e-06,
      "loss": 0.0223,
      "step": 109020
    },
    {
      "epoch": 13.136144578313253,
      "grad_norm": 0.0010342064779251814,
      "learning_rate": 6.863855421686747e-06,
      "loss": 0.0117,
      "step": 109030
    },
    {
      "epoch": 13.137349397590361,
      "grad_norm": 0.22164179384708405,
      "learning_rate": 6.862650602409639e-06,
      "loss": 0.0544,
      "step": 109040
    },
    {
      "epoch": 13.13855421686747,
      "grad_norm": 2.2963876724243164,
      "learning_rate": 6.861445783132531e-06,
      "loss": 0.0297,
      "step": 109050
    },
    {
      "epoch": 13.139759036144579,
      "grad_norm": 0.00306317419745028,
      "learning_rate": 6.860240963855422e-06,
      "loss": 0.0128,
      "step": 109060
    },
    {
      "epoch": 13.140963855421687,
      "grad_norm": 0.01938583515584469,
      "learning_rate": 6.859036144578314e-06,
      "loss": 0.0115,
      "step": 109070
    },
    {
      "epoch": 13.142168674698794,
      "grad_norm": 0.0022651872131973505,
      "learning_rate": 6.857831325301206e-06,
      "loss": 0.0292,
      "step": 109080
    },
    {
      "epoch": 13.143373493975904,
      "grad_norm": 0.0015431629726663232,
      "learning_rate": 6.856626506024096e-06,
      "loss": 0.0116,
      "step": 109090
    },
    {
      "epoch": 13.144578313253012,
      "grad_norm": 1.0809025764465332,
      "learning_rate": 6.855421686746988e-06,
      "loss": 0.0078,
      "step": 109100
    },
    {
      "epoch": 13.14578313253012,
      "grad_norm": 0.001662348280660808,
      "learning_rate": 6.85421686746988e-06,
      "loss": 0.0158,
      "step": 109110
    },
    {
      "epoch": 13.14698795180723,
      "grad_norm": 2.2156686782836914,
      "learning_rate": 6.853012048192772e-06,
      "loss": 0.018,
      "step": 109120
    },
    {
      "epoch": 13.148192771084338,
      "grad_norm": 0.001551194814965129,
      "learning_rate": 6.8518072289156635e-06,
      "loss": 0.0113,
      "step": 109130
    },
    {
      "epoch": 13.149397590361446,
      "grad_norm": 0.02913840115070343,
      "learning_rate": 6.850602409638555e-06,
      "loss": 0.007,
      "step": 109140
    },
    {
      "epoch": 13.150602409638553,
      "grad_norm": 9.834343910217285,
      "learning_rate": 6.849397590361446e-06,
      "loss": 0.039,
      "step": 109150
    },
    {
      "epoch": 13.151807228915663,
      "grad_norm": 0.0022542981896549463,
      "learning_rate": 6.8481927710843374e-06,
      "loss": 0.024,
      "step": 109160
    },
    {
      "epoch": 13.153012048192771,
      "grad_norm": 0.0038305462803691626,
      "learning_rate": 6.846987951807229e-06,
      "loss": 0.0062,
      "step": 109170
    },
    {
      "epoch": 13.154216867469879,
      "grad_norm": 0.0018792561022564769,
      "learning_rate": 6.845783132530121e-06,
      "loss": 0.0097,
      "step": 109180
    },
    {
      "epoch": 13.155421686746989,
      "grad_norm": 0.2615702450275421,
      "learning_rate": 6.844578313253013e-06,
      "loss": 0.0054,
      "step": 109190
    },
    {
      "epoch": 13.156626506024097,
      "grad_norm": 0.004403338301926851,
      "learning_rate": 6.843373493975905e-06,
      "loss": 0.0009,
      "step": 109200
    },
    {
      "epoch": 13.157831325301204,
      "grad_norm": 44.91637420654297,
      "learning_rate": 6.842168674698796e-06,
      "loss": 0.0447,
      "step": 109210
    },
    {
      "epoch": 13.159036144578312,
      "grad_norm": 1.1021039485931396,
      "learning_rate": 6.840963855421687e-06,
      "loss": 0.016,
      "step": 109220
    },
    {
      "epoch": 13.160240963855422,
      "grad_norm": 0.1554846316576004,
      "learning_rate": 6.8397590361445786e-06,
      "loss": 0.0072,
      "step": 109230
    },
    {
      "epoch": 13.16144578313253,
      "grad_norm": 0.005201282911002636,
      "learning_rate": 6.83855421686747e-06,
      "loss": 0.0054,
      "step": 109240
    },
    {
      "epoch": 13.162650602409638,
      "grad_norm": 7.870513439178467,
      "learning_rate": 6.837349397590362e-06,
      "loss": 0.0344,
      "step": 109250
    },
    {
      "epoch": 13.163855421686748,
      "grad_norm": 0.22940272092819214,
      "learning_rate": 6.836144578313254e-06,
      "loss": 0.0006,
      "step": 109260
    },
    {
      "epoch": 13.165060240963856,
      "grad_norm": 0.0010198148665949702,
      "learning_rate": 6.834939759036146e-06,
      "loss": 0.0489,
      "step": 109270
    },
    {
      "epoch": 13.166265060240963,
      "grad_norm": 0.15623541176319122,
      "learning_rate": 6.8337349397590365e-06,
      "loss": 0.0349,
      "step": 109280
    },
    {
      "epoch": 13.167469879518073,
      "grad_norm": 0.056113068014383316,
      "learning_rate": 6.832530120481928e-06,
      "loss": 0.0009,
      "step": 109290
    },
    {
      "epoch": 13.168674698795181,
      "grad_norm": 0.005655218381434679,
      "learning_rate": 6.83132530120482e-06,
      "loss": 0.0027,
      "step": 109300
    },
    {
      "epoch": 13.169879518072289,
      "grad_norm": 0.27787643671035767,
      "learning_rate": 6.830120481927711e-06,
      "loss": 0.0108,
      "step": 109310
    },
    {
      "epoch": 13.171084337349397,
      "grad_norm": 0.5401691198348999,
      "learning_rate": 6.828915662650603e-06,
      "loss": 0.0163,
      "step": 109320
    },
    {
      "epoch": 13.172289156626507,
      "grad_norm": 227.46389770507812,
      "learning_rate": 6.827710843373494e-06,
      "loss": 0.0192,
      "step": 109330
    },
    {
      "epoch": 13.173493975903614,
      "grad_norm": 2.47235369682312,
      "learning_rate": 6.826506024096387e-06,
      "loss": 0.0157,
      "step": 109340
    },
    {
      "epoch": 13.174698795180722,
      "grad_norm": 0.006281963083893061,
      "learning_rate": 6.825301204819278e-06,
      "loss": 0.0001,
      "step": 109350
    },
    {
      "epoch": 13.175903614457832,
      "grad_norm": 0.0013524501118808985,
      "learning_rate": 6.824096385542169e-06,
      "loss": 0.006,
      "step": 109360
    },
    {
      "epoch": 13.17710843373494,
      "grad_norm": 0.08290256559848785,
      "learning_rate": 6.822891566265061e-06,
      "loss": 0.0109,
      "step": 109370
    },
    {
      "epoch": 13.178313253012048,
      "grad_norm": 0.21785344183444977,
      "learning_rate": 6.821686746987952e-06,
      "loss": 0.0416,
      "step": 109380
    },
    {
      "epoch": 13.179518072289156,
      "grad_norm": 0.00120129669085145,
      "learning_rate": 6.820481927710844e-06,
      "loss": 0.0117,
      "step": 109390
    },
    {
      "epoch": 13.180722891566266,
      "grad_norm": 0.007129222620278597,
      "learning_rate": 6.819277108433735e-06,
      "loss": 0.0273,
      "step": 109400
    },
    {
      "epoch": 13.181927710843373,
      "grad_norm": 1.4892634153366089,
      "learning_rate": 6.818072289156627e-06,
      "loss": 0.0535,
      "step": 109410
    },
    {
      "epoch": 13.183132530120481,
      "grad_norm": 0.3626127541065216,
      "learning_rate": 6.816867469879519e-06,
      "loss": 0.0013,
      "step": 109420
    },
    {
      "epoch": 13.184337349397591,
      "grad_norm": 0.9735202789306641,
      "learning_rate": 6.81566265060241e-06,
      "loss": 0.0114,
      "step": 109430
    },
    {
      "epoch": 13.185542168674699,
      "grad_norm": 0.0016070468118414283,
      "learning_rate": 6.814457831325302e-06,
      "loss": 0.0199,
      "step": 109440
    },
    {
      "epoch": 13.186746987951807,
      "grad_norm": 0.005722723435610533,
      "learning_rate": 6.8132530120481935e-06,
      "loss": 0.0528,
      "step": 109450
    },
    {
      "epoch": 13.187951807228915,
      "grad_norm": 0.012543984688818455,
      "learning_rate": 6.812048192771084e-06,
      "loss": 0.0055,
      "step": 109460
    },
    {
      "epoch": 13.189156626506024,
      "grad_norm": 1.0408281087875366,
      "learning_rate": 6.810843373493976e-06,
      "loss": 0.0458,
      "step": 109470
    },
    {
      "epoch": 13.190361445783132,
      "grad_norm": 0.22670388221740723,
      "learning_rate": 6.809638554216867e-06,
      "loss": 0.0245,
      "step": 109480
    },
    {
      "epoch": 13.19156626506024,
      "grad_norm": 0.0029267214704304934,
      "learning_rate": 6.80843373493976e-06,
      "loss": 0.0017,
      "step": 109490
    },
    {
      "epoch": 13.19277108433735,
      "grad_norm": 0.10920915752649307,
      "learning_rate": 6.8072289156626514e-06,
      "loss": 0.0396,
      "step": 109500
    },
    {
      "epoch": 13.193975903614458,
      "grad_norm": 0.00287934229709208,
      "learning_rate": 6.806024096385543e-06,
      "loss": 0.0243,
      "step": 109510
    },
    {
      "epoch": 13.195180722891566,
      "grad_norm": 4.429975986480713,
      "learning_rate": 6.804819277108435e-06,
      "loss": 0.016,
      "step": 109520
    },
    {
      "epoch": 13.196385542168676,
      "grad_norm": 0.017297938466072083,
      "learning_rate": 6.803614457831325e-06,
      "loss": 0.0155,
      "step": 109530
    },
    {
      "epoch": 13.197590361445783,
      "grad_norm": 0.018366467207670212,
      "learning_rate": 6.802409638554217e-06,
      "loss": 0.0021,
      "step": 109540
    },
    {
      "epoch": 13.198795180722891,
      "grad_norm": 4.019778251647949,
      "learning_rate": 6.8012048192771085e-06,
      "loss": 0.0152,
      "step": 109550
    },
    {
      "epoch": 13.2,
      "grad_norm": 0.015782462432980537,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0145,
      "step": 109560
    },
    {
      "epoch": 13.201204819277109,
      "grad_norm": 3.2439186573028564,
      "learning_rate": 6.7987951807228926e-06,
      "loss": 0.0305,
      "step": 109570
    },
    {
      "epoch": 13.202409638554217,
      "grad_norm": 0.0011635975679382682,
      "learning_rate": 6.797590361445784e-06,
      "loss": 0.0128,
      "step": 109580
    },
    {
      "epoch": 13.203614457831325,
      "grad_norm": 0.00255667045712471,
      "learning_rate": 6.796385542168675e-06,
      "loss": 0.0186,
      "step": 109590
    },
    {
      "epoch": 13.204819277108435,
      "grad_norm": 1.6600890159606934,
      "learning_rate": 6.7951807228915665e-06,
      "loss": 0.0104,
      "step": 109600
    },
    {
      "epoch": 13.206024096385542,
      "grad_norm": 0.014257779344916344,
      "learning_rate": 6.793975903614458e-06,
      "loss": 0.0242,
      "step": 109610
    },
    {
      "epoch": 13.20722891566265,
      "grad_norm": 0.1124996766448021,
      "learning_rate": 6.79277108433735e-06,
      "loss": 0.0211,
      "step": 109620
    },
    {
      "epoch": 13.208433734939758,
      "grad_norm": 0.22004960477352142,
      "learning_rate": 6.791566265060241e-06,
      "loss": 0.0072,
      "step": 109630
    },
    {
      "epoch": 13.209638554216868,
      "grad_norm": 0.0034074499271810055,
      "learning_rate": 6.790361445783134e-06,
      "loss": 0.0196,
      "step": 109640
    },
    {
      "epoch": 13.210843373493976,
      "grad_norm": 2.220381259918213,
      "learning_rate": 6.789156626506025e-06,
      "loss": 0.0119,
      "step": 109650
    },
    {
      "epoch": 13.212048192771084,
      "grad_norm": 0.9914575815200806,
      "learning_rate": 6.787951807228916e-06,
      "loss": 0.0077,
      "step": 109660
    },
    {
      "epoch": 13.213253012048193,
      "grad_norm": 0.8067777156829834,
      "learning_rate": 6.786746987951808e-06,
      "loss": 0.011,
      "step": 109670
    },
    {
      "epoch": 13.214457831325301,
      "grad_norm": 0.003559666685760021,
      "learning_rate": 6.785542168674699e-06,
      "loss": 0.0402,
      "step": 109680
    },
    {
      "epoch": 13.21566265060241,
      "grad_norm": 0.007835783064365387,
      "learning_rate": 6.784337349397591e-06,
      "loss": 0.0208,
      "step": 109690
    },
    {
      "epoch": 13.216867469879517,
      "grad_norm": 0.001979548018425703,
      "learning_rate": 6.783132530120482e-06,
      "loss": 0.0051,
      "step": 109700
    },
    {
      "epoch": 13.218072289156627,
      "grad_norm": 0.0016207518056035042,
      "learning_rate": 6.781927710843375e-06,
      "loss": 0.0167,
      "step": 109710
    },
    {
      "epoch": 13.219277108433735,
      "grad_norm": 1.1000641584396362,
      "learning_rate": 6.780722891566266e-06,
      "loss": 0.0473,
      "step": 109720
    },
    {
      "epoch": 13.220481927710843,
      "grad_norm": 0.008843881078064442,
      "learning_rate": 6.779518072289157e-06,
      "loss": 0.0368,
      "step": 109730
    },
    {
      "epoch": 13.221686746987952,
      "grad_norm": 3.5381619930267334,
      "learning_rate": 6.778313253012049e-06,
      "loss": 0.0402,
      "step": 109740
    },
    {
      "epoch": 13.22289156626506,
      "grad_norm": 0.8871033787727356,
      "learning_rate": 6.77710843373494e-06,
      "loss": 0.0179,
      "step": 109750
    },
    {
      "epoch": 13.224096385542168,
      "grad_norm": 0.15859609842300415,
      "learning_rate": 6.775903614457832e-06,
      "loss": 0.0179,
      "step": 109760
    },
    {
      "epoch": 13.225301204819278,
      "grad_norm": 0.1850469410419464,
      "learning_rate": 6.7746987951807235e-06,
      "loss": 0.0176,
      "step": 109770
    },
    {
      "epoch": 13.226506024096386,
      "grad_norm": 0.048699647188186646,
      "learning_rate": 6.773493975903614e-06,
      "loss": 0.0266,
      "step": 109780
    },
    {
      "epoch": 13.227710843373494,
      "grad_norm": 0.26193761825561523,
      "learning_rate": 6.772289156626507e-06,
      "loss": 0.0351,
      "step": 109790
    },
    {
      "epoch": 13.228915662650602,
      "grad_norm": 0.029440654441714287,
      "learning_rate": 6.771084337349398e-06,
      "loss": 0.0153,
      "step": 109800
    },
    {
      "epoch": 13.230120481927711,
      "grad_norm": 0.012014070525765419,
      "learning_rate": 6.76987951807229e-06,
      "loss": 0.0012,
      "step": 109810
    },
    {
      "epoch": 13.23132530120482,
      "grad_norm": 0.7705669403076172,
      "learning_rate": 6.768674698795181e-06,
      "loss": 0.0236,
      "step": 109820
    },
    {
      "epoch": 13.232530120481927,
      "grad_norm": 0.0015646194806322455,
      "learning_rate": 6.767469879518073e-06,
      "loss": 0.0101,
      "step": 109830
    },
    {
      "epoch": 13.233734939759037,
      "grad_norm": 0.001582848490215838,
      "learning_rate": 6.766265060240964e-06,
      "loss": 0.0023,
      "step": 109840
    },
    {
      "epoch": 13.234939759036145,
      "grad_norm": 0.002393938135355711,
      "learning_rate": 6.765060240963855e-06,
      "loss": 0.0212,
      "step": 109850
    },
    {
      "epoch": 13.236144578313253,
      "grad_norm": 0.006589244585484266,
      "learning_rate": 6.763855421686748e-06,
      "loss": 0.0442,
      "step": 109860
    },
    {
      "epoch": 13.23734939759036,
      "grad_norm": 2.0851311683654785,
      "learning_rate": 6.762650602409639e-06,
      "loss": 0.0154,
      "step": 109870
    },
    {
      "epoch": 13.23855421686747,
      "grad_norm": 0.0018818271346390247,
      "learning_rate": 6.761445783132531e-06,
      "loss": 0.0037,
      "step": 109880
    },
    {
      "epoch": 13.239759036144578,
      "grad_norm": 0.0020175473764538765,
      "learning_rate": 6.7602409638554225e-06,
      "loss": 0.0232,
      "step": 109890
    },
    {
      "epoch": 13.240963855421686,
      "grad_norm": 0.22097820043563843,
      "learning_rate": 6.759036144578314e-06,
      "loss": 0.012,
      "step": 109900
    },
    {
      "epoch": 13.242168674698796,
      "grad_norm": 0.0032278166618198156,
      "learning_rate": 6.757831325301205e-06,
      "loss": 0.0042,
      "step": 109910
    },
    {
      "epoch": 13.243373493975904,
      "grad_norm": 0.0146839814260602,
      "learning_rate": 6.7566265060240964e-06,
      "loss": 0.0329,
      "step": 109920
    },
    {
      "epoch": 13.244578313253012,
      "grad_norm": 0.08328816294670105,
      "learning_rate": 6.755421686746988e-06,
      "loss": 0.0039,
      "step": 109930
    },
    {
      "epoch": 13.24578313253012,
      "grad_norm": 0.13576291501522064,
      "learning_rate": 6.7542168674698805e-06,
      "loss": 0.0187,
      "step": 109940
    },
    {
      "epoch": 13.24698795180723,
      "grad_norm": 0.00030169638921506703,
      "learning_rate": 6.753012048192772e-06,
      "loss": 0.0219,
      "step": 109950
    },
    {
      "epoch": 13.248192771084337,
      "grad_norm": 0.0008024583803489804,
      "learning_rate": 6.751807228915664e-06,
      "loss": 0.0369,
      "step": 109960
    },
    {
      "epoch": 13.249397590361445,
      "grad_norm": 0.0015546218492090702,
      "learning_rate": 6.750602409638554e-06,
      "loss": 0.0223,
      "step": 109970
    },
    {
      "epoch": 13.250602409638555,
      "grad_norm": 0.0008560990099795163,
      "learning_rate": 6.749397590361446e-06,
      "loss": 0.0014,
      "step": 109980
    },
    {
      "epoch": 13.251807228915663,
      "grad_norm": 1.2355366945266724,
      "learning_rate": 6.7481927710843376e-06,
      "loss": 0.0447,
      "step": 109990
    },
    {
      "epoch": 13.25301204819277,
      "grad_norm": 0.3136654198169708,
      "learning_rate": 6.746987951807229e-06,
      "loss": 0.0152,
      "step": 110000
    },
    {
      "epoch": 13.25421686746988,
      "grad_norm": 0.0368785560131073,
      "learning_rate": 6.7457831325301216e-06,
      "loss": 0.0182,
      "step": 110010
    },
    {
      "epoch": 13.255421686746988,
      "grad_norm": 0.2822965383529663,
      "learning_rate": 6.744578313253013e-06,
      "loss": 0.0514,
      "step": 110020
    },
    {
      "epoch": 13.256626506024096,
      "grad_norm": 0.0021029189229011536,
      "learning_rate": 6.743373493975905e-06,
      "loss": 0.0011,
      "step": 110030
    },
    {
      "epoch": 13.257831325301204,
      "grad_norm": 0.0006264580297283828,
      "learning_rate": 6.7421686746987955e-06,
      "loss": 0.0048,
      "step": 110040
    },
    {
      "epoch": 13.259036144578314,
      "grad_norm": 0.0008501544361934066,
      "learning_rate": 6.740963855421687e-06,
      "loss": 0.0072,
      "step": 110050
    },
    {
      "epoch": 13.260240963855422,
      "grad_norm": 1.345909595489502,
      "learning_rate": 6.739759036144579e-06,
      "loss": 0.0396,
      "step": 110060
    },
    {
      "epoch": 13.26144578313253,
      "grad_norm": 0.0171340499073267,
      "learning_rate": 6.73855421686747e-06,
      "loss": 0.0062,
      "step": 110070
    },
    {
      "epoch": 13.26265060240964,
      "grad_norm": 0.9994737505912781,
      "learning_rate": 6.737349397590363e-06,
      "loss": 0.0125,
      "step": 110080
    },
    {
      "epoch": 13.263855421686747,
      "grad_norm": 0.0006025925395078957,
      "learning_rate": 6.736144578313254e-06,
      "loss": 0.0045,
      "step": 110090
    },
    {
      "epoch": 13.265060240963855,
      "grad_norm": 3.775575876235962,
      "learning_rate": 6.734939759036145e-06,
      "loss": 0.0319,
      "step": 110100
    },
    {
      "epoch": 13.266265060240963,
      "grad_norm": 0.006305678281933069,
      "learning_rate": 6.733734939759037e-06,
      "loss": 0.0197,
      "step": 110110
    },
    {
      "epoch": 13.267469879518073,
      "grad_norm": 0.012289891019463539,
      "learning_rate": 6.732530120481928e-06,
      "loss": 0.0051,
      "step": 110120
    },
    {
      "epoch": 13.26867469879518,
      "grad_norm": 0.005085743498057127,
      "learning_rate": 6.73132530120482e-06,
      "loss": 0.0307,
      "step": 110130
    },
    {
      "epoch": 13.269879518072289,
      "grad_norm": 1.5243804454803467,
      "learning_rate": 6.730120481927711e-06,
      "loss": 0.0219,
      "step": 110140
    },
    {
      "epoch": 13.271084337349398,
      "grad_norm": 0.051722247153520584,
      "learning_rate": 6.728915662650602e-06,
      "loss": 0.0127,
      "step": 110150
    },
    {
      "epoch": 13.272289156626506,
      "grad_norm": 0.0006553267012350261,
      "learning_rate": 6.727710843373495e-06,
      "loss": 0.0045,
      "step": 110160
    },
    {
      "epoch": 13.273493975903614,
      "grad_norm": 0.00045410709572024643,
      "learning_rate": 6.726506024096386e-06,
      "loss": 0.0646,
      "step": 110170
    },
    {
      "epoch": 13.274698795180722,
      "grad_norm": 1.5883920192718506,
      "learning_rate": 6.725301204819278e-06,
      "loss": 0.0212,
      "step": 110180
    },
    {
      "epoch": 13.275903614457832,
      "grad_norm": 0.0036623901687562466,
      "learning_rate": 6.724096385542169e-06,
      "loss": 0.0252,
      "step": 110190
    },
    {
      "epoch": 13.27710843373494,
      "grad_norm": 0.28753432631492615,
      "learning_rate": 6.722891566265061e-06,
      "loss": 0.0147,
      "step": 110200
    },
    {
      "epoch": 13.278313253012048,
      "grad_norm": 0.9428436160087585,
      "learning_rate": 6.7216867469879525e-06,
      "loss": 0.0313,
      "step": 110210
    },
    {
      "epoch": 13.279518072289157,
      "grad_norm": 4.647494316101074,
      "learning_rate": 6.720481927710843e-06,
      "loss": 0.0087,
      "step": 110220
    },
    {
      "epoch": 13.280722891566265,
      "grad_norm": 0.0007948056445457041,
      "learning_rate": 6.719277108433736e-06,
      "loss": 0.011,
      "step": 110230
    },
    {
      "epoch": 13.281927710843373,
      "grad_norm": 0.003145551774650812,
      "learning_rate": 6.718072289156627e-06,
      "loss": 0.0292,
      "step": 110240
    },
    {
      "epoch": 13.283132530120483,
      "grad_norm": 0.0008119633421301842,
      "learning_rate": 6.716867469879519e-06,
      "loss": 0.006,
      "step": 110250
    },
    {
      "epoch": 13.28433734939759,
      "grad_norm": 0.000821052526589483,
      "learning_rate": 6.7156626506024104e-06,
      "loss": 0.0035,
      "step": 110260
    },
    {
      "epoch": 13.285542168674699,
      "grad_norm": 1.1017003059387207,
      "learning_rate": 6.714457831325302e-06,
      "loss": 0.0235,
      "step": 110270
    },
    {
      "epoch": 13.286746987951807,
      "grad_norm": 1.289417028427124,
      "learning_rate": 6.713253012048193e-06,
      "loss": 0.014,
      "step": 110280
    },
    {
      "epoch": 13.287951807228916,
      "grad_norm": 0.0009619260090403259,
      "learning_rate": 6.712048192771084e-06,
      "loss": 0.0,
      "step": 110290
    },
    {
      "epoch": 13.289156626506024,
      "grad_norm": 0.712619423866272,
      "learning_rate": 6.710843373493976e-06,
      "loss": 0.0047,
      "step": 110300
    },
    {
      "epoch": 13.290361445783132,
      "grad_norm": 0.0007137073553167284,
      "learning_rate": 6.709638554216868e-06,
      "loss": 0.0207,
      "step": 110310
    },
    {
      "epoch": 13.291566265060242,
      "grad_norm": 0.44203880429267883,
      "learning_rate": 6.70843373493976e-06,
      "loss": 0.0362,
      "step": 110320
    },
    {
      "epoch": 13.29277108433735,
      "grad_norm": 0.007195006124675274,
      "learning_rate": 6.7072289156626515e-06,
      "loss": 0.0056,
      "step": 110330
    },
    {
      "epoch": 13.293975903614458,
      "grad_norm": 0.210832878947258,
      "learning_rate": 6.706024096385543e-06,
      "loss": 0.0128,
      "step": 110340
    },
    {
      "epoch": 13.295180722891565,
      "grad_norm": 0.002763882279396057,
      "learning_rate": 6.704819277108434e-06,
      "loss": 0.0108,
      "step": 110350
    },
    {
      "epoch": 13.296385542168675,
      "grad_norm": 0.0022864362690597773,
      "learning_rate": 6.7036144578313255e-06,
      "loss": 0.0031,
      "step": 110360
    },
    {
      "epoch": 13.297590361445783,
      "grad_norm": 0.006685219239443541,
      "learning_rate": 6.702409638554217e-06,
      "loss": 0.0022,
      "step": 110370
    },
    {
      "epoch": 13.298795180722891,
      "grad_norm": 0.001780227874405682,
      "learning_rate": 6.7012048192771095e-06,
      "loss": 0.0236,
      "step": 110380
    },
    {
      "epoch": 13.3,
      "grad_norm": 1.0831066370010376,
      "learning_rate": 6.700000000000001e-06,
      "loss": 0.0209,
      "step": 110390
    },
    {
      "epoch": 13.301204819277109,
      "grad_norm": 0.21316662430763245,
      "learning_rate": 6.698795180722893e-06,
      "loss": 0.0177,
      "step": 110400
    },
    {
      "epoch": 13.302409638554217,
      "grad_norm": 0.0012118082959204912,
      "learning_rate": 6.697590361445783e-06,
      "loss": 0.0293,
      "step": 110410
    },
    {
      "epoch": 13.303614457831324,
      "grad_norm": 0.7914226055145264,
      "learning_rate": 6.696385542168675e-06,
      "loss": 0.0106,
      "step": 110420
    },
    {
      "epoch": 13.304819277108434,
      "grad_norm": 0.0011848399881273508,
      "learning_rate": 6.695180722891567e-06,
      "loss": 0.0115,
      "step": 110430
    },
    {
      "epoch": 13.306024096385542,
      "grad_norm": 0.0029272756073623896,
      "learning_rate": 6.693975903614458e-06,
      "loss": 0.0335,
      "step": 110440
    },
    {
      "epoch": 13.30722891566265,
      "grad_norm": 0.8701831102371216,
      "learning_rate": 6.69277108433735e-06,
      "loss": 0.0182,
      "step": 110450
    },
    {
      "epoch": 13.30843373493976,
      "grad_norm": 0.8381735682487488,
      "learning_rate": 6.691566265060242e-06,
      "loss": 0.0159,
      "step": 110460
    },
    {
      "epoch": 13.309638554216868,
      "grad_norm": 0.0017670447705313563,
      "learning_rate": 6.690361445783134e-06,
      "loss": 0.0097,
      "step": 110470
    },
    {
      "epoch": 13.310843373493976,
      "grad_norm": 0.0011167057091370225,
      "learning_rate": 6.6891566265060245e-06,
      "loss": 0.0031,
      "step": 110480
    },
    {
      "epoch": 13.312048192771085,
      "grad_norm": 0.000667873362544924,
      "learning_rate": 6.687951807228916e-06,
      "loss": 0.0171,
      "step": 110490
    },
    {
      "epoch": 13.313253012048193,
      "grad_norm": 0.005354885943233967,
      "learning_rate": 6.686746987951808e-06,
      "loss": 0.005,
      "step": 110500
    },
    {
      "epoch": 13.314457831325301,
      "grad_norm": 0.016212522983551025,
      "learning_rate": 6.685542168674699e-06,
      "loss": 0.0145,
      "step": 110510
    },
    {
      "epoch": 13.315662650602409,
      "grad_norm": 0.02350224368274212,
      "learning_rate": 6.684337349397591e-06,
      "loss": 0.0052,
      "step": 110520
    },
    {
      "epoch": 13.316867469879519,
      "grad_norm": 0.009436793625354767,
      "learning_rate": 6.683132530120483e-06,
      "loss": 0.0163,
      "step": 110530
    },
    {
      "epoch": 13.318072289156627,
      "grad_norm": 0.3504285514354706,
      "learning_rate": 6.681927710843374e-06,
      "loss": 0.0041,
      "step": 110540
    },
    {
      "epoch": 13.319277108433734,
      "grad_norm": 1.335305094718933,
      "learning_rate": 6.680722891566266e-06,
      "loss": 0.0157,
      "step": 110550
    },
    {
      "epoch": 13.320481927710844,
      "grad_norm": 0.00044213063665665686,
      "learning_rate": 6.679518072289157e-06,
      "loss": 0.0014,
      "step": 110560
    },
    {
      "epoch": 13.321686746987952,
      "grad_norm": 6.5755462646484375,
      "learning_rate": 6.678313253012049e-06,
      "loss": 0.0175,
      "step": 110570
    },
    {
      "epoch": 13.32289156626506,
      "grad_norm": 0.0054314834997057915,
      "learning_rate": 6.67710843373494e-06,
      "loss": 0.0037,
      "step": 110580
    },
    {
      "epoch": 13.324096385542168,
      "grad_norm": 0.0913650244474411,
      "learning_rate": 6.675903614457831e-06,
      "loss": 0.0102,
      "step": 110590
    },
    {
      "epoch": 13.325301204819278,
      "grad_norm": 0.001415653619915247,
      "learning_rate": 6.674698795180723e-06,
      "loss": 0.0196,
      "step": 110600
    },
    {
      "epoch": 13.326506024096386,
      "grad_norm": 0.7444522380828857,
      "learning_rate": 6.673493975903615e-06,
      "loss": 0.002,
      "step": 110610
    },
    {
      "epoch": 13.327710843373493,
      "grad_norm": 0.0006877246778458357,
      "learning_rate": 6.672289156626507e-06,
      "loss": 0.0017,
      "step": 110620
    },
    {
      "epoch": 13.328915662650603,
      "grad_norm": 1.7714998722076416,
      "learning_rate": 6.671084337349398e-06,
      "loss": 0.009,
      "step": 110630
    },
    {
      "epoch": 13.330120481927711,
      "grad_norm": 0.5688761472702026,
      "learning_rate": 6.66987951807229e-06,
      "loss": 0.0137,
      "step": 110640
    },
    {
      "epoch": 13.331325301204819,
      "grad_norm": 0.0007842196500860155,
      "learning_rate": 6.6686746987951815e-06,
      "loss": 0.0208,
      "step": 110650
    },
    {
      "epoch": 13.332530120481927,
      "grad_norm": 4.916288375854492,
      "learning_rate": 6.667469879518072e-06,
      "loss": 0.0591,
      "step": 110660
    },
    {
      "epoch": 13.333734939759037,
      "grad_norm": 0.7290215492248535,
      "learning_rate": 6.666265060240964e-06,
      "loss": 0.0432,
      "step": 110670
    },
    {
      "epoch": 13.334939759036144,
      "grad_norm": 0.34867289662361145,
      "learning_rate": 6.665060240963856e-06,
      "loss": 0.0055,
      "step": 110680
    },
    {
      "epoch": 13.336144578313252,
      "grad_norm": 0.3315731883049011,
      "learning_rate": 6.663855421686748e-06,
      "loss": 0.007,
      "step": 110690
    },
    {
      "epoch": 13.337349397590362,
      "grad_norm": 0.0010275918757542968,
      "learning_rate": 6.6626506024096395e-06,
      "loss": 0.0286,
      "step": 110700
    },
    {
      "epoch": 13.33855421686747,
      "grad_norm": 1.053385615348816,
      "learning_rate": 6.661445783132531e-06,
      "loss": 0.0136,
      "step": 110710
    },
    {
      "epoch": 13.339759036144578,
      "grad_norm": 10.344778060913086,
      "learning_rate": 6.660240963855422e-06,
      "loss": 0.0406,
      "step": 110720
    },
    {
      "epoch": 13.340963855421688,
      "grad_norm": 0.012009830214083195,
      "learning_rate": 6.659036144578313e-06,
      "loss": 0.0084,
      "step": 110730
    },
    {
      "epoch": 13.342168674698796,
      "grad_norm": 0.01953173242509365,
      "learning_rate": 6.657831325301205e-06,
      "loss": 0.0033,
      "step": 110740
    },
    {
      "epoch": 13.343373493975903,
      "grad_norm": 0.02174963243305683,
      "learning_rate": 6.6566265060240965e-06,
      "loss": 0.0048,
      "step": 110750
    },
    {
      "epoch": 13.344578313253011,
      "grad_norm": 0.00143332255538553,
      "learning_rate": 6.655421686746989e-06,
      "loss": 0.0165,
      "step": 110760
    },
    {
      "epoch": 13.345783132530121,
      "grad_norm": 0.023004459217190742,
      "learning_rate": 6.6542168674698806e-06,
      "loss": 0.0432,
      "step": 110770
    },
    {
      "epoch": 13.346987951807229,
      "grad_norm": 0.7876467108726501,
      "learning_rate": 6.653012048192772e-06,
      "loss": 0.0187,
      "step": 110780
    },
    {
      "epoch": 13.348192771084337,
      "grad_norm": 0.005950655788183212,
      "learning_rate": 6.651807228915663e-06,
      "loss": 0.041,
      "step": 110790
    },
    {
      "epoch": 13.349397590361447,
      "grad_norm": 1.0828626155853271,
      "learning_rate": 6.6506024096385545e-06,
      "loss": 0.0182,
      "step": 110800
    },
    {
      "epoch": 13.350602409638554,
      "grad_norm": 14.89846420288086,
      "learning_rate": 6.649397590361446e-06,
      "loss": 0.0761,
      "step": 110810
    },
    {
      "epoch": 13.351807228915662,
      "grad_norm": 0.002515435218811035,
      "learning_rate": 6.648192771084338e-06,
      "loss": 0.0091,
      "step": 110820
    },
    {
      "epoch": 13.35301204819277,
      "grad_norm": 0.004566090647131205,
      "learning_rate": 6.64698795180723e-06,
      "loss": 0.0228,
      "step": 110830
    },
    {
      "epoch": 13.35421686746988,
      "grad_norm": 0.06904753297567368,
      "learning_rate": 6.645783132530122e-06,
      "loss": 0.0005,
      "step": 110840
    },
    {
      "epoch": 13.355421686746988,
      "grad_norm": 0.544592022895813,
      "learning_rate": 6.6445783132530124e-06,
      "loss": 0.0184,
      "step": 110850
    },
    {
      "epoch": 13.356626506024096,
      "grad_norm": 0.011986857280135155,
      "learning_rate": 6.643373493975904e-06,
      "loss": 0.0213,
      "step": 110860
    },
    {
      "epoch": 13.357831325301206,
      "grad_norm": 1.2502312660217285,
      "learning_rate": 6.642168674698796e-06,
      "loss": 0.0119,
      "step": 110870
    },
    {
      "epoch": 13.359036144578313,
      "grad_norm": 0.0014388045528903604,
      "learning_rate": 6.640963855421687e-06,
      "loss": 0.0007,
      "step": 110880
    },
    {
      "epoch": 13.360240963855421,
      "grad_norm": 0.011209841817617416,
      "learning_rate": 6.639759036144579e-06,
      "loss": 0.0079,
      "step": 110890
    },
    {
      "epoch": 13.36144578313253,
      "grad_norm": 0.0077739981934428215,
      "learning_rate": 6.6385542168674695e-06,
      "loss": 0.0323,
      "step": 110900
    },
    {
      "epoch": 13.362650602409639,
      "grad_norm": 0.003239658661186695,
      "learning_rate": 6.637349397590363e-06,
      "loss": 0.0267,
      "step": 110910
    },
    {
      "epoch": 13.363855421686747,
      "grad_norm": 1.6273733377456665,
      "learning_rate": 6.6361445783132535e-06,
      "loss": 0.0195,
      "step": 110920
    },
    {
      "epoch": 13.365060240963855,
      "grad_norm": 0.643286943435669,
      "learning_rate": 6.634939759036145e-06,
      "loss": 0.0208,
      "step": 110930
    },
    {
      "epoch": 13.366265060240965,
      "grad_norm": 0.5556379556655884,
      "learning_rate": 6.633734939759037e-06,
      "loss": 0.0223,
      "step": 110940
    },
    {
      "epoch": 13.367469879518072,
      "grad_norm": 0.0035779878962785006,
      "learning_rate": 6.632530120481928e-06,
      "loss": 0.0134,
      "step": 110950
    },
    {
      "epoch": 13.36867469879518,
      "grad_norm": 0.589474618434906,
      "learning_rate": 6.63132530120482e-06,
      "loss": 0.0107,
      "step": 110960
    },
    {
      "epoch": 13.369879518072288,
      "grad_norm": 0.006532267667353153,
      "learning_rate": 6.630120481927711e-06,
      "loss": 0.0299,
      "step": 110970
    },
    {
      "epoch": 13.371084337349398,
      "grad_norm": 0.4114707410335541,
      "learning_rate": 6.628915662650603e-06,
      "loss": 0.0088,
      "step": 110980
    },
    {
      "epoch": 13.372289156626506,
      "grad_norm": 0.020826956257224083,
      "learning_rate": 6.627710843373495e-06,
      "loss": 0.0189,
      "step": 110990
    },
    {
      "epoch": 13.373493975903614,
      "grad_norm": 0.7895480394363403,
      "learning_rate": 6.626506024096386e-06,
      "loss": 0.0203,
      "step": 111000
    },
    {
      "epoch": 13.374698795180723,
      "grad_norm": 0.02008184790611267,
      "learning_rate": 6.625301204819278e-06,
      "loss": 0.014,
      "step": 111010
    },
    {
      "epoch": 13.375903614457831,
      "grad_norm": 0.002854555379599333,
      "learning_rate": 6.6240963855421694e-06,
      "loss": 0.0392,
      "step": 111020
    },
    {
      "epoch": 13.37710843373494,
      "grad_norm": 0.0008075644145719707,
      "learning_rate": 6.62289156626506e-06,
      "loss": 0.0058,
      "step": 111030
    },
    {
      "epoch": 13.378313253012049,
      "grad_norm": 0.33874571323394775,
      "learning_rate": 6.621686746987952e-06,
      "loss": 0.0487,
      "step": 111040
    },
    {
      "epoch": 13.379518072289157,
      "grad_norm": 0.002286993432790041,
      "learning_rate": 6.620481927710843e-06,
      "loss": 0.0065,
      "step": 111050
    },
    {
      "epoch": 13.380722891566265,
      "grad_norm": 0.022773955017328262,
      "learning_rate": 6.619277108433736e-06,
      "loss": 0.0215,
      "step": 111060
    },
    {
      "epoch": 13.381927710843373,
      "grad_norm": 0.009317812509834766,
      "learning_rate": 6.618072289156627e-06,
      "loss": 0.0764,
      "step": 111070
    },
    {
      "epoch": 13.383132530120482,
      "grad_norm": 0.003908502869307995,
      "learning_rate": 6.616867469879519e-06,
      "loss": 0.0217,
      "step": 111080
    },
    {
      "epoch": 13.38433734939759,
      "grad_norm": 0.7494421005249023,
      "learning_rate": 6.6156626506024105e-06,
      "loss": 0.0079,
      "step": 111090
    },
    {
      "epoch": 13.385542168674698,
      "grad_norm": 1.9813835620880127,
      "learning_rate": 6.614457831325301e-06,
      "loss": 0.0324,
      "step": 111100
    },
    {
      "epoch": 13.386746987951808,
      "grad_norm": 0.09241016209125519,
      "learning_rate": 6.613253012048193e-06,
      "loss": 0.0316,
      "step": 111110
    },
    {
      "epoch": 13.387951807228916,
      "grad_norm": 0.0006679114885628223,
      "learning_rate": 6.6120481927710845e-06,
      "loss": 0.0129,
      "step": 111120
    },
    {
      "epoch": 13.389156626506024,
      "grad_norm": 0.0012050512013956904,
      "learning_rate": 6.610843373493977e-06,
      "loss": 0.0095,
      "step": 111130
    },
    {
      "epoch": 13.390361445783132,
      "grad_norm": 7.021185874938965,
      "learning_rate": 6.6096385542168685e-06,
      "loss": 0.0903,
      "step": 111140
    },
    {
      "epoch": 13.391566265060241,
      "grad_norm": 0.007614376489073038,
      "learning_rate": 6.60843373493976e-06,
      "loss": 0.0115,
      "step": 111150
    },
    {
      "epoch": 13.39277108433735,
      "grad_norm": 0.003042450174689293,
      "learning_rate": 6.607228915662652e-06,
      "loss": 0.0073,
      "step": 111160
    },
    {
      "epoch": 13.393975903614457,
      "grad_norm": 0.0036636670120060444,
      "learning_rate": 6.606024096385542e-06,
      "loss": 0.0028,
      "step": 111170
    },
    {
      "epoch": 13.395180722891567,
      "grad_norm": 0.019370179623365402,
      "learning_rate": 6.604819277108434e-06,
      "loss": 0.0073,
      "step": 111180
    },
    {
      "epoch": 13.396385542168675,
      "grad_norm": 0.8383128643035889,
      "learning_rate": 6.6036144578313256e-06,
      "loss": 0.0047,
      "step": 111190
    },
    {
      "epoch": 13.397590361445783,
      "grad_norm": 0.001595677575096488,
      "learning_rate": 6.602409638554217e-06,
      "loss": 0.0232,
      "step": 111200
    },
    {
      "epoch": 13.398795180722892,
      "grad_norm": 0.001645389012992382,
      "learning_rate": 6.60120481927711e-06,
      "loss": 0.0333,
      "step": 111210
    },
    {
      "epoch": 13.4,
      "grad_norm": 1.4651707410812378,
      "learning_rate": 6.600000000000001e-06,
      "loss": 0.0468,
      "step": 111220
    },
    {
      "epoch": 13.401204819277108,
      "grad_norm": 0.002352431882172823,
      "learning_rate": 6.598795180722892e-06,
      "loss": 0.0306,
      "step": 111230
    },
    {
      "epoch": 13.402409638554216,
      "grad_norm": 0.0013091842411085963,
      "learning_rate": 6.5975903614457835e-06,
      "loss": 0.0176,
      "step": 111240
    },
    {
      "epoch": 13.403614457831326,
      "grad_norm": 0.3634030818939209,
      "learning_rate": 6.596385542168675e-06,
      "loss": 0.0122,
      "step": 111250
    },
    {
      "epoch": 13.404819277108434,
      "grad_norm": 0.005402819719165564,
      "learning_rate": 6.595180722891567e-06,
      "loss": 0.0015,
      "step": 111260
    },
    {
      "epoch": 13.406024096385542,
      "grad_norm": 3.292781114578247,
      "learning_rate": 6.593975903614458e-06,
      "loss": 0.0192,
      "step": 111270
    },
    {
      "epoch": 13.407228915662651,
      "grad_norm": 0.000993301160633564,
      "learning_rate": 6.592771084337351e-06,
      "loss": 0.033,
      "step": 111280
    },
    {
      "epoch": 13.40843373493976,
      "grad_norm": 0.334462434053421,
      "learning_rate": 6.591566265060242e-06,
      "loss": 0.0171,
      "step": 111290
    },
    {
      "epoch": 13.409638554216867,
      "grad_norm": 0.04669150337576866,
      "learning_rate": 6.590361445783133e-06,
      "loss": 0.0113,
      "step": 111300
    },
    {
      "epoch": 13.410843373493975,
      "grad_norm": 0.0018996561411768198,
      "learning_rate": 6.589156626506025e-06,
      "loss": 0.0029,
      "step": 111310
    },
    {
      "epoch": 13.412048192771085,
      "grad_norm": 10.212498664855957,
      "learning_rate": 6.587951807228916e-06,
      "loss": 0.0223,
      "step": 111320
    },
    {
      "epoch": 13.413253012048193,
      "grad_norm": 0.0007441187626682222,
      "learning_rate": 6.586746987951808e-06,
      "loss": 0.0097,
      "step": 111330
    },
    {
      "epoch": 13.4144578313253,
      "grad_norm": 0.0006623990484513342,
      "learning_rate": 6.585542168674699e-06,
      "loss": 0.0197,
      "step": 111340
    },
    {
      "epoch": 13.41566265060241,
      "grad_norm": 0.004309343174099922,
      "learning_rate": 6.58433734939759e-06,
      "loss": 0.0054,
      "step": 111350
    },
    {
      "epoch": 13.416867469879518,
      "grad_norm": 0.7104348540306091,
      "learning_rate": 6.5831325301204826e-06,
      "loss": 0.0117,
      "step": 111360
    },
    {
      "epoch": 13.418072289156626,
      "grad_norm": 0.21963895857334137,
      "learning_rate": 6.581927710843374e-06,
      "loss": 0.0065,
      "step": 111370
    },
    {
      "epoch": 13.419277108433734,
      "grad_norm": 0.03139682859182358,
      "learning_rate": 6.580722891566266e-06,
      "loss": 0.0087,
      "step": 111380
    },
    {
      "epoch": 13.420481927710844,
      "grad_norm": 0.0005477979429997504,
      "learning_rate": 6.579518072289157e-06,
      "loss": 0.0121,
      "step": 111390
    },
    {
      "epoch": 13.421686746987952,
      "grad_norm": 0.000887598842382431,
      "learning_rate": 6.578313253012049e-06,
      "loss": 0.0108,
      "step": 111400
    },
    {
      "epoch": 13.42289156626506,
      "grad_norm": 0.7219434380531311,
      "learning_rate": 6.57710843373494e-06,
      "loss": 0.0025,
      "step": 111410
    },
    {
      "epoch": 13.42409638554217,
      "grad_norm": 0.0008767321123741567,
      "learning_rate": 6.575903614457831e-06,
      "loss": 0.0108,
      "step": 111420
    },
    {
      "epoch": 13.425301204819277,
      "grad_norm": 0.0012911077355965972,
      "learning_rate": 6.574698795180724e-06,
      "loss": 0.0007,
      "step": 111430
    },
    {
      "epoch": 13.426506024096385,
      "grad_norm": 0.11203530430793762,
      "learning_rate": 6.573493975903615e-06,
      "loss": 0.0001,
      "step": 111440
    },
    {
      "epoch": 13.427710843373493,
      "grad_norm": 1.0889092683792114,
      "learning_rate": 6.572289156626507e-06,
      "loss": 0.0176,
      "step": 111450
    },
    {
      "epoch": 13.428915662650603,
      "grad_norm": 0.0009803742868825793,
      "learning_rate": 6.5710843373493984e-06,
      "loss": 0.0003,
      "step": 111460
    },
    {
      "epoch": 13.43012048192771,
      "grad_norm": 0.00047007310786284506,
      "learning_rate": 6.56987951807229e-06,
      "loss": 0.0213,
      "step": 111470
    },
    {
      "epoch": 13.431325301204819,
      "grad_norm": 0.0008342869696207345,
      "learning_rate": 6.568674698795181e-06,
      "loss": 0.023,
      "step": 111480
    },
    {
      "epoch": 13.432530120481928,
      "grad_norm": 6.4538116455078125,
      "learning_rate": 6.567469879518072e-06,
      "loss": 0.0402,
      "step": 111490
    },
    {
      "epoch": 13.433734939759036,
      "grad_norm": 0.0003879279538523406,
      "learning_rate": 6.566265060240964e-06,
      "loss": 0.009,
      "step": 111500
    },
    {
      "epoch": 13.434939759036144,
      "grad_norm": 0.00048181868623942137,
      "learning_rate": 6.565060240963856e-06,
      "loss": 0.0038,
      "step": 111510
    },
    {
      "epoch": 13.436144578313254,
      "grad_norm": 0.006251148413866758,
      "learning_rate": 6.563855421686748e-06,
      "loss": 0.0051,
      "step": 111520
    },
    {
      "epoch": 13.437349397590362,
      "grad_norm": 0.01446030754595995,
      "learning_rate": 6.5626506024096396e-06,
      "loss": 0.0091,
      "step": 111530
    },
    {
      "epoch": 13.43855421686747,
      "grad_norm": 0.0006082633626647294,
      "learning_rate": 6.56144578313253e-06,
      "loss": 0.0174,
      "step": 111540
    },
    {
      "epoch": 13.439759036144578,
      "grad_norm": 0.000654157716780901,
      "learning_rate": 6.560240963855422e-06,
      "loss": 0.0099,
      "step": 111550
    },
    {
      "epoch": 13.440963855421687,
      "grad_norm": 0.0012809195322915912,
      "learning_rate": 6.5590361445783135e-06,
      "loss": 0.016,
      "step": 111560
    },
    {
      "epoch": 13.442168674698795,
      "grad_norm": 0.0003462366003077477,
      "learning_rate": 6.557831325301205e-06,
      "loss": 0.0048,
      "step": 111570
    },
    {
      "epoch": 13.443373493975903,
      "grad_norm": 0.0005040914402343333,
      "learning_rate": 6.5566265060240975e-06,
      "loss": 0.0185,
      "step": 111580
    },
    {
      "epoch": 13.444578313253013,
      "grad_norm": 3.7184712886810303,
      "learning_rate": 6.555421686746989e-06,
      "loss": 0.0372,
      "step": 111590
    },
    {
      "epoch": 13.44578313253012,
      "grad_norm": 0.0009912785608321428,
      "learning_rate": 6.554216867469881e-06,
      "loss": 0.0095,
      "step": 111600
    },
    {
      "epoch": 13.446987951807229,
      "grad_norm": 4.907076835632324,
      "learning_rate": 6.553012048192771e-06,
      "loss": 0.0221,
      "step": 111610
    },
    {
      "epoch": 13.448192771084337,
      "grad_norm": 0.002414451912045479,
      "learning_rate": 6.551807228915663e-06,
      "loss": 0.0181,
      "step": 111620
    },
    {
      "epoch": 13.449397590361446,
      "grad_norm": 0.2550372779369354,
      "learning_rate": 6.550602409638555e-06,
      "loss": 0.0131,
      "step": 111630
    },
    {
      "epoch": 13.450602409638554,
      "grad_norm": 0.0030209128744900227,
      "learning_rate": 6.549397590361446e-06,
      "loss": 0.0254,
      "step": 111640
    },
    {
      "epoch": 13.451807228915662,
      "grad_norm": 0.004167506936937571,
      "learning_rate": 6.548192771084338e-06,
      "loss": 0.0123,
      "step": 111650
    },
    {
      "epoch": 13.453012048192772,
      "grad_norm": 0.017567304894328117,
      "learning_rate": 6.54698795180723e-06,
      "loss": 0.001,
      "step": 111660
    },
    {
      "epoch": 13.45421686746988,
      "grad_norm": 0.008622892200946808,
      "learning_rate": 6.545783132530121e-06,
      "loss": 0.0185,
      "step": 111670
    },
    {
      "epoch": 13.455421686746988,
      "grad_norm": 0.0012230353895574808,
      "learning_rate": 6.5445783132530125e-06,
      "loss": 0.0397,
      "step": 111680
    },
    {
      "epoch": 13.456626506024097,
      "grad_norm": 0.07240834087133408,
      "learning_rate": 6.543373493975904e-06,
      "loss": 0.0139,
      "step": 111690
    },
    {
      "epoch": 13.457831325301205,
      "grad_norm": 0.021444886922836304,
      "learning_rate": 6.542168674698796e-06,
      "loss": 0.0104,
      "step": 111700
    },
    {
      "epoch": 13.459036144578313,
      "grad_norm": 0.22894276678562164,
      "learning_rate": 6.540963855421687e-06,
      "loss": 0.0109,
      "step": 111710
    },
    {
      "epoch": 13.460240963855421,
      "grad_norm": 0.0355612114071846,
      "learning_rate": 6.539759036144578e-06,
      "loss": 0.013,
      "step": 111720
    },
    {
      "epoch": 13.46144578313253,
      "grad_norm": 0.8454636931419373,
      "learning_rate": 6.538554216867471e-06,
      "loss": 0.004,
      "step": 111730
    },
    {
      "epoch": 13.462650602409639,
      "grad_norm": 0.0005621646414510906,
      "learning_rate": 6.537349397590362e-06,
      "loss": 0.0279,
      "step": 111740
    },
    {
      "epoch": 13.463855421686747,
      "grad_norm": 0.001775624230504036,
      "learning_rate": 6.536144578313254e-06,
      "loss": 0.0162,
      "step": 111750
    },
    {
      "epoch": 13.465060240963856,
      "grad_norm": 0.0006646637921221554,
      "learning_rate": 6.534939759036145e-06,
      "loss": 0.0132,
      "step": 111760
    },
    {
      "epoch": 13.466265060240964,
      "grad_norm": 0.2658933103084564,
      "learning_rate": 6.533734939759037e-06,
      "loss": 0.0137,
      "step": 111770
    },
    {
      "epoch": 13.467469879518072,
      "grad_norm": 0.0006897904677316546,
      "learning_rate": 6.532530120481928e-06,
      "loss": 0.0396,
      "step": 111780
    },
    {
      "epoch": 13.46867469879518,
      "grad_norm": 0.0014027488650754094,
      "learning_rate": 6.531325301204819e-06,
      "loss": 0.0028,
      "step": 111790
    },
    {
      "epoch": 13.46987951807229,
      "grad_norm": 0.00463579036295414,
      "learning_rate": 6.530120481927711e-06,
      "loss": 0.0086,
      "step": 111800
    },
    {
      "epoch": 13.471084337349398,
      "grad_norm": 0.000653368653729558,
      "learning_rate": 6.528915662650603e-06,
      "loss": 0.0032,
      "step": 111810
    },
    {
      "epoch": 13.472289156626506,
      "grad_norm": 0.9546176195144653,
      "learning_rate": 6.527710843373495e-06,
      "loss": 0.0228,
      "step": 111820
    },
    {
      "epoch": 13.473493975903615,
      "grad_norm": 1.578087568283081,
      "learning_rate": 6.526506024096386e-06,
      "loss": 0.0238,
      "step": 111830
    },
    {
      "epoch": 13.474698795180723,
      "grad_norm": 0.0004512727027758956,
      "learning_rate": 6.525301204819278e-06,
      "loss": 0.006,
      "step": 111840
    },
    {
      "epoch": 13.475903614457831,
      "grad_norm": 0.000504284689668566,
      "learning_rate": 6.524096385542169e-06,
      "loss": 0.0203,
      "step": 111850
    },
    {
      "epoch": 13.477108433734939,
      "grad_norm": 0.00023652285744901747,
      "learning_rate": 6.52289156626506e-06,
      "loss": 0.0233,
      "step": 111860
    },
    {
      "epoch": 13.478313253012049,
      "grad_norm": 0.0008487846935167909,
      "learning_rate": 6.521686746987952e-06,
      "loss": 0.02,
      "step": 111870
    },
    {
      "epoch": 13.479518072289157,
      "grad_norm": 0.06065037474036217,
      "learning_rate": 6.520481927710844e-06,
      "loss": 0.0116,
      "step": 111880
    },
    {
      "epoch": 13.480722891566264,
      "grad_norm": 0.015019666403532028,
      "learning_rate": 6.519277108433736e-06,
      "loss": 0.003,
      "step": 111890
    },
    {
      "epoch": 13.481927710843374,
      "grad_norm": 0.00943054724484682,
      "learning_rate": 6.5180722891566275e-06,
      "loss": 0.0077,
      "step": 111900
    },
    {
      "epoch": 13.483132530120482,
      "grad_norm": 0.03346807509660721,
      "learning_rate": 6.516867469879519e-06,
      "loss": 0.0129,
      "step": 111910
    },
    {
      "epoch": 13.48433734939759,
      "grad_norm": 0.0007470652926713228,
      "learning_rate": 6.51566265060241e-06,
      "loss": 0.008,
      "step": 111920
    },
    {
      "epoch": 13.485542168674698,
      "grad_norm": 0.03426273167133331,
      "learning_rate": 6.514457831325301e-06,
      "loss": 0.0089,
      "step": 111930
    },
    {
      "epoch": 13.486746987951808,
      "grad_norm": 0.005290508270263672,
      "learning_rate": 6.513253012048193e-06,
      "loss": 0.0336,
      "step": 111940
    },
    {
      "epoch": 13.487951807228916,
      "grad_norm": 0.0006112171686254442,
      "learning_rate": 6.5120481927710846e-06,
      "loss": 0.0343,
      "step": 111950
    },
    {
      "epoch": 13.489156626506023,
      "grad_norm": 0.016102582216262817,
      "learning_rate": 6.510843373493977e-06,
      "loss": 0.0137,
      "step": 111960
    },
    {
      "epoch": 13.490361445783133,
      "grad_norm": 0.0006515552522614598,
      "learning_rate": 6.509638554216869e-06,
      "loss": 0.0138,
      "step": 111970
    },
    {
      "epoch": 13.491566265060241,
      "grad_norm": 0.9375878572463989,
      "learning_rate": 6.508433734939759e-06,
      "loss": 0.0286,
      "step": 111980
    },
    {
      "epoch": 13.492771084337349,
      "grad_norm": 0.10437630116939545,
      "learning_rate": 6.507228915662651e-06,
      "loss": 0.0467,
      "step": 111990
    },
    {
      "epoch": 13.493975903614459,
      "grad_norm": 0.0023454513866454363,
      "learning_rate": 6.5060240963855425e-06,
      "loss": 0.009,
      "step": 112000
    },
    {
      "epoch": 13.495180722891567,
      "grad_norm": 1.0835891962051392,
      "learning_rate": 6.504819277108434e-06,
      "loss": 0.0124,
      "step": 112010
    },
    {
      "epoch": 13.496385542168674,
      "grad_norm": 0.9640662670135498,
      "learning_rate": 6.503614457831326e-06,
      "loss": 0.0088,
      "step": 112020
    },
    {
      "epoch": 13.497590361445782,
      "grad_norm": 3.0135304927825928,
      "learning_rate": 6.502409638554218e-06,
      "loss": 0.0147,
      "step": 112030
    },
    {
      "epoch": 13.498795180722892,
      "grad_norm": 0.0009483220055699348,
      "learning_rate": 6.50120481927711e-06,
      "loss": 0.0091,
      "step": 112040
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.0004991946625523269,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0027,
      "step": 112050
    },
    {
      "epoch": 13.501204819277108,
      "grad_norm": 0.3776904344558716,
      "learning_rate": 6.498795180722892e-06,
      "loss": 0.0129,
      "step": 112060
    },
    {
      "epoch": 13.502409638554218,
      "grad_norm": 1.2945640087127686,
      "learning_rate": 6.497590361445784e-06,
      "loss": 0.0173,
      "step": 112070
    },
    {
      "epoch": 13.503614457831326,
      "grad_norm": 0.0006117761367931962,
      "learning_rate": 6.496385542168675e-06,
      "loss": 0.0064,
      "step": 112080
    },
    {
      "epoch": 13.504819277108433,
      "grad_norm": 0.0003664903633762151,
      "learning_rate": 6.495180722891567e-06,
      "loss": 0.0041,
      "step": 112090
    },
    {
      "epoch": 13.506024096385541,
      "grad_norm": 0.0003487665671855211,
      "learning_rate": 6.4939759036144575e-06,
      "loss": 0.0164,
      "step": 112100
    },
    {
      "epoch": 13.507228915662651,
      "grad_norm": 0.0023944757413119078,
      "learning_rate": 6.49277108433735e-06,
      "loss": 0.0389,
      "step": 112110
    },
    {
      "epoch": 13.508433734939759,
      "grad_norm": 0.01601899415254593,
      "learning_rate": 6.4915662650602416e-06,
      "loss": 0.0032,
      "step": 112120
    },
    {
      "epoch": 13.509638554216867,
      "grad_norm": 1.0011183023452759,
      "learning_rate": 6.490361445783133e-06,
      "loss": 0.0478,
      "step": 112130
    },
    {
      "epoch": 13.510843373493977,
      "grad_norm": 0.0007176664075814188,
      "learning_rate": 6.489156626506025e-06,
      "loss": 0.0558,
      "step": 112140
    },
    {
      "epoch": 13.512048192771084,
      "grad_norm": 0.0020647416822612286,
      "learning_rate": 6.487951807228916e-06,
      "loss": 0.0024,
      "step": 112150
    },
    {
      "epoch": 13.513253012048192,
      "grad_norm": 0.0018665931420400739,
      "learning_rate": 6.486746987951807e-06,
      "loss": 0.011,
      "step": 112160
    },
    {
      "epoch": 13.514457831325302,
      "grad_norm": 0.0020022373646497726,
      "learning_rate": 6.485542168674699e-06,
      "loss": 0.0086,
      "step": 112170
    },
    {
      "epoch": 13.51566265060241,
      "grad_norm": 0.1452980637550354,
      "learning_rate": 6.484337349397591e-06,
      "loss": 0.0336,
      "step": 112180
    },
    {
      "epoch": 13.516867469879518,
      "grad_norm": 0.0049144066870212555,
      "learning_rate": 6.483132530120483e-06,
      "loss": 0.0062,
      "step": 112190
    },
    {
      "epoch": 13.518072289156626,
      "grad_norm": 0.0029086449649184942,
      "learning_rate": 6.481927710843374e-06,
      "loss": 0.0169,
      "step": 112200
    },
    {
      "epoch": 13.519277108433736,
      "grad_norm": 0.9678746461868286,
      "learning_rate": 6.480722891566266e-06,
      "loss": 0.024,
      "step": 112210
    },
    {
      "epoch": 13.520481927710843,
      "grad_norm": 0.6382846832275391,
      "learning_rate": 6.4795180722891574e-06,
      "loss": 0.0392,
      "step": 112220
    },
    {
      "epoch": 13.521686746987951,
      "grad_norm": 0.0017055933130905032,
      "learning_rate": 6.478313253012048e-06,
      "loss": 0.0002,
      "step": 112230
    },
    {
      "epoch": 13.522891566265061,
      "grad_norm": 0.0046440367586910725,
      "learning_rate": 6.47710843373494e-06,
      "loss": 0.011,
      "step": 112240
    },
    {
      "epoch": 13.524096385542169,
      "grad_norm": 0.41721203923225403,
      "learning_rate": 6.475903614457831e-06,
      "loss": 0.0377,
      "step": 112250
    },
    {
      "epoch": 13.525301204819277,
      "grad_norm": 0.001818597549572587,
      "learning_rate": 6.474698795180724e-06,
      "loss": 0.0175,
      "step": 112260
    },
    {
      "epoch": 13.526506024096385,
      "grad_norm": 4.93795108795166,
      "learning_rate": 6.473493975903615e-06,
      "loss": 0.0593,
      "step": 112270
    },
    {
      "epoch": 13.527710843373494,
      "grad_norm": 0.005701138637959957,
      "learning_rate": 6.472289156626507e-06,
      "loss": 0.0013,
      "step": 112280
    },
    {
      "epoch": 13.528915662650602,
      "grad_norm": 0.0053127482533454895,
      "learning_rate": 6.471084337349398e-06,
      "loss": 0.0055,
      "step": 112290
    },
    {
      "epoch": 13.53012048192771,
      "grad_norm": 0.9608880281448364,
      "learning_rate": 6.469879518072289e-06,
      "loss": 0.0052,
      "step": 112300
    },
    {
      "epoch": 13.53132530120482,
      "grad_norm": 0.7879936099052429,
      "learning_rate": 6.468674698795181e-06,
      "loss": 0.0191,
      "step": 112310
    },
    {
      "epoch": 13.532530120481928,
      "grad_norm": 1.3935458660125732,
      "learning_rate": 6.4674698795180725e-06,
      "loss": 0.0241,
      "step": 112320
    },
    {
      "epoch": 13.533734939759036,
      "grad_norm": 6.134853839874268,
      "learning_rate": 6.466265060240965e-06,
      "loss": 0.0749,
      "step": 112330
    },
    {
      "epoch": 13.534939759036144,
      "grad_norm": 1.0131820440292358,
      "learning_rate": 6.4650602409638565e-06,
      "loss": 0.0068,
      "step": 112340
    },
    {
      "epoch": 13.536144578313253,
      "grad_norm": 1.2986409664154053,
      "learning_rate": 6.463855421686748e-06,
      "loss": 0.0182,
      "step": 112350
    },
    {
      "epoch": 13.537349397590361,
      "grad_norm": 0.14539915323257446,
      "learning_rate": 6.462650602409639e-06,
      "loss": 0.0372,
      "step": 112360
    },
    {
      "epoch": 13.53855421686747,
      "grad_norm": 0.2653137743473053,
      "learning_rate": 6.46144578313253e-06,
      "loss": 0.0081,
      "step": 112370
    },
    {
      "epoch": 13.539759036144579,
      "grad_norm": 0.019980965182185173,
      "learning_rate": 6.460240963855422e-06,
      "loss": 0.0389,
      "step": 112380
    },
    {
      "epoch": 13.540963855421687,
      "grad_norm": 1.108163833618164,
      "learning_rate": 6.459036144578314e-06,
      "loss": 0.0295,
      "step": 112390
    },
    {
      "epoch": 13.542168674698795,
      "grad_norm": 0.0060666995123028755,
      "learning_rate": 6.457831325301205e-06,
      "loss": 0.0112,
      "step": 112400
    },
    {
      "epoch": 13.543373493975903,
      "grad_norm": 0.013900388963520527,
      "learning_rate": 6.456626506024098e-06,
      "loss": 0.0344,
      "step": 112410
    },
    {
      "epoch": 13.544578313253012,
      "grad_norm": 3.302323341369629,
      "learning_rate": 6.455421686746988e-06,
      "loss": 0.0431,
      "step": 112420
    },
    {
      "epoch": 13.54578313253012,
      "grad_norm": 0.014687384478747845,
      "learning_rate": 6.45421686746988e-06,
      "loss": 0.0038,
      "step": 112430
    },
    {
      "epoch": 13.546987951807228,
      "grad_norm": 0.24402262270450592,
      "learning_rate": 6.4530120481927715e-06,
      "loss": 0.0048,
      "step": 112440
    },
    {
      "epoch": 13.548192771084338,
      "grad_norm": 0.00857071578502655,
      "learning_rate": 6.451807228915663e-06,
      "loss": 0.0073,
      "step": 112450
    },
    {
      "epoch": 13.549397590361446,
      "grad_norm": 0.7681517004966736,
      "learning_rate": 6.450602409638555e-06,
      "loss": 0.0163,
      "step": 112460
    },
    {
      "epoch": 13.550602409638554,
      "grad_norm": 0.01406009029597044,
      "learning_rate": 6.4493975903614454e-06,
      "loss": 0.009,
      "step": 112470
    },
    {
      "epoch": 13.551807228915663,
      "grad_norm": 0.23135709762573242,
      "learning_rate": 6.448192771084339e-06,
      "loss": 0.0087,
      "step": 112480
    },
    {
      "epoch": 13.553012048192771,
      "grad_norm": 0.46672844886779785,
      "learning_rate": 6.4469879518072295e-06,
      "loss": 0.024,
      "step": 112490
    },
    {
      "epoch": 13.55421686746988,
      "grad_norm": 30.1815185546875,
      "learning_rate": 6.445783132530121e-06,
      "loss": 0.0347,
      "step": 112500
    },
    {
      "epoch": 13.555421686746987,
      "grad_norm": 0.011434183456003666,
      "learning_rate": 6.444578313253013e-06,
      "loss": 0.0031,
      "step": 112510
    },
    {
      "epoch": 13.556626506024097,
      "grad_norm": 0.48219507932662964,
      "learning_rate": 6.443373493975904e-06,
      "loss": 0.0037,
      "step": 112520
    },
    {
      "epoch": 13.557831325301205,
      "grad_norm": 0.0008645040215924382,
      "learning_rate": 6.442168674698796e-06,
      "loss": 0.0136,
      "step": 112530
    },
    {
      "epoch": 13.559036144578313,
      "grad_norm": 0.0021579281892627478,
      "learning_rate": 6.4409638554216866e-06,
      "loss": 0.0172,
      "step": 112540
    },
    {
      "epoch": 13.560240963855422,
      "grad_norm": 0.0008946940652094781,
      "learning_rate": 6.439759036144578e-06,
      "loss": 0.0221,
      "step": 112550
    },
    {
      "epoch": 13.56144578313253,
      "grad_norm": 0.005854702554643154,
      "learning_rate": 6.438554216867471e-06,
      "loss": 0.0103,
      "step": 112560
    },
    {
      "epoch": 13.562650602409638,
      "grad_norm": 0.6747483015060425,
      "learning_rate": 6.437349397590362e-06,
      "loss": 0.0138,
      "step": 112570
    },
    {
      "epoch": 13.563855421686746,
      "grad_norm": 0.9486433267593384,
      "learning_rate": 6.436144578313254e-06,
      "loss": 0.0121,
      "step": 112580
    },
    {
      "epoch": 13.565060240963856,
      "grad_norm": 0.0008174240938387811,
      "learning_rate": 6.434939759036145e-06,
      "loss": 0.0153,
      "step": 112590
    },
    {
      "epoch": 13.566265060240964,
      "grad_norm": 0.0010684800799936056,
      "learning_rate": 6.433734939759036e-06,
      "loss": 0.0129,
      "step": 112600
    },
    {
      "epoch": 13.567469879518072,
      "grad_norm": 0.0008691871771588922,
      "learning_rate": 6.432530120481928e-06,
      "loss": 0.009,
      "step": 112610
    },
    {
      "epoch": 13.568674698795181,
      "grad_norm": 0.01202437561005354,
      "learning_rate": 6.431325301204819e-06,
      "loss": 0.0113,
      "step": 112620
    },
    {
      "epoch": 13.56987951807229,
      "grad_norm": 0.0005703610368072987,
      "learning_rate": 6.430120481927712e-06,
      "loss": 0.0017,
      "step": 112630
    },
    {
      "epoch": 13.571084337349397,
      "grad_norm": 0.01480177417397499,
      "learning_rate": 6.428915662650603e-06,
      "loss": 0.0366,
      "step": 112640
    },
    {
      "epoch": 13.572289156626507,
      "grad_norm": 0.8115867376327515,
      "learning_rate": 6.427710843373495e-06,
      "loss": 0.0196,
      "step": 112650
    },
    {
      "epoch": 13.573493975903615,
      "grad_norm": 0.41509172320365906,
      "learning_rate": 6.4265060240963865e-06,
      "loss": 0.0046,
      "step": 112660
    },
    {
      "epoch": 13.574698795180723,
      "grad_norm": 0.008346818387508392,
      "learning_rate": 6.425301204819277e-06,
      "loss": 0.0045,
      "step": 112670
    },
    {
      "epoch": 13.57590361445783,
      "grad_norm": 0.00044135170173831284,
      "learning_rate": 6.424096385542169e-06,
      "loss": 0.0066,
      "step": 112680
    },
    {
      "epoch": 13.57710843373494,
      "grad_norm": 0.0006848872289992869,
      "learning_rate": 6.42289156626506e-06,
      "loss": 0.0004,
      "step": 112690
    },
    {
      "epoch": 13.578313253012048,
      "grad_norm": 0.0005037859664298594,
      "learning_rate": 6.421686746987952e-06,
      "loss": 0.0204,
      "step": 112700
    },
    {
      "epoch": 13.579518072289156,
      "grad_norm": 0.002803842769935727,
      "learning_rate": 6.420481927710844e-06,
      "loss": 0.0071,
      "step": 112710
    },
    {
      "epoch": 13.580722891566266,
      "grad_norm": 0.0016317155677825212,
      "learning_rate": 6.419277108433736e-06,
      "loss": 0.0,
      "step": 112720
    },
    {
      "epoch": 13.581927710843374,
      "grad_norm": 0.6089019179344177,
      "learning_rate": 6.418072289156628e-06,
      "loss": 0.0197,
      "step": 112730
    },
    {
      "epoch": 13.583132530120482,
      "grad_norm": 0.00038206332828849554,
      "learning_rate": 6.416867469879518e-06,
      "loss": 0.0241,
      "step": 112740
    },
    {
      "epoch": 13.58433734939759,
      "grad_norm": 0.29212328791618347,
      "learning_rate": 6.41566265060241e-06,
      "loss": 0.0298,
      "step": 112750
    },
    {
      "epoch": 13.5855421686747,
      "grad_norm": 0.30649691820144653,
      "learning_rate": 6.4144578313253015e-06,
      "loss": 0.0104,
      "step": 112760
    },
    {
      "epoch": 13.586746987951807,
      "grad_norm": 0.7737927436828613,
      "learning_rate": 6.413253012048193e-06,
      "loss": 0.0102,
      "step": 112770
    },
    {
      "epoch": 13.587951807228915,
      "grad_norm": 0.002872215583920479,
      "learning_rate": 6.4120481927710855e-06,
      "loss": 0.0433,
      "step": 112780
    },
    {
      "epoch": 13.589156626506025,
      "grad_norm": 0.0006902124150656164,
      "learning_rate": 6.410843373493977e-06,
      "loss": 0.0219,
      "step": 112790
    },
    {
      "epoch": 13.590361445783133,
      "grad_norm": 2.0371861457824707,
      "learning_rate": 6.409638554216868e-06,
      "loss": 0.0261,
      "step": 112800
    },
    {
      "epoch": 13.59156626506024,
      "grad_norm": 0.2315145581960678,
      "learning_rate": 6.4084337349397594e-06,
      "loss": 0.044,
      "step": 112810
    },
    {
      "epoch": 13.592771084337349,
      "grad_norm": 0.8674333691596985,
      "learning_rate": 6.407228915662651e-06,
      "loss": 0.0468,
      "step": 112820
    },
    {
      "epoch": 13.593975903614458,
      "grad_norm": 0.012716257013380527,
      "learning_rate": 6.406024096385543e-06,
      "loss": 0.0056,
      "step": 112830
    },
    {
      "epoch": 13.595180722891566,
      "grad_norm": 0.019644221290946007,
      "learning_rate": 6.404819277108434e-06,
      "loss": 0.0042,
      "step": 112840
    },
    {
      "epoch": 13.596385542168674,
      "grad_norm": 0.41730254888534546,
      "learning_rate": 6.403614457831325e-06,
      "loss": 0.0195,
      "step": 112850
    },
    {
      "epoch": 13.597590361445784,
      "grad_norm": 0.7971966862678528,
      "learning_rate": 6.402409638554218e-06,
      "loss": 0.005,
      "step": 112860
    },
    {
      "epoch": 13.598795180722892,
      "grad_norm": 0.018537500873208046,
      "learning_rate": 6.401204819277109e-06,
      "loss": 0.0045,
      "step": 112870
    },
    {
      "epoch": 13.6,
      "grad_norm": 0.03962714225053787,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0438,
      "step": 112880
    },
    {
      "epoch": 13.601204819277108,
      "grad_norm": 0.0009686957928352058,
      "learning_rate": 6.398795180722892e-06,
      "loss": 0.01,
      "step": 112890
    },
    {
      "epoch": 13.602409638554217,
      "grad_norm": 0.0014778166078031063,
      "learning_rate": 6.397590361445784e-06,
      "loss": 0.0073,
      "step": 112900
    },
    {
      "epoch": 13.603614457831325,
      "grad_norm": 0.02164226956665516,
      "learning_rate": 6.396385542168675e-06,
      "loss": 0.0197,
      "step": 112910
    },
    {
      "epoch": 13.604819277108433,
      "grad_norm": 13.746978759765625,
      "learning_rate": 6.395180722891566e-06,
      "loss": 0.036,
      "step": 112920
    },
    {
      "epoch": 13.606024096385543,
      "grad_norm": 0.0032295440323650837,
      "learning_rate": 6.3939759036144585e-06,
      "loss": 0.0009,
      "step": 112930
    },
    {
      "epoch": 13.60722891566265,
      "grad_norm": 0.007139616180211306,
      "learning_rate": 6.39277108433735e-06,
      "loss": 0.0015,
      "step": 112940
    },
    {
      "epoch": 13.608433734939759,
      "grad_norm": 0.09600388258695602,
      "learning_rate": 6.391566265060242e-06,
      "loss": 0.0148,
      "step": 112950
    },
    {
      "epoch": 13.609638554216868,
      "grad_norm": 0.003749522613361478,
      "learning_rate": 6.390361445783133e-06,
      "loss": 0.0053,
      "step": 112960
    },
    {
      "epoch": 13.610843373493976,
      "grad_norm": 1.1950870752334595,
      "learning_rate": 6.389156626506025e-06,
      "loss": 0.0237,
      "step": 112970
    },
    {
      "epoch": 13.612048192771084,
      "grad_norm": 0.0023721763864159584,
      "learning_rate": 6.387951807228916e-06,
      "loss": 0.0026,
      "step": 112980
    },
    {
      "epoch": 13.613253012048192,
      "grad_norm": 0.0027164670173078775,
      "learning_rate": 6.386746987951807e-06,
      "loss": 0.0231,
      "step": 112990
    },
    {
      "epoch": 13.614457831325302,
      "grad_norm": 0.25657540559768677,
      "learning_rate": 6.385542168674699e-06,
      "loss": 0.0037,
      "step": 113000
    },
    {
      "epoch": 13.61566265060241,
      "grad_norm": 13.306992530822754,
      "learning_rate": 6.384337349397591e-06,
      "loss": 0.0313,
      "step": 113010
    },
    {
      "epoch": 13.616867469879518,
      "grad_norm": 0.4622874855995178,
      "learning_rate": 6.383132530120483e-06,
      "loss": 0.0032,
      "step": 113020
    },
    {
      "epoch": 13.618072289156627,
      "grad_norm": 0.0016771384980529547,
      "learning_rate": 6.381927710843374e-06,
      "loss": 0.0425,
      "step": 113030
    },
    {
      "epoch": 13.619277108433735,
      "grad_norm": 0.0011265070643275976,
      "learning_rate": 6.380722891566266e-06,
      "loss": 0.0063,
      "step": 113040
    },
    {
      "epoch": 13.620481927710843,
      "grad_norm": 0.002941619139164686,
      "learning_rate": 6.379518072289157e-06,
      "loss": 0.0035,
      "step": 113050
    },
    {
      "epoch": 13.621686746987951,
      "grad_norm": 0.002301555359736085,
      "learning_rate": 6.378313253012048e-06,
      "loss": 0.0249,
      "step": 113060
    },
    {
      "epoch": 13.62289156626506,
      "grad_norm": 0.0023267525248229504,
      "learning_rate": 6.37710843373494e-06,
      "loss": 0.0034,
      "step": 113070
    },
    {
      "epoch": 13.624096385542169,
      "grad_norm": 6.987945079803467,
      "learning_rate": 6.375903614457832e-06,
      "loss": 0.0421,
      "step": 113080
    },
    {
      "epoch": 13.625301204819277,
      "grad_norm": 0.027111748233437538,
      "learning_rate": 6.374698795180724e-06,
      "loss": 0.0355,
      "step": 113090
    },
    {
      "epoch": 13.626506024096386,
      "grad_norm": 0.4320513606071472,
      "learning_rate": 6.3734939759036155e-06,
      "loss": 0.0111,
      "step": 113100
    },
    {
      "epoch": 13.627710843373494,
      "grad_norm": 0.9188022017478943,
      "learning_rate": 6.372289156626506e-06,
      "loss": 0.0213,
      "step": 113110
    },
    {
      "epoch": 13.628915662650602,
      "grad_norm": 1.1216548681259155,
      "learning_rate": 6.371084337349398e-06,
      "loss": 0.0113,
      "step": 113120
    },
    {
      "epoch": 13.630120481927712,
      "grad_norm": 0.7404876947402954,
      "learning_rate": 6.369879518072289e-06,
      "loss": 0.0068,
      "step": 113130
    },
    {
      "epoch": 13.63132530120482,
      "grad_norm": 0.002204681746661663,
      "learning_rate": 6.368674698795181e-06,
      "loss": 0.0003,
      "step": 113140
    },
    {
      "epoch": 13.632530120481928,
      "grad_norm": 1.5190662145614624,
      "learning_rate": 6.367469879518073e-06,
      "loss": 0.0179,
      "step": 113150
    },
    {
      "epoch": 13.633734939759035,
      "grad_norm": 0.009486290626227856,
      "learning_rate": 6.366265060240965e-06,
      "loss": 0.0238,
      "step": 113160
    },
    {
      "epoch": 13.634939759036145,
      "grad_norm": 0.2601638436317444,
      "learning_rate": 6.365060240963857e-06,
      "loss": 0.0076,
      "step": 113170
    },
    {
      "epoch": 13.636144578313253,
      "grad_norm": 0.04070504382252693,
      "learning_rate": 6.363855421686747e-06,
      "loss": 0.0005,
      "step": 113180
    },
    {
      "epoch": 13.637349397590361,
      "grad_norm": 0.0012100490275770426,
      "learning_rate": 6.362650602409639e-06,
      "loss": 0.0065,
      "step": 113190
    },
    {
      "epoch": 13.638554216867469,
      "grad_norm": 0.0035808109678328037,
      "learning_rate": 6.3614457831325305e-06,
      "loss": 0.0038,
      "step": 113200
    },
    {
      "epoch": 13.639759036144579,
      "grad_norm": 0.0072060273960232735,
      "learning_rate": 6.360240963855422e-06,
      "loss": 0.0064,
      "step": 113210
    },
    {
      "epoch": 13.640963855421687,
      "grad_norm": 0.004607346374541521,
      "learning_rate": 6.359036144578314e-06,
      "loss": 0.0219,
      "step": 113220
    },
    {
      "epoch": 13.642168674698794,
      "grad_norm": 1.7824945449829102,
      "learning_rate": 6.357831325301206e-06,
      "loss": 0.0093,
      "step": 113230
    },
    {
      "epoch": 13.643373493975904,
      "grad_norm": 0.0006595528684556484,
      "learning_rate": 6.356626506024097e-06,
      "loss": 0.0234,
      "step": 113240
    },
    {
      "epoch": 13.644578313253012,
      "grad_norm": 0.008242001757025719,
      "learning_rate": 6.3554216867469885e-06,
      "loss": 0.0109,
      "step": 113250
    },
    {
      "epoch": 13.64578313253012,
      "grad_norm": 1.5764480829238892,
      "learning_rate": 6.35421686746988e-06,
      "loss": 0.0537,
      "step": 113260
    },
    {
      "epoch": 13.64698795180723,
      "grad_norm": 0.0007005349034443498,
      "learning_rate": 6.353012048192772e-06,
      "loss": 0.0138,
      "step": 113270
    },
    {
      "epoch": 13.648192771084338,
      "grad_norm": 0.2700471878051758,
      "learning_rate": 6.351807228915663e-06,
      "loss": 0.0124,
      "step": 113280
    },
    {
      "epoch": 13.649397590361446,
      "grad_norm": 0.3743060231208801,
      "learning_rate": 6.350602409638554e-06,
      "loss": 0.037,
      "step": 113290
    },
    {
      "epoch": 13.650602409638553,
      "grad_norm": 0.9996423125267029,
      "learning_rate": 6.3493975903614456e-06,
      "loss": 0.0374,
      "step": 113300
    },
    {
      "epoch": 13.651807228915663,
      "grad_norm": 0.0032958637457340956,
      "learning_rate": 6.348192771084338e-06,
      "loss": 0.0061,
      "step": 113310
    },
    {
      "epoch": 13.653012048192771,
      "grad_norm": 0.07355387508869171,
      "learning_rate": 6.34698795180723e-06,
      "loss": 0.0232,
      "step": 113320
    },
    {
      "epoch": 13.654216867469879,
      "grad_norm": 0.8811812996864319,
      "learning_rate": 6.345783132530121e-06,
      "loss": 0.0068,
      "step": 113330
    },
    {
      "epoch": 13.655421686746989,
      "grad_norm": 0.011786816641688347,
      "learning_rate": 6.344578313253013e-06,
      "loss": 0.0111,
      "step": 113340
    },
    {
      "epoch": 13.656626506024097,
      "grad_norm": 1.6542731523513794,
      "learning_rate": 6.343373493975904e-06,
      "loss": 0.033,
      "step": 113350
    },
    {
      "epoch": 13.657831325301204,
      "grad_norm": 0.016036909073591232,
      "learning_rate": 6.342168674698795e-06,
      "loss": 0.0291,
      "step": 113360
    },
    {
      "epoch": 13.659036144578312,
      "grad_norm": 0.0028255193028599024,
      "learning_rate": 6.340963855421687e-06,
      "loss": 0.0039,
      "step": 113370
    },
    {
      "epoch": 13.660240963855422,
      "grad_norm": 0.0009367049788124859,
      "learning_rate": 6.339759036144579e-06,
      "loss": 0.0047,
      "step": 113380
    },
    {
      "epoch": 13.66144578313253,
      "grad_norm": 0.000841364380903542,
      "learning_rate": 6.338554216867471e-06,
      "loss": 0.0065,
      "step": 113390
    },
    {
      "epoch": 13.662650602409638,
      "grad_norm": 0.003371304599568248,
      "learning_rate": 6.337349397590362e-06,
      "loss": 0.0086,
      "step": 113400
    },
    {
      "epoch": 13.663855421686748,
      "grad_norm": 0.3730647563934326,
      "learning_rate": 6.336144578313254e-06,
      "loss": 0.0385,
      "step": 113410
    },
    {
      "epoch": 13.665060240963856,
      "grad_norm": 0.0015969211235642433,
      "learning_rate": 6.334939759036145e-06,
      "loss": 0.0168,
      "step": 113420
    },
    {
      "epoch": 13.666265060240963,
      "grad_norm": 0.36763450503349304,
      "learning_rate": 6.333734939759036e-06,
      "loss": 0.0125,
      "step": 113430
    },
    {
      "epoch": 13.667469879518073,
      "grad_norm": 0.003693830454722047,
      "learning_rate": 6.332530120481928e-06,
      "loss": 0.0202,
      "step": 113440
    },
    {
      "epoch": 13.668674698795181,
      "grad_norm": 0.0019777570851147175,
      "learning_rate": 6.331325301204819e-06,
      "loss": 0.0128,
      "step": 113450
    },
    {
      "epoch": 13.669879518072289,
      "grad_norm": 0.001363307354040444,
      "learning_rate": 6.330120481927712e-06,
      "loss": 0.0398,
      "step": 113460
    },
    {
      "epoch": 13.671084337349397,
      "grad_norm": 0.0018428103066980839,
      "learning_rate": 6.328915662650603e-06,
      "loss": 0.0032,
      "step": 113470
    },
    {
      "epoch": 13.672289156626507,
      "grad_norm": 0.16599391400814056,
      "learning_rate": 6.327710843373495e-06,
      "loss": 0.0039,
      "step": 113480
    },
    {
      "epoch": 13.673493975903614,
      "grad_norm": 0.0024559027515351772,
      "learning_rate": 6.326506024096386e-06,
      "loss": 0.0078,
      "step": 113490
    },
    {
      "epoch": 13.674698795180722,
      "grad_norm": 0.0015813350910320878,
      "learning_rate": 6.325301204819277e-06,
      "loss": 0.0186,
      "step": 113500
    },
    {
      "epoch": 13.675903614457832,
      "grad_norm": 0.3456633388996124,
      "learning_rate": 6.324096385542169e-06,
      "loss": 0.0045,
      "step": 113510
    },
    {
      "epoch": 13.67710843373494,
      "grad_norm": 0.07721223682165146,
      "learning_rate": 6.3228915662650605e-06,
      "loss": 0.0184,
      "step": 113520
    },
    {
      "epoch": 13.678313253012048,
      "grad_norm": 0.8328793048858643,
      "learning_rate": 6.321686746987953e-06,
      "loss": 0.0233,
      "step": 113530
    },
    {
      "epoch": 13.679518072289156,
      "grad_norm": 0.010647794231772423,
      "learning_rate": 6.3204819277108445e-06,
      "loss": 0.0244,
      "step": 113540
    },
    {
      "epoch": 13.680722891566266,
      "grad_norm": 1.1331621408462524,
      "learning_rate": 6.319277108433735e-06,
      "loss": 0.0201,
      "step": 113550
    },
    {
      "epoch": 13.681927710843373,
      "grad_norm": 1.0686061382293701,
      "learning_rate": 6.318072289156627e-06,
      "loss": 0.014,
      "step": 113560
    },
    {
      "epoch": 13.683132530120481,
      "grad_norm": 0.0023323979694396257,
      "learning_rate": 6.3168674698795184e-06,
      "loss": 0.0255,
      "step": 113570
    },
    {
      "epoch": 13.684337349397591,
      "grad_norm": 0.45311903953552246,
      "learning_rate": 6.31566265060241e-06,
      "loss": 0.0216,
      "step": 113580
    },
    {
      "epoch": 13.685542168674699,
      "grad_norm": 0.36305949091911316,
      "learning_rate": 6.314457831325302e-06,
      "loss": 0.0146,
      "step": 113590
    },
    {
      "epoch": 13.686746987951807,
      "grad_norm": 0.0009868796914815903,
      "learning_rate": 6.313253012048192e-06,
      "loss": 0.0113,
      "step": 113600
    },
    {
      "epoch": 13.687951807228917,
      "grad_norm": 0.4032200872898102,
      "learning_rate": 6.312048192771086e-06,
      "loss": 0.0141,
      "step": 113610
    },
    {
      "epoch": 13.689156626506024,
      "grad_norm": 0.20707134902477264,
      "learning_rate": 6.310843373493976e-06,
      "loss": 0.0132,
      "step": 113620
    },
    {
      "epoch": 13.690361445783132,
      "grad_norm": 0.509859025478363,
      "learning_rate": 6.309638554216868e-06,
      "loss": 0.0179,
      "step": 113630
    },
    {
      "epoch": 13.69156626506024,
      "grad_norm": 0.6223639249801636,
      "learning_rate": 6.3084337349397596e-06,
      "loss": 0.005,
      "step": 113640
    },
    {
      "epoch": 13.69277108433735,
      "grad_norm": 0.006517952773720026,
      "learning_rate": 6.307228915662651e-06,
      "loss": 0.0069,
      "step": 113650
    },
    {
      "epoch": 13.693975903614458,
      "grad_norm": 0.1004776582121849,
      "learning_rate": 6.306024096385543e-06,
      "loss": 0.0084,
      "step": 113660
    },
    {
      "epoch": 13.695180722891566,
      "grad_norm": 1.6368494033813477,
      "learning_rate": 6.3048192771084335e-06,
      "loss": 0.012,
      "step": 113670
    },
    {
      "epoch": 13.696385542168674,
      "grad_norm": 0.29593291878700256,
      "learning_rate": 6.303614457831326e-06,
      "loss": 0.0062,
      "step": 113680
    },
    {
      "epoch": 13.697590361445783,
      "grad_norm": 1.1132385730743408,
      "learning_rate": 6.3024096385542175e-06,
      "loss": 0.0196,
      "step": 113690
    },
    {
      "epoch": 13.698795180722891,
      "grad_norm": 0.0005099914851598442,
      "learning_rate": 6.301204819277109e-06,
      "loss": 0.0142,
      "step": 113700
    },
    {
      "epoch": 13.7,
      "grad_norm": 0.0008257010485976934,
      "learning_rate": 6.300000000000001e-06,
      "loss": 0.0036,
      "step": 113710
    },
    {
      "epoch": 13.701204819277109,
      "grad_norm": 0.023646587505936623,
      "learning_rate": 6.298795180722892e-06,
      "loss": 0.0296,
      "step": 113720
    },
    {
      "epoch": 13.702409638554217,
      "grad_norm": 0.16571851074695587,
      "learning_rate": 6.297590361445783e-06,
      "loss": 0.0426,
      "step": 113730
    },
    {
      "epoch": 13.703614457831325,
      "grad_norm": 11.408406257629395,
      "learning_rate": 6.296385542168675e-06,
      "loss": 0.0214,
      "step": 113740
    },
    {
      "epoch": 13.704819277108435,
      "grad_norm": 0.006645368877798319,
      "learning_rate": 6.295180722891566e-06,
      "loss": 0.0124,
      "step": 113750
    },
    {
      "epoch": 13.706024096385542,
      "grad_norm": 66.61454772949219,
      "learning_rate": 6.293975903614459e-06,
      "loss": 0.049,
      "step": 113760
    },
    {
      "epoch": 13.70722891566265,
      "grad_norm": 0.004687564913183451,
      "learning_rate": 6.29277108433735e-06,
      "loss": 0.0122,
      "step": 113770
    },
    {
      "epoch": 13.708433734939758,
      "grad_norm": 0.0005318615003488958,
      "learning_rate": 6.291566265060242e-06,
      "loss": 0.0,
      "step": 113780
    },
    {
      "epoch": 13.709638554216868,
      "grad_norm": 0.0003260110679548234,
      "learning_rate": 6.290361445783133e-06,
      "loss": 0.033,
      "step": 113790
    },
    {
      "epoch": 13.710843373493976,
      "grad_norm": 0.0003403309383429587,
      "learning_rate": 6.289156626506024e-06,
      "loss": 0.0074,
      "step": 113800
    },
    {
      "epoch": 13.712048192771084,
      "grad_norm": 0.0008675731369294226,
      "learning_rate": 6.287951807228916e-06,
      "loss": 0.0041,
      "step": 113810
    },
    {
      "epoch": 13.713253012048193,
      "grad_norm": 0.1288454234600067,
      "learning_rate": 6.286746987951807e-06,
      "loss": 0.0022,
      "step": 113820
    },
    {
      "epoch": 13.714457831325301,
      "grad_norm": 0.08897840231657028,
      "learning_rate": 6.2855421686747e-06,
      "loss": 0.0071,
      "step": 113830
    },
    {
      "epoch": 13.71566265060241,
      "grad_norm": 8.279389381408691,
      "learning_rate": 6.284337349397591e-06,
      "loss": 0.0078,
      "step": 113840
    },
    {
      "epoch": 13.716867469879517,
      "grad_norm": 0.0005847843713127077,
      "learning_rate": 6.283132530120483e-06,
      "loss": 0.0152,
      "step": 113850
    },
    {
      "epoch": 13.718072289156627,
      "grad_norm": 0.04959521070122719,
      "learning_rate": 6.281927710843374e-06,
      "loss": 0.019,
      "step": 113860
    },
    {
      "epoch": 13.719277108433735,
      "grad_norm": 0.2579006254673004,
      "learning_rate": 6.280722891566265e-06,
      "loss": 0.0113,
      "step": 113870
    },
    {
      "epoch": 13.720481927710843,
      "grad_norm": 0.0015087398933246732,
      "learning_rate": 6.279518072289157e-06,
      "loss": 0.0093,
      "step": 113880
    },
    {
      "epoch": 13.721686746987952,
      "grad_norm": 0.07815861701965332,
      "learning_rate": 6.278313253012048e-06,
      "loss": 0.0234,
      "step": 113890
    },
    {
      "epoch": 13.72289156626506,
      "grad_norm": 1.8945081233978271,
      "learning_rate": 6.27710843373494e-06,
      "loss": 0.0336,
      "step": 113900
    },
    {
      "epoch": 13.724096385542168,
      "grad_norm": 0.8910225033760071,
      "learning_rate": 6.2759036144578324e-06,
      "loss": 0.0443,
      "step": 113910
    },
    {
      "epoch": 13.725301204819278,
      "grad_norm": 0.4562036991119385,
      "learning_rate": 6.274698795180724e-06,
      "loss": 0.0212,
      "step": 113920
    },
    {
      "epoch": 13.726506024096386,
      "grad_norm": 0.0008985131862573326,
      "learning_rate": 6.273493975903615e-06,
      "loss": 0.0073,
      "step": 113930
    },
    {
      "epoch": 13.727710843373494,
      "grad_norm": 0.0057308427058160305,
      "learning_rate": 6.272289156626506e-06,
      "loss": 0.0286,
      "step": 113940
    },
    {
      "epoch": 13.728915662650602,
      "grad_norm": 0.0027317567728459835,
      "learning_rate": 6.271084337349398e-06,
      "loss": 0.0049,
      "step": 113950
    },
    {
      "epoch": 13.730120481927711,
      "grad_norm": 0.0068940832279622555,
      "learning_rate": 6.2698795180722895e-06,
      "loss": 0.0315,
      "step": 113960
    },
    {
      "epoch": 13.73132530120482,
      "grad_norm": 0.0006544457282871008,
      "learning_rate": 6.268674698795181e-06,
      "loss": 0.0129,
      "step": 113970
    },
    {
      "epoch": 13.732530120481927,
      "grad_norm": 0.05579841881990433,
      "learning_rate": 6.2674698795180735e-06,
      "loss": 0.0057,
      "step": 113980
    },
    {
      "epoch": 13.733734939759037,
      "grad_norm": 1.0212335586547852,
      "learning_rate": 6.266265060240964e-06,
      "loss": 0.0315,
      "step": 113990
    },
    {
      "epoch": 13.734939759036145,
      "grad_norm": 0.0012154370779171586,
      "learning_rate": 6.265060240963856e-06,
      "loss": 0.0264,
      "step": 114000
    },
    {
      "epoch": 13.736144578313253,
      "grad_norm": 0.0008451915346086025,
      "learning_rate": 6.2638554216867475e-06,
      "loss": 0.0307,
      "step": 114010
    },
    {
      "epoch": 13.73734939759036,
      "grad_norm": 0.0005707332165911794,
      "learning_rate": 6.262650602409639e-06,
      "loss": 0.0116,
      "step": 114020
    },
    {
      "epoch": 13.73855421686747,
      "grad_norm": 0.9797753095626831,
      "learning_rate": 6.261445783132531e-06,
      "loss": 0.015,
      "step": 114030
    },
    {
      "epoch": 13.739759036144578,
      "grad_norm": 3.4814043045043945,
      "learning_rate": 6.260240963855421e-06,
      "loss": 0.0162,
      "step": 114040
    },
    {
      "epoch": 13.740963855421686,
      "grad_norm": 5.3990654945373535,
      "learning_rate": 6.259036144578313e-06,
      "loss": 0.0025,
      "step": 114050
    },
    {
      "epoch": 13.742168674698796,
      "grad_norm": 0.8790785670280457,
      "learning_rate": 6.257831325301205e-06,
      "loss": 0.0203,
      "step": 114060
    },
    {
      "epoch": 13.743373493975904,
      "grad_norm": 0.04282458871603012,
      "learning_rate": 6.256626506024097e-06,
      "loss": 0.012,
      "step": 114070
    },
    {
      "epoch": 13.744578313253012,
      "grad_norm": 0.0050387270748615265,
      "learning_rate": 6.255421686746989e-06,
      "loss": 0.009,
      "step": 114080
    },
    {
      "epoch": 13.745783132530121,
      "grad_norm": 0.0011010735761374235,
      "learning_rate": 6.25421686746988e-06,
      "loss": 0.0282,
      "step": 114090
    },
    {
      "epoch": 13.74698795180723,
      "grad_norm": 0.00427863746881485,
      "learning_rate": 6.253012048192772e-06,
      "loss": 0.0134,
      "step": 114100
    },
    {
      "epoch": 13.748192771084337,
      "grad_norm": 6.937154769897461,
      "learning_rate": 6.2518072289156625e-06,
      "loss": 0.0434,
      "step": 114110
    },
    {
      "epoch": 13.749397590361445,
      "grad_norm": 0.7549993991851807,
      "learning_rate": 6.250602409638554e-06,
      "loss": 0.0076,
      "step": 114120
    },
    {
      "epoch": 13.750602409638555,
      "grad_norm": 4.031022548675537,
      "learning_rate": 6.2493975903614465e-06,
      "loss": 0.0163,
      "step": 114130
    },
    {
      "epoch": 13.751807228915663,
      "grad_norm": 0.2978106141090393,
      "learning_rate": 6.248192771084338e-06,
      "loss": 0.0104,
      "step": 114140
    },
    {
      "epoch": 13.75301204819277,
      "grad_norm": 0.04937583580613136,
      "learning_rate": 6.24698795180723e-06,
      "loss": 0.0231,
      "step": 114150
    },
    {
      "epoch": 13.754216867469879,
      "grad_norm": 0.003368114586919546,
      "learning_rate": 6.245783132530121e-06,
      "loss": 0.0146,
      "step": 114160
    },
    {
      "epoch": 13.755421686746988,
      "grad_norm": 0.0013468017568811774,
      "learning_rate": 6.244578313253013e-06,
      "loss": 0.0087,
      "step": 114170
    },
    {
      "epoch": 13.756626506024096,
      "grad_norm": 0.0008677514852024615,
      "learning_rate": 6.243373493975904e-06,
      "loss": 0.0085,
      "step": 114180
    },
    {
      "epoch": 13.757831325301204,
      "grad_norm": 1.54654061794281,
      "learning_rate": 6.242168674698795e-06,
      "loss": 0.0092,
      "step": 114190
    },
    {
      "epoch": 13.759036144578314,
      "grad_norm": 0.004348860587924719,
      "learning_rate": 6.240963855421688e-06,
      "loss": 0.0144,
      "step": 114200
    },
    {
      "epoch": 13.760240963855422,
      "grad_norm": 0.2332264631986618,
      "learning_rate": 6.239759036144579e-06,
      "loss": 0.0045,
      "step": 114210
    },
    {
      "epoch": 13.76144578313253,
      "grad_norm": 0.0011073409114032984,
      "learning_rate": 6.238554216867471e-06,
      "loss": 0.0219,
      "step": 114220
    },
    {
      "epoch": 13.76265060240964,
      "grad_norm": 0.04656975343823433,
      "learning_rate": 6.237349397590362e-06,
      "loss": 0.0166,
      "step": 114230
    },
    {
      "epoch": 13.763855421686747,
      "grad_norm": 0.007098707836121321,
      "learning_rate": 6.236144578313253e-06,
      "loss": 0.0376,
      "step": 114240
    },
    {
      "epoch": 13.765060240963855,
      "grad_norm": 0.0061426288448274136,
      "learning_rate": 6.234939759036145e-06,
      "loss": 0.0068,
      "step": 114250
    },
    {
      "epoch": 13.766265060240963,
      "grad_norm": 0.8096385598182678,
      "learning_rate": 6.233734939759036e-06,
      "loss": 0.0165,
      "step": 114260
    },
    {
      "epoch": 13.767469879518073,
      "grad_norm": 16.017118453979492,
      "learning_rate": 6.232530120481928e-06,
      "loss": 0.0138,
      "step": 114270
    },
    {
      "epoch": 13.76867469879518,
      "grad_norm": 0.6501350998878479,
      "learning_rate": 6.23132530120482e-06,
      "loss": 0.0088,
      "step": 114280
    },
    {
      "epoch": 13.769879518072289,
      "grad_norm": 0.4915400445461273,
      "learning_rate": 6.230120481927712e-06,
      "loss": 0.0273,
      "step": 114290
    },
    {
      "epoch": 13.771084337349398,
      "grad_norm": 0.0009628668194636703,
      "learning_rate": 6.2289156626506035e-06,
      "loss": 0.015,
      "step": 114300
    },
    {
      "epoch": 13.772289156626506,
      "grad_norm": 0.7194310426712036,
      "learning_rate": 6.227710843373494e-06,
      "loss": 0.004,
      "step": 114310
    },
    {
      "epoch": 13.773493975903614,
      "grad_norm": 0.0005807853885926306,
      "learning_rate": 6.226506024096386e-06,
      "loss": 0.0284,
      "step": 114320
    },
    {
      "epoch": 13.774698795180722,
      "grad_norm": 8.388134956359863,
      "learning_rate": 6.2253012048192774e-06,
      "loss": 0.0385,
      "step": 114330
    },
    {
      "epoch": 13.775903614457832,
      "grad_norm": 1.0601954460144043,
      "learning_rate": 6.224096385542169e-06,
      "loss": 0.021,
      "step": 114340
    },
    {
      "epoch": 13.77710843373494,
      "grad_norm": 0.0011198496213182807,
      "learning_rate": 6.2228915662650615e-06,
      "loss": 0.006,
      "step": 114350
    },
    {
      "epoch": 13.778313253012048,
      "grad_norm": 0.019448895007371902,
      "learning_rate": 6.221686746987953e-06,
      "loss": 0.0405,
      "step": 114360
    },
    {
      "epoch": 13.779518072289157,
      "grad_norm": 0.6249839067459106,
      "learning_rate": 6.220481927710844e-06,
      "loss": 0.012,
      "step": 114370
    },
    {
      "epoch": 13.780722891566265,
      "grad_norm": 0.0008214652189053595,
      "learning_rate": 6.219277108433735e-06,
      "loss": 0.0164,
      "step": 114380
    },
    {
      "epoch": 13.781927710843373,
      "grad_norm": 1.9850668907165527,
      "learning_rate": 6.218072289156627e-06,
      "loss": 0.0095,
      "step": 114390
    },
    {
      "epoch": 13.783132530120483,
      "grad_norm": 0.009557186625897884,
      "learning_rate": 6.2168674698795185e-06,
      "loss": 0.0163,
      "step": 114400
    },
    {
      "epoch": 13.78433734939759,
      "grad_norm": 0.23534515500068665,
      "learning_rate": 6.21566265060241e-06,
      "loss": 0.0059,
      "step": 114410
    },
    {
      "epoch": 13.785542168674699,
      "grad_norm": 0.8808533549308777,
      "learning_rate": 6.214457831325301e-06,
      "loss": 0.0228,
      "step": 114420
    },
    {
      "epoch": 13.786746987951807,
      "grad_norm": 0.27440810203552246,
      "learning_rate": 6.213253012048194e-06,
      "loss": 0.0135,
      "step": 114430
    },
    {
      "epoch": 13.787951807228916,
      "grad_norm": 0.26596155762672424,
      "learning_rate": 6.212048192771085e-06,
      "loss": 0.0474,
      "step": 114440
    },
    {
      "epoch": 13.789156626506024,
      "grad_norm": 0.29314786195755005,
      "learning_rate": 6.2108433734939765e-06,
      "loss": 0.003,
      "step": 114450
    },
    {
      "epoch": 13.790361445783132,
      "grad_norm": 0.5165969729423523,
      "learning_rate": 6.209638554216868e-06,
      "loss": 0.0115,
      "step": 114460
    },
    {
      "epoch": 13.791566265060242,
      "grad_norm": 0.1135471984744072,
      "learning_rate": 6.20843373493976e-06,
      "loss": 0.0406,
      "step": 114470
    },
    {
      "epoch": 13.79277108433735,
      "grad_norm": 0.0012229131534695625,
      "learning_rate": 6.207228915662651e-06,
      "loss": 0.0035,
      "step": 114480
    },
    {
      "epoch": 13.793975903614458,
      "grad_norm": 0.1686592549085617,
      "learning_rate": 6.206024096385542e-06,
      "loss": 0.0071,
      "step": 114490
    },
    {
      "epoch": 13.795180722891565,
      "grad_norm": 0.00710968067869544,
      "learning_rate": 6.2048192771084344e-06,
      "loss": 0.0063,
      "step": 114500
    },
    {
      "epoch": 13.796385542168675,
      "grad_norm": 1.4755266904830933,
      "learning_rate": 6.203614457831326e-06,
      "loss": 0.0129,
      "step": 114510
    },
    {
      "epoch": 13.797590361445783,
      "grad_norm": 1.7044639587402344,
      "learning_rate": 6.202409638554218e-06,
      "loss": 0.0236,
      "step": 114520
    },
    {
      "epoch": 13.798795180722891,
      "grad_norm": 0.15664291381835938,
      "learning_rate": 6.201204819277109e-06,
      "loss": 0.0087,
      "step": 114530
    },
    {
      "epoch": 13.8,
      "grad_norm": 2.28094482421875,
      "learning_rate": 6.200000000000001e-06,
      "loss": 0.0157,
      "step": 114540
    },
    {
      "epoch": 13.801204819277109,
      "grad_norm": 0.005671743769198656,
      "learning_rate": 6.1987951807228915e-06,
      "loss": 0.0129,
      "step": 114550
    },
    {
      "epoch": 13.802409638554217,
      "grad_norm": 0.0008125916356220841,
      "learning_rate": 6.197590361445783e-06,
      "loss": 0.0169,
      "step": 114560
    },
    {
      "epoch": 13.803614457831326,
      "grad_norm": 0.0026711474638432264,
      "learning_rate": 6.196385542168675e-06,
      "loss": 0.0164,
      "step": 114570
    },
    {
      "epoch": 13.804819277108434,
      "grad_norm": 0.41327476501464844,
      "learning_rate": 6.195180722891567e-06,
      "loss": 0.0128,
      "step": 114580
    },
    {
      "epoch": 13.806024096385542,
      "grad_norm": 0.0015766264405101538,
      "learning_rate": 6.193975903614459e-06,
      "loss": 0.0128,
      "step": 114590
    },
    {
      "epoch": 13.80722891566265,
      "grad_norm": 0.03270972520112991,
      "learning_rate": 6.19277108433735e-06,
      "loss": 0.0092,
      "step": 114600
    },
    {
      "epoch": 13.80843373493976,
      "grad_norm": 0.00044296670239418745,
      "learning_rate": 6.191566265060242e-06,
      "loss": 0.0061,
      "step": 114610
    },
    {
      "epoch": 13.809638554216868,
      "grad_norm": 0.0006061196327209473,
      "learning_rate": 6.190361445783133e-06,
      "loss": 0.0645,
      "step": 114620
    },
    {
      "epoch": 13.810843373493976,
      "grad_norm": 0.28516075015068054,
      "learning_rate": 6.189156626506024e-06,
      "loss": 0.0232,
      "step": 114630
    },
    {
      "epoch": 13.812048192771083,
      "grad_norm": 0.0008685839711688459,
      "learning_rate": 6.187951807228916e-06,
      "loss": 0.0056,
      "step": 114640
    },
    {
      "epoch": 13.813253012048193,
      "grad_norm": 1.6547454595565796,
      "learning_rate": 6.186746987951808e-06,
      "loss": 0.0529,
      "step": 114650
    },
    {
      "epoch": 13.814457831325301,
      "grad_norm": 0.0018873026128858328,
      "learning_rate": 6.1855421686747e-06,
      "loss": 0.0495,
      "step": 114660
    },
    {
      "epoch": 13.815662650602409,
      "grad_norm": 0.013221107423305511,
      "learning_rate": 6.184337349397591e-06,
      "loss": 0.0194,
      "step": 114670
    },
    {
      "epoch": 13.816867469879519,
      "grad_norm": 1.3540935516357422,
      "learning_rate": 6.183132530120482e-06,
      "loss": 0.0166,
      "step": 114680
    },
    {
      "epoch": 13.818072289156627,
      "grad_norm": 0.010200509801506996,
      "learning_rate": 6.181927710843374e-06,
      "loss": 0.0041,
      "step": 114690
    },
    {
      "epoch": 13.819277108433734,
      "grad_norm": 0.00273426016792655,
      "learning_rate": 6.180722891566265e-06,
      "loss": 0.0062,
      "step": 114700
    },
    {
      "epoch": 13.820481927710844,
      "grad_norm": 0.8481647968292236,
      "learning_rate": 6.179518072289157e-06,
      "loss": 0.0262,
      "step": 114710
    },
    {
      "epoch": 13.821686746987952,
      "grad_norm": 0.3366699814796448,
      "learning_rate": 6.1783132530120485e-06,
      "loss": 0.0045,
      "step": 114720
    },
    {
      "epoch": 13.82289156626506,
      "grad_norm": 1.3441517353057861,
      "learning_rate": 6.177108433734941e-06,
      "loss": 0.0255,
      "step": 114730
    },
    {
      "epoch": 13.824096385542168,
      "grad_norm": 0.21931666135787964,
      "learning_rate": 6.1759036144578325e-06,
      "loss": 0.0089,
      "step": 114740
    },
    {
      "epoch": 13.825301204819278,
      "grad_norm": 0.5160890221595764,
      "learning_rate": 6.174698795180723e-06,
      "loss": 0.009,
      "step": 114750
    },
    {
      "epoch": 13.826506024096386,
      "grad_norm": 0.04285658150911331,
      "learning_rate": 6.173493975903615e-06,
      "loss": 0.0139,
      "step": 114760
    },
    {
      "epoch": 13.827710843373493,
      "grad_norm": 0.8458296060562134,
      "learning_rate": 6.1722891566265065e-06,
      "loss": 0.0155,
      "step": 114770
    },
    {
      "epoch": 13.828915662650603,
      "grad_norm": 0.0008267438970506191,
      "learning_rate": 6.171084337349398e-06,
      "loss": 0.0074,
      "step": 114780
    },
    {
      "epoch": 13.830120481927711,
      "grad_norm": 0.33770349621772766,
      "learning_rate": 6.16987951807229e-06,
      "loss": 0.0154,
      "step": 114790
    },
    {
      "epoch": 13.831325301204819,
      "grad_norm": 0.9820676445960999,
      "learning_rate": 6.168674698795182e-06,
      "loss": 0.009,
      "step": 114800
    },
    {
      "epoch": 13.832530120481927,
      "grad_norm": 0.000919615791644901,
      "learning_rate": 6.167469879518073e-06,
      "loss": 0.0073,
      "step": 114810
    },
    {
      "epoch": 13.833734939759037,
      "grad_norm": 82.71821594238281,
      "learning_rate": 6.166265060240964e-06,
      "loss": 0.0173,
      "step": 114820
    },
    {
      "epoch": 13.834939759036144,
      "grad_norm": 0.0005077943787910044,
      "learning_rate": 6.165060240963856e-06,
      "loss": 0.0075,
      "step": 114830
    },
    {
      "epoch": 13.836144578313252,
      "grad_norm": 0.5465387105941772,
      "learning_rate": 6.1638554216867476e-06,
      "loss": 0.0061,
      "step": 114840
    },
    {
      "epoch": 13.837349397590362,
      "grad_norm": 0.4765743017196655,
      "learning_rate": 6.162650602409639e-06,
      "loss": 0.0144,
      "step": 114850
    },
    {
      "epoch": 13.83855421686747,
      "grad_norm": 2.3131446838378906,
      "learning_rate": 6.16144578313253e-06,
      "loss": 0.0557,
      "step": 114860
    },
    {
      "epoch": 13.839759036144578,
      "grad_norm": 2.9992828369140625,
      "learning_rate": 6.1602409638554215e-06,
      "loss": 0.0533,
      "step": 114870
    },
    {
      "epoch": 13.840963855421688,
      "grad_norm": 0.006697922013700008,
      "learning_rate": 6.159036144578314e-06,
      "loss": 0.0094,
      "step": 114880
    },
    {
      "epoch": 13.842168674698796,
      "grad_norm": 0.0009826009627431631,
      "learning_rate": 6.1578313253012055e-06,
      "loss": 0.011,
      "step": 114890
    },
    {
      "epoch": 13.843373493975903,
      "grad_norm": 0.5524390339851379,
      "learning_rate": 6.156626506024097e-06,
      "loss": 0.0189,
      "step": 114900
    },
    {
      "epoch": 13.844578313253011,
      "grad_norm": 0.001227404223755002,
      "learning_rate": 6.155421686746989e-06,
      "loss": 0.0079,
      "step": 114910
    },
    {
      "epoch": 13.845783132530121,
      "grad_norm": 0.0016250374028459191,
      "learning_rate": 6.15421686746988e-06,
      "loss": 0.0077,
      "step": 114920
    },
    {
      "epoch": 13.846987951807229,
      "grad_norm": 0.053086232393980026,
      "learning_rate": 6.153012048192771e-06,
      "loss": 0.0048,
      "step": 114930
    },
    {
      "epoch": 13.848192771084337,
      "grad_norm": 0.22662758827209473,
      "learning_rate": 6.151807228915663e-06,
      "loss": 0.0005,
      "step": 114940
    },
    {
      "epoch": 13.849397590361447,
      "grad_norm": 2.771144151687622,
      "learning_rate": 6.150602409638555e-06,
      "loss": 0.0279,
      "step": 114950
    },
    {
      "epoch": 13.850602409638554,
      "grad_norm": 0.0022387972567230463,
      "learning_rate": 6.149397590361447e-06,
      "loss": 0.0297,
      "step": 114960
    },
    {
      "epoch": 13.851807228915662,
      "grad_norm": 0.0010154879419133067,
      "learning_rate": 6.148192771084338e-06,
      "loss": 0.0004,
      "step": 114970
    },
    {
      "epoch": 13.85301204819277,
      "grad_norm": 0.19274358451366425,
      "learning_rate": 6.14698795180723e-06,
      "loss": 0.0041,
      "step": 114980
    },
    {
      "epoch": 13.85421686746988,
      "grad_norm": 0.00423054676502943,
      "learning_rate": 6.1457831325301205e-06,
      "loss": 0.0066,
      "step": 114990
    },
    {
      "epoch": 13.855421686746988,
      "grad_norm": 0.0035640837159007788,
      "learning_rate": 6.144578313253012e-06,
      "loss": 0.0242,
      "step": 115000
    },
    {
      "epoch": 13.856626506024096,
      "grad_norm": 0.05481131374835968,
      "learning_rate": 6.143373493975904e-06,
      "loss": 0.0612,
      "step": 115010
    },
    {
      "epoch": 13.857831325301206,
      "grad_norm": 0.01009525265544653,
      "learning_rate": 6.142168674698795e-06,
      "loss": 0.0127,
      "step": 115020
    },
    {
      "epoch": 13.859036144578313,
      "grad_norm": 0.0007656548405066133,
      "learning_rate": 6.140963855421688e-06,
      "loss": 0.0129,
      "step": 115030
    },
    {
      "epoch": 13.860240963855421,
      "grad_norm": 0.0004932031151838601,
      "learning_rate": 6.139759036144579e-06,
      "loss": 0.0114,
      "step": 115040
    },
    {
      "epoch": 13.861445783132531,
      "grad_norm": 1.8311442136764526,
      "learning_rate": 6.138554216867471e-06,
      "loss": 0.0302,
      "step": 115050
    },
    {
      "epoch": 13.862650602409639,
      "grad_norm": 1.0523526668548584,
      "learning_rate": 6.137349397590362e-06,
      "loss": 0.003,
      "step": 115060
    },
    {
      "epoch": 13.863855421686747,
      "grad_norm": 0.0020916706416755915,
      "learning_rate": 6.136144578313253e-06,
      "loss": 0.0287,
      "step": 115070
    },
    {
      "epoch": 13.865060240963855,
      "grad_norm": 1.0567041635513306,
      "learning_rate": 6.134939759036145e-06,
      "loss": 0.0351,
      "step": 115080
    },
    {
      "epoch": 13.866265060240965,
      "grad_norm": 0.25742098689079285,
      "learning_rate": 6.1337349397590364e-06,
      "loss": 0.0207,
      "step": 115090
    },
    {
      "epoch": 13.867469879518072,
      "grad_norm": 0.003630557795986533,
      "learning_rate": 6.132530120481929e-06,
      "loss": 0.0026,
      "step": 115100
    },
    {
      "epoch": 13.86867469879518,
      "grad_norm": 1.0298960208892822,
      "learning_rate": 6.1313253012048204e-06,
      "loss": 0.0075,
      "step": 115110
    },
    {
      "epoch": 13.869879518072288,
      "grad_norm": 1.6098531484603882,
      "learning_rate": 6.130120481927711e-06,
      "loss": 0.0385,
      "step": 115120
    },
    {
      "epoch": 13.871084337349398,
      "grad_norm": 0.00867382064461708,
      "learning_rate": 6.128915662650603e-06,
      "loss": 0.0037,
      "step": 115130
    },
    {
      "epoch": 13.872289156626506,
      "grad_norm": 0.002121193800121546,
      "learning_rate": 6.127710843373494e-06,
      "loss": 0.0028,
      "step": 115140
    },
    {
      "epoch": 13.873493975903614,
      "grad_norm": 0.40213948488235474,
      "learning_rate": 6.126506024096386e-06,
      "loss": 0.0012,
      "step": 115150
    },
    {
      "epoch": 13.874698795180723,
      "grad_norm": 0.0010068961419165134,
      "learning_rate": 6.1253012048192775e-06,
      "loss": 0.0213,
      "step": 115160
    },
    {
      "epoch": 13.875903614457831,
      "grad_norm": 0.25523093342781067,
      "learning_rate": 6.124096385542168e-06,
      "loss": 0.0173,
      "step": 115170
    },
    {
      "epoch": 13.87710843373494,
      "grad_norm": 0.3229495882987976,
      "learning_rate": 6.1228915662650616e-06,
      "loss": 0.0165,
      "step": 115180
    },
    {
      "epoch": 13.878313253012049,
      "grad_norm": 0.030637532472610474,
      "learning_rate": 6.121686746987952e-06,
      "loss": 0.0045,
      "step": 115190
    },
    {
      "epoch": 13.879518072289157,
      "grad_norm": 0.0005404541152529418,
      "learning_rate": 6.120481927710844e-06,
      "loss": 0.0069,
      "step": 115200
    },
    {
      "epoch": 13.880722891566265,
      "grad_norm": 0.998522937297821,
      "learning_rate": 6.1192771084337355e-06,
      "loss": 0.0172,
      "step": 115210
    },
    {
      "epoch": 13.881927710843373,
      "grad_norm": 0.8794722557067871,
      "learning_rate": 6.118072289156627e-06,
      "loss": 0.0111,
      "step": 115220
    },
    {
      "epoch": 13.883132530120482,
      "grad_norm": 0.006069826893508434,
      "learning_rate": 6.116867469879519e-06,
      "loss": 0.0016,
      "step": 115230
    },
    {
      "epoch": 13.88433734939759,
      "grad_norm": 0.004371072631329298,
      "learning_rate": 6.115662650602409e-06,
      "loss": 0.0091,
      "step": 115240
    },
    {
      "epoch": 13.885542168674698,
      "grad_norm": 0.006676806602627039,
      "learning_rate": 6.114457831325302e-06,
      "loss": 0.0094,
      "step": 115250
    },
    {
      "epoch": 13.886746987951808,
      "grad_norm": 3.124661445617676,
      "learning_rate": 6.113253012048193e-06,
      "loss": 0.0178,
      "step": 115260
    },
    {
      "epoch": 13.887951807228916,
      "grad_norm": 0.2716597020626068,
      "learning_rate": 6.112048192771085e-06,
      "loss": 0.0081,
      "step": 115270
    },
    {
      "epoch": 13.889156626506024,
      "grad_norm": 0.06011511757969856,
      "learning_rate": 6.110843373493977e-06,
      "loss": 0.0221,
      "step": 115280
    },
    {
      "epoch": 13.890361445783132,
      "grad_norm": 0.0013365469640120864,
      "learning_rate": 6.109638554216868e-06,
      "loss": 0.0307,
      "step": 115290
    },
    {
      "epoch": 13.891566265060241,
      "grad_norm": 1.5319269895553589,
      "learning_rate": 6.108433734939759e-06,
      "loss": 0.0305,
      "step": 115300
    },
    {
      "epoch": 13.89277108433735,
      "grad_norm": 0.007281409110873938,
      "learning_rate": 6.1072289156626505e-06,
      "loss": 0.0087,
      "step": 115310
    },
    {
      "epoch": 13.893975903614457,
      "grad_norm": 0.017149947583675385,
      "learning_rate": 6.106024096385542e-06,
      "loss": 0.0141,
      "step": 115320
    },
    {
      "epoch": 13.895180722891567,
      "grad_norm": 1.0294920206069946,
      "learning_rate": 6.1048192771084345e-06,
      "loss": 0.0329,
      "step": 115330
    },
    {
      "epoch": 13.896385542168675,
      "grad_norm": 0.0008671464747749269,
      "learning_rate": 6.103614457831326e-06,
      "loss": 0.0064,
      "step": 115340
    },
    {
      "epoch": 13.897590361445783,
      "grad_norm": 0.16026484966278076,
      "learning_rate": 6.102409638554218e-06,
      "loss": 0.0102,
      "step": 115350
    },
    {
      "epoch": 13.898795180722892,
      "grad_norm": 0.00671788863837719,
      "learning_rate": 6.101204819277109e-06,
      "loss": 0.0024,
      "step": 115360
    },
    {
      "epoch": 13.9,
      "grad_norm": 0.4711299240589142,
      "learning_rate": 6.1e-06,
      "loss": 0.0069,
      "step": 115370
    },
    {
      "epoch": 13.901204819277108,
      "grad_norm": 0.07250825315713882,
      "learning_rate": 6.098795180722892e-06,
      "loss": 0.0153,
      "step": 115380
    },
    {
      "epoch": 13.902409638554216,
      "grad_norm": 0.002043104963377118,
      "learning_rate": 6.097590361445783e-06,
      "loss": 0.0069,
      "step": 115390
    },
    {
      "epoch": 13.903614457831326,
      "grad_norm": 0.03141921013593674,
      "learning_rate": 6.096385542168676e-06,
      "loss": 0.0034,
      "step": 115400
    },
    {
      "epoch": 13.904819277108434,
      "grad_norm": 3.0251004695892334,
      "learning_rate": 6.095180722891567e-06,
      "loss": 0.0144,
      "step": 115410
    },
    {
      "epoch": 13.906024096385542,
      "grad_norm": 0.00026908720610663295,
      "learning_rate": 6.093975903614459e-06,
      "loss": 0.0142,
      "step": 115420
    },
    {
      "epoch": 13.907228915662651,
      "grad_norm": 0.0004896667087450624,
      "learning_rate": 6.0927710843373496e-06,
      "loss": 0.0248,
      "step": 115430
    },
    {
      "epoch": 13.90843373493976,
      "grad_norm": 0.002330539980903268,
      "learning_rate": 6.091566265060241e-06,
      "loss": 0.0487,
      "step": 115440
    },
    {
      "epoch": 13.909638554216867,
      "grad_norm": 0.6089106202125549,
      "learning_rate": 6.090361445783133e-06,
      "loss": 0.0068,
      "step": 115450
    },
    {
      "epoch": 13.910843373493975,
      "grad_norm": 0.0032774745486676693,
      "learning_rate": 6.089156626506024e-06,
      "loss": 0.0039,
      "step": 115460
    },
    {
      "epoch": 13.912048192771085,
      "grad_norm": 0.0005497833481058478,
      "learning_rate": 6.087951807228916e-06,
      "loss": 0.0066,
      "step": 115470
    },
    {
      "epoch": 13.913253012048193,
      "grad_norm": 3.0512170791625977,
      "learning_rate": 6.086746987951808e-06,
      "loss": 0.025,
      "step": 115480
    },
    {
      "epoch": 13.9144578313253,
      "grad_norm": 0.007721531670540571,
      "learning_rate": 6.0855421686747e-06,
      "loss": 0.0246,
      "step": 115490
    },
    {
      "epoch": 13.91566265060241,
      "grad_norm": 0.000702126300893724,
      "learning_rate": 6.084337349397591e-06,
      "loss": 0.0159,
      "step": 115500
    },
    {
      "epoch": 13.916867469879518,
      "grad_norm": 1.0238008499145508,
      "learning_rate": 6.083132530120482e-06,
      "loss": 0.0294,
      "step": 115510
    },
    {
      "epoch": 13.918072289156626,
      "grad_norm": 1.106582760810852,
      "learning_rate": 6.081927710843374e-06,
      "loss": 0.0114,
      "step": 115520
    },
    {
      "epoch": 13.919277108433734,
      "grad_norm": 0.0015335947973653674,
      "learning_rate": 6.0807228915662654e-06,
      "loss": 0.0022,
      "step": 115530
    },
    {
      "epoch": 13.920481927710844,
      "grad_norm": 0.0010272206272929907,
      "learning_rate": 6.079518072289157e-06,
      "loss": 0.0112,
      "step": 115540
    },
    {
      "epoch": 13.921686746987952,
      "grad_norm": 0.005392192397266626,
      "learning_rate": 6.0783132530120495e-06,
      "loss": 0.0043,
      "step": 115550
    },
    {
      "epoch": 13.92289156626506,
      "grad_norm": 0.0006872758967801929,
      "learning_rate": 6.077108433734941e-06,
      "loss": 0.007,
      "step": 115560
    },
    {
      "epoch": 13.92409638554217,
      "grad_norm": 0.20963583886623383,
      "learning_rate": 6.075903614457832e-06,
      "loss": 0.0131,
      "step": 115570
    },
    {
      "epoch": 13.925301204819277,
      "grad_norm": 0.0006919933366589248,
      "learning_rate": 6.074698795180723e-06,
      "loss": 0.0032,
      "step": 115580
    },
    {
      "epoch": 13.926506024096385,
      "grad_norm": 0.005097114481031895,
      "learning_rate": 6.073493975903615e-06,
      "loss": 0.0151,
      "step": 115590
    },
    {
      "epoch": 13.927710843373493,
      "grad_norm": 0.5835193395614624,
      "learning_rate": 6.0722891566265066e-06,
      "loss": 0.0202,
      "step": 115600
    },
    {
      "epoch": 13.928915662650603,
      "grad_norm": 0.7269241809844971,
      "learning_rate": 6.071084337349397e-06,
      "loss": 0.0203,
      "step": 115610
    },
    {
      "epoch": 13.93012048192771,
      "grad_norm": 0.4866723418235779,
      "learning_rate": 6.069879518072289e-06,
      "loss": 0.0115,
      "step": 115620
    },
    {
      "epoch": 13.931325301204819,
      "grad_norm": 0.0013052980648353696,
      "learning_rate": 6.068674698795181e-06,
      "loss": 0.007,
      "step": 115630
    },
    {
      "epoch": 13.932530120481928,
      "grad_norm": 0.4127081334590912,
      "learning_rate": 6.067469879518073e-06,
      "loss": 0.0083,
      "step": 115640
    },
    {
      "epoch": 13.933734939759036,
      "grad_norm": 0.00024184626818168908,
      "learning_rate": 6.0662650602409645e-06,
      "loss": 0.0211,
      "step": 115650
    },
    {
      "epoch": 13.934939759036144,
      "grad_norm": 1.2028180360794067,
      "learning_rate": 6.065060240963856e-06,
      "loss": 0.0354,
      "step": 115660
    },
    {
      "epoch": 13.936144578313254,
      "grad_norm": 0.0016804178012534976,
      "learning_rate": 6.063855421686748e-06,
      "loss": 0.0104,
      "step": 115670
    },
    {
      "epoch": 13.937349397590362,
      "grad_norm": 0.0011730361729860306,
      "learning_rate": 6.062650602409638e-06,
      "loss": 0.0454,
      "step": 115680
    },
    {
      "epoch": 13.93855421686747,
      "grad_norm": 0.002175729488953948,
      "learning_rate": 6.06144578313253e-06,
      "loss": 0.002,
      "step": 115690
    },
    {
      "epoch": 13.939759036144578,
      "grad_norm": 0.20695853233337402,
      "learning_rate": 6.0602409638554224e-06,
      "loss": 0.0299,
      "step": 115700
    },
    {
      "epoch": 13.940963855421687,
      "grad_norm": 0.0023698110599070787,
      "learning_rate": 6.059036144578314e-06,
      "loss": 0.0323,
      "step": 115710
    },
    {
      "epoch": 13.942168674698795,
      "grad_norm": 0.07146784663200378,
      "learning_rate": 6.057831325301206e-06,
      "loss": 0.0038,
      "step": 115720
    },
    {
      "epoch": 13.943373493975903,
      "grad_norm": 1.5803356170654297,
      "learning_rate": 6.056626506024097e-06,
      "loss": 0.0384,
      "step": 115730
    },
    {
      "epoch": 13.944578313253013,
      "grad_norm": 0.0027250628918409348,
      "learning_rate": 6.055421686746989e-06,
      "loss": 0.0178,
      "step": 115740
    },
    {
      "epoch": 13.94578313253012,
      "grad_norm": 0.019615553319454193,
      "learning_rate": 6.0542168674698795e-06,
      "loss": 0.0176,
      "step": 115750
    },
    {
      "epoch": 13.946987951807229,
      "grad_norm": 0.002223231131210923,
      "learning_rate": 6.053012048192771e-06,
      "loss": 0.0128,
      "step": 115760
    },
    {
      "epoch": 13.948192771084337,
      "grad_norm": 0.0020913968328386545,
      "learning_rate": 6.051807228915663e-06,
      "loss": 0.0173,
      "step": 115770
    },
    {
      "epoch": 13.949397590361446,
      "grad_norm": 0.45345836877822876,
      "learning_rate": 6.050602409638555e-06,
      "loss": 0.0054,
      "step": 115780
    },
    {
      "epoch": 13.950602409638554,
      "grad_norm": 0.7339005470275879,
      "learning_rate": 6.049397590361447e-06,
      "loss": 0.0381,
      "step": 115790
    },
    {
      "epoch": 13.951807228915662,
      "grad_norm": 0.1876184642314911,
      "learning_rate": 6.048192771084338e-06,
      "loss": 0.0193,
      "step": 115800
    },
    {
      "epoch": 13.953012048192772,
      "grad_norm": 1.2576441764831543,
      "learning_rate": 6.046987951807229e-06,
      "loss": 0.0298,
      "step": 115810
    },
    {
      "epoch": 13.95421686746988,
      "grad_norm": 0.010820205323398113,
      "learning_rate": 6.045783132530121e-06,
      "loss": 0.0214,
      "step": 115820
    },
    {
      "epoch": 13.955421686746988,
      "grad_norm": 0.0074603622779250145,
      "learning_rate": 6.044578313253012e-06,
      "loss": 0.0411,
      "step": 115830
    },
    {
      "epoch": 13.956626506024097,
      "grad_norm": 2.068572521209717,
      "learning_rate": 6.043373493975904e-06,
      "loss": 0.013,
      "step": 115840
    },
    {
      "epoch": 13.957831325301205,
      "grad_norm": 10.36998462677002,
      "learning_rate": 6.042168674698796e-06,
      "loss": 0.0207,
      "step": 115850
    },
    {
      "epoch": 13.959036144578313,
      "grad_norm": 0.04139259457588196,
      "learning_rate": 6.040963855421688e-06,
      "loss": 0.0062,
      "step": 115860
    },
    {
      "epoch": 13.960240963855421,
      "grad_norm": 0.00494535593315959,
      "learning_rate": 6.0397590361445794e-06,
      "loss": 0.0063,
      "step": 115870
    },
    {
      "epoch": 13.96144578313253,
      "grad_norm": 0.1528719663619995,
      "learning_rate": 6.03855421686747e-06,
      "loss": 0.0224,
      "step": 115880
    },
    {
      "epoch": 13.962650602409639,
      "grad_norm": 0.00892147608101368,
      "learning_rate": 6.037349397590362e-06,
      "loss": 0.0378,
      "step": 115890
    },
    {
      "epoch": 13.963855421686747,
      "grad_norm": 0.0014219617005437613,
      "learning_rate": 6.036144578313253e-06,
      "loss": 0.0085,
      "step": 115900
    },
    {
      "epoch": 13.965060240963856,
      "grad_norm": 0.020456047728657722,
      "learning_rate": 6.034939759036145e-06,
      "loss": 0.0331,
      "step": 115910
    },
    {
      "epoch": 13.966265060240964,
      "grad_norm": 0.17074871063232422,
      "learning_rate": 6.0337349397590365e-06,
      "loss": 0.0089,
      "step": 115920
    },
    {
      "epoch": 13.967469879518072,
      "grad_norm": 1.042567253112793,
      "learning_rate": 6.032530120481929e-06,
      "loss": 0.0387,
      "step": 115930
    },
    {
      "epoch": 13.96867469879518,
      "grad_norm": 0.004393626470118761,
      "learning_rate": 6.03132530120482e-06,
      "loss": 0.0021,
      "step": 115940
    },
    {
      "epoch": 13.96987951807229,
      "grad_norm": 0.03666774183511734,
      "learning_rate": 6.030120481927711e-06,
      "loss": 0.0179,
      "step": 115950
    },
    {
      "epoch": 13.971084337349398,
      "grad_norm": 0.02966395393013954,
      "learning_rate": 6.028915662650603e-06,
      "loss": 0.0132,
      "step": 115960
    },
    {
      "epoch": 13.972289156626506,
      "grad_norm": 1.05370032787323,
      "learning_rate": 6.0277108433734945e-06,
      "loss": 0.0193,
      "step": 115970
    },
    {
      "epoch": 13.973493975903615,
      "grad_norm": 0.0008807888953015208,
      "learning_rate": 6.026506024096386e-06,
      "loss": 0.0088,
      "step": 115980
    },
    {
      "epoch": 13.974698795180723,
      "grad_norm": 0.8468754887580872,
      "learning_rate": 6.025301204819277e-06,
      "loss": 0.0238,
      "step": 115990
    },
    {
      "epoch": 13.975903614457831,
      "grad_norm": 0.0014378662453964353,
      "learning_rate": 6.02409638554217e-06,
      "loss": 0.0096,
      "step": 116000
    },
    {
      "epoch": 13.977108433734939,
      "grad_norm": 1.191649317741394,
      "learning_rate": 6.022891566265061e-06,
      "loss": 0.0119,
      "step": 116010
    },
    {
      "epoch": 13.978313253012049,
      "grad_norm": 0.826284646987915,
      "learning_rate": 6.021686746987952e-06,
      "loss": 0.014,
      "step": 116020
    },
    {
      "epoch": 13.979518072289157,
      "grad_norm": 0.08546175062656403,
      "learning_rate": 6.020481927710844e-06,
      "loss": 0.0043,
      "step": 116030
    },
    {
      "epoch": 13.980722891566264,
      "grad_norm": 0.9759706258773804,
      "learning_rate": 6.019277108433736e-06,
      "loss": 0.0077,
      "step": 116040
    },
    {
      "epoch": 13.981927710843374,
      "grad_norm": 0.009658727794885635,
      "learning_rate": 6.018072289156627e-06,
      "loss": 0.0077,
      "step": 116050
    },
    {
      "epoch": 13.983132530120482,
      "grad_norm": 1.404152274131775,
      "learning_rate": 6.016867469879518e-06,
      "loss": 0.0424,
      "step": 116060
    },
    {
      "epoch": 13.98433734939759,
      "grad_norm": 0.0007186731090769172,
      "learning_rate": 6.0156626506024095e-06,
      "loss": 0.0054,
      "step": 116070
    },
    {
      "epoch": 13.985542168674698,
      "grad_norm": 0.006522326730191708,
      "learning_rate": 6.014457831325302e-06,
      "loss": 0.0533,
      "step": 116080
    },
    {
      "epoch": 13.986746987951808,
      "grad_norm": 0.017648207023739815,
      "learning_rate": 6.0132530120481935e-06,
      "loss": 0.0034,
      "step": 116090
    },
    {
      "epoch": 13.987951807228916,
      "grad_norm": 0.0031880352180451155,
      "learning_rate": 6.012048192771085e-06,
      "loss": 0.0128,
      "step": 116100
    },
    {
      "epoch": 13.989156626506023,
      "grad_norm": 0.8430879712104797,
      "learning_rate": 6.010843373493977e-06,
      "loss": 0.0158,
      "step": 116110
    },
    {
      "epoch": 13.990361445783133,
      "grad_norm": 0.3279381990432739,
      "learning_rate": 6.0096385542168674e-06,
      "loss": 0.015,
      "step": 116120
    },
    {
      "epoch": 13.991566265060241,
      "grad_norm": 0.8184679746627808,
      "learning_rate": 6.008433734939759e-06,
      "loss": 0.0065,
      "step": 116130
    },
    {
      "epoch": 13.992771084337349,
      "grad_norm": 0.008018233813345432,
      "learning_rate": 6.007228915662651e-06,
      "loss": 0.0093,
      "step": 116140
    },
    {
      "epoch": 13.993975903614459,
      "grad_norm": 0.007751820608973503,
      "learning_rate": 6.006024096385543e-06,
      "loss": 0.0048,
      "step": 116150
    },
    {
      "epoch": 13.995180722891567,
      "grad_norm": 1.0127543210983276,
      "learning_rate": 6.004819277108435e-06,
      "loss": 0.0089,
      "step": 116160
    },
    {
      "epoch": 13.996385542168674,
      "grad_norm": 0.26486676931381226,
      "learning_rate": 6.003614457831326e-06,
      "loss": 0.0169,
      "step": 116170
    },
    {
      "epoch": 13.997590361445782,
      "grad_norm": 0.001129414071328938,
      "learning_rate": 6.002409638554218e-06,
      "loss": 0.0135,
      "step": 116180
    },
    {
      "epoch": 13.998795180722892,
      "grad_norm": 0.0022963748779147863,
      "learning_rate": 6.0012048192771086e-06,
      "loss": 0.0007,
      "step": 116190
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.0012620604829862714,
      "learning_rate": 6e-06,
      "loss": 0.0633,
      "step": 116200
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.9861970378702662,
      "eval_f1": 0.9635677614894539,
      "eval_loss": 0.05291822925209999,
      "eval_precision": 0.9644626052501238,
      "eval_recall": 0.9626745766901496,
      "eval_runtime": 3371.5905,
      "eval_samples_per_second": 12.662,
      "eval_steps_per_second": 0.528,
      "step": 116200
    },
    {
      "epoch": 14.001204819277108,
      "grad_norm": 1.072472333908081,
      "learning_rate": 5.998795180722892e-06,
      "loss": 0.0083,
      "step": 116210
    },
    {
      "epoch": 14.002409638554218,
      "grad_norm": 0.008578798733651638,
      "learning_rate": 5.997590361445783e-06,
      "loss": 0.0117,
      "step": 116220
    },
    {
      "epoch": 14.003614457831326,
      "grad_norm": 0.012859701178967953,
      "learning_rate": 5.996385542168676e-06,
      "loss": 0.0132,
      "step": 116230
    },
    {
      "epoch": 14.004819277108433,
      "grad_norm": 0.0015639096964150667,
      "learning_rate": 5.995180722891567e-06,
      "loss": 0.0122,
      "step": 116240
    },
    {
      "epoch": 14.006024096385541,
      "grad_norm": 1.0009926557540894,
      "learning_rate": 5.993975903614458e-06,
      "loss": 0.0113,
      "step": 116250
    },
    {
      "epoch": 14.007228915662651,
      "grad_norm": 0.0017293067649006844,
      "learning_rate": 5.99277108433735e-06,
      "loss": 0.01,
      "step": 116260
    },
    {
      "epoch": 14.008433734939759,
      "grad_norm": 0.0006237999768927693,
      "learning_rate": 5.991566265060241e-06,
      "loss": 0.0106,
      "step": 116270
    },
    {
      "epoch": 14.009638554216867,
      "grad_norm": 1.4812052249908447,
      "learning_rate": 5.990361445783133e-06,
      "loss": 0.0148,
      "step": 116280
    },
    {
      "epoch": 14.010843373493977,
      "grad_norm": 0.9345035552978516,
      "learning_rate": 5.9891566265060244e-06,
      "loss": 0.0115,
      "step": 116290
    },
    {
      "epoch": 14.012048192771084,
      "grad_norm": 0.6463961005210876,
      "learning_rate": 5.987951807228917e-06,
      "loss": 0.0026,
      "step": 116300
    },
    {
      "epoch": 14.013253012048192,
      "grad_norm": 0.3296036124229431,
      "learning_rate": 5.9867469879518085e-06,
      "loss": 0.0195,
      "step": 116310
    },
    {
      "epoch": 14.0144578313253,
      "grad_norm": 1.3026372194290161,
      "learning_rate": 5.985542168674699e-06,
      "loss": 0.0108,
      "step": 116320
    },
    {
      "epoch": 14.01566265060241,
      "grad_norm": 0.0006289466400630772,
      "learning_rate": 5.984337349397591e-06,
      "loss": 0.0054,
      "step": 116330
    },
    {
      "epoch": 14.016867469879518,
      "grad_norm": 0.0017636477714404464,
      "learning_rate": 5.983132530120482e-06,
      "loss": 0.0206,
      "step": 116340
    },
    {
      "epoch": 14.018072289156626,
      "grad_norm": 0.9222884774208069,
      "learning_rate": 5.981927710843374e-06,
      "loss": 0.0178,
      "step": 116350
    },
    {
      "epoch": 14.019277108433736,
      "grad_norm": 0.0006329804309643805,
      "learning_rate": 5.9807228915662656e-06,
      "loss": 0.0035,
      "step": 116360
    },
    {
      "epoch": 14.020481927710843,
      "grad_norm": 0.0016705782618373632,
      "learning_rate": 5.979518072289156e-06,
      "loss": 0.0096,
      "step": 116370
    },
    {
      "epoch": 14.021686746987951,
      "grad_norm": 0.00029257219284772873,
      "learning_rate": 5.978313253012049e-06,
      "loss": 0.0106,
      "step": 116380
    },
    {
      "epoch": 14.022891566265061,
      "grad_norm": 0.0005520146223716438,
      "learning_rate": 5.97710843373494e-06,
      "loss": 0.0081,
      "step": 116390
    },
    {
      "epoch": 14.024096385542169,
      "grad_norm": 0.35803186893463135,
      "learning_rate": 5.975903614457832e-06,
      "loss": 0.0183,
      "step": 116400
    },
    {
      "epoch": 14.025301204819277,
      "grad_norm": 0.0009635160677134991,
      "learning_rate": 5.9746987951807235e-06,
      "loss": 0.0419,
      "step": 116410
    },
    {
      "epoch": 14.026506024096385,
      "grad_norm": 0.000335816788719967,
      "learning_rate": 5.973493975903615e-06,
      "loss": 0.0022,
      "step": 116420
    },
    {
      "epoch": 14.027710843373494,
      "grad_norm": 0.001517864759080112,
      "learning_rate": 5.972289156626506e-06,
      "loss": 0.0115,
      "step": 116430
    },
    {
      "epoch": 14.028915662650602,
      "grad_norm": 0.00026617260300554335,
      "learning_rate": 5.971084337349397e-06,
      "loss": 0.0126,
      "step": 116440
    },
    {
      "epoch": 14.03012048192771,
      "grad_norm": 0.0004556989879347384,
      "learning_rate": 5.96987951807229e-06,
      "loss": 0.009,
      "step": 116450
    },
    {
      "epoch": 14.03132530120482,
      "grad_norm": 0.8289560675621033,
      "learning_rate": 5.9686746987951814e-06,
      "loss": 0.007,
      "step": 116460
    },
    {
      "epoch": 14.032530120481928,
      "grad_norm": 0.013188766315579414,
      "learning_rate": 5.967469879518073e-06,
      "loss": 0.005,
      "step": 116470
    },
    {
      "epoch": 14.033734939759036,
      "grad_norm": 0.0003744828572962433,
      "learning_rate": 5.966265060240965e-06,
      "loss": 0.0004,
      "step": 116480
    },
    {
      "epoch": 14.034939759036144,
      "grad_norm": 0.2342551350593567,
      "learning_rate": 5.965060240963856e-06,
      "loss": 0.0086,
      "step": 116490
    },
    {
      "epoch": 14.036144578313253,
      "grad_norm": 1.3053052425384521,
      "learning_rate": 5.963855421686747e-06,
      "loss": 0.0303,
      "step": 116500
    },
    {
      "epoch": 14.037349397590361,
      "grad_norm": 0.5965130925178528,
      "learning_rate": 5.9626506024096385e-06,
      "loss": 0.0069,
      "step": 116510
    },
    {
      "epoch": 14.03855421686747,
      "grad_norm": 1.2902473211288452,
      "learning_rate": 5.96144578313253e-06,
      "loss": 0.0183,
      "step": 116520
    },
    {
      "epoch": 14.039759036144579,
      "grad_norm": 0.7279491424560547,
      "learning_rate": 5.9602409638554226e-06,
      "loss": 0.011,
      "step": 116530
    },
    {
      "epoch": 14.040963855421687,
      "grad_norm": 0.0024769161827862263,
      "learning_rate": 5.959036144578314e-06,
      "loss": 0.0167,
      "step": 116540
    },
    {
      "epoch": 14.042168674698795,
      "grad_norm": 0.0052184248343110085,
      "learning_rate": 5.957831325301206e-06,
      "loss": 0.0038,
      "step": 116550
    },
    {
      "epoch": 14.043373493975903,
      "grad_norm": 0.0006591324345208704,
      "learning_rate": 5.9566265060240965e-06,
      "loss": 0.0391,
      "step": 116560
    },
    {
      "epoch": 14.044578313253012,
      "grad_norm": 0.0011056842049583793,
      "learning_rate": 5.955421686746988e-06,
      "loss": 0.028,
      "step": 116570
    },
    {
      "epoch": 14.04578313253012,
      "grad_norm": 0.20505817234516144,
      "learning_rate": 5.95421686746988e-06,
      "loss": 0.0238,
      "step": 116580
    },
    {
      "epoch": 14.046987951807228,
      "grad_norm": 0.006158290896564722,
      "learning_rate": 5.953012048192771e-06,
      "loss": 0.0049,
      "step": 116590
    },
    {
      "epoch": 14.048192771084338,
      "grad_norm": 0.5751038193702698,
      "learning_rate": 5.951807228915664e-06,
      "loss": 0.0033,
      "step": 116600
    },
    {
      "epoch": 14.049397590361446,
      "grad_norm": 1.1076714992523193,
      "learning_rate": 5.950602409638555e-06,
      "loss": 0.017,
      "step": 116610
    },
    {
      "epoch": 14.050602409638554,
      "grad_norm": 0.0030129847582429647,
      "learning_rate": 5.949397590361447e-06,
      "loss": 0.0416,
      "step": 116620
    },
    {
      "epoch": 14.051807228915663,
      "grad_norm": 0.0008563264273107052,
      "learning_rate": 5.948192771084338e-06,
      "loss": 0.0282,
      "step": 116630
    },
    {
      "epoch": 14.053012048192771,
      "grad_norm": 0.009666328318417072,
      "learning_rate": 5.946987951807229e-06,
      "loss": 0.0141,
      "step": 116640
    },
    {
      "epoch": 14.05421686746988,
      "grad_norm": 0.01280147023499012,
      "learning_rate": 5.945783132530121e-06,
      "loss": 0.0255,
      "step": 116650
    },
    {
      "epoch": 14.055421686746987,
      "grad_norm": 1.0547380447387695,
      "learning_rate": 5.944578313253012e-06,
      "loss": 0.0296,
      "step": 116660
    },
    {
      "epoch": 14.056626506024097,
      "grad_norm": 0.8626076579093933,
      "learning_rate": 5.943373493975904e-06,
      "loss": 0.0238,
      "step": 116670
    },
    {
      "epoch": 14.057831325301205,
      "grad_norm": 3.3784468173980713,
      "learning_rate": 5.942168674698796e-06,
      "loss": 0.0111,
      "step": 116680
    },
    {
      "epoch": 14.059036144578313,
      "grad_norm": 0.109710194170475,
      "learning_rate": 5.940963855421687e-06,
      "loss": 0.0104,
      "step": 116690
    },
    {
      "epoch": 14.060240963855422,
      "grad_norm": 0.0022197142243385315,
      "learning_rate": 5.939759036144579e-06,
      "loss": 0.0012,
      "step": 116700
    },
    {
      "epoch": 14.06144578313253,
      "grad_norm": 0.0009871185757219791,
      "learning_rate": 5.93855421686747e-06,
      "loss": 0.013,
      "step": 116710
    },
    {
      "epoch": 14.062650602409638,
      "grad_norm": 7.773029327392578,
      "learning_rate": 5.937349397590362e-06,
      "loss": 0.0413,
      "step": 116720
    },
    {
      "epoch": 14.063855421686746,
      "grad_norm": 0.023599719628691673,
      "learning_rate": 5.9361445783132535e-06,
      "loss": 0.0069,
      "step": 116730
    },
    {
      "epoch": 14.065060240963856,
      "grad_norm": 1.129772424697876,
      "learning_rate": 5.934939759036144e-06,
      "loss": 0.0153,
      "step": 116740
    },
    {
      "epoch": 14.066265060240964,
      "grad_norm": 0.11379674822092056,
      "learning_rate": 5.9337349397590375e-06,
      "loss": 0.0147,
      "step": 116750
    },
    {
      "epoch": 14.067469879518072,
      "grad_norm": 0.008282073773443699,
      "learning_rate": 5.932530120481928e-06,
      "loss": 0.0085,
      "step": 116760
    },
    {
      "epoch": 14.068674698795181,
      "grad_norm": 0.0008716584998182952,
      "learning_rate": 5.93132530120482e-06,
      "loss": 0.0036,
      "step": 116770
    },
    {
      "epoch": 14.06987951807229,
      "grad_norm": 0.009044867008924484,
      "learning_rate": 5.930120481927711e-06,
      "loss": 0.0221,
      "step": 116780
    },
    {
      "epoch": 14.071084337349397,
      "grad_norm": 0.7170965671539307,
      "learning_rate": 5.928915662650603e-06,
      "loss": 0.0221,
      "step": 116790
    },
    {
      "epoch": 14.072289156626505,
      "grad_norm": 0.13842827081680298,
      "learning_rate": 5.927710843373495e-06,
      "loss": 0.011,
      "step": 116800
    },
    {
      "epoch": 14.073493975903615,
      "grad_norm": 0.07949665933847427,
      "learning_rate": 5.926506024096385e-06,
      "loss": 0.0152,
      "step": 116810
    },
    {
      "epoch": 14.074698795180723,
      "grad_norm": 0.0007270330679602921,
      "learning_rate": 5.925301204819277e-06,
      "loss": 0.0219,
      "step": 116820
    },
    {
      "epoch": 14.07590361445783,
      "grad_norm": 0.0010677293175831437,
      "learning_rate": 5.924096385542169e-06,
      "loss": 0.014,
      "step": 116830
    },
    {
      "epoch": 14.07710843373494,
      "grad_norm": 0.0010018994798883796,
      "learning_rate": 5.922891566265061e-06,
      "loss": 0.0046,
      "step": 116840
    },
    {
      "epoch": 14.078313253012048,
      "grad_norm": 0.000500268826726824,
      "learning_rate": 5.9216867469879525e-06,
      "loss": 0.0067,
      "step": 116850
    },
    {
      "epoch": 14.079518072289156,
      "grad_norm": 0.6360400915145874,
      "learning_rate": 5.920481927710844e-06,
      "loss": 0.0166,
      "step": 116860
    },
    {
      "epoch": 14.080722891566266,
      "grad_norm": 0.0004670619673561305,
      "learning_rate": 5.919277108433735e-06,
      "loss": 0.004,
      "step": 116870
    },
    {
      "epoch": 14.081927710843374,
      "grad_norm": 1.7792041301727295,
      "learning_rate": 5.9180722891566264e-06,
      "loss": 0.0153,
      "step": 116880
    },
    {
      "epoch": 14.083132530120482,
      "grad_norm": 1.7546360492706299,
      "learning_rate": 5.916867469879518e-06,
      "loss": 0.0224,
      "step": 116890
    },
    {
      "epoch": 14.08433734939759,
      "grad_norm": 0.0003943204355891794,
      "learning_rate": 5.9156626506024105e-06,
      "loss": 0.0064,
      "step": 116900
    },
    {
      "epoch": 14.0855421686747,
      "grad_norm": 0.0016440729377791286,
      "learning_rate": 5.914457831325302e-06,
      "loss": 0.011,
      "step": 116910
    },
    {
      "epoch": 14.086746987951807,
      "grad_norm": 0.001838342985138297,
      "learning_rate": 5.913253012048194e-06,
      "loss": 0.0043,
      "step": 116920
    },
    {
      "epoch": 14.087951807228915,
      "grad_norm": 0.2777341604232788,
      "learning_rate": 5.912048192771085e-06,
      "loss": 0.0112,
      "step": 116930
    },
    {
      "epoch": 14.089156626506025,
      "grad_norm": 1.3789674043655396,
      "learning_rate": 5.910843373493976e-06,
      "loss": 0.0135,
      "step": 116940
    },
    {
      "epoch": 14.090361445783133,
      "grad_norm": 0.00033590360544621944,
      "learning_rate": 5.9096385542168676e-06,
      "loss": 0.0022,
      "step": 116950
    },
    {
      "epoch": 14.09156626506024,
      "grad_norm": 1.4335469007492065,
      "learning_rate": 5.908433734939759e-06,
      "loss": 0.0203,
      "step": 116960
    },
    {
      "epoch": 14.092771084337349,
      "grad_norm": 0.0003695671330206096,
      "learning_rate": 5.907228915662651e-06,
      "loss": 0.0077,
      "step": 116970
    },
    {
      "epoch": 14.093975903614458,
      "grad_norm": 0.000507074233610183,
      "learning_rate": 5.906024096385543e-06,
      "loss": 0.0312,
      "step": 116980
    },
    {
      "epoch": 14.095180722891566,
      "grad_norm": 0.0012435754761099815,
      "learning_rate": 5.904819277108435e-06,
      "loss": 0.0024,
      "step": 116990
    },
    {
      "epoch": 14.096385542168674,
      "grad_norm": 1.4657829999923706,
      "learning_rate": 5.9036144578313255e-06,
      "loss": 0.0159,
      "step": 117000
    },
    {
      "epoch": 14.097590361445784,
      "grad_norm": 0.0023714180570095778,
      "learning_rate": 5.902409638554217e-06,
      "loss": 0.0027,
      "step": 117010
    },
    {
      "epoch": 14.098795180722892,
      "grad_norm": 0.514185905456543,
      "learning_rate": 5.901204819277109e-06,
      "loss": 0.0173,
      "step": 117020
    },
    {
      "epoch": 14.1,
      "grad_norm": 0.003952888306230307,
      "learning_rate": 5.9e-06,
      "loss": 0.0174,
      "step": 117030
    },
    {
      "epoch": 14.101204819277108,
      "grad_norm": 0.0014767133397981524,
      "learning_rate": 5.898795180722892e-06,
      "loss": 0.0096,
      "step": 117040
    },
    {
      "epoch": 14.102409638554217,
      "grad_norm": 0.004580290522426367,
      "learning_rate": 5.897590361445784e-06,
      "loss": 0.0048,
      "step": 117050
    },
    {
      "epoch": 14.103614457831325,
      "grad_norm": 0.2356603890657425,
      "learning_rate": 5.896385542168676e-06,
      "loss": 0.041,
      "step": 117060
    },
    {
      "epoch": 14.104819277108433,
      "grad_norm": 0.03740224614739418,
      "learning_rate": 5.895180722891567e-06,
      "loss": 0.0087,
      "step": 117070
    },
    {
      "epoch": 14.106024096385543,
      "grad_norm": 0.0002936095406766981,
      "learning_rate": 5.893975903614458e-06,
      "loss": 0.0001,
      "step": 117080
    },
    {
      "epoch": 14.10722891566265,
      "grad_norm": 0.004940755665302277,
      "learning_rate": 5.89277108433735e-06,
      "loss": 0.0693,
      "step": 117090
    },
    {
      "epoch": 14.108433734939759,
      "grad_norm": 158.78182983398438,
      "learning_rate": 5.891566265060241e-06,
      "loss": 0.017,
      "step": 117100
    },
    {
      "epoch": 14.109638554216868,
      "grad_norm": 0.008772087283432484,
      "learning_rate": 5.890361445783133e-06,
      "loss": 0.0124,
      "step": 117110
    },
    {
      "epoch": 14.110843373493976,
      "grad_norm": 1.5323543548583984,
      "learning_rate": 5.889156626506024e-06,
      "loss": 0.0247,
      "step": 117120
    },
    {
      "epoch": 14.112048192771084,
      "grad_norm": 0.002882162109017372,
      "learning_rate": 5.887951807228917e-06,
      "loss": 0.0341,
      "step": 117130
    },
    {
      "epoch": 14.113253012048192,
      "grad_norm": 0.0003394709783606231,
      "learning_rate": 5.886746987951808e-06,
      "loss": 0.0121,
      "step": 117140
    },
    {
      "epoch": 14.114457831325302,
      "grad_norm": 0.06886779516935349,
      "learning_rate": 5.885542168674699e-06,
      "loss": 0.0294,
      "step": 117150
    },
    {
      "epoch": 14.11566265060241,
      "grad_norm": 0.0019019482424482703,
      "learning_rate": 5.884337349397591e-06,
      "loss": 0.0164,
      "step": 117160
    },
    {
      "epoch": 14.116867469879518,
      "grad_norm": 0.001487691537477076,
      "learning_rate": 5.8831325301204825e-06,
      "loss": 0.0039,
      "step": 117170
    },
    {
      "epoch": 14.118072289156627,
      "grad_norm": 0.42920970916748047,
      "learning_rate": 5.881927710843374e-06,
      "loss": 0.0024,
      "step": 117180
    },
    {
      "epoch": 14.119277108433735,
      "grad_norm": 0.011348925530910492,
      "learning_rate": 5.880722891566265e-06,
      "loss": 0.0097,
      "step": 117190
    },
    {
      "epoch": 14.120481927710843,
      "grad_norm": 0.7509340047836304,
      "learning_rate": 5.879518072289157e-06,
      "loss": 0.0335,
      "step": 117200
    },
    {
      "epoch": 14.121686746987951,
      "grad_norm": 5.819177150726318,
      "learning_rate": 5.878313253012049e-06,
      "loss": 0.0239,
      "step": 117210
    },
    {
      "epoch": 14.12289156626506,
      "grad_norm": 0.004137356765568256,
      "learning_rate": 5.8771084337349404e-06,
      "loss": 0.0116,
      "step": 117220
    },
    {
      "epoch": 14.124096385542169,
      "grad_norm": 0.00801071710884571,
      "learning_rate": 5.875903614457832e-06,
      "loss": 0.0392,
      "step": 117230
    },
    {
      "epoch": 14.125301204819277,
      "grad_norm": 1.003745198249817,
      "learning_rate": 5.874698795180724e-06,
      "loss": 0.0213,
      "step": 117240
    },
    {
      "epoch": 14.126506024096386,
      "grad_norm": 0.004304188769310713,
      "learning_rate": 5.873493975903614e-06,
      "loss": 0.0203,
      "step": 117250
    },
    {
      "epoch": 14.127710843373494,
      "grad_norm": 0.014683226123452187,
      "learning_rate": 5.872289156626506e-06,
      "loss": 0.0288,
      "step": 117260
    },
    {
      "epoch": 14.128915662650602,
      "grad_norm": 1.1092908382415771,
      "learning_rate": 5.8710843373493975e-06,
      "loss": 0.0285,
      "step": 117270
    },
    {
      "epoch": 14.13012048192771,
      "grad_norm": 0.009530141949653625,
      "learning_rate": 5.86987951807229e-06,
      "loss": 0.0173,
      "step": 117280
    },
    {
      "epoch": 14.13132530120482,
      "grad_norm": 0.020208675414323807,
      "learning_rate": 5.8686746987951816e-06,
      "loss": 0.0119,
      "step": 117290
    },
    {
      "epoch": 14.132530120481928,
      "grad_norm": 0.5151454210281372,
      "learning_rate": 5.867469879518073e-06,
      "loss": 0.021,
      "step": 117300
    },
    {
      "epoch": 14.133734939759035,
      "grad_norm": 0.03629165142774582,
      "learning_rate": 5.866265060240965e-06,
      "loss": 0.0309,
      "step": 117310
    },
    {
      "epoch": 14.134939759036145,
      "grad_norm": 0.0013152087340131402,
      "learning_rate": 5.8650602409638555e-06,
      "loss": 0.0239,
      "step": 117320
    },
    {
      "epoch": 14.136144578313253,
      "grad_norm": 0.6141421794891357,
      "learning_rate": 5.863855421686747e-06,
      "loss": 0.0128,
      "step": 117330
    },
    {
      "epoch": 14.137349397590361,
      "grad_norm": 0.1953398883342743,
      "learning_rate": 5.862650602409639e-06,
      "loss": 0.0186,
      "step": 117340
    },
    {
      "epoch": 14.13855421686747,
      "grad_norm": 0.26377686858177185,
      "learning_rate": 5.861445783132531e-06,
      "loss": 0.0015,
      "step": 117350
    },
    {
      "epoch": 14.139759036144579,
      "grad_norm": 2.4764437675476074,
      "learning_rate": 5.860240963855423e-06,
      "loss": 0.0399,
      "step": 117360
    },
    {
      "epoch": 14.140963855421687,
      "grad_norm": 0.23575586080551147,
      "learning_rate": 5.859036144578314e-06,
      "loss": 0.0042,
      "step": 117370
    },
    {
      "epoch": 14.142168674698794,
      "grad_norm": 0.01634032092988491,
      "learning_rate": 5.857831325301205e-06,
      "loss": 0.0297,
      "step": 117380
    },
    {
      "epoch": 14.143373493975904,
      "grad_norm": 0.7125876545906067,
      "learning_rate": 5.856626506024097e-06,
      "loss": 0.0161,
      "step": 117390
    },
    {
      "epoch": 14.144578313253012,
      "grad_norm": 0.011266679503023624,
      "learning_rate": 5.855421686746988e-06,
      "loss": 0.0086,
      "step": 117400
    },
    {
      "epoch": 14.14578313253012,
      "grad_norm": 0.0011875819182023406,
      "learning_rate": 5.85421686746988e-06,
      "loss": 0.0123,
      "step": 117410
    },
    {
      "epoch": 14.14698795180723,
      "grad_norm": 0.0010307168122380972,
      "learning_rate": 5.853012048192771e-06,
      "loss": 0.002,
      "step": 117420
    },
    {
      "epoch": 14.148192771084338,
      "grad_norm": 1.087990641593933,
      "learning_rate": 5.851807228915664e-06,
      "loss": 0.0244,
      "step": 117430
    },
    {
      "epoch": 14.149397590361446,
      "grad_norm": 0.0083363251760602,
      "learning_rate": 5.850602409638555e-06,
      "loss": 0.0001,
      "step": 117440
    },
    {
      "epoch": 14.150602409638553,
      "grad_norm": 0.0005705018993467093,
      "learning_rate": 5.849397590361446e-06,
      "loss": 0.0284,
      "step": 117450
    },
    {
      "epoch": 14.151807228915663,
      "grad_norm": 0.014389537274837494,
      "learning_rate": 5.848192771084338e-06,
      "loss": 0.0157,
      "step": 117460
    },
    {
      "epoch": 14.153012048192771,
      "grad_norm": 1.285973310470581,
      "learning_rate": 5.846987951807229e-06,
      "loss": 0.0148,
      "step": 117470
    },
    {
      "epoch": 14.154216867469879,
      "grad_norm": 0.472808301448822,
      "learning_rate": 5.845783132530121e-06,
      "loss": 0.0163,
      "step": 117480
    },
    {
      "epoch": 14.155421686746989,
      "grad_norm": 1.5902572870254517,
      "learning_rate": 5.8445783132530125e-06,
      "loss": 0.0234,
      "step": 117490
    },
    {
      "epoch": 14.156626506024097,
      "grad_norm": 1.1953470706939697,
      "learning_rate": 5.843373493975905e-06,
      "loss": 0.0241,
      "step": 117500
    },
    {
      "epoch": 14.157831325301204,
      "grad_norm": 0.0007435680599883199,
      "learning_rate": 5.842168674698796e-06,
      "loss": 0.0095,
      "step": 117510
    },
    {
      "epoch": 14.159036144578312,
      "grad_norm": 0.005178916733711958,
      "learning_rate": 5.840963855421687e-06,
      "loss": 0.0146,
      "step": 117520
    },
    {
      "epoch": 14.160240963855422,
      "grad_norm": 0.0003110567922703922,
      "learning_rate": 5.839759036144579e-06,
      "loss": 0.0205,
      "step": 117530
    },
    {
      "epoch": 14.16144578313253,
      "grad_norm": 0.015062002465128899,
      "learning_rate": 5.83855421686747e-06,
      "loss": 0.0173,
      "step": 117540
    },
    {
      "epoch": 14.162650602409638,
      "grad_norm": 0.0009407494217157364,
      "learning_rate": 5.837349397590362e-06,
      "loss": 0.0078,
      "step": 117550
    },
    {
      "epoch": 14.163855421686748,
      "grad_norm": 1.330793857574463,
      "learning_rate": 5.836144578313253e-06,
      "loss": 0.0216,
      "step": 117560
    },
    {
      "epoch": 14.165060240963856,
      "grad_norm": 0.0010912991128861904,
      "learning_rate": 5.834939759036144e-06,
      "loss": 0.0041,
      "step": 117570
    },
    {
      "epoch": 14.166265060240963,
      "grad_norm": 9.17074966430664,
      "learning_rate": 5.833734939759037e-06,
      "loss": 0.0352,
      "step": 117580
    },
    {
      "epoch": 14.167469879518073,
      "grad_norm": 0.09539397805929184,
      "learning_rate": 5.832530120481928e-06,
      "loss": 0.0181,
      "step": 117590
    },
    {
      "epoch": 14.168674698795181,
      "grad_norm": 0.0038258021231740713,
      "learning_rate": 5.83132530120482e-06,
      "loss": 0.0056,
      "step": 117600
    },
    {
      "epoch": 14.169879518072289,
      "grad_norm": 0.000630197289865464,
      "learning_rate": 5.8301204819277115e-06,
      "loss": 0.0116,
      "step": 117610
    },
    {
      "epoch": 14.171084337349397,
      "grad_norm": 0.0015522827161476016,
      "learning_rate": 5.828915662650603e-06,
      "loss": 0.017,
      "step": 117620
    },
    {
      "epoch": 14.172289156626507,
      "grad_norm": 0.13870932161808014,
      "learning_rate": 5.827710843373494e-06,
      "loss": 0.0241,
      "step": 117630
    },
    {
      "epoch": 14.173493975903614,
      "grad_norm": 1.69704270362854,
      "learning_rate": 5.8265060240963854e-06,
      "loss": 0.02,
      "step": 117640
    },
    {
      "epoch": 14.174698795180722,
      "grad_norm": 0.9750404357910156,
      "learning_rate": 5.825301204819278e-06,
      "loss": 0.0179,
      "step": 117650
    },
    {
      "epoch": 14.175903614457832,
      "grad_norm": 0.0005432841135188937,
      "learning_rate": 5.8240963855421695e-06,
      "loss": 0.0756,
      "step": 117660
    },
    {
      "epoch": 14.17710843373494,
      "grad_norm": 8.849332809448242,
      "learning_rate": 5.822891566265061e-06,
      "loss": 0.027,
      "step": 117670
    },
    {
      "epoch": 14.178313253012048,
      "grad_norm": 0.0033847622107714415,
      "learning_rate": 5.821686746987953e-06,
      "loss": 0.0141,
      "step": 117680
    },
    {
      "epoch": 14.179518072289156,
      "grad_norm": 0.6738958954811096,
      "learning_rate": 5.820481927710843e-06,
      "loss": 0.0096,
      "step": 117690
    },
    {
      "epoch": 14.180722891566266,
      "grad_norm": 0.008501111529767513,
      "learning_rate": 5.819277108433735e-06,
      "loss": 0.0062,
      "step": 117700
    },
    {
      "epoch": 14.181927710843373,
      "grad_norm": 0.333133339881897,
      "learning_rate": 5.8180722891566266e-06,
      "loss": 0.015,
      "step": 117710
    },
    {
      "epoch": 14.183132530120481,
      "grad_norm": 0.019023951143026352,
      "learning_rate": 5.816867469879518e-06,
      "loss": 0.0046,
      "step": 117720
    },
    {
      "epoch": 14.184337349397591,
      "grad_norm": 0.0068262978456914425,
      "learning_rate": 5.8156626506024106e-06,
      "loss": 0.0049,
      "step": 117730
    },
    {
      "epoch": 14.185542168674699,
      "grad_norm": 0.015100647695362568,
      "learning_rate": 5.814457831325302e-06,
      "loss": 0.0027,
      "step": 117740
    },
    {
      "epoch": 14.186746987951807,
      "grad_norm": 1.0514189004898071,
      "learning_rate": 5.813253012048194e-06,
      "loss": 0.0105,
      "step": 117750
    },
    {
      "epoch": 14.187951807228915,
      "grad_norm": 1.7668399810791016,
      "learning_rate": 5.8120481927710845e-06,
      "loss": 0.0303,
      "step": 117760
    },
    {
      "epoch": 14.189156626506024,
      "grad_norm": 0.0010132092284038663,
      "learning_rate": 5.810843373493976e-06,
      "loss": 0.0116,
      "step": 117770
    },
    {
      "epoch": 14.190361445783132,
      "grad_norm": 0.010696413926780224,
      "learning_rate": 5.809638554216868e-06,
      "loss": 0.0257,
      "step": 117780
    },
    {
      "epoch": 14.19156626506024,
      "grad_norm": 0.8231844305992126,
      "learning_rate": 5.808433734939759e-06,
      "loss": 0.0185,
      "step": 117790
    },
    {
      "epoch": 14.19277108433735,
      "grad_norm": 0.027343595400452614,
      "learning_rate": 5.807228915662652e-06,
      "loss": 0.0142,
      "step": 117800
    },
    {
      "epoch": 14.193975903614458,
      "grad_norm": 2.0063869953155518,
      "learning_rate": 5.806024096385543e-06,
      "loss": 0.0103,
      "step": 117810
    },
    {
      "epoch": 14.195180722891566,
      "grad_norm": 0.06582488864660263,
      "learning_rate": 5.804819277108434e-06,
      "loss": 0.0079,
      "step": 117820
    },
    {
      "epoch": 14.196385542168676,
      "grad_norm": 0.0005766365793533623,
      "learning_rate": 5.803614457831326e-06,
      "loss": 0.0119,
      "step": 117830
    },
    {
      "epoch": 14.197590361445783,
      "grad_norm": 0.09110840409994125,
      "learning_rate": 5.802409638554217e-06,
      "loss": 0.0128,
      "step": 117840
    },
    {
      "epoch": 14.198795180722891,
      "grad_norm": 0.001038736547343433,
      "learning_rate": 5.801204819277109e-06,
      "loss": 0.0068,
      "step": 117850
    },
    {
      "epoch": 14.2,
      "grad_norm": 0.0016752012306824327,
      "learning_rate": 5.8e-06,
      "loss": 0.0061,
      "step": 117860
    },
    {
      "epoch": 14.201204819277109,
      "grad_norm": 0.09925584495067596,
      "learning_rate": 5.798795180722891e-06,
      "loss": 0.0121,
      "step": 117870
    },
    {
      "epoch": 14.202409638554217,
      "grad_norm": 0.0003504741471260786,
      "learning_rate": 5.797590361445784e-06,
      "loss": 0.049,
      "step": 117880
    },
    {
      "epoch": 14.203614457831325,
      "grad_norm": 0.0005026260041631758,
      "learning_rate": 5.796385542168675e-06,
      "loss": 0.0458,
      "step": 117890
    },
    {
      "epoch": 14.204819277108435,
      "grad_norm": 0.024746054783463478,
      "learning_rate": 5.795180722891567e-06,
      "loss": 0.0178,
      "step": 117900
    },
    {
      "epoch": 14.206024096385542,
      "grad_norm": 0.6753244996070862,
      "learning_rate": 5.793975903614458e-06,
      "loss": 0.0157,
      "step": 117910
    },
    {
      "epoch": 14.20722891566265,
      "grad_norm": 0.7270146012306213,
      "learning_rate": 5.79277108433735e-06,
      "loss": 0.0182,
      "step": 117920
    },
    {
      "epoch": 14.208433734939758,
      "grad_norm": 0.9681477546691895,
      "learning_rate": 5.7915662650602415e-06,
      "loss": 0.014,
      "step": 117930
    },
    {
      "epoch": 14.209638554216868,
      "grad_norm": 0.0005810002330690622,
      "learning_rate": 5.790361445783132e-06,
      "loss": 0.041,
      "step": 117940
    },
    {
      "epoch": 14.210843373493976,
      "grad_norm": 0.2562183737754822,
      "learning_rate": 5.789156626506025e-06,
      "loss": 0.021,
      "step": 117950
    },
    {
      "epoch": 14.212048192771084,
      "grad_norm": 0.001026785233989358,
      "learning_rate": 5.787951807228916e-06,
      "loss": 0.0209,
      "step": 117960
    },
    {
      "epoch": 14.213253012048193,
      "grad_norm": 0.004135128576308489,
      "learning_rate": 5.786746987951808e-06,
      "loss": 0.0045,
      "step": 117970
    },
    {
      "epoch": 14.214457831325301,
      "grad_norm": 0.3061136305332184,
      "learning_rate": 5.7855421686746994e-06,
      "loss": 0.0087,
      "step": 117980
    },
    {
      "epoch": 14.21566265060241,
      "grad_norm": 0.000674392853397876,
      "learning_rate": 5.784337349397591e-06,
      "loss": 0.0106,
      "step": 117990
    },
    {
      "epoch": 14.216867469879517,
      "grad_norm": 0.03671965375542641,
      "learning_rate": 5.783132530120482e-06,
      "loss": 0.0303,
      "step": 118000
    },
    {
      "epoch": 14.218072289156627,
      "grad_norm": 0.07001301646232605,
      "learning_rate": 5.781927710843373e-06,
      "loss": 0.0099,
      "step": 118010
    },
    {
      "epoch": 14.219277108433735,
      "grad_norm": 0.013505974784493446,
      "learning_rate": 5.780722891566265e-06,
      "loss": 0.0114,
      "step": 118020
    },
    {
      "epoch": 14.220481927710843,
      "grad_norm": 0.0007343756151385605,
      "learning_rate": 5.779518072289157e-06,
      "loss": 0.0251,
      "step": 118030
    },
    {
      "epoch": 14.221686746987952,
      "grad_norm": 0.042480237782001495,
      "learning_rate": 5.778313253012049e-06,
      "loss": 0.0413,
      "step": 118040
    },
    {
      "epoch": 14.22289156626506,
      "grad_norm": 0.29139280319213867,
      "learning_rate": 5.7771084337349405e-06,
      "loss": 0.0218,
      "step": 118050
    },
    {
      "epoch": 14.224096385542168,
      "grad_norm": 0.0006604116642847657,
      "learning_rate": 5.775903614457832e-06,
      "loss": 0.009,
      "step": 118060
    },
    {
      "epoch": 14.225301204819278,
      "grad_norm": 0.5787361860275269,
      "learning_rate": 5.774698795180723e-06,
      "loss": 0.004,
      "step": 118070
    },
    {
      "epoch": 14.226506024096386,
      "grad_norm": 0.544847309589386,
      "learning_rate": 5.7734939759036145e-06,
      "loss": 0.0099,
      "step": 118080
    },
    {
      "epoch": 14.227710843373494,
      "grad_norm": 0.0007130918093025684,
      "learning_rate": 5.772289156626506e-06,
      "loss": 0.0185,
      "step": 118090
    },
    {
      "epoch": 14.228915662650602,
      "grad_norm": 0.0009672316955402493,
      "learning_rate": 5.7710843373493985e-06,
      "loss": 0.0028,
      "step": 118100
    },
    {
      "epoch": 14.230120481927711,
      "grad_norm": 0.028417332097887993,
      "learning_rate": 5.76987951807229e-06,
      "loss": 0.0199,
      "step": 118110
    },
    {
      "epoch": 14.23132530120482,
      "grad_norm": 1.6833522319793701,
      "learning_rate": 5.768674698795182e-06,
      "loss": 0.0145,
      "step": 118120
    },
    {
      "epoch": 14.232530120481927,
      "grad_norm": 0.0003834470408037305,
      "learning_rate": 5.767469879518072e-06,
      "loss": 0.0129,
      "step": 118130
    },
    {
      "epoch": 14.233734939759037,
      "grad_norm": 0.8367424607276917,
      "learning_rate": 5.766265060240964e-06,
      "loss": 0.0133,
      "step": 118140
    },
    {
      "epoch": 14.234939759036145,
      "grad_norm": 0.2764255702495575,
      "learning_rate": 5.765060240963856e-06,
      "loss": 0.0047,
      "step": 118150
    },
    {
      "epoch": 14.236144578313253,
      "grad_norm": 0.00020706953364424407,
      "learning_rate": 5.763855421686747e-06,
      "loss": 0.0064,
      "step": 118160
    },
    {
      "epoch": 14.23734939759036,
      "grad_norm": 0.11681050807237625,
      "learning_rate": 5.762650602409639e-06,
      "loss": 0.002,
      "step": 118170
    },
    {
      "epoch": 14.23855421686747,
      "grad_norm": 0.0002900733379647136,
      "learning_rate": 5.761445783132531e-06,
      "loss": 0.0207,
      "step": 118180
    },
    {
      "epoch": 14.239759036144578,
      "grad_norm": 0.000307863432681188,
      "learning_rate": 5.760240963855423e-06,
      "loss": 0.0029,
      "step": 118190
    },
    {
      "epoch": 14.240963855421686,
      "grad_norm": 0.0013738198904320598,
      "learning_rate": 5.7590361445783135e-06,
      "loss": 0.0047,
      "step": 118200
    },
    {
      "epoch": 14.242168674698796,
      "grad_norm": 0.0011543281143531203,
      "learning_rate": 5.757831325301205e-06,
      "loss": 0.004,
      "step": 118210
    },
    {
      "epoch": 14.243373493975904,
      "grad_norm": 0.00030790147138759494,
      "learning_rate": 5.756626506024097e-06,
      "loss": 0.0099,
      "step": 118220
    },
    {
      "epoch": 14.244578313253012,
      "grad_norm": 0.0003740325919352472,
      "learning_rate": 5.755421686746988e-06,
      "loss": 0.0218,
      "step": 118230
    },
    {
      "epoch": 14.24578313253012,
      "grad_norm": 9.536544799804688,
      "learning_rate": 5.75421686746988e-06,
      "loss": 0.0571,
      "step": 118240
    },
    {
      "epoch": 14.24698795180723,
      "grad_norm": 0.0004764912591781467,
      "learning_rate": 5.753012048192772e-06,
      "loss": 0.0005,
      "step": 118250
    },
    {
      "epoch": 14.248192771084337,
      "grad_norm": 0.0004899600171484053,
      "learning_rate": 5.751807228915663e-06,
      "loss": 0.015,
      "step": 118260
    },
    {
      "epoch": 14.249397590361445,
      "grad_norm": 1.508407711982727,
      "learning_rate": 5.750602409638555e-06,
      "loss": 0.0202,
      "step": 118270
    },
    {
      "epoch": 14.250602409638555,
      "grad_norm": 1.7872823476791382,
      "learning_rate": 5.749397590361446e-06,
      "loss": 0.0528,
      "step": 118280
    },
    {
      "epoch": 14.251807228915663,
      "grad_norm": 0.21075865626335144,
      "learning_rate": 5.748192771084338e-06,
      "loss": 0.0094,
      "step": 118290
    },
    {
      "epoch": 14.25301204819277,
      "grad_norm": 0.755074679851532,
      "learning_rate": 5.746987951807229e-06,
      "loss": 0.0102,
      "step": 118300
    },
    {
      "epoch": 14.25421686746988,
      "grad_norm": 0.0039392272010445595,
      "learning_rate": 5.74578313253012e-06,
      "loss": 0.0014,
      "step": 118310
    },
    {
      "epoch": 14.255421686746988,
      "grad_norm": 1.5808075666427612,
      "learning_rate": 5.744578313253013e-06,
      "loss": 0.028,
      "step": 118320
    },
    {
      "epoch": 14.256626506024096,
      "grad_norm": 0.006785963661968708,
      "learning_rate": 5.743373493975904e-06,
      "loss": 0.0105,
      "step": 118330
    },
    {
      "epoch": 14.257831325301204,
      "grad_norm": 0.0002870173775590956,
      "learning_rate": 5.742168674698796e-06,
      "loss": 0.0137,
      "step": 118340
    },
    {
      "epoch": 14.259036144578314,
      "grad_norm": 0.0003554787253960967,
      "learning_rate": 5.740963855421687e-06,
      "loss": 0.0129,
      "step": 118350
    },
    {
      "epoch": 14.260240963855422,
      "grad_norm": 0.0482061505317688,
      "learning_rate": 5.739759036144579e-06,
      "loss": 0.0018,
      "step": 118360
    },
    {
      "epoch": 14.26144578313253,
      "grad_norm": 0.0005042634438723326,
      "learning_rate": 5.7385542168674705e-06,
      "loss": 0.0046,
      "step": 118370
    },
    {
      "epoch": 14.26265060240964,
      "grad_norm": 2.059788227081299,
      "learning_rate": 5.737349397590361e-06,
      "loss": 0.0244,
      "step": 118380
    },
    {
      "epoch": 14.263855421686747,
      "grad_norm": 1.4873160123825073,
      "learning_rate": 5.736144578313253e-06,
      "loss": 0.0408,
      "step": 118390
    },
    {
      "epoch": 14.265060240963855,
      "grad_norm": 0.00037559689371846616,
      "learning_rate": 5.734939759036145e-06,
      "loss": 0.0025,
      "step": 118400
    },
    {
      "epoch": 14.266265060240963,
      "grad_norm": 0.0005579894059337676,
      "learning_rate": 5.733734939759037e-06,
      "loss": 0.0417,
      "step": 118410
    },
    {
      "epoch": 14.267469879518073,
      "grad_norm": 0.25063130259513855,
      "learning_rate": 5.7325301204819285e-06,
      "loss": 0.0165,
      "step": 118420
    },
    {
      "epoch": 14.26867469879518,
      "grad_norm": 0.0006586943636648357,
      "learning_rate": 5.73132530120482e-06,
      "loss": 0.05,
      "step": 118430
    },
    {
      "epoch": 14.269879518072289,
      "grad_norm": 0.18757790327072144,
      "learning_rate": 5.730120481927711e-06,
      "loss": 0.0005,
      "step": 118440
    },
    {
      "epoch": 14.271084337349398,
      "grad_norm": 1.212931752204895,
      "learning_rate": 5.728915662650602e-06,
      "loss": 0.0046,
      "step": 118450
    },
    {
      "epoch": 14.272289156626506,
      "grad_norm": 0.0019197255605831742,
      "learning_rate": 5.727710843373494e-06,
      "loss": 0.0069,
      "step": 118460
    },
    {
      "epoch": 14.273493975903614,
      "grad_norm": 0.002090316265821457,
      "learning_rate": 5.726506024096386e-06,
      "loss": 0.0388,
      "step": 118470
    },
    {
      "epoch": 14.274698795180722,
      "grad_norm": 1.8263649940490723,
      "learning_rate": 5.725301204819278e-06,
      "loss": 0.0166,
      "step": 118480
    },
    {
      "epoch": 14.275903614457832,
      "grad_norm": 0.000982283498160541,
      "learning_rate": 5.7240963855421696e-06,
      "loss": 0.01,
      "step": 118490
    },
    {
      "epoch": 14.27710843373494,
      "grad_norm": 9.079386711120605,
      "learning_rate": 5.722891566265061e-06,
      "loss": 0.0193,
      "step": 118500
    },
    {
      "epoch": 14.278313253012048,
      "grad_norm": 0.18425096571445465,
      "learning_rate": 5.721686746987952e-06,
      "loss": 0.0073,
      "step": 118510
    },
    {
      "epoch": 14.279518072289157,
      "grad_norm": 0.0020346418023109436,
      "learning_rate": 5.7204819277108435e-06,
      "loss": 0.0208,
      "step": 118520
    },
    {
      "epoch": 14.280722891566265,
      "grad_norm": 9.767436027526855,
      "learning_rate": 5.719277108433735e-06,
      "loss": 0.0557,
      "step": 118530
    },
    {
      "epoch": 14.281927710843373,
      "grad_norm": 0.9457654356956482,
      "learning_rate": 5.718072289156627e-06,
      "loss": 0.0435,
      "step": 118540
    },
    {
      "epoch": 14.283132530120483,
      "grad_norm": 0.08577775210142136,
      "learning_rate": 5.716867469879519e-06,
      "loss": 0.0105,
      "step": 118550
    },
    {
      "epoch": 14.28433734939759,
      "grad_norm": 0.010175182484090328,
      "learning_rate": 5.715662650602411e-06,
      "loss": 0.0024,
      "step": 118560
    },
    {
      "epoch": 14.285542168674699,
      "grad_norm": 0.001003767130896449,
      "learning_rate": 5.714457831325302e-06,
      "loss": 0.0156,
      "step": 118570
    },
    {
      "epoch": 14.286746987951807,
      "grad_norm": 2.1795334815979004,
      "learning_rate": 5.713253012048193e-06,
      "loss": 0.0169,
      "step": 118580
    },
    {
      "epoch": 14.287951807228916,
      "grad_norm": 0.00045262958155944943,
      "learning_rate": 5.712048192771085e-06,
      "loss": 0.014,
      "step": 118590
    },
    {
      "epoch": 14.289156626506024,
      "grad_norm": 0.0003224771935492754,
      "learning_rate": 5.710843373493976e-06,
      "loss": 0.0169,
      "step": 118600
    },
    {
      "epoch": 14.290361445783132,
      "grad_norm": 0.0003434889658819884,
      "learning_rate": 5.709638554216868e-06,
      "loss": 0.0076,
      "step": 118610
    },
    {
      "epoch": 14.291566265060242,
      "grad_norm": 0.010736907832324505,
      "learning_rate": 5.70843373493976e-06,
      "loss": 0.0227,
      "step": 118620
    },
    {
      "epoch": 14.29277108433735,
      "grad_norm": 0.003280509263277054,
      "learning_rate": 5.707228915662652e-06,
      "loss": 0.0245,
      "step": 118630
    },
    {
      "epoch": 14.293975903614458,
      "grad_norm": 0.002599885920062661,
      "learning_rate": 5.7060240963855425e-06,
      "loss": 0.0037,
      "step": 118640
    },
    {
      "epoch": 14.295180722891565,
      "grad_norm": 1.5292855501174927,
      "learning_rate": 5.704819277108434e-06,
      "loss": 0.0069,
      "step": 118650
    },
    {
      "epoch": 14.296385542168675,
      "grad_norm": 0.0003533567360136658,
      "learning_rate": 5.703614457831326e-06,
      "loss": 0.0046,
      "step": 118660
    },
    {
      "epoch": 14.297590361445783,
      "grad_norm": 0.009555651806294918,
      "learning_rate": 5.702409638554217e-06,
      "loss": 0.0013,
      "step": 118670
    },
    {
      "epoch": 14.298795180722891,
      "grad_norm": 0.0030758290085941553,
      "learning_rate": 5.701204819277109e-06,
      "loss": 0.0282,
      "step": 118680
    },
    {
      "epoch": 14.3,
      "grad_norm": 0.1532536745071411,
      "learning_rate": 5.7e-06,
      "loss": 0.0524,
      "step": 118690
    },
    {
      "epoch": 14.301204819277109,
      "grad_norm": 0.48957860469818115,
      "learning_rate": 5.698795180722893e-06,
      "loss": 0.0173,
      "step": 118700
    },
    {
      "epoch": 14.302409638554217,
      "grad_norm": 0.7923292517662048,
      "learning_rate": 5.697590361445784e-06,
      "loss": 0.0106,
      "step": 118710
    },
    {
      "epoch": 14.303614457831324,
      "grad_norm": 0.0002914615033660084,
      "learning_rate": 5.696385542168675e-06,
      "loss": 0.0178,
      "step": 118720
    },
    {
      "epoch": 14.304819277108434,
      "grad_norm": 0.021960921585559845,
      "learning_rate": 5.695180722891567e-06,
      "loss": 0.0199,
      "step": 118730
    },
    {
      "epoch": 14.306024096385542,
      "grad_norm": 0.00024719792418181896,
      "learning_rate": 5.693975903614458e-06,
      "loss": 0.0203,
      "step": 118740
    },
    {
      "epoch": 14.30722891566265,
      "grad_norm": 0.0010705157183110714,
      "learning_rate": 5.69277108433735e-06,
      "loss": 0.0071,
      "step": 118750
    },
    {
      "epoch": 14.30843373493976,
      "grad_norm": 0.657071053981781,
      "learning_rate": 5.691566265060241e-06,
      "loss": 0.0118,
      "step": 118760
    },
    {
      "epoch": 14.309638554216868,
      "grad_norm": 0.3033004403114319,
      "learning_rate": 5.690361445783133e-06,
      "loss": 0.0047,
      "step": 118770
    },
    {
      "epoch": 14.310843373493976,
      "grad_norm": 0.0008057304657995701,
      "learning_rate": 5.689156626506025e-06,
      "loss": 0.0016,
      "step": 118780
    },
    {
      "epoch": 14.312048192771085,
      "grad_norm": 0.3212137222290039,
      "learning_rate": 5.687951807228916e-06,
      "loss": 0.0185,
      "step": 118790
    },
    {
      "epoch": 14.313253012048193,
      "grad_norm": 0.1860324591398239,
      "learning_rate": 5.686746987951808e-06,
      "loss": 0.0068,
      "step": 118800
    },
    {
      "epoch": 14.314457831325301,
      "grad_norm": 1.5119154453277588,
      "learning_rate": 5.6855421686746995e-06,
      "loss": 0.0217,
      "step": 118810
    },
    {
      "epoch": 14.315662650602409,
      "grad_norm": 0.00016976527695078403,
      "learning_rate": 5.68433734939759e-06,
      "loss": 0.0035,
      "step": 118820
    },
    {
      "epoch": 14.316867469879519,
      "grad_norm": 0.5340211987495422,
      "learning_rate": 5.683132530120482e-06,
      "loss": 0.0185,
      "step": 118830
    },
    {
      "epoch": 14.318072289156627,
      "grad_norm": 0.0002118974953191355,
      "learning_rate": 5.6819277108433735e-06,
      "loss": 0.0088,
      "step": 118840
    },
    {
      "epoch": 14.319277108433734,
      "grad_norm": 0.00018396320228930563,
      "learning_rate": 5.680722891566266e-06,
      "loss": 0.015,
      "step": 118850
    },
    {
      "epoch": 14.320481927710844,
      "grad_norm": 0.00021084629406686872,
      "learning_rate": 5.6795180722891575e-06,
      "loss": 0.009,
      "step": 118860
    },
    {
      "epoch": 14.321686746987952,
      "grad_norm": 1.3912867307662964,
      "learning_rate": 5.678313253012049e-06,
      "loss": 0.0186,
      "step": 118870
    },
    {
      "epoch": 14.32289156626506,
      "grad_norm": 0.00021191567066125572,
      "learning_rate": 5.677108433734941e-06,
      "loss": 0.0069,
      "step": 118880
    },
    {
      "epoch": 14.324096385542168,
      "grad_norm": 0.00026073367916978896,
      "learning_rate": 5.675903614457831e-06,
      "loss": 0.0143,
      "step": 118890
    },
    {
      "epoch": 14.325301204819278,
      "grad_norm": 1.1079527139663696,
      "learning_rate": 5.674698795180723e-06,
      "loss": 0.0145,
      "step": 118900
    },
    {
      "epoch": 14.326506024096386,
      "grad_norm": 1.2729195356369019,
      "learning_rate": 5.6734939759036146e-06,
      "loss": 0.0162,
      "step": 118910
    },
    {
      "epoch": 14.327710843373493,
      "grad_norm": 0.00724806496873498,
      "learning_rate": 5.672289156626507e-06,
      "loss": 0.0194,
      "step": 118920
    },
    {
      "epoch": 14.328915662650603,
      "grad_norm": 0.3830706775188446,
      "learning_rate": 5.671084337349399e-06,
      "loss": 0.014,
      "step": 118930
    },
    {
      "epoch": 14.330120481927711,
      "grad_norm": 0.9482688307762146,
      "learning_rate": 5.66987951807229e-06,
      "loss": 0.0173,
      "step": 118940
    },
    {
      "epoch": 14.331325301204819,
      "grad_norm": 0.0018926744814962149,
      "learning_rate": 5.668674698795181e-06,
      "loss": 0.0243,
      "step": 118950
    },
    {
      "epoch": 14.332530120481927,
      "grad_norm": 0.028018558397889137,
      "learning_rate": 5.6674698795180725e-06,
      "loss": 0.0313,
      "step": 118960
    },
    {
      "epoch": 14.333734939759037,
      "grad_norm": 0.0008141603320837021,
      "learning_rate": 5.666265060240964e-06,
      "loss": 0.0146,
      "step": 118970
    },
    {
      "epoch": 14.334939759036144,
      "grad_norm": 0.0003493044641800225,
      "learning_rate": 5.665060240963856e-06,
      "loss": 0.027,
      "step": 118980
    },
    {
      "epoch": 14.336144578313252,
      "grad_norm": 0.00035820589982904494,
      "learning_rate": 5.663855421686747e-06,
      "loss": 0.0089,
      "step": 118990
    },
    {
      "epoch": 14.337349397590362,
      "grad_norm": 0.00037247236468829215,
      "learning_rate": 5.66265060240964e-06,
      "loss": 0.0138,
      "step": 119000
    },
    {
      "epoch": 14.33855421686747,
      "grad_norm": 0.0003050563973374665,
      "learning_rate": 5.661445783132531e-06,
      "loss": 0.002,
      "step": 119010
    },
    {
      "epoch": 14.339759036144578,
      "grad_norm": 0.0005638600559905171,
      "learning_rate": 5.660240963855422e-06,
      "loss": 0.0306,
      "step": 119020
    },
    {
      "epoch": 14.340963855421688,
      "grad_norm": 0.28849929571151733,
      "learning_rate": 5.659036144578314e-06,
      "loss": 0.0097,
      "step": 119030
    },
    {
      "epoch": 14.342168674698796,
      "grad_norm": 0.1886896789073944,
      "learning_rate": 5.657831325301205e-06,
      "loss": 0.0132,
      "step": 119040
    },
    {
      "epoch": 14.343373493975903,
      "grad_norm": 0.25983908772468567,
      "learning_rate": 5.656626506024097e-06,
      "loss": 0.0094,
      "step": 119050
    },
    {
      "epoch": 14.344578313253011,
      "grad_norm": 0.004222454968839884,
      "learning_rate": 5.655421686746988e-06,
      "loss": 0.042,
      "step": 119060
    },
    {
      "epoch": 14.345783132530121,
      "grad_norm": 0.727230966091156,
      "learning_rate": 5.654216867469881e-06,
      "loss": 0.0099,
      "step": 119070
    },
    {
      "epoch": 14.346987951807229,
      "grad_norm": 0.1531645804643631,
      "learning_rate": 5.6530120481927716e-06,
      "loss": 0.0161,
      "step": 119080
    },
    {
      "epoch": 14.348192771084337,
      "grad_norm": 0.015143800526857376,
      "learning_rate": 5.651807228915663e-06,
      "loss": 0.0106,
      "step": 119090
    },
    {
      "epoch": 14.349397590361447,
      "grad_norm": 0.09384041279554367,
      "learning_rate": 5.650602409638555e-06,
      "loss": 0.0069,
      "step": 119100
    },
    {
      "epoch": 14.350602409638554,
      "grad_norm": 0.133192241191864,
      "learning_rate": 5.649397590361446e-06,
      "loss": 0.0014,
      "step": 119110
    },
    {
      "epoch": 14.351807228915662,
      "grad_norm": 0.0011071128537878394,
      "learning_rate": 5.648192771084338e-06,
      "loss": 0.0222,
      "step": 119120
    },
    {
      "epoch": 14.35301204819277,
      "grad_norm": 0.742067813873291,
      "learning_rate": 5.646987951807229e-06,
      "loss": 0.0171,
      "step": 119130
    },
    {
      "epoch": 14.35421686746988,
      "grad_norm": 0.7413290739059448,
      "learning_rate": 5.64578313253012e-06,
      "loss": 0.0264,
      "step": 119140
    },
    {
      "epoch": 14.355421686746988,
      "grad_norm": 0.003989383578300476,
      "learning_rate": 5.644578313253013e-06,
      "loss": 0.007,
      "step": 119150
    },
    {
      "epoch": 14.356626506024096,
      "grad_norm": 0.0027279953937977552,
      "learning_rate": 5.643373493975904e-06,
      "loss": 0.0008,
      "step": 119160
    },
    {
      "epoch": 14.357831325301206,
      "grad_norm": 5.33867073059082,
      "learning_rate": 5.642168674698796e-06,
      "loss": 0.0373,
      "step": 119170
    },
    {
      "epoch": 14.359036144578313,
      "grad_norm": 0.00042482285061851144,
      "learning_rate": 5.6409638554216874e-06,
      "loss": 0.0124,
      "step": 119180
    },
    {
      "epoch": 14.360240963855421,
      "grad_norm": 1.2928744554519653,
      "learning_rate": 5.639759036144579e-06,
      "loss": 0.0131,
      "step": 119190
    },
    {
      "epoch": 14.36144578313253,
      "grad_norm": 0.00030921617872081697,
      "learning_rate": 5.63855421686747e-06,
      "loss": 0.0554,
      "step": 119200
    },
    {
      "epoch": 14.362650602409639,
      "grad_norm": 508.8931884765625,
      "learning_rate": 5.637349397590361e-06,
      "loss": 0.0091,
      "step": 119210
    },
    {
      "epoch": 14.363855421686747,
      "grad_norm": 0.0009373718639835715,
      "learning_rate": 5.636144578313254e-06,
      "loss": 0.0186,
      "step": 119220
    },
    {
      "epoch": 14.365060240963855,
      "grad_norm": 0.00024738244246691465,
      "learning_rate": 5.634939759036145e-06,
      "loss": 0.0057,
      "step": 119230
    },
    {
      "epoch": 14.366265060240965,
      "grad_norm": 3.112600564956665,
      "learning_rate": 5.633734939759037e-06,
      "loss": 0.0159,
      "step": 119240
    },
    {
      "epoch": 14.367469879518072,
      "grad_norm": 1.2133281230926514,
      "learning_rate": 5.6325301204819286e-06,
      "loss": 0.0058,
      "step": 119250
    },
    {
      "epoch": 14.36867469879518,
      "grad_norm": 0.0006577878957614303,
      "learning_rate": 5.631325301204819e-06,
      "loss": 0.0069,
      "step": 119260
    },
    {
      "epoch": 14.369879518072288,
      "grad_norm": 0.0011477527441456914,
      "learning_rate": 5.630120481927711e-06,
      "loss": 0.0105,
      "step": 119270
    },
    {
      "epoch": 14.371084337349398,
      "grad_norm": 0.018983939662575722,
      "learning_rate": 5.6289156626506025e-06,
      "loss": 0.0169,
      "step": 119280
    },
    {
      "epoch": 14.372289156626506,
      "grad_norm": 0.00036926244501955807,
      "learning_rate": 5.627710843373494e-06,
      "loss": 0.0459,
      "step": 119290
    },
    {
      "epoch": 14.373493975903614,
      "grad_norm": 1.6915243864059448,
      "learning_rate": 5.6265060240963865e-06,
      "loss": 0.0133,
      "step": 119300
    },
    {
      "epoch": 14.374698795180723,
      "grad_norm": 0.0005810129223391414,
      "learning_rate": 5.625301204819278e-06,
      "loss": 0.0145,
      "step": 119310
    },
    {
      "epoch": 14.375903614457831,
      "grad_norm": 0.00018307195568922907,
      "learning_rate": 5.62409638554217e-06,
      "loss": 0.0337,
      "step": 119320
    },
    {
      "epoch": 14.37710843373494,
      "grad_norm": 0.00026624463498592377,
      "learning_rate": 5.62289156626506e-06,
      "loss": 0.0022,
      "step": 119330
    },
    {
      "epoch": 14.378313253012049,
      "grad_norm": 0.0006591347046196461,
      "learning_rate": 5.621686746987952e-06,
      "loss": 0.0162,
      "step": 119340
    },
    {
      "epoch": 14.379518072289157,
      "grad_norm": 0.0005518161342479289,
      "learning_rate": 5.620481927710844e-06,
      "loss": 0.0033,
      "step": 119350
    },
    {
      "epoch": 14.380722891566265,
      "grad_norm": 0.0016596514033153653,
      "learning_rate": 5.619277108433735e-06,
      "loss": 0.024,
      "step": 119360
    },
    {
      "epoch": 14.381927710843373,
      "grad_norm": 0.010075774043798447,
      "learning_rate": 5.618072289156628e-06,
      "loss": 0.0091,
      "step": 119370
    },
    {
      "epoch": 14.383132530120482,
      "grad_norm": 0.47633877396583557,
      "learning_rate": 5.616867469879519e-06,
      "loss": 0.0067,
      "step": 119380
    },
    {
      "epoch": 14.38433734939759,
      "grad_norm": 0.002820862689986825,
      "learning_rate": 5.61566265060241e-06,
      "loss": 0.0064,
      "step": 119390
    },
    {
      "epoch": 14.385542168674698,
      "grad_norm": 0.013415413908660412,
      "learning_rate": 5.6144578313253015e-06,
      "loss": 0.017,
      "step": 119400
    },
    {
      "epoch": 14.386746987951808,
      "grad_norm": 0.0003203981905244291,
      "learning_rate": 5.613253012048193e-06,
      "loss": 0.0186,
      "step": 119410
    },
    {
      "epoch": 14.387951807228916,
      "grad_norm": 0.14645937085151672,
      "learning_rate": 5.612048192771085e-06,
      "loss": 0.0089,
      "step": 119420
    },
    {
      "epoch": 14.389156626506024,
      "grad_norm": 0.983279824256897,
      "learning_rate": 5.610843373493976e-06,
      "loss": 0.0117,
      "step": 119430
    },
    {
      "epoch": 14.390361445783132,
      "grad_norm": 1.7266342639923096,
      "learning_rate": 5.609638554216867e-06,
      "loss": 0.0326,
      "step": 119440
    },
    {
      "epoch": 14.391566265060241,
      "grad_norm": 0.0002473735366947949,
      "learning_rate": 5.60843373493976e-06,
      "loss": 0.0134,
      "step": 119450
    },
    {
      "epoch": 14.39277108433735,
      "grad_norm": 0.0006084073102101684,
      "learning_rate": 5.607228915662651e-06,
      "loss": 0.0176,
      "step": 119460
    },
    {
      "epoch": 14.393975903614457,
      "grad_norm": 0.0004020629567094147,
      "learning_rate": 5.606024096385543e-06,
      "loss": 0.0396,
      "step": 119470
    },
    {
      "epoch": 14.395180722891567,
      "grad_norm": 1.227620005607605,
      "learning_rate": 5.604819277108434e-06,
      "loss": 0.0287,
      "step": 119480
    },
    {
      "epoch": 14.396385542168675,
      "grad_norm": 0.0007542665698565543,
      "learning_rate": 5.603614457831326e-06,
      "loss": 0.0195,
      "step": 119490
    },
    {
      "epoch": 14.397590361445783,
      "grad_norm": 0.23941132426261902,
      "learning_rate": 5.602409638554217e-06,
      "loss": 0.0295,
      "step": 119500
    },
    {
      "epoch": 14.398795180722892,
      "grad_norm": 0.9113707542419434,
      "learning_rate": 5.601204819277108e-06,
      "loss": 0.0154,
      "step": 119510
    },
    {
      "epoch": 14.4,
      "grad_norm": 0.0015721619129180908,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.021,
      "step": 119520
    },
    {
      "epoch": 14.401204819277108,
      "grad_norm": 0.8771247863769531,
      "learning_rate": 5.598795180722892e-06,
      "loss": 0.0174,
      "step": 119530
    },
    {
      "epoch": 14.402409638554216,
      "grad_norm": 0.00034730290644802153,
      "learning_rate": 5.597590361445784e-06,
      "loss": 0.017,
      "step": 119540
    },
    {
      "epoch": 14.403614457831326,
      "grad_norm": 0.0006321389810182154,
      "learning_rate": 5.596385542168675e-06,
      "loss": 0.0053,
      "step": 119550
    },
    {
      "epoch": 14.404819277108434,
      "grad_norm": 18.399887084960938,
      "learning_rate": 5.595180722891567e-06,
      "loss": 0.0122,
      "step": 119560
    },
    {
      "epoch": 14.406024096385542,
      "grad_norm": 0.0014759411569684744,
      "learning_rate": 5.593975903614458e-06,
      "loss": 0.0213,
      "step": 119570
    },
    {
      "epoch": 14.407228915662651,
      "grad_norm": 0.0001836144074331969,
      "learning_rate": 5.592771084337349e-06,
      "loss": 0.0044,
      "step": 119580
    },
    {
      "epoch": 14.40843373493976,
      "grad_norm": 0.8353831171989441,
      "learning_rate": 5.591566265060241e-06,
      "loss": 0.0146,
      "step": 119590
    },
    {
      "epoch": 14.409638554216867,
      "grad_norm": 0.00042886182200163603,
      "learning_rate": 5.590361445783133e-06,
      "loss": 0.0266,
      "step": 119600
    },
    {
      "epoch": 14.410843373493975,
      "grad_norm": 0.0015125366626307368,
      "learning_rate": 5.589156626506025e-06,
      "loss": 0.0536,
      "step": 119610
    },
    {
      "epoch": 14.412048192771085,
      "grad_norm": 2.867746353149414,
      "learning_rate": 5.5879518072289165e-06,
      "loss": 0.0164,
      "step": 119620
    },
    {
      "epoch": 14.413253012048193,
      "grad_norm": 0.7136346101760864,
      "learning_rate": 5.586746987951808e-06,
      "loss": 0.0152,
      "step": 119630
    },
    {
      "epoch": 14.4144578313253,
      "grad_norm": 0.003157653845846653,
      "learning_rate": 5.585542168674699e-06,
      "loss": 0.0105,
      "step": 119640
    },
    {
      "epoch": 14.41566265060241,
      "grad_norm": 0.00032712711254134774,
      "learning_rate": 5.58433734939759e-06,
      "loss": 0.0092,
      "step": 119650
    },
    {
      "epoch": 14.416867469879518,
      "grad_norm": 0.00022573102614842355,
      "learning_rate": 5.583132530120482e-06,
      "loss": 0.0,
      "step": 119660
    },
    {
      "epoch": 14.418072289156626,
      "grad_norm": 0.0008502899436280131,
      "learning_rate": 5.581927710843374e-06,
      "loss": 0.0202,
      "step": 119670
    },
    {
      "epoch": 14.419277108433734,
      "grad_norm": 0.0011289557442069054,
      "learning_rate": 5.580722891566266e-06,
      "loss": 0.007,
      "step": 119680
    },
    {
      "epoch": 14.420481927710844,
      "grad_norm": 0.00022312928922474384,
      "learning_rate": 5.579518072289158e-06,
      "loss": 0.001,
      "step": 119690
    },
    {
      "epoch": 14.421686746987952,
      "grad_norm": 0.002457206603139639,
      "learning_rate": 5.578313253012048e-06,
      "loss": 0.0158,
      "step": 119700
    },
    {
      "epoch": 14.42289156626506,
      "grad_norm": 0.7850936651229858,
      "learning_rate": 5.57710843373494e-06,
      "loss": 0.0153,
      "step": 119710
    },
    {
      "epoch": 14.42409638554217,
      "grad_norm": 0.6128576993942261,
      "learning_rate": 5.5759036144578315e-06,
      "loss": 0.004,
      "step": 119720
    },
    {
      "epoch": 14.425301204819277,
      "grad_norm": 0.0006357404636219144,
      "learning_rate": 5.574698795180723e-06,
      "loss": 0.013,
      "step": 119730
    },
    {
      "epoch": 14.426506024096385,
      "grad_norm": 0.0003404857125133276,
      "learning_rate": 5.573493975903615e-06,
      "loss": 0.0216,
      "step": 119740
    },
    {
      "epoch": 14.427710843373493,
      "grad_norm": 0.00024978991132229567,
      "learning_rate": 5.572289156626507e-06,
      "loss": 0.021,
      "step": 119750
    },
    {
      "epoch": 14.428915662650603,
      "grad_norm": 1.3984986543655396,
      "learning_rate": 5.571084337349399e-06,
      "loss": 0.0163,
      "step": 119760
    },
    {
      "epoch": 14.43012048192771,
      "grad_norm": 0.00041359831811860204,
      "learning_rate": 5.5698795180722894e-06,
      "loss": 0.0107,
      "step": 119770
    },
    {
      "epoch": 14.431325301204819,
      "grad_norm": 0.8623955845832825,
      "learning_rate": 5.568674698795181e-06,
      "loss": 0.0331,
      "step": 119780
    },
    {
      "epoch": 14.432530120481928,
      "grad_norm": 0.000261868437519297,
      "learning_rate": 5.567469879518073e-06,
      "loss": 0.0031,
      "step": 119790
    },
    {
      "epoch": 14.433734939759036,
      "grad_norm": 1.5074867010116577,
      "learning_rate": 5.566265060240964e-06,
      "loss": 0.0065,
      "step": 119800
    },
    {
      "epoch": 14.434939759036144,
      "grad_norm": 0.30789101123809814,
      "learning_rate": 5.565060240963856e-06,
      "loss": 0.0361,
      "step": 119810
    },
    {
      "epoch": 14.436144578313254,
      "grad_norm": 0.9137690663337708,
      "learning_rate": 5.563855421686748e-06,
      "loss": 0.0113,
      "step": 119820
    },
    {
      "epoch": 14.437349397590362,
      "grad_norm": 0.07952859252691269,
      "learning_rate": 5.562650602409639e-06,
      "loss": 0.0168,
      "step": 119830
    },
    {
      "epoch": 14.43855421686747,
      "grad_norm": 0.006308855954557657,
      "learning_rate": 5.5614457831325306e-06,
      "loss": 0.0283,
      "step": 119840
    },
    {
      "epoch": 14.439759036144578,
      "grad_norm": 0.29701560735702515,
      "learning_rate": 5.560240963855422e-06,
      "loss": 0.0273,
      "step": 119850
    },
    {
      "epoch": 14.440963855421687,
      "grad_norm": 0.051803383976221085,
      "learning_rate": 5.559036144578314e-06,
      "loss": 0.004,
      "step": 119860
    },
    {
      "epoch": 14.442168674698795,
      "grad_norm": 1.3875133991241455,
      "learning_rate": 5.557831325301205e-06,
      "loss": 0.0408,
      "step": 119870
    },
    {
      "epoch": 14.443373493975903,
      "grad_norm": 1.4167890548706055,
      "learning_rate": 5.556626506024096e-06,
      "loss": 0.0277,
      "step": 119880
    },
    {
      "epoch": 14.444578313253013,
      "grad_norm": 0.44321733713150024,
      "learning_rate": 5.555421686746988e-06,
      "loss": 0.039,
      "step": 119890
    },
    {
      "epoch": 14.44578313253012,
      "grad_norm": 0.0005067073507234454,
      "learning_rate": 5.55421686746988e-06,
      "loss": 0.0051,
      "step": 119900
    },
    {
      "epoch": 14.446987951807229,
      "grad_norm": 0.028423761948943138,
      "learning_rate": 5.553012048192772e-06,
      "loss": 0.0207,
      "step": 119910
    },
    {
      "epoch": 14.448192771084337,
      "grad_norm": 1.8682607412338257,
      "learning_rate": 5.551807228915663e-06,
      "loss": 0.0226,
      "step": 119920
    },
    {
      "epoch": 14.449397590361446,
      "grad_norm": 0.7950077056884766,
      "learning_rate": 5.550602409638555e-06,
      "loss": 0.0108,
      "step": 119930
    },
    {
      "epoch": 14.450602409638554,
      "grad_norm": 0.00021452741930261254,
      "learning_rate": 5.5493975903614464e-06,
      "loss": 0.0039,
      "step": 119940
    },
    {
      "epoch": 14.451807228915662,
      "grad_norm": 1.029829978942871,
      "learning_rate": 5.548192771084337e-06,
      "loss": 0.0123,
      "step": 119950
    },
    {
      "epoch": 14.453012048192772,
      "grad_norm": 0.00818086788058281,
      "learning_rate": 5.546987951807229e-06,
      "loss": 0.0085,
      "step": 119960
    },
    {
      "epoch": 14.45421686746988,
      "grad_norm": 0.0016686056042090058,
      "learning_rate": 5.545783132530121e-06,
      "loss": 0.0039,
      "step": 119970
    },
    {
      "epoch": 14.455421686746988,
      "grad_norm": 0.021738408133387566,
      "learning_rate": 5.544578313253013e-06,
      "loss": 0.003,
      "step": 119980
    },
    {
      "epoch": 14.456626506024097,
      "grad_norm": 10.043099403381348,
      "learning_rate": 5.543373493975904e-06,
      "loss": 0.0479,
      "step": 119990
    },
    {
      "epoch": 14.457831325301205,
      "grad_norm": 0.8930407166481018,
      "learning_rate": 5.542168674698796e-06,
      "loss": 0.0046,
      "step": 120000
    },
    {
      "epoch": 14.459036144578313,
      "grad_norm": 1.9971336126327515,
      "learning_rate": 5.540963855421687e-06,
      "loss": 0.0228,
      "step": 120010
    },
    {
      "epoch": 14.460240963855421,
      "grad_norm": 0.0001334606495220214,
      "learning_rate": 5.539759036144578e-06,
      "loss": 0.0121,
      "step": 120020
    },
    {
      "epoch": 14.46144578313253,
      "grad_norm": 0.0006910547963343561,
      "learning_rate": 5.53855421686747e-06,
      "loss": 0.0227,
      "step": 120030
    },
    {
      "epoch": 14.462650602409639,
      "grad_norm": 0.000753768312279135,
      "learning_rate": 5.5373493975903615e-06,
      "loss": 0.0182,
      "step": 120040
    },
    {
      "epoch": 14.463855421686747,
      "grad_norm": 0.001534121111035347,
      "learning_rate": 5.536144578313254e-06,
      "loss": 0.0097,
      "step": 120050
    },
    {
      "epoch": 14.465060240963856,
      "grad_norm": 1.6383432149887085,
      "learning_rate": 5.5349397590361455e-06,
      "loss": 0.0228,
      "step": 120060
    },
    {
      "epoch": 14.466265060240964,
      "grad_norm": 0.002949552843347192,
      "learning_rate": 5.533734939759037e-06,
      "loss": 0.0145,
      "step": 120070
    },
    {
      "epoch": 14.467469879518072,
      "grad_norm": 0.0011715878499671817,
      "learning_rate": 5.532530120481928e-06,
      "loss": 0.014,
      "step": 120080
    },
    {
      "epoch": 14.46867469879518,
      "grad_norm": 0.26805099844932556,
      "learning_rate": 5.531325301204819e-06,
      "loss": 0.0126,
      "step": 120090
    },
    {
      "epoch": 14.46987951807229,
      "grad_norm": 0.8877925276756287,
      "learning_rate": 5.530120481927711e-06,
      "loss": 0.0183,
      "step": 120100
    },
    {
      "epoch": 14.471084337349398,
      "grad_norm": 1.711151123046875,
      "learning_rate": 5.528915662650603e-06,
      "loss": 0.02,
      "step": 120110
    },
    {
      "epoch": 14.472289156626506,
      "grad_norm": 0.0003047536301892251,
      "learning_rate": 5.527710843373495e-06,
      "loss": 0.0037,
      "step": 120120
    },
    {
      "epoch": 14.473493975903615,
      "grad_norm": 0.0004746183112729341,
      "learning_rate": 5.526506024096387e-06,
      "loss": 0.013,
      "step": 120130
    },
    {
      "epoch": 14.474698795180723,
      "grad_norm": 1.0440856218338013,
      "learning_rate": 5.525301204819278e-06,
      "loss": 0.0075,
      "step": 120140
    },
    {
      "epoch": 14.475903614457831,
      "grad_norm": 0.00035227692569606006,
      "learning_rate": 5.524096385542169e-06,
      "loss": 0.0439,
      "step": 120150
    },
    {
      "epoch": 14.477108433734939,
      "grad_norm": 0.3297155499458313,
      "learning_rate": 5.5228915662650605e-06,
      "loss": 0.0347,
      "step": 120160
    },
    {
      "epoch": 14.478313253012049,
      "grad_norm": 0.0015187141252681613,
      "learning_rate": 5.521686746987952e-06,
      "loss": 0.0113,
      "step": 120170
    },
    {
      "epoch": 14.479518072289157,
      "grad_norm": 0.00021753129840362817,
      "learning_rate": 5.520481927710844e-06,
      "loss": 0.0084,
      "step": 120180
    },
    {
      "epoch": 14.480722891566264,
      "grad_norm": 0.3145575523376465,
      "learning_rate": 5.519277108433735e-06,
      "loss": 0.0549,
      "step": 120190
    },
    {
      "epoch": 14.481927710843374,
      "grad_norm": 0.0004474552988540381,
      "learning_rate": 5.518072289156628e-06,
      "loss": 0.0029,
      "step": 120200
    },
    {
      "epoch": 14.483132530120482,
      "grad_norm": 0.007277806755155325,
      "learning_rate": 5.5168674698795185e-06,
      "loss": 0.017,
      "step": 120210
    },
    {
      "epoch": 14.48433734939759,
      "grad_norm": 2.4632997512817383,
      "learning_rate": 5.51566265060241e-06,
      "loss": 0.0321,
      "step": 120220
    },
    {
      "epoch": 14.485542168674698,
      "grad_norm": 0.004698998760432005,
      "learning_rate": 5.514457831325302e-06,
      "loss": 0.0352,
      "step": 120230
    },
    {
      "epoch": 14.486746987951808,
      "grad_norm": 0.0006942514446564019,
      "learning_rate": 5.513253012048193e-06,
      "loss": 0.0189,
      "step": 120240
    },
    {
      "epoch": 14.487951807228916,
      "grad_norm": 0.05638771131634712,
      "learning_rate": 5.512048192771085e-06,
      "loss": 0.0078,
      "step": 120250
    },
    {
      "epoch": 14.489156626506023,
      "grad_norm": 0.8328390121459961,
      "learning_rate": 5.5108433734939756e-06,
      "loss": 0.0062,
      "step": 120260
    },
    {
      "epoch": 14.490361445783133,
      "grad_norm": 0.005080911796540022,
      "learning_rate": 5.509638554216869e-06,
      "loss": 0.0131,
      "step": 120270
    },
    {
      "epoch": 14.491566265060241,
      "grad_norm": 0.2207835465669632,
      "learning_rate": 5.50843373493976e-06,
      "loss": 0.0087,
      "step": 120280
    },
    {
      "epoch": 14.492771084337349,
      "grad_norm": 0.002446783473715186,
      "learning_rate": 5.507228915662651e-06,
      "loss": 0.0112,
      "step": 120290
    },
    {
      "epoch": 14.493975903614459,
      "grad_norm": 1.8621248006820679,
      "learning_rate": 5.506024096385543e-06,
      "loss": 0.0167,
      "step": 120300
    },
    {
      "epoch": 14.495180722891567,
      "grad_norm": 0.00023325798974838108,
      "learning_rate": 5.504819277108434e-06,
      "loss": 0.0092,
      "step": 120310
    },
    {
      "epoch": 14.496385542168674,
      "grad_norm": 0.006096270401030779,
      "learning_rate": 5.503614457831326e-06,
      "loss": 0.0035,
      "step": 120320
    },
    {
      "epoch": 14.497590361445782,
      "grad_norm": 0.0001958075154107064,
      "learning_rate": 5.502409638554217e-06,
      "loss": 0.0031,
      "step": 120330
    },
    {
      "epoch": 14.498795180722892,
      "grad_norm": 0.282514363527298,
      "learning_rate": 5.501204819277108e-06,
      "loss": 0.0095,
      "step": 120340
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.0033456955570727587,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.033,
      "step": 120350
    },
    {
      "epoch": 14.501204819277108,
      "grad_norm": 0.00019298797997180372,
      "learning_rate": 5.498795180722892e-06,
      "loss": 0.0166,
      "step": 120360
    },
    {
      "epoch": 14.502409638554218,
      "grad_norm": 0.9907017350196838,
      "learning_rate": 5.497590361445784e-06,
      "loss": 0.0063,
      "step": 120370
    },
    {
      "epoch": 14.503614457831326,
      "grad_norm": 0.00048282992793247104,
      "learning_rate": 5.4963855421686755e-06,
      "loss": 0.0041,
      "step": 120380
    },
    {
      "epoch": 14.504819277108433,
      "grad_norm": 0.00018411542987450957,
      "learning_rate": 5.495180722891566e-06,
      "loss": 0.0079,
      "step": 120390
    },
    {
      "epoch": 14.506024096385541,
      "grad_norm": 0.33152052760124207,
      "learning_rate": 5.493975903614458e-06,
      "loss": 0.0359,
      "step": 120400
    },
    {
      "epoch": 14.507228915662651,
      "grad_norm": 0.05182996392250061,
      "learning_rate": 5.492771084337349e-06,
      "loss": 0.001,
      "step": 120410
    },
    {
      "epoch": 14.508433734939759,
      "grad_norm": 0.0007968847639858723,
      "learning_rate": 5.491566265060242e-06,
      "loss": 0.0517,
      "step": 120420
    },
    {
      "epoch": 14.509638554216867,
      "grad_norm": 0.04452550411224365,
      "learning_rate": 5.490361445783133e-06,
      "loss": 0.0168,
      "step": 120430
    },
    {
      "epoch": 14.510843373493977,
      "grad_norm": 0.0036341683007776737,
      "learning_rate": 5.489156626506025e-06,
      "loss": 0.0461,
      "step": 120440
    },
    {
      "epoch": 14.512048192771084,
      "grad_norm": 0.0020824847742915154,
      "learning_rate": 5.487951807228917e-06,
      "loss": 0.0001,
      "step": 120450
    },
    {
      "epoch": 14.513253012048192,
      "grad_norm": 0.457456111907959,
      "learning_rate": 5.486746987951807e-06,
      "loss": 0.0061,
      "step": 120460
    },
    {
      "epoch": 14.514457831325302,
      "grad_norm": 0.003986774943768978,
      "learning_rate": 5.485542168674699e-06,
      "loss": 0.031,
      "step": 120470
    },
    {
      "epoch": 14.51566265060241,
      "grad_norm": 0.007544677704572678,
      "learning_rate": 5.4843373493975905e-06,
      "loss": 0.0117,
      "step": 120480
    },
    {
      "epoch": 14.516867469879518,
      "grad_norm": 1.1122246980667114,
      "learning_rate": 5.483132530120482e-06,
      "loss": 0.01,
      "step": 120490
    },
    {
      "epoch": 14.518072289156626,
      "grad_norm": 1.2977241277694702,
      "learning_rate": 5.4819277108433745e-06,
      "loss": 0.0058,
      "step": 120500
    },
    {
      "epoch": 14.519277108433736,
      "grad_norm": 15.616868019104004,
      "learning_rate": 5.480722891566266e-06,
      "loss": 0.0199,
      "step": 120510
    },
    {
      "epoch": 14.520481927710843,
      "grad_norm": 2.2053275108337402,
      "learning_rate": 5.479518072289157e-06,
      "loss": 0.0289,
      "step": 120520
    },
    {
      "epoch": 14.521686746987951,
      "grad_norm": 0.005937575828284025,
      "learning_rate": 5.4783132530120484e-06,
      "loss": 0.0291,
      "step": 120530
    },
    {
      "epoch": 14.522891566265061,
      "grad_norm": 0.000866603571921587,
      "learning_rate": 5.47710843373494e-06,
      "loss": 0.0216,
      "step": 120540
    },
    {
      "epoch": 14.524096385542169,
      "grad_norm": 0.0003785525041166693,
      "learning_rate": 5.475903614457832e-06,
      "loss": 0.005,
      "step": 120550
    },
    {
      "epoch": 14.525301204819277,
      "grad_norm": 0.995429277420044,
      "learning_rate": 5.474698795180723e-06,
      "loss": 0.0205,
      "step": 120560
    },
    {
      "epoch": 14.526506024096385,
      "grad_norm": 0.0011229391675442457,
      "learning_rate": 5.473493975903616e-06,
      "loss": 0.0058,
      "step": 120570
    },
    {
      "epoch": 14.527710843373494,
      "grad_norm": 0.0042515285313129425,
      "learning_rate": 5.472289156626507e-06,
      "loss": 0.0205,
      "step": 120580
    },
    {
      "epoch": 14.528915662650602,
      "grad_norm": 0.0012803226709365845,
      "learning_rate": 5.471084337349398e-06,
      "loss": 0.0184,
      "step": 120590
    },
    {
      "epoch": 14.53012048192771,
      "grad_norm": 0.23790249228477478,
      "learning_rate": 5.4698795180722896e-06,
      "loss": 0.014,
      "step": 120600
    },
    {
      "epoch": 14.53132530120482,
      "grad_norm": 0.9724031686782837,
      "learning_rate": 5.468674698795181e-06,
      "loss": 0.0119,
      "step": 120610
    },
    {
      "epoch": 14.532530120481928,
      "grad_norm": 1.190627932548523,
      "learning_rate": 5.467469879518073e-06,
      "loss": 0.0046,
      "step": 120620
    },
    {
      "epoch": 14.533734939759036,
      "grad_norm": 0.46225374937057495,
      "learning_rate": 5.466265060240964e-06,
      "loss": 0.0081,
      "step": 120630
    },
    {
      "epoch": 14.534939759036144,
      "grad_norm": 0.9853571653366089,
      "learning_rate": 5.465060240963855e-06,
      "loss": 0.0144,
      "step": 120640
    },
    {
      "epoch": 14.536144578313253,
      "grad_norm": 1.8636524677276611,
      "learning_rate": 5.4638554216867475e-06,
      "loss": 0.0139,
      "step": 120650
    },
    {
      "epoch": 14.537349397590361,
      "grad_norm": 2.1826894283294678,
      "learning_rate": 5.462650602409639e-06,
      "loss": 0.0285,
      "step": 120660
    },
    {
      "epoch": 14.53855421686747,
      "grad_norm": 1.0391212701797485,
      "learning_rate": 5.461445783132531e-06,
      "loss": 0.0315,
      "step": 120670
    },
    {
      "epoch": 14.539759036144579,
      "grad_norm": 0.012309771962463856,
      "learning_rate": 5.460240963855422e-06,
      "loss": 0.0024,
      "step": 120680
    },
    {
      "epoch": 14.540963855421687,
      "grad_norm": 0.012127493508160114,
      "learning_rate": 5.459036144578314e-06,
      "loss": 0.0121,
      "step": 120690
    },
    {
      "epoch": 14.542168674698795,
      "grad_norm": 0.9840649962425232,
      "learning_rate": 5.457831325301205e-06,
      "loss": 0.0122,
      "step": 120700
    },
    {
      "epoch": 14.543373493975903,
      "grad_norm": 0.022117866203188896,
      "learning_rate": 5.456626506024096e-06,
      "loss": 0.0174,
      "step": 120710
    },
    {
      "epoch": 14.544578313253012,
      "grad_norm": 0.0003784637083299458,
      "learning_rate": 5.455421686746989e-06,
      "loss": 0.0067,
      "step": 120720
    },
    {
      "epoch": 14.54578313253012,
      "grad_norm": 0.010046451352536678,
      "learning_rate": 5.45421686746988e-06,
      "loss": 0.0201,
      "step": 120730
    },
    {
      "epoch": 14.546987951807228,
      "grad_norm": 0.00030170471291057765,
      "learning_rate": 5.453012048192772e-06,
      "loss": 0.0151,
      "step": 120740
    },
    {
      "epoch": 14.548192771084338,
      "grad_norm": 0.008670161478221416,
      "learning_rate": 5.451807228915663e-06,
      "loss": 0.0078,
      "step": 120750
    },
    {
      "epoch": 14.549397590361446,
      "grad_norm": 0.7285609245300293,
      "learning_rate": 5.450602409638555e-06,
      "loss": 0.0188,
      "step": 120760
    },
    {
      "epoch": 14.550602409638554,
      "grad_norm": 0.001257823663763702,
      "learning_rate": 5.449397590361446e-06,
      "loss": 0.0269,
      "step": 120770
    },
    {
      "epoch": 14.551807228915663,
      "grad_norm": 0.7329111099243164,
      "learning_rate": 5.448192771084337e-06,
      "loss": 0.0028,
      "step": 120780
    },
    {
      "epoch": 14.553012048192771,
      "grad_norm": 0.00021930495859123766,
      "learning_rate": 5.446987951807229e-06,
      "loss": 0.0138,
      "step": 120790
    },
    {
      "epoch": 14.55421686746988,
      "grad_norm": 0.0006181427743285894,
      "learning_rate": 5.445783132530121e-06,
      "loss": 0.0076,
      "step": 120800
    },
    {
      "epoch": 14.555421686746987,
      "grad_norm": 0.34044262766838074,
      "learning_rate": 5.444578313253013e-06,
      "loss": 0.0059,
      "step": 120810
    },
    {
      "epoch": 14.556626506024097,
      "grad_norm": 0.00025957298930734396,
      "learning_rate": 5.4433734939759045e-06,
      "loss": 0.0043,
      "step": 120820
    },
    {
      "epoch": 14.557831325301205,
      "grad_norm": 0.0004057835030835122,
      "learning_rate": 5.442168674698795e-06,
      "loss": 0.0046,
      "step": 120830
    },
    {
      "epoch": 14.559036144578313,
      "grad_norm": 0.43849238753318787,
      "learning_rate": 5.440963855421687e-06,
      "loss": 0.0284,
      "step": 120840
    },
    {
      "epoch": 14.560240963855422,
      "grad_norm": 0.011391466483473778,
      "learning_rate": 5.439759036144578e-06,
      "loss": 0.0215,
      "step": 120850
    },
    {
      "epoch": 14.56144578313253,
      "grad_norm": 0.0020075603388249874,
      "learning_rate": 5.43855421686747e-06,
      "loss": 0.0115,
      "step": 120860
    },
    {
      "epoch": 14.562650602409638,
      "grad_norm": 0.000314760603941977,
      "learning_rate": 5.4373493975903624e-06,
      "loss": 0.0001,
      "step": 120870
    },
    {
      "epoch": 14.563855421686746,
      "grad_norm": 1.3372678756713867,
      "learning_rate": 5.436144578313254e-06,
      "loss": 0.0107,
      "step": 120880
    },
    {
      "epoch": 14.565060240963856,
      "grad_norm": 0.2834654152393341,
      "learning_rate": 5.434939759036146e-06,
      "loss": 0.0227,
      "step": 120890
    },
    {
      "epoch": 14.566265060240964,
      "grad_norm": 1.0883255004882812,
      "learning_rate": 5.433734939759036e-06,
      "loss": 0.013,
      "step": 120900
    },
    {
      "epoch": 14.567469879518072,
      "grad_norm": 0.06369340419769287,
      "learning_rate": 5.432530120481928e-06,
      "loss": 0.0051,
      "step": 120910
    },
    {
      "epoch": 14.568674698795181,
      "grad_norm": 0.5695465803146362,
      "learning_rate": 5.4313253012048195e-06,
      "loss": 0.0269,
      "step": 120920
    },
    {
      "epoch": 14.56987951807229,
      "grad_norm": 0.15936000645160675,
      "learning_rate": 5.430120481927711e-06,
      "loss": 0.0145,
      "step": 120930
    },
    {
      "epoch": 14.571084337349397,
      "grad_norm": 0.9282070398330688,
      "learning_rate": 5.428915662650603e-06,
      "loss": 0.0359,
      "step": 120940
    },
    {
      "epoch": 14.572289156626507,
      "grad_norm": 0.0002796109183691442,
      "learning_rate": 5.427710843373495e-06,
      "loss": 0.025,
      "step": 120950
    },
    {
      "epoch": 14.573493975903615,
      "grad_norm": 0.0002928877074737102,
      "learning_rate": 5.426506024096386e-06,
      "loss": 0.0017,
      "step": 120960
    },
    {
      "epoch": 14.574698795180723,
      "grad_norm": 0.00044976940262131393,
      "learning_rate": 5.4253012048192775e-06,
      "loss": 0.0059,
      "step": 120970
    },
    {
      "epoch": 14.57590361445783,
      "grad_norm": 0.00035469653084874153,
      "learning_rate": 5.424096385542169e-06,
      "loss": 0.0188,
      "step": 120980
    },
    {
      "epoch": 14.57710843373494,
      "grad_norm": 0.0007963406387716532,
      "learning_rate": 5.422891566265061e-06,
      "loss": 0.0288,
      "step": 120990
    },
    {
      "epoch": 14.578313253012048,
      "grad_norm": 0.0007685096352361143,
      "learning_rate": 5.421686746987952e-06,
      "loss": 0.0102,
      "step": 121000
    },
    {
      "epoch": 14.579518072289156,
      "grad_norm": 1.0824079513549805,
      "learning_rate": 5.420481927710843e-06,
      "loss": 0.0101,
      "step": 121010
    },
    {
      "epoch": 14.580722891566266,
      "grad_norm": 0.004072312731295824,
      "learning_rate": 5.419277108433736e-06,
      "loss": 0.0146,
      "step": 121020
    },
    {
      "epoch": 14.581927710843374,
      "grad_norm": 0.018754666671156883,
      "learning_rate": 5.418072289156627e-06,
      "loss": 0.011,
      "step": 121030
    },
    {
      "epoch": 14.583132530120482,
      "grad_norm": 0.0006173726869747043,
      "learning_rate": 5.416867469879519e-06,
      "loss": 0.0505,
      "step": 121040
    },
    {
      "epoch": 14.58433734939759,
      "grad_norm": 0.0010242274729534984,
      "learning_rate": 5.41566265060241e-06,
      "loss": 0.0179,
      "step": 121050
    },
    {
      "epoch": 14.5855421686747,
      "grad_norm": 0.0012769420864060521,
      "learning_rate": 5.414457831325302e-06,
      "loss": 0.0388,
      "step": 121060
    },
    {
      "epoch": 14.586746987951807,
      "grad_norm": 0.0009439389104954898,
      "learning_rate": 5.413253012048193e-06,
      "loss": 0.0043,
      "step": 121070
    },
    {
      "epoch": 14.587951807228915,
      "grad_norm": 0.002011285861954093,
      "learning_rate": 5.412048192771084e-06,
      "loss": 0.0099,
      "step": 121080
    },
    {
      "epoch": 14.589156626506025,
      "grad_norm": 0.0020122264977544546,
      "learning_rate": 5.410843373493976e-06,
      "loss": 0.0223,
      "step": 121090
    },
    {
      "epoch": 14.590361445783133,
      "grad_norm": 0.01800195686519146,
      "learning_rate": 5.409638554216868e-06,
      "loss": 0.0295,
      "step": 121100
    },
    {
      "epoch": 14.59156626506024,
      "grad_norm": 0.23354321718215942,
      "learning_rate": 5.40843373493976e-06,
      "loss": 0.0053,
      "step": 121110
    },
    {
      "epoch": 14.592771084337349,
      "grad_norm": 0.0008953319047577679,
      "learning_rate": 5.407228915662651e-06,
      "loss": 0.0106,
      "step": 121120
    },
    {
      "epoch": 14.593975903614458,
      "grad_norm": 0.00923442654311657,
      "learning_rate": 5.406024096385543e-06,
      "loss": 0.0116,
      "step": 121130
    },
    {
      "epoch": 14.595180722891566,
      "grad_norm": 0.0011793053708970547,
      "learning_rate": 5.404819277108434e-06,
      "loss": 0.0063,
      "step": 121140
    },
    {
      "epoch": 14.596385542168674,
      "grad_norm": 0.0006106295040808618,
      "learning_rate": 5.403614457831325e-06,
      "loss": 0.0107,
      "step": 121150
    },
    {
      "epoch": 14.597590361445784,
      "grad_norm": 0.0005173311219550669,
      "learning_rate": 5.402409638554217e-06,
      "loss": 0.0118,
      "step": 121160
    },
    {
      "epoch": 14.598795180722892,
      "grad_norm": 0.2813345789909363,
      "learning_rate": 5.401204819277109e-06,
      "loss": 0.0026,
      "step": 121170
    },
    {
      "epoch": 14.6,
      "grad_norm": 0.0006630824063904583,
      "learning_rate": 5.400000000000001e-06,
      "loss": 0.0119,
      "step": 121180
    },
    {
      "epoch": 14.601204819277108,
      "grad_norm": 0.0008247758960351348,
      "learning_rate": 5.398795180722892e-06,
      "loss": 0.0037,
      "step": 121190
    },
    {
      "epoch": 14.602409638554217,
      "grad_norm": 0.0005880715325474739,
      "learning_rate": 5.397590361445784e-06,
      "loss": 0.0375,
      "step": 121200
    },
    {
      "epoch": 14.603614457831325,
      "grad_norm": 1.6794298887252808,
      "learning_rate": 5.396385542168675e-06,
      "loss": 0.0156,
      "step": 121210
    },
    {
      "epoch": 14.604819277108433,
      "grad_norm": 0.0005440632230602205,
      "learning_rate": 5.395180722891566e-06,
      "loss": 0.0055,
      "step": 121220
    },
    {
      "epoch": 14.606024096385543,
      "grad_norm": 0.984909176826477,
      "learning_rate": 5.393975903614458e-06,
      "loss": 0.0113,
      "step": 121230
    },
    {
      "epoch": 14.60722891566265,
      "grad_norm": 0.0005604454781860113,
      "learning_rate": 5.3927710843373495e-06,
      "loss": 0.0032,
      "step": 121240
    },
    {
      "epoch": 14.608433734939759,
      "grad_norm": 0.9020318388938904,
      "learning_rate": 5.391566265060242e-06,
      "loss": 0.0113,
      "step": 121250
    },
    {
      "epoch": 14.609638554216868,
      "grad_norm": 0.0034693998750299215,
      "learning_rate": 5.3903614457831335e-06,
      "loss": 0.0063,
      "step": 121260
    },
    {
      "epoch": 14.610843373493976,
      "grad_norm": 0.9177417159080505,
      "learning_rate": 5.389156626506024e-06,
      "loss": 0.0262,
      "step": 121270
    },
    {
      "epoch": 14.612048192771084,
      "grad_norm": 0.0014638456050306559,
      "learning_rate": 5.387951807228916e-06,
      "loss": 0.0029,
      "step": 121280
    },
    {
      "epoch": 14.613253012048192,
      "grad_norm": 0.004422172904014587,
      "learning_rate": 5.3867469879518074e-06,
      "loss": 0.0054,
      "step": 121290
    },
    {
      "epoch": 14.614457831325302,
      "grad_norm": 0.20140044391155243,
      "learning_rate": 5.385542168674699e-06,
      "loss": 0.0011,
      "step": 121300
    },
    {
      "epoch": 14.61566265060241,
      "grad_norm": 0.005249813199043274,
      "learning_rate": 5.384337349397591e-06,
      "loss": 0.0078,
      "step": 121310
    },
    {
      "epoch": 14.616867469879518,
      "grad_norm": 1.3591455221176147,
      "learning_rate": 5.383132530120483e-06,
      "loss": 0.0215,
      "step": 121320
    },
    {
      "epoch": 14.618072289156627,
      "grad_norm": 0.0005683832569047809,
      "learning_rate": 5.381927710843375e-06,
      "loss": 0.033,
      "step": 121330
    },
    {
      "epoch": 14.619277108433735,
      "grad_norm": 0.011332755908370018,
      "learning_rate": 5.380722891566265e-06,
      "loss": 0.0325,
      "step": 121340
    },
    {
      "epoch": 14.620481927710843,
      "grad_norm": 0.0005603842437267303,
      "learning_rate": 5.379518072289157e-06,
      "loss": 0.0102,
      "step": 121350
    },
    {
      "epoch": 14.621686746987951,
      "grad_norm": 0.003246007952839136,
      "learning_rate": 5.3783132530120486e-06,
      "loss": 0.0001,
      "step": 121360
    },
    {
      "epoch": 14.62289156626506,
      "grad_norm": 0.0005357308546081185,
      "learning_rate": 5.37710843373494e-06,
      "loss": 0.0096,
      "step": 121370
    },
    {
      "epoch": 14.624096385542169,
      "grad_norm": 1.1335601806640625,
      "learning_rate": 5.375903614457832e-06,
      "loss": 0.0073,
      "step": 121380
    },
    {
      "epoch": 14.625301204819277,
      "grad_norm": 0.0006520208553411067,
      "learning_rate": 5.3746987951807225e-06,
      "loss": 0.0051,
      "step": 121390
    },
    {
      "epoch": 14.626506024096386,
      "grad_norm": 0.0006513414555229247,
      "learning_rate": 5.373493975903615e-06,
      "loss": 0.0047,
      "step": 121400
    },
    {
      "epoch": 14.627710843373494,
      "grad_norm": 0.0036638088058680296,
      "learning_rate": 5.3722891566265065e-06,
      "loss": 0.0043,
      "step": 121410
    },
    {
      "epoch": 14.628915662650602,
      "grad_norm": 0.00041800044709816575,
      "learning_rate": 5.371084337349398e-06,
      "loss": 0.0099,
      "step": 121420
    },
    {
      "epoch": 14.630120481927712,
      "grad_norm": 0.000471630715765059,
      "learning_rate": 5.36987951807229e-06,
      "loss": 0.0258,
      "step": 121430
    },
    {
      "epoch": 14.63132530120482,
      "grad_norm": 0.002509207231923938,
      "learning_rate": 5.368674698795181e-06,
      "loss": 0.0234,
      "step": 121440
    },
    {
      "epoch": 14.632530120481928,
      "grad_norm": 0.0009665880352258682,
      "learning_rate": 5.367469879518072e-06,
      "loss": 0.0194,
      "step": 121450
    },
    {
      "epoch": 14.633734939759035,
      "grad_norm": 1.065341830253601,
      "learning_rate": 5.366265060240964e-06,
      "loss": 0.0235,
      "step": 121460
    },
    {
      "epoch": 14.634939759036145,
      "grad_norm": 0.000472017505671829,
      "learning_rate": 5.365060240963856e-06,
      "loss": 0.0067,
      "step": 121470
    },
    {
      "epoch": 14.636144578313253,
      "grad_norm": 0.0013224806170910597,
      "learning_rate": 5.363855421686748e-06,
      "loss": 0.0001,
      "step": 121480
    },
    {
      "epoch": 14.637349397590361,
      "grad_norm": 21.968921661376953,
      "learning_rate": 5.362650602409639e-06,
      "loss": 0.0329,
      "step": 121490
    },
    {
      "epoch": 14.638554216867469,
      "grad_norm": 5.5422258377075195,
      "learning_rate": 5.361445783132531e-06,
      "loss": 0.0345,
      "step": 121500
    },
    {
      "epoch": 14.639759036144579,
      "grad_norm": 0.3489459156990051,
      "learning_rate": 5.360240963855422e-06,
      "loss": 0.0188,
      "step": 121510
    },
    {
      "epoch": 14.640963855421687,
      "grad_norm": 0.014921588823199272,
      "learning_rate": 5.359036144578313e-06,
      "loss": 0.0233,
      "step": 121520
    },
    {
      "epoch": 14.642168674698794,
      "grad_norm": 0.001904137316159904,
      "learning_rate": 5.357831325301205e-06,
      "loss": 0.0071,
      "step": 121530
    },
    {
      "epoch": 14.643373493975904,
      "grad_norm": 0.2631755471229553,
      "learning_rate": 5.356626506024096e-06,
      "loss": 0.0168,
      "step": 121540
    },
    {
      "epoch": 14.644578313253012,
      "grad_norm": 1.8283743858337402,
      "learning_rate": 5.355421686746989e-06,
      "loss": 0.0248,
      "step": 121550
    },
    {
      "epoch": 14.64578313253012,
      "grad_norm": 0.0075758397579193115,
      "learning_rate": 5.35421686746988e-06,
      "loss": 0.0039,
      "step": 121560
    },
    {
      "epoch": 14.64698795180723,
      "grad_norm": 0.001536812400445342,
      "learning_rate": 5.353012048192772e-06,
      "loss": 0.0069,
      "step": 121570
    },
    {
      "epoch": 14.648192771084338,
      "grad_norm": 0.995568037033081,
      "learning_rate": 5.3518072289156635e-06,
      "loss": 0.0081,
      "step": 121580
    },
    {
      "epoch": 14.649397590361446,
      "grad_norm": 1.2445390224456787,
      "learning_rate": 5.350602409638554e-06,
      "loss": 0.0224,
      "step": 121590
    },
    {
      "epoch": 14.650602409638553,
      "grad_norm": 1.043472170829773,
      "learning_rate": 5.349397590361446e-06,
      "loss": 0.0207,
      "step": 121600
    },
    {
      "epoch": 14.651807228915663,
      "grad_norm": 0.00042695438605733216,
      "learning_rate": 5.348192771084337e-06,
      "loss": 0.0159,
      "step": 121610
    },
    {
      "epoch": 14.653012048192771,
      "grad_norm": 0.0005455311038531363,
      "learning_rate": 5.34698795180723e-06,
      "loss": 0.0021,
      "step": 121620
    },
    {
      "epoch": 14.654216867469879,
      "grad_norm": 1.5271917581558228,
      "learning_rate": 5.3457831325301214e-06,
      "loss": 0.0145,
      "step": 121630
    },
    {
      "epoch": 14.655421686746989,
      "grad_norm": 0.2659221887588501,
      "learning_rate": 5.344578313253013e-06,
      "loss": 0.0084,
      "step": 121640
    },
    {
      "epoch": 14.656626506024097,
      "grad_norm": 0.17712661623954773,
      "learning_rate": 5.343373493975904e-06,
      "loss": 0.0104,
      "step": 121650
    },
    {
      "epoch": 14.657831325301204,
      "grad_norm": 5.082473278045654,
      "learning_rate": 5.342168674698795e-06,
      "loss": 0.052,
      "step": 121660
    },
    {
      "epoch": 14.659036144578312,
      "grad_norm": 0.9445840716362,
      "learning_rate": 5.340963855421687e-06,
      "loss": 0.0143,
      "step": 121670
    },
    {
      "epoch": 14.660240963855422,
      "grad_norm": 0.2603820860385895,
      "learning_rate": 5.3397590361445785e-06,
      "loss": 0.0053,
      "step": 121680
    },
    {
      "epoch": 14.66144578313253,
      "grad_norm": 0.0013799247099086642,
      "learning_rate": 5.33855421686747e-06,
      "loss": 0.0164,
      "step": 121690
    },
    {
      "epoch": 14.662650602409638,
      "grad_norm": 0.004530887119472027,
      "learning_rate": 5.3373493975903625e-06,
      "loss": 0.0153,
      "step": 121700
    },
    {
      "epoch": 14.663855421686748,
      "grad_norm": 0.0014230069937184453,
      "learning_rate": 5.336144578313254e-06,
      "loss": 0.0026,
      "step": 121710
    },
    {
      "epoch": 14.665060240963856,
      "grad_norm": 0.000660884368699044,
      "learning_rate": 5.334939759036145e-06,
      "loss": 0.0182,
      "step": 121720
    },
    {
      "epoch": 14.666265060240963,
      "grad_norm": 0.0005641955649480224,
      "learning_rate": 5.3337349397590365e-06,
      "loss": 0.0085,
      "step": 121730
    },
    {
      "epoch": 14.667469879518073,
      "grad_norm": 0.00037503414205275476,
      "learning_rate": 5.332530120481928e-06,
      "loss": 0.0154,
      "step": 121740
    },
    {
      "epoch": 14.668674698795181,
      "grad_norm": 0.0012433414813131094,
      "learning_rate": 5.33132530120482e-06,
      "loss": 0.0063,
      "step": 121750
    },
    {
      "epoch": 14.669879518072289,
      "grad_norm": 0.0009002811275422573,
      "learning_rate": 5.330120481927711e-06,
      "loss": 0.007,
      "step": 121760
    },
    {
      "epoch": 14.671084337349397,
      "grad_norm": 0.48429009318351746,
      "learning_rate": 5.328915662650604e-06,
      "loss": 0.007,
      "step": 121770
    },
    {
      "epoch": 14.672289156626507,
      "grad_norm": 0.006593964993953705,
      "learning_rate": 5.327710843373494e-06,
      "loss": 0.0042,
      "step": 121780
    },
    {
      "epoch": 14.673493975903614,
      "grad_norm": 0.0012764559360221028,
      "learning_rate": 5.326506024096386e-06,
      "loss": 0.0046,
      "step": 121790
    },
    {
      "epoch": 14.674698795180722,
      "grad_norm": 0.00038519964437000453,
      "learning_rate": 5.325301204819278e-06,
      "loss": 0.0023,
      "step": 121800
    },
    {
      "epoch": 14.675903614457832,
      "grad_norm": 14.228264808654785,
      "learning_rate": 5.324096385542169e-06,
      "loss": 0.0506,
      "step": 121810
    },
    {
      "epoch": 14.67710843373494,
      "grad_norm": 0.8130667805671692,
      "learning_rate": 5.322891566265061e-06,
      "loss": 0.0105,
      "step": 121820
    },
    {
      "epoch": 14.678313253012048,
      "grad_norm": 0.0003394402447156608,
      "learning_rate": 5.3216867469879515e-06,
      "loss": 0.0616,
      "step": 121830
    },
    {
      "epoch": 14.679518072289156,
      "grad_norm": 1.9785393476486206,
      "learning_rate": 5.320481927710843e-06,
      "loss": 0.0124,
      "step": 121840
    },
    {
      "epoch": 14.680722891566266,
      "grad_norm": 0.0006873460370115936,
      "learning_rate": 5.3192771084337355e-06,
      "loss": 0.031,
      "step": 121850
    },
    {
      "epoch": 14.681927710843373,
      "grad_norm": 1.1154229640960693,
      "learning_rate": 5.318072289156627e-06,
      "loss": 0.064,
      "step": 121860
    },
    {
      "epoch": 14.683132530120481,
      "grad_norm": 0.015248251147568226,
      "learning_rate": 5.316867469879519e-06,
      "loss": 0.0042,
      "step": 121870
    },
    {
      "epoch": 14.684337349397591,
      "grad_norm": 0.001742655411362648,
      "learning_rate": 5.31566265060241e-06,
      "loss": 0.0029,
      "step": 121880
    },
    {
      "epoch": 14.685542168674699,
      "grad_norm": 0.00550517113879323,
      "learning_rate": 5.314457831325302e-06,
      "loss": 0.0083,
      "step": 121890
    },
    {
      "epoch": 14.686746987951807,
      "grad_norm": 0.9397504329681396,
      "learning_rate": 5.313253012048193e-06,
      "loss": 0.0208,
      "step": 121900
    },
    {
      "epoch": 14.687951807228917,
      "grad_norm": 0.0076456633396446705,
      "learning_rate": 5.312048192771084e-06,
      "loss": 0.0081,
      "step": 121910
    },
    {
      "epoch": 14.689156626506024,
      "grad_norm": 0.003545867744833231,
      "learning_rate": 5.310843373493977e-06,
      "loss": 0.0119,
      "step": 121920
    },
    {
      "epoch": 14.690361445783132,
      "grad_norm": 0.0046757603995501995,
      "learning_rate": 5.309638554216868e-06,
      "loss": 0.0107,
      "step": 121930
    },
    {
      "epoch": 14.69156626506024,
      "grad_norm": 1.8444881439208984,
      "learning_rate": 5.30843373493976e-06,
      "loss": 0.0139,
      "step": 121940
    },
    {
      "epoch": 14.69277108433735,
      "grad_norm": 0.0009658008348196745,
      "learning_rate": 5.307228915662651e-06,
      "loss": 0.013,
      "step": 121950
    },
    {
      "epoch": 14.693975903614458,
      "grad_norm": 0.004804414696991444,
      "learning_rate": 5.306024096385542e-06,
      "loss": 0.0125,
      "step": 121960
    },
    {
      "epoch": 14.695180722891566,
      "grad_norm": 0.0008325353264808655,
      "learning_rate": 5.304819277108434e-06,
      "loss": 0.0049,
      "step": 121970
    },
    {
      "epoch": 14.696385542168674,
      "grad_norm": 0.3546921908855438,
      "learning_rate": 5.303614457831325e-06,
      "loss": 0.0046,
      "step": 121980
    },
    {
      "epoch": 14.697590361445783,
      "grad_norm": 0.6580097675323486,
      "learning_rate": 5.302409638554217e-06,
      "loss": 0.0191,
      "step": 121990
    },
    {
      "epoch": 14.698795180722891,
      "grad_norm": 0.005655538756400347,
      "learning_rate": 5.301204819277109e-06,
      "loss": 0.0111,
      "step": 122000
    },
    {
      "epoch": 14.7,
      "grad_norm": 0.008735084906220436,
      "learning_rate": 5.300000000000001e-06,
      "loss": 0.0172,
      "step": 122010
    },
    {
      "epoch": 14.701204819277109,
      "grad_norm": 0.1397402137517929,
      "learning_rate": 5.2987951807228925e-06,
      "loss": 0.0161,
      "step": 122020
    },
    {
      "epoch": 14.702409638554217,
      "grad_norm": 0.0032094165217131376,
      "learning_rate": 5.297590361445783e-06,
      "loss": 0.0292,
      "step": 122030
    },
    {
      "epoch": 14.703614457831325,
      "grad_norm": 0.0025528811383992434,
      "learning_rate": 5.296385542168675e-06,
      "loss": 0.011,
      "step": 122040
    },
    {
      "epoch": 14.704819277108435,
      "grad_norm": 0.2636405825614929,
      "learning_rate": 5.2951807228915664e-06,
      "loss": 0.0134,
      "step": 122050
    },
    {
      "epoch": 14.706024096385542,
      "grad_norm": 0.0004925475222989917,
      "learning_rate": 5.293975903614458e-06,
      "loss": 0.0129,
      "step": 122060
    },
    {
      "epoch": 14.70722891566265,
      "grad_norm": 1.41063392162323,
      "learning_rate": 5.2927710843373505e-06,
      "loss": 0.008,
      "step": 122070
    },
    {
      "epoch": 14.708433734939758,
      "grad_norm": 0.8547261357307434,
      "learning_rate": 5.291566265060242e-06,
      "loss": 0.0127,
      "step": 122080
    },
    {
      "epoch": 14.709638554216868,
      "grad_norm": 0.0002711837296374142,
      "learning_rate": 5.290361445783133e-06,
      "loss": 0.0101,
      "step": 122090
    },
    {
      "epoch": 14.710843373493976,
      "grad_norm": 0.001508643850684166,
      "learning_rate": 5.289156626506024e-06,
      "loss": 0.0393,
      "step": 122100
    },
    {
      "epoch": 14.712048192771084,
      "grad_norm": 0.6825047135353088,
      "learning_rate": 5.287951807228916e-06,
      "loss": 0.0115,
      "step": 122110
    },
    {
      "epoch": 14.713253012048193,
      "grad_norm": 0.6191203594207764,
      "learning_rate": 5.2867469879518075e-06,
      "loss": 0.008,
      "step": 122120
    },
    {
      "epoch": 14.714457831325301,
      "grad_norm": 1.9296541213989258,
      "learning_rate": 5.285542168674699e-06,
      "loss": 0.0108,
      "step": 122130
    },
    {
      "epoch": 14.71566265060241,
      "grad_norm": 0.952433168888092,
      "learning_rate": 5.28433734939759e-06,
      "loss": 0.0053,
      "step": 122140
    },
    {
      "epoch": 14.716867469879517,
      "grad_norm": 0.0003407563199289143,
      "learning_rate": 5.283132530120483e-06,
      "loss": 0.0128,
      "step": 122150
    },
    {
      "epoch": 14.718072289156627,
      "grad_norm": 0.029072964563965797,
      "learning_rate": 5.281927710843374e-06,
      "loss": 0.0284,
      "step": 122160
    },
    {
      "epoch": 14.719277108433735,
      "grad_norm": 0.0054815830662846565,
      "learning_rate": 5.2807228915662655e-06,
      "loss": 0.0198,
      "step": 122170
    },
    {
      "epoch": 14.720481927710843,
      "grad_norm": 0.00018558456213213503,
      "learning_rate": 5.279518072289157e-06,
      "loss": 0.0087,
      "step": 122180
    },
    {
      "epoch": 14.721686746987952,
      "grad_norm": 1.743909239768982,
      "learning_rate": 5.278313253012049e-06,
      "loss": 0.0254,
      "step": 122190
    },
    {
      "epoch": 14.72289156626506,
      "grad_norm": 0.007189648691564798,
      "learning_rate": 5.27710843373494e-06,
      "loss": 0.0013,
      "step": 122200
    },
    {
      "epoch": 14.724096385542168,
      "grad_norm": 0.0003772915806621313,
      "learning_rate": 5.275903614457831e-06,
      "loss": 0.0151,
      "step": 122210
    },
    {
      "epoch": 14.725301204819278,
      "grad_norm": 0.6814836263656616,
      "learning_rate": 5.2746987951807234e-06,
      "loss": 0.0429,
      "step": 122220
    },
    {
      "epoch": 14.726506024096386,
      "grad_norm": 0.0003061612951569259,
      "learning_rate": 5.273493975903615e-06,
      "loss": 0.0172,
      "step": 122230
    },
    {
      "epoch": 14.727710843373494,
      "grad_norm": 0.00022058145259507,
      "learning_rate": 5.272289156626507e-06,
      "loss": 0.0181,
      "step": 122240
    },
    {
      "epoch": 14.728915662650602,
      "grad_norm": 0.0002984851016663015,
      "learning_rate": 5.271084337349398e-06,
      "loss": 0.0122,
      "step": 122250
    },
    {
      "epoch": 14.730120481927711,
      "grad_norm": 0.017564481124281883,
      "learning_rate": 5.26987951807229e-06,
      "loss": 0.0181,
      "step": 122260
    },
    {
      "epoch": 14.73132530120482,
      "grad_norm": 0.2839280068874359,
      "learning_rate": 5.2686746987951805e-06,
      "loss": 0.018,
      "step": 122270
    },
    {
      "epoch": 14.732530120481927,
      "grad_norm": 0.0007448785472661257,
      "learning_rate": 5.267469879518072e-06,
      "loss": 0.0,
      "step": 122280
    },
    {
      "epoch": 14.733734939759037,
      "grad_norm": 1.3999862670898438,
      "learning_rate": 5.266265060240964e-06,
      "loss": 0.0255,
      "step": 122290
    },
    {
      "epoch": 14.734939759036145,
      "grad_norm": 0.0015298420330509543,
      "learning_rate": 5.265060240963856e-06,
      "loss": 0.007,
      "step": 122300
    },
    {
      "epoch": 14.736144578313253,
      "grad_norm": 0.00779718067497015,
      "learning_rate": 5.263855421686748e-06,
      "loss": 0.0135,
      "step": 122310
    },
    {
      "epoch": 14.73734939759036,
      "grad_norm": 0.004558596760034561,
      "learning_rate": 5.262650602409639e-06,
      "loss": 0.0293,
      "step": 122320
    },
    {
      "epoch": 14.73855421686747,
      "grad_norm": 0.103180430829525,
      "learning_rate": 5.261445783132531e-06,
      "loss": 0.0035,
      "step": 122330
    },
    {
      "epoch": 14.739759036144578,
      "grad_norm": 0.013036718592047691,
      "learning_rate": 5.260240963855422e-06,
      "loss": 0.0385,
      "step": 122340
    },
    {
      "epoch": 14.740963855421686,
      "grad_norm": 0.0022591131273657084,
      "learning_rate": 5.259036144578313e-06,
      "loss": 0.0203,
      "step": 122350
    },
    {
      "epoch": 14.742168674698796,
      "grad_norm": 0.24376210570335388,
      "learning_rate": 5.257831325301205e-06,
      "loss": 0.0106,
      "step": 122360
    },
    {
      "epoch": 14.743373493975904,
      "grad_norm": 0.03962573781609535,
      "learning_rate": 5.256626506024097e-06,
      "loss": 0.0154,
      "step": 122370
    },
    {
      "epoch": 14.744578313253012,
      "grad_norm": 0.0005773574812337756,
      "learning_rate": 5.255421686746989e-06,
      "loss": 0.0092,
      "step": 122380
    },
    {
      "epoch": 14.745783132530121,
      "grad_norm": 1.3846256732940674,
      "learning_rate": 5.25421686746988e-06,
      "loss": 0.0163,
      "step": 122390
    },
    {
      "epoch": 14.74698795180723,
      "grad_norm": 0.4062342941761017,
      "learning_rate": 5.253012048192771e-06,
      "loss": 0.0113,
      "step": 122400
    },
    {
      "epoch": 14.748192771084337,
      "grad_norm": 1.4846339225769043,
      "learning_rate": 5.251807228915663e-06,
      "loss": 0.023,
      "step": 122410
    },
    {
      "epoch": 14.749397590361445,
      "grad_norm": 0.6799275875091553,
      "learning_rate": 5.250602409638554e-06,
      "loss": 0.0048,
      "step": 122420
    },
    {
      "epoch": 14.750602409638555,
      "grad_norm": 0.2906840443611145,
      "learning_rate": 5.249397590361446e-06,
      "loss": 0.0112,
      "step": 122430
    },
    {
      "epoch": 14.751807228915663,
      "grad_norm": 0.0004168862651567906,
      "learning_rate": 5.248192771084338e-06,
      "loss": 0.0068,
      "step": 122440
    },
    {
      "epoch": 14.75301204819277,
      "grad_norm": 0.007434036582708359,
      "learning_rate": 5.24698795180723e-06,
      "loss": 0.0014,
      "step": 122450
    },
    {
      "epoch": 14.754216867469879,
      "grad_norm": 0.001368959085084498,
      "learning_rate": 5.2457831325301215e-06,
      "loss": 0.0075,
      "step": 122460
    },
    {
      "epoch": 14.755421686746988,
      "grad_norm": 0.0006267930148169398,
      "learning_rate": 5.244578313253012e-06,
      "loss": 0.0092,
      "step": 122470
    },
    {
      "epoch": 14.756626506024096,
      "grad_norm": 0.0004572209727484733,
      "learning_rate": 5.243373493975904e-06,
      "loss": 0.0219,
      "step": 122480
    },
    {
      "epoch": 14.757831325301204,
      "grad_norm": 0.00032659422140568495,
      "learning_rate": 5.2421686746987955e-06,
      "loss": 0.0113,
      "step": 122490
    },
    {
      "epoch": 14.759036144578314,
      "grad_norm": 15.18732738494873,
      "learning_rate": 5.240963855421687e-06,
      "loss": 0.051,
      "step": 122500
    },
    {
      "epoch": 14.760240963855422,
      "grad_norm": 0.0003016742703039199,
      "learning_rate": 5.239759036144579e-06,
      "loss": 0.0134,
      "step": 122510
    },
    {
      "epoch": 14.76144578313253,
      "grad_norm": 0.035268284380435944,
      "learning_rate": 5.238554216867471e-06,
      "loss": 0.0051,
      "step": 122520
    },
    {
      "epoch": 14.76265060240964,
      "grad_norm": 0.0007633257773704827,
      "learning_rate": 5.237349397590362e-06,
      "loss": 0.0038,
      "step": 122530
    },
    {
      "epoch": 14.763855421686747,
      "grad_norm": 0.00025112577714025974,
      "learning_rate": 5.236144578313253e-06,
      "loss": 0.01,
      "step": 122540
    },
    {
      "epoch": 14.765060240963855,
      "grad_norm": 2.0369255542755127,
      "learning_rate": 5.234939759036145e-06,
      "loss": 0.0154,
      "step": 122550
    },
    {
      "epoch": 14.766265060240963,
      "grad_norm": 0.018168428912758827,
      "learning_rate": 5.2337349397590366e-06,
      "loss": 0.0086,
      "step": 122560
    },
    {
      "epoch": 14.767469879518073,
      "grad_norm": 1.2468982934951782,
      "learning_rate": 5.232530120481928e-06,
      "loss": 0.0149,
      "step": 122570
    },
    {
      "epoch": 14.76867469879518,
      "grad_norm": 0.0004725829348899424,
      "learning_rate": 5.231325301204819e-06,
      "loss": 0.0011,
      "step": 122580
    },
    {
      "epoch": 14.769879518072289,
      "grad_norm": 0.15603020787239075,
      "learning_rate": 5.230120481927712e-06,
      "loss": 0.0233,
      "step": 122590
    },
    {
      "epoch": 14.771084337349398,
      "grad_norm": 0.00023676545242778957,
      "learning_rate": 5.228915662650603e-06,
      "loss": 0.0001,
      "step": 122600
    },
    {
      "epoch": 14.772289156626506,
      "grad_norm": 0.012552488595247269,
      "learning_rate": 5.2277108433734945e-06,
      "loss": 0.0119,
      "step": 122610
    },
    {
      "epoch": 14.773493975903614,
      "grad_norm": 0.0011557441903278232,
      "learning_rate": 5.226506024096386e-06,
      "loss": 0.0115,
      "step": 122620
    },
    {
      "epoch": 14.774698795180722,
      "grad_norm": 0.0004136927891522646,
      "learning_rate": 5.225301204819278e-06,
      "loss": 0.0487,
      "step": 122630
    },
    {
      "epoch": 14.775903614457832,
      "grad_norm": 0.7027302980422974,
      "learning_rate": 5.224096385542169e-06,
      "loss": 0.006,
      "step": 122640
    },
    {
      "epoch": 14.77710843373494,
      "grad_norm": 0.7939615845680237,
      "learning_rate": 5.22289156626506e-06,
      "loss": 0.0103,
      "step": 122650
    },
    {
      "epoch": 14.778313253012048,
      "grad_norm": 0.9416298866271973,
      "learning_rate": 5.221686746987952e-06,
      "loss": 0.0049,
      "step": 122660
    },
    {
      "epoch": 14.779518072289157,
      "grad_norm": 0.0029109695460647345,
      "learning_rate": 5.220481927710844e-06,
      "loss": 0.0133,
      "step": 122670
    },
    {
      "epoch": 14.780722891566265,
      "grad_norm": 0.022052139043807983,
      "learning_rate": 5.219277108433736e-06,
      "loss": 0.0107,
      "step": 122680
    },
    {
      "epoch": 14.781927710843373,
      "grad_norm": 1.3807246685028076,
      "learning_rate": 5.218072289156627e-06,
      "loss": 0.0133,
      "step": 122690
    },
    {
      "epoch": 14.783132530120483,
      "grad_norm": 0.0005115941166877747,
      "learning_rate": 5.216867469879519e-06,
      "loss": 0.0047,
      "step": 122700
    },
    {
      "epoch": 14.78433734939759,
      "grad_norm": 0.731808066368103,
      "learning_rate": 5.2156626506024095e-06,
      "loss": 0.014,
      "step": 122710
    },
    {
      "epoch": 14.785542168674699,
      "grad_norm": 0.00037440838059410453,
      "learning_rate": 5.214457831325301e-06,
      "loss": 0.0027,
      "step": 122720
    },
    {
      "epoch": 14.786746987951807,
      "grad_norm": 0.038445014506578445,
      "learning_rate": 5.213253012048193e-06,
      "loss": 0.0052,
      "step": 122730
    },
    {
      "epoch": 14.787951807228916,
      "grad_norm": 2.154376983642578,
      "learning_rate": 5.212048192771085e-06,
      "loss": 0.0154,
      "step": 122740
    },
    {
      "epoch": 14.789156626506024,
      "grad_norm": 0.0005540451384149492,
      "learning_rate": 5.210843373493977e-06,
      "loss": 0.013,
      "step": 122750
    },
    {
      "epoch": 14.790361445783132,
      "grad_norm": 0.00037951971171423793,
      "learning_rate": 5.209638554216868e-06,
      "loss": 0.0056,
      "step": 122760
    },
    {
      "epoch": 14.791566265060242,
      "grad_norm": 0.0001693038793746382,
      "learning_rate": 5.20843373493976e-06,
      "loss": 0.03,
      "step": 122770
    },
    {
      "epoch": 14.79277108433735,
      "grad_norm": 0.00013153685722500086,
      "learning_rate": 5.207228915662651e-06,
      "loss": 0.02,
      "step": 122780
    },
    {
      "epoch": 14.793975903614458,
      "grad_norm": 1.3115544319152832,
      "learning_rate": 5.206024096385542e-06,
      "loss": 0.0145,
      "step": 122790
    },
    {
      "epoch": 14.795180722891565,
      "grad_norm": 0.00042738928459584713,
      "learning_rate": 5.204819277108434e-06,
      "loss": 0.006,
      "step": 122800
    },
    {
      "epoch": 14.796385542168675,
      "grad_norm": 0.9285022616386414,
      "learning_rate": 5.2036144578313254e-06,
      "loss": 0.0131,
      "step": 122810
    },
    {
      "epoch": 14.797590361445783,
      "grad_norm": 0.3729010224342346,
      "learning_rate": 5.202409638554218e-06,
      "loss": 0.022,
      "step": 122820
    },
    {
      "epoch": 14.798795180722891,
      "grad_norm": 0.0005956963286735117,
      "learning_rate": 5.2012048192771094e-06,
      "loss": 0.0275,
      "step": 122830
    },
    {
      "epoch": 14.8,
      "grad_norm": 0.0034362899605184793,
      "learning_rate": 5.2e-06,
      "loss": 0.0032,
      "step": 122840
    },
    {
      "epoch": 14.801204819277109,
      "grad_norm": 1.0427392721176147,
      "learning_rate": 5.198795180722892e-06,
      "loss": 0.0085,
      "step": 122850
    },
    {
      "epoch": 14.802409638554217,
      "grad_norm": 0.004561087116599083,
      "learning_rate": 5.197590361445783e-06,
      "loss": 0.0133,
      "step": 122860
    },
    {
      "epoch": 14.803614457831326,
      "grad_norm": 22.73558807373047,
      "learning_rate": 5.196385542168675e-06,
      "loss": 0.0469,
      "step": 122870
    },
    {
      "epoch": 14.804819277108434,
      "grad_norm": 0.00020675081759691238,
      "learning_rate": 5.1951807228915665e-06,
      "loss": 0.0073,
      "step": 122880
    },
    {
      "epoch": 14.806024096385542,
      "grad_norm": 1.0930238962173462,
      "learning_rate": 5.193975903614459e-06,
      "loss": 0.013,
      "step": 122890
    },
    {
      "epoch": 14.80722891566265,
      "grad_norm": 0.0005160950822755694,
      "learning_rate": 5.1927710843373506e-06,
      "loss": 0.0291,
      "step": 122900
    },
    {
      "epoch": 14.80843373493976,
      "grad_norm": 0.845195472240448,
      "learning_rate": 5.191566265060241e-06,
      "loss": 0.0043,
      "step": 122910
    },
    {
      "epoch": 14.809638554216868,
      "grad_norm": 1.0257099866867065,
      "learning_rate": 5.190361445783133e-06,
      "loss": 0.0167,
      "step": 122920
    },
    {
      "epoch": 14.810843373493976,
      "grad_norm": 0.00016044116637203842,
      "learning_rate": 5.1891566265060245e-06,
      "loss": 0.0032,
      "step": 122930
    },
    {
      "epoch": 14.812048192771083,
      "grad_norm": 1.3686399459838867,
      "learning_rate": 5.187951807228916e-06,
      "loss": 0.0088,
      "step": 122940
    },
    {
      "epoch": 14.813253012048193,
      "grad_norm": 0.0003357142850290984,
      "learning_rate": 5.186746987951808e-06,
      "loss": 0.0073,
      "step": 122950
    },
    {
      "epoch": 14.814457831325301,
      "grad_norm": 0.00720168137922883,
      "learning_rate": 5.185542168674698e-06,
      "loss": 0.0179,
      "step": 122960
    },
    {
      "epoch": 14.815662650602409,
      "grad_norm": 0.00043255629134364426,
      "learning_rate": 5.184337349397592e-06,
      "loss": 0.005,
      "step": 122970
    },
    {
      "epoch": 14.816867469879519,
      "grad_norm": 0.0002045449218712747,
      "learning_rate": 5.183132530120482e-06,
      "loss": 0.0049,
      "step": 122980
    },
    {
      "epoch": 14.818072289156627,
      "grad_norm": 0.00023787001555319875,
      "learning_rate": 5.181927710843374e-06,
      "loss": 0.0142,
      "step": 122990
    },
    {
      "epoch": 14.819277108433734,
      "grad_norm": 0.005430559162050486,
      "learning_rate": 5.180722891566266e-06,
      "loss": 0.0421,
      "step": 123000
    },
    {
      "epoch": 14.820481927710844,
      "grad_norm": 0.0017321457853540778,
      "learning_rate": 5.179518072289157e-06,
      "loss": 0.0102,
      "step": 123010
    },
    {
      "epoch": 14.821686746987952,
      "grad_norm": 0.0158099178224802,
      "learning_rate": 5.178313253012048e-06,
      "loss": 0.0094,
      "step": 123020
    },
    {
      "epoch": 14.82289156626506,
      "grad_norm": 0.00020261610916350037,
      "learning_rate": 5.1771084337349395e-06,
      "loss": 0.0079,
      "step": 123030
    },
    {
      "epoch": 14.824096385542168,
      "grad_norm": 0.0019874037243425846,
      "learning_rate": 5.175903614457832e-06,
      "loss": 0.0055,
      "step": 123040
    },
    {
      "epoch": 14.825301204819278,
      "grad_norm": 0.04445192590355873,
      "learning_rate": 5.1746987951807235e-06,
      "loss": 0.0068,
      "step": 123050
    },
    {
      "epoch": 14.826506024096386,
      "grad_norm": 0.6101991534233093,
      "learning_rate": 5.173493975903615e-06,
      "loss": 0.0044,
      "step": 123060
    },
    {
      "epoch": 14.827710843373493,
      "grad_norm": 0.0002133045782102272,
      "learning_rate": 5.172289156626507e-06,
      "loss": 0.0021,
      "step": 123070
    },
    {
      "epoch": 14.828915662650603,
      "grad_norm": 0.0010383930057287216,
      "learning_rate": 5.171084337349398e-06,
      "loss": 0.0141,
      "step": 123080
    },
    {
      "epoch": 14.830120481927711,
      "grad_norm": 0.0001322748721577227,
      "learning_rate": 5.169879518072289e-06,
      "loss": 0.0179,
      "step": 123090
    },
    {
      "epoch": 14.831325301204819,
      "grad_norm": 10.771982192993164,
      "learning_rate": 5.168674698795181e-06,
      "loss": 0.0569,
      "step": 123100
    },
    {
      "epoch": 14.832530120481927,
      "grad_norm": 0.00494015496224165,
      "learning_rate": 5.167469879518072e-06,
      "loss": 0.0065,
      "step": 123110
    },
    {
      "epoch": 14.833734939759037,
      "grad_norm": 0.29429516196250916,
      "learning_rate": 5.166265060240965e-06,
      "loss": 0.025,
      "step": 123120
    },
    {
      "epoch": 14.834939759036144,
      "grad_norm": 2.9242489337921143,
      "learning_rate": 5.165060240963856e-06,
      "loss": 0.0325,
      "step": 123130
    },
    {
      "epoch": 14.836144578313252,
      "grad_norm": 0.0007202384294942021,
      "learning_rate": 5.163855421686748e-06,
      "loss": 0.0111,
      "step": 123140
    },
    {
      "epoch": 14.837349397590362,
      "grad_norm": 0.15382012724876404,
      "learning_rate": 5.162650602409639e-06,
      "loss": 0.0217,
      "step": 123150
    },
    {
      "epoch": 14.83855421686747,
      "grad_norm": 0.43623384833335876,
      "learning_rate": 5.16144578313253e-06,
      "loss": 0.0044,
      "step": 123160
    },
    {
      "epoch": 14.839759036144578,
      "grad_norm": 1.282514214515686,
      "learning_rate": 5.160240963855422e-06,
      "loss": 0.0189,
      "step": 123170
    },
    {
      "epoch": 14.840963855421688,
      "grad_norm": 0.0006620505009777844,
      "learning_rate": 5.159036144578313e-06,
      "loss": 0.0488,
      "step": 123180
    },
    {
      "epoch": 14.842168674698796,
      "grad_norm": 0.0007292724912986159,
      "learning_rate": 5.157831325301206e-06,
      "loss": 0.0029,
      "step": 123190
    },
    {
      "epoch": 14.843373493975903,
      "grad_norm": 19.640060424804688,
      "learning_rate": 5.156626506024097e-06,
      "loss": 0.0183,
      "step": 123200
    },
    {
      "epoch": 14.844578313253011,
      "grad_norm": 1.6876485347747803,
      "learning_rate": 5.155421686746989e-06,
      "loss": 0.022,
      "step": 123210
    },
    {
      "epoch": 14.845783132530121,
      "grad_norm": 2.050727367401123,
      "learning_rate": 5.15421686746988e-06,
      "loss": 0.0098,
      "step": 123220
    },
    {
      "epoch": 14.846987951807229,
      "grad_norm": 20.821256637573242,
      "learning_rate": 5.153012048192771e-06,
      "loss": 0.0264,
      "step": 123230
    },
    {
      "epoch": 14.848192771084337,
      "grad_norm": 0.7380111813545227,
      "learning_rate": 5.151807228915663e-06,
      "loss": 0.026,
      "step": 123240
    },
    {
      "epoch": 14.849397590361447,
      "grad_norm": 0.00021199941693339497,
      "learning_rate": 5.1506024096385544e-06,
      "loss": 0.004,
      "step": 123250
    },
    {
      "epoch": 14.850602409638554,
      "grad_norm": 0.0830325111746788,
      "learning_rate": 5.149397590361446e-06,
      "loss": 0.0227,
      "step": 123260
    },
    {
      "epoch": 14.851807228915662,
      "grad_norm": 11.300405502319336,
      "learning_rate": 5.1481927710843385e-06,
      "loss": 0.0354,
      "step": 123270
    },
    {
      "epoch": 14.85301204819277,
      "grad_norm": 0.0004774393455591053,
      "learning_rate": 5.14698795180723e-06,
      "loss": 0.0036,
      "step": 123280
    },
    {
      "epoch": 14.85421686746988,
      "grad_norm": 0.38504335284233093,
      "learning_rate": 5.145783132530121e-06,
      "loss": 0.0048,
      "step": 123290
    },
    {
      "epoch": 14.855421686746988,
      "grad_norm": 0.0005405519041232765,
      "learning_rate": 5.144578313253012e-06,
      "loss": 0.0324,
      "step": 123300
    },
    {
      "epoch": 14.856626506024096,
      "grad_norm": 0.24480460584163666,
      "learning_rate": 5.143373493975904e-06,
      "loss": 0.0136,
      "step": 123310
    },
    {
      "epoch": 14.857831325301206,
      "grad_norm": 0.8142566680908203,
      "learning_rate": 5.1421686746987956e-06,
      "loss": 0.0072,
      "step": 123320
    },
    {
      "epoch": 14.859036144578313,
      "grad_norm": 0.24964457750320435,
      "learning_rate": 5.140963855421687e-06,
      "loss": 0.0045,
      "step": 123330
    },
    {
      "epoch": 14.860240963855421,
      "grad_norm": 0.41285228729248047,
      "learning_rate": 5.13975903614458e-06,
      "loss": 0.0121,
      "step": 123340
    },
    {
      "epoch": 14.861445783132531,
      "grad_norm": 0.0003751101903617382,
      "learning_rate": 5.13855421686747e-06,
      "loss": 0.011,
      "step": 123350
    },
    {
      "epoch": 14.862650602409639,
      "grad_norm": 0.011220893822610378,
      "learning_rate": 5.137349397590362e-06,
      "loss": 0.0106,
      "step": 123360
    },
    {
      "epoch": 14.863855421686747,
      "grad_norm": 0.00033746339613571763,
      "learning_rate": 5.1361445783132535e-06,
      "loss": 0.0129,
      "step": 123370
    },
    {
      "epoch": 14.865060240963855,
      "grad_norm": 0.0018494809046387672,
      "learning_rate": 5.134939759036145e-06,
      "loss": 0.0007,
      "step": 123380
    },
    {
      "epoch": 14.866265060240965,
      "grad_norm": 0.009854404255747795,
      "learning_rate": 5.133734939759037e-06,
      "loss": 0.0013,
      "step": 123390
    },
    {
      "epoch": 14.867469879518072,
      "grad_norm": 0.0004126886778976768,
      "learning_rate": 5.132530120481927e-06,
      "loss": 0.0149,
      "step": 123400
    },
    {
      "epoch": 14.86867469879518,
      "grad_norm": 0.0003604519588407129,
      "learning_rate": 5.131325301204819e-06,
      "loss": 0.0055,
      "step": 123410
    },
    {
      "epoch": 14.869879518072288,
      "grad_norm": 0.2498587965965271,
      "learning_rate": 5.1301204819277114e-06,
      "loss": 0.0185,
      "step": 123420
    },
    {
      "epoch": 14.871084337349398,
      "grad_norm": 0.35626664757728577,
      "learning_rate": 5.128915662650603e-06,
      "loss": 0.0145,
      "step": 123430
    },
    {
      "epoch": 14.872289156626506,
      "grad_norm": 0.10426225513219833,
      "learning_rate": 5.127710843373495e-06,
      "loss": 0.0477,
      "step": 123440
    },
    {
      "epoch": 14.873493975903614,
      "grad_norm": 0.0036007072776556015,
      "learning_rate": 5.126506024096386e-06,
      "loss": 0.0081,
      "step": 123450
    },
    {
      "epoch": 14.874698795180723,
      "grad_norm": 0.7748695611953735,
      "learning_rate": 5.125301204819278e-06,
      "loss": 0.0046,
      "step": 123460
    },
    {
      "epoch": 14.875903614457831,
      "grad_norm": 0.17810268700122833,
      "learning_rate": 5.1240963855421685e-06,
      "loss": 0.0595,
      "step": 123470
    },
    {
      "epoch": 14.87710843373494,
      "grad_norm": 0.0006470763473771513,
      "learning_rate": 5.12289156626506e-06,
      "loss": 0.0084,
      "step": 123480
    },
    {
      "epoch": 14.878313253012049,
      "grad_norm": 0.00015609290858265013,
      "learning_rate": 5.1216867469879526e-06,
      "loss": 0.0182,
      "step": 123490
    },
    {
      "epoch": 14.879518072289157,
      "grad_norm": 0.0002518514811526984,
      "learning_rate": 5.120481927710844e-06,
      "loss": 0.0333,
      "step": 123500
    },
    {
      "epoch": 14.880722891566265,
      "grad_norm": 0.0017200487200170755,
      "learning_rate": 5.119277108433736e-06,
      "loss": 0.0029,
      "step": 123510
    },
    {
      "epoch": 14.881927710843373,
      "grad_norm": 0.06427451968193054,
      "learning_rate": 5.118072289156627e-06,
      "loss": 0.0026,
      "step": 123520
    },
    {
      "epoch": 14.883132530120482,
      "grad_norm": 0.00025553381419740617,
      "learning_rate": 5.116867469879518e-06,
      "loss": 0.004,
      "step": 123530
    },
    {
      "epoch": 14.88433734939759,
      "grad_norm": 0.002173737622797489,
      "learning_rate": 5.11566265060241e-06,
      "loss": 0.008,
      "step": 123540
    },
    {
      "epoch": 14.885542168674698,
      "grad_norm": 0.015385464765131474,
      "learning_rate": 5.114457831325301e-06,
      "loss": 0.0186,
      "step": 123550
    },
    {
      "epoch": 14.886746987951808,
      "grad_norm": 1.390428900718689,
      "learning_rate": 5.113253012048193e-06,
      "loss": 0.0536,
      "step": 123560
    },
    {
      "epoch": 14.887951807228916,
      "grad_norm": 1.7159733772277832,
      "learning_rate": 5.112048192771085e-06,
      "loss": 0.0192,
      "step": 123570
    },
    {
      "epoch": 14.889156626506024,
      "grad_norm": 0.0008197097340598702,
      "learning_rate": 5.110843373493977e-06,
      "loss": 0.0079,
      "step": 123580
    },
    {
      "epoch": 14.890361445783132,
      "grad_norm": 0.3357093036174774,
      "learning_rate": 5.1096385542168684e-06,
      "loss": 0.0226,
      "step": 123590
    },
    {
      "epoch": 14.891566265060241,
      "grad_norm": 0.00232833088375628,
      "learning_rate": 5.108433734939759e-06,
      "loss": 0.049,
      "step": 123600
    },
    {
      "epoch": 14.89277108433735,
      "grad_norm": 0.001431110198609531,
      "learning_rate": 5.107228915662651e-06,
      "loss": 0.012,
      "step": 123610
    },
    {
      "epoch": 14.893975903614457,
      "grad_norm": 1.4873745441436768,
      "learning_rate": 5.106024096385542e-06,
      "loss": 0.0144,
      "step": 123620
    },
    {
      "epoch": 14.895180722891567,
      "grad_norm": 0.3218267261981964,
      "learning_rate": 5.104819277108434e-06,
      "loss": 0.0178,
      "step": 123630
    },
    {
      "epoch": 14.896385542168675,
      "grad_norm": 0.4911917448043823,
      "learning_rate": 5.103614457831326e-06,
      "loss": 0.0222,
      "step": 123640
    },
    {
      "epoch": 14.897590361445783,
      "grad_norm": 0.7362749576568604,
      "learning_rate": 5.102409638554218e-06,
      "loss": 0.0042,
      "step": 123650
    },
    {
      "epoch": 14.898795180722892,
      "grad_norm": 0.7549417018890381,
      "learning_rate": 5.101204819277109e-06,
      "loss": 0.0125,
      "step": 123660
    },
    {
      "epoch": 14.9,
      "grad_norm": 0.20006322860717773,
      "learning_rate": 5.1e-06,
      "loss": 0.0066,
      "step": 123670
    },
    {
      "epoch": 14.901204819277108,
      "grad_norm": 0.7548623085021973,
      "learning_rate": 5.098795180722892e-06,
      "loss": 0.003,
      "step": 123680
    },
    {
      "epoch": 14.902409638554216,
      "grad_norm": 0.00034219358349218965,
      "learning_rate": 5.0975903614457835e-06,
      "loss": 0.0041,
      "step": 123690
    },
    {
      "epoch": 14.903614457831326,
      "grad_norm": 0.0011389256687834859,
      "learning_rate": 5.096385542168675e-06,
      "loss": 0.0048,
      "step": 123700
    },
    {
      "epoch": 14.904819277108434,
      "grad_norm": 0.00019004259957000613,
      "learning_rate": 5.095180722891566e-06,
      "loss": 0.0061,
      "step": 123710
    },
    {
      "epoch": 14.906024096385542,
      "grad_norm": 0.0014061116380617023,
      "learning_rate": 5.093975903614459e-06,
      "loss": 0.0237,
      "step": 123720
    },
    {
      "epoch": 14.907228915662651,
      "grad_norm": 1.0055370330810547,
      "learning_rate": 5.09277108433735e-06,
      "loss": 0.0212,
      "step": 123730
    },
    {
      "epoch": 14.90843373493976,
      "grad_norm": 3.6612818241119385,
      "learning_rate": 5.091566265060241e-06,
      "loss": 0.0108,
      "step": 123740
    },
    {
      "epoch": 14.909638554216867,
      "grad_norm": 1.9743289947509766,
      "learning_rate": 5.090361445783133e-06,
      "loss": 0.0554,
      "step": 123750
    },
    {
      "epoch": 14.910843373493975,
      "grad_norm": 0.004129422828555107,
      "learning_rate": 5.089156626506025e-06,
      "loss": 0.0123,
      "step": 123760
    },
    {
      "epoch": 14.912048192771085,
      "grad_norm": 0.0006663100211881101,
      "learning_rate": 5.087951807228916e-06,
      "loss": 0.0417,
      "step": 123770
    },
    {
      "epoch": 14.913253012048193,
      "grad_norm": 0.0048489877954125404,
      "learning_rate": 5.086746987951807e-06,
      "loss": 0.0499,
      "step": 123780
    },
    {
      "epoch": 14.9144578313253,
      "grad_norm": 0.34854817390441895,
      "learning_rate": 5.085542168674699e-06,
      "loss": 0.0025,
      "step": 123790
    },
    {
      "epoch": 14.91566265060241,
      "grad_norm": 0.928074061870575,
      "learning_rate": 5.084337349397591e-06,
      "loss": 0.0195,
      "step": 123800
    },
    {
      "epoch": 14.916867469879518,
      "grad_norm": 1.1148850917816162,
      "learning_rate": 5.0831325301204825e-06,
      "loss": 0.0392,
      "step": 123810
    },
    {
      "epoch": 14.918072289156626,
      "grad_norm": 0.0019771174993366003,
      "learning_rate": 5.081927710843374e-06,
      "loss": 0.0137,
      "step": 123820
    },
    {
      "epoch": 14.919277108433734,
      "grad_norm": 0.0014644988114014268,
      "learning_rate": 5.080722891566266e-06,
      "loss": 0.0034,
      "step": 123830
    },
    {
      "epoch": 14.920481927710844,
      "grad_norm": 0.0009067108621820807,
      "learning_rate": 5.0795180722891564e-06,
      "loss": 0.0046,
      "step": 123840
    },
    {
      "epoch": 14.921686746987952,
      "grad_norm": 0.0028766931500285864,
      "learning_rate": 5.078313253012048e-06,
      "loss": 0.0008,
      "step": 123850
    },
    {
      "epoch": 14.92289156626506,
      "grad_norm": 0.008136388845741749,
      "learning_rate": 5.07710843373494e-06,
      "loss": 0.0095,
      "step": 123860
    },
    {
      "epoch": 14.92409638554217,
      "grad_norm": 0.0006284198607318103,
      "learning_rate": 5.075903614457832e-06,
      "loss": 0.0389,
      "step": 123870
    },
    {
      "epoch": 14.925301204819277,
      "grad_norm": 1.2566663026809692,
      "learning_rate": 5.074698795180724e-06,
      "loss": 0.0385,
      "step": 123880
    },
    {
      "epoch": 14.926506024096385,
      "grad_norm": 0.07040181010961533,
      "learning_rate": 5.073493975903615e-06,
      "loss": 0.0114,
      "step": 123890
    },
    {
      "epoch": 14.927710843373493,
      "grad_norm": 7.100340843200684,
      "learning_rate": 5.072289156626507e-06,
      "loss": 0.0331,
      "step": 123900
    },
    {
      "epoch": 14.928915662650603,
      "grad_norm": 0.018350213766098022,
      "learning_rate": 5.0710843373493976e-06,
      "loss": 0.0041,
      "step": 123910
    },
    {
      "epoch": 14.93012048192771,
      "grad_norm": 0.6739976406097412,
      "learning_rate": 5.069879518072289e-06,
      "loss": 0.0083,
      "step": 123920
    },
    {
      "epoch": 14.931325301204819,
      "grad_norm": 1.5865342617034912,
      "learning_rate": 5.068674698795181e-06,
      "loss": 0.0167,
      "step": 123930
    },
    {
      "epoch": 14.932530120481928,
      "grad_norm": 0.10328460484743118,
      "learning_rate": 5.067469879518073e-06,
      "loss": 0.0022,
      "step": 123940
    },
    {
      "epoch": 14.933734939759036,
      "grad_norm": 0.207335963845253,
      "learning_rate": 5.066265060240965e-06,
      "loss": 0.0226,
      "step": 123950
    },
    {
      "epoch": 14.934939759036144,
      "grad_norm": 0.33471062779426575,
      "learning_rate": 5.065060240963856e-06,
      "loss": 0.0275,
      "step": 123960
    },
    {
      "epoch": 14.936144578313254,
      "grad_norm": 0.003766754176467657,
      "learning_rate": 5.063855421686747e-06,
      "loss": 0.0277,
      "step": 123970
    },
    {
      "epoch": 14.937349397590362,
      "grad_norm": 1.1778945922851562,
      "learning_rate": 5.062650602409639e-06,
      "loss": 0.0241,
      "step": 123980
    },
    {
      "epoch": 14.93855421686747,
      "grad_norm": 0.40614020824432373,
      "learning_rate": 5.06144578313253e-06,
      "loss": 0.0035,
      "step": 123990
    },
    {
      "epoch": 14.939759036144578,
      "grad_norm": 0.6999198794364929,
      "learning_rate": 5.060240963855422e-06,
      "loss": 0.0011,
      "step": 124000
    },
    {
      "epoch": 14.940963855421687,
      "grad_norm": 0.007017407566308975,
      "learning_rate": 5.0590361445783134e-06,
      "loss": 0.0303,
      "step": 124010
    },
    {
      "epoch": 14.942168674698795,
      "grad_norm": 0.007945148274302483,
      "learning_rate": 5.057831325301206e-06,
      "loss": 0.0164,
      "step": 124020
    },
    {
      "epoch": 14.943373493975903,
      "grad_norm": 0.000712015142198652,
      "learning_rate": 5.0566265060240975e-06,
      "loss": 0.0178,
      "step": 124030
    },
    {
      "epoch": 14.944578313253013,
      "grad_norm": 0.00787375122308731,
      "learning_rate": 5.055421686746988e-06,
      "loss": 0.0107,
      "step": 124040
    },
    {
      "epoch": 14.94578313253012,
      "grad_norm": 1.56643545627594,
      "learning_rate": 5.05421686746988e-06,
      "loss": 0.0291,
      "step": 124050
    },
    {
      "epoch": 14.946987951807229,
      "grad_norm": 0.0006511052488349378,
      "learning_rate": 5.053012048192771e-06,
      "loss": 0.0036,
      "step": 124060
    },
    {
      "epoch": 14.948192771084337,
      "grad_norm": 0.02223716489970684,
      "learning_rate": 5.051807228915663e-06,
      "loss": 0.0028,
      "step": 124070
    },
    {
      "epoch": 14.949397590361446,
      "grad_norm": 1.197766661643982,
      "learning_rate": 5.0506024096385546e-06,
      "loss": 0.0176,
      "step": 124080
    },
    {
      "epoch": 14.950602409638554,
      "grad_norm": 0.0011234314879402518,
      "learning_rate": 5.049397590361447e-06,
      "loss": 0.0045,
      "step": 124090
    },
    {
      "epoch": 14.951807228915662,
      "grad_norm": 0.0027510884683579206,
      "learning_rate": 5.048192771084338e-06,
      "loss": 0.0028,
      "step": 124100
    },
    {
      "epoch": 14.953012048192772,
      "grad_norm": 0.002018759725615382,
      "learning_rate": 5.046987951807229e-06,
      "loss": 0.0107,
      "step": 124110
    },
    {
      "epoch": 14.95421686746988,
      "grad_norm": 0.031554583460092545,
      "learning_rate": 5.045783132530121e-06,
      "loss": 0.0511,
      "step": 124120
    },
    {
      "epoch": 14.955421686746988,
      "grad_norm": 0.0028738705441355705,
      "learning_rate": 5.0445783132530125e-06,
      "loss": 0.0024,
      "step": 124130
    },
    {
      "epoch": 14.956626506024097,
      "grad_norm": 0.014806229621171951,
      "learning_rate": 5.043373493975904e-06,
      "loss": 0.0459,
      "step": 124140
    },
    {
      "epoch": 14.957831325301205,
      "grad_norm": 0.04018086940050125,
      "learning_rate": 5.042168674698795e-06,
      "loss": 0.0441,
      "step": 124150
    },
    {
      "epoch": 14.959036144578313,
      "grad_norm": 0.007404145784676075,
      "learning_rate": 5.040963855421686e-06,
      "loss": 0.0177,
      "step": 124160
    },
    {
      "epoch": 14.960240963855421,
      "grad_norm": 0.004449407570064068,
      "learning_rate": 5.039759036144579e-06,
      "loss": 0.0153,
      "step": 124170
    },
    {
      "epoch": 14.96144578313253,
      "grad_norm": 0.032164547592401505,
      "learning_rate": 5.0385542168674704e-06,
      "loss": 0.016,
      "step": 124180
    },
    {
      "epoch": 14.962650602409639,
      "grad_norm": 0.004235643427819014,
      "learning_rate": 5.037349397590362e-06,
      "loss": 0.0165,
      "step": 124190
    },
    {
      "epoch": 14.963855421686747,
      "grad_norm": 0.5587602853775024,
      "learning_rate": 5.036144578313254e-06,
      "loss": 0.037,
      "step": 124200
    },
    {
      "epoch": 14.965060240963856,
      "grad_norm": 0.013672986067831516,
      "learning_rate": 5.034939759036145e-06,
      "loss": 0.0092,
      "step": 124210
    },
    {
      "epoch": 14.966265060240964,
      "grad_norm": 0.0081412885338068,
      "learning_rate": 5.033734939759036e-06,
      "loss": 0.0064,
      "step": 124220
    },
    {
      "epoch": 14.967469879518072,
      "grad_norm": 0.18463531136512756,
      "learning_rate": 5.0325301204819275e-06,
      "loss": 0.0034,
      "step": 124230
    },
    {
      "epoch": 14.96867469879518,
      "grad_norm": 0.04134541004896164,
      "learning_rate": 5.03132530120482e-06,
      "loss": 0.026,
      "step": 124240
    },
    {
      "epoch": 14.96987951807229,
      "grad_norm": 0.6495895981788635,
      "learning_rate": 5.0301204819277116e-06,
      "loss": 0.0103,
      "step": 124250
    },
    {
      "epoch": 14.971084337349398,
      "grad_norm": 1.0783705711364746,
      "learning_rate": 5.028915662650603e-06,
      "loss": 0.0237,
      "step": 124260
    },
    {
      "epoch": 14.972289156626506,
      "grad_norm": 0.017499081790447235,
      "learning_rate": 5.027710843373495e-06,
      "loss": 0.0228,
      "step": 124270
    },
    {
      "epoch": 14.973493975903615,
      "grad_norm": 0.9787575006484985,
      "learning_rate": 5.0265060240963855e-06,
      "loss": 0.0043,
      "step": 124280
    },
    {
      "epoch": 14.974698795180723,
      "grad_norm": 0.23423773050308228,
      "learning_rate": 5.025301204819277e-06,
      "loss": 0.0183,
      "step": 124290
    },
    {
      "epoch": 14.975903614457831,
      "grad_norm": 1.4236934185028076,
      "learning_rate": 5.024096385542169e-06,
      "loss": 0.0146,
      "step": 124300
    },
    {
      "epoch": 14.977108433734939,
      "grad_norm": 0.0023251723032444715,
      "learning_rate": 5.02289156626506e-06,
      "loss": 0.008,
      "step": 124310
    },
    {
      "epoch": 14.978313253012049,
      "grad_norm": 0.011964404955506325,
      "learning_rate": 5.021686746987953e-06,
      "loss": 0.037,
      "step": 124320
    },
    {
      "epoch": 14.979518072289157,
      "grad_norm": 0.016572359949350357,
      "learning_rate": 5.020481927710844e-06,
      "loss": 0.0047,
      "step": 124330
    },
    {
      "epoch": 14.980722891566264,
      "grad_norm": 0.01027321070432663,
      "learning_rate": 5.019277108433736e-06,
      "loss": 0.0109,
      "step": 124340
    },
    {
      "epoch": 14.981927710843374,
      "grad_norm": 0.002607561880722642,
      "learning_rate": 5.018072289156627e-06,
      "loss": 0.0217,
      "step": 124350
    },
    {
      "epoch": 14.983132530120482,
      "grad_norm": 0.004437914118170738,
      "learning_rate": 5.016867469879518e-06,
      "loss": 0.0212,
      "step": 124360
    },
    {
      "epoch": 14.98433734939759,
      "grad_norm": 0.0018741723615676165,
      "learning_rate": 5.01566265060241e-06,
      "loss": 0.0088,
      "step": 124370
    },
    {
      "epoch": 14.985542168674698,
      "grad_norm": 0.0030898002441972494,
      "learning_rate": 5.014457831325301e-06,
      "loss": 0.0124,
      "step": 124380
    },
    {
      "epoch": 14.986746987951808,
      "grad_norm": 0.0009585752268321812,
      "learning_rate": 5.013253012048194e-06,
      "loss": 0.0115,
      "step": 124390
    },
    {
      "epoch": 14.987951807228916,
      "grad_norm": 0.8111530542373657,
      "learning_rate": 5.012048192771085e-06,
      "loss": 0.013,
      "step": 124400
    },
    {
      "epoch": 14.989156626506023,
      "grad_norm": 10.377572059631348,
      "learning_rate": 5.010843373493976e-06,
      "loss": 0.0409,
      "step": 124410
    },
    {
      "epoch": 14.990361445783133,
      "grad_norm": 0.01968945935368538,
      "learning_rate": 5.009638554216868e-06,
      "loss": 0.0012,
      "step": 124420
    },
    {
      "epoch": 14.991566265060241,
      "grad_norm": 1.0178707838058472,
      "learning_rate": 5.008433734939759e-06,
      "loss": 0.0227,
      "step": 124430
    },
    {
      "epoch": 14.992771084337349,
      "grad_norm": 0.008409698493778706,
      "learning_rate": 5.007228915662651e-06,
      "loss": 0.0207,
      "step": 124440
    },
    {
      "epoch": 14.993975903614459,
      "grad_norm": 1.2004494667053223,
      "learning_rate": 5.0060240963855425e-06,
      "loss": 0.0252,
      "step": 124450
    },
    {
      "epoch": 14.995180722891567,
      "grad_norm": 0.015281480737030506,
      "learning_rate": 5.004819277108433e-06,
      "loss": 0.0042,
      "step": 124460
    },
    {
      "epoch": 14.996385542168674,
      "grad_norm": 0.17785754799842834,
      "learning_rate": 5.0036144578313265e-06,
      "loss": 0.0076,
      "step": 124470
    },
    {
      "epoch": 14.997590361445782,
      "grad_norm": 0.8447251915931702,
      "learning_rate": 5.002409638554217e-06,
      "loss": 0.0177,
      "step": 124480
    },
    {
      "epoch": 14.998795180722892,
      "grad_norm": 0.0025283864233642817,
      "learning_rate": 5.001204819277109e-06,
      "loss": 0.0064,
      "step": 124490
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.18955965340137482,
      "learning_rate": 5e-06,
      "loss": 0.0563,
      "step": 124500
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.9874156355455568,
      "eval_f1": 0.9662751993970985,
      "eval_loss": 0.050654105842113495,
      "eval_precision": 0.9822522982635342,
      "eval_recall": 0.9508095414658262,
      "eval_runtime": 3350.7223,
      "eval_samples_per_second": 12.741,
      "eval_steps_per_second": 0.531,
      "step": 124500
    },
    {
      "epoch": 15.001204819277108,
      "grad_norm": 0.45481494069099426,
      "learning_rate": 4.998795180722892e-06,
      "loss": 0.0146,
      "step": 124510
    },
    {
      "epoch": 15.002409638554218,
      "grad_norm": 0.1121804341673851,
      "learning_rate": 4.997590361445784e-06,
      "loss": 0.011,
      "step": 124520
    },
    {
      "epoch": 15.003614457831326,
      "grad_norm": 0.00443072896450758,
      "learning_rate": 4.996385542168675e-06,
      "loss": 0.0055,
      "step": 124530
    },
    {
      "epoch": 15.004819277108433,
      "grad_norm": 0.001158451777882874,
      "learning_rate": 4.995180722891567e-06,
      "loss": 0.0502,
      "step": 124540
    },
    {
      "epoch": 15.006024096385541,
      "grad_norm": 0.0009223131346516311,
      "learning_rate": 4.993975903614458e-06,
      "loss": 0.0055,
      "step": 124550
    },
    {
      "epoch": 15.007228915662651,
      "grad_norm": 0.0010077508632093668,
      "learning_rate": 4.99277108433735e-06,
      "loss": 0.0264,
      "step": 124560
    },
    {
      "epoch": 15.008433734939759,
      "grad_norm": 0.27920636534690857,
      "learning_rate": 4.9915662650602415e-06,
      "loss": 0.0032,
      "step": 124570
    },
    {
      "epoch": 15.009638554216867,
      "grad_norm": 3.156857967376709,
      "learning_rate": 4.990361445783133e-06,
      "loss": 0.0368,
      "step": 124580
    },
    {
      "epoch": 15.010843373493977,
      "grad_norm": 0.8002665042877197,
      "learning_rate": 4.989156626506025e-06,
      "loss": 0.0049,
      "step": 124590
    },
    {
      "epoch": 15.012048192771084,
      "grad_norm": 1.634973168373108,
      "learning_rate": 4.987951807228916e-06,
      "loss": 0.0233,
      "step": 124600
    },
    {
      "epoch": 15.013253012048192,
      "grad_norm": 0.5675866007804871,
      "learning_rate": 4.986746987951808e-06,
      "loss": 0.0136,
      "step": 124610
    },
    {
      "epoch": 15.0144578313253,
      "grad_norm": 0.0025581461377441883,
      "learning_rate": 4.9855421686746995e-06,
      "loss": 0.0103,
      "step": 124620
    },
    {
      "epoch": 15.01566265060241,
      "grad_norm": 1.0501307249069214,
      "learning_rate": 4.98433734939759e-06,
      "loss": 0.0141,
      "step": 124630
    },
    {
      "epoch": 15.016867469879518,
      "grad_norm": 0.5035594701766968,
      "learning_rate": 4.983132530120483e-06,
      "loss": 0.0316,
      "step": 124640
    },
    {
      "epoch": 15.018072289156626,
      "grad_norm": 0.0007856223382987082,
      "learning_rate": 4.981927710843374e-06,
      "loss": 0.0068,
      "step": 124650
    },
    {
      "epoch": 15.019277108433736,
      "grad_norm": 0.6869357228279114,
      "learning_rate": 4.980722891566265e-06,
      "loss": 0.0103,
      "step": 124660
    },
    {
      "epoch": 15.020481927710843,
      "grad_norm": 0.0012429916532710195,
      "learning_rate": 4.979518072289157e-06,
      "loss": 0.0037,
      "step": 124670
    },
    {
      "epoch": 15.021686746987951,
      "grad_norm": 1.0824110507965088,
      "learning_rate": 4.978313253012049e-06,
      "loss": 0.0108,
      "step": 124680
    },
    {
      "epoch": 15.022891566265061,
      "grad_norm": 0.009762470610439777,
      "learning_rate": 4.97710843373494e-06,
      "loss": 0.0101,
      "step": 124690
    },
    {
      "epoch": 15.024096385542169,
      "grad_norm": 0.20775067806243896,
      "learning_rate": 4.975903614457831e-06,
      "loss": 0.0072,
      "step": 124700
    },
    {
      "epoch": 15.025301204819277,
      "grad_norm": 0.0024055938702076674,
      "learning_rate": 4.974698795180724e-06,
      "loss": 0.0063,
      "step": 124710
    },
    {
      "epoch": 15.026506024096385,
      "grad_norm": 0.0030777137726545334,
      "learning_rate": 4.973493975903615e-06,
      "loss": 0.0117,
      "step": 124720
    },
    {
      "epoch": 15.027710843373494,
      "grad_norm": 0.00753981014713645,
      "learning_rate": 4.972289156626506e-06,
      "loss": 0.0165,
      "step": 124730
    },
    {
      "epoch": 15.028915662650602,
      "grad_norm": 0.0015306140994653106,
      "learning_rate": 4.971084337349398e-06,
      "loss": 0.0078,
      "step": 124740
    },
    {
      "epoch": 15.03012048192771,
      "grad_norm": 0.0014696542639285326,
      "learning_rate": 4.96987951807229e-06,
      "loss": 0.0204,
      "step": 124750
    },
    {
      "epoch": 15.03132530120482,
      "grad_norm": 13.021455764770508,
      "learning_rate": 4.968674698795181e-06,
      "loss": 0.0223,
      "step": 124760
    },
    {
      "epoch": 15.032530120481928,
      "grad_norm": 0.0011658217990770936,
      "learning_rate": 4.9674698795180724e-06,
      "loss": 0.0101,
      "step": 124770
    },
    {
      "epoch": 15.033734939759036,
      "grad_norm": 0.0005026055150665343,
      "learning_rate": 4.966265060240964e-06,
      "loss": 0.0174,
      "step": 124780
    },
    {
      "epoch": 15.034939759036144,
      "grad_norm": 0.22559624910354614,
      "learning_rate": 4.965060240963856e-06,
      "loss": 0.0218,
      "step": 124790
    },
    {
      "epoch": 15.036144578313253,
      "grad_norm": 1.3439382314682007,
      "learning_rate": 4.963855421686747e-06,
      "loss": 0.012,
      "step": 124800
    },
    {
      "epoch": 15.037349397590361,
      "grad_norm": 0.0020499862730503082,
      "learning_rate": 4.962650602409639e-06,
      "loss": 0.0201,
      "step": 124810
    },
    {
      "epoch": 15.03855421686747,
      "grad_norm": 1.2590595483779907,
      "learning_rate": 4.96144578313253e-06,
      "loss": 0.0155,
      "step": 124820
    },
    {
      "epoch": 15.039759036144579,
      "grad_norm": 0.4156493842601776,
      "learning_rate": 4.960240963855422e-06,
      "loss": 0.0137,
      "step": 124830
    },
    {
      "epoch": 15.040963855421687,
      "grad_norm": 0.0009126166696660221,
      "learning_rate": 4.9590361445783136e-06,
      "loss": 0.0086,
      "step": 124840
    },
    {
      "epoch": 15.042168674698795,
      "grad_norm": 0.002016118261963129,
      "learning_rate": 4.957831325301205e-06,
      "loss": 0.0061,
      "step": 124850
    },
    {
      "epoch": 15.043373493975903,
      "grad_norm": 0.05282580479979515,
      "learning_rate": 4.956626506024097e-06,
      "loss": 0.0373,
      "step": 124860
    },
    {
      "epoch": 15.044578313253012,
      "grad_norm": 1.3119969367980957,
      "learning_rate": 4.955421686746988e-06,
      "loss": 0.008,
      "step": 124870
    },
    {
      "epoch": 15.04578313253012,
      "grad_norm": 0.002551248762756586,
      "learning_rate": 4.95421686746988e-06,
      "loss": 0.0083,
      "step": 124880
    },
    {
      "epoch": 15.046987951807228,
      "grad_norm": 0.001703388523310423,
      "learning_rate": 4.9530120481927715e-06,
      "loss": 0.0228,
      "step": 124890
    },
    {
      "epoch": 15.048192771084338,
      "grad_norm": 0.0012109872186556458,
      "learning_rate": 4.951807228915663e-06,
      "loss": 0.0228,
      "step": 124900
    },
    {
      "epoch": 15.049397590361446,
      "grad_norm": 0.0016813150141388178,
      "learning_rate": 4.950602409638555e-06,
      "loss": 0.0012,
      "step": 124910
    },
    {
      "epoch": 15.050602409638554,
      "grad_norm": 0.011258631944656372,
      "learning_rate": 4.949397590361446e-06,
      "loss": 0.0009,
      "step": 124920
    },
    {
      "epoch": 15.051807228915663,
      "grad_norm": 0.00038832207792438567,
      "learning_rate": 4.948192771084338e-06,
      "loss": 0.0236,
      "step": 124930
    },
    {
      "epoch": 15.053012048192771,
      "grad_norm": 0.000630575290415436,
      "learning_rate": 4.9469879518072294e-06,
      "loss": 0.0078,
      "step": 124940
    },
    {
      "epoch": 15.05421686746988,
      "grad_norm": 0.016850512474775314,
      "learning_rate": 4.945783132530121e-06,
      "loss": 0.0085,
      "step": 124950
    },
    {
      "epoch": 15.055421686746987,
      "grad_norm": 0.00027133323601447046,
      "learning_rate": 4.944578313253013e-06,
      "loss": 0.0075,
      "step": 124960
    },
    {
      "epoch": 15.056626506024097,
      "grad_norm": 0.012108485214412212,
      "learning_rate": 4.943373493975904e-06,
      "loss": 0.0006,
      "step": 124970
    },
    {
      "epoch": 15.057831325301205,
      "grad_norm": 0.0014195590047165751,
      "learning_rate": 4.942168674698796e-06,
      "loss": 0.0038,
      "step": 124980
    },
    {
      "epoch": 15.059036144578313,
      "grad_norm": 0.00020111128105781972,
      "learning_rate": 4.940963855421687e-06,
      "loss": 0.018,
      "step": 124990
    },
    {
      "epoch": 15.060240963855422,
      "grad_norm": 0.012105362489819527,
      "learning_rate": 4.939759036144578e-06,
      "loss": 0.0031,
      "step": 125000
    },
    {
      "epoch": 15.06144578313253,
      "grad_norm": 0.0010814425768330693,
      "learning_rate": 4.9385542168674706e-06,
      "loss": 0.0046,
      "step": 125010
    },
    {
      "epoch": 15.062650602409638,
      "grad_norm": 0.0005406130803748965,
      "learning_rate": 4.937349397590362e-06,
      "loss": 0.0268,
      "step": 125020
    },
    {
      "epoch": 15.063855421686746,
      "grad_norm": 0.004303182475268841,
      "learning_rate": 4.936144578313254e-06,
      "loss": 0.0098,
      "step": 125030
    },
    {
      "epoch": 15.065060240963856,
      "grad_norm": 0.00019876184524036944,
      "learning_rate": 4.9349397590361445e-06,
      "loss": 0.0284,
      "step": 125040
    },
    {
      "epoch": 15.066265060240964,
      "grad_norm": 1.0248783826828003,
      "learning_rate": 4.933734939759037e-06,
      "loss": 0.011,
      "step": 125050
    },
    {
      "epoch": 15.067469879518072,
      "grad_norm": 0.9336832761764526,
      "learning_rate": 4.9325301204819285e-06,
      "loss": 0.0065,
      "step": 125060
    },
    {
      "epoch": 15.068674698795181,
      "grad_norm": 0.9522690773010254,
      "learning_rate": 4.931325301204819e-06,
      "loss": 0.008,
      "step": 125070
    },
    {
      "epoch": 15.06987951807229,
      "grad_norm": 0.000801312446128577,
      "learning_rate": 4.930120481927711e-06,
      "loss": 0.0204,
      "step": 125080
    },
    {
      "epoch": 15.071084337349397,
      "grad_norm": 0.22967788577079773,
      "learning_rate": 4.928915662650603e-06,
      "loss": 0.0055,
      "step": 125090
    },
    {
      "epoch": 15.072289156626505,
      "grad_norm": 0.0025417832657694817,
      "learning_rate": 4.927710843373494e-06,
      "loss": 0.0157,
      "step": 125100
    },
    {
      "epoch": 15.073493975903615,
      "grad_norm": 0.33153581619262695,
      "learning_rate": 4.926506024096386e-06,
      "loss": 0.0084,
      "step": 125110
    },
    {
      "epoch": 15.074698795180723,
      "grad_norm": 0.0005944743752479553,
      "learning_rate": 4.925301204819278e-06,
      "loss": 0.0135,
      "step": 125120
    },
    {
      "epoch": 15.07590361445783,
      "grad_norm": 0.00025650273892097175,
      "learning_rate": 4.924096385542169e-06,
      "loss": 0.0063,
      "step": 125130
    },
    {
      "epoch": 15.07710843373494,
      "grad_norm": 0.01612851582467556,
      "learning_rate": 4.92289156626506e-06,
      "loss": 0.016,
      "step": 125140
    },
    {
      "epoch": 15.078313253012048,
      "grad_norm": 0.010461409576237202,
      "learning_rate": 4.921686746987952e-06,
      "loss": 0.0341,
      "step": 125150
    },
    {
      "epoch": 15.079518072289156,
      "grad_norm": 13.143757820129395,
      "learning_rate": 4.920481927710844e-06,
      "loss": 0.0313,
      "step": 125160
    },
    {
      "epoch": 15.080722891566266,
      "grad_norm": 0.002431517466902733,
      "learning_rate": 4.919277108433735e-06,
      "loss": 0.0071,
      "step": 125170
    },
    {
      "epoch": 15.081927710843374,
      "grad_norm": 0.8116298913955688,
      "learning_rate": 4.918072289156627e-06,
      "loss": 0.0147,
      "step": 125180
    },
    {
      "epoch": 15.083132530120482,
      "grad_norm": 0.017769718542695045,
      "learning_rate": 4.916867469879518e-06,
      "loss": 0.0061,
      "step": 125190
    },
    {
      "epoch": 15.08433734939759,
      "grad_norm": 0.00015230223652906716,
      "learning_rate": 4.91566265060241e-06,
      "loss": 0.0212,
      "step": 125200
    },
    {
      "epoch": 15.0855421686747,
      "grad_norm": 0.21844473481178284,
      "learning_rate": 4.9144578313253015e-06,
      "loss": 0.0043,
      "step": 125210
    },
    {
      "epoch": 15.086746987951807,
      "grad_norm": 0.00017513195052742958,
      "learning_rate": 4.913253012048193e-06,
      "loss": 0.0048,
      "step": 125220
    },
    {
      "epoch": 15.087951807228915,
      "grad_norm": 0.00021218572510406375,
      "learning_rate": 4.912048192771085e-06,
      "loss": 0.0424,
      "step": 125230
    },
    {
      "epoch": 15.089156626506025,
      "grad_norm": 0.004222354386001825,
      "learning_rate": 4.910843373493976e-06,
      "loss": 0.0103,
      "step": 125240
    },
    {
      "epoch": 15.090361445783133,
      "grad_norm": 0.0004638459358830005,
      "learning_rate": 4.909638554216868e-06,
      "loss": 0.0098,
      "step": 125250
    },
    {
      "epoch": 15.09156626506024,
      "grad_norm": 0.29447469115257263,
      "learning_rate": 4.908433734939759e-06,
      "loss": 0.0149,
      "step": 125260
    },
    {
      "epoch": 15.092771084337349,
      "grad_norm": 1.2581863403320312,
      "learning_rate": 4.907228915662651e-06,
      "loss": 0.0064,
      "step": 125270
    },
    {
      "epoch": 15.093975903614458,
      "grad_norm": 0.8708965182304382,
      "learning_rate": 4.906024096385543e-06,
      "loss": 0.0044,
      "step": 125280
    },
    {
      "epoch": 15.095180722891566,
      "grad_norm": 0.3068898022174835,
      "learning_rate": 4.904819277108434e-06,
      "loss": 0.0307,
      "step": 125290
    },
    {
      "epoch": 15.096385542168674,
      "grad_norm": 0.0015587139641866088,
      "learning_rate": 4.903614457831326e-06,
      "loss": 0.0186,
      "step": 125300
    },
    {
      "epoch": 15.097590361445784,
      "grad_norm": 0.0006229992723092437,
      "learning_rate": 4.902409638554217e-06,
      "loss": 0.0121,
      "step": 125310
    },
    {
      "epoch": 15.098795180722892,
      "grad_norm": 0.007558545097708702,
      "learning_rate": 4.901204819277109e-06,
      "loss": 0.0176,
      "step": 125320
    },
    {
      "epoch": 15.1,
      "grad_norm": 0.0017849778523668647,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.0251,
      "step": 125330
    },
    {
      "epoch": 15.101204819277108,
      "grad_norm": 0.00026825733948498964,
      "learning_rate": 4.898795180722892e-06,
      "loss": 0.0027,
      "step": 125340
    },
    {
      "epoch": 15.102409638554217,
      "grad_norm": 0.00033671865821816027,
      "learning_rate": 4.897590361445784e-06,
      "loss": 0.008,
      "step": 125350
    },
    {
      "epoch": 15.103614457831325,
      "grad_norm": 4.6597185134887695,
      "learning_rate": 4.896385542168675e-06,
      "loss": 0.0144,
      "step": 125360
    },
    {
      "epoch": 15.104819277108433,
      "grad_norm": 0.00022646060097031295,
      "learning_rate": 4.895180722891567e-06,
      "loss": 0.0076,
      "step": 125370
    },
    {
      "epoch": 15.106024096385543,
      "grad_norm": 0.0009512343676760793,
      "learning_rate": 4.893975903614458e-06,
      "loss": 0.0047,
      "step": 125380
    },
    {
      "epoch": 15.10722891566265,
      "grad_norm": 0.00036486765020526946,
      "learning_rate": 4.89277108433735e-06,
      "loss": 0.0009,
      "step": 125390
    },
    {
      "epoch": 15.108433734939759,
      "grad_norm": 1.6276012659072876,
      "learning_rate": 4.891566265060242e-06,
      "loss": 0.0208,
      "step": 125400
    },
    {
      "epoch": 15.109638554216868,
      "grad_norm": 0.42805057764053345,
      "learning_rate": 4.890361445783132e-06,
      "loss": 0.0169,
      "step": 125410
    },
    {
      "epoch": 15.110843373493976,
      "grad_norm": 0.0002899319806601852,
      "learning_rate": 4.889156626506025e-06,
      "loss": 0.0215,
      "step": 125420
    },
    {
      "epoch": 15.112048192771084,
      "grad_norm": 0.0033427143935114145,
      "learning_rate": 4.887951807228916e-06,
      "loss": 0.0176,
      "step": 125430
    },
    {
      "epoch": 15.113253012048192,
      "grad_norm": 0.8777400255203247,
      "learning_rate": 4.886746987951808e-06,
      "loss": 0.0201,
      "step": 125440
    },
    {
      "epoch": 15.114457831325302,
      "grad_norm": 0.1649739295244217,
      "learning_rate": 4.885542168674699e-06,
      "loss": 0.0232,
      "step": 125450
    },
    {
      "epoch": 15.11566265060241,
      "grad_norm": 0.33465102314949036,
      "learning_rate": 4.884337349397591e-06,
      "loss": 0.0106,
      "step": 125460
    },
    {
      "epoch": 15.116867469879518,
      "grad_norm": 0.0014058095403015614,
      "learning_rate": 4.883132530120483e-06,
      "loss": 0.0017,
      "step": 125470
    },
    {
      "epoch": 15.118072289156627,
      "grad_norm": 4.776033165398985e-05,
      "learning_rate": 4.8819277108433735e-06,
      "loss": 0.0147,
      "step": 125480
    },
    {
      "epoch": 15.119277108433735,
      "grad_norm": 0.0014269466046243906,
      "learning_rate": 4.880722891566265e-06,
      "loss": 0.008,
      "step": 125490
    },
    {
      "epoch": 15.120481927710843,
      "grad_norm": 0.3628673851490021,
      "learning_rate": 4.8795180722891575e-06,
      "loss": 0.0166,
      "step": 125500
    },
    {
      "epoch": 15.121686746987951,
      "grad_norm": 0.7261566519737244,
      "learning_rate": 4.878313253012048e-06,
      "loss": 0.039,
      "step": 125510
    },
    {
      "epoch": 15.12289156626506,
      "grad_norm": 0.6011053919792175,
      "learning_rate": 4.87710843373494e-06,
      "loss": 0.0267,
      "step": 125520
    },
    {
      "epoch": 15.124096385542169,
      "grad_norm": 5.199756622314453,
      "learning_rate": 4.8759036144578314e-06,
      "loss": 0.0221,
      "step": 125530
    },
    {
      "epoch": 15.125301204819277,
      "grad_norm": 1.149349331855774,
      "learning_rate": 4.874698795180723e-06,
      "loss": 0.0553,
      "step": 125540
    },
    {
      "epoch": 15.126506024096386,
      "grad_norm": 0.8809177875518799,
      "learning_rate": 4.873493975903615e-06,
      "loss": 0.0197,
      "step": 125550
    },
    {
      "epoch": 15.127710843373494,
      "grad_norm": 0.0021636912133544683,
      "learning_rate": 4.872289156626506e-06,
      "loss": 0.0011,
      "step": 125560
    },
    {
      "epoch": 15.128915662650602,
      "grad_norm": 0.0009503097389824688,
      "learning_rate": 4.871084337349399e-06,
      "loss": 0.0123,
      "step": 125570
    },
    {
      "epoch": 15.13012048192771,
      "grad_norm": 0.00024755531921982765,
      "learning_rate": 4.869879518072289e-06,
      "loss": 0.005,
      "step": 125580
    },
    {
      "epoch": 15.13132530120482,
      "grad_norm": 0.02188076637685299,
      "learning_rate": 4.868674698795181e-06,
      "loss": 0.0268,
      "step": 125590
    },
    {
      "epoch": 15.132530120481928,
      "grad_norm": 0.0034534865990281105,
      "learning_rate": 4.8674698795180725e-06,
      "loss": 0.0404,
      "step": 125600
    },
    {
      "epoch": 15.133734939759035,
      "grad_norm": 0.0037531668785959482,
      "learning_rate": 4.866265060240964e-06,
      "loss": 0.0015,
      "step": 125610
    },
    {
      "epoch": 15.134939759036145,
      "grad_norm": 0.002402103738859296,
      "learning_rate": 4.865060240963856e-06,
      "loss": 0.0064,
      "step": 125620
    },
    {
      "epoch": 15.136144578313253,
      "grad_norm": 0.004006410017609596,
      "learning_rate": 4.863855421686747e-06,
      "loss": 0.0118,
      "step": 125630
    },
    {
      "epoch": 15.137349397590361,
      "grad_norm": 0.0004494986205827445,
      "learning_rate": 4.862650602409639e-06,
      "loss": 0.0095,
      "step": 125640
    },
    {
      "epoch": 15.13855421686747,
      "grad_norm": 1.8040207624435425,
      "learning_rate": 4.8614457831325305e-06,
      "loss": 0.0105,
      "step": 125650
    },
    {
      "epoch": 15.139759036144579,
      "grad_norm": 0.03910643607378006,
      "learning_rate": 4.860240963855422e-06,
      "loss": 0.0039,
      "step": 125660
    },
    {
      "epoch": 15.140963855421687,
      "grad_norm": 13.75989055633545,
      "learning_rate": 4.859036144578314e-06,
      "loss": 0.038,
      "step": 125670
    },
    {
      "epoch": 15.142168674698794,
      "grad_norm": 0.02783474698662758,
      "learning_rate": 4.857831325301205e-06,
      "loss": 0.0093,
      "step": 125680
    },
    {
      "epoch": 15.143373493975904,
      "grad_norm": 0.00493120402097702,
      "learning_rate": 4.856626506024097e-06,
      "loss": 0.0012,
      "step": 125690
    },
    {
      "epoch": 15.144578313253012,
      "grad_norm": 0.24258427321910858,
      "learning_rate": 4.8554216867469884e-06,
      "loss": 0.0053,
      "step": 125700
    },
    {
      "epoch": 15.14578313253012,
      "grad_norm": 0.0029425318352878094,
      "learning_rate": 4.85421686746988e-06,
      "loss": 0.0207,
      "step": 125710
    },
    {
      "epoch": 15.14698795180723,
      "grad_norm": 0.5070647597312927,
      "learning_rate": 4.853012048192772e-06,
      "loss": 0.0154,
      "step": 125720
    },
    {
      "epoch": 15.148192771084338,
      "grad_norm": 0.179868683218956,
      "learning_rate": 4.851807228915663e-06,
      "loss": 0.0121,
      "step": 125730
    },
    {
      "epoch": 15.149397590361446,
      "grad_norm": 0.30146145820617676,
      "learning_rate": 4.850602409638555e-06,
      "loss": 0.0032,
      "step": 125740
    },
    {
      "epoch": 15.150602409638553,
      "grad_norm": 0.19434550404548645,
      "learning_rate": 4.849397590361446e-06,
      "loss": 0.0382,
      "step": 125750
    },
    {
      "epoch": 15.151807228915663,
      "grad_norm": 1.0412105321884155,
      "learning_rate": 4.848192771084338e-06,
      "loss": 0.007,
      "step": 125760
    },
    {
      "epoch": 15.153012048192771,
      "grad_norm": 0.004047568421810865,
      "learning_rate": 4.8469879518072295e-06,
      "loss": 0.0062,
      "step": 125770
    },
    {
      "epoch": 15.154216867469879,
      "grad_norm": 3.1663167476654053,
      "learning_rate": 4.845783132530121e-06,
      "loss": 0.0209,
      "step": 125780
    },
    {
      "epoch": 15.155421686746989,
      "grad_norm": 2.151350975036621,
      "learning_rate": 4.844578313253012e-06,
      "loss": 0.0201,
      "step": 125790
    },
    {
      "epoch": 15.156626506024097,
      "grad_norm": 0.8239374756813049,
      "learning_rate": 4.843373493975904e-06,
      "loss": 0.0138,
      "step": 125800
    },
    {
      "epoch": 15.157831325301204,
      "grad_norm": 0.0015733804320916533,
      "learning_rate": 4.842168674698796e-06,
      "loss": 0.0109,
      "step": 125810
    },
    {
      "epoch": 15.159036144578312,
      "grad_norm": 0.001583955716341734,
      "learning_rate": 4.840963855421687e-06,
      "loss": 0.009,
      "step": 125820
    },
    {
      "epoch": 15.160240963855422,
      "grad_norm": 0.8381307721138,
      "learning_rate": 4.839759036144579e-06,
      "loss": 0.012,
      "step": 125830
    },
    {
      "epoch": 15.16144578313253,
      "grad_norm": 0.0017588078044354916,
      "learning_rate": 4.838554216867471e-06,
      "loss": 0.0291,
      "step": 125840
    },
    {
      "epoch": 15.162650602409638,
      "grad_norm": 0.0028358069248497486,
      "learning_rate": 4.837349397590361e-06,
      "loss": 0.0115,
      "step": 125850
    },
    {
      "epoch": 15.163855421686748,
      "grad_norm": 0.0019268000032752752,
      "learning_rate": 4.836144578313253e-06,
      "loss": 0.009,
      "step": 125860
    },
    {
      "epoch": 15.165060240963856,
      "grad_norm": 0.1858503669500351,
      "learning_rate": 4.8349397590361454e-06,
      "loss": 0.0017,
      "step": 125870
    },
    {
      "epoch": 15.166265060240963,
      "grad_norm": 0.010101238265633583,
      "learning_rate": 4.833734939759037e-06,
      "loss": 0.0162,
      "step": 125880
    },
    {
      "epoch": 15.167469879518073,
      "grad_norm": 0.0018728914437815547,
      "learning_rate": 4.832530120481928e-06,
      "loss": 0.0003,
      "step": 125890
    },
    {
      "epoch": 15.168674698795181,
      "grad_norm": 11.126036643981934,
      "learning_rate": 4.831325301204819e-06,
      "loss": 0.0557,
      "step": 125900
    },
    {
      "epoch": 15.169879518072289,
      "grad_norm": 0.07463992387056351,
      "learning_rate": 4.830120481927712e-06,
      "loss": 0.0075,
      "step": 125910
    },
    {
      "epoch": 15.171084337349397,
      "grad_norm": 0.19150406122207642,
      "learning_rate": 4.8289156626506025e-06,
      "loss": 0.0114,
      "step": 125920
    },
    {
      "epoch": 15.172289156626507,
      "grad_norm": 0.9038068652153015,
      "learning_rate": 4.827710843373494e-06,
      "loss": 0.0076,
      "step": 125930
    },
    {
      "epoch": 15.173493975903614,
      "grad_norm": 0.015354323200881481,
      "learning_rate": 4.826506024096386e-06,
      "loss": 0.019,
      "step": 125940
    },
    {
      "epoch": 15.174698795180722,
      "grad_norm": 0.16229143738746643,
      "learning_rate": 4.825301204819277e-06,
      "loss": 0.0158,
      "step": 125950
    },
    {
      "epoch": 15.175903614457832,
      "grad_norm": 0.0004505026445258409,
      "learning_rate": 4.824096385542169e-06,
      "loss": 0.0232,
      "step": 125960
    },
    {
      "epoch": 15.17710843373494,
      "grad_norm": 0.2851466238498688,
      "learning_rate": 4.8228915662650605e-06,
      "loss": 0.0264,
      "step": 125970
    },
    {
      "epoch": 15.178313253012048,
      "grad_norm": 0.0022137267515063286,
      "learning_rate": 4.821686746987953e-06,
      "loss": 0.0004,
      "step": 125980
    },
    {
      "epoch": 15.179518072289156,
      "grad_norm": 1.6079063415527344,
      "learning_rate": 4.820481927710844e-06,
      "loss": 0.0143,
      "step": 125990
    },
    {
      "epoch": 15.180722891566266,
      "grad_norm": 0.015613503754138947,
      "learning_rate": 4.819277108433735e-06,
      "loss": 0.0,
      "step": 126000
    },
    {
      "epoch": 15.181927710843373,
      "grad_norm": 0.002179717645049095,
      "learning_rate": 4.818072289156627e-06,
      "loss": 0.0157,
      "step": 126010
    },
    {
      "epoch": 15.183132530120481,
      "grad_norm": 0.000530509976670146,
      "learning_rate": 4.816867469879518e-06,
      "loss": 0.006,
      "step": 126020
    },
    {
      "epoch": 15.184337349397591,
      "grad_norm": 0.0002950858906842768,
      "learning_rate": 4.81566265060241e-06,
      "loss": 0.0089,
      "step": 126030
    },
    {
      "epoch": 15.185542168674699,
      "grad_norm": 0.00024838384706526995,
      "learning_rate": 4.8144578313253016e-06,
      "loss": 0.0009,
      "step": 126040
    },
    {
      "epoch": 15.186746987951807,
      "grad_norm": 0.0012710504233837128,
      "learning_rate": 4.813253012048193e-06,
      "loss": 0.0459,
      "step": 126050
    },
    {
      "epoch": 15.187951807228915,
      "grad_norm": 0.0006521653849631548,
      "learning_rate": 4.812048192771085e-06,
      "loss": 0.0573,
      "step": 126060
    },
    {
      "epoch": 15.189156626506024,
      "grad_norm": 0.012381548061966896,
      "learning_rate": 4.810843373493976e-06,
      "loss": 0.0086,
      "step": 126070
    },
    {
      "epoch": 15.190361445783132,
      "grad_norm": 0.08523743599653244,
      "learning_rate": 4.809638554216868e-06,
      "loss": 0.0198,
      "step": 126080
    },
    {
      "epoch": 15.19156626506024,
      "grad_norm": 0.0019289001356810331,
      "learning_rate": 4.8084337349397595e-06,
      "loss": 0.0078,
      "step": 126090
    },
    {
      "epoch": 15.19277108433735,
      "grad_norm": 0.0026026060804724693,
      "learning_rate": 4.807228915662651e-06,
      "loss": 0.0232,
      "step": 126100
    },
    {
      "epoch": 15.193975903614458,
      "grad_norm": 0.8701243996620178,
      "learning_rate": 4.806024096385543e-06,
      "loss": 0.0203,
      "step": 126110
    },
    {
      "epoch": 15.195180722891566,
      "grad_norm": 0.8630861639976501,
      "learning_rate": 4.804819277108434e-06,
      "loss": 0.0115,
      "step": 126120
    },
    {
      "epoch": 15.196385542168676,
      "grad_norm": 0.002460071351379156,
      "learning_rate": 4.803614457831326e-06,
      "loss": 0.016,
      "step": 126130
    },
    {
      "epoch": 15.197590361445783,
      "grad_norm": 0.9679631590843201,
      "learning_rate": 4.8024096385542175e-06,
      "loss": 0.0152,
      "step": 126140
    },
    {
      "epoch": 15.198795180722891,
      "grad_norm": 0.0006205937825143337,
      "learning_rate": 4.801204819277109e-06,
      "loss": 0.0145,
      "step": 126150
    },
    {
      "epoch": 15.2,
      "grad_norm": 0.0078395651653409,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0049,
      "step": 126160
    },
    {
      "epoch": 15.201204819277109,
      "grad_norm": 41.689430236816406,
      "learning_rate": 4.798795180722892e-06,
      "loss": 0.01,
      "step": 126170
    },
    {
      "epoch": 15.202409638554217,
      "grad_norm": 0.009742374531924725,
      "learning_rate": 4.797590361445784e-06,
      "loss": 0.0158,
      "step": 126180
    },
    {
      "epoch": 15.203614457831325,
      "grad_norm": 0.0026228919159621,
      "learning_rate": 4.796385542168675e-06,
      "loss": 0.0117,
      "step": 126190
    },
    {
      "epoch": 15.204819277108435,
      "grad_norm": 0.0002353891177335754,
      "learning_rate": 4.795180722891566e-06,
      "loss": 0.0056,
      "step": 126200
    },
    {
      "epoch": 15.206024096385542,
      "grad_norm": 0.004545727279037237,
      "learning_rate": 4.7939759036144586e-06,
      "loss": 0.009,
      "step": 126210
    },
    {
      "epoch": 15.20722891566265,
      "grad_norm": 0.00020708008378278464,
      "learning_rate": 4.79277108433735e-06,
      "loss": 0.0061,
      "step": 126220
    },
    {
      "epoch": 15.208433734939758,
      "grad_norm": 0.00013101812510285527,
      "learning_rate": 4.791566265060241e-06,
      "loss": 0.0176,
      "step": 126230
    },
    {
      "epoch": 15.209638554216868,
      "grad_norm": 1.5100247859954834,
      "learning_rate": 4.7903614457831325e-06,
      "loss": 0.0189,
      "step": 126240
    },
    {
      "epoch": 15.210843373493976,
      "grad_norm": 0.7187350988388062,
      "learning_rate": 4.789156626506025e-06,
      "loss": 0.0078,
      "step": 126250
    },
    {
      "epoch": 15.212048192771084,
      "grad_norm": 0.0047027720138430595,
      "learning_rate": 4.787951807228916e-06,
      "loss": 0.0043,
      "step": 126260
    },
    {
      "epoch": 15.213253012048193,
      "grad_norm": 1.670810580253601,
      "learning_rate": 4.786746987951807e-06,
      "loss": 0.0211,
      "step": 126270
    },
    {
      "epoch": 15.214457831325301,
      "grad_norm": 0.31570491194725037,
      "learning_rate": 4.7855421686747e-06,
      "loss": 0.0025,
      "step": 126280
    },
    {
      "epoch": 15.21566265060241,
      "grad_norm": 0.0002937196986749768,
      "learning_rate": 4.784337349397591e-06,
      "loss": 0.0029,
      "step": 126290
    },
    {
      "epoch": 15.216867469879517,
      "grad_norm": 0.8385889530181885,
      "learning_rate": 4.783132530120482e-06,
      "loss": 0.0135,
      "step": 126300
    },
    {
      "epoch": 15.218072289156627,
      "grad_norm": 0.9386988282203674,
      "learning_rate": 4.781927710843374e-06,
      "loss": 0.0191,
      "step": 126310
    },
    {
      "epoch": 15.219277108433735,
      "grad_norm": 0.009320151060819626,
      "learning_rate": 4.780722891566266e-06,
      "loss": 0.0295,
      "step": 126320
    },
    {
      "epoch": 15.220481927710843,
      "grad_norm": 0.00015348651504609734,
      "learning_rate": 4.779518072289157e-06,
      "loss": 0.0267,
      "step": 126330
    },
    {
      "epoch": 15.221686746987952,
      "grad_norm": 0.00021251736325211823,
      "learning_rate": 4.778313253012048e-06,
      "loss": 0.0096,
      "step": 126340
    },
    {
      "epoch": 15.22289156626506,
      "grad_norm": 0.00239250878803432,
      "learning_rate": 4.77710843373494e-06,
      "loss": 0.0078,
      "step": 126350
    },
    {
      "epoch": 15.224096385542168,
      "grad_norm": 0.2006780505180359,
      "learning_rate": 4.7759036144578315e-06,
      "loss": 0.0037,
      "step": 126360
    },
    {
      "epoch": 15.225301204819278,
      "grad_norm": 7.276944637298584,
      "learning_rate": 4.774698795180723e-06,
      "loss": 0.0316,
      "step": 126370
    },
    {
      "epoch": 15.226506024096386,
      "grad_norm": 0.1589018553495407,
      "learning_rate": 4.773493975903615e-06,
      "loss": 0.0109,
      "step": 126380
    },
    {
      "epoch": 15.227710843373494,
      "grad_norm": 0.0031315244268625975,
      "learning_rate": 4.772289156626506e-06,
      "loss": 0.0075,
      "step": 126390
    },
    {
      "epoch": 15.228915662650602,
      "grad_norm": 1.5895838737487793,
      "learning_rate": 4.771084337349398e-06,
      "loss": 0.016,
      "step": 126400
    },
    {
      "epoch": 15.230120481927711,
      "grad_norm": 0.0032203260343521833,
      "learning_rate": 4.7698795180722895e-06,
      "loss": 0.0055,
      "step": 126410
    },
    {
      "epoch": 15.23132530120482,
      "grad_norm": 0.00019684023573063314,
      "learning_rate": 4.768674698795181e-06,
      "loss": 0.0079,
      "step": 126420
    },
    {
      "epoch": 15.232530120481927,
      "grad_norm": 0.006998081691563129,
      "learning_rate": 4.767469879518073e-06,
      "loss": 0.0302,
      "step": 126430
    },
    {
      "epoch": 15.233734939759037,
      "grad_norm": 0.00018834322690963745,
      "learning_rate": 4.766265060240964e-06,
      "loss": 0.0331,
      "step": 126440
    },
    {
      "epoch": 15.234939759036145,
      "grad_norm": 0.7910141944885254,
      "learning_rate": 4.765060240963856e-06,
      "loss": 0.0214,
      "step": 126450
    },
    {
      "epoch": 15.236144578313253,
      "grad_norm": 0.003228067420423031,
      "learning_rate": 4.763855421686747e-06,
      "loss": 0.0001,
      "step": 126460
    },
    {
      "epoch": 15.23734939759036,
      "grad_norm": 0.004165698308497667,
      "learning_rate": 4.762650602409639e-06,
      "loss": 0.0158,
      "step": 126470
    },
    {
      "epoch": 15.23855421686747,
      "grad_norm": 0.12637338042259216,
      "learning_rate": 4.761445783132531e-06,
      "loss": 0.0066,
      "step": 126480
    },
    {
      "epoch": 15.239759036144578,
      "grad_norm": 0.00024257253971882164,
      "learning_rate": 4.760240963855422e-06,
      "loss": 0.01,
      "step": 126490
    },
    {
      "epoch": 15.240963855421686,
      "grad_norm": 0.2255336046218872,
      "learning_rate": 4.759036144578314e-06,
      "loss": 0.0055,
      "step": 126500
    },
    {
      "epoch": 15.242168674698796,
      "grad_norm": 2.207777261734009,
      "learning_rate": 4.757831325301205e-06,
      "loss": 0.0262,
      "step": 126510
    },
    {
      "epoch": 15.243373493975904,
      "grad_norm": 1.7309733629226685,
      "learning_rate": 4.756626506024097e-06,
      "loss": 0.0095,
      "step": 126520
    },
    {
      "epoch": 15.244578313253012,
      "grad_norm": 0.0169789120554924,
      "learning_rate": 4.7554216867469885e-06,
      "loss": 0.0036,
      "step": 126530
    },
    {
      "epoch": 15.24578313253012,
      "grad_norm": 0.8942424654960632,
      "learning_rate": 4.754216867469879e-06,
      "loss": 0.0311,
      "step": 126540
    },
    {
      "epoch": 15.24698795180723,
      "grad_norm": 0.0006175636663101614,
      "learning_rate": 4.753012048192772e-06,
      "loss": 0.0121,
      "step": 126550
    },
    {
      "epoch": 15.248192771084337,
      "grad_norm": 0.026314478367567062,
      "learning_rate": 4.751807228915663e-06,
      "loss": 0.009,
      "step": 126560
    },
    {
      "epoch": 15.249397590361445,
      "grad_norm": 0.00010161769023397937,
      "learning_rate": 4.750602409638554e-06,
      "loss": 0.0069,
      "step": 126570
    },
    {
      "epoch": 15.250602409638555,
      "grad_norm": 0.2258305549621582,
      "learning_rate": 4.7493975903614465e-06,
      "loss": 0.0002,
      "step": 126580
    },
    {
      "epoch": 15.251807228915663,
      "grad_norm": 0.47600165009498596,
      "learning_rate": 4.748192771084338e-06,
      "loss": 0.0009,
      "step": 126590
    },
    {
      "epoch": 15.25301204819277,
      "grad_norm": 0.0003146115050185472,
      "learning_rate": 4.74698795180723e-06,
      "loss": 0.0068,
      "step": 126600
    },
    {
      "epoch": 15.25421686746988,
      "grad_norm": 0.971592366695404,
      "learning_rate": 4.74578313253012e-06,
      "loss": 0.0088,
      "step": 126610
    },
    {
      "epoch": 15.255421686746988,
      "grad_norm": 0.0007831539260223508,
      "learning_rate": 4.744578313253013e-06,
      "loss": 0.0112,
      "step": 126620
    },
    {
      "epoch": 15.256626506024096,
      "grad_norm": 0.00018701083899941295,
      "learning_rate": 4.743373493975904e-06,
      "loss": 0.0074,
      "step": 126630
    },
    {
      "epoch": 15.257831325301204,
      "grad_norm": 0.004250794183462858,
      "learning_rate": 4.742168674698795e-06,
      "loss": 0.0144,
      "step": 126640
    },
    {
      "epoch": 15.259036144578314,
      "grad_norm": 0.00018779268430080265,
      "learning_rate": 4.740963855421687e-06,
      "loss": 0.02,
      "step": 126650
    },
    {
      "epoch": 15.260240963855422,
      "grad_norm": 0.0030212693382054567,
      "learning_rate": 4.739759036144579e-06,
      "loss": 0.0107,
      "step": 126660
    },
    {
      "epoch": 15.26144578313253,
      "grad_norm": 0.006516662891954184,
      "learning_rate": 4.73855421686747e-06,
      "loss": 0.0225,
      "step": 126670
    },
    {
      "epoch": 15.26265060240964,
      "grad_norm": 0.0005947306053712964,
      "learning_rate": 4.7373493975903615e-06,
      "loss": 0.0097,
      "step": 126680
    },
    {
      "epoch": 15.263855421686747,
      "grad_norm": 0.0003697114298120141,
      "learning_rate": 4.736144578313253e-06,
      "loss": 0.0049,
      "step": 126690
    },
    {
      "epoch": 15.265060240963855,
      "grad_norm": 0.0003227810957469046,
      "learning_rate": 4.734939759036145e-06,
      "loss": 0.013,
      "step": 126700
    },
    {
      "epoch": 15.266265060240963,
      "grad_norm": 1.7269445657730103,
      "learning_rate": 4.733734939759036e-06,
      "loss": 0.0173,
      "step": 126710
    },
    {
      "epoch": 15.267469879518073,
      "grad_norm": 0.0004417350282892585,
      "learning_rate": 4.732530120481928e-06,
      "loss": 0.0455,
      "step": 126720
    },
    {
      "epoch": 15.26867469879518,
      "grad_norm": 0.012728315778076649,
      "learning_rate": 4.73132530120482e-06,
      "loss": 0.0055,
      "step": 126730
    },
    {
      "epoch": 15.269879518072289,
      "grad_norm": 0.10490802675485611,
      "learning_rate": 4.730120481927711e-06,
      "loss": 0.0372,
      "step": 126740
    },
    {
      "epoch": 15.271084337349398,
      "grad_norm": 0.3244488537311554,
      "learning_rate": 4.728915662650603e-06,
      "loss": 0.0602,
      "step": 126750
    },
    {
      "epoch": 15.272289156626506,
      "grad_norm": 0.0017174636013805866,
      "learning_rate": 4.727710843373494e-06,
      "loss": 0.0043,
      "step": 126760
    },
    {
      "epoch": 15.273493975903614,
      "grad_norm": 0.0009610764100216329,
      "learning_rate": 4.726506024096386e-06,
      "loss": 0.0008,
      "step": 126770
    },
    {
      "epoch": 15.274698795180722,
      "grad_norm": 0.00020389935525599867,
      "learning_rate": 4.725301204819277e-06,
      "loss": 0.0162,
      "step": 126780
    },
    {
      "epoch": 15.275903614457832,
      "grad_norm": 0.9692545533180237,
      "learning_rate": 4.724096385542169e-06,
      "loss": 0.0379,
      "step": 126790
    },
    {
      "epoch": 15.27710843373494,
      "grad_norm": 0.1444007009267807,
      "learning_rate": 4.7228915662650606e-06,
      "loss": 0.0212,
      "step": 126800
    },
    {
      "epoch": 15.278313253012048,
      "grad_norm": 1.5608477592468262,
      "learning_rate": 4.721686746987952e-06,
      "loss": 0.0069,
      "step": 126810
    },
    {
      "epoch": 15.279518072289157,
      "grad_norm": 0.19879689812660217,
      "learning_rate": 4.720481927710844e-06,
      "loss": 0.0197,
      "step": 126820
    },
    {
      "epoch": 15.280722891566265,
      "grad_norm": 0.5859922766685486,
      "learning_rate": 4.719277108433735e-06,
      "loss": 0.0092,
      "step": 126830
    },
    {
      "epoch": 15.281927710843373,
      "grad_norm": 0.00021928205387666821,
      "learning_rate": 4.718072289156627e-06,
      "loss": 0.0008,
      "step": 126840
    },
    {
      "epoch": 15.283132530120483,
      "grad_norm": 0.2505260407924652,
      "learning_rate": 4.7168674698795185e-06,
      "loss": 0.002,
      "step": 126850
    },
    {
      "epoch": 15.28433734939759,
      "grad_norm": 0.000132691056933254,
      "learning_rate": 4.71566265060241e-06,
      "loss": 0.0059,
      "step": 126860
    },
    {
      "epoch": 15.285542168674699,
      "grad_norm": 0.0003432036319281906,
      "learning_rate": 4.714457831325302e-06,
      "loss": 0.0244,
      "step": 126870
    },
    {
      "epoch": 15.286746987951807,
      "grad_norm": 0.8336518406867981,
      "learning_rate": 4.713253012048193e-06,
      "loss": 0.0066,
      "step": 126880
    },
    {
      "epoch": 15.287951807228916,
      "grad_norm": 0.0448964387178421,
      "learning_rate": 4.712048192771085e-06,
      "loss": 0.004,
      "step": 126890
    },
    {
      "epoch": 15.289156626506024,
      "grad_norm": 0.24016894400119781,
      "learning_rate": 4.7108433734939764e-06,
      "loss": 0.0121,
      "step": 126900
    },
    {
      "epoch": 15.290361445783132,
      "grad_norm": 0.11423466354608536,
      "learning_rate": 4.709638554216868e-06,
      "loss": 0.0026,
      "step": 126910
    },
    {
      "epoch": 15.291566265060242,
      "grad_norm": 1.6317152976989746,
      "learning_rate": 4.70843373493976e-06,
      "loss": 0.0474,
      "step": 126920
    },
    {
      "epoch": 15.29277108433735,
      "grad_norm": 0.00037783972220495343,
      "learning_rate": 4.707228915662651e-06,
      "loss": 0.0039,
      "step": 126930
    },
    {
      "epoch": 15.293975903614458,
      "grad_norm": 0.0007332468521781266,
      "learning_rate": 4.706024096385543e-06,
      "loss": 0.0138,
      "step": 126940
    },
    {
      "epoch": 15.295180722891565,
      "grad_norm": 0.0002715015725698322,
      "learning_rate": 4.7048192771084335e-06,
      "loss": 0.0004,
      "step": 126950
    },
    {
      "epoch": 15.296385542168675,
      "grad_norm": 1.9781112670898438,
      "learning_rate": 4.703614457831326e-06,
      "loss": 0.0128,
      "step": 126960
    },
    {
      "epoch": 15.297590361445783,
      "grad_norm": 0.0010674039367586374,
      "learning_rate": 4.7024096385542176e-06,
      "loss": 0.0117,
      "step": 126970
    },
    {
      "epoch": 15.298795180722891,
      "grad_norm": 0.0010721324943006039,
      "learning_rate": 4.701204819277108e-06,
      "loss": 0.0253,
      "step": 126980
    },
    {
      "epoch": 15.3,
      "grad_norm": 0.00031471156398765743,
      "learning_rate": 4.7e-06,
      "loss": 0.0199,
      "step": 126990
    },
    {
      "epoch": 15.301204819277109,
      "grad_norm": 0.013654090464115143,
      "learning_rate": 4.698795180722892e-06,
      "loss": 0.0217,
      "step": 127000
    },
    {
      "epoch": 15.302409638554217,
      "grad_norm": 0.00010543182725086808,
      "learning_rate": 4.697590361445784e-06,
      "loss": 0.0001,
      "step": 127010
    },
    {
      "epoch": 15.303614457831324,
      "grad_norm": 0.01928088068962097,
      "learning_rate": 4.696385542168675e-06,
      "loss": 0.006,
      "step": 127020
    },
    {
      "epoch": 15.304819277108434,
      "grad_norm": 1.063531517982483,
      "learning_rate": 4.695180722891567e-06,
      "loss": 0.0292,
      "step": 127030
    },
    {
      "epoch": 15.306024096385542,
      "grad_norm": 1.2532777786254883,
      "learning_rate": 4.693975903614459e-06,
      "loss": 0.0146,
      "step": 127040
    },
    {
      "epoch": 15.30722891566265,
      "grad_norm": 0.00015180457558017224,
      "learning_rate": 4.692771084337349e-06,
      "loss": 0.0132,
      "step": 127050
    },
    {
      "epoch": 15.30843373493976,
      "grad_norm": 8.276433944702148,
      "learning_rate": 4.691566265060241e-06,
      "loss": 0.0439,
      "step": 127060
    },
    {
      "epoch": 15.309638554216868,
      "grad_norm": 0.0004283747111912817,
      "learning_rate": 4.6903614457831334e-06,
      "loss": 0.0307,
      "step": 127070
    },
    {
      "epoch": 15.310843373493976,
      "grad_norm": 0.0005189639050513506,
      "learning_rate": 4.689156626506024e-06,
      "loss": 0.0143,
      "step": 127080
    },
    {
      "epoch": 15.312048192771085,
      "grad_norm": 2.098254680633545,
      "learning_rate": 4.687951807228916e-06,
      "loss": 0.0116,
      "step": 127090
    },
    {
      "epoch": 15.313253012048193,
      "grad_norm": 0.0019473101710900664,
      "learning_rate": 4.686746987951807e-06,
      "loss": 0.0085,
      "step": 127100
    },
    {
      "epoch": 15.314457831325301,
      "grad_norm": 1.238480567932129,
      "learning_rate": 4.685542168674699e-06,
      "loss": 0.0081,
      "step": 127110
    },
    {
      "epoch": 15.315662650602409,
      "grad_norm": 0.0730799213051796,
      "learning_rate": 4.6843373493975905e-06,
      "loss": 0.0052,
      "step": 127120
    },
    {
      "epoch": 15.316867469879519,
      "grad_norm": 0.7972294688224792,
      "learning_rate": 4.683132530120482e-06,
      "loss": 0.0068,
      "step": 127130
    },
    {
      "epoch": 15.318072289156627,
      "grad_norm": 1.208097219467163,
      "learning_rate": 4.681927710843374e-06,
      "loss": 0.0157,
      "step": 127140
    },
    {
      "epoch": 15.319277108433734,
      "grad_norm": 0.01964661478996277,
      "learning_rate": 4.680722891566265e-06,
      "loss": 0.0432,
      "step": 127150
    },
    {
      "epoch": 15.320481927710844,
      "grad_norm": 1.1255145072937012,
      "learning_rate": 4.679518072289157e-06,
      "loss": 0.0191,
      "step": 127160
    },
    {
      "epoch": 15.321686746987952,
      "grad_norm": 0.000193145708180964,
      "learning_rate": 4.6783132530120485e-06,
      "loss": 0.0032,
      "step": 127170
    },
    {
      "epoch": 15.32289156626506,
      "grad_norm": 0.00033003653516061604,
      "learning_rate": 4.67710843373494e-06,
      "loss": 0.0036,
      "step": 127180
    },
    {
      "epoch": 15.324096385542168,
      "grad_norm": 1.7085492610931396,
      "learning_rate": 4.675903614457832e-06,
      "loss": 0.0168,
      "step": 127190
    },
    {
      "epoch": 15.325301204819278,
      "grad_norm": 0.4951613247394562,
      "learning_rate": 4.674698795180723e-06,
      "loss": 0.0152,
      "step": 127200
    },
    {
      "epoch": 15.326506024096386,
      "grad_norm": 0.4798216223716736,
      "learning_rate": 4.673493975903615e-06,
      "loss": 0.0109,
      "step": 127210
    },
    {
      "epoch": 15.327710843373493,
      "grad_norm": 2.1059787273406982,
      "learning_rate": 4.672289156626506e-06,
      "loss": 0.022,
      "step": 127220
    },
    {
      "epoch": 15.328915662650603,
      "grad_norm": 0.44569316506385803,
      "learning_rate": 4.671084337349398e-06,
      "loss": 0.0044,
      "step": 127230
    },
    {
      "epoch": 15.330120481927711,
      "grad_norm": 0.7455664277076721,
      "learning_rate": 4.66987951807229e-06,
      "loss": 0.004,
      "step": 127240
    },
    {
      "epoch": 15.331325301204819,
      "grad_norm": 0.00017195232794620097,
      "learning_rate": 4.668674698795181e-06,
      "loss": 0.0688,
      "step": 127250
    },
    {
      "epoch": 15.332530120481927,
      "grad_norm": 0.00043266109423711896,
      "learning_rate": 4.667469879518073e-06,
      "loss": 0.0258,
      "step": 127260
    },
    {
      "epoch": 15.333734939759037,
      "grad_norm": 0.030163589864969254,
      "learning_rate": 4.666265060240964e-06,
      "loss": 0.0028,
      "step": 127270
    },
    {
      "epoch": 15.334939759036144,
      "grad_norm": 0.08474747836589813,
      "learning_rate": 4.665060240963856e-06,
      "loss": 0.0033,
      "step": 127280
    },
    {
      "epoch": 15.336144578313252,
      "grad_norm": 0.0007197220111265779,
      "learning_rate": 4.663855421686747e-06,
      "loss": 0.011,
      "step": 127290
    },
    {
      "epoch": 15.337349397590362,
      "grad_norm": 0.00030820953543297946,
      "learning_rate": 4.662650602409639e-06,
      "loss": 0.0047,
      "step": 127300
    },
    {
      "epoch": 15.33855421686747,
      "grad_norm": 0.003389847930520773,
      "learning_rate": 4.661445783132531e-06,
      "loss": 0.0143,
      "step": 127310
    },
    {
      "epoch": 15.339759036144578,
      "grad_norm": 0.9744903445243835,
      "learning_rate": 4.660240963855422e-06,
      "loss": 0.0075,
      "step": 127320
    },
    {
      "epoch": 15.340963855421688,
      "grad_norm": 0.0002793562598526478,
      "learning_rate": 4.659036144578314e-06,
      "loss": 0.0046,
      "step": 127330
    },
    {
      "epoch": 15.342168674698796,
      "grad_norm": 0.054996270686388016,
      "learning_rate": 4.6578313253012055e-06,
      "loss": 0.0168,
      "step": 127340
    },
    {
      "epoch": 15.343373493975903,
      "grad_norm": 0.4551040828227997,
      "learning_rate": 4.656626506024097e-06,
      "loss": 0.0079,
      "step": 127350
    },
    {
      "epoch": 15.344578313253011,
      "grad_norm": 0.8921392560005188,
      "learning_rate": 4.655421686746988e-06,
      "loss": 0.0182,
      "step": 127360
    },
    {
      "epoch": 15.345783132530121,
      "grad_norm": 1.5757596492767334,
      "learning_rate": 4.65421686746988e-06,
      "loss": 0.0541,
      "step": 127370
    },
    {
      "epoch": 15.346987951807229,
      "grad_norm": 0.00014361782814376056,
      "learning_rate": 4.653012048192772e-06,
      "loss": 0.0071,
      "step": 127380
    },
    {
      "epoch": 15.348192771084337,
      "grad_norm": 0.001802530838176608,
      "learning_rate": 4.6518072289156626e-06,
      "loss": 0.0211,
      "step": 127390
    },
    {
      "epoch": 15.349397590361447,
      "grad_norm": 0.00030818500090390444,
      "learning_rate": 4.650602409638554e-06,
      "loss": 0.0135,
      "step": 127400
    },
    {
      "epoch": 15.350602409638554,
      "grad_norm": 0.008078939281404018,
      "learning_rate": 4.649397590361447e-06,
      "loss": 0.019,
      "step": 127410
    },
    {
      "epoch": 15.351807228915662,
      "grad_norm": 0.00018285268743056804,
      "learning_rate": 4.648192771084337e-06,
      "loss": 0.0011,
      "step": 127420
    },
    {
      "epoch": 15.35301204819277,
      "grad_norm": 0.006641838699579239,
      "learning_rate": 4.646987951807229e-06,
      "loss": 0.0,
      "step": 127430
    },
    {
      "epoch": 15.35421686746988,
      "grad_norm": 1.5907031297683716,
      "learning_rate": 4.6457831325301205e-06,
      "loss": 0.0155,
      "step": 127440
    },
    {
      "epoch": 15.355421686746988,
      "grad_norm": 0.0002542888396419585,
      "learning_rate": 4.644578313253013e-06,
      "loss": 0.0349,
      "step": 127450
    },
    {
      "epoch": 15.356626506024096,
      "grad_norm": 0.9078823328018188,
      "learning_rate": 4.643373493975904e-06,
      "loss": 0.0225,
      "step": 127460
    },
    {
      "epoch": 15.357831325301206,
      "grad_norm": 0.00017828904674388468,
      "learning_rate": 4.642168674698795e-06,
      "loss": 0.002,
      "step": 127470
    },
    {
      "epoch": 15.359036144578313,
      "grad_norm": 0.32493555545806885,
      "learning_rate": 4.640963855421688e-06,
      "loss": 0.0381,
      "step": 127480
    },
    {
      "epoch": 15.360240963855421,
      "grad_norm": 9.72274792729877e-05,
      "learning_rate": 4.6397590361445784e-06,
      "loss": 0.0147,
      "step": 127490
    },
    {
      "epoch": 15.36144578313253,
      "grad_norm": 0.0005177110433578491,
      "learning_rate": 4.63855421686747e-06,
      "loss": 0.014,
      "step": 127500
    },
    {
      "epoch": 15.362650602409639,
      "grad_norm": 0.7773306965827942,
      "learning_rate": 4.637349397590362e-06,
      "loss": 0.0245,
      "step": 127510
    },
    {
      "epoch": 15.363855421686747,
      "grad_norm": 0.28190547227859497,
      "learning_rate": 4.636144578313253e-06,
      "loss": 0.0134,
      "step": 127520
    },
    {
      "epoch": 15.365060240963855,
      "grad_norm": 0.00016536518523935229,
      "learning_rate": 4.634939759036145e-06,
      "loss": 0.0094,
      "step": 127530
    },
    {
      "epoch": 15.366265060240965,
      "grad_norm": 0.9858492016792297,
      "learning_rate": 4.633734939759036e-06,
      "loss": 0.0205,
      "step": 127540
    },
    {
      "epoch": 15.367469879518072,
      "grad_norm": 0.0002016162616200745,
      "learning_rate": 4.632530120481928e-06,
      "loss": 0.0019,
      "step": 127550
    },
    {
      "epoch": 15.36867469879518,
      "grad_norm": 0.1818104088306427,
      "learning_rate": 4.6313253012048196e-06,
      "loss": 0.0194,
      "step": 127560
    },
    {
      "epoch": 15.369879518072288,
      "grad_norm": 0.9150862693786621,
      "learning_rate": 4.630120481927711e-06,
      "loss": 0.0072,
      "step": 127570
    },
    {
      "epoch": 15.371084337349398,
      "grad_norm": 0.0004953457973897457,
      "learning_rate": 4.628915662650603e-06,
      "loss": 0.0042,
      "step": 127580
    },
    {
      "epoch": 15.372289156626506,
      "grad_norm": 0.00047459741472266614,
      "learning_rate": 4.627710843373494e-06,
      "loss": 0.0061,
      "step": 127590
    },
    {
      "epoch": 15.373493975903614,
      "grad_norm": 0.9051345586776733,
      "learning_rate": 4.626506024096386e-06,
      "loss": 0.0258,
      "step": 127600
    },
    {
      "epoch": 15.374698795180723,
      "grad_norm": 18.12192153930664,
      "learning_rate": 4.6253012048192775e-06,
      "loss": 0.0216,
      "step": 127610
    },
    {
      "epoch": 15.375903614457831,
      "grad_norm": 0.000186703575309366,
      "learning_rate": 4.624096385542169e-06,
      "loss": 0.0073,
      "step": 127620
    },
    {
      "epoch": 15.37710843373494,
      "grad_norm": 1.239203929901123,
      "learning_rate": 4.622891566265061e-06,
      "loss": 0.0095,
      "step": 127630
    },
    {
      "epoch": 15.378313253012049,
      "grad_norm": 0.0003552777343429625,
      "learning_rate": 4.621686746987952e-06,
      "loss": 0.0047,
      "step": 127640
    },
    {
      "epoch": 15.379518072289157,
      "grad_norm": 0.001216637552715838,
      "learning_rate": 4.620481927710844e-06,
      "loss": 0.0114,
      "step": 127650
    },
    {
      "epoch": 15.380722891566265,
      "grad_norm": 1.0488468408584595,
      "learning_rate": 4.6192771084337354e-06,
      "loss": 0.0416,
      "step": 127660
    },
    {
      "epoch": 15.381927710843373,
      "grad_norm": 0.00032230393844656646,
      "learning_rate": 4.618072289156627e-06,
      "loss": 0.0068,
      "step": 127670
    },
    {
      "epoch": 15.383132530120482,
      "grad_norm": 0.0007747632334940135,
      "learning_rate": 4.616867469879519e-06,
      "loss": 0.0271,
      "step": 127680
    },
    {
      "epoch": 15.38433734939759,
      "grad_norm": 0.036937396973371506,
      "learning_rate": 4.61566265060241e-06,
      "loss": 0.0266,
      "step": 127690
    },
    {
      "epoch": 15.385542168674698,
      "grad_norm": 0.0029952775221318007,
      "learning_rate": 4.614457831325301e-06,
      "loss": 0.0006,
      "step": 127700
    },
    {
      "epoch": 15.386746987951808,
      "grad_norm": 0.9456067085266113,
      "learning_rate": 4.613253012048193e-06,
      "loss": 0.0191,
      "step": 127710
    },
    {
      "epoch": 15.387951807228916,
      "grad_norm": 0.018138322979211807,
      "learning_rate": 4.612048192771085e-06,
      "loss": 0.0084,
      "step": 127720
    },
    {
      "epoch": 15.389156626506024,
      "grad_norm": 0.033069346100091934,
      "learning_rate": 4.6108433734939766e-06,
      "loss": 0.0104,
      "step": 127730
    },
    {
      "epoch": 15.390361445783132,
      "grad_norm": 0.0006661043735221028,
      "learning_rate": 4.609638554216868e-06,
      "loss": 0.0033,
      "step": 127740
    },
    {
      "epoch": 15.391566265060241,
      "grad_norm": 0.8601336479187012,
      "learning_rate": 4.60843373493976e-06,
      "loss": 0.0059,
      "step": 127750
    },
    {
      "epoch": 15.39277108433735,
      "grad_norm": 1.6748464107513428,
      "learning_rate": 4.607228915662651e-06,
      "loss": 0.0473,
      "step": 127760
    },
    {
      "epoch": 15.393975903614457,
      "grad_norm": 0.9271984100341797,
      "learning_rate": 4.606024096385542e-06,
      "loss": 0.013,
      "step": 127770
    },
    {
      "epoch": 15.395180722891567,
      "grad_norm": 0.013018006458878517,
      "learning_rate": 4.6048192771084345e-06,
      "loss": 0.0023,
      "step": 127780
    },
    {
      "epoch": 15.396385542168675,
      "grad_norm": 0.012212825939059258,
      "learning_rate": 4.603614457831326e-06,
      "loss": 0.0156,
      "step": 127790
    },
    {
      "epoch": 15.397590361445783,
      "grad_norm": 0.00022457577870227396,
      "learning_rate": 4.602409638554217e-06,
      "loss": 0.0063,
      "step": 127800
    },
    {
      "epoch": 15.398795180722892,
      "grad_norm": 0.0009934718254953623,
      "learning_rate": 4.601204819277108e-06,
      "loss": 0.0067,
      "step": 127810
    },
    {
      "epoch": 15.4,
      "grad_norm": 0.022220846265554428,
      "learning_rate": 4.600000000000001e-06,
      "loss": 0.0036,
      "step": 127820
    },
    {
      "epoch": 15.401204819277108,
      "grad_norm": 0.00033511812216602266,
      "learning_rate": 4.598795180722892e-06,
      "loss": 0.0245,
      "step": 127830
    },
    {
      "epoch": 15.402409638554216,
      "grad_norm": 0.000193890169612132,
      "learning_rate": 4.597590361445783e-06,
      "loss": 0.0046,
      "step": 127840
    },
    {
      "epoch": 15.403614457831326,
      "grad_norm": 0.8262969255447388,
      "learning_rate": 4.596385542168675e-06,
      "loss": 0.0413,
      "step": 127850
    },
    {
      "epoch": 15.404819277108434,
      "grad_norm": 0.0005095163360238075,
      "learning_rate": 4.595180722891567e-06,
      "loss": 0.0216,
      "step": 127860
    },
    {
      "epoch": 15.406024096385542,
      "grad_norm": 0.0015459808055311441,
      "learning_rate": 4.593975903614458e-06,
      "loss": 0.0027,
      "step": 127870
    },
    {
      "epoch": 15.407228915662651,
      "grad_norm": 0.000379512261133641,
      "learning_rate": 4.5927710843373495e-06,
      "loss": 0.0148,
      "step": 127880
    },
    {
      "epoch": 15.40843373493976,
      "grad_norm": 1.4316545724868774,
      "learning_rate": 4.591566265060242e-06,
      "loss": 0.0126,
      "step": 127890
    },
    {
      "epoch": 15.409638554216867,
      "grad_norm": 0.0003628126869443804,
      "learning_rate": 4.590361445783133e-06,
      "loss": 0.0034,
      "step": 127900
    },
    {
      "epoch": 15.410843373493975,
      "grad_norm": 0.0001699124404694885,
      "learning_rate": 4.589156626506024e-06,
      "loss": 0.0071,
      "step": 127910
    },
    {
      "epoch": 15.412048192771085,
      "grad_norm": 0.0035995584912598133,
      "learning_rate": 4.587951807228916e-06,
      "loss": 0.0203,
      "step": 127920
    },
    {
      "epoch": 15.413253012048193,
      "grad_norm": 0.0011770029086619616,
      "learning_rate": 4.5867469879518075e-06,
      "loss": 0.0125,
      "step": 127930
    },
    {
      "epoch": 15.4144578313253,
      "grad_norm": 1.7945373058319092,
      "learning_rate": 4.585542168674699e-06,
      "loss": 0.0636,
      "step": 127940
    },
    {
      "epoch": 15.41566265060241,
      "grad_norm": 0.0019392011454328895,
      "learning_rate": 4.584337349397591e-06,
      "loss": 0.0407,
      "step": 127950
    },
    {
      "epoch": 15.416867469879518,
      "grad_norm": 0.006283465772867203,
      "learning_rate": 4.583132530120482e-06,
      "loss": 0.0052,
      "step": 127960
    },
    {
      "epoch": 15.418072289156626,
      "grad_norm": 0.006549514830112457,
      "learning_rate": 4.581927710843374e-06,
      "loss": 0.0058,
      "step": 127970
    },
    {
      "epoch": 15.419277108433734,
      "grad_norm": 0.7215931415557861,
      "learning_rate": 4.580722891566265e-06,
      "loss": 0.0012,
      "step": 127980
    },
    {
      "epoch": 15.420481927710844,
      "grad_norm": 0.0012837446993216872,
      "learning_rate": 4.579518072289157e-06,
      "loss": 0.0131,
      "step": 127990
    },
    {
      "epoch": 15.421686746987952,
      "grad_norm": 0.43056535720825195,
      "learning_rate": 4.578313253012049e-06,
      "loss": 0.0069,
      "step": 128000
    },
    {
      "epoch": 15.42289156626506,
      "grad_norm": 0.0002276018785778433,
      "learning_rate": 4.57710843373494e-06,
      "loss": 0.012,
      "step": 128010
    },
    {
      "epoch": 15.42409638554217,
      "grad_norm": 0.9490919709205627,
      "learning_rate": 4.575903614457832e-06,
      "loss": 0.0084,
      "step": 128020
    },
    {
      "epoch": 15.425301204819277,
      "grad_norm": 0.0036688537802547216,
      "learning_rate": 4.574698795180723e-06,
      "loss": 0.0154,
      "step": 128030
    },
    {
      "epoch": 15.426506024096385,
      "grad_norm": 1.3711252212524414,
      "learning_rate": 4.573493975903615e-06,
      "loss": 0.0172,
      "step": 128040
    },
    {
      "epoch": 15.427710843373493,
      "grad_norm": 0.4521620571613312,
      "learning_rate": 4.5722891566265065e-06,
      "loss": 0.004,
      "step": 128050
    },
    {
      "epoch": 15.428915662650603,
      "grad_norm": 1.2762608528137207,
      "learning_rate": 4.571084337349398e-06,
      "loss": 0.0139,
      "step": 128060
    },
    {
      "epoch": 15.43012048192771,
      "grad_norm": 0.9446621537208557,
      "learning_rate": 4.56987951807229e-06,
      "loss": 0.0124,
      "step": 128070
    },
    {
      "epoch": 15.431325301204819,
      "grad_norm": 1.3697408437728882,
      "learning_rate": 4.568674698795181e-06,
      "loss": 0.0199,
      "step": 128080
    },
    {
      "epoch": 15.432530120481928,
      "grad_norm": 0.007917946204543114,
      "learning_rate": 4.567469879518073e-06,
      "loss": 0.0041,
      "step": 128090
    },
    {
      "epoch": 15.433734939759036,
      "grad_norm": 0.8166443705558777,
      "learning_rate": 4.5662650602409645e-06,
      "loss": 0.0606,
      "step": 128100
    },
    {
      "epoch": 15.434939759036144,
      "grad_norm": 0.000826457398943603,
      "learning_rate": 4.565060240963855e-06,
      "loss": 0.0181,
      "step": 128110
    },
    {
      "epoch": 15.436144578313254,
      "grad_norm": 0.0009701117523945868,
      "learning_rate": 4.563855421686748e-06,
      "loss": 0.0105,
      "step": 128120
    },
    {
      "epoch": 15.437349397590362,
      "grad_norm": 0.09540503472089767,
      "learning_rate": 4.562650602409639e-06,
      "loss": 0.0061,
      "step": 128130
    },
    {
      "epoch": 15.43855421686747,
      "grad_norm": 0.007315612863749266,
      "learning_rate": 4.56144578313253e-06,
      "loss": 0.0249,
      "step": 128140
    },
    {
      "epoch": 15.439759036144578,
      "grad_norm": 0.00532147753983736,
      "learning_rate": 4.5602409638554216e-06,
      "loss": 0.0005,
      "step": 128150
    },
    {
      "epoch": 15.440963855421687,
      "grad_norm": 0.0025402922183275223,
      "learning_rate": 4.559036144578314e-06,
      "loss": 0.0195,
      "step": 128160
    },
    {
      "epoch": 15.442168674698795,
      "grad_norm": 0.009252618998289108,
      "learning_rate": 4.557831325301206e-06,
      "loss": 0.0291,
      "step": 128170
    },
    {
      "epoch": 15.443373493975903,
      "grad_norm": 8.527082443237305,
      "learning_rate": 4.556626506024096e-06,
      "loss": 0.0327,
      "step": 128180
    },
    {
      "epoch": 15.444578313253013,
      "grad_norm": 0.0011909587774425745,
      "learning_rate": 4.555421686746989e-06,
      "loss": 0.013,
      "step": 128190
    },
    {
      "epoch": 15.44578313253012,
      "grad_norm": 0.001926939468830824,
      "learning_rate": 4.55421686746988e-06,
      "loss": 0.0112,
      "step": 128200
    },
    {
      "epoch": 15.446987951807229,
      "grad_norm": 0.013092423789203167,
      "learning_rate": 4.553012048192771e-06,
      "loss": 0.0087,
      "step": 128210
    },
    {
      "epoch": 15.448192771084337,
      "grad_norm": 17.428173065185547,
      "learning_rate": 4.551807228915663e-06,
      "loss": 0.0472,
      "step": 128220
    },
    {
      "epoch": 15.449397590361446,
      "grad_norm": 0.35437679290771484,
      "learning_rate": 4.550602409638555e-06,
      "loss": 0.0371,
      "step": 128230
    },
    {
      "epoch": 15.450602409638554,
      "grad_norm": 0.0009777451632544398,
      "learning_rate": 4.549397590361446e-06,
      "loss": 0.007,
      "step": 128240
    },
    {
      "epoch": 15.451807228915662,
      "grad_norm": 1.006455659866333,
      "learning_rate": 4.5481927710843374e-06,
      "loss": 0.0161,
      "step": 128250
    },
    {
      "epoch": 15.453012048192772,
      "grad_norm": 0.0012707281857728958,
      "learning_rate": 4.546987951807229e-06,
      "loss": 0.0028,
      "step": 128260
    },
    {
      "epoch": 15.45421686746988,
      "grad_norm": 0.002287163631990552,
      "learning_rate": 4.5457831325301215e-06,
      "loss": 0.0103,
      "step": 128270
    },
    {
      "epoch": 15.455421686746988,
      "grad_norm": 0.0017932434566318989,
      "learning_rate": 4.544578313253012e-06,
      "loss": 0.022,
      "step": 128280
    },
    {
      "epoch": 15.456626506024097,
      "grad_norm": 0.8445107340812683,
      "learning_rate": 4.543373493975904e-06,
      "loss": 0.0133,
      "step": 128290
    },
    {
      "epoch": 15.457831325301205,
      "grad_norm": 9.966287612915039,
      "learning_rate": 4.542168674698795e-06,
      "loss": 0.0484,
      "step": 128300
    },
    {
      "epoch": 15.459036144578313,
      "grad_norm": 0.00024325902631971985,
      "learning_rate": 4.540963855421687e-06,
      "loss": 0.0084,
      "step": 128310
    },
    {
      "epoch": 15.460240963855421,
      "grad_norm": 0.0007761947344988585,
      "learning_rate": 4.5397590361445786e-06,
      "loss": 0.0108,
      "step": 128320
    },
    {
      "epoch": 15.46144578313253,
      "grad_norm": 0.25503870844841003,
      "learning_rate": 4.53855421686747e-06,
      "loss": 0.0139,
      "step": 128330
    },
    {
      "epoch": 15.462650602409639,
      "grad_norm": 0.0010678820544853806,
      "learning_rate": 4.537349397590362e-06,
      "loss": 0.0038,
      "step": 128340
    },
    {
      "epoch": 15.463855421686747,
      "grad_norm": 0.25052544474601746,
      "learning_rate": 4.536144578313253e-06,
      "loss": 0.007,
      "step": 128350
    },
    {
      "epoch": 15.465060240963856,
      "grad_norm": 0.015446760691702366,
      "learning_rate": 4.534939759036145e-06,
      "loss": 0.0064,
      "step": 128360
    },
    {
      "epoch": 15.466265060240964,
      "grad_norm": 0.0021129476372152567,
      "learning_rate": 4.5337349397590365e-06,
      "loss": 0.0,
      "step": 128370
    },
    {
      "epoch": 15.467469879518072,
      "grad_norm": 1.6540604829788208,
      "learning_rate": 4.532530120481928e-06,
      "loss": 0.0157,
      "step": 128380
    },
    {
      "epoch": 15.46867469879518,
      "grad_norm": 0.0005624729092232883,
      "learning_rate": 4.53132530120482e-06,
      "loss": 0.0062,
      "step": 128390
    },
    {
      "epoch": 15.46987951807229,
      "grad_norm": 0.0008652873220853508,
      "learning_rate": 4.530120481927711e-06,
      "loss": 0.0347,
      "step": 128400
    },
    {
      "epoch": 15.471084337349398,
      "grad_norm": 39.322174072265625,
      "learning_rate": 4.528915662650603e-06,
      "loss": 0.0147,
      "step": 128410
    },
    {
      "epoch": 15.472289156626506,
      "grad_norm": 0.2913966476917267,
      "learning_rate": 4.5277108433734944e-06,
      "loss": 0.0034,
      "step": 128420
    },
    {
      "epoch": 15.473493975903615,
      "grad_norm": 1.4599535465240479,
      "learning_rate": 4.526506024096386e-06,
      "loss": 0.0091,
      "step": 128430
    },
    {
      "epoch": 15.474698795180723,
      "grad_norm": 0.8060882091522217,
      "learning_rate": 4.525301204819278e-06,
      "loss": 0.0179,
      "step": 128440
    },
    {
      "epoch": 15.475903614457831,
      "grad_norm": 0.0017579966224730015,
      "learning_rate": 4.524096385542169e-06,
      "loss": 0.0244,
      "step": 128450
    },
    {
      "epoch": 15.477108433734939,
      "grad_norm": 0.6111345291137695,
      "learning_rate": 4.522891566265061e-06,
      "loss": 0.0098,
      "step": 128460
    },
    {
      "epoch": 15.478313253012049,
      "grad_norm": 0.24679167568683624,
      "learning_rate": 4.521686746987952e-06,
      "loss": 0.0028,
      "step": 128470
    },
    {
      "epoch": 15.479518072289157,
      "grad_norm": 0.007409932091832161,
      "learning_rate": 4.520481927710844e-06,
      "loss": 0.0225,
      "step": 128480
    },
    {
      "epoch": 15.480722891566264,
      "grad_norm": 5.907584190368652,
      "learning_rate": 4.5192771084337356e-06,
      "loss": 0.0486,
      "step": 128490
    },
    {
      "epoch": 15.481927710843374,
      "grad_norm": 0.0007534672040492296,
      "learning_rate": 4.518072289156627e-06,
      "loss": 0.0061,
      "step": 128500
    },
    {
      "epoch": 15.483132530120482,
      "grad_norm": 0.0013722737785428762,
      "learning_rate": 4.516867469879519e-06,
      "loss": 0.0067,
      "step": 128510
    },
    {
      "epoch": 15.48433734939759,
      "grad_norm": 0.7640398144721985,
      "learning_rate": 4.5156626506024095e-06,
      "loss": 0.0216,
      "step": 128520
    },
    {
      "epoch": 15.485542168674698,
      "grad_norm": 0.4129311144351959,
      "learning_rate": 4.514457831325302e-06,
      "loss": 0.0312,
      "step": 128530
    },
    {
      "epoch": 15.486746987951808,
      "grad_norm": 0.8328759670257568,
      "learning_rate": 4.5132530120481935e-06,
      "loss": 0.006,
      "step": 128540
    },
    {
      "epoch": 15.487951807228916,
      "grad_norm": 0.0012261857045814395,
      "learning_rate": 4.512048192771084e-06,
      "loss": 0.0107,
      "step": 128550
    },
    {
      "epoch": 15.489156626506023,
      "grad_norm": 0.0019899688195437193,
      "learning_rate": 4.510843373493976e-06,
      "loss": 0.0037,
      "step": 128560
    },
    {
      "epoch": 15.490361445783133,
      "grad_norm": 0.23354317247867584,
      "learning_rate": 4.509638554216868e-06,
      "loss": 0.0123,
      "step": 128570
    },
    {
      "epoch": 15.491566265060241,
      "grad_norm": 0.0007605515420436859,
      "learning_rate": 4.50843373493976e-06,
      "loss": 0.0044,
      "step": 128580
    },
    {
      "epoch": 15.492771084337349,
      "grad_norm": 1.0225684642791748,
      "learning_rate": 4.507228915662651e-06,
      "loss": 0.0099,
      "step": 128590
    },
    {
      "epoch": 15.493975903614459,
      "grad_norm": 0.15412259101867676,
      "learning_rate": 4.506024096385542e-06,
      "loss": 0.0001,
      "step": 128600
    },
    {
      "epoch": 15.495180722891567,
      "grad_norm": 0.0010466501116752625,
      "learning_rate": 4.504819277108435e-06,
      "loss": 0.0139,
      "step": 128610
    },
    {
      "epoch": 15.496385542168674,
      "grad_norm": 0.000560683838557452,
      "learning_rate": 4.503614457831325e-06,
      "loss": 0.0094,
      "step": 128620
    },
    {
      "epoch": 15.497590361445782,
      "grad_norm": 0.0005271554691717029,
      "learning_rate": 4.502409638554217e-06,
      "loss": 0.006,
      "step": 128630
    },
    {
      "epoch": 15.498795180722892,
      "grad_norm": 0.4059155583381653,
      "learning_rate": 4.501204819277109e-06,
      "loss": 0.0008,
      "step": 128640
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.0008285217918455601,
      "learning_rate": 4.5e-06,
      "loss": 0.0173,
      "step": 128650
    },
    {
      "epoch": 15.501204819277108,
      "grad_norm": 1.1646233797073364,
      "learning_rate": 4.498795180722892e-06,
      "loss": 0.0172,
      "step": 128660
    },
    {
      "epoch": 15.502409638554218,
      "grad_norm": 0.00042648951057344675,
      "learning_rate": 4.497590361445783e-06,
      "loss": 0.0066,
      "step": 128670
    },
    {
      "epoch": 15.503614457831326,
      "grad_norm": 0.13907456398010254,
      "learning_rate": 4.496385542168675e-06,
      "loss": 0.0078,
      "step": 128680
    },
    {
      "epoch": 15.504819277108433,
      "grad_norm": 0.0005066900048404932,
      "learning_rate": 4.4951807228915665e-06,
      "loss": 0.019,
      "step": 128690
    },
    {
      "epoch": 15.506024096385541,
      "grad_norm": 0.0009435282554477453,
      "learning_rate": 4.493975903614458e-06,
      "loss": 0.007,
      "step": 128700
    },
    {
      "epoch": 15.507228915662651,
      "grad_norm": 0.00021697807824239135,
      "learning_rate": 4.49277108433735e-06,
      "loss": 0.0138,
      "step": 128710
    },
    {
      "epoch": 15.508433734939759,
      "grad_norm": 0.0007126780110411346,
      "learning_rate": 4.491566265060241e-06,
      "loss": 0.0131,
      "step": 128720
    },
    {
      "epoch": 15.509638554216867,
      "grad_norm": 0.8456831574440002,
      "learning_rate": 4.490361445783133e-06,
      "loss": 0.0122,
      "step": 128730
    },
    {
      "epoch": 15.510843373493977,
      "grad_norm": 0.0006714428891427815,
      "learning_rate": 4.489156626506024e-06,
      "loss": 0.0161,
      "step": 128740
    },
    {
      "epoch": 15.512048192771084,
      "grad_norm": 0.0009777200175449252,
      "learning_rate": 4.487951807228916e-06,
      "loss": 0.0036,
      "step": 128750
    },
    {
      "epoch": 15.513253012048192,
      "grad_norm": 0.0004937441553920507,
      "learning_rate": 4.486746987951808e-06,
      "loss": 0.0476,
      "step": 128760
    },
    {
      "epoch": 15.514457831325302,
      "grad_norm": 0.0003117445157840848,
      "learning_rate": 4.485542168674699e-06,
      "loss": 0.0187,
      "step": 128770
    },
    {
      "epoch": 15.51566265060241,
      "grad_norm": 0.0005772594013251364,
      "learning_rate": 4.484337349397591e-06,
      "loss": 0.0132,
      "step": 128780
    },
    {
      "epoch": 15.516867469879518,
      "grad_norm": 0.002441328950226307,
      "learning_rate": 4.483132530120482e-06,
      "loss": 0.0038,
      "step": 128790
    },
    {
      "epoch": 15.518072289156626,
      "grad_norm": 0.004177767783403397,
      "learning_rate": 4.481927710843374e-06,
      "loss": 0.0169,
      "step": 128800
    },
    {
      "epoch": 15.519277108433736,
      "grad_norm": 0.0003975348372478038,
      "learning_rate": 4.4807228915662655e-06,
      "loss": 0.0077,
      "step": 128810
    },
    {
      "epoch": 15.520481927710843,
      "grad_norm": 0.5000482797622681,
      "learning_rate": 4.479518072289157e-06,
      "loss": 0.0141,
      "step": 128820
    },
    {
      "epoch": 15.521686746987951,
      "grad_norm": 0.0005612910608761013,
      "learning_rate": 4.478313253012049e-06,
      "loss": 0.0062,
      "step": 128830
    },
    {
      "epoch": 15.522891566265061,
      "grad_norm": 0.043125253170728683,
      "learning_rate": 4.47710843373494e-06,
      "loss": 0.0255,
      "step": 128840
    },
    {
      "epoch": 15.524096385542169,
      "grad_norm": 0.5866759419441223,
      "learning_rate": 4.475903614457832e-06,
      "loss": 0.0145,
      "step": 128850
    },
    {
      "epoch": 15.525301204819277,
      "grad_norm": 0.005401273723691702,
      "learning_rate": 4.474698795180723e-06,
      "loss": 0.0322,
      "step": 128860
    },
    {
      "epoch": 15.526506024096385,
      "grad_norm": 1.8711764812469482,
      "learning_rate": 4.473493975903615e-06,
      "loss": 0.0125,
      "step": 128870
    },
    {
      "epoch": 15.527710843373494,
      "grad_norm": 0.0004782053001690656,
      "learning_rate": 4.472289156626507e-06,
      "loss": 0.0091,
      "step": 128880
    },
    {
      "epoch": 15.528915662650602,
      "grad_norm": 0.27393049001693726,
      "learning_rate": 4.471084337349398e-06,
      "loss": 0.0036,
      "step": 128890
    },
    {
      "epoch": 15.53012048192771,
      "grad_norm": 0.0007797979051247239,
      "learning_rate": 4.469879518072289e-06,
      "loss": 0.0069,
      "step": 128900
    },
    {
      "epoch": 15.53132530120482,
      "grad_norm": 0.8015328049659729,
      "learning_rate": 4.468674698795181e-06,
      "loss": 0.0032,
      "step": 128910
    },
    {
      "epoch": 15.532530120481928,
      "grad_norm": 0.0007335139089263976,
      "learning_rate": 4.467469879518073e-06,
      "loss": 0.0117,
      "step": 128920
    },
    {
      "epoch": 15.533734939759036,
      "grad_norm": 0.6276018023490906,
      "learning_rate": 4.466265060240964e-06,
      "loss": 0.0158,
      "step": 128930
    },
    {
      "epoch": 15.534939759036144,
      "grad_norm": 0.0004604370624292642,
      "learning_rate": 4.465060240963856e-06,
      "loss": 0.0328,
      "step": 128940
    },
    {
      "epoch": 15.536144578313253,
      "grad_norm": 0.02739005722105503,
      "learning_rate": 4.463855421686748e-06,
      "loss": 0.0171,
      "step": 128950
    },
    {
      "epoch": 15.537349397590361,
      "grad_norm": 0.0004407377273309976,
      "learning_rate": 4.4626506024096385e-06,
      "loss": 0.0035,
      "step": 128960
    },
    {
      "epoch": 15.53855421686747,
      "grad_norm": 0.0003920593298971653,
      "learning_rate": 4.46144578313253e-06,
      "loss": 0.041,
      "step": 128970
    },
    {
      "epoch": 15.539759036144579,
      "grad_norm": 0.9146499633789062,
      "learning_rate": 4.4602409638554225e-06,
      "loss": 0.0163,
      "step": 128980
    },
    {
      "epoch": 15.540963855421687,
      "grad_norm": 0.9626116752624512,
      "learning_rate": 4.459036144578314e-06,
      "loss": 0.0178,
      "step": 128990
    },
    {
      "epoch": 15.542168674698795,
      "grad_norm": 0.9138293862342834,
      "learning_rate": 4.457831325301205e-06,
      "loss": 0.011,
      "step": 129000
    },
    {
      "epoch": 15.543373493975903,
      "grad_norm": 0.0005875842180103064,
      "learning_rate": 4.4566265060240964e-06,
      "loss": 0.0232,
      "step": 129010
    },
    {
      "epoch": 15.544578313253012,
      "grad_norm": 1.6249972581863403,
      "learning_rate": 4.455421686746989e-06,
      "loss": 0.0137,
      "step": 129020
    },
    {
      "epoch": 15.54578313253012,
      "grad_norm": 1.549033284187317,
      "learning_rate": 4.45421686746988e-06,
      "loss": 0.0207,
      "step": 129030
    },
    {
      "epoch": 15.546987951807228,
      "grad_norm": 0.0012478280114009976,
      "learning_rate": 4.453012048192771e-06,
      "loss": 0.016,
      "step": 129040
    },
    {
      "epoch": 15.548192771084338,
      "grad_norm": 0.020565439015626907,
      "learning_rate": 4.451807228915663e-06,
      "loss": 0.0229,
      "step": 129050
    },
    {
      "epoch": 15.549397590361446,
      "grad_norm": 1.1201646327972412,
      "learning_rate": 4.450602409638554e-06,
      "loss": 0.0138,
      "step": 129060
    },
    {
      "epoch": 15.550602409638554,
      "grad_norm": 6.439194679260254,
      "learning_rate": 4.449397590361446e-06,
      "loss": 0.0279,
      "step": 129070
    },
    {
      "epoch": 15.551807228915663,
      "grad_norm": 0.002303938614204526,
      "learning_rate": 4.4481927710843376e-06,
      "loss": 0.0151,
      "step": 129080
    },
    {
      "epoch": 15.553012048192771,
      "grad_norm": 0.014830134809017181,
      "learning_rate": 4.446987951807229e-06,
      "loss": 0.0169,
      "step": 129090
    },
    {
      "epoch": 15.55421686746988,
      "grad_norm": 1.2150323390960693,
      "learning_rate": 4.445783132530121e-06,
      "loss": 0.0075,
      "step": 129100
    },
    {
      "epoch": 15.555421686746987,
      "grad_norm": 0.44510728120803833,
      "learning_rate": 4.444578313253012e-06,
      "loss": 0.0051,
      "step": 129110
    },
    {
      "epoch": 15.556626506024097,
      "grad_norm": 0.008202423341572285,
      "learning_rate": 4.443373493975904e-06,
      "loss": 0.0106,
      "step": 129120
    },
    {
      "epoch": 15.557831325301205,
      "grad_norm": 0.0007437312160618603,
      "learning_rate": 4.4421686746987955e-06,
      "loss": 0.0144,
      "step": 129130
    },
    {
      "epoch": 15.559036144578313,
      "grad_norm": 1.57997727394104,
      "learning_rate": 4.440963855421687e-06,
      "loss": 0.0178,
      "step": 129140
    },
    {
      "epoch": 15.560240963855422,
      "grad_norm": 1.2099053859710693,
      "learning_rate": 4.439759036144579e-06,
      "loss": 0.0169,
      "step": 129150
    },
    {
      "epoch": 15.56144578313253,
      "grad_norm": 0.00020602240692824125,
      "learning_rate": 4.43855421686747e-06,
      "loss": 0.0008,
      "step": 129160
    },
    {
      "epoch": 15.562650602409638,
      "grad_norm": 0.00024460910935886204,
      "learning_rate": 4.437349397590362e-06,
      "loss": 0.0079,
      "step": 129170
    },
    {
      "epoch": 15.563855421686746,
      "grad_norm": 0.03478842228651047,
      "learning_rate": 4.4361445783132534e-06,
      "loss": 0.0083,
      "step": 129180
    },
    {
      "epoch": 15.565060240963856,
      "grad_norm": 0.29485341906547546,
      "learning_rate": 4.434939759036145e-06,
      "loss": 0.0116,
      "step": 129190
    },
    {
      "epoch": 15.566265060240964,
      "grad_norm": 0.0014842506498098373,
      "learning_rate": 4.433734939759037e-06,
      "loss": 0.0236,
      "step": 129200
    },
    {
      "epoch": 15.567469879518072,
      "grad_norm": 0.24825513362884521,
      "learning_rate": 4.432530120481928e-06,
      "loss": 0.0049,
      "step": 129210
    },
    {
      "epoch": 15.568674698795181,
      "grad_norm": 0.0003458314167801291,
      "learning_rate": 4.43132530120482e-06,
      "loss": 0.013,
      "step": 129220
    },
    {
      "epoch": 15.56987951807229,
      "grad_norm": 0.0003405556199140847,
      "learning_rate": 4.430120481927711e-06,
      "loss": 0.0219,
      "step": 129230
    },
    {
      "epoch": 15.571084337349397,
      "grad_norm": 0.00029080186504870653,
      "learning_rate": 4.428915662650603e-06,
      "loss": 0.0464,
      "step": 129240
    },
    {
      "epoch": 15.572289156626507,
      "grad_norm": 0.0015606890665367246,
      "learning_rate": 4.4277108433734945e-06,
      "loss": 0.0092,
      "step": 129250
    },
    {
      "epoch": 15.573493975903615,
      "grad_norm": 0.000525325012858957,
      "learning_rate": 4.426506024096386e-06,
      "loss": 0.0078,
      "step": 129260
    },
    {
      "epoch": 15.574698795180723,
      "grad_norm": 0.00045594843686558306,
      "learning_rate": 4.425301204819277e-06,
      "loss": 0.0106,
      "step": 129270
    },
    {
      "epoch": 15.57590361445783,
      "grad_norm": 0.00016489255358465016,
      "learning_rate": 4.424096385542169e-06,
      "loss": 0.0054,
      "step": 129280
    },
    {
      "epoch": 15.57710843373494,
      "grad_norm": 0.0008778932970017195,
      "learning_rate": 4.422891566265061e-06,
      "loss": 0.0077,
      "step": 129290
    },
    {
      "epoch": 15.578313253012048,
      "grad_norm": 0.0014644352486357093,
      "learning_rate": 4.4216867469879525e-06,
      "loss": 0.0326,
      "step": 129300
    },
    {
      "epoch": 15.579518072289156,
      "grad_norm": 0.933273196220398,
      "learning_rate": 4.420481927710843e-06,
      "loss": 0.0068,
      "step": 129310
    },
    {
      "epoch": 15.580722891566266,
      "grad_norm": 1.0314602851867676,
      "learning_rate": 4.419277108433736e-06,
      "loss": 0.0088,
      "step": 129320
    },
    {
      "epoch": 15.581927710843374,
      "grad_norm": 0.0002392077585682273,
      "learning_rate": 4.418072289156627e-06,
      "loss": 0.0041,
      "step": 129330
    },
    {
      "epoch": 15.583132530120482,
      "grad_norm": 0.005869776010513306,
      "learning_rate": 4.416867469879518e-06,
      "loss": 0.0228,
      "step": 129340
    },
    {
      "epoch": 15.58433734939759,
      "grad_norm": 0.0016742049483582377,
      "learning_rate": 4.41566265060241e-06,
      "loss": 0.0036,
      "step": 129350
    },
    {
      "epoch": 15.5855421686747,
      "grad_norm": 0.00024714507162570953,
      "learning_rate": 4.414457831325302e-06,
      "loss": 0.0129,
      "step": 129360
    },
    {
      "epoch": 15.586746987951807,
      "grad_norm": 0.02175489068031311,
      "learning_rate": 4.413253012048193e-06,
      "loss": 0.01,
      "step": 129370
    },
    {
      "epoch": 15.587951807228915,
      "grad_norm": 0.01525892410427332,
      "learning_rate": 4.412048192771084e-06,
      "loss": 0.0005,
      "step": 129380
    },
    {
      "epoch": 15.589156626506025,
      "grad_norm": 0.0032460864167660475,
      "learning_rate": 4.410843373493977e-06,
      "loss": 0.0089,
      "step": 129390
    },
    {
      "epoch": 15.590361445783133,
      "grad_norm": 0.7177728414535522,
      "learning_rate": 4.4096385542168675e-06,
      "loss": 0.0189,
      "step": 129400
    },
    {
      "epoch": 15.59156626506024,
      "grad_norm": 0.0003398085536900908,
      "learning_rate": 4.408433734939759e-06,
      "loss": 0.0198,
      "step": 129410
    },
    {
      "epoch": 15.592771084337349,
      "grad_norm": 0.00020746067457366735,
      "learning_rate": 4.407228915662651e-06,
      "loss": 0.0374,
      "step": 129420
    },
    {
      "epoch": 15.593975903614458,
      "grad_norm": 0.6902986764907837,
      "learning_rate": 4.406024096385543e-06,
      "loss": 0.0295,
      "step": 129430
    },
    {
      "epoch": 15.595180722891566,
      "grad_norm": 0.0047090803273022175,
      "learning_rate": 4.404819277108434e-06,
      "loss": 0.0001,
      "step": 129440
    },
    {
      "epoch": 15.596385542168674,
      "grad_norm": 0.18581241369247437,
      "learning_rate": 4.4036144578313255e-06,
      "loss": 0.0131,
      "step": 129450
    },
    {
      "epoch": 15.597590361445784,
      "grad_norm": 0.0022536213509738445,
      "learning_rate": 4.402409638554217e-06,
      "loss": 0.0094,
      "step": 129460
    },
    {
      "epoch": 15.598795180722892,
      "grad_norm": 0.23365795612335205,
      "learning_rate": 4.401204819277109e-06,
      "loss": 0.0029,
      "step": 129470
    },
    {
      "epoch": 15.6,
      "grad_norm": 0.0003320582618471235,
      "learning_rate": 4.4e-06,
      "loss": 0.0242,
      "step": 129480
    },
    {
      "epoch": 15.601204819277108,
      "grad_norm": 0.00046989621478132904,
      "learning_rate": 4.398795180722892e-06,
      "loss": 0.0153,
      "step": 129490
    },
    {
      "epoch": 15.602409638554217,
      "grad_norm": 0.0013259570114314556,
      "learning_rate": 4.397590361445783e-06,
      "loss": 0.0086,
      "step": 129500
    },
    {
      "epoch": 15.603614457831325,
      "grad_norm": 0.00024618286988697946,
      "learning_rate": 4.396385542168675e-06,
      "loss": 0.0021,
      "step": 129510
    },
    {
      "epoch": 15.604819277108433,
      "grad_norm": 0.00029569739126600325,
      "learning_rate": 4.3951807228915666e-06,
      "loss": 0.0046,
      "step": 129520
    },
    {
      "epoch": 15.606024096385543,
      "grad_norm": 0.0002578390412963927,
      "learning_rate": 4.393975903614458e-06,
      "loss": 0.0045,
      "step": 129530
    },
    {
      "epoch": 15.60722891566265,
      "grad_norm": 0.00048593536484986544,
      "learning_rate": 4.39277108433735e-06,
      "loss": 0.0171,
      "step": 129540
    },
    {
      "epoch": 15.608433734939759,
      "grad_norm": 0.007094887550920248,
      "learning_rate": 4.391566265060241e-06,
      "loss": 0.0145,
      "step": 129550
    },
    {
      "epoch": 15.609638554216868,
      "grad_norm": 0.0016340961446985602,
      "learning_rate": 4.390361445783133e-06,
      "loss": 0.0021,
      "step": 129560
    },
    {
      "epoch": 15.610843373493976,
      "grad_norm": 0.0001736611156957224,
      "learning_rate": 4.3891566265060245e-06,
      "loss": 0.0041,
      "step": 129570
    },
    {
      "epoch": 15.612048192771084,
      "grad_norm": 0.7231791019439697,
      "learning_rate": 4.387951807228916e-06,
      "loss": 0.0118,
      "step": 129580
    },
    {
      "epoch": 15.613253012048192,
      "grad_norm": 0.3024606704711914,
      "learning_rate": 4.386746987951808e-06,
      "loss": 0.0022,
      "step": 129590
    },
    {
      "epoch": 15.614457831325302,
      "grad_norm": 0.00026346894446760416,
      "learning_rate": 4.385542168674699e-06,
      "loss": 0.0035,
      "step": 129600
    },
    {
      "epoch": 15.61566265060241,
      "grad_norm": 0.0006073513068258762,
      "learning_rate": 4.384337349397591e-06,
      "loss": 0.0076,
      "step": 129610
    },
    {
      "epoch": 15.616867469879518,
      "grad_norm": 0.27208593487739563,
      "learning_rate": 4.3831325301204825e-06,
      "loss": 0.0111,
      "step": 129620
    },
    {
      "epoch": 15.618072289156627,
      "grad_norm": 0.0002898835518863052,
      "learning_rate": 4.381927710843374e-06,
      "loss": 0.0091,
      "step": 129630
    },
    {
      "epoch": 15.619277108433735,
      "grad_norm": 0.00031306673190556467,
      "learning_rate": 4.380722891566266e-06,
      "loss": 0.0362,
      "step": 129640
    },
    {
      "epoch": 15.620481927710843,
      "grad_norm": 9.12244701385498,
      "learning_rate": 4.379518072289156e-06,
      "loss": 0.0193,
      "step": 129650
    },
    {
      "epoch": 15.621686746987951,
      "grad_norm": 0.061814211308956146,
      "learning_rate": 4.378313253012049e-06,
      "loss": 0.0204,
      "step": 129660
    },
    {
      "epoch": 15.62289156626506,
      "grad_norm": 0.00025468229432590306,
      "learning_rate": 4.37710843373494e-06,
      "loss": 0.0023,
      "step": 129670
    },
    {
      "epoch": 15.624096385542169,
      "grad_norm": 2.1517369747161865,
      "learning_rate": 4.375903614457831e-06,
      "loss": 0.0211,
      "step": 129680
    },
    {
      "epoch": 15.625301204819277,
      "grad_norm": 0.008304490707814693,
      "learning_rate": 4.3746987951807236e-06,
      "loss": 0.0047,
      "step": 129690
    },
    {
      "epoch": 15.626506024096386,
      "grad_norm": 0.022786524146795273,
      "learning_rate": 4.373493975903615e-06,
      "loss": 0.0066,
      "step": 129700
    },
    {
      "epoch": 15.627710843373494,
      "grad_norm": 0.0002678055316209793,
      "learning_rate": 4.372289156626507e-06,
      "loss": 0.0402,
      "step": 129710
    },
    {
      "epoch": 15.628915662650602,
      "grad_norm": 1.0860916376113892,
      "learning_rate": 4.3710843373493975e-06,
      "loss": 0.0109,
      "step": 129720
    },
    {
      "epoch": 15.630120481927712,
      "grad_norm": 1.3845096826553345,
      "learning_rate": 4.36987951807229e-06,
      "loss": 0.0286,
      "step": 129730
    },
    {
      "epoch": 15.63132530120482,
      "grad_norm": 0.00030294572934508324,
      "learning_rate": 4.3686746987951815e-06,
      "loss": 0.0037,
      "step": 129740
    },
    {
      "epoch": 15.632530120481928,
      "grad_norm": 0.0051674810238182545,
      "learning_rate": 4.367469879518072e-06,
      "loss": 0.0278,
      "step": 129750
    },
    {
      "epoch": 15.633734939759035,
      "grad_norm": 0.0004019867046736181,
      "learning_rate": 4.366265060240964e-06,
      "loss": 0.0078,
      "step": 129760
    },
    {
      "epoch": 15.634939759036145,
      "grad_norm": 0.004699438810348511,
      "learning_rate": 4.365060240963856e-06,
      "loss": 0.0168,
      "step": 129770
    },
    {
      "epoch": 15.636144578313253,
      "grad_norm": 0.747389554977417,
      "learning_rate": 4.363855421686747e-06,
      "loss": 0.0066,
      "step": 129780
    },
    {
      "epoch": 15.637349397590361,
      "grad_norm": 0.01184475515037775,
      "learning_rate": 4.362650602409639e-06,
      "loss": 0.0008,
      "step": 129790
    },
    {
      "epoch": 15.638554216867469,
      "grad_norm": 0.0006353940698318183,
      "learning_rate": 4.361445783132531e-06,
      "loss": 0.0109,
      "step": 129800
    },
    {
      "epoch": 15.639759036144579,
      "grad_norm": 0.0010215055663138628,
      "learning_rate": 4.360240963855422e-06,
      "loss": 0.0076,
      "step": 129810
    },
    {
      "epoch": 15.640963855421687,
      "grad_norm": 0.006066041998565197,
      "learning_rate": 4.359036144578313e-06,
      "loss": 0.0121,
      "step": 129820
    },
    {
      "epoch": 15.642168674698794,
      "grad_norm": 0.000848134804982692,
      "learning_rate": 4.357831325301205e-06,
      "loss": 0.0051,
      "step": 129830
    },
    {
      "epoch": 15.643373493975904,
      "grad_norm": 0.689750611782074,
      "learning_rate": 4.356626506024097e-06,
      "loss": 0.0377,
      "step": 129840
    },
    {
      "epoch": 15.644578313253012,
      "grad_norm": 0.0010629253229126334,
      "learning_rate": 4.355421686746988e-06,
      "loss": 0.0054,
      "step": 129850
    },
    {
      "epoch": 15.64578313253012,
      "grad_norm": 0.3891126811504364,
      "learning_rate": 4.35421686746988e-06,
      "loss": 0.0212,
      "step": 129860
    },
    {
      "epoch": 15.64698795180723,
      "grad_norm": 0.00586708914488554,
      "learning_rate": 4.353012048192771e-06,
      "loss": 0.0131,
      "step": 129870
    },
    {
      "epoch": 15.648192771084338,
      "grad_norm": 0.00022637436632066965,
      "learning_rate": 4.351807228915663e-06,
      "loss": 0.0042,
      "step": 129880
    },
    {
      "epoch": 15.649397590361446,
      "grad_norm": 0.0003114600258413702,
      "learning_rate": 4.3506024096385545e-06,
      "loss": 0.0069,
      "step": 129890
    },
    {
      "epoch": 15.650602409638553,
      "grad_norm": 0.0003258481156080961,
      "learning_rate": 4.349397590361446e-06,
      "loss": 0.0025,
      "step": 129900
    },
    {
      "epoch": 15.651807228915663,
      "grad_norm": 3.841283082962036,
      "learning_rate": 4.348192771084338e-06,
      "loss": 0.0197,
      "step": 129910
    },
    {
      "epoch": 15.653012048192771,
      "grad_norm": 0.0003748174349311739,
      "learning_rate": 4.346987951807229e-06,
      "loss": 0.0068,
      "step": 129920
    },
    {
      "epoch": 15.654216867469879,
      "grad_norm": 0.00013074165326543152,
      "learning_rate": 4.345783132530121e-06,
      "loss": 0.022,
      "step": 129930
    },
    {
      "epoch": 15.655421686746989,
      "grad_norm": 0.0027663367800414562,
      "learning_rate": 4.3445783132530124e-06,
      "loss": 0.0132,
      "step": 129940
    },
    {
      "epoch": 15.656626506024097,
      "grad_norm": 0.00020871913875453174,
      "learning_rate": 4.343373493975904e-06,
      "loss": 0.0041,
      "step": 129950
    },
    {
      "epoch": 15.657831325301204,
      "grad_norm": 0.036099642515182495,
      "learning_rate": 4.342168674698796e-06,
      "loss": 0.0271,
      "step": 129960
    },
    {
      "epoch": 15.659036144578312,
      "grad_norm": 0.11328624188899994,
      "learning_rate": 4.340963855421687e-06,
      "loss": 0.0349,
      "step": 129970
    },
    {
      "epoch": 15.660240963855422,
      "grad_norm": 0.40872907638549805,
      "learning_rate": 4.339759036144579e-06,
      "loss": 0.0311,
      "step": 129980
    },
    {
      "epoch": 15.66144578313253,
      "grad_norm": 0.011989993043243885,
      "learning_rate": 4.33855421686747e-06,
      "loss": 0.0135,
      "step": 129990
    },
    {
      "epoch": 15.662650602409638,
      "grad_norm": 0.07171075791120529,
      "learning_rate": 4.337349397590362e-06,
      "loss": 0.0029,
      "step": 130000
    },
    {
      "epoch": 15.663855421686748,
      "grad_norm": 0.8680991530418396,
      "learning_rate": 4.3361445783132535e-06,
      "loss": 0.0192,
      "step": 130010
    },
    {
      "epoch": 15.665060240963856,
      "grad_norm": 0.002019958570599556,
      "learning_rate": 4.334939759036145e-06,
      "loss": 0.0284,
      "step": 130020
    },
    {
      "epoch": 15.666265060240963,
      "grad_norm": 0.00027538949507288635,
      "learning_rate": 4.333734939759037e-06,
      "loss": 0.008,
      "step": 130030
    },
    {
      "epoch": 15.667469879518073,
      "grad_norm": 0.8980672359466553,
      "learning_rate": 4.332530120481928e-06,
      "loss": 0.0387,
      "step": 130040
    },
    {
      "epoch": 15.668674698795181,
      "grad_norm": 0.000680157623719424,
      "learning_rate": 4.33132530120482e-06,
      "loss": 0.0028,
      "step": 130050
    },
    {
      "epoch": 15.669879518072289,
      "grad_norm": 0.7039728164672852,
      "learning_rate": 4.330120481927711e-06,
      "loss": 0.0392,
      "step": 130060
    },
    {
      "epoch": 15.671084337349397,
      "grad_norm": 0.054445426911115646,
      "learning_rate": 4.328915662650603e-06,
      "loss": 0.0374,
      "step": 130070
    },
    {
      "epoch": 15.672289156626507,
      "grad_norm": 0.023420562967658043,
      "learning_rate": 4.327710843373495e-06,
      "loss": 0.0105,
      "step": 130080
    },
    {
      "epoch": 15.673493975903614,
      "grad_norm": 0.006227485369890928,
      "learning_rate": 4.326506024096385e-06,
      "loss": 0.013,
      "step": 130090
    },
    {
      "epoch": 15.674698795180722,
      "grad_norm": 0.3344564139842987,
      "learning_rate": 4.325301204819278e-06,
      "loss": 0.0103,
      "step": 130100
    },
    {
      "epoch": 15.675903614457832,
      "grad_norm": 1.4502687454223633,
      "learning_rate": 4.324096385542169e-06,
      "loss": 0.0281,
      "step": 130110
    },
    {
      "epoch": 15.67710843373494,
      "grad_norm": 0.00012051821977365762,
      "learning_rate": 4.32289156626506e-06,
      "loss": 0.0086,
      "step": 130120
    },
    {
      "epoch": 15.678313253012048,
      "grad_norm": 0.6749963164329529,
      "learning_rate": 4.321686746987952e-06,
      "loss": 0.0046,
      "step": 130130
    },
    {
      "epoch": 15.679518072289156,
      "grad_norm": 0.6724360585212708,
      "learning_rate": 4.320481927710844e-06,
      "loss": 0.0161,
      "step": 130140
    },
    {
      "epoch": 15.680722891566266,
      "grad_norm": 0.034676630049943924,
      "learning_rate": 4.319277108433736e-06,
      "loss": 0.0135,
      "step": 130150
    },
    {
      "epoch": 15.681927710843373,
      "grad_norm": 0.00044119072845205665,
      "learning_rate": 4.3180722891566265e-06,
      "loss": 0.0106,
      "step": 130160
    },
    {
      "epoch": 15.683132530120481,
      "grad_norm": 0.907829999923706,
      "learning_rate": 4.316867469879518e-06,
      "loss": 0.0105,
      "step": 130170
    },
    {
      "epoch": 15.684337349397591,
      "grad_norm": 0.00034782569855451584,
      "learning_rate": 4.3156626506024105e-06,
      "loss": 0.0029,
      "step": 130180
    },
    {
      "epoch": 15.685542168674699,
      "grad_norm": 0.00022361220908351243,
      "learning_rate": 4.314457831325301e-06,
      "loss": 0.0273,
      "step": 130190
    },
    {
      "epoch": 15.686746987951807,
      "grad_norm": 0.01293330080807209,
      "learning_rate": 4.313253012048193e-06,
      "loss": 0.0614,
      "step": 130200
    },
    {
      "epoch": 15.687951807228917,
      "grad_norm": 0.0037162427324801683,
      "learning_rate": 4.3120481927710845e-06,
      "loss": 0.0039,
      "step": 130210
    },
    {
      "epoch": 15.689156626506024,
      "grad_norm": 1.503671407699585,
      "learning_rate": 4.310843373493976e-06,
      "loss": 0.0132,
      "step": 130220
    },
    {
      "epoch": 15.690361445783132,
      "grad_norm": 0.0015574567951261997,
      "learning_rate": 4.309638554216868e-06,
      "loss": 0.0333,
      "step": 130230
    },
    {
      "epoch": 15.69156626506024,
      "grad_norm": 1.989389181137085,
      "learning_rate": 4.308433734939759e-06,
      "loss": 0.0196,
      "step": 130240
    },
    {
      "epoch": 15.69277108433735,
      "grad_norm": 0.0003220321668777615,
      "learning_rate": 4.307228915662651e-06,
      "loss": 0.0227,
      "step": 130250
    },
    {
      "epoch": 15.693975903614458,
      "grad_norm": 0.0006858762935735285,
      "learning_rate": 4.306024096385542e-06,
      "loss": 0.0306,
      "step": 130260
    },
    {
      "epoch": 15.695180722891566,
      "grad_norm": 0.7674669027328491,
      "learning_rate": 4.304819277108434e-06,
      "loss": 0.0112,
      "step": 130270
    },
    {
      "epoch": 15.696385542168674,
      "grad_norm": 0.762933611869812,
      "learning_rate": 4.3036144578313256e-06,
      "loss": 0.003,
      "step": 130280
    },
    {
      "epoch": 15.697590361445783,
      "grad_norm": 2.019845485687256,
      "learning_rate": 4.302409638554217e-06,
      "loss": 0.0135,
      "step": 130290
    },
    {
      "epoch": 15.698795180722891,
      "grad_norm": 1.3204060792922974,
      "learning_rate": 4.301204819277109e-06,
      "loss": 0.0266,
      "step": 130300
    },
    {
      "epoch": 15.7,
      "grad_norm": 0.10971668362617493,
      "learning_rate": 4.3e-06,
      "loss": 0.0038,
      "step": 130310
    },
    {
      "epoch": 15.701204819277109,
      "grad_norm": 0.474001407623291,
      "learning_rate": 4.298795180722892e-06,
      "loss": 0.0192,
      "step": 130320
    },
    {
      "epoch": 15.702409638554217,
      "grad_norm": 0.012399625033140182,
      "learning_rate": 4.2975903614457835e-06,
      "loss": 0.0245,
      "step": 130330
    },
    {
      "epoch": 15.703614457831325,
      "grad_norm": 0.5781480073928833,
      "learning_rate": 4.296385542168675e-06,
      "loss": 0.0155,
      "step": 130340
    },
    {
      "epoch": 15.704819277108435,
      "grad_norm": 0.0003658775531221181,
      "learning_rate": 4.295180722891567e-06,
      "loss": 0.0323,
      "step": 130350
    },
    {
      "epoch": 15.706024096385542,
      "grad_norm": 0.0002984103048220277,
      "learning_rate": 4.293975903614458e-06,
      "loss": 0.0545,
      "step": 130360
    },
    {
      "epoch": 15.70722891566265,
      "grad_norm": 0.001224649720825255,
      "learning_rate": 4.29277108433735e-06,
      "loss": 0.0086,
      "step": 130370
    },
    {
      "epoch": 15.708433734939758,
      "grad_norm": 0.41617095470428467,
      "learning_rate": 4.2915662650602415e-06,
      "loss": 0.0129,
      "step": 130380
    },
    {
      "epoch": 15.709638554216868,
      "grad_norm": 0.0004151035100221634,
      "learning_rate": 4.290361445783133e-06,
      "loss": 0.0221,
      "step": 130390
    },
    {
      "epoch": 15.710843373493976,
      "grad_norm": 1.2428054809570312,
      "learning_rate": 4.289156626506025e-06,
      "loss": 0.0175,
      "step": 130400
    },
    {
      "epoch": 15.712048192771084,
      "grad_norm": 0.00032883964013308287,
      "learning_rate": 4.287951807228916e-06,
      "loss": 0.0047,
      "step": 130410
    },
    {
      "epoch": 15.713253012048193,
      "grad_norm": 1.2729923725128174,
      "learning_rate": 4.286746987951808e-06,
      "loss": 0.0142,
      "step": 130420
    },
    {
      "epoch": 15.714457831325301,
      "grad_norm": 3.179644823074341,
      "learning_rate": 4.2855421686746985e-06,
      "loss": 0.0383,
      "step": 130430
    },
    {
      "epoch": 15.71566265060241,
      "grad_norm": 0.06668774783611298,
      "learning_rate": 4.284337349397591e-06,
      "loss": 0.0116,
      "step": 130440
    },
    {
      "epoch": 15.716867469879517,
      "grad_norm": 0.2640385925769806,
      "learning_rate": 4.2831325301204826e-06,
      "loss": 0.0046,
      "step": 130450
    },
    {
      "epoch": 15.718072289156627,
      "grad_norm": 0.01708565466105938,
      "learning_rate": 4.281927710843374e-06,
      "loss": 0.0148,
      "step": 130460
    },
    {
      "epoch": 15.719277108433735,
      "grad_norm": 0.042244795709848404,
      "learning_rate": 4.280722891566265e-06,
      "loss": 0.0058,
      "step": 130470
    },
    {
      "epoch": 15.720481927710843,
      "grad_norm": 0.020690392702817917,
      "learning_rate": 4.279518072289157e-06,
      "loss": 0.0103,
      "step": 130480
    },
    {
      "epoch": 15.721686746987952,
      "grad_norm": 0.0004056187754031271,
      "learning_rate": 4.278313253012049e-06,
      "loss": 0.0129,
      "step": 130490
    },
    {
      "epoch": 15.72289156626506,
      "grad_norm": 1.68132483959198,
      "learning_rate": 4.27710843373494e-06,
      "loss": 0.0108,
      "step": 130500
    },
    {
      "epoch": 15.724096385542168,
      "grad_norm": 0.00017377085168845952,
      "learning_rate": 4.275903614457831e-06,
      "loss": 0.0077,
      "step": 130510
    },
    {
      "epoch": 15.725301204819278,
      "grad_norm": 0.00036173738772049546,
      "learning_rate": 4.274698795180724e-06,
      "loss": 0.014,
      "step": 130520
    },
    {
      "epoch": 15.726506024096386,
      "grad_norm": 0.004241088405251503,
      "learning_rate": 4.2734939759036144e-06,
      "loss": 0.0079,
      "step": 130530
    },
    {
      "epoch": 15.727710843373494,
      "grad_norm": 0.00026386306853964925,
      "learning_rate": 4.272289156626506e-06,
      "loss": 0.017,
      "step": 130540
    },
    {
      "epoch": 15.728915662650602,
      "grad_norm": 0.00022658811940345913,
      "learning_rate": 4.2710843373493984e-06,
      "loss": 0.0499,
      "step": 130550
    },
    {
      "epoch": 15.730120481927711,
      "grad_norm": 0.0017991457134485245,
      "learning_rate": 4.26987951807229e-06,
      "loss": 0.0303,
      "step": 130560
    },
    {
      "epoch": 15.73132530120482,
      "grad_norm": 0.00019987535779364407,
      "learning_rate": 4.268674698795181e-06,
      "loss": 0.0036,
      "step": 130570
    },
    {
      "epoch": 15.732530120481927,
      "grad_norm": 1.6918056011199951,
      "learning_rate": 4.267469879518072e-06,
      "loss": 0.0089,
      "step": 130580
    },
    {
      "epoch": 15.733734939759037,
      "grad_norm": 0.3816714584827423,
      "learning_rate": 4.266265060240965e-06,
      "loss": 0.0428,
      "step": 130590
    },
    {
      "epoch": 15.734939759036145,
      "grad_norm": 0.13110189139842987,
      "learning_rate": 4.2650602409638555e-06,
      "loss": 0.0105,
      "step": 130600
    },
    {
      "epoch": 15.736144578313253,
      "grad_norm": 0.4041152596473694,
      "learning_rate": 4.263855421686747e-06,
      "loss": 0.031,
      "step": 130610
    },
    {
      "epoch": 15.73734939759036,
      "grad_norm": 0.004448750987648964,
      "learning_rate": 4.262650602409639e-06,
      "loss": 0.001,
      "step": 130620
    },
    {
      "epoch": 15.73855421686747,
      "grad_norm": 0.00031896395375952125,
      "learning_rate": 4.26144578313253e-06,
      "loss": 0.0027,
      "step": 130630
    },
    {
      "epoch": 15.739759036144578,
      "grad_norm": 0.00025554790045134723,
      "learning_rate": 4.260240963855422e-06,
      "loss": 0.0196,
      "step": 130640
    },
    {
      "epoch": 15.740963855421686,
      "grad_norm": 129.69456481933594,
      "learning_rate": 4.2590361445783135e-06,
      "loss": 0.0197,
      "step": 130650
    },
    {
      "epoch": 15.742168674698796,
      "grad_norm": 0.0022745339665561914,
      "learning_rate": 4.257831325301205e-06,
      "loss": 0.0065,
      "step": 130660
    },
    {
      "epoch": 15.743373493975904,
      "grad_norm": 0.00023012046585790813,
      "learning_rate": 4.256626506024097e-06,
      "loss": 0.0121,
      "step": 130670
    },
    {
      "epoch": 15.744578313253012,
      "grad_norm": 0.005619300529360771,
      "learning_rate": 4.255421686746988e-06,
      "loss": 0.0142,
      "step": 130680
    },
    {
      "epoch": 15.745783132530121,
      "grad_norm": 0.0004980175290256739,
      "learning_rate": 4.25421686746988e-06,
      "loss": 0.0361,
      "step": 130690
    },
    {
      "epoch": 15.74698795180723,
      "grad_norm": 0.03384631499648094,
      "learning_rate": 4.253012048192771e-06,
      "loss": 0.022,
      "step": 130700
    },
    {
      "epoch": 15.748192771084337,
      "grad_norm": 0.027825094759464264,
      "learning_rate": 4.251807228915663e-06,
      "loss": 0.0031,
      "step": 130710
    },
    {
      "epoch": 15.749397590361445,
      "grad_norm": 0.000202395225642249,
      "learning_rate": 4.250602409638555e-06,
      "loss": 0.0059,
      "step": 130720
    },
    {
      "epoch": 15.750602409638555,
      "grad_norm": 0.027187567204236984,
      "learning_rate": 4.249397590361446e-06,
      "loss": 0.0173,
      "step": 130730
    },
    {
      "epoch": 15.751807228915663,
      "grad_norm": 0.0004968531429767609,
      "learning_rate": 4.248192771084338e-06,
      "loss": 0.0057,
      "step": 130740
    },
    {
      "epoch": 15.75301204819277,
      "grad_norm": 0.3500620722770691,
      "learning_rate": 4.246987951807229e-06,
      "loss": 0.0085,
      "step": 130750
    },
    {
      "epoch": 15.754216867469879,
      "grad_norm": 1.3626079559326172,
      "learning_rate": 4.245783132530121e-06,
      "loss": 0.0123,
      "step": 130760
    },
    {
      "epoch": 15.755421686746988,
      "grad_norm": 1.0757473707199097,
      "learning_rate": 4.2445783132530125e-06,
      "loss": 0.0054,
      "step": 130770
    },
    {
      "epoch": 15.756626506024096,
      "grad_norm": 5.671168327331543,
      "learning_rate": 4.243373493975904e-06,
      "loss": 0.0276,
      "step": 130780
    },
    {
      "epoch": 15.757831325301204,
      "grad_norm": 0.000228308723308146,
      "learning_rate": 4.242168674698796e-06,
      "loss": 0.0147,
      "step": 130790
    },
    {
      "epoch": 15.759036144578314,
      "grad_norm": 0.0007054079324007034,
      "learning_rate": 4.240963855421687e-06,
      "loss": 0.0134,
      "step": 130800
    },
    {
      "epoch": 15.760240963855422,
      "grad_norm": 0.0008582459413446486,
      "learning_rate": 4.239759036144578e-06,
      "loss": 0.0066,
      "step": 130810
    },
    {
      "epoch": 15.76144578313253,
      "grad_norm": 0.00014027583529241383,
      "learning_rate": 4.2385542168674705e-06,
      "loss": 0.0211,
      "step": 130820
    },
    {
      "epoch": 15.76265060240964,
      "grad_norm": 4.452704429626465,
      "learning_rate": 4.237349397590362e-06,
      "loss": 0.0421,
      "step": 130830
    },
    {
      "epoch": 15.763855421686747,
      "grad_norm": 6.537221908569336,
      "learning_rate": 4.236144578313253e-06,
      "loss": 0.0444,
      "step": 130840
    },
    {
      "epoch": 15.765060240963855,
      "grad_norm": 0.0005764520028606057,
      "learning_rate": 4.234939759036145e-06,
      "loss": 0.0089,
      "step": 130850
    },
    {
      "epoch": 15.766265060240963,
      "grad_norm": 3.367863178253174,
      "learning_rate": 4.233734939759037e-06,
      "loss": 0.024,
      "step": 130860
    },
    {
      "epoch": 15.767469879518073,
      "grad_norm": 0.5145740509033203,
      "learning_rate": 4.232530120481928e-06,
      "loss": 0.0098,
      "step": 130870
    },
    {
      "epoch": 15.76867469879518,
      "grad_norm": 0.011104000732302666,
      "learning_rate": 4.231325301204819e-06,
      "loss": 0.0131,
      "step": 130880
    },
    {
      "epoch": 15.769879518072289,
      "grad_norm": 0.0035441413056105375,
      "learning_rate": 4.230120481927712e-06,
      "loss": 0.0077,
      "step": 130890
    },
    {
      "epoch": 15.771084337349398,
      "grad_norm": 0.00034769828198477626,
      "learning_rate": 4.228915662650603e-06,
      "loss": 0.0208,
      "step": 130900
    },
    {
      "epoch": 15.772289156626506,
      "grad_norm": 0.7157968282699585,
      "learning_rate": 4.227710843373494e-06,
      "loss": 0.0198,
      "step": 130910
    },
    {
      "epoch": 15.773493975903614,
      "grad_norm": 1.1387284994125366,
      "learning_rate": 4.2265060240963855e-06,
      "loss": 0.0516,
      "step": 130920
    },
    {
      "epoch": 15.774698795180722,
      "grad_norm": 0.0004988709697499871,
      "learning_rate": 4.225301204819278e-06,
      "loss": 0.0142,
      "step": 130930
    },
    {
      "epoch": 15.775903614457832,
      "grad_norm": 0.010040934197604656,
      "learning_rate": 4.224096385542169e-06,
      "loss": 0.0234,
      "step": 130940
    },
    {
      "epoch": 15.77710843373494,
      "grad_norm": 0.0007439847686327994,
      "learning_rate": 4.22289156626506e-06,
      "loss": 0.0261,
      "step": 130950
    },
    {
      "epoch": 15.778313253012048,
      "grad_norm": 0.0016827465733513236,
      "learning_rate": 4.221686746987952e-06,
      "loss": 0.0158,
      "step": 130960
    },
    {
      "epoch": 15.779518072289157,
      "grad_norm": 0.0022446014918386936,
      "learning_rate": 4.2204819277108434e-06,
      "loss": 0.0114,
      "step": 130970
    },
    {
      "epoch": 15.780722891566265,
      "grad_norm": 0.012505589984357357,
      "learning_rate": 4.219277108433735e-06,
      "loss": 0.0118,
      "step": 130980
    },
    {
      "epoch": 15.781927710843373,
      "grad_norm": 0.0019030096009373665,
      "learning_rate": 4.218072289156627e-06,
      "loss": 0.0049,
      "step": 130990
    },
    {
      "epoch": 15.783132530120483,
      "grad_norm": 0.006523974239826202,
      "learning_rate": 4.216867469879519e-06,
      "loss": 0.0097,
      "step": 131000
    },
    {
      "epoch": 15.78433734939759,
      "grad_norm": 0.3623100817203522,
      "learning_rate": 4.21566265060241e-06,
      "loss": 0.0023,
      "step": 131010
    },
    {
      "epoch": 15.785542168674699,
      "grad_norm": 0.0031932033598423004,
      "learning_rate": 4.214457831325301e-06,
      "loss": 0.0032,
      "step": 131020
    },
    {
      "epoch": 15.786746987951807,
      "grad_norm": 1.0774835348129272,
      "learning_rate": 4.213253012048193e-06,
      "loss": 0.003,
      "step": 131030
    },
    {
      "epoch": 15.787951807228916,
      "grad_norm": 0.0025058879982680082,
      "learning_rate": 4.2120481927710846e-06,
      "loss": 0.0026,
      "step": 131040
    },
    {
      "epoch": 15.789156626506024,
      "grad_norm": 0.0032711876556277275,
      "learning_rate": 4.210843373493976e-06,
      "loss": 0.0082,
      "step": 131050
    },
    {
      "epoch": 15.790361445783132,
      "grad_norm": 0.00025965890381485224,
      "learning_rate": 4.209638554216868e-06,
      "loss": 0.0286,
      "step": 131060
    },
    {
      "epoch": 15.791566265060242,
      "grad_norm": 0.0002725269878283143,
      "learning_rate": 4.208433734939759e-06,
      "loss": 0.0093,
      "step": 131070
    },
    {
      "epoch": 15.79277108433735,
      "grad_norm": 0.2091580331325531,
      "learning_rate": 4.207228915662651e-06,
      "loss": 0.0299,
      "step": 131080
    },
    {
      "epoch": 15.793975903614458,
      "grad_norm": 1.0684689283370972,
      "learning_rate": 4.2060240963855425e-06,
      "loss": 0.0147,
      "step": 131090
    },
    {
      "epoch": 15.795180722891565,
      "grad_norm": 0.0018031626241281629,
      "learning_rate": 4.204819277108434e-06,
      "loss": 0.0242,
      "step": 131100
    },
    {
      "epoch": 15.796385542168675,
      "grad_norm": 0.00034694428904913366,
      "learning_rate": 4.203614457831326e-06,
      "loss": 0.02,
      "step": 131110
    },
    {
      "epoch": 15.797590361445783,
      "grad_norm": 0.021025197580456734,
      "learning_rate": 4.202409638554217e-06,
      "loss": 0.0145,
      "step": 131120
    },
    {
      "epoch": 15.798795180722891,
      "grad_norm": 0.0015361238038167357,
      "learning_rate": 4.201204819277109e-06,
      "loss": 0.0337,
      "step": 131130
    },
    {
      "epoch": 15.8,
      "grad_norm": 0.028292961418628693,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0084,
      "step": 131140
    },
    {
      "epoch": 15.801204819277109,
      "grad_norm": 0.1227162554860115,
      "learning_rate": 4.198795180722892e-06,
      "loss": 0.0097,
      "step": 131150
    },
    {
      "epoch": 15.802409638554217,
      "grad_norm": 0.885794460773468,
      "learning_rate": 4.197590361445784e-06,
      "loss": 0.0077,
      "step": 131160
    },
    {
      "epoch": 15.803614457831326,
      "grad_norm": 0.0006233452586457133,
      "learning_rate": 4.196385542168675e-06,
      "loss": 0.0212,
      "step": 131170
    },
    {
      "epoch": 15.804819277108434,
      "grad_norm": 0.010790578089654446,
      "learning_rate": 4.195180722891567e-06,
      "loss": 0.0147,
      "step": 131180
    },
    {
      "epoch": 15.806024096385542,
      "grad_norm": 0.001733167446218431,
      "learning_rate": 4.193975903614458e-06,
      "loss": 0.0041,
      "step": 131190
    },
    {
      "epoch": 15.80722891566265,
      "grad_norm": 1.6331779956817627,
      "learning_rate": 4.19277108433735e-06,
      "loss": 0.0071,
      "step": 131200
    },
    {
      "epoch": 15.80843373493976,
      "grad_norm": 0.0691157653927803,
      "learning_rate": 4.1915662650602416e-06,
      "loss": 0.031,
      "step": 131210
    },
    {
      "epoch": 15.809638554216868,
      "grad_norm": 0.8591455817222595,
      "learning_rate": 4.190361445783132e-06,
      "loss": 0.0196,
      "step": 131220
    },
    {
      "epoch": 15.810843373493976,
      "grad_norm": 0.07098440825939178,
      "learning_rate": 4.189156626506025e-06,
      "loss": 0.0225,
      "step": 131230
    },
    {
      "epoch": 15.812048192771083,
      "grad_norm": 0.002554170787334442,
      "learning_rate": 4.187951807228916e-06,
      "loss": 0.0126,
      "step": 131240
    },
    {
      "epoch": 15.813253012048193,
      "grad_norm": 1.064889907836914,
      "learning_rate": 4.186746987951807e-06,
      "loss": 0.0221,
      "step": 131250
    },
    {
      "epoch": 15.814457831325301,
      "grad_norm": 0.00224634469486773,
      "learning_rate": 4.185542168674699e-06,
      "loss": 0.0151,
      "step": 131260
    },
    {
      "epoch": 15.815662650602409,
      "grad_norm": 0.00021968234796077013,
      "learning_rate": 4.184337349397591e-06,
      "loss": 0.0126,
      "step": 131270
    },
    {
      "epoch": 15.816867469879519,
      "grad_norm": 0.25567880272865295,
      "learning_rate": 4.183132530120483e-06,
      "loss": 0.0174,
      "step": 131280
    },
    {
      "epoch": 15.818072289156627,
      "grad_norm": 0.33719566464424133,
      "learning_rate": 4.181927710843373e-06,
      "loss": 0.0387,
      "step": 131290
    },
    {
      "epoch": 15.819277108433734,
      "grad_norm": 0.035001859068870544,
      "learning_rate": 4.180722891566266e-06,
      "loss": 0.0221,
      "step": 131300
    },
    {
      "epoch": 15.820481927710844,
      "grad_norm": 0.0005291916895657778,
      "learning_rate": 4.1795180722891574e-06,
      "loss": 0.0196,
      "step": 131310
    },
    {
      "epoch": 15.821686746987952,
      "grad_norm": 0.00404152600094676,
      "learning_rate": 4.178313253012048e-06,
      "loss": 0.0027,
      "step": 131320
    },
    {
      "epoch": 15.82289156626506,
      "grad_norm": 0.0007471719291061163,
      "learning_rate": 4.17710843373494e-06,
      "loss": 0.006,
      "step": 131330
    },
    {
      "epoch": 15.824096385542168,
      "grad_norm": 0.0001940533984452486,
      "learning_rate": 4.175903614457832e-06,
      "loss": 0.0026,
      "step": 131340
    },
    {
      "epoch": 15.825301204819278,
      "grad_norm": 0.41894370317459106,
      "learning_rate": 4.174698795180723e-06,
      "loss": 0.0062,
      "step": 131350
    },
    {
      "epoch": 15.826506024096386,
      "grad_norm": 0.00016572853201068938,
      "learning_rate": 4.1734939759036145e-06,
      "loss": 0.0,
      "step": 131360
    },
    {
      "epoch": 15.827710843373493,
      "grad_norm": 0.0012313274201005697,
      "learning_rate": 4.172289156626506e-06,
      "loss": 0.0286,
      "step": 131370
    },
    {
      "epoch": 15.828915662650603,
      "grad_norm": 0.09595999866724014,
      "learning_rate": 4.171084337349398e-06,
      "loss": 0.0399,
      "step": 131380
    },
    {
      "epoch": 15.830120481927711,
      "grad_norm": 0.009896391071379185,
      "learning_rate": 4.169879518072289e-06,
      "loss": 0.0217,
      "step": 131390
    },
    {
      "epoch": 15.831325301204819,
      "grad_norm": 0.9868324398994446,
      "learning_rate": 4.168674698795181e-06,
      "loss": 0.0168,
      "step": 131400
    },
    {
      "epoch": 15.832530120481927,
      "grad_norm": 0.00043599450145848095,
      "learning_rate": 4.1674698795180725e-06,
      "loss": 0.0097,
      "step": 131410
    },
    {
      "epoch": 15.833734939759037,
      "grad_norm": 0.22951246798038483,
      "learning_rate": 4.166265060240964e-06,
      "loss": 0.0071,
      "step": 131420
    },
    {
      "epoch": 15.834939759036144,
      "grad_norm": 0.012419266626238823,
      "learning_rate": 4.165060240963856e-06,
      "loss": 0.0093,
      "step": 131430
    },
    {
      "epoch": 15.836144578313252,
      "grad_norm": 0.00020139649859629571,
      "learning_rate": 4.163855421686747e-06,
      "loss": 0.0244,
      "step": 131440
    },
    {
      "epoch": 15.837349397590362,
      "grad_norm": 1.2255529165267944,
      "learning_rate": 4.162650602409639e-06,
      "loss": 0.0215,
      "step": 131450
    },
    {
      "epoch": 15.83855421686747,
      "grad_norm": 0.01357022114098072,
      "learning_rate": 4.16144578313253e-06,
      "loss": 0.0219,
      "step": 131460
    },
    {
      "epoch": 15.839759036144578,
      "grad_norm": 0.00046995258890092373,
      "learning_rate": 4.160240963855422e-06,
      "loss": 0.0142,
      "step": 131470
    },
    {
      "epoch": 15.840963855421688,
      "grad_norm": 1.34456467628479,
      "learning_rate": 4.159036144578314e-06,
      "loss": 0.0091,
      "step": 131480
    },
    {
      "epoch": 15.842168674698796,
      "grad_norm": 0.00038364980719052255,
      "learning_rate": 4.157831325301205e-06,
      "loss": 0.0167,
      "step": 131490
    },
    {
      "epoch": 15.843373493975903,
      "grad_norm": 0.28984925150871277,
      "learning_rate": 4.156626506024097e-06,
      "loss": 0.0206,
      "step": 131500
    },
    {
      "epoch": 15.844578313253011,
      "grad_norm": 0.001811794238165021,
      "learning_rate": 4.155421686746988e-06,
      "loss": 0.0008,
      "step": 131510
    },
    {
      "epoch": 15.845783132530121,
      "grad_norm": 0.002615307690575719,
      "learning_rate": 4.15421686746988e-06,
      "loss": 0.0055,
      "step": 131520
    },
    {
      "epoch": 15.846987951807229,
      "grad_norm": 4.201888084411621,
      "learning_rate": 4.1530120481927715e-06,
      "loss": 0.0183,
      "step": 131530
    },
    {
      "epoch": 15.848192771084337,
      "grad_norm": 0.0025125208776444197,
      "learning_rate": 4.151807228915663e-06,
      "loss": 0.0385,
      "step": 131540
    },
    {
      "epoch": 15.849397590361447,
      "grad_norm": 0.0007437304011546075,
      "learning_rate": 4.150602409638555e-06,
      "loss": 0.006,
      "step": 131550
    },
    {
      "epoch": 15.850602409638554,
      "grad_norm": 0.015269920229911804,
      "learning_rate": 4.1493975903614454e-06,
      "loss": 0.0142,
      "step": 131560
    },
    {
      "epoch": 15.851807228915662,
      "grad_norm": 0.00040393712697550654,
      "learning_rate": 4.148192771084338e-06,
      "loss": 0.0035,
      "step": 131570
    },
    {
      "epoch": 15.85301204819277,
      "grad_norm": 0.000493390136398375,
      "learning_rate": 4.1469879518072295e-06,
      "loss": 0.0246,
      "step": 131580
    },
    {
      "epoch": 15.85421686746988,
      "grad_norm": 0.0002490725019015372,
      "learning_rate": 4.145783132530121e-06,
      "loss": 0.0411,
      "step": 131590
    },
    {
      "epoch": 15.855421686746988,
      "grad_norm": 0.0009857516270130873,
      "learning_rate": 4.144578313253013e-06,
      "loss": 0.0054,
      "step": 131600
    },
    {
      "epoch": 15.856626506024096,
      "grad_norm": 0.0011208648793399334,
      "learning_rate": 4.143373493975904e-06,
      "loss": 0.0054,
      "step": 131610
    },
    {
      "epoch": 15.857831325301206,
      "grad_norm": 0.7897273898124695,
      "learning_rate": 4.142168674698796e-06,
      "loss": 0.0089,
      "step": 131620
    },
    {
      "epoch": 15.859036144578313,
      "grad_norm": 0.00039527344051748514,
      "learning_rate": 4.1409638554216866e-06,
      "loss": 0.0185,
      "step": 131630
    },
    {
      "epoch": 15.860240963855421,
      "grad_norm": 0.0010020716581493616,
      "learning_rate": 4.139759036144579e-06,
      "loss": 0.0147,
      "step": 131640
    },
    {
      "epoch": 15.861445783132531,
      "grad_norm": 0.00041463703382760286,
      "learning_rate": 4.138554216867471e-06,
      "loss": 0.0042,
      "step": 131650
    },
    {
      "epoch": 15.862650602409639,
      "grad_norm": 0.0019036589656025171,
      "learning_rate": 4.137349397590361e-06,
      "loss": 0.0053,
      "step": 131660
    },
    {
      "epoch": 15.863855421686747,
      "grad_norm": 0.00028135409229435027,
      "learning_rate": 4.136144578313253e-06,
      "loss": 0.0183,
      "step": 131670
    },
    {
      "epoch": 15.865060240963855,
      "grad_norm": 0.0006765450816601515,
      "learning_rate": 4.134939759036145e-06,
      "loss": 0.0122,
      "step": 131680
    },
    {
      "epoch": 15.866265060240965,
      "grad_norm": 0.8000934720039368,
      "learning_rate": 4.133734939759036e-06,
      "loss": 0.0059,
      "step": 131690
    },
    {
      "epoch": 15.867469879518072,
      "grad_norm": 0.0019801666494458914,
      "learning_rate": 4.132530120481928e-06,
      "loss": 0.0084,
      "step": 131700
    },
    {
      "epoch": 15.86867469879518,
      "grad_norm": 0.0037556919269263744,
      "learning_rate": 4.131325301204819e-06,
      "loss": 0.0067,
      "step": 131710
    },
    {
      "epoch": 15.869879518072288,
      "grad_norm": 0.0016074985032901168,
      "learning_rate": 4.130120481927712e-06,
      "loss": 0.0133,
      "step": 131720
    },
    {
      "epoch": 15.871084337349398,
      "grad_norm": 0.5990244746208191,
      "learning_rate": 4.1289156626506024e-06,
      "loss": 0.0099,
      "step": 131730
    },
    {
      "epoch": 15.872289156626506,
      "grad_norm": 0.0005749069387093186,
      "learning_rate": 4.127710843373494e-06,
      "loss": 0.0254,
      "step": 131740
    },
    {
      "epoch": 15.873493975903614,
      "grad_norm": 0.0010192150948569179,
      "learning_rate": 4.1265060240963865e-06,
      "loss": 0.0048,
      "step": 131750
    },
    {
      "epoch": 15.874698795180723,
      "grad_norm": 0.0052172779105603695,
      "learning_rate": 4.125301204819277e-06,
      "loss": 0.0067,
      "step": 131760
    },
    {
      "epoch": 15.875903614457831,
      "grad_norm": 0.0005432562902569771,
      "learning_rate": 4.124096385542169e-06,
      "loss": 0.0206,
      "step": 131770
    },
    {
      "epoch": 15.87710843373494,
      "grad_norm": 1.6785142421722412,
      "learning_rate": 4.12289156626506e-06,
      "loss": 0.0102,
      "step": 131780
    },
    {
      "epoch": 15.878313253012049,
      "grad_norm": 0.00044266198528930545,
      "learning_rate": 4.121686746987952e-06,
      "loss": 0.0084,
      "step": 131790
    },
    {
      "epoch": 15.879518072289157,
      "grad_norm": 0.00039207059307955205,
      "learning_rate": 4.1204819277108436e-06,
      "loss": 0.002,
      "step": 131800
    },
    {
      "epoch": 15.880722891566265,
      "grad_norm": 1.5076371431350708,
      "learning_rate": 4.119277108433735e-06,
      "loss": 0.0086,
      "step": 131810
    },
    {
      "epoch": 15.881927710843373,
      "grad_norm": 0.9490071535110474,
      "learning_rate": 4.118072289156627e-06,
      "loss": 0.0146,
      "step": 131820
    },
    {
      "epoch": 15.883132530120482,
      "grad_norm": 0.00021737765928264707,
      "learning_rate": 4.116867469879518e-06,
      "loss": 0.0098,
      "step": 131830
    },
    {
      "epoch": 15.88433734939759,
      "grad_norm": 0.00014885935524944216,
      "learning_rate": 4.11566265060241e-06,
      "loss": 0.0006,
      "step": 131840
    },
    {
      "epoch": 15.885542168674698,
      "grad_norm": 0.0015932460082694888,
      "learning_rate": 4.1144578313253015e-06,
      "loss": 0.0097,
      "step": 131850
    },
    {
      "epoch": 15.886746987951808,
      "grad_norm": 0.10381513088941574,
      "learning_rate": 4.113253012048193e-06,
      "loss": 0.0138,
      "step": 131860
    },
    {
      "epoch": 15.887951807228916,
      "grad_norm": 0.0006617383332923055,
      "learning_rate": 4.112048192771085e-06,
      "loss": 0.0041,
      "step": 131870
    },
    {
      "epoch": 15.889156626506024,
      "grad_norm": 0.069936603307724,
      "learning_rate": 4.110843373493976e-06,
      "loss": 0.0552,
      "step": 131880
    },
    {
      "epoch": 15.890361445783132,
      "grad_norm": 0.04422948509454727,
      "learning_rate": 4.109638554216868e-06,
      "loss": 0.027,
      "step": 131890
    },
    {
      "epoch": 15.891566265060241,
      "grad_norm": 0.40257757902145386,
      "learning_rate": 4.1084337349397594e-06,
      "loss": 0.0101,
      "step": 131900
    },
    {
      "epoch": 15.89277108433735,
      "grad_norm": 0.0006256003398448229,
      "learning_rate": 4.107228915662651e-06,
      "loss": 0.015,
      "step": 131910
    },
    {
      "epoch": 15.893975903614457,
      "grad_norm": 0.001481179497204721,
      "learning_rate": 4.106024096385543e-06,
      "loss": 0.0027,
      "step": 131920
    },
    {
      "epoch": 15.895180722891567,
      "grad_norm": 1.0751904249191284,
      "learning_rate": 4.104819277108434e-06,
      "loss": 0.0543,
      "step": 131930
    },
    {
      "epoch": 15.896385542168675,
      "grad_norm": 0.0009171710698865354,
      "learning_rate": 4.103614457831326e-06,
      "loss": 0.0225,
      "step": 131940
    },
    {
      "epoch": 15.897590361445783,
      "grad_norm": 0.0007950740400701761,
      "learning_rate": 4.102409638554217e-06,
      "loss": 0.0262,
      "step": 131950
    },
    {
      "epoch": 15.898795180722892,
      "grad_norm": 0.0033494241070002317,
      "learning_rate": 4.101204819277109e-06,
      "loss": 0.0061,
      "step": 131960
    },
    {
      "epoch": 15.9,
      "grad_norm": 0.002795700915157795,
      "learning_rate": 4.1e-06,
      "loss": 0.0076,
      "step": 131970
    },
    {
      "epoch": 15.901204819277108,
      "grad_norm": 1.1662299633026123,
      "learning_rate": 4.098795180722892e-06,
      "loss": 0.0108,
      "step": 131980
    },
    {
      "epoch": 15.902409638554216,
      "grad_norm": 0.41093528270721436,
      "learning_rate": 4.097590361445784e-06,
      "loss": 0.006,
      "step": 131990
    },
    {
      "epoch": 15.903614457831326,
      "grad_norm": 0.5450164675712585,
      "learning_rate": 4.096385542168675e-06,
      "loss": 0.0129,
      "step": 132000
    },
    {
      "epoch": 15.904819277108434,
      "grad_norm": 0.03662443906068802,
      "learning_rate": 4.095180722891567e-06,
      "loss": 0.0101,
      "step": 132010
    },
    {
      "epoch": 15.906024096385542,
      "grad_norm": 1.4695160388946533,
      "learning_rate": 4.0939759036144585e-06,
      "loss": 0.0101,
      "step": 132020
    },
    {
      "epoch": 15.907228915662651,
      "grad_norm": 1.6470366716384888,
      "learning_rate": 4.09277108433735e-06,
      "loss": 0.0142,
      "step": 132030
    },
    {
      "epoch": 15.90843373493976,
      "grad_norm": 1.513320803642273,
      "learning_rate": 4.091566265060241e-06,
      "loss": 0.0164,
      "step": 132040
    },
    {
      "epoch": 15.909638554216867,
      "grad_norm": 0.0018996719736605883,
      "learning_rate": 4.090361445783133e-06,
      "loss": 0.0096,
      "step": 132050
    },
    {
      "epoch": 15.910843373493975,
      "grad_norm": 0.3166877031326294,
      "learning_rate": 4.089156626506025e-06,
      "loss": 0.0215,
      "step": 132060
    },
    {
      "epoch": 15.912048192771085,
      "grad_norm": 0.0008852682658471167,
      "learning_rate": 4.087951807228916e-06,
      "loss": 0.0014,
      "step": 132070
    },
    {
      "epoch": 15.913253012048193,
      "grad_norm": 0.0014070342294871807,
      "learning_rate": 4.086746987951807e-06,
      "loss": 0.0238,
      "step": 132080
    },
    {
      "epoch": 15.9144578313253,
      "grad_norm": 0.0016443149652332067,
      "learning_rate": 4.0855421686747e-06,
      "loss": 0.0177,
      "step": 132090
    },
    {
      "epoch": 15.91566265060241,
      "grad_norm": 1.2017024755477905,
      "learning_rate": 4.08433734939759e-06,
      "loss": 0.0123,
      "step": 132100
    },
    {
      "epoch": 15.916867469879518,
      "grad_norm": 0.0007959867944009602,
      "learning_rate": 4.083132530120482e-06,
      "loss": 0.0037,
      "step": 132110
    },
    {
      "epoch": 15.918072289156626,
      "grad_norm": 0.00042686870438046753,
      "learning_rate": 4.0819277108433735e-06,
      "loss": 0.0234,
      "step": 132120
    },
    {
      "epoch": 15.919277108433734,
      "grad_norm": 0.21083346009254456,
      "learning_rate": 4.080722891566266e-06,
      "loss": 0.0015,
      "step": 132130
    },
    {
      "epoch": 15.920481927710844,
      "grad_norm": 2.663566827774048,
      "learning_rate": 4.079518072289157e-06,
      "loss": 0.0203,
      "step": 132140
    },
    {
      "epoch": 15.921686746987952,
      "grad_norm": 0.10657839477062225,
      "learning_rate": 4.078313253012048e-06,
      "loss": 0.0075,
      "step": 132150
    },
    {
      "epoch": 15.92289156626506,
      "grad_norm": 0.38534876704216003,
      "learning_rate": 4.077108433734941e-06,
      "loss": 0.0045,
      "step": 132160
    },
    {
      "epoch": 15.92409638554217,
      "grad_norm": 0.03230820223689079,
      "learning_rate": 4.0759036144578315e-06,
      "loss": 0.0024,
      "step": 132170
    },
    {
      "epoch": 15.925301204819277,
      "grad_norm": 0.00041351799154654145,
      "learning_rate": 4.074698795180723e-06,
      "loss": 0.0409,
      "step": 132180
    },
    {
      "epoch": 15.926506024096385,
      "grad_norm": 0.0004968440625816584,
      "learning_rate": 4.073493975903615e-06,
      "loss": 0.0076,
      "step": 132190
    },
    {
      "epoch": 15.927710843373493,
      "grad_norm": 0.0004576967912726104,
      "learning_rate": 4.072289156626506e-06,
      "loss": 0.0089,
      "step": 132200
    },
    {
      "epoch": 15.928915662650603,
      "grad_norm": 1.8828015327453613,
      "learning_rate": 4.071084337349398e-06,
      "loss": 0.0386,
      "step": 132210
    },
    {
      "epoch": 15.93012048192771,
      "grad_norm": 0.0005293780122883618,
      "learning_rate": 4.069879518072289e-06,
      "loss": 0.0053,
      "step": 132220
    },
    {
      "epoch": 15.931325301204819,
      "grad_norm": 0.24011792242527008,
      "learning_rate": 4.068674698795181e-06,
      "loss": 0.0126,
      "step": 132230
    },
    {
      "epoch": 15.932530120481928,
      "grad_norm": 0.18668973445892334,
      "learning_rate": 4.067469879518073e-06,
      "loss": 0.0321,
      "step": 132240
    },
    {
      "epoch": 15.933734939759036,
      "grad_norm": 1.2426116466522217,
      "learning_rate": 4.066265060240964e-06,
      "loss": 0.0343,
      "step": 132250
    },
    {
      "epoch": 15.934939759036144,
      "grad_norm": 0.0003044652403332293,
      "learning_rate": 4.065060240963856e-06,
      "loss": 0.0101,
      "step": 132260
    },
    {
      "epoch": 15.936144578313254,
      "grad_norm": 0.0002742962387856096,
      "learning_rate": 4.063855421686747e-06,
      "loss": 0.0148,
      "step": 132270
    },
    {
      "epoch": 15.937349397590362,
      "grad_norm": 0.793062686920166,
      "learning_rate": 4.062650602409639e-06,
      "loss": 0.0169,
      "step": 132280
    },
    {
      "epoch": 15.93855421686747,
      "grad_norm": 0.0010520049836486578,
      "learning_rate": 4.0614457831325305e-06,
      "loss": 0.0211,
      "step": 132290
    },
    {
      "epoch": 15.939759036144578,
      "grad_norm": 0.0006695398478768766,
      "learning_rate": 4.060240963855422e-06,
      "loss": 0.0075,
      "step": 132300
    },
    {
      "epoch": 15.940963855421687,
      "grad_norm": 0.0413067527115345,
      "learning_rate": 4.059036144578314e-06,
      "loss": 0.0012,
      "step": 132310
    },
    {
      "epoch": 15.942168674698795,
      "grad_norm": 0.02878544293344021,
      "learning_rate": 4.057831325301205e-06,
      "loss": 0.0005,
      "step": 132320
    },
    {
      "epoch": 15.943373493975903,
      "grad_norm": 0.00043807909241877496,
      "learning_rate": 4.056626506024097e-06,
      "loss": 0.0133,
      "step": 132330
    },
    {
      "epoch": 15.944578313253013,
      "grad_norm": 0.0008458453230559826,
      "learning_rate": 4.0554216867469885e-06,
      "loss": 0.0114,
      "step": 132340
    },
    {
      "epoch": 15.94578313253012,
      "grad_norm": 1.0560446977615356,
      "learning_rate": 4.05421686746988e-06,
      "loss": 0.0199,
      "step": 132350
    },
    {
      "epoch": 15.946987951807229,
      "grad_norm": 0.9269154667854309,
      "learning_rate": 4.053012048192772e-06,
      "loss": 0.0121,
      "step": 132360
    },
    {
      "epoch": 15.948192771084337,
      "grad_norm": 1.3571183681488037,
      "learning_rate": 4.051807228915663e-06,
      "loss": 0.0046,
      "step": 132370
    },
    {
      "epoch": 15.949397590361446,
      "grad_norm": 1.1377450227737427,
      "learning_rate": 4.050602409638554e-06,
      "loss": 0.0465,
      "step": 132380
    },
    {
      "epoch": 15.950602409638554,
      "grad_norm": 1.0210785865783691,
      "learning_rate": 4.049397590361446e-06,
      "loss": 0.0199,
      "step": 132390
    },
    {
      "epoch": 15.951807228915662,
      "grad_norm": 0.0007240973063744605,
      "learning_rate": 4.048192771084338e-06,
      "loss": 0.0103,
      "step": 132400
    },
    {
      "epoch": 15.953012048192772,
      "grad_norm": 0.0009954433189705014,
      "learning_rate": 4.046987951807229e-06,
      "loss": 0.0186,
      "step": 132410
    },
    {
      "epoch": 15.95421686746988,
      "grad_norm": 0.7209017276763916,
      "learning_rate": 4.04578313253012e-06,
      "loss": 0.0069,
      "step": 132420
    },
    {
      "epoch": 15.955421686746988,
      "grad_norm": 0.0010450811823830009,
      "learning_rate": 4.044578313253013e-06,
      "loss": 0.025,
      "step": 132430
    },
    {
      "epoch": 15.956626506024097,
      "grad_norm": 0.012926975265145302,
      "learning_rate": 4.043373493975904e-06,
      "loss": 0.0002,
      "step": 132440
    },
    {
      "epoch": 15.957831325301205,
      "grad_norm": 0.0016396855935454369,
      "learning_rate": 4.042168674698795e-06,
      "loss": 0.0277,
      "step": 132450
    },
    {
      "epoch": 15.959036144578313,
      "grad_norm": 0.0008540205308236182,
      "learning_rate": 4.0409638554216875e-06,
      "loss": 0.0043,
      "step": 132460
    },
    {
      "epoch": 15.960240963855421,
      "grad_norm": 0.019654899835586548,
      "learning_rate": 4.039759036144579e-06,
      "loss": 0.0021,
      "step": 132470
    },
    {
      "epoch": 15.96144578313253,
      "grad_norm": 0.7124711275100708,
      "learning_rate": 4.03855421686747e-06,
      "loss": 0.0506,
      "step": 132480
    },
    {
      "epoch": 15.962650602409639,
      "grad_norm": 0.0007035903399810195,
      "learning_rate": 4.0373493975903614e-06,
      "loss": 0.0035,
      "step": 132490
    },
    {
      "epoch": 15.963855421686747,
      "grad_norm": 0.0016369572840631008,
      "learning_rate": 4.036144578313254e-06,
      "loss": 0.0118,
      "step": 132500
    },
    {
      "epoch": 15.965060240963856,
      "grad_norm": 0.0003816703101620078,
      "learning_rate": 4.034939759036145e-06,
      "loss": 0.0423,
      "step": 132510
    },
    {
      "epoch": 15.966265060240964,
      "grad_norm": 0.01923789083957672,
      "learning_rate": 4.033734939759036e-06,
      "loss": 0.0201,
      "step": 132520
    },
    {
      "epoch": 15.967469879518072,
      "grad_norm": 0.03528503701090813,
      "learning_rate": 4.032530120481928e-06,
      "loss": 0.0073,
      "step": 132530
    },
    {
      "epoch": 15.96867469879518,
      "grad_norm": 0.0015267777489498258,
      "learning_rate": 4.031325301204819e-06,
      "loss": 0.0062,
      "step": 132540
    },
    {
      "epoch": 15.96987951807229,
      "grad_norm": 0.003034435911104083,
      "learning_rate": 4.030120481927711e-06,
      "loss": 0.0088,
      "step": 132550
    },
    {
      "epoch": 15.971084337349398,
      "grad_norm": 0.002437744988128543,
      "learning_rate": 4.0289156626506026e-06,
      "loss": 0.027,
      "step": 132560
    },
    {
      "epoch": 15.972289156626506,
      "grad_norm": 0.0012504600454121828,
      "learning_rate": 4.027710843373494e-06,
      "loss": 0.0031,
      "step": 132570
    },
    {
      "epoch": 15.973493975903615,
      "grad_norm": 0.0034189436119049788,
      "learning_rate": 4.026506024096386e-06,
      "loss": 0.0083,
      "step": 132580
    },
    {
      "epoch": 15.974698795180723,
      "grad_norm": 0.0008601162116974592,
      "learning_rate": 4.025301204819277e-06,
      "loss": 0.0153,
      "step": 132590
    },
    {
      "epoch": 15.975903614457831,
      "grad_norm": 1.3893392086029053,
      "learning_rate": 4.024096385542169e-06,
      "loss": 0.0175,
      "step": 132600
    },
    {
      "epoch": 15.977108433734939,
      "grad_norm": 0.000905829481780529,
      "learning_rate": 4.0228915662650605e-06,
      "loss": 0.0085,
      "step": 132610
    },
    {
      "epoch": 15.978313253012049,
      "grad_norm": 0.13678990304470062,
      "learning_rate": 4.021686746987952e-06,
      "loss": 0.0247,
      "step": 132620
    },
    {
      "epoch": 15.979518072289157,
      "grad_norm": 0.7577195763587952,
      "learning_rate": 4.020481927710844e-06,
      "loss": 0.0104,
      "step": 132630
    },
    {
      "epoch": 15.980722891566264,
      "grad_norm": 0.5525339245796204,
      "learning_rate": 4.019277108433735e-06,
      "loss": 0.0122,
      "step": 132640
    },
    {
      "epoch": 15.981927710843374,
      "grad_norm": 0.00044993069604970515,
      "learning_rate": 4.018072289156627e-06,
      "loss": 0.0052,
      "step": 132650
    },
    {
      "epoch": 15.983132530120482,
      "grad_norm": 0.5822692513465881,
      "learning_rate": 4.0168674698795184e-06,
      "loss": 0.0071,
      "step": 132660
    },
    {
      "epoch": 15.98433734939759,
      "grad_norm": 3.2505249977111816,
      "learning_rate": 4.01566265060241e-06,
      "loss": 0.0379,
      "step": 132670
    },
    {
      "epoch": 15.985542168674698,
      "grad_norm": 0.0006027360795997083,
      "learning_rate": 4.014457831325302e-06,
      "loss": 0.0177,
      "step": 132680
    },
    {
      "epoch": 15.986746987951808,
      "grad_norm": 0.000829530821647495,
      "learning_rate": 4.013253012048193e-06,
      "loss": 0.0013,
      "step": 132690
    },
    {
      "epoch": 15.987951807228916,
      "grad_norm": 0.0022555470932275057,
      "learning_rate": 4.012048192771085e-06,
      "loss": 0.0152,
      "step": 132700
    },
    {
      "epoch": 15.989156626506023,
      "grad_norm": 0.0003349289472680539,
      "learning_rate": 4.010843373493976e-06,
      "loss": 0.0211,
      "step": 132710
    },
    {
      "epoch": 15.990361445783133,
      "grad_norm": 0.0010713186347857118,
      "learning_rate": 4.009638554216868e-06,
      "loss": 0.0197,
      "step": 132720
    },
    {
      "epoch": 15.991566265060241,
      "grad_norm": 0.0007856223382987082,
      "learning_rate": 4.0084337349397595e-06,
      "loss": 0.0011,
      "step": 132730
    },
    {
      "epoch": 15.992771084337349,
      "grad_norm": 0.23106509447097778,
      "learning_rate": 4.007228915662651e-06,
      "loss": 0.0006,
      "step": 132740
    },
    {
      "epoch": 15.993975903614459,
      "grad_norm": 0.0022254488430917263,
      "learning_rate": 4.006024096385543e-06,
      "loss": 0.0091,
      "step": 132750
    },
    {
      "epoch": 15.995180722891567,
      "grad_norm": 0.0010366591159254313,
      "learning_rate": 4.004819277108434e-06,
      "loss": 0.0211,
      "step": 132760
    },
    {
      "epoch": 15.996385542168674,
      "grad_norm": 0.761916995048523,
      "learning_rate": 4.003614457831326e-06,
      "loss": 0.0176,
      "step": 132770
    },
    {
      "epoch": 15.997590361445782,
      "grad_norm": 0.00922080222517252,
      "learning_rate": 4.0024096385542175e-06,
      "loss": 0.0011,
      "step": 132780
    },
    {
      "epoch": 15.998795180722892,
      "grad_norm": 0.605169415473938,
      "learning_rate": 4.001204819277108e-06,
      "loss": 0.0124,
      "step": 132790
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.504138231277466,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0238,
      "step": 132800
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.9877905886764154,
      "eval_f1": 0.9676979353958709,
      "eval_loss": 0.05784750357270241,
      "eval_precision": 0.9708882806668325,
      "eval_recall": 0.9645284884439501,
      "eval_runtime": 3387.5074,
      "eval_samples_per_second": 12.602,
      "eval_steps_per_second": 0.525,
      "step": 132800
    },
    {
      "epoch": 16.00120481927711,
      "grad_norm": 1.098371982574463,
      "learning_rate": 3.998795180722892e-06,
      "loss": 0.0248,
      "step": 132810
    },
    {
      "epoch": 16.002409638554216,
      "grad_norm": 1.2201848030090332,
      "learning_rate": 3.997590361445783e-06,
      "loss": 0.007,
      "step": 132820
    },
    {
      "epoch": 16.003614457831326,
      "grad_norm": 0.00035859012859873474,
      "learning_rate": 3.996385542168675e-06,
      "loss": 0.0413,
      "step": 132830
    },
    {
      "epoch": 16.004819277108435,
      "grad_norm": 0.70322185754776,
      "learning_rate": 3.995180722891567e-06,
      "loss": 0.0041,
      "step": 132840
    },
    {
      "epoch": 16.00602409638554,
      "grad_norm": 0.024909550324082375,
      "learning_rate": 3.993975903614459e-06,
      "loss": 0.0109,
      "step": 132850
    },
    {
      "epoch": 16.00722891566265,
      "grad_norm": 0.9092410206794739,
      "learning_rate": 3.992771084337349e-06,
      "loss": 0.0167,
      "step": 132860
    },
    {
      "epoch": 16.00843373493976,
      "grad_norm": 0.7001233696937561,
      "learning_rate": 3.991566265060241e-06,
      "loss": 0.012,
      "step": 132870
    },
    {
      "epoch": 16.009638554216867,
      "grad_norm": 0.0005127326585352421,
      "learning_rate": 3.990361445783133e-06,
      "loss": 0.0017,
      "step": 132880
    },
    {
      "epoch": 16.010843373493977,
      "grad_norm": 0.001947235083207488,
      "learning_rate": 3.989156626506024e-06,
      "loss": 0.0132,
      "step": 132890
    },
    {
      "epoch": 16.012048192771083,
      "grad_norm": 0.0002520983398426324,
      "learning_rate": 3.987951807228916e-06,
      "loss": 0.0083,
      "step": 132900
    },
    {
      "epoch": 16.013253012048192,
      "grad_norm": 0.0003091791004408151,
      "learning_rate": 3.986746987951808e-06,
      "loss": 0.0055,
      "step": 132910
    },
    {
      "epoch": 16.014457831325302,
      "grad_norm": 0.0012078993022441864,
      "learning_rate": 3.985542168674699e-06,
      "loss": 0.0236,
      "step": 132920
    },
    {
      "epoch": 16.01566265060241,
      "grad_norm": 0.8969469666481018,
      "learning_rate": 3.9843373493975905e-06,
      "loss": 0.0053,
      "step": 132930
    },
    {
      "epoch": 16.016867469879518,
      "grad_norm": 0.0002795340260490775,
      "learning_rate": 3.983132530120482e-06,
      "loss": 0.0099,
      "step": 132940
    },
    {
      "epoch": 16.018072289156628,
      "grad_norm": 28.89012336730957,
      "learning_rate": 3.981927710843374e-06,
      "loss": 0.0121,
      "step": 132950
    },
    {
      "epoch": 16.019277108433734,
      "grad_norm": 0.9313390254974365,
      "learning_rate": 3.980722891566265e-06,
      "loss": 0.0226,
      "step": 132960
    },
    {
      "epoch": 16.020481927710843,
      "grad_norm": 0.00011182108573848382,
      "learning_rate": 3.979518072289157e-06,
      "loss": 0.0107,
      "step": 132970
    },
    {
      "epoch": 16.021686746987953,
      "grad_norm": 0.0009178814361803234,
      "learning_rate": 3.978313253012048e-06,
      "loss": 0.005,
      "step": 132980
    },
    {
      "epoch": 16.02289156626506,
      "grad_norm": 2.510127544403076,
      "learning_rate": 3.97710843373494e-06,
      "loss": 0.0271,
      "step": 132990
    },
    {
      "epoch": 16.02409638554217,
      "grad_norm": 0.0004386560176499188,
      "learning_rate": 3.975903614457832e-06,
      "loss": 0.0012,
      "step": 133000
    },
    {
      "epoch": 16.02530120481928,
      "grad_norm": 0.0003475049452390522,
      "learning_rate": 3.974698795180723e-06,
      "loss": 0.0082,
      "step": 133010
    },
    {
      "epoch": 16.026506024096385,
      "grad_norm": 0.00038292171666398644,
      "learning_rate": 3.973493975903615e-06,
      "loss": 0.0258,
      "step": 133020
    },
    {
      "epoch": 16.027710843373494,
      "grad_norm": 0.00016217445954680443,
      "learning_rate": 3.972289156626506e-06,
      "loss": 0.0018,
      "step": 133030
    },
    {
      "epoch": 16.0289156626506,
      "grad_norm": 1.2958110570907593,
      "learning_rate": 3.971084337349398e-06,
      "loss": 0.009,
      "step": 133040
    },
    {
      "epoch": 16.03012048192771,
      "grad_norm": 0.020330218598246574,
      "learning_rate": 3.9698795180722895e-06,
      "loss": 0.0047,
      "step": 133050
    },
    {
      "epoch": 16.03132530120482,
      "grad_norm": 0.02297697775065899,
      "learning_rate": 3.968674698795181e-06,
      "loss": 0.0204,
      "step": 133060
    },
    {
      "epoch": 16.032530120481926,
      "grad_norm": 0.00020521147234831005,
      "learning_rate": 3.967469879518073e-06,
      "loss": 0.0128,
      "step": 133070
    },
    {
      "epoch": 16.033734939759036,
      "grad_norm": 0.0011013118783012033,
      "learning_rate": 3.966265060240964e-06,
      "loss": 0.013,
      "step": 133080
    },
    {
      "epoch": 16.034939759036146,
      "grad_norm": 0.0036086956970393658,
      "learning_rate": 3.965060240963856e-06,
      "loss": 0.0131,
      "step": 133090
    },
    {
      "epoch": 16.03614457831325,
      "grad_norm": 0.00042502046562731266,
      "learning_rate": 3.9638554216867475e-06,
      "loss": 0.0008,
      "step": 133100
    },
    {
      "epoch": 16.03734939759036,
      "grad_norm": 0.0001421805063728243,
      "learning_rate": 3.962650602409639e-06,
      "loss": 0.0139,
      "step": 133110
    },
    {
      "epoch": 16.03855421686747,
      "grad_norm": 0.00017875921912491322,
      "learning_rate": 3.961445783132531e-06,
      "loss": 0.0131,
      "step": 133120
    },
    {
      "epoch": 16.039759036144577,
      "grad_norm": 0.1739300787448883,
      "learning_rate": 3.960240963855421e-06,
      "loss": 0.0103,
      "step": 133130
    },
    {
      "epoch": 16.040963855421687,
      "grad_norm": 0.0037919830065220594,
      "learning_rate": 3.959036144578314e-06,
      "loss": 0.0012,
      "step": 133140
    },
    {
      "epoch": 16.042168674698797,
      "grad_norm": 1.095077395439148,
      "learning_rate": 3.957831325301205e-06,
      "loss": 0.0067,
      "step": 133150
    },
    {
      "epoch": 16.043373493975903,
      "grad_norm": 0.000379437580704689,
      "learning_rate": 3.956626506024097e-06,
      "loss": 0.0124,
      "step": 133160
    },
    {
      "epoch": 16.044578313253012,
      "grad_norm": 0.00033278626506216824,
      "learning_rate": 3.955421686746988e-06,
      "loss": 0.059,
      "step": 133170
    },
    {
      "epoch": 16.045783132530122,
      "grad_norm": 0.0023202162701636553,
      "learning_rate": 3.95421686746988e-06,
      "loss": 0.0216,
      "step": 133180
    },
    {
      "epoch": 16.04698795180723,
      "grad_norm": 2.3300328254699707,
      "learning_rate": 3.953012048192772e-06,
      "loss": 0.0611,
      "step": 133190
    },
    {
      "epoch": 16.048192771084338,
      "grad_norm": 0.0041453223675489426,
      "learning_rate": 3.9518072289156625e-06,
      "loss": 0.0195,
      "step": 133200
    },
    {
      "epoch": 16.049397590361444,
      "grad_norm": 0.0005935980007052422,
      "learning_rate": 3.950602409638555e-06,
      "loss": 0.0117,
      "step": 133210
    },
    {
      "epoch": 16.050602409638554,
      "grad_norm": 0.5806946158409119,
      "learning_rate": 3.9493975903614465e-06,
      "loss": 0.0054,
      "step": 133220
    },
    {
      "epoch": 16.051807228915663,
      "grad_norm": 0.8092153072357178,
      "learning_rate": 3.948192771084337e-06,
      "loss": 0.0088,
      "step": 133230
    },
    {
      "epoch": 16.05301204819277,
      "grad_norm": 0.0005704136565327644,
      "learning_rate": 3.946987951807229e-06,
      "loss": 0.0088,
      "step": 133240
    },
    {
      "epoch": 16.05421686746988,
      "grad_norm": 0.00020771411072928458,
      "learning_rate": 3.945783132530121e-06,
      "loss": 0.0197,
      "step": 133250
    },
    {
      "epoch": 16.05542168674699,
      "grad_norm": 0.00043270434252917767,
      "learning_rate": 3.944578313253012e-06,
      "loss": 0.0077,
      "step": 133260
    },
    {
      "epoch": 16.056626506024095,
      "grad_norm": 0.0018116106512024999,
      "learning_rate": 3.943373493975904e-06,
      "loss": 0.0137,
      "step": 133270
    },
    {
      "epoch": 16.057831325301205,
      "grad_norm": 0.0006503626354970038,
      "learning_rate": 3.942168674698795e-06,
      "loss": 0.0047,
      "step": 133280
    },
    {
      "epoch": 16.059036144578315,
      "grad_norm": 0.0015956603456288576,
      "learning_rate": 3.940963855421688e-06,
      "loss": 0.0116,
      "step": 133290
    },
    {
      "epoch": 16.06024096385542,
      "grad_norm": 0.0005950467311777174,
      "learning_rate": 3.939759036144578e-06,
      "loss": 0.0191,
      "step": 133300
    },
    {
      "epoch": 16.06144578313253,
      "grad_norm": 0.0012224375968798995,
      "learning_rate": 3.93855421686747e-06,
      "loss": 0.0124,
      "step": 133310
    },
    {
      "epoch": 16.06265060240964,
      "grad_norm": 0.10125076025724411,
      "learning_rate": 3.9373493975903615e-06,
      "loss": 0.0129,
      "step": 133320
    },
    {
      "epoch": 16.063855421686746,
      "grad_norm": 0.00038248172495514154,
      "learning_rate": 3.936144578313253e-06,
      "loss": 0.0146,
      "step": 133330
    },
    {
      "epoch": 16.065060240963856,
      "grad_norm": 0.0046720486134290695,
      "learning_rate": 3.934939759036145e-06,
      "loss": 0.0124,
      "step": 133340
    },
    {
      "epoch": 16.066265060240966,
      "grad_norm": 0.0007451882120221853,
      "learning_rate": 3.933734939759036e-06,
      "loss": 0.0149,
      "step": 133350
    },
    {
      "epoch": 16.06746987951807,
      "grad_norm": 0.48937511444091797,
      "learning_rate": 3.932530120481928e-06,
      "loss": 0.0129,
      "step": 133360
    },
    {
      "epoch": 16.06867469879518,
      "grad_norm": 0.000687110994476825,
      "learning_rate": 3.9313253012048195e-06,
      "loss": 0.0135,
      "step": 133370
    },
    {
      "epoch": 16.069879518072288,
      "grad_norm": 0.0004289714270271361,
      "learning_rate": 3.930120481927711e-06,
      "loss": 0.0072,
      "step": 133380
    },
    {
      "epoch": 16.071084337349397,
      "grad_norm": 0.000703789119143039,
      "learning_rate": 3.928915662650603e-06,
      "loss": 0.0128,
      "step": 133390
    },
    {
      "epoch": 16.072289156626507,
      "grad_norm": 0.0003942122566513717,
      "learning_rate": 3.927710843373494e-06,
      "loss": 0.0069,
      "step": 133400
    },
    {
      "epoch": 16.073493975903613,
      "grad_norm": 0.00010219794057775289,
      "learning_rate": 3.926506024096386e-06,
      "loss": 0.0069,
      "step": 133410
    },
    {
      "epoch": 16.074698795180723,
      "grad_norm": 0.000698246352840215,
      "learning_rate": 3.9253012048192774e-06,
      "loss": 0.004,
      "step": 133420
    },
    {
      "epoch": 16.075903614457832,
      "grad_norm": 0.0004945831024087965,
      "learning_rate": 3.924096385542169e-06,
      "loss": 0.0159,
      "step": 133430
    },
    {
      "epoch": 16.07710843373494,
      "grad_norm": 0.00023550800688099116,
      "learning_rate": 3.922891566265061e-06,
      "loss": 0.0259,
      "step": 133440
    },
    {
      "epoch": 16.07831325301205,
      "grad_norm": 0.000440951029304415,
      "learning_rate": 3.921686746987952e-06,
      "loss": 0.0042,
      "step": 133450
    },
    {
      "epoch": 16.079518072289158,
      "grad_norm": 0.0001748655195115134,
      "learning_rate": 3.920481927710844e-06,
      "loss": 0.0198,
      "step": 133460
    },
    {
      "epoch": 16.080722891566264,
      "grad_norm": 0.003638932714238763,
      "learning_rate": 3.919277108433735e-06,
      "loss": 0.0076,
      "step": 133470
    },
    {
      "epoch": 16.081927710843374,
      "grad_norm": 0.039654191583395004,
      "learning_rate": 3.918072289156627e-06,
      "loss": 0.023,
      "step": 133480
    },
    {
      "epoch": 16.083132530120483,
      "grad_norm": 0.49580273032188416,
      "learning_rate": 3.9168674698795185e-06,
      "loss": 0.0203,
      "step": 133490
    },
    {
      "epoch": 16.08433734939759,
      "grad_norm": 0.00019436058937571943,
      "learning_rate": 3.91566265060241e-06,
      "loss": 0.0169,
      "step": 133500
    },
    {
      "epoch": 16.0855421686747,
      "grad_norm": 0.00033073461963795125,
      "learning_rate": 3.914457831325302e-06,
      "loss": 0.0103,
      "step": 133510
    },
    {
      "epoch": 16.086746987951805,
      "grad_norm": 1.7789850234985352,
      "learning_rate": 3.913253012048193e-06,
      "loss": 0.0103,
      "step": 133520
    },
    {
      "epoch": 16.087951807228915,
      "grad_norm": 0.00323332822881639,
      "learning_rate": 3.912048192771085e-06,
      "loss": 0.0042,
      "step": 133530
    },
    {
      "epoch": 16.089156626506025,
      "grad_norm": 28.396738052368164,
      "learning_rate": 3.910843373493976e-06,
      "loss": 0.0506,
      "step": 133540
    },
    {
      "epoch": 16.09036144578313,
      "grad_norm": 1.3356540203094482,
      "learning_rate": 3.909638554216868e-06,
      "loss": 0.0127,
      "step": 133550
    },
    {
      "epoch": 16.09156626506024,
      "grad_norm": 0.00033589129452593625,
      "learning_rate": 3.90843373493976e-06,
      "loss": 0.0232,
      "step": 133560
    },
    {
      "epoch": 16.09277108433735,
      "grad_norm": 0.008765961043536663,
      "learning_rate": 3.907228915662651e-06,
      "loss": 0.0112,
      "step": 133570
    },
    {
      "epoch": 16.093975903614457,
      "grad_norm": 0.4349616467952728,
      "learning_rate": 3.906024096385542e-06,
      "loss": 0.0052,
      "step": 133580
    },
    {
      "epoch": 16.095180722891566,
      "grad_norm": 0.9440017342567444,
      "learning_rate": 3.9048192771084344e-06,
      "loss": 0.003,
      "step": 133590
    },
    {
      "epoch": 16.096385542168676,
      "grad_norm": 0.0005783283268101513,
      "learning_rate": 3.903614457831326e-06,
      "loss": 0.0134,
      "step": 133600
    },
    {
      "epoch": 16.097590361445782,
      "grad_norm": 0.00034372013760730624,
      "learning_rate": 3.902409638554217e-06,
      "loss": 0.0057,
      "step": 133610
    },
    {
      "epoch": 16.09879518072289,
      "grad_norm": 1.319189190864563,
      "learning_rate": 3.901204819277108e-06,
      "loss": 0.0341,
      "step": 133620
    },
    {
      "epoch": 16.1,
      "grad_norm": 1.6429344415664673,
      "learning_rate": 3.900000000000001e-06,
      "loss": 0.0232,
      "step": 133630
    },
    {
      "epoch": 16.101204819277108,
      "grad_norm": 0.0005670773098245263,
      "learning_rate": 3.8987951807228915e-06,
      "loss": 0.0059,
      "step": 133640
    },
    {
      "epoch": 16.102409638554217,
      "grad_norm": 1.8395278453826904,
      "learning_rate": 3.897590361445783e-06,
      "loss": 0.018,
      "step": 133650
    },
    {
      "epoch": 16.103614457831327,
      "grad_norm": 0.3277204632759094,
      "learning_rate": 3.8963855421686755e-06,
      "loss": 0.0211,
      "step": 133660
    },
    {
      "epoch": 16.104819277108433,
      "grad_norm": 0.0008857224020175636,
      "learning_rate": 3.895180722891566e-06,
      "loss": 0.0213,
      "step": 133670
    },
    {
      "epoch": 16.106024096385543,
      "grad_norm": 0.0005647552898153663,
      "learning_rate": 3.893975903614458e-06,
      "loss": 0.0128,
      "step": 133680
    },
    {
      "epoch": 16.10722891566265,
      "grad_norm": 27.667957305908203,
      "learning_rate": 3.8927710843373495e-06,
      "loss": 0.062,
      "step": 133690
    },
    {
      "epoch": 16.10843373493976,
      "grad_norm": 0.002012440701946616,
      "learning_rate": 3.891566265060242e-06,
      "loss": 0.0013,
      "step": 133700
    },
    {
      "epoch": 16.10963855421687,
      "grad_norm": 1.3678838014602661,
      "learning_rate": 3.890361445783133e-06,
      "loss": 0.0244,
      "step": 133710
    },
    {
      "epoch": 16.110843373493974,
      "grad_norm": 2.3717031478881836,
      "learning_rate": 3.889156626506024e-06,
      "loss": 0.0208,
      "step": 133720
    },
    {
      "epoch": 16.112048192771084,
      "grad_norm": 1.1844830513000488,
      "learning_rate": 3.887951807228916e-06,
      "loss": 0.006,
      "step": 133730
    },
    {
      "epoch": 16.113253012048194,
      "grad_norm": 0.00013861437037121505,
      "learning_rate": 3.886746987951807e-06,
      "loss": 0.0207,
      "step": 133740
    },
    {
      "epoch": 16.1144578313253,
      "grad_norm": 0.0004486536781769246,
      "learning_rate": 3.885542168674699e-06,
      "loss": 0.0004,
      "step": 133750
    },
    {
      "epoch": 16.11566265060241,
      "grad_norm": 0.9446089267730713,
      "learning_rate": 3.8843373493975906e-06,
      "loss": 0.007,
      "step": 133760
    },
    {
      "epoch": 16.11686746987952,
      "grad_norm": 0.00013578563812188804,
      "learning_rate": 3.883132530120482e-06,
      "loss": 0.0169,
      "step": 133770
    },
    {
      "epoch": 16.118072289156625,
      "grad_norm": 0.0005463933921419084,
      "learning_rate": 3.881927710843374e-06,
      "loss": 0.0094,
      "step": 133780
    },
    {
      "epoch": 16.119277108433735,
      "grad_norm": 0.07171794027090073,
      "learning_rate": 3.880722891566265e-06,
      "loss": 0.004,
      "step": 133790
    },
    {
      "epoch": 16.120481927710845,
      "grad_norm": 0.9834271669387817,
      "learning_rate": 3.879518072289157e-06,
      "loss": 0.0107,
      "step": 133800
    },
    {
      "epoch": 16.12168674698795,
      "grad_norm": 0.8518021702766418,
      "learning_rate": 3.8783132530120485e-06,
      "loss": 0.0034,
      "step": 133810
    },
    {
      "epoch": 16.12289156626506,
      "grad_norm": 0.15489564836025238,
      "learning_rate": 3.87710843373494e-06,
      "loss": 0.0172,
      "step": 133820
    },
    {
      "epoch": 16.12409638554217,
      "grad_norm": 0.287192165851593,
      "learning_rate": 3.875903614457832e-06,
      "loss": 0.017,
      "step": 133830
    },
    {
      "epoch": 16.125301204819277,
      "grad_norm": 1.192836880683899,
      "learning_rate": 3.874698795180723e-06,
      "loss": 0.0114,
      "step": 133840
    },
    {
      "epoch": 16.126506024096386,
      "grad_norm": 0.001937828492373228,
      "learning_rate": 3.873493975903615e-06,
      "loss": 0.0,
      "step": 133850
    },
    {
      "epoch": 16.127710843373492,
      "grad_norm": 0.00012401753338053823,
      "learning_rate": 3.8722891566265065e-06,
      "loss": 0.0179,
      "step": 133860
    },
    {
      "epoch": 16.128915662650602,
      "grad_norm": 0.0014113954966887832,
      "learning_rate": 3.871084337349398e-06,
      "loss": 0.0059,
      "step": 133870
    },
    {
      "epoch": 16.13012048192771,
      "grad_norm": 0.0008684158674441278,
      "learning_rate": 3.86987951807229e-06,
      "loss": 0.0081,
      "step": 133880
    },
    {
      "epoch": 16.131325301204818,
      "grad_norm": 0.0007557375938631594,
      "learning_rate": 3.868674698795181e-06,
      "loss": 0.0046,
      "step": 133890
    },
    {
      "epoch": 16.132530120481928,
      "grad_norm": 0.0006555703585036099,
      "learning_rate": 3.867469879518073e-06,
      "loss": 0.0187,
      "step": 133900
    },
    {
      "epoch": 16.133734939759037,
      "grad_norm": 1.1005008220672607,
      "learning_rate": 3.866265060240964e-06,
      "loss": 0.0114,
      "step": 133910
    },
    {
      "epoch": 16.134939759036143,
      "grad_norm": 0.24242986738681793,
      "learning_rate": 3.865060240963856e-06,
      "loss": 0.0119,
      "step": 133920
    },
    {
      "epoch": 16.136144578313253,
      "grad_norm": 0.002903505926951766,
      "learning_rate": 3.8638554216867476e-06,
      "loss": 0.0194,
      "step": 133930
    },
    {
      "epoch": 16.137349397590363,
      "grad_norm": 0.001830901252105832,
      "learning_rate": 3.862650602409639e-06,
      "loss": 0.0041,
      "step": 133940
    },
    {
      "epoch": 16.13855421686747,
      "grad_norm": 0.9611786007881165,
      "learning_rate": 3.86144578313253e-06,
      "loss": 0.0273,
      "step": 133950
    },
    {
      "epoch": 16.13975903614458,
      "grad_norm": 0.00020000332733616233,
      "learning_rate": 3.860240963855422e-06,
      "loss": 0.009,
      "step": 133960
    },
    {
      "epoch": 16.14096385542169,
      "grad_norm": 1.2323487997055054,
      "learning_rate": 3.859036144578314e-06,
      "loss": 0.0096,
      "step": 133970
    },
    {
      "epoch": 16.142168674698794,
      "grad_norm": 0.27770763635635376,
      "learning_rate": 3.857831325301205e-06,
      "loss": 0.0055,
      "step": 133980
    },
    {
      "epoch": 16.143373493975904,
      "grad_norm": 0.2479526400566101,
      "learning_rate": 3.856626506024096e-06,
      "loss": 0.0221,
      "step": 133990
    },
    {
      "epoch": 16.14457831325301,
      "grad_norm": 0.6978718638420105,
      "learning_rate": 3.855421686746989e-06,
      "loss": 0.0026,
      "step": 134000
    },
    {
      "epoch": 16.14578313253012,
      "grad_norm": 0.2568611204624176,
      "learning_rate": 3.85421686746988e-06,
      "loss": 0.0045,
      "step": 134010
    },
    {
      "epoch": 16.14698795180723,
      "grad_norm": 0.4537299573421478,
      "learning_rate": 3.853012048192771e-06,
      "loss": 0.0084,
      "step": 134020
    },
    {
      "epoch": 16.148192771084336,
      "grad_norm": 0.0001925052929436788,
      "learning_rate": 3.851807228915663e-06,
      "loss": 0.013,
      "step": 134030
    },
    {
      "epoch": 16.149397590361446,
      "grad_norm": 0.0011751308338716626,
      "learning_rate": 3.850602409638555e-06,
      "loss": 0.0089,
      "step": 134040
    },
    {
      "epoch": 16.150602409638555,
      "grad_norm": 0.00013214080536272377,
      "learning_rate": 3.849397590361446e-06,
      "loss": 0.0093,
      "step": 134050
    },
    {
      "epoch": 16.15180722891566,
      "grad_norm": 1.8817641735076904,
      "learning_rate": 3.848192771084337e-06,
      "loss": 0.0155,
      "step": 134060
    },
    {
      "epoch": 16.15301204819277,
      "grad_norm": 0.0002514275547582656,
      "learning_rate": 3.84698795180723e-06,
      "loss": 0.0129,
      "step": 134070
    },
    {
      "epoch": 16.15421686746988,
      "grad_norm": 0.0001805607753340155,
      "learning_rate": 3.8457831325301205e-06,
      "loss": 0.021,
      "step": 134080
    },
    {
      "epoch": 16.155421686746987,
      "grad_norm": 0.000318197620799765,
      "learning_rate": 3.844578313253012e-06,
      "loss": 0.0072,
      "step": 134090
    },
    {
      "epoch": 16.156626506024097,
      "grad_norm": 0.00011990178609266877,
      "learning_rate": 3.843373493975904e-06,
      "loss": 0.0004,
      "step": 134100
    },
    {
      "epoch": 16.157831325301206,
      "grad_norm": 0.3537611961364746,
      "learning_rate": 3.842168674698796e-06,
      "loss": 0.0276,
      "step": 134110
    },
    {
      "epoch": 16.159036144578312,
      "grad_norm": 5.795501232147217,
      "learning_rate": 3.840963855421687e-06,
      "loss": 0.0253,
      "step": 134120
    },
    {
      "epoch": 16.160240963855422,
      "grad_norm": 0.00019462325144559145,
      "learning_rate": 3.8397590361445785e-06,
      "loss": 0.0037,
      "step": 134130
    },
    {
      "epoch": 16.16144578313253,
      "grad_norm": 0.36218512058258057,
      "learning_rate": 3.83855421686747e-06,
      "loss": 0.0193,
      "step": 134140
    },
    {
      "epoch": 16.162650602409638,
      "grad_norm": 0.00019909862021449953,
      "learning_rate": 3.837349397590362e-06,
      "loss": 0.0172,
      "step": 134150
    },
    {
      "epoch": 16.163855421686748,
      "grad_norm": 0.0029678947757929564,
      "learning_rate": 3.836144578313253e-06,
      "loss": 0.0162,
      "step": 134160
    },
    {
      "epoch": 16.165060240963854,
      "grad_norm": 0.0003109453828074038,
      "learning_rate": 3.834939759036145e-06,
      "loss": 0.0201,
      "step": 134170
    },
    {
      "epoch": 16.166265060240963,
      "grad_norm": 0.00030308711575344205,
      "learning_rate": 3.833734939759036e-06,
      "loss": 0.0036,
      "step": 134180
    },
    {
      "epoch": 16.167469879518073,
      "grad_norm": 10.04601764678955,
      "learning_rate": 3.832530120481928e-06,
      "loss": 0.0586,
      "step": 134190
    },
    {
      "epoch": 16.16867469879518,
      "grad_norm": 0.35134461522102356,
      "learning_rate": 3.83132530120482e-06,
      "loss": 0.0131,
      "step": 134200
    },
    {
      "epoch": 16.16987951807229,
      "grad_norm": 1.394722580909729,
      "learning_rate": 3.830120481927711e-06,
      "loss": 0.004,
      "step": 134210
    },
    {
      "epoch": 16.1710843373494,
      "grad_norm": 0.0001458459155401215,
      "learning_rate": 3.828915662650603e-06,
      "loss": 0.0253,
      "step": 134220
    },
    {
      "epoch": 16.172289156626505,
      "grad_norm": 0.22166059911251068,
      "learning_rate": 3.827710843373494e-06,
      "loss": 0.0287,
      "step": 134230
    },
    {
      "epoch": 16.173493975903614,
      "grad_norm": 0.001345880446024239,
      "learning_rate": 3.826506024096386e-06,
      "loss": 0.0004,
      "step": 134240
    },
    {
      "epoch": 16.174698795180724,
      "grad_norm": 1.1580137014389038,
      "learning_rate": 3.8253012048192775e-06,
      "loss": 0.0081,
      "step": 134250
    },
    {
      "epoch": 16.17590361445783,
      "grad_norm": 0.003932362888008356,
      "learning_rate": 3.824096385542169e-06,
      "loss": 0.0073,
      "step": 134260
    },
    {
      "epoch": 16.17710843373494,
      "grad_norm": 0.000425166537752375,
      "learning_rate": 3.822891566265061e-06,
      "loss": 0.0068,
      "step": 134270
    },
    {
      "epoch": 16.17831325301205,
      "grad_norm": 0.00018929061479866505,
      "learning_rate": 3.821686746987952e-06,
      "loss": 0.0027,
      "step": 134280
    },
    {
      "epoch": 16.179518072289156,
      "grad_norm": 0.00013824507186654955,
      "learning_rate": 3.820481927710844e-06,
      "loss": 0.0072,
      "step": 134290
    },
    {
      "epoch": 16.180722891566266,
      "grad_norm": 0.0004516073677223176,
      "learning_rate": 3.8192771084337355e-06,
      "loss": 0.019,
      "step": 134300
    },
    {
      "epoch": 16.181927710843375,
      "grad_norm": 7.095235824584961,
      "learning_rate": 3.818072289156627e-06,
      "loss": 0.0042,
      "step": 134310
    },
    {
      "epoch": 16.18313253012048,
      "grad_norm": 0.26510030031204224,
      "learning_rate": 3.816867469879519e-06,
      "loss": 0.0303,
      "step": 134320
    },
    {
      "epoch": 16.18433734939759,
      "grad_norm": 0.2600535750389099,
      "learning_rate": 3.815662650602409e-06,
      "loss": 0.0168,
      "step": 134330
    },
    {
      "epoch": 16.185542168674697,
      "grad_norm": 1.611031174659729,
      "learning_rate": 3.814457831325302e-06,
      "loss": 0.0069,
      "step": 134340
    },
    {
      "epoch": 16.186746987951807,
      "grad_norm": 0.0006442040321417153,
      "learning_rate": 3.813253012048193e-06,
      "loss": 0.0103,
      "step": 134350
    },
    {
      "epoch": 16.187951807228917,
      "grad_norm": 0.00044241867726668715,
      "learning_rate": 3.8120481927710846e-06,
      "loss": 0.0115,
      "step": 134360
    },
    {
      "epoch": 16.189156626506023,
      "grad_norm": 1.9077385663986206,
      "learning_rate": 3.8108433734939766e-06,
      "loss": 0.0157,
      "step": 134370
    },
    {
      "epoch": 16.190361445783132,
      "grad_norm": 0.0002507961180526763,
      "learning_rate": 3.8096385542168678e-06,
      "loss": 0.0143,
      "step": 134380
    },
    {
      "epoch": 16.191566265060242,
      "grad_norm": 0.5199592709541321,
      "learning_rate": 3.8084337349397593e-06,
      "loss": 0.0258,
      "step": 134390
    },
    {
      "epoch": 16.19277108433735,
      "grad_norm": 0.00029288107180036604,
      "learning_rate": 3.807228915662651e-06,
      "loss": 0.0264,
      "step": 134400
    },
    {
      "epoch": 16.193975903614458,
      "grad_norm": 0.008583638817071915,
      "learning_rate": 3.8060240963855425e-06,
      "loss": 0.0095,
      "step": 134410
    },
    {
      "epoch": 16.195180722891568,
      "grad_norm": 0.00011386944242985919,
      "learning_rate": 3.804819277108434e-06,
      "loss": 0.0069,
      "step": 134420
    },
    {
      "epoch": 16.196385542168674,
      "grad_norm": 0.0002890532196033746,
      "learning_rate": 3.8036144578313257e-06,
      "loss": 0.0109,
      "step": 134430
    },
    {
      "epoch": 16.197590361445783,
      "grad_norm": 0.03495208919048309,
      "learning_rate": 3.802409638554217e-06,
      "loss": 0.005,
      "step": 134440
    },
    {
      "epoch": 16.198795180722893,
      "grad_norm": 0.0010535545879974961,
      "learning_rate": 3.801204819277109e-06,
      "loss": 0.0182,
      "step": 134450
    },
    {
      "epoch": 16.2,
      "grad_norm": 0.4047040045261383,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 0.0079,
      "step": 134460
    },
    {
      "epoch": 16.20120481927711,
      "grad_norm": 0.00015017019177321345,
      "learning_rate": 3.7987951807228916e-06,
      "loss": 0.0196,
      "step": 134470
    },
    {
      "epoch": 16.202409638554215,
      "grad_norm": 0.00019962583610322326,
      "learning_rate": 3.7975903614457832e-06,
      "loss": 0.0018,
      "step": 134480
    },
    {
      "epoch": 16.203614457831325,
      "grad_norm": 1.2770034074783325,
      "learning_rate": 3.7963855421686752e-06,
      "loss": 0.0173,
      "step": 134490
    },
    {
      "epoch": 16.204819277108435,
      "grad_norm": 0.21203458309173584,
      "learning_rate": 3.7951807228915664e-06,
      "loss": 0.021,
      "step": 134500
    },
    {
      "epoch": 16.20602409638554,
      "grad_norm": 0.004499754402786493,
      "learning_rate": 3.793975903614458e-06,
      "loss": 0.0103,
      "step": 134510
    },
    {
      "epoch": 16.20722891566265,
      "grad_norm": 0.002692120848223567,
      "learning_rate": 3.79277108433735e-06,
      "loss": 0.0085,
      "step": 134520
    },
    {
      "epoch": 16.20843373493976,
      "grad_norm": 0.0006814628141000867,
      "learning_rate": 3.7915662650602416e-06,
      "loss": 0.013,
      "step": 134530
    },
    {
      "epoch": 16.209638554216866,
      "grad_norm": 0.2534031271934509,
      "learning_rate": 3.7903614457831327e-06,
      "loss": 0.0159,
      "step": 134540
    },
    {
      "epoch": 16.210843373493976,
      "grad_norm": 0.0022135174367576838,
      "learning_rate": 3.7891566265060243e-06,
      "loss": 0.0076,
      "step": 134550
    },
    {
      "epoch": 16.212048192771086,
      "grad_norm": 0.0017847587587311864,
      "learning_rate": 3.7879518072289163e-06,
      "loss": 0.0007,
      "step": 134560
    },
    {
      "epoch": 16.21325301204819,
      "grad_norm": 9.402376599609852e-05,
      "learning_rate": 3.7867469879518075e-06,
      "loss": 0.0061,
      "step": 134570
    },
    {
      "epoch": 16.2144578313253,
      "grad_norm": 0.002691368106752634,
      "learning_rate": 3.785542168674699e-06,
      "loss": 0.0097,
      "step": 134580
    },
    {
      "epoch": 16.21566265060241,
      "grad_norm": 0.00024384260177612305,
      "learning_rate": 3.7843373493975903e-06,
      "loss": 0.0065,
      "step": 134590
    },
    {
      "epoch": 16.216867469879517,
      "grad_norm": 0.9676368236541748,
      "learning_rate": 3.7831325301204823e-06,
      "loss": 0.0158,
      "step": 134600
    },
    {
      "epoch": 16.218072289156627,
      "grad_norm": 0.00010833419946720824,
      "learning_rate": 3.781927710843374e-06,
      "loss": 0.0057,
      "step": 134610
    },
    {
      "epoch": 16.219277108433737,
      "grad_norm": 1.535524606704712,
      "learning_rate": 3.7807228915662654e-06,
      "loss": 0.0226,
      "step": 134620
    },
    {
      "epoch": 16.220481927710843,
      "grad_norm": 0.00012845228775404394,
      "learning_rate": 3.7795180722891566e-06,
      "loss": 0.0127,
      "step": 134630
    },
    {
      "epoch": 16.221686746987952,
      "grad_norm": 0.8486746549606323,
      "learning_rate": 3.7783132530120486e-06,
      "loss": 0.0067,
      "step": 134640
    },
    {
      "epoch": 16.22289156626506,
      "grad_norm": 0.00013112122542224824,
      "learning_rate": 3.7771084337349402e-06,
      "loss": 0.0077,
      "step": 134650
    },
    {
      "epoch": 16.22409638554217,
      "grad_norm": 0.0006416390533559024,
      "learning_rate": 3.7759036144578314e-06,
      "loss": 0.008,
      "step": 134660
    },
    {
      "epoch": 16.225301204819278,
      "grad_norm": 0.0002850123855751008,
      "learning_rate": 3.7746987951807234e-06,
      "loss": 0.0278,
      "step": 134670
    },
    {
      "epoch": 16.226506024096384,
      "grad_norm": 0.0002006133581744507,
      "learning_rate": 3.773493975903615e-06,
      "loss": 0.0034,
      "step": 134680
    },
    {
      "epoch": 16.227710843373494,
      "grad_norm": 0.00019251182675361633,
      "learning_rate": 3.772289156626506e-06,
      "loss": 0.004,
      "step": 134690
    },
    {
      "epoch": 16.228915662650603,
      "grad_norm": 0.0003519968595355749,
      "learning_rate": 3.7710843373493977e-06,
      "loss": 0.0102,
      "step": 134700
    },
    {
      "epoch": 16.23012048192771,
      "grad_norm": 1.5462900400161743,
      "learning_rate": 3.7698795180722897e-06,
      "loss": 0.0068,
      "step": 134710
    },
    {
      "epoch": 16.23132530120482,
      "grad_norm": 0.00023574160877615213,
      "learning_rate": 3.768674698795181e-06,
      "loss": 0.0096,
      "step": 134720
    },
    {
      "epoch": 16.23253012048193,
      "grad_norm": 0.00025125793763436377,
      "learning_rate": 3.7674698795180725e-06,
      "loss": 0.012,
      "step": 134730
    },
    {
      "epoch": 16.233734939759035,
      "grad_norm": 1.8377900123596191,
      "learning_rate": 3.766265060240964e-06,
      "loss": 0.0386,
      "step": 134740
    },
    {
      "epoch": 16.234939759036145,
      "grad_norm": 0.000288808427285403,
      "learning_rate": 3.765060240963856e-06,
      "loss": 0.0019,
      "step": 134750
    },
    {
      "epoch": 16.236144578313255,
      "grad_norm": 0.00012604749645106494,
      "learning_rate": 3.7638554216867473e-06,
      "loss": 0.0029,
      "step": 134760
    },
    {
      "epoch": 16.23734939759036,
      "grad_norm": 0.28143590688705444,
      "learning_rate": 3.762650602409639e-06,
      "loss": 0.0323,
      "step": 134770
    },
    {
      "epoch": 16.23855421686747,
      "grad_norm": 0.3733822703361511,
      "learning_rate": 3.76144578313253e-06,
      "loss": 0.0124,
      "step": 134780
    },
    {
      "epoch": 16.23975903614458,
      "grad_norm": 0.00014100747648626566,
      "learning_rate": 3.760240963855422e-06,
      "loss": 0.0134,
      "step": 134790
    },
    {
      "epoch": 16.240963855421686,
      "grad_norm": 0.00011358836491126567,
      "learning_rate": 3.7590361445783136e-06,
      "loss": 0.0166,
      "step": 134800
    },
    {
      "epoch": 16.242168674698796,
      "grad_norm": 0.0012462992453947663,
      "learning_rate": 3.7578313253012048e-06,
      "loss": 0.0045,
      "step": 134810
    },
    {
      "epoch": 16.243373493975902,
      "grad_norm": 5.290471381158568e-05,
      "learning_rate": 3.7566265060240968e-06,
      "loss": 0.0228,
      "step": 134820
    },
    {
      "epoch": 16.24457831325301,
      "grad_norm": 0.0007145091658458114,
      "learning_rate": 3.7554216867469884e-06,
      "loss": 0.0001,
      "step": 134830
    },
    {
      "epoch": 16.24578313253012,
      "grad_norm": 0.6362113952636719,
      "learning_rate": 3.75421686746988e-06,
      "loss": 0.0132,
      "step": 134840
    },
    {
      "epoch": 16.246987951807228,
      "grad_norm": 0.00014058353553991765,
      "learning_rate": 3.753012048192771e-06,
      "loss": 0.0027,
      "step": 134850
    },
    {
      "epoch": 16.248192771084337,
      "grad_norm": 0.6599002480506897,
      "learning_rate": 3.751807228915663e-06,
      "loss": 0.0185,
      "step": 134860
    },
    {
      "epoch": 16.249397590361447,
      "grad_norm": 0.8890678882598877,
      "learning_rate": 3.7506024096385547e-06,
      "loss": 0.014,
      "step": 134870
    },
    {
      "epoch": 16.250602409638553,
      "grad_norm": 0.11482564359903336,
      "learning_rate": 3.749397590361446e-06,
      "loss": 0.0212,
      "step": 134880
    },
    {
      "epoch": 16.251807228915663,
      "grad_norm": 0.00022283656289801002,
      "learning_rate": 3.7481927710843375e-06,
      "loss": 0.0226,
      "step": 134890
    },
    {
      "epoch": 16.253012048192772,
      "grad_norm": 2.1192429065704346,
      "learning_rate": 3.7469879518072295e-06,
      "loss": 0.0134,
      "step": 134900
    },
    {
      "epoch": 16.25421686746988,
      "grad_norm": 0.00014194948016665876,
      "learning_rate": 3.7457831325301207e-06,
      "loss": 0.0175,
      "step": 134910
    },
    {
      "epoch": 16.25542168674699,
      "grad_norm": 0.00021758164803031832,
      "learning_rate": 3.7445783132530122e-06,
      "loss": 0.0116,
      "step": 134920
    },
    {
      "epoch": 16.256626506024098,
      "grad_norm": 0.00020504309213720262,
      "learning_rate": 3.743373493975904e-06,
      "loss": 0.0155,
      "step": 134930
    },
    {
      "epoch": 16.257831325301204,
      "grad_norm": 0.0003027909842785448,
      "learning_rate": 3.742168674698796e-06,
      "loss": 0.0211,
      "step": 134940
    },
    {
      "epoch": 16.259036144578314,
      "grad_norm": 0.6070569753646851,
      "learning_rate": 3.740963855421687e-06,
      "loss": 0.0122,
      "step": 134950
    },
    {
      "epoch": 16.26024096385542,
      "grad_norm": 0.0005560267600230873,
      "learning_rate": 3.7397590361445786e-06,
      "loss": 0.0039,
      "step": 134960
    },
    {
      "epoch": 16.26144578313253,
      "grad_norm": 0.0003456761478446424,
      "learning_rate": 3.7385542168674706e-06,
      "loss": 0.0229,
      "step": 134970
    },
    {
      "epoch": 16.26265060240964,
      "grad_norm": 0.3032585382461548,
      "learning_rate": 3.7373493975903618e-06,
      "loss": 0.0017,
      "step": 134980
    },
    {
      "epoch": 16.263855421686745,
      "grad_norm": 0.00031813819077797234,
      "learning_rate": 3.7361445783132534e-06,
      "loss": 0.0192,
      "step": 134990
    },
    {
      "epoch": 16.265060240963855,
      "grad_norm": 0.2917100191116333,
      "learning_rate": 3.7349397590361445e-06,
      "loss": 0.0431,
      "step": 135000
    },
    {
      "epoch": 16.266265060240965,
      "grad_norm": 0.0019327773479744792,
      "learning_rate": 3.7337349397590365e-06,
      "loss": 0.0059,
      "step": 135010
    },
    {
      "epoch": 16.26746987951807,
      "grad_norm": 0.259388267993927,
      "learning_rate": 3.732530120481928e-06,
      "loss": 0.0024,
      "step": 135020
    },
    {
      "epoch": 16.26867469879518,
      "grad_norm": 0.00024229034897871315,
      "learning_rate": 3.7313253012048197e-06,
      "loss": 0.0077,
      "step": 135030
    },
    {
      "epoch": 16.26987951807229,
      "grad_norm": 1.6239478588104248,
      "learning_rate": 3.730120481927711e-06,
      "loss": 0.0147,
      "step": 135040
    },
    {
      "epoch": 16.271084337349397,
      "grad_norm": 0.011857951059937477,
      "learning_rate": 3.728915662650603e-06,
      "loss": 0.0093,
      "step": 135050
    },
    {
      "epoch": 16.272289156626506,
      "grad_norm": 1.9328083992004395,
      "learning_rate": 3.7277108433734945e-06,
      "loss": 0.033,
      "step": 135060
    },
    {
      "epoch": 16.273493975903616,
      "grad_norm": 2.038813352584839,
      "learning_rate": 3.7265060240963856e-06,
      "loss": 0.0302,
      "step": 135070
    },
    {
      "epoch": 16.274698795180722,
      "grad_norm": 0.0005464860005304217,
      "learning_rate": 3.7253012048192772e-06,
      "loss": 0.0083,
      "step": 135080
    },
    {
      "epoch": 16.27590361445783,
      "grad_norm": 0.0002503151772543788,
      "learning_rate": 3.7240963855421692e-06,
      "loss": 0.0275,
      "step": 135090
    },
    {
      "epoch": 16.27710843373494,
      "grad_norm": 1.2466548681259155,
      "learning_rate": 3.7228915662650604e-06,
      "loss": 0.0083,
      "step": 135100
    },
    {
      "epoch": 16.278313253012048,
      "grad_norm": 0.0003086616634391248,
      "learning_rate": 3.721686746987952e-06,
      "loss": 0.0106,
      "step": 135110
    },
    {
      "epoch": 16.279518072289157,
      "grad_norm": 4.3723859786987305,
      "learning_rate": 3.720481927710844e-06,
      "loss": 0.0107,
      "step": 135120
    },
    {
      "epoch": 16.280722891566263,
      "grad_norm": 0.00013165376731194556,
      "learning_rate": 3.719277108433735e-06,
      "loss": 0.0052,
      "step": 135130
    },
    {
      "epoch": 16.281927710843373,
      "grad_norm": 0.00014601662405766547,
      "learning_rate": 3.7180722891566268e-06,
      "loss": 0.0049,
      "step": 135140
    },
    {
      "epoch": 16.283132530120483,
      "grad_norm": 0.00013660469267051667,
      "learning_rate": 3.7168674698795183e-06,
      "loss": 0.0063,
      "step": 135150
    },
    {
      "epoch": 16.28433734939759,
      "grad_norm": 0.00040194179746322334,
      "learning_rate": 3.7156626506024104e-06,
      "loss": 0.0148,
      "step": 135160
    },
    {
      "epoch": 16.2855421686747,
      "grad_norm": 1.9905824661254883,
      "learning_rate": 3.7144578313253015e-06,
      "loss": 0.0124,
      "step": 135170
    },
    {
      "epoch": 16.28674698795181,
      "grad_norm": 0.15752363204956055,
      "learning_rate": 3.713253012048193e-06,
      "loss": 0.0204,
      "step": 135180
    },
    {
      "epoch": 16.287951807228914,
      "grad_norm": 1.9380251169204712,
      "learning_rate": 3.7120481927710843e-06,
      "loss": 0.0164,
      "step": 135190
    },
    {
      "epoch": 16.289156626506024,
      "grad_norm": 0.7030616998672485,
      "learning_rate": 3.7108433734939763e-06,
      "loss": 0.0213,
      "step": 135200
    },
    {
      "epoch": 16.290361445783134,
      "grad_norm": 0.000311481358949095,
      "learning_rate": 3.709638554216868e-06,
      "loss": 0.016,
      "step": 135210
    },
    {
      "epoch": 16.29156626506024,
      "grad_norm": 0.9451345205307007,
      "learning_rate": 3.708433734939759e-06,
      "loss": 0.0286,
      "step": 135220
    },
    {
      "epoch": 16.29277108433735,
      "grad_norm": 0.002106104977428913,
      "learning_rate": 3.7072289156626506e-06,
      "loss": 0.0,
      "step": 135230
    },
    {
      "epoch": 16.29397590361446,
      "grad_norm": 0.6984819769859314,
      "learning_rate": 3.7060240963855426e-06,
      "loss": 0.0104,
      "step": 135240
    },
    {
      "epoch": 16.295180722891565,
      "grad_norm": 0.0002394348121015355,
      "learning_rate": 3.7048192771084342e-06,
      "loss": 0.0195,
      "step": 135250
    },
    {
      "epoch": 16.296385542168675,
      "grad_norm": 0.0016555462498217821,
      "learning_rate": 3.7036144578313254e-06,
      "loss": 0.0149,
      "step": 135260
    },
    {
      "epoch": 16.297590361445785,
      "grad_norm": 0.0004416900046635419,
      "learning_rate": 3.7024096385542174e-06,
      "loss": 0.0063,
      "step": 135270
    },
    {
      "epoch": 16.29879518072289,
      "grad_norm": 0.0001796058495528996,
      "learning_rate": 3.701204819277109e-06,
      "loss": 0.0139,
      "step": 135280
    },
    {
      "epoch": 16.3,
      "grad_norm": 0.0005629999213851988,
      "learning_rate": 3.7e-06,
      "loss": 0.0095,
      "step": 135290
    },
    {
      "epoch": 16.301204819277107,
      "grad_norm": 0.0001769805676303804,
      "learning_rate": 3.6987951807228917e-06,
      "loss": 0.0279,
      "step": 135300
    },
    {
      "epoch": 16.302409638554217,
      "grad_norm": 0.00023376315948553383,
      "learning_rate": 3.6975903614457837e-06,
      "loss": 0.0036,
      "step": 135310
    },
    {
      "epoch": 16.303614457831326,
      "grad_norm": 1.595467448234558,
      "learning_rate": 3.696385542168675e-06,
      "loss": 0.0129,
      "step": 135320
    },
    {
      "epoch": 16.304819277108432,
      "grad_norm": 0.0014163198648020625,
      "learning_rate": 3.6951807228915665e-06,
      "loss": 0.0146,
      "step": 135330
    },
    {
      "epoch": 16.306024096385542,
      "grad_norm": 5.931041717529297,
      "learning_rate": 3.693975903614458e-06,
      "loss": 0.0282,
      "step": 135340
    },
    {
      "epoch": 16.30722891566265,
      "grad_norm": 8.801906369626522e-05,
      "learning_rate": 3.6927710843373497e-06,
      "loss": 0.0025,
      "step": 135350
    },
    {
      "epoch": 16.308433734939758,
      "grad_norm": 1.5570752620697021,
      "learning_rate": 3.6915662650602413e-06,
      "loss": 0.0078,
      "step": 135360
    },
    {
      "epoch": 16.309638554216868,
      "grad_norm": 0.00011757362517528236,
      "learning_rate": 3.690361445783133e-06,
      "loss": 0.0487,
      "step": 135370
    },
    {
      "epoch": 16.310843373493977,
      "grad_norm": 0.43643879890441895,
      "learning_rate": 3.689156626506024e-06,
      "loss": 0.0168,
      "step": 135380
    },
    {
      "epoch": 16.312048192771083,
      "grad_norm": 0.00017745680816005915,
      "learning_rate": 3.687951807228916e-06,
      "loss": 0.0053,
      "step": 135390
    },
    {
      "epoch": 16.313253012048193,
      "grad_norm": 0.00020351105195004493,
      "learning_rate": 3.6867469879518076e-06,
      "loss": 0.0116,
      "step": 135400
    },
    {
      "epoch": 16.314457831325303,
      "grad_norm": 0.015800945460796356,
      "learning_rate": 3.6855421686746988e-06,
      "loss": 0.0062,
      "step": 135410
    },
    {
      "epoch": 16.31566265060241,
      "grad_norm": 0.25919973850250244,
      "learning_rate": 3.684337349397591e-06,
      "loss": 0.0065,
      "step": 135420
    },
    {
      "epoch": 16.31686746987952,
      "grad_norm": 0.7765931487083435,
      "learning_rate": 3.6831325301204824e-06,
      "loss": 0.0053,
      "step": 135430
    },
    {
      "epoch": 16.318072289156625,
      "grad_norm": 1.522628903388977,
      "learning_rate": 3.6819277108433735e-06,
      "loss": 0.0253,
      "step": 135440
    },
    {
      "epoch": 16.319277108433734,
      "grad_norm": 0.0001332019455730915,
      "learning_rate": 3.680722891566265e-06,
      "loss": 0.0096,
      "step": 135450
    },
    {
      "epoch": 16.320481927710844,
      "grad_norm": 0.0003844625025521964,
      "learning_rate": 3.679518072289157e-06,
      "loss": 0.0047,
      "step": 135460
    },
    {
      "epoch": 16.32168674698795,
      "grad_norm": 0.4735139012336731,
      "learning_rate": 3.6783132530120487e-06,
      "loss": 0.0543,
      "step": 135470
    },
    {
      "epoch": 16.32289156626506,
      "grad_norm": 0.32132065296173096,
      "learning_rate": 3.67710843373494e-06,
      "loss": 0.0059,
      "step": 135480
    },
    {
      "epoch": 16.32409638554217,
      "grad_norm": 0.00026858982164412737,
      "learning_rate": 3.6759036144578315e-06,
      "loss": 0.0149,
      "step": 135490
    },
    {
      "epoch": 16.325301204819276,
      "grad_norm": 0.2699194848537445,
      "learning_rate": 3.6746987951807235e-06,
      "loss": 0.0029,
      "step": 135500
    },
    {
      "epoch": 16.326506024096386,
      "grad_norm": 0.32694077491760254,
      "learning_rate": 3.6734939759036147e-06,
      "loss": 0.0073,
      "step": 135510
    },
    {
      "epoch": 16.327710843373495,
      "grad_norm": 0.0018274437170475721,
      "learning_rate": 3.6722891566265063e-06,
      "loss": 0.0246,
      "step": 135520
    },
    {
      "epoch": 16.3289156626506,
      "grad_norm": 0.00017076876247301698,
      "learning_rate": 3.6710843373493974e-06,
      "loss": 0.0128,
      "step": 135530
    },
    {
      "epoch": 16.33012048192771,
      "grad_norm": 0.9063870310783386,
      "learning_rate": 3.6698795180722894e-06,
      "loss": 0.0264,
      "step": 135540
    },
    {
      "epoch": 16.33132530120482,
      "grad_norm": 1.5995826721191406,
      "learning_rate": 3.668674698795181e-06,
      "loss": 0.0372,
      "step": 135550
    },
    {
      "epoch": 16.332530120481927,
      "grad_norm": 0.0009885678300634027,
      "learning_rate": 3.6674698795180726e-06,
      "loss": 0.0032,
      "step": 135560
    },
    {
      "epoch": 16.333734939759037,
      "grad_norm": 0.31718289852142334,
      "learning_rate": 3.666265060240964e-06,
      "loss": 0.0032,
      "step": 135570
    },
    {
      "epoch": 16.334939759036146,
      "grad_norm": 0.0005262684426270425,
      "learning_rate": 3.6650602409638558e-06,
      "loss": 0.0163,
      "step": 135580
    },
    {
      "epoch": 16.336144578313252,
      "grad_norm": 0.000682638434227556,
      "learning_rate": 3.6638554216867474e-06,
      "loss": 0.0059,
      "step": 135590
    },
    {
      "epoch": 16.337349397590362,
      "grad_norm": 0.2933971583843231,
      "learning_rate": 3.6626506024096385e-06,
      "loss": 0.0138,
      "step": 135600
    },
    {
      "epoch": 16.33855421686747,
      "grad_norm": 0.18188773095607758,
      "learning_rate": 3.6614457831325305e-06,
      "loss": 0.0004,
      "step": 135610
    },
    {
      "epoch": 16.339759036144578,
      "grad_norm": 1.6934566497802734,
      "learning_rate": 3.660240963855422e-06,
      "loss": 0.011,
      "step": 135620
    },
    {
      "epoch": 16.340963855421688,
      "grad_norm": 0.0002815673069562763,
      "learning_rate": 3.6590361445783133e-06,
      "loss": 0.0103,
      "step": 135630
    },
    {
      "epoch": 16.342168674698794,
      "grad_norm": 0.24318185448646545,
      "learning_rate": 3.657831325301205e-06,
      "loss": 0.0059,
      "step": 135640
    },
    {
      "epoch": 16.343373493975903,
      "grad_norm": 0.0007696317625232041,
      "learning_rate": 3.656626506024097e-06,
      "loss": 0.021,
      "step": 135650
    },
    {
      "epoch": 16.344578313253013,
      "grad_norm": 0.28069397807121277,
      "learning_rate": 3.6554216867469885e-06,
      "loss": 0.0117,
      "step": 135660
    },
    {
      "epoch": 16.34578313253012,
      "grad_norm": 0.35301676392555237,
      "learning_rate": 3.6542168674698796e-06,
      "loss": 0.0093,
      "step": 135670
    },
    {
      "epoch": 16.34698795180723,
      "grad_norm": 0.0002024687419179827,
      "learning_rate": 3.6530120481927712e-06,
      "loss": 0.0073,
      "step": 135680
    },
    {
      "epoch": 16.34819277108434,
      "grad_norm": 0.2124929130077362,
      "learning_rate": 3.6518072289156632e-06,
      "loss": 0.0082,
      "step": 135690
    },
    {
      "epoch": 16.349397590361445,
      "grad_norm": 0.00042959334678016603,
      "learning_rate": 3.6506024096385544e-06,
      "loss": 0.0463,
      "step": 135700
    },
    {
      "epoch": 16.350602409638554,
      "grad_norm": 0.0008432787726633251,
      "learning_rate": 3.649397590361446e-06,
      "loss": 0.0249,
      "step": 135710
    },
    {
      "epoch": 16.351807228915664,
      "grad_norm": 1.6068321466445923,
      "learning_rate": 3.648192771084338e-06,
      "loss": 0.0209,
      "step": 135720
    },
    {
      "epoch": 16.35301204819277,
      "grad_norm": 0.00020926521392539144,
      "learning_rate": 3.646987951807229e-06,
      "loss": 0.0055,
      "step": 135730
    },
    {
      "epoch": 16.35421686746988,
      "grad_norm": 0.0006645701359957457,
      "learning_rate": 3.6457831325301208e-06,
      "loss": 0.0232,
      "step": 135740
    },
    {
      "epoch": 16.355421686746986,
      "grad_norm": 0.17987345159053802,
      "learning_rate": 3.6445783132530124e-06,
      "loss": 0.0111,
      "step": 135750
    },
    {
      "epoch": 16.356626506024096,
      "grad_norm": 0.012000764720141888,
      "learning_rate": 3.643373493975904e-06,
      "loss": 0.0058,
      "step": 135760
    },
    {
      "epoch": 16.357831325301206,
      "grad_norm": 0.00015522494504693896,
      "learning_rate": 3.6421686746987955e-06,
      "loss": 0.0036,
      "step": 135770
    },
    {
      "epoch": 16.35903614457831,
      "grad_norm": 0.0003579123876988888,
      "learning_rate": 3.640963855421687e-06,
      "loss": 0.0151,
      "step": 135780
    },
    {
      "epoch": 16.36024096385542,
      "grad_norm": 1.1583802700042725,
      "learning_rate": 3.6397590361445783e-06,
      "loss": 0.0063,
      "step": 135790
    },
    {
      "epoch": 16.36144578313253,
      "grad_norm": 8.86900961631909e-05,
      "learning_rate": 3.6385542168674703e-06,
      "loss": 0.0091,
      "step": 135800
    },
    {
      "epoch": 16.362650602409637,
      "grad_norm": 0.2559739649295807,
      "learning_rate": 3.637349397590362e-06,
      "loss": 0.01,
      "step": 135810
    },
    {
      "epoch": 16.363855421686747,
      "grad_norm": 0.0002365965920034796,
      "learning_rate": 3.636144578313253e-06,
      "loss": 0.0179,
      "step": 135820
    },
    {
      "epoch": 16.365060240963857,
      "grad_norm": 1.284011721611023,
      "learning_rate": 3.6349397590361446e-06,
      "loss": 0.0165,
      "step": 135830
    },
    {
      "epoch": 16.366265060240963,
      "grad_norm": 0.9743489623069763,
      "learning_rate": 3.6337349397590366e-06,
      "loss": 0.01,
      "step": 135840
    },
    {
      "epoch": 16.367469879518072,
      "grad_norm": 0.0006892026285640895,
      "learning_rate": 3.632530120481928e-06,
      "loss": 0.0054,
      "step": 135850
    },
    {
      "epoch": 16.368674698795182,
      "grad_norm": 0.00012323123519308865,
      "learning_rate": 3.6313253012048194e-06,
      "loss": 0.0066,
      "step": 135860
    },
    {
      "epoch": 16.36987951807229,
      "grad_norm": 0.0004059210477862507,
      "learning_rate": 3.6301204819277114e-06,
      "loss": 0.027,
      "step": 135870
    },
    {
      "epoch": 16.371084337349398,
      "grad_norm": 0.0002855963830370456,
      "learning_rate": 3.628915662650603e-06,
      "loss": 0.026,
      "step": 135880
    },
    {
      "epoch": 16.372289156626508,
      "grad_norm": 0.9116164445877075,
      "learning_rate": 3.627710843373494e-06,
      "loss": 0.0068,
      "step": 135890
    },
    {
      "epoch": 16.373493975903614,
      "grad_norm": 0.25083664059638977,
      "learning_rate": 3.6265060240963857e-06,
      "loss": 0.0163,
      "step": 135900
    },
    {
      "epoch": 16.374698795180723,
      "grad_norm": 0.0009146348456852138,
      "learning_rate": 3.6253012048192778e-06,
      "loss": 0.0077,
      "step": 135910
    },
    {
      "epoch": 16.37590361445783,
      "grad_norm": 0.96006178855896,
      "learning_rate": 3.624096385542169e-06,
      "loss": 0.0526,
      "step": 135920
    },
    {
      "epoch": 16.37710843373494,
      "grad_norm": 0.00036237799213267863,
      "learning_rate": 3.6228915662650605e-06,
      "loss": 0.0017,
      "step": 135930
    },
    {
      "epoch": 16.37831325301205,
      "grad_norm": 1.368813157081604,
      "learning_rate": 3.6216867469879517e-06,
      "loss": 0.0175,
      "step": 135940
    },
    {
      "epoch": 16.379518072289155,
      "grad_norm": 0.0006809487822465599,
      "learning_rate": 3.6204819277108437e-06,
      "loss": 0.0025,
      "step": 135950
    },
    {
      "epoch": 16.380722891566265,
      "grad_norm": 0.0020857711788266897,
      "learning_rate": 3.6192771084337353e-06,
      "loss": 0.0121,
      "step": 135960
    },
    {
      "epoch": 16.381927710843375,
      "grad_norm": 0.00013638769451063126,
      "learning_rate": 3.618072289156627e-06,
      "loss": 0.0078,
      "step": 135970
    },
    {
      "epoch": 16.38313253012048,
      "grad_norm": 0.9300960898399353,
      "learning_rate": 3.6168674698795185e-06,
      "loss": 0.0133,
      "step": 135980
    },
    {
      "epoch": 16.38433734939759,
      "grad_norm": 0.13481707870960236,
      "learning_rate": 3.61566265060241e-06,
      "loss": 0.0292,
      "step": 135990
    },
    {
      "epoch": 16.3855421686747,
      "grad_norm": 0.0007564248517155647,
      "learning_rate": 3.6144578313253016e-06,
      "loss": 0.0014,
      "step": 136000
    },
    {
      "epoch": 16.386746987951806,
      "grad_norm": 4.4434814453125,
      "learning_rate": 3.613253012048193e-06,
      "loss": 0.0211,
      "step": 136010
    },
    {
      "epoch": 16.387951807228916,
      "grad_norm": 0.00017005670815706253,
      "learning_rate": 3.612048192771085e-06,
      "loss": 0.0058,
      "step": 136020
    },
    {
      "epoch": 16.389156626506026,
      "grad_norm": 1.049293875694275,
      "learning_rate": 3.6108433734939764e-06,
      "loss": 0.0082,
      "step": 136030
    },
    {
      "epoch": 16.39036144578313,
      "grad_norm": 0.00022127277043182403,
      "learning_rate": 3.6096385542168676e-06,
      "loss": 0.0008,
      "step": 136040
    },
    {
      "epoch": 16.39156626506024,
      "grad_norm": 0.0001266184845007956,
      "learning_rate": 3.608433734939759e-06,
      "loss": 0.0063,
      "step": 136050
    },
    {
      "epoch": 16.39277108433735,
      "grad_norm": 0.0001763766340445727,
      "learning_rate": 3.607228915662651e-06,
      "loss": 0.0088,
      "step": 136060
    },
    {
      "epoch": 16.393975903614457,
      "grad_norm": 1.9007726907730103,
      "learning_rate": 3.6060240963855423e-06,
      "loss": 0.0193,
      "step": 136070
    },
    {
      "epoch": 16.395180722891567,
      "grad_norm": 0.12814733386039734,
      "learning_rate": 3.604819277108434e-06,
      "loss": 0.014,
      "step": 136080
    },
    {
      "epoch": 16.396385542168673,
      "grad_norm": 0.0001815139694372192,
      "learning_rate": 3.6036144578313255e-06,
      "loss": 0.0131,
      "step": 136090
    },
    {
      "epoch": 16.397590361445783,
      "grad_norm": 2.528212070465088,
      "learning_rate": 3.6024096385542175e-06,
      "loss": 0.0146,
      "step": 136100
    },
    {
      "epoch": 16.398795180722892,
      "grad_norm": 0.00021407146414276212,
      "learning_rate": 3.6012048192771087e-06,
      "loss": 0.0232,
      "step": 136110
    },
    {
      "epoch": 16.4,
      "grad_norm": 0.8847301602363586,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.0273,
      "step": 136120
    },
    {
      "epoch": 16.40120481927711,
      "grad_norm": 0.08158160001039505,
      "learning_rate": 3.5987951807228923e-06,
      "loss": 0.0048,
      "step": 136130
    },
    {
      "epoch": 16.402409638554218,
      "grad_norm": 0.9847273826599121,
      "learning_rate": 3.5975903614457834e-06,
      "loss": 0.0175,
      "step": 136140
    },
    {
      "epoch": 16.403614457831324,
      "grad_norm": 0.00019994280592072755,
      "learning_rate": 3.596385542168675e-06,
      "loss": 0.005,
      "step": 136150
    },
    {
      "epoch": 16.404819277108434,
      "grad_norm": 0.00342688150703907,
      "learning_rate": 3.595180722891566e-06,
      "loss": 0.0151,
      "step": 136160
    },
    {
      "epoch": 16.406024096385543,
      "grad_norm": 0.00011206927592866123,
      "learning_rate": 3.593975903614458e-06,
      "loss": 0.0105,
      "step": 136170
    },
    {
      "epoch": 16.40722891566265,
      "grad_norm": 0.00014322518836706877,
      "learning_rate": 3.59277108433735e-06,
      "loss": 0.0042,
      "step": 136180
    },
    {
      "epoch": 16.40843373493976,
      "grad_norm": 1.1113371849060059,
      "learning_rate": 3.5915662650602414e-06,
      "loss": 0.0073,
      "step": 136190
    },
    {
      "epoch": 16.40963855421687,
      "grad_norm": 0.0009518589358776808,
      "learning_rate": 3.5903614457831325e-06,
      "loss": 0.0027,
      "step": 136200
    },
    {
      "epoch": 16.410843373493975,
      "grad_norm": 0.00016231334302574396,
      "learning_rate": 3.5891566265060246e-06,
      "loss": 0.0032,
      "step": 136210
    },
    {
      "epoch": 16.412048192771085,
      "grad_norm": 0.00011460033420007676,
      "learning_rate": 3.587951807228916e-06,
      "loss": 0.0093,
      "step": 136220
    },
    {
      "epoch": 16.413253012048195,
      "grad_norm": 1.1908979415893555,
      "learning_rate": 3.5867469879518073e-06,
      "loss": 0.0063,
      "step": 136230
    },
    {
      "epoch": 16.4144578313253,
      "grad_norm": 0.00028984335949644446,
      "learning_rate": 3.585542168674699e-06,
      "loss": 0.0109,
      "step": 136240
    },
    {
      "epoch": 16.41566265060241,
      "grad_norm": 1.8569196462631226,
      "learning_rate": 3.584337349397591e-06,
      "loss": 0.0171,
      "step": 136250
    },
    {
      "epoch": 16.416867469879517,
      "grad_norm": 0.00025879943859763443,
      "learning_rate": 3.583132530120482e-06,
      "loss": 0.0253,
      "step": 136260
    },
    {
      "epoch": 16.418072289156626,
      "grad_norm": 0.4598797857761383,
      "learning_rate": 3.5819277108433737e-06,
      "loss": 0.0288,
      "step": 136270
    },
    {
      "epoch": 16.419277108433736,
      "grad_norm": 0.0006190560525283217,
      "learning_rate": 3.5807228915662657e-06,
      "loss": 0.0001,
      "step": 136280
    },
    {
      "epoch": 16.420481927710842,
      "grad_norm": 6.191363334655762,
      "learning_rate": 3.579518072289157e-06,
      "loss": 0.0064,
      "step": 136290
    },
    {
      "epoch": 16.42168674698795,
      "grad_norm": 0.000131602690089494,
      "learning_rate": 3.5783132530120484e-06,
      "loss": 0.0005,
      "step": 136300
    },
    {
      "epoch": 16.42289156626506,
      "grad_norm": 0.9770348072052002,
      "learning_rate": 3.57710843373494e-06,
      "loss": 0.0074,
      "step": 136310
    },
    {
      "epoch": 16.424096385542168,
      "grad_norm": 0.07758300006389618,
      "learning_rate": 3.575903614457832e-06,
      "loss": 0.0308,
      "step": 136320
    },
    {
      "epoch": 16.425301204819277,
      "grad_norm": 0.00017077002848964185,
      "learning_rate": 3.574698795180723e-06,
      "loss": 0.0152,
      "step": 136330
    },
    {
      "epoch": 16.426506024096387,
      "grad_norm": 0.0023573082871735096,
      "learning_rate": 3.5734939759036148e-06,
      "loss": 0.0102,
      "step": 136340
    },
    {
      "epoch": 16.427710843373493,
      "grad_norm": 0.005960426758974791,
      "learning_rate": 3.572289156626506e-06,
      "loss": 0.0057,
      "step": 136350
    },
    {
      "epoch": 16.428915662650603,
      "grad_norm": 0.0005605773767456412,
      "learning_rate": 3.571084337349398e-06,
      "loss": 0.0079,
      "step": 136360
    },
    {
      "epoch": 16.430120481927712,
      "grad_norm": 0.0002555188548285514,
      "learning_rate": 3.5698795180722895e-06,
      "loss": 0.0204,
      "step": 136370
    },
    {
      "epoch": 16.43132530120482,
      "grad_norm": 0.001127769472077489,
      "learning_rate": 3.568674698795181e-06,
      "loss": 0.0563,
      "step": 136380
    },
    {
      "epoch": 16.43253012048193,
      "grad_norm": 0.00039616323192603886,
      "learning_rate": 3.5674698795180723e-06,
      "loss": 0.0094,
      "step": 136390
    },
    {
      "epoch": 16.433734939759034,
      "grad_norm": 0.8856770396232605,
      "learning_rate": 3.5662650602409643e-06,
      "loss": 0.0219,
      "step": 136400
    },
    {
      "epoch": 16.434939759036144,
      "grad_norm": 0.0009559498867020011,
      "learning_rate": 3.565060240963856e-06,
      "loss": 0.0371,
      "step": 136410
    },
    {
      "epoch": 16.436144578313254,
      "grad_norm": 0.001598820905201137,
      "learning_rate": 3.563855421686747e-06,
      "loss": 0.0085,
      "step": 136420
    },
    {
      "epoch": 16.43734939759036,
      "grad_norm": 0.0011480852263048291,
      "learning_rate": 3.562650602409639e-06,
      "loss": 0.0167,
      "step": 136430
    },
    {
      "epoch": 16.43855421686747,
      "grad_norm": 2.2968432903289795,
      "learning_rate": 3.5614457831325307e-06,
      "loss": 0.017,
      "step": 136440
    },
    {
      "epoch": 16.43975903614458,
      "grad_norm": 2.053145408630371,
      "learning_rate": 3.560240963855422e-06,
      "loss": 0.0121,
      "step": 136450
    },
    {
      "epoch": 16.440963855421685,
      "grad_norm": 0.0002586265036370605,
      "learning_rate": 3.5590361445783134e-06,
      "loss": 0.0044,
      "step": 136460
    },
    {
      "epoch": 16.442168674698795,
      "grad_norm": 0.013161995448172092,
      "learning_rate": 3.5578313253012054e-06,
      "loss": 0.0043,
      "step": 136470
    },
    {
      "epoch": 16.443373493975905,
      "grad_norm": 0.8656080365180969,
      "learning_rate": 3.5566265060240966e-06,
      "loss": 0.0026,
      "step": 136480
    },
    {
      "epoch": 16.44457831325301,
      "grad_norm": 0.04059801995754242,
      "learning_rate": 3.555421686746988e-06,
      "loss": 0.0005,
      "step": 136490
    },
    {
      "epoch": 16.44578313253012,
      "grad_norm": 0.10339872539043427,
      "learning_rate": 3.5542168674698798e-06,
      "loss": 0.0099,
      "step": 136500
    },
    {
      "epoch": 16.44698795180723,
      "grad_norm": 0.6149405241012573,
      "learning_rate": 3.5530120481927718e-06,
      "loss": 0.0015,
      "step": 136510
    },
    {
      "epoch": 16.448192771084337,
      "grad_norm": 0.0005732065765187144,
      "learning_rate": 3.551807228915663e-06,
      "loss": 0.0076,
      "step": 136520
    },
    {
      "epoch": 16.449397590361446,
      "grad_norm": 0.562898576259613,
      "learning_rate": 3.5506024096385545e-06,
      "loss": 0.0027,
      "step": 136530
    },
    {
      "epoch": 16.450602409638556,
      "grad_norm": 0.0004981740494258702,
      "learning_rate": 3.5493975903614457e-06,
      "loss": 0.0038,
      "step": 136540
    },
    {
      "epoch": 16.451807228915662,
      "grad_norm": 0.0014015591004863381,
      "learning_rate": 3.5481927710843377e-06,
      "loss": 0.0166,
      "step": 136550
    },
    {
      "epoch": 16.45301204819277,
      "grad_norm": 0.00026995327789336443,
      "learning_rate": 3.5469879518072293e-06,
      "loss": 0.0176,
      "step": 136560
    },
    {
      "epoch": 16.454216867469878,
      "grad_norm": 0.000277177692623809,
      "learning_rate": 3.5457831325301205e-06,
      "loss": 0.0318,
      "step": 136570
    },
    {
      "epoch": 16.455421686746988,
      "grad_norm": 0.014880192466080189,
      "learning_rate": 3.5445783132530125e-06,
      "loss": 0.016,
      "step": 136580
    },
    {
      "epoch": 16.456626506024097,
      "grad_norm": 0.0012230805587023497,
      "learning_rate": 3.543373493975904e-06,
      "loss": 0.0497,
      "step": 136590
    },
    {
      "epoch": 16.457831325301203,
      "grad_norm": 0.0007205271394923329,
      "learning_rate": 3.5421686746987956e-06,
      "loss": 0.014,
      "step": 136600
    },
    {
      "epoch": 16.459036144578313,
      "grad_norm": 0.001162378815934062,
      "learning_rate": 3.540963855421687e-06,
      "loss": 0.0195,
      "step": 136610
    },
    {
      "epoch": 16.460240963855423,
      "grad_norm": 0.16470834612846375,
      "learning_rate": 3.539759036144579e-06,
      "loss": 0.0114,
      "step": 136620
    },
    {
      "epoch": 16.46144578313253,
      "grad_norm": 0.0017896040808409452,
      "learning_rate": 3.5385542168674704e-06,
      "loss": 0.0613,
      "step": 136630
    },
    {
      "epoch": 16.46265060240964,
      "grad_norm": 0.0007072295411489904,
      "learning_rate": 3.5373493975903616e-06,
      "loss": 0.0118,
      "step": 136640
    },
    {
      "epoch": 16.46385542168675,
      "grad_norm": 0.8329785466194153,
      "learning_rate": 3.536144578313253e-06,
      "loss": 0.011,
      "step": 136650
    },
    {
      "epoch": 16.465060240963854,
      "grad_norm": 0.8393959999084473,
      "learning_rate": 3.534939759036145e-06,
      "loss": 0.0137,
      "step": 136660
    },
    {
      "epoch": 16.466265060240964,
      "grad_norm": 0.9217638373374939,
      "learning_rate": 3.5337349397590363e-06,
      "loss": 0.0076,
      "step": 136670
    },
    {
      "epoch": 16.467469879518074,
      "grad_norm": 0.0005971981445327401,
      "learning_rate": 3.532530120481928e-06,
      "loss": 0.0028,
      "step": 136680
    },
    {
      "epoch": 16.46867469879518,
      "grad_norm": 0.1499987542629242,
      "learning_rate": 3.5313253012048195e-06,
      "loss": 0.0053,
      "step": 136690
    },
    {
      "epoch": 16.46987951807229,
      "grad_norm": 0.0005424683913588524,
      "learning_rate": 3.530120481927711e-06,
      "loss": 0.002,
      "step": 136700
    },
    {
      "epoch": 16.471084337349396,
      "grad_norm": 0.048956409096717834,
      "learning_rate": 3.5289156626506027e-06,
      "loss": 0.0162,
      "step": 136710
    },
    {
      "epoch": 16.472289156626506,
      "grad_norm": 0.0007008580141700804,
      "learning_rate": 3.5277108433734943e-06,
      "loss": 0.0045,
      "step": 136720
    },
    {
      "epoch": 16.473493975903615,
      "grad_norm": 0.0012601728085428476,
      "learning_rate": 3.5265060240963863e-06,
      "loss": 0.0124,
      "step": 136730
    },
    {
      "epoch": 16.47469879518072,
      "grad_norm": 0.0014848534483462572,
      "learning_rate": 3.5253012048192774e-06,
      "loss": 0.0049,
      "step": 136740
    },
    {
      "epoch": 16.47590361445783,
      "grad_norm": 0.0028283940628170967,
      "learning_rate": 3.524096385542169e-06,
      "loss": 0.0052,
      "step": 136750
    },
    {
      "epoch": 16.47710843373494,
      "grad_norm": 0.0008417911594733596,
      "learning_rate": 3.52289156626506e-06,
      "loss": 0.0107,
      "step": 136760
    },
    {
      "epoch": 16.478313253012047,
      "grad_norm": 0.8195905089378357,
      "learning_rate": 3.521686746987952e-06,
      "loss": 0.0376,
      "step": 136770
    },
    {
      "epoch": 16.479518072289157,
      "grad_norm": 0.015516632236540318,
      "learning_rate": 3.520481927710844e-06,
      "loss": 0.0557,
      "step": 136780
    },
    {
      "epoch": 16.480722891566266,
      "grad_norm": 1.955855369567871,
      "learning_rate": 3.519277108433735e-06,
      "loss": 0.0267,
      "step": 136790
    },
    {
      "epoch": 16.481927710843372,
      "grad_norm": 0.005869181826710701,
      "learning_rate": 3.5180722891566266e-06,
      "loss": 0.0139,
      "step": 136800
    },
    {
      "epoch": 16.483132530120482,
      "grad_norm": 0.0676962360739708,
      "learning_rate": 3.5168674698795186e-06,
      "loss": 0.0084,
      "step": 136810
    },
    {
      "epoch": 16.48433734939759,
      "grad_norm": 0.01379138883203268,
      "learning_rate": 3.51566265060241e-06,
      "loss": 0.003,
      "step": 136820
    },
    {
      "epoch": 16.485542168674698,
      "grad_norm": 0.010754231363534927,
      "learning_rate": 3.5144578313253013e-06,
      "loss": 0.0084,
      "step": 136830
    },
    {
      "epoch": 16.486746987951808,
      "grad_norm": 0.0010875440202653408,
      "learning_rate": 3.513253012048193e-06,
      "loss": 0.0069,
      "step": 136840
    },
    {
      "epoch": 16.487951807228917,
      "grad_norm": 1.3237749338150024,
      "learning_rate": 3.512048192771085e-06,
      "loss": 0.0095,
      "step": 136850
    },
    {
      "epoch": 16.489156626506023,
      "grad_norm": 0.00037544340011663735,
      "learning_rate": 3.510843373493976e-06,
      "loss": 0.0151,
      "step": 136860
    },
    {
      "epoch": 16.490361445783133,
      "grad_norm": 0.003241902682930231,
      "learning_rate": 3.5096385542168677e-06,
      "loss": 0.0117,
      "step": 136870
    },
    {
      "epoch": 16.49156626506024,
      "grad_norm": 0.001601550029590726,
      "learning_rate": 3.5084337349397597e-06,
      "loss": 0.0005,
      "step": 136880
    },
    {
      "epoch": 16.49277108433735,
      "grad_norm": 1.0021581649780273,
      "learning_rate": 3.507228915662651e-06,
      "loss": 0.0094,
      "step": 136890
    },
    {
      "epoch": 16.49397590361446,
      "grad_norm": 0.7291717529296875,
      "learning_rate": 3.5060240963855424e-06,
      "loss": 0.0084,
      "step": 136900
    },
    {
      "epoch": 16.495180722891565,
      "grad_norm": 1.2771563529968262,
      "learning_rate": 3.504819277108434e-06,
      "loss": 0.0083,
      "step": 136910
    },
    {
      "epoch": 16.496385542168674,
      "grad_norm": 0.0005979235284030437,
      "learning_rate": 3.5036144578313256e-06,
      "loss": 0.0238,
      "step": 136920
    },
    {
      "epoch": 16.497590361445784,
      "grad_norm": 0.002011364558711648,
      "learning_rate": 3.502409638554217e-06,
      "loss": 0.0443,
      "step": 136930
    },
    {
      "epoch": 16.49879518072289,
      "grad_norm": 0.0020841658115386963,
      "learning_rate": 3.5012048192771088e-06,
      "loss": 0.005,
      "step": 136940
    },
    {
      "epoch": 16.5,
      "grad_norm": 0.0740823969244957,
      "learning_rate": 3.5e-06,
      "loss": 0.0086,
      "step": 136950
    },
    {
      "epoch": 16.50120481927711,
      "grad_norm": 0.0018358350498601794,
      "learning_rate": 3.498795180722892e-06,
      "loss": 0.0188,
      "step": 136960
    },
    {
      "epoch": 16.502409638554216,
      "grad_norm": 0.9899793267250061,
      "learning_rate": 3.4975903614457835e-06,
      "loss": 0.0191,
      "step": 136970
    },
    {
      "epoch": 16.503614457831326,
      "grad_norm": 0.0038660464342683554,
      "learning_rate": 3.4963855421686747e-06,
      "loss": 0.001,
      "step": 136980
    },
    {
      "epoch": 16.504819277108435,
      "grad_norm": 0.0018440040294080973,
      "learning_rate": 3.4951807228915663e-06,
      "loss": 0.0033,
      "step": 136990
    },
    {
      "epoch": 16.50602409638554,
      "grad_norm": 0.02371339127421379,
      "learning_rate": 3.4939759036144583e-06,
      "loss": 0.0256,
      "step": 137000
    },
    {
      "epoch": 16.50722891566265,
      "grad_norm": 1.7360368967056274,
      "learning_rate": 3.4927710843373495e-06,
      "loss": 0.0136,
      "step": 137010
    },
    {
      "epoch": 16.50843373493976,
      "grad_norm": 0.37993335723876953,
      "learning_rate": 3.491566265060241e-06,
      "loss": 0.0039,
      "step": 137020
    },
    {
      "epoch": 16.509638554216867,
      "grad_norm": 1.2381221055984497,
      "learning_rate": 3.490361445783133e-06,
      "loss": 0.0088,
      "step": 137030
    },
    {
      "epoch": 16.510843373493977,
      "grad_norm": 0.045544300228357315,
      "learning_rate": 3.4891566265060247e-06,
      "loss": 0.0396,
      "step": 137040
    },
    {
      "epoch": 16.512048192771083,
      "grad_norm": 0.14390601217746735,
      "learning_rate": 3.487951807228916e-06,
      "loss": 0.0118,
      "step": 137050
    },
    {
      "epoch": 16.513253012048192,
      "grad_norm": 0.12068604677915573,
      "learning_rate": 3.4867469879518074e-06,
      "loss": 0.0134,
      "step": 137060
    },
    {
      "epoch": 16.514457831325302,
      "grad_norm": 0.002333238022401929,
      "learning_rate": 3.4855421686746994e-06,
      "loss": 0.0139,
      "step": 137070
    },
    {
      "epoch": 16.51566265060241,
      "grad_norm": 0.0012688180431723595,
      "learning_rate": 3.4843373493975906e-06,
      "loss": 0.007,
      "step": 137080
    },
    {
      "epoch": 16.516867469879518,
      "grad_norm": 0.0017403163947165012,
      "learning_rate": 3.483132530120482e-06,
      "loss": 0.0091,
      "step": 137090
    },
    {
      "epoch": 16.518072289156628,
      "grad_norm": 1.6463221311569214,
      "learning_rate": 3.4819277108433733e-06,
      "loss": 0.0057,
      "step": 137100
    },
    {
      "epoch": 16.519277108433734,
      "grad_norm": 1.335105061531067,
      "learning_rate": 3.4807228915662654e-06,
      "loss": 0.0195,
      "step": 137110
    },
    {
      "epoch": 16.520481927710843,
      "grad_norm": 0.0031759412959218025,
      "learning_rate": 3.479518072289157e-06,
      "loss": 0.0084,
      "step": 137120
    },
    {
      "epoch": 16.521686746987953,
      "grad_norm": 0.0009038957650773227,
      "learning_rate": 3.4783132530120485e-06,
      "loss": 0.0065,
      "step": 137130
    },
    {
      "epoch": 16.52289156626506,
      "grad_norm": 0.009308838285505772,
      "learning_rate": 3.4771084337349397e-06,
      "loss": 0.0141,
      "step": 137140
    },
    {
      "epoch": 16.52409638554217,
      "grad_norm": 1.0294722318649292,
      "learning_rate": 3.4759036144578317e-06,
      "loss": 0.0124,
      "step": 137150
    },
    {
      "epoch": 16.52530120481928,
      "grad_norm": 0.717395544052124,
      "learning_rate": 3.4746987951807233e-06,
      "loss": 0.0244,
      "step": 137160
    },
    {
      "epoch": 16.526506024096385,
      "grad_norm": 0.15775123238563538,
      "learning_rate": 3.4734939759036145e-06,
      "loss": 0.0225,
      "step": 137170
    },
    {
      "epoch": 16.527710843373494,
      "grad_norm": 0.00045404702541418374,
      "learning_rate": 3.4722891566265065e-06,
      "loss": 0.0165,
      "step": 137180
    },
    {
      "epoch": 16.528915662650604,
      "grad_norm": 1.2392929792404175,
      "learning_rate": 3.471084337349398e-06,
      "loss": 0.0304,
      "step": 137190
    },
    {
      "epoch": 16.53012048192771,
      "grad_norm": 0.04854874685406685,
      "learning_rate": 3.4698795180722892e-06,
      "loss": 0.0028,
      "step": 137200
    },
    {
      "epoch": 16.53132530120482,
      "grad_norm": 0.0013279456179589033,
      "learning_rate": 3.468674698795181e-06,
      "loss": 0.0148,
      "step": 137210
    },
    {
      "epoch": 16.532530120481926,
      "grad_norm": 0.0003211627481505275,
      "learning_rate": 3.467469879518073e-06,
      "loss": 0.0177,
      "step": 137220
    },
    {
      "epoch": 16.533734939759036,
      "grad_norm": 0.04373347386717796,
      "learning_rate": 3.4662650602409644e-06,
      "loss": 0.0099,
      "step": 137230
    },
    {
      "epoch": 16.534939759036146,
      "grad_norm": 0.0005183626199141145,
      "learning_rate": 3.4650602409638556e-06,
      "loss": 0.012,
      "step": 137240
    },
    {
      "epoch": 16.53614457831325,
      "grad_norm": 0.0005818285862915218,
      "learning_rate": 3.463855421686747e-06,
      "loss": 0.0095,
      "step": 137250
    },
    {
      "epoch": 16.53734939759036,
      "grad_norm": 0.0012608857359737158,
      "learning_rate": 3.462650602409639e-06,
      "loss": 0.0121,
      "step": 137260
    },
    {
      "epoch": 16.53855421686747,
      "grad_norm": 0.006501469295471907,
      "learning_rate": 3.4614457831325303e-06,
      "loss": 0.0121,
      "step": 137270
    },
    {
      "epoch": 16.539759036144577,
      "grad_norm": 1.0220615863800049,
      "learning_rate": 3.460240963855422e-06,
      "loss": 0.0184,
      "step": 137280
    },
    {
      "epoch": 16.540963855421687,
      "grad_norm": 3.53938364982605,
      "learning_rate": 3.459036144578313e-06,
      "loss": 0.0166,
      "step": 137290
    },
    {
      "epoch": 16.542168674698797,
      "grad_norm": 1.8867911100387573,
      "learning_rate": 3.457831325301205e-06,
      "loss": 0.0099,
      "step": 137300
    },
    {
      "epoch": 16.543373493975903,
      "grad_norm": 0.0023356142919510603,
      "learning_rate": 3.4566265060240967e-06,
      "loss": 0.0226,
      "step": 137310
    },
    {
      "epoch": 16.544578313253012,
      "grad_norm": 1.0280944108963013,
      "learning_rate": 3.4554216867469883e-06,
      "loss": 0.0531,
      "step": 137320
    },
    {
      "epoch": 16.545783132530122,
      "grad_norm": 0.03315076231956482,
      "learning_rate": 3.45421686746988e-06,
      "loss": 0.0036,
      "step": 137330
    },
    {
      "epoch": 16.54698795180723,
      "grad_norm": 0.00983412191271782,
      "learning_rate": 3.4530120481927715e-06,
      "loss": 0.0108,
      "step": 137340
    },
    {
      "epoch": 16.548192771084338,
      "grad_norm": 0.002383918734267354,
      "learning_rate": 3.451807228915663e-06,
      "loss": 0.0183,
      "step": 137350
    },
    {
      "epoch": 16.549397590361444,
      "grad_norm": 0.02524418570101261,
      "learning_rate": 3.450602409638554e-06,
      "loss": 0.0171,
      "step": 137360
    },
    {
      "epoch": 16.550602409638554,
      "grad_norm": 0.007210958749055862,
      "learning_rate": 3.4493975903614462e-06,
      "loss": 0.0079,
      "step": 137370
    },
    {
      "epoch": 16.551807228915663,
      "grad_norm": 0.00376214855350554,
      "learning_rate": 3.448192771084338e-06,
      "loss": 0.0048,
      "step": 137380
    },
    {
      "epoch": 16.55301204819277,
      "grad_norm": 0.04003363102674484,
      "learning_rate": 3.446987951807229e-06,
      "loss": 0.0051,
      "step": 137390
    },
    {
      "epoch": 16.55421686746988,
      "grad_norm": 6.042690753936768,
      "learning_rate": 3.4457831325301206e-06,
      "loss": 0.02,
      "step": 137400
    },
    {
      "epoch": 16.55542168674699,
      "grad_norm": 3.3316447734832764,
      "learning_rate": 3.4445783132530126e-06,
      "loss": 0.0233,
      "step": 137410
    },
    {
      "epoch": 16.556626506024095,
      "grad_norm": 0.0018245697719976306,
      "learning_rate": 3.4433734939759037e-06,
      "loss": 0.0084,
      "step": 137420
    },
    {
      "epoch": 16.557831325301205,
      "grad_norm": 0.0009503139881417155,
      "learning_rate": 3.4421686746987953e-06,
      "loss": 0.0398,
      "step": 137430
    },
    {
      "epoch": 16.559036144578315,
      "grad_norm": 0.003156846622005105,
      "learning_rate": 3.440963855421687e-06,
      "loss": 0.0097,
      "step": 137440
    },
    {
      "epoch": 16.56024096385542,
      "grad_norm": 0.0014277551090344787,
      "learning_rate": 3.439759036144579e-06,
      "loss": 0.0065,
      "step": 137450
    },
    {
      "epoch": 16.56144578313253,
      "grad_norm": 0.004103141371160746,
      "learning_rate": 3.43855421686747e-06,
      "loss": 0.0097,
      "step": 137460
    },
    {
      "epoch": 16.56265060240964,
      "grad_norm": 0.07452544569969177,
      "learning_rate": 3.4373493975903617e-06,
      "loss": 0.0315,
      "step": 137470
    },
    {
      "epoch": 16.563855421686746,
      "grad_norm": 0.0009365386213175952,
      "learning_rate": 3.4361445783132537e-06,
      "loss": 0.0118,
      "step": 137480
    },
    {
      "epoch": 16.565060240963856,
      "grad_norm": 0.00453529367223382,
      "learning_rate": 3.434939759036145e-06,
      "loss": 0.012,
      "step": 137490
    },
    {
      "epoch": 16.566265060240966,
      "grad_norm": 0.0062050120905041695,
      "learning_rate": 3.4337349397590364e-06,
      "loss": 0.0151,
      "step": 137500
    },
    {
      "epoch": 16.56746987951807,
      "grad_norm": 0.05737327039241791,
      "learning_rate": 3.4325301204819276e-06,
      "loss": 0.0042,
      "step": 137510
    },
    {
      "epoch": 16.56867469879518,
      "grad_norm": 0.0013231828343123198,
      "learning_rate": 3.4313253012048196e-06,
      "loss": 0.0073,
      "step": 137520
    },
    {
      "epoch": 16.569879518072288,
      "grad_norm": 0.0011072505731135607,
      "learning_rate": 3.430120481927711e-06,
      "loss": 0.0087,
      "step": 137530
    },
    {
      "epoch": 16.571084337349397,
      "grad_norm": 0.0003879290306940675,
      "learning_rate": 3.428915662650603e-06,
      "loss": 0.0099,
      "step": 137540
    },
    {
      "epoch": 16.572289156626507,
      "grad_norm": 0.0016834101406857371,
      "learning_rate": 3.427710843373494e-06,
      "loss": 0.0046,
      "step": 137550
    },
    {
      "epoch": 16.573493975903613,
      "grad_norm": 0.0007444990915246308,
      "learning_rate": 3.426506024096386e-06,
      "loss": 0.007,
      "step": 137560
    },
    {
      "epoch": 16.574698795180723,
      "grad_norm": 0.005776186008006334,
      "learning_rate": 3.4253012048192776e-06,
      "loss": 0.0023,
      "step": 137570
    },
    {
      "epoch": 16.575903614457832,
      "grad_norm": 0.001877730479463935,
      "learning_rate": 3.4240963855421687e-06,
      "loss": 0.0238,
      "step": 137580
    },
    {
      "epoch": 16.57710843373494,
      "grad_norm": 15.853944778442383,
      "learning_rate": 3.4228915662650603e-06,
      "loss": 0.0296,
      "step": 137590
    },
    {
      "epoch": 16.57831325301205,
      "grad_norm": 0.004859456792473793,
      "learning_rate": 3.4216867469879523e-06,
      "loss": 0.0021,
      "step": 137600
    },
    {
      "epoch": 16.579518072289158,
      "grad_norm": 0.007140889763832092,
      "learning_rate": 3.4204819277108435e-06,
      "loss": 0.0168,
      "step": 137610
    },
    {
      "epoch": 16.580722891566264,
      "grad_norm": 0.0006076662102714181,
      "learning_rate": 3.419277108433735e-06,
      "loss": 0.0271,
      "step": 137620
    },
    {
      "epoch": 16.581927710843374,
      "grad_norm": 1.5645402669906616,
      "learning_rate": 3.418072289156627e-06,
      "loss": 0.0152,
      "step": 137630
    },
    {
      "epoch": 16.583132530120483,
      "grad_norm": 0.9377959370613098,
      "learning_rate": 3.4168674698795182e-06,
      "loss": 0.016,
      "step": 137640
    },
    {
      "epoch": 16.58433734939759,
      "grad_norm": 0.01380909513682127,
      "learning_rate": 3.41566265060241e-06,
      "loss": 0.0068,
      "step": 137650
    },
    {
      "epoch": 16.5855421686747,
      "grad_norm": 0.0007330069784075022,
      "learning_rate": 3.4144578313253014e-06,
      "loss": 0.0219,
      "step": 137660
    },
    {
      "epoch": 16.586746987951805,
      "grad_norm": 1.085288643836975,
      "learning_rate": 3.4132530120481934e-06,
      "loss": 0.0227,
      "step": 137670
    },
    {
      "epoch": 16.587951807228915,
      "grad_norm": 1.1772300004959106,
      "learning_rate": 3.4120481927710846e-06,
      "loss": 0.0075,
      "step": 137680
    },
    {
      "epoch": 16.589156626506025,
      "grad_norm": 2.890623092651367,
      "learning_rate": 3.410843373493976e-06,
      "loss": 0.0244,
      "step": 137690
    },
    {
      "epoch": 16.59036144578313,
      "grad_norm": 0.0014774743467569351,
      "learning_rate": 3.4096385542168674e-06,
      "loss": 0.0001,
      "step": 137700
    },
    {
      "epoch": 16.59156626506024,
      "grad_norm": 0.9306929111480713,
      "learning_rate": 3.4084337349397594e-06,
      "loss": 0.0272,
      "step": 137710
    },
    {
      "epoch": 16.59277108433735,
      "grad_norm": 0.00027293513994663954,
      "learning_rate": 3.407228915662651e-06,
      "loss": 0.0079,
      "step": 137720
    },
    {
      "epoch": 16.593975903614457,
      "grad_norm": 0.0009132682462222874,
      "learning_rate": 3.406024096385542e-06,
      "loss": 0.0105,
      "step": 137730
    },
    {
      "epoch": 16.595180722891566,
      "grad_norm": 0.0012783443089574575,
      "learning_rate": 3.4048192771084337e-06,
      "loss": 0.0115,
      "step": 137740
    },
    {
      "epoch": 16.596385542168676,
      "grad_norm": 0.003195284865796566,
      "learning_rate": 3.4036144578313257e-06,
      "loss": 0.0238,
      "step": 137750
    },
    {
      "epoch": 16.597590361445782,
      "grad_norm": 1.170559287071228,
      "learning_rate": 3.4024096385542173e-06,
      "loss": 0.0137,
      "step": 137760
    },
    {
      "epoch": 16.59879518072289,
      "grad_norm": 0.00025057478342205286,
      "learning_rate": 3.4012048192771085e-06,
      "loss": 0.0084,
      "step": 137770
    },
    {
      "epoch": 16.6,
      "grad_norm": 0.03021957539021969,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.0063,
      "step": 137780
    },
    {
      "epoch": 16.601204819277108,
      "grad_norm": 0.0007628952153027058,
      "learning_rate": 3.398795180722892e-06,
      "loss": 0.0046,
      "step": 137790
    },
    {
      "epoch": 16.602409638554217,
      "grad_norm": 1.115207552909851,
      "learning_rate": 3.3975903614457832e-06,
      "loss": 0.0085,
      "step": 137800
    },
    {
      "epoch": 16.603614457831327,
      "grad_norm": 0.00033422597334720194,
      "learning_rate": 3.396385542168675e-06,
      "loss": 0.0205,
      "step": 137810
    },
    {
      "epoch": 16.604819277108433,
      "grad_norm": 0.8180586099624634,
      "learning_rate": 3.395180722891567e-06,
      "loss": 0.0116,
      "step": 137820
    },
    {
      "epoch": 16.606024096385543,
      "grad_norm": 0.0022888020612299442,
      "learning_rate": 3.393975903614458e-06,
      "loss": 0.0328,
      "step": 137830
    },
    {
      "epoch": 16.60722891566265,
      "grad_norm": 0.005725546274334192,
      "learning_rate": 3.3927710843373496e-06,
      "loss": 0.009,
      "step": 137840
    },
    {
      "epoch": 16.60843373493976,
      "grad_norm": 0.21912498772144318,
      "learning_rate": 3.391566265060241e-06,
      "loss": 0.0107,
      "step": 137850
    },
    {
      "epoch": 16.60963855421687,
      "grad_norm": 0.012394504621624947,
      "learning_rate": 3.390361445783133e-06,
      "loss": 0.0009,
      "step": 137860
    },
    {
      "epoch": 16.610843373493974,
      "grad_norm": 0.00029087375150993466,
      "learning_rate": 3.3891566265060243e-06,
      "loss": 0.0162,
      "step": 137870
    },
    {
      "epoch": 16.612048192771084,
      "grad_norm": 0.00019125327526126057,
      "learning_rate": 3.387951807228916e-06,
      "loss": 0.0,
      "step": 137880
    },
    {
      "epoch": 16.613253012048194,
      "grad_norm": 0.019597109407186508,
      "learning_rate": 3.386746987951807e-06,
      "loss": 0.0004,
      "step": 137890
    },
    {
      "epoch": 16.6144578313253,
      "grad_norm": 0.0005263807834126055,
      "learning_rate": 3.385542168674699e-06,
      "loss": 0.0053,
      "step": 137900
    },
    {
      "epoch": 16.61566265060241,
      "grad_norm": 0.0003402802103664726,
      "learning_rate": 3.3843373493975907e-06,
      "loss": 0.0089,
      "step": 137910
    },
    {
      "epoch": 16.61686746987952,
      "grad_norm": 1.6954209804534912,
      "learning_rate": 3.383132530120482e-06,
      "loss": 0.0455,
      "step": 137920
    },
    {
      "epoch": 16.618072289156625,
      "grad_norm": 0.0005770653369836509,
      "learning_rate": 3.381927710843374e-06,
      "loss": 0.0144,
      "step": 137930
    },
    {
      "epoch": 16.619277108433735,
      "grad_norm": 0.0002760392671916634,
      "learning_rate": 3.3807228915662655e-06,
      "loss": 0.0141,
      "step": 137940
    },
    {
      "epoch": 16.620481927710845,
      "grad_norm": 0.0004988026339560747,
      "learning_rate": 3.379518072289157e-06,
      "loss": 0.0128,
      "step": 137950
    },
    {
      "epoch": 16.62168674698795,
      "grad_norm": 0.0002120938734151423,
      "learning_rate": 3.3783132530120482e-06,
      "loss": 0.0113,
      "step": 137960
    },
    {
      "epoch": 16.62289156626506,
      "grad_norm": 0.0006150419358164072,
      "learning_rate": 3.3771084337349402e-06,
      "loss": 0.0077,
      "step": 137970
    },
    {
      "epoch": 16.62409638554217,
      "grad_norm": 0.0002064230211544782,
      "learning_rate": 3.375903614457832e-06,
      "loss": 0.0189,
      "step": 137980
    },
    {
      "epoch": 16.625301204819277,
      "grad_norm": 0.00012439752754289657,
      "learning_rate": 3.374698795180723e-06,
      "loss": 0.0141,
      "step": 137990
    },
    {
      "epoch": 16.626506024096386,
      "grad_norm": 2.492511034011841,
      "learning_rate": 3.3734939759036146e-06,
      "loss": 0.0339,
      "step": 138000
    },
    {
      "epoch": 16.627710843373492,
      "grad_norm": 0.0001716231636237353,
      "learning_rate": 3.3722891566265066e-06,
      "loss": 0.0141,
      "step": 138010
    },
    {
      "epoch": 16.628915662650602,
      "grad_norm": 2.0157101154327393,
      "learning_rate": 3.3710843373493977e-06,
      "loss": 0.0139,
      "step": 138020
    },
    {
      "epoch": 16.63012048192771,
      "grad_norm": 2.664468288421631,
      "learning_rate": 3.3698795180722893e-06,
      "loss": 0.0282,
      "step": 138030
    },
    {
      "epoch": 16.631325301204818,
      "grad_norm": 1.5876727104187012,
      "learning_rate": 3.3686746987951813e-06,
      "loss": 0.0097,
      "step": 138040
    },
    {
      "epoch": 16.632530120481928,
      "grad_norm": 0.004323833156377077,
      "learning_rate": 3.3674698795180725e-06,
      "loss": 0.0059,
      "step": 138050
    },
    {
      "epoch": 16.633734939759037,
      "grad_norm": 0.00027070112992078066,
      "learning_rate": 3.366265060240964e-06,
      "loss": 0.029,
      "step": 138060
    },
    {
      "epoch": 16.634939759036143,
      "grad_norm": 1.6518168449401855,
      "learning_rate": 3.3650602409638557e-06,
      "loss": 0.0133,
      "step": 138070
    },
    {
      "epoch": 16.636144578313253,
      "grad_norm": 1.4529664516448975,
      "learning_rate": 3.3638554216867477e-06,
      "loss": 0.0196,
      "step": 138080
    },
    {
      "epoch": 16.637349397590363,
      "grad_norm": 0.00029575207736343145,
      "learning_rate": 3.362650602409639e-06,
      "loss": 0.0115,
      "step": 138090
    },
    {
      "epoch": 16.63855421686747,
      "grad_norm": 0.0004654710355680436,
      "learning_rate": 3.3614457831325305e-06,
      "loss": 0.0096,
      "step": 138100
    },
    {
      "epoch": 16.63975903614458,
      "grad_norm": 1.910921335220337,
      "learning_rate": 3.3602409638554216e-06,
      "loss": 0.0341,
      "step": 138110
    },
    {
      "epoch": 16.64096385542169,
      "grad_norm": 0.00028803813620470464,
      "learning_rate": 3.3590361445783136e-06,
      "loss": 0.0546,
      "step": 138120
    },
    {
      "epoch": 16.642168674698794,
      "grad_norm": 0.04362295940518379,
      "learning_rate": 3.3578313253012052e-06,
      "loss": 0.016,
      "step": 138130
    },
    {
      "epoch": 16.643373493975904,
      "grad_norm": 0.0006722884136252105,
      "learning_rate": 3.3566265060240964e-06,
      "loss": 0.0024,
      "step": 138140
    },
    {
      "epoch": 16.644578313253014,
      "grad_norm": 0.0004427882668096572,
      "learning_rate": 3.355421686746988e-06,
      "loss": 0.0115,
      "step": 138150
    },
    {
      "epoch": 16.64578313253012,
      "grad_norm": 0.4113631248474121,
      "learning_rate": 3.35421686746988e-06,
      "loss": 0.0026,
      "step": 138160
    },
    {
      "epoch": 16.64698795180723,
      "grad_norm": 0.000822250556666404,
      "learning_rate": 3.3530120481927716e-06,
      "loss": 0.0211,
      "step": 138170
    },
    {
      "epoch": 16.648192771084336,
      "grad_norm": 0.0004770228115376085,
      "learning_rate": 3.3518072289156627e-06,
      "loss": 0.0066,
      "step": 138180
    },
    {
      "epoch": 16.649397590361446,
      "grad_norm": 1.604886531829834,
      "learning_rate": 3.3506024096385547e-06,
      "loss": 0.0145,
      "step": 138190
    },
    {
      "epoch": 16.650602409638555,
      "grad_norm": 0.00017796014435589314,
      "learning_rate": 3.3493975903614463e-06,
      "loss": 0.0064,
      "step": 138200
    },
    {
      "epoch": 16.65180722891566,
      "grad_norm": 0.0005252970149740577,
      "learning_rate": 3.3481927710843375e-06,
      "loss": 0.0083,
      "step": 138210
    },
    {
      "epoch": 16.65301204819277,
      "grad_norm": 0.000213573599467054,
      "learning_rate": 3.346987951807229e-06,
      "loss": 0.0167,
      "step": 138220
    },
    {
      "epoch": 16.65421686746988,
      "grad_norm": 0.0007255786913447082,
      "learning_rate": 3.345783132530121e-06,
      "loss": 0.0054,
      "step": 138230
    },
    {
      "epoch": 16.655421686746987,
      "grad_norm": 0.00047062101657502353,
      "learning_rate": 3.3445783132530123e-06,
      "loss": 0.0189,
      "step": 138240
    },
    {
      "epoch": 16.656626506024097,
      "grad_norm": 0.0003399654815439135,
      "learning_rate": 3.343373493975904e-06,
      "loss": 0.0011,
      "step": 138250
    },
    {
      "epoch": 16.657831325301206,
      "grad_norm": 0.676099419593811,
      "learning_rate": 3.3421686746987954e-06,
      "loss": 0.003,
      "step": 138260
    },
    {
      "epoch": 16.659036144578312,
      "grad_norm": 0.5662298798561096,
      "learning_rate": 3.340963855421687e-06,
      "loss": 0.0138,
      "step": 138270
    },
    {
      "epoch": 16.660240963855422,
      "grad_norm": 0.04037508741021156,
      "learning_rate": 3.3397590361445786e-06,
      "loss": 0.0138,
      "step": 138280
    },
    {
      "epoch": 16.66144578313253,
      "grad_norm": 8.18409538269043,
      "learning_rate": 3.33855421686747e-06,
      "loss": 0.0228,
      "step": 138290
    },
    {
      "epoch": 16.662650602409638,
      "grad_norm": 0.21181264519691467,
      "learning_rate": 3.3373493975903614e-06,
      "loss": 0.0034,
      "step": 138300
    },
    {
      "epoch": 16.663855421686748,
      "grad_norm": 0.0007106430712155998,
      "learning_rate": 3.3361445783132534e-06,
      "loss": 0.0148,
      "step": 138310
    },
    {
      "epoch": 16.665060240963854,
      "grad_norm": 0.0002978751144837588,
      "learning_rate": 3.334939759036145e-06,
      "loss": 0.0018,
      "step": 138320
    },
    {
      "epoch": 16.666265060240963,
      "grad_norm": 0.0002902474079746753,
      "learning_rate": 3.333734939759036e-06,
      "loss": 0.007,
      "step": 138330
    },
    {
      "epoch": 16.667469879518073,
      "grad_norm": 0.00030052257352508605,
      "learning_rate": 3.332530120481928e-06,
      "loss": 0.003,
      "step": 138340
    },
    {
      "epoch": 16.66867469879518,
      "grad_norm": 7.907483100891113,
      "learning_rate": 3.3313253012048197e-06,
      "loss": 0.0484,
      "step": 138350
    },
    {
      "epoch": 16.66987951807229,
      "grad_norm": 0.00043959758477285504,
      "learning_rate": 3.330120481927711e-06,
      "loss": 0.0106,
      "step": 138360
    },
    {
      "epoch": 16.6710843373494,
      "grad_norm": 0.0001433545257896185,
      "learning_rate": 3.3289156626506025e-06,
      "loss": 0.0137,
      "step": 138370
    },
    {
      "epoch": 16.672289156626505,
      "grad_norm": 0.00025959438062272966,
      "learning_rate": 3.3277108433734945e-06,
      "loss": 0.0099,
      "step": 138380
    },
    {
      "epoch": 16.673493975903614,
      "grad_norm": 0.0014768315013498068,
      "learning_rate": 3.326506024096386e-06,
      "loss": 0.0045,
      "step": 138390
    },
    {
      "epoch": 16.674698795180724,
      "grad_norm": 0.0011022054823115468,
      "learning_rate": 3.3253012048192772e-06,
      "loss": 0.0318,
      "step": 138400
    },
    {
      "epoch": 16.67590361445783,
      "grad_norm": 1.2969189882278442,
      "learning_rate": 3.324096385542169e-06,
      "loss": 0.0026,
      "step": 138410
    },
    {
      "epoch": 16.67710843373494,
      "grad_norm": 0.005121440626680851,
      "learning_rate": 3.322891566265061e-06,
      "loss": 0.0112,
      "step": 138420
    },
    {
      "epoch": 16.67831325301205,
      "grad_norm": 0.0069299363531172276,
      "learning_rate": 3.321686746987952e-06,
      "loss": 0.0114,
      "step": 138430
    },
    {
      "epoch": 16.679518072289156,
      "grad_norm": 0.0002929692855104804,
      "learning_rate": 3.3204819277108436e-06,
      "loss": 0.001,
      "step": 138440
    },
    {
      "epoch": 16.680722891566266,
      "grad_norm": 0.00042068155016750097,
      "learning_rate": 3.3192771084337348e-06,
      "loss": 0.0185,
      "step": 138450
    },
    {
      "epoch": 16.681927710843375,
      "grad_norm": 0.00047487529809586704,
      "learning_rate": 3.3180722891566268e-06,
      "loss": 0.0176,
      "step": 138460
    },
    {
      "epoch": 16.68313253012048,
      "grad_norm": 0.000667524931486696,
      "learning_rate": 3.3168674698795184e-06,
      "loss": 0.008,
      "step": 138470
    },
    {
      "epoch": 16.68433734939759,
      "grad_norm": 0.000536426727194339,
      "learning_rate": 3.31566265060241e-06,
      "loss": 0.0005,
      "step": 138480
    },
    {
      "epoch": 16.685542168674697,
      "grad_norm": 0.0003078352310694754,
      "learning_rate": 3.3144578313253015e-06,
      "loss": 0.0036,
      "step": 138490
    },
    {
      "epoch": 16.686746987951807,
      "grad_norm": 0.0007004359504207969,
      "learning_rate": 3.313253012048193e-06,
      "loss": 0.0096,
      "step": 138500
    },
    {
      "epoch": 16.687951807228917,
      "grad_norm": 0.0024645617231726646,
      "learning_rate": 3.3120481927710847e-06,
      "loss": 0.0122,
      "step": 138510
    },
    {
      "epoch": 16.689156626506023,
      "grad_norm": 0.35759198665618896,
      "learning_rate": 3.310843373493976e-06,
      "loss": 0.0031,
      "step": 138520
    },
    {
      "epoch": 16.690361445783132,
      "grad_norm": 0.0012095053680241108,
      "learning_rate": 3.309638554216868e-06,
      "loss": 0.0603,
      "step": 138530
    },
    {
      "epoch": 16.691566265060242,
      "grad_norm": 1.8267320394515991,
      "learning_rate": 3.3084337349397595e-06,
      "loss": 0.013,
      "step": 138540
    },
    {
      "epoch": 16.69277108433735,
      "grad_norm": 0.5031569004058838,
      "learning_rate": 3.3072289156626506e-06,
      "loss": 0.0071,
      "step": 138550
    },
    {
      "epoch": 16.693975903614458,
      "grad_norm": 0.00026612039073370397,
      "learning_rate": 3.3060240963855422e-06,
      "loss": 0.0113,
      "step": 138560
    },
    {
      "epoch": 16.695180722891568,
      "grad_norm": 0.00030624878127127886,
      "learning_rate": 3.3048192771084342e-06,
      "loss": 0.0003,
      "step": 138570
    },
    {
      "epoch": 16.696385542168674,
      "grad_norm": 0.01655266061425209,
      "learning_rate": 3.303614457831326e-06,
      "loss": 0.0128,
      "step": 138580
    },
    {
      "epoch": 16.697590361445783,
      "grad_norm": 0.0007227354217320681,
      "learning_rate": 3.302409638554217e-06,
      "loss": 0.0056,
      "step": 138590
    },
    {
      "epoch": 16.698795180722893,
      "grad_norm": 0.0013149167643859982,
      "learning_rate": 3.3012048192771086e-06,
      "loss": 0.0009,
      "step": 138600
    },
    {
      "epoch": 16.7,
      "grad_norm": 0.00024232181021943688,
      "learning_rate": 3.3000000000000006e-06,
      "loss": 0.0045,
      "step": 138610
    },
    {
      "epoch": 16.70120481927711,
      "grad_norm": 0.00031905705691315234,
      "learning_rate": 3.2987951807228918e-06,
      "loss": 0.0347,
      "step": 138620
    },
    {
      "epoch": 16.702409638554215,
      "grad_norm": 0.0007157385116443038,
      "learning_rate": 3.2975903614457833e-06,
      "loss": 0.0074,
      "step": 138630
    },
    {
      "epoch": 16.703614457831325,
      "grad_norm": 0.00043590794666670263,
      "learning_rate": 3.2963855421686754e-06,
      "loss": 0.0053,
      "step": 138640
    },
    {
      "epoch": 16.704819277108435,
      "grad_norm": 0.00028755670064128935,
      "learning_rate": 3.2951807228915665e-06,
      "loss": 0.0017,
      "step": 138650
    },
    {
      "epoch": 16.70602409638554,
      "grad_norm": 0.0011768253752961755,
      "learning_rate": 3.293975903614458e-06,
      "loss": 0.0261,
      "step": 138660
    },
    {
      "epoch": 16.70722891566265,
      "grad_norm": 0.002485389821231365,
      "learning_rate": 3.2927710843373497e-06,
      "loss": 0.0009,
      "step": 138670
    },
    {
      "epoch": 16.70843373493976,
      "grad_norm": 0.0033678573090583086,
      "learning_rate": 3.2915662650602413e-06,
      "loss": 0.0032,
      "step": 138680
    },
    {
      "epoch": 16.709638554216866,
      "grad_norm": 0.0008035923819988966,
      "learning_rate": 3.290361445783133e-06,
      "loss": 0.0061,
      "step": 138690
    },
    {
      "epoch": 16.710843373493976,
      "grad_norm": 0.0003479080623947084,
      "learning_rate": 3.2891566265060245e-06,
      "loss": 0.0025,
      "step": 138700
    },
    {
      "epoch": 16.712048192771086,
      "grad_norm": 1.0274674892425537,
      "learning_rate": 3.2879518072289156e-06,
      "loss": 0.0152,
      "step": 138710
    },
    {
      "epoch": 16.71325301204819,
      "grad_norm": 5.758181571960449,
      "learning_rate": 3.2867469879518076e-06,
      "loss": 0.0078,
      "step": 138720
    },
    {
      "epoch": 16.7144578313253,
      "grad_norm": 1.3000540733337402,
      "learning_rate": 3.2855421686746992e-06,
      "loss": 0.0255,
      "step": 138730
    },
    {
      "epoch": 16.71566265060241,
      "grad_norm": 0.0007956112385727465,
      "learning_rate": 3.2843373493975904e-06,
      "loss": 0.0044,
      "step": 138740
    },
    {
      "epoch": 16.716867469879517,
      "grad_norm": 1.1403697729110718,
      "learning_rate": 3.283132530120482e-06,
      "loss": 0.0233,
      "step": 138750
    },
    {
      "epoch": 16.718072289156627,
      "grad_norm": 3.4936368465423584,
      "learning_rate": 3.281927710843374e-06,
      "loss": 0.0109,
      "step": 138760
    },
    {
      "epoch": 16.719277108433737,
      "grad_norm": 0.00017421967640984803,
      "learning_rate": 3.280722891566265e-06,
      "loss": 0.0018,
      "step": 138770
    },
    {
      "epoch": 16.720481927710843,
      "grad_norm": 0.00043614301830530167,
      "learning_rate": 3.2795180722891567e-06,
      "loss": 0.0063,
      "step": 138780
    },
    {
      "epoch": 16.721686746987952,
      "grad_norm": 0.040440883487463,
      "learning_rate": 3.2783132530120488e-06,
      "loss": 0.0155,
      "step": 138790
    },
    {
      "epoch": 16.72289156626506,
      "grad_norm": 1.0305815935134888,
      "learning_rate": 3.2771084337349403e-06,
      "loss": 0.0199,
      "step": 138800
    },
    {
      "epoch": 16.72409638554217,
      "grad_norm": 0.20636330544948578,
      "learning_rate": 3.2759036144578315e-06,
      "loss": 0.0242,
      "step": 138810
    },
    {
      "epoch": 16.725301204819278,
      "grad_norm": 0.001220179139636457,
      "learning_rate": 3.274698795180723e-06,
      "loss": 0.0037,
      "step": 138820
    },
    {
      "epoch": 16.726506024096384,
      "grad_norm": 0.00034250254975631833,
      "learning_rate": 3.273493975903615e-06,
      "loss": 0.0098,
      "step": 138830
    },
    {
      "epoch": 16.727710843373494,
      "grad_norm": 0.00016606634017080069,
      "learning_rate": 3.2722891566265063e-06,
      "loss": 0.008,
      "step": 138840
    },
    {
      "epoch": 16.728915662650603,
      "grad_norm": 0.00040806096512824297,
      "learning_rate": 3.271084337349398e-06,
      "loss": 0.0183,
      "step": 138850
    },
    {
      "epoch": 16.73012048192771,
      "grad_norm": 1.0706192255020142,
      "learning_rate": 3.269879518072289e-06,
      "loss": 0.0207,
      "step": 138860
    },
    {
      "epoch": 16.73132530120482,
      "grad_norm": 0.00067070999648422,
      "learning_rate": 3.268674698795181e-06,
      "loss": 0.0184,
      "step": 138870
    },
    {
      "epoch": 16.73253012048193,
      "grad_norm": 2.6013572216033936,
      "learning_rate": 3.2674698795180726e-06,
      "loss": 0.0272,
      "step": 138880
    },
    {
      "epoch": 16.733734939759035,
      "grad_norm": 0.0006500006420537829,
      "learning_rate": 3.266265060240964e-06,
      "loss": 0.0075,
      "step": 138890
    },
    {
      "epoch": 16.734939759036145,
      "grad_norm": 0.047163546085357666,
      "learning_rate": 3.2650602409638554e-06,
      "loss": 0.0076,
      "step": 138900
    },
    {
      "epoch": 16.736144578313255,
      "grad_norm": 0.00040049926610663533,
      "learning_rate": 3.2638554216867474e-06,
      "loss": 0.016,
      "step": 138910
    },
    {
      "epoch": 16.73734939759036,
      "grad_norm": 0.0005632612737827003,
      "learning_rate": 3.262650602409639e-06,
      "loss": 0.0184,
      "step": 138920
    },
    {
      "epoch": 16.73855421686747,
      "grad_norm": 0.0011975044617429376,
      "learning_rate": 3.26144578313253e-06,
      "loss": 0.0051,
      "step": 138930
    },
    {
      "epoch": 16.739759036144576,
      "grad_norm": 0.01110356580466032,
      "learning_rate": 3.260240963855422e-06,
      "loss": 0.0041,
      "step": 138940
    },
    {
      "epoch": 16.740963855421686,
      "grad_norm": 1.1078697443008423,
      "learning_rate": 3.2590361445783137e-06,
      "loss": 0.0179,
      "step": 138950
    },
    {
      "epoch": 16.742168674698796,
      "grad_norm": 2.2039337158203125,
      "learning_rate": 3.257831325301205e-06,
      "loss": 0.0198,
      "step": 138960
    },
    {
      "epoch": 16.743373493975902,
      "grad_norm": 0.005714362487196922,
      "learning_rate": 3.2566265060240965e-06,
      "loss": 0.0139,
      "step": 138970
    },
    {
      "epoch": 16.74457831325301,
      "grad_norm": 0.0015688937855884433,
      "learning_rate": 3.2554216867469885e-06,
      "loss": 0.0258,
      "step": 138980
    },
    {
      "epoch": 16.74578313253012,
      "grad_norm": 0.0007185725844465196,
      "learning_rate": 3.2542168674698797e-06,
      "loss": 0.0072,
      "step": 138990
    },
    {
      "epoch": 16.746987951807228,
      "grad_norm": 0.00024148725788109004,
      "learning_rate": 3.2530120481927713e-06,
      "loss": 0.0117,
      "step": 139000
    },
    {
      "epoch": 16.748192771084337,
      "grad_norm": 0.10617108643054962,
      "learning_rate": 3.251807228915663e-06,
      "loss": 0.0284,
      "step": 139010
    },
    {
      "epoch": 16.749397590361447,
      "grad_norm": 0.00032595230732113123,
      "learning_rate": 3.250602409638555e-06,
      "loss": 0.0,
      "step": 139020
    },
    {
      "epoch": 16.750602409638553,
      "grad_norm": 0.025085682049393654,
      "learning_rate": 3.249397590361446e-06,
      "loss": 0.0072,
      "step": 139030
    },
    {
      "epoch": 16.751807228915663,
      "grad_norm": 0.7914968132972717,
      "learning_rate": 3.2481927710843376e-06,
      "loss": 0.0067,
      "step": 139040
    },
    {
      "epoch": 16.753012048192772,
      "grad_norm": 0.0008622772293165326,
      "learning_rate": 3.2469879518072288e-06,
      "loss": 0.0085,
      "step": 139050
    },
    {
      "epoch": 16.75421686746988,
      "grad_norm": 0.016184022650122643,
      "learning_rate": 3.2457831325301208e-06,
      "loss": 0.0075,
      "step": 139060
    },
    {
      "epoch": 16.75542168674699,
      "grad_norm": 0.010306437499821186,
      "learning_rate": 3.2445783132530124e-06,
      "loss": 0.0265,
      "step": 139070
    },
    {
      "epoch": 16.756626506024098,
      "grad_norm": 0.056657496839761734,
      "learning_rate": 3.2433734939759035e-06,
      "loss": 0.007,
      "step": 139080
    },
    {
      "epoch": 16.757831325301204,
      "grad_norm": 0.001628292491659522,
      "learning_rate": 3.2421686746987955e-06,
      "loss": 0.0083,
      "step": 139090
    },
    {
      "epoch": 16.759036144578314,
      "grad_norm": 0.00017525501607451588,
      "learning_rate": 3.240963855421687e-06,
      "loss": 0.0024,
      "step": 139100
    },
    {
      "epoch": 16.760240963855424,
      "grad_norm": 0.00351281207986176,
      "learning_rate": 3.2397590361445787e-06,
      "loss": 0.0059,
      "step": 139110
    },
    {
      "epoch": 16.76144578313253,
      "grad_norm": 0.00021288426069077104,
      "learning_rate": 3.23855421686747e-06,
      "loss": 0.0152,
      "step": 139120
    },
    {
      "epoch": 16.76265060240964,
      "grad_norm": 0.00023184811288956553,
      "learning_rate": 3.237349397590362e-06,
      "loss": 0.0064,
      "step": 139130
    },
    {
      "epoch": 16.763855421686745,
      "grad_norm": 0.006135550793260336,
      "learning_rate": 3.2361445783132535e-06,
      "loss": 0.0192,
      "step": 139140
    },
    {
      "epoch": 16.765060240963855,
      "grad_norm": 0.0007520373328588903,
      "learning_rate": 3.2349397590361447e-06,
      "loss": 0.0047,
      "step": 139150
    },
    {
      "epoch": 16.766265060240965,
      "grad_norm": 0.0005369933787733316,
      "learning_rate": 3.2337349397590362e-06,
      "loss": 0.0116,
      "step": 139160
    },
    {
      "epoch": 16.76746987951807,
      "grad_norm": 0.0026957194786518812,
      "learning_rate": 3.2325301204819282e-06,
      "loss": 0.0028,
      "step": 139170
    },
    {
      "epoch": 16.76867469879518,
      "grad_norm": 0.18523657321929932,
      "learning_rate": 3.2313253012048194e-06,
      "loss": 0.0275,
      "step": 139180
    },
    {
      "epoch": 16.76987951807229,
      "grad_norm": 0.00038733507972210646,
      "learning_rate": 3.230120481927711e-06,
      "loss": 0.0083,
      "step": 139190
    },
    {
      "epoch": 16.771084337349397,
      "grad_norm": 0.00023426867846865207,
      "learning_rate": 3.2289156626506026e-06,
      "loss": 0.0005,
      "step": 139200
    },
    {
      "epoch": 16.772289156626506,
      "grad_norm": 0.00024078853311948478,
      "learning_rate": 3.227710843373494e-06,
      "loss": 0.0324,
      "step": 139210
    },
    {
      "epoch": 16.773493975903616,
      "grad_norm": 0.0007981545641086996,
      "learning_rate": 3.2265060240963858e-06,
      "loss": 0.0061,
      "step": 139220
    },
    {
      "epoch": 16.774698795180722,
      "grad_norm": 0.0008931678021326661,
      "learning_rate": 3.2253012048192774e-06,
      "loss": 0.0053,
      "step": 139230
    },
    {
      "epoch": 16.77590361445783,
      "grad_norm": 1.1767972707748413,
      "learning_rate": 3.2240963855421694e-06,
      "loss": 0.0124,
      "step": 139240
    },
    {
      "epoch": 16.77710843373494,
      "grad_norm": 0.00037895512650720775,
      "learning_rate": 3.2228915662650605e-06,
      "loss": 0.0123,
      "step": 139250
    },
    {
      "epoch": 16.778313253012048,
      "grad_norm": 0.0002575750113464892,
      "learning_rate": 3.221686746987952e-06,
      "loss": 0.0169,
      "step": 139260
    },
    {
      "epoch": 16.779518072289157,
      "grad_norm": 0.0002053353819064796,
      "learning_rate": 3.2204819277108433e-06,
      "loss": 0.0163,
      "step": 139270
    },
    {
      "epoch": 16.780722891566263,
      "grad_norm": 0.0003528233792167157,
      "learning_rate": 3.2192771084337353e-06,
      "loss": 0.0044,
      "step": 139280
    },
    {
      "epoch": 16.781927710843373,
      "grad_norm": 1.0640757083892822,
      "learning_rate": 3.218072289156627e-06,
      "loss": 0.0325,
      "step": 139290
    },
    {
      "epoch": 16.783132530120483,
      "grad_norm": 0.00019713715300895274,
      "learning_rate": 3.216867469879518e-06,
      "loss": 0.0139,
      "step": 139300
    },
    {
      "epoch": 16.78433734939759,
      "grad_norm": 0.0002095426170853898,
      "learning_rate": 3.2156626506024096e-06,
      "loss": 0.0072,
      "step": 139310
    },
    {
      "epoch": 16.7855421686747,
      "grad_norm": 0.00038931056042201817,
      "learning_rate": 3.2144578313253016e-06,
      "loss": 0.0108,
      "step": 139320
    },
    {
      "epoch": 16.78674698795181,
      "grad_norm": 0.01653970777988434,
      "learning_rate": 3.2132530120481932e-06,
      "loss": 0.0008,
      "step": 139330
    },
    {
      "epoch": 16.787951807228914,
      "grad_norm": 0.0007631192565895617,
      "learning_rate": 3.2120481927710844e-06,
      "loss": 0.0003,
      "step": 139340
    },
    {
      "epoch": 16.789156626506024,
      "grad_norm": 0.00480253528803587,
      "learning_rate": 3.210843373493976e-06,
      "loss": 0.0181,
      "step": 139350
    },
    {
      "epoch": 16.790361445783134,
      "grad_norm": 0.39714813232421875,
      "learning_rate": 3.209638554216868e-06,
      "loss": 0.0302,
      "step": 139360
    },
    {
      "epoch": 16.79156626506024,
      "grad_norm": 0.0009171096025966108,
      "learning_rate": 3.208433734939759e-06,
      "loss": 0.0443,
      "step": 139370
    },
    {
      "epoch": 16.79277108433735,
      "grad_norm": 0.00043898590956814587,
      "learning_rate": 3.2072289156626508e-06,
      "loss": 0.0137,
      "step": 139380
    },
    {
      "epoch": 16.79397590361446,
      "grad_norm": 0.0009743736009113491,
      "learning_rate": 3.2060240963855428e-06,
      "loss": 0.0111,
      "step": 139390
    },
    {
      "epoch": 16.795180722891565,
      "grad_norm": 0.00034141025389544666,
      "learning_rate": 3.204819277108434e-06,
      "loss": 0.0023,
      "step": 139400
    },
    {
      "epoch": 16.796385542168675,
      "grad_norm": 0.3062340021133423,
      "learning_rate": 3.2036144578313255e-06,
      "loss": 0.0247,
      "step": 139410
    },
    {
      "epoch": 16.797590361445785,
      "grad_norm": 0.0005133626400493085,
      "learning_rate": 3.202409638554217e-06,
      "loss": 0.0083,
      "step": 139420
    },
    {
      "epoch": 16.79879518072289,
      "grad_norm": 0.0044488320127129555,
      "learning_rate": 3.201204819277109e-06,
      "loss": 0.0648,
      "step": 139430
    },
    {
      "epoch": 16.8,
      "grad_norm": 0.340111643075943,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0009,
      "step": 139440
    },
    {
      "epoch": 16.801204819277107,
      "grad_norm": 0.00019706445164047182,
      "learning_rate": 3.198795180722892e-06,
      "loss": 0.0081,
      "step": 139450
    },
    {
      "epoch": 16.802409638554217,
      "grad_norm": 0.0009944307385012507,
      "learning_rate": 3.197590361445783e-06,
      "loss": 0.0094,
      "step": 139460
    },
    {
      "epoch": 16.803614457831326,
      "grad_norm": 0.0037288512103259563,
      "learning_rate": 3.196385542168675e-06,
      "loss": 0.0107,
      "step": 139470
    },
    {
      "epoch": 16.804819277108432,
      "grad_norm": 0.00012021559086861089,
      "learning_rate": 3.1951807228915666e-06,
      "loss": 0.0081,
      "step": 139480
    },
    {
      "epoch": 16.806024096385542,
      "grad_norm": 0.00026520105893723667,
      "learning_rate": 3.193975903614458e-06,
      "loss": 0.0206,
      "step": 139490
    },
    {
      "epoch": 16.80722891566265,
      "grad_norm": 7.627408027648926,
      "learning_rate": 3.1927710843373494e-06,
      "loss": 0.025,
      "step": 139500
    },
    {
      "epoch": 16.808433734939758,
      "grad_norm": 15.75196647644043,
      "learning_rate": 3.1915662650602414e-06,
      "loss": 0.0276,
      "step": 139510
    },
    {
      "epoch": 16.809638554216868,
      "grad_norm": 0.1787838339805603,
      "learning_rate": 3.190361445783133e-06,
      "loss": 0.0112,
      "step": 139520
    },
    {
      "epoch": 16.810843373493977,
      "grad_norm": 0.005956601817160845,
      "learning_rate": 3.189156626506024e-06,
      "loss": 0.0102,
      "step": 139530
    },
    {
      "epoch": 16.812048192771083,
      "grad_norm": 0.0002922091807704419,
      "learning_rate": 3.187951807228916e-06,
      "loss": 0.0199,
      "step": 139540
    },
    {
      "epoch": 16.813253012048193,
      "grad_norm": 0.27868688106536865,
      "learning_rate": 3.1867469879518077e-06,
      "loss": 0.0473,
      "step": 139550
    },
    {
      "epoch": 16.814457831325303,
      "grad_norm": 0.014615168794989586,
      "learning_rate": 3.185542168674699e-06,
      "loss": 0.0129,
      "step": 139560
    },
    {
      "epoch": 16.81566265060241,
      "grad_norm": 0.002263057278469205,
      "learning_rate": 3.1843373493975905e-06,
      "loss": 0.0164,
      "step": 139570
    },
    {
      "epoch": 16.81686746987952,
      "grad_norm": 0.5984976887702942,
      "learning_rate": 3.1831325301204825e-06,
      "loss": 0.0381,
      "step": 139580
    },
    {
      "epoch": 16.818072289156625,
      "grad_norm": 0.0011470859171822667,
      "learning_rate": 3.1819277108433737e-06,
      "loss": 0.0073,
      "step": 139590
    },
    {
      "epoch": 16.819277108433734,
      "grad_norm": 1.763994574546814,
      "learning_rate": 3.1807228915662653e-06,
      "loss": 0.0205,
      "step": 139600
    },
    {
      "epoch": 16.820481927710844,
      "grad_norm": 0.008711683563888073,
      "learning_rate": 3.179518072289157e-06,
      "loss": 0.0093,
      "step": 139610
    },
    {
      "epoch": 16.82168674698795,
      "grad_norm": 0.9145402312278748,
      "learning_rate": 3.1783132530120484e-06,
      "loss": 0.0294,
      "step": 139620
    },
    {
      "epoch": 16.82289156626506,
      "grad_norm": 0.0006937035941518843,
      "learning_rate": 3.17710843373494e-06,
      "loss": 0.0073,
      "step": 139630
    },
    {
      "epoch": 16.82409638554217,
      "grad_norm": 0.0014263727935031056,
      "learning_rate": 3.1759036144578316e-06,
      "loss": 0.0083,
      "step": 139640
    },
    {
      "epoch": 16.825301204819276,
      "grad_norm": 0.0012796783121302724,
      "learning_rate": 3.1746987951807228e-06,
      "loss": 0.0201,
      "step": 139650
    },
    {
      "epoch": 16.826506024096386,
      "grad_norm": 0.3134894073009491,
      "learning_rate": 3.173493975903615e-06,
      "loss": 0.0105,
      "step": 139660
    },
    {
      "epoch": 16.827710843373495,
      "grad_norm": 0.0008854549960233271,
      "learning_rate": 3.1722891566265064e-06,
      "loss": 0.0154,
      "step": 139670
    },
    {
      "epoch": 16.8289156626506,
      "grad_norm": 0.005667045712471008,
      "learning_rate": 3.1710843373493975e-06,
      "loss": 0.0159,
      "step": 139680
    },
    {
      "epoch": 16.83012048192771,
      "grad_norm": 2.828256130218506,
      "learning_rate": 3.1698795180722896e-06,
      "loss": 0.0121,
      "step": 139690
    },
    {
      "epoch": 16.83132530120482,
      "grad_norm": 0.009935131296515465,
      "learning_rate": 3.168674698795181e-06,
      "loss": 0.0044,
      "step": 139700
    },
    {
      "epoch": 16.832530120481927,
      "grad_norm": 0.3220755457878113,
      "learning_rate": 3.1674698795180723e-06,
      "loss": 0.0149,
      "step": 139710
    },
    {
      "epoch": 16.833734939759037,
      "grad_norm": 0.009648675099015236,
      "learning_rate": 3.166265060240964e-06,
      "loss": 0.0195,
      "step": 139720
    },
    {
      "epoch": 16.834939759036146,
      "grad_norm": 0.0004238963592797518,
      "learning_rate": 3.165060240963856e-06,
      "loss": 0.0053,
      "step": 139730
    },
    {
      "epoch": 16.836144578313252,
      "grad_norm": 0.23694883286952972,
      "learning_rate": 3.1638554216867475e-06,
      "loss": 0.0236,
      "step": 139740
    },
    {
      "epoch": 16.837349397590362,
      "grad_norm": 0.855127215385437,
      "learning_rate": 3.1626506024096387e-06,
      "loss": 0.0124,
      "step": 139750
    },
    {
      "epoch": 16.83855421686747,
      "grad_norm": 0.8323551416397095,
      "learning_rate": 3.1614457831325302e-06,
      "loss": 0.0238,
      "step": 139760
    },
    {
      "epoch": 16.839759036144578,
      "grad_norm": 0.000507119984831661,
      "learning_rate": 3.1602409638554223e-06,
      "loss": 0.0035,
      "step": 139770
    },
    {
      "epoch": 16.840963855421688,
      "grad_norm": 0.7695748209953308,
      "learning_rate": 3.1590361445783134e-06,
      "loss": 0.0162,
      "step": 139780
    },
    {
      "epoch": 16.842168674698794,
      "grad_norm": 0.0007444545044563711,
      "learning_rate": 3.157831325301205e-06,
      "loss": 0.0061,
      "step": 139790
    },
    {
      "epoch": 16.843373493975903,
      "grad_norm": 1.2192670106887817,
      "learning_rate": 3.156626506024096e-06,
      "loss": 0.0162,
      "step": 139800
    },
    {
      "epoch": 16.844578313253013,
      "grad_norm": 0.0003140157787129283,
      "learning_rate": 3.155421686746988e-06,
      "loss": 0.008,
      "step": 139810
    },
    {
      "epoch": 16.84578313253012,
      "grad_norm": 0.15424835681915283,
      "learning_rate": 3.1542168674698798e-06,
      "loss": 0.0186,
      "step": 139820
    },
    {
      "epoch": 16.84698795180723,
      "grad_norm": 0.012746614404022694,
      "learning_rate": 3.1530120481927714e-06,
      "loss": 0.0178,
      "step": 139830
    },
    {
      "epoch": 16.84819277108434,
      "grad_norm": 0.00026995831285603344,
      "learning_rate": 3.151807228915663e-06,
      "loss": 0.0068,
      "step": 139840
    },
    {
      "epoch": 16.849397590361445,
      "grad_norm": 1.5975492000579834,
      "learning_rate": 3.1506024096385545e-06,
      "loss": 0.0363,
      "step": 139850
    },
    {
      "epoch": 16.850602409638554,
      "grad_norm": 0.00021964419283904135,
      "learning_rate": 3.149397590361446e-06,
      "loss": 0.0112,
      "step": 139860
    },
    {
      "epoch": 16.851807228915664,
      "grad_norm": 0.0005211748066358268,
      "learning_rate": 3.1481927710843373e-06,
      "loss": 0.0024,
      "step": 139870
    },
    {
      "epoch": 16.85301204819277,
      "grad_norm": 0.0013262963620945811,
      "learning_rate": 3.1469879518072293e-06,
      "loss": 0.0071,
      "step": 139880
    },
    {
      "epoch": 16.85421686746988,
      "grad_norm": 0.7810608148574829,
      "learning_rate": 3.145783132530121e-06,
      "loss": 0.0036,
      "step": 139890
    },
    {
      "epoch": 16.855421686746986,
      "grad_norm": 0.0004040670464746654,
      "learning_rate": 3.144578313253012e-06,
      "loss": 0.0181,
      "step": 139900
    },
    {
      "epoch": 16.856626506024096,
      "grad_norm": 0.00040724556311033666,
      "learning_rate": 3.1433734939759036e-06,
      "loss": 0.0197,
      "step": 139910
    },
    {
      "epoch": 16.857831325301206,
      "grad_norm": 0.00014107134484220296,
      "learning_rate": 3.1421686746987957e-06,
      "loss": 0.0024,
      "step": 139920
    },
    {
      "epoch": 16.85903614457831,
      "grad_norm": 0.9163715243339539,
      "learning_rate": 3.140963855421687e-06,
      "loss": 0.0111,
      "step": 139930
    },
    {
      "epoch": 16.86024096385542,
      "grad_norm": 0.00016592074825894088,
      "learning_rate": 3.1397590361445784e-06,
      "loss": 0.0408,
      "step": 139940
    },
    {
      "epoch": 16.86144578313253,
      "grad_norm": 0.0005719384644180536,
      "learning_rate": 3.13855421686747e-06,
      "loss": 0.0221,
      "step": 139950
    },
    {
      "epoch": 16.862650602409637,
      "grad_norm": 1.8146296739578247,
      "learning_rate": 3.137349397590362e-06,
      "loss": 0.0084,
      "step": 139960
    },
    {
      "epoch": 16.863855421686747,
      "grad_norm": 1.4353632926940918,
      "learning_rate": 3.136144578313253e-06,
      "loss": 0.0234,
      "step": 139970
    },
    {
      "epoch": 16.865060240963857,
      "grad_norm": 0.0005530198686756194,
      "learning_rate": 3.1349397590361448e-06,
      "loss": 0.0271,
      "step": 139980
    },
    {
      "epoch": 16.866265060240963,
      "grad_norm": 0.5245655179023743,
      "learning_rate": 3.1337349397590368e-06,
      "loss": 0.0106,
      "step": 139990
    },
    {
      "epoch": 16.867469879518072,
      "grad_norm": 1.7805826663970947,
      "learning_rate": 3.132530120481928e-06,
      "loss": 0.0224,
      "step": 140000
    },
    {
      "epoch": 16.868674698795182,
      "grad_norm": 0.0003429225762374699,
      "learning_rate": 3.1313253012048195e-06,
      "loss": 0.0058,
      "step": 140010
    },
    {
      "epoch": 16.86987951807229,
      "grad_norm": 0.28983554244041443,
      "learning_rate": 3.1301204819277107e-06,
      "loss": 0.007,
      "step": 140020
    },
    {
      "epoch": 16.871084337349398,
      "grad_norm": 0.022110288962721825,
      "learning_rate": 3.1289156626506027e-06,
      "loss": 0.0021,
      "step": 140030
    },
    {
      "epoch": 16.872289156626508,
      "grad_norm": 0.0017808014526963234,
      "learning_rate": 3.1277108433734943e-06,
      "loss": 0.0104,
      "step": 140040
    },
    {
      "epoch": 16.873493975903614,
      "grad_norm": 0.00010545970144448802,
      "learning_rate": 3.126506024096386e-06,
      "loss": 0.0095,
      "step": 140050
    },
    {
      "epoch": 16.874698795180723,
      "grad_norm": 0.00037640839582309127,
      "learning_rate": 3.125301204819277e-06,
      "loss": 0.0375,
      "step": 140060
    },
    {
      "epoch": 16.87590361445783,
      "grad_norm": 0.0077202534303069115,
      "learning_rate": 3.124096385542169e-06,
      "loss": 0.013,
      "step": 140070
    },
    {
      "epoch": 16.87710843373494,
      "grad_norm": 0.0002530622004996985,
      "learning_rate": 3.1228915662650606e-06,
      "loss": 0.0071,
      "step": 140080
    },
    {
      "epoch": 16.87831325301205,
      "grad_norm": 0.0016068306285887957,
      "learning_rate": 3.121686746987952e-06,
      "loss": 0.0261,
      "step": 140090
    },
    {
      "epoch": 16.879518072289155,
      "grad_norm": 0.5267581343650818,
      "learning_rate": 3.120481927710844e-06,
      "loss": 0.0089,
      "step": 140100
    },
    {
      "epoch": 16.880722891566265,
      "grad_norm": 0.00046969097456894815,
      "learning_rate": 3.1192771084337354e-06,
      "loss": 0.0054,
      "step": 140110
    },
    {
      "epoch": 16.881927710843375,
      "grad_norm": 0.0013153367908671498,
      "learning_rate": 3.1180722891566266e-06,
      "loss": 0.0046,
      "step": 140120
    },
    {
      "epoch": 16.88313253012048,
      "grad_norm": 0.897000253200531,
      "learning_rate": 3.116867469879518e-06,
      "loss": 0.0158,
      "step": 140130
    },
    {
      "epoch": 16.88433734939759,
      "grad_norm": 0.0015574493445456028,
      "learning_rate": 3.11566265060241e-06,
      "loss": 0.0036,
      "step": 140140
    },
    {
      "epoch": 16.8855421686747,
      "grad_norm": 0.26227039098739624,
      "learning_rate": 3.1144578313253018e-06,
      "loss": 0.0023,
      "step": 140150
    },
    {
      "epoch": 16.886746987951806,
      "grad_norm": 0.00018710506265051663,
      "learning_rate": 3.113253012048193e-06,
      "loss": 0.001,
      "step": 140160
    },
    {
      "epoch": 16.887951807228916,
      "grad_norm": 0.003923628479242325,
      "learning_rate": 3.1120481927710845e-06,
      "loss": 0.0237,
      "step": 140170
    },
    {
      "epoch": 16.889156626506026,
      "grad_norm": 0.22182543575763702,
      "learning_rate": 3.1108433734939765e-06,
      "loss": 0.0054,
      "step": 140180
    },
    {
      "epoch": 16.89036144578313,
      "grad_norm": 0.00011216512211831287,
      "learning_rate": 3.1096385542168677e-06,
      "loss": 0.0074,
      "step": 140190
    },
    {
      "epoch": 16.89156626506024,
      "grad_norm": 0.0001995154016185552,
      "learning_rate": 3.1084337349397593e-06,
      "loss": 0.0058,
      "step": 140200
    },
    {
      "epoch": 16.89277108433735,
      "grad_norm": 0.005977464374154806,
      "learning_rate": 3.1072289156626504e-06,
      "loss": 0.0186,
      "step": 140210
    },
    {
      "epoch": 16.893975903614457,
      "grad_norm": 0.00105138192884624,
      "learning_rate": 3.1060240963855424e-06,
      "loss": 0.0074,
      "step": 140220
    },
    {
      "epoch": 16.895180722891567,
      "grad_norm": 0.0002528714539948851,
      "learning_rate": 3.104819277108434e-06,
      "loss": 0.0039,
      "step": 140230
    },
    {
      "epoch": 16.896385542168673,
      "grad_norm": 0.0010034163715317845,
      "learning_rate": 3.1036144578313256e-06,
      "loss": 0.0148,
      "step": 140240
    },
    {
      "epoch": 16.897590361445783,
      "grad_norm": 0.7058794498443604,
      "learning_rate": 3.1024096385542172e-06,
      "loss": 0.0112,
      "step": 140250
    },
    {
      "epoch": 16.898795180722892,
      "grad_norm": 0.0001677065883995965,
      "learning_rate": 3.101204819277109e-06,
      "loss": 0.0233,
      "step": 140260
    },
    {
      "epoch": 16.9,
      "grad_norm": 0.001973928650841117,
      "learning_rate": 3.1000000000000004e-06,
      "loss": 0.0001,
      "step": 140270
    },
    {
      "epoch": 16.90120481927711,
      "grad_norm": 0.0001797442528186366,
      "learning_rate": 3.0987951807228916e-06,
      "loss": 0.0207,
      "step": 140280
    },
    {
      "epoch": 16.902409638554218,
      "grad_norm": 0.23712924122810364,
      "learning_rate": 3.0975903614457836e-06,
      "loss": 0.0219,
      "step": 140290
    },
    {
      "epoch": 16.903614457831324,
      "grad_norm": 0.20694515109062195,
      "learning_rate": 3.096385542168675e-06,
      "loss": 0.0145,
      "step": 140300
    },
    {
      "epoch": 16.904819277108434,
      "grad_norm": 0.46734726428985596,
      "learning_rate": 3.0951807228915663e-06,
      "loss": 0.0091,
      "step": 140310
    },
    {
      "epoch": 16.906024096385543,
      "grad_norm": 0.2168668955564499,
      "learning_rate": 3.093975903614458e-06,
      "loss": 0.0036,
      "step": 140320
    },
    {
      "epoch": 16.90722891566265,
      "grad_norm": 0.00013000983744859695,
      "learning_rate": 3.09277108433735e-06,
      "loss": 0.0086,
      "step": 140330
    },
    {
      "epoch": 16.90843373493976,
      "grad_norm": 0.00012681589578278363,
      "learning_rate": 3.091566265060241e-06,
      "loss": 0.0105,
      "step": 140340
    },
    {
      "epoch": 16.90963855421687,
      "grad_norm": 0.00026144683943130076,
      "learning_rate": 3.0903614457831327e-06,
      "loss": 0.0024,
      "step": 140350
    },
    {
      "epoch": 16.910843373493975,
      "grad_norm": 0.0014895700151100755,
      "learning_rate": 3.0891566265060243e-06,
      "loss": 0.0052,
      "step": 140360
    },
    {
      "epoch": 16.912048192771085,
      "grad_norm": 0.001175026991404593,
      "learning_rate": 3.0879518072289163e-06,
      "loss": 0.0153,
      "step": 140370
    },
    {
      "epoch": 16.913253012048195,
      "grad_norm": 0.008848156780004501,
      "learning_rate": 3.0867469879518074e-06,
      "loss": 0.0061,
      "step": 140380
    },
    {
      "epoch": 16.9144578313253,
      "grad_norm": 0.0002266623778268695,
      "learning_rate": 3.085542168674699e-06,
      "loss": 0.0177,
      "step": 140390
    },
    {
      "epoch": 16.91566265060241,
      "grad_norm": 0.0008690622053109109,
      "learning_rate": 3.084337349397591e-06,
      "loss": 0.0023,
      "step": 140400
    },
    {
      "epoch": 16.916867469879517,
      "grad_norm": 0.00016901733761187643,
      "learning_rate": 3.083132530120482e-06,
      "loss": 0.0142,
      "step": 140410
    },
    {
      "epoch": 16.918072289156626,
      "grad_norm": 0.0002488673781044781,
      "learning_rate": 3.0819277108433738e-06,
      "loss": 0.0257,
      "step": 140420
    },
    {
      "epoch": 16.919277108433736,
      "grad_norm": 1.1674913167953491,
      "learning_rate": 3.080722891566265e-06,
      "loss": 0.0083,
      "step": 140430
    },
    {
      "epoch": 16.920481927710842,
      "grad_norm": 0.00015880705905146897,
      "learning_rate": 3.079518072289157e-06,
      "loss": 0.0219,
      "step": 140440
    },
    {
      "epoch": 16.92168674698795,
      "grad_norm": 1.0916612148284912,
      "learning_rate": 3.0783132530120485e-06,
      "loss": 0.0143,
      "step": 140450
    },
    {
      "epoch": 16.92289156626506,
      "grad_norm": 0.00011371166328899562,
      "learning_rate": 3.07710843373494e-06,
      "loss": 0.0081,
      "step": 140460
    },
    {
      "epoch": 16.924096385542168,
      "grad_norm": 3.023885488510132,
      "learning_rate": 3.0759036144578313e-06,
      "loss": 0.0237,
      "step": 140470
    },
    {
      "epoch": 16.925301204819277,
      "grad_norm": 0.00023766954836901277,
      "learning_rate": 3.0746987951807233e-06,
      "loss": 0.0039,
      "step": 140480
    },
    {
      "epoch": 16.926506024096387,
      "grad_norm": 0.00025764331803657115,
      "learning_rate": 3.073493975903615e-06,
      "loss": 0.0237,
      "step": 140490
    },
    {
      "epoch": 16.927710843373493,
      "grad_norm": 0.00023618077102582902,
      "learning_rate": 3.072289156626506e-06,
      "loss": 0.0027,
      "step": 140500
    },
    {
      "epoch": 16.928915662650603,
      "grad_norm": 0.00010722607839852571,
      "learning_rate": 3.0710843373493977e-06,
      "loss": 0.0137,
      "step": 140510
    },
    {
      "epoch": 16.930120481927712,
      "grad_norm": 0.00015211217396426946,
      "learning_rate": 3.0698795180722897e-06,
      "loss": 0.0114,
      "step": 140520
    },
    {
      "epoch": 16.93132530120482,
      "grad_norm": 0.00014227235806174576,
      "learning_rate": 3.068674698795181e-06,
      "loss": 0.0008,
      "step": 140530
    },
    {
      "epoch": 16.93253012048193,
      "grad_norm": 9.626913379179314e-05,
      "learning_rate": 3.0674698795180724e-06,
      "loss": 0.0002,
      "step": 140540
    },
    {
      "epoch": 16.933734939759034,
      "grad_norm": 1.1587345600128174,
      "learning_rate": 3.0662650602409644e-06,
      "loss": 0.013,
      "step": 140550
    },
    {
      "epoch": 16.934939759036144,
      "grad_norm": 0.26779958605766296,
      "learning_rate": 3.0650602409638556e-06,
      "loss": 0.0383,
      "step": 140560
    },
    {
      "epoch": 16.936144578313254,
      "grad_norm": 0.00018656392057891935,
      "learning_rate": 3.063855421686747e-06,
      "loss": 0.0423,
      "step": 140570
    },
    {
      "epoch": 16.93734939759036,
      "grad_norm": 0.00020848434360232204,
      "learning_rate": 3.0626506024096388e-06,
      "loss": 0.0062,
      "step": 140580
    },
    {
      "epoch": 16.93855421686747,
      "grad_norm": 0.006203442811965942,
      "learning_rate": 3.0614457831325308e-06,
      "loss": 0.0314,
      "step": 140590
    },
    {
      "epoch": 16.93975903614458,
      "grad_norm": 0.0015615985030308366,
      "learning_rate": 3.060240963855422e-06,
      "loss": 0.0139,
      "step": 140600
    },
    {
      "epoch": 16.940963855421685,
      "grad_norm": 0.0037864274345338345,
      "learning_rate": 3.0590361445783135e-06,
      "loss": 0.01,
      "step": 140610
    },
    {
      "epoch": 16.942168674698795,
      "grad_norm": 0.00027526100166141987,
      "learning_rate": 3.0578313253012047e-06,
      "loss": 0.0105,
      "step": 140620
    },
    {
      "epoch": 16.943373493975905,
      "grad_norm": 2.0277562141418457,
      "learning_rate": 3.0566265060240967e-06,
      "loss": 0.0119,
      "step": 140630
    },
    {
      "epoch": 16.94457831325301,
      "grad_norm": 1.0145586729049683,
      "learning_rate": 3.0554216867469883e-06,
      "loss": 0.0118,
      "step": 140640
    },
    {
      "epoch": 16.94578313253012,
      "grad_norm": 0.0002612056559883058,
      "learning_rate": 3.0542168674698795e-06,
      "loss": 0.0389,
      "step": 140650
    },
    {
      "epoch": 16.94698795180723,
      "grad_norm": 0.0004589654563460499,
      "learning_rate": 3.053012048192771e-06,
      "loss": 0.0208,
      "step": 140660
    },
    {
      "epoch": 16.948192771084337,
      "grad_norm": 0.00027174694696441293,
      "learning_rate": 3.051807228915663e-06,
      "loss": 0.0135,
      "step": 140670
    },
    {
      "epoch": 16.949397590361446,
      "grad_norm": 0.010746873915195465,
      "learning_rate": 3.0506024096385547e-06,
      "loss": 0.0079,
      "step": 140680
    },
    {
      "epoch": 16.950602409638556,
      "grad_norm": 0.08838700503110886,
      "learning_rate": 3.049397590361446e-06,
      "loss": 0.0409,
      "step": 140690
    },
    {
      "epoch": 16.951807228915662,
      "grad_norm": 0.00424146605655551,
      "learning_rate": 3.048192771084338e-06,
      "loss": 0.0081,
      "step": 140700
    },
    {
      "epoch": 16.95301204819277,
      "grad_norm": 0.0021152382250875235,
      "learning_rate": 3.0469879518072294e-06,
      "loss": 0.0066,
      "step": 140710
    },
    {
      "epoch": 16.954216867469878,
      "grad_norm": 16.56414222717285,
      "learning_rate": 3.0457831325301206e-06,
      "loss": 0.0384,
      "step": 140720
    },
    {
      "epoch": 16.955421686746988,
      "grad_norm": 0.24865169823169708,
      "learning_rate": 3.044578313253012e-06,
      "loss": 0.0123,
      "step": 140730
    },
    {
      "epoch": 16.956626506024097,
      "grad_norm": 0.00035529505112208426,
      "learning_rate": 3.043373493975904e-06,
      "loss": 0.0097,
      "step": 140740
    },
    {
      "epoch": 16.957831325301203,
      "grad_norm": 0.21572960913181305,
      "learning_rate": 3.0421686746987953e-06,
      "loss": 0.0031,
      "step": 140750
    },
    {
      "epoch": 16.959036144578313,
      "grad_norm": 0.728879451751709,
      "learning_rate": 3.040963855421687e-06,
      "loss": 0.0102,
      "step": 140760
    },
    {
      "epoch": 16.960240963855423,
      "grad_norm": 0.000462248019175604,
      "learning_rate": 3.0397590361445785e-06,
      "loss": 0.0118,
      "step": 140770
    },
    {
      "epoch": 16.96144578313253,
      "grad_norm": 0.1938944309949875,
      "learning_rate": 3.0385542168674705e-06,
      "loss": 0.0139,
      "step": 140780
    },
    {
      "epoch": 16.96265060240964,
      "grad_norm": 0.0019465867662802339,
      "learning_rate": 3.0373493975903617e-06,
      "loss": 0.0026,
      "step": 140790
    },
    {
      "epoch": 16.96385542168675,
      "grad_norm": 0.2313879430294037,
      "learning_rate": 3.0361445783132533e-06,
      "loss": 0.0115,
      "step": 140800
    },
    {
      "epoch": 16.965060240963854,
      "grad_norm": 1.1016101837158203,
      "learning_rate": 3.0349397590361444e-06,
      "loss": 0.0084,
      "step": 140810
    },
    {
      "epoch": 16.966265060240964,
      "grad_norm": 0.21107660233974457,
      "learning_rate": 3.0337349397590365e-06,
      "loss": 0.0068,
      "step": 140820
    },
    {
      "epoch": 16.967469879518074,
      "grad_norm": 0.0005765390815213323,
      "learning_rate": 3.032530120481928e-06,
      "loss": 0.0015,
      "step": 140830
    },
    {
      "epoch": 16.96867469879518,
      "grad_norm": 0.0005598178249783814,
      "learning_rate": 3.031325301204819e-06,
      "loss": 0.0024,
      "step": 140840
    },
    {
      "epoch": 16.96987951807229,
      "grad_norm": 0.00023359990154858679,
      "learning_rate": 3.0301204819277112e-06,
      "loss": 0.0074,
      "step": 140850
    },
    {
      "epoch": 16.971084337349396,
      "grad_norm": 0.018664663657546043,
      "learning_rate": 3.028915662650603e-06,
      "loss": 0.0059,
      "step": 140860
    },
    {
      "epoch": 16.972289156626506,
      "grad_norm": 0.0002674102142918855,
      "learning_rate": 3.0277108433734944e-06,
      "loss": 0.0014,
      "step": 140870
    },
    {
      "epoch": 16.973493975903615,
      "grad_norm": 0.0003072192776016891,
      "learning_rate": 3.0265060240963856e-06,
      "loss": 0.0074,
      "step": 140880
    },
    {
      "epoch": 16.97469879518072,
      "grad_norm": 0.9724807739257812,
      "learning_rate": 3.0253012048192776e-06,
      "loss": 0.0055,
      "step": 140890
    },
    {
      "epoch": 16.97590361445783,
      "grad_norm": 2.2847161293029785,
      "learning_rate": 3.024096385542169e-06,
      "loss": 0.0271,
      "step": 140900
    },
    {
      "epoch": 16.97710843373494,
      "grad_norm": 2.863475799560547,
      "learning_rate": 3.0228915662650603e-06,
      "loss": 0.0629,
      "step": 140910
    },
    {
      "epoch": 16.978313253012047,
      "grad_norm": 0.0006949478411115706,
      "learning_rate": 3.021686746987952e-06,
      "loss": 0.0148,
      "step": 140920
    },
    {
      "epoch": 16.979518072289157,
      "grad_norm": 0.00029124869615770876,
      "learning_rate": 3.020481927710844e-06,
      "loss": 0.0019,
      "step": 140930
    },
    {
      "epoch": 16.980722891566266,
      "grad_norm": 1.322191596031189,
      "learning_rate": 3.019277108433735e-06,
      "loss": 0.0045,
      "step": 140940
    },
    {
      "epoch": 16.981927710843372,
      "grad_norm": 0.0004186629957985133,
      "learning_rate": 3.0180722891566267e-06,
      "loss": 0.0104,
      "step": 140950
    },
    {
      "epoch": 16.983132530120482,
      "grad_norm": 0.00042955914977937937,
      "learning_rate": 3.0168674698795183e-06,
      "loss": 0.0269,
      "step": 140960
    },
    {
      "epoch": 16.98433734939759,
      "grad_norm": 0.0004417862219270319,
      "learning_rate": 3.01566265060241e-06,
      "loss": 0.0116,
      "step": 140970
    },
    {
      "epoch": 16.985542168674698,
      "grad_norm": 0.000387151085305959,
      "learning_rate": 3.0144578313253014e-06,
      "loss": 0.0237,
      "step": 140980
    },
    {
      "epoch": 16.986746987951808,
      "grad_norm": 0.00023121890262700617,
      "learning_rate": 3.013253012048193e-06,
      "loss": 0.0078,
      "step": 140990
    },
    {
      "epoch": 16.987951807228917,
      "grad_norm": 0.00014248939987737685,
      "learning_rate": 3.012048192771085e-06,
      "loss": 0.0091,
      "step": 141000
    },
    {
      "epoch": 16.989156626506023,
      "grad_norm": 0.0001462097861804068,
      "learning_rate": 3.010843373493976e-06,
      "loss": 0.0058,
      "step": 141010
    },
    {
      "epoch": 16.990361445783133,
      "grad_norm": 0.3107808232307434,
      "learning_rate": 3.009638554216868e-06,
      "loss": 0.0099,
      "step": 141020
    },
    {
      "epoch": 16.99156626506024,
      "grad_norm": 0.0013103140518069267,
      "learning_rate": 3.008433734939759e-06,
      "loss": 0.0069,
      "step": 141030
    },
    {
      "epoch": 16.99277108433735,
      "grad_norm": 0.24914929270744324,
      "learning_rate": 3.007228915662651e-06,
      "loss": 0.033,
      "step": 141040
    },
    {
      "epoch": 16.99397590361446,
      "grad_norm": 0.00843366514891386,
      "learning_rate": 3.0060240963855426e-06,
      "loss": 0.007,
      "step": 141050
    },
    {
      "epoch": 16.995180722891565,
      "grad_norm": 0.0004768995277117938,
      "learning_rate": 3.0048192771084337e-06,
      "loss": 0.0151,
      "step": 141060
    },
    {
      "epoch": 16.996385542168674,
      "grad_norm": 0.00079598359297961,
      "learning_rate": 3.0036144578313253e-06,
      "loss": 0.014,
      "step": 141070
    },
    {
      "epoch": 16.997590361445784,
      "grad_norm": 0.0002371594891883433,
      "learning_rate": 3.0024096385542173e-06,
      "loss": 0.0133,
      "step": 141080
    },
    {
      "epoch": 16.99879518072289,
      "grad_norm": 1.5600723028182983,
      "learning_rate": 3.001204819277109e-06,
      "loss": 0.0122,
      "step": 141090
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.5325182676315308,
      "learning_rate": 3e-06,
      "loss": 0.0091,
      "step": 141100
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.9875796775403075,
      "eval_f1": 0.9668708588573572,
      "eval_loss": 0.05471426993608475,
      "eval_precision": 0.978120652586316,
      "eval_recall": 0.9558769002595476,
      "eval_runtime": 3371.6171,
      "eval_samples_per_second": 12.662,
      "eval_steps_per_second": 0.528,
      "step": 141100
    },
    {
      "epoch": 17.00120481927711,
      "grad_norm": 0.00015629472909495234,
      "learning_rate": 2.9987951807228917e-06,
      "loss": 0.0033,
      "step": 141110
    },
    {
      "epoch": 17.002409638554216,
      "grad_norm": 0.008099871687591076,
      "learning_rate": 2.9975903614457837e-06,
      "loss": 0.0242,
      "step": 141120
    },
    {
      "epoch": 17.003614457831326,
      "grad_norm": 0.3238869309425354,
      "learning_rate": 2.996385542168675e-06,
      "loss": 0.0037,
      "step": 141130
    },
    {
      "epoch": 17.004819277108435,
      "grad_norm": 0.0006866343901492655,
      "learning_rate": 2.9951807228915664e-06,
      "loss": 0.0131,
      "step": 141140
    },
    {
      "epoch": 17.00602409638554,
      "grad_norm": 0.617808997631073,
      "learning_rate": 2.9939759036144584e-06,
      "loss": 0.0117,
      "step": 141150
    },
    {
      "epoch": 17.00722891566265,
      "grad_norm": 0.00886578019708395,
      "learning_rate": 2.9927710843373496e-06,
      "loss": 0.0079,
      "step": 141160
    },
    {
      "epoch": 17.00843373493976,
      "grad_norm": 0.00046045382623560727,
      "learning_rate": 2.991566265060241e-06,
      "loss": 0.0077,
      "step": 141170
    },
    {
      "epoch": 17.009638554216867,
      "grad_norm": 0.9385064840316772,
      "learning_rate": 2.9903614457831328e-06,
      "loss": 0.0072,
      "step": 141180
    },
    {
      "epoch": 17.010843373493977,
      "grad_norm": 0.03836759552359581,
      "learning_rate": 2.9891566265060244e-06,
      "loss": 0.0127,
      "step": 141190
    },
    {
      "epoch": 17.012048192771083,
      "grad_norm": 0.7330021858215332,
      "learning_rate": 2.987951807228916e-06,
      "loss": 0.0093,
      "step": 141200
    },
    {
      "epoch": 17.013253012048192,
      "grad_norm": 0.00017664780898485333,
      "learning_rate": 2.9867469879518075e-06,
      "loss": 0.0146,
      "step": 141210
    },
    {
      "epoch": 17.014457831325302,
      "grad_norm": 0.00025053758872672915,
      "learning_rate": 2.9855421686746987e-06,
      "loss": 0.0196,
      "step": 141220
    },
    {
      "epoch": 17.01566265060241,
      "grad_norm": 0.00013752351514995098,
      "learning_rate": 2.9843373493975907e-06,
      "loss": 0.0425,
      "step": 141230
    },
    {
      "epoch": 17.016867469879518,
      "grad_norm": 0.00027302405214868486,
      "learning_rate": 2.9831325301204823e-06,
      "loss": 0.0072,
      "step": 141240
    },
    {
      "epoch": 17.018072289156628,
      "grad_norm": 0.0002505830198060721,
      "learning_rate": 2.9819277108433735e-06,
      "loss": 0.0125,
      "step": 141250
    },
    {
      "epoch": 17.019277108433734,
      "grad_norm": 0.0004806523793376982,
      "learning_rate": 2.980722891566265e-06,
      "loss": 0.0064,
      "step": 141260
    },
    {
      "epoch": 17.020481927710843,
      "grad_norm": 0.00014776972238905728,
      "learning_rate": 2.979518072289157e-06,
      "loss": 0.0191,
      "step": 141270
    },
    {
      "epoch": 17.021686746987953,
      "grad_norm": 0.7187743186950684,
      "learning_rate": 2.9783132530120482e-06,
      "loss": 0.0123,
      "step": 141280
    },
    {
      "epoch": 17.02289156626506,
      "grad_norm": 27.27231788635254,
      "learning_rate": 2.97710843373494e-06,
      "loss": 0.0575,
      "step": 141290
    },
    {
      "epoch": 17.02409638554217,
      "grad_norm": 0.00020651964587159455,
      "learning_rate": 2.975903614457832e-06,
      "loss": 0.0103,
      "step": 141300
    },
    {
      "epoch": 17.02530120481928,
      "grad_norm": 0.0017350229900330305,
      "learning_rate": 2.9746987951807234e-06,
      "loss": 0.0053,
      "step": 141310
    },
    {
      "epoch": 17.026506024096385,
      "grad_norm": 0.0002502384886611253,
      "learning_rate": 2.9734939759036146e-06,
      "loss": 0.0069,
      "step": 141320
    },
    {
      "epoch": 17.027710843373494,
      "grad_norm": 0.15357095003128052,
      "learning_rate": 2.972289156626506e-06,
      "loss": 0.0009,
      "step": 141330
    },
    {
      "epoch": 17.0289156626506,
      "grad_norm": 0.794880211353302,
      "learning_rate": 2.971084337349398e-06,
      "loss": 0.0072,
      "step": 141340
    },
    {
      "epoch": 17.03012048192771,
      "grad_norm": 0.0002168439095839858,
      "learning_rate": 2.9698795180722894e-06,
      "loss": 0.0094,
      "step": 141350
    },
    {
      "epoch": 17.03132530120482,
      "grad_norm": 0.24196314811706543,
      "learning_rate": 2.968674698795181e-06,
      "loss": 0.0048,
      "step": 141360
    },
    {
      "epoch": 17.032530120481926,
      "grad_norm": 0.0001791069225873798,
      "learning_rate": 2.967469879518072e-06,
      "loss": 0.0127,
      "step": 141370
    },
    {
      "epoch": 17.033734939759036,
      "grad_norm": 0.006771878805011511,
      "learning_rate": 2.966265060240964e-06,
      "loss": 0.005,
      "step": 141380
    },
    {
      "epoch": 17.034939759036146,
      "grad_norm": 0.9660437107086182,
      "learning_rate": 2.9650602409638557e-06,
      "loss": 0.0184,
      "step": 141390
    },
    {
      "epoch": 17.03614457831325,
      "grad_norm": 0.00017119756375905126,
      "learning_rate": 2.9638554216867473e-06,
      "loss": 0.0,
      "step": 141400
    },
    {
      "epoch": 17.03734939759036,
      "grad_norm": 0.01774289831519127,
      "learning_rate": 2.9626506024096385e-06,
      "loss": 0.0184,
      "step": 141410
    },
    {
      "epoch": 17.03855421686747,
      "grad_norm": 0.0003666482225526124,
      "learning_rate": 2.9614457831325305e-06,
      "loss": 0.0058,
      "step": 141420
    },
    {
      "epoch": 17.039759036144577,
      "grad_norm": 0.10657919198274612,
      "learning_rate": 2.960240963855422e-06,
      "loss": 0.0081,
      "step": 141430
    },
    {
      "epoch": 17.040963855421687,
      "grad_norm": 2.4828011989593506,
      "learning_rate": 2.9590361445783132e-06,
      "loss": 0.0624,
      "step": 141440
    },
    {
      "epoch": 17.042168674698797,
      "grad_norm": 0.00031780058634467423,
      "learning_rate": 2.9578313253012052e-06,
      "loss": 0.0033,
      "step": 141450
    },
    {
      "epoch": 17.043373493975903,
      "grad_norm": 3.137763023376465,
      "learning_rate": 2.956626506024097e-06,
      "loss": 0.0103,
      "step": 141460
    },
    {
      "epoch": 17.044578313253012,
      "grad_norm": 2.130070209503174,
      "learning_rate": 2.955421686746988e-06,
      "loss": 0.0105,
      "step": 141470
    },
    {
      "epoch": 17.045783132530122,
      "grad_norm": 0.004987769760191441,
      "learning_rate": 2.9542168674698796e-06,
      "loss": 0.0059,
      "step": 141480
    },
    {
      "epoch": 17.04698795180723,
      "grad_norm": 0.3210926651954651,
      "learning_rate": 2.9530120481927716e-06,
      "loss": 0.0016,
      "step": 141490
    },
    {
      "epoch": 17.048192771084338,
      "grad_norm": 0.8738349676132202,
      "learning_rate": 2.9518072289156627e-06,
      "loss": 0.0292,
      "step": 141500
    },
    {
      "epoch": 17.049397590361444,
      "grad_norm": 1.826170802116394,
      "learning_rate": 2.9506024096385543e-06,
      "loss": 0.0197,
      "step": 141510
    },
    {
      "epoch": 17.050602409638554,
      "grad_norm": 0.00027422347920946777,
      "learning_rate": 2.949397590361446e-06,
      "loss": 0.0029,
      "step": 141520
    },
    {
      "epoch": 17.051807228915663,
      "grad_norm": 0.0009003590093925595,
      "learning_rate": 2.948192771084338e-06,
      "loss": 0.0307,
      "step": 141530
    },
    {
      "epoch": 17.05301204819277,
      "grad_norm": 0.0015537765575572848,
      "learning_rate": 2.946987951807229e-06,
      "loss": 0.0006,
      "step": 141540
    },
    {
      "epoch": 17.05421686746988,
      "grad_norm": 1.0454233884811401,
      "learning_rate": 2.9457831325301207e-06,
      "loss": 0.0112,
      "step": 141550
    },
    {
      "epoch": 17.05542168674699,
      "grad_norm": 0.00041157155646942556,
      "learning_rate": 2.944578313253012e-06,
      "loss": 0.0127,
      "step": 141560
    },
    {
      "epoch": 17.056626506024095,
      "grad_norm": 0.0008457691874355078,
      "learning_rate": 2.943373493975904e-06,
      "loss": 0.0065,
      "step": 141570
    },
    {
      "epoch": 17.057831325301205,
      "grad_norm": 0.004920481704175472,
      "learning_rate": 2.9421686746987955e-06,
      "loss": 0.0059,
      "step": 141580
    },
    {
      "epoch": 17.059036144578315,
      "grad_norm": 1.9975560903549194,
      "learning_rate": 2.940963855421687e-06,
      "loss": 0.0115,
      "step": 141590
    },
    {
      "epoch": 17.06024096385542,
      "grad_norm": 0.0008813232416287065,
      "learning_rate": 2.9397590361445786e-06,
      "loss": 0.0145,
      "step": 141600
    },
    {
      "epoch": 17.06144578313253,
      "grad_norm": 0.001078614965081215,
      "learning_rate": 2.9385542168674702e-06,
      "loss": 0.0292,
      "step": 141610
    },
    {
      "epoch": 17.06265060240964,
      "grad_norm": 0.00036063368315808475,
      "learning_rate": 2.937349397590362e-06,
      "loss": 0.0011,
      "step": 141620
    },
    {
      "epoch": 17.063855421686746,
      "grad_norm": 0.0006650533759966493,
      "learning_rate": 2.936144578313253e-06,
      "loss": 0.0054,
      "step": 141630
    },
    {
      "epoch": 17.065060240963856,
      "grad_norm": 2.0952038764953613,
      "learning_rate": 2.934939759036145e-06,
      "loss": 0.0178,
      "step": 141640
    },
    {
      "epoch": 17.066265060240966,
      "grad_norm": 1.2127426862716675,
      "learning_rate": 2.9337349397590366e-06,
      "loss": 0.0142,
      "step": 141650
    },
    {
      "epoch": 17.06746987951807,
      "grad_norm": 0.0007390272221527994,
      "learning_rate": 2.9325301204819277e-06,
      "loss": 0.0158,
      "step": 141660
    },
    {
      "epoch": 17.06867469879518,
      "grad_norm": 0.0002836148487403989,
      "learning_rate": 2.9313253012048193e-06,
      "loss": 0.0094,
      "step": 141670
    },
    {
      "epoch": 17.069879518072288,
      "grad_norm": 0.00039586779894307256,
      "learning_rate": 2.9301204819277113e-06,
      "loss": 0.0113,
      "step": 141680
    },
    {
      "epoch": 17.071084337349397,
      "grad_norm": 0.00029590935446321964,
      "learning_rate": 2.9289156626506025e-06,
      "loss": 0.0351,
      "step": 141690
    },
    {
      "epoch": 17.072289156626507,
      "grad_norm": 0.000315177661832422,
      "learning_rate": 2.927710843373494e-06,
      "loss": 0.0198,
      "step": 141700
    },
    {
      "epoch": 17.073493975903613,
      "grad_norm": 0.9418317079544067,
      "learning_rate": 2.9265060240963857e-06,
      "loss": 0.0059,
      "step": 141710
    },
    {
      "epoch": 17.074698795180723,
      "grad_norm": 0.010486883111298084,
      "learning_rate": 2.9253012048192777e-06,
      "loss": 0.0001,
      "step": 141720
    },
    {
      "epoch": 17.075903614457832,
      "grad_norm": 0.002487360965460539,
      "learning_rate": 2.924096385542169e-06,
      "loss": 0.0097,
      "step": 141730
    },
    {
      "epoch": 17.07710843373494,
      "grad_norm": 1.9310296773910522,
      "learning_rate": 2.9228915662650604e-06,
      "loss": 0.0139,
      "step": 141740
    },
    {
      "epoch": 17.07831325301205,
      "grad_norm": 0.0003501583414617926,
      "learning_rate": 2.9216867469879524e-06,
      "loss": 0.0099,
      "step": 141750
    },
    {
      "epoch": 17.079518072289158,
      "grad_norm": 0.0004545057308860123,
      "learning_rate": 2.9204819277108436e-06,
      "loss": 0.0127,
      "step": 141760
    },
    {
      "epoch": 17.080722891566264,
      "grad_norm": 0.00017218977154698223,
      "learning_rate": 2.919277108433735e-06,
      "loss": 0.0068,
      "step": 141770
    },
    {
      "epoch": 17.081927710843374,
      "grad_norm": 1.9095569849014282,
      "learning_rate": 2.9180722891566264e-06,
      "loss": 0.0164,
      "step": 141780
    },
    {
      "epoch": 17.083132530120483,
      "grad_norm": 1.1390914916992188,
      "learning_rate": 2.9168674698795184e-06,
      "loss": 0.0238,
      "step": 141790
    },
    {
      "epoch": 17.08433734939759,
      "grad_norm": 0.7506259083747864,
      "learning_rate": 2.91566265060241e-06,
      "loss": 0.0188,
      "step": 141800
    },
    {
      "epoch": 17.0855421686747,
      "grad_norm": 0.22706784307956696,
      "learning_rate": 2.9144578313253016e-06,
      "loss": 0.0142,
      "step": 141810
    },
    {
      "epoch": 17.086746987951805,
      "grad_norm": 0.07646976411342621,
      "learning_rate": 2.9132530120481927e-06,
      "loss": 0.001,
      "step": 141820
    },
    {
      "epoch": 17.087951807228915,
      "grad_norm": 0.0013242479180917144,
      "learning_rate": 2.9120481927710847e-06,
      "loss": 0.0191,
      "step": 141830
    },
    {
      "epoch": 17.089156626506025,
      "grad_norm": 0.0009347563027404249,
      "learning_rate": 2.9108433734939763e-06,
      "loss": 0.0105,
      "step": 141840
    },
    {
      "epoch": 17.09036144578313,
      "grad_norm": 0.46481630206108093,
      "learning_rate": 2.9096385542168675e-06,
      "loss": 0.0043,
      "step": 141850
    },
    {
      "epoch": 17.09156626506024,
      "grad_norm": 0.00029337353771552444,
      "learning_rate": 2.908433734939759e-06,
      "loss": 0.0179,
      "step": 141860
    },
    {
      "epoch": 17.09277108433735,
      "grad_norm": 0.7926638126373291,
      "learning_rate": 2.907228915662651e-06,
      "loss": 0.018,
      "step": 141870
    },
    {
      "epoch": 17.093975903614457,
      "grad_norm": 0.3608979880809784,
      "learning_rate": 2.9060240963855422e-06,
      "loss": 0.003,
      "step": 141880
    },
    {
      "epoch": 17.095180722891566,
      "grad_norm": 0.7638112306594849,
      "learning_rate": 2.904819277108434e-06,
      "loss": 0.0132,
      "step": 141890
    },
    {
      "epoch": 17.096385542168676,
      "grad_norm": 0.7462868690490723,
      "learning_rate": 2.903614457831326e-06,
      "loss": 0.0048,
      "step": 141900
    },
    {
      "epoch": 17.097590361445782,
      "grad_norm": 0.001748143695294857,
      "learning_rate": 2.902409638554217e-06,
      "loss": 0.0055,
      "step": 141910
    },
    {
      "epoch": 17.09879518072289,
      "grad_norm": 0.001127215102314949,
      "learning_rate": 2.9012048192771086e-06,
      "loss": 0.0206,
      "step": 141920
    },
    {
      "epoch": 17.1,
      "grad_norm": 1.049714207649231,
      "learning_rate": 2.9e-06,
      "loss": 0.0288,
      "step": 141930
    },
    {
      "epoch": 17.101204819277108,
      "grad_norm": 0.00012727729335892946,
      "learning_rate": 2.898795180722892e-06,
      "loss": 0.0485,
      "step": 141940
    },
    {
      "epoch": 17.102409638554217,
      "grad_norm": 0.00021930669026914984,
      "learning_rate": 2.8975903614457834e-06,
      "loss": 0.0124,
      "step": 141950
    },
    {
      "epoch": 17.103614457831327,
      "grad_norm": 0.00044816898298449814,
      "learning_rate": 2.896385542168675e-06,
      "loss": 0.038,
      "step": 141960
    },
    {
      "epoch": 17.104819277108433,
      "grad_norm": 1.446303129196167,
      "learning_rate": 2.895180722891566e-06,
      "loss": 0.0167,
      "step": 141970
    },
    {
      "epoch": 17.106024096385543,
      "grad_norm": 0.28998133540153503,
      "learning_rate": 2.893975903614458e-06,
      "loss": 0.0218,
      "step": 141980
    },
    {
      "epoch": 17.10722891566265,
      "grad_norm": 0.0012637609615921974,
      "learning_rate": 2.8927710843373497e-06,
      "loss": 0.0044,
      "step": 141990
    },
    {
      "epoch": 17.10843373493976,
      "grad_norm": 0.0006945102359168231,
      "learning_rate": 2.891566265060241e-06,
      "loss": 0.0096,
      "step": 142000
    },
    {
      "epoch": 17.10963855421687,
      "grad_norm": 0.0009961505420506,
      "learning_rate": 2.8903614457831325e-06,
      "loss": 0.0113,
      "step": 142010
    },
    {
      "epoch": 17.110843373493974,
      "grad_norm": 0.0006130494875833392,
      "learning_rate": 2.8891566265060245e-06,
      "loss": 0.0082,
      "step": 142020
    },
    {
      "epoch": 17.112048192771084,
      "grad_norm": 0.6479915976524353,
      "learning_rate": 2.887951807228916e-06,
      "loss": 0.0188,
      "step": 142030
    },
    {
      "epoch": 17.113253012048194,
      "grad_norm": 0.8785496354103088,
      "learning_rate": 2.8867469879518072e-06,
      "loss": 0.0036,
      "step": 142040
    },
    {
      "epoch": 17.1144578313253,
      "grad_norm": 0.0003162276407238096,
      "learning_rate": 2.8855421686746992e-06,
      "loss": 0.0071,
      "step": 142050
    },
    {
      "epoch": 17.11566265060241,
      "grad_norm": 0.3328459560871124,
      "learning_rate": 2.884337349397591e-06,
      "loss": 0.0187,
      "step": 142060
    },
    {
      "epoch": 17.11686746987952,
      "grad_norm": 1.1603468656539917,
      "learning_rate": 2.883132530120482e-06,
      "loss": 0.0057,
      "step": 142070
    },
    {
      "epoch": 17.118072289156625,
      "grad_norm": 0.00147852988447994,
      "learning_rate": 2.8819277108433736e-06,
      "loss": 0.0215,
      "step": 142080
    },
    {
      "epoch": 17.119277108433735,
      "grad_norm": 0.6936337947845459,
      "learning_rate": 2.8807228915662656e-06,
      "loss": 0.0203,
      "step": 142090
    },
    {
      "epoch": 17.120481927710845,
      "grad_norm": 0.00013799607404507697,
      "learning_rate": 2.8795180722891568e-06,
      "loss": 0.0103,
      "step": 142100
    },
    {
      "epoch": 17.12168674698795,
      "grad_norm": 0.002461007796227932,
      "learning_rate": 2.8783132530120483e-06,
      "loss": 0.009,
      "step": 142110
    },
    {
      "epoch": 17.12289156626506,
      "grad_norm": 0.000764543772675097,
      "learning_rate": 2.87710843373494e-06,
      "loss": 0.0291,
      "step": 142120
    },
    {
      "epoch": 17.12409638554217,
      "grad_norm": 0.20146824419498444,
      "learning_rate": 2.8759036144578315e-06,
      "loss": 0.0266,
      "step": 142130
    },
    {
      "epoch": 17.125301204819277,
      "grad_norm": 0.3589051067829132,
      "learning_rate": 2.874698795180723e-06,
      "loss": 0.0009,
      "step": 142140
    },
    {
      "epoch": 17.126506024096386,
      "grad_norm": 0.005100129637867212,
      "learning_rate": 2.8734939759036147e-06,
      "loss": 0.0068,
      "step": 142150
    },
    {
      "epoch": 17.127710843373492,
      "grad_norm": 1.2217148542404175,
      "learning_rate": 2.8722891566265067e-06,
      "loss": 0.0121,
      "step": 142160
    },
    {
      "epoch": 17.128915662650602,
      "grad_norm": 0.0005580720608122647,
      "learning_rate": 2.871084337349398e-06,
      "loss": 0.0613,
      "step": 142170
    },
    {
      "epoch": 17.13012048192771,
      "grad_norm": 0.17617172002792358,
      "learning_rate": 2.8698795180722895e-06,
      "loss": 0.0072,
      "step": 142180
    },
    {
      "epoch": 17.131325301204818,
      "grad_norm": 0.44440603256225586,
      "learning_rate": 2.8686746987951806e-06,
      "loss": 0.0041,
      "step": 142190
    },
    {
      "epoch": 17.132530120481928,
      "grad_norm": 0.9263529181480408,
      "learning_rate": 2.8674698795180726e-06,
      "loss": 0.014,
      "step": 142200
    },
    {
      "epoch": 17.133734939759037,
      "grad_norm": 0.0008229778613895178,
      "learning_rate": 2.8662650602409642e-06,
      "loss": 0.0303,
      "step": 142210
    },
    {
      "epoch": 17.134939759036143,
      "grad_norm": 0.0028856259305030107,
      "learning_rate": 2.8650602409638554e-06,
      "loss": 0.036,
      "step": 142220
    },
    {
      "epoch": 17.136144578313253,
      "grad_norm": 1.0011391639709473,
      "learning_rate": 2.863855421686747e-06,
      "loss": 0.0364,
      "step": 142230
    },
    {
      "epoch": 17.137349397590363,
      "grad_norm": 0.006458038929849863,
      "learning_rate": 2.862650602409639e-06,
      "loss": 0.0104,
      "step": 142240
    },
    {
      "epoch": 17.13855421686747,
      "grad_norm": 0.00037303101271390915,
      "learning_rate": 2.8614457831325306e-06,
      "loss": 0.0151,
      "step": 142250
    },
    {
      "epoch": 17.13975903614458,
      "grad_norm": 0.31094983220100403,
      "learning_rate": 2.8602409638554217e-06,
      "loss": 0.0054,
      "step": 142260
    },
    {
      "epoch": 17.14096385542169,
      "grad_norm": 1.3809866905212402,
      "learning_rate": 2.8590361445783133e-06,
      "loss": 0.0334,
      "step": 142270
    },
    {
      "epoch": 17.142168674698794,
      "grad_norm": 0.0013794525293633342,
      "learning_rate": 2.8578313253012053e-06,
      "loss": 0.0121,
      "step": 142280
    },
    {
      "epoch": 17.143373493975904,
      "grad_norm": 0.3944985866546631,
      "learning_rate": 2.8566265060240965e-06,
      "loss": 0.0074,
      "step": 142290
    },
    {
      "epoch": 17.14457831325301,
      "grad_norm": 0.00011538412218214944,
      "learning_rate": 2.855421686746988e-06,
      "loss": 0.0062,
      "step": 142300
    },
    {
      "epoch": 17.14578313253012,
      "grad_norm": 0.007245567161589861,
      "learning_rate": 2.85421686746988e-06,
      "loss": 0.0028,
      "step": 142310
    },
    {
      "epoch": 17.14698795180723,
      "grad_norm": 0.0002473813365213573,
      "learning_rate": 2.8530120481927713e-06,
      "loss": 0.0127,
      "step": 142320
    },
    {
      "epoch": 17.148192771084336,
      "grad_norm": 0.0008852476603351533,
      "learning_rate": 2.851807228915663e-06,
      "loss": 0.0116,
      "step": 142330
    },
    {
      "epoch": 17.149397590361446,
      "grad_norm": 0.19898712635040283,
      "learning_rate": 2.8506024096385544e-06,
      "loss": 0.0286,
      "step": 142340
    },
    {
      "epoch": 17.150602409638555,
      "grad_norm": 0.0008800122304819524,
      "learning_rate": 2.8493975903614465e-06,
      "loss": 0.0113,
      "step": 142350
    },
    {
      "epoch": 17.15180722891566,
      "grad_norm": 0.0002150822983821854,
      "learning_rate": 2.8481927710843376e-06,
      "loss": 0.0229,
      "step": 142360
    },
    {
      "epoch": 17.15301204819277,
      "grad_norm": 0.0017746135126799345,
      "learning_rate": 2.846987951807229e-06,
      "loss": 0.0179,
      "step": 142370
    },
    {
      "epoch": 17.15421686746988,
      "grad_norm": 0.00039330238359980285,
      "learning_rate": 2.8457831325301204e-06,
      "loss": 0.0009,
      "step": 142380
    },
    {
      "epoch": 17.155421686746987,
      "grad_norm": 0.00022781315783504397,
      "learning_rate": 2.8445783132530124e-06,
      "loss": 0.0128,
      "step": 142390
    },
    {
      "epoch": 17.156626506024097,
      "grad_norm": 0.000779481662902981,
      "learning_rate": 2.843373493975904e-06,
      "loss": 0.0004,
      "step": 142400
    },
    {
      "epoch": 17.157831325301206,
      "grad_norm": 0.006643497385084629,
      "learning_rate": 2.842168674698795e-06,
      "loss": 0.008,
      "step": 142410
    },
    {
      "epoch": 17.159036144578312,
      "grad_norm": 0.00014589143393095583,
      "learning_rate": 2.8409638554216867e-06,
      "loss": 0.0164,
      "step": 142420
    },
    {
      "epoch": 17.160240963855422,
      "grad_norm": 0.00022249184257816523,
      "learning_rate": 2.8397590361445787e-06,
      "loss": 0.0149,
      "step": 142430
    },
    {
      "epoch": 17.16144578313253,
      "grad_norm": 0.8987367749214172,
      "learning_rate": 2.8385542168674703e-06,
      "loss": 0.0125,
      "step": 142440
    },
    {
      "epoch": 17.162650602409638,
      "grad_norm": 0.002731438959017396,
      "learning_rate": 2.8373493975903615e-06,
      "loss": 0.0092,
      "step": 142450
    },
    {
      "epoch": 17.163855421686748,
      "grad_norm": 0.0003231394221074879,
      "learning_rate": 2.8361445783132535e-06,
      "loss": 0.0079,
      "step": 142460
    },
    {
      "epoch": 17.165060240963854,
      "grad_norm": 6.651281000813469e-05,
      "learning_rate": 2.834939759036145e-06,
      "loss": 0.0075,
      "step": 142470
    },
    {
      "epoch": 17.166265060240963,
      "grad_norm": 0.0008085442241281271,
      "learning_rate": 2.8337349397590363e-06,
      "loss": 0.0016,
      "step": 142480
    },
    {
      "epoch": 17.167469879518073,
      "grad_norm": 0.0001746496418491006,
      "learning_rate": 2.832530120481928e-06,
      "loss": 0.0129,
      "step": 142490
    },
    {
      "epoch": 17.16867469879518,
      "grad_norm": 0.0006367343012243509,
      "learning_rate": 2.83132530120482e-06,
      "loss": 0.0103,
      "step": 142500
    },
    {
      "epoch": 17.16987951807229,
      "grad_norm": 0.00019572227029129863,
      "learning_rate": 2.830120481927711e-06,
      "loss": 0.0052,
      "step": 142510
    },
    {
      "epoch": 17.1710843373494,
      "grad_norm": 0.00048591711674816906,
      "learning_rate": 2.8289156626506026e-06,
      "loss": 0.0094,
      "step": 142520
    },
    {
      "epoch": 17.172289156626505,
      "grad_norm": 1.4496822357177734,
      "learning_rate": 2.827710843373494e-06,
      "loss": 0.0109,
      "step": 142530
    },
    {
      "epoch": 17.173493975903614,
      "grad_norm": 0.00041641711140982807,
      "learning_rate": 2.8265060240963858e-06,
      "loss": 0.018,
      "step": 142540
    },
    {
      "epoch": 17.174698795180724,
      "grad_norm": 0.002003604779019952,
      "learning_rate": 2.8253012048192774e-06,
      "loss": 0.0033,
      "step": 142550
    },
    {
      "epoch": 17.17590361445783,
      "grad_norm": 1.2904319763183594,
      "learning_rate": 2.824096385542169e-06,
      "loss": 0.0102,
      "step": 142560
    },
    {
      "epoch": 17.17710843373494,
      "grad_norm": 0.16305315494537354,
      "learning_rate": 2.82289156626506e-06,
      "loss": 0.0071,
      "step": 142570
    },
    {
      "epoch": 17.17831325301205,
      "grad_norm": 0.0001985708368010819,
      "learning_rate": 2.821686746987952e-06,
      "loss": 0.0012,
      "step": 142580
    },
    {
      "epoch": 17.179518072289156,
      "grad_norm": 0.005041250493377447,
      "learning_rate": 2.8204819277108437e-06,
      "loss": 0.0215,
      "step": 142590
    },
    {
      "epoch": 17.180722891566266,
      "grad_norm": 0.0009254689794033766,
      "learning_rate": 2.819277108433735e-06,
      "loss": 0.0035,
      "step": 142600
    },
    {
      "epoch": 17.181927710843375,
      "grad_norm": 0.00015038720448501408,
      "learning_rate": 2.818072289156627e-06,
      "loss": 0.0248,
      "step": 142610
    },
    {
      "epoch": 17.18313253012048,
      "grad_norm": 0.07432837039232254,
      "learning_rate": 2.8168674698795185e-06,
      "loss": 0.0008,
      "step": 142620
    },
    {
      "epoch": 17.18433734939759,
      "grad_norm": 0.0002974981034640223,
      "learning_rate": 2.8156626506024097e-06,
      "loss": 0.0073,
      "step": 142630
    },
    {
      "epoch": 17.185542168674697,
      "grad_norm": 0.00038307104841805995,
      "learning_rate": 2.8144578313253012e-06,
      "loss": 0.0055,
      "step": 142640
    },
    {
      "epoch": 17.186746987951807,
      "grad_norm": 1.0109453201293945,
      "learning_rate": 2.8132530120481933e-06,
      "loss": 0.005,
      "step": 142650
    },
    {
      "epoch": 17.187951807228917,
      "grad_norm": 0.0028017659205943346,
      "learning_rate": 2.812048192771085e-06,
      "loss": 0.0196,
      "step": 142660
    },
    {
      "epoch": 17.189156626506023,
      "grad_norm": 0.0994868203997612,
      "learning_rate": 2.810843373493976e-06,
      "loss": 0.0238,
      "step": 142670
    },
    {
      "epoch": 17.190361445783132,
      "grad_norm": 0.00042086339090019464,
      "learning_rate": 2.8096385542168676e-06,
      "loss": 0.0216,
      "step": 142680
    },
    {
      "epoch": 17.191566265060242,
      "grad_norm": 0.00019922202045563608,
      "learning_rate": 2.8084337349397596e-06,
      "loss": 0.0124,
      "step": 142690
    },
    {
      "epoch": 17.19277108433735,
      "grad_norm": 0.7793596982955933,
      "learning_rate": 2.8072289156626508e-06,
      "loss": 0.0175,
      "step": 142700
    },
    {
      "epoch": 17.193975903614458,
      "grad_norm": 0.0004170080355834216,
      "learning_rate": 2.8060240963855424e-06,
      "loss": 0.0177,
      "step": 142710
    },
    {
      "epoch": 17.195180722891568,
      "grad_norm": 0.0013898183824494481,
      "learning_rate": 2.8048192771084335e-06,
      "loss": 0.0084,
      "step": 142720
    },
    {
      "epoch": 17.196385542168674,
      "grad_norm": 1.0628509521484375,
      "learning_rate": 2.8036144578313255e-06,
      "loss": 0.0071,
      "step": 142730
    },
    {
      "epoch": 17.197590361445783,
      "grad_norm": 0.0008776379399932921,
      "learning_rate": 2.802409638554217e-06,
      "loss": 0.0106,
      "step": 142740
    },
    {
      "epoch": 17.198795180722893,
      "grad_norm": 0.17439372837543488,
      "learning_rate": 2.8012048192771087e-06,
      "loss": 0.0182,
      "step": 142750
    },
    {
      "epoch": 17.2,
      "grad_norm": 0.00033103537862189114,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0271,
      "step": 142760
    },
    {
      "epoch": 17.20120481927711,
      "grad_norm": 0.4880906939506531,
      "learning_rate": 2.798795180722892e-06,
      "loss": 0.0073,
      "step": 142770
    },
    {
      "epoch": 17.202409638554215,
      "grad_norm": 0.00014853384345769882,
      "learning_rate": 2.7975903614457835e-06,
      "loss": 0.0417,
      "step": 142780
    },
    {
      "epoch": 17.203614457831325,
      "grad_norm": 0.029077356681227684,
      "learning_rate": 2.7963855421686746e-06,
      "loss": 0.0102,
      "step": 142790
    },
    {
      "epoch": 17.204819277108435,
      "grad_norm": 0.0003186957910656929,
      "learning_rate": 2.7951807228915666e-06,
      "loss": 0.0234,
      "step": 142800
    },
    {
      "epoch": 17.20602409638554,
      "grad_norm": 0.0012880268041044474,
      "learning_rate": 2.7939759036144582e-06,
      "loss": 0.0143,
      "step": 142810
    },
    {
      "epoch": 17.20722891566265,
      "grad_norm": 0.4195511043071747,
      "learning_rate": 2.7927710843373494e-06,
      "loss": 0.0032,
      "step": 142820
    },
    {
      "epoch": 17.20843373493976,
      "grad_norm": 0.0006537575391121209,
      "learning_rate": 2.791566265060241e-06,
      "loss": 0.0126,
      "step": 142830
    },
    {
      "epoch": 17.209638554216866,
      "grad_norm": 2.227854013442993,
      "learning_rate": 2.790361445783133e-06,
      "loss": 0.01,
      "step": 142840
    },
    {
      "epoch": 17.210843373493976,
      "grad_norm": 0.5477349162101746,
      "learning_rate": 2.789156626506024e-06,
      "loss": 0.0095,
      "step": 142850
    },
    {
      "epoch": 17.212048192771086,
      "grad_norm": 0.001151286531239748,
      "learning_rate": 2.7879518072289158e-06,
      "loss": 0.0242,
      "step": 142860
    },
    {
      "epoch": 17.21325301204819,
      "grad_norm": 0.0007330833468586206,
      "learning_rate": 2.7867469879518073e-06,
      "loss": 0.0066,
      "step": 142870
    },
    {
      "epoch": 17.2144578313253,
      "grad_norm": 0.0015915058320388198,
      "learning_rate": 2.7855421686746994e-06,
      "loss": 0.006,
      "step": 142880
    },
    {
      "epoch": 17.21566265060241,
      "grad_norm": 0.23921355605125427,
      "learning_rate": 2.7843373493975905e-06,
      "loss": 0.0168,
      "step": 142890
    },
    {
      "epoch": 17.216867469879517,
      "grad_norm": 0.004630933050066233,
      "learning_rate": 2.783132530120482e-06,
      "loss": 0.0106,
      "step": 142900
    },
    {
      "epoch": 17.218072289156627,
      "grad_norm": 0.0021783215925097466,
      "learning_rate": 2.781927710843374e-06,
      "loss": 0.0145,
      "step": 142910
    },
    {
      "epoch": 17.219277108433737,
      "grad_norm": 0.00045167497592046857,
      "learning_rate": 2.7807228915662653e-06,
      "loss": 0.0014,
      "step": 142920
    },
    {
      "epoch": 17.220481927710843,
      "grad_norm": 3.5086464881896973,
      "learning_rate": 2.779518072289157e-06,
      "loss": 0.0205,
      "step": 142930
    },
    {
      "epoch": 17.221686746987952,
      "grad_norm": 0.005378848407417536,
      "learning_rate": 2.778313253012048e-06,
      "loss": 0.0043,
      "step": 142940
    },
    {
      "epoch": 17.22289156626506,
      "grad_norm": 0.866790771484375,
      "learning_rate": 2.77710843373494e-06,
      "loss": 0.0198,
      "step": 142950
    },
    {
      "epoch": 17.22409638554217,
      "grad_norm": 0.2252190113067627,
      "learning_rate": 2.7759036144578316e-06,
      "loss": 0.0204,
      "step": 142960
    },
    {
      "epoch": 17.225301204819278,
      "grad_norm": 1.2233952283859253,
      "learning_rate": 2.7746987951807232e-06,
      "loss": 0.0074,
      "step": 142970
    },
    {
      "epoch": 17.226506024096384,
      "grad_norm": 2.3461596965789795,
      "learning_rate": 2.7734939759036144e-06,
      "loss": 0.0261,
      "step": 142980
    },
    {
      "epoch": 17.227710843373494,
      "grad_norm": 0.9490441679954529,
      "learning_rate": 2.7722891566265064e-06,
      "loss": 0.0167,
      "step": 142990
    },
    {
      "epoch": 17.228915662650603,
      "grad_norm": 0.0009326848085038364,
      "learning_rate": 2.771084337349398e-06,
      "loss": 0.0036,
      "step": 143000
    },
    {
      "epoch": 17.23012048192771,
      "grad_norm": 0.0003987447707913816,
      "learning_rate": 2.769879518072289e-06,
      "loss": 0.0127,
      "step": 143010
    },
    {
      "epoch": 17.23132530120482,
      "grad_norm": 0.00019720684213098139,
      "learning_rate": 2.7686746987951807e-06,
      "loss": 0.0001,
      "step": 143020
    },
    {
      "epoch": 17.23253012048193,
      "grad_norm": 0.02018221653997898,
      "learning_rate": 2.7674698795180727e-06,
      "loss": 0.0141,
      "step": 143030
    },
    {
      "epoch": 17.233734939759035,
      "grad_norm": 0.03158693388104439,
      "learning_rate": 2.766265060240964e-06,
      "loss": 0.0244,
      "step": 143040
    },
    {
      "epoch": 17.234939759036145,
      "grad_norm": 0.0005482565611600876,
      "learning_rate": 2.7650602409638555e-06,
      "loss": 0.0133,
      "step": 143050
    },
    {
      "epoch": 17.236144578313255,
      "grad_norm": 0.009160876274108887,
      "learning_rate": 2.7638554216867475e-06,
      "loss": 0.0077,
      "step": 143060
    },
    {
      "epoch": 17.23734939759036,
      "grad_norm": 1.4236619472503662,
      "learning_rate": 2.762650602409639e-06,
      "loss": 0.0213,
      "step": 143070
    },
    {
      "epoch": 17.23855421686747,
      "grad_norm": 0.6796478033065796,
      "learning_rate": 2.7614457831325303e-06,
      "loss": 0.0105,
      "step": 143080
    },
    {
      "epoch": 17.23975903614458,
      "grad_norm": 0.1134127825498581,
      "learning_rate": 2.760240963855422e-06,
      "loss": 0.0108,
      "step": 143090
    },
    {
      "epoch": 17.240963855421686,
      "grad_norm": 1.794137716293335,
      "learning_rate": 2.759036144578314e-06,
      "loss": 0.0424,
      "step": 143100
    },
    {
      "epoch": 17.242168674698796,
      "grad_norm": 0.8416303396224976,
      "learning_rate": 2.757831325301205e-06,
      "loss": 0.0116,
      "step": 143110
    },
    {
      "epoch": 17.243373493975902,
      "grad_norm": 0.0005442829569801688,
      "learning_rate": 2.7566265060240966e-06,
      "loss": 0.0268,
      "step": 143120
    },
    {
      "epoch": 17.24457831325301,
      "grad_norm": 0.0004005572700407356,
      "learning_rate": 2.7554216867469878e-06,
      "loss": 0.0323,
      "step": 143130
    },
    {
      "epoch": 17.24578313253012,
      "grad_norm": 0.002575538819655776,
      "learning_rate": 2.75421686746988e-06,
      "loss": 0.021,
      "step": 143140
    },
    {
      "epoch": 17.246987951807228,
      "grad_norm": 0.00269868690520525,
      "learning_rate": 2.7530120481927714e-06,
      "loss": 0.0094,
      "step": 143150
    },
    {
      "epoch": 17.248192771084337,
      "grad_norm": 1.0104254484176636,
      "learning_rate": 2.751807228915663e-06,
      "loss": 0.0252,
      "step": 143160
    },
    {
      "epoch": 17.249397590361447,
      "grad_norm": 7.101813316345215,
      "learning_rate": 2.750602409638554e-06,
      "loss": 0.011,
      "step": 143170
    },
    {
      "epoch": 17.250602409638553,
      "grad_norm": 0.03227284923195839,
      "learning_rate": 2.749397590361446e-06,
      "loss": 0.0116,
      "step": 143180
    },
    {
      "epoch": 17.251807228915663,
      "grad_norm": 0.0013647065497934818,
      "learning_rate": 2.7481927710843377e-06,
      "loss": 0.004,
      "step": 143190
    },
    {
      "epoch": 17.253012048192772,
      "grad_norm": 0.02883007749915123,
      "learning_rate": 2.746987951807229e-06,
      "loss": 0.0019,
      "step": 143200
    },
    {
      "epoch": 17.25421686746988,
      "grad_norm": 0.003497482743114233,
      "learning_rate": 2.745783132530121e-06,
      "loss": 0.0089,
      "step": 143210
    },
    {
      "epoch": 17.25542168674699,
      "grad_norm": 0.004159777425229549,
      "learning_rate": 2.7445783132530125e-06,
      "loss": 0.0179,
      "step": 143220
    },
    {
      "epoch": 17.256626506024098,
      "grad_norm": 1.329635739326477,
      "learning_rate": 2.7433734939759037e-06,
      "loss": 0.0047,
      "step": 143230
    },
    {
      "epoch": 17.257831325301204,
      "grad_norm": 0.0007494362071156502,
      "learning_rate": 2.7421686746987953e-06,
      "loss": 0.0069,
      "step": 143240
    },
    {
      "epoch": 17.259036144578314,
      "grad_norm": 0.00048102441360242665,
      "learning_rate": 2.7409638554216873e-06,
      "loss": 0.0119,
      "step": 143250
    },
    {
      "epoch": 17.26024096385542,
      "grad_norm": 0.002566712675616145,
      "learning_rate": 2.7397590361445784e-06,
      "loss": 0.0086,
      "step": 143260
    },
    {
      "epoch": 17.26144578313253,
      "grad_norm": 0.33439064025878906,
      "learning_rate": 2.73855421686747e-06,
      "loss": 0.0193,
      "step": 143270
    },
    {
      "epoch": 17.26265060240964,
      "grad_norm": 0.3034414052963257,
      "learning_rate": 2.7373493975903616e-06,
      "loss": 0.0081,
      "step": 143280
    },
    {
      "epoch": 17.263855421686745,
      "grad_norm": 1.2591520547866821,
      "learning_rate": 2.7361445783132536e-06,
      "loss": 0.0122,
      "step": 143290
    },
    {
      "epoch": 17.265060240963855,
      "grad_norm": 0.883601725101471,
      "learning_rate": 2.7349397590361448e-06,
      "loss": 0.0191,
      "step": 143300
    },
    {
      "epoch": 17.266265060240965,
      "grad_norm": 0.0002866397553589195,
      "learning_rate": 2.7337349397590364e-06,
      "loss": 0.021,
      "step": 143310
    },
    {
      "epoch": 17.26746987951807,
      "grad_norm": 0.000988369807600975,
      "learning_rate": 2.7325301204819275e-06,
      "loss": 0.0007,
      "step": 143320
    },
    {
      "epoch": 17.26867469879518,
      "grad_norm": 0.00027239060727879405,
      "learning_rate": 2.7313253012048195e-06,
      "loss": 0.0232,
      "step": 143330
    },
    {
      "epoch": 17.26987951807229,
      "grad_norm": 1.0264537334442139,
      "learning_rate": 2.730120481927711e-06,
      "loss": 0.0263,
      "step": 143340
    },
    {
      "epoch": 17.271084337349397,
      "grad_norm": 0.0002470312174409628,
      "learning_rate": 2.7289156626506023e-06,
      "loss": 0.0144,
      "step": 143350
    },
    {
      "epoch": 17.272289156626506,
      "grad_norm": 0.23066361248493195,
      "learning_rate": 2.7277108433734943e-06,
      "loss": 0.0069,
      "step": 143360
    },
    {
      "epoch": 17.273493975903616,
      "grad_norm": 0.0003376404638402164,
      "learning_rate": 2.726506024096386e-06,
      "loss": 0.015,
      "step": 143370
    },
    {
      "epoch": 17.274698795180722,
      "grad_norm": 0.30791884660720825,
      "learning_rate": 2.7253012048192775e-06,
      "loss": 0.0083,
      "step": 143380
    },
    {
      "epoch": 17.27590361445783,
      "grad_norm": 0.00011219336010981351,
      "learning_rate": 2.7240963855421686e-06,
      "loss": 0.0066,
      "step": 143390
    },
    {
      "epoch": 17.27710843373494,
      "grad_norm": 0.0004937461344525218,
      "learning_rate": 2.7228915662650607e-06,
      "loss": 0.007,
      "step": 143400
    },
    {
      "epoch": 17.278313253012048,
      "grad_norm": 0.0002562587906140834,
      "learning_rate": 2.7216867469879522e-06,
      "loss": 0.017,
      "step": 143410
    },
    {
      "epoch": 17.279518072289157,
      "grad_norm": 1.2150592803955078,
      "learning_rate": 2.7204819277108434e-06,
      "loss": 0.0096,
      "step": 143420
    },
    {
      "epoch": 17.280722891566263,
      "grad_norm": 0.0012584506766870618,
      "learning_rate": 2.719277108433735e-06,
      "loss": 0.004,
      "step": 143430
    },
    {
      "epoch": 17.281927710843373,
      "grad_norm": 0.05295775085687637,
      "learning_rate": 2.718072289156627e-06,
      "loss": 0.0264,
      "step": 143440
    },
    {
      "epoch": 17.283132530120483,
      "grad_norm": 0.0020266969222575426,
      "learning_rate": 2.716867469879518e-06,
      "loss": 0.0133,
      "step": 143450
    },
    {
      "epoch": 17.28433734939759,
      "grad_norm": 0.00026738489395938814,
      "learning_rate": 2.7156626506024098e-06,
      "loss": 0.0221,
      "step": 143460
    },
    {
      "epoch": 17.2855421686747,
      "grad_norm": 0.6226145029067993,
      "learning_rate": 2.7144578313253014e-06,
      "loss": 0.0076,
      "step": 143470
    },
    {
      "epoch": 17.28674698795181,
      "grad_norm": 0.0004289194766897708,
      "learning_rate": 2.713253012048193e-06,
      "loss": 0.0111,
      "step": 143480
    },
    {
      "epoch": 17.287951807228914,
      "grad_norm": 0.5737937688827515,
      "learning_rate": 2.7120481927710845e-06,
      "loss": 0.0015,
      "step": 143490
    },
    {
      "epoch": 17.289156626506024,
      "grad_norm": 1.2000669240951538,
      "learning_rate": 2.710843373493976e-06,
      "loss": 0.0177,
      "step": 143500
    },
    {
      "epoch": 17.290361445783134,
      "grad_norm": 0.00018459177226759493,
      "learning_rate": 2.709638554216868e-06,
      "loss": 0.0165,
      "step": 143510
    },
    {
      "epoch": 17.29156626506024,
      "grad_norm": 0.00031068531097844243,
      "learning_rate": 2.7084337349397593e-06,
      "loss": 0.0244,
      "step": 143520
    },
    {
      "epoch": 17.29277108433735,
      "grad_norm": 7.945825927890837e-05,
      "learning_rate": 2.707228915662651e-06,
      "loss": 0.0053,
      "step": 143530
    },
    {
      "epoch": 17.29397590361446,
      "grad_norm": 0.04206206649541855,
      "learning_rate": 2.706024096385542e-06,
      "loss": 0.0199,
      "step": 143540
    },
    {
      "epoch": 17.295180722891565,
      "grad_norm": 7.328356878133491e-05,
      "learning_rate": 2.704819277108434e-06,
      "loss": 0.0105,
      "step": 143550
    },
    {
      "epoch": 17.296385542168675,
      "grad_norm": 0.9656825065612793,
      "learning_rate": 2.7036144578313256e-06,
      "loss": 0.0059,
      "step": 143560
    },
    {
      "epoch": 17.297590361445785,
      "grad_norm": 0.1725967824459076,
      "learning_rate": 2.702409638554217e-06,
      "loss": 0.0072,
      "step": 143570
    },
    {
      "epoch": 17.29879518072289,
      "grad_norm": 0.0001499841018812731,
      "learning_rate": 2.7012048192771084e-06,
      "loss": 0.0066,
      "step": 143580
    },
    {
      "epoch": 17.3,
      "grad_norm": 0.13763919472694397,
      "learning_rate": 2.7000000000000004e-06,
      "loss": 0.0191,
      "step": 143590
    },
    {
      "epoch": 17.301204819277107,
      "grad_norm": 0.0001767029461916536,
      "learning_rate": 2.698795180722892e-06,
      "loss": 0.0158,
      "step": 143600
    },
    {
      "epoch": 17.302409638554217,
      "grad_norm": 1.067216157913208,
      "learning_rate": 2.697590361445783e-06,
      "loss": 0.0201,
      "step": 143610
    },
    {
      "epoch": 17.303614457831326,
      "grad_norm": 1.1870434284210205,
      "learning_rate": 2.6963855421686747e-06,
      "loss": 0.009,
      "step": 143620
    },
    {
      "epoch": 17.304819277108432,
      "grad_norm": 0.0006280259694904089,
      "learning_rate": 2.6951807228915668e-06,
      "loss": 0.0104,
      "step": 143630
    },
    {
      "epoch": 17.306024096385542,
      "grad_norm": 0.00015521641762461513,
      "learning_rate": 2.693975903614458e-06,
      "loss": 0.0034,
      "step": 143640
    },
    {
      "epoch": 17.30722891566265,
      "grad_norm": 1.833368182182312,
      "learning_rate": 2.6927710843373495e-06,
      "loss": 0.0219,
      "step": 143650
    },
    {
      "epoch": 17.308433734939758,
      "grad_norm": 0.00028351787477731705,
      "learning_rate": 2.6915662650602415e-06,
      "loss": 0.0075,
      "step": 143660
    },
    {
      "epoch": 17.309638554216868,
      "grad_norm": 0.0003271362220402807,
      "learning_rate": 2.6903614457831327e-06,
      "loss": 0.0009,
      "step": 143670
    },
    {
      "epoch": 17.310843373493977,
      "grad_norm": 0.0001334764965577051,
      "learning_rate": 2.6891566265060243e-06,
      "loss": 0.001,
      "step": 143680
    },
    {
      "epoch": 17.312048192771083,
      "grad_norm": 0.001052179024554789,
      "learning_rate": 2.687951807228916e-06,
      "loss": 0.0026,
      "step": 143690
    },
    {
      "epoch": 17.313253012048193,
      "grad_norm": 3.334549903869629,
      "learning_rate": 2.6867469879518075e-06,
      "loss": 0.0283,
      "step": 143700
    },
    {
      "epoch": 17.314457831325303,
      "grad_norm": 0.00017167929036077112,
      "learning_rate": 2.685542168674699e-06,
      "loss": 0.0028,
      "step": 143710
    },
    {
      "epoch": 17.31566265060241,
      "grad_norm": 1.0039618015289307,
      "learning_rate": 2.6843373493975906e-06,
      "loss": 0.0071,
      "step": 143720
    },
    {
      "epoch": 17.31686746987952,
      "grad_norm": 1.0345977544784546,
      "learning_rate": 2.683132530120482e-06,
      "loss": 0.0147,
      "step": 143730
    },
    {
      "epoch": 17.318072289156625,
      "grad_norm": 0.00035628137993626297,
      "learning_rate": 2.681927710843374e-06,
      "loss": 0.0057,
      "step": 143740
    },
    {
      "epoch": 17.319277108433734,
      "grad_norm": 0.8409250974655151,
      "learning_rate": 2.6807228915662654e-06,
      "loss": 0.0067,
      "step": 143750
    },
    {
      "epoch": 17.320481927710844,
      "grad_norm": 0.7197386026382446,
      "learning_rate": 2.6795180722891566e-06,
      "loss": 0.0134,
      "step": 143760
    },
    {
      "epoch": 17.32168674698795,
      "grad_norm": 2.2322309017181396,
      "learning_rate": 2.678313253012048e-06,
      "loss": 0.0183,
      "step": 143770
    },
    {
      "epoch": 17.32289156626506,
      "grad_norm": 0.36278119683265686,
      "learning_rate": 2.67710843373494e-06,
      "loss": 0.0118,
      "step": 143780
    },
    {
      "epoch": 17.32409638554217,
      "grad_norm": 0.0005179729196242988,
      "learning_rate": 2.6759036144578317e-06,
      "loss": 0.0169,
      "step": 143790
    },
    {
      "epoch": 17.325301204819276,
      "grad_norm": 0.00029012421146035194,
      "learning_rate": 2.674698795180723e-06,
      "loss": 0.0042,
      "step": 143800
    },
    {
      "epoch": 17.326506024096386,
      "grad_norm": 0.0003481126914266497,
      "learning_rate": 2.673493975903615e-06,
      "loss": 0.0083,
      "step": 143810
    },
    {
      "epoch": 17.327710843373495,
      "grad_norm": 0.00035932305036112666,
      "learning_rate": 2.6722891566265065e-06,
      "loss": 0.0038,
      "step": 143820
    },
    {
      "epoch": 17.3289156626506,
      "grad_norm": 0.003652602434158325,
      "learning_rate": 2.6710843373493977e-06,
      "loss": 0.0072,
      "step": 143830
    },
    {
      "epoch": 17.33012048192771,
      "grad_norm": 0.003955960739403963,
      "learning_rate": 2.6698795180722893e-06,
      "loss": 0.0154,
      "step": 143840
    },
    {
      "epoch": 17.33132530120482,
      "grad_norm": 0.00032052811002358794,
      "learning_rate": 2.6686746987951813e-06,
      "loss": 0.0292,
      "step": 143850
    },
    {
      "epoch": 17.332530120481927,
      "grad_norm": 0.4100182056427002,
      "learning_rate": 2.6674698795180724e-06,
      "loss": 0.0171,
      "step": 143860
    },
    {
      "epoch": 17.333734939759037,
      "grad_norm": 0.0007027697865851223,
      "learning_rate": 2.666265060240964e-06,
      "loss": 0.0181,
      "step": 143870
    },
    {
      "epoch": 17.334939759036146,
      "grad_norm": 0.008654170669615269,
      "learning_rate": 2.6650602409638556e-06,
      "loss": 0.0061,
      "step": 143880
    },
    {
      "epoch": 17.336144578313252,
      "grad_norm": 0.00013881897029932588,
      "learning_rate": 2.663855421686747e-06,
      "loss": 0.0007,
      "step": 143890
    },
    {
      "epoch": 17.337349397590362,
      "grad_norm": 0.5100761651992798,
      "learning_rate": 2.662650602409639e-06,
      "loss": 0.0117,
      "step": 143900
    },
    {
      "epoch": 17.33855421686747,
      "grad_norm": 0.00019808733486570418,
      "learning_rate": 2.6614457831325304e-06,
      "loss": 0.0011,
      "step": 143910
    },
    {
      "epoch": 17.339759036144578,
      "grad_norm": 0.00014041639224160463,
      "learning_rate": 2.6602409638554215e-06,
      "loss": 0.005,
      "step": 143920
    },
    {
      "epoch": 17.340963855421688,
      "grad_norm": 0.000645629595965147,
      "learning_rate": 2.6590361445783136e-06,
      "loss": 0.0133,
      "step": 143930
    },
    {
      "epoch": 17.342168674698794,
      "grad_norm": 0.33712562918663025,
      "learning_rate": 2.657831325301205e-06,
      "loss": 0.0025,
      "step": 143940
    },
    {
      "epoch": 17.343373493975903,
      "grad_norm": 0.00015981862088665366,
      "learning_rate": 2.6566265060240963e-06,
      "loss": 0.0074,
      "step": 143950
    },
    {
      "epoch": 17.344578313253013,
      "grad_norm": 0.00017262267647311091,
      "learning_rate": 2.6554216867469883e-06,
      "loss": 0.005,
      "step": 143960
    },
    {
      "epoch": 17.34578313253012,
      "grad_norm": 0.00019803893519565463,
      "learning_rate": 2.65421686746988e-06,
      "loss": 0.0003,
      "step": 143970
    },
    {
      "epoch": 17.34698795180723,
      "grad_norm": 0.000313511467538774,
      "learning_rate": 2.653012048192771e-06,
      "loss": 0.0021,
      "step": 143980
    },
    {
      "epoch": 17.34819277108434,
      "grad_norm": 0.0001314592082053423,
      "learning_rate": 2.6518072289156627e-06,
      "loss": 0.0076,
      "step": 143990
    },
    {
      "epoch": 17.349397590361445,
      "grad_norm": 0.00011944844300160185,
      "learning_rate": 2.6506024096385547e-06,
      "loss": 0.0258,
      "step": 144000
    },
    {
      "epoch": 17.350602409638554,
      "grad_norm": 0.1092054545879364,
      "learning_rate": 2.6493975903614463e-06,
      "loss": 0.0058,
      "step": 144010
    },
    {
      "epoch": 17.351807228915664,
      "grad_norm": 0.0001844801299739629,
      "learning_rate": 2.6481927710843374e-06,
      "loss": 0.0186,
      "step": 144020
    },
    {
      "epoch": 17.35301204819277,
      "grad_norm": 0.9752464294433594,
      "learning_rate": 2.646987951807229e-06,
      "loss": 0.0214,
      "step": 144030
    },
    {
      "epoch": 17.35421686746988,
      "grad_norm": 0.00019353805691935122,
      "learning_rate": 2.645783132530121e-06,
      "loss": 0.0106,
      "step": 144040
    },
    {
      "epoch": 17.355421686746986,
      "grad_norm": 0.00019484407675918192,
      "learning_rate": 2.644578313253012e-06,
      "loss": 0.0093,
      "step": 144050
    },
    {
      "epoch": 17.356626506024096,
      "grad_norm": 1.8074311017990112,
      "learning_rate": 2.6433734939759038e-06,
      "loss": 0.0065,
      "step": 144060
    },
    {
      "epoch": 17.357831325301206,
      "grad_norm": 0.00022152869496494532,
      "learning_rate": 2.642168674698795e-06,
      "loss": 0.0001,
      "step": 144070
    },
    {
      "epoch": 17.35903614457831,
      "grad_norm": 0.00037572052679024637,
      "learning_rate": 2.640963855421687e-06,
      "loss": 0.0075,
      "step": 144080
    },
    {
      "epoch": 17.36024096385542,
      "grad_norm": 0.00012096136197214946,
      "learning_rate": 2.6397590361445785e-06,
      "loss": 0.0064,
      "step": 144090
    },
    {
      "epoch": 17.36144578313253,
      "grad_norm": 2.062181234359741,
      "learning_rate": 2.63855421686747e-06,
      "loss": 0.0246,
      "step": 144100
    },
    {
      "epoch": 17.362650602409637,
      "grad_norm": 0.00043906315113417804,
      "learning_rate": 2.6373493975903617e-06,
      "loss": 0.0047,
      "step": 144110
    },
    {
      "epoch": 17.363855421686747,
      "grad_norm": 0.00011064275895478204,
      "learning_rate": 2.6361445783132533e-06,
      "loss": 0.0191,
      "step": 144120
    },
    {
      "epoch": 17.365060240963857,
      "grad_norm": 0.38646966218948364,
      "learning_rate": 2.634939759036145e-06,
      "loss": 0.0061,
      "step": 144130
    },
    {
      "epoch": 17.366265060240963,
      "grad_norm": 0.5827594995498657,
      "learning_rate": 2.633734939759036e-06,
      "loss": 0.009,
      "step": 144140
    },
    {
      "epoch": 17.367469879518072,
      "grad_norm": 0.11441587656736374,
      "learning_rate": 2.632530120481928e-06,
      "loss": 0.0056,
      "step": 144150
    },
    {
      "epoch": 17.368674698795182,
      "grad_norm": 0.0005454798811115324,
      "learning_rate": 2.6313253012048197e-06,
      "loss": 0.02,
      "step": 144160
    },
    {
      "epoch": 17.36987951807229,
      "grad_norm": 0.0002514613152015954,
      "learning_rate": 2.630120481927711e-06,
      "loss": 0.0061,
      "step": 144170
    },
    {
      "epoch": 17.371084337349398,
      "grad_norm": 0.0031128888949751854,
      "learning_rate": 2.6289156626506024e-06,
      "loss": 0.0073,
      "step": 144180
    },
    {
      "epoch": 17.372289156626508,
      "grad_norm": 0.005566345062106848,
      "learning_rate": 2.6277108433734944e-06,
      "loss": 0.0138,
      "step": 144190
    },
    {
      "epoch": 17.373493975903614,
      "grad_norm": 6.842013359069824,
      "learning_rate": 2.6265060240963856e-06,
      "loss": 0.0307,
      "step": 144200
    },
    {
      "epoch": 17.374698795180723,
      "grad_norm": 17.42314338684082,
      "learning_rate": 2.625301204819277e-06,
      "loss": 0.0418,
      "step": 144210
    },
    {
      "epoch": 17.37590361445783,
      "grad_norm": 1.4640140533447266,
      "learning_rate": 2.624096385542169e-06,
      "loss": 0.0127,
      "step": 144220
    },
    {
      "epoch": 17.37710843373494,
      "grad_norm": 6.562162889167666e-05,
      "learning_rate": 2.6228915662650608e-06,
      "loss": 0.018,
      "step": 144230
    },
    {
      "epoch": 17.37831325301205,
      "grad_norm": 0.0004458525509107858,
      "learning_rate": 2.621686746987952e-06,
      "loss": 0.0164,
      "step": 144240
    },
    {
      "epoch": 17.379518072289155,
      "grad_norm": 1.3390157222747803,
      "learning_rate": 2.6204819277108435e-06,
      "loss": 0.0107,
      "step": 144250
    },
    {
      "epoch": 17.380722891566265,
      "grad_norm": 0.41528576612472534,
      "learning_rate": 2.6192771084337355e-06,
      "loss": 0.0075,
      "step": 144260
    },
    {
      "epoch": 17.381927710843375,
      "grad_norm": 1.0319576263427734,
      "learning_rate": 2.6180722891566267e-06,
      "loss": 0.0242,
      "step": 144270
    },
    {
      "epoch": 17.38313253012048,
      "grad_norm": 0.0004968217108398676,
      "learning_rate": 2.6168674698795183e-06,
      "loss": 0.0201,
      "step": 144280
    },
    {
      "epoch": 17.38433734939759,
      "grad_norm": 0.5962882041931152,
      "learning_rate": 2.6156626506024095e-06,
      "loss": 0.0066,
      "step": 144290
    },
    {
      "epoch": 17.3855421686747,
      "grad_norm": 0.00017857132479548454,
      "learning_rate": 2.6144578313253015e-06,
      "loss": 0.0042,
      "step": 144300
    },
    {
      "epoch": 17.386746987951806,
      "grad_norm": 0.0007704789750277996,
      "learning_rate": 2.613253012048193e-06,
      "loss": 0.0312,
      "step": 144310
    },
    {
      "epoch": 17.387951807228916,
      "grad_norm": 0.00017622759332880378,
      "learning_rate": 2.6120481927710846e-06,
      "loss": 0.006,
      "step": 144320
    },
    {
      "epoch": 17.389156626506026,
      "grad_norm": 0.014795802533626556,
      "learning_rate": 2.610843373493976e-06,
      "loss": 0.0008,
      "step": 144330
    },
    {
      "epoch": 17.39036144578313,
      "grad_norm": 0.20683729648590088,
      "learning_rate": 2.609638554216868e-06,
      "loss": 0.0053,
      "step": 144340
    },
    {
      "epoch": 17.39156626506024,
      "grad_norm": 0.03558172658085823,
      "learning_rate": 2.6084337349397594e-06,
      "loss": 0.0014,
      "step": 144350
    },
    {
      "epoch": 17.39277108433735,
      "grad_norm": 0.0002553791564423591,
      "learning_rate": 2.6072289156626506e-06,
      "loss": 0.0085,
      "step": 144360
    },
    {
      "epoch": 17.393975903614457,
      "grad_norm": 1.3669155836105347,
      "learning_rate": 2.6060240963855426e-06,
      "loss": 0.0094,
      "step": 144370
    },
    {
      "epoch": 17.395180722891567,
      "grad_norm": 2.015298366546631,
      "learning_rate": 2.604819277108434e-06,
      "loss": 0.0382,
      "step": 144380
    },
    {
      "epoch": 17.396385542168673,
      "grad_norm": 1.806306004524231,
      "learning_rate": 2.6036144578313253e-06,
      "loss": 0.0178,
      "step": 144390
    },
    {
      "epoch": 17.397590361445783,
      "grad_norm": 0.21152301132678986,
      "learning_rate": 2.602409638554217e-06,
      "loss": 0.0037,
      "step": 144400
    },
    {
      "epoch": 17.398795180722892,
      "grad_norm": 1.426838755607605,
      "learning_rate": 2.601204819277109e-06,
      "loss": 0.0049,
      "step": 144410
    },
    {
      "epoch": 17.4,
      "grad_norm": 0.7517288327217102,
      "learning_rate": 2.6e-06,
      "loss": 0.0045,
      "step": 144420
    },
    {
      "epoch": 17.40120481927711,
      "grad_norm": 0.2797948122024536,
      "learning_rate": 2.5987951807228917e-06,
      "loss": 0.0022,
      "step": 144430
    },
    {
      "epoch": 17.402409638554218,
      "grad_norm": 5.114795203553513e-05,
      "learning_rate": 2.5975903614457833e-06,
      "loss": 0.016,
      "step": 144440
    },
    {
      "epoch": 17.403614457831324,
      "grad_norm": 0.002050964394584298,
      "learning_rate": 2.5963855421686753e-06,
      "loss": 0.011,
      "step": 144450
    },
    {
      "epoch": 17.404819277108434,
      "grad_norm": 0.7494117021560669,
      "learning_rate": 2.5951807228915664e-06,
      "loss": 0.0184,
      "step": 144460
    },
    {
      "epoch": 17.406024096385543,
      "grad_norm": 0.00029329166864044964,
      "learning_rate": 2.593975903614458e-06,
      "loss": 0.0087,
      "step": 144470
    },
    {
      "epoch": 17.40722891566265,
      "grad_norm": 0.00026127262390218675,
      "learning_rate": 2.592771084337349e-06,
      "loss": 0.0109,
      "step": 144480
    },
    {
      "epoch": 17.40843373493976,
      "grad_norm": 0.01281372457742691,
      "learning_rate": 2.591566265060241e-06,
      "loss": 0.0117,
      "step": 144490
    },
    {
      "epoch": 17.40963855421687,
      "grad_norm": 1.5163477659225464,
      "learning_rate": 2.590361445783133e-06,
      "loss": 0.0222,
      "step": 144500
    },
    {
      "epoch": 17.410843373493975,
      "grad_norm": 0.31764960289001465,
      "learning_rate": 2.589156626506024e-06,
      "loss": 0.0347,
      "step": 144510
    },
    {
      "epoch": 17.412048192771085,
      "grad_norm": 0.00048241313197650015,
      "learning_rate": 2.587951807228916e-06,
      "loss": 0.0004,
      "step": 144520
    },
    {
      "epoch": 17.413253012048195,
      "grad_norm": 0.22436635196208954,
      "learning_rate": 2.5867469879518076e-06,
      "loss": 0.0132,
      "step": 144530
    },
    {
      "epoch": 17.4144578313253,
      "grad_norm": 0.00036876980448141694,
      "learning_rate": 2.585542168674699e-06,
      "loss": 0.0105,
      "step": 144540
    },
    {
      "epoch": 17.41566265060241,
      "grad_norm": 0.00019222823902964592,
      "learning_rate": 2.5843373493975903e-06,
      "loss": 0.0034,
      "step": 144550
    },
    {
      "epoch": 17.416867469879517,
      "grad_norm": 1.9362667798995972,
      "learning_rate": 2.5831325301204823e-06,
      "loss": 0.0176,
      "step": 144560
    },
    {
      "epoch": 17.418072289156626,
      "grad_norm": 0.0001515624753665179,
      "learning_rate": 2.581927710843374e-06,
      "loss": 0.0092,
      "step": 144570
    },
    {
      "epoch": 17.419277108433736,
      "grad_norm": 6.164630758576095e-05,
      "learning_rate": 2.580722891566265e-06,
      "loss": 0.0099,
      "step": 144580
    },
    {
      "epoch": 17.420481927710842,
      "grad_norm": 0.00011080591502832249,
      "learning_rate": 2.5795180722891567e-06,
      "loss": 0.0019,
      "step": 144590
    },
    {
      "epoch": 17.42168674698795,
      "grad_norm": 8.90266674105078e-05,
      "learning_rate": 2.5783132530120487e-06,
      "loss": 0.014,
      "step": 144600
    },
    {
      "epoch": 17.42289156626506,
      "grad_norm": 0.45921480655670166,
      "learning_rate": 2.57710843373494e-06,
      "loss": 0.0178,
      "step": 144610
    },
    {
      "epoch": 17.424096385542168,
      "grad_norm": 0.0001885726669570431,
      "learning_rate": 2.5759036144578314e-06,
      "loss": 0.001,
      "step": 144620
    },
    {
      "epoch": 17.425301204819277,
      "grad_norm": 0.00011081245611421764,
      "learning_rate": 2.574698795180723e-06,
      "loss": 0.0147,
      "step": 144630
    },
    {
      "epoch": 17.426506024096387,
      "grad_norm": 0.19366440176963806,
      "learning_rate": 2.573493975903615e-06,
      "loss": 0.0058,
      "step": 144640
    },
    {
      "epoch": 17.427710843373493,
      "grad_norm": 0.00014532575733028352,
      "learning_rate": 2.572289156626506e-06,
      "loss": 0.007,
      "step": 144650
    },
    {
      "epoch": 17.428915662650603,
      "grad_norm": 0.00011911655019503087,
      "learning_rate": 2.5710843373493978e-06,
      "loss": 0.0141,
      "step": 144660
    },
    {
      "epoch": 17.430120481927712,
      "grad_norm": 0.0002732929424382746,
      "learning_rate": 2.56987951807229e-06,
      "loss": 0.0094,
      "step": 144670
    },
    {
      "epoch": 17.43132530120482,
      "grad_norm": 0.0004078895435668528,
      "learning_rate": 2.568674698795181e-06,
      "loss": 0.0055,
      "step": 144680
    },
    {
      "epoch": 17.43253012048193,
      "grad_norm": 0.00024236775061581284,
      "learning_rate": 2.5674698795180725e-06,
      "loss": 0.0,
      "step": 144690
    },
    {
      "epoch": 17.433734939759034,
      "grad_norm": 7.989084243774414,
      "learning_rate": 2.5662650602409637e-06,
      "loss": 0.0245,
      "step": 144700
    },
    {
      "epoch": 17.434939759036144,
      "grad_norm": 0.00019999682263005525,
      "learning_rate": 2.5650602409638557e-06,
      "loss": 0.0203,
      "step": 144710
    },
    {
      "epoch": 17.436144578313254,
      "grad_norm": 0.00014527597522828728,
      "learning_rate": 2.5638554216867473e-06,
      "loss": 0.007,
      "step": 144720
    },
    {
      "epoch": 17.43734939759036,
      "grad_norm": 0.00012200978380860761,
      "learning_rate": 2.562650602409639e-06,
      "loss": 0.017,
      "step": 144730
    },
    {
      "epoch": 17.43855421686747,
      "grad_norm": 0.00021725980332121253,
      "learning_rate": 2.56144578313253e-06,
      "loss": 0.0005,
      "step": 144740
    },
    {
      "epoch": 17.43975903614458,
      "grad_norm": 4.482008080231026e-05,
      "learning_rate": 2.560240963855422e-06,
      "loss": 0.0018,
      "step": 144750
    },
    {
      "epoch": 17.440963855421685,
      "grad_norm": 0.00010762022429844365,
      "learning_rate": 2.5590361445783137e-06,
      "loss": 0.0102,
      "step": 144760
    },
    {
      "epoch": 17.442168674698795,
      "grad_norm": 0.00015284225810319185,
      "learning_rate": 2.557831325301205e-06,
      "loss": 0.0039,
      "step": 144770
    },
    {
      "epoch": 17.443373493975905,
      "grad_norm": 0.9126061201095581,
      "learning_rate": 2.5566265060240964e-06,
      "loss": 0.0198,
      "step": 144780
    },
    {
      "epoch": 17.44457831325301,
      "grad_norm": 1.581923484802246,
      "learning_rate": 2.5554216867469884e-06,
      "loss": 0.01,
      "step": 144790
    },
    {
      "epoch": 17.44578313253012,
      "grad_norm": 3.2331759929656982,
      "learning_rate": 2.5542168674698796e-06,
      "loss": 0.0413,
      "step": 144800
    },
    {
      "epoch": 17.44698795180723,
      "grad_norm": 0.1751590520143509,
      "learning_rate": 2.553012048192771e-06,
      "loss": 0.0599,
      "step": 144810
    },
    {
      "epoch": 17.448192771084337,
      "grad_norm": 0.7958472967147827,
      "learning_rate": 2.551807228915663e-06,
      "loss": 0.0147,
      "step": 144820
    },
    {
      "epoch": 17.449397590361446,
      "grad_norm": 0.00010698971163947135,
      "learning_rate": 2.5506024096385544e-06,
      "loss": 0.0146,
      "step": 144830
    },
    {
      "epoch": 17.450602409638556,
      "grad_norm": 0.0007950468570925295,
      "learning_rate": 2.549397590361446e-06,
      "loss": 0.0058,
      "step": 144840
    },
    {
      "epoch": 17.451807228915662,
      "grad_norm": 0.000137926428578794,
      "learning_rate": 2.5481927710843375e-06,
      "loss": 0.0111,
      "step": 144850
    },
    {
      "epoch": 17.45301204819277,
      "grad_norm": 0.004999816883355379,
      "learning_rate": 2.5469879518072295e-06,
      "loss": 0.0075,
      "step": 144860
    },
    {
      "epoch": 17.454216867469878,
      "grad_norm": 0.00016363229951821268,
      "learning_rate": 2.5457831325301207e-06,
      "loss": 0.0054,
      "step": 144870
    },
    {
      "epoch": 17.455421686746988,
      "grad_norm": 1.695308804512024,
      "learning_rate": 2.5445783132530123e-06,
      "loss": 0.0162,
      "step": 144880
    },
    {
      "epoch": 17.456626506024097,
      "grad_norm": 0.006423668935894966,
      "learning_rate": 2.5433734939759035e-06,
      "loss": 0.0102,
      "step": 144890
    },
    {
      "epoch": 17.457831325301203,
      "grad_norm": 0.0014424350811168551,
      "learning_rate": 2.5421686746987955e-06,
      "loss": 0.0055,
      "step": 144900
    },
    {
      "epoch": 17.459036144578313,
      "grad_norm": 0.00017553525685798377,
      "learning_rate": 2.540963855421687e-06,
      "loss": 0.0058,
      "step": 144910
    },
    {
      "epoch": 17.460240963855423,
      "grad_norm": 0.00027986220084130764,
      "learning_rate": 2.5397590361445782e-06,
      "loss": 0.0093,
      "step": 144920
    },
    {
      "epoch": 17.46144578313253,
      "grad_norm": 9.848314221017063e-05,
      "learning_rate": 2.53855421686747e-06,
      "loss": 0.0121,
      "step": 144930
    },
    {
      "epoch": 17.46265060240964,
      "grad_norm": 0.006677971221506596,
      "learning_rate": 2.537349397590362e-06,
      "loss": 0.0038,
      "step": 144940
    },
    {
      "epoch": 17.46385542168675,
      "grad_norm": 0.9083834290504456,
      "learning_rate": 2.5361445783132534e-06,
      "loss": 0.0254,
      "step": 144950
    },
    {
      "epoch": 17.465060240963854,
      "grad_norm": 5.5214084568433464e-05,
      "learning_rate": 2.5349397590361446e-06,
      "loss": 0.0154,
      "step": 144960
    },
    {
      "epoch": 17.466265060240964,
      "grad_norm": 0.00017835930339060724,
      "learning_rate": 2.5337349397590366e-06,
      "loss": 0.0056,
      "step": 144970
    },
    {
      "epoch": 17.467469879518074,
      "grad_norm": 0.0007751845405437052,
      "learning_rate": 2.532530120481928e-06,
      "loss": 0.0021,
      "step": 144980
    },
    {
      "epoch": 17.46867469879518,
      "grad_norm": 0.0002336128818569705,
      "learning_rate": 2.5313253012048193e-06,
      "loss": 0.0068,
      "step": 144990
    },
    {
      "epoch": 17.46987951807229,
      "grad_norm": 9.127911471296102e-05,
      "learning_rate": 2.530120481927711e-06,
      "loss": 0.007,
      "step": 145000
    },
    {
      "epoch": 17.471084337349396,
      "grad_norm": 0.00015231972793117166,
      "learning_rate": 2.528915662650603e-06,
      "loss": 0.0107,
      "step": 145010
    },
    {
      "epoch": 17.472289156626506,
      "grad_norm": 0.00013350308290682733,
      "learning_rate": 2.527710843373494e-06,
      "loss": 0.0056,
      "step": 145020
    },
    {
      "epoch": 17.473493975903615,
      "grad_norm": 0.00015066456398926675,
      "learning_rate": 2.5265060240963857e-06,
      "loss": 0.005,
      "step": 145030
    },
    {
      "epoch": 17.47469879518072,
      "grad_norm": 0.8123459219932556,
      "learning_rate": 2.5253012048192773e-06,
      "loss": 0.0169,
      "step": 145040
    },
    {
      "epoch": 17.47590361445783,
      "grad_norm": 0.41084715723991394,
      "learning_rate": 2.524096385542169e-06,
      "loss": 0.0084,
      "step": 145050
    },
    {
      "epoch": 17.47710843373494,
      "grad_norm": 0.00019601140229497105,
      "learning_rate": 2.5228915662650605e-06,
      "loss": 0.0071,
      "step": 145060
    },
    {
      "epoch": 17.478313253012047,
      "grad_norm": 0.00018026218458544463,
      "learning_rate": 2.521686746987952e-06,
      "loss": 0.0028,
      "step": 145070
    },
    {
      "epoch": 17.479518072289157,
      "grad_norm": 0.0001373303384752944,
      "learning_rate": 2.520481927710843e-06,
      "loss": 0.0038,
      "step": 145080
    },
    {
      "epoch": 17.480722891566266,
      "grad_norm": 0.0001160784304374829,
      "learning_rate": 2.5192771084337352e-06,
      "loss": 0.0274,
      "step": 145090
    },
    {
      "epoch": 17.481927710843372,
      "grad_norm": 0.00018838317191693932,
      "learning_rate": 2.518072289156627e-06,
      "loss": 0.0072,
      "step": 145100
    },
    {
      "epoch": 17.483132530120482,
      "grad_norm": 0.9217246174812317,
      "learning_rate": 2.516867469879518e-06,
      "loss": 0.0114,
      "step": 145110
    },
    {
      "epoch": 17.48433734939759,
      "grad_norm": 0.00012450838403310627,
      "learning_rate": 2.51566265060241e-06,
      "loss": 0.002,
      "step": 145120
    },
    {
      "epoch": 17.485542168674698,
      "grad_norm": 0.25941604375839233,
      "learning_rate": 2.5144578313253016e-06,
      "loss": 0.0141,
      "step": 145130
    },
    {
      "epoch": 17.486746987951808,
      "grad_norm": 5.493740172823891e-05,
      "learning_rate": 2.5132530120481927e-06,
      "loss": 0.0233,
      "step": 145140
    },
    {
      "epoch": 17.487951807228917,
      "grad_norm": 8.452685142401606e-05,
      "learning_rate": 2.5120481927710843e-06,
      "loss": 0.0185,
      "step": 145150
    },
    {
      "epoch": 17.489156626506023,
      "grad_norm": 0.00014824047684669495,
      "learning_rate": 2.5108433734939763e-06,
      "loss": 0.0038,
      "step": 145160
    },
    {
      "epoch": 17.490361445783133,
      "grad_norm": 0.00016491046699229628,
      "learning_rate": 2.509638554216868e-06,
      "loss": 0.0146,
      "step": 145170
    },
    {
      "epoch": 17.49156626506024,
      "grad_norm": 0.00026407759287394583,
      "learning_rate": 2.508433734939759e-06,
      "loss": 0.0284,
      "step": 145180
    },
    {
      "epoch": 17.49277108433735,
      "grad_norm": 1.5152006149291992,
      "learning_rate": 2.5072289156626507e-06,
      "loss": 0.0179,
      "step": 145190
    },
    {
      "epoch": 17.49397590361446,
      "grad_norm": 0.3856150805950165,
      "learning_rate": 2.5060240963855427e-06,
      "loss": 0.007,
      "step": 145200
    },
    {
      "epoch": 17.495180722891565,
      "grad_norm": 0.8749229311943054,
      "learning_rate": 2.504819277108434e-06,
      "loss": 0.0248,
      "step": 145210
    },
    {
      "epoch": 17.496385542168674,
      "grad_norm": 0.004913923796266317,
      "learning_rate": 2.5036144578313254e-06,
      "loss": 0.044,
      "step": 145220
    },
    {
      "epoch": 17.497590361445784,
      "grad_norm": 0.22621724009513855,
      "learning_rate": 2.5024096385542166e-06,
      "loss": 0.0076,
      "step": 145230
    },
    {
      "epoch": 17.49879518072289,
      "grad_norm": 9.312216570833698e-05,
      "learning_rate": 2.5012048192771086e-06,
      "loss": 0.0094,
      "step": 145240
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.8957804441452026,
      "learning_rate": 2.5e-06,
      "loss": 0.0072,
      "step": 145250
    },
    {
      "epoch": 17.50120481927711,
      "grad_norm": 0.00011760064080590382,
      "learning_rate": 2.498795180722892e-06,
      "loss": 0.0266,
      "step": 145260
    },
    {
      "epoch": 17.502409638554216,
      "grad_norm": 0.00010883044160436839,
      "learning_rate": 2.4975903614457834e-06,
      "loss": 0.0086,
      "step": 145270
    },
    {
      "epoch": 17.503614457831326,
      "grad_norm": 0.0001077864071703516,
      "learning_rate": 2.496385542168675e-06,
      "loss": 0.0062,
      "step": 145280
    },
    {
      "epoch": 17.504819277108435,
      "grad_norm": 1.2135930061340332,
      "learning_rate": 2.4951807228915666e-06,
      "loss": 0.0244,
      "step": 145290
    },
    {
      "epoch": 17.50602409638554,
      "grad_norm": 0.00018858643306884915,
      "learning_rate": 2.493975903614458e-06,
      "loss": 0.0046,
      "step": 145300
    },
    {
      "epoch": 17.50722891566265,
      "grad_norm": 0.5101796388626099,
      "learning_rate": 2.4927710843373497e-06,
      "loss": 0.0239,
      "step": 145310
    },
    {
      "epoch": 17.50843373493976,
      "grad_norm": 0.00013935400056652725,
      "learning_rate": 2.4915662650602413e-06,
      "loss": 0.0093,
      "step": 145320
    },
    {
      "epoch": 17.509638554216867,
      "grad_norm": 0.00013514429156202823,
      "learning_rate": 2.4903614457831325e-06,
      "loss": 0.0091,
      "step": 145330
    },
    {
      "epoch": 17.510843373493977,
      "grad_norm": 13.597620964050293,
      "learning_rate": 2.4891566265060245e-06,
      "loss": 0.0113,
      "step": 145340
    },
    {
      "epoch": 17.512048192771083,
      "grad_norm": 9.72200941760093e-05,
      "learning_rate": 2.4879518072289157e-06,
      "loss": 0.0035,
      "step": 145350
    },
    {
      "epoch": 17.513253012048192,
      "grad_norm": 0.00010260529961669818,
      "learning_rate": 2.4867469879518077e-06,
      "loss": 0.0168,
      "step": 145360
    },
    {
      "epoch": 17.514457831325302,
      "grad_norm": 0.00014896399807184935,
      "learning_rate": 2.485542168674699e-06,
      "loss": 0.0018,
      "step": 145370
    },
    {
      "epoch": 17.51566265060241,
      "grad_norm": 1.216518759727478,
      "learning_rate": 2.4843373493975904e-06,
      "loss": 0.0284,
      "step": 145380
    },
    {
      "epoch": 17.516867469879518,
      "grad_norm": 0.00011396734771551564,
      "learning_rate": 2.483132530120482e-06,
      "loss": 0.0024,
      "step": 145390
    },
    {
      "epoch": 17.518072289156628,
      "grad_norm": 6.285809649853036e-05,
      "learning_rate": 2.4819277108433736e-06,
      "loss": 0.0098,
      "step": 145400
    },
    {
      "epoch": 17.519277108433734,
      "grad_norm": 0.8779099583625793,
      "learning_rate": 2.480722891566265e-06,
      "loss": 0.0197,
      "step": 145410
    },
    {
      "epoch": 17.520481927710843,
      "grad_norm": 0.7495990991592407,
      "learning_rate": 2.4795180722891568e-06,
      "loss": 0.024,
      "step": 145420
    },
    {
      "epoch": 17.521686746987953,
      "grad_norm": 0.3361313045024872,
      "learning_rate": 2.4783132530120484e-06,
      "loss": 0.0092,
      "step": 145430
    },
    {
      "epoch": 17.52289156626506,
      "grad_norm": 0.6942362785339355,
      "learning_rate": 2.47710843373494e-06,
      "loss": 0.0155,
      "step": 145440
    },
    {
      "epoch": 17.52409638554217,
      "grad_norm": 0.18549804389476776,
      "learning_rate": 2.4759036144578315e-06,
      "loss": 0.0116,
      "step": 145450
    },
    {
      "epoch": 17.52530120481928,
      "grad_norm": 0.21185685694217682,
      "learning_rate": 2.474698795180723e-06,
      "loss": 0.0146,
      "step": 145460
    },
    {
      "epoch": 17.526506024096385,
      "grad_norm": 0.20724612474441528,
      "learning_rate": 2.4734939759036147e-06,
      "loss": 0.0109,
      "step": 145470
    },
    {
      "epoch": 17.527710843373494,
      "grad_norm": 1.9131993055343628,
      "learning_rate": 2.4722891566265063e-06,
      "loss": 0.0319,
      "step": 145480
    },
    {
      "epoch": 17.528915662650604,
      "grad_norm": 0.00010473409201949835,
      "learning_rate": 2.471084337349398e-06,
      "loss": 0.0395,
      "step": 145490
    },
    {
      "epoch": 17.53012048192771,
      "grad_norm": 0.0008881748653948307,
      "learning_rate": 2.469879518072289e-06,
      "loss": 0.0086,
      "step": 145500
    },
    {
      "epoch": 17.53132530120482,
      "grad_norm": 8.23303489596583e-05,
      "learning_rate": 2.468674698795181e-06,
      "loss": 0.002,
      "step": 145510
    },
    {
      "epoch": 17.532530120481926,
      "grad_norm": 0.9702017307281494,
      "learning_rate": 2.4674698795180722e-06,
      "loss": 0.0153,
      "step": 145520
    },
    {
      "epoch": 17.533734939759036,
      "grad_norm": 0.00015952855756040663,
      "learning_rate": 2.4662650602409642e-06,
      "loss": 0.0225,
      "step": 145530
    },
    {
      "epoch": 17.534939759036146,
      "grad_norm": 0.007275572046637535,
      "learning_rate": 2.4650602409638554e-06,
      "loss": 0.0011,
      "step": 145540
    },
    {
      "epoch": 17.53614457831325,
      "grad_norm": 1.5015804767608643,
      "learning_rate": 2.463855421686747e-06,
      "loss": 0.0058,
      "step": 145550
    },
    {
      "epoch": 17.53734939759036,
      "grad_norm": 1.4446231126785278,
      "learning_rate": 2.462650602409639e-06,
      "loss": 0.0216,
      "step": 145560
    },
    {
      "epoch": 17.53855421686747,
      "grad_norm": 9.01887979125604e-05,
      "learning_rate": 2.46144578313253e-06,
      "loss": 0.0028,
      "step": 145570
    },
    {
      "epoch": 17.539759036144577,
      "grad_norm": 1.9732364416122437,
      "learning_rate": 2.460240963855422e-06,
      "loss": 0.0106,
      "step": 145580
    },
    {
      "epoch": 17.540963855421687,
      "grad_norm": 0.9745162129402161,
      "learning_rate": 2.4590361445783133e-06,
      "loss": 0.0034,
      "step": 145590
    },
    {
      "epoch": 17.542168674698797,
      "grad_norm": 0.00017848509014584124,
      "learning_rate": 2.457831325301205e-06,
      "loss": 0.0192,
      "step": 145600
    },
    {
      "epoch": 17.543373493975903,
      "grad_norm": 0.23672163486480713,
      "learning_rate": 2.4566265060240965e-06,
      "loss": 0.0331,
      "step": 145610
    },
    {
      "epoch": 17.544578313253012,
      "grad_norm": 0.0864168033003807,
      "learning_rate": 2.455421686746988e-06,
      "loss": 0.0083,
      "step": 145620
    },
    {
      "epoch": 17.545783132530122,
      "grad_norm": 0.00010990257578669116,
      "learning_rate": 2.4542168674698797e-06,
      "loss": 0.0069,
      "step": 145630
    },
    {
      "epoch": 17.54698795180723,
      "grad_norm": 0.00020349740225356072,
      "learning_rate": 2.4530120481927713e-06,
      "loss": 0.0169,
      "step": 145640
    },
    {
      "epoch": 17.548192771084338,
      "grad_norm": 0.00017273305275011808,
      "learning_rate": 2.451807228915663e-06,
      "loss": 0.043,
      "step": 145650
    },
    {
      "epoch": 17.549397590361444,
      "grad_norm": 0.00017516153457108885,
      "learning_rate": 2.4506024096385545e-06,
      "loss": 0.0001,
      "step": 145660
    },
    {
      "epoch": 17.550602409638554,
      "grad_norm": 0.002023849403485656,
      "learning_rate": 2.449397590361446e-06,
      "loss": 0.0081,
      "step": 145670
    },
    {
      "epoch": 17.551807228915663,
      "grad_norm": 0.00023497676011174917,
      "learning_rate": 2.4481927710843376e-06,
      "loss": 0.0187,
      "step": 145680
    },
    {
      "epoch": 17.55301204819277,
      "grad_norm": 0.00019813989638350904,
      "learning_rate": 2.446987951807229e-06,
      "loss": 0.0434,
      "step": 145690
    },
    {
      "epoch": 17.55421686746988,
      "grad_norm": 0.0007185859140008688,
      "learning_rate": 2.445783132530121e-06,
      "loss": 0.0164,
      "step": 145700
    },
    {
      "epoch": 17.55542168674699,
      "grad_norm": 1.4066994190216064,
      "learning_rate": 2.4445783132530124e-06,
      "loss": 0.021,
      "step": 145710
    },
    {
      "epoch": 17.556626506024095,
      "grad_norm": 0.0006744320853613317,
      "learning_rate": 2.443373493975904e-06,
      "loss": 0.0058,
      "step": 145720
    },
    {
      "epoch": 17.557831325301205,
      "grad_norm": 0.000277329352684319,
      "learning_rate": 2.4421686746987956e-06,
      "loss": 0.0089,
      "step": 145730
    },
    {
      "epoch": 17.559036144578315,
      "grad_norm": 0.9539552330970764,
      "learning_rate": 2.4409638554216867e-06,
      "loss": 0.0062,
      "step": 145740
    },
    {
      "epoch": 17.56024096385542,
      "grad_norm": 0.00021343326079659164,
      "learning_rate": 2.4397590361445788e-06,
      "loss": 0.0081,
      "step": 145750
    },
    {
      "epoch": 17.56144578313253,
      "grad_norm": 0.019470946863293648,
      "learning_rate": 2.43855421686747e-06,
      "loss": 0.0068,
      "step": 145760
    },
    {
      "epoch": 17.56265060240964,
      "grad_norm": 0.0010462079662829638,
      "learning_rate": 2.4373493975903615e-06,
      "loss": 0.0278,
      "step": 145770
    },
    {
      "epoch": 17.563855421686746,
      "grad_norm": 0.8112421035766602,
      "learning_rate": 2.436144578313253e-06,
      "loss": 0.0101,
      "step": 145780
    },
    {
      "epoch": 17.565060240963856,
      "grad_norm": 0.0002335141325602308,
      "learning_rate": 2.4349397590361447e-06,
      "loss": 0.0101,
      "step": 145790
    },
    {
      "epoch": 17.566265060240966,
      "grad_norm": 0.29282447695732117,
      "learning_rate": 2.4337349397590363e-06,
      "loss": 0.0631,
      "step": 145800
    },
    {
      "epoch": 17.56746987951807,
      "grad_norm": 0.8250152468681335,
      "learning_rate": 2.432530120481928e-06,
      "loss": 0.015,
      "step": 145810
    },
    {
      "epoch": 17.56867469879518,
      "grad_norm": 0.46363842487335205,
      "learning_rate": 2.4313253012048195e-06,
      "loss": 0.0086,
      "step": 145820
    },
    {
      "epoch": 17.569879518072288,
      "grad_norm": 0.00014848004502709955,
      "learning_rate": 2.430120481927711e-06,
      "loss": 0.01,
      "step": 145830
    },
    {
      "epoch": 17.571084337349397,
      "grad_norm": 1.6598331928253174,
      "learning_rate": 2.4289156626506026e-06,
      "loss": 0.0339,
      "step": 145840
    },
    {
      "epoch": 17.572289156626507,
      "grad_norm": 1.4043078422546387,
      "learning_rate": 2.4277108433734942e-06,
      "loss": 0.0186,
      "step": 145850
    },
    {
      "epoch": 17.573493975903613,
      "grad_norm": 1.1135486364364624,
      "learning_rate": 2.426506024096386e-06,
      "loss": 0.0229,
      "step": 145860
    },
    {
      "epoch": 17.574698795180723,
      "grad_norm": 0.45728492736816406,
      "learning_rate": 2.4253012048192774e-06,
      "loss": 0.0069,
      "step": 145870
    },
    {
      "epoch": 17.575903614457832,
      "grad_norm": 0.4576451778411865,
      "learning_rate": 2.424096385542169e-06,
      "loss": 0.0081,
      "step": 145880
    },
    {
      "epoch": 17.57710843373494,
      "grad_norm": 0.0001789758534869179,
      "learning_rate": 2.4228915662650606e-06,
      "loss": 0.0043,
      "step": 145890
    },
    {
      "epoch": 17.57831325301205,
      "grad_norm": 1.1359535455703735,
      "learning_rate": 2.421686746987952e-06,
      "loss": 0.0235,
      "step": 145900
    },
    {
      "epoch": 17.579518072289158,
      "grad_norm": 0.0002571259392425418,
      "learning_rate": 2.4204819277108433e-06,
      "loss": 0.0059,
      "step": 145910
    },
    {
      "epoch": 17.580722891566264,
      "grad_norm": 0.00023264104675035924,
      "learning_rate": 2.4192771084337353e-06,
      "loss": 0.0138,
      "step": 145920
    },
    {
      "epoch": 17.581927710843374,
      "grad_norm": 0.0001986354182008654,
      "learning_rate": 2.4180722891566265e-06,
      "loss": 0.0046,
      "step": 145930
    },
    {
      "epoch": 17.583132530120483,
      "grad_norm": 0.0004329744551796466,
      "learning_rate": 2.4168674698795185e-06,
      "loss": 0.0009,
      "step": 145940
    },
    {
      "epoch": 17.58433734939759,
      "grad_norm": 0.25526341795921326,
      "learning_rate": 2.4156626506024097e-06,
      "loss": 0.0126,
      "step": 145950
    },
    {
      "epoch": 17.5855421686747,
      "grad_norm": 0.00015175000589806587,
      "learning_rate": 2.4144578313253013e-06,
      "loss": 0.0459,
      "step": 145960
    },
    {
      "epoch": 17.586746987951805,
      "grad_norm": 0.00020682020112872124,
      "learning_rate": 2.413253012048193e-06,
      "loss": 0.0045,
      "step": 145970
    },
    {
      "epoch": 17.587951807228915,
      "grad_norm": 0.006436996161937714,
      "learning_rate": 2.4120481927710844e-06,
      "loss": 0.0192,
      "step": 145980
    },
    {
      "epoch": 17.589156626506025,
      "grad_norm": 0.43439024686813354,
      "learning_rate": 2.4108433734939764e-06,
      "loss": 0.0043,
      "step": 145990
    },
    {
      "epoch": 17.59036144578313,
      "grad_norm": 0.0001989160809898749,
      "learning_rate": 2.4096385542168676e-06,
      "loss": 0.0141,
      "step": 146000
    },
    {
      "epoch": 17.59156626506024,
      "grad_norm": 0.00030146801145747304,
      "learning_rate": 2.408433734939759e-06,
      "loss": 0.0256,
      "step": 146010
    },
    {
      "epoch": 17.59277108433735,
      "grad_norm": 0.0013409571256488562,
      "learning_rate": 2.4072289156626508e-06,
      "loss": 0.0004,
      "step": 146020
    },
    {
      "epoch": 17.593975903614457,
      "grad_norm": 7.6460676193237305,
      "learning_rate": 2.4060240963855424e-06,
      "loss": 0.0272,
      "step": 146030
    },
    {
      "epoch": 17.595180722891566,
      "grad_norm": 0.29391801357269287,
      "learning_rate": 2.404819277108434e-06,
      "loss": 0.008,
      "step": 146040
    },
    {
      "epoch": 17.596385542168676,
      "grad_norm": 0.016473934054374695,
      "learning_rate": 2.4036144578313256e-06,
      "loss": 0.0013,
      "step": 146050
    },
    {
      "epoch": 17.597590361445782,
      "grad_norm": 0.0004414719296619296,
      "learning_rate": 2.402409638554217e-06,
      "loss": 0.0129,
      "step": 146060
    },
    {
      "epoch": 17.59879518072289,
      "grad_norm": 0.0006410531932488084,
      "learning_rate": 2.4012048192771087e-06,
      "loss": 0.0056,
      "step": 146070
    },
    {
      "epoch": 17.6,
      "grad_norm": 0.00020935936481691897,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0023,
      "step": 146080
    },
    {
      "epoch": 17.601204819277108,
      "grad_norm": 0.00020045955898240209,
      "learning_rate": 2.398795180722892e-06,
      "loss": 0.0139,
      "step": 146090
    },
    {
      "epoch": 17.602409638554217,
      "grad_norm": 0.003970538731664419,
      "learning_rate": 2.397590361445783e-06,
      "loss": 0.0049,
      "step": 146100
    },
    {
      "epoch": 17.603614457831327,
      "grad_norm": 0.9036271572113037,
      "learning_rate": 2.396385542168675e-06,
      "loss": 0.0073,
      "step": 146110
    },
    {
      "epoch": 17.604819277108433,
      "grad_norm": 1.768802285194397,
      "learning_rate": 2.3951807228915662e-06,
      "loss": 0.018,
      "step": 146120
    },
    {
      "epoch": 17.606024096385543,
      "grad_norm": 0.0016241826815530658,
      "learning_rate": 2.393975903614458e-06,
      "loss": 0.0032,
      "step": 146130
    },
    {
      "epoch": 17.60722891566265,
      "grad_norm": 0.000393651716876775,
      "learning_rate": 2.39277108433735e-06,
      "loss": 0.0125,
      "step": 146140
    },
    {
      "epoch": 17.60843373493976,
      "grad_norm": 0.021481947973370552,
      "learning_rate": 2.391566265060241e-06,
      "loss": 0.0062,
      "step": 146150
    },
    {
      "epoch": 17.60963855421687,
      "grad_norm": 1.1534597873687744,
      "learning_rate": 2.390361445783133e-06,
      "loss": 0.0094,
      "step": 146160
    },
    {
      "epoch": 17.610843373493974,
      "grad_norm": 0.00047954919864423573,
      "learning_rate": 2.389156626506024e-06,
      "loss": 0.0028,
      "step": 146170
    },
    {
      "epoch": 17.612048192771084,
      "grad_norm": 0.0005952029023319483,
      "learning_rate": 2.3879518072289158e-06,
      "loss": 0.0035,
      "step": 146180
    },
    {
      "epoch": 17.613253012048194,
      "grad_norm": 0.0007042873767204583,
      "learning_rate": 2.3867469879518074e-06,
      "loss": 0.0343,
      "step": 146190
    },
    {
      "epoch": 17.6144578313253,
      "grad_norm": 0.0009797202656045556,
      "learning_rate": 2.385542168674699e-06,
      "loss": 0.0032,
      "step": 146200
    },
    {
      "epoch": 17.61566265060241,
      "grad_norm": 1.0466283559799194,
      "learning_rate": 2.3843373493975905e-06,
      "loss": 0.0176,
      "step": 146210
    },
    {
      "epoch": 17.61686746987952,
      "grad_norm": 0.00034573112498037517,
      "learning_rate": 2.383132530120482e-06,
      "loss": 0.0058,
      "step": 146220
    },
    {
      "epoch": 17.618072289156625,
      "grad_norm": 0.20486712455749512,
      "learning_rate": 2.3819277108433737e-06,
      "loss": 0.01,
      "step": 146230
    },
    {
      "epoch": 17.619277108433735,
      "grad_norm": 0.0003833519876934588,
      "learning_rate": 2.3807228915662653e-06,
      "loss": 0.0054,
      "step": 146240
    },
    {
      "epoch": 17.620481927710845,
      "grad_norm": 0.020703149959445,
      "learning_rate": 2.379518072289157e-06,
      "loss": 0.0168,
      "step": 146250
    },
    {
      "epoch": 17.62168674698795,
      "grad_norm": 2.1587412357330322,
      "learning_rate": 2.3783132530120485e-06,
      "loss": 0.0282,
      "step": 146260
    },
    {
      "epoch": 17.62289156626506,
      "grad_norm": 0.000690335058607161,
      "learning_rate": 2.3771084337349396e-06,
      "loss": 0.013,
      "step": 146270
    },
    {
      "epoch": 17.62409638554217,
      "grad_norm": 0.00030969889485277236,
      "learning_rate": 2.3759036144578317e-06,
      "loss": 0.0001,
      "step": 146280
    },
    {
      "epoch": 17.625301204819277,
      "grad_norm": 0.5900861024856567,
      "learning_rate": 2.3746987951807232e-06,
      "loss": 0.0179,
      "step": 146290
    },
    {
      "epoch": 17.626506024096386,
      "grad_norm": 1.7684879302978516,
      "learning_rate": 2.373493975903615e-06,
      "loss": 0.0128,
      "step": 146300
    },
    {
      "epoch": 17.627710843373492,
      "grad_norm": 0.00022465267102234066,
      "learning_rate": 2.3722891566265064e-06,
      "loss": 0.0136,
      "step": 146310
    },
    {
      "epoch": 17.628915662650602,
      "grad_norm": 0.00019409944070503116,
      "learning_rate": 2.3710843373493976e-06,
      "loss": 0.0041,
      "step": 146320
    },
    {
      "epoch": 17.63012048192771,
      "grad_norm": 0.355255663394928,
      "learning_rate": 2.3698795180722896e-06,
      "loss": 0.0244,
      "step": 146330
    },
    {
      "epoch": 17.631325301204818,
      "grad_norm": 0.001368087949231267,
      "learning_rate": 2.3686746987951808e-06,
      "loss": 0.0068,
      "step": 146340
    },
    {
      "epoch": 17.632530120481928,
      "grad_norm": 0.0017271636752411723,
      "learning_rate": 2.3674698795180723e-06,
      "loss": 0.0262,
      "step": 146350
    },
    {
      "epoch": 17.633734939759037,
      "grad_norm": 0.00034538860199972987,
      "learning_rate": 2.366265060240964e-06,
      "loss": 0.0013,
      "step": 146360
    },
    {
      "epoch": 17.634939759036143,
      "grad_norm": 0.0005206509958952665,
      "learning_rate": 2.3650602409638555e-06,
      "loss": 0.0,
      "step": 146370
    },
    {
      "epoch": 17.636144578313253,
      "grad_norm": 0.2804366648197174,
      "learning_rate": 2.363855421686747e-06,
      "loss": 0.021,
      "step": 146380
    },
    {
      "epoch": 17.637349397590363,
      "grad_norm": 0.8886353373527527,
      "learning_rate": 2.3626506024096387e-06,
      "loss": 0.0425,
      "step": 146390
    },
    {
      "epoch": 17.63855421686747,
      "grad_norm": 0.0006019243155606091,
      "learning_rate": 2.3614457831325303e-06,
      "loss": 0.006,
      "step": 146400
    },
    {
      "epoch": 17.63975903614458,
      "grad_norm": 0.0005893619963899255,
      "learning_rate": 2.360240963855422e-06,
      "loss": 0.0322,
      "step": 146410
    },
    {
      "epoch": 17.64096385542169,
      "grad_norm": 0.004984906874597073,
      "learning_rate": 2.3590361445783135e-06,
      "loss": 0.0014,
      "step": 146420
    },
    {
      "epoch": 17.642168674698794,
      "grad_norm": 0.0004910114803351462,
      "learning_rate": 2.357831325301205e-06,
      "loss": 0.004,
      "step": 146430
    },
    {
      "epoch": 17.643373493975904,
      "grad_norm": 0.6384052634239197,
      "learning_rate": 2.3566265060240966e-06,
      "loss": 0.0171,
      "step": 146440
    },
    {
      "epoch": 17.644578313253014,
      "grad_norm": 0.19780294597148895,
      "learning_rate": 2.3554216867469882e-06,
      "loss": 0.0009,
      "step": 146450
    },
    {
      "epoch": 17.64578313253012,
      "grad_norm": 0.0003609734703786671,
      "learning_rate": 2.35421686746988e-06,
      "loss": 0.0086,
      "step": 146460
    },
    {
      "epoch": 17.64698795180723,
      "grad_norm": 0.00019202126713935286,
      "learning_rate": 2.3530120481927714e-06,
      "loss": 0.0039,
      "step": 146470
    },
    {
      "epoch": 17.648192771084336,
      "grad_norm": 0.00023808212426956743,
      "learning_rate": 2.351807228915663e-06,
      "loss": 0.0099,
      "step": 146480
    },
    {
      "epoch": 17.649397590361446,
      "grad_norm": 1.8743581771850586,
      "learning_rate": 2.350602409638554e-06,
      "loss": 0.0334,
      "step": 146490
    },
    {
      "epoch": 17.650602409638555,
      "grad_norm": 0.022029349580407143,
      "learning_rate": 2.349397590361446e-06,
      "loss": 0.0077,
      "step": 146500
    },
    {
      "epoch": 17.65180722891566,
      "grad_norm": 0.00030587840592488647,
      "learning_rate": 2.3481927710843373e-06,
      "loss": 0.0108,
      "step": 146510
    },
    {
      "epoch": 17.65301204819277,
      "grad_norm": 1.3071953058242798,
      "learning_rate": 2.3469879518072293e-06,
      "loss": 0.0172,
      "step": 146520
    },
    {
      "epoch": 17.65421686746988,
      "grad_norm": 0.00032057042699307203,
      "learning_rate": 2.3457831325301205e-06,
      "loss": 0.0014,
      "step": 146530
    },
    {
      "epoch": 17.655421686746987,
      "grad_norm": 0.2361467331647873,
      "learning_rate": 2.344578313253012e-06,
      "loss": 0.001,
      "step": 146540
    },
    {
      "epoch": 17.656626506024097,
      "grad_norm": 0.0001749744697008282,
      "learning_rate": 2.3433734939759037e-06,
      "loss": 0.0183,
      "step": 146550
    },
    {
      "epoch": 17.657831325301206,
      "grad_norm": 1.0279879570007324,
      "learning_rate": 2.3421686746987953e-06,
      "loss": 0.0209,
      "step": 146560
    },
    {
      "epoch": 17.659036144578312,
      "grad_norm": 0.00021185407240409404,
      "learning_rate": 2.340963855421687e-06,
      "loss": 0.0159,
      "step": 146570
    },
    {
      "epoch": 17.660240963855422,
      "grad_norm": 0.0009538669837638736,
      "learning_rate": 2.3397590361445784e-06,
      "loss": 0.0252,
      "step": 146580
    },
    {
      "epoch": 17.66144578313253,
      "grad_norm": 0.000900297483894974,
      "learning_rate": 2.33855421686747e-06,
      "loss": 0.0085,
      "step": 146590
    },
    {
      "epoch": 17.662650602409638,
      "grad_norm": 0.0012221270008012652,
      "learning_rate": 2.3373493975903616e-06,
      "loss": 0.0256,
      "step": 146600
    },
    {
      "epoch": 17.663855421686748,
      "grad_norm": 0.0032055082265287638,
      "learning_rate": 2.336144578313253e-06,
      "loss": 0.0462,
      "step": 146610
    },
    {
      "epoch": 17.665060240963854,
      "grad_norm": 0.00020842667436227202,
      "learning_rate": 2.334939759036145e-06,
      "loss": 0.0167,
      "step": 146620
    },
    {
      "epoch": 17.666265060240963,
      "grad_norm": 0.0005022345576435328,
      "learning_rate": 2.3337349397590364e-06,
      "loss": 0.0174,
      "step": 146630
    },
    {
      "epoch": 17.667469879518073,
      "grad_norm": 0.00025802498566918075,
      "learning_rate": 2.332530120481928e-06,
      "loss": 0.0171,
      "step": 146640
    },
    {
      "epoch": 17.66867469879518,
      "grad_norm": 0.00037702536792494357,
      "learning_rate": 2.3313253012048196e-06,
      "loss": 0.0244,
      "step": 146650
    },
    {
      "epoch": 17.66987951807229,
      "grad_norm": 0.00039190828101709485,
      "learning_rate": 2.330120481927711e-06,
      "loss": 0.0169,
      "step": 146660
    },
    {
      "epoch": 17.6710843373494,
      "grad_norm": 0.00024010772176552564,
      "learning_rate": 2.3289156626506027e-06,
      "loss": 0.003,
      "step": 146670
    },
    {
      "epoch": 17.672289156626505,
      "grad_norm": 0.03377353027462959,
      "learning_rate": 2.327710843373494e-06,
      "loss": 0.0009,
      "step": 146680
    },
    {
      "epoch": 17.673493975903614,
      "grad_norm": 1.0827131271362305,
      "learning_rate": 2.326506024096386e-06,
      "loss": 0.0042,
      "step": 146690
    },
    {
      "epoch": 17.674698795180724,
      "grad_norm": 1.1663306951522827,
      "learning_rate": 2.325301204819277e-06,
      "loss": 0.0043,
      "step": 146700
    },
    {
      "epoch": 17.67590361445783,
      "grad_norm": 1.5482401847839355,
      "learning_rate": 2.3240963855421687e-06,
      "loss": 0.018,
      "step": 146710
    },
    {
      "epoch": 17.67710843373494,
      "grad_norm": 0.0020588429179042578,
      "learning_rate": 2.3228915662650603e-06,
      "loss": 0.0111,
      "step": 146720
    },
    {
      "epoch": 17.67831325301205,
      "grad_norm": 0.9047573804855347,
      "learning_rate": 2.321686746987952e-06,
      "loss": 0.0131,
      "step": 146730
    },
    {
      "epoch": 17.679518072289156,
      "grad_norm": 1.0229157209396362,
      "learning_rate": 2.320481927710844e-06,
      "loss": 0.0055,
      "step": 146740
    },
    {
      "epoch": 17.680722891566266,
      "grad_norm": 0.2107786238193512,
      "learning_rate": 2.319277108433735e-06,
      "loss": 0.0162,
      "step": 146750
    },
    {
      "epoch": 17.681927710843375,
      "grad_norm": 0.00044214382069185376,
      "learning_rate": 2.3180722891566266e-06,
      "loss": 0.0073,
      "step": 146760
    },
    {
      "epoch": 17.68313253012048,
      "grad_norm": 0.007639165036380291,
      "learning_rate": 2.316867469879518e-06,
      "loss": 0.0026,
      "step": 146770
    },
    {
      "epoch": 17.68433734939759,
      "grad_norm": 0.0008787635597400367,
      "learning_rate": 2.3156626506024098e-06,
      "loss": 0.0303,
      "step": 146780
    },
    {
      "epoch": 17.685542168674697,
      "grad_norm": 0.9318898916244507,
      "learning_rate": 2.3144578313253014e-06,
      "loss": 0.0337,
      "step": 146790
    },
    {
      "epoch": 17.686746987951807,
      "grad_norm": 0.0002485134173184633,
      "learning_rate": 2.313253012048193e-06,
      "loss": 0.0086,
      "step": 146800
    },
    {
      "epoch": 17.687951807228917,
      "grad_norm": 0.2376008778810501,
      "learning_rate": 2.3120481927710845e-06,
      "loss": 0.0124,
      "step": 146810
    },
    {
      "epoch": 17.689156626506023,
      "grad_norm": 0.9248694181442261,
      "learning_rate": 2.310843373493976e-06,
      "loss": 0.0276,
      "step": 146820
    },
    {
      "epoch": 17.690361445783132,
      "grad_norm": 0.6309782266616821,
      "learning_rate": 2.3096385542168677e-06,
      "loss": 0.0105,
      "step": 146830
    },
    {
      "epoch": 17.691566265060242,
      "grad_norm": 0.2042427510023117,
      "learning_rate": 2.3084337349397593e-06,
      "loss": 0.0198,
      "step": 146840
    },
    {
      "epoch": 17.69277108433735,
      "grad_norm": 0.004175301641225815,
      "learning_rate": 2.3072289156626505e-06,
      "loss": 0.0078,
      "step": 146850
    },
    {
      "epoch": 17.693975903614458,
      "grad_norm": 2.1025731563568115,
      "learning_rate": 2.3060240963855425e-06,
      "loss": 0.032,
      "step": 146860
    },
    {
      "epoch": 17.695180722891568,
      "grad_norm": 0.0004404040228109807,
      "learning_rate": 2.304819277108434e-06,
      "loss": 0.0195,
      "step": 146870
    },
    {
      "epoch": 17.696385542168674,
      "grad_norm": 0.0002312686265213415,
      "learning_rate": 2.3036144578313257e-06,
      "loss": 0.0156,
      "step": 146880
    },
    {
      "epoch": 17.697590361445783,
      "grad_norm": 1.6527193784713745,
      "learning_rate": 2.3024096385542172e-06,
      "loss": 0.0127,
      "step": 146890
    },
    {
      "epoch": 17.698795180722893,
      "grad_norm": 0.005987480282783508,
      "learning_rate": 2.3012048192771084e-06,
      "loss": 0.007,
      "step": 146900
    },
    {
      "epoch": 17.7,
      "grad_norm": 1.4422751665115356,
      "learning_rate": 2.3000000000000004e-06,
      "loss": 0.0091,
      "step": 146910
    },
    {
      "epoch": 17.70120481927711,
      "grad_norm": 0.0001509296998847276,
      "learning_rate": 2.2987951807228916e-06,
      "loss": 0.0232,
      "step": 146920
    },
    {
      "epoch": 17.702409638554215,
      "grad_norm": 0.3022184371948242,
      "learning_rate": 2.2975903614457836e-06,
      "loss": 0.0156,
      "step": 146930
    },
    {
      "epoch": 17.703614457831325,
      "grad_norm": 11.73267936706543,
      "learning_rate": 2.2963855421686748e-06,
      "loss": 0.058,
      "step": 146940
    },
    {
      "epoch": 17.704819277108435,
      "grad_norm": 0.00022767111659049988,
      "learning_rate": 2.2951807228915664e-06,
      "loss": 0.0134,
      "step": 146950
    },
    {
      "epoch": 17.70602409638554,
      "grad_norm": 0.022107990458607674,
      "learning_rate": 2.293975903614458e-06,
      "loss": 0.0159,
      "step": 146960
    },
    {
      "epoch": 17.70722891566265,
      "grad_norm": 0.34291312098503113,
      "learning_rate": 2.2927710843373495e-06,
      "loss": 0.0159,
      "step": 146970
    },
    {
      "epoch": 17.70843373493976,
      "grad_norm": 0.0006265758420340717,
      "learning_rate": 2.291566265060241e-06,
      "loss": 0.0082,
      "step": 146980
    },
    {
      "epoch": 17.709638554216866,
      "grad_norm": 0.889546811580658,
      "learning_rate": 2.2903614457831327e-06,
      "loss": 0.0098,
      "step": 146990
    },
    {
      "epoch": 17.710843373493976,
      "grad_norm": 0.00040634331526234746,
      "learning_rate": 2.2891566265060243e-06,
      "loss": 0.0048,
      "step": 147000
    },
    {
      "epoch": 17.712048192771086,
      "grad_norm": 1.8662456274032593,
      "learning_rate": 2.287951807228916e-06,
      "loss": 0.0066,
      "step": 147010
    },
    {
      "epoch": 17.71325301204819,
      "grad_norm": 0.04489042982459068,
      "learning_rate": 2.2867469879518075e-06,
      "loss": 0.0001,
      "step": 147020
    },
    {
      "epoch": 17.7144578313253,
      "grad_norm": 0.0009436878026463091,
      "learning_rate": 2.285542168674699e-06,
      "loss": 0.0083,
      "step": 147030
    },
    {
      "epoch": 17.71566265060241,
      "grad_norm": 0.00041363196214661,
      "learning_rate": 2.2843373493975906e-06,
      "loss": 0.0116,
      "step": 147040
    },
    {
      "epoch": 17.716867469879517,
      "grad_norm": 0.0012107506627216935,
      "learning_rate": 2.2831325301204822e-06,
      "loss": 0.001,
      "step": 147050
    },
    {
      "epoch": 17.718072289156627,
      "grad_norm": 0.0013236600207164884,
      "learning_rate": 2.281927710843374e-06,
      "loss": 0.0292,
      "step": 147060
    },
    {
      "epoch": 17.719277108433737,
      "grad_norm": 0.9873788356781006,
      "learning_rate": 2.280722891566265e-06,
      "loss": 0.0093,
      "step": 147070
    },
    {
      "epoch": 17.720481927710843,
      "grad_norm": 0.001548909000121057,
      "learning_rate": 2.279518072289157e-06,
      "loss": 0.0054,
      "step": 147080
    },
    {
      "epoch": 17.721686746987952,
      "grad_norm": 2.0805892944335938,
      "learning_rate": 2.278313253012048e-06,
      "loss": 0.0233,
      "step": 147090
    },
    {
      "epoch": 17.72289156626506,
      "grad_norm": 0.000592659751418978,
      "learning_rate": 2.27710843373494e-06,
      "loss": 0.0129,
      "step": 147100
    },
    {
      "epoch": 17.72409638554217,
      "grad_norm": 0.00037073789280839264,
      "learning_rate": 2.2759036144578313e-06,
      "loss": 0.0178,
      "step": 147110
    },
    {
      "epoch": 17.725301204819278,
      "grad_norm": 1.1878330707550049,
      "learning_rate": 2.274698795180723e-06,
      "loss": 0.0327,
      "step": 147120
    },
    {
      "epoch": 17.726506024096384,
      "grad_norm": 0.6054133176803589,
      "learning_rate": 2.2734939759036145e-06,
      "loss": 0.0131,
      "step": 147130
    },
    {
      "epoch": 17.727710843373494,
      "grad_norm": 0.00017471190949436277,
      "learning_rate": 2.272289156626506e-06,
      "loss": 0.0113,
      "step": 147140
    },
    {
      "epoch": 17.728915662650603,
      "grad_norm": 0.8565770387649536,
      "learning_rate": 2.2710843373493977e-06,
      "loss": 0.0097,
      "step": 147150
    },
    {
      "epoch": 17.73012048192771,
      "grad_norm": 3.1490914821624756,
      "learning_rate": 2.2698795180722893e-06,
      "loss": 0.0257,
      "step": 147160
    },
    {
      "epoch": 17.73132530120482,
      "grad_norm": 0.00023829737619962543,
      "learning_rate": 2.268674698795181e-06,
      "loss": 0.011,
      "step": 147170
    },
    {
      "epoch": 17.73253012048193,
      "grad_norm": 0.19661472737789154,
      "learning_rate": 2.2674698795180725e-06,
      "loss": 0.0011,
      "step": 147180
    },
    {
      "epoch": 17.733734939759035,
      "grad_norm": 0.0017263001063838601,
      "learning_rate": 2.266265060240964e-06,
      "loss": 0.014,
      "step": 147190
    },
    {
      "epoch": 17.734939759036145,
      "grad_norm": 0.0002560090215411037,
      "learning_rate": 2.2650602409638556e-06,
      "loss": 0.0251,
      "step": 147200
    },
    {
      "epoch": 17.736144578313255,
      "grad_norm": 0.2839162349700928,
      "learning_rate": 2.2638554216867472e-06,
      "loss": 0.0021,
      "step": 147210
    },
    {
      "epoch": 17.73734939759036,
      "grad_norm": 0.0001834957511164248,
      "learning_rate": 2.262650602409639e-06,
      "loss": 0.0016,
      "step": 147220
    },
    {
      "epoch": 17.73855421686747,
      "grad_norm": 0.0004043308144900948,
      "learning_rate": 2.2614457831325304e-06,
      "loss": 0.0087,
      "step": 147230
    },
    {
      "epoch": 17.739759036144576,
      "grad_norm": 0.2672673463821411,
      "learning_rate": 2.260240963855422e-06,
      "loss": 0.0289,
      "step": 147240
    },
    {
      "epoch": 17.740963855421686,
      "grad_norm": 0.0007330795051530004,
      "learning_rate": 2.2590361445783136e-06,
      "loss": 0.0062,
      "step": 147250
    },
    {
      "epoch": 17.742168674698796,
      "grad_norm": 0.019520847126841545,
      "learning_rate": 2.2578313253012047e-06,
      "loss": 0.002,
      "step": 147260
    },
    {
      "epoch": 17.743373493975902,
      "grad_norm": 0.00038404224324040115,
      "learning_rate": 2.2566265060240967e-06,
      "loss": 0.0068,
      "step": 147270
    },
    {
      "epoch": 17.74457831325301,
      "grad_norm": 0.9562720656394958,
      "learning_rate": 2.255421686746988e-06,
      "loss": 0.0053,
      "step": 147280
    },
    {
      "epoch": 17.74578313253012,
      "grad_norm": 0.7847491502761841,
      "learning_rate": 2.25421686746988e-06,
      "loss": 0.0112,
      "step": 147290
    },
    {
      "epoch": 17.746987951807228,
      "grad_norm": 1.1033529043197632,
      "learning_rate": 2.253012048192771e-06,
      "loss": 0.0105,
      "step": 147300
    },
    {
      "epoch": 17.748192771084337,
      "grad_norm": 0.0007463600486516953,
      "learning_rate": 2.2518072289156627e-06,
      "loss": 0.0059,
      "step": 147310
    },
    {
      "epoch": 17.749397590361447,
      "grad_norm": 0.0121838990598917,
      "learning_rate": 2.2506024096385547e-06,
      "loss": 0.0187,
      "step": 147320
    },
    {
      "epoch": 17.750602409638553,
      "grad_norm": 0.0002388132270425558,
      "learning_rate": 2.249397590361446e-06,
      "loss": 0.001,
      "step": 147330
    },
    {
      "epoch": 17.751807228915663,
      "grad_norm": 0.005920763593167067,
      "learning_rate": 2.2481927710843374e-06,
      "loss": 0.0108,
      "step": 147340
    },
    {
      "epoch": 17.753012048192772,
      "grad_norm": 0.00021174455469008535,
      "learning_rate": 2.246987951807229e-06,
      "loss": 0.0115,
      "step": 147350
    },
    {
      "epoch": 17.75421686746988,
      "grad_norm": 0.6608866453170776,
      "learning_rate": 2.2457831325301206e-06,
      "loss": 0.0049,
      "step": 147360
    },
    {
      "epoch": 17.75542168674699,
      "grad_norm": 0.00027226979727856815,
      "learning_rate": 2.244578313253012e-06,
      "loss": 0.0093,
      "step": 147370
    },
    {
      "epoch": 17.756626506024098,
      "grad_norm": 0.00018156820442527533,
      "learning_rate": 2.243373493975904e-06,
      "loss": 0.0002,
      "step": 147380
    },
    {
      "epoch": 17.757831325301204,
      "grad_norm": 0.1876172423362732,
      "learning_rate": 2.2421686746987954e-06,
      "loss": 0.0051,
      "step": 147390
    },
    {
      "epoch": 17.759036144578314,
      "grad_norm": 0.00019226392032578588,
      "learning_rate": 2.240963855421687e-06,
      "loss": 0.004,
      "step": 147400
    },
    {
      "epoch": 17.760240963855424,
      "grad_norm": 0.00014561603893525898,
      "learning_rate": 2.2397590361445786e-06,
      "loss": 0.001,
      "step": 147410
    },
    {
      "epoch": 17.76144578313253,
      "grad_norm": 0.8686113953590393,
      "learning_rate": 2.23855421686747e-06,
      "loss": 0.0103,
      "step": 147420
    },
    {
      "epoch": 17.76265060240964,
      "grad_norm": 0.19908273220062256,
      "learning_rate": 2.2373493975903613e-06,
      "loss": 0.01,
      "step": 147430
    },
    {
      "epoch": 17.763855421686745,
      "grad_norm": 0.00012608284305315465,
      "learning_rate": 2.2361445783132533e-06,
      "loss": 0.0101,
      "step": 147440
    },
    {
      "epoch": 17.765060240963855,
      "grad_norm": 0.0001273525704164058,
      "learning_rate": 2.2349397590361445e-06,
      "loss": 0.0188,
      "step": 147450
    },
    {
      "epoch": 17.766265060240965,
      "grad_norm": 0.0001967358693946153,
      "learning_rate": 2.2337349397590365e-06,
      "loss": 0.0306,
      "step": 147460
    },
    {
      "epoch": 17.76746987951807,
      "grad_norm": 0.24745304882526398,
      "learning_rate": 2.232530120481928e-06,
      "loss": 0.0164,
      "step": 147470
    },
    {
      "epoch": 17.76867469879518,
      "grad_norm": 0.40397995710372925,
      "learning_rate": 2.2313253012048192e-06,
      "loss": 0.0106,
      "step": 147480
    },
    {
      "epoch": 17.76987951807229,
      "grad_norm": 0.3011716306209564,
      "learning_rate": 2.2301204819277113e-06,
      "loss": 0.005,
      "step": 147490
    },
    {
      "epoch": 17.771084337349397,
      "grad_norm": 0.0013617515796795487,
      "learning_rate": 2.2289156626506024e-06,
      "loss": 0.0109,
      "step": 147500
    },
    {
      "epoch": 17.772289156626506,
      "grad_norm": 0.7555217742919922,
      "learning_rate": 2.2277108433734944e-06,
      "loss": 0.0028,
      "step": 147510
    },
    {
      "epoch": 17.773493975903616,
      "grad_norm": 0.0010348757496103644,
      "learning_rate": 2.2265060240963856e-06,
      "loss": 0.0019,
      "step": 147520
    },
    {
      "epoch": 17.774698795180722,
      "grad_norm": 0.00029244180768728256,
      "learning_rate": 2.225301204819277e-06,
      "loss": 0.0327,
      "step": 147530
    },
    {
      "epoch": 17.77590361445783,
      "grad_norm": 0.00013001241313759238,
      "learning_rate": 2.2240963855421688e-06,
      "loss": 0.0033,
      "step": 147540
    },
    {
      "epoch": 17.77710843373494,
      "grad_norm": 0.0001415870792698115,
      "learning_rate": 2.2228915662650604e-06,
      "loss": 0.0286,
      "step": 147550
    },
    {
      "epoch": 17.778313253012048,
      "grad_norm": 0.4045577645301819,
      "learning_rate": 2.221686746987952e-06,
      "loss": 0.0159,
      "step": 147560
    },
    {
      "epoch": 17.779518072289157,
      "grad_norm": 0.002037788275629282,
      "learning_rate": 2.2204819277108435e-06,
      "loss": 0.0178,
      "step": 147570
    },
    {
      "epoch": 17.780722891566263,
      "grad_norm": 0.7248488068580627,
      "learning_rate": 2.219277108433735e-06,
      "loss": 0.0172,
      "step": 147580
    },
    {
      "epoch": 17.781927710843373,
      "grad_norm": 1.5611974000930786,
      "learning_rate": 2.2180722891566267e-06,
      "loss": 0.0189,
      "step": 147590
    },
    {
      "epoch": 17.783132530120483,
      "grad_norm": 0.0001939213543664664,
      "learning_rate": 2.2168674698795183e-06,
      "loss": 0.0058,
      "step": 147600
    },
    {
      "epoch": 17.78433734939759,
      "grad_norm": 1.7900338172912598,
      "learning_rate": 2.21566265060241e-06,
      "loss": 0.0096,
      "step": 147610
    },
    {
      "epoch": 17.7855421686747,
      "grad_norm": 0.0004094757605344057,
      "learning_rate": 2.2144578313253015e-06,
      "loss": 0.0057,
      "step": 147620
    },
    {
      "epoch": 17.78674698795181,
      "grad_norm": 1.3634705543518066,
      "learning_rate": 2.213253012048193e-06,
      "loss": 0.008,
      "step": 147630
    },
    {
      "epoch": 17.787951807228914,
      "grad_norm": 4.919848918914795,
      "learning_rate": 2.2120481927710847e-06,
      "loss": 0.0172,
      "step": 147640
    },
    {
      "epoch": 17.789156626506024,
      "grad_norm": 0.8318702578544617,
      "learning_rate": 2.2108433734939762e-06,
      "loss": 0.0296,
      "step": 147650
    },
    {
      "epoch": 17.790361445783134,
      "grad_norm": 0.00037506018998101354,
      "learning_rate": 2.209638554216868e-06,
      "loss": 0.0418,
      "step": 147660
    },
    {
      "epoch": 17.79156626506024,
      "grad_norm": 0.7021123170852661,
      "learning_rate": 2.208433734939759e-06,
      "loss": 0.0103,
      "step": 147670
    },
    {
      "epoch": 17.79277108433735,
      "grad_norm": 0.00015983934281393886,
      "learning_rate": 2.207228915662651e-06,
      "loss": 0.015,
      "step": 147680
    },
    {
      "epoch": 17.79397590361446,
      "grad_norm": 0.009253380820155144,
      "learning_rate": 2.206024096385542e-06,
      "loss": 0.0078,
      "step": 147690
    },
    {
      "epoch": 17.795180722891565,
      "grad_norm": 0.287847101688385,
      "learning_rate": 2.2048192771084338e-06,
      "loss": 0.0217,
      "step": 147700
    },
    {
      "epoch": 17.796385542168675,
      "grad_norm": 1.054834246635437,
      "learning_rate": 2.2036144578313253e-06,
      "loss": 0.0089,
      "step": 147710
    },
    {
      "epoch": 17.797590361445785,
      "grad_norm": 0.3015407919883728,
      "learning_rate": 2.202409638554217e-06,
      "loss": 0.0161,
      "step": 147720
    },
    {
      "epoch": 17.79879518072289,
      "grad_norm": 0.00021851994097232819,
      "learning_rate": 2.2012048192771085e-06,
      "loss": 0.0074,
      "step": 147730
    },
    {
      "epoch": 17.8,
      "grad_norm": 0.0007692509097978473,
      "learning_rate": 2.2e-06,
      "loss": 0.0055,
      "step": 147740
    },
    {
      "epoch": 17.801204819277107,
      "grad_norm": 0.024573838338255882,
      "learning_rate": 2.1987951807228917e-06,
      "loss": 0.0001,
      "step": 147750
    },
    {
      "epoch": 17.802409638554217,
      "grad_norm": 1.065326452255249,
      "learning_rate": 2.1975903614457833e-06,
      "loss": 0.0143,
      "step": 147760
    },
    {
      "epoch": 17.803614457831326,
      "grad_norm": 1.9978340864181519,
      "learning_rate": 2.196385542168675e-06,
      "loss": 0.0291,
      "step": 147770
    },
    {
      "epoch": 17.804819277108432,
      "grad_norm": 0.22740307450294495,
      "learning_rate": 2.1951807228915665e-06,
      "loss": 0.0081,
      "step": 147780
    },
    {
      "epoch": 17.806024096385542,
      "grad_norm": 1.395469307899475,
      "learning_rate": 2.193975903614458e-06,
      "loss": 0.0152,
      "step": 147790
    },
    {
      "epoch": 17.80722891566265,
      "grad_norm": 0.8052332401275635,
      "learning_rate": 2.1927710843373496e-06,
      "loss": 0.0121,
      "step": 147800
    },
    {
      "epoch": 17.808433734939758,
      "grad_norm": 0.00046671717427670956,
      "learning_rate": 2.1915662650602412e-06,
      "loss": 0.0049,
      "step": 147810
    },
    {
      "epoch": 17.809638554216868,
      "grad_norm": 0.00018860293494071811,
      "learning_rate": 2.190361445783133e-06,
      "loss": 0.0308,
      "step": 147820
    },
    {
      "epoch": 17.810843373493977,
      "grad_norm": 0.00023910889285616577,
      "learning_rate": 2.1891566265060244e-06,
      "loss": 0.0059,
      "step": 147830
    },
    {
      "epoch": 17.812048192771083,
      "grad_norm": 0.0003448455245234072,
      "learning_rate": 2.1879518072289156e-06,
      "loss": 0.0043,
      "step": 147840
    },
    {
      "epoch": 17.813253012048193,
      "grad_norm": 0.8359561562538147,
      "learning_rate": 2.1867469879518076e-06,
      "loss": 0.0061,
      "step": 147850
    },
    {
      "epoch": 17.814457831325303,
      "grad_norm": 0.3282203674316406,
      "learning_rate": 2.1855421686746987e-06,
      "loss": 0.0252,
      "step": 147860
    },
    {
      "epoch": 17.81566265060241,
      "grad_norm": 0.0008055559592321515,
      "learning_rate": 2.1843373493975908e-06,
      "loss": 0.0225,
      "step": 147870
    },
    {
      "epoch": 17.81686746987952,
      "grad_norm": 0.23091867566108704,
      "learning_rate": 2.183132530120482e-06,
      "loss": 0.0155,
      "step": 147880
    },
    {
      "epoch": 17.818072289156625,
      "grad_norm": 0.7224411964416504,
      "learning_rate": 2.1819277108433735e-06,
      "loss": 0.0148,
      "step": 147890
    },
    {
      "epoch": 17.819277108433734,
      "grad_norm": 0.0009636597824282944,
      "learning_rate": 2.1807228915662655e-06,
      "loss": 0.0153,
      "step": 147900
    },
    {
      "epoch": 17.820481927710844,
      "grad_norm": 0.00022779969731345773,
      "learning_rate": 2.1795180722891567e-06,
      "loss": 0.0208,
      "step": 147910
    },
    {
      "epoch": 17.82168674698795,
      "grad_norm": 0.05324985459446907,
      "learning_rate": 2.1783132530120487e-06,
      "loss": 0.0057,
      "step": 147920
    },
    {
      "epoch": 17.82289156626506,
      "grad_norm": 0.22802364826202393,
      "learning_rate": 2.17710843373494e-06,
      "loss": 0.0011,
      "step": 147930
    },
    {
      "epoch": 17.82409638554217,
      "grad_norm": 1.3184881210327148,
      "learning_rate": 2.1759036144578314e-06,
      "loss": 0.0345,
      "step": 147940
    },
    {
      "epoch": 17.825301204819276,
      "grad_norm": 0.0005193164688535035,
      "learning_rate": 2.174698795180723e-06,
      "loss": 0.0049,
      "step": 147950
    },
    {
      "epoch": 17.826506024096386,
      "grad_norm": 0.00038099579978734255,
      "learning_rate": 2.1734939759036146e-06,
      "loss": 0.0211,
      "step": 147960
    },
    {
      "epoch": 17.827710843373495,
      "grad_norm": 1.2473551034927368,
      "learning_rate": 2.1722891566265062e-06,
      "loss": 0.0081,
      "step": 147970
    },
    {
      "epoch": 17.8289156626506,
      "grad_norm": 0.00015954872651491314,
      "learning_rate": 2.171084337349398e-06,
      "loss": 0.0273,
      "step": 147980
    },
    {
      "epoch": 17.83012048192771,
      "grad_norm": 0.021408116444945335,
      "learning_rate": 2.1698795180722894e-06,
      "loss": 0.0559,
      "step": 147990
    },
    {
      "epoch": 17.83132530120482,
      "grad_norm": 1.8501054048538208,
      "learning_rate": 2.168674698795181e-06,
      "loss": 0.0113,
      "step": 148000
    },
    {
      "epoch": 17.832530120481927,
      "grad_norm": 0.9571409225463867,
      "learning_rate": 2.1674698795180726e-06,
      "loss": 0.0072,
      "step": 148010
    },
    {
      "epoch": 17.833734939759037,
      "grad_norm": 0.0004090124275535345,
      "learning_rate": 2.166265060240964e-06,
      "loss": 0.0088,
      "step": 148020
    },
    {
      "epoch": 17.834939759036146,
      "grad_norm": 2.088730812072754,
      "learning_rate": 2.1650602409638553e-06,
      "loss": 0.0089,
      "step": 148030
    },
    {
      "epoch": 17.836144578313252,
      "grad_norm": 0.0019388649379834533,
      "learning_rate": 2.1638554216867473e-06,
      "loss": 0.0084,
      "step": 148040
    },
    {
      "epoch": 17.837349397590362,
      "grad_norm": 0.31077373027801514,
      "learning_rate": 2.162650602409639e-06,
      "loss": 0.0071,
      "step": 148050
    },
    {
      "epoch": 17.83855421686747,
      "grad_norm": 0.0022728147450834513,
      "learning_rate": 2.16144578313253e-06,
      "loss": 0.0048,
      "step": 148060
    },
    {
      "epoch": 17.839759036144578,
      "grad_norm": 0.0005088879261165857,
      "learning_rate": 2.160240963855422e-06,
      "loss": 0.0218,
      "step": 148070
    },
    {
      "epoch": 17.840963855421688,
      "grad_norm": 0.0004391742404550314,
      "learning_rate": 2.1590361445783133e-06,
      "loss": 0.0012,
      "step": 148080
    },
    {
      "epoch": 17.842168674698794,
      "grad_norm": 0.009036488831043243,
      "learning_rate": 2.1578313253012053e-06,
      "loss": 0.0168,
      "step": 148090
    },
    {
      "epoch": 17.843373493975903,
      "grad_norm": 1.1118429899215698,
      "learning_rate": 2.1566265060240964e-06,
      "loss": 0.016,
      "step": 148100
    },
    {
      "epoch": 17.844578313253013,
      "grad_norm": 0.0004327319620642811,
      "learning_rate": 2.155421686746988e-06,
      "loss": 0.0062,
      "step": 148110
    },
    {
      "epoch": 17.84578313253012,
      "grad_norm": 1.5046643018722534,
      "learning_rate": 2.1542168674698796e-06,
      "loss": 0.0182,
      "step": 148120
    },
    {
      "epoch": 17.84698795180723,
      "grad_norm": 0.0003691782185342163,
      "learning_rate": 2.153012048192771e-06,
      "loss": 0.0174,
      "step": 148130
    },
    {
      "epoch": 17.84819277108434,
      "grad_norm": 0.00039501566789112985,
      "learning_rate": 2.1518072289156628e-06,
      "loss": 0.0136,
      "step": 148140
    },
    {
      "epoch": 17.849397590361445,
      "grad_norm": 0.01630869135260582,
      "learning_rate": 2.1506024096385544e-06,
      "loss": 0.003,
      "step": 148150
    },
    {
      "epoch": 17.850602409638554,
      "grad_norm": 0.00039161540917120874,
      "learning_rate": 2.149397590361446e-06,
      "loss": 0.0031,
      "step": 148160
    },
    {
      "epoch": 17.851807228915664,
      "grad_norm": 0.0030888114124536514,
      "learning_rate": 2.1481927710843375e-06,
      "loss": 0.0055,
      "step": 148170
    },
    {
      "epoch": 17.85301204819277,
      "grad_norm": 0.00023873511236160994,
      "learning_rate": 2.146987951807229e-06,
      "loss": 0.0169,
      "step": 148180
    },
    {
      "epoch": 17.85421686746988,
      "grad_norm": 0.0006697421194985509,
      "learning_rate": 2.1457831325301207e-06,
      "loss": 0.0267,
      "step": 148190
    },
    {
      "epoch": 17.855421686746986,
      "grad_norm": 2.099818229675293,
      "learning_rate": 2.1445783132530123e-06,
      "loss": 0.0107,
      "step": 148200
    },
    {
      "epoch": 17.856626506024096,
      "grad_norm": 0.0003033503016922623,
      "learning_rate": 2.143373493975904e-06,
      "loss": 0.015,
      "step": 148210
    },
    {
      "epoch": 17.857831325301206,
      "grad_norm": 1.8641537427902222,
      "learning_rate": 2.1421686746987955e-06,
      "loss": 0.0104,
      "step": 148220
    },
    {
      "epoch": 17.85903614457831,
      "grad_norm": 0.17465335130691528,
      "learning_rate": 2.140963855421687e-06,
      "loss": 0.0023,
      "step": 148230
    },
    {
      "epoch": 17.86024096385542,
      "grad_norm": 2.2064368724823,
      "learning_rate": 2.1397590361445787e-06,
      "loss": 0.0332,
      "step": 148240
    },
    {
      "epoch": 17.86144578313253,
      "grad_norm": 0.00045784024405293167,
      "learning_rate": 2.13855421686747e-06,
      "loss": 0.0016,
      "step": 148250
    },
    {
      "epoch": 17.862650602409637,
      "grad_norm": 1.8772211074829102,
      "learning_rate": 2.137349397590362e-06,
      "loss": 0.0283,
      "step": 148260
    },
    {
      "epoch": 17.863855421686747,
      "grad_norm": 0.00016466699889861047,
      "learning_rate": 2.136144578313253e-06,
      "loss": 0.0035,
      "step": 148270
    },
    {
      "epoch": 17.865060240963857,
      "grad_norm": 0.0117332199588418,
      "learning_rate": 2.134939759036145e-06,
      "loss": 0.0058,
      "step": 148280
    },
    {
      "epoch": 17.866265060240963,
      "grad_norm": 0.7351831197738647,
      "learning_rate": 2.133734939759036e-06,
      "loss": 0.0029,
      "step": 148290
    },
    {
      "epoch": 17.867469879518072,
      "grad_norm": 0.0002464792050886899,
      "learning_rate": 2.1325301204819278e-06,
      "loss": 0.0104,
      "step": 148300
    },
    {
      "epoch": 17.868674698795182,
      "grad_norm": 0.00014862358511891216,
      "learning_rate": 2.1313253012048194e-06,
      "loss": 0.0043,
      "step": 148310
    },
    {
      "epoch": 17.86987951807229,
      "grad_norm": 0.00013829953968524933,
      "learning_rate": 2.130120481927711e-06,
      "loss": 0.0018,
      "step": 148320
    },
    {
      "epoch": 17.871084337349398,
      "grad_norm": 1.366135597229004,
      "learning_rate": 2.1289156626506025e-06,
      "loss": 0.0066,
      "step": 148330
    },
    {
      "epoch": 17.872289156626508,
      "grad_norm": 0.0001635301305213943,
      "learning_rate": 2.127710843373494e-06,
      "loss": 0.001,
      "step": 148340
    },
    {
      "epoch": 17.873493975903614,
      "grad_norm": 0.0005922189448028803,
      "learning_rate": 2.1265060240963857e-06,
      "loss": 0.0103,
      "step": 148350
    },
    {
      "epoch": 17.874698795180723,
      "grad_norm": 1.0839147567749023,
      "learning_rate": 2.1253012048192773e-06,
      "loss": 0.0117,
      "step": 148360
    },
    {
      "epoch": 17.87590361445783,
      "grad_norm": 0.00016382831381633878,
      "learning_rate": 2.124096385542169e-06,
      "loss": 0.0041,
      "step": 148370
    },
    {
      "epoch": 17.87710843373494,
      "grad_norm": 0.8671036958694458,
      "learning_rate": 2.1228915662650605e-06,
      "loss": 0.0093,
      "step": 148380
    },
    {
      "epoch": 17.87831325301205,
      "grad_norm": 0.00011921466648345813,
      "learning_rate": 2.121686746987952e-06,
      "loss": 0.0154,
      "step": 148390
    },
    {
      "epoch": 17.879518072289155,
      "grad_norm": 0.0001259010605281219,
      "learning_rate": 2.1204819277108437e-06,
      "loss": 0.0136,
      "step": 148400
    },
    {
      "epoch": 17.880722891566265,
      "grad_norm": 0.00021307622955646366,
      "learning_rate": 2.1192771084337352e-06,
      "loss": 0.008,
      "step": 148410
    },
    {
      "epoch": 17.881927710843375,
      "grad_norm": 0.001106529962271452,
      "learning_rate": 2.1180722891566264e-06,
      "loss": 0.0051,
      "step": 148420
    },
    {
      "epoch": 17.88313253012048,
      "grad_norm": 0.35222479701042175,
      "learning_rate": 2.1168674698795184e-06,
      "loss": 0.008,
      "step": 148430
    },
    {
      "epoch": 17.88433734939759,
      "grad_norm": 0.00012821800191886723,
      "learning_rate": 2.1156626506024096e-06,
      "loss": 0.0044,
      "step": 148440
    },
    {
      "epoch": 17.8855421686747,
      "grad_norm": 1.751841425895691,
      "learning_rate": 2.1144578313253016e-06,
      "loss": 0.0082,
      "step": 148450
    },
    {
      "epoch": 17.886746987951806,
      "grad_norm": 0.000172972577274777,
      "learning_rate": 2.1132530120481928e-06,
      "loss": 0.0374,
      "step": 148460
    },
    {
      "epoch": 17.887951807228916,
      "grad_norm": 0.00024237221805378795,
      "learning_rate": 2.1120481927710843e-06,
      "loss": 0.0138,
      "step": 148470
    },
    {
      "epoch": 17.889156626506026,
      "grad_norm": 1.64683198928833,
      "learning_rate": 2.110843373493976e-06,
      "loss": 0.0321,
      "step": 148480
    },
    {
      "epoch": 17.89036144578313,
      "grad_norm": 0.7491783499717712,
      "learning_rate": 2.1096385542168675e-06,
      "loss": 0.0143,
      "step": 148490
    },
    {
      "epoch": 17.89156626506024,
      "grad_norm": 0.1327868402004242,
      "learning_rate": 2.1084337349397595e-06,
      "loss": 0.0081,
      "step": 148500
    },
    {
      "epoch": 17.89277108433735,
      "grad_norm": 0.2173403650522232,
      "learning_rate": 2.1072289156626507e-06,
      "loss": 0.0027,
      "step": 148510
    },
    {
      "epoch": 17.893975903614457,
      "grad_norm": 0.3543211817741394,
      "learning_rate": 2.1060240963855423e-06,
      "loss": 0.0155,
      "step": 148520
    },
    {
      "epoch": 17.895180722891567,
      "grad_norm": 0.6428160667419434,
      "learning_rate": 2.104819277108434e-06,
      "loss": 0.0191,
      "step": 148530
    },
    {
      "epoch": 17.896385542168673,
      "grad_norm": 0.001702699693851173,
      "learning_rate": 2.1036144578313255e-06,
      "loss": 0.0156,
      "step": 148540
    },
    {
      "epoch": 17.897590361445783,
      "grad_norm": 0.1678304374217987,
      "learning_rate": 2.102409638554217e-06,
      "loss": 0.0208,
      "step": 148550
    },
    {
      "epoch": 17.898795180722892,
      "grad_norm": 6.058437347412109,
      "learning_rate": 2.1012048192771086e-06,
      "loss": 0.0203,
      "step": 148560
    },
    {
      "epoch": 17.9,
      "grad_norm": 0.0011152038350701332,
      "learning_rate": 2.1000000000000002e-06,
      "loss": 0.0108,
      "step": 148570
    },
    {
      "epoch": 17.90120481927711,
      "grad_norm": 0.0001875497546279803,
      "learning_rate": 2.098795180722892e-06,
      "loss": 0.001,
      "step": 148580
    },
    {
      "epoch": 17.902409638554218,
      "grad_norm": 1.0650348663330078,
      "learning_rate": 2.0975903614457834e-06,
      "loss": 0.0031,
      "step": 148590
    },
    {
      "epoch": 17.903614457831324,
      "grad_norm": 0.00039526159525848925,
      "learning_rate": 2.096385542168675e-06,
      "loss": 0.0164,
      "step": 148600
    },
    {
      "epoch": 17.904819277108434,
      "grad_norm": 0.0021858918480575085,
      "learning_rate": 2.095180722891566e-06,
      "loss": 0.0014,
      "step": 148610
    },
    {
      "epoch": 17.906024096385543,
      "grad_norm": 0.00014980175183154643,
      "learning_rate": 2.093975903614458e-06,
      "loss": 0.0093,
      "step": 148620
    },
    {
      "epoch": 17.90722891566265,
      "grad_norm": 0.00024015882809180766,
      "learning_rate": 2.0927710843373493e-06,
      "loss": 0.0139,
      "step": 148630
    },
    {
      "epoch": 17.90843373493976,
      "grad_norm": 0.28903302550315857,
      "learning_rate": 2.0915662650602413e-06,
      "loss": 0.0083,
      "step": 148640
    },
    {
      "epoch": 17.90963855421687,
      "grad_norm": 0.0001434202422387898,
      "learning_rate": 2.090361445783133e-06,
      "loss": 0.0245,
      "step": 148650
    },
    {
      "epoch": 17.910843373493975,
      "grad_norm": 0.2830736041069031,
      "learning_rate": 2.089156626506024e-06,
      "loss": 0.0021,
      "step": 148660
    },
    {
      "epoch": 17.912048192771085,
      "grad_norm": 0.0002953435177914798,
      "learning_rate": 2.087951807228916e-06,
      "loss": 0.0211,
      "step": 148670
    },
    {
      "epoch": 17.913253012048195,
      "grad_norm": 1.0972955226898193,
      "learning_rate": 2.0867469879518073e-06,
      "loss": 0.0114,
      "step": 148680
    },
    {
      "epoch": 17.9144578313253,
      "grad_norm": 0.00012709145084954798,
      "learning_rate": 2.085542168674699e-06,
      "loss": 0.0005,
      "step": 148690
    },
    {
      "epoch": 17.91566265060241,
      "grad_norm": 0.001068999175913632,
      "learning_rate": 2.0843373493975904e-06,
      "loss": 0.0066,
      "step": 148700
    },
    {
      "epoch": 17.916867469879517,
      "grad_norm": 2.027172088623047,
      "learning_rate": 2.083132530120482e-06,
      "loss": 0.0255,
      "step": 148710
    },
    {
      "epoch": 17.918072289156626,
      "grad_norm": 0.0001580599055159837,
      "learning_rate": 2.0819277108433736e-06,
      "loss": 0.0142,
      "step": 148720
    },
    {
      "epoch": 17.919277108433736,
      "grad_norm": 0.07225088775157928,
      "learning_rate": 2.080722891566265e-06,
      "loss": 0.0069,
      "step": 148730
    },
    {
      "epoch": 17.920481927710842,
      "grad_norm": 0.00018677279877010733,
      "learning_rate": 2.079518072289157e-06,
      "loss": 0.0165,
      "step": 148740
    },
    {
      "epoch": 17.92168674698795,
      "grad_norm": 0.00012795145448762923,
      "learning_rate": 2.0783132530120484e-06,
      "loss": 0.0113,
      "step": 148750
    },
    {
      "epoch": 17.92289156626506,
      "grad_norm": 1.0424860715866089,
      "learning_rate": 2.07710843373494e-06,
      "loss": 0.0313,
      "step": 148760
    },
    {
      "epoch": 17.924096385542168,
      "grad_norm": 0.0015070303343236446,
      "learning_rate": 2.0759036144578316e-06,
      "loss": 0.0082,
      "step": 148770
    },
    {
      "epoch": 17.925301204819277,
      "grad_norm": 0.00020385219249874353,
      "learning_rate": 2.0746987951807227e-06,
      "loss": 0.028,
      "step": 148780
    },
    {
      "epoch": 17.926506024096387,
      "grad_norm": 0.00012251098814886063,
      "learning_rate": 2.0734939759036147e-06,
      "loss": 0.0009,
      "step": 148790
    },
    {
      "epoch": 17.927710843373493,
      "grad_norm": 0.2488398402929306,
      "learning_rate": 2.0722891566265063e-06,
      "loss": 0.0032,
      "step": 148800
    },
    {
      "epoch": 17.928915662650603,
      "grad_norm": 0.0026293869595974684,
      "learning_rate": 2.071084337349398e-06,
      "loss": 0.0213,
      "step": 148810
    },
    {
      "epoch": 17.930120481927712,
      "grad_norm": 0.17568065226078033,
      "learning_rate": 2.0698795180722895e-06,
      "loss": 0.0215,
      "step": 148820
    },
    {
      "epoch": 17.93132530120482,
      "grad_norm": 0.00023186978069134057,
      "learning_rate": 2.0686746987951807e-06,
      "loss": 0.0171,
      "step": 148830
    },
    {
      "epoch": 17.93253012048193,
      "grad_norm": 0.0004024590307381004,
      "learning_rate": 2.0674698795180727e-06,
      "loss": 0.0398,
      "step": 148840
    },
    {
      "epoch": 17.933734939759034,
      "grad_norm": 0.0004506106488406658,
      "learning_rate": 2.066265060240964e-06,
      "loss": 0.0064,
      "step": 148850
    },
    {
      "epoch": 17.934939759036144,
      "grad_norm": 0.0002037412632489577,
      "learning_rate": 2.065060240963856e-06,
      "loss": 0.02,
      "step": 148860
    },
    {
      "epoch": 17.936144578313254,
      "grad_norm": 0.0021530825179070234,
      "learning_rate": 2.063855421686747e-06,
      "loss": 0.0,
      "step": 148870
    },
    {
      "epoch": 17.93734939759036,
      "grad_norm": 0.00010915254097199067,
      "learning_rate": 2.0626506024096386e-06,
      "loss": 0.0173,
      "step": 148880
    },
    {
      "epoch": 17.93855421686747,
      "grad_norm": 0.00015757822257000953,
      "learning_rate": 2.06144578313253e-06,
      "loss": 0.0092,
      "step": 148890
    },
    {
      "epoch": 17.93975903614458,
      "grad_norm": 1.547918438911438,
      "learning_rate": 2.0602409638554218e-06,
      "loss": 0.0083,
      "step": 148900
    },
    {
      "epoch": 17.940963855421685,
      "grad_norm": 9.512445831205696e-05,
      "learning_rate": 2.0590361445783134e-06,
      "loss": 0.0315,
      "step": 148910
    },
    {
      "epoch": 17.942168674698795,
      "grad_norm": 0.2855055332183838,
      "learning_rate": 2.057831325301205e-06,
      "loss": 0.0005,
      "step": 148920
    },
    {
      "epoch": 17.943373493975905,
      "grad_norm": 1.0276914834976196,
      "learning_rate": 2.0566265060240965e-06,
      "loss": 0.0157,
      "step": 148930
    },
    {
      "epoch": 17.94457831325301,
      "grad_norm": 0.0002174347755499184,
      "learning_rate": 2.055421686746988e-06,
      "loss": 0.0076,
      "step": 148940
    },
    {
      "epoch": 17.94578313253012,
      "grad_norm": 0.9710747599601746,
      "learning_rate": 2.0542168674698797e-06,
      "loss": 0.006,
      "step": 148950
    },
    {
      "epoch": 17.94698795180723,
      "grad_norm": 0.0002739963529165834,
      "learning_rate": 2.0530120481927713e-06,
      "loss": 0.008,
      "step": 148960
    },
    {
      "epoch": 17.948192771084337,
      "grad_norm": 8.952146163210273e-05,
      "learning_rate": 2.051807228915663e-06,
      "loss": 0.0043,
      "step": 148970
    },
    {
      "epoch": 17.949397590361446,
      "grad_norm": 0.0013161350507289171,
      "learning_rate": 2.0506024096385545e-06,
      "loss": 0.0272,
      "step": 148980
    },
    {
      "epoch": 17.950602409638556,
      "grad_norm": 0.10993136465549469,
      "learning_rate": 2.049397590361446e-06,
      "loss": 0.0083,
      "step": 148990
    },
    {
      "epoch": 17.951807228915662,
      "grad_norm": 0.00016540016804356128,
      "learning_rate": 2.0481927710843377e-06,
      "loss": 0.0161,
      "step": 149000
    },
    {
      "epoch": 17.95301204819277,
      "grad_norm": 0.0009496451239101589,
      "learning_rate": 2.0469879518072292e-06,
      "loss": 0.014,
      "step": 149010
    },
    {
      "epoch": 17.954216867469878,
      "grad_norm": 0.00014664097398053855,
      "learning_rate": 2.0457831325301204e-06,
      "loss": 0.013,
      "step": 149020
    },
    {
      "epoch": 17.955421686746988,
      "grad_norm": 1.2114160060882568,
      "learning_rate": 2.0445783132530124e-06,
      "loss": 0.0077,
      "step": 149030
    },
    {
      "epoch": 17.956626506024097,
      "grad_norm": 0.0009123620111495256,
      "learning_rate": 2.0433734939759036e-06,
      "loss": 0.0022,
      "step": 149040
    },
    {
      "epoch": 17.957831325301203,
      "grad_norm": 0.0008774264133535326,
      "learning_rate": 2.042168674698795e-06,
      "loss": 0.0165,
      "step": 149050
    },
    {
      "epoch": 17.959036144578313,
      "grad_norm": 0.0025636041536927223,
      "learning_rate": 2.0409638554216868e-06,
      "loss": 0.0136,
      "step": 149060
    },
    {
      "epoch": 17.960240963855423,
      "grad_norm": 0.0001766535424394533,
      "learning_rate": 2.0397590361445784e-06,
      "loss": 0.0142,
      "step": 149070
    },
    {
      "epoch": 17.96144578313253,
      "grad_norm": 0.42943939566612244,
      "learning_rate": 2.0385542168674704e-06,
      "loss": 0.0059,
      "step": 149080
    },
    {
      "epoch": 17.96265060240964,
      "grad_norm": 0.00014283214113675058,
      "learning_rate": 2.0373493975903615e-06,
      "loss": 0.0342,
      "step": 149090
    },
    {
      "epoch": 17.96385542168675,
      "grad_norm": 0.00011693996202666312,
      "learning_rate": 2.036144578313253e-06,
      "loss": 0.0039,
      "step": 149100
    },
    {
      "epoch": 17.965060240963854,
      "grad_norm": 0.5438222289085388,
      "learning_rate": 2.0349397590361447e-06,
      "loss": 0.0175,
      "step": 149110
    },
    {
      "epoch": 17.966265060240964,
      "grad_norm": 1.2003830671310425,
      "learning_rate": 2.0337349397590363e-06,
      "loss": 0.0091,
      "step": 149120
    },
    {
      "epoch": 17.967469879518074,
      "grad_norm": 9.813028736971319e-05,
      "learning_rate": 2.032530120481928e-06,
      "loss": 0.0071,
      "step": 149130
    },
    {
      "epoch": 17.96867469879518,
      "grad_norm": 9.223943925462663e-05,
      "learning_rate": 2.0313253012048195e-06,
      "loss": 0.0097,
      "step": 149140
    },
    {
      "epoch": 17.96987951807229,
      "grad_norm": 0.2767471373081207,
      "learning_rate": 2.030120481927711e-06,
      "loss": 0.0317,
      "step": 149150
    },
    {
      "epoch": 17.971084337349396,
      "grad_norm": 0.013973388820886612,
      "learning_rate": 2.0289156626506026e-06,
      "loss": 0.0107,
      "step": 149160
    },
    {
      "epoch": 17.972289156626506,
      "grad_norm": 0.2573203444480896,
      "learning_rate": 2.0277108433734942e-06,
      "loss": 0.0284,
      "step": 149170
    },
    {
      "epoch": 17.973493975903615,
      "grad_norm": 0.0002355978504056111,
      "learning_rate": 2.026506024096386e-06,
      "loss": 0.0057,
      "step": 149180
    },
    {
      "epoch": 17.97469879518072,
      "grad_norm": 0.2823558747768402,
      "learning_rate": 2.025301204819277e-06,
      "loss": 0.0126,
      "step": 149190
    },
    {
      "epoch": 17.97590361445783,
      "grad_norm": 0.509432852268219,
      "learning_rate": 2.024096385542169e-06,
      "loss": 0.0094,
      "step": 149200
    },
    {
      "epoch": 17.97710843373494,
      "grad_norm": 0.0003905077464878559,
      "learning_rate": 2.02289156626506e-06,
      "loss": 0.0107,
      "step": 149210
    },
    {
      "epoch": 17.978313253012047,
      "grad_norm": 0.0007589738816022873,
      "learning_rate": 2.021686746987952e-06,
      "loss": 0.0155,
      "step": 149220
    },
    {
      "epoch": 17.979518072289157,
      "grad_norm": 0.002665901090949774,
      "learning_rate": 2.0204819277108438e-06,
      "loss": 0.0116,
      "step": 149230
    },
    {
      "epoch": 17.980722891566266,
      "grad_norm": 0.1602683663368225,
      "learning_rate": 2.019277108433735e-06,
      "loss": 0.0032,
      "step": 149240
    },
    {
      "epoch": 17.981927710843372,
      "grad_norm": 1.2006508111953735,
      "learning_rate": 2.018072289156627e-06,
      "loss": 0.0269,
      "step": 149250
    },
    {
      "epoch": 17.983132530120482,
      "grad_norm": 0.5149548649787903,
      "learning_rate": 2.016867469879518e-06,
      "loss": 0.0067,
      "step": 149260
    },
    {
      "epoch": 17.98433734939759,
      "grad_norm": 0.7239002585411072,
      "learning_rate": 2.0156626506024097e-06,
      "loss": 0.0042,
      "step": 149270
    },
    {
      "epoch": 17.985542168674698,
      "grad_norm": 0.9379982352256775,
      "learning_rate": 2.0144578313253013e-06,
      "loss": 0.0125,
      "step": 149280
    },
    {
      "epoch": 17.986746987951808,
      "grad_norm": 0.00022693577921018004,
      "learning_rate": 2.013253012048193e-06,
      "loss": 0.0112,
      "step": 149290
    },
    {
      "epoch": 17.987951807228917,
      "grad_norm": 2.134451150894165,
      "learning_rate": 2.0120481927710845e-06,
      "loss": 0.0232,
      "step": 149300
    },
    {
      "epoch": 17.989156626506023,
      "grad_norm": 0.9878875613212585,
      "learning_rate": 2.010843373493976e-06,
      "loss": 0.0189,
      "step": 149310
    },
    {
      "epoch": 17.990361445783133,
      "grad_norm": 0.0002180008596042171,
      "learning_rate": 2.0096385542168676e-06,
      "loss": 0.0117,
      "step": 149320
    },
    {
      "epoch": 17.99156626506024,
      "grad_norm": 0.20160025358200073,
      "learning_rate": 2.0084337349397592e-06,
      "loss": 0.0036,
      "step": 149330
    },
    {
      "epoch": 17.99277108433735,
      "grad_norm": 1.1425557136535645,
      "learning_rate": 2.007228915662651e-06,
      "loss": 0.0083,
      "step": 149340
    },
    {
      "epoch": 17.99397590361446,
      "grad_norm": 0.0001859227049862966,
      "learning_rate": 2.0060240963855424e-06,
      "loss": 0.0043,
      "step": 149350
    },
    {
      "epoch": 17.995180722891565,
      "grad_norm": 0.892852783203125,
      "learning_rate": 2.004819277108434e-06,
      "loss": 0.0215,
      "step": 149360
    },
    {
      "epoch": 17.996385542168674,
      "grad_norm": 0.00011764542432501912,
      "learning_rate": 2.0036144578313256e-06,
      "loss": 0.0077,
      "step": 149370
    },
    {
      "epoch": 17.997590361445784,
      "grad_norm": 2.401167392730713,
      "learning_rate": 2.002409638554217e-06,
      "loss": 0.0188,
      "step": 149380
    },
    {
      "epoch": 17.99879518072289,
      "grad_norm": 0.00012908465578220785,
      "learning_rate": 2.0012048192771087e-06,
      "loss": 0.0009,
      "step": 149390
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.00011075501242885366,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0212,
      "step": 149400
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.9875562429696289,
      "eval_f1": 0.9669220706410017,
      "eval_loss": 0.059611380100250244,
      "eval_precision": 0.9747550866616428,
      "eval_recall": 0.9592139414163886,
      "eval_runtime": 3367.6702,
      "eval_samples_per_second": 12.676,
      "eval_steps_per_second": 0.528,
      "step": 149400
    },
    {
      "epoch": 18.00120481927711,
      "grad_norm": 0.00027860383852384984,
      "learning_rate": 1.9987951807228915e-06,
      "loss": 0.0112,
      "step": 149410
    },
    {
      "epoch": 18.002409638554216,
      "grad_norm": 0.0003372292558196932,
      "learning_rate": 1.9975903614457835e-06,
      "loss": 0.0112,
      "step": 149420
    },
    {
      "epoch": 18.003614457831326,
      "grad_norm": 0.00010781449236674234,
      "learning_rate": 1.9963855421686747e-06,
      "loss": 0.0039,
      "step": 149430
    },
    {
      "epoch": 18.004819277108435,
      "grad_norm": 0.9308754801750183,
      "learning_rate": 1.9951807228915667e-06,
      "loss": 0.015,
      "step": 149440
    },
    {
      "epoch": 18.00602409638554,
      "grad_norm": 1.9282796382904053,
      "learning_rate": 1.993975903614458e-06,
      "loss": 0.0095,
      "step": 149450
    },
    {
      "epoch": 18.00722891566265,
      "grad_norm": 0.5987947583198547,
      "learning_rate": 1.9927710843373494e-06,
      "loss": 0.0191,
      "step": 149460
    },
    {
      "epoch": 18.00843373493976,
      "grad_norm": 0.00013297490659169853,
      "learning_rate": 1.991566265060241e-06,
      "loss": 0.0174,
      "step": 149470
    },
    {
      "epoch": 18.009638554216867,
      "grad_norm": 8.109446935122833e-05,
      "learning_rate": 1.9903614457831326e-06,
      "loss": 0.0149,
      "step": 149480
    },
    {
      "epoch": 18.010843373493977,
      "grad_norm": 0.0010255040833726525,
      "learning_rate": 1.989156626506024e-06,
      "loss": 0.004,
      "step": 149490
    },
    {
      "epoch": 18.012048192771083,
      "grad_norm": 0.0001324448239756748,
      "learning_rate": 1.987951807228916e-06,
      "loss": 0.0005,
      "step": 149500
    },
    {
      "epoch": 18.013253012048192,
      "grad_norm": 0.4650834798812866,
      "learning_rate": 1.9867469879518074e-06,
      "loss": 0.016,
      "step": 149510
    },
    {
      "epoch": 18.014457831325302,
      "grad_norm": 0.00013747306365985423,
      "learning_rate": 1.985542168674699e-06,
      "loss": 0.0131,
      "step": 149520
    },
    {
      "epoch": 18.01566265060241,
      "grad_norm": 0.33093637228012085,
      "learning_rate": 1.9843373493975906e-06,
      "loss": 0.0013,
      "step": 149530
    },
    {
      "epoch": 18.016867469879518,
      "grad_norm": 8.83155080373399e-05,
      "learning_rate": 1.983132530120482e-06,
      "loss": 0.013,
      "step": 149540
    },
    {
      "epoch": 18.018072289156628,
      "grad_norm": 0.00018201532657258213,
      "learning_rate": 1.9819277108433737e-06,
      "loss": 0.0098,
      "step": 149550
    },
    {
      "epoch": 18.019277108433734,
      "grad_norm": 0.0005598851130343974,
      "learning_rate": 1.9807228915662653e-06,
      "loss": 0.0106,
      "step": 149560
    },
    {
      "epoch": 18.020481927710843,
      "grad_norm": 0.0020392953883856535,
      "learning_rate": 1.979518072289157e-06,
      "loss": 0.0101,
      "step": 149570
    },
    {
      "epoch": 18.021686746987953,
      "grad_norm": 0.00020530498295556754,
      "learning_rate": 1.9783132530120485e-06,
      "loss": 0.0186,
      "step": 149580
    },
    {
      "epoch": 18.02289156626506,
      "grad_norm": 0.00022159784566611052,
      "learning_rate": 1.97710843373494e-06,
      "loss": 0.0168,
      "step": 149590
    },
    {
      "epoch": 18.02409638554217,
      "grad_norm": 0.002248126547783613,
      "learning_rate": 1.9759036144578312e-06,
      "loss": 0.0006,
      "step": 149600
    },
    {
      "epoch": 18.02530120481928,
      "grad_norm": 0.010766101069748402,
      "learning_rate": 1.9746987951807233e-06,
      "loss": 0.0032,
      "step": 149610
    },
    {
      "epoch": 18.026506024096385,
      "grad_norm": 0.00013709418999496847,
      "learning_rate": 1.9734939759036144e-06,
      "loss": 0.0208,
      "step": 149620
    },
    {
      "epoch": 18.027710843373494,
      "grad_norm": 0.24769669771194458,
      "learning_rate": 1.972289156626506e-06,
      "loss": 0.0082,
      "step": 149630
    },
    {
      "epoch": 18.0289156626506,
      "grad_norm": 0.2019823044538498,
      "learning_rate": 1.9710843373493976e-06,
      "loss": 0.0161,
      "step": 149640
    },
    {
      "epoch": 18.03012048192771,
      "grad_norm": 9.614507871447131e-05,
      "learning_rate": 1.969879518072289e-06,
      "loss": 0.0057,
      "step": 149650
    },
    {
      "epoch": 18.03132530120482,
      "grad_norm": 0.9272170662879944,
      "learning_rate": 1.9686746987951808e-06,
      "loss": 0.0259,
      "step": 149660
    },
    {
      "epoch": 18.032530120481926,
      "grad_norm": 0.00010745021427283064,
      "learning_rate": 1.9674698795180724e-06,
      "loss": 0.0073,
      "step": 149670
    },
    {
      "epoch": 18.033734939759036,
      "grad_norm": 9.43583290791139e-05,
      "learning_rate": 1.966265060240964e-06,
      "loss": 0.0067,
      "step": 149680
    },
    {
      "epoch": 18.034939759036146,
      "grad_norm": 1.0593055486679077,
      "learning_rate": 1.9650602409638555e-06,
      "loss": 0.0093,
      "step": 149690
    },
    {
      "epoch": 18.03614457831325,
      "grad_norm": 8.568195335101336e-05,
      "learning_rate": 1.963855421686747e-06,
      "loss": 0.0047,
      "step": 149700
    },
    {
      "epoch": 18.03734939759036,
      "grad_norm": 0.00015361560508608818,
      "learning_rate": 1.9626506024096387e-06,
      "loss": 0.022,
      "step": 149710
    },
    {
      "epoch": 18.03855421686747,
      "grad_norm": 0.17096799612045288,
      "learning_rate": 1.9614457831325303e-06,
      "loss": 0.0043,
      "step": 149720
    },
    {
      "epoch": 18.039759036144577,
      "grad_norm": 0.0009764294954948127,
      "learning_rate": 1.960240963855422e-06,
      "loss": 0.0074,
      "step": 149730
    },
    {
      "epoch": 18.040963855421687,
      "grad_norm": 7.316338451346382e-05,
      "learning_rate": 1.9590361445783135e-06,
      "loss": 0.017,
      "step": 149740
    },
    {
      "epoch": 18.042168674698797,
      "grad_norm": 0.00025937697500921786,
      "learning_rate": 1.957831325301205e-06,
      "loss": 0.0,
      "step": 149750
    },
    {
      "epoch": 18.043373493975903,
      "grad_norm": 0.00018756034842226654,
      "learning_rate": 1.9566265060240967e-06,
      "loss": 0.0112,
      "step": 149760
    },
    {
      "epoch": 18.044578313253012,
      "grad_norm": 8.246073412010446e-05,
      "learning_rate": 1.955421686746988e-06,
      "loss": 0.0104,
      "step": 149770
    },
    {
      "epoch": 18.045783132530122,
      "grad_norm": 0.8805711269378662,
      "learning_rate": 1.95421686746988e-06,
      "loss": 0.0097,
      "step": 149780
    },
    {
      "epoch": 18.04698795180723,
      "grad_norm": 0.00015862626605667174,
      "learning_rate": 1.953012048192771e-06,
      "loss": 0.0385,
      "step": 149790
    },
    {
      "epoch": 18.048192771084338,
      "grad_norm": 0.0013725197641178966,
      "learning_rate": 1.951807228915663e-06,
      "loss": 0.0032,
      "step": 149800
    },
    {
      "epoch": 18.049397590361444,
      "grad_norm": 0.0001210004702443257,
      "learning_rate": 1.950602409638554e-06,
      "loss": 0.0197,
      "step": 149810
    },
    {
      "epoch": 18.050602409638554,
      "grad_norm": 0.00015812920173630118,
      "learning_rate": 1.9493975903614458e-06,
      "loss": 0.0162,
      "step": 149820
    },
    {
      "epoch": 18.051807228915663,
      "grad_norm": 0.733881950378418,
      "learning_rate": 1.9481927710843378e-06,
      "loss": 0.0197,
      "step": 149830
    },
    {
      "epoch": 18.05301204819277,
      "grad_norm": 0.001065195887349546,
      "learning_rate": 1.946987951807229e-06,
      "loss": 0.0346,
      "step": 149840
    },
    {
      "epoch": 18.05421686746988,
      "grad_norm": 0.9115058183670044,
      "learning_rate": 1.945783132530121e-06,
      "loss": 0.0093,
      "step": 149850
    },
    {
      "epoch": 18.05542168674699,
      "grad_norm": 0.3691490888595581,
      "learning_rate": 1.944578313253012e-06,
      "loss": 0.0044,
      "step": 149860
    },
    {
      "epoch": 18.056626506024095,
      "grad_norm": 0.0018555802525952458,
      "learning_rate": 1.9433734939759037e-06,
      "loss": 0.0015,
      "step": 149870
    },
    {
      "epoch": 18.057831325301205,
      "grad_norm": 0.0001792830298654735,
      "learning_rate": 1.9421686746987953e-06,
      "loss": 0.0068,
      "step": 149880
    },
    {
      "epoch": 18.059036144578315,
      "grad_norm": 0.00020110217155888677,
      "learning_rate": 1.940963855421687e-06,
      "loss": 0.0097,
      "step": 149890
    },
    {
      "epoch": 18.06024096385542,
      "grad_norm": 0.00013678376853931695,
      "learning_rate": 1.9397590361445785e-06,
      "loss": 0.0018,
      "step": 149900
    },
    {
      "epoch": 18.06144578313253,
      "grad_norm": 0.001987612806260586,
      "learning_rate": 1.93855421686747e-06,
      "loss": 0.022,
      "step": 149910
    },
    {
      "epoch": 18.06265060240964,
      "grad_norm": 0.00012039612920489162,
      "learning_rate": 1.9373493975903616e-06,
      "loss": 0.0053,
      "step": 149920
    },
    {
      "epoch": 18.063855421686746,
      "grad_norm": 1.9973376989364624,
      "learning_rate": 1.9361445783132532e-06,
      "loss": 0.0197,
      "step": 149930
    },
    {
      "epoch": 18.065060240963856,
      "grad_norm": 1.6890937089920044,
      "learning_rate": 1.934939759036145e-06,
      "loss": 0.015,
      "step": 149940
    },
    {
      "epoch": 18.066265060240966,
      "grad_norm": 0.00020234395924489945,
      "learning_rate": 1.9337349397590364e-06,
      "loss": 0.0136,
      "step": 149950
    },
    {
      "epoch": 18.06746987951807,
      "grad_norm": 0.22611424326896667,
      "learning_rate": 1.932530120481928e-06,
      "loss": 0.0091,
      "step": 149960
    },
    {
      "epoch": 18.06867469879518,
      "grad_norm": 0.00017560651758685708,
      "learning_rate": 1.9313253012048196e-06,
      "loss": 0.0108,
      "step": 149970
    },
    {
      "epoch": 18.069879518072288,
      "grad_norm": 0.0012454139068722725,
      "learning_rate": 1.930120481927711e-06,
      "loss": 0.0172,
      "step": 149980
    },
    {
      "epoch": 18.071084337349397,
      "grad_norm": 1.8485523462295532,
      "learning_rate": 1.9289156626506023e-06,
      "loss": 0.0139,
      "step": 149990
    },
    {
      "epoch": 18.072289156626507,
      "grad_norm": 0.00023451016750186682,
      "learning_rate": 1.9277108433734943e-06,
      "loss": 0.0114,
      "step": 150000
    },
    {
      "epoch": 18.073493975903613,
      "grad_norm": 2.2452306747436523,
      "learning_rate": 1.9265060240963855e-06,
      "loss": 0.0163,
      "step": 150010
    },
    {
      "epoch": 18.074698795180723,
      "grad_norm": 0.18318507075309753,
      "learning_rate": 1.9253012048192775e-06,
      "loss": 0.016,
      "step": 150020
    },
    {
      "epoch": 18.075903614457832,
      "grad_norm": 0.0004547310818452388,
      "learning_rate": 1.9240963855421687e-06,
      "loss": 0.0075,
      "step": 150030
    },
    {
      "epoch": 18.07710843373494,
      "grad_norm": 1.608525276184082,
      "learning_rate": 1.9228915662650603e-06,
      "loss": 0.0205,
      "step": 150040
    },
    {
      "epoch": 18.07831325301205,
      "grad_norm": 0.0001925763499457389,
      "learning_rate": 1.921686746987952e-06,
      "loss": 0.0121,
      "step": 150050
    },
    {
      "epoch": 18.079518072289158,
      "grad_norm": 0.00012476459960453212,
      "learning_rate": 1.9204819277108434e-06,
      "loss": 0.0121,
      "step": 150060
    },
    {
      "epoch": 18.080722891566264,
      "grad_norm": 0.00014550265041179955,
      "learning_rate": 1.919277108433735e-06,
      "loss": 0.0338,
      "step": 150070
    },
    {
      "epoch": 18.081927710843374,
      "grad_norm": 0.0019438202725723386,
      "learning_rate": 1.9180722891566266e-06,
      "loss": 0.0045,
      "step": 150080
    },
    {
      "epoch": 18.083132530120483,
      "grad_norm": 0.8114011883735657,
      "learning_rate": 1.916867469879518e-06,
      "loss": 0.0056,
      "step": 150090
    },
    {
      "epoch": 18.08433734939759,
      "grad_norm": 0.00012829017941839993,
      "learning_rate": 1.91566265060241e-06,
      "loss": 0.0011,
      "step": 150100
    },
    {
      "epoch": 18.0855421686747,
      "grad_norm": 0.00017848992138169706,
      "learning_rate": 1.9144578313253014e-06,
      "loss": 0.0144,
      "step": 150110
    },
    {
      "epoch": 18.086746987951805,
      "grad_norm": 0.0011843352112919092,
      "learning_rate": 1.913253012048193e-06,
      "loss": 0.0032,
      "step": 150120
    },
    {
      "epoch": 18.087951807228915,
      "grad_norm": 1.0744540691375732,
      "learning_rate": 1.9120481927710846e-06,
      "loss": 0.0062,
      "step": 150130
    },
    {
      "epoch": 18.089156626506025,
      "grad_norm": 0.00010027200187323615,
      "learning_rate": 1.910843373493976e-06,
      "loss": 0.006,
      "step": 150140
    },
    {
      "epoch": 18.09036144578313,
      "grad_norm": 0.00016089384735096246,
      "learning_rate": 1.9096385542168677e-06,
      "loss": 0.0021,
      "step": 150150
    },
    {
      "epoch": 18.09156626506024,
      "grad_norm": 0.00014165215543471277,
      "learning_rate": 1.9084337349397593e-06,
      "loss": 0.0013,
      "step": 150160
    },
    {
      "epoch": 18.09277108433735,
      "grad_norm": 0.0006826598546467721,
      "learning_rate": 1.907228915662651e-06,
      "loss": 0.0354,
      "step": 150170
    },
    {
      "epoch": 18.093975903614457,
      "grad_norm": 0.00020882526587229222,
      "learning_rate": 1.9060240963855423e-06,
      "loss": 0.0091,
      "step": 150180
    },
    {
      "epoch": 18.095180722891566,
      "grad_norm": 0.25416725873947144,
      "learning_rate": 1.9048192771084339e-06,
      "loss": 0.0015,
      "step": 150190
    },
    {
      "epoch": 18.096385542168676,
      "grad_norm": 0.0005574426613748074,
      "learning_rate": 1.9036144578313255e-06,
      "loss": 0.0031,
      "step": 150200
    },
    {
      "epoch": 18.097590361445782,
      "grad_norm": 0.9456056952476501,
      "learning_rate": 1.902409638554217e-06,
      "loss": 0.0106,
      "step": 150210
    },
    {
      "epoch": 18.09879518072289,
      "grad_norm": 2.2362706661224365,
      "learning_rate": 1.9012048192771084e-06,
      "loss": 0.0329,
      "step": 150220
    },
    {
      "epoch": 18.1,
      "grad_norm": 0.0001308202772634104,
      "learning_rate": 1.9000000000000002e-06,
      "loss": 0.0111,
      "step": 150230
    },
    {
      "epoch": 18.101204819277108,
      "grad_norm": 0.00010329623910365626,
      "learning_rate": 1.8987951807228916e-06,
      "loss": 0.0036,
      "step": 150240
    },
    {
      "epoch": 18.102409638554217,
      "grad_norm": 0.25664693117141724,
      "learning_rate": 1.8975903614457832e-06,
      "loss": 0.0241,
      "step": 150250
    },
    {
      "epoch": 18.103614457831327,
      "grad_norm": 0.00014058861415833235,
      "learning_rate": 1.896385542168675e-06,
      "loss": 0.0005,
      "step": 150260
    },
    {
      "epoch": 18.104819277108433,
      "grad_norm": 0.01141158677637577,
      "learning_rate": 1.8951807228915664e-06,
      "loss": 0.0176,
      "step": 150270
    },
    {
      "epoch": 18.106024096385543,
      "grad_norm": 0.00010599206871120259,
      "learning_rate": 1.8939759036144582e-06,
      "loss": 0.0039,
      "step": 150280
    },
    {
      "epoch": 18.10722891566265,
      "grad_norm": 0.9214254021644592,
      "learning_rate": 1.8927710843373495e-06,
      "loss": 0.0146,
      "step": 150290
    },
    {
      "epoch": 18.10843373493976,
      "grad_norm": 0.9068105816841125,
      "learning_rate": 1.8915662650602411e-06,
      "loss": 0.0072,
      "step": 150300
    },
    {
      "epoch": 18.10963855421687,
      "grad_norm": 0.0001224139705300331,
      "learning_rate": 1.8903614457831327e-06,
      "loss": 0.0055,
      "step": 150310
    },
    {
      "epoch": 18.110843373493974,
      "grad_norm": 1.1864560842514038,
      "learning_rate": 1.8891566265060243e-06,
      "loss": 0.0174,
      "step": 150320
    },
    {
      "epoch": 18.112048192771084,
      "grad_norm": 0.00038762824260629714,
      "learning_rate": 1.8879518072289157e-06,
      "loss": 0.0076,
      "step": 150330
    },
    {
      "epoch": 18.113253012048194,
      "grad_norm": 0.003240375779569149,
      "learning_rate": 1.8867469879518075e-06,
      "loss": 0.0183,
      "step": 150340
    },
    {
      "epoch": 18.1144578313253,
      "grad_norm": 0.13308057188987732,
      "learning_rate": 1.8855421686746989e-06,
      "loss": 0.0064,
      "step": 150350
    },
    {
      "epoch": 18.11566265060241,
      "grad_norm": 0.00012557368609122932,
      "learning_rate": 1.8843373493975905e-06,
      "loss": 0.0012,
      "step": 150360
    },
    {
      "epoch": 18.11686746987952,
      "grad_norm": 0.00038704078178852797,
      "learning_rate": 1.883132530120482e-06,
      "loss": 0.0268,
      "step": 150370
    },
    {
      "epoch": 18.118072289156625,
      "grad_norm": 0.3349238336086273,
      "learning_rate": 1.8819277108433736e-06,
      "loss": 0.011,
      "step": 150380
    },
    {
      "epoch": 18.119277108433735,
      "grad_norm": 0.0001117563879233785,
      "learning_rate": 1.880722891566265e-06,
      "loss": 0.0091,
      "step": 150390
    },
    {
      "epoch": 18.120481927710845,
      "grad_norm": 0.015342708677053452,
      "learning_rate": 1.8795180722891568e-06,
      "loss": 0.0106,
      "step": 150400
    },
    {
      "epoch": 18.12168674698795,
      "grad_norm": 0.9016534686088562,
      "learning_rate": 1.8783132530120484e-06,
      "loss": 0.0136,
      "step": 150410
    },
    {
      "epoch": 18.12289156626506,
      "grad_norm": 0.0001120919332606718,
      "learning_rate": 1.87710843373494e-06,
      "loss": 0.0157,
      "step": 150420
    },
    {
      "epoch": 18.12409638554217,
      "grad_norm": 9.783747373148799e-05,
      "learning_rate": 1.8759036144578316e-06,
      "loss": 0.0199,
      "step": 150430
    },
    {
      "epoch": 18.125301204819277,
      "grad_norm": 0.00010748305066954345,
      "learning_rate": 1.874698795180723e-06,
      "loss": 0.0247,
      "step": 150440
    },
    {
      "epoch": 18.126506024096386,
      "grad_norm": 0.8803602457046509,
      "learning_rate": 1.8734939759036147e-06,
      "loss": 0.0262,
      "step": 150450
    },
    {
      "epoch": 18.127710843373492,
      "grad_norm": 0.9870581030845642,
      "learning_rate": 1.8722891566265061e-06,
      "loss": 0.0222,
      "step": 150460
    },
    {
      "epoch": 18.128915662650602,
      "grad_norm": 0.3875836133956909,
      "learning_rate": 1.871084337349398e-06,
      "loss": 0.0171,
      "step": 150470
    },
    {
      "epoch": 18.13012048192771,
      "grad_norm": 0.0010184774873778224,
      "learning_rate": 1.8698795180722893e-06,
      "loss": 0.0057,
      "step": 150480
    },
    {
      "epoch": 18.131325301204818,
      "grad_norm": 0.00012926103954669088,
      "learning_rate": 1.8686746987951809e-06,
      "loss": 0.0275,
      "step": 150490
    },
    {
      "epoch": 18.132530120481928,
      "grad_norm": 0.00011314414587104693,
      "learning_rate": 1.8674698795180723e-06,
      "loss": 0.0028,
      "step": 150500
    },
    {
      "epoch": 18.133734939759037,
      "grad_norm": 0.00023097440134733915,
      "learning_rate": 1.866265060240964e-06,
      "loss": 0.0148,
      "step": 150510
    },
    {
      "epoch": 18.134939759036143,
      "grad_norm": 1.051312804222107,
      "learning_rate": 1.8650602409638554e-06,
      "loss": 0.0076,
      "step": 150520
    },
    {
      "epoch": 18.136144578313253,
      "grad_norm": 0.0001701631845207885,
      "learning_rate": 1.8638554216867472e-06,
      "loss": 0.0141,
      "step": 150530
    },
    {
      "epoch": 18.137349397590363,
      "grad_norm": 0.7413403391838074,
      "learning_rate": 1.8626506024096386e-06,
      "loss": 0.0023,
      "step": 150540
    },
    {
      "epoch": 18.13855421686747,
      "grad_norm": 0.0010925419628620148,
      "learning_rate": 1.8614457831325302e-06,
      "loss": 0.0302,
      "step": 150550
    },
    {
      "epoch": 18.13975903614458,
      "grad_norm": 0.00028237231890670955,
      "learning_rate": 1.860240963855422e-06,
      "loss": 0.0236,
      "step": 150560
    },
    {
      "epoch": 18.14096385542169,
      "grad_norm": 0.00013459156616590917,
      "learning_rate": 1.8590361445783134e-06,
      "loss": 0.0108,
      "step": 150570
    },
    {
      "epoch": 18.142168674698794,
      "grad_norm": 0.8310608267784119,
      "learning_rate": 1.8578313253012052e-06,
      "loss": 0.0052,
      "step": 150580
    },
    {
      "epoch": 18.143373493975904,
      "grad_norm": 0.002699183067306876,
      "learning_rate": 1.8566265060240966e-06,
      "loss": 0.0089,
      "step": 150590
    },
    {
      "epoch": 18.14457831325301,
      "grad_norm": 0.00020002776000183076,
      "learning_rate": 1.8554216867469881e-06,
      "loss": 0.0028,
      "step": 150600
    },
    {
      "epoch": 18.14578313253012,
      "grad_norm": 0.00016099731146823615,
      "learning_rate": 1.8542168674698795e-06,
      "loss": 0.0152,
      "step": 150610
    },
    {
      "epoch": 18.14698795180723,
      "grad_norm": 0.000111768240458332,
      "learning_rate": 1.8530120481927713e-06,
      "loss": 0.0118,
      "step": 150620
    },
    {
      "epoch": 18.148192771084336,
      "grad_norm": 0.010603537783026695,
      "learning_rate": 1.8518072289156627e-06,
      "loss": 0.0036,
      "step": 150630
    },
    {
      "epoch": 18.149397590361446,
      "grad_norm": 0.00012970983516424894,
      "learning_rate": 1.8506024096385545e-06,
      "loss": 0.0152,
      "step": 150640
    },
    {
      "epoch": 18.150602409638555,
      "grad_norm": 0.0001517980854259804,
      "learning_rate": 1.8493975903614459e-06,
      "loss": 0.0082,
      "step": 150650
    },
    {
      "epoch": 18.15180722891566,
      "grad_norm": 0.003671280574053526,
      "learning_rate": 1.8481927710843375e-06,
      "loss": 0.0092,
      "step": 150660
    },
    {
      "epoch": 18.15301204819277,
      "grad_norm": 0.00016136268095578998,
      "learning_rate": 1.846987951807229e-06,
      "loss": 0.0074,
      "step": 150670
    },
    {
      "epoch": 18.15421686746988,
      "grad_norm": 0.00012668124691117555,
      "learning_rate": 1.8457831325301206e-06,
      "loss": 0.008,
      "step": 150680
    },
    {
      "epoch": 18.155421686746987,
      "grad_norm": 0.0014504817081615329,
      "learning_rate": 1.844578313253012e-06,
      "loss": 0.0077,
      "step": 150690
    },
    {
      "epoch": 18.156626506024097,
      "grad_norm": 1.0407203435897827,
      "learning_rate": 1.8433734939759038e-06,
      "loss": 0.0041,
      "step": 150700
    },
    {
      "epoch": 18.157831325301206,
      "grad_norm": 8.293290011351928e-05,
      "learning_rate": 1.8421686746987954e-06,
      "loss": 0.0,
      "step": 150710
    },
    {
      "epoch": 18.159036144578312,
      "grad_norm": 0.00015399786934722215,
      "learning_rate": 1.8409638554216868e-06,
      "loss": 0.0244,
      "step": 150720
    },
    {
      "epoch": 18.160240963855422,
      "grad_norm": 0.0006385682499967515,
      "learning_rate": 1.8397590361445786e-06,
      "loss": 0.0,
      "step": 150730
    },
    {
      "epoch": 18.16144578313253,
      "grad_norm": 0.0001105998526327312,
      "learning_rate": 1.83855421686747e-06,
      "loss": 0.0126,
      "step": 150740
    },
    {
      "epoch": 18.162650602409638,
      "grad_norm": 0.022626500576734543,
      "learning_rate": 1.8373493975903617e-06,
      "loss": 0.0162,
      "step": 150750
    },
    {
      "epoch": 18.163855421686748,
      "grad_norm": 0.0010738716227933764,
      "learning_rate": 1.8361445783132531e-06,
      "loss": 0.0235,
      "step": 150760
    },
    {
      "epoch": 18.165060240963854,
      "grad_norm": 0.6082189083099365,
      "learning_rate": 1.8349397590361447e-06,
      "loss": 0.0122,
      "step": 150770
    },
    {
      "epoch": 18.166265060240963,
      "grad_norm": 0.00019551190780475736,
      "learning_rate": 1.8337349397590363e-06,
      "loss": 0.0122,
      "step": 150780
    },
    {
      "epoch": 18.167469879518073,
      "grad_norm": 0.04271301254630089,
      "learning_rate": 1.8325301204819279e-06,
      "loss": 0.03,
      "step": 150790
    },
    {
      "epoch": 18.16867469879518,
      "grad_norm": 0.0001589297316968441,
      "learning_rate": 1.8313253012048193e-06,
      "loss": 0.0063,
      "step": 150800
    },
    {
      "epoch": 18.16987951807229,
      "grad_norm": 0.8475286960601807,
      "learning_rate": 1.830120481927711e-06,
      "loss": 0.0114,
      "step": 150810
    },
    {
      "epoch": 18.1710843373494,
      "grad_norm": 0.7205018997192383,
      "learning_rate": 1.8289156626506024e-06,
      "loss": 0.0031,
      "step": 150820
    },
    {
      "epoch": 18.172289156626505,
      "grad_norm": 0.00013215509534347802,
      "learning_rate": 1.8277108433734942e-06,
      "loss": 0.0138,
      "step": 150830
    },
    {
      "epoch": 18.173493975903614,
      "grad_norm": 0.8062853217124939,
      "learning_rate": 1.8265060240963856e-06,
      "loss": 0.0101,
      "step": 150840
    },
    {
      "epoch": 18.174698795180724,
      "grad_norm": 0.7690280675888062,
      "learning_rate": 1.8253012048192772e-06,
      "loss": 0.0071,
      "step": 150850
    },
    {
      "epoch": 18.17590361445783,
      "grad_norm": 0.00019990757573395967,
      "learning_rate": 1.824096385542169e-06,
      "loss": 0.0039,
      "step": 150860
    },
    {
      "epoch": 18.17710843373494,
      "grad_norm": 8.151624206220731e-05,
      "learning_rate": 1.8228915662650604e-06,
      "loss": 0.0,
      "step": 150870
    },
    {
      "epoch": 18.17831325301205,
      "grad_norm": 7.345911581069231e-05,
      "learning_rate": 1.821686746987952e-06,
      "loss": 0.0152,
      "step": 150880
    },
    {
      "epoch": 18.179518072289156,
      "grad_norm": 0.0011905697174370289,
      "learning_rate": 1.8204819277108436e-06,
      "loss": 0.0068,
      "step": 150890
    },
    {
      "epoch": 18.180722891566266,
      "grad_norm": 0.34250593185424805,
      "learning_rate": 1.8192771084337351e-06,
      "loss": 0.0092,
      "step": 150900
    },
    {
      "epoch": 18.181927710843375,
      "grad_norm": 0.00025841870228759944,
      "learning_rate": 1.8180722891566265e-06,
      "loss": 0.0,
      "step": 150910
    },
    {
      "epoch": 18.18313253012048,
      "grad_norm": 0.9060575366020203,
      "learning_rate": 1.8168674698795183e-06,
      "loss": 0.0096,
      "step": 150920
    },
    {
      "epoch": 18.18433734939759,
      "grad_norm": 0.054888609796762466,
      "learning_rate": 1.8156626506024097e-06,
      "loss": 0.0031,
      "step": 150930
    },
    {
      "epoch": 18.185542168674697,
      "grad_norm": 0.00012380484258756042,
      "learning_rate": 1.8144578313253015e-06,
      "loss": 0.0114,
      "step": 150940
    },
    {
      "epoch": 18.186746987951807,
      "grad_norm": 0.0002252230915473774,
      "learning_rate": 1.8132530120481929e-06,
      "loss": 0.0018,
      "step": 150950
    },
    {
      "epoch": 18.187951807228917,
      "grad_norm": 0.0002867146104108542,
      "learning_rate": 1.8120481927710845e-06,
      "loss": 0.0048,
      "step": 150960
    },
    {
      "epoch": 18.189156626506023,
      "grad_norm": 7.156280480558053e-05,
      "learning_rate": 1.8108433734939758e-06,
      "loss": 0.0055,
      "step": 150970
    },
    {
      "epoch": 18.190361445783132,
      "grad_norm": 0.0016555337933823466,
      "learning_rate": 1.8096385542168676e-06,
      "loss": 0.0167,
      "step": 150980
    },
    {
      "epoch": 18.191566265060242,
      "grad_norm": 0.00011727480159606785,
      "learning_rate": 1.8084337349397592e-06,
      "loss": 0.0034,
      "step": 150990
    },
    {
      "epoch": 18.19277108433735,
      "grad_norm": 0.00018477512639947236,
      "learning_rate": 1.8072289156626508e-06,
      "loss": 0.0056,
      "step": 151000
    },
    {
      "epoch": 18.193975903614458,
      "grad_norm": 0.0002633437979966402,
      "learning_rate": 1.8060240963855424e-06,
      "loss": 0.0011,
      "step": 151010
    },
    {
      "epoch": 18.195180722891568,
      "grad_norm": 1.2059348821640015,
      "learning_rate": 1.8048192771084338e-06,
      "loss": 0.0162,
      "step": 151020
    },
    {
      "epoch": 18.196385542168674,
      "grad_norm": 0.0003794975928030908,
      "learning_rate": 1.8036144578313256e-06,
      "loss": 0.0187,
      "step": 151030
    },
    {
      "epoch": 18.197590361445783,
      "grad_norm": 0.00010799388837767765,
      "learning_rate": 1.802409638554217e-06,
      "loss": 0.0067,
      "step": 151040
    },
    {
      "epoch": 18.198795180722893,
      "grad_norm": 0.12169365584850311,
      "learning_rate": 1.8012048192771088e-06,
      "loss": 0.0122,
      "step": 151050
    },
    {
      "epoch": 18.2,
      "grad_norm": 0.0008085371810011566,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 0.01,
      "step": 151060
    },
    {
      "epoch": 18.20120481927711,
      "grad_norm": 0.0007243588916026056,
      "learning_rate": 1.7987951807228917e-06,
      "loss": 0.0158,
      "step": 151070
    },
    {
      "epoch": 18.202409638554215,
      "grad_norm": 0.00016866404621396214,
      "learning_rate": 1.797590361445783e-06,
      "loss": 0.0114,
      "step": 151080
    },
    {
      "epoch": 18.203614457831325,
      "grad_norm": 0.0001741263986332342,
      "learning_rate": 1.796385542168675e-06,
      "loss": 0.0005,
      "step": 151090
    },
    {
      "epoch": 18.204819277108435,
      "grad_norm": 0.5917275547981262,
      "learning_rate": 1.7951807228915663e-06,
      "loss": 0.0075,
      "step": 151100
    },
    {
      "epoch": 18.20602409638554,
      "grad_norm": 1.7829954624176025,
      "learning_rate": 1.793975903614458e-06,
      "loss": 0.0116,
      "step": 151110
    },
    {
      "epoch": 18.20722891566265,
      "grad_norm": 0.0012382416753098369,
      "learning_rate": 1.7927710843373494e-06,
      "loss": 0.0041,
      "step": 151120
    },
    {
      "epoch": 18.20843373493976,
      "grad_norm": 0.0004262303118593991,
      "learning_rate": 1.791566265060241e-06,
      "loss": 0.0105,
      "step": 151130
    },
    {
      "epoch": 18.209638554216866,
      "grad_norm": 0.006810890510678291,
      "learning_rate": 1.7903614457831328e-06,
      "loss": 0.0031,
      "step": 151140
    },
    {
      "epoch": 18.210843373493976,
      "grad_norm": 0.00015242300287354738,
      "learning_rate": 1.7891566265060242e-06,
      "loss": 0.0104,
      "step": 151150
    },
    {
      "epoch": 18.212048192771086,
      "grad_norm": 0.8845259547233582,
      "learning_rate": 1.787951807228916e-06,
      "loss": 0.0069,
      "step": 151160
    },
    {
      "epoch": 18.21325301204819,
      "grad_norm": 0.011817583814263344,
      "learning_rate": 1.7867469879518074e-06,
      "loss": 0.0032,
      "step": 151170
    },
    {
      "epoch": 18.2144578313253,
      "grad_norm": 0.00011327346146572381,
      "learning_rate": 1.785542168674699e-06,
      "loss": 0.0049,
      "step": 151180
    },
    {
      "epoch": 18.21566265060241,
      "grad_norm": 0.9828488230705261,
      "learning_rate": 1.7843373493975906e-06,
      "loss": 0.0149,
      "step": 151190
    },
    {
      "epoch": 18.216867469879517,
      "grad_norm": 0.0001408921234542504,
      "learning_rate": 1.7831325301204822e-06,
      "loss": 0.0121,
      "step": 151200
    },
    {
      "epoch": 18.218072289156627,
      "grad_norm": 1.5258771181106567,
      "learning_rate": 1.7819277108433735e-06,
      "loss": 0.0124,
      "step": 151210
    },
    {
      "epoch": 18.219277108433737,
      "grad_norm": 7.945906691020355e-05,
      "learning_rate": 1.7807228915662653e-06,
      "loss": 0.0161,
      "step": 151220
    },
    {
      "epoch": 18.220481927710843,
      "grad_norm": 0.00012428710761014372,
      "learning_rate": 1.7795180722891567e-06,
      "loss": 0.0256,
      "step": 151230
    },
    {
      "epoch": 18.221686746987952,
      "grad_norm": 0.00022043660283088684,
      "learning_rate": 1.7783132530120483e-06,
      "loss": 0.0175,
      "step": 151240
    },
    {
      "epoch": 18.22289156626506,
      "grad_norm": 9.376552770845592e-05,
      "learning_rate": 1.7771084337349399e-06,
      "loss": 0.0154,
      "step": 151250
    },
    {
      "epoch": 18.22409638554217,
      "grad_norm": 1.4649245738983154,
      "learning_rate": 1.7759036144578315e-06,
      "loss": 0.016,
      "step": 151260
    },
    {
      "epoch": 18.225301204819278,
      "grad_norm": 0.3429425060749054,
      "learning_rate": 1.7746987951807228e-06,
      "loss": 0.0107,
      "step": 151270
    },
    {
      "epoch": 18.226506024096384,
      "grad_norm": 0.12360546737909317,
      "learning_rate": 1.7734939759036146e-06,
      "loss": 0.0148,
      "step": 151280
    },
    {
      "epoch": 18.227710843373494,
      "grad_norm": 0.0002429295564070344,
      "learning_rate": 1.7722891566265062e-06,
      "loss": 0.0045,
      "step": 151290
    },
    {
      "epoch": 18.228915662650603,
      "grad_norm": 1.6952084302902222,
      "learning_rate": 1.7710843373493978e-06,
      "loss": 0.0225,
      "step": 151300
    },
    {
      "epoch": 18.23012048192771,
      "grad_norm": 24.50664520263672,
      "learning_rate": 1.7698795180722894e-06,
      "loss": 0.0466,
      "step": 151310
    },
    {
      "epoch": 18.23132530120482,
      "grad_norm": 1.1646838188171387,
      "learning_rate": 1.7686746987951808e-06,
      "loss": 0.0103,
      "step": 151320
    },
    {
      "epoch": 18.23253012048193,
      "grad_norm": 0.7599397897720337,
      "learning_rate": 1.7674698795180726e-06,
      "loss": 0.0366,
      "step": 151330
    },
    {
      "epoch": 18.233734939759035,
      "grad_norm": 0.00013974789180792868,
      "learning_rate": 1.766265060240964e-06,
      "loss": 0.0228,
      "step": 151340
    },
    {
      "epoch": 18.234939759036145,
      "grad_norm": 0.0003249404253438115,
      "learning_rate": 1.7650602409638555e-06,
      "loss": 0.0033,
      "step": 151350
    },
    {
      "epoch": 18.236144578313255,
      "grad_norm": 9.95081354631111e-05,
      "learning_rate": 1.7638554216867471e-06,
      "loss": 0.0119,
      "step": 151360
    },
    {
      "epoch": 18.23734939759036,
      "grad_norm": 0.9063446521759033,
      "learning_rate": 1.7626506024096387e-06,
      "loss": 0.0042,
      "step": 151370
    },
    {
      "epoch": 18.23855421686747,
      "grad_norm": 0.2727414071559906,
      "learning_rate": 1.76144578313253e-06,
      "loss": 0.0105,
      "step": 151380
    },
    {
      "epoch": 18.23975903614458,
      "grad_norm": 0.11321628838777542,
      "learning_rate": 1.760240963855422e-06,
      "loss": 0.0237,
      "step": 151390
    },
    {
      "epoch": 18.240963855421686,
      "grad_norm": 0.0004916005418635905,
      "learning_rate": 1.7590361445783133e-06,
      "loss": 0.0035,
      "step": 151400
    },
    {
      "epoch": 18.242168674698796,
      "grad_norm": 1.754824161529541,
      "learning_rate": 1.757831325301205e-06,
      "loss": 0.0569,
      "step": 151410
    },
    {
      "epoch": 18.243373493975902,
      "grad_norm": 0.0007437382009811699,
      "learning_rate": 1.7566265060240965e-06,
      "loss": 0.0083,
      "step": 151420
    },
    {
      "epoch": 18.24457831325301,
      "grad_norm": 5.548429489135742,
      "learning_rate": 1.755421686746988e-06,
      "loss": 0.0263,
      "step": 151430
    },
    {
      "epoch": 18.24578313253012,
      "grad_norm": 0.0002146356418961659,
      "learning_rate": 1.7542168674698798e-06,
      "loss": 0.0029,
      "step": 151440
    },
    {
      "epoch": 18.246987951807228,
      "grad_norm": 9.881761798169464e-05,
      "learning_rate": 1.7530120481927712e-06,
      "loss": 0.0267,
      "step": 151450
    },
    {
      "epoch": 18.248192771084337,
      "grad_norm": 0.8816140294075012,
      "learning_rate": 1.7518072289156628e-06,
      "loss": 0.0054,
      "step": 151460
    },
    {
      "epoch": 18.249397590361447,
      "grad_norm": 0.00017482177645433694,
      "learning_rate": 1.7506024096385544e-06,
      "loss": 0.0118,
      "step": 151470
    },
    {
      "epoch": 18.250602409638553,
      "grad_norm": 0.00011455513595137745,
      "learning_rate": 1.749397590361446e-06,
      "loss": 0.0132,
      "step": 151480
    },
    {
      "epoch": 18.251807228915663,
      "grad_norm": 0.0002826601266860962,
      "learning_rate": 1.7481927710843374e-06,
      "loss": 0.0049,
      "step": 151490
    },
    {
      "epoch": 18.253012048192772,
      "grad_norm": 0.000521682552061975,
      "learning_rate": 1.7469879518072292e-06,
      "loss": 0.0049,
      "step": 151500
    },
    {
      "epoch": 18.25421686746988,
      "grad_norm": 0.00027403957210481167,
      "learning_rate": 1.7457831325301205e-06,
      "loss": 0.0266,
      "step": 151510
    },
    {
      "epoch": 18.25542168674699,
      "grad_norm": 0.00013920052151661366,
      "learning_rate": 1.7445783132530123e-06,
      "loss": 0.0055,
      "step": 151520
    },
    {
      "epoch": 18.256626506024098,
      "grad_norm": 1.0425065755844116,
      "learning_rate": 1.7433734939759037e-06,
      "loss": 0.0201,
      "step": 151530
    },
    {
      "epoch": 18.257831325301204,
      "grad_norm": 0.00010098480561282486,
      "learning_rate": 1.7421686746987953e-06,
      "loss": 0.0053,
      "step": 151540
    },
    {
      "epoch": 18.259036144578314,
      "grad_norm": 0.5987460017204285,
      "learning_rate": 1.7409638554216867e-06,
      "loss": 0.0038,
      "step": 151550
    },
    {
      "epoch": 18.26024096385542,
      "grad_norm": 1.5709227323532104,
      "learning_rate": 1.7397590361445785e-06,
      "loss": 0.0282,
      "step": 151560
    },
    {
      "epoch": 18.26144578313253,
      "grad_norm": 0.003126570489257574,
      "learning_rate": 1.7385542168674698e-06,
      "loss": 0.0002,
      "step": 151570
    },
    {
      "epoch": 18.26265060240964,
      "grad_norm": 0.8334659337997437,
      "learning_rate": 1.7373493975903616e-06,
      "loss": 0.0102,
      "step": 151580
    },
    {
      "epoch": 18.263855421686745,
      "grad_norm": 0.0001309600193053484,
      "learning_rate": 1.7361445783132532e-06,
      "loss": 0.0123,
      "step": 151590
    },
    {
      "epoch": 18.265060240963855,
      "grad_norm": 0.024379335343837738,
      "learning_rate": 1.7349397590361446e-06,
      "loss": 0.0048,
      "step": 151600
    },
    {
      "epoch": 18.266265060240965,
      "grad_norm": 6.952027615625411e-05,
      "learning_rate": 1.7337349397590364e-06,
      "loss": 0.0245,
      "step": 151610
    },
    {
      "epoch": 18.26746987951807,
      "grad_norm": 0.14128781855106354,
      "learning_rate": 1.7325301204819278e-06,
      "loss": 0.0008,
      "step": 151620
    },
    {
      "epoch": 18.26867469879518,
      "grad_norm": 0.006584287621080875,
      "learning_rate": 1.7313253012048196e-06,
      "loss": 0.0006,
      "step": 151630
    },
    {
      "epoch": 18.26987951807229,
      "grad_norm": 0.693943202495575,
      "learning_rate": 1.730120481927711e-06,
      "loss": 0.0172,
      "step": 151640
    },
    {
      "epoch": 18.271084337349397,
      "grad_norm": 0.00012492734822444618,
      "learning_rate": 1.7289156626506026e-06,
      "loss": 0.0005,
      "step": 151650
    },
    {
      "epoch": 18.272289156626506,
      "grad_norm": 9.351452899863943e-05,
      "learning_rate": 1.7277108433734941e-06,
      "loss": 0.0166,
      "step": 151660
    },
    {
      "epoch": 18.273493975903616,
      "grad_norm": 0.8889803886413574,
      "learning_rate": 1.7265060240963857e-06,
      "loss": 0.0156,
      "step": 151670
    },
    {
      "epoch": 18.274698795180722,
      "grad_norm": 0.0006977271987125278,
      "learning_rate": 1.725301204819277e-06,
      "loss": 0.0348,
      "step": 151680
    },
    {
      "epoch": 18.27590361445783,
      "grad_norm": 9.638328629080206e-05,
      "learning_rate": 1.724096385542169e-06,
      "loss": 0.0003,
      "step": 151690
    },
    {
      "epoch": 18.27710843373494,
      "grad_norm": 0.5362931489944458,
      "learning_rate": 1.7228915662650603e-06,
      "loss": 0.0467,
      "step": 151700
    },
    {
      "epoch": 18.278313253012048,
      "grad_norm": 7.301611185539514e-05,
      "learning_rate": 1.7216867469879519e-06,
      "loss": 0.0064,
      "step": 151710
    },
    {
      "epoch": 18.279518072289157,
      "grad_norm": 0.0006865411414764822,
      "learning_rate": 1.7204819277108435e-06,
      "loss": 0.0012,
      "step": 151720
    },
    {
      "epoch": 18.280722891566263,
      "grad_norm": 0.2895160913467407,
      "learning_rate": 1.719277108433735e-06,
      "loss": 0.0019,
      "step": 151730
    },
    {
      "epoch": 18.281927710843373,
      "grad_norm": 0.12014356255531311,
      "learning_rate": 1.7180722891566268e-06,
      "loss": 0.0141,
      "step": 151740
    },
    {
      "epoch": 18.283132530120483,
      "grad_norm": 0.8400328159332275,
      "learning_rate": 1.7168674698795182e-06,
      "loss": 0.0098,
      "step": 151750
    },
    {
      "epoch": 18.28433734939759,
      "grad_norm": 2.0550642013549805,
      "learning_rate": 1.7156626506024098e-06,
      "loss": 0.0286,
      "step": 151760
    },
    {
      "epoch": 18.2855421686747,
      "grad_norm": 0.0001940215443028137,
      "learning_rate": 1.7144578313253014e-06,
      "loss": 0.0003,
      "step": 151770
    },
    {
      "epoch": 18.28674698795181,
      "grad_norm": 0.00017672035028226674,
      "learning_rate": 1.713253012048193e-06,
      "loss": 0.0035,
      "step": 151780
    },
    {
      "epoch": 18.287951807228914,
      "grad_norm": 0.0004871415439993143,
      "learning_rate": 1.7120481927710844e-06,
      "loss": 0.0009,
      "step": 151790
    },
    {
      "epoch": 18.289156626506024,
      "grad_norm": 0.0005800551152788103,
      "learning_rate": 1.7108433734939762e-06,
      "loss": 0.0127,
      "step": 151800
    },
    {
      "epoch": 18.290361445783134,
      "grad_norm": 9.44866260397248e-05,
      "learning_rate": 1.7096385542168675e-06,
      "loss": 0.0098,
      "step": 151810
    },
    {
      "epoch": 18.29156626506024,
      "grad_norm": 0.0027977824211120605,
      "learning_rate": 1.7084337349397591e-06,
      "loss": 0.0142,
      "step": 151820
    },
    {
      "epoch": 18.29277108433735,
      "grad_norm": 0.00020071789913345128,
      "learning_rate": 1.7072289156626507e-06,
      "loss": 0.0065,
      "step": 151830
    },
    {
      "epoch": 18.29397590361446,
      "grad_norm": 0.6859999299049377,
      "learning_rate": 1.7060240963855423e-06,
      "loss": 0.006,
      "step": 151840
    },
    {
      "epoch": 18.295180722891565,
      "grad_norm": 0.00012427363253664225,
      "learning_rate": 1.7048192771084337e-06,
      "loss": 0.0122,
      "step": 151850
    },
    {
      "epoch": 18.296385542168675,
      "grad_norm": 0.0004125918203499168,
      "learning_rate": 1.7036144578313255e-06,
      "loss": 0.0091,
      "step": 151860
    },
    {
      "epoch": 18.297590361445785,
      "grad_norm": 0.00013981708616483957,
      "learning_rate": 1.7024096385542169e-06,
      "loss": 0.0182,
      "step": 151870
    },
    {
      "epoch": 18.29879518072289,
      "grad_norm": 0.00037245609564706683,
      "learning_rate": 1.7012048192771087e-06,
      "loss": 0.0234,
      "step": 151880
    },
    {
      "epoch": 18.3,
      "grad_norm": 9.743153350427747e-05,
      "learning_rate": 1.7000000000000002e-06,
      "loss": 0.007,
      "step": 151890
    },
    {
      "epoch": 18.301204819277107,
      "grad_norm": 0.00011397937487345189,
      "learning_rate": 1.6987951807228916e-06,
      "loss": 0.0028,
      "step": 151900
    },
    {
      "epoch": 18.302409638554217,
      "grad_norm": 0.00012590551341418177,
      "learning_rate": 1.6975903614457834e-06,
      "loss": 0.008,
      "step": 151910
    },
    {
      "epoch": 18.303614457831326,
      "grad_norm": 0.980959951877594,
      "learning_rate": 1.6963855421686748e-06,
      "loss": 0.0144,
      "step": 151920
    },
    {
      "epoch": 18.304819277108432,
      "grad_norm": 2.99049711227417,
      "learning_rate": 1.6951807228915666e-06,
      "loss": 0.0245,
      "step": 151930
    },
    {
      "epoch": 18.306024096385542,
      "grad_norm": 0.8116504549980164,
      "learning_rate": 1.693975903614458e-06,
      "loss": 0.0076,
      "step": 151940
    },
    {
      "epoch": 18.30722891566265,
      "grad_norm": 0.0016301366267725825,
      "learning_rate": 1.6927710843373496e-06,
      "loss": 0.003,
      "step": 151950
    },
    {
      "epoch": 18.308433734939758,
      "grad_norm": 2.271744728088379,
      "learning_rate": 1.691566265060241e-06,
      "loss": 0.0436,
      "step": 151960
    },
    {
      "epoch": 18.309638554216868,
      "grad_norm": 0.0006907181232236326,
      "learning_rate": 1.6903614457831327e-06,
      "loss": 0.0112,
      "step": 151970
    },
    {
      "epoch": 18.310843373493977,
      "grad_norm": 0.00015420978888869286,
      "learning_rate": 1.6891566265060241e-06,
      "loss": 0.0137,
      "step": 151980
    },
    {
      "epoch": 18.312048192771083,
      "grad_norm": 2.409034013748169,
      "learning_rate": 1.687951807228916e-06,
      "loss": 0.0245,
      "step": 151990
    },
    {
      "epoch": 18.313253012048193,
      "grad_norm": 0.00010716580436564982,
      "learning_rate": 1.6867469879518073e-06,
      "loss": 0.0291,
      "step": 152000
    },
    {
      "epoch": 18.314457831325303,
      "grad_norm": 0.00026190240168944,
      "learning_rate": 1.6855421686746989e-06,
      "loss": 0.0056,
      "step": 152010
    },
    {
      "epoch": 18.31566265060241,
      "grad_norm": 0.012865835800766945,
      "learning_rate": 1.6843373493975907e-06,
      "loss": 0.006,
      "step": 152020
    },
    {
      "epoch": 18.31686746987952,
      "grad_norm": 0.00013035611482337117,
      "learning_rate": 1.683132530120482e-06,
      "loss": 0.0289,
      "step": 152030
    },
    {
      "epoch": 18.318072289156625,
      "grad_norm": 0.00016413537377957255,
      "learning_rate": 1.6819277108433738e-06,
      "loss": 0.0079,
      "step": 152040
    },
    {
      "epoch": 18.319277108433734,
      "grad_norm": 0.007902991026639938,
      "learning_rate": 1.6807228915662652e-06,
      "loss": 0.0128,
      "step": 152050
    },
    {
      "epoch": 18.320481927710844,
      "grad_norm": 0.0002154492976842448,
      "learning_rate": 1.6795180722891568e-06,
      "loss": 0.0258,
      "step": 152060
    },
    {
      "epoch": 18.32168674698795,
      "grad_norm": 0.9423143863677979,
      "learning_rate": 1.6783132530120482e-06,
      "loss": 0.0128,
      "step": 152070
    },
    {
      "epoch": 18.32289156626506,
      "grad_norm": 0.0003397035470698029,
      "learning_rate": 1.67710843373494e-06,
      "loss": 0.0002,
      "step": 152080
    },
    {
      "epoch": 18.32409638554217,
      "grad_norm": 0.03890053555369377,
      "learning_rate": 1.6759036144578314e-06,
      "loss": 0.0331,
      "step": 152090
    },
    {
      "epoch": 18.325301204819276,
      "grad_norm": 1.0389662981033325,
      "learning_rate": 1.6746987951807232e-06,
      "loss": 0.0111,
      "step": 152100
    },
    {
      "epoch": 18.326506024096386,
      "grad_norm": 0.16450196504592896,
      "learning_rate": 1.6734939759036145e-06,
      "loss": 0.0035,
      "step": 152110
    },
    {
      "epoch": 18.327710843373495,
      "grad_norm": 0.9814376831054688,
      "learning_rate": 1.6722891566265061e-06,
      "loss": 0.009,
      "step": 152120
    },
    {
      "epoch": 18.3289156626506,
      "grad_norm": 0.14027643203735352,
      "learning_rate": 1.6710843373493977e-06,
      "loss": 0.0065,
      "step": 152130
    },
    {
      "epoch": 18.33012048192771,
      "grad_norm": 0.00026145786978304386,
      "learning_rate": 1.6698795180722893e-06,
      "loss": 0.0255,
      "step": 152140
    },
    {
      "epoch": 18.33132530120482,
      "grad_norm": 1.1693906784057617,
      "learning_rate": 1.6686746987951807e-06,
      "loss": 0.0088,
      "step": 152150
    },
    {
      "epoch": 18.332530120481927,
      "grad_norm": 0.8916820287704468,
      "learning_rate": 1.6674698795180725e-06,
      "loss": 0.0078,
      "step": 152160
    },
    {
      "epoch": 18.333734939759037,
      "grad_norm": 0.03945165127515793,
      "learning_rate": 1.666265060240964e-06,
      "loss": 0.0038,
      "step": 152170
    },
    {
      "epoch": 18.334939759036146,
      "grad_norm": 0.00016550516011193395,
      "learning_rate": 1.6650602409638554e-06,
      "loss": 0.0087,
      "step": 152180
    },
    {
      "epoch": 18.336144578313252,
      "grad_norm": 0.00018685756367631257,
      "learning_rate": 1.6638554216867472e-06,
      "loss": 0.0125,
      "step": 152190
    },
    {
      "epoch": 18.337349397590362,
      "grad_norm": 0.00014923798153176904,
      "learning_rate": 1.6626506024096386e-06,
      "loss": 0.0272,
      "step": 152200
    },
    {
      "epoch": 18.33855421686747,
      "grad_norm": 0.0002155764086637646,
      "learning_rate": 1.6614457831325304e-06,
      "loss": 0.0101,
      "step": 152210
    },
    {
      "epoch": 18.339759036144578,
      "grad_norm": 0.004329103510826826,
      "learning_rate": 1.6602409638554218e-06,
      "loss": 0.0122,
      "step": 152220
    },
    {
      "epoch": 18.340963855421688,
      "grad_norm": 1.144239068031311,
      "learning_rate": 1.6590361445783134e-06,
      "loss": 0.0042,
      "step": 152230
    },
    {
      "epoch": 18.342168674698794,
      "grad_norm": 0.7217956185340881,
      "learning_rate": 1.657831325301205e-06,
      "loss": 0.0109,
      "step": 152240
    },
    {
      "epoch": 18.343373493975903,
      "grad_norm": 0.0001660682901274413,
      "learning_rate": 1.6566265060240966e-06,
      "loss": 0.0036,
      "step": 152250
    },
    {
      "epoch": 18.344578313253013,
      "grad_norm": 1.952117681503296,
      "learning_rate": 1.655421686746988e-06,
      "loss": 0.0227,
      "step": 152260
    },
    {
      "epoch": 18.34578313253012,
      "grad_norm": 0.6368483901023865,
      "learning_rate": 1.6542168674698797e-06,
      "loss": 0.0076,
      "step": 152270
    },
    {
      "epoch": 18.34698795180723,
      "grad_norm": 0.00030343717662617564,
      "learning_rate": 1.6530120481927711e-06,
      "loss": 0.0046,
      "step": 152280
    },
    {
      "epoch": 18.34819277108434,
      "grad_norm": 0.0012608936522156,
      "learning_rate": 1.651807228915663e-06,
      "loss": 0.0163,
      "step": 152290
    },
    {
      "epoch": 18.349397590361445,
      "grad_norm": 1.8504616022109985,
      "learning_rate": 1.6506024096385543e-06,
      "loss": 0.0256,
      "step": 152300
    },
    {
      "epoch": 18.350602409638554,
      "grad_norm": 0.0001847488310886547,
      "learning_rate": 1.6493975903614459e-06,
      "loss": 0.0176,
      "step": 152310
    },
    {
      "epoch": 18.351807228915664,
      "grad_norm": 8.346099639311433e-05,
      "learning_rate": 1.6481927710843377e-06,
      "loss": 0.0026,
      "step": 152320
    },
    {
      "epoch": 18.35301204819277,
      "grad_norm": 0.00023423015954904258,
      "learning_rate": 1.646987951807229e-06,
      "loss": 0.0205,
      "step": 152330
    },
    {
      "epoch": 18.35421686746988,
      "grad_norm": 0.00014128534530755132,
      "learning_rate": 1.6457831325301206e-06,
      "loss": 0.0037,
      "step": 152340
    },
    {
      "epoch": 18.355421686746986,
      "grad_norm": 0.00019926503591705114,
      "learning_rate": 1.6445783132530122e-06,
      "loss": 0.0129,
      "step": 152350
    },
    {
      "epoch": 18.356626506024096,
      "grad_norm": 0.222799152135849,
      "learning_rate": 1.6433734939759038e-06,
      "loss": 0.0138,
      "step": 152360
    },
    {
      "epoch": 18.357831325301206,
      "grad_norm": 0.00022150691074784845,
      "learning_rate": 1.6421686746987952e-06,
      "loss": 0.0056,
      "step": 152370
    },
    {
      "epoch": 18.35903614457831,
      "grad_norm": 0.18290473520755768,
      "learning_rate": 1.640963855421687e-06,
      "loss": 0.0166,
      "step": 152380
    },
    {
      "epoch": 18.36024096385542,
      "grad_norm": 0.7698296308517456,
      "learning_rate": 1.6397590361445784e-06,
      "loss": 0.0055,
      "step": 152390
    },
    {
      "epoch": 18.36144578313253,
      "grad_norm": 1.1846131086349487,
      "learning_rate": 1.6385542168674702e-06,
      "loss": 0.0222,
      "step": 152400
    },
    {
      "epoch": 18.362650602409637,
      "grad_norm": 0.7261407971382141,
      "learning_rate": 1.6373493975903615e-06,
      "loss": 0.016,
      "step": 152410
    },
    {
      "epoch": 18.363855421686747,
      "grad_norm": 0.00017210574878845364,
      "learning_rate": 1.6361445783132531e-06,
      "loss": 0.0066,
      "step": 152420
    },
    {
      "epoch": 18.365060240963857,
      "grad_norm": 0.0002130477223545313,
      "learning_rate": 1.6349397590361445e-06,
      "loss": 0.0017,
      "step": 152430
    },
    {
      "epoch": 18.366265060240963,
      "grad_norm": 0.21596334874629974,
      "learning_rate": 1.6337349397590363e-06,
      "loss": 0.0064,
      "step": 152440
    },
    {
      "epoch": 18.367469879518072,
      "grad_norm": 0.0015505847986787558,
      "learning_rate": 1.6325301204819277e-06,
      "loss": 0.0071,
      "step": 152450
    },
    {
      "epoch": 18.368674698795182,
      "grad_norm": 0.0008808690472505987,
      "learning_rate": 1.6313253012048195e-06,
      "loss": 0.0124,
      "step": 152460
    },
    {
      "epoch": 18.36987951807229,
      "grad_norm": 1.1193480491638184,
      "learning_rate": 1.630120481927711e-06,
      "loss": 0.0233,
      "step": 152470
    },
    {
      "epoch": 18.371084337349398,
      "grad_norm": 0.0035654334351420403,
      "learning_rate": 1.6289156626506025e-06,
      "loss": 0.0001,
      "step": 152480
    },
    {
      "epoch": 18.372289156626508,
      "grad_norm": 0.1917722374200821,
      "learning_rate": 1.6277108433734943e-06,
      "loss": 0.0038,
      "step": 152490
    },
    {
      "epoch": 18.373493975903614,
      "grad_norm": 0.00012459589925128967,
      "learning_rate": 1.6265060240963856e-06,
      "loss": 0.0034,
      "step": 152500
    },
    {
      "epoch": 18.374698795180723,
      "grad_norm": 0.5232439041137695,
      "learning_rate": 1.6253012048192774e-06,
      "loss": 0.0097,
      "step": 152510
    },
    {
      "epoch": 18.37590361445783,
      "grad_norm": 0.00013231161574367434,
      "learning_rate": 1.6240963855421688e-06,
      "loss": 0.0091,
      "step": 152520
    },
    {
      "epoch": 18.37710843373494,
      "grad_norm": 0.21475546061992645,
      "learning_rate": 1.6228915662650604e-06,
      "loss": 0.007,
      "step": 152530
    },
    {
      "epoch": 18.37831325301205,
      "grad_norm": 0.0003752145858015865,
      "learning_rate": 1.6216867469879518e-06,
      "loss": 0.0166,
      "step": 152540
    },
    {
      "epoch": 18.379518072289155,
      "grad_norm": 0.00012864830205217004,
      "learning_rate": 1.6204819277108436e-06,
      "loss": 0.0088,
      "step": 152550
    },
    {
      "epoch": 18.380722891566265,
      "grad_norm": 0.7113408446311951,
      "learning_rate": 1.619277108433735e-06,
      "loss": 0.0089,
      "step": 152560
    },
    {
      "epoch": 18.381927710843375,
      "grad_norm": 0.1940886378288269,
      "learning_rate": 1.6180722891566267e-06,
      "loss": 0.0155,
      "step": 152570
    },
    {
      "epoch": 18.38313253012048,
      "grad_norm": 1.3218629360198975,
      "learning_rate": 1.6168674698795181e-06,
      "loss": 0.0135,
      "step": 152580
    },
    {
      "epoch": 18.38433734939759,
      "grad_norm": 0.0001041814248310402,
      "learning_rate": 1.6156626506024097e-06,
      "loss": 0.0024,
      "step": 152590
    },
    {
      "epoch": 18.3855421686747,
      "grad_norm": 0.002387362066656351,
      "learning_rate": 1.6144578313253013e-06,
      "loss": 0.0069,
      "step": 152600
    },
    {
      "epoch": 18.386746987951806,
      "grad_norm": 0.00016124798275996,
      "learning_rate": 1.6132530120481929e-06,
      "loss": 0.0074,
      "step": 152610
    },
    {
      "epoch": 18.387951807228916,
      "grad_norm": 0.00018146653019357473,
      "learning_rate": 1.6120481927710847e-06,
      "loss": 0.0296,
      "step": 152620
    },
    {
      "epoch": 18.389156626506026,
      "grad_norm": 1.0923309326171875,
      "learning_rate": 1.610843373493976e-06,
      "loss": 0.0173,
      "step": 152630
    },
    {
      "epoch": 18.39036144578313,
      "grad_norm": 2.6728899478912354,
      "learning_rate": 1.6096385542168676e-06,
      "loss": 0.0152,
      "step": 152640
    },
    {
      "epoch": 18.39156626506024,
      "grad_norm": 0.0003865243634209037,
      "learning_rate": 1.608433734939759e-06,
      "loss": 0.0031,
      "step": 152650
    },
    {
      "epoch": 18.39277108433735,
      "grad_norm": 1.602912425994873,
      "learning_rate": 1.6072289156626508e-06,
      "loss": 0.0179,
      "step": 152660
    },
    {
      "epoch": 18.393975903614457,
      "grad_norm": 0.00014824849495198578,
      "learning_rate": 1.6060240963855422e-06,
      "loss": 0.0066,
      "step": 152670
    },
    {
      "epoch": 18.395180722891567,
      "grad_norm": 0.00015163636999204755,
      "learning_rate": 1.604819277108434e-06,
      "loss": 0.0047,
      "step": 152680
    },
    {
      "epoch": 18.396385542168673,
      "grad_norm": 0.0013761535519734025,
      "learning_rate": 1.6036144578313254e-06,
      "loss": 0.0105,
      "step": 152690
    },
    {
      "epoch": 18.397590361445783,
      "grad_norm": 0.00016811132081784308,
      "learning_rate": 1.602409638554217e-06,
      "loss": 0.0166,
      "step": 152700
    },
    {
      "epoch": 18.398795180722892,
      "grad_norm": 0.00026727188378572464,
      "learning_rate": 1.6012048192771086e-06,
      "loss": 0.0033,
      "step": 152710
    },
    {
      "epoch": 18.4,
      "grad_norm": 0.21817241609096527,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.0102,
      "step": 152720
    },
    {
      "epoch": 18.40120481927711,
      "grad_norm": 0.0036127292551100254,
      "learning_rate": 1.5987951807228915e-06,
      "loss": 0.023,
      "step": 152730
    },
    {
      "epoch": 18.402409638554218,
      "grad_norm": 0.00026765489019453526,
      "learning_rate": 1.5975903614457833e-06,
      "loss": 0.0,
      "step": 152740
    },
    {
      "epoch": 18.403614457831324,
      "grad_norm": 0.6971902847290039,
      "learning_rate": 1.5963855421686747e-06,
      "loss": 0.0116,
      "step": 152750
    },
    {
      "epoch": 18.404819277108434,
      "grad_norm": 0.012597150169312954,
      "learning_rate": 1.5951807228915665e-06,
      "loss": 0.0223,
      "step": 152760
    },
    {
      "epoch": 18.406024096385543,
      "grad_norm": 0.00019153965695295483,
      "learning_rate": 1.593975903614458e-06,
      "loss": 0.004,
      "step": 152770
    },
    {
      "epoch": 18.40722891566265,
      "grad_norm": 0.00028937406023032963,
      "learning_rate": 1.5927710843373495e-06,
      "loss": 0.009,
      "step": 152780
    },
    {
      "epoch": 18.40843373493976,
      "grad_norm": 0.00018470406939741224,
      "learning_rate": 1.5915662650602413e-06,
      "loss": 0.0051,
      "step": 152790
    },
    {
      "epoch": 18.40963855421687,
      "grad_norm": 0.00010209859465248883,
      "learning_rate": 1.5903614457831326e-06,
      "loss": 0.0229,
      "step": 152800
    },
    {
      "epoch": 18.410843373493975,
      "grad_norm": 0.0011253281263634562,
      "learning_rate": 1.5891566265060242e-06,
      "loss": 0.0072,
      "step": 152810
    },
    {
      "epoch": 18.412048192771085,
      "grad_norm": 0.7585237622261047,
      "learning_rate": 1.5879518072289158e-06,
      "loss": 0.0138,
      "step": 152820
    },
    {
      "epoch": 18.413253012048195,
      "grad_norm": 0.002285066759213805,
      "learning_rate": 1.5867469879518074e-06,
      "loss": 0.0101,
      "step": 152830
    },
    {
      "epoch": 18.4144578313253,
      "grad_norm": 0.00015603814972564578,
      "learning_rate": 1.5855421686746988e-06,
      "loss": 0.0091,
      "step": 152840
    },
    {
      "epoch": 18.41566265060241,
      "grad_norm": 0.4013265371322632,
      "learning_rate": 1.5843373493975906e-06,
      "loss": 0.0135,
      "step": 152850
    },
    {
      "epoch": 18.416867469879517,
      "grad_norm": 0.13840685784816742,
      "learning_rate": 1.583132530120482e-06,
      "loss": 0.0186,
      "step": 152860
    },
    {
      "epoch": 18.418072289156626,
      "grad_norm": 1.667057752609253,
      "learning_rate": 1.5819277108433737e-06,
      "loss": 0.0151,
      "step": 152870
    },
    {
      "epoch": 18.419277108433736,
      "grad_norm": 0.0002219436428276822,
      "learning_rate": 1.5807228915662651e-06,
      "loss": 0.0059,
      "step": 152880
    },
    {
      "epoch": 18.420481927710842,
      "grad_norm": 0.00012667964620050043,
      "learning_rate": 1.5795180722891567e-06,
      "loss": 0.006,
      "step": 152890
    },
    {
      "epoch": 18.42168674698795,
      "grad_norm": 0.6144284605979919,
      "learning_rate": 1.578313253012048e-06,
      "loss": 0.0074,
      "step": 152900
    },
    {
      "epoch": 18.42289156626506,
      "grad_norm": 0.22449615597724915,
      "learning_rate": 1.5771084337349399e-06,
      "loss": 0.0109,
      "step": 152910
    },
    {
      "epoch": 18.424096385542168,
      "grad_norm": 0.00018003632430918515,
      "learning_rate": 1.5759036144578315e-06,
      "loss": 0.0075,
      "step": 152920
    },
    {
      "epoch": 18.425301204819277,
      "grad_norm": 0.0002904559369198978,
      "learning_rate": 1.574698795180723e-06,
      "loss": 0.0348,
      "step": 152930
    },
    {
      "epoch": 18.426506024096387,
      "grad_norm": 0.00013009698886889964,
      "learning_rate": 1.5734939759036147e-06,
      "loss": 0.0005,
      "step": 152940
    },
    {
      "epoch": 18.427710843373493,
      "grad_norm": 0.21682842075824738,
      "learning_rate": 1.572289156626506e-06,
      "loss": 0.028,
      "step": 152950
    },
    {
      "epoch": 18.428915662650603,
      "grad_norm": 0.00011417739005992189,
      "learning_rate": 1.5710843373493978e-06,
      "loss": 0.0125,
      "step": 152960
    },
    {
      "epoch": 18.430120481927712,
      "grad_norm": 0.000817683117929846,
      "learning_rate": 1.5698795180722892e-06,
      "loss": 0.0376,
      "step": 152970
    },
    {
      "epoch": 18.43132530120482,
      "grad_norm": 0.0008143468294292688,
      "learning_rate": 1.568674698795181e-06,
      "loss": 0.0063,
      "step": 152980
    },
    {
      "epoch": 18.43253012048193,
      "grad_norm": 0.00010757989366538823,
      "learning_rate": 1.5674698795180724e-06,
      "loss": 0.0139,
      "step": 152990
    },
    {
      "epoch": 18.433734939759034,
      "grad_norm": 1.037561058998108,
      "learning_rate": 1.566265060240964e-06,
      "loss": 0.0183,
      "step": 153000
    },
    {
      "epoch": 18.434939759036144,
      "grad_norm": 0.0002920979750342667,
      "learning_rate": 1.5650602409638553e-06,
      "loss": 0.0077,
      "step": 153010
    },
    {
      "epoch": 18.436144578313254,
      "grad_norm": 0.8251938223838806,
      "learning_rate": 1.5638554216867471e-06,
      "loss": 0.0161,
      "step": 153020
    },
    {
      "epoch": 18.43734939759036,
      "grad_norm": 0.0005278474418446422,
      "learning_rate": 1.5626506024096385e-06,
      "loss": 0.0159,
      "step": 153030
    },
    {
      "epoch": 18.43855421686747,
      "grad_norm": 0.00010108519927598536,
      "learning_rate": 1.5614457831325303e-06,
      "loss": 0.005,
      "step": 153040
    },
    {
      "epoch": 18.43975903614458,
      "grad_norm": 0.00016158171638380736,
      "learning_rate": 1.560240963855422e-06,
      "loss": 0.0055,
      "step": 153050
    },
    {
      "epoch": 18.440963855421685,
      "grad_norm": 0.00013871277042198926,
      "learning_rate": 1.5590361445783133e-06,
      "loss": 0.0049,
      "step": 153060
    },
    {
      "epoch": 18.442168674698795,
      "grad_norm": 0.00016237070667557418,
      "learning_rate": 1.557831325301205e-06,
      "loss": 0.0406,
      "step": 153070
    },
    {
      "epoch": 18.443373493975905,
      "grad_norm": 0.0673833116889,
      "learning_rate": 1.5566265060240965e-06,
      "loss": 0.0203,
      "step": 153080
    },
    {
      "epoch": 18.44457831325301,
      "grad_norm": 0.00023082908592186868,
      "learning_rate": 1.5554216867469883e-06,
      "loss": 0.0085,
      "step": 153090
    },
    {
      "epoch": 18.44578313253012,
      "grad_norm": 9.995587606681511e-05,
      "learning_rate": 1.5542168674698796e-06,
      "loss": 0.0056,
      "step": 153100
    },
    {
      "epoch": 18.44698795180723,
      "grad_norm": 0.0006492217653430998,
      "learning_rate": 1.5530120481927712e-06,
      "loss": 0.0132,
      "step": 153110
    },
    {
      "epoch": 18.448192771084337,
      "grad_norm": 0.00011117516260128468,
      "learning_rate": 1.5518072289156628e-06,
      "loss": 0.0013,
      "step": 153120
    },
    {
      "epoch": 18.449397590361446,
      "grad_norm": 0.0005171537632122636,
      "learning_rate": 1.5506024096385544e-06,
      "loss": 0.0056,
      "step": 153130
    },
    {
      "epoch": 18.450602409638556,
      "grad_norm": 0.00018995192658621818,
      "learning_rate": 1.5493975903614458e-06,
      "loss": 0.0031,
      "step": 153140
    },
    {
      "epoch": 18.451807228915662,
      "grad_norm": 0.15939946472644806,
      "learning_rate": 1.5481927710843376e-06,
      "loss": 0.0035,
      "step": 153150
    },
    {
      "epoch": 18.45301204819277,
      "grad_norm": 0.14245332777500153,
      "learning_rate": 1.546987951807229e-06,
      "loss": 0.0065,
      "step": 153160
    },
    {
      "epoch": 18.454216867469878,
      "grad_norm": 0.0002780024951789528,
      "learning_rate": 1.5457831325301205e-06,
      "loss": 0.0064,
      "step": 153170
    },
    {
      "epoch": 18.455421686746988,
      "grad_norm": 7.537422061432153e-05,
      "learning_rate": 1.5445783132530121e-06,
      "loss": 0.0,
      "step": 153180
    },
    {
      "epoch": 18.456626506024097,
      "grad_norm": 0.00013090510037727654,
      "learning_rate": 1.5433734939759037e-06,
      "loss": 0.0123,
      "step": 153190
    },
    {
      "epoch": 18.457831325301203,
      "grad_norm": 0.00015011652430985123,
      "learning_rate": 1.5421686746987955e-06,
      "loss": 0.012,
      "step": 153200
    },
    {
      "epoch": 18.459036144578313,
      "grad_norm": 0.0001549570879433304,
      "learning_rate": 1.5409638554216869e-06,
      "loss": 0.0028,
      "step": 153210
    },
    {
      "epoch": 18.460240963855423,
      "grad_norm": 0.00010903517249971628,
      "learning_rate": 1.5397590361445785e-06,
      "loss": 0.0073,
      "step": 153220
    },
    {
      "epoch": 18.46144578313253,
      "grad_norm": 0.013515251688659191,
      "learning_rate": 1.53855421686747e-06,
      "loss": 0.0067,
      "step": 153230
    },
    {
      "epoch": 18.46265060240964,
      "grad_norm": 0.00011626677587628365,
      "learning_rate": 1.5373493975903617e-06,
      "loss": 0.0132,
      "step": 153240
    },
    {
      "epoch": 18.46385542168675,
      "grad_norm": 0.0004347579088062048,
      "learning_rate": 1.536144578313253e-06,
      "loss": 0.0049,
      "step": 153250
    },
    {
      "epoch": 18.465060240963854,
      "grad_norm": 1.7206463813781738,
      "learning_rate": 1.5349397590361448e-06,
      "loss": 0.0191,
      "step": 153260
    },
    {
      "epoch": 18.466265060240964,
      "grad_norm": 0.001347038778476417,
      "learning_rate": 1.5337349397590362e-06,
      "loss": 0.0005,
      "step": 153270
    },
    {
      "epoch": 18.467469879518074,
      "grad_norm": 8.200457523344085e-05,
      "learning_rate": 1.5325301204819278e-06,
      "loss": 0.0087,
      "step": 153280
    },
    {
      "epoch": 18.46867469879518,
      "grad_norm": 0.00024716887855902314,
      "learning_rate": 1.5313253012048194e-06,
      "loss": 0.0234,
      "step": 153290
    },
    {
      "epoch": 18.46987951807229,
      "grad_norm": 0.17406043410301208,
      "learning_rate": 1.530120481927711e-06,
      "loss": 0.0078,
      "step": 153300
    },
    {
      "epoch": 18.471084337349396,
      "grad_norm": 0.00012217673065606505,
      "learning_rate": 1.5289156626506023e-06,
      "loss": 0.0073,
      "step": 153310
    },
    {
      "epoch": 18.472289156626506,
      "grad_norm": 0.2663055956363678,
      "learning_rate": 1.5277108433734941e-06,
      "loss": 0.0045,
      "step": 153320
    },
    {
      "epoch": 18.473493975903615,
      "grad_norm": 0.001456750906072557,
      "learning_rate": 1.5265060240963855e-06,
      "loss": 0.0027,
      "step": 153330
    },
    {
      "epoch": 18.47469879518072,
      "grad_norm": 0.00011729513062164187,
      "learning_rate": 1.5253012048192773e-06,
      "loss": 0.0133,
      "step": 153340
    },
    {
      "epoch": 18.47590361445783,
      "grad_norm": 0.00013063345977570862,
      "learning_rate": 1.524096385542169e-06,
      "loss": 0.0065,
      "step": 153350
    },
    {
      "epoch": 18.47710843373494,
      "grad_norm": 8.068331226240844e-05,
      "learning_rate": 1.5228915662650603e-06,
      "loss": 0.0345,
      "step": 153360
    },
    {
      "epoch": 18.478313253012047,
      "grad_norm": 0.00016585314006078988,
      "learning_rate": 1.521686746987952e-06,
      "loss": 0.0071,
      "step": 153370
    },
    {
      "epoch": 18.479518072289157,
      "grad_norm": 0.00028624862898141146,
      "learning_rate": 1.5204819277108435e-06,
      "loss": 0.0351,
      "step": 153380
    },
    {
      "epoch": 18.480722891566266,
      "grad_norm": 0.27246159315109253,
      "learning_rate": 1.5192771084337353e-06,
      "loss": 0.019,
      "step": 153390
    },
    {
      "epoch": 18.481927710843372,
      "grad_norm": 0.0032312306575477123,
      "learning_rate": 1.5180722891566266e-06,
      "loss": 0.0044,
      "step": 153400
    },
    {
      "epoch": 18.483132530120482,
      "grad_norm": 8.370256546186283e-05,
      "learning_rate": 1.5168674698795182e-06,
      "loss": 0.0061,
      "step": 153410
    },
    {
      "epoch": 18.48433734939759,
      "grad_norm": 7.006271334830672e-05,
      "learning_rate": 1.5156626506024096e-06,
      "loss": 0.0151,
      "step": 153420
    },
    {
      "epoch": 18.485542168674698,
      "grad_norm": 0.002835468854755163,
      "learning_rate": 1.5144578313253014e-06,
      "loss": 0.0148,
      "step": 153430
    },
    {
      "epoch": 18.486746987951808,
      "grad_norm": 0.015527979470789433,
      "learning_rate": 1.5132530120481928e-06,
      "loss": 0.0114,
      "step": 153440
    },
    {
      "epoch": 18.487951807228917,
      "grad_norm": 0.00017177134577650577,
      "learning_rate": 1.5120481927710846e-06,
      "loss": 0.0041,
      "step": 153450
    },
    {
      "epoch": 18.489156626506023,
      "grad_norm": 0.18830499053001404,
      "learning_rate": 1.510843373493976e-06,
      "loss": 0.0059,
      "step": 153460
    },
    {
      "epoch": 18.490361445783133,
      "grad_norm": 0.0018573813140392303,
      "learning_rate": 1.5096385542168675e-06,
      "loss": 0.0009,
      "step": 153470
    },
    {
      "epoch": 18.49156626506024,
      "grad_norm": 0.7760804295539856,
      "learning_rate": 1.5084337349397591e-06,
      "loss": 0.0286,
      "step": 153480
    },
    {
      "epoch": 18.49277108433735,
      "grad_norm": 1.4778016805648804,
      "learning_rate": 1.5072289156626507e-06,
      "loss": 0.035,
      "step": 153490
    },
    {
      "epoch": 18.49397590361446,
      "grad_norm": 0.0005052063497714698,
      "learning_rate": 1.5060240963855425e-06,
      "loss": 0.0009,
      "step": 153500
    },
    {
      "epoch": 18.495180722891565,
      "grad_norm": 0.0004822841437999159,
      "learning_rate": 1.504819277108434e-06,
      "loss": 0.0088,
      "step": 153510
    },
    {
      "epoch": 18.496385542168674,
      "grad_norm": 9.022597078001127e-05,
      "learning_rate": 1.5036144578313255e-06,
      "loss": 0.0121,
      "step": 153520
    },
    {
      "epoch": 18.497590361445784,
      "grad_norm": 1.797734022140503,
      "learning_rate": 1.5024096385542169e-06,
      "loss": 0.0151,
      "step": 153530
    },
    {
      "epoch": 18.49879518072289,
      "grad_norm": 6.127724918769673e-05,
      "learning_rate": 1.5012048192771087e-06,
      "loss": 0.0121,
      "step": 153540
    },
    {
      "epoch": 18.5,
      "grad_norm": 1.8965058326721191,
      "learning_rate": 1.5e-06,
      "loss": 0.0179,
      "step": 153550
    },
    {
      "epoch": 18.50120481927711,
      "grad_norm": 9.752688492881134e-05,
      "learning_rate": 1.4987951807228918e-06,
      "loss": 0.0354,
      "step": 153560
    },
    {
      "epoch": 18.502409638554216,
      "grad_norm": 0.022613920271396637,
      "learning_rate": 1.4975903614457832e-06,
      "loss": 0.0035,
      "step": 153570
    },
    {
      "epoch": 18.503614457831326,
      "grad_norm": 0.8891730308532715,
      "learning_rate": 1.4963855421686748e-06,
      "loss": 0.0063,
      "step": 153580
    },
    {
      "epoch": 18.504819277108435,
      "grad_norm": 0.00015000696294009686,
      "learning_rate": 1.4951807228915664e-06,
      "loss": 0.0247,
      "step": 153590
    },
    {
      "epoch": 18.50602409638554,
      "grad_norm": 1.1737841367721558,
      "learning_rate": 1.493975903614458e-06,
      "loss": 0.0185,
      "step": 153600
    },
    {
      "epoch": 18.50722891566265,
      "grad_norm": 0.0002902912674471736,
      "learning_rate": 1.4927710843373494e-06,
      "loss": 0.0133,
      "step": 153610
    },
    {
      "epoch": 18.50843373493976,
      "grad_norm": 0.0002844551345333457,
      "learning_rate": 1.4915662650602412e-06,
      "loss": 0.0054,
      "step": 153620
    },
    {
      "epoch": 18.509638554216867,
      "grad_norm": 8.794194582151249e-05,
      "learning_rate": 1.4903614457831325e-06,
      "loss": 0.0356,
      "step": 153630
    },
    {
      "epoch": 18.510843373493977,
      "grad_norm": 0.000275306636467576,
      "learning_rate": 1.4891566265060241e-06,
      "loss": 0.0124,
      "step": 153640
    },
    {
      "epoch": 18.512048192771083,
      "grad_norm": 0.0005301040946505964,
      "learning_rate": 1.487951807228916e-06,
      "loss": 0.0047,
      "step": 153650
    },
    {
      "epoch": 18.513253012048192,
      "grad_norm": 0.00017461780225858092,
      "learning_rate": 1.4867469879518073e-06,
      "loss": 0.0134,
      "step": 153660
    },
    {
      "epoch": 18.514457831325302,
      "grad_norm": 0.0012726689456030726,
      "learning_rate": 1.485542168674699e-06,
      "loss": 0.0116,
      "step": 153670
    },
    {
      "epoch": 18.51566265060241,
      "grad_norm": 0.00012625922681763768,
      "learning_rate": 1.4843373493975905e-06,
      "loss": 0.0026,
      "step": 153680
    },
    {
      "epoch": 18.516867469879518,
      "grad_norm": 0.002763404045253992,
      "learning_rate": 1.483132530120482e-06,
      "loss": 0.0169,
      "step": 153690
    },
    {
      "epoch": 18.518072289156628,
      "grad_norm": 0.00038533672341145575,
      "learning_rate": 1.4819277108433736e-06,
      "loss": 0.0084,
      "step": 153700
    },
    {
      "epoch": 18.519277108433734,
      "grad_norm": 5.800625149277039e-05,
      "learning_rate": 1.4807228915662652e-06,
      "loss": 0.0095,
      "step": 153710
    },
    {
      "epoch": 18.520481927710843,
      "grad_norm": 1.1015158891677856,
      "learning_rate": 1.4795180722891566e-06,
      "loss": 0.0161,
      "step": 153720
    },
    {
      "epoch": 18.521686746987953,
      "grad_norm": 0.002273330930620432,
      "learning_rate": 1.4783132530120484e-06,
      "loss": 0.0063,
      "step": 153730
    },
    {
      "epoch": 18.52289156626506,
      "grad_norm": 0.0068182386457920074,
      "learning_rate": 1.4771084337349398e-06,
      "loss": 0.0298,
      "step": 153740
    },
    {
      "epoch": 18.52409638554217,
      "grad_norm": 0.9241507649421692,
      "learning_rate": 1.4759036144578314e-06,
      "loss": 0.0286,
      "step": 153750
    },
    {
      "epoch": 18.52530120481928,
      "grad_norm": 0.3507811725139618,
      "learning_rate": 1.474698795180723e-06,
      "loss": 0.0325,
      "step": 153760
    },
    {
      "epoch": 18.526506024096385,
      "grad_norm": 0.03622659295797348,
      "learning_rate": 1.4734939759036146e-06,
      "loss": 0.0145,
      "step": 153770
    },
    {
      "epoch": 18.527710843373494,
      "grad_norm": 0.00020842690719291568,
      "learning_rate": 1.472289156626506e-06,
      "loss": 0.0046,
      "step": 153780
    },
    {
      "epoch": 18.528915662650604,
      "grad_norm": 0.7192174792289734,
      "learning_rate": 1.4710843373493977e-06,
      "loss": 0.0131,
      "step": 153790
    },
    {
      "epoch": 18.53012048192771,
      "grad_norm": 0.00021019886480644345,
      "learning_rate": 1.4698795180722893e-06,
      "loss": 0.0107,
      "step": 153800
    },
    {
      "epoch": 18.53132530120482,
      "grad_norm": 0.00016457542369607836,
      "learning_rate": 1.468674698795181e-06,
      "loss": 0.0151,
      "step": 153810
    },
    {
      "epoch": 18.532530120481926,
      "grad_norm": 0.00027294890605844557,
      "learning_rate": 1.4674698795180725e-06,
      "loss": 0.007,
      "step": 153820
    },
    {
      "epoch": 18.533734939759036,
      "grad_norm": 0.00021925769397057593,
      "learning_rate": 1.4662650602409639e-06,
      "loss": 0.0108,
      "step": 153830
    },
    {
      "epoch": 18.534939759036146,
      "grad_norm": 1.2196767330169678,
      "learning_rate": 1.4650602409638557e-06,
      "loss": 0.0164,
      "step": 153840
    },
    {
      "epoch": 18.53614457831325,
      "grad_norm": 5.366767883300781,
      "learning_rate": 1.463855421686747e-06,
      "loss": 0.0375,
      "step": 153850
    },
    {
      "epoch": 18.53734939759036,
      "grad_norm": 1.2725820541381836,
      "learning_rate": 1.4626506024096388e-06,
      "loss": 0.0114,
      "step": 153860
    },
    {
      "epoch": 18.53855421686747,
      "grad_norm": 0.00017295367433689535,
      "learning_rate": 1.4614457831325302e-06,
      "loss": 0.0137,
      "step": 153870
    },
    {
      "epoch": 18.539759036144577,
      "grad_norm": 0.00019597390200942755,
      "learning_rate": 1.4602409638554218e-06,
      "loss": 0.0217,
      "step": 153880
    },
    {
      "epoch": 18.540963855421687,
      "grad_norm": 0.19294437766075134,
      "learning_rate": 1.4590361445783132e-06,
      "loss": 0.0163,
      "step": 153890
    },
    {
      "epoch": 18.542168674698797,
      "grad_norm": 0.4226791560649872,
      "learning_rate": 1.457831325301205e-06,
      "loss": 0.0088,
      "step": 153900
    },
    {
      "epoch": 18.543373493975903,
      "grad_norm": 9.880273864837363e-05,
      "learning_rate": 1.4566265060240964e-06,
      "loss": 0.026,
      "step": 153910
    },
    {
      "epoch": 18.544578313253012,
      "grad_norm": 80.90120697021484,
      "learning_rate": 1.4554216867469882e-06,
      "loss": 0.0234,
      "step": 153920
    },
    {
      "epoch": 18.545783132530122,
      "grad_norm": 2.1917500495910645,
      "learning_rate": 1.4542168674698795e-06,
      "loss": 0.0244,
      "step": 153930
    },
    {
      "epoch": 18.54698795180723,
      "grad_norm": 3.6583492755889893,
      "learning_rate": 1.4530120481927711e-06,
      "loss": 0.0198,
      "step": 153940
    },
    {
      "epoch": 18.548192771084338,
      "grad_norm": 0.00012187295942567289,
      "learning_rate": 1.451807228915663e-06,
      "loss": 0.0148,
      "step": 153950
    },
    {
      "epoch": 18.549397590361444,
      "grad_norm": 0.00015640903438907117,
      "learning_rate": 1.4506024096385543e-06,
      "loss": 0.005,
      "step": 153960
    },
    {
      "epoch": 18.550602409638554,
      "grad_norm": 1.0603339672088623,
      "learning_rate": 1.449397590361446e-06,
      "loss": 0.0127,
      "step": 153970
    },
    {
      "epoch": 18.551807228915663,
      "grad_norm": 1.9816862344741821,
      "learning_rate": 1.4481927710843375e-06,
      "loss": 0.026,
      "step": 153980
    },
    {
      "epoch": 18.55301204819277,
      "grad_norm": 0.0004590666794683784,
      "learning_rate": 1.446987951807229e-06,
      "loss": 0.0019,
      "step": 153990
    },
    {
      "epoch": 18.55421686746988,
      "grad_norm": 0.00011985928722424433,
      "learning_rate": 1.4457831325301204e-06,
      "loss": 0.0035,
      "step": 154000
    },
    {
      "epoch": 18.55542168674699,
      "grad_norm": 0.0017691414104774594,
      "learning_rate": 1.4445783132530122e-06,
      "loss": 0.0038,
      "step": 154010
    },
    {
      "epoch": 18.556626506024095,
      "grad_norm": 1.2019784450531006,
      "learning_rate": 1.4433734939759036e-06,
      "loss": 0.0277,
      "step": 154020
    },
    {
      "epoch": 18.557831325301205,
      "grad_norm": 0.0002627591893542558,
      "learning_rate": 1.4421686746987954e-06,
      "loss": 0.0164,
      "step": 154030
    },
    {
      "epoch": 18.559036144578315,
      "grad_norm": 0.007939807139337063,
      "learning_rate": 1.4409638554216868e-06,
      "loss": 0.0239,
      "step": 154040
    },
    {
      "epoch": 18.56024096385542,
      "grad_norm": 0.8452712297439575,
      "learning_rate": 1.4397590361445784e-06,
      "loss": 0.0157,
      "step": 154050
    },
    {
      "epoch": 18.56144578313253,
      "grad_norm": 7.506184192607179e-05,
      "learning_rate": 1.43855421686747e-06,
      "loss": 0.0145,
      "step": 154060
    },
    {
      "epoch": 18.56265060240964,
      "grad_norm": 0.7280938029289246,
      "learning_rate": 1.4373493975903616e-06,
      "loss": 0.0092,
      "step": 154070
    },
    {
      "epoch": 18.563855421686746,
      "grad_norm": 1.1632359027862549,
      "learning_rate": 1.4361445783132534e-06,
      "loss": 0.0216,
      "step": 154080
    },
    {
      "epoch": 18.565060240963856,
      "grad_norm": 0.0004073352611158043,
      "learning_rate": 1.4349397590361447e-06,
      "loss": 0.0418,
      "step": 154090
    },
    {
      "epoch": 18.566265060240966,
      "grad_norm": 0.0001436719176126644,
      "learning_rate": 1.4337349397590363e-06,
      "loss": 0.0074,
      "step": 154100
    },
    {
      "epoch": 18.56746987951807,
      "grad_norm": 0.831416130065918,
      "learning_rate": 1.4325301204819277e-06,
      "loss": 0.0032,
      "step": 154110
    },
    {
      "epoch": 18.56867469879518,
      "grad_norm": 0.002232262631878257,
      "learning_rate": 1.4313253012048195e-06,
      "loss": 0.0172,
      "step": 154120
    },
    {
      "epoch": 18.569879518072288,
      "grad_norm": 0.23743192851543427,
      "learning_rate": 1.4301204819277109e-06,
      "loss": 0.0024,
      "step": 154130
    },
    {
      "epoch": 18.571084337349397,
      "grad_norm": 0.00019314115343149751,
      "learning_rate": 1.4289156626506027e-06,
      "loss": 0.0163,
      "step": 154140
    },
    {
      "epoch": 18.572289156626507,
      "grad_norm": 0.013912682421505451,
      "learning_rate": 1.427710843373494e-06,
      "loss": 0.0143,
      "step": 154150
    },
    {
      "epoch": 18.573493975903613,
      "grad_norm": 7.565166743006557e-05,
      "learning_rate": 1.4265060240963856e-06,
      "loss": 0.0091,
      "step": 154160
    },
    {
      "epoch": 18.574698795180723,
      "grad_norm": 0.00021333312906790525,
      "learning_rate": 1.4253012048192772e-06,
      "loss": 0.016,
      "step": 154170
    },
    {
      "epoch": 18.575903614457832,
      "grad_norm": 0.0017873452743515372,
      "learning_rate": 1.4240963855421688e-06,
      "loss": 0.0018,
      "step": 154180
    },
    {
      "epoch": 18.57710843373494,
      "grad_norm": 0.2662091851234436,
      "learning_rate": 1.4228915662650602e-06,
      "loss": 0.0034,
      "step": 154190
    },
    {
      "epoch": 18.57831325301205,
      "grad_norm": 0.00018968361837323755,
      "learning_rate": 1.421686746987952e-06,
      "loss": 0.0159,
      "step": 154200
    },
    {
      "epoch": 18.579518072289158,
      "grad_norm": 0.00018063346215058118,
      "learning_rate": 1.4204819277108434e-06,
      "loss": 0.0187,
      "step": 154210
    },
    {
      "epoch": 18.580722891566264,
      "grad_norm": 0.005475503858178854,
      "learning_rate": 1.4192771084337352e-06,
      "loss": 0.0099,
      "step": 154220
    },
    {
      "epoch": 18.581927710843374,
      "grad_norm": 0.0003126916999462992,
      "learning_rate": 1.4180722891566268e-06,
      "loss": 0.0032,
      "step": 154230
    },
    {
      "epoch": 18.583132530120483,
      "grad_norm": 42.010746002197266,
      "learning_rate": 1.4168674698795181e-06,
      "loss": 0.0136,
      "step": 154240
    },
    {
      "epoch": 18.58433734939759,
      "grad_norm": 0.006783094722777605,
      "learning_rate": 1.41566265060241e-06,
      "loss": 0.012,
      "step": 154250
    },
    {
      "epoch": 18.5855421686747,
      "grad_norm": 0.00010780771117424592,
      "learning_rate": 1.4144578313253013e-06,
      "loss": 0.0103,
      "step": 154260
    },
    {
      "epoch": 18.586746987951805,
      "grad_norm": 0.00023626259644515812,
      "learning_rate": 1.4132530120481929e-06,
      "loss": 0.0077,
      "step": 154270
    },
    {
      "epoch": 18.587951807228915,
      "grad_norm": 0.00012658152263611555,
      "learning_rate": 1.4120481927710845e-06,
      "loss": 0.0169,
      "step": 154280
    },
    {
      "epoch": 18.589156626506025,
      "grad_norm": 0.00012944337504450232,
      "learning_rate": 1.410843373493976e-06,
      "loss": 0.0015,
      "step": 154290
    },
    {
      "epoch": 18.59036144578313,
      "grad_norm": 9.883516759146005e-05,
      "learning_rate": 1.4096385542168674e-06,
      "loss": 0.0085,
      "step": 154300
    },
    {
      "epoch": 18.59156626506024,
      "grad_norm": 1.5158779621124268,
      "learning_rate": 1.4084337349397592e-06,
      "loss": 0.0103,
      "step": 154310
    },
    {
      "epoch": 18.59277108433735,
      "grad_norm": 0.32171913981437683,
      "learning_rate": 1.4072289156626506e-06,
      "loss": 0.0183,
      "step": 154320
    },
    {
      "epoch": 18.593975903614457,
      "grad_norm": 0.00016654877981636673,
      "learning_rate": 1.4060240963855424e-06,
      "loss": 0.0157,
      "step": 154330
    },
    {
      "epoch": 18.595180722891566,
      "grad_norm": 0.32325175404548645,
      "learning_rate": 1.4048192771084338e-06,
      "loss": 0.0061,
      "step": 154340
    },
    {
      "epoch": 18.596385542168676,
      "grad_norm": 1.3191990852355957,
      "learning_rate": 1.4036144578313254e-06,
      "loss": 0.0108,
      "step": 154350
    },
    {
      "epoch": 18.597590361445782,
      "grad_norm": 0.00027864903677254915,
      "learning_rate": 1.4024096385542168e-06,
      "loss": 0.0118,
      "step": 154360
    },
    {
      "epoch": 18.59879518072289,
      "grad_norm": 1.837835431098938,
      "learning_rate": 1.4012048192771086e-06,
      "loss": 0.0101,
      "step": 154370
    },
    {
      "epoch": 18.6,
      "grad_norm": 1.683184027671814,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.0242,
      "step": 154380
    },
    {
      "epoch": 18.601204819277108,
      "grad_norm": 0.00015528834774158895,
      "learning_rate": 1.3987951807228917e-06,
      "loss": 0.0118,
      "step": 154390
    },
    {
      "epoch": 18.602409638554217,
      "grad_norm": 0.0012942588655278087,
      "learning_rate": 1.3975903614457833e-06,
      "loss": 0.0334,
      "step": 154400
    },
    {
      "epoch": 18.603614457831327,
      "grad_norm": 15.922480583190918,
      "learning_rate": 1.3963855421686747e-06,
      "loss": 0.0035,
      "step": 154410
    },
    {
      "epoch": 18.604819277108433,
      "grad_norm": 0.005293240770697594,
      "learning_rate": 1.3951807228915665e-06,
      "loss": 0.0065,
      "step": 154420
    },
    {
      "epoch": 18.606024096385543,
      "grad_norm": 0.013175600208342075,
      "learning_rate": 1.3939759036144579e-06,
      "loss": 0.0117,
      "step": 154430
    },
    {
      "epoch": 18.60722891566265,
      "grad_norm": 0.027151422575116158,
      "learning_rate": 1.3927710843373497e-06,
      "loss": 0.0067,
      "step": 154440
    },
    {
      "epoch": 18.60843373493976,
      "grad_norm": 0.00011998017726000398,
      "learning_rate": 1.391566265060241e-06,
      "loss": 0.0116,
      "step": 154450
    },
    {
      "epoch": 18.60963855421687,
      "grad_norm": 0.00011900778190465644,
      "learning_rate": 1.3903614457831326e-06,
      "loss": 0.0099,
      "step": 154460
    },
    {
      "epoch": 18.610843373493974,
      "grad_norm": 0.00021395691146608442,
      "learning_rate": 1.389156626506024e-06,
      "loss": 0.0087,
      "step": 154470
    },
    {
      "epoch": 18.612048192771084,
      "grad_norm": 0.622403621673584,
      "learning_rate": 1.3879518072289158e-06,
      "loss": 0.0115,
      "step": 154480
    },
    {
      "epoch": 18.613253012048194,
      "grad_norm": 1.7744433879852295,
      "learning_rate": 1.3867469879518072e-06,
      "loss": 0.0094,
      "step": 154490
    },
    {
      "epoch": 18.6144578313253,
      "grad_norm": 0.32040169835090637,
      "learning_rate": 1.385542168674699e-06,
      "loss": 0.0174,
      "step": 154500
    },
    {
      "epoch": 18.61566265060241,
      "grad_norm": 0.008782626129686832,
      "learning_rate": 1.3843373493975904e-06,
      "loss": 0.0308,
      "step": 154510
    },
    {
      "epoch": 18.61686746987952,
      "grad_norm": 0.0004832469567190856,
      "learning_rate": 1.383132530120482e-06,
      "loss": 0.0252,
      "step": 154520
    },
    {
      "epoch": 18.618072289156625,
      "grad_norm": 0.0001171957264887169,
      "learning_rate": 1.3819277108433738e-06,
      "loss": 0.0042,
      "step": 154530
    },
    {
      "epoch": 18.619277108433735,
      "grad_norm": 0.0013193045742809772,
      "learning_rate": 1.3807228915662651e-06,
      "loss": 0.0007,
      "step": 154540
    },
    {
      "epoch": 18.620481927710845,
      "grad_norm": 0.000108302068838384,
      "learning_rate": 1.379518072289157e-06,
      "loss": 0.0055,
      "step": 154550
    },
    {
      "epoch": 18.62168674698795,
      "grad_norm": 0.8775126338005066,
      "learning_rate": 1.3783132530120483e-06,
      "loss": 0.0129,
      "step": 154560
    },
    {
      "epoch": 18.62289156626506,
      "grad_norm": 0.00015247781993821263,
      "learning_rate": 1.37710843373494e-06,
      "loss": 0.0304,
      "step": 154570
    },
    {
      "epoch": 18.62409638554217,
      "grad_norm": 0.8825298547744751,
      "learning_rate": 1.3759036144578315e-06,
      "loss": 0.0143,
      "step": 154580
    },
    {
      "epoch": 18.625301204819277,
      "grad_norm": 1.0930637121200562,
      "learning_rate": 1.374698795180723e-06,
      "loss": 0.0072,
      "step": 154590
    },
    {
      "epoch": 18.626506024096386,
      "grad_norm": 0.8222224116325378,
      "learning_rate": 1.3734939759036144e-06,
      "loss": 0.0188,
      "step": 154600
    },
    {
      "epoch": 18.627710843373492,
      "grad_norm": 0.00016078376211225986,
      "learning_rate": 1.3722891566265062e-06,
      "loss": 0.0009,
      "step": 154610
    },
    {
      "epoch": 18.628915662650602,
      "grad_norm": 8.695456926943734e-05,
      "learning_rate": 1.3710843373493976e-06,
      "loss": 0.014,
      "step": 154620
    },
    {
      "epoch": 18.63012048192771,
      "grad_norm": 0.0007533192401751876,
      "learning_rate": 1.3698795180722892e-06,
      "loss": 0.0082,
      "step": 154630
    },
    {
      "epoch": 18.631325301204818,
      "grad_norm": 0.00014441674284171313,
      "learning_rate": 1.3686746987951808e-06,
      "loss": 0.0077,
      "step": 154640
    },
    {
      "epoch": 18.632530120481928,
      "grad_norm": 0.00016689124458935112,
      "learning_rate": 1.3674698795180724e-06,
      "loss": 0.0086,
      "step": 154650
    },
    {
      "epoch": 18.633734939759037,
      "grad_norm": 0.7018725872039795,
      "learning_rate": 1.3662650602409638e-06,
      "loss": 0.0059,
      "step": 154660
    },
    {
      "epoch": 18.634939759036143,
      "grad_norm": 0.00012532714754343033,
      "learning_rate": 1.3650602409638556e-06,
      "loss": 0.0131,
      "step": 154670
    },
    {
      "epoch": 18.636144578313253,
      "grad_norm": 9.8427728516981e-05,
      "learning_rate": 1.3638554216867472e-06,
      "loss": 0.0024,
      "step": 154680
    },
    {
      "epoch": 18.637349397590363,
      "grad_norm": 0.00041819989564828575,
      "learning_rate": 1.3626506024096387e-06,
      "loss": 0.0093,
      "step": 154690
    },
    {
      "epoch": 18.63855421686747,
      "grad_norm": 7.978241774253547e-05,
      "learning_rate": 1.3614457831325303e-06,
      "loss": 0.0106,
      "step": 154700
    },
    {
      "epoch": 18.63975903614458,
      "grad_norm": 8.421143866144121e-05,
      "learning_rate": 1.3602409638554217e-06,
      "loss": 0.0104,
      "step": 154710
    },
    {
      "epoch": 18.64096385542169,
      "grad_norm": 1.6071815490722656,
      "learning_rate": 1.3590361445783135e-06,
      "loss": 0.03,
      "step": 154720
    },
    {
      "epoch": 18.642168674698794,
      "grad_norm": 40.92107391357422,
      "learning_rate": 1.3578313253012049e-06,
      "loss": 0.0093,
      "step": 154730
    },
    {
      "epoch": 18.643373493975904,
      "grad_norm": 0.5540486574172974,
      "learning_rate": 1.3566265060240965e-06,
      "loss": 0.0087,
      "step": 154740
    },
    {
      "epoch": 18.644578313253014,
      "grad_norm": 0.00013243063585832715,
      "learning_rate": 1.355421686746988e-06,
      "loss": 0.0058,
      "step": 154750
    },
    {
      "epoch": 18.64578313253012,
      "grad_norm": 0.003527505788952112,
      "learning_rate": 1.3542168674698796e-06,
      "loss": 0.0089,
      "step": 154760
    },
    {
      "epoch": 18.64698795180723,
      "grad_norm": 0.0005647201323881745,
      "learning_rate": 1.353012048192771e-06,
      "loss": 0.0152,
      "step": 154770
    },
    {
      "epoch": 18.648192771084336,
      "grad_norm": 0.8098670840263367,
      "learning_rate": 1.3518072289156628e-06,
      "loss": 0.0172,
      "step": 154780
    },
    {
      "epoch": 18.649397590361446,
      "grad_norm": 0.0013278162805363536,
      "learning_rate": 1.3506024096385542e-06,
      "loss": 0.0296,
      "step": 154790
    },
    {
      "epoch": 18.650602409638555,
      "grad_norm": 0.0017262821784242988,
      "learning_rate": 1.349397590361446e-06,
      "loss": 0.0031,
      "step": 154800
    },
    {
      "epoch": 18.65180722891566,
      "grad_norm": 0.004389604087918997,
      "learning_rate": 1.3481927710843374e-06,
      "loss": 0.0022,
      "step": 154810
    },
    {
      "epoch": 18.65301204819277,
      "grad_norm": 0.819959282875061,
      "learning_rate": 1.346987951807229e-06,
      "loss": 0.0123,
      "step": 154820
    },
    {
      "epoch": 18.65421686746988,
      "grad_norm": 0.00012896042608190328,
      "learning_rate": 1.3457831325301208e-06,
      "loss": 0.0137,
      "step": 154830
    },
    {
      "epoch": 18.655421686746987,
      "grad_norm": 0.00010821651085279882,
      "learning_rate": 1.3445783132530121e-06,
      "loss": 0.0119,
      "step": 154840
    },
    {
      "epoch": 18.656626506024097,
      "grad_norm": 0.0994701236486435,
      "learning_rate": 1.3433734939759037e-06,
      "loss": 0.0133,
      "step": 154850
    },
    {
      "epoch": 18.657831325301206,
      "grad_norm": 0.287030965089798,
      "learning_rate": 1.3421686746987953e-06,
      "loss": 0.003,
      "step": 154860
    },
    {
      "epoch": 18.659036144578312,
      "grad_norm": 1.065470576286316,
      "learning_rate": 1.340963855421687e-06,
      "loss": 0.0256,
      "step": 154870
    },
    {
      "epoch": 18.660240963855422,
      "grad_norm": 6.9508416345343e-05,
      "learning_rate": 1.3397590361445783e-06,
      "loss": 0.0125,
      "step": 154880
    },
    {
      "epoch": 18.66144578313253,
      "grad_norm": 7.637503586011007e-05,
      "learning_rate": 1.33855421686747e-06,
      "loss": 0.0076,
      "step": 154890
    },
    {
      "epoch": 18.662650602409638,
      "grad_norm": 0.00020764078362844884,
      "learning_rate": 1.3373493975903615e-06,
      "loss": 0.0073,
      "step": 154900
    },
    {
      "epoch": 18.663855421686748,
      "grad_norm": 0.0002845061244443059,
      "learning_rate": 1.3361445783132533e-06,
      "loss": 0.0051,
      "step": 154910
    },
    {
      "epoch": 18.665060240963854,
      "grad_norm": 0.756568193435669,
      "learning_rate": 1.3349397590361446e-06,
      "loss": 0.0145,
      "step": 154920
    },
    {
      "epoch": 18.666265060240963,
      "grad_norm": 0.3658480942249298,
      "learning_rate": 1.3337349397590362e-06,
      "loss": 0.0855,
      "step": 154930
    },
    {
      "epoch": 18.667469879518073,
      "grad_norm": 0.9350509643554688,
      "learning_rate": 1.3325301204819278e-06,
      "loss": 0.0198,
      "step": 154940
    },
    {
      "epoch": 18.66867469879518,
      "grad_norm": 0.1836157888174057,
      "learning_rate": 1.3313253012048194e-06,
      "loss": 0.0068,
      "step": 154950
    },
    {
      "epoch": 18.66987951807229,
      "grad_norm": 0.0001645132142584771,
      "learning_rate": 1.3301204819277108e-06,
      "loss": 0.0077,
      "step": 154960
    },
    {
      "epoch": 18.6710843373494,
      "grad_norm": 0.00011885337880812585,
      "learning_rate": 1.3289156626506026e-06,
      "loss": 0.0051,
      "step": 154970
    },
    {
      "epoch": 18.672289156626505,
      "grad_norm": 0.30026593804359436,
      "learning_rate": 1.3277108433734942e-06,
      "loss": 0.0131,
      "step": 154980
    },
    {
      "epoch": 18.673493975903614,
      "grad_norm": 0.00015485544281546026,
      "learning_rate": 1.3265060240963855e-06,
      "loss": 0.0258,
      "step": 154990
    },
    {
      "epoch": 18.674698795180724,
      "grad_norm": 0.00012675208563450724,
      "learning_rate": 1.3253012048192773e-06,
      "loss": 0.0135,
      "step": 155000
    },
    {
      "epoch": 18.67590361445783,
      "grad_norm": 0.00010314073733752593,
      "learning_rate": 1.3240963855421687e-06,
      "loss": 0.0034,
      "step": 155010
    },
    {
      "epoch": 18.67710843373494,
      "grad_norm": 0.000174886648892425,
      "learning_rate": 1.3228915662650605e-06,
      "loss": 0.0013,
      "step": 155020
    },
    {
      "epoch": 18.67831325301205,
      "grad_norm": 0.0007130057783797383,
      "learning_rate": 1.3216867469879519e-06,
      "loss": 0.015,
      "step": 155030
    },
    {
      "epoch": 18.679518072289156,
      "grad_norm": 0.30101943016052246,
      "learning_rate": 1.3204819277108435e-06,
      "loss": 0.0062,
      "step": 155040
    },
    {
      "epoch": 18.680722891566266,
      "grad_norm": 0.4189194440841675,
      "learning_rate": 1.319277108433735e-06,
      "loss": 0.0168,
      "step": 155050
    },
    {
      "epoch": 18.681927710843375,
      "grad_norm": 0.00011925485159736127,
      "learning_rate": 1.3180722891566267e-06,
      "loss": 0.0209,
      "step": 155060
    },
    {
      "epoch": 18.68313253012048,
      "grad_norm": 0.4684191048145294,
      "learning_rate": 1.316867469879518e-06,
      "loss": 0.0061,
      "step": 155070
    },
    {
      "epoch": 18.68433734939759,
      "grad_norm": 0.00030071247601881623,
      "learning_rate": 1.3156626506024098e-06,
      "loss": 0.0057,
      "step": 155080
    },
    {
      "epoch": 18.685542168674697,
      "grad_norm": 0.001162674743682146,
      "learning_rate": 1.3144578313253012e-06,
      "loss": 0.0078,
      "step": 155090
    },
    {
      "epoch": 18.686746987951807,
      "grad_norm": 0.1940654069185257,
      "learning_rate": 1.3132530120481928e-06,
      "loss": 0.0076,
      "step": 155100
    },
    {
      "epoch": 18.687951807228917,
      "grad_norm": 0.0003357628302183002,
      "learning_rate": 1.3120481927710846e-06,
      "loss": 0.039,
      "step": 155110
    },
    {
      "epoch": 18.689156626506023,
      "grad_norm": 0.00016777124255895615,
      "learning_rate": 1.310843373493976e-06,
      "loss": 0.0102,
      "step": 155120
    },
    {
      "epoch": 18.690361445783132,
      "grad_norm": 0.3073407709598541,
      "learning_rate": 1.3096385542168678e-06,
      "loss": 0.0117,
      "step": 155130
    },
    {
      "epoch": 18.691566265060242,
      "grad_norm": 1.8025164604187012,
      "learning_rate": 1.3084337349397591e-06,
      "loss": 0.02,
      "step": 155140
    },
    {
      "epoch": 18.69277108433735,
      "grad_norm": 0.00012072852405253798,
      "learning_rate": 1.3072289156626507e-06,
      "loss": 0.0039,
      "step": 155150
    },
    {
      "epoch": 18.693975903614458,
      "grad_norm": 0.00044043781235814095,
      "learning_rate": 1.3060240963855423e-06,
      "loss": 0.0102,
      "step": 155160
    },
    {
      "epoch": 18.695180722891568,
      "grad_norm": 0.27144965529441833,
      "learning_rate": 1.304819277108434e-06,
      "loss": 0.0153,
      "step": 155170
    },
    {
      "epoch": 18.696385542168674,
      "grad_norm": 0.00018267818086314946,
      "learning_rate": 1.3036144578313253e-06,
      "loss": 0.0033,
      "step": 155180
    },
    {
      "epoch": 18.697590361445783,
      "grad_norm": 0.9035751819610596,
      "learning_rate": 1.302409638554217e-06,
      "loss": 0.0073,
      "step": 155190
    },
    {
      "epoch": 18.698795180722893,
      "grad_norm": 0.2591160237789154,
      "learning_rate": 1.3012048192771085e-06,
      "loss": 0.0156,
      "step": 155200
    },
    {
      "epoch": 18.7,
      "grad_norm": 1.2673543691635132,
      "learning_rate": 1.3e-06,
      "loss": 0.0249,
      "step": 155210
    },
    {
      "epoch": 18.70120481927711,
      "grad_norm": 7.787079084664583e-05,
      "learning_rate": 1.2987951807228916e-06,
      "loss": 0.0098,
      "step": 155220
    },
    {
      "epoch": 18.702409638554215,
      "grad_norm": 9.939930896507576e-05,
      "learning_rate": 1.2975903614457832e-06,
      "loss": 0.0044,
      "step": 155230
    },
    {
      "epoch": 18.703614457831325,
      "grad_norm": 0.00022282759891822934,
      "learning_rate": 1.2963855421686746e-06,
      "loss": 0.0202,
      "step": 155240
    },
    {
      "epoch": 18.704819277108435,
      "grad_norm": 0.0033317029010504484,
      "learning_rate": 1.2951807228915664e-06,
      "loss": 0.0001,
      "step": 155250
    },
    {
      "epoch": 18.70602409638554,
      "grad_norm": 0.8871192932128906,
      "learning_rate": 1.293975903614458e-06,
      "loss": 0.0288,
      "step": 155260
    },
    {
      "epoch": 18.70722891566265,
      "grad_norm": 1.0106755495071411,
      "learning_rate": 1.2927710843373496e-06,
      "loss": 0.0273,
      "step": 155270
    },
    {
      "epoch": 18.70843373493976,
      "grad_norm": 0.00011374492169125006,
      "learning_rate": 1.2915662650602412e-06,
      "loss": 0.004,
      "step": 155280
    },
    {
      "epoch": 18.709638554216866,
      "grad_norm": 0.0023216584231704473,
      "learning_rate": 1.2903614457831325e-06,
      "loss": 0.0082,
      "step": 155290
    },
    {
      "epoch": 18.710843373493976,
      "grad_norm": 0.00012541421165224165,
      "learning_rate": 1.2891566265060243e-06,
      "loss": 0.0054,
      "step": 155300
    },
    {
      "epoch": 18.712048192771086,
      "grad_norm": 0.00025141207152046263,
      "learning_rate": 1.2879518072289157e-06,
      "loss": 0.0019,
      "step": 155310
    },
    {
      "epoch": 18.71325301204819,
      "grad_norm": 0.0002093806688208133,
      "learning_rate": 1.2867469879518075e-06,
      "loss": 0.0008,
      "step": 155320
    },
    {
      "epoch": 18.7144578313253,
      "grad_norm": 0.00011212299432372674,
      "learning_rate": 1.2855421686746989e-06,
      "loss": 0.0318,
      "step": 155330
    },
    {
      "epoch": 18.71566265060241,
      "grad_norm": 0.24592724442481995,
      "learning_rate": 1.2843373493975905e-06,
      "loss": 0.0102,
      "step": 155340
    },
    {
      "epoch": 18.716867469879517,
      "grad_norm": 0.508912205696106,
      "learning_rate": 1.2831325301204819e-06,
      "loss": 0.0249,
      "step": 155350
    },
    {
      "epoch": 18.718072289156627,
      "grad_norm": 5.841076927026734e-05,
      "learning_rate": 1.2819277108433737e-06,
      "loss": 0.009,
      "step": 155360
    },
    {
      "epoch": 18.719277108433737,
      "grad_norm": 0.00010818523878697306,
      "learning_rate": 1.280722891566265e-06,
      "loss": 0.0244,
      "step": 155370
    },
    {
      "epoch": 18.720481927710843,
      "grad_norm": 0.00015619648911524564,
      "learning_rate": 1.2795180722891568e-06,
      "loss": 0.0068,
      "step": 155380
    },
    {
      "epoch": 18.721686746987952,
      "grad_norm": 8.212291868403554e-05,
      "learning_rate": 1.2783132530120482e-06,
      "loss": 0.0029,
      "step": 155390
    },
    {
      "epoch": 18.72289156626506,
      "grad_norm": 0.0001088788703782484,
      "learning_rate": 1.2771084337349398e-06,
      "loss": 0.0073,
      "step": 155400
    },
    {
      "epoch": 18.72409638554217,
      "grad_norm": 7.245364395203069e-05,
      "learning_rate": 1.2759036144578316e-06,
      "loss": 0.0183,
      "step": 155410
    },
    {
      "epoch": 18.725301204819278,
      "grad_norm": 2.0285634994506836,
      "learning_rate": 1.274698795180723e-06,
      "loss": 0.0252,
      "step": 155420
    },
    {
      "epoch": 18.726506024096384,
      "grad_norm": 1.231384038925171,
      "learning_rate": 1.2734939759036148e-06,
      "loss": 0.0085,
      "step": 155430
    },
    {
      "epoch": 18.727710843373494,
      "grad_norm": 0.6202056407928467,
      "learning_rate": 1.2722891566265061e-06,
      "loss": 0.0057,
      "step": 155440
    },
    {
      "epoch": 18.728915662650603,
      "grad_norm": 0.001621778472326696,
      "learning_rate": 1.2710843373493977e-06,
      "loss": 0.0103,
      "step": 155450
    },
    {
      "epoch": 18.73012048192771,
      "grad_norm": 5.999839413561858e-05,
      "learning_rate": 1.2698795180722891e-06,
      "loss": 0.0247,
      "step": 155460
    },
    {
      "epoch": 18.73132530120482,
      "grad_norm": 0.00010078267951030284,
      "learning_rate": 1.268674698795181e-06,
      "loss": 0.0196,
      "step": 155470
    },
    {
      "epoch": 18.73253012048193,
      "grad_norm": 0.5470742583274841,
      "learning_rate": 1.2674698795180723e-06,
      "loss": 0.0058,
      "step": 155480
    },
    {
      "epoch": 18.733734939759035,
      "grad_norm": 0.00011588577763177454,
      "learning_rate": 1.266265060240964e-06,
      "loss": 0.0192,
      "step": 155490
    },
    {
      "epoch": 18.734939759036145,
      "grad_norm": 0.509756326675415,
      "learning_rate": 1.2650602409638555e-06,
      "loss": 0.0112,
      "step": 155500
    },
    {
      "epoch": 18.736144578313255,
      "grad_norm": 0.0001455607416573912,
      "learning_rate": 1.263855421686747e-06,
      "loss": 0.0055,
      "step": 155510
    },
    {
      "epoch": 18.73734939759036,
      "grad_norm": 0.00010095882316818461,
      "learning_rate": 1.2626506024096386e-06,
      "loss": 0.0,
      "step": 155520
    },
    {
      "epoch": 18.73855421686747,
      "grad_norm": 0.25210121273994446,
      "learning_rate": 1.2614457831325302e-06,
      "loss": 0.0042,
      "step": 155530
    },
    {
      "epoch": 18.739759036144576,
      "grad_norm": 0.0015721956733614206,
      "learning_rate": 1.2602409638554216e-06,
      "loss": 0.0263,
      "step": 155540
    },
    {
      "epoch": 18.740963855421686,
      "grad_norm": 0.0007281077560037374,
      "learning_rate": 1.2590361445783134e-06,
      "loss": 0.0036,
      "step": 155550
    },
    {
      "epoch": 18.742168674698796,
      "grad_norm": 0.8004240989685059,
      "learning_rate": 1.257831325301205e-06,
      "loss": 0.0145,
      "step": 155560
    },
    {
      "epoch": 18.743373493975902,
      "grad_norm": 0.9754727482795715,
      "learning_rate": 1.2566265060240964e-06,
      "loss": 0.0051,
      "step": 155570
    },
    {
      "epoch": 18.74457831325301,
      "grad_norm": 0.2194228321313858,
      "learning_rate": 1.2554216867469882e-06,
      "loss": 0.0082,
      "step": 155580
    },
    {
      "epoch": 18.74578313253012,
      "grad_norm": 0.2496432214975357,
      "learning_rate": 1.2542168674698795e-06,
      "loss": 0.0041,
      "step": 155590
    },
    {
      "epoch": 18.746987951807228,
      "grad_norm": 0.0001398229505866766,
      "learning_rate": 1.2530120481927713e-06,
      "loss": 0.0122,
      "step": 155600
    },
    {
      "epoch": 18.748192771084337,
      "grad_norm": 0.00014129224291536957,
      "learning_rate": 1.2518072289156627e-06,
      "loss": 0.0051,
      "step": 155610
    },
    {
      "epoch": 18.749397590361447,
      "grad_norm": 0.8896809816360474,
      "learning_rate": 1.2506024096385543e-06,
      "loss": 0.0125,
      "step": 155620
    },
    {
      "epoch": 18.750602409638553,
      "grad_norm": 0.0008258021553047001,
      "learning_rate": 1.249397590361446e-06,
      "loss": 0.006,
      "step": 155630
    },
    {
      "epoch": 18.751807228915663,
      "grad_norm": 0.7466492652893066,
      "learning_rate": 1.2481927710843375e-06,
      "loss": 0.0124,
      "step": 155640
    },
    {
      "epoch": 18.753012048192772,
      "grad_norm": 0.00015060824807733297,
      "learning_rate": 1.246987951807229e-06,
      "loss": 0.0307,
      "step": 155650
    },
    {
      "epoch": 18.75421686746988,
      "grad_norm": 7.135383202694356e-05,
      "learning_rate": 1.2457831325301207e-06,
      "loss": 0.0068,
      "step": 155660
    },
    {
      "epoch": 18.75542168674699,
      "grad_norm": 0.00020454195328056812,
      "learning_rate": 1.2445783132530122e-06,
      "loss": 0.0097,
      "step": 155670
    },
    {
      "epoch": 18.756626506024098,
      "grad_norm": 1.3581345081329346,
      "learning_rate": 1.2433734939759038e-06,
      "loss": 0.0231,
      "step": 155680
    },
    {
      "epoch": 18.757831325301204,
      "grad_norm": 0.6855908632278442,
      "learning_rate": 1.2421686746987952e-06,
      "loss": 0.014,
      "step": 155690
    },
    {
      "epoch": 18.759036144578314,
      "grad_norm": 0.9352748394012451,
      "learning_rate": 1.2409638554216868e-06,
      "loss": 0.0105,
      "step": 155700
    },
    {
      "epoch": 18.760240963855424,
      "grad_norm": 7.64963187975809e-05,
      "learning_rate": 1.2397590361445784e-06,
      "loss": 0.0188,
      "step": 155710
    },
    {
      "epoch": 18.76144578313253,
      "grad_norm": 4.802499825018458e-05,
      "learning_rate": 1.23855421686747e-06,
      "loss": 0.001,
      "step": 155720
    },
    {
      "epoch": 18.76265060240964,
      "grad_norm": 0.6787408590316772,
      "learning_rate": 1.2373493975903616e-06,
      "loss": 0.0029,
      "step": 155730
    },
    {
      "epoch": 18.763855421686745,
      "grad_norm": 0.00011980779527220875,
      "learning_rate": 1.2361445783132532e-06,
      "loss": 0.0119,
      "step": 155740
    },
    {
      "epoch": 18.765060240963855,
      "grad_norm": 0.00013367075007408857,
      "learning_rate": 1.2349397590361445e-06,
      "loss": 0.0039,
      "step": 155750
    },
    {
      "epoch": 18.766265060240965,
      "grad_norm": 0.2483271360397339,
      "learning_rate": 1.2337349397590361e-06,
      "loss": 0.0048,
      "step": 155760
    },
    {
      "epoch": 18.76746987951807,
      "grad_norm": 6.770937761757523e-05,
      "learning_rate": 1.2325301204819277e-06,
      "loss": 0.0354,
      "step": 155770
    },
    {
      "epoch": 18.76867469879518,
      "grad_norm": 1.9385288953781128,
      "learning_rate": 1.2313253012048195e-06,
      "loss": 0.0287,
      "step": 155780
    },
    {
      "epoch": 18.76987951807229,
      "grad_norm": 0.0003743817505892366,
      "learning_rate": 1.230120481927711e-06,
      "loss": 0.0,
      "step": 155790
    },
    {
      "epoch": 18.771084337349397,
      "grad_norm": 1.9384489059448242,
      "learning_rate": 1.2289156626506025e-06,
      "loss": 0.0108,
      "step": 155800
    },
    {
      "epoch": 18.772289156626506,
      "grad_norm": 6.153754657134414e-05,
      "learning_rate": 1.227710843373494e-06,
      "loss": 0.0052,
      "step": 155810
    },
    {
      "epoch": 18.773493975903616,
      "grad_norm": 0.0006396541139110923,
      "learning_rate": 1.2265060240963856e-06,
      "loss": 0.0004,
      "step": 155820
    },
    {
      "epoch": 18.774698795180722,
      "grad_norm": 0.0003656902408692986,
      "learning_rate": 1.2253012048192772e-06,
      "loss": 0.0211,
      "step": 155830
    },
    {
      "epoch": 18.77590361445783,
      "grad_norm": 0.0003476905112620443,
      "learning_rate": 1.2240963855421688e-06,
      "loss": 0.0061,
      "step": 155840
    },
    {
      "epoch": 18.77710843373494,
      "grad_norm": 0.0002067691966658458,
      "learning_rate": 1.2228915662650604e-06,
      "loss": 0.0087,
      "step": 155850
    },
    {
      "epoch": 18.778313253012048,
      "grad_norm": 8.823134703561664e-05,
      "learning_rate": 1.221686746987952e-06,
      "loss": 0.0122,
      "step": 155860
    },
    {
      "epoch": 18.779518072289157,
      "grad_norm": 0.000785809475928545,
      "learning_rate": 1.2204819277108434e-06,
      "loss": 0.0101,
      "step": 155870
    },
    {
      "epoch": 18.780722891566263,
      "grad_norm": 0.2728610932826996,
      "learning_rate": 1.219277108433735e-06,
      "loss": 0.0083,
      "step": 155880
    },
    {
      "epoch": 18.781927710843373,
      "grad_norm": 0.9836369156837463,
      "learning_rate": 1.2180722891566265e-06,
      "loss": 0.0078,
      "step": 155890
    },
    {
      "epoch": 18.783132530120483,
      "grad_norm": 7.807133806636557e-05,
      "learning_rate": 1.2168674698795181e-06,
      "loss": 0.0109,
      "step": 155900
    },
    {
      "epoch": 18.78433734939759,
      "grad_norm": 0.9401523470878601,
      "learning_rate": 1.2156626506024097e-06,
      "loss": 0.0051,
      "step": 155910
    },
    {
      "epoch": 18.7855421686747,
      "grad_norm": 0.00011246661597397178,
      "learning_rate": 1.2144578313253013e-06,
      "loss": 0.0016,
      "step": 155920
    },
    {
      "epoch": 18.78674698795181,
      "grad_norm": 0.2406759262084961,
      "learning_rate": 1.213253012048193e-06,
      "loss": 0.0036,
      "step": 155930
    },
    {
      "epoch": 18.787951807228914,
      "grad_norm": 8.778352639637887e-05,
      "learning_rate": 1.2120481927710845e-06,
      "loss": 0.0009,
      "step": 155940
    },
    {
      "epoch": 18.789156626506024,
      "grad_norm": 8.634541882202029e-05,
      "learning_rate": 1.210843373493976e-06,
      "loss": 0.003,
      "step": 155950
    },
    {
      "epoch": 18.790361445783134,
      "grad_norm": 0.00010049984120996669,
      "learning_rate": 1.2096385542168677e-06,
      "loss": 0.0013,
      "step": 155960
    },
    {
      "epoch": 18.79156626506024,
      "grad_norm": 1.875796914100647,
      "learning_rate": 1.2084337349397593e-06,
      "loss": 0.0579,
      "step": 155970
    },
    {
      "epoch": 18.79277108433735,
      "grad_norm": 0.000153573855641298,
      "learning_rate": 1.2072289156626506e-06,
      "loss": 0.0104,
      "step": 155980
    },
    {
      "epoch": 18.79397590361446,
      "grad_norm": 7.965193799464032e-05,
      "learning_rate": 1.2060240963855422e-06,
      "loss": 0.012,
      "step": 155990
    },
    {
      "epoch": 18.795180722891565,
      "grad_norm": 1.9402203559875488,
      "learning_rate": 1.2048192771084338e-06,
      "loss": 0.0114,
      "step": 156000
    },
    {
      "epoch": 18.796385542168675,
      "grad_norm": 0.00021421747806016356,
      "learning_rate": 1.2036144578313254e-06,
      "loss": 0.0005,
      "step": 156010
    },
    {
      "epoch": 18.797590361445785,
      "grad_norm": 0.18478718400001526,
      "learning_rate": 1.202409638554217e-06,
      "loss": 0.0053,
      "step": 156020
    },
    {
      "epoch": 18.79879518072289,
      "grad_norm": 0.0001025279561872594,
      "learning_rate": 1.2012048192771086e-06,
      "loss": 0.0237,
      "step": 156030
    },
    {
      "epoch": 18.8,
      "grad_norm": 9.040981240104884e-05,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.0041,
      "step": 156040
    },
    {
      "epoch": 18.801204819277107,
      "grad_norm": 0.0001995727652683854,
      "learning_rate": 1.1987951807228915e-06,
      "loss": 0.0142,
      "step": 156050
    },
    {
      "epoch": 18.802409638554217,
      "grad_norm": 8.152507507475093e-05,
      "learning_rate": 1.1975903614457831e-06,
      "loss": 0.0136,
      "step": 156060
    },
    {
      "epoch": 18.803614457831326,
      "grad_norm": 7.402409391943365e-05,
      "learning_rate": 1.196385542168675e-06,
      "loss": 0.0172,
      "step": 156070
    },
    {
      "epoch": 18.804819277108432,
      "grad_norm": 0.00010185687278863043,
      "learning_rate": 1.1951807228915665e-06,
      "loss": 0.0098,
      "step": 156080
    },
    {
      "epoch": 18.806024096385542,
      "grad_norm": 0.00013490351557265967,
      "learning_rate": 1.1939759036144579e-06,
      "loss": 0.0065,
      "step": 156090
    },
    {
      "epoch": 18.80722891566265,
      "grad_norm": 7.792233373038471e-05,
      "learning_rate": 1.1927710843373495e-06,
      "loss": 0.0089,
      "step": 156100
    },
    {
      "epoch": 18.808433734939758,
      "grad_norm": 0.016514329239726067,
      "learning_rate": 1.191566265060241e-06,
      "loss": 0.0311,
      "step": 156110
    },
    {
      "epoch": 18.809638554216868,
      "grad_norm": 0.00012454837269615382,
      "learning_rate": 1.1903614457831326e-06,
      "loss": 0.0038,
      "step": 156120
    },
    {
      "epoch": 18.810843373493977,
      "grad_norm": 0.00023065455025061965,
      "learning_rate": 1.1891566265060242e-06,
      "loss": 0.0148,
      "step": 156130
    },
    {
      "epoch": 18.812048192771083,
      "grad_norm": 0.21315330266952515,
      "learning_rate": 1.1879518072289158e-06,
      "loss": 0.008,
      "step": 156140
    },
    {
      "epoch": 18.813253012048193,
      "grad_norm": 7.798721344443038e-05,
      "learning_rate": 1.1867469879518074e-06,
      "loss": 0.0072,
      "step": 156150
    },
    {
      "epoch": 18.814457831325303,
      "grad_norm": 0.18590742349624634,
      "learning_rate": 1.1855421686746988e-06,
      "loss": 0.0126,
      "step": 156160
    },
    {
      "epoch": 18.81566265060241,
      "grad_norm": 0.00013285811292007565,
      "learning_rate": 1.1843373493975904e-06,
      "loss": 0.0053,
      "step": 156170
    },
    {
      "epoch": 18.81686746987952,
      "grad_norm": 1.0373705625534058,
      "learning_rate": 1.183132530120482e-06,
      "loss": 0.0099,
      "step": 156180
    },
    {
      "epoch": 18.818072289156625,
      "grad_norm": 0.12422939389944077,
      "learning_rate": 1.1819277108433736e-06,
      "loss": 0.0088,
      "step": 156190
    },
    {
      "epoch": 18.819277108433734,
      "grad_norm": 0.0027359335217624903,
      "learning_rate": 1.1807228915662651e-06,
      "loss": 0.0119,
      "step": 156200
    },
    {
      "epoch": 18.820481927710844,
      "grad_norm": 6.492436659755185e-05,
      "learning_rate": 1.1795180722891567e-06,
      "loss": 0.044,
      "step": 156210
    },
    {
      "epoch": 18.82168674698795,
      "grad_norm": 0.9630367755889893,
      "learning_rate": 1.1783132530120483e-06,
      "loss": 0.0153,
      "step": 156220
    },
    {
      "epoch": 18.82289156626506,
      "grad_norm": 0.00017491112521383911,
      "learning_rate": 1.17710843373494e-06,
      "loss": 0.0356,
      "step": 156230
    },
    {
      "epoch": 18.82409638554217,
      "grad_norm": 0.00010432382259750739,
      "learning_rate": 1.1759036144578315e-06,
      "loss": 0.0247,
      "step": 156240
    },
    {
      "epoch": 18.825301204819276,
      "grad_norm": 0.00011169629578944296,
      "learning_rate": 1.174698795180723e-06,
      "loss": 0.0004,
      "step": 156250
    },
    {
      "epoch": 18.826506024096386,
      "grad_norm": 0.7487167716026306,
      "learning_rate": 1.1734939759036147e-06,
      "loss": 0.0164,
      "step": 156260
    },
    {
      "epoch": 18.827710843373495,
      "grad_norm": 0.00020419093198142946,
      "learning_rate": 1.172289156626506e-06,
      "loss": 0.0151,
      "step": 156270
    },
    {
      "epoch": 18.8289156626506,
      "grad_norm": 0.00011800560605479404,
      "learning_rate": 1.1710843373493976e-06,
      "loss": 0.0119,
      "step": 156280
    },
    {
      "epoch": 18.83012048192771,
      "grad_norm": 0.00015607888053636998,
      "learning_rate": 1.1698795180722892e-06,
      "loss": 0.0004,
      "step": 156290
    },
    {
      "epoch": 18.83132530120482,
      "grad_norm": 0.00012107453949283808,
      "learning_rate": 1.1686746987951808e-06,
      "loss": 0.0149,
      "step": 156300
    },
    {
      "epoch": 18.832530120481927,
      "grad_norm": 0.01627921313047409,
      "learning_rate": 1.1674698795180724e-06,
      "loss": 0.0036,
      "step": 156310
    },
    {
      "epoch": 18.833734939759037,
      "grad_norm": 0.8811402916908264,
      "learning_rate": 1.166265060240964e-06,
      "loss": 0.0216,
      "step": 156320
    },
    {
      "epoch": 18.834939759036146,
      "grad_norm": 8.76286649145186e-05,
      "learning_rate": 1.1650602409638556e-06,
      "loss": 0.0163,
      "step": 156330
    },
    {
      "epoch": 18.836144578313252,
      "grad_norm": 1.8288084268569946,
      "learning_rate": 1.163855421686747e-06,
      "loss": 0.0117,
      "step": 156340
    },
    {
      "epoch": 18.837349397590362,
      "grad_norm": 0.0001433851575711742,
      "learning_rate": 1.1626506024096385e-06,
      "loss": 0.0028,
      "step": 156350
    },
    {
      "epoch": 18.83855421686747,
      "grad_norm": 0.00017869009752757847,
      "learning_rate": 1.1614457831325301e-06,
      "loss": 0.0037,
      "step": 156360
    },
    {
      "epoch": 18.839759036144578,
      "grad_norm": 0.00027976863202638924,
      "learning_rate": 1.160240963855422e-06,
      "loss": 0.0118,
      "step": 156370
    },
    {
      "epoch": 18.840963855421688,
      "grad_norm": 9.687140118330717e-05,
      "learning_rate": 1.1590361445783133e-06,
      "loss": 0.0116,
      "step": 156380
    },
    {
      "epoch": 18.842168674698794,
      "grad_norm": 0.0004665586748160422,
      "learning_rate": 1.1578313253012049e-06,
      "loss": 0.0032,
      "step": 156390
    },
    {
      "epoch": 18.843373493975903,
      "grad_norm": 0.00011168168566655368,
      "learning_rate": 1.1566265060240965e-06,
      "loss": 0.009,
      "step": 156400
    },
    {
      "epoch": 18.844578313253013,
      "grad_norm": 0.00013986679550725967,
      "learning_rate": 1.155421686746988e-06,
      "loss": 0.0034,
      "step": 156410
    },
    {
      "epoch": 18.84578313253012,
      "grad_norm": 1.1366467475891113,
      "learning_rate": 1.1542168674698797e-06,
      "loss": 0.0202,
      "step": 156420
    },
    {
      "epoch": 18.84698795180723,
      "grad_norm": 0.1962004005908966,
      "learning_rate": 1.1530120481927712e-06,
      "loss": 0.0106,
      "step": 156430
    },
    {
      "epoch": 18.84819277108434,
      "grad_norm": 0.0009130939142778516,
      "learning_rate": 1.1518072289156628e-06,
      "loss": 0.0154,
      "step": 156440
    },
    {
      "epoch": 18.849397590361445,
      "grad_norm": 0.00013293643132783473,
      "learning_rate": 1.1506024096385542e-06,
      "loss": 0.0033,
      "step": 156450
    },
    {
      "epoch": 18.850602409638554,
      "grad_norm": 1.9446651935577393,
      "learning_rate": 1.1493975903614458e-06,
      "loss": 0.0251,
      "step": 156460
    },
    {
      "epoch": 18.851807228915664,
      "grad_norm": 1.9476667642593384,
      "learning_rate": 1.1481927710843374e-06,
      "loss": 0.0211,
      "step": 156470
    },
    {
      "epoch": 18.85301204819277,
      "grad_norm": 0.000376906682504341,
      "learning_rate": 1.146987951807229e-06,
      "loss": 0.0089,
      "step": 156480
    },
    {
      "epoch": 18.85421686746988,
      "grad_norm": 0.00443264190107584,
      "learning_rate": 1.1457831325301206e-06,
      "loss": 0.0072,
      "step": 156490
    },
    {
      "epoch": 18.855421686746986,
      "grad_norm": 0.26472607254981995,
      "learning_rate": 1.1445783132530121e-06,
      "loss": 0.0081,
      "step": 156500
    },
    {
      "epoch": 18.856626506024096,
      "grad_norm": 0.0001054479944286868,
      "learning_rate": 1.1433734939759037e-06,
      "loss": 0.0301,
      "step": 156510
    },
    {
      "epoch": 18.857831325301206,
      "grad_norm": 1.3884776830673218,
      "learning_rate": 1.1421686746987953e-06,
      "loss": 0.0081,
      "step": 156520
    },
    {
      "epoch": 18.85903614457831,
      "grad_norm": 0.5501270294189453,
      "learning_rate": 1.140963855421687e-06,
      "loss": 0.0045,
      "step": 156530
    },
    {
      "epoch": 18.86024096385542,
      "grad_norm": 0.08629266172647476,
      "learning_rate": 1.1397590361445785e-06,
      "loss": 0.0012,
      "step": 156540
    },
    {
      "epoch": 18.86144578313253,
      "grad_norm": 0.0007221858249977231,
      "learning_rate": 1.13855421686747e-06,
      "loss": 0.0115,
      "step": 156550
    },
    {
      "epoch": 18.862650602409637,
      "grad_norm": 0.00022878510935697705,
      "learning_rate": 1.1373493975903615e-06,
      "loss": 0.0133,
      "step": 156560
    },
    {
      "epoch": 18.863855421686747,
      "grad_norm": 0.0011029778979718685,
      "learning_rate": 1.136144578313253e-06,
      "loss": 0.0142,
      "step": 156570
    },
    {
      "epoch": 18.865060240963857,
      "grad_norm": 0.00013871303235646337,
      "learning_rate": 1.1349397590361446e-06,
      "loss": 0.004,
      "step": 156580
    },
    {
      "epoch": 18.866265060240963,
      "grad_norm": 0.00011562702275114134,
      "learning_rate": 1.1337349397590362e-06,
      "loss": 0.0162,
      "step": 156590
    },
    {
      "epoch": 18.867469879518072,
      "grad_norm": 0.2917218506336212,
      "learning_rate": 1.1325301204819278e-06,
      "loss": 0.0153,
      "step": 156600
    },
    {
      "epoch": 18.868674698795182,
      "grad_norm": 9.728071745485067e-05,
      "learning_rate": 1.1313253012048194e-06,
      "loss": 0.0131,
      "step": 156610
    },
    {
      "epoch": 18.86987951807229,
      "grad_norm": 0.48573288321495056,
      "learning_rate": 1.130120481927711e-06,
      "loss": 0.0018,
      "step": 156620
    },
    {
      "epoch": 18.871084337349398,
      "grad_norm": 0.950218915939331,
      "learning_rate": 1.1289156626506024e-06,
      "loss": 0.0027,
      "step": 156630
    },
    {
      "epoch": 18.872289156626508,
      "grad_norm": 0.8849350214004517,
      "learning_rate": 1.127710843373494e-06,
      "loss": 0.0306,
      "step": 156640
    },
    {
      "epoch": 18.873493975903614,
      "grad_norm": 0.15184004604816437,
      "learning_rate": 1.1265060240963855e-06,
      "loss": 0.018,
      "step": 156650
    },
    {
      "epoch": 18.874698795180723,
      "grad_norm": 9.100640454562381e-05,
      "learning_rate": 1.1253012048192773e-06,
      "loss": 0.0109,
      "step": 156660
    },
    {
      "epoch": 18.87590361445783,
      "grad_norm": 0.00040607526898384094,
      "learning_rate": 1.1240963855421687e-06,
      "loss": 0.0062,
      "step": 156670
    },
    {
      "epoch": 18.87710843373494,
      "grad_norm": 0.0002808386634569615,
      "learning_rate": 1.1228915662650603e-06,
      "loss": 0.0011,
      "step": 156680
    },
    {
      "epoch": 18.87831325301205,
      "grad_norm": 0.0001517154014436528,
      "learning_rate": 1.121686746987952e-06,
      "loss": 0.018,
      "step": 156690
    },
    {
      "epoch": 18.879518072289155,
      "grad_norm": 0.00010500974167371169,
      "learning_rate": 1.1204819277108435e-06,
      "loss": 0.0119,
      "step": 156700
    },
    {
      "epoch": 18.880722891566265,
      "grad_norm": 0.02055998146533966,
      "learning_rate": 1.119277108433735e-06,
      "loss": 0.0267,
      "step": 156710
    },
    {
      "epoch": 18.881927710843375,
      "grad_norm": 7.6786909103393555,
      "learning_rate": 1.1180722891566267e-06,
      "loss": 0.0166,
      "step": 156720
    },
    {
      "epoch": 18.88313253012048,
      "grad_norm": 1.3659378290176392,
      "learning_rate": 1.1168674698795182e-06,
      "loss": 0.006,
      "step": 156730
    },
    {
      "epoch": 18.88433734939759,
      "grad_norm": 8.503225399181247e-05,
      "learning_rate": 1.1156626506024096e-06,
      "loss": 0.009,
      "step": 156740
    },
    {
      "epoch": 18.8855421686747,
      "grad_norm": 1.1815381050109863,
      "learning_rate": 1.1144578313253012e-06,
      "loss": 0.0227,
      "step": 156750
    },
    {
      "epoch": 18.886746987951806,
      "grad_norm": 1.949231743812561,
      "learning_rate": 1.1132530120481928e-06,
      "loss": 0.0238,
      "step": 156760
    },
    {
      "epoch": 18.887951807228916,
      "grad_norm": 0.3432622253894806,
      "learning_rate": 1.1120481927710844e-06,
      "loss": 0.0159,
      "step": 156770
    },
    {
      "epoch": 18.889156626506026,
      "grad_norm": 9.723546099849045e-05,
      "learning_rate": 1.110843373493976e-06,
      "loss": 0.0146,
      "step": 156780
    },
    {
      "epoch": 18.89036144578313,
      "grad_norm": 0.000386403757147491,
      "learning_rate": 1.1096385542168676e-06,
      "loss": 0.0174,
      "step": 156790
    },
    {
      "epoch": 18.89156626506024,
      "grad_norm": 8.908297604648396e-05,
      "learning_rate": 1.1084337349397592e-06,
      "loss": 0.0111,
      "step": 156800
    },
    {
      "epoch": 18.89277108433735,
      "grad_norm": 0.0001130653836298734,
      "learning_rate": 1.1072289156626507e-06,
      "loss": 0.0071,
      "step": 156810
    },
    {
      "epoch": 18.893975903614457,
      "grad_norm": 0.000490733771584928,
      "learning_rate": 1.1060240963855423e-06,
      "loss": 0.0203,
      "step": 156820
    },
    {
      "epoch": 18.895180722891567,
      "grad_norm": 0.00015593731950502843,
      "learning_rate": 1.104819277108434e-06,
      "loss": 0.0148,
      "step": 156830
    },
    {
      "epoch": 18.896385542168673,
      "grad_norm": 0.00035816075978800654,
      "learning_rate": 1.1036144578313255e-06,
      "loss": 0.0041,
      "step": 156840
    },
    {
      "epoch": 18.897590361445783,
      "grad_norm": 1.5342463254928589,
      "learning_rate": 1.1024096385542169e-06,
      "loss": 0.0109,
      "step": 156850
    },
    {
      "epoch": 18.898795180722892,
      "grad_norm": 1.0427807569503784,
      "learning_rate": 1.1012048192771085e-06,
      "loss": 0.0156,
      "step": 156860
    },
    {
      "epoch": 18.9,
      "grad_norm": 0.00011254286800976843,
      "learning_rate": 1.1e-06,
      "loss": 0.003,
      "step": 156870
    },
    {
      "epoch": 18.90120481927711,
      "grad_norm": 0.4417155683040619,
      "learning_rate": 1.0987951807228916e-06,
      "loss": 0.0175,
      "step": 156880
    },
    {
      "epoch": 18.902409638554218,
      "grad_norm": 9.670136932982132e-05,
      "learning_rate": 1.0975903614457832e-06,
      "loss": 0.016,
      "step": 156890
    },
    {
      "epoch": 18.903614457831324,
      "grad_norm": 8.521581185050309e-05,
      "learning_rate": 1.0963855421686748e-06,
      "loss": 0.0112,
      "step": 156900
    },
    {
      "epoch": 18.904819277108434,
      "grad_norm": 0.00029719591839239,
      "learning_rate": 1.0951807228915664e-06,
      "loss": 0.004,
      "step": 156910
    },
    {
      "epoch": 18.906024096385543,
      "grad_norm": 0.8763113021850586,
      "learning_rate": 1.0939759036144578e-06,
      "loss": 0.0128,
      "step": 156920
    },
    {
      "epoch": 18.90722891566265,
      "grad_norm": 7.748780626570806e-05,
      "learning_rate": 1.0927710843373494e-06,
      "loss": 0.0151,
      "step": 156930
    },
    {
      "epoch": 18.90843373493976,
      "grad_norm": 0.000470958388177678,
      "learning_rate": 1.091566265060241e-06,
      "loss": 0.0238,
      "step": 156940
    },
    {
      "epoch": 18.90963855421687,
      "grad_norm": 0.017049947753548622,
      "learning_rate": 1.0903614457831328e-06,
      "loss": 0.0146,
      "step": 156950
    },
    {
      "epoch": 18.910843373493975,
      "grad_norm": 6.836083048256114e-05,
      "learning_rate": 1.0891566265060243e-06,
      "loss": 0.0022,
      "step": 156960
    },
    {
      "epoch": 18.912048192771085,
      "grad_norm": 0.0002442729892209172,
      "learning_rate": 1.0879518072289157e-06,
      "loss": 0.0159,
      "step": 156970
    },
    {
      "epoch": 18.913253012048195,
      "grad_norm": 2.019655227661133,
      "learning_rate": 1.0867469879518073e-06,
      "loss": 0.018,
      "step": 156980
    },
    {
      "epoch": 18.9144578313253,
      "grad_norm": 0.002829505829140544,
      "learning_rate": 1.085542168674699e-06,
      "loss": 0.0062,
      "step": 156990
    },
    {
      "epoch": 18.91566265060241,
      "grad_norm": 3.4963197708129883,
      "learning_rate": 1.0843373493975905e-06,
      "loss": 0.0119,
      "step": 157000
    },
    {
      "epoch": 18.916867469879517,
      "grad_norm": 1.1308202743530273,
      "learning_rate": 1.083132530120482e-06,
      "loss": 0.0158,
      "step": 157010
    },
    {
      "epoch": 18.918072289156626,
      "grad_norm": 0.28920677304267883,
      "learning_rate": 1.0819277108433737e-06,
      "loss": 0.0038,
      "step": 157020
    },
    {
      "epoch": 18.919277108433736,
      "grad_norm": 0.7821664214134216,
      "learning_rate": 1.080722891566265e-06,
      "loss": 0.0302,
      "step": 157030
    },
    {
      "epoch": 18.920481927710842,
      "grad_norm": 5.3029085393063724e-05,
      "learning_rate": 1.0795180722891566e-06,
      "loss": 0.0098,
      "step": 157040
    },
    {
      "epoch": 18.92168674698795,
      "grad_norm": 0.00032471769372932613,
      "learning_rate": 1.0783132530120482e-06,
      "loss": 0.0005,
      "step": 157050
    },
    {
      "epoch": 18.92289156626506,
      "grad_norm": 0.38436973094940186,
      "learning_rate": 1.0771084337349398e-06,
      "loss": 0.0012,
      "step": 157060
    },
    {
      "epoch": 18.924096385542168,
      "grad_norm": 0.00010548008867772296,
      "learning_rate": 1.0759036144578314e-06,
      "loss": 0.0086,
      "step": 157070
    },
    {
      "epoch": 18.925301204819277,
      "grad_norm": 1.6226086616516113,
      "learning_rate": 1.074698795180723e-06,
      "loss": 0.0135,
      "step": 157080
    },
    {
      "epoch": 18.926506024096387,
      "grad_norm": 0.892299234867096,
      "learning_rate": 1.0734939759036146e-06,
      "loss": 0.0171,
      "step": 157090
    },
    {
      "epoch": 18.927710843373493,
      "grad_norm": 7.865180668886751e-05,
      "learning_rate": 1.0722891566265062e-06,
      "loss": 0.0088,
      "step": 157100
    },
    {
      "epoch": 18.928915662650603,
      "grad_norm": 0.0008405110565945506,
      "learning_rate": 1.0710843373493977e-06,
      "loss": 0.0071,
      "step": 157110
    },
    {
      "epoch": 18.930120481927712,
      "grad_norm": 0.9842182993888855,
      "learning_rate": 1.0698795180722893e-06,
      "loss": 0.0448,
      "step": 157120
    },
    {
      "epoch": 18.93132530120482,
      "grad_norm": 0.0002180409210268408,
      "learning_rate": 1.068674698795181e-06,
      "loss": 0.0098,
      "step": 157130
    },
    {
      "epoch": 18.93253012048193,
      "grad_norm": 0.011052093468606472,
      "learning_rate": 1.0674698795180725e-06,
      "loss": 0.0294,
      "step": 157140
    },
    {
      "epoch": 18.933734939759034,
      "grad_norm": 0.0012059776345267892,
      "learning_rate": 1.0662650602409639e-06,
      "loss": 0.0069,
      "step": 157150
    },
    {
      "epoch": 18.934939759036144,
      "grad_norm": 0.792916476726532,
      "learning_rate": 1.0650602409638555e-06,
      "loss": 0.0064,
      "step": 157160
    },
    {
      "epoch": 18.936144578313254,
      "grad_norm": 0.6323435306549072,
      "learning_rate": 1.063855421686747e-06,
      "loss": 0.0103,
      "step": 157170
    },
    {
      "epoch": 18.93734939759036,
      "grad_norm": 0.012630267068743706,
      "learning_rate": 1.0626506024096386e-06,
      "loss": 0.0034,
      "step": 157180
    },
    {
      "epoch": 18.93855421686747,
      "grad_norm": 0.32827889919281006,
      "learning_rate": 1.0614457831325302e-06,
      "loss": 0.0123,
      "step": 157190
    },
    {
      "epoch": 18.93975903614458,
      "grad_norm": 1.0887688398361206,
      "learning_rate": 1.0602409638554218e-06,
      "loss": 0.014,
      "step": 157200
    },
    {
      "epoch": 18.940963855421685,
      "grad_norm": 0.0001077660926966928,
      "learning_rate": 1.0590361445783132e-06,
      "loss": 0.0047,
      "step": 157210
    },
    {
      "epoch": 18.942168674698795,
      "grad_norm": 0.0038491564337164164,
      "learning_rate": 1.0578313253012048e-06,
      "loss": 0.0239,
      "step": 157220
    },
    {
      "epoch": 18.943373493975905,
      "grad_norm": 0.00010458614997332916,
      "learning_rate": 1.0566265060240964e-06,
      "loss": 0.015,
      "step": 157230
    },
    {
      "epoch": 18.94457831325301,
      "grad_norm": 0.0001565661805216223,
      "learning_rate": 1.055421686746988e-06,
      "loss": 0.0085,
      "step": 157240
    },
    {
      "epoch": 18.94578313253012,
      "grad_norm": 0.003213810035958886,
      "learning_rate": 1.0542168674698798e-06,
      "loss": 0.0017,
      "step": 157250
    },
    {
      "epoch": 18.94698795180723,
      "grad_norm": 0.01196240447461605,
      "learning_rate": 1.0530120481927711e-06,
      "loss": 0.0116,
      "step": 157260
    },
    {
      "epoch": 18.948192771084337,
      "grad_norm": 0.003609846578910947,
      "learning_rate": 1.0518072289156627e-06,
      "loss": 0.0145,
      "step": 157270
    },
    {
      "epoch": 18.949397590361446,
      "grad_norm": 9.710987069411203e-05,
      "learning_rate": 1.0506024096385543e-06,
      "loss": 0.0036,
      "step": 157280
    },
    {
      "epoch": 18.950602409638556,
      "grad_norm": 0.00011460336827440187,
      "learning_rate": 1.049397590361446e-06,
      "loss": 0.012,
      "step": 157290
    },
    {
      "epoch": 18.951807228915662,
      "grad_norm": 0.1188642829656601,
      "learning_rate": 1.0481927710843375e-06,
      "loss": 0.0237,
      "step": 157300
    },
    {
      "epoch": 18.95301204819277,
      "grad_norm": 0.00030489463824778795,
      "learning_rate": 1.046987951807229e-06,
      "loss": 0.0115,
      "step": 157310
    },
    {
      "epoch": 18.954216867469878,
      "grad_norm": 0.0002336784527869895,
      "learning_rate": 1.0457831325301207e-06,
      "loss": 0.011,
      "step": 157320
    },
    {
      "epoch": 18.955421686746988,
      "grad_norm": 0.941440224647522,
      "learning_rate": 1.044578313253012e-06,
      "loss": 0.0137,
      "step": 157330
    },
    {
      "epoch": 18.956626506024097,
      "grad_norm": 0.0007988520665094256,
      "learning_rate": 1.0433734939759036e-06,
      "loss": 0.0069,
      "step": 157340
    },
    {
      "epoch": 18.957831325301203,
      "grad_norm": 0.0001812480913940817,
      "learning_rate": 1.0421686746987952e-06,
      "loss": 0.01,
      "step": 157350
    },
    {
      "epoch": 18.959036144578313,
      "grad_norm": 1.0487085580825806,
      "learning_rate": 1.0409638554216868e-06,
      "loss": 0.006,
      "step": 157360
    },
    {
      "epoch": 18.960240963855423,
      "grad_norm": 2.197810411453247,
      "learning_rate": 1.0397590361445784e-06,
      "loss": 0.0136,
      "step": 157370
    },
    {
      "epoch": 18.96144578313253,
      "grad_norm": 0.00017223319446202368,
      "learning_rate": 1.03855421686747e-06,
      "loss": 0.0013,
      "step": 157380
    },
    {
      "epoch": 18.96265060240964,
      "grad_norm": 1.5967859029769897,
      "learning_rate": 1.0373493975903614e-06,
      "loss": 0.0284,
      "step": 157390
    },
    {
      "epoch": 18.96385542168675,
      "grad_norm": 0.8400413393974304,
      "learning_rate": 1.0361445783132532e-06,
      "loss": 0.012,
      "step": 157400
    },
    {
      "epoch": 18.965060240963854,
      "grad_norm": 0.0002875750360544771,
      "learning_rate": 1.0349397590361447e-06,
      "loss": 0.0211,
      "step": 157410
    },
    {
      "epoch": 18.966265060240964,
      "grad_norm": 0.000735502049792558,
      "learning_rate": 1.0337349397590363e-06,
      "loss": 0.002,
      "step": 157420
    },
    {
      "epoch": 18.967469879518074,
      "grad_norm": 0.4913456439971924,
      "learning_rate": 1.032530120481928e-06,
      "loss": 0.0032,
      "step": 157430
    },
    {
      "epoch": 18.96867469879518,
      "grad_norm": 0.9034638404846191,
      "learning_rate": 1.0313253012048193e-06,
      "loss": 0.0102,
      "step": 157440
    },
    {
      "epoch": 18.96987951807229,
      "grad_norm": 8.577268454246223e-05,
      "learning_rate": 1.0301204819277109e-06,
      "loss": 0.0157,
      "step": 157450
    },
    {
      "epoch": 18.971084337349396,
      "grad_norm": 1.0662425756454468,
      "learning_rate": 1.0289156626506025e-06,
      "loss": 0.0085,
      "step": 157460
    },
    {
      "epoch": 18.972289156626506,
      "grad_norm": 1.8862665891647339,
      "learning_rate": 1.027710843373494e-06,
      "loss": 0.0118,
      "step": 157470
    },
    {
      "epoch": 18.973493975903615,
      "grad_norm": 1.0072684288024902,
      "learning_rate": 1.0265060240963857e-06,
      "loss": 0.017,
      "step": 157480
    },
    {
      "epoch": 18.97469879518072,
      "grad_norm": 1.7175021171569824,
      "learning_rate": 1.0253012048192772e-06,
      "loss": 0.0231,
      "step": 157490
    },
    {
      "epoch": 18.97590361445783,
      "grad_norm": 0.00015868377522565424,
      "learning_rate": 1.0240963855421688e-06,
      "loss": 0.0085,
      "step": 157500
    },
    {
      "epoch": 18.97710843373494,
      "grad_norm": 0.7440941333770752,
      "learning_rate": 1.0228915662650602e-06,
      "loss": 0.0202,
      "step": 157510
    },
    {
      "epoch": 18.978313253012047,
      "grad_norm": 0.0001338394795311615,
      "learning_rate": 1.0216867469879518e-06,
      "loss": 0.005,
      "step": 157520
    },
    {
      "epoch": 18.979518072289157,
      "grad_norm": 0.00031091898563317955,
      "learning_rate": 1.0204819277108434e-06,
      "loss": 0.0065,
      "step": 157530
    },
    {
      "epoch": 18.980722891566266,
      "grad_norm": 0.02342822216451168,
      "learning_rate": 1.0192771084337352e-06,
      "loss": 0.0024,
      "step": 157540
    },
    {
      "epoch": 18.981927710843372,
      "grad_norm": 0.8468440175056458,
      "learning_rate": 1.0180722891566266e-06,
      "loss": 0.0063,
      "step": 157550
    },
    {
      "epoch": 18.983132530120482,
      "grad_norm": 0.00019720825366675854,
      "learning_rate": 1.0168674698795181e-06,
      "loss": 0.0166,
      "step": 157560
    },
    {
      "epoch": 18.98433734939759,
      "grad_norm": 0.6962969899177551,
      "learning_rate": 1.0156626506024097e-06,
      "loss": 0.0286,
      "step": 157570
    },
    {
      "epoch": 18.985542168674698,
      "grad_norm": 7.288763299584389e-05,
      "learning_rate": 1.0144578313253013e-06,
      "loss": 0.0165,
      "step": 157580
    },
    {
      "epoch": 18.986746987951808,
      "grad_norm": 0.06318513303995132,
      "learning_rate": 1.013253012048193e-06,
      "loss": 0.0047,
      "step": 157590
    },
    {
      "epoch": 18.987951807228917,
      "grad_norm": 0.00014068630116526037,
      "learning_rate": 1.0120481927710845e-06,
      "loss": 0.0096,
      "step": 157600
    },
    {
      "epoch": 18.989156626506023,
      "grad_norm": 8.049664756981656e-05,
      "learning_rate": 1.010843373493976e-06,
      "loss": 0.0169,
      "step": 157610
    },
    {
      "epoch": 18.990361445783133,
      "grad_norm": 0.9659914970397949,
      "learning_rate": 1.0096385542168675e-06,
      "loss": 0.0081,
      "step": 157620
    },
    {
      "epoch": 18.99156626506024,
      "grad_norm": 0.00017822500376496464,
      "learning_rate": 1.008433734939759e-06,
      "loss": 0.0052,
      "step": 157630
    },
    {
      "epoch": 18.99277108433735,
      "grad_norm": 0.4528907239437103,
      "learning_rate": 1.0072289156626506e-06,
      "loss": 0.0199,
      "step": 157640
    },
    {
      "epoch": 18.99397590361446,
      "grad_norm": 0.7606187462806702,
      "learning_rate": 1.0060240963855422e-06,
      "loss": 0.0203,
      "step": 157650
    },
    {
      "epoch": 18.995180722891565,
      "grad_norm": 7.56615845602937e-05,
      "learning_rate": 1.0048192771084338e-06,
      "loss": 0.0066,
      "step": 157660
    },
    {
      "epoch": 18.996385542168674,
      "grad_norm": 8.556646935176104e-05,
      "learning_rate": 1.0036144578313254e-06,
      "loss": 0.0077,
      "step": 157670
    },
    {
      "epoch": 18.997590361445784,
      "grad_norm": 0.0014468322042375803,
      "learning_rate": 1.002409638554217e-06,
      "loss": 0.0006,
      "step": 157680
    },
    {
      "epoch": 18.99879518072289,
      "grad_norm": 0.0001913692831294611,
      "learning_rate": 1.0012048192771086e-06,
      "loss": 0.0062,
      "step": 157690
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.9131174087524414,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0108,
      "step": 157700
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.9879077615298087,
      "eval_f1": 0.9678824847504046,
      "eval_loss": 0.06138496845960617,
      "eval_precision": 0.9749216300940439,
      "eval_recall": 0.9609442590532691,
      "eval_runtime": 3382.1598,
      "eval_samples_per_second": 12.622,
      "eval_steps_per_second": 0.526,
      "step": 157700
    }
  ],
  "logging_steps": 10,
  "max_steps": 166000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0035584994366638e+18,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
