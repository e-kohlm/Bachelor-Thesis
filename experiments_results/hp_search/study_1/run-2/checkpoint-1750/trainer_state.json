{
  "best_metric": 0.9344537815126052,
  "best_model_checkpoint": "../hyperparameter_search/run-2/checkpoint-1750",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 1750,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002285714285714286,
      "grad_norm": 34.88250732421875,
      "learning_rate": 5.880125517984578e-08,
      "loss": 0.7253,
      "step": 1
    },
    {
      "epoch": 0.022857142857142857,
      "grad_norm": 58.258750915527344,
      "learning_rate": 5.880125517984578e-07,
      "loss": 0.8789,
      "step": 10
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 36.24790573120117,
      "learning_rate": 1.1760251035969155e-06,
      "loss": 0.7312,
      "step": 20
    },
    {
      "epoch": 0.06857142857142857,
      "grad_norm": 23.068622589111328,
      "learning_rate": 1.7640376553953733e-06,
      "loss": 0.5968,
      "step": 30
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 19.69792366027832,
      "learning_rate": 2.352050207193831e-06,
      "loss": 0.4554,
      "step": 40
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 35.917354583740234,
      "learning_rate": 2.9400627589922888e-06,
      "loss": 0.3847,
      "step": 50
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 20.716758728027344,
      "learning_rate": 3.5280753107907465e-06,
      "loss": 0.3222,
      "step": 60
    },
    {
      "epoch": 0.16,
      "grad_norm": 24.41313934326172,
      "learning_rate": 4.116087862589204e-06,
      "loss": 0.3211,
      "step": 70
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 11.093037605285645,
      "learning_rate": 4.704100414387662e-06,
      "loss": 0.2217,
      "step": 80
    },
    {
      "epoch": 0.2057142857142857,
      "grad_norm": 19.75326919555664,
      "learning_rate": 5.29211296618612e-06,
      "loss": 0.3681,
      "step": 90
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 8.120849609375,
      "learning_rate": 5.8801255179845775e-06,
      "loss": 0.2602,
      "step": 100
    },
    {
      "epoch": 0.25142857142857145,
      "grad_norm": 8.129250526428223,
      "learning_rate": 6.468138069783035e-06,
      "loss": 0.2837,
      "step": 110
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 17.829050064086914,
      "learning_rate": 7.056150621581493e-06,
      "loss": 0.4138,
      "step": 120
    },
    {
      "epoch": 0.29714285714285715,
      "grad_norm": 38.97264862060547,
      "learning_rate": 7.64416317337995e-06,
      "loss": 0.3384,
      "step": 130
    },
    {
      "epoch": 0.32,
      "grad_norm": 36.49933624267578,
      "learning_rate": 8.232175725178409e-06,
      "loss": 0.3473,
      "step": 140
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 3.901712417602539,
      "learning_rate": 8.820188276976866e-06,
      "loss": 0.278,
      "step": 150
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 17.42291259765625,
      "learning_rate": 9.408200828775324e-06,
      "loss": 0.4001,
      "step": 160
    },
    {
      "epoch": 0.38857142857142857,
      "grad_norm": 16.48517608642578,
      "learning_rate": 9.996213380573782e-06,
      "loss": 0.3601,
      "step": 170
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 227.209228515625,
      "learning_rate": 1.058422593237224e-05,
      "loss": 0.3581,
      "step": 180
    },
    {
      "epoch": 0.4342857142857143,
      "grad_norm": 17.236671447753906,
      "learning_rate": 1.1172238484170699e-05,
      "loss": 0.2798,
      "step": 190
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 6.8559699058532715,
      "learning_rate": 1.1760251035969155e-05,
      "loss": 0.335,
      "step": 200
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.242589473724365,
      "learning_rate": 1.2348263587767613e-05,
      "loss": 0.2749,
      "step": 210
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 12.770120620727539,
      "learning_rate": 1.293627613956607e-05,
      "loss": 0.2654,
      "step": 220
    },
    {
      "epoch": 0.5257142857142857,
      "grad_norm": 12.726625442504883,
      "learning_rate": 1.352428869136453e-05,
      "loss": 0.2679,
      "step": 230
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 9.81013011932373,
      "learning_rate": 1.4112301243162986e-05,
      "loss": 0.2587,
      "step": 240
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 92.4858169555664,
      "learning_rate": 1.4700313794961444e-05,
      "loss": 0.3397,
      "step": 250
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 20.54606819152832,
      "learning_rate": 1.5109476494690546e-05,
      "loss": 0.2791,
      "step": 260
    },
    {
      "epoch": 0.6171428571428571,
      "grad_norm": 11.889272689819336,
      "learning_rate": 1.5101322872924484e-05,
      "loss": 0.2866,
      "step": 270
    },
    {
      "epoch": 0.64,
      "grad_norm": 14.287054061889648,
      "learning_rate": 1.509316925115842e-05,
      "loss": 0.267,
      "step": 280
    },
    {
      "epoch": 0.6628571428571428,
      "grad_norm": 9.276202201843262,
      "learning_rate": 1.5085015629392358e-05,
      "loss": 0.2249,
      "step": 290
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 10.677119255065918,
      "learning_rate": 1.5076862007626296e-05,
      "loss": 0.2771,
      "step": 300
    },
    {
      "epoch": 0.7085714285714285,
      "grad_norm": 3.955202341079712,
      "learning_rate": 1.5068708385860232e-05,
      "loss": 0.174,
      "step": 310
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 9.106794357299805,
      "learning_rate": 1.5060554764094172e-05,
      "loss": 0.2118,
      "step": 320
    },
    {
      "epoch": 0.7542857142857143,
      "grad_norm": 8.286971092224121,
      "learning_rate": 1.5052401142328108e-05,
      "loss": 0.2699,
      "step": 330
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 11.100552558898926,
      "learning_rate": 1.5044247520562044e-05,
      "loss": 0.2404,
      "step": 340
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.553625106811523,
      "learning_rate": 1.5036093898795984e-05,
      "loss": 0.1544,
      "step": 350
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 9.732099533081055,
      "learning_rate": 1.502794027702992e-05,
      "loss": 0.2328,
      "step": 360
    },
    {
      "epoch": 0.8457142857142858,
      "grad_norm": 5.4694504737854,
      "learning_rate": 1.5019786655263858e-05,
      "loss": 0.1888,
      "step": 370
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 7.044602870941162,
      "learning_rate": 1.5011633033497796e-05,
      "loss": 0.2064,
      "step": 380
    },
    {
      "epoch": 0.8914285714285715,
      "grad_norm": 6.264312744140625,
      "learning_rate": 1.5003479411731732e-05,
      "loss": 0.2774,
      "step": 390
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 3.843444585800171,
      "learning_rate": 1.499532578996567e-05,
      "loss": 0.1881,
      "step": 400
    },
    {
      "epoch": 0.9371428571428572,
      "grad_norm": 2.9457337856292725,
      "learning_rate": 1.4987172168199608e-05,
      "loss": 0.2648,
      "step": 410
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.034855842590332,
      "learning_rate": 1.4979018546433546e-05,
      "loss": 0.1545,
      "step": 420
    },
    {
      "epoch": 0.9828571428571429,
      "grad_norm": 3.9193150997161865,
      "learning_rate": 1.4970864924667482e-05,
      "loss": 0.1603,
      "step": 430
    },
    {
      "epoch": 0.9988571428571429,
      "eval_accuracy": 0.925,
      "eval_f1": 0.43609022556390975,
      "eval_loss": 0.20457462966442108,
      "eval_precision": 0.8787878787878788,
      "eval_recall": 0.29,
      "eval_runtime": 389.8883,
      "eval_samples_per_second": 7.695,
      "eval_steps_per_second": 0.962,
      "step": 437
    },
    {
      "epoch": 0.9988571428571429,
      "eval_accuracy": 0.925,
      "eval_f1": 0.43609022556390975,
      "eval_loss": 0.20457462966442108,
      "eval_precision": 0.8787878787878788,
      "eval_recall": 0.29,
      "eval_runtime": 394.4634,
      "eval_samples_per_second": 7.605,
      "eval_steps_per_second": 0.951,
      "step": 437
    },
    {
      "epoch": 1.0057142857142858,
      "grad_norm": 11.62212085723877,
      "learning_rate": 1.496271130290142e-05,
      "loss": 0.1768,
      "step": 440
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 8.015865325927734,
      "learning_rate": 1.4954557681135358e-05,
      "loss": 0.2131,
      "step": 450
    },
    {
      "epoch": 1.0514285714285714,
      "grad_norm": 6.780943870544434,
      "learning_rate": 1.4946404059369294e-05,
      "loss": 0.1411,
      "step": 460
    },
    {
      "epoch": 1.0742857142857143,
      "grad_norm": 9.472837448120117,
      "learning_rate": 1.4938250437603233e-05,
      "loss": 0.2457,
      "step": 470
    },
    {
      "epoch": 1.0971428571428572,
      "grad_norm": 11.163199424743652,
      "learning_rate": 1.493009681583717e-05,
      "loss": 0.2059,
      "step": 480
    },
    {
      "epoch": 1.12,
      "grad_norm": 10.293078422546387,
      "learning_rate": 1.4921943194071106e-05,
      "loss": 0.1561,
      "step": 490
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 13.8908052444458,
      "learning_rate": 1.4913789572305045e-05,
      "loss": 0.1933,
      "step": 500
    },
    {
      "epoch": 1.1657142857142857,
      "grad_norm": 6.874258518218994,
      "learning_rate": 1.4905635950538982e-05,
      "loss": 0.1404,
      "step": 510
    },
    {
      "epoch": 1.1885714285714286,
      "grad_norm": 6.283362865447998,
      "learning_rate": 1.489748232877292e-05,
      "loss": 0.117,
      "step": 520
    },
    {
      "epoch": 1.2114285714285715,
      "grad_norm": 10.733515739440918,
      "learning_rate": 1.4889328707006856e-05,
      "loss": 0.1987,
      "step": 530
    },
    {
      "epoch": 1.2342857142857142,
      "grad_norm": 3.0698695182800293,
      "learning_rate": 1.4881175085240794e-05,
      "loss": 0.1149,
      "step": 540
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 9.507318496704102,
      "learning_rate": 1.4873021463474732e-05,
      "loss": 0.1742,
      "step": 550
    },
    {
      "epoch": 1.28,
      "grad_norm": 6.323618412017822,
      "learning_rate": 1.4864867841708668e-05,
      "loss": 0.1549,
      "step": 560
    },
    {
      "epoch": 1.302857142857143,
      "grad_norm": 4.075364589691162,
      "learning_rate": 1.4856714219942606e-05,
      "loss": 0.1492,
      "step": 570
    },
    {
      "epoch": 1.3257142857142856,
      "grad_norm": 12.379345893859863,
      "learning_rate": 1.4848560598176544e-05,
      "loss": 0.1971,
      "step": 580
    },
    {
      "epoch": 1.3485714285714285,
      "grad_norm": 3.383816719055176,
      "learning_rate": 1.484040697641048e-05,
      "loss": 0.1656,
      "step": 590
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 5.983409404754639,
      "learning_rate": 1.483225335464442e-05,
      "loss": 0.2243,
      "step": 600
    },
    {
      "epoch": 1.3942857142857144,
      "grad_norm": 11.782270431518555,
      "learning_rate": 1.4824099732878356e-05,
      "loss": 0.1332,
      "step": 610
    },
    {
      "epoch": 1.4171428571428573,
      "grad_norm": 5.305349826812744,
      "learning_rate": 1.4815946111112292e-05,
      "loss": 0.1565,
      "step": 620
    },
    {
      "epoch": 1.44,
      "grad_norm": 6.997832775115967,
      "learning_rate": 1.4807792489346232e-05,
      "loss": 0.1037,
      "step": 630
    },
    {
      "epoch": 1.4628571428571429,
      "grad_norm": 4.105653285980225,
      "learning_rate": 1.4799638867580168e-05,
      "loss": 0.1417,
      "step": 640
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 9.96159553527832,
      "learning_rate": 1.4791485245814106e-05,
      "loss": 0.168,
      "step": 650
    },
    {
      "epoch": 1.5085714285714285,
      "grad_norm": 0.840542197227478,
      "learning_rate": 1.4783331624048044e-05,
      "loss": 0.2162,
      "step": 660
    },
    {
      "epoch": 1.5314285714285716,
      "grad_norm": 7.014449596405029,
      "learning_rate": 1.477517800228198e-05,
      "loss": 0.1436,
      "step": 670
    },
    {
      "epoch": 1.5542857142857143,
      "grad_norm": 6.162995338439941,
      "learning_rate": 1.4767024380515918e-05,
      "loss": 0.1219,
      "step": 680
    },
    {
      "epoch": 1.5771428571428572,
      "grad_norm": 5.840466022491455,
      "learning_rate": 1.4758870758749856e-05,
      "loss": 0.1222,
      "step": 690
    },
    {
      "epoch": 1.6,
      "grad_norm": 8.39632511138916,
      "learning_rate": 1.4750717136983794e-05,
      "loss": 0.1281,
      "step": 700
    },
    {
      "epoch": 1.6228571428571428,
      "grad_norm": 4.800091743469238,
      "learning_rate": 1.474256351521773e-05,
      "loss": 0.117,
      "step": 710
    },
    {
      "epoch": 1.6457142857142857,
      "grad_norm": 8.65593433380127,
      "learning_rate": 1.4734409893451668e-05,
      "loss": 0.1297,
      "step": 720
    },
    {
      "epoch": 1.6685714285714286,
      "grad_norm": 6.847512722015381,
      "learning_rate": 1.4726256271685606e-05,
      "loss": 0.1353,
      "step": 730
    },
    {
      "epoch": 1.6914285714285713,
      "grad_norm": 5.698057174682617,
      "learning_rate": 1.4718102649919542e-05,
      "loss": 0.1064,
      "step": 740
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 9.218720436096191,
      "learning_rate": 1.4709949028153481e-05,
      "loss": 0.168,
      "step": 750
    },
    {
      "epoch": 1.737142857142857,
      "grad_norm": 5.7946271896362305,
      "learning_rate": 1.4701795406387418e-05,
      "loss": 0.1035,
      "step": 760
    },
    {
      "epoch": 1.76,
      "grad_norm": 5.252152919769287,
      "learning_rate": 1.4693641784621354e-05,
      "loss": 0.1321,
      "step": 770
    },
    {
      "epoch": 1.782857142857143,
      "grad_norm": 5.639858245849609,
      "learning_rate": 1.4685488162855294e-05,
      "loss": 0.1373,
      "step": 780
    },
    {
      "epoch": 1.8057142857142856,
      "grad_norm": 1.033892273902893,
      "learning_rate": 1.467733454108923e-05,
      "loss": 0.1889,
      "step": 790
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 1.8533767461776733,
      "learning_rate": 1.4669180919323168e-05,
      "loss": 0.1314,
      "step": 800
    },
    {
      "epoch": 1.8514285714285714,
      "grad_norm": 12.978243827819824,
      "learning_rate": 1.4661027297557106e-05,
      "loss": 0.0976,
      "step": 810
    },
    {
      "epoch": 1.8742857142857143,
      "grad_norm": 0.9262220859527588,
      "learning_rate": 1.4652873675791042e-05,
      "loss": 0.0969,
      "step": 820
    },
    {
      "epoch": 1.8971428571428572,
      "grad_norm": 10.117839813232422,
      "learning_rate": 1.464472005402498e-05,
      "loss": 0.1318,
      "step": 830
    },
    {
      "epoch": 1.92,
      "grad_norm": 5.042925834655762,
      "learning_rate": 1.4636566432258916e-05,
      "loss": 0.0954,
      "step": 840
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 7.973910331726074,
      "learning_rate": 1.4628412810492856e-05,
      "loss": 0.1114,
      "step": 850
    },
    {
      "epoch": 1.9657142857142857,
      "grad_norm": 7.662099361419678,
      "learning_rate": 1.4620259188726792e-05,
      "loss": 0.1363,
      "step": 860
    },
    {
      "epoch": 1.9885714285714284,
      "grad_norm": 1.0418020486831665,
      "learning_rate": 1.4612105566960728e-05,
      "loss": 0.0732,
      "step": 870
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9666666666666667,
      "eval_f1": 0.806201550387597,
      "eval_loss": 0.10523134469985962,
      "eval_precision": 0.9629629629629629,
      "eval_recall": 0.6933333333333334,
      "eval_runtime": 393.4597,
      "eval_samples_per_second": 7.625,
      "eval_steps_per_second": 0.953,
      "step": 875
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9666666666666667,
      "eval_f1": 0.806201550387597,
      "eval_loss": 0.10523134469985962,
      "eval_precision": 0.9629629629629629,
      "eval_recall": 0.6933333333333334,
      "eval_runtime": 394.6036,
      "eval_samples_per_second": 7.603,
      "eval_steps_per_second": 0.95,
      "step": 875
    },
    {
      "epoch": 2.0114285714285716,
      "grad_norm": 3.230436325073242,
      "learning_rate": 1.4603951945194668e-05,
      "loss": 0.0643,
      "step": 880
    },
    {
      "epoch": 2.0342857142857143,
      "grad_norm": 0.2805424630641937,
      "learning_rate": 1.4595798323428604e-05,
      "loss": 0.0768,
      "step": 890
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 9.972626686096191,
      "learning_rate": 1.458764470166254e-05,
      "loss": 0.1132,
      "step": 900
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.9488954544067383,
      "learning_rate": 1.457949107989648e-05,
      "loss": 0.0707,
      "step": 910
    },
    {
      "epoch": 2.1028571428571428,
      "grad_norm": 3.675704002380371,
      "learning_rate": 1.4571337458130416e-05,
      "loss": 0.0873,
      "step": 920
    },
    {
      "epoch": 2.125714285714286,
      "grad_norm": 6.437801837921143,
      "learning_rate": 1.4563183836364354e-05,
      "loss": 0.0852,
      "step": 930
    },
    {
      "epoch": 2.1485714285714286,
      "grad_norm": 0.3341902494430542,
      "learning_rate": 1.4555030214598292e-05,
      "loss": 0.0651,
      "step": 940
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 7.873762130737305,
      "learning_rate": 1.4546876592832228e-05,
      "loss": 0.1036,
      "step": 950
    },
    {
      "epoch": 2.1942857142857144,
      "grad_norm": 1.7415028810501099,
      "learning_rate": 1.4538722971066166e-05,
      "loss": 0.112,
      "step": 960
    },
    {
      "epoch": 2.217142857142857,
      "grad_norm": 1.427527666091919,
      "learning_rate": 1.4530569349300104e-05,
      "loss": 0.0697,
      "step": 970
    },
    {
      "epoch": 2.24,
      "grad_norm": 5.146524906158447,
      "learning_rate": 1.4522415727534042e-05,
      "loss": 0.0704,
      "step": 980
    },
    {
      "epoch": 2.262857142857143,
      "grad_norm": 9.343280792236328,
      "learning_rate": 1.4514262105767978e-05,
      "loss": 0.1055,
      "step": 990
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.4800509810447693,
      "learning_rate": 1.4506108484001916e-05,
      "loss": 0.113,
      "step": 1000
    },
    {
      "epoch": 2.3085714285714287,
      "grad_norm": 4.043716907501221,
      "learning_rate": 1.4497954862235854e-05,
      "loss": 0.0661,
      "step": 1010
    },
    {
      "epoch": 2.3314285714285714,
      "grad_norm": 8.776877403259277,
      "learning_rate": 1.448980124046979e-05,
      "loss": 0.0691,
      "step": 1020
    },
    {
      "epoch": 2.354285714285714,
      "grad_norm": 5.393332004547119,
      "learning_rate": 1.448164761870373e-05,
      "loss": 0.041,
      "step": 1030
    },
    {
      "epoch": 2.3771428571428572,
      "grad_norm": 9.55805778503418,
      "learning_rate": 1.4473493996937666e-05,
      "loss": 0.0773,
      "step": 1040
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.789035677909851,
      "learning_rate": 1.4465340375171602e-05,
      "loss": 0.0973,
      "step": 1050
    },
    {
      "epoch": 2.422857142857143,
      "grad_norm": 5.0516204833984375,
      "learning_rate": 1.4457186753405542e-05,
      "loss": 0.0639,
      "step": 1060
    },
    {
      "epoch": 2.4457142857142857,
      "grad_norm": 0.4005858600139618,
      "learning_rate": 1.4449033131639478e-05,
      "loss": 0.0765,
      "step": 1070
    },
    {
      "epoch": 2.4685714285714284,
      "grad_norm": 0.9670827984809875,
      "learning_rate": 1.4440879509873416e-05,
      "loss": 0.1144,
      "step": 1080
    },
    {
      "epoch": 2.4914285714285715,
      "grad_norm": 4.8656158447265625,
      "learning_rate": 1.4432725888107354e-05,
      "loss": 0.0629,
      "step": 1090
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 13.109149932861328,
      "learning_rate": 1.442457226634129e-05,
      "loss": 0.105,
      "step": 1100
    },
    {
      "epoch": 2.5371428571428574,
      "grad_norm": 4.407620429992676,
      "learning_rate": 1.4416418644575228e-05,
      "loss": 0.0434,
      "step": 1110
    },
    {
      "epoch": 2.56,
      "grad_norm": 6.290403842926025,
      "learning_rate": 1.4408265022809166e-05,
      "loss": 0.0506,
      "step": 1120
    },
    {
      "epoch": 2.5828571428571427,
      "grad_norm": 5.652689456939697,
      "learning_rate": 1.4400111401043104e-05,
      "loss": 0.0145,
      "step": 1130
    },
    {
      "epoch": 2.605714285714286,
      "grad_norm": 7.0553460121154785,
      "learning_rate": 1.439195777927704e-05,
      "loss": 0.0727,
      "step": 1140
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 1.461037039756775,
      "learning_rate": 1.4383804157510976e-05,
      "loss": 0.0196,
      "step": 1150
    },
    {
      "epoch": 2.6514285714285712,
      "grad_norm": 7.129383563995361,
      "learning_rate": 1.4375650535744916e-05,
      "loss": 0.0846,
      "step": 1160
    },
    {
      "epoch": 2.6742857142857144,
      "grad_norm": 15.57919979095459,
      "learning_rate": 1.4367496913978852e-05,
      "loss": 0.123,
      "step": 1170
    },
    {
      "epoch": 2.697142857142857,
      "grad_norm": 5.663235187530518,
      "learning_rate": 1.4359343292212788e-05,
      "loss": 0.0431,
      "step": 1180
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 12.210275650024414,
      "learning_rate": 1.4351189670446728e-05,
      "loss": 0.0849,
      "step": 1190
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 0.8179730176925659,
      "learning_rate": 1.4343036048680664e-05,
      "loss": 0.0948,
      "step": 1200
    },
    {
      "epoch": 2.7657142857142856,
      "grad_norm": 8.245894432067871,
      "learning_rate": 1.4334882426914602e-05,
      "loss": 0.0891,
      "step": 1210
    },
    {
      "epoch": 2.7885714285714287,
      "grad_norm": 0.4261755049228668,
      "learning_rate": 1.432672880514854e-05,
      "loss": 0.0407,
      "step": 1220
    },
    {
      "epoch": 2.8114285714285714,
      "grad_norm": 0.02270941063761711,
      "learning_rate": 1.4318575183382476e-05,
      "loss": 0.099,
      "step": 1230
    },
    {
      "epoch": 2.8342857142857145,
      "grad_norm": 4.933980464935303,
      "learning_rate": 1.4310421561616414e-05,
      "loss": 0.0595,
      "step": 1240
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 8.464000701904297,
      "learning_rate": 1.4302267939850352e-05,
      "loss": 0.0795,
      "step": 1250
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5407288074493408,
      "learning_rate": 1.429411431808429e-05,
      "loss": 0.0368,
      "step": 1260
    },
    {
      "epoch": 2.902857142857143,
      "grad_norm": 43.510677337646484,
      "learning_rate": 1.4285960696318226e-05,
      "loss": 0.0795,
      "step": 1270
    },
    {
      "epoch": 2.9257142857142857,
      "grad_norm": 0.8402108550071716,
      "learning_rate": 1.4277807074552164e-05,
      "loss": 0.0862,
      "step": 1280
    },
    {
      "epoch": 2.9485714285714284,
      "grad_norm": 5.17248010635376,
      "learning_rate": 1.4269653452786102e-05,
      "loss": 0.0337,
      "step": 1290
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 0.19519291818141937,
      "learning_rate": 1.4261499831020038e-05,
      "loss": 0.0654,
      "step": 1300
    },
    {
      "epoch": 2.994285714285714,
      "grad_norm": 1.888978123664856,
      "learning_rate": 1.4253346209253978e-05,
      "loss": 0.0534,
      "step": 1310
    },
    {
      "epoch": 2.998857142857143,
      "eval_accuracy": 0.9786666666666667,
      "eval_f1": 0.8865248226950356,
      "eval_loss": 0.08494184166193008,
      "eval_precision": 0.946969696969697,
      "eval_recall": 0.8333333333333334,
      "eval_runtime": 392.828,
      "eval_samples_per_second": 7.637,
      "eval_steps_per_second": 0.955,
      "step": 1312
    },
    {
      "epoch": 2.998857142857143,
      "eval_accuracy": 0.9786666666666667,
      "eval_f1": 0.8865248226950356,
      "eval_loss": 0.08494184166193008,
      "eval_precision": 0.946969696969697,
      "eval_recall": 0.8333333333333334,
      "eval_runtime": 391.6776,
      "eval_samples_per_second": 7.659,
      "eval_steps_per_second": 0.957,
      "step": 1312
    },
    {
      "epoch": 3.0171428571428573,
      "grad_norm": 0.036303967237472534,
      "learning_rate": 1.4245192587487914e-05,
      "loss": 0.0115,
      "step": 1320
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.017349613830447197,
      "learning_rate": 1.423703896572185e-05,
      "loss": 0.0252,
      "step": 1330
    },
    {
      "epoch": 3.0628571428571427,
      "grad_norm": 7.795572280883789,
      "learning_rate": 1.422888534395579e-05,
      "loss": 0.0501,
      "step": 1340
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 4.155703067779541,
      "learning_rate": 1.4220731722189726e-05,
      "loss": 0.0551,
      "step": 1350
    },
    {
      "epoch": 3.1085714285714285,
      "grad_norm": 0.14358319342136383,
      "learning_rate": 1.4212578100423664e-05,
      "loss": 0.0572,
      "step": 1360
    },
    {
      "epoch": 3.1314285714285712,
      "grad_norm": 4.809110164642334,
      "learning_rate": 1.4204424478657602e-05,
      "loss": 0.0086,
      "step": 1370
    },
    {
      "epoch": 3.1542857142857144,
      "grad_norm": 0.9030104875564575,
      "learning_rate": 1.4196270856891538e-05,
      "loss": 0.0998,
      "step": 1380
    },
    {
      "epoch": 3.177142857142857,
      "grad_norm": 0.9744618535041809,
      "learning_rate": 1.4188117235125476e-05,
      "loss": 0.0205,
      "step": 1390
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.050333600491285324,
      "learning_rate": 1.4179963613359414e-05,
      "loss": 0.0277,
      "step": 1400
    },
    {
      "epoch": 3.222857142857143,
      "grad_norm": 1.1904505491256714,
      "learning_rate": 1.4171809991593352e-05,
      "loss": 0.0309,
      "step": 1410
    },
    {
      "epoch": 3.2457142857142856,
      "grad_norm": 0.693457841873169,
      "learning_rate": 1.4163656369827288e-05,
      "loss": 0.0343,
      "step": 1420
    },
    {
      "epoch": 3.2685714285714287,
      "grad_norm": 0.28523436188697815,
      "learning_rate": 1.4155502748061226e-05,
      "loss": 0.0753,
      "step": 1430
    },
    {
      "epoch": 3.2914285714285714,
      "grad_norm": 3.889329195022583,
      "learning_rate": 1.4147349126295164e-05,
      "loss": 0.0402,
      "step": 1440
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 0.9629537463188171,
      "learning_rate": 1.41391955045291e-05,
      "loss": 0.0307,
      "step": 1450
    },
    {
      "epoch": 3.337142857142857,
      "grad_norm": 0.7647919058799744,
      "learning_rate": 1.4131041882763036e-05,
      "loss": 0.0649,
      "step": 1460
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.5941157937049866,
      "learning_rate": 1.4122888260996976e-05,
      "loss": 0.0379,
      "step": 1470
    },
    {
      "epoch": 3.382857142857143,
      "grad_norm": 4.276917457580566,
      "learning_rate": 1.4114734639230912e-05,
      "loss": 0.0186,
      "step": 1480
    },
    {
      "epoch": 3.4057142857142857,
      "grad_norm": 11.659554481506348,
      "learning_rate": 1.410658101746485e-05,
      "loss": 0.1348,
      "step": 1490
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 12.309389114379883,
      "learning_rate": 1.4098427395698788e-05,
      "loss": 0.0489,
      "step": 1500
    },
    {
      "epoch": 3.4514285714285715,
      "grad_norm": 0.36048269271850586,
      "learning_rate": 1.4090273773932724e-05,
      "loss": 0.0673,
      "step": 1510
    },
    {
      "epoch": 3.474285714285714,
      "grad_norm": 3.3876254558563232,
      "learning_rate": 1.4082120152166662e-05,
      "loss": 0.0352,
      "step": 1520
    },
    {
      "epoch": 3.4971428571428573,
      "grad_norm": 1.134869933128357,
      "learning_rate": 1.40739665304006e-05,
      "loss": 0.0489,
      "step": 1530
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.264011412858963,
      "learning_rate": 1.4065812908634538e-05,
      "loss": 0.068,
      "step": 1540
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 6.434349536895752,
      "learning_rate": 1.4057659286868474e-05,
      "loss": 0.0143,
      "step": 1550
    },
    {
      "epoch": 3.565714285714286,
      "grad_norm": 0.20242270827293396,
      "learning_rate": 1.4049505665102412e-05,
      "loss": 0.0573,
      "step": 1560
    },
    {
      "epoch": 3.5885714285714285,
      "grad_norm": 1.5147751569747925,
      "learning_rate": 1.404135204333635e-05,
      "loss": 0.0278,
      "step": 1570
    },
    {
      "epoch": 3.611428571428571,
      "grad_norm": 4.39271879196167,
      "learning_rate": 1.4033198421570286e-05,
      "loss": 0.0457,
      "step": 1580
    },
    {
      "epoch": 3.6342857142857143,
      "grad_norm": 12.515889167785645,
      "learning_rate": 1.4025044799804226e-05,
      "loss": 0.0622,
      "step": 1590
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 3.1039326190948486,
      "learning_rate": 1.4016891178038162e-05,
      "loss": 0.0791,
      "step": 1600
    },
    {
      "epoch": 3.68,
      "grad_norm": 8.731179237365723,
      "learning_rate": 1.4008737556272098e-05,
      "loss": 0.0287,
      "step": 1610
    },
    {
      "epoch": 3.702857142857143,
      "grad_norm": 0.3564649820327759,
      "learning_rate": 1.4000583934506038e-05,
      "loss": 0.0541,
      "step": 1620
    },
    {
      "epoch": 3.725714285714286,
      "grad_norm": 0.4071097671985626,
      "learning_rate": 1.3992430312739974e-05,
      "loss": 0.029,
      "step": 1630
    },
    {
      "epoch": 3.7485714285714287,
      "grad_norm": 9.835596084594727,
      "learning_rate": 1.3984276690973912e-05,
      "loss": 0.071,
      "step": 1640
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 9.41921615600586,
      "learning_rate": 1.397612306920785e-05,
      "loss": 0.0361,
      "step": 1650
    },
    {
      "epoch": 3.7942857142857145,
      "grad_norm": 0.023823168128728867,
      "learning_rate": 1.3967969447441786e-05,
      "loss": 0.0876,
      "step": 1660
    },
    {
      "epoch": 3.817142857142857,
      "grad_norm": 0.41903722286224365,
      "learning_rate": 1.3959815825675724e-05,
      "loss": 0.0546,
      "step": 1670
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.1978880763053894,
      "learning_rate": 1.3951662203909662e-05,
      "loss": 0.0321,
      "step": 1680
    },
    {
      "epoch": 3.862857142857143,
      "grad_norm": 4.131640434265137,
      "learning_rate": 1.39435085821436e-05,
      "loss": 0.021,
      "step": 1690
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 0.10714826732873917,
      "learning_rate": 1.3935354960377536e-05,
      "loss": 0.0283,
      "step": 1700
    },
    {
      "epoch": 3.9085714285714284,
      "grad_norm": 6.716972827911377,
      "learning_rate": 1.3927201338611474e-05,
      "loss": 0.032,
      "step": 1710
    },
    {
      "epoch": 3.9314285714285715,
      "grad_norm": 0.06306372582912445,
      "learning_rate": 1.3919047716845412e-05,
      "loss": 0.016,
      "step": 1720
    },
    {
      "epoch": 3.954285714285714,
      "grad_norm": 10.14380168914795,
      "learning_rate": 1.3910894095079348e-05,
      "loss": 0.0689,
      "step": 1730
    },
    {
      "epoch": 3.977142857142857,
      "grad_norm": 2.9141201972961426,
      "learning_rate": 1.3902740473313286e-05,
      "loss": 0.0173,
      "step": 1740
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3791601061820984,
      "learning_rate": 1.3894586851547224e-05,
      "loss": 0.0738,
      "step": 1750
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.987,
      "eval_f1": 0.9344537815126052,
      "eval_loss": 0.0648796558380127,
      "eval_precision": 0.9423728813559322,
      "eval_recall": 0.9266666666666666,
      "eval_runtime": 350.5183,
      "eval_samples_per_second": 8.559,
      "eval_steps_per_second": 1.07,
      "step": 1750
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.987,
      "eval_f1": 0.9344537815126052,
      "eval_loss": 0.0648796558380127,
      "eval_precision": 0.9423728813559322,
      "eval_recall": 0.9266666666666666,
      "eval_runtime": 333.6548,
      "eval_samples_per_second": 8.991,
      "eval_steps_per_second": 1.124,
      "step": 1750
    }
  ],
  "logging_steps": 10,
  "max_steps": 18791,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 43,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 4
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.243516983928992e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": {
    "epochs": 43,
    "gradient_accumulation_steps": 4,
    "learning_rate": 1.5111922581220365e-05,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 8,
    "warmup_steps": 257,
    "weight_decay": 0.07486330069379805
  }
}
