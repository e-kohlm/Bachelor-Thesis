{
  "best_metric": 0.5156993339676499,
  "best_model_checkpoint": "../hyperparameter_search/run-0/checkpoint-2715",
  "epoch": 17.9950289975145,
  "eval_steps": 500,
  "global_step": 2715,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006628003314001657,
      "grad_norm": 31.263988494873047,
      "learning_rate": 5.8210166801912015e-09,
      "loss": 0.8633,
      "step": 1
    },
    {
      "epoch": 0.06628003314001657,
      "grad_norm": 91.11425018310547,
      "learning_rate": 5.8210166801912015e-08,
      "loss": 0.8469,
      "step": 10
    },
    {
      "epoch": 0.13256006628003314,
      "grad_norm": 22.372928619384766,
      "learning_rate": 1.1642033360382403e-07,
      "loss": 0.8279,
      "step": 20
    },
    {
      "epoch": 0.1988400994200497,
      "grad_norm": 20.86929702758789,
      "learning_rate": 1.7463050040573604e-07,
      "loss": 0.8094,
      "step": 30
    },
    {
      "epoch": 0.2651201325600663,
      "grad_norm": 23.017671585083008,
      "learning_rate": 2.3284066720764806e-07,
      "loss": 0.7526,
      "step": 40
    },
    {
      "epoch": 0.33140016570008285,
      "grad_norm": 25.87468147277832,
      "learning_rate": 2.910508340095601e-07,
      "loss": 0.7051,
      "step": 50
    },
    {
      "epoch": 0.3976801988400994,
      "grad_norm": 17.71041488647461,
      "learning_rate": 3.492610008114721e-07,
      "loss": 0.6364,
      "step": 60
    },
    {
      "epoch": 0.463960231980116,
      "grad_norm": 31.945938110351562,
      "learning_rate": 4.074711676133841e-07,
      "loss": 0.5898,
      "step": 70
    },
    {
      "epoch": 0.5302402651201326,
      "grad_norm": 12.256519317626953,
      "learning_rate": 4.656813344152961e-07,
      "loss": 0.5178,
      "step": 80
    },
    {
      "epoch": 0.5965202982601492,
      "grad_norm": 15.457810401916504,
      "learning_rate": 5.238915012172081e-07,
      "loss": 0.4713,
      "step": 90
    },
    {
      "epoch": 0.6628003314001657,
      "grad_norm": 18.25419807434082,
      "learning_rate": 5.821016680191202e-07,
      "loss": 0.4295,
      "step": 100
    },
    {
      "epoch": 0.7290803645401823,
      "grad_norm": 25.175025939941406,
      "learning_rate": 6.403118348210321e-07,
      "loss": 0.3905,
      "step": 110
    },
    {
      "epoch": 0.7953603976801988,
      "grad_norm": 13.381843566894531,
      "learning_rate": 6.985220016229442e-07,
      "loss": 0.3913,
      "step": 120
    },
    {
      "epoch": 0.8616404308202155,
      "grad_norm": 29.831554412841797,
      "learning_rate": 7.567321684248563e-07,
      "loss": 0.3556,
      "step": 130
    },
    {
      "epoch": 0.927920463960232,
      "grad_norm": 31.940052032470703,
      "learning_rate": 8.149423352267682e-07,
      "loss": 0.3613,
      "step": 140
    },
    {
      "epoch": 0.9942004971002486,
      "grad_norm": 36.06698989868164,
      "learning_rate": 8.731525020286802e-07,
      "loss": 0.3325,
      "step": 150
    },
    {
      "epoch": 0.9942004971002486,
      "eval_accuracy": 0.9041344294003868,
      "eval_f1": 0.0,
      "eval_loss": 0.36114227771759033,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 1275.0745,
      "eval_samples_per_second": 6.491,
      "eval_steps_per_second": 0.812,
      "step": 150
    },
    {
      "epoch": 0.9942004971002486,
      "eval_accuracy": 0.9041344294003868,
      "eval_f1": 0.0,
      "eval_loss": 0.36114227771759033,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 1229.4727,
      "eval_samples_per_second": 6.732,
      "eval_steps_per_second": 0.842,
      "step": 150
    },
    {
      "epoch": 1.0604805302402651,
      "grad_norm": 12.543525695800781,
      "learning_rate": 9.313626688305922e-07,
      "loss": 0.3497,
      "step": 160
    },
    {
      "epoch": 1.1267605633802817,
      "grad_norm": 11.905604362487793,
      "learning_rate": 9.895728356325041e-07,
      "loss": 0.3318,
      "step": 170
    },
    {
      "epoch": 1.1930405965202984,
      "grad_norm": 21.375038146972656,
      "learning_rate": 1.0477830024344162e-06,
      "loss": 0.3215,
      "step": 180
    },
    {
      "epoch": 1.2593206296603148,
      "grad_norm": 6.467016220092773,
      "learning_rate": 1.1059931692363283e-06,
      "loss": 0.3689,
      "step": 190
    },
    {
      "epoch": 1.3256006628003314,
      "grad_norm": 13.737393379211426,
      "learning_rate": 1.1142713645151554e-06,
      "loss": 0.3566,
      "step": 200
    },
    {
      "epoch": 1.391880695940348,
      "grad_norm": 8.077312469482422,
      "learning_rate": 1.1100665669132114e-06,
      "loss": 0.3386,
      "step": 210
    },
    {
      "epoch": 1.4581607290803644,
      "grad_norm": 10.8502779006958,
      "learning_rate": 1.1058617693112677e-06,
      "loss": 0.3512,
      "step": 220
    },
    {
      "epoch": 1.5244407622203813,
      "grad_norm": 6.407405853271484,
      "learning_rate": 1.1016569717093234e-06,
      "loss": 0.3134,
      "step": 230
    },
    {
      "epoch": 1.5907207953603977,
      "grad_norm": 6.736649990081787,
      "learning_rate": 1.0974521741073797e-06,
      "loss": 0.3428,
      "step": 240
    },
    {
      "epoch": 1.6570008285004143,
      "grad_norm": 7.778434753417969,
      "learning_rate": 1.0932473765054357e-06,
      "loss": 0.3196,
      "step": 250
    },
    {
      "epoch": 1.723280861640431,
      "grad_norm": 24.725099563598633,
      "learning_rate": 1.0890425789034917e-06,
      "loss": 0.3004,
      "step": 260
    },
    {
      "epoch": 1.7895608947804473,
      "grad_norm": 9.358606338500977,
      "learning_rate": 1.0848377813015477e-06,
      "loss": 0.3275,
      "step": 270
    },
    {
      "epoch": 1.855840927920464,
      "grad_norm": 13.17846393585205,
      "learning_rate": 1.0806329836996037e-06,
      "loss": 0.3051,
      "step": 280
    },
    {
      "epoch": 1.9221209610604806,
      "grad_norm": 6.272348403930664,
      "learning_rate": 1.0764281860976597e-06,
      "loss": 0.2704,
      "step": 290
    },
    {
      "epoch": 1.988400994200497,
      "grad_norm": 7.14018440246582,
      "learning_rate": 1.0722233884957157e-06,
      "loss": 0.3008,
      "step": 300
    },
    {
      "epoch": 1.9950289975144988,
      "eval_accuracy": 0.9084864603481625,
      "eval_f1": 0.04539722572509458,
      "eval_loss": 0.32408297061920166,
      "eval_precision": 0.47368421052631576,
      "eval_recall": 0.02384105960264901,
      "eval_runtime": 1184.6011,
      "eval_samples_per_second": 6.987,
      "eval_steps_per_second": 0.874,
      "step": 301
    },
    {
      "epoch": 1.9950289975144988,
      "eval_accuracy": 0.9084864603481625,
      "eval_f1": 0.04539722572509458,
      "eval_loss": 0.32408297061920166,
      "eval_precision": 0.47368421052631576,
      "eval_recall": 0.02384105960264901,
      "eval_runtime": 1190.1457,
      "eval_samples_per_second": 6.955,
      "eval_steps_per_second": 0.87,
      "step": 301
    },
    {
      "epoch": 2.054681027340514,
      "grad_norm": 10.504290580749512,
      "learning_rate": 1.0680185908937717e-06,
      "loss": 0.3103,
      "step": 310
    },
    {
      "epoch": 2.1209610604805302,
      "grad_norm": 13.104262351989746,
      "learning_rate": 1.0638137932918277e-06,
      "loss": 0.2774,
      "step": 320
    },
    {
      "epoch": 2.1872410936205466,
      "grad_norm": 7.804155349731445,
      "learning_rate": 1.0596089956898837e-06,
      "loss": 0.3175,
      "step": 330
    },
    {
      "epoch": 2.2535211267605635,
      "grad_norm": 12.806668281555176,
      "learning_rate": 1.0554041980879399e-06,
      "loss": 0.2939,
      "step": 340
    },
    {
      "epoch": 2.31980115990058,
      "grad_norm": 8.209358215332031,
      "learning_rate": 1.0511994004859957e-06,
      "loss": 0.3007,
      "step": 350
    },
    {
      "epoch": 2.3860811930405967,
      "grad_norm": 8.083577156066895,
      "learning_rate": 1.0469946028840519e-06,
      "loss": 0.2915,
      "step": 360
    },
    {
      "epoch": 2.452361226180613,
      "grad_norm": 11.993276596069336,
      "learning_rate": 1.0427898052821079e-06,
      "loss": 0.3011,
      "step": 370
    },
    {
      "epoch": 2.5186412593206295,
      "grad_norm": 6.266880035400391,
      "learning_rate": 1.0385850076801639e-06,
      "loss": 0.2882,
      "step": 380
    },
    {
      "epoch": 2.5849212924606464,
      "grad_norm": 6.055278301239014,
      "learning_rate": 1.0343802100782199e-06,
      "loss": 0.3053,
      "step": 390
    },
    {
      "epoch": 2.651201325600663,
      "grad_norm": 55.66518783569336,
      "learning_rate": 1.0301754124762759e-06,
      "loss": 0.2913,
      "step": 400
    },
    {
      "epoch": 2.717481358740679,
      "grad_norm": 6.4583048820495605,
      "learning_rate": 1.0259706148743319e-06,
      "loss": 0.2867,
      "step": 410
    },
    {
      "epoch": 2.783761391880696,
      "grad_norm": 7.417133331298828,
      "learning_rate": 1.0217658172723879e-06,
      "loss": 0.2741,
      "step": 420
    },
    {
      "epoch": 2.8500414250207124,
      "grad_norm": 8.503110885620117,
      "learning_rate": 1.0175610196704439e-06,
      "loss": 0.2964,
      "step": 430
    },
    {
      "epoch": 2.916321458160729,
      "grad_norm": 7.030170917510986,
      "learning_rate": 1.0133562220685e-06,
      "loss": 0.3054,
      "step": 440
    },
    {
      "epoch": 2.9826014913007457,
      "grad_norm": 5.278331756591797,
      "learning_rate": 1.009151424466556e-06,
      "loss": 0.3005,
      "step": 450
    },
    {
      "epoch": 2.995857497928749,
      "eval_accuracy": 0.910178916827853,
      "eval_f1": 0.10804321728691477,
      "eval_loss": 0.29563388228416443,
      "eval_precision": 0.5769230769230769,
      "eval_recall": 0.059602649006622516,
      "eval_runtime": 1296.0841,
      "eval_samples_per_second": 6.386,
      "eval_steps_per_second": 0.799,
      "step": 452
    },
    {
      "epoch": 2.995857497928749,
      "eval_accuracy": 0.910178916827853,
      "eval_f1": 0.10804321728691477,
      "eval_loss": 0.29563388228416443,
      "eval_precision": 0.5769230769230769,
      "eval_recall": 0.059602649006622516,
      "eval_runtime": 1305.8305,
      "eval_samples_per_second": 6.338,
      "eval_steps_per_second": 0.793,
      "step": 452
    },
    {
      "epoch": 3.048881524440762,
      "grad_norm": 7.022629261016846,
      "learning_rate": 1.004946626864612e-06,
      "loss": 0.2597,
      "step": 460
    },
    {
      "epoch": 3.115161557580779,
      "grad_norm": 5.656550407409668,
      "learning_rate": 1.000741829262668e-06,
      "loss": 0.2639,
      "step": 470
    },
    {
      "epoch": 3.1814415907207954,
      "grad_norm": 7.5886616706848145,
      "learning_rate": 9.96537031660724e-07,
      "loss": 0.2881,
      "step": 480
    },
    {
      "epoch": 3.2477216238608118,
      "grad_norm": 8.22104263305664,
      "learning_rate": 9.9233223405878e-07,
      "loss": 0.2646,
      "step": 490
    },
    {
      "epoch": 3.3140016570008286,
      "grad_norm": 9.207550048828125,
      "learning_rate": 9.88127436456836e-07,
      "loss": 0.2777,
      "step": 500
    },
    {
      "epoch": 3.380281690140845,
      "grad_norm": 7.4068145751953125,
      "learning_rate": 9.839226388548921e-07,
      "loss": 0.291,
      "step": 510
    },
    {
      "epoch": 3.446561723280862,
      "grad_norm": 5.62319278717041,
      "learning_rate": 9.79717841252948e-07,
      "loss": 0.2509,
      "step": 520
    },
    {
      "epoch": 3.5128417564208783,
      "grad_norm": 5.212287425994873,
      "learning_rate": 9.755130436510041e-07,
      "loss": 0.2899,
      "step": 530
    },
    {
      "epoch": 3.5791217895608947,
      "grad_norm": 7.446111679077148,
      "learning_rate": 9.713082460490601e-07,
      "loss": 0.2936,
      "step": 540
    },
    {
      "epoch": 3.6454018227009115,
      "grad_norm": 5.4910197257995605,
      "learning_rate": 9.671034484471161e-07,
      "loss": 0.2721,
      "step": 550
    },
    {
      "epoch": 3.711681855840928,
      "grad_norm": 7.415546417236328,
      "learning_rate": 9.628986508451721e-07,
      "loss": 0.2856,
      "step": 560
    },
    {
      "epoch": 3.7779618889809443,
      "grad_norm": 6.1195173263549805,
      "learning_rate": 9.586938532432281e-07,
      "loss": 0.2971,
      "step": 570
    },
    {
      "epoch": 3.844241922120961,
      "grad_norm": 12.393099784851074,
      "learning_rate": 9.544890556412841e-07,
      "loss": 0.2801,
      "step": 580
    },
    {
      "epoch": 3.9105219552609776,
      "grad_norm": 7.71267032623291,
      "learning_rate": 9.502842580393401e-07,
      "loss": 0.28,
      "step": 590
    },
    {
      "epoch": 3.976801988400994,
      "grad_norm": 6.281956672668457,
      "learning_rate": 9.460794604373961e-07,
      "loss": 0.2898,
      "step": 600
    },
    {
      "epoch": 3.996685998342999,
      "eval_accuracy": 0.9154980657640233,
      "eval_f1": 0.17861339600470033,
      "eval_loss": 0.2745998203754425,
      "eval_precision": 0.7916666666666666,
      "eval_recall": 0.10066225165562914,
      "eval_runtime": 1997.1422,
      "eval_samples_per_second": 4.144,
      "eval_steps_per_second": 0.518,
      "step": 603
    },
    {
      "epoch": 3.996685998342999,
      "eval_accuracy": 0.9154980657640233,
      "eval_f1": 0.17861339600470033,
      "eval_loss": 0.2745998203754425,
      "eval_precision": 0.7916666666666666,
      "eval_recall": 0.10066225165562914,
      "eval_runtime": 1870.0653,
      "eval_samples_per_second": 4.426,
      "eval_steps_per_second": 0.553,
      "step": 603
    },
    {
      "epoch": 4.043082021541011,
      "grad_norm": 9.03317642211914,
      "learning_rate": 9.418746628354522e-07,
      "loss": 0.2627,
      "step": 610
    },
    {
      "epoch": 4.109362054681028,
      "grad_norm": 8.03544807434082,
      "learning_rate": 9.376698652335081e-07,
      "loss": 0.275,
      "step": 620
    },
    {
      "epoch": 4.175642087821044,
      "grad_norm": 13.55727481842041,
      "learning_rate": 9.334650676315642e-07,
      "loss": 0.2519,
      "step": 630
    },
    {
      "epoch": 4.2419221209610605,
      "grad_norm": 6.592374324798584,
      "learning_rate": 9.292602700296202e-07,
      "loss": 0.2791,
      "step": 640
    },
    {
      "epoch": 4.308202154101077,
      "grad_norm": 10.04865550994873,
      "learning_rate": 9.250554724276762e-07,
      "loss": 0.2957,
      "step": 650
    },
    {
      "epoch": 4.374482187241093,
      "grad_norm": 6.989992141723633,
      "learning_rate": 9.208506748257322e-07,
      "loss": 0.265,
      "step": 660
    },
    {
      "epoch": 4.44076222038111,
      "grad_norm": 5.742043972015381,
      "learning_rate": 9.166458772237883e-07,
      "loss": 0.2781,
      "step": 670
    },
    {
      "epoch": 4.507042253521127,
      "grad_norm": 12.191655158996582,
      "learning_rate": 9.124410796218442e-07,
      "loss": 0.2705,
      "step": 680
    },
    {
      "epoch": 4.573322286661144,
      "grad_norm": 29.087491989135742,
      "learning_rate": 9.082362820199003e-07,
      "loss": 0.2542,
      "step": 690
    },
    {
      "epoch": 4.63960231980116,
      "grad_norm": 7.056267261505127,
      "learning_rate": 9.040314844179564e-07,
      "loss": 0.2663,
      "step": 700
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 5.6896185874938965,
      "learning_rate": 8.998266868160124e-07,
      "loss": 0.2253,
      "step": 710
    },
    {
      "epoch": 4.7721623860811935,
      "grad_norm": 13.919315338134766,
      "learning_rate": 8.956218892140684e-07,
      "loss": 0.2676,
      "step": 720
    },
    {
      "epoch": 4.838442419221209,
      "grad_norm": 7.823299407958984,
      "learning_rate": 8.914170916121245e-07,
      "loss": 0.2581,
      "step": 730
    },
    {
      "epoch": 4.904722452361226,
      "grad_norm": 13.798311233520508,
      "learning_rate": 8.872122940101804e-07,
      "loss": 0.2528,
      "step": 740
    },
    {
      "epoch": 4.971002485501243,
      "grad_norm": 10.15721607208252,
      "learning_rate": 8.830074964082365e-07,
      "loss": 0.2363,
      "step": 750
    },
    {
      "epoch": 4.9975144987572495,
      "eval_accuracy": 0.9191247582205029,
      "eval_f1": 0.2508398656215006,
      "eval_loss": 0.25728267431259155,
      "eval_precision": 0.8115942028985508,
      "eval_recall": 0.14834437086092717,
      "eval_runtime": 1397.4934,
      "eval_samples_per_second": 5.923,
      "eval_steps_per_second": 0.741,
      "step": 754
    },
    {
      "epoch": 4.9975144987572495,
      "eval_accuracy": 0.9191247582205029,
      "eval_f1": 0.2508398656215006,
      "eval_loss": 0.25728267431259155,
      "eval_precision": 0.8115942028985508,
      "eval_recall": 0.14834437086092717,
      "eval_runtime": 1315.1738,
      "eval_samples_per_second": 6.293,
      "eval_steps_per_second": 0.787,
      "step": 754
    },
    {
      "epoch": 5.037282518641259,
      "grad_norm": 7.783010482788086,
      "learning_rate": 8.788026988062924e-07,
      "loss": 0.2574,
      "step": 760
    },
    {
      "epoch": 5.103562551781276,
      "grad_norm": 8.962998390197754,
      "learning_rate": 8.745979012043485e-07,
      "loss": 0.2456,
      "step": 770
    },
    {
      "epoch": 5.169842584921293,
      "grad_norm": 10.534239768981934,
      "learning_rate": 8.703931036024045e-07,
      "loss": 0.256,
      "step": 780
    },
    {
      "epoch": 5.236122618061309,
      "grad_norm": 6.198122024536133,
      "learning_rate": 8.661883060004605e-07,
      "loss": 0.2064,
      "step": 790
    },
    {
      "epoch": 5.302402651201326,
      "grad_norm": 5.084803104400635,
      "learning_rate": 8.619835083985165e-07,
      "loss": 0.245,
      "step": 800
    },
    {
      "epoch": 5.368682684341342,
      "grad_norm": 13.4791259765625,
      "learning_rate": 8.577787107965726e-07,
      "loss": 0.2562,
      "step": 810
    },
    {
      "epoch": 5.434962717481358,
      "grad_norm": 7.791759967803955,
      "learning_rate": 8.535739131946285e-07,
      "loss": 0.2272,
      "step": 820
    },
    {
      "epoch": 5.501242750621375,
      "grad_norm": 5.92961311340332,
      "learning_rate": 8.493691155926846e-07,
      "loss": 0.2394,
      "step": 830
    },
    {
      "epoch": 5.567522783761392,
      "grad_norm": 5.933164596557617,
      "learning_rate": 8.451643179907406e-07,
      "loss": 0.25,
      "step": 840
    },
    {
      "epoch": 5.633802816901408,
      "grad_norm": 6.113883972167969,
      "learning_rate": 8.409595203887966e-07,
      "loss": 0.2571,
      "step": 850
    },
    {
      "epoch": 5.700082850041425,
      "grad_norm": 30.675275802612305,
      "learning_rate": 8.367547227868526e-07,
      "loss": 0.2225,
      "step": 860
    },
    {
      "epoch": 5.766362883181442,
      "grad_norm": 5.5552144050598145,
      "learning_rate": 8.325499251849087e-07,
      "loss": 0.2508,
      "step": 870
    },
    {
      "epoch": 5.832642916321458,
      "grad_norm": 12.926629066467285,
      "learning_rate": 8.283451275829646e-07,
      "loss": 0.2594,
      "step": 880
    },
    {
      "epoch": 5.8989229494614746,
      "grad_norm": 5.266103267669678,
      "learning_rate": 8.241403299810207e-07,
      "loss": 0.2519,
      "step": 890
    },
    {
      "epoch": 5.965202982601491,
      "grad_norm": 4.115339279174805,
      "learning_rate": 8.199355323790767e-07,
      "loss": 0.227,
      "step": 900
    },
    {
      "epoch": 5.998342999171499,
      "eval_accuracy": 0.9216634429400387,
      "eval_f1": 0.28159645232815966,
      "eval_loss": 0.24267233908176422,
      "eval_precision": 0.8639455782312925,
      "eval_recall": 0.16821192052980133,
      "eval_runtime": 1200.8246,
      "eval_samples_per_second": 6.893,
      "eval_steps_per_second": 0.862,
      "step": 905
    },
    {
      "epoch": 5.998342999171499,
      "eval_accuracy": 0.9216634429400387,
      "eval_f1": 0.28159645232815966,
      "eval_loss": 0.24267233908176422,
      "eval_precision": 0.8639455782312925,
      "eval_recall": 0.16821192052980133,
      "eval_runtime": 1199.6172,
      "eval_samples_per_second": 6.9,
      "eval_steps_per_second": 0.863,
      "step": 905
    },
    {
      "epoch": 6.031483015741508,
      "grad_norm": 8.773797035217285,
      "learning_rate": 8.157307347771327e-07,
      "loss": 0.2515,
      "step": 910
    },
    {
      "epoch": 6.097763048881524,
      "grad_norm": 5.114437103271484,
      "learning_rate": 8.115259371751887e-07,
      "loss": 0.2342,
      "step": 920
    },
    {
      "epoch": 6.164043082021541,
      "grad_norm": 4.621519088745117,
      "learning_rate": 8.073211395732448e-07,
      "loss": 0.2415,
      "step": 930
    },
    {
      "epoch": 6.230323115161558,
      "grad_norm": 5.943474769592285,
      "learning_rate": 8.031163419713007e-07,
      "loss": 0.2302,
      "step": 940
    },
    {
      "epoch": 6.296603148301574,
      "grad_norm": 6.992000579833984,
      "learning_rate": 7.989115443693568e-07,
      "loss": 0.2276,
      "step": 950
    },
    {
      "epoch": 6.362883181441591,
      "grad_norm": 5.5979814529418945,
      "learning_rate": 7.947067467674128e-07,
      "loss": 0.221,
      "step": 960
    },
    {
      "epoch": 6.4291632145816076,
      "grad_norm": 10.04655933380127,
      "learning_rate": 7.905019491654688e-07,
      "loss": 0.2658,
      "step": 970
    },
    {
      "epoch": 6.4954432477216235,
      "grad_norm": 7.016721248626709,
      "learning_rate": 7.862971515635248e-07,
      "loss": 0.2461,
      "step": 980
    },
    {
      "epoch": 6.56172328086164,
      "grad_norm": 8.890090942382812,
      "learning_rate": 7.820923539615809e-07,
      "loss": 0.2274,
      "step": 990
    },
    {
      "epoch": 6.628003314001657,
      "grad_norm": 4.641598224639893,
      "learning_rate": 7.778875563596368e-07,
      "loss": 0.2076,
      "step": 1000
    },
    {
      "epoch": 6.694283347141674,
      "grad_norm": 16.80718421936035,
      "learning_rate": 7.736827587576929e-07,
      "loss": 0.2375,
      "step": 1010
    },
    {
      "epoch": 6.76056338028169,
      "grad_norm": 4.982463836669922,
      "learning_rate": 7.694779611557488e-07,
      "loss": 0.2286,
      "step": 1020
    },
    {
      "epoch": 6.826843413421707,
      "grad_norm": 6.021143436431885,
      "learning_rate": 7.652731635538049e-07,
      "loss": 0.2251,
      "step": 1030
    },
    {
      "epoch": 6.893123446561724,
      "grad_norm": 7.239780426025391,
      "learning_rate": 7.610683659518609e-07,
      "loss": 0.2192,
      "step": 1040
    },
    {
      "epoch": 6.95940347970174,
      "grad_norm": 5.6482038497924805,
      "learning_rate": 7.568635683499169e-07,
      "loss": 0.2292,
      "step": 1050
    },
    {
      "epoch": 6.99917149958575,
      "eval_accuracy": 0.9239603481624759,
      "eval_f1": 0.32146709816612723,
      "eval_loss": 0.226582333445549,
      "eval_precision": 0.8662790697674418,
      "eval_recall": 0.19735099337748344,
      "eval_runtime": 1206.8125,
      "eval_samples_per_second": 6.859,
      "eval_steps_per_second": 0.858,
      "step": 1056
    },
    {
      "epoch": 6.99917149958575,
      "eval_accuracy": 0.9239603481624759,
      "eval_f1": 0.32146709816612723,
      "eval_loss": 0.226582333445549,
      "eval_precision": 0.8662790697674418,
      "eval_recall": 0.19735099337748344,
      "eval_runtime": 1214.1448,
      "eval_samples_per_second": 6.817,
      "eval_steps_per_second": 0.852,
      "step": 1056
    },
    {
      "epoch": 7.0256835128417565,
      "grad_norm": 6.42064094543457,
      "learning_rate": 7.526587707479729e-07,
      "loss": 0.2276,
      "step": 1060
    },
    {
      "epoch": 7.091963545981773,
      "grad_norm": 20.962099075317383,
      "learning_rate": 7.48453973146029e-07,
      "loss": 0.2329,
      "step": 1070
    },
    {
      "epoch": 7.158243579121789,
      "grad_norm": 5.161554336547852,
      "learning_rate": 7.442491755440849e-07,
      "loss": 0.2146,
      "step": 1080
    },
    {
      "epoch": 7.224523612261806,
      "grad_norm": 27.508262634277344,
      "learning_rate": 7.40044377942141e-07,
      "loss": 0.2219,
      "step": 1090
    },
    {
      "epoch": 7.290803645401823,
      "grad_norm": 23.109872817993164,
      "learning_rate": 7.35839580340197e-07,
      "loss": 0.2185,
      "step": 1100
    },
    {
      "epoch": 7.357083678541839,
      "grad_norm": 5.577244758605957,
      "learning_rate": 7.31634782738253e-07,
      "loss": 0.2342,
      "step": 1110
    },
    {
      "epoch": 7.423363711681856,
      "grad_norm": 6.190860748291016,
      "learning_rate": 7.27429985136309e-07,
      "loss": 0.2146,
      "step": 1120
    },
    {
      "epoch": 7.489643744821873,
      "grad_norm": 5.184406280517578,
      "learning_rate": 7.232251875343651e-07,
      "loss": 0.2045,
      "step": 1130
    },
    {
      "epoch": 7.555923777961889,
      "grad_norm": 26.33963966369629,
      "learning_rate": 7.19020389932421e-07,
      "loss": 0.2334,
      "step": 1140
    },
    {
      "epoch": 7.6222038111019055,
      "grad_norm": 5.047670841217041,
      "learning_rate": 7.148155923304771e-07,
      "loss": 0.2232,
      "step": 1150
    },
    {
      "epoch": 7.688483844241922,
      "grad_norm": 5.183322906494141,
      "learning_rate": 7.106107947285331e-07,
      "loss": 0.2221,
      "step": 1160
    },
    {
      "epoch": 7.754763877381938,
      "grad_norm": 7.031914710998535,
      "learning_rate": 7.064059971265891e-07,
      "loss": 0.2121,
      "step": 1170
    },
    {
      "epoch": 7.821043910521955,
      "grad_norm": 6.306288719177246,
      "learning_rate": 7.022011995246451e-07,
      "loss": 0.207,
      "step": 1180
    },
    {
      "epoch": 7.887323943661972,
      "grad_norm": 9.332119941711426,
      "learning_rate": 6.979964019227013e-07,
      "loss": 0.222,
      "step": 1190
    },
    {
      "epoch": 7.953603976801988,
      "grad_norm": 4.8039937019348145,
      "learning_rate": 6.937916043207572e-07,
      "loss": 0.2192,
      "step": 1200
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9261363636363636,
      "eval_f1": 0.3479188900747065,
      "eval_loss": 0.2178557962179184,
      "eval_precision": 0.8956043956043956,
      "eval_recall": 0.21589403973509932,
      "eval_runtime": 1208.1853,
      "eval_samples_per_second": 6.851,
      "eval_steps_per_second": 0.857,
      "step": 1207
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9261363636363636,
      "eval_f1": 0.3479188900747065,
      "eval_loss": 0.2178557962179184,
      "eval_precision": 0.8956043956043956,
      "eval_recall": 0.21589403973509932,
      "eval_runtime": 1206.6936,
      "eval_samples_per_second": 6.859,
      "eval_steps_per_second": 0.858,
      "step": 1207
    },
    {
      "epoch": 8.019884009942006,
      "grad_norm": 6.605312347412109,
      "learning_rate": 6.895868067188133e-07,
      "loss": 0.2099,
      "step": 1210
    },
    {
      "epoch": 8.086164043082022,
      "grad_norm": 6.399252414703369,
      "learning_rate": 6.853820091168693e-07,
      "loss": 0.2247,
      "step": 1220
    },
    {
      "epoch": 8.152444076222038,
      "grad_norm": 10.37939167022705,
      "learning_rate": 6.811772115149253e-07,
      "loss": 0.2139,
      "step": 1230
    },
    {
      "epoch": 8.218724109362055,
      "grad_norm": 6.8169097900390625,
      "learning_rate": 6.769724139129813e-07,
      "loss": 0.2156,
      "step": 1240
    },
    {
      "epoch": 8.285004142502071,
      "grad_norm": 4.902048110961914,
      "learning_rate": 6.727676163110374e-07,
      "loss": 0.2135,
      "step": 1250
    },
    {
      "epoch": 8.351284175642087,
      "grad_norm": 7.513495922088623,
      "learning_rate": 6.685628187090933e-07,
      "loss": 0.2134,
      "step": 1260
    },
    {
      "epoch": 8.417564208782105,
      "grad_norm": 5.04834508895874,
      "learning_rate": 6.643580211071494e-07,
      "loss": 0.2167,
      "step": 1270
    },
    {
      "epoch": 8.483844241922121,
      "grad_norm": 4.5880866050720215,
      "learning_rate": 6.601532235052053e-07,
      "loss": 0.1972,
      "step": 1280
    },
    {
      "epoch": 8.550124275062137,
      "grad_norm": 6.096904754638672,
      "learning_rate": 6.559484259032614e-07,
      "loss": 0.2164,
      "step": 1290
    },
    {
      "epoch": 8.616404308202155,
      "grad_norm": 7.848718166351318,
      "learning_rate": 6.517436283013174e-07,
      "loss": 0.1882,
      "step": 1300
    },
    {
      "epoch": 8.68268434134217,
      "grad_norm": 10.26037311553955,
      "learning_rate": 6.475388306993734e-07,
      "loss": 0.1999,
      "step": 1310
    },
    {
      "epoch": 8.748964374482187,
      "grad_norm": 13.776142120361328,
      "learning_rate": 6.433340330974294e-07,
      "loss": 0.1837,
      "step": 1320
    },
    {
      "epoch": 8.815244407622204,
      "grad_norm": 5.771705627441406,
      "learning_rate": 6.391292354954855e-07,
      "loss": 0.204,
      "step": 1330
    },
    {
      "epoch": 8.88152444076222,
      "grad_norm": 17.37812614440918,
      "learning_rate": 6.349244378935414e-07,
      "loss": 0.2133,
      "step": 1340
    },
    {
      "epoch": 8.947804473902236,
      "grad_norm": 4.738296031951904,
      "learning_rate": 6.307196402915975e-07,
      "loss": 0.2114,
      "step": 1350
    },
    {
      "epoch": 8.994200497100248,
      "eval_accuracy": 0.9271034816247582,
      "eval_f1": 0.36325237592397047,
      "eval_loss": 0.20854532718658447,
      "eval_precision": 0.8958333333333334,
      "eval_recall": 0.22781456953642384,
      "eval_runtime": 1167.4091,
      "eval_samples_per_second": 7.09,
      "eval_steps_per_second": 0.887,
      "step": 1357
    },
    {
      "epoch": 8.994200497100248,
      "eval_accuracy": 0.9271034816247582,
      "eval_f1": 0.36325237592397047,
      "eval_loss": 0.20854532718658447,
      "eval_precision": 0.8958333333333334,
      "eval_recall": 0.22781456953642384,
      "eval_runtime": 1192.2433,
      "eval_samples_per_second": 6.942,
      "eval_steps_per_second": 0.868,
      "step": 1357
    },
    {
      "epoch": 9.014084507042254,
      "grad_norm": 5.017783164978027,
      "learning_rate": 6.265148426896535e-07,
      "loss": 0.2159,
      "step": 1360
    },
    {
      "epoch": 9.08036454018227,
      "grad_norm": 12.586617469787598,
      "learning_rate": 6.223100450877095e-07,
      "loss": 0.2033,
      "step": 1370
    },
    {
      "epoch": 9.146644573322286,
      "grad_norm": 6.031528472900391,
      "learning_rate": 6.181052474857655e-07,
      "loss": 0.2136,
      "step": 1380
    },
    {
      "epoch": 9.212924606462304,
      "grad_norm": 4.520636081695557,
      "learning_rate": 6.139004498838216e-07,
      "loss": 0.2057,
      "step": 1390
    },
    {
      "epoch": 9.27920463960232,
      "grad_norm": 5.801137447357178,
      "learning_rate": 6.096956522818775e-07,
      "loss": 0.1795,
      "step": 1400
    },
    {
      "epoch": 9.345484672742336,
      "grad_norm": 5.141849517822266,
      "learning_rate": 6.054908546799336e-07,
      "loss": 0.1774,
      "step": 1410
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 4.982614517211914,
      "learning_rate": 6.012860570779896e-07,
      "loss": 0.2028,
      "step": 1420
    },
    {
      "epoch": 9.47804473902237,
      "grad_norm": 4.922280311584473,
      "learning_rate": 5.970812594760456e-07,
      "loss": 0.1974,
      "step": 1430
    },
    {
      "epoch": 9.544324772162387,
      "grad_norm": 6.29597806930542,
      "learning_rate": 5.928764618741016e-07,
      "loss": 0.2234,
      "step": 1440
    },
    {
      "epoch": 9.610604805302403,
      "grad_norm": 6.4327263832092285,
      "learning_rate": 5.886716642721577e-07,
      "loss": 0.198,
      "step": 1450
    },
    {
      "epoch": 9.676884838442419,
      "grad_norm": 7.386579990386963,
      "learning_rate": 5.844668666702136e-07,
      "loss": 0.2266,
      "step": 1460
    },
    {
      "epoch": 9.743164871582437,
      "grad_norm": 4.613065719604492,
      "learning_rate": 5.802620690682697e-07,
      "loss": 0.1918,
      "step": 1470
    },
    {
      "epoch": 9.809444904722453,
      "grad_norm": 13.673530578613281,
      "learning_rate": 5.760572714663257e-07,
      "loss": 0.208,
      "step": 1480
    },
    {
      "epoch": 9.875724937862469,
      "grad_norm": 6.2745161056518555,
      "learning_rate": 5.718524738643817e-07,
      "loss": 0.2167,
      "step": 1490
    },
    {
      "epoch": 9.942004971002486,
      "grad_norm": 6.228554725646973,
      "learning_rate": 5.676476762624377e-07,
      "loss": 0.2039,
      "step": 1500
    },
    {
      "epoch": 9.995028997514499,
      "eval_accuracy": 0.9283123791102514,
      "eval_f1": 0.37775445960125914,
      "eval_loss": 0.20101937651634216,
      "eval_precision": 0.9090909090909091,
      "eval_recall": 0.23841059602649006,
      "eval_runtime": 1192.7593,
      "eval_samples_per_second": 6.939,
      "eval_steps_per_second": 0.868,
      "step": 1508
    },
    {
      "epoch": 9.995028997514499,
      "eval_accuracy": 0.9283123791102514,
      "eval_f1": 0.37775445960125914,
      "eval_loss": 0.20101937651634216,
      "eval_precision": 0.9090909090909091,
      "eval_recall": 0.23841059602649006,
      "eval_runtime": 1341.779,
      "eval_samples_per_second": 6.169,
      "eval_steps_per_second": 0.771,
      "step": 1508
    },
    {
      "epoch": 10.008285004142502,
      "grad_norm": 4.233753681182861,
      "learning_rate": 5.634428786604938e-07,
      "loss": 0.1786,
      "step": 1510
    },
    {
      "epoch": 10.074565037282518,
      "grad_norm": 8.001741409301758,
      "learning_rate": 5.592380810585497e-07,
      "loss": 0.2002,
      "step": 1520
    },
    {
      "epoch": 10.140845070422536,
      "grad_norm": 8.835076332092285,
      "learning_rate": 5.550332834566057e-07,
      "loss": 0.1675,
      "step": 1530
    },
    {
      "epoch": 10.207125103562552,
      "grad_norm": 6.269027233123779,
      "learning_rate": 5.508284858546617e-07,
      "loss": 0.2101,
      "step": 1540
    },
    {
      "epoch": 10.273405136702568,
      "grad_norm": 6.042844772338867,
      "learning_rate": 5.466236882527178e-07,
      "loss": 0.2098,
      "step": 1550
    },
    {
      "epoch": 10.339685169842586,
      "grad_norm": 6.225949764251709,
      "learning_rate": 5.424188906507738e-07,
      "loss": 0.203,
      "step": 1560
    },
    {
      "epoch": 10.405965202982602,
      "grad_norm": 9.157736778259277,
      "learning_rate": 5.382140930488298e-07,
      "loss": 0.187,
      "step": 1570
    },
    {
      "epoch": 10.472245236122617,
      "grad_norm": 5.088829040527344,
      "learning_rate": 5.340092954468858e-07,
      "loss": 0.1985,
      "step": 1580
    },
    {
      "epoch": 10.538525269262635,
      "grad_norm": 11.25454044342041,
      "learning_rate": 5.298044978449418e-07,
      "loss": 0.1833,
      "step": 1590
    },
    {
      "epoch": 10.604805302402651,
      "grad_norm": 4.561530113220215,
      "learning_rate": 5.255997002429978e-07,
      "loss": 0.2017,
      "step": 1600
    },
    {
      "epoch": 10.671085335542667,
      "grad_norm": 4.637657165527344,
      "learning_rate": 5.213949026410539e-07,
      "loss": 0.2033,
      "step": 1610
    },
    {
      "epoch": 10.737365368682685,
      "grad_norm": 8.459409713745117,
      "learning_rate": 5.171901050391099e-07,
      "loss": 0.1817,
      "step": 1620
    },
    {
      "epoch": 10.8036454018227,
      "grad_norm": 4.691905498504639,
      "learning_rate": 5.129853074371659e-07,
      "loss": 0.1818,
      "step": 1630
    },
    {
      "epoch": 10.869925434962717,
      "grad_norm": 5.148805141448975,
      "learning_rate": 5.087805098352219e-07,
      "loss": 0.2013,
      "step": 1640
    },
    {
      "epoch": 10.936205468102735,
      "grad_norm": 10.42292594909668,
      "learning_rate": 5.04575712233278e-07,
      "loss": 0.1978,
      "step": 1650
    },
    {
      "epoch": 10.99585749792875,
      "eval_accuracy": 0.9304883945841392,
      "eval_f1": 0.4114636642784033,
      "eval_loss": 0.19393233954906464,
      "eval_precision": 0.9054054054054054,
      "eval_recall": 0.2662251655629139,
      "eval_runtime": 1179.4007,
      "eval_samples_per_second": 7.018,
      "eval_steps_per_second": 0.878,
      "step": 1659
    },
    {
      "epoch": 10.99585749792875,
      "eval_accuracy": 0.9304883945841392,
      "eval_f1": 0.4114636642784033,
      "eval_loss": 0.19393233954906464,
      "eval_precision": 0.9054054054054054,
      "eval_recall": 0.2662251655629139,
      "eval_runtime": 1174.667,
      "eval_samples_per_second": 7.046,
      "eval_steps_per_second": 0.881,
      "step": 1659
    },
    {
      "epoch": 11.00248550124275,
      "grad_norm": 5.152189254760742,
      "learning_rate": 5.00370914631334e-07,
      "loss": 0.183,
      "step": 1660
    },
    {
      "epoch": 11.068765534382766,
      "grad_norm": 5.423937797546387,
      "learning_rate": 4.9616611702939e-07,
      "loss": 0.2034,
      "step": 1670
    },
    {
      "epoch": 11.135045567522784,
      "grad_norm": 5.515514850616455,
      "learning_rate": 4.919613194274461e-07,
      "loss": 0.1991,
      "step": 1680
    },
    {
      "epoch": 11.2013256006628,
      "grad_norm": 4.7378249168396,
      "learning_rate": 4.877565218255021e-07,
      "loss": 0.1898,
      "step": 1690
    },
    {
      "epoch": 11.267605633802816,
      "grad_norm": 4.544405937194824,
      "learning_rate": 4.835517242235581e-07,
      "loss": 0.1757,
      "step": 1700
    },
    {
      "epoch": 11.333885666942834,
      "grad_norm": 11.083749771118164,
      "learning_rate": 4.793469266216141e-07,
      "loss": 0.1822,
      "step": 1710
    },
    {
      "epoch": 11.40016570008285,
      "grad_norm": 4.906002044677734,
      "learning_rate": 4.7514212901967006e-07,
      "loss": 0.1897,
      "step": 1720
    },
    {
      "epoch": 11.466445733222866,
      "grad_norm": 5.416046142578125,
      "learning_rate": 4.709373314177261e-07,
      "loss": 0.1809,
      "step": 1730
    },
    {
      "epoch": 11.532725766362883,
      "grad_norm": 19.763294219970703,
      "learning_rate": 4.667325338157821e-07,
      "loss": 0.171,
      "step": 1740
    },
    {
      "epoch": 11.5990057995029,
      "grad_norm": 6.677394866943359,
      "learning_rate": 4.625277362138381e-07,
      "loss": 0.1817,
      "step": 1750
    },
    {
      "epoch": 11.665285832642915,
      "grad_norm": 5.68847131729126,
      "learning_rate": 4.5832293861189417e-07,
      "loss": 0.1759,
      "step": 1760
    },
    {
      "epoch": 11.731565865782933,
      "grad_norm": 4.779020309448242,
      "learning_rate": 4.541181410099502e-07,
      "loss": 0.1851,
      "step": 1770
    },
    {
      "epoch": 11.797845898922949,
      "grad_norm": 5.110501289367676,
      "learning_rate": 4.499133434080062e-07,
      "loss": 0.186,
      "step": 1780
    },
    {
      "epoch": 11.864125932062967,
      "grad_norm": 6.241785049438477,
      "learning_rate": 4.4570854580606223e-07,
      "loss": 0.1788,
      "step": 1790
    },
    {
      "epoch": 11.930405965202983,
      "grad_norm": 7.151760578155518,
      "learning_rate": 4.4150374820411823e-07,
      "loss": 0.1898,
      "step": 1800
    },
    {
      "epoch": 11.996685998342999,
      "grad_norm": 5.9746994972229,
      "learning_rate": 4.3729895060217423e-07,
      "loss": 0.1887,
      "step": 1810
    },
    {
      "epoch": 11.996685998342999,
      "eval_accuracy": 0.933389748549323,
      "eval_f1": 0.4506480558325026,
      "eval_loss": 0.1882445365190506,
      "eval_precision": 0.9112903225806451,
      "eval_recall": 0.2993377483443709,
      "eval_runtime": 1147.5378,
      "eval_samples_per_second": 7.213,
      "eval_steps_per_second": 0.902,
      "step": 1810
    },
    {
      "epoch": 11.996685998342999,
      "eval_accuracy": 0.933389748549323,
      "eval_f1": 0.4506480558325026,
      "eval_loss": 0.1882445365190506,
      "eval_precision": 0.9112903225806451,
      "eval_recall": 0.2993377483443709,
      "eval_runtime": 1180.2131,
      "eval_samples_per_second": 7.013,
      "eval_steps_per_second": 0.877,
      "step": 1810
    },
    {
      "epoch": 12.062966031483016,
      "grad_norm": 5.714660167694092,
      "learning_rate": 4.3309415300023023e-07,
      "loss": 0.1804,
      "step": 1820
    },
    {
      "epoch": 12.129246064623032,
      "grad_norm": 6.130439281463623,
      "learning_rate": 4.288893553982863e-07,
      "loss": 0.1931,
      "step": 1830
    },
    {
      "epoch": 12.195526097763048,
      "grad_norm": 4.541530132293701,
      "learning_rate": 4.246845577963423e-07,
      "loss": 0.1696,
      "step": 1840
    },
    {
      "epoch": 12.261806130903066,
      "grad_norm": 5.778137683868408,
      "learning_rate": 4.204797601943983e-07,
      "loss": 0.1949,
      "step": 1850
    },
    {
      "epoch": 12.328086164043082,
      "grad_norm": 6.364988803863525,
      "learning_rate": 4.1627496259245434e-07,
      "loss": 0.1825,
      "step": 1860
    },
    {
      "epoch": 12.394366197183098,
      "grad_norm": 8.710246086120605,
      "learning_rate": 4.1207016499051035e-07,
      "loss": 0.1955,
      "step": 1870
    },
    {
      "epoch": 12.460646230323116,
      "grad_norm": 6.998594284057617,
      "learning_rate": 4.0786536738856635e-07,
      "loss": 0.1662,
      "step": 1880
    },
    {
      "epoch": 12.526926263463132,
      "grad_norm": 9.062559127807617,
      "learning_rate": 4.036605697866224e-07,
      "loss": 0.1822,
      "step": 1890
    },
    {
      "epoch": 12.593206296603148,
      "grad_norm": 5.586736679077148,
      "learning_rate": 3.994557721846784e-07,
      "loss": 0.2005,
      "step": 1900
    },
    {
      "epoch": 12.659486329743165,
      "grad_norm": 4.296246528625488,
      "learning_rate": 3.952509745827344e-07,
      "loss": 0.1806,
      "step": 1910
    },
    {
      "epoch": 12.725766362883181,
      "grad_norm": 4.187483310699463,
      "learning_rate": 3.9104617698079046e-07,
      "loss": 0.1816,
      "step": 1920
    },
    {
      "epoch": 12.792046396023197,
      "grad_norm": 6.840069770812988,
      "learning_rate": 3.8684137937884646e-07,
      "loss": 0.1863,
      "step": 1930
    },
    {
      "epoch": 12.858326429163215,
      "grad_norm": 4.44397497177124,
      "learning_rate": 3.8263658177690246e-07,
      "loss": 0.1754,
      "step": 1940
    },
    {
      "epoch": 12.924606462303231,
      "grad_norm": 9.308977127075195,
      "learning_rate": 3.7843178417495846e-07,
      "loss": 0.1864,
      "step": 1950
    },
    {
      "epoch": 12.990886495443247,
      "grad_norm": 7.633670330047607,
      "learning_rate": 3.742269865730145e-07,
      "loss": 0.1683,
      "step": 1960
    },
    {
      "epoch": 12.99751449875725,
      "eval_accuracy": 0.934477756286267,
      "eval_f1": 0.4748062015503876,
      "eval_loss": 0.18063263595104218,
      "eval_precision": 0.8844765342960289,
      "eval_recall": 0.32450331125827814,
      "eval_runtime": 921.7906,
      "eval_samples_per_second": 8.979,
      "eval_steps_per_second": 1.123,
      "step": 1961
    },
    {
      "epoch": 12.99751449875725,
      "eval_accuracy": 0.934477756286267,
      "eval_f1": 0.4748062015503876,
      "eval_loss": 0.18063263595104218,
      "eval_precision": 0.8844765342960289,
      "eval_recall": 0.32450331125827814,
      "eval_runtime": 923.9582,
      "eval_samples_per_second": 8.958,
      "eval_steps_per_second": 1.12,
      "step": 1961
    },
    {
      "epoch": 13.057166528583265,
      "grad_norm": 5.244739532470703,
      "learning_rate": 3.700221889710705e-07,
      "loss": 0.172,
      "step": 1970
    },
    {
      "epoch": 13.12344656172328,
      "grad_norm": 8.279306411743164,
      "learning_rate": 3.658173913691265e-07,
      "loss": 0.1751,
      "step": 1980
    },
    {
      "epoch": 13.189726594863297,
      "grad_norm": 8.64757251739502,
      "learning_rate": 3.6161259376718257e-07,
      "loss": 0.1785,
      "step": 1990
    },
    {
      "epoch": 13.256006628003314,
      "grad_norm": 4.212028980255127,
      "learning_rate": 3.5740779616523857e-07,
      "loss": 0.1847,
      "step": 2000
    },
    {
      "epoch": 13.32228666114333,
      "grad_norm": 4.408637523651123,
      "learning_rate": 3.532029985632946e-07,
      "loss": 0.1755,
      "step": 2010
    },
    {
      "epoch": 13.388566694283346,
      "grad_norm": 6.0443620681762695,
      "learning_rate": 3.4899820096135063e-07,
      "loss": 0.1917,
      "step": 2020
    },
    {
      "epoch": 13.454846727423364,
      "grad_norm": 5.522130012512207,
      "learning_rate": 3.4479340335940663e-07,
      "loss": 0.1801,
      "step": 2030
    },
    {
      "epoch": 13.52112676056338,
      "grad_norm": 6.329433441162109,
      "learning_rate": 3.4058860575746263e-07,
      "loss": 0.1671,
      "step": 2040
    },
    {
      "epoch": 13.587406793703398,
      "grad_norm": 3.9607717990875244,
      "learning_rate": 3.363838081555187e-07,
      "loss": 0.1694,
      "step": 2050
    },
    {
      "epoch": 13.653686826843414,
      "grad_norm": 6.565866470336914,
      "learning_rate": 3.321790105535747e-07,
      "loss": 0.1811,
      "step": 2060
    },
    {
      "epoch": 13.71996685998343,
      "grad_norm": 4.774301052093506,
      "learning_rate": 3.279742129516307e-07,
      "loss": 0.1785,
      "step": 2070
    },
    {
      "epoch": 13.786246893123447,
      "grad_norm": 5.165701866149902,
      "learning_rate": 3.237694153496867e-07,
      "loss": 0.1748,
      "step": 2080
    },
    {
      "epoch": 13.852526926263463,
      "grad_norm": 5.128248691558838,
      "learning_rate": 3.1956461774774274e-07,
      "loss": 0.1643,
      "step": 2090
    },
    {
      "epoch": 13.91880695940348,
      "grad_norm": 4.088461875915527,
      "learning_rate": 3.1535982014579874e-07,
      "loss": 0.1649,
      "step": 2100
    },
    {
      "epoch": 13.985086992543497,
      "grad_norm": 4.428869247436523,
      "learning_rate": 3.1115502254385475e-07,
      "loss": 0.1614,
      "step": 2110
    },
    {
      "epoch": 13.9983429991715,
      "eval_accuracy": 0.9350822050290135,
      "eval_f1": 0.47813411078717194,
      "eval_loss": 0.17574885487556458,
      "eval_precision": 0.8978102189781022,
      "eval_recall": 0.3258278145695364,
      "eval_runtime": 1200.7701,
      "eval_samples_per_second": 6.893,
      "eval_steps_per_second": 0.862,
      "step": 2112
    },
    {
      "epoch": 13.9983429991715,
      "eval_accuracy": 0.9350822050290135,
      "eval_f1": 0.47813411078717194,
      "eval_loss": 0.17574885487556458,
      "eval_precision": 0.8978102189781022,
      "eval_recall": 0.3258278145695364,
      "eval_runtime": 933.6788,
      "eval_samples_per_second": 8.865,
      "eval_steps_per_second": 1.109,
      "step": 2112
    },
    {
      "epoch": 14.051367025683513,
      "grad_norm": 4.755098342895508,
      "learning_rate": 3.069502249419108e-07,
      "loss": 0.1801,
      "step": 2120
    },
    {
      "epoch": 14.117647058823529,
      "grad_norm": 5.215721607208252,
      "learning_rate": 3.027454273399668e-07,
      "loss": 0.1797,
      "step": 2130
    },
    {
      "epoch": 14.183927091963547,
      "grad_norm": 4.112954616546631,
      "learning_rate": 2.985406297380228e-07,
      "loss": 0.1745,
      "step": 2140
    },
    {
      "epoch": 14.250207125103563,
      "grad_norm": 5.045387268066406,
      "learning_rate": 2.9433583213607886e-07,
      "loss": 0.1536,
      "step": 2150
    },
    {
      "epoch": 14.316487158243579,
      "grad_norm": 5.077286243438721,
      "learning_rate": 2.9013103453413486e-07,
      "loss": 0.1842,
      "step": 2160
    },
    {
      "epoch": 14.382767191383596,
      "grad_norm": 5.186576843261719,
      "learning_rate": 2.8592623693219086e-07,
      "loss": 0.1685,
      "step": 2170
    },
    {
      "epoch": 14.449047224523612,
      "grad_norm": 4.863690376281738,
      "learning_rate": 2.817214393302469e-07,
      "loss": 0.1741,
      "step": 2180
    },
    {
      "epoch": 14.515327257663628,
      "grad_norm": 5.433289051055908,
      "learning_rate": 2.7751664172830286e-07,
      "loss": 0.1811,
      "step": 2190
    },
    {
      "epoch": 14.581607290803646,
      "grad_norm": 8.359926223754883,
      "learning_rate": 2.733118441263589e-07,
      "loss": 0.175,
      "step": 2200
    },
    {
      "epoch": 14.647887323943662,
      "grad_norm": 4.303366184234619,
      "learning_rate": 2.691070465244149e-07,
      "loss": 0.1705,
      "step": 2210
    },
    {
      "epoch": 14.714167357083678,
      "grad_norm": 7.560873985290527,
      "learning_rate": 2.649022489224709e-07,
      "loss": 0.1791,
      "step": 2220
    },
    {
      "epoch": 14.780447390223696,
      "grad_norm": 11.974101066589355,
      "learning_rate": 2.6069745132052697e-07,
      "loss": 0.1592,
      "step": 2230
    },
    {
      "epoch": 14.846727423363712,
      "grad_norm": 8.663378715515137,
      "learning_rate": 2.5649265371858297e-07,
      "loss": 0.158,
      "step": 2240
    },
    {
      "epoch": 14.913007456503728,
      "grad_norm": 5.84954833984375,
      "learning_rate": 2.52287856116639e-07,
      "loss": 0.1648,
      "step": 2250
    },
    {
      "epoch": 14.979287489643745,
      "grad_norm": 5.216155529022217,
      "learning_rate": 2.48083058514695e-07,
      "loss": 0.1912,
      "step": 2260
    },
    {
      "epoch": 14.99917149958575,
      "eval_accuracy": 0.9373791102514507,
      "eval_f1": 0.5057251908396947,
      "eval_loss": 0.17030298709869385,
      "eval_precision": 0.9044368600682594,
      "eval_recall": 0.3509933774834437,
      "eval_runtime": 970.2964,
      "eval_samples_per_second": 8.53,
      "eval_steps_per_second": 1.067,
      "step": 2263
    },
    {
      "epoch": 14.99917149958575,
      "eval_accuracy": 0.9373791102514507,
      "eval_f1": 0.5057251908396947,
      "eval_loss": 0.17030298709869385,
      "eval_precision": 0.9044368600682594,
      "eval_recall": 0.3509933774834437,
      "eval_runtime": 970.9519,
      "eval_samples_per_second": 8.525,
      "eval_steps_per_second": 1.066,
      "step": 2263
    },
    {
      "epoch": 15.045567522783761,
      "grad_norm": 5.450430393218994,
      "learning_rate": 2.4387826091275103e-07,
      "loss": 0.179,
      "step": 2270
    },
    {
      "epoch": 15.111847555923777,
      "grad_norm": 8.089364051818848,
      "learning_rate": 2.3967346331080703e-07,
      "loss": 0.1703,
      "step": 2280
    },
    {
      "epoch": 15.178127589063795,
      "grad_norm": 7.190782070159912,
      "learning_rate": 2.3546866570886306e-07,
      "loss": 0.1628,
      "step": 2290
    },
    {
      "epoch": 15.244407622203811,
      "grad_norm": 63.2301139831543,
      "learning_rate": 2.3126386810691906e-07,
      "loss": 0.1703,
      "step": 2300
    },
    {
      "epoch": 15.310687655343827,
      "grad_norm": 15.373970985412598,
      "learning_rate": 2.270590705049751e-07,
      "loss": 0.1795,
      "step": 2310
    },
    {
      "epoch": 15.376967688483845,
      "grad_norm": 7.134634017944336,
      "learning_rate": 2.2285427290303111e-07,
      "loss": 0.1814,
      "step": 2320
    },
    {
      "epoch": 15.44324772162386,
      "grad_norm": 5.285058498382568,
      "learning_rate": 2.1864947530108712e-07,
      "loss": 0.1632,
      "step": 2330
    },
    {
      "epoch": 15.509527754763877,
      "grad_norm": 4.733790874481201,
      "learning_rate": 2.1444467769914314e-07,
      "loss": 0.1658,
      "step": 2340
    },
    {
      "epoch": 15.575807787903894,
      "grad_norm": 5.66674280166626,
      "learning_rate": 2.1023988009719915e-07,
      "loss": 0.1782,
      "step": 2350
    },
    {
      "epoch": 15.64208782104391,
      "grad_norm": 4.647049903869629,
      "learning_rate": 2.0603508249525517e-07,
      "loss": 0.1568,
      "step": 2360
    },
    {
      "epoch": 15.708367854183926,
      "grad_norm": 4.3085713386535645,
      "learning_rate": 2.018302848933112e-07,
      "loss": 0.17,
      "step": 2370
    },
    {
      "epoch": 15.774647887323944,
      "grad_norm": 3.5192527770996094,
      "learning_rate": 1.976254872913672e-07,
      "loss": 0.1612,
      "step": 2380
    },
    {
      "epoch": 15.84092792046396,
      "grad_norm": 4.6415324211120605,
      "learning_rate": 1.9342068968942323e-07,
      "loss": 0.1533,
      "step": 2390
    },
    {
      "epoch": 15.907207953603976,
      "grad_norm": 4.954392910003662,
      "learning_rate": 1.8921589208747923e-07,
      "loss": 0.1578,
      "step": 2400
    },
    {
      "epoch": 15.973487986743994,
      "grad_norm": 5.334512710571289,
      "learning_rate": 1.8501109448553526e-07,
      "loss": 0.1693,
      "step": 2410
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.9381044487427466,
      "eval_f1": 0.5067437379576109,
      "eval_loss": 0.1688079535961151,
      "eval_precision": 0.9293286219081273,
      "eval_recall": 0.3483443708609272,
      "eval_runtime": 913.9131,
      "eval_samples_per_second": 9.057,
      "eval_steps_per_second": 1.132,
      "step": 2414
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.9381044487427466,
      "eval_f1": 0.5067437379576109,
      "eval_loss": 0.1688079535961151,
      "eval_precision": 0.9293286219081273,
      "eval_recall": 0.3483443708609272,
      "eval_runtime": 936.7408,
      "eval_samples_per_second": 8.836,
      "eval_steps_per_second": 1.105,
      "step": 2414
    },
    {
      "epoch": 16.03976801988401,
      "grad_norm": 5.381922721862793,
      "learning_rate": 1.8080629688359129e-07,
      "loss": 0.1616,
      "step": 2420
    },
    {
      "epoch": 16.106048053024026,
      "grad_norm": 5.735135078430176,
      "learning_rate": 1.766014992816473e-07,
      "loss": 0.1613,
      "step": 2430
    },
    {
      "epoch": 16.172328086164043,
      "grad_norm": 6.9998087882995605,
      "learning_rate": 1.7239670167970331e-07,
      "loss": 0.1713,
      "step": 2440
    },
    {
      "epoch": 16.23860811930406,
      "grad_norm": 5.678830146789551,
      "learning_rate": 1.6819190407775934e-07,
      "loss": 0.1738,
      "step": 2450
    },
    {
      "epoch": 16.304888152444075,
      "grad_norm": 4.605173110961914,
      "learning_rate": 1.6398710647581534e-07,
      "loss": 0.1622,
      "step": 2460
    },
    {
      "epoch": 16.371168185584093,
      "grad_norm": 5.356619358062744,
      "learning_rate": 1.5978230887387137e-07,
      "loss": 0.1763,
      "step": 2470
    },
    {
      "epoch": 16.43744821872411,
      "grad_norm": 4.728435039520264,
      "learning_rate": 1.5557751127192737e-07,
      "loss": 0.1607,
      "step": 2480
    },
    {
      "epoch": 16.503728251864125,
      "grad_norm": 6.286999702453613,
      "learning_rate": 1.513727136699834e-07,
      "loss": 0.1757,
      "step": 2490
    },
    {
      "epoch": 16.570008285004143,
      "grad_norm": 4.6743855476379395,
      "learning_rate": 1.4716791606803943e-07,
      "loss": 0.1647,
      "step": 2500
    },
    {
      "epoch": 16.63628831814416,
      "grad_norm": 4.239821434020996,
      "learning_rate": 1.4296311846609543e-07,
      "loss": 0.1476,
      "step": 2510
    },
    {
      "epoch": 16.702568351284174,
      "grad_norm": 3.5487802028656006,
      "learning_rate": 1.3875832086415143e-07,
      "loss": 0.1569,
      "step": 2520
    },
    {
      "epoch": 16.768848384424192,
      "grad_norm": 4.821102619171143,
      "learning_rate": 1.3455352326220746e-07,
      "loss": 0.1645,
      "step": 2530
    },
    {
      "epoch": 16.83512841756421,
      "grad_norm": 5.555367946624756,
      "learning_rate": 1.3034872566026349e-07,
      "loss": 0.1714,
      "step": 2540
    },
    {
      "epoch": 16.901408450704224,
      "grad_norm": 6.667064666748047,
      "learning_rate": 1.261439280583195e-07,
      "loss": 0.1694,
      "step": 2550
    },
    {
      "epoch": 16.967688483844242,
      "grad_norm": 6.819190502166748,
      "learning_rate": 1.2193913045637551e-07,
      "loss": 0.1739,
      "step": 2560
    },
    {
      "epoch": 16.99420049710025,
      "eval_accuracy": 0.9383462282398453,
      "eval_f1": 0.5124282982791587,
      "eval_loss": 0.16695645451545715,
      "eval_precision": 0.9209621993127147,
      "eval_recall": 0.35496688741721855,
      "eval_runtime": 954.9076,
      "eval_samples_per_second": 8.668,
      "eval_steps_per_second": 1.084,
      "step": 2564
    },
    {
      "epoch": 16.99420049710025,
      "eval_accuracy": 0.9383462282398453,
      "eval_f1": 0.5124282982791587,
      "eval_loss": 0.16695645451545715,
      "eval_precision": 0.9209621993127147,
      "eval_recall": 0.35496688741721855,
      "eval_runtime": 920.4453,
      "eval_samples_per_second": 8.992,
      "eval_steps_per_second": 1.124,
      "step": 2564
    },
    {
      "epoch": 17.03396851698426,
      "grad_norm": 5.0340447425842285,
      "learning_rate": 1.1773433285443153e-07,
      "loss": 0.1656,
      "step": 2570
    },
    {
      "epoch": 17.100248550124274,
      "grad_norm": 5.24855375289917,
      "learning_rate": 1.1352953525248754e-07,
      "loss": 0.1525,
      "step": 2580
    },
    {
      "epoch": 17.16652858326429,
      "grad_norm": 10.417102813720703,
      "learning_rate": 1.0932473765054356e-07,
      "loss": 0.1711,
      "step": 2590
    },
    {
      "epoch": 17.23280861640431,
      "grad_norm": 5.2248406410217285,
      "learning_rate": 1.0511994004859957e-07,
      "loss": 0.1629,
      "step": 2600
    },
    {
      "epoch": 17.299088649544323,
      "grad_norm": 5.458412170410156,
      "learning_rate": 1.009151424466556e-07,
      "loss": 0.1553,
      "step": 2610
    },
    {
      "epoch": 17.36536868268434,
      "grad_norm": 5.513725280761719,
      "learning_rate": 9.671034484471161e-08,
      "loss": 0.162,
      "step": 2620
    },
    {
      "epoch": 17.43164871582436,
      "grad_norm": 5.7010626792907715,
      "learning_rate": 9.250554724276763e-08,
      "loss": 0.1587,
      "step": 2630
    },
    {
      "epoch": 17.497928748964373,
      "grad_norm": 6.590139389038086,
      "learning_rate": 8.830074964082364e-08,
      "loss": 0.1583,
      "step": 2640
    },
    {
      "epoch": 17.56420878210439,
      "grad_norm": 4.235012054443359,
      "learning_rate": 8.409595203887967e-08,
      "loss": 0.1625,
      "step": 2650
    },
    {
      "epoch": 17.63048881524441,
      "grad_norm": 4.248852729797363,
      "learning_rate": 7.989115443693569e-08,
      "loss": 0.1762,
      "step": 2660
    },
    {
      "epoch": 17.696768848384423,
      "grad_norm": 13.804130554199219,
      "learning_rate": 7.56863568349917e-08,
      "loss": 0.1727,
      "step": 2670
    },
    {
      "epoch": 17.76304888152444,
      "grad_norm": 5.256136894226074,
      "learning_rate": 7.148155923304771e-08,
      "loss": 0.172,
      "step": 2680
    },
    {
      "epoch": 17.82932891466446,
      "grad_norm": 6.029238700866699,
      "learning_rate": 6.727676163110373e-08,
      "loss": 0.1683,
      "step": 2690
    },
    {
      "epoch": 17.895608947804472,
      "grad_norm": 5.549646377563477,
      "learning_rate": 6.307196402915974e-08,
      "loss": 0.1719,
      "step": 2700
    },
    {
      "epoch": 17.96188898094449,
      "grad_norm": 4.14778995513916,
      "learning_rate": 5.8867166427215765e-08,
      "loss": 0.1651,
      "step": 2710
    },
    {
      "epoch": 17.9950289975145,
      "eval_accuracy": 0.9384671179883946,
      "eval_f1": 0.5156993339676499,
      "eval_loss": 0.16505499184131622,
      "eval_precision": 0.9155405405405406,
      "eval_recall": 0.35894039735099337,
      "eval_runtime": 1405.8303,
      "eval_samples_per_second": 5.888,
      "eval_steps_per_second": 0.736,
      "step": 2715
    },
    {
      "epoch": 17.9950289975145,
      "eval_accuracy": 0.9384671179883946,
      "eval_f1": 0.5156993339676499,
      "eval_loss": 0.16505499184131622,
      "eval_precision": 0.9155405405405406,
      "eval_recall": 0.35894039735099337,
      "eval_runtime": 1176.0325,
      "eval_samples_per_second": 7.038,
      "eval_steps_per_second": 0.88,
      "step": 2715
    }
  ],
  "logging_steps": 10,
  "max_steps": 2850,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 19,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.558681688867424e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": {
    "epochs": 19,
    "gradient_accumulation_steps": 8,
    "learning_rate": 1.1176352025967107e-06,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 32,
    "warmup_steps": 192,
    "weight_decay": 0.05988551309974289
  }
}
