{
  "best_metric": 0.8959212376933895,
  "best_model_checkpoint": "../hyperparameter_search/run-7/checkpoint-2414",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2414,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00041425020712510354,
      "grad_norm": 158.12144470214844,
      "learning_rate": 3.18452949449393e-07,
      "loss": 0.7415,
      "step": 1
    },
    {
      "epoch": 0.004142502071251036,
      "grad_norm": 44.721981048583984,
      "learning_rate": 3.18452949449393e-06,
      "loss": 0.7991,
      "step": 10
    },
    {
      "epoch": 0.008285004142502071,
      "grad_norm": 29.31369400024414,
      "learning_rate": 6.36905898898786e-06,
      "loss": 0.5819,
      "step": 20
    },
    {
      "epoch": 0.012427506213753107,
      "grad_norm": 15.40004825592041,
      "learning_rate": 9.55358848348179e-06,
      "loss": 0.3634,
      "step": 30
    },
    {
      "epoch": 0.016570008285004142,
      "grad_norm": 4.1027750968933105,
      "learning_rate": 1.273811797797572e-05,
      "loss": 0.368,
      "step": 40
    },
    {
      "epoch": 0.020712510356255178,
      "grad_norm": 17.429386138916016,
      "learning_rate": 1.5922647472469653e-05,
      "loss": 0.5299,
      "step": 50
    },
    {
      "epoch": 0.024855012427506214,
      "grad_norm": 4.213267803192139,
      "learning_rate": 1.910717696696358e-05,
      "loss": 0.4957,
      "step": 60
    },
    {
      "epoch": 0.02899751449875725,
      "grad_norm": 26.914995193481445,
      "learning_rate": 2.229170646145751e-05,
      "loss": 0.288,
      "step": 70
    },
    {
      "epoch": 0.033140016570008285,
      "grad_norm": 3.4841063022613525,
      "learning_rate": 2.547623595595144e-05,
      "loss": 0.2997,
      "step": 80
    },
    {
      "epoch": 0.037282518641259324,
      "grad_norm": 19.74591636657715,
      "learning_rate": 2.7383921103245444e-05,
      "loss": 0.3669,
      "step": 90
    },
    {
      "epoch": 0.041425020712510356,
      "grad_norm": 21.74051856994629,
      "learning_rate": 2.7376339729739566e-05,
      "loss": 0.2947,
      "step": 100
    },
    {
      "epoch": 0.045567522783761395,
      "grad_norm": 7.892909049987793,
      "learning_rate": 2.7368758356233682e-05,
      "loss": 0.3173,
      "step": 110
    },
    {
      "epoch": 0.04971002485501243,
      "grad_norm": 77.97030639648438,
      "learning_rate": 2.73611769827278e-05,
      "loss": 0.3562,
      "step": 120
    },
    {
      "epoch": 0.053852526926263466,
      "grad_norm": 5.890148162841797,
      "learning_rate": 2.7353595609221916e-05,
      "loss": 0.37,
      "step": 130
    },
    {
      "epoch": 0.0579950289975145,
      "grad_norm": 11.313488006591797,
      "learning_rate": 2.734601423571604e-05,
      "loss": 0.4243,
      "step": 140
    },
    {
      "epoch": 0.06213753106876554,
      "grad_norm": 2.4763288497924805,
      "learning_rate": 2.7338432862210155e-05,
      "loss": 0.2911,
      "step": 150
    },
    {
      "epoch": 0.06628003314001657,
      "grad_norm": 18.918033599853516,
      "learning_rate": 2.7330851488704274e-05,
      "loss": 0.2882,
      "step": 160
    },
    {
      "epoch": 0.07042253521126761,
      "grad_norm": 12.510088920593262,
      "learning_rate": 2.732327011519839e-05,
      "loss": 0.2486,
      "step": 170
    },
    {
      "epoch": 0.07456503728251865,
      "grad_norm": 5.548717498779297,
      "learning_rate": 2.731568874169251e-05,
      "loss": 0.3155,
      "step": 180
    },
    {
      "epoch": 0.07870753935376967,
      "grad_norm": 8.070220947265625,
      "learning_rate": 2.7308107368186628e-05,
      "loss": 0.3371,
      "step": 190
    },
    {
      "epoch": 0.08285004142502071,
      "grad_norm": 24.97348976135254,
      "learning_rate": 2.7300525994680747e-05,
      "loss": 0.2521,
      "step": 200
    },
    {
      "epoch": 0.08699254349627175,
      "grad_norm": 21.78693389892578,
      "learning_rate": 2.7292944621174862e-05,
      "loss": 0.2141,
      "step": 210
    },
    {
      "epoch": 0.09113504556752279,
      "grad_norm": 17.28107261657715,
      "learning_rate": 2.7285363247668978e-05,
      "loss": 0.4572,
      "step": 220
    },
    {
      "epoch": 0.09527754763877382,
      "grad_norm": 31.238000869750977,
      "learning_rate": 2.72777818741631e-05,
      "loss": 0.2557,
      "step": 230
    },
    {
      "epoch": 0.09942004971002485,
      "grad_norm": 23.252412796020508,
      "learning_rate": 2.7270200500657216e-05,
      "loss": 0.3221,
      "step": 240
    },
    {
      "epoch": 0.1035625517812759,
      "grad_norm": 2.7245497703552246,
      "learning_rate": 2.7262619127151335e-05,
      "loss": 0.2038,
      "step": 250
    },
    {
      "epoch": 0.10770505385252693,
      "grad_norm": 11.040946960449219,
      "learning_rate": 2.725503775364545e-05,
      "loss": 0.291,
      "step": 260
    },
    {
      "epoch": 0.11184755592377796,
      "grad_norm": 46.11796188354492,
      "learning_rate": 2.7247456380139573e-05,
      "loss": 0.2015,
      "step": 270
    },
    {
      "epoch": 0.115990057995029,
      "grad_norm": 28.10091209411621,
      "learning_rate": 2.723987500663369e-05,
      "loss": 0.3386,
      "step": 280
    },
    {
      "epoch": 0.12013256006628004,
      "grad_norm": 3.0668749809265137,
      "learning_rate": 2.7232293633127808e-05,
      "loss": 0.3629,
      "step": 290
    },
    {
      "epoch": 0.12427506213753108,
      "grad_norm": 14.033703804016113,
      "learning_rate": 2.7224712259621924e-05,
      "loss": 0.2275,
      "step": 300
    },
    {
      "epoch": 0.12841756420878211,
      "grad_norm": 3.7869627475738525,
      "learning_rate": 2.7217130886116046e-05,
      "loss": 0.3176,
      "step": 310
    },
    {
      "epoch": 0.13256006628003314,
      "grad_norm": 6.723422050476074,
      "learning_rate": 2.7209549512610162e-05,
      "loss": 0.2183,
      "step": 320
    },
    {
      "epoch": 0.13670256835128416,
      "grad_norm": 7.083799839019775,
      "learning_rate": 2.720196813910428e-05,
      "loss": 0.15,
      "step": 330
    },
    {
      "epoch": 0.14084507042253522,
      "grad_norm": 6.891176223754883,
      "learning_rate": 2.7194386765598397e-05,
      "loss": 0.3655,
      "step": 340
    },
    {
      "epoch": 0.14498757249378624,
      "grad_norm": 2.4567558765411377,
      "learning_rate": 2.7186805392092516e-05,
      "loss": 0.2434,
      "step": 350
    },
    {
      "epoch": 0.1491300745650373,
      "grad_norm": 12.167905807495117,
      "learning_rate": 2.7179224018586635e-05,
      "loss": 0.4176,
      "step": 360
    },
    {
      "epoch": 0.15327257663628832,
      "grad_norm": 5.107712268829346,
      "learning_rate": 2.717164264508075e-05,
      "loss": 0.2887,
      "step": 370
    },
    {
      "epoch": 0.15741507870753935,
      "grad_norm": 1.4874138832092285,
      "learning_rate": 2.716406127157487e-05,
      "loss": 0.1776,
      "step": 380
    },
    {
      "epoch": 0.1615575807787904,
      "grad_norm": 9.216086387634277,
      "learning_rate": 2.715647989806899e-05,
      "loss": 0.2237,
      "step": 390
    },
    {
      "epoch": 0.16570008285004142,
      "grad_norm": 0.7115365862846375,
      "learning_rate": 2.7148898524563108e-05,
      "loss": 0.1969,
      "step": 400
    },
    {
      "epoch": 0.16984258492129245,
      "grad_norm": 4.669458866119385,
      "learning_rate": 2.7141317151057224e-05,
      "loss": 0.3217,
      "step": 410
    },
    {
      "epoch": 0.1739850869925435,
      "grad_norm": 6.296909809112549,
      "learning_rate": 2.7133735777551343e-05,
      "loss": 0.2611,
      "step": 420
    },
    {
      "epoch": 0.17812758906379453,
      "grad_norm": 10.815659523010254,
      "learning_rate": 2.7126154404045462e-05,
      "loss": 0.2026,
      "step": 430
    },
    {
      "epoch": 0.18227009113504558,
      "grad_norm": 0.4949212074279785,
      "learning_rate": 2.711857303053958e-05,
      "loss": 0.16,
      "step": 440
    },
    {
      "epoch": 0.1864125932062966,
      "grad_norm": 4.1060309410095215,
      "learning_rate": 2.7110991657033696e-05,
      "loss": 0.3255,
      "step": 450
    },
    {
      "epoch": 0.19055509527754763,
      "grad_norm": 10.934890747070312,
      "learning_rate": 2.7103410283527816e-05,
      "loss": 0.2503,
      "step": 460
    },
    {
      "epoch": 0.19469759734879868,
      "grad_norm": 1.0785492658615112,
      "learning_rate": 2.7095828910021935e-05,
      "loss": 0.2834,
      "step": 470
    },
    {
      "epoch": 0.1988400994200497,
      "grad_norm": 11.399311065673828,
      "learning_rate": 2.7088247536516054e-05,
      "loss": 0.1848,
      "step": 480
    },
    {
      "epoch": 0.20298260149130073,
      "grad_norm": 12.8245267868042,
      "learning_rate": 2.708066616301017e-05,
      "loss": 0.2723,
      "step": 490
    },
    {
      "epoch": 0.2071251035625518,
      "grad_norm": 0.7338860034942627,
      "learning_rate": 2.707308478950429e-05,
      "loss": 0.2009,
      "step": 500
    },
    {
      "epoch": 0.2112676056338028,
      "grad_norm": 8.367884635925293,
      "learning_rate": 2.7065503415998408e-05,
      "loss": 0.3452,
      "step": 510
    },
    {
      "epoch": 0.21541010770505387,
      "grad_norm": 5.451719760894775,
      "learning_rate": 2.7057922042492523e-05,
      "loss": 0.2053,
      "step": 520
    },
    {
      "epoch": 0.2195526097763049,
      "grad_norm": 1.911605715751648,
      "learning_rate": 2.7050340668986642e-05,
      "loss": 0.1464,
      "step": 530
    },
    {
      "epoch": 0.22369511184755592,
      "grad_norm": 6.529282569885254,
      "learning_rate": 2.7042759295480758e-05,
      "loss": 0.1766,
      "step": 540
    },
    {
      "epoch": 0.22783761391880697,
      "grad_norm": 2.0859642028808594,
      "learning_rate": 2.703517792197488e-05,
      "loss": 0.2551,
      "step": 550
    },
    {
      "epoch": 0.231980115990058,
      "grad_norm": 6.638892650604248,
      "learning_rate": 2.7027596548468996e-05,
      "loss": 0.1403,
      "step": 560
    },
    {
      "epoch": 0.23612261806130902,
      "grad_norm": 12.201237678527832,
      "learning_rate": 2.7020015174963115e-05,
      "loss": 0.1729,
      "step": 570
    },
    {
      "epoch": 0.24026512013256007,
      "grad_norm": 7.344378471374512,
      "learning_rate": 2.701243380145723e-05,
      "loss": 0.2051,
      "step": 580
    },
    {
      "epoch": 0.2444076222038111,
      "grad_norm": 11.520726203918457,
      "learning_rate": 2.700485242795135e-05,
      "loss": 0.1753,
      "step": 590
    },
    {
      "epoch": 0.24855012427506215,
      "grad_norm": 4.404767990112305,
      "learning_rate": 2.699727105444547e-05,
      "loss": 0.163,
      "step": 600
    },
    {
      "epoch": 0.2526926263463132,
      "grad_norm": 7.454681396484375,
      "learning_rate": 2.6989689680939588e-05,
      "loss": 0.1579,
      "step": 610
    },
    {
      "epoch": 0.25683512841756423,
      "grad_norm": 7.790285110473633,
      "learning_rate": 2.6982108307433704e-05,
      "loss": 0.1185,
      "step": 620
    },
    {
      "epoch": 0.2609776304888152,
      "grad_norm": 8.999266624450684,
      "learning_rate": 2.6974526933927823e-05,
      "loss": 0.2339,
      "step": 630
    },
    {
      "epoch": 0.2651201325600663,
      "grad_norm": 8.440032005310059,
      "learning_rate": 2.6966945560421942e-05,
      "loss": 0.2791,
      "step": 640
    },
    {
      "epoch": 0.26926263463131733,
      "grad_norm": 4.572268962860107,
      "learning_rate": 2.6959364186916058e-05,
      "loss": 0.1866,
      "step": 650
    },
    {
      "epoch": 0.27340513670256833,
      "grad_norm": 9.998238563537598,
      "learning_rate": 2.6951782813410177e-05,
      "loss": 0.3162,
      "step": 660
    },
    {
      "epoch": 0.2775476387738194,
      "grad_norm": 0.8457555770874023,
      "learning_rate": 2.6944201439904292e-05,
      "loss": 0.1107,
      "step": 670
    },
    {
      "epoch": 0.28169014084507044,
      "grad_norm": 5.992648601531982,
      "learning_rate": 2.6936620066398415e-05,
      "loss": 0.1847,
      "step": 680
    },
    {
      "epoch": 0.28583264291632143,
      "grad_norm": 7.313864231109619,
      "learning_rate": 2.692903869289253e-05,
      "loss": 0.1424,
      "step": 690
    },
    {
      "epoch": 0.2899751449875725,
      "grad_norm": 7.218875885009766,
      "learning_rate": 2.692145731938665e-05,
      "loss": 0.2007,
      "step": 700
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 2.447089672088623,
      "learning_rate": 2.6913875945880765e-05,
      "loss": 0.2537,
      "step": 710
    },
    {
      "epoch": 0.2982601491300746,
      "grad_norm": 6.256088733673096,
      "learning_rate": 2.6906294572374888e-05,
      "loss": 0.1863,
      "step": 720
    },
    {
      "epoch": 0.3024026512013256,
      "grad_norm": 0.5254260897636414,
      "learning_rate": 2.6898713198869004e-05,
      "loss": 0.087,
      "step": 730
    },
    {
      "epoch": 0.30654515327257664,
      "grad_norm": 0.1948678195476532,
      "learning_rate": 2.6891131825363123e-05,
      "loss": 0.1237,
      "step": 740
    },
    {
      "epoch": 0.3106876553438277,
      "grad_norm": 9.83481216430664,
      "learning_rate": 2.688355045185724e-05,
      "loss": 0.1303,
      "step": 750
    },
    {
      "epoch": 0.3148301574150787,
      "grad_norm": 10.328493118286133,
      "learning_rate": 2.687596907835136e-05,
      "loss": 0.2441,
      "step": 760
    },
    {
      "epoch": 0.31897265948632975,
      "grad_norm": 5.033119201660156,
      "learning_rate": 2.6868387704845477e-05,
      "loss": 0.1404,
      "step": 770
    },
    {
      "epoch": 0.3231151615575808,
      "grad_norm": 3.7198824882507324,
      "learning_rate": 2.6860806331339596e-05,
      "loss": 0.1488,
      "step": 780
    },
    {
      "epoch": 0.3272576636288318,
      "grad_norm": 1.1849666833877563,
      "learning_rate": 2.685322495783371e-05,
      "loss": 0.2567,
      "step": 790
    },
    {
      "epoch": 0.33140016570008285,
      "grad_norm": 2.0909557342529297,
      "learning_rate": 2.684564358432783e-05,
      "loss": 0.1998,
      "step": 800
    },
    {
      "epoch": 0.3355426677713339,
      "grad_norm": 4.019129753112793,
      "learning_rate": 2.683806221082195e-05,
      "loss": 0.1607,
      "step": 810
    },
    {
      "epoch": 0.3396851698425849,
      "grad_norm": 11.623539924621582,
      "learning_rate": 2.6830480837316065e-05,
      "loss": 0.2227,
      "step": 820
    },
    {
      "epoch": 0.34382767191383595,
      "grad_norm": 1.3897042274475098,
      "learning_rate": 2.6822899463810184e-05,
      "loss": 0.1435,
      "step": 830
    },
    {
      "epoch": 0.347970173985087,
      "grad_norm": 0.1067020446062088,
      "learning_rate": 2.6815318090304303e-05,
      "loss": 0.0907,
      "step": 840
    },
    {
      "epoch": 0.352112676056338,
      "grad_norm": 0.07701165974140167,
      "learning_rate": 2.6807736716798422e-05,
      "loss": 0.152,
      "step": 850
    },
    {
      "epoch": 0.35625517812758906,
      "grad_norm": 0.23647883534431458,
      "learning_rate": 2.6800155343292538e-05,
      "loss": 0.1437,
      "step": 860
    },
    {
      "epoch": 0.3603976801988401,
      "grad_norm": 9.089881896972656,
      "learning_rate": 2.6792573969786657e-05,
      "loss": 0.221,
      "step": 870
    },
    {
      "epoch": 0.36454018227009116,
      "grad_norm": 7.183530330657959,
      "learning_rate": 2.6784992596280776e-05,
      "loss": 0.1947,
      "step": 880
    },
    {
      "epoch": 0.36868268434134216,
      "grad_norm": 1.9668095111846924,
      "learning_rate": 2.6777411222774895e-05,
      "loss": 0.1469,
      "step": 890
    },
    {
      "epoch": 0.3728251864125932,
      "grad_norm": 1.0168036222457886,
      "learning_rate": 2.676982984926901e-05,
      "loss": 0.0895,
      "step": 900
    },
    {
      "epoch": 0.37696768848384427,
      "grad_norm": 0.03473782166838646,
      "learning_rate": 2.676224847576313e-05,
      "loss": 0.0624,
      "step": 910
    },
    {
      "epoch": 0.38111019055509526,
      "grad_norm": 0.5312386155128479,
      "learning_rate": 2.675466710225725e-05,
      "loss": 0.2792,
      "step": 920
    },
    {
      "epoch": 0.3852526926263463,
      "grad_norm": 0.4942350387573242,
      "learning_rate": 2.6747085728751365e-05,
      "loss": 0.1362,
      "step": 930
    },
    {
      "epoch": 0.38939519469759737,
      "grad_norm": 4.475904941558838,
      "learning_rate": 2.6739504355245484e-05,
      "loss": 0.0983,
      "step": 940
    },
    {
      "epoch": 0.39353769676884837,
      "grad_norm": 0.14048339426517487,
      "learning_rate": 2.67319229817396e-05,
      "loss": 0.0504,
      "step": 950
    },
    {
      "epoch": 0.3976801988400994,
      "grad_norm": 0.7751637697219849,
      "learning_rate": 2.6724341608233722e-05,
      "loss": 0.2588,
      "step": 960
    },
    {
      "epoch": 0.40182270091135047,
      "grad_norm": 5.224793434143066,
      "learning_rate": 2.6716760234727838e-05,
      "loss": 0.2202,
      "step": 970
    },
    {
      "epoch": 0.40596520298260147,
      "grad_norm": 5.401694297790527,
      "learning_rate": 2.6709178861221957e-05,
      "loss": 0.105,
      "step": 980
    },
    {
      "epoch": 0.4101077050538525,
      "grad_norm": 0.354540079832077,
      "learning_rate": 2.6701597487716073e-05,
      "loss": 0.2312,
      "step": 990
    },
    {
      "epoch": 0.4142502071251036,
      "grad_norm": 14.605941772460938,
      "learning_rate": 2.669401611421019e-05,
      "loss": 0.154,
      "step": 1000
    },
    {
      "epoch": 0.4183927091963546,
      "grad_norm": 4.1685051918029785,
      "learning_rate": 2.668643474070431e-05,
      "loss": 0.1281,
      "step": 1010
    },
    {
      "epoch": 0.4225352112676056,
      "grad_norm": 0.3162478506565094,
      "learning_rate": 2.667885336719843e-05,
      "loss": 0.0412,
      "step": 1020
    },
    {
      "epoch": 0.4266777133388567,
      "grad_norm": 7.1519083976745605,
      "learning_rate": 2.6671271993692545e-05,
      "loss": 0.1499,
      "step": 1030
    },
    {
      "epoch": 0.43082021541010773,
      "grad_norm": 15.948486328125,
      "learning_rate": 2.6663690620186665e-05,
      "loss": 0.1719,
      "step": 1040
    },
    {
      "epoch": 0.43496271748135873,
      "grad_norm": 9.918790817260742,
      "learning_rate": 2.6656109246680784e-05,
      "loss": 0.1999,
      "step": 1050
    },
    {
      "epoch": 0.4391052195526098,
      "grad_norm": 7.391894340515137,
      "learning_rate": 2.6648527873174903e-05,
      "loss": 0.1103,
      "step": 1060
    },
    {
      "epoch": 0.44324772162386084,
      "grad_norm": 8.727791786193848,
      "learning_rate": 2.664094649966902e-05,
      "loss": 0.1328,
      "step": 1070
    },
    {
      "epoch": 0.44739022369511183,
      "grad_norm": 0.047380413860082626,
      "learning_rate": 2.6633365126163137e-05,
      "loss": 0.0534,
      "step": 1080
    },
    {
      "epoch": 0.4515327257663629,
      "grad_norm": 1.0521214008331299,
      "learning_rate": 2.6625783752657257e-05,
      "loss": 0.2098,
      "step": 1090
    },
    {
      "epoch": 0.45567522783761394,
      "grad_norm": 5.105883598327637,
      "learning_rate": 2.6618202379151372e-05,
      "loss": 0.109,
      "step": 1100
    },
    {
      "epoch": 0.45981772990886494,
      "grad_norm": 4.842369079589844,
      "learning_rate": 2.661062100564549e-05,
      "loss": 0.1997,
      "step": 1110
    },
    {
      "epoch": 0.463960231980116,
      "grad_norm": 6.364273548126221,
      "learning_rate": 2.6603039632139607e-05,
      "loss": 0.0926,
      "step": 1120
    },
    {
      "epoch": 0.46810273405136704,
      "grad_norm": 8.184174537658691,
      "learning_rate": 2.659545825863373e-05,
      "loss": 0.1162,
      "step": 1130
    },
    {
      "epoch": 0.47224523612261804,
      "grad_norm": 7.115694999694824,
      "learning_rate": 2.6587876885127845e-05,
      "loss": 0.0746,
      "step": 1140
    },
    {
      "epoch": 0.4763877381938691,
      "grad_norm": 10.991273880004883,
      "learning_rate": 2.6580295511621964e-05,
      "loss": 0.0867,
      "step": 1150
    },
    {
      "epoch": 0.48053024026512015,
      "grad_norm": 0.28813913464546204,
      "learning_rate": 2.657271413811608e-05,
      "loss": 0.0155,
      "step": 1160
    },
    {
      "epoch": 0.48467274233637114,
      "grad_norm": 9.685111045837402,
      "learning_rate": 2.6565132764610202e-05,
      "loss": 0.1912,
      "step": 1170
    },
    {
      "epoch": 0.4888152444076222,
      "grad_norm": 14.210061073303223,
      "learning_rate": 2.6557551391104318e-05,
      "loss": 0.1126,
      "step": 1180
    },
    {
      "epoch": 0.49295774647887325,
      "grad_norm": 0.2956501245498657,
      "learning_rate": 2.6549970017598437e-05,
      "loss": 0.096,
      "step": 1190
    },
    {
      "epoch": 0.4971002485501243,
      "grad_norm": 0.2675141394138336,
      "learning_rate": 2.6542388644092553e-05,
      "loss": 0.1317,
      "step": 1200
    },
    {
      "epoch": 0.5012427506213754,
      "grad_norm": 2.3220553398132324,
      "learning_rate": 2.6534807270586672e-05,
      "loss": 0.1857,
      "step": 1210
    },
    {
      "epoch": 0.5053852526926264,
      "grad_norm": 6.563757419586182,
      "learning_rate": 2.652722589708079e-05,
      "loss": 0.1403,
      "step": 1220
    },
    {
      "epoch": 0.5095277547638773,
      "grad_norm": 8.81635570526123,
      "learning_rate": 2.6519644523574907e-05,
      "loss": 0.1654,
      "step": 1230
    },
    {
      "epoch": 0.5136702568351285,
      "grad_norm": 6.786826133728027,
      "learning_rate": 2.6512063150069026e-05,
      "loss": 0.1552,
      "step": 1240
    },
    {
      "epoch": 0.5178127589063795,
      "grad_norm": 0.2910865545272827,
      "learning_rate": 2.6504481776563145e-05,
      "loss": 0.0556,
      "step": 1250
    },
    {
      "epoch": 0.5219552609776305,
      "grad_norm": 5.584820747375488,
      "learning_rate": 2.6496900403057264e-05,
      "loss": 0.1109,
      "step": 1260
    },
    {
      "epoch": 0.5260977630488816,
      "grad_norm": 0.04813828319311142,
      "learning_rate": 2.648931902955138e-05,
      "loss": 0.0166,
      "step": 1270
    },
    {
      "epoch": 0.5302402651201326,
      "grad_norm": 7.617443561553955,
      "learning_rate": 2.64817376560455e-05,
      "loss": 0.1348,
      "step": 1280
    },
    {
      "epoch": 0.5343827671913836,
      "grad_norm": 0.02248440682888031,
      "learning_rate": 2.6474156282539618e-05,
      "loss": 0.0115,
      "step": 1290
    },
    {
      "epoch": 0.5385252692626347,
      "grad_norm": 5.436805248260498,
      "learning_rate": 2.6466574909033737e-05,
      "loss": 0.0831,
      "step": 1300
    },
    {
      "epoch": 0.5426677713338857,
      "grad_norm": 6.212355613708496,
      "learning_rate": 2.6458993535527853e-05,
      "loss": 0.1963,
      "step": 1310
    },
    {
      "epoch": 0.5468102734051367,
      "grad_norm": 5.111941337585449,
      "learning_rate": 2.645141216202197e-05,
      "loss": 0.0297,
      "step": 1320
    },
    {
      "epoch": 0.5509527754763878,
      "grad_norm": 0.07179874926805496,
      "learning_rate": 2.644383078851609e-05,
      "loss": 0.0417,
      "step": 1330
    },
    {
      "epoch": 0.5550952775476388,
      "grad_norm": 5.769792556762695,
      "learning_rate": 2.643624941501021e-05,
      "loss": 0.1243,
      "step": 1340
    },
    {
      "epoch": 0.5592377796188898,
      "grad_norm": 1.9790353775024414,
      "learning_rate": 2.6428668041504325e-05,
      "loss": 0.0957,
      "step": 1350
    },
    {
      "epoch": 0.5633802816901409,
      "grad_norm": 0.2554411292076111,
      "learning_rate": 2.6421086667998445e-05,
      "loss": 0.0505,
      "step": 1360
    },
    {
      "epoch": 0.5675227837613919,
      "grad_norm": 0.05709490925073624,
      "learning_rate": 2.6413505294492564e-05,
      "loss": 0.0025,
      "step": 1370
    },
    {
      "epoch": 0.5716652858326429,
      "grad_norm": 8.715326309204102,
      "learning_rate": 2.640592392098668e-05,
      "loss": 0.0959,
      "step": 1380
    },
    {
      "epoch": 0.575807787903894,
      "grad_norm": 0.13168446719646454,
      "learning_rate": 2.63983425474808e-05,
      "loss": 0.1426,
      "step": 1390
    },
    {
      "epoch": 0.579950289975145,
      "grad_norm": 9.15468692779541,
      "learning_rate": 2.6390761173974914e-05,
      "loss": 0.1535,
      "step": 1400
    },
    {
      "epoch": 0.584092792046396,
      "grad_norm": 3.46061635017395,
      "learning_rate": 2.6383179800469033e-05,
      "loss": 0.1874,
      "step": 1410
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.8396068215370178,
      "learning_rate": 2.6375598426963152e-05,
      "loss": 0.1579,
      "step": 1420
    },
    {
      "epoch": 0.5923777961888981,
      "grad_norm": 0.34764334559440613,
      "learning_rate": 2.636801705345727e-05,
      "loss": 0.1299,
      "step": 1430
    },
    {
      "epoch": 0.5965202982601492,
      "grad_norm": 1.058268427848816,
      "learning_rate": 2.6360435679951387e-05,
      "loss": 0.0854,
      "step": 1440
    },
    {
      "epoch": 0.6006628003314002,
      "grad_norm": 0.2575078010559082,
      "learning_rate": 2.6352854306445506e-05,
      "loss": 0.0387,
      "step": 1450
    },
    {
      "epoch": 0.6048053024026512,
      "grad_norm": 6.366754055023193,
      "learning_rate": 2.6345272932939625e-05,
      "loss": 0.1724,
      "step": 1460
    },
    {
      "epoch": 0.6089478044739023,
      "grad_norm": 14.959486961364746,
      "learning_rate": 2.6337691559433744e-05,
      "loss": 0.0696,
      "step": 1470
    },
    {
      "epoch": 0.6130903065451533,
      "grad_norm": 4.284148693084717,
      "learning_rate": 2.633011018592786e-05,
      "loss": 0.1707,
      "step": 1480
    },
    {
      "epoch": 0.6172328086164043,
      "grad_norm": 0.11319699883460999,
      "learning_rate": 2.632252881242198e-05,
      "loss": 0.1063,
      "step": 1490
    },
    {
      "epoch": 0.6213753106876554,
      "grad_norm": 12.980884552001953,
      "learning_rate": 2.6314947438916098e-05,
      "loss": 0.1156,
      "step": 1500
    },
    {
      "epoch": 0.6255178127589064,
      "grad_norm": 0.7505433559417725,
      "learning_rate": 2.6307366065410214e-05,
      "loss": 0.105,
      "step": 1510
    },
    {
      "epoch": 0.6296603148301574,
      "grad_norm": 2.643561840057373,
      "learning_rate": 2.6299784691904333e-05,
      "loss": 0.0817,
      "step": 1520
    },
    {
      "epoch": 0.6338028169014085,
      "grad_norm": 10.064386367797852,
      "learning_rate": 2.629220331839845e-05,
      "loss": 0.1973,
      "step": 1530
    },
    {
      "epoch": 0.6379453189726595,
      "grad_norm": 0.3120749890804291,
      "learning_rate": 2.628462194489257e-05,
      "loss": 0.0983,
      "step": 1540
    },
    {
      "epoch": 0.6420878210439105,
      "grad_norm": 0.10730336606502533,
      "learning_rate": 2.6277040571386687e-05,
      "loss": 0.0703,
      "step": 1550
    },
    {
      "epoch": 0.6462303231151616,
      "grad_norm": 78.39254760742188,
      "learning_rate": 2.6269459197880806e-05,
      "loss": 0.236,
      "step": 1560
    },
    {
      "epoch": 0.6503728251864126,
      "grad_norm": 5.515563488006592,
      "learning_rate": 2.626187782437492e-05,
      "loss": 0.1419,
      "step": 1570
    },
    {
      "epoch": 0.6545153272576636,
      "grad_norm": 0.15272289514541626,
      "learning_rate": 2.6254296450869044e-05,
      "loss": 0.0988,
      "step": 1580
    },
    {
      "epoch": 0.6586578293289147,
      "grad_norm": 0.1881912797689438,
      "learning_rate": 2.624671507736316e-05,
      "loss": 0.1007,
      "step": 1590
    },
    {
      "epoch": 0.6628003314001657,
      "grad_norm": 6.854607582092285,
      "learning_rate": 2.623913370385728e-05,
      "loss": 0.2858,
      "step": 1600
    },
    {
      "epoch": 0.6669428334714167,
      "grad_norm": 0.8287562131881714,
      "learning_rate": 2.6231552330351394e-05,
      "loss": 0.1446,
      "step": 1610
    },
    {
      "epoch": 0.6710853355426678,
      "grad_norm": 7.551389694213867,
      "learning_rate": 2.6223970956845517e-05,
      "loss": 0.0844,
      "step": 1620
    },
    {
      "epoch": 0.6752278376139188,
      "grad_norm": 0.0928565189242363,
      "learning_rate": 2.6216389583339633e-05,
      "loss": 0.0065,
      "step": 1630
    },
    {
      "epoch": 0.6793703396851698,
      "grad_norm": 0.02607516013085842,
      "learning_rate": 2.620880820983375e-05,
      "loss": 0.0187,
      "step": 1640
    },
    {
      "epoch": 0.6835128417564209,
      "grad_norm": 0.5379101037979126,
      "learning_rate": 2.6201226836327867e-05,
      "loss": 0.0963,
      "step": 1650
    },
    {
      "epoch": 0.6876553438276719,
      "grad_norm": 0.3172972798347473,
      "learning_rate": 2.6193645462821986e-05,
      "loss": 0.1874,
      "step": 1660
    },
    {
      "epoch": 0.6917978458989229,
      "grad_norm": 0.06475364416837692,
      "learning_rate": 2.6186064089316105e-05,
      "loss": 0.0742,
      "step": 1670
    },
    {
      "epoch": 0.695940347970174,
      "grad_norm": 5.806591510772705,
      "learning_rate": 2.617848271581022e-05,
      "loss": 0.1274,
      "step": 1680
    },
    {
      "epoch": 0.700082850041425,
      "grad_norm": 0.6281907558441162,
      "learning_rate": 2.617090134230434e-05,
      "loss": 0.1426,
      "step": 1690
    },
    {
      "epoch": 0.704225352112676,
      "grad_norm": 0.396579384803772,
      "learning_rate": 2.616331996879846e-05,
      "loss": 0.0333,
      "step": 1700
    },
    {
      "epoch": 0.7083678541839271,
      "grad_norm": 4.896944522857666,
      "learning_rate": 2.615573859529258e-05,
      "loss": 0.1156,
      "step": 1710
    },
    {
      "epoch": 0.7125103562551781,
      "grad_norm": 0.13950078189373016,
      "learning_rate": 2.6148157221786694e-05,
      "loss": 0.157,
      "step": 1720
    },
    {
      "epoch": 0.7166528583264291,
      "grad_norm": 0.8751905560493469,
      "learning_rate": 2.6140575848280813e-05,
      "loss": 0.0886,
      "step": 1730
    },
    {
      "epoch": 0.7207953603976802,
      "grad_norm": 0.02922678366303444,
      "learning_rate": 2.6132994474774932e-05,
      "loss": 0.0527,
      "step": 1740
    },
    {
      "epoch": 0.7249378624689312,
      "grad_norm": 8.756200790405273,
      "learning_rate": 2.612541310126905e-05,
      "loss": 0.0492,
      "step": 1750
    },
    {
      "epoch": 0.7290803645401823,
      "grad_norm": 0.01747150532901287,
      "learning_rate": 2.6117831727763167e-05,
      "loss": 0.1026,
      "step": 1760
    },
    {
      "epoch": 0.7332228666114333,
      "grad_norm": 0.10323357582092285,
      "learning_rate": 2.6110250354257286e-05,
      "loss": 0.1894,
      "step": 1770
    },
    {
      "epoch": 0.7373653686826843,
      "grad_norm": 0.5743538737297058,
      "learning_rate": 2.6102668980751405e-05,
      "loss": 0.0678,
      "step": 1780
    },
    {
      "epoch": 0.7415078707539354,
      "grad_norm": 0.19686496257781982,
      "learning_rate": 2.6095087607245524e-05,
      "loss": 0.131,
      "step": 1790
    },
    {
      "epoch": 0.7456503728251864,
      "grad_norm": 3.9432168006896973,
      "learning_rate": 2.608750623373964e-05,
      "loss": 0.0878,
      "step": 1800
    },
    {
      "epoch": 0.7497928748964374,
      "grad_norm": 4.273324012756348,
      "learning_rate": 2.6079924860233756e-05,
      "loss": 0.1275,
      "step": 1810
    },
    {
      "epoch": 0.7539353769676885,
      "grad_norm": 0.10428500920534134,
      "learning_rate": 2.6072343486727875e-05,
      "loss": 0.1706,
      "step": 1820
    },
    {
      "epoch": 0.7580778790389395,
      "grad_norm": 0.2836873233318329,
      "learning_rate": 2.6064762113221994e-05,
      "loss": 0.0069,
      "step": 1830
    },
    {
      "epoch": 0.7622203811101905,
      "grad_norm": 0.09594280272722244,
      "learning_rate": 2.6057180739716113e-05,
      "loss": 0.02,
      "step": 1840
    },
    {
      "epoch": 0.7663628831814416,
      "grad_norm": 0.1328224539756775,
      "learning_rate": 2.604959936621023e-05,
      "loss": 0.0907,
      "step": 1850
    },
    {
      "epoch": 0.7705053852526926,
      "grad_norm": 3.5896005630493164,
      "learning_rate": 2.6042017992704348e-05,
      "loss": 0.1057,
      "step": 1860
    },
    {
      "epoch": 0.7746478873239436,
      "grad_norm": 0.18813009560108185,
      "learning_rate": 2.6034436619198467e-05,
      "loss": 0.0502,
      "step": 1870
    },
    {
      "epoch": 0.7787903893951947,
      "grad_norm": 4.14601993560791,
      "learning_rate": 2.6026855245692586e-05,
      "loss": 0.1203,
      "step": 1880
    },
    {
      "epoch": 0.7829328914664457,
      "grad_norm": 7.849925518035889,
      "learning_rate": 2.60192738721867e-05,
      "loss": 0.0894,
      "step": 1890
    },
    {
      "epoch": 0.7870753935376967,
      "grad_norm": 0.029632018879055977,
      "learning_rate": 2.601169249868082e-05,
      "loss": 0.0762,
      "step": 1900
    },
    {
      "epoch": 0.7912178956089478,
      "grad_norm": 0.040374793112277985,
      "learning_rate": 2.600411112517494e-05,
      "loss": 0.032,
      "step": 1910
    },
    {
      "epoch": 0.7953603976801988,
      "grad_norm": 0.25717318058013916,
      "learning_rate": 2.599652975166906e-05,
      "loss": 0.0876,
      "step": 1920
    },
    {
      "epoch": 0.7995028997514498,
      "grad_norm": 0.048960983753204346,
      "learning_rate": 2.5988948378163174e-05,
      "loss": 0.0051,
      "step": 1930
    },
    {
      "epoch": 0.8036454018227009,
      "grad_norm": 0.020872021093964577,
      "learning_rate": 2.5981367004657293e-05,
      "loss": 0.0625,
      "step": 1940
    },
    {
      "epoch": 0.8077879038939519,
      "grad_norm": 5.856494426727295,
      "learning_rate": 2.5973785631151413e-05,
      "loss": 0.2542,
      "step": 1950
    },
    {
      "epoch": 0.8119304059652029,
      "grad_norm": 7.099965572357178,
      "learning_rate": 2.5966204257645528e-05,
      "loss": 0.0201,
      "step": 1960
    },
    {
      "epoch": 0.816072908036454,
      "grad_norm": 6.190831184387207,
      "learning_rate": 2.5958622884139647e-05,
      "loss": 0.1279,
      "step": 1970
    },
    {
      "epoch": 0.820215410107705,
      "grad_norm": 0.0312836579978466,
      "learning_rate": 2.5951041510633763e-05,
      "loss": 0.0478,
      "step": 1980
    },
    {
      "epoch": 0.824357912178956,
      "grad_norm": 4.718728065490723,
      "learning_rate": 2.5943460137127885e-05,
      "loss": 0.0761,
      "step": 1990
    },
    {
      "epoch": 0.8285004142502072,
      "grad_norm": 0.7133755087852478,
      "learning_rate": 2.5935878763622e-05,
      "loss": 0.0829,
      "step": 2000
    },
    {
      "epoch": 0.8326429163214581,
      "grad_norm": 0.24359171092510223,
      "learning_rate": 2.592829739011612e-05,
      "loss": 0.094,
      "step": 2010
    },
    {
      "epoch": 0.8367854183927091,
      "grad_norm": 0.026697499677538872,
      "learning_rate": 2.5920716016610236e-05,
      "loss": 0.0513,
      "step": 2020
    },
    {
      "epoch": 0.8409279204639603,
      "grad_norm": 0.040772054344415665,
      "learning_rate": 2.591313464310436e-05,
      "loss": 0.0728,
      "step": 2030
    },
    {
      "epoch": 0.8450704225352113,
      "grad_norm": 1.5838054418563843,
      "learning_rate": 2.5905553269598474e-05,
      "loss": 0.03,
      "step": 2040
    },
    {
      "epoch": 0.8492129246064622,
      "grad_norm": 4.06743860244751,
      "learning_rate": 2.5897971896092593e-05,
      "loss": 0.1432,
      "step": 2050
    },
    {
      "epoch": 0.8533554266777134,
      "grad_norm": 5.662973403930664,
      "learning_rate": 2.589039052258671e-05,
      "loss": 0.1037,
      "step": 2060
    },
    {
      "epoch": 0.8574979287489644,
      "grad_norm": 15.77283000946045,
      "learning_rate": 2.588280914908083e-05,
      "loss": 0.0818,
      "step": 2070
    },
    {
      "epoch": 0.8616404308202155,
      "grad_norm": 1.8038465976715088,
      "learning_rate": 2.5875227775574947e-05,
      "loss": 0.1528,
      "step": 2080
    },
    {
      "epoch": 0.8657829328914665,
      "grad_norm": 2.8732900619506836,
      "learning_rate": 2.5867646402069066e-05,
      "loss": 0.1231,
      "step": 2090
    },
    {
      "epoch": 0.8699254349627175,
      "grad_norm": 6.148952007293701,
      "learning_rate": 2.5860065028563182e-05,
      "loss": 0.0722,
      "step": 2100
    },
    {
      "epoch": 0.8740679370339686,
      "grad_norm": 4.865981578826904,
      "learning_rate": 2.58524836550573e-05,
      "loss": 0.0931,
      "step": 2110
    },
    {
      "epoch": 0.8782104391052196,
      "grad_norm": 0.016947099938988686,
      "learning_rate": 2.584490228155142e-05,
      "loss": 0.1028,
      "step": 2120
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 2.1419949531555176,
      "learning_rate": 2.5837320908045536e-05,
      "loss": 0.0633,
      "step": 2130
    },
    {
      "epoch": 0.8864954432477217,
      "grad_norm": 5.49483060836792,
      "learning_rate": 2.5829739534539655e-05,
      "loss": 0.035,
      "step": 2140
    },
    {
      "epoch": 0.8906379453189727,
      "grad_norm": 0.19424571096897125,
      "learning_rate": 2.5822158161033774e-05,
      "loss": 0.2166,
      "step": 2150
    },
    {
      "epoch": 0.8947804473902237,
      "grad_norm": 0.08545573800802231,
      "learning_rate": 2.5814576787527893e-05,
      "loss": 0.0757,
      "step": 2160
    },
    {
      "epoch": 0.8989229494614748,
      "grad_norm": 6.041334629058838,
      "learning_rate": 2.580699541402201e-05,
      "loss": 0.0545,
      "step": 2170
    },
    {
      "epoch": 0.9030654515327258,
      "grad_norm": 5.901354789733887,
      "learning_rate": 2.5799414040516128e-05,
      "loss": 0.0873,
      "step": 2180
    },
    {
      "epoch": 0.9072079536039768,
      "grad_norm": 0.07888884842395782,
      "learning_rate": 2.5791832667010247e-05,
      "loss": 0.0487,
      "step": 2190
    },
    {
      "epoch": 0.9113504556752279,
      "grad_norm": 0.7791761755943298,
      "learning_rate": 2.5784251293504366e-05,
      "loss": 0.0571,
      "step": 2200
    },
    {
      "epoch": 0.9154929577464789,
      "grad_norm": 0.1725582480430603,
      "learning_rate": 2.577666991999848e-05,
      "loss": 0.0981,
      "step": 2210
    },
    {
      "epoch": 0.9196354598177299,
      "grad_norm": 0.1517120897769928,
      "learning_rate": 2.57690885464926e-05,
      "loss": 0.0022,
      "step": 2220
    },
    {
      "epoch": 0.923777961888981,
      "grad_norm": 0.32292038202285767,
      "learning_rate": 2.5761507172986716e-05,
      "loss": 0.0009,
      "step": 2230
    },
    {
      "epoch": 0.927920463960232,
      "grad_norm": 0.028657881543040276,
      "learning_rate": 2.5753925799480835e-05,
      "loss": 0.0812,
      "step": 2240
    },
    {
      "epoch": 0.932062966031483,
      "grad_norm": 0.03142494708299637,
      "learning_rate": 2.5746344425974954e-05,
      "loss": 0.0153,
      "step": 2250
    },
    {
      "epoch": 0.9362054681027341,
      "grad_norm": 0.03541162982583046,
      "learning_rate": 2.573876305246907e-05,
      "loss": 0.1111,
      "step": 2260
    },
    {
      "epoch": 0.9403479701739851,
      "grad_norm": 0.0547882504761219,
      "learning_rate": 2.573118167896319e-05,
      "loss": 0.0272,
      "step": 2270
    },
    {
      "epoch": 0.9444904722452361,
      "grad_norm": 12.304231643676758,
      "learning_rate": 2.5723600305457308e-05,
      "loss": 0.0897,
      "step": 2280
    },
    {
      "epoch": 0.9486329743164872,
      "grad_norm": 0.3216392993927002,
      "learning_rate": 2.5716018931951427e-05,
      "loss": 0.149,
      "step": 2290
    },
    {
      "epoch": 0.9527754763877382,
      "grad_norm": 0.06460004299879074,
      "learning_rate": 2.5708437558445543e-05,
      "loss": 0.0278,
      "step": 2300
    },
    {
      "epoch": 0.9569179784589892,
      "grad_norm": 0.05446988344192505,
      "learning_rate": 2.5700856184939662e-05,
      "loss": 0.0164,
      "step": 2310
    },
    {
      "epoch": 0.9610604805302403,
      "grad_norm": 8.246145248413086,
      "learning_rate": 2.569327481143378e-05,
      "loss": 0.1214,
      "step": 2320
    },
    {
      "epoch": 0.9652029826014913,
      "grad_norm": 3.016545534133911,
      "learning_rate": 2.56856934379279e-05,
      "loss": 0.0898,
      "step": 2330
    },
    {
      "epoch": 0.9693454846727423,
      "grad_norm": 0.42347678542137146,
      "learning_rate": 2.5678112064422016e-05,
      "loss": 0.0947,
      "step": 2340
    },
    {
      "epoch": 0.9734879867439934,
      "grad_norm": 0.09008453786373138,
      "learning_rate": 2.5670530690916135e-05,
      "loss": 0.028,
      "step": 2350
    },
    {
      "epoch": 0.9776304888152444,
      "grad_norm": 6.366384506225586,
      "learning_rate": 2.5662949317410254e-05,
      "loss": 0.0939,
      "step": 2360
    },
    {
      "epoch": 0.9817729908864954,
      "grad_norm": 0.5536946058273315,
      "learning_rate": 2.5655367943904373e-05,
      "loss": 0.0683,
      "step": 2370
    },
    {
      "epoch": 0.9859154929577465,
      "grad_norm": 30.406320571899414,
      "learning_rate": 2.564778657039849e-05,
      "loss": 0.051,
      "step": 2380
    },
    {
      "epoch": 0.9900579950289975,
      "grad_norm": 10.701363563537598,
      "learning_rate": 2.5640205196892608e-05,
      "loss": 0.1717,
      "step": 2390
    },
    {
      "epoch": 0.9942004971002486,
      "grad_norm": 0.05437922105193138,
      "learning_rate": 2.5632623823386727e-05,
      "loss": 0.0763,
      "step": 2400
    },
    {
      "epoch": 0.9983429991714996,
      "grad_norm": 0.23946233093738556,
      "learning_rate": 2.5625042449880843e-05,
      "loss": 0.1413,
      "step": 2410
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9821083172147002,
      "eval_f1": 0.8959212376933895,
      "eval_loss": 0.05387189984321594,
      "eval_precision": 0.9550224887556222,
      "eval_recall": 0.8437086092715231,
      "eval_runtime": 2098.3652,
      "eval_samples_per_second": 3.944,
      "eval_steps_per_second": 0.493,
      "step": 2414
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9821083172147002,
      "eval_f1": 0.8959212376933895,
      "eval_loss": 0.05387189984321594,
      "eval_precision": 0.9550224887556222,
      "eval_recall": 0.8437086092715231,
      "eval_runtime": 2049.7091,
      "eval_samples_per_second": 4.038,
      "eval_steps_per_second": 0.505,
      "step": 2414
    }
  ],
  "logging_steps": 10,
  "max_steps": 36210,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 4
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8628426376169280.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": {
    "epochs": 15,
    "gradient_accumulation_steps": 1,
    "learning_rate": 2.73869536526478e-05,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 16,
    "warmup_steps": 86,
    "weight_decay": 0.0673925458056486
  }
}
