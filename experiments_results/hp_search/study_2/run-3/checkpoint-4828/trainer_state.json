{
  "best_metric": 0.9602157788267026,
  "best_model_checkpoint": "../hyperparameter_search/run-3/checkpoint-4828",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 4828,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0014498757249378626,
      "grad_norm": 34.081138610839844,
      "learning_rate": 6.935402872831713e-08,
      "loss": 0.7116,
      "step": 1
    },
    {
      "epoch": 0.014498757249378625,
      "grad_norm": 29.88652801513672,
      "learning_rate": 6.935402872831714e-07,
      "loss": 0.8204,
      "step": 10
    },
    {
      "epoch": 0.02899751449875725,
      "grad_norm": 36.01459884643555,
      "learning_rate": 1.3870805745663428e-06,
      "loss": 0.6941,
      "step": 20
    },
    {
      "epoch": 0.043496271748135876,
      "grad_norm": 18.073444366455078,
      "learning_rate": 2.080620861849514e-06,
      "loss": 0.5365,
      "step": 30
    },
    {
      "epoch": 0.0579950289975145,
      "grad_norm": 16.857643127441406,
      "learning_rate": 2.7741611491326856e-06,
      "loss": 0.4383,
      "step": 40
    },
    {
      "epoch": 0.07249378624689312,
      "grad_norm": 77.32138061523438,
      "learning_rate": 3.467701436415857e-06,
      "loss": 0.3025,
      "step": 50
    },
    {
      "epoch": 0.08699254349627175,
      "grad_norm": 39.03904342651367,
      "learning_rate": 4.161241723699028e-06,
      "loss": 0.3082,
      "step": 60
    },
    {
      "epoch": 0.10149130074565037,
      "grad_norm": 10.704826354980469,
      "learning_rate": 4.854782010982199e-06,
      "loss": 0.388,
      "step": 70
    },
    {
      "epoch": 0.115990057995029,
      "grad_norm": 21.662622451782227,
      "learning_rate": 5.548322298265371e-06,
      "loss": 0.3061,
      "step": 80
    },
    {
      "epoch": 0.1304888152444076,
      "grad_norm": 21.351730346679688,
      "learning_rate": 6.241862585548542e-06,
      "loss": 0.3391,
      "step": 90
    },
    {
      "epoch": 0.14498757249378624,
      "grad_norm": 10.800354957580566,
      "learning_rate": 6.935402872831714e-06,
      "loss": 0.3188,
      "step": 100
    },
    {
      "epoch": 0.15948632974316487,
      "grad_norm": 19.026809692382812,
      "learning_rate": 7.6289431601148846e-06,
      "loss": 0.3174,
      "step": 110
    },
    {
      "epoch": 0.1739850869925435,
      "grad_norm": 11.051339149475098,
      "learning_rate": 8.322483447398056e-06,
      "loss": 0.3303,
      "step": 120
    },
    {
      "epoch": 0.18848384424192213,
      "grad_norm": 9.330852508544922,
      "learning_rate": 9.016023734681228e-06,
      "loss": 0.2463,
      "step": 130
    },
    {
      "epoch": 0.20298260149130073,
      "grad_norm": 12.831767082214355,
      "learning_rate": 9.709564021964399e-06,
      "loss": 0.3497,
      "step": 140
    },
    {
      "epoch": 0.21748135874067936,
      "grad_norm": 10.281744003295898,
      "learning_rate": 1.040310430924757e-05,
      "loss": 0.2912,
      "step": 150
    },
    {
      "epoch": 0.231980115990058,
      "grad_norm": 9.554474830627441,
      "learning_rate": 1.1096644596530743e-05,
      "loss": 0.2881,
      "step": 160
    },
    {
      "epoch": 0.24647887323943662,
      "grad_norm": 13.982902526855469,
      "learning_rate": 1.1790184883813914e-05,
      "loss": 0.3074,
      "step": 170
    },
    {
      "epoch": 0.2609776304888152,
      "grad_norm": 9.612614631652832,
      "learning_rate": 1.2483725171097085e-05,
      "loss": 0.2316,
      "step": 180
    },
    {
      "epoch": 0.2754763877381939,
      "grad_norm": 7.091908931732178,
      "learning_rate": 1.3177265458380254e-05,
      "loss": 0.272,
      "step": 190
    },
    {
      "epoch": 0.2899751449875725,
      "grad_norm": 10.038822174072266,
      "learning_rate": 1.3870805745663429e-05,
      "loss": 0.2406,
      "step": 200
    },
    {
      "epoch": 0.30447390223695114,
      "grad_norm": 10.965568542480469,
      "learning_rate": 1.4564346032946598e-05,
      "loss": 0.2789,
      "step": 210
    },
    {
      "epoch": 0.31897265948632975,
      "grad_norm": 11.850482940673828,
      "learning_rate": 1.5257886320229769e-05,
      "loss": 0.2563,
      "step": 220
    },
    {
      "epoch": 0.33347141673570835,
      "grad_norm": 10.38819694519043,
      "learning_rate": 1.595142660751294e-05,
      "loss": 0.2847,
      "step": 230
    },
    {
      "epoch": 0.347970173985087,
      "grad_norm": 5.115543842315674,
      "learning_rate": 1.6644966894796113e-05,
      "loss": 0.2268,
      "step": 240
    },
    {
      "epoch": 0.3624689312344656,
      "grad_norm": 9.451969146728516,
      "learning_rate": 1.7338507182079286e-05,
      "loss": 0.2441,
      "step": 250
    },
    {
      "epoch": 0.37696768848384427,
      "grad_norm": 16.02366065979004,
      "learning_rate": 1.8032047469362455e-05,
      "loss": 0.2443,
      "step": 260
    },
    {
      "epoch": 0.39146644573322287,
      "grad_norm": 5.244675636291504,
      "learning_rate": 1.8011313828487026e-05,
      "loss": 0.2287,
      "step": 270
    },
    {
      "epoch": 0.40596520298260147,
      "grad_norm": 6.427607536315918,
      "learning_rate": 1.7990580187611593e-05,
      "loss": 0.226,
      "step": 280
    },
    {
      "epoch": 0.4204639602319801,
      "grad_norm": 5.8137102127075195,
      "learning_rate": 1.7969846546736163e-05,
      "loss": 0.2083,
      "step": 290
    },
    {
      "epoch": 0.43496271748135873,
      "grad_norm": 10.44100570678711,
      "learning_rate": 1.794911290586073e-05,
      "loss": 0.2135,
      "step": 300
    },
    {
      "epoch": 0.4494614747307374,
      "grad_norm": 4.684502124786377,
      "learning_rate": 1.79283792649853e-05,
      "loss": 0.1894,
      "step": 310
    },
    {
      "epoch": 0.463960231980116,
      "grad_norm": 5.163472652435303,
      "learning_rate": 1.790764562410987e-05,
      "loss": 0.2113,
      "step": 320
    },
    {
      "epoch": 0.4784589892294946,
      "grad_norm": 5.537144660949707,
      "learning_rate": 1.7886911983234436e-05,
      "loss": 0.2003,
      "step": 330
    },
    {
      "epoch": 0.49295774647887325,
      "grad_norm": 5.738603591918945,
      "learning_rate": 1.7866178342359006e-05,
      "loss": 0.1826,
      "step": 340
    },
    {
      "epoch": 0.5074565037282519,
      "grad_norm": 5.641097545623779,
      "learning_rate": 1.7845444701483573e-05,
      "loss": 0.1877,
      "step": 350
    },
    {
      "epoch": 0.5219552609776305,
      "grad_norm": 5.574896335601807,
      "learning_rate": 1.7824711060608144e-05,
      "loss": 0.1762,
      "step": 360
    },
    {
      "epoch": 0.5364540182270091,
      "grad_norm": 5.274430274963379,
      "learning_rate": 1.780397741973271e-05,
      "loss": 0.1469,
      "step": 370
    },
    {
      "epoch": 0.5509527754763878,
      "grad_norm": 2.7464308738708496,
      "learning_rate": 1.778324377885728e-05,
      "loss": 0.1129,
      "step": 380
    },
    {
      "epoch": 0.5654515327257663,
      "grad_norm": 1.973676323890686,
      "learning_rate": 1.776251013798185e-05,
      "loss": 0.1642,
      "step": 390
    },
    {
      "epoch": 0.579950289975145,
      "grad_norm": 3.4215755462646484,
      "learning_rate": 1.774177649710642e-05,
      "loss": 0.1937,
      "step": 400
    },
    {
      "epoch": 0.5944490472245236,
      "grad_norm": 7.0116496086120605,
      "learning_rate": 1.772104285623099e-05,
      "loss": 0.1603,
      "step": 410
    },
    {
      "epoch": 0.6089478044739023,
      "grad_norm": 6.594470500946045,
      "learning_rate": 1.7700309215355557e-05,
      "loss": 0.1731,
      "step": 420
    },
    {
      "epoch": 0.6234465617232808,
      "grad_norm": 5.184927940368652,
      "learning_rate": 1.7679575574480128e-05,
      "loss": 0.1621,
      "step": 430
    },
    {
      "epoch": 0.6379453189726595,
      "grad_norm": 6.707918167114258,
      "learning_rate": 1.7658841933604695e-05,
      "loss": 0.1758,
      "step": 440
    },
    {
      "epoch": 0.6524440762220381,
      "grad_norm": 4.450709819793701,
      "learning_rate": 1.7638108292729265e-05,
      "loss": 0.1595,
      "step": 450
    },
    {
      "epoch": 0.6669428334714167,
      "grad_norm": 5.926711559295654,
      "learning_rate": 1.7617374651853833e-05,
      "loss": 0.1499,
      "step": 460
    },
    {
      "epoch": 0.6814415907207954,
      "grad_norm": 6.137160778045654,
      "learning_rate": 1.75966410109784e-05,
      "loss": 0.1114,
      "step": 470
    },
    {
      "epoch": 0.695940347970174,
      "grad_norm": 3.7236475944519043,
      "learning_rate": 1.757590737010297e-05,
      "loss": 0.1327,
      "step": 480
    },
    {
      "epoch": 0.7104391052195526,
      "grad_norm": 4.936381816864014,
      "learning_rate": 1.7555173729227538e-05,
      "loss": 0.1202,
      "step": 490
    },
    {
      "epoch": 0.7249378624689312,
      "grad_norm": 18.883258819580078,
      "learning_rate": 1.7534440088352108e-05,
      "loss": 0.1495,
      "step": 500
    },
    {
      "epoch": 0.7394366197183099,
      "grad_norm": 3.9192702770233154,
      "learning_rate": 1.7513706447476675e-05,
      "loss": 0.1804,
      "step": 510
    },
    {
      "epoch": 0.7539353769676885,
      "grad_norm": 8.281048774719238,
      "learning_rate": 1.7492972806601246e-05,
      "loss": 0.2073,
      "step": 520
    },
    {
      "epoch": 0.7684341342170671,
      "grad_norm": 4.7745866775512695,
      "learning_rate": 1.7472239165725813e-05,
      "loss": 0.1261,
      "step": 530
    },
    {
      "epoch": 0.7829328914664457,
      "grad_norm": 4.612105846405029,
      "learning_rate": 1.7451505524850384e-05,
      "loss": 0.1077,
      "step": 540
    },
    {
      "epoch": 0.7974316487158244,
      "grad_norm": 5.7085652351379395,
      "learning_rate": 1.7430771883974954e-05,
      "loss": 0.1307,
      "step": 550
    },
    {
      "epoch": 0.8119304059652029,
      "grad_norm": 5.059426307678223,
      "learning_rate": 1.741003824309952e-05,
      "loss": 0.1362,
      "step": 560
    },
    {
      "epoch": 0.8264291632145816,
      "grad_norm": 1.479446530342102,
      "learning_rate": 1.7389304602224092e-05,
      "loss": 0.0814,
      "step": 570
    },
    {
      "epoch": 0.8409279204639603,
      "grad_norm": 3.980748176574707,
      "learning_rate": 1.736857096134866e-05,
      "loss": 0.1036,
      "step": 580
    },
    {
      "epoch": 0.8554266777133389,
      "grad_norm": 1.6307594776153564,
      "learning_rate": 1.734783732047323e-05,
      "loss": 0.1166,
      "step": 590
    },
    {
      "epoch": 0.8699254349627175,
      "grad_norm": 7.603625297546387,
      "learning_rate": 1.7327103679597797e-05,
      "loss": 0.1354,
      "step": 600
    },
    {
      "epoch": 0.8844241922120961,
      "grad_norm": 5.803844451904297,
      "learning_rate": 1.7306370038722364e-05,
      "loss": 0.1196,
      "step": 610
    },
    {
      "epoch": 0.8989229494614748,
      "grad_norm": 3.062607526779175,
      "learning_rate": 1.7285636397846935e-05,
      "loss": 0.1086,
      "step": 620
    },
    {
      "epoch": 0.9134217067108533,
      "grad_norm": 2.4045400619506836,
      "learning_rate": 1.7264902756971502e-05,
      "loss": 0.0892,
      "step": 630
    },
    {
      "epoch": 0.927920463960232,
      "grad_norm": 1.7539880275726318,
      "learning_rate": 1.7244169116096072e-05,
      "loss": 0.0774,
      "step": 640
    },
    {
      "epoch": 0.9424192212096106,
      "grad_norm": 4.246334552764893,
      "learning_rate": 1.722343547522064e-05,
      "loss": 0.0797,
      "step": 650
    },
    {
      "epoch": 0.9569179784589892,
      "grad_norm": 2.1479876041412354,
      "learning_rate": 1.720270183434521e-05,
      "loss": 0.0719,
      "step": 660
    },
    {
      "epoch": 0.9714167357083678,
      "grad_norm": 30.177061080932617,
      "learning_rate": 1.7181968193469777e-05,
      "loss": 0.1097,
      "step": 670
    },
    {
      "epoch": 0.9859154929577465,
      "grad_norm": 2.3602476119995117,
      "learning_rate": 1.7161234552594348e-05,
      "loss": 0.0963,
      "step": 680
    },
    {
      "epoch": 0.9989643744821872,
      "eval_accuracy": 0.968568665377176,
      "eval_f1": 0.8278145695364238,
      "eval_loss": 0.08730405569076538,
      "eval_precision": 0.8278145695364238,
      "eval_recall": 0.8278145695364238,
      "eval_runtime": 5572.7109,
      "eval_samples_per_second": 1.485,
      "eval_steps_per_second": 0.186,
      "step": 689
    },
    {
      "epoch": 0.9989643744821872,
      "eval_accuracy": 0.968568665377176,
      "eval_f1": 0.8278145695364238,
      "eval_loss": 0.08730405569076538,
      "eval_precision": 0.8278145695364238,
      "eval_recall": 0.8278145695364238,
      "eval_runtime": 5640.7023,
      "eval_samples_per_second": 1.467,
      "eval_steps_per_second": 0.183,
      "step": 689
    },
    {
      "epoch": 1.0004142502071252,
      "grad_norm": 2.211040496826172,
      "learning_rate": 1.714050091171892e-05,
      "loss": 0.0899,
      "step": 690
    },
    {
      "epoch": 1.0149130074565038,
      "grad_norm": 2.7266297340393066,
      "learning_rate": 1.7119767270843486e-05,
      "loss": 0.0671,
      "step": 700
    },
    {
      "epoch": 1.0294117647058822,
      "grad_norm": 4.2334794998168945,
      "learning_rate": 1.7099033629968056e-05,
      "loss": 0.068,
      "step": 710
    },
    {
      "epoch": 1.043910521955261,
      "grad_norm": 5.153541564941406,
      "learning_rate": 1.7078299989092623e-05,
      "loss": 0.0751,
      "step": 720
    },
    {
      "epoch": 1.0584092792046396,
      "grad_norm": 5.173806190490723,
      "learning_rate": 1.7057566348217194e-05,
      "loss": 0.0658,
      "step": 730
    },
    {
      "epoch": 1.0729080364540182,
      "grad_norm": 2.346475124359131,
      "learning_rate": 1.703683270734176e-05,
      "loss": 0.0461,
      "step": 740
    },
    {
      "epoch": 1.0874067937033969,
      "grad_norm": 6.159321308135986,
      "learning_rate": 1.7016099066466328e-05,
      "loss": 0.0969,
      "step": 750
    },
    {
      "epoch": 1.1019055509527755,
      "grad_norm": 2.4898252487182617,
      "learning_rate": 1.69953654255909e-05,
      "loss": 0.0987,
      "step": 760
    },
    {
      "epoch": 1.1164043082021542,
      "grad_norm": 5.895386695861816,
      "learning_rate": 1.6974631784715466e-05,
      "loss": 0.091,
      "step": 770
    },
    {
      "epoch": 1.1309030654515326,
      "grad_norm": 1.5579994916915894,
      "learning_rate": 1.6953898143840037e-05,
      "loss": 0.0851,
      "step": 780
    },
    {
      "epoch": 1.1454018227009113,
      "grad_norm": 0.3116747736930847,
      "learning_rate": 1.6933164502964604e-05,
      "loss": 0.0752,
      "step": 790
    },
    {
      "epoch": 1.15990057995029,
      "grad_norm": 3.4911863803863525,
      "learning_rate": 1.6912430862089174e-05,
      "loss": 0.0646,
      "step": 800
    },
    {
      "epoch": 1.1743993371996686,
      "grad_norm": 4.218676567077637,
      "learning_rate": 1.689169722121374e-05,
      "loss": 0.0609,
      "step": 810
    },
    {
      "epoch": 1.1888980944490473,
      "grad_norm": 2.72763991355896,
      "learning_rate": 1.6870963580338312e-05,
      "loss": 0.0491,
      "step": 820
    },
    {
      "epoch": 1.203396851698426,
      "grad_norm": 4.136964797973633,
      "learning_rate": 1.685022993946288e-05,
      "loss": 0.089,
      "step": 830
    },
    {
      "epoch": 1.2178956089478046,
      "grad_norm": 0.4492267966270447,
      "learning_rate": 1.682949629858745e-05,
      "loss": 0.0666,
      "step": 840
    },
    {
      "epoch": 1.232394366197183,
      "grad_norm": 0.7122538685798645,
      "learning_rate": 1.680876265771202e-05,
      "loss": 0.1019,
      "step": 850
    },
    {
      "epoch": 1.2468931234465617,
      "grad_norm": 2.1414475440979004,
      "learning_rate": 1.6788029016836588e-05,
      "loss": 0.068,
      "step": 860
    },
    {
      "epoch": 1.2613918806959403,
      "grad_norm": 2.872589111328125,
      "learning_rate": 1.6767295375961158e-05,
      "loss": 0.0484,
      "step": 870
    },
    {
      "epoch": 1.275890637945319,
      "grad_norm": 4.4563822746276855,
      "learning_rate": 1.6746561735085725e-05,
      "loss": 0.0724,
      "step": 880
    },
    {
      "epoch": 1.2903893951946976,
      "grad_norm": 0.5590136051177979,
      "learning_rate": 1.6725828094210293e-05,
      "loss": 0.0633,
      "step": 890
    },
    {
      "epoch": 1.3048881524440763,
      "grad_norm": 3.6849167346954346,
      "learning_rate": 1.6705094453334863e-05,
      "loss": 0.0517,
      "step": 900
    },
    {
      "epoch": 1.319386909693455,
      "grad_norm": 7.5394086837768555,
      "learning_rate": 1.668436081245943e-05,
      "loss": 0.0863,
      "step": 910
    },
    {
      "epoch": 1.3338856669428334,
      "grad_norm": 1.2913727760314941,
      "learning_rate": 1.6663627171584e-05,
      "loss": 0.0707,
      "step": 920
    },
    {
      "epoch": 1.348384424192212,
      "grad_norm": 3.129546642303467,
      "learning_rate": 1.6642893530708568e-05,
      "loss": 0.0629,
      "step": 930
    },
    {
      "epoch": 1.3628831814415907,
      "grad_norm": 2.995485782623291,
      "learning_rate": 1.662215988983314e-05,
      "loss": 0.0469,
      "step": 940
    },
    {
      "epoch": 1.3773819386909694,
      "grad_norm": 0.5184095501899719,
      "learning_rate": 1.6601426248957706e-05,
      "loss": 0.0394,
      "step": 950
    },
    {
      "epoch": 1.391880695940348,
      "grad_norm": 4.027637481689453,
      "learning_rate": 1.6580692608082276e-05,
      "loss": 0.0582,
      "step": 960
    },
    {
      "epoch": 1.4063794531897265,
      "grad_norm": 1.9705651998519897,
      "learning_rate": 1.6559958967206844e-05,
      "loss": 0.0408,
      "step": 970
    },
    {
      "epoch": 1.4208782104391053,
      "grad_norm": 2.6017138957977295,
      "learning_rate": 1.6539225326331414e-05,
      "loss": 0.0454,
      "step": 980
    },
    {
      "epoch": 1.4353769676884838,
      "grad_norm": 1.0213496685028076,
      "learning_rate": 1.6518491685455985e-05,
      "loss": 0.0525,
      "step": 990
    },
    {
      "epoch": 1.4498757249378624,
      "grad_norm": 3.6740729808807373,
      "learning_rate": 1.6497758044580552e-05,
      "loss": 0.0438,
      "step": 1000
    },
    {
      "epoch": 1.464374482187241,
      "grad_norm": 8.804876327514648,
      "learning_rate": 1.6477024403705122e-05,
      "loss": 0.0539,
      "step": 1010
    },
    {
      "epoch": 1.4788732394366197,
      "grad_norm": 0.6827623844146729,
      "learning_rate": 1.645629076282969e-05,
      "loss": 0.0448,
      "step": 1020
    },
    {
      "epoch": 1.4933719966859984,
      "grad_norm": 2.035281181335449,
      "learning_rate": 1.6435557121954257e-05,
      "loss": 0.0828,
      "step": 1030
    },
    {
      "epoch": 1.5078707539353768,
      "grad_norm": 4.404580116271973,
      "learning_rate": 1.6414823481078827e-05,
      "loss": 0.0824,
      "step": 1040
    },
    {
      "epoch": 1.5223695111847557,
      "grad_norm": 5.909735202789307,
      "learning_rate": 1.6394089840203394e-05,
      "loss": 0.0718,
      "step": 1050
    },
    {
      "epoch": 1.5368682684341342,
      "grad_norm": 5.309474468231201,
      "learning_rate": 1.6373356199327965e-05,
      "loss": 0.0785,
      "step": 1060
    },
    {
      "epoch": 1.5513670256835128,
      "grad_norm": 1.9492547512054443,
      "learning_rate": 1.6352622558452532e-05,
      "loss": 0.0586,
      "step": 1070
    },
    {
      "epoch": 1.5658657829328915,
      "grad_norm": 2.421107292175293,
      "learning_rate": 1.6331888917577103e-05,
      "loss": 0.042,
      "step": 1080
    },
    {
      "epoch": 1.5803645401822701,
      "grad_norm": 1.9251879453659058,
      "learning_rate": 1.631115527670167e-05,
      "loss": 0.0511,
      "step": 1090
    },
    {
      "epoch": 1.5948632974316488,
      "grad_norm": 0.8775240778923035,
      "learning_rate": 1.629042163582624e-05,
      "loss": 0.0246,
      "step": 1100
    },
    {
      "epoch": 1.6093620546810272,
      "grad_norm": 1.1600784063339233,
      "learning_rate": 1.6269687994950808e-05,
      "loss": 0.0235,
      "step": 1110
    },
    {
      "epoch": 1.623860811930406,
      "grad_norm": 4.6284942626953125,
      "learning_rate": 1.624895435407538e-05,
      "loss": 0.0576,
      "step": 1120
    },
    {
      "epoch": 1.6383595691797845,
      "grad_norm": 1.321791648864746,
      "learning_rate": 1.622822071319995e-05,
      "loss": 0.0659,
      "step": 1130
    },
    {
      "epoch": 1.6528583264291632,
      "grad_norm": 2.766916513442993,
      "learning_rate": 1.6207487072324516e-05,
      "loss": 0.0348,
      "step": 1140
    },
    {
      "epoch": 1.6673570836785419,
      "grad_norm": 1.6072627305984497,
      "learning_rate": 1.6186753431449087e-05,
      "loss": 0.0442,
      "step": 1150
    },
    {
      "epoch": 1.6818558409279205,
      "grad_norm": 3.3151562213897705,
      "learning_rate": 1.6166019790573654e-05,
      "loss": 0.0557,
      "step": 1160
    },
    {
      "epoch": 1.6963545981772992,
      "grad_norm": 0.0950239896774292,
      "learning_rate": 1.614528614969822e-05,
      "loss": 0.0512,
      "step": 1170
    },
    {
      "epoch": 1.7108533554266776,
      "grad_norm": 7.2408552169799805,
      "learning_rate": 1.612455250882279e-05,
      "loss": 0.0851,
      "step": 1180
    },
    {
      "epoch": 1.7253521126760565,
      "grad_norm": 6.300607681274414,
      "learning_rate": 1.610381886794736e-05,
      "loss": 0.0547,
      "step": 1190
    },
    {
      "epoch": 1.739850869925435,
      "grad_norm": 3.1028571128845215,
      "learning_rate": 1.608308522707193e-05,
      "loss": 0.0408,
      "step": 1200
    },
    {
      "epoch": 1.7543496271748136,
      "grad_norm": 0.9181589484214783,
      "learning_rate": 1.6062351586196496e-05,
      "loss": 0.0385,
      "step": 1210
    },
    {
      "epoch": 1.7688483844241922,
      "grad_norm": 2.6145002841949463,
      "learning_rate": 1.6041617945321067e-05,
      "loss": 0.0449,
      "step": 1220
    },
    {
      "epoch": 1.783347141673571,
      "grad_norm": 6.695553302764893,
      "learning_rate": 1.6020884304445634e-05,
      "loss": 0.0667,
      "step": 1230
    },
    {
      "epoch": 1.7978458989229495,
      "grad_norm": 0.7041991353034973,
      "learning_rate": 1.6000150663570205e-05,
      "loss": 0.0369,
      "step": 1240
    },
    {
      "epoch": 1.812344656172328,
      "grad_norm": 3.737623691558838,
      "learning_rate": 1.5979417022694772e-05,
      "loss": 0.0362,
      "step": 1250
    },
    {
      "epoch": 1.8268434134217069,
      "grad_norm": 3.1268789768218994,
      "learning_rate": 1.5958683381819343e-05,
      "loss": 0.0412,
      "step": 1260
    },
    {
      "epoch": 1.8413421706710853,
      "grad_norm": 1.1156584024429321,
      "learning_rate": 1.5937949740943913e-05,
      "loss": 0.0635,
      "step": 1270
    },
    {
      "epoch": 1.855840927920464,
      "grad_norm": 5.462100028991699,
      "learning_rate": 1.591721610006848e-05,
      "loss": 0.0427,
      "step": 1280
    },
    {
      "epoch": 1.8703396851698426,
      "grad_norm": 1.9860504865646362,
      "learning_rate": 1.589648245919305e-05,
      "loss": 0.0493,
      "step": 1290
    },
    {
      "epoch": 1.884838442419221,
      "grad_norm": 0.3560471832752228,
      "learning_rate": 1.5875748818317618e-05,
      "loss": 0.0335,
      "step": 1300
    },
    {
      "epoch": 1.8993371996686,
      "grad_norm": 2.0806784629821777,
      "learning_rate": 1.5855015177442185e-05,
      "loss": 0.0309,
      "step": 1310
    },
    {
      "epoch": 1.9138359569179784,
      "grad_norm": 2.325289011001587,
      "learning_rate": 1.5834281536566756e-05,
      "loss": 0.0578,
      "step": 1320
    },
    {
      "epoch": 1.9283347141673572,
      "grad_norm": 3.0945141315460205,
      "learning_rate": 1.5813547895691323e-05,
      "loss": 0.0396,
      "step": 1330
    },
    {
      "epoch": 1.9428334714167357,
      "grad_norm": 5.680812358856201,
      "learning_rate": 1.5792814254815894e-05,
      "loss": 0.0402,
      "step": 1340
    },
    {
      "epoch": 1.9573322286661143,
      "grad_norm": 4.246526718139648,
      "learning_rate": 1.577208061394046e-05,
      "loss": 0.0413,
      "step": 1350
    },
    {
      "epoch": 1.971830985915493,
      "grad_norm": 0.016419142484664917,
      "learning_rate": 1.575134697306503e-05,
      "loss": 0.0303,
      "step": 1360
    },
    {
      "epoch": 1.9863297431648714,
      "grad_norm": 0.14186935126781464,
      "learning_rate": 1.57306133321896e-05,
      "loss": 0.0512,
      "step": 1370
    },
    {
      "epoch": 1.9993786246893124,
      "eval_accuracy": 0.9870647969052224,
      "eval_f1": 0.927457627118644,
      "eval_loss": 0.036860547959804535,
      "eval_precision": 0.95,
      "eval_recall": 0.9059602649006623,
      "eval_runtime": 2057.0628,
      "eval_samples_per_second": 4.024,
      "eval_steps_per_second": 0.503,
      "step": 1379
    },
    {
      "epoch": 1.9993786246893124,
      "eval_accuracy": 0.9870647969052224,
      "eval_f1": 0.927457627118644,
      "eval_loss": 0.036860547959804535,
      "eval_precision": 0.95,
      "eval_recall": 0.9059602649006623,
      "eval_runtime": 20513.0565,
      "eval_samples_per_second": 0.403,
      "eval_steps_per_second": 0.05,
      "step": 1379
    },
    {
      "epoch": 2.0008285004142503,
      "grad_norm": 2.6880311965942383,
      "learning_rate": 1.570987969131417e-05,
      "loss": 0.0718,
      "step": 1380
    },
    {
      "epoch": 2.0153272576636287,
      "grad_norm": 1.7477657794952393,
      "learning_rate": 1.5689146050438736e-05,
      "loss": 0.0463,
      "step": 1390
    },
    {
      "epoch": 2.0298260149130076,
      "grad_norm": 0.277229905128479,
      "learning_rate": 1.5668412409563307e-05,
      "loss": 0.0438,
      "step": 1400
    },
    {
      "epoch": 2.044324772162386,
      "grad_norm": 3.40995192527771,
      "learning_rate": 1.5647678768687877e-05,
      "loss": 0.0472,
      "step": 1410
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 0.846538782119751,
      "learning_rate": 1.5626945127812445e-05,
      "loss": 0.0474,
      "step": 1420
    },
    {
      "epoch": 2.0733222866611434,
      "grad_norm": 0.8599992394447327,
      "learning_rate": 1.5606211486937012e-05,
      "loss": 0.0183,
      "step": 1430
    },
    {
      "epoch": 2.087821043910522,
      "grad_norm": 3.381720542907715,
      "learning_rate": 1.5585477846061582e-05,
      "loss": 0.0259,
      "step": 1440
    },
    {
      "epoch": 2.1023198011599007,
      "grad_norm": 1.3885557651519775,
      "learning_rate": 1.556474420518615e-05,
      "loss": 0.0111,
      "step": 1450
    },
    {
      "epoch": 2.116818558409279,
      "grad_norm": 0.10850489884614944,
      "learning_rate": 1.554401056431072e-05,
      "loss": 0.0156,
      "step": 1460
    },
    {
      "epoch": 2.131317315658658,
      "grad_norm": 2.8644299507141113,
      "learning_rate": 1.5523276923435287e-05,
      "loss": 0.0466,
      "step": 1470
    },
    {
      "epoch": 2.1458160729080364,
      "grad_norm": 1.4885841608047485,
      "learning_rate": 1.5502543282559858e-05,
      "loss": 0.0228,
      "step": 1480
    },
    {
      "epoch": 2.160314830157415,
      "grad_norm": 4.5224127769470215,
      "learning_rate": 1.5481809641684425e-05,
      "loss": 0.0327,
      "step": 1490
    },
    {
      "epoch": 2.1748135874067938,
      "grad_norm": 0.1868310421705246,
      "learning_rate": 1.5461076000808996e-05,
      "loss": 0.0285,
      "step": 1500
    },
    {
      "epoch": 2.189312344656172,
      "grad_norm": 5.313519477844238,
      "learning_rate": 1.5440342359933563e-05,
      "loss": 0.0545,
      "step": 1510
    },
    {
      "epoch": 2.203811101905551,
      "grad_norm": 4.572500228881836,
      "learning_rate": 1.5419608719058133e-05,
      "loss": 0.0365,
      "step": 1520
    },
    {
      "epoch": 2.2183098591549295,
      "grad_norm": 2.9534318447113037,
      "learning_rate": 1.53988750781827e-05,
      "loss": 0.0486,
      "step": 1530
    },
    {
      "epoch": 2.2328086164043084,
      "grad_norm": 1.1885111331939697,
      "learning_rate": 1.537814143730727e-05,
      "loss": 0.0288,
      "step": 1540
    },
    {
      "epoch": 2.247307373653687,
      "grad_norm": 0.15821486711502075,
      "learning_rate": 1.535740779643184e-05,
      "loss": 0.033,
      "step": 1550
    },
    {
      "epoch": 2.2618061309030653,
      "grad_norm": 0.717381477355957,
      "learning_rate": 1.533667415555641e-05,
      "loss": 0.0197,
      "step": 1560
    },
    {
      "epoch": 2.276304888152444,
      "grad_norm": 2.6250522136688232,
      "learning_rate": 1.5315940514680976e-05,
      "loss": 0.0461,
      "step": 1570
    },
    {
      "epoch": 2.2908036454018226,
      "grad_norm": 2.429804563522339,
      "learning_rate": 1.5295206873805546e-05,
      "loss": 0.0195,
      "step": 1580
    },
    {
      "epoch": 2.3053024026512015,
      "grad_norm": 1.3457165956497192,
      "learning_rate": 1.5274473232930114e-05,
      "loss": 0.0153,
      "step": 1590
    },
    {
      "epoch": 2.31980115990058,
      "grad_norm": 1.686786413192749,
      "learning_rate": 1.5253739592054683e-05,
      "loss": 0.0236,
      "step": 1600
    },
    {
      "epoch": 2.3342999171499583,
      "grad_norm": 0.06253515183925629,
      "learning_rate": 1.5233005951179251e-05,
      "loss": 0.0218,
      "step": 1610
    },
    {
      "epoch": 2.348798674399337,
      "grad_norm": 0.9514955878257751,
      "learning_rate": 1.521227231030382e-05,
      "loss": 0.0496,
      "step": 1620
    },
    {
      "epoch": 2.3632974316487156,
      "grad_norm": 4.697098255157471,
      "learning_rate": 1.5191538669428391e-05,
      "loss": 0.0216,
      "step": 1630
    },
    {
      "epoch": 2.3777961888980945,
      "grad_norm": 2.472446918487549,
      "learning_rate": 1.517080502855296e-05,
      "loss": 0.0184,
      "step": 1640
    },
    {
      "epoch": 2.392294946147473,
      "grad_norm": 1.4150371551513672,
      "learning_rate": 1.5150071387677529e-05,
      "loss": 0.0277,
      "step": 1650
    },
    {
      "epoch": 2.406793703396852,
      "grad_norm": 4.9338555335998535,
      "learning_rate": 1.5129337746802097e-05,
      "loss": 0.0244,
      "step": 1660
    },
    {
      "epoch": 2.4212924606462303,
      "grad_norm": 1.0549191236495972,
      "learning_rate": 1.5108604105926666e-05,
      "loss": 0.0063,
      "step": 1670
    },
    {
      "epoch": 2.435791217895609,
      "grad_norm": 0.3128446340560913,
      "learning_rate": 1.5087870465051235e-05,
      "loss": 0.0182,
      "step": 1680
    },
    {
      "epoch": 2.4502899751449876,
      "grad_norm": 1.675346851348877,
      "learning_rate": 1.5067136824175804e-05,
      "loss": 0.0214,
      "step": 1690
    },
    {
      "epoch": 2.464788732394366,
      "grad_norm": 0.007118268869817257,
      "learning_rate": 1.5046403183300373e-05,
      "loss": 0.0157,
      "step": 1700
    },
    {
      "epoch": 2.479287489643745,
      "grad_norm": 2.3714869022369385,
      "learning_rate": 1.502566954242494e-05,
      "loss": 0.0444,
      "step": 1710
    },
    {
      "epoch": 2.4937862468931233,
      "grad_norm": 4.7653303146362305,
      "learning_rate": 1.5004935901549509e-05,
      "loss": 0.027,
      "step": 1720
    },
    {
      "epoch": 2.508285004142502,
      "grad_norm": 1.331956386566162,
      "learning_rate": 1.4984202260674078e-05,
      "loss": 0.0259,
      "step": 1730
    },
    {
      "epoch": 2.5227837613918807,
      "grad_norm": 0.1340002566576004,
      "learning_rate": 1.4963468619798647e-05,
      "loss": 0.0331,
      "step": 1740
    },
    {
      "epoch": 2.537282518641259,
      "grad_norm": 0.06684716045856476,
      "learning_rate": 1.4942734978923216e-05,
      "loss": 0.0151,
      "step": 1750
    },
    {
      "epoch": 2.551781275890638,
      "grad_norm": 0.9619008302688599,
      "learning_rate": 1.4922001338047785e-05,
      "loss": 0.0477,
      "step": 1760
    },
    {
      "epoch": 2.566280033140017,
      "grad_norm": 2.933582305908203,
      "learning_rate": 1.4901267697172353e-05,
      "loss": 0.0403,
      "step": 1770
    },
    {
      "epoch": 2.5807787903893953,
      "grad_norm": 0.2649928033351898,
      "learning_rate": 1.4880534056296924e-05,
      "loss": 0.0065,
      "step": 1780
    },
    {
      "epoch": 2.5952775476387737,
      "grad_norm": 1.0276490449905396,
      "learning_rate": 1.4859800415421493e-05,
      "loss": 0.025,
      "step": 1790
    },
    {
      "epoch": 2.6097763048881526,
      "grad_norm": 8.969606399536133,
      "learning_rate": 1.4839066774546062e-05,
      "loss": 0.0309,
      "step": 1800
    },
    {
      "epoch": 2.624275062137531,
      "grad_norm": 0.4296351969242096,
      "learning_rate": 1.481833313367063e-05,
      "loss": 0.0139,
      "step": 1810
    },
    {
      "epoch": 2.63877381938691,
      "grad_norm": 2.8421146869659424,
      "learning_rate": 1.47975994927952e-05,
      "loss": 0.036,
      "step": 1820
    },
    {
      "epoch": 2.6532725766362883,
      "grad_norm": 0.03019394539296627,
      "learning_rate": 1.4776865851919768e-05,
      "loss": 0.018,
      "step": 1830
    },
    {
      "epoch": 2.667771333885667,
      "grad_norm": 0.025458402931690216,
      "learning_rate": 1.4756132211044337e-05,
      "loss": 0.017,
      "step": 1840
    },
    {
      "epoch": 2.6822700911350457,
      "grad_norm": 0.8846240639686584,
      "learning_rate": 1.4735398570168904e-05,
      "loss": 0.0198,
      "step": 1850
    },
    {
      "epoch": 2.696768848384424,
      "grad_norm": 3.5438129901885986,
      "learning_rate": 1.4714664929293473e-05,
      "loss": 0.02,
      "step": 1860
    },
    {
      "epoch": 2.711267605633803,
      "grad_norm": 2.004743814468384,
      "learning_rate": 1.4693931288418042e-05,
      "loss": 0.0332,
      "step": 1870
    },
    {
      "epoch": 2.7257663628831814,
      "grad_norm": 2.3850858211517334,
      "learning_rate": 1.4673197647542611e-05,
      "loss": 0.0137,
      "step": 1880
    },
    {
      "epoch": 2.74026512013256,
      "grad_norm": 3.587242364883423,
      "learning_rate": 1.465246400666718e-05,
      "loss": 0.0419,
      "step": 1890
    },
    {
      "epoch": 2.7547638773819387,
      "grad_norm": 0.013484690338373184,
      "learning_rate": 1.4631730365791749e-05,
      "loss": 0.0093,
      "step": 1900
    },
    {
      "epoch": 2.769262634631317,
      "grad_norm": 0.01497478224337101,
      "learning_rate": 1.4610996724916318e-05,
      "loss": 0.0191,
      "step": 1910
    },
    {
      "epoch": 2.783761391880696,
      "grad_norm": 2.5898072719573975,
      "learning_rate": 1.4590263084040888e-05,
      "loss": 0.0501,
      "step": 1920
    },
    {
      "epoch": 2.7982601491300745,
      "grad_norm": 0.9446876645088196,
      "learning_rate": 1.4569529443165457e-05,
      "loss": 0.0274,
      "step": 1930
    },
    {
      "epoch": 2.812758906379453,
      "grad_norm": 4.6166229248046875,
      "learning_rate": 1.4548795802290026e-05,
      "loss": 0.0456,
      "step": 1940
    },
    {
      "epoch": 2.827257663628832,
      "grad_norm": 2.287616729736328,
      "learning_rate": 1.4528062161414595e-05,
      "loss": 0.0235,
      "step": 1950
    },
    {
      "epoch": 2.8417564208782107,
      "grad_norm": 3.7980716228485107,
      "learning_rate": 1.4507328520539164e-05,
      "loss": 0.0523,
      "step": 1960
    },
    {
      "epoch": 2.856255178127589,
      "grad_norm": 2.8325788974761963,
      "learning_rate": 1.4486594879663733e-05,
      "loss": 0.0349,
      "step": 1970
    },
    {
      "epoch": 2.8707539353769675,
      "grad_norm": 4.673666000366211,
      "learning_rate": 1.4465861238788301e-05,
      "loss": 0.0314,
      "step": 1980
    },
    {
      "epoch": 2.8852526926263464,
      "grad_norm": 0.7553388476371765,
      "learning_rate": 1.4445127597912869e-05,
      "loss": 0.0198,
      "step": 1990
    },
    {
      "epoch": 2.899751449875725,
      "grad_norm": 1.5939552783966064,
      "learning_rate": 1.4424393957037437e-05,
      "loss": 0.044,
      "step": 2000
    },
    {
      "epoch": 2.9142502071251037,
      "grad_norm": 4.273496150970459,
      "learning_rate": 1.4403660316162006e-05,
      "loss": 0.0404,
      "step": 2010
    },
    {
      "epoch": 2.928748964374482,
      "grad_norm": 0.13221266865730286,
      "learning_rate": 1.4382926675286575e-05,
      "loss": 0.0122,
      "step": 2020
    },
    {
      "epoch": 2.9432477216238606,
      "grad_norm": 2.2574548721313477,
      "learning_rate": 1.4362193034411144e-05,
      "loss": 0.0468,
      "step": 2030
    },
    {
      "epoch": 2.9577464788732395,
      "grad_norm": 4.309885501861572,
      "learning_rate": 1.4341459393535713e-05,
      "loss": 0.0246,
      "step": 2040
    },
    {
      "epoch": 2.972245236122618,
      "grad_norm": 0.6903380155563354,
      "learning_rate": 1.4320725752660282e-05,
      "loss": 0.0368,
      "step": 2050
    },
    {
      "epoch": 2.986743993371997,
      "grad_norm": 0.8687577843666077,
      "learning_rate": 1.4299992111784852e-05,
      "loss": 0.0237,
      "step": 2060
    },
    {
      "epoch": 2.9997928748964373,
      "eval_accuracy": 0.9873065764023211,
      "eval_f1": 0.9269311064718164,
      "eval_loss": 0.04956039786338806,
      "eval_precision": 0.9765395894428153,
      "eval_recall": 0.8821192052980132,
      "eval_runtime": 2158.7321,
      "eval_samples_per_second": 3.834,
      "eval_steps_per_second": 0.479,
      "step": 2069
    },
    {
      "epoch": 2.9997928748964373,
      "eval_accuracy": 0.9873065764023211,
      "eval_f1": 0.9269311064718164,
      "eval_loss": 0.04956039786338806,
      "eval_precision": 0.9765395894428153,
      "eval_recall": 0.8821192052980132,
      "eval_runtime": 2097.7248,
      "eval_samples_per_second": 3.946,
      "eval_steps_per_second": 0.493,
      "step": 2069
    },
    {
      "epoch": 3.0012427506213752,
      "grad_norm": 1.6420966386795044,
      "learning_rate": 1.4279258470909421e-05,
      "loss": 0.0191,
      "step": 2070
    },
    {
      "epoch": 3.015741507870754,
      "grad_norm": 0.3723710775375366,
      "learning_rate": 1.425852483003399e-05,
      "loss": 0.0146,
      "step": 2080
    },
    {
      "epoch": 3.0302402651201326,
      "grad_norm": 0.10428246855735779,
      "learning_rate": 1.4237791189158559e-05,
      "loss": 0.0195,
      "step": 2090
    },
    {
      "epoch": 3.044739022369511,
      "grad_norm": 2.347630500793457,
      "learning_rate": 1.4217057548283128e-05,
      "loss": 0.0192,
      "step": 2100
    },
    {
      "epoch": 3.05923777961889,
      "grad_norm": 0.8464445471763611,
      "learning_rate": 1.4196323907407697e-05,
      "loss": 0.0188,
      "step": 2110
    },
    {
      "epoch": 3.0737365368682683,
      "grad_norm": 2.985966444015503,
      "learning_rate": 1.4175590266532264e-05,
      "loss": 0.0428,
      "step": 2120
    },
    {
      "epoch": 3.088235294117647,
      "grad_norm": 0.17521628737449646,
      "learning_rate": 1.4154856625656833e-05,
      "loss": 0.0191,
      "step": 2130
    },
    {
      "epoch": 3.1027340513670256,
      "grad_norm": 0.25541847944259644,
      "learning_rate": 1.4134122984781402e-05,
      "loss": 0.0059,
      "step": 2140
    },
    {
      "epoch": 3.1172328086164045,
      "grad_norm": 8.781220436096191,
      "learning_rate": 1.411338934390597e-05,
      "loss": 0.0139,
      "step": 2150
    },
    {
      "epoch": 3.131731565865783,
      "grad_norm": 3.173257350921631,
      "learning_rate": 1.409265570303054e-05,
      "loss": 0.0129,
      "step": 2160
    },
    {
      "epoch": 3.1462303231151614,
      "grad_norm": 0.9448584914207458,
      "learning_rate": 1.4071922062155108e-05,
      "loss": 0.0468,
      "step": 2170
    },
    {
      "epoch": 3.1607290803645403,
      "grad_norm": 2.3375132083892822,
      "learning_rate": 1.4051188421279677e-05,
      "loss": 0.0125,
      "step": 2180
    },
    {
      "epoch": 3.1752278376139187,
      "grad_norm": 0.012098879553377628,
      "learning_rate": 1.4030454780404246e-05,
      "loss": 0.0143,
      "step": 2190
    },
    {
      "epoch": 3.1897265948632976,
      "grad_norm": 1.3881072998046875,
      "learning_rate": 1.4009721139528817e-05,
      "loss": 0.0153,
      "step": 2200
    },
    {
      "epoch": 3.204225352112676,
      "grad_norm": 0.01997373066842556,
      "learning_rate": 1.3988987498653386e-05,
      "loss": 0.0078,
      "step": 2210
    },
    {
      "epoch": 3.218724109362055,
      "grad_norm": 0.026329468935728073,
      "learning_rate": 1.3968253857777954e-05,
      "loss": 0.0053,
      "step": 2220
    },
    {
      "epoch": 3.2332228666114333,
      "grad_norm": 1.5937713384628296,
      "learning_rate": 1.3947520216902523e-05,
      "loss": 0.0089,
      "step": 2230
    },
    {
      "epoch": 3.2477216238608118,
      "grad_norm": 2.5313658714294434,
      "learning_rate": 1.3926786576027092e-05,
      "loss": 0.0266,
      "step": 2240
    },
    {
      "epoch": 3.2622203811101906,
      "grad_norm": 0.1620536893606186,
      "learning_rate": 1.3906052935151661e-05,
      "loss": 0.0173,
      "step": 2250
    },
    {
      "epoch": 3.276719138359569,
      "grad_norm": 8.031825065612793,
      "learning_rate": 1.3885319294276228e-05,
      "loss": 0.0472,
      "step": 2260
    },
    {
      "epoch": 3.291217895608948,
      "grad_norm": 0.022169815376400948,
      "learning_rate": 1.3864585653400797e-05,
      "loss": 0.0193,
      "step": 2270
    },
    {
      "epoch": 3.3057166528583264,
      "grad_norm": 0.12418951094150543,
      "learning_rate": 1.3843852012525366e-05,
      "loss": 0.0124,
      "step": 2280
    },
    {
      "epoch": 3.3202154101077053,
      "grad_norm": 0.8984944820404053,
      "learning_rate": 1.3823118371649935e-05,
      "loss": 0.0215,
      "step": 2290
    },
    {
      "epoch": 3.3347141673570837,
      "grad_norm": 3.1240286827087402,
      "learning_rate": 1.3802384730774504e-05,
      "loss": 0.0368,
      "step": 2300
    },
    {
      "epoch": 3.349212924606462,
      "grad_norm": 0.05362389236688614,
      "learning_rate": 1.3781651089899073e-05,
      "loss": 0.0264,
      "step": 2310
    },
    {
      "epoch": 3.363711681855841,
      "grad_norm": 0.06681555509567261,
      "learning_rate": 1.3760917449023641e-05,
      "loss": 0.0256,
      "step": 2320
    },
    {
      "epoch": 3.3782104391052195,
      "grad_norm": 2.2142081260681152,
      "learning_rate": 1.374018380814821e-05,
      "loss": 0.0224,
      "step": 2330
    },
    {
      "epoch": 3.3927091963545983,
      "grad_norm": 2.9914464950561523,
      "learning_rate": 1.371945016727278e-05,
      "loss": 0.0187,
      "step": 2340
    },
    {
      "epoch": 3.4072079536039768,
      "grad_norm": 2.1589229106903076,
      "learning_rate": 1.369871652639735e-05,
      "loss": 0.0197,
      "step": 2350
    },
    {
      "epoch": 3.421706710853355,
      "grad_norm": 0.3620103597640991,
      "learning_rate": 1.3677982885521919e-05,
      "loss": 0.0132,
      "step": 2360
    },
    {
      "epoch": 3.436205468102734,
      "grad_norm": 2.9663052558898926,
      "learning_rate": 1.3657249244646488e-05,
      "loss": 0.0146,
      "step": 2370
    },
    {
      "epoch": 3.4507042253521125,
      "grad_norm": 1.4225839376449585,
      "learning_rate": 1.3636515603771056e-05,
      "loss": 0.007,
      "step": 2380
    },
    {
      "epoch": 3.4652029826014914,
      "grad_norm": 2.160740852355957,
      "learning_rate": 1.3615781962895625e-05,
      "loss": 0.0161,
      "step": 2390
    },
    {
      "epoch": 3.47970173985087,
      "grad_norm": 2.520129919052124,
      "learning_rate": 1.3595048322020192e-05,
      "loss": 0.0184,
      "step": 2400
    },
    {
      "epoch": 3.4942004971002487,
      "grad_norm": 1.8260630369186401,
      "learning_rate": 1.3574314681144761e-05,
      "loss": 0.02,
      "step": 2410
    },
    {
      "epoch": 3.508699254349627,
      "grad_norm": 0.0028112977743148804,
      "learning_rate": 1.355358104026933e-05,
      "loss": 0.0316,
      "step": 2420
    },
    {
      "epoch": 3.523198011599006,
      "grad_norm": 0.031316813081502914,
      "learning_rate": 1.3532847399393899e-05,
      "loss": 0.0388,
      "step": 2430
    },
    {
      "epoch": 3.5376967688483845,
      "grad_norm": 2.9571354389190674,
      "learning_rate": 1.3512113758518468e-05,
      "loss": 0.0164,
      "step": 2440
    },
    {
      "epoch": 3.552195526097763,
      "grad_norm": 0.026019025593996048,
      "learning_rate": 1.3491380117643037e-05,
      "loss": 0.0157,
      "step": 2450
    },
    {
      "epoch": 3.566694283347142,
      "grad_norm": 0.984574019908905,
      "learning_rate": 1.3470646476767606e-05,
      "loss": 0.0152,
      "step": 2460
    },
    {
      "epoch": 3.58119304059652,
      "grad_norm": 0.20114563405513763,
      "learning_rate": 1.3449912835892175e-05,
      "loss": 0.0235,
      "step": 2470
    },
    {
      "epoch": 3.595691797845899,
      "grad_norm": 1.7693830728530884,
      "learning_rate": 1.3429179195016743e-05,
      "loss": 0.0181,
      "step": 2480
    },
    {
      "epoch": 3.6101905550952775,
      "grad_norm": 0.06838877499103546,
      "learning_rate": 1.3408445554141314e-05,
      "loss": 0.0081,
      "step": 2490
    },
    {
      "epoch": 3.624689312344656,
      "grad_norm": 1.9170200824737549,
      "learning_rate": 1.3387711913265883e-05,
      "loss": 0.011,
      "step": 2500
    },
    {
      "epoch": 3.639188069594035,
      "grad_norm": 0.021147044375538826,
      "learning_rate": 1.3366978272390452e-05,
      "loss": 0.0114,
      "step": 2510
    },
    {
      "epoch": 3.6536868268434133,
      "grad_norm": 1.821062445640564,
      "learning_rate": 1.334624463151502e-05,
      "loss": 0.0102,
      "step": 2520
    },
    {
      "epoch": 3.668185584092792,
      "grad_norm": 3.062936305999756,
      "learning_rate": 1.332551099063959e-05,
      "loss": 0.0189,
      "step": 2530
    },
    {
      "epoch": 3.6826843413421706,
      "grad_norm": 0.10919187217950821,
      "learning_rate": 1.3304777349764157e-05,
      "loss": 0.0033,
      "step": 2540
    },
    {
      "epoch": 3.697183098591549,
      "grad_norm": 2.6873602867126465,
      "learning_rate": 1.3284043708888726e-05,
      "loss": 0.0102,
      "step": 2550
    },
    {
      "epoch": 3.711681855840928,
      "grad_norm": 0.45652228593826294,
      "learning_rate": 1.3263310068013294e-05,
      "loss": 0.0082,
      "step": 2560
    },
    {
      "epoch": 3.726180613090307,
      "grad_norm": 0.26617375016212463,
      "learning_rate": 1.3242576427137863e-05,
      "loss": 0.0184,
      "step": 2570
    },
    {
      "epoch": 3.7406793703396852,
      "grad_norm": 3.5360584259033203,
      "learning_rate": 1.3221842786262432e-05,
      "loss": 0.0329,
      "step": 2580
    },
    {
      "epoch": 3.7551781275890637,
      "grad_norm": 0.07542659342288971,
      "learning_rate": 1.3201109145387001e-05,
      "loss": 0.0395,
      "step": 2590
    },
    {
      "epoch": 3.7696768848384425,
      "grad_norm": 3.0072107315063477,
      "learning_rate": 1.318037550451157e-05,
      "loss": 0.0354,
      "step": 2600
    },
    {
      "epoch": 3.784175642087821,
      "grad_norm": 0.23353977501392365,
      "learning_rate": 1.3159641863636139e-05,
      "loss": 0.0196,
      "step": 2610
    },
    {
      "epoch": 3.7986743993372,
      "grad_norm": 5.8333868980407715,
      "learning_rate": 1.3138908222760708e-05,
      "loss": 0.027,
      "step": 2620
    },
    {
      "epoch": 3.8131731565865783,
      "grad_norm": 2.940530776977539,
      "learning_rate": 1.3118174581885278e-05,
      "loss": 0.0143,
      "step": 2630
    },
    {
      "epoch": 3.8276719138359567,
      "grad_norm": 3.0021488666534424,
      "learning_rate": 1.3097440941009847e-05,
      "loss": 0.0346,
      "step": 2640
    },
    {
      "epoch": 3.8421706710853356,
      "grad_norm": 0.29180216789245605,
      "learning_rate": 1.3076707300134416e-05,
      "loss": 0.0249,
      "step": 2650
    },
    {
      "epoch": 3.856669428334714,
      "grad_norm": 0.4372410774230957,
      "learning_rate": 1.3055973659258985e-05,
      "loss": 0.0153,
      "step": 2660
    },
    {
      "epoch": 3.871168185584093,
      "grad_norm": 0.2864433228969574,
      "learning_rate": 1.3035240018383552e-05,
      "loss": 0.0247,
      "step": 2670
    },
    {
      "epoch": 3.8856669428334714,
      "grad_norm": 0.2887369990348816,
      "learning_rate": 1.3014506377508121e-05,
      "loss": 0.007,
      "step": 2680
    },
    {
      "epoch": 3.90016570008285,
      "grad_norm": 0.010808522813022137,
      "learning_rate": 1.299377273663269e-05,
      "loss": 0.0133,
      "step": 2690
    },
    {
      "epoch": 3.9146644573322287,
      "grad_norm": 13.627447128295898,
      "learning_rate": 1.2973039095757259e-05,
      "loss": 0.0148,
      "step": 2700
    },
    {
      "epoch": 3.9291632145816076,
      "grad_norm": 3.990154981613159,
      "learning_rate": 1.2952305454881828e-05,
      "loss": 0.0588,
      "step": 2710
    },
    {
      "epoch": 3.943661971830986,
      "grad_norm": 0.02453073486685753,
      "learning_rate": 1.2931571814006396e-05,
      "loss": 0.0427,
      "step": 2720
    },
    {
      "epoch": 3.9581607290803644,
      "grad_norm": 4.213497638702393,
      "learning_rate": 1.2910838173130965e-05,
      "loss": 0.0235,
      "step": 2730
    },
    {
      "epoch": 3.9726594863297433,
      "grad_norm": 16.815706253051758,
      "learning_rate": 1.2890104532255534e-05,
      "loss": 0.0259,
      "step": 2740
    },
    {
      "epoch": 3.9871582435791217,
      "grad_norm": 0.09956655651330948,
      "learning_rate": 1.2869370891380103e-05,
      "loss": 0.032,
      "step": 2750
    },
    {
      "epoch": 3.9987572493786248,
      "eval_accuracy": 0.9900870406189555,
      "eval_f1": 0.9456233421750663,
      "eval_loss": 0.03233662620186806,
      "eval_precision": 0.9468791500664011,
      "eval_recall": 0.9443708609271523,
      "eval_runtime": 2102.4175,
      "eval_samples_per_second": 3.937,
      "eval_steps_per_second": 0.492,
      "step": 2758
    },
    {
      "epoch": 3.9987572493786248,
      "eval_accuracy": 0.9900870406189555,
      "eval_f1": 0.9456233421750663,
      "eval_loss": 0.03233662620186806,
      "eval_precision": 0.9468791500664011,
      "eval_recall": 0.9443708609271523,
      "eval_runtime": 2154.8892,
      "eval_samples_per_second": 3.841,
      "eval_steps_per_second": 0.48,
      "step": 2758
    },
    {
      "epoch": 4.001657000828501,
      "grad_norm": 0.030534490942955017,
      "learning_rate": 1.2848637250504672e-05,
      "loss": 0.0097,
      "step": 2760
    },
    {
      "epoch": 4.016155758077879,
      "grad_norm": 4.879022121429443,
      "learning_rate": 1.2827903609629242e-05,
      "loss": 0.0141,
      "step": 2770
    },
    {
      "epoch": 4.0306545153272575,
      "grad_norm": 0.17371653020381927,
      "learning_rate": 1.2807169968753811e-05,
      "loss": 0.0076,
      "step": 2780
    },
    {
      "epoch": 4.045153272576636,
      "grad_norm": 0.02644982747733593,
      "learning_rate": 1.278643632787838e-05,
      "loss": 0.0179,
      "step": 2790
    },
    {
      "epoch": 4.059652029826015,
      "grad_norm": 0.16573867201805115,
      "learning_rate": 1.2765702687002949e-05,
      "loss": 0.0094,
      "step": 2800
    },
    {
      "epoch": 4.074150787075394,
      "grad_norm": 0.1014711931347847,
      "learning_rate": 1.2744969046127516e-05,
      "loss": 0.0065,
      "step": 2810
    },
    {
      "epoch": 4.088649544324772,
      "grad_norm": 1.1479171514511108,
      "learning_rate": 1.2724235405252085e-05,
      "loss": 0.0092,
      "step": 2820
    },
    {
      "epoch": 4.103148301574151,
      "grad_norm": 3.112368106842041,
      "learning_rate": 1.2703501764376654e-05,
      "loss": 0.052,
      "step": 2830
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.14699076116085052,
      "learning_rate": 1.2682768123501223e-05,
      "loss": 0.0113,
      "step": 2840
    },
    {
      "epoch": 4.132145816072908,
      "grad_norm": 0.05196807160973549,
      "learning_rate": 1.2662034482625792e-05,
      "loss": 0.0228,
      "step": 2850
    },
    {
      "epoch": 4.146644573322287,
      "grad_norm": 1.6561217308044434,
      "learning_rate": 1.264130084175036e-05,
      "loss": 0.0075,
      "step": 2860
    },
    {
      "epoch": 4.161143330571665,
      "grad_norm": 2.182673215866089,
      "learning_rate": 1.262056720087493e-05,
      "loss": 0.0299,
      "step": 2870
    },
    {
      "epoch": 4.175642087821044,
      "grad_norm": 0.7480728626251221,
      "learning_rate": 1.2599833559999498e-05,
      "loss": 0.0095,
      "step": 2880
    },
    {
      "epoch": 4.190140845070423,
      "grad_norm": 0.43670836091041565,
      "learning_rate": 1.2579099919124067e-05,
      "loss": 0.0184,
      "step": 2890
    },
    {
      "epoch": 4.204639602319801,
      "grad_norm": 1.7043423652648926,
      "learning_rate": 1.2558366278248636e-05,
      "loss": 0.0193,
      "step": 2900
    },
    {
      "epoch": 4.21913835956918,
      "grad_norm": 0.0477241650223732,
      "learning_rate": 1.2537632637373205e-05,
      "loss": 0.01,
      "step": 2910
    },
    {
      "epoch": 4.233637116818558,
      "grad_norm": 2.784156322479248,
      "learning_rate": 1.2516898996497776e-05,
      "loss": 0.0207,
      "step": 2920
    },
    {
      "epoch": 4.248135874067937,
      "grad_norm": 0.025114107877016068,
      "learning_rate": 1.2496165355622344e-05,
      "loss": 0.0047,
      "step": 2930
    },
    {
      "epoch": 4.262634631317316,
      "grad_norm": 0.6736134886741638,
      "learning_rate": 1.2475431714746913e-05,
      "loss": 0.0196,
      "step": 2940
    },
    {
      "epoch": 4.2771333885666944,
      "grad_norm": 0.1690286546945572,
      "learning_rate": 1.245469807387148e-05,
      "loss": 0.0349,
      "step": 2950
    },
    {
      "epoch": 4.291632145816073,
      "grad_norm": 0.0939195454120636,
      "learning_rate": 1.243396443299605e-05,
      "loss": 0.0245,
      "step": 2960
    },
    {
      "epoch": 4.306130903065451,
      "grad_norm": 0.6238277554512024,
      "learning_rate": 1.2413230792120618e-05,
      "loss": 0.0273,
      "step": 2970
    },
    {
      "epoch": 4.32062966031483,
      "grad_norm": 0.013086263090372086,
      "learning_rate": 1.2392497151245187e-05,
      "loss": 0.0027,
      "step": 2980
    },
    {
      "epoch": 4.335128417564209,
      "grad_norm": 1.336377739906311,
      "learning_rate": 1.2371763510369756e-05,
      "loss": 0.0034,
      "step": 2990
    },
    {
      "epoch": 4.3496271748135875,
      "grad_norm": 3.661085605621338,
      "learning_rate": 1.2351029869494325e-05,
      "loss": 0.0461,
      "step": 3000
    },
    {
      "epoch": 4.364125932062966,
      "grad_norm": 0.03054264932870865,
      "learning_rate": 1.2330296228618894e-05,
      "loss": 0.0161,
      "step": 3010
    },
    {
      "epoch": 4.378624689312344,
      "grad_norm": 2.411428689956665,
      "learning_rate": 1.2309562587743463e-05,
      "loss": 0.0305,
      "step": 3020
    },
    {
      "epoch": 4.393123446561724,
      "grad_norm": 0.03912799805402756,
      "learning_rate": 1.2288828946868031e-05,
      "loss": 0.015,
      "step": 3030
    },
    {
      "epoch": 4.407622203811102,
      "grad_norm": 0.010453133843839169,
      "learning_rate": 1.22680953059926e-05,
      "loss": 0.0216,
      "step": 3040
    },
    {
      "epoch": 4.422120961060481,
      "grad_norm": 0.03934149816632271,
      "learning_rate": 1.224736166511717e-05,
      "loss": 0.0134,
      "step": 3050
    },
    {
      "epoch": 4.436619718309859,
      "grad_norm": 0.05482399836182594,
      "learning_rate": 1.222662802424174e-05,
      "loss": 0.0049,
      "step": 3060
    },
    {
      "epoch": 4.4511184755592375,
      "grad_norm": 1.7382715940475464,
      "learning_rate": 1.2205894383366309e-05,
      "loss": 0.0203,
      "step": 3070
    },
    {
      "epoch": 4.465617232808617,
      "grad_norm": 29.0975284576416,
      "learning_rate": 1.2185160742490878e-05,
      "loss": 0.0356,
      "step": 3080
    },
    {
      "epoch": 4.480115990057995,
      "grad_norm": 0.023502347990870476,
      "learning_rate": 1.2164427101615445e-05,
      "loss": 0.0207,
      "step": 3090
    },
    {
      "epoch": 4.494614747307374,
      "grad_norm": 0.0072969840839505196,
      "learning_rate": 1.2143693460740014e-05,
      "loss": 0.0063,
      "step": 3100
    },
    {
      "epoch": 4.509113504556752,
      "grad_norm": 0.6570004224777222,
      "learning_rate": 1.2122959819864582e-05,
      "loss": 0.0141,
      "step": 3110
    },
    {
      "epoch": 4.5236122618061305,
      "grad_norm": 1.1634507179260254,
      "learning_rate": 1.2102226178989151e-05,
      "loss": 0.0088,
      "step": 3120
    },
    {
      "epoch": 4.53811101905551,
      "grad_norm": 3.0945661067962646,
      "learning_rate": 1.208149253811372e-05,
      "loss": 0.0154,
      "step": 3130
    },
    {
      "epoch": 4.552609776304888,
      "grad_norm": 0.04832316190004349,
      "learning_rate": 1.2060758897238289e-05,
      "loss": 0.0031,
      "step": 3140
    },
    {
      "epoch": 4.567108533554267,
      "grad_norm": 8.478264808654785,
      "learning_rate": 1.2040025256362858e-05,
      "loss": 0.0216,
      "step": 3150
    },
    {
      "epoch": 4.581607290803645,
      "grad_norm": 0.009060868062078953,
      "learning_rate": 1.2019291615487427e-05,
      "loss": 0.0167,
      "step": 3160
    },
    {
      "epoch": 4.596106048053024,
      "grad_norm": 0.024042971432209015,
      "learning_rate": 1.1998557974611996e-05,
      "loss": 0.0254,
      "step": 3170
    },
    {
      "epoch": 4.610604805302403,
      "grad_norm": 0.1863245666027069,
      "learning_rate": 1.1977824333736565e-05,
      "loss": 0.0116,
      "step": 3180
    },
    {
      "epoch": 4.625103562551781,
      "grad_norm": 0.006328973453491926,
      "learning_rate": 1.1957090692861133e-05,
      "loss": 0.0265,
      "step": 3190
    },
    {
      "epoch": 4.63960231980116,
      "grad_norm": 2.363079071044922,
      "learning_rate": 1.1936357051985704e-05,
      "loss": 0.0133,
      "step": 3200
    },
    {
      "epoch": 4.654101077050538,
      "grad_norm": 5.727721691131592,
      "learning_rate": 1.1915623411110273e-05,
      "loss": 0.0193,
      "step": 3210
    },
    {
      "epoch": 4.668599834299917,
      "grad_norm": 0.07871025800704956,
      "learning_rate": 1.189488977023484e-05,
      "loss": 0.005,
      "step": 3220
    },
    {
      "epoch": 4.683098591549296,
      "grad_norm": 2.80326247215271,
      "learning_rate": 1.1874156129359409e-05,
      "loss": 0.0377,
      "step": 3230
    },
    {
      "epoch": 4.697597348798674,
      "grad_norm": 0.011283572763204575,
      "learning_rate": 1.1853422488483978e-05,
      "loss": 0.0282,
      "step": 3240
    },
    {
      "epoch": 4.712096106048053,
      "grad_norm": 3.2324414253234863,
      "learning_rate": 1.1832688847608547e-05,
      "loss": 0.0128,
      "step": 3250
    },
    {
      "epoch": 4.726594863297431,
      "grad_norm": 0.8829429745674133,
      "learning_rate": 1.1811955206733116e-05,
      "loss": 0.0185,
      "step": 3260
    },
    {
      "epoch": 4.741093620546811,
      "grad_norm": 0.09359803050756454,
      "learning_rate": 1.1791221565857684e-05,
      "loss": 0.0318,
      "step": 3270
    },
    {
      "epoch": 4.755592377796189,
      "grad_norm": 0.024056479334831238,
      "learning_rate": 1.1770487924982253e-05,
      "loss": 0.0107,
      "step": 3280
    },
    {
      "epoch": 4.7700911350455675,
      "grad_norm": 0.10867394506931305,
      "learning_rate": 1.1749754284106822e-05,
      "loss": 0.0011,
      "step": 3290
    },
    {
      "epoch": 4.784589892294946,
      "grad_norm": 4.708465576171875,
      "learning_rate": 1.1729020643231391e-05,
      "loss": 0.0151,
      "step": 3300
    },
    {
      "epoch": 4.799088649544325,
      "grad_norm": 0.06701666861772537,
      "learning_rate": 1.170828700235596e-05,
      "loss": 0.04,
      "step": 3310
    },
    {
      "epoch": 4.813587406793704,
      "grad_norm": 0.48106443881988525,
      "learning_rate": 1.1687553361480529e-05,
      "loss": 0.0145,
      "step": 3320
    },
    {
      "epoch": 4.828086164043082,
      "grad_norm": 0.6846518516540527,
      "learning_rate": 1.1666819720605098e-05,
      "loss": 0.0362,
      "step": 3330
    },
    {
      "epoch": 4.8425849212924605,
      "grad_norm": 8.058666229248047,
      "learning_rate": 1.1646086079729667e-05,
      "loss": 0.0155,
      "step": 3340
    },
    {
      "epoch": 4.857083678541839,
      "grad_norm": 0.09429396688938141,
      "learning_rate": 1.1625352438854237e-05,
      "loss": 0.0158,
      "step": 3350
    },
    {
      "epoch": 4.871582435791218,
      "grad_norm": 2.049013614654541,
      "learning_rate": 1.1604618797978803e-05,
      "loss": 0.012,
      "step": 3360
    },
    {
      "epoch": 4.886081193040597,
      "grad_norm": 0.0430513359606266,
      "learning_rate": 1.1583885157103373e-05,
      "loss": 0.0184,
      "step": 3370
    },
    {
      "epoch": 4.900579950289975,
      "grad_norm": 0.004063846077769995,
      "learning_rate": 1.1563151516227942e-05,
      "loss": 0.0054,
      "step": 3380
    },
    {
      "epoch": 4.915078707539354,
      "grad_norm": 0.2665650248527527,
      "learning_rate": 1.1542417875352511e-05,
      "loss": 0.0073,
      "step": 3390
    },
    {
      "epoch": 4.929577464788732,
      "grad_norm": 0.010652896948158741,
      "learning_rate": 1.152168423447708e-05,
      "loss": 0.0244,
      "step": 3400
    },
    {
      "epoch": 4.944076222038111,
      "grad_norm": 0.009094024077057838,
      "learning_rate": 1.1500950593601649e-05,
      "loss": 0.0112,
      "step": 3410
    },
    {
      "epoch": 4.95857497928749,
      "grad_norm": 4.186131954193115,
      "learning_rate": 1.1480216952726218e-05,
      "loss": 0.0323,
      "step": 3420
    },
    {
      "epoch": 4.973073736536868,
      "grad_norm": 0.012897558510303497,
      "learning_rate": 1.1459483311850786e-05,
      "loss": 0.0161,
      "step": 3430
    },
    {
      "epoch": 4.987572493786247,
      "grad_norm": 0.02249608375132084,
      "learning_rate": 1.1438749670975355e-05,
      "loss": 0.0042,
      "step": 3440
    },
    {
      "epoch": 4.99917149958575,
      "eval_accuracy": 0.9911750483558994,
      "eval_f1": 0.9512358049432199,
      "eval_loss": 0.03106945939362049,
      "eval_precision": 0.9595687331536388,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 2173.964,
      "eval_samples_per_second": 3.807,
      "eval_steps_per_second": 0.476,
      "step": 3448
    },
    {
      "epoch": 4.99917149958575,
      "eval_accuracy": 0.9911750483558994,
      "eval_f1": 0.9512358049432199,
      "eval_loss": 0.03106945939362049,
      "eval_precision": 0.9595687331536388,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 2246.3225,
      "eval_samples_per_second": 3.685,
      "eval_steps_per_second": 0.461,
      "step": 3448
    },
    {
      "epoch": 5.002071251035625,
      "grad_norm": 0.45443102717399597,
      "learning_rate": 1.1418016030099924e-05,
      "loss": 0.0131,
      "step": 3450
    },
    {
      "epoch": 5.016570008285004,
      "grad_norm": 0.013331394642591476,
      "learning_rate": 1.1397282389224493e-05,
      "loss": 0.0078,
      "step": 3460
    },
    {
      "epoch": 5.031068765534383,
      "grad_norm": 0.0017850600415840745,
      "learning_rate": 1.1376548748349062e-05,
      "loss": 0.0011,
      "step": 3470
    },
    {
      "epoch": 5.045567522783761,
      "grad_norm": 0.4682575464248657,
      "learning_rate": 1.135581510747363e-05,
      "loss": 0.0068,
      "step": 3480
    },
    {
      "epoch": 5.06006628003314,
      "grad_norm": 1.448607325553894,
      "learning_rate": 1.1335081466598201e-05,
      "loss": 0.0134,
      "step": 3490
    },
    {
      "epoch": 5.074565037282519,
      "grad_norm": 0.020280325785279274,
      "learning_rate": 1.1314347825722767e-05,
      "loss": 0.0092,
      "step": 3500
    },
    {
      "epoch": 5.0890637945318975,
      "grad_norm": 3.5467331409454346,
      "learning_rate": 1.1293614184847337e-05,
      "loss": 0.0261,
      "step": 3510
    },
    {
      "epoch": 5.103562551781276,
      "grad_norm": 1.2155624628067017,
      "learning_rate": 1.1272880543971906e-05,
      "loss": 0.0145,
      "step": 3520
    },
    {
      "epoch": 5.118061309030654,
      "grad_norm": 5.056617259979248,
      "learning_rate": 1.1252146903096475e-05,
      "loss": 0.0221,
      "step": 3530
    },
    {
      "epoch": 5.132560066280033,
      "grad_norm": 1.1913317441940308,
      "learning_rate": 1.1231413262221044e-05,
      "loss": 0.0018,
      "step": 3540
    },
    {
      "epoch": 5.147058823529412,
      "grad_norm": 0.037619054317474365,
      "learning_rate": 1.1210679621345613e-05,
      "loss": 0.0037,
      "step": 3550
    },
    {
      "epoch": 5.161557580778791,
      "grad_norm": 0.004968259483575821,
      "learning_rate": 1.1189945980470182e-05,
      "loss": 0.0185,
      "step": 3560
    },
    {
      "epoch": 5.176056338028169,
      "grad_norm": 3.3099000453948975,
      "learning_rate": 1.116921233959475e-05,
      "loss": 0.0079,
      "step": 3570
    },
    {
      "epoch": 5.190555095277547,
      "grad_norm": 0.13842295110225677,
      "learning_rate": 1.114847869871932e-05,
      "loss": 0.0137,
      "step": 3580
    },
    {
      "epoch": 5.205053852526926,
      "grad_norm": 0.0051938374526798725,
      "learning_rate": 1.1127745057843888e-05,
      "loss": 0.008,
      "step": 3590
    },
    {
      "epoch": 5.219552609776305,
      "grad_norm": 0.036170970648527145,
      "learning_rate": 1.1107011416968457e-05,
      "loss": 0.0139,
      "step": 3600
    },
    {
      "epoch": 5.234051367025684,
      "grad_norm": 2.859503984451294,
      "learning_rate": 1.1086277776093026e-05,
      "loss": 0.0225,
      "step": 3610
    },
    {
      "epoch": 5.248550124275062,
      "grad_norm": 0.2796086370944977,
      "learning_rate": 1.1065544135217595e-05,
      "loss": 0.0259,
      "step": 3620
    },
    {
      "epoch": 5.2630488815244405,
      "grad_norm": 0.13521626591682434,
      "learning_rate": 1.1044810494342166e-05,
      "loss": 0.0027,
      "step": 3630
    },
    {
      "epoch": 5.27754763877382,
      "grad_norm": 0.006800067611038685,
      "learning_rate": 1.1024076853466731e-05,
      "loss": 0.0088,
      "step": 3640
    },
    {
      "epoch": 5.292046396023198,
      "grad_norm": 0.027142208069562912,
      "learning_rate": 1.1003343212591302e-05,
      "loss": 0.0077,
      "step": 3650
    },
    {
      "epoch": 5.306545153272577,
      "grad_norm": 7.122773170471191,
      "learning_rate": 1.098260957171587e-05,
      "loss": 0.017,
      "step": 3660
    },
    {
      "epoch": 5.321043910521955,
      "grad_norm": 0.25144392251968384,
      "learning_rate": 1.096187593084044e-05,
      "loss": 0.0088,
      "step": 3670
    },
    {
      "epoch": 5.335542667771334,
      "grad_norm": 0.4688328206539154,
      "learning_rate": 1.0941142289965008e-05,
      "loss": 0.014,
      "step": 3680
    },
    {
      "epoch": 5.350041425020713,
      "grad_norm": 0.21203012764453888,
      "learning_rate": 1.0920408649089577e-05,
      "loss": 0.0069,
      "step": 3690
    },
    {
      "epoch": 5.364540182270091,
      "grad_norm": 0.24014100432395935,
      "learning_rate": 1.0899675008214146e-05,
      "loss": 0.0071,
      "step": 3700
    },
    {
      "epoch": 5.37903893951947,
      "grad_norm": 0.04612216353416443,
      "learning_rate": 1.0878941367338715e-05,
      "loss": 0.0082,
      "step": 3710
    },
    {
      "epoch": 5.393537696768848,
      "grad_norm": 2.47196626663208,
      "learning_rate": 1.0858207726463284e-05,
      "loss": 0.0124,
      "step": 3720
    },
    {
      "epoch": 5.408036454018227,
      "grad_norm": 0.04661817103624344,
      "learning_rate": 1.0837474085587853e-05,
      "loss": 0.0115,
      "step": 3730
    },
    {
      "epoch": 5.422535211267606,
      "grad_norm": 0.01956878788769245,
      "learning_rate": 1.0816740444712422e-05,
      "loss": 0.0229,
      "step": 3740
    },
    {
      "epoch": 5.437033968516984,
      "grad_norm": 0.027816615998744965,
      "learning_rate": 1.079600680383699e-05,
      "loss": 0.0053,
      "step": 3750
    },
    {
      "epoch": 5.451532725766363,
      "grad_norm": 1.839033603668213,
      "learning_rate": 1.077527316296156e-05,
      "loss": 0.009,
      "step": 3760
    },
    {
      "epoch": 5.466031483015741,
      "grad_norm": 1.3591948747634888,
      "learning_rate": 1.0754539522086126e-05,
      "loss": 0.0034,
      "step": 3770
    },
    {
      "epoch": 5.48053024026512,
      "grad_norm": 0.1283128559589386,
      "learning_rate": 1.0733805881210695e-05,
      "loss": 0.0062,
      "step": 3780
    },
    {
      "epoch": 5.495028997514499,
      "grad_norm": 2.642512321472168,
      "learning_rate": 1.0713072240335264e-05,
      "loss": 0.0203,
      "step": 3790
    },
    {
      "epoch": 5.5095277547638775,
      "grad_norm": 0.0603906475007534,
      "learning_rate": 1.0692338599459835e-05,
      "loss": 0.0221,
      "step": 3800
    },
    {
      "epoch": 5.524026512013256,
      "grad_norm": 0.008607356809079647,
      "learning_rate": 1.0671604958584404e-05,
      "loss": 0.0137,
      "step": 3810
    },
    {
      "epoch": 5.538525269262634,
      "grad_norm": 0.11695773899555206,
      "learning_rate": 1.0650871317708972e-05,
      "loss": 0.0081,
      "step": 3820
    },
    {
      "epoch": 5.553024026512013,
      "grad_norm": 0.025145746767520905,
      "learning_rate": 1.0630137676833541e-05,
      "loss": 0.0055,
      "step": 3830
    },
    {
      "epoch": 5.567522783761392,
      "grad_norm": 0.020614109933376312,
      "learning_rate": 1.060940403595811e-05,
      "loss": 0.0128,
      "step": 3840
    },
    {
      "epoch": 5.5820215410107705,
      "grad_norm": 2.1722164154052734,
      "learning_rate": 1.0588670395082679e-05,
      "loss": 0.0136,
      "step": 3850
    },
    {
      "epoch": 5.596520298260149,
      "grad_norm": 0.3705105483531952,
      "learning_rate": 1.0567936754207248e-05,
      "loss": 0.0312,
      "step": 3860
    },
    {
      "epoch": 5.611019055509527,
      "grad_norm": 0.16705864667892456,
      "learning_rate": 1.0547203113331817e-05,
      "loss": 0.0082,
      "step": 3870
    },
    {
      "epoch": 5.625517812758907,
      "grad_norm": 0.02649041824042797,
      "learning_rate": 1.0526469472456386e-05,
      "loss": 0.0101,
      "step": 3880
    },
    {
      "epoch": 5.640016570008285,
      "grad_norm": 0.7814837098121643,
      "learning_rate": 1.0505735831580955e-05,
      "loss": 0.0038,
      "step": 3890
    },
    {
      "epoch": 5.654515327257664,
      "grad_norm": 0.028479628264904022,
      "learning_rate": 1.0485002190705523e-05,
      "loss": 0.0065,
      "step": 3900
    },
    {
      "epoch": 5.669014084507042,
      "grad_norm": 0.0031919146422296762,
      "learning_rate": 1.046426854983009e-05,
      "loss": 0.0055,
      "step": 3910
    },
    {
      "epoch": 5.683512841756421,
      "grad_norm": 2.022343158721924,
      "learning_rate": 1.044353490895466e-05,
      "loss": 0.01,
      "step": 3920
    },
    {
      "epoch": 5.6980115990058,
      "grad_norm": 0.013648031279444695,
      "learning_rate": 1.0422801268079228e-05,
      "loss": 0.0073,
      "step": 3930
    },
    {
      "epoch": 5.712510356255178,
      "grad_norm": 0.04986318200826645,
      "learning_rate": 1.0402067627203799e-05,
      "loss": 0.0018,
      "step": 3940
    },
    {
      "epoch": 5.727009113504557,
      "grad_norm": 6.488920211791992,
      "learning_rate": 1.0381333986328368e-05,
      "loss": 0.0219,
      "step": 3950
    },
    {
      "epoch": 5.741507870753935,
      "grad_norm": 0.3120214343070984,
      "learning_rate": 1.0360600345452937e-05,
      "loss": 0.0018,
      "step": 3960
    },
    {
      "epoch": 5.756006628003314,
      "grad_norm": 3.571272373199463,
      "learning_rate": 1.0339866704577506e-05,
      "loss": 0.0336,
      "step": 3970
    },
    {
      "epoch": 5.770505385252693,
      "grad_norm": 3.5838027000427246,
      "learning_rate": 1.0319133063702074e-05,
      "loss": 0.0189,
      "step": 3980
    },
    {
      "epoch": 5.785004142502071,
      "grad_norm": 0.00529538793489337,
      "learning_rate": 1.0298399422826643e-05,
      "loss": 0.0225,
      "step": 3990
    },
    {
      "epoch": 5.79950289975145,
      "grad_norm": 2.9921882152557373,
      "learning_rate": 1.0277665781951212e-05,
      "loss": 0.0086,
      "step": 4000
    },
    {
      "epoch": 5.814001657000828,
      "grad_norm": 0.004143610130995512,
      "learning_rate": 1.0256932141075781e-05,
      "loss": 0.0126,
      "step": 4010
    },
    {
      "epoch": 5.8285004142502075,
      "grad_norm": 2.834857225418091,
      "learning_rate": 1.023619850020035e-05,
      "loss": 0.0403,
      "step": 4020
    },
    {
      "epoch": 5.842999171499586,
      "grad_norm": 1.571929693222046,
      "learning_rate": 1.0215464859324919e-05,
      "loss": 0.0317,
      "step": 4030
    },
    {
      "epoch": 5.857497928748964,
      "grad_norm": 0.1885879933834076,
      "learning_rate": 1.0194731218449488e-05,
      "loss": 0.0159,
      "step": 4040
    },
    {
      "epoch": 5.871996685998343,
      "grad_norm": 2.62555193901062,
      "learning_rate": 1.0173997577574055e-05,
      "loss": 0.0172,
      "step": 4050
    },
    {
      "epoch": 5.886495443247721,
      "grad_norm": 4.382898807525635,
      "learning_rate": 1.0153263936698624e-05,
      "loss": 0.0213,
      "step": 4060
    },
    {
      "epoch": 5.9009942004971006,
      "grad_norm": 0.028451478108763695,
      "learning_rate": 1.0132530295823193e-05,
      "loss": 0.0064,
      "step": 4070
    },
    {
      "epoch": 5.915492957746479,
      "grad_norm": 4.573553562164307,
      "learning_rate": 1.0111796654947763e-05,
      "loss": 0.0146,
      "step": 4080
    },
    {
      "epoch": 5.929991714995857,
      "grad_norm": 2.0626730918884277,
      "learning_rate": 1.0091063014072332e-05,
      "loss": 0.0095,
      "step": 4090
    },
    {
      "epoch": 5.944490472245236,
      "grad_norm": 11.491506576538086,
      "learning_rate": 1.0070329373196901e-05,
      "loss": 0.0135,
      "step": 4100
    },
    {
      "epoch": 5.958989229494614,
      "grad_norm": 2.3935248851776123,
      "learning_rate": 1.004959573232147e-05,
      "loss": 0.0073,
      "step": 4110
    },
    {
      "epoch": 5.973487986743994,
      "grad_norm": 2.5194363594055176,
      "learning_rate": 1.0028862091446039e-05,
      "loss": 0.0097,
      "step": 4120
    },
    {
      "epoch": 5.987986743993372,
      "grad_norm": 0.01471933163702488,
      "learning_rate": 1.0008128450570608e-05,
      "loss": 0.0096,
      "step": 4130
    },
    {
      "epoch": 5.999585749792875,
      "eval_accuracy": 0.9914168278529981,
      "eval_f1": 0.9521885521885521,
      "eval_loss": 0.032097622752189636,
      "eval_precision": 0.9684931506849315,
      "eval_recall": 0.9364238410596026,
      "eval_runtime": 2104.831,
      "eval_samples_per_second": 3.932,
      "eval_steps_per_second": 0.492,
      "step": 4138
    },
    {
      "epoch": 5.999585749792875,
      "eval_accuracy": 0.9914168278529981,
      "eval_f1": 0.9521885521885521,
      "eval_loss": 0.032097622752189636,
      "eval_precision": 0.9684931506849315,
      "eval_recall": 0.9364238410596026,
      "eval_runtime": 2098.8121,
      "eval_samples_per_second": 3.944,
      "eval_steps_per_second": 0.493,
      "step": 4138
    },
    {
      "epoch": 6.0024855012427505,
      "grad_norm": 0.016434654593467712,
      "learning_rate": 9.987394809695176e-06,
      "loss": 0.017,
      "step": 4140
    },
    {
      "epoch": 6.016984258492129,
      "grad_norm": 2.3776564598083496,
      "learning_rate": 9.966661168819745e-06,
      "loss": 0.006,
      "step": 4150
    },
    {
      "epoch": 6.031483015741508,
      "grad_norm": 0.513137698173523,
      "learning_rate": 9.945927527944314e-06,
      "loss": 0.0129,
      "step": 4160
    },
    {
      "epoch": 6.045981772990887,
      "grad_norm": 0.02400558441877365,
      "learning_rate": 9.925193887068883e-06,
      "loss": 0.0101,
      "step": 4170
    },
    {
      "epoch": 6.060480530240265,
      "grad_norm": 0.5910676717758179,
      "learning_rate": 9.904460246193452e-06,
      "loss": 0.008,
      "step": 4180
    },
    {
      "epoch": 6.0749792874896436,
      "grad_norm": 0.015840405598282814,
      "learning_rate": 9.883726605318019e-06,
      "loss": 0.0007,
      "step": 4190
    },
    {
      "epoch": 6.089478044739022,
      "grad_norm": 0.11698627471923828,
      "learning_rate": 9.862992964442588e-06,
      "loss": 0.0163,
      "step": 4200
    },
    {
      "epoch": 6.103976801988401,
      "grad_norm": 0.002537303837016225,
      "learning_rate": 9.842259323567157e-06,
      "loss": 0.0064,
      "step": 4210
    },
    {
      "epoch": 6.11847555923778,
      "grad_norm": 0.2925353944301605,
      "learning_rate": 9.821525682691727e-06,
      "loss": 0.015,
      "step": 4220
    },
    {
      "epoch": 6.132974316487158,
      "grad_norm": 0.2675149142742157,
      "learning_rate": 9.800792041816296e-06,
      "loss": 0.0036,
      "step": 4230
    },
    {
      "epoch": 6.147473073736537,
      "grad_norm": 0.044411901384592056,
      "learning_rate": 9.780058400940865e-06,
      "loss": 0.0055,
      "step": 4240
    },
    {
      "epoch": 6.161971830985916,
      "grad_norm": 0.009000562131404877,
      "learning_rate": 9.759324760065434e-06,
      "loss": 0.0225,
      "step": 4250
    },
    {
      "epoch": 6.176470588235294,
      "grad_norm": 0.003166387788951397,
      "learning_rate": 9.738591119190003e-06,
      "loss": 0.0029,
      "step": 4260
    },
    {
      "epoch": 6.190969345484673,
      "grad_norm": 0.0031244996935129166,
      "learning_rate": 9.717857478314572e-06,
      "loss": 0.0137,
      "step": 4270
    },
    {
      "epoch": 6.205468102734051,
      "grad_norm": 0.014714660122990608,
      "learning_rate": 9.69712383743914e-06,
      "loss": 0.0004,
      "step": 4280
    },
    {
      "epoch": 6.21996685998343,
      "grad_norm": 0.765095591545105,
      "learning_rate": 9.67639019656371e-06,
      "loss": 0.0139,
      "step": 4290
    },
    {
      "epoch": 6.234465617232809,
      "grad_norm": 0.06345774978399277,
      "learning_rate": 9.655656555688278e-06,
      "loss": 0.0027,
      "step": 4300
    },
    {
      "epoch": 6.2489643744821874,
      "grad_norm": 0.000893089862074703,
      "learning_rate": 9.634922914812847e-06,
      "loss": 0.0051,
      "step": 4310
    },
    {
      "epoch": 6.263463131731566,
      "grad_norm": 0.5791464447975159,
      "learning_rate": 9.614189273937414e-06,
      "loss": 0.0148,
      "step": 4320
    },
    {
      "epoch": 6.277961888980944,
      "grad_norm": 0.0686216875910759,
      "learning_rate": 9.593455633061983e-06,
      "loss": 0.0012,
      "step": 4330
    },
    {
      "epoch": 6.292460646230323,
      "grad_norm": 0.5575367212295532,
      "learning_rate": 9.572721992186552e-06,
      "loss": 0.0023,
      "step": 4340
    },
    {
      "epoch": 6.306959403479702,
      "grad_norm": 0.07125157862901688,
      "learning_rate": 9.551988351311121e-06,
      "loss": 0.0114,
      "step": 4350
    },
    {
      "epoch": 6.3214581607290805,
      "grad_norm": 2.9468886852264404,
      "learning_rate": 9.53125471043569e-06,
      "loss": 0.0196,
      "step": 4360
    },
    {
      "epoch": 6.335956917978459,
      "grad_norm": 0.9796721339225769,
      "learning_rate": 9.51052106956026e-06,
      "loss": 0.0193,
      "step": 4370
    },
    {
      "epoch": 6.350455675227837,
      "grad_norm": 3.626511812210083,
      "learning_rate": 9.48978742868483e-06,
      "loss": 0.0392,
      "step": 4380
    },
    {
      "epoch": 6.364954432477216,
      "grad_norm": 0.11081629246473312,
      "learning_rate": 9.469053787809398e-06,
      "loss": 0.0078,
      "step": 4390
    },
    {
      "epoch": 6.379453189726595,
      "grad_norm": 2.4787392616271973,
      "learning_rate": 9.448320146933967e-06,
      "loss": 0.0184,
      "step": 4400
    },
    {
      "epoch": 6.393951946975974,
      "grad_norm": 0.6693715453147888,
      "learning_rate": 9.427586506058536e-06,
      "loss": 0.0045,
      "step": 4410
    },
    {
      "epoch": 6.408450704225352,
      "grad_norm": 0.22953389585018158,
      "learning_rate": 9.406852865183105e-06,
      "loss": 0.0128,
      "step": 4420
    },
    {
      "epoch": 6.4229494614747304,
      "grad_norm": 0.3857884109020233,
      "learning_rate": 9.386119224307674e-06,
      "loss": 0.0111,
      "step": 4430
    },
    {
      "epoch": 6.43744821872411,
      "grad_norm": 5.279794692993164,
      "learning_rate": 9.365385583432243e-06,
      "loss": 0.0089,
      "step": 4440
    },
    {
      "epoch": 6.451946975973488,
      "grad_norm": 0.00862500723451376,
      "learning_rate": 9.344651942556812e-06,
      "loss": 0.0169,
      "step": 4450
    },
    {
      "epoch": 6.466445733222867,
      "grad_norm": 0.1761210709810257,
      "learning_rate": 9.323918301681379e-06,
      "loss": 0.0111,
      "step": 4460
    },
    {
      "epoch": 6.480944490472245,
      "grad_norm": 0.1689077913761139,
      "learning_rate": 9.303184660805948e-06,
      "loss": 0.0122,
      "step": 4470
    },
    {
      "epoch": 6.4954432477216235,
      "grad_norm": 0.35220637917518616,
      "learning_rate": 9.282451019930516e-06,
      "loss": 0.0049,
      "step": 4480
    },
    {
      "epoch": 6.509942004971003,
      "grad_norm": 1.156807541847229,
      "learning_rate": 9.261717379055085e-06,
      "loss": 0.0168,
      "step": 4490
    },
    {
      "epoch": 6.524440762220381,
      "grad_norm": 0.45724064111709595,
      "learning_rate": 9.240983738179654e-06,
      "loss": 0.0124,
      "step": 4500
    },
    {
      "epoch": 6.53893951946976,
      "grad_norm": 0.0018757377984002233,
      "learning_rate": 9.220250097304225e-06,
      "loss": 0.0275,
      "step": 4510
    },
    {
      "epoch": 6.553438276719138,
      "grad_norm": 0.6786627769470215,
      "learning_rate": 9.199516456428794e-06,
      "loss": 0.0009,
      "step": 4520
    },
    {
      "epoch": 6.5679370339685175,
      "grad_norm": 0.01360301859676838,
      "learning_rate": 9.178782815553363e-06,
      "loss": 0.0036,
      "step": 4530
    },
    {
      "epoch": 6.582435791217896,
      "grad_norm": 0.01879473775625229,
      "learning_rate": 9.158049174677931e-06,
      "loss": 0.008,
      "step": 4540
    },
    {
      "epoch": 6.596934548467274,
      "grad_norm": 0.647760272026062,
      "learning_rate": 9.1373155338025e-06,
      "loss": 0.0216,
      "step": 4550
    },
    {
      "epoch": 6.611433305716653,
      "grad_norm": 0.00416005402803421,
      "learning_rate": 9.116581892927069e-06,
      "loss": 0.015,
      "step": 4560
    },
    {
      "epoch": 6.625932062966031,
      "grad_norm": 0.07829552888870239,
      "learning_rate": 9.095848252051638e-06,
      "loss": 0.0096,
      "step": 4570
    },
    {
      "epoch": 6.6404308202154105,
      "grad_norm": 1.986182689666748,
      "learning_rate": 9.075114611176207e-06,
      "loss": 0.017,
      "step": 4580
    },
    {
      "epoch": 6.654929577464789,
      "grad_norm": 0.31067514419555664,
      "learning_rate": 9.054380970300776e-06,
      "loss": 0.0049,
      "step": 4590
    },
    {
      "epoch": 6.669428334714167,
      "grad_norm": 0.5062239766120911,
      "learning_rate": 9.033647329425343e-06,
      "loss": 0.0178,
      "step": 4600
    },
    {
      "epoch": 6.683927091963546,
      "grad_norm": 0.015952862799167633,
      "learning_rate": 9.012913688549914e-06,
      "loss": 0.006,
      "step": 4610
    },
    {
      "epoch": 6.698425849212924,
      "grad_norm": 0.009341544471681118,
      "learning_rate": 8.992180047674482e-06,
      "loss": 0.0103,
      "step": 4620
    },
    {
      "epoch": 6.712924606462304,
      "grad_norm": 0.37960126996040344,
      "learning_rate": 8.97144640679905e-06,
      "loss": 0.0019,
      "step": 4630
    },
    {
      "epoch": 6.727423363711682,
      "grad_norm": 2.698158025741577,
      "learning_rate": 8.950712765923618e-06,
      "loss": 0.0233,
      "step": 4640
    },
    {
      "epoch": 6.7419221209610605,
      "grad_norm": 0.02273477241396904,
      "learning_rate": 8.929979125048189e-06,
      "loss": 0.0163,
      "step": 4650
    },
    {
      "epoch": 6.756420878210439,
      "grad_norm": 0.007208334747701883,
      "learning_rate": 8.909245484172758e-06,
      "loss": 0.0098,
      "step": 4660
    },
    {
      "epoch": 6.770919635459817,
      "grad_norm": 3.1260082721710205,
      "learning_rate": 8.888511843297327e-06,
      "loss": 0.0204,
      "step": 4670
    },
    {
      "epoch": 6.785418392709197,
      "grad_norm": 0.4471770226955414,
      "learning_rate": 8.867778202421896e-06,
      "loss": 0.0121,
      "step": 4680
    },
    {
      "epoch": 6.799917149958575,
      "grad_norm": 3.553318738937378,
      "learning_rate": 8.847044561546465e-06,
      "loss": 0.0392,
      "step": 4690
    },
    {
      "epoch": 6.8144159072079535,
      "grad_norm": 0.7847631573677063,
      "learning_rate": 8.826310920671032e-06,
      "loss": 0.01,
      "step": 4700
    },
    {
      "epoch": 6.828914664457332,
      "grad_norm": 0.9922741651535034,
      "learning_rate": 8.8055772797956e-06,
      "loss": 0.0185,
      "step": 4710
    },
    {
      "epoch": 6.84341342170671,
      "grad_norm": 0.338530957698822,
      "learning_rate": 8.784843638920171e-06,
      "loss": 0.0122,
      "step": 4720
    },
    {
      "epoch": 6.85791217895609,
      "grad_norm": 0.05907706543803215,
      "learning_rate": 8.76410999804474e-06,
      "loss": 0.0082,
      "step": 4730
    },
    {
      "epoch": 6.872410936205468,
      "grad_norm": 2.142761468887329,
      "learning_rate": 8.743376357169309e-06,
      "loss": 0.0029,
      "step": 4740
    },
    {
      "epoch": 6.886909693454847,
      "grad_norm": 0.0039280373603105545,
      "learning_rate": 8.722642716293878e-06,
      "loss": 0.0022,
      "step": 4750
    },
    {
      "epoch": 6.901408450704225,
      "grad_norm": 0.0073056211695075035,
      "learning_rate": 8.701909075418447e-06,
      "loss": 0.0064,
      "step": 4760
    },
    {
      "epoch": 6.915907207953604,
      "grad_norm": 0.011225378140807152,
      "learning_rate": 8.681175434543014e-06,
      "loss": 0.0036,
      "step": 4770
    },
    {
      "epoch": 6.930405965202983,
      "grad_norm": 0.07824917137622833,
      "learning_rate": 8.660441793667583e-06,
      "loss": 0.0064,
      "step": 4780
    },
    {
      "epoch": 6.944904722452361,
      "grad_norm": 0.00489416578784585,
      "learning_rate": 8.639708152792152e-06,
      "loss": 0.0225,
      "step": 4790
    },
    {
      "epoch": 6.95940347970174,
      "grad_norm": 0.01056930422782898,
      "learning_rate": 8.618974511916722e-06,
      "loss": 0.0186,
      "step": 4800
    },
    {
      "epoch": 6.973902236951118,
      "grad_norm": 0.017957715317606926,
      "learning_rate": 8.598240871041291e-06,
      "loss": 0.0108,
      "step": 4810
    },
    {
      "epoch": 6.988400994200497,
      "grad_norm": 0.015453930012881756,
      "learning_rate": 8.57750723016586e-06,
      "loss": 0.0048,
      "step": 4820
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9928675048355899,
      "eval_f1": 0.9602157788267026,
      "eval_loss": 0.028449714183807373,
      "eval_precision": 0.978021978021978,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 2107.095,
      "eval_samples_per_second": 3.928,
      "eval_steps_per_second": 0.491,
      "step": 4828
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9928675048355899,
      "eval_f1": 0.9602157788267026,
      "eval_loss": 0.028449714183807373,
      "eval_precision": 0.978021978021978,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 2136.4107,
      "eval_samples_per_second": 3.874,
      "eval_steps_per_second": 0.484,
      "step": 4828
    }
  ],
  "logging_steps": 10,
  "max_steps": 8957,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 13,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 4
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.005241645148176e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": {
    "epochs": 13,
    "gradient_accumulation_steps": 7,
    "learning_rate": 1.8032047469362455e-05,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 8,
    "warmup_steps": 260,
    "weight_decay": 0.09619071683814717
  }
}
