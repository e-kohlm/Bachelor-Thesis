{
  "best_metric": 0.9621621621621622,
  "best_model_checkpoint": "../hyperparameter_search/run-9/checkpoint-3621",
  "epoch": 6.99917149958575,
  "eval_steps": 500,
  "global_step": 4224,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016570008285004142,
      "grad_norm": 60.84390640258789,
      "learning_rate": 1.1581091522177022e-07,
      "loss": 0.8737,
      "step": 1
    },
    {
      "epoch": 0.016570008285004142,
      "grad_norm": 27.21248435974121,
      "learning_rate": 1.158109152217702e-06,
      "loss": 0.8222,
      "step": 10
    },
    {
      "epoch": 0.033140016570008285,
      "grad_norm": 38.4334602355957,
      "learning_rate": 2.316218304435404e-06,
      "loss": 0.6666,
      "step": 20
    },
    {
      "epoch": 0.04971002485501243,
      "grad_norm": 15.357807159423828,
      "learning_rate": 3.474327456653106e-06,
      "loss": 0.4111,
      "step": 30
    },
    {
      "epoch": 0.06628003314001657,
      "grad_norm": 22.86359977722168,
      "learning_rate": 4.632436608870808e-06,
      "loss": 0.3156,
      "step": 40
    },
    {
      "epoch": 0.08285004142502071,
      "grad_norm": 14.171662330627441,
      "learning_rate": 5.790545761088511e-06,
      "loss": 0.3479,
      "step": 50
    },
    {
      "epoch": 0.09942004971002485,
      "grad_norm": 38.482662200927734,
      "learning_rate": 6.948654913306212e-06,
      "loss": 0.3277,
      "step": 60
    },
    {
      "epoch": 0.115990057995029,
      "grad_norm": 16.685895919799805,
      "learning_rate": 8.106764065523914e-06,
      "loss": 0.3207,
      "step": 70
    },
    {
      "epoch": 0.13256006628003314,
      "grad_norm": 15.282288551330566,
      "learning_rate": 9.264873217741616e-06,
      "loss": 0.3213,
      "step": 80
    },
    {
      "epoch": 0.1491300745650373,
      "grad_norm": 17.063589096069336,
      "learning_rate": 1.042298236995932e-05,
      "loss": 0.3005,
      "step": 90
    },
    {
      "epoch": 0.16570008285004142,
      "grad_norm": 13.945707321166992,
      "learning_rate": 1.1581091522177022e-05,
      "loss": 0.2974,
      "step": 100
    },
    {
      "epoch": 0.18227009113504558,
      "grad_norm": 8.707870483398438,
      "learning_rate": 1.2739200674394722e-05,
      "loss": 0.2916,
      "step": 110
    },
    {
      "epoch": 0.1988400994200497,
      "grad_norm": 13.89316177368164,
      "learning_rate": 1.3897309826612424e-05,
      "loss": 0.3184,
      "step": 120
    },
    {
      "epoch": 0.21541010770505387,
      "grad_norm": 10.455998420715332,
      "learning_rate": 1.5055418978830128e-05,
      "loss": 0.3207,
      "step": 130
    },
    {
      "epoch": 0.231980115990058,
      "grad_norm": 13.629228591918945,
      "learning_rate": 1.6213528131047828e-05,
      "loss": 0.2536,
      "step": 140
    },
    {
      "epoch": 0.24855012427506215,
      "grad_norm": 10.21115779876709,
      "learning_rate": 1.737163728326553e-05,
      "loss": 0.2732,
      "step": 150
    },
    {
      "epoch": 0.2651201325600663,
      "grad_norm": 15.228748321533203,
      "learning_rate": 1.8529746435483232e-05,
      "loss": 0.2414,
      "step": 160
    },
    {
      "epoch": 0.28169014084507044,
      "grad_norm": 6.447710990905762,
      "learning_rate": 1.9687855587700934e-05,
      "loss": 0.2297,
      "step": 170
    },
    {
      "epoch": 0.2982601491300746,
      "grad_norm": 11.026060104370117,
      "learning_rate": 2.084596473991864e-05,
      "loss": 0.2925,
      "step": 180
    },
    {
      "epoch": 0.3148301574150787,
      "grad_norm": 7.523696422576904,
      "learning_rate": 2.2004073892136338e-05,
      "loss": 0.218,
      "step": 190
    },
    {
      "epoch": 0.33140016570008285,
      "grad_norm": 7.587543964385986,
      "learning_rate": 2.3162183044354044e-05,
      "loss": 0.2628,
      "step": 200
    },
    {
      "epoch": 0.347970173985087,
      "grad_norm": 5.1425395011901855,
      "learning_rate": 2.4320292196571742e-05,
      "loss": 0.216,
      "step": 210
    },
    {
      "epoch": 0.36454018227009116,
      "grad_norm": 11.249942779541016,
      "learning_rate": 2.5478401348789444e-05,
      "loss": 0.2352,
      "step": 220
    },
    {
      "epoch": 0.38111019055509526,
      "grad_norm": 10.616106986999512,
      "learning_rate": 2.663651050100715e-05,
      "loss": 0.214,
      "step": 230
    },
    {
      "epoch": 0.3976801988400994,
      "grad_norm": 10.662224769592285,
      "learning_rate": 2.7794619653224848e-05,
      "loss": 0.2267,
      "step": 240
    },
    {
      "epoch": 0.4142502071251036,
      "grad_norm": 7.759096145629883,
      "learning_rate": 2.8952728805442554e-05,
      "loss": 0.2258,
      "step": 250
    },
    {
      "epoch": 0.43082021541010773,
      "grad_norm": 5.459511756896973,
      "learning_rate": 3.0110837957660256e-05,
      "loss": 0.1801,
      "step": 260
    },
    {
      "epoch": 0.44739022369511183,
      "grad_norm": 3.433666944503784,
      "learning_rate": 3.126894710987795e-05,
      "loss": 0.1957,
      "step": 270
    },
    {
      "epoch": 0.463960231980116,
      "grad_norm": 8.06937313079834,
      "learning_rate": 3.2427056262095656e-05,
      "loss": 0.1718,
      "step": 280
    },
    {
      "epoch": 0.48053024026512015,
      "grad_norm": 4.033435344696045,
      "learning_rate": 3.358516541431336e-05,
      "loss": 0.1642,
      "step": 290
    },
    {
      "epoch": 0.4971002485501243,
      "grad_norm": 9.171120643615723,
      "learning_rate": 3.474327456653106e-05,
      "loss": 0.1707,
      "step": 300
    },
    {
      "epoch": 0.5136702568351285,
      "grad_norm": 5.682998180389404,
      "learning_rate": 3.5901383718748766e-05,
      "loss": 0.1708,
      "step": 310
    },
    {
      "epoch": 0.5302402651201326,
      "grad_norm": 5.591992378234863,
      "learning_rate": 3.7059492870966464e-05,
      "loss": 0.1582,
      "step": 320
    },
    {
      "epoch": 0.5468102734051367,
      "grad_norm": 3.3182079792022705,
      "learning_rate": 3.821760202318417e-05,
      "loss": 0.161,
      "step": 330
    },
    {
      "epoch": 0.5633802816901409,
      "grad_norm": 3.6549503803253174,
      "learning_rate": 3.937571117540187e-05,
      "loss": 0.1325,
      "step": 340
    },
    {
      "epoch": 0.579950289975145,
      "grad_norm": 5.489011287689209,
      "learning_rate": 4.0533820327619574e-05,
      "loss": 0.1602,
      "step": 350
    },
    {
      "epoch": 0.5965202982601492,
      "grad_norm": 3.287860631942749,
      "learning_rate": 4.169192947983728e-05,
      "loss": 0.1757,
      "step": 360
    },
    {
      "epoch": 0.6130903065451533,
      "grad_norm": 2.7098984718322754,
      "learning_rate": 4.285003863205497e-05,
      "loss": 0.1437,
      "step": 370
    },
    {
      "epoch": 0.6296603148301574,
      "grad_norm": 2.6422369480133057,
      "learning_rate": 4.4008147784272676e-05,
      "loss": 0.1397,
      "step": 380
    },
    {
      "epoch": 0.6462303231151616,
      "grad_norm": 7.761825084686279,
      "learning_rate": 4.516625693649038e-05,
      "loss": 0.1294,
      "step": 390
    },
    {
      "epoch": 0.6628003314001657,
      "grad_norm": 3.705979585647583,
      "learning_rate": 4.632436608870809e-05,
      "loss": 0.146,
      "step": 400
    },
    {
      "epoch": 0.6793703396851698,
      "grad_norm": 2.5158724784851074,
      "learning_rate": 4.7482475240925786e-05,
      "loss": 0.1085,
      "step": 410
    },
    {
      "epoch": 0.695940347970174,
      "grad_norm": 2.9417171478271484,
      "learning_rate": 4.8640584393143484e-05,
      "loss": 0.1207,
      "step": 420
    },
    {
      "epoch": 0.7125103562551781,
      "grad_norm": 4.415793418884277,
      "learning_rate": 4.979869354536119e-05,
      "loss": 0.1145,
      "step": 430
    },
    {
      "epoch": 0.7290803645401823,
      "grad_norm": 5.844159126281738,
      "learning_rate": 5.095680269757889e-05,
      "loss": 0.1491,
      "step": 440
    },
    {
      "epoch": 0.7456503728251864,
      "grad_norm": 3.6459996700286865,
      "learning_rate": 5.2114911849796594e-05,
      "loss": 0.1666,
      "step": 450
    },
    {
      "epoch": 0.7622203811101905,
      "grad_norm": 2.316601276397705,
      "learning_rate": 5.32730210020143e-05,
      "loss": 0.1204,
      "step": 460
    },
    {
      "epoch": 0.7787903893951947,
      "grad_norm": 2.598609685897827,
      "learning_rate": 5.4431130154232e-05,
      "loss": 0.1035,
      "step": 470
    },
    {
      "epoch": 0.7953603976801988,
      "grad_norm": 1.935848593711853,
      "learning_rate": 5.5589239306449696e-05,
      "loss": 0.0973,
      "step": 480
    },
    {
      "epoch": 0.8119304059652029,
      "grad_norm": 5.334174633026123,
      "learning_rate": 5.67473484586674e-05,
      "loss": 0.1206,
      "step": 490
    },
    {
      "epoch": 0.8285004142502072,
      "grad_norm": 3.2786965370178223,
      "learning_rate": 5.66983014850644e-05,
      "loss": 0.0925,
      "step": 500
    },
    {
      "epoch": 0.8450704225352113,
      "grad_norm": 2.8034677505493164,
      "learning_rate": 5.6649254511461405e-05,
      "loss": 0.0852,
      "step": 510
    },
    {
      "epoch": 0.8616404308202155,
      "grad_norm": 1.7619348764419556,
      "learning_rate": 5.6600207537858406e-05,
      "loss": 0.1072,
      "step": 520
    },
    {
      "epoch": 0.8782104391052196,
      "grad_norm": 1.3165642023086548,
      "learning_rate": 5.6551160564255415e-05,
      "loss": 0.1178,
      "step": 530
    },
    {
      "epoch": 0.8947804473902237,
      "grad_norm": 2.071162462234497,
      "learning_rate": 5.6502113590652416e-05,
      "loss": 0.1166,
      "step": 540
    },
    {
      "epoch": 0.9113504556752279,
      "grad_norm": 3.016319990158081,
      "learning_rate": 5.6453066617049425e-05,
      "loss": 0.076,
      "step": 550
    },
    {
      "epoch": 0.927920463960232,
      "grad_norm": 1.7617177963256836,
      "learning_rate": 5.6404019643446426e-05,
      "loss": 0.0512,
      "step": 560
    },
    {
      "epoch": 0.9444904722452361,
      "grad_norm": 4.036942005157471,
      "learning_rate": 5.635497266984343e-05,
      "loss": 0.0411,
      "step": 570
    },
    {
      "epoch": 0.9610604805302403,
      "grad_norm": 5.789239883422852,
      "learning_rate": 5.630592569624043e-05,
      "loss": 0.0682,
      "step": 580
    },
    {
      "epoch": 0.9776304888152444,
      "grad_norm": 1.9331185817718506,
      "learning_rate": 5.625687872263743e-05,
      "loss": 0.1007,
      "step": 590
    },
    {
      "epoch": 0.9942004971002486,
      "grad_norm": 2.7610089778900146,
      "learning_rate": 5.620783174903443e-05,
      "loss": 0.0786,
      "step": 600
    },
    {
      "epoch": 0.9991714995857498,
      "eval_accuracy": 0.9758220502901354,
      "eval_f1": 0.8577524893314367,
      "eval_loss": 0.07305478304624557,
      "eval_precision": 0.9262672811059908,
      "eval_recall": 0.7986754966887417,
      "eval_runtime": 2032.4174,
      "eval_samples_per_second": 4.072,
      "eval_steps_per_second": 0.509,
      "step": 603
    },
    {
      "epoch": 0.9991714995857498,
      "eval_accuracy": 0.9758220502901354,
      "eval_f1": 0.8577524893314367,
      "eval_loss": 0.07305478304624557,
      "eval_precision": 0.9262672811059908,
      "eval_recall": 0.7986754966887417,
      "eval_runtime": 2028.0222,
      "eval_samples_per_second": 4.081,
      "eval_steps_per_second": 0.51,
      "step": 603
    },
    {
      "epoch": 1.0107705053852527,
      "grad_norm": 2.200120687484741,
      "learning_rate": 5.615878477543144e-05,
      "loss": 0.0609,
      "step": 610
    },
    {
      "epoch": 1.027340513670257,
      "grad_norm": 2.089219093322754,
      "learning_rate": 5.610973780182844e-05,
      "loss": 0.0609,
      "step": 620
    },
    {
      "epoch": 1.043910521955261,
      "grad_norm": 4.3231916427612305,
      "learning_rate": 5.6060690828225444e-05,
      "loss": 0.0777,
      "step": 630
    },
    {
      "epoch": 1.0604805302402651,
      "grad_norm": 4.309798717498779,
      "learning_rate": 5.6011643854622446e-05,
      "loss": 0.0531,
      "step": 640
    },
    {
      "epoch": 1.0770505385252693,
      "grad_norm": 1.777101755142212,
      "learning_rate": 5.5962596881019454e-05,
      "loss": 0.0586,
      "step": 650
    },
    {
      "epoch": 1.0936205468102733,
      "grad_norm": 1.9317810535430908,
      "learning_rate": 5.5913549907416456e-05,
      "loss": 0.0908,
      "step": 660
    },
    {
      "epoch": 1.1101905550952775,
      "grad_norm": 5.137489318847656,
      "learning_rate": 5.586450293381346e-05,
      "loss": 0.0507,
      "step": 670
    },
    {
      "epoch": 1.1267605633802817,
      "grad_norm": 2.6519925594329834,
      "learning_rate": 5.581545596021046e-05,
      "loss": 0.0826,
      "step": 680
    },
    {
      "epoch": 1.143330571665286,
      "grad_norm": 0.12729772925376892,
      "learning_rate": 5.576640898660747e-05,
      "loss": 0.0973,
      "step": 690
    },
    {
      "epoch": 1.15990057995029,
      "grad_norm": 5.153082847595215,
      "learning_rate": 5.571736201300447e-05,
      "loss": 0.0617,
      "step": 700
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 4.2281622886657715,
      "learning_rate": 5.566831503940147e-05,
      "loss": 0.0868,
      "step": 710
    },
    {
      "epoch": 1.1930405965202984,
      "grad_norm": 3.4608263969421387,
      "learning_rate": 5.561926806579847e-05,
      "loss": 0.0575,
      "step": 720
    },
    {
      "epoch": 1.2096106048053024,
      "grad_norm": 0.3531339764595032,
      "learning_rate": 5.557022109219547e-05,
      "loss": 0.1247,
      "step": 730
    },
    {
      "epoch": 1.2261806130903066,
      "grad_norm": 1.077655553817749,
      "learning_rate": 5.5521174118592475e-05,
      "loss": 0.0627,
      "step": 740
    },
    {
      "epoch": 1.2427506213753108,
      "grad_norm": 1.9437416791915894,
      "learning_rate": 5.5472127144989477e-05,
      "loss": 0.041,
      "step": 750
    },
    {
      "epoch": 1.2593206296603148,
      "grad_norm": 0.6694947481155396,
      "learning_rate": 5.5423080171386485e-05,
      "loss": 0.066,
      "step": 760
    },
    {
      "epoch": 1.275890637945319,
      "grad_norm": 2.6990652084350586,
      "learning_rate": 5.537403319778349e-05,
      "loss": 0.0524,
      "step": 770
    },
    {
      "epoch": 1.2924606462303232,
      "grad_norm": 1.840806484222412,
      "learning_rate": 5.5324986224180495e-05,
      "loss": 0.0958,
      "step": 780
    },
    {
      "epoch": 1.3090306545153272,
      "grad_norm": 1.5912439823150635,
      "learning_rate": 5.5275939250577496e-05,
      "loss": 0.0668,
      "step": 790
    },
    {
      "epoch": 1.3256006628003314,
      "grad_norm": 1.6093910932540894,
      "learning_rate": 5.52268922769745e-05,
      "loss": 0.0557,
      "step": 800
    },
    {
      "epoch": 1.3421706710853356,
      "grad_norm": 2.0911335945129395,
      "learning_rate": 5.51778453033715e-05,
      "loss": 0.0567,
      "step": 810
    },
    {
      "epoch": 1.3587406793703396,
      "grad_norm": 0.18713872134685516,
      "learning_rate": 5.51287983297685e-05,
      "loss": 0.0342,
      "step": 820
    },
    {
      "epoch": 1.3753106876553438,
      "grad_norm": 0.112970270216465,
      "learning_rate": 5.50797513561655e-05,
      "loss": 0.0659,
      "step": 830
    },
    {
      "epoch": 1.391880695940348,
      "grad_norm": 2.571321487426758,
      "learning_rate": 5.503070438256251e-05,
      "loss": 0.0601,
      "step": 840
    },
    {
      "epoch": 1.408450704225352,
      "grad_norm": 3.0230634212493896,
      "learning_rate": 5.498165740895951e-05,
      "loss": 0.0746,
      "step": 850
    },
    {
      "epoch": 1.4250207125103562,
      "grad_norm": 1.7702875137329102,
      "learning_rate": 5.493261043535652e-05,
      "loss": 0.0526,
      "step": 860
    },
    {
      "epoch": 1.4415907207953604,
      "grad_norm": 1.859412431716919,
      "learning_rate": 5.488356346175352e-05,
      "loss": 0.0443,
      "step": 870
    },
    {
      "epoch": 1.4581607290803644,
      "grad_norm": 2.1202361583709717,
      "learning_rate": 5.4834516488150524e-05,
      "loss": 0.0623,
      "step": 880
    },
    {
      "epoch": 1.4747307373653686,
      "grad_norm": 0.4034031331539154,
      "learning_rate": 5.4785469514547526e-05,
      "loss": 0.0634,
      "step": 890
    },
    {
      "epoch": 1.4913007456503728,
      "grad_norm": 1.896158218383789,
      "learning_rate": 5.473642254094453e-05,
      "loss": 0.056,
      "step": 900
    },
    {
      "epoch": 1.5078707539353768,
      "grad_norm": 1.9349545240402222,
      "learning_rate": 5.468737556734153e-05,
      "loss": 0.0947,
      "step": 910
    },
    {
      "epoch": 1.5244407622203813,
      "grad_norm": 1.4722509384155273,
      "learning_rate": 5.463832859373854e-05,
      "loss": 0.0593,
      "step": 920
    },
    {
      "epoch": 1.5410107705053853,
      "grad_norm": 3.156947374343872,
      "learning_rate": 5.458928162013554e-05,
      "loss": 0.0643,
      "step": 930
    },
    {
      "epoch": 1.5575807787903893,
      "grad_norm": 2.921780586242676,
      "learning_rate": 5.454023464653254e-05,
      "loss": 0.0231,
      "step": 940
    },
    {
      "epoch": 1.5741507870753937,
      "grad_norm": 2.141467809677124,
      "learning_rate": 5.449118767292954e-05,
      "loss": 0.046,
      "step": 950
    },
    {
      "epoch": 1.5907207953603977,
      "grad_norm": 0.6127538084983826,
      "learning_rate": 5.444214069932655e-05,
      "loss": 0.0409,
      "step": 960
    },
    {
      "epoch": 1.6072908036454017,
      "grad_norm": 2.116023063659668,
      "learning_rate": 5.439309372572355e-05,
      "loss": 0.0419,
      "step": 970
    },
    {
      "epoch": 1.623860811930406,
      "grad_norm": 1.9806021451950073,
      "learning_rate": 5.4344046752120553e-05,
      "loss": 0.032,
      "step": 980
    },
    {
      "epoch": 1.64043082021541,
      "grad_norm": 1.571659803390503,
      "learning_rate": 5.429499977851756e-05,
      "loss": 0.0379,
      "step": 990
    },
    {
      "epoch": 1.6570008285004143,
      "grad_norm": 1.8877379894256592,
      "learning_rate": 5.424595280491456e-05,
      "loss": 0.0531,
      "step": 1000
    },
    {
      "epoch": 1.6735708367854185,
      "grad_norm": 0.9972739219665527,
      "learning_rate": 5.4196905831311565e-05,
      "loss": 0.0337,
      "step": 1010
    },
    {
      "epoch": 1.6901408450704225,
      "grad_norm": 0.2956008315086365,
      "learning_rate": 5.4147858857708566e-05,
      "loss": 0.0438,
      "step": 1020
    },
    {
      "epoch": 1.7067108533554267,
      "grad_norm": 2.8223559856414795,
      "learning_rate": 5.409881188410557e-05,
      "loss": 0.0634,
      "step": 1030
    },
    {
      "epoch": 1.723280861640431,
      "grad_norm": 3.3472208976745605,
      "learning_rate": 5.404976491050257e-05,
      "loss": 0.0532,
      "step": 1040
    },
    {
      "epoch": 1.739850869925435,
      "grad_norm": 2.5668509006500244,
      "learning_rate": 5.400071793689957e-05,
      "loss": 0.0562,
      "step": 1050
    },
    {
      "epoch": 1.7564208782104391,
      "grad_norm": 0.28927314281463623,
      "learning_rate": 5.395167096329657e-05,
      "loss": 0.0257,
      "step": 1060
    },
    {
      "epoch": 1.7729908864954433,
      "grad_norm": 1.666941523551941,
      "learning_rate": 5.390262398969359e-05,
      "loss": 0.0301,
      "step": 1070
    },
    {
      "epoch": 1.7895608947804473,
      "grad_norm": 0.07054434716701508,
      "learning_rate": 5.385357701609059e-05,
      "loss": 0.0296,
      "step": 1080
    },
    {
      "epoch": 1.8061309030654515,
      "grad_norm": 2.7670300006866455,
      "learning_rate": 5.380453004248759e-05,
      "loss": 0.0277,
      "step": 1090
    },
    {
      "epoch": 1.8227009113504558,
      "grad_norm": 0.06275903433561325,
      "learning_rate": 5.375548306888459e-05,
      "loss": 0.038,
      "step": 1100
    },
    {
      "epoch": 1.8392709196354597,
      "grad_norm": 2.547581434249878,
      "learning_rate": 5.3706436095281594e-05,
      "loss": 0.0598,
      "step": 1110
    },
    {
      "epoch": 1.855840927920464,
      "grad_norm": 4.729307651519775,
      "learning_rate": 5.3657389121678596e-05,
      "loss": 0.0497,
      "step": 1120
    },
    {
      "epoch": 1.8724109362054682,
      "grad_norm": 1.589056134223938,
      "learning_rate": 5.36083421480756e-05,
      "loss": 0.0414,
      "step": 1130
    },
    {
      "epoch": 1.8889809444904722,
      "grad_norm": 0.009936653077602386,
      "learning_rate": 5.35592951744726e-05,
      "loss": 0.0138,
      "step": 1140
    },
    {
      "epoch": 1.9055509527754764,
      "grad_norm": 1.7936193943023682,
      "learning_rate": 5.351024820086961e-05,
      "loss": 0.055,
      "step": 1150
    },
    {
      "epoch": 1.9221209610604806,
      "grad_norm": 1.740314245223999,
      "learning_rate": 5.346120122726661e-05,
      "loss": 0.0347,
      "step": 1160
    },
    {
      "epoch": 1.9386909693454846,
      "grad_norm": 1.397760272026062,
      "learning_rate": 5.341215425366362e-05,
      "loss": 0.0471,
      "step": 1170
    },
    {
      "epoch": 1.9552609776304888,
      "grad_norm": 1.2536842823028564,
      "learning_rate": 5.336310728006062e-05,
      "loss": 0.0389,
      "step": 1180
    },
    {
      "epoch": 1.971830985915493,
      "grad_norm": 0.16515421867370605,
      "learning_rate": 5.331406030645762e-05,
      "loss": 0.0389,
      "step": 1190
    },
    {
      "epoch": 1.988400994200497,
      "grad_norm": 2.2627079486846924,
      "learning_rate": 5.326501333285462e-05,
      "loss": 0.029,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9881528046421664,
      "eval_f1": 0.9331514324693041,
      "eval_loss": 0.043556373566389084,
      "eval_precision": 0.9620253164556962,
      "eval_recall": 0.9059602649006623,
      "eval_runtime": 1996.9387,
      "eval_samples_per_second": 4.145,
      "eval_steps_per_second": 0.518,
      "step": 1207
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9881528046421664,
      "eval_f1": 0.9331514324693041,
      "eval_loss": 0.043556373566389084,
      "eval_precision": 0.9620253164556962,
      "eval_recall": 0.9059602649006623,
      "eval_runtime": 2028.3219,
      "eval_samples_per_second": 4.081,
      "eval_steps_per_second": 0.51,
      "step": 1207
    },
    {
      "epoch": 2.0049710024855014,
      "grad_norm": 2.5966622829437256,
      "learning_rate": 5.3215966359251624e-05,
      "loss": 0.0432,
      "step": 1210
    },
    {
      "epoch": 2.0215410107705054,
      "grad_norm": 2.185173749923706,
      "learning_rate": 5.316691938564863e-05,
      "loss": 0.0289,
      "step": 1220
    },
    {
      "epoch": 2.0381110190555094,
      "grad_norm": 2.477978467941284,
      "learning_rate": 5.3117872412045633e-05,
      "loss": 0.0391,
      "step": 1230
    },
    {
      "epoch": 2.054681027340514,
      "grad_norm": 1.6547422409057617,
      "learning_rate": 5.3068825438442635e-05,
      "loss": 0.0375,
      "step": 1240
    },
    {
      "epoch": 2.071251035625518,
      "grad_norm": 1.4506251811981201,
      "learning_rate": 5.3019778464839637e-05,
      "loss": 0.0188,
      "step": 1250
    },
    {
      "epoch": 2.087821043910522,
      "grad_norm": 1.6332886219024658,
      "learning_rate": 5.297073149123664e-05,
      "loss": 0.0288,
      "step": 1260
    },
    {
      "epoch": 2.1043910521955262,
      "grad_norm": 0.16565795242786407,
      "learning_rate": 5.292168451763364e-05,
      "loss": 0.0224,
      "step": 1270
    },
    {
      "epoch": 2.1209610604805302,
      "grad_norm": 1.2777948379516602,
      "learning_rate": 5.287263754403065e-05,
      "loss": 0.0344,
      "step": 1280
    },
    {
      "epoch": 2.1375310687655342,
      "grad_norm": 0.544096827507019,
      "learning_rate": 5.282359057042765e-05,
      "loss": 0.0287,
      "step": 1290
    },
    {
      "epoch": 2.1541010770505387,
      "grad_norm": 0.08171980082988739,
      "learning_rate": 5.277454359682466e-05,
      "loss": 0.0269,
      "step": 1300
    },
    {
      "epoch": 2.1706710853355426,
      "grad_norm": 0.8499513268470764,
      "learning_rate": 5.272549662322166e-05,
      "loss": 0.043,
      "step": 1310
    },
    {
      "epoch": 2.1872410936205466,
      "grad_norm": 0.5646451711654663,
      "learning_rate": 5.267644964961866e-05,
      "loss": 0.0414,
      "step": 1320
    },
    {
      "epoch": 2.203811101905551,
      "grad_norm": 1.443877100944519,
      "learning_rate": 5.262740267601566e-05,
      "loss": 0.013,
      "step": 1330
    },
    {
      "epoch": 2.220381110190555,
      "grad_norm": 0.06599023193120956,
      "learning_rate": 5.2578355702412664e-05,
      "loss": 0.0322,
      "step": 1340
    },
    {
      "epoch": 2.236951118475559,
      "grad_norm": 0.4674433767795563,
      "learning_rate": 5.2529308728809666e-05,
      "loss": 0.0323,
      "step": 1350
    },
    {
      "epoch": 2.2535211267605635,
      "grad_norm": 0.7571859955787659,
      "learning_rate": 5.248026175520667e-05,
      "loss": 0.0334,
      "step": 1360
    },
    {
      "epoch": 2.2700911350455675,
      "grad_norm": 1.4916844367980957,
      "learning_rate": 5.2431214781603676e-05,
      "loss": 0.0274,
      "step": 1370
    },
    {
      "epoch": 2.286661143330572,
      "grad_norm": 0.7222310304641724,
      "learning_rate": 5.2382167808000684e-05,
      "loss": 0.0394,
      "step": 1380
    },
    {
      "epoch": 2.303231151615576,
      "grad_norm": 0.4089110791683197,
      "learning_rate": 5.2333120834397686e-05,
      "loss": 0.0269,
      "step": 1390
    },
    {
      "epoch": 2.31980115990058,
      "grad_norm": 0.9535024166107178,
      "learning_rate": 5.228407386079469e-05,
      "loss": 0.0258,
      "step": 1400
    },
    {
      "epoch": 2.3363711681855843,
      "grad_norm": 1.1914093494415283,
      "learning_rate": 5.223502688719169e-05,
      "loss": 0.0271,
      "step": 1410
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.03262738510966301,
      "learning_rate": 5.218597991358869e-05,
      "loss": 0.0446,
      "step": 1420
    },
    {
      "epoch": 2.3695111847555923,
      "grad_norm": 0.5556226968765259,
      "learning_rate": 5.213693293998569e-05,
      "loss": 0.023,
      "step": 1430
    },
    {
      "epoch": 2.3860811930405967,
      "grad_norm": 0.029904618859291077,
      "learning_rate": 5.2087885966382694e-05,
      "loss": 0.019,
      "step": 1440
    },
    {
      "epoch": 2.4026512013256007,
      "grad_norm": 0.5225953459739685,
      "learning_rate": 5.20388389927797e-05,
      "loss": 0.0225,
      "step": 1450
    },
    {
      "epoch": 2.4192212096106047,
      "grad_norm": 0.09645450115203857,
      "learning_rate": 5.1989792019176704e-05,
      "loss": 0.023,
      "step": 1460
    },
    {
      "epoch": 2.435791217895609,
      "grad_norm": 0.06416323035955429,
      "learning_rate": 5.1940745045573705e-05,
      "loss": 0.0085,
      "step": 1470
    },
    {
      "epoch": 2.452361226180613,
      "grad_norm": 1.1857481002807617,
      "learning_rate": 5.189169807197071e-05,
      "loss": 0.0218,
      "step": 1480
    },
    {
      "epoch": 2.468931234465617,
      "grad_norm": 0.043197281658649445,
      "learning_rate": 5.1842651098367715e-05,
      "loss": 0.0077,
      "step": 1490
    },
    {
      "epoch": 2.4855012427506216,
      "grad_norm": 1.312461018562317,
      "learning_rate": 5.179360412476472e-05,
      "loss": 0.0375,
      "step": 1500
    },
    {
      "epoch": 2.5020712510356256,
      "grad_norm": 0.6393839716911316,
      "learning_rate": 5.174455715116172e-05,
      "loss": 0.033,
      "step": 1510
    },
    {
      "epoch": 2.5186412593206295,
      "grad_norm": 1.6513383388519287,
      "learning_rate": 5.169551017755872e-05,
      "loss": 0.023,
      "step": 1520
    },
    {
      "epoch": 2.535211267605634,
      "grad_norm": 0.05741812661290169,
      "learning_rate": 5.164646320395573e-05,
      "loss": 0.0166,
      "step": 1530
    },
    {
      "epoch": 2.551781275890638,
      "grad_norm": 0.2812129855155945,
      "learning_rate": 5.159741623035273e-05,
      "loss": 0.0349,
      "step": 1540
    },
    {
      "epoch": 2.568351284175642,
      "grad_norm": 0.866420328617096,
      "learning_rate": 5.154836925674973e-05,
      "loss": 0.0275,
      "step": 1550
    },
    {
      "epoch": 2.5849212924606464,
      "grad_norm": 1.9211987257003784,
      "learning_rate": 5.149932228314673e-05,
      "loss": 0.02,
      "step": 1560
    },
    {
      "epoch": 2.6014913007456504,
      "grad_norm": 0.11735562980175018,
      "learning_rate": 5.1450275309543734e-05,
      "loss": 0.0238,
      "step": 1570
    },
    {
      "epoch": 2.6180613090306544,
      "grad_norm": 0.19944266974925995,
      "learning_rate": 5.1401228335940736e-05,
      "loss": 0.0433,
      "step": 1580
    },
    {
      "epoch": 2.634631317315659,
      "grad_norm": 0.012622158974409103,
      "learning_rate": 5.1352181362337744e-05,
      "loss": 0.0209,
      "step": 1590
    },
    {
      "epoch": 2.651201325600663,
      "grad_norm": 2.610328435897827,
      "learning_rate": 5.1303134388734746e-05,
      "loss": 0.0288,
      "step": 1600
    },
    {
      "epoch": 2.667771333885667,
      "grad_norm": 0.09343608468770981,
      "learning_rate": 5.1254087415131754e-05,
      "loss": 0.0151,
      "step": 1610
    },
    {
      "epoch": 2.684341342170671,
      "grad_norm": 0.15632149577140808,
      "learning_rate": 5.1205040441528756e-05,
      "loss": 0.0149,
      "step": 1620
    },
    {
      "epoch": 2.700911350455675,
      "grad_norm": 0.4700845181941986,
      "learning_rate": 5.115599346792576e-05,
      "loss": 0.0235,
      "step": 1630
    },
    {
      "epoch": 2.717481358740679,
      "grad_norm": 0.10653522610664368,
      "learning_rate": 5.110694649432276e-05,
      "loss": 0.0186,
      "step": 1640
    },
    {
      "epoch": 2.7340513670256836,
      "grad_norm": 0.5271371603012085,
      "learning_rate": 5.105789952071976e-05,
      "loss": 0.0209,
      "step": 1650
    },
    {
      "epoch": 2.7506213753106876,
      "grad_norm": 1.6706032752990723,
      "learning_rate": 5.100885254711676e-05,
      "loss": 0.0201,
      "step": 1660
    },
    {
      "epoch": 2.7671913835956916,
      "grad_norm": 2.5172791481018066,
      "learning_rate": 5.0959805573513764e-05,
      "loss": 0.0306,
      "step": 1670
    },
    {
      "epoch": 2.783761391880696,
      "grad_norm": 0.12983815371990204,
      "learning_rate": 5.091075859991077e-05,
      "loss": 0.0213,
      "step": 1680
    },
    {
      "epoch": 2.8003314001657,
      "grad_norm": 0.05732807517051697,
      "learning_rate": 5.086171162630778e-05,
      "loss": 0.039,
      "step": 1690
    },
    {
      "epoch": 2.816901408450704,
      "grad_norm": 0.12367319315671921,
      "learning_rate": 5.081266465270478e-05,
      "loss": 0.0169,
      "step": 1700
    },
    {
      "epoch": 2.8334714167357085,
      "grad_norm": 0.3173017203807831,
      "learning_rate": 5.0763617679101784e-05,
      "loss": 0.0367,
      "step": 1710
    },
    {
      "epoch": 2.8500414250207124,
      "grad_norm": 4.277586460113525,
      "learning_rate": 5.0714570705498785e-05,
      "loss": 0.0227,
      "step": 1720
    },
    {
      "epoch": 2.8666114333057164,
      "grad_norm": 0.10256094485521317,
      "learning_rate": 5.066552373189579e-05,
      "loss": 0.0378,
      "step": 1730
    },
    {
      "epoch": 2.883181441590721,
      "grad_norm": 0.694892942905426,
      "learning_rate": 5.061647675829279e-05,
      "loss": 0.0134,
      "step": 1740
    },
    {
      "epoch": 2.899751449875725,
      "grad_norm": 1.7859349250793457,
      "learning_rate": 5.056742978468979e-05,
      "loss": 0.0325,
      "step": 1750
    },
    {
      "epoch": 2.916321458160729,
      "grad_norm": 0.0623452253639698,
      "learning_rate": 5.05183828110868e-05,
      "loss": 0.034,
      "step": 1760
    },
    {
      "epoch": 2.9328914664457333,
      "grad_norm": 1.0193232297897339,
      "learning_rate": 5.04693358374838e-05,
      "loss": 0.0125,
      "step": 1770
    },
    {
      "epoch": 2.9494614747307373,
      "grad_norm": 2.9642138481140137,
      "learning_rate": 5.04202888638808e-05,
      "loss": 0.0172,
      "step": 1780
    },
    {
      "epoch": 2.9660314830157413,
      "grad_norm": 0.995586633682251,
      "learning_rate": 5.03712418902778e-05,
      "loss": 0.0461,
      "step": 1790
    },
    {
      "epoch": 2.9826014913007457,
      "grad_norm": 1.6575725078582764,
      "learning_rate": 5.032219491667481e-05,
      "loss": 0.028,
      "step": 1800
    },
    {
      "epoch": 2.9991714995857497,
      "grad_norm": 0.2668341100215912,
      "learning_rate": 5.027314794307181e-05,
      "loss": 0.0103,
      "step": 1810
    },
    {
      "epoch": 2.9991714995857497,
      "eval_accuracy": 0.9905705996131529,
      "eval_f1": 0.9475806451612904,
      "eval_loss": 0.034264009445905685,
      "eval_precision": 0.9618008185538881,
      "eval_recall": 0.9337748344370861,
      "eval_runtime": 4150.6075,
      "eval_samples_per_second": 1.994,
      "eval_steps_per_second": 0.249,
      "step": 1810
    },
    {
      "epoch": 2.9991714995857497,
      "eval_accuracy": 0.9905705996131529,
      "eval_f1": 0.9475806451612904,
      "eval_loss": 0.034264009445905685,
      "eval_precision": 0.9618008185538881,
      "eval_recall": 0.9337748344370861,
      "eval_runtime": 5195.3721,
      "eval_samples_per_second": 1.593,
      "eval_steps_per_second": 0.199,
      "step": 1810
    },
    {
      "epoch": 3.015741507870754,
      "grad_norm": 0.029155172407627106,
      "learning_rate": 5.0224100969468815e-05,
      "loss": 0.011,
      "step": 1820
    },
    {
      "epoch": 3.032311516155758,
      "grad_norm": 0.010687185451388359,
      "learning_rate": 5.0175053995865816e-05,
      "loss": 0.0229,
      "step": 1830
    },
    {
      "epoch": 3.048881524440762,
      "grad_norm": 0.03862232342362404,
      "learning_rate": 5.0126007022262824e-05,
      "loss": 0.0128,
      "step": 1840
    },
    {
      "epoch": 3.0654515327257665,
      "grad_norm": 0.2843243479728699,
      "learning_rate": 5.0076960048659826e-05,
      "loss": 0.0469,
      "step": 1850
    },
    {
      "epoch": 3.0820215410107705,
      "grad_norm": 1.3542929887771606,
      "learning_rate": 5.002791307505683e-05,
      "loss": 0.0251,
      "step": 1860
    },
    {
      "epoch": 3.0985915492957745,
      "grad_norm": 0.03698348626494408,
      "learning_rate": 4.997886610145383e-05,
      "loss": 0.0061,
      "step": 1870
    },
    {
      "epoch": 3.115161557580779,
      "grad_norm": 0.004872314631938934,
      "learning_rate": 4.992981912785083e-05,
      "loss": 0.0122,
      "step": 1880
    },
    {
      "epoch": 3.131731565865783,
      "grad_norm": 1.3858997821807861,
      "learning_rate": 4.988077215424783e-05,
      "loss": 0.0111,
      "step": 1890
    },
    {
      "epoch": 3.148301574150787,
      "grad_norm": 1.3078244924545288,
      "learning_rate": 4.983172518064484e-05,
      "loss": 0.0252,
      "step": 1900
    },
    {
      "epoch": 3.1648715824357914,
      "grad_norm": 2.2155487537384033,
      "learning_rate": 4.978267820704185e-05,
      "loss": 0.0211,
      "step": 1910
    },
    {
      "epoch": 3.1814415907207954,
      "grad_norm": 0.131118044257164,
      "learning_rate": 4.973363123343885e-05,
      "loss": 0.015,
      "step": 1920
    },
    {
      "epoch": 3.1980115990057993,
      "grad_norm": 2.317720413208008,
      "learning_rate": 4.968458425983585e-05,
      "loss": 0.0121,
      "step": 1930
    },
    {
      "epoch": 3.2145816072908038,
      "grad_norm": 0.09571535885334015,
      "learning_rate": 4.9635537286232854e-05,
      "loss": 0.0031,
      "step": 1940
    },
    {
      "epoch": 3.2311516155758078,
      "grad_norm": 0.03672723099589348,
      "learning_rate": 4.9586490312629855e-05,
      "loss": 0.0109,
      "step": 1950
    },
    {
      "epoch": 3.2477216238608118,
      "grad_norm": 0.3102591335773468,
      "learning_rate": 4.953744333902686e-05,
      "loss": 0.0251,
      "step": 1960
    },
    {
      "epoch": 3.264291632145816,
      "grad_norm": 1.3836877346038818,
      "learning_rate": 4.948839636542386e-05,
      "loss": 0.014,
      "step": 1970
    },
    {
      "epoch": 3.28086164043082,
      "grad_norm": 1.8960418701171875,
      "learning_rate": 4.943934939182086e-05,
      "loss": 0.0298,
      "step": 1980
    },
    {
      "epoch": 3.297431648715824,
      "grad_norm": 1.4107893705368042,
      "learning_rate": 4.939030241821787e-05,
      "loss": 0.0273,
      "step": 1990
    },
    {
      "epoch": 3.3140016570008286,
      "grad_norm": 1.8382072448730469,
      "learning_rate": 4.934125544461487e-05,
      "loss": 0.0196,
      "step": 2000
    },
    {
      "epoch": 3.3305716652858326,
      "grad_norm": 0.19041170179843903,
      "learning_rate": 4.929220847101188e-05,
      "loss": 0.0246,
      "step": 2010
    },
    {
      "epoch": 3.347141673570837,
      "grad_norm": 0.6247087717056274,
      "learning_rate": 4.924316149740888e-05,
      "loss": 0.0331,
      "step": 2020
    },
    {
      "epoch": 3.363711681855841,
      "grad_norm": 0.5839367508888245,
      "learning_rate": 4.919411452380588e-05,
      "loss": 0.0209,
      "step": 2030
    },
    {
      "epoch": 3.380281690140845,
      "grad_norm": 0.16613081097602844,
      "learning_rate": 4.914506755020288e-05,
      "loss": 0.019,
      "step": 2040
    },
    {
      "epoch": 3.3968516984258494,
      "grad_norm": 0.5991812944412231,
      "learning_rate": 4.9096020576599885e-05,
      "loss": 0.0185,
      "step": 2050
    },
    {
      "epoch": 3.4134217067108534,
      "grad_norm": 0.14597730338573456,
      "learning_rate": 4.9046973602996886e-05,
      "loss": 0.0079,
      "step": 2060
    },
    {
      "epoch": 3.4299917149958574,
      "grad_norm": 0.9210067987442017,
      "learning_rate": 4.8997926629393895e-05,
      "loss": 0.0235,
      "step": 2070
    },
    {
      "epoch": 3.446561723280862,
      "grad_norm": 0.3674640953540802,
      "learning_rate": 4.8948879655790896e-05,
      "loss": 0.0067,
      "step": 2080
    },
    {
      "epoch": 3.463131731565866,
      "grad_norm": 0.9378771185874939,
      "learning_rate": 4.88998326821879e-05,
      "loss": 0.027,
      "step": 2090
    },
    {
      "epoch": 3.47970173985087,
      "grad_norm": 0.40635159611701965,
      "learning_rate": 4.88507857085849e-05,
      "loss": 0.0212,
      "step": 2100
    },
    {
      "epoch": 3.4962717481358743,
      "grad_norm": 0.7106351256370544,
      "learning_rate": 4.880173873498191e-05,
      "loss": 0.0396,
      "step": 2110
    },
    {
      "epoch": 3.5128417564208783,
      "grad_norm": 0.39631393551826477,
      "learning_rate": 4.875269176137891e-05,
      "loss": 0.0219,
      "step": 2120
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 0.24957826733589172,
      "learning_rate": 4.870364478777591e-05,
      "loss": 0.0237,
      "step": 2130
    },
    {
      "epoch": 3.5459817729908867,
      "grad_norm": 0.05180584639310837,
      "learning_rate": 4.865459781417292e-05,
      "loss": 0.0331,
      "step": 2140
    },
    {
      "epoch": 3.5625517812758907,
      "grad_norm": 0.11927972733974457,
      "learning_rate": 4.860555084056992e-05,
      "loss": 0.015,
      "step": 2150
    },
    {
      "epoch": 3.5791217895608947,
      "grad_norm": 0.4998351037502289,
      "learning_rate": 4.855650386696692e-05,
      "loss": 0.0196,
      "step": 2160
    },
    {
      "epoch": 3.595691797845899,
      "grad_norm": 0.31965839862823486,
      "learning_rate": 4.8507456893363924e-05,
      "loss": 0.0126,
      "step": 2170
    },
    {
      "epoch": 3.612261806130903,
      "grad_norm": 0.2251231074333191,
      "learning_rate": 4.8458409919760925e-05,
      "loss": 0.0167,
      "step": 2180
    },
    {
      "epoch": 3.628831814415907,
      "grad_norm": 0.3284197449684143,
      "learning_rate": 4.840936294615793e-05,
      "loss": 0.0122,
      "step": 2190
    },
    {
      "epoch": 3.6454018227009115,
      "grad_norm": 1.953888177871704,
      "learning_rate": 4.836031597255493e-05,
      "loss": 0.0101,
      "step": 2200
    },
    {
      "epoch": 3.6619718309859155,
      "grad_norm": 2.52935528755188,
      "learning_rate": 4.831126899895194e-05,
      "loss": 0.0077,
      "step": 2210
    },
    {
      "epoch": 3.6785418392709195,
      "grad_norm": 2.124600887298584,
      "learning_rate": 4.8262222025348945e-05,
      "loss": 0.0131,
      "step": 2220
    },
    {
      "epoch": 3.695111847555924,
      "grad_norm": 0.720088005065918,
      "learning_rate": 4.821317505174595e-05,
      "loss": 0.0053,
      "step": 2230
    },
    {
      "epoch": 3.711681855840928,
      "grad_norm": 0.6023657917976379,
      "learning_rate": 4.816412807814295e-05,
      "loss": 0.0099,
      "step": 2240
    },
    {
      "epoch": 3.728251864125932,
      "grad_norm": 1.3627876043319702,
      "learning_rate": 4.811508110453995e-05,
      "loss": 0.0359,
      "step": 2250
    },
    {
      "epoch": 3.7448218724109363,
      "grad_norm": 0.5037737488746643,
      "learning_rate": 4.806603413093695e-05,
      "loss": 0.0203,
      "step": 2260
    },
    {
      "epoch": 3.7613918806959403,
      "grad_norm": 0.6278684139251709,
      "learning_rate": 4.801698715733395e-05,
      "loss": 0.0362,
      "step": 2270
    },
    {
      "epoch": 3.7779618889809443,
      "grad_norm": 0.7093528509140015,
      "learning_rate": 4.7967940183730955e-05,
      "loss": 0.0189,
      "step": 2280
    },
    {
      "epoch": 3.7945318972659487,
      "grad_norm": 0.7267375588417053,
      "learning_rate": 4.791889321012796e-05,
      "loss": 0.0091,
      "step": 2290
    },
    {
      "epoch": 3.8111019055509527,
      "grad_norm": 3.1662585735321045,
      "learning_rate": 4.7869846236524965e-05,
      "loss": 0.0086,
      "step": 2300
    },
    {
      "epoch": 3.8276719138359567,
      "grad_norm": 1.0863566398620605,
      "learning_rate": 4.7820799262921966e-05,
      "loss": 0.0415,
      "step": 2310
    },
    {
      "epoch": 3.844241922120961,
      "grad_norm": 0.3280559182167053,
      "learning_rate": 4.7771752289318975e-05,
      "loss": 0.0192,
      "step": 2320
    },
    {
      "epoch": 3.860811930405965,
      "grad_norm": 0.005922004114836454,
      "learning_rate": 4.7722705315715976e-05,
      "loss": 0.0073,
      "step": 2330
    },
    {
      "epoch": 3.877381938690969,
      "grad_norm": 0.05522363632917404,
      "learning_rate": 4.767365834211298e-05,
      "loss": 0.0094,
      "step": 2340
    },
    {
      "epoch": 3.8939519469759736,
      "grad_norm": 0.5943393111228943,
      "learning_rate": 4.762461136850998e-05,
      "loss": 0.0081,
      "step": 2350
    },
    {
      "epoch": 3.9105219552609776,
      "grad_norm": 0.28456684947013855,
      "learning_rate": 4.757556439490698e-05,
      "loss": 0.0094,
      "step": 2360
    },
    {
      "epoch": 3.9270919635459816,
      "grad_norm": 0.03438013419508934,
      "learning_rate": 4.752651742130399e-05,
      "loss": 0.0283,
      "step": 2370
    },
    {
      "epoch": 3.943661971830986,
      "grad_norm": 0.4916750192642212,
      "learning_rate": 4.747747044770099e-05,
      "loss": 0.0256,
      "step": 2380
    },
    {
      "epoch": 3.96023198011599,
      "grad_norm": 0.2827090322971344,
      "learning_rate": 4.742842347409799e-05,
      "loss": 0.028,
      "step": 2390
    },
    {
      "epoch": 3.976801988400994,
      "grad_norm": 0.01977635733783245,
      "learning_rate": 4.7379376500494994e-05,
      "loss": 0.0352,
      "step": 2400
    },
    {
      "epoch": 3.9933719966859984,
      "grad_norm": 0.9125289916992188,
      "learning_rate": 4.7330329526891996e-05,
      "loss": 0.0106,
      "step": 2410
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9914168278529981,
      "eval_f1": 0.9526350900600402,
      "eval_loss": 0.0264139287173748,
      "eval_precision": 0.9596774193548387,
      "eval_recall": 0.9456953642384106,
      "eval_runtime": 4689.2259,
      "eval_samples_per_second": 1.765,
      "eval_steps_per_second": 0.221,
      "step": 2414
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9914168278529981,
      "eval_f1": 0.9526350900600402,
      "eval_loss": 0.0264139287173748,
      "eval_precision": 0.9596774193548387,
      "eval_recall": 0.9456953642384106,
      "eval_runtime": 3411.9261,
      "eval_samples_per_second": 2.426,
      "eval_steps_per_second": 0.303,
      "step": 2414
    },
    {
      "epoch": 4.009942004971003,
      "grad_norm": 0.3019806146621704,
      "learning_rate": 4.7281282553289004e-05,
      "loss": 0.0039,
      "step": 2420
    },
    {
      "epoch": 4.026512013256006,
      "grad_norm": 0.57737797498703,
      "learning_rate": 4.7232235579686005e-05,
      "loss": 0.0106,
      "step": 2430
    },
    {
      "epoch": 4.043082021541011,
      "grad_norm": 2.403268575668335,
      "learning_rate": 4.718318860608301e-05,
      "loss": 0.0214,
      "step": 2440
    },
    {
      "epoch": 4.059652029826015,
      "grad_norm": 0.0032677266281098127,
      "learning_rate": 4.7134141632480015e-05,
      "loss": 0.0037,
      "step": 2450
    },
    {
      "epoch": 4.076222038111019,
      "grad_norm": 3.9294779300689697,
      "learning_rate": 4.708509465887702e-05,
      "loss": 0.0153,
      "step": 2460
    },
    {
      "epoch": 4.092792046396023,
      "grad_norm": 0.8044359087944031,
      "learning_rate": 4.703604768527402e-05,
      "loss": 0.0199,
      "step": 2470
    },
    {
      "epoch": 4.109362054681028,
      "grad_norm": 0.027746720239520073,
      "learning_rate": 4.698700071167102e-05,
      "loss": 0.0241,
      "step": 2480
    },
    {
      "epoch": 4.125932062966031,
      "grad_norm": 0.10303540527820587,
      "learning_rate": 4.693795373806802e-05,
      "loss": 0.0142,
      "step": 2490
    },
    {
      "epoch": 4.142502071251036,
      "grad_norm": 0.68260258436203,
      "learning_rate": 4.688890676446502e-05,
      "loss": 0.0202,
      "step": 2500
    },
    {
      "epoch": 4.15907207953604,
      "grad_norm": 0.03953368961811066,
      "learning_rate": 4.6839859790862025e-05,
      "loss": 0.0173,
      "step": 2510
    },
    {
      "epoch": 4.175642087821044,
      "grad_norm": 0.28457629680633545,
      "learning_rate": 4.679081281725903e-05,
      "loss": 0.014,
      "step": 2520
    },
    {
      "epoch": 4.192212096106048,
      "grad_norm": 0.0014794798335060477,
      "learning_rate": 4.674176584365604e-05,
      "loss": 0.0104,
      "step": 2530
    },
    {
      "epoch": 4.2087821043910525,
      "grad_norm": 1.2099273204803467,
      "learning_rate": 4.669271887005304e-05,
      "loss": 0.0197,
      "step": 2540
    },
    {
      "epoch": 4.225352112676056,
      "grad_norm": 0.6009286046028137,
      "learning_rate": 4.6643671896450045e-05,
      "loss": 0.0121,
      "step": 2550
    },
    {
      "epoch": 4.2419221209610605,
      "grad_norm": 0.08945254236459732,
      "learning_rate": 4.6594624922847046e-05,
      "loss": 0.0109,
      "step": 2560
    },
    {
      "epoch": 4.258492129246065,
      "grad_norm": 2.422783851623535,
      "learning_rate": 4.654557794924405e-05,
      "loss": 0.0108,
      "step": 2570
    },
    {
      "epoch": 4.2750621375310685,
      "grad_norm": 0.1303391456604004,
      "learning_rate": 4.649653097564105e-05,
      "loss": 0.0184,
      "step": 2580
    },
    {
      "epoch": 4.291632145816073,
      "grad_norm": 0.010286226868629456,
      "learning_rate": 4.644748400203805e-05,
      "loss": 0.0126,
      "step": 2590
    },
    {
      "epoch": 4.308202154101077,
      "grad_norm": 0.2825932502746582,
      "learning_rate": 4.639843702843506e-05,
      "loss": 0.0156,
      "step": 2600
    },
    {
      "epoch": 4.324772162386081,
      "grad_norm": 0.08020206540822983,
      "learning_rate": 4.634939005483206e-05,
      "loss": 0.0044,
      "step": 2610
    },
    {
      "epoch": 4.341342170671085,
      "grad_norm": 0.09038020670413971,
      "learning_rate": 4.630034308122906e-05,
      "loss": 0.0056,
      "step": 2620
    },
    {
      "epoch": 4.35791217895609,
      "grad_norm": 1.8618297576904297,
      "learning_rate": 4.625129610762607e-05,
      "loss": 0.0216,
      "step": 2630
    },
    {
      "epoch": 4.374482187241093,
      "grad_norm": 0.3676470220088959,
      "learning_rate": 4.620224913402307e-05,
      "loss": 0.0252,
      "step": 2640
    },
    {
      "epoch": 4.391052195526098,
      "grad_norm": 0.05726061761379242,
      "learning_rate": 4.6153202160420074e-05,
      "loss": 0.0172,
      "step": 2650
    },
    {
      "epoch": 4.407622203811102,
      "grad_norm": 0.005576295778155327,
      "learning_rate": 4.6104155186817076e-05,
      "loss": 0.0086,
      "step": 2660
    },
    {
      "epoch": 4.424192212096106,
      "grad_norm": 1.3370420932769775,
      "learning_rate": 4.605510821321408e-05,
      "loss": 0.037,
      "step": 2670
    },
    {
      "epoch": 4.44076222038111,
      "grad_norm": 0.12714101374149323,
      "learning_rate": 4.6006061239611086e-05,
      "loss": 0.0032,
      "step": 2680
    },
    {
      "epoch": 4.457332228666115,
      "grad_norm": 1.0784709453582764,
      "learning_rate": 4.595701426600809e-05,
      "loss": 0.02,
      "step": 2690
    },
    {
      "epoch": 4.473902236951118,
      "grad_norm": 0.032255396246910095,
      "learning_rate": 4.590796729240509e-05,
      "loss": 0.0315,
      "step": 2700
    },
    {
      "epoch": 4.4904722452361225,
      "grad_norm": 5.234325408935547,
      "learning_rate": 4.585892031880209e-05,
      "loss": 0.0113,
      "step": 2710
    },
    {
      "epoch": 4.507042253521127,
      "grad_norm": 0.03393349051475525,
      "learning_rate": 4.580987334519909e-05,
      "loss": 0.012,
      "step": 2720
    },
    {
      "epoch": 4.5236122618061305,
      "grad_norm": 0.8874229788780212,
      "learning_rate": 4.5760826371596093e-05,
      "loss": 0.0076,
      "step": 2730
    },
    {
      "epoch": 4.540182270091135,
      "grad_norm": 0.15616415441036224,
      "learning_rate": 4.57117793979931e-05,
      "loss": 0.0098,
      "step": 2740
    },
    {
      "epoch": 4.556752278376139,
      "grad_norm": 0.27762967348098755,
      "learning_rate": 4.56627324243901e-05,
      "loss": 0.0199,
      "step": 2750
    },
    {
      "epoch": 4.573322286661144,
      "grad_norm": 0.3778418004512787,
      "learning_rate": 4.561368545078711e-05,
      "loss": 0.0118,
      "step": 2760
    },
    {
      "epoch": 4.589892294946147,
      "grad_norm": 0.011907661333680153,
      "learning_rate": 4.556463847718411e-05,
      "loss": 0.0242,
      "step": 2770
    },
    {
      "epoch": 4.606462303231152,
      "grad_norm": 0.0668463483452797,
      "learning_rate": 4.5515591503581115e-05,
      "loss": 0.0147,
      "step": 2780
    },
    {
      "epoch": 4.623032311516155,
      "grad_norm": 0.73671954870224,
      "learning_rate": 4.5466544529978116e-05,
      "loss": 0.0072,
      "step": 2790
    },
    {
      "epoch": 4.63960231980116,
      "grad_norm": 1.2214646339416504,
      "learning_rate": 4.541749755637512e-05,
      "loss": 0.0141,
      "step": 2800
    },
    {
      "epoch": 4.656172328086164,
      "grad_norm": 0.03996684402227402,
      "learning_rate": 4.536845058277212e-05,
      "loss": 0.0072,
      "step": 2810
    },
    {
      "epoch": 4.672742336371169,
      "grad_norm": 2.8030588626861572,
      "learning_rate": 4.531940360916912e-05,
      "loss": 0.0143,
      "step": 2820
    },
    {
      "epoch": 4.689312344656172,
      "grad_norm": 0.6181252002716064,
      "learning_rate": 4.527035663556613e-05,
      "loss": 0.0216,
      "step": 2830
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.5370349287986755,
      "learning_rate": 4.522130966196314e-05,
      "loss": 0.0143,
      "step": 2840
    },
    {
      "epoch": 4.72245236122618,
      "grad_norm": 0.8541839122772217,
      "learning_rate": 4.517226268836014e-05,
      "loss": 0.0215,
      "step": 2850
    },
    {
      "epoch": 4.739022369511185,
      "grad_norm": 1.7391616106033325,
      "learning_rate": 4.512321571475714e-05,
      "loss": 0.0269,
      "step": 2860
    },
    {
      "epoch": 4.755592377796189,
      "grad_norm": 0.1433992236852646,
      "learning_rate": 4.507416874115414e-05,
      "loss": 0.0076,
      "step": 2870
    },
    {
      "epoch": 4.7721623860811935,
      "grad_norm": 0.006869333330541849,
      "learning_rate": 4.5025121767551144e-05,
      "loss": 0.0027,
      "step": 2880
    },
    {
      "epoch": 4.788732394366197,
      "grad_norm": 0.008014656603336334,
      "learning_rate": 4.4976074793948146e-05,
      "loss": 0.0196,
      "step": 2890
    },
    {
      "epoch": 4.8053024026512015,
      "grad_norm": 1.8948338031768799,
      "learning_rate": 4.492702782034515e-05,
      "loss": 0.034,
      "step": 2900
    },
    {
      "epoch": 4.821872410936205,
      "grad_norm": 0.006409836001694202,
      "learning_rate": 4.4877980846742156e-05,
      "loss": 0.0107,
      "step": 2910
    },
    {
      "epoch": 4.838442419221209,
      "grad_norm": 1.8039439916610718,
      "learning_rate": 4.482893387313916e-05,
      "loss": 0.0197,
      "step": 2920
    },
    {
      "epoch": 4.855012427506214,
      "grad_norm": 2.3747506141662598,
      "learning_rate": 4.477988689953616e-05,
      "loss": 0.018,
      "step": 2930
    },
    {
      "epoch": 4.871582435791218,
      "grad_norm": 1.5145548582077026,
      "learning_rate": 4.473083992593317e-05,
      "loss": 0.0215,
      "step": 2940
    },
    {
      "epoch": 4.888152444076222,
      "grad_norm": 0.2288045734167099,
      "learning_rate": 4.468179295233017e-05,
      "loss": 0.0062,
      "step": 2950
    },
    {
      "epoch": 4.904722452361226,
      "grad_norm": 6.170899391174316,
      "learning_rate": 4.463274597872717e-05,
      "loss": 0.0125,
      "step": 2960
    },
    {
      "epoch": 4.92129246064623,
      "grad_norm": 2.0769360065460205,
      "learning_rate": 4.458369900512417e-05,
      "loss": 0.0338,
      "step": 2970
    },
    {
      "epoch": 4.937862468931234,
      "grad_norm": 0.21461746096611023,
      "learning_rate": 4.4534652031521173e-05,
      "loss": 0.013,
      "step": 2980
    },
    {
      "epoch": 4.954432477216239,
      "grad_norm": 0.03820687159895897,
      "learning_rate": 4.448560505791818e-05,
      "loss": 0.0107,
      "step": 2990
    },
    {
      "epoch": 4.971002485501243,
      "grad_norm": 0.4555639624595642,
      "learning_rate": 4.443655808431518e-05,
      "loss": 0.0184,
      "step": 3000
    },
    {
      "epoch": 4.987572493786247,
      "grad_norm": 0.018948223441839218,
      "learning_rate": 4.4387511110712185e-05,
      "loss": 0.0082,
      "step": 3010
    },
    {
      "epoch": 4.99917149958575,
      "eval_accuracy": 0.992142166344294,
      "eval_f1": 0.9556918882072256,
      "eval_loss": 0.03138599172234535,
      "eval_precision": 0.9845505617977528,
      "eval_recall": 0.928476821192053,
      "eval_runtime": 2134.6015,
      "eval_samples_per_second": 3.878,
      "eval_steps_per_second": 0.485,
      "step": 3017
    },
    {
      "epoch": 4.99917149958575,
      "eval_accuracy": 0.992142166344294,
      "eval_f1": 0.9556918882072256,
      "eval_loss": 0.03138599172234535,
      "eval_precision": 0.9845505617977528,
      "eval_recall": 0.928476821192053,
      "eval_runtime": 2091.9848,
      "eval_samples_per_second": 3.957,
      "eval_steps_per_second": 0.495,
      "step": 3017
    },
    {
      "epoch": 5.004142502071251,
      "grad_norm": 0.12027779966592789,
      "learning_rate": 4.4338464137109187e-05,
      "loss": 0.0084,
      "step": 3020
    },
    {
      "epoch": 5.0207125103562555,
      "grad_norm": 0.0042083547450602055,
      "learning_rate": 4.428941716350619e-05,
      "loss": 0.0151,
      "step": 3030
    },
    {
      "epoch": 5.037282518641259,
      "grad_norm": 3.086246967315674,
      "learning_rate": 4.424037018990319e-05,
      "loss": 0.0044,
      "step": 3040
    },
    {
      "epoch": 5.0538525269262635,
      "grad_norm": 0.08986587822437286,
      "learning_rate": 4.41913232163002e-05,
      "loss": 0.0058,
      "step": 3050
    },
    {
      "epoch": 5.070422535211268,
      "grad_norm": 0.1515192985534668,
      "learning_rate": 4.4142276242697206e-05,
      "loss": 0.0114,
      "step": 3060
    },
    {
      "epoch": 5.0869925434962715,
      "grad_norm": 0.7739114165306091,
      "learning_rate": 4.409322926909421e-05,
      "loss": 0.0102,
      "step": 3070
    },
    {
      "epoch": 5.103562551781276,
      "grad_norm": 1.515532374382019,
      "learning_rate": 4.404418229549121e-05,
      "loss": 0.037,
      "step": 3080
    },
    {
      "epoch": 5.12013256006628,
      "grad_norm": 0.6621149778366089,
      "learning_rate": 4.399513532188821e-05,
      "loss": 0.0217,
      "step": 3090
    },
    {
      "epoch": 5.136702568351284,
      "grad_norm": 0.5477527379989624,
      "learning_rate": 4.394608834828521e-05,
      "loss": 0.0064,
      "step": 3100
    },
    {
      "epoch": 5.153272576636288,
      "grad_norm": 0.5231236219406128,
      "learning_rate": 4.3897041374682214e-05,
      "loss": 0.0083,
      "step": 3110
    },
    {
      "epoch": 5.169842584921293,
      "grad_norm": 0.003916725516319275,
      "learning_rate": 4.3847994401079216e-05,
      "loss": 0.0003,
      "step": 3120
    },
    {
      "epoch": 5.186412593206296,
      "grad_norm": 1.2313178777694702,
      "learning_rate": 4.379894742747622e-05,
      "loss": 0.0156,
      "step": 3130
    },
    {
      "epoch": 5.202982601491301,
      "grad_norm": 0.8109147548675537,
      "learning_rate": 4.3749900453873226e-05,
      "loss": 0.0257,
      "step": 3140
    },
    {
      "epoch": 5.219552609776305,
      "grad_norm": 1.8024460077285767,
      "learning_rate": 4.3700853480270234e-05,
      "loss": 0.0104,
      "step": 3150
    },
    {
      "epoch": 5.236122618061309,
      "grad_norm": 1.704559087753296,
      "learning_rate": 4.3651806506667236e-05,
      "loss": 0.0377,
      "step": 3160
    },
    {
      "epoch": 5.252692626346313,
      "grad_norm": 1.0422786474227905,
      "learning_rate": 4.360275953306424e-05,
      "loss": 0.0203,
      "step": 3170
    },
    {
      "epoch": 5.269262634631318,
      "grad_norm": 1.7384651899337769,
      "learning_rate": 4.355371255946124e-05,
      "loss": 0.0462,
      "step": 3180
    },
    {
      "epoch": 5.285832642916321,
      "grad_norm": 0.017913442105054855,
      "learning_rate": 4.350466558585824e-05,
      "loss": 0.0115,
      "step": 3190
    },
    {
      "epoch": 5.302402651201326,
      "grad_norm": 0.0885034054517746,
      "learning_rate": 4.345561861225524e-05,
      "loss": 0.0124,
      "step": 3200
    },
    {
      "epoch": 5.31897265948633,
      "grad_norm": 0.06593911349773407,
      "learning_rate": 4.340657163865225e-05,
      "loss": 0.042,
      "step": 3210
    },
    {
      "epoch": 5.335542667771334,
      "grad_norm": 0.6897241473197937,
      "learning_rate": 4.335752466504925e-05,
      "loss": 0.0143,
      "step": 3220
    },
    {
      "epoch": 5.352112676056338,
      "grad_norm": 0.1801464557647705,
      "learning_rate": 4.3308477691446254e-05,
      "loss": 0.008,
      "step": 3230
    },
    {
      "epoch": 5.368682684341342,
      "grad_norm": 0.013607332482933998,
      "learning_rate": 4.3259430717843255e-05,
      "loss": 0.015,
      "step": 3240
    },
    {
      "epoch": 5.385252692626346,
      "grad_norm": 0.00735802948474884,
      "learning_rate": 4.321038374424026e-05,
      "loss": 0.0116,
      "step": 3250
    },
    {
      "epoch": 5.40182270091135,
      "grad_norm": 0.0580601803958416,
      "learning_rate": 4.3161336770637265e-05,
      "loss": 0.0233,
      "step": 3260
    },
    {
      "epoch": 5.418392709196355,
      "grad_norm": 0.8690329790115356,
      "learning_rate": 4.3112289797034267e-05,
      "loss": 0.0083,
      "step": 3270
    },
    {
      "epoch": 5.434962717481358,
      "grad_norm": 0.011412544175982475,
      "learning_rate": 4.306324282343127e-05,
      "loss": 0.0052,
      "step": 3280
    },
    {
      "epoch": 5.451532725766363,
      "grad_norm": 0.6457775235176086,
      "learning_rate": 4.3014195849828277e-05,
      "loss": 0.0119,
      "step": 3290
    },
    {
      "epoch": 5.468102734051367,
      "grad_norm": 0.049774881452322006,
      "learning_rate": 4.296514887622528e-05,
      "loss": 0.0144,
      "step": 3300
    },
    {
      "epoch": 5.484672742336371,
      "grad_norm": 2.033993721008301,
      "learning_rate": 4.291610190262228e-05,
      "loss": 0.0046,
      "step": 3310
    },
    {
      "epoch": 5.501242750621375,
      "grad_norm": 0.3107285499572754,
      "learning_rate": 4.286705492901928e-05,
      "loss": 0.0156,
      "step": 3320
    },
    {
      "epoch": 5.51781275890638,
      "grad_norm": 0.1067289486527443,
      "learning_rate": 4.281800795541628e-05,
      "loss": 0.0315,
      "step": 3330
    },
    {
      "epoch": 5.534382767191383,
      "grad_norm": 1.8713526725769043,
      "learning_rate": 4.2768960981813284e-05,
      "loss": 0.0115,
      "step": 3340
    },
    {
      "epoch": 5.550952775476388,
      "grad_norm": 0.049097690731287,
      "learning_rate": 4.2719914008210286e-05,
      "loss": 0.0176,
      "step": 3350
    },
    {
      "epoch": 5.567522783761392,
      "grad_norm": 0.2600855231285095,
      "learning_rate": 4.2670867034607294e-05,
      "loss": 0.0074,
      "step": 3360
    },
    {
      "epoch": 5.584092792046396,
      "grad_norm": 0.02667025849223137,
      "learning_rate": 4.26218200610043e-05,
      "loss": 0.0153,
      "step": 3370
    },
    {
      "epoch": 5.6006628003314,
      "grad_norm": 0.011658038944005966,
      "learning_rate": 4.2572773087401304e-05,
      "loss": 0.0224,
      "step": 3380
    },
    {
      "epoch": 5.6172328086164045,
      "grad_norm": 0.5048539042472839,
      "learning_rate": 4.2523726113798306e-05,
      "loss": 0.0219,
      "step": 3390
    },
    {
      "epoch": 5.633802816901408,
      "grad_norm": 0.03827831521630287,
      "learning_rate": 4.247467914019531e-05,
      "loss": 0.0121,
      "step": 3400
    },
    {
      "epoch": 5.6503728251864125,
      "grad_norm": 3.6330068111419678,
      "learning_rate": 4.242563216659231e-05,
      "loss": 0.0112,
      "step": 3410
    },
    {
      "epoch": 5.666942833471417,
      "grad_norm": 0.0729154571890831,
      "learning_rate": 4.237658519298931e-05,
      "loss": 0.0111,
      "step": 3420
    },
    {
      "epoch": 5.683512841756421,
      "grad_norm": 0.5337303280830383,
      "learning_rate": 4.232753821938631e-05,
      "loss": 0.0117,
      "step": 3430
    },
    {
      "epoch": 5.700082850041425,
      "grad_norm": 0.05775652453303337,
      "learning_rate": 4.227849124578332e-05,
      "loss": 0.0085,
      "step": 3440
    },
    {
      "epoch": 5.716652858326429,
      "grad_norm": 0.6545917391777039,
      "learning_rate": 4.222944427218032e-05,
      "loss": 0.0144,
      "step": 3450
    },
    {
      "epoch": 5.733222866611433,
      "grad_norm": 0.01203832682222128,
      "learning_rate": 4.2180397298577324e-05,
      "loss": 0.0041,
      "step": 3460
    },
    {
      "epoch": 5.749792874896437,
      "grad_norm": 0.7793937921524048,
      "learning_rate": 4.213135032497433e-05,
      "loss": 0.0094,
      "step": 3470
    },
    {
      "epoch": 5.766362883181442,
      "grad_norm": 0.020942671224474907,
      "learning_rate": 4.2082303351371334e-05,
      "loss": 0.0216,
      "step": 3480
    },
    {
      "epoch": 5.782932891466446,
      "grad_norm": 0.015765376389026642,
      "learning_rate": 4.2033256377768335e-05,
      "loss": 0.0156,
      "step": 3490
    },
    {
      "epoch": 5.79950289975145,
      "grad_norm": 0.7212013006210327,
      "learning_rate": 4.198420940416534e-05,
      "loss": 0.0164,
      "step": 3500
    },
    {
      "epoch": 5.816072908036454,
      "grad_norm": 0.6714059114456177,
      "learning_rate": 4.193516243056234e-05,
      "loss": 0.0161,
      "step": 3510
    },
    {
      "epoch": 5.832642916321458,
      "grad_norm": 1.8847278356552124,
      "learning_rate": 4.188611545695935e-05,
      "loss": 0.0266,
      "step": 3520
    },
    {
      "epoch": 5.849212924606462,
      "grad_norm": 0.7710350751876831,
      "learning_rate": 4.183706848335635e-05,
      "loss": 0.0241,
      "step": 3530
    },
    {
      "epoch": 5.865782932891467,
      "grad_norm": 0.040103912353515625,
      "learning_rate": 4.178802150975335e-05,
      "loss": 0.0064,
      "step": 3540
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.8256834149360657,
      "learning_rate": 4.173897453615035e-05,
      "loss": 0.0104,
      "step": 3550
    },
    {
      "epoch": 5.8989229494614746,
      "grad_norm": 0.009242560714483261,
      "learning_rate": 4.168992756254735e-05,
      "loss": 0.0122,
      "step": 3560
    },
    {
      "epoch": 5.915492957746479,
      "grad_norm": 0.8156492114067078,
      "learning_rate": 4.164088058894436e-05,
      "loss": 0.0145,
      "step": 3570
    },
    {
      "epoch": 5.9320629660314825,
      "grad_norm": 6.889967918395996,
      "learning_rate": 4.159183361534136e-05,
      "loss": 0.011,
      "step": 3580
    },
    {
      "epoch": 5.948632974316487,
      "grad_norm": 0.017364125698804855,
      "learning_rate": 4.1542786641738364e-05,
      "loss": 0.0103,
      "step": 3590
    },
    {
      "epoch": 5.965202982601491,
      "grad_norm": 0.4323115348815918,
      "learning_rate": 4.149373966813537e-05,
      "loss": 0.0099,
      "step": 3600
    },
    {
      "epoch": 5.981772990886496,
      "grad_norm": 0.41339364647865295,
      "learning_rate": 4.1444692694532374e-05,
      "loss": 0.0112,
      "step": 3610
    },
    {
      "epoch": 5.998342999171499,
      "grad_norm": 1.4605523347854614,
      "learning_rate": 4.1395645720929376e-05,
      "loss": 0.0262,
      "step": 3620
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9932301740812379,
      "eval_f1": 0.9621621621621622,
      "eval_loss": 0.025255557149648666,
      "eval_precision": 0.9820689655172414,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 2054.3787,
      "eval_samples_per_second": 4.029,
      "eval_steps_per_second": 0.504,
      "step": 3621
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9932301740812379,
      "eval_f1": 0.9621621621621622,
      "eval_loss": 0.025255557149648666,
      "eval_precision": 0.9820689655172414,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 2084.2061,
      "eval_samples_per_second": 3.971,
      "eval_steps_per_second": 0.497,
      "step": 3621
    },
    {
      "epoch": 6.014913007456504,
      "grad_norm": 0.03948761522769928,
      "learning_rate": 4.134659874732638e-05,
      "loss": 0.0053,
      "step": 3630
    },
    {
      "epoch": 6.031483015741508,
      "grad_norm": 0.39390313625335693,
      "learning_rate": 4.129755177372338e-05,
      "loss": 0.017,
      "step": 3640
    },
    {
      "epoch": 6.048053024026512,
      "grad_norm": 0.06503499299287796,
      "learning_rate": 4.124850480012038e-05,
      "loss": 0.0079,
      "step": 3650
    },
    {
      "epoch": 6.064623032311516,
      "grad_norm": 0.461003839969635,
      "learning_rate": 4.119945782651738e-05,
      "loss": 0.01,
      "step": 3660
    },
    {
      "epoch": 6.081193040596521,
      "grad_norm": 2.039379119873047,
      "learning_rate": 4.115041085291439e-05,
      "loss": 0.0031,
      "step": 3670
    },
    {
      "epoch": 6.097763048881524,
      "grad_norm": 0.9610140919685364,
      "learning_rate": 4.11013638793114e-05,
      "loss": 0.0079,
      "step": 3680
    },
    {
      "epoch": 6.114333057166529,
      "grad_norm": 0.0016366579802706838,
      "learning_rate": 4.10523169057084e-05,
      "loss": 0.0064,
      "step": 3690
    },
    {
      "epoch": 6.130903065451533,
      "grad_norm": 0.3509061932563782,
      "learning_rate": 4.10032699321054e-05,
      "loss": 0.0057,
      "step": 3700
    },
    {
      "epoch": 6.147473073736537,
      "grad_norm": 0.569054126739502,
      "learning_rate": 4.0954222958502404e-05,
      "loss": 0.0131,
      "step": 3710
    },
    {
      "epoch": 6.164043082021541,
      "grad_norm": 0.005201411433517933,
      "learning_rate": 4.0905175984899405e-05,
      "loss": 0.005,
      "step": 3720
    },
    {
      "epoch": 6.1806130903065455,
      "grad_norm": 0.47568583488464355,
      "learning_rate": 4.085612901129641e-05,
      "loss": 0.0046,
      "step": 3730
    },
    {
      "epoch": 6.197183098591549,
      "grad_norm": 0.026676727458834648,
      "learning_rate": 4.080708203769341e-05,
      "loss": 0.009,
      "step": 3740
    },
    {
      "epoch": 6.2137531068765535,
      "grad_norm": 0.005124627146869898,
      "learning_rate": 4.075803506409042e-05,
      "loss": 0.0131,
      "step": 3750
    },
    {
      "epoch": 6.230323115161558,
      "grad_norm": 0.13685457408428192,
      "learning_rate": 4.070898809048742e-05,
      "loss": 0.0096,
      "step": 3760
    },
    {
      "epoch": 6.2468931234465614,
      "grad_norm": 2.30806040763855,
      "learning_rate": 4.065994111688442e-05,
      "loss": 0.0173,
      "step": 3770
    },
    {
      "epoch": 6.263463131731566,
      "grad_norm": 0.4871222674846649,
      "learning_rate": 4.061089414328143e-05,
      "loss": 0.0115,
      "step": 3780
    },
    {
      "epoch": 6.28003314001657,
      "grad_norm": 0.04495728760957718,
      "learning_rate": 4.056184716967843e-05,
      "loss": 0.0061,
      "step": 3790
    },
    {
      "epoch": 6.296603148301574,
      "grad_norm": 0.18043102324008942,
      "learning_rate": 4.051280019607543e-05,
      "loss": 0.0078,
      "step": 3800
    },
    {
      "epoch": 6.313173156586578,
      "grad_norm": 0.27167370915412903,
      "learning_rate": 4.046375322247243e-05,
      "loss": 0.0047,
      "step": 3810
    },
    {
      "epoch": 6.329743164871583,
      "grad_norm": 1.2132662534713745,
      "learning_rate": 4.0414706248869435e-05,
      "loss": 0.0175,
      "step": 3820
    },
    {
      "epoch": 6.346313173156586,
      "grad_norm": 1.3016104698181152,
      "learning_rate": 4.036565927526644e-05,
      "loss": 0.0334,
      "step": 3830
    },
    {
      "epoch": 6.362883181441591,
      "grad_norm": 0.13855211436748505,
      "learning_rate": 4.0316612301663444e-05,
      "loss": 0.0096,
      "step": 3840
    },
    {
      "epoch": 6.379453189726595,
      "grad_norm": 0.6116520166397095,
      "learning_rate": 4.0267565328060446e-05,
      "loss": 0.0385,
      "step": 3850
    },
    {
      "epoch": 6.396023198011599,
      "grad_norm": 1.5702252388000488,
      "learning_rate": 4.021851835445745e-05,
      "loss": 0.0155,
      "step": 3860
    },
    {
      "epoch": 6.412593206296603,
      "grad_norm": 0.004596638958901167,
      "learning_rate": 4.016947138085445e-05,
      "loss": 0.007,
      "step": 3870
    },
    {
      "epoch": 6.4291632145816076,
      "grad_norm": 0.011722351424396038,
      "learning_rate": 4.012042440725146e-05,
      "loss": 0.0054,
      "step": 3880
    },
    {
      "epoch": 6.445733222866611,
      "grad_norm": 0.009474394842982292,
      "learning_rate": 4.007137743364846e-05,
      "loss": 0.0208,
      "step": 3890
    },
    {
      "epoch": 6.4623032311516155,
      "grad_norm": 0.0673629492521286,
      "learning_rate": 4.002233046004546e-05,
      "loss": 0.0113,
      "step": 3900
    },
    {
      "epoch": 6.47887323943662,
      "grad_norm": 0.1747005730867386,
      "learning_rate": 3.997328348644247e-05,
      "loss": 0.0144,
      "step": 3910
    },
    {
      "epoch": 6.4954432477216235,
      "grad_norm": 0.540241003036499,
      "learning_rate": 3.992423651283947e-05,
      "loss": 0.0101,
      "step": 3920
    },
    {
      "epoch": 6.512013256006628,
      "grad_norm": 0.07530730217695236,
      "learning_rate": 3.987518953923647e-05,
      "loss": 0.012,
      "step": 3930
    },
    {
      "epoch": 6.528583264291632,
      "grad_norm": 0.2542620897293091,
      "learning_rate": 3.9826142565633474e-05,
      "loss": 0.01,
      "step": 3940
    },
    {
      "epoch": 6.545153272576636,
      "grad_norm": 0.01496348436921835,
      "learning_rate": 3.9777095592030475e-05,
      "loss": 0.0111,
      "step": 3950
    },
    {
      "epoch": 6.56172328086164,
      "grad_norm": 0.08650138974189758,
      "learning_rate": 3.972804861842748e-05,
      "loss": 0.0072,
      "step": 3960
    },
    {
      "epoch": 6.578293289146645,
      "grad_norm": 0.3431137800216675,
      "learning_rate": 3.967900164482448e-05,
      "loss": 0.0068,
      "step": 3970
    },
    {
      "epoch": 6.594863297431648,
      "grad_norm": 0.002676299773156643,
      "learning_rate": 3.962995467122149e-05,
      "loss": 0.0378,
      "step": 3980
    },
    {
      "epoch": 6.611433305716653,
      "grad_norm": 0.0017771755810827017,
      "learning_rate": 3.9580907697618495e-05,
      "loss": 0.0176,
      "step": 3990
    },
    {
      "epoch": 6.628003314001657,
      "grad_norm": 0.668601930141449,
      "learning_rate": 3.95318607240155e-05,
      "loss": 0.0198,
      "step": 4000
    },
    {
      "epoch": 6.644573322286661,
      "grad_norm": 0.6763117909431458,
      "learning_rate": 3.94828137504125e-05,
      "loss": 0.0138,
      "step": 4010
    },
    {
      "epoch": 6.661143330571665,
      "grad_norm": 0.7090654373168945,
      "learning_rate": 3.94337667768095e-05,
      "loss": 0.0055,
      "step": 4020
    },
    {
      "epoch": 6.67771333885667,
      "grad_norm": 0.21422208845615387,
      "learning_rate": 3.93847198032065e-05,
      "loss": 0.0087,
      "step": 4030
    },
    {
      "epoch": 6.694283347141674,
      "grad_norm": 0.007370269391685724,
      "learning_rate": 3.93356728296035e-05,
      "loss": 0.0047,
      "step": 4040
    },
    {
      "epoch": 6.710853355426678,
      "grad_norm": 0.006634774152189493,
      "learning_rate": 3.9286625856000505e-05,
      "loss": 0.0055,
      "step": 4050
    },
    {
      "epoch": 6.727423363711682,
      "grad_norm": 0.1232924610376358,
      "learning_rate": 3.923757888239751e-05,
      "loss": 0.02,
      "step": 4060
    },
    {
      "epoch": 6.743993371996686,
      "grad_norm": 0.9787251353263855,
      "learning_rate": 3.9188531908794515e-05,
      "loss": 0.0071,
      "step": 4070
    },
    {
      "epoch": 6.76056338028169,
      "grad_norm": 0.13277308642864227,
      "learning_rate": 3.9139484935191516e-05,
      "loss": 0.009,
      "step": 4080
    },
    {
      "epoch": 6.7771333885666944,
      "grad_norm": 0.44744160771369934,
      "learning_rate": 3.9090437961588525e-05,
      "loss": 0.016,
      "step": 4090
    },
    {
      "epoch": 6.793703396851699,
      "grad_norm": 1.5714131593704224,
      "learning_rate": 3.9041390987985526e-05,
      "loss": 0.0118,
      "step": 4100
    },
    {
      "epoch": 6.810273405136702,
      "grad_norm": 0.26437464356422424,
      "learning_rate": 3.899234401438253e-05,
      "loss": 0.0168,
      "step": 4110
    },
    {
      "epoch": 6.826843413421707,
      "grad_norm": 1.5662775039672852,
      "learning_rate": 3.894329704077953e-05,
      "loss": 0.0115,
      "step": 4120
    },
    {
      "epoch": 6.84341342170671,
      "grad_norm": 0.0028753343503922224,
      "learning_rate": 3.889425006717654e-05,
      "loss": 0.0194,
      "step": 4130
    },
    {
      "epoch": 6.859983429991715,
      "grad_norm": 0.10013402253389359,
      "learning_rate": 3.884520309357354e-05,
      "loss": 0.0048,
      "step": 4140
    },
    {
      "epoch": 6.876553438276719,
      "grad_norm": 0.6276663541793823,
      "learning_rate": 3.879615611997054e-05,
      "loss": 0.003,
      "step": 4150
    },
    {
      "epoch": 6.893123446561724,
      "grad_norm": 0.26263031363487244,
      "learning_rate": 3.874710914636754e-05,
      "loss": 0.0028,
      "step": 4160
    },
    {
      "epoch": 6.909693454846727,
      "grad_norm": 1.6675779819488525,
      "learning_rate": 3.8698062172764544e-05,
      "loss": 0.006,
      "step": 4170
    },
    {
      "epoch": 6.926263463131732,
      "grad_norm": 0.03706160560250282,
      "learning_rate": 3.8649015199161545e-05,
      "loss": 0.0107,
      "step": 4180
    },
    {
      "epoch": 6.942833471416735,
      "grad_norm": 0.06663642823696136,
      "learning_rate": 3.859996822555855e-05,
      "loss": 0.0201,
      "step": 4190
    },
    {
      "epoch": 6.95940347970174,
      "grad_norm": 0.002534350147470832,
      "learning_rate": 3.8550921251955555e-05,
      "loss": 0.0155,
      "step": 4200
    },
    {
      "epoch": 6.975973487986744,
      "grad_norm": 0.002361348830163479,
      "learning_rate": 3.8501874278352564e-05,
      "loss": 0.0088,
      "step": 4210
    },
    {
      "epoch": 6.9925434962717485,
      "grad_norm": 0.18222947418689728,
      "learning_rate": 3.8452827304749565e-05,
      "loss": 0.0108,
      "step": 4220
    },
    {
      "epoch": 6.99917149958575,
      "eval_accuracy": 0.9928675048355899,
      "eval_f1": 0.9595613433858807,
      "eval_loss": 0.021246926859021187,
      "eval_precision": 0.9943181818181818,
      "eval_recall": 0.9271523178807947,
      "eval_runtime": 1953.4396,
      "eval_samples_per_second": 4.237,
      "eval_steps_per_second": 0.53,
      "step": 4224
    },
    {
      "epoch": 6.99917149958575,
      "eval_accuracy": 0.9928675048355899,
      "eval_f1": 0.9595613433858807,
      "eval_loss": 0.021246926859021187,
      "eval_precision": 0.9943181818181818,
      "eval_recall": 0.9271523178807947,
      "eval_runtime": 1994.2217,
      "eval_samples_per_second": 4.15,
      "eval_steps_per_second": 0.519,
      "step": 4224
    }
  ],
  "logging_steps": 10,
  "max_steps": 12060,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.049348327383552e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": {
    "epochs": 20,
    "gradient_accumulation_steps": 4,
    "learning_rate": 5.67473484586674e-05,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 16,
    "warmup_steps": 490,
    "weight_decay": 0.08437036567854012
  }
}
