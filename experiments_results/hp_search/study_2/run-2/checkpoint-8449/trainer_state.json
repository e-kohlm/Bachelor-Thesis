{
  "best_metric": 0.9629130141604855,
  "best_model_checkpoint": "../hyperparameter_search/run-2/checkpoint-8449",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 8449,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008285004142502071,
      "grad_norm": 84.08092498779297,
      "learning_rate": 6.5791986889497e-08,
      "loss": 0.7424,
      "step": 1
    },
    {
      "epoch": 0.008285004142502071,
      "grad_norm": 33.43291091918945,
      "learning_rate": 6.579198688949701e-07,
      "loss": 0.8548,
      "step": 10
    },
    {
      "epoch": 0.016570008285004142,
      "grad_norm": 47.08543395996094,
      "learning_rate": 1.3158397377899402e-06,
      "loss": 0.7345,
      "step": 20
    },
    {
      "epoch": 0.024855012427506214,
      "grad_norm": 25.92664337158203,
      "learning_rate": 1.97375960668491e-06,
      "loss": 0.5717,
      "step": 30
    },
    {
      "epoch": 0.033140016570008285,
      "grad_norm": 22.28635597229004,
      "learning_rate": 2.6316794755798804e-06,
      "loss": 0.4651,
      "step": 40
    },
    {
      "epoch": 0.041425020712510356,
      "grad_norm": 18.690338134765625,
      "learning_rate": 3.28959934447485e-06,
      "loss": 0.3636,
      "step": 50
    },
    {
      "epoch": 0.04971002485501243,
      "grad_norm": 32.13459014892578,
      "learning_rate": 3.94751921336982e-06,
      "loss": 0.3608,
      "step": 60
    },
    {
      "epoch": 0.0579950289975145,
      "grad_norm": 18.896440505981445,
      "learning_rate": 4.60543908226479e-06,
      "loss": 0.3872,
      "step": 70
    },
    {
      "epoch": 0.06628003314001657,
      "grad_norm": 21.821910858154297,
      "learning_rate": 5.263358951159761e-06,
      "loss": 0.2844,
      "step": 80
    },
    {
      "epoch": 0.07456503728251865,
      "grad_norm": 91.12966918945312,
      "learning_rate": 5.92127882005473e-06,
      "loss": 0.2982,
      "step": 90
    },
    {
      "epoch": 0.08285004142502071,
      "grad_norm": 21.49425506591797,
      "learning_rate": 6.5791986889497e-06,
      "loss": 0.3653,
      "step": 100
    },
    {
      "epoch": 0.09113504556752279,
      "grad_norm": 14.933799743652344,
      "learning_rate": 7.23711855784467e-06,
      "loss": 0.2494,
      "step": 110
    },
    {
      "epoch": 0.09942004971002485,
      "grad_norm": 23.9744873046875,
      "learning_rate": 7.89503842673964e-06,
      "loss": 0.392,
      "step": 120
    },
    {
      "epoch": 0.10770505385252693,
      "grad_norm": 15.829710960388184,
      "learning_rate": 8.55295829563461e-06,
      "loss": 0.2903,
      "step": 130
    },
    {
      "epoch": 0.115990057995029,
      "grad_norm": 28.03322410583496,
      "learning_rate": 9.078283527402142e-06,
      "loss": 0.3044,
      "step": 140
    },
    {
      "epoch": 0.12427506213753108,
      "grad_norm": 14.315386772155762,
      "learning_rate": 9.07323021065992e-06,
      "loss": 0.2942,
      "step": 150
    },
    {
      "epoch": 0.13256006628003314,
      "grad_norm": 16.864091873168945,
      "learning_rate": 9.068176893917698e-06,
      "loss": 0.3423,
      "step": 160
    },
    {
      "epoch": 0.14084507042253522,
      "grad_norm": 19.64238739013672,
      "learning_rate": 9.063123577175476e-06,
      "loss": 0.2844,
      "step": 170
    },
    {
      "epoch": 0.1491300745650373,
      "grad_norm": 17.879154205322266,
      "learning_rate": 9.058070260433253e-06,
      "loss": 0.2956,
      "step": 180
    },
    {
      "epoch": 0.15741507870753935,
      "grad_norm": 13.320667266845703,
      "learning_rate": 9.053016943691031e-06,
      "loss": 0.2952,
      "step": 190
    },
    {
      "epoch": 0.16570008285004142,
      "grad_norm": 17.40520668029785,
      "learning_rate": 9.04796362694881e-06,
      "loss": 0.2487,
      "step": 200
    },
    {
      "epoch": 0.1739850869925435,
      "grad_norm": 15.260472297668457,
      "learning_rate": 9.042910310206588e-06,
      "loss": 0.3214,
      "step": 210
    },
    {
      "epoch": 0.18227009113504558,
      "grad_norm": 8.029084205627441,
      "learning_rate": 9.037856993464364e-06,
      "loss": 0.2126,
      "step": 220
    },
    {
      "epoch": 0.19055509527754763,
      "grad_norm": 39.35014724731445,
      "learning_rate": 9.032803676722143e-06,
      "loss": 0.3092,
      "step": 230
    },
    {
      "epoch": 0.1988400994200497,
      "grad_norm": 17.252431869506836,
      "learning_rate": 9.02775035997992e-06,
      "loss": 0.2992,
      "step": 240
    },
    {
      "epoch": 0.2071251035625518,
      "grad_norm": 10.448795318603516,
      "learning_rate": 9.022697043237697e-06,
      "loss": 0.3264,
      "step": 250
    },
    {
      "epoch": 0.21541010770505387,
      "grad_norm": 37.84086990356445,
      "learning_rate": 9.017643726495476e-06,
      "loss": 0.3065,
      "step": 260
    },
    {
      "epoch": 0.22369511184755592,
      "grad_norm": 11.661465644836426,
      "learning_rate": 9.012590409753254e-06,
      "loss": 0.2191,
      "step": 270
    },
    {
      "epoch": 0.231980115990058,
      "grad_norm": 16.051984786987305,
      "learning_rate": 9.007537093011032e-06,
      "loss": 0.2849,
      "step": 280
    },
    {
      "epoch": 0.24026512013256007,
      "grad_norm": 13.051770210266113,
      "learning_rate": 9.002483776268809e-06,
      "loss": 0.2828,
      "step": 290
    },
    {
      "epoch": 0.24855012427506215,
      "grad_norm": 13.35865306854248,
      "learning_rate": 8.997430459526587e-06,
      "loss": 0.219,
      "step": 300
    },
    {
      "epoch": 0.25683512841756423,
      "grad_norm": 18.17281150817871,
      "learning_rate": 8.992377142784365e-06,
      "loss": 0.181,
      "step": 310
    },
    {
      "epoch": 0.2651201325600663,
      "grad_norm": 27.957534790039062,
      "learning_rate": 8.987323826042142e-06,
      "loss": 0.3014,
      "step": 320
    },
    {
      "epoch": 0.27340513670256833,
      "grad_norm": 16.818635940551758,
      "learning_rate": 8.98227050929992e-06,
      "loss": 0.2508,
      "step": 330
    },
    {
      "epoch": 0.28169014084507044,
      "grad_norm": 8.394221305847168,
      "learning_rate": 8.977217192557698e-06,
      "loss": 0.1722,
      "step": 340
    },
    {
      "epoch": 0.2899751449875725,
      "grad_norm": 17.618284225463867,
      "learning_rate": 8.972163875815476e-06,
      "loss": 0.2724,
      "step": 350
    },
    {
      "epoch": 0.2982601491300746,
      "grad_norm": 12.508604049682617,
      "learning_rate": 8.967110559073253e-06,
      "loss": 0.3308,
      "step": 360
    },
    {
      "epoch": 0.30654515327257664,
      "grad_norm": 7.45387077331543,
      "learning_rate": 8.962057242331031e-06,
      "loss": 0.1609,
      "step": 370
    },
    {
      "epoch": 0.3148301574150787,
      "grad_norm": 12.87486743927002,
      "learning_rate": 8.95700392558881e-06,
      "loss": 0.2399,
      "step": 380
    },
    {
      "epoch": 0.3231151615575808,
      "grad_norm": 8.453543663024902,
      "learning_rate": 8.951950608846588e-06,
      "loss": 0.2431,
      "step": 390
    },
    {
      "epoch": 0.33140016570008285,
      "grad_norm": 8.3956880569458,
      "learning_rate": 8.946897292104364e-06,
      "loss": 0.3081,
      "step": 400
    },
    {
      "epoch": 0.3396851698425849,
      "grad_norm": 16.73734474182129,
      "learning_rate": 8.941843975362143e-06,
      "loss": 0.2109,
      "step": 410
    },
    {
      "epoch": 0.347970173985087,
      "grad_norm": 4.235161781311035,
      "learning_rate": 8.936790658619921e-06,
      "loss": 0.1999,
      "step": 420
    },
    {
      "epoch": 0.35625517812758906,
      "grad_norm": 14.0466890335083,
      "learning_rate": 8.931737341877699e-06,
      "loss": 0.2133,
      "step": 430
    },
    {
      "epoch": 0.36454018227009116,
      "grad_norm": 13.818334579467773,
      "learning_rate": 8.926684025135476e-06,
      "loss": 0.2546,
      "step": 440
    },
    {
      "epoch": 0.3728251864125932,
      "grad_norm": 7.189779281616211,
      "learning_rate": 8.921630708393254e-06,
      "loss": 0.2401,
      "step": 450
    },
    {
      "epoch": 0.38111019055509526,
      "grad_norm": 10.315874099731445,
      "learning_rate": 8.916577391651032e-06,
      "loss": 0.2295,
      "step": 460
    },
    {
      "epoch": 0.38939519469759737,
      "grad_norm": 9.402329444885254,
      "learning_rate": 8.91152407490881e-06,
      "loss": 0.2486,
      "step": 470
    },
    {
      "epoch": 0.3976801988400994,
      "grad_norm": 5.961086750030518,
      "learning_rate": 8.906470758166587e-06,
      "loss": 0.2056,
      "step": 480
    },
    {
      "epoch": 0.40596520298260147,
      "grad_norm": 9.23922348022461,
      "learning_rate": 8.901417441424365e-06,
      "loss": 0.2317,
      "step": 490
    },
    {
      "epoch": 0.4142502071251036,
      "grad_norm": 13.754563331604004,
      "learning_rate": 8.896364124682144e-06,
      "loss": 0.2035,
      "step": 500
    },
    {
      "epoch": 0.4225352112676056,
      "grad_norm": 7.719964504241943,
      "learning_rate": 8.891310807939922e-06,
      "loss": 0.1883,
      "step": 510
    },
    {
      "epoch": 0.43082021541010773,
      "grad_norm": 11.516236305236816,
      "learning_rate": 8.8862574911977e-06,
      "loss": 0.2217,
      "step": 520
    },
    {
      "epoch": 0.4391052195526098,
      "grad_norm": 13.156454086303711,
      "learning_rate": 8.881204174455477e-06,
      "loss": 0.2275,
      "step": 530
    },
    {
      "epoch": 0.44739022369511183,
      "grad_norm": 9.252042770385742,
      "learning_rate": 8.876150857713255e-06,
      "loss": 0.1949,
      "step": 540
    },
    {
      "epoch": 0.45567522783761394,
      "grad_norm": 1.9957886934280396,
      "learning_rate": 8.871097540971033e-06,
      "loss": 0.2154,
      "step": 550
    },
    {
      "epoch": 0.463960231980116,
      "grad_norm": 11.056687355041504,
      "learning_rate": 8.866044224228811e-06,
      "loss": 0.2403,
      "step": 560
    },
    {
      "epoch": 0.47224523612261804,
      "grad_norm": 11.016351699829102,
      "learning_rate": 8.860990907486588e-06,
      "loss": 0.1939,
      "step": 570
    },
    {
      "epoch": 0.48053024026512015,
      "grad_norm": 9.504632949829102,
      "learning_rate": 8.855937590744366e-06,
      "loss": 0.1808,
      "step": 580
    },
    {
      "epoch": 0.4888152444076222,
      "grad_norm": 12.0668306350708,
      "learning_rate": 8.850884274002144e-06,
      "loss": 0.1814,
      "step": 590
    },
    {
      "epoch": 0.4971002485501243,
      "grad_norm": 7.859781742095947,
      "learning_rate": 8.845830957259923e-06,
      "loss": 0.2022,
      "step": 600
    },
    {
      "epoch": 0.5053852526926264,
      "grad_norm": 11.595061302185059,
      "learning_rate": 8.8407776405177e-06,
      "loss": 0.1965,
      "step": 610
    },
    {
      "epoch": 0.5136702568351285,
      "grad_norm": 10.869845390319824,
      "learning_rate": 8.835724323775477e-06,
      "loss": 0.228,
      "step": 620
    },
    {
      "epoch": 0.5219552609776305,
      "grad_norm": 9.787540435791016,
      "learning_rate": 8.830671007033256e-06,
      "loss": 0.1993,
      "step": 630
    },
    {
      "epoch": 0.5302402651201326,
      "grad_norm": 6.620828628540039,
      "learning_rate": 8.825617690291034e-06,
      "loss": 0.1567,
      "step": 640
    },
    {
      "epoch": 0.5385252692626347,
      "grad_norm": 9.856879234313965,
      "learning_rate": 8.82056437354881e-06,
      "loss": 0.1316,
      "step": 650
    },
    {
      "epoch": 0.5468102734051367,
      "grad_norm": 6.079031944274902,
      "learning_rate": 8.815511056806589e-06,
      "loss": 0.168,
      "step": 660
    },
    {
      "epoch": 0.5550952775476388,
      "grad_norm": 135.76235961914062,
      "learning_rate": 8.810457740064367e-06,
      "loss": 0.229,
      "step": 670
    },
    {
      "epoch": 0.5633802816901409,
      "grad_norm": 4.0197272300720215,
      "learning_rate": 8.805404423322144e-06,
      "loss": 0.1524,
      "step": 680
    },
    {
      "epoch": 0.5716652858326429,
      "grad_norm": 8.83323860168457,
      "learning_rate": 8.800351106579922e-06,
      "loss": 0.1935,
      "step": 690
    },
    {
      "epoch": 0.579950289975145,
      "grad_norm": 5.247686862945557,
      "learning_rate": 8.7952977898377e-06,
      "loss": 0.154,
      "step": 700
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 5.954621315002441,
      "learning_rate": 8.790244473095478e-06,
      "loss": 0.2095,
      "step": 710
    },
    {
      "epoch": 0.5965202982601492,
      "grad_norm": 5.934857368469238,
      "learning_rate": 8.785191156353255e-06,
      "loss": 0.1785,
      "step": 720
    },
    {
      "epoch": 0.6048053024026512,
      "grad_norm": 24.831077575683594,
      "learning_rate": 8.780137839611033e-06,
      "loss": 0.1845,
      "step": 730
    },
    {
      "epoch": 0.6130903065451533,
      "grad_norm": 6.3604655265808105,
      "learning_rate": 8.775084522868811e-06,
      "loss": 0.1495,
      "step": 740
    },
    {
      "epoch": 0.6213753106876554,
      "grad_norm": 5.243675231933594,
      "learning_rate": 8.770031206126588e-06,
      "loss": 0.1852,
      "step": 750
    },
    {
      "epoch": 0.6296603148301574,
      "grad_norm": 7.885067939758301,
      "learning_rate": 8.764977889384366e-06,
      "loss": 0.1598,
      "step": 760
    },
    {
      "epoch": 0.6379453189726595,
      "grad_norm": 12.305590629577637,
      "learning_rate": 8.759924572642145e-06,
      "loss": 0.1874,
      "step": 770
    },
    {
      "epoch": 0.6462303231151616,
      "grad_norm": 11.017467498779297,
      "learning_rate": 8.754871255899923e-06,
      "loss": 0.12,
      "step": 780
    },
    {
      "epoch": 0.6545153272576636,
      "grad_norm": 3.799776792526245,
      "learning_rate": 8.7498179391577e-06,
      "loss": 0.1674,
      "step": 790
    },
    {
      "epoch": 0.6628003314001657,
      "grad_norm": 6.892767429351807,
      "learning_rate": 8.744764622415478e-06,
      "loss": 0.1581,
      "step": 800
    },
    {
      "epoch": 0.6710853355426678,
      "grad_norm": 8.935501098632812,
      "learning_rate": 8.739711305673256e-06,
      "loss": 0.1596,
      "step": 810
    },
    {
      "epoch": 0.6793703396851698,
      "grad_norm": 5.8511810302734375,
      "learning_rate": 8.734657988931034e-06,
      "loss": 0.1387,
      "step": 820
    },
    {
      "epoch": 0.6876553438276719,
      "grad_norm": 8.64247989654541,
      "learning_rate": 8.72960467218881e-06,
      "loss": 0.1515,
      "step": 830
    },
    {
      "epoch": 0.695940347970174,
      "grad_norm": 7.8312788009643555,
      "learning_rate": 8.724551355446589e-06,
      "loss": 0.1543,
      "step": 840
    },
    {
      "epoch": 0.704225352112676,
      "grad_norm": 6.822661876678467,
      "learning_rate": 8.719498038704367e-06,
      "loss": 0.1478,
      "step": 850
    },
    {
      "epoch": 0.7125103562551781,
      "grad_norm": 9.580070495605469,
      "learning_rate": 8.714444721962145e-06,
      "loss": 0.1422,
      "step": 860
    },
    {
      "epoch": 0.7207953603976802,
      "grad_norm": 7.363261699676514,
      "learning_rate": 8.709391405219922e-06,
      "loss": 0.1489,
      "step": 870
    },
    {
      "epoch": 0.7290803645401823,
      "grad_norm": 1.537235140800476,
      "learning_rate": 8.7043380884777e-06,
      "loss": 0.1584,
      "step": 880
    },
    {
      "epoch": 0.7373653686826843,
      "grad_norm": 4.0300092697143555,
      "learning_rate": 8.699284771735478e-06,
      "loss": 0.157,
      "step": 890
    },
    {
      "epoch": 0.7456503728251864,
      "grad_norm": 5.95357608795166,
      "learning_rate": 8.694231454993257e-06,
      "loss": 0.1515,
      "step": 900
    },
    {
      "epoch": 0.7539353769676885,
      "grad_norm": 163.3026123046875,
      "learning_rate": 8.689178138251035e-06,
      "loss": 0.1709,
      "step": 910
    },
    {
      "epoch": 0.7622203811101905,
      "grad_norm": 5.244248867034912,
      "learning_rate": 8.684124821508812e-06,
      "loss": 0.0987,
      "step": 920
    },
    {
      "epoch": 0.7705053852526926,
      "grad_norm": 6.578812599182129,
      "learning_rate": 8.67907150476659e-06,
      "loss": 0.1387,
      "step": 930
    },
    {
      "epoch": 0.7787903893951947,
      "grad_norm": 2.571666955947876,
      "learning_rate": 8.674018188024368e-06,
      "loss": 0.1257,
      "step": 940
    },
    {
      "epoch": 0.7870753935376967,
      "grad_norm": 2.7535064220428467,
      "learning_rate": 8.668964871282146e-06,
      "loss": 0.1689,
      "step": 950
    },
    {
      "epoch": 0.7953603976801988,
      "grad_norm": 6.628139495849609,
      "learning_rate": 8.663911554539923e-06,
      "loss": 0.1123,
      "step": 960
    },
    {
      "epoch": 0.8036454018227009,
      "grad_norm": 6.650729179382324,
      "learning_rate": 8.658858237797701e-06,
      "loss": 0.1217,
      "step": 970
    },
    {
      "epoch": 0.8119304059652029,
      "grad_norm": 8.030447959899902,
      "learning_rate": 8.65380492105548e-06,
      "loss": 0.1547,
      "step": 980
    },
    {
      "epoch": 0.820215410107705,
      "grad_norm": 2.286123275756836,
      "learning_rate": 8.648751604313258e-06,
      "loss": 0.0908,
      "step": 990
    },
    {
      "epoch": 0.8285004142502072,
      "grad_norm": 6.39274263381958,
      "learning_rate": 8.643698287571034e-06,
      "loss": 0.1217,
      "step": 1000
    },
    {
      "epoch": 0.8367854183927091,
      "grad_norm": 8.123185157775879,
      "learning_rate": 8.638644970828812e-06,
      "loss": 0.0849,
      "step": 1010
    },
    {
      "epoch": 0.8450704225352113,
      "grad_norm": 10.105095863342285,
      "learning_rate": 8.63359165408659e-06,
      "loss": 0.154,
      "step": 1020
    },
    {
      "epoch": 0.8533554266777134,
      "grad_norm": 10.247477531433105,
      "learning_rate": 8.628538337344369e-06,
      "loss": 0.1607,
      "step": 1030
    },
    {
      "epoch": 0.8616404308202155,
      "grad_norm": 19.30020523071289,
      "learning_rate": 8.623485020602146e-06,
      "loss": 0.1077,
      "step": 1040
    },
    {
      "epoch": 0.8699254349627175,
      "grad_norm": 5.0251851081848145,
      "learning_rate": 8.618431703859924e-06,
      "loss": 0.1659,
      "step": 1050
    },
    {
      "epoch": 0.8782104391052196,
      "grad_norm": 14.564702033996582,
      "learning_rate": 8.613378387117702e-06,
      "loss": 0.1317,
      "step": 1060
    },
    {
      "epoch": 0.8864954432477217,
      "grad_norm": 7.551034927368164,
      "learning_rate": 8.60832507037548e-06,
      "loss": 0.1222,
      "step": 1070
    },
    {
      "epoch": 0.8947804473902237,
      "grad_norm": 6.1582560539245605,
      "learning_rate": 8.603271753633257e-06,
      "loss": 0.1184,
      "step": 1080
    },
    {
      "epoch": 0.9030654515327258,
      "grad_norm": 14.305971145629883,
      "learning_rate": 8.598218436891035e-06,
      "loss": 0.1134,
      "step": 1090
    },
    {
      "epoch": 0.9113504556752279,
      "grad_norm": 2.5290184020996094,
      "learning_rate": 8.593165120148813e-06,
      "loss": 0.0851,
      "step": 1100
    },
    {
      "epoch": 0.9196354598177299,
      "grad_norm": 1.5713075399398804,
      "learning_rate": 8.58811180340659e-06,
      "loss": 0.0692,
      "step": 1110
    },
    {
      "epoch": 0.927920463960232,
      "grad_norm": 6.797249794006348,
      "learning_rate": 8.583058486664368e-06,
      "loss": 0.0684,
      "step": 1120
    },
    {
      "epoch": 0.9362054681027341,
      "grad_norm": 6.4700541496276855,
      "learning_rate": 8.578005169922146e-06,
      "loss": 0.1023,
      "step": 1130
    },
    {
      "epoch": 0.9444904722452361,
      "grad_norm": 13.812623023986816,
      "learning_rate": 8.572951853179925e-06,
      "loss": 0.0858,
      "step": 1140
    },
    {
      "epoch": 0.9527754763877382,
      "grad_norm": 3.7303037643432617,
      "learning_rate": 8.567898536437701e-06,
      "loss": 0.055,
      "step": 1150
    },
    {
      "epoch": 0.9610604805302403,
      "grad_norm": 7.957231044769287,
      "learning_rate": 8.56284521969548e-06,
      "loss": 0.1129,
      "step": 1160
    },
    {
      "epoch": 0.9693454846727423,
      "grad_norm": 8.943323135375977,
      "learning_rate": 8.557791902953258e-06,
      "loss": 0.0791,
      "step": 1170
    },
    {
      "epoch": 0.9776304888152444,
      "grad_norm": 6.826103210449219,
      "learning_rate": 8.552738586211034e-06,
      "loss": 0.0943,
      "step": 1180
    },
    {
      "epoch": 0.9859154929577465,
      "grad_norm": 2.7131459712982178,
      "learning_rate": 8.547685269468813e-06,
      "loss": 0.0942,
      "step": 1190
    },
    {
      "epoch": 0.9942004971002486,
      "grad_norm": 5.820192337036133,
      "learning_rate": 8.54263195272659e-06,
      "loss": 0.1089,
      "step": 1200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9711073500967118,
      "eval_f1": 0.8343728343728344,
      "eval_loss": 0.08286203444004059,
      "eval_precision": 0.875,
      "eval_recall": 0.7973509933774835,
      "eval_runtime": 1226.0877,
      "eval_samples_per_second": 6.751,
      "eval_steps_per_second": 0.844,
      "step": 1207
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9711073500967118,
      "eval_f1": 0.8343728343728344,
      "eval_loss": 0.08286203444004059,
      "eval_precision": 0.875,
      "eval_recall": 0.7973509933774835,
      "eval_runtime": 1222.779,
      "eval_samples_per_second": 6.769,
      "eval_steps_per_second": 0.846,
      "step": 1207
    },
    {
      "epoch": 1.0024855012427507,
      "grad_norm": 7.084474086761475,
      "learning_rate": 8.537578635984369e-06,
      "loss": 0.0901,
      "step": 1210
    },
    {
      "epoch": 1.0107705053852527,
      "grad_norm": 2.433769702911377,
      "learning_rate": 8.532525319242146e-06,
      "loss": 0.0906,
      "step": 1220
    },
    {
      "epoch": 1.0190555095277547,
      "grad_norm": 7.995697498321533,
      "learning_rate": 8.527472002499924e-06,
      "loss": 0.0807,
      "step": 1230
    },
    {
      "epoch": 1.027340513670257,
      "grad_norm": 4.940711975097656,
      "learning_rate": 8.522418685757702e-06,
      "loss": 0.0626,
      "step": 1240
    },
    {
      "epoch": 1.035625517812759,
      "grad_norm": 3.2250022888183594,
      "learning_rate": 8.51736536901548e-06,
      "loss": 0.0815,
      "step": 1250
    },
    {
      "epoch": 1.043910521955261,
      "grad_norm": 39.50357437133789,
      "learning_rate": 8.512312052273257e-06,
      "loss": 0.0775,
      "step": 1260
    },
    {
      "epoch": 1.0521955260977631,
      "grad_norm": 6.367577075958252,
      "learning_rate": 8.507258735531035e-06,
      "loss": 0.0719,
      "step": 1270
    },
    {
      "epoch": 1.0604805302402651,
      "grad_norm": 6.784246921539307,
      "learning_rate": 8.502205418788813e-06,
      "loss": 0.0613,
      "step": 1280
    },
    {
      "epoch": 1.0687655343827671,
      "grad_norm": 7.790759563446045,
      "learning_rate": 8.497152102046592e-06,
      "loss": 0.0707,
      "step": 1290
    },
    {
      "epoch": 1.0770505385252693,
      "grad_norm": 7.026669979095459,
      "learning_rate": 8.49209878530437e-06,
      "loss": 0.0599,
      "step": 1300
    },
    {
      "epoch": 1.0853355426677713,
      "grad_norm": 1.1724615097045898,
      "learning_rate": 8.487045468562147e-06,
      "loss": 0.0769,
      "step": 1310
    },
    {
      "epoch": 1.0936205468102733,
      "grad_norm": 9.612443923950195,
      "learning_rate": 8.481992151819925e-06,
      "loss": 0.1414,
      "step": 1320
    },
    {
      "epoch": 1.1019055509527755,
      "grad_norm": 7.529407024383545,
      "learning_rate": 8.476938835077703e-06,
      "loss": 0.1076,
      "step": 1330
    },
    {
      "epoch": 1.1101905550952775,
      "grad_norm": 0.5210123062133789,
      "learning_rate": 8.471885518335481e-06,
      "loss": 0.0685,
      "step": 1340
    },
    {
      "epoch": 1.1184755592377795,
      "grad_norm": 8.95743179321289,
      "learning_rate": 8.466832201593258e-06,
      "loss": 0.1262,
      "step": 1350
    },
    {
      "epoch": 1.1267605633802817,
      "grad_norm": 3.6959667205810547,
      "learning_rate": 8.461778884851036e-06,
      "loss": 0.0884,
      "step": 1360
    },
    {
      "epoch": 1.1350455675227837,
      "grad_norm": 5.303630352020264,
      "learning_rate": 8.456725568108814e-06,
      "loss": 0.0726,
      "step": 1370
    },
    {
      "epoch": 1.143330571665286,
      "grad_norm": 0.1431392878293991,
      "learning_rate": 8.451672251366593e-06,
      "loss": 0.0624,
      "step": 1380
    },
    {
      "epoch": 1.151615575807788,
      "grad_norm": 10.287715911865234,
      "learning_rate": 8.44661893462437e-06,
      "loss": 0.0797,
      "step": 1390
    },
    {
      "epoch": 1.15990057995029,
      "grad_norm": 6.087654113769531,
      "learning_rate": 8.441565617882147e-06,
      "loss": 0.0584,
      "step": 1400
    },
    {
      "epoch": 1.1681855840927922,
      "grad_norm": 1.636445164680481,
      "learning_rate": 8.436512301139926e-06,
      "loss": 0.0316,
      "step": 1410
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 11.772896766662598,
      "learning_rate": 8.431458984397704e-06,
      "loss": 0.0964,
      "step": 1420
    },
    {
      "epoch": 1.1847555923777962,
      "grad_norm": 11.250575065612793,
      "learning_rate": 8.426405667655482e-06,
      "loss": 0.0732,
      "step": 1430
    },
    {
      "epoch": 1.1930405965202984,
      "grad_norm": 14.908432006835938,
      "learning_rate": 8.421352350913259e-06,
      "loss": 0.0973,
      "step": 1440
    },
    {
      "epoch": 1.2013256006628004,
      "grad_norm": 15.870579719543457,
      "learning_rate": 8.416299034171037e-06,
      "loss": 0.1033,
      "step": 1450
    },
    {
      "epoch": 1.2096106048053024,
      "grad_norm": 2.5632121562957764,
      "learning_rate": 8.411245717428815e-06,
      "loss": 0.1454,
      "step": 1460
    },
    {
      "epoch": 1.2178956089478046,
      "grad_norm": 0.7160834074020386,
      "learning_rate": 8.406192400686594e-06,
      "loss": 0.034,
      "step": 1470
    },
    {
      "epoch": 1.2261806130903066,
      "grad_norm": 6.371807098388672,
      "learning_rate": 8.40113908394437e-06,
      "loss": 0.1017,
      "step": 1480
    },
    {
      "epoch": 1.2344656172328086,
      "grad_norm": 2.7721328735351562,
      "learning_rate": 8.396085767202148e-06,
      "loss": 0.04,
      "step": 1490
    },
    {
      "epoch": 1.2427506213753108,
      "grad_norm": 7.602298736572266,
      "learning_rate": 8.391032450459927e-06,
      "loss": 0.0876,
      "step": 1500
    },
    {
      "epoch": 1.2510356255178128,
      "grad_norm": 9.69300651550293,
      "learning_rate": 8.385979133717703e-06,
      "loss": 0.0893,
      "step": 1510
    },
    {
      "epoch": 1.2593206296603148,
      "grad_norm": 4.264705181121826,
      "learning_rate": 8.380925816975481e-06,
      "loss": 0.0638,
      "step": 1520
    },
    {
      "epoch": 1.267605633802817,
      "grad_norm": 4.423193454742432,
      "learning_rate": 8.37587250023326e-06,
      "loss": 0.1011,
      "step": 1530
    },
    {
      "epoch": 1.275890637945319,
      "grad_norm": 16.252742767333984,
      "learning_rate": 8.370819183491036e-06,
      "loss": 0.0509,
      "step": 1540
    },
    {
      "epoch": 1.284175642087821,
      "grad_norm": 13.955796241760254,
      "learning_rate": 8.365765866748814e-06,
      "loss": 0.0961,
      "step": 1550
    },
    {
      "epoch": 1.2924606462303232,
      "grad_norm": 9.812834739685059,
      "learning_rate": 8.360712550006593e-06,
      "loss": 0.0829,
      "step": 1560
    },
    {
      "epoch": 1.3007456503728252,
      "grad_norm": 10.416004180908203,
      "learning_rate": 8.355659233264371e-06,
      "loss": 0.0689,
      "step": 1570
    },
    {
      "epoch": 1.3090306545153272,
      "grad_norm": 7.393953323364258,
      "learning_rate": 8.350605916522148e-06,
      "loss": 0.1037,
      "step": 1580
    },
    {
      "epoch": 1.3173156586578294,
      "grad_norm": 0.9485092759132385,
      "learning_rate": 8.345552599779926e-06,
      "loss": 0.0749,
      "step": 1590
    },
    {
      "epoch": 1.3256006628003314,
      "grad_norm": 1.0308181047439575,
      "learning_rate": 8.340499283037704e-06,
      "loss": 0.1207,
      "step": 1600
    },
    {
      "epoch": 1.3338856669428334,
      "grad_norm": 6.3985276222229,
      "learning_rate": 8.33544596629548e-06,
      "loss": 0.0962,
      "step": 1610
    },
    {
      "epoch": 1.3421706710853356,
      "grad_norm": 14.348546028137207,
      "learning_rate": 8.330392649553259e-06,
      "loss": 0.0838,
      "step": 1620
    },
    {
      "epoch": 1.3504556752278376,
      "grad_norm": 3.4008333683013916,
      "learning_rate": 8.325339332811037e-06,
      "loss": 0.0315,
      "step": 1630
    },
    {
      "epoch": 1.3587406793703396,
      "grad_norm": 4.329814910888672,
      "learning_rate": 8.320286016068815e-06,
      "loss": 0.0422,
      "step": 1640
    },
    {
      "epoch": 1.3670256835128418,
      "grad_norm": 9.747529983520508,
      "learning_rate": 8.315232699326592e-06,
      "loss": 0.1183,
      "step": 1650
    },
    {
      "epoch": 1.3753106876553438,
      "grad_norm": 3.32104754447937,
      "learning_rate": 8.31017938258437e-06,
      "loss": 0.0394,
      "step": 1660
    },
    {
      "epoch": 1.3835956917978458,
      "grad_norm": 10.538158416748047,
      "learning_rate": 8.305126065842148e-06,
      "loss": 0.0601,
      "step": 1670
    },
    {
      "epoch": 1.391880695940348,
      "grad_norm": 8.68061351776123,
      "learning_rate": 8.300072749099927e-06,
      "loss": 0.0883,
      "step": 1680
    },
    {
      "epoch": 1.40016570008285,
      "grad_norm": 5.3449015617370605,
      "learning_rate": 8.295019432357705e-06,
      "loss": 0.0948,
      "step": 1690
    },
    {
      "epoch": 1.408450704225352,
      "grad_norm": 12.059290885925293,
      "learning_rate": 8.289966115615482e-06,
      "loss": 0.0742,
      "step": 1700
    },
    {
      "epoch": 1.4167357083678542,
      "grad_norm": 8.966198921203613,
      "learning_rate": 8.28491279887326e-06,
      "loss": 0.0736,
      "step": 1710
    },
    {
      "epoch": 1.4250207125103562,
      "grad_norm": 2.9841678142547607,
      "learning_rate": 8.279859482131038e-06,
      "loss": 0.0775,
      "step": 1720
    },
    {
      "epoch": 1.4333057166528582,
      "grad_norm": 4.58912992477417,
      "learning_rate": 8.274806165388816e-06,
      "loss": 0.0342,
      "step": 1730
    },
    {
      "epoch": 1.4415907207953604,
      "grad_norm": 7.460705280303955,
      "learning_rate": 8.269752848646593e-06,
      "loss": 0.0389,
      "step": 1740
    },
    {
      "epoch": 1.4498757249378624,
      "grad_norm": 0.5308708548545837,
      "learning_rate": 8.264699531904371e-06,
      "loss": 0.049,
      "step": 1750
    },
    {
      "epoch": 1.4581607290803644,
      "grad_norm": 4.927154541015625,
      "learning_rate": 8.25964621516215e-06,
      "loss": 0.0637,
      "step": 1760
    },
    {
      "epoch": 1.4664457332228666,
      "grad_norm": 0.29825136065483093,
      "learning_rate": 8.254592898419928e-06,
      "loss": 0.0575,
      "step": 1770
    },
    {
      "epoch": 1.4747307373653686,
      "grad_norm": 0.33827629685401917,
      "learning_rate": 8.249539581677704e-06,
      "loss": 0.1506,
      "step": 1780
    },
    {
      "epoch": 1.4830157415078706,
      "grad_norm": 8.11099910736084,
      "learning_rate": 8.244486264935482e-06,
      "loss": 0.09,
      "step": 1790
    },
    {
      "epoch": 1.4913007456503728,
      "grad_norm": 7.263080596923828,
      "learning_rate": 8.23943294819326e-06,
      "loss": 0.0608,
      "step": 1800
    },
    {
      "epoch": 1.4995857497928748,
      "grad_norm": 10.908945083618164,
      "learning_rate": 8.234379631451039e-06,
      "loss": 0.0655,
      "step": 1810
    },
    {
      "epoch": 1.5078707539353768,
      "grad_norm": 0.3955589234828949,
      "learning_rate": 8.229326314708817e-06,
      "loss": 0.0305,
      "step": 1820
    },
    {
      "epoch": 1.516155758077879,
      "grad_norm": 0.46580302715301514,
      "learning_rate": 8.224272997966594e-06,
      "loss": 0.0732,
      "step": 1830
    },
    {
      "epoch": 1.5244407622203813,
      "grad_norm": 17.323856353759766,
      "learning_rate": 8.219219681224372e-06,
      "loss": 0.0839,
      "step": 1840
    },
    {
      "epoch": 1.532725766362883,
      "grad_norm": 4.0279436111450195,
      "learning_rate": 8.21416636448215e-06,
      "loss": 0.0682,
      "step": 1850
    },
    {
      "epoch": 1.5410107705053853,
      "grad_norm": 7.230100154876709,
      "learning_rate": 8.209113047739928e-06,
      "loss": 0.0871,
      "step": 1860
    },
    {
      "epoch": 1.5492957746478875,
      "grad_norm": 1.9044396877288818,
      "learning_rate": 8.204059730997705e-06,
      "loss": 0.0443,
      "step": 1870
    },
    {
      "epoch": 1.5575807787903893,
      "grad_norm": 6.747298240661621,
      "learning_rate": 8.199006414255483e-06,
      "loss": 0.0725,
      "step": 1880
    },
    {
      "epoch": 1.5658657829328915,
      "grad_norm": 5.2289042472839355,
      "learning_rate": 8.193953097513262e-06,
      "loss": 0.0403,
      "step": 1890
    },
    {
      "epoch": 1.5741507870753937,
      "grad_norm": 6.269410133361816,
      "learning_rate": 8.18889978077104e-06,
      "loss": 0.0535,
      "step": 1900
    },
    {
      "epoch": 1.5824357912178955,
      "grad_norm": 0.29712969064712524,
      "learning_rate": 8.183846464028816e-06,
      "loss": 0.0474,
      "step": 1910
    },
    {
      "epoch": 1.5907207953603977,
      "grad_norm": 0.22694434225559235,
      "learning_rate": 8.178793147286595e-06,
      "loss": 0.0356,
      "step": 1920
    },
    {
      "epoch": 1.5990057995029,
      "grad_norm": 4.736926078796387,
      "learning_rate": 8.173739830544373e-06,
      "loss": 0.0302,
      "step": 1930
    },
    {
      "epoch": 1.6072908036454017,
      "grad_norm": 2.897113084793091,
      "learning_rate": 8.16868651380215e-06,
      "loss": 0.0285,
      "step": 1940
    },
    {
      "epoch": 1.6155758077879039,
      "grad_norm": 12.011285781860352,
      "learning_rate": 8.163633197059928e-06,
      "loss": 0.0299,
      "step": 1950
    },
    {
      "epoch": 1.623860811930406,
      "grad_norm": 5.97914457321167,
      "learning_rate": 8.158579880317706e-06,
      "loss": 0.029,
      "step": 1960
    },
    {
      "epoch": 1.6321458160729079,
      "grad_norm": 9.532928466796875,
      "learning_rate": 8.153526563575484e-06,
      "loss": 0.0517,
      "step": 1970
    },
    {
      "epoch": 1.64043082021541,
      "grad_norm": 1.3326958417892456,
      "learning_rate": 8.14847324683326e-06,
      "loss": 0.0543,
      "step": 1980
    },
    {
      "epoch": 1.6487158243579123,
      "grad_norm": 10.794350624084473,
      "learning_rate": 8.143419930091039e-06,
      "loss": 0.0326,
      "step": 1990
    },
    {
      "epoch": 1.6570008285004143,
      "grad_norm": 14.061790466308594,
      "learning_rate": 8.138366613348817e-06,
      "loss": 0.0865,
      "step": 2000
    },
    {
      "epoch": 1.6652858326429163,
      "grad_norm": 7.522449493408203,
      "learning_rate": 8.133313296606594e-06,
      "loss": 0.0213,
      "step": 2010
    },
    {
      "epoch": 1.6735708367854185,
      "grad_norm": 7.2565598487854,
      "learning_rate": 8.128259979864372e-06,
      "loss": 0.0225,
      "step": 2020
    },
    {
      "epoch": 1.6818558409279205,
      "grad_norm": 8.141093254089355,
      "learning_rate": 8.12320666312215e-06,
      "loss": 0.0939,
      "step": 2030
    },
    {
      "epoch": 1.6901408450704225,
      "grad_norm": 0.053192686289548874,
      "learning_rate": 8.118153346379927e-06,
      "loss": 0.0402,
      "step": 2040
    },
    {
      "epoch": 1.6984258492129247,
      "grad_norm": 0.0036665743682533503,
      "learning_rate": 8.113100029637705e-06,
      "loss": 0.1034,
      "step": 2050
    },
    {
      "epoch": 1.7067108533554267,
      "grad_norm": 17.54552459716797,
      "learning_rate": 8.108046712895483e-06,
      "loss": 0.0644,
      "step": 2060
    },
    {
      "epoch": 1.7149958574979287,
      "grad_norm": 0.516610324382782,
      "learning_rate": 8.102993396153262e-06,
      "loss": 0.0445,
      "step": 2070
    },
    {
      "epoch": 1.723280861640431,
      "grad_norm": 7.918540000915527,
      "learning_rate": 8.09794007941104e-06,
      "loss": 0.1466,
      "step": 2080
    },
    {
      "epoch": 1.731565865782933,
      "grad_norm": 7.515031814575195,
      "learning_rate": 8.092886762668816e-06,
      "loss": 0.0571,
      "step": 2090
    },
    {
      "epoch": 1.739850869925435,
      "grad_norm": 12.343511581420898,
      "learning_rate": 8.087833445926595e-06,
      "loss": 0.0761,
      "step": 2100
    },
    {
      "epoch": 1.7481358740679371,
      "grad_norm": 6.280521392822266,
      "learning_rate": 8.082780129184373e-06,
      "loss": 0.0415,
      "step": 2110
    },
    {
      "epoch": 1.7564208782104391,
      "grad_norm": 0.89591383934021,
      "learning_rate": 8.077726812442151e-06,
      "loss": 0.0372,
      "step": 2120
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.09375464171171188,
      "learning_rate": 8.072673495699928e-06,
      "loss": 0.035,
      "step": 2130
    },
    {
      "epoch": 1.7729908864954433,
      "grad_norm": 1.5647060871124268,
      "learning_rate": 8.067620178957706e-06,
      "loss": 0.0366,
      "step": 2140
    },
    {
      "epoch": 1.7812758906379453,
      "grad_norm": 4.684528350830078,
      "learning_rate": 8.062566862215484e-06,
      "loss": 0.071,
      "step": 2150
    },
    {
      "epoch": 1.7895608947804473,
      "grad_norm": 3.7997071743011475,
      "learning_rate": 8.057513545473263e-06,
      "loss": 0.024,
      "step": 2160
    },
    {
      "epoch": 1.7978458989229495,
      "grad_norm": 0.16842420399188995,
      "learning_rate": 8.052460228731039e-06,
      "loss": 0.0389,
      "step": 2170
    },
    {
      "epoch": 1.8061309030654515,
      "grad_norm": 2.969099760055542,
      "learning_rate": 8.047406911988817e-06,
      "loss": 0.041,
      "step": 2180
    },
    {
      "epoch": 1.8144159072079535,
      "grad_norm": 3.7576138973236084,
      "learning_rate": 8.042353595246596e-06,
      "loss": 0.0097,
      "step": 2190
    },
    {
      "epoch": 1.8227009113504558,
      "grad_norm": 0.3659493923187256,
      "learning_rate": 8.037300278504374e-06,
      "loss": 0.0274,
      "step": 2200
    },
    {
      "epoch": 1.8309859154929577,
      "grad_norm": 2.0175633430480957,
      "learning_rate": 8.03224696176215e-06,
      "loss": 0.0439,
      "step": 2210
    },
    {
      "epoch": 1.8392709196354597,
      "grad_norm": 22.07223129272461,
      "learning_rate": 8.027193645019929e-06,
      "loss": 0.1097,
      "step": 2220
    },
    {
      "epoch": 1.847555923777962,
      "grad_norm": 5.7456560134887695,
      "learning_rate": 8.022140328277707e-06,
      "loss": 0.06,
      "step": 2230
    },
    {
      "epoch": 1.855840927920464,
      "grad_norm": 4.851104259490967,
      "learning_rate": 8.017087011535485e-06,
      "loss": 0.0464,
      "step": 2240
    },
    {
      "epoch": 1.864125932062966,
      "grad_norm": 0.9162869453430176,
      "learning_rate": 8.012033694793263e-06,
      "loss": 0.0475,
      "step": 2250
    },
    {
      "epoch": 1.8724109362054682,
      "grad_norm": 1.7096835374832153,
      "learning_rate": 8.00698037805104e-06,
      "loss": 0.032,
      "step": 2260
    },
    {
      "epoch": 1.8806959403479702,
      "grad_norm": 0.1311386376619339,
      "learning_rate": 8.001927061308818e-06,
      "loss": 0.0286,
      "step": 2270
    },
    {
      "epoch": 1.8889809444904722,
      "grad_norm": 0.07722429186105728,
      "learning_rate": 7.996873744566597e-06,
      "loss": 0.0234,
      "step": 2280
    },
    {
      "epoch": 1.8972659486329744,
      "grad_norm": 3.431088447570801,
      "learning_rate": 7.991820427824375e-06,
      "loss": 0.0252,
      "step": 2290
    },
    {
      "epoch": 1.9055509527754764,
      "grad_norm": 7.813427448272705,
      "learning_rate": 7.986767111082151e-06,
      "loss": 0.0949,
      "step": 2300
    },
    {
      "epoch": 1.9138359569179784,
      "grad_norm": 9.882965087890625,
      "learning_rate": 7.98171379433993e-06,
      "loss": 0.0481,
      "step": 2310
    },
    {
      "epoch": 1.9221209610604806,
      "grad_norm": 0.6551738381385803,
      "learning_rate": 7.976660477597708e-06,
      "loss": 0.0162,
      "step": 2320
    },
    {
      "epoch": 1.9304059652029826,
      "grad_norm": 0.40987008810043335,
      "learning_rate": 7.971607160855486e-06,
      "loss": 0.0522,
      "step": 2330
    },
    {
      "epoch": 1.9386909693454846,
      "grad_norm": 7.638538360595703,
      "learning_rate": 7.966553844113263e-06,
      "loss": 0.0234,
      "step": 2340
    },
    {
      "epoch": 1.9469759734879868,
      "grad_norm": 0.7611766457557678,
      "learning_rate": 7.961500527371041e-06,
      "loss": 0.0208,
      "step": 2350
    },
    {
      "epoch": 1.9552609776304888,
      "grad_norm": 6.463350772857666,
      "learning_rate": 7.95644721062882e-06,
      "loss": 0.0899,
      "step": 2360
    },
    {
      "epoch": 1.9635459817729908,
      "grad_norm": 6.702579021453857,
      "learning_rate": 7.951393893886596e-06,
      "loss": 0.0817,
      "step": 2370
    },
    {
      "epoch": 1.971830985915493,
      "grad_norm": 0.06750178337097168,
      "learning_rate": 7.946340577144374e-06,
      "loss": 0.0437,
      "step": 2380
    },
    {
      "epoch": 1.980115990057995,
      "grad_norm": 0.1717686653137207,
      "learning_rate": 7.941287260402152e-06,
      "loss": 0.0714,
      "step": 2390
    },
    {
      "epoch": 1.988400994200497,
      "grad_norm": 2.273009777069092,
      "learning_rate": 7.93623394365993e-06,
      "loss": 0.035,
      "step": 2400
    },
    {
      "epoch": 1.9966859983429992,
      "grad_norm": 9.743253707885742,
      "learning_rate": 7.931180626917707e-06,
      "loss": 0.0587,
      "step": 2410
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9850096711798839,
      "eval_f1": 0.9125528913963329,
      "eval_loss": 0.05657904967665672,
      "eval_precision": 0.975867269984917,
      "eval_recall": 0.856953642384106,
      "eval_runtime": 1214.0223,
      "eval_samples_per_second": 6.818,
      "eval_steps_per_second": 0.853,
      "step": 2414
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9850096711798839,
      "eval_f1": 0.9125528913963329,
      "eval_loss": 0.05657904967665672,
      "eval_precision": 0.975867269984917,
      "eval_recall": 0.856953642384106,
      "eval_runtime": 1206.3967,
      "eval_samples_per_second": 6.861,
      "eval_steps_per_second": 0.858,
      "step": 2414
    },
    {
      "epoch": 2.0049710024855014,
      "grad_norm": 0.01390097662806511,
      "learning_rate": 7.926127310175485e-06,
      "loss": 0.0808,
      "step": 2420
    },
    {
      "epoch": 2.013256006628003,
      "grad_norm": 4.445160865783691,
      "learning_rate": 7.921073993433264e-06,
      "loss": 0.0235,
      "step": 2430
    },
    {
      "epoch": 2.0215410107705054,
      "grad_norm": 0.32977595925331116,
      "learning_rate": 7.91602067669104e-06,
      "loss": 0.0437,
      "step": 2440
    },
    {
      "epoch": 2.0298260149130076,
      "grad_norm": 0.1471567004919052,
      "learning_rate": 7.910967359948818e-06,
      "loss": 0.0789,
      "step": 2450
    },
    {
      "epoch": 2.0381110190555094,
      "grad_norm": 3.805471658706665,
      "learning_rate": 7.905914043206597e-06,
      "loss": 0.0462,
      "step": 2460
    },
    {
      "epoch": 2.0463960231980116,
      "grad_norm": 1.8528944253921509,
      "learning_rate": 7.900860726464375e-06,
      "loss": 0.062,
      "step": 2470
    },
    {
      "epoch": 2.054681027340514,
      "grad_norm": 6.575252532958984,
      "learning_rate": 7.895807409722151e-06,
      "loss": 0.0171,
      "step": 2480
    },
    {
      "epoch": 2.0629660314830156,
      "grad_norm": 7.969465732574463,
      "learning_rate": 7.89075409297993e-06,
      "loss": 0.0279,
      "step": 2490
    },
    {
      "epoch": 2.071251035625518,
      "grad_norm": 1.1669912338256836,
      "learning_rate": 7.885700776237708e-06,
      "loss": 0.0021,
      "step": 2500
    },
    {
      "epoch": 2.07953603976802,
      "grad_norm": 0.008226069621741772,
      "learning_rate": 7.880647459495486e-06,
      "loss": 0.0085,
      "step": 2510
    },
    {
      "epoch": 2.087821043910522,
      "grad_norm": 14.587381362915039,
      "learning_rate": 7.875594142753263e-06,
      "loss": 0.0532,
      "step": 2520
    },
    {
      "epoch": 2.096106048053024,
      "grad_norm": 2.213238477706909,
      "learning_rate": 7.870540826011041e-06,
      "loss": 0.0109,
      "step": 2530
    },
    {
      "epoch": 2.1043910521955262,
      "grad_norm": 1.5572097301483154,
      "learning_rate": 7.86548750926882e-06,
      "loss": 0.0318,
      "step": 2540
    },
    {
      "epoch": 2.112676056338028,
      "grad_norm": 3.3592660427093506,
      "learning_rate": 7.860434192526598e-06,
      "loss": 0.0317,
      "step": 2550
    },
    {
      "epoch": 2.1209610604805302,
      "grad_norm": 1.9727061986923218,
      "learning_rate": 7.855380875784374e-06,
      "loss": 0.007,
      "step": 2560
    },
    {
      "epoch": 2.1292460646230325,
      "grad_norm": 2.5569090843200684,
      "learning_rate": 7.850327559042152e-06,
      "loss": 0.0716,
      "step": 2570
    },
    {
      "epoch": 2.1375310687655342,
      "grad_norm": 3.899620294570923,
      "learning_rate": 7.84527424229993e-06,
      "loss": 0.0282,
      "step": 2580
    },
    {
      "epoch": 2.1458160729080364,
      "grad_norm": 0.018113642930984497,
      "learning_rate": 7.840220925557709e-06,
      "loss": 0.0334,
      "step": 2590
    },
    {
      "epoch": 2.1541010770505387,
      "grad_norm": 0.10910499095916748,
      "learning_rate": 7.835167608815485e-06,
      "loss": 0.0299,
      "step": 2600
    },
    {
      "epoch": 2.1623860811930404,
      "grad_norm": 34.71322250366211,
      "learning_rate": 7.830114292073264e-06,
      "loss": 0.1003,
      "step": 2610
    },
    {
      "epoch": 2.1706710853355426,
      "grad_norm": 1.8123217821121216,
      "learning_rate": 7.825060975331042e-06,
      "loss": 0.0198,
      "step": 2620
    },
    {
      "epoch": 2.178956089478045,
      "grad_norm": 9.283021926879883,
      "learning_rate": 7.82000765858882e-06,
      "loss": 0.0327,
      "step": 2630
    },
    {
      "epoch": 2.1872410936205466,
      "grad_norm": 0.023881491273641586,
      "learning_rate": 7.814954341846598e-06,
      "loss": 0.09,
      "step": 2640
    },
    {
      "epoch": 2.195526097763049,
      "grad_norm": 6.913341999053955,
      "learning_rate": 7.809901025104375e-06,
      "loss": 0.0299,
      "step": 2650
    },
    {
      "epoch": 2.203811101905551,
      "grad_norm": 2.827458381652832,
      "learning_rate": 7.804847708362153e-06,
      "loss": 0.0249,
      "step": 2660
    },
    {
      "epoch": 2.212096106048053,
      "grad_norm": 0.6604866981506348,
      "learning_rate": 7.799794391619931e-06,
      "loss": 0.0477,
      "step": 2670
    },
    {
      "epoch": 2.220381110190555,
      "grad_norm": 3.1753976345062256,
      "learning_rate": 7.79474107487771e-06,
      "loss": 0.0307,
      "step": 2680
    },
    {
      "epoch": 2.2286661143330573,
      "grad_norm": 1.1832237243652344,
      "learning_rate": 7.789687758135486e-06,
      "loss": 0.0122,
      "step": 2690
    },
    {
      "epoch": 2.236951118475559,
      "grad_norm": 16.51018714904785,
      "learning_rate": 7.784634441393265e-06,
      "loss": 0.0646,
      "step": 2700
    },
    {
      "epoch": 2.2452361226180613,
      "grad_norm": 2.8040096759796143,
      "learning_rate": 7.779581124651043e-06,
      "loss": 0.0549,
      "step": 2710
    },
    {
      "epoch": 2.2535211267605635,
      "grad_norm": 0.5248673558235168,
      "learning_rate": 7.774527807908821e-06,
      "loss": 0.0231,
      "step": 2720
    },
    {
      "epoch": 2.2618061309030653,
      "grad_norm": 0.1310742348432541,
      "learning_rate": 7.769474491166598e-06,
      "loss": 0.0515,
      "step": 2730
    },
    {
      "epoch": 2.2700911350455675,
      "grad_norm": 0.07403431832790375,
      "learning_rate": 7.764421174424376e-06,
      "loss": 0.0394,
      "step": 2740
    },
    {
      "epoch": 2.2783761391880697,
      "grad_norm": 7.458978176116943,
      "learning_rate": 7.759367857682154e-06,
      "loss": 0.0469,
      "step": 2750
    },
    {
      "epoch": 2.286661143330572,
      "grad_norm": 10.868087768554688,
      "learning_rate": 7.754314540939932e-06,
      "loss": 0.0282,
      "step": 2760
    },
    {
      "epoch": 2.2949461474730737,
      "grad_norm": 6.998411655426025,
      "learning_rate": 7.749261224197709e-06,
      "loss": 0.0223,
      "step": 2770
    },
    {
      "epoch": 2.303231151615576,
      "grad_norm": 1.4817237854003906,
      "learning_rate": 7.744207907455487e-06,
      "loss": 0.03,
      "step": 2780
    },
    {
      "epoch": 2.3115161557580777,
      "grad_norm": 0.35786178708076477,
      "learning_rate": 7.739154590713265e-06,
      "loss": 0.0199,
      "step": 2790
    },
    {
      "epoch": 2.31980115990058,
      "grad_norm": 0.2061891257762909,
      "learning_rate": 7.734101273971042e-06,
      "loss": 0.0246,
      "step": 2800
    },
    {
      "epoch": 2.328086164043082,
      "grad_norm": 8.052862167358398,
      "learning_rate": 7.72904795722882e-06,
      "loss": 0.0346,
      "step": 2810
    },
    {
      "epoch": 2.3363711681855843,
      "grad_norm": 9.70974063873291,
      "learning_rate": 7.723994640486599e-06,
      "loss": 0.034,
      "step": 2820
    },
    {
      "epoch": 2.344656172328086,
      "grad_norm": 15.093234062194824,
      "learning_rate": 7.718941323744377e-06,
      "loss": 0.1124,
      "step": 2830
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 9.043947219848633,
      "learning_rate": 7.713888007002153e-06,
      "loss": 0.011,
      "step": 2840
    },
    {
      "epoch": 2.36122618061309,
      "grad_norm": 0.00827513076364994,
      "learning_rate": 7.708834690259932e-06,
      "loss": 0.0383,
      "step": 2850
    },
    {
      "epoch": 2.3695111847555923,
      "grad_norm": 8.457340240478516,
      "learning_rate": 7.70378137351771e-06,
      "loss": 0.0589,
      "step": 2860
    },
    {
      "epoch": 2.3777961888980945,
      "grad_norm": 3.2457704544067383,
      "learning_rate": 7.698728056775486e-06,
      "loss": 0.0106,
      "step": 2870
    },
    {
      "epoch": 2.3860811930405967,
      "grad_norm": 0.03429073095321655,
      "learning_rate": 7.693674740033265e-06,
      "loss": 0.0071,
      "step": 2880
    },
    {
      "epoch": 2.3943661971830985,
      "grad_norm": 0.6671630144119263,
      "learning_rate": 7.688621423291043e-06,
      "loss": 0.0204,
      "step": 2890
    },
    {
      "epoch": 2.4026512013256007,
      "grad_norm": 6.7267584800720215,
      "learning_rate": 7.683568106548821e-06,
      "loss": 0.0521,
      "step": 2900
    },
    {
      "epoch": 2.4109362054681025,
      "grad_norm": 12.791143417358398,
      "learning_rate": 7.678514789806598e-06,
      "loss": 0.024,
      "step": 2910
    },
    {
      "epoch": 2.4192212096106047,
      "grad_norm": 0.6287320852279663,
      "learning_rate": 7.673461473064376e-06,
      "loss": 0.0195,
      "step": 2920
    },
    {
      "epoch": 2.427506213753107,
      "grad_norm": 0.019368255510926247,
      "learning_rate": 7.668408156322154e-06,
      "loss": 0.0056,
      "step": 2930
    },
    {
      "epoch": 2.435791217895609,
      "grad_norm": 0.7385741472244263,
      "learning_rate": 7.663354839579932e-06,
      "loss": 0.014,
      "step": 2940
    },
    {
      "epoch": 2.444076222038111,
      "grad_norm": 7.8749613761901855,
      "learning_rate": 7.658301522837709e-06,
      "loss": 0.0216,
      "step": 2950
    },
    {
      "epoch": 2.452361226180613,
      "grad_norm": 5.345181465148926,
      "learning_rate": 7.653248206095487e-06,
      "loss": 0.0221,
      "step": 2960
    },
    {
      "epoch": 2.460646230323115,
      "grad_norm": 0.04233771562576294,
      "learning_rate": 7.648194889353266e-06,
      "loss": 0.0381,
      "step": 2970
    },
    {
      "epoch": 2.468931234465617,
      "grad_norm": 0.4516437351703644,
      "learning_rate": 7.643141572611044e-06,
      "loss": 0.0461,
      "step": 2980
    },
    {
      "epoch": 2.4772162386081193,
      "grad_norm": 4.103643417358398,
      "learning_rate": 7.63808825586882e-06,
      "loss": 0.0833,
      "step": 2990
    },
    {
      "epoch": 2.4855012427506216,
      "grad_norm": 0.00925479270517826,
      "learning_rate": 7.633034939126599e-06,
      "loss": 0.0128,
      "step": 3000
    },
    {
      "epoch": 2.4937862468931233,
      "grad_norm": 3.0165319442749023,
      "learning_rate": 7.627981622384377e-06,
      "loss": 0.0866,
      "step": 3010
    },
    {
      "epoch": 2.5020712510356256,
      "grad_norm": 8.01038932800293,
      "learning_rate": 7.622928305642155e-06,
      "loss": 0.0468,
      "step": 3020
    },
    {
      "epoch": 2.5103562551781273,
      "grad_norm": 7.322289943695068,
      "learning_rate": 7.617874988899933e-06,
      "loss": 0.0239,
      "step": 3030
    },
    {
      "epoch": 2.5186412593206295,
      "grad_norm": 6.660730361938477,
      "learning_rate": 7.61282167215771e-06,
      "loss": 0.0637,
      "step": 3040
    },
    {
      "epoch": 2.5269262634631318,
      "grad_norm": 4.662241458892822,
      "learning_rate": 7.607768355415488e-06,
      "loss": 0.0254,
      "step": 3050
    },
    {
      "epoch": 2.535211267605634,
      "grad_norm": 0.006433493457734585,
      "learning_rate": 7.6027150386732665e-06,
      "loss": 0.0491,
      "step": 3060
    },
    {
      "epoch": 2.5434962717481358,
      "grad_norm": 0.045131098479032516,
      "learning_rate": 7.597661721931044e-06,
      "loss": 0.0376,
      "step": 3070
    },
    {
      "epoch": 2.551781275890638,
      "grad_norm": 0.21359556913375854,
      "learning_rate": 7.592608405188821e-06,
      "loss": 0.0309,
      "step": 3080
    },
    {
      "epoch": 2.5600662800331397,
      "grad_norm": 0.03410289064049721,
      "learning_rate": 7.5875550884465995e-06,
      "loss": 0.055,
      "step": 3090
    },
    {
      "epoch": 2.568351284175642,
      "grad_norm": 3.6864326000213623,
      "learning_rate": 7.582501771704378e-06,
      "loss": 0.0052,
      "step": 3100
    },
    {
      "epoch": 2.576636288318144,
      "grad_norm": 0.06008484214544296,
      "learning_rate": 7.577448454962155e-06,
      "loss": 0.022,
      "step": 3110
    },
    {
      "epoch": 2.5849212924606464,
      "grad_norm": 0.09697192907333374,
      "learning_rate": 7.572395138219933e-06,
      "loss": 0.0038,
      "step": 3120
    },
    {
      "epoch": 2.593206296603148,
      "grad_norm": 17.46430015563965,
      "learning_rate": 7.567341821477711e-06,
      "loss": 0.0292,
      "step": 3130
    },
    {
      "epoch": 2.6014913007456504,
      "grad_norm": 5.771088600158691,
      "learning_rate": 7.562288504735488e-06,
      "loss": 0.0229,
      "step": 3140
    },
    {
      "epoch": 2.6097763048881526,
      "grad_norm": 1.1823571920394897,
      "learning_rate": 7.5572351879932665e-06,
      "loss": 0.0475,
      "step": 3150
    },
    {
      "epoch": 2.6180613090306544,
      "grad_norm": 0.03605702891945839,
      "learning_rate": 7.552181871251045e-06,
      "loss": 0.0438,
      "step": 3160
    },
    {
      "epoch": 2.6263463131731566,
      "grad_norm": 0.048321228474378586,
      "learning_rate": 7.547128554508822e-06,
      "loss": 0.0096,
      "step": 3170
    },
    {
      "epoch": 2.634631317315659,
      "grad_norm": 0.0006836491520516574,
      "learning_rate": 7.5420752377665996e-06,
      "loss": 0.0229,
      "step": 3180
    },
    {
      "epoch": 2.6429163214581606,
      "grad_norm": 0.04162954166531563,
      "learning_rate": 7.537021921024378e-06,
      "loss": 0.0236,
      "step": 3190
    },
    {
      "epoch": 2.651201325600663,
      "grad_norm": 3.210207939147949,
      "learning_rate": 7.531968604282156e-06,
      "loss": 0.0685,
      "step": 3200
    },
    {
      "epoch": 2.659486329743165,
      "grad_norm": 3.103487730026245,
      "learning_rate": 7.526915287539933e-06,
      "loss": 0.0141,
      "step": 3210
    },
    {
      "epoch": 2.667771333885667,
      "grad_norm": 0.23890672624111176,
      "learning_rate": 7.521861970797711e-06,
      "loss": 0.0176,
      "step": 3220
    },
    {
      "epoch": 2.676056338028169,
      "grad_norm": 0.12959811091423035,
      "learning_rate": 7.516808654055489e-06,
      "loss": 0.0132,
      "step": 3230
    },
    {
      "epoch": 2.684341342170671,
      "grad_norm": 0.009943914599716663,
      "learning_rate": 7.511755337313267e-06,
      "loss": 0.0184,
      "step": 3240
    },
    {
      "epoch": 2.692626346313173,
      "grad_norm": 0.00971334706991911,
      "learning_rate": 7.506702020571044e-06,
      "loss": 0.0276,
      "step": 3250
    },
    {
      "epoch": 2.700911350455675,
      "grad_norm": 0.016471724957227707,
      "learning_rate": 7.501648703828822e-06,
      "loss": 0.0519,
      "step": 3260
    },
    {
      "epoch": 2.7091963545981774,
      "grad_norm": 19.3527889251709,
      "learning_rate": 7.4965953870866005e-06,
      "loss": 0.0227,
      "step": 3270
    },
    {
      "epoch": 2.717481358740679,
      "grad_norm": 9.26025390625,
      "learning_rate": 7.491542070344379e-06,
      "loss": 0.0334,
      "step": 3280
    },
    {
      "epoch": 2.7257663628831814,
      "grad_norm": 0.17710575461387634,
      "learning_rate": 7.486488753602156e-06,
      "loss": 0.0043,
      "step": 3290
    },
    {
      "epoch": 2.7340513670256836,
      "grad_norm": 8.859393119812012,
      "learning_rate": 7.4814354368599335e-06,
      "loss": 0.0389,
      "step": 3300
    },
    {
      "epoch": 2.742336371168186,
      "grad_norm": 2.725640058517456,
      "learning_rate": 7.476382120117712e-06,
      "loss": 0.0577,
      "step": 3310
    },
    {
      "epoch": 2.7506213753106876,
      "grad_norm": 0.07622984051704407,
      "learning_rate": 7.471328803375489e-06,
      "loss": 0.0114,
      "step": 3320
    },
    {
      "epoch": 2.75890637945319,
      "grad_norm": 5.665632724761963,
      "learning_rate": 7.4662754866332675e-06,
      "loss": 0.0023,
      "step": 3330
    },
    {
      "epoch": 2.7671913835956916,
      "grad_norm": 0.18157832324504852,
      "learning_rate": 7.461222169891045e-06,
      "loss": 0.0383,
      "step": 3340
    },
    {
      "epoch": 2.775476387738194,
      "grad_norm": 2.0738494396209717,
      "learning_rate": 7.456168853148823e-06,
      "loss": 0.0804,
      "step": 3350
    },
    {
      "epoch": 2.783761391880696,
      "grad_norm": 0.0740305483341217,
      "learning_rate": 7.4511155364066005e-06,
      "loss": 0.0155,
      "step": 3360
    },
    {
      "epoch": 2.7920463960231983,
      "grad_norm": 16.990449905395508,
      "learning_rate": 7.446062219664379e-06,
      "loss": 0.0559,
      "step": 3370
    },
    {
      "epoch": 2.8003314001657,
      "grad_norm": 0.0015395780792459846,
      "learning_rate": 7.441008902922156e-06,
      "loss": 0.0525,
      "step": 3380
    },
    {
      "epoch": 2.8086164043082023,
      "grad_norm": 0.33620062470436096,
      "learning_rate": 7.435955586179934e-06,
      "loss": 0.0324,
      "step": 3390
    },
    {
      "epoch": 2.816901408450704,
      "grad_norm": 0.40875256061553955,
      "learning_rate": 7.430902269437712e-06,
      "loss": 0.041,
      "step": 3400
    },
    {
      "epoch": 2.8251864125932062,
      "grad_norm": 5.021298408508301,
      "learning_rate": 7.42584895269549e-06,
      "loss": 0.052,
      "step": 3410
    },
    {
      "epoch": 2.8334714167357085,
      "grad_norm": 0.357740193605423,
      "learning_rate": 7.420795635953268e-06,
      "loss": 0.0682,
      "step": 3420
    },
    {
      "epoch": 2.8417564208782107,
      "grad_norm": 0.2225690484046936,
      "learning_rate": 7.415742319211045e-06,
      "loss": 0.0177,
      "step": 3430
    },
    {
      "epoch": 2.8500414250207124,
      "grad_norm": 7.487999439239502,
      "learning_rate": 7.410689002468823e-06,
      "loss": 0.0302,
      "step": 3440
    },
    {
      "epoch": 2.8583264291632147,
      "grad_norm": 0.13542349636554718,
      "learning_rate": 7.405635685726601e-06,
      "loss": 0.0259,
      "step": 3450
    },
    {
      "epoch": 2.8666114333057164,
      "grad_norm": 14.28032112121582,
      "learning_rate": 7.40058236898438e-06,
      "loss": 0.0547,
      "step": 3460
    },
    {
      "epoch": 2.8748964374482187,
      "grad_norm": 0.04168360307812691,
      "learning_rate": 7.395529052242156e-06,
      "loss": 0.0354,
      "step": 3470
    },
    {
      "epoch": 2.883181441590721,
      "grad_norm": 0.03386707603931427,
      "learning_rate": 7.3904757354999345e-06,
      "loss": 0.0154,
      "step": 3480
    },
    {
      "epoch": 2.891466445733223,
      "grad_norm": 2.965785503387451,
      "learning_rate": 7.385422418757713e-06,
      "loss": 0.0312,
      "step": 3490
    },
    {
      "epoch": 2.899751449875725,
      "grad_norm": 0.033131957054138184,
      "learning_rate": 7.380369102015491e-06,
      "loss": 0.024,
      "step": 3500
    },
    {
      "epoch": 2.908036454018227,
      "grad_norm": 6.583034515380859,
      "learning_rate": 7.3753157852732676e-06,
      "loss": 0.057,
      "step": 3510
    },
    {
      "epoch": 2.916321458160729,
      "grad_norm": 0.024747446179389954,
      "learning_rate": 7.370262468531046e-06,
      "loss": 0.0188,
      "step": 3520
    },
    {
      "epoch": 2.924606462303231,
      "grad_norm": 0.3340492248535156,
      "learning_rate": 7.365209151788824e-06,
      "loss": 0.0292,
      "step": 3530
    },
    {
      "epoch": 2.9328914664457333,
      "grad_norm": 3.771146059036255,
      "learning_rate": 7.3601558350466015e-06,
      "loss": 0.0678,
      "step": 3540
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 1.4327747821807861,
      "learning_rate": 7.35510251830438e-06,
      "loss": 0.0203,
      "step": 3550
    },
    {
      "epoch": 2.9494614747307373,
      "grad_norm": 0.14388607442378998,
      "learning_rate": 7.350049201562157e-06,
      "loss": 0.0238,
      "step": 3560
    },
    {
      "epoch": 2.9577464788732395,
      "grad_norm": 0.011720895767211914,
      "learning_rate": 7.3449958848199345e-06,
      "loss": 0.0589,
      "step": 3570
    },
    {
      "epoch": 2.9660314830157413,
      "grad_norm": 7.315248966217041,
      "learning_rate": 7.339942568077713e-06,
      "loss": 0.0594,
      "step": 3580
    },
    {
      "epoch": 2.9743164871582435,
      "grad_norm": 1.4463605880737305,
      "learning_rate": 7.334889251335491e-06,
      "loss": 0.0356,
      "step": 3590
    },
    {
      "epoch": 2.9826014913007457,
      "grad_norm": 11.679400444030762,
      "learning_rate": 7.3298359345932685e-06,
      "loss": 0.0234,
      "step": 3600
    },
    {
      "epoch": 2.990886495443248,
      "grad_norm": 0.026415182277560234,
      "learning_rate": 7.324782617851046e-06,
      "loss": 0.0191,
      "step": 3610
    },
    {
      "epoch": 2.9991714995857497,
      "grad_norm": 0.08200281858444214,
      "learning_rate": 7.319729301108824e-06,
      "loss": 0.0014,
      "step": 3620
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9904497098646035,
      "eval_f1": 0.9470154258886654,
      "eval_loss": 0.039639100432395935,
      "eval_precision": 0.9592391304347826,
      "eval_recall": 0.9350993377483444,
      "eval_runtime": 1255.8791,
      "eval_samples_per_second": 6.591,
      "eval_steps_per_second": 0.824,
      "step": 3621
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9904497098646035,
      "eval_f1": 0.9470154258886654,
      "eval_loss": 0.039639100432395935,
      "eval_precision": 0.9592391304347826,
      "eval_recall": 0.9350993377483444,
      "eval_runtime": 1208.984,
      "eval_samples_per_second": 6.846,
      "eval_steps_per_second": 0.856,
      "step": 3621
    },
    {
      "epoch": 3.007456503728252,
      "grad_norm": 0.3907223641872406,
      "learning_rate": 7.314675984366602e-06,
      "loss": 0.0286,
      "step": 3630
    },
    {
      "epoch": 3.015741507870754,
      "grad_norm": 1.1389518976211548,
      "learning_rate": 7.309622667624379e-06,
      "loss": 0.0094,
      "step": 3640
    },
    {
      "epoch": 3.024026512013256,
      "grad_norm": 10.084410667419434,
      "learning_rate": 7.304569350882157e-06,
      "loss": 0.021,
      "step": 3650
    },
    {
      "epoch": 3.032311516155758,
      "grad_norm": 0.005446947179734707,
      "learning_rate": 7.2995160341399354e-06,
      "loss": 0.0271,
      "step": 3660
    },
    {
      "epoch": 3.0405965202982603,
      "grad_norm": 0.028859032317996025,
      "learning_rate": 7.294462717397714e-06,
      "loss": 0.0364,
      "step": 3670
    },
    {
      "epoch": 3.048881524440762,
      "grad_norm": 0.3911978006362915,
      "learning_rate": 7.289409400655492e-06,
      "loss": 0.0066,
      "step": 3680
    },
    {
      "epoch": 3.0571665285832643,
      "grad_norm": 0.09017802029848099,
      "learning_rate": 7.2843560839132685e-06,
      "loss": 0.0318,
      "step": 3690
    },
    {
      "epoch": 3.0654515327257665,
      "grad_norm": 0.5370222926139832,
      "learning_rate": 7.279302767171047e-06,
      "loss": 0.0265,
      "step": 3700
    },
    {
      "epoch": 3.0737365368682683,
      "grad_norm": 0.3754766881465912,
      "learning_rate": 7.274249450428825e-06,
      "loss": 0.0511,
      "step": 3710
    },
    {
      "epoch": 3.0820215410107705,
      "grad_norm": 0.11776170879602432,
      "learning_rate": 7.269196133686602e-06,
      "loss": 0.0301,
      "step": 3720
    },
    {
      "epoch": 3.0903065451532727,
      "grad_norm": 0.10989842563867569,
      "learning_rate": 7.26414281694438e-06,
      "loss": 0.0014,
      "step": 3730
    },
    {
      "epoch": 3.0985915492957745,
      "grad_norm": 0.016229873523116112,
      "learning_rate": 7.259089500202158e-06,
      "loss": 0.0222,
      "step": 3740
    },
    {
      "epoch": 3.1068765534382767,
      "grad_norm": 0.01651720516383648,
      "learning_rate": 7.254036183459936e-06,
      "loss": 0.007,
      "step": 3750
    },
    {
      "epoch": 3.115161557580779,
      "grad_norm": 0.060417406260967255,
      "learning_rate": 7.248982866717714e-06,
      "loss": 0.0002,
      "step": 3760
    },
    {
      "epoch": 3.1234465617232807,
      "grad_norm": 17.884891510009766,
      "learning_rate": 7.243929549975491e-06,
      "loss": 0.0134,
      "step": 3770
    },
    {
      "epoch": 3.131731565865783,
      "grad_norm": 0.019493933767080307,
      "learning_rate": 7.238876233233269e-06,
      "loss": 0.0109,
      "step": 3780
    },
    {
      "epoch": 3.140016570008285,
      "grad_norm": 0.022454289719462395,
      "learning_rate": 7.233822916491047e-06,
      "loss": 0.0493,
      "step": 3790
    },
    {
      "epoch": 3.148301574150787,
      "grad_norm": 0.06018184497952461,
      "learning_rate": 7.228769599748825e-06,
      "loss": 0.0328,
      "step": 3800
    },
    {
      "epoch": 3.156586578293289,
      "grad_norm": 0.016910681501030922,
      "learning_rate": 7.223716283006603e-06,
      "loss": 0.0361,
      "step": 3810
    },
    {
      "epoch": 3.1648715824357914,
      "grad_norm": 0.07554055750370026,
      "learning_rate": 7.21866296626438e-06,
      "loss": 0.0214,
      "step": 3820
    },
    {
      "epoch": 3.173156586578293,
      "grad_norm": 0.15716104209423065,
      "learning_rate": 7.213609649522158e-06,
      "loss": 0.0335,
      "step": 3830
    },
    {
      "epoch": 3.1814415907207954,
      "grad_norm": 3.1156957149505615,
      "learning_rate": 7.208556332779936e-06,
      "loss": 0.0483,
      "step": 3840
    },
    {
      "epoch": 3.1897265948632976,
      "grad_norm": 6.039947986602783,
      "learning_rate": 7.203503016037715e-06,
      "loss": 0.0062,
      "step": 3850
    },
    {
      "epoch": 3.1980115990057993,
      "grad_norm": 10.471912384033203,
      "learning_rate": 7.198449699295491e-06,
      "loss": 0.009,
      "step": 3860
    },
    {
      "epoch": 3.2062966031483016,
      "grad_norm": 0.18382976949214935,
      "learning_rate": 7.1933963825532695e-06,
      "loss": 0.009,
      "step": 3870
    },
    {
      "epoch": 3.2145816072908038,
      "grad_norm": 0.03518882393836975,
      "learning_rate": 7.188343065811048e-06,
      "loss": 0.015,
      "step": 3880
    },
    {
      "epoch": 3.2228666114333056,
      "grad_norm": 0.09937087446451187,
      "learning_rate": 7.183289749068826e-06,
      "loss": 0.0051,
      "step": 3890
    },
    {
      "epoch": 3.2311516155758078,
      "grad_norm": 2.558744192123413,
      "learning_rate": 7.1782364323266025e-06,
      "loss": 0.0317,
      "step": 3900
    },
    {
      "epoch": 3.23943661971831,
      "grad_norm": 9.772430419921875,
      "learning_rate": 7.173183115584381e-06,
      "loss": 0.0251,
      "step": 3910
    },
    {
      "epoch": 3.2477216238608118,
      "grad_norm": 0.2794838845729828,
      "learning_rate": 7.168129798842159e-06,
      "loss": 0.0377,
      "step": 3920
    },
    {
      "epoch": 3.256006628003314,
      "grad_norm": 0.550210177898407,
      "learning_rate": 7.163076482099937e-06,
      "loss": 0.0042,
      "step": 3930
    },
    {
      "epoch": 3.264291632145816,
      "grad_norm": 4.624694347381592,
      "learning_rate": 7.158023165357714e-06,
      "loss": 0.0773,
      "step": 3940
    },
    {
      "epoch": 3.272576636288318,
      "grad_norm": 0.5341090559959412,
      "learning_rate": 7.152969848615492e-06,
      "loss": 0.0647,
      "step": 3950
    },
    {
      "epoch": 3.28086164043082,
      "grad_norm": 1.1105265617370605,
      "learning_rate": 7.14791653187327e-06,
      "loss": 0.0045,
      "step": 3960
    },
    {
      "epoch": 3.2891466445733224,
      "grad_norm": 0.5198929309844971,
      "learning_rate": 7.142863215131048e-06,
      "loss": 0.0144,
      "step": 3970
    },
    {
      "epoch": 3.297431648715824,
      "grad_norm": 11.705574989318848,
      "learning_rate": 7.137809898388826e-06,
      "loss": 0.0084,
      "step": 3980
    },
    {
      "epoch": 3.3057166528583264,
      "grad_norm": 7.464025974273682,
      "learning_rate": 7.1327565816466034e-06,
      "loss": 0.0395,
      "step": 3990
    },
    {
      "epoch": 3.3140016570008286,
      "grad_norm": 0.025705039501190186,
      "learning_rate": 7.127703264904382e-06,
      "loss": 0.0017,
      "step": 4000
    },
    {
      "epoch": 3.3222866611433304,
      "grad_norm": 6.968526840209961,
      "learning_rate": 7.122649948162159e-06,
      "loss": 0.0494,
      "step": 4010
    },
    {
      "epoch": 3.3305716652858326,
      "grad_norm": 4.303006172180176,
      "learning_rate": 7.117596631419937e-06,
      "loss": 0.0157,
      "step": 4020
    },
    {
      "epoch": 3.338856669428335,
      "grad_norm": 0.10479786247015,
      "learning_rate": 7.112543314677715e-06,
      "loss": 0.0421,
      "step": 4030
    },
    {
      "epoch": 3.347141673570837,
      "grad_norm": 5.1338982582092285,
      "learning_rate": 7.107489997935492e-06,
      "loss": 0.029,
      "step": 4040
    },
    {
      "epoch": 3.355426677713339,
      "grad_norm": 0.003575123380869627,
      "learning_rate": 7.10243668119327e-06,
      "loss": 0.0044,
      "step": 4050
    },
    {
      "epoch": 3.363711681855841,
      "grad_norm": 15.08465576171875,
      "learning_rate": 7.097383364451049e-06,
      "loss": 0.032,
      "step": 4060
    },
    {
      "epoch": 3.371996685998343,
      "grad_norm": 0.5936737060546875,
      "learning_rate": 7.092330047708825e-06,
      "loss": 0.0238,
      "step": 4070
    },
    {
      "epoch": 3.380281690140845,
      "grad_norm": 5.875706672668457,
      "learning_rate": 7.0872767309666035e-06,
      "loss": 0.0466,
      "step": 4080
    },
    {
      "epoch": 3.3885666942833472,
      "grad_norm": 12.50003433227539,
      "learning_rate": 7.082223414224382e-06,
      "loss": 0.0085,
      "step": 4090
    },
    {
      "epoch": 3.3968516984258494,
      "grad_norm": 0.018399622291326523,
      "learning_rate": 7.07717009748216e-06,
      "loss": 0.0473,
      "step": 4100
    },
    {
      "epoch": 3.405136702568351,
      "grad_norm": 4.116938591003418,
      "learning_rate": 7.072116780739938e-06,
      "loss": 0.0037,
      "step": 4110
    },
    {
      "epoch": 3.4134217067108534,
      "grad_norm": 0.04306470975279808,
      "learning_rate": 7.067063463997715e-06,
      "loss": 0.0017,
      "step": 4120
    },
    {
      "epoch": 3.421706710853355,
      "grad_norm": 0.03239264339208603,
      "learning_rate": 7.062010147255493e-06,
      "loss": 0.0349,
      "step": 4130
    },
    {
      "epoch": 3.4299917149958574,
      "grad_norm": 0.0080633033066988,
      "learning_rate": 7.056956830513271e-06,
      "loss": 0.0331,
      "step": 4140
    },
    {
      "epoch": 3.4382767191383596,
      "grad_norm": 1.0608267784118652,
      "learning_rate": 7.051903513771049e-06,
      "loss": 0.0138,
      "step": 4150
    },
    {
      "epoch": 3.446561723280862,
      "grad_norm": 0.474513977766037,
      "learning_rate": 7.046850197028826e-06,
      "loss": 0.0057,
      "step": 4160
    },
    {
      "epoch": 3.4548467274233636,
      "grad_norm": 0.0024643109645694494,
      "learning_rate": 7.041796880286604e-06,
      "loss": 0.0058,
      "step": 4170
    },
    {
      "epoch": 3.463131731565866,
      "grad_norm": 7.47425651550293,
      "learning_rate": 7.036743563544383e-06,
      "loss": 0.036,
      "step": 4180
    },
    {
      "epoch": 3.4714167357083676,
      "grad_norm": 4.011843204498291,
      "learning_rate": 7.03169024680216e-06,
      "loss": 0.0645,
      "step": 4190
    },
    {
      "epoch": 3.47970173985087,
      "grad_norm": 5.537101745605469,
      "learning_rate": 7.0266369300599374e-06,
      "loss": 0.0137,
      "step": 4200
    },
    {
      "epoch": 3.487986743993372,
      "grad_norm": 14.040050506591797,
      "learning_rate": 7.021583613317716e-06,
      "loss": 0.0241,
      "step": 4210
    },
    {
      "epoch": 3.4962717481358743,
      "grad_norm": 6.090011119842529,
      "learning_rate": 7.016530296575493e-06,
      "loss": 0.049,
      "step": 4220
    },
    {
      "epoch": 3.504556752278376,
      "grad_norm": 0.0750882551074028,
      "learning_rate": 7.011476979833271e-06,
      "loss": 0.0398,
      "step": 4230
    },
    {
      "epoch": 3.5128417564208783,
      "grad_norm": 5.6782050132751465,
      "learning_rate": 7.00642366309105e-06,
      "loss": 0.0277,
      "step": 4240
    },
    {
      "epoch": 3.52112676056338,
      "grad_norm": 3.088730573654175,
      "learning_rate": 7.001370346348827e-06,
      "loss": 0.0188,
      "step": 4250
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 0.8787186741828918,
      "learning_rate": 6.9963170296066044e-06,
      "loss": 0.0267,
      "step": 4260
    },
    {
      "epoch": 3.5376967688483845,
      "grad_norm": 10.423563003540039,
      "learning_rate": 6.991263712864383e-06,
      "loss": 0.0324,
      "step": 4270
    },
    {
      "epoch": 3.5459817729908867,
      "grad_norm": 0.02717292495071888,
      "learning_rate": 6.986210396122161e-06,
      "loss": 0.0182,
      "step": 4280
    },
    {
      "epoch": 3.5542667771333885,
      "grad_norm": 0.003837226191535592,
      "learning_rate": 6.9811570793799375e-06,
      "loss": 0.0333,
      "step": 4290
    },
    {
      "epoch": 3.5625517812758907,
      "grad_norm": 0.04698869585990906,
      "learning_rate": 6.976103762637716e-06,
      "loss": 0.025,
      "step": 4300
    },
    {
      "epoch": 3.5708367854183924,
      "grad_norm": 0.04559161141514778,
      "learning_rate": 6.971050445895494e-06,
      "loss": 0.001,
      "step": 4310
    },
    {
      "epoch": 3.5791217895608947,
      "grad_norm": 3.810671091079712,
      "learning_rate": 6.965997129153272e-06,
      "loss": 0.0256,
      "step": 4320
    },
    {
      "epoch": 3.587406793703397,
      "grad_norm": 3.370033025741577,
      "learning_rate": 6.960943812411049e-06,
      "loss": 0.0096,
      "step": 4330
    },
    {
      "epoch": 3.595691797845899,
      "grad_norm": 0.09121467173099518,
      "learning_rate": 6.955890495668827e-06,
      "loss": 0.0577,
      "step": 4340
    },
    {
      "epoch": 3.603976801988401,
      "grad_norm": 0.0279079657047987,
      "learning_rate": 6.950837178926605e-06,
      "loss": 0.0127,
      "step": 4350
    },
    {
      "epoch": 3.612261806130903,
      "grad_norm": 0.042133767157793045,
      "learning_rate": 6.945783862184384e-06,
      "loss": 0.0045,
      "step": 4360
    },
    {
      "epoch": 3.6205468102734053,
      "grad_norm": 0.040449269115924835,
      "learning_rate": 6.940730545442161e-06,
      "loss": 0.0054,
      "step": 4370
    },
    {
      "epoch": 3.628831814415907,
      "grad_norm": 2.009094476699829,
      "learning_rate": 6.935677228699938e-06,
      "loss": 0.0107,
      "step": 4380
    },
    {
      "epoch": 3.6371168185584093,
      "grad_norm": 9.083456993103027,
      "learning_rate": 6.930623911957717e-06,
      "loss": 0.0354,
      "step": 4390
    },
    {
      "epoch": 3.6454018227009115,
      "grad_norm": 7.833932876586914,
      "learning_rate": 6.925570595215494e-06,
      "loss": 0.0051,
      "step": 4400
    },
    {
      "epoch": 3.6536868268434133,
      "grad_norm": 9.65606689453125,
      "learning_rate": 6.920517278473272e-06,
      "loss": 0.0112,
      "step": 4410
    },
    {
      "epoch": 3.6619718309859155,
      "grad_norm": 27.136905670166016,
      "learning_rate": 6.91546396173105e-06,
      "loss": 0.0432,
      "step": 4420
    },
    {
      "epoch": 3.6702568351284177,
      "grad_norm": 0.004035172518342733,
      "learning_rate": 6.910410644988828e-06,
      "loss": 0.035,
      "step": 4430
    },
    {
      "epoch": 3.6785418392709195,
      "grad_norm": 4.464483737945557,
      "learning_rate": 6.905357328246605e-06,
      "loss": 0.0165,
      "step": 4440
    },
    {
      "epoch": 3.6868268434134217,
      "grad_norm": 0.0420113168656826,
      "learning_rate": 6.900304011504384e-06,
      "loss": 0.001,
      "step": 4450
    },
    {
      "epoch": 3.695111847555924,
      "grad_norm": 0.009987272322177887,
      "learning_rate": 6.895250694762161e-06,
      "loss": 0.0015,
      "step": 4460
    },
    {
      "epoch": 3.7033968516984257,
      "grad_norm": 2.8979737758636475,
      "learning_rate": 6.8901973780199384e-06,
      "loss": 0.0344,
      "step": 4470
    },
    {
      "epoch": 3.711681855840928,
      "grad_norm": 0.5959828495979309,
      "learning_rate": 6.885144061277717e-06,
      "loss": 0.0104,
      "step": 4480
    },
    {
      "epoch": 3.71996685998343,
      "grad_norm": 0.626646876335144,
      "learning_rate": 6.880090744535495e-06,
      "loss": 0.0256,
      "step": 4490
    },
    {
      "epoch": 3.728251864125932,
      "grad_norm": 0.2635841369628906,
      "learning_rate": 6.875037427793273e-06,
      "loss": 0.054,
      "step": 4500
    },
    {
      "epoch": 3.736536868268434,
      "grad_norm": 2.6579947471618652,
      "learning_rate": 6.86998411105105e-06,
      "loss": 0.0323,
      "step": 4510
    },
    {
      "epoch": 3.7448218724109363,
      "grad_norm": 6.3410563468933105,
      "learning_rate": 6.864930794308828e-06,
      "loss": 0.01,
      "step": 4520
    },
    {
      "epoch": 3.7531068765534386,
      "grad_norm": 5.0168304443359375,
      "learning_rate": 6.859877477566606e-06,
      "loss": 0.0084,
      "step": 4530
    },
    {
      "epoch": 3.7613918806959403,
      "grad_norm": 3.248323678970337,
      "learning_rate": 6.8548241608243845e-06,
      "loss": 0.0353,
      "step": 4540
    },
    {
      "epoch": 3.7696768848384425,
      "grad_norm": 0.00316116982139647,
      "learning_rate": 6.849770844082161e-06,
      "loss": 0.0257,
      "step": 4550
    },
    {
      "epoch": 3.7779618889809443,
      "grad_norm": 0.020525097846984863,
      "learning_rate": 6.844717527339939e-06,
      "loss": 0.0431,
      "step": 4560
    },
    {
      "epoch": 3.7862468931234465,
      "grad_norm": 0.09934956580400467,
      "learning_rate": 6.839664210597718e-06,
      "loss": 0.0037,
      "step": 4570
    },
    {
      "epoch": 3.7945318972659487,
      "grad_norm": 0.025721313431859016,
      "learning_rate": 6.834610893855495e-06,
      "loss": 0.0354,
      "step": 4580
    },
    {
      "epoch": 3.802816901408451,
      "grad_norm": 0.009443309158086777,
      "learning_rate": 6.829557577113272e-06,
      "loss": 0.0162,
      "step": 4590
    },
    {
      "epoch": 3.8111019055509527,
      "grad_norm": 0.005041682627052069,
      "learning_rate": 6.824504260371051e-06,
      "loss": 0.0094,
      "step": 4600
    },
    {
      "epoch": 3.819386909693455,
      "grad_norm": 7.130050182342529,
      "learning_rate": 6.819450943628829e-06,
      "loss": 0.052,
      "step": 4610
    },
    {
      "epoch": 3.8276719138359567,
      "grad_norm": 0.009752591140568256,
      "learning_rate": 6.814397626886606e-06,
      "loss": 0.0983,
      "step": 4620
    },
    {
      "epoch": 3.835956917978459,
      "grad_norm": 0.03755870833992958,
      "learning_rate": 6.809344310144385e-06,
      "loss": 0.0415,
      "step": 4630
    },
    {
      "epoch": 3.844241922120961,
      "grad_norm": 0.15155889093875885,
      "learning_rate": 6.804290993402162e-06,
      "loss": 0.0342,
      "step": 4640
    },
    {
      "epoch": 3.8525269262634634,
      "grad_norm": 0.31486251950263977,
      "learning_rate": 6.799237676659939e-06,
      "loss": 0.012,
      "step": 4650
    },
    {
      "epoch": 3.860811930405965,
      "grad_norm": 0.016689417883753777,
      "learning_rate": 6.794184359917718e-06,
      "loss": 0.0045,
      "step": 4660
    },
    {
      "epoch": 3.8690969345484674,
      "grad_norm": 11.869598388671875,
      "learning_rate": 6.789131043175496e-06,
      "loss": 0.0501,
      "step": 4670
    },
    {
      "epoch": 3.877381938690969,
      "grad_norm": 0.03380108252167702,
      "learning_rate": 6.784077726433273e-06,
      "loss": 0.0286,
      "step": 4680
    },
    {
      "epoch": 3.8856669428334714,
      "grad_norm": 0.4584619104862213,
      "learning_rate": 6.779024409691051e-06,
      "loss": 0.0349,
      "step": 4690
    },
    {
      "epoch": 3.8939519469759736,
      "grad_norm": 5.897984504699707,
      "learning_rate": 6.773971092948829e-06,
      "loss": 0.0273,
      "step": 4700
    },
    {
      "epoch": 3.902236951118476,
      "grad_norm": 0.4481477439403534,
      "learning_rate": 6.768917776206607e-06,
      "loss": 0.0088,
      "step": 4710
    },
    {
      "epoch": 3.9105219552609776,
      "grad_norm": 1.0997109413146973,
      "learning_rate": 6.763864459464384e-06,
      "loss": 0.0353,
      "step": 4720
    },
    {
      "epoch": 3.91880695940348,
      "grad_norm": 0.13842880725860596,
      "learning_rate": 6.758811142722162e-06,
      "loss": 0.0468,
      "step": 4730
    },
    {
      "epoch": 3.9270919635459816,
      "grad_norm": 2.980766534805298,
      "learning_rate": 6.75375782597994e-06,
      "loss": 0.0243,
      "step": 4740
    },
    {
      "epoch": 3.9353769676884838,
      "grad_norm": 3.336549758911133,
      "learning_rate": 6.7487045092377185e-06,
      "loss": 0.0191,
      "step": 4750
    },
    {
      "epoch": 3.943661971830986,
      "grad_norm": 0.0598808154463768,
      "learning_rate": 6.743651192495496e-06,
      "loss": 0.0297,
      "step": 4760
    },
    {
      "epoch": 3.951946975973488,
      "grad_norm": 0.14729952812194824,
      "learning_rate": 6.738597875753273e-06,
      "loss": 0.0279,
      "step": 4770
    },
    {
      "epoch": 3.96023198011599,
      "grad_norm": 0.016206292435526848,
      "learning_rate": 6.733544559011052e-06,
      "loss": 0.0344,
      "step": 4780
    },
    {
      "epoch": 3.968516984258492,
      "grad_norm": 6.728063106536865,
      "learning_rate": 6.72849124226883e-06,
      "loss": 0.0563,
      "step": 4790
    },
    {
      "epoch": 3.976801988400994,
      "grad_norm": 0.06540314853191376,
      "learning_rate": 6.723437925526607e-06,
      "loss": 0.0367,
      "step": 4800
    },
    {
      "epoch": 3.985086992543496,
      "grad_norm": 0.20593880116939545,
      "learning_rate": 6.718384608784385e-06,
      "loss": 0.0234,
      "step": 4810
    },
    {
      "epoch": 3.9933719966859984,
      "grad_norm": 0.6831282377243042,
      "learning_rate": 6.713331292042163e-06,
      "loss": 0.0196,
      "step": 4820
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9910541586073501,
      "eval_f1": 0.9502018842530282,
      "eval_loss": 0.034804269671440125,
      "eval_precision": 0.9658002735978112,
      "eval_recall": 0.9350993377483444,
      "eval_runtime": 1220.5413,
      "eval_samples_per_second": 6.781,
      "eval_steps_per_second": 0.848,
      "step": 4828
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9910541586073501,
      "eval_f1": 0.9502018842530282,
      "eval_loss": 0.034804269671440125,
      "eval_precision": 0.9658002735978112,
      "eval_recall": 0.9350993377483444,
      "eval_runtime": 1212.3363,
      "eval_samples_per_second": 6.827,
      "eval_steps_per_second": 0.854,
      "step": 4828
    },
    {
      "epoch": 4.001657000828501,
      "grad_norm": 0.017925504595041275,
      "learning_rate": 6.70827797529994e-06,
      "loss": 0.0032,
      "step": 4830
    },
    {
      "epoch": 4.009942004971003,
      "grad_norm": 0.3281845450401306,
      "learning_rate": 6.703224658557719e-06,
      "loss": 0.0007,
      "step": 4840
    },
    {
      "epoch": 4.018227009113504,
      "grad_norm": 0.011425400152802467,
      "learning_rate": 6.698171341815496e-06,
      "loss": 0.0126,
      "step": 4850
    },
    {
      "epoch": 4.026512013256006,
      "grad_norm": 0.019804328680038452,
      "learning_rate": 6.693118025073274e-06,
      "loss": 0.0073,
      "step": 4860
    },
    {
      "epoch": 4.034797017398509,
      "grad_norm": 7.764557838439941,
      "learning_rate": 6.688064708331052e-06,
      "loss": 0.0327,
      "step": 4870
    },
    {
      "epoch": 4.043082021541011,
      "grad_norm": 0.04118459299206734,
      "learning_rate": 6.68301139158883e-06,
      "loss": 0.0089,
      "step": 4880
    },
    {
      "epoch": 4.051367025683513,
      "grad_norm": 0.007896972820162773,
      "learning_rate": 6.677958074846608e-06,
      "loss": 0.0053,
      "step": 4890
    },
    {
      "epoch": 4.059652029826015,
      "grad_norm": 1.7863961458206177,
      "learning_rate": 6.672904758104385e-06,
      "loss": 0.0037,
      "step": 4900
    },
    {
      "epoch": 4.067937033968517,
      "grad_norm": 0.061624184250831604,
      "learning_rate": 6.667851441362163e-06,
      "loss": 0.0241,
      "step": 4910
    },
    {
      "epoch": 4.076222038111019,
      "grad_norm": 0.005462911445647478,
      "learning_rate": 6.662798124619941e-06,
      "loss": 0.0192,
      "step": 4920
    },
    {
      "epoch": 4.084507042253521,
      "grad_norm": 0.03670725226402283,
      "learning_rate": 6.6577448078777195e-06,
      "loss": 0.0006,
      "step": 4930
    },
    {
      "epoch": 4.092792046396023,
      "grad_norm": 0.6834023594856262,
      "learning_rate": 6.652691491135496e-06,
      "loss": 0.0363,
      "step": 4940
    },
    {
      "epoch": 4.1010770505385254,
      "grad_norm": 0.13179267942905426,
      "learning_rate": 6.647638174393274e-06,
      "loss": 0.019,
      "step": 4950
    },
    {
      "epoch": 4.109362054681028,
      "grad_norm": 0.05865143984556198,
      "learning_rate": 6.6425848576510526e-06,
      "loss": 0.0191,
      "step": 4960
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.005129779223352671,
      "learning_rate": 6.637531540908831e-06,
      "loss": 0.0049,
      "step": 4970
    },
    {
      "epoch": 4.125932062966031,
      "grad_norm": 0.0009848418412730098,
      "learning_rate": 6.632478224166607e-06,
      "loss": 0.0045,
      "step": 4980
    },
    {
      "epoch": 4.134217067108533,
      "grad_norm": 0.4182901382446289,
      "learning_rate": 6.627424907424386e-06,
      "loss": 0.0519,
      "step": 4990
    },
    {
      "epoch": 4.142502071251036,
      "grad_norm": 0.0010898251784965396,
      "learning_rate": 6.622371590682164e-06,
      "loss": 0.0181,
      "step": 5000
    },
    {
      "epoch": 4.150787075393538,
      "grad_norm": 12.556767463684082,
      "learning_rate": 6.617318273939941e-06,
      "loss": 0.0126,
      "step": 5010
    },
    {
      "epoch": 4.15907207953604,
      "grad_norm": 0.07330308109521866,
      "learning_rate": 6.6122649571977195e-06,
      "loss": 0.0149,
      "step": 5020
    },
    {
      "epoch": 4.167357083678542,
      "grad_norm": 9.554981231689453,
      "learning_rate": 6.607211640455497e-06,
      "loss": 0.0336,
      "step": 5030
    },
    {
      "epoch": 4.175642087821044,
      "grad_norm": 0.1352289617061615,
      "learning_rate": 6.602158323713275e-06,
      "loss": 0.0101,
      "step": 5040
    },
    {
      "epoch": 4.183927091963546,
      "grad_norm": 11.316449165344238,
      "learning_rate": 6.597105006971053e-06,
      "loss": 0.0434,
      "step": 5050
    },
    {
      "epoch": 4.192212096106048,
      "grad_norm": 0.3980953097343445,
      "learning_rate": 6.592051690228831e-06,
      "loss": 0.0229,
      "step": 5060
    },
    {
      "epoch": 4.20049710024855,
      "grad_norm": 1.5666465759277344,
      "learning_rate": 6.586998373486608e-06,
      "loss": 0.0249,
      "step": 5070
    },
    {
      "epoch": 4.2087821043910525,
      "grad_norm": 0.0033146373461931944,
      "learning_rate": 6.581945056744386e-06,
      "loss": 0.0176,
      "step": 5080
    },
    {
      "epoch": 4.217067108533554,
      "grad_norm": 6.097555160522461,
      "learning_rate": 6.576891740002164e-06,
      "loss": 0.0214,
      "step": 5090
    },
    {
      "epoch": 4.225352112676056,
      "grad_norm": 19.535127639770508,
      "learning_rate": 6.571838423259942e-06,
      "loss": 0.0139,
      "step": 5100
    },
    {
      "epoch": 4.233637116818558,
      "grad_norm": 5.05801248550415,
      "learning_rate": 6.56678510651772e-06,
      "loss": 0.0418,
      "step": 5110
    },
    {
      "epoch": 4.2419221209610605,
      "grad_norm": 0.01756890118122101,
      "learning_rate": 6.561731789775497e-06,
      "loss": 0.0012,
      "step": 5120
    },
    {
      "epoch": 4.250207125103563,
      "grad_norm": 0.02412632293999195,
      "learning_rate": 6.556678473033275e-06,
      "loss": 0.0086,
      "step": 5130
    },
    {
      "epoch": 4.258492129246065,
      "grad_norm": 7.117795944213867,
      "learning_rate": 6.5516251562910535e-06,
      "loss": 0.0201,
      "step": 5140
    },
    {
      "epoch": 4.266777133388567,
      "grad_norm": 1.3082849979400635,
      "learning_rate": 6.546571839548832e-06,
      "loss": 0.0327,
      "step": 5150
    },
    {
      "epoch": 4.2750621375310685,
      "grad_norm": 0.5332332253456116,
      "learning_rate": 6.541518522806608e-06,
      "loss": 0.0317,
      "step": 5160
    },
    {
      "epoch": 4.283347141673571,
      "grad_norm": 7.2814741134643555,
      "learning_rate": 6.536465206064387e-06,
      "loss": 0.0422,
      "step": 5170
    },
    {
      "epoch": 4.291632145816073,
      "grad_norm": 0.001172337681055069,
      "learning_rate": 6.531411889322165e-06,
      "loss": 0.0077,
      "step": 5180
    },
    {
      "epoch": 4.299917149958575,
      "grad_norm": 12.69571304321289,
      "learning_rate": 6.526358572579942e-06,
      "loss": 0.03,
      "step": 5190
    },
    {
      "epoch": 4.308202154101077,
      "grad_norm": 8.547905921936035,
      "learning_rate": 6.52130525583772e-06,
      "loss": 0.0082,
      "step": 5200
    },
    {
      "epoch": 4.3164871582435795,
      "grad_norm": 0.029935024678707123,
      "learning_rate": 6.516251939095498e-06,
      "loss": 0.0054,
      "step": 5210
    },
    {
      "epoch": 4.324772162386081,
      "grad_norm": 0.0034796670079231262,
      "learning_rate": 6.511198622353276e-06,
      "loss": 0.0045,
      "step": 5220
    },
    {
      "epoch": 4.333057166528583,
      "grad_norm": 0.0014130541821941733,
      "learning_rate": 6.5061453056110536e-06,
      "loss": 0.0045,
      "step": 5230
    },
    {
      "epoch": 4.341342170671085,
      "grad_norm": 0.013107378967106342,
      "learning_rate": 6.501091988868831e-06,
      "loss": 0.0089,
      "step": 5240
    },
    {
      "epoch": 4.3496271748135875,
      "grad_norm": 6.963432788848877,
      "learning_rate": 6.496038672126609e-06,
      "loss": 0.0398,
      "step": 5250
    },
    {
      "epoch": 4.35791217895609,
      "grad_norm": 8.2455415725708,
      "learning_rate": 6.490985355384387e-06,
      "loss": 0.0144,
      "step": 5260
    },
    {
      "epoch": 4.366197183098592,
      "grad_norm": 3.910099506378174,
      "learning_rate": 6.485932038642165e-06,
      "loss": 0.005,
      "step": 5270
    },
    {
      "epoch": 4.374482187241093,
      "grad_norm": 0.2479192018508911,
      "learning_rate": 6.480878721899943e-06,
      "loss": 0.0054,
      "step": 5280
    },
    {
      "epoch": 4.3827671913835955,
      "grad_norm": 9.816327095031738,
      "learning_rate": 6.4758254051577205e-06,
      "loss": 0.0293,
      "step": 5290
    },
    {
      "epoch": 4.391052195526098,
      "grad_norm": 0.015822676941752434,
      "learning_rate": 6.470772088415498e-06,
      "loss": 0.0013,
      "step": 5300
    },
    {
      "epoch": 4.3993371996686,
      "grad_norm": 8.018157005310059,
      "learning_rate": 6.465718771673276e-06,
      "loss": 0.0216,
      "step": 5310
    },
    {
      "epoch": 4.407622203811102,
      "grad_norm": 0.039321418851614,
      "learning_rate": 6.4606654549310545e-06,
      "loss": 0.0237,
      "step": 5320
    },
    {
      "epoch": 4.415907207953604,
      "grad_norm": 0.09325224906206131,
      "learning_rate": 6.455612138188831e-06,
      "loss": 0.0005,
      "step": 5330
    },
    {
      "epoch": 4.424192212096106,
      "grad_norm": 5.755509376525879,
      "learning_rate": 6.450558821446609e-06,
      "loss": 0.0393,
      "step": 5340
    },
    {
      "epoch": 4.432477216238608,
      "grad_norm": 0.0952281653881073,
      "learning_rate": 6.4455055047043875e-06,
      "loss": 0.0037,
      "step": 5350
    },
    {
      "epoch": 4.44076222038111,
      "grad_norm": 0.031748946756124496,
      "learning_rate": 6.440452187962166e-06,
      "loss": 0.0066,
      "step": 5360
    },
    {
      "epoch": 4.449047224523612,
      "grad_norm": 0.04226436838507652,
      "learning_rate": 6.435398871219942e-06,
      "loss": 0.0262,
      "step": 5370
    },
    {
      "epoch": 4.457332228666115,
      "grad_norm": 0.028338126838207245,
      "learning_rate": 6.430345554477721e-06,
      "loss": 0.0139,
      "step": 5380
    },
    {
      "epoch": 4.465617232808617,
      "grad_norm": 3.6916093826293945,
      "learning_rate": 6.425292237735499e-06,
      "loss": 0.0436,
      "step": 5390
    },
    {
      "epoch": 4.473902236951118,
      "grad_norm": 0.27442029118537903,
      "learning_rate": 6.420238920993277e-06,
      "loss": 0.0125,
      "step": 5400
    },
    {
      "epoch": 4.48218724109362,
      "grad_norm": 3.767120361328125,
      "learning_rate": 6.4151856042510545e-06,
      "loss": 0.0053,
      "step": 5410
    },
    {
      "epoch": 4.4904722452361225,
      "grad_norm": 0.026962848380208015,
      "learning_rate": 6.410132287508832e-06,
      "loss": 0.0012,
      "step": 5420
    },
    {
      "epoch": 4.498757249378625,
      "grad_norm": 0.04163780435919762,
      "learning_rate": 6.40507897076661e-06,
      "loss": 0.0173,
      "step": 5430
    },
    {
      "epoch": 4.507042253521127,
      "grad_norm": 0.011217965744435787,
      "learning_rate": 6.400025654024388e-06,
      "loss": 0.0027,
      "step": 5440
    },
    {
      "epoch": 4.515327257663629,
      "grad_norm": 0.09725555777549744,
      "learning_rate": 6.394972337282166e-06,
      "loss": 0.0063,
      "step": 5450
    },
    {
      "epoch": 4.5236122618061305,
      "grad_norm": 0.012602913193404675,
      "learning_rate": 6.389919020539943e-06,
      "loss": 0.0216,
      "step": 5460
    },
    {
      "epoch": 4.531897265948633,
      "grad_norm": 8.157644271850586,
      "learning_rate": 6.3848657037977215e-06,
      "loss": 0.0095,
      "step": 5470
    },
    {
      "epoch": 4.540182270091135,
      "grad_norm": 0.003825981169939041,
      "learning_rate": 6.379812387055499e-06,
      "loss": 0.0157,
      "step": 5480
    },
    {
      "epoch": 4.548467274233637,
      "grad_norm": 2.2045297622680664,
      "learning_rate": 6.374759070313277e-06,
      "loss": 0.0079,
      "step": 5490
    },
    {
      "epoch": 4.556752278376139,
      "grad_norm": 0.012460070662200451,
      "learning_rate": 6.3697057535710546e-06,
      "loss": 0.0301,
      "step": 5500
    },
    {
      "epoch": 4.565037282518642,
      "grad_norm": 0.019460054114460945,
      "learning_rate": 6.364652436828832e-06,
      "loss": 0.0098,
      "step": 5510
    },
    {
      "epoch": 4.573322286661144,
      "grad_norm": 0.035902559757232666,
      "learning_rate": 6.35959912008661e-06,
      "loss": 0.0342,
      "step": 5520
    },
    {
      "epoch": 4.581607290803645,
      "grad_norm": 0.0011134290834888816,
      "learning_rate": 6.3545458033443885e-06,
      "loss": 0.0338,
      "step": 5530
    },
    {
      "epoch": 4.589892294946147,
      "grad_norm": 0.010628201067447662,
      "learning_rate": 6.349492486602167e-06,
      "loss": 0.0366,
      "step": 5540
    },
    {
      "epoch": 4.59817729908865,
      "grad_norm": 5.005951404571533,
      "learning_rate": 6.344439169859943e-06,
      "loss": 0.0201,
      "step": 5550
    },
    {
      "epoch": 4.606462303231152,
      "grad_norm": 0.07855833321809769,
      "learning_rate": 6.3393858531177215e-06,
      "loss": 0.028,
      "step": 5560
    },
    {
      "epoch": 4.614747307373654,
      "grad_norm": 0.0025593775790184736,
      "learning_rate": 6.3343325363755e-06,
      "loss": 0.0177,
      "step": 5570
    },
    {
      "epoch": 4.623032311516155,
      "grad_norm": 0.006683971267193556,
      "learning_rate": 6.329279219633278e-06,
      "loss": 0.0274,
      "step": 5580
    },
    {
      "epoch": 4.631317315658658,
      "grad_norm": 1.1425697803497314,
      "learning_rate": 6.324225902891055e-06,
      "loss": 0.0032,
      "step": 5590
    },
    {
      "epoch": 4.63960231980116,
      "grad_norm": 6.697190284729004,
      "learning_rate": 6.319172586148833e-06,
      "loss": 0.0547,
      "step": 5600
    },
    {
      "epoch": 4.647887323943662,
      "grad_norm": 8.138501167297363,
      "learning_rate": 6.314119269406611e-06,
      "loss": 0.0192,
      "step": 5610
    },
    {
      "epoch": 4.656172328086164,
      "grad_norm": 0.03687557205557823,
      "learning_rate": 6.309065952664389e-06,
      "loss": 0.0187,
      "step": 5620
    },
    {
      "epoch": 4.664457332228666,
      "grad_norm": 0.0009556707227602601,
      "learning_rate": 6.304012635922166e-06,
      "loss": 0.0015,
      "step": 5630
    },
    {
      "epoch": 4.672742336371169,
      "grad_norm": 4.986640930175781,
      "learning_rate": 6.298959319179944e-06,
      "loss": 0.0192,
      "step": 5640
    },
    {
      "epoch": 4.68102734051367,
      "grad_norm": 0.9560719728469849,
      "learning_rate": 6.2939060024377224e-06,
      "loss": 0.0017,
      "step": 5650
    },
    {
      "epoch": 4.689312344656172,
      "grad_norm": 0.050427842885255814,
      "learning_rate": 6.2888526856955e-06,
      "loss": 0.0213,
      "step": 5660
    },
    {
      "epoch": 4.697597348798674,
      "grad_norm": 12.355167388916016,
      "learning_rate": 6.283799368953277e-06,
      "loss": 0.0633,
      "step": 5670
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 1.1784350872039795,
      "learning_rate": 6.2787460522110555e-06,
      "loss": 0.0168,
      "step": 5680
    },
    {
      "epoch": 4.714167357083679,
      "grad_norm": 1.8448535203933716,
      "learning_rate": 6.273692735468833e-06,
      "loss": 0.0165,
      "step": 5690
    },
    {
      "epoch": 4.72245236122618,
      "grad_norm": 3.440279960632324,
      "learning_rate": 6.268639418726611e-06,
      "loss": 0.0277,
      "step": 5700
    },
    {
      "epoch": 4.730737365368682,
      "grad_norm": 1.2962629795074463,
      "learning_rate": 6.2635861019843894e-06,
      "loss": 0.0135,
      "step": 5710
    },
    {
      "epoch": 4.739022369511185,
      "grad_norm": 7.727339744567871,
      "learning_rate": 6.258532785242167e-06,
      "loss": 0.0498,
      "step": 5720
    },
    {
      "epoch": 4.747307373653687,
      "grad_norm": 0.7417356967926025,
      "learning_rate": 6.253479468499944e-06,
      "loss": 0.027,
      "step": 5730
    },
    {
      "epoch": 4.755592377796189,
      "grad_norm": 3.385453462600708,
      "learning_rate": 6.2484261517577225e-06,
      "loss": 0.0048,
      "step": 5740
    },
    {
      "epoch": 4.763877381938691,
      "grad_norm": 7.648086071014404,
      "learning_rate": 6.243372835015501e-06,
      "loss": 0.04,
      "step": 5750
    },
    {
      "epoch": 4.7721623860811935,
      "grad_norm": 0.009490731172263622,
      "learning_rate": 6.238319518273277e-06,
      "loss": 0.0074,
      "step": 5760
    },
    {
      "epoch": 4.780447390223695,
      "grad_norm": 4.460846424102783,
      "learning_rate": 6.2332662015310556e-06,
      "loss": 0.0113,
      "step": 5770
    },
    {
      "epoch": 4.788732394366197,
      "grad_norm": 0.0035381773486733437,
      "learning_rate": 6.228212884788834e-06,
      "loss": 0.0172,
      "step": 5780
    },
    {
      "epoch": 4.797017398508699,
      "grad_norm": 0.1630699187517166,
      "learning_rate": 6.223159568046612e-06,
      "loss": 0.0478,
      "step": 5790
    },
    {
      "epoch": 4.8053024026512015,
      "grad_norm": 0.11910494416952133,
      "learning_rate": 6.218106251304389e-06,
      "loss": 0.0339,
      "step": 5800
    },
    {
      "epoch": 4.813587406793704,
      "grad_norm": 0.12612798810005188,
      "learning_rate": 6.213052934562167e-06,
      "loss": 0.011,
      "step": 5810
    },
    {
      "epoch": 4.821872410936205,
      "grad_norm": 0.03138132393360138,
      "learning_rate": 6.207999617819945e-06,
      "loss": 0.0315,
      "step": 5820
    },
    {
      "epoch": 4.830157415078707,
      "grad_norm": 0.15106576681137085,
      "learning_rate": 6.202946301077723e-06,
      "loss": 0.025,
      "step": 5830
    },
    {
      "epoch": 4.838442419221209,
      "grad_norm": 7.7745442390441895,
      "learning_rate": 6.197892984335501e-06,
      "loss": 0.0289,
      "step": 5840
    },
    {
      "epoch": 4.846727423363712,
      "grad_norm": 0.222401961684227,
      "learning_rate": 6.192839667593278e-06,
      "loss": 0.004,
      "step": 5850
    },
    {
      "epoch": 4.855012427506214,
      "grad_norm": 0.00831336248666048,
      "learning_rate": 6.1877863508510565e-06,
      "loss": 0.0204,
      "step": 5860
    },
    {
      "epoch": 4.863297431648716,
      "grad_norm": 0.006316943094134331,
      "learning_rate": 6.182733034108835e-06,
      "loss": 0.0422,
      "step": 5870
    },
    {
      "epoch": 4.871582435791218,
      "grad_norm": 4.790838718414307,
      "learning_rate": 6.177679717366612e-06,
      "loss": 0.0172,
      "step": 5880
    },
    {
      "epoch": 4.87986743993372,
      "grad_norm": 0.14432980120182037,
      "learning_rate": 6.1726264006243895e-06,
      "loss": 0.0315,
      "step": 5890
    },
    {
      "epoch": 4.888152444076222,
      "grad_norm": 0.003786682151257992,
      "learning_rate": 6.167573083882168e-06,
      "loss": 0.0015,
      "step": 5900
    },
    {
      "epoch": 4.896437448218724,
      "grad_norm": 2.9755940437316895,
      "learning_rate": 6.162519767139945e-06,
      "loss": 0.0133,
      "step": 5910
    },
    {
      "epoch": 4.904722452361226,
      "grad_norm": 0.07572133094072342,
      "learning_rate": 6.1574664503977234e-06,
      "loss": 0.0079,
      "step": 5920
    },
    {
      "epoch": 4.9130074565037285,
      "grad_norm": 0.007224014960229397,
      "learning_rate": 6.152413133655501e-06,
      "loss": 0.0053,
      "step": 5930
    },
    {
      "epoch": 4.92129246064623,
      "grad_norm": 4.7206244468688965,
      "learning_rate": 6.147359816913278e-06,
      "loss": 0.0592,
      "step": 5940
    },
    {
      "epoch": 4.929577464788732,
      "grad_norm": 0.005017485935240984,
      "learning_rate": 6.1423065001710565e-06,
      "loss": 0.0001,
      "step": 5950
    },
    {
      "epoch": 4.937862468931234,
      "grad_norm": 0.0007359822629950941,
      "learning_rate": 6.137253183428835e-06,
      "loss": 0.0328,
      "step": 5960
    },
    {
      "epoch": 4.9461474730737365,
      "grad_norm": 0.007067001890391111,
      "learning_rate": 6.132199866686613e-06,
      "loss": 0.0001,
      "step": 5970
    },
    {
      "epoch": 4.954432477216239,
      "grad_norm": 0.007921854965388775,
      "learning_rate": 6.12714654994439e-06,
      "loss": 0.0428,
      "step": 5980
    },
    {
      "epoch": 4.962717481358741,
      "grad_norm": 0.0026686075143516064,
      "learning_rate": 6.122093233202168e-06,
      "loss": 0.0277,
      "step": 5990
    },
    {
      "epoch": 4.971002485501243,
      "grad_norm": 0.8190701007843018,
      "learning_rate": 6.117039916459946e-06,
      "loss": 0.0023,
      "step": 6000
    },
    {
      "epoch": 4.9792874896437445,
      "grad_norm": 0.06630957126617432,
      "learning_rate": 6.111986599717724e-06,
      "loss": 0.0036,
      "step": 6010
    },
    {
      "epoch": 4.987572493786247,
      "grad_norm": 0.00532712833955884,
      "learning_rate": 6.106933282975501e-06,
      "loss": 0.014,
      "step": 6020
    },
    {
      "epoch": 4.995857497928749,
      "grad_norm": 0.0036656749434769154,
      "learning_rate": 6.101879966233279e-06,
      "loss": 0.004,
      "step": 6030
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9922630560928434,
      "eval_f1": 0.9566982408660352,
      "eval_loss": 0.03713385388255119,
      "eval_precision": 0.9778699861687413,
      "eval_recall": 0.9364238410596026,
      "eval_runtime": 1226.0199,
      "eval_samples_per_second": 6.751,
      "eval_steps_per_second": 0.844,
      "step": 6035
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9922630560928434,
      "eval_f1": 0.9566982408660352,
      "eval_loss": 0.03713385388255119,
      "eval_precision": 0.9778699861687413,
      "eval_recall": 0.9364238410596026,
      "eval_runtime": 1200.41,
      "eval_samples_per_second": 6.895,
      "eval_steps_per_second": 0.862,
      "step": 6035
    },
    {
      "epoch": 5.004142502071251,
      "grad_norm": 0.10937926918268204,
      "learning_rate": 6.096826649491057e-06,
      "loss": 0.0047,
      "step": 6040
    },
    {
      "epoch": 5.012427506213753,
      "grad_norm": 4.863097667694092,
      "learning_rate": 6.091773332748836e-06,
      "loss": 0.0133,
      "step": 6050
    },
    {
      "epoch": 5.0207125103562555,
      "grad_norm": 0.009552571922540665,
      "learning_rate": 6.086720016006612e-06,
      "loss": 0.0151,
      "step": 6060
    },
    {
      "epoch": 5.028997514498757,
      "grad_norm": 0.008888110518455505,
      "learning_rate": 6.0816666992643905e-06,
      "loss": 0.0016,
      "step": 6070
    },
    {
      "epoch": 5.037282518641259,
      "grad_norm": 0.060877811163663864,
      "learning_rate": 6.076613382522169e-06,
      "loss": 0.0001,
      "step": 6080
    },
    {
      "epoch": 5.045567522783761,
      "grad_norm": 0.017715083435177803,
      "learning_rate": 6.071560065779946e-06,
      "loss": 0.0202,
      "step": 6090
    },
    {
      "epoch": 5.0538525269262635,
      "grad_norm": 0.04507438838481903,
      "learning_rate": 6.066506749037724e-06,
      "loss": 0.0004,
      "step": 6100
    },
    {
      "epoch": 5.062137531068766,
      "grad_norm": 0.007901209406554699,
      "learning_rate": 6.061453432295502e-06,
      "loss": 0.0179,
      "step": 6110
    },
    {
      "epoch": 5.070422535211268,
      "grad_norm": 0.01973723992705345,
      "learning_rate": 6.05640011555328e-06,
      "loss": 0.004,
      "step": 6120
    },
    {
      "epoch": 5.078707539353769,
      "grad_norm": 0.3570236563682556,
      "learning_rate": 6.0513467988110575e-06,
      "loss": 0.0256,
      "step": 6130
    },
    {
      "epoch": 5.0869925434962715,
      "grad_norm": 0.22943860292434692,
      "learning_rate": 6.046293482068836e-06,
      "loss": 0.017,
      "step": 6140
    },
    {
      "epoch": 5.095277547638774,
      "grad_norm": 0.004805842414498329,
      "learning_rate": 6.041240165326613e-06,
      "loss": 0.0078,
      "step": 6150
    },
    {
      "epoch": 5.103562551781276,
      "grad_norm": 0.032733429223299026,
      "learning_rate": 6.0361868485843905e-06,
      "loss": 0.0384,
      "step": 6160
    },
    {
      "epoch": 5.111847555923778,
      "grad_norm": 6.861148357391357,
      "learning_rate": 6.031133531842169e-06,
      "loss": 0.0456,
      "step": 6170
    },
    {
      "epoch": 5.12013256006628,
      "grad_norm": 0.1355857402086258,
      "learning_rate": 6.026080215099947e-06,
      "loss": 0.0254,
      "step": 6180
    },
    {
      "epoch": 5.128417564208782,
      "grad_norm": 0.0769440233707428,
      "learning_rate": 6.021026898357724e-06,
      "loss": 0.0036,
      "step": 6190
    },
    {
      "epoch": 5.136702568351284,
      "grad_norm": 3.702479839324951,
      "learning_rate": 6.015973581615502e-06,
      "loss": 0.0203,
      "step": 6200
    },
    {
      "epoch": 5.144987572493786,
      "grad_norm": 0.005509663373231888,
      "learning_rate": 6.01092026487328e-06,
      "loss": 0.0006,
      "step": 6210
    },
    {
      "epoch": 5.153272576636288,
      "grad_norm": 0.0875454768538475,
      "learning_rate": 6.005866948131058e-06,
      "loss": 0.0134,
      "step": 6220
    },
    {
      "epoch": 5.161557580778791,
      "grad_norm": 0.002123165177181363,
      "learning_rate": 6.000813631388837e-06,
      "loss": 0.0055,
      "step": 6230
    },
    {
      "epoch": 5.169842584921293,
      "grad_norm": 4.61250114440918,
      "learning_rate": 5.995760314646613e-06,
      "loss": 0.0008,
      "step": 6240
    },
    {
      "epoch": 5.178127589063794,
      "grad_norm": 0.0017479956150054932,
      "learning_rate": 5.9907069979043914e-06,
      "loss": 0.0225,
      "step": 6250
    },
    {
      "epoch": 5.186412593206296,
      "grad_norm": 0.009126877412199974,
      "learning_rate": 5.98565368116217e-06,
      "loss": 0.0169,
      "step": 6260
    },
    {
      "epoch": 5.1946975973487985,
      "grad_norm": 0.0043102651834487915,
      "learning_rate": 5.980600364419947e-06,
      "loss": 0.0111,
      "step": 6270
    },
    {
      "epoch": 5.202982601491301,
      "grad_norm": 0.008609828539192677,
      "learning_rate": 5.9755470476777245e-06,
      "loss": 0.0075,
      "step": 6280
    },
    {
      "epoch": 5.211267605633803,
      "grad_norm": 9.067154884338379,
      "learning_rate": 5.970493730935503e-06,
      "loss": 0.0422,
      "step": 6290
    },
    {
      "epoch": 5.219552609776305,
      "grad_norm": 0.3069058358669281,
      "learning_rate": 5.965440414193281e-06,
      "loss": 0.0014,
      "step": 6300
    },
    {
      "epoch": 5.2278376139188065,
      "grad_norm": 0.0025555728934705257,
      "learning_rate": 5.960387097451058e-06,
      "loss": 0.0137,
      "step": 6310
    },
    {
      "epoch": 5.236122618061309,
      "grad_norm": 0.00388315599411726,
      "learning_rate": 5.955333780708836e-06,
      "loss": 0.0143,
      "step": 6320
    },
    {
      "epoch": 5.244407622203811,
      "grad_norm": 4.046947002410889,
      "learning_rate": 5.950280463966614e-06,
      "loss": 0.0154,
      "step": 6330
    },
    {
      "epoch": 5.252692626346313,
      "grad_norm": 0.967959463596344,
      "learning_rate": 5.9452271472243915e-06,
      "loss": 0.0093,
      "step": 6340
    },
    {
      "epoch": 5.260977630488815,
      "grad_norm": 0.37430325150489807,
      "learning_rate": 5.94017383048217e-06,
      "loss": 0.0014,
      "step": 6350
    },
    {
      "epoch": 5.269262634631318,
      "grad_norm": 0.5928346514701843,
      "learning_rate": 5.935120513739948e-06,
      "loss": 0.0038,
      "step": 6360
    },
    {
      "epoch": 5.27754763877382,
      "grad_norm": 0.0013060062192380428,
      "learning_rate": 5.930067196997725e-06,
      "loss": 0.0067,
      "step": 6370
    },
    {
      "epoch": 5.285832642916321,
      "grad_norm": 0.0005478027742356062,
      "learning_rate": 5.925013880255503e-06,
      "loss": 0.017,
      "step": 6380
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 0.007775681558996439,
      "learning_rate": 5.919960563513281e-06,
      "loss": 0.0143,
      "step": 6390
    },
    {
      "epoch": 5.302402651201326,
      "grad_norm": 0.015243494883179665,
      "learning_rate": 5.914907246771059e-06,
      "loss": 0.0178,
      "step": 6400
    },
    {
      "epoch": 5.310687655343828,
      "grad_norm": 5.312691688537598,
      "learning_rate": 5.909853930028836e-06,
      "loss": 0.0355,
      "step": 6410
    },
    {
      "epoch": 5.31897265948633,
      "grad_norm": 0.0016010449035093188,
      "learning_rate": 5.904800613286614e-06,
      "loss": 0.0028,
      "step": 6420
    },
    {
      "epoch": 5.327257663628831,
      "grad_norm": 15.939936637878418,
      "learning_rate": 5.899747296544392e-06,
      "loss": 0.0147,
      "step": 6430
    },
    {
      "epoch": 5.335542667771334,
      "grad_norm": 0.23263685405254364,
      "learning_rate": 5.894693979802171e-06,
      "loss": 0.0008,
      "step": 6440
    },
    {
      "epoch": 5.343827671913836,
      "grad_norm": 0.09160737693309784,
      "learning_rate": 5.889640663059947e-06,
      "loss": 0.0028,
      "step": 6450
    },
    {
      "epoch": 5.352112676056338,
      "grad_norm": 3.323472261428833,
      "learning_rate": 5.8845873463177254e-06,
      "loss": 0.0033,
      "step": 6460
    },
    {
      "epoch": 5.36039768019884,
      "grad_norm": 0.04482261836528778,
      "learning_rate": 5.879534029575504e-06,
      "loss": 0.0071,
      "step": 6470
    },
    {
      "epoch": 5.368682684341342,
      "grad_norm": 0.011074147187173367,
      "learning_rate": 5.874480712833282e-06,
      "loss": 0.0308,
      "step": 6480
    },
    {
      "epoch": 5.376967688483845,
      "grad_norm": 0.0013660795520991087,
      "learning_rate": 5.869427396091059e-06,
      "loss": 0.0145,
      "step": 6490
    },
    {
      "epoch": 5.385252692626346,
      "grad_norm": 0.00023827912809792906,
      "learning_rate": 5.864374079348837e-06,
      "loss": 0.0008,
      "step": 6500
    },
    {
      "epoch": 5.393537696768848,
      "grad_norm": 0.0011819183127954602,
      "learning_rate": 5.859320762606615e-06,
      "loss": 0.0147,
      "step": 6510
    },
    {
      "epoch": 5.40182270091135,
      "grad_norm": 0.05828912928700447,
      "learning_rate": 5.8542674458643924e-06,
      "loss": 0.0029,
      "step": 6520
    },
    {
      "epoch": 5.410107705053853,
      "grad_norm": 0.35032135248184204,
      "learning_rate": 5.849214129122171e-06,
      "loss": 0.0027,
      "step": 6530
    },
    {
      "epoch": 5.418392709196355,
      "grad_norm": 0.008779345080256462,
      "learning_rate": 5.844160812379948e-06,
      "loss": 0.0263,
      "step": 6540
    },
    {
      "epoch": 5.426677713338857,
      "grad_norm": 0.028171829879283905,
      "learning_rate": 5.839107495637726e-06,
      "loss": 0.02,
      "step": 6550
    },
    {
      "epoch": 5.434962717481358,
      "grad_norm": 0.008515874855220318,
      "learning_rate": 5.834054178895504e-06,
      "loss": 0.0039,
      "step": 6560
    },
    {
      "epoch": 5.443247721623861,
      "grad_norm": 0.015500218607485294,
      "learning_rate": 5.829000862153282e-06,
      "loss": 0.0073,
      "step": 6570
    },
    {
      "epoch": 5.451532725766363,
      "grad_norm": 7.475865364074707,
      "learning_rate": 5.823947545411059e-06,
      "loss": 0.0163,
      "step": 6580
    },
    {
      "epoch": 5.459817729908865,
      "grad_norm": 0.004700752440840006,
      "learning_rate": 5.818894228668837e-06,
      "loss": 0.0026,
      "step": 6590
    },
    {
      "epoch": 5.468102734051367,
      "grad_norm": 0.00129206501878798,
      "learning_rate": 5.813840911926615e-06,
      "loss": 0.0029,
      "step": 6600
    },
    {
      "epoch": 5.4763877381938695,
      "grad_norm": 0.18842288851737976,
      "learning_rate": 5.808787595184393e-06,
      "loss": 0.0083,
      "step": 6610
    },
    {
      "epoch": 5.484672742336371,
      "grad_norm": 26.229536056518555,
      "learning_rate": 5.803734278442172e-06,
      "loss": 0.0265,
      "step": 6620
    },
    {
      "epoch": 5.492957746478873,
      "grad_norm": 15.269270896911621,
      "learning_rate": 5.798680961699948e-06,
      "loss": 0.0558,
      "step": 6630
    },
    {
      "epoch": 5.501242750621375,
      "grad_norm": 0.1050521582365036,
      "learning_rate": 5.793627644957726e-06,
      "loss": 0.0022,
      "step": 6640
    },
    {
      "epoch": 5.5095277547638775,
      "grad_norm": 0.07267671823501587,
      "learning_rate": 5.788574328215505e-06,
      "loss": 0.0306,
      "step": 6650
    },
    {
      "epoch": 5.51781275890638,
      "grad_norm": 0.0049124970100820065,
      "learning_rate": 5.783521011473283e-06,
      "loss": 0.0233,
      "step": 6660
    },
    {
      "epoch": 5.526097763048882,
      "grad_norm": 0.4759010970592499,
      "learning_rate": 5.7784676947310595e-06,
      "loss": 0.0011,
      "step": 6670
    },
    {
      "epoch": 5.534382767191383,
      "grad_norm": 6.123138427734375,
      "learning_rate": 5.773414377988838e-06,
      "loss": 0.0172,
      "step": 6680
    },
    {
      "epoch": 5.542667771333885,
      "grad_norm": 4.345461368560791,
      "learning_rate": 5.768361061246616e-06,
      "loss": 0.0197,
      "step": 6690
    },
    {
      "epoch": 5.550952775476388,
      "grad_norm": 0.48229658603668213,
      "learning_rate": 5.763307744504393e-06,
      "loss": 0.0062,
      "step": 6700
    },
    {
      "epoch": 5.55923777961889,
      "grad_norm": 0.00032288904185406864,
      "learning_rate": 5.758254427762171e-06,
      "loss": 0.0039,
      "step": 6710
    },
    {
      "epoch": 5.567522783761392,
      "grad_norm": 0.047405071556568146,
      "learning_rate": 5.753201111019949e-06,
      "loss": 0.0387,
      "step": 6720
    },
    {
      "epoch": 5.575807787903894,
      "grad_norm": 0.0003611006250139326,
      "learning_rate": 5.748147794277727e-06,
      "loss": 0.0256,
      "step": 6730
    },
    {
      "epoch": 5.584092792046396,
      "grad_norm": 0.0028696043882519007,
      "learning_rate": 5.743094477535505e-06,
      "loss": 0.0044,
      "step": 6740
    },
    {
      "epoch": 5.592377796188898,
      "grad_norm": 16.00385284423828,
      "learning_rate": 5.738041160793283e-06,
      "loss": 0.0456,
      "step": 6750
    },
    {
      "epoch": 5.6006628003314,
      "grad_norm": 0.005232041701674461,
      "learning_rate": 5.73298784405106e-06,
      "loss": 0.0187,
      "step": 6760
    },
    {
      "epoch": 5.608947804473902,
      "grad_norm": 0.5217763185501099,
      "learning_rate": 5.727934527308838e-06,
      "loss": 0.025,
      "step": 6770
    },
    {
      "epoch": 5.6172328086164045,
      "grad_norm": 6.7354583740234375,
      "learning_rate": 5.722881210566616e-06,
      "loss": 0.0166,
      "step": 6780
    },
    {
      "epoch": 5.625517812758907,
      "grad_norm": 0.4568021893501282,
      "learning_rate": 5.717827893824394e-06,
      "loss": 0.0215,
      "step": 6790
    },
    {
      "epoch": 5.633802816901408,
      "grad_norm": 0.0025399946607649326,
      "learning_rate": 5.712774577082172e-06,
      "loss": 0.0129,
      "step": 6800
    },
    {
      "epoch": 5.64208782104391,
      "grad_norm": 0.04006042331457138,
      "learning_rate": 5.707721260339949e-06,
      "loss": 0.0034,
      "step": 6810
    },
    {
      "epoch": 5.6503728251864125,
      "grad_norm": 1.5285934209823608,
      "learning_rate": 5.702667943597727e-06,
      "loss": 0.0027,
      "step": 6820
    },
    {
      "epoch": 5.658657829328915,
      "grad_norm": 0.20026375353336334,
      "learning_rate": 5.697614626855506e-06,
      "loss": 0.0003,
      "step": 6830
    },
    {
      "epoch": 5.666942833471417,
      "grad_norm": 0.014628984965384007,
      "learning_rate": 5.692561310113282e-06,
      "loss": 0.0072,
      "step": 6840
    },
    {
      "epoch": 5.675227837613919,
      "grad_norm": 0.5544551014900208,
      "learning_rate": 5.68750799337106e-06,
      "loss": 0.0028,
      "step": 6850
    },
    {
      "epoch": 5.683512841756421,
      "grad_norm": 0.013575003482401371,
      "learning_rate": 5.682454676628839e-06,
      "loss": 0.0424,
      "step": 6860
    },
    {
      "epoch": 5.691797845898923,
      "grad_norm": 0.004469745792448521,
      "learning_rate": 5.677401359886617e-06,
      "loss": 0.0026,
      "step": 6870
    },
    {
      "epoch": 5.700082850041425,
      "grad_norm": 0.0381770096719265,
      "learning_rate": 5.672348043144394e-06,
      "loss": 0.0266,
      "step": 6880
    },
    {
      "epoch": 5.708367854183927,
      "grad_norm": 0.3896876275539398,
      "learning_rate": 5.667294726402172e-06,
      "loss": 0.0054,
      "step": 6890
    },
    {
      "epoch": 5.716652858326429,
      "grad_norm": 0.08741969615221024,
      "learning_rate": 5.66224140965995e-06,
      "loss": 0.0274,
      "step": 6900
    },
    {
      "epoch": 5.7249378624689315,
      "grad_norm": 0.31366515159606934,
      "learning_rate": 5.657188092917728e-06,
      "loss": 0.0051,
      "step": 6910
    },
    {
      "epoch": 5.733222866611433,
      "grad_norm": 0.07484995573759079,
      "learning_rate": 5.652134776175506e-06,
      "loss": 0.0179,
      "step": 6920
    },
    {
      "epoch": 5.741507870753935,
      "grad_norm": 0.9015611410140991,
      "learning_rate": 5.647081459433283e-06,
      "loss": 0.0076,
      "step": 6930
    },
    {
      "epoch": 5.749792874896437,
      "grad_norm": 2.827454090118408,
      "learning_rate": 5.642028142691061e-06,
      "loss": 0.0067,
      "step": 6940
    },
    {
      "epoch": 5.7580778790389395,
      "grad_norm": 0.9913235902786255,
      "learning_rate": 5.636974825948839e-06,
      "loss": 0.0334,
      "step": 6950
    },
    {
      "epoch": 5.766362883181442,
      "grad_norm": 0.011999073438346386,
      "learning_rate": 5.631921509206617e-06,
      "loss": 0.026,
      "step": 6960
    },
    {
      "epoch": 5.774647887323944,
      "grad_norm": 0.01164333801716566,
      "learning_rate": 5.626868192464394e-06,
      "loss": 0.0203,
      "step": 6970
    },
    {
      "epoch": 5.782932891466446,
      "grad_norm": 0.005497945938259363,
      "learning_rate": 5.621814875722173e-06,
      "loss": 0.0349,
      "step": 6980
    },
    {
      "epoch": 5.7912178956089475,
      "grad_norm": 0.7145596742630005,
      "learning_rate": 5.61676155897995e-06,
      "loss": 0.0328,
      "step": 6990
    },
    {
      "epoch": 5.79950289975145,
      "grad_norm": 5.059746742248535,
      "learning_rate": 5.611708242237728e-06,
      "loss": 0.0219,
      "step": 7000
    },
    {
      "epoch": 5.807787903893952,
      "grad_norm": 3.2617876529693604,
      "learning_rate": 5.6066549254955066e-06,
      "loss": 0.0035,
      "step": 7010
    },
    {
      "epoch": 5.816072908036454,
      "grad_norm": 0.007911672815680504,
      "learning_rate": 5.601601608753283e-06,
      "loss": 0.0287,
      "step": 7020
    },
    {
      "epoch": 5.824357912178956,
      "grad_norm": 0.012626813724637032,
      "learning_rate": 5.596548292011061e-06,
      "loss": 0.0236,
      "step": 7030
    },
    {
      "epoch": 5.832642916321458,
      "grad_norm": 0.3137657344341278,
      "learning_rate": 5.59149497526884e-06,
      "loss": 0.0507,
      "step": 7040
    },
    {
      "epoch": 5.84092792046396,
      "grad_norm": 0.03586464002728462,
      "learning_rate": 5.586441658526618e-06,
      "loss": 0.0256,
      "step": 7050
    },
    {
      "epoch": 5.849212924606462,
      "grad_norm": 8.908127784729004,
      "learning_rate": 5.5813883417843944e-06,
      "loss": 0.0304,
      "step": 7060
    },
    {
      "epoch": 5.857497928748964,
      "grad_norm": 0.003462183056399226,
      "learning_rate": 5.576335025042173e-06,
      "loss": 0.0012,
      "step": 7070
    },
    {
      "epoch": 5.865782932891467,
      "grad_norm": 0.08255962282419205,
      "learning_rate": 5.571281708299951e-06,
      "loss": 0.0439,
      "step": 7080
    },
    {
      "epoch": 5.874067937033969,
      "grad_norm": 6.8433332443237305,
      "learning_rate": 5.566228391557729e-06,
      "loss": 0.0181,
      "step": 7090
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 2.2128634452819824,
      "learning_rate": 5.561175074815506e-06,
      "loss": 0.0051,
      "step": 7100
    },
    {
      "epoch": 5.890637945318972,
      "grad_norm": 0.015268322080373764,
      "learning_rate": 5.556121758073284e-06,
      "loss": 0.0368,
      "step": 7110
    },
    {
      "epoch": 5.8989229494614746,
      "grad_norm": 0.07491800934076309,
      "learning_rate": 5.551068441331062e-06,
      "loss": 0.0025,
      "step": 7120
    },
    {
      "epoch": 5.907207953603977,
      "grad_norm": 0.15823188424110413,
      "learning_rate": 5.54601512458884e-06,
      "loss": 0.0141,
      "step": 7130
    },
    {
      "epoch": 5.915492957746479,
      "grad_norm": 0.0013109897263348103,
      "learning_rate": 5.540961807846618e-06,
      "loss": 0.0217,
      "step": 7140
    },
    {
      "epoch": 5.923777961888981,
      "grad_norm": 0.4633348882198334,
      "learning_rate": 5.535908491104395e-06,
      "loss": 0.0131,
      "step": 7150
    },
    {
      "epoch": 5.9320629660314825,
      "grad_norm": 0.02172536589205265,
      "learning_rate": 5.530855174362174e-06,
      "loss": 0.0012,
      "step": 7160
    },
    {
      "epoch": 5.940347970173985,
      "grad_norm": 0.018665820360183716,
      "learning_rate": 5.525801857619951e-06,
      "loss": 0.0033,
      "step": 7170
    },
    {
      "epoch": 5.948632974316487,
      "grad_norm": 0.15442807972431183,
      "learning_rate": 5.520748540877729e-06,
      "loss": 0.0203,
      "step": 7180
    },
    {
      "epoch": 5.956917978458989,
      "grad_norm": 0.011783206835389137,
      "learning_rate": 5.515695224135507e-06,
      "loss": 0.0001,
      "step": 7190
    },
    {
      "epoch": 5.965202982601491,
      "grad_norm": 0.0022113334853202105,
      "learning_rate": 5.510641907393284e-06,
      "loss": 0.0022,
      "step": 7200
    },
    {
      "epoch": 5.973487986743994,
      "grad_norm": 3.299630641937256,
      "learning_rate": 5.505588590651062e-06,
      "loss": 0.0089,
      "step": 7210
    },
    {
      "epoch": 5.981772990886496,
      "grad_norm": 0.002354425610974431,
      "learning_rate": 5.5005352739088406e-06,
      "loss": 0.009,
      "step": 7220
    },
    {
      "epoch": 5.990057995028997,
      "grad_norm": 0.37459349632263184,
      "learning_rate": 5.495481957166618e-06,
      "loss": 0.0184,
      "step": 7230
    },
    {
      "epoch": 5.998342999171499,
      "grad_norm": 1.0899590253829956,
      "learning_rate": 5.490428640424395e-06,
      "loss": 0.0077,
      "step": 7240
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9928675048355899,
      "eval_f1": 0.9608493696084937,
      "eval_loss": 0.03125173598527908,
      "eval_precision": 0.9627659574468085,
      "eval_recall": 0.9589403973509933,
      "eval_runtime": 1170.135,
      "eval_samples_per_second": 7.074,
      "eval_steps_per_second": 0.885,
      "step": 7242
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9928675048355899,
      "eval_f1": 0.9608493696084937,
      "eval_loss": 0.03125173598527908,
      "eval_precision": 0.9627659574468085,
      "eval_recall": 0.9589403973509933,
      "eval_runtime": 1180.7134,
      "eval_samples_per_second": 7.01,
      "eval_steps_per_second": 0.877,
      "step": 7242
    },
    {
      "epoch": 6.006628003314002,
      "grad_norm": 0.005492446478456259,
      "learning_rate": 5.485375323682174e-06,
      "loss": 0.0152,
      "step": 7250
    },
    {
      "epoch": 6.014913007456504,
      "grad_norm": 0.04053564369678497,
      "learning_rate": 5.480322006939952e-06,
      "loss": 0.0004,
      "step": 7260
    },
    {
      "epoch": 6.023198011599006,
      "grad_norm": 0.007819389924407005,
      "learning_rate": 5.47526869019773e-06,
      "loss": 0.0334,
      "step": 7270
    },
    {
      "epoch": 6.031483015741508,
      "grad_norm": 0.009880856610834599,
      "learning_rate": 5.470215373455507e-06,
      "loss": 0.0267,
      "step": 7280
    },
    {
      "epoch": 6.03976801988401,
      "grad_norm": 0.0024891572538763285,
      "learning_rate": 5.465162056713285e-06,
      "loss": 0.0071,
      "step": 7290
    },
    {
      "epoch": 6.048053024026512,
      "grad_norm": 0.05228222906589508,
      "learning_rate": 5.460108739971063e-06,
      "loss": 0.0057,
      "step": 7300
    },
    {
      "epoch": 6.056338028169014,
      "grad_norm": 0.0051988414488732815,
      "learning_rate": 5.455055423228841e-06,
      "loss": 0.0092,
      "step": 7310
    },
    {
      "epoch": 6.064623032311516,
      "grad_norm": 3.8473398685455322,
      "learning_rate": 5.450002106486618e-06,
      "loss": 0.006,
      "step": 7320
    },
    {
      "epoch": 6.072908036454018,
      "grad_norm": 0.0009778010426089168,
      "learning_rate": 5.444948789744396e-06,
      "loss": 0.0001,
      "step": 7330
    },
    {
      "epoch": 6.081193040596521,
      "grad_norm": 0.013474413193762302,
      "learning_rate": 5.4398954730021745e-06,
      "loss": 0.0158,
      "step": 7340
    },
    {
      "epoch": 6.089478044739022,
      "grad_norm": 1.4304900169372559,
      "learning_rate": 5.434842156259952e-06,
      "loss": 0.0047,
      "step": 7350
    },
    {
      "epoch": 6.097763048881524,
      "grad_norm": 7.936012843856588e-05,
      "learning_rate": 5.429788839517729e-06,
      "loss": 0.0265,
      "step": 7360
    },
    {
      "epoch": 6.106048053024026,
      "grad_norm": 4.704567909240723,
      "learning_rate": 5.424735522775508e-06,
      "loss": 0.0103,
      "step": 7370
    },
    {
      "epoch": 6.114333057166529,
      "grad_norm": 0.052381597459316254,
      "learning_rate": 5.419682206033285e-06,
      "loss": 0.0131,
      "step": 7380
    },
    {
      "epoch": 6.122618061309031,
      "grad_norm": 0.05921921133995056,
      "learning_rate": 5.414628889291063e-06,
      "loss": 0.0014,
      "step": 7390
    },
    {
      "epoch": 6.130903065451533,
      "grad_norm": 5.2473225593566895,
      "learning_rate": 5.4095755725488415e-06,
      "loss": 0.011,
      "step": 7400
    },
    {
      "epoch": 6.139188069594034,
      "grad_norm": 0.0018714697798714042,
      "learning_rate": 5.404522255806619e-06,
      "loss": 0.0209,
      "step": 7410
    },
    {
      "epoch": 6.147473073736537,
      "grad_norm": 0.004829104524105787,
      "learning_rate": 5.399468939064396e-06,
      "loss": 0.0088,
      "step": 7420
    },
    {
      "epoch": 6.155758077879039,
      "grad_norm": 1.058707594871521,
      "learning_rate": 5.394415622322175e-06,
      "loss": 0.0249,
      "step": 7430
    },
    {
      "epoch": 6.164043082021541,
      "grad_norm": 0.0007557275239378214,
      "learning_rate": 5.389362305579953e-06,
      "loss": 0.0138,
      "step": 7440
    },
    {
      "epoch": 6.172328086164043,
      "grad_norm": 20.909557342529297,
      "learning_rate": 5.384308988837729e-06,
      "loss": 0.0126,
      "step": 7450
    },
    {
      "epoch": 6.1806130903065455,
      "grad_norm": 0.27111873030662537,
      "learning_rate": 5.379255672095508e-06,
      "loss": 0.0019,
      "step": 7460
    },
    {
      "epoch": 6.188898094449047,
      "grad_norm": 5.778200626373291,
      "learning_rate": 5.374202355353286e-06,
      "loss": 0.011,
      "step": 7470
    },
    {
      "epoch": 6.197183098591549,
      "grad_norm": 0.007424940355122089,
      "learning_rate": 5.369149038611064e-06,
      "loss": 0.0,
      "step": 7480
    },
    {
      "epoch": 6.205468102734051,
      "grad_norm": 0.009731261059641838,
      "learning_rate": 5.364095721868841e-06,
      "loss": 0.0039,
      "step": 7490
    },
    {
      "epoch": 6.2137531068765535,
      "grad_norm": 0.004580053500831127,
      "learning_rate": 5.359042405126619e-06,
      "loss": 0.0184,
      "step": 7500
    },
    {
      "epoch": 6.222038111019056,
      "grad_norm": 0.001230941852554679,
      "learning_rate": 5.353989088384397e-06,
      "loss": 0.0023,
      "step": 7510
    },
    {
      "epoch": 6.230323115161558,
      "grad_norm": 0.02431333437561989,
      "learning_rate": 5.3489357716421755e-06,
      "loss": 0.0186,
      "step": 7520
    },
    {
      "epoch": 6.238608119304059,
      "grad_norm": 0.023796476423740387,
      "learning_rate": 5.343882454899952e-06,
      "loss": 0.0006,
      "step": 7530
    },
    {
      "epoch": 6.2468931234465614,
      "grad_norm": 0.18791690468788147,
      "learning_rate": 5.33882913815773e-06,
      "loss": 0.0025,
      "step": 7540
    },
    {
      "epoch": 6.255178127589064,
      "grad_norm": 0.0019388305954635143,
      "learning_rate": 5.3337758214155086e-06,
      "loss": 0.0108,
      "step": 7550
    },
    {
      "epoch": 6.263463131731566,
      "grad_norm": 2.839646339416504,
      "learning_rate": 5.328722504673286e-06,
      "loss": 0.0068,
      "step": 7560
    },
    {
      "epoch": 6.271748135874068,
      "grad_norm": 0.00665175449103117,
      "learning_rate": 5.323669187931064e-06,
      "loss": 0.0187,
      "step": 7570
    },
    {
      "epoch": 6.28003314001657,
      "grad_norm": 0.0005441204993985593,
      "learning_rate": 5.318615871188842e-06,
      "loss": 0.0076,
      "step": 7580
    },
    {
      "epoch": 6.2883181441590725,
      "grad_norm": 0.023263942450284958,
      "learning_rate": 5.31356255444662e-06,
      "loss": 0.0001,
      "step": 7590
    },
    {
      "epoch": 6.296603148301574,
      "grad_norm": 0.06788693368434906,
      "learning_rate": 5.308509237704397e-06,
      "loss": 0.0167,
      "step": 7600
    },
    {
      "epoch": 6.304888152444076,
      "grad_norm": 0.005660218186676502,
      "learning_rate": 5.3034559209621755e-06,
      "loss": 0.0045,
      "step": 7610
    },
    {
      "epoch": 6.313173156586578,
      "grad_norm": 0.1742277592420578,
      "learning_rate": 5.298402604219953e-06,
      "loss": 0.0064,
      "step": 7620
    },
    {
      "epoch": 6.3214581607290805,
      "grad_norm": 0.00011735841690097004,
      "learning_rate": 5.29334928747773e-06,
      "loss": 0.0102,
      "step": 7630
    },
    {
      "epoch": 6.329743164871583,
      "grad_norm": 0.02048402838408947,
      "learning_rate": 5.288295970735509e-06,
      "loss": 0.0095,
      "step": 7640
    },
    {
      "epoch": 6.338028169014084,
      "grad_norm": 0.018603160977363586,
      "learning_rate": 5.283242653993287e-06,
      "loss": 0.019,
      "step": 7650
    },
    {
      "epoch": 6.346313173156586,
      "grad_norm": 3.519136428833008,
      "learning_rate": 5.278189337251064e-06,
      "loss": 0.0367,
      "step": 7660
    },
    {
      "epoch": 6.3545981772990885,
      "grad_norm": 2.237926721572876,
      "learning_rate": 5.273136020508842e-06,
      "loss": 0.0379,
      "step": 7670
    },
    {
      "epoch": 6.362883181441591,
      "grad_norm": 0.12488594651222229,
      "learning_rate": 5.26808270376662e-06,
      "loss": 0.0156,
      "step": 7680
    },
    {
      "epoch": 6.371168185584093,
      "grad_norm": 0.06199178099632263,
      "learning_rate": 5.263029387024398e-06,
      "loss": 0.0196,
      "step": 7690
    },
    {
      "epoch": 6.379453189726595,
      "grad_norm": 0.016497651115059853,
      "learning_rate": 5.2579760702821764e-06,
      "loss": 0.0523,
      "step": 7700
    },
    {
      "epoch": 6.387738193869097,
      "grad_norm": 5.085812568664551,
      "learning_rate": 5.252922753539953e-06,
      "loss": 0.0062,
      "step": 7710
    },
    {
      "epoch": 6.396023198011599,
      "grad_norm": 8.7073392868042,
      "learning_rate": 5.247869436797731e-06,
      "loss": 0.0476,
      "step": 7720
    },
    {
      "epoch": 6.404308202154101,
      "grad_norm": 8.653952598571777,
      "learning_rate": 5.2428161200555095e-06,
      "loss": 0.029,
      "step": 7730
    },
    {
      "epoch": 6.412593206296603,
      "grad_norm": 0.0005116070387884974,
      "learning_rate": 5.237762803313288e-06,
      "loss": 0.0091,
      "step": 7740
    },
    {
      "epoch": 6.420878210439105,
      "grad_norm": 0.03084874339401722,
      "learning_rate": 5.232709486571064e-06,
      "loss": 0.0104,
      "step": 7750
    },
    {
      "epoch": 6.4291632145816076,
      "grad_norm": 0.0004316353879403323,
      "learning_rate": 5.2276561698288426e-06,
      "loss": 0.0166,
      "step": 7760
    },
    {
      "epoch": 6.43744821872411,
      "grad_norm": 0.15492475032806396,
      "learning_rate": 5.222602853086621e-06,
      "loss": 0.0173,
      "step": 7770
    },
    {
      "epoch": 6.445733222866611,
      "grad_norm": 0.04151339828968048,
      "learning_rate": 5.217549536344398e-06,
      "loss": 0.0018,
      "step": 7780
    },
    {
      "epoch": 6.454018227009113,
      "grad_norm": 13.88277816772461,
      "learning_rate": 5.212496219602176e-06,
      "loss": 0.0281,
      "step": 7790
    },
    {
      "epoch": 6.4623032311516155,
      "grad_norm": 0.010678502731025219,
      "learning_rate": 5.207442902859954e-06,
      "loss": 0.0007,
      "step": 7800
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 3.2812421321868896,
      "learning_rate": 5.202389586117731e-06,
      "loss": 0.0127,
      "step": 7810
    },
    {
      "epoch": 6.47887323943662,
      "grad_norm": 0.07589801400899887,
      "learning_rate": 5.1973362693755096e-06,
      "loss": 0.015,
      "step": 7820
    },
    {
      "epoch": 6.487158243579122,
      "grad_norm": 0.5663973689079285,
      "learning_rate": 5.192282952633288e-06,
      "loss": 0.001,
      "step": 7830
    },
    {
      "epoch": 6.4954432477216235,
      "grad_norm": 0.0219971165060997,
      "learning_rate": 5.187229635891065e-06,
      "loss": 0.0072,
      "step": 7840
    },
    {
      "epoch": 6.503728251864126,
      "grad_norm": 0.06492476910352707,
      "learning_rate": 5.182176319148843e-06,
      "loss": 0.0181,
      "step": 7850
    },
    {
      "epoch": 6.512013256006628,
      "grad_norm": 0.0017267684452235699,
      "learning_rate": 5.177123002406621e-06,
      "loss": 0.0103,
      "step": 7860
    },
    {
      "epoch": 6.52029826014913,
      "grad_norm": 1.0644112825393677,
      "learning_rate": 5.172069685664399e-06,
      "loss": 0.0278,
      "step": 7870
    },
    {
      "epoch": 6.528583264291632,
      "grad_norm": 0.0013176227221265435,
      "learning_rate": 5.167016368922176e-06,
      "loss": 0.0176,
      "step": 7880
    },
    {
      "epoch": 6.536868268434135,
      "grad_norm": 0.27754849195480347,
      "learning_rate": 5.161963052179954e-06,
      "loss": 0.0403,
      "step": 7890
    },
    {
      "epoch": 6.545153272576636,
      "grad_norm": 0.009086995385587215,
      "learning_rate": 5.156909735437732e-06,
      "loss": 0.0002,
      "step": 7900
    },
    {
      "epoch": 6.553438276719138,
      "grad_norm": 0.23307624459266663,
      "learning_rate": 5.1518564186955105e-06,
      "loss": 0.0017,
      "step": 7910
    },
    {
      "epoch": 6.56172328086164,
      "grad_norm": 0.056453172117471695,
      "learning_rate": 5.146803101953287e-06,
      "loss": 0.0146,
      "step": 7920
    },
    {
      "epoch": 6.570008285004143,
      "grad_norm": 0.004664156120270491,
      "learning_rate": 5.141749785211065e-06,
      "loss": 0.0001,
      "step": 7930
    },
    {
      "epoch": 6.578293289146645,
      "grad_norm": 0.7709291577339172,
      "learning_rate": 5.1366964684688435e-06,
      "loss": 0.006,
      "step": 7940
    },
    {
      "epoch": 6.586578293289147,
      "grad_norm": 4.464188575744629,
      "learning_rate": 5.131643151726622e-06,
      "loss": 0.0107,
      "step": 7950
    },
    {
      "epoch": 6.594863297431648,
      "grad_norm": 0.008310073055326939,
      "learning_rate": 5.126589834984399e-06,
      "loss": 0.027,
      "step": 7960
    },
    {
      "epoch": 6.603148301574151,
      "grad_norm": 0.00014325961819849908,
      "learning_rate": 5.121536518242177e-06,
      "loss": 0.0062,
      "step": 7970
    },
    {
      "epoch": 6.611433305716653,
      "grad_norm": 0.0009027543710544705,
      "learning_rate": 5.116483201499955e-06,
      "loss": 0.0007,
      "step": 7980
    },
    {
      "epoch": 6.619718309859155,
      "grad_norm": 0.22800442576408386,
      "learning_rate": 5.111429884757733e-06,
      "loss": 0.0154,
      "step": 7990
    },
    {
      "epoch": 6.628003314001657,
      "grad_norm": 0.038001690059900284,
      "learning_rate": 5.1063765680155105e-06,
      "loss": 0.0046,
      "step": 8000
    },
    {
      "epoch": 6.636288318144159,
      "grad_norm": 0.05254733934998512,
      "learning_rate": 5.101323251273288e-06,
      "loss": 0.0296,
      "step": 8010
    },
    {
      "epoch": 6.644573322286661,
      "grad_norm": 3.551044225692749,
      "learning_rate": 5.096269934531066e-06,
      "loss": 0.0502,
      "step": 8020
    },
    {
      "epoch": 6.652858326429163,
      "grad_norm": 0.0028123208321630955,
      "learning_rate": 5.0912166177888436e-06,
      "loss": 0.0016,
      "step": 8030
    },
    {
      "epoch": 6.661143330571665,
      "grad_norm": 4.698671817779541,
      "learning_rate": 5.086163301046622e-06,
      "loss": 0.0149,
      "step": 8040
    },
    {
      "epoch": 6.669428334714167,
      "grad_norm": 0.009375941939651966,
      "learning_rate": 5.081109984304399e-06,
      "loss": 0.0132,
      "step": 8050
    },
    {
      "epoch": 6.67771333885667,
      "grad_norm": 0.2680821716785431,
      "learning_rate": 5.076056667562177e-06,
      "loss": 0.0004,
      "step": 8060
    },
    {
      "epoch": 6.685998342999172,
      "grad_norm": 0.004090732894837856,
      "learning_rate": 5.071003350819955e-06,
      "loss": 0.0077,
      "step": 8070
    },
    {
      "epoch": 6.694283347141674,
      "grad_norm": 0.030154509469866753,
      "learning_rate": 5.065950034077733e-06,
      "loss": 0.001,
      "step": 8080
    },
    {
      "epoch": 6.702568351284175,
      "grad_norm": 0.43040749430656433,
      "learning_rate": 5.060896717335511e-06,
      "loss": 0.0064,
      "step": 8090
    },
    {
      "epoch": 6.710853355426678,
      "grad_norm": 0.0008498049573972821,
      "learning_rate": 5.055843400593288e-06,
      "loss": 0.0036,
      "step": 8100
    },
    {
      "epoch": 6.71913835956918,
      "grad_norm": 0.0017349865520372987,
      "learning_rate": 5.050790083851066e-06,
      "loss": 0.0268,
      "step": 8110
    },
    {
      "epoch": 6.727423363711682,
      "grad_norm": 0.16710077226161957,
      "learning_rate": 5.0457367671088445e-06,
      "loss": 0.0351,
      "step": 8120
    },
    {
      "epoch": 6.735708367854184,
      "grad_norm": 1.4370288848876953,
      "learning_rate": 5.040683450366623e-06,
      "loss": 0.0453,
      "step": 8130
    },
    {
      "epoch": 6.743993371996686,
      "grad_norm": 0.05396256595849991,
      "learning_rate": 5.035630133624399e-06,
      "loss": 0.0016,
      "step": 8140
    },
    {
      "epoch": 6.752278376139188,
      "grad_norm": 0.004330129828304052,
      "learning_rate": 5.0305768168821775e-06,
      "loss": 0.0059,
      "step": 8150
    },
    {
      "epoch": 6.76056338028169,
      "grad_norm": 0.01658380590379238,
      "learning_rate": 5.025523500139956e-06,
      "loss": 0.0244,
      "step": 8160
    },
    {
      "epoch": 6.768848384424192,
      "grad_norm": 1.7339140176773071,
      "learning_rate": 5.020470183397734e-06,
      "loss": 0.0338,
      "step": 8170
    },
    {
      "epoch": 6.7771333885666944,
      "grad_norm": 2.133232593536377,
      "learning_rate": 5.015416866655511e-06,
      "loss": 0.0349,
      "step": 8180
    },
    {
      "epoch": 6.785418392709197,
      "grad_norm": 0.02355552837252617,
      "learning_rate": 5.010363549913289e-06,
      "loss": 0.0138,
      "step": 8190
    },
    {
      "epoch": 6.793703396851699,
      "grad_norm": 9.10693645477295,
      "learning_rate": 5.005310233171067e-06,
      "loss": 0.0375,
      "step": 8200
    },
    {
      "epoch": 6.8019884009942,
      "grad_norm": 0.06095976009964943,
      "learning_rate": 5.0002569164288445e-06,
      "loss": 0.0151,
      "step": 8210
    },
    {
      "epoch": 6.810273405136702,
      "grad_norm": 0.0019525003153830767,
      "learning_rate": 4.995203599686623e-06,
      "loss": 0.0202,
      "step": 8220
    },
    {
      "epoch": 6.818558409279205,
      "grad_norm": 0.3809799253940582,
      "learning_rate": 4.9901502829444e-06,
      "loss": 0.0027,
      "step": 8230
    },
    {
      "epoch": 6.826843413421707,
      "grad_norm": 6.505613803863525,
      "learning_rate": 4.9850969662021784e-06,
      "loss": 0.0336,
      "step": 8240
    },
    {
      "epoch": 6.835128417564209,
      "grad_norm": 0.0025191891472786665,
      "learning_rate": 4.980043649459956e-06,
      "loss": 0.0215,
      "step": 8250
    },
    {
      "epoch": 6.84341342170671,
      "grad_norm": 2.282900333404541,
      "learning_rate": 4.974990332717734e-06,
      "loss": 0.0005,
      "step": 8260
    },
    {
      "epoch": 6.851698425849213,
      "grad_norm": 0.00029718628502450883,
      "learning_rate": 4.9699370159755115e-06,
      "loss": 0.0165,
      "step": 8270
    },
    {
      "epoch": 6.859983429991715,
      "grad_norm": 0.0016734208911657333,
      "learning_rate": 4.964883699233289e-06,
      "loss": 0.0021,
      "step": 8280
    },
    {
      "epoch": 6.868268434134217,
      "grad_norm": 16.82394790649414,
      "learning_rate": 4.959830382491067e-06,
      "loss": 0.0156,
      "step": 8290
    },
    {
      "epoch": 6.876553438276719,
      "grad_norm": 0.0448138564825058,
      "learning_rate": 4.954777065748845e-06,
      "loss": 0.0009,
      "step": 8300
    },
    {
      "epoch": 6.8848384424192215,
      "grad_norm": 0.0048658233135938644,
      "learning_rate": 4.949723749006622e-06,
      "loss": 0.005,
      "step": 8310
    },
    {
      "epoch": 6.893123446561724,
      "grad_norm": 2.1375744342803955,
      "learning_rate": 4.9446704322644e-06,
      "loss": 0.0035,
      "step": 8320
    },
    {
      "epoch": 6.901408450704225,
      "grad_norm": 0.0427313856780529,
      "learning_rate": 4.9396171155221785e-06,
      "loss": 0.0218,
      "step": 8330
    },
    {
      "epoch": 6.909693454846727,
      "grad_norm": 24.63555908203125,
      "learning_rate": 4.934563798779957e-06,
      "loss": 0.0154,
      "step": 8340
    },
    {
      "epoch": 6.9179784589892295,
      "grad_norm": 0.18700797855854034,
      "learning_rate": 4.929510482037735e-06,
      "loss": 0.008,
      "step": 8350
    },
    {
      "epoch": 6.926263463131732,
      "grad_norm": 0.007452512625604868,
      "learning_rate": 4.9244571652955116e-06,
      "loss": 0.0042,
      "step": 8360
    },
    {
      "epoch": 6.934548467274234,
      "grad_norm": 1.3996903896331787,
      "learning_rate": 4.91940384855329e-06,
      "loss": 0.0014,
      "step": 8370
    },
    {
      "epoch": 6.942833471416735,
      "grad_norm": 0.00682181678712368,
      "learning_rate": 4.914350531811068e-06,
      "loss": 0.0243,
      "step": 8380
    },
    {
      "epoch": 6.9511184755592375,
      "grad_norm": 1.9886518716812134,
      "learning_rate": 4.9092972150688455e-06,
      "loss": 0.0176,
      "step": 8390
    },
    {
      "epoch": 6.95940347970174,
      "grad_norm": 0.0009973058477044106,
      "learning_rate": 4.904243898326623e-06,
      "loss": 0.0384,
      "step": 8400
    },
    {
      "epoch": 6.967688483844242,
      "grad_norm": 3.3150815963745117,
      "learning_rate": 4.899190581584401e-06,
      "loss": 0.0066,
      "step": 8410
    },
    {
      "epoch": 6.975973487986744,
      "grad_norm": 0.0065665217116475105,
      "learning_rate": 4.894137264842179e-06,
      "loss": 0.017,
      "step": 8420
    },
    {
      "epoch": 6.984258492129246,
      "grad_norm": 10.744457244873047,
      "learning_rate": 4.889083948099957e-06,
      "loss": 0.018,
      "step": 8430
    },
    {
      "epoch": 6.9925434962717485,
      "grad_norm": 0.0005913330824114382,
      "learning_rate": 4.884030631357734e-06,
      "loss": 0.0112,
      "step": 8440
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9933510638297872,
      "eval_f1": 0.9629130141604855,
      "eval_loss": 0.029611174017190933,
      "eval_precision": 0.9807692307692307,
      "eval_recall": 0.9456953642384106,
      "eval_runtime": 1179.7769,
      "eval_samples_per_second": 7.016,
      "eval_steps_per_second": 0.877,
      "step": 8449
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9933510638297872,
      "eval_f1": 0.9629130141604855,
      "eval_loss": 0.029611174017190933,
      "eval_precision": 0.9807692307692307,
      "eval_recall": 0.9456953642384106,
      "eval_runtime": 1169.1035,
      "eval_samples_per_second": 7.08,
      "eval_steps_per_second": 0.885,
      "step": 8449
    }
  ],
  "logging_steps": 10,
  "max_steps": 18105,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.06803046623808e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": {
    "epochs": 15,
    "gradient_accumulation_steps": 1,
    "learning_rate": 9.079294190750586e-06,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 32,
    "warmup_steps": 138,
    "weight_decay": 0.06890605330179864
  }
}
