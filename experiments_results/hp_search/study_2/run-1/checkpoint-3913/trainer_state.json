{
  "best_metric": 0.9514304723885563,
  "best_model_checkpoint": "../hyperparameter_search/run-1/checkpoint-3913",
  "epoch": 12.97844112769486,
  "eval_steps": 500,
  "global_step": 3913,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003316749585406302,
      "grad_norm": 26.964208602905273,
      "learning_rate": 5.389732866261731e-08,
      "loss": 0.8904,
      "step": 1
    },
    {
      "epoch": 0.03316749585406302,
      "grad_norm": 25.805471420288086,
      "learning_rate": 5.389732866261732e-07,
      "loss": 0.7836,
      "step": 10
    },
    {
      "epoch": 0.06633499170812604,
      "grad_norm": 20.67563819885254,
      "learning_rate": 1.0779465732523463e-06,
      "loss": 0.7323,
      "step": 20
    },
    {
      "epoch": 0.09950248756218906,
      "grad_norm": 26.882993698120117,
      "learning_rate": 1.6169198598785191e-06,
      "loss": 0.5732,
      "step": 30
    },
    {
      "epoch": 0.13266998341625208,
      "grad_norm": 12.324896812438965,
      "learning_rate": 2.1558931465046926e-06,
      "loss": 0.4236,
      "step": 40
    },
    {
      "epoch": 0.16583747927031509,
      "grad_norm": 7.941479682922363,
      "learning_rate": 2.6948664331308657e-06,
      "loss": 0.3478,
      "step": 50
    },
    {
      "epoch": 0.19900497512437812,
      "grad_norm": 7.99422550201416,
      "learning_rate": 3.2338397197570383e-06,
      "loss": 0.3303,
      "step": 60
    },
    {
      "epoch": 0.23217247097844113,
      "grad_norm": 14.321361541748047,
      "learning_rate": 3.7728130063832118e-06,
      "loss": 0.344,
      "step": 70
    },
    {
      "epoch": 0.26533996683250416,
      "grad_norm": 11.35463809967041,
      "learning_rate": 4.311786293009385e-06,
      "loss": 0.3195,
      "step": 80
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 11.302779197692871,
      "learning_rate": 4.850759579635558e-06,
      "loss": 0.3185,
      "step": 90
    },
    {
      "epoch": 0.33167495854063017,
      "grad_norm": 9.60422420501709,
      "learning_rate": 5.389732866261731e-06,
      "loss": 0.3403,
      "step": 100
    },
    {
      "epoch": 0.3648424543946932,
      "grad_norm": 565.2225952148438,
      "learning_rate": 5.596492584407744e-06,
      "loss": 0.3124,
      "step": 110
    },
    {
      "epoch": 0.39800995024875624,
      "grad_norm": 10.473276138305664,
      "learning_rate": 5.58177659023365e-06,
      "loss": 0.3225,
      "step": 120
    },
    {
      "epoch": 0.4311774461028192,
      "grad_norm": 6.905956745147705,
      "learning_rate": 5.567060596059558e-06,
      "loss": 0.3174,
      "step": 130
    },
    {
      "epoch": 0.46434494195688225,
      "grad_norm": 9.182356834411621,
      "learning_rate": 5.552344601885464e-06,
      "loss": 0.3158,
      "step": 140
    },
    {
      "epoch": 0.4975124378109453,
      "grad_norm": 8.820307731628418,
      "learning_rate": 5.537628607711371e-06,
      "loss": 0.2928,
      "step": 150
    },
    {
      "epoch": 0.5306799336650083,
      "grad_norm": 8.743195533752441,
      "learning_rate": 5.522912613537277e-06,
      "loss": 0.3021,
      "step": 160
    },
    {
      "epoch": 0.5638474295190713,
      "grad_norm": 11.710644721984863,
      "learning_rate": 5.508196619363184e-06,
      "loss": 0.2554,
      "step": 170
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 8.126203536987305,
      "learning_rate": 5.49348062518909e-06,
      "loss": 0.2766,
      "step": 180
    },
    {
      "epoch": 0.6301824212271974,
      "grad_norm": 7.2152628898620605,
      "learning_rate": 5.478764631014997e-06,
      "loss": 0.2735,
      "step": 190
    },
    {
      "epoch": 0.6633499170812603,
      "grad_norm": 7.211183071136475,
      "learning_rate": 5.464048636840903e-06,
      "loss": 0.2575,
      "step": 200
    },
    {
      "epoch": 0.6965174129353234,
      "grad_norm": 7.814392566680908,
      "learning_rate": 5.44933264266681e-06,
      "loss": 0.2582,
      "step": 210
    },
    {
      "epoch": 0.7296849087893864,
      "grad_norm": 8.85117244720459,
      "learning_rate": 5.434616648492716e-06,
      "loss": 0.2797,
      "step": 220
    },
    {
      "epoch": 0.7628524046434494,
      "grad_norm": 8.156543731689453,
      "learning_rate": 5.419900654318623e-06,
      "loss": 0.2806,
      "step": 230
    },
    {
      "epoch": 0.7960199004975125,
      "grad_norm": 7.744139671325684,
      "learning_rate": 5.4051846601445294e-06,
      "loss": 0.2714,
      "step": 240
    },
    {
      "epoch": 0.8291873963515755,
      "grad_norm": 6.124651908874512,
      "learning_rate": 5.390468665970436e-06,
      "loss": 0.2393,
      "step": 250
    },
    {
      "epoch": 0.8623548922056384,
      "grad_norm": 6.7101006507873535,
      "learning_rate": 5.375752671796342e-06,
      "loss": 0.238,
      "step": 260
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 6.903068542480469,
      "learning_rate": 5.361036677622248e-06,
      "loss": 0.2681,
      "step": 270
    },
    {
      "epoch": 0.9286898839137645,
      "grad_norm": 7.080708026885986,
      "learning_rate": 5.346320683448155e-06,
      "loss": 0.2256,
      "step": 280
    },
    {
      "epoch": 0.9618573797678275,
      "grad_norm": 6.705533027648926,
      "learning_rate": 5.331604689274061e-06,
      "loss": 0.2099,
      "step": 290
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 7.031564235687256,
      "learning_rate": 5.316888695099968e-06,
      "loss": 0.2461,
      "step": 300
    },
    {
      "epoch": 0.9983416252072969,
      "eval_accuracy": 0.9249274661508704,
      "eval_f1": 0.35647668393782384,
      "eval_loss": 0.22087348997592926,
      "eval_precision": 0.819047619047619,
      "eval_recall": 0.22781456953642384,
      "eval_runtime": 987.8381,
      "eval_samples_per_second": 8.379,
      "eval_steps_per_second": 1.048,
      "step": 301
    },
    {
      "epoch": 0.9983416252072969,
      "eval_accuracy": 0.9249274661508704,
      "eval_f1": 0.35647668393782384,
      "eval_loss": 0.22087348997592926,
      "eval_precision": 0.819047619047619,
      "eval_recall": 0.22781456953642384,
      "eval_runtime": 994.0495,
      "eval_samples_per_second": 8.327,
      "eval_steps_per_second": 1.041,
      "step": 301
    },
    {
      "epoch": 1.0281923714759535,
      "grad_norm": 6.9430365562438965,
      "learning_rate": 5.302172700925874e-06,
      "loss": 0.2263,
      "step": 310
    },
    {
      "epoch": 1.0613598673300166,
      "grad_norm": 7.093142032623291,
      "learning_rate": 5.287456706751782e-06,
      "loss": 0.2028,
      "step": 320
    },
    {
      "epoch": 1.0945273631840795,
      "grad_norm": 10.763915061950684,
      "learning_rate": 5.272740712577688e-06,
      "loss": 0.2002,
      "step": 330
    },
    {
      "epoch": 1.1276948590381426,
      "grad_norm": 8.053380966186523,
      "learning_rate": 5.258024718403595e-06,
      "loss": 0.2243,
      "step": 340
    },
    {
      "epoch": 1.1608623548922057,
      "grad_norm": 5.609781742095947,
      "learning_rate": 5.243308724229501e-06,
      "loss": 0.1925,
      "step": 350
    },
    {
      "epoch": 1.1940298507462686,
      "grad_norm": 6.950540542602539,
      "learning_rate": 5.228592730055408e-06,
      "loss": 0.1948,
      "step": 360
    },
    {
      "epoch": 1.2271973466003316,
      "grad_norm": 11.812267303466797,
      "learning_rate": 5.213876735881314e-06,
      "loss": 0.2035,
      "step": 370
    },
    {
      "epoch": 1.2603648424543947,
      "grad_norm": 9.841348648071289,
      "learning_rate": 5.199160741707221e-06,
      "loss": 0.2195,
      "step": 380
    },
    {
      "epoch": 1.2935323383084576,
      "grad_norm": 122.87271118164062,
      "learning_rate": 5.184444747533127e-06,
      "loss": 0.2096,
      "step": 390
    },
    {
      "epoch": 1.3266998341625207,
      "grad_norm": 4.303558826446533,
      "learning_rate": 5.169728753359034e-06,
      "loss": 0.1884,
      "step": 400
    },
    {
      "epoch": 1.3598673300165838,
      "grad_norm": 3.8206186294555664,
      "learning_rate": 5.15501275918494e-06,
      "loss": 0.1714,
      "step": 410
    },
    {
      "epoch": 1.3930348258706466,
      "grad_norm": 74.73873138427734,
      "learning_rate": 5.140296765010847e-06,
      "loss": 0.1985,
      "step": 420
    },
    {
      "epoch": 1.4262023217247097,
      "grad_norm": 18.138710021972656,
      "learning_rate": 5.125580770836753e-06,
      "loss": 0.1892,
      "step": 430
    },
    {
      "epoch": 1.4593698175787728,
      "grad_norm": 5.713503360748291,
      "learning_rate": 5.11086477666266e-06,
      "loss": 0.2008,
      "step": 440
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 7.24809455871582,
      "learning_rate": 5.096148782488566e-06,
      "loss": 0.1918,
      "step": 450
    },
    {
      "epoch": 1.525704809286899,
      "grad_norm": 6.792764663696289,
      "learning_rate": 5.081432788314473e-06,
      "loss": 0.174,
      "step": 460
    },
    {
      "epoch": 1.5588723051409619,
      "grad_norm": 6.655391216278076,
      "learning_rate": 5.0667167941403795e-06,
      "loss": 0.1896,
      "step": 470
    },
    {
      "epoch": 1.5920398009950247,
      "grad_norm": 3.7256765365600586,
      "learning_rate": 5.052000799966286e-06,
      "loss": 0.1488,
      "step": 480
    },
    {
      "epoch": 1.625207296849088,
      "grad_norm": 5.571889400482178,
      "learning_rate": 5.0372848057921925e-06,
      "loss": 0.158,
      "step": 490
    },
    {
      "epoch": 1.658374792703151,
      "grad_norm": 5.117885589599609,
      "learning_rate": 5.022568811618099e-06,
      "loss": 0.1567,
      "step": 500
    },
    {
      "epoch": 1.6915422885572138,
      "grad_norm": 12.912540435791016,
      "learning_rate": 5.0078528174440056e-06,
      "loss": 0.17,
      "step": 510
    },
    {
      "epoch": 1.724709784411277,
      "grad_norm": 6.814199924468994,
      "learning_rate": 4.993136823269912e-06,
      "loss": 0.1677,
      "step": 520
    },
    {
      "epoch": 1.75787728026534,
      "grad_norm": 6.982125282287598,
      "learning_rate": 4.978420829095819e-06,
      "loss": 0.1578,
      "step": 530
    },
    {
      "epoch": 1.7910447761194028,
      "grad_norm": 5.148756980895996,
      "learning_rate": 4.963704834921725e-06,
      "loss": 0.1507,
      "step": 540
    },
    {
      "epoch": 1.8242122719734661,
      "grad_norm": 5.058485984802246,
      "learning_rate": 4.948988840747632e-06,
      "loss": 0.1445,
      "step": 550
    },
    {
      "epoch": 1.857379767827529,
      "grad_norm": 6.750051498413086,
      "learning_rate": 4.934272846573538e-06,
      "loss": 0.1635,
      "step": 560
    },
    {
      "epoch": 1.890547263681592,
      "grad_norm": 5.1348676681518555,
      "learning_rate": 4.919556852399445e-06,
      "loss": 0.1394,
      "step": 570
    },
    {
      "epoch": 1.9237147595356552,
      "grad_norm": 12.528144836425781,
      "learning_rate": 4.904840858225351e-06,
      "loss": 0.1371,
      "step": 580
    },
    {
      "epoch": 1.956882255389718,
      "grad_norm": 6.74944543838501,
      "learning_rate": 4.890124864051258e-06,
      "loss": 0.1622,
      "step": 590
    },
    {
      "epoch": 1.9900497512437811,
      "grad_norm": 16.0424747467041,
      "learning_rate": 4.875408869877164e-06,
      "loss": 0.1516,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9462040618955513,
      "eval_f1": 0.5950864422202002,
      "eval_loss": 0.1379207819700241,
      "eval_precision": 0.9505813953488372,
      "eval_recall": 0.433112582781457,
      "eval_runtime": 1277.4622,
      "eval_samples_per_second": 6.479,
      "eval_steps_per_second": 0.81,
      "step": 603
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9462040618955513,
      "eval_f1": 0.5950864422202002,
      "eval_loss": 0.1379207819700241,
      "eval_precision": 0.9505813953488372,
      "eval_recall": 0.433112582781457,
      "eval_runtime": 1278.2943,
      "eval_samples_per_second": 6.475,
      "eval_steps_per_second": 0.81,
      "step": 603
    },
    {
      "epoch": 2.0232172470978442,
      "grad_norm": 6.251214981079102,
      "learning_rate": 4.860692875703071e-06,
      "loss": 0.1555,
      "step": 610
    },
    {
      "epoch": 2.056384742951907,
      "grad_norm": 4.871125221252441,
      "learning_rate": 4.845976881528977e-06,
      "loss": 0.1461,
      "step": 620
    },
    {
      "epoch": 2.08955223880597,
      "grad_norm": 6.666764736175537,
      "learning_rate": 4.831260887354884e-06,
      "loss": 0.1074,
      "step": 630
    },
    {
      "epoch": 2.1227197346600333,
      "grad_norm": 4.996448040008545,
      "learning_rate": 4.81654489318079e-06,
      "loss": 0.136,
      "step": 640
    },
    {
      "epoch": 2.155887230514096,
      "grad_norm": 5.537008285522461,
      "learning_rate": 4.801828899006697e-06,
      "loss": 0.1423,
      "step": 650
    },
    {
      "epoch": 2.189054726368159,
      "grad_norm": 5.3556365966796875,
      "learning_rate": 4.787112904832603e-06,
      "loss": 0.1509,
      "step": 660
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 3.8716909885406494,
      "learning_rate": 4.77239691065851e-06,
      "loss": 0.1322,
      "step": 670
    },
    {
      "epoch": 2.255389718076285,
      "grad_norm": 3.3415470123291016,
      "learning_rate": 4.7576809164844165e-06,
      "loss": 0.1158,
      "step": 680
    },
    {
      "epoch": 2.288557213930348,
      "grad_norm": 4.735534191131592,
      "learning_rate": 4.742964922310323e-06,
      "loss": 0.1075,
      "step": 690
    },
    {
      "epoch": 2.3217247097844114,
      "grad_norm": 5.69488525390625,
      "learning_rate": 4.7282489281362295e-06,
      "loss": 0.1119,
      "step": 700
    },
    {
      "epoch": 2.3548922056384742,
      "grad_norm": 6.387297630310059,
      "learning_rate": 4.713532933962136e-06,
      "loss": 0.1037,
      "step": 710
    },
    {
      "epoch": 2.388059701492537,
      "grad_norm": 7.284554481506348,
      "learning_rate": 4.6988169397880426e-06,
      "loss": 0.1072,
      "step": 720
    },
    {
      "epoch": 2.4212271973466004,
      "grad_norm": 4.613234519958496,
      "learning_rate": 4.684100945613949e-06,
      "loss": 0.1137,
      "step": 730
    },
    {
      "epoch": 2.4543946932006633,
      "grad_norm": 6.112837791442871,
      "learning_rate": 4.669384951439856e-06,
      "loss": 0.0958,
      "step": 740
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 3.8625328540802,
      "learning_rate": 4.654668957265762e-06,
      "loss": 0.09,
      "step": 750
    },
    {
      "epoch": 2.5207296849087895,
      "grad_norm": 5.246092319488525,
      "learning_rate": 4.6399529630916695e-06,
      "loss": 0.1019,
      "step": 760
    },
    {
      "epoch": 2.5538971807628523,
      "grad_norm": 6.6563639640808105,
      "learning_rate": 4.625236968917576e-06,
      "loss": 0.1228,
      "step": 770
    },
    {
      "epoch": 2.587064676616915,
      "grad_norm": 5.071183681488037,
      "learning_rate": 4.6105209747434825e-06,
      "loss": 0.0974,
      "step": 780
    },
    {
      "epoch": 2.6202321724709785,
      "grad_norm": 4.127743721008301,
      "learning_rate": 4.595804980569389e-06,
      "loss": 0.0947,
      "step": 790
    },
    {
      "epoch": 2.6533996683250414,
      "grad_norm": 4.447211265563965,
      "learning_rate": 4.581088986395296e-06,
      "loss": 0.1063,
      "step": 800
    },
    {
      "epoch": 2.6865671641791042,
      "grad_norm": 6.940059661865234,
      "learning_rate": 4.566372992221202e-06,
      "loss": 0.0989,
      "step": 810
    },
    {
      "epoch": 2.7197346600331676,
      "grad_norm": 8.163690567016602,
      "learning_rate": 4.551656998047109e-06,
      "loss": 0.1137,
      "step": 820
    },
    {
      "epoch": 2.7529021558872304,
      "grad_norm": 4.8105340003967285,
      "learning_rate": 4.536941003873015e-06,
      "loss": 0.0739,
      "step": 830
    },
    {
      "epoch": 2.7860696517412933,
      "grad_norm": 5.016195774078369,
      "learning_rate": 4.522225009698922e-06,
      "loss": 0.0858,
      "step": 840
    },
    {
      "epoch": 2.8192371475953566,
      "grad_norm": 3.731902599334717,
      "learning_rate": 4.507509015524828e-06,
      "loss": 0.0973,
      "step": 850
    },
    {
      "epoch": 2.8524046434494195,
      "grad_norm": 4.330935478210449,
      "learning_rate": 4.492793021350735e-06,
      "loss": 0.0962,
      "step": 860
    },
    {
      "epoch": 2.8855721393034823,
      "grad_norm": 4.879040241241455,
      "learning_rate": 4.47807702717664e-06,
      "loss": 0.1028,
      "step": 870
    },
    {
      "epoch": 2.9187396351575456,
      "grad_norm": 5.711342811584473,
      "learning_rate": 4.463361033002547e-06,
      "loss": 0.1095,
      "step": 880
    },
    {
      "epoch": 2.9519071310116085,
      "grad_norm": 5.566775321960449,
      "learning_rate": 4.4486450388284535e-06,
      "loss": 0.0941,
      "step": 890
    },
    {
      "epoch": 2.9850746268656714,
      "grad_norm": 4.803378105163574,
      "learning_rate": 4.43392904465436e-06,
      "loss": 0.0841,
      "step": 900
    },
    {
      "epoch": 2.998341625207297,
      "eval_accuracy": 0.9656673114119922,
      "eval_f1": 0.7698541329011346,
      "eval_loss": 0.09472215920686722,
      "eval_precision": 0.9916492693110647,
      "eval_recall": 0.6291390728476821,
      "eval_runtime": 1005.2149,
      "eval_samples_per_second": 8.234,
      "eval_steps_per_second": 1.03,
      "step": 904
    },
    {
      "epoch": 2.998341625207297,
      "eval_accuracy": 0.9656673114119922,
      "eval_f1": 0.7698541329011346,
      "eval_loss": 0.09472215920686722,
      "eval_precision": 0.9916492693110647,
      "eval_recall": 0.6291390728476821,
      "eval_runtime": 1019.6929,
      "eval_samples_per_second": 8.117,
      "eval_steps_per_second": 1.015,
      "step": 904
    },
    {
      "epoch": 3.0182421227197347,
      "grad_norm": 20.060226440429688,
      "learning_rate": 4.4192130504802665e-06,
      "loss": 0.0674,
      "step": 910
    },
    {
      "epoch": 3.0514096185737976,
      "grad_norm": 8.594515800476074,
      "learning_rate": 4.404497056306173e-06,
      "loss": 0.0835,
      "step": 920
    },
    {
      "epoch": 3.084577114427861,
      "grad_norm": 6.420520305633545,
      "learning_rate": 4.3897810621320795e-06,
      "loss": 0.0791,
      "step": 930
    },
    {
      "epoch": 3.1177446102819237,
      "grad_norm": 2.035173177719116,
      "learning_rate": 4.375065067957987e-06,
      "loss": 0.0632,
      "step": 940
    },
    {
      "epoch": 3.1509121061359866,
      "grad_norm": 4.362942218780518,
      "learning_rate": 4.3603490737838934e-06,
      "loss": 0.082,
      "step": 950
    },
    {
      "epoch": 3.18407960199005,
      "grad_norm": 4.379368782043457,
      "learning_rate": 4.3456330796098e-06,
      "loss": 0.0639,
      "step": 960
    },
    {
      "epoch": 3.217247097844113,
      "grad_norm": 3.5410044193267822,
      "learning_rate": 4.3309170854357065e-06,
      "loss": 0.0643,
      "step": 970
    },
    {
      "epoch": 3.2504145936981756,
      "grad_norm": 4.0874433517456055,
      "learning_rate": 4.316201091261613e-06,
      "loss": 0.0844,
      "step": 980
    },
    {
      "epoch": 3.283582089552239,
      "grad_norm": 7.026724815368652,
      "learning_rate": 4.3014850970875195e-06,
      "loss": 0.0697,
      "step": 990
    },
    {
      "epoch": 3.316749585406302,
      "grad_norm": 4.370837211608887,
      "learning_rate": 4.286769102913426e-06,
      "loss": 0.0591,
      "step": 1000
    },
    {
      "epoch": 3.3499170812603647,
      "grad_norm": 1.9200204610824585,
      "learning_rate": 4.272053108739333e-06,
      "loss": 0.0547,
      "step": 1010
    },
    {
      "epoch": 3.383084577114428,
      "grad_norm": 3.398440361022949,
      "learning_rate": 4.257337114565239e-06,
      "loss": 0.0796,
      "step": 1020
    },
    {
      "epoch": 3.416252072968491,
      "grad_norm": 4.771766662597656,
      "learning_rate": 4.242621120391146e-06,
      "loss": 0.0507,
      "step": 1030
    },
    {
      "epoch": 3.4494195688225537,
      "grad_norm": 2.9144434928894043,
      "learning_rate": 4.227905126217052e-06,
      "loss": 0.0474,
      "step": 1040
    },
    {
      "epoch": 3.482587064676617,
      "grad_norm": 5.3083086013793945,
      "learning_rate": 4.213189132042959e-06,
      "loss": 0.0643,
      "step": 1050
    },
    {
      "epoch": 3.51575456053068,
      "grad_norm": 5.353035926818848,
      "learning_rate": 4.198473137868865e-06,
      "loss": 0.0777,
      "step": 1060
    },
    {
      "epoch": 3.5489220563847432,
      "grad_norm": 2.6827876567840576,
      "learning_rate": 4.183757143694772e-06,
      "loss": 0.0679,
      "step": 1070
    },
    {
      "epoch": 3.582089552238806,
      "grad_norm": 3.2551980018615723,
      "learning_rate": 4.169041149520678e-06,
      "loss": 0.0596,
      "step": 1080
    },
    {
      "epoch": 3.615257048092869,
      "grad_norm": 2.855875015258789,
      "learning_rate": 4.154325155346585e-06,
      "loss": 0.0592,
      "step": 1090
    },
    {
      "epoch": 3.6484245439469323,
      "grad_norm": 7.216331958770752,
      "learning_rate": 4.139609161172491e-06,
      "loss": 0.0467,
      "step": 1100
    },
    {
      "epoch": 3.681592039800995,
      "grad_norm": 3.88708233833313,
      "learning_rate": 4.124893166998398e-06,
      "loss": 0.0591,
      "step": 1110
    },
    {
      "epoch": 3.714759535655058,
      "grad_norm": 5.895383358001709,
      "learning_rate": 4.110177172824304e-06,
      "loss": 0.0475,
      "step": 1120
    },
    {
      "epoch": 3.7479270315091213,
      "grad_norm": 4.438551902770996,
      "learning_rate": 4.095461178650211e-06,
      "loss": 0.0728,
      "step": 1130
    },
    {
      "epoch": 3.781094527363184,
      "grad_norm": 6.411782264709473,
      "learning_rate": 4.080745184476117e-06,
      "loss": 0.0673,
      "step": 1140
    },
    {
      "epoch": 3.814262023217247,
      "grad_norm": 6.243862628936768,
      "learning_rate": 4.066029190302024e-06,
      "loss": 0.0682,
      "step": 1150
    },
    {
      "epoch": 3.8474295190713104,
      "grad_norm": 3.4062070846557617,
      "learning_rate": 4.0513131961279304e-06,
      "loss": 0.0531,
      "step": 1160
    },
    {
      "epoch": 3.8805970149253732,
      "grad_norm": 4.376400947570801,
      "learning_rate": 4.036597201953837e-06,
      "loss": 0.0717,
      "step": 1170
    },
    {
      "epoch": 3.913764510779436,
      "grad_norm": 3.36185622215271,
      "learning_rate": 4.0218812077797435e-06,
      "loss": 0.0384,
      "step": 1180
    },
    {
      "epoch": 3.9469320066334994,
      "grad_norm": 3.4004547595977783,
      "learning_rate": 4.00716521360565e-06,
      "loss": 0.0684,
      "step": 1190
    },
    {
      "epoch": 3.9800995024875623,
      "grad_norm": 2.8447940349578857,
      "learning_rate": 3.9924492194315565e-06,
      "loss": 0.0635,
      "step": 1200
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9794487427466151,
      "eval_f1": 0.8776978417266188,
      "eval_loss": 0.05086784437298775,
      "eval_precision": 0.9606299212598425,
      "eval_recall": 0.8079470198675497,
      "eval_runtime": 1019.4647,
      "eval_samples_per_second": 8.119,
      "eval_steps_per_second": 1.015,
      "step": 1206
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9794487427466151,
      "eval_f1": 0.8776978417266188,
      "eval_loss": 0.05086784437298775,
      "eval_precision": 0.9606299212598425,
      "eval_recall": 0.8079470198675497,
      "eval_runtime": 1003.1601,
      "eval_samples_per_second": 8.251,
      "eval_steps_per_second": 1.032,
      "step": 1206
    },
    {
      "epoch": 4.013266998341625,
      "grad_norm": 4.794472694396973,
      "learning_rate": 3.977733225257463e-06,
      "loss": 0.0382,
      "step": 1210
    },
    {
      "epoch": 4.0464344941956885,
      "grad_norm": 2.9434101581573486,
      "learning_rate": 3.9630172310833696e-06,
      "loss": 0.0389,
      "step": 1220
    },
    {
      "epoch": 4.079601990049751,
      "grad_norm": 1.8754127025604248,
      "learning_rate": 3.948301236909276e-06,
      "loss": 0.0485,
      "step": 1230
    },
    {
      "epoch": 4.112769485903814,
      "grad_norm": 6.548973560333252,
      "learning_rate": 3.933585242735183e-06,
      "loss": 0.0523,
      "step": 1240
    },
    {
      "epoch": 4.1459369817578775,
      "grad_norm": 3.1628785133361816,
      "learning_rate": 3.918869248561089e-06,
      "loss": 0.0532,
      "step": 1250
    },
    {
      "epoch": 4.17910447761194,
      "grad_norm": 7.69321346282959,
      "learning_rate": 3.904153254386996e-06,
      "loss": 0.0501,
      "step": 1260
    },
    {
      "epoch": 4.212271973466003,
      "grad_norm": 5.600610256195068,
      "learning_rate": 3.889437260212902e-06,
      "loss": 0.0493,
      "step": 1270
    },
    {
      "epoch": 4.2454394693200666,
      "grad_norm": 10.847305297851562,
      "learning_rate": 3.874721266038809e-06,
      "loss": 0.0608,
      "step": 1280
    },
    {
      "epoch": 4.278606965174129,
      "grad_norm": 3.9885079860687256,
      "learning_rate": 3.860005271864715e-06,
      "loss": 0.0472,
      "step": 1290
    },
    {
      "epoch": 4.311774461028192,
      "grad_norm": 2.9284913539886475,
      "learning_rate": 3.845289277690622e-06,
      "loss": 0.0465,
      "step": 1300
    },
    {
      "epoch": 4.344941956882256,
      "grad_norm": 4.596166610717773,
      "learning_rate": 3.830573283516528e-06,
      "loss": 0.0406,
      "step": 1310
    },
    {
      "epoch": 4.378109452736318,
      "grad_norm": 4.10037899017334,
      "learning_rate": 3.815857289342435e-06,
      "loss": 0.0475,
      "step": 1320
    },
    {
      "epoch": 4.411276948590381,
      "grad_norm": 3.4149937629699707,
      "learning_rate": 3.8011412951683418e-06,
      "loss": 0.0385,
      "step": 1330
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 3.7266952991485596,
      "learning_rate": 3.7864253009942483e-06,
      "loss": 0.0383,
      "step": 1340
    },
    {
      "epoch": 4.477611940298507,
      "grad_norm": 2.5303053855895996,
      "learning_rate": 3.771709306820155e-06,
      "loss": 0.0553,
      "step": 1350
    },
    {
      "epoch": 4.51077943615257,
      "grad_norm": 2.1288816928863525,
      "learning_rate": 3.7569933126460613e-06,
      "loss": 0.0347,
      "step": 1360
    },
    {
      "epoch": 4.543946932006634,
      "grad_norm": 5.393789291381836,
      "learning_rate": 3.742277318471968e-06,
      "loss": 0.0365,
      "step": 1370
    },
    {
      "epoch": 4.577114427860696,
      "grad_norm": 6.035567760467529,
      "learning_rate": 3.7275613242978744e-06,
      "loss": 0.0407,
      "step": 1380
    },
    {
      "epoch": 4.610281923714759,
      "grad_norm": 3.646857261657715,
      "learning_rate": 3.712845330123781e-06,
      "loss": 0.0457,
      "step": 1390
    },
    {
      "epoch": 4.643449419568823,
      "grad_norm": 3.3356542587280273,
      "learning_rate": 3.6981293359496874e-06,
      "loss": 0.0393,
      "step": 1400
    },
    {
      "epoch": 4.676616915422885,
      "grad_norm": 2.829602003097534,
      "learning_rate": 3.683413341775594e-06,
      "loss": 0.0367,
      "step": 1410
    },
    {
      "epoch": 4.7097844112769485,
      "grad_norm": 4.990158557891846,
      "learning_rate": 3.6686973476015005e-06,
      "loss": 0.0471,
      "step": 1420
    },
    {
      "epoch": 4.742951907131012,
      "grad_norm": 2.8802034854888916,
      "learning_rate": 3.653981353427407e-06,
      "loss": 0.056,
      "step": 1430
    },
    {
      "epoch": 4.776119402985074,
      "grad_norm": 8.937077522277832,
      "learning_rate": 3.639265359253314e-06,
      "loss": 0.0432,
      "step": 1440
    },
    {
      "epoch": 4.8092868988391375,
      "grad_norm": 3.6803832054138184,
      "learning_rate": 3.6245493650792205e-06,
      "loss": 0.0287,
      "step": 1450
    },
    {
      "epoch": 4.842454394693201,
      "grad_norm": 18.358413696289062,
      "learning_rate": 3.609833370905127e-06,
      "loss": 0.0428,
      "step": 1460
    },
    {
      "epoch": 4.875621890547263,
      "grad_norm": 5.392284870147705,
      "learning_rate": 3.5951173767310335e-06,
      "loss": 0.039,
      "step": 1470
    },
    {
      "epoch": 4.908789386401327,
      "grad_norm": 3.6017260551452637,
      "learning_rate": 3.580401382556939e-06,
      "loss": 0.031,
      "step": 1480
    },
    {
      "epoch": 4.94195688225539,
      "grad_norm": 1.0221537351608276,
      "learning_rate": 3.5656853883828457e-06,
      "loss": 0.0265,
      "step": 1490
    },
    {
      "epoch": 4.975124378109452,
      "grad_norm": 2.477006196975708,
      "learning_rate": 3.5509693942087527e-06,
      "loss": 0.0512,
      "step": 1500
    },
    {
      "epoch": 4.9983416252072965,
      "eval_accuracy": 0.9876692456479691,
      "eval_f1": 0.9309878213802436,
      "eval_loss": 0.03167876973748207,
      "eval_precision": 0.9515905947441217,
      "eval_recall": 0.9112582781456954,
      "eval_runtime": 1224.6159,
      "eval_samples_per_second": 6.759,
      "eval_steps_per_second": 0.845,
      "step": 1507
    },
    {
      "epoch": 4.9983416252072965,
      "eval_accuracy": 0.9876692456479691,
      "eval_f1": 0.9309878213802436,
      "eval_loss": 0.03167876973748207,
      "eval_precision": 0.9515905947441217,
      "eval_recall": 0.9112582781456954,
      "eval_runtime": 1222.7646,
      "eval_samples_per_second": 6.769,
      "eval_steps_per_second": 0.846,
      "step": 1507
    },
    {
      "epoch": 5.008291873963516,
      "grad_norm": 4.683608055114746,
      "learning_rate": 3.536253400034659e-06,
      "loss": 0.036,
      "step": 1510
    },
    {
      "epoch": 5.041459369817579,
      "grad_norm": 1.291567325592041,
      "learning_rate": 3.5215374058605657e-06,
      "loss": 0.0243,
      "step": 1520
    },
    {
      "epoch": 5.074626865671641,
      "grad_norm": 19.625308990478516,
      "learning_rate": 3.5068214116864722e-06,
      "loss": 0.0514,
      "step": 1530
    },
    {
      "epoch": 5.107794361525705,
      "grad_norm": 6.10153865814209,
      "learning_rate": 3.4921054175123788e-06,
      "loss": 0.0267,
      "step": 1540
    },
    {
      "epoch": 5.140961857379768,
      "grad_norm": 5.334019660949707,
      "learning_rate": 3.4773894233382853e-06,
      "loss": 0.029,
      "step": 1550
    },
    {
      "epoch": 5.174129353233831,
      "grad_norm": 5.597215175628662,
      "learning_rate": 3.462673429164192e-06,
      "loss": 0.0262,
      "step": 1560
    },
    {
      "epoch": 5.207296849087894,
      "grad_norm": 4.176295757293701,
      "learning_rate": 3.4479574349900983e-06,
      "loss": 0.0328,
      "step": 1570
    },
    {
      "epoch": 5.240464344941957,
      "grad_norm": 5.923614501953125,
      "learning_rate": 3.433241440816005e-06,
      "loss": 0.0385,
      "step": 1580
    },
    {
      "epoch": 5.273631840796019,
      "grad_norm": 6.870272636413574,
      "learning_rate": 3.4185254466419114e-06,
      "loss": 0.0259,
      "step": 1590
    },
    {
      "epoch": 5.306799336650083,
      "grad_norm": 11.91473388671875,
      "learning_rate": 3.403809452467818e-06,
      "loss": 0.0393,
      "step": 1600
    },
    {
      "epoch": 5.339966832504146,
      "grad_norm": 4.765864849090576,
      "learning_rate": 3.3890934582937244e-06,
      "loss": 0.0236,
      "step": 1610
    },
    {
      "epoch": 5.373134328358209,
      "grad_norm": 1.560383915901184,
      "learning_rate": 3.374377464119631e-06,
      "loss": 0.0283,
      "step": 1620
    },
    {
      "epoch": 5.406301824212272,
      "grad_norm": 3.4262218475341797,
      "learning_rate": 3.359661469945538e-06,
      "loss": 0.0327,
      "step": 1630
    },
    {
      "epoch": 5.439469320066335,
      "grad_norm": 3.445849895477295,
      "learning_rate": 3.3449454757714444e-06,
      "loss": 0.0256,
      "step": 1640
    },
    {
      "epoch": 5.472636815920398,
      "grad_norm": 1.611698031425476,
      "learning_rate": 3.330229481597351e-06,
      "loss": 0.023,
      "step": 1650
    },
    {
      "epoch": 5.505804311774461,
      "grad_norm": 4.6323723793029785,
      "learning_rate": 3.3155134874232575e-06,
      "loss": 0.0351,
      "step": 1660
    },
    {
      "epoch": 5.538971807628524,
      "grad_norm": 1.6956368684768677,
      "learning_rate": 3.300797493249164e-06,
      "loss": 0.0271,
      "step": 1670
    },
    {
      "epoch": 5.572139303482587,
      "grad_norm": 6.617647647857666,
      "learning_rate": 3.2860814990750705e-06,
      "loss": 0.0247,
      "step": 1680
    },
    {
      "epoch": 5.60530679933665,
      "grad_norm": 10.50680923461914,
      "learning_rate": 3.271365504900977e-06,
      "loss": 0.0361,
      "step": 1690
    },
    {
      "epoch": 5.638474295190713,
      "grad_norm": 2.5960195064544678,
      "learning_rate": 3.2566495107268836e-06,
      "loss": 0.0276,
      "step": 1700
    },
    {
      "epoch": 5.6716417910447765,
      "grad_norm": 2.991736888885498,
      "learning_rate": 3.24193351655279e-06,
      "loss": 0.0232,
      "step": 1710
    },
    {
      "epoch": 5.704809286898839,
      "grad_norm": 9.115209579467773,
      "learning_rate": 3.2272175223786966e-06,
      "loss": 0.0251,
      "step": 1720
    },
    {
      "epoch": 5.737976782752902,
      "grad_norm": 3.0746347904205322,
      "learning_rate": 3.212501528204603e-06,
      "loss": 0.0301,
      "step": 1730
    },
    {
      "epoch": 5.7711442786069655,
      "grad_norm": 5.771823883056641,
      "learning_rate": 3.1977855340305096e-06,
      "loss": 0.0339,
      "step": 1740
    },
    {
      "epoch": 5.804311774461028,
      "grad_norm": 3.90299916267395,
      "learning_rate": 3.183069539856416e-06,
      "loss": 0.0253,
      "step": 1750
    },
    {
      "epoch": 5.837479270315091,
      "grad_norm": 3.2761096954345703,
      "learning_rate": 3.168353545682323e-06,
      "loss": 0.0396,
      "step": 1760
    },
    {
      "epoch": 5.870646766169155,
      "grad_norm": 2.5146846771240234,
      "learning_rate": 3.1536375515082296e-06,
      "loss": 0.0283,
      "step": 1770
    },
    {
      "epoch": 5.903814262023217,
      "grad_norm": 5.49894380569458,
      "learning_rate": 3.1389215573341353e-06,
      "loss": 0.03,
      "step": 1780
    },
    {
      "epoch": 5.93698175787728,
      "grad_norm": 3.8459384441375732,
      "learning_rate": 3.124205563160042e-06,
      "loss": 0.026,
      "step": 1790
    },
    {
      "epoch": 5.970149253731344,
      "grad_norm": 4.756380081176758,
      "learning_rate": 3.1094895689859484e-06,
      "loss": 0.0263,
      "step": 1800
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9889990328820116,
      "eval_f1": 0.9406392694063926,
      "eval_loss": 0.031025851145386696,
      "eval_precision": 0.9267352185089974,
      "eval_recall": 0.9549668874172186,
      "eval_runtime": 984.5024,
      "eval_samples_per_second": 8.407,
      "eval_steps_per_second": 1.051,
      "step": 1809
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9889990328820116,
      "eval_f1": 0.9406392694063926,
      "eval_loss": 0.031025851145386696,
      "eval_precision": 0.9267352185089974,
      "eval_recall": 0.9549668874172186,
      "eval_runtime": 993.6312,
      "eval_samples_per_second": 8.33,
      "eval_steps_per_second": 1.042,
      "step": 1809
    },
    {
      "epoch": 6.003316749585406,
      "grad_norm": 10.340165138244629,
      "learning_rate": 3.094773574811855e-06,
      "loss": 0.0277,
      "step": 1810
    },
    {
      "epoch": 6.036484245439469,
      "grad_norm": 5.0312418937683105,
      "learning_rate": 3.080057580637762e-06,
      "loss": 0.0332,
      "step": 1820
    },
    {
      "epoch": 6.069651741293533,
      "grad_norm": 4.3324480056762695,
      "learning_rate": 3.0653415864636684e-06,
      "loss": 0.0213,
      "step": 1830
    },
    {
      "epoch": 6.102819237147595,
      "grad_norm": 6.222653865814209,
      "learning_rate": 3.050625592289575e-06,
      "loss": 0.0248,
      "step": 1840
    },
    {
      "epoch": 6.135986733001658,
      "grad_norm": 3.7286672592163086,
      "learning_rate": 3.0359095981154814e-06,
      "loss": 0.0304,
      "step": 1850
    },
    {
      "epoch": 6.169154228855722,
      "grad_norm": 8.904224395751953,
      "learning_rate": 3.021193603941388e-06,
      "loss": 0.0428,
      "step": 1860
    },
    {
      "epoch": 6.202321724709784,
      "grad_norm": 4.377466678619385,
      "learning_rate": 3.0064776097672945e-06,
      "loss": 0.03,
      "step": 1870
    },
    {
      "epoch": 6.2354892205638475,
      "grad_norm": 2.9130775928497314,
      "learning_rate": 2.991761615593201e-06,
      "loss": 0.0257,
      "step": 1880
    },
    {
      "epoch": 6.268656716417911,
      "grad_norm": 2.4273836612701416,
      "learning_rate": 2.9770456214191075e-06,
      "loss": 0.0243,
      "step": 1890
    },
    {
      "epoch": 6.301824212271973,
      "grad_norm": 2.1629977226257324,
      "learning_rate": 2.962329627245014e-06,
      "loss": 0.0171,
      "step": 1900
    },
    {
      "epoch": 6.3349917081260365,
      "grad_norm": 2.6534037590026855,
      "learning_rate": 2.9476136330709205e-06,
      "loss": 0.0209,
      "step": 1910
    },
    {
      "epoch": 6.3681592039801,
      "grad_norm": 4.036760330200195,
      "learning_rate": 2.932897638896827e-06,
      "loss": 0.0335,
      "step": 1920
    },
    {
      "epoch": 6.401326699834162,
      "grad_norm": 1.8578057289123535,
      "learning_rate": 2.9181816447227336e-06,
      "loss": 0.0275,
      "step": 1930
    },
    {
      "epoch": 6.434494195688226,
      "grad_norm": 5.809139251708984,
      "learning_rate": 2.9034656505486405e-06,
      "loss": 0.0288,
      "step": 1940
    },
    {
      "epoch": 6.467661691542289,
      "grad_norm": 3.4509835243225098,
      "learning_rate": 2.888749656374547e-06,
      "loss": 0.0282,
      "step": 1950
    },
    {
      "epoch": 6.500829187396351,
      "grad_norm": 6.997410297393799,
      "learning_rate": 2.8740336622004536e-06,
      "loss": 0.0298,
      "step": 1960
    },
    {
      "epoch": 6.533996683250415,
      "grad_norm": 7.689084529876709,
      "learning_rate": 2.85931766802636e-06,
      "loss": 0.0289,
      "step": 1970
    },
    {
      "epoch": 6.567164179104478,
      "grad_norm": 3.2876181602478027,
      "learning_rate": 2.8446016738522666e-06,
      "loss": 0.0167,
      "step": 1980
    },
    {
      "epoch": 6.60033167495854,
      "grad_norm": 4.293584823608398,
      "learning_rate": 2.829885679678173e-06,
      "loss": 0.027,
      "step": 1990
    },
    {
      "epoch": 6.633499170812604,
      "grad_norm": 3.8780975341796875,
      "learning_rate": 2.8151696855040797e-06,
      "loss": 0.0184,
      "step": 2000
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 4.310855388641357,
      "learning_rate": 2.8004536913299858e-06,
      "loss": 0.0239,
      "step": 2010
    },
    {
      "epoch": 6.699834162520729,
      "grad_norm": 0.5425668954849243,
      "learning_rate": 2.7857376971558923e-06,
      "loss": 0.0172,
      "step": 2020
    },
    {
      "epoch": 6.733001658374793,
      "grad_norm": 6.196296691894531,
      "learning_rate": 2.7710217029817993e-06,
      "loss": 0.045,
      "step": 2030
    },
    {
      "epoch": 6.766169154228856,
      "grad_norm": 19.950151443481445,
      "learning_rate": 2.7563057088077058e-06,
      "loss": 0.0276,
      "step": 2040
    },
    {
      "epoch": 6.799336650082918,
      "grad_norm": 4.390010356903076,
      "learning_rate": 2.7415897146336123e-06,
      "loss": 0.0243,
      "step": 2050
    },
    {
      "epoch": 6.832504145936982,
      "grad_norm": 2.0883538722991943,
      "learning_rate": 2.726873720459519e-06,
      "loss": 0.0245,
      "step": 2060
    },
    {
      "epoch": 6.865671641791045,
      "grad_norm": 0.28267353773117065,
      "learning_rate": 2.7121577262854253e-06,
      "loss": 0.0242,
      "step": 2070
    },
    {
      "epoch": 6.8988391376451075,
      "grad_norm": 5.951056957244873,
      "learning_rate": 2.697441732111332e-06,
      "loss": 0.0198,
      "step": 2080
    },
    {
      "epoch": 6.932006633499171,
      "grad_norm": 3.145439863204956,
      "learning_rate": 2.6827257379372384e-06,
      "loss": 0.0209,
      "step": 2090
    },
    {
      "epoch": 6.965174129353234,
      "grad_norm": 1.3288230895996094,
      "learning_rate": 2.668009743763145e-06,
      "loss": 0.019,
      "step": 2100
    },
    {
      "epoch": 6.9983416252072965,
      "grad_norm": 6.702155113220215,
      "learning_rate": 2.6532937495890514e-06,
      "loss": 0.0215,
      "step": 2110
    },
    {
      "epoch": 6.9983416252072965,
      "eval_accuracy": 0.9896034816247582,
      "eval_f1": 0.9411764705882353,
      "eval_loss": 0.0346946083009243,
      "eval_precision": 0.9731258840169731,
      "eval_recall": 0.9112582781456954,
      "eval_runtime": 2719.7028,
      "eval_samples_per_second": 3.043,
      "eval_steps_per_second": 0.381,
      "step": 2110
    },
    {
      "epoch": 6.9983416252072965,
      "eval_accuracy": 0.9896034816247582,
      "eval_f1": 0.9411764705882353,
      "eval_loss": 0.0346946083009243,
      "eval_precision": 0.9731258840169731,
      "eval_recall": 0.9112582781456954,
      "eval_runtime": 1295.7205,
      "eval_samples_per_second": 6.388,
      "eval_steps_per_second": 0.799,
      "step": 2110
    },
    {
      "epoch": 7.03150912106136,
      "grad_norm": 0.48762810230255127,
      "learning_rate": 2.638577755414958e-06,
      "loss": 0.0169,
      "step": 2120
    },
    {
      "epoch": 7.064676616915423,
      "grad_norm": 1.0018913745880127,
      "learning_rate": 2.6238617612408645e-06,
      "loss": 0.0341,
      "step": 2130
    },
    {
      "epoch": 7.097844112769486,
      "grad_norm": 2.76104998588562,
      "learning_rate": 2.609145767066771e-06,
      "loss": 0.0171,
      "step": 2140
    },
    {
      "epoch": 7.131011608623549,
      "grad_norm": 0.9153473377227783,
      "learning_rate": 2.5944297728926775e-06,
      "loss": 0.0114,
      "step": 2150
    },
    {
      "epoch": 7.164179104477612,
      "grad_norm": 10.238992691040039,
      "learning_rate": 2.5797137787185845e-06,
      "loss": 0.0184,
      "step": 2160
    },
    {
      "epoch": 7.197346600331675,
      "grad_norm": 0.5881858468055725,
      "learning_rate": 2.5649977845444906e-06,
      "loss": 0.0146,
      "step": 2170
    },
    {
      "epoch": 7.230514096185738,
      "grad_norm": 2.061793565750122,
      "learning_rate": 2.550281790370397e-06,
      "loss": 0.0128,
      "step": 2180
    },
    {
      "epoch": 7.263681592039801,
      "grad_norm": 1.0749160051345825,
      "learning_rate": 2.5355657961963036e-06,
      "loss": 0.0309,
      "step": 2190
    },
    {
      "epoch": 7.296849087893864,
      "grad_norm": 0.9733470678329468,
      "learning_rate": 2.52084980202221e-06,
      "loss": 0.0141,
      "step": 2200
    },
    {
      "epoch": 7.330016583747927,
      "grad_norm": 3.4854848384857178,
      "learning_rate": 2.5061338078481167e-06,
      "loss": 0.0345,
      "step": 2210
    },
    {
      "epoch": 7.36318407960199,
      "grad_norm": 3.712880849838257,
      "learning_rate": 2.491417813674023e-06,
      "loss": 0.0259,
      "step": 2220
    },
    {
      "epoch": 7.396351575456053,
      "grad_norm": 8.994887351989746,
      "learning_rate": 2.4767018194999297e-06,
      "loss": 0.0222,
      "step": 2230
    },
    {
      "epoch": 7.429519071310116,
      "grad_norm": 3.6802589893341064,
      "learning_rate": 2.4619858253258362e-06,
      "loss": 0.0118,
      "step": 2240
    },
    {
      "epoch": 7.462686567164179,
      "grad_norm": 0.6372223496437073,
      "learning_rate": 2.447269831151743e-06,
      "loss": 0.0107,
      "step": 2250
    },
    {
      "epoch": 7.495854063018242,
      "grad_norm": 3.4653279781341553,
      "learning_rate": 2.4325538369776497e-06,
      "loss": 0.0255,
      "step": 2260
    },
    {
      "epoch": 7.529021558872305,
      "grad_norm": 0.504813551902771,
      "learning_rate": 2.4178378428035562e-06,
      "loss": 0.0162,
      "step": 2270
    },
    {
      "epoch": 7.562189054726368,
      "grad_norm": 2.6061301231384277,
      "learning_rate": 2.4031218486294628e-06,
      "loss": 0.0226,
      "step": 2280
    },
    {
      "epoch": 7.595356550580431,
      "grad_norm": 3.8820769786834717,
      "learning_rate": 2.3884058544553693e-06,
      "loss": 0.0216,
      "step": 2290
    },
    {
      "epoch": 7.628524046434494,
      "grad_norm": 3.8254404067993164,
      "learning_rate": 2.373689860281276e-06,
      "loss": 0.0199,
      "step": 2300
    },
    {
      "epoch": 7.661691542288557,
      "grad_norm": 2.4656693935394287,
      "learning_rate": 2.3589738661071823e-06,
      "loss": 0.0251,
      "step": 2310
    },
    {
      "epoch": 7.69485903814262,
      "grad_norm": 0.616972804069519,
      "learning_rate": 2.3442578719330884e-06,
      "loss": 0.0161,
      "step": 2320
    },
    {
      "epoch": 7.728026533996683,
      "grad_norm": 3.760866641998291,
      "learning_rate": 2.329541877758995e-06,
      "loss": 0.0344,
      "step": 2330
    },
    {
      "epoch": 7.7611940298507465,
      "grad_norm": 2.6051056385040283,
      "learning_rate": 2.3148258835849015e-06,
      "loss": 0.0225,
      "step": 2340
    },
    {
      "epoch": 7.79436152570481,
      "grad_norm": 2.4425411224365234,
      "learning_rate": 2.3001098894108084e-06,
      "loss": 0.0295,
      "step": 2350
    },
    {
      "epoch": 7.827529021558872,
      "grad_norm": 0.5920639038085938,
      "learning_rate": 2.285393895236715e-06,
      "loss": 0.0243,
      "step": 2360
    },
    {
      "epoch": 7.8606965174129355,
      "grad_norm": 0.8289245963096619,
      "learning_rate": 2.2706779010626215e-06,
      "loss": 0.0091,
      "step": 2370
    },
    {
      "epoch": 7.893864013266999,
      "grad_norm": 2.913651704788208,
      "learning_rate": 2.255961906888528e-06,
      "loss": 0.017,
      "step": 2380
    },
    {
      "epoch": 7.927031509121061,
      "grad_norm": 4.3942999839782715,
      "learning_rate": 2.2412459127144345e-06,
      "loss": 0.024,
      "step": 2390
    },
    {
      "epoch": 7.960199004975125,
      "grad_norm": 5.7562031745910645,
      "learning_rate": 2.226529918540341e-06,
      "loss": 0.0242,
      "step": 2400
    },
    {
      "epoch": 7.993366500829188,
      "grad_norm": 1.9467248916625977,
      "learning_rate": 2.2118139243662476e-06,
      "loss": 0.0221,
      "step": 2410
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9897243713733076,
      "eval_f1": 0.9419002050580998,
      "eval_loss": 0.03310232236981392,
      "eval_precision": 0.9731638418079096,
      "eval_recall": 0.9125827814569536,
      "eval_runtime": 1202.0673,
      "eval_samples_per_second": 6.886,
      "eval_steps_per_second": 0.861,
      "step": 2412
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9897243713733076,
      "eval_f1": 0.9419002050580998,
      "eval_loss": 0.03310232236981392,
      "eval_precision": 0.9731638418079096,
      "eval_recall": 0.9125827814569536,
      "eval_runtime": 1190.8628,
      "eval_samples_per_second": 6.95,
      "eval_steps_per_second": 0.869,
      "step": 2412
    },
    {
      "epoch": 8.02653399668325,
      "grad_norm": 0.47569531202316284,
      "learning_rate": 2.197097930192154e-06,
      "loss": 0.0118,
      "step": 2420
    },
    {
      "epoch": 8.059701492537313,
      "grad_norm": 0.3512030243873596,
      "learning_rate": 2.1823819360180606e-06,
      "loss": 0.0078,
      "step": 2430
    },
    {
      "epoch": 8.092868988391377,
      "grad_norm": 2.0656638145446777,
      "learning_rate": 2.167665941843967e-06,
      "loss": 0.0157,
      "step": 2440
    },
    {
      "epoch": 8.12603648424544,
      "grad_norm": 3.5812742710113525,
      "learning_rate": 2.1529499476698737e-06,
      "loss": 0.0202,
      "step": 2450
    },
    {
      "epoch": 8.159203980099502,
      "grad_norm": 1.3641023635864258,
      "learning_rate": 2.13823395349578e-06,
      "loss": 0.0152,
      "step": 2460
    },
    {
      "epoch": 8.192371475953566,
      "grad_norm": 1.2627273797988892,
      "learning_rate": 2.1235179593216867e-06,
      "loss": 0.0114,
      "step": 2470
    },
    {
      "epoch": 8.225538971807628,
      "grad_norm": 6.124019145965576,
      "learning_rate": 2.1088019651475932e-06,
      "loss": 0.0216,
      "step": 2480
    },
    {
      "epoch": 8.25870646766169,
      "grad_norm": 4.309211254119873,
      "learning_rate": 2.0940859709734998e-06,
      "loss": 0.0274,
      "step": 2490
    },
    {
      "epoch": 8.291873963515755,
      "grad_norm": 1.392011046409607,
      "learning_rate": 2.0793699767994063e-06,
      "loss": 0.0198,
      "step": 2500
    },
    {
      "epoch": 8.325041459369817,
      "grad_norm": 4.393800258636475,
      "learning_rate": 2.064653982625313e-06,
      "loss": 0.021,
      "step": 2510
    },
    {
      "epoch": 8.35820895522388,
      "grad_norm": 3.399617910385132,
      "learning_rate": 2.0499379884512193e-06,
      "loss": 0.0221,
      "step": 2520
    },
    {
      "epoch": 8.391376451077944,
      "grad_norm": 6.477573871612549,
      "learning_rate": 2.035221994277126e-06,
      "loss": 0.0137,
      "step": 2530
    },
    {
      "epoch": 8.424543946932006,
      "grad_norm": 0.2900259792804718,
      "learning_rate": 2.0205060001030324e-06,
      "loss": 0.012,
      "step": 2540
    },
    {
      "epoch": 8.457711442786069,
      "grad_norm": 3.789968252182007,
      "learning_rate": 2.005790005928939e-06,
      "loss": 0.017,
      "step": 2550
    },
    {
      "epoch": 8.490878938640133,
      "grad_norm": 0.8432955145835876,
      "learning_rate": 1.9910740117548454e-06,
      "loss": 0.0175,
      "step": 2560
    },
    {
      "epoch": 8.524046434494196,
      "grad_norm": 9.211844444274902,
      "learning_rate": 1.9763580175807524e-06,
      "loss": 0.0265,
      "step": 2570
    },
    {
      "epoch": 8.557213930348258,
      "grad_norm": 2.3765931129455566,
      "learning_rate": 1.961642023406659e-06,
      "loss": 0.0231,
      "step": 2580
    },
    {
      "epoch": 8.590381426202322,
      "grad_norm": 3.4669976234436035,
      "learning_rate": 1.9469260292325654e-06,
      "loss": 0.0179,
      "step": 2590
    },
    {
      "epoch": 8.623548922056385,
      "grad_norm": 2.568264961242676,
      "learning_rate": 1.932210035058472e-06,
      "loss": 0.0381,
      "step": 2600
    },
    {
      "epoch": 8.656716417910447,
      "grad_norm": 3.833979606628418,
      "learning_rate": 1.9174940408843785e-06,
      "loss": 0.0197,
      "step": 2610
    },
    {
      "epoch": 8.689883913764511,
      "grad_norm": 4.566088676452637,
      "learning_rate": 1.9027780467102846e-06,
      "loss": 0.0128,
      "step": 2620
    },
    {
      "epoch": 8.723051409618574,
      "grad_norm": 7.637330055236816,
      "learning_rate": 1.8880620525361913e-06,
      "loss": 0.0218,
      "step": 2630
    },
    {
      "epoch": 8.756218905472636,
      "grad_norm": 0.48658671975135803,
      "learning_rate": 1.8733460583620978e-06,
      "loss": 0.0092,
      "step": 2640
    },
    {
      "epoch": 8.7893864013267,
      "grad_norm": 7.624046802520752,
      "learning_rate": 1.8586300641880043e-06,
      "loss": 0.0205,
      "step": 2650
    },
    {
      "epoch": 8.822553897180763,
      "grad_norm": 3.8472015857696533,
      "learning_rate": 1.8439140700139109e-06,
      "loss": 0.021,
      "step": 2660
    },
    {
      "epoch": 8.855721393034825,
      "grad_norm": 1.1343512535095215,
      "learning_rate": 1.8291980758398174e-06,
      "loss": 0.0152,
      "step": 2670
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 2.3980793952941895,
      "learning_rate": 1.814482081665724e-06,
      "loss": 0.0115,
      "step": 2680
    },
    {
      "epoch": 8.922056384742952,
      "grad_norm": 0.8956525921821594,
      "learning_rate": 1.7997660874916306e-06,
      "loss": 0.0199,
      "step": 2690
    },
    {
      "epoch": 8.955223880597014,
      "grad_norm": 1.2940151691436768,
      "learning_rate": 1.7850500933175372e-06,
      "loss": 0.0164,
      "step": 2700
    },
    {
      "epoch": 8.988391376451078,
      "grad_norm": 1.7847353219985962,
      "learning_rate": 1.7703340991434437e-06,
      "loss": 0.0243,
      "step": 2710
    },
    {
      "epoch": 8.998341625207297,
      "eval_accuracy": 0.9897243713733076,
      "eval_f1": 0.9441157133464826,
      "eval_loss": 0.029872268438339233,
      "eval_precision": 0.9373368146214099,
      "eval_recall": 0.9509933774834437,
      "eval_runtime": 957.7187,
      "eval_samples_per_second": 8.642,
      "eval_steps_per_second": 1.081,
      "step": 2713
    },
    {
      "epoch": 8.998341625207297,
      "eval_accuracy": 0.9897243713733076,
      "eval_f1": 0.9441157133464826,
      "eval_loss": 0.029872268438339233,
      "eval_precision": 0.9373368146214099,
      "eval_recall": 0.9509933774834437,
      "eval_runtime": 924.2296,
      "eval_samples_per_second": 8.956,
      "eval_steps_per_second": 1.12,
      "step": 2713
    },
    {
      "epoch": 9.02155887230514,
      "grad_norm": 5.38875150680542,
      "learning_rate": 1.7556181049693502e-06,
      "loss": 0.0207,
      "step": 2720
    },
    {
      "epoch": 9.054726368159203,
      "grad_norm": 4.267789363861084,
      "learning_rate": 1.7409021107952567e-06,
      "loss": 0.0171,
      "step": 2730
    },
    {
      "epoch": 9.087893864013267,
      "grad_norm": 0.02704325132071972,
      "learning_rate": 1.7261861166211633e-06,
      "loss": 0.0217,
      "step": 2740
    },
    {
      "epoch": 9.12106135986733,
      "grad_norm": 2.4590566158294678,
      "learning_rate": 1.71147012244707e-06,
      "loss": 0.0134,
      "step": 2750
    },
    {
      "epoch": 9.154228855721392,
      "grad_norm": 4.025748252868652,
      "learning_rate": 1.6967541282729765e-06,
      "loss": 0.0107,
      "step": 2760
    },
    {
      "epoch": 9.187396351575456,
      "grad_norm": 0.3305419385433197,
      "learning_rate": 1.682038134098883e-06,
      "loss": 0.0096,
      "step": 2770
    },
    {
      "epoch": 9.220563847429519,
      "grad_norm": 0.22748005390167236,
      "learning_rate": 1.6673221399247894e-06,
      "loss": 0.0141,
      "step": 2780
    },
    {
      "epoch": 9.253731343283581,
      "grad_norm": 3.874993085861206,
      "learning_rate": 1.6526061457506959e-06,
      "loss": 0.0138,
      "step": 2790
    },
    {
      "epoch": 9.286898839137645,
      "grad_norm": 0.30863428115844727,
      "learning_rate": 1.6378901515766024e-06,
      "loss": 0.0273,
      "step": 2800
    },
    {
      "epoch": 9.320066334991708,
      "grad_norm": 0.708578884601593,
      "learning_rate": 1.623174157402509e-06,
      "loss": 0.0145,
      "step": 2810
    },
    {
      "epoch": 9.35323383084577,
      "grad_norm": 3.5236282348632812,
      "learning_rate": 1.6084581632284155e-06,
      "loss": 0.0096,
      "step": 2820
    },
    {
      "epoch": 9.386401326699835,
      "grad_norm": 2.0420427322387695,
      "learning_rate": 1.593742169054322e-06,
      "loss": 0.0143,
      "step": 2830
    },
    {
      "epoch": 9.419568822553897,
      "grad_norm": 0.6270666718482971,
      "learning_rate": 1.5790261748802285e-06,
      "loss": 0.0205,
      "step": 2840
    },
    {
      "epoch": 9.45273631840796,
      "grad_norm": 4.4330267906188965,
      "learning_rate": 1.5643101807061352e-06,
      "loss": 0.0232,
      "step": 2850
    },
    {
      "epoch": 9.485903814262024,
      "grad_norm": 0.24574415385723114,
      "learning_rate": 1.5495941865320418e-06,
      "loss": 0.013,
      "step": 2860
    },
    {
      "epoch": 9.519071310116086,
      "grad_norm": 1.1264128684997559,
      "learning_rate": 1.5348781923579483e-06,
      "loss": 0.0112,
      "step": 2870
    },
    {
      "epoch": 9.552238805970148,
      "grad_norm": 4.926446437835693,
      "learning_rate": 1.5201621981838548e-06,
      "loss": 0.021,
      "step": 2880
    },
    {
      "epoch": 9.585406301824213,
      "grad_norm": 8.657315254211426,
      "learning_rate": 1.5054462040097613e-06,
      "loss": 0.0136,
      "step": 2890
    },
    {
      "epoch": 9.618573797678275,
      "grad_norm": 2.785747528076172,
      "learning_rate": 1.4907302098356679e-06,
      "loss": 0.0088,
      "step": 2900
    },
    {
      "epoch": 9.65174129353234,
      "grad_norm": 4.344675064086914,
      "learning_rate": 1.4760142156615746e-06,
      "loss": 0.0165,
      "step": 2910
    },
    {
      "epoch": 9.684908789386402,
      "grad_norm": 0.8342950940132141,
      "learning_rate": 1.4612982214874811e-06,
      "loss": 0.0164,
      "step": 2920
    },
    {
      "epoch": 9.718076285240464,
      "grad_norm": 3.5668983459472656,
      "learning_rate": 1.4465822273133872e-06,
      "loss": 0.0154,
      "step": 2930
    },
    {
      "epoch": 9.751243781094526,
      "grad_norm": 11.813000679016113,
      "learning_rate": 1.431866233139294e-06,
      "loss": 0.0219,
      "step": 2940
    },
    {
      "epoch": 9.78441127694859,
      "grad_norm": 5.857692241668701,
      "learning_rate": 1.4171502389652005e-06,
      "loss": 0.0185,
      "step": 2950
    },
    {
      "epoch": 9.817578772802653,
      "grad_norm": 3.9569897651672363,
      "learning_rate": 1.402434244791107e-06,
      "loss": 0.0138,
      "step": 2960
    },
    {
      "epoch": 9.850746268656717,
      "grad_norm": 3.3848459720611572,
      "learning_rate": 1.3877182506170135e-06,
      "loss": 0.0261,
      "step": 2970
    },
    {
      "epoch": 9.88391376451078,
      "grad_norm": 4.038116455078125,
      "learning_rate": 1.37300225644292e-06,
      "loss": 0.015,
      "step": 2980
    },
    {
      "epoch": 9.917081260364842,
      "grad_norm": 3.637319803237915,
      "learning_rate": 1.3582862622688266e-06,
      "loss": 0.0223,
      "step": 2990
    },
    {
      "epoch": 9.950248756218905,
      "grad_norm": 0.9026098847389221,
      "learning_rate": 1.3435702680947333e-06,
      "loss": 0.0051,
      "step": 3000
    },
    {
      "epoch": 9.983416252072969,
      "grad_norm": 1.6151171922683716,
      "learning_rate": 1.3288542739206398e-06,
      "loss": 0.0175,
      "step": 3010
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9905705996131529,
      "eval_f1": 0.9479305740987984,
      "eval_loss": 0.02921907790005207,
      "eval_precision": 0.955585464333782,
      "eval_recall": 0.9403973509933775,
      "eval_runtime": 1807.1911,
      "eval_samples_per_second": 4.58,
      "eval_steps_per_second": 0.573,
      "step": 3015
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9905705996131529,
      "eval_f1": 0.9479305740987984,
      "eval_loss": 0.02921907790005207,
      "eval_precision": 0.955585464333782,
      "eval_recall": 0.9403973509933775,
      "eval_runtime": 1763.9272,
      "eval_samples_per_second": 4.692,
      "eval_steps_per_second": 0.587,
      "step": 3015
    },
    {
      "epoch": 10.016583747927031,
      "grad_norm": 2.4417483806610107,
      "learning_rate": 1.3141382797465463e-06,
      "loss": 0.0088,
      "step": 3020
    },
    {
      "epoch": 10.049751243781095,
      "grad_norm": 1.6276812553405762,
      "learning_rate": 1.2994222855724529e-06,
      "loss": 0.0092,
      "step": 3030
    },
    {
      "epoch": 10.082918739635158,
      "grad_norm": 0.2304149717092514,
      "learning_rate": 1.2847062913983592e-06,
      "loss": 0.0071,
      "step": 3040
    },
    {
      "epoch": 10.11608623548922,
      "grad_norm": 8.417678833007812,
      "learning_rate": 1.269990297224266e-06,
      "loss": 0.0183,
      "step": 3050
    },
    {
      "epoch": 10.149253731343283,
      "grad_norm": 0.6040161848068237,
      "learning_rate": 1.2552743030501724e-06,
      "loss": 0.0097,
      "step": 3060
    },
    {
      "epoch": 10.182421227197347,
      "grad_norm": 0.44146421551704407,
      "learning_rate": 1.240558308876079e-06,
      "loss": 0.015,
      "step": 3070
    },
    {
      "epoch": 10.21558872305141,
      "grad_norm": 2.993023157119751,
      "learning_rate": 1.2258423147019855e-06,
      "loss": 0.019,
      "step": 3080
    },
    {
      "epoch": 10.248756218905474,
      "grad_norm": 1.1612915992736816,
      "learning_rate": 1.211126320527892e-06,
      "loss": 0.0153,
      "step": 3090
    },
    {
      "epoch": 10.281923714759536,
      "grad_norm": 0.8156561851501465,
      "learning_rate": 1.1964103263537985e-06,
      "loss": 0.0119,
      "step": 3100
    },
    {
      "epoch": 10.315091210613598,
      "grad_norm": 6.288950443267822,
      "learning_rate": 1.1816943321797053e-06,
      "loss": 0.0165,
      "step": 3110
    },
    {
      "epoch": 10.348258706467663,
      "grad_norm": 5.60654354095459,
      "learning_rate": 1.1669783380056116e-06,
      "loss": 0.0114,
      "step": 3120
    },
    {
      "epoch": 10.381426202321725,
      "grad_norm": 0.08158054202795029,
      "learning_rate": 1.1522623438315181e-06,
      "loss": 0.0174,
      "step": 3130
    },
    {
      "epoch": 10.414593698175787,
      "grad_norm": 0.3045007288455963,
      "learning_rate": 1.1375463496574246e-06,
      "loss": 0.0243,
      "step": 3140
    },
    {
      "epoch": 10.447761194029852,
      "grad_norm": 0.2268710732460022,
      "learning_rate": 1.1228303554833312e-06,
      "loss": 0.0093,
      "step": 3150
    },
    {
      "epoch": 10.480928689883914,
      "grad_norm": 2.656339645385742,
      "learning_rate": 1.1081143613092379e-06,
      "loss": 0.0246,
      "step": 3160
    },
    {
      "epoch": 10.514096185737976,
      "grad_norm": 1.5727144479751587,
      "learning_rate": 1.0933983671351444e-06,
      "loss": 0.0097,
      "step": 3170
    },
    {
      "epoch": 10.547263681592039,
      "grad_norm": 2.7162344455718994,
      "learning_rate": 1.078682372961051e-06,
      "loss": 0.0191,
      "step": 3180
    },
    {
      "epoch": 10.580431177446103,
      "grad_norm": 2.8693959712982178,
      "learning_rate": 1.0639663787869572e-06,
      "loss": 0.0151,
      "step": 3190
    },
    {
      "epoch": 10.613598673300165,
      "grad_norm": 7.638680934906006,
      "learning_rate": 1.049250384612864e-06,
      "loss": 0.0179,
      "step": 3200
    },
    {
      "epoch": 10.64676616915423,
      "grad_norm": 0.48648136854171753,
      "learning_rate": 1.0345343904387705e-06,
      "loss": 0.0163,
      "step": 3210
    },
    {
      "epoch": 10.679933665008292,
      "grad_norm": 3.4021425247192383,
      "learning_rate": 1.019818396264677e-06,
      "loss": 0.0125,
      "step": 3220
    },
    {
      "epoch": 10.713101160862355,
      "grad_norm": 3.6360161304473877,
      "learning_rate": 1.0051024020905836e-06,
      "loss": 0.0185,
      "step": 3230
    },
    {
      "epoch": 10.746268656716419,
      "grad_norm": 6.505480766296387,
      "learning_rate": 9.9038640791649e-07,
      "loss": 0.016,
      "step": 3240
    },
    {
      "epoch": 10.779436152570481,
      "grad_norm": 0.9011428952217102,
      "learning_rate": 9.756704137423966e-07,
      "loss": 0.013,
      "step": 3250
    },
    {
      "epoch": 10.812603648424544,
      "grad_norm": 2.909222364425659,
      "learning_rate": 9.609544195683031e-07,
      "loss": 0.0101,
      "step": 3260
    },
    {
      "epoch": 10.845771144278608,
      "grad_norm": 7.635441780090332,
      "learning_rate": 9.462384253942096e-07,
      "loss": 0.0218,
      "step": 3270
    },
    {
      "epoch": 10.87893864013267,
      "grad_norm": 0.14594635367393494,
      "learning_rate": 9.315224312201162e-07,
      "loss": 0.0096,
      "step": 3280
    },
    {
      "epoch": 10.912106135986733,
      "grad_norm": 2.8720626831054688,
      "learning_rate": 9.168064370460227e-07,
      "loss": 0.0289,
      "step": 3290
    },
    {
      "epoch": 10.945273631840797,
      "grad_norm": 0.4523354470729828,
      "learning_rate": 9.020904428719293e-07,
      "loss": 0.0146,
      "step": 3300
    },
    {
      "epoch": 10.97844112769486,
      "grad_norm": 0.9727373719215393,
      "learning_rate": 8.873744486978358e-07,
      "loss": 0.0143,
      "step": 3310
    },
    {
      "epoch": 10.998341625207297,
      "eval_accuracy": 0.9910541586073501,
      "eval_f1": 0.9506008010680908,
      "eval_loss": 0.026311811059713364,
      "eval_precision": 0.9582772543741588,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 1208.0499,
      "eval_samples_per_second": 6.852,
      "eval_steps_per_second": 0.857,
      "step": 3316
    },
    {
      "epoch": 10.998341625207297,
      "eval_accuracy": 0.9910541586073501,
      "eval_f1": 0.9506008010680908,
      "eval_loss": 0.026311811059713364,
      "eval_precision": 0.9582772543741588,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 1221.8786,
      "eval_samples_per_second": 6.774,
      "eval_steps_per_second": 0.847,
      "step": 3316
    },
    {
      "epoch": 11.011608623548922,
      "grad_norm": 4.416426658630371,
      "learning_rate": 8.726584545237424e-07,
      "loss": 0.0113,
      "step": 3320
    },
    {
      "epoch": 11.044776119402986,
      "grad_norm": 3.422131299972534,
      "learning_rate": 8.57942460349649e-07,
      "loss": 0.0274,
      "step": 3330
    },
    {
      "epoch": 11.077943615257048,
      "grad_norm": 2.841357469558716,
      "learning_rate": 8.432264661755555e-07,
      "loss": 0.011,
      "step": 3340
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 5.132075786590576,
      "learning_rate": 8.285104720014619e-07,
      "loss": 0.0123,
      "step": 3350
    },
    {
      "epoch": 11.144278606965175,
      "grad_norm": 2.3907110691070557,
      "learning_rate": 8.137944778273685e-07,
      "loss": 0.0116,
      "step": 3360
    },
    {
      "epoch": 11.177446102819237,
      "grad_norm": 1.0829824209213257,
      "learning_rate": 7.99078483653275e-07,
      "loss": 0.007,
      "step": 3370
    },
    {
      "epoch": 11.2106135986733,
      "grad_norm": 2.0468597412109375,
      "learning_rate": 7.843624894791816e-07,
      "loss": 0.0166,
      "step": 3380
    },
    {
      "epoch": 11.243781094527364,
      "grad_norm": 3.543581247329712,
      "learning_rate": 7.696464953050881e-07,
      "loss": 0.0111,
      "step": 3390
    },
    {
      "epoch": 11.276948590381426,
      "grad_norm": 0.9540805220603943,
      "learning_rate": 7.549305011309947e-07,
      "loss": 0.0134,
      "step": 3400
    },
    {
      "epoch": 11.310116086235489,
      "grad_norm": 1.4842784404754639,
      "learning_rate": 7.402145069569013e-07,
      "loss": 0.013,
      "step": 3410
    },
    {
      "epoch": 11.343283582089553,
      "grad_norm": 1.4766275882720947,
      "learning_rate": 7.254985127828077e-07,
      "loss": 0.0124,
      "step": 3420
    },
    {
      "epoch": 11.376451077943615,
      "grad_norm": 3.055386543273926,
      "learning_rate": 7.107825186087142e-07,
      "loss": 0.0141,
      "step": 3430
    },
    {
      "epoch": 11.409618573797678,
      "grad_norm": 1.1666021347045898,
      "learning_rate": 6.960665244346208e-07,
      "loss": 0.0114,
      "step": 3440
    },
    {
      "epoch": 11.442786069651742,
      "grad_norm": 6.430481910705566,
      "learning_rate": 6.813505302605274e-07,
      "loss": 0.0097,
      "step": 3450
    },
    {
      "epoch": 11.475953565505804,
      "grad_norm": 2.814531087875366,
      "learning_rate": 6.666345360864339e-07,
      "loss": 0.009,
      "step": 3460
    },
    {
      "epoch": 11.509121061359867,
      "grad_norm": 3.351602077484131,
      "learning_rate": 6.519185419123404e-07,
      "loss": 0.0096,
      "step": 3470
    },
    {
      "epoch": 11.542288557213931,
      "grad_norm": 3.901001453399658,
      "learning_rate": 6.37202547738247e-07,
      "loss": 0.0098,
      "step": 3480
    },
    {
      "epoch": 11.575456053067994,
      "grad_norm": 1.087295651435852,
      "learning_rate": 6.224865535641535e-07,
      "loss": 0.0192,
      "step": 3490
    },
    {
      "epoch": 11.608623548922056,
      "grad_norm": 3.6053664684295654,
      "learning_rate": 6.0777055939006e-07,
      "loss": 0.0094,
      "step": 3500
    },
    {
      "epoch": 11.64179104477612,
      "grad_norm": 0.20359134674072266,
      "learning_rate": 5.930545652159666e-07,
      "loss": 0.0163,
      "step": 3510
    },
    {
      "epoch": 11.674958540630183,
      "grad_norm": 1.6104649305343628,
      "learning_rate": 5.783385710418731e-07,
      "loss": 0.0174,
      "step": 3520
    },
    {
      "epoch": 11.708126036484245,
      "grad_norm": 4.1617865562438965,
      "learning_rate": 5.636225768677797e-07,
      "loss": 0.0127,
      "step": 3530
    },
    {
      "epoch": 11.74129353233831,
      "grad_norm": 2.1302101612091064,
      "learning_rate": 5.489065826936862e-07,
      "loss": 0.0189,
      "step": 3540
    },
    {
      "epoch": 11.774461028192372,
      "grad_norm": 0.06839842349290848,
      "learning_rate": 5.341905885195927e-07,
      "loss": 0.0083,
      "step": 3550
    },
    {
      "epoch": 11.807628524046434,
      "grad_norm": 8.057988166809082,
      "learning_rate": 5.194745943454993e-07,
      "loss": 0.0198,
      "step": 3560
    },
    {
      "epoch": 11.840796019900498,
      "grad_norm": 1.2002644538879395,
      "learning_rate": 5.047586001714058e-07,
      "loss": 0.0058,
      "step": 3570
    },
    {
      "epoch": 11.87396351575456,
      "grad_norm": 5.03493070602417,
      "learning_rate": 4.900426059973123e-07,
      "loss": 0.0067,
      "step": 3580
    },
    {
      "epoch": 11.907131011608623,
      "grad_norm": 1.1323158740997314,
      "learning_rate": 4.753266118232188e-07,
      "loss": 0.0111,
      "step": 3590
    },
    {
      "epoch": 11.940298507462687,
      "grad_norm": 4.126866817474365,
      "learning_rate": 4.606106176491254e-07,
      "loss": 0.0197,
      "step": 3600
    },
    {
      "epoch": 11.97346600331675,
      "grad_norm": 1.8144512176513672,
      "learning_rate": 4.458946234750319e-07,
      "loss": 0.0095,
      "step": 3610
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.9910541586073501,
      "eval_f1": 0.9507323568575233,
      "eval_loss": 0.027024950832128525,
      "eval_precision": 0.9558232931726908,
      "eval_recall": 0.9456953642384106,
      "eval_runtime": 1586.9706,
      "eval_samples_per_second": 5.216,
      "eval_steps_per_second": 0.652,
      "step": 3618
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.9910541586073501,
      "eval_f1": 0.9507323568575233,
      "eval_loss": 0.027024950832128525,
      "eval_precision": 0.9558232931726908,
      "eval_recall": 0.9456953642384106,
      "eval_runtime": 1533.8075,
      "eval_samples_per_second": 5.396,
      "eval_steps_per_second": 0.675,
      "step": 3618
    },
    {
      "epoch": 12.006633499170812,
      "grad_norm": 1.209637999534607,
      "learning_rate": 4.311786293009385e-07,
      "loss": 0.0134,
      "step": 3620
    },
    {
      "epoch": 12.039800995024876,
      "grad_norm": 2.1202187538146973,
      "learning_rate": 4.1646263512684497e-07,
      "loss": 0.0093,
      "step": 3630
    },
    {
      "epoch": 12.072968490878939,
      "grad_norm": 0.18907880783081055,
      "learning_rate": 4.0174664095275155e-07,
      "loss": 0.0094,
      "step": 3640
    },
    {
      "epoch": 12.106135986733001,
      "grad_norm": 9.943485260009766,
      "learning_rate": 3.8703064677865807e-07,
      "loss": 0.0155,
      "step": 3650
    },
    {
      "epoch": 12.139303482587065,
      "grad_norm": 0.5802953243255615,
      "learning_rate": 3.7231465260456465e-07,
      "loss": 0.0177,
      "step": 3660
    },
    {
      "epoch": 12.172470978441128,
      "grad_norm": 1.0348197221755981,
      "learning_rate": 3.575986584304711e-07,
      "loss": 0.0089,
      "step": 3670
    },
    {
      "epoch": 12.20563847429519,
      "grad_norm": 2.3128721714019775,
      "learning_rate": 3.428826642563777e-07,
      "loss": 0.0112,
      "step": 3680
    },
    {
      "epoch": 12.238805970149254,
      "grad_norm": 10.498770713806152,
      "learning_rate": 3.281666700822842e-07,
      "loss": 0.0205,
      "step": 3690
    },
    {
      "epoch": 12.271973466003317,
      "grad_norm": 2.354069471359253,
      "learning_rate": 3.1345067590819074e-07,
      "loss": 0.0147,
      "step": 3700
    },
    {
      "epoch": 12.30514096185738,
      "grad_norm": 0.4390949308872223,
      "learning_rate": 2.987346817340973e-07,
      "loss": 0.0112,
      "step": 3710
    },
    {
      "epoch": 12.338308457711443,
      "grad_norm": 0.22495540976524353,
      "learning_rate": 2.8401868756000384e-07,
      "loss": 0.0053,
      "step": 3720
    },
    {
      "epoch": 12.371475953565506,
      "grad_norm": 4.009115219116211,
      "learning_rate": 2.693026933859104e-07,
      "loss": 0.0096,
      "step": 3730
    },
    {
      "epoch": 12.404643449419568,
      "grad_norm": 3.319772243499756,
      "learning_rate": 2.545866992118169e-07,
      "loss": 0.0205,
      "step": 3740
    },
    {
      "epoch": 12.437810945273633,
      "grad_norm": 3.514319896697998,
      "learning_rate": 2.3987070503772347e-07,
      "loss": 0.0157,
      "step": 3750
    },
    {
      "epoch": 12.470978441127695,
      "grad_norm": 4.619039058685303,
      "learning_rate": 2.2515471086363e-07,
      "loss": 0.0176,
      "step": 3760
    },
    {
      "epoch": 12.504145936981757,
      "grad_norm": 2.2699661254882812,
      "learning_rate": 2.1043871668953654e-07,
      "loss": 0.0138,
      "step": 3770
    },
    {
      "epoch": 12.537313432835822,
      "grad_norm": 3.1271378993988037,
      "learning_rate": 1.9572272251544306e-07,
      "loss": 0.0075,
      "step": 3780
    },
    {
      "epoch": 12.570480928689884,
      "grad_norm": 5.449326515197754,
      "learning_rate": 1.8100672834134959e-07,
      "loss": 0.005,
      "step": 3790
    },
    {
      "epoch": 12.603648424543946,
      "grad_norm": 0.6553621888160706,
      "learning_rate": 1.6629073416725614e-07,
      "loss": 0.0166,
      "step": 3800
    },
    {
      "epoch": 12.63681592039801,
      "grad_norm": 4.836333274841309,
      "learning_rate": 1.5157473999316269e-07,
      "loss": 0.0256,
      "step": 3810
    },
    {
      "epoch": 12.669983416252073,
      "grad_norm": 4.683343410491943,
      "learning_rate": 1.368587458190692e-07,
      "loss": 0.012,
      "step": 3820
    },
    {
      "epoch": 12.703150912106135,
      "grad_norm": 1.9491842985153198,
      "learning_rate": 1.2214275164497576e-07,
      "loss": 0.01,
      "step": 3830
    },
    {
      "epoch": 12.7363184079602,
      "grad_norm": 4.325347900390625,
      "learning_rate": 1.0742675747088228e-07,
      "loss": 0.0122,
      "step": 3840
    },
    {
      "epoch": 12.769485903814262,
      "grad_norm": 1.9977511167526245,
      "learning_rate": 9.271076329678883e-08,
      "loss": 0.0102,
      "step": 3850
    },
    {
      "epoch": 12.802653399668324,
      "grad_norm": 2.8009581565856934,
      "learning_rate": 7.799476912269536e-08,
      "loss": 0.0071,
      "step": 3860
    },
    {
      "epoch": 12.835820895522389,
      "grad_norm": 0.39675912261009216,
      "learning_rate": 6.327877494860189e-08,
      "loss": 0.0133,
      "step": 3870
    },
    {
      "epoch": 12.868988391376451,
      "grad_norm": 2.484133005142212,
      "learning_rate": 4.856278077450843e-08,
      "loss": 0.0095,
      "step": 3880
    },
    {
      "epoch": 12.902155887230514,
      "grad_norm": 3.3224284648895264,
      "learning_rate": 3.384678660041497e-08,
      "loss": 0.0137,
      "step": 3890
    },
    {
      "epoch": 12.935323383084578,
      "grad_norm": 8.479129791259766,
      "learning_rate": 1.9130792426321504e-08,
      "loss": 0.0177,
      "step": 3900
    },
    {
      "epoch": 12.96849087893864,
      "grad_norm": 3.008739948272705,
      "learning_rate": 4.414798252228039e-09,
      "loss": 0.0086,
      "step": 3910
    },
    {
      "epoch": 12.97844112769486,
      "eval_accuracy": 0.9911750483558994,
      "eval_f1": 0.9514304723885563,
      "eval_loss": 0.027092980220913887,
      "eval_precision": 0.9558823529411765,
      "eval_recall": 0.9470198675496688,
      "eval_runtime": 1227.8231,
      "eval_samples_per_second": 6.741,
      "eval_steps_per_second": 0.843,
      "step": 3913
    },
    {
      "epoch": 12.97844112769486,
      "eval_accuracy": 0.9911750483558994,
      "eval_f1": 0.9514304723885563,
      "eval_loss": 0.027092980220913887,
      "eval_precision": 0.9558823529411765,
      "eval_recall": 0.9470198675496688,
      "eval_runtime": 1230.4838,
      "eval_samples_per_second": 6.727,
      "eval_steps_per_second": 0.841,
      "step": 3913
    }
  ],
  "logging_steps": 10,
  "max_steps": 3913,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 13,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1270544237182976e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": {
    "epochs": 13,
    "gradient_accumulation_steps": 2,
    "learning_rate": 5.6053221809122e-06,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 64,
    "warmup_steps": 104,
    "weight_decay": 0.07060067803221977
  }
}
