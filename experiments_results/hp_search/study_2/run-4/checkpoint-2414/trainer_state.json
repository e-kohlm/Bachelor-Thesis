{
  "best_metric": 0.0,
  "best_model_checkpoint": "../hyperparameter_search/run-4/checkpoint-2414",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2414,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00041425020712510354,
      "grad_norm": 158.12144470214844,
      "learning_rate": 6.1278749638982235e-06,
      "loss": 0.7415,
      "step": 1
    },
    {
      "epoch": 0.004142502071251036,
      "grad_norm": 16.544097900390625,
      "learning_rate": 6.127874963898223e-05,
      "loss": 0.4344,
      "step": 10
    },
    {
      "epoch": 0.008285004142502071,
      "grad_norm": 20.004575729370117,
      "learning_rate": 0.00012255749927796446,
      "loss": 0.6588,
      "step": 20
    },
    {
      "epoch": 0.012427506213753107,
      "grad_norm": 12.287286758422852,
      "learning_rate": 0.0001838362489169467,
      "loss": 0.3801,
      "step": 30
    },
    {
      "epoch": 0.016570008285004142,
      "grad_norm": 0.29128125309944153,
      "learning_rate": 0.0002451149985559289,
      "loss": 0.4275,
      "step": 40
    },
    {
      "epoch": 0.020712510356255178,
      "grad_norm": 5.149472236633301,
      "learning_rate": 0.00030639374819491116,
      "loss": 0.4202,
      "step": 50
    },
    {
      "epoch": 0.024855012427506214,
      "grad_norm": 13.299643516540527,
      "learning_rate": 0.0003676724978338934,
      "loss": 0.4371,
      "step": 60
    },
    {
      "epoch": 0.02899751449875725,
      "grad_norm": 3.1349704265594482,
      "learning_rate": 0.00042895124747287564,
      "loss": 0.3256,
      "step": 70
    },
    {
      "epoch": 0.033140016570008285,
      "grad_norm": 1.48761785030365,
      "learning_rate": 0.0004902299971118578,
      "loss": 0.3398,
      "step": 80
    },
    {
      "epoch": 0.037282518641259324,
      "grad_norm": 4.048626899719238,
      "learning_rate": 0.0004961721943315156,
      "loss": 0.3642,
      "step": 90
    },
    {
      "epoch": 0.041425020712510356,
      "grad_norm": 2.646515369415283,
      "learning_rate": 0.000495965885726804,
      "loss": 0.2802,
      "step": 100
    },
    {
      "epoch": 0.045567522783761395,
      "grad_norm": 3.8326056003570557,
      "learning_rate": 0.0004957595771220923,
      "loss": 0.2845,
      "step": 110
    },
    {
      "epoch": 0.04971002485501243,
      "grad_norm": 5.326892852783203,
      "learning_rate": 0.0004955532685173807,
      "loss": 0.2927,
      "step": 120
    },
    {
      "epoch": 0.053852526926263466,
      "grad_norm": 2.690941333770752,
      "learning_rate": 0.000495346959912669,
      "loss": 0.2745,
      "step": 130
    },
    {
      "epoch": 0.0579950289975145,
      "grad_norm": 3.8749449253082275,
      "learning_rate": 0.0004951406513079574,
      "loss": 0.4056,
      "step": 140
    },
    {
      "epoch": 0.06213753106876554,
      "grad_norm": 1.9232902526855469,
      "learning_rate": 0.0004949343427032457,
      "loss": 0.2706,
      "step": 150
    },
    {
      "epoch": 0.06628003314001657,
      "grad_norm": 1.3221166133880615,
      "learning_rate": 0.000494728034098534,
      "loss": 0.2635,
      "step": 160
    },
    {
      "epoch": 0.07042253521126761,
      "grad_norm": 1.574569821357727,
      "learning_rate": 0.0004945217254938224,
      "loss": 0.2425,
      "step": 170
    },
    {
      "epoch": 0.07456503728251865,
      "grad_norm": 1.817176342010498,
      "learning_rate": 0.0004943154168891109,
      "loss": 0.3377,
      "step": 180
    },
    {
      "epoch": 0.07870753935376967,
      "grad_norm": 5.391452312469482,
      "learning_rate": 0.0004941091082843992,
      "loss": 0.3004,
      "step": 190
    },
    {
      "epoch": 0.08285004142502071,
      "grad_norm": 2.513336420059204,
      "learning_rate": 0.0004939027996796875,
      "loss": 0.3053,
      "step": 200
    },
    {
      "epoch": 0.08699254349627175,
      "grad_norm": 3.900080919265747,
      "learning_rate": 0.0004936964910749759,
      "loss": 0.202,
      "step": 210
    },
    {
      "epoch": 0.09113504556752279,
      "grad_norm": 2.446227788925171,
      "learning_rate": 0.0004934901824702642,
      "loss": 0.3335,
      "step": 220
    },
    {
      "epoch": 0.09527754763877382,
      "grad_norm": 8.229430198669434,
      "learning_rate": 0.0004932838738655526,
      "loss": 0.3448,
      "step": 230
    },
    {
      "epoch": 0.09942004971002485,
      "grad_norm": 1.4661109447479248,
      "learning_rate": 0.0004930775652608409,
      "loss": 0.4069,
      "step": 240
    },
    {
      "epoch": 0.1035625517812759,
      "grad_norm": 3.0247678756713867,
      "learning_rate": 0.0004928712566561293,
      "loss": 0.3686,
      "step": 250
    },
    {
      "epoch": 0.10770505385252693,
      "grad_norm": 0.06753496825695038,
      "learning_rate": 0.0004926649480514176,
      "loss": 0.3109,
      "step": 260
    },
    {
      "epoch": 0.11184755592377796,
      "grad_norm": 3.5293548107147217,
      "learning_rate": 0.000492458639446706,
      "loss": 0.2044,
      "step": 270
    },
    {
      "epoch": 0.115990057995029,
      "grad_norm": 8.459882736206055,
      "learning_rate": 0.0004922523308419943,
      "loss": 0.3431,
      "step": 280
    },
    {
      "epoch": 0.12013256006628004,
      "grad_norm": 3.6944868564605713,
      "learning_rate": 0.0004920460222372827,
      "loss": 0.3057,
      "step": 290
    },
    {
      "epoch": 0.12427506213753108,
      "grad_norm": 3.648949384689331,
      "learning_rate": 0.000491839713632571,
      "loss": 0.2479,
      "step": 300
    },
    {
      "epoch": 0.12841756420878211,
      "grad_norm": 4.619781017303467,
      "learning_rate": 0.0004916334050278593,
      "loss": 0.3596,
      "step": 310
    },
    {
      "epoch": 0.13256006628003314,
      "grad_norm": 1.6210737228393555,
      "learning_rate": 0.0004914270964231477,
      "loss": 0.3151,
      "step": 320
    },
    {
      "epoch": 0.13670256835128416,
      "grad_norm": 4.349527835845947,
      "learning_rate": 0.000491220787818436,
      "loss": 0.2843,
      "step": 330
    },
    {
      "epoch": 0.14084507042253522,
      "grad_norm": 2.820620059967041,
      "learning_rate": 0.0004910144792137245,
      "loss": 0.3398,
      "step": 340
    },
    {
      "epoch": 0.14498757249378624,
      "grad_norm": 4.669487476348877,
      "learning_rate": 0.0004908081706090127,
      "loss": 0.3178,
      "step": 350
    },
    {
      "epoch": 0.1491300745650373,
      "grad_norm": 2.885556221008301,
      "learning_rate": 0.0004906018620043011,
      "loss": 0.3162,
      "step": 360
    },
    {
      "epoch": 0.15327257663628832,
      "grad_norm": 3.1130337715148926,
      "learning_rate": 0.0004903955533995894,
      "loss": 0.3364,
      "step": 370
    },
    {
      "epoch": 0.15741507870753935,
      "grad_norm": 1.1728233098983765,
      "learning_rate": 0.0004901892447948778,
      "loss": 0.2505,
      "step": 380
    },
    {
      "epoch": 0.1615575807787904,
      "grad_norm": 4.297334671020508,
      "learning_rate": 0.0004899829361901662,
      "loss": 0.3229,
      "step": 390
    },
    {
      "epoch": 0.16570008285004142,
      "grad_norm": 0.6938730478286743,
      "learning_rate": 0.0004897766275854546,
      "loss": 0.2844,
      "step": 400
    },
    {
      "epoch": 0.16984258492129245,
      "grad_norm": 3.226161241531372,
      "learning_rate": 0.0004895703189807429,
      "loss": 0.3121,
      "step": 410
    },
    {
      "epoch": 0.1739850869925435,
      "grad_norm": 1.2468963861465454,
      "learning_rate": 0.0004893640103760313,
      "loss": 0.3559,
      "step": 420
    },
    {
      "epoch": 0.17812758906379453,
      "grad_norm": 3.05289363861084,
      "learning_rate": 0.0004891577017713196,
      "loss": 0.2911,
      "step": 430
    },
    {
      "epoch": 0.18227009113504558,
      "grad_norm": 1.597193717956543,
      "learning_rate": 0.0004889513931666079,
      "loss": 0.1653,
      "step": 440
    },
    {
      "epoch": 0.1864125932062966,
      "grad_norm": 3.5879528522491455,
      "learning_rate": 0.0004887450845618963,
      "loss": 0.3341,
      "step": 450
    },
    {
      "epoch": 0.19055509527754763,
      "grad_norm": 2.303856134414673,
      "learning_rate": 0.0004885387759571846,
      "loss": 0.3443,
      "step": 460
    },
    {
      "epoch": 0.19469759734879868,
      "grad_norm": 7.594249725341797,
      "learning_rate": 0.000488332467352473,
      "loss": 0.3193,
      "step": 470
    },
    {
      "epoch": 0.1988400994200497,
      "grad_norm": 2.7740464210510254,
      "learning_rate": 0.0004881261587477613,
      "loss": 0.3017,
      "step": 480
    },
    {
      "epoch": 0.20298260149130073,
      "grad_norm": 2.050849676132202,
      "learning_rate": 0.00048791985014304967,
      "loss": 0.3502,
      "step": 490
    },
    {
      "epoch": 0.2071251035625518,
      "grad_norm": 4.651731491088867,
      "learning_rate": 0.000487713541538338,
      "loss": 0.3098,
      "step": 500
    },
    {
      "epoch": 0.2112676056338028,
      "grad_norm": 1.3535785675048828,
      "learning_rate": 0.00048750723293362636,
      "loss": 0.3579,
      "step": 510
    },
    {
      "epoch": 0.21541010770505387,
      "grad_norm": 0.23696471750736237,
      "learning_rate": 0.00048730092432891476,
      "loss": 0.2375,
      "step": 520
    },
    {
      "epoch": 0.2195526097763049,
      "grad_norm": 2.1034085750579834,
      "learning_rate": 0.0004870946157242031,
      "loss": 0.2179,
      "step": 530
    },
    {
      "epoch": 0.22369511184755592,
      "grad_norm": 0.9200311899185181,
      "learning_rate": 0.00048688830711949145,
      "loss": 0.2526,
      "step": 540
    },
    {
      "epoch": 0.22783761391880697,
      "grad_norm": 5.084600448608398,
      "learning_rate": 0.0004866819985147798,
      "loss": 0.3424,
      "step": 550
    },
    {
      "epoch": 0.231980115990058,
      "grad_norm": 1.9081522226333618,
      "learning_rate": 0.00048647568991006814,
      "loss": 0.2917,
      "step": 560
    },
    {
      "epoch": 0.23612261806130902,
      "grad_norm": 2.882251739501953,
      "learning_rate": 0.0004862693813053565,
      "loss": 0.3002,
      "step": 570
    },
    {
      "epoch": 0.24026512013256007,
      "grad_norm": 0.5806586146354675,
      "learning_rate": 0.0004860630727006449,
      "loss": 0.3225,
      "step": 580
    },
    {
      "epoch": 0.2444076222038111,
      "grad_norm": 6.0590972900390625,
      "learning_rate": 0.0004858567640959332,
      "loss": 0.2859,
      "step": 590
    },
    {
      "epoch": 0.24855012427506215,
      "grad_norm": 1.088404655456543,
      "learning_rate": 0.0004856504554912215,
      "loss": 0.3673,
      "step": 600
    },
    {
      "epoch": 0.2526926263463132,
      "grad_norm": 4.791062355041504,
      "learning_rate": 0.00048544414688650987,
      "loss": 0.3163,
      "step": 610
    },
    {
      "epoch": 0.25683512841756423,
      "grad_norm": 0.9663558006286621,
      "learning_rate": 0.0004852378382817982,
      "loss": 0.1855,
      "step": 620
    },
    {
      "epoch": 0.2609776304888152,
      "grad_norm": 0.15651662647724152,
      "learning_rate": 0.0004850315296770866,
      "loss": 0.2814,
      "step": 630
    },
    {
      "epoch": 0.2651201325600663,
      "grad_norm": 2.9203126430511475,
      "learning_rate": 0.00048482522107237496,
      "loss": 0.3442,
      "step": 640
    },
    {
      "epoch": 0.26926263463131733,
      "grad_norm": 0.987855851650238,
      "learning_rate": 0.0004846189124676633,
      "loss": 0.358,
      "step": 650
    },
    {
      "epoch": 0.27340513670256833,
      "grad_norm": 4.4424262046813965,
      "learning_rate": 0.00048441260386295165,
      "loss": 0.3563,
      "step": 660
    },
    {
      "epoch": 0.2775476387738194,
      "grad_norm": 1.8091576099395752,
      "learning_rate": 0.00048420629525824,
      "loss": 0.2383,
      "step": 670
    },
    {
      "epoch": 0.28169014084507044,
      "grad_norm": 0.39625075459480286,
      "learning_rate": 0.0004839999866535284,
      "loss": 0.2489,
      "step": 680
    },
    {
      "epoch": 0.28583264291632143,
      "grad_norm": 4.1172566413879395,
      "learning_rate": 0.00048379367804881674,
      "loss": 0.2312,
      "step": 690
    },
    {
      "epoch": 0.2899751449875725,
      "grad_norm": 4.499196529388428,
      "learning_rate": 0.0004835873694441051,
      "loss": 0.3594,
      "step": 700
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 4.428491592407227,
      "learning_rate": 0.0004833810608393934,
      "loss": 0.3548,
      "step": 710
    },
    {
      "epoch": 0.2982601491300746,
      "grad_norm": 2.852036952972412,
      "learning_rate": 0.0004831747522346817,
      "loss": 0.3581,
      "step": 720
    },
    {
      "epoch": 0.3024026512013256,
      "grad_norm": 1.759533166885376,
      "learning_rate": 0.00048296844362997007,
      "loss": 0.2016,
      "step": 730
    },
    {
      "epoch": 0.30654515327257664,
      "grad_norm": 4.1222734451293945,
      "learning_rate": 0.00048276213502525847,
      "loss": 0.2624,
      "step": 740
    },
    {
      "epoch": 0.3106876553438277,
      "grad_norm": 2.348109245300293,
      "learning_rate": 0.0004825558264205468,
      "loss": 0.3247,
      "step": 750
    },
    {
      "epoch": 0.3148301574150787,
      "grad_norm": 0.5812842845916748,
      "learning_rate": 0.00048234951781583516,
      "loss": 0.388,
      "step": 760
    },
    {
      "epoch": 0.31897265948632975,
      "grad_norm": 5.36679744720459,
      "learning_rate": 0.0004821432092111235,
      "loss": 0.3571,
      "step": 770
    },
    {
      "epoch": 0.3231151615575808,
      "grad_norm": 0.33722493052482605,
      "learning_rate": 0.00048193690060641185,
      "loss": 0.2716,
      "step": 780
    },
    {
      "epoch": 0.3272576636288318,
      "grad_norm": 1.3288661241531372,
      "learning_rate": 0.00048173059200170025,
      "loss": 0.3458,
      "step": 790
    },
    {
      "epoch": 0.33140016570008285,
      "grad_norm": 2.111629009246826,
      "learning_rate": 0.0004815242833969886,
      "loss": 0.3664,
      "step": 800
    },
    {
      "epoch": 0.3355426677713339,
      "grad_norm": 1.1118125915527344,
      "learning_rate": 0.00048131797479227694,
      "loss": 0.2891,
      "step": 810
    },
    {
      "epoch": 0.3396851698425849,
      "grad_norm": 6.665634632110596,
      "learning_rate": 0.0004811116661875653,
      "loss": 0.3418,
      "step": 820
    },
    {
      "epoch": 0.34382767191383595,
      "grad_norm": 3.214865207672119,
      "learning_rate": 0.0004809053575828536,
      "loss": 0.3733,
      "step": 830
    },
    {
      "epoch": 0.347970173985087,
      "grad_norm": 3.3254504203796387,
      "learning_rate": 0.000480699048978142,
      "loss": 0.2723,
      "step": 840
    },
    {
      "epoch": 0.352112676056338,
      "grad_norm": 1.3515762090682983,
      "learning_rate": 0.0004804927403734303,
      "loss": 0.2943,
      "step": 850
    },
    {
      "epoch": 0.35625517812758906,
      "grad_norm": 1.4312281608581543,
      "learning_rate": 0.00048028643176871867,
      "loss": 0.2938,
      "step": 860
    },
    {
      "epoch": 0.3603976801988401,
      "grad_norm": 1.2763656377792358,
      "learning_rate": 0.000480080123164007,
      "loss": 0.3636,
      "step": 870
    },
    {
      "epoch": 0.36454018227009116,
      "grad_norm": 4.356200218200684,
      "learning_rate": 0.00047987381455929536,
      "loss": 0.3348,
      "step": 880
    },
    {
      "epoch": 0.36868268434134216,
      "grad_norm": 6.244858264923096,
      "learning_rate": 0.0004796675059545837,
      "loss": 0.3269,
      "step": 890
    },
    {
      "epoch": 0.3728251864125932,
      "grad_norm": 0.5272730588912964,
      "learning_rate": 0.0004794611973498721,
      "loss": 0.3117,
      "step": 900
    },
    {
      "epoch": 0.37696768848384427,
      "grad_norm": 0.5763294100761414,
      "learning_rate": 0.00047925488874516045,
      "loss": 0.3324,
      "step": 910
    },
    {
      "epoch": 0.38111019055509526,
      "grad_norm": 6.884688377380371,
      "learning_rate": 0.0004790485801404488,
      "loss": 0.3713,
      "step": 920
    },
    {
      "epoch": 0.3852526926263463,
      "grad_norm": 1.7378787994384766,
      "learning_rate": 0.00047884227153573714,
      "loss": 0.3235,
      "step": 930
    },
    {
      "epoch": 0.38939519469759737,
      "grad_norm": 0.09126140922307968,
      "learning_rate": 0.0004786359629310255,
      "loss": 0.3075,
      "step": 940
    },
    {
      "epoch": 0.39353769676884837,
      "grad_norm": 2.522742509841919,
      "learning_rate": 0.00047842965432631383,
      "loss": 0.2192,
      "step": 950
    },
    {
      "epoch": 0.3976801988400994,
      "grad_norm": 1.3365051746368408,
      "learning_rate": 0.0004782233457216022,
      "loss": 0.3451,
      "step": 960
    },
    {
      "epoch": 0.40182270091135047,
      "grad_norm": 1.2856632471084595,
      "learning_rate": 0.0004780170371168905,
      "loss": 0.4192,
      "step": 970
    },
    {
      "epoch": 0.40596520298260147,
      "grad_norm": 2.0568552017211914,
      "learning_rate": 0.00047781072851217887,
      "loss": 0.3136,
      "step": 980
    },
    {
      "epoch": 0.4101077050538525,
      "grad_norm": 4.4715118408203125,
      "learning_rate": 0.0004776044199074672,
      "loss": 0.3724,
      "step": 990
    },
    {
      "epoch": 0.4142502071251036,
      "grad_norm": 5.401775360107422,
      "learning_rate": 0.0004773981113027556,
      "loss": 0.2477,
      "step": 1000
    },
    {
      "epoch": 0.4183927091963546,
      "grad_norm": 7.350805759429932,
      "learning_rate": 0.00047719180269804396,
      "loss": 0.3043,
      "step": 1010
    },
    {
      "epoch": 0.4225352112676056,
      "grad_norm": 1.331383466720581,
      "learning_rate": 0.0004769854940933323,
      "loss": 0.2974,
      "step": 1020
    },
    {
      "epoch": 0.4266777133388567,
      "grad_norm": 1.300391435623169,
      "learning_rate": 0.00047677918548862065,
      "loss": 0.3173,
      "step": 1030
    },
    {
      "epoch": 0.43082021541010773,
      "grad_norm": 2.162928819656372,
      "learning_rate": 0.000476572876883909,
      "loss": 0.3437,
      "step": 1040
    },
    {
      "epoch": 0.43496271748135873,
      "grad_norm": 0.6428831219673157,
      "learning_rate": 0.00047636656827919734,
      "loss": 0.3825,
      "step": 1050
    },
    {
      "epoch": 0.4391052195526098,
      "grad_norm": 2.1522514820098877,
      "learning_rate": 0.00047616025967448574,
      "loss": 0.3293,
      "step": 1060
    },
    {
      "epoch": 0.44324772162386084,
      "grad_norm": 2.4230637550354004,
      "learning_rate": 0.00047595395106977403,
      "loss": 0.3079,
      "step": 1070
    },
    {
      "epoch": 0.44739022369511183,
      "grad_norm": 2.505929946899414,
      "learning_rate": 0.0004757476424650624,
      "loss": 0.2525,
      "step": 1080
    },
    {
      "epoch": 0.4515327257663629,
      "grad_norm": 1.3042652606964111,
      "learning_rate": 0.0004755413338603507,
      "loss": 0.4103,
      "step": 1090
    },
    {
      "epoch": 0.45567522783761394,
      "grad_norm": 2.764321804046631,
      "learning_rate": 0.00047533502525563907,
      "loss": 0.2567,
      "step": 1100
    },
    {
      "epoch": 0.45981772990886494,
      "grad_norm": 4.690799236297607,
      "learning_rate": 0.00047512871665092747,
      "loss": 0.3967,
      "step": 1110
    },
    {
      "epoch": 0.463960231980116,
      "grad_norm": 4.779212951660156,
      "learning_rate": 0.0004749224080462158,
      "loss": 0.3792,
      "step": 1120
    },
    {
      "epoch": 0.46810273405136704,
      "grad_norm": 3.5418283939361572,
      "learning_rate": 0.00047471609944150416,
      "loss": 0.315,
      "step": 1130
    },
    {
      "epoch": 0.47224523612261804,
      "grad_norm": 4.139476299285889,
      "learning_rate": 0.0004745097908367925,
      "loss": 0.4214,
      "step": 1140
    },
    {
      "epoch": 0.4763877381938691,
      "grad_norm": 1.7734514474868774,
      "learning_rate": 0.00047430348223208085,
      "loss": 0.3402,
      "step": 1150
    },
    {
      "epoch": 0.48053024026512015,
      "grad_norm": 10.484601020812988,
      "learning_rate": 0.00047409717362736925,
      "loss": 0.3635,
      "step": 1160
    },
    {
      "epoch": 0.48467274233637114,
      "grad_norm": 2.203468084335327,
      "learning_rate": 0.0004738908650226576,
      "loss": 0.3141,
      "step": 1170
    },
    {
      "epoch": 0.4888152444076222,
      "grad_norm": 7.724849700927734,
      "learning_rate": 0.00047368455641794594,
      "loss": 0.2911,
      "step": 1180
    },
    {
      "epoch": 0.49295774647887325,
      "grad_norm": 2.191635847091675,
      "learning_rate": 0.00047347824781323423,
      "loss": 0.3223,
      "step": 1190
    },
    {
      "epoch": 0.4971002485501243,
      "grad_norm": 1.8327033519744873,
      "learning_rate": 0.0004732719392085226,
      "loss": 0.2371,
      "step": 1200
    },
    {
      "epoch": 0.5012427506213754,
      "grad_norm": 0.38487645983695984,
      "learning_rate": 0.0004730656306038109,
      "loss": 0.33,
      "step": 1210
    },
    {
      "epoch": 0.5053852526926264,
      "grad_norm": 0.9034037590026855,
      "learning_rate": 0.0004728593219990993,
      "loss": 0.2707,
      "step": 1220
    },
    {
      "epoch": 0.5095277547638773,
      "grad_norm": 4.224576950073242,
      "learning_rate": 0.00047265301339438767,
      "loss": 0.3548,
      "step": 1230
    },
    {
      "epoch": 0.5136702568351285,
      "grad_norm": 2.6905605792999268,
      "learning_rate": 0.000472446704789676,
      "loss": 0.3714,
      "step": 1240
    },
    {
      "epoch": 0.5178127589063795,
      "grad_norm": 0.8602455854415894,
      "learning_rate": 0.00047224039618496436,
      "loss": 0.3138,
      "step": 1250
    },
    {
      "epoch": 0.5219552609776305,
      "grad_norm": 4.9534502029418945,
      "learning_rate": 0.0004720340875802527,
      "loss": 0.3255,
      "step": 1260
    },
    {
      "epoch": 0.5260977630488816,
      "grad_norm": 2.607386827468872,
      "learning_rate": 0.0004718277789755411,
      "loss": 0.2198,
      "step": 1270
    },
    {
      "epoch": 0.5302402651201326,
      "grad_norm": 0.9117487072944641,
      "learning_rate": 0.00047162147037082945,
      "loss": 0.3639,
      "step": 1280
    },
    {
      "epoch": 0.5343827671913836,
      "grad_norm": 2.927116870880127,
      "learning_rate": 0.0004714151617661178,
      "loss": 0.3238,
      "step": 1290
    },
    {
      "epoch": 0.5385252692626347,
      "grad_norm": 0.9556717276573181,
      "learning_rate": 0.00047120885316140614,
      "loss": 0.1672,
      "step": 1300
    },
    {
      "epoch": 0.5426677713338857,
      "grad_norm": 8.644536018371582,
      "learning_rate": 0.00047100254455669443,
      "loss": 0.3119,
      "step": 1310
    },
    {
      "epoch": 0.5468102734051367,
      "grad_norm": 2.3866052627563477,
      "learning_rate": 0.00047079623595198283,
      "loss": 0.2682,
      "step": 1320
    },
    {
      "epoch": 0.5509527754763878,
      "grad_norm": 1.4518851041793823,
      "learning_rate": 0.0004705899273472712,
      "loss": 0.2005,
      "step": 1330
    },
    {
      "epoch": 0.5550952775476388,
      "grad_norm": 3.099846124649048,
      "learning_rate": 0.0004703836187425595,
      "loss": 0.3787,
      "step": 1340
    },
    {
      "epoch": 0.5592377796188898,
      "grad_norm": 0.39525777101516724,
      "learning_rate": 0.00047017731013784787,
      "loss": 0.2927,
      "step": 1350
    },
    {
      "epoch": 0.5633802816901409,
      "grad_norm": 1.9818508625030518,
      "learning_rate": 0.0004699710015331362,
      "loss": 0.244,
      "step": 1360
    },
    {
      "epoch": 0.5675227837613919,
      "grad_norm": 3.8014509677886963,
      "learning_rate": 0.00046976469292842456,
      "loss": 0.1904,
      "step": 1370
    },
    {
      "epoch": 0.5716652858326429,
      "grad_norm": 0.09793221950531006,
      "learning_rate": 0.00046955838432371296,
      "loss": 0.4227,
      "step": 1380
    },
    {
      "epoch": 0.575807787903894,
      "grad_norm": 6.823747158050537,
      "learning_rate": 0.0004693520757190013,
      "loss": 0.4195,
      "step": 1390
    },
    {
      "epoch": 0.579950289975145,
      "grad_norm": 0.8840986490249634,
      "learning_rate": 0.00046914576711428965,
      "loss": 0.2197,
      "step": 1400
    },
    {
      "epoch": 0.584092792046396,
      "grad_norm": 3.6952712535858154,
      "learning_rate": 0.000468939458509578,
      "loss": 0.4405,
      "step": 1410
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 8.885519027709961,
      "learning_rate": 0.00046873314990486634,
      "loss": 0.3912,
      "step": 1420
    },
    {
      "epoch": 0.5923777961888981,
      "grad_norm": 0.317158579826355,
      "learning_rate": 0.0004685268413001547,
      "loss": 0.3715,
      "step": 1430
    },
    {
      "epoch": 0.5965202982601492,
      "grad_norm": 4.615341663360596,
      "learning_rate": 0.00046832053269544303,
      "loss": 0.3243,
      "step": 1440
    },
    {
      "epoch": 0.6006628003314002,
      "grad_norm": 0.9085701107978821,
      "learning_rate": 0.0004681142240907314,
      "loss": 0.2777,
      "step": 1450
    },
    {
      "epoch": 0.6048053024026512,
      "grad_norm": 1.6462807655334473,
      "learning_rate": 0.0004679079154860197,
      "loss": 0.4213,
      "step": 1460
    },
    {
      "epoch": 0.6089478044739023,
      "grad_norm": 3.088620662689209,
      "learning_rate": 0.00046770160688130807,
      "loss": 0.2717,
      "step": 1470
    },
    {
      "epoch": 0.6130903065451533,
      "grad_norm": 3.1633963584899902,
      "learning_rate": 0.00046749529827659647,
      "loss": 0.2979,
      "step": 1480
    },
    {
      "epoch": 0.6172328086164043,
      "grad_norm": 2.823030948638916,
      "learning_rate": 0.0004672889896718848,
      "loss": 0.3395,
      "step": 1490
    },
    {
      "epoch": 0.6213753106876554,
      "grad_norm": 0.16953018307685852,
      "learning_rate": 0.00046708268106717316,
      "loss": 0.2529,
      "step": 1500
    },
    {
      "epoch": 0.6255178127589064,
      "grad_norm": 8.104066848754883,
      "learning_rate": 0.0004668763724624615,
      "loss": 0.3048,
      "step": 1510
    },
    {
      "epoch": 0.6296603148301574,
      "grad_norm": 3.7436113357543945,
      "learning_rate": 0.00046667006385774985,
      "loss": 0.2853,
      "step": 1520
    },
    {
      "epoch": 0.6338028169014085,
      "grad_norm": 0.6292157173156738,
      "learning_rate": 0.0004664637552530382,
      "loss": 0.3593,
      "step": 1530
    },
    {
      "epoch": 0.6379453189726595,
      "grad_norm": 2.0358591079711914,
      "learning_rate": 0.0004662574466483266,
      "loss": 0.3328,
      "step": 1540
    },
    {
      "epoch": 0.6420878210439105,
      "grad_norm": 1.1111457347869873,
      "learning_rate": 0.0004660511380436149,
      "loss": 0.172,
      "step": 1550
    },
    {
      "epoch": 0.6462303231151616,
      "grad_norm": 3.9279398918151855,
      "learning_rate": 0.00046584482943890323,
      "loss": 0.2841,
      "step": 1560
    },
    {
      "epoch": 0.6503728251864126,
      "grad_norm": 2.0618338584899902,
      "learning_rate": 0.0004656385208341916,
      "loss": 0.3258,
      "step": 1570
    },
    {
      "epoch": 0.6545153272576636,
      "grad_norm": 0.22578772902488708,
      "learning_rate": 0.0004654322122294799,
      "loss": 0.277,
      "step": 1580
    },
    {
      "epoch": 0.6586578293289147,
      "grad_norm": 3.1740050315856934,
      "learning_rate": 0.0004652259036247683,
      "loss": 0.2786,
      "step": 1590
    },
    {
      "epoch": 0.6628003314001657,
      "grad_norm": 0.5347949862480164,
      "learning_rate": 0.00046501959502005666,
      "loss": 0.3186,
      "step": 1600
    },
    {
      "epoch": 0.6669428334714167,
      "grad_norm": 3.6950523853302,
      "learning_rate": 0.000464813286415345,
      "loss": 0.3395,
      "step": 1610
    },
    {
      "epoch": 0.6710853355426678,
      "grad_norm": 3.7087490558624268,
      "learning_rate": 0.00046460697781063336,
      "loss": 0.3323,
      "step": 1620
    },
    {
      "epoch": 0.6752278376139188,
      "grad_norm": 7.468784332275391,
      "learning_rate": 0.0004644006692059217,
      "loss": 0.3378,
      "step": 1630
    },
    {
      "epoch": 0.6793703396851698,
      "grad_norm": 0.5725728869438171,
      "learning_rate": 0.0004641943606012101,
      "loss": 0.2747,
      "step": 1640
    },
    {
      "epoch": 0.6835128417564209,
      "grad_norm": 4.550611972808838,
      "learning_rate": 0.00046398805199649845,
      "loss": 0.2968,
      "step": 1650
    },
    {
      "epoch": 0.6876553438276719,
      "grad_norm": 1.4802560806274414,
      "learning_rate": 0.0004637817433917868,
      "loss": 0.327,
      "step": 1660
    },
    {
      "epoch": 0.6917978458989229,
      "grad_norm": 0.20180433988571167,
      "learning_rate": 0.0004635754347870751,
      "loss": 0.2713,
      "step": 1670
    },
    {
      "epoch": 0.695940347970174,
      "grad_norm": 0.5601328611373901,
      "learning_rate": 0.00046336912618236343,
      "loss": 0.2196,
      "step": 1680
    },
    {
      "epoch": 0.700082850041425,
      "grad_norm": 0.7540254592895508,
      "learning_rate": 0.0004631628175776518,
      "loss": 0.3266,
      "step": 1690
    },
    {
      "epoch": 0.704225352112676,
      "grad_norm": 3.5829944610595703,
      "learning_rate": 0.0004629565089729402,
      "loss": 0.2037,
      "step": 1700
    },
    {
      "epoch": 0.7083678541839271,
      "grad_norm": 0.40625882148742676,
      "learning_rate": 0.0004627502003682285,
      "loss": 0.28,
      "step": 1710
    },
    {
      "epoch": 0.7125103562551781,
      "grad_norm": 0.15445327758789062,
      "learning_rate": 0.00046254389176351686,
      "loss": 0.2708,
      "step": 1720
    },
    {
      "epoch": 0.7166528583264291,
      "grad_norm": 1.603955626487732,
      "learning_rate": 0.0004623375831588052,
      "loss": 0.3822,
      "step": 1730
    },
    {
      "epoch": 0.7207953603976802,
      "grad_norm": 1.2237628698349,
      "learning_rate": 0.00046213127455409356,
      "loss": 0.1971,
      "step": 1740
    },
    {
      "epoch": 0.7249378624689312,
      "grad_norm": 0.4057231545448303,
      "learning_rate": 0.00046192496594938195,
      "loss": 0.3784,
      "step": 1750
    },
    {
      "epoch": 0.7290803645401823,
      "grad_norm": 8.409186363220215,
      "learning_rate": 0.0004617186573446703,
      "loss": 0.3608,
      "step": 1760
    },
    {
      "epoch": 0.7332228666114333,
      "grad_norm": 0.33087727427482605,
      "learning_rate": 0.00046151234873995865,
      "loss": 0.3991,
      "step": 1770
    },
    {
      "epoch": 0.7373653686826843,
      "grad_norm": 3.2146542072296143,
      "learning_rate": 0.000461306040135247,
      "loss": 0.3447,
      "step": 1780
    },
    {
      "epoch": 0.7415078707539354,
      "grad_norm": 2.9932522773742676,
      "learning_rate": 0.0004610997315305353,
      "loss": 0.3476,
      "step": 1790
    },
    {
      "epoch": 0.7456503728251864,
      "grad_norm": 4.278341770172119,
      "learning_rate": 0.00046089342292582363,
      "loss": 0.3552,
      "step": 1800
    },
    {
      "epoch": 0.7497928748964374,
      "grad_norm": 0.5546351671218872,
      "learning_rate": 0.00046068711432111203,
      "loss": 0.292,
      "step": 1810
    },
    {
      "epoch": 0.7539353769676885,
      "grad_norm": 3.363192558288574,
      "learning_rate": 0.0004604808057164004,
      "loss": 0.3585,
      "step": 1820
    },
    {
      "epoch": 0.7580778790389395,
      "grad_norm": 2.092989921569824,
      "learning_rate": 0.0004602744971116887,
      "loss": 0.2381,
      "step": 1830
    },
    {
      "epoch": 0.7622203811101905,
      "grad_norm": 2.2563693523406982,
      "learning_rate": 0.00046006818850697706,
      "loss": 0.2755,
      "step": 1840
    },
    {
      "epoch": 0.7663628831814416,
      "grad_norm": 4.081775188446045,
      "learning_rate": 0.0004598618799022654,
      "loss": 0.4284,
      "step": 1850
    },
    {
      "epoch": 0.7705053852526926,
      "grad_norm": 3.269766092300415,
      "learning_rate": 0.0004596555712975538,
      "loss": 0.2853,
      "step": 1860
    },
    {
      "epoch": 0.7746478873239436,
      "grad_norm": 5.767225742340088,
      "learning_rate": 0.00045944926269284215,
      "loss": 0.2924,
      "step": 1870
    },
    {
      "epoch": 0.7787903893951947,
      "grad_norm": 2.4749841690063477,
      "learning_rate": 0.0004592429540881305,
      "loss": 0.2945,
      "step": 1880
    },
    {
      "epoch": 0.7829328914664457,
      "grad_norm": 0.35605406761169434,
      "learning_rate": 0.00045903664548341885,
      "loss": 0.3262,
      "step": 1890
    },
    {
      "epoch": 0.7870753935376967,
      "grad_norm": 6.161259174346924,
      "learning_rate": 0.0004588303368787072,
      "loss": 0.3899,
      "step": 1900
    },
    {
      "epoch": 0.7912178956089478,
      "grad_norm": 2.2512385845184326,
      "learning_rate": 0.00045862402827399554,
      "loss": 0.3328,
      "step": 1910
    },
    {
      "epoch": 0.7953603976801988,
      "grad_norm": 0.95899498462677,
      "learning_rate": 0.0004584177196692839,
      "loss": 0.2623,
      "step": 1920
    },
    {
      "epoch": 0.7995028997514498,
      "grad_norm": 1.7439756393432617,
      "learning_rate": 0.00045821141106457223,
      "loss": 0.299,
      "step": 1930
    },
    {
      "epoch": 0.8036454018227009,
      "grad_norm": 8.599896430969238,
      "learning_rate": 0.00045800510245986057,
      "loss": 0.4354,
      "step": 1940
    },
    {
      "epoch": 0.8077879038939519,
      "grad_norm": 0.5827453136444092,
      "learning_rate": 0.0004577987938551489,
      "loss": 0.4013,
      "step": 1950
    },
    {
      "epoch": 0.8119304059652029,
      "grad_norm": 1.9118571281433105,
      "learning_rate": 0.00045759248525043726,
      "loss": 0.2156,
      "step": 1960
    },
    {
      "epoch": 0.816072908036454,
      "grad_norm": 4.5295491218566895,
      "learning_rate": 0.00045738617664572566,
      "loss": 0.3041,
      "step": 1970
    },
    {
      "epoch": 0.820215410107705,
      "grad_norm": 4.6571526527404785,
      "learning_rate": 0.000457179868041014,
      "loss": 0.3056,
      "step": 1980
    },
    {
      "epoch": 0.824357912178956,
      "grad_norm": 8.431594848632812,
      "learning_rate": 0.00045697355943630235,
      "loss": 0.3254,
      "step": 1990
    },
    {
      "epoch": 0.8285004142502072,
      "grad_norm": 0.6895391345024109,
      "learning_rate": 0.0004567672508315907,
      "loss": 0.2236,
      "step": 2000
    },
    {
      "epoch": 0.8326429163214581,
      "grad_norm": 0.5361433029174805,
      "learning_rate": 0.00045656094222687905,
      "loss": 0.2578,
      "step": 2010
    },
    {
      "epoch": 0.8367854183927091,
      "grad_norm": 1.8821215629577637,
      "learning_rate": 0.00045635463362216744,
      "loss": 0.2394,
      "step": 2020
    },
    {
      "epoch": 0.8409279204639603,
      "grad_norm": 1.7611488103866577,
      "learning_rate": 0.00045614832501745574,
      "loss": 0.241,
      "step": 2030
    },
    {
      "epoch": 0.8450704225352113,
      "grad_norm": 6.161854267120361,
      "learning_rate": 0.0004559420164127441,
      "loss": 0.3407,
      "step": 2040
    },
    {
      "epoch": 0.8492129246064622,
      "grad_norm": 1.5220540761947632,
      "learning_rate": 0.0004557357078080324,
      "loss": 0.3037,
      "step": 2050
    },
    {
      "epoch": 0.8533554266777134,
      "grad_norm": 1.7540417909622192,
      "learning_rate": 0.00045552939920332077,
      "loss": 0.3813,
      "step": 2060
    },
    {
      "epoch": 0.8574979287489644,
      "grad_norm": 3.874809741973877,
      "learning_rate": 0.00045532309059860917,
      "loss": 0.2158,
      "step": 2070
    },
    {
      "epoch": 0.8616404308202155,
      "grad_norm": 0.7814970016479492,
      "learning_rate": 0.0004551167819938975,
      "loss": 0.3598,
      "step": 2080
    },
    {
      "epoch": 0.8657829328914665,
      "grad_norm": 3.4513142108917236,
      "learning_rate": 0.00045491047338918586,
      "loss": 0.3519,
      "step": 2090
    },
    {
      "epoch": 0.8699254349627175,
      "grad_norm": 5.534661769866943,
      "learning_rate": 0.0004547041647844742,
      "loss": 0.2953,
      "step": 2100
    },
    {
      "epoch": 0.8740679370339686,
      "grad_norm": 0.4935089647769928,
      "learning_rate": 0.00045449785617976255,
      "loss": 0.2884,
      "step": 2110
    },
    {
      "epoch": 0.8782104391052196,
      "grad_norm": 7.0489888191223145,
      "learning_rate": 0.00045429154757505095,
      "loss": 0.4415,
      "step": 2120
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 4.570616245269775,
      "learning_rate": 0.0004540852389703393,
      "loss": 0.367,
      "step": 2130
    },
    {
      "epoch": 0.8864954432477217,
      "grad_norm": 0.22860270738601685,
      "learning_rate": 0.00045387893036562764,
      "loss": 0.2859,
      "step": 2140
    },
    {
      "epoch": 0.8906379453189727,
      "grad_norm": 3.2011303901672363,
      "learning_rate": 0.00045367262176091594,
      "loss": 0.4929,
      "step": 2150
    },
    {
      "epoch": 0.8947804473902237,
      "grad_norm": 1.8431422710418701,
      "learning_rate": 0.0004534663131562043,
      "loss": 0.2526,
      "step": 2160
    },
    {
      "epoch": 0.8989229494614748,
      "grad_norm": 2.3156936168670654,
      "learning_rate": 0.0004532600045514926,
      "loss": 0.3382,
      "step": 2170
    },
    {
      "epoch": 0.9030654515327258,
      "grad_norm": 4.566453456878662,
      "learning_rate": 0.000453053695946781,
      "loss": 0.3313,
      "step": 2180
    },
    {
      "epoch": 0.9072079536039768,
      "grad_norm": 0.07390809059143066,
      "learning_rate": 0.00045284738734206937,
      "loss": 0.2532,
      "step": 2190
    },
    {
      "epoch": 0.9113504556752279,
      "grad_norm": 3.9842610359191895,
      "learning_rate": 0.0004526410787373577,
      "loss": 0.2872,
      "step": 2200
    },
    {
      "epoch": 0.9154929577464789,
      "grad_norm": 3.804760217666626,
      "learning_rate": 0.00045243477013264606,
      "loss": 0.336,
      "step": 2210
    },
    {
      "epoch": 0.9196354598177299,
      "grad_norm": 2.9195032119750977,
      "learning_rate": 0.0004522284615279344,
      "loss": 0.2443,
      "step": 2220
    },
    {
      "epoch": 0.923777961888981,
      "grad_norm": 1.230532169342041,
      "learning_rate": 0.0004520221529232228,
      "loss": 0.2599,
      "step": 2230
    },
    {
      "epoch": 0.927920463960232,
      "grad_norm": 6.343193531036377,
      "learning_rate": 0.00045181584431851115,
      "loss": 0.3317,
      "step": 2240
    },
    {
      "epoch": 0.932062966031483,
      "grad_norm": 1.103690266609192,
      "learning_rate": 0.0004516095357137995,
      "loss": 0.2282,
      "step": 2250
    },
    {
      "epoch": 0.9362054681027341,
      "grad_norm": 1.5811386108398438,
      "learning_rate": 0.00045140322710908784,
      "loss": 0.4011,
      "step": 2260
    },
    {
      "epoch": 0.9403479701739851,
      "grad_norm": 2.1762871742248535,
      "learning_rate": 0.00045119691850437614,
      "loss": 0.2559,
      "step": 2270
    },
    {
      "epoch": 0.9444904722452361,
      "grad_norm": 0.7424517273902893,
      "learning_rate": 0.0004509906098996645,
      "loss": 0.2997,
      "step": 2280
    },
    {
      "epoch": 0.9486329743164872,
      "grad_norm": 0.2417212724685669,
      "learning_rate": 0.0004507843012949529,
      "loss": 0.2348,
      "step": 2290
    },
    {
      "epoch": 0.9527754763877382,
      "grad_norm": 1.988499641418457,
      "learning_rate": 0.0004505779926902412,
      "loss": 0.2134,
      "step": 2300
    },
    {
      "epoch": 0.9569179784589892,
      "grad_norm": 3.7127270698547363,
      "learning_rate": 0.00045037168408552957,
      "loss": 0.4081,
      "step": 2310
    },
    {
      "epoch": 0.9610604805302403,
      "grad_norm": 3.9156389236450195,
      "learning_rate": 0.0004501653754808179,
      "loss": 0.3628,
      "step": 2320
    },
    {
      "epoch": 0.9652029826014913,
      "grad_norm": 2.4131481647491455,
      "learning_rate": 0.00044995906687610626,
      "loss": 0.3666,
      "step": 2330
    },
    {
      "epoch": 0.9693454846727423,
      "grad_norm": 3.4162991046905518,
      "learning_rate": 0.00044975275827139466,
      "loss": 0.2902,
      "step": 2340
    },
    {
      "epoch": 0.9734879867439934,
      "grad_norm": 3.4129366874694824,
      "learning_rate": 0.000449546449666683,
      "loss": 0.3128,
      "step": 2350
    },
    {
      "epoch": 0.9776304888152444,
      "grad_norm": 0.8963351845741272,
      "learning_rate": 0.00044934014106197135,
      "loss": 0.2283,
      "step": 2360
    },
    {
      "epoch": 0.9817729908864954,
      "grad_norm": 0.9074028730392456,
      "learning_rate": 0.0004491338324572597,
      "loss": 0.3542,
      "step": 2370
    },
    {
      "epoch": 0.9859154929577465,
      "grad_norm": 3.2887301445007324,
      "learning_rate": 0.00044892752385254804,
      "loss": 0.3232,
      "step": 2380
    },
    {
      "epoch": 0.9900579950289975,
      "grad_norm": 1.0393855571746826,
      "learning_rate": 0.0004487212152478364,
      "loss": 0.3309,
      "step": 2390
    },
    {
      "epoch": 0.9942004971002486,
      "grad_norm": 2.2640838623046875,
      "learning_rate": 0.00044851490664312473,
      "loss": 0.3041,
      "step": 2400
    },
    {
      "epoch": 0.9983429991714996,
      "grad_norm": 3.7892532348632812,
      "learning_rate": 0.0004483085980384131,
      "loss": 0.3858,
      "step": 2410
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9087282398452611,
      "eval_f1": 0.0,
      "eval_loss": 0.3055426776409149,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 2173.9696,
      "eval_samples_per_second": 3.807,
      "eval_steps_per_second": 0.476,
      "step": 2414
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9087282398452611,
      "eval_f1": 0.0,
      "eval_loss": 0.3055426776409149,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 2048.8957,
      "eval_samples_per_second": 4.04,
      "eval_steps_per_second": 0.505,
      "step": 2414
    }
  ],
  "logging_steps": 10,
  "max_steps": 24140,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 4
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8628426376169280.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": {
    "epochs": 10,
    "gradient_accumulation_steps": 1,
    "learning_rate": 0.0004963578720757561,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 16,
    "warmup_steps": 81,
    "weight_decay": 0.05945018017115814
  }
}
