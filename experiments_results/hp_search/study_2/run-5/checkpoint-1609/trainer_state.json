{
  "best_metric": 0.0,
  "best_model_checkpoint": "../hyperparameter_search/run-5/checkpoint-804",
  "epoch": 1.9995857497928748,
  "eval_steps": 500,
  "global_step": 1609,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0012427506213753107,
      "grad_norm": 33.72175979614258,
      "learning_rate": 1.2174781763577127e-05,
      "loss": 0.6624,
      "step": 1
    },
    {
      "epoch": 0.012427506213753107,
      "grad_norm": 7.164342403411865,
      "learning_rate": 0.00012174781763577127,
      "loss": 0.5688,
      "step": 10
    },
    {
      "epoch": 0.024855012427506214,
      "grad_norm": 19.235063552856445,
      "learning_rate": 0.00024349563527154255,
      "loss": 0.3677,
      "step": 20
    },
    {
      "epoch": 0.037282518641259324,
      "grad_norm": 6.887600898742676,
      "learning_rate": 0.0003652434529073138,
      "loss": 0.3781,
      "step": 30
    },
    {
      "epoch": 0.04971002485501243,
      "grad_norm": 1.9149280786514282,
      "learning_rate": 0.0004869912705430851,
      "loss": 0.3193,
      "step": 40
    },
    {
      "epoch": 0.06213753106876554,
      "grad_norm": 1.3632711172103882,
      "learning_rate": 0.0006087390881788564,
      "loss": 0.3032,
      "step": 50
    },
    {
      "epoch": 0.07456503728251865,
      "grad_norm": 2.089581251144409,
      "learning_rate": 0.0007304869058146276,
      "loss": 0.2632,
      "step": 60
    },
    {
      "epoch": 0.08699254349627175,
      "grad_norm": 3.635807514190674,
      "learning_rate": 0.0007299163912052754,
      "loss": 0.2757,
      "step": 70
    },
    {
      "epoch": 0.09942004971002485,
      "grad_norm": 4.257771968841553,
      "learning_rate": 0.0007293458765959231,
      "loss": 0.3476,
      "step": 80
    },
    {
      "epoch": 0.11184755592377796,
      "grad_norm": 1.1105782985687256,
      "learning_rate": 0.0007287753619865709,
      "loss": 0.2646,
      "step": 90
    },
    {
      "epoch": 0.12427506213753108,
      "grad_norm": 0.314532995223999,
      "learning_rate": 0.0007282048473772186,
      "loss": 0.3051,
      "step": 100
    },
    {
      "epoch": 0.13670256835128416,
      "grad_norm": 2.3254823684692383,
      "learning_rate": 0.0007276343327678663,
      "loss": 0.324,
      "step": 110
    },
    {
      "epoch": 0.1491300745650373,
      "grad_norm": 0.25191494822502136,
      "learning_rate": 0.000727063818158514,
      "loss": 0.3181,
      "step": 120
    },
    {
      "epoch": 0.1615575807787904,
      "grad_norm": 1.9860740900039673,
      "learning_rate": 0.0007264933035491619,
      "loss": 0.2873,
      "step": 130
    },
    {
      "epoch": 0.1739850869925435,
      "grad_norm": 1.1374847888946533,
      "learning_rate": 0.0007259227889398097,
      "loss": 0.2998,
      "step": 140
    },
    {
      "epoch": 0.1864125932062966,
      "grad_norm": 0.8607712984085083,
      "learning_rate": 0.0007253522743304574,
      "loss": 0.2597,
      "step": 150
    },
    {
      "epoch": 0.1988400994200497,
      "grad_norm": 0.5086775422096252,
      "learning_rate": 0.0007247817597211051,
      "loss": 0.3126,
      "step": 160
    },
    {
      "epoch": 0.2112676056338028,
      "grad_norm": 0.17577457427978516,
      "learning_rate": 0.0007242112451117528,
      "loss": 0.3357,
      "step": 170
    },
    {
      "epoch": 0.22369511184755592,
      "grad_norm": 1.962361216545105,
      "learning_rate": 0.0007236407305024007,
      "loss": 0.2431,
      "step": 180
    },
    {
      "epoch": 0.23612261806130902,
      "grad_norm": 2.2654473781585693,
      "learning_rate": 0.0007230702158930484,
      "loss": 0.3454,
      "step": 190
    },
    {
      "epoch": 0.24855012427506215,
      "grad_norm": 0.11510487645864487,
      "learning_rate": 0.0007224997012836961,
      "loss": 0.3182,
      "step": 200
    },
    {
      "epoch": 0.2609776304888152,
      "grad_norm": 0.7312834858894348,
      "learning_rate": 0.0007219291866743438,
      "loss": 0.2614,
      "step": 210
    },
    {
      "epoch": 0.27340513670256833,
      "grad_norm": 0.5844627618789673,
      "learning_rate": 0.0007213586720649915,
      "loss": 0.3456,
      "step": 220
    },
    {
      "epoch": 0.28583264291632143,
      "grad_norm": 0.7835553288459778,
      "learning_rate": 0.0007207881574556393,
      "loss": 0.2485,
      "step": 230
    },
    {
      "epoch": 0.2982601491300746,
      "grad_norm": 1.743537425994873,
      "learning_rate": 0.000720217642846287,
      "loss": 0.363,
      "step": 240
    },
    {
      "epoch": 0.3106876553438277,
      "grad_norm": 2.604090452194214,
      "learning_rate": 0.0007196471282369348,
      "loss": 0.2688,
      "step": 250
    },
    {
      "epoch": 0.3231151615575808,
      "grad_norm": 0.03977619484066963,
      "learning_rate": 0.0007190766136275825,
      "loss": 0.3384,
      "step": 260
    },
    {
      "epoch": 0.3355426677713339,
      "grad_norm": 0.83561110496521,
      "learning_rate": 0.0007185060990182303,
      "loss": 0.3561,
      "step": 270
    },
    {
      "epoch": 0.347970173985087,
      "grad_norm": 2.270402193069458,
      "learning_rate": 0.000717935584408878,
      "loss": 0.3233,
      "step": 280
    },
    {
      "epoch": 0.3603976801988401,
      "grad_norm": 2.1460015773773193,
      "learning_rate": 0.0007173650697995258,
      "loss": 0.3026,
      "step": 290
    },
    {
      "epoch": 0.3728251864125932,
      "grad_norm": 2.1770172119140625,
      "learning_rate": 0.0007167945551901735,
      "loss": 0.3172,
      "step": 300
    },
    {
      "epoch": 0.3852526926263463,
      "grad_norm": 1.8690154552459717,
      "learning_rate": 0.0007162240405808213,
      "loss": 0.3398,
      "step": 310
    },
    {
      "epoch": 0.3976801988400994,
      "grad_norm": 0.1591120809316635,
      "learning_rate": 0.0007156535259714691,
      "loss": 0.297,
      "step": 320
    },
    {
      "epoch": 0.4101077050538525,
      "grad_norm": 1.4033689498901367,
      "learning_rate": 0.0007150830113621168,
      "loss": 0.3778,
      "step": 330
    },
    {
      "epoch": 0.4225352112676056,
      "grad_norm": 3.3980541229248047,
      "learning_rate": 0.0007145124967527645,
      "loss": 0.3118,
      "step": 340
    },
    {
      "epoch": 0.43496271748135873,
      "grad_norm": 0.3333631157875061,
      "learning_rate": 0.0007139419821434122,
      "loss": 0.36,
      "step": 350
    },
    {
      "epoch": 0.44739022369511183,
      "grad_norm": 1.4065353870391846,
      "learning_rate": 0.0007133714675340599,
      "loss": 0.2994,
      "step": 360
    },
    {
      "epoch": 0.45981772990886494,
      "grad_norm": 2.0060882568359375,
      "learning_rate": 0.0007128009529247078,
      "loss": 0.3055,
      "step": 370
    },
    {
      "epoch": 0.47224523612261804,
      "grad_norm": 0.739231526851654,
      "learning_rate": 0.0007122304383153555,
      "loss": 0.3335,
      "step": 380
    },
    {
      "epoch": 0.48467274233637114,
      "grad_norm": 2.0833606719970703,
      "learning_rate": 0.0007116599237060032,
      "loss": 0.3365,
      "step": 390
    },
    {
      "epoch": 0.4971002485501243,
      "grad_norm": 1.0340259075164795,
      "learning_rate": 0.0007110894090966509,
      "loss": 0.2788,
      "step": 400
    },
    {
      "epoch": 0.5095277547638773,
      "grad_norm": 3.563582181930542,
      "learning_rate": 0.0007105188944872987,
      "loss": 0.2825,
      "step": 410
    },
    {
      "epoch": 0.5219552609776305,
      "grad_norm": 0.944507896900177,
      "learning_rate": 0.0007099483798779464,
      "loss": 1.0257,
      "step": 420
    },
    {
      "epoch": 0.5343827671913836,
      "grad_norm": 3.9954442977905273,
      "learning_rate": 0.0007093778652685942,
      "loss": 0.3542,
      "step": 430
    },
    {
      "epoch": 0.5468102734051367,
      "grad_norm": 1.1713615655899048,
      "learning_rate": 0.000708807350659242,
      "loss": 0.2545,
      "step": 440
    },
    {
      "epoch": 0.5592377796188898,
      "grad_norm": 0.31594881415367126,
      "learning_rate": 0.0007082368360498897,
      "loss": 0.2784,
      "step": 450
    },
    {
      "epoch": 0.5716652858326429,
      "grad_norm": 3.115830421447754,
      "learning_rate": 0.0007076663214405375,
      "loss": 0.2925,
      "step": 460
    },
    {
      "epoch": 0.584092792046396,
      "grad_norm": 1.7890801429748535,
      "learning_rate": 0.0007070958068311852,
      "loss": 0.3179,
      "step": 470
    },
    {
      "epoch": 0.5965202982601492,
      "grad_norm": 1.8556365966796875,
      "learning_rate": 0.0007065252922218329,
      "loss": 0.3379,
      "step": 480
    },
    {
      "epoch": 0.6089478044739023,
      "grad_norm": 4.457969665527344,
      "learning_rate": 0.0007059547776124807,
      "loss": 0.3255,
      "step": 490
    },
    {
      "epoch": 0.6213753106876554,
      "grad_norm": 1.229552149772644,
      "learning_rate": 0.0007053842630031285,
      "loss": 0.3037,
      "step": 500
    },
    {
      "epoch": 0.6338028169014085,
      "grad_norm": 4.116261005401611,
      "learning_rate": 0.0007048137483937762,
      "loss": 0.3154,
      "step": 510
    },
    {
      "epoch": 0.6462303231151616,
      "grad_norm": 4.9831132888793945,
      "learning_rate": 0.0007042432337844239,
      "loss": 0.2675,
      "step": 520
    },
    {
      "epoch": 0.6586578293289147,
      "grad_norm": 5.1773505210876465,
      "learning_rate": 0.0007036727191750716,
      "loss": 0.3143,
      "step": 530
    },
    {
      "epoch": 0.6710853355426678,
      "grad_norm": 5.092060565948486,
      "learning_rate": 0.0007031022045657193,
      "loss": 0.345,
      "step": 540
    },
    {
      "epoch": 0.6835128417564209,
      "grad_norm": 2.151900291442871,
      "learning_rate": 0.0007025316899563672,
      "loss": 0.2933,
      "step": 550
    },
    {
      "epoch": 0.695940347970174,
      "grad_norm": 2.4153223037719727,
      "learning_rate": 0.0007019611753470149,
      "loss": 0.281,
      "step": 560
    },
    {
      "epoch": 0.7083678541839271,
      "grad_norm": 2.8735218048095703,
      "learning_rate": 0.0007013906607376626,
      "loss": 0.2685,
      "step": 570
    },
    {
      "epoch": 0.7207953603976802,
      "grad_norm": 5.915097236633301,
      "learning_rate": 0.0007008201461283103,
      "loss": 0.3074,
      "step": 580
    },
    {
      "epoch": 0.7332228666114333,
      "grad_norm": 2.4347870349884033,
      "learning_rate": 0.0007002496315189581,
      "loss": 0.3385,
      "step": 590
    },
    {
      "epoch": 0.7456503728251864,
      "grad_norm": 1.6909273862838745,
      "learning_rate": 0.0006996791169096059,
      "loss": 0.3341,
      "step": 600
    },
    {
      "epoch": 0.7580778790389395,
      "grad_norm": 1.3473763465881348,
      "learning_rate": 0.0006991086023002537,
      "loss": 0.294,
      "step": 610
    },
    {
      "epoch": 0.7705053852526926,
      "grad_norm": 1.7401463985443115,
      "learning_rate": 0.0006985380876909014,
      "loss": 0.3288,
      "step": 620
    },
    {
      "epoch": 0.7829328914664457,
      "grad_norm": 0.25416478514671326,
      "learning_rate": 0.0006979675730815491,
      "loss": 0.2986,
      "step": 630
    },
    {
      "epoch": 0.7953603976801988,
      "grad_norm": 0.8959341645240784,
      "learning_rate": 0.0006973970584721969,
      "loss": 0.3202,
      "step": 640
    },
    {
      "epoch": 0.8077879038939519,
      "grad_norm": 1.414750337600708,
      "learning_rate": 0.0006968265438628446,
      "loss": 0.3386,
      "step": 650
    },
    {
      "epoch": 0.820215410107705,
      "grad_norm": 1.1490206718444824,
      "learning_rate": 0.0006962560292534923,
      "loss": 0.2962,
      "step": 660
    },
    {
      "epoch": 0.8326429163214581,
      "grad_norm": 0.25281989574432373,
      "learning_rate": 0.00069568551464414,
      "loss": 0.2584,
      "step": 670
    },
    {
      "epoch": 0.8450704225352113,
      "grad_norm": 2.0413739681243896,
      "learning_rate": 0.0006951150000347878,
      "loss": 0.281,
      "step": 680
    },
    {
      "epoch": 0.8574979287489644,
      "grad_norm": 1.4081639051437378,
      "learning_rate": 0.0006945444854254356,
      "loss": 0.2976,
      "step": 690
    },
    {
      "epoch": 0.8699254349627175,
      "grad_norm": 0.6284672617912292,
      "learning_rate": 0.0006939739708160833,
      "loss": 0.3158,
      "step": 700
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 3.811107873916626,
      "learning_rate": 0.000693403456206731,
      "loss": 0.3573,
      "step": 710
    },
    {
      "epoch": 0.8947804473902237,
      "grad_norm": 3.233869791030884,
      "learning_rate": 0.0006928329415973787,
      "loss": 0.3332,
      "step": 720
    },
    {
      "epoch": 0.9072079536039768,
      "grad_norm": 1.823691487312317,
      "learning_rate": 0.0006922624269880266,
      "loss": 0.2935,
      "step": 730
    },
    {
      "epoch": 0.9196354598177299,
      "grad_norm": 0.9380178451538086,
      "learning_rate": 0.0006916919123786743,
      "loss": 0.2834,
      "step": 740
    },
    {
      "epoch": 0.932062966031483,
      "grad_norm": 2.611150026321411,
      "learning_rate": 0.0006911213977693221,
      "loss": 0.2659,
      "step": 750
    },
    {
      "epoch": 0.9444904722452361,
      "grad_norm": 2.7922370433807373,
      "learning_rate": 0.0006905508831599698,
      "loss": 0.2855,
      "step": 760
    },
    {
      "epoch": 0.9569179784589892,
      "grad_norm": 1.8075206279754639,
      "learning_rate": 0.0006899803685506175,
      "loss": 0.2485,
      "step": 770
    },
    {
      "epoch": 0.9693454846727423,
      "grad_norm": 3.8821702003479004,
      "learning_rate": 0.0006894098539412653,
      "loss": 0.3283,
      "step": 780
    },
    {
      "epoch": 0.9817729908864954,
      "grad_norm": 1.6006709337234497,
      "learning_rate": 0.0006888393393319131,
      "loss": 0.277,
      "step": 790
    },
    {
      "epoch": 0.9942004971002486,
      "grad_norm": 0.9020209908485413,
      "learning_rate": 0.0006882688247225608,
      "loss": 0.319,
      "step": 800
    },
    {
      "epoch": 0.9991714995857498,
      "eval_accuracy": 0.9087282398452611,
      "eval_f1": 0.0,
      "eval_loss": 0.30577200651168823,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 2064.6601,
      "eval_samples_per_second": 4.009,
      "eval_steps_per_second": 0.501,
      "step": 804
    },
    {
      "epoch": 0.9991714995857498,
      "eval_accuracy": 0.9087282398452611,
      "eval_f1": 0.0,
      "eval_loss": 0.30577200651168823,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 2088.7121,
      "eval_samples_per_second": 3.963,
      "eval_steps_per_second": 0.496,
      "step": 804
    },
    {
      "epoch": 1.0066280033140016,
      "grad_norm": 2.711016893386841,
      "learning_rate": 0.0006876983101132085,
      "loss": 0.3225,
      "step": 810
    },
    {
      "epoch": 1.0190555095277547,
      "grad_norm": 1.3230726718902588,
      "learning_rate": 0.0006871277955038562,
      "loss": 0.3131,
      "step": 820
    },
    {
      "epoch": 1.0314830157415078,
      "grad_norm": 0.9327141046524048,
      "learning_rate": 0.000686557280894504,
      "loss": 0.3171,
      "step": 830
    },
    {
      "epoch": 1.043910521955261,
      "grad_norm": 4.481544017791748,
      "learning_rate": 0.0006859867662851517,
      "loss": 0.285,
      "step": 840
    },
    {
      "epoch": 1.056338028169014,
      "grad_norm": 0.7889583110809326,
      "learning_rate": 0.0006854162516757994,
      "loss": 0.312,
      "step": 850
    },
    {
      "epoch": 1.0687655343827671,
      "grad_norm": 3.6668460369110107,
      "learning_rate": 0.0006848457370664472,
      "loss": 0.2476,
      "step": 860
    },
    {
      "epoch": 1.0811930405965202,
      "grad_norm": 5.071972846984863,
      "learning_rate": 0.000684275222457095,
      "loss": 0.3114,
      "step": 870
    },
    {
      "epoch": 1.0936205468102733,
      "grad_norm": 3.034726142883301,
      "learning_rate": 0.0006837047078477427,
      "loss": 0.3235,
      "step": 880
    },
    {
      "epoch": 1.1060480530240264,
      "grad_norm": 1.4281569719314575,
      "learning_rate": 0.0006831341932383904,
      "loss": 0.3316,
      "step": 890
    },
    {
      "epoch": 1.1184755592377795,
      "grad_norm": 1.0780892372131348,
      "learning_rate": 0.0006825636786290382,
      "loss": 0.289,
      "step": 900
    },
    {
      "epoch": 1.1309030654515326,
      "grad_norm": 1.6543601751327515,
      "learning_rate": 0.000681993164019686,
      "loss": 0.3132,
      "step": 910
    },
    {
      "epoch": 1.143330571665286,
      "grad_norm": 5.568000793457031,
      "learning_rate": 0.0006814226494103338,
      "loss": 0.3385,
      "step": 920
    },
    {
      "epoch": 1.1557580778790388,
      "grad_norm": 1.2555075883865356,
      "learning_rate": 0.0006808521348009815,
      "loss": 0.2742,
      "step": 930
    },
    {
      "epoch": 1.1681855840927922,
      "grad_norm": 2.503323793411255,
      "learning_rate": 0.0006802816201916292,
      "loss": 0.2391,
      "step": 940
    },
    {
      "epoch": 1.180613090306545,
      "grad_norm": 0.27738577127456665,
      "learning_rate": 0.0006797111055822769,
      "loss": 0.3109,
      "step": 950
    },
    {
      "epoch": 1.1930405965202984,
      "grad_norm": 0.15021131932735443,
      "learning_rate": 0.0006791405909729246,
      "loss": 0.2876,
      "step": 960
    },
    {
      "epoch": 1.2054681027340513,
      "grad_norm": 2.1637206077575684,
      "learning_rate": 0.0006785700763635725,
      "loss": 0.3468,
      "step": 970
    },
    {
      "epoch": 1.2178956089478046,
      "grad_norm": 0.7033995985984802,
      "learning_rate": 0.0006779995617542202,
      "loss": 0.2733,
      "step": 980
    },
    {
      "epoch": 1.2303231151615575,
      "grad_norm": 8.0324068069458,
      "learning_rate": 0.0006774290471448679,
      "loss": 0.3786,
      "step": 990
    },
    {
      "epoch": 1.2427506213753108,
      "grad_norm": 1.3269145488739014,
      "learning_rate": 0.0006768585325355156,
      "loss": 0.3227,
      "step": 1000
    },
    {
      "epoch": 1.2551781275890637,
      "grad_norm": 2.3805973529815674,
      "learning_rate": 0.0006762880179261634,
      "loss": 0.3502,
      "step": 1010
    },
    {
      "epoch": 1.267605633802817,
      "grad_norm": 4.030162811279297,
      "learning_rate": 0.0006757175033168111,
      "loss": 0.3344,
      "step": 1020
    },
    {
      "epoch": 1.2800331400165699,
      "grad_norm": 2.201329231262207,
      "learning_rate": 0.0006751469887074588,
      "loss": 0.3048,
      "step": 1030
    },
    {
      "epoch": 1.2924606462303232,
      "grad_norm": 2.7247612476348877,
      "learning_rate": 0.0006745764740981066,
      "loss": 0.3851,
      "step": 1040
    },
    {
      "epoch": 1.3048881524440763,
      "grad_norm": 3.737510919570923,
      "learning_rate": 0.0006740059594887544,
      "loss": 0.3063,
      "step": 1050
    },
    {
      "epoch": 1.3173156586578294,
      "grad_norm": 1.1362271308898926,
      "learning_rate": 0.0006734354448794022,
      "loss": 0.2871,
      "step": 1060
    },
    {
      "epoch": 1.3297431648715825,
      "grad_norm": 0.41617247462272644,
      "learning_rate": 0.0006728649302700499,
      "loss": 0.3483,
      "step": 1070
    },
    {
      "epoch": 1.3421706710853356,
      "grad_norm": 2.955108165740967,
      "learning_rate": 0.0006722944156606976,
      "loss": 0.3179,
      "step": 1080
    },
    {
      "epoch": 1.3545981772990887,
      "grad_norm": 0.9526714086532593,
      "learning_rate": 0.0006717239010513453,
      "loss": 0.4044,
      "step": 1090
    },
    {
      "epoch": 1.3670256835128418,
      "grad_norm": 3.340233325958252,
      "learning_rate": 0.0006711533864419931,
      "loss": 0.3433,
      "step": 1100
    },
    {
      "epoch": 1.379453189726595,
      "grad_norm": 3.2819249629974365,
      "learning_rate": 0.0006705828718326409,
      "loss": 0.3106,
      "step": 1110
    },
    {
      "epoch": 1.391880695940348,
      "grad_norm": 0.07752171158790588,
      "learning_rate": 0.0006700123572232886,
      "loss": 0.301,
      "step": 1120
    },
    {
      "epoch": 1.4043082021541011,
      "grad_norm": 2.5354487895965576,
      "learning_rate": 0.0006694418426139363,
      "loss": 0.3288,
      "step": 1130
    },
    {
      "epoch": 1.4167357083678542,
      "grad_norm": 0.014710115268826485,
      "learning_rate": 0.000668871328004584,
      "loss": 0.2949,
      "step": 1140
    },
    {
      "epoch": 1.4291632145816073,
      "grad_norm": 5.18403434753418,
      "learning_rate": 0.0006683008133952318,
      "loss": 0.2966,
      "step": 1150
    },
    {
      "epoch": 1.4415907207953604,
      "grad_norm": 2.2668309211730957,
      "learning_rate": 0.0006677302987858796,
      "loss": 0.3093,
      "step": 1160
    },
    {
      "epoch": 1.4540182270091135,
      "grad_norm": 1.9731436967849731,
      "learning_rate": 0.0006671597841765273,
      "loss": 0.3576,
      "step": 1170
    },
    {
      "epoch": 1.4664457332228666,
      "grad_norm": 0.2012042999267578,
      "learning_rate": 0.000666589269567175,
      "loss": 0.2728,
      "step": 1180
    },
    {
      "epoch": 1.4788732394366197,
      "grad_norm": 2.087757110595703,
      "learning_rate": 0.0006660187549578228,
      "loss": 0.2924,
      "step": 1190
    },
    {
      "epoch": 1.4913007456503728,
      "grad_norm": 2.1023266315460205,
      "learning_rate": 0.0006654482403484706,
      "loss": 0.346,
      "step": 1200
    },
    {
      "epoch": 1.503728251864126,
      "grad_norm": 2.0855956077575684,
      "learning_rate": 0.0006648777257391183,
      "loss": 0.2668,
      "step": 1210
    },
    {
      "epoch": 1.516155758077879,
      "grad_norm": 2.923609972000122,
      "learning_rate": 0.0006643072111297661,
      "loss": 0.3093,
      "step": 1220
    },
    {
      "epoch": 1.5285832642916322,
      "grad_norm": 3.561081647872925,
      "learning_rate": 0.0006637366965204138,
      "loss": 0.3582,
      "step": 1230
    },
    {
      "epoch": 1.5410107705053853,
      "grad_norm": 2.603153944015503,
      "learning_rate": 0.0006631661819110616,
      "loss": 0.4083,
      "step": 1240
    },
    {
      "epoch": 1.5534382767191384,
      "grad_norm": 1.832810640335083,
      "learning_rate": 0.0006625956673017093,
      "loss": 0.2997,
      "step": 1250
    },
    {
      "epoch": 1.5658657829328915,
      "grad_norm": 0.47759905457496643,
      "learning_rate": 0.000662025152692357,
      "loss": 0.3618,
      "step": 1260
    },
    {
      "epoch": 1.5782932891466446,
      "grad_norm": 2.2006523609161377,
      "learning_rate": 0.0006614546380830047,
      "loss": 0.3501,
      "step": 1270
    },
    {
      "epoch": 1.5907207953603977,
      "grad_norm": 1.4557031393051147,
      "learning_rate": 0.0006608841234736525,
      "loss": 0.25,
      "step": 1280
    },
    {
      "epoch": 1.6031483015741508,
      "grad_norm": 0.5316895246505737,
      "learning_rate": 0.0006603136088643003,
      "loss": 0.2762,
      "step": 1290
    },
    {
      "epoch": 1.6155758077879039,
      "grad_norm": 1.133231282234192,
      "learning_rate": 0.000659743094254948,
      "loss": 0.3416,
      "step": 1300
    },
    {
      "epoch": 1.628003314001657,
      "grad_norm": 0.027973219752311707,
      "learning_rate": 0.0006591725796455957,
      "loss": 0.2775,
      "step": 1310
    },
    {
      "epoch": 1.64043082021541,
      "grad_norm": 4.279878616333008,
      "learning_rate": 0.0006586020650362434,
      "loss": 0.3115,
      "step": 1320
    },
    {
      "epoch": 1.6528583264291632,
      "grad_norm": 1.6756935119628906,
      "learning_rate": 0.0006580315504268912,
      "loss": 0.279,
      "step": 1330
    },
    {
      "epoch": 1.6652858326429163,
      "grad_norm": 1.4637500047683716,
      "learning_rate": 0.000657461035817539,
      "loss": 0.3152,
      "step": 1340
    },
    {
      "epoch": 1.6777133388566694,
      "grad_norm": 0.7565745115280151,
      "learning_rate": 0.0006568905212081868,
      "loss": 0.3315,
      "step": 1350
    },
    {
      "epoch": 1.6901408450704225,
      "grad_norm": 5.069314956665039,
      "learning_rate": 0.0006563200065988345,
      "loss": 0.3427,
      "step": 1360
    },
    {
      "epoch": 1.7025683512841756,
      "grad_norm": 4.003355979919434,
      "learning_rate": 0.0006557494919894822,
      "loss": 0.2787,
      "step": 1370
    },
    {
      "epoch": 1.7149958574979287,
      "grad_norm": 3.6167385578155518,
      "learning_rate": 0.00065517897738013,
      "loss": 0.2463,
      "step": 1380
    },
    {
      "epoch": 1.7274233637116818,
      "grad_norm": 0.7050014138221741,
      "learning_rate": 0.0006546084627707777,
      "loss": 0.306,
      "step": 1390
    },
    {
      "epoch": 1.739850869925435,
      "grad_norm": 0.5741730332374573,
      "learning_rate": 0.0006540379481614255,
      "loss": 0.289,
      "step": 1400
    },
    {
      "epoch": 1.752278376139188,
      "grad_norm": 4.112014293670654,
      "learning_rate": 0.0006534674335520732,
      "loss": 0.3815,
      "step": 1410
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.8790743947029114,
      "learning_rate": 0.0006528969189427209,
      "loss": 0.3589,
      "step": 1420
    },
    {
      "epoch": 1.7771333885666944,
      "grad_norm": 0.24673889577388763,
      "learning_rate": 0.0006523264043333687,
      "loss": 0.3147,
      "step": 1430
    },
    {
      "epoch": 1.7895608947804473,
      "grad_norm": 0.36695367097854614,
      "learning_rate": 0.0006517558897240164,
      "loss": 0.2692,
      "step": 1440
    },
    {
      "epoch": 1.8019884009942007,
      "grad_norm": 1.9902877807617188,
      "learning_rate": 0.0006511853751146641,
      "loss": 0.3082,
      "step": 1450
    },
    {
      "epoch": 1.8144159072079535,
      "grad_norm": 0.968788743019104,
      "learning_rate": 0.0006506148605053119,
      "loss": 0.315,
      "step": 1460
    },
    {
      "epoch": 1.8268434134217069,
      "grad_norm": 0.8364377021789551,
      "learning_rate": 0.0006500443458959597,
      "loss": 0.2377,
      "step": 1470
    },
    {
      "epoch": 1.8392709196354597,
      "grad_norm": 3.1981453895568848,
      "learning_rate": 0.0006494738312866074,
      "loss": 0.3444,
      "step": 1480
    },
    {
      "epoch": 1.851698425849213,
      "grad_norm": 2.1453258991241455,
      "learning_rate": 0.0006489033166772551,
      "loss": 0.2546,
      "step": 1490
    },
    {
      "epoch": 1.864125932062966,
      "grad_norm": 5.308783531188965,
      "learning_rate": 0.0006483328020679028,
      "loss": 0.3102,
      "step": 1500
    },
    {
      "epoch": 1.8765534382767193,
      "grad_norm": 0.165663480758667,
      "learning_rate": 0.0006477622874585506,
      "loss": 0.274,
      "step": 1510
    },
    {
      "epoch": 1.8889809444904722,
      "grad_norm": 3.3708672523498535,
      "learning_rate": 0.0006471917728491985,
      "loss": 0.2817,
      "step": 1520
    },
    {
      "epoch": 1.9014084507042255,
      "grad_norm": 4.713986396789551,
      "learning_rate": 0.0006466212582398462,
      "loss": 0.2533,
      "step": 1530
    },
    {
      "epoch": 1.9138359569179784,
      "grad_norm": 1.1271986961364746,
      "learning_rate": 0.0006460507436304939,
      "loss": 0.2745,
      "step": 1540
    },
    {
      "epoch": 1.9262634631317317,
      "grad_norm": 2.4745476245880127,
      "learning_rate": 0.0006454802290211416,
      "loss": 0.2701,
      "step": 1550
    },
    {
      "epoch": 1.9386909693454846,
      "grad_norm": 0.5909184813499451,
      "learning_rate": 0.0006449097144117893,
      "loss": 0.2955,
      "step": 1560
    },
    {
      "epoch": 1.951118475559238,
      "grad_norm": 0.5415320992469788,
      "learning_rate": 0.0006443391998024371,
      "loss": 0.2963,
      "step": 1570
    },
    {
      "epoch": 1.9635459817729908,
      "grad_norm": 0.2900345027446747,
      "learning_rate": 0.0006437686851930849,
      "loss": 0.3348,
      "step": 1580
    },
    {
      "epoch": 1.975973487986744,
      "grad_norm": 0.888300895690918,
      "learning_rate": 0.0006431981705837326,
      "loss": 0.2615,
      "step": 1590
    },
    {
      "epoch": 1.988400994200497,
      "grad_norm": 1.829491138458252,
      "learning_rate": 0.0006426276559743803,
      "loss": 0.3169,
      "step": 1600
    },
    {
      "epoch": 1.9995857497928748,
      "eval_accuracy": 0.9087282398452611,
      "eval_f1": 0.0,
      "eval_loss": 0.32398784160614014,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 5392.9084,
      "eval_samples_per_second": 1.535,
      "eval_steps_per_second": 0.192,
      "step": 1609
    },
    {
      "epoch": 1.9995857497928748,
      "eval_accuracy": 0.9087282398452611,
      "eval_f1": 0.0,
      "eval_loss": 0.32398784160614014,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 4036.8893,
      "eval_samples_per_second": 2.05,
      "eval_steps_per_second": 0.256,
      "step": 1609
    }
  ],
  "logging_steps": 10,
  "max_steps": 12864,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 16,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 4
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.708545348086976e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": {
    "epochs": 16,
    "gradient_accumulation_steps": 6,
    "learning_rate": 0.0007304869058146276,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 8,
    "warmup_steps": 60,
    "weight_decay": 0.061241089805531716
  }
}
