{
  "best_metric": 0.9617706237424548,
  "best_model_checkpoint": "../hyperparameter_search/run-6/checkpoint-1608",
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 1608,
  "is_hyper_param_search": true,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004975124378109453,
      "grad_norm": 24.14982032775879,
      "learning_rate": 1.149586875533118e-07,
      "loss": 0.8414,
      "step": 1
    },
    {
      "epoch": 0.04975124378109453,
      "grad_norm": 28.058555603027344,
      "learning_rate": 1.149586875533118e-06,
      "loss": 0.7974,
      "step": 10
    },
    {
      "epoch": 0.09950248756218906,
      "grad_norm": 14.436946868896484,
      "learning_rate": 2.299173751066236e-06,
      "loss": 0.5953,
      "step": 20
    },
    {
      "epoch": 0.14925373134328357,
      "grad_norm": 9.764202117919922,
      "learning_rate": 3.4487606265993538e-06,
      "loss": 0.3833,
      "step": 30
    },
    {
      "epoch": 0.19900497512437812,
      "grad_norm": 5.967156887054443,
      "learning_rate": 4.598347502132472e-06,
      "loss": 0.338,
      "step": 40
    },
    {
      "epoch": 0.24875621890547264,
      "grad_norm": 9.732102394104004,
      "learning_rate": 5.74793437766559e-06,
      "loss": 0.3551,
      "step": 50
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 8.920114517211914,
      "learning_rate": 6.8975212531987075e-06,
      "loss": 0.3133,
      "step": 60
    },
    {
      "epoch": 0.3482587064676617,
      "grad_norm": 7.336696624755859,
      "learning_rate": 8.047108128731827e-06,
      "loss": 0.3332,
      "step": 70
    },
    {
      "epoch": 0.39800995024875624,
      "grad_norm": 12.070537567138672,
      "learning_rate": 9.196695004264944e-06,
      "loss": 0.3176,
      "step": 80
    },
    {
      "epoch": 0.44776119402985076,
      "grad_norm": 7.147818565368652,
      "learning_rate": 1.0346281879798063e-05,
      "loss": 0.3098,
      "step": 90
    },
    {
      "epoch": 0.4975124378109453,
      "grad_norm": 8.477709770202637,
      "learning_rate": 1.149586875533118e-05,
      "loss": 0.2868,
      "step": 100
    },
    {
      "epoch": 0.5472636815920398,
      "grad_norm": 6.075718402862549,
      "learning_rate": 1.2645455630864298e-05,
      "loss": 0.27,
      "step": 110
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 7.191989421844482,
      "learning_rate": 1.3795042506397415e-05,
      "loss": 0.2743,
      "step": 120
    },
    {
      "epoch": 0.6467661691542289,
      "grad_norm": 142.96836853027344,
      "learning_rate": 1.4944629381930534e-05,
      "loss": 0.2548,
      "step": 130
    },
    {
      "epoch": 0.6965174129353234,
      "grad_norm": 4.050400257110596,
      "learning_rate": 1.6094216257463653e-05,
      "loss": 0.237,
      "step": 140
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 6.7736406326293945,
      "learning_rate": 1.7243803132996767e-05,
      "loss": 0.2429,
      "step": 150
    },
    {
      "epoch": 0.7960199004975125,
      "grad_norm": 5.3459153175354,
      "learning_rate": 1.8393390008529888e-05,
      "loss": 0.226,
      "step": 160
    },
    {
      "epoch": 0.845771144278607,
      "grad_norm": 5.160364151000977,
      "learning_rate": 1.9542976884063005e-05,
      "loss": 0.1881,
      "step": 170
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 7.931015491485596,
      "learning_rate": 2.0692563759596126e-05,
      "loss": 0.2174,
      "step": 180
    },
    {
      "epoch": 0.945273631840796,
      "grad_norm": 3.4669365882873535,
      "learning_rate": 2.1842150635129243e-05,
      "loss": 0.1746,
      "step": 190
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 4.133074760437012,
      "learning_rate": 2.299173751066236e-05,
      "loss": 0.178,
      "step": 200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9393133462282398,
      "eval_f1": 0.5290806754221389,
      "eval_loss": 0.1634191870689392,
      "eval_precision": 0.9067524115755627,
      "eval_recall": 0.37350993377483444,
      "eval_runtime": 5340.7539,
      "eval_samples_per_second": 1.55,
      "eval_steps_per_second": 0.194,
      "step": 201
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9393133462282398,
      "eval_f1": 0.5290806754221389,
      "eval_loss": 0.1634191870689392,
      "eval_precision": 0.9067524115755627,
      "eval_recall": 0.37350993377483444,
      "eval_runtime": 3005.791,
      "eval_samples_per_second": 2.754,
      "eval_steps_per_second": 0.344,
      "step": 201
    },
    {
      "epoch": 1.044776119402985,
      "grad_norm": 4.0131916999816895,
      "learning_rate": 2.4141324386195478e-05,
      "loss": 0.1712,
      "step": 210
    },
    {
      "epoch": 1.0945273631840795,
      "grad_norm": 6.2424635887146,
      "learning_rate": 2.5290911261728595e-05,
      "loss": 0.1377,
      "step": 220
    },
    {
      "epoch": 1.144278606965174,
      "grad_norm": 6.939559459686279,
      "learning_rate": 2.6440498137261713e-05,
      "loss": 0.1516,
      "step": 230
    },
    {
      "epoch": 1.1940298507462686,
      "grad_norm": 4.6727800369262695,
      "learning_rate": 2.759008501279483e-05,
      "loss": 0.1283,
      "step": 240
    },
    {
      "epoch": 1.243781094527363,
      "grad_norm": 3.8942015171051025,
      "learning_rate": 2.8739671888327947e-05,
      "loss": 0.1478,
      "step": 250
    },
    {
      "epoch": 1.2935323383084576,
      "grad_norm": 3.6271109580993652,
      "learning_rate": 2.9889258763861068e-05,
      "loss": 0.1284,
      "step": 260
    },
    {
      "epoch": 1.3432835820895521,
      "grad_norm": 2.250411033630371,
      "learning_rate": 3.1038845639394186e-05,
      "loss": 0.1114,
      "step": 270
    },
    {
      "epoch": 1.3930348258706466,
      "grad_norm": 9.169798851013184,
      "learning_rate": 3.2188432514927306e-05,
      "loss": 0.1127,
      "step": 280
    },
    {
      "epoch": 1.4427860696517412,
      "grad_norm": 2.728847026824951,
      "learning_rate": 3.333801939046042e-05,
      "loss": 0.1097,
      "step": 290
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 3.8409972190856934,
      "learning_rate": 3.3323315372284995e-05,
      "loss": 0.1108,
      "step": 300
    },
    {
      "epoch": 1.5422885572139302,
      "grad_norm": 2.7290420532226562,
      "learning_rate": 3.317924569925307e-05,
      "loss": 0.1059,
      "step": 310
    },
    {
      "epoch": 1.5920398009950247,
      "grad_norm": 2.652850389480591,
      "learning_rate": 3.3035176026221144e-05,
      "loss": 0.081,
      "step": 320
    },
    {
      "epoch": 1.6417910447761193,
      "grad_norm": 3.1502089500427246,
      "learning_rate": 3.2891106353189216e-05,
      "loss": 0.0768,
      "step": 330
    },
    {
      "epoch": 1.6915422885572138,
      "grad_norm": 2.763331651687622,
      "learning_rate": 3.274703668015728e-05,
      "loss": 0.0901,
      "step": 340
    },
    {
      "epoch": 1.7412935323383083,
      "grad_norm": 3.148879289627075,
      "learning_rate": 3.260296700712535e-05,
      "loss": 0.1094,
      "step": 350
    },
    {
      "epoch": 1.7910447761194028,
      "grad_norm": 2.6671640872955322,
      "learning_rate": 3.245889733409343e-05,
      "loss": 0.09,
      "step": 360
    },
    {
      "epoch": 1.8407960199004973,
      "grad_norm": 3.319524049758911,
      "learning_rate": 3.23148276610615e-05,
      "loss": 0.071,
      "step": 370
    },
    {
      "epoch": 1.890547263681592,
      "grad_norm": 1.2393790483474731,
      "learning_rate": 3.217075798802957e-05,
      "loss": 0.0565,
      "step": 380
    },
    {
      "epoch": 1.9402985074626866,
      "grad_norm": 3.3653719425201416,
      "learning_rate": 3.2026688314997645e-05,
      "loss": 0.0634,
      "step": 390
    },
    {
      "epoch": 1.9900497512437811,
      "grad_norm": 2.755777597427368,
      "learning_rate": 3.1882618641965716e-05,
      "loss": 0.0817,
      "step": 400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9792069632495164,
      "eval_f1": 0.8759018759018758,
      "eval_loss": 0.05517563596367836,
      "eval_precision": 0.9619651347068146,
      "eval_recall": 0.8039735099337748,
      "eval_runtime": 1994.548,
      "eval_samples_per_second": 4.15,
      "eval_steps_per_second": 0.519,
      "step": 402
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9792069632495164,
      "eval_f1": 0.8759018759018758,
      "eval_loss": 0.05517563596367836,
      "eval_precision": 0.9619651347068146,
      "eval_recall": 0.8039735099337748,
      "eval_runtime": 2018.5735,
      "eval_samples_per_second": 4.1,
      "eval_steps_per_second": 0.513,
      "step": 402
    },
    {
      "epoch": 2.0398009950248754,
      "grad_norm": 2.3855319023132324,
      "learning_rate": 3.173854896893379e-05,
      "loss": 0.0668,
      "step": 410
    },
    {
      "epoch": 2.08955223880597,
      "grad_norm": 3.088740587234497,
      "learning_rate": 3.159447929590186e-05,
      "loss": 0.03,
      "step": 420
    },
    {
      "epoch": 2.1393034825870645,
      "grad_norm": 2.055893898010254,
      "learning_rate": 3.145040962286993e-05,
      "loss": 0.035,
      "step": 430
    },
    {
      "epoch": 2.189054726368159,
      "grad_norm": 1.7691861391067505,
      "learning_rate": 3.1306339949838e-05,
      "loss": 0.0548,
      "step": 440
    },
    {
      "epoch": 2.2388059701492535,
      "grad_norm": 2.0170135498046875,
      "learning_rate": 3.1162270276806074e-05,
      "loss": 0.048,
      "step": 450
    },
    {
      "epoch": 2.288557213930348,
      "grad_norm": 2.5269699096679688,
      "learning_rate": 3.1018200603774145e-05,
      "loss": 0.041,
      "step": 460
    },
    {
      "epoch": 2.3383084577114426,
      "grad_norm": 1.8312097787857056,
      "learning_rate": 3.087413093074222e-05,
      "loss": 0.0445,
      "step": 470
    },
    {
      "epoch": 2.388059701492537,
      "grad_norm": 2.3619728088378906,
      "learning_rate": 3.073006125771029e-05,
      "loss": 0.0384,
      "step": 480
    },
    {
      "epoch": 2.4378109452736316,
      "grad_norm": 1.3280844688415527,
      "learning_rate": 3.058599158467836e-05,
      "loss": 0.0324,
      "step": 490
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 0.7836816310882568,
      "learning_rate": 3.0441921911646435e-05,
      "loss": 0.0382,
      "step": 500
    },
    {
      "epoch": 2.5373134328358207,
      "grad_norm": 1.651808261871338,
      "learning_rate": 3.0297852238614506e-05,
      "loss": 0.0601,
      "step": 510
    },
    {
      "epoch": 2.587064676616915,
      "grad_norm": 1.440833330154419,
      "learning_rate": 3.0153782565582578e-05,
      "loss": 0.0358,
      "step": 520
    },
    {
      "epoch": 2.6368159203980097,
      "grad_norm": 0.5506914854049683,
      "learning_rate": 3.000971289255065e-05,
      "loss": 0.0343,
      "step": 530
    },
    {
      "epoch": 2.6865671641791042,
      "grad_norm": 2.1820943355560303,
      "learning_rate": 2.9865643219518717e-05,
      "loss": 0.0414,
      "step": 540
    },
    {
      "epoch": 2.7363184079601988,
      "grad_norm": 2.191584587097168,
      "learning_rate": 2.9721573546486792e-05,
      "loss": 0.0382,
      "step": 550
    },
    {
      "epoch": 2.7860696517412933,
      "grad_norm": 2.334157943725586,
      "learning_rate": 2.9577503873454864e-05,
      "loss": 0.0367,
      "step": 560
    },
    {
      "epoch": 2.835820895522388,
      "grad_norm": 1.8425511121749878,
      "learning_rate": 2.9433434200422935e-05,
      "loss": 0.052,
      "step": 570
    },
    {
      "epoch": 2.8855721393034823,
      "grad_norm": 1.9396051168441772,
      "learning_rate": 2.9289364527391007e-05,
      "loss": 0.047,
      "step": 580
    },
    {
      "epoch": 2.935323383084577,
      "grad_norm": 1.9974586963653564,
      "learning_rate": 2.914529485435908e-05,
      "loss": 0.0385,
      "step": 590
    },
    {
      "epoch": 2.9850746268656714,
      "grad_norm": 1.202386736869812,
      "learning_rate": 2.900122518132715e-05,
      "loss": 0.0285,
      "step": 600
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9885154738878144,
      "eval_f1": 0.9344375431331953,
      "eval_loss": 0.03386571258306503,
      "eval_precision": 0.9755043227665706,
      "eval_recall": 0.8966887417218543,
      "eval_runtime": 1926.2877,
      "eval_samples_per_second": 4.297,
      "eval_steps_per_second": 0.537,
      "step": 603
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9885154738878144,
      "eval_f1": 0.9344375431331953,
      "eval_loss": 0.03386571258306503,
      "eval_precision": 0.9755043227665706,
      "eval_recall": 0.8966887417218543,
      "eval_runtime": 2108.4331,
      "eval_samples_per_second": 3.926,
      "eval_steps_per_second": 0.491,
      "step": 603
    },
    {
      "epoch": 3.0348258706467663,
      "grad_norm": 2.3188323974609375,
      "learning_rate": 2.885715550829522e-05,
      "loss": 0.0205,
      "step": 610
    },
    {
      "epoch": 3.084577114427861,
      "grad_norm": 1.0590392351150513,
      "learning_rate": 2.8713085835263293e-05,
      "loss": 0.0312,
      "step": 620
    },
    {
      "epoch": 3.1343283582089554,
      "grad_norm": 1.633012056350708,
      "learning_rate": 2.8569016162231367e-05,
      "loss": 0.0145,
      "step": 630
    },
    {
      "epoch": 3.18407960199005,
      "grad_norm": 0.9130573868751526,
      "learning_rate": 2.842494648919944e-05,
      "loss": 0.0294,
      "step": 640
    },
    {
      "epoch": 3.2338308457711444,
      "grad_norm": 3.845940351486206,
      "learning_rate": 2.828087681616751e-05,
      "loss": 0.0211,
      "step": 650
    },
    {
      "epoch": 3.283582089552239,
      "grad_norm": 2.0946288108825684,
      "learning_rate": 2.8136807143135582e-05,
      "loss": 0.024,
      "step": 660
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 1.0118780136108398,
      "learning_rate": 2.7992737470103653e-05,
      "loss": 0.0249,
      "step": 670
    },
    {
      "epoch": 3.383084577114428,
      "grad_norm": 0.5303537845611572,
      "learning_rate": 2.7848667797071725e-05,
      "loss": 0.0265,
      "step": 680
    },
    {
      "epoch": 3.4328358208955225,
      "grad_norm": 1.6440281867980957,
      "learning_rate": 2.7704598124039796e-05,
      "loss": 0.0283,
      "step": 690
    },
    {
      "epoch": 3.482587064676617,
      "grad_norm": 1.8165831565856934,
      "learning_rate": 2.7560528451007868e-05,
      "loss": 0.0231,
      "step": 700
    },
    {
      "epoch": 3.5323383084577116,
      "grad_norm": 1.405167579650879,
      "learning_rate": 2.7416458777975943e-05,
      "loss": 0.037,
      "step": 710
    },
    {
      "epoch": 3.582089552238806,
      "grad_norm": 1.332832932472229,
      "learning_rate": 2.7272389104944014e-05,
      "loss": 0.0237,
      "step": 720
    },
    {
      "epoch": 3.6318407960199006,
      "grad_norm": 1.1953366994857788,
      "learning_rate": 2.7128319431912082e-05,
      "loss": 0.0209,
      "step": 730
    },
    {
      "epoch": 3.681592039800995,
      "grad_norm": 1.2881031036376953,
      "learning_rate": 2.6984249758880154e-05,
      "loss": 0.0196,
      "step": 740
    },
    {
      "epoch": 3.7313432835820897,
      "grad_norm": 1.6435582637786865,
      "learning_rate": 2.6840180085848225e-05,
      "loss": 0.0175,
      "step": 750
    },
    {
      "epoch": 3.781094527363184,
      "grad_norm": 0.1841256022453308,
      "learning_rate": 2.66961104128163e-05,
      "loss": 0.0371,
      "step": 760
    },
    {
      "epoch": 3.8308457711442787,
      "grad_norm": 2.222377061843872,
      "learning_rate": 2.6552040739784372e-05,
      "loss": 0.0221,
      "step": 770
    },
    {
      "epoch": 3.8805970149253732,
      "grad_norm": 1.7643389701843262,
      "learning_rate": 2.6407971066752443e-05,
      "loss": 0.0234,
      "step": 780
    },
    {
      "epoch": 3.9303482587064678,
      "grad_norm": 1.2194585800170898,
      "learning_rate": 2.6263901393720518e-05,
      "loss": 0.0289,
      "step": 790
    },
    {
      "epoch": 3.9800995024875623,
      "grad_norm": 1.3986865282058716,
      "learning_rate": 2.6119831720688586e-05,
      "loss": 0.0432,
      "step": 800
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9900870406189555,
      "eval_f1": 0.9454787234042553,
      "eval_loss": 0.02662711963057518,
      "eval_precision": 0.9492656875834445,
      "eval_recall": 0.9417218543046357,
      "eval_runtime": 2129.3709,
      "eval_samples_per_second": 3.887,
      "eval_steps_per_second": 0.486,
      "step": 804
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9900870406189555,
      "eval_f1": 0.9454787234042553,
      "eval_loss": 0.02662711963057518,
      "eval_precision": 0.9492656875834445,
      "eval_recall": 0.9417218543046357,
      "eval_runtime": 1967.7389,
      "eval_samples_per_second": 4.206,
      "eval_steps_per_second": 0.526,
      "step": 804
    },
    {
      "epoch": 4.029850746268656,
      "grad_norm": 0.5591415166854858,
      "learning_rate": 2.5975762047656658e-05,
      "loss": 0.0201,
      "step": 810
    },
    {
      "epoch": 4.079601990049751,
      "grad_norm": 0.33182305097579956,
      "learning_rate": 2.583169237462473e-05,
      "loss": 0.0148,
      "step": 820
    },
    {
      "epoch": 4.129353233830845,
      "grad_norm": 1.4440110921859741,
      "learning_rate": 2.56876227015928e-05,
      "loss": 0.0277,
      "step": 830
    },
    {
      "epoch": 4.17910447761194,
      "grad_norm": 0.9813074469566345,
      "learning_rate": 2.5543553028560876e-05,
      "loss": 0.0139,
      "step": 840
    },
    {
      "epoch": 4.2288557213930345,
      "grad_norm": 1.7689881324768066,
      "learning_rate": 2.5399483355528947e-05,
      "loss": 0.019,
      "step": 850
    },
    {
      "epoch": 4.278606965174129,
      "grad_norm": 2.130875825881958,
      "learning_rate": 2.5255413682497015e-05,
      "loss": 0.0164,
      "step": 860
    },
    {
      "epoch": 4.3283582089552235,
      "grad_norm": 0.3056735694408417,
      "learning_rate": 2.5111344009465087e-05,
      "loss": 0.029,
      "step": 870
    },
    {
      "epoch": 4.378109452736318,
      "grad_norm": 1.034252405166626,
      "learning_rate": 2.496727433643316e-05,
      "loss": 0.0223,
      "step": 880
    },
    {
      "epoch": 4.4278606965174125,
      "grad_norm": 0.7553071975708008,
      "learning_rate": 2.4823204663401233e-05,
      "loss": 0.0175,
      "step": 890
    },
    {
      "epoch": 4.477611940298507,
      "grad_norm": 1.051389217376709,
      "learning_rate": 2.4679134990369305e-05,
      "loss": 0.0171,
      "step": 900
    },
    {
      "epoch": 4.5273631840796025,
      "grad_norm": 1.5936613082885742,
      "learning_rate": 2.4535065317337376e-05,
      "loss": 0.0168,
      "step": 910
    },
    {
      "epoch": 4.577114427860696,
      "grad_norm": 1.5560475587844849,
      "learning_rate": 2.439099564430545e-05,
      "loss": 0.0138,
      "step": 920
    },
    {
      "epoch": 4.6268656716417915,
      "grad_norm": 2.559415578842163,
      "learning_rate": 2.424692597127352e-05,
      "loss": 0.0224,
      "step": 930
    },
    {
      "epoch": 4.676616915422885,
      "grad_norm": 1.3661528825759888,
      "learning_rate": 2.410285629824159e-05,
      "loss": 0.0125,
      "step": 940
    },
    {
      "epoch": 4.726368159203981,
      "grad_norm": 1.7979824542999268,
      "learning_rate": 2.3958786625209662e-05,
      "loss": 0.0208,
      "step": 950
    },
    {
      "epoch": 4.776119402985074,
      "grad_norm": 0.9474805593490601,
      "learning_rate": 2.3814716952177737e-05,
      "loss": 0.0194,
      "step": 960
    },
    {
      "epoch": 4.82587064676617,
      "grad_norm": 1.588686466217041,
      "learning_rate": 2.367064727914581e-05,
      "loss": 0.0141,
      "step": 970
    },
    {
      "epoch": 4.875621890547263,
      "grad_norm": 0.8291963934898376,
      "learning_rate": 2.352657760611388e-05,
      "loss": 0.02,
      "step": 980
    },
    {
      "epoch": 4.925373134328359,
      "grad_norm": 0.9209533333778381,
      "learning_rate": 2.3382507933081948e-05,
      "loss": 0.0161,
      "step": 990
    },
    {
      "epoch": 4.975124378109452,
      "grad_norm": 0.5069712400436401,
      "learning_rate": 2.323843826005002e-05,
      "loss": 0.0159,
      "step": 1000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9915377176015474,
      "eval_f1": 0.9530201342281879,
      "eval_loss": 0.026645001024007797,
      "eval_precision": 0.9659863945578231,
      "eval_recall": 0.9403973509933775,
      "eval_runtime": 1959.4727,
      "eval_samples_per_second": 4.224,
      "eval_steps_per_second": 0.528,
      "step": 1005
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9915377176015474,
      "eval_f1": 0.9530201342281879,
      "eval_loss": 0.026645001024007797,
      "eval_precision": 0.9659863945578231,
      "eval_recall": 0.9403973509933775,
      "eval_runtime": 2072.7219,
      "eval_samples_per_second": 3.993,
      "eval_steps_per_second": 0.499,
      "step": 1005
    },
    {
      "epoch": 5.024875621890548,
      "grad_norm": 0.9065829515457153,
      "learning_rate": 2.3094368587018094e-05,
      "loss": 0.012,
      "step": 1010
    },
    {
      "epoch": 5.074626865671641,
      "grad_norm": 0.8212998509407043,
      "learning_rate": 2.2950298913986166e-05,
      "loss": 0.0118,
      "step": 1020
    },
    {
      "epoch": 5.124378109452737,
      "grad_norm": 0.44578322768211365,
      "learning_rate": 2.2806229240954237e-05,
      "loss": 0.0221,
      "step": 1030
    },
    {
      "epoch": 5.174129353233831,
      "grad_norm": 0.7109887003898621,
      "learning_rate": 2.266215956792231e-05,
      "loss": 0.0076,
      "step": 1040
    },
    {
      "epoch": 5.223880597014926,
      "grad_norm": 1.0490081310272217,
      "learning_rate": 2.2518089894890384e-05,
      "loss": 0.0131,
      "step": 1050
    },
    {
      "epoch": 5.273631840796019,
      "grad_norm": 0.5669865012168884,
      "learning_rate": 2.2374020221858452e-05,
      "loss": 0.0098,
      "step": 1060
    },
    {
      "epoch": 5.323383084577115,
      "grad_norm": 4.077725887298584,
      "learning_rate": 2.2229950548826523e-05,
      "loss": 0.0146,
      "step": 1070
    },
    {
      "epoch": 5.373134328358209,
      "grad_norm": 1.0010126829147339,
      "learning_rate": 2.2085880875794595e-05,
      "loss": 0.0113,
      "step": 1080
    },
    {
      "epoch": 5.422885572139304,
      "grad_norm": 0.578267514705658,
      "learning_rate": 2.194181120276267e-05,
      "loss": 0.0089,
      "step": 1090
    },
    {
      "epoch": 5.472636815920398,
      "grad_norm": 1.143665075302124,
      "learning_rate": 2.179774152973074e-05,
      "loss": 0.012,
      "step": 1100
    },
    {
      "epoch": 5.522388059701493,
      "grad_norm": 0.8862566351890564,
      "learning_rate": 2.1653671856698813e-05,
      "loss": 0.0149,
      "step": 1110
    },
    {
      "epoch": 5.572139303482587,
      "grad_norm": 1.0811655521392822,
      "learning_rate": 2.150960218366688e-05,
      "loss": 0.0158,
      "step": 1120
    },
    {
      "epoch": 5.621890547263682,
      "grad_norm": 1.0381925106048584,
      "learning_rate": 2.1365532510634956e-05,
      "loss": 0.0156,
      "step": 1130
    },
    {
      "epoch": 5.6716417910447765,
      "grad_norm": 0.32909253239631653,
      "learning_rate": 2.1221462837603027e-05,
      "loss": 0.0059,
      "step": 1140
    },
    {
      "epoch": 5.721393034825871,
      "grad_norm": 0.4503680169582367,
      "learning_rate": 2.10773931645711e-05,
      "loss": 0.012,
      "step": 1150
    },
    {
      "epoch": 5.7711442786069655,
      "grad_norm": 1.5129973888397217,
      "learning_rate": 2.093332349153917e-05,
      "loss": 0.0159,
      "step": 1160
    },
    {
      "epoch": 5.82089552238806,
      "grad_norm": 0.7066344618797302,
      "learning_rate": 2.0789253818507245e-05,
      "loss": 0.0142,
      "step": 1170
    },
    {
      "epoch": 5.870646766169155,
      "grad_norm": 0.1907099336385727,
      "learning_rate": 2.0645184145475316e-05,
      "loss": 0.0178,
      "step": 1180
    },
    {
      "epoch": 5.920398009950249,
      "grad_norm": 0.8656816482543945,
      "learning_rate": 2.0501114472443385e-05,
      "loss": 0.0125,
      "step": 1190
    },
    {
      "epoch": 5.970149253731344,
      "grad_norm": 0.5699319839477539,
      "learning_rate": 2.0357044799411456e-05,
      "loss": 0.0099,
      "step": 1200
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9926257253384912,
      "eval_f1": 0.958922558922559,
      "eval_loss": 0.025912407785654068,
      "eval_precision": 0.9753424657534246,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 2028.6474,
      "eval_samples_per_second": 4.08,
      "eval_steps_per_second": 0.51,
      "step": 1206
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9926257253384912,
      "eval_f1": 0.958922558922559,
      "eval_loss": 0.025912407785654068,
      "eval_precision": 0.9753424657534246,
      "eval_recall": 0.9430463576158941,
      "eval_runtime": 1936.0176,
      "eval_samples_per_second": 4.275,
      "eval_steps_per_second": 0.535,
      "step": 1206
    },
    {
      "epoch": 6.019900497512438,
      "grad_norm": 1.629844069480896,
      "learning_rate": 2.0212975126379528e-05,
      "loss": 0.0131,
      "step": 1210
    },
    {
      "epoch": 6.069651741293533,
      "grad_norm": 0.14528711140155792,
      "learning_rate": 2.0068905453347602e-05,
      "loss": 0.0134,
      "step": 1220
    },
    {
      "epoch": 6.119402985074627,
      "grad_norm": 0.4833994209766388,
      "learning_rate": 1.9924835780315674e-05,
      "loss": 0.0093,
      "step": 1230
    },
    {
      "epoch": 6.169154228855722,
      "grad_norm": 0.19657747447490692,
      "learning_rate": 1.9780766107283745e-05,
      "loss": 0.0091,
      "step": 1240
    },
    {
      "epoch": 6.218905472636816,
      "grad_norm": 1.1680731773376465,
      "learning_rate": 1.9636696434251814e-05,
      "loss": 0.0113,
      "step": 1250
    },
    {
      "epoch": 6.268656716417911,
      "grad_norm": 0.1657952219247818,
      "learning_rate": 1.949262676121989e-05,
      "loss": 0.0052,
      "step": 1260
    },
    {
      "epoch": 6.318407960199005,
      "grad_norm": 0.9133977890014648,
      "learning_rate": 1.934855708818796e-05,
      "loss": 0.007,
      "step": 1270
    },
    {
      "epoch": 6.3681592039801,
      "grad_norm": 0.33164215087890625,
      "learning_rate": 1.920448741515603e-05,
      "loss": 0.0187,
      "step": 1280
    },
    {
      "epoch": 6.417910447761194,
      "grad_norm": 1.5654468536376953,
      "learning_rate": 1.9060417742124103e-05,
      "loss": 0.0158,
      "step": 1290
    },
    {
      "epoch": 6.467661691542289,
      "grad_norm": 0.06179463490843773,
      "learning_rate": 1.8916348069092178e-05,
      "loss": 0.0093,
      "step": 1300
    },
    {
      "epoch": 6.517412935323383,
      "grad_norm": 0.791739284992218,
      "learning_rate": 1.877227839606025e-05,
      "loss": 0.0132,
      "step": 1310
    },
    {
      "epoch": 6.567164179104478,
      "grad_norm": 0.19004252552986145,
      "learning_rate": 1.8628208723028317e-05,
      "loss": 0.0082,
      "step": 1320
    },
    {
      "epoch": 6.616915422885572,
      "grad_norm": 0.7450995445251465,
      "learning_rate": 1.848413904999639e-05,
      "loss": 0.0089,
      "step": 1330
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.5870160460472107,
      "learning_rate": 1.8340069376964464e-05,
      "loss": 0.0125,
      "step": 1340
    },
    {
      "epoch": 6.7164179104477615,
      "grad_norm": 0.5082821249961853,
      "learning_rate": 1.8195999703932535e-05,
      "loss": 0.0073,
      "step": 1350
    },
    {
      "epoch": 6.766169154228856,
      "grad_norm": 1.2364888191223145,
      "learning_rate": 1.8051930030900607e-05,
      "loss": 0.0146,
      "step": 1360
    },
    {
      "epoch": 6.8159203980099505,
      "grad_norm": 0.36004531383514404,
      "learning_rate": 1.7907860357868678e-05,
      "loss": 0.0133,
      "step": 1370
    },
    {
      "epoch": 6.865671641791045,
      "grad_norm": 0.0694144144654274,
      "learning_rate": 1.7763790684836753e-05,
      "loss": 0.0087,
      "step": 1380
    },
    {
      "epoch": 6.91542288557214,
      "grad_norm": 0.528835654258728,
      "learning_rate": 1.761972101180482e-05,
      "loss": 0.012,
      "step": 1390
    },
    {
      "epoch": 6.965174129353234,
      "grad_norm": 5.570969581604004,
      "learning_rate": 1.7475651338772893e-05,
      "loss": 0.0115,
      "step": 1400
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9923839458413927,
      "eval_f1": 0.9574611748818366,
      "eval_loss": 0.025343654677271843,
      "eval_precision": 0.9765840220385675,
      "eval_recall": 0.9390728476821192,
      "eval_runtime": 2075.5291,
      "eval_samples_per_second": 3.988,
      "eval_steps_per_second": 0.499,
      "step": 1407
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9923839458413927,
      "eval_f1": 0.9574611748818366,
      "eval_loss": 0.025343654677271843,
      "eval_precision": 0.9765840220385675,
      "eval_recall": 0.9390728476821192,
      "eval_runtime": 2076.0309,
      "eval_samples_per_second": 3.987,
      "eval_steps_per_second": 0.499,
      "step": 1407
    },
    {
      "epoch": 7.014925373134329,
      "grad_norm": 0.2525898814201355,
      "learning_rate": 1.7331581665740964e-05,
      "loss": 0.009,
      "step": 1410
    },
    {
      "epoch": 7.064676616915423,
      "grad_norm": 0.6395272612571716,
      "learning_rate": 1.7187511992709036e-05,
      "loss": 0.0058,
      "step": 1420
    },
    {
      "epoch": 7.114427860696518,
      "grad_norm": 0.1424161046743393,
      "learning_rate": 1.704344231967711e-05,
      "loss": 0.0068,
      "step": 1430
    },
    {
      "epoch": 7.164179104477612,
      "grad_norm": 0.5260193347930908,
      "learning_rate": 1.6899372646645182e-05,
      "loss": 0.0043,
      "step": 1440
    },
    {
      "epoch": 7.213930348258707,
      "grad_norm": 0.8678063154220581,
      "learning_rate": 1.675530297361325e-05,
      "loss": 0.008,
      "step": 1450
    },
    {
      "epoch": 7.263681592039801,
      "grad_norm": 0.01187829114496708,
      "learning_rate": 1.6611233300581325e-05,
      "loss": 0.0089,
      "step": 1460
    },
    {
      "epoch": 7.313432835820896,
      "grad_norm": 1.0460680723190308,
      "learning_rate": 1.6467163627549397e-05,
      "loss": 0.0074,
      "step": 1470
    },
    {
      "epoch": 7.36318407960199,
      "grad_norm": 0.5494433045387268,
      "learning_rate": 1.6323093954517468e-05,
      "loss": 0.009,
      "step": 1480
    },
    {
      "epoch": 7.412935323383085,
      "grad_norm": 0.5291463136672974,
      "learning_rate": 1.617902428148554e-05,
      "loss": 0.0076,
      "step": 1490
    },
    {
      "epoch": 7.462686567164179,
      "grad_norm": 1.3351869583129883,
      "learning_rate": 1.603495460845361e-05,
      "loss": 0.0104,
      "step": 1500
    },
    {
      "epoch": 7.512437810945274,
      "grad_norm": 0.6404370069503784,
      "learning_rate": 1.5890884935421683e-05,
      "loss": 0.0079,
      "step": 1510
    },
    {
      "epoch": 7.562189054726368,
      "grad_norm": 0.38155707716941833,
      "learning_rate": 1.5746815262389754e-05,
      "loss": 0.0162,
      "step": 1520
    },
    {
      "epoch": 7.611940298507463,
      "grad_norm": 1.08560311794281,
      "learning_rate": 1.5602745589357825e-05,
      "loss": 0.0089,
      "step": 1530
    },
    {
      "epoch": 7.661691542288557,
      "grad_norm": 0.6758681535720825,
      "learning_rate": 1.5458675916325897e-05,
      "loss": 0.0082,
      "step": 1540
    },
    {
      "epoch": 7.711442786069652,
      "grad_norm": 0.8098576664924622,
      "learning_rate": 1.5314606243293972e-05,
      "loss": 0.0107,
      "step": 1550
    },
    {
      "epoch": 7.7611940298507465,
      "grad_norm": 0.19258815050125122,
      "learning_rate": 1.517053657026204e-05,
      "loss": 0.0096,
      "step": 1560
    },
    {
      "epoch": 7.810945273631841,
      "grad_norm": 1.285760760307312,
      "learning_rate": 1.5026466897230113e-05,
      "loss": 0.0113,
      "step": 1570
    },
    {
      "epoch": 7.8606965174129355,
      "grad_norm": 0.18786966800689697,
      "learning_rate": 1.4882397224198185e-05,
      "loss": 0.0051,
      "step": 1580
    },
    {
      "epoch": 7.91044776119403,
      "grad_norm": 0.15398772060871124,
      "learning_rate": 1.4738327551166258e-05,
      "loss": 0.0042,
      "step": 1590
    },
    {
      "epoch": 7.960199004975125,
      "grad_norm": 0.6929457187652588,
      "learning_rate": 1.4594257878134328e-05,
      "loss": 0.0101,
      "step": 1600
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9931092843326886,
      "eval_f1": 0.9617706237424548,
      "eval_loss": 0.02281636744737625,
      "eval_precision": 0.9741847826086957,
      "eval_recall": 0.9496688741721855,
      "eval_runtime": 1904.4462,
      "eval_samples_per_second": 4.346,
      "eval_steps_per_second": 0.543,
      "step": 1608
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9931092843326886,
      "eval_f1": 0.9617706237424548,
      "eval_loss": 0.02281636744737625,
      "eval_precision": 0.9741847826086957,
      "eval_recall": 0.9496688741721855,
      "eval_runtime": 1970.0608,
      "eval_samples_per_second": 4.201,
      "eval_steps_per_second": 0.525,
      "step": 1608
    }
  ],
  "logging_steps": 10,
  "max_steps": 2613,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 13,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 4
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.922571309520336e+16,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": {
    "epochs": 13,
    "gradient_accumulation_steps": 3,
    "learning_rate": 3.345297807801373e-05,
    "optim": "adamw_torch",
    "per_device_train_batch_size": 64,
    "warmup_steps": 291,
    "weight_decay": 0.060582828218983246
  }
}
